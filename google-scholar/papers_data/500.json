[{"title": "Whose emotions and moral sentiments do language models reflect?", "year": "2024", "pdf_data": "Whose Emotions and Moral Sentiments Do Language Models Reflect?\nZihao He, Siyi Guo, Ashwin Rao, Kristina Lerman\nUSC Information Sciences Institute\n{zihaoh, siyiguo, mohamrao}@usc.edu ,lerman@isi.edu\nAbstract\nLanguage models (LMs) are known to repre-\nsent the perspectives of some social groups bet-\nter than others, which may impact their per-\nformance, especially on subjective tasks such\nas content moderation and hate speech detec-\ntion. To explore how LMs represent different\nperspectives, existing research focused on posi-\ntional alignment, i.e., how closely the models\nmimic the opinions and stances of different\ngroups, e.g., liberals or conservatives. How-\never, human communication also encompasses\nemotional and moral dimensions. We define\nthe problem of affective alignment , which mea-\nsures how LMs\u2019 emotional and moral tone rep-\nresents those of different groups. By comparing\nthe affect of responses generated by 36 LMs\nto the affect of Twitter messages written by\ntwo ideological groups, we observe significant\nmisalignment of LMs with both ideological\ngroups. This misalignment is larger than the\npartisan divide in the U.S. Even after steering\nthe LMs towards specific ideological perspec-\ntives, the misalignment and liberal tendencies\nof the model persist, suggesting a systemic bias\nwithin LMs.1\n1 Introduction\nThe capacity of language models (LMs) to generate\nhuman-like responses to natural language prompts\nhas led to new technologies that support people\non cognitive tasks requiring complex judgements.\nHowever, researchers found that LMs inherit bi-\nases2from humans, as their views are shaped by\nonline users who produced the pretraining data,\nfeedback from crowdworkers during Reinforce-\nment Learning from Human Feedback (RLHF) pro-\ncess (Ouyang et al., 2022), and potentially, the de-\ncisions made by the model developers themselves\n(Santurkar et al., 2023). In subjective tasks, such as\n1Code and data are available at https://github.\ncom/zihaohe123/llm-affective-alignment .\n2Throughout this paper, we use \u201cbias\u201d to refer to a system-\natic statistical tendency, rather than unfairness or prejudice.hate speech detection (Hartvigsen et al., 2022), con-\ntent moderation (He et al., 2023), and legal judge-\nment (Jiang and Yang, 2023), these biases may\nshow up as LMs adopting the perspectives of one\ngroup while excluding others. This may lead to un-\ndesirable downstream consequences, ranging from\nnegative user experiences with LMs to societal-\nlevel inequity, division and polarization.\nTo examine how LMs represent differences in\nperspectives of different groups, existing research\nhas looked at positional alignment : how closely\nthe model\u2019s opinions or stances mirror those of\ndifferent social groups (Santurkar et al., 2023; Dur-\nmus et al., 2023). Using multi-choice survey ques-\ntions, researchers have demonstrated that language\nmodels are misaligned with the US population and\nrepresent the perspectives of some demographic\ngroups better than others.\nHowever, positional agreement captures just one\naspect of alignment. Human communication also\ncarries cues to emotions and moral sentiments\u2013\ncollectively referred to as affect \u2013which are inte-\ngral to social interaction and cohesion (Graham\net al., 2009; Iyengar et al., 2019; Mokhberian et al.,\n2020). While emotions help shape individual\u2019s\npositions and stances on issues, they are distinct\nconstructs. Take an example of a specific position\n\u2013 a pro-masking stance. The same position can\nbe expressed using contrasting emotions as in the\nfollowing two statements:\n\u2022Every mask we wear is a badge of honor, show-\ning love and respect for our communities.\n\u2022It\u2019s heartbreaking to see the impact of not\nwearing masks - lives lost, dreams deferred.\nEvery choice to ditch the mask deepens the\ncrisis. Let\u2019s not add to the pain.\nWhile both statement take a pro-masking stance,\nthe first one expresses positive emotions, and the\nsecond negative ones.arXiv:2402.11114v2  [cs.CL]  17 Jun 2024\nComposeatweetaboutCOVID-19maskmandatesandpolicies.ComposeatweetaboutCOVID-19maskmandatesandpoliciesfromliberal/conservativeviewpoint.\n1.Wearingamaskisasimpleandeffectivewaytoprotectyourselfandothers.2.COVID-19maskmandatesandpoliciesareaninfringementonindividualfreedomandpersonalresponsibility\u2026.1.WeneedmaskforeverypersoninAmerica.Thespreadof#Covid19islikenothingwe\u2019veseenbefore.2.Thisisridiculous.WhatifIcan\u2019taffordthem.Whataboutverypoorandwhatiftherearen\u2019tany.Thisisasickpowerplayedbyliberals.\u2026.\nalignment=1-JSDEmotion/MFDetectionhumanshuman-writtentweetsLM-generatedtweetsLMdefaultpromptingsteeredpromptingORLM-generatedemotion/MFdistribution\nhumanemotion/MFdistributionFigure 1: The framework for evaluating affective alignment of LMs. We first prompt LMs to generate tweets\non a topic using default prompting or steered prompting. The distributions of emotions and moral sentiments of\nLM-generated tweets are then compared to that of human-authored tweets. Affective alignment is measured as one\nminus the Jensen-Shannon distance (JSD) between the two distributions.\nHow LMs represent affect plays an important\nrole in their performance in downstream tasks, es-\npecially subjective tasks. Consider how an LM\nfacilitating online discussions may handle the com-\nment: \u201c Wearing a mask is a personal choice, not a\npublic responsibility. \u201d An LM aligned with conser-\nvatives would not flag this comment as it prioritized\nthe moral sentiments of liberty and authority typi-\ncally associated with conservatives (Do \u02d8gruyol et al.,\n2019). However, this comment may evoke nega-\ntive reactions from liberals, as it goes against their\ndeeply-held values of care and fairness, prompting\na liberal-aligned LM to flag it. Therefore, we ask:\nWhose affect, i.e., emotional and moral tone, do\nlanguage models reflect?\nOur contributions. We define affective alignment\nas the degree to which a model\u2019s emotional and\nmoral tone matches that of people in similar sit-\nuations. To study this, we analyze two datasets\nof Twitter messages on contentious issues like\nCOVID-19 and abortion, disaggregating users by\npolitical ideology (liberal or conservative). We\nprompt 36 LMs of varying sizes to generate state-\nments on topics like \u201cCOVID-19 mask mandates\u201d\nand \u201cabortion rights and access,\u201d then compare\nthe emotions and moral sentiments in the model-\ngenerated responses to those of Twitter users from\ndifferent ideological groups.\nWe first assess the models\u2019 default affective\nalignment, based on the responses to default\nprompts that do not include information about a tar-\nget demographic (persona). Our findings suggest\nthat LMs show significant misalignment in affect\nwith either ideological group, and the differences\nare larger than the ideological divide on Twitter.\nMoreover, consistent with prior findings (Santurkaret al., 2023; Perez et al., 2022; Hartmann et al.,\n2023), all LMs exhibit liberal tendencies on topics\nrelated to COVID-19.\nNext, we assess LMs\u2019 affective alignment after\nwe provide additional context in the prompt\u2014 steer\nthe model\u2014to generate texts from the perspective\nof liberals or conservatives. The results reveal that\nsteering can help align LMs with the target group\u2019s\naffect. However, even after steering, the models\nremain misaligned, and liberal tendencies of LMs\ncannot be mitigated by steering.\nWe believe that a deep analysis of the affect ex-\npressed by existing LMs is crucial for building AI\nsystems for greater social good. To the best of our\nknowledge, our work is the first to systematically\nassess the affective alignment of LMs, which high-\nlights the unequal affective representations of dif-\nferent ideological groups in current LMs. We hope\nthat our framework can help guide future research\nin better understanding LMs\u2019 representativeness of\npeople from diverse backgrounds on an emotional\nand moral level. We elaborate the broader impact\nof the affective alignment in Appendix A.\nClarification on the scope. Our work introduces\na new task of systematically probing LMs\u2019 affective\nalignment with different social groups. We aim to\nobjectively present our finding and offer insights,\nrather than prescribing optimization. Whether a\nhigh degree of affective alignment towards each\nsingle group is desirable, and whether LMs should\nequally represent each group\u2019s affect, are highly\ndependent on the application context.\n2 Measuring Affective Alignment\nFigure 1 shows the overall framework. We first\nprompt LMs to generate tweets on some topic us-\ningdefault prompting orsteered prompting . We\nuse state-of-the-art classifiers to measure emotions\nand moral sentiment of both LM-generated tweets\nand human-authored tweets. The affective align-\nment is measured as one minus the Jensen-Shannon\ndistance (JSD) between the distributions of affect.\n2.1 Online Sociopolitical Discourse\nTo represent human affect empirically, we compile\ntwo Twitter datasets on sociopolitical discourse\u2014\nCOVID-19 Tweets and Roe v. Wade Tweets\u2014and\nidentify fine-grained sub-topics related to both is-\nsues. We estimate the ideological leanings (liberals\nvs. conservatives) of users based on the political\nbias of the news outlets they share. See Appendix\nB for details.\n2.2 Text Generated by LMs\nWe categorize LMs into two groups: 1) base LMs\n(Ouyang et al., 2022; Touvron et al., 2023; Al-\nmazrouei et al., 2023; Jiang et al., 2023; Conover\net al., 2023; Chung et al., 2022; Zheng et al., 2023),\nthat have been pretrained with the causal language\nmodeling objective using data from the Internet; 2)\ninstruction-tuned LMs (Ouyang et al., 2022; Tou-\nvron et al., 2023; Almazrouei et al., 2023; Jiang\net al., 2023; Conover et al., 2023; Chung et al.,\n2022; Zheng et al., 2023), that have been further\nfinetuned on instructions following and with RLHF\nfor better alignment with human values. To guide\nthe LM to generate open-ended responses on dif-\nferent topics, we use opinion-eliciting prompts. To\nmeasure affect representativeness of models in dif-\nferent configurations, we consider the following\ntwo settings:\n\u2022Default Prompting \u2013 We prompt the LM to\ngenerate responses without providing with any\nadditional context. Our goal is to measure the\ndefault representativeness of affect expressed\nby the LM. This would potentially disclose the\ndisparity (if any) of the LM in representing\nperspectives of different demographic groups.\nAn example prompt for base LMs is \u201cIn a\ntweet about [topic], it\u2019s said that: \u201d, and for\ninstruction-tuned LMs is \u201cShare your thoughts\non [topic] in a tweet.\u201d, where \u201c[topic]\u201d is re-\nplaced with the one of the fine-grained topics\ndiscovered in the COVID-19 Tweets or the\nRoe v. Wade Tweets (Table 1 and 2 in Ap-\npendix B).\u2022Steered Prompting \u2013 We steer the LM to\ngenerate responses from the perspective of\na specific demographic group, or persona, by\nadding context to the prompt. This aims to\ntest the model\u2019s steerability, i.e., how well it\ncan align itself with a specific demographic\ngroup when instructed to do so. We explore\nwhether the model\u2019s affective alignment with\na persona increases through steered prompt-\ningcompared to default prompting . In this\nwork we focus on ideological groups (i.e., lib-\nerals vs conservatives) and perform \u201cliberal\nsteering\u201d and \u201cconservative steering.\u201d One\nexample of steered prompting for base LMs\nis \u201cHere\u2019s a tweet regarding [topic] from a\nliberal/conservative standpoint :\u201d, and for\ninstruction-tuned LMs is \u201cCompose a tweet\nabout [topic] from a liberal/conservative\nviewpoint.\u201d\nThe idea for these two kinds of prompting is in-\nspired by previous works (Santurkar et al., 2023;\nDurmus et al., 2023). To mitigate the effect of\nthe model\u2019s sensitivity to the specific wording in\na prompt, we craft 10 different prompts for the\nbase LMs and instruction-tuned LMs, using default\nprompting andsteered prompting , respectively (Ta-\nble 4 in Appendix). For each fine-grained topic,\nwe generate 2,000 responses, using 2,000 prompts\nrandomly sampled (with replacement) from the 10\ncandidate prompts. For more details on the genera-\ntion process, please see Appendix D.1.\n2.3 Measuring Affect\nHuman affect, including emotions and morality, in\nonline discourses is used as an indicator to track\npublic opinion on important issues and monitor the\nwell-being of populations (Kla\u0161nja et al., 2018).\nDetecting Emotions. Emotions are a powerful el-\nement of human communication (vanKleef et al.,\n2016). To detect emotions, we use SpanEmo (Al-\nhuzali et al., 2021), fine-tuned on top of BERT (De-\nvlin et al., 2019) on the SemEval 2018 1e-c data\n(Mohammad et al., 2018), which is specifically\ncurated from Twitter and widely recognized as a\nbenchmark for emotion detection on social media.\nSpanEmo learns the correlations among the emo-\ntions and achieves a micro-F1 score of 0.713 on this\ndataset, outperforming several other baselines and\nachieving the state-of-the-art in detecting emotions\non Twitter data. In addition, Rao et al. (2023a) an-\nnotated the emotions of a subset of the Roe v. Wade\ntweets that we use in our paper, and further evalu-\nated SpanEmo\u2019s performance on it. They showed\nan average accuracy of over 0.9 across different\nemotions. We measure the following emotions: an-\nticipation ,joy,love,trust,optimism ,anger ,disgust ,\nfear,sadness ,pessimism andsurprise . The model\nreturns a score giving the confidence that a tweet\nexpresses an emotion. We average scores over all\ntweets with that emotion.\nDetecting Moral Sentiments. Moral Founda-\ntions Theory (Haidt et al., 2007) posits that\nindividuals\u2019 moral perspectives are a combina-\ntion of a set of foundational values. These\nmoral foundations are quantified along five dimen-\nsions: dislike of suffering ( care/harm ), dislike of\ncheating ( fairness /cheating ), group loyalty ( loy-\nalty/betrayal ), respect for authority and tradition\n(authority /subversion ), and concerns with purity\nand contamination ( purity /degradation ). These\nmoral dimensions are crucial for understanding\nthe values driving liberal and conservative dis-\ncourse. We use DAMF (Guo et al., 2023b) for\nmoral sentiment detection, which is finetuned on\ntop of BERT (Devlin et al., 2019) on three Twitter\ndatasets (including COVID-19 tweets and abortion-\nrelated tweets studied in this paper) and one news\narticle dataset. The large amount and the variety\nof topics in the training data helps mitigate the\ndata distribution shift during inference. Guo et al.\n(2023b) annotated the moral foundations of a sub-\nset of the COVID-19 tweets that we use in our\npaper, and further evaluated the performance of\nDAMF on it, which led to F1-score of 0.71 . The\nmodel returns a value indicating a confidence that\na tweet expresses a moral foundation. We average\nscores over all tweets with that moral foundation.\n2.4 Measuring Alignment\nLet us represent an LM as fand a group of hu-\nmans as g. We aim to measure affective alignment\nST(f, g)between the LM fand humans gon a set\nofntopics T={t1, t2, ..., t n}by measuring emo-\ntions (resp. moral sentiments) expressed in tweets\nabout each topic ti\u2208T. Human-authored tweets\nabout tare available in a dataset (e.g., COVID-19\nTweets or Roe v. Wade Tweets). To create LM\u2019s\ntweets about ti, we prompt it on the topic to gen-\nerate a set of mresponses R={r1, r2, ..., r m}.\nWe compare \u02c6D(ti), the distribution of emotions\n(resp. moral foundations) in LM-generated tweets\non topic ti, and D(ti), the distribution in human-authored tweets on the same topic. We measure af-\nfective alignment on a topic tiasSti(f, g)\u2208[0,1],\nusing (1 - Jensen-Shannon Distance) between the\ndistributions \u02c6D(ti)andD(ti). The alignment of\nLMfwith humans gon the set of topics Tis aver-\naged over that for each topic tiin it:\nST(f, g) =1\nnnX\ni=1(1\u2212JSD(\u02c6D(ti), D(ti))).(1)\nA value of STclose to 1 implies strong align-\nment, while smaller values imply weak alignment.\nFor an LM f, we study the default model ( fdefault ),\nthe liberal steered model ( flib_steered ), and the con-\nservative steered model ( fcon_steered ). For humans,\nwe study liberals ( gl) and conservatives ( gc).\n2.4.1 Proximity Between Emotions\nTo more accurately capture the interrelated nature\nof emotions3, we integrate the concept of emo-\ntional proximity using the Plutchik Emotion Agree-\nment (PEA). For instance, emotions like joyand\nlove are closer on the emotional spectrum than joy\nandanger . To quantitatively capture these relation-\nships, we utilize the Plutchik Emotion Agreement\n(PEA) (Desai et al., 2020), leveraging the Plutchik\nwheel (Plutchik, 2001) which organizes emotions\ninto a spatial model indicative of their relational\nproximity. The PEA is calculated from the polar\ncoordinates of each emotion on the wheel, as\nPEA(ei, ej) =max(|1\u22121\n\u03c0|f(ei), f(ej)||),(2)\nwhere eiandejare two different emotions, and\nf(e)represents the polar coordinate of the emo-\ntion. The emotion proximity matrix A, where\nAijrepresents the proximity between eiandej, is\nshown in Appendix C. This methodological adjust-\nment allows us to account for the interconnected\nnature of emotional expressions, refining our align-\nment measurements. We weight the emotion dis-\ntributions vectors using the proximity matrix, as\n\u02c6D\u2032(t) =A\u00b7\u02c6D(t), andD\u2032(t) =A\u00b7D(t), then use\nthe weighted vectors for computing the affective\nalignment as in Equation 1.\n3We only consider the agreement between different emo-\ntions but not moral foundations, as there is no existing work on\nmodeling the structure of moral foundations as the Plutchik\u2019s\nwheel for emotions.\n1.0 0.9 0.8 0.7\naffective alignment (S)gl\ngc\ngpt-3.5*\nllama-2-7b-chat*\nllama-2-13b-chat*\nmistral-7b-instruct*\nfalcon-7b-instruct*\ndolly-v2-3b*\ndolly-v2-7b*\ndolly-v2-12b*\nflan-t5-xl*\nflan-t5-xxl*\nvicuna-7b-v1.5-16k*\nvicuna-13b-v1.5-16k*\ngpt-3-davinci*\ngpt-3-babbage*\nllama-2-7b*\nllama-2-13b*\nmistral-7b*\nfalcon-7b*\nopt-125m*\nopt-350m*\nopt-1.3b*\nopt-2.7b*\nopt-6.7b*\nopt-13b*\nopt-iml-1.3b*\nbloom-560m*\nbloom-1b1*\nbloom-1b7*\nbloom-3b*\npythia-160m*\npythia-410m*\npythia-1b*\npythia-1.4b*\npythia-2.8b*\npythia-6.9b*\npythia-12b*\nS(f,gl)\nS(f,gc)(a) Affective alignment Sin COVID-19.\n1.0 0.9 0.8 0.7 0.6\naffective alignment (S)gl\ngc\ngpt-3.5\nllama-2-7b-chat\nllama-2-13b-chat\nmistral-7b-instruct\nfalcon-7b-instruct\ndolly-v2-3b\ndolly-v2-7b\ndolly-v2-12b\nflan-t5-xl\nflan-t5-xxl\nvicuna-7b-v1.5-16k\nvicuna-13b-v1.5-16k\ngpt-3-davinci\ngpt-3-babbage\nllama-2-7b\nllama-2-13b\nmistral-7b\nfalcon-7b\nopt-125m\nopt-350m\nopt-1.3b\nopt-2.7b\nopt-6.7b\nopt-13b\nopt-iml-1.3b\nbloom-560m\nbloom-1b1\nbloom-1b7\nbloom-3b\npythia-160m\npythia-410m\npythia-1b\npythia-1.4b\npythia-2.8b\npythia-6.9b\npythia-12b\nS(f,gl)\nS(f,gc) (b) Affective alignment Sin Roe v. Wade.\nFigure 2: Default affect alignment Sof different LMs with ideological groups \u2013 liberals ( gl) and conservatives ( gc),\nmeasured by emotions . * indicates that the alignment of the model with both ideological groups are significantly\ndifferent at p <0.05. For each LM, the alignment is averaged over that on different topics related to the issue, with\nthe means shown by circles and the standard deviations shown by errors bars. Base LMs and instruction-tuned LMs\nare separated by the black horizontal dashed line. The alignment between the two ideological groups (above the red\nhorizontal dashed line) themselves are measured as a baseline.\n3 Results and Analysis\n3.1 Representativeness of Affect under\nDefault Prompting\nOur investigation into the affective alignment of\nLMs with humans starts with two research ques-\ntions: (1) Do language models exhibit strong af-\nfective alignment with human groups? (2)Do the\nmodels equitably represent each group?\nFigures 2 reports the affective alignment of var-\nious LMs with liberals ( gl) and conservatives ( gc)\nby default prompting in the two datasets, measured\nby emotions. Please refer to Appendix D.2 for\nresults measured by moral sentiments. Since the\npatterns of alignment measured by emotions and\nmoral sentiments are similar, we focus on the emo-\ntional alignment.\nDo the models exhibit strong affective align-\nment? Defining a precise threshold for \u201cstrong\u201d\nalignment is challenging. We consider as baseline\nthe alignment between the two ideological groups\non Twitter, i.e. emotion similarity between liber-als and conservatives in online discourses (vertical\nlines in Figure 2). Any alignment falling short of\nthis benchmark could be deemed insufficient, given\nthe profound divisions in contemporary sociopolit-\nical discourse (Rao et al., 2023b). This baseline is\nhenceforth referred to as the \u201cpartisan alignment\nbaseline\u201d.\nFrom Figure 2, it is evident that nearly all LMs\nfall short of the partisan alignment baseline, indicat-\ning weak alignment. Base LMs, trained on causal\nlanguage modeling tasks without explicit affective\nalignment tuning, seem to lack the capacity to learn\naffect during the pretraining phase. Instruction-\ntuned models, despite undergoing instruction-based\nand RLHF training to foster alignment with human\nvalues, do not appear to extend this alignment to\nemotional or moral dimensions. Notably, even so-\nphisticated models like GPT-3.5 exhibit heightened\nmisalignment compared to base models. This could\nbe attributed to the models\u2019 intricate architectures\nand training processes, which may inadvertently\namplify misalignment due to their complexity and\nsensitivity to the training data\u2019s composition.\nWhile this paper focuses on political identities,\nit is conceivable that the default affect distribution\nof the models might be more closely aligned with\nother demographic groups. Future research could\nexplore various demographic segments beyond the\npolitical dimension to identify those with which the\nmodels demonstrate stronger affective alignment.\nDo the models represent each group equi-\ntably? It is apparent that on COVID-19, all LMs\nreveal liberal tendencies, as the alignment with lib-\nerals is consistently higher, and the partisan align-\nment difference is statistically significant. Given\nthe novelty of COVID-19 and its prevalence on\nsocial media, where liberal perspectives dominate\n(Shah et al., 2020), we hypothesize that a signifi-\ncant portion of the LMs\u2019 pretraining data is derived\nfrom discussions in these forums, and thus LMs\nabsorb more emotional and moral tone of liberal\nnarratives.\nConversely, on the Roe v. Wade Tweets (Fig-\nure 2b) the LMs display no discernible political\ntendencies, with some models exhibiting a slight\nliberal inclination and others conservative, leading\nto a generally balanced alignment with both po-\nlitical ideologies. In fact, the partisan alignment\ndifference is not statistically significant on Roe v.\nWade. In contrast to COVID-19, Roe v. Wade\nis a longstanding issue in U.S. history, with dis-\ncourses extending well beyond social media plat-\nforms. Consequently, it is likely that the discus-\nsions encompassing both political ideologies are\nmore evenly represented in the pretraining data for\nLMs.\n3.2 Representativeness of Affect in Steered\nPrompting\nWe now move to analyze the affect representative-\nness in steered scenarios, where models are explic-\nitly prompted to align with ideological leanings.\nThis approach helps us understand the malleability\nof LMs when directed to mimic specific personas.\nWe aim to study the following research questions:\n(1)Is steering effective for LMs to mimic a tar-\nget group (persona)? (2)Do the models exhibit\nhigher affective alignment to the specific persona\nwhen prompted to behave like it? (3)Do steered\nmodels exhibit strong affective alignment with each\npersona? (4)Is the representational imbalance\ncontrollable by steering?\nFigure 3 provides insights into how steeringinstruction-tuned LMs to adopt a liberal ( gl) or\nconservative ( gc) persona impacts affective align-\nment measured by emotions. Please refer to Ap-\npendix D.3 for that of base LMs measured by emo-\ntions, and that of all LMs measured by moral sen-\ntiments. The directionality of triangle symbols\nshows the nature of steering: left for liberal steer-\ning and right for conservative steering. The circles\nshow the models\u2019 baselines, i.e. the default align-\nment which are identical to the circles in Figure\n2.\nIs steering effective? We expect that a model\u2019s\naffective alignment with an ideological group after\nliberal steering and conservative steering should\ndiffer; otherwise, we deem that the steering is in-\neffective. In Figure 3, it is evident that steering\nis effective for most instruction-tuned LMs, as in-\ndicated by the left-facing and right-facing trian-\ngles of the same color positioned apart from each\nother. However, such failure cases happen for al-\nmost all base LMs, as indicated by the the left-\nfacing and right-facing triangles of the same color\npositioned extremely close to each other or even\noverlapping (Figure 6 in Appendix D.3). This ob-\nservation demonstrates that instruction-tuning and\nRLHF make LMs more steerable. We do not ex-\nclude the possibility that the failure cases for base\nLMs are caused by the specific prompts we used to\nsteer the base LMs, but we leave how to craft better\nprompts to steer base LMs for future work. In the\nregard, in the following analysis related to steering,\nwe only focus on instruction-tuned models .\nDoes steering improve affective alignment?\nFor emotions on COVID-19 (Figure 3a), it is ev-\nident that most instruction-tuned LMs (8 out of\n12) are better aligned with the target ideological\ngroup after steering, as indicated by blue left-facing\n(resp. orange right-facing) triangles positioned to\nthe right of the blue (resp. range) circles. In addi-\ntion, for these models, either ideological steering\nleads to higher affective alignment with both ide-\nological groups. We argue that this is because if\nthe model detects ideology-related keywords in the\nprompt, either \u201cliberal\u201d or \u201cconservative\u201d, it au-\ntomatically aligns itself to the political domain,\nachieving higher alignment to both ideological\ngroups. Moreover, the improvement in alignment\nby conservative steering is much more pronounced\nthan that by liberal steering, as indicated by the\ndistance between orange right-facing triangle and\nthe orange circle much longer than that between\n0.8 0.9 1.0\naffective alignment (S)gl\ngc\ngpt-3.5*^\nllama-2-7b-chat*^\nllama-2-13b-chat*^\nmistral-7b-instruct*^\nfalcon-7b-instruct*^\ndolly-v2-3b*^\ndolly-v2-7b*^\ndolly-v2-12b*^\nflan-t5-xl*^\nflan-t5-xxl*^\nvicuna-7b-v1.5-16k*^\nvicuna-13b-v1.5-16k*^\nS(fdefault,gl)\nS(flib_steered,gl)S(fcon_steered,gl)\nS(fdefault,gc)S(flib_steered,gc)\nS(fcon_steered,gc)(a) Affective alignment Sin COVID-19 Tweets.\n0.8 0.9 1.0\naffective alignment (S)gl\ngc\ngpt-3.5\nllama-2-7b-chat\nllama-2-13b-chat\nmistral-7b-instruct\nfalcon-7b-instruct\ndolly-v2-3b\ndolly-v2-7b\ndolly-v2-12b\nflan-t5-xl\nflan-t5-xxl\nvicuna-7b-v1.5-16k\nvicuna-13b-v1.5-16k\nS(fdefault,gl)\nS(flib_steered,gl)S(fcon_steered,gl)\nS(fdefault,gc)S(flib_steered,gc)\nS(fcon_steered,gc) (b) Affective alignment Smeasured in Roe v. Wade Tweets.\nFigure 3: Steered affective alignment Sof different instruction-tuned LMs with both ideological groups \u2013 liberals\n(gl) and conservatives ( gc), measured by emotions , for . * indicates that the alignment of the liberal steered model\nwith both ideological groups are significantly different at p <0.05; ^ indicates that for the conservative steered\nmodel. Left-facing triangles represent the models by liberal steered prompting; right-facing triangles represent the\nmodels by conservative steered prompting; circles with no filling colors represent the models by default. For each\nLM, the alignment is averaged over that on different topics detected within the dataset. The alignment between the\ntwo ideological groups (above the red horizontal dashed line) themselves are measured as a baseline.\nthe blue left-facing triangle and the blue circle, pos-\nsibly because LMs already exhibit stronger align-\nment by default with liberals, thus offering limited\nscope for further liberal alignment enhancement.\nIn the context of Roe v. Wade (Figure 3b),\nwhile we also observe better alignment for most\ninstruction-tuned LMs, the impact of steering is\nless pronounced, with the alignment for some mod-\nels after steering showing minimal change from de-\nfault prompting. This may suggest that the models\u2019\naffective responses to long-standing, deeply polar-\nizing issues are more entrenched, making them less\namenable to steering.\nDo the models exhibit strong affective align-\nment after steering? Although steering enhances\naffective alignment for most instruction-tuned LMs,\nthe alignment of nearly all LMs to either ideologi-\ncal group is still lower than the partisan alignment\nbaseline. Notably, the more sophisticated model\ngpt-3.5 , even after steering, is least aligned with\nboth partisan perspectives.\nIs the representational imbalance controllable\nby steering? In\u00a73.1we observe the default LMs\u2019\nliberal representational tendencies on COVID-19\nTweets. We aim to investigate (1) whether the lib-\neral tendencies will be further exacerbated by lib-\neral steering, and (2) whether the liberal tenden-cies will be mitigated or even reversed by conser-\nvative steering. We observe from Figure 3a that\nall instruction-tuned LMs retain liberal tendencies,\nafter both liberal steering (indicated by blue left-\nfacing triangles to the right of orange left-facing\ntriangles) and conservative steering (indicated by\nblue right-facing triangles positioned to the right of\norange right-facing triangles). In addition, the mag-\nnitude of the tendencies (as indicated by distance\nbetween the blue and orange markers of the same\nshape) barely changes after steering. This sug-\ngests that the representational imbalance is deeply\nentrenched in the instruction-tuned LMs, which\ncannot be mitigated or reversed simply through\nsteering.\n3.3 Topic-level analysis\nTo gain deeper insights into the observations from\n\u00a73.1 and \u00a73.2, we examine the topic-level distri-\nbution of emotions and moral foundations of LM-\ngenerated responses and compare them to those\nin human-authored tweets. Figure 4 shows these\ndistributions of tweets from two LMs \u2013 gpt-3.5 and\nllama-2-7b-chat \u2013 and humans from both ideolog-\nical groups, on the topic \u201cCOVID-19 mask man-\ndates and policies\u201d from the COVID-19 Tweets.\nPlease refer to Appendix D.4 for the distributions\nanger anticipation disgust fear joy love optimism pessimism sadness0.00.10.20.30.40.50.60.70.8gl\ngc\ngpt-3.5default\ngpt-3.5lib_steered\ngpt-3.5con_steered\nllama2-7b-chat-ftdefault\nllama2-7b-chat-ftlib_steered\nllama2-7b-chat-ftcon_steered(a) Emotions\ncare harm fairness cheating loyalty betrayal authority subversion purity0.00.10.20.30.40.5gl\ngc\ngpt-3.5default\ngpt-3.5lib_steeredgpt-3.5con_steered\nllama2-7b-chat-ftdefault\nllama2-7b-chat-ftlib_steered\nllama2-7b-chat-ftcon_steered\n(b) Moral foundations\nFigure 4: Distribution of affect (emotions and moral foundations) on topic \u201cCOVID-19 mask mandates and policies\u201d\nin COVID-19 Tweets, from human-authored tweets and those generated by different LMs using different ways of\nprompting.\non the topic \u201cfetal rights debate in abortion\u201d from\nthe Roe v. Wade Tweets. Observing from Figure\n4, compared to humans, LMs show a more focused\ndistribution across different types of emotions or\nmoral foundations. This is similar to Durmus et al.\n(2023), where the authors find that LM tends to as-\nsign a high confidence to a single option for multi-\nchoice questions. Such high confidence is observed\nin both the default models and liberal steered mod-\nels. With conservative steering, LMs\u2019 generated\ndistribution becomes smoother and more aligned\nwith that from humans. This might be one of the\nreasons why conservative steering better aligns the\nmodels with both liberals and conservatives, as ob-\nserved in \u00a73.2.\nFor both gpt-3.5 andllama-2-7b-chat , on emo-\ntions, the default models and the liberal steered\nmodels show substantially less anger and dis-\ngust and substantially more optimism than human\ntweets. With respect to moral foundations, these\nmodels also express substantially more care, lessharm, more loyalty and less subversion that human-\nauthored tweets. We hypothesize that LMs are\ntrained to relentlessly convey optimism, due to cer-\ntain concerns of risks. However, conservative steer-\ning distributes the probability mass in positive emo-\ntions and moral foundations to more negative ones,\ndemonstrating the implicit bias inherent in LMs to\nassociate conservatives with negative affect.\n4 Related Work\nMeasuring human-LM Alignment LMs trained\non extensive datasets of human language from the\nInternet, are capable of simulating realistic dis-\ncourse. To ensure that LMs generate text consistent\nwith human values and ethical principles, many re-\ncent works have investigated the human-LM align-\nment. Popular frameworks include reinforcement\nlearning with human feedback (RLHF) or AI feed-\nback (RLAIF) (Ouyang et al., 2022; Glaese et al.,\n2022; Bai et al., 2022). To measure alignment San-\nturkar et al. (2023) compared LMs\u2019 opinions with\nhuman responses in public opinion polls among\nvarious demographic groups and found substantial\nmisalignment. Durmus et al. (2023) expanded the\nstudy of alignment to a global scale using cross-\nnational surveys and discovered LMs\u2019 inclination\ntowards certain countries like USA, as well as un-\nwanted cultural stereotypes. Simmons (2022) mea-\nsured LMs\u2019 moral biases associated with political\ngroups in the United States when responding to dif-\nferent moral scenarios; however, they only evaluate\nthe models\u2019 moral responses based on a general\nstatistical finding from previous works that \u201cliber-\nals rely primarily on individualizing foundations\nwhile conservatives make more balanced appeals\nto all 5 foundations\u201d. Abdulhai et al. (2023) mea-\nsured moral foundations of LLMs using the Moral\nFoundations Questionnaire (MFQ) questionnaire\nand compared the results of LLMs to humans. In\ncontrast, our work evaluate the models against af-\nfect distributions observed from real-world human-\ngenerated texts on a topic basis. The affect peo-\nple/models express in open-ended texts is likely\nto be different from how they answer the close-\nended questionnaire, and our framework can cap-\nture the fluidity and complexity of human affective\nresponses in a way that structured questionnaires\nmight not fully encompass.\nLMs and Political Leanings Feng et al. (2023)\ndiscovered that pretrained LMs do exhibit political\nbiases, propagating them into downstream tasks. In\nterms of adapting LMs to simulate human opinions,\nArgyle et al. (2023) showed that GPT-3 can mimic\nrespondents in extensive, nationally-representative\nopinion surveys. Other researchers have finetuned\nLMs to learn the political views of different parti-\nsan communities to study polarization (Jiang et al.,\n2022; He et al., 2024). To evaluate news feed algo-\nrithms, T\u00f6rnberg et al. (2023) created multiple LM\npersonas from election data to simulate conversa-\ntions on social media platforms. Chen et al. (2024)\nfound that most LLMs show a left-leaning stance\non a wide range of issues and LLMs can be easily\nmanipulated by instruction tuning.\n5 Conclusion\nOur study has explored how LMs align with the\naffective expressions of liberal and conservative\nideologies. Through the lens of two contentious so-\nciopolitical issues, we discover that LMs can mimic\npartisan affect to a degree, which, nevertheless, is\nweaker than that between liberals and conservativesin the real world. In addition, LMs show liberal\ntendencies on certain issues, aligning more with the\naffect of liberals. The misalignment and the liberal\ntendencies are not solvable by steering. As a first\nstep towards systematically measuring the affec-\ntive alignment of LMs with different social groups,\nwe hope that this study will gather more attention\nfrom the research community in understanding the\ninteractions of affect between LMs and humans.\nAcknowledgements\nThis project has been funded, in part, by\nDARPA under contract HR00112290106 and\nHR00112290106. We appreciate the constructive\nadvice and suggestions from the anonymous re-\nviewers.\nLimitations\nData Collection and Demographic Limitations.\nThe dataset utilized in our study is derived from\nTwitter and focuses solely on liberal and conser-\nvative perspectives within the United States. Such\na narrow scope overlooks the multifaceted nature\nof global demographics and political leanings. Ad-\nditionally, limiting the data source to Twitter may\nnot provide a comprehensive view of the social and\npolitical discourse surrounding the issues in ques-\ntion. Moving forward, our methodology should\nbe applied to broader datasets that encapsulate a\nmore diverse range of subjects, platforms, and de-\nmographics.\nAffective Classifier Accuracies The classifiers\nused for emotions and moralities are not perfect.\nHowever, our method depends on comparing the\nemotion and morality distributions between the\nreal-world and model-generated tweets. This com-\nparative approach mitigates the impact of potential\nclassifier inaccuracies, as the same classifier is ap-\nplied consistently across both corpora. Since we\nare primarily looking at differences, rather than ab-\nsolute values of emotions in the data, we believe\nwe are justified in using the imperfect classifiers\nto reveal differences in affective alignment. Nev-\nertheless, we have endeavored to utilize the most\nadvanced models currently available for accurately\nmeasuring emotions and moral foundations in the\nsociopolitical domain. The performance of both\nmodels has been validated on a variety of social\nmedia data (Rao et al., 2023b; Guo et al., 2023a;\nChochlakis et al., 2023), and proposing methods\nto achieve the new state-of-the-art on emotion and\nmorality detection is out of the scope of this work.\nAffective Classifier Constraints. Our affect mea-\nsurement relies on classifiers built upon BERT, a\nmodel whose simplicity and scale are modest com-\npared to the 36 larger LMs analyzed. This dis-\ncrepancy raises concerns about the precision of\naffect detection; the classifiers might not capture\nthe nuances of affect as effectively as those based\non larger models. Moreover, the divergence in af-\nfect understanding between the classifiers and the\nLMs could introduce discrepancies. While the LMs\nmight generate affectively coherent responses from\ntheir perspective, these may not align with the inter-\npretations of a BERT-based \"third-party\" classifier.\nEmotion and moral foundation detection are in-\nherently subjective, and the potential mismatch in\naffect recognition necessitates caution. Future re-\nsearch should consider leveraging the studied LMs\nthemselves to evaluate affect. This could provide\na more congruent assessment of the models\u2019 affec-\ntive outputs and allow for a deeper investigation\ninto the observed misalignments.\nSteering Efficacy and Prompt Design. Our at-\ntempts to steer base LMs towards specific political\nidentities revealed a notable challenge: the models\ndid not adequately distinguish between \u201cliberals\u201d\nand \u201cconservatives\u201d. The design of our steering\nprompts may play a significant role in this limita-\ntion. If the prompts are not sufficiently nuanced or\nif they fail to encapsulate the essence of the targeted\npolitical identities, the models\u2019 responses may not\nreflect the intended affective stance. In future itera-\ntions, prompt design must be meticulously refined\nto ensure it elicits the desired affective response\nfrom the model. This may involve a more iterative\nand data-driven approach to prompt engineering,\npossibly incorporating feedback loops with human\nevaluators to finetune the prompts\u2019 effectiveness.\nEthics Statement\nOur work utilizes publicly available data from so-\ncial media, specifically Twitter, which poses po-\ntential privacy concerns. We have ensured that all\nTwitter data used in our study has been accessed\nin compliance with Twitter\u2019s data use policies and\nthat individual privacy has been respected, with no\nattempt to de-anonymize or reveal personally iden-\ntifiable information. The dataset consists of tweets\nrelated to COVID-19 and Roe v. Wade, which are\ntopics of public interest and social importance. In\nhandling this data, we were careful to maintain theanonymity of the users and to treat the content with\nthe utmost respect, given the sensitive nature of the\ntopics.\nReferences\nMarwa Abdulhai, Gregory Serapio-Garcia, Cl\u00e9ment\nCrepy, Daria Valter, John Canny, and Natasha Jaques.\n2023. Moral foundations of large language models.\narXiv preprint arXiv:2310.15337 .\nHassan Alhuzali et al. 2021. SpanEmo: Casting multi-\nlabel emotion classification as span-prediction. In\nECACL , pages 1573\u20131584. ACL.\nEbtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al-\nshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\nMerouane Debbah, Etienne Goffinet, Daniel Hes-\nlow, Julien Launay, Quentin Malartic, et al. 2023.\nFalcon-40b: an open large language model with state-\nof-the-art performance. Findings of the Association\nfor Computational Linguistics: ACL , 2023:10755\u2013\n10773.\nLisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R\nGubler, Christopher Rytting, and David Wingate.\n2023. Out of one, many: Using language mod-\nels to simulate human samples. Political Analysis ,\n31(3):337\u2013351.\nYuntao Bai, Saurav Kadavath, Sandipan Kundu,\nAmanda Askell, Jackson Kernion, Andy Jones,\nAnna Chen, Anna Goldie, Azalia Mirhoseini,\nCameron McKinnon, et al. 2022. Constitutional\nai: Harmlessness from ai feedback. arXiv preprint\narXiv:2212.08073 .\nRong-Ching Chang, Ashwin Rao, Qiankun Zhong, Mag-\ndalena Wojcieszak, and Kristina Lerman. 2023. #\nroeoverturned: Twitter dataset on the abortion rights\ncontroversy. In Proceedings of the International\nAAAI Conference on Web and Social Media , vol-\nume 17, pages 997\u20131005.\nMedia Bias-Fact Check. 2023. The media bias chart.\nhttps://mediabiasfactcheck.com . Ac-\ncessed: 2023-05-06.\nEmily Chen, Kristina Lerman, Emilio Ferrara, et al.\n2020. Tracking social media discourse about the\ncovid-19 pandemic: Development of a public coro-\nnavirus twitter data set. JMIR public health and\nsurveillance , 6(2):e19273.\nKai Chen, Zihao He, Jun Yan, Taiwei Shi, and Kristina\nLerman. 2024. How susceptible are large language\nmodels to ideological manipulation? arXiv preprint\narXiv:2402.11725 .\nGeorgios Chochlakis, Gireesh Mahajan, Sabyasachee\nBaruah, Keith Burghardt, Kristina Lerman, and\nShrikanth Narayanan. 2023. Using emotion embed-\ndings to transfer knowledge between emotions, lan-\nguages, and annotation formats. In ICASSP 2023-\n2023 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP) , pages 1\u20135.\nIEEE.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling instruction-finetuned language models.\narXiv preprint arXiv:2210.11416 .\nMike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,\nJun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell,\nMatei Zaharia, and Reynold Xin. 2023. Free dolly:\nIntroducing the world\u2019s first truly open instruction-\ntuned llm. Company Blog of Databricks .\nShrey Desai, Cornelia Caragea, and Junyi Jessy Li. 2020.\nDetecting perceived emotions in hurricane disasters.\nInProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics , pages 5290\u2013\n5305.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long and Short Papers) , pages 4171\u2013\n4186.\nBurak Do \u02d8gruyol, Sinan Alper, and Onurcan Yilmaz.\n2019. The five-factor model of the moral foundations\ntheory is stable across weird and non-weird cultures.\nPersonality and Individual Differences , 151:109547.\nMark Dredze, Michael J Paul, Shane Bergsma, and Hieu\nTran. 2013. Carmen: A twitter geolocation system\nwith applications to public health. In AAAI workshop\non HIAI , volume 23, page 45. Citeseer.\nEsin Durmus, Karina Nyugen, Thomas I Liao, Nicholas\nSchiefer, Amanda Askell, Anton Bakhtin, Carol\nChen, Zac Hatfield-Dodds, Danny Hernandez,\nNicholas Joseph, et al. 2023. Towards measuring\nthe representation of subjective global opinions in\nlanguage models. arXiv preprint arXiv:2306.16388 .\nShangbin Feng, Chan Young Park, Yuhan Liu, and Yulia\nTsvetkov. 2023. From pretraining data to language\nmodels to downstream tasks: Tracking the trails of\npolitical biases leading to unfair nlp models. arXiv\npreprint arXiv:2305.08283 .\nAmelia Glaese, Nat McAleese, Maja Tr\u02db ebacz, John\nAslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh,\nLaura Weidinger, Martin Chadwick, Phoebe Thacker,\net al. 2022. Improving alignment of dialogue agents\nvia targeted human judgements. arXiv preprint\narXiv:2209.14375 .\nJesse Graham, Jonathan Haidt, and Brian A Nosek.\n2009. Liberals and conservatives rely on different\nsets of moral foundations. Journal of personality and\nsocial psychology , 96(5):1029.Siyi Guo, Zihao He, Ashwin Rao, Eugene Jang, Yuan-\nfeixue Nan, Fred Morstatter, Jeffrey Brantingham,\nand Kristina Lerman. 2023a. Measuring online emo-\ntional reactions to offline events. arXiv preprint\narXiv:2307.10245 .\nSiyi Guo et al. 2023b. A data fusion framework for\nmulti-domain morality learning. In ICWSM-2023 ,\nvolume 17, pages 281\u2013291.\nJonathan Haidt et al. 2007. The moral mind: How\nfive sets of innate intuitions guide the development\nof many culture-specific virtues, and perhaps even\nmodules. The innate mind , 3:367\u2013391.\nJochen Hartmann, Jasper Schwenzow, and Maximil-\nian Witte. 2023. The political ideology of conver-\nsational ai: Converging evidence on chatgpt\u2019s pro-\nenvironmental, left-libertarian orientation. arXiv\npreprint arXiv:2301.01768 .\nThomas Hartvigsen, Saadia Gabriel, Hamid Palangi,\nMaarten Sap, Dipankar Ray, and Ece Kamar. 2022.\nToxigen: A large-scale machine-generated dataset\nfor adversarial and implicit hate speech detection.\nInProceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers) , pages 3309\u20133326.\nZihao He, Jonathan May, and Kristina Lerman. 2023.\nCpl-novid: Context-aware prompt-based learning\nfor norm violation detection in online communities.\narXiv preprint arXiv:2305.09846 .\nZihao He, Ashwin Rao, Siyi Guo, Negar Mokhberian,\nand Kristina Lerman. 2024. Reading between the\ntweets: Deciphering ideological stances of intercon-\nnected mixed-ideology communities. arXiv preprint\narXiv:2402.01091 .\nShanto Iyengar, Yphtach Lelkes, Matthew Levendusky,\nNeil Malhotra, and Sean J Westwood. 2019. The\norigins and consequences of affective polarization in\nthe united states. Annual review of political science ,\n22:129\u2013146.\nAlbert Q Jiang, Alexandre Sablayrolles, Arthur Men-\nsch, Chris Bamford, Devendra Singh Chaplot, Diego\nde las Casas, Florian Bressand, Gianna Lengyel, Guil-\nlaume Lample, Lucile Saulnier, et al. 2023. Mistral\n7b.arXiv preprint arXiv:2310.06825 .\nCong Jiang and Xiaolei Yang. 2023. Legal syllogism\nprompting: Teaching large language models for legal\njudgment prediction. In Proceedings of the Nine-\nteenth International Conference on Artificial Intelli-\ngence and Law , pages 417\u2013421.\nHang Jiang, Doug Beeferman, Brandon Roy, and Deb\nRoy. 2022. Communitylm: Probing partisan world-\nviews from language models. In Proceedings of the\n29th International Conference on Computational Lin-\nguistics , pages 6818\u20136826.\nMarko Kla\u0161nja et al. 2018. Measuring Public Opinion\nwith Social Media Data. Oxford University Press.\nSaif Mohammad et al. 2018. SemEval-2018 task 1:\nAffect in tweets. In Proc. 12th Int. Workshop on\nSemantic Evaluation , pages 1\u201317.\nNegar Mokhberian, Andr\u00e9s Abeliuk, Patrick Cummings,\nand Kristina Lerman. 2020. Moral framing and ide-\nological bias of news. In Social Informatics: 12th\nInternational Conference, SocInfo 2020, Pisa, Italy,\nOctober 6\u20139, 2020, Proceedings 12 , pages 206\u2013219.\nSpringer.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback, 2022. URL https://arxiv.\norg/abs/2203.02155 , 13.\nEthan Perez, Sam Ringer, Kamil \u02d9e Luko\u0161i \u00afut\u02d9e, Karina\nNguyen, Edwin Chen, Scott Heiner, Craig Pettit,\nCatherine Olsson, Sandipan Kundu, Saurav Kada-\nvath, et al. 2022. Discovering language model behav-\niors with model-written evaluations. arXiv preprint\narXiv:2212.09251 .\nRobert Plutchik. 2001. The nature of emotions: Human\nemotions have deep evolutionary roots, a fact that\nmay explain their complexity and provide tools for\nclinical practice. American scientist , 89(4):344\u2013350.\nAshwin Rao, Rong-Ching Chang, Qiankun Zhong,\nKristina Lerman, and Magdalena Wojcieszak. 2023a.\nTracking a year of polarized twitter discourse on abor-\ntion. arXiv preprint arXiv:2311.16831 .\nAshwin Rao, Siyi Guo, Sze-Yuh Nina Wang, Fred\nMorstatter, and Kristina Lerman. 2023b. Pandemic\nculture wars: Partisan asymmetries in the moral\nlanguage of covid-19 discussions. arXiv preprint\narXiv:2305.18533 .\nAshwin Rao, Fred Morstatter, Minda Hu, Emily Chen,\nKeith Burghardt, Emilio Ferrara, and Kristina Ler-\nman. 2021. Political partisanship and antiscience\nattitudes in online discussions about covid-19: Twit-\nter content analysis. Journal of medical Internet\nresearch , 23(6):e26692.\nShibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo\nLee, Percy Liang, and Tatsunori Hashimoto. 2023.\nWhose opinions do language models reflect? arXiv\npreprint arXiv:2303.17548 .\nSono Shah, Emma Remy, and Aaron Smith. 2020. Dif-\nferences in how democrats and republicans behave\non twitter. Pew Research Center .\nGabriel Simmons. 2022. Moral mimicry: Large\nlanguage models produce moral rationalizations\ntailored to political identity. arXiv preprint\narXiv:2209.12106 .\nPetter T\u00f6rnberg, Diliara Valeeva, Justus Uitermark,\nand Christopher Bail. 2023. Simulating social me-\ndia using large language models to evaluate al-\nternative news feed algorithms. arXiv preprint\narXiv:2310.05984 .Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971 .\nGerben A. vanKleef et al. 2016. Editorial: The social\nnature of emotions. Frontiers in Psychology , 7:896.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz,\net al. 2019. Huggingface\u2019s transformers: State-of-\nthe-art natural language processing. arXiv preprint\narXiv:1910.03771 .\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nZhuohan Li, Dacheng Li, Eric Xing, et al. 2023.\nJudging llm-as-a-judge with mt-bench and chatbot\narena. arXiv preprint arXiv:2306.05685 .\nA Broader Impact\nImplications of affective alignment. Introduc-\ning affective alignment, our paper bridges a gap left\nby prior research focused predominantly on posi-\ntional alignment. The impact of affective alignment\nof LMs is crucial in the following contexts.\nIn mental health applications, an LM\u2019s ability\nto align affectively with users can provide support\nand improve therapeutic outcomes. In educational\nsettings, affective alignment in LMs can foster a\nconducive learning environment, adapting to stu-\ndents\u2019 emotional states to enhance engagement and\ncomprehension. In political discourse, affective\nalignment is key to fostering constructive debates\nand reducing polarization; for instance, during elec-\ntion campaigns, LMs that can align affectively with\nthe emotional and moral sentiments of different\nvoter bases can facilitate more resonant and effec-\ntive communication.\nHowever, there are also scenarios where affec-\ntive alignment is undesirable. For example, In\nhigh-stakes negotiation or diplomacy settings, ex-\ncessive affective alignment might hinder the ability\nto maintain a firm stance or negotiate effectively.\nIn legal or judicial contexts, an overly empathetic\nLM could bias the presentation of facts or argu-\nments, potentially affecting impartiality. Similarly,\nin news reporting, high affective alignment might\nlead to biased news coverage, undermining journal-\nistic neutrality.\nTherefore, it is important to achieve a balanced\naffective alignment that enhances positive interac-\ntions and outcomes without compromising on ob-\njectivity and fairness. Recognizing these subtleties\ncan guide the ethical and effective deployment of\nLMs, ensuring they serve as beneficial tools in so-\nciety rather than exacerbating existing divides or\nbiases.\nImplications of LM representativeness of affect\nacross different demographics. The representa-\ntiveness of LMs in capturing affect across different\ndemographics is crucial for ensuring that AI sys-\ntems communicate in ways that are emotionally and\nculturally resonant. However, the representative-\nness of LMs in reflecting affect across demograph-\nics should be contextually calibrated, not merely\nequalized. For example, an LM used in a global\nsocial media platform should accurately reflect the\nemotional and moral nuances of its worldwide user\nbase, avoiding over-representation of any single\ngroup\u2019s affective norms. In contrast, an LM in lo-\ncalized service applications, like community-based\nmental health support, should be tuned to the spe-\ncific emotional and cultural characteristics of that\ncommunity. Balancing these representational needs\nrequires a strategic approach to developing LMs\nthat are both inclusive and contextually aware.\nImplications of the framework to measure af-\nfective alignment. Our proposed framework of-\nfers a comprehensive tool for assessing how well\nLMs resonate with human emotions and morals\nacross various demographics and subjects. This\nversatility facilitates broader research applications,\nenabling researchers and developers to evaluate\nand enhance LM designs for cultural sensitivity,\ninclusiveness, and ethical alignment with human\nvalues, thus paving the way for more responsible\nAI innovations.\nImplications of our findings on the affective\nalignment of LMs with both political groups.\nOur analysis reveals that LMs display a notable\nliberal bias, especially in contexts like COVID-19\ndiscussions, and exhibit an overall affective\nmisalignment with political groups, surpassing\nthe existing partisan divide in the U.S. This\nindicates a systemic inclination within LMs. These\nobservations underscore the challenge of LMs\nachieving strong affective alignment with humans\nand equal affective representations.\nIn conclusion, our research not only contributes\nto the academic understanding of LMs but also\nserves as a pivotal guide for developing AI that isemotionally intelligent, morally considerate, and\nsocially representative.\nB Online Sociopolitical Discourse Data\nWe compile two datasets on sociopolitical dis-\ncourse on Twitter: COVID-19 Tweets and Roe\nv. Wade Tweets. They cover a wide range of fine-\ngrained topics, including emotionally divisive top-\nics. Our selection of COVID-19 and Roe vs. Wade\nTwitter datasets was based on the following factors:\n\u2022COVID-19 has global significance, affecting\ndiverse aspects of life and eliciting a wide\nrange of emotional and moral responses, mak-\ning it ideal for studying affective alignment.\nRoe v. Wade, representing a longstanding\nand polarizing issue in U.S. politics, provides\na rich dataset to explore deeply entrenched\nmoral and emotional viewpoints, allowing for\na detailed analysis of language models\u2019 align-\nment with complex ideological positions.\n\u2022These datasets are publicly accessible, which\nis crucial for ensuring the transparency and\nreproducibility of our research.\n\u2022The method for estimating user partisanship\n(Rao et al., 2021) is particularly effective for\nthese datasets. This is because the tweets\nin these datasets frequently include URLs to\nnews articles, which serve as reliable indica-\ntors of the users\u2019 political leanings. We\u2019ll add\nthese considerations to the paper.\nTo assess the affect alignment, we identify impor-\ntant issues discussed in the Twitter datasets using\na semi-supervised method described in Rao et al.\n(2023b). This method harvests and selects from\nWikipedia the relevant and distinctive keywords for\neach issue, and detect the issues in each tweet using\nthe presence of these keywords and phrases. An\nissue, such as \u201cmasking\u201d in COVID-19 tweets, can\nstill be broad and too general. In order to obtain a\nfine-grained span of topics, we use GPT-4 to cluster\nthe keywords in each issue into sub-topics, such\nas \u201cmask mandates and policies\u201d and \u201cmask health\nconcerns\u201d. We manually validated the clustering\nresults. Each tweet can be associated with multiple\nissues and sub-topics.\nB.1 COVID-19 Tweets\nThe corpus of discussions about the COVID-19\npandemic (Chen et al., 2020) consists of 270 mil-\nlion tweets, generated by 2.1 million users, posted\nbetween January 2020 and December 2021. These\ntweets contain one or more COVID-19-related key-\nwords, such as \u201ccoronavirus\u201d, \u201cpandemic\u201d, and\n\u201cWuhan,\u201d among others. Users participating in\nthese discussions were geo-located to states within\nthe U.S. based on their profile and tweets using a\ntool Carmen (Dredze et al., 2013). We use a val-\nidated method (Rao et al., 2021) to estimate the\npartisanship of individual users. This method uses\npolitical bias scores of the domains users share ac-\ncording to Media Bias-Fact Check (Check, 2023)\nto estimate the ideology of users. In other words, if\na users shares more left-leaning domains, they are\nconsidered to be liberal.\nWe focus on the issues that divided public opin-\nion during the pandemic, including: (1) origins\nof the COVID-19 pandemic, (2) lockdowns, (3)\nmasking, (4) education and (5) vaccines. Within\nthese issues, we further detect a total of 26 fine-\ngrained sub-topics (see Table 1). When using LMs\nto generate responses on the topics, we only keep\nthose with at least has 1,000 tweets from both ideo-\nlogical leanings. After filtering original tweets (as\nopposed to retweets and quoted tweets) categorized\nto one of the five issues and authored by users with\nidentified political affiliation, we are left with 9M\ntweets.\nB.2 Roe v. Wade Tweets\nOur second dataset comprises of tweets about abor-\ntion rights in the U.S. and the overturning of Roe vs\nWade. These tweets were posted between January\n2022 to January 2023 (Chang et al., 2023). Each\ntweet contains at least one term from a list of key-\nwords that reflect both sides of the abortion debate\nin the United States. This dataset includes approx-\nimately 12 million tweets generated by about 1\nmillion users in the U.S. We used the same tech-\nnique to geo-locate users, infer user political ide-\nology, and detect issues and sub-topics as for the\nCOVID-19 tweets dataset. We focus on the follow-\ning five major issues: (1) religious concerns, (2)\nbodily autonomy, (3) fetal rights and personhood,\n(4) women\u2019s health and (5) exceptions to abortion\nbans. The associated 24 fine-grained topics are\nlisted in Table 2. When using LMs to generate re-\nsponses on the topics, we only keep those with at\nleast has 1,000 tweets from both political identities.C Proximity between Emotions\nThe polar coordinates of the 11 emotions ( anger ,\nanticipation ,disgust ,fear,joy,love,optimism ,\npessimism ,sadness ,surprise , and trust) are\u22121\n2\u03c0,\n\u22121\n4\u03c0,\u22123\n4\u03c0,1\n2\u03c0,0,1\n8\u03c0,\u22121\n8\u03c0,7\n8\u03c0,\u03c0,3\n4\u03c0, and1\n4\u03c0\nrespectively. For emotions that are not the Plutchik-\n8 emotions, we aggregate the coordinates of their\nneighboring emotions. The emotion proximity ma-\ntrix is shown in Table 3.\nD Experiments\nD.1 Experimental Setup\nOn each topic, we obtain 2,000 generations from a\nmodel, using the prompt templates shown in Table\n4.\nFor GPT based models we queried OpenAI\u2019s\nAPI. The specific models we used for gpt-3.5 ,gpt-\n3-davinci , and gpt-3-babbage are gpt-3.5-turbo-\n1106, davinci-002, and babbage-002 respectively.\nWe set temperature to0.9and only allow maximum\ngeneration length of 96due to the concerns of cost.\nFor other open-sourced models, we use their\ncheckpoints on huggingface (Wolf et al., 2019) to\nrun the generation. For all generations we set top_p\nto0.9,temperature to0.9, and do_sample toTrue.\nThe inference is run using an Tesla A100 GPU with\n80GB memory. The running time for all topics\nin either COVID-19 Tweets or the Roe v. Wade\nTweets varies from 2hrs to 30hrs, depending the\nsize of the model.\nD.2 Representativeness of Affect under\nDefault Prompting\nFigure 5 shows the affective alignment of various\nLMs with liberals ( gl) and conservatives ( gc) by\ndefault prompting in the two datasets measured by\nmoral sentiments.\nD.3 Representativeness of Affect under\nSteered Prompting\nFigure 6 provides insights into how steering\ninstruction-tuned LMs to adopt a liberal ( gl) or con-\nservative ( gc) persona impacts affective alignment\nmeasured by moral sentiments. Figure 7 shows\nthe affective alignment under steered prompting\nmeasured by moral foundations.\nD.4 Topic-Level Analysis\nFigure 8 shows emotion and moral foundation dis-\ntributions of tweets from two LMs \u2013 gpt-3.5 and\nIssue Topic #Lib_Tweets #Con_Tweets\nEducationCOVID-19 online and remote education 366,944 31,655\nCOVID-19 educational institution adaptations 988,233 120,456\nCOVID-19 teaching and learning adjustments 805,062 88,812\nCOVID-19 education disruptions and responses 15,387 2,585\nCOVID-19 early childhood and kindergarten education 28,420 1,746\nLockdownsCOVID-19 lockdown measures and regulations 696,359 207,129\nCOVID-19 lockdown responses and protests 1,225 733\nCOVID-19 business and public service impact 2,676 692\nCOVID-19 community and personal practices 117,271 22,547\nCOVID-19 government and health policies 6,487 1,100\nMaskingCOVID-19 mask types and features 142,307 25,775\nCOVID-19 mask usage and compliance 223,094 44,287\nCOVID-19 mask mandates and policies 323,600 77,570\nCOVID-19 mask health concerns 11,546 2,159\nCOVID-19 mask sanitization and maintenance 20,780 3,304\nOriginsCOVID-19 natural origin theories 37,125 21,772\nCOVID-19 lab leak hypotheses 5,066 4,454\nCOVID-19 conspiracy theories 65,554 32,773\nCOVID-19 scientific research and personalities 7,557 7,157\nVaccinesCOVID-19 vaccine types 354,177 55,279\nCOVID-19 vaccine administration 1,233,436 170,415\nCOVID-19 vaccine efficacy and safety 47,259 5,545\nCOVID-19 vaccine approval and authorization 135,412 18,605\nCOVID-19 vaccine distribution and accessibility 343,470 50,401\nCOVID-19 vaccine misinformation 24,455 6,545\nCOVID-19 vaccine reporting 44,784 9,041\nTable 1: Wedge issues and fine-grained topics in the discussions about the COVID-19 pandemic. Numeric columns\nshow the number of tweets authored by liberals (resp. conservatives) in the dataset that contain keywords from each\ntopic.\nllama-2-7b-chat \u2013 and humans from both ideolog-\nical groups, on the topic \u201cfetal rights debate in\nabortion\u201d from the Roe v. Wade Tweets.\nIssue Topic #Lib_Tweets #Con_Tweets\nBodily\nAutonomyabortion rights and access 2.054,856 71,246\nreproductive rights and body autonomy 1,650,878 110,537\npro-choice movement 1,255,456 193,726\nabortion legal and political debate 665,772 146,799\nforced practices and coercion in reproduction 1,269,362 107,015\nalternative methods for abortion 28,216 1,256\nhistorical symbols in abortion debates 159,198 37,307\nExceptions\nto Abortion\nBansabortion viability and medical exceptions 1,601,819 283,493\nlegal and ethical exceptions in abortion 3,237,146 233,050\nparental consent in abortion decisions 12,535 10,969\nadoption as an alternative in abortion discussions 183,936 51,125\nFetal Rightsfetal rights debate in abortion 216,710 309,476\nanti-abortion arguments 106,207 91,491\nphilosophical and ethical perspectives on abortion 156 53\nfetal rights advocacy 90 382\nabortion alternatives and fetal rights 183,936 51,125\nReligionreligious beliefs and abortion 396,611 284,416\nchristian denominations and abortion 1,466,007 428,294\nreligious practices and abortion 111,581 84,246\nWomen\u2019s Healthwomen\u2019s reproductive rights and abortion 3,924,108 160,381\nabortion methods and medications 233,258 7,213\nmaternal health and abortion 368,214 7,919\nhealthcare access and effects in abortion 1,122,226 116,382\nhistorical and illegal abortion practices 95,321 6,144\nTable 2: Wedge issues and fine-grained topics in the abortion discourse. Numeric columns show the number of\ntweets authored by liberals (resp. conservatives) in the dataset that contain keywords from each topic.\nanger anticipation disgust fear joy love optimism pessimism sadness surprise trust\nanger 1 0.75 0.75 0 0.5 0.375 0.625 0.375 0.5 0.25 0.25\nanticipation 1 0.5 0.25 0.75 0.625 0.875 0.125 0.25 0 0.5\ndisgust 1 0.25 0.25 0.125 0.375 0.625 0.75 0.5 0\nfear 1 0.5 0.625 0.375 0.625 0.5 0.75 0.75\njoy 1 0.875 0.875 0.125 0 0.25 0.75\nlove 1 0.75 0.25 0.125 0.375 0.875\noptimism 1 0 0.125 0.125 0.625\npessimism 1 0.875 0.875 0.375\nsadness 1 0.75 0.25\nsurprise 1 0.5\ntrust 1\nTable 3: Proximity scores between different emotions. We only show the upper triangle as it is a symmetric matrix.\nPrompt Type Model Type Prompts\nDefaultbaseHere\u2019s a tweet regarding [topic]:\nTweeting about [topic]:\nIn a tweet about [topic], it\u2019s said that:\nA tweet on the topic of [topic] reads:\nA social media post about [topic] states:\nOn Twitter, someone says about [topic]:\nIn a brief tweet about [topic], you find:\nSomeone tweets about [topic], mentioning that:\nA recent tweet on [topic] highlighted:\nDiscussing [topic] in a tweet, it\u2019s noted:\nInstruction-tunedCompose a tweet about [topic].\nShare your thoughts on [topic] in a tweet.\nIf you were to tweet about [topic], what would you say?\nImagine you\u2019re tweeting about [topic]. What would your tweet be?\nCreate a short message on [topic] suitable for a tweet.\nExpress your views on [topic] in the form of a tweet.\nDraft a tweet discussing [topic].\nHow would you comment on [topic] in a tweet?\nWrite a social media post about [topic].\nIn a tweet, describe your perspective on [topic].\nSteeredbaseHere\u2019s a tweet regarding [topic] from a liberal/conservative standpoint:\nTweeting about [topic] as a Democrat/Republican:\nIn a tweet about [topic], a liberal/conservative might say:\nA tweet on the topic of [topic] from a Democrat/Republican perspective reads:\nA social media post about [topic] that states a liberal/conservative viewpoint:\nOn Twitter, a liberal/conservative says about [topic]:\nIn a brief tweet about [topic], a Democratic/Republican viewpoint is:\nSomeone tweets about [topic] from a liberal/conservative angle, mentioning that:\nA recent tweet on [topic] by a Democrat/Republican highlighted:\nDiscussing [topic] in a tweet from a liberal/conservative stance, it\u2019s noted:\nInstruction-tunedCompose a tweet about [topic] from a liberal/conservative viewpoint.\nShare your thoughts on [topic] in a tweet, emphasizing Democratic/Republican values.\nIf you were a liberal/conservative tweeting about [topic], what would you say?\nImagine you\u2019re a Democrat/Republican tweeting about [topic]. What would your tweet be?\nCreate a short message on [topic] suitable for a tweet that reflects liberal/conservative ideals.\nExpress your liberal/conservative views on [topic] in the form of a tweet.\nDraft a tweet discussing [topic] from a Democratic/Republican perspective.\nAs a liberal/conservative, how would you comment on [topic] in a tweet?\nWrite a social media post about [topic] that aligns with Democratic/Republican principles.\nIn a tweet, describe your perspective on [topic] as a liberal/conservative.\nTable 4: Prompts used for generating tweets from the base model and instruction-tuned models, for default\nprompting and steered prompting. In some prompts for steering we substitute \u201cliberal/conservative\u201d with \u201cDemo-\ncrat/Republican\u201d to mitigate the sensitivity of LMs to the wording in prompts.\n1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3\naffective alignment (S)gl\ngc\ngpt-3.5*\nllama-2-7b-chat*\nllama-2-13b-chat*\nmistral-7b-instruct*\nfalcon-7b-instruct*\ndolly-v2-3b*\ndolly-v2-7b*\ndolly-v2-12b*\nflan-t5-xl*\nflan-t5-xxl*\nvicuna-7b-v1.5-16k*\nvicuna-13b-v1.5-16k*\ngpt-3-davinci*\ngpt-3-babbage*\nllama-2-7b*\nllama-2-13b*\nmistral-7b*\nfalcon-7b*\nopt-125m*\nopt-350m*\nopt-1.3b*\nopt-2.7b*\nopt-6.7b*\nopt-13b*\nopt-iml-1.3b*\nbloom-560m*\nbloom-1b1*\nbloom-1b7*\nbloom-3b*\npythia-160m*\npythia-410m*\npythia-1b*\npythia-1.4b*\npythia-2.8b*\npythia-6.9b*\npythia-12b*\nS(f,gl)\nS(f,gc)(a) Affective alignment Sin COVID-19 Tweets.\n1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3\naffective alignment (S)gl\ngc\ngpt-3.5\nllama-2-7b-chat\nllama-2-13b-chat\nmistral-7b-instruct\nfalcon-7b-instruct\ndolly-v2-3b\ndolly-v2-7b\ndolly-v2-12b\nflan-t5-xl\nflan-t5-xxl\nvicuna-7b-v1.5-16k\nvicuna-13b-v1.5-16k\ngpt-3-davinci\ngpt-3-babbage\nllama-2-7b\nllama-2-13b\nmistral-7b\nfalcon-7b\nopt-125m\nopt-350m\nopt-1.3b\nopt-2.7b\nopt-6.7b\nopt-13b\nopt-iml-1.3b\nbloom-560m\nbloom-1b1\nbloom-1b7\nbloom-3b\npythia-160m\npythia-410m\npythia-1b\npythia-1.4b\npythia-2.8b\npythia-6.9b\npythia-12b\nS(f,gl)\nS(f,gc) (b) Affective alignment Smeasured in Roe v. Wade Tweets.\nFigure 5: Default affect alignment Sof different LMs with both ideological groups \u2013 liberals ( gl) and conservatives\n(gc), measured by moral foundations . * indicates that the alignment of the liberal steered model with both\nideological groups are significantly different at p <0.05. For each LM, the alignment is averaged over that on\ndifferent topics detected within the dataset, with the means shown by circles and the standard deviations shown by\nerrors bars. Base LMs and instruction-tuned LMs are separated by the black horizontal dashed line. The alignment\nbetween the two ideological groups (above the red horizontal dashed line) themselves are measured as a baseline.\n0.8 0.9 1.0\naffective alignment (S)gl\ngc\ngpt-3-davinci*^\ngpt-3-babbage*^\nllama-2-7b^\nllama-2-13b\nmistral-7b^\nfalcon-7b\nopt-125m*^\nopt-350m*^\nopt-1.3b^\nopt-2.7b^\nopt-6.7b^\nopt-13b*^\nopt-iml-1.3b*^\nbloom-560m*^\nbloom-1b1*^\nbloom-1b7*^\nbloom-3b*^\npythia-160m*^\npythia-410m*^\npythia-1b*^\npythia-1.4b*^\npythia-2.8b*^\npythia-6.9b*^\npythia-12b*\nS(fdefault,gl)\nS(flib_steered,gl)S(fcon_steered,gl)\nS(fdefault,gc)S(flib_steered,gc)\nS(fcon_steered,gc)(a) Affective alignment Sin COVID-19 Tweets.\n0.9 1.0\naffective alignment (S)gl\ngc\ngpt-3-davinci\ngpt-3-babbage\nllama-2-7b\nllama-2-13b\nmistral-7b\nfalcon-7b\nopt-125m\nopt-350m\nopt-1.3b\nopt-2.7b\nopt-6.7b\nopt-13b\nopt-iml-1.3b\nbloom-560m\nbloom-1b1\nbloom-1b7\nbloom-3b\npythia-160m\npythia-410m\npythia-1b\npythia-1.4b\npythia-2.8b\npythia-6.9b\npythia-12b\nS(fdefault,gl)\nS(flib_steered,gl)S(fcon_steered,gl)\nS(fdefault,gc)S(flib_steered,gc)\nS(fcon_steered,gc) (b) Affective alignment Smeasured in Roe v. Wade Tweets.\nFigure 6: Steered affective alignment Sof different base LMs with both ideological groups \u2013 liberals ( gl) and\nconservatives ( gc), measured by emotions . Left-facing triangles represent the models by liberal steered prompting;\nright-facing triangles represent the models by conservative steered prompting; circles with no filling colors represent\nthe models by default. * indicates that the alignment of the liberal steered model with both ideological groups are\nsignificantly different at p <0.05; ^ indicates that for the conservative steered model. For each LM, the alignment\nis averaged over that on different topics detected within the dataset. The alignment between the two ideological\ngroups (above the red horizontal dashed line) themselves are measured as a baseline.\n0.5 0.6 0.7 0.8 0.9\naffective alignment (S)gl\ngc\ngpt-3.5\nllama-2-7b-chat\nllama-2-13b-chat\nmistral-7b-instruct\nfalcon-7b-instruct\ndolly-v2-3b\ndolly-v2-7b\ndolly-v2-12b\nflan-t5-xl\nflan-t5-xxl\nvicuna-7b-v1.5-16k\nvicuna-13b-v1.5-16k\ngpt-3-davinci\ngpt-3-babbage\nllama-2-7b\nllama-2-13b\nmistral-7b\nfalcon-7b\nopt-125m\nopt-350m\nopt-1.3b\nopt-2.7b\nopt-6.7b\nopt-13b\nopt-iml-1.3b\nbloom-560m\nbloom-1b1\nbloom-1b7\nbloom-3b\npythia-160m\npythia-410m\npythia-1b\npythia-1.4b\npythia-2.8b\npythia-6.9b\npythia-12b\nS(fdefault,gl)\nS(flib_steered,gl)S(fcon_steered,gl)\nS(fdefault,gc)S(flib_steered,gc)\nS(fcon_steered,gc)(a) Affective alignment Sin COVID-19 Tweets.\n0.5 0.6 0.7 0.8 0.9\naffective alignment (S)gl\ngc\ngpt-3.5\nllama-2-7b-chat\nllama-2-13b-chat\nmistral-7b-instruct\nfalcon-7b-instruct\ndolly-v2-3b\ndolly-v2-7b\ndolly-v2-12b\nflan-t5-xl\nflan-t5-xxl\nvicuna-7b-v1.5-16k\nvicuna-13b-v1.5-16k\ngpt-3-davinci\ngpt-3-babbage\nllama-2-7b\nllama-2-13b\nmistral-7b\nfalcon-7b\nopt-125m\nopt-350m\nopt-1.3b\nopt-2.7b\nopt-6.7b\nopt-13b\nopt-iml-1.3b\nbloom-560m\nbloom-1b1\nbloom-1b7\nbloom-3b\npythia-160m\npythia-410m\npythia-1b\npythia-1.4b\npythia-2.8b\npythia-6.9b\npythia-12b\nS(fdefault,gl)\nS(flib_steered,gl)S(fcon_steered,gl)\nS(fdefault,gc)S(flib_steered,gc)\nS(fcon_steered,gc) (b) Affective alignment Smeasured in Roe v. Wade Tweets.\nFigure 7: Steered affect alignment Sof different LMs with ideological groups \u2013 liberals ( gl) and conservatives\n(gc), measured by moral foundations. Left-facing triangles represent the models by liberal steered prompting;\nright-facing triangles represent the models by conservative steered prompting; circles with no filling colors represent\nthe models by default. * indicates that the alignment of the liberal steered model with both ideological groups are\nsignificantly different at p <0.05; ^ indicates that for the conservative steered model. For each LM, the alignment\nis averaged over that on different topics detected within the dataset. Base LMs and instruction-tuned LMs are\nseparated by the black horizontal dashed line. The alignment between the two ideological groups (above the red\nhorizontal dashed line) themselves are measured as a baseline.\nanger anticipation disgust fear joy love optimism pessimism sadness0.00.20.40.60.8gl\ngc\ngpt-3.5default\ngpt-3.5lib_steered\ngpt-3.5con_steered\nllama2-7b-chat-ftdefault\nllama2-7b-chat-ftlib_steered\nllama2-7b-chat-ftcon_steered(a) Emotions.\ncare harm fairness cheating loyalty betrayal authority subversion purity0.00.20.40.60.8gl\ngc\ngpt-3.5default\ngpt-3.5lib_steeredgpt-3.5con_steered\nllama2-7b-chat-ftdefault\nllama2-7b-chat-ftlib_steered\nllama2-7b-chat-ftcon_steered\n(b) Moral Foundations.\nFigure 8: Distribution of affect (emotions and moral foundations) on topic \u201cfetal rights debate in abortion\u201d in Roe v.\nWade Tweets, from human-authored tweets and those generated by different LMs using different ways of prompting.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Whose emotions and moral sentiments do language models reflect?", "author": ["Z He", "S Guo", "A Rao", "K Lerman"], "pub_year": "2024", "venue": "arXiv preprint arXiv:2402.11114", "abstract": "Language models (LMs) are known to represent the perspectives of some social groups better  than others, which may impact their performance, especially on subjective tasks such as"}, "filled": false, "gsrank": 793, "pub_url": "https://arxiv.org/abs/2402.11114", "author_id": ["yrkXzXIAAAAJ", "s6JVFUIAAAAJ", "QovGNgYAAAAJ", "PlAG11IAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:emxumqOEVmkJ:scholar.google.com/&output=cite&scirp=792&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D790%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=emxumqOEVmkJ&ei=lrWsaPi1IL_SieoPzJnloAQ&json=", "num_citations": 19, "citedby_url": "/scholar?cites=7590400060185013370&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:emxumqOEVmkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2402.11114"}}, {"title": "Framing the Fray: Conflict Framing in Indian Election News Coverage", "year": "2025", "pdf_data": "Framing the Fray:\nConflict Framing in Indian Election News Coverage\nTejasvi Chebrolu\u2217\ntejasvi.chebrolu@research.iiit.ac.in\nInternational Institute of Information\nTechnology, Hyderabad\nHyderabad, Telangana, IndiaRohan Chowdhary\nrohan.modepalle@research.iiit.ac.in\nInternational Institute of Information\nTechnology, Hyderabad\nHyderabad, Telangana, IndiaN Harsha Vardhan\nnemani.v@research.iiit.ac.in\nInternational Institute of Information\nTechnology, Hyderabad\nHyderabad, Telangana, India\nPonnurangam Kumaraguru\npk.guru@iiit.ac.in\nInternational Institute of Information\nTechnology, Hyderabad\nHyderabad, Telangana, IndiaAshwin Rajadesingan\u2020\narajades@austin.utexas.edu\nUniversity of Texas at Austin\nAustin, Texas, USA\nAbstract\nIn covering elections, journalists often use conflict frames which\ndepict events and issues as adversarial, often highlighting confronta-\ntions between opposing parties. Although conflict frames result in\nmore citizen engagement, they may distract from substantive policy\ndiscussion. In this work, we analyze the use of conflict frames in\nonline English-language news articles by seven major news outlets\nin the 2014 and 2019 Indian general elections. We find that the\nuse of conflict frames is not linked to the news outlets\u2019 ideological\nbiases but is associated with TV-based (rather than print-based)\nmedia. Further, the majority of news outlets do not exhibit ideolog-\nical biases in portraying parties as aggressors or targets in articles\nwith conflict frames. Finally, comparing news articles reporting\non political speeches to their original speech transcripts, we find\nthat, on average, news outlets tend to consistently report on attacks\non the opposition party in the speeches but under-report on more\nsubstantive electoral issues covered in the speeches such as farmers\u2019\nissues and infrastructure.\nCCS Concepts\n\u2022Applied computing \u2192Publishing .\nKeywords\nNews framing, Indian elections, conflict frames\nACM Reference Format:\nTejasvi Chebrolu, Rohan Chowdhary, N Harsha Vardhan, Ponnurangam Ku-\nmaraguru, and Ashwin Rajadesingan. 2025. Framing the Fray: Conflict Fram-\ning in Indian Election News Coverage. In Proceedings of the 17th ACM Web\n\u2217Work done while at UT Austin\n\u2020Corresponding author\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA\n\u00a92025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-1483-2/2025/05\nhttps://doi.org/10.1145/3717867.3717900Science Conference 2025 (Websci \u201925), May 20\u201324, 2025, New Brunswick, NJ,\nUSA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3717867.\n3717900\n1 Introduction\nNews framing is a deliberate and strategic communication tech-\nnique that involves carefully selecting specific aspects of an issue\nand amplifying their significance to effectively convey a message\n[20]. News frames in election contexts are especially consequential\nas they influence how people perceive this fundamental democratic\nexercise. For example, in news reporting, elections can be framed\nas a conflict to be won, emphasizing the competitive aspects of\nelections. Alternatively, they can be framed as a platform for ex-\nchanging ideas and debating issues, highlighting the importance of\ncivic engagement and informed decision-making.\nIn this paper, we analyzed the use of conflict frames in Indian\nelection English-language news reporting. Conflict frames are de-\nfined as news frames that \u201cemphasize conflict between individuals,\ngroups, or institutions as a means of capturing audience interest\u201d\n[59]. Table 1 lists examples of article headlines with conflict frames.\nIn the first example, Modi, leader of the Bharatiya Janata Party\n(part of the NDA coalition) and the current prime minister of India,\nattacks the Indian National Congress (part of the UPA coalition),\nthe main opposition. Table 1 further highlights how various news\noutlets construct their conflict frames. For each outlet, we present\ntwo examples\u2014one portraying the NDA as the aggressor and an-\nother depicting the UPA in that role. Notably, both the NDA and\nthe UPA frequently engage in attacks on their opponents\u2019 character,\nyet the underlying reasons for these attacks are seldom mentioned.\nThis pattern suggests a broader trend in political coverage, where\nconflict is emphasized over substantive discussions. Finally, we pro-\nvide examples of headlines that do not employ conflict frames to\noffer a clearer contrast and better illustrate the concept\nWe chose to focus on conflict frames as they are known to have\nmixed consequences for how people perceive democracy. On the\none hand, conflict is inherent in politics, and reporting on such\nconflicts can highlight disagreement and differences, signalling to\nthe citizens that they have political choices [ 17]. Further, conflict\nframes may engage and excite citizens, increasing voter turnout\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA Chebrolu et al.\nTable 1: Some examples of election news headlines are shown here. The first group shows headlines with conflict frames,\nincluding the aggressor (political coalition making the attack) and target (political coalition being attacked). The second group\nshows headlines without conflict frames. The source is shown for all headlines.\nConflict Frame Headline Aggressor Target Source\nMedia chasing Sadhvi Pragya must also talk about corruption against Congress, its allies: PM Modi NDA UPA India Today\nRahul Gandhi mocks PM Modi\u2019s chowkidar campaign UPA NDA India Today\nMamata accuses Modi of buying votes with black money converted to white through demonetisation UPA NDA The Indian Express\nYour dad was \u2019Mr Clean\u2019, but ended life as a \u2019bhrashtachari\u2019: PM Modi to Rahul Gandhi NDA UPA The Indian Express\nVote for AAP to save India from Modi: CM Arvind Kejriwal UPA NDA The Times of India\nAAP, Cong jointly creating anarchy in Delhi: BJP NDA UPA The Times of India\nRahul begins campaign with attack on BJP UPA NDA The Hindu\nBJP hits back at Rahul on personality-oriented politics NDA UPA The Hindu\nRahul Gandhi compares Narendra Modi to Hitler UPA NDA NDTV\nNarendra Modi attacks Congress, Rahul Gandhi: His top 10 quotes NDA UPA NDTV\nCong MLA uses derogatory word for BJP leaders at Rahul\u2019s rally UPA NDA Zee News\nCongress Fielding Two Batsmen to Take Blame For Poll Defeat: PM Modi NDA UPA Zee News\nModi\u2019s 5 years \u2019most traumatic\u2019, should be shown exit door: Dr. Manmohan Singh UPA NDA Republic World\nCongress manifesto full of lies, hypocrisy: PM Modi NDA UPA Republic World\nNon-Conflict Frame Headline\nRamdev to urge people to vote for Modi - The Times of India\nMamata Banerjee to begin poll campaign on Women\u2019s Day - Republic World\nL K Advani lauds Harsh Vardhan for pulse polio campaign - The Indian Express\nPM rules out third term, but makes robust defense of economic policies - NDTV\nAAP\u2019s former Delhi ministers to campaign in Varanasi, Amethi - Zee News\nParties rope in celebs to jazz up campaigning in Himachal - India Today\nAAP government wins confidence vote - The Hindu\n[58]. On the other hand, conflict frames, by emphasizing disagree-\nment, which is often framed as attacks, increase polarization [ 31]\nand erode political trust [ 43]. Further, this way of framing distracts\ncitizens from obtaining substantive policy or issue information,\ndepressing political knowledge, and increasing cynicism [ 13]. Par-\nticularly in an increasingly hostile and polarized Indian political\nclimate [ 28], conflict frames may play a crucial role in how the\nelectorate views their democratic systems and politics.\nTo study conflict frames, we fine-tuned a DistilBERT classifier\n[56] to identify conflict frames in news headlines from seven promi-\nnent Indian news outlets (N=69,400 articles) during the 2014 and\n2019 Indian General elections. Using the classifier, we evaluated\nhow these frames vary by media outlets\u2019 ideological bias, their pri-\nmary modality (TV vs print), and which party they were reporting\non.\nAn enduring puzzle in framing research is understanding to what\nextent media coverage actually reflects the complex ground reality\nthat it hopes to represent [ 21]. In our case, the question is whether\nnews outlets overemphasize conflict over more substantive issues\nin their election coverage. The challenge in conducting such an\nanalysis is that it is hard to separate out news reporting choosing\nto emphasize attacks between parties from the ground reality of\npolitical parties stepping up their attacks. We resolved this issue\nby constructing a unique dataset of campaign speeches and news\narticles that report on these speeches. By directly comparing the\nissues extracted from the transcript of campaign speeches to the\nissues covered in their corresponding articles, we were able to\nevaluate which issues were under and over-reported.\nWe summarize the key findings of this study:\u2022Media modality (TV-based vs print-based), rather than media\nbias, significantly correlates with the use of conflict frames\nin election news articles in India.\n\u2022Most sources do not exhibit ideological biases in portraying\na party as the aggressor or target in articles with conflict\nframes.\n\u2022Compared to regional parties, national parties are more\nprominently featured in headlines that employ conflict frames.\n\u2022Media coverage often under-reports on substantive issues\nsuch as farmer concerns and infrastructure in favour of high-\nlighting attacks on the opposition when reporting on politi-\ncians\u2019 speeches.\n2 Related work\n2.1 Conflict framing\nConflict frames are one of the most commonly used news frames\n[59]. They highlight conflicts between individuals, groups, insti-\ntutions, or countries. Conflict frames are generic frames and are\nnot related to a specific topic or issue [ 18]. These frames may high-\nlight personal/substantive, civil/uncivil, deep/superficial or norma-\ntive/factual aspects of political conflicts [ 61]. The use of conflict\nframes when reporting election-related news has mixed effects -\nerosion of political trust [ 13,43] and decline in the approval of\npoliticians [ 23] as well as increased awareness of the significance\nof political decision-making [ 57] and increased voter turnout [ 39].\nHence, understanding conflict framing in election news is crucial\ndue to its complex effects on the electorate.\nFraming the Fray:\nConflict Framing in Indian Election News Coverage Websci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA\n2.2 (Over)emphasizing conflict frames\nJournalists and newsrooms strive to accurately reflect the happen-\nings on the ground. However, with limited resources, journalists\nmake deliberate choices on what events to report on and how to\ncover them, relying on heuristics such as novelty to determine cov-\nerage [ 62]. These practices sometimes lead to coverage that often\ndistorts reality [ 21]. There may be multiple factors that lead jour-\nnalists to overemphasize conflict frames beyond the ground reality.\nResearch suggests that providing a confrontational angle to news\ngrabs attention and engages a larger audience [ 42]. Commercial\ninterests [ 37] and rising competition [ 6] may also influence the use\nof conflict frames.\nThere is some evidence to suggest that the media may indeed\noveremphasize conflict frames over substantive issues. Through\nsemi-structured interviews of journalists, Bartholom\u00e9 et al . [4]\nfound that journalists play an active role in the conflict frame-\nbuilding process. They find that \u201csubtle methods of journalistic\nnews production are applied to facilitate, emphasize, and sometimes\neven exaggerate conflict.\u201d In their interviews with journalists and\ncontent analysis of Swiss election campaign coverage, H\u00e4nggli and\nKriesi [26] found that journalists do use conflict frames more than\npolitical actors. Yet, questions remain on the extent to which conflict\nframes are favoured over substantive issues. In this work, using a\nnovel dataset of campaign speeches and their corresponding news\nreporting, we quantitatively uncovered how conflict frames may\noverride other issue frames in reporting.\n2.3 News framing in online Indian news\nIn recent times, online news media has played a crucial role in\nthe Indian elections [ 36]. However, there is little empirical work\non online news media and Indian elections. Unsurprisingly, given\nthe complex and well-funded party-affiliated \u2018IT cells\u2019 [ 15], the\nmajority of research focuses on Narendra Modi and the BJP\u2019s use\nof social media in political campaigning [ 50,51]. Neyazi et al . [46]\ntrace how the BJP\u2019s social media dominance often translates to\nsignificant coverage on traditional media. However, there is little\nempirical research on news framing in the Indian context (see Jha\nand Vats [29], Mudgal [41]for exceptions). While conflict frames\nhave not been explicitly studied, research suggests that \u201cthe media\nenvironment was conducive to lively contestation\u201d during the re-\ncent election cycles, with media featuring parties often attacking\neach other [ 47]. Our research aims to address the gap in existing lit-\nerature, where there is a lack of large-scale analyses on how Indian\nnews media employ conflict frames.\n2.4 News frame detection\nComputational framing methods can be categorized into topic mod-\nelling, frequency modelling, neural network-based models, and\ncluster-based models [ 2]. Researchers have used topic modelling\n[48,54], frequency modelling [ 55], and cluster-based models [ 11]\nto analyze frames in large datasets. Embedding-based techniques\nenable cross-lingual frame projection [ 22]. Neural models, includ-\ning LSTMs [ 44] and RNNs, have also been used for frame detec-\ntion. Transformer-based models like RoBERTa have been applied in\nmulti-task learning scenarios [ 12]. Frame detection is often posedas a multi-label classification problem [ 38], with pre-trained trans-\nformer models fine-tuned for this task [ 30]. Multilingual transfer\nlearning has been used in low-resource contexts [ 1]. Most existing\nneural network-based models draw inspiration from The Media\nFrames Corpus [ 14], which contains news articles discussing five\npolicy issues: tobacco, immigration, same-sex marriage, gun con-\ntrol, and the death penalty. While these models perform well on\ntheir specific tasks, the frames they analyze and the contexts they\naddress differ significantly from our focus. As a result these models\nand datasets are not particularly relevant to the Indian context.\nTherefore, we trained a new classifier with a new dataset tailored\nspecifically to our research objectives.\n3 Background: Indian electoral context\nIn this work, we analyzed news articles published during the 2014\nand 2019 Indian general elections. Through the general elections,\ncandidates are elected to the Indian Parliament (Lok Sabha). The\npolitical party or coalition that secures the majority of seats in the\nLok Sabha forms the government. In India, the United Progressive\nAlliance (UPA) and the National Democratic Alliance (NDA) are\nthe two major political coalitions. The UPA is a center-left alliance\nled by the Indian National Congress (INC), while the NDA is a\ncenter-right alliance led by the Bharatiya Janata Party (BJP). The\nUPA was the incumbent alliance in the 2014 elections, while the\nNDA has been in power from 2019 and beyond (as of 2024).\nIn 2014, the polling dates spanned a period from 7 April to 12\nMay in nine phases, culminating in the declaration of results on 16\nMay. Similarly, in 2019, the polling dates extended from 11 April to\n19 May in seven phases.\n4 Data\n4.1 News articles\nWe analyzed news articles from seven major news outlets that are\namong India\u2019s most popular and influential English-language news\nmedia agencies [ 27]. The Hindu, The Indian Express, and NDTV\nare considered either left or left-center (N=35,870 articles). While\nZee News, The Times of India, Republic World and India Today\nare either right or right-center (N=33,530 articles). These biases\nare based on Media Bias Fact Check classifications (MBFC) [ 63].\nMBFC uses stance on policy issues to determine ideological bias.\nAlthough US-based, its ratings on Indian sources align well with\nresearch showing that The Hindu, The Indian Express and NDTV\nprovide an anti-(BJP) government frame while the other sources\nprovide a pro-government frame in their coverage [7, 24, 45, 60].\nIn contrast to the Global North, India\u2019s news landscape remains\ndominated by traditional print and television media. The online\nnews outlets selected are relatively newer offshoots of established\nprint or TV platforms, reflecting this media environment. We fo-\ncused this study on nationally prominent, predominantly English-\nlanguage outlets with diverse regional bases, analyzing full-length\ntext articles and excluding any video material from both print\nand television-based media. These sources were chosen for their\nwide circulation, national presence, and regional diversity. Though\nnot exhaustive, this selection provides a diverse sample of India\u2019s\nEnglish-language national news outlets.\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA Chebrolu et al.\nFor each source, we collected the news articles published on their\nwebsites for the two general elections cycles. Our analysis is limited\nto these two election years as online archives were unavailable for\nprevious election cycles for most news outlets. Republic World was\nlaunched in 2017, and hence, we analyze articles from this source\nonly for the 2019 elections. Table 2 gives an overview of the dataset.\nWe limited our data to the articles that were published between\nJanuary 1st of that year until the day before the results were an-\nnounced (1 January - 16 May 2014 and 1 January - 23 May 2019).\nThen, we use keyword-based matching on article headlines and\nURLs to identify election-related articles published during the anal-\nysis period. The list of keywords (such as election and vote) used is\nshown in the Appendix (Section A).\nTable 2: The number of articles belonging to a particular out-\nlet, the outlet\u2019s bias (according to MBFC), and their modality.\nSource Article Count Bias Modality\nThe Hindu 12,711 Left-leaning Print\nThe Times of India 15,158 Right-leaning Print\nThe Indian Express 13,748 Left-leaning Print\nNDTV 9,411 Left-leaning TV\nIndia Today 9,157 Right-leaning TV\nRepublic World 2,640 Right-leaning TV\nZee News 6,575 Right-leaning TV\n4.2 Campaign speeches\nWe collected campaign speeches made by BJP and INC party leaders\nduring election campaigning to evaluate how issues were reported\nby the news outlets (N=224 speeches). Some speeches were origi-\nnally in Hindi and were translated with the aid of GPT4-Turbo [ 49].\nThe translation prompt can be found in the Appendix (Section B).\nWe note that this dataset is not an exhaustive list of all speeches\nmade during the campaigns, as some speeches were not recorded\non the official websites. A random selection of five full-text speech\ntranslations was evaluated by an annotator fluent in both Hindi\nand English and was found to be accurately translated. The dataset\nand code used in this project are publicly available on GitHub.1\n5 Methodology\n5.1 Unit of analysis: Article headline\nWe analyzed conflict frames in news headlines because of their\noutsized influence on content interpretation and their high con-\nsumption. Headlines are \u201cthe most potent framing device within the\nsyntactical structure\u201d [ 52], which influence article interpretation\neven when full text is read [ 19]. Further, 6 out of 10 readers only\nread headlines [ 9]. Paywalls also increase headlines\u2019 importance\nas accessible information sources. This approach aligns with prior\nliterature examining headlines for frame analysis [1, 16, 35].\n5.2 Operationalizing conflict frame\nWe operationalized conflict frames in news headlines based on\nSchuck et al . [58] \u2019s criteria, which include references to multiple\n1https://github.com/Ashwin-R/WebScience25-Conflict-Framessides of an issue, mentions of conflict or disagreement, personal\nattacks between actors, or instances of reproach or blame. Given\nthat conflict frames require at least two political entities, we auto-\nmatically label headlines with fewer than two entities as not conflict .\nFor headlines containing two or more political entities, we train a\nclassifier to determine the presence of a conflict frame based on the\naforementioned criteria.\n5.3 Training data for conflict frame classifier\nTo create the training dataset for our classifier, we employed a\ntwo-stage annotation process. Initially, two human annotators clas-\nsified 151 news headlines, each containing at least two political\nentities, into either conflict or non-conflict frames based on the\naforementioned operationalization. A high inter-rater agreement\nwas achieved (Cohen\u2019s \ud835\udf05= 0.81). Subsequently, the annotators in-\ndependently classified an additional 709 headlines with similar cri-\nteria, resulting in a total dataset of 860 headlines. The final dataset\ncomprised 566 conflict frames and 294 non-conflict frames. This\ndataset was used for training our model to identify conflict frames\nin election news headlines.\n5.4 Conflict frame classifier\nWe finetuned a pre-trained English DistilBERT model2for text\nclassification using the 860 labelled samples. We performed a hyper-\nparameter search to optimize model performance using wandb\n[8]. Following established research [ 64], we extended the training\nepochs, as current literature suggests this approach improves both\nperformance and stability for smaller datasets (<1000 samples). Our\ntraining approach follows a proven transfer learning methodology\n[53]. We fine-tuned a pre-trained model, which was initially trained\non language modeling and further fine-tuned on SST-2 for text\nclassification prior to our task-specific training. This progressive\nlearning approach enhances model robustness. The optimal hyper-\nparameters are listed in the Appendix (Table 7). The average values\nof the 5-fold cross-validation are summarized in Table 3.\nApplying the classifier to the full dataset of news headlines, we\nfind that 11,225 of the 69,400 news headlines (19.29%) have been\nclassified as having a conflict frame. More classifier validation and\nrobustness checks are mentioned in the Appendix (Section E).\nTable 3: 5-fold cross-validation metrics of the classifier used\nto identify frames in election news headlines.\nClass Precision Recall F1-Score\nConflict 0.92 0.91 0.92\nNon-Conflict 0.81 0.82 0.81\nMacro average 0.87 0.87 0.87\n5.5 Extracting political parties and politicians\nWe identified politicians and political parties mentioned in arti-\ncle headlines by matching with data from official party websites\nand the LokDhaba Indian Elections dataset [ 33]. Then, we mapped\nmentions of politicians to their respective parties. In total, 47,376\n2https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\nFraming the Fray:\nConflict Framing in Indian Election News Coverage Websci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA\narticles mentioned at least one party in their headlines, with 16,827\nmentioning at least two parties. Further details and a worked exam-\nple detailing the matching process are mentioned in the Appendix\n(Section C).\n5.6 Extracting aggressors and targets\nFor headlines that employed conflict frame, we identified the ag-\ngressors and targets by analyzing the structure of the headline.\nUsing GPT-4 Turbo [ 49], we extracted these roles, typically with\nthe aggressor as the speaker or subject and the target as the object\nof the headline respectively. Then, we mapped politicians to their\nrespective political parties using the approach described above. This\nmethod was validated with a list of 100 headlines, human-annotated\nfor aggressors and targets, achieving 98% accuracy. Accuracy was\ncalculated as the percentage of headlines where both the aggressor\nand target were correctly identified. Further metrics and additional\ndetails can be found in the Appendix (Section G).\n5.7 Matching campaign speeches to news\narticles\nFor each speech in the speech dataset, we manually extracted the\nlocation and speaker from the titles of the speech, discarding unclear\ncases. Articles were matched to speeches if published within three\ndays of the speech, mentioning the speaker, location, and at least\none speech-related term in the article text. This approach matched\n145 speeches to 607 articles. A manual evaluation of 50 samples\nshowed 85% accuracy. Accuracy is defined as the percentage of\nmatched articles that actually mentioned or discussed the speech\nin question. The full list of speech event terms (such as \u2018rally\u2019 and\n\u2018meeting\u2019) is shown in the Appendix (Section D).\n5.8 Extracting electoral issues mentioned in\nspeeches and news articles\nTo identify electoral issues, we used data from the 2014 (Q8) and\n2019 (Q12, Q38) National Election Study Pre-Poll Surveys which\nsurveyed participants on the importance of different issues. We\nselected issues that at least 1% of the survey respondents rated as\nimportant. This included 19 issues, such as healthcare and elec-\ntricity. We also included an \u2018Opposition\u2019 issue, which corresponds\nto mentions of the opposition party or its members. To identify\nthese mentions of the opposition, we use the approach described\nearlier (Section 5.5). These opposition party mentions in campaign\nspeeches are invariably negative and attacking in nature.\nTo identify which of these issues were covered in the speeches,\nwe followed Muddiman and Stroud [40]\u2019s dictionary-based ap-\nproach. Initially, we generated a list of the most frequently used\n5,000 stemmed terms from speeches and articles after removing stop\nwords. Then, in the first pass, three annotators manually scanned\nthrough these terms and mapped all relevant terms to each issue\nbased on their reading of party manifestos and domain knowledge.\nFor each candidate term, 10 sentences containing the term were\nsampled and manually labelled for topic relevance (1 or 0). For\nthe first 100 candidate terms (1000 sentences), three annotators\nachieved high inter-rater reliability in their topic relevance coding\n(Fleiss\ud835\udf05=0.84). Then, the three annotators independently labelled\nthe remaining terms. The candidate terms were removed if lessthan 80% of the sampled sentences related to the issue. This process\nyielded a dataset of 19 issues containing 139 keywords from 584\ncandidate terms. The list of issues and keywords can be found in\nthe Appendix (Table 10).\n6 Analysis\nThe regression analyses were performed using the \ud835\udc59\ud835\udc5a\ud835\udc524R package\n[5]. The marginal means estimation and the planned contrasts were\nconducted using the \ud835\udc52\ud835\udc5a\ud835\udc5a\ud835\udc52\ud835\udc4e\ud835\udc5b\ud835\udc60 R package [34].\n6.1 How do media bias and modality relate to\nmedia outlets\u2019 use of conflict frames?\nWe conducted a random-effects logistic regression on the 69,400\nnews headlines dataset, modeling the presence of a conflict frame\nin the news headline as a dependent variable (0 or 1) with a random\neffect for news source, a control variable indicating election year\n(2014 or 2019) and the variable of interest, media bias (left or right).\nTo evaluate how the modality of the source relates to the use of\nconflict frames, we used an identical logistic regression model with\nan additional independent variable indicating whether the source\nwas print-based or TV-based. The results of the two regressions are\navailable in the left and center columns of Table 4.\nFrom the left column in Table 4, we find that the coefficient for\nthe media bias indicator is not statistically significant. Thus, we did\nnot find reliable evidence of an association between the ideological\nbias of the media outlet and the frequency with which it employs\nconflict frames in election news. Whereas, from the center column,\nbased on the co-efficient for the primary modality indicator, we\nfind that the odds of TV-based news outlets employing conflict\nframes is twice the odds of such usage at print-based news outlets\n(\ud835\udc4f=0.707,\ud835\udc42\ud835\udc45=2.030,\ud835\udc46\ud835\udc38=0.17982,\ud835\udc67-\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 =3.933,\ud835\udc5d<0.001).\nThis difference is statistically significant. These results suggest that\nin English-medium Indian election news, conflict frames are driven\nmore by the media modality (TV vs. print) than by ideological bias.\n6.2 How does the use of conflict frames vary\nwhen reporting on national and regional\nparties?\nWe conducted a similar logistic regression as before and included\ntwo indicator variables indicating the presence of national and\nregional parties. Note that we use separate indicator variables as\nthe headlines may include both national and regional parties. For\nthis analysis, since we were comparing the two party types, we\nonly included articles that mention at least one party (n = 47,376).\nFrom the coefficient for the national party indicator in the right\ncolumn in Table 4, we find that the mention of a national party\nin the headline is positively associated with the headline using a\nconflict frame ( \ud835\udc4f=3.277,\ud835\udc42\ud835\udc45=26.490,\ud835\udc67-\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 =71.810,\ud835\udc5d<0.01).\nSimilarly, the presence of a regional party is also positively asso-\nciated with the headline using a conflict frame (\ud835\udc4f=2.085,\ud835\udc42\ud835\udc45=\n8.047,\ud835\udc67-\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 =77.129,\ud835\udc5d<0.01). Further, the odds of using con-\nflict frames in headlines mentioning national parties is more than\nthree times that of headlines mentioning regional parties. This dif-\nference is statistically significant (via Wald test, W(1) = 745.61,\n\ud835\udc5d<0.01).\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA Chebrolu et al.\nTable 4: Results from random-effects logistic regressions modeling conflict frames in the headlines as the dependent variable,\nincluding random effects for news source, election year control variable, and other variables of interest.\nDependent variable:\nIs conflict frame\nSection 6.1 Section 6.1 Section 6.2\n(Media bias) (Media modality) (Regional vs national party)\nMentions national party 3.277\u2217\u2217\u2217\n(0.046)\nMentions regional party 2.085\u2217\u2217\u2217\n(0.027)\nMedia bias: left-leaning (vs right-leaning) \u22120.228 0.068 0.090\n(0.256) (0.175) (0.094)\nPrimary modality: TV-based (vs print-based) 0.707\u2217\u2217\u22170.467\u2217\u2217\u2217\n(0.180) (0.094)\nElection cycle: 2019 (vs 2014) 0.304\u2217\u2217\u22170.304\u2217\u2217\u22170.259\u2217\u2217\u2217\n(0.023) (0.023) (0.028)\nConstant \u22121.657\u2217\u2217\u2217\u22122.188\u2217\u2217\u2217\u22125.271\u2217\u2217\u2217\n(0.172) (0.171) (0.102)\nObservations 69,400 69,400 47,376\nLog Likelihood \u221229,957.160\u221229,953.050 \u221220,734.490\nNote:\u2217p<0.1;\u2217\u2217p<0.05;\u2217\u2217\u2217p<0.01\nFigure 1: 95% CI of probabilities for major political coalitions as aggressors (a) and targets (b) in conflict frame headlines across\nmedia outlets. Left-leaning media and UPA are shown in blue; right-leaning media and NDA are in orange. The CI values and\nestimates are detailed in Table 11 and Table 12.\n6.3 How do news outlets differ in reporting\nwhich parties and coalitions are attacking or\nbeing attacked in conflict frame headlines?\nWe aggregated by source, the proportion of conflict frame articles\nthat portray the UPA (left-wing coalition including the INC) and the\nNDA (right-wing coalition including the BJP) as attacking another\nparty or being attacked by another party. Figure 1 shows, aggregated\nby the news outlet, the 95% CI of the proportion of conflict headlineswhere the coalitions are the aggressors (a) and where the coalitions\nare the targets (b).\nFrom Figure 1 (a), we observe that a majority of sources (India\nToday, The Times of India, The Indian Express, NDTV) across both\nyears report on similar proportions of conflict-framed headlines\nwhere NDA and UPA coalitions are the aggressors. The differences\nbetween the proportion of UPA attacking ( \ud835\udc4eUPA) and NDA attack-\ning (\ud835\udc4eNDA) headlines are statistically significant for The Hindu\n(\ud835\udc4eUPA=0.34,\ud835\udc4eNDA=0.29,\ud835\udc67-\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 =2.231,\ud835\udc5d<0.05), Republic\nFraming the Fray:\nConflict Framing in Indian Election News Coverage Websci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA\nWorld (\ud835\udc4eUPA=0.31,\ud835\udc4eNDA=0.37,\ud835\udc67-\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 =\u22122.729,\ud835\udc5d<0.01), and\nZee News (\ud835\udc4eUPA=0.31,\ud835\udc4eNDA=0.39,\ud835\udc67-\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 =\u22124.690,\ud835\udc5d<0.01)\nin 2019. The Hindu (left-leaning) published a higher proportion of\nheadlines with the UPA coalition (left-leaning) as the aggressor,\nwhile the Republic World and Zee News (both right-leaning) pub-\nlished a higher proportion of the NDA coalition (right-leaning) as\naggressors, which was consistent with their ideological biases.\nFrom Figure 1 (b), most sources across both years report a signif-\nicantly higher proportion of conflict-framed headlines where the\nNDA is being attacked compared to the UPA. Zee News in 2014\nand Republic World in 2019 do not exhibit a statistically significant\ndifference in their reporting of NDA and UPA being attacked.3\nSomewhat surprisingly, even in the case of the Republic World,\nknown for its extreme pro-BJP stance [ 24], over 40% of news head-\nlines with conflict frames portray the NDA as being attacked.\n6.4 Are conflicts over-emphasized compared to\nelectoral issues?\nTo evaluate this question, we compared the issues mentioned in\nthe speeches to the issues mentioned in the news reporting on the\nspeeches using the issue keywords identified in Section 5.8. First,\nthe headlines of news articles reporting on campaign speeches\nwere classified as having a conflict frame at a much higher rate\nthan the full dataset ( 31.96% vs 19.29%, z-score=10.48, \ud835\udc5d<\n0.01), suggesting that campaign speeches are disproportionately\nreported with a conflict frame. In contrast, only 1.1% of news articles\nreporting on campaign speeches included a headline mentioning\none of the issue topics, highlighting the significant underreporting\nof issues compared to conflicts.\nExamining the full content of the matched news articles, Figure\n2 shows a scatter plot with the x-axis representing the number of\nspeeches that mention an issue and the y-axis representing the\nproportion of matched articles that mention that issue. Higher y-\nvalues imply that a higher proportion of articles that were matched\nto the speech discuss that issue.\nFrom Figure 2, we find that most speeches reference the opposi-\ntion, likely with attacking intent and given that the speech mentions\nthe opposition, 88% of articles that report on the speech also men-\ntion the opposition in the article text. However, this proportion\ndrops significantly when speeches mention other more substan-\ntive issues. For example, only about 30% of articles reporting on\ncampaign speeches that mention farmer issues actually mention\nfarmer issues. Thus, while news outlets do not technically over-\nreport on conflict (since political campaign speeches more often\nthan not deride the opposition party), they appear to underreport\nmore substantive policy issues.\n7 Discussion\n7.1 Effect of media ideological bias in online\nnews\nFrom our analyses, ideological biases of the news outlets were not\nsignificantly associated with the use of conflict frames. Barring\nsome exceptions in the 2019 election cycle, we found that sources,\n3We do not print the proportion percentages in the figure for readability reasons.\nAppendix Tables 11 and 12 contain all the proportion percentages.\nFigure 2: The frequency of speeches mentioning a specific\nissue versus the proportion of articles mentioning the same\nissue. Analysis shows substantive topics, like farmers\u2019 issues,\nare underrepresented (bottom-left), whereas the most fre-\nquently mentioned issue is the opposition. The frequency\nand proportion values are detailed in Table 9.\nirrespective of their ideological biases, did not significantly differ\nin terms of the proportion of news headlines that portrayed the\nUPA and NDA coalitions as aggressors. Surprisingly, given the\nrelative lack of press freedom4, most sources, irrespective of their\nideological biases, published a much higher proportion of news\nheadlines where the right-leaning NDA was targeted. These results\nsuggest that ideological bias doesn\u2019t correlate with conflict framing\nchoices in Indian election news coverage.\nOther factors may play a more substantial role in selecting con-\nflict frames. We find that TV-based news outlets publish a higher\nproportion of conflict-frame headlines than print-based outlets.\nThis finding is in contrast to past studies in Europe, which suggest\nthat the major difference was not between print and TV media\nbut between sensationalist and sober media [ 59]. Further, other re-\nsearch suggests that conflict frames increase readership, and hence,\nmedia outlets may have commercial interests in publishing news\nheadlines with conflict frames [ 37]. Also, interestingly, even Re-\npublic World, the heavily pro-BJP/NDA news outlet [ 24] published\nover 40% of conflict frame headlines targeting the right-wing NDA\ncoalition. One potential reason is that attacks on the in-party can\nprovoke anger and mobilize partisans [ 25], leading to increased\nconsumption of partisan content. Further, conflict frames highlight\ndisagreements and contentious interactions and are especially ef-\nfective at drawing viewers\u2019 attention [ 59]. Since higher viewers\ntranslate into increased advertising revenue, outlets have a strong\nincentive to use conflict frames, even if the attacks are against the\ncoalition they may be biased towards, in order to boost viewership\nand, ultimately, their profits [ 37]. An alternate reason could be that\nthe media reports simply reflect the inter-party dynamics on the\nground. Since NDA coalition has emerged as the stronger coali-\ntion over the past decade, winning three consecutive elections, it is\nlikely that other parties have stepped up their attacks on the NDA\nresulting in an uptick of such reporting.\n4https://rsf.org/en/country/india\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA Chebrolu et al.\n7.2 Pathway to political polarization\nOur findings indicate that news outlets use conflict frames more fre-\nquently when reporting on national parties than regional parties. As\nnational parties are followed by more citizens compared to regional\nparties, this may further contribute to public perception that poli-\ntics is highly negative and hyperpartisan, exacerbating polarization.\nResearch suggests that citizens draw their cues from political elites\nand respond to elite polarization by expressing negative evaluations\nof the outparty, resulting in what political scientists call affective\npolarization [ 3]. Affective polarization has significant negative con-\nsequences, such as reducing political trust and lowering support\nfor bipartisanship [32] (see [10] for an alternate perspective).\nComparing campaign speeches and the news articles that re-\nported on them, we find that news articles consistently report on\nmentions of the opposition party in the speeches, which are likely\nnegative in nature, while significantly under-reporting on elec-\ntorally consequential issues such as farmer welfare, which were\nalso brought up in the speeches. Such emphasis on conflict rather\nthan substantive issues may result in lower knowledge about politi-\ncal issues among citizens [ 13] while exacerbating polarization [ 31].\nIt can also lead to an erosion of public trust [ 13,43], and decline in\nthe approval of politicians [23].\n8 Limitations and Future Work\nWhile our research provides meaningful insights, it is not without\nlimitations. Our analysis is restricted to conflict frames. Although\nconflict framing is critical to understanding election news reporting,\nincorporating other frames, such as strategy or game frames, could\nyield alternative perspectives. Future research may explore these\nadditional frames, identify multiple frames, and integrate multi-\nmedia content such as images to develop a better understanding\nof election news framing. Similarly, while the regression analyses\nperformed were useful, we likely did not control for other potential\nconfounding factors influencing conflict framing such as media\nownership or market share. The dataset includes articles from only\nEnglish-language news outlets, which, while widely read, exclude\nregional news outlets and Indian-language publications. It is unclear\nif these results can be generalized to regional language publications.\nExpanding the dataset to include diverse sources could provide a\nmore representative analysis.\nThis work focuses primarily on headlines, given their outsized\ninfluence on readers\u2019 perceptions. However, the body of the arti-\ncles and multimedia elements, may also play significant roles in\nframing and warrant further investigation. The campaign speech\ndataset is constrained to those available on the official websites of\nnational parties (INC and BJP). Regional parties often lack archived\nspeeches, limiting the scope of our analysis. Finally, the research\nis contextually focused on India, precluding cross-country com-\nparisons. A comparative analysis with other democratic systems\ncould provide valuable insights into the universality or uniqueness\nof conflict framing in election coverage. Additionally, analyzing\ndifferences in headline framing across media outlets with varying\npolitical orientations could also provide more details on how media\nbias could influence conflict framing.9 Ethical Considerations\nStudying media processes in India is crucial, given the complex\nand evolving landscape of press freedom in the country. There\nhave been significant challenges to press freedom in the country\nwith Reporters Without Borders ranking India at 159 out of 180\ncountries in their Press Freedom Index5. In this context, we aimed\nto provide a nuanced perspective of how news outlets employ\nconflict frames while acknowledging that the political climate has\nseen increasing pressure on media outlets and journalists in recent\nyears. All analyses presented in the paper are at the news source\nlevel, do not identify individual reporters and use publicly available\nnews articles.\nAcknowledgments\nThe authors acknowledge the generous support from the Center for\nMedia Engagement and the Moody College of Communication at\nThe University of Texas at Austin. They also acknowledge various\nstudents at Precog, IIITH for valuable suggestions which helped\nthe paper immensely.\nReferences\n[1]Afra Feyza Aky\u00fcrek, Lei Guo, Randa Elanwar, Prakash Ishwar, Margrit Betke, and\nDerry Tanti Wijaya. 2020. Multi-Label and Multilingual News Framing Analysis.\nInProceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics . Association for Computational Linguistics, Online, 8614\u20138624. https:\n//doi.org/10.18653/v1/2020.acl-main.763\n[2]Mohammad Ali and Naeemul Hassan. 2022. A Survey of Computational Framing\nAnalysis Approaches. In Proceedings of the 2022 Conference on Empirical Meth-\nods in Natural Language Processing . Association for Computational Linguistics,\nAbu Dhabi, United Arab Emirates, 9335\u20139348. https://doi.org/10.18653/v1/2022.\nemnlp-main.633\n[3]Kevin K Banda and John Cluverius. 2018. Elite polarization, party extremity, and\naffective polarization. Electoral Studies 56 (2018), 90\u2013101.\n[4]Guus Bartholom\u00e9, Sophie Lecheler, and Claes de Vreese. 2015. Manufacturing\nconflict? How journalists intervene in the conflict frame building process. The\nInternational Journal of Press/Politics 20, 4 (2015), 438\u2013457.\n[5]Douglas Bates, Martin M\u00e4chler, Ben Bolker, and Steve Walker. 2015. Fitting linear\nmixed-effects models using lme4. Journal of statistical software 67 (2015), 1\u201348.\n[6]W Lance Bennett. 2016. News: The politics of illusion . University of Chicago\nPress.\n[7]Prashanth Bhat. 2020. Anti-media populism: Media criticism by right-wing al-\nternative media in India . Ph. D. Dissertation. University of Maryland, College\nPark.\n[8]Lukas Biewald. 2020. Experiment Tracking with Weights and Biases. https:\n//www.wandb.com/ Software available from wandb.com.\n[9]Ray Boyer. 2014. National Survey: The Personal News Cycle: How Americans\nGet Their News. (2014).\n[10] David E Broockman, Joshua L Kalla, and Sean J Westwood. 2023. Does affec-\ntive polarization undermine democratic norms or accountability? Maybe not.\nAmerican Journal of Political Science 67, 3 (2023), 808\u2013828.\n[11] Bjorn Burscher, Rens Vliegenthart, and Claes H de Vreese. 2016. Frames beyond\nwords: Applying cluster and sentiment analysis to news coverage of the nuclear\npower issue. Social Science Computer Review 34, 5 (2016), 530\u2013545.\n[12] Pere-Llu\u00eds Huguet Cabot, Verna Dankers, David Abadi, Agneta Fischer, and\nEkaterina Shutova. 2020. The pragmatics behind politics: Modelling metaphor,\nframing and emotion in political discourse. In Findings of the association for\ncomputational linguistics: emnlp 2020 . 4479\u20134488.\n[13] Joseph N Cappella and Kathleen Hall Jamieson. 1997. Spiral of cynicism: The press\nand the public good . Oxford University Press.\n[14] Dallas Card, Amber Boydstun, Justin Gross, Philip Resnik, and Noah Smith. 2015.\nThe Media Frames Corpus: Annotations of Frames Across Issues. 2 (01 2015),\n438\u2013444. https://doi.org/10.3115/v1/P15-2072\n[15] Swati Chaturvedi. 2016. I am a troll: Inside the secret world of the BJP\u2019s digital\narmy . Juggernaut Books.\n[16] Aaron Chuey, Yiwei Luo, and Ellen M Markman. 2024. Epistemic language in\nnews headlines shapes readers\u2019 perceptions of objectivity. Proceedings of the\nNational Academy of Sciences 121, 20 (2024), e2314091121.\n5https://rsf.org/en/index\nFraming the Fray:\nConflict Framing in Indian Election News Coverage Websci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA\n[17] Claes De Vreese and Mette Tobiasen. 2007. Conflict and identity: explaining\nturnout and anti-integrationist voting in the Danish 2004 elections for the Euro-\npean Parliament. Scandinavian Political Studies 30, 1 (2007), 87\u2013114.\n[18] Claes H De Vreese. 2005. News framing: Theory and typology. Information design\njournal+ document design 13, 1 (2005), 51\u201362.\n[19] Ullrich KH Ecker, Stephan Lewandowsky, Ee Pin Chang, and Rekha Pillai. 2014.\nThe effects of subtle misinformation in news headlines. Journal of experimental\npsychology: applied 20, 4 (2014), 323.\n[20] Robert M. Entman. 2006. Framing: Toward Clarification of a Fractured Par-\nadigm. Journal of Communication 43, 4 (02 2006), 51\u201358. https://doi.org/\n10.1111/j.1460-2466.1993.tb01304.x arXiv:https://academic.oup.com/joc/article-\npdf/43/4/51/22343264/jjnlcom0051.pdf\n[21] Robert M Entman. 2007. Framing bias: Media in the distribution of power. Journal\nof communication 57, 1 (2007), 163\u2013173.\n[22] Anjalie Field, Doron Kliger, Shuly Wintner, Jennifer Pan, Dan Jurafsky, and Yulia\nTsvetkov. 2018. Framing and Agenda-setting in Russian News: a Computational\nAnalysis of Intricate Political Strategies. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing . Association for Computational\nLinguistics, Brussels, Belgium, 3570\u20133580. https://doi.org/10.18653/v1/D18-1393\n[23] Richard Forgette and Jonathan S Morris. 2006. High-conflict television news and\npublic opinion. Political Research Quarterly 59, 3 (2006), 447\u2013456.\n[24] Kiran Garimella and Abhilash Datta. 2024. Unraveling the Dynamics of Television\nDebates and Social Media Engagement: Insights from an Indian News Show. In\nProceedings of the International AAAI Conference on Web and Social Media , Vol. 18.\n435\u2013447.\n[25] Bryan T Gervais. 2019. Rousing the partisan combatant: Elite incivility, anger,\nand antideliberative attitudes. Political Psychology 40, 3 (2019), 637\u2013655.\n[26] Regula H\u00e4nggli and Hanspeter Kriesi. 2010. Political framing strategies and\ntheir impact on media framing in a Swiss direct-democratic campaign. Political\ncommunication 27, 2 (2010), 141\u2013157.\n[27] R S C I Indian Readership Survey. 2019. Indian readership survey, 2019. https:\n//mruc.net/uploads/posts/8e428e54a95edcd6e8be593a7021a185.pdf\n[28] Christophe Jaffrelot. 2021. Modi\u2019s India: Hindu nationalism and the rise of ethnic\ndemocracy . Princeton University Press.\n[29] Amaresh Jha and Aman Vats. 2015. Media, Mindset and Mandate: Framing\nAnalysis of Newspaper Coverage of Delhi Assembly Election 2015. AMITY\nJOURNAL OF MEDIA AND COMMUNICATION STUDIES (2015), 107.\n[30] Shima Khanehzar, Andrew Turpin, and Gosia Mikolajczak. 2019. Modeling\npolitical framing across policy issues and contexts. In Proceedings of the The 17th\nAnnual Workshop of the Australasian Language Technology Association . 61\u201366.\n[31] Youngju Kim and Shuhua Zhou. 2020. The effects of political conflict news frame\non political polarization: A social identity approach. International Journal of\nCommunication 14 (2020), 22.\n[32] Jon Kingzette, James N Druckman, Samara Klar, Yanna Krupnikov, Matthew\nLevendusky, and John Barry Ryan. 2021. How affective polarization undermines\nsupport for democratic norms. Public Opinion Quarterly 85, 2 (2021), 663\u2013677.\n[33] Mohit Kumar, Chinmay Narayan, Sudheendra Hangal, and Priyamvada Trivedi.\n2020. LokDhaba: Acquiring, Visualizing and Disseminating Data on Indian\nElections. In Proceedings of the 3rd ACM SIGCAS Conference on Computing and\nSustainable Societies . 243\u2013253.\n[34] Russell Lenth et al .2022. emmeans: Estimated marginal means, aka least-squares\nmeans. R package version 1.7. 2.\n[35] Siyi Liu, Lei Guo, Kate Mays, Margrit Betke, and Derry Tanti Wijaya. 2019.\nDetecting frames in news headlines and its application to analyzing news framing\ntrends surrounding US gun violence. In Proceedings of the 23rd conference on\ncomputational natural language learning (CoNLL) . 504\u2013514.\n[36] Silvia Maj\u00f3-V\u00e1zquez, Subhayan Mukerjee, T Neyazi, and R Nielsen. 2019. Online\naudience engagement with legacy and digital-born news media in the 2019 Indian\nelections. RISJ Factsheet (2019).\n[37] John H McManus. 1994. Market-driven journalism: Let the citizen beware? (No\nTitle) (1994).\n[38] Julia Mendelsohn, Ceren Budak, and David Jurgens. 2021. Modeling Framing in\nImmigration Discourse on Social Media. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies . Association for Computational Linguistics, Online,\n2219\u20132263. https://doi.org/10.18653/v1/2021.naacl-main.179\n[39] Young Min. 2004. News coverage of negative political campaigns: An experiment\nof negative campaign effects on turnout and candidate preference. Harvard\nInternational Journal of Press/Politics 9, 4 (2004), 95\u2013111.\n[40] Ashley Muddiman and Natalie Jomini Stroud. 2017. News values, cognitive\nbiases, and partisan incivility in comment sections. Journal of communication 67,\n4 (2017), 586\u2013609.\n[41] Vipul Mudgal. 2015. Framing the 2014 Elections: The Curious Absence of Devel-\nopment. Television & New Media 16, 4 (2015), 354\u2013360. https://doi.org/10.1177/\n1527476415575907 arXiv:https://doi.org/10.1177/1527476415575907\n[42] Diana C Mutz. 2015. In-your-face politics: The consequences of uncivil media.\nInIn-Your-Face Politics . Princeton University Press.[43] Diana C Mutz and Byron Reeves. 2005. The new videomalaise: Effects of televised\nincivility on political trust. American Political Science Review 99, 1 (2005), 1\u201315.\n[44] Nona Naderi and Graeme Hirst. 2017. Classifying Frames at the Sentence Level\nin News Articles. 536\u2013542. https://doi.org/10.26615/978-954-452-049-6_070\n[45] Taberez Ahmed Neyazi. 2020. Digital propaganda, political bots and polarized\npolitics in India. Asian Journal of Communication 30, 1 (2020), 39\u201357.\n[46] Taberez Ahmed Neyazi, Anup Kumar, and Mohan J Dutta. 2019. Channel comple-\nmentarity or displacement? Theory and evidence from a non-Western election\ncontext. Journal of Broadcasting & Electronic Media 63, 4 (2019), 656\u2013676.\n[47] Taberez A Neyazi and Ralph Schroeder. 2021. Was the 2019 Indian election won\nby digital media? The Communication Review 24, 2 (2021), 87\u2013106.\n[48] Viet-An Nguyen. 2015. Guided probabilistic topic models for agenda-setting and\nframing . Ph. D. Dissertation. University of Maryland, College Park.\n[49] OpenAI. 2024. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL] https://arxiv.\norg/abs/2303.08774\n[50] Joyojeet Pal, Priyank Chandra, Padma Chirumamilla, Vaishnav Kameswaran, An-\ndre Gonawela, Udit Thawani, and Pritika Dasgupta. 2017. Mediatized populisms|\nInnuendo as outreach:@ narendramodi and the use of political irony on Twitter.\nInternational Journal of Communication 11 (2017), 22.\n[51] Joyojeet Pal, Priyank Chandra, and VG Vinod Vydiswaran. 2016. Twitter and the\nrebranding of Narendra Modi. Economic and Political Weekly (2016), 52\u201360.\n[52] Zhongdang Pan and Gerald M Kosicki. 1993. Framing analysis: An approach to\nnews discourse. Political communication 10, 1 (1993), 55\u201375.\n[53] Jason Phang, Thibault F\u00e9vry, and Samuel R Bowman. 2018. Sentence encoders on\nstilts: Supplementary training on intermediate labeled-data tasks. arXiv preprint\narXiv:1811.01088 (2018).\n[54] Margaret Roberts, Brandon Stewart, Dustin Tingley, Christopher Lucas, Jetson\nLeder-Luis, Shana Gadarian, and Bethany Albertson. 2014. Structural Topic\nModels for Open-Ended Survey Responses. American Journal of Political Science\n58 (03 2014). https://doi.org/10.1111/ajps.12103\n[55] Lisa Sanderink. 2020. Shattered frames in global energy governance: Exploring\nfragmented interpretations among renewable energy institutions. Energy research\n& social science 61 (2020), 101355.\n[56] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Dis-\ntilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. CoRR\nabs/1910.01108 (2019). arXiv:1910.01108 http://arxiv.org/abs/1910.01108\n[57] Andreas RT Schuck, Rens Vliegenthart, Hajo G Boomgaarden, Matthijs Elenbaas,\nRachid Azrout, Joost van Spanje, and Claes H De Vreese. 2013. Explaining\ncampaign news coverage: How medium, time, and context explain variation in\nthe media framing of the 2009 European parliamentary elections. Journal of\nPolitical Marketing 12, 1 (2013), 8\u201328.\n[58] Andreas RT Schuck, Rens Vliegenthart, and Claes H De Vreese. 2016. Who\u2019s\nafraid of conflict? The mobilizing effect of conflict framing in campaign news.\nBritish Journal of Political Science 46, 1 (2016), 177\u2013194.\n[59] Holli A Semetko and Patti M Valkenburg. 2000. Framing European politics: A\ncontent analysis of press and television news. Journal of communication 50, 2\n(2000), 93\u2013109.\n[60] Anirban Sen, Debanjan Ghatak, Gurjeet Khanuja, Kumari Rekha, Mehak Gupta,\nSanket Dhakate, Kartikeya Sharma, and Aaditeshwar Seth. 2022. Analysis of me-\ndia bias in policy discourse in india. In Proceedings of the 5th ACM SIGCAS/SIGCHI\nConference on Computing and Sustainable Societies . 57\u201377.\n[61] Emma van der Goot, Sanne Kruikemeier, Jeroen de Ridder, and Rens Vliegenthart.\n2024. Online and offline battles: Usage of different political conflict frames. The\nInternational Journal of Press/Politics 29, 1 (2024), 26\u201346.\n[62] Toni GLA Van der Meer, Anne C Kroon, Piet Verhoeven, and Jeroen Jonkman.\n2019. Mediatization and the disproportionate attention to negative news: The\ncase of airplane crashes. Journalism Studies 20, 6 (2019), 783\u2013803.\n[63] Dave Van Zandt. 2024. Media Bias/Fact Check News. https://mediabiasfactcheck.\ncom/\n[64] Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q Weinberger, and Yoav Artzi.\n2020. Revisiting few-sample BERT fine-tuning. arXiv preprint arXiv:2006.05987\n(2020).\nA Keywords used for filtering articles\nThe keywords used to filter for articles and decide whether a given\narticle was election-based or not are as follows:\nCampaign, rally, campaigning, rallying, Poll, poll, polling, Election,\nelection, Voting, votes, vote, voter, EC, EVM, EVMs, Manifesto, Lok\nSabha, Parliamentary, electoral, lok-sabha, INC, Congress, BJP, TDP,\nBharatiya Janata Party, Telugu Desam Party, YSRCP, TMC, Trinamool\nCongress, TRS, Telangana Rashtra Samithi, BSP, Bahujan Samaj Party,\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA Chebrolu et al.\nSP, Samajwadi Party, AAP, Aam Aadmi Party, NCP, Nationalist Con-\ngress Party, DMK, Dravida Munnetra Kazhagam, AIADMK, All India\nAnna Dravida Munnetra Kazhagam, Biju Janata Dal, BJD .\nB Translation prompt\nThe following prompt was used to translate speeches from Hindi\nto English:\nGiven some content in Hindi, translate it\nto English while retaining the original\nmeaning.\nReturn the translated content. If\nthere is English content in the input,\nkeep the English content as is.\nThe output should be in the\nfollowing format:\n{\n'translated_content ':\n'Translated content here '\n}\nTranslate the following Hindi content\nto English:\nC Identifying parties from record\nWe curated a dataset containing an entry of popular politicians of each party\nand the acronym used to refer to the party. We enhanced this list by including\nalternate names for prominent politicians, such as Maya (Mayawati) and\nNaMo (Narendra Modi), to improve matching accuracy. We then sort the\nentries based on length and start matching from the largest entry to the\nsmallest entry, replacing each time an exact match has been found. This\naccounts for the fact that sometimes the keywords may be nested, and just\nan exact match could be erroneous. Table 5 shows a sample of the parties\ndataset. A pictorial example can be seen in Figure 3.\nTable 5: A sample of the parties dataset used to identify the\npolitical parties mentioned in a news headline.\nINC BJP\nPriyanka Gandhi Narendra Modi\nRahul Gandhi Varun Gandhi\nSonia Gandhi Amit Shah\nGandhi Modi\nFigure 3: An example of how parties are extracted for a par-\nticular article.D Keywords used for rallies\nThe full list of speech event terms used to identify rallies:\nspeech, address, talk, oration, lecture, presentation, discourse, monologue, ser-\nmon, declaration, statement, pronouncement, elocution, rally, event, assembly,\ngathering, meeting, convocation, conclave, conference, convention, congrega-\ntion, protest, demonstration, parade, march, road show, roadshow, campaign\nE Masking parties and politicians\nWe also ran experiments to check if the classifier is robust in understand-\ning the context properly surrounding conflict frames and if masking the\npoliticians (with <PERSON> ) and party (with <PARTY> ) changes the metrics.\nNo discernible deviations were observed in the metrics, suggesting that\nmasking does not significantly impact the classifier\u2019s outcomes. Table 6 pro-\nvides an overview of the performance metrics associated with this masked\napproach.\nTable 6: Performance Metrics for a classifier trained to predict\nframes with a masked dataset.\nPrecision Recall F1-Score\nConflict 0.86 0.92 0.89\nNon-Conflict 0.84 0.73 0.77\nMacro average 0.85 0.82 0.83\nF Hyperparameters\nOur hyperparameter search was completed using a random selection method.\nOur objective was to maximize the average macro average F1-score. In this\nexperiment, we adjusted several parameters. For class weights related to\nconflict and non-conflict classes, we applied a uniform distribution ranging\nfrom 1 to 10. The learning rate was set with a uniform distribution between\n1\u00d710\u22126and 1\u00d710\u22123, while the number of epochs followed an integer\nuniform distribution from 1 to 20. The final hyperparameters can be seen\nin table 7.\nTable 7: Hyperparameters for the classifier used to identify\nframes from election-related news headlines.\nHyperparameter Value\nConflict Class Weight 1.69\nNon-Conflict Class Weight 9.01\nLearning Rate 6.008\u00d710\u22125\nEpochs 9\nG Identification of aggressors and targets\nThe attached prompt (below) was used to identify the aggressor(s) and\ntarget(s) from a conflict-frame headline.\nTable 8: Metrics for the identification of aggressors and tar-\ngets from a headline.\nClass Precision Recall F1-Score\nAggressor 0.99 1.0 0.995\nTarget 0.98 1.0 0.99\nOverall 0.985 1.0 0.993\nThe classification report for the identification of aggressors and targets\ncan be seen in table 8. A true positive is a headline for which the aggressor\nFraming the Fray:\nConflict Framing in Indian Election News Coverage Websci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA\nis identified correctly. A false negative is a headline for which the aggressor\nis not identified. A false positive is a headline for which the aggressor is\nidentified incorrectly. The same definitions were used for identifying the\nmetrics for the target.\nGiven a set of headlines, identify the\nspeaker/subject (some political entity\n/ entities) and the target/object (some,\nmaybe different or similar political\nentity / entities) for each headline.\nI will give you a few examples and\nthe example output format. You\ncan use this format to provide\nthe output for the headlines\nI give you.\nThe output format is:\n{\n\"headline\": \"headline text\",\n\"speaker\": [list of political entities],\n\"target\": [list of political entities]},\n...\n}\nIf there is no speaker or target, you can\nleave the list empty.\nSome examples:\nHeadline 1: 10% quota to Economically\nWeaker: It\u2019s too late, Modi should\nhave done it in 2014, says state\nCongress leader\nSpeaker: Congress\nTarget: Modi\nOutput:\n{\n\"headline\": \"10% quota to Economically\nWeaker: It\u2019s too late, Modi should\nhave done it in 2014, says state\nCongress leader\",\n\"speaker\": [\"Congress\"],\n\"target\": [\"Modi\"]\n}\nHeadline 2: Narendra Modi must apologise\nfor 'liquor 'slur: Congress\nSpeaker: Congress\nTarget: Narendra Modi\nOutput:\n{\n\"headline\": \"Narendra Modi must\napologise for 'liquor 'slur: Congress\",\n\"speaker\": [\"Congress\"],\n\"target\": [\"Narendra Modi\"]\n}\nHeadline 3: Maharashtra: Congress,\nNCP call Governor \u2018pro-RSS\u2019,\nboycott address\nSpeaker: [\"Congress\", \"NCP\"]\nTarget: RSS\nOutput:\n{\n\"headline\": \"Maharashtra: Congress,\nNCP call Governor \u2018pro-RSS\u2019,boycott address\",\n\"speaker\": [\"Congress\", \"NCP\"],\n\"target\": [\"RSS\"]\n}\nIn this case, notice the multiple\nspeakers and the target is an indirect\nentity (RSS). Return the same format\nfor all the headlines given below.\nNow, here are the headlines:\nH (Over)emphasizing conflict frames\nTable 9 shows the number of mentions of each issue and the proportion of\nmatched articles mentioning the issue. Note, that there were no occurrences\nof any speeches mentioning the Ram Mandir. This could potentially be\nattributed to the limited number of keywords identified for that particular\nissue.\nTable 9: For each issue: Total speech count and percentage of\nspeeches addressing the issue\nIssue Occurrences Proportion\nOpposition 126 0.88\nEconomic Growth 122 0.38\nCorruption 49 0.37\nFarmers Issues 76 0.32\nReservation 52 0.30\nPoverty 92 0.28\nIndustrialisation 79 0.22\nTerrorism 77 0.17\nUnemployment 50 0.15\nHighways / Roads 99 0.12\nEducation 92 0.09\nHealthcare 89 0.09\nCAA/NRC 8 0.08\nInflation 55 0.05\nWater 71 0.04\nElectricity 106 0.04\nWomen\u2019s Safety 31 0.01\nCow Protection 2 0.00\nRam Mandir \u2013 0.00\nI Keywords for issues\nThe keywords used to match speeches to articles for the issues are seen in\nTable 10. Note, there is no entry for the issue Opposition because the party\nmatching algorithm was used to detect the presence of an opposition party.\nJ Confidence intervals and proportion\npercentages for coalitions as aggressors and\ntargets\nWe print the confidence intervals of headlines with the coalition as the\naggressor in Table 11 and the confidence intervals with the coalition as the\ntarget in Table 12.\nWebsci \u201925, May 20\u201324, 2025, New Brunswick, NJ, USA Chebrolu et al.\nTable 10: The list of issues and corresponding keywords used to identify these issues.\nIssue Keywords\nCorruption bail, black, bribe, cbi, chor, conspiraci, corrupt, croni, demonet, demonetis, expos, helicopt, investig, jail, jumla, lokpal,\nloot, nirav, pocket, probe, prosecut, rafal, raid, scam, scandal, steal, theft, thief\nInflation inflat, loan\nUnemployment employ, job, labor, labour, mgnrega, unemploy\nEconomic Growth econom, economi, export, gdp, global, grow, growth, gst, job, money, prosper, scheme\nFarmers Issues agrarian, agricultur, crop, farm, farmer, field, irrig, kisan, msp, price, seed, sugarcane\nWater drink, drought, flood, irrig, pollut, river, water\nHighways / Roads airport, buse, highway, road, traffic\nElectricity electr\nEducation aiim, colleg, educ, iit, scientist, student, teacher, univers\nPoverty basic, poor, poorest, poverti, rural\nWomen\u2019s Safety beti, girl, rape\nTerrorism airstrik, blast, milit, pulwama, terrorist, uri\nCow Protection cow, slaughter\nRam Mandir ayodhya, masjid\nReservation adivasi, ambedkar, bhim, cast, casteism, class, dalit, discrimin, jat, obc, quota, section, tribal, tribe, upper\nIndustrialisation built, factori, forest, industri, invest, manufactur, project, sector, trade, trader\nHealthcare ayushman, basic, doctor, health, healthcar, hospit, leprosi, medic, toilet\nCAA/NRC amend, articl, citizenship, migrant, nrc, refuge\nTable 11: Proportion of headlines with coalition as aggressor\nSource Year Coalition Lower Upper Est.\nThe Hindu 2014 UPA .252 .331 .292\nNDA .303 .386 .345\n2019 UPA .307 .372 .340\nNDA .257 .320 .289\nNDTV 2014 UPA .310 .382 .346\nNDA .324 .397 .361\n2019 UPA .325 .378 .352\nNDA .351 .406 .379\nThe Indian Express 2014 UPA .333 .399 .366\nNDA .318 .383 .351\n2019 UPA .335 .383 .359\nNDA .319 .367 .343\nThe Times of India 2014 UPA .285 .361 .323\nNDA .287 .363 .325\n2019 UPA .321 .381 .351\nNDA .303 .362 .333\nIndia Today 2014 UPA .294 .369 .332\nNDA .279 .352 .316\n2019 UPA .329 .382 .356\nNDA .317 .371 .344\nZee News 2014 UPA .183 .359 .271\nNDA .281 .466 .374\n2019 UPA .281 .331 .306\nNDA .367 .420 .394\nRepublic World 2019 UPA .273 .338 .306\nNDA .337 .405 .371Table 12: Proportion of headlines with coalition as target\nSource Year Coalition Lower Upper Est.\nThe Hindu 2014 UPA .337 .422 .380\nNDA .445 .532 .489\n2019 UPA .290 .354 .322\nNDA .485 .553 .519\nNDTV 2014 UPA .369 .443 .406\nNDA .490 .566 .528\n2019 UPA .369 .424 .397\nNDA .444 .500 .472\nThe Indian Express 2014 UPA .347 .413 .380\nNDA .468 .536 .502\n2019 UPA .322 .370 .346\nNDA .484 .535 .510\nThe Times of India 2014 UPA .305 .381 .343\nNDA .464 .544 .504\n2019 UPA .346 .407 .377\nNDA .431 .493 .462\nIndia Today 2014 UPA .327 .403 .365\nNDA .517 .595 .556\n2019 UPA .328 .382 .355\nNDA .518 .574 .546\nZee News 2014 UPA .378 .573 .476\nNDA .359 .554 .457\n2019 UPA .330 .382 .356\nNDA .474 .529 .502\nRepublic World 2019 UPA .446 .517 .482\nNDA .410 .480 .445", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Framing the Fray: Conflict Framing in Indian Election News Coverage", "author": ["T Chebrolu", "R Modepalle", "NH Vardhan"], "pub_year": "2025", "venue": "Proceedings of the 17th \u2026", "abstract": "In covering elections, journalists often use conflict frames which depict events and issues as  adversarial, often highlighting confrontations between opposing parties. Although conflict"}, "filled": false, "gsrank": 794, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3717867.3717900", "author_id": ["", "", "vL4sjtMAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:sHAByMCNfG8J:scholar.google.com/&output=cite&scirp=793&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D790%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=sHAByMCNfG8J&ei=lrWsaPi1IL_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:sHAByMCNfG8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ashwinrajadesingan.com/assets/pdf/2025_websci_framing.pdf"}}, {"title": "1 \u201cSerious queries\u201d and \u201ceditorial epistemologies\u201d", "year": "NA", "pdf_data": "Rogers (ed.) The Propagation of Misinformation in Social MediaThe Propagation  \nof Misinformation  \nin Social Media A Cross-\nplatform \nAnalysis\nEdited  \nby Richard Ro\ngers\nThe Propagation of Misinformation in Social Media\n\nThe Propagation of Misinformation \nin\u00a0Social Media\nA Cross-platform Analysis\nEdited by Richard Rogers\nAmsterdam University Press\nThe publication of this book is made possible by grants from First Draft and SoBigData++ \nwhich received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement nr. 871042.\nCover illustration: Kurt Schwitters, Merz #1, 1920.\nCover design: Co\u00f6rdesign, Leiden\nLay-out: Crius Group, Hulshout\nisbn\n 9\n78 94 6372 076 2\ne-isbn  9\n78 90 4855 424 9\ndoi \n10.5117/9789463720762\nnur  \n670\nCreative Commons License CC BY NC ND (http://creativecommons.org/licenses/by-nc-nd/4.0)\n\u00a0All authors / Amsterdam University Press B.V., Amsterdam 2023\nSome rights reserved. Without limiting the rights under copyright reserved above, any part of \nthis book may be reproduced, stored in or introduced into a retrieval system, or transmitted, in any form or by any means (electronic, mechanical, photocopying, recording or otherwise).\nEvery effort has been made to obtain permission to use all copyrighted illustrations \nreproduced in this book. Nonetheless, whosoever believes to have rights to this material is advised to contact the publisher.\n T able of Contents\nPreface   7\n1 \u201c Serious queries\u201d and \u201ceditorial epistemologies\u201d   9\nHow social media are contending with misinformation\nRichard Rogers\n2 P roblematic information in Google Web Search?   33\nScrutinizing the results from U.S. election-related queries\nGuillen Torres\n3 T he scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified   47\nRichard Rogers\n4 W hen misinformation migrates   67\nCross-platform posting, YouTube and the deep vernacular web\nAnthony Glyn Burton\n5 F ringe players on political Twitter   83\nSource-sharing dynamics, partisanship and problematic actors\nMaarten Groen and Marloes Geboers\n6 T witter as accidental authority   109\nHow a platform assumed an adjudicative role during the COVID-19 \npandemic\nEmillie de Keulenaar, Ivan Kisjes, Rory Smith, Carina Albrecht and Eleonora Cappuccio\n7 T he earnest platform   139\nU.S. presidential candidates, COVID-19, and social issues on Instagram\nSabine Niederer and Gabriele Colombo\n8 A f ringe mainstreamed, or tracing antagonistic slang between \n4chan and Breitbart before and after Trump\n  165\nStijn Peeters, Tom Willaert, Marc Tuters, Katrien Beuls, Paul Van Eecke and Jeroen Van Soest\n9 P olitical TikTok   187\nPlayful performance, ambivalent critique and event-commentary\nNatalia S\u00e1nchez-Querub\u00edn, Shuaishuai Wang, Briar Dickey and \nAndrea Benedetti\nAfterword: The misinformation problem and the deplatforming \ndebates   207\nBibliography   213\nIndex   237\n Preface\nThis book is a product of a collaboration of media researchers at the University \nof Amsterdam, working together with colleagues in Belgium, Canada, Italy, \nthe U.K. and the U.S. and supported by First Draft, the journalist training \nnetwork concerned with misinformation. As a group we set out to study \nthe \u201cmisinformation problem\u201d in the areas where social media platforms \nwere seemingly working with great ardor to address it: elections and the \npandemic. How are they contending with misinformation in the areas that \nhave their special focus, some years on from the seminal \u201cfake news\u201d crisis? \nIn preliminary work we had found that platforms such as Facebook appeared \nactive in retarding the spread of extreme viewpoints and sources that directly \nrelated to elections and the pandemic but less successful in immediately \nadjacent areas such as election-related social issues and vaccines.\nWhat have platform efforts to curb the misinformation problem yielded? \nThe findings we report here are both generalizable as well as platform-\nspecific, which are the two sides of our cross-platform analysis. Generally, \nsocial media platforms are mainstreaming the fringe and marginalizing the \nmainstream. As others have found, extreme viewpoints and sources, particu -\nlarly from one side of the political spectrum, are receiving disproportionate \nengagement compared to other sources. But we made the additional, broad \nobservation that even in issue areas deemed serious\u2014elections and the pan -\ndemic\u2014mainstream media are less referenced or otherwise marginalized.\nMore specifically, the manner in which the platforms decenter the \nmainstream differs. Twitter, for example, has high percentages of \u201chyper -\npartisan\u201d sources present in tweets concerning politics, and while not in \nthe majority, many of Facebook\u2019s most engaged-with sources would be \nclassified as \u201cfake news,\u201d if one deploys the original definition by Craig \nSilverman in the seminal 2016 Buzzfeed News  article ushering in the term. \nWhere other platforms are concerned, Instagram users prefer influencers \nover experts, and rely on their social responsibility in debunking falsehoods. \nTikTok users parody mainstream media, and Reddit and 4chan (at least \ntheir leading forums and boards) dismiss it and send users to alternative \ninfluence networks and YouTube videos with extreme cultural commentary. \nGoogle Web Search, whose results for political queries we also studied, \nreturns more quality than alternative media but the presence of these \nsources decline as the election nears, owing to the preponderance of what \nthe researchers call special interest sites. Incidentally, we also found that \nin election-related Google returns the sources are politically imbalanced.\n8 T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nAs I note in the opening chapter, the social media platforms have \nintroduced \u201ceditorial epistemologies\u201d for elections and the pandemic, \nauthoring lists of authoritative sources that appear when one queries core \nelection-related or pandemic-related keywords or making other manual \ninterventions beyond commercial content moderation, the outsourced, \nlow-wage work of removing offensive content. They also have had to assume \nthe role of \u201caccidental authorities,\u201d developing rapidly evolving source and \ninformation adjudication policy that at the same time invites backlash for \nheavy-handedness as well as competition from \u201calt-tech\u201d platforms that \nmoderate with a lighter touch. The extent of the platforms\u2019 editing, and \nparticularly where it ends, is on display in each of the studies.\nEach of the chapters benefits from techniques developed to capture the \ndata necessary to exhibit the current state of the misinformation problem. \nSome rely on platform-supplied data (Twitter, Instagram), another on a \nrepurposed marketing data dashboard (Facebook) and others on scraping \n(Google Web Search, Reddit, 4chan, TikTok). There is also a study that uses \none platform (4chan) to analyze another (YouTube), given the copious \nreferencing of YouTube videos by \u201calternative influencers\u201d and later to \nvernacular newcomers. Many of the studies also classify sources as main -\nstream or alternative (to varying degrees) as well as evincing a political bent, \nrelying on (and triangulating) external classification schemes developed \nby journalists and other media analysts.\nThe platform studies were undertaken twice (and on occasion three \ntimes), first in the early run-up to the U.S. presidential elections and the \npandemic (March, 2020) and again after the elections and deeper into the \npandemic (January, 2021 and/or March, 2021). One of the Twitter studies \ntakes advantage of the data spanning the Capitol riots of January\u00a06, 2021 in \nWashington, DC, allowing for the analysis of how the platform\u2019s subsequent \npurge of accounts had an impact on the quality of the sources encountered.\nThe studies have been written up in the format of the Harvard Kennedy \nSchool Misinformation Review , where earlier versions of the Facebook and \n4chan/Reddit chapters were published. It is a format that leads with the \nresearch questions and is followed by an essay summary, the implications \nand the findings. The methods section comes last. To us the format highlights \nthe relevance of the work to journalists and thus also serves well the col -\nlaboration with First Draft.\nRichard Rogers\nNovember, 2022\n1 \u201c Serious queries\u201d and \u201ceditorial \nepistemologies\u201d\nHow social media are contending with misinformation\nRichard Rogers\nAbstract\nThe following concerns the \u201cmisinformation problem\u201d on social media \nduring the run-up to the 2020 U.S. presidential election. Employing data \njournalism techniques, it develops a form of cross-platform analysis that \nis attuned to both commensurability as well as platform specificity. It \nanalyses the top-ranked political content on seven platforms and finds that \neach marginalizes mainstream media and mainstreams the fringe. TikTok \nparodies mainstream media, while 4chan and Reddit dismiss it and direct \nusers to alternative influence networks and extreme YouTube content. \nTwitter prefers the hyperpartisan over it. Facebook\u2019s \u201cfake news\u201d problem \nconcerns declining amounts of mainstream media referenced. Instagram \nhas influencers dominating user engagement. By comparison, Google Web \nSearch buoys special interest sites. It concludes with a discussion of how \nplatforms filter the content through increasing editorial intervention.\nKeywords: Problematic information, content moderation, cross-platform \nanalysis, platform criticism, fringe media\nIntroduction: The politics of problematic information and its \ncross-platform study\nWhile scholars of hearsay, rumor and conspiracism would point to the history \nof its staying power (Olmsted, 2009), the spread of misinformation and other \nproblematic information is said to be \u201csupercharged\u201d by contemporary \nsocial media (Bounegru et al., 2018; Daniels, 2018). The following examines \nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch01\n10 T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nthat thesis through an analysis of the current state of what globally could \nbe called the \u201cmisinformation problem\u201d (Allcott et al., 2019) across seven \nonline platforms: TikTok, 4chan, Reddit, Twitter, Facebook, Instagram \nand Google Web Search. The part played by YouTube is viewed by way \nof the videos referenced on 4chan. The case in question is the political \ninformation environment in the run-up to the U.S. presidential elections, \nor what may be dubbed U.S.-based, \u201cpolitical Facebook,\u201d \u201cpolitical Twitter,\u201d \n\u201cpolitical Instagram,\u201d etc. Borrowing a technique from data journalism, \nand examining the most interacted-with content around the candidates, \npolitical parties and election-related issues, the work reported here found \nthat stricter definitions of misinformation (imposter sites, pseudo-science, \nconspiracy, extremism only) lessen the scale of the problem, while roomier \nones (adding \u201chyperpartisan\u201d and \u201cjunk\u201d sites serving clickbait) increase it, \nalbeit rarely to the point where it outperforms mainstream media.\nThe misinformation problem differs per platform. On such youthful \nplatforms as TikTok and to a lesser extent Instagram, misinformation may \nbe delivered sarcastically or insincerely, making it difficult to characterize \nintent (Phillips and Milner, 2017). On the masked or anonymized political \nboards and communities of 4chan and Reddit, problematic sources are \nnot as copiously referenced as mainstream ones, but that finding does not \nmean to suggest the absence of a problem, as the most referenced collection \nof sources (on 4chan) are extreme YouTube videos, many of which end up \nbeing deleted from the platform. The users of mainstream social media as Twitter and Facebook continue to point in great proportions to hyperpar -\ntisan sources, originally defined as \u201copenly ideological web operations\u201d \n(Herrman, 2016). Political spaces on Instagram, however, were found to \nbe the \u201ccleanest,\u201d where most election-related content is non-divisive and \nearnestly posted, and influencers, with some exceptions, were found to be \nresponsible information providers, debunking rather than spreading 5G \ncoronavirus conspiracy theories.\nThe research provides a technique for \u201ccross-platform analysis,\u201d or the \nexamination of a single phenomenon (through engagement analysis) across a \nvariety of social media. It thereby addresses critiques of \u201csingle platform studies,\u201d \nwhere societal trends or phenomena are seen through one social media lens \nwithout the benefit of a comparative perspective that would furnish a baseline \n(Rogers, 2019). Engagement analysis of a single subject matter (election-related \ninformation, in this case) is considered one robust cross-platform approach \nsince it captures each platform\u2019s top content, which refers to the posts or web \nURLs that receive the most interactions (directly or indirectly). It has the \nbenefit of being more global in its outlook compared to other cross-platform \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 11\napproaches that rely on seeking one or more digital objects shared across \nplatforms (e.g., a hyperlink) and comparing resonance (Rogers, 2017).\nBut the cross-platform approach put forward here is not blind to platform \nspecificities. It seeks to account for differing platform metrics, vernaculars \nof use and user subcultures. Accounting for this \u201cmedium specificity\u201d is \nperformed in at least three ways. The first is that engagement is measured \ndistinctively per platform, as discussed in some detail below. Second, social \nmedia manipulation (such as artificially amplifying misinformation so \nthat it appears to be engaged-with content) also differs per platform. One is \ninterested in fake followers on Instagram and bots on Twitter, for example. \nBeing attuned to platform vernaculars, finally, rests on the study of cultures \nof use. For example, certain sound effects or facial gestures on TikTok suggest \ndisbelief or mistrust. In all, commensurability thereby relies on both the \ncross-platform study of engagement as well as individual platform analyses \nimbued with a medium-specific approach.\nIn the following I first introduce the current misinformation problem \nonline as bearing some resemblance to the quality of information debates \nfrom early web history. The contemporary concerns, however, flow from the \n\u201cfake news\u201d crisis of 2016, together with the continual study of the extent \nto which the platforms have addressed the issue (and how they have done \nso). Moreover, these debates have not escaped the politicization of \u201cbig \ntech\u201d and its supposed \u201cliberal bias\u201d (Vaidhyanathan, 2019), a claim that is \nalso a source of empirical study in the Google Web Search analysis below.\nIndeed, designating certain information as problematic may be political \n(and increasingly politicized), because, as others before us also have found \n(Benkler et al., 2018; Rogers and Hagen, 2020), it is more prevalent on the \nright side of the political spectrum, as are problematic or \u201cinauthentic\u201d \nusers, though they are not alone there. Making a case for balancing the \npartisanship of sources outputted by social media and search engines \n(rather than serving filter bubbles through personalization, for example) is \namong the emerging source adjudication methods under consideration, as \nI will discuss. The piece concludes with a discussion of source criticism on \nsocial media, including the recent rise of \u201ceditorial epistemologies\u201d alongside \ncrowdsourced ones associated with the (early) web.\nUncertainty online renewed\nThe web historically has been thought of as a space for the unsubstanti -\nated, authored by rumormongers, conspiracy theorists and all manner of \n12 r ichard rog erS \nself-publishers and fringe contributors. Indeed, one could argue, as it was put \nin 1994, that on the web \u201cthe eminent and the crackpot\u201d stand side-by-side, \na feature once celebrated as a productive collision (Rheingold, 1994; Rogers, \n2004). Indeed, in early internet studies, next to the blurring of the real and \nthe virtual, conspiracy theory in particular but also the production and \ncirculation of rumor were subjects of study, before notions as the \u201cwisdom \nof the crowd\u201d and projects as Wikipedia appeared to place the web on a less \nshaky epistemological footing (Dean, 1998; Shirky, 2008). Arguably, social \nmedia have put paid to that brief period of relative stability. Conspiracists or \nat least those who discuss such phenomena as the link between 5G and the \ncoronavirus are among some of the high-profile influencers or microcelebrities \nfound there (Bruns et al., 2020).1 In turn, scholars now write, as they did two \ndecades earlier, that the internet is \u201cmainstreaming the fringe\u201d (Barkun, 2016).\nThe recent uptick in attention to the study of problematic content online \ncould be attributed as well to the \u201cfake news crisis\u201d of 2016, where it was \nfound that so-called fake news outperformed mainstream news on Face -\nbook in the run-up to the U.S. presidential elections that year (Silverman, 2016). That finding also set in motion the subsequent struggle around the \noccupation of the term from a type of news originating from imposter \nmedia organizations or other dubious sources to a \u201cpopulist\u201d charge against \nmainstream and \u201celite\u201d media that seeks to delegitimate sources found \npublishing inconvenient or displeasing stories (van der Linden et al., 2020).\nIn its recent study we have had calls to cease using the term, fake news \n(Pepp et al., 2019). There also has been a series of classification moves. \nBoth the expansion as well as contraction of the notion may be seen in its \nreconceptualization by scholars as well as by the platforms themselves \n(Venturini, 2019). The definitional evolution is embodied in such phrasings \nas \u201cjunk news\u201d and \u201cproblematic information,\u201d which are broader in their \nclassification, while the platforms appear to prefer terms such as \u201cfalse\u201d \n(Facebook), which is narrower (Rogers, 2020a).\nOn the back end the platform companies also develop responses to these \nactivities. They would like to automate as well as outsource its detection \nand policing, be it through low-wage, outsourced content moderators, \n(volunteer) fact-checking outfits or user-centered collaborative filtering \nsuch as Twitter\u2019s \u201cbirdwatchers,\u201d an initiative they say born of societal \ndistaste for a central decision-making authority, as found through qualitative \ninterviews (Gillespie, 2018; Roberts, 2019; Coleman, 2021). They also take \nmajor decisions to label content by world leaders (and indeed have world \n1 5 G is the \u201cfifth generation\u201d technology standard for mobile phone networks.\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 13\nleader content policies), which subsequently land platform governance and \ndecision-making in the spotlight (Twitter, 2019).\nMore broadly there has been a rise in the study of \u201ccomputational \npropaganda\u201d and \u201cartificial amplification\u201d which the platforms refer to \nas \u201cinauthentic behavior\u201d (Woolley and Howard, 2016; Colombo and De \nGaetano, 2020). These may take the form of bots or trolls; they may be \n\u201ccoordinated\u201d by \u201ctroll armies,\u201d which has been outlined in Facebook\u2019s \nregular \u201ccoordinated inauthentic behavior reports\u201d (Facebook, 2021a). As its \nhead of security policy puts it, Facebook defines it (in a plain speak manner) \nas \u201cpeople or pages working together to mislead others about who they are \nor what they are doing\u201d (Facebook, 2018). Occasionally datasets become \navailable (by Twitter or other researchers) that purport to be collections of \ntweets by these inauthentic, coordinated campaigners, whereupon scholars \n(among other efforts) seek to make sense of which signals can be employed \nto detect them (Roeder, 2018).\nOther types of individuals online have caught the attention of the plat -\nforms as \u201cdangerous\u201d (Facebook), and have been deplatformed, a somewhat \ndrastic step that follows (repeated) violations of platform rules and presum -\nably temporary suspensions (Rogers, 2020b). \u201cDemonetization\u201d also is among \nthe platforms\u2019 repertoire of actions, should these individuals, such as extreme \ninternet celebrities, be turning vitriol into revenue, though there is also \nthe question of which advertisers attach themselves (knowingly or not) to \nsuch content (Wilkinson and Berry, 2020). Moreover, there are questions \nabout why certain channels have been demonetized for being \u201cextremist.\u201d \nOthers ask, is \u201ccounter-speech\u201d an alternative to counter-action (Bartlett \nand Krasodomski-Jones, 2015; Gagliardone, 2019)?\nOn the interface, where the metrics are concerned, there may be fol -\nlower factories behind high follower and like counts (Lindquist, 2019). The \nmarketing industry dedicated to social listening as well as computational \nresearchers have arrived at a series of rules of thumb as well as signal \nprocessing that aid in the flagging or detection of the inauthentic. Just as \nsudden rises in follower counts might indicate bought followers, a sudden \ndecline suggests a platform \u201cpurge\u201d of them (Confessore et al., 2018). Perhaps \nmore expensive followers gradually populate an account, making it appear \nnatural. Indeed, there is the question of which kinds of (purchased) followers \nare \u201cgood enough\u201d to count and be counted. What is the minimum amount \nof grooming? Can it be automated, or is there always some human touch? \nFinally, there is a hierarchy in the industry, where Instagram followers \nare the most sought after, but \u201cinfluencers\u201d (who market wares there) are \noften contractually bound to promise that they have not \u201cparticipated in \n14 r ichard rog erS \ncomment pods (group \u2018liking\u2019 pacts), botting (automated interactions), or \npurchasing fake followers\u201d (Ellis, 2019).\nHaving touched upon the current state of uncertainty online, I would \nlike to turn to how problematic information manifests itself in social media \nplatforms around specific social issues as well as election-related keywords. \nThe following recounts a cross-platform analysis into the \u201cmisinformation \nproblem\u201d in the run-up to the 2020 U.S. presidential election. As noted above, \nthe overall approach is to study most engaged-with content with a sensitivity \nto platform metrics, vernaculars of use and user subcultures. It relates a \nset of empirical studies that enquire into the extent to which platforms are \nagain mainstreaming the fringe, examining more specifically those spaces \nconjured through \u201cserious queries\u201d that contain election-related as well \nas COVID-19 information. When querying political hashtags, candidate \nand party names as well as issues, and sifting through the content most \ninteracted with on the platforms, how do more mainstream sources fare \nin comparison to those characterized as problematic? More to the point, \nis social media marginalizing the mainstream?\nHere I take the most salient findings per platform in turn, before conclud -\ning with a discussion of the emergence of editorial epistemologies put into \nuse by social media platforms as well as search engines. Editorial source \nadjudication is a remarkable transformation in how these platforms sift \nand filter sources, indicating an exceptional information state, a point \nupon which I conclude.\nTikTok: Instilling doubt in mainstream accounts\nTikTok is not usually considered a site for political encounter, but recently \nthe short video sharing platform, used predominantly by youth, has posted \nrules about political content, indicating its growing presence there. It also \nwarns against \u201cmisleading information\u201d and urges users to \u201cverify facts \nusing trusted sources,\u201d suggesting that misinformation could be worthy \nof investigation on the platform (TikTok, 2020). Apart from how to think \nabout TikTok\u2019s place in political discourse, we asked, how do TikTok users \nexpress themselves politically? How may forms of creative expression on \nTikTok manifest themselves as misinformation?\nOn TikTok the most engaged-with videos (returned through platform \nqueries of hashtags) are fresh and topical, which implies that the platform can \nbe regarded as an event-commentary medium, where users may encounter \npolitical \u201cnews\u201d first through its parody. Political parody in media has a long \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 15\nhistory, though here the argument is that rather than specialized magazines \nsuch as Punch , the British weekly satirical magazine (1841\u20132002), or The \nOnion , an American one (1988\u2013 ), it is a regular or \u201cmainstream mode\u201d of \nelection engagement for users of the platform.\nHow are they expressing themselves? The singing and dancing users \ndemonstrate a form of civic engagement by making, tagging and uploading \nvideos that are characterized as forms of \u201cplayful political performances\u201d \nas well as \u201cremixing as ambivalent critique.\u201d The playful performances \ninclude \u201cgiving a speech\u201d as well as \u201cstaging an opinion\u201d such as when a \nman speculates that he hears \u201cthank God for Donald Trump\u201d in the song, \nDa Da Da. The remixing of news clips and other video that is typical on \nTikTok satirize candidates, their supporters as well as their viewpoints by \nintroducing sounds that sew mistrust or ridicule, though it is not always clear \nwhether the critique is sincere or ironic, thereby meriting the description \n\u201cambivalent critique\u201d (Philips and Milner, 2017).\nThese sounds are networked objects in the sense that one can select and \nfollow the sound to other videos that have embedded it. The sounds are \noften deployed in analogous manners, meaning that the audio pathway \nwill lead to more remixed videos that satirize the candidates and their \nsupporters, or videos that have stitched into the another with the sound \nin order to comment on it (e.g., by commenting on it or mocking it). For \ninstance, \u201cRide It\u201d by Regard is a viral sound that is often paired with finger \ndancing to relate stories of cultural misunderstanding. TikTokers have used \nit when dealing with accusations of being a Trump supporter, such as \u201cget called racist 24/7\u201d (sound), \u201cget yelled at for presenting facts\u201d (sound), and \n\u201caccused of not respecting women\u201d (sound). The viral sound denotes being \nmisunderstood, eliciting sympathy but also a knowing smile.\nTikTokers employ a range of creative expression such as singing, dancing, \nduet, lip-syncing, mimicking, finger dancing, viral sounds and facial expres -\nsions. Some have specific connotations for TikTok insiders and make for \ntrends. Having queried election related hashtags, such as #trump2020 and \n#biden2020, it was found first that TikTokers make copious use of political \nhashtags, attaching both Trump and Biden-related hashtags to the same \nvideo, thereby striving to maximize the audience and view counts, rather \nthan identify with one candidate or another. In the analysis, the researchers \nundertook a format and content analysis of the top 30 videos per hashtag \nquery, examining which forms of creative expression are used in political videos and where misinformation may be imparted.\nApart from viral sounds, two other forms of creative expression stand out: \nlip-synching and facial expressions. TikTokers match the lip movements of \n16 r ichard rog erS \nthe candidates, often sarcastically, for example when the comedian, Sarah \nCooper, lip-synched Trump\u2019s remarks during a White House briefing on using \nultraviolet light and detergent to thwart the coronavirus (2020). Finally, the \nfacial expression that approximates the doubtful emoji is another creative \nexpression often encountered. In these videos news footage may be cut \ninto the shots, such as multiple clips of Joseph Biden hugging women, with \nthe intention to sew doubt about his fitness for presidential office. Here \nwe found many of the political videos instilling mistrust in news clips \nthrough sarcastic and doubtful facial expressions. Such a finding prompted \nconsideration of adding \u201cinstilling mistrust\u201d as a category of misinformation \ntypes developed by Wardle (2017), which ranges from parody (least intent \nto deceive) through misleading content and false context to fabricated \n(most intent). Alternatively, one could argue that on TikTok all categories \nof misinformation could be hybridized, for TikTokers are employing parody \nwhen simultaneously introducing misleading content, false context or other \nmisinformation types.\n4chan and Reddit: Referencing extreme YouTube content\nUnlike public-facing platforms such as Facebook and Twitter, where users \ncultivate an online self, 4chan and Reddit are so-called masked spaces of \nanonymous users (De Zeeuw and Tuters, 2020). Particularly the board, \n4chan/pol, and the subreddit, r/TheDonald, have been associated with \nelection politics, and especially the 2016 Trump campaign, where support \nfor his candidacy took the form of \u201cthe great meme war,\u201d which comprised \nthe deployment of vernacular language, image macros and other tactical \nmedia to support the candidate\u2019s cause (Donovan, 2019). Previous research \ninto misinformation in 4chan/pol and across Reddit found little reference \nto outwardly problematic sources, such as imposter news sites or (Russian) \ndisinformation, but rather numerous links to extreme videos on YouTube \nthat were later removed (Hagen and Jokubauskait\u0117, 2020). Thus, while not \nnecessarily a space that links to disinformation sources, it is problematic \nfor other reasons.\nHere, in the context of the run-up to the U.S. presidential elections of \n2020, the research enquired into the extent to which U.S.-based political \nboards and forums on 4chan and Reddit share misinformation and \u201cjunk\u201d \ncontent, and more specifically imposter news and other types of \u201cpink slime\u201d \nwebsites, termed as such for the use of low-cost, newspaper-like sites often \npublishing repurposed content (Tarkov, 2012; Bengani, 2019). We also were \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 17\nquestioning the interest these boards and communities might have in what \nhas been termed an \u201calternative influence network,\u201d a group of extreme \nsocial media influencers that \u201cfacilitates radicalization\u201d (Lewis, 2018). The \nresearch employed the so-called \u201cneedle-to-haystack\u201d technique, querying \n4chan/pol and all of Reddit for the URLs of the pink slime websites, and the \u201chaystack-to-needle\u201d technique which queries an expert list of problematic \nsources (hosts) in the same platform datasets (Hagen and Jokubauskait\u0117, 2020).\nThere are two separate sub-studies, one covering the period from \nJanuary\u00a011, 2019 to March\u00a025, 2020 and the second picks up where the first \nended and runs to December\u00a031, 2021. Throughout no pink slime sites were \nencountered, suggesting either their lack of significance (despite returning \nhigh in Google queries) or the media literacy of the users on the boards and \ncommunities (or both). Modest amounts of problematic sources were found \nbut like in previous research copious YouTube links were identified, which \nled to the inquiry into whether YouTubers from the alternative influence \nnetwork are significantly present in those online cultures. The alternative \ninfluence network (AIN) is described here as a set of YouTube channels \nfluctuating between \u201cnews and personality-centric vlogging, spreading \nmisinformation-laden commentary\u201d (Burton and Koehorst, 2020). Indeed, \nin the first period, many of these channels were found between the boards \nand subreddits under study, though their presence was unequally distributed. \n4chan/pol and Reddit are rather different in their media consumption, with \npolitical Reddit preferring to reference videos using the \u201calternative debate \nstyle\u201d and /pol electing more for the \u201ctoxic vox populist\u201d style of single person, \ndirect-to-audience (Tuters and Burton, 2020). Indicating their extreme \nspeech, a significant percentage of the YouTube videos referenced on 4chan \nhas been removed by the platform. In the second period in the run-up to the \nelections, however, the alternative influence network\u2019s presence declined \nsignificantly. It should be noted that in June\u00a02020 Reddit closed r/TheDonald \nas well as other extreme subreddits for breaking platform rules. The decline \nin links to the AIN coincided with the deplatforming as well as the decline \nin \u201cjunk news\u201d referenced in political Reddit. But given the AIN\u2019s decline on \n4chan (where no analogous deplatforming took place) one could speculate \nthat they were no longer considered \u201calternative\u201d for the fringe space.\nTwitter: Hyperpartisan sources in ascendancy\nLike Facebook and to a lesser extent Instagram, Twitter also has been the focus of public attention concerning misinformation around the 2016 U.S. \n18 r ichard rog erS \npresidential elections and beyond. Twitter, rather unlike the other two \nplatforms, has aided researchers in its study through providing curated \ndatasets of Russian and alleged Iranian trolls and influence campaigners, \nor what are referred to as inauthentic users (Gadde and Roth, 2018). Thus, in \nthe study of misinformation on Twitter, there are generally two strands of \nanalysis to consider\u2014problematic content as well as users. During the 2016 \nelection campaigning and running through to at least late 2019, much of that \ncontent and those users, described as \u201csprawling inauthentic operation[s]\u201d \nwere promoting \u201cpro-Trump messages\u201d (Romm and Stanley-Becker, 2019).\nHere we revisit these claims through a study of the content and users on \n\u201cpolitical Twitter\u201d in the early run up to the 2020 U.S. presidential elections \nand its aftermath, where we examine result sets of queries for election-\nrelated hashtags and keywords, together with the users most active in \ndeploying them (Groen and Geboers, this volume). How much problematic \ninformation is present in the most interacted-with content on political \nTwitter? Are problematic users among the most active? Are they generally \nof a particular political persuasion?\nThe content under study are the URLs (hosts) that are referenced in the \ntweets, and the most active users defined as those who tweet the most. In a \nthree-week timeframe prior to and just after Super Tuesday (March, 2020), \nwhen a cluster of election primaries and caucuses were held, in the aftermath \n(December, 2020 / January, 2021) and after the dust had settled on the Capitol \nbuilding riots (March\u00a02021), we compared the hosts found in the tweets to a \nlist of problematic sources curated by combining pre-existing labeling sites, \nincluding Allsides.com, Media Bias/Fact Check, \u201cthe Chart,\u201d and NewsGuard. \nWe also consulted Wikipedia and other news sources mentioning the sources \nin question. With one exception (related to the query DACA, the immigration \nissue), we found little reference to disinformation, imposter news sources, \npseudo-science, conspiracy theory sources or extreme sites. When expanding \nthe definition of problematic information to include hyperpartisan sites, \nhowever, in the first period nearly half would fall into that category, with the \nimplication that social media (or at least a goodly share of users of political \nTwitter) appear to marginalize mainstream sources. Put differently, if we \nwere to employ Craig Silverman\u2019s original definition of \u201cfake news,\u201d it could \nbe said to challenge mainstream sources anew, as it had in the immediate run-up to the 2016 U.S. elections (on Facebook) (2016). In December\u00a02020 / \nJanuary\u00a02021 the proportion of hyperpartisan hosts in the examined tweets \ndecreased slightly, but by March, 2021, after Twitter removed users breaking \nplatform rules (e.g., of glorification of violence) that figure was significantly \nlower, suggesting a \u201cdeplatforming effect.\u201d\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 19\nFor the study of the most active users, we analyzed \u201cauthenticity\u201d with \nthe aid of SparkToro, which employs indicators (abnormal tweeting activity, \nunusual combinations of followers/following, etc.) to make a determination. \nWe also studied user partisanship or side-taking through qualitative profile \nanalysis. Our findings are not dissimilar to others in that there is far more \ninauthenticity in the pro-Trump user base, but we also found that there are \na few flagged users on the other side of the political spectrum, too.\nFacebook: The seminal \u201cfake news\u201d problem persists\nJournalists began calling Facebook the seminal \u201cfake news machine\u201d (Gal -\nlucci, 2016) just after the finding made by Buzzfeed News  that so-called \nfake news was liked and shared more than mainstream news on the social \nmedia platform in the three months prior to 2016 U.S. presidential elections \n(Silverman, 2016). Since then, there has been a steady stream of stories from \nFacebook\u2019s corporate blog concerning both its crackdowns on \u201cinauthentic \ncoordinated behavior,\u201d or influence campaigning, as well as its initiatives to \ncurb misinformation and \u201cfalse news,\u201d which is a narrow definition includ -\ning pseudo-science and conspiracy sites though excluding hyperpartisan \nones (Mosseri, 2017). The measures began in at least April\u00a02017 with among \nother plans to economically disincentivize such sources as the infamous \nMacedonian fake news factory that chose divisive pro-Trump messaging \n(over pro-Sanders\u2019) because it brought in far more revenue (Silverman and \nAlexander, 2016; Tynan, 2016). Has much changed in how well \u201cfake news\u201d is consumed on the platform since 2016?\nA team of researchers and I revisited the original Buzzfeed News  story and \nits data journalism method in order to investigate the state of the \u201cfake news\u201d \nproblem in January\u2013March, 2020 (Rogers, 2020a), which is roughly the first \nof the three timeframes under consideration in the original Buzzfeed News  \npiece entitled, \u201cviral fake election news stories outperformed real news on \nFacebook\u201d (Silverman, 2016). We investigated again in January\u00a02021, looking \ninto the run-up to the election as well as its aftermath, from March\u00a02020 \nuntil the end of December, 2020.\nSilverman defined \u201cfake news\u201d as sources ranging from \u201choax sites [to] \nhyperpartisan blogs\u201d (Silverman, 2016). Akin to his method, we ran election-\nrelated queries in BuzzSumo, the social media research and monitoring \ntool. From the results we compiled a list of sources and characterized them \nwith the aid of a series pre-existing \u201cbias\u201d labeling sites, as in both Twitter \nand Google studies in this volume, so that we had a rough indication of \n20 r ichard rog erS \ntheir quality and partisanship. Sources are categorized as problematic or \nnon-problematic (which more colloquially could be called \u201cmainstream\u201d), \nand those falling into the latter category were subcategorized as (hyper)\npartisan-conservative, (hyper)partisan-progressive or neither of the two, \nagain with the aid of the existing labeling sites. Problematic sources included \nimposter news (and so-called \u201cpink slime\u201d sites), pseudo-science, conspiracy \ntheory and extreme sites, as was done in the Twitter study above (Bengani, \n2019).\nWhen using Silverman\u2019s \u201cfake news\u201d definition (that includes hyperparti -\nsan sites) Facebook\u2019s fake news problem has worsened slightly. In the seven \ntimeframes under study (from March\u00a02019 to December\u00a02020) the proportion \nof engagement of \u201cfake news\u201d to mainstream was on average 1:1.8 compared \nto 1:2.6 in 2016. If, however, we tighten the definition, as Facebook has done, \nto \u201cfalse news\u201d and include in that category only the sources or stories flagged \nas \u201cproblematic\u201d the scale of the problem drops substantially to 1 in 12 on \naverage per quarter. It should be noted that we encountered one imposter \nnews site, which may suggest that they are well targeted by Facebook or \nthat they are not significantly resonating among users.\nNonetheless, in the last period under study in 2016, when Silverman \nfound that \u201cfake news\u201d performed well, imposter sites (as the Denver Guard -\nian) comprised a majority of those most interacted-with. One implication \nof the finding is that efforts to identify imposter sites (and other \u201cpink \nslime\u201d) continue to have value, despite the fact that they are not yet well \nconsumed. Another implication is that if the problem remains of a smaller \nscale, scaled-up fact-checking may continue to find its place amongst \nthe counter-initiatives, rather than only mass content moderation and \nautomation.\nInstagram: Influencers as responsible information sources?\nInstagram had been one of the more understudied and under-appreciated \nsocial media platforms when it came to misinformation. That changed with \nthe release of two major reports on the Russian disinformation campaigning \nsurrounding the 2016 U.S. presidential elections (Howard et al., 2018; DiResta \net al., 2018). In fact, in one study, it was noted that unlike the other social \nmedia platforms Instagram actually saw a rise in disinformation activity in \nthe period just after the elections (Howard et al., 2018). Many of the posts, \nincluding memes, were openly divisive, but others were sarcastic and more \ndifficult to decode with respect to stance or side-taking. As scholars have \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 21\nfound, over the past few years more and more content online could be \ndescribed as equivocal or ambivalent, where the sincerity of the post and \nthe sender is unclear (Phillips and Milner, 2017; Hedrick et al., 2018).\nIn the study of election-related Instagram posts in the early run-up to the \n2020 U.S. presidential elections (January\u2013April, 2020) and in the run-up to \nthe election and its aftermath (September, 2020\u2013January, 2021), we enquired \ninto the amount of divisive and ambivalent posts, compared to non-divisive \nand earnest ones (Colombo and Niederer, this volume). How sarcastic and \n\u201cedgy\u201d are the top election-related posts on Instagram? Does it form the \ndominant mode of political discourse on the platform? We also are interested \nin whether misinformation is spread in this divisive, ambivalent style. To \nbegin to answer these questions, we queried CrowdTangle, Facebook\u2019s \ncontent monitoring tool, for the names of the candidates and select social \nissues (healthcare, gun control, COVID-19 and 5G), and coded the top 50 \nposts for divisiveness (or non-divisiveness) and ambivalence (or earnestness), \nwhereby each post is ultimately given a hybrid label, e.g., divisive-ambivalent. \nWe scrutinized the candidate- or issue-related posts by influencers that had \nparticularly high engagement scores, often at the top of the rankings. We \nalso sought misinformation.\nPerhaps counter-intuitively, we found Instagram to be a rather healthy \nplatform. The vast majority of the top posts concerning the candidates as \nwell as the social issues are earnest and non-divisive. Virtually no posts \nwere found to be divisive and ambivalent. Indeed, most posts were sincere \nexpressions of support. Of the few divisive posts which the coders addition -\nally found to be earnest, half were by Donald Trump or Donald Trump, Jr., \nand most of the rest concern Trump or gun control. Apart from a few posts \npushing a conspiracy theory surrounding 5G and COVID-19 (including \none post that ranked second in engagement), no other misinformation \nwas encountered. The top 5G related post, by an influencer, debunked the \nconspiracy. Indeed, with a few exceptions we also found that the influencers \nwere posting responsibly and earnestly.\nIn a separate exercise we studied the authenticity of the followers as well \nas the political parties, employing the HypeAuditor tool. While, in both \ntimeframes, the Republican Party\u2019s account had over 25% of suspect follow -\ners, and Trump\u2019s had 25%, Biden was not far behind at about 20%. His party \nalso had 25% of suspect followers. It should be noted that when separating \nthe two categories that make up inauthentic followers\u2014\u201cmass follower\u201d \naccounts and \u201csuspect\u201d accounts\u2014in the first period the Republican Party \nand Trump tally higher on suspicious followers, defined as \u201cInstagram bots \nand people who use specific services for likes, comments and followers \n22 r ichard rog erS \npurchase\u201d (Komok, 2020), while in the second period the candidates and \nparties grow closer together in their suspect counts.\nGoogle Web Search: Liberal sources outnumber conservative \nones\nWhile Google Web Search could be considered the dominant information \nmachine online, among the major platforms and online services it has been \none of the least studied for misinformation. Recognizing the potential for \nits spread during the pandemic, or what the head of the WHO called the \n\u201cinfodemic\u201d (UN DGC, 2020), Google has been curating the results for queries \nconcerning the COVID-19 pandemic, with side bars ordering the official \ninformation served, and results geo-tailored to provide local and national \nresources. Such information curation is rather unprecedented, unless one \ncounts Google\u2019s disclaimer notice on top of the results page for the query \n\u201cJew\u201d (Sullivan, 2004), or the cleaning up of autosuggested queries to remove \nethnic, homosexual and other slurs (Gibbs, 2016). Another contemporary \ncontext behind the study of election-related Google results concerns the \ndebate surrounding \u201cliberal tech bias\u201d (Schwartz, 2018). Could Google results \nbe thought to exhibit a bias towards or against particular types of sites? \nHow to characterize the sites returned for political queries?\nIn order to start to answer these questions, we queried candidate names, \npolitical parties and a host of election-related issues in Google, with results \nfrom the \u201cU.S. region\u201d from January\u00a012, 2019 to March\u00a023, 2020 and again from \nMarch\u00a024, 2020 to January\u00a05, 2021 (Torres, this volume). In an examination \nof the top 20 results per query, we ask, how to characterize the sources \nreturned? Are problematic sources present and even highly ranked? How \ncould the results be characterized politically? To do the analysis, we curated \na source list of problematic and non-problematic sources, largely news \nand cultural commentary, combining a set of media labeling sources, as \nin the Twitter and Facebook projects discussed above. We also consulted \nWikipedia and online news mentions of potentially problematic sources. \nThe categorization is considered rough and is meant to give an indication \nrather than a determination. With the aid of the labeling sites, we also \nassigned political leanings. There are two distinctive political categorization \nschemes, one \u201cample\u201d and one \u201cnarrow,\u201d with the former merging center-left \nand left and center-right and right, and the latter only including left (liberal) \nor right (conservative) labels, according to the sites that sort sources in such \na fashion. (When there was disagreement among the labeling sites, we went \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 23\nwith the majority.) We also labeled the sites returned that fell outside the \ncategories, such as \u201cspecial interest,\u201d \u201clocal news\u201d and \u201cofficial.\u201d\nIn all we found that the Google results for our nearly 120 queries resulted in \nscant problematic information returned. Hardly present as well were official \nsources that we defined as federal or local government, intergovernmental \nagencies, politicians, or campaign websites. Special interest sites, a broad \ncategory ranging from think tanks to advocacy groups, have an outsized pres -\nence in the results, however, especially in the run-up to the elections. These \nsites tend to specialize in an issue or industry, which is also an indication of \nhow Google values information sources. Most significantly, when considering \nthe political leanings of sources, it is striking that Google could be said not \nto seek \u201cbalance.\u201d That is, liberal sources outnumber conservative ones in the results for all queries made. Employing the \u201cample\u201d categorization, for \nthe first period, the results were 6:1 in favor of liberal sources, and 3:1 when \nemploying the narrower scheme, and for the second period they jumped \nto 12:1 and 14:1.\nMarginalizing the mainstream\nAt the outset the question to be addressed concerned the extent to which \nsocial media is \u201cmainstreaming the fringe,\u201d not so unlike the early web, \nprior to the development of epistemologies that placed it on firmer ground. \nAmong those mentioned were the wisdom of the crowd such as Wikipedia\u2019s \ncollaborative editing, but there were others. For instance, Yahoo! and DMOZ \nemployed librarianship in their directory-making, Google used hyperlink \nanalysis scientometrically, and the early U.S. blogosphere constituted a kind \nof fact-checking, epistemic community, most famously uncovering faked \ndocuments held up as authentic by an authoritative TV news program (60 \nMinutes), in what has become known as the \u201cKillian documents controversy\u201d \n(Callery and Proulx, 1997; Langville and Meyer, 2006; Wikipedia contributors, \n2020). Here we now ask the same of social media. How to characterize the current epistemological foundations of online platforms?\nIn order to grapple with that question, I briefly sum up the findings \nwith respect to the relationship between the mainstream and the fringe \nper platform and draw conclusions from our cross-platform approach. \nGenerally speaking, social media and its users appear to be marginalizing \nthe mainstream. Subsequently, I discuss the prospects of source adjudication \nin terms of results curation or otherwise managing which content is allowed \nto remain on social media platforms. It is a form of \u201cplatform criticism\u201d \n24 r ichard rog erS \nthat speaks to the various emerging epistemologies on offer to stabilize \nsocial media.\nThe social media platforms under study have varied relationships with main -\nstream media, at least with respect to those sources or posts most interacted \nwith in the run-up to the 2020 U.S. presidential elections and its aftermath. \nBroadly speaking, TikTok parodies it, 4chan and Reddit dismiss it and direct \nusers to alternative influence networks and extreme as well as conspiratorial \nYouTube content. Twitter nearly prefers the hyperpartisan over it. Facebook\u2019s \n\u201cfake news\u201d problem also concerns declining amounts of mainstream media \nreferenced. Instagram has influencers (rather than, say, experts) dominating \nuser engagement, though is a rather healthy space. By comparison, Google \nWeb Search buoys the liberal mainstream (and sinks conservative sites), but \ngenerally gives special interest sources, as they were termed in the study, the \nprivilege to provide information rather than official sources.\nThese findings were made on the basis of cross-platform approach that \nseeks to attain commensurability of the findings through employing engage -\nment analysis on each platform. At the same time, it remains sensitive to \nthe platforms\u2019 specificities by remaining attuned to each of their differing \nmetrics, vernaculars of use and user subcultures, as related above.\nOverall, we found that social media marginalize the mainstream, albeit in \nmanners specific to each platform. Given the decline of what one could call \n\u201cmainstream authority\u201d online, how to characterize the contemporary ap -\nproaches to source adjudication, when considering problematic information? \nThat platforms are manually editing results (for certain queries) indicates what I would call an \u201cexceptional information state.\u201d\nRecently, social media platforms and Google web search have begun to \ncurate the results of such \u201cserious queries\u201d as coronavirus, COVID-19 and \nsimilar terms related to the global pandemic. Such filtering may explain \nthe scant amount of outwardly problematic information such as conspiracy \nwebsites encountered in the top results for coronavirus queries across the platforms. It does, however, raise the question of the epistemology behind the authority that is being applied, and whether it puts paid (for example) \nto the signals approach of algorithms, and instead puts forward \u201cediting in\u201d \nofficial sources as the top content recommended.\nEditorial epistemologies and serious queries\nSource list or results curation is laborious work and fell into decline with \nthe overall demise of the human editing of the web and the rise of the \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 25\nback end, and algorithmic signals, taking over from the editors (Rogers, \n2013). COVID-19 and the coronavirus are thus exceptional for they have \nmarked the return of the editors and raise the question of whether their \nwork should extend beyond pandemic sources to election-related informa -\ntion, as discussed above. Maintaining COVID-19 and the coronavirus as \nan exceptional information state would draw the line there, though cases \ncould be made to extend the adjudicative practice to the democratic process, \nwhere policymakers especially in Europe have directed their efforts. France\u2019s \nfalse news legislation comes to mind, as does Germany\u2019s extension of its \nhate speech act. There are also Facebook\u2019s efforts to maintain a political \nad archive tool. Each is (partially) a response to concerns of a repeat, in \nEurope and beyond, of the \u201cfake news\u201d crisis of 2016.\nSo far, the pandemic and (for some) election-related matters are \u201cserious \nqueries\u201d in the sense that the information returned should not be fully in \nthe hands of current trends in algorithmic culture but returned to editors. \nWith content reviewers and moderators, there is currently a blurring (and \nin a sense cheapening) of editors, however. Their low-wage, outsourced \nwork to date has had to do with violent and pornographic content rather \nthan the \u201cquality of information\u201d (Roberts, 2019). There is the question of \nthe journalistic training and qualifications for the editing work (Parks, \n2019). The professional fact-checking editors, as mentioned above, would \nstruggle with volume.\nThere are advocates of an editorial recovery online. Source adjudica -\ntion techniques on offer these days for results curation are, among others, \njournalistic balance, the absence of biased sources, fact-checked stories, and \n\u201clongue dur\u00e9e\u201d expertise, be it official and/or established. Crowd-sourcing \nusers to flag inappropriate content or only checking trending content are \nalso available approaches. All mark the return of qualitatively determin -\ning the worthiness of source appearance and could be dubbed editorial \nepistemologies. Each requires judgements in advance of the moment of \ngaveling the A/B or ignore/delete decision, as platforms are wont to decide \nto allow a post or not. (For world leaders, as mentioned, the posts may be \nlabeled.) There is also the question of handling the volume of posts to be \nscrutinized\nWhen curating results or otherwise managing outputs, to undertake \n\u201cbalanced list\u201d work implies making political or partisan source distinctions, \nand continually returning to the outputs to check the weight of each side \nper substantive query. An approach seeking an \u201cabsence of biased sources\u201d \npresupposes classification and monitoring and likely relying on official, \ninstitutionalized information. Fact-checking, rather than on a source level, \n26 r ichard rog erS \nswitches the efforts to the individual story, and subsequently researches, \narchives and labels them. At least as it has been performed on Facebook \nposts by DPA and AFP, the German and French news agencies respectively, \nit is such meticulous work that it outputs a total of about four fact-checks \nper day, if their production prior to the 2021 Dutch elections is exemplary \n(AFP, 2021; DPA, 2021). Relying on \u201clongue dur\u00e9e\u201d expertise could be another \nmeans of offering high-quality sources, as organizations working in the same \nterrain for many years would have accrued credibility, but to official sources \nit would add non-governmental and other specialized organizations with an established track record (and perhaps a noticeable political leaning).\nAnother starting point is to take an active audience approach, and assume \nthat another, perhaps more significant instance of filtering lies with the \nuser or what was once known as the \u201cwisdom of the crowd.\u201d Users can \n\u201cflag\u201d or report content on various platforms and label it as inappropriate, \nmisleading, etc. Taking such user reporting practices a step further, as \nmentioned above, Twitter\u2019s \u201cBirdwatch\u201d program seeks dedicated users (not \nso unlike Wikipedians, albeit without the non-profit spirit) to sift content and enforce platform rules.\nAs demonstrated in the empirical research reported above, engagement \nmeasures that consider rating (liking), circulating (sharing) and comment -\ning (reading) are another means to determine the activity of audiences. \nOn Facebook, but also on Twitter (retweeting), one may inquire into the \nstories about the coronavirus and other issues making audiences active. \nAdjudicating only those posts with the highest engagement would allow \nliking and sharing to trigger editorial interest.\nFinally, one also could argue for an \u201canything goes\u201d approach to mis -\ninformation, returning to a pre-pandemic algorithmic signals method \noperated in tandem with standard content moderation, editing out violence, \npornography, terrorism and hate. Such a return would appear unlikely \nas it would imply a regress in content review standards on mainstream \nplatforms. For example, since 2019, Twitter policies cover not just  violence \nbut its \u201cglorification\u201d (Twitter, 2019a), as publicized in a case of the labeling \na Donald Trump tweet as such. Indeed, more content types are scrutinized \nthese days. Specifically, since the coronavirus pandemic, the types have \nbeen expanded to include \u201cmisleading\u201d information.\nWith respect to identifying such information, Twitter writes, \u201cmoving \nforward, we may use these labels \u2026 in situations where the risks of harm \n\u2026 are less severe but where people may still be confused or misled by the content\u201d (Roth and Pickles, 2020). Setting aside for a moment the question \nof taking social media company utterances at face value (John, 2019), the \n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 27\nstatement raises the prospect that the new editorial epistemologies, together \nwith the contestation that accompanies their fundaments, may abide beyond \nthe current exceptional information state.\nNote\nAn earlier version of the article appeared in the journal, Frontiers in Big \nData  (Rogers, 2021) .\nReferences\nAFP (2021). AFP Factcheck Nederland, Agence France-Presse. https://factcheckned -\nerland.afp.com/list.\nAllcott, H., Gentzkow, M. and Yu, C. (2019). Trends in the diffusion of misinforma -\ntion on social media. Research & Politics , April\u2013June\u00a02019: 1\u20138.\u2028 https://doi.\norg/10.1177/2053168019848554.\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nBarkun, M. (2016). Conspiracy theories as stigmatized knowledge. Diogenes , 62(3\u20134). \nhttps://doi.org/10.1177/0392192116669288.\nBartlett, J. and Krasodomski-Jones, A. (2015). Counter-speech: Examining content \nthat challenges extremism online. Demos. http://www.demos.co.uk/wp-content/\nuploads/2015/10/Counter-speech.pdf.\nBengani, P. (2019, December\u00a018) Hundreds of \u201cpink slime\u201d local news outlets are \ndistributing algorithmic stories and conservative talking points, Tow Center \nfor Journalism, Columbia University. https://www.cjr.org/tow_center_reports/\nhundreds-of-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php.\nBenkler, Y., Faris, R. and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBounegru, L., Gray, J., Venturini, T. and Michele, M. (2018). A field guide to fake \nnews . Public Data Lab.\nBruns, A., Harrington, S. and Hurcombe, E. (2020) \u201cCorona? 5G? or both?\u201d: The \ndynamics of COVID-19/5G conspiracy theories on Facebook. Media International \nAustralia , 177 (1). https://doi.org/10.1177/1329878X20946113.\nBurton, A. and Koehorst, D. (2020). The spread of political misinformation on \nonline subcultural platforms. Harvard Kennedy School Misinformation Review , \n1(6). https://doi.org/10.37016/mr-2020-40.\nBuzzSumo (2020). Buzzsumo media monitoring. https://buzzsumo.com.\n28 r ichard rog erS \nCallery, A. and Proulx, D.T. (1997) Yahoo! Cataloging the web. Journal of Internet \nCataloging , 1(1). https://doi.org/10.1300/J141v01n01_06.\nColeman, K. (2021). Introducing Birdwatch, a community-based approach to mis -\ninformation. https://blog.twitter.com/en_us/topics/product/2021/introducing-\nbirdwatch-a-community-based-approach-to-misinformation.html.\nColombo, G. and De Gaetano, C. (2020). Dutch political Instagram: Junk news, fol -\nlower ecologies and artificial amplification, In R. Rogers and S. Niederer (Eds.) The \npolitics of social media manipulation (pp.\u00a0147\u2013168). Amsterdam University Press.\nCooper, Sara (2020). How to medical, TikTok video. https://www.tiktok.com/@\nwhatchugotforme/video/6819061413877763334.\nDaniels, J. (2018). The algorithmic rise of the \u201calt-right.\u201d Contexts , 17(1). ht tps://doi.\norg/10.1177/1536504218766547.\nDe Zeeuw, D. and Tuters, M. (2020). Teh Internet is serious business: On the deep \nvernacular web and its discontents. Cultural Politics , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\nDean, J. (1998). Aliens in America . Cornell University Press.\nDiResta, R., Shaffer, K., Ruppel, B., Sullivan, D., Matney, R., Fox, R., Albright, J. and \nJohnson, B. (2018). The tactics & tropes of the Internet Research Agency. New \nKnowledge. https://disinformationreport.blob.core.windows.net/disinformation-\nreport/NewKnowledge- Disinformation-Report-Whitepaper.pdf.\nDonovan, J. (2019). How memes got weaponized: A short history. MIT Tech -\nnology Review .  https://www.technologyreview.com/2019/10/24/132228/\npolitical-war-memes-disinformation/.\nDPA (2021). DPA fact-checking. Deutsche Presse-Agentur. https://dpa-factchecking.\ncom/netherlands/.\nEllis, E.G. (2019, September\u00a010) Fighting Instagram\u2019s $1.3 billion problem\u2014fake \nfollowers. Wired . https://www.wired.com/story/instagram-fake-followers/.\nFacebook (2018, December\u00a06). Coordinated inauthentic behavior. Facebook News -\nroom. https://about.fb.com/news/2018/12/inside-feed-coordinated-inauthentic-\nbehavior/.\nFacebook (2021a, February\u00a09). January\u00a02021 coordinated inauthentic be -\nhavior report. Facebook Newsroom. https://about.fb.com/news/2021/02/\njanuary-2021-coordinated-inauthentic-behavior-report/.\nGadde, V. and Roth, Y. (2018, October\u00a017). Enabling further research of information \noperations on Twitter. Twitter blog. https://blog.twitter.com/en_us/topics/\ncompany/2018/enabling-further-research-of-information-operations-on-twitter.\nhtml.\nGagliardone, I. (2019). Defining online hate and its \u201cpublic lives\u201d: What is the place \nfor \u201cextreme speech\u201d? International Journal of Communication , 13. ht tps://doi.\norg/1932\u20138036/20190005.\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 29\nGallucci, N. (2016, November\u00a022). 8 ways to consume news without using Facebook. \nMashable . https://mashable.com/2016/11/22/consume-news-without-facebook/.\nGibbs, S. (2016, December\u00a05). Google alters search autocomplete to remove \u201care Jews \nevil\u201d suggestion. The Guardian . https://www.theguardian.com/technology/2016/\ndec/05/google-alters-search-autocomplete-remove-are-jews-evil-suggestion.\nGillespie, T. (2018). Custodians of the Internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nHarris, S. (2019, February\u00a05). #148 \u2013 Jack Dorsey. Sam Harris Podcast. https://\nsamharris.org/podcasts/148-jack-dorsey/.\nHedrick, A., Karpf, D. and Kreiss, D. (2018). The earnest internet vs. the ambivalent \ninternet. International Journal of Communication , 12(8). https://ijoc.org/index.\nphp/ijoc/article/view/8736.\nHerrman, J. (2016, August\u00a024). Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHoward, P.N., Ganesh, B., Liotsiou, D., Kelly, J. and Fran\u00e7ois, C. (2018). The IRA, social \nmedia and political polarization in the United States, 2012\u20132018, Computational \nPropaganda Research Project, Oxford Internet Institute.\nHypeAuditor (2020). Instagram reports, https://hypeauditor.com/reports/\ninstagram/.\nJohn, N.A. (2019). Social media bullshit: What we don\u2019t know about facebook.com/\npeace and why we should care. Social Media + Society , January\u2013March: 1\u201316. \nhttps://doi.org/10.1177/2056305119829863.\nKomok, A. (2018). How to check Instagram account for fake followers. HypeAuditor. htt -\nps://hypeauditor.com/blog/how-to-check-instagram-account-for-fake-followers/.\nLangville, A.N. and Meyer, C.D. (2006). Google\u2019s PageRank and beyond: The science \nof search engine rankings . Princeton University Press.\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on \nYouTube. Data & Society Research Institute. https://datasociety.net/output/\nalternative-influence/.\nLindquist, J. (2019). Illicit economies of the internet. Made in China Journal , 3(4), \npp.\u00a088\u201391. https://madeinchinajournal.com/2019/01/12/illicit-economies-of-the-\ninternet-click-farming-in-indonesia-and-beyond/.\nMahendran, L. and Alsherif, N. (2020, January\u00a08) Adding clarity to our Com -\nmunity Guidelines. TikTok newsroom. https://newsroom.tiktok.com/en-us/\nadding-clarity-to-our-community-guidelines.\nMedia Bias/Fact Check (2020). Filtered search. https://mediabiasfactcheck.com.\nMosseri, A. (2017, April\u00a06). Working to stop misinformation and false news. Facebook \nNewsroom. https://about.fb.com/news/2017/04/working-to-stop-misinformation-\nand-false-news/.\n30 r ichard rog erS \nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nOlmsted, K. (2009) Real enemies: Conspiracy theories and American democracy, \nWorld War I to 9/11 . Oxford University Press.\nOtero, V. (2017). The Chart. version 3.1. ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nParks, L. (2019). Dirty data: Content moderation, regulatory outsourcing and The \nCleaners. Film Quarterly , 73(1). https://doi.org/10.1525/fq.2019.73.1.11.\nPepp, J., Michaelson, E. and Sterken, R. (2019). Why we should keep talking about \nfake news. Inquiry . https://doi.org/10.1080/0020174X.2019.1685231.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nPorter, J. (2020, May\u00a029). Twitter restricts new Trump tweet for \u201cglorifying violence.\u201d \nThe Verge . https://www.theverge.com/2020/5/29/21274323/trump-twitter-\nglorifying-violence-minneapolis-shooting-looting-notice-restriction.\nRheingold, H. (1994). The millennial whole earth catalog . HarperCollins.\nRoeder, O. (2018, August\u00a08). We gave you 3 million Russian troll tweets. Here\u2019s \nwhat you\u2019ve found so far. FiveThirtyEight. https://fivethirtyeight.com/features/\nwhat-you-found-in-3-million-russian-troll-tweets/.\nRogers, R. (2004 ). Information politics on the web . MIT Press.\nRogers, R. (2013). Digital methods . MIT Press.\nRogers, R. (2017). Digital methods for cross-platform analysis. In J. Burgess, A. \nMarwick and T. Poell (Eds.) The SAGE handbook of social media  (pp.\u00a091\u2013108). Sage.\nRogers, R. (2019). Doing digital methods . Sage.\nRogers, R. (2020a). The scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified. Harvard Kennedy School Misinformation Review , 1(6). ht tps://doi.\norg/10.37016/mr-2020-43.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nRogers, R. and Hagen, S. (2020). Epilogue: After the tweet storm. In R. Rogers \nand S. Niederer (Eds.) The politics of social media manipulation (pp.\u00a0253\u2013256). \nAmsterdam University Press.\nRomm, T. and Stanley-Becker, I. (2019, December\u00a021). Facebook, Twitter disable \nsprawling inauthentic operation that used AI to make fake faces. Washington \nPost . https://www.washingtonpost.com/technology/2019/12/20/facebook-twitter-\ndisable-sprawling-inauthentic-operation-that-used-ai-make-fake-faces/.\nRoth, Y. and Pickles, N. (2020, May\u00a011). Updating our approach to misleading in -\nformation. Twitter Blog. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.html.\n\u201cSeriou S q uerie S\u201d  and \u201cedi To rial e PiS TeMo logie S\u201d 31\nSchwartz, O. (2018, December\u00a04). Are Google and Facebook really suppressing con -\nservative politics? The Guardian . https://www.theguardian.com/technology/2018/\ndec/04/google-facebook-anti-conservative-bias-claims.\nShirky, C. (2008). Here comes everybody . Penguin.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nSilverman, C. and Alexander, L. (2016, November\u00a03). How teens in the Balkans \nare duping Trump supporters with fake news. Buzzfeed News . https://www.\nbuzzfeednews.com/article/craigsilverman/how-macedonia-became-a-global-\nhub-for-pro-trump-misinfo.\nSparktoro (2021). Audience intelligence. https://sparktoro.com.\nSullivan, D. (2004, April\u00a024) Google in controversy over top-tanking for anti-Jewish \nsite. Search Engine Watch . https://www.searchenginewatch.com/2004/04/24/\ngoogle-in-controversy-over-top-ranking-for-anti-jewish-site/.\nTarkov, A. (2012, June\u00a030). Journatic worker takes \u201cThis American Life\u201d inside out -\nsourced journalism. Poynter. https://www.poynter.org/reporting-editing/2012/\njournatic-staffer-takes-this-american-life-inside-outsourced-journalism/.\nTuters, M. and Burton, A. (2021). The rebel yell: Toxic vox populism on YouTube. \nCanadian Journal of Communication . forthcoming.\nTwitter (2019a). Glorification of violence policy, Twitter help center. https://help.\ntwitter.com/en/rules-and-policies/glorification-of-violence.\nTynan, D. (2016, August\u00a024) How Facebook powers money machines for obscure polit -\nical \u201cnews\u201d sites. The Guardian . https://www.theguardian.com/technology/2016/\naug/24/facebook-clickbait-political-news-sites-us-election-trump.\nUN DGC. (2020, March\u00a031). UN tackles \u201cinfodemic\u201d of misinformation and \ncybercrime in COVID-19 crisis. UN Department of Global Communica -\ntions. https://www.un.org/en/un-coronavirus-communications-team/\nun-tackling-\u2018infodemic\u2019-misinformation-and-cybercrime-covid-19.\nVaidhyanathan, S. (2019, July\u00a028). Why conservatives allege big tech is muzzling \nthem. The Atlantic . https://www.theatlantic.com/ideas/archive/2019/07/\nconservatives-pretend-big-tech-biased-against-them/594916/.\nVan der Linden, S., Panagopoulos, C. and Roozenbeek, J. (2020). You are fake news: \nPolitical bias in perceptions of fake news. Media, Culture & Society , 42(3). ht tps://\ndoi.org/10.1177/0163443720906992.\nVenturini, T. (2019). From fake to junk news: The data politics of online virality. \nIn D. Bigo, E. Isin and E. Ruppert (Eds.) Data politics: Worlds, subjects, rights  \n(pp.\u00a0123\u2013144). Routledge.\n32 r ichard rog erS \nWardle, C. (2017, February\u00a016). Fake news: It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nWikipedia contributors (2020). Killian documents controversy. Wikipedia: The \nFree Encyclopaedia . https://en.wikipedia.org/w/index.php?title=Killian_docu -\nments_authenticity_issues&oldid=962589844.\nWilkinson, W.W. and Berry, S.D. (2020). Together they are Troy and Chase: Who \nsupports demonetization of gay content on YouTube? Psychology of Popular \nMedia , 9(2). https://doi.org/10.1037/ppm0000228.\nAbout the author\nRichard Rogers , PhD, is Professor of New Media & Digital Culture, Media \nStudies, University of Amsterdam, and Director of the Digital Methods \nInitiative. He is author of Information Politics on the Web and Digital Methods  \n(both MIT Press) and Doing Digital Methods (SAGE).\n2 P roblematic information in Google \nWeb Search?\nScrutinizing the results from U.S. election-related queries\nGuillen Torres1\nAbstract\nThe goal of this study is to analyze the type and ranking of informa -\ntion sources furnished by Google Web Search for queries related to the \n2020 U.S. presidential election. Overall, we found that the presence of \nproblematic information in the returns is scant. In additionally studying \nthe diversity of sources, we found an asymmetry between liberal and \nconservative websites in the top results. This imbalance is notable when \napproaching it through the lens of an opposition or even competition for \nhigh rankings between liberal and conservative media, broadly defined. A \nmore nuanced classification does not eliminate the imbalance given the \nnear absence (from March\u00a02020 to January\u00a02021) of explicitly conservative \noutlets.\nKeywords: Google, problematic information, digital methods, elections \nresearch\nResearch questions\nHow are problematic sources positioned within the first 20 Google.com \nresults, when querying U.S. candidates and their most significant issues? \nFor issue-related queries, what are the predominant source types returned, \nand how may their leanings be characterized politically?\n1 Pa rts of this research were carried out in collaboration with Varvara Boboc and Robert \nBaciu.\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch02\n34 g uillen Torre S \nEssay summary\nThe main finding is that within the top 20 Google results for election-related \nqueries from February\u00a02019 to January\u00a02021 the presence of problematic \ninformation is low. We also find that when using either \u201cample\u201d or \u201cnarrow\u201d \ndefinitions of liberal and conservative sources to query Google Web Search \nin different moments in time, liberal outnumber conservative. Moreover, \nwe find the predominance of mainstream news, a considerable presence \nof \u201cspecial interest\u201d websites and a fluctuating presence of official sources. \n\u201cSpecial interest\u201d is used as a broad category including professional as -\nsociations, think tanks, and industry or community news sites, producing \ninformation mostly around one specific topic (e.g., farming or taxes), while \n\u201cofficial sources\u201d are largely governmental or the candidates\u2019 own campaign \nwebsites.\nThis study undertakes a source-distance analysis of Google.com results \nfor the periods of February\u00a012, 2019 to March\u00a023, 2020 and March\u00a024, 2020 \nto January\u00a05, 2021, where one measures how far from the top of the returns \nare particular types of sources. To assign a rough political bias category \nto the search results, two classifications were devised, based on existing \nschemes. An \u201cample\u201d classification combines center-left and left political \norientations into left, and center-right and right into right. A \u201cnarrow\u201d \nclassification makes a stricter division and only considers explicitly left or \nright sources as liberal or conservative, while center-left and center-right \noutlets are considered mainstream.\nImplications\nThe low presence of official institutional sources in the returns to our queries \nis not necessarily problematic, but the strategies Google implemented to \nfight problematic information related to SARS-CoV-2 beg the question about \nwhether something similar may be justified for queries related specifically \nto elections, or more generally to public policies or governmental programs \nthat have proven controversial or divisive in the past (e.g., DACA or foreign \nrelations with China). Google already employs \u201cfeatured snippets\u201d that \nhighlight certain sources for general searches (e.g., [Trump policies] bring \nup a Wikipedia page), but this is not the case for queries about specific \npolicies. Whether it is desirable that Google privileges information produced \nby politically accountable institutions is a discussion that lies beyond the \nProble MaTi c infor MaTi on in go ogle Web Search?  35\nscope, but the fact that the company has decided to take a stance regarding \nSARS-CoV-2 suggests that there might be benefits to such a strategy.\nSecondly, the near absence of such problematic sources as imposter, \nconspiracy, pseudo-science or extreme sites in the top twenty results suggests \nthat Google\u2019s efforts to prevent such misinformation from rising to the top \nare succeeding (Google 2019a). This is the case at least for queries related \nto political issues and candidates. As other platforms are arguably losing \nthe battle against problematic information, particularly in the context of \nthe global pandemic and political unrest in the U.S. (Alba, 2020), Google\u2019s \nstrategies could be considered by other actors.\nThird, we found a preponderance of liberal sources over conservative \nones using both an \u201cample\u201d and a \u201cnarrow\u201d classification of information \nsources. Although this result could be related to the wording of our \nqueries (i.e., occasionally using more liberal keywords), we found that \nthe imbalance still stands for those queries that could be considered \nmore neutral (i.e., immigration). Considering that a perceived liberal \nmedia bias lingers in the U.S. political imaginary (Hassel et al., 2020), \nGoogle may find that clarifying anew why its algorithm privileges certain \noutlets over others could contribute to the debate about a \u201cliberal tech \nbias\u201d (Boxell et al., 2020). Although Google previously has openly stated \nthat there is no bias affecting its results (Wakabayashi, 2018) and the \nplatform\u2019s role in polarizing its users is still a heavily contested matter \n(Boxell et al., 2017; Sunstein, 2018; Bail et al., 2018), Google\u2019s reflection \nabout the possibilities of implicit bias could be beneficial. The company \noften frames the production of its results as a process guided by objective \nmeasures of content quality and value (Google, 2019a, 2019b); however, \nreflections around these concepts (Kelemen, 2005; Heuts and Mol, 2013) \nas well as about the politics of search engine rankings (Introna and \nNissenbaum, 2000; Noble 2018) could be matters for Google to discuss \nmore explicitly.\nFinally, the considerable presence of websites of special interest in our \nqueries implies that these sources have the privilege of supplying election-\nrelated information. Considering how those voices are boosted over official \nsources, this finding calls for a more specific analysis into the politics of the \ninformation they produce. Although previous studies have also noted the \npresence of this type of source (Courtois et al., 2018; Unkel and Haim, 2019), \nthey have not yet been the exclusive object of research. Such an analysis \nwould pertain to the study of less obvious partisanship in search engine \nrankings (Robertson et al., 2018).\n36 g uillen Torre S \nFindings\nFinding 1: Official sources are hardly in evidence in Google Web Search results \nfor queries related to the 2020 U.S. presidential candidates Joe Biden and Donald \nTrump. Overall, the presence of official sources, such as \u201c.gov\u201d sites or official \ncampaign sites is quite low. For the first period under research (February\u00a012, 2019 \nto March\u00a023, 2020), official sources make up only 1% of the total. For the second \n(March\u00a024, 2020 to January\u00a05, 2021), which includes the official campaign season, \nthe elections and the days prior to inauguration day, the presence of these \nsources increases considerably, making up 5% of the dataset. Queries related \nto Donald Trump produce the highest number of official sources, accounting \nfor nearly 10% of that subset of the results. In fact, the whitehouse.gov website \nwas the third most common top result for Trump-related queries. Given the \nscope of this chapter, it is not possible to identify whether this change is related \nto contextual factors such as current events or a change in the evaluation of \nsource relevance by the Google Web Search service.\nFinding 2: Problematic information is hardly present in Google Web \nSearch results for queries related to the 2020 U.S. presidential candidates \nbefore the start of the pre-campaigning, and it is entirely absent afterwards. \nProblematic sources are only present in our dataset if this category is made \nto include hyperpartisan websites. No imposter, fake news or fly-by-night \nsources were identified. Only five sources classified as problematic were \nidentified: The World Tribune, National File, RedState, TheBL, and  Breitbart, \nall labeled as hyperpartisan. These sources were present exclusively during \nthe period between the unofficial start of Trump\u2019s campaign and the suspen -\nsion of in-person rallies due to the COVID pandemic. Table\u00a02.1 displays the \ndistribution of problematic sources among the results. There is no particular \nquery that seems to be more likely to return problematic sources than others, \nalthough queries where hyperpartisan sources are present also seem to \nhave more conservative sources than liberal, which is remarkable given the \noverall low presence of right-of-center sources. It is noteworthy that while \nthe presence of this type of source is minimal, The World Tribune , National \nFile and RedState  show up as the first result for some queries. Queries related \nto Joe Biden produced the highest number of problematic sources.\nTable\u00a02.1  P roblematic sources in Google Web Search results.\nSource Query Candidate Result ranking\nWorld Tribune K-12 \nedu\ncation do\nnald Trump 1\nThe bl re\nparations Joe \nbid\nen 14\nProble MaTi c infor MaTi on in go ogle Web Search?  37\nSource Query Candidate Result ranking\nn\national \nfi\nle ch\narter Schools Joe \nbid\nen 1\nbre\nitbart da\nca J\noe \nbid\nen 19, 20\nre\nd State The \nco\nnstitution Joe \nbid\nen 1\nTimeframe: fe bruary\u00a012, 2019 to March\u00a023, 2020. da ta from go ogle.com.\nFinding 3: Mainstream news websites dominate the top 20 Google Web \nSearch Results. For both periods under review, the majority of the websites \npresent in the first 20 results of our political queries are mainstream news \nand special interest sites. Table\u00a02.2 summarizes the types of sources present \nin our queries for the first period under review. The ten most present sources \nare the following: Politico , The New York Times, The Hill , Forbes , Common \nDreams (which we classified as a liberal source, rather than mainstream), \nThe Guardian , Reuters , USA Today , The Wall Street Journal and Wikipedia . \nTogether, they make up 28% of the total results.\nTable\u00a02.2   Oc currences of different types of sources in the results of Google Web \nSearch to political queries. \nCandidate News \n(national)Special interestNews (local)Official Platform Academic Problematic/hyperpartisanOther\nTrump 73% 19.2% 6.2% 1% 0.9% 0.09% 0.04% 1.3%\nbid\nen 71% 15.8% 9.34% 1.5% 1.2% 0.08% 0.2% 1.3%\nTimeframe: \nfe\nbruary\u00a012, 2019 to March\u00a023, 2020. The category \u201cother\u201d includes websites that \nappeared in the results due to the keywords we used in connection with the names of the \ncandidates, but that did not include political information. \nda\nta from \ngo\nogle.com.\nTable\u00a02.3 summarizes the types of sources returned by Google Web Search \nfor the second period under review. The top positions this time are held \nby The Washington Post , followed by CNBC, The New York Times, Reuters, \nForbes, NPR, Politico, The White House, The Guardian and  NBC News . Together, \nthese sources represent 34% of the total results, which implies an increase \nin the overall prominence of these ten mainstream sources (together with \nthe one official source) in comparison to the period before. This result is \nnoteworthy considering that the overall presence of mainstream sources \nis lower in this second dataset, since special interest websites increased \ntheir incidence. The stable presence of The New York Times, Politico, Forbes, \nReuters and  The Guardian  suggests that Google Web Search assigns them \na high relevance.\n38 g uillen Torre S \nTable\u00a02.3   Oc currences of different types of sources in the results of Google Web \nSearch to political queries.\nCandidate News \n(national)Special interestNews (local)Official Platform Academic Other\nTrump 58% 20% 8% 9.3% 3% 0.7% 1%\nbid\nen 53.4% 28.5% 11.4% 3% 2.3% 0.5% 0.7%\nTimeframe: March\u00a024, 2020 to January\u00a05, 2021. The categories of \u201cproblematic\u201d and \u201chyperparti-\nsan\u201d are not included given that no source was classified as such. \nda\nta from \ngo\nogle.com.\nFinding 4: Overall, the presence of liberal sources is greater than that \nof conservative websites. Using news bias labeling sites as a rough in-\ndicator, we found a greater presence of liberal sources in comparison to \nconservative ones in all queries and for both periods under review, with \na slight decrease in the presence of right-of-center sources in the second. \nThis was the case both with \u201cample\u201d and \u201cnarrow\u201d definitions of what \nconstitutes a liberal or conservative source. Imbalances within search \nresults have been noted before by researchers, journalists and civil society \norganizations, and results have varied depending on geography and subject \nmatter. For example, Haim et al. (2017) found an overrepresentation of \nconservative sources in Germany, while in the U.S. audits tend to find more \nliberal websites than conservative ones (Trielly and Diakopoulos, 2018). \nIn our case, using the \u201cample\u201d classification makes the imbalance grow \nto a proportion of 6:1 in favor of liberal sources for the first period under \nanalysis and 12:1 for the second. Using the \u201cnarrow\u201d scheme changes the \nimbalance to around 3:1 and 14:1, respectively. The increase in the ratio of \nliberal to conservative sources in the second period of analysis is credited \nto a considerable decrease in the number of conservative websites in the \nreturns, rather than an increase of liberal ones. In fact, the data show \nan overall decrease of both types of sources, although the presence of \nconservative sources declined more. Tables\u00a02.4 and 2.5 show the propor -\ntions using both classifications. The imbalance stands even for queries \nthat deal with topics that would, intuitively, be connected to a higher \npresence of conservative sources (i.e., [Donald Trump] [Gun control] or \n[Donald Trump] [immigration]).\nProble MaTi c infor MaTi on in go ogle Web Search?  39\nTable\u00a02.4   P roportion of liberal and conservative news sources per candidate. \nEarly campaigning period\nCandidate Liberal\n(ample)Unbiased(ample)Conservative(ample)Liberal(narrow)Unbiased(narrow)Conservative(narrow)\ndo nald Trump 44.4% 24.2% 8% 11% 63% 3%\nJoe \nbid\nen 39% 25% 14% 12% 59% 6%\n\u201cSpecial interest\u201d websites are not considered, as their political orientation has not been defined. \nTimeframe: \nfe\nbruary\u00a012, 2019 to March\u00a023, 2020. \nda\nta from \ngo\nogle.com.\nTable\u00a02.5   P roportion of liberal and conservative news sources per candidate. \nRun-up to election and aftermath\nCandidate Liberal\n(ample)Unbiased(ample) Conservative\n(ample)Liberal(narrow)Unbiased(narrow)Conservative(narrow)\ndo nald Trump 41% 22% 2% 4% 61% 0.3\u00a0%\nJoe \nbid\nen 39% 22% 3% 5% 59% 1%\n\u201cSpecial interest\u201d websites are not considered, as their political orientation has not been defined. \nTimeframe: March\u00a024, 2020 to January\u00a05, 2021. \nda\nta from \ngo\nogle.com.\nThe imbalance is also present when analyzing the diversity of unique URLs \nfrom which Google Web Search draws its results. Our dataset consists of 1,300 \nunique URLs. The proportion liberal/conservative of these sources using \nthe ample scheme is around 3:1, whereas using the more restrictive criteria \nit is around 4:1. This difference suggests that, overall, Google seems to be \ndrawing results from a more diverse pool of liberal sites than conservative. \nWhen only explicitly progressive/conservative websites are classified as \nsuch, the imbalance increases. Rather than implying a liberal bias, this \nresult could be related to the existence of a higher number of liberal outlets \n(Trielli and Diakopoulos, 2019).\nThere is also a slight difference in the political composition of the unique \nsources in the two moments of data capture. For example, the five hyper -\npartisan conservative sources found in the first dataset did not appear in \nsubsequent queries, despite the use of the same keywords. This could be \nrelated to current events during the dates of the queries rather than a bias \nin Google\u2019s service. Table\u00a02.6 showcases the political composition of the two \ndatasets in terms of unique sources. This table suggests a tendency towards the \nreduction of liberal and conservative sources in the search results over time.\n40 g uillen Torre S \nTable\u00a02.6   Numb er of unique sources in absolute numbers, by political \norientation.\nFebruary\u00a012, 2019\u2013March\u00a023, 2020 March\u00a024, 2020\u2013January\u00a05, 2021\nLeft Center Right Left Center Right\nNarrow 60 290 28 40 265 7\nAmple 235 80 78 201 79 36\nda ta from go ogle.com.\nTable\u00a02.7 digs further into the reduction in the presence of explicitly liberal \nor conservative sources by showcasing how their presence changed between \nthe two periods under review. Common Dreams and Jacobin Magazine  \nexhibit the biggest change, given that they were prominently featured in \nthe first period, when they were even featured as the top result in 11 out of \n114 queries.\nTable\u00a02.7   T op liberal and conservative sources in absolute numbers, for both \nperiods under research.\nFebruary\u00a012, 2019\u2013March\u00a023, 2020 March\u00a024, 2020\u2013January\u00a05, 2021\nLiberal Conservative Liberal Conservative\ncommondreams.com 96 washingtontimes.com 53 newsweek.com 21 f\noxbusiness.com 10\njacobinmag.com 61 washingtonexaminer.com 45 newyorker.com 20 washingtonexaminer.com 3\nnewsweek.com 55 nationalreview.com 36 prospect.org 17 city-journal.org 1\nnymag.com 49 thefederalist.com 7 vanityfair.com 13 washingtontimes.com 1\nthenation.com 12 city-journal.org 1 nymag.com 9 nationalreview.com 1\nda ta from go ogle.com.\nFinding 5: Special interest websites (and local news stations) have a \nconsiderable presence within top 20 Google results for election-related \nqueries. Although national mainstream news outlets make up for the \nlargest proportion of results to our queries, they are not in the majority \nwhen analyzing the diversity of unique sources. For the first period of \nanalysis, special interest websites represent 40% of the pool of sources from \nwhich Google Web Search draws its results, whereas local news websites \nrepresent 20% and mainstream news websites represent only 19%. The \npresence of this type of source is higher when querying candidate names \nProble MaTi c infor MaTi on in go ogle Web Search?  41\ntogether with sensitive topics such as drugs, migration or gun control, but \nalso for some less obviously contentious topics such as K-12 education and \ntransportation.\nTable\u00a02.8 presents the distribution of unique sources in the results to \nour queries for both periods under review. Sites we have defined as special \ninterest are the largest number in both cases, and the data shows an increase \nof 40% of this type of source in the latter queries. The considerable presence \nof special interest websites suggests that Google\u2019s understanding of relevance \nvalues specialization and expertise less than the journalistic qualities of \nestablished news outlets. Thus, although search results are drawn from a \nmore diverse pool of special interest websites, they are featured less often. \nThe top five special interest websites for the first period were Marijuana \nMoment (cannabis enthusiasts), The Motley Fool (investment), EdWeek  \n(education), American for Tax Reform (policy), and The Tax Foundation \n(policy). For the second period, the top five sources were Marijuana Moment, \nThe Tax Foundation, The Balance (real estate), KHN (public health), and \nThe Tax Policy Center (policy). These sources tend to feature prominently \nand exclusively within their niche topics, rather than being spread over \nmultiple issue-queries.\nThe presence of local news websites within our dataset can be character -\nized in similar terms to special interest websites with the difference that \nthe numbers of the former did not increase from the first period of analysis \nto the second. In this case, we could argue that Google\u2019s understanding \nof relevance values the geographic proximity of content producers to the \nissues in question, but that this quality is less valued than the expertise of \nmainstream news outlets. Local news sources are usually confined to the \nsecond page of results, and although high in number in terms of source \ndiversity, they have a low occurrence. The most prominent local news sites \nin both datasets are connected to large metropolitan areas, such as Los \nAngeles, Philadelphia, Miami or Chicago.\nTable\u00a02.8  C lassification of unique sources in search results.\nNational \nNewsLocal NewsSpecial InterestAcademic Platform Official Problematic Other\nFirst period 179 213 267 7 8 20 5 36\nSecond period 136 188 372 18 7 34 0 24\nda ta from go ogle.com.\n42 g uillen Torre S \nMethods\nWe implemented a simple source-distance methodology (Rogers, 2019) whose \nobjective is to locate the position of different types of sources within Google \nWeb Search results, in order to find which ones are privileged by the search \nengine by assigning them positions close to the top. This method is employed \nto answer the following research questions: How are problematic sources \npositioned within the first 20 Google.com results for queries concerning \nU.S. candidates and their most significant issues? And for election-related \nqueries, what are the predominant source types returned, and how may they \nbe characterized politically? We followed Caroline Jack\u2019s conceptualization \nof problematic information as \u201cinaccurate, misleading, inappropriately \nattributed, or altogether fabricated\u201d (2017: 1).\nThe queries were designed on the basis of a list of political issues, trian-\ngulated from the two political parties\u2019 platforms, individual candidate\u2019s \nplatforms, and three voter support services: Politico,2 VoteSmart3 and On \nthe Issues.4 The queries consisted of the following keywords: [candidate] \nAND [issue]. Donald Trump and Joe Biden were the candidates queried. The \nqueries do not strive to replicate the search behavior by Google users, but \nrather to test the type of information returned generically in the United \nStates by the search engine when querying political issues deemed relevant \nby voter support services.\nAlthough research has shown that personalization is low in Google\u2019s \nWeb Search (Haim et al.\u00a02017, Robertson et al., 2018b), we still sought to \nreduce the prospects of individual (but not geographical) personalization \nin our results by performing queries on a clean Firefox Extended Support \nRelease browser (with a fresh installation and with no prior use of any \nother Firefox version); Virtual Private Network (VPN) software was used \nto acquire a U.S. IP address. The queries were performed with the Search \nEngine Scraper (Search Engine Scraper, n.d.). Adjusting the parameters of the \ntool, we scraped the first 20 results provided by Google, in the U.S. region, for two different periods: February\u00a012, 2019\u2013March\u00a023, 2020 and March\u00a024, \n2020\u2013January\u00a05, 2021. While the first period captures the unofficial start of \nthe Trump campaign and up to the suspension of in-person rallies due to the \nCOVID pandemic, the second period captures the official pre-campaigns, the elections, and up to a few days before Joe Biden\u2019s inauguration. We set \n2 ht tps://www.politico.com/2020-election/candidates-views-on-the-issues/\n3 \nhttps://justfacts.votesmart.org/\n4 ht\ntps://www.ontheissues.org/Issues.htm\nProble MaTi c infor MaTi on in go ogle Web Search?  43\nthe number of results to 20 under the assumption that users tend not to look \nmuch further than that (Jansen and Spink, 2003; Dan and Davison, 2016). \nOur dataset consists of the results for searches of about 114 issues, each of \nwhich was queried two times (one for each candidate) on two different dates \n(March\u00a023, 2020 and January\u00a05, 2021). This \u201cone shot\u201d strategy introduces \nsome limitations to the study given the known variability in the composition \nof Google results through time. This variability can be connected with \nbreaking news (Curtois et al.\u00a02018), or updates to the algorithm. Although \nresults variability affects the position that each source holds in the results \npage (which would have been relevant for our second finding, had we found \nmore problematic information), it seems to affect less the composition of the \nresults in terms of source diversity. For example, in two studies conducted \nby Trielly and Diakopoulos (2019, 2020) source diversity seems to remain \nstable throughout the queries performed. Thus, our findings 1, 3 and 4 \ncould be considered indicative despite ours not being a longitudinal study conducted through daily queries.\nThe resulting list of 9,120 links was compared against an expert list of \nknown problematic sources, which was curated by fellow researchers, \nusing a combination of labeling sites, AllSides.com, Media Bias/Fact Check, \n\u201cthe Chart,\u201d and NewsGuard. Wikipedia and news mentions of potentially \nproblematic sources also were consulted. In the relatively few cases where \nsources had not been previously classified, two researchers independently \nclassified them, following the guidelines of the labeling sites. When unla -\nbeled sources reproduced the content created by larger outlets (as is the \ncase with most local news), the resulting label was the same as assigned \nto the parent outlet (e.g., CBS, ABC, NPR). In cases where no affiliate was \nexplicitly acknowledged (mostly local news editorial pieces), the coding \nattempted to locate politically laden opinions. If no bias was detected, the source was labeled as \u201cleast biased.\u201d\nTwo categorization schemes were devised, still following the existing \nlabeling sites\u2019 overall viewpoints. The first, \u201cample\u201d one, combines center-\nleft and left political orientations, on the one hand, and center-right and \nright, on the other. As a result, mainstream sites such as The Guardian  and \nThe New York Times were labeled \u201cliberal,\u201d while The Wall Street Journal  \nwas labeled \u201cconservative.\u201d The second, \u201cnarrow\u201d scheme makes a stricter division and only considers more explicitly liberal or conservative sources \nas either left or right, while most mainstream news outlets remain in the \ncenter. As a result, sites as The New York Times, The Guardian  and The Wall \nStreet Journal  switched categories to \u201ccenter\u201d and sites as The National Review  \nand The Washington Times were labeled as conservative. Furthermore, we \n44 g uillen Torre S \nalso labeled certain websites as \u201cspecial interest,\u201d \u201clocal news,\u201d \u201cofficial,\u201d \n\u201cacademic,\u201d \u201cplatform\u201d and \u201cother.\u201d Special interest, the broad category of \nsources whose content is mostly oriented towards one particular topic, \ninclude such professional associations and think tanks whose ultimate goal is \nto advocate for public policy (e.g., Americans for Tax Reform or the Center for \nImmigration Studies), as well as industry or community news sites focusing \non a particular audience (e.g., Transport News, Agripulse  or the National Low \nIncome Housing Coalition). We differentiated between local and national \nnews outlets, since even if the first sometimes reproduce the content of the \nlatter, we found considerable original local reporting and opinion columns \nin the results of our queries, prompting a further opportunity to classify \npartisanship. We considered as \u201cofficial sources\u201d those belonging to the U.S. \nfederal or local government, inter-governmental agencies, politicians in \noffice, or the official campaign websites of current and former candidates. \nAcademic sources are those connected to a university (e.g., the University \nof Pennsylvania\u2019s Budget Model), while the platforms encountered are \nWikipedia, Twitter, YouTube and Facebook. Finally, the category \u201cother\u201d \nincludes all sources that bore no direct relation to the other types.\nReferences\nAlba, D. (2020, June\u00a01). Misinformation about George Floyd protests surges on social \nmedia. The New York Times. https://www.nytimes.com/2020/06/01/technology/\ngeorge-floyd-misinformation-online.html.\nBail, C.A., Argyle, L.P., Brown, T. W., Bumpus, J.P., Chen, H., Hunzaker, M.B.F., \nLee, J., Mann, M., Merhout, F., and Volfovsky, A. (2018). Exposure to opposing \nviews on social media can increase political polarization. Proceedings of the \nNational Academy of Sciences , 115(37), pp.\u00a09216\u20139221. https://doi.org/10.1073/\npnas.1804840115.\nBoxell, L., Gentzkow, M., and Shapiro, J. (2017). Is the internet causing political \npolarization? Evidence from demographics. National Bureau of Economic \nResearch. http://www.nber.org/papers/w23258.\nBoxell, L., Gentzkow, M., and Shapiro, J. M. (2020). Cross-country trends in affective \npolarization. National Bureau of Economic Research. https://www.nber.org/\npapers/w26669.\nCourtois, C., Slechten, L., and Coenen, L. (2018). Challenging Google Search filter \nbubbles in social and political information: Disconforming evidence from a \ndigital methods case study. Telematics and Informatics , 35(7), pp.\u00a02006\u20132015. \nhttps://doi.org/10.1016/j.tele.2018.07.004.\nProble MaTi c infor MaTi on in go ogle Web Search?  45\nDan, O., and Davison, B. D. (2016). Measuring and predicting search engine users\u2019 sat -\nisfaction. ACM Computing Surveys , 49(1), pp.\u00a01\u201335. https://doi.org/10.1145/2893486.\nDiakopoulos, N., Trielli, D., Stark, J., and Mussenden, S. (2018). I Vote For\u2014How \nSearch Informs Our Choice of Candidate. In M. Moore and D. Tambini (Eds.), Digi -\ntal dominance: The power of Google, Amazon, Facebook and Apple (pp.\u00a0320\u2013341). \nOxford University Press.\nDigital Methods Initiative. (n.d.). Search Engine Scraper . https://wiki.digitalmethods.\nnet/Dmi/ToolSearchEngineScraper.\nGoogle. (2019a). How Google Fights Misinformation. Google Blog. https://www.\nblog.google/documents/37/How_Google_Fights_Disinformation.pdf.\nGoogle. (2019b). Search Quality Evaluator Guidelines. https://static.googleusercon -\ntent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.\npdf.\nHaim, M., Graefe, A., and Brosius, H.-B. (2018). Burst of the filter bubble?: Effects \nof personalization on the diversity of Google News. Digital Journalism , 6(3), \npp.\u00a0330\u2013343. https://doi.org/10.1080/21670811.2017.1338145.\nHassell, H. J. G., Holbein, J. B., and Miles, M. R. (2020). There is no liberal media bias \nin which news stories political journalists choose to cover. Science Advances , \n6(14), eaay9344. https://doi.org/10.1126/sciadv.aay9344.\nHeuts, F., and Mol, A. (2013). What is a good tomato? A case of valuing in practice. \nValuation Studies , 1(2), pp.\u00a0125\u2013146. https://doi.org/10.3384/vs.2001-5992.1312125.\nIntrona, L., and Wood, D. (2004). Picturing algorithmic surveillance: The politics \nof facial recognition systems. Surveillance & Society , 2(2/3), pp.\u00a0177\u2013198.\nJack, C. (2017). Lexicon of Lies. Terms for Problematic Information. Data & Society \nResearch Institute. https://datasociety.net/pubs/oh/DataAndSociety_Lexi -\nconofLies.pdf.\nJansen, B. J., and Spink, A. (2006). How are we searching the World Wide Web? A \ncomparison of nine search engine transaction logs. Information Processing & \nManagement , 42(1), pp.\u00a0248\u2013263. https://doi.org/10.1016/j.ipm.2004.10.007\nKelemen, M. (2005). Managing Quality: Managerial and Critical Perspectives . Sage. \nhttps://doi.org/10.4135/9781446220382.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nNoble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism . \nNew York University Press.\nOtero, V. (2017). The Chart. version 3.1. ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nRobertson, R. E., Lazer, D., and Wilson, C. (2018). Auditing the personalization and \ncomposition of politically related search engine results pages. Proceedings of the \n2018 World Wide Web Conference on World Wide Web \u2013 WWW \u201818 , pp.\u00a0955\u2013965. \nhttps://doi.org/10.1145/3178876.3186143.\n46 g uillen Torre S \nRogers, R. (2019). Doing digital methods . Sage.\nSunstein, C. R. (2018). #Republic: Divided democracy in the age of social media . \nPrinceton University Press. https://doi.org/10.2307/j.ctv8xnhtd.\nTrielli, D., and Diakopoulos, N. (2019). Search as news curator: The role of Google \nin shaping attention to news information. Proceedings of the 2019 CHI Con -\nference on Human Factors in Computing Systems \u2013 CHI \u201819 , 1\u201315. https://doi.\norg/10.1145/3290605.3300683\nUnkel, J., and Haim, M. (2019). Googling politics: Parties, sources, and issue owner -\nships on Google in the 2017 German federal election campaign. Social Science \nComputer Review , 39(5), pp.\u00a0844\u2013861. https://doi.org/10.1177/0894439319881634.\nWakabayashi, D. (2018, September\u00a05). Trump says Google is rigged, despite its \ndenials. What do we know about how it works? The New York Times . ht tps://\nwww.nytimes.com/2018/09/05/technology/google-trump-bias.html.\nData availability\nData available at: https://bit.ly/2Q10kCO\nAbout the author\nGuill\u00e9n Torres is a PhD researcher and Lecturer at the Department of Media \nStudies, University of Amsterdam. His research focuses on how datafica -\ntion may foster the political action of minoritized communities. Within \nthe Digital Methods initiative, Guill\u00e9n\u2019s work revolves around the role of \nplatforms in mediating access to information.\n3 T he scale of Facebook\u2019s problem \ndepends upon how \u201cfake news\u201d is \nclassified\nRichard Rogers1\nAbstract\nUshering in the contemporary \u201cfake news\u201d crisis, Craig Silverman of \nBuzzfeed News  reported that it outperformed mainstream news on \nFacebook prior to the 2016 U.S. presidential election. Here the report\u2019s \nmethods are revisited for 2020. Examining Facebook user engagement \nof election-related stories, and applying Silverman\u2019s classification of fake \nnews, it was found that the problem has worsened. If, however, one were \nto classify \u201cfake news\u201d in a stricter fashion, as Facebook and others do \nwith the notion of \u201cfalse news,\u201d the scale of the problem shrinks. A smaller \nscale problem could imply a greater role for fact-checkers, while a larger \none could lead to the further politicization of source adjudication, where \nlabeling certain sources as \u201cfake\u201d results in backlash.\nKeywords: Fake news, false news, junk news, hyperpartisan, media \nlabeling\nResearch questions\nTo what extent is \u201cfake news\u201d (as defined in the 2016 seminal news article) \npresent in the most engaged-with, election-related content on Facebook in \nthe run-up to the 2020 U.S. presidential elections? How does the current \n1 T he first period of the analysis was reported in Rogers, 2020a. The research benefited \nfrom research assistance by Paul Bugeja, Maria Lompe, Yumeng Luo, Rimmert Sijtsma, Tatiana \nSmirnova, Giulio Valentini, Ilian Velasco and Nina Welt.\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch03\n48 r ichard rog erS \n\u201cfake news\u201d problem compare to that of the 2016 election period, both with \nthe same as well as a stricter definition of \u201cfake news\u201d? Is there more user \nengagement with hyperpartisan conservative or progressive sources in politi -\ncal spaces on Facebook? How does such engagement imply a politicization \nof the \u201cfake news\u201d problem?\nEssay summary\nIn all, it was found that the \u201cfake news\u201d problem around the U.S. elections \nas observed in 2016 has worsened overall on Facebook in 2020. While \u201cfake \nnews\u201d did not outperform mainstream news in any period under study (as \nit did in August to November of 2016) the proportion of user engagement \nwith \u201cfake news\u201d to mainstream news stories was higher compared to 2016. \nIn the seven full quarters under study in the run up to and aftermath of \nthe 2020 elections (from March\u00a02019 to December\u00a02020) the proportion of \nengagement of \u201cfake news\u201d to mainstream was on average 1:1.8 compared \nto 1:2.6 in 2016. It is both an observation concerning the persistence of the \nproblem and an admonition that the measures undertaken to date have \nnot lessened the phenomenon.\nIf one applies a stricter definition of \u201cfake news\u201d such as only imposter \nnews and conspiracy sites (thereby removing hyperpartisan sites as in \nSilverman\u2019s original definition), mainstream sources outperform \u201cfake\u201d \nones by a much greater proportion.\nThe findings imply that how one defines such information has an impact \non the perceived scale of the problem, including the types of approaches to \naddress it. With a smaller-scale problem, fact-checking and labeling become \nmore viable alongside the \u201cbig data\u201d custodial approaches employed by \nsocial media firms.\nGiven there are more hyperpartisan conservative sources engaged with \nthan hyperpartisan progressive ones, the research points to how considera -\ntions of what constitutes \u201cfake news\u201d may be politicized. Targeting \u201cfake \nnews\u201d presumably would affect hyperpartisan conservative sources to a \ngreater degree than progressive ones. It thereby could invite criticism of \u201cbig \ntech,\u201d including claims of censorship on one side of the political spectrum. \nIt also could prompt social media firms to become less open to critical \nscrutiny by scholars and journalists alike interested in which sources and \nstories are being degraded or deplatformed.\nThe findings are made on the basis of Facebook user engagement of the \ntop 200 stories returned for queries for candidates and social issues. Based on \nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  49\nexisting labeling sites, the stories and by extension the sources are classified \nalong a spectrum from more to less problematic as well as partisan.\nImplications\nThe initial \u201cfake news\u201d crisis (Silverman, 2016; 2017) had to do with fly-by-\nnight, imposter, conspiracy as well as so-called \u201chyperpartisan\u201d news sources \noutperforming mainstream news on Facebook in the three months prior \nto the 2016 U.S. presidential elections. In a sense it was both a critique of \nFacebook as \u201chyperpartisan political-media machine\u201d (Herrman, 2016) but \nalso that of the quality of a social media landscape witnessing a precipitous \nrise in the consumption and sharing of \u201calternative right\u201d news and cultural \ncommentary (Benkler et al., 2017; Holt et al., 2019).\nThe events of the first crisis have been overtaken by a second one where \npoliticians as former President Trump in the U.S. and elsewhere employ \nthe same term for certain media organizations in order to undermine their \ncredibility. Against the backdrop of that politicization as well as rhetorical \ntactic, scholars and platforms alike have demurred on using the term \u201cfake \nnews\u201d and instead offered \u201cjunk news,\u201d \u201cproblematic information,\u201d \u201cfalse \nnews\u201d and others (Vosoughi et al., 2018). Some definitions (as junk news and \nproblematic information) are roomier, while others are stricter in their source \nclassification schemes. Subsumed under the original \u201cfake news\u201d definition \nare imposter news, conspiracy sources and hyperpartisan, defined as \u201coverly \nideological web operations\u201d (Herrman, 2016) or sources that \u201cexpressly \npromotes views\u201d (Otero, 2017). The newer term, \u201cjunk news,\u201d covers the same \ntypes of sources but adds the connotation of attractively packaged junk \nfood that when consumed could be considered unhealthy (Howard, 2020; \nVenturini, 2019). It also includes two web-native source types. \u201cClickbait\u201d \ncaptures how the manner in which it is packaged or formatted lures one \ninto consumption, and \u201ccomputational propaganda\u201d refers to dubious news \ncirculation by bot and troll-like means, artificially amplifying its symbolic \npower. Problematic information is even roomier, as it expands its field of \nvision beyond news to cultural commentary and satire (Jack, 2017). Stricter \ndefinitions such as \u201cfalse news\u201d would encompass imposter and conspiracy \nbut are less apt to include hyperpartisan news and cultural commentary, \ndiscussing those sources as \u201cmisleading\u201d rather than as \u201cfake\u201d or \u201cjunk\u201d or \nas not being \u201cnews\u201d in the first instance (Kist and Zantingh, 2017).\nRather than an either/or proposition, \u201cfake news\u201d could be understood as \na spectrum with problematic information (the roomiest notion) on one end \n50 r ichard rog erS \nand \u201cfalse news,\u201d the strictest, on the other, with junk news and fake news \nin the middle (Wardle, 2016; 2017). While beyond the scope, the purview \ncould be widened even further to include more media than stories and \nsources, such as video and images.\nDepending on the definition, the scale of the problem changes as does \nthe range of means to address it (Gillespie, 2020). With \u201cfalse news,\u201d it grows \nsmaller, and fact-checking again could be a profession to which to turn \nfor background research into the story and the source. Fact-checking\u2019s \neffectiveness is occasionally regarded as limited, given the enormity of the \ntask, the large reach of some fake news stories (well before fact-checks have \nappeared) and the number of fact-checks an organization can complete per \nday (Annany, 2018). Moreover, the audiences of \u201cfake news\u201d and fact-checked \n\u201cfake news\u201d also may differ significantly, meaning that corrections rarely \nreach the original consumers of the offending content (Bounegru et al., 2018). \nMore attention may be paid to the stories that have merited a fact-check or \na label, expanding their reach and engagement.\nFacebook\u2019s content moderation is multi-facetted, relying on human review, \nuser reporting and automated approaches (Roberts, 2016; Gillespie, 2018; \nFacebook, 2021b). Where their approach to misinformation is concerned, \nFacebook has striven to work with fact-checking bodies, though some of the \nfledgling partnerships ended after a year or two (Madrigal, 2019). For the \nremaining partner organizations, there is a Facebook dashboard, populated \nwith content flagged through crowd-sourcing and automated techniques, \nwhere the fact-checkers can choose articles and write their reports, from \ntwo to five per day per fact-checker (Annany, 2018). These reports result in \ncontent removal or downgrading. When the problem is scaled down, these \napproaches become more viable as do other qualitative approaches such as \nlabeling, with adjudicators sifting through posts one by one.\nRoomier definitions make the problem larger and result in findings such \nas the most well-known \u201cfake news\u201d story of 2016. \u201cPope Francis Shocks \nWorld, Endorses Donald Trump for President\u201d began as satire and was \nlater circulated on a hyperpartisan, fly-by-night site (Ending the Fed). It \ngarnered higher engagement rates on Facebook than more serious articles \nin the mainstream news. When such stories are counted as \u201cfake,\u201d \u201cjunk\u201d \nor \u201cproblematic,\u201d and the scale increases, industrial-style \u201cscalable\u201d solu -\ntions may be preferred such as automated review and commercial content \nmoderation (rather than journalist fact-checking).\nAs more content is taken down as a result of roomy source classification \nschemes, debates about freedom of choice may become more vociferous \nrather than less. It recalls the junk food debate, and in this regard, Zygmunt \nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  51\nBauman stressed how we as homo eligens or \u201cchoosing animals\u201d are wont \nto resist such restrictions, be it in opting for \u201chyperprocessed\u201d food or \nhyperpartisan news and cultural commentary (2013).\nLabeling hyperpartisan news as \u201cfake\u201d or \u201cjunk,\u201d moreover, may lead to \ngreater political backlash. Indeed, as our findings imply, the \u201cfake news\u201d or \n\u201cjunk news\u201d problem is largely a hyperpartisan conservative source problem, \nwhereas the \u201cfalse news\u201d one is not. As recently witnessed in the Netherlands, \nthe designation of hyperpartisan conservative sources as \u201cjunk news\u201d drew \nthe ire of sources so labeled as well as the leader of a conservative political \nparty, who subsequently labeled mainstream news as \u201cjunk fake news\u201d \n(Rogers and Niederer, 2020; Van Den Berg, 2019). Opting for the narrower \n\u201cfalse news\u201d classification would imply a depoliticization of the problem.\nFinally, it should be remarked that the sources outputting questionable \ncontent in 2020 do not appear to be the fly-by-night, imposter news sites in \noperation in 2016, but rather more \u201cestablished\u201d conspiracy and hyperparti -\nsan sites. If Facebook, as its policy states (2021), were to degrade the posts in \nthe News Feed from at least the conspiracy sites, thereby affecting their reach \nand engagement, then the scale of \u201cfalse news\u201d problem may be reduced. \nThe circulation of hyperpartisan sources would remain, however, making \nthe platform still the site where the competition between mainstream and \n\u201cproblematic information,\u201d \u201cjunk news\u201d and \u201cfake news\u201d will remain.\nSource and story classification tensions remain. Certain sources may \nhave hyperpartisan commentary but run mainstream stories from wire \nservices. Hyperpartisan sources may gradually mainstream. Distinctions \nbetween the hyperpartisan and conspiracy may be difficult to disentangle. \nConspiracy theories may become more legitimate with time such as the lab \norigins of the coronavirus.\nFindings\nThis study revisits the initial \u201cfake news\u201d findings made by Craig Silverman \nof Buzzfeed News  in 2016, where it was found that in the three months prior \nto the 2016 U.S. presidential elections \u201cfake news\u201d stories received more \ninteractions on Facebook than mainstream stories (see Figure\u00a03.1). It ushered \nin the \u201cfake news\u201d crisis with Facebook at its center.\nFinding 1: If we employ the same definition of \u201cfake news\u201d as Silverman \ndid during 2016, to date the problem has worsened somewhat. Whereas 1 in \n2.6 \u201cfake news\u201d sources (on average per quarter) were most engaged-with in \nFebruary\u2013November\u00a02016, from March, 2019 to December, 2020 it is now 1 \n52 r ichard rog erS \nfi gure\u00a03.1 \u201c fa ke news\u201d outperforms mainstream news in the months prior to the 2016 u. S. \npresidential elections. Source: Silverman, 2016.\n \nfi gure\u00a03.2 fa cebook engagement scores of \u201cfake news\u201d (Silverman\u2019s roomy definition) versus \nmainstream news for political candidate and social issue queries overall, March\u00a024, 2019\u2013 de-\nce\nmber\u00a023, 2020. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  53\nin 1.8 (see Figures 3.1 and 3.2). The main finding, in other words, is that the \n\u201cfake news problem\u201d of 2016 has not been remedied four years later.\nFinding 2: If, however, one tightens the definition of \u201cfake news\u201d sites \nto imposter and conspiracy sites (as the definition of \u201cfalse news\u201d would \nhave it), thereby removing hyperpartisan sources from the categorization \nscheme, the proportion of most engaged-with \u201cfake news\u201d to mainstream \nnews in March\u00a02019 to December\u00a02020 lessens to 1 in 12 (see Figure\u00a03.3). After \na spike in the run up to the elections, there is a general downward trend in \nthe engagement with such sites.\nNote that the 2016 problem also could be thought to diminish if one were \nto disaggregate Silverman\u2019s original source list and remove hyperpartisan \nstories and sites. An examination of his list per period in question indicates \nin the first two quarters (February through July\u00a02016) most sources are \nhyperpartisan and satirical (Silverman, 2016). Only in the period between \nSeptember and the election do we find imposter sites. A case in point is the \nDenver Guardian (which is no longer online); as the Denver Post  wrote, \u201c[t]\nhere is no such thing as the Denver Guardian, despite that Facebook post \nyou saw\u201d (Lubbers, 2016). Imposter sites, however, are in the minority and \nmost engagement is driven by the hyperpartisan and the satirical such \nas Ending the Fed, Breitbart News and the World News Daily Report. In \nother words, their removal from the \u201cfake news\u201d classification would put \nmainstream news back on top.ProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\noverall\n0\n200,000,000\n400,000,000\n600,000,000\n800,000,000\n1,000,000,000\n1,200,000,000\n1,400,000,000\n1,600,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7engagement\ntimeQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.3 fa cebook engagement scores of \u201cfake news\u201d (narrow definition) versus mainstream \nnews for political candidate and social issue queries overall, March\u00a024, 2019\u2013 de\ncember\u00a023, 2020. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n54 r ichard rog erS \nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesNon ProblematicFacebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.4 fa cebook engagement scores of \u201cfake news\u201d (Silverman\u2019s original roomy definition) \nversus mainstream news for political candidate and social issue queries, March\u00a02019\u2013 de\ncem-\nber\u00a02020. \nab\nsolute numbers shown for the sake of trend comparison. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  55\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesNon ProblematicFacebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesNon ProblematicFacebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\n56 r ichard rog erS \nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.5 fa cebook engagement scores of \u201cfake news\u201d (narrow definition) versus mainstream \nnews for political candidate and social issue queries, March\u00a02019\u2013 de\ncember\u00a02020. \nab\nsolute \nnumbers shown for the sake of trend comparison. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  57\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nabortion\naffordable housing\nassault weapon\nbackground checks\nBiden\ncampaign finance\ncarbon emission\ncharter school\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drill\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\nProblematicNon Problematic\nIncludes (hyper)partisanconservative and (hyper)partisanprogressive sourcesFacebook engagement over time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\n58 r ichard rog erS \nFinding 3: There are certain issues where more alternative sources provide \nthe coverage that was consumed (see Figure\u00a03.4), but, with the strict defini -\ntion, in no case did they (consistently) outperform mainstream sources (see \nFigure\u00a03.5). If we return to the original \u201cfake news\u201d definition (that includes \nhyperpartisan sites), alternative sources outperform mainstream ones (either \noverall or in certain weeks) for certain divisive issues such as abortion, death \npenalty, gun control, social security as well as the issue of fake news itself \n(see Figure\u00a03.4). There is also one issue (social security) where there is more \nengagement with \u201cfake news\u201d in the narrow sense than with mainstream \nnews (see Figure\u00a03.5), but overall the mainstream outperforms fake news \nin a narrow sense across most all issues and periods. With respect to the \ncandidates, Biden has proportionately more \u201cfake news\u201d (and \u201cfalse news\u201d) \nassociated with it than Trump, though Trump has a higher quantity overall. \nThe most engaged-with \u201cfake news\u201d story (PJ Media) relates to Trump and \nreads \u201cmilitary ballots found in the trash in Pennsylvania all were Trump votes.\u201d\nFinding 4: There is more engagement with hyperpartisan conservative \nsources than hyperpartisan progressive ones both overall as well as for \nthe majority of the candidates and issues (see Figures 3.6 and 3.7). The \nfinding suggests that any \u201cfake news\u201d definition that includes hyperpartisan \nsources will associate the problem more with conservative sources. When \nadjusting the definition to exclude such sources, \u201cfake news\u201d itself becomes \nless politicized.(hyper)partisan progressive(hyper)partisan conservativeFacebook engagement \nover time\noverall\n0\n200,000,000\n400,000,000\n600,000,000\n800,000,000\n1,000,000,000\n1,200,000,000\n1,400,000,000\n1,600,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7engagement\ntimeQ1: from 03/24/2019 to 06/23/2019 \nQ2: from 06/24/2019 to 09/23/2019 \nQ3: from 09/24/2019 to 12/23/2019 \nQ4: from 12/24/2019 to 03/23/2020 \nQ5: from 03/24/2020 to 06/23/2020 \nQ6: from 06/24/2020 to 09/23/2020 \nQ7: from 09/24/2020 to 12/23/2020\nfi gure\u00a03.6 fa cebook engagement scores of hyperpartisan conservative and hyperpartisan \nprogressive sources for political candidate and social issue queries, overall, March\u00a02019\u2013 de\ncem-\nber\u00a02020. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  59\nabortion\naffordable housing\nassault weapons\nbackground checks\nBiden\ncampaign finance\ncarbon emissions\ncharter schools\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drilling\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\n(hyper)partisan progressive(hyper)partisan conservative\nQ1: from 24/03/2019 to 23/06/2019\nQ2: from 24/06/2019 to 23/09/2019\nQ3: from 24/09/2019 to 23/12/2019\nQ4: from 24/12/2019 to 23/03/2020\nQ5: from 24/03/2020 to 23/06/2020\nQ6: from 24/06/2020 to 23/09/2020\nQ7: from 24/09/2020 to 23/12/2020Facebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nfi gure\u00a03.7 fa cebook engagement scores of hyperpartisan conservative and hyperpartisan \nprogressive sources for political candidate and social issue queries, March\u00a02019\u2013 de\ncember\u00a02020. \nab\nsolute numbers shown for the sake of trend comparison. \nda\nta source: \nbu\nzzsumo.com. \ngr\naphic \nby \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n60 r ichard rog erS \nabortion\naffordable housing\nassault weapons\nbackground checks\nBiden\ncampaign finance\ncarbon emissions\ncharter schools\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drilling\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\n(hyper)partisan progressive(hyper)partisan conservative\nQ1: from 24/03/2019 to 23/06/2019\nQ2: from 24/06/2019 to 23/09/2019\nQ3: from 24/09/2019 to 23/12/2019\nQ4: from 24/12/2019 to 23/03/2020\nQ5: from 24/03/2020 to 23/06/2020\nQ6: from 24/06/2020 to 23/09/2020\nQ7: from 24/09/2020 to 23/12/2020Facebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nabortion\naffordable housing\nassault weapons\nbackground checks\nBiden\ncampaign finance\ncarbon emissions\ncharter schools\nclimate change\nCoronavirus\nCOVID\nDACA\ndeath penalty\nelection security\nfake news\ngun control\nhealth insurance\nimmigration\ninfrastructure\nmedicare\nminimum wage\noil and gas drilling\npaid leave\nprivate prisons\nSanders\nsecuring 5G\nsocial security\nstudent debt\nteacher pay\nTrump\nveterans\nwealth taxes\n(hyper)partisan progressive(hyper)partisan conservative\nQ1: from 24/03/2019 to 23/06/2019\nQ2: from 24/06/2019 to 23/09/2019\nQ3: from 24/09/2019 to 23/12/2019\nQ4: from 24/12/2019 to 23/03/2020\nQ5: from 24/03/2020 to 23/06/2020\nQ6: from 24/06/2020 to 23/09/2020\nQ7: from 24/09/2020 to 23/12/2020Facebook engagement \nover time\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\ntimeengagement\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\n1,100,000\n1,200,000\n1,300,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n10,000,000\n20,000,000\n30,000,000\n40,000,000\n50,000,000\n60,000,000\n70,000,000\n80,000,000\n90,000,000\n100,000,000\n110,000,000\n120,000,000\n130,000,000\n140,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n2,000,000\n2,200,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n450,000,000\n500,000,000\n550,000,000\n600,000,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n400,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n22,000,000\n24,000,000\n26,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n18,000,000\n20,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n6,000,000\n6,500,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n1,000,000\n2,000,000\n3,000,000\n4,000,000\n5,000,000\n6,000,000\n7,000,000\n8,000,000\n9,000,000\n10,000,000\n11,000,000\n12,000,000\n13,000,000\n14,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n5,000,000\n5,500,000\n0\n50,000\n100,000\n150,000\n200,000\n250,000\n300,000\n350,000\n400,000\n450,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n0\n200,000\n400,000\n600,000\n800,000\n1,000,000\n1,200,000\n1,400,000\n1,600,000\n1,800,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n45,000,000\n50,000,000\n55,000,000\n60,000,000\n0\n10,000\n20,000\n30,000\n40,000\n50,000\n60,000\n70,000\n80,000\n0\n2,000,000\n4,000,000\n6,000,000\n8,000,000\n10,000,000\n12,000,000\n14,000,000\n16,000,000\n0\n500,000\n1,000,000\n1,500,000\n2,000,000\n2,500,000\n3,000,000\n3,500,000\n4,000,000\n4,500,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n0\n50,000,000\n100,000,000\n150,000,000\n200,000,000\n250,000,000\n300,000,000\n350,000,000\n0\n5,000,000\n10,000,000\n15,000,000\n20,000,000\n25,000,000\n30,000,000\n35,000,000\n40,000,000\n0\n100,000\n200,000\n300,000\n400,000\n500,000\n600,000\n700,000\n800,000\n900,000\n1,000,000\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  61\nMethods\nThis study builds upon the \u201cfake news\u201d report written by Craig Silverman \nand published in Buzzfeed News  in 2016. It employs a similar methodology, \nalbeit introducing a \u201cslider\u201d or gradient to indicate the extent of the problem \ndepending on how one classifies sources. The research enquires into the \ncurrent scale of the problem and compares it to the same timeframe in \n2016. It also demonstrates how roomier definitions of \u201cfake news\u201d make the \nproblem appear larger, compared to stricter definitions.\nFirst, a list of candidates and social issues is curated. The candidates \nchosen are the ones from the major parties, still in the race and campaigning \nat the time of the study. For social issues, the issue lists at four voting aid \nsources are first merged, and then filtered for those that appear on multiple \nlists: Politico, VoteSmart, On the Issues and Gallup (see Table\u00a03.1).\nTable\u00a03.1   T he list of candidates and issues queried in BuzzSumo.com in \nMarch\u00a02020 and January\u00a02021.\nTrump ca rbon emissions gun  control Private prisons\nbid\nen ch\narter schools healt\nh insurance Securing 5 g\nS\nanders cli\nmate change i\nmmigration Social security\nab\nortion co\nronavirus inf\nrastructure Student debt\naff\nordable housing da\nca M\nedicare Teacher pay\nas\nsault weapons dea\nth penalty Minimum wage Veterans\nba\nckground checks el\nection security oi\nl and gas drilling Wealth taxes\ncamp\naign financing fa\nke news Paid leave\nNext, we queried Buzzsumo, the marketing research and analysis tool, for \neach candidate and issue keyword, using the date ranges of March\u00a023, 2019 to \nMarch\u00a023, 2020 and March\u00a024, 2020 to January\u00a04, 2021, and the filter \u201cEnglish.\u201d \n(We limited our analysis to the end date, December\u00a023, 2020, thereby covering \nseven three-month periods.) We also retained non-American sources, in order \nto ensure that we did not miss highly engaging, problematic sources that are \nfrom outside the U.S. Buzzsumo returns a list of web URLs, ranked by interac -\ntions, which is the sum of reactions (including likes), shares and comments. \nThe study of engagement (or interactions) concerns a combination of rating \n(like), reading (comment) and circulating (share). In that sense, it is a rather \ncomprehensive measure. For every candidate and issue, we examined only \nthe top 200 stories returned, which is a limitation. Analyzing Facebook user \nengagement of \u201ctop\u201d content follows Silverman\u2019s original method. Silverman\u2019s \nincluded top 20 sources, whereas \u201ctop\u201d content is greater by a factor of 10.\n62 r ichard rog erS \nEach of the source names, headlines and any description text are read, \nand the sources are roughly labeled by concatenating pre-existing source \nclassification schemes (or when in disagreement choosing the majority label). \nTo gain an indication of their genre (non-problematic or problematic news \nincluding imposter news, conspiracy site, or clickbait) and (hyper)partisan-\nship, the sources are checked against media bias labeling sites including \nAllSides (2020), Media Bias/Fact Check (2020), \u201cThe Chart\u201d (Otero, 2017) and \nNewsGuard (2020); news sources\u2019 Wikipedia entries are also consulted. We \nalso searched for them online and consulted news and analysis that mention \nthe sources. Additionally, we checked the source lists returned by Buzzsumo \nagainst a study of imposter sources called \u201cpink slime sites,\u201d or sites that \nimitate local or national news sites (Bengani, 2019). Throughout the entire \nperiod and across all issues in the top 200 most engaged-with stories just \none pink slime site was found.\nSubsequently, we characterized the stories as problematic or non-\nproblematic, where the former adheres to the strict \u201cfalse news\u201d definition \n(imposter or conspiracy sites). These are then graphed overtime using RAW \ngraphs. We also applied the roomier definitions of \u201cfake news,\u201d which adds \nto imposter and conspiracy sites \u201chyperpartisan\u201d sources. We graphed these \nvalues anew. These graphs display the proportion of \u201cfake news\u201d versus \nnon-problematic sources in Facebook for the results of each candidate \nand social issue query over the election campaigning timeframe and its \naftermath, March\u00a02019 to December\u00a02020.\nWe then compared the 2020 findings with the 2016 results, in two ways. \nFirst, we compared the 2020 results with the roomier definition (imposter \n+ conspiracy + hyperpartisan) to the \u201cfake news\u201d findings of 2016 as propor -\ntions, finding that in 2019\u20132020, on average per quarter, there are 1 in 1.8 \nsources that are \u201cfake\u201d compared to 1 in 2.6 in 2016. Thus, the \u201coriginal\u201d \u201cfake \nnews problem\u201d has worsened. Second, we examined the source list from \nFebruary to November\u00a02016 in order to ascertain whether the findings were \nbased on a strict or roomy definition for that timeframe. Early in the 2016 \ncampaign, those sources were largely hyperpartisan or satirical, but the \nbest-performing story by far was from a reputable source that mistakenly \npublished a \u201cfake story,\u201d originating from a tweet by Sean Hannity of Fox \nNews  that the then candidate Trump had used his own private plane to \ntransport \u201c200 stranded marines\u201d (American Military News, 2016). Right \nbefore the 2016 election (August to November), the best-performing sources \nwere again hyperpartisan or satirical ones (as Ending the Fed, Breitbart and \nWorld News Daily Report), though imposter sites also make an appearance \n(Denver Guardian). For a sense of how definitions of fake news politicize, \nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  63\nwe also examined which candidates were associated with hyperpartisan \nnews, noting how Biden is targeted far more often in such sources.\nTo study the politicization of the \u201cfake news\u201d problem further, we com -\npared the overall engagement on Facebook of hyperpartisan sources, both \nconservative and progressive, as well as the candidates and issues that \nhad each type most associated with it, finding that conservative, so-called \nhyperpartisan sources outperformed hyperpartisan progressive ones.\nReferences\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nAmerican Military News (2016, May\u00a023). Article removed\u2014Here\u2019s why. \nAmerican Military News , https://americanmilitarynews.com/2016/05/\ndonald-trump-sent-his-own-plane-to-transport-200-stranded-marines/.\nAnnany, M. (2018, April\u00a04). The partnership press: Lessons for platform-publisher \ncollaborations as Facebook and news outlets team to fight misinformation. Co -\nlumbia Journalism Review . https://www.cjr.org/tow_center_reports/partnership-\npress-facebook-news-outlets-team-fight-misinformation.php.\nBauman, Z. (2013). Does the richness of the few benefit us all? Polity.\nBengani, P. (2019, December\u00a018). Hundreds of \u201cpink slime\u201d local news outlets are \ndistributing algorithmic stories and conservative talking points. Tow Center \nfor Journalism, Columbia University. https://www.cjr.org/tow_center_reports/\nhundreds-of-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php.\nBenkler, Y., Faris, R., Roberts, H. and Zuckerman, E. (2017, March\u00a03). Study: Breitbart-led \nright-wing media ecosystem altered broader media agenda. Columbia Journalism \nReview . https:/ /www.cjr.org/analysis/breitbart-media-trump-harvard-study.php.\nBounegru, L., Gray, J., Venturini, T. and Mauri, M. (2018). A field guide to \u201cfake news\u201d \nand other information disorders . Public Data Lab.\nFacebook (2021b, May\u00a025). False news, Facebook Transparency Center. https://\ntransparency.fb.com/policies/community-standards/false-news/.\nHerrman, J. (2016, August\u00a024). Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHolt, K., Figenschou, T.U. and Frischlich, L. (2019). Key dimensions of alternative \nnews media. Digital Journalism , 7(7), pp.\u00a0860\u2013869. https://doi.org/10.1080/2167\n0811.2019.1625715\n64 r ichard rog erS \nGillespie, T. (2018). Custodians of the internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nGillespie, T. (2020). Content moderation, AI, and the question of scale. Big Data & \nSociety , July\u2013December: 1\u20135, https://doi.org/10.1177/2053951720943234.\nHoward, P. (2020). Lie machines . Yale University Press.\nJack, C. (2017) Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\nKist, R. and Zantingh, P. (2017, March\u00a06). Geen grote rol nepnieuws in aanloop \nnaar verkiezingen. NRC Handelsblad . https://www.nrc.nl/nieuws/2017/03/06/\nfake-news-nee-zo-erg-is-het-hier-niet-7144615-a1549050.\nLubbers, E. (2016, November\u00a05). There is no such thing as the Denver Guardian, \ndespite that Facebook post you saw. The Denver Post . https://www.denverpost.\ncom/2016/11/05/there-is-no-such-thing-as-the-denver-guardian/.\nMedia Bias/Fact Check (2020). Filtered search. https://mediabiasfactcheck.com.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nOtero, V. (2017). The chart, version 3.1, ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nRoberts, S.T. (2016). Commercial content moderation: Digital laborers\u2019 dirty work. \nIn S.U. Noble and B.M. Tynes (Eds.), The intersectional internet: Race, sex, class \nand culture online (pp.\u00a0147\u2013160). Peter Lang.\nRogers, R. and Niederer, S. (Eds.) (2020). The politics of social media manipulation . \nAmsterdam University Press.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake \nelection news stories outperformed real news on Facebook, Buzz -\nfeed News .  https://www.buzzfeednews.com/article/craigsilverman/\nviral-fake-election-news-outperformed-real-news-on-facebook.\nWardle, C. (2016, November\u00a018). 6 types of misinformation circulated this election \nseason. Columbia Journalism Review . https://www.cjr.org/tow_center/6_types_\nelection_fake_news.php.\nWardle, C. (2017, February\u00a016). Fake news. It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nVan Den Berg, E. (2019, July\u00a030). Opnieuw misser bij Forum voor Democratie: Per -\nsoonlijke advertentie Thierry Baudet offline gehaald. NPO3. https://www.npo3.\nnl/brandpuntplus/opnieuw-misser-bij-forum-voor-democratie-persoonlijke-\nadvertentie-thierry-baudet-offline-gehaald.\nVenturini, T. (2019) From fake to junk news: The data politics of online virality. \nIn D. Bigo, E. Isin, and E. Ruppert (Eds.) Data politics: Worlds, subjects, rights \n(pp.\u00a0123\u2013144). Routledge.\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. \nScience , 359 (6380), pp.\u00a01146\u20131151. https://doi.org/10.1126/science.aap9559.\nThe Sc ale of fa ceboo K\u2019S  Pr oble M  de Pe ndS  uPo n ho W  \u201cfa Ke n eW S\u201d  iS  cla S Si fied  65\nData availability\nhttps://doi.org/10.7910/DVN/VFMJUH\nAbout the author\nRichard Rogers , PhD, is Professor of New Media & Digital Culture, Media \nStudies, University of Amsterdam, and Director of the Digital Methods \nInitiative. He is author of Information Politics on the Web and Digital Methods  \n(both MIT Press) and Doing Digital Methods (SAGE).\n\n4 W hen misinformation migrates\nCross-platform posting, YouTube and the deep vernacular \nweb\nAnthony Glyn Burton1\nAbstract\nThis chapter investigates the political information ecologies of the \n\u201cdeep vernacular web\u201d by studying the cross-posting of links on 4chan\u2019s \n\u201cpolitically incorrect\u201d board and a host of political subreddits. It finds \nthat Reddit\u2019s banning of political subreddits in June\u00a02020 proved effec -\ntive in culling the spread of misinformation. 4chan users turned from \nsharing propagandistic content towards conspiratorial links as the \n2020 U.S. election approached. This turn towards conspiracy parallels \nthe decline in popularity of alt-right punditry on both platforms, \nreflected in the shift in presence over time of these types of videos. \nThe chapter offers an example of how URLs and YouTube links can \nbe used as a cross-platform digital method in studying the spread of \nmisinformation.\nKeywords: 4chan, Reddit, misinformation, digital methods, YouTube\nResearch questions\nTo what extent do U.S.-based political boards and forums on 4chan and Red -\ndit share misinformation and \u201cjunk\u201d content? Are algorithmically generated \nimposter news websites among the misinformation that circulates? How \ncan we quantify and qualify the degree to which \u201calternative influence \n1 Pa rts of this chapter are drawn from Burton and Koehorst, 2020. The research team included \nDmitri Koehorst and Martijn van Schjip, who aided in the first round of research, and Yentel \nBoot, Frederikke Christiansen, David Dijkhuis, Morris Nieuwenhuis, and Alejandra O\u2019Connor, \nwho aided in the second round.\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023doi: 10.5117/9789463720762_ch04\n68 anTh ony gl yn bu rTon  \nnetworks\u201d proliferate on these sites? How might we characterize the shift \nin the information ecologies of these spaces around the time of the 2020 \nU.S. election?\nEssay summary\nThis chapter takes up these questions through a quantitative analysis of the \nnews links shared on the spaces of the subcultural political web. It details \nthe results of two separate studies. The first dataset covers the beginning \nof the 2020 presidential primaries, while the second period the lead-up and \nfollow-through of the November\u00a03, 2020 election. We employed a variety \nof methods to tackle these questions, of which the \u201chaystack-to-needle\u201d \ndeductive method pioneered by Hagen and Jokubauskaite (2019) produced \nthe best results in investigating the texture of informational websites \nshared.\nConstructing a coding schema based on Benkler et al.\u2019s work studying the \n2016 U.S. election, we first investigated the presence of \u201cjunk\u201d news on each \nplatform, which Howard et al. define as content \u201cextremist, sensationalist, \nconspiratorial, masked commentary, [or] fake\u201d that presents itself as news \n(Howard et al.\u00a02017; see also Gray et al., 2019). The presence of junk news \non each platform remained relatively stable, comprising approximately a \nthird of sources on 4chan and a fifth on Reddit.\nWe then investigated those sources coded as news proper and as well as \nfor partisanship using a variety of expert sources. We find that while the \nfirst collection period was characterized by a plurality of websites coded \nas neutral news, the period leading up to and through the election marks \na shift towards partisanship in the news ecologies of both spaces.\nFinding YouTube as an outsized source in both spaces\u2014in both time -\nframes making up a higher share of links on 4chan than all other sites \ncombined, and a stark presence on Reddit\u2014we focus further on the types of \nvideos that characterize each platform\u2019s YouTube shares. While the network \nof right-wing pundits that make up what Lewis (2018) dubs the \u201calternative \ninfluence network\u201d constituted a strong presence in the first dataset, their \npopularity in the lead-up to the election dramatically wanes\u2014replaced by \nvideo clips that purport to illustrate the very theories that the AIN traffics \nin, and illustrating a potential abandonment of the mediated, parasocial \nrelationships that make up the AIN\u2019s appeal (Lewis, 2020). Methodologically \nspeaking, this chapter\u2019s cross-platform methods\u2014using hyperlinks as \nWhen MiSi nfor MaTi on M igra Te S 69\nmetaphors for interest as opposed to tracking infrastructural syntaxes \nspecific to particular platforms\u2014offers a further potential avenue for study \nin the face of deplatforming and the migration of user audiences across \nplatforms (Rogers, 2020b).\nImplications\nThe accelerated informational exchange and ease of publication afforded \nby social media took on a dystopic turn during the 2016 U.S. election, \nwhere coordinated campaigns to manipulate information ecologies on \nmainstream social media platforms like Twitter sounded an epistemic \nalarm and added \u201cmisinformation\u201d to the cultural lexicon (Shao et al., 2018). \nBut as platforms strengthen their harmful content policies in response \nto criticism for harboring misinformation and hate speech, especially \nafter the election (Einwiller and Kim, 2020; Donovan and boyd, 2018), \nwe began to see alternative spaces such as the relatively unmoderated \nand historically uncensored subcultural political web found on spaces \nlike Reddit and 4chan as primary hubs for the spread of misinformation \n(Coppins, 2020). The lack of oversight in these spaces marks a continuation \nof what Starbird et al. refer to as the \u201cecho-systems\u201d that characterized \nthe spread of misinformation in 2016, wherein particular news sources \nare amplified within a discursive space and iteratively gain volume and \nattention (2018). And while Reddit banned a number of subreddits in \nJune\u00a02020 for violating their hate speech policy\u2014including the notori-\nous alt-right subreddit \u201cr/The_Donald\u201d (included in our dataset)\u2014the \npseudonymous nature, sheer scale, and ideological underpinnings of these \nplatforms set up a \u201cpropaganda pipeline\u201d where misinformation and its \ncorrelates gain vivacity (Benkler et al., 2019). These subcultural political \nplatforms make up what Tuters calls the \u201cdeep vernacular web\u201d (2019), \ncharacterized by pseudonymous participation and its antecedent trolling, \nplayfulness, and dreams of unfettered freedom of speech (Massanari, \n2017; Coleman, 2012; Buyukozturk et al., 2018), and are thus important \nplayers in contemporary news ecologies. But to characterize every user of \nthese spaces as a part of this propaganda pipeline would be too general. \nWhat does news circulation on these spaces look like? How are common \nnarratives and shared realities drawn in these spaces? And what might \nbe different about their conceptions of information, political punditry, \nand mediated verification?\n70 anTh ony gl yn bu rTon  \nFindings: News ecologies, compared\nIncreasing junk news as the election drew near\nWe observed that \u201cjunk news\u201d aesthetically or through the adoption of tech -\nniques masquerading as news websites either pushed conspiracy theories \nor presented content with the aims of sensationalizing or propagandizing. \nOn 4chan, the presence of junk news remained relatively stable across our \ndatasets, with 32% of links posted falling under the category in the first \ntime period and 31% of websites in the second time period. On the other \nhand, the stark shift in the presence of junk news on Reddit between our \nfirst and second datasets points to the fact that Reddit\u2019s banning of starkly \npolitical subreddits may have played a role in the information ecologies of \nthe site: while 17% of links shared fell under the category of junk news in \nour first dataset, it fell to about 4% in the second dataset, with propaganda \nmaking up little over 1% of links, sensationalist media counting 3%, and \nconspiracy a paltry 0.5%.\nThe types of junk news that appear on each website provide us with fur -\nther insight on changes that occurred as the election approached, especially \non 4chan. While propaganda was in relative abundance in the initial data \ncollection period\u2014with 20.2% of total links falling under the category, \ncompared to 10.7% as sensationalist and 1.2% as conspiratorial\u2014the lead-up \nto the election saw propaganda junk news fall by almost half, to 10.4% of \ntotal news links posted. Sensationalist news decreased slightly to 6.9%. \nMost notably, 14.4% of links in our second dataset were categorized as \nconspiratorial. This is an increase by a factor of 14. And while it is still \noutranked by the first dataset\u2019s number of propagandistic links, the increase \nin conspiracy as the election approached signals a dramatic shift.\nIncreasing partisanship as the election drew near\nCompared to junk news, websites which appeared to follow journalistic \nstandards made up the majority of links in both datasets. The changes over \ntime, however, are notable: while both Reddit and 4chan hovered around \n60% of all links being to news websites in the first data collection period, \nnews links on 4chan slightly lowered to 58% on the second run while Reddit\u2019s \nnumber increased by almost a third to 83%. But what appears on the surface \nas a relatively stable and socially endorsed informational ecology belies the \npartisan shift that occurred as the election approached.\nWhen MiSi nfor MaTi on M igra Te S 71\nIn the first dataset, Reddit\u2019s news sources contained a plurality of neutral \nsources\u201448% of all websites, and 57.8% of all websites coded as \u201cnews.\u201d \nLeft-leaning sources made up 24.8% of all links, while right-leaning sources \nmade up 9.9% of news links. The second dataset saw a marked shift in the \npolitical valence of hostnames, however. In this period, left-leaning websites \nmade up a plurality of the links, with 42.0% of links posted being categorized \nas such. Much of this gain was at the loss of neutral links, which numbered \n21.1% of all total news links; meanwhile, the number of right-leaning links \ndecreased to 3.9% of all news links.\nThe shift towards partisanship (according to our coding) was starker on \n4chan. In the first dataset, news websites categorized as neutral made up \n46.4% of the total information websites posted, while right-leaning websites \nmade up 12.3% of links and left-leaning websites just 4.1%. In the run-up \nto the election, however, the amount of neutral websites that appeared \ndecreased by more than half, comprising just 17.5% of total news-coded \nlinks. This decrease was counterbalanced by a tripling of both left- and \nright-leaning links. Left-leaning links appeared 15.9% of the time in the \nsecond dataset, while right-leaning links made up over a third of all news links, appearing 35.0% of the time.\nVideo ecologies: Categories versus our own coding\nOn both 4chan\u2019s /pol/ and in the political subreddits, video plays an \nimportant part in collective information habits. In both datasets, links \nto YouTube on 4chan were higher than all other links combined; on Red -\ndit, YouTube was the top-linked website. In the first run-through of the \ndataset, we focused on studying the videos posted by using YouTube\u2019s \nown categories to characterize videos. \u201cNews & Politics\u201d made up the \nmajority of links shared on both websites, with \u201cPeople & Blogs\u201d being the \nsecond highest. \u201cNews & Politics\u201d contains political content, news clips, \nbroadcasts, and other related content, while the purview of \u201cPeople & \nBlogs\u201d is slightly larger, containing talk shows, interviews, video casts of \npodcast recordings, and vlogs. Despite these core similarities, \u201cEducation\u201d \nand \u201cNonprofits and Activism\u201d made up the third- and fourth-highest \ncategories in the Reddit data, while \u201cEntertainment\u201d and \u201cMusic\u201d made \nup the third- and fourth-largest categories on 4chan. Given the lack of \ngranularity of these categories we performed our own coding for the \nsecond dataset, applied to YouTube links on both 4chan and Reddit, \ndetailed in Table\u00a04.1.\n72 anTh ony gl yn bu rTon  \nTable\u00a04.1  C oding scheme of Y ouTube videos.\nVideo type Definition\ncl\nip Short, standalone clip without context\nShitposting de\nliberately low-quality content that provokes attention and disrupts \ndiscursive exchange \nco\nlley and Moore 2020, 22)\ndi\nscussion co\nnversation or debate surrounding a particular issue\nPress \nco\nnference Videos of partial or full press conferences held by officials\ninte\nrview i\nnterviews between individuals\nre\nportage re\nporting of an event by press or individuals\nl\nivestream The live filming and transmission of an event\ncom\npilation an e\ndited collection of videos, clips, reporting, etc.\ncamp\naign Video Videos created by political consultants or staff with a direct promo-\ntional purpose\nMeme Videos of a typically humorous nature with viral qualities\naud\niobook a\n video containing a narrativized recording of a book\noth\ner an\ny content that does not fit in the above categories\nOn 4chan a significant number of videos shared were categorized as \nshitposting, followed by discussion and clip (see Table\u00a04.2). On Reddit, \nthe top categories differed, with audiobooks, discussions, and inter -\nviews making up the top three. There was likewise a much higher level \nof homogeneity among videos shared on Reddit: only five of the twelve \ncategories appeared on Reddit, while 4chan\u2019s shared videos ran across \nthe different types.\nTable\u00a04.2  Y ouTube video types per platform (Reddit and 4chan).\nVideo type Reddit appearances 4chan appearances\ncl\nip 17.0 4% 30.81%\nShitposting 0% 18.23%\ndi\nscussion 22.69% 12.88%\nPress \nco\nnference 0% 5.93%\ninte\nrview 26.2% 2.77%\nre\nportage 24% 8.36%\nl\nivestream 0% 2.21%\ncom\npilation 0% 10.02%\ncamp\naign Video 0% 5.37%\nMeme 0% 2.12%\naud\niobook 10.07% 0%\noth\ner 0% 1.31%\nWhen MiSi nfor MaTi on M igra Te S 73\nThe decline of the alternative influence network\nWhile these categories were not used in the first round of data collection, \nqualitative observation of the data indicates that the type of videos shared \nshifted strongly over two datasets: the direct viewer address of alt-right \npolitical punditry gave way to a documentarian form of video clip, usually \ntaken out of its overall context, designed to act as \u201cunmediated\u201d footage \nof depicted events. At the beginning of the election period, videos from a \ngroup of alt-right pundits that Rebecca Lewis calls the \u201calternative influence \nnetwork\u201d constituted these spaces\u2019 video culture. The AIN is a group of \nloosely associated pundits that form a sort of \u201cnetwork,\u201d in Lewis\u2019s terminol -\nogy, by appearing on each other\u2019s YouTube channels and repeating talking \npoints brought up by websites such as Breitbart and the Daily Caller. The \ncast of characters on this network differentiate themselves by peddling \ntheir own particular brands of misinformative and conspiratorial content \nthat ideologically speaking ranges from the Trumpian Republican party \nline to neo-Nazism. AIN member Richard Spencer regularly propagandizes \nfor a white ethnostate (Kaplan, 2017); Paul Joseph Watson of Prison Planet \npushes the conspiracy that 9/11 was a covert government operation (Hines, \n2018); Jordan Peterson shot to fame by claiming a Canadian government bill \nintroducing gender identity as grounds for discrimination was an example \nof creeping \u201cpost-modern radical leftism\u201d (Peterson, 2016). The AIN could be \ndescribed as reactionary politics pivoting to video: by explicitly positioning \nthemselves as alternatives to legacy and mainstream news outlets, members \ncan adopt the techniques of social media influencers to \u201cbuild audiences \nand \u2018sell\u2019 them on far-right ideology\u201d (Lewis, 2018, p.\u00a04).\nIn the earlier dataset, these links made up 596 of the total YouTube links \nshared on 4chan, and 3989 of the links shared on Reddit. The second dataset \npaints a different picture of the video cultures of the deep vernacular web: \nthe AIN made an appearance on 4chan just 337 times, for a 42.5% reduction, \nwhile Reddit users shared videos from the AIN just 458 times, a reduction \nof 88.6%. The Reddit numbers are likewise boosted by 378 shares of a video \nby Mike Cernovich titled \u201cUn/Convention: Exposing Fake News at the RNC \nand DNC\u201d (2016). The second-most popular AIN members\u2014Ben Shapiro\u2019s \n\u201cDaily Wire,\u201d Rick Rubin\u2019s \u201cRubin Report,\u201d and Tim Pool\u2014were only shared \n15 times apiece.\nOne possible explanation is that a combination of deplatforming and \nsubreddit banning could explain their decline, but it does not bear out. The \nmost popular AIN figures on 4chan and Reddit in the earlier dataset, Joe Ro -\ngan and Ben Shapiro (\u201cPowerfulJRE\u201d and \u201cThe Daily Wire,\u201d in channel-name \n74 anTh ony gl yn bu rTon  \nterms), remain on YouTube, as do 4chan\u2019s two favorites, Sargon of Akkad and \nTarl Warwick (\u201cThe Thinkery\u201d and \u201cStyxhexenhammer666,\u201d respectively). \nAnd while Reddit banned a significant number of subreddits between the \nfirst and second data collection periods, as detailed above, this would have \nno bearing on 4chan\u2019s sharing numbers, which show a decline in viewing \nby nearly half.\nAlternative or mainstream influence network?\nFrom the purview of the subcultural spaces under study, the AIN\u2019s desig -\nnation as alternative could be revisited. Put differently, they could have \nmainstreamed or normified, in the sense that all the figures above as well \nas many others in the AIN still enjoy robust followings and high YouTube \nsubscriber counts outside of the subcultural spaces discussed here. Yet \nthe video consumption tastes of their original fans seem to have shifted. \nInstead of pointing to AIN pundit commentaries on political clips, they point \nincreasingly to clips discussed by lesser-known YouTube accounts. Three of \nthe top five shared YouTube videos on 4chan in the second dataset fall under \nthis category, and all are documentary-style recordings recontextualized \nto articulate a particular political or empirical theory by non-AINs. One \n\u201cAmy Adams\u201d has two of the top shared videos. The first is a 35-second \nundated clip of Joe Biden, posted in 2016, titled \u201cSHOCKING: Joe Biden \ndiscusses the left\u2019s globalist agenda\u201d (Adams 2016). The other is \u201cKRAKEN \nUNLEASHED: The press conference they don\u2019t want you to see\u2026\u201d (2020). \nAnother is a 70-second clip from 2017 titled \u201cSenator Schumer says God \nmade him a guardian of Israel,\u201d posted by the user \u201cIf Americans Knew,\u201d who \ndescribe themselves on their biography page as \u201can independent research \nand information dissemination institute, with particular focus on the \nIsraeli-Palestinian conflict, U.S. foreign policy regarding the Middle East, \nand media coverage of this issue. Specifically, the organization\u2019s objective is to provide information that is to a large degree missing from American press coverage of this critical region\u201d (2017).\nMigrating misinformation\nTwo observations may be made from a comparison of these two periods. \nWhen it comes to \u201ccleaning up\u201d the junk news strewn about on a platform, \neliminating spaces\u2014not necessarily users, which would be considered \ndeplatforming and is another discussion (see, e.g., Rogers, 2020; de Keule -\nnaar and Burton, 2021; Urman and Katz, 2020)\u2014may lead to precipitous \nWhen MiSi nfor MaTi on M igra Te S 75\nreductions. Reddit\u2019s banning of politically charged subreddits, especially the \nnotorious r/the_Donald, coincided with a steep decline in dubious content \non Reddit. The amounts also dwarf those in comparison with 4chan. If we \nthink of the changes in 4chan data as a rough way to normalize the Reddit \nchanges, the fact that only 4% of links were categorized as junk news at all \n(let alone a particular type of junk news) while the amount of junk news on \n4chan remained relatively stable lends credence to arguments concerning \nthe effectiveness of such actions.\nAs was found in a previous study of subreddit closures, users of r/the_Don -\nald are not known to have migrated en masse to any other particular subred -\ndit but rather moving to the group of independent \u201c.win\u201d platforms (Goforth, \n2021). While the \u201c.win\u201d platforms were outside the scope of this study, it\u2019s \nalso possible that some of the purged users from Reddit made their way to \n4chan/pol/ after June\u00a02020. It could explain the rise of conspiratorial content \non 4chan in the run-up to the election: not necessarily a shift in existing \nuser sentiment, but a migration of users themselves. It is worthy of further \ninvestigation given how that subreddit and /pol/ have been credited with \nan outsize influence on the spread of political misinformation (Blackburn, \n2018; Zanettou et al., 2017).\nThe second notable observation in the dataset is the decline in popularity \nof the alternative influence network in these spaces, paralleled on 4chan \nby the rise in conspiratorial \u201cfound footage,\u201d documentary-style clips. Out \nof the videos shared over 100 times on 4chan in the run-up to the election, \nthese clips made up 30.81% of all total videos\u2014almost double the runner-up, \n\u201cshitposting,\u201d at 18.23%. While these clips do not carry the explicitly political \nexplanations or expressions that characterize the AIN, they instead act to \nsupport pre-existing conspiratorial narratives on the far right. Adopting the \ngeneric affordances of documentary footage, they play into narratives of \nelection irregularities, COVID-19 hoax theories, and Hunter Biden\u2019s alleged \nties to Ukraine. Thus, the stark rise in conspiratorial links on 4chan is \nparalleled by the rise in popularity of these fodder-style videos, which is \nlikewise paralleled by Reddit\u2019s closing of r/the_Donald and other politically \nunsavory subreddits. Investigating this further would require a closer lens \non the months surrounding the subreddit\u2019s banning as well as innovations \nin method to determine an appropriate proxy for user migration, considering \nReddit\u2019s pseudonymity and 4chan\u2019s anonymity.\nWhat\u2019s clear is that the instability of contemporary platform ecologies \nrequires a robust framework for studying them across particular spaces and \nthat the open nature of hyperlinks, despite being one of the web\u2019s oldest \ninfrastructural elements, provides a way to track these spatial conflations. \n76 anTh ony gl yn bu rTon  \nIt\u2019s also clear that in order for the misinformation epidemic to stay under the \ngrasp of those tracking it, further research is needed on both the ecologies \nthat spring up on migratory platforms as well as the role these shifts play \nin the evolution of verification, epistemologies, and political narratives.\nMethod: Finding links in a web stack\nThis project consisted of two periods of data collection: from the beginning \nof the 2020 U.S. presidential campaign to its middle, and then the end of \nthe campaign and two months of its aftermath. We took Tulsi Gabbard\u2019s \ncampaign announcement for the Democratic Party nomination on January\u00a011, 2019 as marking the beginning of the campaign period. This research window \nran until March\u00a025, 2020, the day we began our data collection. The second \nround of research, conducted from January\u00a07\u201310, 2021, picked up where the \nfirst research window left off, up to December\u00a031, 2020.\nMethodologically, we oriented our data collection around the political \nspaces of the respective platforms. On 4chan, we drew our data from the /\npol/ board. Titled \u201cpolitically incorrect,\u201d /pol/ is the forum\u2019s largest board and \ncontains a few unique infrastructural syntaxes that allowed us to narrow \nour research. User posts are tagged with a small flag, which is automatically \nchosen based on the geographic location of the user\u2019s IP address. We thus \nqueried for user posts tagged with a U.S. flag in our given time periods. The \nflag is not a perfect proxy for location, because users can manually select \ncustom flags such as \u201cCommunist\u201d and \u201cEuropean\u201d alongside explicitly \noffensive and anachronistic flags like the Rhodesian flag (for context, during \nour first data collection period there were 4,173,476 posts with custom flags \non the entirety of the board, and 25,872,606 posts with U.S. flags). Users \ncannot change their flag to another geographic location, however, so while \nour collection did not incorporate users with custom flags, those U.S. flags \nwe did capture can reliably be said to originate in the U.S.\nFor Reddit, we relied on the Reddit bot named \u201cuserleansbot,\u201d in order to \ncollect political subreddits. Userleansbot is designed to provide \u201cinformation \nand transparency to the users engaged in political communities across \nreddit\u201d (userleansbot, 2020). Userleansbot\u2019s primary purpose is to provide \nthe political leaning of Reddit users on request. By replying to a user\u2019s \npost and tagging the bot, userleansbot analyzes the posting history of the initial poster and quantify the frequency of their participation on various \nsubreddits in order to provide an estimation of their political leanings. The \nlist from which userleansbot sources its information is crowd-sourced from \nWhen MiSi nfor MaTi on M igra Te S 77\nvarious Reddit users through personal threads as well as direct suggestions \nvia Reddit\u2019s direct messaging feature. The bot is popular on Reddit: users \nhave awarded it 50,254 karma points, a (high) score that refers to Reddit\u2019s \ninfrastructural points system that allows users to endorse the activity of \nother users (userleansbot, 2020). In order to build our list for analysis, we \ntook the list of subreddits that userleansbot relies on to code partisanship \nand then selected those subreddits that dealt with U.S. national politics.\nIn the first round of data collection, we began our research by employing \nthe \u201cneedle-to-haystack\u201d method (Hagen and Jokubauskaite, 2018). This \nmethod entails inductive investigation, looking for a \u201cneedle\u201d of particularly \ndefined URLs within the \u201chaystack\u201d of collected data. We employed the \n4chan Capture and Analysis Toolkit, or 4CAT (Peeters and Hagen, 2018), to \ncollect all posts in our time range from 4chan/pol/ with U.S. flags, and from \nour collected political subreddits. Given that our initial research questions \nrevolved around the presence of \u201cpink slime\u201d websites outlined in Bengani \n(2019), we used a list of these websites as our needle and our collected data as \nthe haystack. There were no pink slime websites found in either dataset. We \nthen turned to the \u201chaystack-to-needle\u201d method, taking a deductive approach \nto investigate the news ecologies of each space. In our first collection period, \nwe wrote a python script to filter for a regular expression that matched \nURLs to construct this dataset. In the second collection period, we used \n4CAT\u2019s functionality to extract hostnames from our datasets (which uses a similar regular expression strategy on its backend).\nHostnames were then manually coded according to the coding schema \nadapted from Benkler et al.\u2019s study of the media ecologies of the 2016 U.S. \nelection (Table\u00a04.1), using a combination of the qualitative study of each \nwebsite\u2019s front page alongside information from Media Bias/Fact Check \n(2020) (when the political valence was still unclear after consulting Media \nBias/Fact Check, both NewsGuard and AllSides.com were used). Media Bias/\nFact Check codes websites according to their political partisanship into 9 \ncategories, using a qualitative methodology to rank sources on 4 metrics: \nBiased Wording/Headlines, Factual/Sourcing, Story Choices, and Political \nAffiliation. While we drew basic readings from Media Bias/Fact Check, we \nused it as a guide for our first reading of the websites as opposed to adapting \nits coding schema directly because of its breadth. We coded news websites \nas those that adhered to journalistic standards, while websites that made \nno attempt or posture towards the appearance of presenting news were \ncoded as \u201cnon-news.\u201d The remainder, which we classified as \u201cjunk news,\u201d \nwas further split into conspiracy (circulating conspiratorial narratives), \npropaganda (misrepresenting facts for political aims), and sensational \n78 anTh ony gl yn bu rTon  \n(websites aiming to emphasize salacious perspectives or \u201cclickbait\u201d-style \ncontent). These coding definitions are found in Table\u00a04.3.\nTable\u00a04.3  C oding schema for hostnames. Adapted from Benkler et al., 2019.\nCode Definition\nnew\ns Websites that adhere to a framework of \u201cprofessional journalistic \nnorms,\u201d including the imposition of \u201chigher reputational costs on sites and authors who propagate rumor\u201d and the focus on \u201crelatively rapid fact checking, criticism of false claims, and rapid dissemination of and coalescence around corrected narratives\u201d (2018, p.\u00a074).\ncon\nspiracy Sites whose primary narrative or ideological focus is \u201calternative,\u201d \u201cconspiratorial,\u201d or otherwise outside of mainstream established truths as articulated by outlets who fall under the \u201cnews\u201d category.\nPropaganda\nco\nntent focused on \u201cmanipulating and misleading people intentionally \nto achieve political ends\u201d (2018, p.\u00a024).\nSensationalist cl\nickbait or disinformation focused on \u201cpartisan-confirming news \nemphasized over truth.\u201d \nas d\nistinct from propaganda, sensationalist \ncontent is organized based on the acquisition of attention (and, in turn due to the infrastructure of digital news, profit) as opposed to intentional political manipulation (2018, p.\u00a0274).\ncamp\naign an\ny website directly related to or directly promoting the political \ncampaign of a presidential candidate or public servant\nno\nn-news an\ny website that does not fall into the above categories (examples \ninclude Wikipedia, \nyo\nuTube, recipe websites, etc.).\nNews was further divided based on a rough indication of political and \nideological biases, based on an expert list informed by such media and \nnews bias sources as Allsides.com, Media Bias/Fact Check and NewsGuard \n(see Table\u00a04.4).\nTable\u00a04.4  P olitical valence coding scheme with examples.\nPolitical valence Examples\nne\nutral NBC ; Monthly Review\nl\niberal The Guardian ; The Nation\ncon\nservative Fox News ; Wall Street Journal\nada pted from Media bi as/fa ct ch eck, al lSides, and ne wsgua rd.\nIn the first observational period of this research, we selected our news sites \nto code based on whether they appeared over 2,000 times on Reddit and \n400 times on 4chan. From this, our coding dataset contained 204 websites \nWhen MiSi nfor MaTi on M igra Te S 79\nfrom Reddit and 182 from 4chan. We used Bernhard Reider\u2019s YouTube Data \nTools (2015) to collect video metadata, including category, view count, date \npublished, and title. Since the YouTube Data Tools use the YouTube API, \nwhich occasionally returns malformed data, we scripted a separate call in \nPython to the YouTube API that individually verified each video returned and whether it was deleted since its appearance in the links dataset.\nBoth our tooling and sampling criteria were changed for the second \nobservational period. Between our observational periods, Reddit banned four \nsubreddits that together constituted a large portion of data in our first study: \nr/ChapoTrapHouse, r/The_Donald, r/RightwingLGBT, and r/TheNewRight (Ingram and Collins, 2020). Our second observational period spanned the \nperiod of 9\u00a0months, in contrast to the 15\u00a0months observed between Janu -\nary\u00a02019 and March\u00a02020. Because of this smaller window, we reduced the \ncut-off we used for coding hostname links on Reddit from 2,000 to 100, which \nresulted in 220 hostnames from Reddit being coded. On 4chan, likewise, \nwe reduced the cutoff for coding websites from 400 mentions to 200, which \nyielded 219 results. Regressions and limitations introduced into YouTube\u2019s \nAPI between the first observational period and the second led us to writing \na custom script using youtube-dl (ytdl-org, 2021), in order to capture video \nmetadata. Instead of using YouTube\u2019s API, youtube-dl programmatically \nscrapes the information from the video by simulating the loading of what \na casual user would see on a video page. While this took longer to run than \nusing the YouTube Data Tools, our requests were not malformed or subject \nto the unknowns of YouTube\u2019s API interface.\nReferences\nAdams, A. (2016, August\u00a025). SHOCKING: Joe Biden discusses the left\u2019s globalist \nagenda. https://www.youtube.com/watch?v=KaCBYrVsic4. Accessed April\u00a021, \n2021.\nAdams, A. (2020, November\u00a020). KRAKEN UNLEASHED: The press conference \nthey don\u2019t want you to see\u2026 https://www.youtube.com/watch?v=_u34jhCKT2U. \nAccessed April\u00a021, 2021.\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBlackburn, J. (2018, February\u00a016). How 4chan and The_Donald influence the \nfake news ecosystem . FIC Observatory. https://observatoire-fic.com/en/\n80 anTh ony gl yn bu rTon  \nhow-4chan-and-the_donald-influence-the-fake-news-ecosystem-by-jeremy-\nblackburn-university-of-alabama-at-birmingham/. Accessed April\u00a021, 2021.\nBuyukozturk, B., Gaulden, S. and Dowd-Arrow, B. (2018). Contestation on Reddit, \nGamergate, and movement barriers. Social Movement Studies , 17(5), pp.\u00a0592\u2013609. \nhttps://doi.org/10.1080/14742837.2018.1483227\nCernovich, M. (2016, September\u00a014). Un/Convention: Exposing fake news at the RNC \nand DNC. YouTube video. https://www.youtube.com/watch?v=cNwgKR88UDo.\nColeman, E.G. (2014). Hacker, hoaxer, whistleblower, spy: The many faces of Anony -\nmous . Verso.\nColley, T. and Moore, M. (2020). The challenges of studying 4chan and the Alt-Right: \n\u201cCome on in the water\u2019s fine.\u201d New Media & Society , 1461444820948803. https://\ndoi.org/10.1177/1461444820948803.\nCoppins, M. (2020, March). The billion-dollar disinformation campaign to reelect the \npresident. The Atlantic . https://www.theatlantic.com/magazine/archive/2020/03/\nthe-2020-disinformation-war/605530/.\nDonovan, J. and boyd, d. (2018, June\u00a01). The case for quarantining extremist \nideas. The Guardian . http://www.theguardian.com/commentisfree/2018/jun/01/\nextremist-ideas-media-coverage-kkk.\nEinwiller, S.A. and Kim, S. (2020). How online content providers moderate user-\ngenerated content to prevent harmful online communication: An analysis of \npolicies and their implementation. Policy & Internet , 12(2), pp.\u00a0184\u2013206. https://\ndoi.org/10.1002/poi3.239.\nGoforth, C. (2021, January\u00a021). Notorious pro-Trump forum rebrands as \u201cpatriots\u201d \nafter post-Capitol riot infighting. The Daily Dot . https://www.dailydot.com/\ndebug/pro-trump-site-renamed-internal-conflict/.\nGray, J., Bounegru, L., and Venturini, T. (2020). \u201cFake news\u201d as infrastructural uncanny. \nNew Media & Society , 22(2), pp.\u00a0317\u2013341. https://doi.org/10.1177/1461444819856912.\nHagen, S., Burton, A., Wilson, J., and Tuters, M. (2019, September\u00a08). Infinity\u2019s abyss: An \noverview of 8chan. OILab . https://oilab.eu/infinitys-abyss-an-overview-of-8chan/.\nHagen, S. and Jokubauskaite, E. (2019). Dutch junk news on 4chan and Reddit /\npol/. In R. Rogers and S. Niederer (Eds.), The politics of social media manipulation \n(pp.\u00a0115\u2013151). Dutch Ministry of the Interior and Kingdom Relations.\nHines, N. (2018, April\u00a022). Alex Jones\u2019 proteg\u00e9, Paul Joseph Watson, is about to \nsteal his crackpot crown. The Daily Beast . https://www.thedailybeast.com/\nalex-jones-protege-paul-joseph-watson-is-about-to-steal-his-crackpot-crown.\nHoward, P. N., Bolsover, G., Kollyani, B., Bradshaw, S., and Neudert, L.-M. (2017). \nJunk news and bots during the U.S. election: What were Michigan voters sharing \nover Twitter?  Data Memo 2017.1, Project on Computational Propaganda, Oxford \nInternet Institute. http://blogs.oii.ox.ac.uk/politicalbots/wp- content/uploads/\nsites/89/2017/03/What-Were-Michigan-Voters-Sharing-Over-Twitter-v2.pdf.\nWhen MiSi nfor MaTi on M igra Te S 81\nIf Americans Knew. (2017, February\u00a03). Senator Schumer says God made him a guard -\nian of Israel. YouTube video. https://web.archive.org/web/20210417224317/https://\nwww.youtube.com/c/IfAmericansKnew-Video/about. Accessed August\u00a02, 2020.\nIngram, D. and Collins, B. (2020, June\u00a029). Reddit bans hundreds of subreddits for \nhate speech including Trump community. NBC News . https://www.nbcnews.\ncom/tech/tech-news/reddit-bans-hundreds-subreddits-hate-speech-including-\ntrump-community-n1232408.\nKaplan Sommer, A. (2017, October\u00a019). White nationalist Richard Spencer gives \nIsrael as example of ethno-state he wants in U.S. Haaretz . https://www.haaretz.\ncom/us-news/richard-spencer-gives-israel-as-example-of-ethno-state-he-wants-\nin-u-s-1.5459154.\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on \nYouTube.  Data & Society Research Institute. https://datasociety.net/library/\nalternative-influence/.\nLewis, R. (2020). \u201cThis is what the news won\u2019t show you\u201d: YouTube creators and the \nreactionary politics of micro-celebrity. Television & New Media , 21(2), pp.\u00a0201\u2013217. \nhttps://doi.org/10.1177/1527476419879919.\nMassanari, A. (2017). #Gamergate and the fappening: How Reddit\u2019s algorithm, \ngovernance, and culture support toxic technocultures. New Media & Society , \n19(3), pp.\u00a0329\u2013346. https://doi.org/10.1177/1461444815608807.\nMedia Bias/Fact Check (2020). Filtered search. https://mediabiasfactcheck.com.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nPeeters, S. (2020, May\u00a015). Normiefication of extreme speech and the wid -\nening of the Overton window. Open Intelligence Lab. https://oilab.eu/\nnormiefication-of-extreme-speech-and-the-widening-of-the-overton-window/.\nPeeters, S. and Hagen, S. (2018). 4CAT: 4chan Capture and Analysis Toolkit [soft -\nware]. https://4cat.oilab.eu.\nPeterson, J. (2016, November\u00a0 8). Jordan Peterson: The right to be po -\nlitically incorrect. National Post. https://nationalpost.com/opinion/\njordan-peterson-the-right-to-be-politically-incorrect.\nPhillips, W. (2018). The oxygen of amplification. Data & Society Research Institute. \nhttps://datasociety.net/output/oxygen-of- amplification/.\nReider, B. (2015). YouTube Data Tools [software]. https://tools.digitalmethods.net/\nnetvizz/youtube/index.php.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nShao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., and Menczer, F. \n(2018). The spread of low-credibility content by social bots. Nature Communica -\ntions, 9 (1), p.\u00a04787. https://doi.org/10.1038/s41467-018-06930-7.\n82 anTh ony gl yn bu rTon  \nTuters, M. (2019). LARPing & liberal tears: Irony, idiocy & belief in the deep ver -\nnacular web. In M. Fielitz and N. Thurston (Eds.) Post-digital cultures of the far \nright: Online actions and offline consequences in Europe and the U.S. (pp.\u00a037\u201348). \nTranscript.\nUrman, A. and Katz, S. (2020). What they do in the shadows: Examining the far-right \nnetworks on Telegram. Information, Communication & Society , pp.\u00a01\u201320. https://\ndoi.org/10.1080/1369118X.2020.1803946.\nuserleansbot. (n.d.). List of political subreddits used by userleansbot. Reddit. \nhttps://www.reddit.com/user/userleansbot/comments/cfzho2/list_of_politi -\ncal_subreddits_used_ by_userleansbot/.\nytdl-org. (2021, February\u00a01). Youtube-dl . Youtube-Dl: Download Videos from YouTube \n(and More Sites). http://ytdl-org.github.io/youtube-dl/.\nZannettou, S., Caulfield, T., De Cristofaro, E., Kourtelris, N., Leontiadis, I., Sirivianos, \nM., Stringhini, G., and Blackburn, J. (2017). The web centipede: Understanding \nhow web communities influence each other through the lens of mainstream \nand alternative news sources. Proceedings of the 2017 Internet Measurement \nConference IMC\u201917  (pp.\u00a0405\u2013417). ACM. https://doi.org/10.1145/3131365.3131390.\nAbout the author\nAnthony Glyn Burton  is SSHRC Joseph Armand Bombardier Doctoral \nScholar in the Department of Communication, Simon Fraser University \nand holds a SFU-Mellon Critical Data Studies fellowship at the Digital \nDemocracies Institute. His dissertation work investigates the relationship \nbetween optimization and fascism.\n5 F ringe players on political Twitter\nSource-sharing dynamics, partisanship and problematic \nactors\nMaarten Groen and Marloes Geboers\nAbstract\nFocusing on the (early) run-up to and aftermath of the 2020 U.S. \npresidential elections, this study examines the extent of problematic \ninformation in the most engaged-with content and with the most active \nusers in \u201cpolitical Twitter.\u201d It was found that mainstream sources are \nshared more often than problematic ones, but their percentage was much \nhigher prior to the Capitol riots of January\u00a02021. Significantly, (hyper)\npartisan sources are close to half of all sources shared, implying a robust \npresence. By March\u00a02021, though, both the share of problematic and of \n(hyper)partisan sources decreased significantly, suggesting the impact \nof Twitter\u2019s deplatforming actions. Additionally, active, problematic users \n(fake profiles, etc.) were found across the political spectrum, albeit more \nabundantly on the conservative side.\nKeywords: hyperpartisanship, misinformation, U.S. elections, deplatform -\ning, Capitol riots, digital methods\nResearch questions\nTo what extent are problematic sources present in the most engaged-with \ncontent in political and social issue spaces on Twitter in the run-up to and aftermath of the 2020 U.S. elections? Has Twitter\u2019s deplatforming affected \nthe quality of sources shared? Are there problematic users among the most \nactive, and are they typically of a particular political leaning?\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch05\n84 M aar Te n gr oen and Marloe S  ge boer S \nEssay summary\nTo probe the extent to which problematic sources are present on political \nTwitter, the study queries political keywords and investigates the most \nshared news sources and their credibility as well as the most active users, \ntheir authenticity and partisanship. Problematic sources refer to Jack\u2019s \ncharacterization as containing information that is \u201cinaccurate, mislead -\ning, inappropriately attributed, or altogether fabricated\u201d (2017, p.\u00a01). Most \nengaged-with  content on Twitter refers to the most retweeted tweets and/\nor most frequently shared sources within the given time periods. Most \nactive users or accounts are those with the highest tweeting activity, and \nproblematic ones are fake accounts, bots or locked/suspended users. Political \nand issue spaces on Twitter (or \u201cpolitical Twitter\u201d) refer to the result sets \nfrom keyword and hashtags queries for presidential candidates, political \nparties and social issues.\nIn March\u00a02020 the amount of problematic news sources shared on Twit -\nter was 16% of all shared news sources. By December\u00a02020 the share of \nproblematic news sources almost had doubled to 30%. In March\u00a02021 we \nfound a sharp decline in those shared, at just over 10%. While it may have \nto do with the decline in source sharing during that time frame, it also \ncould reflect the significant purge of user accounts by Twitter in the days \nafter the Capitol riots of January\u00a06. The purge likely affected users who were \ninvolved in sharing problematic sources.\nIn the first two time spans under study (March\u00a02020 and December\u00a02020/\nJanuary\u00a02021), close to half of the non-problematic sources circulating the \nnews were classified as (hyper)partisan,1 suggesting that Twitter, like Fa -\ncebook before it, is a platform where such sources perform well (Silverman, \n2016). In March\u00a02021, the third timeframe, we saw a drop to 34% in that \ncategory. The first two periods set themselves apart from the third in that \nthey witnessed the dominance of conservative (hyper)partisan sources \nwhich were no longer as strongly in evidence in the third period of time \n(after the deplatforming).\nIn terms of the users, in 2016 it was mostly pro-Republican fake and bot \naccounts that shared problematic information on Twitter (Bovet and Makse, \n2019). We noticed, however, that there are also pro-Democrat fake and bot \n1 (H yper)partisan is used with the parentheses not only to indicate an amalgamation of \nthe hyperpartisan and partisan source types, but also to signal the difficulty in consistently \ndisentangling them. Below we use (hyper)partisan when discussing sources that were labeled \nas such in the study.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 85\naccounts actively circulating such information. In addition, instead of using \ntheir own hashtags, both Democrat and Republican supporters tend to use \neach other\u2019s hashtags to draw attention from their opposition.\nImplications\nEver since its tagline changed from What are you doing? to What\u2019s happening? \n(2009) Twitter has become regarded less as an ambient friend-following \nmedium than as a \u201creporting machine\u201d at least in the Western social media \nrealm (Rogers, 2014; Tate, 2009). In the past decade, Twitter also has been \nregarded as a space for doing politics, exemplified by Donald Trump\u2019s usage \nof the platform as a political tool in his campaigning for the presidency \nin 2015\u20132016 and later by its integration into his administration. Trump\u2019s \ntweeting changed the nature of the presidency and allowed him to leverage a \nrelatively novel form of media power (Enli, 2017), at least up until the banning \nof his account on January\u00a08, 2021, as a response to the Capitol building riots \nand violence two days before, given the role that Trump played in fueling \nand \u201cglorifying\u201d them.\nGiven the dominant presence of Trump on Twitter, but also of other \ncandidates and their supporters and observers, it arguably became the \nkey social media platform where the politics of the 2020 U.S. presidential \nelections played out. Trump\u2019s \u201cpopulist anger\u201d (Wahl-Jorgensen, 2019, p.\u00a0117) \nwas not only on display on Twitter but connected to a hybrid media system \nin which mainstream media co-mingle with \u201cfringe\u201d players (Chadwick, \n2017; Wahl-Jorgensen, 2019). It is the extent of this co-mingling that one is able to study on Twitter.\nIn this regard, it is important to note how social media posting not \nonly \u201cfolds into\u201d (Niederer, 2019, pp.\u00a0119\u2013120) the content of mainstream \nmedia (within which we distinguish more or less partisan sources) but \nalso impacts their \u201caffective styles\u201d (Wahl-Jorgensen, 2019, p.\u00a0116). A broad \nset of transformations have accompanied these new media, enabling a \nmedia regime to emerge in which there is a \u201cnormalization of a new set of \n\u2018emotion rules\u2019 that allow a president to consistently make statements that \nare verifiably false, be called out on these falsehoods and pay no political price for them\u201d (Delli Carpini, 2018, pp.\u00a018\u201320).\nTwitter is a space that is vulnerable to problematic information and \nthe presence of potentially problematic users such as fake accounts and \nbots (Boyd et al., 2018). We identified such problematic activity during \nthe periods under study, each of which with distinctive user activity. The \n86 M aar Te n gr oen and Marloe S  ge boer S \ninitial time span is the period around \u201cSuper Tuesday\u201d on March\u00a03, 2020, \nwhen the greatest number of states hold their primaries or caucuses. We \nthen repeated our analyses in the final days of 2020 from late December \nup until January\u00a04, 2021, which covers the post-election time span and the \nsignificant U.S. Senate run-off elections in Georgia on January\u00a05 which \nwould result in a Senate majority for the Democrats. In retrospect, these \ndays were also close to the Capitol riots of January\u00a06 that were spurred by \nongoing speculations about election fraud. This time frame represents a \nTwitter discourse centering on speculations concerning the balance of \npower after the Senate run-offs as well as allegations of election fraud and \nsubsequent calls for protesting the \u201cvote steal.\u201d The final time span under \nstudy covers March\u00a010 to 22, 2021 and can be characterized as not only \npost-election but also post-purge after Twitter deplatformed over 70,000 \naccounts (many linked to QAnon conspiracies) between January\u00a09 and 12, in response to the aforementioned riots (Conger, 2021).\nOverall, our findings show that mainstream sources outperform (or are \nshared more often than) problematic sources on political Twitter. Though \nthe circulation of problematic sources was higher just after the election, \nthey never outperformed mainstream sources as was the case on Facebook \nin the run-up to the 2016 elections (Silverman, 2016). We do see a significant \ndrop in March\u00a02021 in the circulation of problematic sources after the \nTwitter purge.\nIn both March\u00a02020 and December\u00a02020/January\u00a02021 nearly half of the \nsources shared were coming from sources that we sub-categorized as (hyper)\npartisan progressive or (hyper)partisan conservative. We also witnessed a \nnoticeable uptick in problematic sources shared in the aftermath of the elec -\ntions which spans the weeks in which the Twitter discourse was dominated \nby allegations of electoral fraud. While (hyper)partisan sources do not share \nconspiracy or pseudo-science and are not problematic in that sense, the \nfindings point to a particular kind of hybrid media landscape. It provides \nplenty of space for (hyper)partisanship and problematic information to \nco-mingle with mainstream sources. Put differently, mainstream news is \nincreasingly confronted with more partisan players in the field, at least on \nTwitter in the run-up to and aftermath of the U.S. elections.\nThough beyond the scope of this study, our findings imply that more \nproblematic information is engaged with on social media than in other online \nmedia spaces such as the web, where the top-ranked media properties (by \ntraffic) are rather mainstream and include NBC, CBS, Disney and Turner \n(ComScore, 2019), though a separate measure should be taken of the \u201cpolitical \nweb.\u201d This disparity between Twitter and the web aligns with what Barnidge \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 87\nand Peacock (2019) point out concerning the reliance on social media for \nthe dissemination of hyperpartisan (and problematic) sources.\nIn the run-up to the presidential elections in 2016, multiple studies \nindicated that suspect accounts were mostly spreading problematic, pro-\nRepublican information on Twitter (Bovet and Makse, 2019). During the cam -\npaigning and in the (immediate) aftermath of the 2020 elections, however, \nwe also identified problematic, pro-Democrat accounts actively spreading \nproblematic information across Twitter, though they do not outnumber \nthose on the other side of the political spectrum. That is, compared to the \nfindings of previous studies concerning the type of problematic accounts, \nto date there are indications of a shift from mainly conservative to a mix \nof conservative as well as progressive problematic accounts. Additionally, \namong the datasets of most active users we found more problematic accounts \nthan authentic ones, implying that highly active accounts during election campaigning deserve scrutiny.\nWith respect to the most engaged-with tweets, the vast majority is posted \nby influential users, and they do not circulate many problematic sources. \nThe finding indicates that most retweeted content (rather than most tweeted \ncontent only) is a quality indicator, at least in this brief study. The role of \nfollower counts is thus important as there is a direct relationship between follower and retweet counts. If problematic users would attain influential masses of followers, such analyses might look different.\nIn light of the societal consequences of disseminating problematic or \nhyperpartisan sources, it is important to stipulate that the link between \nsharing and the actual visibility of such sources is not clear cut, given how \nvisibility is algorithmically determined. We can assume a higher probability \nof exposure, however, when tweets are retweeted (Kwak et al., 2010). Meier \net al. (2014) found that retweeting and liking could be regarded as audience \nengagement in a conversation and attention to the messages, which facilitates \ninformation transmission.\nSituating the findings: Diversification and polarization on \nTwitter\nWe situate our findings around the sharing of problematic and non-\nproblematic sources in the affordances of a platform that, to a certain \nextent, democratized news sharing in the sense of opening the gates for \nnon-mainstream sources to circulate and be amplified. In order for sources \nto be successful on Twitter, we need to understand both how people are \n88 M aar Te n gr oen and Marloe S  ge boer S \nexposed to news sources and what makes (news) content prone to ampli -\nfication in that realm. The rise of social platforms has posed challenges \nto theorizing selective exposure to news. Barnidge and Peacock (2019) \ndistinguish two ways in which social media have restructured selective \nexposure to news. Both ways provide a means to assess the implications \nof our findings that social media diversify social connections and facilitate \nthe rise of hyperpartisan news.\nThe diversification aligns with Bruns\u2019s reflections (2019) on the existence \nof filter bubbles and echo chambers (Pariser, 2011; Sunstein, 2001). Such \nstructures of isolated communities are based on a belief that social media \ninevitably promote echo chambers and filter bubbles as they personalize \ncontent to the extent that individuals consume news in isolated ways. \nEmpirical research into the existence of such structures have not found \nevidence to support this belief (O\u2019Hara and Stevens, 2015; Barnidge, 2017). \nBruns (2019) modified these concepts through introducing degrees of \n\u201cbubbleness\u201d or \u201cchamberness\u201d: scholars can quantify the extent to which \npeople connect or communicate within and beyond ideological groups. This \nmodification does justice to the fact that by far most people use multiple \nsources for their news consumption (Dubois and Blank, 2018) and that \npeople befriend others not just on the basis of their political leanings. Bruns \n(2019) backs the latter argument by stating how people are not primarily \non social media (or at least on Facebook) to talk politics. We would like to \nnote that Twitter\u2019s use culture is more geared toward talking politics than is Facebook\u2019s, for example, which might lead to different ways of curating one\u2019s social network.\nThough Twitter users may have diverse social networks and the infor -\nmation that people are exposed to is varied, the findings from our study \nunderscore how sharing sources seems to largely follow one\u2019s own political \nleaning: in the datasets where Republican leaning users were most active, \nthe (hyper)partisan sources were mainly conservative in kind and vice versa. \nNote, too, how the Republicans are overrepresented in the data demarcated \nby keywords pertaining to the Democrats, which is related to how Twitter users are calling out or attacking their opponents in their tweets.\nWithin all datasets we found a pattern whereby users employ the op -\nposition\u2019s keywords and hashtags, in order to target each other. It occurs \nin political spaces organized around both political parties and candidates. \nWithin these supporter spaces, there appear to be more sources shared that \nattack the opponent rather than support the candidate. (See also Starbird \n(2017) as well as Groshek and Koc-Michalska (2017) for investigations into \nstrategies of attack and trolling of mainstream media, especially apparent \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 89\non Twitter.) Our findings thus reiterate how the relentless targeting of people \nthrough hyperpartisan viewpoints continues and is a phenomenon practiced \non both sides of the political spectrum. One methodological implication is \nthat one cannot neatly demarcate a supporter space through hashtag and/\nor keyword queries only.\nBarnidge and Peacock (2019) point out that alongside the diversification of \ninformation described above, social media also allow hyperpartisan voices \nto reach a wider audience that is now able to share messages independently \nof mainstream media. Hyperpartisan news could be described as having \na slanted political agenda and making scant effort to balance opposing \nviews. It could be said to push anti-system messages that are critical of \nmainstream media and established politicians, relying on dubious informa-\ntion or misinformation to do so. It also depends heavily on social media for \nits dissemination (Barnidge and Peacock, 2019).\nThrough challenging mainstream narratives, hyperpartisan media also \noverlap with notions of alternative media. Strengthening Bruns\u2019s argument \nabout the absence of isolated bubbles, Peacock et al.\u2019s empirical investiga -\ntion (2019) found that strong partisans on social media are exposed to \nboth left- as well as right-leaning news. In order to proffer an \u201calternative \nperspective\u201d to mainstream news, hyperpartisan media and users have to \nmonitor mainstream sources to know how these outlets talk about issues. \nThey attach commentary to the narratives of mainstream media. As O\u2019Hara \nand Stevens point out: \u201cengaging with the enemy does not necessarily make \na group less partisan\u201d (2015, p.\u00a0418). Bruns (2019) expands on this point and \nsituates exposure to diversified information as intensifying polarization \nthrough in-group identification and providing an outside \u201cother\u201d that serves \nas an embodiment of the political enemy. We might not live in isolated \nbubbles; rather, it is the diversification of information on platforms that \nseems to spur polarization because of an increased exposure to opposing views. This observation would involve a much-needed research focus into \nhow people perceive and recontextualize news on social media to fit it into \ntheir existing beliefs.\nExpanding on Bruns\u2019 argument about \u201cporous\u201d filter bubbles and \necho chambers, we found that many tweets were formatted to call out or \nattack opponents, e.g., from the dataset that queried GOP: \u201cIf we \u2018move \non\u2019, the GOP will refuse to concede future elections, then judge-shop \nuntil they steal one. There must be a price paid for sedition or we will \nlose our democracy. This is critically important work in the next couple \nof years\u201d (Alter, 2021). This strategy of attacking opponents was apparent \nin the fact that the tweet data collected through (for example) words \n90 M aar Te n gr oen and Marloe S  ge boer S \nthat relate to Democrats contained largely Republican-leaning users \nwho were calling out or attacking Democrats and vice versa. Note for \nexample that in the March\u00a02020 Republican-oriented dataset, a tweet \nfrom a Democrat reads: \u201cReal quick: How are Republicans like Donald \nok with 2% of people dying from coronavirus as if 2% is not a very high \nnumber. But when you discuss a 2-cent wealth tax on people making over \n50 million they freak out like it\u2019s the worst thing that could ever happen \nto them\u201d (Salenger, 2020).\nMainstream media attempts to contextualize and balance the narra -\ntives injected by hyperpartisan sources. When terms like \u201cjunk news\u201d and \n\u201cconspiracy theory\u201d are invoked, they seem to trigger political backlash \n(Rogers, 2020a) and increase distrust in mainstream media. This dynamic \ncan only be further understood if affective and intuitive tactics of people \nwho are consuming and sharing news on social media are taken into account. \nAs Swart and Broersma (2021) found in their analyses of young people\u2019s \nassessments of the trustworthiness of news, it is prior knowledge, lived \nexperiences, and endorsements of sources by people within their own social \nnetworks that guide how people assess sources, which in turn plays a vital role in the choice to share particular sources over others.\nWhen it comes to sharing news, the existing literature also steers attention \ntoward the emotive underpinnings of hyperpartisan news and its effects \nwhen disseminated in the realm of social media. Twitter\u2019s business model \nis based on an attention economy, which places emotion at the forefront \nof journalistic practices. While emotion and information are not mutually \nexclusive, hyperpartisan media tend to exploit anger and a culture of outrage \n(Barnidge and Peacock, 2019; Berry and Sobieraj, 2014). Berry and Sobieraj \n(2014) move away from conventional wisdom that the rise of outrage media \nis the result of increased political polarization and argue for considering \nthe economic underpinnings of what they dub an \u201coutrage industry.\u201d They \nsituate this industry in the context of structural changes to the media \nlandscape that have fostered its exponential growth.\nTwitter as part of this new media landscape is market-driven and \ndependent on the stickiness of content circulating on its platform. What \nmakes users stick around (and share)? In the context of problematic and \nhyperpartisan news media, Berger and Milkman\u2019s study into viral news \ncontent (2012) is instructive for it examines what animates users to share \ncontent by assessing the emotive components of more and less shared \ncontent. They found that the virality of the content depends on evoking \nhigh-arousal positive (awe) or high-arousal negative (anger or anxiety) \nemotions. Content that evokes low-arousal, or deactivating, emotions (e.g., \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 91\nsadness) is less viral.2 Thus outrage is seen as viral, which sheds light on \nthe rise of hyperpartisan news on Twitter, as this kind of news is \u201cmeant \nto cause outrage, cue partisan emotions, and get clicks (i.e., make money). \nHyperpartisan news \u2026 provides low-quality news with the goal of making \nmoney from people\u2019s\u2014in many cases misguided\u2014anger and outrage\u201d \n(Barnidge and Peacock, 2019, p.\u00a06). Note, however, that a binary opposition \nbetween quality journalism that is \u201cinforming\u201d and less emotive and a \nsensationalized form that is merely emotive is false, as Wahl-Jorgensen \n(2019) also stipulates, in reference to Boltanski (1999). The creation of \nempathy is a prerequisite for political action. We want to stipulate that our \ndistinction between problematic and non-problematic sources is not based \non considerations regarding a distinction between factual and emotive \nnews sources; rather, we point to the role of exploiting outrage through \na socio-technical synergy between (hyper)partisan news outlets and a \nmarket-driven platform.\nNotwithstanding the fact that all journalistic items hold some emo -\ntion, the affordances of Twitter facilitate a discursive climate which is \nmore extreme, divisive and polarized than most mainstream news spaces \n(Shepherd et al., 2015). Trump but also hyperpartisan (and problematic) \nnews outlets have benefitted from this affective shift by crafting messages \nin such a way that they spill over to mainstream media (Karpf, 2017) that in \nturn, and perhaps unwantedly, amplify fringe players on the platform. So, \nalthough the majority of shared sources is still comprised of mainstream \nnews organizations, problematic and hyperpartisan sources are pushing \nfor more space and might have spillover effects in the form of steering \nmainstream content and affective styles of communication on the platform.\nThough investigating such spillover effects into content and style of legacy \nmedia is beyond the scope of our analyses, we did find that in political issue \nspaces such as that of DACA, mainstream media either followed uptakes \nin problematic source-sharing (see third time span, Figure\u00a05.4) or seemed \nto veer upwards after such flares in problematic source-sharing (second \ntime span, Figure\u00a05.4), suggesting that problematic sources can be at the \nforefront of constructing a particular narrative about an issue at hand that is \nthen taken up by mainstream sources. The latter dynamic can be the result \nof an algorithmically maintained power disparity between mainstream \nand fringe sources due to the intensification of majority (already popular) \n2 T hese results hold even when the authors controlled for how surprising, interesting, or \npractically useful content is (all of which are positively linked to virality), as well as external \ndrivers of attention, e.g., how prominently content was featured.\n92 M aar Te n gr oen and Marloe S  ge boer S \nvoices, a dynamic also hypothesized by among others Bruns (2019) as well as \nBozdag and Van den Hoven (2015). This observation opens a relevant future \ndirection for misinformation research which is more sensitive to detecting \nthe adoption, or the \u201cfolding in,\u201d of fringe and at times problematic sources \nin the coverage and affective styles of mainstream media.\nFindings\nFinding 1: On Twitter the number of mainstream sources attached to political \ntweets or retweets is greater than problematic sources, however much the \nhigh share of (hyper)partisan sources within mainstream sources points to \na rather polarized platform. After the Twitter purge of problematic accounts \nin January\u00a02021, the share of (hyper)partisan sources within mainstream \nsources decreased significantly.\nIn the data collected during all three time frames (March\u00a02\u201322, 2020, \nDecember\u00a024, 2020\u2013January\u00a04, 2021 and March\u00a010\u201321, 2021) around a million \nlinks to media articles were shared. Of these, overall, mainstream news \nsources outperformed problematic sources on Twitter. In March\u00a02020, the \nshare of problematic news sources shared on Twitter was 16% of all shared \nnews sources. In December, the share of problematic news sources almost \ndoubled to 30%. In March\u00a02021, the share of problematic sources dropped \nsignificantly to 11%. The source classifications are based on source labeling \nplatforms and contain two main categories indicating whether a source is \nmainstream or problematic and sub-labels for mainstream sources indicating \n(hyper)partisanship conservative or (hyper)partisanship progressive. The \npercentage of mainstream sources shared from sources subcategorized \nas (hyper)partisan decreased slightly from 48% in March\u00a02020 to 43% in \nDecember and further dropped to 33% in March\u00a02021. This drop mostly \nowes to conservative (hyper)partisan sources being less circulated. Overall, \nmainstream sources are shared more often than problematic news websites, \nthough closely after the election, there was a significant rise in the share of \nproblematic sources which decreased again in March\u00a02021.\nFinding 2: Conservative sources are shared more often when discussing \nDemocrat keywords, and in most cases progressive sources are shared more \noften when discussing Republican ones. In Twitter we queried for specific \nkeywords and hashtags (see Table\u00a05.1) that represent each party and political \ncandidate and found that in both March periods of 2020 and 2021 conservative \nsources were shared more than progressive ones when discussing Democrat \nkeywords, and vice versa (Figures 5.2 and 5.3). Only in the December/January \nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 93\nperiod the share of progressive sources in the Republican dataset was lower \nthan that of conservative sources. We also found that in both March periods \nthere were fewer problematic sources shared when discussing Republican \nkeywords than Democrat ones. In December the proportion of problematic \nsources was much higher which is a trend we see across all datasets. The \n(hyper)partisan conservative sources in December are shared more often \nacross both Republican and Democrat political spaces.\nThis finding is in contrast with the results in the other two periods that \nindicate a crossover of information where (hyper)partisan conservative \nsources were shared in the Democrat issue space and (hyper)partisan \nprogressive sources were shared in the Republican. The change in December \nindicates that in the aftermath of the elections, Democrats continue to \nattack Donald Trump and the Republican party while some problematic \nand conservative (hyper)partisan sources seem to make a shift and even \nattack Republicans in the December/January time period when the alleged \nelection fraud was a major topic. One example of this shift is an article3 \n3 https://www.thegatewaypundit.com/2020/12/raffensperger-gets-caught-georgia-ballots-\nprinted-differently-gop-counties-vs-dem-counties-election-rigged/\nfi gure\u00a05.1 cu mulative total of mainstream and problematic hosts shared on political Twitter over \nthree time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, 2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n94 M aar Te n gr oen and Marloe S  ge boer S \nfi gures 5.2 and 5.3 cum ulative total of mainstream and problematic hosts shared on political \nTwitter when querying \nre\npublican or \nde\nmocrat terms for three time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, 2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 95\nby the Gateway Pundit which made up 25% (23,000 shares) of the total of \nproblematic content shared in that 4-day period, attacking a Republican \nin Georgia (who had not followed Trump\u2019s wishes). In terms of hashtag \nuse, users who support the Democrats would use Republican keywords or \nhashtags such as #gop and #republicans to tweet against or at them. The \nsame holds for the Republican supporters using the Democrat terms.\nFinding 3: Mainstream sources are shared more often than problematic \nsources concerning social issues related to health care and climate change \nbut not DACA (Deferred Action for Childhood Arrivals) where problematic \nsources outperformed mainstream sources in certain periods during March \nand December\u00a02020 as well as in March\u00a02021. In the third time span DACA \nhas fewer partisan sources than in the first two time spans. That is, of those \nunder study, the one issue where problematic sources are shared more \noften than mainstream sources (only during the first week of March and \nDecember\u00a02020) is DACA (Figure\u00a05.4), though the high engagement is largely \nattributed to a few articles. In the second and third weeks of March\u00a02020, \nthe number of problematic sources in the DACA issue space significantly \ndecreased. Indeed, across the three social issues, with the exception of \nDACA, few problematic sources were shared.\nWe note a similar pattern of shared problematic sources across the issues \nwhen comparing all time frames. In general, all issue spaces show less \nengagement in the time periods after the election. For example, there was \nalmost no activity in the Medicare issue space in March\u00a02021, indicating \nits election relevance rather than a broader societal concern. Note that \nthe sample sizes in these issue spaces are small, so one article can quickly \nspike engagement.\nFinding 4: There were more problematic accounts (fake accounts, bots or \nlocked/suspended) than real accounts on Twitter among selected keyword \nand hashtag datasets (Democrat, Republican, Trump) except for Biden\u2019s \ndataset in the first time frame. The latter data did contain problematic \naccounts in the second time span, covering the immediate aftermath of \nthe elections.\nWe now move to the top 20 users with the highest number of tweets and \nretweets during two, three-day time frames in March (one during and one \nafter \u201cSuper Tuesday,\u201d March\u00a03, 2020) and a third time frame (January\u00a01\u20134, \n2021). In the Republican and Democrat keyword and hashtag datasets we \nnoticed that, in total, there were more problematic accounts than real \naccounts (Figure\u00a05.7) for these time frames. For the Democrat dataset we \nfound only four real accounts in March and one account that clearly labeled \nitself as a bot that retweets all tweets by Trump. The rest was a combination \n96 M aar Te n gr oen and Marloe S  ge boer S \nfi gure\u00a05.4 cu mulative total of mainstream and problematic hosts shared on political Twitter \nconcerning \ndaca , d\nuring the time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, 2021 \nand March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfi gure\u00a05.5 cu mulative total of mainstream and problematic hosts shared on political Twitter \nconcerning Medicare, during the time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013January\u00a04, \n2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 97\nof fake accounts and locked/suspended accounts that had been banned \nby Twitter. In the Democrat keyword and hashtag dataset, most accounts, \nwhether real or fake, were mostly pro-Republican, indicating again how \nusers are employing the opposing political party\u2019s terms. The same applies \nto the Republican keyword and hashtag dataset, where most users are \npro-Democrat as opposed to Republican, though a smaller proportion is \nfake. Interestingly, in January\u00a02021, the share of fake and bot accounts \nshifts between these two issue spaces. The number of fake accounts in the \nRepublican hashtag space is now larger than the Democratic space. In our \ndatasets in total, problematic accounts in January make up about 60% of \nall accounts which is roughly the same as in March.\nIn 2016 it was found that suspect accounts were mostly Pro-Republican, \nand these were responsible for spreading most of the problematic in -\nformation (Bovet and Maske, 2019). In March we found that there was \nalready a rise in problematic accounts associated with pro-Democrats. \nIn January, we found that there are more problematic pro-Democrat \naccounts compared to March. Thus, it can be argued that Democrats are \nemploying problematic accounts within Republican political spaces to \nattack the Republican party.\nfi gure\u00a05.6 cu mulative total of mainstream and problematic hosts shared on political Twitter \nconcerning \ngr\neen \nne\nw \nde\nal, during the time spans: March\u00a02\u201322, 2020, \nde\ncember\u00a024, 2020\u2013Janu-\nary\u00a04, 2021 and March\u00a010\u201321, 2021. \nli\nne graphs by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n98 M aar Te n gr oen and Marloe S  ge boer S \nfi gure\u00a05.7 The top 20 users with the highest activity measure on Twitter within the de mocrat, \nre\npublican, \nbi\nden and Trump hashtag/keyword datasets, collected March\u00a02\u20134, 2020 and \nJanuary\u00a01\u20134, 2021. \nbu\nbble diagrams by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 99\nfi gure\u00a05.8 The top 20 users with the highest activity measure on Twitter within the de mocrat and \nre\npublican hashtags/keywords datasets, collected during the time spans: March\u00a02\u20134, 2020 and \nJanuary\u00a01\u20134, 2021. \ndi\nagrams by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\n100  M aar Te n gr oen and Marloe S  ge boer S \nfi gure\u00a05.9 The top 20 users with the highest activity measure on Twitter within the hashtag/\nkeyword datasets for the three political issues, collected during the time spans: March\u00a02\u20134, 2020 and January\u00a01\u20134, 2021. \ndi\nagrams by \nca\nrlo \nde \nga\netano and \nfe\nderica \nba\nrdelli.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 101\nFor the candidates\u2019 datasets (Biden and Trump) the same process was fol-\nlowed, but we filtered the top 20 users (by tweeting activity) that @mention \neach candidate (Figure\u00a05.7). Interestingly, a similar shift can be seen in the \nDemocrat and Republican datasets when comparing the two time frames. \nIn March, the Biden dataset had the highest number of real accounts, with \na few fake and locked/suspended accounts. The majority of users that @\nmention Biden is not problematic, and they are supporters of his political \ncampaign. The opposite holds for users mentioning Trump where results \nare equally distributed between bots, fake, and real accounts. In terms \nof partisanship, the majority is pro-Republican, which indicates that in \ncontrast to the political party spaces, the most active users are supportive. \nIn January, however, the most active users are those who are attacking either \ncandidate. There are more pro-Democrat bots attacking Trump and more \nreal pro-Republican accounts attacking Biden. Overall, the debate seems \n(even) more polarized in January compared to March.\nFinding 5: The most retweeted tweets among all datasets in both \nMarch\u00a02020 and December\u2013January\u00a02021 were made mostly by influential \naccounts like the presidential candidates, members of Congress, organiza -\ntions, and journalists and largely do not contain any problematic sources. \nFew problematic sources were found among the top 20 most retweeted tweets \nin the Democrat and Republican keyword and hashtag datasets in the two \ntime frames (Figure\u00a05.8). For example, the two tweets flagged as problematic \nin the Republican space in March are linked to the website run by Dan \nBongino, a conservative talk show host. A large majority of the retweets are \nby less controversial, influential people, including presidential candidates, \nmembers of Congress and journalists. The results are largely similar for \nthe January\u00a02021 dataset, where one highly resonating retweet opposing \nDemocrats was labeled as questionable. It relates to a news item around \nelectoral fraud from the OAN (One America News), which is a problematic \nsource as per our classification based on Media Bias/Fact Check (see also \nmethods section). Another resonating retweet referred to Breitbart News \ncovering calls for investigating electoral fraud.\nMethods\nBefore initiating our Twitter data collection, we curated a list of queries \nfor political candidates, political parties and social issues, incorporating \npolitician-specific, party-specific and issue-specific keywords and hashtags \n(Table\u00a05.1). Three social issues (likely to animate both sides of the political \n102  M aar Te n gr oen and Marloe S  ge boer S \nspectrum) were selected from a longer issue list made by triangulating issue \nlists on voter aid sites: Politico, VoteSmart, On the Issues and Gallup. These \nkeywords and hashtags were captured using DMI-TCAT (Borra and Rieder, \n2014) from the 2nd until the 23rd of March\u00a02020 and from December\u00a024, \n2020 until January\u00a04, 2021. 4CAT4 was used in the period from March\u00a010 to \n22, 2021, when problematic users were not analyzed. In these time spans, \nclose to 3 million tweets were captured that contain a link to a news article. \nThese tweet sets we term \u201cpolitical Twitter.\u201d\nTable\u00a05.1  C urated list of political keywords and hashtags queried in Twitter.\nTopic Query\nd\nemocrat #democrats, 2020 de\nmocrats, \nba\nckThe b\nlueWave, \nco\nuntry ov\nerParty, \nde\nmocraticParty, \nde\nmocrats2020, \nde\nms, \nnot\nMeus\n, Towards\nade\nmo-\ncraticParty\nica\nnTrust, Vote b\nlue, Vote b\nluenoMa\ntterWho, Vote b\nlue-\nno\nMatterWho2020, Vote\nbl\nueToSave ame\nrica, WelcomeTo no\ntMe us\n, \ndemocrats, thedemocrats \nr\nepublican #gop, gop, republicans, #republicans, Vote re\nd, Vote re\nd2020, \nVote\nre\ndToSave ame\nrica, Vote\nre\ndToSave ame\nrica2020\nbid\nen #biden, #joebiden, \u201cjoe biden,\u201d \nbid\nen2020, \nbid\nenbou\nnceba\nck, \nbid\nenfo\nrPresident, \nbid\nenha\nrris, \nbid\nenha\nrris2020, \nbid\nenbe\natsTrump, \nJoebid\nen2020, JoeMentum, Mojoe, \nqu\nidProJoe, \nrid\ninWith bid\nen, \nTeam\nbid\nen, TeamJoe, WeKnowJoe, biden, joebiden\nTrump #trump, \u201cdonald trump,\u201d \nbl\nackVoices fo\nrTrump, \ncub\nansfo\nrTrump, \ndo\nnaldTrumpjr, K a\ng, Ka\ng2\n020, K a\ng2\n020la\nndslideVictory, Keep\nam\neri-\ncagr\neat, M a\nga,\n Ma\nga2\n020, M a\nga2\n020la\nndslide, PresidentTrump, \nPresidentTrump2020, \nreel\nectPresidentTrump2020, TW\ngrP\n, Trump2020, \nTrump2020 la\nndslide, Trump2020 la\nndslideVictory, trump\nda\nca d\naca\ngr\neen \nne\nw \nde\nal gre\nennewdeal\nMedicare medicareforall, medicare4all\nThe three types of data we collected were most shared links, the top users \n(in terms of the number of tweets made), and the most retweeted tweets. \nTo study the most shared links, an expert list of sources was created. Each \nsource was labeled into two main categories, mainstream or problematic. \nMainstream sources could be sub-categorized as (hyper)partisan conserva -\ntive, (hyper)partisan progressive or neither. The expert list was created \nusing existing labeling sites such as Allsides.com, Media Bias/Fact Check, \u201cthe Chart,\u201d and NewsGuard. We consider the categorization as rough. By \ncalculating the total number of times problematic sources were shared \n4 h ttps://github.com/digitalmethodsinitiative/4cat\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 103\nduring our duration of study and comparing it with the mainstream sources \nwe were able to show the magnitude of the matter at hand. Are problematic \nsources present and shared by the users on Twitter who make use of specific \npolitical hashtags and keywords? We limited the scope of the top users and \nhashtags under study to three days in the first two time frames, starting \nfrom the 2nd of March\u00a02020 and from the 1st of January\u00a02021. The reason for \nchoosing the specific March period was that it encompassed \u201cSuper Tuesday,\u201d \na day when the largest number of U.S. states hold primary elections, and it \nwould be a reasonable assumption that the Twitter engagement on this day, \nthe day prior, and the day after would be higher than the other days in our \ndate range. The January time frame was just before the deciding Georgia \nrun-off elections for the U.S. Senate on January\u00a05, which would give the \nDemocrats a slim majority and in hindsight, with that time frame, we also \ncaptured the days before the Capitol riots of January\u00a06, 2021.\nWith the dataset of most active users, we investigated the extent to which \nproblematic users/accounts (fake profiles, bots, or locked/suspended users) \nwere present. We examined the top 20 users with the greatest number of \ntweets on political Twitter. These users were then coded or categorized on \ntwo scales: \u201cauthenticity\u201d and \u201cpartisanship.\u201d For the authenticity label, \nthe top 20 users were classified into four types based on their Twitter \nprofiles, where the idea is to gain a sense of the genuineness and legitimacy \nof the top users: real, fake, bot, and locked/suspended. The categories are \nadopted from the audience intelligence website, SparkToro, which ranks \nTwitter users based on their attributes (Fishkin, 2018). For bots, the website \ncategorizes accounts by determining whether they have Twitter\u2019s default \nprofile image, if an account has an unusual ratio of followers/following, \nor posts an abnormal number of tweets per day, among other signals. \nFake/real profiles, too, are judged according to (usual/unusual) tweeting \nhabits and behavior. The second categorization is \u201cpartisanship,\u201d where \nall the top users\u2019 political leanings were labeled independently by two \nauthors by looking at their Twitter profiles and classifying them into one \nof three categories: Democrat-leaning, Republican-leaning, or unknown. \nAny disagreements between the authors resulted in labeling the one in \nquestion as unknown.\nWith regards to the most retweeted tweets, the top 20 tweets were ex -\ntracted from the political spaces, and from the three issue-specific hashtags, \nDACA, Green New Deal, and Medicare. The most retweeted or the most \npopular tweets were further categorized into two categories of partisanship \nand the categories problematic or non-problematic information provider.  \nSimilar to the problematic users\u2019 segment, the partisanship of the tweets was \n104  M aar Te n gr oen and Marloe S  ge boer S \nmanually labeled by looking at the language of the tweet and further details \nabout the person who tweeted. To decide if a tweet contains problematic \ninformation, we checked whether any news sources linked in the tweets \nwere classified as such in the labeled source list.\nReferences\nAlter, J. [jonathanalter]. (2021, January\u00a01). \u201cIf we \u2018move on\u2019, the GOP will refuse to \nconcede future elections, then judge-shop until they steal one. There must be a \nprice paid for sedition or we will lose our democracy. This is critically important \nwork in the next couple of years\u201d [tweet]. https://twitter.com/jonathanalter/\nstatus/1345074521561292800.\nBarnidge, M. and Peacock, C. (2019). A third wave of selective exposure research? \nThe challenges posed by hyperpartisan news on social media. Media and Com -\nmunication , 7(3), pp.\u00a04\u20137. https://doi.org/10.17645/mac.v7i3.2257.\nBarnidge, M. (2017). Exposure to political disagreement in social media versus \nface-to-face and anonymous online settings. Political Communication , 34(2), \n302\u2013321. https://doi.org/10.1080/10584609.2016.1235639.\nBerger, J. and Milkman, K. L. (2012). What makes online content viral? Journal of \nMarketing Research,  49(2), 192\u2013205. https://doi.org/10.1509/jmr.10.0353.\nBerry, J. and Sobieraj, S. (2014). The outrage industry . Oxford University Press.\nBoltanski, L. (1999). Distant suffering: Morality, media and politics. Cambridge \nUniversity Press.\nBorra, E. and Rieder, B. (2014). Programmed method: Developing a toolset for \ncapturing and analyzing tweets. Journal of Information Management  66(3), \npp.\u00a0262\u2013278. https://doi.org/10.1108/AJIM-09-2013-0094.\nBovet, A. and Makse, H.A. (2019). Influence of fake news in Twitter during the \n2016 U.S. presidential election. Nature Communications , 10(1), p.\u00a07. https://doi.\norg/10.1038/s41467-018-07761-2.\nBoyd, R. L., Spangher, A., Fourney, A., Nushi, B., Ranade, G., Pennebaker, J., and \nHorvitz, E. (2018). Characterizing the Internet Research Agency\u2019s social media \noperations during the 2016 U.S. presidential election using linguistic analyses \n[Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/ajh2q.\nBozdag, E. and Van den Hoven, J. (2015). Breaking the filter bubble: Democracy and \ndesign. Ethics and Information Technology, 17 (4), 249\u201365. https://doi.org/10.1007/\ns10676-015-9380-y.\nBruns, A. (2019). Are filter bubbles real? Polity Press.\nChadwick, A. (2017). The hybrid media system: Politics and power. Oxford University \nPress.\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 105\nComscore (2019). Comscore March\u00a02019 top 50 multi-platform website properties \n(desktop and mobile). https://www.comscore.com/Insights/Rankings.\nConger, K. (2021). Twitter, in widening crackdown, removes over 70,000 QAnon \naccounts. New York Times . https://www.nytimes.com/2021/01/11/technology/\ntwitter-removes-70000-qanon-accounts.html.\nDelli Carpini, M.X. (2018). Alternative facts: Donald Trump and the emergence of \na new U.S. media regime. In Z. Papacharissi and P. Boczkowski (Eds.), Trump \nand the media (pp.\u00a017\u201323). MIT Press.\nDubois, E. and Blank, G. (2018). The echo chamber is overstated: The moderating \neffect of political interest and diverse media. Information, Communication & \nSociety,  21(5), pp.\u00a0729\u201345. https://doi.org/10.1080/1369118X.2018.1428656.\nEnli, G. (2017). Twitter as arena for the authentic outsider: Exploring the social \nmedia campaigns of Trump and Clinton in the 2016 U.S. presidential elec -\ntion. E uropean Journal of Communication , 32(1), pp.\u00a050\u201361. https://doi.\norg/10.1177/0267323116682802.\nFishkin, R. (2018). SparkToro\u2019s new tool to uncover real vs. fake followers on Twitter, \nSparkToro. https://sparktoro.com/blog/sparktoros-new-tool-to-uncover-real-\nvs-fake-followers-on-twitter/.\nGroshek, J. and Koc-Michalska, K. (2017). Helping populism win? Social media use, \nfilter bubbles, and support for populist presidential candidates in the 2016 U.S. \nElection Campaign. Information, Communication & Society, 20 (9), 1389\u2013407. \nhttps://doi.org/10.1080/1369118X.2017.1329334.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\nKarpf, D. Digital politics after Trump. Annals of the International Communication \nAssociation , 41(2), pp.\u00a0198\u2013207. https://doi.org/10.1080/23808985.2017.1316675.\nKwak, H., Lee, C., Park, H. and Moon, S. (2010). What is Twitter, a social network \nor a news media? In Proceedings of the 19th International Conference on World \nWide Web  (pp.\u00a0591\u2013600). ACM.\nMeier, F., Elsweiler, D., and Wilson, M.L. (2014). More than liking and bookmark -\ning? Towards understanding Twitter favouriting behaviour. In Proceedings of \nICWSM\u201914 . AAAI Press. http://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/\npaper/view/8094.\nNewsGuard (2020). NewsGuard Nutrition Label. https://www.newsguardtech.com.\nNiederer, S. (2019). Networked content analysis: The case of climate change. \nInstitute of Network Cultures. https://networkcultures.org/blog/publication/\ntod32-networked-content-analysis-the-case-of-climate-change/.\nO\u2019Hara, K. and Stevens, D. (2015). Echo chambers and online radicalism: Assessing \nthe internet\u2019s complicity in violent extremism. Policy & Internet, 7(4), pp.\u00a0401\u2013422. \nhttps://doi.org/10.1002/poi3.88.\n106  M aar Te n gr oen and Marloe S  ge boer S \nPariser, E. (2011). The filter bubble: What the internet is hiding from you . Penguin.\nPeacock, C., Hoewe, J., Panek, E., and Willis, G. P. (2019). Hyperpartisan news use: \nRelationships with partisanship, traditional news use, and cognitive and affec -\ntive involvement. Paper presented at the Annual Conference of the International \nCommunication Association, Washington, DC.\nRogers, R. (2014). Debanalising Twitter: The transformation of an object of study. \nIn Weller, K., Bruns, A., Burgess, J., Mahrt, M. and Puschmann, C. (Eds.), Twitter \nand society (pp. ix-xxvi) . Peter Lang.\nRogers, R. (2020a). The scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified. Harvard Kennedy School Misinformation Review , 1(6). ht tps://doi.\norg/10.37016/mr-2020-43.\nSalenger, M. [meredthsalenger]. (2020, March\u00a002). \u201cReal quick: How are Republicans \nlike Donald ok with 2% of people dying from coronavirus as if 2% is not a very \nhigh number. But when you discuss a 2-cent wealth tax on people making over \n50 million they freak out like it\u2019s the worst thing that could ever happened to \nthem\u201d [tweet]. https://twitter.com/meredthsalenger/status/1234337053.\nShepherd, T., Harvey, A., Jordan, T., Srauy, S., and Miltner, K. (2015). Histories of \nhating. Social Media + Society. https://doi.org/10.1177/2056305115603997.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook\nStarbird, K. (2017). Examining the alternative media ecosystem through the produc -\ntion of alternative narratives of mass shooting events on Twitter. In Proceedings \nof the 11th International AAAI Conference on Web and Social Media . AAAI Press. \nhttp:/ /faculty.washington.edu/kstarbi/Alt_Narratives_ICWSM17-CameraReady.\npdf.\nSunstein, C. R. (2001). Echo chambers: Bush v. Gore, impeachment, and beyond. \nPrinceton University Press.\nTate, R. (2009, 19 Nov.). Twitter\u2019s new prompt: A linguist weighs in . Gawker . ht tps://\ngawker.com/5408768/twitters-new-prompt-a-linguist-weighs-in.\nWahl-Jorgensen, K. (2019). Emotions, media and politics. Polity.\nData availability\nhttps://doi.org/10.7910/DVN/QIJQ3X\nfr inge Pl ayer S on  Pol i Ti cal T Wi TTe r 107\nAbout the authors\nMaarten Groen  is a researcher and programmer at the Visual Methodologies \nCollective at the Amsterdam University of Applied Sciences. His research \nfocuses on using data to empower citizens through participatory and \ndigital methods and the analysis and visualization of the resulting data. \nHis background is in Computer and Information Science.\nMarloes Geboers , PhD, is a member of the Visual Methodologies Collective \nat the Amsterdam University of Applied Sciences and Postdoctoral Fellow \nin platform subcultures in Media Studies, University of Amsterdam. She \nresearches the affective affordances of platforms, particularly how they \nshape the visualities and narratives of war and suffering. Her educational \nbackground is in political science and journalism.\n\n6 T witter as accidental authority\nHow a platform assumed an adjudicative role during the \nCOVID-19 pandemic\nEmillie de Keulenaar, Ivan Kisjes, Rory Smith, Carina Albrecht \nand Eleonora Cappuccio1\nAbstract\nThis chapter explores Twitter\u2019s moderation of authoritative sources and \ntheir audience\u2019s claims concerning COVID-19 treatments, transmission \nand prevention techniques. It examines how they diverge over time, \nand how Twitter intervenes in resulting debates via content moderation \nguidelines and techniques. It argues that as public health organizations \nand heads of state struggle to maintain consensus among themselves \nand with their Twitter audiences on these issues Twitter exceptionally \nsteps in as an authority in its own right. It does so by flagging, suspend -\ning and deleting contents, including those of authoritative sources that \nthreaten to disrupt a common understanding of the virus and vital health \ninformation.\nKeywords: Content moderation, platform rules, sensemaking, problematic \ninformation, COVID-19 treatment\nResearch questions\nHow did claims by authoritative sources (@realDonaldTrump, @CDC, @\nNIH, @WHO and @pahowho, the North American division of the World \nHealth Organization) on COVID-19 transmission, prevention and treatments \n1 T he authors would like to acknowledge Jack Wilson and Carlo De Gaetano for their con -\ntributions to this research. Emillie de Keulenaar\u2019s participation has been supported by the \nUKRI-Canada ESRC grant, Responsible AI for inclusive, democratic societies: A cross-disciplinary \napproach to detecting and countering abusive language online (ESRC reference: ES/T012714/1).\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch06\n110  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \ndiverge from those of their audiences between March and October\u00a02020? How \ndid Twitter\u2019s content moderation guidelines and techniques for COVID-19 \nmisinformation interfere in these divergences? How did COVID-19 affect \nTwitter\u2019s overall policies on misinformation?\nEssay summary\nAs new information on the epidemiological nature of COVID-19 infections \nand its impact on public safety evolves, so do claims on which objective \nfacts constitute it (Yong, 2020). Twitter has been tasked with ensuring \nthat their users maintain a basic level of consensus around public safety \nguidelines and other information relative to personal and public health by, \nfor example, centralizing access to local health organizations and representa -\ntives, flagging and at times deleting \u201cmisleading\u201d tweets that contradict \nsuch sources (Skopeliti and John, 2020). But with diverging guidelines and \nfacts occasionally opposing even authorities\u2014notably ex-U.S. President \nTrump, the American Center for Disease Control, the National Institutes \nof Health and the World Health Organization\u2014the platform has struggled \nto determine whom to attribute ultimate authority for reliable information \nabout COVID-19 transmission, treatment and protection.\nIn this context, we find that English-speaking publics who interact with \nany of these authorities have at times been polarized around either Donald \nTrump or the World Health Organization. As these authorities contradict \neach other, we find that Twitter begins to moderate\u2014and ultimately \nsuspend\u2014authorities that disrupt the general consensus over COVID-19, \nparticularly Donald Trump. We conclude that Twitter\u2019s moderation of \nproblematic information on the virus demonstrates how the platform relies \nless on specific guidelines over what constitute true and false information \nthan on the general consensus between public health authorities.\nThese findings suggest two main implications. First, Twitter\u2019s moderation \nof authoritative sources renders the platform an authority in its own right, as \nit ultimately decides which of these authorities can and cannot govern on its \nplatform. Second, COVID-19 has pushed platform moderation of misinforma-\ntion from detecting and suppressing technically inauthentic contents to \ninformation that affects the overall consensus over what constitutes correct \ninformation, leading the platform to sanction outliers or \u201cextremes,\u201d and \nshrink its size down to a more homogeneous (and thereby cohesive) public \nsphere. Both of these implications constitute a few emerging characteristics \nof a kind of \u201cpost-Trump\u201d internet.\nTWiT T e r a S  acciden Ta l au Th ori Ty  111\nImplications\nHeads of state, health organizations and the public have been frequently \ndivided on claims around COVID-19, such as whether asymptomatic people \nand children can contaminate others, whether one should use a mask, or if \nchildren can be contagious (Iati et al., 2020; O\u2019Leary, 2020). In this context, \ngovernments and public health authorities have struggled to maintain a \nconsensus with their local publics and each other (Starbird, 2020), hurting \npublic trust in their capacities as main references about the pandemic \n(Bordia and Difonzo, 2004; Bostrom et al., 2015; Starbird et al., 2016).\nIn response, social media, search engines and encyclopedic wikis have \nbeen tasked with ensuring that their users maintain consensus around \npublic safety guidelines and other information relative to public health \n(Skopeliti and John, 2020). Since the early months of 2020, Google Web \nSearch, YouTube, Facebook, Twitter and Reddit have set up centralized \naccess points to information provided by local and global \u201cauthoritative \nsources\u201d (Skopeliti and John, 2020). Though some stakeholders continue \nto demand more radical platform redesign (Dwoskin, 2020), more mod -\nest measures include prompting local guidelines on the virus whenever \none searches or consults information about COVID-19 (Lee and Oppong, \n2020), temporarily disabling the personalization of Newsfeeds (Lyons, \n2020); flagging contents (tweets, posts, videos) that disseminate contested \nclaims (Lyons, 2020), demoting \u201cborderline\u201d or suspicious contents like \nconspiracy theories and raising \u201cauthoritative content\u201d to the top of search \nand recommendation results (De Keulenaar et al., 2021; YouTube, 2019), \nand altogether deleting materials that pose a danger to public health, such \nas anti-vaccination or alternative medication (De Keulenaar et al., 2021; \nYouTube, 2020).\nBut with information about the virus being uncertain in the early months \nof the pandemic, one wonders how a platform like Twitter has adapted \nits COVID misinformation policy to tolerate the relative contingency of \nknowledge and facts about the virus. Not only have authoritative guid -\nance on treatments and protection frequently changed, but they have also \ncontradicted each other. Guidance by the World Health Organization, favored \nby nearly all social media platforms, at times differed from what the Centers \nfor Disease and Control Prevention, the NIH and then-U.S. President Donald \nTrump advised. While such discordances are to be expected, we assume \nthat it has at times created a crisis of authority in the platform\u2014a \u201cstate of \nexception\u201d (Schmitt, 2005)\u2014that has pushed Twitter to take exceptional \nmeasures to maintain a baseline of consensus in its platform.\n112  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nDrawing partly from studies on collective sensemaking and rumors \n(Caplow, 1946; Dailey and Starbird, 2015; Krafft et al., 2017; Shibutani, \n1966), we use close reading and natural language processing techniques \nto measure the relative divergence of authoritative and \u201caudience\u201d claims \nabout COVID transmission, prevention and treatments. Authoritative \nsources include international and U.S. representatives and public health \norganizations, with claims released on Twitter and their respective websites, \nand their \u201caudiences,\u201d defined here as the users who have at some point \nengaged with or referred to the former on Twitter. Our dataset contained \n250 million tweets that mention #covid or #coronavirus between March \nand October of 2020. Authoritative sources include then-U.S. President \nDonald Trump, the Centers for Disease Control and Prevention, the National \nInstitutes of Health, and the World Health Organization\u2019s International and \nRegional Office for the Americas. Using the Wayback Machine (Internet \nArchive, 2021), we then examine how Twitter adapted its content modera -\ntion techniques to moderate COVID-19 misinformation. We capture Twitter \nmoderation data for each of the tweets in our dataset using Selenium, a \nweb interface scraper, obtaining labels, suspensions and other removal \ndisclaimers.\nWe find that the pandemic has pushed Twitter and its platform counter -\nparts to delimit what \u201cmisinformation\u201d or other problematic information \nis, be it in a technical, authoritative or even rhetorical sense. Determining \nthe objective value of statements on COVID-19 treatments, prevention \nand transmission vehicles, however, is not a responsibility the platform \ninitially embraces. Its preference is to relay that decision to \u201cauthoritative \nsources,\u201d a solution already set by other platforms to prioritize authoritative \ncontents as \u201creputed\u201d or \u201ctrustworthy\u201d sources, despite mixed reactions \nfrom users suspicious of \u201cpolitical bias\u201d in favor of left-wing American \npolitical culture (Economist, 2019). This study also shows mixed results. \nThe absence of consensus among authoritative sources makes the 2020 \nU.S. (and international) crisis of authority on COVID-19 even more evident, \nwith the WHO, CDC, NIV and the White House contradicting one another. \nThe difference, we find, is that in the absence of authority, Twitter steps in \nas an authority itself.\nConsensus and misinformation in the process of COVID-19 \nsensemaking: Conceptual implications\nA number of misinformation policies and studies have focused on detecting \nand correcting misinformation by (for example) investing in media literacy \nTWiT T e r a S  acciden Ta l au Th ori Ty  113\nand pinpointing factors that can \u201cincrease the chances of citizens to be \nexposed to correct(ive) information\u201d (Scheufele and Krause, 2019, p.\u00a07664). \nStrategies include removing false content and demoting false or \u201cborderline\u201d \ninformation in favor of authoritative sources (Scheufele and Krause, 2019, \np.\u00a07664).\nA possible drawback of these strategies is the decontextualization of \nmisinformed claims from the premises and info spheres that substantiate \nthem. These spheres are frequently outside of misinformation-policed \nsocial media platforms (De Zeeuw et al., 2020), and their users may be \nunaware of the information needed to understand claims and directives from \nauthoritative sources (Kou et al., 2017). In other instances, misinformative \nclaims can come from more innocuous misunderstandings (De Zeeuw et \nal., 2020), or attempts at making sense of situations still unexplained by \nauthorities (Krafft et al., 2017, p.\u00a02976; Starbird et al., 2016). The inconsistency \nof official information is characteristic of the formation of rumors and other \n\u201cimprovised\u201d sensemaking (Shibutani, 1966), which in themselves constitute \nan attempt to create consensus or a \u201ccommon understanding\u201d where there \nis none (Bordia and Difonzo, 2004).\nIn this sense, we join a field of study that approaches misinformation as \na dynamic by-product of poor consensus between information providers \nand recipients\u2014authoritative sources and their audiences\u2014who must in \ncrises \u201cconverge\u201d around a common understanding of facts and the epistemic \nframeworks used to validate them (Scheufele and Krause, 2019, p.\u00a07663; \nStarbird, 2012, p.\u00a01). By pinpointing information that authoritative sources \nand their audiences mutually ignore and comparing diverging claims related \nto these terms,2 we find that authoritative sources and their audiences do \nnot always focus on the same aspects of COVID-19, nor do audiences always \nrely on the same authoritative sources.\nFrom misinformative to misleading tweets: How COVID affected \nTwitter\u2019s moderation of \u201cproblematic information\u201d\nOver the course of 2020, Twitter adapted its anti-misinformation content \nmoderation policies significantly. Twitter\u2019s initial approach to manag -\ning COVID-19 misinformation on its platform piggy-backed on existing \npolicies that targeted inauthentic user behavior. In early February\u00a02020, \nthe platform targeted COVID misinformation as deceitful contents, or \n2 F or example, audiences mention \u201c5G\u201d and \u201cfood\u201d as transmission vectors, while authoritative \nsources focus on \u201ccough\u201d and \u201ctouch.\u201d\n114  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \ndisinformation: doctored footage or photography, or contents forged with \nthe intention to mislead other users (Twitter, 2020). It uses the World \nHealth Organization as a reference from which to determine whether a \ntweet is false or not. This requires heavy-handed, top-down measures to \nremove tweets that contradict such authorities before they can spread \non the platform.\nAs the pandemic began to spread globally, however, it became clear \nthat existing conceptions of disinformation do not capture the fact that \nCOVID-19 is also the subject of widely diverging and contingent information. \nIt becomes difficult, arguably impossible, for the \u201cauthoritative sources\u201d \nTwitter recommends delivering stable facts and guidelines on the virus. On \nthe one hand, this leads Twitter to fine-tune its definition of misinformation \ndown to the level of the rhetoric of a tweet. This includes both what a tweet \nclaims and how  it claims it. On the other, Twitter also broadens its definition \nof misinformation as a problem of consensus. It recognizes that information \nabout the virus, even when provided by authoritative sources, is subject to \ndisagreements and change.\nRather than resorting merely to deletion, it seeks to reinforce a consensus \non guidelines and facts about the virus by centralizing users\u2019 access to COVID \ninformation. It wants to ensure that users comment on the virus within \ndelimited epistemic boundaries of what can and cannot be entrusted to \nbe true. The delimitation of those perimeters is an arbitration outsourced \nto local, legislative and medical authorities: those tasked with deciding \nthe truth about the virus. This means pointing users to local authorita -\ntive sources\u2019 websites on tweets that mention the virus or adding links \nto national or state-level guidelines on newsfeeds and homepages. These \nmeasures\u2014exemplified by the early #KnowTheFacts prompt\u2014would help \nfill in possible \u201cdata voids\u201d (Golebiewski and boyd, 2019) between authorita -\ntive sources and their audiences.\nTwitter as an accidental authority\nStill, trouble comes when authoritative sources begin to contradict one \nanother around mask usage, hydroxychloroquine treatments or airborne \nviral transmission. In such cases, Twitter does not favor one or another public \nhealth authority but does at times moderate authorities that disrupt their \noverall consensus. Ex-U.S. President Donald Trump\u2019s analogies of COVID \nand seasonal flu, or the merits of hydroxychloroquine-based treatments, \ncontradict and confuse statements by the CDC and NIH. His tweets are \nflagged, counter-balanced by resources Twitter recommends users consult \nTWiT T e r a S  acciden Ta l au Th ori Ty  115\ninstead. Though the first tweet it suspended was sanctioned for violating \nits \u201cglorification of violence\u201d policy, Trump\u2019s tweets on COVID are nearly \nalways labeled by default.\nThe decision to moderate authorities appears to mark a shift between \nredirecting users towards trust-worthy sources of information to curating \nsuch sources relative to their capacity to maintain a greater consensus \namongst other relevant authorities. In this sense, Twitter is no longer mod -\nerating tweets individually, but as a larger ensemble of statements whose \noverall consensus constitutes the objective quality of COVID information. \nTechnically, moderating consensus rather than single falsehoods grants \nTwitter significant institutional responsibilities. As it optimizes the relative \nproportion of public safety and consensus, Twitter accidentally becomes an \n\u201cauthoritative source\u201d\u2014or authority, for short\u2014in its own right.\nTwitter\u2019s moderation of existing authorities speaks to a number of foun -\ndational concepts of political theory, among which is Carl Schmitt\u2019s famed \nphrase that the \u201csovereign\u201d is \u201cthat which decides the state of exception\u201d \n(Schmitt, 1932). As consensus wanes among existing authorities in a given \nbody politic and crisis sets in, the one who will hold ultimate authority is \nthat who intervenes and decides for those in this sphere regardless of the \nlegality of their actions. It is not so much Twitter\u2019s content moderation \npolicies that legitimize its moderation of authoritative sources, but its very \nability to do so regardless of existing conventions.\nFindings\nFinding 1: Authoritative sources and their audiences contradict each \nother most on undetermined facts, such as COVID-19 treatments. As may \nbe expected, audiences and authoritative sources diverge most around \nunconfirmed information. There were no single, confirmed treatments \nfor COVID-19 until the announcement of the Pfizer vaccine in August of \n2020. Despite declaring that \u201cno treatment\u201d and \u201cvaccines\u201d were available by January, authoritative sources like the World Health Organization and \nthe CDC fail to prevent their audiences from contemplating a plethora of \ntreatments ranging from house-grown remedies and specialized medicines \n(see Figure\u00a06.1), be it vitamin C, ethanol, zinc or remdesivir.\nIn this context, authoritative sources act primarily as debunkers of \nunconfirmed or false information. The World Health Organization opens \na page dedicated to debunking false ingredients reported on social media. From January, it debunks nearly half of the ingredients discussed by their \n116  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nMar 23 2020\nApr 06 2020\nApr 20 2020\nMay 04 2020\nMay 18 2020\nJun 01 2020\nJun 15 2020\nJun 29 2020\nJul 13 202O\nJul 27 2020\nAug 10 2020\nAug 24 2020\nSep 07 2020\nSep 21 2020\nOct 05 2020\naspirin\nazithromycin\nbiocharger\ncannabis\ncbd oil\nchlorine dioxide\nchloroquine\ncocaine\ncolloidal silver\ncow dung\ncow urine\ndexamethasone\ndietary supplement\ndurian\nessential oil\nethanol\nhoney\nlemon grass\nmango\nmethanol\nmineral\nnasal spray\nno cure\nno drug\nno treatment\nno vaccine\nremdesivir\nsaline\nsalt water\nsnake oil\nsupplemental oxygen\nsupportive care\ntamiflu\ntoothpaste\nturmeric\nvinegar\nvitamin c\nvitamin d\nwudu\n1,0\n1,051\n2,102\nApr 06 2020\nMay 04 202O\nJun 22 2020\nAug 10 2020\nSep 07 2020\nOct 05 2020\ndexamethasone\nethanol\nmethanol\nmineral\nremdesivirTimes a word is mentioned\n35,225 total mentions\n496,166 tweets98 total mentions\n910 tweetsCOVID-19 treatments mentioned by audiences (right) and authoritative sources (left), March 23 2020 - October 12 2020\nfi gure\u00a06.1 he atmap of forms of coVi d- 19 treatment mentioned by authoritative sources (tweets \nand website data) and their Twitter audiences (tweet replies and mentions of website domains by \nauthoritative sources, e.g., whitehouse.gov). Visualization by \nem\nillie de Keulenaar and \nel\neonora \nc\nappuccio.\nTWiT T e r a S  acciden Ta l au Th ori Ty  117\naudiences: ethanol, honey, lemon, cannabis, cocaine, colloidal silver, lopi -\nnavir and others (see Figure\u00a06.2).\nElsewhere, authoritative claims also express uncertainty on transmission, \ntreatments and prevention, stressing the uncertain nature of research on \nCOVID-19 (Bostrom et al., 2015, p.\u00a0633). This can be said about chloroquine, \nhydroxychloroquine, remdesivir, dexamethasone, prednisolone and Tamiflu, \nabout which authoritative sources mention ongoing research and testing. This \ndoes not prevent audiences from continuing to engage with these ingredients.\nFinding 2: Audiences are divided around contradicting claims by au-\nthoritative sources. Zooming into authoritative and audience claims on \nthe efficacy of hydroxychloroquine, we see that audiences (below, \u201cusers\u201d) \nappear to polarize around diverging authoritative statements. While some \necho Donald Trump\u2019s claims that the ingredient is effective (including in \ncombination with azithromycin), others relay the World Health Organiza -\ntion\u2019s claim that it is not. A small majority state the same claim as the CDC \nand the NIH who rule the matter as still \u201cuncertain.\u201d\nThe same can be said about modes of transmission. In the early months \nof the pandemic, authoritative sources and their audiences usually referred \nTreatment\nalcohol\n1\n0\nantibiotic\n1\n0\nbath\n1\n0\nblack pepper\n1\n0\nbleach\n1\n0\nchlorine\n1\n0\nchloroquine\n1\n0\n2\n0\ncold weather\n1\n0\nconvalescent plasma\n1\n0\ndisinfectant\n1\n0\ndryer\n1\n0\nethanol\n1\n0\ngarlic\n1\n0\nhydroxychloroquine\n1\n0\n2\n0\nhydroxychloroquine and azithromycin\n1\n0\n1\n0\nhyperimmune immunoglobulin\n1\n0\ninfluenza complex\n1\n0\nInterferons\n1\n0\nInterleukin-1 inhibitors\n1\n0\nInterleukin-6 inhibitors\n1\n0\nJanus kinase inhibitors\n1\n0\nlopinavir\n1\n0\nmineral\n1\n0\nno vaccine\n1\n0\n1\n0\nremdesivir\n1\n0\nsaline\n1\n0\nsesame oil\n1\n0\nsunlight\n1\n0\n1\n0\nuvc\n1\n0\n1\n0\nvitamin c\n1\n0\nvitamin d\n1\n0\nwarm weather\n1\n0\n1\n0\nzinc\n1\n0\nDebunk\nDisputed\nAuthoritative sourcesfi gure\u00a06.2 he atmap of authoritative clams on coVi d- 19 treatments. Purple values count as \nauthoritative debunks of audience claims; blue values indicate instances in which authoritative \nhave framed a given treatment as disputed. Visualization by \nca\nrlo \nga\netano.\n118  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nto different modes of COVID-19 transmission. Audiences do focus on modes \nof transmission mentioned by authoritative sources: (respiratory) droplets, \nclose contact, community spread, coughing, sneezing and touch. Here, too, \nauthoritative sources act as debunkers: 5G is dismissed at least twice after \ngaining considerable traction among audiences in March.\nThe caveat, here, is that audiences continue to focus on modes of trans -\nmission disputed among authoritative sources (see Figure\u00a06.4). With little \nscientific consensus on the minutiae of droplet transmissions, there is notable \npublic confusion on the airborne nature of the virus (Achenbach and Johnson, \n2020; Lewis, 2020; Mandavilli, 2020). The World Health Organization expresses \nuncertainty about airborne transmission throughout February, then later \njoins the U.S. Centers for Disease Control and Prevention in March to affirm \nthat it spreads mainly via droplets. Only in April\u00a02020 does the CDC offer a \nverdict: \u201caccording to experts,\u201d it says, \u201cthe virus can be transmitted by both \ndroplets and smaller, \u2018aerosol\u2019 types of particles\u201d (Centers for Disease Control \nand Prevention, 2020). While the World Health Organization rejects this claim, \na slight majority of users echoes the CDC\u2019s statement well until October.\nIn this context, audiences express a relatively constant amount of un -\ncertainty throughout, as well as conspiratorial suspicions in early March. \nFEBRUARY\nMARCH\nAPRIL\nMAY\nJUNE\nJULY\nAUGUST\nSEPTEMBER\nOCTOBER\nFEBRUARY\nMARCH\nAPRIL\nMAY\nJUNE\nJULY\nAUGUST\nSEPTEMBER\nOCTOBERamount of claims\namount of moderated claimsUsers\nAuthoritative sources\n@RealDonaldTrump\nwho.int\ncdc.gov nih.gov\nyes\nno\nyes, in combination with azithromycinIs hydroxychloroquine \neffective against COVID-19?\nuncertain\nfi gure\u00a06.3 be e swarm of authoritative and audience claims on whether hydroxychloroquine is or is \nnot effective against \ncoVi\nd-\n19 infections. Visualization by \nca\nrlo de \nga\netano.\nTWiT T e r a S  acciden Ta l au Th ori Ty  119\nMar 23 2020\nApr 06 2020\nApr 20 2020\nMay 04 2020\nMay 18 2020\nJun 01 2020\nJun 15 2020\nJun 29 2020\nJul 13 2020\nJul 27 2020\nAug 10 2020\nAug 24 2020\nSep 07 2020\nSep 21 2020\nOct 05 2020\n5g\nairborne\nasymptomatic people\nblood transfusion\nbreast milk\nclose contact\ncommunity spread\ncoughing\ndirect contact\ndroplet nuclei\ndroplets\nelectromagnetic\nfecal transmission\nfecal-oral transmission\nfomites\nindirect contact\nintimate contact\nkissing\nmicrochip\nmosquito\noral transmission\npetrol\nphysical contact\nradiation\nrespiratory droplets\nsaliva\nsneezing\nsputum\ntick\ntouch\nwet particles\nwireless\n1\n1,051\n2,102\nMar 30 2020\nApr 27 2020\nMay 11 2020\nJun 01 2020\nJun 22 2020\nJul 13 2020\nJul 27 2020\nAug 10 2020\nAug 24 2020\nSep 14 2020\nSep 28 2020\nOct 12 2020\n5g\nairborne\nasymptomatic people\nbreast milk\nclose contact\ncommunity spread\ncoughing\ndroplets\nelectromagnetic\nmosquito\nrespiratory droplets\nsaliva\nsneezing\ntick\ntouch\nTimes a word is mentioned\n32,230 total mentions\n496,166 tweetsTypes of transmission mentioned by authoritative sources (down) and \ntheir Twitter audiences (up), March 23 2020 - October 12 2020\n20 total mentions\n910 tweets\nfi gure\u00a06.4 he atmap of modes of transmission mentioned by authoritative sources (tweets and \nwebsites) and their Twitter audiences (tweet replies and mentions of website domains by authorita -\ntive sources, e.g., whitehouse.gov). Visualization by \nem\nillie de Keulenaar and \nel\neonora \nca\nppuccio.\n120  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nWhile this is especially applicable in the months of February and March, \naudiences appear to express a relatively constant amount of claims aligned \nwith the majority of authoritative sources. This may suggest that more \nconsensus between  authoritative sources could foster consensus among \ntheir publics.\nThere is further disagreement on whether COVID-19 is transmitted \nthrough droplets or smaller aerosol particles (see Figure\u00a06.5). While virtually \nall sources agree that the virus is transmitted by the former, some specify \nthat aerosols may remain in the air for longer periods of time. The World \nIs COVID-19 airborne? \n2342 -\n0 @whowpro \nFACT: #COVID19 is NOT airborne. \nThe #coronavirus is mainly transmitted \nthrough droplets generated when an \ninfected person coughs. sneezes or speaks. \nwhitehouse.gov \nyes whitehouse.gov \nyes \n57 -\n0 \n12 who.int conspiratorial \nclaims \nwho.int \nuncertain uncertain \nI \nFebruary March \nWeb domains: who.int, whitehouse.gov. cdc.gov and nih.gov I \nApril \nTweet replies for@who, @whitehouse, @cdc, @RealDonaldTrump and @nih \nTweets mentioning websites of authoritative sources who.int \n\ufffd within 1 meter \ncdc.gov\nunlikely\nI \nMay Key \n\u25a0 No\u25a0 Yes\n\u25a0 Uncertain \nI \nJune July \nfi gure\u00a06.5 li ne graph of audience and authoritative statements about whether coVi d- 19 is \nairborne or not. Visualization by \nele\nonora \nc\nappuccio and \nem\nillie de Keulenaar.\nTWiT T e r a S  acciden Ta l au Th ori Ty  121\nHealth Organization\u2019s expressions of doubt regarding the latter claim is \nquickly contradicted by the White House. Audiences express an equally \ndistributed amount of agreement with each claim, seemingly partitioned \ninto groups that either rely on the word of the World Health Organization or that of the White House.\nThe debate on whether the virus is droplet or aerosol airborne shows how \npopular understandings of viral transmission appear to have evolved through \ndiscussions between authoritative sources and audiences. Early public \ndoubts about whether the virus was airborne have prompted authorities to \ndefine and measure airborne transmission in increasingly concrete terms \n(see Figure\u00a06.6). While the World Health Organization had stated earlier \nthat airborne transmission is an exchange of infected droplets, recent \nfindings on aerosol transmission substantiate earlier public conceptions \nof airborne transmission as a somewhat ubiquitous form of \u201cair infection\u201d (Mandavilli, 2020).\nFinding 3: Twitter has adapted its content moderation policies to capture \nthe disputed nature of COVID-19 information. In the face of such disputes, \nTwitter\u2019s \u201cCOVID-19 misleading information\u201d policy underwent frequent changes throughout 2020 (see Figure\u00a06.7). On February\u00a04, 2020, Twitter\u2019s \ninitial definition of COVID-19 misinformation is based on a conception \nfi gure\u00a06.6 li ne graph of claims on droplet or aerosol transmission by authoritative sources \n(web domains) and their Twitter audiences (tweet replies and mentions of website domains by \nauthoritative sources, e.g., whitehouse.gov). Visualisation by \nele\nonora \nc\nappuccio and \nem\nillie de \nKeulenaar.\n122  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nof misinformation as deceit, be that in the intent of its author (\u201cmedia \nshared in a deceptive manner\u201d) or in its technical composition (\u201csynthetic \nor manipulated media\u201d on the virus) (Chu and McDonald, 2020). This \ndefinition follows existing conceptions of misinformation as disinforma -\ntion, or as semantically or technically inauthentic. Examples of the former \ninclude \u201ca deliberate intent to deceive people about the nature or origin \nof the content,\u201d and for the latter, \u201ccontent that has been substantially \nedited in a manner that fundamentally alters its composition, sequence, \ntiming, or framing,\u201d \u201cany visual or auditory information that has been \nadded or removed,\u201d and \u201cfabricated or simulated media depicting a real \nperson\u201d (Twitter, 2020a). Both of these types of information are subjected \nto an incremental type of moderation, where they are first labeled, de -\nmoted and altogether removed after infringing misinformation policies \nmore than once (Roth and Pickels, 2020). Twitter\u2019s policy against COVID \nmisinformation as \u201cmanipulated media\u201d is sealed with a general \u201czero \ntolerance approach to platform manipulation,\u201d announced in March\u00a04, \n2020 (Twitter, 2020b).\nAs the virus disseminates outside of China in early March, Twitter broad -\nens its conception of COVID-19 misinformation as contradicting local and \ninternational \u201cauthoritative sources\u201d (Twitter, 2020b). The idea, then, is to establish a baseline of facts about the virus with which to moderate user-\ngenerated contents. Content moderation targets content that may contradict \nwhat is known and stated by authoritative sources. This includes \u201cdenial of \nglobal or local health authority recommendations to decrease someone\u2019s \nlikelihood of exposure to COVID-19\u201d; \u201cdenial of established scientific facts \nabout transmission during the incubation period or transmission guidance \nfrom global and local health authorities\u201d; and \u201calleged cures for COVID-19 that are not immediately harmful but are known to be ineffective\u201d (Twit -\nter, 2020b). To reinforce this policy, Twitter prioritizes posts by the World \nHealth Organization and local health organizations in users\u2019 homepages and \npersonal timelines. From January\u00a029, 2020, Twitter also launches a series of \nlabeling techniques to redirect users towards claims by authoritative sources \non the transmission, protection and treatment of the virus. Contradictions \nto these claims are first labeled and then removed (see Figure\u00a06.6) (Twitter, \n2020b).\nThe fact that authoritative sources occasionally disagree with each other \nposes a new challenge to existing COVID policies. For this reason, content \nmoderation guidelines adopt a two-fold strategy: they simultaneously \nrestrict the kind of claims users can make about COVID-19 transmission, \nprevention and treatments, and highlight the disputed nature of such \nTWiT T e r a S  acciden Ta l au Th ori Ty  123\nclaims. The idea is to adapt moderation to the contingent and disputed \nnature of various information about the disease, be they international \ndiscrepancies in public health policies or diverging claims made by au-\nthoritative sources about the virus. As did other platforms (e.g., Google \nand Facebook), it also creates a flag prompt (\u201c#KnowTheFacts\u201d) whenever \nusers search or encounter information about the virus on the platform (Chu \nand McDonald, 2020). By May\u00a011, it introduces new labeling and warning \ntechniques intended to \u201cprovide additional context and information on \nsome tweets containing disputed or misleading information related to \nCOVID-19\u201d (Twitter, 2020c).\nLater, on December\u00a016, 2020, Twitter goes as far as to specify the type \nof rhetoric that infringes upon its COVID-19 misinformation policy. \nIt targets tweets that \u201cadvance a claim of fact, expressed in definite \nterms\u201d and later \u201ctweets that are an assertion of fact (not an opinion), \nexpressed definitely, and intended to influence others\u2019 behavior\u201d (Twit -\nter, 2020d). Misleading statements on \u201cvaccines\u201d consist in spreading \n\u201cpreventative measures that are not approved by health authorities, \nor that are approved by health authorities but not safe to administer \nfrom home\u201d; \u201cthe sale or facilitation of medicines or drugs that require \na prescription or physician consultation\u201d; or information on \u201cadverse \nimpacts or effects of receiving vaccinations, where these claims have been \nwidely debunked\u201d (Twitter, 2020d). It targets conspiratorial language, \nlabeling tweets \u201cwhich suggest that COVID-19 vaccinations are part of a \ndeliberate or intentional attempt to cause harm or control populations\u201d \n(Twitter, 2020d). It reinforces consent to local authoritative guidelines by \ntargeting tweets that dispute \u201clocal or national advisories or mandates \npertaining to curfews, lockdowns, travel restrictions, quarantine proto -\ncols, inoculations \u2026,\u201d and even targets tweets about \u201cresearch findings \n(such as misrepresentations of or unsubstantiated conclusions about \nstatistical data) used to advance a specific narrative that diminishes the \nsignificance of the disease.\u201d Once again, all of the above is first labeled, \nand then removed (Twitter, 2020d).\nFinding 4: Twitter acts as a debunking system. In practice, this means \nlabeling almost every tweet that mentions a COVID-19 treatment ingredient \ndisputed by authoritative sources (see Figure\u00a06.8). Though some are deleted, \nmost are simply flagged and redirected to a centralized reference page on \nlocal COVID-19 guidelines and information. This also applies to claims dis -\nputed amongst authoritative sources, such as whether hydroxychloroquine \nis or is not a safe drug.\n124  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nCovid-19 misleading information policy\nJanuary 29, 2020\nF\nebruary 4, 2020\nMarch 4, 2020\nZero tolerance approach to platform manipulation\nApril 11, 2020\nMay 11, 2020\nType of rhetoric\nMedia shared in a deceptive manner\nMarch 16, 2020\nJuly 14, 2020\nInformation that may increase the likelihood \nof exposure to the virus\nInformation that may have adverse effects \non the public health system\u2019s capacity to \ncope with the crisis\nDec 16, 2020\nFalse of misleading affiliation\nCounterspeech\nPersonal anectodes or first-person accounts\nPublic debate about the advancement of \nCOVID-19 science and research\nCOVID-19 #KnowTheFacts search prompt launched\n#KNOWTHEFACTS LABEL\nSynthetic or manipulated media\nREMOVAL\nLABEL\nWARNING\nDEMOTION\nREMOVAL\nLABEL\nWARNING\nDEMOTION\nBroadened definition of \n\u201c\nharm\n\u201d\nLABEL\nREMOVAL\nUnverified claims that have the potential to incite\npeople to action, could lead to the destruction or\ndamage of critical infrastructures, or cause \nwidespread panic or social unrest\nSUSPENSION\nNew labels and warning images\nLABEL\nTweets that are an assertion of fact (not an option),\nexpressed definitely, and intended to influence\nothers\u2019 behavior\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nFalse or misleading information about the nature \nof the virus\nLABEL\nREMOVAL\nLABEL\nREMOVAL\nFalse or misleading information about the efficacy\nand/or safety of preventative measures, \ntreatments, or other precautions to mitigate or \ntreat the disease\nLABEL\nREMOVAL\nStrong commentary, opinions, and/or satire\nALLOWED\nALLOWED\nALLOWED\nALLOWED\nfi gure\u00a06.7 Timeline of Twitter\u2019s \u201c c oVi d- 19 \nmisleading information policy.\u201d Source \nin image. Visualization by \nem\nillie de \nKeulenaar, with previous contributions by \ngu\nilherme \nap\npolin\u00e1rio.\nTWiT T e r a S  acciden Ta l au Th ori Ty  125\nfi gure\u00a06.8 he atmap of audience tweets that mention a list of treatments for coVi d- 19. in g reen are \nnumbers of unmoderated tweets; in red, moderated tweets. Visualization by \nca\nrlo \nga\netano.\n126  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nfi gure\u00a06.9 be e swarm of Twitter labels for tweets mentioning coVi d  \ntransmission, prevention and treatment. Visualization by \nemi\nllie de \nKeulenaar.\nTWiT T e r a S  acciden Ta l au Th ori Ty  127\nfi gure\u00a06.10 be e swarm of moderated audience and Trump tweets mentioning words related to \nc\noVi\nd-\n19 treatments, transmission and prevention. \nev\nery dot is one or many tweets posted in a \ngiven day. Visualization by \nemi\nllie de Keulenaar.\n128  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nIt also means supporting authoritative sources in their continuous debunk -\ning of user claims (Figure\u00a06.9). Authoritative sources\u2014the World Health \nOrganization, in particular\u2014repeatedly deny claims made on social media.\nFinding 5: In the absence of consensus between authoritative sources, \nTwitter intervenes as an authority in its own right. At issue is that disagree -\nments amongst authoritative sources create a crisis of authority on the \nplatform. Twitter can no longer redirect users to one specific source. In \nthe absence of consensus among authorities, Twitter begins to highlight \nthe disputed nature of even authoritative claims (see Figure\u00a06.10). This \napplies particularly to U.S. President Donald Trump\u2019s private account. While \naudience tweets are more severely moderated (suspended, deleted), Trump\u2019s \ntweets initially obtain the \u201c#KnowTheFacts\u201d prompt the platform introduced \nin January\u00a029th (see Figure\u00a06.7). Reuniting several other authoritative sources, \nthis prompt is intended to display current consensus among a majority of \nauthoritative sources, including \u201ctrusted news sources\u201d (Twitter, 2020c). \nAs Trump alleges that \u201csometimes over 100,000\u201d people \u201cdie from the Flu\u201d \nin October, Twitter flags it for violating \u201cthe Twitter Rules about spreading \nmisleading and potentially harmful information related to COVID-19.\u201d The \nsame happens to a later tweet claiming immunity from COVID-19.\nBoth of them do stay up, in accordance with Twitter\u2019s \u201cWorld leaders\u201d and \n\u201cPublic-interest exceptions\u201d policies (Twitter, 2019), until Trump\u2019s account is \npermanently suspended for violating a separate policy designed to prevent \n\u201cglorification of violence\u201d (Twitter, 2021) .\nMethods\nThe methodology of this study is two-fold. Based on a collection of millions \nof tweets, we first parse, analyze and visualize diverging claims on COVID-19 \ntransmission, prevention and treatments between U.S. authoritative sources \nand their respective audiences. We then look at how Twitter moderated \ndisputed claims by first consulting content moderation policies designed \nfor COVID-19 misinformation, and then obtaining moderation metadata \nfrom tweets containing disputed contents.\nDefinitions\nThe U.S. has at least two channels responsible for communicating authorita -\ntive information on COVID-19: its head of state and its health departments \nor disease prevention agencies (See Table\u00a06.1 in Annex). Because Twitter \nTWiT T e r a S  acciden Ta l au Th ori Ty  129\nprioritizes the World Health Organization as an authoritative source, we also \ncaptured data from that organization\u2019s international and American offices. \nWe refer to heads of state and public health organizations as \u201cauthoritative \nsources,\u201d and the WHO, health ministries, departments and disease preven -\ntion agencies as \u201cpublic health organizations.\u201d By \u201caudiences,\u201d we refer to \nusers who have at some point interacted with any one of the authoritative \nsources on our list, be it by replying, mentioning them or their website \ndomains (e.g., whitehouse.org).\nBy \u201cclaims\u201d about the coronavirus, we mean information that can be \nconfirmed as true or refuted as false by governments and health organiza -\ntions. We focused on how the virus is transmitted, available treatments, \nand preventive methods.\nData collectionFor data collection on Twitter, we used Borra and Rieder\u2019s Twitter Capture \nand Analysis Toolkit, which collects tweets based on a chosen set of queries \n(Borra and Rieder, 2014). These queries were \u201ccovid,\u201d \u201ccoronavirus\u201d and \n\u201cWuhanVirus\u201d and captured a total of 61,498,037 tweets from January\u00a026 to \nOctober\u00a02020. Of those, we extracted 910 tweets from government and public \nhealth organizations and 496,166 replies and mentions of official domains. \nIn addition to tweets, we also collected claims on COVID-19 transmission, \nprevention and treatment by the CDC, NIV and Donald Trump\u2019s administra -\ntion on their official websites (cdc.gov, nih.org, whitehouse.gov). Information \non Twitter\u2019s COVID-19 misinformation moderation policies came primarily \nfrom two sources: Twitter\u2019s blog on COVID-19 and its \u201cCOVID-19 Misleading \nInformation Policy.\u201d From these, we were able to note what information they \ntarget and how they moderate it (suspension, labeling, deletion, etc.). We \nthen obtained moderation metadata from tweets that mentioned disputed \nclaims by using Selenium, the web scraping application.Parsing claims inductively and deductivelyTo map divergences in government, public health organization and \u201caudi -\nence\u201d statements about COVID-19, we sought to capture and compare the \nwidest possible range of claims about the transmission, prevention and \ntreatment of the virus. We captured both true and false statements with \nboth deductive and inductive approaches. The deductive approach consisted \nin consulting secondary sources on COVID-19 misinformation, such as \nWikipedia (Table\u00a06.1 in Annex). The inductive approach consisted in manual \n130  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nand semi-automatic capture of claims. This involved reading tweets and \n(authoritative or official) websites that contained the words \u201ctransmission,\u201d \n\u201cprevention\u201d or \u201cprotection\u201d and \u201ctreatment\u201d or \u201ccure.\u201d We also generated \nword embeddings and bigrams for the queries \u201ctransmission,\u201d \u201cprevention\u201d \nor \u201cprotection\u201d and \u201ctreatments\u201d or \u201ccure\u201d to find other relevant terms. We \nobtained a total of 48 words for transmission, 83 for treatments (2,739 with \nmedications extracted from drugbank.ca) and 79 for prevention (Table\u00a06.2 \nin Annex).\nCoding and filtering claims in tweets and official websitesWe split and detected sentences per topic as follows:\n1. Transmission: sentences mentioning \u201cinfect,\u201d \u201ctransmi,\u201d \u201ctransfer,\u201d \u201ccontag,\u201d \n\u201ccontamin,\u201d \u201ccatch,\u201d or \u201cspread\u201d;\n2. Prevention: sentences mentioning \u201cprevent,\u201d \u201cprotect\u201d; and3. Treatment: sentences mentioning \u201ctreatment,\u201d \u201ccure\u201d and \u201cvaccine.\u201d\nFor more complex queries such as whether the virus is airborne or whether \none should wear masks, we manually coded every sentence that mentioned \nboth \u201cwear\u201d and \u201cmask\u201d for the masks query and \u201cairborne\u201d and either \n\u201caerosol\u201d or \u201cdroplet\u201d for the \u201cairborne\u201d query. For sentences mentioning \nCOVID-19 transmission, coding meant annotating claims that (1) the virus \nis or is not airborne, and more specifically that (2) it spread through droplets \nor aerosols. For those mentioning protection, it implied annotating claims \nthat (1) the general public should and should not wear masks (\u201cshould wear,\u201d \n\u201cshould not wear,\u201d respectively) and (2) who should be wearing masks \n(caregivers, essential workers, travelers\u2026). In many cases, claims were far beyond simple binaries, and if frequent, required a category of their own.\nWe then manually coded the information retrieved from government \nand health authorities\u2019 official webpages on whether they provided any \ninstructions or claims about transmission, treatments and use of masks \nthat were inconsistent among them. We used the Internet Archive to track \nchanges in the information in these webpages from January\u00a02020 to July\u00a02020. \nFor each page with any information about transmission, treatments or use \nof masks, we coded them by date of change accordingly. For transmission, we coded if they agree if the transmission is possible through airborne or \naerosol, contact, droplet, fluid or animals. For treatments, we coded if they \nrecommend chloroquine, hydroxychloroquine or ibuprofen. For masks, we \ncoded if they recommend wearing a mask or face-covering in public, wear a mask if one has symptoms, or wear a mask if around sick people.\nTWiT T e r a S  acciden Ta l au Th ori Ty  131\nCoding and filtering claims in social media textual data: Limitations\nTwitter audience responses contain a large number of retweets of claims \nmade by authoritative sources. Because of this, we also included tweets that \ndo not necessarily reply or mention authoritative sources but are geolocated \nin the U.S. Geolocation is included in TCAT\u2019s tweet metadata.\nModeration data\nModeration status and labels for the 4.2 million relevant tweets (i.e., by \nauthoritative sources or audiences, and containing any of our keywords) \nwere gathered using web scraping (Selenium).\nReferences\nAchenbach, J. and Johnson, C. Y. (2020, April\u00a030). Studies leave question of \u201cair -\nborne\u201d coronavirus transmission unanswered. Washington Post . https://www.\nwashingtonpost.com/health/2020/04/29/studies-leave-question-airborne-\ncoronavirus-transmission-unanswered/.\nBordia, P. and Difonzo, N. (2004). Problem solving in social interactions on the \ninternet: Rumor as social cognition. Social Psychology Quarterly , 67(1), pp.\u00a033\u201349. \nhttps://doi.org/10.1177/019027250406700105.\nBorra, E. and Rieder, B. (2014). Programmed method: Developing a toolset for \ncapturing and analyzing tweets. Aslib Journal of Information Management , \n66(3), pp.\u00a0262\u2013278. https://doi.org/10.1108/AJIM-09-2013-0094.\nBostrom, A., Joslyn, S., Pavia, R., Walker, A. H., Starbird, K., and Leschine, T. M. (2015). \nMethods for communicating the complexity and uncertainty of oil spill response \nactions and tradeoffs. Human and Ecological Risk Assessment: An International \nJournal , 21(3), pp.\u00a0631\u2013645. https://doi.org/10.1080/10807039.2014.947867.\nCaplow, T. (1946). Rumors in war departmental contributions: Teaching and research \nin the social sciences. Social Forces , 25(3), pp.\u00a0298\u2013302. https://heinonline.org/\nHOL/P?h=hein.journals/josf25andi=314.\nCenters for Disease Control and Prevention. (2020, April\u00a01). Healthcare professionals: \nFrequently asked questions and answers. Centers for Disease Control and \nPrevention. https://web.archive.org/web/20200401051025/https://www.cdc.gov/\ncoronavirus/2019-ncov/hcp/faq.html.\nChu, J. and McDonald, J. (2020, January\u00a029). Helping the world find credible informa -\ntion about novel #coronavirus. Twitter Blog. https://blog.twitter.com/en_us/\ntopics/company/2020/authoritative-information-about-novel-coronavirus.\n132  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nDailey, D. and Starbird, K. (2015). \u201cIt\u2019s raining dispersants\u201d: Collective sensemaking of \ncomplex information in crisis contexts. In Proceedings of the 18th ACM Conference \nCompanion on Computer Supported Cooperative Work and Social Computing , \npp.\u00a0155\u2013158. https://doi.org/10.1145/2685553.2698995.\nDe Keulenaar, E., Burton, A.G., and Kisjes, I. (2021). Deplatforming, demotion and \nfolk theories of Big Tech persecution. Fronteiras \u2013 Estudos Midi\u00e1ticos , 23(2), \npp.\u00a0118\u2013139. https://doi.org/10.4013/fem.2021.232.09.\nDe Zeeuw, D., Hagen, S., Peeters, S., and Jokubauskaite, E. (2020). Tracing normiefica -\ntion: A cross-platform analysis of the QAnon conspiracy theory. First Monday , \n25(11). https://doi.org/10.5210/fm.v25i11.10643.\nDwoskin, E. (2020, November\u00a012). Trump\u2019s attacks on election outcome prolong \ntech\u2019s emergency measures. Washington Post . https://www.washingtonpost.\ncom/technology/2020/11/12/facebook-ad-ban-lame-duck/.\nEconomist (2019, June\u00a08). Google rewards reputable reporting, not left-wing \npolitics. The Economist . https://www.economist.com/graphic-detail/2019/06/08/\ngoogle-rewards-reputable-reporting-not-left-wing-politics.\nGolebiewski, M. and boyd, d. (2019). Data voids: Where missing data can easily be \nexploited. Data & Society Research Institute. https://datasociety.net/wp-content/\nuploads/2019/11/Data-Voids-2.0-Final.pdf.\nIati, M., Kornfield, M., O\u2019Grady, S., and Mellen, R. (2020, May\u00a04). Trump says it\u2019s \nsafe to reopen states, while Birx finds protesters with no masks or distancing \n\u201cdevastatingly worrisome.\u201d Washington Post . https://www.washingtonpost.com/\nworld/2020/05/03/coronavirus-latest-news/.\nInternet Archive. (2021). Internet archive: Digital library of free & borrowable \nbooks, movies, music & Wayback Machine [Web-based]. Internet Archive. \nhttps://archive.org/.\nKou, Y., Gui, X., Chen, Y., and Pine, K. (2017). Conspiracy talk on social media: \nCollective sensemaking during a public health crisis. In Proceedings of the \nACM on Human-Computer Interaction , 1(CSCW), article no.\u00a061. https://doi.\norg/10.1145/3134696.\nKrafft, P., Zhou, K., Edwards, I., Starbird, K., and Spiro, E.S. (2017). Centralized, \nparallel, and distributed information processing during collective sensemaking. \nIn Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , \npp.\u00a02976\u20132987. https://doi.org/10.1145/3025453.3026012.\nLee, L. and Oppong, F. (2020, September\u00a01). Adding more context to trends. Twitter Blog. \nhttps://blog.twitter.com/en_us/topics/product/2020/adding-more-context-to-trends.\nLewis, D. (2020). Is the coronavirus airborne? Experts can\u2019t agree. Nature , 580(7802), \np.\u00a0175. https://doi.org/10.1038/d41586-020-00974-w.\nLyons, K. (2020, October\u00a011). Twitter flags, limits sharing on Trump tweet about being \u201cim -\nmune\u201d to coronavirus. The Verge . https://www.theverge.com/2020/10/11/21511682/\ntwitter-disables-sharing-trump-tweet-coronavirus-misinformation.\nTWiT T e r a S  acciden Ta l au Th ori Ty  133\nMandavilli, A. (2020, July\u00a04). 239 experts with one big claim: The coronavirus is \nairborne. New York Times . https://www.nytimes.com/2020/07/04/health/239-\nexperts-with-one-big-claim-the-coronavirus-is-airborne.html.\nO\u2019Leary, N. (2020, March\u00a010). How Dutch false sense of security helped corona -\nvirus spread. Irish Times . https://www.irishtimes.com/news/world/europe/\nhow-dutch-false-sense-of-security-helped-coronavirus-spread-1.4199027.\nRoth, Y. and Pickels, N. (2020, May\u00a011). Updating our approach to misleading in -\nformation. Twitter Blog. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.\nScheufele, D. A. and Krause, N. M. (2019). Science audiences, misinformation, and \nfake news. Proceedings of the National Academy of Sciences , 116(16), pp.\u00a07662\u20137669. \nhttps://doi.org/10.1073/pnas.1805871115.\nSchmitt, C. (2005). Political theology: Four chapters on the concept of sovereignty . \nUniversity of Chicago Press.\nShibutani, T. (1966). Improvised news: A sociological study of rumor . Ardent Media.\nSkopeliti, C., and John, B. (2020, March\u00a019). Coronavirus: How are the social media \nplatforms responding to the \u201cinfodemic\u201d? First Draft. https://firstdraftnews.\norg:443/latest/how-social-media-platforms-are-responding-to-the-coronavirus-\ninfodemic/.\nStarbird, K. (2012). Crowdwork, crisis and convergence: How the connected crowd \norganizes information during mass disruption events [PhD].\nStarbird, K. (2020, April\u00a027). How to cope with an infodemic. Brookings. https://\nwww.brookings.edu/techstream/how-to-cope-with-an-infodemic/.\nStarbird, K., Spiro, E., Edwards, I., Zhou, K., Maddock, J., and Narasimhan, S. (2016). \nCould this be true? I think so! Expressed uncertainty in online rumoring. In \nProceedings of the 2016 CHI Conference on Human Factors in Computing Systems , \npp.\u00a0360\u2013371. https://doi.org/10.1145/2858036.2858551.\nTwitter (2019, October\u00a015). World leaders on Twitter: Principles & approach. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2019/worldleaders2019.\nTwitter (2020a, February\u00a07). Synthetic and manipulated media policy. Twitter. \nhttps://web.archive.org/web/20200207000218/https://help.twitter.com/en/\nrules-and-policies/manipulated-media.\nTwitter (2020b, April). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020c, May\u00a011). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020d, December\u00a016). COVID-19 misleading information policy. Twitter. \nhttps://web.archive.org/web/20201216200114/https://help.twitter.com/en/\nrules-and-policies/medical-misinformation-policy.\nTwitter (2021, January\u00a08). Permanent suspension of @realDonaldTrump. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/suspension.\n134  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nYong, E. (2020, April\u00a029). Why the coronavirus is so confusing. The Atlantic . \nhttps://www.theatlantic.com/health/archive/2020/04/pandemic-confusing-\nuncertainty/610819/.\nYouTube (2019, January\u00a025). Continuing our work to improve recommenda -\ntions on YouTube. YouTube Blog. https://blog.youtube/news-and-events/\ncontinuing-our-work-to-improve/.\nYouTube (2020). COVID-19 medical misinformation policy\u2014YouTube Help. https://\nsupport.google.com/youtube/answer/9891785?hl=en.\nAbout the authors\nEmillie de Keulenaar  is a PhD candidate at the University of Groningen, \nand a researcher at the University of Amsterdam\u2019s Open Intelligence Lab \nand the United Nations Department of Political and Peacebuilding Affairs. \nHer interests lie in the history and impact of speech moderation from a \ncross-platform perspective as well as the effects of deep disagreements in \nthe production of online misinformation.\nIvan Kisjes  is a scientific programmer at the CREATE lab at the University \nof Amsterdam, involved in computational research in various humanities domains.\nRory Smith  is the Research Manager at First Draft, where he leads on the \norganization\u2019s digital investigations into mis- and disinformation around \nthe world. Before joining First Draft, Rory worked for CNN, Vox and Vice, \ncovering various topics from immigration and food policy to politics and \norganized crime.\nCarina Albrecht is a doctoral candidate and SSHRC Canada Graduate \nScholar in the School of Communication at Simon Fraser University, and \nSFU-Mellon Critical Data Studies fellow at the Digital Democracies Institute. \nHer dissertation project explores alternative network science models for \nrecommendation systems and search engines.\nEleonora Cappuccio  is a PhD student in the Italian National Doctoral \nProgram in Artificial Intelligence. She completed her master\u2019s degree in \nCommunication Design at the Polytechnic University of Milan, developing \nher thesis at the DensityDesign research lab.\nTWiT T e r a S  acciden Ta l au Th ori Ty  135Annex\nTable\u00a06.1  S ources of false and true COVID-19 information.\nTransmission (only vehicles) Treatment (ingredients and medication) Prevention (protective measures, gear \nand preventive medicine)\nSecondary \nsourcesWikipedia (2020) \u201cTransmission (medicine),\u201d Wikipedia. https://en.wikipedia.org/w/index.php?title=Transmission_(medicine)&oldid=963983254.Wikipedia (2020a) \u201c\nco\nronavirus disease \n2019,\u201d Wikipedia. https://en.wikipedia.org/w/index.php?title=\ncor\nonavirus_\ndisease_2019&oldid=966470660.Wikipedia (2020a) \u201c co\nronavirus disease \n2019,\u201d Wikipedia. https://en.wikipedia.org/w/index.php?title=\ncor\nonavirus_\ndisease_2019&oldid=966470660.\nWikipedia (2020) \u201cMisinformation related to the \ncoVi\nd-\n19 pandemic,\u201d \nWikipedia. https://en.wikipedia.org/w/index.php?title=Misinformation_related_to_the_\nc\noVi\nd-\n19_pandemic&oldid=966340289.Wikipedia (2020b) \u201c li\nst of unproven methods \nagainst \ncoVi\nd-\n19,\u201d Wikipedia. https://\nen.wikipedia.org/w/index.php?title= li\nst_\nof_unproven_methods_against_ c\noVi\nd-\n1\n9&oldid=966515765.Wikipedia (2020b) \u201c li\nst of unproven methods \nagainst \ncoVi\nd-\n19,\u201d Wikipedia. https://\nen.wikipedia.org/w/index.php?title= li\nst_\nof_unproven_methods_against_ c\noVi\nd-\n1\n9&oldid=966515765.\nWikipedia (2020) \u201c co\nronavirus disease 2019,\u201d Wikipedia. https://en.wikipedia.org/w/index.\nphp?title= co\nronavirus_disease_2019&oldid=966470660.\nPrimary sources c\ndc\n (2020) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Transmission, \nce\nnters for \ndi\nsease \nco\nntrol and Prevention. https://\nwww.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/how-covid-spreads.html.c\ndc\n (2020a) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Prevention & Treatment, \nce\nnters for \ndi\nsease \nco\nntrol and Prevention. \nhttps://www.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/prevention.html.c\ndc\n (2020) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Prevention & Treatment, \nce\nnters for \ndi\nsease \nco\nntrol and Prevention. \nhttps://www.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/prevention.html.\ngo\nv.us (2020) \nho\nw it spreads \u2013 \ncoVi\nd-\n19 \nan\nswers, gov.us. https://faq.coronavirus.gov/\nspread/.c\ndc\n (2020b) \nco\nronavirus \ndi\nsease 2019 \n(c\noVi\nd-\n19)\u2014Therapeutic \nop\ntions, \ncen\nters \nfor \ndi\nsease \nco\nntrol and Prevention. https://\nwww.cdc.gov/coronavirus/2019-ncov/hcp/therapeutic-options.html.go\nv.uk (2020) \nco\nronavirus \n(c\noVi\nd-\n19): guidance, \ngoV\n.uK\n. https://\nwww.gov.uk/government/collections/coronavirus-covid-19-list-of-guidance.\n136  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  Transmission (only vehicles) Treatment (ingredients and medication) Prevention (protective measures, gear \nand preventive medicine)\nn\nhS\n (2020) \nco\nronavirus\u2014Virus transmis-\nsion, \nnh\nS. https://www.england.nhs.uk/\ncoronavirus/primary-care/about-covid-19/\nvirus-transmission/.drugba\nnk (2020) \ndrug\ns\u2014drugba\nnk, \ndr\nugba\nnk. https://www.drugbank.ca/drugs.go\nv.us (2020) \nho\nw it spreads\u2014 c\noVi\nd-\n19 \nan\nswers, gov.us. https://faq.coronavirus.gov/\nspread/.\ngo\nv.uk (2020) \nco\nronavirus \n(c\noVi\nd-\n19): guidance, \ngoV\n.uK\n. https://\nwww.gov.uk/government/collections/coronavirus-covid-19-list-of-guidance.n\nh\nS (2020) \nco\nronavirus\u2014Virus transmission, \nnh\nS. https://www.england.nhs.uk/\ncoronavirus/primary-care/about-covid-19/virus-transmission/.\nWorld \nhe\nalth \nor\nganization (2020) \nad\nvice \nfor the public, World \nhe\nalth \nor\nganization. \nhttps://www.who.int/emergencies/diseases/novel-coronavirus-2019/advice-for-public.ni\nh.gov (2020) What\u2019s new | \nco\nronavirus \ndi\nsease \ncoVi\nd-\n19, \ncoVi\nd-\n19 Treatment \ngu\nidelines. \nhttps://www.covid19treatmentguidelines.nih.gov/whats-new/.\nWorld \nhe\nalth \nor\nganization (2020) \nad\nvice for the public, W h\no. h\nttps://www.who.int/\nemergencies/diseases/novel-coronavirus-2019/advice-for-public.\nAdditional \nsourcesWord embeddings and bigrams for \u201ctransmission\u201d and \u201ccontagion\u201dWord embeddings and bigrams for \u201ccure\u201d and \u201ctreatment\u201dWord embeddings and bigrams for \u201cprotec -\ntion\u201d and \u201cprevention\u201d\nTWiT T e r a S  acciden Ta l au Th ori Ty  137\nTable\u00a06.2  D ictionaries of types of COVID transmission, treatment and prevention.\nTransmission (only \nvehicles)Treatment (ingredients and medication)Prevention (protective measures, gear and preventive medicine)\n5g ablution 1.5\u00a0m\nairborne alcohol 2\u00a0m\nasymptomatic people andrographis paniculata 6 ft\nbath tissue antihistamine ablution\nblood transfusion aspirin alcohol\nbreast milk azithromycin antibacterial soap\nclose contact bitter gourd avoid close contact\ncommunity spread black pepper avoid touching your eyes\ncoughing cannabis avoid touching your eyes, nose and mouth\ndirect contact\ncb\nd o\nil avoid touching your mouth\ndirect physical contact chlorine dioxide avoid touching your nose\ndroplet nuclei chloroform boiled ginger\ndroplets chloroquine carbolic soap\nelectromagnetic cocaine chlorine\nfecal-oral routes colloidal silver clean and disinfect\nfecal transmission cow dung cloth\nfecal-oral transmission cow urine disinfect regularly\nfomites dietary supplement disinfection\nindirect contact durian dispose of tissues\nindirect physical contact essential oil dryer\nintimate contact ethanol environmental cleaning\nkissing fasting facemask\nmicrochip fennel tea fasting\nmosquito goose fat gargling\noral transmission honey garlic\npetrol hot liquids garlic, ginger and onion\nphysical contact hot whiskey ginger\nradiation hydroxychloroquine sulphategood hygiene\nrespiratory droplets influenza complex high temperature\nsaliva lemon isolate\nsneezing mango lemon\nsputum methanol\nn95\nt\nick mineral mask\ntouch acetic acid face mask\nwet particles amphetamine, cocaine and nicotine2 arms\u2019 length\nwireless azithromycin 6 feet\nbiocharger arsenicum album\nboiled ginger avoid being exposed\n138  de Ke ulenaar ,  Ki SJeS , SM iTh,  albrech T  and  ca PPu ccio  \nTransmission (only \nvehicles)Treatment (ingredients and medication)Prevention (protective measures, gear and preventive medicine)\ndexamethasone cover your mouth\nin\ndian cow cover your nose\nlemon grass hand hygiene\nmechanical ventilatory supporthot liquids\nmint tea limits for public gatherings\nmiracle mineral supplement physical distance\nmustard patch physical distancing\nnasal spray plain soap\nneem leave red soap\nno cure respiratory etiquette\nno drug rum, bleach and fabric softener\nno treatment salt water\nno vaccine sauna\nplant sap self-isolation\nremdesivir sneeze in the crook of your elbow\nsaline soap and water\nsalt water social distance\nshuanghuanglian surgical masks\nsix deep breaths throw used tissues\nsnake oil turmeric\nsupplemental oxygen\nuV-c\ns\nupportive care uVc\nTa\nmiflu Virus Shut \nou\nt Protection\ntinospora crispa warm water\ntoothpaste warm weather\nturmeric wash hand\nvinegar wash your hands\nvitamin \nc w\nater and soap\nvitamin \nd c\nloth face cover\nwudu hand sanitizer\nzitroneer wet wipes\nall drugs mentioned in drugbank.cawhite handkerchief\nwhite tissue\n7 T he earnest platform\nU.S. presidential candidates, COVID-19, and social issues on \nInstagram\nSabine Niederer and Gabriele Colombo\nAbstract\nIncreasingly, Instagram is discussed as a site for misinformation, inau -\nthentic activities, and polarization, particularly in recent studies about \nelections, the COVID-19 pandemic and vaccines. In this study, we have \nfound a different platform. By looking at the content that receives the \nmost interactions over two time periods (in 2020) related to three U.S. \npresidential candidates and the issues of COVID-19, healthcare, 5G and \ngun control, we characterize Instagram as a site of earnest (as opposed \nto ambivalent) political campaigning and moral support, with a rela -\ntive absence of polarizing content (particularly from influencers) and \nlittle to no misinformation and artificial amplification practices. Most \nimportantly, while misinformation and polarization might be spreading \non the platform, they do not receive much user interaction.\nKeywords: social media, Instagram, U.S. elections, COVID-19, disinforma -\ntion, digital methods\nResearch questions\nTo what extent is ambivalent and divisive (or earnest and non-divisive) \ncontent present in the most interacted-with posts concerning political \ncandidates and social issues on Instagram in the run-up to the 2020 U.S. \npresidential elections? Do the candidates control their own \u201cname space,\u201d \ni.e., the (top) posts about them? Are there signs of artificial amplification (so-\ncalled fake or suspicious followers) among the candidates and their parties? \nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch07\n140  S abine ni ederer and ga briele co loMb o \nHow do influencers and celebrities on \u201cpolitical Instagram\u201d contribute to \nthe information climate?\nEssay summary\nDuring the \u201cfake news crisis\u201d of 2016, false news sources and front groups \nspread divisive and ambivalent information and misinformation across social \nmedia\u2014notably on Facebook but also on Twitter and Instagram\u2014in the \nperiod leading up to the U.S. presidential election (Silverman, 2016; DiResta \net al., 2018; Howard et al., 2018). In 2020, concerns about such misinformation \nand divisiveness heightened in the lead-up to the U.S. elections. These \nconcerns hit the global stage in full force with the rise of the COVID-19 \npandemic, in which misinformation about the disease, the necessity of \nthe precautions taken to curb its spread, and the safety of its vaccinations \ncould pose immediate public health threats.\nRecent studies and reporting have demonstrated that Instagram is suscep -\ntible to problematic information related to elections. Prior to the 2016 U.S. \nelections, Instagram was a fertile ground for disseminating misinformation \nand divisive content (Jack, 2017; DiResta et al., 2018). Furthermore, an analysis \nof Netherlands-based news media accounts on Instagram surfaced a special \naffinity (in terms of shared followers) between mainstream news sources and \nso-called junk news providers (Colombo and De Gaetano, 2020). Additionally, \nrecent studies have found that conspiracy theories and anti-vaccine content \nspread under the guise of lifestyle content (Bond, 2021; Tiffany, 2021; Maragkou, \n2020; McNeal and Broderick, 2020). Such \u201cpastel QAnon\u201d accounts\u2014con -\nspiracy theories spread in sugar-coated messages by \u201cmummy bloggers, \nwellness coaches and lifestyle influencers\u201d (Gillespie, 2020)\u2014are yet another \naddition to the \u201ccacophony of voices and narratives\u201d which \u201chave coalesced to create an environment of extreme uncertainty\u201d (Smith et al., 2020, p.\u00a02).\nA report by the Center for Countering Hate describes how users who follow \nanti-vax accounts are presented with other problematic information by the \nplatform\u2019s recommendation systems. These include \u201crecommendations for \nantisemitic content, QAnon conspiracy theories, and COVID misinforma -\ntion\u201d (Center for Countering Hate, 2021, p.\u00a08). The study points out how the \nU.S. elections and the pandemic have fueled the disinformation problem \n(Bond, 2021). Not only has there been an increase in disinformation because \nof the divisive U.S. elections and the COVID-19 pandemic, the platform\u2019s \nrecommendation systems further grow the problem by connecting health information to a diverse range of conspiracy theories.\nThe earne S T Pl aT for M 141\nInstagram has been studied for its role in spreading divisive and polarizing \ncontent and the amplification of hate speech or harmful content (Bradshaw \nand Howard, 2018). When other mainstream platforms successfully \u201cde -\nplatformed\u201d accounts accused of sharing hateful messages and polarizing \ncontent, for a while, Instagram functioned as a refuge, dubbed as \u201cinternet\u2019s \nnew home for hate\u201d (Lorenz, 2019) or \u201calt-right\u2019s new favorite haven\u201d (Sommer, \n2018). With deplatforming recently on the rise, and extreme user accounts \nforced to move to \u201can alternative social media ecosystem\u201d (Rogers, 2020b), \nthis opens up the question of whether the characterization of Instagram as \na safe place still holds and whether the platform has succeeded in cleaning \nup divisive and polarizing content, at least in high-engagement spaces.\nInstagram is also the platform most known (and studied) for inauthentic \nbehaviors, such as purchased followers or artificially inflated like and \ncomments counts, obtained through \u201cclick farms and follower factories\u201d \n(Lindquist, 2019), or by participating in \u201ccomment pods,\u201d where users convene to like and comment each other\u2019s posts to inflate their own \nengagement metrics (Ellis, 2019). Detecting and limiting such inauthentic \nactivities is an increasing need of the marketing industry, as one can \nnote from the deluge of audit tools to \u201cexamine the health\u201d (Hypeauditor, \n2021) of one account\u2019s follower base through scrutinizing various features \nsuch as following-follower ratios or number of posts. The platform itself \nperiodically deploys new measures with the aim of \u201ckeeping Instagram \nauthentic\u201d (Systrom, 2014), deactivating \u201cspammy accounts\u201d (Systrom, \n2014), deleting those using \u201cthird-party apps to boost their popularity\u201d \n(Instagram, 2018), or, more recently, asking suspicious profiles to verify \ntheir identity (Instagram, 2020).\nIn this study, we focus on multiple topics, exploring the quality of in -\nformation and the users active in those spaces as well as the authenticity \nof their follower bases. U.S. election-related posts are studied through the prism of the presidential candidates, Trump, Biden, and Sanders. We then identified much-discussed topics in these candidates\u2019 spaces and selected \ngun control, healthcare, COVID-19 and 5G as particularly salient. Where \nsome studies choose to filter out verified Instagram accounts to capture \n\u201corganic social media conversations as opposed to media reports\u201d (Smith \net al., 2020, p.\u00a08), or look at the \u201ctwilight zone\u201d (Shane, 2020) beyond highly engaged-with posts, for this study we focus on the most engaging content \n(in terms of user interactions) regardless of the source. Therefore, we do \nnot filter out any user accounts, which allows us to include in the analysis \ncelebrities and influencers, whose role in spreading misinformation and \ndivisive content has been an object of scrutiny in multiple cases due to \n142  S abine ni ederer and ga briele co loMb o \ntheir high level of interactions and follower bases \u201cpredisposed to believe \nthem and trust their messages\u201d (Ahmadi and Chan, 2020).\nThis study considers the quality of information on Instagram about \nthe U.S. presidential candidates of 2020, the COVID-19 pandemic, and a \nselection of social issues (healthcare, 5G, gun control). These topics are \nexplored in the spring and fall of 2020, where the study zooms in on posts \nper period that receive the most user interactions. For the top 50 posts, the \nstudy combines content analysis with user activity analysis and includes \na follower analysis to test for artificial amplification, as discussed in the \nmethods section.\nWe developed a coding scheme for the content analysis that builds on \nBenkler et al. (2018) and distinguishes between divisive content (that might \nfuel polarization, conspiracy, or conflict) and non-divisive content. Following \nPhillips and Milner (2017), we term as ambivalent content (contrasted here \nwith earnest content) posts that are not inflammatory but may still generate \na lighter form of division by possibly excluding those who do not have the \ncultural references to decode it, laugh about it, and involuntary become \n\u201claughed at\u201d (Phillips and Millner, 2017).\nIn applying these notions to the most interacted-with content concerning \npolitical candidates and social issues in 2020, we found, counter-intuitively, \nthat most is earnest as well as non-divisive. In fact, throughout 2020, the \npolitical and issue spaces become even more earnest. There is also little to \nno misinformation encountered. In spring of 2020, influencers, including \ncelebrities, mostly share responsible posts about the pandemic, while later in \nthe year, they mainly encourage people to vote. Regarding COVID-19, there is \nan evolution from health warnings and supportive messages to posts about \nmental health during a pandemic and posts demonstrating that personal \nand professional life goes on despite COVID-19.  Overall, our study finds a \nhealthier platform than one might expect from one often associated with \nmisinformation. While misinformation might be spreading on the platform, \nit does not receive much user interaction.\nImplications\nIncreasingly, Instagram is discussed as a site for misinformation, inauthentic \nactivities, and polarization, particularly in recent studies about elections, \nthe COVID-19 pandemic and vaccines. Conspiracy and anti-vax content \neven have appeared as gradient pastel images under the guise of wellness \nand lifestyle posts. In this study, we have found a different platform. By \nThe earne S T Pl aT for M 143\nlooking at the content that receives the most interaction, we characterize \nInstagram as a site of earnest political campaigning and moral support, with \na relative absence of polarizing content and little to no misinformation.\nFirst, we analyze posts that receive the most user interactions over two \ntime periods (the spring and fall of 2020) related to three U.S. presidential \ncandidates and the issues of COVID-19, healthcare, 5G and gun control. To \ncharacterize these spaces, we adopt a two-fold coding scheme: Following \nBenkler et al. (2018), we distinguish between \u201cdivisive\u201d and \u201cnon-divisive\u201d \nposts, and from Phillips and Milner (2017), we identify \u201cambivalent content\u201d \n(contrasted here with \u201cearnest content\u201d). These are posts that often through \nmultiple layers of meanings and irony might subtly fuel division, excluding \nthose who do not have the cultural references to decode them.\nSecond, in the same candidate and issues spaces, we perform a user \nactivity analysis, examining the most active users and the number of \ninteractions they generate with their posts. Third, in order to assess the \nauthenticity of U.S. presidential candidates and parties\u2019 audiences, we \nanalyze their follower bases, looking at suspicious behaviors (such as dubi -\nous geographical provenance) that might signal automation or artificial \namplification practices. Fourth, we zoom in on the role of celebrities and \ninfluencers, characterizing through close reading the nature and content \nof their posts with an eye towards their role in spreading misinformation and divisive content.\nOverall, our study finds a healthier space than one might expect from \na platform often associated with polarization and misinformation. In fact, \nthroughout 2020, the political and issue spaces become even more earnest. \nWhile misinformation and polarization might be spreading on the platform, \nthey do not receive much user interaction.\nIndeed, the findings show that while posts about political candidates may \nentail fierce campaigning, the overwhelming majority of the most engaged \nwith content is earnest and non-divisive. The finding is significant given \nthat research has shown how well divisive and false news and commentary \noften spread compared to more sincere content (Vosoughi et al., 2018; Klein \nand Robison, 2019).\nFor the posts concerning the three presidential candidates under study, \neach has an equal amount of divisive content (about 15%) in the top 50 \nposts. For that content, however, it was found that over half of it was posted \nby Trump or Trump, Jr. One implication is that the Trumps are a leading \nsource of divisiveness and that they are rather alone in that role, at least in \nthe top posts under study. It should be noted that Trump is also the main target of that content type. Of the remaining divisive content, most posts \n144  S abine ni ederer and ga briele co loMb o \nare about Trump or his administration. Engagement is an impact metric \nrather than a measure of sentiment. In other words, non-divisive, earnest \nposts may trigger positive but also negative comments, as we know from \nresearch into trolling and antagonistic behavior online (Phillips, 2015). \nNegativity in the comment space still leads to a high interaction score, so \nthe findings do not imply the absence of toxicity.\nThe namespace analysis shows an uneven distribution of attention to \nthe three candidates. Trump proved to be successful in dominating his own \nnamespace, while Biden\u2019s space is occupied by a variety of users (mainly \nendorsing him). Sanders is the most successful of the three candidates in \npopulating the others\u2019 namespaces. After losing the race to the presidential \nnomination in the fall, he is left alone in his space, and his language becomes \nmore divisive.\nIn a further examination of the followers of the political candidates and \nparties, we find signs of light artificial amplification only for the accounts \nof the Republican Party and Donald Trump. The finding implies that the \nmajority of the user interaction is not achieved through the purchasing of \nfollowers or likes, as was found in previous research, suggesting an apparent \nslowing of that practice (DiResta et al., 2018; Feldman, 2017).\nLastly, it is worthwhile to zoom in on the outsized role of particular users, \napart from the Trumps and the National Rifle Association. On a platform \nknown for its influencers, we can distinguish between at least two types of \n\u201cissue celebrities\u201d here. The one assumes a more traditional role of celebrity \nfundraising and awareness-raising, which we find mainly in healthcare posts \nby those who support front-line workers and hospitals during the pandemic \n(sometimes with financial donations). For the topic of COVID-19, we also \nsee other, more commercially entangled celebrity engagement, where they \nsell their products and promise to donate a percentage of the profits to a \nCOVID-related cause.\nThe study contributes to scholarly work that examines how visual \npractices on Instagram \u201care not just social media artifacts, isolated and \nindividual, but are surrounded by debates and discussions that take on \npolitical, legal, economic, technological, and sociocultural dimensions\u201d \n(Highfield and Leaver, 2016, p.\u00a049). By selecting the political content with \nmost interactions, we approach engagement on the platform in a more \ncomprehensive way than content posted by influencers only. Indeed, the \npoints of departure are the political debates and discussions. They take \ncenter stage rather than emerge as a byproduct of celebrity and influencer \nculture. In further assessing the content of top posts as earnest or ambiva -\nlent and divisive or non-divisive (Hedrick et al., 2018), it contributes to the \nThe earne S T Pl aT for M 145\ndiscussions on online (mis)information, offering an analytical framework \nthat is sensitive to critiques of thin ontologies as true or false content (Lazer \net al., 2018; Marres, 2018). The work thereby has methodological implications \nfor those categorizing contemporary social media content.\nFindings\nFinding 1: The top posts concerning political candidates and social issues on \nInstagram contain largely earnest and non-divisive content. Social media \nplatforms such as Instagram have been described as sites of misinformation \nand divisiveness, particularly around elections. In this study, however, the \npolitical and issue coverage that has received the most user interactions \non Instagram from January to mid-April\u00a02020 and from September\u00a02020 to \nJanuary\u00a02021 is primarily earnest and non-divisive, with scant ambivalent \ncontent.\nConcerning the political candidates, in spring approximately 85% of \nthe posts are non-divisive, and the vast majority is earnest. The amount \nof divisiveness in each of the different candidate\u2019s namespaces is more or \nless the same, but nearly half of such content is posted by Donald Trump \nor Donald Trump, Jr., and most of the remaining divisive posts are about \nTrump. In the fall, despite the U.S candidates\u2019 spaces remaining generally \nearnest and non-divisive, there are variations compared to the situation \nin spring, depending on the candidate. Biden\u2019s namespace has become \nmuch less divisive; both compared to that in spring and to the others. The \nnamespaces of Trump and Sanders have instead become more divisive than \nin spring. Sanders\u2019 space is the one with more divisive posts in the top 50 \namong the three candidates. Examining the tone and wordings of his posts, \nwe observe an increasingly more divisive language, with direct attacks to \nvarious opponents, including Joe Biden (see Figure\u00a07.2), President Trump and \nWall Street (e.g., \u201cpathetic \u2026 president\u201d and \u201cWall Street crooks\u201d). Posts about \nTrump also become slightly more divisive in spring. Trump\u2019s namespace \nhas the most memes and jokes, some making fun of him and others of his \nopponents (sometimes both in one meme). Furthermore, many of the posts \nin the Trump space are labeled and fact-checked by Instagram (Figure\u00a07.3), \nwith banners, blurring covers and various notices.\nThe fact that Instagram overlays content moderation notices and disclaim -\ners\u2014not only on Trump\u2019s statements and videos but also on memes and fake \nscreenshots posted by satirical accounts\u2014generates an additional layer of \nmessiness that contributes to the ambivalence of this space.\n146  S abine ni ederer and ga briele co loMb o \nfi gure\u00a07.1 ex ample of be rnie Sanders\u2019 posts becoming more divisive in wording. Sources: https://\nwww.instagram.com/p/ b9\nX3SZ o\nbx\nhX/; https://www.instagram.com/p/ c\nh1\nKx5 i\nbsMn/\n.\nfi gure\u00a07.2 ex amples of fact-checking and content moderation notices found in Trump space \nin fall. Sources: https://www.instagram.com/p/ c\ngr\nPpa-\nMKl1\n/; https://www.instagram.com/p/\nc\nhlS\n06f\nbu\nfb/\n; https://www.instagram.com/p/ c\nhncr w\nwl\ni\n4f/.\nThe earne S T Pl aT for M 147\nFinding 2: While social issues are mostly discussed in earnest and non-\ndivisive ways in the most engaging posts, some are more divisive than \nothers. Moving from spring to fall, issue spaces remain largely earnest \nand non-divisive (except for gun control), but the content of the posts dif -\nfers over time. Contrary to reports about online misinformation on social \nmedia, we find Instagram to be an earnest space of non-divisive content \nabout the COVID-19 pandemic and healthcare, mostly posting in support \nof healthcare workers and encouraging users to stay safe. In the fall posts \nabout the pandemic and health, in general, become even more earnest and \nnon-divisive (with only one divisive post in the healthcare space), and the \ncontent of the posts changes. COVID-19 no longer dominates healthcare \nposts; instead, they address mental health and include well-wishing.\nFrom the spring to the fall the COVID-19 space moves from posts support -\ning healthcare workers and encouraging users to stay safe to posts about \nactivities that are taking place despite the pandemic. In the first period \nconspiracy is present in the 5G space, amidst mainly commercial content, \nfi gure\u00a07.3 cl assification of the top 50 in stagram posts (receiving most interactions) in the political \ncandidates\u2019 namespaces. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013\nJanuary\u00a05, 2021. \nda\nta source: \ncr\nowdTangle.\n148  S abine ni ederer and ga briele co loMb o \nwith the top post dismissive of the conspiracy theory that the coronavirus is \nspread through Chinese-made 5G towers. The 5G space becomes even more \nearnest in the second period under study, with a total absence of divisive \nor ambivalent content in the top posts, which are mainly commercial and \nwith no signs of conspiracy-themed content in the top 50. We find one 5G \nconspiracy-related post well down in the results (#306). A post by Robert F. \nKennedy, Jr., now removed from Instagram (Jett, 2021), references \u201cdeadly \n5G radiation\u201d together with \u201cBig Pharma,\u201d \u201cBig Data,\u201d \u201cBill Gates\u201d and the \n\u201cCOVID vaccine project.\u201d Gun control is the most divisive of the issues we analyzed, and its top 50 posts are dominated by a single user, the National \nRifle Association (with 30 out of the 50 posts), becoming even more divisive \nover time.\nfi gure\u00a07.4 cl assification of the top in stagram 50 posts (receiving most interactions) in the issues \nspaces. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013January\u00a05, 2021. \nda\nta \nsource: \ncr\nowdTangle.\nThe earne S T Pl aT for M 149\nFinding 3: Trump performs well in his own namespace in the spring, \nwhile Biden is crowded out of his. In the fall, Sanders is left alone in his own \nnamespace. For each candidate, we looked at their respective namespace, \nthat is, the body of posts that @-mention the candidate. The rationale to \ndo so is that when a presidential candidate holds control over his own \nnamespace, this space is likely to be less divisive or ambivalent than when \nothers mostly post about the candidate. For a candidate, controlling one\u2019s \nown namespace might mean being able to actively steer the discourse in \ntheir favor and reducing the level of divisiveness. In this next analytical step, \nwe assess if and how the namespace is affected\u2014in terms of its divisiveness \nand ambivalence\u2014when the candidate occupies it.\nLooking at the most active users in each candidate\u2019s namespace, Trump \nperforms well in his namespace in both time frames analyzed. Trump\u2019s own \nInstagram content, likely run by his campaign, is not as negative as the \ninsulting messages he is known for on Twitter (Quealy, 2017; Lee and Quealy, \n2019). Many of his most engaging Instagram posts in the initial period are \nabout his Super Tuesday wins in several states. However, of the earnestly \ndivisive posts across all namespaces, many are by Trump or Trump, Jr. \nCompared to the spring, Trump still dominates his own namespace in the \nfall. His top posts in total receive fewer interactions than before, however, \nand there is a broader variety of users receiving interaction, including Snoop \nDogg (with memes) as well as Kamala Harris, Michelle Obama, and Hillary \nClinton (with critical posts).\nIn the spring Biden\u2019s account does not have a strong presence in the top \nposts about him. His namespace shows the most user diversity. Popular \ncontent posted about him by others varies from endorsements, the most \npopular of which was that by Barack Obama, to criticism and campaigning, \nfor instance by Sanders in 1/5 of the top posts. Donald Trump, Jr. is also active \nin Biden\u2019s namespace, calling him out for his son\u2019s business in China and \nhis views on gun control. In the next period, Biden\u2019s namespace remains \ncrowded with diverse users, many of whom are non-political celebrities \nencouraging users to vote for him or congratulating him.\nIn the spring, Sanders is the most successful of the three candidates \nin populating the others\u2019 namespaces, posting much-interacted-with, \ncampaign-style content about Trump and Biden. In second timeframe, \nSanders is left alone in his own namespace, with the number of active users \nshrinking dramatically. Whereas in the first period, Sanders\u2019 namespace is \npopulated by a variety of users, in the second, Sanders dominates his own \nnamespace, with only six active users in the top 50, as expected after Biden \nbecame the democratic presidential candidate.\n150  S abine ni ederer and ga briele co loMb o \nFinding 4: There are few signs of artificial amplification in the U.S. political \nspace. In both time periods the accounts of U.S. presidential candidates \nand political parties on Instagram do not have suspicious follower bases, \nwith almost 75% giving indications of being genuine followers, with some \nexceptions and slight differences between the periods. In the spring Donald \nTrump\u2019s account and, more prominently, the Republican party account, have \nfi gure\u00a07.5 The most active in stagram users per political candidate\u2019s namespace. da te ranges: Janu-\nary\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013January\u00a05, 2021. \nda\nta source: \ncr\nowdTangle. \nThe user accounts in our dataset not marked as \u201cverified\u201d public figures by \nin\nstagram are blurred \nin the visualization.\nThe earne S T Pl aT for M 151\nslightly over 25% followers that the method considers suspicious (bots, or \nreal accounts that use automatic tools for following or unfollowing other \naccounts). In the fall the composition of tool-suspected followers for the \nfi gure\u00a07.6 in stagram follower analysis of political parties and candidates\u2019 accounts. br eakdown of \naudience types into categories. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, \n2020\u2013January\u00a05, 2021. \nda\nta source: \nhy\npeau\nditor.\n152  S abine ni ederer and ga briele co loMb o \naccounts of Trump has slightly decreased, while that of both the Republican \nand Democratic parties remain largely the same. Contrariwise, the number \nof suspicious followers has risen slightly for Joe Biden (with a total of 21.4% \nmass and suspicious followers) and Bernie Sanders (who reaches nearly 27% \nof mass and suspicious followers).\nAnalyzing the geographical provenance of the followers of each ac -\ncount, which can also indicate artificial amplification practices, we \nfound both timeframes the follower bases of the political candidates and \nparties to be overwhelmingly U.S.-based, with the exception of Donald \nTrump\u2019s. In the spring Trump\u2019s official account had 25% of followers \nfrom other locations than the U.S., including Iran, Brazil, and India. \nfi gure\u00a07.7 in stagram follower analysis of political parties and candidates\u2019 accounts. br eakdown \nof followers\u2019 countries of origin, showing the top 5 locations of users in the follower base of each \naccount. \nda\nte ranges: January\u00a01, 2020\u2013 ap\nril\u00a020, 2020 and September\u00a022, 2020\u2013January\u00a05, 2021. \nda\nta source: \nhy\npeau\nditor.\nThe earne S T Pl aT for M 153\nIn the fall we no longer find India-based users in the top 5 locations of \nDonald Trump followers.\nFinding 5: Celebrities and influencers generally make responsible \ncontributions to political Instagram. It is also worthwhile to zoom in \non the role of celebrities and influencers on a platform known for their \nsignificance in influencing public opinion. Generally speaking, their posts \nfall into the category of earnest and non-divisive. They raise awareness, \ndonate to causes, show support for a candidate, serve as role models, \nand debunk conspiracy theories. Indeed, some contributions fit into a \nlongstanding tradition of \u201cissue celebrity\u201d fundraising and awareness-\nraising, particularly concerning healthcare, with posts by celebrities who \nsupport (sometimes with financial donations) healthcare workers and \nhospitals during the pandemic in spring. In the posts concerning COVID-19, \nwe also witness celebrities promoting their products and promising to \ndonate a percentage of the profits to COVID-19 related funds, as Kim \nKardashian does in her four posts that make it into the top 50 on that issue. \nOn healthcare, on top is Tom Hanks\u2019 message from Australia, reporting \nthat he and his wife were infected and in self-isolation in Australia. In \nthe 5G space, it is a repost of hip-hop artist 55Bagz making fun of the \ncoronavirus-5G conspiracy that receives the most user interactions. On \nthe issue of gun control, however, rapper Kevin Gates\u2019s post of his daughter \nposing with a gun receives a great deal of attention in a space otherwise \ndominated by the National Rifle Association (with 30 posts in the top \n50). Concerning posts about political candidates, we see how candidate \nsupport messages by model and actress Emily Ratajkowski attract high \namounts of user interactions.\nIn the fall we still observe the prominent role of celebrities both in the \nissue and candidate spaces, although the pool of most active ones in the \ntop 50 posts changes slightly: new celebrities appear (such as athletes \nCristiano Ronaldo and Virat Kohli), while others who reached the top \nin spring have disappeared (e.g., Tom Hanks). Kim Kardashian (present \nin the top 50 with multiple posts in Spring) remains at the top. For some \nissues, the tone and the content celebrities discuss change considerably \ncompared to the previous period. Concerning COVID-19, messages of \nsupport and advice about the pandemic are replaced by posts that show \nhow life goes on despite the pandemic (at least for celebrities who can afford \nit): film sets are moved to comply with travel restrictions, or \u201cCOVID-free\u201d \nbirthday parties are held on private islands. In the health space, support \nfor healthcare workers is partly replaced with messages of awareness \n154  S abine ni ederer and ga briele co loMb o \nabout mental health issues, specifically around World Mental Health Day \non October\u00a010th.\nIn the political spaces, more celebrities are active, calling on users to \ngo and vote, both in dedicated posts (e.g., Jennifer Aniston) or by adding \n#voteforBiden to otherwise non-political posts. Indeed, among the candi-\ndates, Biden is the one receiving the most celebrity support. Together with \ncelebrities, some famous politicians (e.g., Barack Obama) voice support \nfor Biden, while others express criticism for Trump (e.g., Kamala Harris, \nMichelle Obama, and Hillary Clinton). In the Trump space, Snoop Dogg \nreceives quite a lot of attention by posting memes about the president.\nfi gure\u00a07.8 ex amples of celebrities\u2019 posts in fall: ce lebrities urging to vote in dedicated posts \n(Jennifer \nan\niston), or by inviting to vote (for \nbi\nden) in the caption of otherwise non-political posts \n(ar\niana \ngr\nande); \nce\nlebrity personal life (Kim Kardashian) and professional life (The \nro\nck) going on \ndespite \ncoVi\nd-\n19. Sources: https://www.instagram.com/p/ c\ngs\nker\n_je5\nd; https://www.instagram.\ncom/p/ c\ng5\nrtaa f8\nk_/; https://www.instagram.com/p/ c\ng2\nzK7Wggh f/\n; https://www.instagram.\ncom/p/ c\nhX\n3Tvo\nfrf\nn/.\nThe earne S T Pl aT for M 155\nMethods\nContent analysis of candidates and issues spaces\nThe Instagram data for this study is collected with CrowdTangle, Facebook\u2019s \nmedia monitoring tool that has been made available to academics through \nthe Social Science One program. CrowdTangle allows users to collect \nInstagram posts that mention one or more keywords during a specific \nfi gure\u00a07.9 The most active in stagram users per issue space. da te ranges: January\u00a01, 2020\u2013 ap ril\u00a020, \n2020 and September\u00a022, 2020\u2013January\u00a05, 2021. Source: \ncr\nowdTangle. The user accounts in our \ndataset not marked as \u201cverified\u201d public figures by \nin\nstagram are blurred in the visualization.\n156  S abine ni ederer and ga briele co loMb o \ntime frame. To create our dataset, we first compiled a list of keywords \nfor each candidate, including candidate names, campaign slogans, and \nmost-used hashtags. Then, we selected four of the most-mentioned topics \nin the candidate spaces: healthcare, COVID-19, 5G and gun control. For \neach of these topics, we compiled a list of relevant keywords intending \nto include official terms, vernacular words, and, if applicable, pro- and \ncounter-terminology, e.g., including in the query both \u201cgun control\u201d and \u201cgun \nownership.\u201d (See Appendix for the full list of queries.) We used each query \nto collect Instagram posts shared in two timeframes: between January\u00a01 and \nApril\u00a020, 2020 (we refer to this period as spring throughout this chapter) \nand between September\u00a022, 2020, and January\u00a05, 2021 (which we refer to as \nfall). For each query and each period, we selected the top 50 posts based on \nthe total sum of interactions, which is the number of likes and comments \nby Instagram users that a post has received.\nIn this study, we focus on most engaged with posts, as well as most active \nusers in high-engagement spaces, asking specifically whether the posts from \nhighly visible accounts receiving the most user interactions are earnest or \nambivalent and whether they are divisive or not. After having manually \nremoved unrelated posts from the dataset, we conduct a close reading of the \ntop 50 posts per space, taking into consideration both the visual elements \n(image or video) and the post captions, applying a four-category analytical \nscheme (see Figure\u00a07.10).\nWe flag as divisive content posts that fuel conflict, polarization, or even \nradicalization (following Benkler et al., 2018), in contrast to more positive messages (e.g., supporting a candidate or sharing quarantine tips), which we label as non-divisive. We make a distinction between earnest content \nthat is posted with clear intent and may be understood by many users and \ncontent that often through humor or (sub)cultural references lends itself \nto different interpretations, depending on those who receive it and what \nthey read into it. Here, we keep in mind the possibility of encountering \nconvincing yet \u201cmaliciously \u2018fake\u2019 content\u201d (Highfield and Leaver, 2016, \np.\u00a052).\nIn opposition to \u201cearnest and non-divisive\u201d content, we categorized \nas \u201cearnest and divisive\u201d inflammatory posts that might fuel polariza -\ntion, conspiracy, or conflict. We used \u201cambivalent and non-divisive\u201d to \ncategorize content that is not inflammatory but may still generate a \nlighter form of division by possibly excluding those who do not have the cultural references to decode it, laugh about it, and involuntary become \n\u201claughed at\u201d as Phillips and Millner put it (2018). We subsequently tagged \nas \u201cambivalent and divisive\u201d content that, while ambivalent (as above), \nThe earne S T Pl aT for M 157\nfi gure\u00a07.10 an alytical scheme. ex amples of coded posts in earnest non-divisive, ambivalent \nnon-divisive, earnest divisive, and ambivalent divisive. Sources: https://www.instagram.com/tv/\nc\nhim\ntyqhfo9\n/; https://www.instagram.com/p/ c\nhKe\nganh\n_\ng3\n/; https://www.instagram.com/p/\nc\ngan\n6Kfs\njdq\n/; https://www.instagram.com/p/ c\nf1\n-vqonZJr/.\n158  S abine ni ederer and ga briele co loMb o \ncan be recognized as highly dismissive, polarizing, or otherwise geared \ntowards division.\nIt is important to note that as we are analyzing content during a political \ncampaign, and many posts were \u201ccampaigning\u201d in terms of both their \nmessage and tone of voice. Here, we only coded such content as divisive \nwhen it was explicitly dismissive of a political opponent or another person \nor accusatory in incendiary terms. Not all critical posts were labeled as \ndivisive, just as not all jokes were coded as ambivalent.\nUser activity analysis of candidates and issues spacesFor each of the presidential candidates and issue spaces, we analyzed the \nmost active users. Here, we count how many times a user has posted and \ncalculate the total number of interactions (likes and comments) received \nby each user for the total of his or her posts. User activity analysis tells us \nwhether one or more very active users dominate a political or issue space \nand whether those who are the most vocal are also the most interacted with \nby other users. Concerning the political candidates, we also ask whether \none candidate succeeds in \u201cinvading\u201d another candidate\u2019s namespace. As \none candidate mentions (often attacking or criticizing) another candidate, \ns/he may receive a high number of user interactions, therefore appearing \nin the top 50 posts of one of the opponents.\nArtificial amplification and follower analysis\nTo assess the authenticity of candidates\u2019 and parties\u2019 audiences and \ndetect signs of artificial amplification, we use the digital marketing tool, \nHypeAuditor. The tool provides a set of metrics for one Instagram ac -\ncount, which it compiles into an \u201caudience report.\u201d For each candidate and \nparty (Biden, Sanders, and Trump as well as the political party names), \nwe collect the Instagram usernames and then use HypeAuditor to obtain \nan audience report. The report provides an audience type breakdown, \ndividing followers into four categories: real people, influencers (> 5,000 \nfollowers), mass followers (>1,500 followers), and suspicious followers, \ndefined as \u201cInstagram bots and people who use specific services for likes, \ncomments and followers purchase\u201d (Komok, 2020). From the Hypeauditor \nreport, we also consider the followers\u2019 country analysis for each account, \nwhich breaks down followers by location and could also point to possible \nanomalies in the follower base.\nThe earne S T Pl aT for M 159\nCelebrities on Instagram\nIn the last part of the study, we zoom into the role of celebrities in the \nvarious political and issue spaces. In characterizing online celebrities, \nscholars have made the distinction between \u201csocial media natives,\u201d \nsometimes referred to as micro-celebrities to indicate the niche of their \nfame, whose \u201cactivities have been associated with social media from the \nbeginning\u201d (Giles, 2017), and established celebrities who become active \non social media and employ the techniques of micro-celebrities to engage \nwith their audience (Marwick and boyd, 2010). In our user activity analysis, \nrather than tracing where their fame originated from, we consider as \ncelebrities all public figures whose user accounts are labeled as \u201cverified\u201d \nby the platform.\nTo obtain a verified account on Instagram, reviewers assess whether an \naccount is \u201cin the public interest\u201d and (in addition to following the platform\u2019s \nterms of service) is \u201cauthentic, unique, complete and notable\u201d (Instagram, \nn.d.). Verified accounts must also be famous outside of Instagram, as the \nplatform \u201creview(s) accounts that are featured in multiple news sources\u201d \n(Instagram, n.d.) and assigns a verified badge only to those associated with \na \u201cwell-known, highly searched for person, brand or entity\u201d (Instagram, \nn.d.). Social media influencers who have not built up a public presence \noutside of the platform are not marked as verified. Once the badge of a \nverified account is earned, it is hardly revoked, and \u201cthere appear to be no \nconsequences when authentic, verified accounts share lies and half-truths\u201d \n(Ahmadi and Chan, 2020).\nAppendix\nOverview of queries used in CrowdTangle\nCovid-19 [corona, covid_19, covid, coronaviruspandemic, coronavirus]\n5G [5g]\nHealthcare [healthinsurance, medicareforall, medicare, medicareforallnow, \nhealth, healthcare, lowerdrugcosts, protectourcare, obamacare, Abortion, Medicare]Gun control [gun control, firearms regulation, gun restrictions, anti-gun, \ncarry permit, 2nd amendment, second amendment, right to keep and bear \narms, gun ownership]\n160  S abine ni ederer and ga briele co loMb o \nBiden [biden, joebiden, biden2020]\nSanders [berniesanders, sanders, feelthebern, bernie2020, votebernie]\nTrump [donaldtrump, trump, KAG2020, Trump2020, makeamericagreata -\ngain, maga]\nInstagram accounts that were part of the follower analysis with \nHypeAuditor\nPolitical candidate accounts: @berniesanders, @joebiden, @realdonaldtrump\nPolitical party accounts: @thedemocrats, @gop\nReferences\nAhmadi, A.A., and Chan, E. (2020). Online influencers have become powerful \nvectors in promoting false information and conspiracy theories. First Draft. \nhttps://firstdraftnews.org/latest/influencers-vectors-misinformation/.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBond, S. (2021, March\u00a09) Instagram suggested posts to users. It served up COVID-19 \nfalsehoods, study finds. NPR. https://www.npr.org/2021/03/09/975032249/\ninstagram-suggested-posts-to-users-it-served-up-covid-19-falsehoods-study-finds.\nBradshaw, S. and Howard, P.N. (2018). Challenging truth and trust: A global inventory \nof organized social media manipulation . Computational Propaganda Research \nProject. Oxford Internet Institute. https://demtech.oii.ox.ac.uk/wp-content/\nuploads/sites/93/2018/07/ct2018.pdf.\nBurkhardt, J.M. (2017). Combating fake news in the digital age. ALA Library Technol -\nogy Reports , 53(8): pp.\u00a05\u20139. https://doi.org/10.5860/ltr.53n8.\nCenter for Countering Hate (2021, March\u00a09). Malgorithm: How Instagram\u2019s al -\ngorithm publishes misinformation and hate to millions during a pandemic. \nhttps://252f2edd-1c8b-49f5-9bb2-cb57bb47e4ba.filesusr.com/ugd/f4d9b9_89e\nd644926aa4477a442b55afbeac00e.pdf.\nColombo, G. and De Gaetano, C. (2020). Dutch political Instagram. Junk news, \nfollower ecologies and artificial amplification. In R. Rogers and S. Niederer (Eds.), \nThe politics of social media manipulation (pp.\u00a0147\u2013168). Amsterdam University \nPress.\nDiResta, R., Shaffer, K., Ruppel, B., Sullivan, D., Matney, R., Fox, R., Albright, J., and \nJohnson, B. (2018). The tactics & tropes of the internet research agency, White \nPaper, New Knowledge. https://disinformationreport.blob.core.windows.net/\ndisinformation-report/NewKnowledge-Disinformation-Report-Whitepaper.pdf.\nThe earne S T Pl aT for M 161\nEllis, E. G. (2019, September\u00a010). Fighting Instagram\u2019s $1.3 billion problem\u2014Fake \nfollowers. Wired . https://www.wired.com/story/instagram-fake-followers/.\nFeldman, B. (2017, June\u00a08). In Russia, you can buy Instagram likes from a \nvending machine. New York Times Magazine , June\u00a08. https://nymag.com/\nintelligencer/2017/06/you-can-buy-instagram-likes-from-a-russian-vending-\nmachine.html.\nGillespie, E. (2020, September\u00a030). \u201cPastel QAnon\u201d: The female lifestyle bloggers \nand influencers spreading conspiracy theories through Instagram. The Feed . \nhttps://www.sbs.com.au/news/the-feed/pastel-qanon-the-female-lifestyle-\nbloggers-and-influencers-spreading-conspiracy-theories-through-instagram.\nHedrick, A., Karpf, D., and Kreiss, D. (2018). The earnest internet vs. the ambivalent \ninternet. International Journal of Communication, 12 (8). https://ijoc.org/index.\nphp/ijoc/article/view/8736/.\nHighfield, T. and Leaver, T. (2016). Instagrammatics and digital methods: Studying \nvisual social media, from selfies and GIFs to memes and emoji. Communication \nResearch and Practice , 2(1), pp.\u00a047\u201362. https://doi.org/10.1080/22041451.2016.115\n5332.\nHoward, P.N., Ganesh, B., Liotsiou, D., Kelly, J., and Fran \u00e7o is, C. (2018). The IRA, \nsocial media and political polarization in the United States, 2012\u20132018, Report, \nComputational Propaganda Research Project, Oxford Internet Institute. https://\ncomprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2018/12/The-IRA-Social-\nMedia-and-Political-Polarization.pdf.\nInstagram (n.d.). What are the requirements to apply for a verified badge on \nInstagram? Instagram Help Center. https://help.instagram.com/312685272613322.\nInstagram. (2018). Reducing inauthentic activity on Instagram. Instagram Blog. \nhttps://about.instagram.com/blog/announcements/reducing-inauthentic-\nactivity-on-instagram.\nInstagram. (2020). Introducing new authenticity measures on Instagram. \nInstagram Blog. https://about.instagram.com/blog/announcements/\nintroducing-new-authenticity-measures-on-instagram.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/pubs/oh/DataAndSociety_Lexi -\nconofLies.pdf.\nJenkins, H. (2017, May\u00a030). The ambivalent internet: An interview with Whitney \nPhillips and Ryan M. Milner (Part One). Confessions of an ACA-fan Blog. http://\nhenryjenkins.org/blog/2017/05/the-ambivalent-internet-an-interview-with-\nwhitney-phillips-and-ryan-m-milner-part-one.html.\nJett, J. (2021, February\u00a011). Robert F. Kennedy, Jr. is barred from Instagram over false \ncoronavirus claims. New York Times . https://www.nytimes.com/2021/02/11/us/\nrobert-f-kennedy-jr-instagram-covid-vaccine.html.\n162  S abine ni ederer and ga briele co loMb o \nKlein, E. and Robison, J. (2020). Like, post, and distrust? How social media use \naffects trust. Political Communication , 37(1), pp.\u00a046\u201364. https://doi.org/10.1080\n/10584609.2019.1661891.\nKomok, A. (2020). What are suspicious accounts? HypeAuditor . https://help.\nhypeauditor.com/en/articles/2221742-what-are-suspicious-accounts.\nLazer, D. M., Baum, M.A., Benkler, Y., Berinsky, A.J., Greenhill, K.M., Menczer, \nF., \u2026 and Schudson, M. (2018). The science of fake news. Science, 359 (6380), \npp.\u00a01094\u20131096. https://doi.org/10.1126/science.aao2998.\nLee, J.C. and Quealy, K. (2019, May\u00a024). The 598 people, places and things Donald \nTrump has insulted on Twitter: A complete list. New York Times . https://www.\nnytimes.com/interactive/2016/01/28/upshot/donald-trump-twitter-insults.html.\nLindquist, J. (2019). Illicit economies of the internet. Made in China Journal , 3(4), \npp.\u00a088\u201391. https://madeinchinajournal.com/2019/01/12/illicit-economies-of-the-\ninternet-click-farming-in-indonesia-and-beyond/.\nLorenz. T. (2019, March\u00a021) Instagram is the internet\u2019s new home for hate. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2019/03/\ninstagram-is-the-internets-new-home-for-hate/585382/.\nMaragkou, E. (2020, December\u00a08). The conspiracy theorist as influencer. Insti -\ntute of Network Cultures Blog. https://networkcultures.org/blog/2020/12/08/\nthe-conspiracy-theorist-as-influencer/.\nMarres, N. (2018). Why we can\u2019t have our facts back. Engaging Science, Technology, \nand Society, 4 , 423\u2013443. https://doi.org/10.17351/ests2018.188.\nMcNeal, S. and Broderick, R. (2020, April\u00a04). Lifestyle influencers are now sharing \nsome bogus far-right conspiracy theories about the coronavirus on Instagram. \nBuzzfeed News . https://www.buzzfeednews.com/article/stephaniemcneal/\ncoronavirus-lifestyle-influencers-sharing-conspiracy-qanon.\nOh, D. (2019). Review of The ambivalent internet: mischief, oddity, and antagonism \nonline. Information, Communication & Society , 22(8), pp.\u00a01189\u20131191. https://doi.\norg/10.1080/1369118X.2019.1606267.\nPhillips, W. (2015). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. MIT Press.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nQuealy, K. (2017, July\u00a026). Trump is on track to insult 650 people, places and things \non Twitter by the end of his first term. New York Times . https://www.nytimes.\ncom/interactive/2017/07/26/upshot/president-trumps-newest-focus-discrediting-\nthe-news-media-obamacare.html.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nThe earne S T Pl aT for M 163\nShane, T. (2020, December\u00a01). Searching for the misinformation \u201ctwilight zone.\u201d \nNieman Lab. https://www.niemanlab.org/2020/12/searching-for-the-misinfor -\nmation-twilight-zone/.\nSilverman, Craig (2016, November\u00a016) This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nSmith, R., Cubbon, S. and Wardle, C. (2020, November\u00a012). Under the surface: \nCovid-19 vaccine narratives, misinformation and data deficits on social media. \nFirst Draft. https://firstdraftnews.org/long-form-article/under-the-surface-\ncovid-19-vaccine-narratives-misinformation-and-data-deficits-on-social-media/.\nSommer, W. (2018). Instagram is the alt-right\u2019s new favorite haven. The Daily Beast . \nhttps://www.thedailybeast.com/instagram-is-the-alt-rights-new-favorite-haven.\nSystrom, K. (2014). 300 million Instagrammers sharing real life moments. Insta -\ngram Blog. https://about.instagram.com/blog/announcements/300-million-\ninstagrammers-sharing-real-life-moments.\nTiffany, K. (2020, August\u00a018). How Instagram aesthetics repackage QAnon. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2020/08/\nhow-instagram-aesthetics-repackage-qanon/615364/.\nVan Driel, L. and Dumitrica, D. (2021). Selling brands while staying \u201cauthentic\u201d: \nThe professionalization of Instagram influencers. Convergence , 27(1), pp.\u00a066\u201384. \nhttps://doi.org/10.1177/1354856520902136.\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. \nScience , 359 (6380), pp.\u00a01146\u20131151. https://doi.org/10.1126/science.aap9559.\nAbout the authors\nSabine Niederer , PhD, is Professor of Visual Methodologies at the Amsterdam \nUniversity of Applied Sciences, where she heads the Visual Methodologies \nCollective, specializing in visual, digital, and participatory research of social \nissues. She is Program Manager of ARIAS, the platform for artistic research \nin Amsterdam and co-coordinator of the Digital Methods Initiative at the \nUniversity of Amsterdam.\nGabriele Colombo , PhD, is a Research Associate at King\u2019s College London, \nDepartment of Digital Humanities, and collaborates with DensityDesign, \na research lab at the Design Department of Politecnico di Milano. He is \naffiliated with the Visual Methodologies Collective at the Amsterdam \nUniversity of Applied Sciences.\n\n8 A f ringe mainstreamed, or tracing \nantagonistic slang\n  b\netween 4chan and \nBreitbart before and after Trump\nStijn Peeters, Tom Willaert, Marc Tuters, Katrien Beuls, Paul \nVan Eecke and Jeroen Van Soest\nAbstract\nWe studied whether the vernaculars of the extremely vitriolic, \u201cpolitically incorrect\u201d sub-forum of 4chan/pol/ have crossed over to the comment sec -\ntion of Breitbart News, a right-wing news website that was found in earlier research to have played a significant \u201cagenda-setting\u201d role in the 2016 U.S. \npresidential elections. We study if crossover exists around both the 2016 and \n2020 elections. In our analysis, we find evidence suggestive of such crossover, \ncentered around the presence first on 4chan and later Breitbart of a series of \nracist, antagonistic and otherwise extreme terms. This crossover of 4chan/\npol/\u2019s vitriolic vernacular marks an expansion of hyper-antagonistic \u201calt-\nright\u201d politics to Breitbart\u2019s more mainstream right-wing populist audience.\nKeywords: Alt-right, 4chan, Breitbart, vernacular crossover, extreme \nspeech\nResearch questions\nCan we find evidence of language originating on 4chan that propagates to \nthe comment sections of Breitbart News around the time of the 2016 U.S. \nelections? How to characterize the words used on 4chan as compared to \nBreitbart around that time? Does the use and change in use of language \non both platforms suggest a spread of extreme political thought? Can we \nobserve similar dynamics of language propagation between both platforms \naround the 2020 U.S. presidential elections?\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch08\n166  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nEssay summary\nOver the past decade a diverse and increasingly influential far-right online \nmedia sphere has emerged. It has raised concerns that parts of this sphere \nmay function as incubators for radicalization. In particular, the 2016 \npresidential elections in the United States were marked by the coarsening \nof the tone of political discourse, with candidate and eventual winner \nDonald Trump slandering his opponents, spreading conspiracy theories \nand provoking xenophobia. Alongside Trump\u2019s insurgent takeover of the \nRepublican party, his election campaign during 2015 and 2016 marked the \nemergence of the \u201calt-right\u201d political movement, which perceived Trump \nas an alternative to establishment conservatism.\nAs a libertarian movement with a strongly xenophobic, often racist stance \ntowards immigration, the alt-right was also characterized by its use of \nantagonistic vernacular. We can think of this antagonistic slang as \u201cmemes,\u201d \na concept typically used to refer to user-generated shared images that seem \nto spread across platforms and between communities, but which can also be \nused to refer to any \u201cbuilding blocks of complex cultures\u201d online, including \nwords and phrases (Shifman, 2011, p189). Indeed, in the analysis on offer \nhere, we view specific phrases and tokens as such memetic building blocks \nthat seem to propagate within and between distinct environments online. \nA platform of interest in this context is the far-right image board 4chan, \nwhich has been positioned as a \u201cbirthplace of memes\u201d (Ludemann, 2018), \nan incubator of conspiracy theories like QAnon (De Zeeuw et al., 2020), and \na place of rapid innovation of oftentimes antagonistic language (Peeters et \nal., 2021). It might therefore be expected that antagonistic alt-right slang \nincubated on the platform has the potential to spread to a wider audience, \nwith 4chan acting as a breeding ground. To study this hypothesis, we look at 4chan as well as a more mainstream platform that has been associated with the alt-right, Breitbart News.\nThe questions are particularly relevant as the alt-right is a relatively \nunique, insurgent far-right political movement that rose to international \nattention in 2015 with remarkably little in the way of a centralized organi -\nzational structure, and for whom the circulation of memes and internet \njargon was fundamental to its success (Hawley, 2017). Most emblematically, \nthe memetic subcultural icon of \u201cPepe the Frog\u201d became notoriously as -\nsociated with this school of thought during the first half of the 2010s and \nachieved widespread attention (Lobinger et al., 2020). Arguably, however, \namong the alt-right\u2019s most significant accomplishments was the extent to \nwhich their antagonistic slang succeeded in framing political discussion. \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  167\nIllustrative of this pattern was for example the expression \u201ccuckservative\u201d \nwhich emerged in early 2015 on (now deplatformed) alt-right websites such \nas My Posting Career, The Right Stuff as well as on 4chan\u2019s notorious /pol/ \nforum (Bernstein, 2015). In its original far-right subcultural usage the term \nreferred to a genre of often racialized pornography thereby connecting a \ncritique of establishment republicanism with the far-right\u2019s longstanding \npreoccupation with masculinity and miscegenation. By the end of the year, \nthe prolific alt-right author Vox Day had self-published a track with the \ntitle Cuckservative: How \u201cconservatives\u201d betrayed America , and this alt-right \nmeme had effectively worked its way into political discussion amongst \nmainstream Trump voters. It is this type of \u201cpropagation\u201d of politically \nextreme vocabulary that is under study in this chapter.\nConsidering these recent events, there is a legitimate concern that \nthe subculture associated with sites at the \u201cbottom\u201d of the internet could \ninsinuate itself (or has already done so) with an extreme and conspiratorial \ndiscourse into the American political debate across a continually evolving \nrange of platforms. There are indications that it has already transpired in the \nmore recent 2020 U.S. election campaign. The QAnon persona, central to a \nright-wing conspiracy theory positing, among other things, that prominent \nmembers of the Democratic Party are part of a Satan-worshipping can -\nnibalistic cult, started on 4chan but has since become a major factor in \nmainstream U.S. politics and as such is now discussed on a wide variety \nof platforms (De Zeeuw et al., 2020; Stanley-Becker, 2020). The polarized \nlanguage we study reflects this rift in recent American political discourse.\nAn understanding of the internet as having a \u201cbottom\u201d implies the exist -\nence of further \u201clayers.\u201d Along these lines, at the top we would find big media \nconglomerates, often rooted in \u201clegacy media\u201d such as major newspapers \nas the New York Times, cable broadcasters as CNN, and newer online-first \noutlets like Vox. As one moves \u201cdown,\u201d platforms grow more obscure, with a smaller reach and less clear editorial or content policies. At the bottom, \none finds \u201cfringe\u201d sites, with obscure subcultures; this \u201cdeep vernacular \nweb\u201d (De Zeeuw and Tuters, 2020) can appear culturally baffling as well as \noffensive to the uninitiated. Sites in this stratum usually have a relatively \nsmall number of visitors, compared to mainstream sites. 4chan is particularly \nrelevant here, as a fringe platform that has nevertheless been scrutinized for \nits production of internet memes (Bernstein et al., 2011), peculiar subcultural \npractices (Nissenbaum and Shifman, 2017) as well as language innovation (Tuters and Hagen, 2020; Peeters et al., 2021).\nOur findings are based on datasets centered on the 2016 and 2020 U.S. \nelections, collected from 4chan/pol/ and from the comment section of \n168  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nBreitbart News, a conservative, right-wing American news website especially \npopular during the first period as a staunch supporter of eventual winner \nDonald Trump. Although it has been described as \u201cfactually dubious\u201d (Guess \net al., 2018), Breitbart News occupied a crucial place in the political media \necosystem at the time. Benkler et al. (2018) offered an in-depth study of \nBreitbart\u2019s \u201cagenda-setting\u201d role in that election. Their analysis shows how \nBreitbart \u201canchored\u201d a network of other similarly dubious right-wing news \nsites such as Daily Caller, Gateway Pundit and Infowars. Though no formal or \neditorial association between these sites exists, they provide a similar brand \nof content characterized as a mix of \u201cparanoid conspiracy interpretations \naround a core of true facts\u201d (Benkler, 2018, p.\u00a034). Together they occupied a crucial position in the media ecology around the 2016 elections.\nIn this ecology Breitbart is a particularly interesting site for several \nreasons. One is that, at the time, Breitbart was the largest of these sites \nwith approximately 10% of the entire general news audience according to one estimate (Malone, 2016). Founded by the deceased Andrew Breitbart, \nformerly a reporter for the Huffington Post, under the more recent editorship \nof Steve Bannon the site championed the right-wing libertarian Tea Party \nand a strongly American populist, civic nationalist agenda (cf. Burley, 2017). \nReceiving substantial financial support from the billionaire Mercer family, \nwho initially backed Ted Cruz in the 2015 U.S. election campaigning, Breit -\nbart would develop into a nakedly partisan branch of the Trump campaign \nwhile at the same time Bannon famously claimed that he considered the \nsite to be a \u201cplatform for the alt-right\u201d (Posner, 2016). With a background in \nboth high finance and documentary filmmaking, Bannon is a self-styled \npublic intellectual noted for his interest in an obscure branch of far-right \npolitical philosophy known as Traditionalism, which also had a readership \non 4chan/pol/ (Teitelbaum, 2020; Tuters and OILab, 2020). Bannon would \nlater join the Trump campaign as its chief strategist (Green, 2017). In 2016, \nBreitbart published an article entitled An establishment conservative\u2019s guide \nto the alt-right , co-authored by the notorious alt-right provocateur Milo \nYiannopoulos. An investigative report later revealed it to have been written \nwith the participation of known alt-right ideologues (Bernstein, 2017). As \nsuch, the site combines a clear, alt-right editorial position and explicit ties to the Trump campaign with a relatively wide reach.\nEarlier analyses of Breitbart, including Benkler et al.\u2019s, were limited to \nthe editorial content of the site. We instead study the comment sections of \nBreitbart\u2019s articles that routinely receive thousands of comments, many only \ntangentially related to the article\u2019s subject. These appear to be moderated \nloosely, if at all. A 2017 report cites Disqus, which provides the technology on \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  169\nwhich Breitbart\u2019s comment section runs, promising that Breitbart \u201c[wants] to \nwork with us to figure out ways to minimize [hate speech]\u201d (Captain, 2017). \nIn this permissive setting, the comment section of Breitbart\u2019s London section \nwas characterized as \u201ca malignant swamp of race-baiting, nativism and \nantisemitic conspiracy,\u201d even accused of providing a platform for notorious \nalt-right celebrities (Mulhall et al., 2017). Appearing to function like a largely \nunmoderated discussion forum, the comment threads can thus serve to \nstudy the political views and discourse of the readership of a highly active \nelement of far-right politics that moved increasingly to the center of the \nAmerican Republican party around the 2016 elections.\nIn this same period /pol/, the self-described \u201cpolitically incorrect\u201d \ndiscussion board of anonymous imageboard 4chan, overtook /b/ (the \n\u201crandom\u201d board) as the site\u2019s most active discussion forum. Previous \nquantitative research on /b/ has noted how the site was an \u201cexcellent \nvenue for studying innovation diffusion,\u201d due in part to the fact that it was \ngenerally considered as \u201cthe source of many online memes\u201d (Bernstein, \n2011, p.\u00a056). While in the earlier period in which /b/ had been more popular \n4chan was the source of innocuous memes such as LOLcats, /pol/ memes \nwere far more toxic, including offensive depictions of Pepe the Frog as well \nas the antisemitic triple parentheses phrasal meme (Tuters and Hagen, \n2020). While there has been some quantitative research into the diffusion \nof toxic /pol/ memes to other web communities (Zannettou et al., 2018), to \nour knowledge there is no previous empirical work focused specifically on \nthe crossover of vernacular language from /pol/ to another such threaded \ndiscussion forum.\nThis chapter, then, adds to a growing body of work focused on the \u201cmain -\nstreaming\u201d of previously \u201cfringe\u201d web spaces like 4chan as the source of a \n\u201cneoreactionary\u201d style of political discourse (Nagle, 2017; Wendling, 2018; \nBeran, 2019; Woods, 2019). 4chan and Breitbart represent two parts of the \nmedia ecosystem that are particularly interesting to study in the context \nof the polarized and increasingly extreme U.S. political landscape. As such, \nwe investigate whether 4chan\u2019s discourse resonates beyond its own borders \naround the time of the 2016 and 2020 U.S. presidential elections. Since so \nmuch of the discourse on 4chan\u2019s political discussion board, /pol/, can be \ncharacterized as conspiratorial, racist or otherwise extreme (cf. Tuters and \nHagen, 2020), its later occurrence on other platforms is of great interest to \nthose studying the mainstreaming of extremism and misinformation. While \nour analysis is primarily focused on the 2016 election campaign in which \nthe alt-right movement first gained prominence, we also provide an initial \nanalysis of the 2020 campaign for comparison.\n170  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nWe found that there are far more terms that appear only in the language \nof 4chan/pol/ than in the language of Breitbart comments. Additionally, of \nthe terms that over time are prominent first in one dataset and later in both, \nthose that first appear on 4chan are often highly political and furthermore \ncan be characterized as anti-Muslim and xenophobic (e.g., \u201cgermanistan\u201d), \nhomophobic or transphobic (e.g., \u201cxhe\u201d) or otherwise extreme (e.g., \u201cshitlibs\u201d). \nThese extreme terms are then later observed on Breitbart. Though a direct \nrelationship is difficult to ascertain, our initial findings suggested that \n4chan, an active but non-mainstream niche site, had an outsized impact \nthat reaches beyond its own confines.\nWe reflect on these findings, concluding that for the period 2015\u20132017 \n4chan/pol can be considered an originator or incubator of extreme discourse, \nwhere extreme idioms appear before propagating to the more mainstream \ndiscussion space of Breitbart News. Additionally, our observations indicate \nthat this propagation of idioms between 4chan and Breitbart News seem to \nbe less intense around the time of the 2020 U.S. presidential elections, and \nthat consequently, studies of extreme discourse and misinformation should \nconsider and monitor other platforms as the main sites of the mainstream -\ning of such terms. We end with a brief section on our data collection and \nanalytical methods.\nImplications\nOur findings indicate that around the time of the 2016 U.S. elections antago -\nnistic, highly political and problematic words that also can be characterized \nas xenophobic (e.g., \u201cgermanistan\u201d); transphobic (e.g., \u201cxhe\u201d) or otherwise \nextreme (e.g., \u201cshitlibs\u201d) first observed on 4chan later entered the discourse \nin the comment section of Breitbart News, a more mainstream platform with \nimportant connections to the Trump presidential administration. While \nearlier research has investigated the crossing over of particular ideas (e.g., \nconspiracy theories), our study provides empirical data that suggests that \nthis crossing-over also occurs on the level of language and is not bound \nonly to specific theories or ideas. The findings further support previous \nobservations about the sustained connection between 4chan/pol/ and \nBreitbart\u2019s comment section during this period.\nOne possible explanation for the propagation of extreme \u201cchan\u201d vernacular \ntowards Breitbart around the 2016 elections is that some 4chan posters \nalso frequent Breitbart\u2019s comment section. It would not be surprising if \nthey used the language they were familiar with, which could explain their \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  171\noccurrence in both spaces. Tracing whether actors move between these \nplatforms is difficult because 4chan is designed as an anonymous platform \n(Knuttila, 2011). 4chan posters are notoriously derisive of \u201cmainstream \nmedia\u201d and typically dismiss Breitbart as inadequately extreme. Although \nBreitbart has been described as having an \u201cextreme right-wing bias\u201d (Media \nBias/Fact Check, 2021), it is seen as a place for \u201cnormies.\u201d In the vernacular, \n\u201cnormies\u201d are those who follow mainstream media and otherwise adhere \nto common social norms (De Zeeuw et al., 2020). Nevertheless, it is possible \nthat some 4chan posters may also frequent Breitbart News, which would \nbe one explanation for the appearance of 4chan-like vernacular there. \nIt would be the manner for both this vernacular as well as the extreme \npolitical positions to which it implicitly and explicitly refers to spread to a new \u201cnormie\u201d audience.\nThough a direct relationship between both platforms remains difficult \nto ascertain, our initial findings suggest that 4chan, the active but non-\nmainstream niche site, had an outsized impact that reaches beyond its \nown confines. As such, we conclude that for the period 2015\u20132017 4chan/pol \ncan be considered an originator or incubator of extreme discourse, where \nextreme idioms appeared before they propagated to the more mainstream \ndiscussion space of Breitbart News. Additionally, our observations indicate \nthat this propagation of idioms between 4chan and Breitbart News seems to \nbe less intense around the time of the 2020 U.S. presidential elections, and \nthat consequently studies of extreme discourse and misinformation should \nconsider and monitor other platforms as the main sites of the mainstreaming \nof such terms.\nA key implication of our work, then, is that 4chan /pol/ might give an \nearly impression of problematic discourse that may become used by a wider \naudience at a later stage. As such, continued observation of the language \ndisseminated through these fringe platforms\u2014for which we offer one \nmethodological blueprint by addressing its propagation towards Breitbart \nNews\u2014might benefit journalists, researchers and policy makers seeking \nto signal the emergence of new extreme discourses on emerging platforms \nsuch as Parler (cf. Floridi, 2021) and others that have more recently gained prominence in the 2020 U.S. election campaign.\nMore fundamentally, our findings speak to the much-debated relationship \nbetween the \u201cbottom\u201d of the internet\u2014consisting of niche, often politically \nextreme sites\u2014and more mainstream sites. The observation and study of this \u201cbottom\u201d has acquired urgency as ideas and vernacular that originate \nin these parts have been implicated in several far-right terrorist attacks \nin the United States, Canada and New Zealand. Furthermore, sites like \n172  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n4chan serve as incubators for various impactful conspiracy theories, e.g., \n\u201cPizzagate\u201d (Tuters et al., 2018) and the figure of QAnon (De Zeeuw et al., \n2020). Indeed, while for many years the effects of the web were framed in \nterms of the democratic promise of participatory media (Jenkins, 2006; \nBenkler, 2006), the last half decade has shaken that narrative to its core \nwith the emergence of \u201cdark participation\u201d in the context of online political \ndiscussion (Quandt, 2018). The role of the upstart Breitbart in anchoring a \nright-wing news ecosystem that set the agenda for the 2016 U.S. election \nmay be seen as the fruition of earlier concerns over the fragmentation of the \nweb into personalized spheres (Pariser, 2011), which continue apace with the \nemergence of the alt-tech ecosystem that has benefited from social media \nplatforms\u2019 \u201cdeplatforming\u201d of the Trump movement (Rogers, 2020b). Given \nthe \u201cfringe\u201d quality of some of these sites we have good reason to believe \nthat their vernacular subculture will overlap with that of 4chan, as this \nstudy showed for the \u201cnormie\u201d website, Breitbart News, in the midst of the \n2016 U.S. election.\nFindings\nFor both the 2015\u20132017 and 2020\u20132021 periods, we split up the 4chan and \nBreitbart posts and comments in terms; each word, after filtering out \nhyperlinks and punctuation, is a term. For each term we can then classify \non which of the platforms it occurs on a per-month basis, resulting in a \npropagation pattern for each term (see Figure\u00a08.1).\nOur findings suggest that around the 2016 U.S. presidential elections, the \npolitical vocabulary associated with extreme right-wing politics consistently \nappears on 4chan first, and then on the more mainstream Breitbart News \nlater, potentially representing one strand of this propagation dynamic. We \nalso observed that this dynamic becomes less prominent around the 2020 \nelections, suggesting that the locus for this extreme idiom\u2019s propagation from \nthe \u201cbottom\u201d of the internet has again shifted. In particular, the analysis of \nthese propagation patterns allows for the following observations:\nFinding 1: Around the time of the 2016 U.S. presidential elections, the lan -\nguage of 4chan/pol/ contains more unique terms than that in the Breitbart \ncomment sections. Our analysis shows that there are more terms unique to \nthe /pol/ dataset than there are terms unique to the Breitbart dataset. Of \nthe 67,605 terms, 19,346 (28.6%) were classified as occurring in the 4chan/\npol/ dataset only, while 2,857 (4.2%) were classified as occurring only in the \nBreitbart dataset (see Figure\u00a08.2). 4chan has previously been described as a \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  173\nsource of subcultural and linguistic innovation (Nissenbaum and Shifman, \n2017). This finding empirically confirms the observation, at least concerning \nthe unique use of language on the forum. As English-language datasets, \nboth are concerned with informal political discussion focused primarily on \nthe United States context. Thus, while some variation may be expected; in \nprinciple, one might expect the language used to be similar between both, \nbut this is only partially the case.\n4chan\u2019s vernacular has been referred to as \u201cchanspeak\u201d: \u201cpeculiar in-\ngroup misspellings\u201d characterized by \u201cshortening, simplifying and cutting \ndown words\u201d (Fiorentini, 2013; Herring, 2012). While this is perhaps true for \nthe broader 4chan vernacular, the /pol/ slang we found is not adequately \ncaptured by this description. This can be attributed to the rapid linguistic \ninnovation on this forum (Peeters et al., 2020). The terms we find are more \nadequately described as \u201cphrasal memes,\u201d highly self-referential \u201cremixes\u201d \nof words, e.g., \u201ccuckerberg\u201d (a combination of \u201ccuck\u201d and \u201cZuckerberg\u201d). \nWhile a proper linguistic analysis of this vernacular is outside the scope \nof this article, the dataset on offer here could in the case of /pol/ serve as a \nstarting point for such a study.\nFinding 2: During the same period, a substantial number of terms are \nfirst only observed in the language on 4chan, the fringe platform, but later \nalso on Breitbart, the more mainstream platform, suggesting propagation \nof this vocabulary. Terms that occur on one platform first and later on \nanother platform or both platforms can be observed in both \u201cdirections\u201d; \nsome occur first on Breitbart while others occur first on 4chan/pol/. In total, \n2,043 terms (3%) follow such a pattern. Of these, 932 (45.6%) occur on 4chan \nfirst, while 1,111 (54.4%) occur on Breitbart first. This seems counterintuitive; \nit would imply that terms are first anchored in the language of Breitbart \nand only later in that of 4chan, which is difficult to reconcile with 4chan\u2019s reputation as a more innovative linguistic space as established in Finding \nfi gure\u00a08.1 Visualization of the monthly occurrence of the terms \u201ccuckerberg,\u201d \u201cgermanistan,\u201d \n\u201cxhe,\u201d and \u201cshitlibs\u201d around the time of the 2016 \nu.\nS. presidential elections, between June\u00a02015 \nand March\u00a02017. \nfo\nr each month, terms are classified (color-coded) based on a comparison of their \nrelative frequencies in 4chan/pol posts and in the comments on \nbr\neitbart \nne\nws. These words \nrepresent the political vernacular found within the 4chan dataset.\n174  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n1. On the other hand, Breitbart is a far larger and arguably more influential \nplatform, and agenda-setting power may be attributed to it in that capacity. \nFrom this perspective, the fact that a substantial number of terms occur on \n4chan first at all is significant and suggests that the terms might indeed \n\u201cpropagate,\u201d with language spreading\u2014directly or indirectly\u2014from 4chan \neventually to Breitbart.\nA closer look at these terms reveals that they can be divided into two \nbroad categories\u2014\u201cnamed entities\u201d and \u201cneologisms.\u201d Linguistically, named \nfi gure\u00a08.2 cl assifications of all words in the 2015\u20132017 data ( n  = 67,605) over time. The consecutive \noccurrences of each word are represented as a single row of per-month squares that are color-\ncoded for the occurrence of the word in 4chan/pol/ posts and \nbr\neitbart comments respectively.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  175\nentities refer to all terms that are proper names, for example, countries \nand people. The other category, \u201cneologisms,\u201d are words that are neither \ncommon English nor otherwise used in \u201cnormal\u201d discourse. In practice, \nthese terms are mostly various slurs and part of a memetic vocabulary that \nis associated with 4chan discourse.\nThe named entities cannot reasonably be assumed to originate on either \nplatform. Instead, the likely explanation for the occurrence of these terms \nis that they refer to people, places or organizations that were discussed \nbecause they were relevant to a current event or news item. This indicates \nthat Breitbart users discussed these topics before 4chan, which is interesting \ninsofar as it provides insight into the type of topics discussed by both forums \nand how rapidly they enter the discourse. The \u201cneologisms\u201d (including the \nexamples in Figure\u00a08.1) on the other hand are likely to originate in the \nvernacular of online platforms (Peeters et al., 2021). As such, the fact that they \nappear on 4chan and later on Breitbart suggests that they do propagate from \nthe one to the other, either directly or via another intermediary platform.\nFinding 3: Around the time of the 2016 U.S. presidential elections, many \nterms that seem to propagate from 4chan/pol/ to Breitbart reflect an extreme \nfar-right politics. Of these terms that can be assumed to originate on 4chan/\npol/, most are implicitly or explicitly related to far-right and conspiratorial \ntheories or ideas. This is not surprising, since 4chan/pol/ itself has been \nassociated with the \u201cPizzagate\u201d political conspiracy (Tuters et al., 2018) \nand has been described as a \u201ckind of petri dish for concocting extreme \nand extremely virulent forms of right-wing populist antagonism\u201d (Tuters \nand Hagen, 2020, p.\u00a02223). Of the words that appear first on 4chan (see also \nFigure\u00a08.1) several are emblematic of an extreme political discourse, such as \n\u201ccuckerberg\u201d (a jab at Facebook owner Mark Zuckerberg combined with the \nslur \u201ccuckold\u201d; other variations found were \u201ccuckservative(s),\u201d \u201ccucktard,\u201d \n\u201ccucky,\u201d and \u201ccuckery\u201d), anti-Muslim terms such as \u201cgermanistan\u201d and \n\u201cbritainistan,\u201d words like \u201cxhe\u201d (used mockingly to insult transgender people), \nand various slurs aimed at liberal U.S. voters like \u201cshitlibs\u201d and \u201cberniebots.\u201d1\nWhile 4chan/pol/ is well-known as a far-right discussion space (Hine et \nal., 2017; Ludemann, 2018), our data and analyses show that the vocabulary \nassociated with this discourse is not contained to this \u201cfringe\u201d platform but \nafter initial usage it also appears on more mainstream platforms. More \nspecifically, the various xenophobic or otherwise extreme slurs and phrasal \nmemes that are developed and incubated on 4chan/pol/ in some cases see \n1 T he full list of terms that propagate may be found in the dataset available from Zenodo at \nhttps://doi.org/10.5281/zenodo.5535341.\n176  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nuptake in the comments on Breitbart News. As most of this language is \nunambiguous, and hard to mistake for anything else than derogatory, it \nraises concerns that not only the language but also the extreme political \ndiscourse associated with it is shared across sites.\nFinding 4: Around the time of the 2020 U.S. presidential elections, the \naforementioned mainstreaming of extreme chan vernacular seems to be less \noutspoken. Around the time of the 2020 U.S. presidential elections, some of \nthe vernacular that propagated in 2015\u20132017 remains shared between 4chan \nand Breitbart, with notable examples including \u201ccuck\u201d and its derivatives, \nsuch as \u201ccucked.\u201d Further analysis shows, however, that comparatively fewer \nnew terms propagate from 4chan to Breitbart News around this time. As \nobserved in our 2020\u20132021 dataset, only 347 terms out of 57,602 (or 0.6% \ncompared to 3% for the 2015\u20132017 dataset) actually move from one platform \nto the other, and of those, only 124 were classified as moving from 4chan/\npol to Breitbart (see Figure\u00a08.3). Closer inspection of these moving terms \nreveals few original vernacular terms, even though the data suggest that \nduring this period, 4chan in and of itself remains an incubator for extreme \nvernacular. Examples that do point towards a continued mainstreaming of \n4chan terminology and memes concern the terms \u201ccoomer\u201d (which refers \nto the 4chan meme of the \u201c20-year-old coomer\u201d), and \u201clibshits\u201d (an inver -\nsion of the previously discussed term \u201cshitlibs\u201d), but in comparison with \nthe 2015\u20132017 period, the language propagation dynamics between both \nplatforms seems much less outspoken.\nAny comparison between the two datasets is necessarily tentative as we \nare yet to capture as much of the post-election period as we did for the 2016 \nelections. As such there remains a possibility that the propagation dynamic \nlags in this case, or that Breitbart\u2019s comment space has later become milder \nfor other reasons\u2014perhaps 4chan\u2019s interest in Breitbart has diminished, \nwhich may be found in a subsequent analysis. Nevertheless, the discourse \naround both elections may be assumed to reach its zenith in the months \nsurrounding the election date. As such, the data gathered around the 2020 \nelections should provide a representative impression of the discourse around \nthat election, even if it is quantitatively smaller and of a shorter duration \nthan the earlier dataset.\nThese empirical observations strengthen previous assertions in the \nliterature that the period 2015\u20132017 was one characterized by an intensi-\nfied and salient \u201cmainstreaming\u201d of harmful vernacular between 4chan/\npol and Breitbart News. Possible explanations for the relative decline in \nthe propagation of idioms from 4chan to Breitbart around the 2020 U.S. \npresidential elections include the fact the site experienced a precipitous \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  177\ndecline after Trump took office, ultimately losing as much as three quarters \nof its total audience (Ellefson, 2019). According to Steve Bannon the site \nappears to have struggled financially following an advertiser boycott, \nwhich began in 2016 and was organized by Sleeping Giant to protest the \nsite\u2019s bigotry and sexism (Klayman, 2019). The billionaire Mercer family \nsold their shares in the site in 2017 and are currently majority stakeholders \nof the alternative social media site Parler, connected to the 2021 storm -\ning of the DC Capitol (Lerman, 2021). The growth in significance of such \nfi gure\u00a08.3 cl assifications of all words in the 2020\u20132021 data ( n  = 57,603) over time. The consecutive \noccurrences of each word are represented as a single row of per-month squares that are color-\ncoded for the occurrence of the word in 4chan/pol/ posts and \nbr\neitbart comments respectively.\n178  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n\u201calt-tech sites\u201d can be seen as one of the bi-products of the \u201cdeplatforming\u201d \nof alt-right figureheads from social media\u2014including eventually Trump \nhimself (Rogers, 2020b).\nMethods\n4chan data was collected with 4CAT, a forum analysis toolkit (Peeters and \nHagen, 2021) that contains a dataset comprising 4chan /pol/ data from 2013 \nto the present. This data is collected continuously (as it is posted on 4chan) \nby the tool itself and, for the period prior to 2018, supplemented with data \nfrom 4plebs.org, a third-party 4chan archive which publishes semi-regular \ndata \u201cdumps\u201d on the Internet Archive, containing all posts made on a number \nof 4chan\u2019s boards, including /pol/. (Merged 4plebs\u2019 and 4CAT\u2019s datasets have \nbeen used in other research on 4chan, too (Tuters and Hagen, 2019; Vou\u00e9 et \nal., 2020; Jokubauskait\u0117 and Peeters, 2020).) Notably, posts are included even \nif they are later deleted from the site, as all posts eventually disappear from \n4chan itself, as threads are deleted after a period of inactivity.\nThe 2015\u20132017 Breitbart data was collected between September\u00a02\u20139, 2019 \nusing a custom scraper written in Python which first crawled breitbart.\ncom for internal links to create an index of all articles posted on the site, \nand then collected all comments for all articles posted between June\u00a02015 \nand March\u00a02017, using the Disqus API. The resulting dataset reflects the \nstate of the comment section as it was at the moment of scraping. There \nis a possibility that some comments were removed between the moment \nof posting and the moment of scraping, up to 4 years later; however, as \nmentioned earlier, Breitbart\u2019s moderation policy seems to have been lax \nduring the period we study, and it is unlikely that later policies were enacted \nretroactively. We therefore assume that the data is a reasonably accurate \nreflection of what the comment threads would have looked like closer to \nthe date the comments were posted. The 2020\u20132021 Breitbart data was \ncollected with the same technique, between February\u00a017 and March\u00a03, 2021.\nOur first dataset thus spans the period between the announcement of \nDonald Trump\u2019s candidacy for the U.S. presidential election (June\u00a02015) \nand his first months in office, whereas the second dataset comprises a \nsmaller interval around the 2020 U.S. elections in which Trump was again a \ncandidate (and lost). As data capture of this nature is cumbersome, we were \nunable to gather a dataset comprising an equal timespan so shortly after \nthe 2020 elections; a more direct comparison would be a fruitful avenue \nfor future work.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  179\nBefore analyzing the captured data, for both datasets we cleaned the \nscraped comments and posts by applying case folding and removing punc -\ntuation, URLs, HTML tags (in Breitbart comments) and comment referral \nnumbers such as \u201c>>280207128\u201d (in /pol/ comments).\nAnalysis\nThis chapter addresses the questions of (1) whether we can empirically \nidentify terms that are first prominent in the language on 4chan/pol/ and \nlater also in the language of the Breitbart comment sections around the time \nof the 2016 U.S. presidential elections, (2) how to characterize the language \nused on 4chan/pol/ compared to that of Breitbart\u2019s comment sections at that \ntime, (3) whether the nature of these identified terms indicates a spread of \nextreme political thought, and (4) whether we can identify similar dynam -\nics between both platforms around the time of the 2020 U.S. presidential \nelections. We expect that we can observe this pattern for terms associated \nwith far-right thought, and that it constitutes a mainstreaming of fringe, \ntaboo or otherwise extreme political concepts.Quantitative analysis\nWe investigate corpora of posts and comments using methods from \nnatural language processing to empirically identify terms that occur first \non one platform and then on another, and to quantify the propagation \npatterns of these terms between both platforms (Willaert et al., 2020; \nWillaert et al., 2021). We collected two datasets for both platforms, a first \nset comprising posts from June\u00a02015 through March\u00a02017, and a second \nset containing data from May\u00a02020 through January\u00a02021. These texts \nwere then tokenized (split into individual terms). For both platforms, the \nmonthly frequencies of each term were counted, and those terms with an \nabsolute frequency of less than 200 were removed, as these were mostly \nless germane and included typos. Next, the relative monthly frequency of \neach term was calculated for both /pol/ and Breitbart. Relative frequencies \nwere used because we are interested in the prominence of the terms in \nthe language of each platform, and we aim to compare this prominence \nbetween platforms. We then compare these relative frequencies and \nclassify each term into one of four classification bins, indicating whether \nfor a given month the term:\n\u2013\n o\nccurred neither on /pol/ nor on Breitbart,\n\u2013\n o\nccurred on both /pol/ and Breitbart,\n180  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \n\u2013 o ccurred exclusively on /pol/, or\n\u2013\n o\nccurred exclusively on Breitbart.\nFor each term, this analysis results in a sequence of classification bins. In \norder to reduce the influence of very low frequency terms, a term is only \nassigned to the Breitbart bin or /pol/ bin if it had a relative frequency of at \nleast 0.00001%. If not, its frequency is considered to be 0 for that month. \nThis filtering resulted in a classification sequence for each term, which was \nvisualized using color coding (Figure\u00a08.2).\nQualitative analysisThe initial quantitative approach yielded a subset of terms for both periods \nthat warranted further scrutiny; we are particularly interested in those terms \nthat were first observed as prominent on 4chan/pol/ and later also observed on \nBreitbart. Our approach here was to first remove any obvious named entities \n(people, countries, institutions) from the list as well as common English \nlanguage. The remaining tokens could then be analyzed in more detail via a \ncloser reading, in which the context and occurrence of the token on 4chan/pol/ \nas well as on other platforms is studied via 4plebs (the searchable archive of \n/pol/) and 4CAT (the modular web platform scraping tool). Here we retained \nwords with a clear political (sub)text, similar to those shown in Figure\u00a08.1.\nAs such, we have employed a quali-quantitative approach (Venturini \nand Latour, 2010), where we combine an initial computational analysis of \na large dataset to extract a relevant subset of the corpora at hand, which \nwe then analyze further with a more interpretative qualitative approach \nof this subset.\nReferences\nBenkler, Y. (2006). The wealth of networks: How social production transforms markets \nand freedom . Yale University Press.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBeran, D. (2019). It came from something awful: How a toxic troll army accidentally \nmemed Donald Trump into office . St. Martin\u2019s Publishing Group.\nBernstein, J. (2015, July\u00a027). Behind the racist hashtag that is blowing up Twitter. \nBuzzFeed News . https://www.buzzfeednews.com/article/josephbernstein/\nbehind-the-racist-hashtag-some-donald-trump-fans-love.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  181\nBernstein, J. (2017, October\u00a05). Here\u2019s how Breitbart and Milo smuggled Nazi and \nwhite nationalist ideas into the mainstream. BuzzFeed News . https://www.\nbuzzfeednews.com/article/josephbernstein/heres-how-breitbart-and-milo-\nsmuggled-white-nationalism.\nBernstein, M., Monroy-Hern\u00e1ndez, A., Harry, D., Andr\u00e9, P., Panovich, K., and \nVargas, G. (2011). 4chan and /b/: An analysis of anonymity and ephemerality in \na large online community. In Proceedings of the International AAAI Conference \non Web and Social Media , 5(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/\narticle/view/14134.\nBurley, S. (2017). Disunite the right: The growing divides in the pepe coalition. \nPolitical Research Associates. https://www.politicalresearch.org/2017/09/19/\ndisunite-the-right-the-growing-divides-in-the-pepe-coalition.\nCaptain, S. (2017, March\u00a08). Disqus grapples with hosting toxic comments on \nBreitbart and extreme-right sites. Fast Company . https://www.fastcompany.\ncom/3068698/disqus-grapples-with-hosting-toxic-comments-on-breitbart-\nand-extreme-right-sites.\nDay, V. and Eagle, J. R. (2016). Cuckservative: How \u201cconservatives\u201d betrayed America . \nCastalia House.\nDe Zeeuw, D., Hagen, S., Peeters, S., and Jokubauskaite, E. (2020). Tracing normiefica -\ntion. First Monday . https://doi.org/10.5210/fm.v25i11.10643.\nDe Zeeuw, D. and Tuters, M. (2020). Teh internet is serious business: On the deep \nvernacular web and its discontents. Cultural Politics , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\nEllefson, L. (2019, August\u00a07). Breitbart\u2019s audience has dropped 72% since Trump \ntook office\u2014As other right-wing sites have gained. The Wrap . https://www.\nthewrap.com/breitbart-news-audience-dropped-steve-bannon-72-percent/.\nFiorentini, I. (2013). \u201cZOMG! Dis is a new language\u201d: The case of lolspeak. Newcastle \nWorking Papers in Linguistics , 13(1), pp.\u00a090\u2013108.\nFloridi, L. (2021). Trump, Parler, and regulating the infosphere as our commons. \nPhilosophy & Technology , 34(1), pp.\u00a01\u20135. https://doi.org/10.1007/s13347-021-00446-7.\nGreen, J. (2017). Devil\u2019s bargain: Steve Bannon, Donald Trump, and the nationalist \nuprising . Penguin.\nGuess, A., Nyhan, B., and Reifler, J. (2018). Selective exposure to misinformation: \nEvidence from the consumption of fake news during the 2016 U.S. presidential \ncampaign [Working paper]. http://www.dartmouth.edu/~nyhan/fake-news-2016.\npdf.\nHawley, G. (2017). Making sense of the alt-right . Columbia University Press.\nHerring, S. (2012). Special internet language varieties: Culture, creativity & language \nchange [Paper]. The II LETiSS Workshop Language Go Web: Standard and \nNonstandard Languages on the Internet, Pavia.\n182  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nHine, G., Onaolapo, J., Cristofaro, E. D., Kourtellis, N., Leontiadis, I., Samaras, R., \nStringhini, G., and Blackburn, J. (2017). Kek, cucks, and God emperor Trump: \nA measurement study of 4chan\u2019s politically incorrect forum and its effects \non the web. Proceedings of the International AAAI Conference on Web and \nSocial Media, 11(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/article/\nview/14893.\nJenkins, H. (2006). Convergence culture: Where old and new media collide . New \nYork University Press.\nJokubauskait\u0117, E. and Peeters, S. (2020). Generally curious: Thematically distinct \ndatasets of general threads on 4chan/pol/. In Proceedings of the International \nAAAI Conference on Web and Social Media (pp.\u00a0863\u2013867), 14.\nKlayman, A. (2019). The Brink [Feature documentary; Digital film]. https://ali -\nsonklayman.com/the-brink.\nKnuttila, L. (2011). User unknown: 4chan, anonymity and contingency. First Monday . \nhttps://doi.org/10.5210/fm.v16i10.3665.\nLerman, R. (2021, February\u00a024). Major Trump backer Rebekah Mercer orchestrates \nParler\u2019s second act. Washington Post . https://www.washingtonpost.com/\ntechnology/2021/02/24/parler-relaunch-rebekah-mercer/.\nLobinger, K., Kr\u00e4mer, B., Venema, R., and Benecchi, E. (2020). Pepe\u2014Just a funny \nfrog? A visual meme caught between innocent humor, far-right ideology, and \nfandom. In B. Kr\u00e4mer and C. Holtz-Bacha (Eds.), Perspectives on populism and \nthe media  (pp.\u00a0333\u2013352). Nomos. https://doi.org/10.5771/9783845297392-333.\nLudemann, D. (2018). /pol/emics: Ambiguity, scales, and digital discourse on \n4chan. Discourse, Context & Media , 24, pp.\u00a092\u201398. https://doi.org/10.1016/j.\ndcm.2018.01.010.\nMalone, C. (2016, August\u00a018). Trump made Breitbart great again. FiveThirtyEight . \nhttps://fivethirtyeight.com/features/trump-made-breitbart-great-again/.\nMedia Bias/Fact Check. (2021). Breitbart. https://mediabiasfactcheck.com/breitbart/.\nNagle, A. (2017). Kill all normies: Online culture wars from 4Chan and Tumblr to \nTrump and the alt-right . Zero Books.\nNissenbaum, A. and Shifman, L. (2017). Internet memes as contested cultural \ncapital: The case of 4chan\u2019s /b/ board. New Media & Society , 19(4), pp.\u00a0483\u2013501. \nhttps://doi.org/10.1177/1461444815609313.\nPapasavva, A., Zannettou, S., Cristofaro, E. D., Stringhini, G., and Blackburn, J. \n(2020). Raiders of the lost kek: 3.5 years of augmented 4chan posts from the \npolitically incorrect board. Proceedings of the International AAAI Conference \non Web and Social Media , 14, pp.\u00a0885\u2013894.\nPariser, E. (2011). The filter bubble: What the internet is hiding from you . Penguin.\nPeeters, S. and Hagen, S. (2021). The 4CAT Capture and Analysis Toolkit: A Modular \nTool for Transparent and Traceable Social Media Research (SSRN Scholarly \na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  183\nPaper ID 3914892). Social Science Research Network. https://doi.org/10.2139/\nssrn.3914892.\nPeeters, S., Tuters, M., Willaert, T., and de Zeeuw, D. (2021). On the vernacular \nlanguage games of an antagonistic online subculture. Frontiers in Big Data , \n4(65). https://doi.org/10.3389/fdata.2021.718368.\nQuandt, T. (2018). Dark participation. Media and Communication , 6(4), pp.\u00a036\u201348. \nhttps://doi.org/10.17645/mac.v6i4.1519.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nShifman, L. (2012). An anatomy of a YouTube meme. New Media & Society , 14(2), \npp.\u00a0187\u2013203. https://doi.org/10.1177/1461444811412160.\nStanley-Becker, I. (2020, August\u00a01). How the Trump campaign came to court QAnon, \nthe online conspiracy movement identified by the FBI as a violent threat. Washing-\nton Post . https://www.washingtonpost.com/politics/how-the-trump-campaign-\ncame-to-court-qanon-the-online-conspiracy-movement-identified-by-the-fbi-as-\na-violent-threat/2020/08/01/dd0ea9b4-d1d4-11ea-9038-af089b63ac21_story.html.\nTeitelbaum, B. R. (2020). War for eternity: The return of traditionalism and the rise \nof the populist right . Penguin.\nTuters, M. and Hagen, S. (2020). (((They))) rule: Memetic antagonism and nebulous \nothering on 4chan. New Media & Society , 22(12), pp.\u00a02218\u20132237. https://doi.\norg/10.1177/1461444819888746.\nTuters, M., Jokubauskait\u0117, E., and Bach, D. (2018). Post-truth protest: How 4chan \ncooked up the Pizzagate bullshit. M/C Journal , 21(3), Article\u00a03. https://doi.\norg/10.5204/mcj.1422.\nTuters, M. and OILab. (2020). Esoteric fascism online: 4chan and the Kali Yuga. \nIn L. D. Valencia-Garc\u00eda (Ed.), Far-right revisionism and the end of history: Alt/\nhistories (pp.\u00a0287\u2013303). Routledge.\nVenturini, T. and Latour, B. (2010). The social fabric: Digital footprints and quali-\nquantitative methods. Proceedings of Futur En Seine 2009: The Digital Future of \nthe City . Futur en Seine 2009.\nVou\u00e9, P., De Smedt, T., and De Pauw, G. (2020). 4chan & 8chan embeddings. \nArXiv:2005.06946 [Cs] . http://arxiv.org/abs/2005.06946.\nWendling, M. (2018). Alt-Right: From 4chan to the White House . Pluto Press.\nWillaert, T., Van Eecke, P., Beuls, K., and Steels, L. (2020). Building social media \nobservatories for monitoring online opinion dynamics. Social Media + Society , \n6(2). https://doi.org/10.1177/2056305119898778.\nWillaert, T., Van Eecke, P., Van Soest, J., and Beuls, K. (2021). A tool for tracking the \npropagation of words on Reddit. Computational Communication Research , 3(1), \npp.\u00a0117\u2013132. https://doi.org/10.5117/CCR2021.1.005.WILL.\n184  PeeTerS , Wi llaer T , TuTerS , beul S , Va n eec Ke and  Va n So eS T \nWoods, A. (2019). Cultural Marxism and the cathedral: Two alt-right perspec -\ntives on critical theory. In C. M. Battista and M. R. Sande (Eds.), Critical theory \nand the humanities in the age of the alt-right (pp.\u00a039\u201359). Springer. https://doi.\norg/10.1007/978-3-030-18753-8_3.\nZannettou, S., Caulfield, T., Blackburn, J., De Cristofaro, E., Sirivianos, M., Stringhini, \nG., and Suarez-Tangil, G. (2018). On the origins of memes by means of fringe web \ncommunities. ArXiv:1805.12512 [Cs] . http://arxiv.org/abs/1805.12512.\nFunding\nThe authors received funding from the ODYCCEUS project within the \nEuropean Union\u2019s Horizon 2020 program, grant agreement number 732942.\nData availability\nDatasets with the monthly term counts for Breitbart comments and 4chan/\npol/ counts for the periods under investigation are available from Zenodo at \nhttps://doi.org/10.5281/zenodo.5535341. The data do not contain any personal \ninformation or post-level metadata.\nAbout the authors\nStijn Peeters , PhD, is Assistant Professor in Media Studies at the University \nof Amsterdam, Technical Director of the Digital Methods Initiative, and \na co-investigator of the CAT4SMR project, where he has (co-)developed \nseveral research tools such as 4CAT. His research interests include the \nmedia-archaeological analysis of fringe communities on social media.\nTom Willaert , PhD, is a postdoctoral researcher in digital methods at the \nVrije Universiteit Brussel. His research bridges methodological gaps between \ndata science and humanities interpretative practice, with a focus on methods \nfor the analysis of online (mis)information.\nMarc Tuters , PhD, is a Senior Lecturer in Media Studies at the University of \nAmsterdam where his current research examines radical visual subcultures \nat the bottom of the Web together with colleagues at the Open Intelligence \nLab as well as the Digital Methods Initiative.\na f ringe Ma inS Tr eaMe d, or Tr acing an Ta goni S Ti c Sl ang  185\nKatrien Beuls , PhD, is Assistant Professor in artificial intelligence in the \nFaculty of Computer Science at the University of Namur.\u00a0Her main research \ninterests include emergent communication and language, and computational \nconstruction grammar.\nPaul Van Eecke , PhD, is Assistant Professor in the Artificial Intelligence \nLaboratory at the Vrije Universiteit Brussel. His main research topics include \nthe emergence and evolution of language through communicative interac -\ntions and computational construction grammar and its applications.\nJeroen Van Soest , MSc, is a developer and member of the Evolutionary \nand Hybrid AI team in the Artificial Intelligence Laboratory at the Vrije \nUniversiteit Brussel (VUB). He has developed NLP tools and data science \napplications for the Horizon 2020 ODYCCEUS project and is VUB\u2019s lead \ndeveloper on the imec-ICON Trendify project.\n\n9 P olitical TikTok\nPlayful performance, ambivalent critique and event-\ncommentary\nNatalia S\u00e1nchez-Querub\u00edn, Shuaishuai Wang, Briar Dickey \nand Andrea Benedetti\nAbstract\nDuring the U.S. presidential election of 2020, TikTok, an app known for \nlip-synching and remixes of popular media, became a tool for ludic civic \nengagement, ambivalent critique and event-commentary. More specifi -\ncally, TikTokers practiced types of engagement such as playful political \nperformance, in which they express sentiments about a candidate by \ndancing or singing. They also practice remix as ambivalent critique by \njuxtaposing news clips and music to comment on current events. These \nexamples evoke genres of ludic civic engagement such as flash mobs and \ntactical clowning while also exhibiting qualities specific to TikTok. The \nrhetorical power of playfulness and remix lies in distorting, exaggerating, \nand dramatizing; on TikTok, these practices are mainstream rather than \nfringe, raising questions about the contribution of the platform to political \ndiscourse.\nKeywords: TikTok, remix video, playful engagement, ambivalent critique, \nevent-commentary\nResearch questions\nHow are people using TikTok in the run-up to the 2020 U.S. presidential \nelection, and how to characterize TikTokers\u2019 political engagement?\nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_ch09\n188  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nEssay summary\nDuring the 2020 U.S. presidential election campaign season, TikTok, together \nwith other social media platforms, served a great deal of political content in \nthe form of short videos. In doing so, TikTok became \u201cthe default platform \nfor millions of teenagers who want to educate themselves on issues, express \ntheir political ideologies and organize to take action\u201d (Lorenz, 2020a). \nJournalists reported, for example, on the TikTok teenagers that \u201cmeme the \nvote\u201d (Pardes, 2020), the activities of TikTok party-based coalitions or \u201chype \nhouses\u201d (Lorenz, 2020b) as well as the app\u2019s political misinformation problem.\nThese days people routinely use social media to engage with societal \nissues and events such as elections. For example, YouTube vloggers discuss \npolitics and conspiracy theories. Some of them amass large audiences and \nbecome ideological (social media) influencers (Lewis, 2020; Creech and \nMaddox, 2020). Remixing news content is also a popular sense-making \npractice and form of cultural commentary (Geboers, 2019). Reactions to \nevents circulate on Reddit, Twitter, Facebook, and 4Chan as memes and \nviral clips (Nagle, 2017; Tuters and Hagen, 2020). TikTok also assumed this \nrole in the run-up to the elections through its well-known cultural practices \nof lip-synching and creating sketches involving audio clips from popular \nmedia. TikTok has been described as a \u201cnever-ending talent show\u201d (Aroesti, \n2019, para. 4), for which people create content by replicating, remixing, and \nadapting media and sounds.\nOur research asks how people are using TikTok and its features politically. \nWe analyze popular TikTok videos associated with the 2020 presidential \ncandidates, Trump, Biden, and Sanders, using mixed methods. What we \nfind supports the argument that TikTok is an emerging tool for ludic civic \nengagement, ambivalent critique, event-commentary as well as the main-\nstreaming of polarizing satire. These findings are in line with the argument \nthat online media can facilitate \u201cparticipation through their performative, \nexperimental, and creative affordances\u201d (Glas et al., 2019, p.\u00a011). Moreover, \nthe practices that we explore in this chapter evoke ideas already familiar \nin media and political studies (e.g., using performance for political critique) \nwhile also exhibiting characteristics unique to TikTok as a medium. TikTok \nuse during the elections is, in this way, a recent example of the convergence \nbetween \u201ccitizenship, media technologies, and play\u201d (Glas et al., 2019, p.\u00a011).\nTikTok, we learn, remained \u201cfresh\u201d during the election cycle. The top \nvideos associated with Trump, Biden, and Sanders returned by the app (1,000 \nvideos per candidate), on two different dates, March\u00a02020 and January\u00a02021, \nshowed little overlap. Also, each set of videos addressed events current when \nPoli Ti cal Ti KT o K 189\nthe queries were made, thus offering evidence that TikTok is an emergent \nevent-commentary app.\nFurthermore, two media practices were predominant amongst the most \npopular videos. On the one hand, people use TikTok to practice playful \npolitical performance. By \u201cperformance,\u201d we refer to how people use \nsocial media to stage a persona\u2014in this case, a persona with a political \nstance\u2014while dancing, acting, and singing. In addition, we differentiate \nthree types of videos that involve this media practice. People \u201cstage an \nopinion\u201d about a candidate by acting and dancing, \u201cdocument and share \nactivities\u201d like voting, and \u201cgive speeches.\u201d Medina et al. (2020) describe the \npolitically engaged TikTok user in a similar way, namely, as a \u201cperformer \nwho externalizes personal political opinion via an audio-visual act, with \npolitical communication becoming a far more interactive experience than \non YouTube or Instagram\u201d (2020, p.\u00a0264).\nSecondly, we argue, TikTok users practice remix as ambivalent critique. \nThat means they use the app to re-edit, modify, and juxtapose clips from \nthe news and popular culture to comment on the elections. We see this \npractice in two types of videos. People \u201cdramatize\u201d news clips and remix each \nother\u2019s content to form counterarguments, which we call \u201cpartisan duetting \nand stitching.\u201d We add the term \u201cambivalent\u201d to emphasize that the intent and tone of these remix videos is difficult to pinpoint. Humor and serious \ncritique as well as engagement and disinterest appear to coexist in TikTok.\nFake news and conspiratorial narratives, we find, are mostly absent \nfrom the most popular content. However, the performative, playful, and \nambiguous tone of the videos, as well as its hyperpartisan and humorous \nnature invite reflection about problematic behavior on the app and the \ncontributions made to political discourse.\nImplications\nTikTok as an emerging app for event-commentary\nSocial media are described as \u201cevent-following machines\u201d when content \nabout an issue is fresh and aligns with current events. For instance, Twitter \nis the micro-blogging site where journalists, politicians, and lay people \nvoice opinions about pressing matters and inform themselves about what \nis happening during and in the aftermath of protests, natural disasters, and \ncultural events (Rogers, 2014, 2020; Bruns and Weller, 2016; Rathnayake and \nSuthers, 2018). A \u201cstale\u201d social media, on the contrary, is no longer the go-to \n190  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nspace to find information about what is happening or spread one\u2019s message. \nIt is also not an ideal source of data for cultural analysis.\nTikTok, we find, remained \u201cfresh\u201d during two different moments of the \nelection cycle. The most popular videos associated with Donald Trump, \nBernie Sanders, and Joe Biden, collected first in March\u00a02020 and later, \nin January\u00a02021, showed little overlap. Furthermore, each set of videos \naddressed events related to the elections that were important at the time the \nqueries were made. For example, videos associated with Trump, collected \nin March\u00a02020, featured clips from \u201cNamaste Trump,\u201d a rally held in India \nin late February\u00a02020. At the event, Trump was cheered by thousands of \nsupporting Indians (Crowley, 2020). Throughout and after the event, people \nused TikTok to share their sentiment about the upcoming election and \nvoting preferences. In February\u00a02021, the most popular videos addressed, \nby contrast, the outcomes of the election and issues such as misinformation \nand the alleged voter fraud to which, according to Trump supporters, Biden \nowed his victory. These findings add weight to the emerging argument that \nTikTok is a platform for political communication, issue-formation, and \nevent-commentary (Hautea, 2021).\nPlayful political performance: staging opinions, giving a speech, and \ndocumenting\nIn academic discussions, elections are theorized as theater, performance, and \nspectacles that depend on media coverage and are increasingly fashioned as \nentertainment (Chou and Roland, 2016). For example, politicians sit down \nfor interviews on television shows. Magazines report on the holidays and \nfashion choices of presidential candidates, making them into spectacles. \nPublic figures also promote themselves on social media like Twitter, a \nsoftware platform, but also, metaphorically, a place from which to speak \nto one\u2019s followers (Gillespie, 2010). Conventions and rallies feature musical \nacts and guest artists that lend candidates an air of coolness.\nCitizens also engage in political performance. Social media becomes a \ntool to stage a persona, with a political identity and stance. People use their \nsocial media accounts, for example, to share opinions about current issues, \ndonate, and make public their political affiliations. Sharing news articles, \nposting selfies wearing campaign gear, creating memes, and recording videos \ntalking about their experiences all can be forms of political performance.\nTikTok is a space for citizen political performance, too, albeit of a par -\nticular playful nature. In the context of the U.S. elections, TikTokers, we \nfind, combine political performance, in the sense of presenting a persona \nPoli Ti cal Ti KT o K 191\nwith a political stance online, with dancing, acting, and singing. When \ncreating this content, they also experiment with video editing techniques \nsuch as zooming, soundtracks, filters, special effects, and greenscreens. \nWe differentiate three types of TikTok videos that use playful political \nperformance: \u201cstaging opinions,\u201d \u201cgiving a speech,\u201d and \u201cdocumenting.\u201d\nIn Figure\u00a09.1, a woman dances and sings along to the song \u201cGreat Again\u201d \nby American musician James McCoy Taylor. The sound playing in the \nvideo features the verses, \u201cI voted for a man named Donald J. Trump / \n\u2018Cause when they\u2019re playin\u2019 the anthem I stand up / I know that half of \nAmerica will too / And we ain\u2019t scared of no Kim Jong-un.\u201d The video was \nposted as a response to a comment left on the woman\u2019s account, which \nis displayed also on the screen. It reads: \u201cI followed you and now you lost \nme. No more Trump.\u201d In another video, a man sings along to the \u201cTrump Theme Song.\u201d The song includes verses such as: \u201cRacism / Bigotry / Lying \n/ Polygamy / Immature asshole on God / Pride / Mediocrity / And how he \nhandled Iran\u2026\u201d These two videos are examples of what we call \u201cstaging an opinion.\u201d\nScholarship on music and politics has observed that soundtracks create \nemotional intensity around political personas. According to musicologist \nJames Deadville, specific sounds become associated with the different \npolitical camps and help \u201cto create a collective identity and to construct \nconsensus\u201d (Deadville, 2015, p.\u00a01). Songs are \u201cwritten or modified for a specific \ncandidate\u201d and concerts become political spaces (Deadville, 2015, p.\u00a01), \nlike when the \u201cDixie Chicks lead singer Natalie Maines infamously dissed \nBush at a 2003 concert in London\u201d (Henwood, 2017). Likewise, at public \nappearances, conventions, and rallies, the public expects certain playlists. \nOrganizers, Deadville (2015) explains, draw on new classics of patriotic \nand inspirational character such as Bruce Springsteen\u2019s song \u201cBorn in the \nU.S.A.\u201d for the Democrats. That \u201chardly any of the invited famous pop artists \nwanted to perform at [Donald Trump\u2019s] inauguration in January\u00a02017\u201d was reported extensively (Mehring, 2020, p.\u00a022). Moreover, outside convention \nfi gure\u00a09.1 \u201c i  voted for a man named do nald J. Trump\u201d [video frames]. a  TikTok user sings and \ndances to the pro-Trump song (and now, TikTok sound) \u201c gr\neat \nag\nain\u201d by \nam\nerican musician James \nMcco\ny Taylor.\n192  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nhalls, \u201cprotesters staged their own media-driven spectacles replete with \nmusic (and speech)\u201d (Deadville, 2015, p.\u00a08).\nThe activity on TikTok offers a recent example of the role music plays \nduring elections. When people \u201cstage their opinions,\u201d not unlike during \npolitical rallies and conventions, the lyrics and mood of a song become \nproxies for their feelings about a candidate (Mehring, 2020; Deadville, 2015). \nMusic also becomes a tool for contestation on TikTok. Trump supporters, \nfor example, used clips from the song \u201cRed Kingdom\u201d as a soundtrack for \ntheir TikTok videos. Red Kingdom, however, was intended as an anthem \nfor the Kansas City Chiefs, an American football team. Conservative \nTikTokers , according to a writer for the Kansas-based magazine The Pitch , \n\u201chave trolled themselves into thinking that a song by a Black activist for \na football team with a Black superstar quarterback was created for their \nhateful agenda\u201d (Searles, 2020, para. 3). To address the misappropriation, \nliberal TikTokers \u201cmade videos to flood the sound \u2018tag\u2019 with positive, \ninclusive content to \u2018drown out\u2019 the hateful posts\u201d (Searles, 2020). Luke \nBryan\u2019s song \u201cCountry Girl (Shake It for Me),\u201d similarly, was used by TikTok -\ners as a nod to the \u201cliberal cowboy,\u201d after it became public that the singer \nwas not a Trump supporter (Lenzen, 2020). Also, YG and Nipsey Hussle\u2019s protest track \u201cFDT\u201d (F\u2014 Donald Trump) \u201cmade similar waves but never \ngarnered as much TikTok fame as its conservative counterparts\u201d (Konrad, \n2021, para. 8).\nThe videos we discuss above were returned on top by TikTok\u2019s search \nengine when searching for the presidential candidates. They are successful \nexamples of broader trends and thus linked to other videos on the app, \nboth conceptually and technically by sounds and hashtags. Clicking on the \nhashtag \u201cRed Kingdom\u201d or the \u201cTrump Theme Song\u201d sound redirects users \nto other videos featuring these same auditory elements and engaging with \nthe same video concept, for example, by replicating or parodying it. TikTok \nis, in this sense, an \u201cevolving tapestr[y] of self-referential texts collectively created, circulated, and transformed by participants online\u201d (Phillips and Miller, 2017, p.\u00a030). On Facebook or Reddit, memes look like image macros \nannotated with text. There is scholarship that explores the role of these \nimage-based memes in contemporary politics, uncovering fringe visual \nand textual cultures. TikTok meme behavior is, however, performative, in \nthat \u201cusers replicate the same type of video or similar video concepts using \na sound or effect over and over again\u201d (Zulli and Zulli, 2020, p.\u00a010). TikTok \ninvites those interested in ludic civic engagement online to consider the \nrole of music in a new light.\nPoli Ti cal Ti KT o K 193\n\u201cStaging an opinion\u201d on TikTok also resonates with practices of ludic \ncivic engagement that make use not only of music but that also rely on \ntheatrical and humorous interventions (Glas et al., 2019). Stunts, tactical \nclowning, critical play, the carnival, and flash mobs are examples of such \nludic engagements. Majken Jul S\u00f8rensen (2016), a scholar specializing in \nthe subject of humor in activism, argues that these genres \u201cshare a playful \nattitude towards expression of dissent and use various creative or artistic ways of communicating\u201d (2016, p.\u00a012). For example, in 2013, a Spanish radio \nshow organized a flash mob in an unemployment office, at a time when \nSpain endured an unemployment rate of 26%. A small orchestra arrived \nunnoticed in the waiting room and played \u201cHere Comes the Sun\u201d by The \nBeatles (Urquhart, 2013). The intervention, while on the ground, aimed \nto spread awareness to Spain\u2019s growing economic crisis by going viral. \nOn another occasion, students staged a flash mob by dancing to Michael \nJackson\u2019s song \u201cThriller\u201d in \u201cfull Zombie regalia to protest the death of public \neducation in Chile\u201d (Colquhounon, 2013, para. 4).\nTikTok users also stage their opinions about the U.S. presidential elections \nusing theatrical gestures evocative of flash mobs and clowning. In Figure\u00a09.2, \nfor instance, a man uses Kamala Harris and Joe Biden\u2019s heads as drums. \nThe text on the video reads: \u201cwhich of the two has the most hollow head?\u201d In Figure\u00a09.3, another man bops to the viral sound, Bass Da Da Da , which \nis a fragment from a song by the same name. The text on the screen reads: \n\u201cDoes anyone else hear \u2018thank God for Donald Trump?\u2019\u201d The critiques posed \nby the Spanish and Chilean flash mobs are clear\u2014there is a discontent with \ncurrent employment and education situations. Spectators may read into the \nsymbology of a band of zombie dancing towards a public institution. In the \nTikTok videos we study there is, instead, ambiguity, a topic that we returned \nto in the next section. As a case in point, in Figure\u00a09.2, the discontent with \nBiden and Harris is clear, however much one may not infer a stance or goal \nfrom the video.\nBesides \u201cstaging an opinion,\u201d the two other types of videos that involve \nplayful political performance are \u201cgiving a speech\u201d and \u201cdocumenting.\u201d \nFigure\u00a09.4 is an example of \u201cgiving a speech\u201d; in the video, a man turns \nthe camera towards himself and warns viewers about the liberal party, \nwithout using dramatic embellishments such as music or the video editing \ncapabilities of TikTok. \u201cThe hard left,\u201d he says, \u201cthrows not facts just slurs\u201d and \n\u201cdoesn\u2019t care about facts or truth.\u201d Figure\u00a09.5 is an example of \u201cdocumenting.\u201d \nA man records himself from the inside of his car. The driver of the car \nbeside him has stepped outside and is hitting his window with a metal bar. \n194  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nOverlayed on the screen is the following text: \u201cThis is what happens when \nTrump supporters get mad. Someone identify him?\u201d\n\u201cGiving a speech\u201d and \u201cdocumenting\u201d are familiar online forms of political \nperformance. We find examples of \u201cdocumenting\u201d on Twitter from instances \nof citizen journalism to call outs and requests to find the perpetrator of a transgression. On YouTube, Facebook Live, and Instagram Stories people \nfi gure\u00a09.2 \u201c ho llow heads\u201d  [video frames]. in t his TikTok video a man uses editing effects to play \ndrums with the heads of the then presidential candidate, Joe \nbi\nden, and running mate, Kamala \nha\nrris. The text displayed on the video reads: \u201cwhich of the two has the most hollow head?\u201d\nfi gure\u00a09.3 Thank go d for do nald Trump?  [video frames]. in t his TikTok video, a man bops to the \nsound of Bass Da Da Da , a fragment from the song by the same name. The text on the screen \nreads: \u201c do\nes anyone else hear \u2018thank \ngo\nd for \ndo\nnald Trump?\u2019\u201d\nfi gure\u00a09.4 \u201c The left lies\u201d [video frames]. a  TikTok user turns the camera towards himself. he w arns \nviewers about the liberal party. The hard left, he says, \u201cthrows not facts just slurs\u201d and will avoid \nany facet of truth. \nac\ncording to him, the left \u201cdoesn\u2019t care about facts or truth.\u201d\nfi gure\u00a09.5 \u201c is t his what happens\u2026?\u201d [video frames]. a  man records an alleged Trump supporter \nhitting his car window with a bar. The text \u201cThis is what happens when Trump supporters get mad. Someone identify him?\u201d appears on the video.\nPoli Ti cal Ti KT o K 195\ntalk politics and give speeches, albeit in longer form than on TikTok. \u201cStag -\ning an opinion\u201d through TikTok speech-giving could be said to specific to \nTikTok.\nRemix as ambivalent critique: Dramatization of media clips and \npartisan stitching and duetting\nRemixing is a creative media practice. It involves reediting \u201ctelevision, \nmovies, and news media for critical and political purposes\u201d (McIntosh, 2012, \npara. 1). \u201cDonald Duck Meets Glenn Beck in Right Wing Radio Duck,\u201d a remix \nvideo by artist Jonathan McIntosh, exemplifies the practice. Glenn Beck \nis an American conservative commentator, conspiracy theorist, and radio \nhost. McIntosh edited audio from Beck\u2019s radio show with Disney cartoons, \nsuggesting a narrative in which Donald Duck became radicalized. The aim of \nthe piece was \u201cto demonstrate how right-wing media paradoxically appears \nsympathetic while fear-mongering\u201d (burrough and Dufour, 2018, p.\u00a098).\nAnother example of remix is the parody video \u201cCandidate Obama Debates \nPresident Obama on Government Surveillance.\u201d The creator juxtaposes \nclips from different interviews during Obama\u2019s career, \u201cpointing out the \ninconsistencies in Obama\u2019s position on national security\u201d (Nunes, 2018, \np.\u00a0219\u2013220). The video essay is yet another form of audio-visual criticism. \nRemixed footage has, indeed, been part of \u201cexperimental cinema and film criticism for a number of decades\u201d (McWhirter, 2016, p.\u00a0372). Recently, also \nYouTube has seen an outburst of video essayists. These are all examples \nof what media scholar Henry Jenkins calls participatory politics, namely, \ninstances of citizens having \u201cthe means of creating political commentary \nthrough the reuse and reappropriation of the media content that makes up \nthe majority of our contemporary political discourse\u201d (Nunes, 2018, p.\u00a0219).\nRemixing is an important practice within TikTok. Users of the app tend \nto \u201ccomment on and rework existing cultural imaginaries and narratives \nby refashioning old media forms \u2026. [T]his is immediately visible in TikTok \nusers combining audio fragments from movies and TV news with mimicry to \npoke fun of current events\u201d (Vijay and Gekker, 2021, p.\u00a0717). In line with these \ntrends, in the context of the U.S. presidential elections, we found TikTokers \npracticing remix as ambivalent critique. That is to say, TikTokers are using \nthe app to juxtapose, combine, and enhance audio-visual materials related \nto the elections. Amongst the most popular content are the videos we label \nas \u201cdramatization of media clips\u201d and \u201cpartisan duetting and stitching.\u201d We \nsee them as medium-specific forms of remix and examples of participatory \npolitics.\n196  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nWe labeled videos as \u201cdramatization of media clips\u201d when TikTok users \njuxtapose and re-edit news clips (e.g., fragments from a televised press \nconference) with other clips, text, sounds, and voiceover commentary. \nBringing together news content with these new elements reframes and alters \ntheir meaning, often overstating, mocking, and exaggerating actions, or in \nother words, dramatizing them. Figure\u00a09.6 is an example of this practice. The \nvideo includes footage from a press conference held in the White House, in \nOctober\u00a02018. Donald Trump points to Cecilia Vega, a journalist from ABC \nNews, signaling that she can ask him a question. The sentence \u201cwait for it\u201d appears on the video. Then, Trump says \u201cshe\u2019s shocked that I picked her\u2026 \nshe\u2019s like in a state of shock\u2026 That\u2019s OK. I know you\u2019re not thinking. You \nnever do.\u201d The video transitions into a Trump lookalike dancing in front of \na background with the words Trump 2020\u2014a visual punchline.\nIn another example of the \u201cdramatization of media clips,\u201d a TikTok user \nrecords a segment from the late-night television show Jimmy Kimmel Live!  \nand adds a laugh track (Figure\u00a09.7). The show created a video including \nboth real images of Trump\u2019s visit to Pope Francis and edited images of him \nallegedly taking Pope Francis\u2019s hand and then of Francis slapping it away. \nThe sketch mocked Trump and the former first lady\u2019s cold relationship and a \nsimilar hand-slapping incident. The CNN logo is displayed on the video. This \nuser seems to be in on the joke\u2014the video is a parody. The Jimmy Kimmel \nLive!  video, however, had to be debunked by fact-checker website Snopes \n(Evan, 2017), indicating that once outside the context of the television, not everyone was aware of its nature.\nSimilarly, a TikTok user records his television, where we see Joe Biden \ntaking part in a Wired magazine \u201cAutocomplete\u201d interview in May\u00a02020. \nDuring the segment, guests answer the most \u201cGoogled\u201d questions about \nthemselves (Figure\u00a09.8). One of the questions for Biden is: Does Joe Biden \nhave a brother? Biden responds by saying, \u201cI got a sister who is the love of \nmy life.\u201d The focus of the video shifts to a teenager, sitting in front of the \ntelevision, playing \u201cSweet Home Alabama\u201d on his guitar and tipping his \nhat. In this context, the song plays on the stereotype that incest abounds \nfi gure\u00a09.6 . \u201cWait for it\u201d [video frames]. The video is an example of \u201cremix as ambivalent critique\u201d \nand, specifically, of the \u201cdramatization of media clips.\u201d \na\n TikTok user edits together footage from \nthe press conference when Trump insults \nce\ncilia Vega, a journalist from \nabc\n \nne\nws, with images of \na Trump look-a-like dancing before the slogan Trump 2020.\nPoli Ti cal Ti KT o K 197\nin the American South, hinting that Biden\u2019s relationship with his sister is \ninappropriate. This particular moment in the interview generated numerous \nmemes.\nYet another memetic dynamic built into TikTok is the \u201cduet\u201d function. \n\u201cDuet\u201d means creating a split screen to display one\u2019s video side-by-side a \nvideo created by someone else. People \u201cduet\u201d to create a scene by bringing \ntogether two separate videos, dance parallel to someone else, or comment \non content created by other TikTok users. If a person uses the \u201cstitching\u201d \nfunction, instead of having a split-screen, the videos are integrated into \neach other. It is often about re-using snippets of other people\u2019s video clips \nto create responses and remixes on the same theme. We find that these \nfunctions are used to engage with the elections and offer a TikTok-specific \nform of competition or contestation between political parties. We call this \ntype of video \u201cpartisan duetting and stitching.\u201d\nAn example of duetting can be seen in Figure\u00a09.9. The original video \nfeatures a young Trump supporter, marching to the song \u201cKings & Queens\u201d \nby Ava Max and lifting her hand towards the edge of the screen. The text on \nher screen reads, \u201clet\u2019s start a chain of women for Trump.\u201d The invitation is for other women to post similar videos and to duet or stitch them together. \nfi gure\u00a09.7 \u201c do nald Trump and The Pope\u201d [video frames]. a  TikTok user records and overlaps \nwith a laugh track a comedic sketch from the television show Jimmy Kimmel Live!  where Trump \nappears to reach for Pope \nfr\nancis\u2019s hand and the latter slapping it away.\nfi gure\u00a09.8  \u201cbi den and his sister\u201d [video frames]. a  TikTok user records his television as Joe bi den\u2019s \nWired  magazine \u201c au\ntocomplete\u201d interview plays. When asked if he has a brother, Joe \nbi\nden \nresponds by saying, \u201c i\n got a sister who is the love of my life.\u201d The focus of the video shifts to a \nteenager playing \u201cSweet \nho\nme \nal\nabama\u201d on his guitar and tipping his hat, joking that \nbi\nden\u2019s \nrelationship with his sister might be inappropriate.\n198  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nIf they imitate the way the creator of the original video raises her hand, \nonce the videos come together it would be like they were all holding hands. \nIn Figure\u00a09.9, however, it is a young man who responds and parodies the \noriginal video. He marches to the same song but when the time comes to join \nhands, he lifts an iron, even including a hissing sound. In yet another video, a \nTrump supporter uses a spray bottle to demonstrate how liquid goes through \na mask. The video is \u201cstitched\u201d by a Biden supporter who conducts their own \nexperiment, demonstrating that masks, indeed, work. In yet another example, \nin Figure\u00a09.10, a young woman combs her eyebrows while the following text \nappears on the screen: \u201cwhen I can attract both genders.\u201d The video is stitched \nby a man wearing a Trump hat. He says, \u201cahh, so there are only two genders. \nThank you for proving my point sweetheart. He winks and tips his cap.\u201d\nTikTok, one could argue, has popularized a new form of political remix \nvideo. Yet, this is not to say that the TikTok videos we study are the same as \nthe work of artists as McIntosh, who are explicit about their political intent. \nTikTok videos are, instead, often ambivalent. We use the term ambivalent \nin similar fashion as Phillips and Milner (2017) and Tuters and Hagen (2020) \ndo (see also Niederer and Colombo, this volume). These authors remark how \nonline political communication (e.g., in forums as Reddit) is characterized \nfi gure\u00a09.9 \u201c le t\u2019s start a chain of women for Trump\u201d [video frames]. a  TikTok user invites women to \nrecord themselves marching to the song \u201cKings & \nqu\neens\u201d by \nav\na Max and stitch them together \nto show support for \ndo\nnald Trump. \nin t\nhe video, a man parodies the original video and mocks the \ncontent creator.\nfi gure\u00a09.10 \u201cWhen i  can attract both genders\u201d [video frames]. a  TikTok user combs her eyebrows, \nwhile the sentence \u201cwhen \ni\n can attract both genders\u201d hovers on the screen. The video was stitched \nby a man wearing a Trump hat. \nhe s\nays \u201cahh, so there are only two genders. Thank you for proving \nmy point sweetheart.\u201d \nhe w\ninks and tips his cap.\nPoli Ti cal Ti KT o K 199\nby humor, absurdity, and a sense of detachment. It can be \u201cantagonistic \nand social, creative and disruptive, humorous and barbed, the satirizing of \nproducts, antagonization of celebrities, and creation of questionable fan art\u201d \n(Phillips and Milner, 2017, p.\u00a010). Ambivalent can be understood in opposition \nto earnest or aligned with a clear agenda. TikTok, indeed, often leaves the \nviewer with the sensation that the absurdity of the current political reality \nis the object of critique. On TikTok, the lines between earnest and mocking \nentertainment and political engagement are constantly blurred\u2014\u201csharing a \n\u2018funny\u2019 video that has a certain political stance does not mean committing \nor aligning to that politics\u201d (Vijay and Gekker, 2021, p.\u00a0178).\nTikTok\u2019s misinformation problem\nWe have presented three arguments so far. We first posit that TikTok \nremained \u201cfresh\u201d during the elections as evidence of its function as event-\ncommentary medium. Then, we identified two media practices present in \npopular election-related videos: \u201cplayful political performance\u201d and \u201cremix \nas ambivalent critique.\u201d We also differentiate between types of videos that \ninclude these practices, such as \u201cstaging an opinion\u201d and \u201cdramatizing media \nclips.\u201d Furthermore, we discussed these videos and practices vis-\u00e0-vis playful \nactivism, parody, and political remix videos. TikTok videos relate to these \ngenres while also being medium-specific modes of ludic civic engagement. \nIn this section, we revisit \u201cplayful political performance\u201d and \u201cremix as \nambivalent critique\u201d in relation to the issue of information disorders.\nAccording to Claire Wardle (2017), co-founder of First Draft News, in -\nformation disorders are types of content that raise concern in the context \nof issue-making and democratic process. Existing studies have already \nidentified disorderly information on TikTok in the form of hyperpartisan, \nmisleading content, manipulated content, and false context content about \nthe U.S. presidential elections. For instance, Media Matters, a non-profit \norganization that scrutinizes right-leaning media, identified eleven examples \nof election conspiracies and misleading claims spreading on TikTok. These \ninclude videos with narratives about alleged voter fraud and a deceptively \nedited clip of Joe Biden, which accumulated hundreds of thousands of views \n(Little, 2020). To combat the problem, TikTok set up content guidelines for \nthe elections and moderated \u201cterms associated with hate speech, incitement \nto violence, or disinformation around voter fraud, such as ballot harvesting\u201d \n(TikTok, 2021). Posting about conspiracies like QAnon and anti-vaccination \nnarratives is now banned (TikTok, 2021). Media Matters reported that \nafter their investigation, TikTok removed the flagged videos, reduced the \n200  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \ndiscoverability of other problematic posts, and added banners linking \nsuspicious content to authoritative sources about the election.\nAmong the most popular videos\u2014from a subset of content returned in \nJanuary\u00a02021\u2014there are no fake and conspiratorial videos, for example, \nassociated with QAnon and other known, flagged topics. It is not entirely \nsurprising given the app\u2019s information cleaning efforts. What we did find are \nvideos in which misinformation is a topic. For example, in Figure\u00a09.4 a man \nclaims that the Democratic Party has no regard for the truth, a familiar argu-\nment amongst Trump supporters. This video is example of \u201cplayful political \nperformance\u201d and, specifically, \u201cgiving a speech.\u201d In another video, a TikToker \nduets an anti-mask video. They conduct an experiment that shows that masks \nactually block sprayed liquid. The parody clip created by Jimmy Kimmel Live!  \nfeatured Pope Francis brushing of Trump\u2019s hand is fake and plays on rumors \nabout Donald and Melania Trump\u2019s cold marriage. (As mentioned, the parody, \nnevertheless, had to be debunked by Snopes, the fact-checking organization.)\nTikTok videos beyond the examples above invite yet another line of \nquestioning. Playful performance, remix, and humor are dominant modes \nof expression on TikTok, and their meaning-making capacities depend \non altering, juxtaposing, exaggerating, and dramatizing. The goal is not \nto correct remix and playfulness, or humor. These practices are not new \nand exist in forms of activism, political cartoon, and comedy shows. As \nwe explored earlier in this chapter, they have important critical, civic, and \npolitical capacities to them by making \u201cpolitical issues into a piece of theater \nwhen their attacks on dominant discourses disrupt, subvert, oppose and \ntransform business as usual\u201d (S\u00f8rensen, 2016, p.\u00a013). Yet a challenge TikTok \nposes, we argue, is considering playful performance, remix, and humor \nnot as fringe critical practices but as mainstream modes for engaging with \nelections. Or, in other words, considering, for example, that one may learn \nabout an event first through its parody or remix.\nFor example, Ride It by Regard is a viral sound for TikTokers to create fin -\nger dancing videos with word bubbles denoting cultural misunderstandings. \nThese in-video texts usually display inaccurate representations of a culture, \na nation or a minority group. In the Netherlands, for example, local creators \nuse the sound to make videos indicating that not all Dutch people live in \nAmsterdam or the sunshine over the canals is a typical misrepresentation of Dutch life as wind and rain are a more common occurrence. For young \nvoters in the U.S., the same sound is widely deployed to make dancing videos \nengaging with the \u201caccusations\u201d of being Trump supporters, which include \n\u201cget called racist 24/7,\u201d \u201cget yelled at for presenting facts,\u201d and \u201caccused of not \nrespecting women.\u201d Aligning with the study that finds sounds on TikTok \nPoli Ti cal Ti KT o K 201\nfunctioning as a story builder to convey a specific message (Medina et al., \n2020), Trump supporters employ the sound to suggest that these accusations \nare untrustworthy and even entertaining.\nIn another video, a young man wearing a \u201cMAGA\u201d hat performs a finger \ndance with the caption \u201cnot sorry if you\u2019re offended by facts,\u201d referring to \n\u201cabortion is murder,\u201d \u201cguns don\u2019t kill people, people do,\u201d and \u201ctaking away \nguns is unconstitutional.\u201d These are slickly produced videos, using creative \ntools at once to entertain and to put forward misunderstanding as the root \nof disagreement with Trump politics.\nIn the study of misinformation, parody or satire is said to sometimes fool \nthe viewer, albeit unintentionally. Here we find that the sarcastic videos that \nparody candidates seem to be motivated by an intention to instill mistrust. \nMoreover, their lightheartedness could fool the viewers into thinking that it \nwas just for fun. To consider here is how the \u201cnon-serious nature of TikTok \nfurther obscures its actions as a playfield for (political) persuasion\u201d (Vijay \nand Gekker 2021, p.\u00a0714). TikTok has also raised concern \u201cabout its distorting \nimpacts on political discourse and participation\u201d (Vijay and Gekker, 2021, \np.\u00a0714). Also challenging is the mainstreaming of ambivalence: what is \nlabeled as \u201csatire\u201d is often hateful, polarizing and divisive content but it \nmust not be taken seriously because it is a \u201cjoke.\u201d\nFindings\nFinding 1: TikTok is an event-commentary medium, active and topical \nduring the election cycle. The hashtags linked to videos concerning the \nthen-presidential candidates, Joe Biden (#biden2020), Donald Trump \n(#trump2020, #maga2020), and Bernie Sanders (#bernie2020), were ac -\ntive between March\u00a02020 and February\u00a02021. Comparing the 1,000 most \nengaged with videos on TikTok for each hashtag query in March\u00a02020 and \nJanuary\u00a02021 revealed the most popular videos changed, an indication of \nactivity. Popularity on TikTok is measured in terms of cumulative interac -\ntions, including the number of views, likes, comments, and shares that a \nvideo receives. The videos popular in 2020 and in 2021 have content that \nis highly topical. That is, it is connected to current events such as Trump\u2019s visit to India in 2020, the tensions with Iran, and Bernie Sanders dropping out of the race. They treat current events by way of remixing, dramatizing \nand in general manipulating or creating original media content based on \nthose events. These digital activities are a key form of participating in the political discourse surrounding current events.\n202  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nFinding 2: There are typical TikTok political engagement practices. The \nresults of the coding of 120 TikTok videos collected in 2021 (30 per hashtag) \nresulted in 5 different types of videos, which were further subsumed under \ntwo media practices (see Table\u00a09.1).\nTable\u00a09.1  M edia practices and types of election-related TikTok videos.\nMedia practice Video Concept Description\nPlayful political \nperformanceStaging an opinion TikTok users engage in performative activities such as lip syncing, dancing or roleplaying to express their political ideas.\ndo\ncumenting/sharing a\n pre-existing piece of media is reposted \non TikTok with no meaning-altering embellishment.\ngi\nving a speech TikTok users use only the video capacity of TikTok to record and share a short speech, with no editing or embellishment.\nre\nmixing as \nambivalent critiqueTheatricalization of media TikTok users add embellishments such as sounds, music, laugh tracks, dub dialogue or other editing techniques to existing media clips in a way that frames or alters the meaning of the original clip(s).\nPartisan stitching and duettingTikTok users use the \u201cstitching\u201d tool, which places their own video next to another user\u2019s video, to create contrast with the latter. \nof\nten, the new video contests \nor mock\u2019s the content of the video it is stitched to.\nStrategy Count Percentage \nTheatricalization of media clips 48 40%\ndo\ncumenting/ sharing 24 20%\nac\nting an opinion 19 15.8%\nStitching and duetting as contrast 5 4.2%\ngi\nving a speech 2 1.7%\noth\ner 22 18.3%\nMethodology\nThe data was gathered using the TikTok-scraper (Drawrowfly, 2021), a \nsoftware tool that uses TikTok\u2019s Web API to scrape media and related \nmeta-information. We collected the 1,000 most popular videos associated \nPoli Ti cal Ti KT o K 203\nwith the hashtags #Trump2020, #maga2020, #biden, and #bernie2020 on \nMarch\u00a023, 2020 and January\u00a04, 2021. The scraper collected the video ID, \nusername, date of creation, video URL, caption, hashtags, and engagement \nmetrics such as view count for each of the videos. The dataset consists of \n8,000 videos. We extracted the top 30 videos per hashtags, creating a subset \nof 120 videos. We answered the first research question by comparing the \n1,000 videos collected for each of the hashtags on the two dates. Our goal \nwas to determine if the most popular videos changed. The techniques used \nby TikTok users and the various types of political videos were identified \nthrough a qualitative exploration of the top 30 videos per hashtags. Each \nvideo from this sample was coded according to the performative and remix \ntechniques used by its creator. This began with an open coding process \nto develop a consistent coding schedule which was then repeated several \ntimes. The four authors acted as coders and controlled for the consistency \nof the coding by employing an inter-researcher reliability test.\nReferences\nAroesti, R. (2019, November\u00a01). Why are teenagers on TikTok obsessed with an eerie \n1950s song? The Guardian . https://www.theguardian.com/culture/2019/nov/01/\nwhy-are-teenagers-on-tiktok-obsessed-with-an-eerie-1950s-song.\nBruns, A. and Weller, K. (2016). Twitter as a first draft of the present: And the \nchallenges of preserving it for the future. In Proceedings of the 8th ACM \nConference on Web Science (WebSci\u201916)  (pp.\u00a0183\u2013189). ACM. https://doi.\norg/10.1145/2908131.2908174.\nburrough, x. and Dufour, F. (2018). Creativity. In E. Navas, O. Gallagher, and x. \nburrough (Eds.) Keywords in remix studies (pp.\u00a092\u2013104). Routledge.\nCaramanica, J. (2020, March\u00a020). This \u201cImagine\u201d cover is no heaven. New York \nTimes . https://www.nytimes.com/2020/03/20/arts/music/coronavirus-gal-gadot-\nimagine.html.\nColquhoun, R. (2013, January\u00a013). Political art and activism: Flash mob. National \nCollective. http://www.nationalcollective.com/2013/01/13/political-art-and-\nactivism-flash-mob/.\nCrowley, M. (2020, February\u00a024) \u201cAmerica loves India,\u201d Trump declares at rally \nwith Modi. New York Times . https://www.nytimes.com/2020/02/24/world/asia/\ntrump-india.html.\nDe Zeeuw, D. and Tuters, M. (2020). Teh internet is serious business: On the deep \nvernacular web and its discontents. Public Culture , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\n204  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nDeadville, J. (2015). The sound of media spectacle: Music at the party conventions. \nMusic & Politics, 9 (2), pp.\u00a01\u201324. https://doi.org/10.3998/mp.9460447.0009.205.\nDrawrowfly. (2021). TikTok scraper [software]. https://github.com/drawrowfly/\ntiktok-scraper.\nEvan, D. (2017, May\u00a026). Did Pope Francis slap away President Trump\u2019s hand? \nSnopes . https://www.snopes.com/fact-check/pope-francis-trump-hand-slap/.\nGeboers, M. (2019). \u201cWriting\u201d oneself into tragedy: Visual user practices and \nspectatorship of the Alan Kurdi images on Instagram. Visual Communication . \nhttps://doi.org/10.1177/1470357219857118.\nGekker, A. (2019). Playing with power: Casual politicking as a new frame for political \nanalysis. In R. Glas, S. Lammes, M. de Lange, J. Raessens, and I. de Vries (Eds.) \nThe playful citizen: Civic engagement in a mediatized culture (pp.\u00a0387\u2013419). \nAmsterdam University Press.\nHautea, S., Parks, P., Takahashi, B., and Zeng, J. (2021). Showing they care (or don\u2019t): \nAffective publics and ambivalent climate activism on TikTok. Social Media+ \nSociety . https://doi.org/10.1177/20563051211012344.\n \n K\nonrad, C. (2021, January\u00a028). Trump presidency permanently alters landscape of \nmedia. The Maneater . https://themaneater.com/trump-presidency-permanently-\nalters-landscape-of-media/.\nLenzen, C. (2020, November\u00a09). This Luke Bryan song is an anti-Trump anthem on Tik -\nTok. The Daily Dot . https://www.dailydot.com/irl/luke-bryan-anti-trump-tiktok/.\nLewis, R. (2020) \u201cThis is what the news won\u2019t show you\u201d: YouTube creators and the \nreactionary politics of micro-celebrity. Television & New Media , 21(2), pp.\u00a0201\u2013217. \nhttps://doi.org/10.1177/1527476419879919.\nLorenz, T. (2020, November\u00a04). Election night on TikTok: Anxiety, analysis and \nwishful thinking. New York Times . https://www.nytimes.com/2020/11/04/style/\ntiktok-election-night.html.\nMcIntosh, J. (2012). A history of subversive remix video before YouTube: Thirty \npolitical video mashups made between World War II and 2005. Transformative \nWorks and Cultures, 9 . https://doi.org/10.3983/twc.2012.0371.\nMcWhirter, A. (2015). Film criticism, film scholarship and the video essay. Screen, \n56(3), pp.\u00a0369\u2013377. https://doi.org/10.1093/screen/hjv044.\nMedina Serrano, J.C., Papakyriakopoulos., O. and Hegelich S. (2020). Dancing to \nthe partisan beat: A first analysis of political communication on TikTok. In \nProceedings of the 12th ACM Conference on Web Science, pp.\u00a0257\u2013266. https://\ndoi.org/10.1145/3394231.3397916.\nNagle, A. (2017). Kill all normies: Online culture wars from 4chan and Tumblr to \nTrump and the alt-right . Zero Books.\nNunes, M. (2018). Parody. In E. Navas, O. Gallagher, and x. burrough (Eds.) Keywords \nin remix studies (pp.\u00a0217\u2013229). Routledge.\nPoli Ti cal Ti KT o K 205\nPardes, A. (2020, October\u00a022). The TikTok teens trying to meme the vote. Wired . \nhttps://www.wired.com/story/tiktok-election-2020/.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nRathnayake, C., and Suthers, D.D. (2018). Twitter issue response hashtags as af -\nfordances for momentary connectedness. Social Media+ Society . ht tps://doi.\norg/10.1177/2056305118784780.\nRogers, R. (2014). Debanalising Twitter: The transformation of an object of study. \nIn K. Weller, A. Bruns, J. Burgess, M. Mahrt and C. Puschmann (Eds.), Twitter \nand society (pp. ix\u2013xxvi) . Peter Lang.\nRosenblatt, K. (2020, October\u00a017). They can\u2019t vote, but they can meme: How these TikTokers \nare trying to get Biden elected. NBC News . https://www.nbcnews.com/pop-culture/\nviral/they-can-t-vote-they-can-meme-how-these-TikTokers-n1243555.\nSalen, K. and Zimmerman, E. (2004). Rules of play: Game design fundamentals . \nMIT Press.\nSearles, S. (2020, August\u00a04). Republican Tik Tok thinks \u201cRed Kingdom\u201d by Tech \nN9ne is their new hype song; We\u2019re laughing. The Pitch . https://www.thepitchkc.\ncom/republican-tik-tok-thinks-red-kingdom-by-tech-n9ne-is-their-new-hype-\nsong-were-laughing/.\nSchellewald, A. (2021). Communicative forms on TikTok: Perspectives from digital \nethnography. International Journal of Communication, 15 , pp.\u00a01437\u20131457.\nSmith Gale, S (2020, October\u00a06). U.S. election 2020: TikTok gets pulled into the \ncampaigns. BBC News . https://www.bbc.com/news/technology-54374710.\nTuters, M. and Hagen, S. (2020). (((They))) rule: Memetic antagonism and nebulous \nothering on 4chan. New Media & Society , 22(12), pp.\u00a02218\u20132237. https://doi.\norg/10.1177/1461444819888746.\nUrquhart, C. (2013, January\u00a012). Here comes the sun flash mob cheers Spanish \nunemployment office. The Guardian . https://www.theguardian.com/world/2013/\njan/12/here-comes-the-sun-spanish-unemployment-office.\nVijay, D. and Gekker, A. (2021). Playing politics: How Sabarimala played out \non TikTok. American Behavioral Scientist , 65(5), pp.\u00a0712\u2013734. https://doi.\norg/10.1177/0002764221989769.\nWardle, C. (2017, February\u00a016). Fake news. It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nZulli, D. and Zulli, D. J. (2020). Extending the internet meme: Conceptualizing \ntechnological mimesis and imitation publics on the TikTok platform. New Media \n& Society . https://doi.org/10.1177/1461444820983603.\n206  S \u00c1nc heZ -q uerub \u00cdn,  Wa ng , dic Ke y and  benede T Ti \nAbout the authors\nNatalia S\u00e1nchez-Querub\u00edn , PhD, is Assistant Professor at the University \nof Amsterdam. She works on digital media research and the intersection \nof social media with health stories and social issues.\nShuaishuai Wang , PhD, is Assistant Professor in the Department of Media \nand Communication at Xi\u2019an Jiaotong \u2013 Liverpool University. His research \nlies at the intersection of platform studies, critical algorithm studies and \ndigital culture.\nBriar Dickey  is a graduate of the Social and Cultural Science research \nmaster at Radboud University. His research takes an interdisciplinary, \nmixed methods approach to the examination of the far right, ontologies of \ngender, post-truth and identities online.\nAndrea Benedetti is a PhD student in Design at the Politecnico di Milano, \nItaly. He works in the field of data visualization, studying the relationship \nbetween data, interfaces, and society from a designerly standpoint in order \nto find alternative ways to design technological artifacts.\n A fterword: The misinformation \nproblem and the deplatforming \ndebates\nThe book arrives at the height of the \u201cdeplatforming\u201d debates, which among \nother matters concern the editorial power of social media platforms, with \nquestions about their authority and how they apply it in \u201carbitrating\u201d sources, \nspeech or truth. More specifically, the platforms\u2019 content moderation, as it \nis termed, includes warning, labeling, demoting as well as removing posts \nand users when they break platform rules. When a user is removed, it is \ncalled \u201cdeplatforming,\u201d but it may also refer to broader sanctioning such \nas suppression of content about multi-user movements such as QAnon, a \nwide-ranging conspiracy theory concerning the actions of operators inside \ngovernment. Facebook, in particular, has sought to ban QAnon content, \nremoving it from the platform.\nThe deplatforming debates also revolve around the extent to which the \nplatforms are doing too much or too little moderation. They concern whether \n(and when) it is justified as well as effective (and for whom). While the \nvolume authors do not address these questions directly, in the following I \nwould like to take up what we have found when studying the \u201cmisinforma -\ntion problem\u201d and the contributions we can make to the debates, however \nindirectly.\nIn all, I touch on five points where the misinformation problem relates to \nthe deplatforming discussion: the classification of problematic content (and \nits politics), platform privileging of certain content and users, the work put \ninto establishing editorial authority, the difference in content moderation per platform as well as the methodological challenges (and opportunities) in studying content and user removal. Each is taken in turn, whereupon I conclude with a modest proposal to re-orient the discussion.\nEspecially in the Facebook chapter but also in others, we have taken \na common approach to classifying sources as problematic or less so. The \napproach is both historicized as well as comparative. By historicized, I mean \nRogers. R. (ed.), The Propagation of Misinformation in Social Media: A Cross-platform Analysis . \nAmsterdam: Amsterdam University Press 2023\ndoi: 10.5117/9789463720762_after\n208  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nthat there has been an evolution in the definition and terminology of what \nwas incipiently referred to as \u201cfake news\u201d in 2016 by Craig Silverman of \nBuzzFeed News , when writing up his findings concerning the types of sources \nthat were performing well on Facebook in the run-up to the U.S. presidential \nelections (2016). When comparing engagement scores, or tallies of likes, \nshares and comments, he found that those from fly-by-night, imposter \nas well as \u201chyperpartisan\u201d sources received more engagement than those \nhe called mainstream. Subsequent scholarly work expanded the types of \nsources under study to \u201cproblematic information\u201d as well as \u201cjunk news,\u201d \nadding (for example) satire as well as \u201ccomputational propaganda\u201d which \nincludes amplification efforts such as fake followers and bot work (Jack, \n2017; Bolsover & Howard, 2018). Facebook but also certain journalists, for \ntheir part, then narrowed the classification of problematic content to \u201cfalse \nnews,\u201d focusing on hoaxes and imposter sources and removing from the \ndefinition the \u201chyperpartisan,\u201d originally referring to \u201copenly ideological \nweb operations\u201d (Herrman, 2016). Nowadays the term misinformation \n(which would include non-intentional falsehoods) is enjoying currency \nas an umbrella term. The evolution of the definitional led us to consider \na comparative perspective where we found that an ample classification \n(including hyperpartisan) would enlarge the misinformation problem and a \nnarrower definition (excluding hyperpartisan) would reduce its size, making \nit more ordinary. There is an accompanying political dimension, given that \nthe hyperpartisan sources (receiving the highest engagement) are often \nmore conservative in bent, at least at the time of writing. When classifying \nthem as fake, junk or problematic, the adjectives become sectarian markers, \nand any content moderation along those definitional lines seems to take \nsides and invites backlash.\nAs related particularly in the Twitter studies, the second observation \nconcerns which content as well as users are privileged by platforms. For some \ntime during our work, a New York Times journalist would tweet the most \nengaged-with sources on Facebook, pointing out how they disproportionately \nfavor hyperpartisan, conservative sources (Owen, 2021). A subsequent debate \nbetween the journalist and a Facebook representative took up whether \nthose sources were enjoying as much exposure as the engagement metric \nmight suggest, ultimately pointing to Facebook data in company transpar -\nency reports showing how the results of another metric\u2014reach\u2014indicate \notherwise. In fact, that data seemed to show that Facebook has a problem \nwith \u201cspammy, clickbait\u201d content, apart from that of the popularity of its \n\u201cright-wing pages\u201d (Warzel, 2021). The discussion points up the question \nof which users and content do well, metrically, both overall as well as per \nafTe r Wor d: The MiSi nfor MaTion  Pr oble M a nd Th e de Pl aTf or Mi ng deba TeS 209\nsocial media platform. It was at least partially answered in the expos\u00e9 of \nFacebook\u2019s privileging mechanisms, made possible by the former Facebook \nemployee, Frances Haugen, who presented news organizations with internal \ndocuments showing, among other things, that Facebook boosts posts which \nhave received \u201cangry\u201d reactions over those who have been merely \u201cliked.\u201d \nThus, one is able to score higher or have greater impact with posts that \nmake other users reply with anger. No similar whistle-blowing revelations \nhave been made of other platforms, but on Twitter, we made a finding \nakin to the New York Times journalist\u2019s. Hyperpartisan sources receive a \ndisproportionate amount of retweets, compared to other source types. Apart \nfrom the spammy or clickbait-like, driving engagement on major social media \nplatforms are source types variously characterized as \u201cmisinformation, \ntoxicity and low-quality news\u201d (Merrill and Oremus, 2021). As platforms \ncrack down on such content as misinformation and toxicity, it follows \nthat they are moderating popular material, which attracts attention to \nsuch moderation rather than keeping it out of sight, as was the case with \ncommercial content moderation from the beginning.\nPrior to the fake news crisis of 2016 and beyond, the critique made of \nsocial media content moderation concerned the kind of \u201csoul-crushing\u201d \nlabor behind it (Chen, 2014). Low-wage and outsourced, content moderation \nworkers did not enjoy the status (and benefits) of company employees \n(Roberts, 2016). They also worked at a rapid pace, monitored for their capacity \nto decide accurately which disturbing content should be deleted or ignored. \nIn our study we focus on the type of content that rises to the top when \nusers engage with posts concerning national elections and the COVID-19 \npandemic. Such material may intersect with the areas of conventional \ncontent moderation (such as violence and pornography) but are also moder -\nated, rather exceptionally, for misinformation. The labor still could be \ncalled content moderation by the companies, but given the partnerships \nmade with fact-checking organizations to undertake some of it, it more \nreadily would be called editorial (Perez, 2021). We discuss those social media \nplatforms and search engines specifically targeting misinformation around \nnational elections and the pandemic (including, in our study, Facebook, \nInstagram, Twitter, TikTok as well as Google Web Search) as employing \n\u201ceditorial epistemologies,\u201d curating lists of authoritative sources returned \nfor election- and pandemic-related queries and otherwise adjudicating \ncontent either automatically detected or flagged by users as problematic. \nIt is arguably novel editorial work undertaken by the platforms and opens \nthe questions of which other subject matters apart from elections and the \npandemic should also deserve scrutiny and which expertise is required. For \n210  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nexample, is climate change or another pressing social issue so deserving? \nThe shift in moderation culture would put the platforms on a footing where \nauthority for content demotion or deplatforming is achieved by editorial \nexpertise and delivered as fact checks.\nAs has been pointed out, all platforms perform content moderation, and \nit could be considered at the heart of a platform\u2019s business model (Gillespie, \n2018). The extent of its presence as well as its absence are objects of study, \ngiven how certain platforms have emerged known as \u201calt tech\u201d that explicitly \ntrade on low moderation or \u201cfree speech.\u201d They do not profess to the practice \nof deplatforming. For the platforms under study here, 4chan could be said to \noffer the least content moderation and Facebook (and Instagram) perhaps \nthe most. Whether the platform has high or low content moderation is \nworthy of study, but also of interest is which actors platforms privilege. \nOne could argue that platforms privilege their own \u201cperformers\u201d rather \nthan, say, news organizations. These performers may post hyperpartisan \ncontent, thereby making it more prominent on the platform. Indeed, as we \nreported in one of the Twitter chapters, mainstream news is marginalized \nnot through a lack of content moderation per se but rather by virtue of the \nabundance of hyperpartisan sources present in the posts that perform well \non the medium.\nFinally, there are methodological challenges in studying deplatform -\ning, and its connection to the misinformation problem, for the content is \nno longer available for scrutiny. It is also demanding to study demotion, \nespecially if one relies on engagement metrics to surface pertinent content \nfor study. Having been demoted, it is no longer ranked highly. One avenue \nis taken in the 4chan chapter, which ultimately deals with the extent to \nwhich an \u201calternative influence network\u201d is influential there. The researchers \nextracted the links from a 4chan board and examined the extent to which \nthey point to YouTube alt-influencers, especially on the right of the political \nspectrum. The approach may be called \u201cplatform perspectivism,\u201d whereby \none uses the data available on one platform to study another. The approach \npreviously was used to create a list of extreme YouTube videos linked from \n4chan in order to check whether they are still available on the video sharing \nplatform. Some had been deleted whereas others remained online, raising the \nquestion of the threshold for removal as well as the technique for identifica -\ntion. With respect to demotion, at the time of our study, TikTok introduced \ncontent removal or suppression policies which it later expanded to videos \nconcerning the war in Ukraine. While not explicitly undertaken in the TikTok \nstudy, its approach offers a means to study demotion. Continually archiving \nof the results of a query (as ranked video URL lists) and graphing their ranked \nafTe r Wor d: The MiSi nfor MaTion  Pr oble M a nd Th e de Pl aTf or Mi ng deba TeS 211\nplacement overtime would show whether there are any precipitous dips of \nsingle videos compared to the others in the list.\nIn conclusion, research on misinformation recalls debates about the qual -\nity of information on the internet more generally and content moderation \ndiscussions about approaches to make \u201crelevant\u201d sources rise to the top of \nsearch engine rankings (and what relevance means). The debates continued \nwith the shift in emphasis to the effects of personalization as a \u201csolution\u201d to the relevance problem. Personalization brought with it the atomization or individualization of media exposure. Individual feeds on social media, \noptimized for one\u2019s interests but also for one\u2019s trigger points (so to speak), are \nin a sense a further extension of personalization together with a more evident \naffective component, with the canonical example now being how Facebook \noptimizes for \u201cangry\u201d content or \u201cangertainment.\u201d When we find that social \nmedia, which dominates as an informational medium, is marginalizing the \nmainstream and mainstreaming the fringe, we are returning to the question \nof how to address the quality of information online but also how to handle \nthe affective dimension. These are somewhat different points of departure \nfrom the question of whether or when to deplatform misinformation, but \nthey could be re-introduced to guide the discussions.\nRichard Rogers\nAmsterdam, November\u00a02022\nReferences\nBolsover, G. and Howard, P. (2019). Chinese computational propaganda: Automation, \nalgorithms and the manipulation of information about Chinese politics on \nTwitter and Weibo. Information, Communication & Society , 22(14). https://doi.\norg/10.1080/1369118X.2018.1476576.\nChen, A. (2014, October\u00a023). The laborers who keep dick pics and beheadings out of \nyour Facebook feed. Wired . https://www.wired.com/2014/10/content-moderation/.\nGillespie, T. (2018). Custodians of the internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nHerrman, John (2016, August\u00a028). Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\n212  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nMerrill, J. B. and Oremus, W. (2021, October\u00a026). Five points for anger, one for \na \u201clike\u201d: How Facebook\u2019s formula fostered rage and misinformation. Wash -\nington Post . https://www.washingtonpost.com/technology/2021/10/26/\nfacebook-angry-emoji-algorithm/.\nOwen, L. H. (2021, July\u00a014). At first, Facebook was happy that I and other journalists \nwere finding its tool useful\u2026but the mood shifted. NiemanLab. https://www.\nniemanlab.org/2021/07/at-first-facebook-was-happy-that-i-and-other-journalists-\nwere-finding-its-tool-useful-but-the-mood-shifted/.\nPerez, S. (2021, August\u00a02). Twitter partners with AP and Reuters to address misinfor -\nmation on its platform. TechCrunch . https://techcrunch.com/2021/08/02/twitter-\npartners-with-ap-and-reuters-to-address-misinformation-on-its-platform/.\nRoberts, S. T. (2016). Commercial content moderation: Digital laborers\u2019 dirty work. \nIn S. U. Noble and B. Tynes (Eds.) The intersectional internet: Race, sex, class and \nculture online  (pp.\u00a0147\u2013160), Peter Lang.\nSilverman, C. (2016, November\u00a016) This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nWarzel, C. (2021, November\u00a011). Facebook\u2019s vast wasteland. The Atlantic Monthly . \nhttps://newsletters.theatlantic.com/galaxy-brain/618ad9942e822d00205a26b3/\nfacebooks-vast-wasteland/.\n Bibliography\nAchenbach, J. and Johnson, C. Y. (2020, April\u00a030). Studies leave question of \u201cair -\nborne\u201d coronavirus transmission unanswered. Washington Post . https://www.\nwashingtonpost.com/health/2020/04/29/studies-leave-question-airborne-\ncoronavirus-transmission-unanswered/.\nAdams, A. (2016, August\u00a025). SHOCKING: Joe Biden discusses the left\u2019s globalist \nagenda. https://www.youtube.com/watch?v=KaCBYrVsic4.\nAdams, A. (2020, November\u00a020). KRAKEN UNLEASHED: The press conference \nthey don\u2019t want you to see\u2026 https://www.youtube.com/watch?v=_u34jhCKT2U.\nAFP. (2021). AFP Factcheck Nederland, Agence France-Presse. https://factcheckned -\nerland.afp.com/list.\nAhmadi, A.A. and Chan, E. (2020). Online influencers have become powerful \nvectors in promoting false information and conspiracy theories. First Draft. \nhttps://firstdraftnews.org/latest/influencers-vectors-misinformation/.\nAlba, D. (2020, June\u00a01). Misinformation about George Floyd protests surges on social \nmedia.  New York Times. https://www.nytimes.com/2020/06/01/technology/\ngeorge-floyd-misinformation-online.html.\nAllcott, H., Gentzkow, M. and Yu, C. (2019). Trends in the diffusion of misinforma -\ntion on social media. Research & Politics , April\u2013June\u00a02019: 1\u20138.\u2028 https://doi.\norg/10.1177/2053168019848554.\nAllSides (2020). Media Bias Ratings. https://www.allsides.com/media-bias/\nmedia-bias-ratings#ratings.\nAlter, J. [jonathanalter]. (2021, Jan 01). \u201cIf we \u2018move on\u2019, the GOP will refuse to \nconcede future elections, then judge-shop until they steal one. There must be a \nprice paid for sedition or we will lose our democracy. This is critically important \nwork in the next couple of years\u201d [tweet]. https://twitter.com/jonathanalter/\nstatus/1345074521561292800.\nAmerican Military News (2016, May\u00a023). Article removed\u2014Here\u2019s why. American \nMilitary News , https://americanmilitarynews.com/2016/05/donald-trump-sent-\nhis-own-plane-to-transport-200-stranded-marines/.\nAnnany, M. (2018, April\u00a04). The partnership press: Lessons for platform-publisher \ncollaborations as Facebook and news outlets team to fight misinformation. Co -\nlumbia Journalism Review . https://www.cjr.org/tow_center_reports/partnership-\npress-facebook-news-outlets-team-fight-misinformation.php.\nAroesti, R. (2019, November\u00a01). Why are teenagers on TikTok obsessed with an eerie \n1950s song? The Guardian . https://www.theguardian.com/culture/2019/nov/01/\nwhy-are-teenagers-on-tiktok-obsessed-with-an-eerie-1950s-song.\n214  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nBail, C.A., Argyle, L.P., Brown, T.W., Bumpus, J.P., Chen, H., Hunzaker, M.B.F., \nLee, J., Mann, M., Merhout, F., and Volfovsky, A. (2018). Exposure to opposing \nviews on social media can increase political polarization. Proceedings of the \nNational Academy of Sciences , 115(37), pp.\u00a09216\u20139221. https://doi.org/10.1073/\npnas.1804840115.\nBarkun, M. (2016). Conspiracy theories as stigmatized knowledge. Diogenes , 62(3\u20134). \nhttps://doi.org/10.1177/0392192116669288.\nBarnidge, M. (2017). Exposure to political disagreement in social media versus \nface-to-face and anonymous online settings. Political Communication , 34(2), \npp.\u00a0302\u2013321. https://doi.org/10.1080/10584609.2016.1235639.\nBarnidge, M. and Peacock, C. (2019). A third wave of selective exposure research? \nThe challenges posed by hyperpartisan news on social media. Media and Com -\nmunication , 7(3), pp.\u00a04\u20137. https://doi.org/10.17645/mac.v7i3.2257.\nBartlett, J. and Krasodomski-Jones, A. (2015). Counter-speech: Examining content \nthat challenges extremism online. Demos. http://www.demos.co.uk/wp-content/\nuploads/2015/10/Counter-speech.pdf.\nBauman, Z. (2013). Does the richness of the few benefit us all? Polity.\nBengani, P. (2019, December\u00a018). Hundreds of \u201cpink slime\u201d local news outlets are \ndistributing algorithmic stories and conservative talking points. Tow Center \nfor Journalism, Columbia University. https://www.cjr.org/tow_center_reports/\nhundreds-of-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php.\nBenkler, Y. (2006). The wealth of networks: How social production transforms markets \nand freedom . Yale University Press.\nBenkler, Y., Faris, R. and Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . Oxford University Press.\nBenkler, Y., Faris, R., Roberts, H. and Zuckerman, E. (2017, March\u00a03). Study: Breitbart-\nled right-wing media ecosystem altered broader media agenda. Columbia Journal -\nism Review . https://www.cjr.org/analysis/breitbart-media-trump-harvard-study.\nphp.\nBeran, D. (2019). It came from something awful: How a toxic troll army accidentally \nmemed Donald Trump into office . St. Martin\u2019s Publishing Group.\nBerger, J. and Milkman, K. L. (2012). What makes online content viral? Journal of \nMarketing Research,  49(2), 192\u2013205. https://doi.org/10.1509/jmr.10.0353\nBernstein, J. (2015, July\u00a027). Behind the racist hashtag that is blowing up Twitter. \nBuzzFeed News . https://www.buzzfeednews.com/article/josephbernstein/\nbehind-the-racist-hashtag-some-donald-trump-fans-love.\nBernstein, J. (2017, October\u00a05). Here\u2019s how Breitbart and Milo smuggled Nazi and \nwhite nationalist ideas into the mainstream. BuzzFeed News . https://www.\nbib liogra Phy 215\nbuzzfeednews.com/article/josephbernstein/heres-how-breitbart-and-milo-\nsmuggled-white-nationalism.\nBernstein, M., Monroy-Hern\u00e1ndez, A., Harry, D., Andr\u00e9, P., Panovich, K., and \nVargas, G. (2011). 4chan and /b/: An analysis of anonymity and ephemerality \nin a large online community. Proceedings of the International AAAI Conference \non Web and Social Media , 5(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/\narticle/view/14134.\nBerry, J. and Sobieraj, S. (2014). The outrage industry . Oxford University Press.\nBlackburn, J. (2018, February\u00a016). How 4chan and The_Donald influence the fake \nnews ecosystem . FIC Observatory. https://observatoire-fic.com/en/how-4chan-\nand-the_donald-influence-the-fake-news-ecosystem-by-jeremy-blackburn-\nuniversity-of-alabama-at-birmingham/.\nBolsover, G. and Howard, P. (2019). Chinese computational propaganda: Automation, \nalgorithms and the manipulation of information about Chinese politics on \nTwitter and Weibo. Information, Communication & Society , 22(14).\nBoltanski, L. (1999). Distant suffering: Morality, media and politics. Cambridge \nUniversity Press.\nBond, S. (2021, March\u00a09) Instagram suggested posts to users. It served up COVID-19 \nfalsehoods, study finds. NPR. https://www.npr.org/2021/03/09/975032249/\ninstagram-suggested-posts-to-users-it-served-up-covid-19-falsehoods-study-\nfinds.\nBordia, P. and Difonzo, N. (2004). Problem solving in social interactions on the \ninternet: Rumor as social cognition. Social Psychology Quarterly , 67(1), pp.\u00a033\u201349. \nhttps://doi.org/10.1177/019027250406700105.\nBorra, E. and Rieder, B. (2014). Programmed method: Developing a toolset for \ncapturing and analyzing tweets. Aslib Journal of Information Management , \n66(3), pp.\u00a0262\u2013278. https://doi.org/10.1108/AJIM-09-2013-0094.\nBostrom, A., Joslyn, S., Pavia, R., Walker, A. H., Starbird, K., and Leschine, T. M. (2015). \nMethods for communicating the complexity and uncertainty of oil spill response \nactions and tradeoffs. Human and Ecological Risk Assessment: An International \nJournal , 21(3), pp.\u00a0631\u2013645. https://doi.org/10.1080/10807039.2014.947867.\nBounegru, L., Gray, J., Venturini, T. and Mauri, M. (2018). A field guide to \u201cfake news\u201d \nand other information disorders . Public Data Lab.\nBovet, A. and Makse, H.A. (2019). Influence of fake news in Twitter during the \n2016 U.S. presidential election. Nature Communications , 10(1), p.\u00a07. https://doi.\norg/10.1038/s41467-018-07761-2.\nBoxell, L., Gentzkow, M., and Shapiro, J. (2017). Is the internet causing political \npolarization? Evidence from demographics. National Bureau of Economic \nResearch. http://www.nber.org/papers/w23258.\n216  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nBoxell, L., Gentzkow, M., and Shapiro, J. M. (2020). Cross-country trends in affective \npolarization. National Bureau of Economic Research. https://www.nber.org/\npapers/w26669.\nBoyd, R. L., Spangher, A., Fourney, A., Nushi, B., Ranade, G., Pennebaker, J., and \nHorvitz, E. (2018). Characterizing the Internet Research Agency\u2019s social media \noperations during the 2016 U.S. presidential election using linguistic analyses  \n[Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/ajh2q.\nBozdag, E. and Van den Hoven, J. (2015). Breaking the filter bubble: Democracy and \ndesign. Ethics and Information Technology, 17 (4), 249\u201365. https://doi.org/10.1007/\ns10676-015-9380-y.\nBradshaw, S. and Howard, P. N. (2018). Challenging truth and trust: A global inven -\ntory of organized social media manipulation. Computational Propaganda \nResearch Project. Oxford Internet Institute. https://demtech.oii.ox.ac.uk/wp-\ncontent/uploads/sites/93/2018/07/ct2018.pdf.\nBruns, A. (2019). Are filter bubbles real? Polity Press.\nBruns, A. and Weller, K. (2016). Twitter as a first draft of the present: And the \nchallenges of preserving it for the future. In Proceedings of the 8th ACM \nConference on Web Science (WebSci\u201916)  (pp.\u00a0183\u2013189). ACM. https://doi.\norg/10.1145/2908131.2908174.\nBruns, A., Harrington, S. and Hurcombe, E. (2020) Corona? 5G? Or both?: The \ndynamics of COVID-19/5G conspiracy theories on Facebook. Media International \nAustralia , 177 (1). https://doi.org/10.1177/1329878X20946113.\nBurkhardt, J.M. (2017). Combating fake news in the digital age. ALA Library Technol -\nogy Reports , 53(8): pp.\u00a05\u20139. https://doi.org/10.5860/ltr.53n8.\nBurley, S. (2017). Disunite the right: The growing divides in the pepe coalition. \nPolitical Research Associates. https://www.politicalresearch.org/2017/09/19/\ndisunite-the-right-the-growing-divides-in-the-pepe-coalition.\nburrough, x. and Dufour, F. (2018). Creativity. In E. Navas, O. Gallagher, and x. \nburrough (Eds.) Keywords in remix studies (pp.\u00a092\u2013104). Routledge.\nBurton, A. and Koehorst, D. (2020). The spread of political misinformation on \nonline subcultural platforms. Harvard Kennedy School Misinformation Review , \n1(6). https://doi.org/10.37016/mr-2020-40.\nBuyukozturk, B., Gaulden, S. and Dowd-Arrow, B. (2018). Contestation on Reddit, \nGamergate, and movement barriers. Social Movement Studies , 17(5), pp.\u00a0592\u2013609. \nhttps://doi.org/10.1080/14742837.2018.1483227\nBuzzSumo. (2020). Buzzsumo media monitoring. https://buzzsumo.com.\nCallery, A. and Proulx, D.T. (1997) Yahoo! cataloging the web. Journal of Internet \nCataloging , 1(1). https://doi.org/10.1300/J141v01n01_06.\nbib liogra Phy 217\nCaplow, T. (1946). Rumors in war departmental contributions: Teaching and research \nin the social sciences. Social Forces , 25(3), pp.\u00a0298\u2013302. https://heinonline.org/\nHOL/P?h=hein.journals/josf25andi=314.\nCaptain, S. (2017, March\u00a08). Disqus grapples with hosting toxic comments on \nBreitbart and extreme-right sites. Fast Company . https://www.fastcompany.\ncom/3068698/disqus-grapples-with-hosting-toxic-comments-on-breitbart-\nand-extreme-right-sites.\nCaramanica, J. (2020, March\u00a020). This \u201cImagine\u201d cover is no heaven. New York \nTimes . https://www.nytimes.com/2020/03/20/arts/music/coronavirus-gal-gadot-\nimagine.html.\nCenter for Countering Hate (2021, March\u00a09) Malgorithm: How Instagram\u2019s al -\ngorithm publishes misinformation and hate to millions during a pandemic. \nhttps://252f2edd-1c8b-49f5-9bb2-cb57bb47e4ba.filesusr.com/ugd/f4d9b9_89e\nd644926aa4477a442b55afbeac00e.pdf.\nCenters for Disease Control and Prevention. (2020, April\u00a01). Healthcare professionals: \nFrequently asked questions and answers. Centers for Disease Control and \nPrevention. https://web.archive.org/web/20200401051025/https://www.cdc.gov/\ncoronavirus/2019-ncov/hcp/faq.html.\nCernovich, M. (2016, September\u00a014). Un/Convention: Exposing fake news at the RNC \nand DNC. YouTube video. https://www.youtube.com/watch?v=cNwgKR88UDo.\nChadwick, A. (2017). The hybrid media system: Politics and power. Oxford University \nPress.\nChen, A. (2014, October\u00a023). The laborers who keep dick pics and beheadings out of \nyour Facebook feed. Wired . https://www.wired.com/2014/10/content-moderation/.\nChu, J. and McDonald, J. (2020, January\u00a029). Helping the world find credible informa -\ntion about novel #coronavirus. Twitter Blog. https://blog.twitter.com/en_us/\ntopics/company/2020/authoritative-information-about-novel-coronavirus.\nColeman, E.G. (2014). Hacker, hoaxer, whistleblower, spy: The many faces of Anony -\nmous . Verso.\nColeman, K. (2021). Introducing Birdwatch, a community-based approach to mis -\ninformation. https://blog.twitter.com/en_us/topics/product/2021/introducing-\nbirdwatch-a-community-based-approach-to-misinformation.html.\nColley, T. and Moore, M. (2020). The challenges of studying 4chan and the \nAlt-Right: \u201cCome on in the water\u2019s fine.\u201d New Media & Society . ht tps://doi.\norg/10.1177/1461444820948803.\nColombo, G. and De Gaetano, C. (2020). Dutch political Instagram. Junk news, fol-\nlower ecologies and artificial amplification. In R. Rogers and S. Niederer (Eds.), The \npolitics of social media manipulation (pp.\u00a0147\u2013168). Amsterdam University Press.\n218  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nColquhoun, R. (2013, January\u00a013). Political art and activism: Flash mob. \nNational Collective. http://www.nationalcollective.com/2013/01/13/\npolitical-art-and-activism-flash-mob/.\nComscore (2019). Comscore March\u00a02019 top 50 multi-platform website properties \n(desktop and mobile). https://www.comscore.com/Insights/Rankings.\nConger, K. (2021). Twitter, in widening crackdown, removes over 70,000 QAnon \naccounts. New York Times . https://www.nytimes.com/2021/01/11/technology/\ntwitter-removes-70000-qanon-accounts.html.\nCooper, Sara (2020). How to medical, TikTok video. https://www.tiktok.com/@\nwhatchugotforme/video/6819061413877763334.\nCoppins, M. (2020, March). The billion-dollar disinformation campaign to reelect the \npresident. The Atlantic . https://www.theatlantic.com/magazine/archive/2020/03/\nthe-2020-disinformation-war/605530/.\nCourtois, C., Slechten, L., and Coenen, L. (2018). Challenging Google Search filter \nbubbles in social and political information: Disconforming evidence from a \ndigital methods case study. Telematics and Informatics , 35(7), pp.\u00a02006\u20132015. \nhttps://doi.org/10.1016/j.tele.2018.07.004.\nCrowley, M. (2020, February\u00a024) \u201cAmerica loves India,\u201d Trump declares at rally \nwith Modi. New York Times . https://www.nytimes.com/2020/02/24/world/asia/\ntrump-india.html.\nDailey, D. and Starbird, K. (2015). \u201cIt\u2019s raining dispersants\u201d: Collective sensemaking of \ncomplex information in crisis contexts. In Proceedings of the 18th ACM Conference \nCompanion on Computer Supported Cooperative Work and Social Computing , \npp.\u00a0155\u2013158. https://doi.org/10.1145/2685553.2698995.\nDan, O. and Davison, B. D. (2016). Measuring and predicting search engine users\u2019 sat -\nisfaction. ACM Computing Surveys , 49(1), pp.\u00a01\u201335. https://doi.org/10.1145/2893486.\nDaniels, J. (2018). The algorithmic rise of the \u201calt-right.\u201d Contexts , 17(1). ht tps://doi.\norg/10.1177/1536504218766547.\nDay, V. and Eagle, J. R. (2016). Cuckservative: How \u201cconservatives\u201d betrayed America . \nCastalia House.\nDe Keulenaar, E., Burton, A.G., and Kisjes, I. (2021). Deplatforming, demotion and \nfolk theories of Big Tech persecution. Fronteiras \u2013 Estudos Midi\u00e1ticos , 23(2), \npp.\u00a0118\u2013139. https://doi.org/10.4013/fem.2021.232.09.\nDe Zeeuw, D. and Tuters, M. (2020). Teh internet is serious business: On the deep \nvernacular web and its discontents. Cultural Politics , 16(2), pp.\u00a0214\u2013232. https://\ndoi.org/10.1215/17432197-8233406.\nDe Zeeuw, D., Hagen, S., Peeters, S., and Jokubauskaite, E. (2020). Tracing normiefica -\ntion. First Monday . https://doi.org/10.5210/fm.v25i11.10643.\nDeadville, J. (2015). The sound of media spectacle: Music at the party conventions. \nMusic & Politics, 9 (2), pp.\u00a01\u201324. https://doi.org/10.3998/mp.9460447.0009.205.\nbib liogra Phy 219\nDean, J. (1998). Aliens in America . Cornell University Press.\nDelli Carpini, M.X. (2018). Alternative facts: Donald Trump and the emergence of \na new U.S. media regime. In Z. Papacharissi and P. Boczkowski (Eds.), Trump \nand the media (pp.\u00a017\u201323). MIT Press.\nDiakopoulos, N., Trielli, D., Stark, J., and Mussenden, S. (2018). I Vote For\u2014How \nSearch Informs Our Choice of Candidate. In M. Moore and D. Tambini (Eds.), Digi -\ntal dominance: The power of Google, Amazon, Facebook and Apple (pp.\u00a0320\u2013341). \nOxford University Press.\nDigital Methods Initiative. (n.d.). Search Engine Scraper . https://wiki.digitalmethods.\nnet/Dmi/ToolSearchEngineScraper.\nDiResta, R., Shaffer, K., Ruppel, B., Sullivan, D., Matney, R., Fox, R., Albright, J. and \nJohnson, B. (2018). The tactics & tropes of the Internet Research Agency. New \nKnowledge. https://disinformationreport.blob.core.windows.net/disinformation-\nreport/NewKnowledge- Disinformation-Report-Whitepaper.pdf.\nDonovan, J. (2019). How memes got weaponized: A short history. MIT Tech -\nnology Review .  https://www.technologyreview.com/2019/10/24/132228/\npolitical-war-memes-disinformation/.\nDonovan, J. and boyd, d. (2018, June\u00a01). The case for quarantining extremist \nideas. The Guardian . http://www.theguardian.com/commentisfree/2018/jun/01/\nextremist-ideas-media-coverage-kkk.\nDPA. (2021). DPA fact-checking. Deutsche Presse-Agentur. https://dpa-factchecking.\ncom/netherlands/.\nDrawrowfly. (2021). TikTok scraper [software]. https://github.com/drawrowfly/\ntiktok-scraper.\nDubois, E. and Blank, G. (2018). The echo chamber is overstated: The moderating \neffect of political interest and diverse media. Information, Communication & \nSociety  21 (5): 729\u2013745. https://doi.org/10.1080/1369118X.2018.1428656.\nDwoskin, E. (2020, November\u00a012). Trump\u2019s attacks on election outcome prolong \ntech\u2019s emergency measures. Washington Post . https://www.washingtonpost.\ncom/technology/2020/11/12/facebook-ad-ban-lame-duck/.\nEconomist . (2019, June\u00a08). Google rewards reputable reporting, not left-wing \npolitics. The Economist . https://www.economist.com/graphic-detail/2019/06/08/\ngoogle-rewards-reputable-reporting-not-left-wing-politics.\nEinwiller, S.A. and Kim, S. (2020). How online content providers moderate user-\ngenerated content to prevent harmful online communication: An analysis of \npolicies and their implementation. Policy & Internet , 12(2), pp.\u00a0184\u2013206. https://\ndoi.org/10.1002/poi3.239.\nEllefson, L. (2019, August\u00a07). Breitbart\u2019s audience has dropped 72% since Trump \ntook office\u2014As other right-wing sites have gained. The Wrap . https://www.\nthewrap.com/breitbart-news-audience-dropped-steve-bannon-72-percent/.\n220  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nEllis, E.G. (2019, September\u00a010). Fighting Instagram\u2019s $1.3 billion problem\u2014Fake \nfollowers. Wired . https://www.wired.com/story/instagram-fake-followers/.\nEnli, G. (2017). Twitter as arena for the authentic outsider: Exploring the social \nmedia campaigns of Trump and Clinton in the 2016 U.S. presidential elec -\ntion. E uropean Journal of Communication , 32(1), pp.\u00a050\u201361. https://doi.\norg/10.1177/0267323116682802.\nEvan, D. (2017, May\u00a026). Did Pope Francis slap away President Trump\u2019s hand? \nSnopes . https://www.snopes.com/fact-check/pope-francis-trump-hand-slap/.\nFacebook (2018, December\u00a06). Coordinated inauthentic behavior. Facebook News -\nroom. https://about.fb.com/news/2018/12/inside-feed-coordinated-inauthentic-\nbehavior/.\nFacebook (2021a, February\u00a09). January\u00a02021 coordinated inauthentic be -\nhavior report. Facebook Newsroom. https://about.fb.com/news/2021/02/\njanuary-2021-coordinated-inauthentic-behavior-report/.\nFacebook (2021b, May\u00a025). False news, Facebook Transparency Center. https://\ntransparency.fb.com/policies/community-standards/false-news/.\nFeldman, B. (2017, June\u00a08). In Russia, you can buy Instagram likes from a vending \nmachine. New York Times Magazine , June\u00a08. https://nymag.com/intelligenc -\ner/2017/06/you-can-buy-instagram-likes-from-a-russian-vending-machine.html.\nFiorentini, I. (2013). \u201cZOMG! Dis is a new language\u201d: The case of lolspeak. Newcastle \nWorking Papers in Linguistics , 13(1), pp.\u00a090\u2013108.\nFishkin, R. (2018). SparkToro\u2019s new tool to uncover real vs. fake followers on Twitter, \nSparkToro. https://sparktoro.com/blog/sparktoros-new-tool-to-uncover-real-\nvs-fake-followers-on-twitter/.\nFloridi, L. (2021). Trump, Parler, and regulating the infosphere as our commons. \nPhilosophy & Technology , 34(1), pp.\u00a01\u20135. https://doi.org/10.1007/s13347-021-00446-7.\nGadde, V. and Roth, Y. (2018, October\u00a017). Enabling further research of information \noperations on Twitter. Twitter Blog. https://blog.twitter.com/en_us/topics/\ncompany/2018/enabling-further-research-of-information-operations-on-twitter.\nhtml.\nGagliardone, I. (2019). Defining online hate and its \u201cpublic lives\u201d: What is the place \nfor \u201cextreme speech\u201d? International Journal of Communication , 13. ht tps://doi.\norg/1932\u20138036/20190005.\nGallucci, N. (2016, November\u00a022). 8 ways to consume news without using Facebook. \nMashable . https://mashable.com/2016/11/22/consume-news-without-facebook/.\nGeboers, M. (2019). \u201cWriting\u201d oneself into tragedy: Visual user practices and \nspectatorship of the Alan Kurdi images on Instagram. Visual Communication . \nhttps://doi.org/10.1177/1470357219857118.\nGekker, A. (2019). Playing with power: Casual politicking as a new frame for political \nanalysis. In R. Glas, S. Lammes, M. de Lange, J. Raessens, and I. de Vries (Eds.) \nbib liogra Phy 221\nThe playful citizen: Civic engagement in a mediatized culture (pp.\u00a0387\u2013419). \nAmsterdam University Press.\nGibbs, S. (2016, December\u00a05). Google alters search autocomplete to remove \u201care Jews \nevil\u201d suggestion. The Guardian . https://www.theguardian.com/technology/2016/\ndec/05/google-alters-search-autocomplete-remove-are-jews-evil-suggestion.\nGillespie, E. (2020, September\u00a030). \u201cPastel QAnon\u201d: The female lifestyle bloggers \nand influencers spreading conspiracy theories through Instagram. The Feed . \nhttps://www.sbs.com.au/news/the-feed/pastel-qanon-the-female-lifestyle-\nbloggers-and-influencers-spreading-conspiracy-theories-through-instagram.\nGillespie, T. (2018). Custodians of the internet: Platforms, content moderation, and \nthe hidden decisions that shape social media . Yale University Press.\nGillespie, T. (2020). Content moderation, AI, and the question of scale. Big Data & \nSociety , July\u2013December: 1\u20135, https://doi.org/10.1177/2053951720943234.\nGoforth, C. (2021, January\u00a021). Notorious pro-Trump forum rebrands as \u201cpatriots\u201d \nafter post-Capitol riot infighting. The Daily Dot . https://www.dailydot.com/\ndebug/pro-trump-site-renamed-internal-conflict/.\nGolebiewski, M. and boyd, d. (2019). Data voids: Where missing data can easily be \nexploited. Data & Society Research Institute. https://datasociety.net/wp-content/\nuploads/2019/11/Data-Voids-2.0-Final.pdf.\nGoogle. (2019a). How Google Fights Misinformation. Google Blog. https://www.\nblog.google/documents/37/How_Google_Fights_Disinformation.pdf.\nGoogle. (2019b). Search Quality Evaluator Guidelines. https://static.googleusercontent.\ncom/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf.\nGray, J., Bounegru, L., and Venturini, T. (2020). \u201cFake news\u201d as infrastructural uncanny. \nNew Media & Society , 22(2), pp.\u00a0317\u2013341. https://doi.org/10.1177/1461444819856912.\nGreen, J. (2017). Devil\u2019s bargain: Steve Bannon, Donald Trump, and the nationalist \nuprising . Penguin.\nGroshek, J. and Koc-Michalska, K. (2017). Helping populism win? Social media use, \nfilter bubbles, and support for populist presidential candidates in the 2016 U.S. \nElection Campaign. Information, Communication & Society, 20 (9), 1389\u2013407. \nhttps://doi.org/10.1080/1369118X.2017.1329334.\nGuess, A., Nyhan, B., and Reifler, J. (2018). Selective exposure to misinformation: \nEvidence from the consumption of fake news during the 2016 U.S. presidential \ncampaign [Working paper]. http://www.dartmouth.edu/~nyhan/fake-news-2016.pdf.\nHagen, S. and Jokubauskaite, E. (2019). Dutch junk news on 4chan and Reddit /\npol/. In R. Rogers and S. Niederer (Eds.), The politics of social media manipulation \n(pp.\u00a0115\u2013151). Dutch Ministry of the Interior and Kingdom Relations.\nHagen, S., Burton, A., Wilson, J., and Tuters, M. (2019, September\u00a08). Infinity\u2019s Abyss: \nAn Overview of 8chan. OILab . https://oilab.eu/infinitys-abyss-an-overview-\nof-8chan/.\n222  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nHaim, M., Graefe, A., and Brosius, H.-B. (2018). Burst of the filter bubble?: Effects \nof personalization on the diversity of Google News. Digital Journalism , 6(3), \npp.\u00a0330\u2013343. https://doi.org/10.1080/21670811.2017.1338145.\nHarris, S. (2019, February\u00a05). #148 \u2013 Jack Dorsey. Sam Harris Podcast. https://\nsamharris.org/podcasts/148-jack-dorsey/.\nHassell, H. J. G., Holbein, J. B., and Miles, M. R. (2020). There is no liberal media bias \nin which news stories political journalists choose to cover. Science Advances , \n6(14), eaay9344. https://doi.org/10.1126/sciadv.aay9344.\nHautea, S., Parks, P., Takahashi, B., and Zeng, J. (2021). Showing they care (or don\u2019t): \nAffective publics and ambivalent climate activism on TikTok. Social Media+ \nSociety . https://doi.org/10.1177/20563051211012344.\nHawley, G. (2017). Making sense of the alt-right . Columbia University Press.\nHedrick, A., Karpf, D., and Kreiss, D. (2018). The earnest internet vs. the ambivalent \ninternet. International Journal Of Communication, 12 (8). https://ijoc.org/index.\nphp/ijoc/article/view/8736/.\nHerring, S. (2012). Special internet language varieties: Culture, creativity & language \nchange [Paper]. The II LETiSS Workshop Language Go Web: Standard and \nNonstandard Languages on the Internet, Pavia.\nHerrman, John (2016, August\u00a028) Inside Facebook\u2019s (totally insane, unintentionally \ngigantic, hyperpartisan) political-media machine. New York Times . ht tps://\nwww.nytimes.com/2016/08/28/magazine/inside-facebooks-totally-insane-\nunintentionally-gigantic-hyperpartisan-political-media-machine.html.\nHeuts, F. and Mol, A. (2013). What is a good tomato? A case of valuing in practice. \nValuation Studies , 1(2), pp.\u00a0125\u2013146. https://doi.org/10.3384/vs.2001-5992.1312125.\nHighfield, T. and Leaver, T. (2016). Instagrammatics and digital methods: Studying \nvisual social media, from selfies and GIFs to memes and emoji. Communication \nResearch and Practice , 2(1), pp.\u00a047\u201362. https://doi.org/10.1080/22041451.2016.1155332.\nHine, G., Onaolapo, J., Cristofaro, E. D., Kourtellis, N., Leontiadis, I., Samaras, R., \nStringhini, G., and Blackburn, J. (2017). Kek, cucks, and God emperor Trump: \nA measurement study of 4chan\u2019s politically incorrect forum and its effects on \nthe web. In Proceedings of the International AAAI Conference on Web and Social \nMedia , 11(1), Article\u00a01. https://ojs.aaai.org/index.php/ICWSM/article/view/14893.\nHines, N. (2018, April\u00a022). Alex Jones\u2019 proteg\u00e9, Paul Joseph Watson, is about to \nsteal his crackpot crown. The Daily Beast . https://www.thedailybeast.com/\nalex-jones-protege-paul-joseph-watson-is-about-to-steal-his-crackpot-crown.\nHolt, K., Figenschou, T.U. and Frischlich, L. (2019). Key dimensions of alternative \nnews media. Digital Journalism , 7(7), pp.\u00a0860\u2013869. https://doi.org/10.1080/2167\n0811.2019.1625715.\nHoward, P. (2020). Lie machines . Yale University Press.\nbib liogra Phy 223\nHoward, P. N., Bolsover, G., Kollyani, B., Bradshaw, S., and Neudert, L.-M. (2017). \nJunk news and bots during the U.S. election: What were Michigan voters sharing \nover Twitter?  Data Memo 2017.1, Project on Computational Propaganda, Oxford \nInternet Institute. http://blogs.oii.ox.ac.uk/politicalbots/wp- content/uploads/\nsites/89/2017/03/What-Were-Michigan-Voters-Sharing-Over-Twitter-v2.pdf.\nHoward, P. N., Ganesh, B., Liotsiou, D., Kelly, J., and Fran \u00e7o is, C. (2018). The IRA, \nsocial media and political polarization in the United States, 2012\u20132018, Report, \nComputational Propaganda Research Project, Oxford Internet Institute. https://\ncomprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2018/12/The-IRA-Social-\nMedia-and-Political-Polarization.pdf.\nHypeAuditor. (2020). Instagram reports. https://hypeauditor.com/reports/\ninstagram/.\nIati, M., Kornfield, M., O\u2019Grady, S., and Mellen, R. (2020, May\u00a04). Trump says it\u2019s \nsafe to reopen states, while Birx finds protesters with no masks or distancing \n\u201cdevastatingly worrisome.\u201d Washington Post . https://www.washingtonpost.com/\nworld/2020/05/03/coronavirus-latest-news/.\nIf Americans Knew. (2017, February\u00a03). Senator Schumer says God made him a \nguardian of Israel. YouTube video. https://web.archive.org/web/20210417224317/\nhttps://www.youtube.com/c/IfAmericansKnew-Video/about. Accessed August\u00a02, \n2020.\nIngram, D. and Collins, B. (2020, June\u00a029). Reddit bans hundreds of subreddits for \nhate speech including Trump community. NBC News . https://www.nbcnews.\ncom/tech/tech-news/reddit-bans-hundreds-subreddits-hate-speech-including-\ntrump-community-n1232408.\nInstagram (n.d.). What are the requirements to apply for a verified badge on \nInstagram? Instagram Help Center. https://help.instagram.com/312685272613322.\nInstagram. (2018). Reducing inauthentic activity on Instagram. Instagram Blog. \nhttps://about.instagram.com/blog/announcements/reducing-inauthentic-\nactivity-on-instagram.\nInstagram. (2020). Introducing new authenticity measures on Instagram. \nInstagram Blog. https://about.instagram.com/blog/announcements/\nintroducing-new-authenticity-measures-on-instagram.\nInternet Archive. (2021). Internet archive: Digital library of free & borrowable \nbooks, movies, music & Wayback Machine [Web-based]. Internet Archive. \nhttps://archive.org/.\nIntrona, L. and Wood, D. (2004). Picturing algorithmic surveillance: The politics of \nfacial recognition systems. Surveillance & Society , 2(2/3), pp.\u00a0177\u2013198.\nJack, C. (2017). Lexicon of lies: Terms for problematic information. Data & Society \nResearch Institute. https://datasociety.net/library/lexicon-of-lies/.\n224  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nJansen, B.J. and Spink, A. (2006). How are we searching the World Wide Web? A \ncomparison of nine search engine transaction logs. Information Processing & \nManagement , 42(1), pp.\u00a0248\u2013263. https://doi.org/10.1016/j.ipm.2004.10.007.\nJenkins, H. (2006). Convergence culture: Where old and new media collide . New \nYork University Press.\nJenkins, H. (2017, May\u00a030). The ambivalent internet: An interview with Whitney \nPhillips and Ryan M. Milner (Part One). Confessions of an ACA-fan Blog. http://\nhenryjenkins.org/blog/2017/05/the-ambivalent-internet-an-interview-with-\nwhitney-phillips-and-ryan-m-milner-part-one.html.\nJett, J. (2021, February\u00a011). Robert F. Kennedy, Jr. is barred from Instagram over false \ncoronavirus claims. New York Times . https://www.nytimes.com/2021/02/11/us/\nrobert-f-kennedy-jr-instagram-covid-vaccine.html.\nJohn, N.A. (2019). Social media bullshit: What we don\u2019t know about facebook.com/\npeace and why we should care. Social Media + Society , January-March: 1\u201316. \nhttps://doi.org/10.1177/2056305119829863.\nJokubauskait\u0117, E. and Peeters, S. (2020). Generally curious: Thematically distinct \ndatasets of general threads on 4chan/pol/. Proceedings of the International AAAI \nConference on Web and Social Media , 14, pp.\u00a0863\u2013867.\nKaplan Sommer, A. (2017, October\u00a019). White nationalist Richard Spencer gives \nIsrael as example of ethno-state he wants in U.S. Haaretz . https://www.haaretz.\ncom/us-news/richard-spencer-gives-israel-as-example-of-ethno-state-he-wants-\nin-u-s-1.5459154.\nKarpf, D. Digital politics after Trump. Annals of the International Communication \nAssociation , 41(2), pp.\u00a0198\u2013207. https://doi.org/10.1080/23808985.2017.1316675.\nKelemen, M. (2005). Managing quality: Managerial and critical perspectives . Sage. \nhttps://doi.org/10.4135/9781446220382.\nKist, R. and Zantingh, P. (2017, March\u00a06). Geen grote rol nepnieuws in aanloop \nnaar verkiezingen. NRC Handelsblad . https://www.nrc.nl/nieuws/2017/03/06/\nfake-news-nee-zo-erg-is-het-hier-niet-7144615-a1549050.\nKlayman, A. (2019). The Brink [Feature documentary; Digital film]. https://ali -\nsonklayman.com/the-brink.\nKlein, E. and Robison, J. (2020). Like, post, and distrust? How social media use \naffects trust. Political Communication , 37(1), pp.\u00a046\u201364. https://doi.org/10.1080\n/10584609.2019.1661891.\nKnuttila, L. (2011). User unknown: 4chan, anonymity and contingency. First Monday . \nhttps://doi.org/10.5210/fm.v16i10.3665.\nKomok, A. (2018). How to check Instagram account for fake followers. HypeAuditor. htt -\nps://hypeauditor.com/blog/how-to-check-instagram-account-for-fake-followers/.\nKomok, A. (2020). What are suspicious accounts? HypeAuditor . https://help.\nhypeauditor.com/en/articles/2221742-what-are-suspicious-accounts.\nbib liogra Phy 225\n  Konrad, C. (2021, January\u00a028). Trump presidency permanently alters landscape of \nmedia. The Maneater . https://themaneater.com/trump-presidency-permanently-\nalters-landscape-of-media/.\nKou, Y., Gui, X., Chen, Y., and Pine, K. (2017). Conspiracy talk on social media: \nCollective sensemaking during a public health crisis. In Proceedings of the \nACM on Human-Computer Interaction , 1(CSCW), article no.\u00a061. https://doi.\norg/10.1145/3134696.\nKrafft, P., Zhou, K., Edwards, I., Starbird, K., and Spiro, E.S. (2017). Centralized, \nparallel, and distributed information processing during collective sensemaking. \nIn Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , \npp.\u00a02976\u20132987. https://doi.org/10.1145/3025453.3026012.\nKwak, H., Lee, C., Park, H. and Moon, S. (2010). What is Twitter, a social network or \na news media? In Proceedings of the 19th International Conference on World \nWide Web (pp.\u00a0591\u2013600). ACM.\nLangville, A.N. and Meyer, C.D. (2006). Google\u2019s PageRank and beyond: The science \nof search engine rankings . Princeton University Press.\nLazer, D. M., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, \nF., \u2026 and Schudson, M. (2018). The science of fake news. Science, 359 (6380), \npp.\u00a01094\u20131096. https://doi.org/10.1126/science.aao2998.\nLee, J.C. and Quealy, K. (2019, May\u00a024). The 598 people, places and things Donald \nTrump has insulted on Twitter: A complete list. New York Times . https://www.\nnytimes.com/interactive/2016/01/28/upshot/donald-trump-twitter-insults.html.\nLee, L. and Oppong, F. (2020, September\u00a01). Adding more context to Trends. Twitter Blog. \nhttps://blog.twitter.com/en_us/topics/product/2020/adding-more-context-to-trends.\nLenzen, C. (2020, November\u00a09). This Luke Bryan song is an anti-Trump anthem on Tik -\nTok. The Daily Dot . https://www.dailydot.com/irl/luke-bryan-anti-trump-tiktok/.\nLerman, R. (2021, February\u00a024). Major Trump backer Rebekah Mercer orchestrates \nParler\u2019s second act. Washington Post . https://www.washingtonpost.com/\ntechnology/2021/02/24/parler-relaunch-rebekah-mercer/.\nLewis, D. (2020). Is the coronavirus airborne? Experts can\u2019t agree. Nature , 580(7802), \np.\u00a0175. https://doi.org/10.1038/d41586-020-00974-w.\nLewis, R. (2018). Alternative influence: Broadcasting the reactionary right on \nYouTube.  Data & Society Research Institute. https://datasociety.net/library/\nalternative-influence/.\nLewis, R. (2020). \u201cThis is what the news won\u2019t show you\u201d: YouTube creators and the \nreactionary politics of micro-celebrity. Television & New Media , 21(2), pp.\u00a0201\u2013217. \nhttps://doi.org/10.1177/1527476419879919.\nLindquist, J. (2019). Illicit economies of the internet. Made in China Journal , 3(4), \npp.\u00a088\u201391. https://madeinchinajournal.com/2019/01/12/illicit-economies-of-the-\ninternet-click-farming-in-indonesia-and-beyond/.\n226  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nLobinger, K., Kr\u00e4mer, B., Venema, R., and Benecchi, E. (2020). Pepe\u2014Just a funny \nfrog? A visual meme caught between innocent humor, far-right ideology, and \nfandom. In B. Kr\u00e4mer and C. Holtz-Bacha (Eds.), Perspectives on populism and \nthe media  (pp.\u00a0333\u2013352). Nomos. https://doi.org/10.5771/9783845297392-333.\nLorenz. T. (2019, March\u00a021) Instagram is the internet\u2019s new home for hate. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2019/03/\ninstagram-is-the-internets-new-home-for-hate/585382/.\nLorenz, T. (2020, November\u00a04). Election night on TikTok: Anxiety, analysis and \nwishful thinking. New York Times . https://www.nytimes.com/2020/11/04/style/\ntiktok-election-night.html.\nLubbers, E. (2016, November\u00a05). There is no such thing as the Denver Guardian, \ndespite that Facebook post you saw. The Denver Post . https://www.denverpost.\ncom/2016/11/05/there-is-no-such-thing-as-the-denver-guardian/.\nLudemann, D. (2018). /pol/emics: Ambiguity, scales, and digital discourse on \n4chan. Discourse, Context & Media , 24, pp.\u00a092\u201398. https://doi.org/10.1016/j.\ndcm.2018.01.010.\nLyons, K. (2020, October\u00a011). Twitter flags, limits sharing on Trump tweet about being \u201cim -\nmune\u201d to coronavirus. The Verge . https://www.theverge.com/2020/10/11/21511682/\ntwitter-disables-sharing-trump-tweet-coronavirus-misinformation.\nMahendran, L. and Alsherif, N. (2020, January\u00a08) Adding clarity to our Com -\nmunity Guidelines. TikTok newsroom. https://newsroom.tiktok.com/en-us/\nadding-clarity-to-our-community-guidelines.\nMalone, C. (2016, August\u00a018). Trump made Breitbart great again. FiveThirtyEight . \nhttps://fivethirtyeight.com/features/trump-made-breitbart-great-again/.\nMandavilli, A. (2020, July\u00a04). 239 experts with one big claim: The coronavirus is \nairborne. New York Times . https://www.nytimes.com/2020/07/04/health/239-\nexperts-with-one-big-claim-the-coronavirus-is-airborne.html.\nMaragkou, E. (2020, December\u00a08). The conspiracy theorist as influencer. Insti -\ntute of Network Cultures Blog. https://networkcultures.org/blog/2020/12/08/\nthe-conspiracy-theorist-as-influencer/.\nMarres, N. (2018). Why we can\u2019t have our facts back. Engaging Science, Technology, \nand Society, 4 , pp.\u00a0423\u2013443. https://doi.org/10.17351/ests2018.188.\nMassanari, A. (2017). #Gamergate and the fappening: How Reddit\u2019s algorithm, \ngovernance, and culture support toxic technocultures. New Media & Society , \n19(3), pp.\u00a0329\u2013346. https://doi.org/10.1177/1461444815608807.\nMcIntosh, J. (2012). A history of subversive remix video before YouTube: Thirty \npolitical video mashups made between World War II and 2005. Transformative \nWorks and Cultures, 9 . https://doi.org/10.3983/twc.2012.0371.\nMcNeal, S. and Broderick, R. (2020, April\u00a04). Lifestyle influencers are now sharing \nsome bogus far-right conspiracy theories about the coronavirus on Instagram. \nbib liogra Phy 227\nBuzzfeed News . https://www.buzzfeednews.com/article/stephaniemcneal/\ncoronavirus-lifestyle-influencers-sharing-conspiracy-qanon.\nMcWhirter, A. (2015). Film criticism, film scholarship and the video essay. Screen, \n56(3), pp.\u00a0369\u2013377. https://doi.org/10.1093/screen/hjv044.\nMedia Bias/Fact Check. (2020). Filtered search. https://mediabiasfactcheck.com.\nMedia Bias/Fact Check. (2021). Breitbart. https://mediabiasfactcheck.com/breitbart/.\nMedina Serrano, J.C., Papakyriakopoulos., O. and Hegelich S. (2020). Dancing to \nthe partisan beat: A first analysis of political communication on TikTok. In \nProceedings of the 12th ACM Conference on Web Science, pp.\u00a0257\u2013266. https://\ndoi.org/10.1145/3394231.3397916.\nMeier, F., Elsweiler, D., and Wilson, M.L. (2014). More than liking and bookmark -\ning? Towards understanding Twitter favouriting behaviour. In Proceedings of \nICWSM\u201914 . AAAI Press. http://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/\npaper/view/8094.\nMerrill, J. B. and Oremus, W. (2021, October\u00a026). Five points for anger, one for \na \u201clike\u201d: How Facebook\u2019s formula fostered rage and misinformation. Wash -\nington Post . https://www.washingtonpost.com/technology/2021/10/26/\nfacebook-angry-emoji-algorithm/.\nMosseri, A. (2017, April\u00a06). Working to stop misinformation and false news. Facebook \nNewsroom. https://about.fb.com/news/2017/04/working-to-stop-misinformation-\nand-false-news/.\nNagle, A. (2017). Kill all normies: Online culture wars from 4chan and Tumblr to \nTrump and the alt-right . Zero Books.\nNewsGuard (2020). NewsGuard nutrition label. https://www.newsguardtech.com.\nNiederer, S. (2019). Networked content analysis: The case of climate change. \nInstitute of Network Cultures. https://networkcultures.org/blog/publication/\ntod32-networked-content-analysis-the-case-of-climate-change/\nNissenbaum, A. and Shifman, L. (2017). Internet memes as contested cultural \ncapital: The case of 4chan\u2019s /b/ board. New Media & Society , 19(4), pp.\u00a0483\u2013501. \nhttps://doi.org/10.1177/1461444815609313.\nNoble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism . \nNew York University Press.\nNunes, M. (2018). Parody. In E. Navas, O. Gallagher, and x. burrough (Eds.) Keywords \nin remix studies (pp.\u00a0217\u2013229). Routledge.\nO\u2019Hara, K. and Stevens, D. (2015). Echo chambers and online radicalism: Assessing \nthe internet\u2019s complicity in violent extremism. Policy & Internet, 7(4), pp.\u00a0401\u2013422. \nhttps://doi.org/10.1002/poi3.88.\nO\u2019Leary, N. (2020, March\u00a010). How Dutch false sense of security helped corona -\nvirus spread. Irish Times . https://www.irishtimes.com/news/world/europe/\nhow-dutch-false-sense-of-security-helped-coronavirus-spread-1.4199027.\n228  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nOh, D. (2019). Review of The ambivalent internet: mischief, oddity, and antagonism \nonline. Information, Communication & Society , 22(8), pp.\u00a01189\u20131191. https://doi.\norg/10.1080/1369118X.2019.1606267.\nOlmsted, K. (2009) Real enemies: Conspiracy theories and American democracy, \nWorld War I to 9/11 . Oxford University Press.\nOtero, V. (2017). The chart, version 3.1, ad fontes media. https://www.adfontesmedia.\ncom/the-chart-version-3-0-what-exactly-are-we-reading/.\nOwen, L. H. (2021, July\u00a014) At first, Facebook was happy that I and other journalists \nwere finding its tool useful\u2026but the mood shifted. NiemanLab. https://www.\nniemanlab.org/2021/07/at-first-facebook-was-happy-that-i-and-other-journalists-\nwere-finding-its-tool-useful-but-the-mood-shifted/.\nPapasavva, A., Zannettou, S., Cristofaro, E. D., Stringhini, G., and Blackburn, J. \n(2020). Raiders of the lost kek: 3.5 years of augmented 4chan posts from the \npolitically incorrect board. Proceedings of the International AAAI Conference \non Web and Social Media , 14, pp.\u00a0885\u2013894.\nPardes, A. (2020, October\u00a022). The TikTok teens trying to meme the vote. Wired . \nhttps://www.wired.com/story/tiktok-election-2020/.\nPariser, E. (2011). The filter bubble: What the internet is hiding from you . Penguin.\nParks, L. (2019). Dirty data: Content moderation, regulatory outsourcing and The \nCleaners. Film Quarterly , 73(1). https://doi.org/10.1525/fq.2019.73.1.11.\nPeacock, C., Hoewe, J., Panek, E., and Willis, G. P. (2019). Hyperpartisan news use: \nRelationships with partisanship, traditional news use, and cognitive and affec -\ntive involvement. Paper presented at the Annual Conference of the International \nCommunication Association, Washington, DC.\nPeeters, S. (2020, May\u00a015). Normiefication of extreme speech and the wid -\nening of the Overton window. Open Intelligence Lab. https://oilab.eu/\nnormiefication-of-extreme-speech-and-the-widening-of-the-overton-window/.\nPeeters, S. and Hagen, S. (2018). 4CAT: 4chan Capture and Analysis Toolkit [soft -\nware]. https://4cat.oilab.eu.\nPeeters, S. and Hagen, S. (2021). The 4CAT Capture and Analysis Toolkit: A Modular \nTool for Transparent and Traceable Social Media Research (SSRN Scholarly Paper \nID 3914892). Social Science Research Network. https://doi.org/10.2139/ssrn.3914892.\nPeeters, S., Tuters, M., Willaert, T., and de Zeeuw, D. (2021). On the vernacular \nlanguage games of an antagonistic online subculture. Frontiers in Big Data , \n4(65). https://doi.org/10.3389/fdata.2021.718368.\nPepp, J., Michaelson, E. and Sterken, R. (2019). Why we should keep talking about \nfake news. Inquiry . https://doi.org/10.1080/0020174X.2019.1685231.\nPerez, S. (2021, August\u00a02). Twitter partners with AP and Reuters to address misinfor -\nmation on its platform. TechCrunch . https://techcrunch.com/2021/08/02/twitter-\npartners-with-ap-and-reuters-to-address-misinformation-on-its-platform/.\nbib liogra Phy 229\nPeterson, J. (2016, November\u00a08). Jordan Peterson: The right to be politically incorrect. \nNational Post. https://nationalpost.com/opinion/jordan-peterson-the-right-to-\nbe-politically-incorrect.\nPhillips, W. (2015). This is why we can\u2019t have nice things: Mapping the relationship \nbetween online trolling and mainstream culture. MIT Press.\nPhillips, W. (2018). The oxygen of amplification. Data & Society Research Institute. \nhttps://datasociety.net/output/oxygen-of- amplification/.\nPhillips, W. and Milner, R.M. (2017). The ambivalent internet: Mischief, oddity, and \nantagonism online. Polity.\nPorter, J. (2020, May\u00a029). Twitter restricts new Trump tweet for \u201cglorifying violence.\u201d \nThe Verge . https://www.theverge.com/2020/5/29/21274323/trump-twitter-\nglorifying-violence-minneapolis-shooting-looting-notice-restriction.\nQuandt, T. (2018). Dark participation. Media and Communication , 6(4), pp.\u00a036\u201348. \nhttps://doi.org/10.17645/mac.v6i4.1519.\nQuealy, K. (2017, July\u00a026). Trump is on track to insult 650 people, places and things \non Twitter by the end of his first term. New York Times . https://www.nytimes.\ncom/interactive/2017/07/26/upshot/president-trumps-newest-focus-discrediting-\nthe-news-media-obamacare.html.\nRathnayake, C. and Suthers, D.D. (2018). Twitter issue response hashtags as af -\nfordances for momentary connectedness. Social Media + Society . ht tps://doi.\norg/10.1177/2056305118784780.\nReider, B. (2015). YouTube Data Tools [software]. https://tools.digitalmethods.net/\nnetvizz/youtube/index.php.\nRheingold, H. (1994). The millennial whole earth catalog . HarperCollins.\nRoberts, S. T. (2016). Commercial content moderation: Digital laborers\u2019 dirty work. \nIn S. U. Noble and B.M. Tynes (Eds.), The intersectional internet: Race, sex, class \nand culture online (pp.\u00a0147\u2013160). Peter Lang.\nRobertson, R. E., Lazer, D., and Wilson, C. (2018). Auditing the personalization and \ncomposition of politically related search engine results pages. Proceedings of \nthe 2018 World Wide Web Conference on World Wide Web , pp.\u00a0955\u2013965. https://\ndoi.org/10.1145/3178876.3186143.\nRoeder, O. (2018, August\u00a08). We gave you 3 million Russian troll tweets. Here\u2019s \nwhat you\u2019ve found so far. FiveThirtyEight. https://fivethirtyeight.com/features/\nwhat-you-found-in-3-million-russian-troll-tweets/.\nRogers, R. (2004 ). Information politics on the web . MIT Press.\nRogers, R. (2013). Digital methods . MIT Press.\nRogers, R. (2014). Debanalising Twitter: The transformation of an object of study. \nIn K. Weller, A. Bruns, J. Burgess, M. Mahrt and C. Puschmann (Eds.), Twitter \nand society (pp. ix\u2013xxvi) . Peter Lang.\n230  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nRogers, R. (2017). Digital methods for cross-platform analysis. In J. Burgess, A. \nMarwick and T. Poell (Eds.) The SAGE handbook of social media  (pp.\u00a091\u2013108). Sage.\nRogers, R. (2019). Doing digital methods . Sage.\nRogers, R. (2020a). The scale of Facebook\u2019s problem depends upon how \u201cfake news\u201d \nis classified. Harvard Kennedy School Misinformation Review , 1(6). ht tps://doi.\norg/10.37016/mr-2020-43.\nRogers, R. (2020b). Deplatforming: Following extreme internet celebrities to \nTelegram and alternative social media. European Journal of Communication , \n35(3). https://doi.org/10.1177/0267323120922066.\nRogers, R. (2021) Marginalizing the mainstream: How social media privilege political \ninformation. Frontiers in Big Data . https://doi.org/10.3389/fdata.2021.689036.\nRogers, R. and Hagen, S. (2020). Epilogue: After the tweet storm. In R. Rogers \nand S. Niederer (Eds.) The politics of social media manipulation (pp.\u00a0253\u2013256). \nAmsterdam University Press.\nRogers, R. and Niederer, S. (Eds.) (2020). The politics of social media manipulation . \nAmsterdam University Press.\nRomm, T. and Stanley-Becker, I. (2019, December\u00a021). Facebook, Twitter disable \nsprawling inauthentic operation that used AI to make fake faces. Washington \nPost . https://www.washingtonpost.com/technology/2019/12/20/facebook-twitter-\ndisable-sprawling-inauthentic-operation-that-used-ai-make-fake-faces/.\nRosenblatt, K. (2020, October\u00a017). They can\u2019t vote, but they can meme: How these \nTikTokers are trying to get Biden elected. NBC News . https://www.nbcnews.\ncom/pop-culture/viral/they-can-t-vote-they-can-meme-how-these-TikTokers-\nn1243555.\nRoth, Y. and Pickels, N. (2020, May\u00a011). Updating our approach to misleading in -\nformation. Twitter Blog. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.\nSalen, K. and Zimmerman, E. (2004). Rules of play: Game design fundamentals . \nMIT Press.\nSalenger, M. [meredthsalenger]. (2020, March\u00a002). \u201cReal quick: How are Republicans \nlike Donald ok with 2% of people dying from coronavirus as if 2% is not a very \nhigh number. But when you discuss a 2 cent wealth tax on people making over \n50 million they freak out like it\u2019s the worst thing that could ever happened to \nthem\u201d [tweet]. https://twitter.com/meredthsalenger/status/1234337053.\nSchellewald, A. (2021). Communicative forms on TikTok: Perspectives from digital \nethnography. International Journal of Communication, 15 , pp.\u00a01437\u20131457.\nScheufele, D. A. and Krause, N. M. (2019). Science audiences, misinformation, and \nfake news. Proceedings of the National Academy of Sciences , 116(16), pp.\u00a07662\u20137669. \nhttps://doi.org/10.1073/pnas.1805871115.\nbib liogra Phy 231\nSchmitt, C. (2005). Political theology: Four chapters on the concept of sovereignty . \nUniversity of Chicago Press.\nSchwartz, O. (2018, December\u00a04). Are Google and Facebook really suppressing con -\nservative politics? The Guardian . https://www.theguardian.com/technology/2018/\ndec/04/google-facebook-anti-conservative-bias-claims.\nSearles, S. (2020, August\u00a04). Republican TikTok thinks \u201cRed Kingdom\u201d by Tech \nN9ne is their new hype song; We\u2019re laughing. The Pitch . https://www.thepitchkc.\ncom/republican-tik-tok-thinks-red-kingdom-by-tech-n9ne-is-their-new-hype-\nsong-were-laughing/.\nShane, T. (2020, December\u00a01). Searching for the misinformation \u201ctwilight zone.\u201d \nNieman Lab. https://www.niemanlab.org/2020/12/searching-for-the-misinfor -\nmation-twilight-zone/.\nShao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., and Menczer, F. \n(2018). The spread of low-credibility content by social bots. Nature Communica -\ntions, 9 (1), p.\u00a04787. https://doi.org/10.1038/s41467-018-06930-7.\nShepherd, T., Harvey, A., Jordan, T., Srauy, S., and Miltner, K. (2015). Histories of \nhating. Social Media + Society. https://doi.org/10.1177/2056305115603997.\nShibutani, T. (1966). Improvised news: A sociological study of rumor . Ardent Media.\nShifman, L. (2012). An anatomy of a YouTube meme. New Media & Society , 14(2), \npp.\u00a0187\u2013203. https://doi.org/10.1177/1461444811412160.\nShirky, C. (2008). Here comes everybody . Penguin.\nSilverman, C. (2016, November\u00a016). This analysis shows how viral fake election \nnews stories outperformed real news on Facebook. Buzzfeed News . ht tps://\nwww.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-\noutperformed-real-news-on-facebook.\nSilverman, C. and Alexander, L. (2016, November\u00a03). How teens in the Balkans \nare duping Trump supporters with fake news. Buzzfeed News . https://www.\nbuzzfeednews.com/article/craigsilverman/how-macedonia-became-a-global-\nhub-for-pro-trump-misinfo.\nSkopeliti, C. and John, B. (2020, March\u00a019). Coronavirus: How are the social media \nplatforms responding to the \u201cinfodemic\u201d? First Draft. https://firstdraftnews.\norg:443/latest/how-social-media-platforms-are-responding-to-the-coronavirus-\ninfodemic/.\nSmith Gale, S (2020, October\u00a06). U.S. election 2020: TikTok gets pulled into the \ncampaigns. BBC News . https://www.bbc.com/news/technology-54374710.\nSmith, R., Cubbon, S. and Wardle, C. (2020, November\u00a012). Under the surface: \nCovid-19 vaccine narratives, misinformation and data deficits on social media. \nFirst Draft. https://firstdraftnews.org/long-form-article/under-the-surface-\ncovid-19-vaccine-narratives-misinformation-and-data-deficits-on-social-media/.\n232  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nSommer, W. (2018). Instagram is the alt-right\u2019s new favorite haven. The Daily Beast . \nhttps://www.thedailybeast.com/instagram-is-the-alt-rights-new-favorite-\nhaven.\nSparktoro. (2021). Audience intelligence. https://sparktoro.com.\nStanley-Becker, I. (2020, August\u00a01). How the Trump campaign came to court \nQAnon, the online conspiracy movement identified by the FBI as a violent \nthreat. Washington Post . https://www.washingtonpost.com/politics/how-the-\ntrump-campaign-came-to-court-qanon-the-online-conspiracy-movement-\nidentified-by-the-fbi-as-a-violent-threat/2020/08/01/dd0ea9b4-d1d4-11ea-\n9038-af089b63ac21_story.html.\nStarbird, K. (2012). Crowdwork, crisis and convergence: How the connected crowd \norganizes information during mass disruption events [PhD].\nStarbird, K. (2017). Examining the alternative media ecosystem through the produc -\ntion of alternative narratives of mass shooting events on Twitter. In Proceedings \nof the 11th International AAAI Conference on Web and Social Media . AAAI Press. \nhttp:/ /faculty.washington.edu/kstarbi/Alt_Narratives_ICWSM17-CameraReady.\npdf.\nStarbird, K. (2020, April\u00a027). How to cope with an infodemic. Brookings. https://\nwww.brookings.edu/techstream/how-to-cope-with-an-infodemic/.\nStarbird, K., Spiro, E., Edwards, I., Zhou, K., Maddock, J., and Narasimhan, S. (2016). \nCould this be true? I think so! Expressed uncertainty in online rumoring. In \nProceedings of the 2016 CHI Conference on Human Factors in Computing Systems , \npp.\u00a0360\u2013371. https://doi.org/10.1145/2858036.2858551.\nSullivan, D. (2004, April\u00a024) Google in controversy over top-tanking for anti-Jewish \nsite. Search Engine Watch . https://www.searchenginewatch.com/2004/04/24/\ngoogle-in-controversy-over-top-ranking-for-anti-jewish-site/.\nSunstein, C. R. (2001). Echo chambers: Bush v. Gore, impeachment, and beyond. \nPrinceton University Press.\nSunstein, C. R. (2018). #Republic: Divided democracy in the age of social media . \nPrinceton University Press. https://doi.org/10.2307/j.ctv8xnhtd\nSystrom, K. (2014). 300 million Instagrammers sharing real life moments. Insta -\ngram Blog. https://about.instagram.com/blog/announcements/300-million-\ninstagrammers-sharing-real-life-moments.\nTarkov, A. (2012, June\u00a030). Journatic worker takes \u201cThis American Life\u201d inside out -\nsourced journalism. Poynter. https://www.poynter.org/reporting-editing/2012/\njournatic-staffer-takes-this-american-life-inside-outsourced-journalism/.\nTate, R. (2009, 19 Nov.). Twitter\u2019s new prompt: A linguist weighs in . Gawker . ht tps://\ngawker.com/5408768/twitters-new-prompt-a-linguist-weighs-in.\nTeitelbaum, B.R. (2020). War for eternity: The return of traditionalism and the rise \nof the populist right . Penguin.\nbib liogra Phy 233\nTiffany, K. (2020, August\u00a018). How Instagram aesthetics repackage QAnon. \nThe Atlantic . https://www.theatlantic.com/technology/archive/2020/08/\nhow-instagram-aesthetics-repackage-qanon/615364/.\nTrielli, D. and Diakopoulos, N. (2019). Search as news curator: The role of Google \nin shaping attention to news information. Proceedings of the 2019 CHI Con -\nference on Human Factors in Computing Systems \u2013 CHI \u201819 , 1\u201315. https://doi.\norg/10.1145/3290605.3300683.\nTuters, M. (2019). LARPing & liberal tears: Irony, idiocy & belief in the deep vernacular \nweb. In M. Fielitz and N. Thurston (Eds.) Post-digital cultures of the far right: Online \nactions and offline consequences in Europe and the U.S. (pp.\u00a037\u201348). Transcript.\nTuters, M. and Burton, A. (2021). The rebel yell: Toxic vox populism on YouTube. \nCanadian Journal of Communication . forthcoming.\nTuters, M. and Hagen, S. (2020). (((They))) rule: Memetic antagonism and nebulous \nothering on 4chan. New Media & Society , 22(12), pp.\u00a02218\u20132237. https://doi.\norg/10.1177/1461444819888746.\nTuters, M. and OILab (2020). Esoteric fascism online: 4chan and the Kali Yuga. \nIn L.D. Valencia-Garc\u00eda (Ed.), Far-right revisionism and the end of history: Alt/\nhistories (pp.\u00a0287\u2013303). Routledge.\nTuters, M., Jokubauskait\u0117, E., and Bach, D. (2018). Post-truth protest: How 4chan \ncooked up the Pizzagate bullshit. M/C Journal , 21(3), Article\u00a03. https://doi.\norg/10.5204/mcj.1422.\nTwitter (2019a). Glorification of violence policy, Twitter Help Center. https://help.\ntwitter.com/en/rules-and-policies/glorification-of-violence.\nTwitter (2019b, October\u00a015). World leaders on Twitter: Principles & approach. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2019/worldleaders2019.\nTwitter (2020a, February\u00a07). Synthetic and manipulated media policy. Twitter. \nhttps://web.archive.org/web/20200207000218/https://help.twitter.com/en/\nrules-and-policies/manipulated-media.\nTwitter (2020b, April). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020c, May\u00a011). Coronavirus: Staying safe and informed on Twitter. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/covid-19.\nTwitter (2020d, December\u00a016). COVID-19 misleading information policy. Twitter. \nhttps://web.archive.org/web/20201216200114/https://help.twitter.com/en/\nrules-and-policies/medical-misinformation-policy.\nTwitter (2021, January\u00a08). Permanent suspension of @realDonaldTrump. Twitter \nBlog. https://blog.twitter.com/en_us/topics/company/2020/suspension.\nTynan, D. (2016, August\u00a024) How Facebook powers money machines for obscure polit -\nical \u201cnews\u201d sites. The Guardian . https://www.theguardian.com/technology/2016/\naug/24/facebook-clickbait-political-news-sites-us-election-trump.\n234  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nUN DGC. (2020, March\u00a031). UN tackles \u201cinfodemic\u201d of misinformation and cyber -\ncrime in COVID-19 crisis. UN Department of Global Communications. https://\nwww.un.org/en/un-coronavirus-communications-team/un-tackling-\u2019infodemic\u2019-\nmisinformation-and-cybercrime-covid-19.\nUnkel, J. and Haim, M. (2019). Googling politics: Parties, sources, and issue owner -\nships on Google in the 2017 German federal election campaign. Social Science \nComputer Review, 39 (5), pp.\u00a0844\u2013861. https://doi.org/10.1177/0894439319881634.\nUrman, A. and Katz, S. (2020). What they do in the shadows: Examining the far-right \nnetworks on Telegram. Information, Communication & Society , 1\u201320. https://doi.\norg/10.1080/1369118X.2020.1803946.\nUrquhart, C. (2013, January\u00a012). Here comes the sun flash mob cheers Spanish \nunemployment office. The Guardian . https://www.theguardian.com/world/2013/\njan/12/here-comes-the-sun-spanish-unemployment-office.\nuserleansbot. (n.d.). List of political subreddits used by userleansbot. Reddit. https://\nwww.reddit.com/user/userleansbot/comments/cfzho2/list_of_political_subred -\ndits_used_ by_userleansbot/.\nVaidhyanathan, S. (2019, July\u00a028). Why conservatives allege big tech is muzzling \nthem. The Atlantic . https://www.theatlantic.com/ideas/archive/2019/07/\nconservatives-pretend-big-tech-biased-against-them/594916/.\nVan Den Berg, E. (2019, July\u00a030). Opnieuw misser bij Forum voor Democratie: Per -\nsoonlijke advertentie Thierry Baudet offline gehaald. NPO3. https://www.npo3.\nnl/brandpuntplus/opnieuw-misser-bij-forum-voor-democratie-persoonlijke-\nadvertentie-thierry-baudet-offline-gehaald.\nVan der Linden, S., Panagopoulos, C. and Roozenbeek, J. (2020). You are fake news: \nPolitical bias in perceptions of fake news. Media, Culture & Society , 42(3). ht tps://\ndoi.org/10.1177/0163443720906992.\nVan Driel, L. and Dumitrica, D. (2021). Selling brands while staying \u201cauthentic\u201d: \nThe professionalization of Instagram influencers. Convergence , 27(1), pp.\u00a066\u201384. \nhttps://doi.org/10.1177/1354856520902136.\nVenturini, T. (2019) From fake to junk news: The data politics of online virality. \nIn D. Bigo, E. Isin, and E. Ruppert (Eds.) Data politics: Worlds, subjects, rights \n(pp.\u00a0123\u2013144). Routledge.\nVenturini, T. and Latour, B. (2010). The social fabric: Digital footprints and quali-\nquantitative methods. Proceedings of Futur En Seine 2009: The Digital Future of \nthe City . Futur en Seine 2009.\nVijay, D. and Gekker, A. (2021). Playing politics: How Sabarimala played out \non TikTok. American Behavioral Scientist , 65(5), pp.\u00a0712\u2013734. https://doi.\norg/10.1177/0002764221989769.\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. \nScience , 359 (6380), pp.\u00a01146\u20131151. https://doi.org/10.1126/science.aap9559.\nbib liogra Phy 235\nVou\u00e9, P., De Smedt, T., and De Pauw, G. (2020). 4chan & 8chan embeddings. \nArXiv:2005.06946 [Cs] . http://arxiv.org/abs/2005.06946.\nWahl-Jorgensen, K. (2019). Emotions, media and politics. Polity.\nWakabayashi, D. (2018, September\u00a05). Trump says Google is rigged, despite its \ndenials. What do we know about how it works? New York Times . https://www.\nnytimes.com/2018/09/05/technology/google-trump-bias.html.\nWardle, C. (2016, November\u00a018). 6 types of misinformation circulated this election \nseason. Columbia Journalism Review . https://www.cjr.org/tow_center/6_types_\nelection_fake_news.php.\nWardle, C. (2017, February\u00a016). Fake news: It\u2019s complicated. First Draft. https://\nfirstdraftnews.org/latest/fake-news-complicated/.\nWarzel, C. (2021, November\u00a011). Facebook\u2019s vast wasteland. The Atlantic Monthly . \nhttps://newsletters.theatlantic.com/galaxy-brain/618ad9942e822d00205a26b3/\nfacebooks-vast-wasteland/.\nWendling, M. (2018). Alt-Right: From 4chan to the White House . Pluto Press.\nWikipedia contributors. (2020). Killian documents controversy. Wikipedia: The \nFree Encyclopaedia . https://en.wikipedia.org/w/index.php?title=Killian_docu -\nments_authenticity_issues&oldid=962589844.\nWilkinson, W.W. and Berry, S.D. (2020). Together they are Troy and Chase: Who \nsupports demonetization of gay content on YouTube? Psychology of Popular \nMedia , 9(2). https://doi.org/10.1037/ppm0000228.\nWillaert, T., Van Eecke, P., Beuls, K., and Steels, L. (2020). Building social media \nobservatories for monitoring online opinion dynamics. Social Media + Society , \n6(2). https://doi.org/10.1177/2056305119898778.\nWillaert, T., Van Eecke, P., Van Soest, J., and Beuls, K. (2021). A tool for tracking the \npropagation of words on Reddit. Computational Communication Research , 3(1), \npp.\u00a0117\u2013132. https://doi.org/10.5117/CCR2021.1.005.WILL.\nWoods, A. (2019). Cultural Marxism and the cathedral: Two alt-right perspec -\ntives on critical theory. In C.M. Battista and M.R. Sande (Eds.), Critical theory \nand the humanities in the age of the alt-right (pp.\u00a039\u201359). Springer. https://doi.\norg/10.1007/978-3-030-18753-8_3.\nYong, E. (2020, April\u00a029). Why the coronavirus is so confusing. The Atlantic . \nhttps://www.theatlantic.com/health/archive/2020/04/pandemic-confusing-\nuncertainty/610819/.\nYouTube (2019, January\u00a025). Continuing our work to improve recommenda -\ntions on YouTube. YouTube Blog. https://blog.youtube/news-and-events/\ncontinuing-our-work-to-improve/.\nYouTube (2020). COVID-19 medical misinformation policy\u2014YouTube Help. https://\nsupport.google.com/youtube/answer/9891785?hl=en.\n236  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nytdl-org (2021, February\u00a01). Youtube-dl . Youtube-Dl: Download Videos from YouTube \n(and More Sites). http://ytdl-org.github.io/youtube-dl/.\nZannettou, S., Caulfield, T., Blackburn, J., De Cristofaro, E., Sirivianos, M., Stringhini, \nG., and Suarez-Tangil, G. (2018). On the origins of memes by means of fringe web \ncommunities. ArXiv:1805.12512 [Cs] . http://arxiv.org/abs/1805.12512.\nZannettou, S., Caulfield, T., De Cristofaro, E., Kourtelris, N., Leontiadis, I., Sirivianos, \nM., Stringhini, G., and Blackburn, J. (2017). The web centipede: Understanding \nhow web communities influence each other through the lens of mainstream \nand alternative news sources. Proceedings of the 2017 Internet Measurement \nConference IMC\u201917  (pp.\u00a0405\u2013417). ACM. https://doi.org/10.1145/3131365.3131390.\nZulli, D. and Zulli, D. J. (2020). Extending the internet meme: Conceptualizing \ntechnological mimesis and imitation publics on the TikTok platform. New Media \n& Society . https://doi.org/10.1177/1461444820983603.\n Index\nPage numbers in italics  refer to figures and tables\naccounts\nInstagram verified\u2003159\nproblematic\u200320, 53, 62, 87, 95, 97\u201398purge of\u200383\u201384, 86Republican party\u200321, 144, 150\u201351verified\u2003141, 150 , 155 , 159\nactive audience approach, to content \nmoderation\u200326\nactivity, on social media\u200377, 84\u201386\nengagement and\u200326, 95popularity and\u2003201\nactivity, user\u200398\u2013100AIN see  alternative influence network\nalgorithms\u200335, 43\n\u201cserious queries\u201d and\u200324\u201325\nalternative influence network (AIN)\u200317, 68, \n210alt-right and\u200373deplatforming and\u200373\u201375mainstream and\u200374\nalt-right\u2003165\u201366\nAIN and\u200373deplatforming and\u2003141Facebook and\u200349memes and\u2003167Yiannopoulos and\u2003168\nambivalent content\nearnest compared to\u2003139, 142, 157on Instagram\u200320\u201321, 139mainstreaming of\u2003201TikTok and\u2003198\u201399\nambivalent critique\u2003188\nremix as\u200315, 189, 195, 196 , 199\nanalysis\ncross-platform\u20037\u201311, 14, 24geographical\u2003152Instagram\u2003151\u201352 , 155\u201356, 157\nlinguistic\u2003173namespace\u2003144\u201345, 147 , 149, 150 , 158\nquali-quantitative\u2003179\u201380user activity\u2003142\u201343, 158\nAniston, Jennifer\u2003154anonymity\nof 4chan\u20031694chan and Reddit and\u200310, 75\nartificial amplification, of followers\u2003139\u201340, \n158\u201359Instagram and\u2003150\u201353\nattacks\non candidates\u200388\u201389, 93far-right terrorist\u2003171using opponent hashtags\u200385, 90, 95, 97, \n158audience tweets\u2003125 , 126 , 127, 129\nauthoritative sources compared to\u2003116\u201321\nauthenticity\u2003103\nof behaviors\u200313, 18\u201319of followers\u200321, 141, 143, 158\nauthoritative sources\naudience tweets compared to\u2003116\u201321consensus from\u2003113, 120\u201322content moderation and\u2003115on COVID-19\u2003128\u201329hydroxychloroquine and\u2003123, 128personalization and\u2003111Trump, D., as\u2003110\u201311Twitter as\u2003112, 114\u201315, 128\nbacklash\ncontent moderation and\u2003208political\u200351, 90\nBannon, Steve\u2003168, 177Barnidge, M.\u200386\u201389Bass Da Da Da (viral sound)\u2003193, 194Bauman, Zygmunt\u200350\u201351Benkler, Y.\u200368, 143, 168\nmedia ecologies of\u200377\nBerger, J.\u200390\u201391bias\u200362\nideology and\u200378liberal\u200311, 35politics and\u2003112\nBiden, Joe\u200315\u201316, 36, 58, 74 see also  candidates, \npresidential; presidential elections, U.S.follower authenticity and\u200321hyperpartisan sources and\u200362\u201363influencers and\u2003154Instagram and\u2003144\u201345keyword data for\u200398 , 101\nObama, B., and\u2003149TikTok and\u2003190, 193, 194 , 196\u201397, 201\n\u201cBiden and his sister\u201d (TikTok video)\u2003197\u201cbig data\u201d\u200348, 148bots\u200313, 84\u201386 see also  problematic accounts\nBreitbart News\u2003178\nalt-right and\u2003166comment sections of\u2003168\u201370, 173\u201374 , 177\n4chan compared to\u2003165, 171, 174Trump, D., and\u2003168, 170, 176\u201377vernacular crossover to\u2003165\u201367, 169\u201371, \n173, 176\nvocabulary propagation and\u2003172, 173\u201374 , \n177\nBruns, A.\u200388\u201389Buzzfeed News  (website)\u20037, 19, 51, 61\nBuzzsumo\u200361\u201362\n238  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\ncandidates, presidential\u2003 61, 192 see also  \npresidential elections, U.S.\nattacks on\u200388\u201390, 93influencers and\u2003153, 154Instagram and\u2003141\u201345, 146\u201348 , 150\u201352\nparody of\u2003200\u2013201queries on\u200354\u201360supporters of\u200315, 85, 88\u201389\nCapitol riots\u20038, 18, 103\nParler and\u2003177\u201378purge of accounts after\u200383\u201384, 86Trump, D., and\u200385\ncategorization\nof content\u200316, 71\u201373, 156\u201357users and\u2003103, 151 , 158\nof websites and sources\u200322\u201323, 38 , 43\u201344, \n53, 86, 92, 102\nCDC see  Centers for Disease Control\ncelebrities see  influencers\nCenter for Countering Hate\u2003140Centers for Disease Control (CDC), COVID-19 \nand\u2003115, 118\nchoice, freedom of\u200350\u201351civic engagement\u200315\nludic\u2003188, 192\u201393\nclaims\nCOVID-19 and\u2003111\u201313, 117\u201318 , 121, 122\u201323, \n129\u201331\nDemocratic party and\u2003167, 200\nClinton, Hillary\u2003149coding schema\u200377, 78\ncontent analysis and\u2003142\u201343for sources\u200343, 68, 130\u201331for videos\u200371, 72 , 202\u20133\ncollective sensemaking\u2003112\u201313comment sections, of Breitbart News\u2003168\u201370, \n173\u201374 , 177\ncommunication\nhyperpartisanship and\u200391ideology and\u200369, 73, 88political\u2003189\u201390\nconsensus, from authoritative sources\u2003111, \n113, 120\u201322\nconservative sources\nhyperpartisanship and\u2003 58\u201360 , 208\nliberal compared to\u200323, 33\u201335, 38, 39\u201340 , 43\nin search results\u200340 , 43\nconspiracy theories\u2003140\nof COVID-19\u200351, 118, 120, 123debunking\u2003153extreme speech and\u2003175\u201cfake news\u201d and\u20031895G and\u2003147\u2013484chan and\u2003172\ncontent analysis\ncoding schemas for\u2003142\u201343on Instagram\u2003155\u201356, 157 , 158\ncontent moderation\u20039, 131, 207\nactive audience approach to\u200326authoritative sources and\u2003115backlash and\u2003208in Europe\u200325\u201326Facebook and\u200319\u201320, 48, 50, 210by Google Web Search\u200335on Instagram\u2003145labor of\u200325, 209partisanship and\u200311policies for\u200369problematic information and\u200312\u201313, 110, \n112\u201313, 209\u201310\non Reddit and 4chan\u200369Trump, D., and\u200326, 146on Twitter\u2003109\u201310, 113\u201314, 121\u201323\u201cwisdom of the crowd\u201d and\u200312, 23, 26\ncoronavirus see  COVID-19\nCOVID-19\u200312, 124 , 209\nauthoritative sources on\u2003128\u201329CDC and\u2003115, 118\nclaims about\u2003111\u201313, 117\u201318 , 121, 122\u201323, 129\u201331\nconspiracy theories of\u200351, 118, 120, 123divisiveness and\u2003140earnest content about\u2003142, 147, 153, 154exceptional information state and\u200325Instagram and\u2003144policies and\u2003110, 129problematic information and\u2003112sources on\u2003135\u201336transmission and treatment of\u2003109, 115, \n116\u201321, 117\u201318, 120\u201321, 125\u201327 , 130, 137\u201338\nTrump, D., and\u2003114\u201315Twitter mentions of\u2003116\u201321, 125\u201327uncertainty and\u2003111\ncreative expression, on TikTok\u200315\u201316, 200\u2013201credibility, media and\u200349crisis, of \u201cfake news\u201d\u200311, 49, 140critique, ambivalent\u2003188cross-platform analysis\u20037\u201310, 14, 24\nmedium-specificity in\u200311\nCrowdTangle\u200321, 155\u201356, 159\u201360curation, of information\u200322\u201325, 115, 209\nmethodology and\u200343, 61, 101, 102\nDACA see  Deferred Action for Childhood \nArrivals\n\u201cdark participation\u201d\u2003172data\u20038, 9, 13, 102, 179\u201380\nbig\u200348, 148from 4chan and Breitbart News\u2003178keyword\u200398 , 101\npolitical discourse and\u2003176from Reddit and 4chan\u200378\u201379TikTok and\u2003202\u20133\nDeadville, James\u2003191debates\nCOVID-19 and\u2003121deplatforming\u2003207\u20138, 211freedom of choice and\u200350\u201351political\u2003101, 144, 167\nin de X 239\ndebunking\nconspiracy theories\u2003153\nSnopes and\u2003196, 200Twitter and\u2003123, 128by WHO\u2003115\n\u201cdeep vernacular web\u201d\u200369, 167\non Reddit and 4chan\u200367\u201368\nDeferred Action for Childhood Arrivals \n(DACA)\u200395, 96 , 100 , 102\nDemocratic party\nclaims about\u2003167, 200keywords for\u200392\u201393, 94 , 98\u201399 , 101, 102\ndemocratization, of news, Twitter and\u200387\u201388demonetization\u200313demotion, on TikTok\u2003210Denver Guardian\u200320, 53deplatforming\u200313, 17, 69, 141, 207\u20138, 211\nAIN and\u200373\u201375alt-right and\u2003141QAnon conspiracies and\u200386, 172Trump, D.\u2003178Twitter and\u200318, 83\ndigital methods\u200376, 101\u20134, 128\u201331, 155\u201357\nfollowers and\u2003158\u201359hostnames and\u200371, 77, 78 , 79\nkeywords and\u2003159\u201360namespace analysis and\u2003144\u201345, 147 , 149, \n150, 158\nsource-distance methodology\u200342\u201344user activity analysis and\u2003142\u201343, 158\ndiscourse, political\u2003189, 201\u20132\ndata and\u2003176extreme\u2003171, 175\u201376polarization in\u2003167of Trump, D.\u2003166U.S. presidential elections and\u200386, 169\u201370\ndisinformation\u200316, 20, 114, 122, 140diversification, polarization compared \nto\u200388\u201389\ndivisive content\u200321, 139\nCOVID-19 and\u2003140on Instagram\u2003141\u201342, 145non-divisive compared to\u2003156, 157 , 158\nsocial issues and\u200334\u201335, 58, 147\u201348\ndocumentary video, problematic information \nand\u200374\u201375\n\u201cdocumenting,\u201d on TikTok\u2003193\u201395\u201cDonald Trump and The Pope\u201d (TikTok \nvideo)\u2003 197\nearnest content\nambivalent compared to\u2003139, 142, 157COVID-19 and\u2003147, 154influencers and\u200321, 153\u201354on Instagram\u2003143, 145\necho chambers\u200388\u201390ecologies\ninformation\u200367\u201370media\u200377, 168platform\u200375\u201376video\u200371\u201372\neditorial epistemologies\u2003209\nplatform criticism and\u200324\u201327social issues and\u2003210Twitter and\u200326\u201327\nelections research\u200335, 38, 40 , 42\u201343 see also  \npresidential elections, U.S.\nemotive news, factual compared to\u200391engagement\u200353, 200\nactivity and\u200326, 95civic\u200315on Facebook\u200348\u201349, 61\u201362on Instagram\u2003144, 156on TikTok\u2003188\u201389, 202on Twitter\u200384, 87\nepistemologies, editorial\u200324\u201327, 209\u201310An establishment conservative\u2019s guide to the \nalt-right  (Yiannopoulos)\u2003168\nEurope, content moderation in\u200325\u201326event-commentary\u2003188, 201\n\u201cfresh\u201d content and\u2003189\u201390\nexceptional information state\u200324\nCOVID-19 and\u200325editorial epistemology and\u200327\nexpertise, in search results, relevance \ncompared to\u200341\nextreme speech\nconspiracy theories and\u2003175on 4chan\u2003170\u201371neologisms and\u2003175\u201376right-wing vocabulary of\u2003172\u201373\nFacebook\nalt-right media and\u200349bots and trolls on\u200313, 49content moderation and\u200319\u201320, 48, 50, 210engagement on\u200348\u201349, 61\u201362\u201cfake news\u201d and\u200319, 47, 52\u201357Haugen and\u2003209hyperpartisan sources and\u200348, 51, 58\u201360 , \n62\u201363\nproblematic sources and\u2003207\u20138QAnon content and\u2003207U.S. presidential elections and\u200352\u201360 , \n61\u201362, 208\nwhistle-blowing and\u2003209\nfact-checking\u200325\u201326, 50, 146 , 209\nfactual news, emotive compared to\u200391fake accounts see  problematic accounts\n\u201cfake news\u201d\u200312, 18, 48, 63\nconspiracy theories and\u2003189crisis of\u200311, 49, 140Facebook and\u200319, 47, 52\u201357\u201cfalse news\u201d compared to\u200349, 53, 208\u201cjunk news\u201d and\u200349\u201351mainstream news websites compared \nto\u200352\u201356 , 58\nSilverman and\u20037, 19\u201320, 51, 61, 209\n240  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\n\u201cfalse news\u201d\u200319\u201320, 62\n\u201cfake news\u201d compared to\u200349\u201351, 53, 208\nFrance and\u200325\nfeatured snippets, in Google Web Search\u200334filter bubbles\u200388\u201390\npersonalization and\u200311\nFirst Draft News\u20037\u20138, 1995G (technology)\u200312 n. 1\nconspiracy theories and\u2003147\u201348COVID-19 and\u200312\nflash mobs\u2003193follower factories\u200313, 141followers\u2003150\nartificial amplification of\u2003139\u201340, 158\u201359authenticity of\u200321, 141, 143, 158digital methods and\u2003158\u201359geographical analysis of\u2003152on Instagram\u2003151\u201352\n4chan\u2003173 see also  Reddit, 4chan and\nanonymity of\u2003169Breitbart News compared to\u2003165, 171, 174content moderation on\u2003210data from\u200378\u201379, 178extreme speech on\u2003170\u201371memes on\u2003175\u201376QAnon conspiracies and\u2003166\u201367vernacular crossover from\u2003165, 170\u201371, 176vocabulary propagation and\u2003172, 173\u201374 , \n177\n4chan Capture and Analysis Toolkit\u200377Fox News , Hannity and\u200362\nFrance, \u201cfalse news\u201d and\u200325Francis, pope\u2003196, 197fraud, voter\u2003190, 199freedom, of choice\u200350\u201351\u201cfresh\u201d content\u2003199\nevent-commentary and\u2003189\u201390\u201cstale\u201d social media compared to\u2003188\nfringe activities\u200317, 167\nmainstream compared to\u200314, 23, 85, 187TikTok and\u2003200web history and\u200312\nGabbard, Tulsi\u200376Gates, Kevin\u2003153geographical analysis, of followers\u2003152Germany, search results in\u200338\u201cgiving a speech,\u201d on TikTok\u2003193\u201395, 200Google Web Search\u200333\ncontent moderation by\u200335featured snippets of\u200334imbalances in\u200338\u201339official sources in\u200336personalization in\u200342polarization and\u200335problematic information in\u200322\u201323, 34\u201336, \n36\u201338\nunique sources in\u200339, 40\u201341U.S. presidential elections and\u200336\u201341gradient classification\u200361\u201363Grande, Ariana\u2003154\u201cGreat Again\u201d (song) (Taylor)\u2003191Green New Deal, Twitter and\u200397\nHagen, S.\u2003198\u201399\n\u201chaystack-to-needle\u201d method of\u200368, 77\nHanks, Tom\u2003153\nHannity, Sean\u200362Harris, Kamala\u2003149, 154\nTikTok and\u2003193, 194\nHarvard Kennedy School Misinformation \nReview \u20038\nhashtags\u200315, 103, 203 see also  keywords\nattacks using\u200385, 90, 95, 97, 158\nHaugen, Frances\u2003209\u201chaystack-to-needle\u201d method\u200368, 77history, web\u200311, 23\nfringe contributions and\u200312\n\u201cHollow heads\u201d (TikTok video)\u2003194hostnames, digital methods and\u200371, 77, 78 , 79\nhydroxychloroquine\u2003 118\nauthoritative sources and\u2003123, 128polarization and\u2003117\nHypeAuditor\u200321, 158, 160hyperpartisanship\u200310, 36, 39, 91\nBiden and\u200362\u201363conservatism and\u200358\u201360 , 208\nFacebook and\u200320, 48, 51(hyper)partisanship and\u2003 84, 86, 92\nmainstream sources and\u200389problematic sources and\u200349\u201351, 86\u201387on TikTok\u2003199Twitter and\u2003209\nideology\u200349, 188, 208\nalt-right\u2003168bias and\u200378communication and\u200369, 73, 88\nimbalances, in Google Web Search\u200338\u201339imposter websites\u200320, 53, 62inauthentic behaviors\u200313, 18\u201319, 141India, followers from\u2003152\u201353influencers\ndivisive content and\u2003141\u201342earnest content and\u200321, 153\u201354Instagram and\u200313\u201314, 144, 154 , 159\nsocial issues and\u2003153\u201354, 154\ninformation\u2003142\ncuration of\u200322\u201325, 115, 209problematic\u20039\u201310, 42, 49, 103\u20134\ninformation ecologies\n\u201cjunk news\u201d and\u200370partisanship in\u200368during U.S. presidential elections\u200367\u201369\nInstagram\nambivalent content and\u200320\u201321, 139artificial amplification on\u2003150\u201353Biden and\u2003144\u201345\nin de X 241\ncontent analysis and\u2003155\u201356, 157 , 158\ndivisive compared to earnest content \non\u2003141\u201342, 145\nfollower analysis on\u2003151\u201352\ninfluencers on\u200313\u201314, 144, 154 , 159\nnamespace analysis and\u2003144\u201345, 147 , 149, \n150, 158\npolarization and\u2003139, 141\u201343, 156\u201358presidential candidates and\u2003141\u201345, \n146\u201348 , 150\u201352\nsocial issues and\u2003148 , 155\nTrump, D., and\u2003143\u201344, 146 , 149, 152, 154\nTrump, D., Jr., and\u2003143, 149U.S. presidential elections and\u200320\u201321, \n139\u201340, 143\nverified accounts on\u2003141, 150 , 155 , 159\nissues\ndivisive\u200334\u201335, 58, 147\u201348political\u200395, 96 , 100 , 102\nsocial\u2003 54\u201360 , 61, 141\u201342\nin U.S. presidential elections\u200333\n\u201cIs this what happens\u2026?\u201d (TikTok video)\u2003194\u201cI voted for a man named Donald J. Trump\u201d \n(TikTok video)\u2003191\nJack, Caroline, problematic information \nand\u200342, 84\nJenkins, Henry\u2003195Jimmy Kimmel Live! (television show)\u2003196, 197Jokubauskaite, E., \u201chaystack-to-needle\u201d method \nof\u200368, 77\n\u201cjunk news\u201d\u200377\u201378\n\u201cfake news\u201d and\u200349\u201351information ecologies and\u200370Netherlands and\u200351problematic information and\u2003208\nKardashian, Kim\u2003153, 154Kennedy, Robert F. Jr., Instagram and\u2003148keywords\nDemocrat and Republican\u200392\u201393, 94 , \n98\u201399 , 101, 102\ndigital methods and\u2003159\u201360\n\u201cKings & Queens\u201d (song)\u2003197, 198#KnowTheFacts\u2003114, 123, 128\nlabor, of content moderation\u200325, 209\n\u201cThe left lies\u201d (TikTok video)\u2003194\u201cLet\u2019s start a chain of women for Trump\u201d \n(TikTok video)\u2003198\nLewis, Rebecca\u200373liberalism\u2003 194\nbias and\u200311, 35voters and\u2003175\nliberal sources, conservative compared to\u200323, \n33\u201335, 38, 39\u201340 , 43\nlinguistic analysis\u2003173local news websites\u200340\u201341, 44ludic civic engagement\u2003188, 192\u201393mainstream activities\nAIN and\u200374ambivalence and\u2003201fringe compared to\u2003187harmful vernacular and\u2003176\nmainstreaming the fringe\u200314, 23, \n173\u201374, 179, 211 see also  marginalizing the \nmainstream\n4chan and Breitbart News and\u2003169\nmainstream sources\u200337, 43\u201344\n\u201cfake news\u201d websites compared to\u200352\u201356 , \n58\nfringe media and\u200385, 167hyperpartisan sources compared to\u200389problematic sources compared to\u200392, \n93\u201394 , 96\u201397\nmarginalizing the mainstream\u20037, 14, 23\u201324, \n211\nMax, Ava\u2003197, 198media\ncredibility and\u200349ecologies of\u200377, 168labeling of\u200318\u201320, 22, 38, 43, 47\u201351, 62, \n92, 102\npersonalization and\u2003211TikTok and\u2003199during U.S. presidential elections\u200385\nmedia, social see  specific topics\nMedicare\u2003 96, 100 , 102\nU.S. presidential elections and\u200395\nmedium-specificity, in cross-platform \nanalysis\u200311\nmemes\u200316, 166, 175\u201376\nalt-right and\u2003167news content and\u2003188\nmethodology\u2003178, 180, 203\nBuzzsumo in\u200361\u201362cross-platform analysis and\u20037\u201311, 14, 24CrowdTangle in\u200321, 155\u201356, 159\u201360curation of information and\u200343, 61, 101, 102digital methods and\u200376\u201379, 101\u20134, 128\u201331, \n155\u201360\n4chan Capture and Analysis Toolkit in\u200377gradient classification in\u200361\u201363\u201chaystack-to-needle\u201d\u200368, 77HypeAuditor and\u200321, 158, 160media labeling and\u200318\u201320, 22, 38, 43, \n47\u201351, 62, 92, 102\nnatural language processing in\u2003112, 179observational periods in\u200379pink slime websites and\u200377source-distance\u200342\u201344TikTok-scraper and\u2003202\u20133Twitter Capture and Analysis Toolkit \nand\u2003102, 129\nuserleansbot in\u200376\u201377Wikipedia in\u200322, 43, 62, 129\u201330YouTube Data Tools and\u200379\nMilkman, K. L.\u200390\u201391\n242  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nMilner, R. M.\u2003198\u201399\nmoderation, of content\u20039, 131, 207music, during U.S. presidential \nelections\u2003191\u201392\nnamespace analysis, on Instagram\u2003144\u201345, \n147, 149, 150 , 158\nNational Institutes of Health (NIH)\u2003111, \n114\u201315, 117\nNational Rifle Association, Instagram \nand\u2003144, 148, 153\nnatural language processing\u2003112, 179\u201cneedle-to-haystack\u201d method\u200377neologisms\nextreme speech and\u2003175\u201376right-wing vocabulary and\u2003174\u201376\nNetherlands, \u201cjunk news\u201d and\u200351news\nfake\u200312, 18, 48, 50false\u200319\u201320, 62junk\u200377\u201378local\u200340\u201341, 44memes and\u2003188partisanship and\u200370viral\u200390, 91\nNIH see  National Institutes of Health\nnon-divisive content, divisive compared \nto\u2003156, 157 , 158\nObama, Barack\u2003154, 195\nBiden and\u2003149\nObama, Michelle\u2003149, 154observational periods\u200379official source websites\u200334, 44\nin Google Web Search\u200336special interest compared to\u200335\nO\u2019Hara, K.\u200389\npandemic see  COVID-19\nParler\u2003171\nCapitol riots and\u2003177\u201378\nparody\nof candidates\u2003200\u2013201\nTikTok and\u200314\u201316, 192, 195\u201396, 198\u201399\nparticipation\u2003188\ndark\u2003172politics and\u2003195, 201pseudonyms and\u200369\n\u201cpartisan duetting and stitching,\u201d on \nTikTok\u2003197\u201398\npartisanship\u2003 78, 103\u20134 see also  \nhyperpartisanshipcontent moderation and\u200311in information ecologies\u200368news websites and\u200370Reddit and 4chan and\u200371Twitter and\u200319userleansbot and\u200376\u201377\nPeacock, C.\u200386\u201389personalization\nauthoritative sources and\u2003111filter bubbles and\u200311in Google Web Search\u200342media and\u2003211\nPfizer vaccine, for COVID-19\u2003115Phillips, W.\u2003198\u201399pink slime websites\u200320, 62\nmethodology and\u200377U.S. presidential elections and\u200316\u201317\nplatforms\u200317\nbased in U.S.\u200310, 67criticism of\u200323\u201324cross-platform analysis of\u20037\u201310, 14, 24ecologies of\u200375\u201376rules of\u200318, 128, 207\n\u201cplayful political performance,\u201d on Tik-\nTok\u2003189\u201391, 194\u201395, 199\u2013200\npolarization\ndiversification compared to\u200388\u201389Google Web Search and\u200335hydroxychloroquine and\u2003117Instagram and\u2003139, 141\u201343, 156\u201358TikTok and\u2003188, 201on Twitter\u200390, 92, 101in U.S.\u2003167, 169\npolicies\nBreitbart News\u2003178content moderation\u200369COVID-19 and\u2003110, 129on problematic information\u2003123Twitter\u2003111, 124 , 128, 208\npolitical debates\u2003101, 144, 167political information environment, during U.S. \npresidential elections\u200310\npoliticization\n\u201cfake news\u201d and\u200348, 58, 63liberal bias and\u200311\npolitics\u2003173, 189\u201390\nbacklash and\u200351, 90bias and\u2003112participatory\u2003195, 201search results and\u200322\u201323spectrum of\u200311, 19, 89on Twitter\u200383, 95, 96 , 100 , 102, 102\nunrest in U.S. of\u200335\npopularity, on TikTok\u2003201\u20132presidential elections, U.S.\u200336, 83, 165\ndata and\u2003178exceptional information state and\u200325extreme speech during\u2003170\u201371Facebook and\u2003 52\u201360 , 61\u201362, 208, 209\nGoogle Web Search results and\u200322, 36\u201341information ecologies during\u200367\u201369Instagram and\u200320\u201321, 139\u201340, 143issues in\u200333\u201cjunk news\u201d and\u200370media during\u200385, 168, 202Medicare and\u200395\nin de X 243\nmusic during\u2003191\u201392\npink slime websites and\u200316\u201317political discourse and\u200386, 169\u201370political information environment \nduring\u200310\nproblematic information and\u2003199Reddit and 4chan and\u200376research into\u200335, 38, 40 , 42\u201343\nTikTok and\u2003187\u201389, 190, 1952016\u200316\u201320, 47\u201348, 51, 52 , 53, 62\u201363, 69, 86, \n166, 168\u201376\n2020\u20039, 47, 48, 68, 87, 172, 176\u201377Twitter and\u200317\u201319, 85\u201387voters and\u2003 154, 190\nprevention, of COVID-19\u2003126\u201327 , 130, 137\u201338\nproblematic accounts\u200387, 95, 97\u201398\nimposter websites\u200320, 53, 62\nproblematic information\u20039\u201310, 42\u201343, 49, \n103\u20134content moderation and\u200312\u201313, 110, 112\u201313, \n209\u201310\nCOVID-19 and\u2003112curation and\u200322\u201325disinformation as\u200316, 20, 114, 122, 140documentary video and\u200374\u201375in Google Web Search\u200322\u201323, 34\u201336, \n36\u201338\non Instagram\u2003140\u201cjunk news\u201d and\u2003208policies on\u2003123sources for\u200384, 104Twitter and\u200318, 84\u201387, 110U.S. presidential elections and\u2003199\nproblematic sources\u200384, 91, 104\nFacebook and\u2003207\u20138hyperpartisanship and\u200349\u201351, 86\u201387mainstream sources compared to\u200392, \n93\u201394 , 96\u201397\nTwitter and\u200383\nprogressive sources see  liberal sources, \nconservative compared to\npseudonyms\u200369, 75purge, of accounts\u200383\u201384, 86\nQAnon conspiracies\u2003140\ndeplatforming and\u200386, 172\nFacebook and\u20032074chan and\u2003166\u201367on TikTok\u2003199\u2013200\nquali-quantitative analysis\u2003179\u201380\nRatajkowski, Emily\u2003153\nReddit, 4chan and\u200370\nanonymity and\u200310, 75banned subreddits and\u200373\u201375content moderation on\u200369data from\u200378\u201379\u201cdeep vernacular web\u201d on\u200367\u201368partisanship and\u200371pseudonyms and\u200369, 75U.S. presidential elections and\u200376YouTube links on\u200316\u201317, 68, 71, 72 , 73\u201374\n\u201cRed Kingdom\u201d (song)\u2003192Reider, Bernhard, YouTube Data Tools of\u200379relevance, in search results, expertise \ncompared to\u200341\nremix\u2003173, 198\nas ambivalent critique\u200315, 189, 195, 196 , 199\nRepublican keywords\u200392\u201393, 94, 98\u201399 , 101, 102\nRepublican party\naccounts of\u200321, 144, 150\u201351AIN and\u200373attacks on\u200393, 97Instagram and\u2003150\u201352\nretweets\u200326, 84, 101\u20133, 131 see also  Twitter\nright-wing vocabulary\u2003172\u201373, 173\u201374 , 177, 180 \nsee also  alt-right\nneologisms of\u2003174\u201376\nThe Rock\u2003154\nSanders, Bernie see also  candidates, presiden -\ntial; presidential elections, U.S.\ndivisive content and\u2003145, 146Instagram and\u2003144, 149TikTok and\u2003190, 201\nSchmitt, Carl\u2003115search results\u200322\u201323, 37 see also  Google Web \nSearchconservative compared to liberal sources \nin\u200323, 33\u201335, 38, 39\u201340 , 43\nrelevance and expertise compared in\u200341in U.S. compared to Germany\u200338U.S. presidential elections and\u200322, 36\u201341\nsensemaking, collective\u2003112\u201313\u201cserious queries,\u201d algorithms and\u200324\u201325Silverman, Craig\u200318, 208\nBuzzfeed News  article by\u20037, 51, 61\n\u201cfake news\u201d and\u20037, 19\u201320, 51, 61, 209\nSnoop Dogg\u2003149, 154Snopes, debunking and\u2003196, 200social issues\ndivisiveness and\u2003147\u201348editorial epistemologies and\u2003210influencers and\u2003153\u201354, 154Instagram users and\u2003148 , 155\nsocial media see  specific topics\nS\u00f8rensen, Majken Jul\u2003193source-distance methodology\u200342\u201344sources\nauthoritative\u2003109\u201312coding schemas for\u200343, 68, 130\u201331of COVID-19 information\u2003135\u201336(hyper)partisan\u200386mainstream\u200337, 43\u201344problematic\u200384, 91, 104as spectrum\u200348\u201349\nspecial interest websites\u200334, 37, 40\u201341, 44\nofficial sources compared to\u200335\n244  T he Pro Pa gaTion  of Mi Si nfor MaTion  in\u00a0Social Media\nspectrum\n\u201cfake news\u201d as\u200349\u201350\npolitical\u200311, 19, 89sources as\u200348\u201349\n\u201cstaging an opinion,\u201d on TikTok\u2003191, 193, 195, \n199\n\u201cstale\u201d social media, \u201cfresh\u201d compared \nto\u2003188\u201390\nStevens, D\u200389supporters\nof Biden\u2003101, 198of candidates\u200315, 85, 88\u201389of Trump, D.\u2003190, 192, 194 , 197\u201398, 200\u2013201\n\u201cSweet Home Alabama\u201d (song)\u2003196, 197\nTaylor, James McCoy\u2003191\nterrorist attacks, far-right\u2003171\u201cThank God for Donald Trump?\u201d (TikTok \nvideo)\u2003 194\nTikTok\u2003 202\nambivalent content and\u2003198\u201399Biden and\u2003190, 193, 194 , 196\u201397, 201\ncreative expression on\u200315\u201316, 200\u2013201data and\u2003202\u20133demotion of content on\u2003210\u201cdocumenting\u201d on\u2003193\u201395engagement on\u2003188\u201389, 202fringe practices and\u2003200\u201cgiving a speech\u201d on\u2003193\u201395, 200media on\u2003199parody and\u200314\u201316, 192, 195\u201396, 198\u201399\u201cpartisan duetting and stitching\u201d \non\u2003197\u201398\n\u201cplayful political performance\u201d on\u2003189\u201391, \n194\u201395, 199\u2013200\npolarization and\u2003188, 201remix on\u2003195\u201396Sanders on\u2003190, 201\u201cstaging an opinion\u201d on\u2003191, 193, 195, 199Trump, D., on\u2003190\u201393, 194 , 196, 201\nU.S. presidential elections and\u2003187\u201389, \n190, 195\nvideos from\u2003191 , 194 , 196\u201398\nyouth and\u200310, 14\nTikTok-scraper\u2003202\u20133transmission, of COVID-19\u2003117\u201318, 119\u201321, \n120\u201321, 126\u201327 , 130, 137\u201338\ntreatments, for COVID-19\u2003109, 115, 116\u201318 , \n125\u201327 , 130, 137\u201338\ntrolling\u200318, 69 88\u201389, 144 see also  problematic \naccountson Facebook\u200313, 49\nTrump, Donald\u200358, 178 see also  candidates, \npresidential; presidential elections, U.S.as authoritative source\u2003110\u201311Breitbart News and\u2003168, 170, 176\u201377Capitol riots and\u200385content moderation and\u200326, 146COVID-19 information and\u2003114\u201315deplatforming of\u2003178divisive content and\u2003145\u201cfake news\u201d and\u200349follower authenticity and\u200321Instagram and\u2003143\u201344, 146 , 149, 152, 154\nkeyword data for\u200398 , 101\npolitical discourse of\u2003166TikTok and\u2003190\u201393, 194 , 196, 201\nTwitter and\u200385, 91, 95, 115, 117, 127 , 128\nvoters for\u2003167web content and\u200315\u201316, 36, 38, 93\nTrump, Donald, Jr.\u200321\ndivisive content and\u2003145Instagram and\u2003143, 149\n\u201cTrump Theme Song\u201d\u2003191\u201392trust, in news\u200390Tuters, M.\u2003198\u201399Twitter\u200390\nas authority\u2003112, 114\u201315, 128bots on\u200385\u201386content moderation on\u2003109\u201310, 113\u201314, \n121\u201323\nCOVID-19 mentions on\u2003116\u201321, 125\u201327debunking and\u2003123, 128democratization of news and\u200387\u201388deplatforming and\u200318, 83diversification compared to polarization \non\u200387\u201389\neditorial epistemology and\u200326\u201327engagement on\u200384, 87Green New Deal and\u200397hyperpartisanship and\u2003209#KnowTheFacts on\u2003114, 123, 128mainstream compared to problematic \nsources on\u200393\u201394 , 96\u201397\npartisanship and\u200319polarization on\u200392, 101policies of\u2003111, 123, 124 , 128, 208\npolitical issues on\u200383, 95, 96 , 100 , 102, 102\nproblematic accounts on\u200395, 97\u201398problematic information and\u200318, 84\u201387, 110retweets on\u200326, 84, 101\u20133, 131Trump, D., on\u200385, 91, 115, 117, 127 , 128\nusers of\u200395, 98\u201399 , 101\nU.S. presidential elections and\u200317\u201319, \n85\u201387\nTwitter Capture and Analysis Toolkit\u2003102, 129\nUkraine, war in\u2003210\nuncertainty\u200312\u201314\nCOVID-19 and\u2003111\nunique sources, in Google Web Searches\u200339, \n40\u201341\nUnited States (U.S.)\u200338, 131, 173\nplatforms based in\u200310, 67polarization in\u2003167, 169political unrest in\u200335sources outside\u200361users based in\u200376\nin de X 245\nuserleansbot, partisanship and\u200376\u201377\nusers\nactivity analysis of\u200398\u2013100 , 142\u201343, 158\nbased in U.S.\u200376categorization of\u2003103, 151 , 158\ndigital methods and\u2003142\u201343, 158of Twitter\u200395, 98\u201399 , 101\nvaccines\u2003123, 140, 142\nPfizer\u2003115\nVega, Cecilia\u2003196verified accounts, on Instagram\u2003141, 150 , 155 , \n159\nvernacular see also  \u201cdeep vernacular web\u201d\nof 4chan\u2003165\u201367, 169\u201372, 173 , 176\nmemes and\u200316, 166methodology and\u200311, 155\u201356\nvideos\u200371\u201372\ncoding schemas for\u2003202\u20133documentary\u200374\u201375from TikTok\u2003191 , 194 , 196\u201398\nviral news\u200390, 91vocabulary, right-wing\u2003172\u201373, 173\u201374 , 177, 180\nvoters\nfraud and\u2003190, 199liberal\u2003175support services for\u200342, 101\u20132Trump, D.\u2003167U.S. presidential elections and\u2003154 , 190Wahl-Jorgensen, K.\u200391\u201cWait for it\u201d (TikTok video)\u2003196Wardle, Claire\u2003199Wayback Machine\u2003112web history\u200311, 23\nfringe contributions and\u200312\nwebsites see also  sources\ncategories of\u200322\u201323, 37, 38 , 40, 53, 86, 92, \n102\nhyperpartisan\u200336, 39, 208official source\u200334, 44pink slime\u200320, 62special interest\u200337, 40\u201341, 44\n\u201cWhen I can attract both genders\u201d (TikTok \nvideo)\u2003 198\nwhistle-blowing\u2003209WHO see  World Health Organization\nWikipedia\u200318, 23\nin methodology\u200322, 43, 62, 129\u201330\nWired  (magazine)\u2003196, 197\n\u201cwisdom of the crowd\u201d\u200312, 23, 26World Health Organization (WHO)\u2003110\ndebunking by\u2003115hydroxychloroquine and\u2003117\nYiannopoulos, Milo\u2003168youth, TikTok and\u200310, 14YouTube, Reddit and 4chan linking\u200316\u201317, \n67\u201368, 71, 72 , 73\u201374\nYouTube Data Tools\u200379\n\nThere is growing awareness about how social media circulate extreme \nviewpoints and turn up the temperature of public debate. Posts that exhibit agitation garner disproportionate engagement. Within this clamour, fringe sources and viewpoints are mainstreaming, and mainstream media are marginalized. This book takes up the mainstreaming of the fringe and the marginalization of the mainstream. In a cross-platform analysis of Google Web Search, Facebook, YouTube, Reddit, Twitter, Instagram, 4chan and TikTok, we found that hyperpartisan web operators, alternative influencers and ambivalent commentators are in ascendency. The book can be read as a form of platform criticism. It puts on display the current state of information online, noting how social media platforms have taken on the mantle of accidental authorities, privileging their own on-platform performers and at the same time adjudicating between claims of what is considered acceptable discourse.\nRichard Rogers, PhD, is Professor of New Media and Digital Culture, Media \nStudies, University of Amsterdam, and Director of the Digital Methods Initiative. He is author of Information Politics on the Web and Digital Methods (both MIT Press) and Doing Digital Methods (SAGE).\nAU P. n lISBN: 978-94-6372-076-2\n9789463 720762Rogers (ed.) The Propagation of Misinformation in Social Media", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "1 \u201cSerious queries\u201d and \u201ceditorial epistemologies\u201d", "author": ["R Rogers"], "pub_year": "NA", "venue": "edia", "abstract": "The following concerns the \u201cmisinformation problem\u201d on social media during the run-up to the  2020 US presidential election. Employing data journalism techniques, it develops a form of"}, "filled": false, "gsrank": 795, "pub_url": "https://library.oapen.org/bitstream/handle/20.500.12657/61940/1/9789048554249.pdf#page=10", "author_id": ["pt6XuMYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:enAanE6byN4J:scholar.google.com/&output=cite&scirp=794&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D790%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=enAanE6byN4J&ei=lrWsaPi1IL_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:enAanE6byN4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://library.oapen.org/bitstream/handle/20.500.12657/61940/1/9789048554249.pdf#page=10"}}, {"title": "The Calais Crisis in The Guardian and The Times: An Analysis of Britain's Media Perspective in June-July 2015", "year": "2015", "pdf_data": "Volume II, Spring 2017\nInternationalist\nUnder graduate Journal of Foreign  Affairs\n\nThe Internationalist\nUndergraduate Journal of \nForeign Affairs\nUniversity of North Carolina at Chapel Hill\nVolume II Spring 2017 Issue 1\nThe Internationalist Staff\nEditor-in-Chief\nChristian Haig\nManaging Editors\nCara Schumann\nMichael Ligouri\nStaff Editors\nSasha Gombar\nEmma Verdi\nEmily Venturi\nMichael Purello\nMark Burnett\nEmily Rand\nThe Internationalist would like to thank the Carolina Global Photography Competition and Ingid Smith, for \nallowing us to use the photographs  featured in this journal. We would also like to thank the photographers \nJoseph Taylor, Natalie Scott, Caroline Weber, Robert Gourley, Carolina Valder Grace, Laura Cowan, Ryan \nSeguin, Dana Leah Walker, Parker Owen Vige, Amanda Schroeder, Grace Ann McGlaughlin, Andrew McCarthy, \nand Kate Hewitt for taking the photographs featured here and approving of their publication.\nCover Photo:\nTangier, Morocco- During my time studying abroad in Spain, I went on many excursions discovering new people, places, \nand cultures. One of these excursions led me to the country of Morocco. While on a guided tour in Morocco, we made a \npit stop at this beautiful location where both the Mediterranean Sea and the Atlantic Ocean meet the heavens. The paths \nconverge in such a seamless way. Their beauty is captivating. (Photo by Natalie Scott, \u201817)Production Editor\nDenton OngExecutive Editor\nRebecca Price\nTable of Contents\nThe Deadliest Terrorist Organization in the World: The \nFramework, Failure, and Future of Boko Haram\n By Justin Cole\nOrban\u2019s Illiberal Democracy and its Restrictions on Liberty\n By Madeline Hatcher\nWhat is the price of citizenship? - A look into Malta\u2019s \ncitizenship-by-investment program\n By Matthew Watts\nLeaderless Jihad: Changing Patterns in a New Era of \nModern Terrorism\n By Joseph Petrovic\nThe Black Panthers of Israel\n By Brian Fields1\n6\n13\n18\n26\nThe Democratic Republic of the Congo: Insecurity and \nConflicts of Belonging\n By Morgan Pratt30\nThe Calais Crisis in The Guardian and The Times: An \nAnalysis of Britain\u2019s Media Perspective in June - July 2015\n By Sofie Senecal39\n\nThe Dispute, Background, \nand Strategic Violence of \nBoko Haram\n   Boko Haram was founded by Moham -\nmed Yusuf as a Sunni fundamentalist \ngroup in 2002 on the view that the current \nstate systems in Nigeria were illegitimate \nand therefore did not deserve to retain \nmonopolies on political and military pow -\ner.3 As a result, the primary goals of this \nterrorist group are quite clear: to elimi -\nnate these states and institute a caliphate \nto replace them. The precise structure of \nthis caliphate remains unclear given that \nBoko Haram is more of a loose, divided \nnetwork of cells as opposed to a strong \nhierarchical organization with clear policy goals.4 Despite these extreme5 objectives, \nBoko Haram did not engage in violence \nfor the first seven years of its existence. \nHowever, the growing radicalization of \nthe group eventually prompted a Nigerian \npolice investigation on July 26, 2009. This \nresulted in a minor confrontation between \nthe two groups which eventually sparked \na massive military retaliation.6 Hundreds \nof Boko Haram members were killed and \nYusuf was allegedly executed while in \npolice custody.7 \n   Despite this setback, the group quickly \nexperienced a resurgence under its current \nleader, Abubakar Shekau, after a massive \nprison break in Bauchi. In 2011, the still \nrelatively weak group resorted to targeting attacks against vulnerable civilians with \nimprovised explosive devices. These initial \nattacks can be explained in two ways. \nFirst, Boko Haram needed to signal that \nit had the necessary resolve to achieve its \npolitical demands. The group did not have \nthe capability to directly engage with the \npowerful Nigerian army so it was forced \nto use violence against civilians to send a \nseries of costly signals, a process that Kydd \nand Walter refer to as attrition.8 Second, \nBoko Haram needed to demonstrate to \ncivilians that its threats could be carried \nout, which set the foundation for the group \nto eventually use coercion as a means of \nachieving collective action.9\n   As its capabilities increased, the organiThe Deadliest Terrorist \nOrganization in the World: The \nFramework, Failure, and Future of \nBoko Haram\nOn April 14, 2014, the terrorist organization Boko Haram sparked international uproar when it kid -\nnapped almost three hundred schoolgirls from Chibok, Nigeria and forced them into marriages with \nthe insurgents. Although the incident garnered a great deal of attention from the international com -\nmunity, this was not the first time that Boko Haram had engaged in unspeakable acts against civilians. \nSince its resurgence in 2010, it has killed at least 20,000 people and displaced an additional 2.3 million.1 \nUnsurprisingly, the Global Terrorism Index classified it as the deadliest terrorist organization in the \nworld in 2015.2 This paper presents a critical analysis of Boko Haram and its rise to power in order to \nanswer the question: What are Boko Haram\u2019s political objectives and to what extent has the group been \nsuccessful in achieving its goals? This question can be answered through a review of the organization\u2019s \nbackground, through discussion of its desires to form an Islamic caliphate in the Sahel region to replace \nthe current state system, and through an analysis of the types of violence it uses against civilians. It is \nalso important to examine how Boko Haram has achieved collection action. This investigation finds \ncollective action achieved through the conscription of villagers, through imposing strict barriers of en -\ntry, and through exploiting the indiscriminate violence carried out by the Nigerian military. This paper \nfinds that the terrorist group has not been successful in its ultimate political objective and argues that \na settlement with Boko Haram will not be possible due to the group\u2019s dynamics. It also hypothesizes \nthat this terrorist organization will not return to its former level of strength in the future because of \nthe growing effectiveness of the Nigerian military under newly elected president Muhammadu Buhari.By Justin Cole\nJunior Peace, War and Defense MajorThe Internationalist            Vol. II, Spring 2017\nzation grew bolder. Following the inau -\nguration of Nigerian President Goodluck \nJonathan on May 29, 2011, Boko Haram \nbombed the capital of Abuja in an act of \nindiscriminate violence against the new \nadministration. In northern cities, the ter -\nrorist organization relied more heavily on \nassassinations and the specific targeting of \npolice officers in an effort to minimize the \ncasualties of potential supporters. Suicide \nbombings and other types of indiscrimi -\nnate violence would be far more likely to \nalienate the local population against Boko \nHaram.\n   In total, Boko Haram engaged in 115 \nattacks in 2011 that killed 550 people,10 \nprompting Jonathan to declare a state of emergency at the end of the year. How -\never, this action only produced increased \nviolence. Just three weeks into 2012, Boko \nHaram launched a vicious attack on police \nbuildings in Kano that killed 190 people.11 \nMeanwhile, the Nigerian military was \naccused of numerous human rights abuses \nin their attempts to combat the terrorist \ngroup which didn\u2019t help the military gain \npopular support against Boko Haram.12 \nPresident Jonathan failed to rescue the kid -\nnapped girls from Chibok and to prevent \nskilled militants from taking control of \nhuge portions of territory in the north -\nern territory of Nigeria. In January 2015 \na \u201cMultinational Joint Task Force\u201d which \nconsisted of soldiers from Nigeria, Chad, Cameroon, Niger and Benin came together \nin an organized effort to weaken Boko Ha -\nram.13 By the end of the year, the terrorist \norganization had been beaten back and \ndriven from most of its territory. Contrary \nto the claims of current Nigerian President \nMuhammadu Buhari, however, the group \nhas not been defeated.14 In fact, there is ev -\nidence that it has recently begun to escalate \nits attacks in a desperate attempt to deter \ncivilians from siding with the government. \nBoko Haram was behind a devastating \nattack near Maiduguri, Nigeria that killed \neighty-six people this past December.15 It \nis clear that even the success of the Task \nForce\u2019s military efforts have not completely \ndestroyed Boko Haram. \nJoseph Taylor, \u201818\nThis past winter, I was given the opportunity to explore one of Iceland\u2019s natural wonders, a cave formed naturally out of \nice. This particular ice cave is located inside of Vatnaj\u00f6kull, Iceland\u2019s largest Ice cap. Each year the ice cave will melt and \nentirely new one will form. I chose to photograph the caves only source of light, a spiraling ice tunnel that was carved \nsolely by flowing water.The Internationalist            Vol. II, Spring 2017\n2\nHow Boko Haram Has \nProduced Collective Action\n   A recent report by the Council on For -\neign Relations declared that the origins of \nBoko Haram \u201cappear rooted in grievances \nover poor governance and sharp inequal -\nity in Nigerian society. \u201d16 African analyst \nChris Ngwodo goes even further, arguing \nthat the terrorist group \u201cis a symptom of \ndecades of failed government and elite \ndelinquency finally ripening into so -\ncial chaos. \u201d17 However, in reviewing the \nexisting literature on grievances and civil \nwar\u2013which commonly espouse ties be -\ntween the two\u2013it seems clear that even the \npresence of severe grievances in Nigeria \nare not enough to compel collective groups \nof individuals to commit violence. Collier \nand Hoeffler note that \u201cgrievance-assuage -\nment is predominantly a public good, \u201d18 \nwhich is more difficult to overcome when \nrecruiting because of the collective action \nproblem. It is also important to note that \na comprehensive study performed by \nFearon and Laitin on the causes of civil \nwar found no evidence that \u201ccivil war will \nbreak out where broad political grievances \nare strongest. \u201d19 Boko Haram instead has \nrelied on threatening villagers, instituting \nsteep barriers for entry and exploiting the \nindiscriminate military response of the \nNigerian army. \nCoercion\n   One of the most common methods \nterrorist organizations use to recruit is \ncoercing members through violent threats. \nBoko Haram has employed this strategy \nwith great effectiveness. When the terrorist \ngroup held a significant amount of terri -\ntory, it would resort to lining up people in \nthe villages that it controlled and ordering \nthem to join or be killed.20 Boko Haram \nhas also relied heavily on the forcible \nrecruitment of both women and children. \nAccording to an estimate by Amnesty \nInternational, it has likely kidnapped at \nleast two thousand women, many of whom \nwere forced to take part in the group\u2019s \nviolent activities.21 Not only has Boko \nHaram utilized female suicide bombers \nto an alarming degree, it has even trained \nsome of its abducted women to become \nfighters. In fact, a group of women known \nas the Chibok girls have committed some \nof the worst atrocities of the conflict.22 \nAbducted children have also played an \nimportant role in Boko Haram. Given that children tend to question authority \nfar less than adults, they are more easily \nmanipulated into committing devastating \nattacks. Shockingly, in the past two years, \napproximately 20% of the suicide attacks \nundertaken by Boko Haram were carried \nout by children.23 Without a doubt, Boko \nHaram has been able to leverage its brutal \nreputation to effectively threaten much \nof northern Nigeria to comply with its \ndemands. \nSteep Barriers to Entry\n   Boko Haram is an extremely religious \norganization that adheres to a very \nfundamentalist brand of Islam. There \nare two significant barriers that must be \nsurpassed before joining Boko Haram. \nLike other militant religious organizations, \nprospective members must make a series \nof religious sacrifices to ensure that their \ndevotion is sufficient.24 Perhaps more \nimportantly, many individuals are given \ntests of loyalty before they are permitted to \nbecome members. For example, the attacks \nfollowing Jonathan\u2019s presidential inaugura -\ntion in 2011 were perpetrated by Nigerian \nsoldiers who needed to prove they were \nserious about defecting.25 These sorts of \nviolent tests of loyalty are not limited to \nwilling members. In order to combat the \npossibility of conscripted members turning \non their captors, Boko Haram has forced \nkidnapped individuals to commit murder \nor other acts of violence so as to make \nthem feel isolated from normal society, \nbinding them closer to the organization.26 \nThese barriers to entry help to ensure that \nthose members who do manage to join \ncan be trusted to carry out Boko Haram\u2019s \norders. \nThe Indiscriminate Violence of the \nNigerian Military\n   Through its use of indiscriminate vio -\nlence against civilians, the Nigerian mili -\ntary has contributed to the growth of Boko \nHaram. The corruption in the Nigerian \nmilitary has made it nearly impossible to \ngather sound intelligence on Boko Haram, \nforcing the army to \u201ctake vengeance on the \nwhole civilian population. \u201d28 In its Annual \nReport in 2012, Amnesty International \naccused Nigeria of killing hundreds of \ninnocent civilians in counterattacks against \nBoko Haram. Just a year later, Human \nRights Watch made similar claims.29As \na result, the terrorist organization has \nmanaged to increase its numbers despite the fact that the vast majority of Nigerians \nabhor its actions.30 In some respects, the \nNigerian military has been its own worst \nenemy as it is has allowed Boko Haram to \nleverage the army\u2019s deficiencies and gain \nsupport for the terrorist group.\nThe Failure of Boko Haram \nand the Unlikely Nature of \nNegotiation\n   At this point, neither its brutal slaugh -\nter of civilians nor its temporary seizure \nof territory have allowed Boko Haram \nto achieve its ultimate political objective \nof overthrowing the states in the region. \nThere have also been no attempts at nego -\ntiating a settlement between Boko Haram \nand the governments in the region. There \nare two possible explanations for this: issue \nindivisibility and the dynamics of Boko \nHaram itself.\n   An indivisible good is one that cannot \nbe divided without causing a reduction \nin its worth. In some respects, it seems as \nthough the control of the Nigerian govern -\nment is indivisible; it cannot simultaneous -\nly exist as an Islamic state as envisioned by \nBoko Haram and retain its current status \nas a democratic republic. However, Fearon \nand many other political scientists do not \naccept the validity of this principle.31 The \nissue of governmental control is far more \ncomplex than the simple picture paint -\ned above: Boko Haram could be given \npolitical representation in the current \ngovernment;32 part of the country could be \nclassified as an Islamic state; or leadership \ncould alternate between members of Boko \nHaram and the current policymakers. The \nexistence of these scenarios suggests that \nnegotiations are hindered not by issue in -\ndivisibility, but by a different phenomenon.\n   Boko Haram is best viewed as a cell \nnetwork rather than a formal hierarchy \nwhich has led to some divisions within the \norganization, particularly between nation -\nalists and those more focused on regional \nties with other terrorist groups.33 Although \nShekau has been able to maintain his rel -\natively uncontested status as the leader of \nBoko Haram, he does not possess complete \ndominance.34 A game theory model laid \nout by Best and Bapat explains why this \nsituation will be unlikely The Internationalist            Vol. II, Spring 2017\n3\nto lead to negotiations.35 If Shekau did \nattempt to negotiate, he would potential -\nly spark infighting by rival cells, which \nwould ultimately lead to a weakened Boko \nHaram that would be far more vulnerable \nto defeat.36 Seeking to avoid this, Shekau \nhas no incentive to enter into a settlement. \nThis theory is supported by two important \npieces of empirical evidence. First, Shekau \ndeviated away from the domestic focus \nof Boko Haram by pledging allegiance to the Islamic State in Iraq and Syria \njust about a year ago. Not only does this \nsuggest that the terrorist organization is \nlosing strength, it may mean that Shekau \nis attempting to appease certain factions \nwithin Boko Haram. Second, Shekau \nhas taken steps to \u201csilence] pro-dialogue \nindividuals, \u201d37  indicating that he is taking \naction against the pursuit of negotiations. \nIn summary, it is not indivisibility, but the \ninternal politics of Boko Haram that are likely to make negotiations difficult \nto achieve.\nThe Future of Boko Haram\n   Although this situation will likely \nnot be resolved through negotiations, \nit is possible to predict what the \nfuture of this terrorist organization \nwill be. It is very unlikely that Boko \nHaram will be completely defeated in \nthe near future. Unlike in a hierar -\nchical structure\u2013where eliminating \ntop leaders could quickly lead to the \ncollapse of the organization\u2013killing \nShekau or other leaders in Boko \nHaram will not destroy the organiza -\ntion. Just as the death of Yusuf only \ntemporarily weakened Boko Haram \nin 2009, the system of relatively \nloose connections between different \ncells will ensure the durability of the \ngroup. However, it will likely not \nreturn to its former level of strength. \nAlthough certain characteristics of \nNigeria\u2013such as poverty, rough ter -\nrain, and a large population\u2013do make \nit vulnerable for a return of a Boko \nHaram insurgency, this terrorist or -\nganization would have to once again \novercome the immense problem of \ncollective action. Given the recent \nelection of President Buhari, how -\never, this looks unlikely. It has been \nwidely believed that Buhari will likely \nbe more effective than his predeces -\nsor in maintaining the security of \nthe country. Buhari\u2019s inauguration \nceremony coincided at a time when \nthere was greater cooperation be -\ntween Nigeria and its neighbors and \nthe Multinational Joint Task Force \nhad achieved some success.38 Even \nmore recently, Buhari secured a deal \nin which the United States would re -\nsume a training program for the Ni -\ngerian army that had previously been \nterminated under President Jonathan.39 \nThis should increase the combat effective -\nness of Nigerian soldiers, which should \nallow them to more effectively protect \ncivilians who are vulnerable to coercion by \nBoko Haram. Perhaps more importantly, \nthe United States has agreed to coordinate \ninformation sharing, which will allow the \nNigerian army to launch counterterror -\nist strikes with more precision and \nCaroline Weber, \u201817\n\u201cThis photo was taken at Waiotapu, M\u0101ori for sacred waters, in Rotorua, New Zealand. \nA combination of minerals and silicate gives the \u201cChampagne Pool\u201d pictured here its \nunique color. I was fascinated to learn all about this active geothermal reserve and \nhow it has evolved over the past 900 years.\u201dThe Internationalist            Vol. II, Spring 2017\n4\nminimize the collateral damage of terrorist \nstrikes.40 With a decreased ability to cap -\nitalize on the flaws of the Nigerian army, \nBoko Haram will be less likely to achieve \nits political objectives. \nConclusion\n    Although it has even briefly held signifi -\ncant swathes of territory, Boko Haram has \nnot achieved its main objective of over -\nthrowing the state systems in the Sahel re -\ngion and replacing them with a caliphate. \nThis is due to the fact that Boko Haram is \na relatively flat network in which negotia -\ntions could lead to infighting which makes \na settlement unlikely. However, Boko \nHaram has been able to achieve collective \naction through coercion, steep barriers to \nentry, and through exploiting the violence \ncarried out by the Nigerian army. This has \nallowed the group to launch a variety of \nboth targeted and indiscriminate attacks \nthat have killed thousands of people in the \nhopes of achieving its political objective. \nDespite recent setbacks to its power, Boko \nHaram is unlikely to overcome the col -\nlective action problem to the same extent \nthat it previously has. Unfortunately, the \nterrorist organization is also unlikely to be \ndestroyed for many years to come. \nCitations\n1. Al Jazeera, \u201cDeadly Boko Haram Attacks \nin Northeastern Nigeria\u201d , para. 9.\n2. Institute for Economics and Peace, \n\u201cGlobal Terrorism Index\u201d , 2.\n3. National Consortium for the Study of \nTerrorism and Responses to Terrorism, \n\u201cBoko Haram Recent Attacks\u201d , 2.\n4. Ibid., 3.\n5.The use of the word \u201cextreme\u2019 here does \nnot aim to make any moral judgment; \nrather, it uses a classification of extremism \ndefined by Lake in which the political pref -\nerences are not widely shared and those \nindividuals who do possess them lack the \nmeans of power to obtain them. Lake, \n\u201cRational Extremism - Understanding \nTerrorism in the Twenty-First Century\u201d , \n17-19.\n6. Adesoji, \u201cThe Boko Haram Uprising and \nIslamic Revivalism in Nigeria\u201d , 98.\n7. Ibid., 98.\n8. Kydd and Walter, \u201cThe Strategies of \nTerrorism\u201d , 59-60.\n9. Ibid., 66.10. Kimemia, Africa\u2019s Social Cleavages and \nDemocratization, 146\n11. Oboh, \u201cIslamist insurgents kill over 178 \nin Nigeria\u2019s Kano\u201d , para. 1.\n12. International Coalition for the Respon -\nsibility to Protect, \u201cThe Crisis in Nigeria\u201d , \npara. 11-14.\n13. News Express, \u201cBoko Haram Suffers \nHeavy Defeat in Surprise Attack on Mili -\ntary Base\u201d , para. 1.\n14. Anon, \u201cNigeria Boko Haram: Militants \n\u2018technically defeated\u2019 \u2013 Buhari\u201d , para. 1.\n15. Gaffey, \u201cBoko Haram: Nigerian Army \nInvestigates Recent Attacks\u201d , para. 2\n16. Sergie and Johnson, \u201cBoko Haram\u201d , \npara. 13.\n17. Ibid., para. 13.\n18. Collier and Hoeffler, \u201cGreed and Griev -\nance in Civil War\u201d , 12.\n19.Fearon and Laitin, \u201cEthnicity, Insurgen -\ncy, and Civil War\u201d , 75.20.\n20. Chothia, \u201cBoko Haram Crisis: How \nHave Nigeria\u2019s Militants become so \nStrong?\u201d , para. 8.\n21. Amnesty International, \u201cNigeria: \nAbducted Women and Girls Forced to Join \nBoko Haram Attacks\u201d , para. 1.\n22. Amnesty International, \u201cNigeria: \nAbducted Women and Girls Forced to Join \nBoko Haram Attacks\u201d , para. 1.\n23. Rifai, \u201cBoko Haram Attacks with Chil -\ndren \u2018Suicide Bombers\u2019: UN\u201d , para. 2.\n24. Berman, Radical, Religious, and Vio -\nlent - The New Economics of Terrorism, 16\n25. Berman, Radical, Religious, and Vio -\nlent - The New Economics of Terrorism, 16\n26. Murdock, \u201cNigeria\u2019s Boko Haram Forc -\nes Victims to Fight, Kill\u201d , para. 10-11.\n27. African Studies Centre, Boko Haram: \nIslamism, Politics, Security and the State in \nNigeria, 25.\n28. Amnesty International, \u201cThe State of \nthe World\u2019s Human Rights\u201d , 256.\n29. Human Rights Watch, \u201cWorld Report \n2013: Nigeria\u201d , para 1-2, 7-9.\n30. According to a recent poll by the Pew \nResearch Center, \u201ceighty-two percent of \nNigerians have an unfavorable view of \nBoko Haram, with seventy-nine percent \nholding a very unfavorable view. \u201d Poushter, \n\u201c6 Facts about Public Opinion in Nigeria \nbefore Election Day\u201d , para. 4.\n31. Fearon, \u201cRationalist Explanations for \nWar\u201d , 382, 408.\n32. Forty-three percent of terrorist groups \nend by reengaging in normal politics; thus, \nit would not be unusual for Boko Haram to be given this privilege. Jones and Libicki, \nHow Terrorist Groups End - Lessons for \nCountering Al Qa\u2019ida, 19.\n33. Bapat and Best, \u201cBargaining with Ter -\nrorists in the Shadow of Infighting\u201d , 13.\n34. Ibid., 13.\n35. Ibid., 5-11.\n36. Ibid., 14.\n37. Ibid., 14.38.\n38. Ugwuanyi, \u201cBuhari\u2019s four weeks in \noffice better than Jonathan\u2019s entire tenure\u201d , \npara. 8-10.\n39. Olorunyomi, \u201cUS Resumes Training \nof Nigerian Troops for Anti-Terror War\u201d , \npara. 1\n40. Ibid., para. 6.The Internationalist            Vol. II, Spring 2017\n5\nS ince Fidesz\u2019s landslide victory in 2010, \nHungarian Prime Minister Viktor Orban \nand his party have been able to consolidate \na large degree of power in a particularly \nundemocratic way. This systematic dem -\nolition of a liberal democracy has come \nas a bit of surprise for the international \ncommunity. During and immediately fol -\nlowing the EU accession process, Hungary \n\u201cwas consistently ranked among the most \nadvanced post-communist transforma -\ntion countries, \u201d supporting the general \nexpectation that \u201ccountries far along in the \ntransformation process [would be] most \nlikely to comply with EU rules\u201d . Its \u201cgou -\nlash communism\u201d had allowed Hungary to \nbe the most liberal of the Soviet bloc states \nand transition peacefully into democratic \nrule. In addition, \u201cthe media, judiciary, and \nbusiness sector appeared to be sufficiently \nindependent\u201d to ensure Orban\u2019s coopera -\ntion with the rules.\n   However, it soon became apparent that \nthe positive outlook echoed by both the \nHungarian government and the EU had \nbeen too optimistic. Less than twenty years \nafter gaining EU membership, Hungary \nseems to be in the midst of a democratic backslide, largely due to Orban\u2019s restric -\ntive policies, particularly in relation to the \nmedia and legal institutions. This paper \nwill take a closer look at the implications \nof such legislation, analyzing the extent to \nwhich the EU is able to enforce the rules \nof the democratic playbook once accession \nhas occurred. However, in order to under -\nstand the implications of Orban\u2019s regime \nfor the future of Hungarian democracy, it \nis imperative to first take into account the \nconditions that were perfectly primed for \nOrban\u2019s political takeover in 2010.\nHow was Orban Able to \nSecure Power?\n   What factors can be used to explain such \na sharp decrease in the legitimacy of Hun -\ngarian democracy, so soon after its estab -\nlishment? One possible explanation is that \nthe EU is simply not \u201cequipped to address \nthe massive socioeconomic disruptions of \nthe transformation process, such as rising \nincome inequality and unemployment\u201d . \nThe EU\u2019s status as a supranational entity \nmeans that it lacks a strong enforcement \nmechanism; in addition, it prevents the \nEU from intervening in certain affairs of its member states, such as individual \neconomic issues. Hungary\u2019s economy, \nwhich was already weak, was extremely \ncrippled by the 2008 financial crisis and its \ninternational implications. This was largely \ndue to the fact that in 2007, most countries \nin the midst of EU accession were either \nburdened with high external debt from \ninternational banks or high government \ndebt. Hungary was the only country to \nhave both of these financial problems.\n   In conjunction with the fractured econo -\nmy, the main explanation for Orban\u2019s 2010 \nsuccess can be attributed to the breakdown \nof the Socialist Party, which had been the \nruling party for eight years; it fell prey to \nscandal and debt, and has been unable \nthus far to recover enough to topple the \nOrban regime. This political windfall pro -\nvided a major boost to Orban\u2019s campaign, \nas the other left-leaning parties splintered \nand, consequently, lacked the cohesion \nnecessary to sustain any serious opposition \nto Orban. The combination of a fragile \neconomy, equally unstable political climate \nand EU accession stress acted as the driv -\ning force behind Orban\u2019s massive sweeping \nof the votes in the election. However, it has \nbeen his manipulation of the legislative Orban\u2019s Illiberal Democracy \nand its Restrictions on Liberty\nAs a country that emerged from the throes of Soviet control primed to accept and integrate liberal de -\nmocracy, the Hungary we see now exhibits few of these characteristics and indeed seems to be moving \nin a regressive manner. Prime Minister Viktor Orban and his supporters have amassed an incredible \namount of political power and leverage, leading to restrictions on free speech and unbiased media \nsources, as well as almost unrestrained corruption at all levels of government. Hungary\u2019s accession to \nthe European Union in 2004 has done little to actually combat this illiberal form of modern democ -\nracy with its lack of enforcement mechanisms, suggesting that the Orban administration, and those \nthat follow, will be unlikely to change course anytime soon. The Orban regime\u2019s political clientelism, \ndestructive reforms to Hungarian legislature, and unwillingness to adapt to democratic standards \nhave severely hindered the country\u2019s ability to fully transition from a former Soviet satellite state to a \nfunctioning European nation. These challenges will likely continue to impede Hungary\u2019s progress for \nthe foreseeable future, highlighting the difficulties of a democratic transformation in a country plagued \nby its history of corrupt politics and unfree citizens.By Madeline Hatcher\nSenior Political Science, Global Studies Major, Philosophy, Politics, Economics MinorThe Internationalist            Vol. II, Spring 2017\nprocess and defiance of democratic regu -\nlations that have enabled him to effectively \nblock any form of opposition before it even \narises.\nThe Current Hungarian \nSituation\n   Since Hungary\u2019s EU accession, the \ninternational view of the country has only \ncontinued to sink further and further. One \npolitical commentator has portrayed Hun -\ngary\u2019s political reality as a \u201cFrankenstate, \u201d \nthe pieces of which \u201cmight have operated \nperfectly well in their original contexts, but \ncombined in a new constitutional system, \nthese once-normal rules produce abnor -\nmal results\u201d . This so-called \u201cFrankenstate\u201d \nhas tried to maintain norms that were \nacceptable in pre-1989 Hungary, but are \nnot compatible with modern democratic \nvalues. Why haven\u2019t Orban and the Fidesz \nleaders been under greater scrutiny for \ntheir mistreatment of democracy? Or -\nban openly disavows the importance of \nmaintaining a democratic rule of law in \nHungary in his assertion that \u201cliberal \ndemocratic societies cannot remain globally competitive\u201d . This controversial \ncomment acts as a justification for Orban\u2019s \npolitical actions thus far during his term, \nand highlight the lacking transition to EU \nmembership with only partial implemen -\ntation of democratic values.\n   As this paper will discuss, Orban\u2019s regime \nhas primarily inhibited Hungarian citizens \nfrom exercising their right to free speech \nand has undermined the upholding of \nconstitutional values of the legal system. \nWhile the EU has attempted to force \nOrban to change his ways, it seems that \nHungary\u2019s political climate has changed lit -\ntle, highlighting the inconsistencies of the \nEU\u2019s enforcement abilities and the depth of \nHungary\u2019s issues. Is it reasonable to agree \nwith the many \u201cpolitical scientists, pundits, \nand journalists in Hungary and abroad\u201d \nwho claim that, in light of Orban\u2019s policies, \nHungarian democracy has died after only \ntwenty years. Though Hungary has made \nsignificant improvements since joining \nthe EU, Orban\u2019s regime is part of a larger \nproblem of institutionalized corruption \nand disregard for ethical conduct.Limitations on Free Speech in \nthe Media\n   Orban\u2019s administration has been subject -\ned to much critique since its rise to power, \nin particular for its restrictive control of \nthe media and the negative social effects \ncreated as a result. One of the first major \npolicy actions taken by Orban in the early \nstages of his term, without consulting ei -\nther the opposition parties or relevant or -\nganizations has drawn wide criticism from \nmultiple leaders and institutions within the \ninternational community. In January 2011, \na new media law was passed, a precedent \nthat \u201chanded Viktor Orban the Sword of \nDamocles to hold over the head of Hunga -\nry\u2019s free media\u201d . This legislation granted the \ngovernment the ability to impose heavy \nfines and potentially cause media outlets \nto become bankrupt if they did not choose \nto comply with the government\u2019s idea of \nacceptable material. The law certainly \nseemed to be a revival of the strict cen -\nsorship of the Communist regime with its \nrestrictions on personal liberty and expres -\nsion. Orban\u2019s law also established a Media \nCouncil tasked with overseeing regulation \nRobert Gourley, \u201818\nAnnapurna, the eighth-tallest mountain in the world, rests beneath the stars on a clear night. All stars in the sky rotate \naround the North Star, which appears to be stationary. To capture this spin, this exposure lasted 30 minutes. I was working \non an independent project in rural Nepal when I took this photograph.The Internationalist            Vol. II, Spring 2017\n7\nof publication outlets; unsurprisingly, all \nmembers of this Council were appointed \nby the Fidesz- controlled Parliament.  As \na means of further extending the party\u2019s \ninfluence within the public media sphere, \nthe law also established a term length of \nnine years for the Council Chair and its \nmembers, exceeding two parliamenta -\nry cycles. This symbolizes the pervasive \nnature of Orban\u2019s policies; even if the Fi -\ndesz-controlled parliament was somehow \nousted from power, Orban has ensured \nthat his authoritarian legacy will live on. \nWhile the law may have appeared to be \nmore of a guiding force than anything \nelse, Orban\u2019s intentions soon became clear, \nas many people in related fields began to lose their jobs for speaking out under the \nflimsy guise of protecting the people. Attila \nMong is just one example; she had been a \npopular radio host of a government-owned \nstation, but after conducting a minute of \nsilence in protest of the media law she was \nsuspended and never got her job back.\n   The implications of this media law, as \nwell as the serious nature of the situation, \ncannot be overstated. Here is an overt \nattack on personal liberty and the right \nto freedom of speech, and yet there has \nnot been a substantial public outcry in re -\nsponse.  Kounalakis wonders, \u201cHow could \na law be enacted without public debate \nor even giving the opposition a chance \nto evaluate the law?\u201d , and this has indeed been the central question of the contro -\nversy surrounding the legislature. While \nthe law still remains intact, keeping these \nrestrictions firmly in place, observers have \nbegun to draw attention to the situation. \nFor instance, it has received \u201charsh as -\nsessments from the European Parliament, \nthe European Commission, the United \nNations special rapporteur on freedom of \nexpression, the media representative of the \nOSCE, [and] the Council of Europe\u201d . See -\ning that some institutions were beginning \nto raise alarms concerning the law, Orban \nthen made some smaller agreements \naimed at convincing them that the system \nwas ethical, and should not be viewed as a \nmajor issue. Neelie Kroes, who was \nCarolina Valder Grace, \u201817\nFour hours inland from Lima, Peru, Marcahuasi sits 4,000 meters above the sea. This mysterious rock forest carries \nlegends of gods and giants. A local townsman shared stories and songs as we wandered the plateau. He crushed a local \nplant so I could breathe in its strong scent after the altitude made me faint. The fog lifted as the sun set, and I turned to \nsee this new world.The Internationalist            Vol. II, Spring 2017\n8\nthe EU Commissioner at the time, felt that \nconcerns over the media law had been \nsufficiently addressed through an exchange \nof email correspondence with the Hungar -\nian government, \u201cwhich promised to ease \nrules for foreign media and soften the rules \nagainst \u2018unbalanced\u2019 coverage and \u2018offen -\nsive\u2019 Internet content\u201d .\n   Though his statements have mollified \nsome of the negative reactions, Orban\u2019s \nexplicit limitations on free speech have \nstirred discontent among international \ninstitutions in response. Sedelmeier notes \nthat once the main independent radio sta -\ntion was withdrawn from the air, the case \nwas taken up at a Budapest court, which \ngranted the station temporary freedom \nto stay on air. However, according to the \nCouncil of Europe, this ruling still does \nnot fully comply with the EU\u2019s human \nrights standards, since the station was only \ngranted temporary freedom. While these \ninstitutions clearly disagree with Orban\u2019s \npolicies, their abilities to enforce change \nseem to be limited to chastising him with -\nout offering a real solution to the problems \nat hand.\nReforms to the Legal System\n   Exercising strict control over the media \nis not the only way in which Orban\u2019s \ngovernment has been able to diminish \nthe rights of the Hungarian citizens. The \nFidesz party has fully entrenched itself \nwithin the judicial system, giving Orban \neven more leverage over the legal decisions \nreached in Hungarian courts. According to \nresearch compiled by Freedom House, the \ndemocratic progress of Hungary\u2019s judicial \nframework and governance has worsened \nas well (Kovacs 2013, 241). From the \nbeginning of the Orban regime, it has been \nable to pass through any legislation that \nit chooses, without the threat of a strong \nopposition party to act as a constraint. In \n2010, when the Fidesz-KDNP (Christian \nDemocratic People\u2019s Party) coalition gov -\nernment came to power, it had won more \nthan two-thirds of the parliamentary seats, \na victory that \u201cempowered the government \nto execute its economic, social, and foreign \npolicy without any significant control from \nthe parliament\u201d . In addition, \u201cfrom a legis -\nlative point of view, it meant that the gov -\nernment had the power to change any laws \nor the constitution almost on a daily \nbasis according to political interests\u201d , a situation that clearly does not portray the \nideals of democracy upon which the EU \nwas founded.\n   The Orban government has made use \nof its control of Parliament, primarily \nby aggressively passing legislation that \nconcentrates power in the hands of Fidesz. \nDuring Orban\u2019s initial stint as Prime \nMinister, from 1998-2004, a total of 224 \nbills were adopted, compared with 168 and \n167 total bills in the following Medgyessey \nand Gyurcsany governments. This trend \nhas accelerated since his second victory in \n2010, and it\u2019s evident that governmental \nrestrictions placed on the legislative pro -\ncess have increasingly crippled the coun -\ntry. In the Freedom House\u2019s assessment of \nHungary\u2019s legislature, the authors remark \nthat \u201cOrban tends to appoint weak figures \nto key positions, favoring personal loyalty \nand a lack of serious political ambitions \nover professional expertise and ability\u201d . \nBacked by parliamentary support, Orban \nhas exploited his privileges as PM and \npushed through a variety of reforms and \nlaws aimed at nothing other than substan -\ntiating his seemingly limitless power.\n   One of the most striking, and perhaps \ndisheartening, examples of such reforms \ninstituted by Orban is his complete disre -\ngard for the basic tenets of rule of law and \nthe preservation of constitutional ideals, \ntwo elements found in modern democ -\nracies. For instance, in 2011, the wife of a \nprominent Fidesz politician was appointed \nas head of the judiciary for a new extended \nnine-year period, which \u201ccleared the way \nfor more direct political manipulation of \nthe courts, which had represented one \nof the last state institutions outside the \ngovernment\u2019s control\u201d . Additionally, the \nPresident of the Supreme Court, Andras \nBaka, was forced into early retirement \nostensibly because he didn\u2019t have five years \nof Hungarian judicial experience, even \nthough he had previously served as a judge \non the European Court of Human Rights \nfor seventeen years. In reality, his dismissal \nhas been linked to his public disapproval \nof the legal reforms generated by Orban \nand Fidesz.\n    The legal changes instituted by the Or -\nban administration have not stopped at the \nstrategic positioning of key legislative ac -\ntors, however. Further eroding the system \nof checks and balances in the legal system, \nthe government removed a watchdog insti -tution which had been monitoring human \nrights and the rights of minorities, replac -\ning it with the Office of the Parliamentary \nCommissioner for Fundamental Rights, \nan institution whose head executive is a \nFidesz party member.\nCorruption\n   The prevalence of corruption in Hungar -\nian government has continued to plague \nthe promotion of democracy as well. Free -\ndom House\u2019s analysis of the democratic \nprogress of Hungary\u2019s government found \nthat corruption has steadily worsened in \nthe years following EU accession. The re -\nport also notes that, in Hungarian society, \n\u201csmall-scale corruption\u2026is a widespread \nand blatant phenomenon, and many \npeople see it as a necessary part of life. \u201d  \nThe fact that Hungary\u2019s corruption score \nhas increasingly declined under Orban \nshould not come as a surprise, given the \ntactics he and his party members utilize to \nensure their political protection. A handful \nof journalists, under the protection of \nwatchdog NGOs, have been able to achieve \nsome degree of publication independence. \nHowever, they are far outnumbered, in \nboth quantity of supporters and resources, \nby Orban and his allies, who will stop at \nnothing to defend their concentration of \npower.\n   Within the existing government, there \nhas also been a large degree of bribery and \nquestionable transactions occurring be -\ntween political officials, leading to scandals \nwhich have caused Orban\u2019s former adviser \nJozsef Debreczeni to lament, \u201cIn the West \na similar scandal would have led to the fall \nof a head of government. He would have \nto resign. Not in Hungary\u201d . That isn\u2019t the \nonly monetary infraction committed by \nthe Orban government, though. After EU \naccession, Hungary had been under the \nExcessive Deficit Procedure as a means of \nmonitoring its fiscal responsibility. In re -\ncent years, however, the government began \napplying its own methods for avoiding the \nEU\u2019s regulations, by \u201cintroducing sectoral \ntaxes, eradicating private pension funds, \nand redirecting accumulated assets into \nthe budget or used to reduce government \ndebt\u201d . This further illustrates the lack of \nconstraints placed on Orban\u2019s control of \nthe state, and demonstrates the alarming \nslide towards authoritarianism taking place \nright under the nose of the EU.The Internationalist            Vol. II, Spring 2017\n9\nThe EU\u2019s Response\n   Since the beginning of Orban\u2019s cam -\npaign to accumulate power, particularly \nby threatening the rights of Hungarian citi -\nzens, it has seemed that the EU has largely \nstood by, reprimanding Orban but not \ntaking punitive action against his govern -\nment. Why has the EU not taken a more \nproactive stance in addressing the prob -\nlems associated with the Orban regime? \nZeff and Pirro, in their analysis of the EU\u2019s \nrelationship with its member states, argue \nthat, \u201cthe possibility for intervention is \nextremely unlikely given the lack of legal \npolitical instruments\u201d . The EU is best-\nknown for undertaking methods of passive \nleverage in terms of enforcement policies, generally preferring to abstain from direct \nintervention. Furthermore, it\u2019s possible \nthat Orban wasn\u2019t as harsh in his policies \nduring his first term as Prime Minister in \nthe late 1990\u2019s, because Hungary was in \nthe midst of the EU accession process. But \nonce Hungary had attained EU member \nstatus and Orban had regained his position \nas PM, he wasn\u2019t as concerned with follow -\ning EU rules, resulting in the democratic \nbreakdown observed in Hungary today.\n    The EU has had varying degrees of \nsuccess in its negotiations with Hungary \npertaining to the demonstration of dem -\nocratic ideals. As predicted by the liberal \ninstitutionalist perspective, it seems as \nthough Orban would be most inclined to \ncomply with EU standards if threatened \nfinancially. Some academics argue that \u201cthe need for external financing from the \nEuropean Union and the International \nMonetary Fund may force the leadership \nto backtrack on some of the most promi -\nnent laws that undermine democracy\u201d . On \nthe other hand, a survey conducted by the \nCorruption Research Center found that \nEU funding considerably increases the \nrisk of corruption in Central and Eastern \nEurope. This offers a partial explanation \nfor the EU\u2019s lacking response to Hunga -\nry\u2019s problems; its leaders may be unsure if \nproviding financial assistance will incen -\ntivize Orban to respect the fundamentals \nof democracy, or if it will cause a misuse of \nfunding and dependency on EU institu -\ntions that could lead to the creation of a \nseverely weak and incapable state.\n   Though the EU has encountered some \nAndrew McCarthy, \u201820\nBicycles are a popular mode of transport for getting around Amsterdam. I was lucky enough to travel to Amsterdam this \nsummer with my friends and we rented bikes to ride around town. This is a picture of a three-story bike park where we, \nand thousands of other people, locked up our bikes.The Internationalist            Vol. II, Spring 2017\ndifficulty addressing specific legislation \ndrafted under Orban, it seems to have had \nno problem bringing its complaints to the \nlegal branches of the organization, mostly \nin the form of detailed infringement pro -\nceedings.  Since May 2010, the European \nCommission has initiated over 98 infringe -\nment proceedings against Hungary. In \n2012, the Commission\u2019s main accusations \nagainst the Orban government concerned \nthe independence of its central bank and \njudiciary measures, in particular. These \nlaws were found by the Commission to be \nout of line with EU rules, meaning they \nhad to be revised or Orban be taken to the \nCourt of Justice. While official in nature, \nthe infringement proceedings seem to be \nmore formal than effective in dealing with \nthe Hungarian situation.\n   Why has Orban been able to avoid legal \nprosecution for his actions? According to \nKelemen, Orban\u2019s authoritarian actions \nare protected by the center-right faction \nof the European Parliament, the European \nPeople\u2019s Party, or EPP . For example, the \nParliament\u2019s Committee on Civil Liber -\nties, Justice and Home Affairs published a \nreport in 2013 that criticized the destruc -\ntion of basic human rights in Hungary; \nthis was soon dismissed by the EPP vice \nchair Manfred Weber for being an attack \nby the leftist parties. This instance high -\nlights the ways in which authoritarian \nregimes like Orban\u2019s are able to under -\nmine democracy within the framework of \ninstitutions such as the EU, and suggests \nthat other leaders with similar agendas \nmight also guard themselves with allies \nin order to avoid repercussions for their \nilliberal actions. In particular, Poland has \nalso been experiencing a slide towards \nauthoritarianism; Kauffmann remarks that \nboth nations, \u201conce the poster children of \npost-Communist tradition, \u201d now display \naspects of Communist-era rule, such as an \nunwillingness to share power, the produc -\ntion of conspiracy theories, and \u201cexclu -\nsionary discourse toward opponents\u201d . If \nOrban continues to openly pursue a path \nof illiberal democracy and the EU doesn\u2019t \nactively intervene, what\u2019s to stop Poland \nfrom following the same course toward \nauthoritarianism?\nConclusion\n   Immediately following the collapse \nof Communism in 1989, Hungary seemed to be one of the most promising \nsuccess stories of the former regime. A \nquarter of a century later, it is apparent \nthat Hungary\u2019s liberal democracy has be -\ncome substantially disintegrated, and the \npossibility of a quick remedy is not likely. \nViktor Orban has utilized the declining \neconomy and occurrence of scandal in the \nopposing party to consolidate his power \nand guard it from any form of contention. \nHe has accomplished this through many \nways, including imposing a restrictive \nmedia law, as well as pushing through \nlegislative reforms that further cement his \nparty\u2019s power.\n Though the EU has condemned Orban\u2019s \ntransition to a more authoritarian form \nof rule, it has, for the most part, not been \nable to sanction or persuade him into \nreversing his strict policies. Moreover, \neven if an opposition party is able to come \nto power in the following elections, the \npowers of the new government will still \nbe \u201cconstrained by Fidesz\u2019s takeover of \nindependent institutions and installation \nof clients into key positions\u201d (Kovacs 2013, \n240). The possibility of a new government \ndoes not seem very likely, however, due \nto recent gerrymandering and electoral \nchanges that undeniably tipped the scales \nin Orban\u2019s favor in the 2014 elections, \nindicating that his party\u2019s systematic un -\nraveling of democracy is far from finished. \nIn addition, Fidesz\u2019s only real challenger in \nthe election was the far-right Jobbik party, \nwhose leaders have been dubbed \u201cEurope\u2019s \nnew fascists\u201d; this lack of a strong opposi -\ntion, coupled with an extensive billboard \nadvertising campaign, secured Orban\u2019s po -\nsition as the unbeatable political machine \nfor another term. Clearly, Orban and his \ncontroversial ideas are not going anywhere \nanytime soon, allowing him to continue \nto enact strict legislation and inhibit the \nHungarians from truly experiencing liberal \ndemocracy. If the EU doesn\u2019t adopt a more \naggressive approach to punishing Orban \nand his corrupt government, other coun -\ntries may follow suit, leading to a resur -\ngence of illiberal democracies in Europe \nand worldwide.\nCitations\n1. Sissenich, Beate. Building States without \nSociety: European Union Enlargement and \nthe Transfer of EU Social Policy to Poland \nand Hungary, Lanham, MD: Lexington, 2007, Print, 20.\n2. Kauffmann, Sylvie. \u201cEurope\u2019s Illiberal \nDemocracies. \u201d The New Y ork Times. The \nNew Y ork Times, 09 Mar. 2016. Web. 24 \nApr. 2016.\n3. Kounalakis, Eleni. Madam Ambassador: \nThree Y ears of Diplomacy, Dinner Parties, \nand Democracy in Budapest, New Y ork: \nNew, 2015, Print, 80.\n4. Sissenich, Building States without Soci -\nety, 79.\n5. Valentinyi, Akos. \u201cThe Hungarian Cri -\nsis. \u201d Vox. N.p., 19 Mar. 2012. Web. 24 Apr. \n2016.\n6. Scheppele, Kim Lane. \u201cHungary and the \nEnd of Politics. \u201d The Nation. N.p., 06 May \n2014. Web. 24 Apr. 2016.\n7. Ibid.\n8. Ibid.\n9. Lo Prete, Marco Valerio. \u201cIs Viktor \nOrban Right That Liberal Democracy Has \nFailed? Is Italy Exhibit #1?\u201d New World \nDisorder 2.0 Fall (2014): 23-28. Wiley On -\nline Library, Web. 14 Apr. 2016,  24.\n10. Kounalakis, Madam Ambassador, 157.\n11. Bajomi-L\u00e1z\u00e1r, P\u00e9ter. \u201cHungary. \u201d Party \nColonisation of the Media in Central and \nEastern Europe. Budapest: Central Euro -\npean UP , 2014. 33-61, Print, 53.\n12. Kounalakis, Madame Ambassador, 157.\n13. Deak, Andras. \u201cHungarian Dances- the \nOrigins and the Future of Viktor Orban\u2019s \nRevolution. \u201d Lithuanian Annual Strategic \nReview (2013): n. pag. Rpt. in Hungarian \nInstitute of International Affairs, N.p.: n.p., \n2013 145-67, Web, 14 Apr. 2016, 155-156.\n14. Kounalakis, Madame Ambassador, 157.\n15. Bajomi-L\u00e1z\u00e1r, \u201cHungary\u201d , 54.\n16. Kovacs, Balazs Aron. \u201cHungary. \u201d \nNations in Transit 2012: Democratiza -\ntion from Central Europe to Eurasia. By \nSylvana Habdank-Kolaczkowska, Katherin \nMachalek, and Christopher T. Walker, \nNew Y ork: Freedom House, 2013. 240-258, \nPrint, 250.\n17. Kounalakis, Madame Ambassador, 158.\n18. Ibid.\n19. Kovacs, \u201cHungary. \u201d , 248-249.\n20. Kounalakis, Madame Ambassador, 159.\n21. Sedelmeier, Ulrich, \u201c Anchoring \nDemocracy from Above? The European \nUnion and Democratic Backsliding in \nHungary and Romania after Accession. \u201d \nJournal of Common Market Studies 52.1 \n(2014): 101-21, Wiley Online Library, Web, \n14 Apr. 2016.\n22. Sedelmeier, \u201c Anchoring Democracy The Internationalist            Vol. II, Spring 2017\n11\nfrom Above?\u201d\n23. Kovacs, \u201cHungary. \u201d , 241.\n24. Novak, Tamas. \u201cHungary: Embracing \nEuro-Skepticism. \u201d The European Union \nand the Member States, Ed. Eleanor E. \nZeff and Ellen B. Pirro, Third ed. Boulder: \nLynne Rienner, 2015. 279-98, Print, 283.\n25. Novak, \u201cHungary: Embracing Eu -\nro-Skepticism, \u201d 283.\n26. Ilonszki, Gabriella, and Krisztina \nJager. \u201cChanging Government Advantag -\nes- Challenging a Dominant Executive. \u201d \nThe Role of Governments in Legislative \nAgenda Setting, Ed. Bjorn Erik Rasch and \nGeorge Tsebelis, London: Routledge, 2011. \n95-110, Print, 100.\n27. Kovacs, \u201cHungary. \u201d , 241.\n28. Ibid, 242.\n29.Lendvai, Paul, Hungary: Between De -\nmocracy and Authoritarianism, New Y ork: \nColumbia UP , 2012, Print, 222.\n30. Lendvai, Hungary: Between Democra -\ncy, 222.\n31. Kovacs, \u201cHungary. \u201d , 252.\n32. Ibid., 239.\n33. Ibid, 254.\n34. Ibid.\n35. Lendvai, Hungary: Between Democra -\ncy, 94.\n36. Novak, \u201cHungary: Embracing Eu -\nro-Skepticism, \u201d 287.\n37. Ibid, 287-288.\n38. Ibid, 288.\n39. Kovacs, \u201cHungary, \u201d 242.\n40. Fazekas, Mihaly, et al., eds. Are EU \nFunds a Corruption Risk? The Impact of \nEU Funds on Grand Corruption in Central \nand Eastern Europe, By Mihaly Fazekas, \nJana Chvalkovska, Jiri Skuhrovec, Istv\u00e1n \nJ\u00e1nos T\u00f3th, Lawrence P . King, Social Sci -\nence Research Network, 6 Dec. 2013, Web. \n14 Apr. 20, 19.\n41.Deak, Hungarian Dances, 165.\n42. \u201dEuropean Commission Launches \nAccelerated Infringement Proceedings \nagainst Hungary over the Independence of \nIts Central Bank and Data Protection Au -\nthorities as Well as over Measures Affect -\ning the Judiciary, \u201d European Commission, \nN.p., 17 Jan. 2012, Web. 14 Apr. 2016.\n43. Spiegel, Peter, \u201cEU to Take Legal \nAction against Hungary, \u201d Financial Times, \nN.p., 17 Jan. 2012, Web. 14 Apr. 2016.\n44. Kelemen, R. Daniel, \u201cThe Migrant \nCrisis Is Exposing Hungary\u2019s Slide toward \nAutocracy. Here\u2019s Why the E.U. Hasn\u2019t \nCracked Down, \u201dWashington Post. N.p., 15 Sept. 2015, Web. 24 Apr. 2016.\n45. Kelemen, \u201cThe Migrant Crisis. \u201d\n46. Ibid.\n47. Kovacs, \u201cHungary, \u201d 240.\n48. Scheppele, \u201cHungary and the End of \nPolitics. \u201d\n49. Ibid.The Internationalist            Vol. II, Spring 2017\n12\nM alta has offered new ways in which \nwealthy individuals can obtain Maltese \ncitizenship. In addition to becoming a \nMaltese citizen and accessing the resources \nand perks that follow, it is important to \npoint out that obtaining Maltese citizen -\nship includes access to the EU and its \nadditional benefits. Jansen et al (2015) de -\nscribe that \u201cfor some \u2013 those who hold the \nright passport and have financial means \u2013 \nborders hardly seem to exist, or rather, the \nborders that exist are supposed to enable \nand encourage their mobility. Others are \nlimited in their freedom of movement, \nor may even face detention, deportation \nor death. \u201d1  This statement highlights the \nvarious degrees in which borders can affect \ngroups of people. In the context of migra -\ntion and borders, a multitude of dynamics \ncontributes to the flows and restrictions of \npeople. In particular, wealth is an indicator \nof how easy the border is to navigate for \nsome individuals. Anderson and Keith \n(2014) assert that \u201cwhile for some travelers \n[borders] are impassable, patrolled with \nguns, detectors and unnavigable bureau -\ncracies, for others these same borders are \nbarely noticeable, requiring nothing more \nthan a nod to a security guard. More par -ticularly, travel for the wealthy has usually \nbeen easier than travel for the poor. \u201d2 The \nborder, either justified or fueled by nation -\nalistic ideals, subjectifies certain groups to \ndifferential treatment. Balibar (2010) dis -\ncusses how \u201cborders, the drawing and the \nenforcing of borders, their interpretations \nand negotiations that \u2018make\u2019 or \u2018create\u2019 \npeoples, languages, races and genealogies\u201d \ninterconnect with each other in a way that \nallows for the subjectification or the pref -\nerential treatment of certain groups.3 \n   The Individual Investor Program (IIP) \nplays a meaningful role in discussing the \nrelationship between wealth and mobility. \nThis case focuses less on the restriction of \nlow income populations and instead ex -\nplores the additional travel rights that large \namounts of money can buy. \nBackground of Individual \nInvestor Program\n   Joseph Cardona, who is heavily involved \nin the execution of the IIP through his \nroles such as chief of Identity Malta (an \nagency responsible for issuing and updat -\ning Maltese forms of identification) and \nminister of the IIP itself, demonstrates the \npower that citizenship-by-investment has on a national economy by claiming that \n\u201capplications are pouring in, and the pro -\ngram aims to raise \u20ac2 billion (Euros), more \nthan a quarter of Malta\u2019s gross domestic \nproduct. \u201d4 The Malta Foreign Direct In -\nvestment (FDI) Research Group conducts \nyearly studies to assess the fiscal impact of \nthe IIP . This research is led by Dr. Kenneth \nCamilleri, who is a tax partner at a leading \nMaltese law firm Chetuci Cauchi Advo -\ncates, and he estimates that the program \n\u201cnetted the country over \u20ac1 billion in \ncontributions and direct investments\u201d \nsince its inception.5 The national rewards \nin terms of capital gain incentivize this \ntype of program. Despite these positives, \nthere are as many negatives attributed to \ncitizenship-by-investment. Most notably, \nthe EU discourages this type of program \nby saying that \u201cthe rights conferred by EU \ncitizenship, such as the right to move and \nreside freely within the EU, should not \nbe treated as a tradable commodity. \u201d6 In \nresponse, Malta adjusted the requirements \nto gain citizenship through the IIP to make \nthe process more expensive and ensure \nthat the investor spends more time in Mal -\nta than previously necessary.What is the price of citizenship? - \nA look into Malta\u2019s citizenship-by-\ninvestment program\nThis paper focuses on the idea of citizenship-by-investment in Malta, the critiques made by the EU \ntowards Malta because of this program, and its comparison to other residency benefits through in -\nvestment, particularly in Europe. The border has different meanings for different individuals and the \nability for an individual to cross a border can differ greatly from one to another. Wealth is a significant \nindicator of one\u2019s ability to cross the border. This separation caused by wealth can be as simple as an \nexpensive flight, but increasingly a price tag is becoming attributed to citizenship and visas. Malta has \na program that allows wealthy individuals to purchase citizenship through a combination of donations \nand investments to the national economy. The EU is worried about this idea because Malta is placing \na price tag on EU citizenship and its own citizenship. Other similar programs exist, but do not directly \ngrant citizenship through investment.By Mattew Watts\nSenior Economics, Geography MajorThe Internationalist            Vol. II, Spring 2017\nCost and Number of \nApplicants\n   The IIP met new regulations imposed by \nthe EU in 2014 and set out on its goal to \nattract wealthy individuals by exchanging \nMaltese citizenship rights for a combina -\ntion of a donation, investment in housing \nproperty, and investment in government \nbonds. The IIP brochure details the figures \nas a \u20ac650,000 contribution to the Nation -\nal and Development and Social Fund, \na \u20ac350,000 investment in real estate to \nbe held for at least five years,7 and lastly \na \u20ac150,000 investment in government \nbonds, which must also be held for a \nminimum of five years. Figure 1 details the \nsupplementary fees that are required for \nthe IIP . These fees are nominally hefty, but \nare irrelevant as they pose relatively few \nbarriers to the individuals who can afford \nthis program. This program demonstrates \nthat the applicant is seriously invested in \nthe country economically and residen -\ntially. As will later be discussed, however, \nresidency is not necessary.\n   According to the Chetcuti Cauchi Ad -\nvocates law firm based in Malta, the IIP \nreceived around 578 applications, which \nremains significantly short of the 1,800 \napplication cap that was imposed by the \ngovernment.9 This figure does, however, \nbuild upon the 400 or so individuals who \napplied in 2014.10 Figure 2 shows that the \ntotal applications since 2014 totaled near \n1,000 families. There were 54 individuals \nnaturalized of the 147 individuals who had \ntheir citizenship applications approved in \n2015. Assuming that most of the initial \n578 applicants were financially capable of \nproviding the three investment compo -\nnents, this program proves to be selective \nwhether intentionally or not. Before other \neconomic impacts are even considered, \nthe fees that the Maltese government have \ngained from the 54 applicants awarded \ncitizenship totals \u20ac62.1 million. \n   These numbers are relatively low, but \nif the maximum amount of applicants \n(1,800) was approved for citizenship then \nroughly 0.4% of Malta\u2019s population of \n434,40311 would be citizens-by-investment. \nUsing 2016 figures, if these numbers trans -\nlated to the United States or the EU then \n1.3 million of the United States\u2019 population \nof approximately 325 million12 or 2 million \nof the EU\u2019s population of roughly 510 mil -\nlion13 people would be citizens-by-invest -ment. While Malta is not on the same scale \nof population as the United States and the \nEU, the visualization of the amount of peo -\nple that are purchasing citizenship without \nengaging in a community within Malta is \ncritical.\nCriticisms and Similar \nSchemes\n   Initially, the \nLabor Party, \nwho hold a \nmajority seats \nin the House \nof Represen -\ntatives, had \nproposed to \nsell passports \n\u201cfor \u20ac650,000, \nwith few other \nrequirements \nfor citizen -\ns h i p.\u201d15 Op-\nposing party \nmembers and \nthe EU quickly \nrefuted this \nproposition. \nMarco de Ma -\nrio, a member \nof the National -\nist Party, stated \nthat \u201c[the Nationalist Party] does not wish \nto form part of a law which prostitutes \nMalta\u2019s identity and citizenship. \u201d16 More \nconcretely, the Nationalist Party stated \ntheir disapproval of potentially selling cit -\nizenship to individuals who have never set \nfoot in Malta and that a minimum of five \nyears residency should at least be consid -\nered.17 The European Parliament presented \nits concerns in a plenary session, in which \nthe Members of the European Parliament \n(MEPs) come together from all 27 Member \nStates and participate in decision making. \nA resolution was passed by a resounding \n560 votes to 22. This resolution addressed \nthe following concerns: EU citizenship \nshould not have a \u201cprice tag\u201d , the rights \nand benefits of EU citizenship should not \nbe treated as a \u201ctradable commodity\u201d , it is \nunclear if current Maltese nationals will \nbenefit from the revenue produced by the \nIIP , citizenship involves both rights and re -\nsponsibilities, whether or not the schemes \ndo violate fundamental EU values, and lastly Malta and other member states with \nsimilar schemes must bring their schemes \ninto line with EU values.18\n   The EU is worried about the moral \nimplications that arise from \u2018price tagging\u2019 \nEU citizenship. The institution believes \nthat the values and principles associated \nwith its member states are possibly violat -\ned by the sale of its membership to wealthy \nindividuals. The European Parliament stat -\ned that \u201cthe unions common values and \nachievements\u201d are \u201cinvaluable. \u201d19 In a shift \nof views, it is important to see whether or \nnot Malta and its citizens benefits from \nthis program. Speculation reckons that the \nprogram is or will eventually be executed \nas a program that encourages tax breaks \nto the investors. In regards to this aspect, \nwhat is the economic duty or responsibility \nof a citizen if he or she does not pay taxes? \nThese questions are asked by the EU and \nelaborated through the discussion of rights \nand responsibilities of citizens in the EU. \n   The rights and responsibilities of a \ncitizen, in particularly a citizen of the EU, \nare called into question specifically by the \nEuropean Parliament. First and foremost, \nit is the responsibility of a citizen, as is his \nor her nation\u2019s responsibility, to uphold the \nvalues of the EU. The \u2018European Parlia -\nment in Plain Language\u2019 website provides \na summary of the values, objectives, \nand principles of the EU that are Figure 1: After the initial \u20ac650,000 contribution, a series of \nfees exist ranging from \u20ac200 for \u2018bank charges\u2019 to \u20ac50,000 for \ndependent adults applying alongside an individual.8\nThe Internationalist            Vol. II, Spring 2017\n14\naccessible to internet users. It states that \n\u201cthe main goal of the European Union is to \ndefend these values in Europe and promote \npeace and the wellbeing of the citizens\u201d \nand, accordingly, \u201cthe European Parlia -\nment seeks to ensure that these values are \nrealized in the EU legislation. \u201d20 Lastly, the \nconsequence follows that \u201cno country that \ndoes not recognize these values can belong \nto the Union. \u201d21 While Malta has not been \nsubjected to the consequences of this final \ndecree, it is a warning sign that has caused \nMalta to question and reform its IIP . This \nstructure of values is officially supported \nin the Treaty of Lisbon, which also clarifies \nthe process of decision making in the EU. \nThese values highlight the importance \nof the European Parliament\u2019s decision to \nquestion Malta\u2019s intentions with the IIP \nand why the MEPs voted resoundingly in \nfavor for a solution.22\n   Other schemes currently exist in the \nEU such as Great Britain and Spain that \nfocus on offering visas to the business \nelite to promote travel in that nation. \nAnderson and Keith discuss the ease of \ntravel for the wealthy with support from \nthe \u2018GREAT club\u2019 and the \u201cSpanish golden \nvisa\u201d . The \u2018GREAT club\u2019 is an invitation \nonly \u201cfast track premium visa service \nfor elite business executives coming to \nBritain. \u201d23 It was created in 2013 by UK \nHome Secretary Theresa May to create \n\u201cUK Visas and Immigration in March to \nprovide a focus on delivering excellent \ncustomer service. These changes will allow \nus to maintain a world class, competitive \nvisa system that can innovate in order to \nserve the ever-changing needs of \nbusiness and ensure Britain succeeds in the global race. \u201d24 The \u201cSpanish golden \nvisa\u201d focuses on specific investment in \nexchange for a visa. The requirement for \nthe visa is a \u20ac500,000 or larger investment \nin \u201cresidential real estate or a portfolio of \nproperties. \u201d25 These visas have similar attri -\nbutes of Malta\u2019s IIP by providing transna -\ntional mobility in exchange for long term, \nsubstantial investments. The \u2018GREAT \nclub\u2019 , however, seeks its own clientele and \nneither visa provides citizenship outside \nof the traditional processes of each nation. \nAs of March 2017, Great Britain remains a \npart of the EU, but the British government \nis undergoing negotiations to officially \nleave the EU due to the 2016 \u2018Brexit\u2019 refer -\nendum vote.\n   Outside the context of the EU, many \npayment for passports and visas schemes \nhave existed and some even still remain \ntoday.26 Some are detrimental to the credi -\nbility of a nation and its institutions. Some \nPacific Islands, for example, are known for \nselling passports. Alongside legal practic -\nes, however, are illegal practices that take \nadvantage of the absence of the population \npurchasing passports legally. In refer -\nence to some Pacific Islands where these \npractices take place, Van Fossen (2007) \nstates that \u201cexposure of hidden details by \nthe media and by democratic interests de -\nmanding transparency led to invalidation \nof many passports because (i) sales were \nillegal, (ii) some purchasers were notorious \nundesirables and (iii) secrecy concealed \ncorruption\u201d and as a result the credibility \nof the passport in these nations became \nuncertain.27 There is no recent evidence \nto suggest that illegal practices are taking \nplace in Malta at the same magnitude as in Tonga, Samoa, and other Pacific Islands, \nbut the possibility for exploitation is \ncertainly there, in particularly with Malta\u2019s \ndecision to allow a private firm to take \ncontrol of the application process.\nApplications Processed by \nPrivate Firm\n   Granting a private firm to handle the \ndirect applications for citizenship creates \nmoral and national issues. Citizenship is a \ngovernmental construct, so it would seem \nfit for the government to manage these \napplications. Instead, the Maltese govern -\nment allows Henley and Partners to lead \nthe program with some supervision from \nIdentity Malta.28 The firm attempts to catch \nthe potential applicants attention with the \nfollowing selling points:\n\u2022 The right to live, work and study in any of \nthe 28 EU countries and Switzerland\n\u2022 Travel visa-free to 166 countries, includ -\ning the EU and Canada\n\u2022 World\u2019s strictest due diligence standards \nand vetting of applicants, thus ensuring \nonly highly respectable applicants will be \nadmitted\n\u2022 Citizenship of a well-respected EU \ncountry\n\u2022 Reasonable contribution and efficient \napplication process\n\u2022 Malta is an attractive place to live or to \nown a second home and is strategically \nlocated with excellent air links29\n   These benefits certainly have validity, \nbut have the essence of a business prop -\nosition that does not entail adopting an \nentirely new nationality. The fact that the \nHenley and Partners list the application \nprocess speed as one of the reasons to \napply demonstrates the purely economic, \nand potentially harmful, nature of this \nprogram. The legitimacy of the process is \nquestioned by the EU and Maltese sceptics \nbecause of this delegation.\nWho is Applying?\n   A comparison of the previous nationali -\nties of regular immigrants and individuals \npurchasing citizenship is interesting. In \nreference to wealthy individuals pur -\nchasing passports, Houlder explains that \n\u201caccurate statistics are in short supply, but \nthe International Monetary Fund (IMF) \nhas suggested that demand for citizen -\nship-by-investment programs is led Figure 2: The number of applicants at each stage demonstrates the selectivity of \nthe program.14\nThe Internationalist            Vol. II, Spring 2017\n15\nby clients from China, followed by Russia, \nand to a lesser extent from the Middle \nEast. It says the surge in demand \u2018may \nreflect a combination of growing wealth \nin emerging markets and an increase in \nglobal uncertainties and security issues\u2019 . \u201d30 \nThese particular individuals are attracted \nto benefits of Maltese and EU citizenship. \nRegular immigrants, on the other hand, \nare detailed in Figure 3.32 \n   The immigrants on this map are predom -\ninantly from the UK, Australia, Canada, \nand the USA. These are all wealthy English \nspeaking nations, which is fitting that \nMalta\u2019s two official languages are Maltese \nand English. Malta is a relatively expensive \ncountry, so although these immigrants \nhave not bought citizenship per se, they \nhave accessed the country through wealth.  \nTo put the wealth of the nation into per -\nspective, Malta ranks in the middle of EU \ncountries for GDP per capita in 2015.\n   There does not appear to be any issues \nregarding safety in the context of the ap -\nplicants who are applying for the citizen -\nship-by-investment. Instead, the morality \nof the application process and the role \nof civil responsibility are the concerning \naspects of the IIP . \nConclusion\n   \u201c At one time, second passports were \u2014 \nlike suitcases of cash \u2014 the preserve of spy \nnovels. Now they are becoming increas -ingly common, according to the Inter -\nnational Monetary Fund. \u201d33 The passport \nand carrying multiple passports to travel \nfreely around the world were staples to the \nJames Bond movie industry. Nowadays, \nindividuals with significant wealth are able \nto purchase citizenship to seek econom -\nic advantages. The purpose for multiple \npassports is not quite the same as using \npassports to navigate countries as a spy, but \nit does show the evolving use and nature of \nthe passport. \n   The European Union has many problems \nwith Malta\u2019s IIP . Malta redeveloped the \nprogram so that it was more expensive \nand required the investors to spend time \nin Malta to ease tensions, but is it the exis -\ntence of the program that is concerning or \njust the money associated purchasing the \ncitizenship? It would appear that both con -\ntribute to the discussion. Most importantly, \npricing Malta citizenship creates a begin -\nning price for EU citizenship, which could \nlead to a series of programs in other small \nand possibly economically poor countries \nin Europe that would incite a bidding war \nand create new perception of the role of \ncitizenship. This is dangerous because citi -\nzenship is treated as a commodity that has \na monetary value, which leads to exclusion \n(primarily impoverished groups of people) \nand the devaluation of the culture associat -\ned with citizenship. By no means does this \nlast statement mean that citizenship should be isolated and only given to those born in \nthe geographical boundaries of a country, \nbut instead that they should live in that \narea and contribute to the country in their \nown unique way, rather than simply pur -\nchasing the citizenship. \n   Interestingly, Guy Verhofstadt, a leading \nBrexit negotiator, proposed the idea of \noffering UK citizens the opportunity to \npay for EU citizenship to keep hold of the \nbenefits of the institution.34 Does this have \nthe same implications of Malta selling \ncitizenship? Not directly, but it plays with \nthe same ideas of \u2018price tagging\u2019 citizen -\nship. Malta is not the first country to offer \ncitizenship or residency perks in exchange \nfor money, but their program is one of \nthe first to become a legitimate program, \nwhich has led to many discussions in \nEurope and the rest of the world about the \nfuture of citizenship.\nCitations\n1. Jansen, Y olande, Robin Celikates, and \nJoost de Bloois, eds. 2015. The Irregular -\nization of Migration in Contemporary \nEurope: Detention, Deportation, Drown -\ning. London and New Y ork: Rowman and \nLittlefield.\n2. Anderson, Bridget, and Michael Keith. \n2014. Migration: A COMPAS Anthology. \nOxford: COMPAS.3.\n3. Balibar, Etienne. 2010. \u201c At the \nBorders of Figure 3: Map from 2007 of the origins of immigrants in Malta.31\nThe Internationalist            Vol. II, Spring 2017\n16\nCitizenship: A Democracy in Translation?\u201d \nEuropean Journal of Social Theory 13(3): \n315-322.\n4. Anderson, J. \u201cMalta Offers Citizenship \nand All Its Perks for a Price. \u201d NY Times. \nLast modified April 30, 2015. http://www.\nnytimes.com /2015/05/01/business/deal -\nbook/malta-offers-citizenship-and-all-its-\nperks-for-a-price.html?_r=0\n5. \u201cMalta Citizenship Statistics Update\u201d . \nAccessed April 2, 2017. http://www.mal -\nta-citizenship.eu\n6. European Parliament,. \u201cEU Citizenship \nShould Not Be For Sale At Any Price, \nSays European Parliament. \u201d European \nParliament News. Last modified January \n16, 2014. http://www.europarl.europa.eu/\nnews/en/news-room/20140110IPR32392/\neu-citizenship-should-not-be-for-sale-at-\nany-price-says-european-parliament\n7. Individual Investor Programme of the \nRepublic of Malta [Brochure]. Valletta, \nMalta:  Mediterranean Conference Cen -\ntre. Accessed April 2, 2017. http://iip.gov.\nmt\n8. Individual Investor Programme of the \nRepublic of Malta [Brochure]. Valletta, \nMalta:  Mediterranean Conference Cen -\ntre. Accessed April 2, 2017. http://iip.gov.\nmt\n9. \u201cMalta Citizenship Statistics Update\u201d . \nAccessed April 2, 2017. http://www.mal -\nta-citizenship.eu\n10. Vella, M. \u201cIIP: Malta rakes in \u20ac200 \nmillion from itinerant elites\u201d . Malta Today. \nLast Modified August 23, 2016. http://\nwww.maltatoday.com.mt/news/nation -\nal/68774/iip_malta_rakes_in_200_mil -\nlion_from_itinerant_elites\n11. Eurostat. Accessed April 2, 2017. http://\nec.europa.eu/\n12. United States Census Bureau. Accessed \nApril 2, 2017. http://www.census.gov/pop -\nclock/\n13. Eurostat. Accessed April 2, 2017. http://\nec.europa.eu/\n14. \u201cMalta Citizenship Statistics Update\u201d . \nRetrieved from http://www.malta-citizen -\nship.eu\n15. Anderson, J. \u201cMalta Offers Citizenship \nand All Its Perks for a Price. \u201d NY Times. \nLast modified April 30, 2015. http://www.\nnytimes.com /2015/05/01/business/deal -\nbook/malta-offers-citizenship-and-all-its-\nperks-for-a-price.html?_r=0\n16. Dalli, M. \u201cUpdate | Mario de \nMarco: \u2018Opposition will not support prostitution of Malta\u2019s identity, citizenship\u2019 . \u201d \nMalta Today. Last Modified November \n9, 2013, http://www.maltatoday.com.mt/\nnews/national/31325/opposition-pro -\nposes-change-of-name-to-individual-do -\nnor-programme-20131109#.WOGw8BIr -\nLow\n17. Dalli, M. \u201cUpdate | Mario de Marco: \n\u2018Opposition will not support prostitution \nof Malta\u2019s identity, citizenship\u2019 . \u201d Malta \nToday. Last Modified November 9, 2013. \nhttp://www.maltatoday.com.mt/news/\nnational/31325/opposition-propos -\nes-change-of-name-to-individual-do -\nnor-programme-20131109#.WOGw8BIr -\nLow\n18. European Parliament,. \u201cEU Citizen -\nship Should Not Be For Sale At Any Price, \nSays European Parliament. \u201d European \nParliament News. Last modified January \n16, 2014. http://www.europarl.europa.eu/\nnews/en/news-room/20140110IPR32392/\neu-citizenship-should-not-be-for-sale-at-\nany-price-says-european-parliament\n19. European Parliament,. \u201cEU Citizen -\nship Should Not Be For Sale At Any Price, \nSays European Parliament. \u201d European \nParliament News. Last modified January \n16, 2014. http://www.europarl.europa.eu/\nnews/en/news-room/20140110IPR32392/\neu-citizenship-should-not-be-for-sale-at-\nany-price-says-european-parliament\n20. \u201cValues. \u201d European Parliament in Plain \nLanguage. Accessed April 2, 2017. http://\neuroparlamentti.info/en/values-and-objec -\ntives/values/\n21. \u201cValues. \u201d European Parliament in Plain \nLanguage. Accessed April 2, 2017. http://\neuroparlamentti.info/en/values-and-objec -\ntives/values\n22. \u201cTreaty of Lisbon. \u201d European Parlia -\nment in Plain Language. Accessed April 2, \n2017. http://europarlamentti.info/en\n23. Anderson, Bridget, and Michael Keith. \n2014. Migration: A COMPAS Anthology. \nOxford: COMPAS.\n24. Travis, A. \u201cTheresa May launches \nfast-track visa service for business leaders\u201d . \nThe Guardian. Last modified November 6, \n2013. https://www.theguardian.com\n25. Anderson, Bridget, and Michael Keith. \n2014. Migration: A COMPAS Anthology. \nOxford: COMPAS.\n26. Gittleson, K. \u201cWhere is the cheapest \nplace to buy citizenship?\u201d Last modified \nJune 4, 2014. http://www.bbc.com\n27. Van Fossen, Anthony. 2007. \u201cCom -monwealth & Comparative Politics. \u201d \nCitizenship for Sale: Passports of Conve -\nnience from Pacific Island Tax Havens: \nCommonwealth & Comparative Politics: \nVol 45, No 2.\n28. Balzan, J. \u201cRevamped citizenship \nscheme will require \u20ac1.15 million  in-\nvestment per applicant\u201d . Malta Today. Last \nmodified December 23, 2013. http://www.\nmaltatoday.com.mt/news/national/32628/\nrevamped-citizenship-scheme-will-re -\nquire-1-15-million-investment-20131223\n29. Henley and Partners. Accessed April 2, \n2017. https://www.henleyglobal.com\n30. Houlder, V . \u201cCitizenship is for sale to \nthe wealthy\u201d . Financial Times. Last modi -\nfied June 29, 2016. https://www.ft.com\n31. Migrations Map. Accessed April 2, \n2017. migrationsmap.net\n32. Eurostat. Accessed April 2, 2017. http://\nec.europa.eu/\n33. Houlder, V . \u201cCitizenship is for sale to \nthe wealthy\u201d . Financial Times. Last modi -\nfied June 29, 2016. https://www.ft.com\n34. \u201cBritons could pay for EU citizenship \nafter Brexit, says top negotiator\u201d The \nGuardian. Accessed November 25, 2016. \nhttps://www.theguardian.comThe Internationalist            Vol. II, Spring 2017\n17\nO n 20th September 2001, nine days \nafter the catastrophic events in Manhattan, \nthen-President George W . Bush addressed \nthe nation declaring that the \u201cwar on \nterror begins with Al Qaeda, but it does \nnot end there. \u201d1 His pledge that the United \nStates will not lay dormant \u201cuntil every \nterrorist group of global reach has been \nfound, stopped and defeated, \u201d2 invigorated \nand preluded what would be a decade of \nwar, conflict and fear. Just under twelve \nyears after Bush\u2019s statement, President \nBarack Obama announced that the \u201cGlobal \nWar on Terror\u201d was over.3 However, since \nthen, terror groups across the world have \ngone rampant. Most notably the Islamic \nState (IS), which has taken vast swaths of \nland and control over a destabilized Syria \nand a recovering Iraq, has used a cohesive \ntechnological campaign to recruit and \nindoctrinate supporters. Despite Obama\u2019s \nclaims that Bush\u2019s \u2018War on Terror\u2019 may be \nover, it should not be assumed that the \nnotion of terrorism is not only far from \nthat, but that it also did not begin with the falling of the two towers in Manhattan.\nDavid Rapoport\u2019s attempt to conceptualize \nthe changing patterns of modern terror -\nism offers a wave theory of 19th century \nterrorist trends. According to him, we are \ncurrently in the Fourth Wave of terror -\nism, a wave that he regards as the \u201cReli -\ngious Wave. \u201d Rapoport contests that this \nreligious wave, with Islam at its \u201cheart, \u201d4  \nbegan in 1979 and will end in 2025, upon \nwhich a new wave of terrorism will arise. \nThis thesis will analyze Rapoport\u2019s theory, \ncontending that the Fourth Wave is firmly \nwithin the contraction phase. In addition, \nthis paper aims to approximately predict \nthe point from which this transitionary \nperiod began.\n   To do this requires examination of \nthe change in \u2018energy\u2019 and strategy, the \ntwo components that make up the wave \nperiods. In analysis, it will be important to \nlook beyond the face-value of modern ter -\nrorist organizations as we see them today \nand instead explore the contextual data to \nwhich these groups have formed, grown, \nand changed. Two main contemporary terrorist groups, Al Qaeda and the Islamic \nState, will be referenced in the analysis. \nRapoport\u2019s Wave Theory\n   To understand whether we are in a pe -\nriod of transition out of the \u2018Fourth Wave\u2019 \nrequires a brief examination of Rapoport\u2019s \noverall theory on terrorism. This assess -\nment will give an insight into not only the \nkey features of each wave, but also more \nimportantly, what aspects are visible in a \ntransition. Rapoport defines a \u2018wave\u2019 as \na \u201ccycle of activity in a given time period \nwith expansion and contraction phases. \u201d5 \nHe goes on to explain that those activi -\nties \u201coccur in many countries driven by a \ncommon predominant energy shaping the \nrelationship of participating groups. \u201d6 It \nis in his opinion that a different \u201cenergy\u201d \ndrives each wave. \n   The \u2018First Wave\u2019 is in which, according to \nRapoport, the doctrine of modern terror \nwas created. Beginning in 1880 and lasting \napproximately forty years, tapering off in \nthe 1920s,7 its energy centered around an -\narchistic tendencies, holding the rationale Leaderless Jihad: Changing \nPatterns in a New Era of \nModern Terrorism\nAcademic scholarship surrounding terrorism studies is a disjointed array of contrasting viewpoints. \nHowever, at its center lay a recurring reliance on David Rapoport\u2019s \u2018Four Waves of Modern Terrorism\u2019 \ntheory. This thesis attempts to examine Rapoport\u2019s theory by analyzing the shifts in radical Islamist \ngroups, in a multi-layered study of both al Qaeda and The Islamic State (IS). By examining this period \nof time, this paper contends that between the years of 2004-2005 we entered into a period of transition, \nand as such hypothesize that the Fourth Wave has already entered a state of contraction. The paper \nprovides a historical context to forms of contemporary religious terrorism before examining and con -\ntrasting the timelines of both al Qaeda and IS in relation to technological and societal developments. \nIn turn, culminating in the shifting modus operandi to one of a framework which is not only set upon \nthe concept of \u2018leaderless jihad\u2019 but has also endowed a heightened level of nationalistic politicization \nwithin contemporary terrorism.By Joseph Petrovic\n2nd year, UNC Law SchoolThe Internationalist            Vol. II, Spring 2017\nthat social conventions were immoral, of \nwhich methods of terror were required to \ndestroy them.8 The \u2018Second Wave\u2019 began \nin the 1920s and lasted, once again, for \napproximately forty years. Brought on by \nthe consequences of the Versailles Peace \nTreaty, this wave was aptly named the \u2018 An -\nti-Colonial Wave\u2019 as its primary motivator \nwas the contentious discontinuation of \nEuropean influence in numerous over -\nseas territories.9 The \u2018Third Wave\u2019 rotated \naround Marxist theory and the revolution -\nary rhetoric that accompanied it.\n   Under Rapoport\u2019s theory, \u2018Revolution\u2019 is \nthe overriding aim in every wave. Howev -\ner, the term may be understood differently \nwithin each different wave. In the First \nand Third waves the theme of revolution \nwas understood to be one which meant a \u201cradical reconstruction of authority \nto eliminate all forms of inequality. \u201d10 \nHowever, Rapoport claims that it can also \nrefer to the acquisition of a new source of \nlegitimacy. For example, sacred texts have \npresented themselves as a recurring theme \nthroughout the Fourth Wave.11\n   The \u2018Fourth Wave\u2019 , also regarded as \nthe \u2018Religious Wave\u2019 , began in 1979 and, \nmuch to the apprehension of this essay, \nis predicted to last until 2025. Like the \npreceding waves, the Fourth Wave had \ntwo defining points: the Iranian revolution \nand the invasion of Afghanistan by Soviet \nforces. The revolution in Tehran showed \na number of groups for which \u201creligion \nhad more political appeal than neo-Marx -\ni s m\u201d.12 It is this \u2018political appeal\u2019 that must \nbe examined with respect to how it can, and arguably has, changed the underlying \nmotivations for terror. \n   Rapoport has regarded the Fourth Wave \nas one that \u201creshaped the international \nsystem profoundly\u201d .13 He would not be in -\ncorrect. In this wave, we see the transition \nfrom secular aims to ones centered upon \nthe pursuit of religious dominance. While \nAnarchists held that social conventions \nwere immoral, and as such it was their \nduty to destroy them, the justifications \nbehind the Fourth Wave lay in religious in -\nterpretations that \u201cthe world must become \nimpossibly bad before it could become \nunimaginably good. \u201d14\n   While different \u2018energy\u2019 drives the waves, \nthe other component remains to be strate -\ngy and technique. Rapoport contends that \neach wave produces major techni\nLaura B Cowan, M.A.\nThis photograph was taken during an unseasonably warm fall day in Switzerland and captures the sun setting above the \nvillage of Grindelwald in the Bernese Alps. I was visiting Switzerland for a family hiking vacation in the Alps. The \ndiversity of landscapes and culture in such a small region make for very memorable experiences.The Internationalist            Vol. II, Spring 2017\n19\ncal works that \u201creflect the wave\u2019s special \nproperties\u201d15 while aiding in furthering \nthe tools of terror. While the First Wave \npioneered dynamite, and the Third Wave \npropagated the taking of hostages as its \ndefining feature, the Fourth Wave has ad -\nopted \u2018Suicide\u2019 bombing as its hallmark. In \nconjunction with radical interpretation of \nIslamic scripture that promises rewards of \n\u2018paradise\u2019 , this has become a tool for groups \nto inflict mass murder at an indiscriminate \nlevel. A change in strategy and approach \npresents itself as an indicator of transition, \nfor which we shall examine in due course.\nAl Qaeda\n   Coming from the Arabic root qaf-ayn-\ndal, meaning a base, or more appropriately \na \u201cfoundation, \u201d16 Al Qaeda (AQ) lays forth \nits claim to being a bedrock upon which \nthe radicalization and subsequent mobili -\nzation of the Islamic world can occur. Just \nhow did an organization, which boasted \na meager 30 or so members in 1996, go \non to become a worldwide harbinger of \nterror?17 It is easy to assume that Al Qaeda \nbegan with 9/11. However, while it was a \ntragic mark on the world as we know it, Al \nQaeda\u2019s leader formed his following much \nearlier. \nAs early as 1998, Osama Bin Laden (OBL) \nengaged in a joint-led fatwa calling for the \nmurder of Americans.18 However, in the \nyears prior to this, Al Qaeda was arguably \na failure of an organization. Many scholars \nnote the role Afghanistan had in exacer -\nbating the power of AQ, putting them on \nthe path to being the global name they are \ntoday. This claim has some truth. It is true \nthat Bin Laden, upon hearing the news \nof the Soviet\u2019s invasion into Afghanistan \nin 1979, exclaimed his anger and \u201cwent \nthere at once. \u201d19 What, however, is not true \nis that OBL was either overly influential \nor emotionally attached to the country. \nAccording to a family member, Osama had \nnever even heard of Afghanistan until that \npoint.20 Nonetheless, Al Qaeda was a key \nand relevant force in the Soviet invasion \nof Afghanistan and, as such, formed into \none of the key actors of Rapoport\u2019s Fourth \nWave.21  \n   There is academic disagreement as to \nwhen AQ\u2019s success began. Farrall argues \nthat AQ, under OBL \u2019s leadership, was a \nstruggling organization throughout the \n1990s, with multiple failures in acquiring the allegiance of other groups, ranging \nfrom the Egyptian Islamic Group to mili -\ntant groups within Chechnya.22 In contrast, \nmany analysts hold that AQ\u2019s structure \nonly became united after OBL \u2019s return to \nAfghanistan in 1996.23 Sageman even goes \nas far as stating that the period of 1996 to \n2001 was Al Qaeda\u2019s \u201cgolden age. \u201d24\n   When the Soviets withdrew from Af -\nghanistan nearly a decade after the conflict \nbegan, OBL, and the jihadists he stood by, \nleft the battleground with one overarching \nbelief. Not only had they stood up to a \nworld superpower, but they had defeated \nit.25 With the aid of the Taliban, OBL took \nadvantage of a desolate country, allowing \nhim to build the foundations for a coher -\nent above-ground organization. While \nthere is academic contention as to when \nAQ\u2019s rise occurred, the vast majority of \nscholars agree that following the events \non September 11th 2001 the nature of the \norganization changed dramatically. \n   Moving from an organization that had \nused a pyramidal structure to \u201cfacilitate \nstrategic and tactical direction, \u201d26 AQ \ndeveloped into one of a \u201cdevolved network \nhierarchy, \u201d27 after being driven under -\nground and into the mountains following \nthe U.S. invasion of Afghanistan in late \n2001. Constant bombardment and drones \nstrikes have seen AQ\u2019s higher ranks disin -\ntegrate. The most damning being the raid \non Abbottabad in May 2011, which saw \nthe killing of Osama Bin Laden. Following \nthis, while AQ managed to stay intact, it \nhas seen a decline in relevance.28 This has \nnot been aided by the rise of the Islamic \nState and its corresponding global terror \ncampaign. But why did AQ focus its efforts \non the United States? \n   Iraq\u2019s invasion into Kuwait in 1990 gar -\nnered the attention of AQ. Arguably, to an \nextent, it was less about religious conten -\ntion than it was about ego.  As historians \nhave documented, OBL offered to send \nAQ assistance to Saudi Arabia. However, \nthe Saudis rejected his offer and took the \nopportunity instead to seek help from the \nUnited States, angering a shamed Osama \nBin Laden and prompting his further \nskepticism of the U.S. sphere of influence \nthroughout the region.29 Some historians, \nsuch as Farrall, present the theory that the \nattack on 9/11 was less so about religion \nthan it was about inciting an \u201carmed \nretaliation, \u201d resulting in American troops laying forth over the supposed sacred \nlands and thereby opening up \u201ca new front \nfor jihad. \u201d30 In addition, assuming that the \nleadership of AQ maintained a political \nstandpoint which cared less about religious \nideology than about becoming a powerful \nentity, they would be able to evaluate that \nU.S. retaliation would present AQ as the \n\u201cstrong horse\u201d among Islamist militants, \nleading them to fall under Al Qaeda\u2019s \nleadership in the fight against the \u201cinvad -\ning Americans. \u201d31 This is something they \narguably predicted well.\n   Over fifteen years on from the attacks on \nSeptember 11th, AQ may be a shadow of \ntheir former self, their central organiza -\ntion\u2019s capability having been degraded. But, \nthey should not be completely disregard -\ned.32 Their demise, which resulted in a \nchange of strategy, was not just because of \nAmerica\u2019s reduction of the group\u2019s sphere \nof influence and the targeted killing of \nhigh-ranking AQ leaders such as OBL, \nbut also because of competition from \nother Islamist groups.33 Up until 2015, \none particular group was happy to enact \ntheir \u2018holy war\u2019 in the Middle East without \novertly antagonizing the West. In fact, \nthe leaders of this group, which has been \nrecognized under the banner of many dif -\nferent names, the most common being The \nIslamic State, have openly criticized AQ \nfor the 9/11 attacks because, in their belief, \nit led to the \u201ccrushing of the movement in \nAfghanistan and the defeat of its host, the \nTaliban regime. \u201d34 As such, these remarks, \nin hindsight, are now difficult to compre -\nhend given the acceleration of IS-spon -\nsored attacks outside the Middle East.\nIslamic State (IS)\n   The Islamic State (IS/ISIS) has long co -\nordinated and enacted their attacks on the \nenemy that is \u201cnear, \u201d primarily being the \nArab countries (Iraq, Libya, Saudi Arabia, \nSyria).35 A brief examination into the his -\ntory of ISIS presents the group\u2019s leader Abu \nBakr al-Baghdadi, a religious scholar who \nrose through the ranks of AQI (Al Qaeda \nin Iraq) to become the eventual leader \nof the self-proclaimed Islamic State in a \nperiod between 2011-2013.36 A report by \nEuropol in November 2016 noted that the \ngroup\u2019s primary goals were originally the \nseizure of territory and local resources, of \nwhich they were arguably successful \nin, with vast swaths of Iraq and The Internationalist            Vol. II, Spring 2017\n20\nSyria being under the control of the group \nby 2014-2015.37 Their involvement within \nWestern countries, at that stage, was limit -\ned at most.38\n   The group\u2019s higher echelons have long \nstated that directly sanctioned major \nattacks in the West are to be avoided due \nto the possibility of massive retaliation and \nsubsequent loss of territory that would \noccur in a conventional ground war with \nUS and/or NATO forces.39 Despite this, on \n31st  October 2015 an incendiary device \nblew up an Airbus traveling from Egypt to \nRussia, killing 224 on board and signaling \nthe change toward, what Europol called, \na \u201cbroader international strategy. \u201d40 Since \nthen, ISIS has directly coordinated and \ntrained terrorists involved in some of the \nmost brutal attacks the West has seen, op -\nerating throughout all of Europe. It is clear \nthat there is an increase in the frequency, \nscale and impact of ISIS\u2019s attacks within \nthe EU\u2019s member states, something which, \nin turn, must be analyzed.41\n   While ISIS\u2019s strategy may appear to fit \nwithin the old AQ mantra, and as such be \nfirmly within the confines of the Fourth \nWave, there is evidence to the contrary. \nWhile like many of the organizations \nwithin the Fourth Wave, ISIS is commit -\nting these attacks to garner fear, destruc -\ntion and terror. They are, however, more \nheavily reliant upon them as a means to \ngalvanize and recruit supporters for their \n\u2018State\u2019 . Where we can also see a possible \ntransformation since 2004 is a lack of \ndirect connection between the terror \norganization and the would-be attackers. \nAl Qaeda exhibited similar tendencies, \nwith the Madrid train bombings in 2004, \nnot being plotted by the organization, but \ninstead being done \u2018in the name of \u2019 the \norganization.42 However, where differ -\nences emerge between Al Qaeda and the \nIslamic State is the declared \u2018caliphate\u2019 by \nthe latter. This new-found allegiance to a \nstate-like entity, seeking the expansion of \nits administrative capability, with its own \nset of laws, governance, and infrastructure, \ndraws a vast amount of differences to prior \norganizations within the wave. While ISIS \nfocuses on maintaining and expanding this \n\u2018caliphate\u2019 in Syria and Iraq, the sporadic \nbut deadly attacks they coordinate in the \nWest serve as a means of propagating, \nwith other tactics, the development \nof what Sageman calls \u2018leaderless jihad\u2019 .\nThe \u2018Leaderless Jihad\u2019 \nPhenomenon\n   The term \u2018Leaderless Jihad\u2019 , a phrase \ncoined by terrorism scholar Marc Sage -\nman, is used to describe the \u201cscattered, \ndecentralized structure\u201d of extremists who \nno longer need to rely on direct orders \nfrom the central command of terrorist \norganizations.43 Sageman, supporting this \nthesis, states that there is a new generation \nof extremists:\n   It consists mostly of would-be terrorists, \nwho, angered by the invasion of Iraq, aspire \nto join the movement and the men they \nhail as heroes. But it is nearly impossible \nfor them to link up with Al Qaeda Central, \nwhich was forced underground after 9/11. \nInstead, they form fluid, informal networks \nthat are self-financed and self-trained. They \nhave no physical headquarters or sanctuary, \nbut the tolerant, virtual environment of the \ninternet offers them a semblance of unity \nand purpose.44\n   According to Sageman, \u2018leaderless jihad\u2019 \nis the natural outcome of a \u201cbottom-up \nmechanism of group formation in a \nspecific environment shaped by top-down \ncounterterrorist strategy. \u201d45 The process of \nradicalization stemming from small, local, \nself-organized groups in a \u201chostile envi -\nronment\u201d46 (the West) linked through the \ninternet. However, Sageman notes a key \nlimitation. For the survival of this \u201cleader -\nless social movement\u201d , the terrorist organi -\nzations are required to provide a \u201cconstant \nstream\u201d of new and provoking attacks that, \nin turn, will invigorate potential future \nlone-wolfs (used in the \u2018leaderless jihad\u2019 \nsense) into taking action themselves in at -\ntacks, all in all creating the \u201cimpression of \nvisible progress toward a goal. \u201d47 It can be \nargued that this \u201cgoal\u201d is one of a religious \nnature, and as such indicates we are still \nfirmly within the Fourth Wave. However, \nit may also be contended that, using the \nIslamic State as an example, the outreach \nof the caliphate is, not as a religious move -\nment, but a pseudo-state attempting to \nconsolidate power and territory. As such, \nthe \u2018energy\u2019 , as Rapoport would say, is \npossibly transitioning to become less about \na larger religiously-inspired movement as it is about nationalistic dogma.\n   AQ pre-2004 is a wildly dissimilar group \nthan we are faced with today. Post-2004 \nAl Qaeda Central Command no longer \nknows who its followers are. They no lon -\nger accept recruits through their training \ncamps.48 In fact, they now rely on accept -\ning members after they have committed \nan act of terrorism. As Sageman supports, \nbombings are now the \u201cde facto official \ninitiation ceremony\u201d49 into Al Qaeda. The \ngroup itself has recognized the develop -\nments within the organization, stating, in \n2003, that it will take Americans a \u201clong \ntime to understand the new form of Al \nQaeda. \u201d50\n   As mentioned before, ISIS also relies \non this recruitment strategy. While rarely \ncoordinating attacks in the West, the few \nthat are conceived by the group\u2019s leader -\nship seek to motivate a plethora of foreign \nfighters to join them in Syria and Iraq \n- areas in which they hold higher value \ntowards. Arguments to the contrary have \nto answer the question as to why ISIS has \ntaken little action against the state of Israel \ndespite overt religious animosity, with the \ngroup stopping abruptly along the Golan \nHeights. It could be naive to assume that \nISIS, as a pseudo-state, is exclusively full \nof vitriolic religious extremism. As Cronin \ndocuments, the upper ranks of ISIS consist \nof, not only anti-US insurgents, but also \nsecular former Iraqi military officers who \nare motivated through regaining \u201cthe \npower and security they enjoyed during \nthe Saddam Hussein era. \u201d51 It is therefore \narguable that they are a contingent who \nuses religion as a tool to gain geopolitical \ninfluence and control in the areas that the \n\u2018State\u2019 apparatus deems as attainable. As \nshown by the declaration of the Caliphate \nand an \u2018Islamic\u2019 State, there is the combi -\nnation of both religious and nationalist \ntendencies. As such, ISIS is the underpin -\nning organization of the transitionary peri -\nod, utilizing the preceding wave\u2019s key tenet, \nreligion, to mislead and take advantage of \nits membership.\nThe Internet as a \nTransitionary Tool\n   The internet to the Fourth Wave is what \ndynamite was to the First Wave and, in the \nwords of Sageman, \u201cmakes the existence of \na leaderless jihad possible. \u201d52 The technoThe Internationalist            Vol. II, Spring 2017\n21\nlogical advancement of communications, \ncoupled with the development and propa -\ngation of the internet, is the driving force \nbehind the furthering of global terror.53 It \ncan be argued that, following the develop -\nment of the internet, terrorist groups have \nused this tool wisely with virtually every \nmajor terrorist group maintaining some \nform of website or social media presence. \nThe internet, including the dark web, in \nthe mid-2000s boasted over 4,000 websites \nfor Islamist extremists.54 According to \nSimon, the internet is in fact the \u201cenergy\u201d \nbehind the Fifth Wave, having revolution -\nized the way in which single individuals \ncan \u201cbecome significant players\u201d55 through \ntheir newfound ability to garner infor -\nmation regarding weapons, targets, and \nbomb-making manuals.   While this thesis does not agree with \nSimon\u2019s sentiment concerning the inter -\nnet as the predominant \u201cenergy\u201d , he does, \nhowever, highlight a key characteristic \nthat is apparent in the transition between \nthe waves, and may, to an extent, play a \nsubstantial role in the eventual Fifth Wave. \nFor now, however, it can be ascertained \nthat the development of the internet has \nbought about a changing tool for terror -\nism. Just as dynamite was the influential \ntool of the First Wave, the internet appears \nto arguably be playing a very key role in \nthis transitionary period, and may end up \neventually as a defining feature in the next \nwave.\n   However, where parallel can be drawn \nis through Simon\u2019s statement regarding \nthe internet\u2019s revolutionary effect.56 This effect has arguably been documented by \nthe change in power dynamics of global \nterrorism, with Sageman contending that \nthe \u201ctrue leader\u201d of Islamist terror is no \nlonger a group of authoritative figures at \nthe head of an organization but is instead \nthe \u201chalf-dozen influential jihadi forums. \u201d57 \nOnce again, raising discussion as to a clear \nand demonstrable change in strategy for \nthe Fourth Wave. \n   Sageman\u2019s aforementioned point high -\nlights how the internet, a global system \nconceived in the late 1990s, is only now \nbecoming a catalyst for the transitionary \nperiod. It is no longer about static websites \ncontaining propaganda. The true result of \nthose static pages was not so much as to \ninspire, but to instead act as rein -\nforcement for previously held \nDana Leah Walker, \u201818\nHiking one morning in Banff National Park located in Canada, we passed Moraine Lake. The water was an amazing \nturquoise blue created by the runoff of glacier water juxtaposed against the striking bold colors of the canoes.The Internationalist            Vol. II, Spring 2017\n22\nbeliefs.58 Where the internet and the new \nforms of easily accessible communication \nhave become apparent in the wave\u2019s tran -\nsition is through a new age of interactivity. \nIt is this interactivity that is revolutioniz -\ning global terrorism through the \u201crapidly \nchanging human relationships, \u201d59 concern -\ning anonymity, the little cost involved with \ncutting their interactions when needed, \nand the overarching ability to garner the \nfeeling of belonging to a greater communi -\nty, which they cannot do openly in society. \n   For this transitionary period, we are also \nseeing the transformation of terror itself, \nbeing fear which now arises from the ter -\nrorist who no longer requires training or \nguidance from an overarching command \nstructure, and as such is considerably \nharder to stop before participating in their \nattack. There is now the trepidation that \nwe cannot prevent the next coming attack \nbecause our detection methods are redun -\ndant. In the years prior to 2003, terrorists \nfor AQ would attend training camps before \nbeing sent back to the West. There were \nconsiderable countermeasures, whether \nat borders or through monitoring chatter \ninvolved in the logistics of physical train -\ning, of which Western intelligence agencies \nwere considerably successful at. \n   In contrast, the \u2018terrorists\u2019 in this post-\n2003 transitionary period do not need \nto travel, they do not need to receive \nbomb-making training from specialist \ncamps thousands of miles away; in fact \nthey may not even need to communicate \nwith others in formulating their attack. \nInstead, any necessary bomb-making \ntraining is now acquired through the inter -\nnet with accessible step-by-step guides to \ncreate improvised explosive devices, which \nwhile dangerous, does not require the spe -\ncialist expertise it previously did.60\n   It is difficult to specify the exact mo -\nment a transition will fully occur from \nthe Fourth Wave to the Fifth Wave. As \nRapoport contends, this takes place when \nanother \u2018energy\u2019 becomes more dominant. \nThis would imply that there is a slow, yet \ngradual, \u2018wave-like\u2019 manner to the stages, \nin which as the \u2018energy\u2019 of one slowly de -\ncreases, the other increases. This creates an \neffectual passing where, at a specific point, \nboth energies are in equilibrium. This the -\nsis does not attempt to pinpoint an exact \nmoment this occurred or will occur.  \nHowever, it could be estimated that, around 2003-2004, this process of decline/\nincline for the different \u2018energies\u2019 began. \nAs highlighted earlier, prominent or -\nganizations such as AQ have had their \nframeworks altered. But, it is not just the \norganizations that have become affected; \nso too, in conjunction, have the attacks. \nThe Madrid bombings in 2004, an arguable \nstarting point for this transition, saw the \ninternet, for one of the first times, play a \ncritical role in instructing the attackers.61 \nNumerous later attacks also employed the \ninternet, including the 2005 Cairo Khan \nal-Khalili attack, the 2006 failed bomb plot \nin Germany, and the 2007 plot to bomb \nGlasgow and London\u2019s West End.62 \n   Analysis of cases from the 2004 period \npresents a clear example of the \u201cinversion \nof power\u201d63 for which the internet has \nprovided. As Schwartz argues, AQ has \nmade \u201cexceptional use\u201d64 of the internet \nwith regard to recruitment. However, \nthe case of Y ounis Tsouli, known by his \nscreen name \u2018Irhabi007\u2019 , presents an \ninstance in which power had switched \nfrom the command of AQ to the leader -\nless online jihadis. The \u201cexceptional use\u201d , \nwhich Schwartz refers to, was only able to \noccur due to the facilitation of people like \nTsouli. A young Tsouli, a Moroccan-born \nresident of the United Kingdom, became \nrenowned for being the \u201cinternet jack-of-\nall-trades\u201d65 for aspiring jihadis, allowing \ndissemination of propaganda, beheadings \nand bomb-making manuals. This attracted \nthe attention of AQ leadership, prompting \nthem to seek Tsouli\u2019s assistance in setting \nup web forums, chat rooms and means \nof distribution for their social presence.66 \nAspiring extremists flocked to them, all \nwith the hope of receiving approval from \nthe countless Islamist recruiters within.67 It \nwas these forums, set up by Tsouli, which \nmay have become the breeding ground \nfor the start of the transitionary period, \nbeginning the evolution of contemporary \nreligious terrorism and the \u2018leaderless \njihadi\u2019 movement.\nTransition and the Political \nAppeal\n   Finally, it is key to examine possible \ncounterpoints to this thesis. Critics of \nthis transitionary theory argue that the \naforementioned points are merely just a \nnew tactic used by Islamist organizations, and that we are in fact still firmly within \nthe Fourth Wave. It would be naive of this \nthesis to assume that terrorist organiza -\ntions cannot adapt. However, these critics \nare only partially correct. Rapoport\u2019s Wave \ntheory works around a steady decline and \nthen a steady incline, in a \u2018wave-like\u2019 mo -\ntion. He contends that the waves possess \n\u201cexpansion and contraction phases. \u201d68 \nTherefore, it can be argued that the events \nthis thesis has documented place the \nFourth Wave in this \u2018contraction\u2019 phase, in \nwhich political appeal has played a large \ninfluence. \n   This would not be the first time that \nsuch an influence has presented itself. As \nRapoport himself contends, when assess -\ning the transition between the Third and \nFourth Wave, religion had more political \nappeal than neo-Marxism.69 Could it not \nbe advocated that nationalism is now \nin possession of more political appeal \nthan religion? This is arguably the same \ntransition witnessed in previous waves, \nand, in this case, is exhibited through the \npseudo-state aims of the Islamic State, the \ndominant organization of terror within \ncontemporary religious terrorism. \n   In addition, it must be highlighted that \ncritique based on the argument that the \n2003 Iraq War was purely of a religious \nnature does not hold true. While it is \nclear that there was much religious divide \nwithin the Iraq War, not all militants in, \nand following, the conflict were fighting \nfor religion. Rather, in display of a possible \nemerging energy, there was also a substan -\ntial nationalistic dimension to be found.70 \nAs such, while events may well have been \nwithin the Fourth Wave, this does not \nrule out a steady contraction in the wave\u2019s \nenergy. \n   Twelve years on, we can see how the \n\u2018leaderless jihad\u2019 effect has shown steady \nincreases and propagation within society. \nA new energy has emerged. One which has \nseen religiously motivated groups set their \nsights on the establishments of states and \ngovernance. Attacks are now not only be -\ning inspired by these pseudo-states, as with \nOrlando in 2016,71 but there is also the \nemergence of a new type of terrorist. One \nwhich commits attacks as a \u201csoldier\u201d in the \nname of the pseudo-state, despite having \nno guidance or communication from such \nan entity, operating in mere blind national -\nistic rationale.72 It is this rhetoric which The Internationalist            Vol. II, Spring 2017\n23\nvastly differs from that of the Fourth Wave \nenergy.\n   Evidence of a transition has been shown \nthrough the evolution of strategy and the \ndevelopment of technology. The aforemen -\ntioned attacks have only been possible due \nto the advancements in communication \nthat makes the concept of decentralized \nleaderless attacks, and the network in \nwhich they are conceived, a characteristic \nthat is unlike anything the Fourth Wave \nhas been able to demonstrate until this \npoint. These extremist networks, hidden \nin the depths of the internet and the dark \nweb, have become the hand which guides \nglobal terrorism.73 This is something which \nwas not apparent in the years prior to \n2004.\nConclusion\n   It is arguably apparent that we are \ncurrently witnessing, within the confines \nof Rapoport\u2019s theory, a transformation of \nboth \u2018energy\u2019 and strategy within modern \nterrorism. A pattern is clearly developing \nupon which political appeal is becoming \nthe catalyst for which these transitions \ncan occur. This itself puts the somewhat \nphilosophical question into the forefront \nas to whether there is an underlying mo -\ntive upon which all of these waves stand. \nAs with Rapoport\u2019s own admittance, the \npolitical appeal was clearly acknowledged \nin the transition between the Third and \nFourth Waves, which begs the question \nas to whether this is a recurring theme. \nAs the Fourth Wave clearly demonstrated \nthe ability for religion to be used as a tool \nfor political gain, we may now possibly be \nseeing an adaptation of this in which na -\ntionalism is the apparatus once again upon \nwhich terror organizations can divide and \ntorment the population. \n   This thesis would therefore contend that, \nwhile Rapoport\u2019s Wave theory is a succinct \nway to measure trends and patterns of ter -\nrorism, he does not lay enough focus onto \nthe contraction phase. While an energy \nmay be dominant, there is a peak within \nthe wave from which this energy must, at \nsome point, enter a state of decline. This, \nhowever, does not mean it is no longer the \ndominant energy. Assuming that Rapoport \nis correct, the Fourth Wave\u2019s energy en -\ntered into dominance in 1979 and will be \nsuperseded by the energy of the Fifth Wave \nin 2025. This would imply that the half-way point of the wave would be 2002. After \nthis point, as supported by this thesis, the \nFourth Wave began its contraction and \nentered into its period of transition.\nCitations\n1. Bush, George W . \u201c Address to a joint \nsession of Congress and the American \npeople. \u201d Harv. JL & Pub. Pol\u2019y 25 (2001): \nxviii.\n2. Ibid., xviii.\n3. Shinkman, Paul D. \u201cObama: \u2018Global \nWar on Terror\u2019 Is Over. \u201d US NEWS. May \n23, 2013. Accessed December 4, 2016. \nhttp://www.usnews.com/news/arti -\ncles/2013/05/23/obama-global-war-on-ter -\nror-is-overover&p=DevEx,5090.1. \n4. Rapoport, David C. \u201cThe Four Waves of \nModern Terror: International Dimensions \nand Consequences. \u201d An International His -\ntory of Terrorism: Western and Non-West -\nern Experiences. Routledge, 2013: 283.\n5. Ibid., 283.\n6. Ibid.\n7. Ibid., 282.\n8.  Ibid., 286.\n9. Ibid., 282-283.\n10. Ibid., 285.\n11. Ibid.\n12. Ibid., 295.\n13. Ibid.\n14. Ibid., 304.\n15. Ibid., 283.\n16. Burke, Jason. Al-Qaeda: the true story \nof radical Islam. IB Tauris, 2004. 1.\n17. Farrall, Leah. \u201cHow Al Qaeda Works-\nWhat the Organization\u2019s Subsidiaries Say \nabout Its Strength. \u201d Foreign Aff. 90 (2011): \n129.\n18. McCants, William. \u201c Al Qaeda\u2019s Chal -\nlenge: The Jihadists\u2019 War With Islamist \nDemocrats. \u201d Foreign Aff. 90 (2011): 24.\n19. Wright, Lawrence. The looming tower. \nVintage, 2006. 109.\n20. Ibid., 109-110.\n21. Rapoport, The Four Waves of Modern \nTerror,  295.\n22. Farrall, How Al Qaeda Works-What \nthe Organization\u2019s Subsidiaries Say about \nIts Strength, 129-131.\n23. Rabasa, Angel, Peter Chalk, Kim \nCragin, Sara A. Daly, and Heather S. \nGregg. Beyond al-Qaeda: Part 1, the global \njihadist movement. Vol. 1. Rand Corpora -\ntion, 2002. 28-29.\n24. Sageman, Marc. Leaderless jihad: Ter -\nror networks in the twenty-first century. University of Pennsylvania Press, 2011. \n43-44.\n25. McCants, Al Qaeda\u2019s Challenge: The Ji -\nhadists\u2019 War With Islamist Democrats, 23.\n26. Gunaratna, Rohan. Inside Al Qaeda: \nglobal network of terror. Columbia Uni -\nversity Press, 2002. 57.\n27. Farrall, How Al Qaeda Works-What \nthe Organization\u2019s Subsidiaries Say about \nIts Strength, 133-134.\n28. Zelin, Aaron Y . \u201cThe war between \nIsis and Al-Qaeda for supremacy of the \nglobal jihadist movement. \u201d The Washing -\nton Institute for Near East Policy 20, no. 1 \n(2014): 8.\n29. McCants, Al Qaeda\u2019s Challenge: The Ji -\nhadists\u2019 War With Islamist Democrats, 24.\n30. Farrall, How Al Qaeda Works-What \nthe Organization\u2019s Subsidiaries Say about \nIts Strength, 131.\n31. Ibid.\n32. Sageman, Leaderless jihad: Terror net -\nworks in the twenty-first century, 126.\n33. Rahimullah Yusufzai and Fawaz \nGerges, \u201cWhat Has Happened to Al-Qae -\nda?, \u201d BBC News, April 06, 2016, accessed \nDecember 02, 2016, http://www.bbc.com/\nnews/world-middle-east-35967409.\n34. Haykel, Bernard. \u201cParis Confirms IS\u2019s \nWeakness. \u201d The Hindu. April 20, 2016. \nAccessed December 06, 2016. http://www.\nthehindu.com/opinion/op-ed/paris-con -\nfirms-iss-weakness/article7892753.ece.\n35. Ibid.\n36. McCants, William. The Believer: How \nan Introvert with a Passion for Religion \nand Soccer Became Abu Bakr al-Baghda -\ndi, Leader of the Islamic State. Brookings \nInstitution Press, 2015.\n37. Europol Public Information. \u201cChanges \nin Modus Operandi of Islamic State (IS) \nRevisited. \u201d Europol, 2016. 3\n38. Ibid., 3-4\n39. Haykel, Bernard. \u201cParis Confirms IS\u2019s \nWeakness. \u201d The Hindu. April 20, 2016. \nAccessed December 06, 2016. http://www.\nthehindu.com/opinion/op-ed/paris-con -\nfirms-iss-weakness/article7892753.ece.\n40. Europol Public Information. \u201cChanges \nin Modus Operandi of Islamic State (IS) \nRevisited. \u201d Europol, 2016. 4.\n41. Ibid., 14.\n42. Sageman, Leaderless jihad: Terror net -\nworks in the twenty-first century, 129.\n43. Sageman, Marc. \u201cThe next generation \nof terror. \u201d Foreign Policy 165 (2008): \n39.The Internationalist            Vol. II, Spring 2017\n24\n44. Ibid., 38-39.\n45. Sageman, Leaderless jihad: Terror net -\nworks in the twenty-first century, 143.\n46. Ibid., 143.\n47. Ibid., 145.\n48. Ibid., 142.\n49. Ibid., 136.\n50. Hoffman, Bruce. \u201cThe changing face of \nAl Qaeda and the global war on terrorism. \u201d \nStudies in Conflict and Terrorism 27, no. 6 \n(2004): 549.\n51. Cronin, Audrey Kurth. \u201cISIS is not \na terrorist group: why counterterrorism \nwon\u2019t stop the latest jihadist threat. \u201d For -\neign Aff. 94 (2015): 89.\n52. Sageman, Leaderless jihad: Terror net -\nworks in the twenty-first century, 144.\n53. Simon, Jeffrey D. \u201cTechnological and \nlone operator terrorism: Prospects for a \nFifth Wave of global terrorism\u201d An Inter -\nnational History of Terrorism: Western \nand Non-Western Experiences. Routledge, \n2013: 46.\n54. Rabasa, Beyond al-Qaeda: Part 1, the \nglobal jihadist movement, 18.\n55. Simon, Technological and lone opera -\ntor terrorism: Prospects for a Fifth Wave of \nglobal terrorism, 48.\n56. Ibid., 48.\n57. Sageman, Leaderless jihad: Terror net -\nworks in the twenty-first century, 119.\n58. Ibid., 114.\n59. Ibid., 114\u2013117.\n60. Ibid., 113\u2013114.\n61. Ibid., 109\u2013110, 113.\n62. Ibid., 113.\n63. Ibid., 120.\n64. Ibid., 120.\n65. Kohlmann, Evan F. \u201cReal Online Ter -\nrorist Threat, The. \u201d Foreign Aff. 85 (2006): \n118-119\n66. Corera, Gordon. \u201cThe World\u2019s Most \nWanted Cyber-jihadist. \u201d BBC News. Janu -\nary 16, 2008. Accessed December 06, 2016. \nhttp://news.bbc.co.uk/2/hi/7191248.stm.\n67. Kohlmann, Evan F. \u201c Al-Qaida\u2019s MyS -\npace: terrorist recruitment on the internet. \u201d \nCTC Sentinel 1, no. 2 (2008): 8-9.\n68. Rapoport, The Four Waves of Modern \nTerror, 283.\n69. Ibid., 295.\n70. Simon, Technological and lone opera -\ntor terrorism: Prospects for a Fifth Wave of \nglobal terrorism, 51.\n71. Ellis, Ralph, Ashley Fantz, Faith \nKarimi, and Elliot C. McLaughlin. \n\u201c49 Killed in Florida Nightclub Terror Attack. \u201d CNN. June 13, 2016. \nAccessed December 06, 2016. http://www.\ncnn.com/2016/06/12/us/orlando-night -\nclub-shooting/.\n72. Blau, Max, Emanuella Grinberg, and \nShimon Prokupecz. \u201cInvestigators: Ohio \nState Attacker Inspired by ISIS. \u201d CNN. \nNovember 29, 2016. Accessed December \n06, 2016. http://www.cnn.com/2016/11/29/\nus/ohio-state-university-attack/.\n73. Sageman, Leaderless jihad: Terror net -\nworks in the twenty-first century, 121.The Internationalist            Vol. II, Spring 2017\n25\nT he Black Panthers of Israel emerged in \nearly 1971 as a grassroots social movement \nthat was a manifestation of Mizrahi and \nSephardi discontent surrounding a num -\nber of issues prevalent in Israeli society \nat the time. The Mizrahi Jews were Jews \ncolloquially recognized as Jews of \u201coriental \ndescent\u201d , referring to their ethnic heritage \nfrom Arab or Central Asian cultures, while \nthe Sephardi Jews were Jews of Spanish \ndescent or with ethnic heritage from the \nlarger Iberian Peninsula. These groups \nstood in sharp contrast to the majority of \nIsrael who were descended from Europe -\nan Jews and centered around the Jewish \ndiaspora. Created in the ethnically-diverse \nJerusalem neighborhood of Musrara, a \nsmall core of young Jews began one of \nthe most unique protest groups in Israeli \nhistory1 driven by social inequalities across \nissues including housing, wage discrimina -\ntion, police violence, and the discrimina -\ntory attitudes of the Ashkenazi (European \nJewry) towards them. Such significant class \nand ethnic inequalities set the context for \nthe birth and growth of the Israeli Black \nPanther movement. \n   When the Black Panthers of Israel \nemerged in early 1971, twenty-three years after the creation of the Israeli state, \nnon-Ashkenazi Jews had proportionally \nlower standards of living than their Ashke -\nnazi counterparts.2 As of 1971, the average \nnon-Ashkenazi had an income averaging \nabout 54% of comparable Ashkenazi, and \na relative 59.3% primary school atten -\ndance rate.3 Their relative existence on the \nsocioeconomic periphery of Israeli society \ncultivated strife, resentment, and harsh at -\ntitudes regarding the political climate that \nled them to that point.  Such social issues \ncontributed heavily to the formation of the \ngroup and were compounded by the idea \nthat the Ashkenazi-majority government \ndid not want to act to solve them. Black \nPanther representative Kohkavi Shemesh \narticulated this popular sentiment well \nwith his statement that \u201cthe govern -\nment can solve the poverty problem, it \njust doesn\u2019t want to; the government is \nsupported by and represents the wealthier \n(Ashkenazi) classes. \u201d4 Shemesh\u2019s articula -\ntion of the belief that the government was \ninactive in attempting to rectify non-Ash -\nkenazi social and economic problems \nexemplifies the intersectionality of class \nand ethnic discrimination that served as a \ndriving force in the emergence of the Black \nPanthers in 1970s Israel.Mizrahi and Sephardi Social \nClimate of the 1970s\n   As discussed above, there existed a strong \nresentment of the social stratification in \nIsrael at the beginning of the 1970s, and \nthis ultimately contributed to the climate \nthat caused the Black Panthers to emerge. \nMuch of the negative feeling around the \nissue was directed towards the government \nand their policies that exacerbated income \ndisparity. In the 1950s and 1960s, state \nsponsored labor made up a large sector of \nthe Israeli economy; however, the amount \nof newly created low-paid, unskilled jobs \nthat went to Mizrahi and Sephardi Jews \nwas greater than Ashkenazi both pro -\nportionally and in absolute terms.5 As a \n1971 New Y ork Times report put the new \neconomic growth, \u201can ethnic split (in the \neconomy) was appearing\u2026 the Ashke -\nnazim were the managers and Sephardim \nthe managed\u201d .6 Although this sentiment \nwas widely recognized, the lack of political \nclout by the Mizrahi meant that no politi -\ncal change could be implemented. \n   One aspiring Mizrahi politician protested \nthat \u201ctoday the Oriental (Mizrahi) Jews, \nwho make up 52% of the population, hold \nless than 10% of the seats in Parliament, \n9% of the top jobs in government and the The Black Panthers \nof Israel\nBeginning in 1971, an activist group of Sephardic and Mizrahi Jews known as \u201cthe Black Panthers of \nIsrael\u201d emerged in Jerusalem. Modeled after the American Black Panthers, the Black Panthers of Israel \nmovement was created by Sephardic and Mizrahi Jews as a social justice mission to better the living \nand social conditions of the communities it represented. That sentiment, of marginalization compared \nto the Ashkenazi, left them on the outside of the Israeli social circle and manifested in different means \nof protest and resistance in pursuit of equality in Israel.  They played a significant role in the history \nof Arab Jewish culture, as a political manifestation of the sentiments of three generations of Mizrahi, \nthe Jews of Arab or Central Asian descent that made up their constituency. While the Black Panthers \nof Israel effectively dissolved in 1973, they served to draw focus to the widespread feelings of unrest \nand marginalization that Mizrahi and Sephardi Jews experienced in the 1960s and 1970s Israeli state. By Brian Fields\nJunior Political Science Major, Urban Studies and Planning, History MinorThe Internationalist            Vol. II, Spring 2017\neconomy\u201d .7 It was not that the Mizrahi did \nnot have the desire to implement change \nin economy policy, but that they lacked \nthe capacity to do so given that the ethnic \nmajority that controlled Congress benefit -\nted disproportionately from their policies \nand thus were less inclined to change \nthe system. With this proportionally low \nrepresentation and proportionally high \npoverty rates, conditions were ripe among \nthe non-Ashkenazi community for a polit -\nical uprising.\n   Beyond their economic rights, many \nMizrahi and Sephardi believed that the \nAshkenazi controlled government were \nalso violating the Zionist promise at the \ncore of Israel\u2019s formation. In the early days \nof the Israeli state, Zionist doctrine was re -plete with rhetoric discussing how the Jews \nwere \u201cone people\u201d that were to be united in \nan egalitarian Israel. Indeed, it was seen to \nbe so significant that it was codified in the \n\u201cLaw of Return\u201d , which gave all Jews the \nright to return to Israel and gain Israeli cit -\nizenship.8 The Mizrahi and Sephardi Jews, \nhowever, didn\u2019t feel as though the state was \nfulfilling its promise of an egalitarian so -\nciety. The expansion of low-paying private \nsector jobs coupled with lack of action in \nresolving these groups\u2019 economic policies \nexacerbated poor living conditions and \nwas a factor in the betrayal that these Jews \nfelt. One parliamentarian articulated this \nsentiment of betrayal of the Zionist vision, \nstating that \u201cZionist ideology says that we \nare one people, all equal, and it doesn\u2019t matter where you come from, but sudden -\nly we are not equal\u201d .9 Other Mizrahi and \nSephardi often wondered why they came \nto Israel when they would face unequal \ntreatment at the hands of the state, claim -\ning that \u201cwhat happens to the Jews abroad \nis the same as what happens to Sephardim \nh e r e\u201d.10 This political and economic be -\ntrayal by the state ultimately factored into \nthe political restlessness that caused the \ndivision of the Jewish people and the rise \nof the Black Panthers in 1971.\nResponses to Formation of \nthe Black Panthers\n   The first major emergence of the Israeli \nBlack Panthers into the public sphere \nGrace Ann McGlaughlin, \u201817\nNamtso, the largest lake in Tibet, is regarded as holy. We drove ten hours across rural Tibet to reach it, arriving late at \nnight. The elevation was intense, and the night was cold, but in the morning we were greeted by the most beautiful place I \nhave ever seen. The water was a brilliant blue, and the sky felt close enough to touch. Despite harsh conditions, life, \nand, culture thrived.The Internationalist            Vol. II, Spring 2017\n27\noccurred on the 3rd of March, 1971, \nspawning from this protest and continu -\ning throughout the spring and summer \nas a large array of responses to the Black \nPanthers emerged. In the Mizrahi and \nSephardi communities, the responses \noften differed across generations. Al -\nthough there were many first generation \nMizrahi involved, second generation were \nthe most enthusiastic and formed most \nof the leadership of the organization.11 \nY oung men such as Saadia Marciano and \nCharlie Biton, who averaged a fourth \ngrade education and were only around age \ntwenty at the time of the party\u2019s formation, \nwere extremely enthusiastic about the \nmovement.12 The popularity among young \nMizrahi was reflected in the core\u2019s periph -\nery, which had \u201ctwenty to thirty commit -\nted younger boys and a core of committed \nhelpers\u201d .13 According to one young Mizrahi \nman, \u201cthere are two kinds of people in this \ncountry: a superior one and an inferior \none. If our parents are quiet all the time- \nwe are not going to keep quiet\u201d .14 His \nstatement mirrors the cross-generational \ndifferences of reaction regarding social \nconditions and highlights the heavy youth \ninvolvement in the movement, while at \nthe same time implicating much of the \nolder generation as being less active than \nthe Mizrahi youth. Reactions among the \ndifferent members of the Israeli Black \nPanther constituency were also contingent \nupon location, with the highest levels of \nsupport for the Panthers in urban areas, \nspecifically Jerusalem, but with tinges of \nsupport in Haifa and Tel Aviv. This can be \nattributed to both the ability of urbanites \nto mobilize as well as the dense popula -\ntions, which allowed for stronger networks \nof support. Mizrahi responses to the move -\nment, well varied, showed that there were \ndeeply rooted social issues that unsettled \nlarge sections of the community. \n    Ashkenazi responses were largely \nnegative, with some exceptions. Because \nmany of the issues they raised were inter -\nsectional and also applied to lower class \nAshkenazi, they had some support from \npeople across ethnic lines. Additionally, \nAshkenazi members of Knesset, the Israeli \nParliament, thought it would be politi -\ncally expedient to court the Mizrahi and \nSephardi constituencies that made up the \nBlack Panther support base which led to \nboth the Communist Party and right-wing Likud Party seeking political coalitions \n(although both ultimately failed in this \nobjective).15 Most of the  wealthy and \npolitically powerful Ashkenazi, however, \nhad tumultuous relationships with the \nBlack Panthers. According to Golda Meir, \nthe Black Panthers were a \u201cthreat to Jewish \nunity\u201d , a sentiment echoed by many in the \nupper tiers of Israeli society.16 With mili -\ntarized opponents surrounding them and \nhaving recently fought the Six Day War, \nthe Prime Minister was hesitant to become \nengulfed in domestic social unrest. Over -\nall, the response from Ashkenazi towards \nthe Black Panthers was mixed, standing in \nstark contrast with general support coming \nfrom Mizrahi as a whole.\nProtest Practices and \nSymbolism\n   The practices of the Black Panthers \nserved as symbols of Mizrahi and Sephardi \nsentiment and agenda as a whole. First of \nall, the name Black Panthers was, in and \nof itself, a symbol purposefully chosen \nto show that the marginalized groups of \nIsraeli society were, like their unrelated \nAmerican namesake, empowering them -\nselves and working for social and eco -\nnomic justice. In choosing this name, they \nhighlighted that Israel, like 1970s America, \nhad severe class disparities that dispropor -\ntionately affected the groups that were tak -\nen advantage of and used as the source of \nanother ethnic group\u2019s wealth.17 Addition -\nally, the purposeful selection of extremely \npublic settings to showcase their platform \nand draw disproportionate responses from \npolice allowed them to weaponize govern -\nment resistance and project their message. \nPerhaps the most notable case of this was \nwhen leader Charlie Biton handcuffed \nhimself to the podium in Knesset, pro -\nclaiming \u201cthese social issues deserve more \nthan five minutes\u201d before having to eventu -\nally be cut away from the podium.18 Ad-\nditionally, the brutal retaliation by police \nserved as free negative advertising against \nthe government.  The Black Panthers \nclaimed that the government used these \nprotests as \u201ca pretense to attack\u201d the Mizra -\nhi and Sephardi people. Such examples are \nindicative of both the tension between the \nMizrahi and the government, as well as the \nframing of the Black Panther argument in \na proletariat, marginalized light.    Despite emerging from secular, leftist \nideals, the Black Panthers also utilized \nreligious ideology in their messaging. They \nemphasized the departure of Israel from its \n\u201cvision of egalitarian redemption for the \nJews\u201d to one of economic inequality for the \nMizrahi and Sephard19 and  used religious \ntexts and rituals to emphasize the signif -\nicance of the shift. Religious grounding \nalso served to add a level of legitimacy and \nauthority to their message. In one incident, \nthey took the Haggadah, or the liturgy of \nSeder, and rewrote it in the context of 1971 \nJerusalem and the struggle for Mizrahi \nrights.20 Mirroring this religious text that \nrecounts the story of Moses and his strug -\ngle to liberate slaves in Egypt, the writers \nof this 1971 Haggadah discussed issues \nsuch as socioeconomic poverty in urban \nghettos of Jerusalem and used allegory to \ncompare then Prime Minister Golda Meir \nto the slaveholding Pharaoh and the Black \nPanthers to the liberating Moses. In using \nreligious symbols such as these, the Black \nPanthers made a striking commentary on \nthe treatment of the non-Ashkenazi Jews \nat the hands of the state, which claimed to \nbe fulfilling a religious vision of egalitari -\nanism.\nConclusion\n   The Black Panther movement lost its \nmomentum when the 1973 Y om Kippur \nWar forced economic issues to the back of \nIsraeli political priorities, though remains \none of the most impactful social move -\nments in Israeli history. With continually \nlimited success at the ballot box, they \neventually dissolved and were coopted into \nthe framework of other existing political \nentities, and as generations of Mizrahi Jews \nassimilated into Israeli society the socio -\neconomic disparities became less prevalent \nof a focus for these groups. The movement \ndid, however, leave a lasting mark on \nIsraeli social society as a whole. The Black \nPanther movement was a significant man -\nifestation of the feeling that Mizrahi and \nSephardi Jews had been relegated, both \nsocially and economically, by the Ashke -\nnazi Jews who controlled the government \nand means of production in mid-20th \ncentury Israel. Though they did not last for \nan extended period of time, they served to \nshow the frustration and feelings of mar -\nginalization of Mizrahi and Sephardi \nJews and the ethnic divides that The Internationalist            Vol. II, Spring 2017\n28\nbegan to emerge in the decades following \nthe birth of the Zionist state. Through this \nprotest movement, attention was drawn \nto this marginalization and in turn drew \nwidespread focus onto the Sephardi and \nMizrahi feelings of resentment towards the \nIsraeli government. \nCitations\n1.  Bernstein, Deborah. 1981. \u201cConflict \nand Protest in Israeli Society: The Case of \nthe Black Panthers of Israel. \u201d Y outh and \nSociety 16.2: 129-152.\n2. Herschthal, Eric. 2010. \u201cIsrael\u2019s Black \nPanthers Remembered. \u201d The Jewish Week.\n3. Elon, Amos. \u201cThe Black Panthers of \nIsrael. \u201d New Y ork Times. 12 Sept. 1971.\n4. Cohen, Shalom and Kokhavi Shemesh. \n1976. \u201cThe Origin and Development of the \nIsraeli Black Panther Movement. \u201d MERIP \nREPORTS 49: 19-22.\n5. Bernstein, Deborah. 1981. \u201cConflict and \nProtest in Israeli Society: The Case of the \nBlack Panthers of Israel. \u201d Y outh and Soci -\nety 16.2: 129-152.\n6. Elon, Amos. \u201cThe Black Panthers of \nIsrael. \u201d New Y ork Times. 12 Sept. 1971.\n7. Cohen, Shalom and Kokhavi Shemesh. \n1976. \u201cThe Origin and Development of the \nIsraeli Black Panther Movement. \u201d MERIP \nREPORTS 49: 19-22.\n8. Bernstein, Deborah. 1981. \u201cConflict and \nProtest in Israeli Society: The Case of the \nBlack Panthers of Israel. \u201d Y outh and Soci -\nety 16.2: 129-152.\n9. Cohen, Shalom and Kokhavi Shemesh. \n1976. \u201cThe Origin and Development of the \nIsraeli Black Panther Movement. \u201d MERIP \nREPORTS 49: 19-22.\n10. Cohen, Shalom and Kokhavi Shemesh. \n1976. \u201cThe Origin and Development of the \nIsraeli Black Panther Movement. \u201d MERIP \nREPORTS 49: 19-22.\n11. Bernstein, Deborah. 1981. \u201cConflict \nand Protest in Israeli Society: The Case of \nthe Black Panthers of Israel. \u201d Y outh and \nSociety 16.2: 129-152.\n12. Chertit, Sami Shalom. 1971. \u201cThe Black \nPanthers in Israel- the First and Last Social \nIntifada in Israel. \u201d Manifesta Journal 15.1\n13. Bernstein, Deborah. 1981. \u201cConflict \nand Protest in Israeli Society: The Case of \nthe Black Panthers of Israel. \u201d Y outh and \nSociety 16.2: 129-152.\n14. Bernstein, Deborah. 1981. \u201cConflict \nand Protest in Israeli Society: The \nCase of the Black Panthers of Israel. \u201d Y outh and Society 16.2: 129-152.\n15. Bernstein, Deborah. 1981. \u201cConflict \nand Protest in Israeli Society: The Case of \nthe Black Panthers of Israel. \u201d Y outh and \nSociety 16.2: 129-15.\n16. Chertit, Sami Shalom. 2010. Intra-Jew -\nish Conflict in Israel: White Jews, Black \nJews. London: Routledge.\n17. Lubin, Alex. 2014. Geographies of \nLiberation: The Making of an Afro-Arab \nPolitical Imaginary. Chapel Hill: U of \nNorth Carolina\n18. Chertit, Sami Shalom. 1971. \u201cThe Black \nPanthers in Israel- the First and Last Social \nIntifada in Israel. \u201d Manifesta Journal 15.1\n19. Shalev, Asef. 2015. \u201cWhen Israel\u2019s Black \nPanthers Wrote Their Own Haggadah. \u201d -\nForward 1.7\n20. Shalev, Asef. 2015. \u201cWhen Israel\u2019s Black \nPanthers Wrote Their Own Haggadah. \u201d -\nForward 1.7The Internationalist            Vol. II, Spring 2017\n29\nThe Congo as a Failed State\nIn order to understand what it means to \nhave a weak state, one must first define \nexactly what we mean by \u201cstate. \u201d In this \npaper, \u201cThe modern state may be defined \nas an institution that successfully claims \na monopoly of the means of violence, \ncontrol over a territory and a population \nand the responsibility to provide services, \nand is recognized by other states. \u201d4 Even a \nconcise definition reveals major problems \nwith the DRC. I will first work through the \nabove definition\u2019s application to the DRC \nbefore then providing other pertinent \ninformation on the state.\nThe easiest measurement to draw from \nEriksen\u2019s definition of statehood is the \nqualification that the DRC must be \n\u201crecognized by other states. \u201d For ease of \nanalysis, I will use the United Nations as \nthe putative authority on states. The DRC \nis a member state of the United Nations \nand is universally recognized by its other \nmember states.5 Measuring other qualifiers in Eriksen\u2019s definition is more complex and \nambiguous. Because the DRC is universal -\nly recognized as a state, its failure to clearly \nreach other qualifiers indicates it is a weak \nstate rather than not a state at all.\nThe most catastrophic failure for our \nmeasurement of statehood is controlling \na monopoly on violence. By this measure \nthe DRC is substantially weak and suffers \nthe associated consequences. For example, \n\u201cWeak states lack a monopoly on violence, \nand must face the insurrection of armed \ngroups. \u201d6 Almost nowhere is this statement \nmore accurate than in the DRC, where \narmed rebel groups are abundant and \nresponsible for enormous devastation. In \nthe Kivu regions alone, there are almost 70 \nknown armed groups and more than one \nmillion people have been forcibly dis -\nplaced (ACAPS).7 Additionally, these rebel \ngroups compound the issues of a weak \nstate by further undermining its power \nand institutions. One group, the armed \nmovement called \u201cMai-Mai\u201d (also written Mayi-Mayi), is of particular relevance.\n \nAnti-Allochthon Sentiment in \nMilitias\nThe Mai-Mai are not a singular group; \nrather they are a collective name given \nto multiple nationalist resistance militias \nin the DRC.8 Though their alliances shift \nfrequently,9 the Mai-Mai always have \none objective: to persecute and terrorize \nRwandophones in the DRC, especially in \nthe eastern Kivu regions. Nationalist goals \nto reclaim the DRC and expel foreigners \nmotivate this anti-allochthon activity. The \nMai-Mai\u2019s hate speech has been so harsh \nand pointed, one Congolese tract central -\nizes this rhetoric to the group reading, \n\u201cMututsi Aende Inje [Tutsi Get Out!]\u2013\nMkongomani Aongoze Inchi [Congolese \nGuard Y our Country!]\u2013or MAI-MAI for \nshort\u201d (Jackson 2006:106), though this is \nnot the group\u2019s true eponym. Leaders of \nthe groups pressure potential members \ninto joining the Mai-Mai by presentingThe Democratic Republic of the \nCongo: Insecurity and Conflicts of \nBelonging\nBy Morgan Pratt\nGlobal Studies and Music Double MajorThe Internationalist            Vol. II, Spring 2017\n\u2018Congolese\u2019 is the term used to describe someone from the Democratic Republic of the Congo (DRC).1  \nWhen discussing who is from the DRC, however, one must be wary of the audience. Allochthon, a term \nused to describe someone who does not belong to an area, is an invaluable term for social discourse \non the DRC with a very subjective and situational usage. Its antonym, autochthon, comes from Greek \nmeaning \u201cemerging from the soil, \u201d though declaring such a thing in the DRC is a nervous enterprise.2  \nAs Jackson writes, \u201c At some level, no one in the DRC seems to be sufficiently autochthonous to escape \nat some point becoming the target for accusations of foreignness\u201d.3  In this paper, I will argue these \nwidespread, ambiguous and catastrophic accusations of allochthony are catalyzed by the weakness \nof the DRC state. To explain this, I will first explore the DRC state and its shortcomings. Then, I \nwill show how the power vacuum of a weak DRC state has and continues to allow anti-allochthon \nactivity to terrorize many of its inhabitants. One particularly vulnerable people are denizens of the \nDRC who speak Kirundi or Kinyarwanda. There are many names for this group this paper and its \nsources will use interchangeably throughout this paper including Rwandophones, Banyarwanda and \nMunyamulenge (singular) or Banyamulenge (plural). These are all names encompassing both Hutus \nand Tutsis, which are each distinct ethnic subgroups.\ntheir communities as victims of Rwan -\ndan-Rwandophone conspiracy that leads \ntrue Congolese to be \u201con the point of being \nexterminated. \u201d10 \nLike other armed rebel groups, the \nMai-Mai gained footing in the absence \nof an adequate government presence. \nThough their exact origin is unknown, \nthe deterioration of East Congo at the \nbeginning of the 1990s left conditions \nfavorable for the rise of the Mai-Mai.11 \nThe East Congo\u2019s decline occurred after \nunpopular state land seizures and financial \nstrain on the patronage system left the \nregion with low economic prospects and \ninter-generational conflict.12, 13 In Masisi, \na region north of Goma, \u201ctraditional \nchiefs of the indigenous population, particularly Hunde, began to mobilise \nyoung people against Banyarwanda\u201d due to \nsaid conflict.14 Shortly thereafter self-de -\nclared \u201cautochthonous militias\u201d began to \nmassacre the Banyarwanda community, \nmotivated by longstanding arguments \nover land, socioeconomics and nationality, \nwhich also means political access in this \ncontext.15 This means political access here \nbecause Rwandophone control over dis -\nproportionate amounts of land in the Kivu \nregions has historically led to discontent in \nother populations16\u2013discontent expressed \noften through attempts to restrict Rwan -\ndophone voting rights. It is crucial to note \nthat this division has existed for decades17  \nand cannot be labeled as responsible for \nthe spawning of the Mai-Mai; the lack of established politically regulatory power \ncombined with the militarization of society \nis what allowed the Mai-Mai to rise. Now \nin power, the Mai-Mai cause widespread \nviolence through pillaging, rape and \nmurder while simultaneously utilizing \nthe subsequent insecurity as part of their \nrecruitment strategy.18  \nThe Mai-Mai\u2019s activity continues to \nprovide evidence of a weak Congolese state \nthrough their occupation of territory and \ncontrol over populations. Furthermore, the \nMai-Mai capitalize upon the weaknesses \nof the Congolese state to increase their \ninfluence in these areas. \u201cIn East Congo, \nenrollment in rural militias is a response \nto a \nParker Owen Vige, \u201820\nPrior to their freshman year, UNC selects several admitted students as Global Gap Year Fellows, giving them the \nopportunity to explore different geographies and to engage with people from around the globe. Through this program, I \ntraveled to Kybirwa, Uganda, in an effort to contribute what I could to the community and learn about the crossroads of \nethics and sustainability. This photo tells the story of people working with nature to care for themselves and their families. \nIn the four months I spent living in the village, it was clear that the Nile was the lifeblood of the community .The Internationalist            Vol. II, Spring 2017\n31\ncomplete lack of alternatives such as social \nand economic integration and security. \u201d19  \nLack of viable alternatives in combination \nwith social and economic marginalization \nis a growing problem in the eastern DRC \nand is of particular concern to young \nmales.20, 21 \u201cY oung\u201d here includes, but is \nnot limited to, those who would be child \nsoldiers.22 Vulnerability of the young is \nimportant because \u201cin Africa there is a \nstrong correlation between the social and \neconomic marginalisation of young people \nand war. In East Congo, as well as in other \nwar-torn areas, young combatants often \nemerge as new and leading actors. \u201d23 To \nthe marginalized, the Mai-Mai provide \nsocial mobility and an escape from critical \nconditions economically. Although not \ndirectly mentioned in the above definition \nof a state, it certainly does not help that the \nDRC does not provide economic opportu -\nnity to many of its inhabitants. Even today, \nafter modest recovery from the turmoil of \nthe 1990s, the GDP per capita is US$800.24 \nCompared to the dysfunctional DRC state, \nthe Mai-Mai proclaim they strive for a \nDRC free of dictatorship, Western impe -\nrialism and classes.25 It is easy to see why \nthis promise finds success in the context \nof the DRC\u2019s socioeconomic climate. The \nlack of economic stability can be further \naggravated by chaos in the wake of violent \ngroup activity. Chaos is not a problem for \nthe Mai-Mai because, \u201cSometimes, the \nchoice to enroll is justified simply by the \nwill to pillage and take profit from the \nsituation of disorder. \u201d26  Membership in an \narmed group provides safety both in num -\nbers and power. Occasionally, the Mai-Mai \nprovide bodyguards as well.27 The Mai-\nMai perpetuate terror and insecurity, use \nthis as a recruitment strategy, and further \ncompound the problems the DRC faces \nwhile simultaneously claiming to offer \nsolution. If the state had complete control \nover its territory and its inhabitants, as well \nas a monopoly on violence, such disorder \nwould likely not exist to motivate the peo -\nple attracted to chaotic situations.\nOne source that makes the state\u2019s cul -\npability for popularity of armed groups \nabundantly clear is a survey conducted \nby UNICEF in 1997 Bukavu. This survey \nquestioned members of the Alliance des \nForces D\u00e9mocratiques pour la Lib\u00e9ration \ndu Congo/Za\u00efre (AFDL), a disbanded \nmilitant group Kabila used to overthrow President Mobutu and former ally of \nthe Mai-Mai, though the Mai-Mai later \nchanged their allegiance.28 According to \nVan Acker and Vlassenroot, this survey \nshowed 25% joined the AFDL due to \npromises of generous compensation, 28% \nbecause they lacked other opportunities, \n15% were convinced by other members, \n15% wanted revenge against Kabila\u2019s army \nand only 7% joined for patriotic reasons \nsuch as to liberate the country.29 If one \nextrapolates this information to analyze \nthe Mai-Mai and other rebel groups, the \nrole a weak state plays in the propagation \nof rebel groups\u2013and therefore anti-alloch -\nthon activity\u2013becomes clear.\nThe above discussion of economic dis -\nenfranchisement creating an environment \nripe for recruitment to armed groups \nrelates to our definition of a state under \n\u201cresponsibility to provide services. \u201d While \nit is difficult to determine which services \nare a responsibility of the state to provide, \none can observe how the absences of \ncertain services have become problematic. \nOne example that provides us an oppor -\ntunity to see such a vacancy is arms. The \nsaturation of arms in the DRC shows the \nneed for a service\u2013in this case, security\u2013is \nnot met by the state. \u201cThe proliferation \nand flows of small arms have facilitated \nthe continuation of conflict, the militariza -\ntion of society, and illegal cross-border \ntrade. \u201d30  Activity surrounding weapons \nnot only reflects a widespread attitude of \nviolently seizing what the state cannot \nprovide, it also creates and perpetuates \n\u201cillegal\u201d systems, or those done without \nthe involvement and against the wishes \nof the state. For example, \u201c...most of the \nfactions [of the Mai-Mai] have turned \ninto private militias and are paid by big \ndealers who needed protection for their \ngold and coltan traffic. \u201d31 Predictably, \u201cThe \nlucrative trade in coltan, gold, diamonds, \ntin and other resources extracted through \nviolence has unleashed a permanent reign \nof terror in the region\u2026 \u201d32  Here, it is easy \nto see how the various weaknesses of the \nDRC state reinforce each other. For this \nreason it is difficult to determine whether \nresorting to hire factions of the Mai-Mai to \nprotect trafficking of resources is a failure \nto provide a service or a failure to maintain \na monopoly on the subsequent violence. \nRegardless, the fact that illegal seizure and \nsale of the DRC\u2019s resources occurs shows a fundamental lack of adequate state in -\nfrastructure; the DRC does not seem to be \nable to provide its inhabitants the service \nto safely participate in international and \nintranational resource trade.\nAnti-Allochthon Sentiment in \nLocal, Provincial and National \nGovernment\nUnfortunately, armed militias and rebel \ngroups are not unique as a means by \nwhich the state\u2019s weakness can weaponize \nanti-allochthon sentiment. Politics fans \nthe flames of autochthony discussions at \nthe local, provincial and national levels. \nThough introduced and utilized by Euro -\npean colonizers, autochthonic rhetoric has \nseen widespread use in Congolese politics \nand activity.33 This discourse finds political \nand motivational success for a number \nof reasons: it draws anger and energy \nfrom both contemporary and long-term \nconflicts, its ambiguity allows usage to be \nflexible, and because it maintains power \nsystems that disenfranchise those who \nwould argue against its use. I will provide \nsome examples of the above rhetorical \nadvantages after first analyzing how the \nrhetoric affects its targets. \nLocal Congolese politics is a complex \nendeavor where loopholes and murkiness \nallow autochthonic and anti-allochthonous \nrhetoric to thrive. One such loophole is the \nstate\u2019s use of traditional chiefs to control \nallocation of land. These chiefs have the \npower to replace or evict landowners with \nlimited oversight, and use this power to \nsubjugate Rwandophones.34 In this situ -\nation, Congolese inhabitants who speak \nKirundi or Kinyarwanda are commanded \nto \u201csubmit themselves to the autochthons\u201d \nand either vacate their property or become \na subject to an autochthon.35 These tra -\nditional chiefs have incentives to do this \nbecause many of their constituents believe \nRwandophones unjustly posses their an -\ncestral land.36 This rhetoric is not restricted \nto conflicts with Rwandophones; ongoing \ntensions between the Hunde and Nyanga \nexemplify allochthony vocabulary utilized \namong two ethnic groups seen as autoch -\nthonous at a national level. The Hunde \nand Nyanga are two groups in the North \nKivu province of the DRC, where most of \nthe anti-Rwandophone conflict is located. \nInterestingly, the Hunde and Nyanga The Internationalist            Vol. II, Spring 2017\n32\nboth mythologize their origin in mi -\ngration and more accurately exist on a \nlinguistic and cultural continuum than as \ndistinctly separate groups.37 This means the \nHunde and Nyanga are not only less than \nseparate, they could also both be consid -\nered allochthons depending on the motiva -\ntions of the speakers because, \u201c All central \nAfrica\u2019s self-styled autochthons, in fact, \nseem to accept that the true \u2018first people\u2019 of \nthe region are the now dwindling pygmoid \npopulations: the Twa in Rwanda, Burun -\ndi and the Kivus\u2026 \u201d38 The near complete \neradication and disenfranchisement of the \nTwa makes their recognition as true au -\ntochthons highly unlikely. Compounding \nthe murkiness of autochthony in this area \nare the Bashi and Baidjwi people who orig -\ninate from the Idjwi island in Lake Kivu\u2013\npart of the border between the DRC and \nRwanda. Denizens of the same province as \nthe above conflicts, the Bashi and Baidjwi \nfind themselves stuck between autochthon \nand allochthon, though disdain for their \n\u201cRwandan-ness\u201d is rising.39 What interac -\ntion between these groups at the local level \nshows us is that anti-allochthon activity is \nnot a rigid moral conundrum empowering \nthe original owners of the land but rather \na weapon used ambiguously and with \nlittle consistency in an attempt to justify \nexclusion. I will explore this more when \ndiscussion rhetorical advantages.\nThe importance of belonging occupies \nthe provincial political sphere as well. A \nfrustrating historical example is President \nMobutu\u2019s influence on the Conf\u00e9rence \nNationale Souveraine (CNS) in 1991. Con -\nstructed in response to international and \ndomestic pressure to democratise, the CNS \nwas to function as a discussion on a multi -\nparty Zaire between provincial representa -\ntives. After suggestions that the conference \nreflect \u201cdemographic weight\u201d in each area, \nPresident Mobutu promulgated \u201cdelegates \nonly represent provinces from which they \ncould be considered autochthon. \u201d40  Unsur -\nprisingly, Rwandophones were excluded \nthroughout the CNS conference after being \nlabeled as foreigners; Jackson notes, \u201cnot \none so-called Rwandan appeared on the \nfinal party delegates list\u201d .41  The barring of \nRwandophones from the political process \nalso upset the Nyanga and Hunde in North \nKivu, two groups who wanted to form a \nwinning coalition there to defeat \nthe Nande.42President Mobutu\u2019s actions here were \npart of a bigger political strategy of his \ncalled g\u00e9opolitique or \u201cgeopolitics. \u201d Since \nthen, geopolitics has infiltrated provincial \npolitical thought in the DRC. Geopolitics \napplies in political races where \u201cCandi -\ndates for provincial political office in, say, \nNorth Kivu, are often opposed on the basis \nof their origin in South Kivu and thus their \n\u201callochthon\u2019 status\u201d .43  Furthermore, NGO \naid can be seen as favoritism by the locals \ndepending on the number of autochthons \nand allochthons they employ. It is also not \nuncommon for employers to withhold \njobs based on perceived origin.44 Though \nsimilar to anti-allochthony rhetoric per -\nsecuting Rwandophones, an important \ndistinction is that, in the above examples, \nthe victims of this rhetoric are not being \nchallenged on their Congolese-ness.\nThe most virulent sphere for autochtho -\nny rhetoric is the national. It is common \nto label the unpopular or adversary as \nRwandan or foreign by some other nation -\nality. Even heads of state are not immune; \nPresident Mobutu was accused of both \nhaving foreign parents and a foreign wife.45 \nIronically, even Joseph Kabila\u2013head of a \ngovernment endorsing blatant and vitriolic \nanti-Rwandan rhetoric\u2013suffers rumors of \nbeing a half-Rwandan lovechild.46\nRhetoric is not the only consequence \nof anti-allochthon sentiments; hostility \ntowards those perceived as foreign at a na -\ntional level frequently manifests in official \nlegislation, restrictions of rights and vio -\nlence. Sadiki Koko, a researcher at Institute \nfor Dispute Resolution in Africa, provides \na possible reason for why Congolese \nofficials nonchalantly restrict citizenship \nof Rwandophones: \u201c...due to its dominant \nethnic dimension (a clear legacy of colo -\nnialism), citizenship in most African coun -\ntries is perceived as a community right, \nthe African individual deriving his/her \ncitizenship status through his/her mem -\nbership to the ethnic group\u201d .47  Later in \nCongolese citizenship battles, this concept \nsignificantly complicates interpretations of \nlaw because different members of the same \nethnic groups can have citizenship rights \nwhen others simultaneously lack them.\nRationale aside, Rwandophone citizen -\nship has always been contentious in the \nDRC. This is important because citizenship \nis the closest equivalent to autochthony \ninstitutionalized at a state level. Article 6 of the 1964 Congolese constitution reads, \n\u201cthere exists only one Congolese nationali -\nty. It is granted, beginning from the date of \n30 June 1960 [i.e. independence] to all per -\nsons having now, or at some point in the \npast, as one of their ancestors a member \nof a tribe or a part of a tribe established on \nthe territory of the Congo before the 18th \nOctober 1908\u201d .48  Though some Rwando -\nphones can trace their Congolese-inhabi -\ntant lineage to as early as the 18th century, \nmany more long-time DRC residents trace \ntheir family\u2019s arrival to the 1930s, when \nBelgian colonists imported workers from \nRwanda to alleviate famine there49 and \ncircumvent the perceived laziness of local \nlabor.50 Even more Kirundi- and Kinyar -\nwanda-speaking persons found themselves \nin the DRC as refugees fleeing the Rwan -\ndan genocide. It is estimated over one \nmillion Hutu refugees entered the Kivu \nregions in 1994.51 By this time, however, \nthe legislation had changed. \nThe first person who tried to change this \nclause in the constitution was Barth\u00e9le -\nmy Bisengimana as director of Bureau de \nla Pr\u00e9sidence from 1969 to 1977.52 Bis-\nengimana is a Congolese Tutsi and was \nappointed by President Mobutu, though \nnot for pro-Rwandophone reasons. One of \nPresident Mobutu\u2019s strategies for holding \nonto power was to appoint \u201crepresentatives \nof ethnic groups that could not threaten \nhim because they were numerically weak \nand had ambiguous political and social \ns t a t u s \u201d.53 In the early 1970s, Bisengimana \nmade multiple attempts to repeal rulings \nand proffered legislation that changed the \ncutoff date to January 1, 1950.54 Nothing \nsucceeded in changing the constitution, \nhowever, and his legislation faced serious \nopposition.55 This opposition made the \nimplementation of Bisengimana\u2019s efforts \ndifficult. In fact, even laws restricting \nRwandophone citizenship were enforced \ninconsistently and contradicted each oth -\ner.56 Falling short of effecting constitutional \nreform, one of Bisengimana\u2019s other objec -\ntives was securing Banyarwanda claims \nto citizenship that already existed. Koko \nwrites, \u201c...rather than granting Congolese \ncitizenship to the Banyarwanda (since they \nwere already citizens), the Ordinance-Law \nsimply sought to put an end to contesta -\ntions, exactions and other ill-treatments \ninflicted on the Banyarwanda by other \nCongolese ethnic communities in the eastThe Internationalist            Vol. II, Spring 2017\n33\nern region and ill-intended politicians\u201d .57 \nIn addition to opposition on ethical \ngrounds, many disagreed with Bisengima -na\u2019s law because it altered citizenship ambi -\nguity by means of creating an exception \nfor the Banyarwanda rather than changing Congolese citizenship as a whole.58 \nAfter Bisengimana fell from power, back -\nlash took his efforts in the opposite direc -\ntion. In 1981, President Mobutu\u2019s congress \nnot only annulled Bisengimana\u2019s law, but \nmoved the cutoff date to August 1st, 1885, \nby virtue of Law No 81-002.59 This meant \nthe law retroactively took citizenship rights \naway, \u201cthus effectively excluding most if \nnot all Rwandophones even more decisive -\nl y \u201d.60 Additionally, Law No 81-002 directly \nattached legal acquisition of citizenship to \nethnicity, muddying the waters even fur -\nther for the Banyamulenge. While the vast \nmajority of Rwandophones were excluded, \na small percentage could trace their Con -\ngolese lineage back to before 188561 and \nclaimed as early as the 16th century.62 This \ncreated the question of whether excluded \nRwandophones drew their citizenship \nfrom the few with long ties to the DRC or \nif these few were excluded because the ma -\njority of their ethnic group largely lacking \nlegal claims to citizenship. Law No 81-002 \nwas also unique in allowing the acquisition \nof citizenship to \u201cRwandan and Burundian \nimmigrants, \u201d though this came at the cost \nof relinquishing the ability to hold elected \noffice.63 Though Law No 81-002 was never \nfully implemented, \u201c...it still provided the \ninstitutional basis for increased discrimi -\nnation against the Banyarwanda\u201d .64\nAfter the official legislation and restric -\ntion of rights came the violence. The \naforementioned CNS in 1991 served to \nramp up ethnic tensions and created a leg -\nislative body called the \u201cHaut Conseil de la \nR\u00e9publique-Parlement de Transition\u201d .65 In \n1995, this body promulgated the \u201cRes -\nolution on Nationality\u201d which declared \nall Rwandophones became Congolese by \nfraud and withdrew all citizenship rights \nfor the group.66 \u201cThe \u2018Nationality Question\u2019 \nwas, without doubt, a trigger for the two \nsubsequent wars in which the Congolese \nTutsi [a subset of Rwandophones], par -\nticularly, have played a central role, \u201d with \nthe \u2018Nationality Question\u2019 referring to the \nabove \u201cResolution on Nationality\u201d .67 These \ntwo wars were catastrophically violent \nand had intense ethnic alignments. In the \naforementioned Second Congo War, an \nestimated four million people died.68\nThough many Rwandophones died fight -\ning or as civilian collateral damage, the \nviolence did not end when the wars \nfinished. The Second Congo \nKate Hewitt, \u201817 M.A.\nI took this picture while serving as a Peace Corps volunteer in the Republic of\nMoldova, one of the poorest countries in Europe. Peace Corps volunteers have\nbeen active in the country for more than 20 years, working on multiple projects \nto help further economic and social development. To date, more than 1,350 \nvolunteers have served in about 100 towns and villages across the country . I \nworked with NGOs and government organizations on human rights advocacy . In \nthe face of harsh economic and political times, I often found my job encouraged \nhope and optimism\u2014something all too often lacking in Moldova.\nOn my way home from work one day, I stopped in front of a vacant lot to closer \ninspect the lone-standing building in the midst of rubble and trash. The lot \nwas for sale, and it struck me that here was a sign of optimism: a call to build \nsomething new to replace something broken and in disrepair.The Internationalist            Vol. II, Spring 2017\n34\nWar, waged between the Rassemblement \nCongolais pour la D\u00e9mocratie (RCD) reb -\nels and Kabila\u2019s government, is particularly \nat fault for this. Because the RCD had the \nsupport of the Rwandan government, \u201cthe \nRCD rebellion\u2026 was considered a Tutsi \nattempt to regain Kivu\u201d .69 This is critical \nbecause the Mai-Mai claim Rwandan con -\nspiracies are endangering the Congolese to \njustify violence against Rwandophones.70 \nNot only does this seem plausible to many \nCongolese people, especially in the Kivu \nregions, it was actually true to some degree \nin the past.\nThe Second Congo War is an example of \nhow autochthony discourse finds political \nand motivational success through drawing \nanger and energy from conflict. For exam -\nple, \u201cCongolese public servants who col -\nlaborate with the RCD rebels are reminded \nthat they are inadvertently killing their \nfamily\u2026 \u201d .71 The history of the RCD \nand the associated emotions there -fore appear in politics. Political opponents \ndirectly link the association with a group \ninvolved in the Second Congo War with \nthe violence of this conflict and insinuate \nthe violence will occur again. \nAnother example of a conflict used to \nenergize anti-allochthon rhetoric is the on -\ngoing disagreement over land in the Kivu \nregions. \u201c[The Kivu regions are] a meeting \nplace and melting pot, but also an area \nthat has repeatedly tasted the bitter fruit of \nconflict, most often between groups claim -\ning the status of autochthony and those \ndefined as \u2018strangers\u2019: migrants supposedly \nwithout the same level of attachment to \na mythological native land\u201d .72 Rwando -\nphones in the Kivu regions fall victim to \naccusations they unjustly own ancestral \nland or attempt to control, sell or force \nKivu to secede.73 What is important to note \nis the issues surrounding the CNS confer -\nence and subsequent violence were never \nresolved.74 As discussed earlier in this paper, groups like the Mai-Mai harness \nthis fear of Banyarwanda control over land \nin the Kivus to violently mobilize against \nallochthons, convincing an insecure and \nunsafe population this is their best option.\nWhy Autochthony Rhetoric \nis Successful at the \nGovernmental Level\nAnother reason autochthony rhetoric \nfinds political success is because it is vague \nand flexible. Even in the Kivu regions, the \nsite of arguably the most pointed rhetoric \nin the DRC, the words autochthon and \nallochthon are ambig -\nuous. In the DRC, it is \nwidely accepted that \nthe decimated Twa \npygmoid population \ntruly arrived first.75 \nTherefore, \u201cClaims to \nautochthony are thus \nclaims to have arrived \nfirst, but also second\u201d . \nAdditionally, some \nRwandophones can \nclaim autochthon sta -\ntus regionally,76 which \nI will expand upon \nlater. Of course, this \nambiguity lends itself \nto excellent political \napplication. To explore \nthis, I will first provide \nmore context about \nRwandophone ethnic \ndemographics.\nThe two largest eth -\nnic groups labeled as \nRwandophones or al -\nlochthons in the DRC \nare the Hutu and the \nTutsi.77 Both Hutu and \nTutsi found themselves \nin the eastern DRC \nvia migration. This \nmigration happened \nover centuries, but mostly after the arrival \nof European colonization and specifically \nin response to crises in Rwanda.78 The dif -\nferences between Hutus and Tutsis mainly \nstem from events and power systems in \nRwanda where the Tutsis were of sub -\nstantially higher political power and even \nconsidered by European colonizers to be \nCaucasian.79 This preference stems \nRyan Seguin, \u201817 M.P.H.\nI watched this Vietnamese man and his family cast their fishing net into Jordan Lake for hours. \nWhen I asked if they had caught anything, he smiled and said, \u201cNot really .\u201d As I watched, it struck \nme that the time he spent casting his net was more about tradition than catching fish.The Internationalist            Vol. II, Spring 2017\n35\nfrom the Hamitic hypothesis that Tutsis \nmigrated to Central Africa from Egypt and \ndominated the local Bantu population.80 \nHere, Bantu refers to a \u201cmegaethnicity\u201d \nthat encapsulates the Hutu as well as the \nHunde, Nyanga and other ethnic groups \nin the eastern DRC.81 The Tutsi belong \nto the megaethnicity called Nilotes. The \nBantu-Nilotic rivalry fuels conflicts in \nthe DRC\u2019s Kivu regions and Ituri region \n(just north of the Kivus) as well as those \nin Rwanda and Burundi among other \nlocations across the great lakes region.82 In \nthe DRC, Tutsis are successful pastoralists \nand often the antagonists of conspiracy \ntheories.83 In fact, President Mobutu used \nthem as \u201cintermediary elites, \u201d drawing \nagain upon his tactic of thrusting to power \nthose with ambiguous political status to \nminimize their threat to his power.84 \nThose hungry for power in the Kivu \nregions and elsewhere can therefore use \nanti-allochthon rhetoric in different ways \nand to different means. The easiest way \nto see this is through the shifting allianc -\nes of the Hutu people. Because of their \nBantu megaethnicity, the Hutu have claim \nto regional autochthon status in spite of \ntheir national allochthon status.85 When \nit is politically beneficial, like during \nthe 1996-1997 post-Rwandan Genocide \nviolence in the DRC, pan-Bantu alliances \nform including the Hutu and excluding \nthe Tutsi.86 Other times, like the Second \nCongo War, Rwandophones band together \nagainst a common enemy.87 This flexibility \ncommands the power to include or exclude \na huge number of people with very little \nchange to the rhetoric itself. Thinking back \nto the complexity of autochthony rhetoric \nat the local level (e.g. Hunde vs. Nyanga), \nit is easy to see how this supercharged dis -\ncourse is valuable to achieving short-term \npolitical gain because of its flexibility. Huge \nportions of the population are inflamed \nby this rhetoric and many different groups \ncan be made its victims.\nFinally, anti-allochthon rhetoric finds \npolitical success because it maintains \npower systems that disenfranchise those \nwho would argue against its use. The most \nobvious example is the previously men -\ntioned campaign to restrict Rwandophone \ncitizenship rights. Resources, such as land, \nare scarce in many parts of the DRC.88  \nRestricting the number of people who \nhave access to these resources increases the opportunities for those whose citizenship \nis not questioned. This is because even \nhaving citizenship in the DRC does not \nguarantee you access to land;89 losing or \nnot having citizenship means almost cer -\ntain exclusion. The citizenship restriction \nmethod has an additional advantage of \nrestricting the power Rwandophones have \nto resist their disenfranchisement.90 This \nis not only because they lack access to the \npolitical process, one could argue the eco -\nnomic instability caused by losing citizen -\nship would cause systemic power inequal -\nity. Furthermore, \u201c...endemic state failure, \ncompounded by repeated inconsistencies... \nhas contributed to turning the question of \nthe citizenship of the Banyarwanda into a \nstumbling block to peaceful co-existence \nand human and state security in the coun -\ntry, especially in the Kivu region\u201d .91 This \nmeans the rhetoric motivates violence, \nwhich subjugates the Banyarwanda\u2013and \nthe Congolese as a whole\u2013economically, \nphysically and geographically. Accord -\ning to the UNHCR\u2019s 2015 Global Trends \nReport on Forced Displacement, \u201cThe total \nnumber of refugees originating from the \nDemocratic Republic of the Congo stood \nat 541,500 at the end of 2015\u201d .92 On top \nof this, millions have died in the conflict \nand countless more have suffered either \neconomically or otherwise.93  \nFinally, it is important to understand the \nrole Congolese elites play. To them, the in -\nsecurity in the DRC and the subjugation of \nRwandophones work in their favor. Erik -\nsen, in discussing why international actors \nhave failed to amend the situation in the \nDRC claims, \u201cstate-building has not served \nthe interests of key actors\u201d .94 One such \nactor is the state itself, or rather the regime \nthat controls the state. There are a couple \nreasons why the Kabila regime\u2019s interests \nrun seemingly in contrary to the masses. \nOne is due to the DRC\u2019s economy based on \nexporting raw materials. The consequences \nof perpetuating this model are \u201c...the devel -\nopment of an oligarchy bent on using state \npower as a means of self-enrichment, the \ndeeper underdevelopment of the country, \nand the further impoverishment of the \nmasses\u201d .95 The other is because the DRC is \na neo-patrimonial state. This is deleterious \nbecause, in neo-patrimonial systems, \u201c...\nthe state\u2019s very weakness is a resource, both \nbecause it makes it possible for elite politi -\ncians to get access to economic resources, and because it enables them to maintain \ntheir own armed groups... This has clearly \nbeen the case in the DRC\u201d .96 Not only have \npoliticians like President Mobutu taken \nadvantage of the weak DRC state, they \nlikely also directly benefit from it through \npatronage and clientelism. The patrimonial \nsystem in the DRC is a relic of colonial \ntimes97 and does not change with new \nregimes. Likewise, strong political institu -\ntions breed competition, so \u201c...a weak state \nis forced to pursue policies that weaken it \neven further, in order to prevent the emer -\ngence of alternative power centres within \nthe state apparatus\u201d .98 Other key actors are \nnon-political elites. As discussed earlier, \nthe Mai-Mai and other armed groups are \nable to exist because the DRC is a weak \nstate without a monopoly on violence. \nJust as a weak state benefits these elites, \nso too does a scapegoat for the DRC\u2019s \nproblems. \u201cThat Rwandophone nationality \nhas remained a matter of doubt has been a \npotent tool for postindependence Congo -\nlese elites\u201d .99\nConclusion\nAnti-allochthon rhetoric finds significant  \npolitical and motivational success because \nenergy it draws from conflicts is intense \nand inspires action, it allows groups to \nshift allegiances and suggest multiple inter -\npretations without being contradictory, \nand it creates a feedback loop where its \nsuccess compounds itself and eliminates its \nresistance. What President Mobutu and the \nMai-Mai in particular show us is that these \nstrategies work because of the insecurity \nresulting from a weak DRC state. Presi -\ndent Mobutu knew his power was under \nconstant threat, so institutionalizing the \ninferiority and ambiguity of the Banyar -\nwanda was necessary to remain afloat. For \nboth politicians and armed groups, it is \nsuccessful to tell your constituency Rwan -\ndophones in their communities are con -\nspiring to take power and ruin their way of \nlife when violence constantly looms on the \nhorizon, and some Rwandophones indeed \ndid attempt to seize power well within \nliving memory. Likewise, it is successful \nto tell your neighbor joining the Mai-Mai \nand attacking Rwandophones is a good \nfinancial option when he has few others. \nFurthermore, it is not in the interests of \nthe Congolese elite to strengthen the \nstate nor to reduce discrimination The Internationalist            Vol. II, Spring 2017\n36\nagainst the Banyarwanda. Although it is \nunclear if a strengthening the DRC state \nwould do anything to amend the virulent \nanti-allochthon rhetoric and activity suf -\nfered by Rwandophones, it is undeniable \nstate weakness contributed to its potency \nand proliferation.\nCitations\n1. CAPS. \u201cDRC Country Profile. \u201d ACAPS.\n2. B\u00f8\u00e5s, Morten, \u201c\u201dNew\u201d Nationalism and \nAutochthony - Tales of Origin as Political \nCleavage. \u201d Africa Spectrum 44.1, 2009, 20.\n3. Jackson, Stephen, \u201cSons of Which Soil? \nThe Language and Politics of Autochthony \nin Eastern D.R. Congo. \u201d African Studies \nReview 49.2, 2006, 115.\n4. Eriksen, Stein Sundst\u00f8l. \u201cThe Lib -eral Peace Is Neither: Peacebuilding, State \nBuilding and the Reproduction of Conflict \nin the Democratic Republic of Congo. \u201d In -\nternational Peacekeeping 16.5, 2009, 653.\n5. World Heritage Encyclopedia, \u201cList of \nStates with Limited Recognition. \u201d List of \nStates with Limited Recognition, World \nHeritage Encyclopedia, 2016.\n6. Zachariah, George, \u201cRegional Frame -\nwork for State Reconstruction in the Dem -\nocratic Republic of the Congo. \u201d Journal of \nInternational Affairs 58.1, 2014, 220.\n7. ACAPS, \u201cDRC Country Profile. \u201d\n8. Jackson, Stephen, \u201cSons of Which Soil? \nThe Language and Politics of Autochthony \nin Eastern D.R. Congo. \u201d African Studies \nReview 49.2, 2006, 121.\n9. Jourdan, Luca, \u201cMayi-Mayi: Y oung Rebels in Kivu, DRC. \u201d Africa Development \n36.3&4, 2011, 95.\n10. Jourdan, \u201cMayi-Mayi\u201d , 97.\n11. Ibid, 94.\n12. ACAPS, \u201cDRC Country Profile. \u201d\n13. Jourdan, \u201cMayi-Mayi\u201d , 96.\n14. Ibid, 94. \n15. Ibid, 94.\n16. Koko, Sadiki, \u201cState-Building, Citizen -\nship and the Banyarwanda Question in the \nDemocratic Republic of Congo. \u201d Strategic \nReview for Southern Africa 35.1, 62.\n17. Jackson, \u201cSons of Which Soil?\u201d , 101.\n18. Jourdan, 100.\n19. Ibid, 90.\n20. Ibid, 96. \n21. B\u00f8\u00e5s, \u201c\u201dNew\u201d Nationalism\u201d , 28.\n22. Jourdan, 97.\nAmanda Schroeder, \u201818\nThis photo was taken outside of the Palace of Westminster on July 2, 2016, nine days after the United Kingdom voted to \nleave the European Union. Sixty percent of Londoners voted to remain, which explains why the signs pictured here were \nleft outside the Houses of Parliament.The Internationalist            Vol. II, Spring 2017\n37\n23. Ibid, 95.\n24. CIA, \u201cThe World Factbook: Congo, \nDemocratic Republic of the. \u201d Central \nIntelligence Agency. Central Intelligence \nAgency.\n25. Jourdan, 106.\n26. Ibid, 99.\n27. Ibid, 98.\n28. Ibid, 95.\n29. Van Acker, Franck, and Koen Vlas -\nsenroot, \u201cLes \u00abma\u00ef-ma\u00ef\u00bb Et Les Fonctions \nDe La Violence Milicienne Dans L \u2019 est Du \nCongo. \u201d Politique Africaine 84, 2001, 107. \nTranslation is my own.\n30. Zachariah, \u201cRegional Framework, \u201d 223.\n31. Jourdan, 107.\n32. Nzongola-Ntalaja, Georges, \u201cThe \nFailing State in the Democratic Republic of \nCongo. \u201d Global Dialogue 13.1, 72.\n33. Jackson, 98.\n34. Ibid, 101.\n35. Ibid.\n36. Koko, \u201cState-Building\u201d , 62.\n37. Jackson, 112-114. \n38. Ibid, 113.\n39. Ibid, 114.\n40. Ibid, 102.\n41. Ibid, 105.\n42. Ibid, 102.\n43. Ibid,  103.\n44. Ibid.\n45. Ibid, 104.\n46. Ibid.\n47. Koko, 43.\n48. Jackson, 104.\n49. Koko, 46.\n50. Jackson, 98.\n51. Ibid, 101.\n52. Koko, 59.\n53. Jackson, 104.\n54. B\u00f8\u00e5s, 27.\n55. Jackson, 104.\n56. Koko, 61.\n57. Ibid, 59.\n58. Jackson, 104.\n59. Koko, 62.\n60. Jackson, 105.\n61. Jackson, 98.\n62. B\u00f8\u00e5s, 27.\n63. Koko, 62.\n64. B\u00f8\u00e5s, 27.\n65. Jackson, 106.\n66. Ibid.\n67. Ibid.\n68. Ibid, 97.\n69. Ibid, 95.\n70. Ibid, 97.71. Ibid, 110.\n72. B\u00f8\u00e5s, 26.\n73. Jackson, 110.\n74. B\u00f8\u00e5s, 28.\n75. Jackson,  113.\n76. Ibid.\n77. B\u00f8\u00e5s, 27.\n78. Koko, 54.\n79. Jackson, 107.\n80. Ibid.\n81. Ibid.\n82. Pottier, Johan. \u201cRepresentations of \nEthnicity in the Search for Peace: Ituri, \nDemocratic Republic of Congo, \u201d African \nAffairs 109.434, 2009, 47.\n83. Jourdan, 97.\n84. Jackson,  107.\n85. Ibid, 113.\n86. Ibid.\n87. Nzongola-Ntalaja, 72.\n88. B\u00f8\u00e5s, 22.\n89. Ibid, 19.\n90. Ibid,  22.\n91. Koko, 72.\n92. UNHCR, \u201cGlobal Trends Forced \nDisplacement 2015\u201d , UNHCR The UN \nRefugee Agency, United Nations, 2015.\n93. Jackson, 97.\n94. Eriksen, 652.\n95. Nzongola-Ntalaja, 78.\n96. Eriksen, 662.\n97. Ibid, 661.\n98. Ibid, 655.\n99. Jackson, 104.The Internationalist            Vol. II, Spring 2017\n38\n I was particularly interested in study -\ning media treatment of the Calais crisis \nduring the summer of 2015, when Calais \nwas reaching peak media popularity and \nthe possibility of Brexit had not been an -\nnounced by David Cameron.\n   My research was centrally guided by the \nquestion \u201cHow was the Calais migrant \ncrisis depicted in The Guardian and The \nTimes in June and July of 2015?\u201d More \nspecifically, I was interested in whether \neach newspaper portrayed the crisis as an \neconomic issue, a social issue, a security \nissue, or a diplomatic issue. Was there a \ndifference between The Guardian and the \nmore conservative Times? How did their \nperspectives on the migrants themselves \ndiffer?\n   This research is significant because me -\ndia bias \u2014 a systemic bias in the way that \nthe media presents and discusses issues \u2014 can influence the way citizens perceive an \nissue, in turn affecting political outcomes. \nFor example, scholars have found evidence \nfor media bias affecting public opinion on \nenlargement of the EU,9 public support for \nan EU-wide foreign and security policy,10 \nand the outcome of the 2000 Danish ref -\nerendum on the Euro.11 An experiment by \nGerber et al. found in 2009 that, in a ran -\ndomized trial, households which received \na free subscription to the Washington Post \nwere more likely to vote for a Democratic \ncandidate in the Virginia gubernatorial \nelection than those which received the \nmore conservative Washington Times \u2014 \nwho were more likely to vote for a Repub -\nlican candidate.12 If an observer applies \nthe logic of the effects of media bias to the \nsituation in Calais, they could assume that \nBritons\u2019 perspectives on migrants would \nhave been affected by the newspapers\u2019 \nrepresentations of the Calais crisis.    As immigration-based issues become \nmore prominent in European politics, the \ntreatment of immigrants \u2014 and some -\ntimes migrants\u2019 very lives \u2014 depends on \nthe way citizens perceive their situation. \nMore sympathetic media portrayals may, \nbased on the logic of media bias, create a \nmore sympathetic populace. On the other \nhand, more hostile or more negative media \nportrayals may foster hostility towards mi -\ngrants among the citizenry. The election of \nanti-immigrant, populist leaders in liberal \ndemocracies exemplifies the recent shift \ntowards more negative views on immi -\ngrants. As Brexit demonstrates, these views \ncan have drastic consequences, not just \nfor migrants, but also for native citizens. \nThus, examining the way the media frames \nand portrays issues like the Calais crisis is \ncrucial in understanding grander political \nthemes. The Calais Crisis in The Guardian \nand The Times: An Analysis of \nBritain\u2019s Media Perspective in June \n- July 2015\nThe French port city of Calais has been an important stopping point for migrants trying to get to the \nUK since the 1990s. In 1999, faced with a surge in numbers of migrants in the province, the French \nRed Cross \u2014 sponsored by the French government \u2014 established a camp called Sangatte. The camp \nwas shut down in 2002 due to pressure from the British government, who argued that the overcrowd -\ned Sangatte was facilitating illegal migration into Britain.1 After Sangatte, migrants re-congregated \nin unofficial camps in the city and the forest.2 Throughout the 2000s and 2010s, the city of Calais \nwas caught in a cycle wherein the French authorities would periodically raid and shut down camps, \nwhich the migrants would re-establish, which the French would raid again. As time went on, the \nsqualid, overcrowded camps came to be known as \u201cThe Jungle\u201d by residents and observers.3 Despite \nthe horrible conditions, migrants believed that the suffering in Calais would be worth it if they could \nget to Britain. A 17-year-old refugee concisely captured the sentiments of many migrants in a 2015 \ninterview, saying, \u201cFrance no good. England good, England freedom. \u201d4 The increasing numbers of \nmigrants in Calais coupled with the quickly deteriorating humanitarian situation5 eventually pushed \nthe French government to shut down the largest migrant camp in 2016.6By Sofie Senecal\nSophomore Contemporary European Studies and Middle Eastern Languages Double MajorThe Internationalist            Vol. II, Spring 2017\nResearch Methods\n   My analysis itself was based on 18 \narticles each from The Guardian and The \nTimes, comprising a total set of 36 articles. \nI examined eight weeks\u2019 worth of news, \nwhich roughly averages to 4.5 articles per \nweek. I chose The Guardian and The Times \nfor two major reasons. First, both The \nGuardian and The Times are mainstream \nBritish broadsheets: they are newspapers \nmost Britons know of and trust as legiti -\nmate news sources. Combined, the news -\npapers have a print and online monthly \nreadership of 7,762 thousand adults.13, \n14 Since the underlying motivations of \nmy study are rooted in the consequences \nof mainstream media\u2019s effects on voter \nattitudes, the choice of popular, well-estab -\nlished newspapers was necessary.\n   Second, The Guardian and The Times span the mainstream political spectrum: \nThe Guardian lies slightly left of center15 \nand The Times lies slightly right of cen -\nter.16 I specifically chose newspapers with \ndiffering political biases, because I wanted \nto know: Do their biases in general affect \ntheir representations of the Calais crisis \nin particular? Do their depictions of the \nCalais crisis reflect general beliefs of the \nleft and the right on migration? \n   Furthermore, on a practical level, The \nGuardian and The Times were the two \nnewspapers with the highest number of \narticles that matched my search terms for \nJune - July 2015 on LexusNexus. While \nquantity is by no means an assurance of \nquality, I assumed that a larger amount \nof articles in the beginning would mean I \ncould find a more even time distribution \nof articles after narrowing them down. \nAlso, I assumed that having similar initial numbers of articles would simplify the \nprocess of choosing comparable numbers \nof articles across newspapers. \n   As for the search itself, I used LexisNexis \nto search for articles one newspaper at a \ntime. Restricting my search to 1 June - 31 \nJuly 2015, I found 96 newspaper articles \nin The Times containing both \u201cmigrants\u201d \nand \u201cCalais\u201d and 67 in The Guardian \nunder the same search terms. These search \nterms were deliberately vague: using a \nmore specific term like \u201crefugees\u201d would \nshift the articles toward more sympathetic, \npro-migrant pieces, as \u201crefugees\u201d is a more \nconnotatively positive term than \u201cmi -\ngrants\u201d in mainstream culture.17 Similarly, \nI avoided a search term like \u201cCalais crisis\u201d \nbecause this would shift my results in the \nother direction by only including articles \nthat explicitly referred to the situation in \nCalais as a crisis. \n   After instructing LexisNexis to remove \nduplicate articles with moderate similar -\nity, I was left with 110 total articles. From \nthese, my goal was to choose moder -\nate-length articles that related the Calais \ncrisis to Britain. While ideally I would have \nrandomly selected the articles, with such a \nsmall sample size (36 total articles), I had \nto prioritize relevancy over randomness. \n   Thus, I purposefully excluded exception -\nally short articles. Some articles that ap -\npeared within the search results were bare -\nly a paragraph, which I felt was too short \nto adequately code. Fortunately, in most \ncases an expanded article covering the \nsame topic directly preceded the too-short \narticle, so its information was still included \nin my results. Furthermore, the exclusion \nof exceptionally short articles allowed a \nmore medium article length in general. \nHaving articles of roughly the same length \nwas ideal for making cross-article com -\nparisons of the number of references to a \ncertain hypothesis. For example, if I did \nnot take article length into consideration, \na heavily economy-centric short article \nwould appear to have the same bias as a \nwell-rounded long article if they contained \nthe same number of references to Calais \nas an economic crisis. This situation is \nunideal, hence my exclusion of especially \nshort articles. \n   I also decided to avoid opinion pieces, as \nthe goal of my research was to examine the \ncharacterizations of migrants within \nnews articles, not in op-eds or \nThe Internationalist           Vol. II, Spring 2017\n40\ncolumns where the direct statement of an \nauthor\u2019s opinions is allowed or encouraged. \nThese opinions may or may reflect those of \nthe newspaper\u2019s editorial board. While it is \ntrue that the inclusion or exclusion of op-\neds in in a newspaper can reveal what the \npublication deems acceptable to publish, \nthere is a distinct difference between bias \nin opinion pieces and bias in newswriting \nor feature stories. This experiment aims to \ntest the way the Calais crisis is framed in \nthe news stories of The Guardian and The \nTimes; thus, I excluded opinion articles. \n   Furthermore, while first and foremost \nprioritizing relevancy, I aimed to get a rela -\ntively even distribution of articles over my \ntime frame within that constraint so that I \ncould ensure relatively comparable results \nbetween The Guardian and The Times. \nThus, as the chart below shows, the num -\nber of articles I coded per week per news -\npaper is broadly similar, with the exception \nof the relative imbalance from weeks 1 - 3. \nThe larger changes in article number\u2014 like \nthe upticks in weeks 3 and 8 \u2014 are due to \nan increase in the total number of articles \nthose weeks (due to events in Calais), \nrather than an indiscriminate increase in \nthe number I chose those weeks.\n   The process of coding the articles \npresented a number of challenges. First, \nI did not have the resources or expertise \nto create a computer program to code the \narticles for me, which meant that I had \nto read each paragraph and decide which \ncategory \u2014 or categories \u2014into which the \nrhetoric behind the statements best fit. \nMy strategy to address this unsolv -able problem of subjectivity at the center \nof my data collection is addressed in the \nbelow Hypotheses section. Second, many \narticles had absurdly short paragraphs, \nwhich interfered with  my original para -\ngraph-by-paragraph coding plans. To get \naround this issue, I grouped every three to \nfive sentences that discussed the same idea \ninto a paragraph of my own making and \ncoded this paragraph as a unit. While by \nno means a perfect system, this allowed me \nto avoid over-counting characterizations \n(by not counting each sentence individu -\nally) and under-coding articles (by coding \nthe entire article at once). \nHypotheses \n   I chose my four hypotheses based on the \nways I hypothesized newspaper articles \nwould characterize the Calais crisis. First, \nI drew from existing research on the \ntwo major types of integration problems \nimmigrants face \u2014 economic integration \nand social integration \u2014 and assumed that \nthese general tropes would apply not only \nto characterizations of the migrants them -\nselves, but also to the broader issue under -\nlying their migration. Essentially, I applied \nmy pre-existing knowledge on the worries \npeople \u2014 natives and migrants alike \u2014 \nhave concerning immigration to the Calais \ncrisis. I assumed that since people are often \nconcerned about the economic and social \naspects of immigration, they would also be \nconcerned about the economic and social \naspects of the Calais crisis. \n   Then, knowing the Calais crisis was a \nfundamentally international situation root -ed in questions of border control and secu -\nrity, I added two other hypotheses \u2014 that \nthe issue could be portrayed as a diplomat -\nic issue or security issue. While I saw the \npotential for overlap between diplomatic \nportrayals and security-based portrayals, \nas border controls themselves lie at the \nintersection of both, I decided that the \ntwo hit on equally important yet different \naspects of the crisis: characterizing some -\nthing as a diplomatic issue implies the \nissue is one of failed or mismanaged inter -\nactions between states, while characteriz -\ning something as a security issue implies \nthat the major problem is the situation is \nits lack of security. Thus, I determined that \nmy four hypotheses would be that newspa -\npers would portray the Calais crisis as an \neconomic issue, a social issue, a diplomatic \nissue, or a security issue. \n   The actual mechanics of coding arti -\ncles was relatively straightforward. After \nmentally grouping 3-5 related lines into \nself-made paragraphs, I decided which \nof the four hypotheses the characteriza -\ntion best fit. Sometimes the decision was \nremarkably straightforward: a line clearly \nstated that the crisis was an economic \nissue. Other times I needed to assign more \nthan one characterization to a paragraph \nwhich implied the crisis was rooted in \nboth diplomacy and security. Occasionally, \nparagraphs were incredibly vague about \ntheir perspectives on the crisis.\n   Thus, I created the \u201cindeterminate issue\u201d \ncategory to cover cases when a paragraph\u2019s \ncharacterization was not straightforward; \nfor example, given a paragraph in which \nthe author implied that the situation in \nCalais was a significant problem yet did \nnot offer a clear perspective on what type \nof problem it was. While it is true that the \n\u201cindeterminate issue\u201d category says little \nabout the newspapers\u2019 actual characteriza -\ntions of the crisis, it does provide a helpful \nmetric for how heavily the general negativ -\nity of the situation was implied.\n   Furthermore, because I needed to make \na conscious decision about how to code \neach statement, I was wary of assuming \ntoo much. The \u201cindeterminate issues\u201d \ncategory allowed me to avoid over-as -\nsuming the characterization of the crisis. \nThus, it allowed me to note that the articles \nwere discussing the crisis as an issue to be \nsolved and avoid guessing at the author\u2019s \nunexpressed, internal motivations.\nThe Internationalist            Vol. II, Spring 2017\n41\n   I also kept track of two characterizations \nof the Calais Crisis beyond my central \nhypotheses. First, while I was coding \narticles, I realized that articles frequently \nmentioned Britain\u2019s inherent greatness as \nan instrumental cause for the crisis, so I \ndecided to note all instances of this rheto -\nric. Second, I decided to track the number \nof positive characterizations of migrants. \nThus, I kept track of every time I saw a \npurely positive, sympathetic representation \nof a migrant. While these two metrics stray \nbeyond the central aims of my study, they \nnevertheless provide an interesting, useful \ngauge for factors related to the characteri -\nzation of the crisis itself. \nResults\n   Overall, the crisis was characterized \nmostly as a security issue, with econom -\nic concerns and diplomatic concerns \nroughly tied for the second most frequent \ncharacterization. Broadly, the results do \nshow that the left-right lean of these two \nnewspapers aligns with their characteriza -\ntion of the Calais crisis. Thus, while both \nnewspapers mentioned all four hypothe -\nses, the right-leaning Times characterized \nthe situation as mostly as security and \neconomic issue, while the more liberal \nGuardian was more likely to discuss social \nand diplomatic issues. \n   The prevalence of the discussion of secu -\nrity-based characterizations in both news -\npapers is rooted in the events of June and \nJuly 2015 themselves. In week 3, there was \na surge in conflict in Calais \u2014 migrants \nbegan breaking into lorries during heavy \ntraffic in order to attempt to smuggle \nthemselves into Britain. This \u201clorry crisis, \u201d \nas it began to be called, scared many Brits. \nThere were occasional reports of lorry \ndrivers being threatened. Lorry drivers, \nfaced with their lorries being broken into \nwhenever they stopped, tried to change \ntheir routes to avoid Calais. Unfortunately, \nthe proximity of the Eurotunnel to Calais \nmeant traffic could not be removed from \nthe city. Thus, lorry drivers focused on \ncalling for increased security in Calais.\n   In week 8, the major headlines con -\ncerned the thousands of migrants who had \nattempted to storm the Eurotunnel. Several \nmigrants died, and traffic through the \ntunnel had to be shut down. Understand -\nably, this was also a very security-centric \ntopic, both concerning security to protect the Eurotunnel \u2014 and the British-French \nborder \u2014 and to protect the migrants from \ngetting hurt. \n   The frequent characterization of the \ncrisis as a diplomatic issue also makes \nsense, given the nature of the Calais crisis \nas a problem shared by Britain and France. \nSeveral times, the British government \nimplored the French government to take \naction to curtail unauthorized migration \nthrough Calais \u2014 and the French govern -\nment asked Britain to further discourage \nmigration, as below:\n   \u201cIn response to a request by the French \nauthorities, there is now direct communi -\ncation between our officials and migrants \nto explain to them that there is no El \nDorado there [in the UK], \u201d said the British \nAmbassador to France.18\n   Often, officials stressed diplomatic part -\nnership as a key factor in solving the crisis. \nThus, it is logical that newspapers would \npresent the crisis as a failure of diplomatic \ncooperation.\n   The Times characterized the issue most \noften as a security issue, then as a diplo -\nmatic issue, as an economic issue, and last -\nly as a social issue. Beyond frequently dis -\ncussing the security and diplomatic aspects of the crisis, The Times emphasized the \neconomic motivations of migrants more \nfrequently than The Guardian did and \ndepicted migrants themselves in a more \nnegative light. The Times cited migrants\u2019 \ndesire to work in the illegal economy or \nthe black economy in Britain as a key \ncause of the crisis. Also, The Times more \nclosely followed the lorry crisis, especially \nstressing its economic consequences. One \nof the articles during the first week solely \ndiscussed the lost revenue from food-car -\nrying lorries being broken into, saying, \n\u201cFood worth almost \u00a32 million is being \nwritten off each month because stowaways \nhave broken into lorries heading for Brit -\nain.19 The Times\u2019s economic focus is logical \ngiven its center-right slant and the strong \nconservative interest in protecting the \ndomestic economy. \n   While The Guardian also discussed \nthe economic motivations of migrants, it \ntraced their motivations back to broader \nsocial causes. For example, The Guardian \nframed migrants\u2019 desire to find work in \nBritain as a consequence of the horri -\nble conditions in Calais. Therefore, The \nGuardian implied that the Calais crisis was \nless about the economy and more \nThe Internationalist           Vol. II, Spring 2017\n42\nabout people\u2019s statuses in society. \n   The Guardian also discussed migrants \nthemselves more positively, both through \nframing their often-tragic stories as quests \nfor fair, good lives and through generally \nemphasizing the sympathetic aspects of \nmigrants in Calais: their squalid living \nconditions, limited access to healthcare or \neducation, and desire to work hard. \n   On the following page, I have included \ngraphs of the frequency of the newspapers\u2019 \ncharacterizations over time. This reveals \nsome further distinctions. For example, \nthe lorry crisis in week 3 was deemed by \nThe Times to be most evident of a security \nissue, while The Guardian framed the lorry \ncrisis overwhelmingly as a diplomatic is -\nsue. However, this graph shows us that the \nnewspapers can also present crises similar -\nly: in week 8, at the time of the Eurotunnel \nstorming, both newspapers agreed that it \nwas both a diplomatic and security issue.    Overall, I found two general types of \narticles: event-centric and human-cen -\ntric. Event-centric articles tended to \nstress the facts, focusing on reporting \nwhat happened. Event-centric articles in \ngeneral stressed the economic, security, \nand diplomatic facets of the Calais crisis. \nHuman-centric articles, on the other hand, \nhighlighted the stories of migrants and the \nconditions of the camps in Calais. These \u2014 \nmore often found in The Guardian \u2014 were \nthe most likely to portray migrants in a \npositive light and paint the crisis itself as a \nsocial issue. \n   As I mentioned earlier, I also kept track \nof two other metrics: the \u201cBritain is great\u201d \nrhetoric and the positive characterizations \nof migrants. There were 42 instances of \nblaming British greatness as a major cause \nof the crisis overall, with 23 in The Guard -\nian and 19 in The Times. For an example \nof this rhetoric, see below:    \u201cWho is to blame? Local officials say that \nBritain is causing the problem. They claim \nthat people from poorer countries are \nlured by the prospect of better benefits and \nhousing. \u201d20\n   While this rhetoric is broadly logical \u2014 \n\u201cthe migrants want to leave France because \nBritain is better\u201d \u2014 it oversimplifies the \nissue, which might have hindered deeper \nthought or analysis of other motivational \nfactors. \n   In all 36 articles, there were only seven \npositive characterizations of migrants, \none in The Times and the other six in The \nGuardian. The characterization I found \nmost revealing was in a Guardian article \nabout a musician\u2019s music video, which used \nfootage from a documentary about Calais \nto tell a story inspired by Cormac McCar -\nthy\u2019s The Road, or, as the musician calls it, \nan \u201cextraordinary story of the human spirit \ntrying to survive insurmountable odds. \u201d21 \nThe article ends on this quote by the cre -\nator of the music video: \n   \u201c As the product of British multicultur -\nalism, when I see migrants I see hope and \nhard work. But most of all, I see humans, \nlike you and me. \u201d22\nThough this is quote from a person that \ndoes not necessarily reflect the opinions of \nThe Guardian\u2019s editorial board, the lack of \nadditional author commentary implies the \nauthor agrees, at least partially, with the \nmusician\u2019s assertion.  Furthermore, of all \nthe music videos one would highlight, to \ncall specific attention to \u201cNerina Pallot[\u2019s] \n\u2026 far more poignant approach to the \nmusic video\u201d23 implies at the very least a \nsympathetic eye.. \n   As with any data, there are potential \nalternate explanations. For example, one \ncould argue that these articles represented \nonly the opinions of a few authors. How -\never, to refute this idea, it is important to \nremember that an article must be approved \nby an editorial team, the people responsi -\nble for maintaining a consistent tone and \ndirection across all articles. Thus, the arti -\ncles\u2019 depictions of the crisis in Calais were \nat least deemed cohesive with the papers\u2019 \ntone at the time of publication, meaning \nmy analysis was still significant, if maybe \ntemporally bound. \n   However, that is not to say my data was \nperfect. It would have been impossible \nwith my level of expertise and limited \nresources to impartially choose \nThe Internationalist            Vol. II, Spring 2017\narticles or assess their characterizations of \nthe crisis. Thus, my results are subject to \nsome level of human error, whether that \nbe from mis-categorizing authors\u2019 points \nor unknowingly favoring certain articles \nover others. Nevertheless, I designed this \nproject keeping these potential flaws in \nmind, and tried to set out precautionary \nmeasures to protect against having my own \nbias \u2014 or mistakes \u2014 influence my results. \n   Other potentially interesting future \nstudies in the same vein could ask: how did \nBritish newspapers portray all internation -\nal migration related news in the summer of \n2015? Did Brexit change the way newspa -\npers discussed immigration? Are Syrians \ndepicted more favorably than other mi -\ngrant groups in mainstream British media? \n   In relation to my study in particular, my \nconclusions could benefit from analyz -\ning more newspapers \u2014 or at least more \narticles. Also, a parallel study of readers\u2019 \nopinions could be revealing: do readers\u2019 \ncharacterizations of the calais crisis reflect \nthe left/right slant of the newspaper they \nprefer to read? Does exposure to an article \nslanted in a certain way encourage readers \nto change their views?\n   I would recommend that future studies \nuse a computer program to code articles to \ndecrease the potential for the human error \ninherent in subjective decision-making. \nConclusion \n   My research examined how The Guard -\nian and The Times (London) depicted the \nCalais crisis in June - July 2015. Specifical -\nly, I looked at whether articles depicted the \ncrisis as an economic issue, a social issue, \na diplomatic issue, or an issue of security. \nWhile the security-based characteriza -\ntion prevailed overall due to the nature of \nthe events in Calais over the summer of \n2015, differences between articles of the \ncenter-left Guardian and the center-right \nTimes revealed a systemic bias in accor -\ndance with general left-right character -\nizations of migration. Thus, The Times \ntended to depict the crisis as an economic \nissue, while in contrast The Guardian \ntended to portray the crisis as a social \nissue. Furthermore, The Guardian fostered \na more positive, sympathetic picture of the \nmigrants themselves.\n   Bias in media depictions of current \nevents is significant far beyond Calais. \nIf the news citizens read systemically presents an issue in one light, citizens are \nlikely to start accepting that perspective as \nthe most correct, whether or not they are \naware of alternatives. Seeing the troubling \nrise of fake news and its demonstrated \neffects on elections in liberal democracies, \nit is important now more than ever to \nhold mainstream news media accountable \nto their biases \u2014 and this begins with \nresearch. \nCitations\n1. \u201cSangatte Refugee Camp, \u201d The Guardian, \n23 May 2002, https://www.theguardian.\ncom/uk/2002/may/23/immigration.immi -\ngrationandpublicservices1.\n2. Melodie Bouchaud, \u201cRemembering San -\ngatte, France\u2019s Notorious Refugee Camp, \u201d \nVice News, 4 November 2014, https://\nnews.vice.com/article/remembering-san -\ngatte-frances-notorious-refugee-camp.\n3. Angelique Chrisafis, \u201c\u2018 At night it\u2019s like \na horror movie\u2019 \u2014 Inside Calais\u2019s official \nshantytown. \u201d The Guardian, 6 April 2015, \nhttps://www.theguardian.com/world/2015/\napr/06/at-night-its-like-a-horror-movie-\ninside-calaiss-official-shanty-town.\n4. Rory Mulholland, \u201cCalais Crisis: Bicycle \nrepair shops, mosques, and an Orthodox \nChurch \u2014 the town where migrants wait \nto cross to Britain, \u201d The Telegraph, 5 July \n2015, http://www.telegraph.co.uk/news/\nworldnews/europe/france/11718598/Cal -\nais-crisis-Bicycle-repair-shops-mosques-\nand-an-Orthodox-church-the-town-\nwhere-migrants-wait-to-cross-to-Britain.\nhtml.\n5. William Spindler, \u201cUNHCR appeals for \nurgent action to address deteriorating hu -\nmanitarian situation in Calais, \u201d UNHCR, \n26 September 2014, http://www.unhcr.org/\nen-us/news/latest/2014/9/542563199/un -\nhcr-appeals-urgent-action-address-deteri -\norating-humanitarian-situation.html?que -\nry=calais.\n6. \u201cEU Migrant Crisis: Clashes as France \nclears Calais \u2018Jungle, \u2019\u201d BBC, 29 Febru -\nary 2016, http://www.bbc.co.uk/news/\nworld-europe-35686209,\n7. Marion Solletty, \u201cInfographie: L \u2019 explo -\nsion du nombre de migrants \u00e0 Calais en \nun graphique, \u201d Franceinfo, http://www.\nfrancetvinfo.fr/france/nord-pas-de-calais/\nmigrants-a-calais/infographie-l-explosion-\ndu-nombre-de-migrants-a-calais-en-un-\ngraphique_1806381.html8. https://www.google.com/trends/\nexplore?date=2010-01-01%20\n2016-12-05&geo=GB&q=Calais\n9. Claes H. DeVreese and Hajo G. \nBoomgaarden, \u201cMedia Effects on Public \nOpinion about the Enlargement of the \nEuropean Union, \u201d Journal of Common \nMarket Studies Vol. 44, Issue 2 (2006); Ra -\nchid Azrout, Joost Van Spanje, and Claes \nDeVreese, \u201cWhen News Matters: Media \nEffects on Public Support for European \nUnion Enlargement in 21 Countries, \u201d \nJournal of Common Market Studies Vol. \n50, Issue 2 (2012). \n10. Claes H. DeVreese and Anna Kandyla, \n\u201cNews Framing and Public Support for \na Common Foreign and Security Policy, \u201d \nJournal of Common Market Studies Vol. \n47, Issue 3 (2009). \n11. Claes H. DeVreese and Holli A. Sm -\netko, \u201cNews matters: Influences on the \nvote in the Danish 2000 euro referendum \ncampaign, \u201d European Journal of Political \nResearch Vol. 43, Issue 5 (2004). \n12. Alan S. Gerber, Dean Karlan, and \nDaniel Bergan, \u201cDoes the Media Matter? \nA Field Experiment Measuring the Effect \nof Newspapers on Voting Behavior and \nPolitical Opinions, \u201d American Economic \nJournal: Applied Economics, Vol. 1, No. \n2 (2009), from John R. Lott Jr. and Kevin \nA. Hassett, \u201cIs newspaper coverage of \neconomic events politically biased?\u201d Public \nChoice Vol. 160, Issue 1 (2009). \n13. \u201cThe Guardian, \u201d Newsworks, http://\nwww.newsworks.org.uk/The-Guardian. \n14. \u201cThe Times, \u201d Newsworks, http://www.\nnewsworks.org.uk/The-Times.\n15. \u201cThe Guardian, \u201d AllSides, http://www.\nallsides.com/news-source/guardian.\n16. \u201cThe Times of London, \u201d Media Bias / \nFact Check, https://mediabiasfactcheck.\ncom/the-times-of-london/.\n17. \u201cMigrant or Refugee? Why it matters \nwhich word you choose, \u201d The Conversa -\ntion, 14 September 2015, http://thecon -\nversation.com/migrant-or-refugee-why-it-\nmatters-which-word-you-choose-47227.\n18. \u201cCalais: Britain willing to send more \nsecurity assistance, says Cameron; PM \nrejects blame game and commits to work -\ning more closely with French authorities, \ntackling people-smuggling gangs and mak -\ning UK \u2018less easy\u2019 . \u201d The Guardian. (June \n24, 2015 Wednesday 4:12 PM GMT ): 957 \nwords. LexisNexis Academic. Web. \nDate Accessed: 2016/10/25.The Internationalist           Vol. II, Spring 2017\n44\n\n19. \u201cFood waste scandal of the Calais \nstowaways; UK forced to dump deliveries \nworth millions ; Food waste scandal of the \nCalais stowaways. \u201d The Times (London). \n(June 13, 2015 Saturday ): 901 words. \nLexisNexis Academic. Web. Date Accessed: \n2016/10/25.\n20. \u201cFood waste scandal of the Calais \nstowaways; UK forced to dump deliveries \nworth millions; Food waste scandal of the \nCalais stowaways. \u201d The Times (London). \n(June 13, 2015 Saturday ): 901 words. \nLexisNexis Academic. Web. Date Accessed: \n2016/10/25.\n21. \u201cWatch Nerina Pallot\u2019s video for The \nRoad: a migrant experience of Calais; The \nBritish singer-songwriter\u2019s single from her \nforthcoming album The Sound and the \nFury uses footage from Calais to document \nthe \u2018hope and hard work\u2019 of migrants. \u201d The \nGuardian. (July 13, 2015 Monday 12:00 \nPM GMT ): 207 words. LexisNexis Aca -\ndemic. Web. Date Accessed: 2016/10/25.\n22. Ibid. \n23. Ibid. The Internationalist            Vol. II, Spring 2017\n45\n\n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Calais Crisis in The Guardian and The Times: An Analysis of Britain's Media Perspective in June-July 2015", "author": ["S Senecal"], "pub_year": "2015", "venue": "I nternationalist", "abstract": "The French port city of Calais has been an important stopping point for migrants trying to get  to the UK since the 1990s. In 1999, faced with a surge in numbers of migrants in the province"}, "filled": false, "gsrank": 796, "pub_url": "https://jfacunc.org/s/TheInternationalist-Spring2017-1.pdf#page=45", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:0vuz8c0VIr4J:scholar.google.com/&output=cite&scirp=795&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D790%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=0vuz8c0VIr4J&ei=lrWsaPi1IL_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:0vuz8c0VIr4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://jfacunc.org/s/TheInternationalist-Spring2017-1.pdf#page=45"}}, {"title": "Closing up shop: Exploring media coverage of plant closures in Ontario, Canada", "year": "2024", "pdf_data": "All Rights Reserved \u00a9 Canadian Journal of Regional Science, 2024\nThis document is protected by copyright law. Use of the services of \u00c9rudit\n(including reproduction) is subject to its terms and conditions, which can be\nviewed online.\nhttps://apropos.erudit.org/en/users/policy-on-use/\nThis article is disseminated and preserved by \u00c9rudit.\n\u00c9rudit is a non-profit inter-university consortium of the Universit\u00e9 de Montr\u00e9al,\nUniversit\u00e9 Laval, and the Universit\u00e9 du Qu\u00e9bec \u00e0 Montr\u00e9al. Its mission is to\npromote and disseminate research.\nhttps://www.erudit.org/en/\nDocument generated on 08/25/2025 4:16 p.m.\nCanadian Journal of Regional Science\nRevue canadienne des sciences r\u00e9gionales\nClosing up Shop: Exploring Media Coverage of Plant Closures in\nOntario, Canada\nRobert Nutifafa Arku and Jesse Sutton\nVolume 47, Number 2, 2024\nCanada\u2019s Economic Geography\nURI: https://id.erudit.org/iderudit/1115227ar\nDOI: https://doi.org/10.7202/1115227ar\nSee table of contents\nPublisher(s)\nCanadian Regional Science Association / Association canadienne des sciences\nr\u00e9gionales\nISSN\n0705-4580 (print)\n1925-2218 (digital)\nExplore this journal\nCite this article\nArku, R. N. & Sutton, J. (2024). Closing up Shop: Exploring Media Coverage of\nPlant Closures in Ontario, Canada. Canadian Journal of Regional Science / Revue\ncanadienne des sciences r\u00e9gionales, 47(2), 19\u201328.\nhttps://doi.org/10.7202/1115227ar\nArticle abstract\nThe ongoing issue of plant closures is a significant concern for advanced\neconomies. Consequently, there is a need to update our understanding of plant\nclosures to align with present-day socioeconomic contexts. This paper\nexamines the causes and impacts of plant closures across various contexts in\nOntario, Canada, using a media analysis approach. Specifically, 1,157 news\narticles from 2000 to 2019 are analyzed to gain insights into plant closures in\nthe province. Utilizing media coverage as a novel and robust data source, this\nstudy offers a regional perspective on the causes and impacts of plant closures.\nThe identified causes of plant closures include market forces, corporate factors,\nendogenous factors, economic crises, and globalization. These causes have\neffects at multiple levels, ranging from the individual to regional.\n\nReproduced with permission of the copyright holder. Further reproduction prohibited.19\nCJRS/RCSR | Volume 47, Num\u00e9ro 2\nCLOSING UP SHOP: EXPLORING MEDIA  \nCOVERAGE OF PLANT CLOSURES IN  \nONTARIO, CANADA\nRobert Nutifafa Arku, Jesse Sutton\nRobert Arku \nUniversity of Toronto, Department of Geography and Planning, \nSidney Smith Hall, 100 St. George Street, Toronto, ON,  \nM5S 3G3, Canada \nrn.arku@mail.utoronto.caJesse Sutton  \nWestern University, Department of Geography  \nand Environment, Social Science Centre,  \nLondon, ON, N6A 5C2, Canada \njsutto22@uwo.ca\nRe\u00e7u : 2024-04-29 \nAccept\u00e9 : 2024-09-25\nAbstract : The ongoing issue of plant closures is a significant concern for advanced economies. Consequently, there is a need to \nupdate our understanding of plant closures to align with present-day socioeconomic contexts. This paper examines the causes \nand impacts of plant closures across various contexts in Ontario, Canada, using a media analysis approach. Specifically, 1,157 news \narticles from 2000 to 2019 are analyzed to gain insights into plant closures in the province. Utilizing media coverage as a novel and \nrobust data source, this study offers a regional perspective on the causes and impacts of plant closures. The identified causes of \nplant closures include market forces, corporate factors, endogenous factors, economic crises, and globalization. These causes have \neffects at multiple levels, ranging from the individual to regional.             \nKeywords : Plant closures; Causes; Impacts; Media analysis; Ontario; Economic Restructuring\nCANADIAN JOURNAL   \nOF REGIONAL SCIENCE\nREVUE CANADIENNE DES   \nSCIENCES R\u00c9GIONALESCRSARSC CANADIAN \nREGIONAL \nSCIENCE \nASSOCIATIONASSOCIATION \nCANADIENNE \nDE SCIENCE \nR\u00c9GIONALE\nReproduced with permission of the copyright holder. Further reproduction prohibited.20\nCJRS/RCSR | Volume 47, Num\u00e9ro 2INTRODUCTION\nThe economic restructuring of advanced economies since the 1970s \nhas led to significant challenges posed by ongoing plant closures \n(Sutton et al., 2022). This restructuring, in a post-industrial era, is \ncharacterized by a shift from traditional industrial activities (e.g., ma -\nnufacturing) to service and knowledge-based sectors (Bourne et al., \n2011; Powell & Snellman, 2004; Vanchan et al., 2015; Wolfe & Gertler, \n2001). Plant closures significantly impact local economies, especially \nin small towns and cities, where a few large manufacturers are often \nthe economic backbone. \nRegardless of the rate or scale, these ongoing closures can be very \ndisruptive due to their local multiplier effects, highlighting the need \nto understand current broader representations and socioecono -\nmic effects of such events. Hence, our objective is to examine the \ncauses and impacts of recent plant closures. However, obtaining \ncomprehensive plant closure data, especially at a regional level, can \nbe challenging due to confidentiality, legal issues, cost implications \nand limited information. Consequently, analyzing publicly accessible \nmedia coverage offers a pragmatic approach, potentially providing \ntimely and contextual insights into spatially-extensive and diverse \npublic perspectives on plant closures.\nWithin this context, our study is guided by the following research \nquestion: what are the causes and impacts of plant closures across \nOntario, Canada, from 2000 to 2019, as noted by the media? This \npaper aims to address an identified research gap concerning the re -\nliance on outdated studies, thereby contributing to the plant closure \nliterature. Primarily, recent advancements and shifts in paradigms \n(e.g., technology) potentially render conclusions drawn from older \nstudies, including Bluestone and Harrison (1982), Nigel (1990), and \nMassey and Meegan (1982), less relevant to present-day contexts. \nWhile older studies provide valuable insights and foundational \nknowledge, it is essential to supplement them with more recent re -\nsearch to ensure a comprehensive and up-to-date understanding of \nthe ongoing processes of plant closures. \nConsequently, we conduct an analysis of media coverage of plant \nclosures to provide an updated perspective. Media coverage can of -\nfer an important source of information through, for instance, a regio -\nnal perspective on the processes of plant closures. This paper adds \nto recent attempts on conducting media analysis of plant closures \nwithin the realm of regional studies and economic geography. The \npresent study builds on the methodology used by Sutton and Arku \n(2024), who take a broader approach in analyzing media narratives \nof plant closures and the dynamics that shape these narratives in \nOntario. In contrast, this study offers a different perspective on plant \nclosure dynamics by examining the causes and impacts of plant clo -\nsures in Ontario. In doing so, the paper addresses a research gap \nidentified by Sutton and Arku (2024).           \nWe address our research question using the Province of Ontario as a \ncase study. Case studies involve examining a contemporary, complex \nphenomenon, within some real-life context, especially when the re -\nsearcher has little control over the events, using a variety of evidence \nincluding documents, interviews and observations (Yin, 2003). In our \ncontext, we present a case study on plant closures in Ontario to gain \na rich and up-to-date understanding of their causes and impacts \nwithin its real-life context using media coverage.  \nAs Canada\u2019s industrial and economic hub (Ontario Government, \n2021), the province has faced significant challenges due to plant clo -\nsures, a trend mirrored in advanced economies globally. Particularly \nsince the early 2000s, the Province has witnessed a substantial de -\ncline in its manufacturing sector, with over 250 closures reported \nsince 2008 (Sutton et al., 2022), engendering discussions on regional \neconomic resilience (Sutton et al., 2023). These closures have had profound impacts on local economies within the province, and were \nextensively covered by both local and national media outlets due to \ntheir far-reaching consequences. \nThe paper is structured as follows. The next section provides an \noverview of the plant closure literature and competing theories, fol -\nlowed by the methodology employed in the paper. The penultimate \nsection presents the results, while the final section offers an in-depth \ndiscussion and concludes.\nBACKGROUND\nPlant closures\nSince the turn of the 21st century, most advanced economies have \nbeen plagued by significant declines in employment and econo -\nmic activity within their manufacturing sectors. Notably, the extent \nof deindustrialization varies across spatial scales (e.g., city-level), \nreflecting their diverse economic landscapes. On an international \nscale, the extent of deindustrialization differs among Organization \nof Economic Cooperation and Development (OECD) countries. For \ninstance, Canada, Denmark, the United Kingdom, Sweden, France, \nIsrael, and New Zealand have experienced substantial declines in \nthe share of manufacturing employment and gross domestic pro -\nduct (GDP) in the last two decades compared to others (OECD, \n2023). Moreover, the impacts of deindustrialization and ensuing \nplant closures differ markedly among regions within these coun -\ntries, with industrialized regional economies bearing the brunt of the \nconsequences. In Canada, for example, Ontario, the country\u2019s indus -\ntrial heartland, has experienced substantial manufacturing employ -\nment losses compared to other regions. Although it only possessed \nroughly half of the country\u2019s manufacturing workforce in the 1980s, \nOntario accounted for 90% of such employment losses between the \n1980s to 2010s (Ray et al., 2017).\nAccounts of plant closures and their impacts, well documented by \nscholars such as Bluestone and Harrison (1982), Fothergill and Nigel \n(1990), and Massey and Meegan (1982), reveal adverse effects on \nlocal economies including mass redundancy, increases in precarious \nemployment, loss of social cohesion, lowered business confidence, \nreductions in local tax bases and outmigration (Chapain & Murie, \n2008; Cleave et al., 2019; Sutton et al., 2022; Tomaney et al., 1999). \nImpacting macro-economic trends, plant closures and births can \nplay a pivotal role in shaping the evolution of economies (Bernard \n& Jensen, 2007). Thus, while presenting significant challenges, the \nglobal restructuring process and resulting plant closures also offer \nopportunities (e.g., industrial diversification) for economic adaptation \nand future success.\nCurrent evidence suggests that plant closures exert varied impacts \non local economies, with the magnitude of these effects influenced \nby factors such as the size of the economy and the responsiveness \nof local economic actors to closures. Concerning the former, plant \nclosures in smaller cities have more severe repercussions, setting \noff cascading effects on other sectors, notably the service industry. \nIn comparison, plant closures in large cities, despite still having a \nsevere effect, have less of an impact as the loss of employment com -\nprises a smaller portion of the city\u2019s employment base. In addition, \nlarge cities are typically better positioned to absorb redundant wor -\nkers due to having a larger and more diverse economy (Cleave et al., \n2019; Sutton et al., 2022). There is however the risk that the redun -\ndant workers are absorbed into unskilled jobs in the service sector, \nresulting in wage decreases and labor skill mismatches (Bailey et al., \n2012; Sutton et al., 2022). Regarding the role of agency, Van Winden \n(2008) and Martin and Sunley (2006, 2015) posit that local economic \nactors play an active role in shaping the outcomes of plant closures. \nReproduced with permission of the copyright holder. Further reproduction prohibited.21\nCJRS/RCSR | Volume 47, Num\u00e9ro 2For example, Bailey and MacNeill (2008) found that the Rover Task \nForce\u2019s efforts in the West Midlands, UK, in 2005 helped connected \nsuppliers adapt and diversify, ultimately saving thousands of jobs. \nOverall, economies are still being shaped by the forces of econo -\nmic restructuring. The continued restructuring process is evident \nby the fact that advanced economies like Ontario are experiencing \nnotable employment growth in other sectors like services and em -\nerging green industries (Statistics Canada, 2024). Research typically \nascribes globalization, technological advancements, and trade libe -\nralization as the underlying general forces behind closures and the \nbroader process of economic restructuring (e.g., Beer & Thomas, \n2008; Cleave et al., 2019; Sutton et al., 2022; van Neuss, 2018). Howe -\nver, greater investigation into the causes as well as the impacts of \nplant closures is needed and remains critical, especially given the \nsignificant challenges closures pose for residents and localities, and \nthe imperative to understand how mature industrialized economies \nrespond and adapt to such restructuring.\nCompeting plant closure theories\nAlong with growing concerns regarding the vitality and well-being of \nlocalities due to plant closures in advanced economies, so too has \nthe expansion of empirical research and theoretical development \nin this field. Concerning the latter, although theories on plant clo -\nsures are still underdeveloped, three main strands have emerged: (1) \nneo-classical economics, (2) managerial economics, and (3) political \neconomy (Tomaney et al., 1999). \nNeo-classical economic theory suggests that plant closures are at -\ntributed to economic rationality and market competition (Tomaney \net al., 1999). That is, when plants become unprofitable due to mar -\nket competition, corporations close their plants under the premise of \nprofit-maximizing behaviour. This perspective emphasizes that plant \nclosures are inversely related to profitability and capital intensity of \nthe industries\u2019 technology (Henderson, 1980). Thus, \u201cindustrial clo -\nsures are a natural feature of the economy\u201d (Tomaney et al., 1999: \n402). Simply put, the cause of closure is placed on plants\u2019 perfor -\nmance. Healy (1982) finds that plant closures in Britain\u2019s manufactu -\nring sector are positively associated with plants\u2019 profitability.\nThe managerialist economic theory attributes plant closures to cor -\nporate strategy, market dynamics, and competition (Tomaney et al., \n1999). Plant closures, in this view, are ultimately a corporate strategy \nin response to changing market dynamics and competition (Kirkham \n& Watts, 1997, 1998). Corporations attempt to adapt to changes in \ntheir economic landscape, such as market decline, new entrants, \nand changes in buyer and supplier relations. Plant closures result \neither from the process of strategic adaptation or the failure of corpo -\nrations to adapt (MacLachlan, 1992). Thus, the causes of closures are \nnot solely tied to plants\u2019 profitability. Corporate adaptive strategies \nthat result in plant closures stem from production rationalization, \ntechnological investments, cost-cutting measures, among others \n(Fassin et al., 2017).\nMore recently, a political economy theory of plant closures has been \nput forth, which situates closures within the capitalist economy (To -\nmaney et al., 1999). In particular, the theory argues that the concep -\ntualization of plant closures should be: \u201cfounded upon spatialised \nsocial relations and characterised by a social process of production \nthat unfolds over time, across space and in place\u201d (Pike, 2005: 95). \nThe political economy approach to plant closures provides greater \ninsight into causes of closures by going beyond identifying causal \nfactors and examining the national and international social pro -\ncesses of production and consumption in which plants are embed -\nded (Greco & Yamamoto, 2019; Sutton et al., 2022). For instance, this \napproach provides greater clarity into why some corporations close \nprofitable plants in search of alternative investment opportunities (Tomaney et al., 1999). Ultimately, the political economy theory pro -\nvides a conceptual framework in which to view plant closures.\nResearch area\nThe Province of Ontario, one of Canada\u2019s ten provinces and three \nterritories, has a population of 14.2 million, making it the most popu -\nlous province in the country (Statistics Canada, 2021). It serves as \nCanada\u2019s primary economic hub, contributing about a third of the \nnational GDP (Ontario Government, 2021). Since the 1970s, Ontario \nhas undergone economic restructuring, transitioning from traditional \nindustries to service and knowledge-based sectors (Bourne et al., \n2011; Wolfe & Gertler, 2001). This is influenced by globalization, tech -\nnological advancements, and trade liberalization (Beaulieu, 2001; \nHigh, 2015; Norcliffe & Bates, 2018; Pitblado & Mawhiney, 1999; Sut -\nton et al., 2022). \nNotably, the succession of trade agreements in North America, from \nthe US-Canada Free Trade Agreement (FTA - 1989) to the North \nAmerican Free Trade Agreement (NAFTA - 1994) to the present Ca -\nnada-United States-Mexico Agreement (CUSMA - 2020), have in -\ntensified competitiveness in the southern parts of USA and Mexico, \nleading to the relocation of labor-intensive industries to regions with \nmore flexible labor laws and lower costs of production (Sutton et al., \n2022). Similarly, the termination of the 1965 Canada-US Auto Pact in \n2001 (Crane, 2006) and the long-standing Canada-US softwood lum -\nber dispute (Global Affairs Canada, 2024), have diminished Ontario\u2019s \ncompetitiveness in the automotive and forestry sectors, respectively. \nDespite these institutional changes, Ontario\u2019s industrial base still re -\nmains vital, and the regional economy has seen significant growth \noverall (Statistics Canada, 2022). In other words, Ontario\u2019s economy \nis still growing in this post-industrial era (Statistics Canada, 2024).\nMETHODOLOGY\nThis section outlines the collection and analysis of media coverage to \nexamine the causes and impacts of plant closures in Ontario, Canada.  \nData source\nThis paper utilizes data sourced from Ontario-based newspapers, fo -\ncusing on a media analysis of news articles spanning 2000 to 2019 \nfrom 102 newspapers across the province. Additionally, it incorpo -\nrates content from three national newspapers: The Globe and Mail, \nThe National Post, and The Canadian Press. The comprehensive data -\nset enables the paper to effectively investigate its research inquiries.\nSampling strategy\nA systematic review of news articles covering plant closures in On -\ntario spanning two decades (2000\u20132019) was undertaken, commen -\ncing from a pivotal point in the early 2000s when such closures em -\nerged as a significant economic concern in the region (Constantelos, \n2014; Statistics Canada, 2024). The study concludes in 2019, as the \nCOVID-19 pandemic disrupted the provincial economic landscape \nin a unique manner, requiring an analysis of its own. This extensive \ntimeframe facilitates a thorough examination of media portrayal re -\ngarding plant closures, encompassing key economic shifts in Onta -\nrio, including growth periods (i.e., the early 2000s and 2010s) and the \n2008 global recession.\nA dual approach was employed to select appropriate news articles for \nthis study. First, the ABI/INFORM Collection database was utilized, \nwhich gathers articles from various sources on plant closures in On -\ntario. Starting in the 1970s, this database collects full-text documents \ncovering a diverse range of subjects such as manufacturing, economic \nconditions, and business activities. Specifically, the database archives \nnewspapers from various outlets, spanning national to local/regional \nReproduced with permission of the copyright holder. Further reproduction prohibited.22\nCJRS/RCSR | Volume 47, Num\u00e9ro 2scales, that document plant closures in Ontario since the 2000s. Se -\ncond, the online search engines of Ontario\u2019s 102 news stations were \nused to identify any articles not captured by the ABI/INFORM Col -\nlection database. These search engines identify articles produced by \nthe respective news outlets or their affiliated media conglomerates, as \nwell as those acquired from national newspapers including The Natio -\nnal Post, The Globe and Mail, and The Canadian Press.\nIn line with our study\u2019s objectives, our sampling strategy extracted \nnews articles published between January 1st, 2000 and December \n31st, 2019. We used the following key words in extracting relevant \nnews articles: \u201cfactory\u201d , \u201cplant\u201d , \u201cclosure\u201d , \u201cshutdown\u201d , \u201cmanufactu -\nring\u201d , \u201cautomotive\u201d , \u201cdownsize\u201d , \u201clayoffs\u201d , among others. Altogether, \nour sampling strategy identified over 6,000 newspaper articles. Fol -\nlowing the sampling strategy adopted, screening processes were \nused in the selection of our final sample for the study. Two resear -\nchers independently screened the identified articles, removing du -\nplicates and irrelevant ones. Articles were deemed relevant if they \nprimarily focused on an industrial plant in Ontario, that is in the pro -\ncess of closing or has closed, between 2000 and 2019. This includes \neditorials and news stories specifically related to plant closures, ex -\ncluding general discussions about industrial plants.\nAdditionally, only news articles written in English were included due \nto language barriers, leading to the exclusion of a few local French \nnews outlets. Any conflicts during the screening process were re -\nsolved by a third researcher. Following screening, the final dataset \nconsisted of 1,157 news articles, ranging from approximately 70 to \n4,150 words, with an average length of 690 words. The data was col -\nlected in 2022.\nAnalysis\nWe conducted a thematic analysis to systematically examine the fi -\nnal sample of news articles. This method serves as an analytical tool \nto identify, analyze and interpret patterns or \u201cthemes\u201d within qualita -\ntive data (Clarke & Braun, 2017). Specifically, we used the NVivo sof -\ntware to extract key themes from the news articles. Two researchers \nwere involved in this process \u2013 while one researcher coded the news \narticles, the other reviewed the coded material to verify the accuracy \nand reliability of the collected data.\nTo note, our work is a component of a broader project that inves -\ntigates media narratives and plant closures in Ontario. The project \ntook an inductive coding process, in which the chain of observation \nmoves from newspapers to themes and then subsequently, themes \nwere divided into subthemes (codes) and subthemes into subcodes. \nSpecific to our paper\u2019s objectives, two main themes emerged: causes \nand impacts of plant closures. Regarding causes , 5 subthemes were \nidentified. Following this, 18 subcodes related to these 5 subthemes \nwere further developed. These subcodes are categorized by their \nbroader underlying subtheme (see Table 1).1 Similarly, concerning \nimpacts, many subthemes related to spatial extents of impacts em -\nerged as well, with corresponding subcodes being developed. In \ntotal, as seen in Table 2, 16 subcodes were developed and further \ncategorized by spatial scale (i.e., local, regional and provincial). To \nensure robustness in the coding process, a codebook was created \nand used by the research team. In total, the coding process took \napproximately four months.\nImportantly, media outlets, coupled with their narratives, were as -\nsessed based on their political leanings, ownership and the size of \nthe city they operate. Political leanings were ascertained based on \nevaluations from external sources.2 As expected, political bias of \nnews outlets is influenced by their media ownership, whether they \nwere independently owned or part of a media conglomerate. We find \n1  A detailed description of the coding process, including the list of refined codes, will be provided upon reasonable request.\n2  External source for checking political leaning: https://mediabiasfactcheck.com an approximately equal distribution of left-leaning and right-leaning \nnewspapers, with the majority adopting a centrist stance. The ci -\nties hosting the media outlets were categorized as small, medium, \nor large based on the Population Centre Classifications from Sta -\ntistics Canada. Altogether, considering variations in political orien -\ntation, ownership, and city size enhanced the representativeness of \nthe analysis.\nRESULTS\nBetween 2000 and 2019, media coverage extensively highlighted the \nunderlying causes and subsequent impacts behind plant closures in \nOntario. Over this timeframe, approximately 257 plant closures were \ndocumented, each receiving an average of eight reports spanning \nfrom announcement of plant closure to final closure. The subsequent \nsections are organized according to the prominent themes identified \nin the analysis: the causes  and impacts of plant closures.\nCauses of plant closures\nMany reasons were given for plant closures in Ontario from 2000 \nto 2019. To provide a comprehensive overview, the causes noted in \nnews articles for plant closures were grouped into five broad the -\nmes (Table 1): market forces (31%), corporate factors (28%), endoge -\nnous factors (23%), economic crises (10%), and globalization (7%). \nAlthough these broad themes are discussed separately below, the \nnews articles typically attributed closures to various causes simul -\ntaneously. Simply put, multiple factors and forces simultaneously \ninfluence plant closures.\nTable 1.  Causes of plant closuresTables  \nTable 1 Causes of plant closures  \nBroad Themes  Specific Causes  \nMarket forces  \u2022 Shift in international demand  \n\u2022 Volatile foreign exchange rate s  \n\u2022 Diminishing international prices for raw materials  \n\u2022 Downturn in market share  \n\u2022 Changes in market dynamics  \nCorporate factors  \u2022 Mergers and reorganization  \n\u2022 Subcontracting tasks  \n\u2022 Product flaws  \n\u2022 Transition to added -value goods  \n\u2022 Production adjustments  \n\u2022 Innovation and automation  \nEndogenous factors  \u2022 Manufacturing and operational expenses  \n\u2022 Labor unrest and union disputes  \n\u2022 Legislative actions  \nEconomic crises  \u2022 Unexpected economic slowdowns (e.g., recessions)  \nGlobalization  \u2022 Trade market deregulation  \n\u2022 Economic liberalization \n\u2022 Trade restrictions  \n  \nThe first notable cause of plant closures is market forces. This per -\ntains to situations related to shifts in national and global markets, en -\ncompassing fluctuations in global demand and the Canadian dollar, \ndeclining global resource prices, market share reductions, changes \nin market dynamics, and other similar factors. This was directly cap -\ntured by a news article, \u201cMarket forces were to blame\u201d , and subse -\nquently echoed by others.  \nReproduced with permission of the copyright holder. Further reproduction prohibited.23\nCJRS/RCSR | Volume 47, Num\u00e9ro 2The Canadian dollar provides an illustrative example and was often \ncited as the cause of plant closures in the province. Several news \narticles identified that the rising Canadian dollar has made Canadian \nproducts or goods uncompetitive in the global market, as remarked \nby one news article, in regard to two Collins & Aikman Corp auto part \nplants being closed in Toronto and Gananoque in 2007: \u201cThe high \nCanadian dollar is just killing us\u201d .\u00a0As an illustrative excerpt, one news \narticle stated, \u201cTembec announced yesterday [2005] it is closing three \nsawmills and one small paper mill as it tries to cope with the impact of \nthe stronger [Canadian] dollar\u201d,\u00a0among other factors,\u00a0 with one of the \nsawmills being located in Cochrane, Ontario. Another news article \nreporting on the Penetanguishene CCL Container plant closure in \n2016 quoted Sean Washchuk, the company\u2019s senior vice-president \nand chief financial officer, saying the plant struggled\u00a0 \u201cto remain com -\npetitive with a high Canadian dollar\u201d .\u00a0\u00a0\nInterestingly, several news articles referred to the Canadian dollar as \na\u00a0\u2018Petro-dollar\u2019 because it fluctuates with oil prices. A news article \nnoted that from 1989 to 2003, the Canadian dollar was 74 cents US, \nwhile in 2007, it leaped up to 93 cents and ever further past parity to \n$1.10 in 2014. The news article claimed that rising global oil prices and \nhigh demand for Canadian oil increased the Canadian dollar, redu -\ncing the competitiveness and profitability of Ontario\u2019s industrial base.\nAnother illustrative example is changes in national and global de -\nmand, or more specifically, a fall in demand for products, as it was \nnoted by many news articles to have caused plant closures in On -\ntario. A notable example from the news articles is the closure of the \nSiemens plant in Tillsonburg, Ontario, in 2017. With one news article \nstating, \u201cProduction of the [Siemens] factory\u2019s 55-metre wind turbine \nblades \u2026 suddenly wound down \u2026 demand had simply dried up\u201d.  \nAnother article commenting on the Siemens plant closure noted: \n\u201cCanadian and international markets want the most \ncompetitive technology, which means longer blades, [David \nHickey, chief executive of Siemens Wind Power Ltd] said\u00a0\u2018The \n[Siemens] factory here is constrained. To go beyond the \n55-metre blades, [it] would require significant investment\u2019\u201d.  \nAnother recent example highlighted by a news article was the Ge -\nneral Motors (GM) Oshawa plant closure in 2019 as it was reported \nto have closed \u201cbecause the particular vehicles it is tooled up to make \nare not selling \u2026. Consumers are increasingly uninterested in buying \nsedans - they want crossovers, SUVs and light trucks \u2026 The same is \ntrue for the other facilities that are closing\u201d. \u00a0\nA second identified significant contributor of plant closures in On -\ntario is Corporate factors. This cause of plant closures entails deci -\nsions and actions undertaken by corporations, such as consolida -\ntion, outsourcing, issues with product quality, changes in production \nmethods, technological advancements, and automation. A corporate \nfactor highlighted in several news articles was technological advan -\ncements and automation, which increases output but reduces the \nneed for labour, as expressed by one article:\n\u201cFactory jobs are vanishing, but not output. Output grew 3.2 \nper cent last year, significantly more than the overall growth \nof the economy. Indeed, 2011 continued a trend that stretches \nall the way back to the early 1980s recession. Factory output \ngrew 59 per cent between 1981 and 2010, according to \nStatistics Canada. Over the same period, manufacturing \nemployment fell 16 per cent. The big picture is that Canada \nis producing more widgets with fewer workers, largely \nbecause of new technology and automation\u201d.  To illustrate this point, one news article noted: \n\u201cMaple Leaf Foods Inc. is in the process of closing five \naging plants and replacing them with one highly automated \nfactory in Hamilton, Ont. The result: 1,550 jobs lost, but \none plant capable of cranking out more hot dogs, bacon \nand cold cuts than the five it replaces. Maple Leaf\u2019s story \nis an unfortunate side-effect of productivity. Investment in \ntechnology makes some jobs redundant\u201d.  \nAnother corporate factor commonly noted by news articles to cause \nplant closures was consolidation and restructuring. For example, \none news article reporting on the merger of Kraft and Heinz in 2015, \nwhich Berkshire Hathaway and 3G Capital engineered, stated: \u201c3G \nCapital is known for slashing costs after an acquisition .... Kraft Heinz \nspokesman Michael Mullen said that the company will close \u2026 se -\nven plants over the next 12 to 24 months, shifting work to existing \nlocations, eliminating 2,600 jobs in total\u201d . One of the seven factories \nclosed was in St. Mary\u2019s, Ontario. According to news articles, conso -\nlidation and restructuring typically result in several plant closures in \ntheir production chain.\nEndogenous factors are a third identified cause of plant closures in \nthe province. Endogenous factors are those that are internal to the \nlocal economic environment where plants operate, and include pro -\nduction and operational expenses, government regulations, labor \nstrikes, and union conflicts, among others. Most endogenous factors \nidentified were at the provincial level, specifically regarding provin -\ncial public policies. Nevertheless, the news articles frequently noted \nthat Ontario does not have a competitive landscape for traditional \nindustrial activities, which results in many plants closing. As noted \nby one article, Ontario is \u201cuncompetitive against offshore rivals\u201d,\u00a0and \nthe province\u00a0 \u201ccan't compete with the Third World countries\u201d . To further \nillustrate this point, one news article stated,\u00a0 \u201cpeople in manufacturing \nare very worried about high energy costs, outdated labour laws, high \ntaxes, so much red tape and runaround [causing further closures] it \nmakes them pull their hair out\u201d .\u00a0\nAn exemplary endogenous factor emphasized in several news ar -\nticles was production and operation costs. News articles highlighted \nthat production and operation costs in Ontario are not competitive \nwith global competitors. For example, one news article reporting on \nthe closure of the Chatham Navistar plant in 2008 stated that the \ncompany \u201cplans to shift much of its heavy-duty truck production from \nChatham to lower-cost locations in the southwestern United States \nand Mexico\u201d . Another example brought forth by news articles was \nthe closure of the London Caterpillar plant in 2012. A news article \ncovering the Caterpillar plant closure indicated that the corporation \nshut down the plant due to high production and operation costs, \nspecifically noting:\u00a0 \u201cCaterpillar had demanded pay cuts of 50 per \ncent in many job categories, elimination of a defined-benefit pension \nplan, reductions in dental and other benefits and the end of a cost-\nof-living adjustment\u201d, as it was not profitable due to production and \noperation costs. Since the demands were not met, the company \nshut the plant down.\nMany news articles noted that the Federal and Provincial govern -\nments were responsible for Ontario\u2019s uncompetitive environment, in -\ndirectly incentivizing plant closures or their relocation to more com -\npetitive areas. One article noted:\u00a0 \u201cWe\u2019re losing jobs because we\u2019re \nuncompetitive, and if we lose more jobs, it\u2019ll be because we\u2019re uncom -\npetitive, and that goes back to government policy\u201d . Specifically, one \narticle noted that corporations need \u201crelief from enormous pension, \nhealth and other obligations that have saddled the North American in -\ndustry with an uncompetitive cost structure\u201d . For instance, one article \nstated: \u201cOntario electricity prices are now uncompetitive with many \nReproduced with permission of the copyright holder. Further reproduction prohibited.24\nCJRS/RCSR | Volume 47, Num\u00e9ro 2jurisdictions in the United States - another triumph from the central \nplanning playbook that is slowly driving jobs and industry out of the \nprovince\u201d.  \nFurthermore, news articles criticized the federal and provincial go -\nvernments for not trying to enhance the region\u2019s competitiveness \nbut simply focused on bailing out large plants facing bankruptcy. \nNews articles pointed out that several plants owned by the Detroit \nThree (i.e., General Motors, Ford, and Chrysler) still closed in the pro -\nvince, even after receiving multi-billion dollars in bailouts from the \nOntario and Federal governments in 2009. For example, an article \npointed to the closing of the General Motors Co. Oshawa auto as -\nsembly plant in 2019. The news article stated: \u201cpast bailouts haven\u2019t \nled to any loyalty\u201d.\nEconomic crises like the 2008 Great Recession and the September \n11th, 2001 terrorist attacks in the USA have been cited as another \nreason for plant closures in the province. These events can be consi -\ndered as unforeseen disruptions to economic stability. Most news \narticles that attributed plant closures to economic crises commented \non the 2008 Great Recession. An example highlighted by media co -\nverage was the closure of Brantford\u2019s Eagle Precision Technologies \nin 2009. As expressed by one news article, \u201cAfter 50 years on the \nBrantford manufacturing landscape, Eagle Precision Technologies \nhas closed its doors, a victim of the global recession\u201d . The news article \nwent on to remark that the\u00a0 \n\u201cFederal Liberal international trade critic Martha Hall Findlay \ncouldn\u2019t help but be shocked by the candid reality of the \neconomic recession\u2019s impact on Brantford, in a tour of empty \nfactory buildings on Thursday. \u2018You read the statistics of \n2,000 jobs lost and the companies that have closed, but it\u2019s \nreally graphic when you drive around and see all these empty \nbuildings, nearly empty parking lots and For Sale signs,\u2019 Hall \nFindlay said in an interview from her seat as the bus passed \nthe ninth closed business in the Braneida industrial park\u201d.  \nOverall, as noted by one news article: \u201cFor the [Ontario] factories \nso long-regarded as a key to Canada\u2019s economic health, the global \ndownturn of 2008-09 looked like a death knell\u201d.  \nA fifth identified significant cause of plant closures in Ontario, as \nhighlighted by media reports during the study period, is Globaliza -\ntion. Globalization denotes the growing impact of worldwide dyna -\nmics on economic operations, stemming from increased economic \ninterconnectedness, openness, and changes in trade regulations. \nNews articles reported several plant closures due to the introduc -\ntion of NAFTA in 1994, the end of the Canada-US auto pact in 2001, \nand the effects of the Canada-US softwood lumber dispute since \nthe 1980s. Regarding NAFTA, Jerry Dias, the national president of \nthe Unifor union that represents Cami workers, in one news article, \n\u201claid the blame for the cuts [at the Ingersoll Cami plant in 2017] on \nthe North American Free Trade Agreement, which opened borders ta -\nriff-free between Canada, the U.S. and Mexico\u201d , resulting in jobs being \nshifted to other plants in the USA and Mexico. With respect to the \nending of the Canada-US auto pact in 2001, one article noted, \n\u201cAlthough the pact was abolished in 2001, the closing of \nthe [St. Thomas Ford assembly] plant [in 2011 and the loss \nof 1,100 jobs] represents the headstone on its grave, and is \nanother sign that the Federal and Ontario governments have \nlost one of the strongest levers they had to convince auto \nmakers to invest here\u201d.  Quoting Dimitry Anastakis, a professor at Trent University, the article \nnotes, \n\u201c\u2018Ontario and the Federal government do provide quite \na bit of direct support through either grants or loans, but \nthese are all carrots which every other jurisdiction in North \nAmerica can also offer \u2026. The auto pact was a stick that \ncould be used to force companies to build in Canada or pay \nsignificant fines, which they did their best to avoid\u2019\u201d . \nHowever, the article notes that upper-level governments lost the le -\nvers provided by the 1965 Canada-US auto pact due to the World \nTrade Organization ruling that it was \u2018illegal under global trade rules\u2019.  \nConcerning the Canada-US softwood lumber dispute, one news ar -\nticle stated, Tembec is closing a paper mill plant in Ontario \u201cas it tries \nto cope with the impact of the stronger dollar, \u2026 punishing U.S. import \ntariffs on softwood lumber and other issues\u201d . The news article further \nnoted that the Montreal-based company Tembec as a whole in 2006 \n\u201clost $134.9-million in [the last three months], battered by the softwood \nlumber dispute with the United States and the strong Canadian dollar\u201d.  \nIn summation, news articles noted that increasing global integration \nand economic openness as well as continuing trade barriers had \naccentuated economic restructuring in North America, resulting in \nmany plant closures, especially in Ontario.\nImpacts of closures\nAcross scholarly literature and policy circles, a key concern of plant \nclosures has always been its impacts on the local and national eco -\nnomy, affected workers, and families. Equally, the media has also \nbeen concerned with the impacts of closures. The media coverage \nin Ontario highlighted that plant closures had adverse multi-scalar \neffects, impacting workers, local economies, and the broader pro -\nvincial economy (Table 2). Workers were noted to be the most affec -\nted by plant closures, with several articles stating that over 300,000 \nmanufacturing jobs have been lost in the 2000s alone. Illustrating \nthe gravity of plant closures on workers, a news article remarked: \n\u201cworkers have erected a graveyard of wooden crosses. \u2018Job cemetery\u2019 \none [cross] said\u201d . Besides losing their job, news articles noted that \nworkers were more likely to experience further cycles of unemploy -\nment. Commenting on the massive layoff at the GM plant in Ingersoll \nin 2017, one news article stated regarding a group of recently hired \nworkers:\n\u201cOn Monday morning, 60 people will file into work at their \nnew jobs, earning a high wage, pension and benefits \u2014 \nbut they will soon be out of work, and they know it \u2026. \nThese new workers are at the top of the list to get cut this \nsummer, being lowest in seniority, but that is not stopping \nthe applications from pouring in, said Mike Van Boekel, \nchairperson of Unifor Local 88 that represents workers at the \nIngersoll factory\u201d .\u00a0\nThe previous statement highlights a common impact of plant clo -\nsures, specifically that factory workers who are laid off are more likely \nto experience further cycles of unemployment due to, among other \nfactors, having low seniority. To further illustrate the precarious em -\nployment of laid-off workers, an interviewed worker commented, \u201c\u2018I \nwas laid off from Cami [factory], I was laid off from Dana [factory] and I \nam finally getting back on my feet \u2026 Now, there is this pressure again\u201d,  \nwith the worker indicating that they may soon be laid off again.\u00a0\nReproduced with permission of the copyright holder. Further reproduction prohibited.25\nCJRS/RCSR | Volume 47, Num\u00e9ro 2Table 2.  Multi-scalar effects of plant closuresTable 2 Multi -scalar effects of plant closures  \nLevel of effects  Impacts of plant closures  \nIndividual level  \u2022 Redundancy  \n\u2022 Structural unemployment  \n\u2022 Increased risk of further cycles of unemployment  \n\u2022 Increased precarious work  \n\u2022 Lower wage and part -time work  \nLocal level  \u2022 Mass redundancies and outmigration  \n\u2022 Loss of significant employer or erosion of the industrial base  \n\u2022 Reduced overall tax base, local demand, and gross domestic \nproduct  \n\u2022 Lowered position in the urban hierarchy  \n\u2022 Diminished social support and deteriorates cities\u2019 social fabric  \nSubnational level  \u2022 Reduced subnational gross domestic product  \n\u2022 Increased unemployment rate and long -term unemployment \n\u2022 The multiplier effect on local employment  \n\u2022 Increased subnational deficit and debt* \n\u2022 Lowered position in the regional hierarchy* \n\u2022 Loss of global leading companies  \n*Impacts due to experiencing numerous closures  \nIn addition, news articles emphasized that plant closures resulted in \nthe loss of high-paying jobs in local communities. As noted by one \nnews article commenting on plant closures in Ontario, \u201c[manufactu -\nring], traditionally a source of high-paying jobs, has faded to just 11.8 \nper cent of total employment, half the levels they were in 1976\u201d . The \nprevious quote highlights plant closures\u2019 impact on redundant wor -\nkers\u2019 capacity to find re-employment in a high-paying job in a similar \nsector, with some redundant workers shifting from high-paying jobs \nin manufacturing to low-paying jobs in the service sector.\u00a0To summa -\nrize, plant closures often result in workers experiencing \u201cincreases in \nlow-wage, involuntary part-time and precarious employment, as well \nas long-term unemployment\u201d. \u00a0\nPlant closures in Ontario were also noted to have an adverse effect \non local economies, especially medium- and small-sized cities. As \nnoted by one news article on the closure of the Heinz factory in St. \nMarys, Ontario, in 2015:\u00a0 \u201c\u2018It\u2019s a great loss to our community. We are \nin shock. For a town of 6,800, Heinz was a big employer\u201d .\u00a0 The above \nstory was echoed throughout many news articles. Specifically, the \nmost affected cities were single-industry towns, as expressed by \none news article: \u201cAll small towns in Ontario and Canada in traditio -\nnal manufacturing are in trouble. Unless they change, they are going \nto become ghost towns\u201d . As conveyed by the previous quotes, plant \nclosures had a hollowing-out effect in medium- and small-towns, \nespecially single-industry towns, resulting in a reduced labour force \nand outmigration.\nPlant closures were also noted to significantly reduce local econo -\nmies\u2019 tax base and gross domestic product (GDP). As stated by one \nnews article commenting on the closure of a newspaper mill in Iro -\nquois Falls in 2014, the town lost its \u201clargest employer and one of the \nhighest sources of tax revenue for the town\u2026 which contributed more \nthan $1 million in tax revenues each year\u201d . In addition, news articles \nnoted that closures reduced their overall GDP, resulting directly from \nplant closures but also indirectly from a reduction in local demand \nfor services and goods. To illustrate this point, one article noted a \nlocal store owner stated they are \u201cdown 20 percent\u201d of their normal \nrevenue due to the plant closure, and one restaurant owner noted \nthey \u201clost 30 to 40 customers a day\u201d . Put differently by another article, \n\u201cFor every dollar spent in manufacturing, it creates $3.25 of economic \nactivity in other sectors, and now that\u2019s lost\u201d.\nSocial supports, including charities, were also affected by plant clo -\nsures. As expressed in one news article, \u201cThe United Way of Lon -don estimates it lost $108,000 as a result of the Electro-Motive clo -\nsure. The funding has evaporated just as the need for services such \nas mental health and financial counselling is growing\u201d . Further, news \narticles emphasized that the social fabric of cities also deteriorates \nwhen plants close, especially in small and medium cities. To illus -\ntrate this point, Deputy Mayor Dave Beres notes in one news article, \n\u201cThe shutdown [of the Siemens plant in Tillsonburg in 2017] makes \nthe town less social, too. They don\u2019t want to go to shows. They don\u2019t \nwant to go to restaurants. They don\u2019t want to go to the neighbours for \nsteak barbecue and a beer\u201d . Overall, the cumulative effect that plant \nclosures had on local economies over time was also noted to affect \nthe standing of cities in the urban hierarchy. For instance, one news \narticle noted that due to several plant closures in London, Ontario, \nsince the 2000s, \u201cLondon tumbled out of Ontario\u2019s top-10 big city list\u201d.\nMany news articles stated that plant closures adversely affected the \nProvincial economy, reducing its overall economic prosperity. To il -\nlustrate this point, one news article stated, regarding the Ingersoll \nGM plant laying off 625 workers and moving their production of the \nTerrain to Mexico in 2017:\u00a0 \u201cAn industry rep pegs the loss to Southwes -\ntern Ontario\u2019s economy at $50 million to $80 million\u201d. However, the \nimpact of plant closures on the province is more complex than sim -\nply reducing the provincial GDP. Expressing this point, one article \nremarks:\u00a0\n\u201cOver the past decade [2000-2010], Ontario has experienced \nextraordinary economic decline [due to plant closures]. The \nfacts speak for themselves: 600,000 people unemployed \n[in all sectors], \u2026 historic deficits and a doubling of \nthe provincial debt that will both stifle job creation and \nburden future generations. Our province has had a \nhigher unemployment rate than the national average for \n69 consecutive months. \u2026 Once-mighty Ontario is now \nconsidered a have-not province and receives equalization \npayments from the federal government. We as a province \nhave been experiencing a net loss of leading global \ncompanies for a number of reasons\u201d. \u00a0\nInterestingly, the economic restructuring that has occurred in the \nprovince over the past two decades has also shifted its position in \nthe regional hierarchy among Canadian provinces. \nIn addition, news articles emphasized that plant closures also had \na multiplier effect in which the loss of a plant resulted in additional \njobs being lost in the industry and other sectors. For instance, one \nnews article reporting on a plant closure noted, \u201cthe shutdown will hit \nthe industrial economy in southwestern Ontario hard and cut another \n1,700 spinoff jobs linked to the locomotive plant\u201d . Another news ar -\nticle highlighted that \u201cthe St. Thomas assembly plant will close in \nSeptember 2011, eliminating 1,500 direct jobs and an estimated 6,000 \nto 9,000 related jobs in southwestern Ontario businesses that sup -\nply auto parts and services\u201d . In short, the effects of plant closures \nare widespread across industries and impact economies at various \nscales (i.e., multi-scalar effects).\nDISCUSSION AND CONCLUSION\nPlant closures in advanced economies, such as Ontario, have been a \nsubject of considerable concern and analysis, as they reflect broader \neconomic trends and have implications for local communities and \nthe labor force. Current knowledge of plant closures, particularly in \nOntario, are constrained by outdated information that may not fully \nalign with contemporary dynamics. As plant closures are still on -\ngoing, it is imperative to continuously monitor this phenomenon, as \nReproduced with permission of the copyright holder. Further reproduction prohibited.26\nCJRS/RCSR | Volume 47, Num\u00e9ro 2both causes and impacts can evolve over time and can vary in inten -\nsity. Furthermore, comprehending the complex nature of plant clo -\nsures necessitates adopting a case study methodology. In response, \nour study leverages publicly accessible media coverage to investi -\ngate the causes and consequences of plant closures across various \ncities in Ontario. By doing so, we aim to refresh our understanding of \nthis phenomenon and provide insights that reflect the current eco -\nnomic landscape. \nThe media gave various reasons for why plants closed and hence, \nwhy economies were being adversely impacted. Foremost, five \nbroad themes of factors and forces were attributed to causing plant \nclosures: market forces, corporate factors, endogenous factors, eco -\nnomic crises, and globalization. These demonstrate the complexities \nunderpinning plant closures, indicating some of the various dyna -\nmics influencing the evolution of economies. In short, the causes \nidentified provide an exhaustive and encompassing understanding \nof plant closures in the 21st century. Following this finding, we sub -\nsequently explored potential impacts. Plant closures had various im -\npacts on Ontario\u2019s economy. Some of the impacts of plant closures \nnoted in media reports corroborate previous findings, particularly re -\ngarding the redundancies caused by plant closures (Armstrong et al., \n2008; Sutton et al., 2022) as well as the increased risk of redundant \nworkers falling into further cycles of unemployment and precarious \nwork (Bailey & de Ruyter, 2015). \nOne particularly interesting finding is that media coverage illustrates \nthe social impacts of plant closure. Specifically, they demonstrate \nhow plants financially support social services in local economies. \nThus, as plants close, local economies experience reduced capacity \nto assist and support their communities. This finding is particularly \ntroubling given that recent research (Sutton et al., 2022) has found \nthat local economies may experience increased drug use, home -\nlessness, and mental health issues following a closure. This finding \nsuggests that when there is a growing need for social services due to \nplant closures, local economies are least capable of supporting their \nresidents and maintaining their city\u2019s social fabric.\nAnother notable finding from examining media coverage on the im -\npacts of plant closures is the multi-scalar effects of plant closures. \nIn particular, plant closures affect the redundant workers, their local \neconomy, and the subnational economy in which they are embed -\nded. Previous research has primarily focused on the impact of plant \nclosures on redundant workers (Armstrong et al., 2008; Bailey et al., \n2012, 2014) or local economies (Chapain & Murie, 2008; Jofre-Monse -\nny et al., 2018; Verity & Jolley, 2008), neglecting their multi-scalar \neffects on subnational economies. Subnational economies are ad -\nversely impacted by single closures as well as the accumulation \nof closures over time. Furthermore, news articles connected plant \nclosures to local and regional economies\u2019 position in the urban and \nregional hierarchy, emphasizing the gravity of closures and their in -\nfluence on local and regional development.\nOur findings do not verify a theory but do indicate that the political \neconomy perspective of plant closures seems to provide an appro -\npriate theoretical lens. Notably, the causes of plant closures noted by \nmedia reports in Ontario go beyond the rationale presented by clas -\nsical economics and managerial economics. Also, the results, espe -\ncially in regard to endogenous factors and globalization, illustrate \nthat plant closures need to be understood in the context of \u201cspatia -\nlized social relations\u201d (Pike, 2005: 95). In this view, it is important to \nunderstand the context in which plant closures occur to better grasp \ntheir effects. Our case study has specifically illustrated the Ontario \ncontext, as reported by the media. Insights from our case study can \ncontribute to expanding the plant closure literature and support po -\nlicy development in Ontario and abroad.Overall, although the approach used in this work can be replicated \nelsewhere, there are considerations to guide future work. Media co -\nverage can be influenced by several issues such as political inte -\nrests, selective reporting and editorial decisions. We acknowledge \nthat media consolidation and innovation in news delivery may have \ninfluenced our data sources over time, but addressing this is beyond \nthe scope of the paper. For this reason, we take the data as pre -\nsented. Additionally, an underlying assumption is the data claim to \nbe factual reports. We contend that while reporting a plant closure \nis unlikely to pose issues, identifying the exact cause or effect of the \nclosure could. However, verifying the accuracy of these causes and \nimpacts is outside the scope of this study. In response, future re -\nsearch can contextualize media coverage within broader socioeco -\nnomic contexts to address such inherent issues. Also, researchers \ncan diversify data sources such as the complementary use of prima -\nry data sources with media coverage to enhance reliability.\nREFERENCES\n Armstrong, K., Bailey, D., de Ruyter, A., Mahdon, M., & Thomas, \nH. (2008). Auto plant closures, policy responses and labour mar -\nket outcomes: A comparison of MG Rover in the UK and Mit -\nsubishi in Australia. Policy Studies, 29(3), 343\u2013355. https://doi.\norg/10.1080/01442870802160051\nBailey, D., Bentley, G., de Ruyter, A., & Hall, S. (2014). Plant closures \nand taskforce responses: An analysis of the impact of and policy \nresponse to MG Rover in Birmingham. Regional Studies, Regional \nScience, 1(1), 60\u201378.\nBailey, D., Chapain, C., & Ruyter, A. de. (2012). Employment Outco -\nmes and Plant Closure in a Post-industrial City: An Analysis of the \nLabour Market Status of MG Rover Workers Three Years On. Urban \nStudies, 49 (7), 1411\u20131621. https://doi.org/10.1177/0042098011415438\nBailey, D., & de Ruyter, A. (2015). Plant closures, precariousness and \npolicy responses: Revisiting MG Rover 10 years on. Policy Studies, \n36(4), 363\u2013383. https://doi.org/10.1080/01442872.2015.1073248\nBailey, D., & MacNeill, S. (2008). The Rover Task Force: A case study in \nproactive and reactive policy intervention? Regional Science Policy & \nPractice, 1(1), 109\u2013124. https://doi.org/10.1111/j.1757-7802.2008.00007.x\nBeaulieu, E. (2001). North American integration and plant closures in \nOntario. Canadian Foreign Policy Journal, 8(2), 23\u201338. https://doi.org\n/10.1080/11926422.2001.9673243\nBeer, A., & Thomas, H. (2008). A tale of two cities: Auto plant closures \nand policy responses in Birmingham and Adelaide. Policy Studies, \n29(3), 249\u2013253. https://doi.org/10.1080/01442870802159848\nBernard, A. B., & Jensen, J. B. (2007). Firm structure, multinationals, \nand manufacturing plant deaths. The Review of Economics and Sta -\ntistics, 89 (2), 193\u2013204.\nBluestone, B., & Harrison, B. (1982). The deindustrialization of Ameri -\nca: Plant closings, community abandonment, and the dismantling of \nbasic industry. Basic Books.\nBoschma, R., & Frenken, K. (2018). Evolutionary Economic Geo -\ngraphy. In G. L. Clark, M. P. Feldman, M. S. Gertler, & D. W\u00f3j -\ncik (Eds.), The new oxford handbook of economic geography (pp. \n213\u2013229). Oxford University Press. https://doi.org/10.1093/oxford -\nhb/9780198755609.013.11\nBourne, L., S., Hutton, T. A., Shearmur, R. G., & Simmie, J. (2011). Ca -\nnadian urban regions: Trajectories of growth and change. Oxford Uni -\nversity Press.\nCanadian Manufacturing. (2016). GM to expand Oshawa research, \nopen new lab in Markham, Ont., and invest $10M in cold-weather test \nReproduced with permission of the copyright holder. Further reproduction prohibited.27\nCJRS/RCSR | Volume 47, Num\u00e9ro 2centre . https://www.canadianmanufacturing.com/technology/gm-\nexpand-oshawa-research-open-new-lab-markham-ont-invest-10m-\ncold-weather-test-centre-169946/\nCBC News. (2023). 300 new jobs, battery module production co -\nming soon to CAMI assembly plant in Ingersoll, Ont. https://www.\ncbc.ca/news/canada/london/300-new-jobs-battery-module-pro -\nduction-coming-soon-to-cami-assembly-plant-in-ingersoll-ont-\n1.6917310#:~:text=Auto%20giant%20General%20Motors%20(GM,-\ncovered%20by%20those%20new%20jobs.\nChapain, C., & Murie, A. (2008). The impact of factory closure on \nlocal communities and economies: The case of the MG Rover Long-\nbridge closure in Birmingham. Policy Studies, 29(3), 305\u2013317. https://\ndoi.org/10.1080/01442870802159962\nClarke, V., & Braun, V. (2017). Thematic analysis. The journal of posi -\ntive psychology, 12(3), 297-298. https://doi.org/10.1080/17439760.201\n6.1262613  \nCleave, E., Vecchio, M., Spilsbury, D., & Arku, G. (2019). Manufac -\nturing change and policy response in the contemporary economic \nlandscape: How cities in Ontario, Canada, understand and plan for \nmanufacturing. Regional Studies, Regional Science, 6(1), 469\u2013495. \nhttps://doi.org/10.1080/21681376.2019.1668292\nConstantelos, J. (2014). Vetoes and Venues: Economic Crisis and \nthe Roads to Recovery in Michigan and Ontario. Canadian Jour -\nnal of Political Science, 47(4), 827\u2013853. https://doi.org/10.1017/\nS0008423914001073\nCrane, D. (2006). Canada-US Auto Pact. The Canadian Encyclopedia.  \nhttps://www.thecanadianencyclopedia.ca/en/article/cana -\nda-us-automotive-products-agreement\nDrisko, J., & Maschi, T. (2015). Content Analysis. Oxford University \nPress. https://doi.org/10.1093/acprof:oso/9780190215491.001.0001\nFassin, Y., de Colle, S., & Freeman, R. E. (2017). Intra-stakeholder al -\nliances in plant-closing decisions: A stakeholder theory approach: \nFASSIN et al. Business Ethics: A European Review, 26(2), 97\u2013111. \nhttps://doi.org/10.1111/beer.12136\nFothergill, S., & Nigel, G. (1990). Retreat from the regions: Corporate \nchange and the closure of factories. Regional Studies Association.\nGentzkow, M., & Shapiro, J. M. (2010). What Drives Media Slant? \nEvidence From U.S. Daily Newspapers. Econometrica, 78(1), 35\u201371. \nhttps://doi.org/10.3982/ECTA7195\nGlobal Affairs Canada. (2024). Softwood Lumber. Government of Ca -\nnada. https://www.international.gc.ca/controls-controles/softwood -\nbois_oeuvre/index.aspx?lang=eng\nGreco, A., & Yamamoto, D. (2019). Geographical political economy of \nnuclear power plant closures. Geoforum, 106, 234\u2013243. https://doi.\norg/10.1016/j.geoforum.2019.08.017\nGrossman, E. (2022). Media and Policy Making in the Digital Age. \nAnnual Review of Political Science, 25(1), 443\u2013461. https://doi.\norg/10.1146/annurev-polisci-051120-103422\nHealy, M. J. (1982). Plant closures in multi-plant enterprises\u2014The \ncase of a declining industrial sector. Regional Studies, 16(1), 37\u201351.\nHenderson, R. A. (1980). An analysis of closures amongst Scottish \nmanufacturing plants between 1966 and 1975. Scottish Journal of Po -\nlitical Economy, 27(2), 152\u2013174. https://doi.org/10.1111/j.1467-9485.1980.\ntb00564.x\nHerman, E. S., & Chomsky, N. (2008). Manufacturing consent: The \npolitical economy of the mass media. Random House.High, S. (2015). \u201cThey Were Making Good Money, Just Ten Minutes \nfrom Home\u201d: Proximity and Distance in the Plant Shutdown Stories \nof Northern Ontario Mill Workers. Labour, 76 (1), 11\u201336.\nJofre-Monseny, J., S\u00e1nchez-Vidal, M., & Viladecans-Marsal, E. (2018). \nBig plant closures and local employment. Journal of Economic Geo -\ngraphy, 18(1), 163\u2013186. h ttps://doi.org/10.1093/jeg/lbx026\nKirkham, J. D., & Watts, H. D. (1997). The Influence of Plant Profitabi -\nlity on Plant Closures in Multi-locational Firms. Growth and Change, \n28(4), 459\u2013474.\nKirkham, J. D., & Watts, H. D. (1998). Multi-locational Manufacturing \nOrganisations and Plant Closures in Urban Areas. Urban Studies, \n35(9), 1559\u20131575. https://doi.org/10.1080/0042098984286\nMacKinnon, D., Cumbers, A., Pike, A., Birch, K., & McMaster, R. \n(2009). Evolution in Economic Geography: Institutions, Political Eco -\nnomy, and Adaptation. Economic Geography, 85(2), 129\u2013150. https://\ndoi.org/10.1111/j.1944-8287.2009.01017.x\nMacKinnon, D., Dawley, S., Pike, A., & Cumbers, A. (2019). Rethinking \nPath Creation: A Geographical Political Economy Approach. Econo -\nmic Geography, 95(2), 113\u2013135. https://doi.org/10.1080/00130095.20\n18.1498294\nMacLachlan, I. (1992). Plant Closure and Market Dynamics: Com -\npetitive Strategy and Rationalization. Economic Geography, 68(2), \n128\u2013145. https://doi.org/10.2307/144198\nMalecki, E. (2004). Jockeying for Position: What It Means \nand Why It Matters to Regional Development Policy When \nPlaces Compete. Regional Studies, 38(9), 1101\u20131120. https://doi.\norg/10.1080/0034340042000292665\nMartin, R., & Sunley, P. (2006). Path dependence and regional econo -\nmic evolution. Journal of Economic Geography, 6(4), 395\u2013437. https://\ndoi.org/10.1093/jeg/lbl012\nMartin, R., & Sunley, P. (2015). On the notion of regional economic \nresilience: Conceptualization and explanation. Journal of Economic \nGeography, 15 (1), 1\u201342. https://doi.org/10.1093/jeg/lbu015\nMassey, D., & Meegan, R. (1982). The anatomy of job loss: The \nhow, why and where of employment decline. Methuen. https://doi.\norg/10.4324/9781315882437\nMoretti, E. (2010). Local Multipliers. American Economic Review, \n100(2), 373\u2013377. https://doi.org/10.1257/aer.100.2.373\nNorcliffe, G., & Bates, J. (2018). Neoliberal governance and resource \nperipheries: The case of Ontario\u2019s mid-north during the \u201ccommon \nsense revolution.\u201d Studies in Political Economy, 99(3), 331\u2013354. \nhttps://doi.org/10.1080/07078552.2018.1536372\nOECD. (2023). Value added by activity (indicator). [dataset]. https://\ndoi.org/10.1787/a8b2bd2b\nOntario Government. (2021). About Ontario. https://www.ontario.ca/\npage/about-ontario#section-1\nPike, A. (2005). Building a Geographical Political Economy of Clo -\nsure: The Case of R&DCo in North East England. Antipode, 37(1), \n93\u2013115. https://doi.org/10.1111/j.0066-4812.2005.00475.x\nPitblado, J., & Mawhiney, A. M. (1999). Boom town blues: Elliot Lake, \ncollapse and revival in a single industry community. Dundurn Press.\nPowell, W., & Snellman, K. (2004). The Knowledge Economy. Annual \nReview of Sociology, 30 (1), 199\u2013220.\nRay, D. M., MacLachlan, I., Lamarche, R., & Srinath, K. (2017). Eco -\nnomic shock and regional resilience: Continuity and change in \nCanada\u2019s regional employment structure, 1987\u20132012. Environment \nand Planning A: Economy and Space, 49(4), 952\u2013973. https://doi.\norg/10.1177/0308518X16681788\nReproduced with permission of the copyright holder. Further reproduction prohibited.28\nCJRS/RCSR | Volume 47, Num\u00e9ro 2Statistics Canada. (2021). Census Profile, 2021 Census of Population. \nhttps://www12.statcan.gc.ca/census-recensement/2021/dp-pd/\nprof/index.cfm?Lang=E\nStatistics Canada. (2022). Gross domestic product (GDP) at ba -\nsic prices, by industry, provinces and territories, percentage share. \nhttps://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=3610040001\nStatistics Canada. (2024). Labour force characteristics by industry, \nannual (x 1,000). Table: 14-10-0023-01 (Formerly CANSIM\u00a0282-0008). \nhttps://doi.org/10.25318/1410002301-eng\nSutton, J., & Arku, G. (2024). Media narratives of industrial plant clo -\nsures in Ontario, Canada, from 2000 to 2019. Area , 56(2), e12938.\nSutton, J., Arcidiacono, A., Torrisi, G., & Arku, R. N. (2023). Regional \neconomic resilience: A scoping review. Progress in Human Geogra -\nphy, 47(4), 500-532. DOI: https://doi.org/10.1177/03091325231174183\nSutton, J., Cleave, E., Bailey, D., & Arku, G. (2022). Retooling local \neconomies: Practitioners\u2019 experiences and perspectives on plant \nclosures in Ontario. Urban Research and Practice. https://doi.org/\nDOI: 10.1080/17535069.2022.2151849\nTomaney, J., Pike, A., & Cornford, J. (1999). Plant Closure and the Lo -\ncal Economy: The Case of Swan Hunter on Tyneside. Regional Stu -\ndies, 33 (5), 401\u2013411. https://doi.org/10.1080/00343409950081257\nvan Neuss, L. (2018). Globalization and deindustrialization in ad -\nvanced countries. Structural Change and Economic Dynamics, 45, \n49\u201363. https://doi.org/10.1016/j.strueco.2018.02.002\nVan Winden, W. (2008). Urban governance in the knowledge-based \neconomy: Challenges for different city types. Innovation, 10(2\u20133), \n197\u2013210. https://doi.org/10.5172/impp.453.10.2-3.197\nVanchan, V., Bryson, J., & Clark, J. (2015). Introduction: Manufacturing \nmatters: Space, place, time and production. In J. R. Bryson, J. Clark, & \nV. Vanchan (Eds.), Handbook of manufacturing industries in the world \neconomy (pp. 3\u201316). Edward Elgar Publishing.\nVerity, F., & Jolley, G. (2008). Closure of an automotive plant: Trans -\nformation of a work-based \u2018community.\u2019 Policy Studies, 29(3), 331\u2013\n341. https://doi.org/10.1080/01442870802159996\nWolfe, D. A., & Gertler, M. S. (2001). Globalization and Economic \nRestructuring in Ontario: From Industrial Heartland to Learning \nRegion? European Planning Studies, 9(5), 575\u2013592. https://doi.\norg/10.1080/09654310124479\nYin, R. K. (2003). Case Study Research: Design and Methods (Vol. \n5). SAGE.\n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Closing up shop: Exploring media coverage of plant closures in Ontario, Canada", "author": ["RN Arku", "J Sutton"], "pub_year": "2024", "venue": "Canadian Journal of Regional Science", "abstract": "The ongoing issue of plant closures is a significant concern for advanced economies.  Consequently, there is a need to update our understanding of plant closures to align with present-"}, "filled": false, "gsrank": 798, "pub_url": "https://www.erudit.org/en/journals/cjrs/2024-v47-n2-cjrs09767/1115227ar/abstract/", "author_id": ["IJhZDT4AAAAJ", "F75WJTsAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:gyWq0kVamq0J:scholar.google.com/&output=cite&scirp=797&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D790%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=gyWq0kVamq0J&ei=lrWsaPi1IL_SieoPzJnloAQ&json=", "num_citations": 1, "citedby_url": "/scholar?cites=12509410170908583299&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:gyWq0kVamq0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.erudit.org/en/journals/cjrs/2024-v47-n2-cjrs09767/1115227ar.pdf"}}, {"title": "The Casual Observer: Low-Activity Twitter Users as Arbiters of (Mis) Information in the War in Ukraine", "year": "2023", "pdf_data": " ESSACHESS \u2013 Journal for Communication Studies    \n Article received January 29, 2023. Article accepted on May 9, 2023.                                  Conflict of Interest: The author declares no conflict of interest.   \n         Cite: ROBINSON, J. Y. (2023). The Casual Observer: Low-Activity Twitter Users as Arbiters of (Mis)Information in the War in Ukraine. ESSACHESS. https://doi.org/10.21409/MVFN-PN09  Jessica Yarin ROBINSON Doctoral Research Fellow, Department of Media & Communication, University of Oslo NORWAY email: j.y.robinson@media.uio.no  Abstract: The spread of misinformation in the digital age has become a significant concern, especially during times of crisis and conflict. In the context of the ongoing war in Ukraine, a web of actors \u2013 including government officials, journalists, activists, and ordinary citizens \u2013 participate in shaping public discourse on platforms such as Twitter. Although much attention has been devoted to the role of bots and other highly active users in spreading misinformation, the majority of Twitter users remain \u201ccasual\u201d observers with limited active engagement in crises. This paper investigates the communication strategies of these casual observers concerning the war in Ukraine, focusing on their propensity to share misinformation. Drawing on an analysis of 117 million tweets, the findings indicate casual users are less likely to disseminate links to misinformation sources. This observation underscores the potential of low-activity users to act as a stabilizing force in public discourse, mitigating the spread of false narratives and promoting more accurate information during times of crisis. By shedding light on the role of casual observers in shaping public discourse, this ESSACHESS \u2013  Journal for Communication Studies Volume 16 Issue 1(31), p. 115-134 \u00a9 The Author(s) 2023 Reprints and Permission:  \u00d3 ESSACHESS  https://www.essachess.com/ DOI: 10.21409/essachess.1775-352x The Casual Observer: Low-Activity Twitter Users as Arbiters of (Mis)Information in the War in Ukraine \nROBINSON           \n 116  \n research contributes to a more comprehensive understanding of crisis communication and highlights the need for a nuanced examination of information sharing dynamics on social media platforms. Keywords: armed conflict, social media, engagement, user types, misinformation, Twitter *** L'observateur habituel. Les utilisateurs de Twitter \u00e0 faible activit\u00e9 comme arbitres des (fausses) informations dans la guerre en Ukraine R\u00e9sum\u00e9: La propagation de la d\u00e9sinformation \u00e0 l'\u00e8re num\u00e9rique est devenue une pr\u00e9occupation importante, en particulier en p\u00e9riode de crise et de conflit. Dans le contexte de la guerre en cours en Ukraine, un r\u00e9seau d'acteurs - dont des responsables gouvernementaux, des journalistes, des militants et des citoyens ordinaires - participe \u00e0 l'\u00e9laboration du discours public sur des plateformes telles que Twitter. Bien qu'une grande attention ait \u00e9t\u00e9 accord\u00e9e au r\u00f4le des bots et d'autres utilisateurs tr\u00e8s actifs dans la diffusion de fausses informations, la majorit\u00e9 des utilisateurs de Twitter restent des observateurs \"occasionnels\" avec un engagement actif limit\u00e9 dans les crises. Cet article \u00e9tudie les strat\u00e9gies de communication de ces observateurs occasionnels concernant la guerre en Ukraine, en se concentrant sur leur propension \u00e0 partager des informations erron\u00e9es. S'appuyant sur une analyse de 117 millions de tweets, les r\u00e9sultats indiquent que les utilisateurs occasionnels sont moins susceptibles de diffuser des liens vers des sources de d\u00e9sinformation. Cette observation souligne le potentiel des utilisateurs \u00e0 faible activit\u00e9 \u00e0 agir comme une force stabilisatrice dans le discours public, en att\u00e9nuant la propagation de faux r\u00e9cits et en promouvant des informations plus pr\u00e9cises en temps de crise. En mettant en lumi\u00e8re le r\u00f4le des observateurs occasionnels dans la formation du discours public, cette recherche contribue \u00e0 une compr\u00e9hension plus compl\u00e8te de la communication de crise et souligne la n\u00e9cessit\u00e9 d'un examen nuanc\u00e9 de la dynamique de partage d'informations sur les plateformes de m\u00e9dias sociaux. Mots-cl\u00e9s: conflit arm\u00e9, m\u00e9dias sociaux, engagement, types d'utilisateurs, d\u00e9sinformation, Twitter *** Introduction Russia\u2019s 2022 invasion of Ukraine has been called \u201cthe most documented war in human history\u201d (Johnson, 2022). Images, news articles, military announcements, and social media posts from the ground circulate through virtual information channels in what Hoskins and Shchelin (2023) have called the continuous \u201cwar feed.\u201d Among the most global of these channels is the platform Twitter, which was early on incorporated into the war effort by both Ukraine and its allies and by the Kremlin (Snowden, 2022). Yet, attention is not evenly distributed: most Twitter users do not actively engage with content related to the war in Ukraine. Previous social media research primarily \n \n 117 ESSACHESS vol. 16, no. 1(31) / 2023          focuses on the behaviour and impact of highly active users (Bakshy et al., 2015; Makhortykh & Sydorova, 2017; Vosoughi et al., 2018), even excluding the least active users during the data cleaning process (e.g. Guo et al., 2020; Hagen et al., 2018; Sadri et al., 2018). In an age in which publics are constantly connected to crisis and conflict through the \u201cresidual awareness\u201d provided by media (Hoskins & O\u2019Loughlin, 2010, p. 2), it is argued here that studying communication patterns among the less actively engaged provides a useful window into the experience of mediated war and crisis communication, and potentially helps explain how and why certain information proliferates. This paper thus explores the communicative patterns of low-activity Twitter users, described as \u201ccasual users,\u201d discussing the war in Ukraine. The idea of the casual observer draws on public relations research by James E. Grunig\u2019s (2005) situational theory of publics, as well as public opinion research (Converse, 2006 [1964]). This paper suggests that research should consider the role of low-activity users in public discourse around crises, as these users constitute a large portion of the overall social media user base and their engagement with misinformation may be more representative of the general public (Wojcik & Hughes, 2019). The paper puts a particular focus on sharing of misinformation. Misinformation has been a significant concern on social media platforms, particularly in the context of political conflicts (Allcott & Gentzkow, 2017; Lewandowsky et al., 2017; Wardle & Derakhshan, 2017), and has raised particular concerns around the war in Ukraine (Hoskins & Shchelin, 2023; Pierri et al., 2022).  The paper uses empirical material from the first 150 days of the 2022 Russia\u2013Ukraine conflict collected from Twitter\u2019s global live streaming API between Feb. 25 and July 24, 2022, totalling a data collection of 117 million tweets. This collection includes tweets that may have since been deleted as part of Twitter\u2019s censorship efforts. Casual users are defined in this paper as those who only appear once in the data. Using big data parsing techniques, these users are identified, and their tweeting patterns are compared to more active users in the data. Sources of misinformation are based on the classifications by Media Bias/Fact Check (MB/FC), as demonstrated by Pierri et al. (2022).  The results show that casual observers represent half the users in the global data. Moreover, casual users tend to be more active than previous research might suggest (Hargittai et al., 2010; Nielsen, 2006). Rather than taking a follow-the-leader approach to misinformation, they demonstrate distinct misinformation sharing behaviours from the rest of the userbase and overall they are less likely to share links to misinformation sources, even when accounting for rate of tweeting. In addition, the analysis suggests casual users share qualitatively different types of information from these sources. This research suggests that rather than posing a threat to quality information, low-activity users may act as a mitigator in the spread of information during crisis. Understanding the communication practices of these users, it may be \nROBINSON           \n 118  \n possible to develop more effective strategies for reducing the spread of misinformation on social media platforms by targeting casual users. The paper is structured as follows. The following literature review aims to provide an overview of the current state of research on low-activity Twitter users and identify key themes and gaps in the field. Four hypotheses and two research questions are proposed. The empirical data and methodological approach are then described, followed by the findings of these analyses. Finally, the findings are discussed in relation to the existing literature and the limitations of this study, and lines of future research are described.  1. Theoretical Perspectives There is debate over whether social media increases awareness of armed conflicts. Some scholars argue that social media can contribute to an increase in awareness of armed conflicts by providing real-time access to information from conflict zones, which can include both official statements and citizen-generated content (Makhortykh & Gonz\u00e1lez Aguilar, 2020; Zeitzoff, 2017). This can lead to a greater sense of proximity to the conflict and a greater emotional impact on the audience. Additionally, social media has allowed for a more decentralized dissemination of information about conflicts, which can include a greater diversity of voices and perspectives, including those describing the human impact of the conflict (Chouliaraki, 2015). On the other hand, the vast amount of information available can make it difficult for people to focus on the most important events. For example, in a study of Twitter in the Syrian Civil War, Lynch et al. (2014) warn that social media can create the \u201cdangerous illusion\u201d of having comprehensive information about a conflict, when in fact the information is heavily curated by different actors, algorithms, and network dynamics (p. 5). Other research finds social media is also used to spread polarizing and propagandistic messages (Makhortykh & Sydorova, 2017), which can make it difficult for people to sort out accurate information from misinformation (Hoskins, 2021; Hoskins & Shchelin, 2023). The following sections look more closely at levels of engagement with issues, social media activity, and the relationship to misinformation. 1.1. Publics and their Varying Levels of Attention The variability in people\u2019s engagement with different issues is a well-documented phenomenon in the study of public opinion. The public opinion researcher Philip Converse (1964) argued that voters not only have varying points of view but varying strengths of opinion, such that a voter may express an opinion on an issue when asked by a pollster, but otherwise that issue may not be very important to the voter. \u201cDifferent controversies excite different people,\u201d Converse explained (p. 53). \n \n 119 ESSACHESS vol. 16, no. 1(31) / 2023          Converse was influential in what has become known as \u201cissue publics,\u201d referring to the portion of the public that pays attention to a particular issue. Public relations scholar Grunig (1997) further distinguished between different forms of issue publics Situational Theory of Publics. These include all-issue publics, or those interested in a wide range of problems; apathetic publics, which are generally inattentive to all problems; single-issue publics, which are focused on one subset of problems; and hot-issue publics, which arise around crises in the media (p. 13). As the name suggests, hot-issue publics dissipate once the media moves on to other topics (Aldoory & Grunig, 2012). Even within hot-issue publics, Luoma-aho and Vos (2010) argue that there are active and passive actors \u2013 those \u201con the stage\u201d and those \u201cin the audience\u201d (p. 324). Yet those in the audience are still listening. Research tends to highlight the most politically active members of publics, as they tend to be those who are most knowledgeable and/or most affected by an issue (Grunig, 1997;  Luoma-aho & Vos, 2010). These individuals tend to have a deeper understanding of current events and a more nuanced perspective on them (Delli Carpini & Keeter, 1996), making them influential opinion leaders that help less engaged citizens understand current events (Katz & Lazarsfeld, 2017 [1955]). In contrast, scholars have at times been critical of passive actors (Putnam, 2001; Prior, 2005). Yet more research has been reconsidering, or nuancing, this view of passivity. For example, from the perspective of democratic theory, Ekman and Amn\u00e5 (2012) have theorized \u201clatent\u201d engagement, which they argue is different from political disengagement. Latent engagement is engagement of attention \u2013 taking an interest in a topic, for example. Latent engagement does not rise to the level of more visible forms of political participation or activism, but Ekman and Amn\u00e5 argue it is a necessary precursor to these (p. 293). Moreover, Luoma-aho and Vos (2010) argue that public attention to topics varies over time. \u201cWhen a fierce debate is going on in one arena, it may attract more players on the stage and also a bigger passive audience,\u201d they write (p. 321). Such temporal shifts have become easier to track on social media sites, as will be discussed in the following section. 1.2. Social Media Publics and their Varying Levels of Activity The age of social media and Big Data has provided new means of tracking engagement with issues. Drawing on Converse\u2019s concept, Bruns and Burgess (2011) have proposed that Twitter can be seen as a series of \u201cissue publics,\u201d made up of people engaged in particular issues, whether sports, politics, television, or music. These publics are able to be tracked and visualized through the digital traces \u2013 their tweets, @mentions, and use of #hashtags. In the area of strategic communication, Hellsten et al. (2019) examine \u201cissue arenas\u201d on Twitter, drawing on Luoma-aho and Vos\u2019s theory. They distinguish between active and passive stakeholders in these \nROBINSON           \n 120  \n arenas through forms of activity on the platform, finding that peaks of attention also increase attention among passive stakeholders (p. 42). Such research, however, is heavily reliant on the most active participants. In Hellsten et al.\u2019s definition, for example, passive stakeholders are identifiable only through the tweets of the active stakeholders (p. 40). This is to be expected because it is by definition the active users that provide more digital trace data. Yet there has been significant speculation about what are sometimes called social media \u201clurkers,\u201d the silent majority of electronic fora. One of the oft-cited rules of thumb about social media is the \u201c90-9-1 rule,\u201d referring to the concept that 90% of users never post, 9% post a little, and 1% of users post a lot (Nielsen, 2006). (This oft-cited rule does not appear to have been amended since its development, perhaps a sign of the dearth of research.) Some research has gotten at the phenomenon through other means, such as qualitative interviews and opinion polling. For example, a 2019 Pew survey of Americans with Twitter accounts found that 10% of users contribute 80% of the tweets (Wojcik & Hughes, 2019). These highly active users were more likely to be women, and posted more about politics (p. 3). Some researchers have found that low-activity users tend to be more interested in Twitter as an entertainment medium, which could suggest that they are less informed in civic affairs issues (McClain et al., 2021).  On the other hand, low-activity users may also see following the discussions of others as a form of participation. In a literature review, Sun et al. (2014) found that among the reasons low-activity users don\u2019t post are that they were looking for information (p. 114). In analyses of temporal Twitter patterns, Bruns and Stieglitz (2013) found that immediately following a crisis, lower activity users contribute a large portion of  tweets, but high-activity users are more responsible for the daily ebbs and flows of discussion around a topic (p. 101). While activity should not be confused with influence in online communities (Gr\u010dar et al., 2017; Razis & Anagnostopoulos, 2014), survey data does suggest that high activity users also have higher follower counts, and get more engagement than the average user (Wojcik & Hughes, 2019). Moreover, as found by Karlsen (2015), opinion leaders in social media spaces tend to be those who are actively engaged with politicians and parties. In addition, particularly with regard to foreign affairs, public opinion research in the United States has found that the public tends to be especially reliant on opinion leaders for understanding of the issues (Cavari & Freedman, 2019; Hayes & Guardino, 2011; Golby et al., 2018). With these previous findings in mind, the following hypotheses are proposed. First (Ha), casual users will engage in what Kalnes et al. (2017) have identified as more passive forms of information redistribution, such as retweeting other users and tweeting stories directly from media websites (as indicated by \u201cvia\u201d markers in tweets), as opposed to more active forms of engagement such as @mentioning, \n \n 121 ESSACHESS vol. 16, no. 1(31) / 2023          @replying, and tweeting original commentary. Second, (Hb) casual users will be particularly active during major points in the conflict, but (Hc) will generally follow the same peaks as more active users. Although as noted by Luoma-aho and Vos (201), users may exhibit different degrees of influence in different issue arenas, the fourth hypothesis (Hd) is that casual users will have a lower follower count, reflecting that they are less likely to be opinion leaders. In the follow section, I will further examine the issue of misinformation sharing in relation to low-activity users.  1.3. Misinformation As the internet and social media continue to permeate daily life, concerns have arisen about the potential decline in political knowledge due to the prominence of entertainment and sports content over political and civic affairs (Lewandowsky et al., 2017; Prior, 2005). This shift could increase susceptibility to conspiracy theories and misinformation, especially in the context of social media platforms where bots can exacerbate the spread of false narratives (Shao et al., 2018). On the other hand, social media may facilitate passive engagement with the news, exposing users to current affairs through incidental encounters (Fletcher & Nielsen, 2018), and reinforcing media infrastructures that make personal preferences less of a factor (Haugsgjerd et al., 2021). Importantly, being informed does not necessarily correlate with the level of activity on social media platforms. Hochschild and Einstein (2015a; 2015b) have developed a typology that delineates varying levels of political knowledge and misinformation: the actively informed (engaged and well-informed), the inactively informed (not actively engaged but well-informed), the actively misinformed (actively engaged but ill-informed), and the inactively misinformed (low engagement and low knowledge about an issue). (See Figure 1.) Interestingly, while low engagement with the news generally corresponds to lower levels of political knowledge and a less nuanced understanding of current events (Pennycook & Rand, 2022), research on misinformation sharing often implicates the most politically engaged \u2013 or at least the most politically passionate users (Guess et al., 2018; van der Linden, 2022). Marwick and Lewis (2017) suggest that social media sites are especially susceptible to spreading intentionally and unintentionally false information because of their ability to rapidly connect far-flung communities of people with extreme views. Social media logics also favour highly emotional content, which false information often appeals to (Bakir & McStay, 2018; Vosoughi et al., 2018). Scholarship has often connected misinformation sharing to echo chambers containing adamant political believers (Del Vicario et al., 2015; Valenzuela et al., 2019). As noted by Hochschild and Einstein, it is the actively disinformed who have attracted particular attention, being in internet jargon, \u201cloud wrong.\u201d   \nROBINSON           \n 122  \n    Level of engagement   Low High Level of knowledge Low Inactively misinformed Actively misinformed High Inactively informed Actively informed Figure 1. Informed\u2013engaged typology (as described in Hochschild & Einstein, 2015a; 2015b) However, as noted by Allcott and Gentzkow (2017), these are minority of social media users and the general public overall. As described above, most Twitter users are in the silent, or relatively silent, majority (McClain et al., 2021; Wojcik & Hughes, 2019). There is limited research that directly addresses the left side of Horchschild and Einstein\u2019s typology: that is, the \u201clow\u201d engagement side, and the question of whether low-activity Twitter users are less informed than more active users. Some research would suggest low activity users may have less developed networks and digital literacy skills, and therefore are more susceptible to misinformation (Hargittai, et al. 2010), while other research provides evidence that \u201clay\u201d people can contribute significantly to mitigating misinformation (Pennycook & Rand, 2019). By examining the online behavior of casual observers, we can better understand the dynamics of misinformation spread on Twitter and develop more effective strategies to promote accurate information sharing across diverse user groups (Lewandowsky et al., 2017). Thus, I propose two final research questions. First (RQ1), are casual users more susceptible to misinformation sharing? Additionally, I propose the following qualitative research question (RQ2): In what way does information sharing differ among casual users from the rest of the userbase? This question will be answered using time series analysis and qualitative examination of important tweets. In the next section, I discuss the data and methods used to approach these five hypotheses and one research question.  2. Data and Methods The methods section of this academic research article describes the process used to collect and analyse big data from Twitter in relation to the war in Ukraine in 2022. The data used in this study consisted of 117 million tweets collected from Twitter in real-time using the keywords \u201cukraine\u201d and \u201ckyiv\u201d. Collections were made using the DMI-TCAT, a tool designed for the digital humanities by at the University of Amsterdam (Borra & Rieder, 2014). Following collection, the tweets were loaded into Google BigQuery for further analysis. \n \n 123 ESSACHESS vol. 16, no. 1(31) / 2023          To begin the analysis, low-activity or \u201ccasual\u201d users were first identified. Casual users were defined as those who had tweeted only 1 time during the collection period. This separation of users allowed for a comparison of the behaviour and characteristics of casual users in relation to the war in Ukraine. Next, the tweets were analysed in Google BigQuery using SQL queries. The queries were designed to identify users who had shared misinformation sources, as well as those who had not. The misinformation sources were defined according to the classifications of Media Bias/Fact Check (MB/FC), which is a website that rates the accuracy and bias of news sources (Van Zandt, 2022). Drawing on Pierri et al. (2022), a list of what are classified as \u201clow credibility\u201d sources was compiled; these include what Van Zandt calls questionable sources and conspiracy-pseudoscience sources. A list of 378 misinformation sources and their associated domains was compiled from MB/FC manually. URLs and domains within the tweets were then extracted using built-in tools of the DMI-TCAT in combination with Regex extractions. The top-level domains of the URLs were then compared to the list of misinformation sources. Several measures were used to assess the engagement level of users, in addition to the number of tweets about Ukraine found in the data. These measures are available as metadata in each tweet. For each user, this data is gathered from their last available tweet in the data. - follower count: number of accounts who follow a user - followee count: number of accounts the user follows - verified: whether the user has been verified, a demarcation Twitter previously used to identify public figures, official governmental and organizational accounts, celebrities, and journalists (note that the data pre-dates the subscription-based verification program Twitter Blue) - lifetime tweet count: number of tweets the user has sent (tweets deleted by the user will be deducted from this count) - profile creation date: date that the user set up their Twitter account Since users who have been on Twitter longer will have had more opportunities to tweet, lifetime tweet count may vary based on the age of the Twitter account. To standardize the lifetime tweet count, a measure called daily tweet rate is calculated by dividing lifetime tweet count by the number of days between the profile creation date and the last available tweet in the data. Another aspect of the analysis was to compare the temporal patterns of tweets from casual users to that of the rest of the user base. To do this, time series analysis to identify patterns in the frequency and timing of tweets from casual users was compared to the rest of the user base. Tweeting \u201cpeaks\u201d were defined as those days in which tweet volume was at the 80th percentile or higher; in order to account for the \nROBINSON           \n 124  \n fact that tweeting was higher at the start of the war than in later months, this percentile was calculated separately for February\u2013March, and then April\u2013July. This analysis helped nuance the picture of how casual users engage with social media during a crisis, and how their behaviour compares to that of more active users.  3. Findings The findings from this study address four hypotheses and two research questions. Before establishing the evidence for or against the hypotheses, a general assessment of the data was made to provide a general overview. It was found that casual users, meaning those who only appear once in the data, make up 49.5% of the userbase (4,962,233 users out of 10,020,547), and produced 4.2% of the total tweets (4,962,233 tweets out of 117,144,527). These users provide a general basis for hypothesis testing. In addition, the most prominent online domains shared in tweets were found to be dominated by major English language news outlets. The top domains in order of proportion of shares were YouTube (11% of tweets with URLs), Reuters (5%), the New York Times (5%), the BBC (4%), the Guardian (3.8%), the Washington Post (3.1%), CNN (2.8%), Telegram (2.5%), the Wall Street Journal (1.6%), and the Associated Press (1.4%).  Table 1. Forms of tweeting  Tweet type (proportion)  Active/Interactive  Passive  mention comment, no mention reply  retweet via Non Casual Users 0.01 0.10 0.10  0.77 0.01        Casual Users 0.02 0.13 0.15  0.69 0.01    \n \n 125 ESSACHESS vol. 16, no. 1(31) / 2023          Table 2. Forms of misinformation tweeting   Misinformation sharing : Tweet type (proportion)  Active/Interactive  Passive  mention comment, no mention reply  retweet via Non Casual Users 0.01 0.25 0.03  0.66 0.04        Casual Users 0.01 0.25 0.02  0.68 0.05   3.1. Statistical Analysis Regarding the first hypothesis (Ha), casual users were not found to engage in more passive forms of information exchange, such as retweeting and tweeting directly from media websites, meaning the hypothesis was not supported. As seen in Table 1, casual users were more likely to @mention and @reply to other users, as well as send out original commentary. They had proportionally fewer retweets and \u201cvia\u201d tweets direct from news sites. However, casual users who shared misinformation are less likely to engage in political exchange and more likely to share information passively (Table 2). These differences suggest that casual users may be less politically engaged and more focused on receiving information, rather than actively participating in the conversation. Regarding hypothesis Hb, the findings show that casual users were indeed particularly active during major points in the conflict. For example, the number of tweets from casual users spiked during the initial invasion, during President Zelensky\u2019s address to the German Parliament (March 17), and Russia\u2019s retreat from the city of Kharkiv (May 14). This suggests that casual users may be paying closer attention to the conflict during moments of heightened violence and/or media attention. Hypothesis Hc was also supported by the findings, as casual users were found to exhibit the same peaks as more active users (see Figure 2). This indicates that, despite their low engagement, casual users may still be following the same news cycles and trends as more active users. Moreover, a manual analysis of the peak days (see below) indicates the most-shared content was nearly identical between casual and non-casual users. The fourth hypothesis (Hd) was also supported by the data, as casual users had a lower overall follower count (Mdn = 72; M = 1,337; SD = 76,537) compared with non-casual users (Mdn = 155; M = 3,073; SD = 144,728). This suggests that even on \nROBINSON           \n 126  \n other topics casual observers of the war may have less influence on other users through the information they share. In answer to the first research question (RQ1), initial observations suggest that casual users are not more susceptible to misinformation sharing. Of the 10,020,547 total users in the data, 321,806 (or 3.2%) shared links to misinformation sources; however, only 19,624 of the misinformation sharers are casual users (out of 4,962,233 total casual users. In other words, only 0.39% of casual users shared misinformation. However, casual users by definition share fewer tweets in general, so this lower proportion could be due to their general lower levels of activity. A logistic regression was performed on a random sample of users (n = 200,000) to assess the effect of activity measures on the likelihood that users would share misinformation sources. Before running the analysis, predictor variables were assessed for multilinearity and linearity with the logit. The correlation coefficients between the predictor variables were all under the recommended threshold of 0.7 and variance inflation factor (VIF) values were all close to 1, indicating low collinearity between variables (Field, 2013, p. 325). After examining scatterplots and conducting a Box-Tidwell test, it was determined that some of the continuous predictor variables exhibited nonlinearity in their relationship with the logit. To address this issue and improve the model's performance, these continuous predictor variables were transformed by taking the natural log. This transformation helped linearize the relationship between the predictor variables and the logit of the outcome variable.   Table 3. Relationship between activity and misinformation sharing \n  \n\n \n 127 ESSACHESS vol. 16, no. 1(31) / 2023          The logistic regression model was statistically significant, \u03c72(6) = 17094.15, p < .001. (See Table 3.) The strongest predictor was being verified: \u201cblue check\u201d users were less likely to share misinformation. Being a casual user also decreased the likelihood. In fact, more active users \u2013 as judged by tweet rate and the number of tweets in the data about the war in Ukraine \u2013 appear to be more likely to share misinformation sources. All this suggests that non-verified active users were most likely to share misinformation sources. However, the model has very low sensitivity, successfully identifying only 14.3% of the misinformation sharers. Overall, the results suggest that user activity level is not a good predictor of misinformation sharing. 3.2. Qualitative Analysis of Misinformation Tweeting Finally, addressing the second research question (RQ2), information sharing among casual users differs from the rest of the userbase in several ways. First, the time series analysis, shown in Figure 2, indicates that while casual users generally followed the same patterns as more active users, casual users\u2019 patterns were markedly different from non-casual users\u2019 misinformation sharing patterns. This can be seen in Figure 2 in the differences between the blue top row (casual users) and the orange top row (non-casual users). A qualitative analysis of the top tweets sharing misinformation sources suggests not only temporal, but also thematic differences between user types. Here I provide a narrative. In the first days of the conflict (Feb. 27-28), non-casual users\u2019 most common tweets sharing misinformation sources have to do with U.S. President Joe Biden\u2019s handling of the conflict. Casual users do not focus on this, but on general updates about action on the ground. This changes during a peak from March 10-12, when casual users share information about the removal of an Oliver Stone documentary from YouTube. This is also important among non-casual users, but so is a claim that \u201cdeleted webpages\u201d show Obama led effort to build biolabs in Ukraine. Later on May 2-5, the casual users share a tweet from @rebeccagrantdc (a Fox News analyst) critical of Pakistan\u2019s relationship with Russia. The non-casual users pay relatively little attention to this: instead, they focus on a Tucker Carlson tweet critical of Biden\u2019s support for Ukraine, and a tweet from Russia Today claiming that the Pope blames NATO for the war. Overall, the most popular content among the two groups is a tweet about the Oliver Stone documentary that links to Rumble.com, a Canadian website rated as \u201cQuestionable\u201d by MB/FC. However, casual users tend to favour content that could be characterized as opinion-based, such as the tweet from the Fox News contributor, while non-casual users favour content about hidden motives and other conspiratorial factors behind the war, particularly by President Biden and President Obama.   \nROBINSON           \n 128  \n  Figure 2. Time series data 4. Discussion The role of social media in armed conflict and political crisis is a topic of debate among scholars (Chouliaraki, 2015; Hoskins & Shchelin, 2023; Makhortykh & Gonz\u00e1lez Aguilar, 2020; Zeitzoff, 2017). On one hand, social media provides real-time access to information from combat zones, allowing for a greater sense of proximity and emotional impact on the audience. Yet on the other, the vast amount of information available on social media can also make it difficult for people to focus on the most important events and can lead to the spread of misinformation and propaganda. This analysis has sought to understand the \u201ccasual observer\u201d of war \u2013 that is, the user who represents the silent (or nearly silent) majority of social media users. Admittedly, this is an unconventional approach to studying crisis communication on social media. Much of the previous research has focused on opinion leaders, stakeholders, and organizations in particular issue arenas. However, it is suggested that understanding low-activity users is necessary to understanding the greater information ecosystem, and combatting misinformation in what Hoskins and O\u2019Loughlin (2010) have called the current state of \u201cdiffused war.\u201d  Overall, the findings show that casual users tend to engage in more interactive forms of tweeting, such as @mentions and replies, indicating a more engaged and active approach to the conflict than might be expected. This contradicts the first \n\n \n 129 ESSACHESS vol. 16, no. 1(31) / 2023          hypothesis (Ha) that casual users will be more passive, and suggests that casual users are not simply inactive recipients of information, but rather active participants in the conversation on the war in Ukraine. This is indirectly supported by previous research that suggests low-activity users may have different perceptions of how they are participating that doesn\u2019t conform to the demand that engagement equals posting (Ekman & Amn\u00e5, 2012; Sun et al., 2014). The analysis also showed that casual users had lower follower counts, indicating that they are not opinion leaders according to the usual metrics. This supports the fourth hypothesis (Hd). However, this finding should be viewed with caution, as other factors such as network structure, information diffusion patterns, and overall influence in the Twitter community may also play a role in determining influence in a particular issue arena (Dubois & Gaffney, 2014; Hellsten et al., 2019; Razis & Anagnostopoulos, 2014). The findings also suggest that casual users were not more susceptible to misinformation sharing (RQ1) with a low proportion of the tweets from casual users containing misinformation; a regression analysis further demonstrated that casual users were had less likelihood of sharing questionable sources, even when accounting for the users\u2019 lower activity levels. This finding is important in light of concerns about the spread of misinformation on social media during conflicts, as it supports the idea that low-activity users \u2013 that is, most users \u2013 are not especially susceptible to misinformation. The findings could be interpreted as supporting previous research that suggests highly active partisans may be more politically motivated in what they share (Allcott & Gentzkow, 2017; Hochschild & Einstein, 2015; see van der Linden, 2022, for a discussion on the \u201cmotivated reasoning\u201d vs. \u201cinattention\u201d theses). However, the analysis here shows an additional dimension. Much like Tolstoy\u2019s quip that \u201cevery unhappy family is unhappy in its own way,\u201d the findings here suggest that casual users are misinformation sharers in their own way, while non-misinformation sharing generally followed the same pattern regardless of user type (Figure 2). In particular, casual users appeared to be more interested in opinion-based content than conspiracy content. This finding is important as it highlights the diversity of information sharing behaviours on Twitter, and suggests that different groups of users may have different motivations and approaches to information exchange. Hochschild and Einstein (2015b) have suggested that the actively misinformed are hard minds to change (p. 472). It may be that the inactively (or less-actively) misinformed arrive at misinformation with different motivations. This could have implications for policy makers and media organizations seeking to curb the spread of mis- and disinformation, particularly in the context of sensitive and complex issues like the war in Ukraine. Policymakers and media organizations need to engage with casual users, providing them with accurate and reliable information and helping them develop the \nROBINSON           \n 130  \n skills necessary to critically evaluate the information they come across on social media platforms.  Conclusion This study provides a deeper understanding of the behaviour of low-activity \u201ccasual\u201d users on Twitter during first 150 days of Russia\u2019s invasion of Ukraine. The findings suggest that casual users tend to engage in more interactive forms of tweeting, are not more susceptible to misinformation sharing, have lower follower counts, and have distinct misinformation sharing behaviours from the rest of the userbase. The findings contribute to the broader literature on social media use and user behaviour, particularly in the context of crisis. The results highlight the importance of considering the different ways in which information is being shared and consumed by different types of users, and their different needs and interests. One challenge with this study is that the low-activity users do meet a certain threshold of activity, a necessity for them to be studied using computational methods. In other words, they are not truly \u201clurkers\u201d or \u201cinattentive\u201d users (Sun et al., 2014; van der Linden, 2022). Future research can build upon these findings by exploring motivations and experiences of low-activity users \u2013 including those who never post \u2013 through other means, such as qualitative interviews or surveys. Additionally, this study imposes an artificial threshold to separate casual users from the other users; it would be worth considering gradients of user activity in future research. Studies might for example consider the interplay between low-, medium-, and high-activity users, including on other platforms. Overall, the findings here suggest there is not as much of a follow-the-leader pattern as might be expected, paving the way for novel research trajectories on the mechanisms through which individuals encounter both accurate and misleading information in digital networks.  Acknowledgements Thank you to the members of Centre for the Study of Political Communication (POLKOM) at the University of Oslo for their valuable feedback in the early stages of this work, and to Sahar Hassani for advising on parts of the analysis.  References Aldoory, L., & Grunig, J. E. (2012, 2012/01/01). The rise and fall of hot-issue publics: Relationships that develop from media coverage of events and crises. International Journal of Strategic Communication, 6(1), 93-108. https://doi.org/10.1080/1553118X.2011.634866  Allcott, H., & Gentzkow, M. (2017). Social media and fake news in the 2016 election. Journal of economic perspectives, 31(2), 211-236.  \n \n 131 ESSACHESS vol. 16, no. 1(31) / 2023          Bakir, V., & McStay, A. (2018). Fake news and the economy of emotions. Digital Journalism, 6(2), 154-175. https://doi.org/10.1080/21670811.2017.1345645  Bakshy, E., Messing, S., & Adamic, L. A. (2015). Exposure to ideologically diverse news and opinion on Facebook. Science, 348(6239), 1130-1132. https://doi.org/10.1126/science.aaa1160  Borra, E., & Rieder, B. (2014). Programmed method: Developing a toolset for capturing and analyzing tweets. Aslib Journal of Information Management, 66(3), 262-278. https://doi.org/10.1108/AJIM-09-2013-0094  Bruns, A., & Burgess, J. E. (2011). The use of Twitter hashtags in the formation of ad hoc publics. Proceedings of the 6th European Consortium for Political Research (ECPR) General Conference 2011. Bruns, A., & Stieglitz, S. (2013). Towards more systematic Twitter analysis: Metrics for tweeting activities. International Journal of Social Research Methodology, 16(2), 91-108. https://doi.org/10.1080/13645579.2012.756095  Cavari, A., & Freedman, G. (2019). Partisan cues and opinion formation on foreign policy. American Politics Research, 47(1), 29-57.  Chouliaraki, L. (2015). Digital witnessing in war journalism: The case of post-Arab Spring conflicts. Popular Communication, 13(2), 105-119. https://doi.org/10.1080/15405702.2015.1021467  Converse, P. E. (2006 [1964]). The nature of belief systems in mass publics (1964). Critical Review, 18(1-3), 1-74. https://doi.org/10.1080/08913810608443650  Del Vicario, M., Bessi, A., Zollo, F., Petroni, F., Scala, A., Caldarelli, G., Stanley, H. E., & Quattrociocchi, W. (2016). The spreading of misinformation online. Proceedings of the National Academy of Sciences, 113(3), 554-559. https://doi.org/10.1073/pnas.1517441113  Ekman, J., & Amn\u00e5, E. (2012). Political participation and civic engagement: Towards a new typology. Human affairs, 22, 283-300. https://doi.org/10.2478/s13374-012-0024-1 Field, A. (2013). Discovering statistics using IBM SPSS statistics. Sage.  Fletcher, R., & Nielsen, R. K. (2018). Are people incidentally exposed to news on social media? A comparative analysis. New Media & Society, 20(7), 2450-2468. https://doi.org/10.1177/1461444817724170  Golby, J., Feaver, P., & Dropp, K. (2018). Elite military cues and public opinion about the use of military force. Armed Forces & Society, 44(1), 44-71. https://doi.org/10.1177/0095327X16687 Gr\u010dar, M., Cherepnalkoski, D., Mozeti\u010d, I., & Kralj Novak, P. (2017). Stance and influence of Twitter users regarding the Brexit referendum. Computational Social Networks, 4(1), 6. https://doi.org/10.1186/s40649-017-0042-6  Grunig, J. (2005). Situational theory of publics. In R. L. Heath (Ed.), Encyclopedia of public relations (Vol. 2, pp. 778-780).  Grunig, J. E. (1997). A situational theory of publics: Conceptual history, recent challenges and new research. Public relations research: An international perspective, 3, 48.  \nROBINSON           \n 132  \n Guess, A., Nyhan, B., & Reifler, J. (2018, Jan. 8). Selective exposure to misinformation: Evidence from the consumption of fake news during the 2016 us presidential campaign [Report]. Dartmouth College. https://apo.org.au/node/126961 Guo, L., A. Rohde, J., & Wu, H. D. (2020). Who is responsible for twitter\u2019s echo chamber problem? Evidence from 2016 U.S. Election networks. Information, Communication & Society, 23(2), 234-251. https://doi.org/10.1080/1369118X.2018.1499793  Hagen, L., Keller, T., Neely, S., DePaula, N., & Robert-Cooperman, C. (2018, Oct). Crisis communications in the age of social media: A network analysis of Zika-related tweets. Social Science Computer Review, 36(5), 523-541. https://doi.org/10.1177/0894439317721985  Hargittai, E., Fullerton, L., Menchen-Trevino, E., & Thomas, K. Y. (2010). Trust online: Young adults' evaluation of web content (Vol. 4). https://ijoc.org/index.php/ijoc/article/view/636  Haugsgjerd, A., Hesstvedt, S., & Karlsen, R. (2021). Increased media choice and political knowledge gaps: A comparative longitudinal study of 18 established democracies 1995-2015. Political Communication, 38(6), 731-750. https://doi.org/10.1080/10584609.2020.1868633  Hayes, D., & Guardino, M. (2011). The influence of foreign voices on U.S. Public opinion. American Journal of Political Science, 55(4), 831-851. https://doi.org/10.1111/j.1540-5907.2011.00523.x  Hellsten, I., Jacobs, S., & Wonneberger, A. (2019, Mar). Active and passive stakeholders in issue arenas: A communication network approach to the bird flu debate on Twitter. Public Relations Review, 45(1), 35-48. https://doi.org/10.1016/j.pubrev.2018.12.009  Hochschild, J., & Einstein, K. L. (2015). \u2018It isn\u2019t what we don\u2019t know that gives us trouble, it\u2019s what we know that ain\u2019t so\u2019: Misinformation and democratic politics. British Journal of Political Science, 45(3), 467-475.  Hochschild, J. L., & Einstein, K. L. (2015). Do facts matter? Information and misinformation in American politics. Political Science Quarterly, 130(4), 585-624.  Hoskins, A. (2021). Digital war. In L. Chouliaraki & A. Vestergaard (Eds.), Routledge handbook of humanitarian communication (pp. 66-87). https://doi.org/10.4324/9781315363493  Hoskins, A., & O\u2019Loughlin, B. (2010). War and media. Polity.  Hoskins, A., & Shchelin, P. (2023). The war feed: Digital war in plain sight. American Behavioral Scientist, 67(3), 449-463. https://doi.org/10.1177/00027642221144848  Johnson, D. (2022, Feb. 24). Ukraine could be the most documented war in human history. Slate Magazine. https://slate.com/technology/2022/02/ukraine-russia-livestream-google-maps.html  Kalsnes, B., Larsson, A. O., & Enli, G. S. (2017, 01/22). The social media logic of political interaction: Exploring citizens\u2019 and politicians\u2019 relationship on Facebook and Twitter. First Monday, 22(2). https://doi.org/10.5210/fm.v22i2.6348  \n \n 133 ESSACHESS vol. 16, no. 1(31) / 2023          Karlsen, R. (2015). Followers are opinion leaders: The role of people in the flow of political communication on and beyond social networking sites. European Journal of Communication, 30(3), 301-318. https://doi.org/10.1177/0267323115577305  Katz, E., & Lazarsfeld, P. F. (2017 [1955]). Personal influence: The part played by people in the flow of mass communications. Routledge. Lewandowsky, S., Ecker, U. K. H., & Cook, J. (2017). Beyond misinformation: Understanding and coping with the \u201cpost-truth\u201d era. Journal of Applied Research in Memory and Cognition, 6(4), 353-369. https://doi.org/10.1016/j.jarmac.2017.07.008  Luoma-aho, V., & Vos, M. (2010). Towards a more dynamic stakeholder model: Acknowledging multiple issue arenas. Corporate Communications: An International Journal, 15(3), 315-331. https://doi.org/10.1108/13563281011068159  Lynch, M., Freelon, D., & Aday, S. (2014). Syria's socially mediated civil war (no. 91). United States Institute of Peace. https://www.usip.org/publications/2014/01/syrias-socially-mediated-civil-war Makhortykh, M., & Gonz\u00e1lez Aguilar, J. M. (2020). Memory, politics and emotions: Internet memes and protests in Venezuela and Ukraine. Continuum, 34(3), 342-362. https://doi.org/10.1080/10304312.2020.1764782  Makhortykh, M., & Sydorova, M. (2017). Social media and visual framing of the conflict in eastern Ukraine. Media, War & Conflict, 10(3), 359-381. https://doi.org/10.1177/1750635217702539  Marwick, A. E., & Lewis, R. (2017). Media manipulation and disinformation online. Data & Society. https://datasociety.net/library/media-manipulation-and-disinfo-online/ McClain, C., Widjaya, R., Rivero, G., & Smith, A. (2021). The behaviors and attitudes of U.S. Adults on Twitter. Pew Research Center. https://www.pewresearch.org/internet/2021/11/15/the-behaviors-and-attitudes-of-u-s-adults-on-twitter Nielsen, J. (2006, Oct. 8). Participation inequality: The 90-9-1 rule for social features. Nielsen Norman Group. https://www.nngroup.com/articles/participation-inequality Pennycook, G., & Rand, D. G. (2019). Fighting misinformation on social media using crowdsourced judgments of news source quality. Proceedings of the National Academy of Sciences, 116(7), 2521-2526. https://doi.org/10.1073/pnas.1806781116  Pennycook, G., & Rand, D. G. (2021). The psychology of fake news. Trends in Cognitive Sciences, 25(5), 388-402. https://doi.org/10.1016/j.tics.2021.02.007  Pierri, F., Luceri, L., Jindal, N., & Ferrara, E. (2022). Propaganda and misinformation on Facebook and Twitter during the Russian invasion of Ukraine. arXiv preprint. https://doi.org/10.48550/arXiv.2212.00419 Prior, M. (2005). News vs. Entertainment: How increasing media choice widens gaps in political knowledge and turnout. American Journal of Political Science, 49(3), 577-592. https://doi.org/10.1111/j.1540-5907.2005.00143.x  Putnam, R. D. (2001). Bowling alone: The collapse and revival of American community. Simon & Schuster.  \nROBINSON           \n 134  \n Razis, G., & Anagnostopoulos, I. (2014). Influencetracker: Rating the impact of a Twitter account. In L. Iliadis, I. Maglogiannis, H. Papadopoulos, S. Sioutas, & C. Makris, Artificial Intelligence Applications and Innovations Berlin, Heidelberg. Sadri, A. M., Hasan, S., Ukkusuri, S. V., & Cebrian, M. (2018). Crisis communication patterns in social media during hurricane sandy. Transportation Research Record, 2672(1), 125-137. https://doi.org/10.1177/0361198118773896  Snowden, C. (2022, April 5). Guns, tanks and Twitter: How Russia and Ukraine are using social media as the war drags on. The Conversation. https://theconversation.com/guns-tanks-and-twitter-how-russia-and-ukraine-are-using-social-media-as-the-war-drags-on-180131 Sun, N., Rau, P. P.-L., & Ma, L. (2014, 2014/09/01/). Understanding lurkers in online communities: A literature review. Computers in Human Behavior, 38, 110-117. https://doi.org/10.1016/j.chb.2014.05.022  Valenzuela, S., Halpern, D., Katz, J. E., & Miranda, J. P. (2019). The paradox of participation versus misinformation: Social media, political engagement, and the spread of misinformation. Digital Journalism, 7(6), 802-823. https://doi.org/10.1080/21670811.2019.1623701  Van der Linden, S. (2022). Misinformation: Susceptibility, spread, and interventions to immunize the public. Nature Medicine, 28(3), 460-467. https://doi.org/10.1038/s41591-022-01713-6  Vosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false news online. Science, 359(6380), 1146-1151. https://doi.org/10.1126/science.aap9559  Wardle, C., & Derakhsha, H. (2017). Information disorder: Toward an interdisciplinary framework for research and policy making. Council of Europe. https://edoc.coe.int/en/media/7495-information-disorder-toward-an-interdisciplinary-framework-for-research-and-policy-making.html Wojcik, S., & Hughes, A. (2019). Sizing up Twitter users. Pew Research Center, 24.  Zandt, D. V. (2022). Filtered search (Media Bias/Fact Check) [Database]. https://mediabiasfactcheck.com/filtered-search/  Zeitzoff, T. (2017). How social media is changing conflict. The Journal of Conflict Resolution, 61(9), 1970-1991. https://doi.org/10.1177/0022002717721392    ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Casual Observer: Low-Activity Twitter Users as Arbiters of (Mis) Information in the War in Ukraine", "author": ["JY Robinson"], "pub_year": "2023", "venue": "ESSACHESS-Journal for Communication Studies", "abstract": "The spread of misinformation in the digital age has become a significant concern, especially  during times of crisis and conflict. In the context of the ongoing war in Ukraine, a web of"}, "filled": false, "gsrank": 799, "pub_url": "https://www.ceeol.com/search/article-detail?id=1179386", "author_id": ["RfAfs1sAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:W-lYPA_R77UJ:scholar.google.com/&output=cite&scirp=798&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D790%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=W-lYPA_R77UJ&ei=lrWsaPi1IL_SieoPzJnloAQ&json=", "num_citations": 2, "citedby_url": "/scholar?cites=13109926903665977691&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:W-lYPA_R77UJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://essachess.com/3/index.php/jcs/article/download/55/55"}}, {"title": "Practical Guidelines for Ideology Detection Pipelines and Psychosocial Applications", "year": "2025", "pdf_data": "Practical Guidelines for Ideology Detection Pipelines and Psychosocial Applications\nRohit Ram1,2, Emma Thomas3, David Kernot4, Marian-Andrei Rizoiu2\n1Thaum\n2University of Technology Sydney\n3Flinders University\n4Defence Science and Technology Group\nrohit@thaum.io,marian-andrei.rizoiu@uts.edu.au,\nemma.thomas@flinders.edu.au,david.kernot@defence.gov.au\nAbstract\nOnline ideology detection is crucial for downstream tasks,\nlike countering ideologically motivated violent extremism and\nmodeling opinion dynamics. However, two significant issues\narise in practitioners\u2019 deployment. Firstly, gold-standard train-\ning data is prohibitively labor-intensive to collect and has\nlimited reusability beyond its collection context (i.e., time,\nlocation, and platform). Secondly, to circumvent expense, re-\nsearchers employ ideological signals (such as hashtags shared).\nUnfortunately, these signals\u2019 annotation requirements and con-\ntext transferability are largely unknown, and the bias they\ninduce remains unquantified. This study provides guidelines\nfor practitioners requiring real-time detection of left, right, and\nextreme ideologies in large-scale online settings. We propose\na framework for pipeline constructions, describing ideology\nsignals by their associated labor and context transferability.\nWe evaluate many constructions, quantifying the bias associ-\nated with signals and describing a pipeline that outperforms\nstate-of-the-art methods ( 0.95 AUC ROC). We showcase the\ncapabilities of our pipeline on five datasets containing more\nthan 1.12 million users. We set out to investigate whether\nthe findings in the psychosocial literature, developed for the\noffline environment, apply to the online setting. We evalu-\nate at scale several psychosocial hypotheses that delineate\nideologies concerning morality, grievance, nationalism, and\ndichotomous thinking. We find that right-wing ideologies use\nmore vice-moral language, have more grievance-filled lan-\nguage, exhibit increased black-and-white thinking patterns,\nand have a greater association with national flags. This re-\nsearch empowers practitioners with guidelines for ideology\ndetection, and case studies for its application, fostering a safer\nand better understood digital landscape.\nCode \u2014 github.com/behavioral-ds/ideology prediction\n1 Introduction\nIdeologies are the collection of beliefs and opinions about\nthe ideal arrangement of society (Cohrs 2012). Tracking ex-\ntreme ideologies is particularly important in detecting ex-\ntreme voices that can spread harmful and false information,\nleading to dangerous and even deadly outcomes. Ideology is\ncanonically (and inexactly) projected onto a left-right spec-\ntrum, where the left is associated with equality and reform,\nCopyright \u00a9 2025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.and the right is associated with authority and tradition. There\nhas been a recent increase in fringe and extreme-leaning\nworldviews, including the far-right \u2013 a prominent archetype\nof extreme ideologies associated with ultranationalism and\nopposition to multiculturalism. Worryingly, this has increased\nIdeologically Motivated Violent Extremism (IMVE) (Carr\net al. 2022) \u2013 a term coined to encompass religious, political\nand nationalist extremism. Ideology detection is a lead indi-\ncator for IMVE, fortifying individual and collective security.\nIt facilitates understanding these ideological groups\u2019 values\nand beliefs, which helps design interventions, build political\nbridges and tackle radicalization.\nRadicalization can occur in a matter of weeks (McCauley\nand Moskalenko 2008; Booth et al. 2024), both offline (face-\nto-face) and online (forums and social media platforms). To\ncombat this, practitioners \u2013 such as law enforcement and\nnational security agencies \u2013 need practical, real-time ideol-\nogy detection tools that minimize human effort and can be\napplied across diverse contexts. Despite the significant ex-\nisting literature, practical and effective detection guidelines\nremain scarce. This study establishes a framework for ideol-\nogy detection pipelines, examining diverse constructions and\ndemonstrating practical implementations using off-the-shelf\ncomponents. Our first aim is to identify practical pipelines\nthat reduce annotation efforts while maintaining transferabil-\nity across different contexts. Our second aim is to validate\ninsights into the psychosocial asymmetries of ideologies. We\nleverage five large datasets, totaling 1.12 million profiles,\nand test several hypotheses from the psychosocial literature\nat scale, mainly developed in offline laboratory setups. We\nanswer two specific research questions.\nThe first question involves ideological proxies \u2013 measur-\nable user behavior signals correlating with \u201ctrue\u201d ideology\n\u2013 that minimize annotation labor and are transferable across\ncontexts. We define a context as the tuple (topic, time, ge-\nography, platform). Prior works rely on various sources of\nideological knowledge, including manually labeling users,\nlabeling ideological proxies, and detecting group behavior\ndifferences. However, these approaches have limitations: the\nformer two require extensive expert labeling \u2013 an expensive\nresource \u2013 and often fail to transfer across contexts. The latter\noften lacks robustness. Of the three, ideological proxies are\nthe most common approach to reducing labor; however, they\nvary in reusability. See Section 2 for a complete discussion.\nProceedings of the Nineteenth International AAAI Conference on Web and Social Media (ICWSM 2025)\n1630\nFurthermore, few users partake in direct ideological activ-\nity, and some actively avoid disclosure. Consequently, many\nproxies reveal only the vocal subset of users, biasing down-\nstream analyses (Alkiek, Zhang, and Jurgens 2022; Cohen\nand Ruths 2013). Despite this, prior works commonly use\nproxies as ground truth (Darwish et al. 2020; Rashed et al.\n2021; Xiao et al. 2020) without quantifying the bias this en-\ntices. Our first research question is: Which ideological prox-\nies minimize annotation labor, maximize context transfer-\nability, and reduce bias?\nThe second question involves the psychosocial asymme-\ntries of ideologies. Understanding the values and beliefs of\nideological groups is instrumental in modeling their polariza-\ntion and user radicalization. Ideological asymmetry studies\nare abundant in relevant disciplines (Tomkins 1963; Jost\n2017); often shown via offline surveys. For example, moral\nvalues delineate left-from-right ideologies (Graham, Haidt,\nand Nosek 2009); and grievance/grudge language delineate\nmoderate-from-extreme ideologies (Stankov 2021; Van der\nVegt et al. 2021). Many of these hypotheses were developed\nwith offline populations, and there is limited evidence for\nonline populations. We know online and offline populations\ndiffer demographically (Auxier and Anderson 2021), but we\ndo not understand their psychosocial differences. We ask\ncan we build psychosocial profiles of ideological groups\nand employ them to evaluate hypotheses related to the\npsychosocial traits of these groups?\nSolution Outline. First, we evaluate ideological proxies. We\nmake the widely adopted assumption that homophily \u2013 the\ntendency of similar individuals to associate \u2013 propagates\nideology. We build a framework to construct ideology de-\ntection pipelines. We qualitatively evaluate proxies, by their\nminimization of labelling efforts and how readily they trans-\nfer to new contexts, and quantitatively evaluate proxies on\ntheir prediction of human-annotated ground truth. We show\nthat a pipeline constructed through a proxy based on media\nconsumption and a lens based on text, is both qualitatively\nadvantageous and quantitatively performant. Second, we use\na pipeline to test hypotheses of the psychosocial asymmetries\nof ideology at scale.\nWe address the first question in Section 4. We introduce our\npipeline framework, consisting of four components: dataset,\nideological proxy, homophilic lens, and inference architec-\nture. We use five social media datasets, collected from three\nplatforms (Parler, Facebook and Twitter), containing 1.12 mil-\nlion users, and spanning social domains such as TV shows,\nelections, climate change, antivaccination and the January\n6th US Capitol Insurrection. We frame the problem as user\nclassification: the left-right detection as ternary classifica-\ntion (left, right, and neutral), and the far-right detection as\nbinary classification. We limit our scope to Anglo-centric,\nEnglish-speaking contexts with a dominant uniaxial political\nspectrum1. We explore four left-right and two far-right ideol-\nogy proxies, leveraging behaviors such as posting politically-\n1This is not to discount the need for ideology detection in other\nregions, like the Global South. Nor to suggest that a uniaxial spec-\ntrum is sufficient to encompass the complex politics of global com-\nmunities. See Section 8 for a discussion.\nDataset Proxies Homophilic Lenses Inference\n#QandA, \n#Ausvotes, \n#Socialsense,\n....Hashtags,\nParty Followers,\nPolitician Endorsers,\nMedia Publication ProxyLexical \n[USE (Cichocka et al. 2016)],\nHashtag [TF-IDF],\nResharing [Multi-hot]LightGBM (Ke et al. 2017)\n#MAGA #OBAMA...\n......\n...Figure 1: The schema conceptualizes the four components\nof the pipeline ; (1) the datasets contain information about\nusers (two examples are shown), (2) the ideological proxies\nassign labels on some of the users based on external informa-\ntion (here #MAGA indicates right-leaning, while #OBAMA\nindicates left-leaning), (3) the homophilic lenses build nu-\nmeric descriptions for user and a way to measure their simi-\nlarity, and (4) inference architecture predicts the likely labels\nof all other users in the dataset.\ncharged hashtags, following political parties, endorsing politi-\ncians, and sharing media websites. We build three homophilic\nlenses based on language, endorsements, and topics. We use\nthe ideology proxies and homophily lenses to build ideology\npipelines with an off-the-shelf classifier. See Fig. 1.\nIn Section 6 we evaluate the performance of ideology de-\ntection pipelines. We construct gold-standard benchmarks for\nleft-right and far-right classification via human annotation\nand use them to evaluate bias introduced by ideological prox-\nies. Furthermore, we assess various combinations of ideology\nproxy and homophilic lens to observe interaction effects and\nfind the best performing combination. Finally, we compare\nthis pipeline to state-of-the-art baselines: TIMME (Xiao et al.\n2020), UUS (Darwish et al. 2020), and UUS+ (Samih and\nDarwish 2021) and achieve the best area-under-the-receiver-\noperating-curve (AUC ROC) of 0.95, an improvement of\n6.7% over the next best, TIMME.\nWe address the second question in Section 7. We evalu-\nate psychosocial hypotheses relating to morality, grievance,\nnationalism, and dichotomous thinking. For morality, we eval-\nuate the seminal Moral Foundations Theory (Graham, Haidt,\nand Nosek 2009) hypotheses, operationalized via FrameAxis\n(Kwak et al. 2021) (see Section 3). In its two subsets of\nhypotheses, individualizing and binding; we find relatively\nmore support for the prior. However, only 46% of hypotheses\nare supported overall. As alternative hypotheses, we find that\nthe right uses the language of vice more than the left, with\nstatistical significance. For grievance, following literature\nthat theorized that grudges and grievances are requirements\nfor radicalization (Stankov 2021), we find large-scale proof\nthat the far-right uses grievance language more than moder-\nates. We operationalize via the Grievance Dictionary threat-\nassessment tool (Van der Vegt et al. 2021) (see Section 3).\nFornationalism, we show that the right exhibit nationalism\nvia flag emojis, adding validity to our inferred grouping. Fi-\nnally, for dichotomous thinking, we apply a dictionary-based\napproach, showing that the far-right, followed by the right,\n1631\nexhibits more black-and-white thinking (supporting prior\nwork).\nThe main contributions of this work are as follows:\n\u2022An ideology detection pipeline applicable in large-scale\nonline setups, that minimizes labor requirements and im-\nproves transferability to multiple contexts.\n\u2022The most comprehensive discussion and analysis of ideo-\nlogical proxies (to our knowledge); quantifying their bias\nindependently and jointly with homophilic lenses. One\nconstruction outperforms state-of-the-art methods.\n\u2022Evaluation of psychosocial hypotheses concerning ideolo-\ngies in a large-scale online setting.\nGlossary. For readability, we collocate and define terms here.\nIdeological Proxy: measurable user behaviors correlating\nwith ideology (e.g., emitting hashtags, following ideological\nusers, sharing ideological media, etc.). Homophilic Lens: a\nrepresentation of users highlighting specific behaviors under\nthe homophilic assumption (users who act similarly are likely\nto share similar ideological beliefs). Inference Architecture:\na classifier used to infer user connections in a latent space.\n2 Related Work\nTwo corpora relate to our study; ideology detection and psy-\nchosocial asymmetries. Our primary concern, for the prior,\nis pipeline delineation criteria and, for the latter, is evidence\nbases for hypotheses.\n2.1 Ideology Detection Delineation\nIdeology detection is becoming popular and relevant for re-\nsearchers and practitioners across the computer, social, and\npolitical sciences. We delineate prior work by population\nscope, homophilic lenses, and ideological proxies.\nPopulation Scope describes who the technique applies to?\nMany works limit their scope to a population subset: legisla-\ntors, elites (Xiao et al. 2020), the politically active (Darwish\net al. 2020), or everyone (Samih and Darwish 2021). Subsets\noffer clearer ground truth and easier inference, but lack rep-\nresentativeness of the population, leading to biases when ap-\nplied broadly (Alkiek, Zhang, and Jurgens 2022; Cohen and\nRuths 2013) and constraining the representativeness of corre-\nlational analyses (Alizadeh et al. 2019). This work applies to\nall users, providing representative downstream analysis.\nHomophilic Lenses describe which features are utilized to\ninfer ideology? Underlying detection is the homophilic as-\nsumption \u2013 people who act similarly are likely to share similar\nideological beliefs. Prior works operationalize this via several\nlenses: content (including metadata, images (Xi et al. 2020),\nand text (Preo t \u00b8iuc-Pietro et al. 2017)), network (such as fol-\nlowership and resharing (Xiao et al. 2020)), or a combination\n(Chakraborty, Goyal, and Mukherjee 2022). In political sci-\nence, the modus operandi is Ideal Point Estimation (Poole\nand Rosenthal 1985) using homophily via legislator voting\nbehavior. Ideal Point Estimation techniques are largely unsu-\npervised and rely on distinct behavioral patterns but are used\nin most political science ideology measurement work (Gu\net al. 2016; O\u2019Hagan and Schein 2023). In particular, Barber \u00b4a(2015) utilize the following of politicians on Twitter to esti-\nmate user ideal points, and their work is employed in correla-\ntion analysis (Badaan et al. 2023). Given the host of behaviors\nthat portray ideology, novel lenses continue to emerge, in-\ncluding media sharing (Cann, Weaver, and Williams 2021;\nEady et al. 2020), and community participation (Ravi, Vela,\nand Ewetz 2022). Prior works commonly engineer salient\nlenses and seek their optimal combination (Darwish et al.\n2020; Aldayel and Magdy 2019); however the complexity of\ndata context, inference architecture, and ideological proxy\nchoices often make the conclusions unclear. For example,\nDarwish et al. (2020) recommend a retweet lens, while Al-\ndayel and Magdy (2019) recommend a network and lexical\nlens combination. The ideological salience of lenses and their\ncombinations is not our work\u2019s focus. We implement three ho-\nmophilic lenses previously shown to be ideologically salient,\nto limit interaction effects with ideological proxies concerns.\nIdeological Proxy describes what is the source of ideological\nknowledge? Prior work utilizes three paradigms for detec-\ntion: supervised, unsupervised, and weak supervision. Each\nemploys distinct ideological knowledge sources\u2013 dubbed ide-\nological proxies. In this study, we focus on both the proxies\u2019\nperformance and their expert annotation labor requirement\nwhen used across multiple contexts. We delineate proxies by\n(1) the extent to which they require expert annotation, (2) are\ntransferable to different contexts, and (3) how well they rep-\nresent trueideology. These criteria describe how well proxies\ngeneralize to arbitrary datasets and how much manual effort\nis required for switching contexts.\nDirect user annotation for supervised learning (Thomas\net al. 2022; Xiao et al. 2020) is simple, the most representa-\ntive, and accommodates fine-grained distinctions between ide-\nologies (Liu et al. 2023); however, it is also the most restric-\ntive, requiring laborious expert evaluation of users, across ev-\nery new context. Conversely, unsupervised approaches need\nlittle annotation and, in theory, are applicable in any context.\nSome apply embedding and clustering techniques (Darwish\net al. 2020; Samih and Darwish 2021; Rashed et al. 2021).\nOthers utilize matrix factorization to jointly learn represen-\ntations of users and their behaviors (Lai et al. 2022; Lahoti,\nGarimella, and Gionis 2018). These methods are not robust\nin practice, require highly polarized contexts, fail on homoge-\nnous user sets, and depend heavily on lenses. Furthermore,\nthey require expert knowledge in post-analysis (e.g., identify-\ning clusters) (Darwish et al. 2020), and clusters do not always\nalign with ideology. Weak supervision trades-off between the\nhigh labor of supervised and the instability of unsupervised\nmethods. It employs an ideological proxy, a user behavior\nstrongly correlated with ideology. Prior work utilizes a range\nof ideological proxies, including; politically-charged hash-\ntags (Rizoiu et al. 2018), political party relationships (Eady\net al. 2020), politician relationships, community participa-\ntion (Lai et al. 2022), and news media sharing (Jiang, Ren,\nand Ferrara 2023; Badawy, Lerman, and Ferrara 2019; Bailo,\nJohns, and Rizoiu 2023). We assess proxies\u2019 labor minimiza-\ntion and context transferability qualitatively in Section 4.2\nand assess their representativity quantitatively in Section 6.2.\nRelated Ideology Detection. Jiang, Ren, and Ferrara (2023)\nuse text and retweet features, and a combined media-hashtag\n1632\nproxy which they validate. However, they limit scope to\nactive users who retweet and require hashtag proxy labeling.\n2.2 Psychosocial Profiling of Ideological Groups.\nMany social science works detail the nuanced profiles of fine-\ngrained ideological groups and highlight the asymmetries\nbetween ideologies (Tomkins 1963; Jost 2017; Rao 2017;\nRao, Morstatter, and Lerman 2022), often requiring painstak-\ning surveys and ethnographic inquiry. In this work, we supply\nlarge-scale online evidence for hypotheses surrounding psy-\nchosocial asymmetries of ideologies, relating to morality,\ngrievance, nationalism, and dichotomous thinking.\nMorality. Moral Foundations Theory (Graham, Haidt, and\nNosek 2009) is an explanation of moral values variations\nbetween liberals and conservatives (see Section 3). Despite\nits support in psychological survey data (Graham, Haidt, and\nNosek 2009), and a handful of online studies (Reiter-Haas,\nKopeinik, and Lex 2021; Mokhberian et al. 2020), online\nsocial data inconsistently supports this explanation (Wang\nand Inbar 2021; Alizadeh et al. 2019).\nGrievance and Grudge are linked to extreme ideologies in\npsychological theory;Van der Vegt et al. (2021) link grievance\nto extremism, and Stankov (2021) link grudge to the far-right.\nNationalism is definitionally associated with right-wing\npoliticians. Prior work has shown that flags are associated\nwith nationalism (Kemmelmeier and Winter 2008), emojis\nhold identity and semantics information (Li et al. 2020), and\nthat flag emojis are significant in right-leaning political com-\nmunication (Kariryaa et al. 2022). However, this research is\nlimited to politicians in a US context.\nDichotomous Thinking is a cognitive distortion in people\nwith internalizing disorders, is tied to language (Bathina et al.\n2021), and is associated with the right (Meyer 2020).\nOur concern is evaluating hypotheses in large-scale online\npopulations in various contexts. Accordingly, we limit our\nscope to automated techniques using online metadata alone.\nPrior work, online, analyses left-right (Reiter-Haas, Kopeinik,\nand Lex 2021) or extremist asymmetries, but rarely both\n(Alizadeh et al. 2019). Additionally, they analyze small and\nnon-representative samples. This work analyzes left, right,\nand far-right ideologies in several large-scale online contexts.\n3 Preliminaries\nOur study relies on several techniques from prior work.\nEncoding Techniques are employed to implement ho-\nmophilic lenses; the Universal Sentence Encoder (USE) (Cer\net al. 2018) for our lexical lens (a mature, off-the-shelf,\ntransformer-based model), Term-Frequency Inverse Docu-\nment Frequency (TF-IDF) for our hashtag lens, and a multi-\nhot encoding for our resharing lens. We utilize simple encod-\ning techniques, as they are not our work\u2019s main focus.\nInference Architecture Implementation. We use Light-\nGBM (Ke et al. 2017) \u2013 an efficient tree-based classifier\n\u2013 and FlaML (Wang et al. 2021), a system that infers hyperpa-\nrameters based on dataset characteristics in pipelines.\nMoral Foundations Theory (MFT) (Graham, Haidt, and\nNosek 2009) explains variations in moral reasoning through\nfive modular foundations.It espouses that liberals expressindividualizing foundations (care and fairness) while conser-\nvatives express binding foundations (loyalty, authority, and\nsanctity) relatively more. We characterize users\u2019 language\nwith FrameAxis (Kwak et al. 2021), a dictionary embed-\nding technique, to identify a user\u2019s value for each founda-\ntion. It supplies measures, bias andintensity. Importantly,\ndictionary-embeddings are generally a refinement over dic-\ntionaries alone, particularly for smaller documents, however\nthey do not capture the complexities of human language.\nFor example, such approaches will not handle negations\n(for example, \u201cI do not care\u201d) and do not consider the con-\ntext around word usage. Large-language model (LLM) ap-\nproaches may improve these deficits; however, LLMs in-\ntroduce their own complexities (Liscio et al. 2023) and the\ndictionary/embeddings approaches are better validated.\nGrievance Dictionary (Van der Vegt et al. 2021) is curated\nfor threat assessment, including categories such as fixation,\nviolence, and paranoia. It is validated on social media data,\nand provides features for distinguishing extremist texts.\nState-Of-The-Art Baselines. In Section 6, we compare our\napproach to three state-of-the-art detection approaches. UUS\n(Darwish et al. 2020) encodes the kmost active users, applies\ndimensionality reduction, clusters these embeddings, and\nassigns clusters stances via expert annotation. The authors\ntune parameters including; k, features (based on retweets,\nretweeted accounts, and hashtags), dimensionality reduction\nschemes, and clustering schemes. They recommend encoding\n1000 users via retweets, then applying UMAP and Mean-\nShift. UUS+ (Samih and Darwish 2021) extends UUS by\nfinetuning BERT with UUS -labels; applying it to remaining\nusers. Finally, TIMME (Xiao et al. 2020) is a supervised\nmulti-task multi-relation deep graph method using five user\nrelationships to embed and classify users.\n4 Ideology Framework and Implementation\nIn this section, we describe our ideology pipeline frame-\nwork in two parts; Section 4.1 partitions pipelines into four\ncomponents and Sections 4.2 and 4.3 provides component\nimplementation details.\n4.1 Pipeline Constructions Framework\nIn this section, we abstract four components of ideology\ndetection, shown in Fig. 1: the dataset, ideological proxy,\nhomophilic lens, and inference architecture.\nThe Dataset is a set of unlabelled users and their activity\nmetadata within a context. It has an underappreciated effect\non observed pipeline performance. Section 5 discusses clas-\nsification difficulty and introduces our evaluation datasets.\nThe Ideological Proxy infuses ideological knowledge via\nweak supervision. A user subset is labeled (left, right, or\nfar-right) via ideology-correlated behaviors, such as sharing\nhashtags, following political parties, endorsing politicians, or\nsharing news media. See Section 4.2 for details.\nThe Homophilic Lens characterises ideologically salient\nuser similarity. Section 4.3 describes three homophilic lenses:\nthe lexical lens, the hashtag, and the resharing lens.\nThe Inference Architecture propagates labels from a user\nsubset to the remaining unlabelled users. We train a clas-\nsifier on the ideology-proxy-labeled users represented via\n1633\nProxy AL CT A V\nHASHTAGS * * *\nCOMMUNITY PARTICIPATION ** ** *\nPOLITICIAN ENDORSERS ** ** **\nPARTY FOLLOWERS *** ** ***\nMEDIA *** **** ****\nTable 1: Ideology Proxy Qualitative Comparison for appli-\ncation by practitioners based on three-part criteria; annotation\nlabor minimization (AL), context transferability (CT), and\nAvailability (A V). Criteria are rated out of four-stars.\nhomophilic lenses. We use LightGBM with FlaML as our\nclassifier2. The remainder of this section enumerates the ide-\nological proxies (Section 4.2) and homophilic lenses (Sec-\ntion 4.3) evaluated, and their implementations.\n4.2 Implementating Ideological Proxies\nHere, we qualitatively compare proxies and describe the im-\nplementations of the proxies evaluated in our study.\nProxy Qualitative Comparison. We conduct an assessment\nof proxies, based on their utility for practitioners. Based on\nour reading of the thematic review presented in Section 2,\nwe qualitatively build three criteria to assess each proxy. The\ncriteria are designed to partially order proxies as a guide to\npractitioners. Therefore, we apply a four-star rating (one star\nis lower) for each criterion, as shown in Section 4.2.\nThe first criterion we construct is labor minimization (AL)\ndefined as the extent to which expert labor is required to\ngenerate the proxy. Proxies which require human experts to\nperform the entire contruction will score one star, whereas an\napproach with no human intervention scores four stars. The\nsecond criterion is context transferability3(CT), defined as\nthe number and diversity of contexts in which a proxy can\nbe applied. If a proxy is only available in a given context\nit will score one star, whereas if the proxy is available with\nno restrictions, it will score four stars. The third criterion is\navailability to practitioners4(A V), defined as the extent to\nwhich a proxy or its ingredients are openly available, either\nfor ideology detection or independent tasks.\nHASHTAGS shared is commonly used as a proxy, but re-\nquires domain knowledge and is time-consuming to generate\n(one star on AL), and generally requires reannotation for\nevery dataset (* for CT). Furthermore, not all social media\nplatforms use hashtags therefore it has a low availability (*\nfor A V). C OMMUNITY PARTICIPATION uses user activity in\nideological communities (e.g., subreddit posting). The com-\nmunities tend to be fewer and more persistent (** on AL) and\n2The hyperparameter nestimators is inferred for the far-\nright detection due to the sparsity of labeled users; it is fixed\nto200 for left-right detection to prevent overfitting. We set the\nisunbalance flag due to label imbalance.\n3Note that context transferability has a multiplier effect on anno-\ntation labor since a failure to transfer requires reannotation.\n4We do not discount prior work labor. However, we recognize\nthat availability differs, independently of ideology tasks, and proxies\u2019\nmaintenance should be considered in practitioner guidelines.there is some detectable overlap of the communities between\nplatforms (** on CT). However, they are unavailable on some\nplatforms (e.g., Twitter/X) and are inconsistent across coun-\ntries (* on A V). Furthermore, it requires experts for anno-\ntation, and datasets linking communities to ideologies are\nfew. P ARTY FOLLOWERS and P OLITICIAN ENDORSERS\nleverage databases of political parties and politicians with\ntheir online profiles, which are intermittently available (** on\nA V). Such databases are usually country- and period-specific\n\u2013 political parties emerge, change, and become relegated in\ntime. The advantage of these proxies is their stability and\nnon-ambivalent nature during the studied context (** on CT).\nFurthermore, databases do not encode all ideologically rel-\nevant information, such as the lean of parties or specific\npoliticians, requiring an expert instead (** and *** on AL,\nrespectively). M EDIA proxies utilize users sharing news me-\ndia, which often have known political slants. They leverage\navailable and well-maintained data on media slants (*** on\nAL), which have intrinsic value in communication studies,\nthe news ideology detection task, and general consumer value.\nThere is strong evidence linking news readership (Garimella\net al. 2021; Bakshy, Messing, and Adamic 2015) and sharing\n(An, Quercia, and Crowcroft 2014) to ideology. Media slants\nare fairly consistent across time, media-sharing behaviors\noccur on most platforms (**** on A V), and media tend to be\nideologically consistent across topics (**** on CT). There\nare limitations to the media proxy (see Section 8), but it out-\nperforms its alternatives in terms of annotation labor, context\ntransferability, and general availability.\nLeft-Right ideological proxies. We build four proxies.\nHASHTAGS proxy requires experts to code hashtags. We\nqualitatively inspect the 1,000most common hashtags in our\ndatasets and label their political lean; \u22121if left-leaning, 0\nif non-partisan, and 1if right-leaning. We quantify a user\u2019s\npolitical lean as the mean of the labeled hashtags they emit\nand their ideology label as the sign of this lean.\nPARTY FOLLOWERS proxy requires collecting the follow-\ners of the major political parties\u2019 online accounts for each\ntarget country (i.e., Australia and USA). We code the political\nparties by their ideology. The users in the dataset who follow\na single party receive the party\u2019s ideology label.\nPOLITICIAN ENDORSERS proxy requires a dataset of\npoliticians, their political affiliations, and social media han-\ndles. We use the Twitter Parliamentarian Database (van Vliet,\nT\u00a8ornberg, and Uitermark 2020). We code the politicians us-\ning their party\u2019s ideology (where independents are excluded).\nNote that independents\u2019 exclusion reduces the proxy rep-\nresentativity, but this is preferable to manually labeling all\nindependents. We label users who retweet politicians using\nthe majority vote of the politicians\u2019 ideologies.\nLEFT-RIGHT MPP (Media Publication Proxy) requires\na dataset of media websites with their political slants. We\nutilize an extensive survey (Park et al. 2021; Newman\net al. 2021) of news consumption behavior within English-\nspeaking countries (Australia, New Zealand, UK and the\nUSA), collected in 2020 and 2021 by Reuters. Participants\nindicated the news media they read and self-reported their po-\nlitical leaning ranging from \u22123(extreme left) to 3(extreme\n1634\nright). We compute a publication\u2019s slant as the weighted\nmean political lean of the participants who consume that pub-\nlication, where each participant is weighted by the inverse\nnumber of publications they consume. Since countries\u2019 per-\nspectives on what constitutes left- and right-leaning differ,\nwe calibrate scores across countries with the AllSides Media\nBias Ratings (AllSides 2022). We encode the ratings\u2019 five-\npoint scale onto a numerical scale from \u22121to1. We align\neach country\u2019s scores, minimizing the sum of squared dif-\nferences between a country\u2019s scores and AllSides scores for\noverlapping publications. Finally, we generate slant scores\nfor each publication as the average slant over all countries and\nyears. We associate publications (and their slants) with their\nwebsite domains, averaging where a domain is shared. We\npresent the media organizations and their constructed slant\nscores in online appendix (Appendix 2024). We compute a\nuser\u2019s political lean as the average lean of the media domains\nthey share and their ideology label as the sign of this lean.\nFar-Right ideology proxies. We build two proxies.\nFAR-RIGHT MPP is constructed from the media slant\nscores of mainstream media built for L EFT-RIGHT MPP.\nNext, we label users \u2018far-right\u2019 if their political lean exceeds\n0.5or as \u2018moderate\u2019 otherwise.\nMBFC MPP is constructed from the Media Bias Fact Check\n(Zandt 2022) dataset, including both media slant and veracity,\nand containing conspiratorial and fake news sources. We label\nusers sharing the right-most media category as \u2018far-right\u2019.\n4.3 Homophilic Lenses\nHomophily is the tendency of similar users to be similar\n(McPherson, Smith-Lovin, and Cook 2001) and is commonly\nassumed in ideology detection. A homophilic lens is a user\nembedding that encodes ideologically relevant information.\nHere we convert content about user behavior into numerical\nvectors. This section details three lenses.\nLexical Lens (USE). Language is a strong indicator of one\u2019s\npolitical ideology (Cichocka et al. 2016); since a sociolect is\nformed through associations with others.\nHashtag Lens (HT). Hashtags signal users\u2019 interests and the\ndiscussion topics they participate in (Bode et al. 2013).\nResharing Lens (RT). Resharing is a signal of endorsement\n(Metaxas et al. 2015). We assume users endorsing the same\npeople likely share similar ideologies (Van Vliet, T \u00a8ornberg,\nand Uitermark 2021).\nImplementation. For the lexical lens, we preprocess text, to\nprevent potential data leaks, by removing URLs, hashtags,\nand mentions. We concatenate each user\u2019s tweets and encode\nthem as 512dimensional vectors via the universal sentence\nencoder (USE) (Cer et al. 2018). The encoder choice is arbi-\ntrary and based on its prior user in literature for social media-\noriginating text (Rashed et al. 2021). For the hashtag lens,\nwe use the Term-Frequency Inverse Document Frequency\n(TF-IDF) of users (i.e., documents) via hashtags (i.e., words)\nthey use if used at least 10times. TF-IDF is a refinement\nover the bag-of-words model that weights terms used by their\noccurrence within a corpus, providing a simple but salient\nvector representation. Finally, for the resharing lens, we gen-\nerate a multi-hot encoding for users based on the 1000 mostDataset #Users #Posts Country Hopkins\n#QandA 103,074 768,808 AUS 0.2624\n#Ausvotes 273,874 5,033,982 AUS 0.2445\n#Socialsense 49,442 358,292 AUS 0.2591\nRiot 574,281 1,067,794 US 0.1490\nParler 120,048 603,820 US 0.3016\nTable 2: The datasets used in this work: source, profiling,\nand country of origin (AUS and US refer to Australia and\nUSA, respectively). The last column represents the Hopkins\nstatistics (Hopkins and Skellam 1954) for the lexical lens.\nreshared posts. We represent a user uiashi\u2208R1000, where\nhi[j] = 1 ifuireshares the jth most reshared post ( hi[j] = 0\notherwise). In summary, there are three representations of\nusers; lexical R512, hashtag R|#hashtags|, reshare R1000.\n5 Contexts, Datasets, and Ideology Labels\nThis section introduces datasets and their contexts. Sec-\ntion 5.1 describes the five datasets, and Section 5.2 shows\nhow we qualitatively construct ideology ground truth, used\nto evaluate proxies and pipelines\u2019 performance.\n5.1 Contexts and Datasets\nSection 5.1 summarizes the datasets; there are three Aus-\ntralian and two American datasets; one originates from Par-\nler, another is a mixture of Facebook and Twitter, and the\nremainder are Twitter-based. In prior work datasets, ideology\ncorrelates with explicit user behavior (e.g., discussion topics);\nthis simplifies detection but rarely holds in practice. Here,\nwe use data where detection is difficult, as one would likely\nencounter in the wild. We quantify the detection difficulty\nusing Hopkin\u2019s statistics (Hopkins and Skellam 1954) of the\nlexical lens, indicating the clustering tendency of data, rang-\ning from 1 (highly clustered, easy detection) to 0 (uniformly\ndistributed, difficult detection). Hopkin\u2019s statistic is common\nmeasure of clustering tendency, effectively characterizing the\nprobability that embeddings are drawn from a uniform distri-\nbution. We assume that embeddings with a high clustering\ntendency are easier to classify. Note clusters do not necessar-\nily align with classes, however they often do in real-world\ndata; baselines, like UUS and UUS+, directly employ this\naxiom to infer labels (relying heavily on the underlying clus-\ntering tendency of the data). Quantifying detection difficulty\nof datasets is uncommon in literature and prior work often\nvary dataset difficulty be construction (Maci `a, Orriols-Puig,\nand Bernad \u00b4o-Mansilla 2008) or require class labels to infer\nit (Lorena et al. 2019). We employ Hopkin\u2019s Statistic as a\nsimple quantification of difficulty (which is not the focus of\nour work). It is likely related to the decision boundary aspect\nof classification complexity (Lorena et al. 2019). Section 5.1\nshows values \u2208[0.14, 0.3]indicating no clustering tendency.\nBriefly, the datasets are: #QandA [Twitter/X] surrounding\na political panel show with audience questions; #Ausvotes\n[Twitter/X] surrounding the 2022 Australian Federal Elec-\ntion; #Socialsense [Twitter/X and Facebook] (Calderon, Ram,\nand Rizoiu 2024) surrounding the Australian Black Summer\n1635\nBushfires; Riot [Twitter] (Kerchner and Wrubel 2021) and\nParler [Parler] (Aliapoulios et al. 2021) both surrounding the\nUS capitol insurrection. See (Appendix 2024) for details.\n5.2 Build a Ground Truth\nWe qualitatively annotate a subset of #QandA users to gener-\nate both a left-right and far-right ground truth.\nLeft-Right Ground Truth. Due to the imbalance and spar-\nsity of some ideological classes5, we employ the proposed\npipeline to construct a candidate set of users for manual an-\nnotation. Platforms such as X/Twitter have been shown to\nlean-left, and the imbalance in datasets (such as Q+A which\nattracts a left-leaning audience) can be substantial. While it\ncan be argued that using the pipeline to generate a ground\ntruth to train future pipelines may skew the data selection, it\nhas advantages over the alternatives. For example, (1) con-\nducting a manual search through a random candidate set and\ngenerating a proportionately low-volume of right-leaning\nusers is prohibitively expensive, and (2) employing a proxy\ndirectly as our ground truth (following the baselines we com-\npare against) defeats the purpose of evaluating the proxies\nand introduces significant biases.\nWe generate the candidate set using the following\nfour components; (1) we select each of the four prox-\nies (H ASHTAGS , PARTY FOLLOWERS , POLITICIAN EN-\nDORSERS , LEFT-RIGHT MPP), (2) using labels derived from\nthe selected proxy, we train the classifier to predict user labels\n(since even proxy do not necessarily produce sufficient vol-\numes of right-leaning users), (3) we apply to proxy-trained\nclassifier to the entire #QandA dataset (including those al-\nready labelled), (4) finally, we extract the 100left- and 100\nright-leaning users with the highest classifier confidence (es-\ntimated through the classifier sigmoid scores). We collect the\npool of 800users in one set, deduplicate, shuffle it, and re-\nmove users who are unavailable (either private or suspended).\nThis results in 695users; we sample 200users, inspect their\nprofiles and categorize them as left-leaning, right-leaning,\nfar-right, or indeterminable.\nNext, two experts manually labeled each profile. The ex-\nperts both had extensive knowledge of the Australian political\ncontext, and were native English speakers. They were given\nexamples of left, right, far-right, and indeterminable user\nprofiles for context. They were instructed to use any signals\nof ideological-alignment they observed to make their assess-\nments (see (Appendix 2024) for details). Finally, they were\ngiven links to each user profile and instructed to categorize\nthem. They achieved moderate inter-annotator agreement i.e.,\nCohen\u2019s \u03baof0.515 As a result, our left-right ground truth\ncontains 103left- and 74right-leaning users.\nFar-Right Ground Truth. Bailo, Johns, and Rizoiu (2023)\nsnowball sample Australian far-right users, starting with a\n\u2018seed\u2019 user and recovering \u2018lists\u2019 (a Twitter feature document-\ning similar users) they belong to. They intersected the sample\nwith their dataset, manually validated their far-right status,\ncrawled this validated set\u2019s followers, and manually coded\nthese too. They obtained 1,496users, of which 686are in\n#QandA, and serve as our far-right ground truth.\n5Predicted label counts show this imbalance (Appendix 2024).Left-Right Far-right\nHashtagsParty\nFollow.Pol.\nEndors.L.R.\nMPPF.R.\nMPPMBFC\nMPP\nUSE 0.881 0.868 0.788 0.946 0.691 0.773\nHT 0.873 0.876 0.812 0.849 0.559 0.633\nRT 0.840 0.844 0.752 0.879 0.538 0.668\nUSE+HT 0.949 0.879 0.870 0.939 0.715 0.785\nUSE+RT 0.880 0.821 0.785 0.953 0.666 0.762\nHT+RT 0.904 0.914 0.799 0.937 0.570 0.632\nall 0.950 0.875 0.854 0.929 0.713 0.785\nPrec. 0.889 0.873 0.797 0.892 0.516 0.530\nRecall 0.857 0.820 0.794 0.902 0.540 0.557\nF1 0.855 0.821 0.766 0.893 0.636 0.720\nTable 3: Determine the optimal proxy and lens combina-\ntion. (top) AUC ROC for each combination of lenses (rows)\nand proxy (columns). The underlines show the best lens for\na given proxy. (bottom) The precision, recall and macro-F1\nfor each proxy averaged over all lens combinations. The bold\nshow the best-performing proxy.\n6 Proxy Bias, Baselines, and Validation\nIn this section, we first quantify proxy bias (i.e., representativ-\nity) and homophilic lens interaction effects, by enumerating\nall pipeline constructions, in Section 6.1. Next, we present a\npipeline construction that outperforms three state-of-the-art\nmethods in Section 6.2. Finally, we evaluate transfer learning\nacross contexts, illustrating \u2018in-context\u2019 training superiority,\nand test cross-proxy performance in Section 6.3.\nTo avoid confusion, Section 6.1 employs both ground-truth\nand Section 6.2 uses the left-right ground-truth constructed\nin Section 5.2 for the #QandA dataset. Section 6.3 does not\nutilize the constructed ground truth. In its first segment it\ntrains on labels derived from one proxy and tests on labels\nderived from another, with fixed dataset #QandA. In its sec-\nond segment it trains on users from one dataset and tests on\nusers from another, with fixed proxy L EFT-RIGHT MPP.\n6.1 Quantifying Proxy Bias\nHere we jointly assess ideological proxy and homophilic\nlens combinations and their performance against our ground\ntruths, to infer proxy representativity. The top section of\nSection 6 shows all combinations. The columns represent\nproxies, and the rows show the seven possible concatenations\nof our lens implementations. We use the respective ground\ntruth for validation and testing in a 50% : 50% split, employ-\ning the validation set for threshold calibration (for converting\ncontinuous scores to discrete predictions), and removing neu-\ntral ideologies from training, as they do not appear in testing.\nCells show AUC ROC scores for pipelines trained with re-\nspective proxy and lens combinations. A higher AUC ROC\nscore is better with a maximum score of 1and a random\nbaseline of 0.5. The bottom section of Section 6 shows the\nprecision, recall and F1, averaged over all lens combinations.\nThe purpose is to quantify how well proxies represent \u2018true\u2019\nideology, approximated via our ground truth.\nResults. There are two main conclusions. First, Section 6\n1636\n0.86 0.53 0.51 0.690.69 0.61 0.74 0.620.57 0.55 0.87 0.530.7 0.56 0.54 0.820.62 0.830.94 0.7\nHashtagsParty\nFollowersPolitician\nEndorsersLeft\u2212\nRight\nMPPFar\u2212\nRight\nMPPMBFC\nMPP\nHashtags Party\nFollowersPolitician\nEndorsersLeft\u2212\nRight\nMPPFar\u2212\nRight\nMPPMBFC\nMPP\nTested OnTrained On\n0.000.250.500.751.00Figure 2: Self- and cross-proxy generalization. The AUC\nROC of ideology detection on #QandA when trained on one\nproxy (y-axis) and tested on another (x-axis) for left-right\nfar-right proxies.\nMethod UUS UUS+ TIMME Ours\nMacro-F1 0.60\u00b10.230.61\u00b10.26 0.88 0.92\nAUC ROC \u2013 0.76\u00b10.15 0.89 0.95\nTable 4: Baselines. Left-right classification performance of\nbaselines vs. our pipeline on the ground truth. We report the\nmean and standard deviation over all setup combinations for\nUUS andUUS+. Note that UUS does not produce a score,\nonly labels; therefore, AUC ROC cannot be computed for it.\n(bottom) shows that MPP consistently outperforms other\nproxies for left-right detection. In order of representativity,\nwe have L EFT-RIGHT MPP, H ASHTAGS , PARTY FOLLOW -\nERS, and P OLITICIAN ENDORSERS . The MBFC MPP is\nthe most performant for far-right ideology. This is signifi-\ncant, as we have shown that media-based proxies are both\nqualitatively advantageous and optimal for representativity;\nproviding clear guidelines for practitioners. Second, Section 6\n(top) shows that no homophilic lens dominates all others and\nthe best-performing lens combination changes for each proxy.\nThis may explain unclear conclusions within the literature,\nwhere lens optimization is performed in isolation of other\npipeline components (e.g., proxies). Despite the lack of a\ndominating lens, we observe that pipelines containing the\nlexical lens generally outperform their peers, and USE by\nitself (first row) has competitive performances. In addition,\nUSE is the only platform-independent lens.\n6.2 Prediction Performance Against Baselines\nBaselines. We evaluate a pipeline construction against three\nstate-of-the-art stance detection techniques: UUS (Darwish\net al. 2020), UUS+ (Samih and Darwish 2021), and TIMME\n(Xiao et al. 2020) \u2013 detailed in Section 2. For UUS, the\nauthors\u2019 recommended setup (UMAP+Mean-Shift, retweet\nfeatures, and 1000 active users) does not produce any clusters\non #QandA. To render UUS competitive, we enumerate the\n0.82 0.66 0.66 0.61 0.630.7 0.73 0.64 0.6 0.570.66 0.59 0.81 0.57 0.560.69 0.6 0.67 0.75 0.640.68 0.56 0.61 0.62 0.73\nqandaausvotessocialsenseriotparler\nqanda\nausvotes\nsocialsenseriotparler\nTested OnTrained On\n0.50.60.70.80.91.0Figure 3: Context generalization. AUC ROC of L EFT-\nRIGHT MPP trained on one dataset (y-axis) and tested on\nanother (x-axis).\nsetups similarly to their work. We fix the dimensionality re-\nduction to UMAP and clustering to Mean-Shift following\ntheir recommended setup. We use the default scikit-learn\nsettings (n neighbors=15, min dist=0.1, ncomponents=2,\nmetric=cosine), and do not enumerate different hyperparam-\neters to (1) faithfully replicate their work, and (2) simulate\nthe experience of a time-poor practitioner. Furthermore, we\nimplement setups for every combination of features (retweets,\nretweeted accounts, and hashtags) and number of active users\n(500,1000 , and 5000 ). In addition, UUS only reports the\nmost active users\u2019 labels; however, our ground truth users\nare not the most active. Instead, we use UMAP and Mean-\nShift inference methods to acquire labels for these users. For\nUUS+, we use the same set of UUS setups. Following the\nauthors, we utilize BERT base multilingual , using the Hugging-\nFace implementations with PyTorch. We fine-tune BERT by\nadding a fully-connected dense layer followed by a softmax\noutput layer. We minimize the cross-entropy loss over the\ntraining data. As it is not specified by the authors, we choose\nto fine-tune for 10epochs (a sufficient quantity for our data\nvolume). Finally, for TIMME, we use all relations except the\nfollowership network, which is prohibitive to acquire.\nPredicting Human-Annotated Ideology. We evaluate per-\nformance using the left-right ground truth (see Section 5.2)\nwith a 5-fold cross-validation (where applicable). For this\ntask, we use the pipeline constructed from the L EFT-RIGHT\nMPP and the USE+RT homophilic lens (the best-performing\ncombination from Section 6). Section 6.2 shows the F1-macro\nand AUC ROC scores for each technique. We make several\nobservations. First, our approach consistently outperforms\nall baselines, with the next best being TIMME. Second, UUS\nandUUS+ show low mean performance and high standard\ndeviation. Most setups failed to cluster users and were re-\nmoved before computing the mean and standard deviation.\nFurthermore, the clusters required an expert for labeling. Our\npipeline construction has practical advantages over these\nbaselines and outperforms them.\n1637\n6.3 Cross Proxy and Context Generalization\nCross Proxy Generalization. Here, we characterize the ro-\nbustness of ideological proxies through their self- and cross-\nconsistency. Self-consistency indicates how well the pipeline\npredictions trained with a given proxy align with the same\nproxy on a test set. We evaluate self-consistency using a 5-\nfold cross-validation. Cross-consistency indicates that two\nproxies capture similar ideological signals. We evaluate the\ndirected cross-consistency of a source \u2212\u2192 target proxy by\ndeploying a pipeline with the source proxy to predict the\nideology of every user in the #QandA dataset and testing\nagainst the ideology labels set by the target proxy. We report\nthe performance over users whom the target proxy labels, and\nuse a one-vs-one scheme to adjust to the multiclass setting.\nFor a given proxy, we deploy the pipeline with the best lens\ncombination as per Section 6.\nSection 6.2 shows the AUC ROC performance for every\npair of source \u2212\u2192 target proxy for both left-right and far-\nright ideology detection. The self-consistency (main diagonal)\nis high for all left-right pipelines, except P ARTY FOLLOW -\nERS. It is worth noting, P OLITICIAN ENDORSERS has high\nself-consistency but a low prediction performance against\nthe ground truth (see Section 6). This suggests that politi-\ncian endorsement behavior is distinct from prototypical ideo-\nlogical behavior. Note, far-right proxies have relatively low\nself-consistency, perhaps due to the sparsity of far-right users.\nSection 6.2 shows cross-consistency of left-right pipelines\nis relatively low, except for L EFT-RIGHT MPP and H ASH-\nTAGS . This supports prior work (Cohen and Ruths 2013;\nAlkiek, Zhang, and Jurgens 2022) arguing that different prox-\nies confer diverse ideology prototypes. The L EFT-RIGHT\nMPP and H ASHTAGS proxies generalize well to each other\nand the ground truth (see Section 6), suggesting they accu-\nrately represent true ideology. Both far-right proxies general-\nize well on each other, but their performance on the ground\ntruth is relatively weak. This indicates they represent similar\nbehaviors not fully aligned with ideology.\nIn-Context Dominance. Researchers often implicitly sug-\ngest political signals from one context transfer to others. Here\nwe demonstrate the importance of \u2018in-context\u2019 training. Each\ndataset is typically associated with a distinct context (see\nSection 4.1). We evaluate transfer-learning across contexts by\ntraining a pipeline (constructed with the L EFT-RIGHT MPP\nproxy and the USE+RT lenses) on one dataset and testing on\nanother dataset. Section 6.2 shows the 5-fold cross-validation\nAUC ROC performance of left-right ideology detection for\nevery pair of datasets. Intuitively, models perform best when\ntrained and tested on the same dataset (i.e., in-context). How-\never, we observe a significant performance drop-off with\ntransfer learning (off-diagonal). Despite this, we see rela-\ntively better transfer learning between contexts that share\ntraits. Models trained in Australian contexts perform better\nwhen tested within the Australian context, and noticeably\nunderperform when tested in US contexts. Moreover, a fur-\nther reduction is observed when training or testing with the\nParler dataset (i.e., a different social platform context). These\nobservations indicate that signals of ideology differ between\ncontexts. While transfer learning performs better in similar\ncontexts, \u2018in-context\u2019 training is significantly more effective.\n#QandA\n#Ausvotes\n#Socialsense Riot ParlerTotal\nFairness 2 2 2 2 210/20\nCare 2 4 3 1 313/20\nLoyalty 2 0 1 1 26/20\nAuthority 2 1 2 2 29/20\nSanctity 2 0 1 2 38/20\nTotal10/207/209/208/2012/2046/100\nTable 5: Moral Foundations Hypotheses testing. The num-\nber of times the MFT hypotheses tests are significant for each\nfoundation (rows) and dataset (columns).\n7 Psychosocial Analysis of Ideology Cohorts\nIn this section, we test four hypothesis sets for psychosocial\nasymmetries of ideologies, relating to morality, grievance,\nnationalism, and dichotomous thinking. This serves two pur-\nposes: an application case study for practitioners and to sup-\nply online evidence bases for conclusions of prior work. We\nuse pipelines constructed from the MBFC MPP and L EFT-\nRIGHT MPP proxies, alongside the USE lens for its appli-\ncability across all datasets. The first pipeline labels users\nas \u2018far-right\u2019. If users are not labeled \u2018far-right\u2019, the second\npipeline assigns them as \u2018left\u2019, \u2018neutral\u2019, or \u2018right\u2019. For most\nanalysis below, we highlight results on a single dataset, how-\never we produce the relevant plots for all datasets and label\ndistributions in the supplementary material (Appendix 2024).\nTesting Moral Foundations. We begin by evaluating MFT\nhypotheses. There are five hypotheses relating to individu-\nalizing (liberal) and binding (conservative) foundations. We\nuse a Wilcox Rank Sign Test (95%), with Holm adjustment\nfor family-wise error, to evaluate the support for each moral\nfoundations hypothesis in each dataset. We test these hy-\npotheses with the bias andintensity measures and both \u201cleft\nvs. right\u201d and \u201cleft vs. far-right\u201d (i.e., each combination has\nfour hypotheses). Section 7 shows the number of statistically\nsignificant tests for each moral foundations hypothesis in\neach dataset. Overall, only 46% of hypotheses are supported,\nmarginally favoring the individualizing over the binding hy-\npotheses. This inconsistency, seen in prior work (Wang and\nInbar 2021; Thomas et al. 2022), suggests MFT applies dif-\nferently online than it does offline.\nNext, given the lack of support for MFT, we test an alter-\nnative hypothesis, that right-leaning users, relative to left-\nleaning users, exhibit vice over virtue foundations. For each\nmoral foundation, we assign each user a virtue/vice score\nequal to their intensity, if their bias is positive/negative, re-\nspectively. This segregates the population into vice or virtue\nusers. In Fig. 4a, we plot each foundation\u2019s mean vice and\nvirtue scores for each ideological group in the #QandA\ndataset. We observe that a significant proportion of right-\nleaning users partake in the language of vice rather than virtue\ncompared to left-leaning users. We apply the Wilcox Rank\nSign Test (95%) between the means of ideological groups,\n1638\n0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FRloyalty.virtue\ncare.virtue\nfairness.virtue\nauthority.virtue\nsanctity.virtue\nloyalty.vice\nauthority.vice\nsanctity.vice\ncare.vice\nfairness.vice(a)\n\u22122 0 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FRhonour\ngod\njealousy\nimposter\nfrustration\ngrievance\nparanoia\n\ufb01xation\nhate\nthreat\ndesperation\nmurder\nviolence\nloneliness\nplanning\nsuicide\nhelp\nsoldier\nsurveillance\nrelationship\ndeadline (b)\n (c)\n (d)\nFigure 4: (a)(b) Distribution of psychosocial properties for ideological groups for #QandA and #Ausvotes, respectively. Line\ncolor represents ideological groups, and the y-axis shows psychosocial categories. (a) Vices-Virtues. The x-axis is the mean\ndifference for each ideological group from neutral, for Moral Foundations vice and virtue categories. (b) Grievances. The x-axis\nis the signed-KL divergence of each group ideological group from neutral for grievance categories. (c) Emoji Nationalism.\nThe odds (y-axis) of observing an emoji (x-axis) for a user given their ideological group (color), for #QandA. The odds are\ndetermined via logistic regression with no reference group. (d) Dichotomous Thinking. The bootstrapped prevalence distribution\nof dichotomous thinking CDS (y-axis) in tweets by users from ideological groups (x-axis), for #QandA.\nfor each category, and find all are significantly different6. We\nshow that this is relatively consistent across all datasets in the\nonline appendix (Appendix 2024), This provides a consistent\nmoral asymmetry in the online context.\nTesting Extremists\u2019 Association With Grievance. Early\nsignals of extremism are of particular concern to national\nsecurity and law enforcement practitioners. Prior work sug-\ngests that extreme ideologies hold more grievance and grudge\nbeliefs than moderates. We use the Grievance dictionary\n(Van der Vegt et al. 2021) to quantify users\u2019 grievance and\ngrudge language. In Fig. 4b, we plot the Kuller-Leibach diver-\ngence (signed by mean difference) between the distribution of\neach ideological group from the neutral group for each cate-\ngory with the #Ausvotes dataset. We apply the Kruskal-Wallis\nTest (95%) between ideological groups, for each category,\nand find all are significantly different. We observe that the\nfar-right users differ significantly from the other ideologies in\nall categories and generally use more grievance language. No-\ntably, in the #Ausvotes dataset, the far-right users use honor\nandgodtype language less than other groups. In the online\nappendix (Appendix 2024), we show that this hypothesis\nholds for most datasets. A takeaway for practitioners is that\nfar-right language and threat assessment indicators overlap,\nsuggesting a method to build effective public safety tools.\nTesting Nationalism Via Emoji. Here we add online evi-\ndence that the right-wing are associated with nationalism via\nemojis. This hypothesis is widely accepted (and definitional),\nand supporting it validates our inferred ideologies.\nFig. 4c shows the odds of observing an emoji, given a\nuser\u2019s ideological group in #QandA. Point ranges indicate\n6Except between the right and far-right in the care-virtue cate-\ngory, which is irrelevant to our conclusionsthe 95% confidence interval. The significance of the emoji in\npredicting ideological groups, via the Wald Test, is indicated\nwith stars. We make several observations. First,\n is used\nmore by ideological groups than neutral users. Second, the\nright (and far-right) use\n and\n significantly more than\nthe left. Third,\n is used marginally more by the left than\nother groups. Finally, we include\n as a control (showing\nno associations with any ideology). We conclude that na-\ntionalism, via national flags, is associated with our inferred\nright-leaning ideologies. The use of\n could be evidence\nof imported ideology from America to Australia.\n is only\nmarginally associated with the left.\nTesting Dichotomous Thinking. Recent work suggests the\nright-ideologies applying black-and-white thinking relatively\nmore than left-wing ideologies. Following (Bathina et al.\n2021), we match n-grams relating to cognitive distortions\nschema (CDS) in user tweets in #QandA. We measure the\nprevalence \u2013 the empirical probability of observing a CDS\nn-gram in a tweet given an ideological group. Addition-\nally, we utilize 100bootstrap samples (i.e., repeated sam-\npling of tweets) to estimate the prevalence distributions.\nFig. 4d shows that all non-neutral ideologies exhibit a sig-\nnificantly higher prevalence of dichotomous thinking, with\nright-leaning higher than left-leaning and far-right higher\nthan right-leaning. We perform T-Tests (95%) to compare\ngroup means and find all differ significantly from each other.\nThese findings support prior literature (Meyer 2020), and\nextend it by showing that the far-right might engender an\neven greater extent of dichotomous thinking. Other cogni-\ntive distortions\u2019 prevalences are summarized in the online\nappendix (Appendix 2024).\n1639\n8 Conclusion\nThis work proposes a framework for ideology detection\npipelines and quantifies biases introduced by ideological\nproxies. It tests hypotheses of the psychosocial asymmetries\nof ideological groups, in the online space. We present an\nevaluation of ideological proxies; qualitatively, indicating\nproxies that minimize labor, are transferable across multiple\ncontexts, and are available; and, quantitatively, indicating the\nrepresentativity and robustness of proxies. We find the media\nproxy advantageous, and a pipeline constructed from it and\nthe lexical lens to be optimal, outperforming state-of-the-art\napproaches. Such research is essential for furnishing practi-\ntioners with actionable guidelines for ideology detection and\nits practical applications.\nLimitations. The media proxy has several limitations. Firstly,\nit relies on the availability of up-to-date media slant data. Pub-\nlication slant can shift over time, and publication emergence,\nacquisition and closure can hold significance (particularly\non ideological fringes). Secondly, some users share media to\nrefute it. Thirdly, article slants may differ from publication\nslants. Finally, it will not produce a perfectly representative\nuser subset, although media sharing ubiquity makes it rel-\natively competitive. Furthermore, our conceptualization of\nideology is simplistic, and some political systems are com-\nplex requiring complex ideological proxies (which are largely\nunavailable).\nFuture Work. We limit our scope to English-speaking Anglo-\ncentric countries due to the expertise and language profi-\nciency of the author team. However, the study could be ap-\nplied broadly. Newman et al. (2021) provides data annually\nfor46diverse countries, including segments of the Global\nSouth. Our study could be extended to any other uniaxial\npolitical setting with little amendment.\nReferences\nAldayel, A.; and Magdy, W. 2019. Your stance is exposed! analysing\npossible factors for stance detection on social media. CSCW.\nAliapoulios, M.; Bevensee, E.; Blackburn, J.; Bradlyn, B.; Cristo-\nfaro, E. D.; Stringhini, G.; and Zannettou, S. 2021. A Large Open\nDataset from the Parler Social Network.\nAlizadeh, M.; Weber, I.; Cioffi-Revilla, C.; Fortunato, S.; and Macy,\nM. 2019. Psychology and morality of political extremists: evidence\nfrom Twitter language analysis of alt-right and Antifa. EPJ DS.\nAlkiek, K.; Zhang, B.; and Jurgens, D. 2022. Classification without\n(Proper) Representation: Political Heterogeneity in Social Media\nand Its Implications for Classification and Behavioral Analysis. In\nACL.\nAllSides. 2022. AllSides Media Bias Ratings. https://www.allsides.\ncom/media-bias/ratings. Accessed: 2022-04-08.\nAn, J.; Quercia, D.; and Crowcroft, J. 2014. Partisan sharing: Face-\nbook evidence and societal consequences. In COSN.\nAppendix, O. 2024. Supplementary Material: Practical Guidelines\nfor Ideology Detection Pipelines and Psychosocial Applications.\nhttps://bit.ly/ideology detection.\nAuxier, B.; and Anderson, M. 2021. Social media use in 2021. Pew\nResearch Center.\nBadaan, V .; Hoffarth, M.; Roper, C.; Parker, T.; and Jost, J. T. 2023.\nIdeological asymmetries in online hostility, intimidation, obscenity,\nand prejudice. Scientific reports.Badawy, A.; Lerman, K.; and Ferrara, E. 2019. Who falls for online\npolitical manipulation? In WWW.\nBailo, F.; Johns, A.; and Rizoiu, M.-A. 2023. Riding information\ncrises: the performance of far-right Twitter users in Australia during\nthe 2019\u20132020 bushfires and the COVID-19 pandemic. Information,\nCommunication & Society.\nBakshy, E.; Messing, S.; and Adamic, L. A. 2015. Exposure to\nideologically diverse news and opinion on Facebook. Science.\nBarber \u00b4a, P. 2015. Birds of the same feather tweet together: Bayesian\nideal point estimation using Twitter data. Political analysis.\nBathina, K. C.; Ten Thij, M.; Lorenzo-Luaces, L.; Rutter, L. A.; and\nBollen, J. 2021. Individuals with depression express more distorted\nthinking on social media. Nature Human Behaviour.\nBetz, M. 2016. Constraints and opportunities: what role for media\ndevelopment in countering violent extremism?\nBode, L.; Hanna, A.; Sayre, B.; Yang, J.; and Shah, D. V . 2013.\nMapping the political Twitterverse: Finding connections between\npolitical elites.\nBooth, E.; Lee, J.; Rizoiu, M.-A.; and Farid, H. 2024. Conspiracy,\nmisinformation, radicalisation: understanding the online pathway\nto indoctrination and opportunities for intervention. Journal of\nSociology.\nCalderon, P.; Ram, R.; and Rizoiu, M.-A. 2024. Opinion Market\nModel: Stemming Far-Right Opinion Spread using Positive Inter-\nventions. In ICWSM.\nCann, T. J.; Weaver, I. S.; and Williams, H. T. 2021. Ideological\nbiases in social sharing of online information about climate change.\nPlos one.\nCarr, H. J.; Dancho, R.; Michaud, K.; Chiang, P.; Damoff, P.; Lloyd,\nD.; MacGregor, A.; McKinnon, R.; Noormohamed, T.; Schiefke, P.;\nShipley, D.; Popta, T. V .; and Zuberi, S. 2022. Rise of Ideologically\nMotivated Violent Extremism in Canada. Technical report.\nCer, D.; Yang, Y .; Kong, S.-y.; Hua, N.; Limtiaco, N.; John, R. S.;\nConstant, N.; Guajardo-Cespedes, M.; Yuan, S.; Tar, C.; et al. 2018.\nUniversal sentence encoder. arXiv preprint arXiv:1803.11175.\nChakraborty, S.; Goyal, P.; and Mukherjee, A. 2022. Fast Few Shot\nSelf-attentive Semi-supervised Political Inclination Prediction. In\nICADL.\nCichocka, A.; Bilewicz, M.; Jost, J. T.; Marrouch, N.; and\nWitkowska, M. 2016. On the grammar of politics\u2014or why conser-\nvatives prefer nouns. Political Psychology.\nCohen, R.; and Ruths, D. 2013. Classifying political orientation on\nTwitter: It\u2019s not easy! In ICWSM.\nCohrs, J. C. 2012. Ideological bases of violent conflict.\nDarwish, K.; Stefanov, P.; Aupetit, M.; and Nakov, P. 2020. Unsu-\npervised user stance detection on twitter. In ICWSM.\nEady, G.; Bonneau, R.; Tucker, J. A.; and Nagler, J. 2020. News\nsharing on social media: Mapping the ideology of news media\ncontent, citizens, and politicians.\nGarimella, K.; Smith, T.; Weiss, R.; and West, R. 2021. Political\npolarization in online news consumption. In ICWSM.\nGraham, J.; Haidt, J.; and Nosek, B. A. 2009. Liberals and con-\nservatives rely on different sets of moral foundations. Journal of\npersonality and social psychology.\nGu, Y .; Chen, T.; Sun, Y .; and Wang, B. 2016. Ideology detection\nfor twitter users with heterogeneous types of links. arXiv preprint\narXiv:1612.08207.\nHopkins, B.; and Skellam, J. G. 1954. A New Method for deter-\nmining the Type of Distribution of Plant Individuals. Annals of\nBotany.\n1640\nJiang, J.; Ren, X.; and Ferrara, E. 2023. Retweet-BERT: Politi-\ncal Leaning Detection Using Language Features and Information\nDiffusion on Social Networks. ICWSM.\nJost, J. T. 2017. Asymmetries abound: Ideological differences in\nemotion, partisanship, motivated reasoning, social network structure,\nand political trust. Journal of Consumer Psychology.\nKariryaa, A.; Rund \u00b4e, S.; Heuer, H.; Jungherr, A.; and Sch \u00a8oning,\nJ. 2022. The role of flag emoji in online political communication.\nSocial Science Computer Review.\nKe, G.; Meng, Q.; Finley, T.; Wang, T.; Chen, W.; Ma, W.; Ye, Q.;\nand Liu, T.-Y . 2017. Lightgbm: A highly efficient gradient boosting\ndecision tree. NeurIPS.\nKemmelmeier, M.; and Winter, D. G. 2008. Sowing patriotism, but\nreaping nationalism? Consequences of exposure to the American\nflag. Political Psychology.\nKerchner, D.; and Wrubel, L. 2021. U.S. Capitol Riot and\n#TrumpRally Tweet IDs.\nKwak, H.; An, J.; Jing, E.; and Ahn, Y .-Y . 2021. FrameAxis: charac-\nterizing microframe bias and intensity with word embedding. PeerJ\nComputer Science.\nLahoti, P.; Garimella, K.; and Gionis, A. 2018. Joint non-negative\nmatrix factorization for learning ideological leaning on twitter. In\nWSDM.\nLai, A.; Brown, M. A.; Bisbee, J.; Tucker, J. A.; Nagler, J.; and\nBonneau, R. 2022. Estimating the ideology of political youtube\nvideos. Political Analysis.\nLi, J.; Longinos, G.; Wilson, S.; and Magdy, W. 2020. Emoji and\nself-identity in Twitter bios. In NLP+CSS.\nLiscio, E.; Araque, O.; Gatti, L.; Constantinescu, I.; Jonker, C. M.;\nKalimeri, K.; and Murukannaiah, P. K. 2023. What does a text\nclassifier learn about morality? An explainable method for cross-\ndomain comparison of moral rhetoric. In ACL.\nLiu, S.; Luo, Z.; Xu, M.; Wei, L.; Wei, Z.; Yu, H.; Xiang, W.; and\nWang, B. 2023. Ideology Takes Multiple Looks: A High-Quality\nDataset for Multifaceted Ideology Detection. In EMNLP.\nLorena, A. C.; Garcia, L. P.; Lehmann, J.; Souto, M. C.; and Ho,\nT. K. 2019. How complex is your classification problem? a survey\non measuring classification complexity. CSUR.\nMaci `a, N.; Orriols-Puig, A.; and Bernad \u00b4o-Mansilla, E. 2008.\nGenetic-based synthetic data sets for the analysis of classifiers be-\nhavior. In HAIS.\nMcCauley, C.; and Moskalenko, S. 2008. Mechanisms of Political\nRadicalization: Pathways Toward Terrorism. Terrorism and Political\nViolence.\nMcPherson, M.; Smith-Lovin, L.; and Cook, J. M. 2001. Birds of a\nfeather: Homophily in social networks. Annual review of sociology.\nMetaxas, P.; Mustafaraj, E.; Wong, K.; Zeng, L.; O\u2019Keefe, M.; and\nFinn, S. 2015. What do retweets indicate? Results from user survey\nand meta-review of research. In ICWSM.\nMeyer, P. H. 2020. Political Ideology and Black-and-White Think-\ning.\nMokhberian, N.; Abeliuk, A.; Cummings, P.; and Lerman, K. 2020.\nMoral framing and ideological bias of news. In SocInfo.\nNewman, N.; Fletcher, R.; Schulz, A.; Andi, S.; Robertson, C. T.;\nand Nielsen, R. K. 2021. Reuters Institute digital news report 2021.\nReuters Institute for the Study of Journalism.\nO\u2019Hagan, S.; and Schein, A. 2023. Measurement in the Age of\nLLMs: An Application to Ideological Scaling. arXiv preprint\narXiv:2312.09203.Park, S.; Fisher, C.; McGuinness, K.; Lee, J. Y .; and McCallum,\nK. 2021. Digital news report: Australia 2021. News and Media\nResearch Centre.\nPoole, K. T.; and Rosenthal, H. 1985. A spatial model for legislative\nroll call analysis. American journal of political science.\nPreot \u00b8iuc-Pietro, D.; Liu, Y .; Hopkins, D.; and Ungar, L. 2017. Be-\nyond binary labels: Political ideology prediction of Twitter users. In\nACL.\nRadsch, C. 2016. Media Development and Countering Violent\nExtremism: An Uneasy Relationship, a Need for Dialogue. Center\nfor International Media Assistance.\nRao, A.; Morstatter, F.; and Lerman, K. 2022. Partisan asymmetries\nin exposure to misinformation. Scientific reports.\nRao, A. R. 2017. Red, blue and purple states of mind: Segmenting\nthe political marketplace. Journal of Consumer Psychology.\nRashed, A.; Kutlu, M.; Darwish, K.; Elsayed, T.; and Bayrak, C.\n2021. Embeddings-Based Clustering for Target Specific Stances:\nThe Case of a Polarized Turkey. In ICWSM.\nRavi, K.; Vela, A. E.; and Ewetz, R. 2022. Classifying the Ideo-\nlogical Orientation of User-Submitted Texts in Social Media. In\nICMLA.\nReiter-Haas, M.; Kopeinik, S.; and Lex, E. 2021. Studying Moral-\nbased Differences in the Framing of Political Tweets. In ICWSM.\nRizoiu, M.-A.; Graham, T.; Zhang, R.; Zhang, Y .; Ackland, R.; and\nXie, L. 2018. # DebateNight: The Role and Influence of Socialbots\non Twitter During the 1st 2016 US Presidential Debate. In ICWSM.\nSamih, Y .; and Darwish, K. 2021. A few topical tweets are enough\nfor effective user stance detection. In ACL.\nStankov, L. 2021. From social conservatism and authoritarian pop-\nulism to militant right-wing extremism. Personality and Individual\nDifferences.\nThomas, E. F.; Leggett, N.; Kernot, D.; Mitchell, L.; Magsarjav, S.;\nand Weber, N. 2022. Reclaim the Beach: How Offline Events Shape\nOnline Interactions and Networks Amongst Those Who Support\nand Oppose Right-Wing Protest. Studies in Conflict & Terrorism.\nTomkins, S. 1963. Left and right: A basic dimension of ideology\nand personality.\nVan der Vegt, I.; Mozes, M.; Kleinberg, B.; and Gill, P. 2021. The\ngrievance dictionary: Understanding threatening language use. Be-\nhavior research methods.\nvan Vliet, L.; T \u00a8ornberg, P.; and Uitermark, J. 2020. The Twit-\nter parliamentarian database: Analyzing Twitter politics across 26\ncountries. PLoS one.\nVan Vliet, L.; T \u00a8ornberg, P.; and Uitermark, J. 2021. Political Sys-\ntems and Political Networks: The Structure of Parliamentarians\u2019\nRetweet Networks in 19 Countries. International Journal of Com-\nmunication.\nWang, C.; Wu, Q.; Weimer, M.; and Zhu, E. 2021. FLAML: A fast\nand lightweight automl library. MLSys.\nWang, S.-Y . N.; and Inbar, Y . 2021. Moral-language use by US\npolitical elites. Psychological Science.\nWikipedia. 2023. Q+A (Australian talk show). https://en.wikipedia.\norg/wiki/Q%2BA (Australian talk show). Accessed: 2023-04-27.\nXi, N.; Ma, D.; Liou, M.; Steinert-Threlkeld, Z. C.; Anastasopou-\nlos, J.; and Joo, J. 2020. Understanding the political ideology of\nlegislators from social media images. In ICWSM.\nXiao, Z.; Song, W.; Xu, H.; Ren, Z.; and Sun, Y . 2020. TIMME:\nTwitter ideology-detection via multi-task multi-relational embed-\nding. In KDD.\nZandt, D. 2022. Media Bias/Fact Check. https://mediabiasfactcheck.\ncom/about. Accessed: 2022-04-08.\n1641\nEthics Checklist\n1. For most authors...\n(a)Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes, see the Ethics and\nBroader Impact Statement at the end of this checklist.\n(b)Do your main claims in the abstract and introduction\naccurately reflect the paper\u2019s contributions and scope?\nYes.\n(c)Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes.\n(d)Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? Yes, see\nContexts, Datasets, and Ideology Labels.\n(e)Did you describe the limitations of your work? Yes, see\nthe Conclusion.\n(f)Did you discuss any potential negative societal impacts\nof your work? Yes, see the Ethics and Broader Impact\nStatement at the end of this checklist.\n(g)Did you discuss any potential misuse of your work?\nYes, see the Ethics and Broader Impact Statement at\nthe end of this checklist.\n(h)Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, respon-\nsible release, access control, and the reproducibility of\nfindings? Yes.\n(i)Have you read the ethics review guidelines and ensured\nthat your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a)Did you clearly state the assumptions underlying all\ntheoretical results? Yes.\n(b)Have you provided justifications for all theoretical re-\nsults? Yes.\n(c)Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? Yes.\n(d)Have you considered alternative mechanisms or ex-\nplanations that might account for the same outcomes\nobserved in your study? Yes.\n(e) Did you address potential biases or limitations in your\ntheoretical framework? Yes.\n(f)Have you related your theoretical results to the existing\nliterature in social science? Yes.\n(g)Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? Yes.\n3. Additionally, if you are including theoretical proofs...\n(a)Did you state the full set of assumptions of all theoreti-\ncal results? NA\n(b)Did you include complete proofs of all theoretical re-\nsults? NA4. Additionally, if you ran machine learning experiments...\n(a)Did you include the code, data, and instructions needed\nto reproduce the main experimental results (either in\nthe supplemental material or as a URL)? No, we will\ninclude our git repository once the paper gets accepted.\nThe repository will include the code and instructions.\n(b)Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? Yes.\n(c)Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nYes, where applicable.\n(d)Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? No, our study does not\nrequire significant compute resources.\n(e)Do you justify how the proposed evaluation is sufficient\nand appropriate to the claims made? Yes.\n(f)Do you discuss what is \u201cthe cost\u201c of misclassification\nand fault (in)tolerance? Yes.\n5.Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity...\n(a)If your work uses existing assets, did you cite the cre-\nators? Yes.\n(b) Did you mention the license of the assets? NA\n(c)Did you include any new assets in the supplemental\nmaterial or as a URL? Yes.\n(d)Did you discuss whether and how consent was obtained\nfrom people whose data you\u2019re using/curating? NA.\n(e)Did you discuss whether the data you are using/curating\ncontains personally identifiable information or offen-\nsive content? NA\n(f)If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR?\nNA\n(g)If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset? NA\n6.Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity...\n(a)Did you include the full text of instructions given to\nparticipants and screenshots? NA\n(b)Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? NA\n(c)Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? NA\n(d)Did you discuss how data is stored, shared, and deiden-\ntified? NA\nEthical Statement\nThis work introduces a powerful tool for inferring user ide-\nology based on covert cues such as language patterns. We\n1642\ndemonstrate our tool for detecting far-right ideologies; how-\never, it could, in theory, be used by oppressive regimes to\ninfer the true ideologies of their citizens and expose their op-\nponents (Radsch 2016). The Countering Violent Extremism\n(CVE) literature (Betz 2016) explores the ethical concerns of\ndeveloping tools that can be used for oppressive ends and pro-\nposes mitigation strategies. There are also privacy concerns,\nas one\u2019s ideology can be viewed as an intimate and private\ntrait that our tool can expose. Additionally, we show how to\nuse our pipeline to profile entire online populations based on\ntheir psychosocial characteristics. We argue that the pipeline\npredictions are not prescriptive; they should be treated as an\nearly warning system, requiring human expert investigation.\nWe further note that we only use expert-inferred political af-\nfiliation as our ground truth, not private self-reported political\nindicator data.\n1643\nAppendices\nThis document accompanies the submission. The informa-\ntion in this document complements the submission and is\npresented here for completeness reasons. It is not required to\nunderstand the main paper or reproduce the results.\nA Dataset Collection Details\n#QandA. We collect discussions related to the Australian\npanel show Q+A (Wikipedia 2023), where panelists (pub-\nlic figures, politicians, and experts) answer curated audi-\nence questions. Twitter participation is encouraged in airings.\nWe collect #QandA using the filter keyword qanda during\nJanuary-December 2020.\n#Ausvotes. We collect discussions about the 2022 Australian\nFederal election, tracking the lead-up and aftermath. It fol-\nlows the major parties and their leaders: the left-leaning Aus-\ntralian Labor Party led by Anthony Albanese and the right-\nleaning Liberal-National Coalition led by Scott Morrison. We\ncollect #Ausvotes using the keywords auspol andausvotes,\nand for mentions of @ScottMorrisonMP, @AlboMP, and\n@AusElectoralCom, between 9 May and 15 June 2022 (the\nelections occurred on 21 May).\n#Socialsense (Calderon, Ram, and Rizoiu 2024) features\ndiscussions related to the Australian Black Summer bushfires,\nwhich gathered discourse concerning climate change, and\ncontains far-right opinions. #Socialsense contains 90days of\nTwitter and Facebook discussions, from 1 November to 29\nJanuary 2020.\nRiot (Kerchner and Wrubel 2021) features discussions about\nthe January 6th US Capitol Insurrection, including election\nfraud and insurrection topics. The dataset spans 6 January to\n1 February 2021 and was collected with the filter keywords\nTrumpRally, Democracy, USCapitol, Capitol, DCProtests,\nandAshliBabbit.\nParler (Aliapoulios et al. 2021) features discussions about\nthe US Capitol Insurrection from Parler. We collect all posts\nemitted during the day of 6 January 2021.\nB All UUS/UUS+ Metrics\nThi section shows all possible runs for the UUS andUUS+.\nWe notice that in many instances UUS fails to seperate clus-\nters, and even in instances where seperation can be achieved\nmany suffer from poor performance. This shows that these\ntechniques lack robustness for more difficult datasets.\nC Left-Right Annotation Procedure\nIdeology is the subject of considerable subjectivity, not only\nbecause experts have their own ideology, but because anno-\ntators are often unclear as to what evidence is permissible\nfor use. For this task we issued the following guidelines to\nannotators:\nIt is not always clear what should count as an ideo-\nlogical signal. For our purposes, we will include the\nfollowing as signals of ideology:\n\u2022If a target user promotes/retweets someone or an\norganisation with a known ideological affiliation,\nyou may assume that the target endorse them. ForTable 6: All Baseline Performances. The table shows to\nperformances for all combinations of the UUS andUUS+\nbaselines.\nRepresentation Active\nUsersF1-\nMacroAUC\nROCUUS\nF1-\nMacro\nH 500 0.37 0.68 0.37\nH 1000 - - -\nH 5000 0.37 0.54 0.37\nHR 500 - - -\nHR 1000 - - -\nHR 5000 0.89 0.92 0.85\nR 500 - - -\nR 1000 - - -\nR 5000 0.93 0.93 0.87\nT 500 - - -\nT 1000 - - -\nT 5000 - - -\nTH 500 0.4 0.58 0.54\nTH 1000 - - -\nTH 5000 0.92 0.91 0.87\nTR 500 - - -\nTR 1000 - - -\nTR 5000 - - -\nTRH 500 - - -\nTRH 1000 - - -\nTRH 5000 0.41 0.75 0.36\nexample, if a target user retweets a labor MP then\nyou can label the user as \u2019left\u2019.\n\u2022If a target user, has a stance against someone with a\nknown ideological affiliation, then you might infer\nthat the target user\u2019s ideology is the opposing ideol-\nogy. For example, if a target user calls a labor MP\nan insult, then you can label the user as \u2019right\u2019.\n\u2022If a target user expresses a view about a issue related\nto an ideology, you can infer the user\u2019s ideology. For\nexample, if a user supports LGBTQ or environmen-\ntal issues, then (if there is enough evidence) you\nmay label them as \u2019left\u2019.\nThese guidelines aim to increase the clarity of the anno-\ntation task. In countries where political affiliation is obvert\n(e.g. the united states), this labelling task is often unam-\nbiguous; however, in Australia ideological signals are of-\nten implicit. The full annotation briefing material is avail-\nable in the code repository [https://github.com/behavioral-\nds/ideology prediction].\nContext-Transfer Illustration\nFig. 5 further illustrates the difficulty with utilizing particular\nproxies as ground truth. We observe that some ideological\nproxies are consistent across only some contexts (represented\nby the dashed green boxes). For example, #RoboDebt (in\nrelation to an Australian incident) is not relevant to the USA\nand did not exist before 2016; and, although @MittRomney\nsignaled right-wing ideology in 2012, the right has shifted\n1644\nParty\nFollowers\nPolitician\nEndorsers\nHashtags\nMedia\n(T 1,\n , ) (T 1, , )\n (T2, , ) (T2, , )\n Context@UserA\n@UserB\n@UserC\n@UserD\n@JoeBiden\n@KamalaHarris\n@realDonaldT rump\n@Mike_Pence\n#BLM\n#DefundThePolice\n#MAGA\n#AllLivesMatter\nNYT\nVOX\nFOX\nSKY@User1\n@User2\n@User3\n@User4\n@JoeBiden\n@KamalaHarris\n@realDonaldT rump\n@Mike_Pence\n#BLM\n#DefundThePolice\n#MAGA\n#AllLivesMatter\nNYT\nVOX\nFOX\nSKY@User1\n@User2\n@User3\n@User4\n@BarackObama\n@HillaryClinton\n@MittRomney\n@PRyan\n#W earAMask\n#MaskUp\n#MyBodyMyChoice\n#MasksDontW ork\nNYT\nVOX\nFOX\nSKY@UserE\n@UserF\n@UserG\n@UserH\n@AlboMP\n@billshortenMP\n@ScottMorrisonMP\n@PeterDuttonMP\n#RoboDebt\n#SportsRorts\n#DefundABC\n#DictatorDan\nNYT\nVOX\nFOX\nSKYFigure 5: Most ideology proxies do not generalize across\ncontexts. The x-axis shows four contexts that vary in time ( T1\nandT2), country (Australia and USA), and platform (Twitter\nand Facebook). The y-axis show four proxies: endorsing\npolitical parties or political figures, using politically charged\nhashtags and the consumed media slant. The green dashed\nboxes indicate whether a proxy is applicable across contexts.\nsince Trump\u2019s election.\nPrior ideology detection techniques fail to easily context-\nswitch and cannot be readily applied to multiple distinct\ndomains.\nMedia Publication Slants\nThe media slant scores are shown in Fig. 6, where we ob-\nserved publications like Breitbart andFox News are extremely\nright-leaning, and VoxandNYTimes are left-leaning.\nCognitive Distortions Schemata Prevalence\nFig. 7 shows the prevalence of all twelve cognitive distor-\ntions in each of the ideological groups, for #QandA. Note\nthat many CDS n-grams are extremely rare (or do not appear),\nnamely; emotional reasoning andmental filtering. In several\nCDS the left exhibit higher prevalence, such as catastrophiz-\ning, fortune-telling, disqualifying the positive, and should\nstatements.\nFlag Emoji Hurdle Model\nFor completeness, we present the results of the hurdle model\n(used to model zero-inflated count data, such a tokens in a\ncorpus). The hurdle model is a mixed model, comprised of a\nlogistic regression to model the presense of no emoji, and a\ntruncated poisson with log linkage, to model the count of the\nemoji. Fig. 8 shows the coefficients for each model, including\nthe reference groups.\n is observed more for far-right users\nin both the zero and the count models. The count models for\nthe other flags show mixed results and not significant.\nPrecision-Recall of Pipelines\nFig. 9 shows precision and recall for every lens combinations\nand proxy.Table 7: Distribution of Predicted Labels. The number of\nusers predicted to be in each class (rows) for each dataset\n(columns). Note that for many datasets there is a signifi-\ncant imbalance toward the left (except Parler hich is a right-\nleaning platform).\n#QandA\n#Ausvotes\n#Socialsense\nRiot ParlerLeft 80,375 189,233 48,056 339,095 293\nNeutral 21,176 79,221 604 227,839 48,829\nRight 777 3,689 464 3,624 68,104\nFar-right 746 1,731 318 3,723 2,822\nPredicted Label Distribution\nTable 7 shows the distribution of predicted labels, to provide\ncontext for the psychosocial analysis.\nDataset Profiling\nActivity levels are often a concern for ideology detection\nframeworks, given that low-activity users reveal few signals\nof ideology. Fig. 10 shows the distribution of activity for users\nfor each dataset. It shows long-tailed activity distributions and\nthe proportion of low-activity users. Riot hows a significant\nproportion of low-activity users, who\u2019re often difficult to\nclassify.\nExhaustive Psychosocial Analysis\nGrievance\nThis section shows the difference between ideological groups\nin terms of grievance categories for all available datasets.\nMFT\nThis section shows the difference between ideological groups\nin terms of moral foundations for all available datasets.\n1645\nFigure 6: Media Publication Slants. The plot shows the slants of Media Publications, as averaged over the year, country, and\nsource point estimates.\nFigure 7: CDS Prevalence\n1646\nFigure 8: Hurdle Model\nPrecision\nRecall0.5 0.6 0.7 0.8 0.9 1.00.5 0.6 0.7 0.8 0.9 1.0Far\u2212Right \nMPPMBFC \nMPPPolitician EndorsersParty \nFollowersHashtagsLeft\u2212RightMPP\nFeaturesht ht+rt rt\nuse use+ht use+ht+rtuse+rt\nFigure 9: Precision-Recall. The plot shows the macro-\naveraged precision and recall of pipelines, trained with each\nproxy (y-axis) and each feature set (colors), probability cali-\nbrated with the hold-out validation set for F1-macro scores.\n100101102103104105\ncounts106\n105\n104\n103\n102\n101\n100Proportiondataset\nqanda\nausvotes\nsocialsense\nriot\nparlerFigure 10: Activity Distribution. The log-log ECCDF distri-\nbution of activity (number of posts per user) for each dataset.\nsoldiersuicidemurderviolencethreathatejealousyimpostorfrustrationgrievancehonourparanoiagodfixationlonelinessdesperationdeadlineplanningsurveillancehelprelationship\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FR\nFigure 11: Grievance #QandA\ndeadlinerelationshipsurveillancesoldierhelpsuicideplanninglonelinessviolencemurderdesperationthreathatefixationparanoiagrievancefrustrationimpostorjealousygodhonour\n\u22122 0 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FR\nFigure 12: Grievance #Ausvotes\n1647\nplanningrelationshipviolencethreatmurdersurveillancehelpdesperationsoldierdeadlineparanoiasuicideimpostorhategodgrievancefrustrationlonelinessjealousyfixationhonour\n\u22122 0 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FRFigure 13: Grievance #Socialsense\nthreatjealousyviolenceimpostormurderfrustrationhonoursoldierdeadlinefixationdesperationlonelinessgodgrievanceparanoiahelpsurveillancesuiciderelationshiphateplanning\n\u22120.25 0.00 0.25 0.50\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FR\nFigure 14: Grievance Riot\nsurveillancemurderdeadlinesoldierhelpviolenceplanningthreatsuicidehatefixationparanoiajealousyfrustrationgrievanceimpostorlonelinessdesperationhonourgodrelationship\n\u22122 \u22121 0 1 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FR\nFigure 15: Grievance Parler\nfairness.vicecare.vicesanctity.viceauthority.viceloyalty.vicesanctity.virtueauthority.virtuefairness.virtuecare.virtueloyalty.virtue\n0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FR\nFigure 16: MFT #QandA\nfairness.vicecare.virtueauthority.vicesanctity.viceloyalty.viceauthority.virtueloyalty.virtuesanctity.virtuecare.vicefairness.virtue\n\u22120.0025 0.0000 0.0025\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FRFigure 17: MFT #Ausvotes\ncare.vicefairness.viceauthority.viceloyalty.vicesanctity.vicesanctity.virtueauthority.virtuefairness.virtueloyalty.virtuecare.virtue\n\u22120.005 0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FR\nFigure 18: MFT #Socialsense\nfairness.viceauthority.vicecare.viceloyalty.vicesanctity.vicesanctity.virtueloyalty.virtuecare.virtueauthority.virtuefairness.virtue\n0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FR\nFigure 19: MFT Riot\ncare.vicefairness.viceauthority.viceloyalty.vicesanctity.vicefairness.virtueauthority.virtuesanctity.virtuecare.virtueloyalty.virtue\n\u22120.006 \u22120.003 0.000 0.003\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FR\nFigure 20: MFT Parler\n1648", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Practical Guidelines for Ideology Detection Pipelines and Psychosocial Applications", "author": ["R Ram", "E Thomas", "D Kernot", "MA Rizoiu"], "pub_year": "2025", "venue": "Proceedings of the \u2026", "abstract": "Online ideology detection is crucial for downstream tasks, like countering ideologically  motivated violent extremism and modeling opinion dynamics. However, two significant issues"}, "filled": false, "gsrank": 802, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35892", "author_id": ["", "U3JInqYAAAAJ", "", "J9sjxXYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:S2Yrg___fg8J:scholar.google.com/&output=cite&scirp=801&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D800%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=S2Yrg___fg8J&ei=mLWsaPaIErXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:S2Yrg___fg8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/35892/38046"}}, {"title": "Hyperpt: detection and classification of hyperpartisan news articles", "year": "2021", "pdf_data": "HyperPT\nDetection and Classi/uniFB01cation of\nHyperpartisan News Articles\nMark Muscat\nSupervised by Dr Joel Azzopardi\nCo-supervised by Dr Colin Lay/uniFB01eld\nDepartment of Arti/uniFB01cial Intelligence\nFaculty of ICT\nUniversity of Malta\nAugust, 2020\nA dissertation submitted in partial ful/uniFB01lment of the requirements for the\ndegree of M.Sc. in Arti/uniFB01cial Intelligence .\n\n\nCopyright \u00a92021 University of Malta\nWWW .UM.EDU .MT\nFirst edition, February 12, 2021\n\nTo Fellow Researchers\nFor embarking on such journeys of self-betterment and contribution to the Research\nCommunity.\n\nvii\nAcknowledgements\nSeeing this project through was not an easy task, yet with the continuous help\nand support provided by mentors, friends and close relatives, I \ufb01nd myself at its\nconclusions.\nMy deepest gratitude goes to my supervisor, Dr. Joel Azzopardi and my co-\nsupervisor Dr. Colin Lay\ufb01eld, for their steady counselling and feedback guiding\nme all the way through from the project\u2019s inception to its end.\nA heartfelt thanks also goes to close friends with whom I embarked on this\njourney and shared experiences along the way. Thanks also goes to my family, for\ntheir constant support and help in managing such a task.\nLast but de\ufb01nitely not least, I am in\ufb01nitely grateful to Maria, my life companion\nto whom I dedicate this accomplishment for being there with me every step of the\nway, offering love, wisdom, and encouragement.\n\nix\nAbstract\nThe modern hyper-connected world brings with it an unprecedented rise in fake\nand hyperpartisan news, with anyone connected online harnessing the power of\nproducing such fabricated information. Hyperpartisan news can be de\ufb01ned as ex-\ntremely one-sided or biased news towards or against an entity. It differs from fake\nnews by often exaggerating and sensationalising real-life events. With the spread\nof such malicious information, the otherwise subjective opinion of vulnerable con-\nsumers is compromised, twisted and possibly manipulated by some ulterior agenda\n- resulting in unprecedented and damaging outcomes as already seen in now world-\nwide known incidents.\nWe hence give our contribution to addressing this issue by introducing Hy-\nperPT, a classi\ufb01cation system for the automatic detection of hyperpartisan news\narticles. Throughout this study we experiment with a number of data representa-\ntions, classi\ufb01cation algorithms and external article features with the aim of creating\nan accurate and reliable classi\ufb01cation system. In doing so gaining further insight\ninto the nature of the hyperpartisan news article.\nFrom our experiments we conclude on an SVM-based classi\ufb01cation system work-\ning on article features represented as deep contextualised ELMo embeddings. More-\nover, we test the addition of sentiment within the classi\ufb01cation while also experi-\nmenting with different news article lengths. Explainability A.I. is used to interpret\nthe model\u2019s decision-making and determine the in\ufb02uence of the article features on\nthe classi\ufb01cation. Finally we compare our system with the current state-of-the-art,\nachieving a mean accuracy score of 0.8220 to the other\u2019s 0.8404. In doing so we\nhence present an alternative system for the classi\ufb01cation of hyperpartisan news ar-\nticles.\nContents\n1 Introduction 1\n1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Proposed Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.3 Aims and Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4 Research Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.5 Document Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2 Background and Literature Review 9\n2.1 Hyperpartisan News Article Dataset . . . . . . . . . . . . . . . . . . . . . . 9\n2.1.1 PAN SemEval Hyperpartisan News Detection . . . . . . . . . . . . 10\n2.1.2 PAN SemEval Hyperpartisan News Dataset . . . . . . . . . . . . . 10\n2.2 Feature Preprocessing & Representation . . . . . . . . . . . . . . . . . . . . 13\n2.2.1 Data Preprocessing for Hyperpartisan News Articles . . . . . . . . 14\n2.2.2 Feature Representation for Hyperpartisan News Articles . . . . . . 16\n2.3 Classi\ufb01cation Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.3.1 Traditional Approaches . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.3.2 Deep Learning Approaches . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 Sentiment Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.4.1 Sentiment Analysis - Overview . . . . . . . . . . . . . . . . . . . . . 28\n2.4.2 VADER for Sentiment Analysis . . . . . . . . . . . . . . . . . . . . . 29\n2.5 Explainable A.I. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n2.5.1 Sensitivity Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n2.5.2 Layerwise Relevance Propagation . . . . . . . . . . . . . . . . . . . 31\n2.6 Evaluation Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n2.7 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nx\nContents xi\n2.7.1 Detection of Fake News . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.2 Detection of Hyperpartisan News . . . . . . . . . . . . . . . . . . . 37\n2.7.3 Sentiment in Hyperpartisan News Articles . . . . . . . . . . . . . . 42\n2.7.4 Model Interpretability and Saliency of Features . . . . . . . . . . . 43\n2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n3 System Methodology 47\n3.1 System Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n3.2 Data Loading, Preprocessing and Representation . . . . . . . . . . . . . . . 50\n3.2.1 Data Preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n3.2.2 Feature Representation . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n3.3 Classi\ufb01cation Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.3.1 Traditional ML Approaches . . . . . . . . . . . . . . . . . . . . . . . 53\n3.3.2 Deep Learning Approaches . . . . . . . . . . . . . . . . . . . . . . . 54\n3.3.3 System Implementation and Hyperparameter Tuning . . . . . . . . 56\n3.3.4 Adapting Feature Representations to the Classi\ufb01ers . . . . . . . . . 56\n3.4 External Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n3.4.1 Sentiment Features for Hyperpartisan News Classi\ufb01cation . . . . . 57\n3.4.2 Explainable A.I. for Model Interpretation and Feature Saliency . . 59\n3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n4 System Evaluation and Discussion 63\n4.1 Data Preprocessing and Representation . . . . . . . . . . . . . . . . . . . . 64\n4.1.1 Feature Representation for Hyperpartisan News . . . . . . . . . . . 65\n4.1.2 Data Preprocessing for Hyperpartisan News . . . . . . . . . . . . . 70\n4.1.3 Feature Representation and Data Preprocessing - Discussion . . . . 75\n4.2 Classi\ufb01er . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n4.2.1 Hyperparameter Tuning for Hyperpartisan News Classi\ufb01cation . . 76\n4.2.2 Evaluating HyperPT Classi\ufb01er performance . . . . . . . . . . . . . 81\n4.2.3 Classi\ufb01er for Hyperpartisan News Classi\ufb01cation - Discussion . . . 83\n4.3 External Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n4.3.1 Sentiment as a Feature for Hyperpartisan News . . . . . . . . . . . 84\n4.3.2 Title and Body of a Hyperpartisan News Article . . . . . . . . . . . 89\n4.3.3 Model Explainability and Saliency of Hyperpartisan Features . . . 92\n4.3.4 External Features of Hyperpartisan News - Discussion . . . . . . . 100\n4.4 HyperPT against the State-of-the-Art . . . . . . . . . . . . . . . . . . . . . . 100\n4.4.1 The State-of-the-Art in Hyperpartisan News Classi\ufb01cation . . . . . 101\nxii Contents\n4.4.2 HyperPT vs the State-of-the-Art - Discussion . . . . . . . . . . . . . 101\n4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n5 Conclusions 105\n5.1 Achieved Aims and Objectives . . . . . . . . . . . . . . . . . . . . . . . . . 106\n5.1.1 Features of a Hyperpartisan News Article . . . . . . . . . . . . . . . 106\n5.1.2 Sentiment of a Hyperpartisan News Article . . . . . . . . . . . . . . 106\n5.1.3 Minimum length of text for an Article to be Hyperpartisan . . . . . 107\n5.1.4 Classi\ufb01er for Hyperpartisan News Articles . . . . . . . . . . . . . . 107\n5.1.5 Interpretation of the Classi\ufb01er . . . . . . . . . . . . . . . . . . . . . 107\n5.2 Critique and Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n5.3 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n5.4 Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\nReferences 111\nList of Figures\n1.1 A sample hyperpartisan news article . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.2 A sample non-hyperpartisan news article . . . . . . . . . . . . . . . . . . . . . 2\n2.1 A sample hyperpartisan-\ufb02agged news article in XML form. . . . . . . . . . . . 11\n2.2 A sample article title with punctuation removed. . . . . . . . . . . . . . . . . . 15\n2.3 Stemming using Porter\u2019s and Snowball . . . . . . . . . . . . . . . . . . . . . . 15\n2.4 Basic architecture of a Word2Vec CBOW . . . . . . . . . . . . . . . . . . . . . . 19\n2.5 SVM Hyperplanes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.6 A sentence classi\ufb01cation using CNN . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.7 Basic architecture of a biRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.8 A.I. interpretability using SA and LRP . . . . . . . . . . . . . . . . . . . . . . . 33\n2.9 The biLSTM Self-Attention Mechanism . . . . . . . . . . . . . . . . . . . . . . 44\n3.1 The HyperPT Design Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n4.1 Performance of Data Representation Techniques . . . . . . . . . . . . . . . . . 69\n4.2 Performance of Embedded Sentiment Features . . . . . . . . . . . . . . . . . . 88\n4.3 Evaluation of LRP on the SVM Classi\ufb01er . . . . . . . . . . . . . . . . . . . . . . 93\n4.4 Evaluation of LRP on the CNN Classi\ufb01er . . . . . . . . . . . . . . . . . . . . . 94\n4.5 A hyperpartisan news article classi\ufb01ed using SVM and examined using LRP . 95\n4.6 A neutral news article classi\ufb01ed using SVM and examined using LRP . . . . . 96\n4.7 A hyperpartisan news article classi\ufb01ed using CNN and examined using LRP 97\n4.8 A neutral news article classi\ufb01ed using CNN and examined using LRP . . . . 97\nxiii\nList of Tables\n2.1 Sample NLTK English Stopwords . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1 Article and Sentence level Sentiment . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.1 Accuracy scores for individual Data Preprocessing using SVM. . . . . . . . . 66\n4.2 Accuracy scores for individual Data Preprocessing using RF. . . . . . . . . . . 67\n4.3 Accuracy scores for individual Data Preprocessing using CNN. . . . . . . . . 68\n4.4 Accuracy scores with ELMo embedded features . . . . . . . . . . . . . . . . . 71\n4.5 Accuracy results for aggregate Data Preprocessing techniques. . . . . . . . . . 73\n4.6 SVM classi\ufb01er hyperparameters tested using Grid-Search. . . . . . . . . . . . 77\n4.7 RF classi\ufb01er hyperparameters tested using Grid-Search. . . . . . . . . . . . . . 78\n4.8 CNN classi\ufb01er hyperparameters tested using Grid-Search. . . . . . . . . . . . 80\n4.9 Mean and highest classi\ufb01er accuracy and F1 results. . . . . . . . . . . . . . . . 82\n4.10 Accuracy and F1 Scores using different sentiment embedding techniques . . . 86\n4.11 Accuracy and F1 Scores on article title and body . . . . . . . . . . . . . . . . . 90\n4.12 Most salient hyperpartisan and neutral words . . . . . . . . . . . . . . . . . . 99\n4.13 Mean and highest accuracy scores for HyperPT vs. State-of-the-Art . . . . . . 102\nxiv\nList of Abbreviations\nA.I. Arti\ufb01cial Intelligence\nBERT Bidirectional Encoder Representations from Transformers\nBoW Bag-of-Words\nCNN Convolutional Neural Network\nDL Deep Learning\nELMo Embeddings from Language Models\nGloVe Global Vectors\nLRLogistic Regression\nLRP Layerwise Relevance Propagation\nLSTM Long Short-Term Memory\nML Machine Learning\nNLP Natural Language Processing\nNLTK Natural Language Toolkit\nPOS-Tags Part-of-Speech Tags\nRBF Radial Basis Function\nRFRandom Forest\nRNN Recurrent Neural Network\nSA Sensitivity Analysis\nSVM Support Vector Machine\nTFTerm Frequency\nTF-IDF Term Frequency - Inverse Document Frequency\nV ADER Valence Aware Dictionary for sEntiment Reasoning\nXAI Explainable A.I.\nxv\n\n1\nIntroduction\nDuring the 2016 United States elections, a data analytics company by the name of Cam-\nbridge Analytica is alleged to have purposely fabricated and spread false and targeted\nnews with the aim of altering the outcome of the elections and possibly also the result-\ning Presidency [Berghel (2018)]. The \ufb01rm is alleged to have exploited a vulnerability\nin a Facebook App allowing them to not only gather data on the users using the ap-\nplication, but also on all of their Facebook friends. The personal pro\ufb01les of around 50\nmillion people were exposed and targeted by speci\ufb01c, biased and hyperpartisan adver-\ntisements - personalised towards the different classes of pro\ufb01les mined from this breach,\npotentially effecting the people\u2019s perception and voting at a mass scale throughout the\nelections [Berghel (2018); Cadwalladr and Graham-Harrison (2018a,b)].\n1.1 | Motivation\nHyperpartisan news is de\ufb01ned as extremely one-sided, or biased news [Potthast et al.\n(2018)]. It is often pushed by a hidden agenda towards or against a speci\ufb01c entity or\ngroup of entities. Hyperpartisan news typically makes use of overly dramatic headlines\nand in\ufb02ammatory wording with the aim of quickly capturing the reader\u2019s attention.\nNews is reported with a degree of bias, with the author frequently including opinion-\nated commentary on the reported material.\nDifferent to fake news - which can be considered as containing a degree of fabri-\ncated untruths, hyperpartisan news often reports on actual, authentic events, although\nin a biased way. Despite this, both fake and hyperpartisan news articles typically con-\ntain the use of in\ufb02ammatory and sensationalised vocabulary [Potthast et al. (2018)].\nFact-checking, a useful tool for the evaluation of fake news, is not a potent solution\nfor hyperpartisan news, which due to the exaggerated reporting of real events, makes\n1\nChapter 1. Introduction 1.1. Motivation\nthe detection of such news even more challenging. Two snippets, one of a hyperparti-\nsan, and the other of a non-hyperpartisan news articles can be respectively examined in\nFigure 1.1 and Figure 1.2.\nFigure 1.1: A sample hyperpartisan news article1- labelled through crowd-sourcing.\nFigure 1.2: A sample non-hyperpartisan (neutral) news article2- labelled through crowd-\nsourcing.\nIn Figure 1.1, strong words such as infamous, brags, impunity are used, while unneces-\nsary opinionated expressions like just in case the president had any doubts are also present.\nMoreover, the then president of the United States, Donald Trump, is referred to simply\nby his name. This contrasts to the concise approach employed in Figure 1.2, where both\n1\u2018Access Hollywood\u2019 to Trump: The tape is \u2018very real\u2019 - www.dailydot.com [Last Accessed: 07-2020]\n2Trump Tweets: \u2019We Will Be Taking Strong Action Today\u2019 on SW Border - www.cnsnews.com [Last\nAccessed: 07-2020]\n2\nChapter 1. Introduction 1.2. Proposed Solution\nthe headline and the article body are clear on their message, and the same individual is\naddressed by his full title ( President Donald Trump ).\nThe emergence and widespread distribution of hyperpartisan news inspires us to\nexplore this domain from the lens of A.I., putting to use the power of Machine Learn-\ning (ML) [Michie et al. (1994)] at attempting to provide a pragmatic and ef\ufb01cient tool\nagainst the spread of such malicious information. Without these tools the sharing of\nhyperpartisan news goes uncontrolled, quickly overshadowing genuine, neutral news\nwith its dramatic and sensationalised nature. Moreover, readers themselves often share\nsuch news with their peers before actively checking for authenticity, further speeding\nup the sharing process [Tambuscio et al. (2015)].\nOne \ufb01nds notable progress already made in addressing both fake news and hyper-\npartisan news [Kiesel et al. (2019); Potthast et al. (2018)]. In the domain of fake news\nwe see approaches tackling the spread, stylistic writing and content within, with the\nhopes of detecting such news early on, hindering its tendency to quickly spread and\naffect consumers online. Being arguably less known than fake news, we see this as an\nopportunity to pitch in our contribution in detecting hyperpartisan news - building on\npromising published work with the idea of further improving on the state-of-the-art and\nexpanding on existing research. In doing so, we aim at not only introducing an ef\ufb01cient\nand reliable hyperpartisan news detection system, but also at examining the very nature\nof the hyperpartisan news article, with the hopes that this would inspire us along with\nfellow researchers, to extend on the existing research.\n1.2 | Proposed Solution\nIn detecting hyperpartisan news articles, we feel that due to the often dramatic and sen-\nsationalised nature of such articles, the content within the article and its style of writing\nis the best medium to analyse. We hence form this challenge as a Machine Learning\n(ML) classi\ufb01cation problem, where we represent the article data features as numerical\nvectors which are then passed to a classi\ufb01cation algorithm, in turn giving us a corre-\nsponding prediction label de\ufb01ning whether the inputted document is hyperpartisan or\nneutral.\nBeing the direct medium upon which the classi\ufb01cation process is performed, the fea-\ntures within a hyperpartisan news article are crucial to an accurate and reliable classi\ufb01-\ncation. One must \ufb01rst suf\ufb01ciently clean the dataset from any noise and inconsistencies\nbefore classi\ufb01cation takes place. Moreover, representation techniques converting the\notherwise textual data being passed to the classi\ufb01er are themselves a crucially impor-\n3\nChapter 1. Introduction 1.3. Aims and Objectives\ntant step throughout the whole classi\ufb01cation process. As we see further on in Chapter 4,\nboth data preprocessing and the corresponding data representations are pivotal to the\noverall performance.\nExpanding further on the features making up the news articles, we feel that direct\ninterpretation of the classi\ufb01ers\u2019 decision-making through explainability algorithms may\nallow us to determine precisely the logic responsible for the classi\ufb01er\u2019s behaviour lead-\ning up to such a classi\ufb01cation. In other words, we de\ufb01ne the article features contribut-\ning, or opposing, to the resulting classi\ufb01cation label.\nThorough experimentation is considered, testing different lengths of hyperpartisan\nnews articles along with the inclusion and exclusion of the article title. Such tests are\nperformed with the intention of determining whether short texts such as tweets or sim-\nply article headlines can also be hyperpartisan, and whether the full length of a typical\nhyperpartisan news article would be necessary for reliable detection of such content. In\ndoing so, one would be more knowledgeable as to which article lengths tend to be more\nprone to hyperpartisanship, and whether simpler forms of text are also vulnerable to\nsuch malicious information.\nFurthermore, the sensationalised writing typically associated with hyperpartisan\nnews raises interest as to the potential role sentiment may play in the detection of such\nnews. Basing on the observations of similar systems [Kiesel et al. (2019)] that heavy\nsentimental elements tend to be present within such texts, we take into consideration\nthe detection of sentiment within hyperpartisan articles and \ufb01nd a way of testing them\nintegrated along with the rest of the detection process.\nFinally, we evaluate three promising classi\ufb01cation algorithms (Random Forest [RF],\nSupport Vector Machine [SVM] and Convolutional Neural Network [CNN]) currently\nin use in both similar systems on the same area of research and imported from other\ndisciplines. We compare the performance of these algorithms with that of one another\nalong with similar published work in order to settle on the best performing classi\ufb01cation\nmodel, thereby developing and evaluating our hyperpartisan news article classi\ufb01cation\nsystem.\n1.3 | Aims and Objectives\nThrough our proposed solution discussed in Section 1.2, we hence intend to create a\npragmatic and reliable hyperpartisan news detection system. In doing so, we aim at\ngaining insight into the nature of the hyperpartisan article itself, with the hopes that\nthis may further aid us and future research in improving the work conducted.\n4\nChapter 1. Introduction 1.3. Aims and Objectives\nWe hence divide our project into \ufb01ve individual yet complementary objectives which\nwe plan to address in order to achieve our main goal:\n1.Features of a Hyperpartisan news article : Discover the most salient features indicat-\ning that a news article is hyperpartisan. Some features may prove to have more\nin\ufb02uence on the classi\ufb01cation outcome than others. In analysing the saliency of\neach feature, we could determine which features are the most important.\n2.Sentiment of a Hyperpartisan news article : Experiment with different sentiment in-\ntegration techniques and examine their effects on the detection of hyperpartisan\nnews articles.\n3.Minimum length of text for an article to be Hyperpartisan : Determine the least amount\nof textual data that is required for an article to be classi\ufb01ed as hyperpartisan. Does\nthe title suf\ufb01ce, or does the article body play a crucial part as well? If so, what is\nthe ideal body length?\n4.Classi\ufb01er for Hyperpartisan news articles : Harnessing the knowledge acquired from\nthe previous points, research and develop the best performing classi\ufb01cation sys-\ntem for the detection of hyperpartisan news articles.\n5.Interpretation of the Classi\ufb01er : Use the capabilities brought forward by Explainable\nA.I. - specialised methods capable of analysing the classi\ufb01er and its logic, to inter-\npret the model\u2019s decision-making behind its classi\ufb01cations. In doing so one could\nthen determine the model\u2019s generalisation capabilities and its reliability.\nWith the data features and preprocessing stages playing such a pivotal role within\nthe classi\ufb01cation process, we feel that the attention given to the typical characteristics of\nhyperpartisan articles (as detailed in the \ufb01rst three objectives) is of bene\ufb01t to both our\nstudy and future work. We therefore take into consideration not only the article textual\nfeatures, but also the sentiment, length of the article body, and role of the article title\n- with the hopes that these would provide further insight into the importance of such\nattributes.\nMoreover, we evaluate three classi\ufb01cation algorithms, the RF, SVM, and CNN. These\nthree approaches are chosen from research conducted on related work purposely for the\nclassi\ufb01cation of hyperpartisan news articles. In evaluating these classi\ufb01ers we monitor\ntheir accuracy and performance while also using specialised approaches for the direct\ninterpretation of the model\u2019s behaviour. In doing so we aim at determining whether\nthe model\u2019s approach is as intended, while also attempting at predicting its expected\nperformance with the classi\ufb01cation of new data samples.\n5\nChapter 1. Introduction 1.4. Research Contributions\n1.4 | Research Contributions\nIn tackling the objectives highlighted in Section 1.3, we introduce HyperPT - our con-\ncept for a hyperpartisan news article detection system. We aim at improving on already\npublished research, focusing on the features within hyperpartisan news articles and em-\nploying ML techniques to create a reliable classi\ufb01cation system. Such a system would\nneed to have the capability of assessing whether an article is of a neutral or hyperpar-\ntisan nature. In building the HyperPT system, we attempt at tackling two individual\naspects simultaneously; the proposal and building of an accurate and reliable classi\ufb01ca-\ntion system, and the discovery of further knowledge of the typical nature of hyperpar-\ntisan news content.\nIn conducting our study, we research reputable classi\ufb01cation solutions within the\nML discipline and moreover in the detection of hyperpartisan news content. Following\nour research, we choose the Support Vector Machine (SVM), Random Forest (RF) and\nConvolutional Neural Network (CNN) as our three candidate classi\ufb01ers. Tests are per-\nformed with a number of data preprocessing and various feature representation tech-\nniques - both those of a traditional nature (Bag-of-Words [BoW], Term Frequency - In-\nverse Document Frequency [TF-IDF], Part-of-Speech Taggings [POS-Tags]) and those\nmore associated with modern Deep Learning approaches, namely word embeddings\n(Word2Vec, GloVe, ELMo, and BERT).\nWe compare the performance of the RF, SVM and CNN; 1) Finding the optimal fea-\nture representation and hyperparameter con\ufb01guration for maximising the classi\ufb01cation\naccuracy of each classi\ufb01er, 2) Comparing and contrasting the classical ML classi\ufb01ers\nwith the more elaborate DL [LeCun et al. (2015)] classi\ufb01ers, and \ufb01nally 3) Choosing the\nbest performing system among the three classi\ufb01ers, after evaluating the techniques\u2019 per-\nformance and results acquired in the second step. Experiments conducted compel us to\nsettle on the SVM classi\ufb01er (Chapter 4), in doing so giving our thoughts on the reasons\nbehind the clear performance superiority over the two other candidates.\nSimultaneously with the experiments above, we explore both the hyperpartisan ar-\nticle textual features and external characteristics, namely sentiment, the article title and\nlength of article body. Inspired by similar work and the sensationalised nature typically\nfound within such articles, we particularly experiment with different incorporations of\nthe sentiment within, integrating sentiment score and labels in several con\ufb01gurations\namong the internal features de\ufb01ning the original articles. With the unexpected hin-\ndrance to the system performance resulting from the addition of sentiment, we hypoth-\nesise on the underlying explanations.\nFinally, we implement and evaluate a model explanation technique known as Layer-\n6\nChapter 1. Introduction 1.5. Document Structure\nwise Relevance Propagation (LRP) to interpret the decision-making of our classi\ufb01cation\nmodels - particularly the SVM and the CNN. This in itself gives us two bene\ufb01ts; the\n\ufb01rst and most obvious is that it allows us to gauge the performance of the classi\ufb01er,\ndetermining whether it is working as intended and if is capable of generalising to new\ndata samples. Simultaneously however, this also allows us to explore the news article\nfeatures and their saliency within the classi\ufb01cation. Analysing the acquired saliency\nresults, we notice a correlation between entities (namely individuals and events) ad-\ndressed within the articles and the corresponding hyperpartisan labels.\n1.5 | Document Structure\nThroughout this document we describe our approach to implementing the HyperPT\nstudy into \ufb01ve chapters as follows:\n1.Introduction - Throughout the Introduction, we have discussed the problem pre-\nsented by fake and hyperpartisan news articles. We have proposed \ufb01ve main ob-\njectives which we aim to tackle, thereby not only presenting an accurate and reli-\nable classi\ufb01cation system, but also exploring further the nature of hyperpartisan\nnews articles.\n2.Background and Literature Review - Before delving into the proposed system,\nwe \ufb01rst provide a concise background on algorithms and approaches which are\nin some way relevant to the project. This is followed by an elaborate review of\nrelated work, highlighting systems employing solutions for the detection of fake\nand hyperpartisan news articles.\n3.System Methodology - The system methodology is presented and discussed, where\nwe detail our approach, reasoning behind decisions taken, and physical imple-\nmentation of the system. Visualised also as a \ufb02owchart, we discuss the three main\ncomponents making up the HyperPT system, along with smaller subcomponents\nutilised ad hoc as preprocessing and runtime steps.\n4.System Evaluation and Discussion - We evaluate the three proposed classi\ufb01ca-\ntion algorithms by comparing them altogether. Tests are performed using a range\nof different data preprocessing and representation techniques, including the addi-\ntion of sentiment features. Finally, the LRP explainability algorithm is evaluated,\nbefore utilised for determining the article feature saliency.\n7\nChapter 1. Introduction 1.5. Document Structure\n5.Conclusions - Throughout this conclusive chapter, our \ufb01nal remarks on the Hy-\nperPT project are given. We discuss the implemented system, its limitations and\npotential future work - which would undoubtedly further extend and improve on\nthe work conducted here.\n8\n2\nBackground and Literature Review\nHaving discussed the reality behind hyperpartisan news articles and the problem they\nentail, we introduced our system, HyperPT, for the detection of such malicious con-\ntent. Before delving further into the system and its components, we now give a concise\nbackground on technologies and approaches which are either an inspiration to, or are\ndirectly used within HyperPT.\nThroughout this chapter, we \ufb01rst examine the SemEval Hyperpartisan News Arti-\ncles Dataset (Section 2.1), which is the main and only dataset upon which the HyperPT\nsystem is built. We proceed by discussing feature preprocessing and representation\nmethods in Section 2.2. A selection of classi\ufb01ers is analysed in Section 2.3, thereby com-\npleting the baseline classi\ufb01cation system.\nThe subsequent two sections; Section 2.4 and Section 2.5, would then respectively\nfocus on sentiment features and model explainability. This is followed by an overview\nof the project\u2019s evaluation criteria, discussed in Section 2.6. Finally, in Section 2.7 we\npresent a review of related systems employing the approaches detailed previously (or\nsimilar techniques). With this we conclude the chapter and proceed to the design and\nimplementation process, detailed in Chapter 3.\n2.1 | Hyperpartisan News Article Dataset\nBefore delving into the algorithms themselves, we \ufb01rst discuss the dataset supplying\nus with both hyperpartisan and neutral labelled articles. In Section 2.1.1 we discuss the\nPAN SemEval Hyperpartisan News Detection [Kiesel et al. (2019)] competition, a chal-\nlenge through which the organisers introduce the Hyperpartisan News dataset, while\nkickstarting research on the topic of hyperpartisan news detection. The corresponding\ndataset is thoroughly discussed right after in Section 2.1.2.\n9\nChapter 2. Background and Literature Review 2.1. Hyperpartisan News Article Dataset\n2.1.1 | PAN SemEval Hyperpartisan News Detection\nPAN1is a series of scienti\ufb01c events and a community of shared knowledge on digital text\nand stylometry. Among the range of hosted competitions, one \ufb01nds the PAN SemEval\nHyperpartisan News Detection competition2, held in 2019.\nThe objective of the task is simple, given a dataset consisting of labelled mainstream\nand hyperpartisan news articles, create a system which is able to ef\ufb01ciently and reli-\nably distinguish between the two. In all, 42 teams took part, with Jiang et al. (2019),\nalso known as team Bertha Von Suttner, achieving a classi\ufb01cation accuracy of 0.84 and\nwinning the SemEval Hyperpartisan News Detection competition.\n2.1.2 | PAN SemEval Hyperpartisan News Dataset\nThe dataset3presented for the PAN SemEval Hyperpartisan News Detection is assem-\nbled by Kiesel et al. (2019). It is split into two parts, known as the By-Article collection\nand the By-Publisher collection.\nBoth collections within the dataset contain articles of both left-wing and right-wing\nagendas, yet since both agendas have been shown to share more stylistic similarities be-\ntween them than with mainstream news [Potthast et al. (2018)], we refrain from taking\ninto consideration any political sides, and focus our full attention on the binary classi\ufb01-\ncation of whether an article is hyperpartisan or neutral.\nThe By-Article collection consists of 1273 articles labelled through crowdsourcing on\nan article basis. In other words, each article is peer-reviewed by multiple individuals,\nwith an overall agreement on whether it is of a hyperpartisan or neutral nature. Of these\narticles, solely 645 are made public (and used by external studies such as ours), with the\nrest being maintained privately for the evaluation of competing systems. Of these 645,\n37% (238) are hyperpartisan, with the other 63% (407) of articles being mainstream.\nThe By-Publisher collection on the other hand is signi\ufb01cantly larger and consists of\n754, 000 articles; 600, 000 of which are released as a public dataset, with the remaining\nbeing split into a public validation set (150, 000) and a private evaluation set (4000).\nAll of these sets consist of 50% hyperpartisan and 50% mainstream articles. Different\nto the By-Article collection, these articles are labelled by the overall bias label of their\npublishing source, as given by BuzzFeed journalists and MediaBiasFactCheck4. This\n1PAN Scienti\ufb01c Events - pan.webis.de [Last Accessed: 07-2020]\n2PAN SemEval Hyperpartisan News Detection (2019) - pan.webis.de/semeval19 [Last Accessed: 07-\n2020]\n3PAN SemEval Hyperpartisan News Dataset - www.zenodo.org [Last Accessed: 07-2020]\n4MediaBiasFactCheck - www.mediabiasfactcheck.com [Last Accessed: 07-2020]\n10\nChapter 2. Background and Literature Review 2.1. Hyperpartisan News Article Dataset\nFigure 2.1: A sample hyperpartisan-\ufb02agged news article5in XML form as supplied by\nKiesel et al. (2019) for the SemEval Hyperpartisan News Detection competition and the\npublic.\nimplies that a hyperpartisanship label is assigned to the publishing entity, with all of its\npublished articles inheriting the same label.\nThe dataset is made available publicly following the SemEval event, and is down-\nloadable on request. We acquired it in XML format (as shown in Figure 2.1), with plans\nto give our contribution to the \ufb01eld of hyperpartisan news detection, evaluating our\nsystem on the same grounds as other published systems. Each article in XML form con-\nsists of a unique article ID, article title, date of publication, article URL and the article\nbody. A separate XML \ufb01le known as the ground truth is provided, containing the corre-\nsponding hyperpartisan labels for each article. Each article label is of a Boolean nature,\nindicating whether the article is hyperpartisan (True) or neutral (False).\nInside the article body, one often \ufb01nds links to other related webpages [Jiang et al.\n(2019); Ning et al. (2019)]. These are represented using the URL <a href> tag, and sit\namong the rest of the article textual features. Moreover, being directly scraped off web-\npages, other unwanted text such as advertisements is sometimes included with the ar-\nticle body. We observed that a distinguishing factor between these types of texts and\nthe actual article body is the <p> tags, since article-relevant body text is typically found\nwithin these tags.\n2.1.2.1 | Dataset Labelling for Classi/uniFB01cation\nAs reported by a number of participating teams [Alabdulkarim and Alhindi (2019);\nHanawa et al. (2019); Pali\u00b4 c et al. (2019); Yeh et al. (2019)], the By-Article collection within\nthe dataset is notably more reliable in its labellings than the By-Publisher, resulting in a\n5Trump Just Woke Up & Viciously Attacked Puerto Ricans On Twitter Like A Cruel Old Man - www.\nbipartisanreport.com [Last Accessed: 07-2020]\n11\nChapter 2. Background and Literature Review 2.1. Hyperpartisan News Article Dataset\nsubstantially better training dataset and better classi\ufb01er performance. The authors sug-\ngest that this is since labelling performed on the By-Article collection is personalised to\neach article, while labelling on the By-Publisher collection is done as an aggregate pro-\ncess based on the typical bias of the publishing entity. This is despite the varying levels\nof hyperpartisanship across the published articles - since it is unlikely for every article\nto have the same consistent levels of hyperpartisan bias.\nPoor or inconsistent labelling containing high degree of noise makes it more dif\ufb01-\ncult for the classi\ufb01er to train and generalise properly on the training data - as is appar-\nent in research conducted by similar systems. Indeed one observes large performance\ndiscrepancies among the same classi\ufb01cation systems when trained on the By-Publisher\ncollection to when trained on the By-Article [Kiesel et al. (2019)]. Pali\u00b4 c et al. (2019) train\nan SVM classi\ufb01er on both collections, with the By-Article achieving accuracies upwards\nof 75% and the By-Publisher in the ranges of 58% to 62%. Similarly, one \ufb01nds systems\nsuch as Jiang et al. (2019) and Isbister and Johansson (2019) which boast state-of-the-art\nperformance when training on the By-Article collection, yet suffer signi\ufb01cantly on the\nBy-Publisher. Other studies choose to ignore the latter collection altogether [Kiesel et al.\n(2019)].\nOne \ufb01nds various approaches in trying to address the limitations imposed by poor\ndata labelling. Several systems use just segments of the By-Publisher collection in or-\nder to aid in the classi\ufb01cation process. Hanawa et al. (2019) extract N-grams from the\nBy-Publisher collection in order to assemble a phrase set to be used as features along\nwith the primary classi\ufb01cation on the By-Article collection. Similarly, Drissi et al. (2019)\nuse the By-Publisher collection for further training following initial training on the By-\nArticle collection.\nAlternatively, similar systems attempt at de-noising and re-labelling the data points\navailable within the dataset. Lee et al. (2019) use pseudo-labelling, a semi-supervised\nlearning approach, to \ufb01lter out noisy labels from within the By-Publisher collection by\napproximating new labels. In doing so, the authors extract a de-noised dataset of around\n32, 000 articles. On Similar terms, P\u00e9rez-Almendros et al. (2019) train two SVMs and a\nBiLSTM on the By-Article collection, before applying them as a meta-classi\ufb01er on the\nBy-Publisher collection. In this way, articles having the corresponding label matching\nthe classi\ufb01cation are kept, while all others are discarded.\nThe newly emerging discipline of Explainable A.I. (XAI) [Goebel et al. (2018); Samek\net al. (2017)] may provide further tools with which one is able to determine the quality\nof the labels and the levels of noise within a dataset. In case of having a dataset with a\nvolume of noisy labels, as is reportedly the case for the By-Publisher article collection,\nXAI can be used to analyse the classi\ufb01er\u2019s decision-making and determine whether the\n12\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\nlogic behind it is both correct and reliable [Gade et al. (2019); Goebel et al. (2018)]. In\nthis way one could identify pivotal features within the classi\ufb01cation, and \ufb01ne-tune the\nclassi\ufb01cation system accordingly. Having a \ufb01ne-tuned system, one could then compare\nthe noisy dataset labels with those predicted, and replace the noisy labels with the newly\npredicted ones, thereby attempting to de-noise the dataset.\nBeing a novel subject within the area of A.I., we do not, at the time of writing, \ufb01nd\nany published work attempting to use this method for the de-noising of the SemEval\nHyperpartisan By-Publisher article collection. Having said so, one does \ufb01nd a minority\nof similar systems [Amason et al. (2019); Zhang et al. (2019)] employing XAI for the\nidenti\ufb01cation of salient features, as discussed further in Section 2.7.4.\nWith a limited amount of time available for the project development, we employ\nsolely the By-Article collection for the detection of hyperpartisan news articles. We de-\ncide against incorporating the By-Publisher collection as well since this would enlarge\nthe already elaborate scale of the project. Having said so, we do think there is poten-\ntial in considering, as future work, the de-noising and integration of the By-Publisher\ncollection within the classi\ufb01cation of hyperpartisan news articles.\nWith a concise overview of the Hyperpartisan dataset, in Section 2.2 we now pro-\nvide an elaborate background on the techniques used in building the HyperPT study,\ndiscussing the methodology behind each approach.\n2.2 | Preprocessing and Representation of Hyperparti-\nsan News Article Features\nThe extraction, selection and preparation of data features is a crucial part of the process\nin addressing any ML problem - in our case; the prediction of hyperpartisan articles. The\nperformance of any classi\ufb01cation model strongly depends on the condition and quality\nof the features it is given. It is thereby important that data is cleaned and represented in\nsuch a way that is optimised and ideal for the classi\ufb01er to work with.\nIn Section 2.2.1 we examine the preprocessing typically applied to textual features\nbefore textual classi\ufb01cation tasks. In Section 2.2.2 we then examine traditional and\nDL feature representation approaches for textual data. Traditional systems include the\nwidely used Bag-of-Words and TF-IDF approaches, among others, while coming to DL,\nwe then open up on the concept of Word Embeddings.\n13\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\n2.2.1 | Data Preprocessing for Hyperpartisan News Articles\nBefore being effectively processed by a classi\ufb01cation system, data features typically pass\nthrough a preprocessing layer, in order to be re\ufb01ned as much as possible. When working\nwith textual features, data preprocessing and cleaning often entails:\n\u0004Removal of stopwords\n\u0004Removal of punctuation\n\u0004Lowercasing of features\n\u0004Reducing features to their stem or lemma\nStopword Removal: Stopwords are de\ufb01ned as words which are equally common in\nboth documents relevant to a query and documents which are non-relevant [Wilbur\nand Sirotkin (1992)]. In other words, they are common features which do not typically\ngive any relevant information on a speci\ufb01c subject, but are simply in the text to complete\nthe lexical structure of the language. The Natural Language Toolkit (NLTK) [Bird et al.\n(2009); Loper and Bird (2002)] is an open source language toolkit which comes precon-\n\ufb01gured with a list of 127 English stopwords (some of which are displayed in Table 2.1)\nwhich is often used to easily clarify which words to exclude from a given text snippet.\ndo but at\ndoes if by\ndid or for\ndoing because with\na as about\nan until against\nthe while between\nand of into\nTable 2.1: A sample of 24 stopwords within NLTK for the English Language.\nPunctuation Removal: In tokenising the features of a given text, punctuation may also\nbe removed [Ning et al. (2019); Zehe et al. (2019)]. Along with the removal of stopwords,\nthis step further cleans the textual features, reducing them to individual words as show-\ncased in Figure 2.3. Typically, one simply removes the punctuation characters within a\ntext snippet, or replaces each one \u02d9c with a white-space.\n6\u2018Access Hollywood\u2019 to Trump: The tape is \u2018very real\u2019 - www.dailydot.com [Last Accessed: 07-2020]\n14\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\nFigure 2.2: A sample hyperpartisan-\ufb02agged news article6title with and without punctu-\nation.\nFeature Lowercasing: One may also consider lowercasing all words such that any up-\npercased or capitalised words are \u2019normalised\u2019 to lowercase along with the rest of the\ncorpus. We \ufb01nd systems such as Shaprin et al. (2019) and Sengupta and Pedersen (2019)\nemploying such procedures for the cleaning of hyperpartisan articles.\nFeature Stemming: Moreover, stemming reduces each word to its root form by remov-\ning its suf\ufb01x. In doing so, words which inherently carry the same meaning yet are writ-\nten differently are reduced to their common root, thereby reducing the data complexity\nand removing any possibility of the words being understood, and treated, differently.\nStemming is adapted to the \ufb01eld of hyperpartisan news classi\ufb01cation by systems such\nas Cruz et al. (2019) and Pali\u00b4 c et al. (2019).\nPorter\u2019s Stemmer [Jones and Willett (1997); Porter et al. (1980)] and Snowball [Porter\n(2001)] are two well-known stemming algorithms. Simply removing the suf\ufb01x from the\nword, Porter\u2019s Stemmer is considered as a more basic (nonetheless effective) stemmer.\nSnowball (also known as Porter2) is universally considered as a better, more aggressive\nstemmer to Porter\u2019s [Wiese et al. (2011)]. It does not simply remove the suf\ufb01x of the\nword, but also considers the context of the word and the lexical rules of the language in\nwhich it is written. Moreover, multi-language support and faster execution times to its\npredecessor are features of Snowball.\nFigure 2.3: A sample of few words reduced to their stem using the Porter\u2019s and Snowball\nStemmers. Source: The English (Porter2) stemming algorithm7.\n15\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\nFeature Lemmatisation: An effective alternative system to stemming is lemmatisa-\ntion. Lemmatisation makes use of lexical databases such as WordNet [Miller (1995)] to\nremove in\ufb02ection from a given word and reduce it to its lemma (dictionary form), typi-\ncally achieving better results than stemming [Balakrishnan and Lloyd-Yemoh (2014)]. It\nis a more elaborate process than stemming since the Part-of-Speech (POS) of each word\nis taken into consideration.\nThis added complexity is however often preferred to stemming, with studies such\nas Joo and Hwang (2019) and Pali\u00b4 c et al. (2019) effectively incorporating lemmatisation\nin order to reduce the complexity of terms making up news articles provided for hy-\nperpartisan classi\ufb01cation. In building the HyperPT system, we decided on employing\nlemmatisation due to its reliability and ready to use NLTK support for the WordNet\nlemmatiser8.\n2.2.2 | Feature Representation for Hyperpartisan News Articles\nHaving discussed data preprocessing adapted within HyperPT, we now examine some\nof the most prominent and widely used feature representation approaches for textual\ndata in the \ufb01eld of NLP and more speci\ufb01cally the detection of hyperpartisan articles.\nIn Section 2.2.2.1 we \ufb01rst examine traditional approaches, giving a concise overview\nof each. Approaches discussed are the BoW model, TF-IDF and POS-Tagging. This\nis followed by Section 2.2.2.2 where we discuss word embedding technologies for DL\nmodels, namely Word2Vec, GloVe, ELMo, and \ufb01nally BERT.\n2.2.2.1 | Traditional Feature Representation Approaches\nBag-of-Words (BoW): A very common approach for textual features representation is\nstripping a textual body of its structure, representing it as a list of unique words coupled\nwith their frequency of appearance throughout the document. This is known as the Bag-\nof-Words (BoW) model and is a very popular feature representation method for textual\ndata [Amason et al. (2019); Bestgen (2019); Potthast et al. (2018); Saleh et al. (2019)].\nThe BoW model is easy to understand, simple to implement and an effective baseline\napproach for the representation of textual features. Due to the simplistic nature of the\nBoW model, one does not get any insight into the importance of textual features besides\nthe number of occurrences of each word contained within. Therefore unique, important\nwords and common unimportant ones are treated with the same prominence - if not less\ndue to the more frequent occurrences of the latter.\n7The English (Porter2) stemming algorithm - snowball.tartarus.org [Last Accessed: 07-2020]\n8NLTK Stemming & Lemmatisation - www.nltk.org [Last Accessed: 07-2020]\n16\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\nTerm Frequency - Inverse Document Frequency (TF-IDF): TF-IDF [Jones (1972); Wu\net al. (2008)] is a feature representation which reduces the importance value of a term the\nmore common it is throughout all of the corpus, thereby highlighting words which are\ncommon to a document yet rare across the rest of the dataset as important, and common\nwords all throughout as insigni\ufb01cant.\nTF-IDF calculates the weight of each feature based on two calculations. First, the\nnormalised term frequency (TF) inside of the document is computed. To do so we take\nthe number of occurrences of a term tinside of a document d, and divide it by the total\nnumber of words ( t0) inside the same document. The TF measure [Salton and Buckley\n(1988)] is formally de\ufb01ned in Equation 2.1.\nt f(t,d) =ft,d\n\u00e5\nt0ft\u2019,d(2.1)\nThe second measure is the inverse document frequency (IDF). It is de\ufb01ned by the log\nof; the total number of documents divided by the number of documents containing the\nterm t. Thereby we give weight to the term depending on the amount of documents to\ncontain it. If a word is very common among the set of documents, the weight given will\nbe small, while if the contrary, the weight will be large (implying more importance).\nFormally, the IDF calculation is given as shown in Equation 2.2, where we have the\nterm t, the total number of documents Dand the number of documents containing t,dt.\nid f(t) =logD\ndt(2.2)\nFinally, TF and IDF are multiplied together to obtain the TF-IDF measure, as dis-\nplayed in Equation 2.3.\nt f id f (t,d,D) =t f(t,d)\u0001id f(t,D) (2.3)\nTF-IDF is one of the most widely used traditional feature representation approaches\nfor textual features. It is often preferred due to being a simple calculation with notably\neffective capabilities of distributing weight to salient words. Within the hyperpartisan\nnews detection community, we \ufb01nd TF-IDF prominent as a reliable baseline system with\nwhich other experimental procedures are evaluated [Alabdulkarim and Alhindi (2019);\nShaprin et al. (2019)].\nPart-of-Speech (POS) Tagging: POS-Tagging [DeRose (1988); Petrov et al. (2011)] in-\nvolves labelling each term depending on its morphological properties and context. Words\n17\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\ncan be labelled as verbs, nouns, pronouns, and so on according to their lexical nature.\nThe use of Hidden Markov Models (HMMs) [Charniak (1997)] is an early effort at la-\nbelling POS-tags based on calculating the probability of likelihood that the upcoming\nword is of a certain part-of-speech. Moreover, rule-based POS-Tagging [Brill (1992,\n1994)] systems such as Gupta et al. (2011) are well-known, \ufb01nding their use not only\nin the English language, but also for more exotic languages such as Hindi.\nNowadays NLTK [Bird et al. (2009); Loper and Bird (2002)] offers an off-the-shelf\nPOS-Tagger using the Penn Treebank [Marcus et al. (1993)] annotated corpus for En-\nglish, and is hence widely used due to its \ufb02exibility and ease of use, with systems such\nas Nguyen et al. (2019) applying POS-Tagging within hyperpartisan news classi\ufb01cation.\n2.2.2.2 | Contextualised Word Embedding Feature Representation Approaches\nTraditional feature representation systems struggle to properly identify a word\u2019s char-\nacteristics, be it its context in a document, its semantic or syntactic similarity with other\nwords. Word Embeddings is an approach capable of representing text features in such a\nway that semantically and syntactically similar words are represented with similar fea-\nture vectors, while features not sharing such similarity are represented by correspond-\ningly distant vectors. In this way, another level of detail is added to the corpus features\nwhich does not exist in traditional representation methods, with the expectation of im-\nproving classi\ufb01er performance [Hettinger et al. (2018)].\nWord embeddings are optimised along with the weights of a Neural Network dur-\ning training. Dense vectors representing textual features are modi\ufb01ed until a suf\ufb01cient\nrepresentation is achieved. Moreover, word embeddings are heavily used in DL due\nto their preservation of detail and natural compatibility with such classi\ufb01cation algo-\nrithms. Throughout this section, we take a look at some of the most prominent Word\nEmbedding technologies currently in use.\nWord2Vec: The Word2Vec system is perhaps the most well-known word embeddings\nmodel at the time of writing - commonly employed as well for the classi\ufb01cation of hy-\nperpartisan news articles [Agerri (2019); Joo and Hwang (2019); Stevanoski and Gievska\n(2019); Zehe et al. (2019)]. Introduced by Mikolov et al. (2013a,b), it has gained signi\ufb01-\ncant popularity since. The Word2Vec model is pre-trained on the Google News dataset\nconsisting of more than 100 billion words [Mikolov et al. (2013a)], making it a notably\nknowledgeable model capable of catering to virtually any form of document written in\nthe English language.\n18\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\nIn practice, one \ufb01nds two adaptations of the Word2Vec model, the Continuous Bag-\nof-Words (CBOW) model (featured in Figure 2.4) and the Skipgram model. Albeit be-\ning different, at their core they both consist of a two-layer neural network with a Soft-\nmax activation function, trained on rebuilding the linguistic contexts of given features\n[Mikolov et al. (2013a,b)]. The two systems function inversely to one another; the CBOW\nmodel predicts a target word from the surrounding context words it is given, while\nSkipgram predicts the context surrounding a given word. Moreover through the use\nof hierarchical softmax and negative sampling, computation time is optimised. This is\nsince in hierarchical softmax, all words are represented as a binary tree with probabili-\nties of the representation of words at the leave nodes calculated along the tree paths. As\nfor negative sampling, only a sample of contextual few words is updated (negatively\nsampled) at each iteration [Rong (2014)].\nFigure 2.4: A high level visualisation of the Word2Vec Continuous Bag-of-Words\n(CBOW) Architecture. Source: Rong (2014).\nThe Word2vec Skipgram model utilises the local context around a target word to\nobtain the corresponding vector. This makes it ideal for analogical tasks such as \"king\nis to queen as man is to woman , which results in the vector king - queen = man - woman\n[Mikolov et al. (2013a)]. It performs poorly however when taking into consideration\nglobal statistics on the corpus, since Word2Vec trains using local context windows and\nnot on the global co-occurrence counts of the features.\nGlobal Vectors (GloVe): In order to address this issue, Pennington et al. (2014) in-\ntroduce GloVe. GloVe is a global log-bilinear regression model which produces word\nembeddings by combining the advantages of global matrix factorisation (such as the\n19\nChapter 2. Background and Literature Review 2.2. Feature Preprocessing & Representation\nLatent Semantic Analysis [LSA] model by Deerwester et al. (1990)) and local context\nwindow methods (as discussed, the Word2Vec Skipgram model). The model trains on\nthe non-zero elements in a word-to-word co-occurrence matrix, reducing the complex-\nity in dealing with sparse vectors and in doing so speeding up the training process.\nHence, it is able to evaluate the likelihood (as probability) of two words appearing to-\ngether, thereby determining whether a feature iis only common with another feature\nj, or common all throughout. From these values the relationships formed between the\ncorpus words could be deciphered.\nEmbeddings from Language Models (ELMo): Introduced by Peters et al. (2018), ELMo\nis a deep, contextualised word representation system capable of modelling both 1) com-\nplex characteristics of word use, and also 2) how these uses vary across linguistic con-\ntexts, hence providing context-based feedback for a given corpus.\nSimilar to the Word2Vec CBOW model [Mikolov et al. (2013a,b)], ELMo predicts the\nupcoming target token, given a context of tokens. It does so using a Bidirectional Long\nShort-Term Memory (biLSTM) neural network, with one LSTM scanning the given sen-\ntences from left to right, and the other from right to left. The LSTMs hence compensate\nfor each other\u2019s decreasing attention the further from the starting point they are. The\nbiLSTM is moreover trained with a coupled Language Model (LM) on large volumes of\ntextual data.\nIn this way, ELMo operates differently to other, less elaborate word embedding\ntechnologies such as Word2Vec and GloVe. Such systems generate a single, context-\nindependent representation for each target word, while ELMo representations consist\nof a function of all the internal layers inside the biLSTM. As the authors themselves\nclaim, the combination of the LSTM\u2019s internal states creates rich word representations,\nwhere higher-level LSTM states capture context-dependent word meanings, and lower-\nlevel LSTM states capture the model\u2019s syntactic aspects.\nELMo is pretrained over 10 epochs on the 1B Word Benchmark [Chelba et al. (2014)], a\nstate-of-the-art benchmark corpus for statistical language modelling. Consisting of two\nbiLSTM layers with 4096 units and 512 dimension projections, as well as a linear pro-\njection layer, the ELMo architecture produces three outputs per feature, corresponding\nto each of the three layers. The outputs can be utilised individually or aggregately, de-\npending on the nature of the application - with systems like Jiang et al. (2019) averaging\nthe three representation vectors in order to combine the bene\ufb01ts of all the outputs.\nBidirectional Encoder Representations from Transformers (BERT): An emerging com-\npetitor to the superior performance promised by contextualised word embeddings are\n20\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\ntransformer-based solutions. BERT, a new language representation model developed\nDevlin et al. (2019), is one such system.\nThe Transformer is a neural network architecture introduced by Vaswani et al. (2017)\nwhich reportedly offers added bene\ufb01ts and improvements on RNN and LSTM net-\nworks. Transformers \ufb01nd their beginnings as encoder-decoders. Different to the typ-\nical encoder-decoder architecture however, transformers focus entirely on the attention\ngiven to the corpus, replacing recurrent layers with attention mechanisms - more for-\nmally known as multi-headed self-attention [Vaswani et al. (2017)].\nSince the goal of the algorithm is to generate a language model for the given corpus,\nBERT uses solely the encoding part of the transformer architecture. A level of masking,\nin which 15% of the words passed are hidden, is integrated within the encoding layers\nin order to introduce more stochasticity inside of the network and encourage learning\nefforts (while also decreasing the possibility of internal over\ufb01tting).\nBERT offers two systems (with smaller systems also made available at the time of\nwriting) [Turc et al. (2019)]; BERT-Base and BERT-Large. BERT-Base consists of 12 trans-\nformer blocks and 768 hidden nodes with 12 attention heads, while BERT-Large is made\nup of 24 transformer blocks and 1024 hidden nodes, with 16 attention heads. Both vari-\nations are pretrained with the intention of generating bidirectional representations from\nunlabelled text. Through the use of attention mechanisms, training is conditioned si-\nmultaneously on all textual contexts inside of the corpus, making the model capable of\n\ufb01ne-tuning with only one additional output layer [Devlin et al. (2019)].\n2.3 | Classi/uniFB01cation Approaches for Hyperpartisan News\nArticles\nThroughout this section we examine classi\ufb01cation algorithms prominent in the \ufb01eld\nof text-based NLP. We discuss traditional ML approaches such as Logistic Regression\n(LR), Random Forest (RF) and Support Vector Machine (SVM) in Section 2.3.1, exploring\nthe reasoning and logic behind each method, before repeating the process on the more\nelaborate DL methods, namely Convolutional Neural Networks (CNNs) and Recurrent\nNeural Networks (RNNs) - featured in Section 2.3.2.\n2.3.1 | Traditional Approaches\nTraditional methods employed within the research area of hyperpartisan detection range\nfrom well-known and widely used techniques to other less popular and niche approaches.\n21\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\nPopular methods include the LR - widely used both within the domain of ML and\nthe area of hyperpartisan news articles. Moreover, the SVM is a popular more ad-\nvanced alternative. Although typically being less common, the RF classi\ufb01er is also\nfound adapted to such problems, offering a completely different approach to the pre-\nvious two. Throughout this section we examine these three traditional ML classi\ufb01cation\napproaches, discussing their differences, similarities and expected performance.\nLogistic Regression (LR): LR is a simple method, yet an effective classi\ufb01er to most\nbasic and common binary (0 or 1) classi\ufb01cation problems. Underneath, the Maximum\nLikelihood Estimation (MLE) is computed in order to \ufb01nd the model\u2019s best \ufb01t on the\ngive data, until a convergence criterion is reached.\nSigmoid (x) =1\n1+e\u0000x(2.4)\nThe LR model separates two classes by forming an S-shape curve transitioning from\n0 up to 1 - formally known as a Sigmoid function (Equation 2.4). The value generated\nby LR can be considered as the probability of the input being in one of the two classes.\nIf the output nears 0, the probability of being in the hypothetical class Ais very small -\nimplying that the input sample belongs to class B. The opposite holds true if the output\nnears 1, with the probability being that the input sample \ufb01ts with class Aand not class\nB.\nSupport Vector Machine (SVM): The LR classi\ufb01er is simple and quick, yet struggles\nto \ufb01t more complex multi-dimensional problems. The SVM [Cortes and Vapnik (1995);\nVapnik (1998)] introduces the hyperplane concept for more elaborate non-linear appli-\ncations. Put simply, the goal of the SVM is to \ufb01nd the optimal hyperplane in a multi-\ndimensional space separating different classes of data points (input samples). In doing\nso, a classi\ufb01cation system is created which given a new data sample, can determine with\nwhich class it is most similar depending on its position in the hyperspace in relation to\nthe SVM hyperplane.\nAs its name implies, the SVM makes use of what are known as support vectors to\ndetermine the best \ufb01t to a classi\ufb01cation problem. Support vectors can be understood as\nthe data points forming the smallest margin with the SVM\u2019s separator line. The support\nvectors are the only points taken into consideration and they support the SVM hyper-\nplane itself (as visualised in Figure 2.5). During the training phase, the hyperplane is\noptimised in order to maximise the margin as much as possible. A degree of tolerance is\noften speci\ufb01ed, allowing for a number of data points to breach the hyperplane margins.\n22\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\nFigure 2.5: An example of two hyperplanes, with the second being more spread than the\n\ufb01rst. The second hyperplane is expected to have better generalisation in its classi\ufb01cation\ndue to the larger area covered. Source: Osuna et al. (1997).\nThe optimisation of the hyperplane is performed by transforming the problem using\nwhat is known as a kernel function [Amari and Wu (1999); Fletcher (2009)]. In other\nwords, the kernel maps the given data points to the SVM\u2019s hyperspace. One \ufb01nds a\nnumber of possible kernels, with more complex ones being capable of mapping data\npoints to higher dimensions.\nThe most basic kernel would be Linear, which simulates the same behaviour of the\nLogistic Regression (LR) classi\ufb01er. The Sigmoid kernel on the other hand \ufb01nds its bases\nin the same Sigmoid function at the heart of the Logistic Regression (Equation 2.4). One\n\ufb01nds the Polynomial kernel, which contrary to the Linear kernel, supports polynomial\nfunctions. Moreover, kernels of exponential ( ex) nature such as the Radial Basis Function\n(RBF) [Amari and Wu (1999)], are typically capable of \ufb01tting any classi\ufb01cation problem\nas much as the previous three kernels, along with more elaborate and complex cases.\nAnother general purpose exponential function would be the Gaussian Kernel. Given\nsuch a selection of kernel functions, one must perform experimentations with the data\nat hand and determine objectively which kernel tends to \ufb01t the problem best.\nRandom Forest (RF): The RF classi\ufb01er, introduced by Breiman (2001), is based on the\nprinciple that the correct opinion of a large number of uncorrelated individuals outper-\nforms the mistaken opinion of some individuals. It is made up of a number of Decision\nTrees, each of them classifying random samples picked out from the dataset, and basing\ntheir predictions on different features. Finally the global opinion on a data sample is\nevaluated, and the sample is classi\ufb01ed according to the most common opinion among\n23\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\nthe forest of Decision Trees.\nKnown also as CART (Classi\ufb01cation And Regression Trees), the decision tree model\nis inherently a binary tree. During its inception, the input is split until a satisfactory\ntree model is assembled. To measure the quality of each split a speci\ufb01c function is used\nwhich computes the impurity at each node. Typically, one of the two following func-\ntions is used; the Gini Index impurity or the Entropy information gain (Equation 2.5\nand Equation 2.6 respectively, where p(ci)is the probability of class ciin a given node).\nAlbeit the two being quite similar, Gini is typically preferred due to it being less com-\nputationally expensive [Raileanu and Stoffel (2004)].\nGini =1\u0000n\n\u00e5\ni=1p2(ci) (2.5)\nEntropy =n\n\u00e5\ni=1\u0000p(ci)log2(p(ci)) (2.6)\nConsidered as a high-variance model [Dietterich and Kong (1995)], decision trees are\nmore often than not used in an ensemble method called Bootstrap Aggregation [Breiman\n(1996)] - or Bagging. In such an organisation, multiple decision trees are initialised, with\nall the corresponding outputs being averaged such that the most common prediction\nwithin the group of decision trees is agreed upon as the \ufb01nal output. In this way, more\nstability is introduced to the \ufb01nal prediction which would have otherwise not been pos-\nsible with an individual decision tree.\nVariable splitting at each tree is performed in a greedy manner, with individual trees\nending up splitting at the same variable locations - resulting in very similar outcomes.\nRandom Forest is hence an improvement on the classical Bagging approach, which lim-\nits each sub-group of trees to a set of variables among which to perform their splits,\nthereby limiting the trees to their own set of variables. In doing so, variety is forced\nbetween the tree population, increasing the model\u2019s generalisation capabilities while\nmaintaining the same performance [Breiman (2001)]. Moreover, the RF classi\ufb01er tends\nto be stable in its performance, capable of resisting over\ufb01tting on the training data due\nto the Bagging approach employed within.\n2.3.2 | Deep Learning Approaches\nHaving discussed some of the most prominent traditional ML approaches, we now dis-\ncuss Deep Learning (DL) classi\ufb01cation algorithms for the classi\ufb01cation of text-based\nNLP tasks, in particular the classi\ufb01cation of hyperpartisan news articles. In summary,\n24\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\nthe DL scene within hyperpartisan news detection is dominated by CNN and RNN ar-\nchitectures. Ensemble models utilising both technologies are also quite common, with\nCNN-Bagging, biRNNs and biLSTMs often evaluated against the performance of one\nanother. We hence discuss a concise background on these technologies and examine\nthe underlying functionality which makes them so effective within the corresponding\nresearch area.\nConvolutional Neural Network (CNN): The CNN classi\ufb01er is perhaps more well known\nfor its distinctive ability to adapt to Arti\ufb01cial Vision and image applications. How-\never, as shown in Figure 2.6, textual sequences such as sentences and documents can be\npassed to a CNN in much the same way an image can - as long as the feature represen-\ntation is compatible with the network. The CNN consists of three main parts [O\u2019Shea\nand Nash (2015)]; 1) the convolutional layers, 2) the pooling layers and \ufb01nally 3) the\nfully connected layers.\nFigure 2.6: A high level visualisation of a simple sentence being processed by a Convo-\nlutional Neural Network (CNN). Source: Kim (2014).\nOne considers the convolutional layers as the most distinctive features of the CNN\nmodel. As the name itself implies, convolution functions are applied on the input\ndata. Through the use of convolution \ufb01lters, a feature map of the input is generated\n- highlighting the most important properties of the given image or text sequence. For 2-\ndimensional data inputs such as images, convolution \ufb01lters are applied in the form of a\nwindow being passed over each section of the input, while in the case of 1-dimensional\ntextual data, the same process is performed, yet with a 1-dimensional vector of weights\n25\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\npassing through the sequence of text. In practice one typically \ufb01nds CNN applying\nseveral \ufb01lters on the input, reducing the data dimensionality and extracting the most\nimportant features. The summarised feature vectors are then passed on to the pooling\nlayers.\nThe role of the pooling layers is to compress and generalise the features extracted\nby the convolutional layers - preventing the network from over\ufb01tting on the training\ndata - which is particularly a problem when it comes to the location of the features\ninside of the input image or text sequence. Pooling makes sure that the data is gener-\nalised enough such that the classi\ufb01cation layers could still recognise distinctive features\nlocated at different parts of the input.\nPooling is generally applied after each convolutional layer - with an activation func-\ntion such as ReLU (Equation 2.7) being applied in between for non-linearity. One of two\npooling functions is typically used; average or max pooling. In case of average pooling,\nthe average of the values within the local area is calculated, while for the max pooling,\nthe maximum value of the lot is selected.\nReLU (x) =max (0,x) (2.7)\nFinally, the processed data is passed to the fully-connected layers, which perform\nthe actual classi\ufb01cation on the pooled feature maps generated from the original input.\nA \ufb01nal activation function such as Sigmoid (Equation 2.4) is utilised, outputting a value\nrepresenting the classi\ufb01cation between 0 and 1. It is interesting to note that during\nbackpropagation, the weights inside of the convolutional layers are updated along with\nthe rest of the network, with the aim of enhancing the convolution \ufb01lters.\nRecurrent Neural Network (RNN): Different to the CNN architecture, RNNs [Chen\n(2016)] are designed around the concept of memory and remembrance. The model is\ncapable of remembering the context a data sample is in, and train itself on such a de-\npendency. It is speci\ufb01cally designed to do so for data sequences such as a sample of\ntext. In practical terms, the nodes within the neural network have the added possibility\nof looping their signal back to themselves or neighbouring nodes. Moreover, the output\nof an RNN classi\ufb01cation may be passed back again along with new input. This added\ncomplexity allows the network to communicate the context of an input i1back to itself.\nRNNs are used in multiple areas of research, yet often \ufb01nd their place in the \ufb01eld\nof NLP due to their capability of maintaining context within a sequence of input. Due\nto its complex architecture, updating the network weights is not as straight-forward\nas it is for other neural networks, with classical backpropagation not being feasible.\n26\nChapter 2. Background and Literature Review 2.3. Classi/uniFB01cation Approaches\nInstead, Backpropagation through Time (BPTT) is used; unrolling the network nodes\nsuch that the recurrent links within the network are created as copies of individual node\ninstances. The RNN is hence represented as a classical feed-forward neural network,\nand the weights are then updated accordingly.\nThe classical RNN architecture suffers from a major drawback. In updating the\nweights of deep unrolled neural networks, the gradients upon which the weights are\ncalculated tend to become unstable, approaching either very low (vanishing gradient)\nor very large (exploding gradient) ranges. This in turn makes the network unstable and\nunreliable, while also extending the training time by a large margin.\nLong Short-Term Memory (LSTM) Network: LSTM [Hochreiter and Schmidhuber\n(1997)] networks are an improvement on the RNN architecture - speci\ufb01cally designed\nto address the problem of vanishing and exploding gradients. LSTMs substitute the\notherwise neural nodes with smarter memory blocks - also known as cells. Each cell\ncontains three gates; input, output and forget gate [Gers et al. (1999)]. The input gate\ndecides on which information to update the memory state with, while the output gate\nmaintains the output - conditioned on the input and existing unit memory. The forget\ngate handles discarded information. Each of these three gates has its own weights which\nare themselves trained with the rest of the model.\nFigure 2.7: A simpli\ufb01ed unfolded visual representation of the basic architecture of a\nBidirectional Recurrent Neural Network (biRNN). Source: Schuster and Paliwal (1997).\nBoth RNNs and LSTMs process sequences of data sequentially, with concurrent pro-\ncessing not being possible. Due to the tendency of the network\u2019s attention to degrade\nwith the length of the sequence, RNNs and LSTMs are typically used in a bidirectional\nensemble, in which one network parses the sequence from left to right, and the other\nfrom right to left, thereby dedicating the same amount of attention for both ends of the\n27\nChapter 2. Background and Literature Review 2.4. Sentiment Analysis\ngiven sequence [Schuster and Paliwal (1997)]. These models are known as bidirectional\nRNNs (biRNN) and LSTMs (BiLSTM). A high level overview of a biRNN model archi-\ntecture is displayed in Figure 2.7.\n2.4 | Sentiment Analysis in Hyperpartisan News Arti-\ncles\nSentiment analysis is an important and well-researched domain in the \ufb01eld of NLP. It\naddresses the detection and extraction of opinions, sentiments and emotions towards a\nsubject, be it an individual, an organisation, or any other entity. The sentiment within\na sequence of text is often established through sentiment-bearing terms, their polarity,\nand the context in which they are used [Yadav (2015)].\nDue to the sensationalised and dramatic elements that hyperpartisan articles try to\npass on to the user, we investigate whether sentiment plays a prominent part in the\ndetection on such news. Hereby, we discuss a concise background on the analysis of\nsentiment before considering it within the HyperPT system.\n2.4.1 | Sentiment Analysis - Overview\nOne \ufb01nds three families of sentiment classi\ufb01cation systems; Lexicon-based approaches,\nML approaches and Hybrid approaches [Yadav (2015)]. Lexicon-based approaches con-\nsist of a language lexicon (collection of known sentiment terms), usually including the\nsynonyms and antonyms of each term. A lexicon can be pre-assembled from other cor-\npora and shipped as is (dictionary-based approach), or it could be expanded and built\non a speci\ufb01c corpus in real-time (corpus-based approach). The latter is implemented by\nhaving an already-established list of sentiment-bearing words, upon which statistical\nand semantic methods are then applied to expand the lexicon\u2019s vocabulary.\nML techniques are divided between supervised and unsupervised approaches. Su-\npervised approaches are trained on labelled training corpora, where evaluation criteria\ncorrect the algorithm\u2019s performance. We \ufb01nd studies such as Pang et al. (2002), where\nNaive Bayes (NB), Maximum Entropy Classi\ufb01cation (MaxEnt), and Support Vector Ma-\nchines (SVMs) are evaluated for the classi\ufb01cation of sentiment - with SVMs being the\nbest performer. Moreover, the SVM is compared with ANN systems by studies such as\nMoraes et al. (2013), where the authors compare the performance of the two classi\ufb01ers\non movie and product reviews. The SVM comes at a close second with a highest accu-\nracy of 85.2% to the ANN\u2019s 86.5% (respectively achieved with 1000 and 3000 features).\n28\nChapter 2. Background and Literature Review 2.4. Sentiment Analysis\nDL systems are also prominent in the \ufb01eld of sentiment analysis [Zhang et al. (2018)],\nwith encoders [Glorot et al. (2011); Yin et al. (2017)] and LSTMs [Xu et al. (2016); Zhou\net al. (2016)] being two such well-known classi\ufb01cation approaches.\nUnsupervised approaches are preferred in cases where it is dif\ufb01cult to obtain quan-\ntities of high quality labelled data upon which to train. Unsupervised sentiment clas-\nsi\ufb01cation tends to be heavily based on already known words, with methods such as\nTurney (2002) using known opinionated words and phrases. Paltoglou and Thelwall\n(2012) propose an unsupervised, lexicon-based sentiment analysis system which is less\ndependant than ML-based techniques on the domain in which it is used. The proposed\nsystem is tested on Twitter, MySpace and Digg text snippets, estimating the levels of\nemotional intensity found within the texts.\nHybrid approaches combine both ML and lexicon based techniques to create a sys-\ntem in which ML models are trained on gold-standard lexicons upon which given text\nis then classi\ufb01ed. Due to the pivotal performance offered by language lexicons, such\nsystems are well-known and effective [Yadav (2015)].\nSentiment analysis is typically applied at three levels of granularity; 1) Document-\nlevel, Sentence-level, and Aspect-level. At document level, a single sentiment is given\nfor a document of text, while for sentence-level analysis, the same is repeated for each\nsentence. Aspect-level sentiment analysis however is more complex - assuming that a\ndocument of text contains various entities/objects, having their own aspects. Hence for\nsuccessful sentiment classi\ufb01cation, these objects and their contexts must \ufb01rst be taken\ninto consideration [Yadav (2015)].\n2.4.2 | VADER for Sentiment Analysis\nVADER (Valence Aware Dictionary for sEntiment Reasoning) is a lexicon-based senti-\nment analysis system introduced by Hutto and Gilbert (2014). The researchers make use\nof qualitative and quantitative techniques along with grammatical and syntactical con-\nventions for the expression of sentiment, in order to create a gold-standard sentiment\nlexicon. To our knowledge, VADER is one of the most prominent off-the-shelf sentiment\nanalysis systems currently available.\nThe authors\u2019 aims in designing such a system were to build a computational senti-\nment analysis machine that is generalisable and reliable on different domains and styles\nof writing, while also performing well on social media styles of text. Moreover, the lexi-\ncon requires no training data since it is assembled from a valence (intensity) based gold\nstandard sentiment dictionary created using human expert analysis. Compared to al-\n29\nChapter 2. Background and Literature Review 2.5. Explainable A.I.\nternative methods such as ML-based techniques, VADER is considered to have notably\nlower execution times [Hutto and Gilbert (2014)].\nAs discussed above, VADER is based on expertly selected sentiment lexicons. Hav-\ning been inspired by such word dictionaries (LIWC9, ANEW10and GI11), multiple ex-\npressions from microblogs and social media texts were incorporated - amounting to\nover 9000 lexical features. Wisdom of the crowds [Surowiecki (2004)] was then used to\nacquire estimates for the sentiment valence of each of these features. Finally, these were\nreviewed by ten independent human raters. Moreover, 400 positive and 400 negative\nexpertly-selected tweets were used to generate \ufb01ve generalisable heuristics conveying\nthe intensity of the sentiment.\nVADER is evaluated against other well-known ML and lexicon based systems, namely\nLIWC, ANEW, WSD, SCN, GI and Hu-Liu04 - with ML methods being Naive Bayes\n(NB), SVM, and Maximum Entropy (ME). It performs exceptionally well, surpassing\nany system (including human analysis) on social media text, while maintaining sec-\nond position (exceeded by human analysis) for other datasets such as Amazon Product\nReviews and Movie Reviews. Being offered out-of-the-box by NLTK, the VADER sen-\ntiment lexicon is widely used for the analysis of sentiment, including the \ufb01eld of hy-\nperpartisan news article detection [Anthonio and Kloppenburg (2019); Joo and Hwang\n(2019)].\nIn practice, a string of text can be instantly passed to the VADER object instance,\nwhich would return the corresponding sentiment values for four sentiment measures;\nnegative, neutral, positive and compound . The compound score can be considered as a\nmore context-sensitive sentiment measure, taking into consideration the valence of the\nword within the context in which it is used. It is given as a number between \u00001 to 1,\nwith the former being extreme negative and the latter being extreme positive.\n2.5 | Explainable Arti/uniFB01cial Intelligence for Hyperparti-\nsan News Classi/uniFB01cation\nExplainable Arti\ufb01cial Intelligence (XAI) [Arras et al. (2016); Goebel et al. (2018); Samek\net al. (2017)] is a new and emerging branch of the A.I. research and development com-\nmunity focused on the interpretation and explanation of the logic behind an A.I. sys-\ntem\u2019s behaviour. In our study, we aim at incorporating explainable A.I. for the interpre-\n9LIWC - liwc.wpengine.com [Last Accessed : 07-2020]\n10Affective Norms for English Words (ANEW) - csea.phhp.ufl.edu [Last Accessed : 07-2020]\n11General Inquirer (GI) - www.wjh.harvard.edu [Last Accessed : 07-2020]\n30\nChapter 2. Background and Literature Review 2.5. Explainable A.I.\ntation of the model\u2019s decision-making, in doing understanding the model\u2019s reasoning\nwhile also examining the features in\ufb02uencing it\u2019s decisions.\nTwo recent techniques referred to for the explanation of classi\ufb01ers\u2019 predictions are\nSensitivity Analysis (SA) and Layerwise Relevance Propagation (LRP) [Samek et al.\n(2017)]. Albeit being inherently different, both algorithms produce a similar set of re-\nsults: an individual score for each input feature passed to the classi\ufb01cation system -\nrepresenting the amount of relative in\ufb02uence of each feature on the class prediction.\nThrough such scores, one could observe which features affect the classi\ufb01cation, and\nhow a classi\ufb01cation label is derived from a sequence of inputted features. Both algo-\nrithms are typically applied on Neural Network based architectures, but are adapted to\nother traditional ML classi\ufb01ers as well [Arras et al. (2017)].\n2.5.1 | Sensitivity Analysis\nSensitivity Analysis (SA) [Baehrens et al. (2010); Samek et al. (2017)] attempts at explain-\ning a classi\ufb01er\u2019s prediction based on the model\u2019s locally evaluated gradients (partial\nderivatives). Features having the most sensitive output are considered as the most rele-\nvant. Hence, in formal terminology, the relevance Riof each input feature iis given as\nshown in Equation 2.8, where f(x)is the classi\ufb01cation function.\nRi=kJ\nJxif(x)k (2.8)\nAs published literature points out [Montavon et al. (2018); Samek et al. (2017)], SA\nhas the inherent limitation of not explaining the function value f(x)itself, but a varia-\ntion of it. It highlights which features need to be changed the most (from the model\u2019s\nperspective) for an input to be closer to the predicted class. Due to this fact and other\nsetbacks (discussed below) inherent to the SA interpretability procedure, it is often con-\nsidered as a primitive baseline model, having been proven inferior to alternative tech-\nniques [Samek et al. (2017)].\n2.5.2 | Layerwise Relevance Propagation\nOne such technique showing superiority over SA is Layerwise Revelance Propagation\n(LRP) [Bach et al. (2015); Samek et al. (2017)]. LRP attempts at interpreting a classi\ufb01er\u2019s\ndecisions through decomposition. The classi\ufb01er\u2019s prediction is redistributed backwards\nusing local redistribution rules until eventually a relevance score is assigned to each\ninput feature. At every step of the redistribution the total amount of relevance is pre-\n31\nChapter 2. Background and Literature Review 2.5. Explainable A.I.\nserved. LRP explains the classi\ufb01er\u2019s prediction corresponding to the state of maximum\nuncertainty - in other words identifying the crucial features affecting a classi\ufb01cation.\nHaving been originally developed for pixel-level model evaluation in computer vi-\nsion tasks [Bach et al. (2015)], LRP bases its computations on the hypothesis that there\nexists a relevance score R(l+1)\ndfor each dimension z(l+1)\ndof the vector zat layer l+1. The\nalgorithm hence attempts to maintain the relevance conservation R(l)\ndfor each dimen-\nsion z(l)\ndat the ensuing layer las shown in Equation 2.9 - which states that at any step\nof the redistribution procedure, the total amount of relevance is maintained [Bach et al.\n(2015); Samek et al. (2017)].\nf(x) =\u00e5\nd2l+1R(l+1)\nd=\u00e5\nd2lR(l)\nd=...=\u00e5\ndR(1)\nd(2.9)\nLRP redistributes the relevance from layer l+1 to layer lof the model as given\nin Equation 2.10, where xjare the neuron activations at layer l(assuming the classi-\n\ufb01er is a neural network), Rkrepresents the relevance scores corresponding to the neu-\nrons at later l+1, and wjkbeing the weight between neuron jand neuron k. Note also\nthat a small stabilisation term eis included to avoid the possibility of division by zero.\nThrough this calculation, relevance is distributed according to the neuron activation xj\n(with a larger share of relevance given to the more activated neurons), and the strength\nof the connection between neurons jand k, with more relevance given to more pivotal\nweight connections.\nRj=\u00e5\nkxjwjk\n\u00e5\njxjwjk+e(2.10)\nLRP is also capable of analysing traditional ML models such as SVMs [Arras et al.\n(2017); Bach et al. (2015)]. Assuming that wcand bcare respectively class-speci\ufb01c weights\nand biases, and Dis the number of non-zero vectors representing BoW documents; the\nrelevance decomposition Rjfor an input feature xjis computed as given in Equation\n2.11 [Arras et al. (2017)].\nRj= (wc)j\u0001xj+bc\nD(2.11)\nContrasting to SA, LRP decomposes the actual function value f(x). Further to this,\nLRP has the capability of determining whether each feature supports or opposes a par-\nticular classi\ufb01cation, while SA limits itself to solely determining how relevant a feature\nis to a particular class. Having been evaluated by studies such as Arras et al. (2017)\nand Samek et al. (2017), a clear discrepancy in interpretability performance is indeed\n32\nChapter 2. Background and Literature Review 2.6. Evaluation Criteria\nobserved. In Figure 2.8, Samek et al. (2017) produce heatmaps of SA and LRP inter-\npretability on image and text classi\ufb01cations. Two observations stand out; the clearer\nplotting of the object\u2019s edges in case of the image classi\ufb01cation heatmap, and the addi-\ntion of features opposing the classi\ufb01cation (highlighted in blue) in the text heatmap.\nFigure 2.8: Image and Text classi\ufb01cation interpretability - comparison of Sensitivity\nAnalysis (SA) and Layerwise Relevance Propagation (LRP). Source: Samek et al. (2017).\nSeveral ready to use libraries implementing SA and LRP are available. The LRP\nToolbox [Lapuschkin et al. (2016)] offers LRP analysis adapted to Caffe networks and\nbespoke implementations of neural network models. Moreover, iNNvestigate [Alber\net al. (2019)] is a library offering a range of analysis methods, including gradient-based\nsolutions like SA and variations of LRP. In our system, HyperPT, we make use of iN-\nNvestigate to implement the SA and LRP interpretability methods on our CNN classi-\n\ufb01er, however since at the time of writing we failed to \ufb01nd a reliable off-the-shelf library\nimplementing the same on the SVM classi\ufb01er, we developed the LRP algorithm on this\nalgorithm from \ufb01rst principles, using the work of Arras et al. (2017) as guidance.\n2.6 | Evaluation Criteria\nDue to the nature of the task at hand and the SemEval Hyperpartisan News Dataset\n(Section 2.1), we evaluate the HyperPT system using the classi\ufb01cation accuracy and F1\nscore. This decision is supported by two reasons;\n1. Given that it is a classi\ufb01cation problem, the ultimate performance review would\nbe by examining the classi\ufb01er\u2019s accuracy and balance in its predictions.\n2. Other, similar systems evaluate along the same evaluation metrics, and hence in\nthis way, we can compare our system performance with theirs.\n33\nChapter 2. Background and Literature Review 2.6. Evaluation Criteria\nThe accuracy score is given as a decimal value between 0 and 1, thereby 0 imply-\ning 0% and 1 implying 100%. The F1 score (or F measure) is calculated on the Preci-\nsion (Equation 2.12) and the Recall (Equation 2.13) scores of the classi\ufb01er predictions as\nshown in Equation 2.15.\nPrecision =TruePositives\nTotalPredictedPositives(2.12)\nRecall (Sensitivity ) =TruePositives\nTotalActualPositives(2.13)\nSpeci f icity =TrueNegatives\nTotalActualNegatives(2.14)\nF1=2\u0002Precision\u0002Recall\nPrecision +Recall(2.15)\nThe accuracy measure provides us with the ratio of correctly classi\ufb01ed articles to\nthe total number of articles considered within the classi\ufb01cation. Albeit being a strong\noverall performance overview, accuracy fails in indicating potential biases in a classi\ufb01-\ncation system, where one class could be more susceptible to wrong classi\ufb01cation than\nthe other.\nConversely, the precision takes into consideration the number of true positives (cor-\nrectly classi\ufb01ed hyperpartisan articles) with respect to the total hyperpartisan predicted\narticles (including falsely predicted as so). Moreover, recall (also known as sensitivity)\nis the number of true positives divided by the total number of actually positive (hyper-\npartisan) news articles available within the classi\ufb01cation. Hence a low precision score\nsuggests a high number of false positive classi\ufb01cations (wrongly classi\ufb01ed as hyperpar-\ntisan), while a low recall score implies that a low number of true positive (hyperparti-\nsan) articles are correctly classi\ufb01ed as so, with the rest being falsely classi\ufb01ed as negative\n(neutral).\nSubsequently, the F1 score provides us with the harmonic mean of the precision and\nthe recall. In practice, the F1 score is a value between 0 and 1 - with 0 being the poor-\nest and 1 being the best, performance-wise. This coupled with the accuracy gives us a\nstrong indication as to 1) the overall performance of the system and 2) How balanced\nand reliable the system is proportional to the data samples utilised within the classi\ufb01ca-\ntion.\nTo keep the HyperPT study to a manageable scale, given the limitations imposed on\nthe research, we maintain the accuracy and the F1 score as the main evaluation criteria.\nWe do not rule however, as future work, the consideration of other evaluation criteria\n34\nChapter 2. Background and Literature Review 2.7. Related Work\nin order to provide a more granular indication of the classi\ufb01cation performance. The\nrecall/sensitivity and the speci\ufb01city (Equation 2.14), for instance, could be used to re-\nspectively determine the ratio of correctly classi\ufb01ed hyperpartisan and neutral articles\nwith respect to the total number of available hyperpartisan and neutral articles. In such\na case, due to the harmful effects of widespread hyperpartisan news articles, one may\nwant to focus on the sensitivity in order to verify that all possible hyperpartisan news\narticles are captured.\nSeparate to the classi\ufb01cation system, in employing model interpretability algorithms\nsuch as Sensitivity Analysis (SA) and Layerwise Relevance Propagation (LRP), we eval-\nuate the system by adapting a method introduced by similar studies [Arras et al. (2017);\nSamek et al. (2017)] in which the classi\ufb01cation accuracy is monitored with the removal\nof each salient feature - from the most salient to the least. In this way, the rate of degra-\ndation in accuracy performance is directly related to the quality of the feature selections\nperformed by the interpretability techniques.\n2.7 | Related Work\nHaving examined the background behind techniques utilised within the HyperPT study,\nwe now examine published literature employing the same or similar approaches. We\ncommence in Section 2.7.1 by discussing the related area of fake news detection, explor-\ning the work conducted by other researchers in tackling the spread of such malicious\ninformation.\nThis is followed by similar work on the speci\ufb01c classi\ufb01cation of hyperpartisan news.\nAddressed in Section 2.7.2, we discuss traditional and deep learning approaches for the\ndetection of hyperpartisan news. Moreover, we tackle the role of sentiment within this\nresearch and the addition of explainable A.I. - two prominent components investigated\nwithin this study.\n2.7.1 | Detection of Fake News\nDue to the growing need to control the spread of fake news, one \ufb01nds an interesting\narea of study behind the development of intelligent techniques designed for its auto-\nmatic detection. Throughout this section we examine published literature to discover\nthe spectrum of systems tackling the neighbouring problem of fake news.\nPotthast et al. (2018) classify the detection techniques of both fake and hyperpartisan\nnews into three groups: i) Knowledge-based, ii) Context-based and iii) Style-based.\n35\nChapter 2. Background and Literature Review 2.7. Related Work\nKnowledge-based systems compare individual pieces of knowledge claims inside of\na given text with knowledge gathered from online systems such as webpages [Etzioni\net al. (2008); Yates et al. (2007)] - computing the differences. Other, similar systems\nbuild statistical models, also based on knowledge gathered online [Magdy and Wanas\n(2010)]. Such systems depend heavily on the assumption that webpage sources from\nwhich knowledge is gathered are indeed reliable and accurate. Other approaches like\nWu et al. (2014) make use of more reliable knowledge-bases to try and verify a given\nclaim. By treating claims as queries with corresponding parameters, they can be checked\nnot only for correctness and authenticity, but also for the quality of the claim.\nAlternatively, context-based systems study how information is spread on social me-\ndia, to then engineer ways for slowing down or stopping this spread [Agrawal et al.\n(2011); Nguyen et al. (2015)]. Tambuscio et al. (2015) conduct observations relating to\nhow fake news articles are shared. It is claimed that increasing the threshold required to\nshare a fake news article, such as the amount of convincing individuals needed, should\nbe enough for the news article to die off before going viral. The researchers implement\na stochastic epidemic model in order to describe the spread of a hoax piece of news on\nsocial media, proposing a correlation between the amount of fact-checkers needed and\nthe complete removal of the hoax from online circulation.\nStyle-based fake news detection sets aside the need to verify the truth behind claims,\nfocusing instead on the style of writing. Style-based approaches can be divided into two\nsub-groups; detection of deception within text and categorisation of text. Detection of\ndeception builds on the Undeutsch hypothesis [Undeutsch (1967)] - stating that memo-\nries of real, experienced events differ from those of imagined events.\nStudies such as Kwon et al. (2013) expand on this observation by studying the pat-\nterns of rumour spreading on the Twitter12social media. The researchers explore three\nsets of features; temporal, structural, and linguistic. A pattern of repeating spikes\nin activity for tweets with rumours is noted to not be present in non-rumour tweets.\nMoreover, the structure of the follower-followee connection graph of Twitter users is\ntaken into consideration. Finally, the LIWC dictionary-based sentiment analysis tool\n(addressed also in Section 2.4) is used to detect and categorise the sentiment features\nwithin the tweets.\nRubin et al. (2015) address deceptive news by being the \ufb01rst system to apply decep-\ntion detection techniques to news articles through the analysis of rhetorical structures,\ndiscourse constituent parts and corresponding coherence relations. A vector space model\nis used to cluster news by similarity of discourse, with an accuracy of 0.63. A predictive\n12Twitter - www.twitter.com [Last Accessed : 07-2020]\n36\nChapter 2. Background and Literature Review 2.7. Related Work\nmodel is also introduced with an accuracy of 56%. Despite this somewhat disappoint-\ning score, the authors claim that is still 2% higher than the average human lie-detection\ncapabilities.\nText categorisation, on the other hand, is in itself a powerful and pragmatic approach\nagainst the spread of fake news. Researchers such as Badaskar et al. (2008) and Ru-\nbin et al. (2016) approach this problem by respectively training language models and\nTF-IDF weighted lexical vector-space models to classify the different types of news arti-\ncles according to how they are written, with the latter system training also on satire and\nhumorous fake news. An interesting alternative system for style detection is proposed\nby Afroz et al. (2012). The researchers base their study on the hypothesis that to a cer-\ntain degree, linguistic features within a body of text change when respective authors try\nto hide their style of writing. By identifying these features, the authors point out that\nstylistic deception could be detected.\n2.7.2 | Detection of Hyperpartisan News\nThroughout this section, we examine different approaches implemented by other re-\nsearchers with the hopes of addressing the spread of hyperpartisan news articles through\nML classi\ufb01cation systems. We \ufb01rst take a look at systems implementing traditional ML\nalgorithms, before shifting to more complex DL solutions. Moreover, we tackle the ad-\ndition of sentiment and model interpretability within the \ufb01eld of hyperpartisan news\ndetection. In doing so, we compare and contrast published literature, analysing the\nperformance, limitations, and overall results of the mentioned systems.\n2.7.2.1 | Traditional Approaches\nIn classifying hyperpartisan news articles along with typical text-based binary clas-\nsi\ufb01cation tasks, one often \ufb01nds Logistic Regression (LR) used as a baseline classi\ufb01er\nwith which other (more complex) algorithms are compared [Kiesel et al. (2019)]. Sen-\ngupta and Pedersen (2019) implement a LR classi\ufb01er based on unigram features (Sec-\ntion 2.2.2.1) and a Convolutional Neural Network (CNN) DL classi\ufb01er. Interestingly,\nthe CNN\u2019s disappointing accuracy of 0.58 is exceeded by that of the LR model at 0.70,\nsuggesting the possibility of the CNN model over\ufb01tting on the training data.\nAlternatively, LR can be utilised as a feature extraction classi\ufb01er. Working on the\nBy-Publisher and the smaller By-Article SemEval datasets13(Section 2.1), Pali\u00b4 c et al.\n(2019) train a LR model on the latter collection, to then be used on the former. All\n13PAN SemEval Hyperpartisan News - pan.webis.de/semeval19 [Last Accessed: 07-2020]\n37\nChapter 2. Background and Literature Review 2.7. Related Work\ncorrectly labelled articles from the By-Publisher collection are then added to the smaller\nBy-Article collection, thereby increasing the dimensions of the more reliable dataset.\nSrivastava et al. (2019) manage to exploit a lot of the potential harnessed in an oth-\nerwise simple classi\ufb01cation algorithm. The researchers make use of L2-regularised LR\n[Pedregosa et al. (2011)] - a variation of the LR classi\ufb01er where the tuning parameter l\nis de\ufb01ned during training on a validation set, or in the case of Srivastava et al. (2019),\nusing 10-fold cross validation. They experiment with LR on Doc2vec, GloVe and Uni-\nversal Sentence Encoder (USE) embeddings. The study achieves an accuracy score of\n0.820 using USE embeddings, resulting in second place for the SemEval Hyperpartisan\nNews Detection competition14.\nIf the classi\ufb01cation problem at hand is not linearly separable, more advanced alter-\nnatives to the LR may be required. The SVM is one such approach, capable of utilising\na range of robust kernels, such as Linear, Polynomial, Sigmoid or RBF (refer to Section\n2.3.1). Among a diversity of use cases, SVMs are widely used in NLP , along with the\ndetection of hyperpartisan news articles [Alabdulkarim and Alhindi (2019); Cruz et al.\n(2019); Kiesel et al. (2019)]. Knauth (2019) implements two variations of an SVM model\ntrained using an RBF kernel. The \ufb01rst is based on the stylistic features of the text corpus,\nwhile the second is based on content-related features. The two algorithms are evaluated\nagainst one another, with the former (based on the stylistic features) being the better\nperformer.\nYeh et al. (2019) experiment with several approaches for the representation of article\nfeatures. They evaluate a LR, a SVM classi\ufb01er with linear kernel, and a SVM with RBF\nkernel on each of the representations. The authors note that the SVM exceeds LR at any\ngiven test, with the highest score being attributed to GloVe embedded feature vectors\nwith an RBF-kernel SVM. A corresponding accuracy score of 0.796 is achieved on the\ntraining dataset, with an increase to 0.8057 (and F1 score of 0.7904) on the SemEval\ncompetition held-out test set, earning the system fourth place.\nThe SVM\u2019s popularity sees the classi\ufb01er being used by a number of other systems\nwith varying degrees of success [Kiesel et al. (2019)]. Systems like Isbister and Johansson\n(2019) evaluate the SVM (using a linear kernel) with several other traditional baseline\nclassi\ufb01ers and ULMFiT (Universal Language Model Fine-Tuning) - a DL classi\ufb01cation\nmodel introduced by Howard and Ruder (2018). The SVM comes second to solely ULM-\nFiT, with a respective accuracy of 0.7659 to that of 0.8025 in a fraction of the execution\ntime. Moreover we see SVMs utilised with Word2Vec embeddings [Pali\u00b4 c et al. (2019)],\n14PAN SemEval Hyperpartisan News Detection (2019) - pan.webis.de/semeval19 [Last Accessed: 07-\n2020]\n38\nChapter 2. Background and Literature Review 2.7. Related Work\nword and character n-grams [Nguyen et al. (2019)], and sentiment features [Anthonio\nand Kloppenburg (2019); Pali\u00b4 c et al. (2019)].\nAn interesting alternative to the two commonly used approaches above is Ran-\ndom Forests (RFs) - \ufb01nding its way to the detection of hyperpartisan news articles\n[Kiesel et al. (2019)] as well. Cruz et al. (2019) take a feature-based approach to hyper-\npartisan news classi\ufb01cation, experimenting with various algorithms including SVMs\n(with Squared Hinge-Loss), RFs, and Gradient-Boosted Trees (GBTs). What is known as\nComputer-Mediated Discourse Analysis (CMDA) [Herring (2004)] - an online research-\ning approach for interactive behaviour, is used for acquiring details about the corpus\nsuch as type-token ratio and frequency of word n-Grams. The RF classi\ufb01er provides\nthe best classi\ufb01cation performance with 100 estimators and the Gini split criterion. The\nmodel achieves the 10-fold cross validation accuracy of 0.763 on the By-Article dataset.\nAlternatively, RFs are utilised with word-embeddings in order to exploit the context-\nbased relations between vector embeddings and the quick, generalisable nature of the\nRF classi\ufb01er. Systems like Stevanoski and Gievska (2019) combine the pretrained Word2Vec\nembeddings with RF. The authors also include various measures such as readability\nscores, stylistic and psycho-linguistic features, scoring a notable validation accuracy of\n0.837 and a hidden test-set accuracy of 0.775.\nDistinctively to the well-known traditional methods discussed above, one \ufb01nds other,\nperhaps less well-known systems. Gupta et al. (2019) make use of XGBoost [Chen and\nGuestrin (2016)], a scalable end-to-end tree boosting system capable of scaling ML algo-\nrithms to use less resources. K-Nearest Neighbours (KNN), RFs, LR, and SVMs are also\ntested, with the best performer claimed to be KNN.\nThe MaxEnt (Maximum Entropy) [Ratnaparkhi (1996)] model is a statistical model\ntrained on a corpus annotated with Part-Of-Speech (POS) tags. MaxEnt is used for the\nlearning of supervised models by Agerri (2019) during the development of the ixa-pipe-\ndocsystem, a document classi\ufb01cation system used on hyperpartisan news articles. ixa-\npipe-doc is designed to be simple and ef\ufb01cient, combining various types of clustering\nfeatures to provide denser document representations. Testing is performed on three\ntypes of features: 1) the current token, 2) the character n-grams of each token and 3) the\nword pre\ufb01xes.\nThroughout this section we have examined some of the most prominent traditional\nML classi\ufb01ers in use for the classi\ufb01cation of hyperpartisan news articles. We started off\nby discussing the application of the LR classi\ufb01er, a simple yet effective baseline model\nfound among any ML task. This was followed by the SVM, arguably the most popu-\nlar traditional algorithm found within the hyperpartisan news domain. An alternative\nensemble model known as RF was also discussed, with our focus then shifting to other,\n39\nChapter 2. Background and Literature Review 2.7. Related Work\nless known systems - namely XGBoost and MaxEnt.\n2.7.2.2 | Deep Learning Approaches\nDiffering from traditional ML techniques, the \ufb01eld of DL generally involves more com-\nplex and elaborate algorithms based on the Deep Arti\ufb01cial Neural Network (ANN) ar-\nchitecture. Throughout this section we examine published literature on the best per-\nformers in the area, namely CNNs, RNNs, and their improved alternatives LSTMs, for\nthe detection of hyperpartisan news articles.\nAs of late, CNNs \ufb01nd themselves competing with RNNs for the best performing\ncomplex classi\ufb01cation algorithm in the \ufb01eld of text-based NLP. One \ufb01nds a good num-\nber of systems comparing the two approaches for the classi\ufb01cation of hyperpartisan\nnews, with outcomes differing according to each system\u2019s con\ufb01guration [Kiesel et al.\n(2019)]. CNNs are also frequently compared to baseline traditional models such as Lo-\ngistic Regression, SVM and Naive Bayes [Papadopoulou et al. (2019); P\u00e9rez-Almendros\net al. (2019); Sengupta and Pedersen (2019)].\nZehe et al. (2019) make use of a CNN model working on Word2Vec [Mikolov et al.\n(2013a,b)] and FastText [Bojanowski et al. (2017)] word embeddings. Due to the natural\nsetback of CNNs requiring features of the same size, all articles are represented with a\n\ufb01xed length of 2000 tokens. A base model CNN focusing on sentence level features is\n\ufb01rst implemented, later modi\ufb01ed with the addition of a second convolutional layer in\norder to support article-level features. Finally, handcrafted features such as the number\nof tokens in the article and the average number of tokens per paragraph are appended\nto the \ufb02attened output of the pooling layers, to be integrated within the fully-connected\nlayers of the CNN. The authors compare the CNN model with a linear SVM, achiev-\ning a highest, yet quite disappointing accuracy of 0.660 to the SVM\u2019S 0.528 - using an\nensemble model consisting of 5 CNNs with article-level support.\nJiang et al. (2019), coming \ufb01rst place in the SemEval Hyperpartisan News Detec-\ntion challenge15, exceed considerably the performance of Zehe et al. (2019). The authors\nuse pre-trained ELMo embeddings [Peters et al. (2018)] based on word representations\nlearned from character-level units. The article title is embedded preceding to the body.\nInside of the CNN model, 5 convolutional layers are employed in order to cater for\ndifferent kernel sizes. Batch normalisation is included for normalisation of the input\ndistribution - reducing the possibility of over\ufb01tting and increasing the model\u2019s training\nspeed. The researchers train 10 separate CNN models using 10-fold cross validation,\n15PAN SemEval Hyperpartisan News Detection (2019) - pan.webis.de/semeval19 [Last Accessed: 07-\n2020]\n40\nChapter 2. Background and Literature Review 2.7. Related Work\nand choose the three best trained CNN instances to then organise into one ensemble\nmodel, where the average of the three models is considered as the \ufb01nal prediction. Ex-\nperiments conducted produce a notable accuracy score of 0.84 during training and 0.82\nduring testing - a signi\ufb01cant improvement on the poorer accuracy results reported by\nZehe et al. (2019).\nOther systems include evaluation of CNN with other niche systems such as Ad-\naboost and SpaCy [Moreno et al. (2019)]. Indeed from the research we conducted, we\nconclude that the CNN is quite a popular algorithm of choice in the application of hy-\nperpartisan news articles. One must not however ignore the strong competition brought\nforward by the RNN architecture - with promising literature employing both RNNs and\nLSTMs.\nThe two models are evaluated against one another by Zhang et al. (2019), where the\nresearchers compare the performance of a CNN, a Recurrent CNN (RCNN), an LSTM\nand a biLSTM. Moreover an attention mechanism is integrated with the aim of deter-\nmining textual features affecting the classi\ufb01cation (more on this in Section 2.7.4). From\nthe experiments conducted, an impressive highest test accuracy of 0.9368 is achieved us-\ning the biLSTM architecture with added attention. The other models are not far off, with\nthe LSTM and CNN getting the same range of accuracies (0.9174 and 0.9147). Despite\nthese very high scores, the submitted models struggle on the SemEval hidden test set,\nwith the corresponding accuracy dropping to 0.683 on the By-Article set and 0.652 on\nthe By-Publisher. This behaviour strongly suggests the possibility of model over\ufb01tting,\nespecially since such high validation accuracies are not shared by systems performing\nsigni\ufb01cantly better on the hidden test set.\nCramerus and Schef\ufb02er (2019) classify hyperpartisan news articles by using an LSTM\nto capture the relationships between textual features. Article features are represented\nby word embeddings generated through a custom built Skipgram Word2Vec model\n[Mikolov et al. (2013b)]. Three LSTM models are trained, one on the By-Publisher hyper-\npartisan training set, one on the By-Publisher hyperpartisan validation set, and one on\nthe separate, By-Article collection. The correctly predicted articles are then passed on to\nthe \ufb01nal model - a separate LSTM trained on the newly chosen articles. A somewhat dis-\nappointing accuracy of 0.652 is acquired, however as the researchers themselves claim,\nthe solution performs considerably better on the less re\ufb01ned By-Publisher hyperpartisan\ndataset (refer to Section 2.1). Hence if otherwise trained on the more reliable By-Article\ndata collection, better results would have been probable.\nThe CNN and RNN neural networks do not strictly have to be used separately. Pa-\npadopoulou et al. (2019) join the two by using a CNN along with a biRNN. The CNN\nis utilised \ufb01rst, capturing the word sequence structure at different levels of granular-\n41\nChapter 2. Background and Literature Review 2.7. Related Work\nity. Following the CNN is a modi\ufb01ed version of the biRNN known as Bidirectional\nGated Recurrent Units (biGRU) - calculating the sentence vectors by taking into account\nthe context formed by their neighbouring sentences. Despite a poor outcome of 0.575\naccuracy on the hidden test set, the researchers are positive that a fusion solution deter-\nmining the best classi\ufb01er to use between traditional and DL methods could theoretically\nraise this score to 0.85.\nThe disruptive performance promised by the Transformer neural network architec-\nture \ufb01nds itself introduced as well to the problem of hyperpartisan news classi\ufb01cation.\nBERT (Section 2.2.2.2) is a specialised transformer model presented by Devlin et al.\n(2019), capable of generating several layers of context-dependent word embeddings for\nany textual input feature. The generated embeddings could then either be extracted\nand used as desired, or classi\ufb01ed internally within the model itself by the addition of a\nclassi\ufb01cation layer.\nHence one \ufb01nds BERT Embeddings used in conjunction with Linear [Hanawa et al.\n(2019)] and Softmax [Mutlu et al. (2019)] classi\ufb01ers. Being the smallest and most versa-\ntile BERT pretrained model, BERT-Base is used by systems like Ning et al. (2019) and\nLee et al. (2019). Interestingly, Lee et al. (2019) evaluate the implementation of 2 LSTMs\n(one for the article title and one for the body) with a multilayer perceptron classi\ufb01er\nappended with the BERT transformer. Despite initially performing better, the LSTMs\nare exceeded by BERT (accuracy of 0.758, F1 of 0.7647) once pseudo-label de-noising is\napplied as a preprocessing step on the dataset.\n2.7.3 | Sentiment in Hyperpartisan News Articles\nGiven the sensationalised nature of hyperpartisan news articles, one may hypothesise\nthat sentiment plays a pivotal role within the opinionated texts encompassed by such\narticles. Thereby, in designing tools for the detection of such news, we \ufb01nd a good\nnumber of studies investigating the role of sentiment within hyperpartisan articles.\nThe NLTK VADER [Hutto and Gilbert (2014)] is perhaps one of the most in-use and\npopular out-of-the-box sentiment labelling solutions. Due to its popularity one \ufb01nds\nit embedded within a number of hyperpartisan news detection systems [Kiesel et al.\n(2019)].\nOne such system, which also stands out due to its unique approach, is introduced\nby Anthonio and Kloppenburg (2019). The researchers approach the problem of hyper-\npartisan news detection in a novel way where the classi\ufb01cation is based solely on the\nsentiment features of the article. Albeit resulting in unimpressive scores both in terms\nof accuracy (0.5616) and F1 score (0.5717), the approach is de\ufb01nitely interesting and the\n42\nChapter 2. Background and Literature Review 2.7. Related Work\nauthors do manage to increase the accuracy score by around 13% from 0.4310 to 0.5616\nwhen using negative VADER sentiment as opposed to compound (Section 2.4.2).\nPali\u00b4 c et al. (2019) make use of several external features along with sentiment, among\nwhich are the publication date and the number of quotations within the article. Different\nto the system above, the authors include all four sentiment scores provided by VADER\n(positive, negative, neutral and compound), consequently reporting an increase in ac-\ncuracy from 0.75663 to 0.76128.\nA similar approach is taken by Joo and Hwang (2019), with multiple feature groups\nbeing supplied to the classi\ufb01cation process. Despite achieving high overall results, per-\nformance seems to suffer with sentiment features, which when tested individually, re-\nsulted in an accuracy of 0.6124 and an F1 of 0.61. Interesting to add that this is a different\nexperience to the one reported by the preceding two systems, yet one that in conducting\nour experimentations we found ourselves agreeing with, as discussed further in Chap-\nter 4.\nAlternatively to the popularity of VADER, one does \ufb01nd a minority of systems util-\nising other lexical-based sentiment engines. Amason et al. (2019) employ two relatively\nsmaller lexicons, with the \ufb01rst containing 2000 words of positive sentiment, and the sec-\nond containing 4000 labelled as negative. Chen et al. (2019) on the other hand make use\nof the TextBlob16Python library - performing sentiment analysis on the articles and their\ntitles. Using a Naive Bayes classi\ufb01er, the authors report improvements, just as same as\nAnthonio and Kloppenburg (2019) and Pali\u00b4 c et al. (2019), when sentiment features are\nincluded.\n2.7.4 | Model Interpretability and Saliency of Features\nThe interpretation or explainability of a ML model is arguably still an emerging dis-\ncipline within the realm of A.I. Moreover, one may not directly realise the importance\nof such an addition to a typical classi\ufb01cation system. In the problem of hyperpartisan\nnews detection, we feel that such functionality provides a double bene\ufb01t to the study;\nan insight into the reasoning of the classi\ufb01er in performing its predictions, and perhaps\nmore importantly, the nature of features within an article pivotal to the hyperpartisan\nclassi\ufb01cation. Despite the infantile stages of such a niche area, we are encouraged by\ntwo similar systems employing preliminary work on de\ufb01ning the features behind the\nmodel\u2019s prediction.\nZhang et al. (2019) employ a Bidirectional LSTM (biLSTM) neural network with the\naddition of a self-attention mechanism [Zhou et al. (2016)]. The attention mechanism\n16TextBlob - textblob.readthedocs.io [Last Accessed : 07-2020]\n43\nChapter 2. Background and Literature Review 2.8. Summary\nis applied on the output vector produced by the biLSTM, with a simple visualisation\n(featured in Figure 2.9) showcasing the article features and their corresponding attention\nscores. Through this system the authors note that heavily polarised, negative words\nsuch as moron and racist are often associated with hyperpartisan articles.\nFigure 2.9: A visualisation of feature saliency within an article \ufb02agged by a biLSTM\nSelf-Attention Mechanism. Note that the colour intensity corresponds to the saliency\ntowards or against a prediction class. Source: Zhang et al. (2019).\nAmason et al. (2019) address similar issues through a completely different, yet equally\ninteresting angle. Having generated a large number of both internal and external fea-\ntures (including article title, BoW features, sentiment and complexity features), the re-\nsearchers employ a feature selection approach based on the Chi-Squared [Greenwood\nand Nikulin (1996)] statistical test. They attempt to establish the most distinguishing\nfeatures, and in doing so, assigning each feature a corresponding score, with the 10\nmost in\ufb02uential features along the whole training set included in the authors\u2019 published\nliterature. One \ufb01nds words such as trump, political, israel... within this list.\n2.8 | Background and Literature Review - Summary\nThroughout this chapter we discussed a background overview of the techniques im-\nplemented in the HyperPT system for the classi\ufb01cation of hyperpartisan news articles.\nWe started off in Section 2.1 by discussing the SemEval Hyperpartisan News Articles\ndataset - the collection of data upon which the study is performed. We then advanced\nto Section 2.2 and Section 2.3, where we respectively examined the feature preprocess-\ning, representation and classi\ufb01ers employed within our system - thereby completing the\nbasic classi\ufb01cation pipeline.\n44\nChapter 2. Background and Literature Review 2.8. Summary\nIn Section 2.4 we provided a brief background on the addition of sentiment, before\nrepeating the process for model explainability in Section 2.5. Evaluation criteria is dis-\ncussed in Section 2.6, to \ufb01nally, in Section 2.7, examine similar systems employing the\nsame or alternative methods for the classi\ufb01cation of fake news (a neighbouring problem)\nand hyperpartisan news.\nIn Chapter 3 we now discuss our design process in building the HyperPT system. In\ndoing so we refer back to the background and related work discussed throughout this\nchapter as a means of guidance and further information on the proposed methodology.\n45\n\n3\nSystem Methodology\nWith a thorough background on the problem of hyperpartisan news addressed in Chap-\nter 1, along with a concise review of the related work in Chapter 2, we now discuss the\ndesign process behind the implementation of the HyperPT system.\nIn Section 3.1 we \ufb01rst discuss the HyperPT system from a high level overview, before\nmoving on to Section 3.2, where we address the extraction, preparation and preprocess-\ning of data. The implementation of various feature representation techniques is exam-\nined, before the corresponding classi\ufb01cation algorithms are integrated within the sys-\ntem as highlighted in Section 3.3. Finally, we address the addition of external features,\nnamely sentiment, model explainability and consequently feature saliency, featured in\nSection 3.4.\n3.1 | System Overview\nIn building the HyperPT system, we base our implementation on the concept of mod-\nularity - where components can be added or discarded from the main pipeline with\nrelative ease. This enables us to modify and extend the project implementation rela-\ntively quickly, allowing us to quickly adapt its con\ufb01gurations to accommodate various\ntest scenarios. To accomplish this, we create separate components, each responsible\nfor a speci\ufb01c project functionality, communicating and sharing data with one another\nthrough a main work\ufb02ow pipeline.\nHyperPT can be summarised to three components - as showcased in Figure 3.1. The\n\ufb01rst component is the data loading and preparation, where data is loaded from \ufb01le,\npreprocessed, cleaned and converted into the chosen feature representation vectors. The\nsecond component handles the classi\ufb01ers, where we initialise our chosen classi\ufb01er and\npass the transformed data samples to it for classi\ufb01cation. As discussed further on in\n47\nChapter 3. System Methodology 3.1. System Overview\nFigure 3.1: A high-level visualisation of the HyperPT design process. The system is\nmade up of three sequential main components; the Data Loading & Preparation, Classi-\n\ufb01er Training & Evaluation, and \ufb01nally Model Interpretability & Feature Saliency.\n48\nChapter 3. System Methodology 3.1. System Overview\nSection 3.3, a number of optional parameters can be included at this stage to de\ufb01ne the\nclassi\ufb01er\u2019s execution and evaluation.\nThe third and \ufb01nal component is the model interpretation where, once the model has\nbeen trained and evaluated, we perform analysis on its decision-making by employing\nexplainability algorithms discussed back in Section 2.5. Moreover, at this stage we also\nperform article reconstruction - taking into consideration the saliency of each feature\nassigned through the model explainability.\nThe HyperPT work\ufb02ow is highly con\ufb01gurable through command-line arguments,\nusing which we instantly inform it which data to load, what preprocessing to apply, how\nto represent the data features, and with which classi\ufb01er to process them with (among\nother con\ufb01gurations and customisations). Such functionality allows us to not only per-\nform speci\ufb01c tests on the \ufb02y, but also run multiple tests in bulk through batch execution\ntasks.\nUsing these three components we establish the complete work\ufb02ow of the HyperPT\nsystem. One must also consider three other, ad hoc subcomponents - used either inde-\npendently as preprocessing steps or by the main functionality blocks addressed above.\nThe \ufb01rst is the I/O Bridge, handling all communication and data \ufb02ow with databases\n(MongoDB) and storage. Second is the Word Embedding Generator (Section 3.2), which\ngenerates feature word embedding vectors and saves them to \ufb01le storage (through the\nI/O Bridge) for fast ad hoc usage. Third and \ufb01nal subcomponent is the Sentiment Gen-\nerator. This component is run independently, assigning sentiment labels according to\nthe user preferences to the given data collection (Section 3.4.1).\nThe whole system is built using Python 3.6.101. Two Anaconda2(v4.8.3) environ-\nments are set up, with the main one used by the three system components and based on\nTensor\ufb02ow31.13.1 (with GPU support), and the other based on Pytorch41.4.0 (with GPU\nsupport) used by the Word Embedding Generator and Sentiment Generator subcom-\nponents. Moreover, MongoDB54.2.1 is utilised as the primary data loading source in\nwhich the parsed dataset is initially imported, and from which data samples are loaded\nduring runtime.\nWe feel that the technology used is of signi\ufb01cant contribution to the extents we go to\nin terms of system design and implementation. With a number of different technologies,\napproaches and components working together as one coherent system, the implementa-\ntion of such modules is not trivial. This however, is achieved through the \ufb02exibility and\n1Python 3.6.10 - www.python.org [Last Accessed : 07-2020]\n2Anaconda - www.anaconda.com [Last Accessed : 07-2020]\n3Tensor\ufb02ow - www.tensorflow.org [Last Accessed : 07-2020]\n4Pytorch - pytorch.org [Last Accessed : 07-2020]\n5MongoDB - www.mongodb.com [Last Accessed : 07-2020]\n49\nChapter 3. System Methodology 3.2. Data Loading, Preprocessing and Representation\ncompatibility offered by the Python programming language, along with the simpli\ufb01ed\nimportation of crucial libraries through Anaconda and the quick and direct data I/O\nthrough MongoDB. Moreover one must also mention the pivotal contribution given by\nthe Tensfor\ufb02ow, Pytorch, Keras6(v2.2.4) and Scikit-Learn7(v0.22) libraries, all of which\nare crucial in the precise and ef\ufb01cient building of any and all classi\ufb01cation algorithms\nused.\nThe project is developed and run on a Windows 10 System, with 32GB of RAM and\nan AMD Ryzen 7 3700x 8-Core Processor running at 3.6GHz. Moreover, an NVIDIA\nRTX2080 is utilised as the GPU unit, proving crucial for the fast generation of word\nembeddings, execution of Deep Learning classi\ufb01cations, and overall system evaluation.\nIn replicating the system, the hardware highlighted above is not a requirement, yet is a\nstrong recommendation for better adaptation to the system implementation and faster\nexecution time.\n3.2 | Data Loading, Preprocessing and Representation\nThe SemEval Hyperpartisan News Article dataset, assembled by Kiesel et al. (2019) con-\nsists of two collections; the smaller By-Article collection amounting to 645 articles, and\na larger By-Publisher collection consisting of 600, 000 articles. As discussed back in Sec-\ntion 2.1, we make use of solely the By-Article collection due to its superior quality of\nlabelling - thereby resulting in a more stable model evaluation process. We make use of\nthe provided labels highlighting whether an article is hyperpartisan or not in order to\nbuild our classi\ufb01cation system.\nHaving acquired the SemEval Hyperpartisan News Article dataset in XML form, we\ninitially extract the original XML and write the data samples to a MongoDB database.\nBeing a document-based system, data is represented with each database document be-\ning equivalent to an article data sample. The corresponding attributes are then added,\nincluding the article hyperpartisan label. We decide on using MongoDB as the main\ndata source due to its quick and \ufb02exible extraction of data through the PyMongo Python\nlibrary. Moreover the I/O Bridge subcomponent is designed around this library such\nthat I/O requests are abstracted by simple, ef\ufb01cient functions.\n6Keras - keras.io [Last Accessed : 07-2020]\n7Scikit-Learn - scikit- learn.org [Last Accessed : 07-2020]\n50\nChapter 3. System Methodology 3.2. Data Loading, Preprocessing and Representation\n3.2.1 | Data Preprocessing\nData is fetched during runtime, with data extracted being in raw (normal) form. Ad\nhoc preprocessing is then performed before it is transformed into corresponding fea-\nture representations. Based on our research of similar systems conducted in Chapter\n2, we choose four individual preprocessing \ufb01lters - the removal of stopwords, removal\nof punctuation, feature lowercasing and feature lemmatisation. Stemming is left out\nof the system due to the more promising approach of feature lemmatisation (Section\n2.2.1). During system evaluation, the best performing three techniques are also applied\naggregately on the corpus, amounting to four other preprocessing combinations. In all,\nconsidering raw unedited features, individual and aggregate data preprocessing, we\nare left with 9 separate preprocessing approaches. Following this data cleaning pro-\ncess, the article string is split into individual words in a simple yet crucial process called\ntokenization.\n3.2.2 | Feature Representation\nThe preprocessed and tokenised data is at this stage ready to be transformed into the\nfeature representation of choice. In deciding on which feature representations to con-\nsider (the same as with classi\ufb01cation techniques as discussed in Section 3.3), we review\nthe sizeable amount of possible representation methods in use by related systems (refer\nto Section 2.7), along with novel approaches which may have not yet been explored.\nWhen it comes to traditional feature representation approaches, we settle on the\nmost well-known, effective techniques which have stood the test of time across multi-\nple research domains within NLP - including the detection of hyperpartisan news [Chen\net al. (2019); Joo and Hwang (2019); Knauth (2019)]. Being the most straight-forward and\nsimple of the lot, we \ufb01rst consider the Term-Frequency (TF) Bag-of-Words (BoW) repre-\nsentation. As a well-known promising variation on this approach due to the addition\nof weights to the input features, we also utilise the Term Frequency - Inverse Docu-\nment Frequency (TF-IDF) measure. Finally, we experiment with POS-Tags, due to the\ngeneralised feature labelling provided by such a technique.\nThe newly emerging yet heavily researched \ufb01eld of word embeddings promises no-\ntable improvements on classical feature representation approaches [Goldberg and Levy\n(2014); Lavelli et al. (2004)]. Moreover the years of 2018 and 2019 saw the rise of deep\ncontextualised word embeddings such as ELMo (Embeddings from Language Models)\n[Peters et al. (2018)] and BERT (Bidirectional Encoder Representations from Transform-\ners) [Devlin et al. (2019)], offering more detailed multi-layered word embeddings gen-\n51\nChapter 3. System Methodology 3.2. Data Loading, Preprocessing and Representation\nerated from the features themselves and surrounding contexts.\nAnalysing published literature, particularly projects submitted to the SemEval 2019\nHyperpartisan News Article Detection challenge (Section 2.1), we decide to include both\nstandard word embedding systems, namely Word2Vec and GloVe, and deep contextu-\nalised representations that are ELMo. In doing so we can examine the differences in\nperformance (if any) encountered between the two approaches, and whether these bring\nsigni\ufb01cant change. Note that since as described in Section 4.1.1, ELMo\u2019s original out-\nput consists of three vectors, we adapt the approach utilised by Jiang et al. (2019) and\naverage the three outputs into one vector.\nAlong with these three approaches, we initially considered as well the addition of\nBERT, eventually deciding against it. This decision was reached due to various reasons.\nFirst of all, in perusing related systems we noticed that BERT is utilised by a number of\nsystems [Drissi et al. (2019); Lee et al. (2019); Ning et al. (2019); Shaprin et al. (2019)] with\nnotably different ranges of success. On the other hand, ELMo Embeddings (to the extent\nof our research) are solely used by one system; Jiang et al. (2019), which also happens\nto be the winner of the SemEval Hyperpartisan challenge, boasting high performance\nresults.\nMoreover as discussed further below, generating the large number of deep contextu-\nalised embeddings needed to cover all test scenarios consumed a large amount of time.\nHence due to the limited time allocated to this study, we decided to safely perform com-\nplete system implementation and evaluation using the three technologies mentioned\nabove, opting to leave out BERT due to the further complexity which would have oth-\nerwise been added to the implementation. This in the end was the right call to make,\nsince building the system, its evaluation and the corresponding dissertation did take a\nserious amount of time to conclude. Increasing the complexity and volume of this work\nwould have run us the otherwise high risk of rendering the project incomplete. We nev-\nertheless consider the addition of BERT as future work, which we think would make for\nan interesting extension to the HyperPT system.\nAll of the utilised embedding technologies are pretrained. The Word2Vec model is\nused twice, both of which are pretrained on the Google News dataset (consisting of\naround 100 billion words), while one being further retrained at runtime on our hyper-\npartisan news dataset. GloVe on the other hand is pretrained on the Common Crawl8\n42 billion token dataset (with other con\ufb01gurations also available). Lastly, ELMo comes\npretrained on the 1 Billion Word Benchmark [Chelba et al. (2013)] - a benchmark corpus\nfor the monitoring of statistical language modelling. Note that while both Word2Vec\n8Common Crawl - commoncrawl.org [Last Accessed : 07-2020]\n52\nChapter 3. System Methodology 3.3. Classi/uniFB01cation Approaches\nand GloVe models are implemented using the Gensim9library, ELMo is implemented\nusing AllenNLP10.\nAs mentioned above, initial word embedding generation is performed during run-\ntime, such that data samples are loaded from MongoDB, cleaned and converted to word\nembeddings. This is not a feasible approach when it comes to ELMo, with just the gen-\neration of embeddings taking the vast majority of the whole runtime. To address this,\nwe design a simple yet pivotal \ufb01le system handler, which translates the embedding pa-\nrameter given as a command-line variable during execution to the speci\ufb01c directory\ncontaining the equivalent ELMo embeddings. This allows us to generate word embed-\ndings as a one-time preprocessing task, saving them to a unique sub-directory as HDF5\nbinary \ufb01les - in doing so reducing the runtime loading of ELMo embeddings from over\n30 minutes to around 20 to 30 seconds.\n3.3 | Classi/uniFB01cation Approaches\nHaving reviewed related work discussed in Chapter 2, we employ within HyperPT\nboth traditional and Deep Learning (DL) classi\ufb01cation approaches. This is since one\nmust consider that despite the more elaborate architecture presented by DL classi\ufb01ers,\ntraditional approaches are 1) still very much in use and 2) provide different and unique\nbene\ufb01ts to DL approaches. This is apparent in similar work discussed in Section 2.7,\nwhere related systems [Isbister and Johansson (2019); Sengupta and Pedersen (2019)]\nreport high accuracies using traditional methods and close performance results between\ntraditional and DL approaches.\n3.3.1 | Traditional ML Approaches\nThe Support Vector Machine (SVM) is one of the most well known traditional classi\ufb01ca-\ntion models employed within the classi\ufb01cation of hyperpartisan news. It is often found\ncompared to both traditional and DL models. It is capable of not only matching the per-\nformance of baseline algorithms like the Logistic Regression (LR), but also improving\non it. Further to this, a number of kernels are available to choose from depending on\nthe nature and complexity of the classi\ufb01cation problem.\nAs we have seen in Section 2.3, the SVM is a popular and effective classi\ufb01er within\nML and the domain of hyperpartisan news detection. Moreover we notice how similar\nsystems [Pali\u00b4 c et al. (2019); Yeh et al. (2019)] adapt word embeddings to \ufb01t this model -\n9Gensim - radimrehurek.com/gensim [Last Accessed : 07-2020]\n10AllenNLP - allennlp.org/elmo [Last Accessed : 07-2020]\n53\nChapter 3. System Methodology 3.3. Classi/uniFB01cation Approaches\nan approach we also pursue in order to evaluate the potential of word embeddings not\nonly with DL approaches but also with traditional classi\ufb01cation models. Backed by this\nreasoning, we settle on the SVM as the \ufb01rst model to employ for the classi\ufb01cation of\nhyperpartisan news articles. Despite the majority of related work making use of either\nlinear or RBF kernel SVMs, we evaluate also the Sigmoid and the Polynomial kernels,\nestablishing the best system through 10-fold cross validation and hyperparameter tun-\ning - discussed in detail in Section 4.2.1.\nThe Random Forest (RF) classi\ufb01er is a popular alternative approach proposing unique\nadvantages not inherently found in other methods such as the SVM. Indeed as dis-\ncussed in Section 2.3, the RF is in itself an ensemble model of a number of decision\ntrees. It is capable of easily adapting to non-linear problems, and naturally resists the\ntendency to over\ufb01t on the training data. In considering this model, we strongly focus\non this property, since in case other models would be getting over\ufb01tted on our training\ndata, RF would act as the baseline with which the degree of over\ufb01tting could be mea-\nsured and corrected. Moreover, we see word embedding technologies adapted to the\nRF classi\ufb01er as well, with systems such as Stevanoski and Gievska (2019) combining\npretrained Word2Vec embeddings with the classi\ufb01er. One also \ufb01nds the neighbour-\ning classi\ufb01er Gradient-Boosting Trees (GBTs) employed in the domain of hyperpartisan\nnews. Systems such as Cruz et al. (2019) compare this method and its performance with\nthat of the RF - with RF being the better performer. We hence integrate the RF classi\ufb01er\nas the second contestant for the classi\ufb01cation of hyperpartisan news.\nGiven the generalisation and adaptability capabilities of the SVM through its range\nof kernel functions, and the unique advantages brought forward by the RF such as\nthe ensemble of decision trees and rejection to over\ufb01tting, we conclude on these two\nclassi\ufb01ers as candidates for the classi\ufb01cation of hyperpartisan news articles. We hence\ncompare the performance of these classi\ufb01ers with one another, and with selected DL\nsystems, as detailed in Section 3.3.2.\n3.3.2 | Deep Learning Approaches\nHaving established the traditional classi\ufb01cation methods to employ, we examine state-\nof-the-art DL classi\ufb01cation approaches for the classi\ufb01cation of text-based NLP tasks and,\nmore speci\ufb01cally, the classi\ufb01cation of hyperpartisan news articles. This space is domi-\nnated by CNNs and RNNs - or rather their optimised relative, the LSTM networks.\nOne \ufb01nds varying performances with both these algorithms. In evaluating similar\nsystems employing such techniques, we notice a minority of studies [F\u00e4rber et al. (2019);\nZhang et al. (2019)] achieving high validation accuracies on the local training dataset, yet\n54\nChapter 3. System Methodology 3.3. Classi/uniFB01cation Approaches\nsuffering when tested on a hidden test set (refer to Section 2.3). This behaviour strongly\nsuggests the tendency of over\ufb01tting on the training data, hindering the model\u2019s capa-\nbility to generalise to unseen data. Such an issue is an added dif\ufb01culty to our analysis,\nsince the resulting poor performance of a model may not be due to the model\u2019s lack of\nability but rather the implementation in which it is used.\nJiang et al. (2019), coming \ufb01rst place in the SemEval Hyperpartisan News Detection\nchallenge, successfully implement a CNN classi\ufb01er on the By-Article Hyperpartisan\ndataset (Section 2.1). Moreover, after training 10 separate classi\ufb01ers using 10-fold cross\nvalidation, the best three are handpicked and aggregated within an ensemble system in\nwhich the output of all three is averaged into one. Each of the classi\ufb01ers makes use of\n\ufb01ve convolutional layers, while batch normalisation is utilised within the classi\ufb01er for\nadded performance and faster training time. We choose to employ the same individ-\nual CNN architecture due to its reputable performance and generalisation capabilities\nshowcased when tested on the hidden test-set. Moreover we also experiment with the\nensemble model suggested by Jiang et al. (2019), as discussed in detail in Section 4.4.\nGiven the time constraints imposed upon the project, we include solely one DL clas-\nsi\ufb01er within HyperPT - the CNN. Our decision on employing the CNN network is\nlargely based on the success displayed by Jiang et al. (2019) - it is not however the only\nreason. Compared with the RNN network, the CNN trains signi\ufb01cantly faster (up to \u00025,\nas shown by DeepBranch11DL benchmarking tools). Moreover the RNN and LSTM net-\nwork family contains a number of various architectures, and are often utilised in double,\nopposite formations known as biRNNs or biLSTMs. This is such that equal attention is\ngiven to the whole sequence features (Section 2.3). Given this reality, such a network\nwould have been more challenging and time-consuming to train and evaluate in the\ngiven timeframe - more so when considering the seemingly overall poorer performance\nfeatured in related work (Section 2.7), with the highest rank achieved using such mod-\nels being \ufb01fth place [Isbister and Johansson (2019)]. Nevertheless we do not exclude\nthat further research into the RNN architecture is possible, and given the opportunity\nto do so as future work, the addition of RNN and LSTM networks and their evaluation\nwith the already implemented models would be an important extension to the HyperPT\nsystem.\n11DeepBranch - github.com [Last Accessed : 07-2020]\n55\nChapter 3. System Methodology 3.3. Classi/uniFB01cation Approaches\n3.3.3 | System Implementation and Hyperparameter Tuning\nFurther to the above, we are left with three classi\ufb01cation algorithms; SVM, RF and\nCNN. The former two algorithms are both implemented using the Scikit-Learn12Python\nlibrary, while the CNN is implemented using Keras13with a Tensor\ufb02ow14backend.\nWithin the physical system implementation, each classi\ufb01er is added as a separate class\nobject module, with the option of which one to execute during runtime speci\ufb01ed as a\ncommand-line parameter. Each classi\ufb01er can be evaluated in two con\ufb01gurations; 10-\nfold cross validation or train-test split (with the test set being either randomly selected\nor statically pre-chosen). Both cross validation and train-test splitting is performed us-\ning the Scikit-Learn framework, making use of Scikit-Learn Keras wrappers15for sup-\nporting the CNN implementation.\nHyperparameter tuning is performed on all three classi\ufb01ers as discussed thoroughly\nin Section 4.2.1. In doing so we attempt at \ufb01nding the best classi\ufb01er con\ufb01guration for\nthe problem at hand, adapting the models as much as possible. Tuning is performed\nin a grid-search and cross validation manner, automated using the Scikit-Learn Grid-\nSearchCV model selection approach, which couples the two techniques automatically.\n3.3.4 | Adapting Feature Representations to the Classi/uniFB01er Architec-\ntures\nThe CNN classi\ufb01er presents the inherent requirement that all data sequences given as\ninput must be of the same length. Thereby we preprocess each article feature length\nsuch that they all contain the same, pre-set number of features. Hence in the case that\nan article is longer it is trimmed to \ufb01t, while articles of smaller lengths are appended\nwith zero vectors. Through initial tests we determined the best pre-set threshold for\neach feature representation approach, settling on 500 features for Word2Vec, 300 fea-\ntures for GloVe and 1024 features for ELMo. Note that traditional feature representation\ntechniques are of equal length already.\nMoreover, evaluating Word2Vec features results in better performance using the\nSkipgram model, which is thereby maintained throughout ensuing tests involving Word2Vec\nembeddings.\nThe adaptation of word-embedding features for the traditional classi\ufb01ers (namely\nthe SVM and RF) involves transforming the input features from 2-dimensional vectors\n12Scikit-Learn - scikit- learn.org [Last Accessed : 07-2020]\n13Keras - keras.io [Last Accessed : 07-2020]\n14Tensor\ufb02ow - www.tensorflow.org [Last Accessed : 07-2020]\n15Scikit-Learn Wrapper for Keras - pypi.org [Last Accessed : 07-2020]\n56\nChapter 3. System Methodology 3.4. External Features\n(vector for each feature) to one vector representing the entire article. Analysing related\nwork, similar systems tend to average all article feature vectors into one [Srivastava\net al. (2019); Yeh et al. (2019)]. We experiment with a more niche approach featured by\nDe Boom et al. (2016) as a baseline method, in which we take the element-wise mini-\nmums and element-wise maximums of all the feature vectors. These two vectors are\nthen appended, with the minimums extended by the maximums - resulting in a single\nvector of double the length of the original.\nInitial evaluations of this approach with more basic ones such as the element-wise\nmean, minimum and maximum resulted in min-max reduction achieving the best over-\nall performance. Alternative approaches such as max-min reduction are not attempted\ndue to time-constraints, however we do recommend the consideration of these ap-\nproaches in future experiments. Alternatively, approaches such as Principal Component\nAnalysis (PCA) [Abdi and Williams (2010); Wold et al. (1987)] could be used to reduce\nthe dimensionality of the feature vectors by deriving their principal components.\nHaving discussed the selection and implementation of the three classi\ufb01cation can-\ndidates for the detection of hyperpartisan news articles, we now move to Section 3.4,\nwhere we shift our focus to external features, particularly the addition of sentiment and\nmodel interpretation along with the corresponding feature saliency.\n3.4 | External Features\nIn Section 3.2 and Section 3.3 we discussed our approach and implementation of the\nhyperpartisan classi\ufb01cation system, including the loading, preprocessing and represen-\ntation of data samples, along with the three classi\ufb01ers used; SVM, RF and CNN.\nIn this section we now examine the addition of external features, with the aim of\nincreasing the accuracy and reliability of our classi\ufb01cation performance, while giving us\nbetter insight into the nature of the hyperpartisan news article itself (as discussed later\non in Chapter 4). First in Section 3.4.1 we discuss the integration of sentiment features\nwithin HyperPT - highlighting the various forms of sentiment applied. Following this,\nin Section 3.4.2 we describe our approach towards implementing an Explainable A.I.\nsystem capable of interpreting the classi\ufb01er\u2019s decisions and consequently highlighting\nthe saliency of each article feature within the classi\ufb01cation.\n3.4.1 | Sentiment Features for Hyperpartisan News Classi/uniFB01cation\nDue to the potentially crucial role sentiment may play in sensationalised written text\nsuch as hyperpartisan news articles, we feel that it is one the most pivotal external fea-\n57\nChapter 3. System Methodology 3.4. External Features\ntures to consider within the classi\ufb01cation. Thereby, further to the concise discussion on\nits underlying functionality in Section 2.4, we use the NLTK VADER (Valence Aware\nDictionary for sEntiment Reasoning) sentiment lexicon to issue sentiment labelling for\nour corpus. Being proved by Hutto and Gilbert (2014) as one of the top off-the-shelf\napproaches currently in use, one \ufb01nds VADER utilised within the application of hyper-\npartisan news detection [Anthonio and Kloppenburg (2019); Joo and Hwang (2019)]. We\nopt for this method not only due to its reliable sentiment labelling, but also because of\nits signi\ufb01cantly faster classi\ufb01cation time compared with other, more complex methods.\nSentiment features are generated as a one-time process by a separate subcompo-\nnent of the HyperPT system known as the Sentiment Generator. The corresponding\nsentiment scores are then written as attributes to the respective articles inside of the\nMongoDB database, to be loaded accordingly at runtime. During classi\ufb01cation, senti-\nment scores are embedded within the article text, preceding the corresponding textual\nfeatures.\nWe make use of sentiment in two forms; label and score. A sentiment label is gener-\nated by rounding the original sentiment score, with high sentiment scores (larger than\n0) being classi\ufb01ed as positive and low sentiment scores (smaller than 0) being classi\ufb01ed\nas negative. A sentiment score of 0 implies that the text is of neutral sentiment. Senti-\nment scores issued by VADER are four; positive, negative, neutral and compound. The\ncompound sentiment score is a \ufb02oat number between \u00001 and 1, with\u00001 being extreme\nnegative, and 1 extreme positive. In calculating this measure, VADER takes into consid-\neration the valence of each feature with respect to the rest of the corpus in which it is\nused - thereby giving us a more true-to-context sentiment measure [Hutto and Gilbert\n(2014)].\nWe implement sentiment at two levels of granularity; at the article level and the\nsentence level. These result in a single sentiment feature appended in front of the article\ntext in case of the former, and a localised sentiment feature appended in front of each\nsentence sequence for the latter. At the article level we generate the sentiment label\nusing two separate approaches; Global Label - where we calculate one global article\nsentiment score, and Derived Label, which is calculated by taking the average of all the\nsentiment scores generated at the sentence level, thereby in theory giving us a more\nlocally-aware measure.\nAmong the number of presented approaches, we also take into consideration just\nthe generated negative score, as well as all VADER scores altogether (Positive, Nega-\ntive, Neutral, Compound). We do so inspired by related work, in order to determine\nwhether these approaches improve on the system performance as respectively reported\nby similar systems - Anthonio and Kloppenburg (2019) and Pali\u00b4 c et al. (2019) (Section\n58\nChapter 3. System Methodology 3.4. External Features\n1 Global Label - Article Level\n2 Derived Label - Article Level\n3 Compound Score - Article Level\n4 Compound Score scaled \u00021000 - Article Level\n5 Negative Score - Article Level\n6 Negative Score\u00021000 - Article Level\n7 Label - Sentence Level\n8 Compound Score - Sentence Level\n9 Compound Score \u00021000 - Sentence Level\n10 Negative Score - Sentence Level\n11 Negative Score\u00021000 - Sentence Level\n12 Positive, Negative, Neutral, Compound - Article Level\n13 Positive, Negative, Neutral, Compound \u00021000 - Article Level\nTable 3.1: Sentiment Integration Approaches employed at the article and the sentence\nlevel within the HyperPT study.\n2.4). Moreover we scale each sentiment score separately by a factor of 1000, to determine\nthe effects of such an enhancement (note that during initial testing we also scaled the\nfeatures by 10 and 100, with close to no difference in performance). In all we employ 13\ndifferent sentiment integration approaches, as showcased in Table 3.1.\n3.4.2 | Explainable A.I. for Model Interpretation and Feature Saliency\nThe newly emerging \ufb01eld of Explainable A.I. allows one to determine the logic behind a\nclassi\ufb01er\u2019s decision, in doing so indicating whether it is working as expected. Moreover,\nit gives one further insight into the data samples and the effects the features play within\nthe classi\ufb01cation.\nThroughout the HyperPT study we make use of a novel effective Explainable A.I.\nalgorithm known as LRP. This approach, as discussed thoroughly in Section 2.5, prop-\nagates back through the classi\ufb01er, analysing each layer of the model until it assigns an\nin\ufb02uence score to each input feature. Moreover we utilise a baseline explainability ap-\nproach known as Sensitivity Analysis (SA) with which to compare the LRP algorithm.\nLRP is put to use once the training and evaluation of the classi\ufb01cation model is\nconcluded. It is run on the trained classi\ufb01er, monitoring Nrandomly chosen articles.\nDue to the assigning of in\ufb02uence scores to each input feature, a saliency map for all\nthe article features is created, through which we determine which features are the most\nrelevant to the classi\ufb01cation. Hence say if a hypothetical topic of classi\ufb01cation would\nbe space exploration, words like astronauts and NASA would have more saliency in the\n59\nChapter 3. System Methodology 3.4. External Features\nclassi\ufb01cation decision compared with other words which are not as directly related to\nthe subject - such as people and environment [Arras et al. (2017)].\nBefore we analyse the features and corresponding in\ufb02uence scores, we make sure\nto evaluate the explainability algorithm itself to be sure that it is trustworthy in its pre-\ndictions. LRP is evaluated using a technique inspired by Arras et al. (2017) and Samek\net al. (2017), whereby we sequentially remove the saliency-\ufb02agged features in descend-\ning order and reclassify the corresponding article samples. In doing so we monitor the\nclassi\ufb01cation accuracy with each word removal, with the fastest degrade in accuracy im-\nplying the best feature saliency \ufb02agging. Hence LRP is evaluated in such a manner with\nthe SA algorithm and with random feature removal, as showcased in detail in Chapter\n4 (Section 4.3.3).\nLRP and SA are both implemented for the CNN model using the iNNvestigate16\nPython framework. Moreover in case of the SVM, we follow the work conducted by\nArras et al. (2017) in order to implement the LRP algorithm from \ufb01rst principles. Note\nthat due to the already clear discrepancy between LRP and SA in the evaluation process\nfor the CNN, and the constraints dictated by time limitations, we refrain from imple-\nmenting the SA algorithm as well on the SVM - since this would imply the building\nof such a technique from \ufb01rst principles as well. Moreover, none of the interpretability\nalgorithms are applied on the RF classi\ufb01er. This is since during the classi\ufb01er evaluation\nstages (which at this point were concluded), we were already aware from the exper-\niments conducted (Section 4.2) that the RF classi\ufb01er performs at an inferiority to the\nother two classi\ufb01ers, defeating the need for further work.\nFinally, a visualisation tool inspired by Arras et al. (2017) is introduced, where the\nclassi\ufb01ed articles are reassembled and each feature is highlighted inside of a heatmap.\nRed shading implies that the feature supports the hyperpartisan class, while blue shad-\ning infers that it opposes it, and white (colourless) implies that the feature is neutral in\nthe classi\ufb01cation. The restructuring of the original article features from the input vectors\nis not a trivial task to implement, and the best way we found to go about it is to sepa-\nrately maintain the preprocessed article tokens right before they are converted to feature\nrepresentation vectors. This is done such that later on throughout the process the input\nvectors could be matched back to the corresponding original textual features through\nelement-wise mapping, thereby mapping also the in\ufb02uence score for each feature.\n16iNNvestigate - github.com [Last Accessed : 07-2020]\n60\nChapter 3. System Methodology 3.5. Summary\n3.5 | System Methodology - Summary\nThroughout this chapter, we described our approach for the implementation of Hy-\nperPT - automatic classi\ufb01cation of hyperpartisan news articles. We started off in Section\n3.1 by discussing a high level overview of the project - highlighting in particular the\nthree main components forming the system. This was followed by an in-depth exam-\nination into the data sample loading and preprocessing, before the article features are\ntransformed into representation vectors - discussed in Section 3.2. Following this, in\nSection 3.3 we described the implementation of three classi\ufb01ers; SVM, RF and CNN for\nthe classi\ufb01cation of hyperpartisan news articles.\nFinally in Section 3.4 we discussed the integration of external features within the\nclassi\ufb01cation process, namely the addition of sentiment and analysis of the classi\ufb01er\u2019s\ndecision-making, resulting in the saliency of features as an external feature.\nIn Chapter 4 we now evaluate the HyperPT system, in the hopes of \ufb01nding the best\ncon\ufb01guration set-up for the problem at hand, while trying to achieve the best attainable\nperformance. In doing so, we also aim at taking a closer look at the hyperpartisan\narticle itself, with the aim of giving us further insight with which we could improve our\nsystem, and ensuing future work.\n61\n\n4\nSystem Evaluation and Discussion\nThe dynamic arrangement discussed in Chapter 3 enables us to ef\ufb01ciently evaluate the\nHyperPT system by conducting a diversity of experiments with a level of ease and celer-\nity.\nThroughout this chapter we discuss these experiments and evaluate the components\nmaking up the HyperPT system. We start off in Section 4.1 where tests are performed\nto establish the best feature representation and data preprocessing techniques. This is\nfollowed by Section 4.2, where we discuss the performance of the three classi\ufb01cation\nalgorithms introduced to the HyperPT system; the SVM, RF and CNN, comparing them\nwith each other and the state-of-the-art.\nHaving discussed the baseline classi\ufb01cation system, we then expand in Section 4.3\non the hyperpartisan article itself, addressing the introduction of sentiment as an extra\nfeature and the minimum length of the hyperpartisan article, along with the impact of\nthe article title on the system performance. Moreover we evaluate the Explainable A.I.\naspect of HyperPT which we then use to interpret the classi\ufb01cation model and generate\nin\ufb02uence scores for textual features within the hyperpartisan articles. Finally in Section\n4.4, the best system con\ufb01guration and classi\ufb01cation model is compared with the state-\nof-the-art and winner of the SemEval Hyperpartisan News Article 2019 challenge - Jiang\net al. (2019).\nFor each of these four sections, a series of experiments are performed, followed by\na succinct discussion on the results achieved and the derived implications, with the\nacquired knowledge then extended to the ensuing batch of experiments. In doing so we\ncreate a form of narrowing-down approach, where we maintain the best performing test\ncon\ufb01gurations for the succeeding tests, and eliminate the weaker candidates. Hence, we\ndecrease the otherwise large number of potential tests and converge towards a leading\nand generalised single system for the classi\ufb01cation of hyperpartisan news articles.\n63\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nNote that all tests are performed on the SemEval Hyperpartisan News Article dataset,\nmore particularly on the By-Article collection consisting of 645 articles. A thorough\nbackground on the dataset, its origin, features and limitations is given in Section 2.1.\n4.1 | Feature Representation and Data Preprocessing\nfor Hyperpartisan News Classi/uniFB01cation\nInitial tests are conducted to 1) establish the ideal feature representation with which to\nrepresent our articles and 2) determine which data preprocessing techniques would be\nthe most effective in cleaning the article features.\nWe conduct experiments using a number of feature representation technologies ap-\nplied alongside data preprocessing \ufb01lters. We experiment with both traditional well-\nknown feature representation methods and more modern word-embedding systems.\nChosen traditional approaches include TF [Potthast et al. (2018)], TF-IDF [Papadopoulou\net al. (2019)] and POS-Tags [Nguyen et al. (2019)].\nAmong a number of embedding systems, we retrain Word2Vec [Mikolov et al. (2013a,b)]\nembeddings on our dataset, while also experimenting with pretrained embeddings; pre-\ntrained Word2Vec, GloVe [Pennington et al. (2014)] and ELMo [Peters et al. (2018)]. The\nintegration of these systems and their use inside of the HyperPT system is discussed in\nChapter 3.\nThese listed feature representations are evaluated with \ufb01ve data preprocessing ap-\nproaches integrated within the HyperPT system; raw text, stopword removal, punctua-\ntion removal, lowercasing and lemmatisation.\nThe rest of Section 4.1 is structured as follows. In Section 4.1.1 feature represen-\ntation techniques are evaluated. We analyse the results acquired and choose the best\nperforming method of all seven. We then move on to determining the most effective\ndata preprocessing methods for the preparation of article features. This is addressed in\nSection 4.1.2.1, where we evaluate the performance of the \ufb01ve individual text cleaning\napproaches. Of these, the most promising ones are chosen and tested together in an\naggregated manner - tackled in Section 4.1.2.2. In doing so we determine whether the\nintegration of multiple preprocessing techniques increases or decreases the classi\ufb01cation\nperformance.\nFor any of the individual scores in the upcoming experiments, we decided on per-\nforming three separate yet identical tests, with the \ufb01nal result being the mean and stan-\ndard deviation of the three scores. Each of these tests is performed using 10-Fold Cross-\nValidation, with each test value being the mean of 10 accuracy scores.\n64\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nWe settled on three tests since we found that it strikes the best balance between re-\npeating the same test con\ufb01gurations for con\ufb01dence in results and allowing us enough\ntime to experiment with a high number of different test set-ups. We test in such rigorous\nfashion with the aim of evaluating the generalisation of different system con\ufb01gurations\nand increasing reliability in our assessment of the results acquired, considering the in-\nherently stochastic nature at the core of each classi\ufb01cation experiment.\n4.1.1 | Feature Representation for Hyperpartisan News Articles\nIn Table 4.1, 4.2 and 4.3 we observe accuracy results obtained for each feature represen-\ntation method coupled with individual preprocessing techniques. We test these couples\nwith the aim of determining the relationship and effects of each data preprocessing and\nfeature representation con\ufb01guration. In doing so we determine the typical behaviour\nexpected by each representation approach in use with each of the various data prepro-\ncessing methods. Based on the acquired results we then choose a number of the best\nperforming individual preprocessing techniques, and test them simultaneously in an\naggregate manner as discussed in Section 4.1.2.2.\nThe three tables mentioned above display feature representation and data prepro-\ncessing results respective to each of the three classi\ufb01ers implemented for hyperpartisan\nclassi\ufb01cation; Support Vector Machine (SVM), Random Forest (RF) and Convolutional\nNeural Network (CNN). Since they share the same experiment con\ufb01gurations, we can\neasily map speci\ufb01c con\ufb01guration results between any of the three classi\ufb01cation algo-\nrithms - in doing so we not only evaluate the generalisation of every approach across\nthe three classi\ufb01ers, but also the performance of each classi\ufb01er (Section 4.2).\n4.1.1.1 | Feature Representation using SVM Classi/uniFB01er\nWe start by examining results obtained using the SVM classi\ufb01er - showcased in Table 4.1.\nOne instantly observes a gap in performance between ELMo embeddings and its com-\npetitors for all \ufb01ve preprocessing con\ufb01gurations. It is the only representation method to\nachieve accuracy scores of 0.80 or above, and does so for four of the \ufb01ve con\ufb01gurations\nin which it is used, with the only exception being stopword removal; with an accuracy\nof 0.783 and a standard deviation of \u00b10.009. Moreover, the highest mean accuracy of\n0.813 (\u00b10.006) for the SVM is achieved again using ELMo and removal of punctuation.\nCompeting word embedding technologies (corpus-trained Word2Vec, pretrained Word2Vec\nand GloVe) do not fare as well as ELMo, achieving results in distinguishably lower\nranges and comparative to those of traditional approaches (TF, TF-IDF and POS-Tags).\n65\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nSupport Vector Machine\nRaw No Stopwords No Punctuation Lowercase Lemmatisation\nTF 0.747 (\u00b10.010) 0.763 (\u00b10.008) 0.755 (\u00b10.002) 0.751 (\u00b10.012) 0.751 (\u00b10.020)\nTF-IDF 0.767 (\u00b10.007) 0.758 (\u00b10.007) 0.771 (\u00b10.010) 0.765 (\u00b10.019) 0.768 (\u00b10.009)\nPOS-Tags 0.778 (\u00b10.019) 0.780 (\u00b10.006) 0.771 (\u00b10.004) 0.787 (\u00b10.002) 0.726 (\u00b10.012)\nWord2Vec 0.735 (\u00b10.013) 0.744 (\u00b10.010) 0.734 (\u00b10.014) 0.730 (\u00b10.010) 0.738 (\u00b10.006)\nWord2Vec (PT) 0.769 (\u00b10.005) 0.756 (\u00b10.007) 0.770 (\u00b10.005) 0.762 (\u00b10.009) 0.746 (\u00b10.012)\nGloVe (PT) 0.746 (\u00b10.012) 0.747 (\u00b10.014) 0.741 (\u00b10.009) 0.737 (\u00b10.007) 0.741 (\u00b10.012)\nELMo (PT) 0.800 (\u00b10.013) 0.783 (\u00b10.009) 0.813 (\u00b10.006) 0.808 (\u00b10.014) 0.800 (\u00b10.021)\nTable 4.1: Accuracy scores of a SVM classi\ufb01cation algorithm using individual Data Pre-\nprocessing and Data Representation con\ufb01gurations. Each result consists of the mean\naccuracy score of three identical 10-Fold Cross-Validation tests, along with the standard\ndeviation.\nPretrained Word2Vec seem to suffer the least in accuracy, exceeding corpus-trained\nWord2Vec and GloVe by around 0.10 to 0.30.\nPOS-Tagging may perhaps be considered the most effective of the lot, exceeding\nall competing feature representations (with the exception of ELMo) in four out of \ufb01ve\ncon\ufb01gurations with the sole disappointing score of 0.726 (\u00b10.012) when used with lem-\nmatised features (Lemmatisation). TF-IDF on the other hand seems to be a general im-\nprovement on TF, with the exception being in the case of stopword removal.\nFrom our analysis in the case of the SVM (Table 4.1), we derive two main observa-\ntions; the distinguishably better performance of ELMo to its competitors and the similar\nrange of accuracies of all the other alternative techniques, irrelevant of their nature. In\nresponse to these two observations one must ask why is this behaviour so in the \ufb01rst\nplace, and whether this is localised on the SVM or replicated for the other two classi-\n\ufb01ers; RF and CNN.\nTo shed some light on the \ufb01rst question, one must perhaps delve into the inner work-\nings of these representation technologies. Different to Word2Vec and GloVe, ELMo fea-\nture representation vectors are contextual; wherein a feature may be represented by\ndifferent dense vectors depending on the context in which it is used. Moreover, mor-\nphological clues are used for out-of-dictionary features in order to create bespoke vector\nembeddings [Peters et al. (2018)] (Section 2.2).\nThese distinctive attributes may give ELMo the extra edge in performance accu-\nracy re\ufb02ected in Table 4.1. Adding to this, competing word embedding technologies\nseem to fail at capturing corpus features and their contexts any better than traditional\nmethods. Unique features inside the dataset may not be available in the vocabulary\nupon which the embedding technologies are trained, particularly for pretrained meth-\n66\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nods (pretrained Word2Vec, GloVe and ELMo). ELMo caters speci\ufb01cally for this since it\nuses heuristically-supported predictors to establish new, context-sensitive representa-\ntion vectors.\nThis leaves us with the second question; whether this behaviour is replicated over\nother classi\ufb01cation algorithms or if it is just manifested in the case of SVM. To investigate\nthis, we now examine accuracy results for the RF classi\ufb01er, as displayed in Table 4.2.\n4.1.1.2 | Feature Representation using Random Forest Classi/uniFB01er\nExamining accuracy results for RF in Table 4.2, one con\ufb01rms that the performance monopoly\nof ELMo embeddings persists, albeit with a lower set of accuracy values. Moreover we\nnotice a trend of reduced accuracy results (compared to the SVM) all throughout this\nbatch of experiments. The highest score achieved is that of 0.785 (\u00b10.015) using ELMo\nvectors and feature lemmatisation - contrasting to the highest accuracy of 0.813 (\u00b10.006)\non the SVM.\nRandom Forest\nRaw No Stopwords No Punctuation Lowercase Lemmatisation\nTF 0.748 (\u00b10.008) 0.761 (\u00b10.007) 0.746 (\u00b10.012) 0.737 (\u00b10.008) 0.743 (\u00b10.002)\nTF-IDF 0.749 (\u00b10.014) 0.763 (\u00b10.007) 0.750 (\u00b10.009) 0.750 (\u00b10.010) 0.752 (\u00b10.017)\nPOS-Tags 0.705 (\u00b10.004) 0.694 (\u00b10.005) 0.713 (\u00b10.011) 0.709 (\u00b10.001) 0.696 (\u00b10.004)\nWord2Vec 0.743 (\u00b10.012) 0.762 (\u00b10.002) 0.750 (\u00b10.005) 0.750 (\u00b10.010) 0.760 (\u00b10.006)\nWord2Vec (PT) 0.757 (\u00b10.015) 0.732 (\u00b10.009) 0.756 (\u00b10.009) 0.739 (\u00b10.004) 0.746 (\u00b10.011)\nGloVe (PT) 0.743 (\u00b10.006) 0.734 (\u00b10.019) 0.734 (\u00b10.003) 0.748 (\u00b10.009) 0.731 (\u00b10.009)\nELMo (PT) 0.769 (\u00b10.012) 0.766 (\u00b10.012) 0.771 (\u00b10.014) 0.769 (\u00b10.008) 0.785 (\u00b10.015)\nTable 4.2: Accuracy scores of a RF classi\ufb01cation algorithm using individual Data Pre-\nprocessing and Data Representation con\ufb01gurations. Each result consists of the mean\naccuracy score of three identical 10-Fold Cross-Validation tests, along with the standard\ndeviation.\nThe notable performance of POS-Tags on SVM is not reciprocated in the case of RF,\nperforming the poorest of all feature representation techniques and being the only one to\nbreak below the 0.70 accuracy mark. While the slight improvement in accuracy between\nTF and TF-IDF persists, so does the lack of difference between traditional and alternative\nembedding technologies; with both Word2Vec and GloVe scoring in the same range of\nresults as that of TF and TF-IDF.\nELMo embeddings yet again suggest their enhanced representation capabilities over\nall other feature representations. The persistence of such behaviour also indicates their\ngeneralisation capabilities when used with different classi\ufb01cation algorithms.\n67\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nHaving evaluated feature representation methods using both SVM and RF classi-\n\ufb01ers, we are close to converging on a single feature representation method; ELMo em-\nbeddings. Before settling on ELMo and disqualifying all other feature representation\napproaches, we examine accuracy results for the CNN classi\ufb01er to determine whether\nthe dominating performance of ELMo embeddings persists.\n4.1.1.3 | Feature Representation using CNN Classi/uniFB01er\nIn Table 4.3, one examines classi\ufb01cation accuracies for feature representation approaches\nusing the CNN classi\ufb01er.\nHere we see a variation in the range of results not previously seen in previous ex-\nperiments, with accuracy scores ranging from as low as 0.567 (\u00b10.008) to as high as\n0.790 (\u00b10.018). The pattern noticed for ELMo embeddings in preceding experiments is\nrepeated here as well, achieving the highest accuracy results for nearly all data prepro-\ncessing con\ufb01gurations except for lemmatisation - where ELMo is exceeded in perfor-\nmance by corpus-trained Word2Vec.\nConvolutional Neural Network\nRaw No Stopwords No Punctuation Lowercase Lemmatisation\nTF 0.623 (\u00b10.022) 0.605 (\u00b10.008) 0.634 (\u00b10.005) 0.636 (\u00b10.011) 0.642 (\u00b10.008)\nTF-IDF 0.648 (\u00b10.005) 0.602 (\u00b10.016) 0.647 (\u00b10.009) 0.651 (\u00b10.008) 0.644 (\u00b10.014)\nPOS-Tags 0.573 (\u00b10.007) 0.567 (\u00b10.008) 0.589 (\u00b10.008) 0.568 (\u00b10.006) 0.668 (\u00b10.004)\nWord2Vec 0.761 (\u00b10.007) 0.772 (\u00b10.005) 0.765 (\u00b10.007) 0.766 (\u00b10.005) 0.771 (\u00b10.006)\nWord2Vec (PT) 0.746 (\u00b10.011) 0.755 (\u00b10.019) 0.759 (\u00b10.018) 0.758 (\u00b10.001) 0.742 (\u00b10.002)\nGloVe (PT) 0.773 (\u00b10.017) 0.759 (\u00b10.010) 0.749 (\u00b10.009) 0.770 (\u00b10.012) 0.762 (\u00b10.014)\nELMo (PT) 0.790 (\u00b10.018) 0.773 (\u00b10.010) 0.778 (\u00b10.012) 0.787 (\u00b10.008) 0.766 (\u00b10.004)\nTable 4.3: Accuracy scores of a CNN classi\ufb01cation algorithm using individual Data Pre-\nprocessing and Data Representation con\ufb01gurations. Each result consists of the mean\naccuracy score of three identical 10-Fold Cross-Validation tests, along with the standard\ndeviation.\nMoreover corpus-trained Word2Vec, for the \ufb01rst time, distinguishes itself from the\nother embedding representations (pretrained Word2Vec and GloVe). For the \ufb01rst time as\nwell, we see a difference between embedding and traditional representation technolo-\ngies, due to the fact that traditional methods achieve very poor results, with the worst\nperformer being yet again POS-Tags.\nIndeed none of the traditional methods achieve results at or over the 0.70 accuracy\nmark, which is a far cry from the notably better results achieved in previous experi-\nments. POS-Tags are without question the most controversial of the lot with the highest\nscores among traditional approaches for SVM and the lowest for both RF and CNN.\n68\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nComparing these experiments to their predecessors, the only variable to change is\nthe classi\ufb01er itself. Being the only Deep Learning (DL) classi\ufb01er of the three, one won-\nders whether the DL nature of CNN plays a part in this outcome. This along with the\nperformance of the SVM and the RF, is discussed further in Section 4.2.\nIn Section 4.1.1.1, Section 4.1.1.2 and Section 4.1.1.3, we discussed experiments con-\nducted on the three classi\ufb01cation algorithms. Now we address the overall performance\nof tested feature representation techniques to reach a conclusion as to the best approach\nfor hyperpartisan news classi\ufb01cation.\n4.1.1.4 | Feature Representation for Hyperpartisan News Articles - Overview\nFrom our analysis of accuracy scores in Table 4.1, Table 4.2 and Table 4.3, we observe\nELMo embeddings distinguishing themselves as the best tested feature representation\napproach. They achieve the highest accuracy in all individual data preprocessing con-\n\ufb01gurations tested, with standard deviation values maintained in the same range as that\nof competing data representation systems.\nFigure 4.1: Accuracy results for individual Data Representation techniques averaged\nover the three classi\ufb01cation algorithms; SVM, RF and CNN.\nThe superior performance of ELMo can perhaps be better visualised in Figure 4.1,\nwhere we plot the mean accuracy scores of tested data representation techniques as a\ntime-series chart. The pretrained ELMo embeddings are completely segregated at the\n69\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\n0.783 level, while competing word-embedding technologies are altogether clustered at\nthe 0.750/0.760 ranges, achieving more or less the same range of results.\nObserving Figure 4.1, all tested word-embedding technologies lie at a higher range\nto traditional data representation systems - in turn lying in the lower ranges of 0.680 to\n0.723. As expected from our observations in Section 4.1.1.3, POS-Tags result in the worst\nperformers, undoubtedly affected by their notably poor performance when tested using\nthe CNN classi\ufb01er (Table 4.3). Moreover, all traditional data representation techniques\nsuffer when used in conjunction with the CNN, resulting in a heavy impact on their\naveraged performance.\nWe hence conclude that pretrained ELMo Embeddings are the most effective feature\nrepresentation approach for all three classi\ufb01ers. In doing so we discontinue experiments\non all other data representation methods and establish ELMo as the chosen data repre-\nsentation technology for our system.\n4.1.2 | Data Preprocessing for Hyperpartisan News Articles\nIn Section 4.1.1 we performed experiments on various feature representation techniques\n- converging on ELMo embeddings [Peters et al. (2018)] as the best performing feature\nrepresentation approach out of the seven tested for the classi\ufb01cation of hyperpartisan\nnews articles.\nTested representations are simultaneously tested with \ufb01ve individual data prepro-\ncessing/cleaning methods; 1) raw textual features (no preprocessing applied), 2) re-\nmoval of stopwords, 3) removal of punctuation, 4) lowercasing of features and 5) lem-\nmatisation of features. In the upcoming Section 4.1.2.1, we discuss the performance of\neach of these approaches with respect to the three classi\ufb01ers. We re-examine the accu-\nracy scores achieved using ELMo embeddings with each of the aforementioned prepro-\ncessing approaches - in doing so evaluating their generalised performance.\nFrom these results we choose a number of the best performing preprocessing tech-\nniques, to then test them together in Section 4.1.2.2 as an aggregate preprocessing func-\ntion applied on the corpus features. This step is applied since unlike feature representa-\ntion approaches, data preprocessing methods can be, and often are, applied simultane-\nously on the same features as an aggregate preprocessing procedure.\n4.1.2.1 | Individual Data Preprocessing for Hyperpartisan News Articles\nIn order to examine the performance of individual data preprocessing techniques, we\nextract accuracy results from Table 4.1, 4.2 and 4.3 corresponding to each of the tested\n70\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\ndata preprocessing approaches in conjunction with ELMo embedded features. In doing\nso we examine preprocessing methods at their proven best performance - when used\nwith ELMo feature representations (Section 4.1.1).\nIn Table 4.4 one can observe these scores, along with the mean accuracy and standard\ndeviation of each technique across all three classi\ufb01cation algorithms; the SVM, RF and\nCNN.\nRaw No Stopwords No Punctuation Lowercase Lemmatisation\nSVM 0.800 (\u00b10.013) 0.783 (\u00b10.009) 0.813 (\u00b10.006) 0.808 (\u00b10.014) 0.800 (\u00b10.021)\nRF 0.769 (\u00b10.012) 0.766 (\u00b10.012) 0.771 (\u00b10.014) 0.769 (\u00b10.008) 0.785 (\u00b10.015)\nCNN 0.790 (\u00b10.018) 0.773 (\u00b10.010) 0.778 (\u00b10.012) 0.787 (\u00b10.008) 0.766 (\u00b10.004)\nMean 0.786 (\u00b10.014) 0.774 (\u00b10.010) 0.787 (\u00b10.011) 0.788 (\u00b10.010) 0.784 (\u00b10.013)\nTable 4.4: Individual and mean accuracy scores for all tested data preprocessing tech-\nniques using ELMo embeddings. The mean results consist of the mean performance of\neach data preprocessing approach when used in conjunction with ELMo embeddings\nacross the 3 classi\ufb01ers.\nAs is also observed in Section 4.1.1, we notice that the best results are achieved using\nSVM, with four out of \ufb01ve preprocessing methods scoring at or above the 0.80 mark. The\nhighest accuracy for both the SVM as well as the rest of the experiments is that of 0.813\n(\u00b10.006) - acquired using non-punctuated features.\nBetween each set of per-classi\ufb01er results we notice a reoccurring pattern where the\nhighest score is typically achieved using SVM, with the lowest being with the RF, and\nthe CNN lying in between. This pattern holds true for four out of the \ufb01ve preprocessing\napproaches, with lemmatisation being the exception where the RF classi\ufb01er score of\n0.785 (\u00b10.015) exceeds that of the CNN\u2019s 0.766 (\u00b10.004). This trend suggests that the\nSVM is perhaps the most adequate for handling the classi\ufb01cation problem at hand, with\nthe RF being the poorest. The same observation is also noted in experiments on feature\nrepresentation approaches in Section 4.1.1, and is discussed further in Section 4.2.\nWe evaluate the overall performance of preprocessing techniques by examining the\nmean accuracy for each across all three classi\ufb01ers as shown in Table 4.4. Albeit scoring\nthe highest individual score, No Punctuation settles at second place, with lowercasing of\nfeatures getting the slightly higher mean accuracy of 0.788 (\u00b10.010) to No Punctuation\u2019s\n0.787 (\u00b10.011). The reason behind this lies in the results acquired using CNN, where\nLowercase achieves signi\ufb01cantly higher accuracy to No Punctuation, balancing out the\notherwise slightly poorer performance in the case of both SVM and RF.\nRaw and lemmatised textual features follow closely behind at 0.786 (\u00b10.014) and\n0.784 (\u00b10.013), with the worst performer being stopword removal at 0.774 (\u00b10.010) -\n71\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nbeing also the only preprocessing method to score an accuracy below 0.80 (at 0.783) on\nthe SVM classi\ufb01er.\nDue to No Punctuation and Lowercase achieving the highest two mean accuracies,\none could argue that reducing the \u2019clutter\u2019 and cleaning the corpus text such that it con-\nsists of simple lowercased textual features facilitates the classi\ufb01cation process; further\npaving the way for the classi\ufb01er and thereby increasing the system\u2019s performance.\nOne must be careful however not to remove too many corpus features such that it\nimpairs the classi\ufb01cation performance. We believe this is the case for No Stopwords.\nThe removal of stopwords may very well be decreasing the inherent perception of hy-\nperpartisan articles, since albeit stopwords seeming trivial at \ufb01rst glance, the context in\nwhich a stopword is used may signi\ufb01cantly affect the meaning the article is trying to\nportray.\nFrom our observations above, we choose No Punctuation, Lowercase, Raw textual\nfeatures and Lemmatisation as the most promising individual contestants. We thereby\nopt to leave out solely the worst performer; No Stopwords, from aggregate prepro-\ncessing testing. In Section 4.1.2.2 we conduct testing using aggregate preprocessing\ntechniques and apply them simultaneously on the corpus features. In doing so we de-\ntermine whether aggregate solutions perform better or worse than individual ones for\nthe detection of hyperpartisan news articles.\n4.1.2.2 | Aggregate Data Preprocessing for Hyperpartisan News Articles\nFurther to the developments on data preprocessing in Section 4.1.2.1, we now combine\nthe four chosen approaches in a number of aggregate preprocessing operations, and\ncompare accuracy performances with that of individual preprocessing methods. In do-\ning so we test out whether aggregate cleaning of corpus features fares better or worse\nthan simpler, individual \ufb01ltering - before eventually converging on a single, best ap-\nproach.\nIn Table 4.5 we observe classi\ufb01cation results using both individual and aggregate\nfeature preprocessing, where we \ufb01nally compute the mean accuracy across all three\nclassi\ufb01ers. Individual preprocessing approaches consist of the four inherited from our\nexperiments in Section 4.1.2.1; Raw text, No Punctuation (NP), Lowercase (LC) and\nLemmatisation (LM). Aggregate preprocessing solutions are then combinations of the\nlatter three; No Punctuation + Lowercase (NP + LC), No Punctuation + Lemmatisation\n(NP + LM), Lowercase + Lemmatisation (LC + LM), and \ufb01nally No Punctuation + Low-\nercase + Lemmatisation (NP + LC + LM).\nOne immediately notices the inferior performance of aggregate solutions to individ-\n72\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\nAccuracy Results for Aggregate Preprocessing Techniques\nSVM RF CNN Mean\nRaw 0.800 (\u00b10.013) 0.769 (\u00b10.012) 0.790 (\u00b10.018) 0.786 (\u00b10.014)\nNo Punctuation (NP) 0.813 (\u00b10.006) 0.771 (\u00b10.014) 0.778 (\u00b10.012) 0.787 (\u00b10.011)\nLowercase (LC) 0.808 (\u00b10.014) 0.769 (\u00b10.008) 0.787 (\u00b10.008) 0.788 (\u00b10.010)\nLemmatisation (LM) 0.800 (\u00b10.021) 0.785 (\u00b10.015) 0.766 (\u00b10.004) 0.784 (\u00b10.013)\nNP + LC 0.788 (\u00b10.015) 0.765 (\u00b10.002) 0.763 (\u00b10.006) 0.772 (\u00b10.008)\nNP + LM 0.777 (\u00b10.006) 0.773 (\u00b10.006) 0.754 (\u00b10.014) 0.768 (\u00b10.009)\nLC + LM 0.791 (\u00b10.021) 0.778 (\u00b10.009) 0.774 (\u00b10.012) 0.781 (\u00b10.014)\nNP + LC + LM 0.794 (\u00b10.016) 0.763 (\u00b10.017) 0.772 (\u00b10.019) 0.776 (\u00b10.017)\nTable 4.5: Accuracy results and their standard deviations for individual and aggre-\ngate Data Preprocessing techniques using ELMo Embeddings. All scores are the mean\nof three separate and identical tests, with each being the score of a 10-Fold Cross-\nValidation.\nual ones; with solely (NP + LM) and (LC + LM) scoring higher than some individual\napproaches and only when applied along with the RF classi\ufb01er. Conversely, the rest\nof the aggregate results are poorer than their counterparts, especially in the case of the\nSVM and CNN.\nThe best performing aggregate solution out of all would be (LC + LM) - achieving the\nhighest score of the lot with all three classi\ufb01cation algorithms. This is further elucidated\nwhen examining the mean accuracies over the three classi\ufb01ers, where (LC + LM) is the\nonly aggregate solution to achieve a mean score higher than 0.780 [at 0.781 (\u00b10.014)].\nThis score still falls short however, compared to any of the individual approaches, with\nthe highest mean score of all experiments in Table 4.5 being Lowercase at 0.788 (\u00b10.010)\nand No Punctuation following close behind at 0.787 (\u00b10.011).\nGiven these observations we eliminate all aggregate solutions and focus on individ-\nual ones. The decision for the ultimate data preprocessing procedure lies between No\nPunctuation and Lowercase, with the two having respective mean accuracies of 0.788\nand 0.787. Examining the mean standard deviations of each, we \ufb01nd a slightly higher\ndeviation for No Punctuation (at 0.011) than for Lowercase (at 0.010). Albeit the differ-\nence being such a small margin, this does offer the suggestion that Lowercase also tends\nto vary less (albeit not by much) between experiments, making it more reliable.\nKeeping this in mind we also notice a slightly higher performance in aggregate pre-\nprocessing solutions containing the lowercasing of features. Examining the mean ac-\ncuracies of the four aggregate approaches, one notices that the lowest score of the lot\n(0.768) is achieved with (NP + LM) - being the only procedure not containing lower-\ncased features. Moreover, adding Lowercase to this combination such that we have (NP\n73\nChapter 4. System Evaluation and Discussion 4.1. Data Preprocessing and Representation\n+ LC + LM) boosts the mean accuracy by nearly 10% to an accuracy of 0.776 - further\nvalidating the positive effects of feature lowercasing.\nThe notable effectiveness of feature-lowercasing and the reasons behind it are inter-\nesting points to investigate. Since lowercasing tends to reduce the size of the corpus\nvocabulary due to some uppercased and capitalised features being the same as other\nlowercased ones, we think this may perhaps decrease the complexity and variety of\nthe corpus articles, particularly for such a small dataset as the SemEval Hyperpartisan\nNews Articles dataset (Section 2.1). The reduction in complexity may increase the classi-\n\ufb01cation accuracy due to the article being simpler for the classi\ufb01cation algorithm to work\nwith.\nFrom the results acquired we hence conclude on lowercasing of all corpus features\nas the ideal preprocessing stage before hyperpartisan news classi\ufb01cation is performed.\nIn doing so we incorporate this procedure in all of the ensuing tests and eliminate all\nthe other contestants.\n4.1.2.3 | Data Preprocessing for Hyperpartisan News Articles - Overview\nThroughout Section 4.1.2 we discussed and evaluated a variety of data preprocessing\ntechniques for the classi\ufb01cation of hyperpartisan news articles.\nWe started off in Section 4.1.2.1 with individual, simplistic data cleaning approaches,\nnamely; raw untouched features, removal of stopwords, removal of punctuation, low-\nercasing and \ufb01nally lemmatisation of corpus features. We performed classi\ufb01cation ex-\nperiments with each of three classi\ufb01ers - SVM, RF and CNN. In doing so we evaluated\nthe classi\ufb01cation performance of each, to \ufb01nally eliminate the removal of stopwords\ndue to its inferior performance (refer to Table 4.4) before proceeding to experiment with\naggregate preprocessing techniques in Section 4.1.2.2.\nAggregate solutions consist of different combinations of multiple individual prepro-\ncessing approaches applied simultaneously on article features. Four aggregate solu-\ntions are tested in all and compared with each other as well as with their individual\ncounterparts (refer to Table 4.5). Despite the added complexity they fail to outperform\naccuracies achieved using simpler individual techniques at almost every scenario.\nObserving both individual and aggregate performances, we \ufb01nally settle on lower-\ncasing of article features as the ideal data preparation process before the article features\nare fed to the corresponding classi\ufb01cation algorithms.\n74\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\n4.1.3 | Feature Representation and Data Preprocessing for Hyper-\npartisan Classi/uniFB01cation - Discussion\nIn Section 4.1 we evaluated ideal feature representation and data preprocessing ap-\nproaches for data preparation before classi\ufb01cation could be performed.\nInitial experiments in Section 4.1.1 consisted of establishing one feature representa-\ntion with which to ef\ufb01ciently represent hyperpartisan article features. Both traditional\nand word-embedding technologies were tested, with traditional features consisting of\nTF, TF-IDF and POS-Tags, and word-embedding approaches namely corpus-trained\nand pretrained Word2Vec, pretrained GloVe and \ufb01nally pretrained ELMo.\nELMo was established as the best performing feature representation approach for\nour articles features, with a clear improvement on performance compared to any of\nthe other approaches (refer to Figure 4.1). Hence ELMo is maintained throughout all\nensuing tests as the go-to feature representation of hyperpartisan news article features.\nHaving established an ideal feature representation approach, we then focused on\nrepeating the same sets of experiments to determine ideal data preprocessing techniques\n(if any) for the preparation of article features. This was tackled in Section 4.1.2, where we\ndiscussed the performance of both individual and aggregate preprocessing solutions.\nAnalysis of acquired accuracy results implies that removal of punctuation and low-\nercasing of features come head to head as the two best preprocessing techniques, with\nlowercasing of features performing slightly better and being more consistent in nearly\nall experiments, thereby establishing itself as the go-to data preprocessing application\nfor our hyperpartisan news classi\ufb01cation system.\nIn Section 4.1 we established the ideal feature representation and data preprocessing\napproaches for the classi\ufb01cation of hyperpartisan news articles. In doing so we con-\nclude the initial stages of our experimentations, extending the knowledge acquired and\nthe established methods to the succeeding segment; Section 4.2, where we review the\nalready conducted experiments and moreover perform new tests to evaluate the perfor-\nmance of classi\ufb01cation algorithms with the hopes of converging on the best performing\none to be used throughout the HyperPT system.\n4.2 | Classi/uniFB01er for Hyperpartisan News Classi/uniFB01cation\nIn our previous discussions we established ELMo embeddings [Peters et al. (2018)] as\nthe most effective approach for representing our corpus features, which, as con\ufb01rmed\nalso in Section 4.1, should be lowercased so that their maximum potential is utilised.\n75\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nWe now examine the classi\ufb01cation algorithms themselves, namely the SVM, RF and\nCNN. Throughout this section we analyse the nature of these three algorithms, compare\ntheir performance with that of one another, and highlight the strengths and weaknesses\nof each to \ufb01nally decide on a single approach.\nThe rest of this section is structured as follows. In Section 4.2.1 we apply hyperpa-\nrameter tuning on each of the three algorithms listed above with the aim of establishing\nthe best hyperparameter con\ufb01guration for each. Afterwards in Section 4.2.2 we proceed\nto evaluate the classi\ufb01cation performance of each classi\ufb01er, in doing so re-examining ex-\nperiments conducted in Section 4.1 along with further new testing. Finally we remark\nour conclusions and verdict on the ideal classi\ufb01cation algorithm for hyperpartisan news\narticles - detailed in Section 4.2.3.\n4.2.1 | Hyperparameter Tuning for Hyperpartisan News Classi/uniFB01ca-\ntion\nWe perform hyperparameter tuning on each classi\ufb01cation algorithm (SVM, RF and CNN)\nwith the aim of establishing the ideal con\ufb01guration for maximising the classi\ufb01er per-\nformance. Note that in practice hyperparameter tuning is conducted in conjunction\nwith initial experimentations on different feature representations and data preprocess-\ning techniques; such that the classi\ufb01er is already optimised and tweaked for any state\nof the preprocessed features.\nSome minor changes to the classi\ufb01er hyperparameters are recommended depending\non the applied feature representations and data preprocessing, however 1) The major\nhyperparameter con\ufb01gurations are clearly established no matter which preprocessing\ncon\ufb01guration is used and 2) In order to maintain our focus on the established prepro-\ncessing approaches (Section 4.1), we focus on hyperparameter tuning with respect to\nlowercased features represented as ELMo embedded vectors.\nIn conducting our experiments we implement a Grid Search optimisation approach,\nwhere a grid of different hyperparameter possibilities is generated, following which all\ncombinations are individually tested. Random Search was also considered at this stage,\nhowever considering that 1) the number of hyperparameters is not very large and 2) the\ntesting itself is not too time consuming; we decided on testing out all possible con\ufb01gu-\nrations and leave no room for doubt.\nWe test using 10-Fold Cross Validation, similar to all preceding testing discussed in\nSection 4.1. In doing so we evaluate the reliability of each hyperparameter con\ufb01guration\nand its generalisation abilities while maintaining a high level of performance over differ-\n76\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nent hyperpartisan news articles. SKLearn\u2019s GridSearchCV1tool is utilised to automate\nthe above process; exhaustively searching for the ideal hyperparameter con\ufb01guration\nusing 10-Fold Cross Validation testing.\n4.2.1.1 | Hyperparameter Tuning the SVM Classi/uniFB01er\nThe SVM classi\ufb01er is tested on three separate hyperparameters; 1) the SVM kernel, 2) the\nkernel coef\ufb01cient gand 3) the regularisation parameter l. We perform our experiments\non the four main types of SVM kernels; Linear, Sigmoid, Polynomial and RBF. All of\nthese kernels with the exception of Linear (since it does not require a kernel coef\ufb01cient)\nare evaluated using four gsamples as displayed in Table 4.6.\nThe four samples for gand the four for lare generated from a log scale ( 10x), where\nxis respectively between \u00005 to 3, and\u00002 to 3. This logarithmic distribution allows us to\nexplore the range of possible values quicker by scaling with an equal scale of difference\nwith each candidate value [Joshi et al. (2016); Pedregosa et al. (2011)]. More on the SVM\nand the corresponding hyperparameters can be perused in Chapter 2.\nHyperparameter Samples\nKernelLinear\nSigmoid\nPolynomial\nRBF\nKernel Coef\ufb01cient g1.00\u000210\u00005\n4.64\u000210\u00003\n2.15\u000210+0\n1.00\u000210+3\nRegularisation Parameter l1.00\u000210\u00002\n4.64\u000210\u00001\n2.15\u000210+1\n1.00\u000210+3\nTable 4.6: SVM classi\ufb01er hyperparameters evaluated using Grid-Search hyperparameter\ntuning.\nInitial testing including a variety of preprocessing approaches (Section 4.1) sug-\ngested a close tie between the Linear kernel and the more complex RBF kernel. The other\ntwo kernels (Sigmoid and Polynomial) are very rarely chosen through Grid-Search, with\nmultiple experiments converging on either the Linear or the RBF kernels.\nShifting our focus to ELMo embeddings with lowercased vectors we see a differ-\nent outcome, where the RBF kernel dominates over multiple experiments as the most\n1SKLearn GridSearchCV - www.scikit- learn.org [Last Accessed: 06-2020]\n77\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nadequate SVM kernel for the classi\ufb01cation of hyperpartisan news articles. Moreover\na kernel coef\ufb01cient gof 4.64\u000210\u00003is suggested as the ideal accompanying coef\ufb01cient,\nwith the SVM regularisation parameter lat 2.15\u000210+1. Over the substantial number of\ntuning experiments conducted on the SVM, this con\ufb01guration achieves a mean accuracy\nof 0.805 and a highest accuracy of 0.840.\n4.2.1.2 | Hyperparameter Tuning the RF Classi/uniFB01er\nCompared to the SVM, the RF classi\ufb01er offers us a wider range of hyperparameters to\ntune. Moreover the seemingly poorer overall performance of the algorithm discussed\nback in Section 4.1 further compels us to perform extensive hyperparameter tuning. In\nTable 4.7 we observe the hyperparameters tuned for the RF classi\ufb01er.\nHyperparameter Samples\nNumber of Estimators50\n200\n500\nMaximum Tree Depth3\n5\nNone\nMaximum Features1\n10\nAuto\nMinimum Sample Split2\n3\n10\nBootstrappingTrue\nFalse\nCriterionGini\nEntropy\nTable 4.7: RF classi\ufb01er hyperparameters evaluated using Grid-Search hyperparameter\ntuning.\nWe again test out all hyperparameter combinations using Grid-Search with 10-Fold\nCross Validation. RF hyperparameters include:\n\u0004The number of estimators/trees to use during classi\ufb01cation.\n\u0004The maximum tree depth, which when set to None implies that no limit is set and\nis expanded as much as necessary.\n78\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\n\u0004The maximum amount of features to consider when looking for the best split. If\nset to Auto ,p\nnum .f eatures is considered by default.\n\u0004The minimum number of samples necessary to split a tree node.\n\u0004Whether to bootstrap the classi\ufb01er or not. If so, samples are used to build the\nclassi\ufb01er trees - if not, the whole dataset is used.\n\u0004The criterion with which to measure the quality of each node split.\nGrid-Search results acquired from multiple experiments indicate that the Entropy\ncriterion performs best in nearly all cases, particularly for ELMo embedded and lower-\ncased features. A high numbers of estimators is suggested, with test Grid-Search results\nvarying between 200 and 500. Despite an estimator count of 200 obtaining less erratic re-\nsults, the highest accuracy of 0.796 is achieved with 500 estimators, with 200 estimators\nfollowing closely behind at 0.793.\nIn all experiments conducted, the maximum tree depth is strongly suggested to be\nkept to None (thereby being expanded as much as necessary). The maximum number\nof features is also to be maintained at Auto , implying again a dynamic adaptation to the\nnumber of features during runtime. Interestingly, a minimum samples split of 2 is main-\ntained for tests recommending 200 estimators, while a samples split of 10 is emphasized\nfor 500 estimators. Bootstrapping is not recommended in any of the tests, implying the\nuse of the whole dataset for the generation of each tree.\n4.2.1.3 | Hyperparameter Tuning the CNN Classi/uniFB01er\nThe CNN implementation is based on the state-of-the-art introduced by Jiang et al.\n(2019); consisting of \ufb01ve convolutional layers followed by Batch Normalization and a\ndense classi\ufb01cation layer (Chapter 2). Despite this static structure, we maintain a num-\nber of experiments on other aspects of the network with the hopes of enhancing the\nalgorithm\u2019s performance and tune it further to the problem at hand.\nAs observable in Table 4.8, four hyperparameters are tested; the ideal number of\ntraining epochs, the batch size at which data batches are inserted, whether to use batch\nnormalisation (as suggested by Jiang et al. (2019)), and whether to use early stopping\n(with differing epoch tolerances). Much the same as the tuning for the other two ap-\nproaches, Grid-Search using 10-Fold Cross Validation is used for the monitoring of re-\nsults and performance.\nFrom the acquired results we notice a few similarities with the system proposed by\nJiang et al. First off the number of epochs is maintained at the relatively low value of 30,\n79\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nHyperparameter Samples\nNumber of Epochs30\n50\n100\nBatch Size15\n32\n50\nBatch NormalisationTrue\nFalse\nEarly StoppingTolerance of 2 Epochs\nTolerance of 5 Epochs\nNone\nTable 4.8: CNN classi\ufb01er hyperparameters evaluated using Grid-Search hyperparame-\nter tuning.\nsuggesting a possibility of over\ufb01tting with more epochs. The same can be said for the\nbatch size, which is kept the same at 32. Batch Normalisation is the third parameter to\nbe preserved - being recommended in every test iteration.\nFinally we get to early stopping. It seems that in our case such a regularisation tech-\nnique is more of a hindrance than an aid, leading us to note that with both tolerances\nof 2 and 5 epochs the algorithm training is perhaps still terminated prematurely. We\nbelieve that particularly in the case of the CNN, the size of the dataset upon which it\nis trained does have a strong affect not only the classi\ufb01er\u2019s performance but also the\nhyperparameter preference. We think that the particularly negative outcome experi-\nenced throughout tests involving early stopping to those consisting of full training is a\ndirect result of the small nature of our dataset (SemEval Hyperpartisan news articles),\nimplying a tendency for the classi\ufb01er to be under-\ufb01tted on the data.\nHaving said so, the low number of training epochs should, in our case, keep the\npossibility of over-\ufb01tting at bay. A mean accuracy of 0.788 and a highest accuracy of\n0.830 is achieved during hyperparameter tuning using the proposed hyperparameter\ncon\ufb01guration.\n4.2.1.4 | Hyperparameter Tuning - Discussion\nIn Section 4.2.1 we determined the ideal hyperparameter con\ufb01guration for each of three\nclassi\ufb01ers; SVM, RF and CNN. The conclusions drawn are based on lowercased arti-\ncle features represented as ELMo embedded vectors - as chosen by initial experiments\nconducted in Section 4.1.\n80\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nIn tuning the hyperparameters for the SVM, we determined that RBF is the best\nperforming kernel. The use of this kernel is coupled with a kernel coef\ufb01cient gof 4.64\u0002\n10\u00003and a misclassi\ufb01cation regularisation parameter lof 2.15\u000210+1.\nIn the case of RF, Entropy is preferred to Gini as the measure of impurity at each\nnode. The lack of bootstrapping slows down the training time yet increases performance\naccuracy. Finally among other hyperparameters, we decide on moving forward with\n200 estimators (trees), since from the experiments conducted we \ufb01nd that it is the most\ngeneralised approach.\nFinally we evaluated the CNN hyperparameters to discern that the majority of the\nresulting parameter con\ufb01gurations mirror those of the state-of-the-art presented by Jiang\net al. (2019). This holds true for the number of training epochs - set at 30, the batch size,\nset at 32, and the con\ufb01rmed effectiveness of batch normalisation within the classi\ufb01er.\nReaching the same hyperparameter con\ufb01gurations as the state-of-the-art gives us trust\nin our work, since it indicates that our implementation is of the quality and precision\nnecessary to reach the same conclusions as the state-of-the-art.\n4.2.2 | Evaluating HyperPT Classi/uniFB01er performance\nFollowing hyperparameter tuning for our classi\ufb01cation algorithms, in Section 4.2.2 we\nevaluate the effectiveness of these classi\ufb01ers.\nIn Section 4.2.2.1 we \ufb01rst discuss the performance of the three tested classi\ufb01ers with\nthat of one another. Using these observations we then reach our conclusion on the most\nadequate classi\ufb01cation algorithm for the classi\ufb01cation of hyperpartisan news articles.\nThe now decreased number of tests from the initial preprocessing experiments con-\nducted in Section 4.1 make it feasible to also take into consideration the F1 score in con-\njunction with the accuracy. F1 (Section 2.6) is a measure which gives us the weighted\nmean between the precision and recall. Such a statistic is important in evaluating the\nperformance of different classi\ufb01ers, since it informs us how generalised the classi\ufb01er is\nin its predictions.\n4.2.2.1 | Evaluating Classi/uniFB01er performance on Hyperpartisan News Classi/uniFB01cation\nWe display the corresponding accuracy results for our three classi\ufb01ers in Table 4.9. Here\nwe list both the mean and highest, accuracy and F1 scores for each classi\ufb01cation algo-\nrithm, be it; the SVM, RF, or CNN. Moreover, we list as well the highest score for each in\ncase of comparisons with other research which may include the highest scores achieved.\nWe examine two sets of experiments for each classi\ufb01er; one using lowercased fea-\ntures (+ LC), since lowercasing of features was chosen (back in Section 4.1.2) as the\n81\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nbest performing general data preprocessing, and another using alternative preprocess-\ning based on the ideal classi\ufb01er performance (observed in Section 4.1). Here we \ufb01nd no\npunctuation (+ NP), lemmatisation (+ LM) and \ufb01nally raw features (+ Raw).\nClassi\ufb01er Mean Accuracy Mean F1 score Highest Accuracy Highest F1 score\nSVM + LC 0.808 (\u00b10.013) 0.722 (\u00b10.009) 0.809 0.730\nSVM + NP 0.813 (\u00b10.006) 0.722 (\u00b10.006) 0.821 0.726\nRF + LC 0.769 (\u00b10.008) 0.648 (\u00b10.019) 0.777 0.659\nRF + LM 0.785 (\u00b10.015) 0.646 (\u00b10.005) 0.795 0.650\nCNN + LC 0.787 (\u00b10.008) 0.699 (\u00b10.019) 0.797 0.713\nCNN + Raw 0.790 (\u00b10.018) 0.708 (\u00b10.013) 0.822 0.719\nTable 4.9: Mean and Highest accuracy and F1 results for each classi\ufb01cation algorithm.\nTwo sets of tests are performed for each classi\ufb01er; one using lowercased features and the\nother using data preprocessing approaches with which initial scores were the highest.\nAll features are represented as ELMo Embeddings.\nWe observe in Table 4.9 that the best mean accuracy, that of 0.813 (\u00b10.006), is main-\ntained by the SVM using No Punctuation (NP), with the highest accuracy achieved be-\ning that of 0.821. These scores are accompanied by the mean and highest respective F1\nscores of 0.722 (\u00b10.006) and 0.726. One notices that the SVM seems to be more adapted\nto non-punctuated than lowercased features, achieving better accuracies at just about\nthe same F1 scores.\nDespite a signi\ufb01cant reduction in mean accuracy, CNN classi\ufb01cation on raw features\nachieves the highest accuracy score throughout - that of 0.822. Compared with the re-\nsults discussed above, the difference in accuracy (0.001) may be considered negligibly\nsmall, more so since 1) a lower F1 score implies that the CNN is not as balanced as the\nalternative and 2) higher deviations from the mean accuracy and F1 imply a decrease in\nthe consistency of the CNN performance.\nTraining on such a small number of data points as our dataset (Section 2.1) may very\nwell be limiting the CNN from reaching its full potential - resulting in similar or poorer\naccuracy ranges to those of alternative traditional approaches. This phenomenon is also\ndocumented in published literature [Arras et al. (2017); Zhang et al. (2015)], where the\nauthors note that the performance of the CNN truly becomes superior to that of TFIDF-\nbased traditional systems when trained on large datasets typically consisting of millions\nof data samples.\nFrom our discussion above we \ufb01nd that the SVM would be the better choice for\nclassifying hyperpartisan news articles, when compared with both the CNN and RF.\nWe base our conclusion on the SemEval Hyperpartisan dataset upon which this study is\n82\nChapter 4. System Evaluation and Discussion 4.2. Classi/uniFB01er\nconducted, however we do not take into consideration solely the performance metrics\nput forward in Table 4.9, but also the \ufb02exibility, resource requirements and feasibility of\neach method.\nFrom the accuracy results analysed above, it is clear that the SVM consistently reaches\nhigher mean accuracies than the CNN and the RF. It \ufb01ts the classi\ufb01cation problem bet-\nter, as judged by higher all-round F1 scores. Moreover standard deviations included\nwith the mean metric values suggest less variations in accuracy results over multiple\nexperiments.\nDespite their superior performance, DL classi\ufb01ers take comparatively longer to train\nand require both larger amounts of training data and more advanced hardware con\ufb01g-\nuration. These prerequisites are not justi\ufb01ed by the above results, making the SVM a\nmore favourable approach not only due to the better classi\ufb01cation performance but also\ndue to simply requiring less resources, less time and less data. Hence we conclude on\nthe SVM as our classi\ufb01er for the detection of hyperpartisan news articles.\nDespite establishing lowercasing of features as the recommended overall prepro-\ncessing step over all tested classi\ufb01ers (Section 4.1.2), one notices that in the speci\ufb01c case\nof the SVM, removal of punctuation seems to work better - typically resulting in a higher\nand more balanced classi\ufb01cation performance. Thereby we conclude that if one is set\non using the SVM as the classi\ufb01cation algorithm, such as in our case, non-punctuated\nfeatures may very well be a better option.\nWe observe that the reason behind this increased performance may be since the\nremoval of punctuation decreases the ambiguity and complexity from the textual se-\nquence, which for classi\ufb01ers (such as the SVM) not taking context into consideration,\nfacilitates the classi\ufb01cation process. In ensuing tests, we hence consider the removal of\npunctuation from article features as much as lowercasing.\n4.2.3 | Classi/uniFB01er for Hyperpartisan News Classi/uniFB01cation - Discus-\nsion\nIn Section 4.2 we discussed the performance of the three classi\ufb01cation algorithms (SVM,\nRF and CNN) employed within the HyperPT system for the classi\ufb01cation of hyperpar-\ntisan news articles. Having tuned our classi\ufb01er hyperparameters as speci\ufb01ed in Section\n4.2.1, we then observed and compared the accuracy results and F1 scores (Section 4.2.2).\nFrom these outcomes we concluded on the SVM as the best performing classi\ufb01ca-\ntion algorithm for the classi\ufb01cation of hyperpartisan news articles. This conclusion is\nsupported by the proven superior performance of the SVM - having the highest mean\naccuracy (0.813 [\u00b10.006]) and highest mean F1 score (0.722 [\u00b10.006]). The RF seems to\n83\nChapter 4. System Evaluation and Discussion 4.3. External Features\nstruggle to properly \ufb01t the problem at hand, presenting the poorest performance of the\nthree. Moreover, the simpler, more feasible nature of the SVM compared to the CNN\nmakes it more feasible to handle and maintain.\nWith the evaluation of the classi\ufb01ers we conclude the evaluation of the baseline clas-\nsi\ufb01cation system employed within HyperPT. In Section 4.3.1 we explore external fea-\ntures with the aim of embedding them within the classi\ufb01cation process to investigate\ntheir effect on the system performance and in doing so delve further into the typical\nnature of a hyperpartisan article.\n4.3 | E/uniFB00ectiveness of Sentiment and additional Features\non Hyperpartisan News Classi/uniFB01cation\nIn Section 4.1 we established ELMo embeddings and lowercasing of data features as\nthe best performing feature representation and generalised preprocessing approaches\nacross the three tested classi\ufb01ers for the classi\ufb01cation of hyperpartisan news articles. In\nthe succeeding Section 4.2 we tuned our classi\ufb01ers and settled on the best performing\none; the SVM.\nThroughout this section we experiment with a number of non-conventional features,\nwith the aim of investigating the resultant effects on the overall performance of the\nclassi\ufb01cation, and in doing so exploring further the typical nature of such news articles.\nIn Section 4.3.1 we \ufb01rst discuss the addition of sentiment within the article textual\nfeatures. We experiment with sentiment embedding techniques to investigate the va-\nrieties in classi\ufb01cation performance. Finally we conclude on whether, from the results\nacquired, to maintain sentiment features within the HyperPT system, or discard them.\nFollowing the evaluation of sentiment, we investigate (Section 4.3.2) the effects of\ndiffering article lengths, and the addition of the article title. This is followed by Section\n4.3.3, where we measure the degree of saliency (in\ufb02uence) of each feature within by\ninterpreting the corresponding classi\ufb01cation. In doing so we not only observe the typi-\ncal features supporting or opposing hyperpartisanship, but also observe the classi\ufb01ers\u2019\nbehaviour in generating the classi\ufb01cation labels.\n4.3.1 | Sentiment as a Feature for Hyperpartisan News Classi/uniFB01ca-\ntion\nAgendas behind hyperpartisan news articles often aim at sensationalising ideas about\nthe topics being presented (Chapter 1). We hence believe it is crucial to investigate\n84\nChapter 4. System Evaluation and Discussion 4.3. External Features\nthe integration of sentiment represented as external features embedded within corpus\narticles, with the aim of determining whether sentiment indeed plays a notable role in\nclassifying hyperpartisan news.\nWe perform tests on thirteen different sentiment feature con\ufb01gurations, with the\naim of benchmarking the approaches with the best non-sentiment classi\ufb01cation results\nand possibly establish the best sentiment feature composition (if any). In doing so, we\nalso evaluate the system\u2019s performance, balance and reliability with the integration of\nsentiment.\nAs discussed in Section 3.4.1, we experiment with sentiment as a compounded score,\na negative score, and a textual label (positive/negative) at the article level and at the\nsentence level. We include negative scores by themselves along with the compound\nscore since other studies [Anthonio and Kloppenburg (2019)] report increased classi\ufb01-\ncation performance using solely negative sentiment scores, rather than positive or com-\npounded.\nFurthermore, we perform additional experiments where sentiment scores are scaled\nby a factor of 1000 in order to determine whether such scaling of sentiment weights\naffects the classi\ufb01cation performance, and in what way. The value of 1000 was chosen\nsince we felt that this strikes a balance between proper scaling of the sentiment scores,\nwithout over-exaggerating the score values. Lastly we conduct tests with all VADER\nscores (positive, negative, neutral and compound) embedded within each article, a tech-\nnique inspired by Pali\u00b4 c et al. (2019).\nFollowing the conclusive results obtained in Section 4.1 and Section 4.2, we perform\nour sentiment analysis experiments using ELMo embeddings along with the SVM clas-\nsi\ufb01er. Separate yet identical sets of tests are performed on the corpus stripped of any\npunctuation and the corpus with lowercased features, since, as discussed earlier, these\ntwo preprocessing approaches have been proven to perform the best with this classi\ufb01er.\nCorresponding accuracy and F1 scores can be examined in Table 4.10.\n4.3.1.1 | Evaluating Sentiment as a Feature for Hyperpartisan News Classi/uniFB01ca-\ntion\nExamining performance results in Table 4.10, one notices that in none of the tests in-\nvolving sentiment is the corresponding accuracy or F1 score comparative to or exceed-\ning scores achieved without sentiment. This holds true for both lowercased and non-\npunctuated features. Indeed the main characteristics of tests involving sentiment are\na reduction in accuracy and F1 score, with higher standard deviations from the mean\nscores. This would imply that the SVM struggles more to \ufb01t the classi\ufb01cation problem\n85\nChapter 4. System Evaluation and Discussion 4.3. External Features\nLowercase\nSentiment Features Accuracy F1 Score\nNo Sentiment 0.808 (\u00b10.013) 0.722 (\u00b10.009)\nGlobal Label - Article 0.757 (\u00b10.008) 0.617 (\u00b10.013)\nDerived Label - Article 0.732 (\u00b10.085) 0.637 (\u00b10.035)\nCompound Score - Article 0.773 (\u00b10.014) 0.643 (\u00b10.019)\nCompound Score \u00021000 - Article 0.778 (\u00b10.013) 0.655 (\u00b10.025)\nNegative Score - Article 0.781 (\u00b10.003) 0.660 (\u00b10.006)\nNegative Score\u00021000 - Article 0.775 (\u00b10.012) 0.646 (\u00b10.020)\nLabel - Sentence 0.782 (\u00b10.011) 0.656 (\u00b10.021)\nCompound Score - Sentence 0.780 (\u00b10.008) 0.651 (\u00b10.018)\nCompound Score \u00021000 - Sentence 0.762 (\u00b10.005) 0.617 (\u00b10.008)\nNegative Score - Sentence 0.777 (\u00b10.012) 0.642 (\u00b10.027)\nNegative Score\u00021000 - Sentence 0.774 (\u00b10.013) 0.634 (\u00b10.028)\nPos, Neg, Neu, Comp - Article 0.782 (\u00b10.006) 0.659 (\u00b10.017)\nPos, Neg, Neu, Comp \u00021000 - Article 0.776 (\u00b10.011) 0.652 (\u00b10.019)\nNo Punctuation\nSentiment Features Accuracy F1 Score\nNo Sentiment 0.813 (\u00b10.006) 0.722 (\u00b10.006)\nGlobal Label - Article 0.766 (\u00b10.006) 0.612 (\u00b10.014)\nDerived Label - Article 0.762 (\u00b10.004) 0.596 (\u00b10.008)\nCompound Score - Article 0.769 (\u00b10.014) 0.616 (\u00b10.023)\nCompound Score \u00021000 - Article 0.755 (\u00b10.011) 0.582 (\u00b10.016)\nNegative Score - Article 0.760 (\u00b10.009) 0.596 (\u00b10.029)\nNegative Score\u00021000 - Article 0.756 (\u00b10.010) 0.591 (\u00b10.018)\nLabel - Sentence 0.775 (\u00b10.003) 0.624 (\u00b10.008)\nCompound Score - Sentence 0.768 (\u00b10.009) 0.611 (\u00b10.013)\nCompound Score \u00021000 - Sentence 0.762 (\u00b10.004) 0.593 (\u00b10.014)\nNegative Score - Sentence 0.767 (\u00b10.016) 0.618 (\u00b10.032)\nNegative Score\u00021000 - Sentence 0.777 (\u00b10.005) 0.635 (\u00b10.013)\nPos, Neg, Neu, Comp - Article 0.770 (\u00b10.008) 0.609 (\u00b10.013)\nPos, Neg, Neu, Comp \u00021000 - Article 0.767 (\u00b10.003) 0.603 (\u00b10.011)\nTable 4.10: Accuracy and F1 scores of different sentiment feature embedding techniques.\nClassi\ufb01cation is performed using the SVM classi\ufb01er. Lowercasing of features and re-\nmoval of punctuation is applied separately on the corpus features, all which are rep-\nresented as ELMo Embeddings. Each of the listed scores is the mean and standard\ndeviation of three identical tests.\n86\nChapter 4. System Evaluation and Discussion 4.3. External Features\nwith sentiment included rather than without - resulting in a more chaotic and unreliable\nsystem.\nIn the case of lowercased as well as non-punctuated features, sentence-level sen-\ntiment features seem to perform slightly better than article-level ones, suggesting the\npossibility of more granular sentiment being less invasive and distracting to the classi-\n\ufb01er. Moreover, scaling sentiment scores seems to be an obstruction to the classi\ufb01cation,\nwith a reduction in performance in nearly all cases.\nInterestingly, results for experiments including sentiment hint towards better per-\nformance using lowercased features to those non-punctuated. Being the proven best\ngeneralised preprocessing approach back in Section 4.1, we think that lowercased fea-\ntures may be more tolerant across different classi\ufb01ers, and able to interfere less than\nother data preprocessing with external features such as sentiment.\nDiffering to Anthonio and Kloppenburg (2019), we do not see any particular im-\nprovement from compound scores to negative. Both sentiment metrics seem to score\nin the same range of values along all test cases. Moreover, taking into consideration all\nVADER scores as suggested by Pali\u00b4 c et al. (2019) does seem to improve on the classi\ufb01-\ncation performance compared to alternative article-level sentiment experiments, yet not\nby much. Indeed despite these reported improvements and the two systems using the\nsame classi\ufb01cation system that is the SVM, there is still no question that classi\ufb01cation\nwithout sentiment, in our case, would be preferred.\n4.3.1.2 | Sentiment as a Feature for Hyperpartisan News Classi/uniFB01cation - Discus-\nsion\nHaving thoroughly tested sentiment features embedded within hyperpartisan article\ntextual features, the corresponding results are somewhat disappointing. As displayed\nin Table 4.10, among all experiments in which sentiment is involved both the accuracy\nand the F1 score suffered.\nIn calculating the F1 measure for each experiment, we noticed the same pattern\nthroughout all embedding con\ufb01gurations; a high precision with very poor recall. Such\nconsistently poor recall implies a high number of false negatives during classi\ufb01cation.\nIn our case this means a high number of article samples which in reality are hyperpar-\ntisan, being classi\ufb01ed as neutral. Due to the low recall score, the F1 measure itself is\ndecreased, while the accuracy score is reduced due to the number of articles wrongly\nclassi\ufb01ed as neutral.\nSuch an observation would suggest the hypothesis that the article sentiment could\nbe masking further the already obscure nature of hyperpartisan articles. Indeed, it does\n87\nChapter 4. System Evaluation and Discussion 4.3. External Features\nseem from the results acquired that hyperpartisan news articles are not so easily distin-\nguishable from their sentimental aspects, as one may initially assume.\nFigure 4.2: Average accuracy results for different sentiment embedding con\ufb01gurations\naveraged over no punctuation and lowercased textual features. Textual features are\nrepresented as ELMo embeddings and results are obtained for the SVM classi\ufb01er.\nIn Figure 4.2 we plot the mean accuracy and F1 scores across both lowercased and\nnon-punctuated features. A clear and distinguishable discrepancy in performance can\nbe noticed between classi\ufb01cation without any sentiment features, and any of the other\nexperiments involving sentiment. Hence we conclude that from our testing the inclu-\nsion of sentiment with article features is not bene\ufb01cial for the classi\ufb01cation of hyperpar-\ntisan news articles, and thereby should not be included.\nOne must however ask why similar systems [Anthonio and Kloppenburg (2019);\nPali\u00b4 c et al. (2019)] report positive outcomes when incorporating sentiment. The answers\nas subjective to each system, with Anthonio and Kloppenburg (2019) focusing solely on\nthe sentiment within the articles. The researchers only see an improvement in accuracy\nwhen VADER negative score is taken into account (as opposed to VADER compound).\nHowever with an accuracy of 0.5616, we and other systems achieving the same ranges of\nhigher baseline performance than Anthonio and Kloppenburg (2019) do not experience\nthe same levels of improvement.\nIn case of Pali\u00b4 c et al. (2019), we notice that despite the improvements reported through\nthe addition of sentiment, the authors achieve highest accuracy scores of 0.76128. With\nthis accuracy the system is comparable to the performance of HyperPT when sentiment\n88\nChapter 4. System Evaluation and Discussion 4.3. External Features\nis included. Moreover, similar systems like Joo and Hwang (2019) mirror the reduction\nin performance encountered by our system during the above testing.\nDifferent to the three systems above, we also represent our features as ELMo em-\nbeddings [Peters et al. (2018)]. This is a different approach to the feature representation\ntechniques utilised by these studies and moreover, we are unsure whether in similar\nsystems sentiment features are passed directly with textual features in the same way\nour system does or in a different manner, since this is not made particularly clear by the\nresearchers.\nThese concerns could undoubtedly be explored further, and we do not believe to\nhave explored all of the potential within the sentiment aspects of hyperpartisan news\narticles. Having said so, from the results above we conclude on leaving sentiment out\nof the \ufb01nal HyperPT system con\ufb01guration, focusing on the textual article features them-\nselves and individual feature elements which could be pivotal to the hyperpartisan na-\nture of the article.\n4.3.2 | Title and Body of a Hyperpartisan News Article\nIn trying to determine the versatility of the HyperPT classi\ufb01cation system as well as\ngain further insight into the possible manifestations of hyperpartisan news articles, we\nperform experiments with the article title and article bodies of differing lengths. We\nperform training and testing on just the article titles and on the article body of different\nlengths - with and without the title. The corresponding test results can be examined in\nTable 4.11. The same seven experiments are performed on both lowercased and non-\npunctuated features (Section 4.1 and Section 4.2) - represented as ELMo embeddings\nand classi\ufb01ed using an RBF kernel SVM.\n4.3.2.1 | Evaluating Title and Body of a Hyperpartisan Article\nObserving test results in Table 4.11, one notices that the article title does produce some\ninteresting insights. Testing on solely the article title does, as may be expected, decrease\nthe performance accuracy, yet surprisingly not by so much. Indeed it still does fairly\nwell, achieving accuracies upwards of 70%. One however also notes that the corre-\nsponding F1 measure is signi\ufb01cantly decreased to just upwards of 0.5 - implying de-\ncreased reliability and balance in the classi\ufb01cations.\nDespite not being enough on its own to safely discard the article body, the title ap-\npears to enhance classi\ufb01cation when appended to the body. The previously best scores\nof 0.813 (\u00b10.006) [mean accuracy] and 0.722 (\u00b10.006) [mean F1] achieved using non-\npunctuated features and full article body are exceeded by the same con\ufb01guration with\n89\nChapter 4. System Evaluation and Discussion 4.3. External Features\nLowercase\nFeatures Mean Accuracy Mean F1 Score Highest Accuracy Highest F1 Score\nTitle 0.708 (\u00b10.009) 0.561 (\u00b10.013) 0.719 0.576\nTitle + Body (5 Sen) 0.756 (\u00b10.004) 0.653 (\u00b10.002) 0.760 0.654\nTitle + Body (15 Sen) 0.785 (\u00b10.005) 0.697 (\u00b10.010) 0.790 0.709\nTitle + Body (Full) 0.805 (\u00b10.003) 0.732 (\u00b10.005) 0.808 0.735\nBody (5 Sen) 0.743 (\u00b10.011) 0.628 (\u00b10.018) 0.756 0.648\nBody (15 Sen) 0.771 (\u00b10.015) 0.679 (\u00b10.030) 0.787 0.711\nBody (Full) 0.808 (\u00b10.013) 0.722 (\u00b10.009) 0.809 0.730\nNo Punctuation\nFeatures Mean Accuracy Mean F1 Score Highest Accuracy Highest F1 Score\nTitle 0.718 (\u00b10.008) 0.572 (\u00b10.012) 0.725 0.585\nTitle + Body (5 Sen) 0.779 (\u00b10.013) 0.684 (\u00b10.021) 0.793 0.707\nTitle + Body (15 Sen) 0.800 (\u00b10.012) 0.714 (\u00b10.017) 0.813 0.732\nTitle + Body (Full) 0.822 (\u00b10.011) 0.745 (\u00b10.012) 0.835 0.758\nBody (5 Sen) 0.754 (\u00b10.004) 0.643 (\u00b10.007) 0.758 0.649\nBody (15 Sen) 0.774 (\u00b10.005) 0.677 (\u00b10.008) 0.780 0.681\nBody (Full) 0.813 (\u00b10.006) 0.722 (\u00b10.006) 0.821 0.726\nTable 4.11: Accuracy and F1 Scores using article title and body of multiple lengths.\nFeatures are represented as ELMo embeddings while classi\ufb01cation is performed using\nSVM.\nthe addition of the article title. A mean accuracy of 0.822 (\u00b10.011) and a mean F1 score\nof 0.745 (\u00b10.012) is achieved, with the highest overall accuracy being that of 0.835 and\nthe highest F1 of 0.758.\nConcurrently with the article title, we test the article body at different lengths. Since\nit is processed as a series of sentences, we trim the article length by specifying the\nnumber of sentences to tolerate while removing the rest. Three different article lengths\nare examined; \ufb01ve sentences (simulating an introductory paragraph), \ufb01fteen sentences\n(roughly analogous to two large or three small paragraphs), and \ufb01nally the entirety of\nthe news article.\nA correlation between the article length and the classi\ufb01cation performance is notice-\nable, where accuracy and F1 measure scores increase gradually with the length of the\narticle for any con\ufb01guration tested. This may be since a lengthier article provides more\ndata to be analysed. The addition of the title once again seems to improve the perfor-\nmance of any body length experiment - particularly visible for non-punctuated features,\nwhere we see an average of \u00181.8% increase in accuracy and a \u00183% increase in F1 score.\nJust the same as observed with the article title, the classi\ufb01cation performance on\nreduced article lengths, albeit degrading, is still maintained at a respectable range, even\n90\nChapter 4. System Evaluation and Discussion 4.3. External Features\nwith such a small portion of the article being analysed as just \ufb01ve sentences; achieving\nmean accuracy scores of 0.756 (\u00b10.004) and 0.779 (\u00b10.013) respectively for lowercased\nand non-punctuated features.\n4.3.2.2 | Title and Body of a Hyperpartisan Article - Discussion\nOne \ufb01nds several systems incorporating the article title within the classi\ufb01cation. Jiang\net al. (2019) embed the article title features preceding to the body. Joo and Hwang (2019)\ntake this work further by computing the sentiment of the article title and its cosine sim-\nilarity to the article body. Systems such as Chen et al. (2019) alternatively take into con-\nsideration the length of the title, of the contained words and the number of capitalised\nwords embedded within.\nIn considering the inclusion of the title within HyperPT, we proceeded with Jiang\net al. (2019)\u2019s simpler approach rather than more elaborated metrics. This is due to\ntwo reasons; the natural time limitations encompassing the study (discussed further in\nChapter 5) and since research on alternative systems shows that the acquired perfor-\nmance does not justify the effort needed in implementing more elaborate techniques,\nrather than simply embedding the title with the body.\nWe display the results to our experimentations in Table 4.11. We feel that the un-\nquestionable bene\ufb01t observed from the addition of the article title is reasonable. Given\nthat it is the introductory, crucial piece of text which readers skim to further peruse or\ndismiss an article, we are of the opinion that the main theme and narrative of the arti-\ncle would already be present in the title itself. Moreover, hyperpartisan news articles\nmay attempt to capture the attention of individuals with a tendency to skim over news\nheadlines through shocking or overly-dramatised titles. This is backed up by the rea-\nsonable accuracy results maintained when classifying solely the article title, divulging\nthe distinguishing hyperpartisan elements already inside of the article title.\nThe same could be said on the length of the article. Despite the classi\ufb01cation pro-\ncess being performed on a small portion of the article, reasonable accuracy results are\nmaintained. Performance is further increased with the length of the article, yet taking\ninto consideration the introductory few sentences of the article, one observes the already\nrevealing hyperpartisan nature at the very beginning of the text.\nFrom these insights we take away two important conclusions. The \ufb01rst one regards\nthe pure classi\ufb01cation aspects of the HyperPT system, where we include the article title\nand maintain the full length of the body due to the con\ufb01rmed best performance in doing\nso. The second is on the nature of the hyperpartisan article itself, where we observe how\nvery early on through the perusing of the text one is already seriously exposed to the\n91\nChapter 4. System Evaluation and Discussion 4.3. External Features\nin\ufb02ammatory, biased and distinguishable hyperpartisan style of writing [Potthast et al.\n(2018)].\n4.3.3 | Model Explainability and Saliency of Hyperpartisan Features\nWe analyse the classi\ufb01er\u2019s decision-making to determine not only its behaviour but also\nthe in\ufb02uence of each input feature within the classi\ufb01cation. We do so by using LRP, a\nmodel explainability technique adapted from Vision to the area of textual NLP [Arras\net al. (2016); Samek et al. (2017)], to retrace the steps from the output back through the\nclassi\ufb01er, till we reach the original input. As discussed with further detail in Section 2,\nLRP identi\ufb01es which features are pivotal in supporting or opposing a prediction class\nthrough decomposition; redistributing the prediction function through the classi\ufb01er\u2019s\nlayers to eventually assign what we call a relevance score to each input variable.\nThroughout this section, we repeat the same steps not only for the SVM classi\ufb01er, but\nalso for the CNN. This is since despite establishing better performance from the SVM\nclassi\ufb01er, we feel it would be a good opportunity to compare the two inherently different\nmodels in order to examine in which ways they are similar, and in which different.\nIn Section 4.3.3.1 we \ufb01rst evaluate the LRP algorithm against baseline techniques. We\ndo so to determine the effectiveness and reliability of the algorithm before putting it to\nuse on the hyperpartisan article samples. We then apply it on our classi\ufb01ers and monitor\nthe acquired results. The interpretability process is executed after the model is fully\ntrained, and is performed by reinputting a number of input samples (article vectors)\nthrough the classi\ufb01er, and capturing the outcome. LRP monitors the classi\ufb01cation and\nprovides each article input with a relevance score.\nFinally in Section 4.3.3.3 we discuss the results acquired and derive our conclusions\non the interpretability approach itself, the article features highlighted by this technique,\nwhat these results show us about the nature of the hyperpartisan article, and \ufb01nally\nhow can such features be leveraged for improved hyperpartisan news detection.\n4.3.3.1 | Evaluating Layer-Wise Relevance Propagation\nTo evaluate LRP, we implement an approach inspired by Samek et al. (2017), where fol-\nlowing the identi\ufb01cation of the most salient features inside of an article, each feature is\nsequentially removed, from the most in\ufb02uential to the least. With each feature removal,\nclassi\ufb01cation is performed on the article, and the corresponding accuracy is monitored.\nThis process is executed simultaneously on a number of articles, with the mean accuracy\nacross the articles at each classi\ufb01cation run being plotted.\n92\nChapter 4. System Evaluation and Discussion 4.3. External Features\nThe same process is repeated on alternative techniques; random feature removal and\nin the case of CNN, Sensitivity Analysis (SA). We expect the mean accuracy to drop the\nfastest and the furthest for the best detected salient features, since the removal of these\nfeatures would imply the deterioration of the classi\ufb01cation quality. Hence we can say\nthat the interpretability process resulting in the heaviest accuracy deterioration is the\nbest.\nFigure 4.3: Evaluating the LRP interpretability algorithm by removing the 50 and 100\nmost salient features and monitoring the corresponding accuracy on the SVM classi\ufb01er.\nIn a more ideal scenario we would have utilised SA as well on the SVM, but due to\nno direct way found for facilitating its implementation, the only possible way was to\nbuild the algorithm from \ufb01rst principles which, limited by time constraints, we decided\nnot to opt for. Besides, having already developed the LRP algorithm for the SVM in\nsimilar fashion (Chapter 2), we believe that from the evaluation results below; against\nrandom feature removal in case of the SVM, and with the addition of SA for the CNN,\nthe superior performance of LRP is clearly de\ufb01ned.\nMoreover due to the Min-Max pooling of ELMo features before SVM classi\ufb01cation\n(Chapter 2), we realised that it would be impossible to map back the aggregated and\naveraged vector representing the whole article to each individual feature. Therefore we\ndecided on utilising TF-IDF representations which, after LRP rankings are issued, can\nbe easily mapped to the corresponding textual features.\nIn Figure 4.3 one can observe the evaluation process of the LRP interpretability tech-\nnique on the SVM classi\ufb01er. Having ranked the features of 50 separate and correctly-\nclassi\ufb01ed articles, the top 50, and top 100 in\ufb02uential features for each article are suc-\n93\nChapter 4. System Evaluation and Discussion 4.3. External Features\ncessively removed. The accuracy starts from 100% only due to the purposely chosen\narticles being initially classi\ufb01ed correctly. We hence see the gradual degradation of the\nSVM classi\ufb01cation accuracy on these 50 articles with each removal of an in\ufb02uential fea-\nture.\nFigure 4.4: Evaluating the LRP interpretability algorithm by removing the 100 most\nsalient features and monitoring the corresponding accuracy on the CNN classi\ufb01er.\nThe same process can be observed for the CNN classi\ufb01er (Figure 4.4), where in this\ncase the accuracy degradation using LRP is also plotted against that using SA. As can\nbe clearly observed from both Figure 4.3 and Figure 4.4, a large discrepancy in accuracy\nexists between the removal of LRP-\ufb02agged features and any of the other approaches.\nThe poorest of the lot, as expected, would be random feature removal, where we ran-\ndomly select and eliminate one of the article features. This is in no way an educated\ndecision and therefore the likeliness of removing a highly salient feature is small.\nMoreover, SA (in the case of CNN) performs just slightly better than random feature\nremoval. This is not however unexpected, since similar outcomes were reported by pub-\nlished literature [Arras et al. (2016); Samek et al. (2017)]. Indeed the SA algorithm can be\nconsidered as a more primitive method compared to its counterpart - being based on the\nclassi\ufb01er\u2019s locally-evaluated gradient, while LRP redistributes the classi\ufb01er\u2019s prediction\nback all the way through to the input. Moreover LRP is capable of detecting both fea-\ntures supporting a classi\ufb01cation and features opposing it, while SA is only capable of\nthe former.\nWith these observations we can con\ufb01rm that using LRP on our classi\ufb01ers does in-\ndeed provide us with the most salient input features making up the hyperpartisan news\n94\nChapter 4. System Evaluation and Discussion 4.3. External Features\nFigure 4.5: A snippet of an article2correctly classi\ufb01ed as hyperpartisan using the SVM\nclassi\ufb01er. The most salient features in the snippet are tagged using LRP. Red-tagged\nfeatures support the Hyperpartisan classi\ufb01cation while blue-tagged features oppose it.\narticles. In Section 4.3.3.2 we now map back the rankings provided to the respective\ntextual features such that we would be able to reconstruct and visually observe the in-\n\ufb02uence of each feature.\n4.3.3.2 | Determining the Saliency of Hyperpartisan Features\nHaving evaluated the LRP interpretability algorithm, we now analyse the saliency scores\nfor the chosen articles. Following the LRP\u2019s saliency scores, we then map the feature\nvectors and corresponding scores back to the original words, reassembling the whole\narticle.\nInspired by Arras et al. (2017)\u2019s approach, we generate a heatmap of the article fea-\ntures by assigning a colour-code to each feature according to its in\ufb02uence value, with\nred implying that the feature supports hyperpartisanship while blue implies opposing\nit and supporting neutrality. White features are considered as not holding any speci\ufb01c\nin\ufb02uence within the classi\ufb01cation. Moreover, the intensity of each feature colour deter-\nmines the level of saliency the feature holds within the classi\ufb01cation.\nIn Figure 4.5 and Figure 4.6 one observes snippets of two articles, one hyperpartisan\nand the other neutral, classi\ufb01ed using the SVM classi\ufb01er. As discussed in Section 4.3.3.1,\nfeatures in this case are represented as a Bag-of-Words (BoW) of TF-IDF values. One\nmust also note that due to the nature of the BoW representation and the inner-workings\nof the SVM, the same feature, no matter in which part of the article it is situated, is given\nthe same in\ufb02uence - resulting in the same colour-code and intensity throughout all of\nthe article. As we shall see further down, this differs when using the CNN classi\ufb01er.\n2Under Trump, opposing \u2019chain migration\u2019 is even bigger than \u2019amnesty\u2019 - www.washingtonexaminer.\ncom[Last Accessed: 07-2020]\n3President-Elect Trump Tours Washington - www.nbcnews.com [Last Accessed: 07-2020]\n95\nChapter 4. System Evaluation and Discussion 4.3. External Features\nIn the \ufb01rst article (Figure 4.5), one notices a lack of neutral features and two particu-\nlar words \ufb02agged as being of hyperpartisan nature - repeatedly present throughout the\narticle snippet. These two words are Trump and immigration , with two other hyperparti-\nsan words being chain and DACA . With Trump and DACA both being proper nouns, we\nnotice, throughout the rest of the article along with other, similar hyperpartisan cases,\nthat the highest \ufb02agged hyperpartisan features tend to be proper nouns. Conversely,\n\u2019heavy\u2019 and superlative words such as fails, disaster, threatens and terrorism are not given\nsuch distinguishable in\ufb02uence scores.\nThe highlighting of proper nouns is also present in articles classi\ufb01ed as neutral. In\nFigure 4.6 we \ufb01nd one such article. Indeed one can notice the persistence of the word\nTrump being \ufb02agged as hyperpartisan. Interestingly, despite being \ufb02agged as so, related\nwords such as President and Donald are highlighted as neutral. From our analysis on\nsimilar articles bearing the same patterns, we propose a hypothesis as to why this, and\nsimilar cases, are so.\nArticles which are typically of a neutral nature tend to report on high-pro\ufb01le indi-\nviduals like the current president of the United States (being one of the most mentioned\nentities throughout our dataset) in full as a sign of authoritative respect - either as Pres-\nident Donald Trump orPresident Trump . Hyperpartisan articles, on the other hand, often\nattempt to criticise and ridicule the same individual, with the majority of the time refer-\nring to him simply as Trump . Hence the words President and Donald are more commonly\nfound in articles of neutral nature, while Trump is widely used in hyperpartisan ones.\nThe rigid nature of hyperpartisan features classi\ufb01ed using SVM is not shared with\nthose classi\ufb01ed using CNN. Indeed in the case of the CNN we are faced with a level\nof ambiguity within the article features, since in this case the context is also taken into\nFigure 4.6: A snippet of an article3correctly classi\ufb01ed as neutral using the SVM classi\ufb01er.\nThe most salient features in the snippet are tagged using LRP. Red-tagged features\nsupport the Hyperpartisan classi\ufb01cation while blue-tagged features oppose it.\n96\nChapter 4. System Evaluation and Discussion 4.3. External Features\nFigure 4.7: A snippet of an article2correctly classi\ufb01ed as hyperpartisan using the CNN\nclassi\ufb01er. The most salient features in the snippet are tagged using LRP. Red-tagged\nfeatures support the Hyperpartisan classi\ufb01cation while blue-tagged features oppose it.\nFigure 4.8: A snippet of an article3correctly classi\ufb01ed as neutral using the CNN classi-\n\ufb01er. The most salient features in the snippet are tagged using LRP. Red-tagged features\nsupport the Hyperpartisan classi\ufb01cation while blue-tagged features opposite it.\nconsideration. Moreover, each feature can be given different in\ufb02uential scores for each\noccurrence within the article, since the in\ufb02uence score is not dependent solely on the\nword itself, but also on the neighbouring features.\nFigure 4.7 and Figure 4.8 showcase the same two articles discussed above, classi-\n\ufb01ed and interpreted on the CNN classi\ufb01er. As one can observe, the sharp, well de\ufb01ned\nfeatures observed with the SVM are not present, yet we do notice that neighbouring\nclusters of features tend to share the same ranges of in\ufb02uence scores. This is particu-\nlarly apparent in Figure 4.7, where the phrases immigration system fails Americans and\nthreatens our security share the same ranges of hyperpartisan intensity. Furthermore,\nwe notice that proper nouns such as Trump , which were previously \ufb02agged as extreme\nhyperpartisan, now vary according to where they are used.\nExamining the neutral article featured in Figure 4.8, we notice more mixture of hy-\nperpartisan and neutral features than in the case of the SVM (Figure 4.6). Not only so,\nbut completely different sections of the article are highlighted, and where in the previ-\nous case we noticed solely the word Trump \ufb02agged as hyperpartisan, we now see various\n97\nChapter 4. System Evaluation and Discussion 4.3. External Features\nfeatures which, according to the LRP interpretability scores, support the hyperpartisan\nside of the classi\ufb01cation.\nHence indeed we notice an added layer of ambiguity and complexity with the CNN\nclassi\ufb01er not present with the simpler SVM. Moreover the two classi\ufb01ers do not neces-\nsarily depend on the same features throughout the classi\ufb01cation process, with the more\ncomplex and sensitive nature of the CNN possibly being a bene\ufb01t or a hindrance to the\nsystem performance. This is discussed further in Section 4.3.3.3, where we reach our\nconclusions on the discussed results.\n4.3.3.3 | Model Explainability and Saliency of Hyperpartisan Features - Discus-\nsion\nHaving examined in Section 4.3.3.2 the simpler, direct nature of the SVM on the article\nfeatures, and the more complex, context-based approach by the CNN, one asks which\napproach would be the best?\nIn answering this question, we think that for the dataset presently used by this study,\nthe SVM would be the best approach, both as shown by the classi\ufb01cation accuracies\nand the clear, straight to the point feature interpretations observed in Section 4.3.3.2.\nHowever we understand the limitations of the small dataset used (Section 2.1) and the\npossibility of the CNN outperforming any traditional methods with larger datasets and\nmore training data. This would de\ufb01nitely make for an interesting future project and\naddition to this work, as we remark further on in Chapter 5.\nOn another note, we compiled a list of the highest-scoring hyperpartisan and neu-\ntral features over 50 randomly-selected articles. Due to stopwords being present inside\nof the corpus and often times being \ufb02agged along with neighbouring features (in the\ncase of context-sensitive in\ufb02uence for the CNN), we omitted such words from this list,\nfocusing on more important, unique and interesting terms.\nObserving the top ranked features in terms of saliency as featured in Table 4.12,\none notices a number of proper nouns, particularly names of politically af\ufb01liated and\nwell-known individuals, such as Trump, Scott, Rauner, Hillary and Clinton . Moreover we\nobserve the multiple occurrences of important and often controversial entities such as\nFBIand ISIS.\nContrary to our initial hypotheses, in\ufb02ammatory words such as superlative adverbs\ndo not make the list for neither the SVM nor the CNN. This suggests an important\npossibility - that in classifying news articles for hyperpartisanship, both classi\ufb01cation\nalgorithms are more focused on the subject and the theme of the article rather than the\nway of writing. This then begs the question of whether topics similar to the ones upon\n98\nChapter 4. System Evaluation and Discussion 4.3. External Features\nSVM CNN\nNo. Hyperpartisan Neutral Hyperpartisan Neutral\n1Trump people Trump Trump\n2Conway ISIS York said\n3Scott Scott said Trumps\n4FBI Clinton Trumps house\n5Rauner Gaffney President new\n6emails story Hillary Hillary\n7justice Kimmel Clinton York\n8Fox Brown one people\n9women Fox new Republican\n10 ISIS Billy times according\n11 Ive victims video president\n12 Berkeley article immigration women\n13 social Korea people law\n14 theyre US immigrants wife\n15 Hillary said state 2016\nTable 4.12: Top 15 hyperpartisan and neutral words calculated over a sample 50\nrandomly-selected, correctly-classi\ufb01ed articles.\nwhich the classi\ufb01er is trained tend to be given the same label, and if new topics unseen\nby the classi\ufb01er heavily risk the possibility of being classi\ufb01ed wrongly.\nDespite the possibility of this outcome, we are of the opinion that measures could\nbe taken to minimise this risk. A larger and more diverse training dataset would \ufb01rst of\nall contain more diversity of topics. Moreover, we noticed that the dataset itself tends to\ncontain a high number of American political themes. Due to the nature of the problem\nof hyperpartisanship, this is expected - yet with more diversity and room for training,\nthe classi\ufb01er is then forced to look for other features upon which to determine the hy-\nperpartisanship of an article rather than letting itself settle on solely the entities within.\nFurthermore, manually giving extra weight to the tone of writing of the article rather\nthan simply the textual features within would incentivise the classi\ufb01cation process to\ndelegate more attention to these features, which coupled with a larger and more di-\nverse dataset would compel the classi\ufb01er to be more sensitive to otherwise overlooked\nfeatures, before settling on the classi\ufb01cation.\n99\nChapter 4. System Evaluation and Discussion 4.4. HyperPT against the State-of-the-Art\n4.3.4 | External Features of Hyperpartisan News Articles - Discus-\nsion\nIn Section 4.3 we experimented with features not typically included in the initial stages\nof a classic classi\ufb01cation process, but which are interesting to explore and hold potential\nfor improving the baseline classi\ufb01cation work\ufb02ow.\nWe started off in Section 4.3.1 by experimenting with sentiment features. We tried\na number of sentiment labelling and integration techniques within our articles, which\ndespite the efforts, all resulted in a hindrance to the classi\ufb01cation performance rather an\nimprovement - compelling us to exclude sentiment from further analysis.\nIn Section 4.3.2 we then experimented with the length of the article body and the\naddition of the title. We found that the length of the title does affect the classi\ufb01cation\naccuracy, with more length implying better performance. However we also noticed\nthat even for extremely short article lengths, the overall classi\ufb01er performance does not\ndecrease by a large amount, implying that hyperpartisan elements are already present\nin the very initial few words of the article. This was further enforced by the addition of\nthe title, where we noticed a performance increase in all experiment con\ufb01gurations.\nFinally, we used the LRP model explainability algorithm on our hyperpartisan article\ninstances with the aim of determining the most salient features affecting the classi\ufb01ca-\ntion process. This was addressed in Section 4.3.3, where we discussed how the most\nsalient features inside of the articles tend to be individuals and entities rather than de-\nscriptive words, implying that the classi\ufb01er is more preoccupied with the subject and\nentities within the article than the style of writing.\nHaving evaluated both the baseline classi\ufb01cation process behind HyperPT, and ex-\nternal features which support further the classi\ufb01cation, we close off Chapter 4 by \ufb01nally\ncomparing our system with the current state-of-the-art and winner of the 2019 SemEval\nHyperpartisan News Articles challenge, Jiang et al. (2019).\n4.4 | Evaluating HyperPT against the State-of-the-Art\nIn evaluating the HyperPT system, we established the SVM as the best performing\ndata preprocessing and feature representation approaches for our data, with the CNN\nfollowing not too far behind. Moreover we investigated the use of external features,\nnamely; sentiment, article title, article length, and salient features - with the aim of ex-\nploiting these for the bene\ufb01t of better detection and shedding more light on the nature\nof the hyperpartisan news article.\n100\nChapter 4. System Evaluation and Discussion 4.4. HyperPT against the State-of-the-Art\nThroughout this section, we \ufb01nally take all of this into consideration and compare\nthe HyperPT system with the state-of-the-art. At the time of writing, the state-of-the-art\nand winner of the 2019 Hyperpartisan News Article challenge4is Jiang et al. (2019) -\nalso known throughout the competition as Team Bertha Von Suttner.\n4.4.1 | The State-of-the-Art in Hyperpartisan News Classi/uniFB01cation\nBeing a direct inspiration to this study, Jiang et al. (2019)\u2019s proposed system shares a\nnumber of similarities with HyperPT. Features are represented as ELMo embeddings,\nyet different to our case, Jiang et al. (2019) average word vectors for each sentence, such\nthat sentences are represented as singular vectors. In our case we maintain each corpus\narticle as a set of consecutive word embeddings. We do so since albeit resulting in\nsmaller volumes of data and faster training times, we think that averaging word vectors\nmay to some extent counter the granularity provided by ELMo and thereby be more of\na hindrance than an advantage to the classi\ufb01cation performance.\nThe CNN classi\ufb01er utilised by HyperPT is, as well, based on the architecture pro-\nposed by Jiang et al. (2019) - consisting of \ufb01ve parallel convolutional layers with kernel\nsizes of 2, 3, 4, 5 and 6. These layers are followed by ReLU activation, batch normali-\nsation and \ufb01nally max-pooling before the output is forwarded to the fully-connected\nclassi\ufb01cation layers. Moreover Jiang et al. (2019) train multiple CNN models through\n10-Fold Cross Validation, choosing the best three models to then be organised into an\nensemble classi\ufb01cation system, where the classi\ufb01er results are averaged into one output\nlabel. More details on the CNN and its architecture can be found in Chapter 2.\n4.4.2 | HyperPT vs the State-of-the-Art - Discussion\nIn comparing our system with that of Jiang et al. (2019), we couldn\u2019t evaluate the two\nsystems directly due to two primary setbacks; a hidden test set used during the SemEval\nHyperpartisan challenge is not made public, and hence we cannot use it to evaluate\nour system on the same test set. Moreover, sacri\ufb01cing a chunk from the public training\ndataset and using it as a replacement for the original hidden one may result in an under-\ntrained classi\ufb01er due to the smaller size of the train set. This hence leaves us with one\noption, to compare the two systems based solely on the results achieved during the\nCross Validation training phase.\n4PAN SemEval Hyperpartisan News Detection (2019) - www.pan.webis.de/semeval19 [Last Accessed:\n05-2020]\n101\nChapter 4. System Evaluation and Discussion 4.4. HyperPT against the State-of-the-Art\nFurthermore, the authors do not include whether the achieved training accuracy of\n0.8404 is the mean over several tests or whether this is the highest accuracy achieved.\nWe hence consider this both as the mean and the highest accuracy, despite knowing\nfrom our experience conducting similar tests, that it is unlikely for each experiment to\nachieve the same score. In doing so we however give more attention to the highest\naccuracy results achieved rather than the mean - since given this lack of clarity, we\nfeel that it is a more fair comparison. In addition to this the authors also refrain from\nincluding the corresponding F1 measure, limiting us to solely the accuracy score.\nFurthermore, we built Jiang et al. (2019)\u2019s ensemble model as a separate implementa-\ntion both to analyse and verify the classi\ufb01er itself, comparing its performance with that\nof the HyperPT SVM and the state-of-the-art. Since as described above we do not hold\nany ownership over the SemEval hidden test set, we decided in the case of the ensemble\nCNN model to split the training set such that we have 20% of it being used as the test\nset. Similarly to Jiang et al. (2019), we train several CNN models using 10-Fold Cross\nValidation, and then select three of the best performing ones to evaluate their collective\nperformance on the test set by averaging their classi\ufb01cation outputs into one.\nSystem Con\ufb01guration Mean Accuracy Mean F1 Highest Accuracy Highest F1\nSVM (HyperPT) 0.822 (\u00b10.011) 0.745 (\u00b10.012) 0.835 0.758\nEns-CNN (HyperPT) 0.783 (\u00b10.035) 0.740 (\u00b10.057) 0.820 0.797\nEns-CNN (Jiang et al.) 0.8404 N/A 0.8404 N/A\nTable 4.13: Mean and highest accuracy and F1 results for the HyperPT system and the\nstate-of-the-art [Jiang et al. (2019)]. For the HyperPT system, we present the SVM clas-\nsi\ufb01er using RBF kernel and an Ensemble-CNN solution based on Jiang et al.\u2019s system.\nThe corresponding results can be observed in Table 4.13. Focusing on the accuracies,\nthe state-of-the-art exceeds any system proposed from our end. Our Ens-CNN model\nachieves a highest accuracy of 0.820, with an expectedly lower mean accuracy of 0.783\n(\u00b10.035). This could be attributed to the 20% less training data provided to the classi\ufb01er\ncompared to the state-of-the-art, however if one were to consider solely the highest\naccuracy score, the two systems score not too far apart.\nConsidering that it is an inherently different and simpler approach, the SVM actu-\nally manages to come close to the accuracy levels of the state-of-the-art. With a mean\naccuracy of 0.822 (\u00b10.011), we are unsure of the actual equivalent mean accuracy by\nthe state-of-the-art, however we feel that even if the mean is indeed as high as the 0.84\nlevels, the SVM would still have achieved close accuracy levels with a fraction of the\ntraining time and resources.\nBetween the highest result scored by the HyperPT SVM and the state-of-the-art, we\n102\nChapter 4. System Evaluation and Discussion 4.5. Summary\n\ufb01nd that there is an accuracy difference of 0.0054 (0.54%). This further enforces the\npoint that the SVM fares considerably well. Indeed in the case of larger, more diverse\ndatasets, as discussed earlier in Section 4.2, we do believe that the distance between the\ntwo classi\ufb01er performances increases, with the SVM lacking behind since CNN-based\nsolutions would be able to scale better to the larger volumes of data. However given the\nexact problem we are trying to tackle here - on the same dataset, we feel that our unique\ncombination of ELMo embeddings adapted to the SVM classi\ufb01er is a worthy alternative\nto the state-of-the-art.\nHaving presented these results, we feel it is not our place to decide on the best\nperforming system between the two, but rather to propose an alternative and equally\npromising approach. At the end of the day before settling for a practical system to be\nused in a real-life scenario, other aspects come in play; the performance capabilities of\nthe hardware upon which the system will perform, the size and diversity of the expected\ndata, and the scaling potential of the system. An SVM-based system is signi\ufb01cantly less\nresource-hungry than its DL counterpart, yet this comes at a cost of less performance\nand less scaling capabilities down the line. One must then decide based on his unique\napplication which system would \ufb01t best.\n4.5 | System Evaluation and Discussion - Summary\nThroughout this chapter we evaluated the HyperPT system and its components, delv-\ning in detail into our evaluation approaches, the results achieved and the conclusions\nderived from these experiments.\nWe started off by evaluating the baseline components of our classi\ufb01cation system.\nIn Section 4.1 and Section 4.2 we respectively studied the best performing data pre-\nprocessing, feature representation and classi\ufb01cation algorithms for the detection of hy-\nperpartisan news articles. From the conducted experiments we concluded on feature\nlowercasing as the best generalised data preprocessing technique and ELMo embed-\ndings as the best feature representation. Out of three classi\ufb01ers, the SVM proved to be\nthe best performer. We also determined that despite lowercasing of features being the\nbest generalised data preprocessing technique, non-punctuated features tend to work\nnotably better when coupled with the SVM.\nFurthermore, we investigated the possibility of non-conventional features for fur-\nther ampli\ufb01cation of the classi\ufb01cation performance - in doing so discovering further the\nhyperpartisan article itself. In Section 4.3 we investigated the addition of sentiment,\nthe addition of the article title and experimented with the length of the article itself.\n103\nChapter 4. System Evaluation and Discussion 4.5. Summary\nMoreover we then evaluated the LRP algorithm and used it to determine the saliency of\nfeatures playing a pivotal role in the classi\ufb01cation process.\nDue to the disappointing performance of sentiment features we decided against\nmaintaining them inside of the HyperPT system. Moreover we noticed a notable in-\ncrease in performance when including the article title, maintaining a respectable accu-\nracy score. Having been selected using LRP, the \ufb01fteen most salient features detailed\nfrom a sample of 50 randomly chosen articles include a number of proper nouns and\nnames of powerful and politically af\ufb01liated individuals. We concluded from these ob-\nservations that in classifying hyperpartisan news articles, more importance is given to\nthe article subject and entities involved rather than the tone in which it is written.\nFinally, we compared the entirety of the HyperPT system with the state-of-the-art;\nJiang et al. (2019). We concluded that despite the state-of-the-art reporting higher ac-\ncuracy results, the SVM-based system we proposed could be a worthy alternative, and\ndepending on the application, it might also be preferred.\n104\n5\nConclusions\nWith the evaluation of the HyperPT system in Chapter 4 and the resulting discussions,\nwe now give our conclusions on this study, where we presented our approach to the\ndetection and classi\ufb01cation of hyperpartisan news articles.\nAn introduction to the problem caused by hyperpartisan news was \ufb01rst given in\nChapter 1, de\ufb01ning also HyperPT; our approach for the detection of hyperpartisan news\narticles. In the ensuing Chapter 2, we detailed the background behind techniques in-\nspiring or directly used within our study - with a concise review of related work and\npublished systems tackling the same or similar problems.\nHaving examined related literature, we moved on to Chapter 3, where our approach\nin designing the HyperPT system was examined. Here we discussed our design process,\nalong with the physical implementation of the components making up the system. We\nsummarised HyperPT into three main components; 1) data loading and preprocessing,\n2) model classi\ufb01cation and evaluation, and 3) model interpretability. Three classi\ufb01cation\nalgorithms were chosen as candidates for the detection of hyperpartisan news articles;\nthe SVM, RF and CNN, before a detailed overview of the approach and implementation\nof the LRP interpretability algorithm was given.\nIn Chapter 4 we evaluated our methodology and its implementation. An elaborate\nsystem evaluation was performed, including a range of data preprocessing and feature\nrepresentation techniques. Hyperparameter tuning was performed on each of the clas-\nsi\ufb01ers before they were thoroughly tested and compared with one another. The addition\nof sentiment features was examined and tested, resulting in an unexpected hindrance\nto the system performance. Furthermore, the consideration of the article title was noted\nas an important and effective addition to the system classi\ufb01cation.\nFinally, we evaluated the LRP model explainability algorithm and utilised it for the\ninterpretation of the two most prominent classi\ufb01cation models; the SVM and the CNN\n105\nChapter 5. Conclusions 5.1. Achieved Aims and Objectives\n- in doing so observing the resulting feature saliency scores. The best performer of\nthe two, the SVM, was compared with the state-of-the-art, where we showed how our\nproject fares as an alternative hyperpartisan classi\ufb01cation system - featuring different\nadvantages and characteristics to its competitor.\n5.1 | Achieved Aims and Objectives\nIn conducting the HyperPT study, we aimed at addressing the \ufb01ve main objectives ini-\ntially set in Chapter 1. Below we brie\ufb02y discuss our observations and conclusions in\ntackling each objective.\n5.1.1 | Features of a Hyperpartisan News Article\nThrough the LRP interpretability algorithm applied on the SVM and the CNN classi-\n\ufb01ers, each of the models\u2019 decision-making was observed. Consequently, a saliency score\nwas given to each of the article features. In doing so we observed (Section 4.3.3) that due\nto the frequent occurrences of proper nouns and names of well-known individuals, the\nclassi\ufb01cation process tends to focus more on the subject of the article and the involved\nentities rather than its method of writing. This observation highlights the importance of\nentities within hyperpartisan news articles, however it also shows that the style of writ-\ning inside of the articles may not be the main priority, contrary to what was previously\nthought. We however tend to believe that with a larger and more diverse dataset, more\ngeneralisation would be present within the article features.\n5.1.2 | Sentiment of a Hyperpartisan News Article\nDespite mixed opinions found in related work on the addition of sentiment, tests con-\nducted on our system and corresponding results implied a decrease in classi\ufb01cation\nperformance. Moreover, similar systems matching the same range of accuracies as us\naligned with this conclusion. To extend the observations made in Section 5.1.1, we think\nthat the lower importance given during classi\ufb01cation to descriptive features compared\nto entities and subjects minimises the potential effects offered by sentiment derived from\nsuch descriptive features.\n106\nChapter 5. Conclusions 5.1. Achieved Aims and Objectives\n5.1.3 | Minimum length of text for an Article to be Hyperpartisan\nAs shown in Section 4.3.2, experiments were conducted with the article body, the arti-\ncle body extended by the title, and \ufb01nally the title by itself. Moreover, we performed\ntests with different lengths of the article body; 5 sentences, 15 sentences, and full length.\nAn instant increase in performance was noticed with the addition of the article title,\nsuggesting the presence of hyperpartisan elements early on throughout the article. Fur-\nthermore, we noticed a direct correlation between the length of the article and the clas-\nsi\ufb01cation performance, implying that the longer the article, the better the probability of\nbeing classi\ufb01ed correctly. This however does not rule out the possibility of short texts\nbeing hyperpartisan. Indeed even with just the title - the shortest length of text with\nwhich we experimented, the performance accuracy was maintained upwards of 0.70.\n5.1.4 | Classi/uniFB01er for Hyperpartisan News Articles\nHaving evaluated the performance of the SVM, RF and CNN, the best performing of the\nthree classi\ufb01ers was the SVM. We hence compared the SVM with results reported by the\nstate-of-the-art [Jiang et al. (2019)] and an implementation of the state-of-the-art ensem-\nble CNN model built by ourselves. We found that testing the in-house implementation\nof the state-of-the-art achieves less performance than that reported by the researchers,\nthough this can be attributed to the smaller dataset upon which it is trained, since the\nhidden SemEval Hyperpartisan News dataset was not made available to us. Moreover\nwe noticed how the SVM achieves results close to those reported by the state-of-the-art\nwith a difference in accuracy of 0.02 or 2%.\nConsidering the SVM\u2019s slightly poorer accuracy result yet notably faster execution\ntime, we feel that the performance showcased by our system should put it in line as a\nworthy alternative hyperpartisan classi\ufb01cation system to Jiang et al. (2019). We hence\nproposed several alternative advantages which one may consider in putting such a sys-\ntem to use; particularly the faster training times and less hardware requirements com-\npared to the CNN-based state-of-the-art.\n5.1.5 | Interpretation of the Classi/uniFB01er\nThrough the generation of feature saliency as discussed in Section 5.1.1, we noticed a\ntendency for the classi\ufb01er associating entities with hyperpartisanship (and others with\nneutrality). We believe that despite the positive performance results, this tendency is\nnot ideal, since with the introduction of new entities, topics and articles, the classi\ufb01er\nmay convey unprecedented behaviour. We think that this is mainly due to the small\n107\nChapter 5. Conclusions 5.2. Critique and Limitations\nunvaried nature of the dataset (Section 2.1) upon which our classi\ufb01ers are trained. We\nhence recommend a follow-up analysis of the classi\ufb01ers\u2019 behaviour on a larger and more\ndiverse dataset, as discussed further in Section 5.3.\n5.2 | Critique and Limitations\nSimilar to any other system, HyperPT is not without its limitations. Despite these set-\nbacks, we do feel that we attempted to present the best approach with the resources that\nwere available, adding our contribution to the research community.\nThe \ufb01rst major limitation is the small size of the SemEval Hyperpartisan News Ar-\nticle dataset, particularly the By-Article collection, amounting to 645 articles (Section\n2.1). Such a small size allowed us only a small range and variety of article samples,\nsomewhat limiting the training of our classi\ufb01ers. Moreover, we refrained from using\nthe larger By-Publisher dataset, since as reported by a number of similar systems, the\nlabelling of this collection is not of the same quality as that of the By-Article, potentially\nresulting in more of a hindrance to the research than an advantage (Section 2.1.2.1).\nCoupled with this setback, we feel that the observations made from model inter-\npretations (Section 4.3.3) suggest an important limitation to the proposed system. The\ntendency of assigning the highest in\ufb02uence scores to proper nouns and entities within\nthe article texts implies a relationship between the entities and the article classi\ufb01cation\nlabels. We believe that the root of this issue may be directly related to the lack of variety\nwithin the small dataset of articles.\nFinally, alternative feature representations and classi\ufb01cation algorithms are always\nan interesting addition to the research conducted. With promising systems such as BERT\nword embeddings, the RNN classi\ufb01cation architecture and the emerging transformer\ntechnology, we feel that the area of NLP and consequently the classi\ufb01cation of hyper-\npartisan news still leaves ample room for further research. Due to the inevitable time\nconstraints imposed on the project, we refrained from introducing further approaches,\nhowever we fully recommended such integrations as future work, as detailed in Section\n5.3.\n5.3 | Future Work\nFurther to the limitations discussed in Section 5.2, we feel that the proposed future work\nbelow would further extend the capabilities of the HyperPT system, consequently al-\n108\nChapter 5. Conclusions 5.3. Future Work\nlowing for further research and more thorough observations into the topic of hyperpar-\ntisan news detection.\nBeing the main limitation encountered in conducting this study, we feel that a larger\nmore diverse dataset would have allowed for more thorough and generalised training\nof the classi\ufb01ers. As initially remarked in Section 4.3.3, the majority of the articles within\nthe SemEval Hyperpartisan News Articles By-Article dataset collection revolve around\nthe same theme of American politics. Despite this being expected since politics are often\nthe subject of sensationalised and opinionated information, we feel that the extra effort\ntaken in enlarging the existing dataset with the inclusion of different themes would\ngreatly help in further training the classi\ufb01cation algorithms.\nAs discussed in Section 2.1.2.1, one could look into de-noising and improving the\notherwise poor labelling found within the By-Publisher data collection through article\nreclassi\ufb01cation and using the insightful capabilities of Explainable A.I. (XAI). In doing\nso, the quality and reliability of the dataset could be improved, with the aim of then\nextending the smaller By-Article data collection with the new set. Moreover, to avoid\nthe tendency of associating speci\ufb01c entities and subjects with hyperpartisanship, the\nmanual introduction of weights to the stylistic features within the news articles would\nfurther encourage the detachment of the classi\ufb01ers from entities, thereby implying more\ngeneralisation.\nFurthermore, the addition and corresponding evaluation of promising feature rep-\nresentation and classi\ufb01cation techniques would give us further insight into the problem\nof hyperpartisan news detection and perhaps suggest improved systems for tackling it.\nIn particular, we feel that the consideration of the BERT word embedding technology\nwould be an interesting extension to explore, with the implementation of RNN (LSTM)\nand transformer architectures as classi\ufb01ers furthering the research conducted on Deep\nLearning classi\ufb01ers for the problem at hand.\nFinally, we think that the consideration of other external features such as the date\nof publication, the publishing entity and the article author may bring out more correla-\ntions to hyperpartisanship. Analysis of the article dissemination and the most proli\ufb01c\nconsumer audience may introduce patterns and observations on the vulnerability of\ndifferent consumer communities and the corresponding spread of hyperpartisan con-\ntent. The addition of such external features may aid both systems which like us clas-\nsify hyperpartisan news according to the content within, and alternative approaches\nattempting to address this issue from different angles, such as the rate of spread and its\nprevention.\n109\nChapter 5. Conclusions 5.4. Final Remarks\n5.4 | Final Remarks\nWith a review of the system limitations in Section 5.2 and an overview of the recom-\nmended future work in Section 5.3, we give our \ufb01nal remarks on our classi\ufb01cation sys-\ntem and the process which gradually but surely led us to developing the project in its\nentirety. The HyperPT project was a challenging yet ful\ufb01lling task, presenting various\nunique challenges during its research and development efforts.\nAll of the work involved is worth the effort when re\ufb02ecting on the use such a system\ncould have in today\u2019s hyper-communicated world, which, perhaps unknowingly, we\n\ufb01nd ourselves trying to adapt to on a regular basis. The damaging potential malicious\ncontent such as fake and hyperpartisan news could have on the masses is both large\nand easily uncontrollable - with unprecedented consequences. We hope that through\nthe HyperPT system we pitch in our small contribution to the effort being made against\nsuch risks, with the aim of counteracting it and establishing control over its spread.\nFinally, we hope that the work conducted throughout this project inspires the next\ngeneration of researchers and encourages more innovative systems to step up, further-\ning the state-of-the-art in both the area of hyperpartisan news detection, and the domain\nof textual NLP in general - one which harnesses great potential and which continues fre-\nquently see notable improvements.\n110\nReferences\nHerv\u00e9 Abdi and Lynne J Williams. Principal component analysis. Wiley interdisciplinary reviews: computa-\ntional statistics , 2(4):433\u2013459, 2010.\nSadia Afroz, Michael Brennan, and Rachel Greenstadt. Detecting hoaxes, frauds, and deception in writing\nstyle online. In 2012 IEEE Symposium on Security and Privacy , pages 461\u2013475. IEEE, 2012.\nRodrigo Agerri. Doris martin at semeval-2019 task 4: Hyperpartisan news detection with generic semi-\nsupervised features. In Proceedings of the 13th International Workshop on Semantic Evaluation , pages 944\u2013\n948, 2019.\nDivyakant Agrawal, Ceren Budak, and Amr El Abbadi. Information diffusion in social networks: observ-\ning and affecting what society cares about. In Proceedings of the 20th ACM international conference on\nInformation and knowledge management , pages 2609\u20132610. ACM, 2011.\nAmal Alabdulkarim and Tariq Alhindi. Spider-jerusalem at semeval-2019 task 4: Hyperpartisan news\ndetection. In Proceedings of the 13th International Workshop on Semantic Evaluation , pages 985\u2013989, 2019.\nMaximilian Alber, Sebastian Lapuschkin, Philipp Seegerer, Miriam H\u00e4gele, Kristof T Sch\u00fctt, Gr\u00e9goire Mon-\ntavon, Wojciech Samek, Klaus-Robert M\u00fcller, Sven D\u00e4hne, and Pieter-Jan Kindermans. innvestigate\nneural networks. Journal of Machine Learning Research , 20(93):1\u20138, 2019.\nShun-ichi Amari and Si Wu. Improving support vector machine classi\ufb01ers by modifying kernel functions.\nNeural Networks , 12(6):783\u2013789, 1999.\nEvan Amason, Jake Palanker, Mary Clare Shen, and Julie Medero. Harvey mudd college at semeval-2019\ntask 4: The dx beaumont hyperpartisan news detector. In Proceedings of the 13th International Workshop\non Semantic Evaluation , pages 967\u2013970, 2019.\nTalita Anthonio and Lennart Kloppenburg. Team kermit-the-frog at semeval-2019 task 4: Bias detection\nthrough sentiment analysis and simple linguistic features. In Proceedings of the 13th International Workshop\non Semantic Evaluation , pages 1016\u20131020, 2019.\nLeila Arras, Franziska Horn, Gr\u00e9goire Montavon, Klaus-Robert M\u00fcller, and Wojciech Samek. Explaining\npredictions of non-linear classi\ufb01ers in nlp. In Proceedings of the 1st Workshop on Representation Learning for\nNLP , pages 1\u20137, 2016.\n111\nReferences References\nLeila Arras, Franziska Horn, Gr\u00e9goire Montavon, Klaus-Robert M\u00fcller, and Wojciech Samek. \" what is\nrelevant in a text document?\": An interpretable machine learning approach. PloS one , 12(8), 2017.\nSebastian Bach, Alexander Binder, Gr\u00e9goire Montavon, Frederick Klauschen, Klaus-Robert M\u00fcller, and\nWojciech Samek. On pixel-wise explanations for non-linear classi\ufb01er decisions by layer-wise relevance\npropagation. PloS one , 10(7), 2015.\nSameer Badaskar, Sachin Agarwal, and Shilpa Arora. Identifying real or fake articles: Towards better\nlanguage modeling. In Proceedings of the Third International Joint Conference on Natural Language Processing:\nVolume-II , 2008.\nDavid Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen, and Klaus-Robert\nM\u00fcller. How to explain individual classi\ufb01cation decisions. The Journal of Machine Learning Research , 11:\n1803\u20131831, 2010.\nVimala Balakrishnan and Ethel Lloyd-Yemoh. Stemming and lemmatization: a comparison of retrieval\nperformances. 2014.\nHal Berghel. Malice domestic: The cambridge analytica dystopia. Computer , (5):84\u201389, 2018.\nYves Bestgen. Tintin at semeval-2019 task 4: Detecting hyperpartisan news article with only simple tokens.\nInProceedings of the 13th International Workshop on Semantic Evaluation , pages 1062\u20131066, 2019.\nSteven Bird, Ewan Klein, and Edward Loper. Natural language processing with Python: analyzing text with the\nnatural language toolkit . \" O\u2019Reilly Media, Inc.\", 2009.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with sub-\nword information. Transactions of the Association for Computational Linguistics , 5:135\u2013146, 2017.\nLeo Breiman. Bagging predictors. Machine learning , 24(2):123\u2013140, 1996.\nLeo Breiman. Random forests. Machine learning , 45(1):5\u201332, 2001.\nEric Brill. A simple rule-based part of speech tagger. Technical report, PENNSYLVANIA UNIV PHILADEL-\nPHIA DEPT OF COMPUTER AND INFORMATION SCIENCE, 1992.\nEric Brill. Some advances in transformation-based part of speech tagging. arXiv preprint cmp-lg/9406010 ,\n1994.\nCarole Cadwalladr and E Graham-Harrison. The cambridge analytica \ufb01les. The Guardian , 21:6\u20137, 2018a.\nCarole Cadwalladr and Emma Graham-Harrison. Revealed: 50 million facebook pro\ufb01les harvested for\ncambridge analytica in major data breach. The Guardian , 17:2018, 2018b.\nEugene Charniak. Statistical techniques for natural language parsing. AI magazine , 18(4):33\u201333, 1997.\nCiprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robin-\nson. One billion word benchmark for measuring progress in statistical language modeling. 2013.\nCiprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robin-\nson. One billion word benchmark for measuring progress in statistical language modeling. In Fifteenth\nAnnual Conference of the International Speech Communication Association , 2014.\n112\nReferences References\nCelena Chen, Celine Park, Jason Dwyer, and Julie Medero. Harvey mudd college at semeval-2019 task 4:\nThe carl kolchak hyperpartisan news detector. In Proceedings of the 13th International Workshop on Semantic\nEvaluation , pages 957\u2013961, 2019.\nGang Chen. A gentle tutorial of recurrent neural network with error backpropagation. 10 2016.\nTianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm\nsigkdd international conference on knowledge discovery and data mining , pages 785\u2013794. ACM, 2016.\nCorinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning , 20(3):273\u2013297, 1995.\nRebekah Cramerus and Tatjana Schef\ufb02er. Team kit kittredge at semeval-2019 task 4: Lstm voting system.\nInProceedings of the 13th International Workshop on Semantic Evaluation , pages 1021\u20131025, 2019.\nAndr\u00e9 Cruz, Gil Rocha, Rui Sousa-Silva, and Henrique Lopes Cardoso. Team fernando-pessa at semeval-\n2019 task 4: Back to basics in hyperpartisan news detection. In Proceedings of the 13th International Work-\nshop on Semantic Evaluation , pages 999\u20131003, 2019.\nCedric De Boom, Steven Van Canneyt, Thomas Demeester, and Bart Dhoedt. Representation learning for\nvery short texts using weighted word embedding aggregation. Pattern Recognition Letters , 80(C):150\u2013156,\n2016.\nScott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. In-\ndexing by latent semantic analysis. Journal of the American society for information science , 41(6):391\u2013407,\n1990.\nSteven J DeRose. Grammatical category disambiguation by statistical optimization. Computational linguis-\ntics, 14(1), 1988.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirec-\ntional transformers for language understanding. In Proceedings of the 2019 Conference of the North Amer-\nican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long\nand Short Papers) , pages 4171\u20134186, Minneapolis, Minnesota, June 2019. Association for Computational\nLinguistics. doi: 10.18653/v1/N19-1423. URL https://www.aclweb.org/anthology/N19- 1423 .\nThomas G Dietterich and Eun Bae Kong. Machine learning bias, statistical bias, and statistical variance of\ndecision tree algorithms. Technical report, Technical report, Department of Computer Science, Oregon\nState University, 1995.\nMehdi Drissi, Pedro Sandoval Segura, Vivaswat Ojha, and Julie Medero. Harvey mudd college at semeval-\n2019 task 4: The clint buchanan hyperpartisan news detector. In Proceedings of the 13th International\nWorkshop on Semantic Evaluation , pages 962\u2013966, 2019.\nOren Etzioni, Michele Banko, Stephen Soderland, and Daniel S Weld. Open information extraction from\nthe web. Communications of the ACM , 51(12):68\u201374, 2008.\nMichael F\u00e4rber, Agon Qurdina, and Lule Ahmedi. Team peter brinkmann at semeval-2019 task 4: Detecting\nbiased news articles using convolutional neural networks. In Proceedings of the 13th International Workshop\non Semantic Evaluation , pages 1032\u20131036, 2019.\n113\nReferences References\nTristan Fletcher. Support vector machines explained. Tutorial paper., Mar , page 28, 2009.\nKrishna Gade, Sahin Cem Geyik, Krishnaram Kenthapadi, Varun Mithal, and Ankur Taly. Explainable ai in\nindustry. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data\nMining , pages 3203\u20133204, 2019.\nFelix A Gers, J\u00fcrgen Schmidhuber, and Fred Cummins. Learning to forget: Continual prediction with lstm.\n1999.\nXavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale sentiment clas-\nsi\ufb01cation: a deep learning approach. In Proceedings of the 28th International Conference on International\nConference on Machine Learning , pages 513\u2013520, 2011.\nRandy Goebel, Ajay Chander, Katharina Holzinger, Freddy Lecue, Zeynep Akata, Simone Stumpf, Peter\nKieseberg, and Andreas Holzinger. Explainable ai: the new 42? In International cross-domain conference\nfor machine learning and knowledge extraction , pages 295\u2013303. Springer, 2018.\nYoav Goldberg and Omer Levy. word2vec explained: deriving mikolov et al.\u2019s negative-sampling word-\nembedding method. CoRR , abs/1402.3722, 2014.\nPriscilla E Greenwood and Michael S Nikulin. A guide to chi-squared testing , volume 280. John Wiley &\nSons, 1996.\nJP Gupta, Devendra K Tayal, and Arti Gupta. A tengram method based part-of-speech tagging of multi-\ncategory words in hindi language. Expert Systems with Applications , 38(12):15084\u201315093, 2011.\nViresh Gupta, Baani Leen Kaur Jolly, Ramneek Kaur, and Tanmoy Chakraborty. Clark kent at semeval-2019\ntask 4: Stylometric insights into hyperpartisan news detection. In Proceedings of the 13th International\nWorkshop on Semantic Evaluation , pages 934\u2013938, 2019.\nKazuaki Hanawa, Shota Sasaki, Hiroki Ouchi, Jun Suzuki, and Kentaro Inui. The sally smedley hyperpar-\ntisan news detector at semeval-2019 task 4. In Proceedings of the 13th International Workshop on Semantic\nEvaluation , pages 1057\u20131061, 2019.\nSusan C Herring. Computer-mediated discourse analysis. Designing for virtual communities in the service of\nlearning , pages 338\u2013376, 2004.\nLena Hettinger, Alexander Dallmann, Albin Zehe, Thomas Niebler, and Andreas Hotho. Claire at semeval-\n2018 task 7: Classi\ufb01cation of relations using embeddings. In Proceedings of The 12th International Workshop\non Semantic Evaluation , pages 836\u2013841, 2018.\nSepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation , 9(8):1735\u20131780,\n1997.\nJeremy Howard and Sebastian Ruder. Universal language model \ufb01ne-tuning for text classi\ufb01cation. In Pro-\nceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\npages 328\u2013339, 2018.\nClayton J Hutto and Eric Gilbert. Vader: A parsimonious rule-based model for sentiment analysis of social\nmedia text. In Eighth international AAAI conference on weblogs and social media , 2014.\n114\nReferences References\nTim Isbister and Fredrik Johansson. Dick-preston and morbo at semeval-2019 task 4: Transfer learning for\nhyperpartisan news detection. In Proceedings of the 13th International Workshop on Semantic Evaluation ,\npages 939\u2013943, 2019.\nYe Jiang, Johann Petrak, Xingyi Song, Kalina Bontcheva, and Diana Maynard. Team bertha von suttner at\nsemeval-2019 task 4: Hyperpartisan news detection using elmo sentence representation convolutional\nnetwork. In Proceedings of the 13th International Workshop on Semantic Evaluation , pages 840\u2013844, 2019.\nKaren Sparck Jones. A statistical interpretation of term speci\ufb01city and its application in retrieval. Journal of\ndocumentation , 1972.\nKaren Sparck Jones and Peter Willett. Readings in information retrieval . Morgan Kaufmann, 1997.\nYoungjun Joo and Inchon Hwang. Steve martin at semeval-2019 task 4: Ensemble learning model for\ndetecting hyperpartisan news. In Proceedings of the 13th International Workshop on Semantic Evaluation ,\npages 990\u2013994, 2019.\nP . Joshi, J. Hearty, B. Sjardin, L. Massaron, and A. Boschetti. Python: Real World Machine Learning , pages\n621\u2013623. Packt Publishing, 2016. ISBN 9781787120679. URL https://books.google.com.mt/books?\nid=g57cDgAAQBAJ .\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh, David Corney, Benno\nStein, and Martin Potthast. Semeval-2019 task 4: Hyperpartisan news detection. In Proceedings of the\n13th International Workshop on Semantic Evaluation , pages 829\u2013839, 2019.\nYoon Kim. Convolutional neural networks for sentence classi\ufb01cation. In EMNLP , 2014.\nJ\u00fcrgen Knauth. Orwellian-times at semeval-2019 task 4: A stylistic and content-based classi\ufb01er. In Proceed-\nings of the 13th International Workshop on Semantic Evaluation , pages 976\u2013980, 2019.\nSejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei Chen, and Yajun Wang. Prominent features of rumor\npropagation in online social media. In 2013 IEEE 13th International Conference on Data Mining , pages\n1103\u20131108. IEEE, 2013.\nSebastian Lapuschkin, Alexander Binder, Gr\u00e9goire Montavon, Klaus-Robert M\u00fcller, and Wojciech Samek.\nThe lrp toolbox for arti\ufb01cial neural networks. The Journal of Machine Learning Research , 17(1):3938\u20133942,\n2016.\nAlberto Lavelli, Fabrizio Sebastiani, and Roberto Zanoli. Distributional term representations: an experi-\nmental comparison. In Proceedings of the thirteenth ACM international conference on Information and knowl-\nedge management , pages 615\u2013624, 2004.\nYann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature , 521(7553):436\u2013444, 2015.\nNayeon Lee, Zihan Liu, and Pascale Fung. Team yeon-zi at semeval-2019 task 4: Hyperpartisan news\ndetection by de-noising weakly-labeled data. In Proceedings of the 13th International Workshop on Semantic\nEvaluation , pages 1052\u20131056, 2019.\nEdward Loper and Steven Bird. Nltk: The natural language toolkit. In Proceedings of the ACL-02 Workshop\non Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics ,\npages 63\u201370, 2002.\n115\nReferences References\nAmr Magdy and Nayer Wanas. Web-based statistical fact checking of textual documents. In Proceedings of\nthe 2nd international workshop on Search and mining user-generated contents , pages 103\u2013110. ACM, 2010.\nMitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. Building a large annotated corpus of\nenglish: The penn treebank. 1993.\nDonald Michie, David J Spiegelhalter, CC Taylor, et al. Machine learning. Neural and Statistical Classi\ufb01cation ,\n13(1994):1\u2013298, 1994.\nTomas Mikolov, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Ef\ufb01cient estimation of word representa-\ntions in vector space. CoRR , abs/1301.3781, 2013a.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of\nwords and phrases and their compositionality. In Advances in neural information processing systems , pages\n3111\u20133119, 2013b.\nGeorge A Miller. Wordnet: a lexical database for english. Communications of the ACM , 38(11):39\u201341, 1995.\nGr\u00e9goire Montavon, Wojciech Samek, and Klaus-Robert M\u00fcller. Methods for interpreting and understand-\ning deep neural networks. Digital Signal Processing , 73:1\u201315, 2018.\nRodrigo Moraes, Jo\u00e3O Francisco Valiati, and Wilson P Gavi\u00e3O Neto. Document-level sentiment classi\ufb01ca-\ntion: An empirical comparison between svm and ann. Expert Systems with Applications , 40(2):621\u2013633,\n2013.\nJos\u00e9 G Moreno, Yoann Pitarch, Karen Pinel-Sauvagnat, and Gilles Hubert. Rouletabille at semeval-2019\ntask 4: Neural network baseline for identi\ufb01cation of hyperpartisan publishers. In Proceedings of the 13th\nInternational Workshop on Semantic Evaluation , pages 981\u2013984, 2019.\nOsman Mutlu, Ozan Arkan Can, and Erenay Dayanik. Team howard beale at semeval-2019 task 4: Hyper-\npartisan news detection with bert. In Proceedings of the 13th International Workshop on Semantic Evaluation ,\npages 1007\u20131011, 2019.\nBang Nguyen, Xiaoyu Yu, TC Melewar, and Junsong Chen. Brand innovation and social media: Knowledge\nacquisition from social media, market orientation, and the moderating role of social media strategic\ncapability. Industrial Marketing Management , 51:11\u201325, 2015.\nDuc-Vu Nguyen, Thin Dang, and Ngan Nguyen. Nlp@ uit at semeval-2019 task 4: The paparazzo hyper-\npartisan news detector. In Proceedings of the 13th International Workshop on Semantic Evaluation , pages\n971\u2013975, 2019.\nZhiyuan Ning, Yuanzhen Lin, and Ruichao Zhong. Team peter-parker at semeval-2019 task 4: Bert-based\nmethod in hyperpartisan news detection. In Proceedings of the 13th International Workshop on Semantic\nEvaluation , pages 1037\u20131040, 2019.\nKeiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks. 11 2015.\nEdgar Osuna, Robert Freund, and Federico Girosit. Training support vector machines: an application to\nface detection. In Proceedings of IEEE computer society conference on computer vision and pattern recognition ,\npages 130\u2013136. IEEE, 1997.\n116\nReferences References\nNiko Pali\u00b4 c, Juraj Vladika, Dominik \u02c7Cubeli\u00b4 c, Ivan Lovren\u02c7 ci\u00b4 c, Maja Buljan, and Jan \u0160najder. Takelab at\nsemeval-2019 task 4: Hyperpartisan news detection. In Proceedings of the 13th International Workshop on\nSemantic Evaluation , pages 995\u2013998, 2019.\nGeorgios Paltoglou and Mike Thelwall. Twitter, myspace, digg: Unsupervised sentiment analysis in social\nmedia. ACM Transactions on Intelligent Systems and Technology (TIST) , 3(4):1\u201319, 2012.\nBo Pang, Lillian Lee, and Shivakumar Vaithyanathan. Thumbs up? sentiment classi\ufb01cation using ma-\nchine learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP 2002) , pages 79\u201386, 2002.\nOlga Papadopoulou, Giorgos Kordopatis-Zilos, Markos Zampoglou, Symeon Papadopoulos, and Yiannis\nKompatsiaris. Brenda starr at semeval-2019 task 4: Hyperpartisan news detection. In Proceedings of the\n13th International Workshop on Semantic Evaluation , pages 924\u2013928, 2019.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel, P . Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.\nScikit-learn: Machine learning in Python. Journal of Machine Learning Research , 12:2825\u20132830, 2011.\nJeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word represen-\ntation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) ,\npages 1532\u20131543, 2014.\nCarla P\u00e9rez-Almendros, Luis Espinosa Anke, and Steven Schockaert. Cardiff university at semeval-2019\ntask 4: Linguistic features for hyperpartisan news detection. In Proceedings of the 13th International Work-\nshop on Semantic Evaluation , pages 929\u2013933, 2019.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. Deep contextualized word representations. In Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume\n1 (Long Papers) , pages 2227\u20132237, New Orleans, Louisiana, June 2018. Association for Computational\nLinguistics. doi: 10.18653/v1/N18-1202. URL https://www.aclweb.org/anthology/N18- 1202 .\nSlav Petrov, Dipanjan Das, and Ryan McDonald. A universal part-of-speech tagset. arXiv preprint\narXiv:1104.2086 , 2011.\nMartin F Porter. Snowball: A language for stemming algorithms, 2001.\nMartin F Porter et al. An algorithm for suf\ufb01x stripping. Program , 14(3):130\u2013137, 1980.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, and Benno Stein. A stylometric in-\nquiry into hyperpartisan and fake news. In Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) , pages 231\u2013240, Melbourne, Australia, July 2018. As-\nsociation for Computational Linguistics. doi: 10.18653/v1/P18-1022. URL https://www.aclweb.org/\nanthology/P18- 1022 .\nLaura Elena Raileanu and Kilian Stoffel. Theoretical comparison between the gini index and information\ngain criteria. Annals of Mathematics and Arti\ufb01cial Intelligence , 41(1):77\u201393, 2004.\n117\nReferences References\nAdwait Ratnaparkhi. A maximum entropy model for part-of-speech tagging. In Conference on Empirical\nMethods in Natural Language Processing , 1996.\nXin Rong. word2vec parameter learning explained. arXiv preprint arXiv:1411.2738 , 2014.\nVictoria Rubin, Niall Conroy, Yimin Chen, and Sarah Cornwell. Fake news or truth? using satirical cues to\ndetect potentially misleading news. In Proceedings of the Second Workshop on Computational Approaches to\nDeception Detection , pages 7\u201317, 2016.\nVictoria L Rubin, Niall J Conroy, and Yimin Chen. Towards news veri\ufb01cation: Deception detection methods\nfor news discourse. 2015.\nAbdelrhman Saleh, Ramy Baly, Alberto Barr\u00f3n-Cede\u00f1o, Giovanni Da San Martino, Mitra Mohtarami,\nPreslav Nakov, and James Glass. Team QCRI-MIT at SemEval-2019 task 4: Propaganda analysis meets\nhyperpartisan news detection. In Proceedings of the 13th International Workshop on Semantic Evaluation ,\npages 1041\u20131046, Minneapolis, Minnesota, USA, June 2019. Association for Computational Linguistics.\ndoi: 10.18653/v1/S19-2182. URL https://www.aclweb.org/anthology/S19- 2182 .\nGerard Salton and Christopher Buckley. Term-weighting approaches in automatic text retrieval. Information\nprocessing & management , 24(5):513\u2013523, 1988.\nWojciech Samek, Thomas Wiegand, and Klaus-Robert M\u00fcller. Explainable arti\ufb01cial intelligence: Under-\nstanding, visualizing and interpreting deep learning models. 2017.\nMike Schuster and Kuldip K Paliwal. Bidirectional recurrent neural networks. IEEE Transactions on Signal\nProcessing , 45(11):2673\u20132681, 1997.\nSaptarshi Sengupta and Ted Pedersen. Duluth at semeval-2019 task 4: The pioquinto manterola hyper-\npartisan news detector. In Proceedings of the 13th International Workshop on Semantic Evaluation , pages\n949\u2013953, 2019.\nDaniel Shaprin, Giovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and Preslav Nakov. Team jack ryder at\nsemeval-2019 task 4: Using bert representations for detecting hyperpartisan news. In Proceedings of the\n13th International Workshop on Semantic Evaluation , pages 1012\u20131015, 2019.\nVertika Srivastava, Ankita Gupta, Divya Prakash, Sudeep Kumar Sahoo, RR Rohit, and Yeon Hyang Kim.\nVernon-fenwick at semeval-2019 task 4: Hyperpartisan news detection using lexical and semantic fea-\ntures. In Proceedings of the 13th International Workshop on Semantic Evaluation , pages 1078\u20131082, 2019.\nBozhidar Stevanoski and Sonja Gievska. Team ned leeds at semeval-2019 task 4: Exploring language indi-\ncators of hyperpartisan reporting. In Proceedings of the 13th International Workshop on Semantic Evaluation ,\npages 1026\u20131031, 2019.\nJames Surowiecki. Wisdom of crowds: The wisdom of crowds, 2004.\nMarcella Tambuscio, Giancarlo Ruffo, Alessandro Flammini, and Filippo Menczer. Fact-checking effect on\nviral hoaxes: A model of misinformation spread in social networks. In Proceedings of the 24th international\nconference on World Wide Web , pages 977\u2013982. ACM, 2015.\n118\nReferences References\nIulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Well-read students learn better: On the\nimportance of pre-training compact models. arXiv preprint arXiv:1908.08962v2 , 2019.\nPeter D Turney. Thumbs up or thumbs down? semantic orientation applied to unsupervised classi\ufb01cation\nof reviews. 2002.\nUdo Undeutsch. Beurteilung der glaubhaftigkeit von aussagen. Handbuch der psychologie , 11:26\u2013181, 1967.\nVladimir N. Vapnik. Statistical Learning Theory . Wiley-Interscience, 1998.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz\nKaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing\nsystems , pages 5998\u20136008, 2017.\nAndrew Wiese, Valerie Ho, and Emily Hill. A comparison of stemmers on source code identi\ufb01ers for\nsoftware search. In 2011 27th IEEE International Conference on Software Maintenance (ICSM) , pages 496\u2013\n499. IEEE, 2011.\nW John Wilbur and Karl Sirotkin. The automatic identi\ufb01cation of stop words. Journal of information science ,\n18(1):45\u201355, 1992.\nSvante Wold, Kim Esbensen, and Paul Geladi. Principal component analysis. Chemometrics and intelligent\nlaboratory systems , 2(1-3):37\u201352, 1987.\nHo Chung Wu, Robert Wing Pong Luk, Kam Fai Wong, and Kui Lam Kwok. Interpreting tf-idf term\nweights as making relevance decisions. ACM Transactions on Information Systems (TOIS) , 26(3):1\u201337,\n2008.\nYou Wu, Pankaj K Agarwal, Chengkai Li, Jun Yang, and Cong Yu. Toward computational fact-checking.\nProceedings of the VLDB Endowment , 7(7):589\u2013600, 2014.\nJiacheng Xu, Danlu Chen, Xipeng Qiu, and Xuan-Jing Huang. Cached long short-term memory neural\nnetworks for document-level sentiment classi\ufb01cation. In Proceedings of the 2016 Conference on Empirical\nMethods in Natural Language Processing , pages 1660\u20131669, 2016.\nShailesh Kumar Yadav. Sentiment analysis and classi\ufb01cation: a survey. International Journal of Advance\nResearch in Computer Science and Management Studies , 3(3):113\u2013121, 2015.\nAlexander Yates, Michael Cafarella, Michele Banko, Oren Etzioni, Matthew Broadhead, and Stephen Soder-\nland. Textrunner: open information extraction on the web. In Proceedings of Human Language Technologies:\nThe Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demon-\nstrations , pages 25\u201326. Association for Computational Linguistics, 2007.\nChia-Lun Yeh, Babak Loni, and Anne Schuth. Tom jumbo-grumbo at semeval-2019 task 4: Hyperpartisan\nnews detection with glove vectors and svm. In Proceedings of the 13th International Workshop on Semantic\nEvaluation , pages 1067\u20131071, 2019.\nYichun Yin, Yangqiu Song, and Ming Zhang. Document-level multi-aspect sentiment classi\ufb01cation as ma-\nchine comprehension. In Proceedings of the 2017 conference on empirical methods in natural language process-\ning, pages 2044\u20132054, 2017.\n119\nReferences References\nAlbin Zehe, Lena Hettinger, Stefan Ernst, Christian Hauptmann, and Andreas Hotho. Team xenophilius\nlovegood at semeval-2019 task 4: Hyperpartisanship classi\ufb01cation using convolutional neural networks.\nInProceedings of the 13th International Workshop on Semantic Evaluation , pages 1047\u20131051, 2019.\nChiyu Zhang, Arun Rajendran, and Muhammad Abdul-Mageed. Ubc-nlp at semeval-2019 task 4: Hyper-\npartisan news detection with attention-based bi-lstms. In Proceedings of the 13th International Workshop\non Semantic Evaluation , pages 1072\u20131077, 2019.\nLei Zhang, Shuai Wang, and Bing Liu. Deep learning for sentiment analysis: A survey. Wiley Interdisci-\nplinary Reviews: Data Mining and Knowledge Discovery , 8(4):e1253, 2018.\nXiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classi\ufb01cation.\nInAdvances in neural information processing systems , pages 649\u2013657, 2015.\nXinjie Zhou, Xiaojun Wan, and Jianguo Xiao. Attention-based lstm network for cross-lingual sentiment\nclassi\ufb01cation. In Proceedings of the 2016 conference on empirical methods in natural language processing , pages\n247\u2013256, 2016.\n120", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Hyperpt: detection and classification of hyperpartisan news articles", "author": ["M Muscat"], "pub_year": "2021", "venue": "NA", "abstract": "The modern hyper-connected world brings with it an unprecedented rise in fake and  hyperpartisan news, with anyone connected online harnessing the power of producing such"}, "filled": false, "gsrank": 806, "pub_url": "https://www.um.edu.mt/library/oar/handle/123456789/91911", "author_id": ["e0i2L9QAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:0uyb1KSSHngJ:scholar.google.com/&output=cite&scirp=805&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D800%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=0uyb1KSSHngJ&ei=mLWsaPaIErXCieoP4PfQ0A8&json=", "num_citations": 1, "citedby_url": "/scholar?cites=8655516770491952338&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:0uyb1KSSHngJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.um.edu.mt/library/oar/bitstream/123456789/91911/1/21MAIPT019.pdf"}}, {"title": "Algorithmic extremism: Examining YouTube's rabbit hole of radicalization", "year": "2019", "pdf_data": "Algorithmic Extremism: Examining YouTube\u2019s\nRabbit Hole of Radicalization\nMark Ledwich\nBrisbane, Australia\nmark@ledwich.com.auAnna Zaitsev\nThe School of Information\nUniversity of California, Berkeley\nBerkeley, United States\nanna.zaitsev@ischool.berkeley.edu\nAbstract \u2014The role that YouTube and its behind-the-scenes\nrecommendation algorithm plays in encouraging online radical-\nization has been suggested by both journalists and academics\nalike. This study directly quanti\ufb01es these claims by examining\nthe role that YouTubes algorithm plays in suggesting radicalized\ncontent. After categorizing nearly 800 political channels, we were\nable to differentiate between political schemas in order to analyze\nthe algorithm traf\ufb01c \ufb02ows out and between each group. After\nconducting a detailed analysis of recommendations received by\neach channel type, we refute the popular radicalization claims. To\nthe contrary, these data suggest that YouTubes recommendation\nalgorithm actively discourages viewers from visiting radicalizing\nor extremist content. Instead, the algorithm is shown to favor\nmainstream media and cable news content over independent\nYouTube channels with slant towards left-leaning or politi-\ncally neutral channels. Our study thus suggests that YouTubes\nrecommendation algorithm fails to promote in\ufb02ammatory or\nradicalized content, as previously claimed by several outlets.\nIndex Terms \u2014YouTube, recommendation algorithm, radical-\nization\nI. I NTRODUCTION\nThe internet can both be a powerful force for good, prosocial\nbehaviors by providing means for civic participation and com-\nmunity organization [1], as well as an attractor for antisocial\nbehaviors that create polarizing extremism [2]. This dual\nnature of the internet has been evident since the early days\nof online communication, where \u201d\ufb02ame-wars\u201d and \u201dtrolling\u201d\nhave been present in online communities for over two decades\n[3] [4] [5]. While such behaviors were previously con\ufb01ned\nto Usenet message boards and limited IRC channels, with\nthe expansion of social media, blogs, and microblogging\nfollowing the rapid growth of internet participation rates, these\nin\ufb02ammatory behaviors are no longer con\ufb01ned and have left\ntheir early back-channels into public consciousness [6].\nThe explosion of platforms, as well as ebbs and \ufb02ows in the\npolitical climate, has exacerbated the prevalence of antisocial\nmessaging [7]. Research focusing on uninhibited or antisocial\ncommunication, as well as extremist messaging online has\npreviously been conducted on platforms including Facebook\n[8], Twitter [9], Reddit [10], 4chan and 8chan [11] [12],\nTumblr [13] and even knitting forums such as Ravelry [14].\nIn addition to these prior studies on other platforms, at-\ntention has recently been paid to the role that YouTube\nmay play as a platform for radicalization [15] [16] [17].\nAs a content host, YouTube provides a great opportunity forbroadcasting a large and widely diverse set of ideas to millions\nof people worldwide. Included among general content creators\nare those who speci\ufb01cally target users with polarizing and\nradicalizing political content. While YouTube and other social\nmedia platforms have generally taken a strict stance against\nmost in\ufb02ammatory material on their platform, extremist groups\nfrom jihadi terrorist organizations [18] [19], various political\npositions [20], and conspiracy theorists have nonetheless been\nable to permeate the content barrier [21].\nExtreme content exists on a spectrum. YouTube and other\nsocial media platforms have generally taken a strict stance\nagainst the most in\ufb02ammatory materials or materials that\nare outright illegal. No social media platform tolerates ISIS\nbeheading videos, child porn, or videos depicting cruelty\ntowards animals. There seems to a consensus amongst all\nsocial media platforms that human moderators or moderation\nalgorithms will remove this type of content [22].\nYouTube\u2019s automatic removal of the most extreme content,\nsuch as explicitly violent acts, child pornography, and animal\ncruelty, has created a new era of algorithmic data mining\n[23] [24] [13]. These methods range from metadata scans\n[25] to sentiment analysis [26]. Nevertheless, content within\nan ideological grey area or that can nonetheless be perceived\nas \u201dradicalizing\u201d exists on YouTube [27]. De\ufb01nitions of free\nspeech differ from country to country. However, YouTube\noperates on a global scale within the cultural background of the\nUnited States with robust legislation that protects speech [7].\nEven if there are limitations to what YouTube will broadcast,\nthe platform does allow a fair bit of content that could be\ndeemed as radicalizing, either by accident or by lack of\nmonitoring resources.\nMeans such as demonetization, \ufb02agging, or comment lim-\niting is several tools available to content moderators on\nYouTube [28]. Nevertheless, removing or demonetizing videos\nor channels that present in\ufb02ammatory content has not curtailed\nscrutiny of YouTube by popular media [29]. Recently, the New\nYork Times published a series of articles, notably critiquing\nYouTube\u2019s recommendation algorithm, which suggests related\nvideos for users based on their prior preferences and users\nwith similar preferences [30] [15]. The argument put forward\nby the NYT is that users would not otherwise have stumbled\nupon extremist content if they were not actively searching for\nit since the role of recommendation algorithms for content onarXiv:1912.11211v1  [cs.SI]  24 Dec 2019\nother websites is less prevalent. As such, YouTube\u2019s algorithm\nmay have a role in guiding content, and to some extent, prefer-\nences towards more extremist predispositions. Critical to this\ncritique is that while previous comments on the role that social\nmedia websites play in spreading radicalization have focused\non user contributions, the implications of the recommendation\nalgorithm strictly implicate YouTube\u2019s programming as an\noffender.\nThe critique of the recommendation algorithm is another\ndifference that sets YouTube apart from other platforms. In\nmost cases, researchers are looking at how the users apply\nsocial media tools as ways to spread jihadism [18], alt-right\nmessages of white supremacy [12]. Studies are also focusing\non the methods the content creators might use to recruit more\nparticipants in various movements; for example, radical left-\nwing Antifa protests [31]. Nevertheless, the premise is that\nusers of Facebook, Tumblr, or Twitter would not stumble upon\nextremists if they are not actively searching for it since the\nrole of recommendation algorithms is less prevalent. There\nare always some edge cases where innocuous Twitter hashtags\ncan be co-opted for malicious purposes by extremists or\ntrolls [19], but in general, users get what they speci\ufb01cally\nseek. However, the case for YouTube is different: the rec-\nommendation algorithm is seen as a major factor in how\nusers engage with YouTube content. Thus, the claims about\nYouTube\u2019s role in radicalization are twofold. First, there are\ncontent creators that publish content that has the potential\nto radicalize [15]. Second, YouTube is being scrutinized for\nhow and where the recommendation algorithm directs the\nuser traf\ufb01c [17] [15]. Nevertheless, empirical evidence of\nYouTube\u2019s role in radicalization is insuf\ufb01cient [32]. There are\nanecdotes of a radicalization pipeline and hate group rabbit\nhole, but academic literature on the topic is scant, as we\ndiscuss in the next section.\nII. P RIOR ACADEMIC STUDIES ON YOUTUBE\nRADICALIZATION\nData-drive papers analyzing radicalization trends online are\nan emerging \ufb01eld of inquiry. To date, few notable studies have\nexamined YouTube\u2019s content in relation to radicalization. As\ndiscussed, previous studies have concentrated on the content\nitself and have widely proposed novel means to analyze\nthese data [13] [33] [25]. However, these studies focus on\nintroducing means for content analysis, rather than the content\nanalysis itself.\nHowever, a few studies go beyond content analysis methods.\nOne such study, Ottoni et al. (218), analyzed the language\nused in right-wing channels compared to their baseline chan-\nnels. The study concludes that there was little bias against\nimmigrants or members of the LGBT community, but there\nwas limited evidence for prejudice towards Muslims. However,\nthe study did \ufb01nd evidence for the negative language used\nby channels labeled as right-wing. Nevertheless, this study\nhas a few weaknesses. The authors of this paper frame their\nanalysis as an investigation into right-wing channels but then\nproceed to analyze kooky conspiracy channels instead ofmore mainstream right-wing content. They have chosen a\nconspiracy theorist Alex Jones\u2019 InfoWars (nowadays removed\nfrom YouTube) as their seed channel, and their list of right-\nwing channels re\ufb02ects this particular niche. InfoWars and\nother conspiracy channels represent only a small segment\nof right-wing channels. Besides, the study applies a topic\nanalysis method derived from the Implicit Association Test\n(IAT) [34]. However, the validity of IAT has been contested\n[35]. In conclusion, we consider the seed channel selection as\nproblematic and the range of the comparison channels as too\nvaguely explained [36].\nIn addition to content analysis of YouTube\u2019s videos, Riberio\net al. (2019) took a novel approach by analyzing the content\nof video comment sections, explaining which types of videos\nindividual users were likely to comment on overtime. Catego-\nrizing videos in four categories, including alt-right, alt-light,\nthe intellectual dark web (IDW), and a \ufb01nal control group,\nthe authors found inconclusive evidence of migration between\ngroups of videos.1\nThe analysis shows that a portion of commenters does\nmigrate from IDW videos to the alt-light videos. There is also\na tiny portion of commenter migration from the centrist IDW\nto the potentially radicalizing alt-right videos. However, we\nbelieve that one cannot conclude that YouTube is a radicalizing\nforce based on commenter traf\ufb01c only. There are several\n\ufb02aws in the setting of the study. Even though the study\nis commendable, it is also omitting the migration from the\ncenter to the left-of-center altogether, presenting a somewhat\nskewed view of the commenter traf\ufb01c. In addition, only a\ntiny fraction of YouTube viewers engage in commenting. For\nexample, the most popular video by Jordan Peterson, a central\ncharacter of the IDW, has 4.7 million views but only ten\nthousand comments. Besides, commenting on a video does\nnot necessarily mean agreement with the content. A person\nleaving a comment on a controversial topic might stem from\na desire to get a reaction (trolling or \ufb02aming) from either\nthe content creator or other viewers [37] [5]. We are hesitant\nto draw any conclusions based on the commenter migration\nwithout analyzing the content of the comments.\nThe most recent study by Munger and Phillips (2019)\ndirectly analyzed YouTube\u2019s recommendation algorithm and\nsuggested that the algorithm operated on a simple supply-\nand-demand principle. That is, rather than algorithms driving\nviewer preference and further radicalization, further radicaliza-\ntion external to YouTube inspired content creators to produce\nmore radicalized content. The study furthermore failed to \ufb01nd\nsupport for radicalization pathways, instead of \ufb01nding that\n1The study borrows a de\ufb01nition for the alt-right from Anti-Defamation\nLeague: \u201dloose segment of the white supremacist movement consisting of\nindividuals who reject mainstream conservatism in favor of politics that\nembrace racist, anti-Semitic and white supremacist ideology\u201d (pp. 2 [32]). The\nalt-light is de\ufb01ned to be a civic nationalist group rather than racial nationalism\ngroups. The third category, \u201dintellectual dark web\u201d (IDW), is de\ufb01ned as a\ncollection of academics and podcasters who engage in controversial topics.\nThe fourth category, the control group, includes a selection of channels form\nfashion magazine channels such as the (Cosmopolitan and GQ Magazine) to\na set of left-wing and right-wing mainstream media outlets.\nthe growth belonging to the centrist IDW category re\ufb02ected a\nderadicalization trend rather than further radicalization. Never-\ntheless, these authors are critical towards claims that watching\ncontent on Youtube will lead to the spread of radical ideas\nlike a \u201dzombie bite\u201d and are further critical of the potential\npipeline from moderate, centrist channels to radical right-wing\ncontent.\nIII. A NALYZING THE YOUTUBE RECOMMENDATION\nALGORITHM\nOur study focuses on the YouTube recommendation algo-\nrithm and the direction of recommendations between different\ngroups of political content. To analyze the common claims\nfrom media and other researchers, we have distilled them into\nspeci\ufb01c claims that can be assessed using our data set.\nC1 - Radical Bubbles. Recommendations in\ufb02uence viewers\nof radical content to watch more similar content than they\nwould otherwise, making it less likely that alternative views\nare presented.\nC2 - Right-Wing Advantage. YouTube\u2019s recommendation\nalgorithm prefers right-wing content over other perspectives.\nC3 - Radicalization In\ufb02uence. YouTube\u2019s algorithm\nin\ufb02uences users by exposing them to more extreme content\nthan they would otherwise seek out.\nC4 - Right-Wing Radicalization Pathway. YouTube\nalgorithm in\ufb02uences viewers of mainstream and center-left\nchannels by recommending extreme right-wing content,\ncontent that aims to disparage left-wing or centrist narratives.\nBy analyzing whether the data supports these claims, we will\nbe able to draw preliminary conclusions on the impact of the\nrecommendation algorithm.\nA. YouTube Channel Selection Criteria\nThe data for this study is collected from two sources.\nFirst, YouTube offers a few tools for software developers and\nresearchers. Our research applies an application programming\ninterface (API) that YouTube provides for other websites that\nintegrate with YouTube and also for research purposes to de-\n\ufb01ne the channel information, including view and engagement\nstatistics and countries. However, the YouTube API limited\nthe amount of information we could retrieve and the period it\ncould be kept and was thus not entirely suitable for this study.\nFor this reason, we use an additional scraping algorithm that\nprovides us information on individual video statistics such as\nviews, likes, video title, and closed captions. This algorithm\noffers data since the \ufb01rst of January, 2018. The scraping\nalgorithm also provides us the primary data applied for this\nstudy: the recommendations that YouTube\u2019s recommendation\nalgorithm offers for each video. The scraping process runs\ndaily.\nThe scraped data, as well as the YouTube API, provides us\na view of the recommendations presented to an anonymous\naccount. In other words, the account has not \u201dwatched\u201d any\nvideos, retaining the neutral baseline recommendations, de-\nscribed in further detail by YouTube in their recent paper thatexplains the inner workings of the recommendation algorithm\n[38]. One should note that the recommendations list provided\nto a user who has an account and who is logged into YouTube\nmight differ from the list presented to this anonymous account.\nHowever, we do not believe that there is a drastic difference in\nthe behavior of the algorithm. Our con\ufb01dence in the similarity\nis due to the description of the algorithm provided by the\ndevelopers of the YouTube algorithm [38]. It would seem\ncounter-intuitive for YouTube to apply vastly different criteria\nfor anonymous users and users who are logged into their\naccounts, especially considering how complex creating such\na recommendation algorithm is in the \ufb01rst place.\nThe study includes eight hundred and sixteen (816) channels\nwhich ful\ufb01ll the following criteria:\n\u000fChannel has over ten thousand subscribers.\n\u000fMore than 30 percent of the content on the channel is\npolitical.\nThe primary channel selection was made based on the number\nof subscriptions. The YouTube API provides channel details,\nincluding the number of subscribers and aggregate views of\nall time on the channel. The sizes of the bubble are based\non the video views in the year 2018m, not the subscriber\ncounts. YouTube also provides detailed info on the views of\neach video and dislikes, thus providing information on the\nadditional engagement each video receives from the users.\nGenerally, only channels that had over ten thousand sub-\nscriptions were analyzed. However, if the channel\u2019s subscrip-\ntion numbers were lower than our threshold value or there\nwere missing data. However, if the channel is averaging over\nten thousand views per month, the channel was still included.\nWe based our selection criteria on the assumption that\ntiny channels with minimal number of views or subscriptions\nare unlikely to ful\ufb01ll YouTube\u2019s recommendation criteria: \u201d 1)\nengagement objectives, such as user clicks, and degree of en-\ngagement with recommended videos; 2) satisfaction objectives,\nsuch as user liking a video on YouTube, and leaving a rating\non the recommendation [38].\u201d\nAnother threshold for the channels was the focus of the\ncontent: only channels where more than 30 percent of the\ncontent was on US political or cultural news or cultural\ncommentary, were selected. We based the cultural commentary\nselection on a list of social issues on the website ISideWith.\nA variety of qualitative techniques compiled the list of these\nchannels.\nThe lists provided by Ad Fontes Media provides a starting\npoint for the more mainstream and well-known alternative\nsites. Several blogs and other websites further list political\nchannels or provide tools for advanced searches based on\ntopics [39] [40] [41]. We also analyzed the recent academic\nstudies and their lists of channels such as Ribero et al. (2019)\nand Munger and Philips (2019). However, not all channels\nincluded in these two studies \ufb01t our selection criteria. Thus\none can observe differences between the channel lists and\ncategories between our research and other recent studies on\na similar subject.\nWe added emerging channels by following the YouTube\nrecommendation algorithm, which suggests similar content\nand which \ufb01t the criteria and passed our threshold. We can con-\nceptualize the recommendation algorithm as a type of snowball\nsampling, a common technique applied in social sciences when\none is conducting interview-based data collection but also in\nthe analysis of social networks. Each source is \u201drequested\u201d\nto nominate a few candidates that would be of interest to the\nstudy. The researcher follows there recommendations until the\ninformants reveal no new information or the inclusion criteria\nare met (e.g., channels become too marginal, or content is\nnot political). In our case, there is a starting point; a channel\nacts as a node in the network. Each connected channel (e.g.,\nnode) in the network is visited. Depending on the content of\nthe channel, it is either added to the collection of channels\nor discarded. Channels are visited until there are no new\nchannels, or the new channels do not \ufb01t the original selection\ncriteria [42].\nB. The Categorization Process\nThe categorization of YouTube channels was a non-trivial\ntask. Activist organizations provide lists and classi\ufb01cations, but\nmany of them are unreliable. For example, there are several\ncontroversies around the lists of hate groups discussed by the\nSouthern Poverty Law Center (SPLC) [43]. Also, there seems\nto be a somewhat contentious relationship between the Anti-\nDefamation League and YouTubers [44] [45]. We decided to\ncreate our categorization, based on multiple existing sources.\nFirst, one has several resources to categorize mainstream\nor alternative media outlets. Mainstream media such as CNN\nor Fox News have been studied and categorized over time by\nvarious outlets [46] [47]. In our study, we applied two sites\nthat provide information on the political views of mainstream\nmedia outlets: Ad Fontes Media and Media Bias Factcheck.\nNeither website is guaranteed to be unbiased, but by cross-\nreferencing both, one can come to a relatively reliable catego-\nrization on the political bias of the major news networks. These\nsites covered the \ufb01fty largest mainstream channels, which\nmake up for almost 80 percent of all YouTube views.\nNevertheless, the majority of the political YouTube channels\nwere not included in sources categorizing mainstream outlets.\nAfter reviewing the existing literature on political YouTube\nand the categorization created by authors such as Ribero\net al. (2019) or Munger and Philips (2019), we decided to\ncreate a new categorization. Our study strives for a granular\nand precise classi\ufb01cation to facilitate a deep dive into the\npolitical subcultures of YouTube, and the extant categories\nwere too narrow in their scope. We decided to apply on both\na high-level left-center-right political classi\ufb01cation for high-\nlevel analysis and create a more granular distinction between\neighteen separate labels, described shortly in Table I or at\nlength in Appendix A-D).\nIn addition to these \u2019soft tags,\u2019 we applied a set of so-called\n\u2019hard tags.\u2019 These additional tags allowed us to differentiate\nbetween YouTube channels that were part of mainstream\nmedia outlets and independent YouTubers. The hard tagsTABLE I\nCATEGORIZATION SOFT TAGS AND EXAMPLES\nTag Examples\nConspiracy A channel that regularly promotes a\nvariety of conspiracy theories.X22Report, The\nNext News Net-\nwork\nLibertarian Political philosophy with liberty as the\nmain principle.Reason, John\nStossel, The Cato\nInstitute\nAnti-SJW Have a signi\ufb01cant focus on criticizing\n\u201dSocial Justice\u201d (see next category) with a positive\nview of the marketplace of ideas and discussing\ncontroversial topics.Sargon of Akkad,\nTim Pool\nSocial Justice Promotes identity Politics and inter-\nsectionalityPeter Cof\ufb01n,\nhbomberguy\nWhite Identitarian Identi\ufb01es-with/is-proud-of the\nsuperiority of \u201dwhites\u201d and western civilization.NPIRADIX\n(Richard\nSpencer)\nEducational Channel that mainly focuses on educa-\ntion material.TED,\nSoulPancake\nLate Night Talk shows Channel with content pre-\nsented humorous monologues about the daily news.Last Week\nTonight, Trevor\nNoah\nPartisan Left Focused on politics and exclusively\ncritical of Republicans.The Young\nTurks, CNN\nPartisan Right Channel mainly focused on politics\nand exclusively critical of Democrats, supporting\nTrump.Fox News, Can-\ndace Owens\nAnti-theist Self-identi\ufb01ed atheist who are also ac-\ntively critical of religion.CosmicSkeptic,\nMatt Dillahunty\nReligious Conservative A channel with a focus on\npromoting Christianity or Judaism in the context of\npolitics and culture.Ben Shapiro,\nPragerU\nSocialist (Anti-Capitalist) Focus on the problems of\ncapitalism.Richald Wolf,\nNonCompete\nRevolutionary Endorses the overthrow of the current\npolitical system.Libertarian\nSocialist Rants,\nJason Unruhe\nProvocateur Enjoys offending and receiving any\nkind of attention.StevenCrowder,\nMILO\nMRA (Mens Rights Activist) Focus on advocating\nfor rights for men.Karen Straughan\nMissing Link Media Channels not large enough to\nbe considered \u201dmainstream.\u201dV ox, NowThis\nNews\nState Funded Channels funded by governments. PBS NewsHour,\nAl Jazeera, RT\nAnti-Whiteness A subset of Social Justice that in\naddition to intersectional beliefs about raceAfrican Diaspora\nNews Channel\nare discussed in more detail in Appendix A. The difference\nbetween \u2019soft\u2019 and \u2019hard\u2019 tags is that hard tags were based\non external sources, whereas the soft tags were based on the\ncontent analysis of the labelers.\nThe tagging process allowed each channel to be character-\nized by a maximum of four different tags to create meaningful\nand fair categories for the content. In addition to labeling\ncreated by the two authors, we recruited an additional vol-\nunteer labeler, who was well versed in the YouTube political\nsphere, and whom we trusted to label channels by their existing\ncontent accurately. When two or more labelers de\ufb01ned a\nchannel by the same label, that label was assigned to the\nchannel. When the labelers disagreed and ended in a draw\nsituation, the tag was not assigned. The majority was needed\nfor a tag to be applied.\nThe visual analysis in Figure 1 shows the intraclass corre-\nlation coef\ufb01ciency (ICC) between the three labelers. Based\non this analysis, we can determine that all three labelers\nwere in agreement when it comes to the high-level labels,\ne.g., left-right-center. Besides, there is a high coef\ufb01ciency in\nthe majority of the granular categories. On the left side of\nthe graph, we can see the intraclass correlation coef\ufb01ciency\nvalues, the estimates of the \u201dreal\u201d information captured by\nour classi\ufb01cation, which ranges from 0 to one. The larger the\nnumber, the more similar the tags were. One the right side of\nthe Figure, we see the reviewer agreement in percentages.\nThe ICC values above 0.75 are considered excellent, be-\ntween 0.75 and 0.59 are good and above 0.4 are consid-\nered as fair [48]. In our categorization, few classi\ufb01cations\nmeasure under 0.4. However, we believe that the explanation\nfor this convergence is related to the nature of these cate-\ngories. The low coef\ufb01ciency scoring of groups,\u2019Provocateur\u2019,\n\u2019Anti-whiteness\u2019 and \u201dRevolutionary,\u2019 could be explained by\nthe labeler\u2019s hesitation to apply these rather extreme labels\nwhere consistent evidence was lacking. Besides, since each\nchannel was allowed four different \u2019soft tags\u2019 de\ufb01ning these\nsubcategories, the channels were likely tagged by the other,\nmilder tags. The rationale behind the lack of agreement on\nthe \u2019Educational\u2019 label is best explained by the fact that\nthis category classi\ufb01cation might be somewhat super\ufb02uous.\nPolitical content, even educational one, often has a clear bias,\nand the content already belongs to one or more stronger\ncategories, such as Partisan Left or to channels that are non-\npolitical.\nFig. 1. The intraclass correlation coef\ufb01ciency between the three labelers\nHowever, if one looks at the percentages of the agreement,\nthe agreement if very high in most cases. The only categorywhere disagreement seems to be signi\ufb01cant is the left-right-\ncenter categorization. However, this disagreement can be ex-\nplained by the weighing applied when calculating the ICC\nfactor.\nTo assign a label, we investigated which topics the channels\ndiscussed and from which perspective. Some channels are\novertly partisan or declare their political stances and support\nfor political parties in their introductions or have posted\nseveral videos where such topics are discussed. For example,\nlibertarian channels support Ron and Rand Paul (Libertarian\npoliticians af\ufb01liated with the Republican party) or discuss\nAustrian economics with references to economists such as\nFrederick von Hayek or Ludwig von Mises or the \ufb01ctional\nworks of the author Ayn Rand. Comparably, many channels\ndedicated to various social justice issues title their videos to\nre\ufb02ect the content and the political slant, e.g., \u201dCan Our Planet\nSurvive Capitalism\u201d or \u201dThe Poor Go To Jail And The Rich\nMake Bail In America\u201d from AJ+.\nNevertheless, other channels are more subtle and required\nmore effort to tease out their af\ufb01liation. In these cases, we\nanalyzed the perspective that these channels took on political\nevents that have elicited polarized opinions (for example, the\nnomination of Brett Kavanaugh in the U.S. Supreme Court, the\nMigrant Caravan, Russiagate). Similarly, we also analyzed the\nreactions that the channels had for polarizing cultural events\nor topics (e.g., protests at university campuses, trans activism,\nfree speech). If the majority of these considerations aligned in\nthe same direction, then the channel was designated as left-\nleaning or right-leaning. If there was a mix, then the channels\nwere likely assigned to the centrist category.\nThe only way to conduct this labeling was to watch the\ncontent on the channels until the labelers found enough\nevidence for assigning speci\ufb01c labels. For some channels, this\nwas relatively straightforward: the channels had introductory\nvideos that stated their political perspectives. Some of the\nintros are very clearly indicating the political viewers of the\ncontent creator; some are more subtle. For example, a polit-\nical commentator Kyle Kulinski explicitly states his political\nleanings (libertarian-left) in channel SecularTalk description.\nIn contrast, a self-described Classical Liberal discussion host\nDave Rubin has a short introduction of various guests, pro-\nviding examples of the political discussions that take place\non his channel The Rubin Report. In other cases, the labelers\ncould not assign a label based on introduction or description\nbut had to watch several videos on the channel to determine\nthe political leanings. On average, every labeler watched over\n60 hours of YouTube videos to de\ufb01ne the political leanings\nwithout miscategorizing the channel and thus misrepresenting\nthe views of the content creators.\nBased on the eighteen classi\ufb01cation categories, we created\nthirteen aggregate groups that broadly represent the political\nviews of the YouTube channels. The eighteen \u2019soft tags\u2019 were\naggregated from ideological groups and better differentiated\nbetween the channels. For more details on tagging aggregation,\nplease see the Appendix A-B. These groupings were applied in\nthe data visualization rather than the more granular eighteen\ncategories for clarity and differentiation purposes. The next\nsection will discuss the data in more detail.\nIV. F INDINGS AND DISCUSSION\nThe data on YouTube channels a viewership each channel\ngarners provides us with insights as to how the recommenda-\ntion algorithm operates.\nPer the data collected for 2019, YouTube hosted more\nchannels with content that could be considered right-wing\nthan before. In de\ufb01ning right-wing, we considered categories\nsuch as proactive \u201dAnti-SJW\u201d (for anti-Social Just Warrior, a\nterm describing feminist/intersectionality advocates), Partisan-\nRight, Religious Conservative, and to some extent Conspiracy\nChannels (for brief explanations, see Table I). For longer\ndescriptions on the labels, see Appendix A). However, these\nmore numerous channels gained only a fraction of the views\nof mainstream media and centrist channels. Categories such as\nthe Center/Left MSM category, Unclassi\ufb01ed category (consist-\ning mainly of centrist, non-political and educational channels),\nand Partisan Left, capture the majority of viewership. The\ndifference here is considerable: where Center/left MSM has\n22 million daily views, the largest non-mainstream category,\nAnti-SJW, has 5.6 million daily views. Figure 2 illustrates the\nnumber of views for each category compared to the number\nof channels.\n2\nFig. 2. Daily Views and Number of Channels\nFigure 3 presents a chart of channel relations illustrating\nrelations between channels and channel clusters based on the\nconcept of a force-directed graph [49]. The area of each\nbubble, but not the radius, corresponds to the number of\nviews a channel has. The force/size of the line links between\nchannels corresponds to the portion of recommendations be-\ntween these channels. From this chart, we can see left-wing\nand centrist mainstream media channels are clustered tightly\ntogether. The Partisan Right cluster is also closer to the large\nmainstream media cluster than it is to any other category. Anti-\nSJW and Provocative Anti-SJW are clustered tightly together\n2The Figure 2 and all the following Figures are applying the aggregated\ncategories rather than the granular labels show in Figure 1 and discussed in\nAppendix A-B.with libertarian channels, while smaller categories such as\nAnti-theists and socialists are very loosely linked to a limited\nnumber of other categories. White Identitarian channels are\nsmall and dispersed across the graph.\nFig. 3. Channel Clusters\nWhen analyzing the recommendation algorithm, we are\nlooking at the impressions the recommendation algorithm\nprovides viewers of each channel.\nBy impressions, we are referring to an estimate for the\nnumber of times a viewer was presented with a speci\ufb01c recom-\nmendation. This number is an estimate because only YouTube\nis privy to the data re\ufb02ecting granulated impressions. However,\npublic-facing data obtained from channels themselves provide\nus with information on at least the top ten recommendations. A\nsimpli\ufb01ed formula for calculating the number of impressions\nfrom Channel A to Channel B is calculated by dividing the\nnumber of recommendations from A to B by the number\nof total recommendations channel A receives summed with\nchannel views and recommendations per video, multiplied\nby ten (for further information, see Appendix A-A). Such\na calculation of impressions allows us to aggregate the data\nbetween channels and categories.\nFigure 4 presents the recommendation algorithm in a \ufb02ow\ndiagram format. The diagram shows the seed channel cat-\negories on the left side and the recommendation channel\ncategories on the left side. The sizes of channel categories\nare based on overall channel view counts. The fourth cate-\ngory from the top is the most viewed channel category, the\nCenter/Left Mainstream media category (MSM). This group is\ncomposed of late-night talk shows, mainstream media shows,\nincluding the New York Times\u2019 YouTube channel. The Partisan\nLeft category closely follows the Center/Left MSM category,\nwith the primary differentiating factor being that the Partisan\nLeft category includes the content of independent YouTube\ncreators. Together, these two most viewed categories garner\nclose to forty million daily views.\nSeveral smaller categories follow the top two-categories.\nNotably, the two-second largest categories are also centrist\nor left-leaning in their political outlook. For example, the\ntwo largest channels in the Anti-SJW category (JRE Clips\nand PowerfulJRE)) both belong to an American podcast host,\nJoe Rogan, who hosts guests from a wide range of political\nbeliefs. The Unclassi\ufb01ed groups consist of centrist, mostly\napolitical, educational channels such as TED or government-\nowned mainstream media channels such as Russia Today.\nBased on our \ufb02ow diagram, we can see that the recommen-\ndation algorithm directs traf\ufb01cs from all channel groups into\nthe two largest ones, away from more niche categories.\nFig. 4. Flow diagram presenting the \ufb02ow or recommendations between\ndifferent groups\nBased on these data, we can now evaluate the claims\nthat the YouTube recommendation algorithm will recommend\ncontent that contributes to the radicalization of YouTube\u2019s user\nbase. By analyzing each radicalization claim and whether the\ndata support these claims, we can also conclude whether the\nYouTube algorithm has a role in political radicalization.\nThe \ufb01rst claim tested is that YouTube creates C1 - Radical\nBubbles. , i.e., recommendations in\ufb02uence viewers of radi-\ncal content to watch more similar content than they would\notherwise, making it less likely that alternative views arepresented. Based on our data analysis, this claim is partially\nsupported. The \ufb02ow diagram presented in Figure 4 shows a\nhigh-level view of the intra-category recommendations. The\nrecommendations provided by the algorithm remain within\nthe same category or categories that bear similarity to the\noriginal content viewed by the audience. However, from the\n\ufb02ow diagram, one can observe that many channels receive\nfewer impressions than what their views are i.e., the rec-\nommendation algorithm directs traf\ufb01c towards other channel\ncategories. A detailed breakdown of intra-category and cross-\ncategory recommendations is presented by recommendations\npercentages in Figure 12 and by a number of impressions in\nFigure 13 in Appendix B show the strength of intra-category\nrecommendations by channel.\nWe can see that the recommendation algorithm does have\nan intra-category preference, but this preference is dependent\non the channel category. For example, 51 percent of traf\ufb01c\nfrom Center Left/MSM channels is directed to other chan-\nnels belonging to the same category (see Figure 12). Also,\nthe remaining recommendations are directed mainly to two\ncategories: Partisan Left (18.2 percent) and Partisan Right\n(11 percent), both primarily consisting of mainstream media\nchannels.\nFigure 5 presents a simpli\ufb01ed version of the recommen-\ndation \ufb02ows, highlighting the channel categories that bene\ufb01t\nfrom the recommendations traf\ufb01c. From this \ufb01gure, we can\nobserve that there is a signi\ufb01cant net \ufb02ow of recommendations\ntowards channels that belong to the category Partisan Left.\nFor example, the Social Justice category suffers from cross-\ncategory recommendations. For viewers of channels that are\ncategorized as Social Justice, the algorithm presents 5.9 more\nrecommendations towards the Partisan Left channels than\nvice versa and another 5.2 million views per day towards\nCenter/Left MSM channels. Figure 5 also shows a \u201dpipeline\u201d\nthat directs traf\ufb01c towards the Partisan Left category from\nother groups via the intermediary Center/Left MSM category.\nThis is true even for the other bene\ufb01ciary category, the Partisan\nRight, which loses 2.9 million recommendations to Partisan\nLeft but bene\ufb01ts with a net \ufb02ow of recommendations from\ndifferent right-leaning categories (16.9M).\nHowever, when it comes to categories that could be poten-\ntially radicalizing, this statement is only partially supported.\nChannels that we grouped into Conspiracy Theory or White\nIdentitarian have very low percentages of recommendations\nwithin the group itself (as shown in 12). In contrast, channels\nthat we categorized into Center/Left MSM or Partisan Left or\nRight have higher numbers for recommendations that remain\nwithin the group. These data show that a dramatic shift to\nmore extreme content, as suggested by media [15] [30], is\nuntenable.\nSecond, we posited that there is a C2 - Right-Wing Advan-\ntage, i.e., YouTube\u2019s recommendation algorithm prefers right-\nwing content over other perspectives. This claim is also not\nsupported by the data. On the contrary, the recommendation\nalgorithm favors content that falls within mainstream media\ngroupings. YouTube has stated that its recommendations are\nFig. 5. The Direction of Algorithmic Recommendations\nbased on content that individual users watch and engage in\nand that peoples\u2019 watching habits in\ufb02uence 70 percent of\nrecommendations.\nFigure 6 shows the algorithmic advantage based on daily\nviews. From this Figure, we can observe that the two out of the\ntop three categories (Partisan Left, and Partisan Right) receive\nmore recommendations than other categories irregardless of\nwhat category the seed channels belong to. Conversely, any\nother category does not get their channels suggested by the\nalgorithm. In other words, the recommendation algorithm\nin\ufb02uences the traf\ufb01c from all channels towards Partisan Left\nand Partisan Right channels, regardless of what category the\nchannel that the users viewed belonged to.\nWe can also observe this trend from a higher-level aggregate\ncategorization, as is presented in Figure 7. The Figure af\ufb01rms\nthat channels that present left or centrist political content are\nadvantaged by the recommendation algorithm, while channels\nthat present content on the right are at a disadvantage.\nThe recommendations algorithm advantages several groups\nto a signi\ufb01cant extent. For example, we can see that when one\nwatches a video that belongs to the Partisan Left category,\nthe algorithm will present an estimated 3.4M impressions to\nthe Center/Left MSM category more than it does the other\nway. On the contrary, we can see that the channels that suffer\nthe most substantial disadvantages are again channels that\nfall outside mainstream media. Both right-wing and left-wing\nYouTuber channels are disadvantaged, with White Identitarian\nand Conspiracy channels being the least advantaged by the\nalgorithm. For viewers of conspiracy channel videos, there are\n5.5 million more recommendations to Partisan Right videos\nthan vice versa.\nWe should also note that right-wing videos are not the\nonly disadvantaged groups. Channels discussing topics such\nas social justice or socialist view are disadvantaged by the\nrecommendations algorithm as well. The common feature of\nFig. 6. Algorithmic Advantage by Groups\nFig. 7. High-level view of Algorithmic Advantages/Disadvantages in Rec-\nommendation Impressions\ndisadvantages channels is that their content creators are seldom\nbroadcasting networks or mainstream journals. These channels\nare independent content creators.\nWhen it comes to the third claim regarding YouTube\u2019s\npotential C3 - Radicalization In\ufb02uence , i.e., YouTube\u2019s al-\ngorithm in\ufb02uences users by exposing them to more extreme\ncontent than they would otherwise ; this claim is also not\nsupported by our data. On the contrary, the recommendation\nalgorithm appears to restrict traf\ufb01c towards extreme right-\nwing categories actively. The two most drastic examples are\nchannels we have grouped under the categories of White\nIdentitarian and Conspiracy theory channels. These two groups\nreceive almost no traf\ufb01c based on the recommendation algo-\nrithm, as presented in Figures 12 and 6.\nFig. 8. Traf\ufb01c from White Identitarian Channels\nAnother way to visualize the lack of traf\ufb01c from recom-\nmendations is to view the recommendations\u2019 \ufb02ow. Figures 8\nand 9 show that the majority of the recommendations \ufb02ow to\neither towards Partisan Right, Center/Left MSM, and Partisan\nLeft content. The White Identitarian channel traf\ufb01c is also\ndirected towards Libertarian and, to a small extent, even\ntowards centrist Anti-SJW content.\nBesides, the Figure 2 showed that the daily views for White\nIdentitarian channels are marginal. Even if we would compare\nthe views of White Identitarian channels with the Conspiracy\nchannels, we could see that Conspiracy channels are twice as\nviewed than content created by the White Identitarians. This\ndiscrepancy is notable since Conspiracy channels seem to gain\nzero traf\ufb01c from recommendations (as shown in Figure 12)\nand are the least advantaged group of all categories. While\nMRA (Men\u2019s Rights Activists) channels form the smallest\ncategory in our study, the White Identitarian category is in the\nbottom \ufb01ve of all groups. Another comparison that illustrates\nthe marginality of White Identitarian channels is the fact that\nthis group consists of thirty-seven channels with enough views\nFig. 9. Traf\ufb01c from Conspiracy Channels\nto \ufb01t within the scope of the study. The White Identitarian\ncategory includes almost the same number of channels as\nLibertarian channels but receives only a third as many views.\nOur fourth claim stated that there exists C4 - Right-Wing\nRadicalization Pathway i.e., YouTube algorithm in\ufb02uences\nviewers of mainstream and center-left channels via increas-\ningly left-wing critical content to the extreme right. \u201d Again,\nthese data suggest the opposite. The right-wing channel that\nbene\ufb01ts the most from the recommendation algorithm is Fox\nNews, a mainstream right-wing media outlet. Figure 10 shows\nthat Fox News receives over 50 percent of the recommen-\ndations form other channels, which map to the category of\nthe Partisan Right. Fox News also receives large numbers\nof recommendations from every other category that could\nbe considered right-wing. This observation is aligned with\nthe overall trend of the algorithm to bene\ufb01ting mainstream\nmedia outlets over independent YouTube channels. Fox News\nis likely disproportionally favored on the right due to a lack\nof other right-leaning mainstream outlets, while traf\ufb01c in the\nCenter/Left MSM and Partisan Left is more evenly distributed\namong their representative mainstream outlets.\nWe can also analyze the overall net bene\ufb01ts the mainstream\nmedia channels are receiving from the algorithm by aggre-\ngating the mainstream channels into one high-level group and\nFig. 10. Algorithmic advantage for Fox News\nindependent YouTubers into another group and comparing the\nalgorithmic advantages and disadvantages for each. The third\ngroup we separated from mainstream media and YouTubers\nis the group we called the \u201dMissing Link Media.\u201d This group\nencompasses media outlets that have \ufb01nancial backing with\nthe traditional mainstream outlets but are not considered part\nof the conventional mainstream media. For example, left-wing\nchannels such as V ox or Vice belong to this category, while\nBlazeTV is an equivalent for the right-leaning media. Figure\n11 shows the clear advantage mainstream media channels\nreceive over both independent channels and Missing Link\nMedia channels.\nFig. 11. Algorithmic Advantage of Mainstream Media\nFinally, based on the \ufb01ndings and analysis of our four\nclaims, we conclude that these data offer little support to the\nclaims that YouTube\u2019s recommendation algorithm will recom-\nmend content that might be contributing to the radicalization\nof the user-base. Only the \ufb01rst claim is partially supported,while the data refute all the other three claims. Rejection of\nthese claims seems to be in line with studies that critique the\nclaims of YouTube\u2019s algorithm as a pathway to radicalization\n[50].\nTABLE II\nCLAIMS AND DATA SUPPORT\nClaim Data Support\nC1 - Radical Bubbles. Recommendations in\ufb02uence\nviewers of radical content to watch more similar\ncontent than they would otherwise, making it less\nlikely that alternative views are presented.Partially\nsupported\nC2 - Right-Wing Advantage. YouTube\u2019s recom-\nmendation algorithm prefers right-wing content over\nother perspectives.Not supported\nC3 - Radicalization In\ufb02uence. YouTube\u2019s algorithm\nin\ufb02uences users by exposing them to more extreme\ncontent than they would otherwise.Not supported\nC4 - Right-Wing Radicalization Pathway.\nYouTube algorithm in\ufb02uences viewers of mainstream\nand center-left channels by recommending extreme\nright-wing content, content that aims to disparage\nleft-wing or centrist narratives.Not supported\nYouTube has stated that its algorithm will favor more\nrecent videos that are popular both in terms of views as\nwell as engagement [38]. The algorithm will recommend\nmore videos based on a user pro\ufb01le, or the most current,\npopular videos for anonymous viewers. YouTube has stated\nthat they are attempting to maximize the likelihood that a\nuser will enjoy their recommended videos and will remain\non the platform for as long as possible. The viewing history\ndetermines whether the algorithm will recommend the viewer\nmore extreme content. Antithetical to this claim is that our data\nshow that even if the user is watching very extreme content,\ntheir recommendations will be populated with a mixture of\nextreme and more mainstream content. YouTube is, therefore,\nmore likely to steer people away from extremist content rather\nthan vice versa.\nV. L IMITATIONS AND CONCLUSIONS\nThere are several limitations to our study that must be\nconsidered for the future. First, the main limitation is the\nanonymity of the data set and the recommendations. The\nrecommendations the algorithm provided were not based on\nvideos watched over extensive periods. We expect and have\nanecdotally observed that the recommendation algorithm gets\nmore \ufb01ne-tuned and context-speci\ufb01c after each video that\nis watched. However, we currently do not have a way of\ncollecting such information from individual user accounts,\nbut our study shows that the anonymous user is generally\ndirected towards more mainstream content than extreme. Sim-\nilarly, anecdotal evidence from a personal account shows\nthat YouTube suggests content that is very similar to previ-\nously watched videos while also directing traf\ufb01c into more\nmainstream channels. That is, contrary to prior claims; the\nalgorithm does not appear to stray into suggesting videos\nseveral degrees away from a user\u2019s normal viewing habits.\nSecond, the video categorization of our study is partially\nsubjective. Although we have taken several measures to bring\nobjectivity into the classi\ufb01cation and analyzed similarities\nbetween each labeler by calculating the intraclass correlation\ncoef\ufb01ciencies, there is no way to eliminate bias. There is\nalways a possibility for disagreement and ambiguity for cate-\ngorizations of political content. We, therefore, welcome future\nsuggestions to help us improve our classi\ufb01cation.\nIn conclusion, our study shows that one cannot proclaim\nthat YouTube\u2019s algorithm, at the current state, is leading\nusers towards more radical content. There is clearly plenty\nof content on YouTube that one might view as radicalizing\nor in\ufb02ammatory. However, the responsibility of that content\nis with the content creator and the consumers themselves.\nShifting the responsibility for radicalization from users and\ncontent creators to YouTube is not supported by our data.\nThe data shows that YouTube does the exact opposite of\nthe radicalization claims. YouTube engineers have said that\n70 percent of all views are based on the recommendations\n[38]. When combined with this remark with the fact that\nthe algorithm clearly favors mainstream media channels, we\nbelieve that it would be fair to state that the majority of the\nviews are directed towards left-leaning mainstream content.\nWe agree with the Munger and Phillips (2019), the scrutiny\nfor radicalization should be shined upon the content creators\nand the demand and supply for radical content, not the\nYouTube algorithm. On the contrary, the current iteration of\nthe recommendations algorithm is working against the extrem-\nists. Nevertheless, YouTube has conducted several deletion\nsweeps targeting extremist content [29]. These actions might\nbe ill-advised. Deleting extremist channels from YouTube does\nnot reduce the supply for the content [50]. These banned con-\ntent creators migrate to other video hosting more permissible\nsites. For example, a few channels that were initially included\nin the Alt-right category of the Ribero et al. (2019) paper,\nare now gone from YouTube but still exist on alternative\nplatforms such as the BitChute. The danger we see here is\nthat there are no algorithms directing viewers from extremist\ncontent towards more centrist materials on these alternative\nplatforms or the Dark Web, making deradicalization efforts\nmore dif\ufb01cult [51]. We believe that YouTube has the potential\nto act as a deradicalization force. However, it seems that the\ncompany will have to decide \ufb01rst if the platform is meant\nfor independent YouTubers or if it is just another outlet for\nmainstream media.\nA. The Visualization and Other Resources\nOur data, channel categorization, and data analysis used\nin this study are all available on GitHub for anyone to see.\nPlease visit the GitHub page for links to data or the Data\nvisualization. We welcome comments, feedback, and critique\non the channel categorization as well as other methods applied\nin this study.B. Publication Plan\nThis paper has been submitted for consideration at First\nMonday.\nC. Acknowledgments\nFirst, we would like to thank our volunteer labeler for all the\nhours spent on YouTube. We would also like to thank Cody\nMoser, Brenton Milne and Justin Murphy and everyone else\nwho gave their feedback on the early drafts of this paper and\naided the editing.\nREFERENCES\n[1] P. Ferdinand, The Internet, democracy and democratization . Routledge,\n2013.\n[2] C. Blaya, \u201cCyberhate A review and content analysis of intervention\nstrategies,\u201d Aggression and Violent Behavior , vol. 45, pp. 163\u2013172, 2019.\n[3] B. Pfaffenberger, \u201c\u201d if i want it, it\u2019s ok\u201d: Usenet and the (outer) limits\nof free speech,\u201d The Information Society , vol. 12, no. 4, pp. 365\u2013386,\n1996.\n[4] J. M. Kayany, \u201cContexts of uninhibited online behavior: Flaming in\nsocial newsgroups on usenet,\u201d Journal of the American Society for\nInformation Science , vol. 49, no. 12, pp. 1135\u20131141, 1998.\n[5] H. Berghel and D. Berleant, \u201cThe online trolling ecosystem,\u201d Computer ,\nno. 8, pp. 44\u201351, 2018.\n[6] ITU, \u201cWorld telecommunication/ict indicators database online,\u201d Interna-\ntional Telecommunication Union, 23rd Edition, http://handle.itu.int/11.\n1002/pub/81377c7d-en , 2019.\n[7] I. Gagliardone, D. Gal, T. Alves, and G. Martinez, Countering online\nhate speech . Unesco Publishing, 2015.\n[8] A. Ben-David and A. Matamoros-Fern \u00b4andez, \u201cHate speech and covert\ndiscrimination on social media: Monitoring the facebook pages of\nextreme-right political parties in spain,\u201d International Journal of Com-\nmunication , vol. 10, pp. 1167\u20131193, 2016.\n[9] P. Burnap and M. L. Williams, \u201cCyber hate speech on twitter: An\napplication of machine classi\ufb01cation and statistical modeling for policy\nand decision making,\u201d Policy & Internet , vol. 7, no. 2, pp. 223\u2013242,\n2015.\n[10] E. Chandrasekharan, U. Pavalanathan, A. Srinivasan, A. Glynn, J. Eisen-\nstein, and E. Gilbert, \u201cYou can\u2019t stay here: The ef\ufb01cacy of reddit\u2019s 2015\nban examined through hate speech,\u201d Proceedings of the ACM on Human-\nComputer Interaction , vol. 1, no. CSCW, p. 31, 2017.\n[11] L. Knuttila, \u201cUser unknown: 4chan, anonymity and contingency,\u201d First\nMonday , vol. 16, no. 10, 2011.\n[12] A. Nagle, Kill all normies: Online culture wars from 4chan and Tumblr\nto Trump and the alt-right . John Hunt Publishing, 2017.\n[13] S. Agarwal and A. Sureka, \u201cSpider and the \ufb02ies: Focused crawl-\ning on tumblr to detect hate promoting communities,\u201d arXiv preprint\narXiv:1603.09164 , 2016.\n[14] Q. Shen, M. M. Yoder, Y . Jo, and C. P. Rose, \u201cPerceptions of censorship\nand moderation bias in political debate forums,\u201d in Twelfth International\nAAAI Conference on Web and Social Media , 2018.\n[15] K. Roose, \u201cThe making of a youtube radical,\u201d The New York\nTimes (June 2019). https://www.nytimes.com/interactive/2019/06/08/\ntechnology/youtube-radical.html , 2019.\n[16] ADL, \u201cDespite youtube policy update, anti-semitic, white supremacist\nchannels remain,\u201d ADLs Center on Extremism , 2019.\n[17] L. Munn, \u201cAlt-right pipeline: Individual journeys to extremism online,\u201d\nFirst Monday , vol. 24, no. 6, 2019.\n[18] V . Andre, \u201cneojihadism and youtube: Patani militant propaganda dis-\nsemination and radicalization,\u201d Asian security , vol. 8, no. 1, pp. 27\u201353,\n2012.\n[19] I. Awan, \u201cCyber-extremism: Isis and the power of social media,\u201d Society ,\nvol. 54, no. 2, pp. 138\u2013149, 2017.\n[20] N. de Boer, H. S \u00a8utfeld, and J. Groshek, \u201cSocial media and personal at-\ntacks: A comparative perspective on co-creation and political advertising\nin presidential campaigns on youtube,\u201d First Monday , vol. 17, no. 12,\n2012.\n[21] J. B. Schmitt, D. Rieger, O. Rutkowski, and J. Ernst, \u201cCounter-messages\nas prevention or promotion of extremism?! the potential role of youtube:\nRecommendation algorithms,\u201d Journal of Communication , vol. 68, no. 4,\npp. 780\u2013808, 2018.\n[22] T. Gillespie, Custodians of the Internet: Platforms, content moderation,\nand the hidden decisions that shape social media . Yale University\nPress, 2018.\n[23] S. Agarwal and A. Sureka, \u201cTopic-speci\ufb01c youtube crawling to detect\nonline radicalization,\u201d in International Workshop on Databases in Net-\nworked Information Systems . Springer, 2015, pp. 133\u2013151.\n[24] A. Sureka, P. Kumaraguru, A. Goyal, and S. Chhabra, \u201cMining youtube\nto discover extremist videos, users and hidden communities,\u201d in Asia\nInformation Retrieval Symposium . Springer, 2010, pp. 13\u201324.\n[25] M. N. Hussain, S. Tokdemir, N. Agarwal, and S. Al-Khateeb, \u201cAnalyzing\ndisinformation and crowd manipulation tactics on youtube,\u201d in 2018\nIEEE/ACM International Conference on Advances in Social Networks\nAnalysis and Mining (ASONAM) . IEEE, 2018, pp. 1092\u20131095.\n[26] M. Z. Asghar, S. Ahmad, A. Marwat, and F. M. Kundi, \u201cSentiment\nanalysis on youtube: a brief survey,\u201d arXiv preprint arXiv:1511.09142 ,\n2015.\n[27] Youtube, \u201cPolicies and safety,\u201d https://www.youtube.com/about/\npolicies/, accessed 7th of November 2019 , 2019.\n[28] Youtube, \u201cLimited features for certain videos,\u201d https://support.google.\ncom/youtube/answer/7458465?hl=en, accessed 7th of November 2019 ,\n2019.\n[29] P. Martienau, \u201cYoutube removes more videos but still misses a\nlot of hate,\u201d The Wired (March 2019). https://www.wired.com/story/\nyoutube-removes-videos-misses-hate/ , 2019.\n[30] Z. Tufekci, \u201cYoutube, the great radicalizer,\u201d The New York Times , vol. 10,\n2018.\n[31] J. R. Vacca, Online Terrorist Propaganda, Recruitment, and Radicaliza-\ntion. CRC Press, 2019.\n[32] M. H. Ribeiro, R. Ottoni, R. West, V . A. Almeida, and W. Meira,\n\u201cAuditing radicalization pathways on youtube,\u201d arXiv preprint\narXiv:1908.08313 , 2019.\n[33] N. Agarwal, R. Gupta, S. K. Singh, and V . Saxena, \u201cMetadata based\nmulti-labelling of youtube videos,\u201d in 2017 7th International Conference\non Cloud Computing, Data Science & Engineering-Con\ufb02uence . IEEE,\n2017, pp. 586\u2013590.\n[34] A. G. Greenwald, D. E. McGhee, and J. L. Schwartz, \u201cMeasuring\nindividual differences in implicit cognition: the implicit association test.\u201d\nJournal of personality and social psychology , vol. 74, no. 6, p. 1464,\n1998.\n[35] P. S. Forscher, C. K. Lai, J. R. Axt, C. R. Ebersole, M. Herman, P. G.\nDevine, and B. A. Nosek, \u201cA meta-analysis of procedures to change\nimplicit measures.\u201d Journal of personality and social psychology , 2019.\n[36] R. Ottoni, E. Cunha, G. Magno, P. Bernardina, W. Meira Jr, and\nV . Almeida, \u201cAnalyzing right-wing youtube channels: Hate, violence\nand discrimination,\u201d in Proceedings of the 10th ACM Conference on\nWeb Science . ACM, 2018, pp. 323\u2013332.\n[37] P. J. Moor, A. Heuvelman, and R. Verleur, \u201cFlaming on youtube,\u201d\nComputers in human behavior , vol. 26, no. 6, pp. 1536\u20131546, 2010.\n[38] Z. Zhao, L. Hong, L. Wei, J. Chen, A. Nath, S. Andrews, A. Kumthekar,\nM. Sathiamoorthy, X. Yi, and E. Chi, \u201cRecommending what video to\nwatch next: a multitask ranking system,\u201d in Proceedings of the 13th\nACM Conference on Recommender Systems . ACM, 2019, pp. 43\u201351.\n[39] ChannelCrawler, \u201cThe youtube channel crawler,\u201d https://channelcrawler.\ncom/ , 2019.\n[40] SocialBlade, \u201cTop 25 youtube users tagged with politics sorted by video\nviews,\u201d https://socialblade.com/youtube/top/tag/politics/videoviews ac-\ncessed 7th of November 2019 , 2019.\n[41] Feedspot, \u201cPoliticial youtube channels,\u201d https://blog.feedspot.com/\npolitical youtube channels/ , 2019.\n[42] S. H. Lee, P.-J. Kim, and H. Jeong, \u201cStatistical properties of sampled\nnetworks,\u201d Physical review E , vol. 73, no. 1, p. 016102, 2006.\n[43] M. Thiessen, \u201cThe southern poverty law center has lost\nall credibility,\u201d https://www.washingtonpost.com/opinions/\nthe-southern-poverty-law-center-has-lost-all-credibility/2018/06/\n21/22ab7d60-756d-11e8-9780-b1dd6a09b549 story.html , accessed 7\nNovember 2019 , 2018.\n[44] B. Mandel, \u201cThe anti-defamation leagues sad slide\ninto just another left-wing pressure group,\u201d The Fed-\neralist (July 2017). https://thefederalist.com/2017/07/28/\nanti-defamation-leagues-sad-slide-just-another-left-wing-pressure-group/ ,\n2019.\n[45] J. Alexander, \u201cPewdiepie pulls 50,000 pledge to jewish\nanti-hate group after fan backlash,\u201d The Verge (September2019). https://www.theverge.com/2019/9/12/20862696/\npewdiepie-adl-donation-backlash-100-million-subscribers , 2019.\n[46] J.-M. Eberl, H. G. Boomgaarden, and M. Wagner, \u201cOne bias \ufb01ts all?\nthree types of media bias and their effects on party preferences,\u201d\nCommunication Research , vol. 44, no. 8, pp. 1125\u20131148, 2017.\n[47] F. N. Ribeiro, L. Henrique, F. Benevenuto, A. Chakraborty, J. Kul-\nshrestha, M. Babaei, and K. P. Gummadi, \u201cMedia bias monitor: Quan-\ntifying biases of social media news outlets at large-scale,\u201d in Twelfth\nInternational AAAI Conference on Web and Social Media , 2018.\n[48] D. V . Cicchetti, \u201cGuidelines, criteria, and rules of thumb for evaluat-\ning normed and standardized assessment instruments in psychology.\u201d\nPsychological assessment , vol. 6, no. 4, p. 284, 1994.\n[49] M. J. Bannister, D. Eppstein, M. T. Goodrich, and L. Trott, \u201cForce-\ndirected graph drawing using social gravity and scaling,\u201d in International\nSymposium on Graph Drawing . Springer, 2012, pp. 414\u2013425.\n[50] K. Munger and J. Phillips, \u201cA supply and demand framework for youtube\npolitics,\u201d Preprint , 2019.\n[51] G. Hussain and E. M. Saltman, Jihad trending: A comprehensive\nanalysis of online extremism and how to counter it . Quilliam, 2014.\nAPPENDIX A\nCHANNEL CATEGORIZATION\nA. Channel Views and Formulas\nWe have used several formulas in order to capture the \ufb02ow\nof recommendations. The main concept in our study is the\nimpression . Impression is an estimate for the number of\ntimes a viewer was presented with a recommendation. We\ncount each of the top 10 recommendations for a video as an\n\u201dimpression\u201d. Only YouTube knows true impressions, so we\nuse the following process create an estimate:\nTag Examples\nImpressions An estimate for the number of times a viewer was\npresented with a recommendation. I.e. we count each\nof the top 10 recommendations for a video as an \u201dim-\npression\u201d. Only YouTube knows true impressions,\nso we use the following process create an estimate:\nConsider each combination of videos (e.g. Video A\nto Video B)\n(A to B impressions) = (recommendations from A to\nB) / (total recommendations from Video A) x (*A\u2019s\nviews) x (recommendations per video = 10)\nRelevant impres-\nsions(A channel\u2019s relevance %) x impressions\nChannel views The total number of video views since \ufb01rst of Jan-\nuary 2018\nDaily channel\nviews(channel views) * (days in the period videos have\nbeen recorded for the channel)\nRelevant channel\nviews(daily channel views) * (channel relevance %)\nB. Tag Aggregation\nIn order to create meaningful ideological categories, we\nhave aggregated the tags assigned for each channel. In order\nto calculate the majority view, each soft tag is assessed\nindependently. For each tag, the number of the reviewer with\nthat rag must tally to more than half. Eighteen categories of\nsoft tags, the soft tags de\ufb01ning left, center, and right, and\nthe hard tags de\ufb01ning the media type, were aggregated for\nthe visualization and data analysis. The following list informs\nwhich tags or tag combinations were aggregated to represent\nan ideology, rather than just a collection of tags.\n\u000fWhite Identitarian !White Identitarian\n\u000fMRA!MRA\n\u000fConspiracy !Conspiracy\n\u000fLibertarian !Libertarian\n\u000fAntiSJW and either Provocateur or PartisanRight !\nProvocative Anti-SJW\n\u000fAntiSJW !Anti-SJW3\n\u000fSocialist !Socialist\n\u000fReligiousConservative !Religious Conservative\n\u000fSocial Justice or Anti-Whiteness !Social Justice\n\u000fLeft or Center \u2019hard\u2019 tag and Mainstream News or\nMissing Link Media \u2019hard\u2019 tag !Center/Left MSM\n\u000fPartisanLeft !Partisan Left\n\u000fPartisanRight !Partisan Right\n\u000fAntiTheist !Anti-Theist\n3This group has a signi\ufb01cant overlap with the intellectual dark web-group\nas described by Ribero et al. (2019), Munger and Phillips (2019)\u000fEverything else !Unclassi\ufb01ed\nC. Hard Tags\nHard tags are tags sources from external sources. Any\ncombination of the following tags can be applied to a channel.\nHard tags are for comparison between the categorization\npresented in this paper and other work, academic or otherwise,\nand also used to distinguish between YouTubers and TV or\nother mainstream media content.\nTag Examples\nMainstream News Reporting on newly received or\nnoteworthy information. Widely accepted and self-\nidenti\ufb01ed as news (even if mostly opinion). Ap-\npears in either https://www.adfontesmedia.com or\nhttps://mediabiasfactcheck.com.\nTo tag they should have \u00bf 30% focus on politics &\nculture.Fox News, Buz-\nzfeed News\nTVContent originally created for broadcast TV or\ncableCNN, Vice\nRibeiro et al.\u2019s alt-lite, alt-right, IDW As listed\nin Auditing\nRadicalization\nPathways on\nYouTube [32]\nD. Soft Tags\nSoft tags are a natural category for US YouTube content.\nMany traditional ways of dividing politics are not natural cate-\ngories that would accurately describe the politics of YouTube\nchannels. In general, YouTubers are providing reaction and\nsensemaking on other channels or current events in the United\nStates. We have created a list of categories that attempt to align\nthe stands taken by the channels more naturally, expanding the\ncategorization beyond the left, center, and right categories.\nThe tag needs to be engaging in some way to the current\nmeta-discussion about YouTube\u2019s in\ufb02uence on politics. Our\nlist of categories intends to cover major cultural topics and\nlabel channels to the best of our abilities. We have tried to\n\ufb01nd speci\ufb01c positions that could be mixed and aggregate in\norder to create categories that would represent ideologies.\nOur guiding principle is that, in order to apply one of these\ntags, one should be able to judge the channel by the channel\ncontent itself. It is important not to rely on an outside judgment\nabout the channel\u2019s content. It is also important to interpret the\ncontent with full context: there should be no mind-reading and\nno relying on a judgment from other sources. There should\nalso be enough channels per each category. If the category is\ntoo niche, it should be excluded, unless it is essential for the\nradicalization pathway theory.\nTag Examples\nConspiracy A channel that regularly promotes a variety of conspiracy theories. A conspiracy theory explains an\nevent/circumstance as the result of a secret plot that is not widely accepted to be true (even though sometimes it\nis).\nExample conspiracy theories:\n\u000fMoon landings were faked\n\u000fQAnon & Pizzagate\n\u000fTrump colluding with Russia to win the electionX22Report, The Next News Network\nLibertarian A political philosophy that has liberty as its main principle. Generally skeptical of authority and\nstate power (e.g., regulation, taxes, government programs). Favors free markets and private ownership.\nNote: To tag someone, this should be the primary driver of their politics. Does not include libertarian socialists\nwho also are anti-state but are anti-capitalist and promote communal living.Reason, John Stossel, The Cato Insti-\ntute\nAnti-SJW Channel has to have a signi\ufb01cant focus on criticizing \u201dSocial Justice\u201d (see next category) with a\npositive view of the marketplace of ideas and discussing controversial topics. To tag a channel, this should be a\ncommon focus in their content.Sargon of Akkad, Tim Pool\nSocial Justice The channel promotes\n\u000fIdentity Politics & Intersectionality narratives of oppression though the combination of historically\noppressed identities: Women, Non-whites, Transgender\n\u000fPolitical Correctness the restriction of ideas and words you can say in polite society.\n\u000fSocial Constructionism the idea that the differences between individuals and groups are explained entirely\nby the environment. For example, sex differences are caused by culture, not by biological sex.\nThe channel content is often in reaction to Anti-SJW or conservative content rather than purely a promotion of\nsocial justice ideas.\nThe supporters of the content creator are active on Reddit in subreddit called r/Breadtube, and the creators often\nidentify with this label. This tag only includes breadtuber\u2019s if their content is criticizing anti-SJW\u2019s (promoting\nsocialism is its own, separate tag).Peter Cof\ufb01n, hbomberguy\nWhite Identitarian Identi\ufb01es-with/is-proud-of the superiority of \u201dwhites\u201d and Western Civilization. An example\nof identifying with \u201dwestern heritage\u201d would be to refer to the Sistine chapel or Bach as \u201dour culture.\u201d\nOften will promote\n\u000fAn ethnostate where residence or citizenship would be limited to \u201dwhites\u201d OR a type of nationalist that\nseek to maintain a white national identity (white nationalism)\n\u000fA historical narrative focused on the \u201dwhite\u201d lineage and its superiority\n\u000fEssentialist concepts of racial differences\nThe content creators are very concerned about whites becoming a minority population in the US/Europe (the\nGreat Replacement - theory)NPIRADIX (Richard Spencer), Stefan\nMolyneux\nEducational Channel that mainly focuses on education material, of which over 30% is focused on making sense\nof culture or politics.TED, SoulPancake\nLate Night Talk shows Channel with content presented humorous monologues about the day\u2019s news, guest\ninterviews, and comedy sketches. To tag, they should have over 30% focus on politics & culture.Last Week Tonight, Trevor Noah\nPartisan Left Channel mainly focused on politics and exclusively critical of Republicans. Would agree with this\nstatement: \u201dGOP policies are a threat to the well-being of the country.\u201dThe Young Turks, CNN\nPartisan Right Channel mainly focused on politics and exclusively critical of Democrats. Must support Trump.\nWould agree with this statement: \u201dDemocratic policies threaten the nation.\u201dFox News, Candace Owens\nAnti-theist The self-identi\ufb01ed atheist who is also actively critical of religion. Also called New Atheists or Street\nEpistemologists. Usually combined with an interest in philosophy.Sam Harris, CosmicSkeptic, Matt Dil-\nlahunty\nReligious Conservative A channel with a focus on promoting Christianity or Judaism in the context of politics\nand culture.Ben Shapiro, PragerU\nSocialist (Anti-Capitalist) Focus on the problems of capitalism. Endorse the view that capitalism is the source\nof most problems in society.\nCritiques of aspects of capitalism that are more speci\ufb01c (i.e., promotion of fee healthcare or a large welfare system\nor public housing) don\u2019t qualify for this tag.\nPromotes alternatives to capitalism. Usually, some form of either Social Anarchist (stateless egalitarian com-\nmunities) or Marxist (nationalized production and a way of viewing society through class relations and social\ncon\ufb02ict).BadMouseProductions, NonCompete\nRevolutionary Endorses the overthrow of the current political system. For example, many Marxist and Ethno-\nnationalists are revolutionaries because they want to overthrow the current system and accept the consequences.Libertarian Socialist Rants, Jason Un-\nruhe\nProvocateur Enjoys offending and receiving any kind of attention (positive or negative). Takes extreme positions,\nor frequently breaks cultural taboos. Often it is unclear if they are joking or serious.StevenCrowder, MILO\nMRA (Mens Rights Activist) Focus on advocating for rights for men. See men as the oppressed sex and will\nfocus on examples where men are currently oppressed.\nIncels, who identify as victims of sex inequality, would also be included in this category.Karen Straughan\nMissing Link Media Channels funded by companies or venture capital, but not large enough to be considered\n\u201dmainstream.\u201d\nThey are generally accepted as more credible than independent YouTube content.V ox, NowThis News\nState Funded Channels that are funded by governments. PBS NewsHour, Al Jazeera, RT\nAnti-Whiteness A subset of Social Justice that, in addition to intersectional beliefs about race, has a signi\ufb01cant\nportion of content that essentializes race and disparages \u201dwhites\u201d as a group. Channel should match most of the\nfollowing:\n\u000fNegative generalization about \u201dwhites\u201d. E.g. \u201dWhite folks are unemotional, they hardly even cry at funerals,\u201d\ne.g., How To Play The Game w/WS 5 Daily Routines\n\u000fUse of the word \u201dwhiteness\u201d as a slur, or an evil force. e.g., \u201dI try to be less white\u201d (Robin DiAngelo)\n\u000fSimplistic narratives about American history, where the most important story is of slavery and racism.\n\u000fDilute terms like racism or white supremacy so that they include most Americans while keeping the stigma\nand power of the word.\n\u000fcontent exclusively framing current events into racial oppression. Usually in the form of police violence\nagainst blacks, x-while-black (e.g., swimming while black, walking while black)...African Diaspora News Channel\nAPPENDIX B\nDETAILED ALGORITHMIC ADVANTAGES AND\nDISADVANTAGES\nWe discuss algorithmic advantages and disadvantages at\nthe higher level in Section IV. This appendix presents two\nadditional \ufb01gures that shows a breakdown of recommendation\nalgorithm traf\ufb01c channel by channel.\nFirst, Figure 12 presents the relative portion of recommen-\ndations between groups. The diagonal column cutting across\nthe chart shows the percentages of intra-category recommenda-\ntions, i.e., the percentage of recommendations that are directed\nto the same category. In contrast, lower percentages in this di-\nagonal that the majority of the traf\ufb01c is directed outwards from\nthe category. The other cells show the percentages each group\nis recommended in relation to other categories. For example,\nif one is to view a video that belongs to the Provocative Anti-\nSJW category, the bulk of the recommendations will suggest\nvideos that belong to either Partisan Right or non-political\nchannels.\nThe non-political channels in this chart are channels that fall\noutside our labeled data categories. The Figure 12 illustrates\nthat these channels are recommended in large numbers for\ncategories that fall on the fringes, such as the White Identi-\ntarian and MRA channels, directing the traf\ufb01c towards less\ncontentious material.\nFig. 12. Cross-category and Intra-category Recommendations\nFigure 12 presents the different advantages and disadvan-\ntages each group has due to the recommendation system\nin more detail. The Figure compares the daily net \ufb02ow of\nrecommendations for each group. The categories in the Figure\nare organized based on their algorithmic advantage, the most\nadvantaged groups are at the top, and least advantaged groupsare at the bottom. Categories in darkest shades of blue are\nmost advantaged, whereas the categories on darker shades of\nred are at least advantage.\nFig. 13. Algorithmic Advantages/Disadvantages in Recommendation Impres-\nsions\nCategories in grey are also at a disadvantage, but to a lesser\nextent than the categories in red the small arrows in the\nimage point towards the category, which is bene\ufb01ting from\nthe recommendations algorithm. Arrows are pointing towards\nthe group that receives more recommendations that it is given\nby the algorithm, i.e., pointing towards the group, which is\nadvantaged.\n...", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Algorithmic extremism: Examining YouTube's rabbit hole of radicalization", "author": ["M Ledwich", "A Zaitsev"], "pub_year": "2019", "venue": "arXiv preprint arXiv:1912.11211", "abstract": "The role that YouTube and its behind-the-scenes recommendation algorithm plays in  encouraging online radicalization has been suggested by both journalists and academics alike."}, "filled": false, "gsrank": 807, "pub_url": "https://arxiv.org/abs/1912.11211", "author_id": ["", "ts_2r1gAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:r_yaykLAp4QJ:scholar.google.com/&output=cite&scirp=806&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D800%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=r_yaykLAp4QJ&ei=mLWsaPaIErXCieoP4PfQ0A8&json=", "num_citations": 249, "citedby_url": "/scholar?cites=9558820127216696495&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:r_yaykLAp4QJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1912.11211"}}, {"title": "Republican Electoral Manipulation After Jan 6", "year": "2025", "pdf_data": "Maria Lind\u00e9n*\nRepublican Electoral Manipulation After Jan 6\nhttps://doi.org/10.1515/for-2025-2010\nAbstract: This article shows that numerous prominent members of the Republican\nParty have resorted to the same electoral manipulation tactics that former president\nDonald Trump utilized in 2020. A case study analyzing acts of electoral manipulation\nundertaken by members of the Republican party in 2021 and 2022 demonstrates that\nRepublicans have been actively engaging in breaking democratic norms, spreading\ndisinformation, gerrymandering, restricting opportunities for voting, pressuring\nfellow partisans to participate in electoral manipulation, intimidating those whoresist their manipulation e \ufb00orts, creating an atmosphere accepting of political\nviolence, and corrupting democratic institutions. There are also similarities between\nTrump and other Republicans in how the tactics are used. Just like Trump in 2020,\nprominent Republicans have been using di \ufb00erent manipulation tools in concert to\ncreate a whole that is larger than the sum of its parts. The situation has various\nimplications for the 2024 presidential election, which are discussed in the concluding\nchapter of this article.\nKeywords: elections; electoral integrity; electoral manipulation; Donald Trump;\nRepublican party\nDonald Trump \u2019s attempt to manipulate the 2020 presidential elections was in many\nways unprecedented all the while being part of a historical continuum. Although\nmany of his manipulation tactics had been utilized countless times in the past, his\nparticular combination of tactics and their interplay created a whole that was novel\nand larger than the sum of its parts. This article shows that prominent members of\nthe Republican Party, including the former president himself, have since then\ncontinued to utilize almost all of the same tactics and exploit their interplay in a\nsimilar manner to 2020. With Trump as the presumptive Republican nominee in the\n2024 presidential election, scrutinizing the similarities between his 2020 manipulation\nattempt and more recent actions taken by prominent members of his party is crucialfor better understanding the potential threat to the integrity of the 2024 elections,\nwhich many prominent experts have warned about (e.g. Gellman 2021; Levitsky and\n*Corresponding author: Maria Lind\u00e9n , PhD Candidate, Tampere University, Tampere, Finland; and\nResearch Fellow, Finnish Institute of International A \ufb00airs, Helsinki, Finland, E-mail: maria.linden@tuni. \ufb01The Forum 2024; 22(4): 545 \u2013565\nOpen Access. \u00a9 2025 the author(s), published by De Gruyter. This work is licensed under the\nCreative Commons Attribution 4.0 International License.\nDaniel 2021; Luttig 2022). The article answers the following questions: 1) Did\nRepublican politicians or their supporters undertake acts of electoral manipulation\nbetween January 7, 2021, and December 30, 2022, and if so, 2) what tactics did they use,\nand 3) was there interplay between the tactics?\nPrevious research on electoral manipulation has tended to examine di \ufb00erent\nmanipulation tactics in isolation instead of analyzing their interplay. As interplay of\ndi\ufb00erent manipulation tactics was crucially important in Trump \u2019s 2020 electoral\nmanipulation attempt, this article takes a di \ufb00erent approach and relies upon a\ncontemporary electoral manipulation framework with an explicit focus on the inter-play of manipulation tactics. A contemporary framework is preferred also because the\npresent-day context surrounding elections and electoral manipulation is markedly\ndi\ufb00erent from that of previous decades (James and Garnett 2023, 10 \u201313), and that\ncontext is not re \ufb02ected in many of the established electoral manipulation frame-\nworks such as the works of Birch (2011, 28 \u201339), Calingaert (2006, 139 \u2013149), Cheeseman\nand Klaas (2018, 31 \u2013207), Morgenbesser (2020, 1056) or Schedler (2002, 39 \u201345) (for a\nmore detailed discussion on the need for this novel framework see Lind\u00e9n 2024).\nThe argument proceeds in the following manner: First, the framework utilized in\nthe article is introduced. Thereafter, data and methodology are introduced, followedby an analysis of the results. In conclusion, the threat to the integrity of the 2024\nelection is re \ufb02ected upon based on the results presented in the article.\n1 A Framework Focused on the Interplay of\nManipulation Tactics\nThe research presented in this article relies upon an electoral manipulation\nframework constructed by this author that depicts electoral manipulation in the\nspeci\ufb01c context of the United States in the 2020s. The framework was formulated based\non a case study of Trump \u2019s attempt to manipulate the 2020 elections (see Lind\u00e9n 2024),\nand it emphasizes interplay between di \ufb00erent manipulation tactics and the whole they\ncreate. The foundation of the framework is a contemporary theory formulated by\nJames and Garnett (2023, 13 \u201319), who take a normative approach to electoral integrity\nbased on democratic theory and de \ufb01ne it as consisting of \ufb01ve key pillars: equality of\ncontestation, equality of participation, meaningful deliberation, electoral manage-\nment delivery, and electoral governance. In formulating the electoral manipulation\nframework utilized in this article, acts undertaken by Trump and his allies were\nconsidered electoral manipulation if they undermined one or several of the key\npillars of electoral integrity as de \ufb01ned by James and Garnett.546 M. Lind\u00e9n\nEmploying qualitative content analysis as the method, acts that were considered\nelectoral manipulation were sorted into categories on the basis of both deductive and\ninductive reasoning. The deductive reasoning relied upon previous electoral\nmanipulation frameworks, most notably that of Birch (2011, 28 \u201339), Calingaert (2006,\n139 \u2013149), Cheeseman and Klaas (2018, 31 \u2013207), but also those of Morgenbesser (2020,\n1056) and Schedler (2002, 39 \u201345). Inductive reasoning was relied upon as there were\nnumerous acts that were coded as electoral manipulation but did not correspond to\ncategories introduced in previous frameworks, prompting the creation of novel\ncategories.\nThe framework consists of nine electoral manipulation tactics, which build upon\nand reinforce each other:\n\u2013Breaking democratic norms\n\u2013Disinformation\n\u2013Gerrymandering\n\u2013Voter suppression\n\u2013Hacking and leaking\n\u2013Collusion with one or more foreign states\n\u2013Intraparty pressure\n\u2013Intimidation and violence\n\u2013Corrupting state and government institutions\nAlthough some of the labels such as breaking democratic norms or intraparty\npressure can also be used to depict acts that are not electoral manipulation, in the\nframework the labels only refer to acts that fall into the umbrella category of elec-\ntoral manipulation. All tactics undermine one or several principles of electoral\nintegrity as de \ufb01ned by James and Garnett (2023, 15 \u201319; see Lind\u00e9n 2024 for a more\ndetailed analysis), but they are not equally harmful to electoral integrity. Tactics at\nthe beginning of the list may seem minor or insigni \ufb01cant, but they play an important\nrole in laying the groundwork for the use of the more pernicious tactics at the end ofthe list. Interplay between the tactics is described in more detail in Table 1 (reproduced\nfrom Lind\u00e9n 2024): for example, intimidation and violence can be justi \ufb01ed with\nbreaches of democratic norms and disinformation, they can rely upon\ngerrymandering, and they can help execute voter suppression, intraparty pressure\nand corruption of democratic institutions.\nDisinformation ,gerrymandering ,voter suppression , and intimidation and\nviolence are commonly used terms depicting manipulation tactics that have been\ncommon in the United States over the course of history (Chervinsky 2021; Cheeseman\nand Klaas 2018, 34 \u201346; Epperly et al. 2020, 758 \u2013764). Hacking and leaking andcollu-\nsion have been the focus of attention in the 2010s and 2020s in the context of foreign\nelection meddling (see e.g. Aaltola 2021, 133 \u2013136). The terms intraparty pressure andRepublican Electoral Manipulation 547\ncorrupting state and government institutions ,\ufb01nally, have been coined for the\npurposes of the novel framework, as the types of actions they depict are absent from\nprevious electoral manipulation frameworks. Despite their absence from the other\nframeworks, the phenomena in question are well established in previous literatureas serious threats to democracy. Svolik (2019, 21), for example, speaks of executive\ntakeovers requiring the complicity of the legislature, which needs to be in the hands\nof fellow partisans of the executive, and Bermeo (2016, 10 \u201311) describes executive\naggrandizement, which can rely in part on legislatures or courts, if supporters of the\nexecutive have control of those bodies. In the framework, intraparty pressure refers\nto attempts by then-executive Trump to gain such complicity of his fellow partisans,\nand corrupting state and government institutions depicts his actions that attempted\nto accomplish executive aggrandizement or an executive takeover. Taking such actsTable \uf131:Reproduced from Lind\u00e9n \uf132\uf130\uf132\uf134 .\n548 M. Lind\u00e9n\ninto consideration as part of an electoral manipulation attempt is a key strength of the\nnovel framework because executive takeovers have for decades been the leading cause\nof democratic breakdown (Svolik 2019, 20 \u201321), which makes their scrutiny vital.\n2 Data and Methodology\nTo determine whether Republicans undertook acts of electoral manipulation in 2021\nor 2022 and to analyze their manipulation tactics and their interplay, a case study\nwas conducted. The study relies mainly on documents containing information\nunearthed by two important institutions of diagonal accountability: the news media\nand non-governmental organizations, both powerful agents in the United States. As\nadditional sources of information it utilizes academic pursuits such as the Princeton\ngerrymandering project, and press releases by authorities such as the Department of\nHomeland Security.\nThe main body of newspaper data consists of news reporting and opinion\ncolumns by the Washington Post , but reporting and opinion columns by the Wall\nStreet Journal were also consulted. Reports by non-governmental organizations were\ninstrumental in providing more in-depth information than newspaper reports. The\nWashington Post was chosen due to its status as the dominant newspaper in the\nnation \u2019s capital, its detailed coverage of American politics, and its long history of\nunearthing political scandals (Britannica 2023). As the paper leans somewhat to the\npolitical left (AllSides 2021; Media Bias/Fact Check 2022b), the Wall Street Journal was\nrelied upon to provide a center or right-leaning perspective (AllSides 2022, 2023;\nMedia Bias/Fact Check 2022a).\nNews articles and opinion columns were retrieved from the digital archives of\ntheWashington Post using search parameters \u201cRepublican \u201dand \u201celection \u201d, spanning\nthe period between Jan 7, 2021, and Dec 31, 2022.1The generic search terms were\nchosen in order to compile a large collection of news articles to form a compre-\nhensive picture of election-related actions taken by members of the Republican\nParty. This allowed the researcher to undertake the coding of the data instead of\nrelying on categorizations done by journalists. An identical collection of newspaper\ndata was compiled from the archives of the Wall Street Journal ,2and it was analyzed\nin search of di \ufb00erences in how electoral manipulation was depicted. The di \ufb00erences\nbetween the manipulation acts described in the Post data and the Journal data\n1The search yielded 5,547 articles, out of which 1,574 were chosen for further analysis based on their\nheadlines.\n2The search yielded 2,400 articles. Articles were only chosen for further analysis if they appeared to\ncontain new information, and therefore they were not counted.Republican Electoral Manipulation 549\nproved minor, and most of the material from the latter was deemed redundant. The\nmain body of newspaper data was complemented with individual journalistic arti-\ncles and blog posts from sources such as the New York Times andFiveThirtyEight .\nThe entirety of the Wahington Post data, the non-redundant sections of the Wall\nStreet Journal data and the supplementary materials such as reports and press\nreleases were analyzed using qualitative content analysis, a method suitable for a\nsystematic and rigorous analysis of data that requires a degree of interpretation on\nthe part of the researcher (Schreier 2012, chapter 1). Interpretation is an inevitable\npart of any study of present-day electoral manipulation in the United States, as theconversation around electoral integrity and electoral manipulation is heavily\npolarized, and these concepts can have very di \ufb00erent or even opposite meanings to\nRepublicans and Democrats (Norris 2017, 27 \u201341). This makes it unfeasible to regard\nelectoral manipulation as a social fact , whose existence derives from human\nagreement and relies on human institutions (Ruggie 1998, 856; Searle 1995, 2), as has\nbeen done in the past for example by Norris (2014). In the present-day United States,\nthe concept of electoral manipulation lacks a highly standardized meaning that\neveryone with a shared cultural background can agree upon and e \ufb00ortlessly deci-\npher, making it a research topic requiring a qualitative approach (Schreier 2012,chapter 1).\nIn qualitative content analysis, a coding frame is created to focus the analysis on\nselected aspects of the object of the study (Schreier 2012, chapter 1). In this study, the\ncoding frame was built deductively based on the electoral manipulation framework\nthat was discussed in an earlier section of this article (for the full coding frame and\nthe de \ufb01nitions of the codes, see Appendix 1 and 2). Actions described in the research\nmaterial were \ufb01rst coded as either electoral manipulation or anything other than\nelectoral manipulation, and the actions coded as the latter were discarded. There-\nafter, the remaining actions were coded as having been undertaken by one or several\nRepublicans or by someone else, and the actions undertaken by someone else were\ndiscarded. Subsequently, the remaining actions were coded as having taken placeafter January 6, 2021, or earlier, and again, the actions coded as the latter were\ndiscarded. Finally, the remaining actions were coded as breaking democratic norms,\ndisinformation, gerrymandering, voter suppression, hacking and leaking, collusion\nwith one or more foreign states, intraparty pressure, intimidation and violence,\ncorrupting state and government institutions, or other. For example, information\nunearthed by the House Select Committee investigating the attack on the Capitol\nprompted numerous news articles describing actions that were coded as electoral\nmanipulation, as having been undertaken by a Republican, and \ufb01nally, as having\ntaken place before January 6, 2021, and hence discarded after the third step. In acontrasting example, an explicitly violent campaign ad targeting political opponents\nby a Republican candidate for o \ufb03ce in the 2022 midterm elections was coded as550\nM. Lind\u00e9n\nelectoral manipulation, as having been undertaken by a Republican, as having taken\nplace after January 6, 2021, and \ufb01nally, as belonging to the category of intimidation\nand violence.\nTo evaluate the reliability of the study, the consistency of the coding process was\ncontrolled for by recoding a randomly selected selection of the research data a year\nafter the original coding had been completed (see Schreier 2012, chapters 2 and 9, for\ndiscussion on assessing reliability in qualitative content analysis). Five percent of the\nWashington Post articles (277 articles in total) and samples of the supplementary data\nwere recoded, and the results were compared with the original coding. The recodedmaterials were chosen using a random number generator. With regard to actions\nthat were coded as being electoral manipulation undertaken by Republicans during\nthe time period of interest, the recoding matched the original 100 percent. However,\nthere were inconsistencies in how many Washington Post articles were chosen for\ncloser analysis in the \ufb01rst stage of coding. This is natural, as the researcher \u2019s\nfamiliarity with the material had increased since conducting the original coding,\nmaking it easier to recognize the relevant articles. Most importantly, the recoding did\nnot bring to light any relevant new information to indicate that something was\nmissing from the results of the case study.\nTo evaluate the validity of the coding frame utilized in the study, the residual\ncategory \u2018other \u2019was scrutinized. No acts of electoral manipulation described in the\nresearch data had been coded as other, which indicates that the coding frame has\nhigh face validity, meaning that the codes that had been chosen provide an\ncomprehensive and accurate description of the object of the study (see Schreier 2012,\nchapter 9). In addition, the validity of the coding frame was analyzed with regard to\nthe extent that the categories adequately capture the concepts in the theoretical\nframework the coding frame was based on. This form of validity, known as content\nvalidity (Schreier 2012, chapter 9), was also high, because the categories and their\ndescriptions were identical to those in the framework.\nQualitative content analysis often includes a quantitative element based on\ncounting the frequency at which each category or subcategory was coded (Schreier\n2012, chapter 11). However, in the case study presented in this article, such calcula-\ntions risk being misleading due to the nature of the research material in relation to\nthe research questions. Counting acts of electoral manipulation that are mentioned\nin news articles or reports by non-governmental organizations uncovers informa-\ntion about the portrayal of electoral manipulation in these publications, which is\nin\ufb02uenced by numerous factors such as priorities and resources. As the research\nquestions of this study, in contrast, concern actual acts of electoral manipulation\ninstead of their portrayal, counting relevant frequencies would require creating acomprehensive database containing all acts of electoral manipulation undertaken\nduring the chosen time period. Constructing such a database would allow forRepublican Electoral Manipulation 551\ndrawing meaningful quantitative comparisons, such as to determine di \ufb00erences in\nthe frequency of di \ufb00erent types of manipulative acts, or the frequency of manipu-\nlative acts between di \ufb00erent time periods or between political parties. Lamentably,\nhowever, creating such a database is impossible due to the inherent secrecy of electoral\nmanipulation (Lehoucq 2003, 233 \u201334) and the immense amount of resources it would\nrequire because of the number of relevant actors and their potentially relevant actions.\nFocusing on one type of manipulation such as gerrymandering might allow for\ncreating quite a comprehensive database, but as the focus of this study is on the\ninterplay between manipulation tactics and the whole their use creates, such anapproach is not supported by the research questions.\n3 Active Electoral Manipulation on Almost all\nFronts\nThe results in the case study show that in 2021 and 2022, prominent members of the\nRepublican Party used almost all of Trump \u2019s electoral manipulation tactics. There\nwas evidence of use of all the tactics other than hacking and leaking or attempted\ncollusion. Like in 2020, some of the tactics were used to facilitate the use of others,\nand some were used to amplify the impact of other tactics or to improve the likeli-\nhood of success of other tactics. Examples of the use of each tactic and their interplayare presented below. Unless otherwise speci \ufb01ed, the newspaper material collected\nfrom the Washington Post and the Wall Street Journal is the source of the infor-\nmation. For the purposes of readability, articles from the two main newspaper\nsources are not quoted individually, as this would dramatically increase the number\nof quotations. With the exception of voter suppression, there were no controversies\nbetween the two newspapers in how each manipulation tactic was discussed. The\ncontroversy regarding voter suppression is discussed in more detail later in this\narticle.\nBreaking democratic norms manifested itself in Republican candidates \u2019unwill-\ningness to commit to accepting their potential loss ahead of the 2022 midterms. Even\nwhen directly confronted by journalists, many prominent candidates declined topromise to accept the election results. This lack of commitment both relied upon and\nsupported disinformation regarding electoral integrity. After the elections, however,\nmost of the losing candidates conceded or at least refrained from spreading disin-\nformation regarding their loss. On the campaign trail, explicitly promised to try to\nchange the outcome the 2024 elections if a Democrat won the presidential contest.\nSeveral candidates made campaign promises to give state legislatures control of\ncertifying election results (Kamarck and Eisen 2022). Such transfer of control to the552\nM. Lind\u00e9n\nhands of the legislature could potentially lead to the legislature refusing to certify\nvalid results for political reasons, which would be an electoral manipulation act of\ncorrupting state and government institutions. Many promised to limit absentee or\nearly voting, often justifying their proposals with disinformation concerning elec-\ntoral integrity (Kamarck and Eisen 2022), all the while making said disinformation\nseem more credible.\nIn Congress, Republicans repeatedly showed silent acceptance of political\nextremism and undemocratic behavior by prominent members of their party. For\nexample, when the Democratic majority removed congresswoman Marjorie TaylorGreene from all committees and censured congressman Paul Gozar for encouraging\npolitical violence, few Republicans voted in favor of the measures. Most Republicans\nwere silent even when Trump suggested terminating the Constitution. These breaches\nof democratic norms laid the foundation for the use of other electoral manipulation\ntactics such as intimidation and violence.\nWhile campaigning for the 2022 midterms, several Republican candidates\nattempted to avoid critical questions and scrutiny by only speaking with Republican-\nfriendly media and skipping televised debates. In preparation for the 2024 presi-\ndential election, the Republican National Committee unanimously decided to pull outof the Commission on Presidential Debates, the organization that has arranged\ntelevised general election debates between presidential candidates for more than\nthree decades. This avoidance of scrutiny lends credence to disinformation. In\naddition, it is in itself a form of electoral manipulation, as liberal democracy relies on\nvoters \u2019ability to receive adequate information to guide their choices. As Birch (2011,\n22, italics added) notes, for this to happen, the \u201c(c)ontestants must have an equal\nopportunity to convey relevant information to the electorate, and they must take\nadvantage of this opportunity \u201d.\nDisinformation about the 2020 elections was embraced by numerous Republicans\nand used to lend support to many other manipulative actions. In January 2021, as\nCongress reconvened at the Capitol immediately after the violent attack on the pre-mises, eight Republican senators and 139 Republican House members voted in support\nof groundless objections to the 2020 election results. Since then, numerous national and\nstate lawmakers have been vocal supporters of Trump \u2019s unfounded fraud claims,\nand many more have been careful not to denounce them. In 2021, there were almost\nsix hundred election deniers in state legislatures (the term election denier is used in\nthis article as a shorthand for someone who denies or questions the legitimacy of the\n2020 election results). The Texas Republican party passed a resolution that rejects the\noutcome of the 2020 presidential election and refers to Joe Biden as an illegitimate\npresident.\nElection denialism continued throughout 2021 and 2022. In the California gu-\nbernatorial recall election of 2021, Republican challenger Larry Elder declined toRepublican Electoral Manipulation 553\ncommit to accepting the results, and a website a \ufb03liated with his campaign made\noutright claims of fraud before votes had been cast. Trump participated in spreading\nthe baseless claims. He also portrayed the Virginia gubernatorial election of 2021 as\nfraudulent before election day. In the 2022 midterms, hundreds of Republican\nprimary candidates were election deniers. Some of them lost their primaries and\nwent on to claim that their loss was due to fraud (Democracy Docket 2022). Many\nothers were victorious in the primaries, and as a result, out of the total of 552\nRepublicans running for House, Senate, Governor, Secretary of State or Attorney\nGeneral, 199 fully denied the legitimacy of the 2020 election and an additional 61raised questions about the 2020 results (FiveThirtyEight 2022). Some of them made\nunfounded claims of electoral fraud a central part of their campaign. A total of 178\nelection deniers were elected (Blanco, Wolfe, and Gardner 2022).\nGerrymandering has a long-lasting impact because electoral districts are\ngenerally drawn only once per decade. The state legislatures whose actions are\nanalyzed in this study had been elected using electoral maps from early 2010s, and\nmany of them were in Republican control because of gerrymandering (Grose et al.\n2019, 2 \u20133). In the time period covered by this study, electoral districts were redrawn,\nwhich provided both parties new opportunities for gerrymandering. Republicans hadcontrol over the redistricting of 187 congressional districts, while Democrats only\ncontrolled the redistricting of 75 districts. Both parties seized the gerrymandering\nopportunities they had, which signi \ufb01cantly reduced the number of competitive\ndistricts for the House of Representatives (Li and Leaverton 2022). Lack of competi-\ntiveness deprives the voters the opportunity to hold candidates or elected o \ufb03cials\naccountable for breaches of democratic norms, disinformation, and other electoral\nmanipulation acts. In the 2022 midterms, for example, election deniers were suc-\ncessful in many uncompetitive races, while in competitive contests, voters rejected\nelection denier candidates decisively.\nWith regards to future presidential elections, one potentially consequential\nstate-level gerrymander undertaken in the early 2020s was that of Georgia, whereboth state legislative maps gave the Republican party a signi \ufb01cant advantage, and the\nparty won control of both chambers of the state legislature (Ballotpedia n.d. a;\nBallotpedia n.d. b; Princeton Gerrymandering Project n.d.). Another one was that of\nWisconsin, where heavily gerrymandered state legislative maps drawn by the\nRepublican controlled state legislature were eventually adopted after a lengthy legal\nbattle (Marley 2022). Republicans retained control of both chambers of the Wisconsin\nstate legislature (Ballotpedia n.d. c; Ballotpedia n.d. d). Republican control of the state\nlegislatures of these two states may prove signi \ufb01cant, if there is an attempt to\noverturn key swing state election results resembling Trump \u2019s 2020 attempt, because\nboth Georgia and Wisconsin are considered key swing states in the 2024 presidential\nelection (Brownstein 2022; Dorman 2022; Mathesian 2022). As Georgia and Wisconsin554\nM. Lind\u00e9n\nmay retain their swing state status in the future, these gerrymanders have potential\nimplications also for the 2028 presidential election.\nVoter suppression was a controversial topic in the two newspapers examined for\nthis case study. The Washington Post often raised alarm over new voting laws\nwhereas the Wall Street Journal mostly defended them and objected to the use of the\nterm voter suppression. From the data analyzed in this study, it is nevertheless\nevident that Republican state legislatures introduced an exceptional number of new\nlaws in 2021 and 2022 that make voting more di \ufb03cult. Furthermore, a large pro-\nportion of the new laws passed. The new laws restrict voting in many ways, forexample by making it more burdensome to vote by mail, limiting Election Day\nregistration, and making it more di \ufb03cult to vote without a traditional address\n(Brennan Center for Justice 2022b, 2022c). An explicit desire to suppress the Black\nvote was expressed in 2022 by Texas Republicans in their state party convention,\nwhere delegates suggested repealing the Voting Rights Act. In an attempt to counter\nthe actions of the state legislatures, the Justice Department sued Georgia, Texas, and\nArizona over their new voting laws. In the Texas case, a U.S. district court ruled that\nportions of a new voting law violated the Civil Rights Act (United States Department\nof Justice 2023a). In Arizona, a U.S. District court ruled against some of the provisionsof the new law, \ufb01nding them to be in violation of federal laws (United States\nDepartment of Justice 2024). At the time of writing, the Georgia case was still ongoing.\nIntraparty pressure within the Republican party assumed multiple forms in 2021\nand 2022. One prominent example was the decision by the Republican National\nConvention to censure representatives Liz Cheney and Adam Kinzinger for their role\nin the House Select Committee to Investigate the January 6th Attack on the\nUnited States Capitol. The 10 House Republicans who voted for Trump \u2019ss e c o n d\nimpeachment were all subject to retaliation by their party, such as censure, resignation\nsuggestions, successful primary challenges and, in the case of Cheney, removal from a\nleadership position. Eight of them left Congress at the end of 2022. The same dynamic\nwas also observed on state and local level, where o \ufb03cials faced censure, threats, and\nousting attempts for having accepted the results of the 2020 election.\nTrump himself continued pressuring his fellow partisans. According to\nWisconsin State Assembly Speaker Robin Vos, a Republican, Trump kept trying to\noverturn the 2020 election all the way up to the summer of 2022 and pressured Vos to\nhelp him. There is also evidence to suggest that he pressured Republican candidates\nin the 2022 midterms to spread disinformation about the 2020 elections (Select\nCommittee 2022, 13 \u201314). When Republicans did not yield under pressure, Trump\nendorsed their opponents in the primaries and lambasted them in public.\nIntimidation and violence were vividly present during the time period in focus in\nthis study and shortly thereafter. In December 2022 and early January 2023, the\nhomes of four Democratic local o \ufb03cials were shot at, and a sleeping ten-year-old wasRepublican Electoral Manipulation 555\nnearly hit. A defeated Republican candidate for state legislature was later charged\nwith having orchestrated the violence and participated in the last shooting\n(United States Department of Justice 2023b). It appeared that disinformation had\nprompted the violence. The alleged culprit, Solomon Pe\u00f1a, had lost his 2022 bid for\nNew Mexico state House by an overwhelming margin in a solidly Democratic district\nbut refused to concede and kept trying to persuade people that the election had been\nrigged, a baseless claim he appears to have believed in. According to Pe\u00f1a \u2019s social\nmedia posts, he had attended the January 6th rally that turned into an attack on the\nCapitol (Gardner and Rosenzweig-Zi \ufb002023a; Romero and Feuer 2023). Republican\nleaders condemned the violence but were mostly unwilling to blame election deni-\nalism and disinformation for Pe\u00f1a \u2019s actions (Gardner and Rosenzweig-Zi \ufb002023b).\nIn the fall of 2021, Republican congressman Paul Gozar used his o \ufb03cial\ncongressional Twitter account to publish an anime video of himself graphically\nmurdering a Democratic congresswoman. Republican leadership did not take a clear\nstand to condemn the action, and only two House Republicans voted in favor of\ncensoring Gozar. There were also several other instances where Republican politi-\ncians made comments that seemed to support or encourage political violence or\nnormalize it through humor. Violent rhetoric was also part of some Republican 2022midterm campaigns.\nIn addition to the violent actions and words, the Republican Party \u2019s attitude\ntowards the violent attack on the Capitol on January 6th contributed to an atmo-\nsphere permissive of political violence. When Republican National Convention\ncensured Cheney and Kinzinger, the formal censure resolution called the Capitol\nattackers \u201cordinary citizens engaged in legitimate political discourse. \u201dThere were\nalso other instances when Republicans downplayed and normalized the Capitol\nattack instead of condemning the violence.\nThe political culture permissive of violence, combined with disinformation\nabout the elections, has created dangerous situations for election workers. Trump\nloyalists have threatened election workers and their families with hanging, \ufb01ring\nsquads, torture, and bomb blasts (So 2021). Ahead of the 2022 midterms, both the FBI\nand the Department of Homeland Security expressed concern about threats to\nelection workers (FBI 2022; United States Department of Homeland Security 2022).\nOne in six local election workers have experienced threats, and over half of them\nhave been threatened in person (Brennan Center for Justice 2022a, 6).\nNot all threats rely on prompting fear of physical violence. Because of new laws\npassed by Republican legislatures, there is a threat of harsh criminal and civil\npenalties hanging over election workers in many states. Numerous new laws make it\neasier to threaten election o \ufb03cials with penalties for innocent mistakes or sincere\nattempts to solve unexpected situations (States United Democracy Center, Protect\nDemocracy, and Law Forward 2022, 6). Intimidating election workers serves a556\nM. Lind\u00e9n\npurpose: to replace democracy-upholding election workers with partisan-minded\nindividuals willing to participate in electoral manipulation (States United Democracy\nCenter, Protect Democracy, and Law Forward 2021, 5 \u20136). The strategy seems to be\nworking: three in 10 local election workers know at least one local election worker or\no\ufb03cial, who has left their job at least in part because of fear for their safety, increased\nthreats, or intimidation (Brennan Center for Justice 2022a, 19).\nDuring the 2022 midterms, some voters were also subject to intimidation. Trump\nand his allies had encouraged supporters to monitor ballot drop boxes, and in\nArizona this resulted in some private citizens surveilling drop box locations intactical gear and body armor, photographing voters and their license plates and\naccusing them of voter fraud. In Florida, Governor Ron DeSantis formed an election\npolice force that acts under his authority and has unprecedented investigative\npower. In August 2022, before the midterms, he held a press conference announcing\nthe arrest of 20 felons accused of voting illegally. Most of the people arrested were\nBlack, and there is substantial evidence to suggest all of them believed they had the\nright to vote and therefore did not commit a crime when voting. The arrests seem\npoised to intimidate individuals unsure of their eligibility to vote and to discourage\nthem from voting.\nCorrupting state and government institutions is where the biggest dangers to\nAmerican democracy most likely lie. In 2021 and 2022, state legislatures proposed and\nenacted a substantial number of bills that can have a corrosive e \ufb00ect. State legisla-\ntures seized power over election responsibilities and attempted to micromanage\nelection minutiae, creating unworkable burdens in election administration. In some\nstates, they even considered bills that would give the legislature the possibility to\nreject the choice of the voters, although none of those were passed. According to a\ngroup of non-governmental organizations focusing on threats to democracy, the new\nmeasures \u201cincrease the risk of election subversion \u2013that is, the risk that an election \u2019s\ndeclared outcome does not re \ufb02ect the choice of the voters \u201d(States United Democracy\nCenter, Protect Democracy, and Law Forward 2022, 4).\nIn several states, Republican o \ufb03cials proposed and occasionally authorized\nunprofessional, partisan audits of the 2020 elections. In Arizona, the Republican-\ncontrolled state senate commissioned a company called Cyber Ninjas to audit ballots\nand voting machines used in Maricopa County. The audit lacked objectivity,\ncompetence and transparency and resulted in security failures. It compromised the\nsecurity of all Maricopa County voting machines, which the county then had to\nreplace, costing taxpayers over two million dollars. Similar scenarios played out in\nother states (Bydlak et al. 2021). None of the audits or reviews unearthed noteworthy\nirregularities, but they lent disinformation undue credibility and further erodedvoters \u2019trust in American elections, which can make manipulating future elections\nseem more acceptable and even prompt political violence. The audits may also haveRepublican Electoral Manipulation 557\ninspired grassroots activists, such as the group that tried to get a small county court to\ndeclare sealed 2020 paper ballots public records for citizens to perform hand\nrecounts. Had the court done so, the decision would have set a precedent applicable\nto all Georgia counties regarding both past and future elections.\nThe Republican Party also inserted election deniers and other potential electoral\nmanipulators into all levels of electoral administration. There was a concerted e \ufb00ort\nto recruit hyper-partisan election sceptics and conspiracy theorists to precinct-level\nelectoral positions such as election judge and inspector. The same applies to at least\nsome county level canvassing boards (States United Democracy Center, ProtectDemocracy, and Law Forward 2021, 5). On the state level, more than half of Repub-\nlican gubernatorial candidates, around one in three of Republican Attorney General\ncandidates and almost half of Republican Secretary of State candidates in the 2022\nmidterms were election deniers (States United Democracy Center 2022). Had the\nelection deniers running for statewide o \ufb03ce been successful in the 2022 midterms,\nthe table would have been set for electoral subversion. Baseless fraud claims could\nhave spread from one election denier to another from precincts to counties and all\nthe way up to the highest election o \ufb03cials in the state.\nThe loss of election denier candidates in key statewide races lessened the risk of\nsuccessful electoral subversion in 2024, but election deniers in precinct and county\nlevel o \ufb03ces can nevertheless cause signi \ufb01cant harm. After the 2020 elections, lawyers\nworking to overturn Trump \u2019s defeat sent computer experts to copy election data in\nseveral states, and there is evidence to suggest that local election o \ufb03cials helped\nthem access the data. The data they obtained was later shared with election deniers,\nconspiracy theorists and right-wing commentators. Security experts have voiced\nconcern that the election data could be exploited by hackers or other people seeking\nto manipulate future elections.\nProminent Republicans, election denier activists, the Republican National\nConvention, and state level Republican parties actively recruited and trained poll\nwatchers with false 2020 fraud claims in mind (Parker, So, and Warburton 2022;Marley, Helderman, and Hamburger 2022), thus politicizing and possibly even\nweaponizing an institution meant to secure electoral integrity. However, attempts to\nalter the 2022 election outcome with baseless post-electoral lawsuits were rare. A\nnotable exception was a suit \ufb01led by the failed Arizona gubernatorial candidate Kari\nLake, in which she claimed without evidence that illegal votes or voting machines\nhad altered the outcome of her race. The claims were dismissed by Arizona Supreme\nCourt (Barchenger 2023). In a similar case, Arizona Secretary of State candidate Mark\nFinchem \ufb01led a lawsuit after his electoral loss, targeting Katie Hobbs, who had served\nas Arizona secretary of the state at the time of the election. Finchem accused Hobbs ofmisconduct but was later sanctioned by a judge who labelled Finchem \u2019s suit\n\u201cgroundless and not brought in good faith \u201d(Cooper 2023). In addition, the process of558\nM. Lind\u00e9n\ncertifying election results was politicized in some counties in Arizona, New Mexico,\nand Pennsylvania, when local election o \ufb03cials attempted to refuse to certify the\nresults, making unfounded claims of fraud and irregularities. All the results were\neventually certi \ufb01ed, but in some cases that only happened after an intervention by\nthe courts.\nPerhaps the most serious attempt to weaken checks and balances was that of\nNorth Carolina state legislative leaders, who \ufb01led a gerrymandering-related lawsuit\nthat could have led to the United States Supreme Court embracing the so-called\nIndependent State Legislature Theory. The theory argues that state legislatures havethe sole power to decide issues regarding federal elections irrespective of the state\nconstitution or decisions by the state supreme court, and it has implications that go\nfar beyond gerrymandering. Conservative former US Court of Appeals judge\nJ. Michael Luttig (2022) saw the lawsuit as a direct continuation of Trump \u2019s 2020\nelectoral manipulation attempt and expressed concern that were the Supreme Court\nto adopt the theory, the Republican party would be willing and able to overturn a\npotential democratic presidential victory in the 2024 elections. However, the\nSupreme Court ruled against the theory (Barnes 2023).\n4 Discussion: Implications for the 2024 Elections\nThis article has shown that numerous prominent members of the Republican partyare following in Trump \u2019s footsteps when it comes to electoral manipulation: not only\nare they resorting to most of Trump \u2019s tactics, but they are also combining the tactics\nin similar ways, for example by using disinformation to justify attacks on democratic\ninstitutions. The situation does not bode well for the 2024 presidential election. Many\nacts of electoral manipulation discussed above have potential to impact the integrity\nof the 2024 election, and it is possible that some of them were undertaken speci \ufb01cally\nto prepare for another attempt to overturn a presidential election were the Repub-\nlican candidate to lose.\nEven though Trump \u2019s attempt to overturn the 2020 election failed, that is not to\nsay a similar but better prepared attempt could not succeed in the future. The actions\nthat were taken to resist Trump in 2020 were, while successful, mostly focused on the\nimmediate situation and did little to prevent a similar attack on electoral integrity in\nthe future (Tomini, Gibril and Bochev 2023, 124 \u20135). Since then, some important steps\nto counter such a threat have been taken, such as passing the Electoral Count Reform\nand Presidential Transition Improvement Act of 2022. In the 2022 midterms, votersalso contributed to diminishing the risk of electoral subversion in 2024 by rejecting\nelection denier candidates who were running for state level positions such asRepublican Electoral Manipulation 559\nSecretary of State that would have put them in charge of administering the 2024\nelection. Nevertheless, the danger persists.\nBased on the case study presented in this article, 10 threats to the integrity of the\n2024 elections can be highlighted: 1) Electoral disinformation has taken a \ufb01rm hold of\nAmerican society and many voters have lost faith in the integrity of American\nelections. 2) The fate of televised debates between presidential candidates is unclear,\nwhich threatens the voters \u2019ability to make informed decisions. 3) Restrictive voting\nlaws may have a negative impact on non-white turnout, and intimidation can also\ndissuade minority voters from casting a vote. 4) Many democracy-upholding electionworkers have left their posts. 5) Several states have made it easier to intimidate those\nelection workers still trying to defend democracy. 6) The Republican party has\ninserted election deniers and other potential electoral manipulators into all levels of\nelectoral administration. 7) New laws in place in many states move power away from\nelection o \ufb03cials into the hands of state legislatures. 8) Gerrymandering has given\nRepublicans control of the state legislature in Georgia and Wisconsin, two likely 2024\nswing states, potentially making it easier to overturn election results in those states.\n9) Intraparty pressure has prompted many moderate Republicans to retire or caused\nthem to lose primary challenges, making Congress and especially the House tilt moretowards election denialism. 10) Violent rhetoric and acceptance of political violence\nare on the rise.\nIdentifying acts of electoral manipulation and understanding their interplay is\nessential for recognizing threats to the integrity of future elections. This, in turn, can\nhelp build democratic resilience and safeguard American democracy.\nAcknowledgements: This research was supported by Jenny and Antti Wihuri\nFoundation, whom I sincerely thank for their generosity and their faith in my work. I\nwould also like to extend my deepest gratitude to Tapio Raunio and Anna Kronlund\nfor their invaluable help in revising the manuscript.\nResearch funding: This work was supported by the Jenny and Antti Wihuri Foun-\ndation (00230217).\nAppendix 1\nCoding frame utilized in the case study.\n\u2013Other than electoral manipulation (discarded)\n\u2013Electoral manipulation\n\u2013Non-Republican (discarded)\n\u2013Republican\n\u2013Actions on or before Jan 6 (discarded)560 M. Lind\u00e9n\n\u2013Actions after Jan 6\n\u2013Breaking democratic norms\n\u2013Disinformation\n\u2013Gerrymandering\n\u2013Voter suppression\n\u2013Hacking and leaking\n\u2013Collusion with one or more foreign states\n\u2013Intraparty pressure\n\u2013Intimidation and violence\n\u2013Corrupting state and government institutions\n\u2013Other\nAppendix 2\nCategory de \ufb01nitions for the coding frame utilized in the case study.\nOther than electoral manipulation: Everything that does not fall within the scope\nof the de \ufb01nition of electoral manipulation below.\nElectoral manipulation: Both legal and illegal actions that undermine electoral\nintegrity undertaken by a candidate or other prominent member of a political party\nbefore, during or after an election to manipulate the elections in their favor or in the\nfavor of their party. In this de \ufb01nition, electoral integrity refers to the key aspects of\nelectoral integrity as de \ufb01ned by James and Garnett (2023, 15 \u201319).\nNon-Republican: Actions undertaken by one or several people none of whom is a\nRepublican as de \ufb01ned below.\nRepublican: Actions undertaken by one or several members of the Republican\nparty or one or several citizens who publicly supports Republican \ufb01gures such as\nformer president Donald Trump. When an action is undertaken by a group of people,\nit is classi \ufb01ed as Republican even if some members of the group are not members of\nthe Republican party or Republican supporters.\nActions on or before Jan 6: Actions that were taken on or before January 6, 2021.\nActions after Jan 6: Actions that were taken after January 6, 2021.\nBreaking democratic norms: A breach of societal soft norms that contributes to\nthe groundwork for the use of more serious electoral manipulation tactics.\nDisinformation: False or misleading information spread deliberately to deceive\npeople.\nGerrymandering: Drawing voting district maps unfairly to gain partisan\nadvantage or to suppress the votes of some subgroup of voters.\nVoter suppression: A legal or illegal measure whose purpose or practical e \ufb00ect is\nto reduce voting by members of a targeted subgroup of voters.Republican Electoral Manipulation 561\nHacking and leaking: Stealing potentially damaging information about a political\nopponent and publicizing it anonymously via a third party such as a newspaper or a\nwebsite.\nAttempted collusion: An attempt to make a secret pact with a foreign entity to\nmanipulate an election.\nIntraparty pressure: Pressuring members of one \u2019s own political party to break\ndemocratic norms or the law to help manipulate an election.\nIntimidation and violence: The action of frightening or threatening someone to\npersuade them to do something, and the use of physical force to injure, abuse,damage, or destroy.\nCorrupting state or government institutions: Undermining, altering, or abusing\npolitical or judicial institutions for political gain.\nOther: Actions that do not belong in any other subcategory on the same level of\nthe coding frame.\nReferences\nAaltola, Mika. 2021. Democratic Vulnerability And Autocratic Meddling: The \u201cThucydidean Brink \u201din Regressive\nGeopolitical Competition . London: Palgrave Macmillan.\nAllSides. 2021. \u201cThe Washington Post. \u201dLast modi \ufb01ed July 2021. https://www.allsides.com/news-source/\nwashington-post-media-bias.\nAllSides. 2022. Wall Street Journal (Opinion) . Last modi \ufb01ed April 2022. https://www.allsides.com/news-\nsource/wall-street-journal-opinion.\nAllSides. 2023. Wall Street Journal (News) . Last modi \ufb01ed September 2023. https://www.allsides.com/news-\nsource/wall-street-journal-media-bias.\nBallotpedia. n.d.a. \u201cGeorgia House of Representatives Elections, 2022. \u201dhttps://ballotpedia.org/Georgia_\nHouse_of_Representatives_elections,_2022 (Accessed October 13, 2023).\nBallotpedia. n.d. b. \u201cGeorgia State Senate Elections, 2022. \u201dhttps://ballotpedia.org/Georgia_House_of_\nRepresentatives_elections,_2022 (Accessed October 13, 2023).\nBallotpedia. n.d. c. \u201cWisconsin State Assembly Elections, 2022. \u201dhttps://ballotpedia.org/Wisconsin_State_\nAssembly_elections,_2022 (Accessed October 13, 2023).\nBallotpedia. n.d. d. \u201cWisconsin State Senate Elections, 2022. \u201dhttps://ballotpedia.org/Wisconsin_State_\nSenate_elections,_2022 (Accessed October 13, 2023).\nBarchenger, Stacey. 2023. \u201cArizona Supreme Court Rejects Most of Kari Lake \u2019s Election Challenge. \u201dArizona\nRepublic . https://eu.azcentral.com/story/news/politics/elections/2023/03/22/kari-lake-governor-\nelection-challenge-mostly-rejected-by-arizona-supreme-court/70034889007/ (Accessed March 22,2023).\nBarnes, Robert. 2023. \u201cSupreme Court Rejects Theory that Would Have Meant Radical Changes to Election\nRules. \u201dWashington Post . https://www.washingtonpost.com/politics/2023/06/27/moore-v-harper-\nsupreme-court-rejects/ (Accessed June 27, 2023).\nBermeo, Nancy. 2016. \u201cOn Democratic Backsliding. \u201dJournal of Democracy 27 (1): 5 \u201319.\nBirch, Sarah. 2011. Electoral Malpractice . Oxford: Oxford University Press.562 M. Lind\u00e9n\nBlanco, Adrian, Daniel Wolfe, and Amy Gardner. 2022. \u201cTracking Which 2020 Election Deniers Are Winning,\nLosing in the Midterms. \u201dWashington Post . https://www.washingtonpost.com/politics/interactive/\n2022/election-deniers-midterms/ (Accessed December 13, 2022).\nBrennan Center for Justice. 2022a. \u201cLocal Election O \ufb03cials Survey March 2022. \u201dBrennan Center for Justice .\nhttps://www.brennancenter.org/our-work/research-reports/local-election-o \ufb03cials-survey-march-\n2022 (Accessed March 10, 2022).\nBrennan Center for Justice. 2022b. \u201cVoting Laws Roundup: October 2022. \u201dBrennan Center for Justice .\nhttps://www.brennancenter.org/our-work/research-reports/voting-laws-roundup-october-2022(Accessed October 6, 2022).\nBrennan Center for Justice. 2022c. \u201cVoting Laws Roundup: December 2022. \u201dBrennan Center for Justice .\nUpdated February 1, 2023 https://www.brennancenter.org/our-work/research-reports/voting-laws-roundup-december-2022 (Accessed December 19, 2022).\nBritannica. n.d. Washington Post . https://www.britannica.com/topic/The-Washington-Post (Accessed April\n19, 2023).\nBrownstein, Ronald. 2022. \u201cWhy Fewer States Than Ever Could Pick the Next President. \u201dCNN. https://\nedition.cnn.com/2022/11/22/politics/2022-preview-2024-presidential-election/index.html (Accessed\nNovember 22, 2022).\nBydlak, Jonathan, Sara Chimene-Weiss, Jared Davidson, Matthew Germer, Elizabeth Howard, and\nGowri Ramachandran. 2021. \u201cPartisan Election Review E \ufb00orts in Five States. \u201dBrennan Center for\nJustice . https://www.brennancenter.org/our-work/research-reports/partisan-election-review-\ne\ufb00orts-\ufb01ve-states (Accessed July 8, 2021).\nCalingaert, Daniel. 2006. \u201cElection Rigging and How to Fight it. \u201dJournal of Democracy 17 (3): 138 \u201351.\nCheeseman, Nic, and Brian Klaas. 2018. How to Rig an Election . New Haven: Yale University Press.\nChervinsky, Lindsay. 2021. \u201cThe History of Fake News from George Washington to Donald Trump. \u201d\nGoverning . https://www.governing.com/context/the-history-of-fake-news-from-george-\nwashington-to-donald-trump (Accessed December 8, 2021).\nCooper, Jonathan J. 2023. \u201cFinchem Sanctioned over \u2018Baseless \u2019Arizona Election Suit. \u201dAP. https://apnews.\ncom/article/ \ufb01nchem-lawsuit-sanctions-2022-election-arizona-\n7e7567bdbe90f4c4ab6d4567a128bd0f (Accessed March 07, 2023).\nDemocracy, Docket. 2022. \u201cThe Republicans Who Cried Fraud after Losing Their Primaries. \u201dDemocracy\nDocket . https://www.democracydocket.com/analysis/the-republicans-who-cried-fraud-after-losing-\ntheir-primaries/ (Accessed September 26, 2022).\nDorman, John L. 2022. \u201cSix Battleground States Will Hold the Key to the White House in 2024. \u201dBusiness\nInsider . https://www.businessinsider.com/battleground-states-2024-presidential-election-road-\nwhite-house-2022-12 (Accessed December 24, 2022).\nEpperly, Brad, Christopher Witko, Ryan Strickler, and Paul White. 2020. \u201cRule by Violence, Rule by Law:\nLynching, Jim Crow, and the Continuing Evolution of Voter Suppression in the U.S. \u201dPerspectives on\nPolitics 18 (3): 756 \u201369.\nFBI. 2022. \u201cFBI Cautions about Threats to Election Workers Ahead of the November 2022 Midterm Elections. \u201d\nFBI. https://www.fbi.gov/news/press-releases/press-releases/fbi-cautions-about-threats-to-election-\nworkers-ahead-of-the-november-2022-midterm-elections (Accessed October 12, 2022).\nFiveThirtyEight. 2022. \u201c60 Percent of Americans Will Have an Election Denier on the Ballot This Fall. \u201d\nFiveThirtyEight . https://projects. \ufb01vethirtyeight.com/republicans-trump-election-fraud/ (Accessed\nNovember 8, 2022).\nGardner, Amy, and Dan Rosenzweig-Zi \ufb00. 2023a. \u201cNew Details Emerge about Plot to Shoot at New Mexico\nDemocrats \u2019Homes. \u201dWashington Post . https://www.washingtonpost.com/politics/2023/01/17/\nsolomon-pea-shooting-new-mexico/ (Accessed January 17, 2023).Republican Electoral Manipulation 563\nGardner, Amy, and Dan Rosenzweig-Zi \ufb00. 2023b. \u201cEven after New Mexico Shootings, Little GOP Reckoning\nover Election Denialism. \u201dWashington Post . https://www.washingtonpost.com/politics/2023/01/23/\nsolomon-pena-new-mexico-election-denialism/ (Accessed January 23, 2023).\nGellman, Barton. 2021. \u201cTrump \u2019s Next Coup Has Already Begun. \u201dThe Atlantic . https://www.theatlantic.\ncom/magazine/archive/2022/01/january-6-insurrection-trump-coup-2024-election/620843/(Accessed December 06, 2021).\nGrose, Christian R., Jordan Carr Peterson, Matthew Nelson, and Sara Sadhwani. 2019. \u201cThe Worst Partisan\nGerrymanders in U.S. State Legislatures. \u201dUniversity of Southern California Schwarzenegger Institute for\nState and Global Policy . https://issuu.com/robquigley/docs/the_worst_gerrymanders_of_2018_us_\nstate_legislatur.\nJames, Toby, and Holly Ann Garnett. 2023. \u201cWhat Is Electoral Integrity? Reconceptualising Election\nQuality. \u201dInEuropean Consortium of Political Research General Conference ,4\u20138. Prague.\nKamarck, Elaine, and Norman Eisen. 2022. \u201cDemocracy on the Ballot \u2013What Do Election Deniers Want? \u201d\nBrookings . https://www.brookings.edu/articles/democracy-on-the-ballot-what-do-election-deniers-\nwant/ (Accessed October 20, 2022).\nLehoucq, Fabrice. 2003. \u201cElectoral Fraud: Causes, Types, and Consequences. \u201dAnnual Review of Political\nScience 6: 233 \u201356.\nLevitsky, Steven, and Daniel Ziblatt. 2021. \u201cThe Biggest Threat to Democracy Is the GOP Stealing the Next\nElection. \u201dThe Atlantic . https://www.theatlantic.com/ideas/archive/2021/07/democracy-could-die-\n2024/619390/ (Accessed July 9, 2021).\nLi, Michael, and Chris Leaverton. 2022. \u201cGerrymandering Competitive Districts to Near Extinction. \u201d\nBrennan Center for Justice . https://www.brennancenter.org/our-work/analysis-opinion/\ngerrymandering-competitive-districts-near-extinction (Accessed August 11, 2022).\nLind\u00e9n, Maria. 2024. \u201cTrump \u2019s Playbook of Electoral Manipulation: An Interplay of Manipulation Tactics in\na Longstanding Democracy. \u201dAmerican Studies in Scandinavia 56 (1): 27 \u201342.\nLuttig, J. Michael. 2022. \u201cOpinion: The Republican Blueprint to Steal the 2024 Election. \u201dCNN. https://\nedition.cnn.com/2022/04/27/opinions/gop-blueprint-to-steal-the-2024-election-luttig/index.html(Accessed April 27, 2022).\nMarley, Patrick. 2022. \u201cWisconsin Finally Has its New Election Maps. Here Is How We Got There and what\nthe End Result Means for Voters. \u201dMilwaukee Journal Sentinel . https://eu.jsonline.com/story/news/\npolitics/elections/2022/04/29/heres-how-wisconsins-new-election-maps- \ufb01nally-came-redistricting-\ngerrymandering-voters/7412010001/ (Accessed April 29, 2022).\nMarley, Patrick, Rosalind S. Helderman, and Tom Hamburger. 2022.\n\u201cPro-Trump Republicans Court\nElection Volunteers to \u2018Challenge Any Vote \u2019.\u201dWashington Post . https://www.washingtonpost.com/\npolitics/2022/10/25/pro-trump-republicans-court-election-volunteers-challenge-any-vote/\n(Accessed October 25, 2022).\nMathesian, Charley. 2022. \u201cWhat 2022 Tells Us about the 2024 Electoral Map. \u201dPol\u00edtico . https://www.\npolitico.com/newsletters/politico-nightly/2022/11/23/what-2022-tells-us-about-the-2024-electoral-\nmap-00070805 (Accessed November 23, 2022).\nMedia Bias/Fact Check. 2022a. Wall Street Journal \u2013Bias and Credibility . Last updated October 31, 2022.\nhttps://mediabiasfactcheck.com/wall-street-journal/.\nMedia Bias/Fact Check. 2022b. \u201cWashington Post. \u201dLast updated October 31, 2022 https://\nmediabiasfactcheck.com/washington-post/.\nMorgenbesser, Lee. 2020. \u201cThe Menu of Autocratic Innovation. \u201dDemocratization 27 (6): 1053 \u201372.\nNorris, Pippa. 2017. Why American Elections Are Flawed (And How to Fix Them) . Ithaca: Cornell University\nPress.\nNorris, Pippa. 2014. Why electoral Integrity Matters . Cambridge: Cambridge University Press.564 M. Lind\u00e9n\nParker, Ned, Linda So, and Moira Warburton. 2022. \u201cStop the Steal \u2019Supporters Train Thousands of U.S.\nPoll Observers. \u201dReuters . https://www.reuters.com/world/us/stop-steal-supporters-train-\nthousands-us-poll-observers-2022-10-13/ (Accessed October 13, 2022).\nPrinceton Gerrymandering Project. n.d. \u201cRedistricting Report Card. \u201dhttps://gerrymander.princeton.edu/\nredistricting-report-card/ (Accessed October 13, 2023).\nRomero, Simon, and Alan Feuer. 2023. \u201cHe Cheered Trump on Jan. 6. Now He \u2019s Accused of Targeting\nPolitical Rivals. \u201dNew York Times . https://www.nytimes.com/2023/01/17/us/solomon-pena-new-\nmexico-shootings.html (Accessed January 17, 2023).\nRuggie, John Gerard. 1998. \u201cWhat Makes the World Hang Together? Neo-Utilitarianism and the Social\nConstructivist Challenge. \u201dInternational Organization 52 (4): 855 \u201385.\nSchedler, Andreas. 2002. \u201cElections without Democracy: The Menu of Manipulation. \u201dJournal of Democracy\n13 (2): 36 \u201350.\nSchreier, Margrit. 2012. Qualitative Content Analysis in Practice , Online edition. London: Sage.\nSearle, John. 1995. The Construction of Social Reality . New York: Free Press.\nSelect Committee. 2022. \u201cInterview of: Hope Hicks. \u201dSelect Committee to Investigate the January 6th\nAttack on the United States Capitol. \u201dhttps://www.govinfo.gov/app/details/GPO-J6-TRANSCRIPT-\nCTRL0000923621/ (Accessed October 25, 2022).\nSo, Linda. 2021. \u201cTrump-Inspired Death Threats Are Terrorizing Election Workers. \u201dReuters . https://www.\nreuters.com/investigates/special-report/usa-trump-georgia-threats/ (Accessed June 11, 2021).\nStates United Democracy Center. 2022. \u201cReplacing the Refs. \u201dStates United Democracy Center . https://\nstatesuniteddemocracy.org/resources/replacingtherefs/ (Accessed September 13, 2022).\nStates United Democracy Center, Protect Democracy, and Law Forward. 2021. \u201cDemocracy Crisis in the\nMaking Report Update: 2021 Year-End Numbers. \u201dStates United Democracy Center . https://\nstatesuniteddemocracy.org/resources/decupdate/ (Accessed December 23, 2021).\nStates United Democracy Center, Protect Democracy, and Law Forward. 2022. \u201cA Democracy Crisis in the\nMaking: How State Legislatures Are Politicizing, Criminalizing, and Interfering with Election\nAdministration. 2022 Edition. \u201dStates United Democracy Center . May 2022 https://\nstatesuniteddemocracy.org/wp-content/uploads/2022/05/DCITM_2022-1.pdf.\nSvolik, Milan W. 2019. \u201cPolarization versus Democracy. \u201dJournal of Democracy 30 (3): 20 \u201332.\nTomini, Luca, Suzan Gibril, and Venelin Bochev. 2023. \u201cStanding up against Autocratization across Political\nRegimes: A Comparative Analysis of Resistance Actors and Strategies. \u201dDemocratization 30 (1):\n119\u201338. https://www.doi.org/10.1080/13510347.2022.2115480.\nUnited States Department of Justice. 2024. \u201cCourt Finds that Arizona Voter Registration Provisions Violate\nFederal Law. \u201dPublished March 1, 2024. https://www.justice.gov/opa/pr/court- \ufb01nds-arizona-voter-\nregistration-provisions-violate-federal-law.\nUnited States Department of Justice. 2023a. \u201cCourt Finds that Texas Law Requiring the Rejection of Mail\nBallots and Applications Violates the Civil Rights Act. \u201dPublished Aug 18, 2023 https://www.justice.\ngov/opa/pr/court- \ufb01nds-texas-law-requiring-rejection-mail-ballots-and-applications-violates-civil.\nUnited States Department of Justice. 2023b. \u201cFormer New Mexico House of Representatives Candidate\nCharged for Shooting Spree. \u201dPublished May 31, 2023 https://www.justice.gov/opa/pr/former-new-\nmexico-house-representatives-candidate-charged-shooting-spree.\nUnited States Department of Homeland Security. 2022. \u201cSummary of Terrorism Threat to the\nUnited States. \u201dPublished June 6, 2022. https://www.dhs.gov/ntas/advisory/national-terrorism-\nadvisory-system-bulletin-june-7-2022.Republican Electoral Manipulation 565", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Republican Electoral Manipulation After Jan 6", "author": ["M Lind\u00e9n"], "pub_year": "2025", "venue": "The Forum", "abstract": "This article shows that numerous prominent members of the Republican Party have resorted  to the same electoral manipulation tactics that former president Donald Trump utilized in"}, "filled": false, "gsrank": 808, "pub_url": "https://www.degruyterbrill.com/document/doi/10.1515/for-2025-2010/html", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:tfDmPo7hPL8J:scholar.google.com/&output=cite&scirp=807&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D800%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=tfDmPo7hPL8J&ei=mLWsaPaIErXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:tfDmPo7hPL8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.degruyterbrill.com/document/doi/10.1515/for-2025-2010/pdf"}}]