[{"title": "Hyperpartisanship in web searched articles", "year": "2019", "pdf_data": "Hyperpartisanship in Web Searched Articles\nAnamika Ashit Sen\nThesis submitted to the Faculty of the\nVirginia Polytechnic Institute and State University\nin partial ful\ufb01llment of the requirements for the degree of\nMaster of Science\nin\nComputer Engineering\nA. Lynn Abbott, Chair\nJiepu Jiang\nRyan Williams\nJune 17, 2019\nBlacksburg, Virginia\nKeywords: Hyperpartisanship, news, fake news, natural language processing,\npropaganda, misinformation\nCopyright 2019, Anamika Ashit Sen\nHyperpartisanship in Web Searched Articles\nAnamika Ashit Sen\n(ABSTRACT)\nNews consumption is primarily done through online news media outlets and social media.\nThere has been a recent rise in both fake news generation, and consumption. Fake news\nrefers to articles that deliberately contain false information to in\ufb02uence readers. Substan-\ntial dissemination of misinformation has been recognized to in\ufb02uence election results. This\nwork focuses on hyperpartisanship in web-searched articles which refers to web searched\narticles which have polarized views and which represent a sensationalized view of the con-\ntent. There are many such news websites which cater to propagating biased news for\npolitical and/or \ufb01nancial gain. This work uses Natural Language Processing (NLP) tech-\nniques on news articles to \ufb01nd out if a web-searched article can be termed as hyperpartisan\nor not. The methods were developed using a labeled dataset which was released as a part\nof the SemEval Task 4 - Hyperpartisan News Detection. The model was applied to queries\nrelated to U. S. midterm elections in 2018. We found that more than half the articles in\nweb search queries showed hyperpartisanship attributes.\nHyperpartisanship in Web Searched Articles\nAnamika Ashit Sen\n(GENERAL AUDIENCE ABSTRACT)\nOver the recent years, the World Wide Web (WWW) has become a very important part of\nsociety. It has overgrown as a powerful medium not only to communicate with known con-\ntacts but also to gather, understand and propagate ideas with the whole world. However,\nin recent times there has been an increasing generation and consumption of misinforma-\ntion and disinformation. These type of news, particularly fake and hyperpartisan news are\nparticularly curated so as to hide the actual facts, and to present a biased, made-up view\nof the issue at hand. This activity can be harmful to the society as greater the spread\nand/or consumption of such news would be, more would be the negative decisions made\nby the readers. Thus, it poses a bigger threat to society as it a\ufb00ects the actions of people\na\ufb00ected by the news. In this work, we look into a similar genre of misinformation that is\nhyperpartisan news. Hyperpartisan news follows a hyperpartisan orientation - the news\nexhibits biased opinions towards a entity (party, people, etc.) In this work, we explore\nto \ufb01nd how Natural Language Processing (NLP) methods could be used to automate the\n\ufb01nding of hyperpartisanship in web searched articles, focusing on extraction of the linguis-\ntic features. We extend our work to test our \ufb01ndings in the web-searched articles related\nto midterm elections 2018.\nDedication\nThis Thesis is dedicated to my Family: Parents - Mitali and Ashit Sen, and Sister -\nMalabika Sen.\niv\nAcknowledgments\nThere are a lot of people I would like to extend my heartfelt thanks to, here at Virginia\nT ech. Firstly , I would like to express my sincere gratitude to my supervisor and guide - Dr.\nJiepu Jiang for his tremendous help in this thesis - right from inception to its completion.\nHis ideas and guidance paved my path to partake in this exciting field of research. I would\nalso like to extend my thanks to both Dr. Lynn Abbott and Dr. Ryan Williams for agreeing\nto serve on my committee. I am thankful to Dr. Abbott for his continuous and helpful\nrevisions to this thesis.\nI would also like to thank all the people at NDSSL, whom I had a chance to work with or\nmerely interact. I did learn a lot working on exciting projects here. I thank them and the\nECE department for providing me the financial assistance to pursue my Masters at T ech.\nI would also like to thank all my friends here at Virginia T ech - Soham Zodpey , Mihir\nKulkarni, Subhashree Radhakrishnan and many others from F all 2017 and 2018 batch, who\nhave been a constant source of motivation, encouragement and fun. Last but not the least,\nthe beautiful town and people of Blacksburg which made me feel welcomed the whole 2 years\nof my stay here.\nLastly , I would like to dedicate this work to my family - Mitali Sen, Ashit Sen and Malabika\nSen for their immeasurable support, love and belief in me which has made it possible for me\nto achieve my goals.\nv\nContents\nList of Figures x\nList of Tables xii\n1 Introduction 1\n1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.3 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4 Outline of Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2 Review of Literature 5\n3 Dataset 10\n3.1 Current Datasets In Practice . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.1.1 Emergent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.1.2 LIAR Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.1.3 BuzzFeed News Dataset . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.1.4 Fake News Challenge Dataset (FNC-1) . . . . . . . . . . . . . . . . . 12\n3.1.5 Kaggle Fake News Dataset . . . . . . . . . . . . . . . . . . . . . . . 12\nv\n3.2 SemEval 2019 Task 4 - Hyperpartisan News Detection . . . . . . . . . . . . 13\n3.2.1 SemEval 2019 Task 4 Dataset . . . . . . . . . . . . . . . . . . . . . . 13\n3.2.2 Midterm Elections 2018 Dataset . . . . . . . . . . . . . . . . . . . . 14\n4 Methods and Results 17\n4.1 Preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.1.1 Tokenization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.1.2 Stop-words Removal . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.1.3 Normalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.2 Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.2.1 Logistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n4.2.2 Naive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n4.2.3 Support Vector Machine . . . . . . . . . . . . . . . . . . . . . . . . . 21\n4.2.4 Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.2.5 Random Forest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2.6 Gradient Boosting . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2.7 Stochastic Gradient Classi\ufb01er . . . . . . . . . . . . . . . . . . . . . . 24\n4.3 Feature Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.4 Headlines of articles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.4.1 Term Frequency-Inverse Document Frequency (TF-IDF) . . . . . . . 25\nvi\n4.4.2 Length of the headline . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n4.4.3 Ratio of capitalized and stop words to total words . . . . . . . . . . 32\n4.4.4 Using Content Words - Parts of Speech analysis . . . . . . . . . . . . 36\n4.5 Publishers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.6 Body of articles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.6.1 Type Token Ratio (TTR) . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.6.2 Readability scores . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.6.3 n-grams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.6.4 Parts Of Speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n5 Discussion 52\n6 Conclusions and Future Work 54\nBibliography 56\nAppendices 61\nAppendix A Timing and accuracy statistics for TF-IDF on headlines of\narticles 62\nA.1 Logistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nA.2 Naive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nA.2.1 Gaussian Naive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nvii\nA.2.2 Multinomial Naive Bayes . . . . . . . . . . . . . . . . . . . . . . . . 64\nA.3 Decision Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nA.4 Random Forest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\nAppendix B Timing and accuracy statistics for headlines 68\nB.1 Logistic Regression - length of headlines . . . . . . . . . . . . . . . . . . . . 68\nB.2 Logistic regression - ratio of capitalized words to total words . . . . . . . . 69\nB.3 Logistic regression - ratio of stop words to total words . . . . . . . . . . . . 70\nAppendix C Timing and accuracy statistics for websites and TTR 71\nC.1 Logistic Regression - URLs . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\nC.2 Accuracy and Timing statistic using TTR . . . . . . . . . . . . . . . . . . . 72\nAppendix D Timing and accuracy statistics for parts of speech on body of\narticles 73\nD.1 Adjectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\nD.2 Nouns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\nD.3 Nouns and Adjectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\nAppendix E Timing and accuracy statistics for sentiment analysis on parts\nof speech of body of articles 76\nE.1 Nouns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\nE.2 Adjectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\nviii\nE.3 Nouns and Adjectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\nix\nList of Figures\n1.1 Generation, consumption and propagation of content over the Internet . . .2\n4.1 Process of text mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.2 Pre-processing of text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.3 Logistic function outputs a value between 0 and 1 . . . . . . . . . . . . . . 20\n4.4 Hyperplane in SVM separating the classes [6] . . . . . . . . . . . . . . . . . 22\n4.5 Accuracy and timing of di\ufb00erent values of hyperparameter Cin Logistic\nregression classi\ufb01er for TF-IDF on headlines of articles . . . . . . . . . . . . 26\n4.6 Accuracy of the TF-IDF vectors on the headlines . . . . . . . . . . . . . . . 28\n4.7 Class frequency distribution of length of headlines of articles . . . . . . . . . 30\n4.8 Class frequency distribution of length of headlines of all the news articles in\nthe training dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n4.9 Accuracy of using the length of the headlines as features . . . . . . . . . . . 31\n4.10 Frequency distribution of capitalized words to total words in the headlines\nof the articles for both classes . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n4.11 Frequency distribution of stop words to total words in the headlines of the\narticles for both classes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n4.12 Accuracy of using the ratio of capitalized words and stop words of total\nwords of length of the headlines as features . . . . . . . . . . . . . . . . . . 35\nx\n4.13 Wordcloud of adjectives in the training set . . . . . . . . . . . . . . . . . . . 37\n4.14 Wordcloud of nouns in the training set . . . . . . . . . . . . . . . . . . . . . 39\n4.15 Accuracy of using 80% most occurring adjectives and nouns for training . .40\n4.16 Websites common to both classes and their contribution to each class . . . . 41\n4.17 Class frequency distribution of top 20 of the websites in each class . . . . . 42\n4.18 Wordcloud of the nouns according to their density in the body of training\ncorpus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n4.19 Wordcloudoftheadjectivesaccordingtotheirdensityinthebodyoftraining\ncorpus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n4.20 Accuracy using adjectives, nouns and both nouns and adjectives . . . . . . 49\n4.21 Sentiment analysis over the context of the word . . . . . . . . . . . . . . . . 50\n4.22 Accuracy of sentiment analysis over the context of the word . . . . . . . . . 51\nxi\nList of Tables\n3.1 Distribution of articles in the LIAR dataset . . . . . . . . . . . . . . . . . . 12\n3.2 Distribution of articles in the SemEval 2019 Task 4 . . . . . . . . . . . . . . 13\n3.3 List of queries related to midterm election in 2018 . . . . . . . . . . . . . . 15\n4.1 Test accuracy for all algorithms with optimum hyperparameter using TF-IDF 28\n4.2 Test accuracy for all algorithms with optimum hyperparameter using length\nof headlines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n4.3 Test accuracy for all algorithms with optimum hyperparameter for ratio of\ncapitalized words to total words in the headline of the article . . . . . . . . 32\n4.4 Test accuracy for all algorithms with optimum hyperparameter for ratio of\nstop words to total words in the headline of the article . . . . . . . . . . . . 35\n4.5 Test accuracy using the top 80% adjectives as features . . . . . . . . . . . . 38\n4.6 Test accuracy using the top 80% nouns as features . . . . . . . . . . . . . . 39\n4.8 List of websites common to both True and False Hyperpartisan articles . . .42\n4.7 Test accuracy for all algorithms with optimum hyperparameter for URL . .44\n4.9 Test accuracy using Automated Readability Index (ARI) on the body of text 45\n5.1 Result of classifying the midterm elections data . . . . . . . . . . . . . . . . 53\n5.2 Result on the top 10 queries of classifying the midterm elections data . . . . 53\nxii\nA.1 Test accuracy with variation in Cfor logistic regression . . . . . . . . . . . 62\nA.2 Test accuracy with variation in min_df for Gaussian Naive Bayes . . . . . 64\nA.3 Test accuracy with variation in min_df for Gaussian Naive Bayes . . . . . 65\nA.4 Test accuracy with variation in min_df for decision trees . . . . . . . . . . 66\nA.5 Test accuracy with variation in max_depth andn_estimators for random\nforest. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\nB.1 Test accuracy with variation in Cfor logistic regression . . . . . . . . . . . 69\nB.2 Test accuracy with variation in Cfor logistic regression . . . . . . . . . . . 70\nB.3 Test accuracy with variation in Cfor logistic regression . . . . . . . . . . . 70\nC.1 Test accuracy with variation in Cfor logistic regression . . . . . . . . . . . 72\nC.2 Test accuracy using TTR on all the algorithms . . . . . . . . . . . . . . . . 72\nD.1 Test accuracy using adjectives in the body of text . . . . . . . . . . . . . . . 74\nD.2 Test accuracy using nouns in the body of text . . . . . . . . . . . . . . . . . 74\nD.3 Test accuracy using both nouns and adjectives in the body of text . . . . . 75\nE.1 Test accuracy using sentiments of nouns in the body of text . . . . . . . . . 77\nE.2 Test accuracy using sentiments of adjectives in the body of text . . . . . . . 77\nE.3 Test accuracy using sentiments of both nouns and adjectives in the body of\ntext. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\nxiii\nChapter 1\nIntroduction\n1.1 Motivation\nThe recent surge in consumption of articles through online media has lead to a paradigm\nshift in the way people keep themselves updated. Memes, tweets, social media posts and\nonline news are some of the ways that readers are entertained, informed and even in\ufb02uenced\nto make online purchases. Thus, the Internet has become a source to in\ufb02uence people as it\nhas a faster dissemination than the tradition physical medium. According to Allcott and\nGentzkow [7], 14% of Americans considered social media as their \u201cmost important\u201d source\nof information. This can be worrisome as there is a recent trend in e\ufb00ortless propagation\nof fake news through social media[ 31]. Propagation and increasing readership of fake news\nis not healthy as it can a\ufb00ect decisions of a huge population/community, as seen in the\n2016 U. S. presidential elections[ 7,18,30,31]. Generation, consumption and propagation\nof content on over the Internet is illustrated in Figure 1.1 .\n1\n2 CHAPTER 1. INTRODUCTION\nFigure 1.1: Generation, consumption and propagation of content over the Internet\nAs seen from Figure 1.1 above, creating cheaper content online has led to an increase\nin generation and easy access of any kind of content all over the world. We consider\nsocial media as a subset of the Internet. The process of coming across an article online and\nactually clicking and reading it is driven by a cognitive phenomenon called as the \u2018Curiosity\nGap\u2019. The article must have come across the reader on the Internet due to his/her recent\nengaging activities in this genre or because one of their followers on the social media shared\nit. This formation of a bubble wherein one encounters content engaging and entertaining\nto their own taste is called an echo chamber . These kinds of content have a polarizing\nand engaging nature to their readers, and consist of anything that one consumes online -\nincluding the fake and hyperpartisan news. Consumption of such content could be harmful\nas information overload of any kind in\ufb02uences human decision making[ 13].\nDetection and control of fake news has become an emerging research topic as the con-\nsequences of it can be alarming. Fake news is intentionally written so as to engage and\nmislead readers into believing false information. Increase in this activity is mainly for\n\ufb01nancial and political gain[ 31]. In this work, we look into detecting hyperpartisanship in\n1.2. CONTRIBUTION 3\nweb-searched articles.\nAccording to Potthast et al. [26],hyperpartisan news follows a hyperpartisan argumenta-\ntion which means that it exhibits blind, prejudiced or unreasoning allegiance to one party,\nfaction, cause, or person. The content in such articles are not fabricated, although they are\nsuggested in a way which stimulates emotional feelings among the readers. Such polarizing\ncontent is generated in order to create a partisan divide among the content consumers.\nOther than news, hyperpartisan content can be propagated through blog posts, and tweets,\netc. Research related to hyperpartisanship is relatively new compared to detection of fake\nnews[31], di\ufb00erentiating between fake news and satire[ 28] and clickbait detection[ 11]. Al-\nthough these are named di\ufb00erently, these di\ufb00erent topics more or less fall under the same\numbrella: they di\ufb00er from actually reporting facts.\nThe premise for this study is to \ufb01nd out cues for hyperpartisanship in web-searched articles\nrelated to U. S. midterm election in 2018[ 3].\n1.2 Contribution\nOur main contribution is to \ufb01nd hyperpartisan cues using both the headlines and the body\nof any text article. We used a novel approach of using presence of morphological text\nfeatures (nouns and adjectives) and their sentiments for classi\ufb01cation. Additionally, we\nhave also employed \ufb01nding clickbait traits in hyperpartisan articles using Term Frequency\nand Inverse Document Frequency (TF-IDF) vectorizer and n-grams. In this work, we\nstart with the modeling of our system to detect hyperpartisanship in news through the\ndataset provided by PAN @ SemEval 2019[ 5]. We report our results on web-scraped articles\nrelated to U. S. midterm elections in 2018. The web articles were collected using BING\nweb search API[ 1] and the queries were curated using Google Trends[ 2] starting with the\n4 CHAPTER 1. INTRODUCTION\nsearch term \u2018United States midterm election\u2019 and iteratively expanding the related queries\nto a total of 86 queries. We found that more than half of the web-queried results showed\nhyperpartisanship attributes.\n1.3 Problem Statement\nThis thesis covers the following problem:\nHYPERPARTISANSHIP DETECTION IN WEB-SEARCHED ARTICLES\nInput: A web-searched article A\nOutput: If the web-searched article Afollows the hyperpartisanship argumentation or not.\nH(A)=8\n>><\n>>:1ifAis hyperpartisan\n0ifAis not hyperpartisan\n1.4 Outline of Thesis\nThis thesis is organized as follows.\nChapter 2 gives an overview of the related work done in this \ufb01eld. Chapter 4 discusses the\nmethodology and the algorithms implemented. It further explains the data curation and\nthe modeling of the system. It also lists the results obtained using our primary dataset. In\nChapter 5 , we discuss our \ufb01ndings on the web-searched articles related to midterm elections\n2018. Finally, Chapter 6 concludes this thesis and provides a brief summary related to\nfuture work and development.\nChapter 2\nReview of Literature\nWork on detecting hyperpartisanship in news has not been much explored. Potthast\net al.[26] explored the technique of \u2018Unmasking\u2019[ 22] to \ufb01nd out distinction between writ-\ning styles of right-wing and left-wing together (hyperpartisan) and mainstream media and\ndetection of fake news. They used features like n-grams, readability scores and frequency\nof words using General Inquirer Dictionaries[ 32] as features for classi\ufb01cation in addition to\nnews-domain speci\ufb01c features like ratios of quoted words and external links, the number\nof paragraphs in the news article and their average length. Their work fared well to dis-\ntinguish hyperpartisan news from mainstream news ( F1= 0.78) as well as from satire ( F1\n= 0.81). Since detection of extremism in text articles is what the aim of this study is, it\ncan be compared to detecting fake news. Thus, we also review the work done in fake news\ndetection as the research done on it can be used as a basis for our work.\nAs earlier discussed, the motive of generation of fake news is for \ufb01nancial and polit-\nical bene\ufb01t. These online articles are written in a way which generate interest in readers\ndue to their disputable nature and are termed as \u2018clickbaits\u2019. Chakraborty et al. [11] stud-\nied how to detect and prevent clickbaits which exploit the cognitive phenomenon called a\n\u2018Curiosity Gap \u2019 [23]. They found that traditional news headlines (non-clickbait) contain\ncontent words referring to people and/or location whereas clickbait headlines are longer and\ncontain both content andfunction words . Most text-processing steps involve removal of\nstop-words, however in non-clickbait articles, inference of stop-words is left to the readers\n5\n6 CHAPTER 2. REVIEW OF LITERATURE\nand thus it was used in the modeling of the classi\ufb01er. Additionally, clickbaits used \u2018very\npositive\u2019 sentiment words like \u2018breathtakingly\u2019, \u2018gut-wrenching\u2019 , internet slangs like \u2018LOL\u2019,\n\u2018LMAO\u2019 along with punctuation patterns. This work achieved 93% accuracy in detecting\nclickbaits.\nShu et al. [31] did a comprehensive review of the characterization of fake news using psy-\nchology and social studies and then detection of fake news. Detection of fake news is not a\ntrivial problem since they are knowingly written to mislead readers, citing true evidence to\nsupport an indisputable claim[ 16]. The authors say the psychological foundations of fake\nnews which make humans vulnerable to its consumption are the following:\n\u2022Naive Realism : A reader\u2019s belief that one\u2019s perception of reality is the only accurate\none, and not being open to discussing other\u2019s views and beliefs[ 35].\n\u2022Con\ufb01rmation Bias : A reader favoring information which already con\ufb01rms to his/her\nexisting rationale/views.\nFake news propagates faster than traditional physical medium (newspapers) through social\nmedia. The low cost of creating social media accounts encourages the creation of malicious\nuser accounts, many of these accounts being social bots controlled by automation. Social\nbots and Russian trolls on social media greatly a\ufb00ected the 2016 United States presidential\nelections[ 4,8]. In social media, there are additional auxiliary information in addition to\nnews content which can be used as features in fake news detection[ 11]. The metainforma-\ntion used in this work[ 11] are the source, i.e., the author or the news publisher, headlines,\nbody text and the image/video content in the news body. Visual cues in images and\nthumbnails of videos help supplement the spread of fake news. Social context features\non an individual and group level also help in understanding the reach and propagation of\nnews. Individual level features include user demographics like registration age, number of\n7\nfollowers/followees and number of tweets authored by the user[ 10]. Group level features\ninclude the overall perception of news by a group[ 38]. Network based features are used\nto identify dissemination of fake news within a social network since the spread of articles\nfollows an echo chamber cycle.\nSatire in news articles can be misunderstood by some readers, as the message is not\ndelivered plainly, rather topped with irony and double-meanings[ 28]. The paper claims\nsatire and fake news to be a part of deception, although the latter is not intended to\nbe found by the audience. Rubin et al. [28] proposed an SVM based algorithm using 5\npredictive features on 360 news articles to detect how satire can be di\ufb00erentiated from fake\nnews. Their best predicting feature combination was absurdity ,grammar andpunctuation\nwhich detected satirical news with an accuracy of 90% and 84% recall.\nAs discussed earlier, social bots without human interaction have been used to spread\nmisinformation. In addition to being a threat to democracies, misinformation can lead to\nreaders making dangerous health decisions[ 19] as well as manipulation of stock markets[ 17].\nIn their work, Shao et al. [30] studied the large scale systematic analysis of the spread of\nfake news. They crawled 122 websites which routinely publish fake news according to\nestablished media. Their analysis showed that these websites publish approximately 100\narticles per week on average. However, the virality of these articles is due to the tweets, on\nan average of 30 tweets per article per week. The authors showed that the super-spreaders\nof these misleading articles are the social bots which perform activities like posting links to\narticles, retweeting other accounts and performing other automated tasks like following and\nreplying to other users. These activities help in amplifying fake news even before a claim\ngoes viral. Social bots use other strategies like mentioning in\ufb02uential people/journalists,\npoliticians in their tweets linking to the debunked claim. This leads to a false appearance\nthat the news is widely shared and the chance that followers of these bot accounts will\n8 CHAPTER 2. REVIEW OF LITERATURE\nshare it as well. In addition, social network behavior also can be used as an important\ncharacteristic in deception detection as authentic social media pro\ufb01les equates to trustful\nposts. Similarly, inclusion of hyperlinks and/or associated metadata can be supplemented\nto establish proof of veracity[ 15].\nConroy et al. [14] provide a description of a variety of veracity assessment methods in\ndeception detection. Linguistic cue approaches, network analysis and a hybrid of the two\nmethods are currently used in fake news detection. In the \ufb01rst method, language patterns\nare extracted to \ufb01nd associative deceptive patterns from word-level to a more discourse-\nlevel, whereas in the second method, message metadata or the structured data network are\nused. Structured data network includes \ufb01nding a shortest path between generic entities in\na statement represented in a graph network. This paper also talks about the inclusion of\npublicly available gold-standard/benchmark datasets to assist in fact-checking. Thus, in\nChapter 3 , we review the current datasets in practice, with the details of the dataset we\nhave worked on, and developed.\nClickbaitsworkonthesoleprinciplethattheheadlinesorthearticletitleshouldevoke\ncuriosity in the readers\u2019 mind. Bourgonje et al. [9] claim that detecting if the headlines bear\nany relation to the article body should be the \ufb01rst step in clickbait/fake news detection.\nThus, they worked on stance detection of headlines with respect to their article bodies\nas a part of the \ufb01rst Fake News Challenge1. Their setup is is based on a lemmatization\nbased n-gram matching using a combination of three binary classi\ufb01ers which resulted in a\nweighted score of 89.59% accuracy.\nBuilding on these previous works, we take into account features like length of the\narticles, writing style of headlines, etc.\nIn the next section, we go through the current benchmark datasets in practice. We\n1http://www.fakenewschallenge.org/\n9\nalso detail the online NLP data challenge that we have worked upon as a part of our\nresearch. The data challenge is task 4 of SemEval workshop: Hyperpartisan News Detec-\ntion2. We were provided with a labeled dataset for this challenge and our experiments\nwere conducted using this dataset.\n2https://pan.webis.de/semeval19/semeval19-web/\nChapter 3\nDataset\nDue to the recent emergence in fake news and increasing interest in its detection, the\nresources for its research are still in the infancy stage. Labeling a dataset requires Subject\nMatter Experts (SMEs) to annotate an article, and the notion of what is fakeand what\nisrealcan be fuzzy since such articles are intended to deceive the readers. The lack of\nreliable benchmark datasets poses a signi\ufb01cant challenge in advancing the research. In this\nsection, we review the current labeled datasets available as well as talk about the SemEval\nTask 4 - Hyperpartisan News Detection1.\n3.1 Current Datasets In Practice\nIn the subsequent sub-sections, we review the current datasets in practice used in deception\ndetection - fake news detection, clickbait detection, stance detection and hyperpartisan\nnews detection.\n1https://pan.webis.de/semeval19/semeval19-web/\n10\n3.1. CURRENT DATASETS IN PRACTICE 11\n3.1.1 Emergent\nVlachosandRiedel [33]proposedusingdatafromfact-checkingwebsiteslikePOLITIFACT.COM2,\na Pulitzer prize-winning website and FULLFACT.ORG3(2014). In 2017, Ferrara et al. [17]\ncreated a rumor-debunking dataset containing 300 rumored claims and 2595 associated\nnews articles, manually annotated by journalists. These claims were collected by journal-\nists from websites like snopes.com and twitter accounts like @Hoaxalizer. Each claim has\nsourced news articles, a stance ( for,against,observing ), article headline and veracity ( true\norfalse). Although a pioneer in creating a dataset for stance detection, the number of\nsamples are quite low in this dataset.\n3.1.2 LIAR Dataset\nThe LIAR dataset by Wang[34] is a publicly available dataset for fake news detection. The\ndataset consists of 12800 manually annotated short statements in various states of a\ufb00air\nfrom POLITIFACT.COM collected over a decade. This dataset has a comprehensive collection\nof detailed analysis reports and source links to all the documents. The truthfulness ratings\nare based on 6 \ufb01ne-grained labels: pants-\ufb01re ,false,barely-true ,half-true ,mostly-true and\ntrue. The distribution of articles can be seen in Table 3.1 .\nThe dataset contains snippets from speakers a\ufb03liated to both Democrats and Republicans\nas well as social media posts, such as facebook posts. In addition to party a\ufb03liation for\nspeakers, the dataset also contains other metadata like their current job, credit history,\nhome and state.\n2www.politifact.com\n3fullfact.org\n12 CHAPTER 3. DATASET\nTable 3.1: Distribution of articles in the LIAR dataset\npants-\ufb01re falsebarely-true half-true mostly-true true\n1047 25072103 2627 2454 2053\n3.1.3 BuzzFeed News Dataset\nBuzzFeed published an article \u2018 Inside The Partisan Fight For Your News Feed \u20194which\nidenti\ufb01ed 667 websites as partisan news outlets along with the associated Facebook pages\n(452). The dataset is available in the GitHub repository5.\n3.1.4 Fake News Challenge Dataset (FNC-1)\nFNC-1 dataset aims to use Arti\ufb01cial Intelligence(AI) to \ufb01nd if a headline and the body of\nthe text are related to each other, i.e., stance detection . The data consists of ( headline,\nbody, stance ) where stance could be any of the following: ( agrees, disagrees, discusses,\nunrelated ). The dataset extends the work of Ferrara et al. [17] and the dataset can be\nfound in this GitHub repository6.\n3.1.5 Kaggle Fake News Dataset\nKaggle\u2019s \u2018 Getting Real about Fake News \u2019 dataset consists of articles scraped from 244 web-\nsites amounting to a total of 12,999 posts. These websites were scraped using a chrome\nextension - BS Detector7. The samples in the dataset seem rather too obvious and/or\nextremely fake, which is di\ufb00erent from the problem at hand - detecting intentionally mis-\n4https://www.buzzfeednews.com/article/craigsilverman/inside-the-partisan-\ufb01ght-for-your-news-feed\n5https://github.com/BuzzFeedNews/2017-08-partisan-sites-and-facebook-pages\n6https://github.com/FakeNewsChallenge/fnc-1\n7https://github.com/selfagency/bs-detector\n3.2. SEMEVAL 2019 TASK 4 - HYPERPARTISAN NEWS DETECTION 13\nleading news. The dataset can be found on Kaggle8.\n3.2 SemEval 2019 Task 4 - Hyperpartisan News De-\ntection\nWe start our work with SemEval 2019 Task 4 - Hyperpartisan News Detection9. The task\nis as follows:\nGiven a news article text, decide whether it follows a hyperpartisan argumen-\ntation, i.e., whether it exhibits blind, prejudiced, or unreasoning allegiance to\none party, faction, cause, or person.\n3.2.1 SemEval 2019 Task 4 Dataset\nOur initial modeling is based on SemEval 2019 Task 4 dataset since the size of the dataset\nis quite large and the articles are labeled by the credibility of the publishers as well as\nbased on the articles.\nThe dataset is split into two parts - labeled by publishers, and labeled by articles. The\ndistribution of the data is as given in Table 3.2 .\nTable 3.2: Distribution of articles in the SemEval 2019 Task 4\nType By Publisher By Article\nTraining set size 600,000 645\nValidation set size 150,000 N/A\nThe \u2018by publishers\u2019 dataset consists of a total of 750,000 articles divided in a 80/20\n8https://www.kaggle.com/mrisdal/fake-news/version/1\n9https://pan.webis.de/semeval19/semeval19-web/\n14 CHAPTER 3. DATASET\nsplit between training and validation. These articles are labeled by the overall bias of the\npublisher assigned by journalists at BuzzFeed or MEDIABIASFACTCHECK.COM. 50% of the\ndataset is hyperpartisan while the other half is not. Out of the 375,000 articles which are\nhyperpartisan , half of them(187,500) fall in the left-spectrum of hyperpartisanship while\nthe other half fall in the right-spectrum. Thus, this dataset is quite balanced as opposed\nto the second part of the dataset labeled by articles.\nIn the \u2018by articles\u2019 dataset, there are a total of 645 articles labeled through crowd-\nsourcing on the basis of content in the articles. The labeling of the articles in this group\nare agreed upon by a consensus. The distribution of hyperpartisanship in this dataset is\n238 articles (37%) and the remaining 407 articles (63%) are not hyperpartisan.\n3.2.2 Midterm Elections 2018 Dataset\nThe goal of this study is to use the model developed using the preliminary work done on\nSemEvalTask4dataset, tocomprehendtheoccurrenceofhyerpartisanshipinweb-searched\narticles related to U. S. midterm elections in 2018.\nWedecidedtoaggregatetrendingqueriesrelatedtothequery: \u2018UnitedStatesmidterm\nelection\u2019 using Google Trends10. A list of 86 queries were curated, less than the initial goal\nof 100 queries as the queries became repetitive and started bottoming out. The queries\ncan be seen in Table 3.3\nOnce the queries were curated, BING web-search API11was used to scrape web-pages\nfor the queries. A maximum of 100 web-pages were collected for each of the queries, based\non the results returned. This resulted in a total of 6616 web articles.\n10https://trends.google.com/trends/\n11https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/\n3.2. SEMEVAL 2019 TASK 4 - HYPERPARTISAN NEWS DETECTION 15\nTable 3.3: List of queries related to midterm election in 2018\nunited states midterm election 2018 election results\n\ufb02orida midterm election who won midterm elections\nmidterms results 2018 midterm election date\nmidterm election map election day 2018\nkavanaugh us midterm results\nmidterm election ballot 2018 ted cruz\n\ufb02orida midterm election results pa midterm elections 2018\nresults of 2018 midterm elections \ufb02orida midterm election 2018\nwho won the midterm elections texas midterm election results\nmissouri midterm elections us midterm election results\ncalifornia midterm election results live midterm election results\nstacey abrams texas senate race\nkansas midterm elections georgia governor race\n\ufb02orida senate race mid election results 2018\nmid term polls where to vote\nwashington state midterm elections arizona senate race\nrepublicans will win midterms andrew gillum\n\ufb02orida election results election day\nelection day results 2018 michigan 2018 election results\nmichigan election results illinois election results 2018\nca election results wisconsin election results 2018\nwisconsin election results ca election results 2018\nca election 2018 colorado election 2018\n16 CHAPTER 3. DATASET\ncolorado election results ky election results 2018\ncolorado election results 2018 nevada election results 2018\ngeorgia governor election results 2018 election results today\nmaryland election 2018 minnesota election results 2018\nnc election results 2018 maine election results 2018\nmaryland election results 2018 maine election 2018\nwho won the election midterm elections 2018\nwho won the georgia midterm elections kavanaugh vote\nkavanaugh hearing kavanaugh con\ufb01rmation\nkavanaugh ford supreme court\nchristine blasey ford kavanaugh christine blasey ford\nbeto cruz debate ted cruz vs beto debate\nted cruz vs beto polls jimmy kimmel vs ted cruz\nted cruz mark zuckerberg us senate election results\n\ufb02orida senate race kemp\nstacey abrams results georgia governor race stacey abrams\ngeorgia election did stacey abrams win georgia\nandrew gillum polls ron desantis\ndesantis orange county ca election results 2018\nca secretary of state sinema\nus senate makeup martha mcsally\nfox news election results\nInthenextchapter, wediscussthefeatures, NLPtechniquesandthedi\ufb00erentmachine\nlearning algorithms used in the modeling of our data.\nChapter 4\nMethods and Results\nIn this chapter, we discuss the various text-features and machine learning algorithms used\nin the classi\ufb01cation of our data to detect hyperpartisanship.\nSection 4.1 describes the standard preprocessing techniques done over the text before any\nfeature engineering and/or modeling. The standard process of text mining is shown in the\nFigure 4.1 .\nFigure 4.1: Process of text mining\n17\n18 CHAPTER 4. METHODS AND RESULTS\n4.1 Preprocessing\nPreprocessing of text is the preliminary step to convert text into a format feasible for input\nto an algorithm. The steps involved are explained in the subsequent sub-sections as well\nas inFigure 4.2 .\nFigure 4.2: Pre-processing of text\n4.1.1 Tokenization\nThis step involves splitting paragraphs into sentences and sentences into words. Sentence\nboundary detection is used to get a list of sentences. We have used PunktSentenceTo-\nkeniser1from NLTK to perform sentence tokenization. It is an implementation of un-\nsupervised multilingual sentence boundary detection by Kiss and Strunk [21]. For word\ntokenization, white spaces are used as delimiters. Additionally, all the words are either\nconverted to lowercase or uppercase so that capitalized words are not considered di\ufb00erent\nfrom non-capitalized one. Abbreviations are kept capitalized, and there should be rules\n1https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n4.2. ALGORITHMS 19\nimplemented to keep them as is, e.g., US(United States) and us(pronoun).\n4.1.2 Stop-words Removal\nStopwords are the often-occurring words in a language which connect sentences, and do not\nhold any importance. We used NLTK\u2019s stopwords list2to \ufb01lter out stopwords like \u2018 the\u2019,\n\u2018a\u2019, \u2018so\u2019, etc. from the corpus. Furthermore, we also removed numbers and punctuation\nsince they are not relevant to our analysis.\n4.1.3 Normalization\nNormalization of text refers to reduction of in\ufb02ectional forms of words into their base\nforms. While stemming chops o\ufb00 the rear ends of in\ufb02ections, lemmatization uses lexical\nknowledge bases to convert them to their root forms. For example, chopping o\ufb00 \u2018 es\u2019 in\n\u2018studies\u2019 becomes \u2018 studi\u2019 instead of \u2018 study\u2019 after stemming while it retains the base form\n\u2018study\u2019 in lemmatization.\nWe employed lemmatization in our corpus using WordNet Lemmatizer3.\n4.2 Algorithms\nIn this work, we explore di\ufb00erent features which could contribute in automated detection\nof hyperpartisanship in our dataset, and use the following machine learning algorithms to\ntest our hypotheses. Here, we explain the algorithms used in this work. We have used the\nstandard implementation of the algorithms from scikit-learn4.\n2https://www.nltk.org/nltk_data/\n3https://www.nltk.org/_modules/nltk/stem/wordnet.html\n4https://scikit-learn.org/stable/\n20 CHAPTER 4. METHODS AND RESULTS\n4.2.1 Logistic Regression\nWe use binary logistic regression (LR) to classify the engineered features as hyperpartisan\nor not. An LR model uses the logistic function to \ufb01t the output of a linear equation between\n0 and 1. Since the features that we have used in our classi\ufb01cation problem are categorical\nin nature, our LR model transforms the output using the logistic sigmoid function to return\na probability value which is used to map to either of the two classes. So, instead of using\na line as a decision boundary, we use a sigmoid function that \ufb02attens out at 0 and 1 which\nare our two distinct classes for classi\ufb01cation. The logistic function is de\ufb01ned in ( 4.1) and\ncan be seen in Figure 4.3 .\nlogistic (\u0011) =1\n1 +exp(\u0000\u0011)(4.1)\nFigure 4.3: Logistic function outputs a value between 0 and 1\nWe used scikit-learn\u2019s logistic regression classi\ufb01er5. In this classi\ufb01cation algorithm,\n5https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n4.2. ALGORITHMS 21\nthe hyperparameter is Cwhich refers to inverse of regularization strength. Regularization\nis done in order to prevent over\ufb01tting of data, and higher value of Ccorresponds to less\nregularization. We tested our classi\ufb01er on a range of values for C, and compared the\naccuracy and time for each di\ufb00erent setting.\n4.2.2 Naive Bayes\nThe Naive Bayes algorithm assumes that each feature in the dataset makes an equal and\nindependent contribution to the outcome and uses Bayes theorem given in Equation 4.2 .\nP(AjB) =P(BjA)P(A)\nP(B)(4.2)\nMetsis et al. [25] compared the performance of di\ufb00erent Naive Bayes versions on text\nclassi\ufb01cation (spam \ufb01ltering). Work by [ 20,24,29] show that Multinomial Naive Bayes\nworks the best with text classi\ufb01cation and hence we also carry our implementation using\nscikit-learn\u2019s Multinomial Naive Bayes classi\ufb01er6in addition to Gaussian Naive Bayes7.\n4.2.3 Support Vector Machine\nA Support Vector Machine (SVM) is a supervised machine learning algorithm which is\nused in our classi\ufb01cation problem to \ufb01nd a hyperplane or a margin which maximizes the\nnearest points separating the classes from the plane of separation. We have used non-linear\nkernel: radial basis function as well, to \ufb01nd a non-linear hyperplane separating the classes.\n6https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n7https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n22 CHAPTER 4. METHODS AND RESULTS\nFigure 4.4: Hyperplane in SVM separating the classes [ 6]\nAs seen from Figure 4.4 , there are three hyperplanes - H1,H2andH3. While H1\ndoes not separate the classes, H2does separate with minimal margin and H3too, but with\nmaximal margin. We used scikit-learn\u2019s SVM implementation8.\n4.2.4 Decision Trees\nWe use scikit-learn\u2019s default decision tree implementation9, which uses gini index as the\ncriterion for the split. Decision trees are easier to understand and visualize. The process\nbegins with a root node representing the entire population or the dataset. The classi\ufb01cation\nof instances is done by splitting an instance on its attributes. The criterion of split could\nbe entropy as de\ufb01ned in Equation 4.3 or gini index in Equation 4.4 .\n8https://scikit-learn.org/stable/modules/svm.html\n9https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassi\ufb01er.html\n4.2. ALGORITHMS 23\nE=c\u2211\ni=1\u0000pilogpi (4.3)\nG= 1 \u0000\u2211\njpj2(4.4)\nwhere prepresents the probability of the presence of an attribute in an instance.\nThese measures are used to quantify the homogeneity of a split. Higher the informa-\ntion gain (decrease in entropy) or gini index, higher is the homogeneity and thus the split\ntakes place on that attribute.\n4.2.5 Random Forest\nBuilding upon the previous algorithm, we make use of random forests in our classi\ufb01cation\nproblem. In a random forest, each tree has access to a random subset of features or the\ntrainingdata. Whilemakingpredictions, ittakesthemajorityvoteofthedecisionsmadeby\nthe individual trees. We have used the hyperparameters n_estimators andmax_depth for\ntuning to \ufb01nd optimum accuracy. This work made use of scikit-learn\u2019s implementation10.\n4.2.6 Gradient Boosting\nThis section refers to the implementation of gradient boosting called XGBoost by Chen\nand Guestrin [12] or eXtreme gradient boosting. This algorithm has been known to fare\nwell in many machine learning challenges due to its scalability and speed [ 12]. They use a\nsparsity-aware algorithm to \ufb01nd the split in tree-learning and block structure to support\n10https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassi\ufb01er.html\n24 CHAPTER 4. METHODS AND RESULTS\nparallelization. We use the default implementation of scikit-learn\u2019s XGBClassi\ufb01er11.\n4.2.7 Stochastic Gradient Classi\ufb01er\nSince we are dealing with huge number of instances, using stochastic gradient descent is\nuseful. The updates in coe\ufb03cients is performed for each training instance and not at the\nend of the batch of instances.\n4.3 Feature Engineering\nOur study is based on exploring how the content of an article, mainly the title and the\nbody, could be used as predictive features for the detection of partisanship in an article.\nWe explore if there are linguistic and style di\ufb00erences between mainstream articles and\narticles with a partisan inclination. We divide the following sections into exploring the\nfeatures of headlines and the body of articles separately. Our metric of evaluation in all\ncases is accuracy.\n4.4 Headlines of articles\nAs discussed in Chapter 2 , headlines of news articles can be an important feature in our\ncase since these articles are created on the foundation of being clickbaits. We applied Term\nFrequency-Inverse Document Frequency (TF-IDF) on the titles of the news articles and\nused the classi\ufb01cation algorithms discussed above.\n11https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py\n4.4. HEADLINES OF ARTICLES 25\n4.4.1 Term Frequency-Inverse Document Frequency (TF-IDF)\nWe use TD-IDF as a weighted statistical measure to \ufb01nd the importance of a word in a\ndocument in a corpus. The importance of a word increases proportionally by the number\nof times it appears in the document, but is o\ufb00set by its frequency in the corpus. The\nTF-IDF score is found out by the multiplication of the following two terms:\n\u2022Term Frequency. It measures the frequency of the occurrence of terms in a doc-\nument. Since every document di\ufb00ers in length, a term might appear more in longer\ndocuments than the shorter ones. To normalize this metric, the term frequency\nis divided by the total number of terms in the document or the document length.\nTerm Frequency =No: of terms\u2032t\u2032in a document\nT otal number of terms in the document\n(All the terms in a document are considered important here.)\n\u2022Inverse Document Frequency. This is a measure of how important a term is, in\nthe whole corpus (collection of documents). Since words like \u201cthe\u201d, \u201cis\u201d, and \u201cof\u201d are\nused very often, and do not hold much importance, it becomes necessary to scale up\nthe rare terms and weigh down the frequent terms.\nThus,Inverse Document Frequency =lnT otal number of documents\nNo: of documents with term \u2018t\u2032in it\nCombining these two,\nTF \u0000IDF(t;d;D) =TF(t; d)\u0001IDF (t; D)\nwhere tis the term, dis the document, and Dis the corpus.\nWe used scikit-learn\u2019s T\ufb01dfVectorizer12instantiated using stop words since the headlines\nare smaller in length, and in non-clickbait articles, inference of stop-words is left to the\n12https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.T\ufb01dfVectorizer.html\n26 CHAPTER 4. METHODS AND RESULTS\nreaders. The hyperparameter \u2018 min_df\u2019 is used to ignore words strictly below the threshold\nto be considered while building the vocabulary. We tuned it for maximum accuracy for\neach algorithm, results of which can be found in the Appendix section described below.\nWe used each of the algorithms as described in Section 4.2 after building the TF-IDF\nvector. We now describe the parameter tuning done for the algorithms, if any.\nLogistic Regression\nThe result can be seen in Figure 4.5 .\nFigure 4.5: Accuracy and timing of di\ufb00erent values of hyperparameter Cin Logistic re-\ngression classi\ufb01er for TF-IDF on headlines of articles\nAs seen from Figure 4.5 , accuracy at C=1 increases and thereafter it does increase,\nbut at a lower pace. Whereas the time required to \ufb01t model increases considerably for\nC=10, 100, 1000. Thus, considering the time and accuracy trade-o\ufb00, we choose C=1.0\n4.4. HEADLINES OF ARTICLES 27\nas our inverse regularization factor. The timing and accuracy data can be found in Sec-\ntion A.1 .\nDecision Tree, Naive Bayes\nOur dataset is quite huge consisting of 700K articles, and thus \ufb01tting the whole vocabulary\ninto memory was not feasible. We tried to reduce the vocabulary using \u2018 min_df\u2019 parameter\nin TF-IDF and worked it on a range of values, and selected 0.0001 as the cut-o\ufb00. The\ncut-o\ufb00 values can be found in Section A.2 andSection A.3 for these algorithms.\nRandom Forest\nWe worked on a range of values for n_estimators andmax_depth for random forest and\nthe results can be seen in Section A.4 .\nFinal Results\nThe \ufb01nal results of using TF-IDF vectors of headlines of articles can be seen in Table 4.1\nandFigure 4.6 below. In the results of all our experiments, the \u2018Time\u2019 column refers to\nthe training time of the algorithms.\n28 CHAPTER 4. METHODS AND RESULTS\nTable 4.1: Test accuracy for all algorithms with optimum hyperparameter using TF-IDF\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 77.49 25.25\nSVM ( Linearkernel) 79 142323.33\nDecision Tree ( min_df = 0.0001) 71.10 789.29\nGaussian Naive Bayes ( min_df = 0.0001) 74.30 27.00\nMultinomial Naive Bayes ( min_df = 0.0001) 73.62 33.62\nRandom Forest 74.34 878.34\nXGBoost 66.55 391.89\nStochastic Gradient Descent 83.23 3064.4\nFigure 4.6: Accuracy of the TF-IDF vectors on the headlines\n4.4. HEADLINES OF ARTICLES 29\n4.4.2 Length of the headline\nChakraborty et al. [11] explained in their paper that headlines of clickbait articles tend to\nbe longer than the mainstream articles, since they contain more function words, and are\nexpected to gauge readers\u2019 attention. Thus, we use the length of headlines to model the\nalgorithms.\nFromFigure 4.7 , it can be seen that in both the classes, the length of a headline is primar-\nily concentrated in the range of [6-9] words. The Figure 4.8 shows the class distribution\nin the whole training dataset. The results of the modeling the algorithms using length of\nheadlines can be seen in Table 4.2 and inFigure 4.9 . The parameter tuning results can be\nfound in Section B.1 .\nAsweseefromtheresultsin Table4.2 , lengthofheadlinesarenotmuchofapredictive\nfeature, due to majority of the articles from both the classes falling in the same range of\nlength.\nTable 4.2: Test accuracy for all algorithms with optimum hyperparameter using length of\nheadlines\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 45.62 1.00\nSVM ( Linearkernel) 74 11752.31\nSVM ( Radial basis kernel) 59 16395.32\nDecision Tree 57.58 0.20\nGaussian Naive Bayes 48.25 0.09\nMultinomial Naive Bayes 49.99 574.65\nRandom Forest 57.82 157.04\nXGBoost 57.82 7.99\nStochastic Gradient Descent 49.99 0.35\n30 CHAPTER 4. METHODS AND RESULTS\n(a) Frequency distribution of length of headlines in the non-hyperpartisan articles\n(b) Frequency distribution of length of headlines in the hyperpartisan articles\nFigure 4.7: Class frequency distribution of length of headlines of articles\n4.4. HEADLINES OF ARTICLES 31\nFigure 4.8: Class frequency distribution of length of headlines of all the news articles in\nthe training dataset\nFigure 4.9: Accuracy of using the length of the headlines as features\n32 CHAPTER 4. METHODS AND RESULTS\n4.4.3 Ratio of capitalized and stop words to total words\nIn this subsection, we explore the writing style of headlines, i.e., usage of capitalized words\nand stop words. Captivating titles tend to have more punctuation and uppercase words.\nSuch titles have fully formed sentences rather than only using content words and leaving\ntheir interpretation to the readers [ 11]. We calculate the ratio of both these factors and\nmodel our algorithms using these features.\nFigure 4.10 shows the frequency distribution of ratio of capitalized words to total\nwords in the headline. The bulk of distribution is in the range of [0.0-0.1] for both classes.\nThe ratio was encoded and the results of the classi\ufb01cation can be seen in Table 4.3 . Thee\nresults of both these factors can be compared in Figure 4.12 .\nTable 4.3: Test accuracy for all algorithms with optimum hyperparameter for ratio of\ncapitalized words to total words in the headline of the article\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 49.06 0.65\nSVM ( Linearkernel) 58 5439.24\nSVM ( Radial basis kernel) 52 14548.12\nDecision Tree 51.35 0.13\nGaussian Naive Bayes 49.82 0.16\nMultinomial Naive Bayes 49.88 30.89\nRandom Forest 51.42 157.04\nXGBoost 51.35 7.31\nStochastic Gradient Descent 49.88 0.34\nWe perform a similar analysis using stop words and the frequency distribution can\nbe seen in Figure 4.11 . The results of the classi\ufb01cation can be seen in Table 4.4 .\n4.4. HEADLINES OF ARTICLES 33\n(a) Frequency distribution of ratio of capitalized words to total words in non-hyperpartisan articles\n(b) Frequency distribution of ratio of capitalized words to total words in hyperpartisan articles\nFigure 4.10: Frequency distribution of capitalized words to total words in the headlines of\nthe articles for both classes\n34 CHAPTER 4. METHODS AND RESULTS\n(a) Frequency distribution of ratio of stop words to total words in non-hyperpartisan articles\n(b) Frequency distribution of ratio of stop words to total words in hyperpartisan articles\nFigure 4.11: Frequency distribution of stop words to total words in the headlines of the\narticles for both classes.\n4.4. HEADLINES OF ARTICLES 35\nTable 4.4: Test accuracy for all algorithms with optimum hyperparameter for ratio of stop\nwords to total words in the headline of the article\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 56.17 0.53\nSVM ( Linearkernel) 58 5439.24\nSVM ( Radial basis kernel) 52 14548.12\nDecision Tree 56.23 0.16\nGaussian Naive Bayes 54.92 0.06\nMultinomial Naive Bayes 49.86 0.17\nRandom Forest 55.85 146.91\nXGBoost 56.03 7.27\nStochastic Gradient Descent 54.92 0.3\nFigure 4.12: Accuracy of using the ratio of capitalized words and stop words of total words\nof length of the headlines as features\n36 CHAPTER 4. METHODS AND RESULTS\n4.4.4 Using Content Words - Parts of Speech analysis\nMorphology of text could be divided into two parts - the function words and the content\nwords. Content words are words that have meaning and belong to the parts of speech,\nparticularly nouns, adjectives, adverbs and verbs. Function words are used to provide\nstructural and grammatical relationship into which the content words might \ufb01t. These\nwords belong to the parts of speech: determiner, conjunction and preposition.\nAdjectives\nIn this section, we explore how using parts of speech in a text, speci\ufb01cally the content\nwords, canbeusedto\ufb01ndoutpartisanshipinanarticle. Weconsidertheideaof subjectivity\ntagging[36]. Subjectivity tagging distinguishes opinions from factual information, mainly\nthe idea of distinguishing hyperpartisan articles from the mainstream articles. There have\nbeen previous studies which show that there is a statistically signi\ufb01cant and a positive\ncorrelation between presence of adjectives and subjectivity [ 37]. We extend this idea to\n\ufb01nd out if subjectivity can be used to distinguish partisanship from mainstream in text\narticles.\nWe used NLTK\u2019s pos_tagger13to \ufb01nd parts of speech in the title of the articles.\nAdjectives are represented by the tag \u2018JJ\u2019 according to the Penn treebank14. The article\ntitles in the training set were traversed to create a dictionary with all the adjectives as\nwell as to keep their count. The top 80% of the adjectives (745) were used as features to\nclassify our dataset.\n13https://www.nltk.org/_modules/nltk/tag.html\n14https://www.clips.uantwerpen.be/pages/mbsp-tags\n4.4. HEADLINES OF ARTICLES 37\nFigure 4.13: Wordcloud of adjectives in the training set\nAs seen in Figure 4.13 , higher the occurrence of a word, bigger is the word represented\nin the wordcloud. This technique is independent of the dataset, since the adjectives covered\nare mostly used in article representations, and are not limited to a particular niche. And\nthus this method can be extended to more unseen articles for analysis. The result of this\nanalysis can be seen in Table 4.5 .\n38 CHAPTER 4. METHODS AND RESULTS\nTable 4.5: Test accuracy using the top 80% adjectives as features\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 71.1 109.87\nDecision Tree 67.5 14518.27\nGaussian Naive Bayes 58.31 194.57\nMultinomial Naive Bayes 69.1 40.26\nRandom Forest 67.11 14592.91\nXGBoost 62.69 11103.74\nStochastic Gradient Descent 70.44 202.64\nNouns\nWe continue our experiment using another part of speech, i.e., nouns. Nouns represent\npeople, places and/or things. Using NLTK\u2019s pos_tagger, we segregate the nouns (NN*)\nconsisting of NN (noun, singular or mass), NNS (noun, plural), NNP (noun, proper singu-\nlar) and NNPS (noun, proper plural).\nThe wordcloud of the nouns can be seen in Figure 4.14 .\n4.4. HEADLINES OF ARTICLES 39\nFigure 4.14: Wordcloud of nouns in the training set\nThe results of classi\ufb01cation can be seen in Table 4.6 .\nTable 4.6: Test accuracy using the top 80% nouns as features\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 72.55 40.9\nDecision Tree 68.87 5778.43\nGaussian Naive Bayes 67.23 76.56\nMultinomial Naive Bayes 71.33 9.69\nRandom Forest 68.23 9812.23\nXGBoost 63.71 3044.02\nStochastic Gradient Descent 72.27 47.14\nThe \ufb01nal results using parts of speech tags, namely adjectives and nouns, can be\nvisualized in Figure 4.15 .\n40 CHAPTER 4. METHODS AND RESULTS\nFigure 4.15: Accuracy of using 80% most occurring adjectives and nouns for training\nAs seen, this method yields better results compared to others (7\u0303 3%).\n4.5 Publishers\nThe mainstream media is distorted with biased and hyperpartisan content for \ufb01nancial\nand political bene\ufb01ts. Thus, publishing houses or the publishers are more of a source for\nconstant production of such articles, and in this section we analyze the di\ufb00erent URLs of\nthe news articles to check for their contribution.\nOur analysis showed that a total of 256 and 318 unique websites contributed to the\ntwo classes. Their intersection resulted in only 27 websites. Top 20 websites of non-\nhyperpartisan class contributed to 94% of the total 350K articles, while top 20% of the\nhyperpartisan class contributed to 72% of the remaining 350K articles. There was no\nintersection between the top 20 websites in either classes. The common websites in the\n4.6. BODY OF ARTICLES 41\ntwo classes and their frequency distribution can be seen below in Figure 4.16 . The class\nfrequency distribution can be seen in Figure 4.17 . These common websites are mentioned\ninTable 4.8 .\nFigure 4.16: Websites common to both classes and their contribution to each class\nThe results of classi\ufb01cation using the websites can be seen in Table 4.7 . Although\nthis method is not practical since we need to have a look-up of all the websites and their\npreference to being in either one of the classes. However, their writing styles can be studied\nas sources of hyperpartisan articles.\n4.6 Body of articles\nIn this section we explore how the writing style of the body of an article can be of help in\nautomated classi\ufb01cation using vocabulary features. We make use of n-grams, type token\nratio, readability scores and presence of dominant parts of speech words.\n42 CHAPTER 4. METHODS AND RESULTS\n(a) Frequency distribution of the top 20 of hyperpartisan websites\n(b) Frequency distribution of the top 20 of non-hyperpartisan websites\nFigure 4.17: Class frequency distribution of top 20 of the websites in each class\nTable 4.8: List of websites common to both True and False Hyperpartisan articles\n1. http://elitedaily.com/ 2. http://heavy.com/\n3. http://hollywoodlife.com/ 4. http://ijr.com/\n4.6. BODY OF ARTICLES 43\n5. http://insider.foxnews.com/ 6. http://nypost.com/\n7. http://people.com/ 8. http://theweek.com/\n9. http://truepundit.com/ 10. http://turtleboysports.com/\n11. http://www.bizpacreview.com/ 12. http://www.brandenton.com/\n13. http://www.cbsnews.com/ 14. http://www.complex.com/\n15. http://www.dcclotheslines.com/ 16. http://www.express.co.uk/\n17. http://www.foxbusiness.com/ 18. http://www.foxnews.com/\n19. http://www.glamour.com/ 20. http://www.gq.com/\n21. http://www.idahostatesman.com/ 22. http://www.nytimes.com/\n23. http://www.rollingstone.com/ 24. http://www.snopes.com/\n25. http://www.thegatewayundit.com/ 26. http://www.trueactivist.com/\n27. http://www.washingtonexaminer.com/ 28. http://bearingarms.com/\n29. http://bossip.com/ 30. http://goodmenproject.com/\n31. http://www.circa.com/ 32. http://www.rawstory.com/\n33. http://www.realclearpolitics.com/\n4.6.1 Type Token Ratio (TTR)\nThis vocabulary feature signi\ufb01es the lexical diversity of a block of text. Tokens in a text\nrefers to the total number of words, whereas type represents the number of unique words.\nThus, TTR can formulated as shown in Equation 4.5 .\nTTR =Type\nTokens=Total unique words\nTotal words in the text(4.5)\n44 CHAPTER 4. METHODS AND RESULTS\nTable 4.7: Test accuracy for all algorithms with optimum hyperparameter for URL\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 67.25 1.4948725700378418\nDecision Tree 99.98 0.54\nGaussian Naive Bayes 66.91 0.08\nMultinomial Naive Bayes 49.83 48.57\nRandom Forest 99.98 351.04\nXGBoost 98.75 8.76\nStochastic Gradient Descent 67.25 0.39\nRichards [27] explains that TTR is mainly used in research for child language. Since\nthis ratio signi\ufb01es lexical variety , it can be used in our dataset to see if text has been\nwritten more \ufb02uidly in partisan articles compared to the ones without any bias, which is\nour hypotheses. Since the length of the text can vary among di\ufb00erent articles, we employed\nTTR on a window of 100 words in each article to maintain uniformity.\nRandom forest works the best among other classi\ufb01ers (53%), the results of which can be\nfound in Section C.2 .\n4.6.2 Readability scores\nReadability scores are designed to perceive how di\ufb03cult a passage in the English language\nis to comprehend. There are many tests which use factors like word length, sentence\nlength, and number of syllables to result a score. We used the following di\ufb00erent tests,\nout of which \u2018Automated Readability Index\u2019 (ARI) yielded the best results, which can be\nfound in Table 4.9 .\n\u2022The Flesch Reading Ease Score formula15\n\u2022The Flesch-Kincaid Grade Score Level16\n15https://en.wikipedia.org/wiki/Flesch\u2013Kincaid_readability_testsFlesch_reading_ease\n16https://en.wikipedia.org/wiki/Flesch\u2013Kincaid_readability_testsFlesch\u2013Kincaid_grade_level\n4.6. BODY OF ARTICLES 45\n\u2022The Fog Scale (Gunning FOG Formula)17\n\u2022The SMOG Index18\n\u2022Automated Readability Index19\n\u2022The Coleman-Liau Index20\n\u2022Linsear Write Formula21\n\u2022Dale-Chall Readability Score22\nTable 4.9: Test accuracy using Automated Readability Index (ARI) on the body of text\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression ( C= 1.0) 57.16 1.41\nDecision Tree 57.16 0.12\nGaussian Naive Bayes 56.77 0.05\nXGBoost 57.16 15.19\nRandom Forest 57.16 112.82\nStochastic Gradient Descent 55.83 0.29\nWe used textstat23library for these tests.\n17https://en.wikipedia.org/wiki/Gunning_fog_index\n18https://en.wikipedia.org/wiki/SMOG\n19https://en.wikipedia.org/wiki/Automated_readability_index\n20https://en.wikipedia.org/wiki/Coleman\u2013Liau_index\n21https://en.wikipedia.org/wiki/Linsear_Write\n22https://en.wikipedia.org/wiki/Dale\u2013Chall_readability_formula\n23https://pypi.org/project/textstat/\n46 CHAPTER 4. METHODS AND RESULTS\n4.6.3 n-grams\nAn n-gram is an contiguous block of words of length nin a sentence. The value for n\ncan start from 1 implying unigrams and the word itself, to any number. Large values\nofnare not considered since larger n-grams might rarely occur together in other text\narticles and lead to the problem of data-sparsity. We varied nfrom 1 to 3, i.e., unigrams,\nbigrams and trigrams. We used a TF-IDF implementation of n-grams ranging from 1 to\n3, excluding stopwords, and using the lemmatized form of the word. This method yielded\na good accuracy of 90.99% using logistic regression. This method cannot be practically\ndeployed to unseen texts since n-grams would vary depending on the topic.\n4.6.4 Parts Of Speech\nIn this implementation, we employ parts of speech tags over the body of the articles,\nnamely extracting the adjectives (JJ*) and nouns (NN*). In this section, we further use a\ncombination of both nouns and adjectives to classify our data and see the result.\nNouns\nThere were a total of 316082 nouns in the training corpus out of which we retained the\ntop 80% most occurring 2485 nouns for our analysis. The wordcloud can be visualized in\nFigure 4.18 .\n4.6. BODY OF ARTICLES 47\nFigure 4.18: Wordcloud of the nouns according to their density in the body of training\ncorpus\nAdjectives\nThe total number adjectives found in the training corpus was about 187430. We used\nthe adjectives which contributed to top 80% of their occurrences. This brought down\nthe number of features to a total of 2273 adjectives. The adjectives can be visualized in\nFigure 4.19\n48 CHAPTER 4. METHODS AND RESULTS\nFigure 4.19: Wordcloud of the adjectives according to their density in the body of training\ncorpus\nWe used a combination of nouns and adjectives as well. The results of this analysis\ncan be found in Appendix section Dand can be visualized below in Figure 4.20 .\n4.6. BODY OF ARTICLES 49\nFigure 4.20: Accuracy using adjectives, nouns and both nouns and adjectives\nAs seen, the combination of both nouns and adjectives performed well in almost all\nalgorithms. This method has yielded better results than the rest of the methods.\nSentiment Analysis\nThe context in which a word is used leads us to a better understanding of the stance rather\nthan just the presence. For example, as in the previous section, we studied how presence\nof certain nouns and adjectives could tell us about the subjectivity or the opinion in a text.\nHowever, if an adjective is preceded by a \u2018 not\u2019, the presence of that particular adjective\ndoes not hold any importance.\nThus, in this subsection, we evaluate how exploring the sentiments surrounding the context\nof the usage of a word could be used for classi\ufb01cation.\n50 CHAPTER 4. METHODS AND RESULTS\nFigure 4.21: Sentiment analysis over the context of the word\nAs seen in Figure 4.21 , we form a k-shaped window around our word of interest\nwhich are nouns and adjectives and see if the sentiments of the context can be used as\ngood predictive features. We used TextBlob library24to \ufb01nd the sentiment polarity of\na block of text. The polarity could be negative, neutral or positive and is a \ufb02oat score\nrepresented in a range of [-1.0, 1.0].\nThe results for this can be seen in Appendix section Dand can be visualized in\nFigure 4.22 . Using sentiments of both nouns and adjectives on random forest yielded the\nbest accuracy of 78.13%.\n24https://textblob.readthedocs.io/en/dev/\n4.6. BODY OF ARTICLES 51\nFigure 4.22: Accuracy of sentiment analysis over the context of the word\nChapter 5\nDiscussion\nThe results of all the above experiments were solely evaluated on the initial dataset that\nwas released as a part of Sem Eval Task 4. The data challenge did not publicly release the\ntesting set which was used for their evaluation, and thus the models could not be evaluated\non the actual test dataset. The feature engineering for all the models was strictly done on\nthe training set so as to not lead to any information leakage.\nThe best model barring any topical dependency used presence of nouns and adjectives in\nthe text of article. This served as our \ufb01nal model - using nouns, adjectives, and noun AND\nadjectives. A random forest was used to model the features. We tested the model on web\nsearched articles related to \u2018Midterm Election 2018\u2019. The web articles were scraped using\nthe BING web-search API and the topics can be found in subsection 3.2.2 .\nWe scraped queries related to \u2018United States midterm election\u2019 and found a total of 86 other\nqueries and at most of 100 articles for each query, resulting in a total of 6616 web articles.\nThe following are the results of testing the partisanship of the web-searched articles using\nour best-performing model which uses random forest with nouns and adjectives, as seen in\nTable 5.1 .\n52\n53\nTable 5.1: Result of classifying the midterm elections data\nAlgorithm uses No. of articles (hyperpartisan) No. of articles (non-hyperpartisan)\nNouns 4051 2565\nAdjectives 4258 2358\nNouns & Adjectives 4352 2264\nAs seen in Table 5.1 , there seem to be more than half the articles indicating a hy-\nperpartisan nature. A deeper analysis was done for the \ufb01rst 10 results of the web-search\nqueries. Since users tend to click and read the articles on the \ufb01rst page of the search engine,\nwe thought this analysis would serve a better perspective as to how many articles among\nthe top 10 returned show hyperpartisanship.\nTable 5.2: Result on the top 10 queries of classifying the midterm elections data\nAlgorithm usesNo. of articles\n(hyperpartisan)No. of articles\n(non-hyperpartisan)Mean\n(hyperpartisan)\nNouns 473 307 6.06\nAdjectives 516 264 6.61\nNouns & Adjectives 505 275 6.47\nTable 5.2 shows that on average a total of 6 articles were found to be hyperpartisan\nin nature from the \ufb01rst 10 displayed to the user on their web-search query.\nChapter 6\nConclusions and Future Work\nIn this thesis, we explored the di\ufb00erent linguistic and morphological features of a text\narticle which can be used to distinguish between hyperpartisan and mainstream news.\nThis is an important problem to address since the implications of consuming such biased\ncontent have an impact on society and daily life. We saw how the headlines and the body\nof an article can separately be used to analyze if there are hyperpartisan attributes in\nthem. Our best model worked with using both nouns and adjectives from the training\ncorpus as features. The analysis on the midterm election dataset have also shown that\nmore than half of the articles in it do show hyperpartisan attributes, similar is the result\non the \ufb01rst web pages retrieved. Easy access and retrieval of hyperpartisan articles could\nresult in misinformation overload since an Internet user mostly reads what is displayed\non the \ufb01rst page results of a web search query. Thus, we need to have measures in place\nin order to block propagation of such articles, or even warn the readers of what they are\nabout to consume.\nThere should be general public awareness about hyperpartisanship, and they should\nbe educated to report instances of such articles. Reporting such content could be used in\ncuration of more labeled dataset for training and automated detection. Additional work\ncould include implementing an unsupervised classi\ufb01cation and identifying the cluster traits.\nIdentifying clusters would lead to comprehending the underlying distinguishing as well as\nintersecting patterns between hyperpartisan and mainstream news better.\n54\n55\nIn addition to NLP, we could also employ some domain knowledge like reporting style\nof a news article for better classi\ufb01cation.\nBibliography\n[1]Bing search API. https://azure.microsoft.com/en-us/services/\ncognitive-services/bing-web-search-api/ . Accessed: 2019-04-09.\n[2]Google trends. https://trends.google.com/trends/ . Accessed: 2019-04-09.\n[3]US midterm election 2018. https://en.wikipedia.org/wiki/2018_United_States_\nelections . Accessed: 2019-04-09.\n[4]Russian troll accounts for presidential elections 2016. https://www.huffpost.com/\nentry/russian-trolls-fake-news_n_58dde6bae4b08194e3b8d5c4 . Accessed: 2019-\n04-09.\n[5]Semeval task 4 - hyperpartisan news detection. https://pan.webis.de/semeval19/\nsemeval19-web/index.html . Accessed: 2019-07-01.\n[6]SVM supporting hyperplanes. https://en.wikipedia.org/wiki/Support-vector_\nmachine#/media/File:Svm_separating_hyperplanes_(SVG).svg . Accessed: 2019-\n05-28.\n[7]Hunt Allcott and Matthew Gentzkow. Social media and fake news in the 2016 election.\nJournal of Economic Perspectives , 31(2):211\u201336, May 2017. doi: 10.1257/jep.31.2.211.\nURL http://www.aeaweb.org/articles?id=10.1257/jep.31.2.211 .\n[8]Alessandro Bessi and Emilio Ferrara. Social bots distort the 2016 U.S. Presi-\ndential election online discussion. First Monday , 21(11), 2016. ISSN 13960466.\ndoi: 10.5210/fm.v21i11.7090. URL https://firstmonday.org/ojs/index.php/fm/\narticle/view/7090 .\n56\nBIBLIOGRAPHY 57\n[9]Peter Bourgonje, Julian Moreno Schneider, and Georg Rehm. From clickbait to fake\nnews detection: an approach based on detecting the stance of headlines to articles. In\nProceedings of the EMNLP Workshop: Natural Language Processing meets Journalism ,\npages 84\u201389, 2017.\n[10]Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. Information credibility on\nTwitter. In Proceedings of the 20th International Conference on World Wide Web ,\npages 675\u2013684. ACM, 2011.\n[11]Abhijnan Chakraborty, Bhargavi Paranjape, Sourya Kakarla, and Niloy Ganguly.\nStop clickbait: Detecting and preventing clickbaits in online news media. In 2016\nIEEE/ACM International Conference on Advances in Social Networks Analysis and\nMining (ASONAM) , pages 9\u201316. IEEE, 2016.\n[12]Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Pro-\nceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining, pages=785\u2013794, year=2016, organization=ACM .\n[13]Yu-Chen Chen, Rong-An Shang, and Chen-Yu Kao. The e\ufb00ects of information over-\nload on consumers\u2019 subjective state towards buying decision in the internet shopping\nenvironment. Electronic Commerce Research and Applications , 8(1):48\u201358, 2009.\n[14]Niall J. Conroy, Victoria L. Rubin, and Yimin Chen. Automatic deception detection:\nMethods for \ufb01nding fake news. Proceedings of the Association for Information Science\nand Technology , 52(1):1\u20134, 2015.\n[15]David M. Cook, Benjamin Waugh, Maldini Abdipanah, Omid Hashemi, and\nShaquille Abdul Rahman. Twitter deception and in\ufb02uence: Issues of identity, slack-\ntivism, and puppetry. Journal of Information Warfare , 13(1):58\u201371, 2014.\n58 BIBLIOGRAPHY\n[16]Song Feng, Ritwik Banerjee, and Yejin Choi. Syntactic stylometry for deception detec-\ntion. In Proceedings of the 50th Annual Meeting of the Association for Computational\nLinguistics: Short Papers-Volume 2 , pages 171\u2013175. Association for Computational\nLinguistics, 2012.\n[17]Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro Flam-\nmini. The rise of social bots. Communications of the ACM , 59(7):96\u2013104, 2016.\n[18]Andrew Guess, Brendan Nyhan, and Jason Rei\ufb02er. Selective exposure to misinforma-\ntion: Evidence from the consumption of fake news during the 2016 US presidential\ncampaign. European Research Council , 9, 2018.\n[19]Peter J. Hotez. Texas and its measles epidemics. PLoS medicine , 13(10):e1002153,\n2016.\n[20]Johan Hovold. Naive Bayes spam \ufb01ltering using word-position-based attributes. In\nThe Conference on Email and Anti-Spam (CEAS) , pages 41\u201348, 2005.\n[21]Tibor Kiss and Jan Strunk. Unsupervised multilingual sentence boundary detection.\nComputational Linguistics , 32(4):485\u2013525, 2006.\n[22]Moshe Koppel, Jonathan Schler, and Elisheva Bonchek-Dokow. Measuring di\ufb00eren-\ntiability: Unmasking pseudonymous authors. Journal of Machine Learning Research ,\n8(Jun):1261\u20131276, 2007.\n[23]George Loewenstein. The psychology of curiosity: A review and reinterpretation.\nPsychological Bulletin , 116(1):75, 1994.\n[24]Andrew McCallum and Kamal Nigam. A comparison of event models for Naive Bayes\ntext classi\ufb01cation. In AAAI-98 Workshop on Learning for Text Categorization , volume\n752, pages 41\u201348. Citeseer, 1998.\nBIBLIOGRAPHY 59\n[25]Vangelis Metsis, Ion Androutsopoulos, and Georgios Paliouras. Spam \ufb01ltering with\nNaive Bayes-which Naive Bayes? In The Conference on Email and Anti-Spam\n(CEAS), volume 17, pages 28\u201369. Mountain View, CA, 2006.\n[26]Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendor\ufb00, and Benno\nStein. A stylometric inquiry into hyperpartisan and fake news. arXiv preprint\narXiv:1702.05638 , 2017.\n[27]Brian Richards. Type/token ratios: what do they really tell us? Journal of Child\nLanguage , 14(2):201\u2013209, 1987. doi: 10.1017/S0305000900012885.\n[28]Victoria Rubin, Niall Conroy, Yimin Chen, and Sarah Cornwell. Fake news or truth?\nusing satirical cues to detect potentially misleading news. In Proceedings of the Second\nWorkshop on Computational Approaches to Deception Detection , pages 7\u201317, 2016.\n[29]Karl-Michael Schneider. A comparison of event models for Naive Bayes anti-spam\ne-mail \ufb01ltering. In Proceedings of the Tenth Conference on European Chapter of the\nAssociation for Computational Linguistics-Volume 1 , pages 307\u2013314. Association for\nComputational Linguistics, 2003.\n[30]Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol, Alessandro Flammini,\nand Filippo Menczer. The spread of fake news by social bots. arXiv preprint\narXiv:1707.07592 , pages 96\u2013104, 2017.\n[31]Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. Fake news detection\non social media: A data mining perspective. SIGKDD Explorations Newsletter , 19\n(1):22\u201336, September 2017. ISSN 1931-0145. doi: 10.1145/3137597.3137600. URL\nhttp://doi.acm.org/10.1145/3137597.3137600 .\n[32]Philip J. Stone, Robert F. Bales, J. Zvi Namenwirth, and Daniel M. Ogilvie. The\n60 BIBLIOGRAPHY\ngeneral inquirer: A computer system for content analysis and retrieval based on the\nsentence as a unit of information. Behavioral Science , 7(4):484\u2013498, 1962.\n[33]Andreas Vlachos and Sebastian Riedel. Fact checking: Task de\ufb01nition and dataset\nconstruction. In Proceedings of the ACL Workshop on Language Technologies and\nComputational Social Science , pages 18\u201322, 2014.\n[34]William Yang Wang. \u201cliar, liar pants on \ufb01re\u201d: A new benchmark dataset for fake news\ndetection. arXiv preprint arXiv:1705.00648 , 2017.\n[35]Andrew Ward, L. Ross, E. Reed, E. Turiel, and T. Brown. Naive realism in everyday\nlife: Implications for social con\ufb02ict and misunderstanding. Values and Knowledge ,\npages 103\u2013135, 1997.\n[36]Janyce Wiebe. Learning subjective adjectives from corpora. Association for the Ad-\nvancement of Arti\ufb01cial Intelligence , 20(0):0, 2000.\n[37]Janyce M. Wiebe, Rebecca F. Bruce, and Thomas P. O\u2019Hara. Development and use\nof a gold-standard data set for subjectivity classi\ufb01cations. In Proceedings of the 37th\nAnnual Meeting of the Association for Computational Linguistics , pages 246\u2013253,\n1999.\n[38]Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. Automatic detection of rumor\non Sina Weibo. In Proceedings of the ACM SIGKDD Workshop on Mining Data\nSemantics , page 13. ACM, 2012.\nAppendices\n61\nAppendix A\nTiming and accuracy statistics for\nTF-IDF on headlines of articles\nThe whole dataset was split into a 80-20 train and test split after random shu\ufb04ing. This\nappendix contains the timing and accuracy statistics of hyperparameter tuning on the\nTF-IDF vectors of the headlines of the articles.\nA.1 Logistic Regression\nIn this subsection, we varied di\ufb00erent values of the inverse regularization factor C.\nTable A.1: Test accuracy with variation in Cfor logistic regression\nC Test accuracy (%) Time (sec)\n0.00167.92 4.19\n0.0169.53 6.02\n0.173.68 12.52\n1 77.5 25.25\n1078.6 53.23\n10078.43 97.83\n100078.25 136.75\n62\nA.2. NAIVE BAYES 63\nAs seen from Table A.1 , the test accuracy increases from C= 1.0, and as Cincreases\nthereafter, there is slight improvement in the accuracy with comparable increase in time.\nThus, we select C= 1.0 keeping the accuracy and time trade-o\ufb00 into consideration.\nA.2 Naive Bayes\nIn this subsection, we varied the hyperparameter \u2018 min_df\u2019 for Gaussian Naive Bayes and\nMultinomial Naive Bayes. \u2018 min_df\u2019 is used to limit words below a threshold while building\na vocabulary, and is explained in subsection 4.4.1 .\nA.2.1 Gaussian Naive Bayes\nWe see the results of tuning the hyperparameter \u2018 min_df\u2019 using Gaussian Naive Bayes in\nTable A.2 .\n64APPENDIX A. TIMING AND ACCURACY STATISTICS FOR TF-IDF ON HEADLINES OF\nARTICLES\nTable A.2: Test accuracy with variation in min_df for Gaussian Naive Bayes\nmin_df Test accuracy (%) min_df Test accuracy (%)\n0.0001 74.3 0.007 65.87\n0.0002 73.21 0.008 59.76\n0.0003 72.77 0.009 62.86\n0.0004 72.22 0.01 62.47\n0.0005 71.66 0.02 60.1\n0.0006 71.07 0.03 59.12\n0.0007 70.77 0.04 59\n0.0008 70.62 0.05 58.89\n0.0009 70.4 0.06 58.19\n0.001 70.18 0.07 57.41\n0.002 67.35 0.08 57.41\n0.003 65.69 0.09 57.41\n0.004 64.36 0.1 57.38\n0.005 62.48 0.2 50.44\n0.006 60.43 1 Vocabulary too huge to \ufb01t into memory\n0.007 59.25\nA.2.2 Multinomial Naive Bayes\nWe see the results of tuning the hyperparameter \u2018 min_df\u2019 using Multinomial Naive Bayes\ninTable A.3 .\nA.3. DECISION TREE 65\nTable A.3: Test accuracy with variation in min_df for Gaussian Naive Bayes\nmin_df Test accuracy (%) min_df Test accuracy (%)\n0.0001 73.62 0.001 69.41\n0.01 62.07 0.1 55.63\n1 Vocabulary too huge to \ufb01t into memory\nA.3 Decision Tree\nIn decision trees, we varied the hyperparameter \u2018 min_df\u2019 thus limiting our vocabulary for\ntraining and the rest of the parameters were used as default. The results can be seen in\nTable A.4 .\n66APPENDIX A. TIMING AND ACCURACY STATISTICS FOR TF-IDF ON HEADLINES OF\nARTICLES\nTable A.4: Test accuracy with variation in min_df for decision trees\nmin_df Test accuracy (%) min_df Test accuracy (%)\n0.0001 71.10 0.007 65.87\n0.0002 71 0.008 65.09\n0.0003 70.54 0.009 64.27\n0.0004 70.64 0.01 63.86\n0.0005 70.34 0.02 61.79\n0.0006 70.67 0.03 60.11\n0.0007 65.87 0.04 59.91\n0.0008 65.87 0.05 59.97\n0.0009 64.26 0.06 58.74\n0.001 70.01 0.07 57.73\n0.002 68.95 0.08 57.73\n0.003 67.68 0.09 57.73\n0.004 67.22 0.1 57.64\n0.005 66.83 0.2 50.6\n0.006 66.17 1 67.87\nA.4 Random Forest\nIn random forests, we tuned the hyperparameters \u2018 max_depth \u2019 and \u2018 n_estimators \u2019 for\nmaximum accuracy. The hyperparameter-tuning can be seen in Table A.5 . These hyper-\nparameters are explained in subsection 4.2.5 .\nA.4. RANDOM FOREST 67\nTable A.5: Test accuracy with variation in max_depth andn_estimators for random forest\nn_estimators max_depth Test accuracy (%) n_estimators max_depthTest\naccuracy (%)\n30 10 57.44 3000 10 72.61\n50 20 65.5 3000 20 73.51\n100 10 65.3 3000 30 73.84\n200 10 69.63 3000 40 74.01\n300 10 70.34 3000 50 74.21\n400 10 70.94 3000 60 74.34\n500 10 71.25 4000 10 72.58\n600 10 71.67 5000 10 72.62\n700 10 71.85 6000 10 72.70\n800 10 72.11 7000 10 72.80\n900 10 72.15 8000 10 72.88\n1000 10 72.20 9000 10 72.91\n2000 10 72.53 10000 10 72.94\nAppendix B\nTiming and accuracy statistics for\nheadlines\nIn this section, we tuned the inverse regularization factor Cfor logistic regression, as\nexplained in subsection 4.4.1 . The results are for three di\ufb00erent features of the headlines\nof a news article, mainly its length, the ratio of capitalized words to total words and the\nratio of stop words to total words.\nB.1 Logistic Regression - length of headlines\nIn this subsection, we explored how length of a headline can be used in hyperpartisanship\ndetection, as explained in subsection 4.4.2 , and tuned Cfor maximum accuracy. The result\nof tuning the hyperparameter Ccan be seen in Table B.1 .\n68\nB.2. LOGISTIC REGRESSION - RATIO OF CAPITALIZED WORDS TO TOTAL WORDS 69\nTable B.1: Test accuracy with variation in Cfor logistic regression\nC Test accuracy (%) Time (sec)\n0.00145.62 1.04\n0.0145.62 1.01\n0.145.62 1.01\n145.62 1.01\n1045.62 1.01\n10045.62 1.01\n100045.62 1.01\nB.2 Logistic regression - ratio of capitalized words to\ntotal words\nIn this subsection, we explored how presence of capitalized words can be used in hyperpar-\ntisanship detection, as explained in subsection 4.4.3 , and tuned Cfor maximum accuracy.\nThe result of tuning the hyperparameter Ccan be seen in Table B.2 .\n70 APPENDIX B. TIMING AND ACCURACY STATISTICS FOR HEADLINES\nTable B.2: Test accuracy with variation in Cfor logistic regression\nC Test accuracy (%) Time (sec)\n0.00149.06 1.01\n0.0149.06 0.64\n0.149.06 0.65\n149.06 0.64\n1049.06 0.64\n10049.06 1.26\n100049.06 0.64\nB.3 Logistic regression - ratio of stop words to total\nwords\nInthissubsection, weexploredhowpresenceofstopwordscanbeusedinhyperpartisanship\ndetection, as explained in subsection 4.4.3 , and tuned Cfor maximum accuracy. The result\nof tuning the hyperparameter Ccan be seen in Table B.3 .\nTable B.3: Test accuracy with variation in Cfor logistic regression\nC Test accuracy (%) Time (sec)\n0.00156.17 0.53\n0.0156.17 0.53\n0.156.17 0.53\n156.17 0.53\n1056.17 0.53\n10056.17 0.53\n10000.56 0.53\nAppendix C\nTiming and accuracy statistics for\nwebsites and TTR\nIn this section, we tuned the inverse regularization factor Con the websites of the news\narticles and the Type Token Ratio (TTR).\nC.1 Logistic Regression - URLs\nIn this subsection, we varied Cfor maximum accuracy on URLs of the websites of the\nnews articles. More about the websites can be found in Section 4.5 . The result can be\nseen inTable C.1 .\n71\n72 APPENDIX C. TIMING AND ACCURACY STATISTICS FOR WEBSITES AND TTR\nTable C.1: Test accuracy with variation in Cfor logistic regression\nC Test accuracy (%) Time (sec)\n0.00167.25 1.44\n0.0167.25 1.49\n0.167.25 1.58\n167.25 1.49\n1067.25 1.56\n10067.25 1.43\n100067.25 1.43\nC.2 Accuracy and Timing statistic using TTR\nIn this subsection, we report the accuracy results of all the algorithms using the TTR of\nthe body of the news articles. More about TTR can be found in subsection 4.6.1 . The\nresult can be found in Table C.2 .\nTable C.2: Test accuracy using TTR on all the algorithms\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 51.71 1.30\nDecision Tree 52.69 7.27\nGaussian Naive Bayes 51.43 0.19\nXGBoost 52.09 17.37\nStochastic Gradient Classi\ufb01er 50.39 0.48\nRandom Forest Classi\ufb01er 53.43 4469.11\nAppendix D\nTiming and accuracy statistics for\nparts of speech on body of articles\nIn this section, we list the timing and accuracy statistics of using nouns and adjectives\nin the analysis of hyperpartisanship in news articles. More about this can be read in\nsubsection 4.4.4 .\nD.1 Adjectives\nInTable D.1 , we see the timing and accuracy statistics of the part of speech analysis of\nadjectives over the body of the news articles.\n73\n74APPENDIX D. TIMING AND ACCURACY STATISTICS FOR PARTS OF SPEECH ON BODY OF\nARTICLES\nTable D.1: Test accuracy using adjectives in the body of text\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 84.38 64.14\nDecision Tree 82.08 527.21\nGaussian Naive Bayes 68.01 31.13\nMultinomial Naive Bayes 78.01 2.75\nXGBoost 82.95 2032.22\nStochastic Gradient Classi\ufb01er 83.68 22.41\nRandom Forest Classi\ufb01er 87.19 7501.19\nD.2 Nouns\nInTable D.2 , we see the timing and accuracy statistics of the part of speech analysis of\nnouns over the body of the news articles.\nTable D.2: Test accuracy using nouns in the body of text\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 88.25 93.97\nDecision Tree 85.31 570.75\nGaussian Naive Bayes 72.56 40.06\nMultinomial Naive Bayes 79.27 3.74\nXGBoost 86.06 1900.49\nStochastic Gradient Classi\ufb01er 87.58 21.74\nRandom Forest Classi\ufb01er 90.14 7028.27\nD.3. NOUNS AND ADJECTIVES 75\nD.3 Nouns and Adjectives\nInTable D.3 , we see the timing and accuracy statistics of the parts of speech analysis of\nboth nouns and adjectives over the body of the news articles.\nTable D.3: Test accuracy using both nouns and adjectives in the body of text\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 88.98 154.86\nDecision Tree 85.56 1175.81\nGaussian Naive Bayes 71.55 69.26\nMultinomial Naive Bayes 79.45 5.61\nXGBoost 86.07 3722.14\nStochastic Gradient Classi\ufb01er 88.04 48.88\nRandom Forest Classi\ufb01er 89.96 8931.88\nAppendix E\nTiming and accuracy statistics for\nsentiment analysis on parts of speech\nof body of articles\nIn this section, we list the timing and accuracy statistics of using sentiments of both nouns\nand adjectives in the analysis of hyperpartisanship in news articles. More about this can\nbe read in Section 4.6.4 .\nE.1 Nouns\nInTable E.1 , we see the timing and accuracy statistics of the sentimental analysis of nouns\nover the body of the news articles.\n76\nE.2. ADJECTIVES 77\nTable E.1: Test accuracy using sentiments of nouns in the body of text\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 65.30 10.13\nDecision Tree 70.00 251.56\nGaussian Naive Bayes 66.33 6.35\nXGBoost 72.99 496.21\nStochastic Gradient Classi\ufb01er 65.25 5.41\nRandom Forest Classi\ufb01er 78.09 1579.85\nE.2 Adjectives\nInTable E.2 , we see the timing and accuracy statistics of the sentimental analysis of\nadjectives over the body of the news articles.\nTable E.2: Test accuracy using sentiments of adjectives in the body of text\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 66.24 12.18\nDecision Tree 67.97 237.83\nGaussian Naive Bayes 64.38 7.9\nXGBoost 71.94 469.69\nStochastic Gradient Classi\ufb01er 64.74 4.92\nRandom Forest Classi\ufb01er 76.27 1525.71\n78APPENDIX E. TIMING AND ACCURACY STATISTICS FOR SENTIMENT ANALYSIS ON PARTS\nOF SPEECH OF BODY OF ARTICLES\nE.3 Nouns and Adjectives\nInTable E.3 , we see the timing and accuracy statistics of the sentimental analysis of nouns\nand adjectives over the body of the news articles.\nTable E.3: Test accuracy using sentiments of both nouns and adjectives in the body of\ntext\nAlgorithm Test accuracy (%) Time (sec)\nLogistic Regression 68.18 14.05\nDecision Tree 70.05 419.15\nGaussian Naive Bayes 66.45 12.34\nXGBoost 71.94 469.69\nStochastic Gradient Classi\ufb01er 73.43 956.77\nRandom Forest Classi\ufb01er 78.13 2201.12", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Hyperpartisanship in web searched articles", "author": ["AA Sen"], "pub_year": "2019", "venue": "NA", "abstract": "News consumption is primarily done through online news media outlets and social media.  There has been a recent rise in both fake news generation, and consumption. Fake news"}, "filled": false, "gsrank": 306, "pub_url": "https://vtechworks.lib.vt.edu/items/bc176070-349a-4b4d-896c-607912726af3", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:2M7Tp0lmWHgJ:scholar.google.com/&output=cite&scirp=305&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D300%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=2M7Tp0lmWHgJ&ei=OrWsaI6ND8DZieoPqdqh8QU&json=", "num_citations": 2, "citedby_url": "/scholar?cites=8671793549036211928&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:2M7Tp0lmWHgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://vtechworks.lib.vt.edu/bitstreams/88b6456e-278a-4932-b963-09a13336988f/download"}}, {"title": "Interactively learning social media representations improves news source factuality detection", "year": "2023", "pdf_data": "Interactively Learning Social Media Representations Improves News\nSource Factuality Detection\nNikhil Mehta\nDepartment of Computer Science\nPurdue University\nWest Lafayette, IN 47907\nmehta52@purdue.eduDan Goldwasser\nDepartment of Computer Science\nPurdue University\nWest Lafayette, IN 47907\ndgoldwas@purdue.edu\nAbstract\nThe rise of social media has enabled the\nwidespread propagation of fake news, text that\nis published with an intent to spread misinfor-\nmation and sway beliefs. Rapidly detecting\nfake news, especially as new events arise, is\nimportant to prevent misinformation.\nWhile prior works have tackled this problem us-\ning supervised learning systems, automatedly\nmodeling the complexities of the social media\nlandscape that enables the spread of fake news\nis challenging. On the contrary, having humans\nfact check all news is not scalable. Thus, in this\npaper, we propose to approach this problem in-\nteractively , where humans can interact to help\nan automated system learn a better social media\nrepresentation quality. On real world events,\nour experiments show performance improve-\nments in detecting factuality of news sources,\neven after few human interactions.\n1 Introduction\nOver the last decade, we have witnessed a rise in\nthe proliferation of \u201cfake news\u201d (Lazer et al., 2018),\nnews content which lacks the journalistic standards\nensuring its quality while maintaining its appear-\nance. Social media is flooded with inaccurate and\nincomplete information (V osoughi et al., 2018), and\ncombating this has attracted significant research in-\nterest (Nguyen et al., 2020). However, this is still\na hard task, particularly on unseen topics. In this\npaper, rather than annotating data to learn these top-\nics, we propose to use quick human interactions\nto characterize social media, allowing us to learn a\nbetter representation, and detect factuality better.\nInstead of fact checking individual articles, some\nworks (Baly et al., 2020) focus on fact-checking\nsources. While still requiring automated systems\ndue to the number of sources online, source fac-\ntuality detection can be more scalable, as sources\noften publish content of similar factuality. Follow-\ning this, we focus on capturing the factuality levels\nof sources: high, mixed, low .One concept underlying methods that aim to\nexploit social information for identifying the fac-\ntuality of news sources is the social homophily\nprinciple (McPherson et al., 2001), which cap-\ntures the tendency of members of the same social\ngroup to hold similar views and content prefer-\nences. This often leads to the formation of \u201cecho\nchambers\u201d (Jamieson and Cappella, 2008; Quat-\ntrociocchi et al., 2016), tightly-knit \u201cinformation\ncommunities\u201d that have little interaction with other\ncommunities holding different views. Prior work\nshows how similar news, particularly misinforma-\ntion, tends to spread more in some of these tightly-\nknit information communities (Bessi et al., 2016).\nThus, identifying them can provide the needed in-\nformation for capturing the factuality of sources\n(communities spreading mostly low factuality con-\ntent in the past are likely to spread low factuality\ncontent in the future). In this work, we first capture\nsocial information in an information graph, model-\ning it via a R-GCN (Schlichtkrull et al., 2018).\nMany approaches to detect news factuality are\noften studied in unrealistic settings, as their suc-\ncess hinges on test data being similar to or re-\nlated to training data. However, a more realistic\nsetup would examine whether a system would be\nable to generalize to emerging news events: These\nevents introduce different narratives, users, and\nnews sources, that are unseen and do not interact\nwith training content; i.e. test users don\u2019t follow\ntrain users and test graph nodes aren\u2019t connected\nto train nodes. In this paper, to simulate these set-\ntings, we collected new data, consisting of the arti-\ncles published around specific news events (Black\nLives Matter and Climate Change - see Sec 5.1),\ntheir sources, and social context. We applied a re-\ncent strong baseline system (Mehta et al., 2022),\ntrained over data sampled from past events, and it\nresulted in significant degradation in performance\non the new events ( \u223c22% Acc, 19% Macro-F1).\nOur main observation in this paper is that evenarXiv:2309.14966v1  [cs.CL]  26 Sep 2023\nFigure 1: Our framework overview: Adapting News Source Factuality Detection to Emerging News Events by Interactively\nCharacterizing the Social Media Context of News Articles and Their Sources . (Key: U = Users, A = Articles, S = Sources,\nGreen/H = High Factuality, Red/L = Low Factuality). From the learned graph model (b), we find pairs of inconsistent users by\nclustering all user embeddings and looking for conflicting factuality labels (c) (L = low; H = high factuality). Here, the High\nFactuality user doesn\u2019t match the mostly Low Factuality cluster. We then build sub-graphs from these pairs of mismatched users\nand their community to show human interactors (d), who create new edges based on content similarity. This is far simpler and\nquicker than identifying factuality, as humans only need to identify which nodes are similar in content. Based on the interactions,\nwe create edges in the broad event graph (a) to do better news source factuality detection (either directly or with more training).\nin these challenging settings, the social homophily\nprinciple can be exploited to better detect source\nfactuality, if the system can identify relevant\ninformation communities over users engaging\nwith the new content . This is since users that are\npart of an information community that propagates\nfake news, are likely to do so as well. As we later\nshow, automatically detecting the factuality of news\nsources is difficult, particularly on emerging news\nevents. Instead , we suggest an interactive learn-\ning protocol , in which human judgements dynam-\nically help the model identify these communities.\nAs humans analyzing all emerging news content\nis clearly infeasible, we propose a novel sampling\nmethod for interactions, based on resolving incon-\nsistencies in the model\u2019s graph-based social repre-\nsentation. Specifically, we identify pairs of users\nthat are clustered in the same community, but have\nconflicting factuality predictions, as this indicates\ninconsistency. We create small sub-graphs corre-\nsponding to the social and content preferences of\nthese users and other members of the community,\nand ask the humans to resolve the conflict: Based\non their profile descriptions, social relations and\narticles endorsed, is it likely (given the principle\nof social homophily) that these two users belong\nto the same community? The human judgements\nprovide rich feedback for this question, by adding\nedges to the graph, which connect users, articles,\nand sources. These edges result in cleaner informa-\ntion communities, which alleviate the difficulty of\nthe source classification task. Fig. 1 describes this.\nIn summary, we make the following contribu-\ntions. (1) We are the first to formulate the task of\ninteractive news source factuality detection by\ncharacterizing social context, and implement an in-\nteraction tool for supporting this. (2) We suggest anovel sampling approach for reducing the number\nof human judgements needed by focusing on social\ninconsistencies. (3) We focus on one of the most\nchallenging settings of news source factuality de-\ntection in emerging news events, collect data, and\nperform experiments showing how minimal, quick\ninteractions can lead to performance improvements\non unseen data. More generally, we propose an in-\nteractive framework to learn stronger information\ncommunities, and apply it to improve news source\nfactuality detection. In the future, it can also be\napplied to other social media analysis tasks.\nSec. 3 describes our graph model, Sec. 4 our\nnovel protocol to incorporate interactions, Sec. 5\nshows results, and Sec. 6 analyzes them.\n2 Related Work\nDetecting fake news on social media is a popular\nresearch topic, studied in supervised learning (Has-\nsan et al., 2017; P\u00e9rez-Rosas et al., 2018; V olkova\nand Jang, 2018; Ma et al., 2018; Shu et al., 2019a,b;\nKim et al., 2019), Graphs (Han et al., 2020; Li et al.,\n2022), zero-shot (Wright et al., 2022), dialogue\n(Gupta et al., 2022), cross-domain (Huang et al.,\n2021; Zhu et al., 2022a,b; Mosallanezhad et al.,\n2022), and low-resource (Lin et al., 2022) settings.\nOne of the most challenging yet most critical so-\ncial context fake news detection settings is the early\ndetection of it, where test data has new users, arti-\ncles, and sources, that do not interact with training\ndata. Recently, researchers have been working on\nthis task, especially at the article/tweet level. Liu\nand Wu classify news propagation paths, Yuan et al.\nmodel user credibility, while Konkobo et al. built a\nsemi-supervised classifier. In our work, we focus\non this challenging early detection setting, specifi-\ncally to identify the factuality of news sources. We\nshow how our interactive setup can be useful, even\nin these settings. If combined with other early de-\ntection methods, our framework may lead to further\ngains, and we leave this for future work.\nUsing human interactions to improve models has\nalso been popular recently (Brantley et al., 2021),\nin scenarios such as active learning (Blok et al.,\n2021), or humans providing general system feed-\nback (Tandon et al., 2022). Other works exploit hu-\nman feedback for concept discovery (Pacheco et al.,\n2022, 2023) by communicating human-level sym-\nbolic knowledge (Pacheco and Goldwasser, 2021).\nIn contrast, our interactions enable stronger general\nmodels, and generalization to new unseen scenar-\nios.\nSocial homophily has been used to better many\nNLP tasks, like sentiment analysis, entity linking,\nand fake news. (West et al., 2014; Yang et al., 2016;\nMehta et al., 2022). Particularly, prior work shows\nhow misinformation (and similar news) spreads\nmore in tightly-knit communities, motivating our\nidea that if we use humans to increase homophily\nand build better information communities, we can\ndetect facutality better (Bessi et al., 2016; Halber-\nstam and Knight, 2016; Cinelli et al., 2021).\n3 Graph Model\nSimilar to Mehta et al., we view fake news source\ndetection as reasoning over relationships between\nsources, articles, and users in an information graph.\nWe use their graph model1, briefly explaining it in\nthis sec. Sec. 4 explains our interactive protocol.\nThe model uses a heterogeneous graph to cap-\nture the interaction between social information and\nnews content, and a Relational Graph Convolu-\ntional Network (R-GCN) to encode it. The R-GCN\nallows us to create contextualized node represen-\ntations for factuality prediction. For example, one\nway sources are represented is by the articles they\npublish (which in turn are also represented by their\nrelationships to other nodes).\nGraph Creation : The graph (see: Fig.1a) con-\nsists of 3 types of nodes, each with feature vectors\n(details: App. A.3.1): (1) S, the news sources ,\nare our classification targets. (2) A, the arti-\ncles published by these sources, (3) U, the Twit-\nterusers . Sources are first connected to articles\nthey publish. Social context is added via Twitter\nusers that interact/connect to sources/ articles/other\n1https://github.com/hockeybro12/FakeNews_\nInference_Operatorsusers. These users provide the means for fake (and\nreal) news spread on social media: (1) Following\nSources/Users: Users are connected to sources and\nusers they follow. (2) Propagating Articles: Arti-\ncles are connected to users that tweet its title/link.\nGraph Embedding: As in Mehta et al., we train\na R-GCN (Schlichtkrull et al., 2018) to learn graph\nembeddings, which will be later used to determine\nwhere human interaction may be beneficial. We op-\ntimize the Classification objective of News Source\nFactuality Detection (categorical cross-entropy).\nTo predict labels, we pass the source node embed-\ndings from R-GCN through the Softmax activa-\ntion.\n4 Interactive Protocol\nWe hypothesize that understanding content and the\ncontext it is provided in is critical to detecting fake\nnews. Specifically, identifying information commu-\nnities of users, sources, and articles based on their\ncontent preferences can be helpful, as a community\nthat mostly shares fake news in the past, is likely\nto share fake news in the future. Further, users that\njoin this community are likely to share beliefs of\nthe community, and thus also share fake news.\nUnfortunately, understanding content on social\nmedia and using it to identify information commu-\nnities is challenging for AI agents. It becomes more\ndifficult as new events with new relationships arise,\nas the agent does not have enough data to determine\nwhat is fake news. This makes the early detection\nof fake news difficult (see Sec. 5.3). On the other\nhand, educated humans can more easily understand\nrelationships on social media, even in new events,\nas they can better analyze social interactions. Thus,\nhumans can clear up model confusion by helping\nthe model identify the information communities or\nmake existing ones bigger. For example, after read-\ning a sample of tweets from users discussing a new\nevent, humans can quickly determine if the users\nare offering the same perspectives, and should be\nin the same community. This knowledge can help\nthe agent model these users and other content they\ninteract with better. As we later show experimen-\ntally, human interactions like these enables us to\nbuild strong information communities, which helps\nthe agent, particularly with the early detection of\nnews sources factuality on new news events.\nUnlike automated agents, humans cannot ana-\nlyze all content that pertains to a new event, as it is\ntoo massive. Instead, due to the highly connected\nstructure of social media, small amounts of inter-\nactions done in the right places can make signif-\nicant impact , as the added information can flow\nthroughout the information graph. Thus, we first\ndiscuss in Sec 4.1 how we determine what content\nhumans should interact with and what interactions\nthey should make (i.e. forming/strengthening infor-\nmation communities). Then, in Sec 4.2, we explain\nhow we can incorporate those interactions back into\nthe model to achieve performance improvements.\n4.1 Soliciting Human Interactions\nNow, we discuss 3 different protocols to identify\nthe data on which humans should interact, and then\nwhat they should do. In general, we want humans\nto analyze a sub-graph of the broad information\ngraph characterizing the new event. Given this sub-\ngraph, we ask humans to help form information\ncommunities by characterizing the content in the\ngraph based on similarity, i.e. identify if two users\nare similar, two articles offer the same perspective,\netc. This is done by asking humans a series of\nquestions (details : App. B) which enables them to\nconnect nodes in the sub-graph based on content\npreferences, via a graphical interface we developed.\nAn ex. is shown in App. Fig 2. We then replicate\nthese connections in the broad information graph.\nIdentifying the sub-graph that will benefit the\nmost from interactions is critical to getting the most\nvalue out of each interaction. We build the sub-\ngraphs by first choosing a pair of users, as our end\ngoal is to build stronger user information communi-\nties. We explore three different protocols for doing\nthis in 4.1.1 and Sec 4.1.2. After finding these pairs\nof users, we build the sub-graph to show humans\nby including these users and their direct connec-\ntions in the graph. This includes the articles they\npropagate, other users that propagate those articles,\nthe sources that publish those articles, and up to 3\n\u201cinfluencers\u201d (users with over 1000 followers) that\none of these users follows. For each node in the\nsub-graph, we populate it with relevant informa-\ntion to enable the human interactors to understand\ncontent. For ex:, user/source nodes show user bio,\ntweets, etc. Article nodes show article publish date,\nheadline, and first paragraph. Details: App B.\n4.1.1 Baselines\nWe have two baselines for selecting pairs of users.\n(1) Random , users at random. (2) Model Confu-\nsion takes an active learning -like approach, and\nchooses users based on a label confusion criterion,calculated by propagating the softmax score of the\nsource prediction downwards to get user confu-\nsion. Specifically, to get this score, we look at all\nthe sources the user directly interacts with (arti-\ncles they propagate and sources they follow), and\nthen take the weighted average of those source\u2019s\nSoftmax predicted label to be the user score (thus\napproximating user confidence). For example, a\nuser interacting with 3 articles predicted with low\nfactuality score of 0.7 and 1 source with high fac-\ntuality score 0.9 will have confidence 0.75.\n4.1.2 Social vs. Factuality Mismatch Criterion\nNow, we discuss our novel protocol to determine\nthe pairs of users, seen also in Alg 1. It is de-\nsigned around one of the key ideas in this paper,\nhomophily, the tendency of users with similar so-\ncial preferences to have similar content preferences.\nOur graph model learns to represent both, by creat-\ning node embeddings which capture users\u2019 similari-\nties, and learning classifiers used for characterizing\ncontent by identifying factuality. Intuitively, our\nprotocol is designed to identify users, that based on\nthe current model parameters, break the homophily\nprinciple. These users are part of the same social\ngroup while at the same time have different factu-\nality predictions, and thus likely different content\npreferences. When this is true, the model may not\nhave clearly understood the content preferences of\nthese users, which a human can help clear up.\nTo identify these pairs of users, we first need\nto compute factuality labels for each user. As the\nmodel is trained for source classification, we de-\nsigned a heuristic to use source labels to compute\nuser labels: We assign users the label of the most\ncommon predicted label of the sources/articles the\nuser is directly connected to. For ex:, a user follow-\ning 3 low factuality sources and tweeting 1 mixed\nfactuality article is assigned a low factuality label,\nas it interacts with more low factuality content.\nAfter computing user labels, we need to find\ngroups of similar users, which we do by k-means\nclustering all users in the event graph using their\nmodel embeddings (Alg 1: 3). Then, we assign\neach cluster a factuality label based on the most\nfrequently occurring user factuality label in that\ncluster (Alg 1: 5). Finally, we choose pairs of users\nthat are in the same cluster, but one has a different\nlabel than the cluster label, as the model thinks they\nare similar but predicts their factuality differently,\nwhich indicates a sign of confusion (Alg 1: 7-9).\nAlgorithm 1 Social vs. Factuality Mismatch\n1:Input: U(Users), UE(Graph User Embeddings), F\n(User Factuality Scores), P(Empty List)\n2:Output: P(Pairs of Users To Build Graphs)\n3:c1...k=k-means (UE)K-means Cluster all Users based on\nGraph User Embeddings\n4:for all i= 1, . . . , k do{for each cluster}\n5: cl= max 0\u2264u\u2264nFuAssign Cluster the Label of the\nmost common user\n6: for all j= 1, . . . , n do{for each user}\n7: ifFj\u0338=clthen {If user label \u0338=cluster label}\n8: Uk=rand(U)where (Fj\u0338=Fk)\u2227(Fk\u2208\ncl)Choose a random user in the cluster with a\ndifferent label\n9: P.insert ((Uj, Uk))Add User Pair to List\n10: end if\n11: end for\n12:end for\n13:return P(Pairs of Users)\n4.2 Incorporating Human Interactions\nHumans interact by making new connections on the\nsub-graphs. We then utilize the interactions by con-\nnecting the appropriate nodes in the broader event\ngraph. Our goal is to show how human interactions\nallow us to have a better model that performs well\nwith and without further interactions.\nWe focus on the challenging fully inductive set-\nting: where all test set nodes are not seen at train-\ning and are also not connected to training set nodes.\nFurther, we evaluate the important setting of early\ndetection of fake news, where test data comes from\nunseen emerging events. As we show in Sec 5.3, in\nthese settings, existing models struggle.\nWe evaluate 3 interaction-based protocols. The\nthree protocols have the same starting point, a\ngraph-based factuality classification system trained\nover an established dataset (Baly et al., 2020). The\nprotocols are designed to show how interactions\ncan enhance that initial system when making pre-\ndictions on data from unseen emerging events, and\nare organized in order of increasing effort required\nand increasing performance. All involve perform-\ning interactions on up to two different data sets\n(each corresponding to a different emerging event,\nsee Sec 5.1). Since some of the protocols we in-\ntroduce update the parameters of the model after\ninteraction, we collect data for two events to en-\nsure that all protocols can be evaluated in the fully\ninductive settings on the second event data (i.e.,\nrelying on interactions alone without training).\nWe hereby refer to the first event as E1, and the\nsecond as E2. Each event is further split into inter-\naction and no interaction halves (ex: E1-1/E1-2),\nfor comparison and model training (see below).(1) Fully Inductive: In the first protocol, hu-\nmans interact on the interaction halves of E1and\nE2, and then the interactions are incorporated,\nwithout any additional training. This is the most\nchallenging, but no extra effort is necessary for\nperformance improvements.\n(2) Interactions Amplify Model Learning:\nHere, our goal is to show how interactions can\nhelp us learn a stronger model that performs well\nwithout interactions. Thus, we interact on the inter-\naction half of E1(half so we can evaluate how we\ndo on the same event without interactions), use it to\ntrain the model, and evaluate it on E2(future event,\nfully inductive) without any additional interactions.\n(3) Learning to Incorporate Interactions: In\nthis protocol, we show how training the model after\ninteractions allows the model to learn how to better\nincorporate them. This enables it to do even better\nwhen interactions are provided on future events.\nTo do this, as above, we interact on half of E1\nand train on it. Then, we evaluate E2on both the\ninteraction and non-interaction half. Both halves of\nE2are connected, so although interactions are only\non half, information can propagate via the graph.\n4.3 Simulating Human Interactions\nDue to constraints involved with human interaction\ntime/cost, to evaluate our models we also designed\na heuristic to simulate humans: We hypothesize\nthat two users are similar if they have the same gold\nfactuality label. While our interaction approach pri-\noritizes content preferences for interactions, iden-\ntifying this automatically is difficult, so this is an\napproximation. Thus, doing human interactions at\nthe scale of simulated ones could perform better,\nand we leave it for future work. To get user gold\nfactuality labels, we use the same heuristic as in\nSec 4.1 (assinging users the label of the source they\nare most often connected to). Note that in this simu-\nlated interaction setting, we are using the test set to\ndetermine user labels, so this setup is not realistic.\n5 Experiments\n5.1 Dataset and Collection\nTo evaluate our model\u2019s ability to predict the factu-\nality of news medium, we used the Media Bias/Fact\nCheck dataset (Baly et al., 2018). We expand it by\nscraping additional sources from Media Bias/Fact\nCheck2, for better coverage of recent events and\nincreasing the number of sources for evaluation.\n2https://mediabiasfactcheck.com\nModel Baly\nAcc.Baly\nF1E1-1\nAccE1-1\nF1\nBaly 71.52 67.25 - -\nMehta R-GCN 68.90 63.72 - -\nMehta BEST 72.55 66.89 - -\nBL: Mehta R-GCN 66.04 54.20 43.21 34.44\nTable 1: Baseline results on Baly (Baly et al., 2020) and an\ninductive future BLM event E1-1(not seen or connected to\nthe training graph). Baseline (BL) is the strong graph\nclassification model from (Mehta et al., 2022) (Mehta\nR-GCN) that was competitive with the state of the art ((Mehta\net al., 2022) - Mehta BEST). Even with this, performance\nsignificantly worsens on E1, showing that detecting fake\nnews on future events inductively is challenging. BL: Mehta\nR-GCN was trained on a smaller (Baly et al., 2020) dataset,\nas some sources were used for evaluation, which is why the\nperformance is slightly lower.\nIdentically to Baly et al., we labeled the sources on\na 3-point factuality scale: high,mixed , orlow.\nOur goal in this paper is to show how human in-\nteractions can help news source factuality detection\non new events, where even strong models strug-\ngle (Sec 5.3). To do this, we evaluated our model\nontwo broad events :Black Lives Matter (BLM)\nandClimate Change (CLM) . For each, we scraped\ndata from Twitter over 3 time periods (01/02/2019 -\n06/01/19; 06/02/19 - 01/1/21; 02/02/21 - 05/06/22),\neach of which additionally cover many different\nsub-events. For each time period, we created a fully\ninductive graph, consisting of at least 99 sources\nand their metadata. None of these graphs are con-\nnected to each other in any way and no nodes in any\nof them are common with each other or the train-\ning set - making our test settings fully inductive,\nand very challenging. To ensure this inductive set-\nting, when collecting data for future time periods,\nwe made sure not to include sources/users/articles\nthat we already used in previous time periods, even\nif they propagated content in those future periods.\nCombined with Baly et al., we used the first time\nperiod for training, to teach the model how to iden-\ntify fake news in general and as it pertains to an\nevent. We used the 2nd and 3rd time period as\nE1andE2in the protocols discussed in Sec 4.2.\nDetails (statistics, etc.): A.2. We release our code\nand data.3\n5.2 Evaluation Method\nFor both BLM and CLM, we evaluate on the two\ninductive sub-events ( E1,E2) collected in Sec 5.1.\nThe interaction half is referred to with a - 1and\n3https://github.com/hockeybro12/Fake_News_\nInteractive_DetectionModel E2-1 Acc E2-1 F1\nRandom Users 35.21 29.99\nConfused Users 36.61 32.72\nUser Clustering 42.10 32.22\nTable 2: Ablation study on our methods for choosing\ninteractions on E2-1. It is clear that finding users based on\nclustering and then factuality mismatch is best.\nthe non-interaction with - 2, for ex: E1-1. For fair\ncomparison, each data split, i.e. E1-1, is the same\nacross all evaluations. We report results on Accu-\nracy, Macro F1 (the dataset is unbalanced), and the\ntotal number of edges added by all interactions.\nWe evaluated 3 settings, the first 2 are simulated\nusing gold test set labels (see Sec 4.3), while the\nlast is done by humans: (1) Interaction Graphs\nOnly: Edges are added only between users in inter-\naction graphs. (2) X% of Data: Edges are added\nbetween X% of all possible users that have the\nsame label in the test set that we run interactions\non (not only users in interaction sub-graphs). X\nis 100%, 75%, or 25%. (3) Human Interactions :\nFor BLM, we evaluate on two separate versions,\neach featuring a different source set (and social\nmedia data). This section shows results on the first\nversion, when one human interacts on 20 graphs\nper data split (details in B.1, B.2). The appendix\nshows the second version of BLM with 3 different\ninteractors , showing the same trends. For space,\nthese interaction results/details (including agree-\nment) are in B.2.3. This section also evaluates\nClimate Change, with 2 interactors interacting on\n10 sub-graphs per data split. (for detailed CLM\nresults, see App. C). The human interaction results\nare also the most realistic evaluation setting, as they\ndon\u2019t use any gold test set labels, like the simulated\ninteractions do.\n5.3 Baselines\nWe trained our baseline model, from Sec. 3, for\nSource Factuality Detection on Baly et al. and the\nfirst event, where it achieved strong performance,\nsimilar to SOTA (Mehta et al., 2022) (we use the\nsame data and methodology) and other baselines\n(Baly et al., 2020) (SVM). However, when evalu-\nated inductively on a BLM event that was published\nafter dates the training data was collected from -\ni.e.E1-1- performance significantly worsened\n(see Table 1). This validated our hypothesis that\nstrong models, even if trained on generic and event\nspecific data, do not translate well to future events.\nThus, we propose to use our interactive protocol.\nModel E1-1\nAccE1-1\nF1E1-2\nAccE1-2\nF1E2-1\nAccE2-1\nF1#\nEdges\nBLM No Interactions 43.21 34.44 37.93 30.70 35.21 27.65 -\nCLM No Interactions 40.16 32.77 39.65 31.86 34.88 30.93 -\nBLM Sim. Interactions on Sub-Graphs Only 44.54 36.45 37.93 30.70 42.10 32.22 2,162\nBLM Sim. Interactions on 100% of Data in E1-1 + E2-1 49.20 40.52 37.93 30.70 44.73 36.82 133,336\nBLM Sim. Interactions on 75% of Data in E1-1 + E2-1 46.03 38.05 37.93 30.70 50.00 40.50 74,414\nBLM Sim. Interactions on 25% of Data in E1-1 + E1-2 46.03 37.65 37.93 30.70 42.10 32.65 8,266\nBLM Human Interactions in E1-1 + E2-1 44.44 35.96 37.93 30.70 44.73 30.03 84\nCLM Human Interactions in E1-1 + E2-1 46.72 43.94 39.65 31.86 39.53 36.95 47\nTable 3: Protocol 1: Interactions results on BLM and Climate Change (CLM) in the difficult, inductive, no training setting. E1\nand E2 are the two separate, inductive graphs. E1-1 is the first half that receives interactions, and E1-2 is the second half that\ndoesn\u2019t. E2-1 (first half E2) also receives interactions, but it\u2019s dev set is not used to select the model. With a minimal number of\nadded edges, human interactions achieve performance improvements in these difficult, inductive settings, with no extra training\n(compared to No Interactions). Ex: results improve on human BLM E2-1 ( \u223c9.5% Acc.) Sim. settings also show improvements.\nModel E1-2\nAccE1-2\nF1E2-1\nAccE2-1\nF1#\nEdges\nBLM No Interactions 37.93 30.70 35.21 27.65 -\nBLM No Interactions Train 64.86 66.91 42.10 40.10 -\nCLM No Interactions Train 49.29 44.84 44.77 42.35 -\nBLM Sim. Interactions on Sub-Graphs Only 62.16 62.95 43.66 29.47 2,162\nBLM Sim. Interactions on 100% of Data in E1-1 56.75 59.27 45.07 40.18 133,336\nBLM Sim. Interactions on 75% of Data in E1-1 65.51 64.01 43.66 39.11 74,414\nBLM Sim. Interactions on 25% of Data in E1-1 54.05 46.48 39.43 35.09 8,266\nBLM Human Interactions in E1-1 67.56 71.56 45.07 35.18 84\nCLM Human Interactions in E1-1 53.52 44.53 40.29 46.38 47\nTable 4: Protocol 2: Interactions results on BLM + Climate Change (CLM) when we train on interactions, and then apply the\nmodel to a new event with no interactions done. E1 and E2 are the two separate, inductive graphs. E1-1 is the interaction half of\nthe1stevent and E1-2 is the 2nd, non-interaction half. E2-1 (non-interaction half) is not connected to E1. Compared to the\nmodel that was trained on E1-1 without interactions (No Interactions Train), human interactions lead to a more accurate model\nfor future events, by \u223c3% better Acc. for BLM and \u223c4% F1 for CLM (E2-1). Sim. settings also show improvements.\n5.4 Interactions\nWe now evaluate our interaction protocols - what\nportions of the graph to show users and how to in-\ncorporate interactions, using the method in Sec 5.2.\n5.4.1 Soliciting Interactions\nWhen comparing our methods for choosing what\nsub-graphs to show on BLM, simulated interactions\nperformance shows a benefit (Table 2) of choos-\ning the users to build interaction graphs for based\non confused user clustering. This matches our in-\ntuition as if the model predicts a users\u2019 factuality\ndifferently than other users similar to it, then the\nmodel is confused and clearing that could improve\nperformance. Thus, we use this method of choosing\nsub-graphs throughout the rest of our experiments.\n5.4.2 Incorporating Interactions\nNow, we evaluate our 3 protocols of incorporating\ninteractions discussed in Sec 4.2, in order of in-\ncreasing performance and model training required.For space, additional human interaction results are\nin App. B.2.3 and detailed CLM results in App. C.\nNote that simulated interactions (4.3) use gold test\nset labels and thus are only used to test our models.\nFirst, Protocol 1, where we evaluate how the\nmodel performs with interactions in the completely\ninductive setting, so no training is necessary. In\nTab. 3, we ran interactions on only the interaction\nhalf of each event ( E1-1+E2-1) and the dev. data\n(also from E1-1), to choose the strongest model.\nTo ensure the dev. set being chosen from E1-1\ndoes not bias us into a strong model, we also did\ninteractions on the interaction half of E2and notice\nstronger performance improvements. Note that E2\nis a future event and is not connected to E1at all.\nAll settings improve performance. Moreover, on\nBLM, human interactions improves performance\n\u223c9.3% Acc. on E2-1, comparable to simulated\ninteractions with significantly more data, showing\nthe large impact benefit of human interactions.\nNext, in Protocol 2, we learn a better model for\nModel E1-2\nAccE1-2\nF1E2-1\nAccE2-1\nF1E2-2\nAccE2-2\nF1#\nEdges\nBLM No Interactions 37.93 30.70 35.21 27.65 30.30 24.84 -\nBLM No Interactions Train 64.86 66.91 42.10 40.10 45.45 42.35 -\nCLM No Interactions Train 49.29 44.84 44.77 42.35 44.44 33.06 -\nBLM Sim. Interactions on Sub-Graphs Only 62.16 62.95 57.89 48.53 45.45 43.49 2,162\nBLM Sim. Interactions on 100% of Data in E1-1 + E1-2 56.75 59.27 57.89 61.90 36.36 35.53 133,336\nBLM Sim. Interactions on 75% of Data in E1-1 + E1-2 65.51 64.01 63.15 61.84 45.45 43.60 74,414\nBLM Sim. Interactions on 25% of Data in E1-1 + E1-2 54.05 46.48 44.73 31.38 51.51 45.31 8,266\nBLM Human Interactions in E1-1 + E2-1 67.56 71.56 50.00 43.60 51.51 40.09 84\nCLM Human Interactions in E1-1 + E2-1 53.52 44.53 53.48 43.07 46.80 38.73 47\nTable 5: Protocol 3: Results on BLM + Climate Change (CLM) when we train on interactions and then do more in the inductive\nsetting. E1 and E2 are the two separate inductive graphs. E1-1 is the interaction half of E1 that is trained on. E1-2 is the\nnon-interaction half. E2 receives interactions on the interaction half (E2-1), but not the non-interaction half (E2-2). Human\ninteractions improve accuracy on both halves of E2 and F1 on E2-1, compared to no interactions train, and more than only\napplying interactions without training for them as Tab.3, showing the benefit of training to learn to incorporate interactions.\nnews source factuality detection after doing inter-\nactions, compared to not doing any. In Tab. 4, we\nran interactions on the interaction half of E1, and\nthen trained on that data. On E2with no interac-\ntions done, we can see how this improves accuracy\ncompared to models trained without interactions.\nFinally, for Protocol 3, we learn to better incor-\nporate interactions into the model after we train for\nit. Thus, we train similarly to Protocol 2, but now\nwe also run interactions on the interaction half of\nE2. In Tab. 5, we see accuracy improves on both\nhalves of E2after we learn to incorporate interac-\ntions on E1, even though E2is inductive. Further,\nF1 improves on E1-1. This shows that training\nwith and then doing interactions helps performance\nsignificantly on future events. We hypothesize that\nthis happens as training with interactions enables\nthe model to learn how to incorporate them bet-\nter, allowing the model to further take advantage\nof them whenever provided. Further, human in-\nteractions based on content preferences provide\nclearer results compared to simulated ones (with-\nout cheating and using test set labels), as the model\nbetter learns the social media landscape, shown by\nit achieving better accuracy on the BLM interacted\nand non-interacted data (both halves of E2).\nFrom these results, we see that our real-world ap-\nplicable human interactions models result in perfor-\nmance improvements in either Accuracy or Macro\nF1, often times both. As a whole, all our mod-\nels improve performance (any non-gain in one of\nthese metrics is offset by significant gains in the\nother). We additionally hypothesize that perform-\ning more interactions (particularly human) will\nachieve higher and more consistent results.Model Purity # Edge\nNo Inter. 36.2, 37.8, 33.3 -\nP1: Inductive Human 39.2, 40.2, 35.3 84\nP2: Train Human 49.5, 37.4, 41.4 84\nP3: Train + Inter. Human 53.4, 41.9, 42.6 84\nTable 6: Purity clustering (sources, articles, users) for the\nhuman interaction protocols on E2-1. As training increases\nwith each protocol (P), purity does too, showing that\ninteractions do help to learn better information communities.\n6 Discussion\nNow, we analyze our best BLM interaction model\nfor fake news source detection (for each protocol)\nonE2-1by answering these research questions:\n(1)Do interactions help learn better communities?\n(2)What pairs of nodes do humans connect?\n(3)How can our model be used in the real world?\n(4)Do interactions change embeddings? App. D.1\n6.1 Learned Communities\nWe analyze how interactions help learn better info.\ncommunities. We evaluate cluster-purity by K-\nmeans clustering sources, articles, and users before\nand after interactions are done. To compute pu-\nrity, each cluster is assigned to the class which is\nmost frequent in it, and then the accuracy of this\nis measured. Users are assigned gold labels based\non the most common label of all the nodes they are\ndirectly connected to in the graph. Results in Tab. 6\nshow purity increases after interactions, showing\ninteractions help learn better communities.\n6.2 Human Interaction Analysis/Examples\nWe analyze the interactions to determine what hu-\nmans connected. We see humans make smart de-\ncisions in matching content preferences. Further,\nwe show specific examples, demonstrating the ease,\nquickness, and lack of subjectivity of the interac-\ntion process. These details/ex. are in App. D.2.\n6.3 Real World Use Case\nAs shown in Sec. 5, our interactive protocols enable\nrapidly (humans spent \u223c3 min/sub-graph) learning\nbetter source factuality detection models for new\nevents, even in the most challenging settings when\nthere are no users, articles, or sources in common\nwith prior data. This happens as contrary to provid-\ning additional labels, which can be time consuming\nand hard, interactions clear up content preferences,\ncreating better social homophily and performance.\nSpecifically, in a real-world use case, interact-\ning at training time learns a better model for the\nnew event setting (Protocol 2 results on E2-1). In\naddition, this model would become even stronger\nas more interactions are performed, even without\nany further training, as seen in Protocol 3. Thus,\nwhen new news events happen, humans can inter-\nact on a few settings (our interaction sub-graphs)\nand our setup enables the model to amplify this\nknowledge to rapidly detect fake news sources on\na large scale.\n7 Summary and Future Work\nWe proposed an initial protocol to interactively\nbuild stronger information communities, applying\nit on source factuality detection. We focused on the\nearly detection settings, where even strong models\ncan struggle. Our approach of finding sub-graphs\nand then interacting on them via 3 protocols en-\nables minimal, quick human interactions to achieve\nsignificant performance improvements. We hypoth-\nesize that our interactive framework can generalize\nto other social media analysis tasks like bias or\ntopic detection, and testing it is our future work.\nAdditionally, we aim to scale up our interaction\nprocess, to include additional human interactions\nand types of interactions.\n8 Acknowledgements\nWe thank the anonymous reviewers of this paper\nfor all of their vital feedback. The project was\nfunded by NSF CAREER award IIS-2048001 and\nIIS-2135573.\n9 Ethics Statement\nIn this section, we first discuss some limitations of\nour model (9.1), and then expand on that with a dis-\ncussion on ethics as it relates to our data collection,data usage, human interaction, and the deployment\nof our models (9.2).\n9.1 Limitations\nThis work tackles fake news source detection in\nEnglish on Twitter (our social media platform of\nchoice). Our methods may or may not apply to\nother languages with different morphology, and\nother social networking platforms. We leave the in-\nvestigation of this to future work, but are optimistic\nthat especially with the benefit of interactivity, our\nmethods may generalize.\nThe nature of our interactive framework also re-\nquires human interactors to interact, which could be\na potential limitation. Interactors must have some\ngeneral understanding of news content and be able\nto identify if two entities (users, sources, or articles)\nhave similar content relationships. However, as in-\nteractors are just looking for content/perspective\nsimilarity, they need not be aware of the latest\nevents or be fake news detection specialists. Fur-\nther, human interactors don\u2019t analyze user-specific\ninformation or profile users themselves, they just\ndetermine if users have similar content relation-\nships.\nWe used a single GeForce GTX 1080 NVIDIA\nGPU to train our models, with 12 GB of memory.\nAs our models are largely textual based, they do\nnot require much GPU usage. However, scaling our\nexperiments to larger scale settings in real world\nsettings could require more compute, which may be\na potential limitation. Our hyper-parameter search,\nmentioned in App A.3 was done manually.\n9.2 Ethics\nTo the best of our knowledge no code of ethics\nwas violated throughout the experiments done in\nthis paper. We reported all hyper-parameters and\nother technical details necessary to reproduce our\nresults, and release the code and dataset we col-\nlected. We evaluated our model on two datasets\nthat we collected in this paper, and was collected\nby prior work, but it is possible that results may\ndiffer on other datasets. We believe our methodol-\nogy is solid and applies to any social media fake\nnews setting. Due to lack of space, we placed\nsome of the technical details and discussion to the\nAppendix section. The results we reported sup-\nports our claims in this paper and we believe it is\nreproducible. Any qualitative result we report is\nan outcome from a machine learning model that\ndoes not represent the authors\u2019 personal views. For\nanything associated with the data we use, we do\nnot include account information and all results are\nanonymous.\nIn our dataset release, we include sources, users,\nand articles, with enough data to produce the results\ndescribed in the paper and the Appendix. Sources\nare public information provided in (Baly et al.,\n2020), and we map each to an ID. We release arti-\ncle graph embeddings, which can be used to train\nour models. As these embeddings are neural net-\nwork representations, they can\u2019t be mapped back to\narticle text. However, we also release article URLs,\nso that the articles can be downloaded, if they are\nstill publicly available. Additionally, we release\nthe Twitter data that we used, in complicance with\nthe Twitter API policies4. In our dataset release,\neach user is referenced by their Twitter ID, and\ntheir graph ID (the graph ID is meaningless on it\u2019s\nown). We release the mapping of the Twitter ID\nto the graph ID. By us only releasing Twitter ID\u2019s,\nand not the actual Twitter text or user information,\nin order to download the exact Twitter data that we\nused, users must use the Twitter API to gather the\nlatest public information5. This ensures that we\nrespect user privacy, in accordance with the poli-\ncies mentioned by the Twitter API, as only user\ncontent that is still public can be downloaded and\nwe are not storing/releasing any data. We also pro-\nvide the model representations for each user, article,\nand source we used as our initial embedding in the\ngraph. As these are neural network model embed-\ndings, they can\u2019t be mapped back to the individual\ntext. Our data is meant for academic research pur-\nposes and should not be used outside of academic\nresearch contexts. All our data is in English.\nIn this paper, we did not use any of the Twitter\ndata for user surveillance purposes, and we encour-\nage the community to do the same, to respect user\nprivacy. We also do not profile users, we only use\nthe user insights as an aggregate to classify news\nsources. Further, we only use public Twitter pro-\nfiles, which there are enough of for our framework\nto work in real-time situations. When doing human\ninteractions, we show humans public Twitter infor-\nmation, so that they can determine user similarity.\nTo do this, we use the Twitter API to determine the\nTwitter data that is publicly available at the time\nof interaction, show that to humans, and then dis-\n4https://developer.twitter.com/en/\ndeveloper-terms/more-on-restricted-use-cases\n5https://developer.twitter.com/en/docs/\ntwitter-apicard the Twitter information. Further, in our graph\nmodel, we do not store any user-specific informa-\ntion, we only store neural network model embed-\ndings which are used for training and cannot be\nmapped back to the original text or user. The same\nis true for articles, so we we are actually discard-\ning all the text (Twitter, article, and source). Users\nof our framework should also do the same - use\npublic knowledge for interactions and not store any\nuser/article specific data, rather use the appropriate\nAPIs to retrieve the data when needed.\nOur framework in general is intended to be used\nto defend against fake news. While our framework\ncould be used to build better methods of design-\ning fake news, our methodology of interactive fake\nnews detection could guard against that as well.\nWe caution that our models and methods be con-\nsidered and used carefully. This is because in an\narea like fake news detection, there are great conse-\nquences of wrong model decisions, such as unfair\ncensorship and other social related issues. Further,\ndespite our efforts, it is possible our models are\nbiased, and this should also be taken into consider-\nation. Our protocol of building sub-graphs based\non model confusion that we used when showing\nhumans what to interact on, can be used to get in-\nsights into the model to help prevent some of these\nissues as well. However, this is definitely an area\nof future work.\nIn the interactive setting we proposed, our ap-\nproach relies on getting insights from human in-\nteractors and using that to improve performance\nin fake news detection. While that lead to perfor-\nmance improvements in this work and we believe it\nwill hold in different settings, there could be issues,\nsuch as biased humans. Running interactions at\nlarge scale with multiple human experts per sub-\ngraph can help mitigate some of these issues. For\nexample, edges can be weighted in the graph based\non how many humans chose to add them. Thus,\nextremely biased interactors decisions would be\ngiven less weight, and maybe even not considered\nby the model. We leave this for future work. How-\never, despite this, there may still be some human\ninteractor bias that can leak into the final fake news\ndetection model, which is why perhaps important\ndecisions should not be made only by machine\nlearning models, but rather the models be used as a\ntool.\nAs mentioned in the Appendix B.2.3, the human\ninteractors we used were Compute Science PhD\nstudents. The interactors were awarded research\ncredits for their work, as the hours they spent work-\ning on the task were considered as part of their\nresearch credit hours. They were explained the\nentire process before hand including what the inter-\nactions would be used for, and agreed to perform\nthe interaction. The total interaction process took\nunder 3 hours, including the time spent explaining\nthe process.\nThese and many other issues are things to con-\nsider when using fake news detection models such\nas the one proposed in this work.\nReferences\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing ,\nEMNLP \u201918, Brussels, Belgium.\nRamy Baly, Georgi Karadzhov, Jisun An, Haewoon\nKwak, Yoan Dinkov, Ahmed Ali, James Glass, and\nPreslav Nakov. 2020. What was written vs. who\nread it: News media profiling using text analysis\nand social media context. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics , ACL \u201920.\nAlessandro Bessi, Fabio Petroni, Michela Del Vicario,\nFabiana Zollo, Aris Anagnostopoulos, Antonio Scala,\nGuido Caldarelli, and Walter Quattrociocchi. 2016.\nHomophily and polarization in the age of misinforma-\ntion. The European Physical Journal Special Topics ,\n225:2047\u20132059.\nPieter M Blok, Gert Kootstra, Hakim Elchaoui Elghor,\nBoubacar Diallo, Frits K van Evert, and Eldert J\nvan Henten. 2021. Active learning with maskal re-\nduces annotation effort for training mask r-cnn. arXiv\npreprint arXiv:2112.06586 .\nKiant\u00e9 Brantley, Soham Dan, Iryna Gurevych, Ji-Ung\nLee, Filip Radlinski, Hinrich Sch\u00fctze, Edwin Simp-\nson, and Lili Yu, editors. 2021. Proceedings of the\nFirst Workshop on Interactive Learning for Natural\nLanguage Processing . Association for Computational\nLinguistics, Online.\nMatteo Cinelli, Gianmarco De Francisci Morales,\nAlessandro Galeazzi, Walter Quattrociocchi, and\nMichele Starnini. 2021. The echo chamber effect on\nsocial media. Proceedings of the National Academy\nof Sciences , 118(9):e2023301118.\nPrakhar Gupta, Chien-Sheng Wu, Wenhao Liu, and\nCaiming Xiong. 2022. Dialfact: A benchmark for\nfact-checking in dialogue. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n3785\u20133801.Yosh Halberstam and Brian Knight. 2016. Homophily,\ngroup size, and the diffusion of political information\nin social networks: Evidence from twitter. Journal\nof public economics , 143:73\u201388.\nFelix Hamborg, Norman Meuschke, Corinna Breitinger,\nand Bela Gipp. 2017. news-please: A generic news\ncrawler and extractor. In Proceedings of the 15th In-\nternational Symposium of Information Science , pages\n218\u2013223.\nYi Han, Shanika Karunasekera, and Christopher Leckie.\n2020. Graph neural networks with continual learning\nfor fake news detection from social media. arXiv\npreprint arXiv:2007.03316 .\nNaeemul Hassan, Fatma Arslan, Chengkai Li, and Mark\nTremayne. 2017. Toward automated fact-checking:\nDetecting check-worthy factual claims by claim-\nbuster. In Proceedings of the 23rd ACM SIGKDD\nInternational Conference on Knowledge Discovery\nand Data Mining , pages 1803\u20131812.\nYinqiu Huang, Min Gao, Jia Wang, and Kai Shu. 2021.\nDafd: Domain adaptation framework for fake news\ndetection. In International Conference on Neural\nInformation Processing , pages 305\u2013316. Springer.\nKathleen Hall Jamieson and Joseph N Cappella. 2008.\nEcho chamber: Rush Limbaugh and the conservative\nmedia establishment . Oxford University Press.\nJooyeon Kim, Dongkwan Kim, and Alice Oh. 2019.\nHomogeneity-based transmissive process to model\ntrue and false news in social networks. In Proceed-\nings of the Twelfth ACM International Conference on\nWeb Search and Data Mining , pages 348\u2013356.\nPakindessama M Konkobo, Rui Zhang, Siyuan Huang,\nToussida T Minoungou, Jose A Ouedraogo, and Lin\nLi. 2020. A deep learning model for early detec-\ntion of fake news on social media. In 2020 7th In-\nternational Conference on Behavioural and Social\nComputing (BESC) , pages 1\u20136. IEEE.\nDavid MJ Lazer, Matthew A Baum, Yochai Ben-\nkler, Adam J Berinsky, Kelly M Greenhill, Filippo\nMenczer, Miriam J Metzger, Brendan Nyhan, Gordon\nPennycook, David Rothschild, et al. 2018. The sci-\nence of fake news. Science , 359(6380):1094\u20131096.\nKe Li, Bin Guo, Jiaqi Liu, Jiangtao Wang, Haoyang Ren,\nFei Yi, and Zhiwen Yu. 2022. Dynamic probabilistic\ngraphical model for progressive fake news detection\non social media platform. ACM Transactions on\nIntelligent Systems and Technology (TIST) .\nHongzhan Lin, Jing Ma, Liangliang Chen, Zhiwei Yang,\nMingfei Cheng, and Chen Guang. 2022. Detect ru-\nmors in microblog posts for low-resource domains\nvia adversarial contrastive learning. In Findings\nof the Association for Computational Linguistics:\nNAACL 2022 , pages 2543\u20132556.\nYang Liu and Yi-Fang Wu. 2018. Early detection of\nfake news on social media through propagation path\nclassification with recurrent and convolutional net-\nworks. In Proceedings of the AAAI conference on\nartificial intelligence , volume 32.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nJing Ma, Wei Gao, and Kam-Fai Wong. 2018. Rumor\ndetection on twitter with tree-structured recursive\nneural networks. In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 1980\u20131989.\nMiller McPherson, Lynn Smith-Lovin, and James M\nCook. 2001. Birds of a feather: Homophily in social\nnetworks. Annual review of sociology , 27(1):415\u2013\n444.\nNikhil Mehta, Mar\u00eda Leonor Pacheco, and Dan Gold-\nwasser. 2022. Tackling fake news detection by con-\ntinually improving social context representations us-\ning graph neural networks. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n1363\u20131380.\nAhmadreza Mosallanezhad, Mansooreh Karami, Kai\nShu, Michelle V Mancenido, and Huan Liu. 2022.\nDomain adaptive fake news detection via reinforce-\nment learning. In Proceedings of the ACM Web Con-\nference 2022 , pages 3632\u20133640.\nVan-Hoang Nguyen, Kazunari Sugiyama, Preslav\nNakov, and Min-Yen Kan. 2020. Fang: Leveraging\nsocial context for fake news detection using graph\nrepresentation. In Proceedings of the 29th ACM In-\nternational Conference on Information & Knowledge\nManagement , pages 1165\u20131174.\nMaria Leonor Pacheco and Dan Goldwasser. 2021.\nModeling content and context with deep relational\nlearning. Transactions of the Association for Compu-\ntational Linguistics , 9:100\u2013119.\nMaria Leonor Pacheco, Tunazzina Islam, Monal Maha-\njan, Andrey Shor, Ming Yin, Lyle Ungar, and Dan\nGoldwasser. 2022. A holistic framework for analyz-\ning the COVID-19 vaccine debate. In Proceedings\nof the 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 5821\u20135839,\nSeattle, United States. Association for Computational\nLinguistics.\nMaria Leonor Pacheco, Tunazzina Islam, Lyle Ungar,\nMing Yin, and Dan Goldwasser. 2023. Interactive\nconcept learning for uncovering latent themes in large\ntext collections. In Findings of the Association for\nComputational Linguistics: ACL 2023 , pages 5059\u2013\n5080, Toronto, Canada. Association for Computa-\ntional Linguistics.Adam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learning\nlibrary. In H. Wallach, H. Larochelle, A. Beygelz-\nimer, F. d 'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems\n32, pages 8024\u20138035. Curran Associates, Inc.\nVer\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 3391\u20133401.\nWalter Quattrociocchi, Antonio Scala, and Cass R Sun-\nstein. 2016. Echo chambers on facebook. Available\nat SSRN 2795110 .\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nInProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP) , pages 3982\u20133992.\nMichael Schlichtkrull, Thomas N Kipf, Peter Bloem,\nRianne Van Den Berg, Ivan Titov, and Max Welling.\n2018. Modeling relational data with graph convolu-\ntional networks. In European semantic web confer-\nence, pages 593\u2013607. Springer.\nKai Shu, Limeng Cui, Suhang Wang, Dongwon Lee,\nand Huan Liu. 2019a. defend: Explainable fake news\ndetection. In Proceedings of the 25th ACM SIGKDD\ninternational conference on knowledge discovery &\ndata mining , pages 395\u2013405.\nKai Shu, Deepak Mahudeswaran, and Huan Liu. 2019b.\nFakenewstracker: a tool for fake news collection, de-\ntection, and visualization. Computational and Math-\nematical Organization Theory , 25(1):60\u201371.\nNiket Tandon, Aman Madaan, Peter Clark, and Yiming\nYang. 2022. Learning to repair: Repairing model out-\nput errors after deployment using a dynamic memory\nof feedback. NAACL Findings.(to appear) .\nSvitlana V olkova and Jin Yea Jang. 2018. Misleading or\nfalsification: Inferring deceptive strategies and types\nin online news and social media. In Companion\nProceedings of the The Web Conference 2018 , pages\n575\u2013583.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151.\nMinjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei\nLi, Xiang Song, Jinjing Zhou, Chao Ma, Lingfan Yu,\nYu Gai, et al. 2019. Deep graph library: A graph-\ncentric, highly-performant package for graph neural\nnetworks. arXiv preprint arXiv:1909.01315 .\nRobert West, Hristo S Paskov, Jure Leskovec, and\nChristopher Potts. 2014. Exploiting social network\nstructure for person-to-person sentiment analysis.\nTransactions of the Association for Computational\nLinguistics , 2:297\u2013310.\nDustin Wright, David Wadden, Kyle Lo, Bailey Kuehl,\nArman Cohan, Isabelle Augenstein, and Lucy Wang.\n2022. Generating scientific claims for zero-shot sci-\nentific fact checking. In Proceedings of the 60th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , pages 2448\u2013\n2460.\nYi Yang, Ming-Wei Chang, and Jacob Eisenstein. 2016.\nToward socially-infused information extraction: Em-\nbedding authors, mentions, and entities. In Proceed-\nings of the 2016 Conference on Empirical Methods\nin Natural Language Processing , pages 1452\u20131461.\nChunyuan Yuan, Qianwen Ma, Wei Zhou, Jizhong Han,\nand Songlin Hu. 2020. Early detection of fake news\nby utilizing the credibility of news, publishers, and\nusers based on weakly supervised learning. In Pro-\nceedings of the 28th International Conference on\nComputational Linguistics , pages 5444\u20135454.\nYongchun Zhu, Qiang Sheng, Juan Cao, Shuokai Li,\nDanding Wang, and Fuzhen Zhuang. 2022a. Gener-\nalizing to the future: Mitigating entity bias in fake\nnews detection. In Proceedings of the 45nd Inter-\nnational ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval . Association\nfor Computing Machinery.\nYongchun Zhu, Qiang Sheng, Juan Cao, Qiong Nan,\nKai Shu, Minghui Wu, Jindong Wang, and Fuzhen\nZhuang. 2022b. Memory-guided multi-view multi-\ndomain fake news detection. IEEE Transactions on\nKnowledge and Data Engineering .A Supplemental Material: Fake News\nSource Detection\nIn this section, we provide implementation details\nfor our models for fake news source detection. The\noriginal dataset we used has 859 sources: 452 high\nfactuality, 245 mixed , and 162 low, and was re-\nleased publicly by (Baly et al., 2020)6. We then\nextended it by scraping sources from the Media\nBias/Fact Check website7, to gain better coverage\nof more recent events. The dataset does not include\nany other raw data (articles, sources, etc.), so we\nmust scrape our own.\nA.1 Data Collection\nWe will release the data and code for this paper\nupon acceptance. Our data collection process is\nidentical to Mehta et al. as we use their code, but\nwe briefly describe the process here completion.\nFurther details are available in Mehta et al.\nFollowing the process used in Mehta et al., we\ntried to scrape news articles for each source in\nthe dataset using public libraries (Newspaper3K8,\nnews-please9(Hamborg et al., 2017), and Scrapy\n10). In cases where the webpage of the news source\nwas removed as often happens with fake news web-\nsites, we used the Wayback Machine11to down-\nload the articles, if possible. As explained in Sec 3,\nwe attempted to get up to 300 articles for each\nsource. For the sources we got for the (Baly et al.,\n2020) dataset, our statistics are the same as Mehta\net al. as we use their data, and thus the sources\nhave an average of 109 articles with a STD of 36.\nTo scrape Twitter data, we used the Twitter\nAPI12. In order to densely populate the graph, we\nattempted to scrape up to 5000 followers for each\nsource that had a Twitter account ((72.5% of the\nsources, the same number as (Baly et al., 2020;\nMehta et al., 2022)). Further, to find users that\npropagate articles, we used the Twitter Search API\nto search articles. From the returned Twitter results,\nwe use users that mention the article title or the ar-\nticle URL and post their tweet within 3 months of\nthe original article being published. For each user\nfound, we download their profile and add them to\nour graph, making the appropriate Twitter User to\n6https://github.com/ramybaly/News-Media-Reliability\n7https://mediabiasfactcheck.com\n8https://github.com/codelucas/newspaper\n9https://github.com/fhamborg/news-please\n10https://github.com/scrapy/scrapy\n11https://archive.org/web/\n12https://developer.twitter.com/en/docs\nArticle connection as discussed in Sec 3. Finally,\nwe scraped the followers of each Twitter user in\nthe graph, and connected them to any user they\nfollowed that was in the graph. This increases the\nconnectivity of the graph and allows us to better\ncapture the social media landscape. To maintain a\ndensely connected graph, we remove users that do\nnot connect to any other node in the graph.\nTo get the data for the YouTube embeddings for\nthe sources, we used the ones released publicly\nby (Baly et al., 2020), who were able to scrape\nYouTube channels for 49% of sources.\nA.2 Event Collection\nTo collect the data for each event ( E1from June\n2, 2019 - Jan 1, 2021 and E2from Feb 2, 2021 -\nMay 6, 2022), we filtered by date and downloaded\nTweets mentioning certain hashtags and a URL\nwith one of the sources in the dataset. The hash-\ntags/search terms we used to collect data for the\nBlack Lives Matter event were: Black Lives Matter,\nBLM, blacklivesmatter, Floyd, George Floyd .\nWe then filtered the data to find the top high,\nmixed , and lowfactuality sources that were men-\ntioned on Twitter for each of these events and time\nperiods. We kept sources that had at least 10 ar-\nticles with Twitter users propagating them. We\nended up with at least 33 sources for each factu-\nality level in each event data split. Other sources\nthat were in the training set of Baly et al. were\nused to train the initial Graph Embedding. Detailed\nstatistics for the training set and the sources used\nin one of our Black Lives Matter splits are shown\nin Table 8.\nA.3 Experimental Settings\nA.3.1 Initial Embeddings\nWe used the same initial graph node embedding\nrepresentations as Mehta et al., which we briefly\nexplain here. The Twitter embedding we used for\neach source and each Twitter user was a 773 dimen-\nsional vector consisting of the SBERT (Reimers\nand Gurevych, 2019) (RoBERTa (Liu et al., 2019)\nBase NLI model) representation of their bio (up\nto the first 512 tokens) concatenated with a vari-\nety of numerical features, as follows: (1) a binary\nnumber representing whether the source is verified,\n(2) the number of users a source follows and the\nnumber that follow it, (3) the number of tweets the\nuser posts, and (4) the number of favorites/likes the\nusers\u2019 tweets have received. The YouTube embed-ding we used consisted of the following numeri-\ncal features: the average of the number of views,\nthe number of dislikes, and the number of com-\nments for each video the source posted on YouTube.\nFor articles, we used the same SBERT RoBERTa\nmodel to generate an embedding based on the ar-\nticle text, which ends up being a 768 dimensional\nvector. In all cases where we encoded text for em-\nbedding representations, we use SBERT (Reimers\nand Gurevych, 2019) RoBERTa (Liu et al., 2019)\nmodel because it provides semantically meaningful\nsentence representations for the text.\nA.3.2 Models and Training\nWe used the publicly released code of Mehta et al.,\nwhich was built using PyTorch (Paszke et al., 2019)\nand DGL (Deep Graph Library) (Wang et al., 2019)\nin Python. The R-GCN used consists of 5 layers,\n128 hidden units, a learning rate of 0.001, and a\nbatch size of 128 for Node Classification. The\ninitial source and article embeddings have hidden\ndimension 768, while the user one has dimension\n773. To do 3-way source classification, the final\nfully connected layer has size 3.\nWe trained our models using a 12GB TITAN\nXP GPU card. To learn the initial model which\nwas used to determine where to perform interac-\ntions, it took approximately 2 hours. Training after\ninteractions takes approximately 30 minutes total.\nInductive settings do not have any training, and\ntake minutes to run as we only have to compute\nembeddings for nodes that we are attempting to\nclassify.\nWe used the development set to evaluate\nmodel performance, and choose the best hyper-\nparameters.\nB Supplemental Material: Interaction\nGraphs\nIn this section, we provide details about the interac-\ntion graphs we showed users in B.1. Then, in B.2,\nwe discuss the interaction process (B.2.1), the de-\ntails behind the interactions used in the main paper\n(B.2.2), and finally new interactions on the second\nBlack Lives Matter Split (B.2.3).\nB.1 Interaction Graph Details\nThe sub-graphs were constructed by first picking\npairs of users, and then adding context around them,\nas discussed in Sec 4.1. The context consists of the\narticle each user propagated, the sources that pub-\nlished it, other users that propagated the same arti-\nModel T1-1\nAccT1-1\nF1T1-2\nAccT1-2\nF1T2-1\nAccT2-1\nF1#\nEdges\nNo Interactions 41.79 37.10 41.93 35.95 37.50 33.54 -\nNo Interactions Train 85.71 85.16 68.42 63.00 40.40 30.75 -\nProtocol 1: Human Interactions in T1-1 43.28 37.39 45.16 42.34 - - 65\nProtocol 2: Human Interactions in T1-1 71.68 72.50 52.63 41.82 41.41 34.79 65\nTable 7: Additional interaction results across the two of our protocols. With minimal interactions, we still see performance\nimprovements in the fully inductive setting in Protocol 1 using all the interactions done by the three humans. We also see how\nthe interactions allow us to learn a better model in Protocol 2, as seen by the improvements on T2-1, despite no interactions\nperformed there (interactions were only on T1-1).\nDataset Low Mixed High\nTraining Event 57 81 153\nT1 56 33 33\nT2 33 33 33\nTable 8: Number of sources in our datasets for the\ntraining event (added to the training set to train the\ninitial model), T1 (first event) and T2 (second event).\nThe results on these data sets are shown in Table 7.\ncles, and finally some additional celebrities (users\nwith more than 1000 followers) that are followed\nby one of the users in the graph. All articles added\nto the graph have to be about the same event, and\nthey are found by searching hashtags related to the\nevent (in our case Black Lives Matter or Climate\nChange, hashtags below) in a four week span on\nTwitter. An example of an interaction graph that is\nshown to humans is in Fig. 2\nEach node in the interaction graphs also contains\nmetadata to provide more information to the human\ninteractors. As seen in Fig 3, article nodes consist\nof the headline, article text, article entities, and the\ndate the article was published. As seen in Fig 4\nsource and user nodes contain Twitter information\nsuch as: username, following count, number of\nfollowers, whether they are verified, how many\ntweets they make, what is their model predicted\nlabel, their biography, the tweet they made about\nthe article, and other tweets they made about the\nsame event.\nOnce the graphs are built, we show them to hu-\nmans and ask a series of questions to guide the\ninteraction process. Each question asks the user\nto create an edge in the interaction graph based\nif there is a positive relationship between the two\nnodes. A Positive relationships mean the nodes\nhave similar content preferences. If a positive rela-\ntionship doesn\u2019t exist, or there is not enough data to\nclearly determine a positive relationship, humans\nare asked to not make any edge connections. Thus,humans are asked to ignore potentially subjective\ncases. Humans identifying positive relationships\nhas multiple benefits for fake news detection: (1)\nSimplicity: It is far simpler than identifying factu-\nality, so it can be used to detect fake news quickly.\nThe simplicity of the interaction process is due to\nthe fact that interactors only have to read a small\namount of content (a few user tweets/profile infor-\nmation + up to two article headlines/summaries),\ncompared to reading multiple articles and gaining\nreal world knowledge. On average, human inter-\nactors spent 3 minutes per interaction graph, and\nmade an average of 8 connections in this time. (2)\nEffectiveness: Interactions improve social media\nrepresentation quality and thus social homophily,\nand that\u2019s what leads to performance improvements.\nHere are the questions we asked human interactors\nfor each sub-graph shown:\n1.Are there any users that are similar to each\nother? Please connect them.\n2.Are there any articles that are similar to each\nother? Please connect them.\n3.Are any users likely to propagate any of the ar-\nticles? Please connect them to the appropriate\narticle.\n4.Are any users likely to interact with another\nuser? Please connect those pairs of users.\n5.Are any users likely to interact with any\nsources? Please connect those users of the\nrespective source.\nB.2 Human Interactor Details\nIn this sub-section, we first discuss the interaction\nprocess, including the graphical interface we built\nfor this task (B.2.1). Then, we discuss the two\nrounds of human interaction protocols we did for\nBlack Lives Matter. Climate change details fol-\nlow in Sec C. The first split of Black Lives Matter,\nSec B.2.2 was presented in the main paper, and the\nsecond split B.2.3 appears in this section.\nB.2.1 Interaction Process\nThe human interactors use a graphical interface\nthat displays the interaction graphs. We hosted\nthe interface on a website built for this interaction\nprocess. Humans must answer the questions dis-\ncussed above (Sec B.1) by connecting nodes to\ncreate edges, which are then saved on our server\nand can be incorporated into the broad event graph\nas new edges, when evaluating the overall perfor-\nmance. The examples of the graphs human inter-\nactors see when interacting, and the metadata they\nare provided with, can be seen in Fig 2, Fig 3, and\nFig 4. Examples of connections made are in 6.2.\nB.2.2 Initial Interactor Details\nWe now describe the initial interaction session we\ndiscussed in the main Paper on Black Lives Matter\nand used for all the BLM Human results presented\nthere. The interactor used for this session was an\nAsian-American PhD student in Computer Science\nand Natural Language Processing. They were ex-\nplained of the entire process before hand including\nwhat the interactions would be used for, and agreed\nto perform the interaction. They interacted on 20\ngraphs per data split (E1-1, dev, and E2-1), which\ntook under an hour for each split.\nB.2.3 Additional Interactor Details\nTo expand our human interactor sessions, we also\nran additional interaction sessions on the Black\nLives Matter dataset (and Climate Change in Sec C.\nFor variety, we used a different source split in this\nsetting, that we will also release. For this reason,\nthese additional results are not comparable to the\nones in the main paper, and we refer to the new\nevents as T1,T1-1,T2, etc. instead of E1,E1-\n1,E2, etc. The data collection was the same as\nbefore.\nFor these additional interactions, we used three\ninteractors of Asian descent, all fluent in the En-\nglish language and all Computer Science PhD stu-\ndents. The interactors were awarded research cred-\nits for their work, as the hours that they spent work-\ning on the task were considered as part of their\nresearch credit hours. They were explained of the\nentire process before hand including what the inter-\nactions would be used for, and agreed to performthe interaction. Each interactor interacted on 10\ngraphs for T1-1, and spent less than one hour. A\nmajority of the time was spent becoming familiar\nthe interaction process, and once complete the in-\nteractions went more rapidly. As a test, we had one\ninteractor do interactions on 10 more graphs, and\nthey were able to do 10 graphs in less than 30 min-\nutes, showing how this process can be done rapidly.\nMoreover, interactors spent an average of 3 mins.\nper interaction sub-graph, once familiar with the\nprocess. Across the three interactors, we had 65\nunique edge connections made for T1-1. We had\n31 edges that were repeated across the interactors,\nshowing a reasonable level of interactor agreement\ngiven the the task.\nResults for this additional interaction process is\nin Tab. 7, and they are consistent with the results\nfor the Protocols in the main paper for the single\ninteractor. For Protocol 1, we see improvements\nin the inductive setting on both the interaction and\nnon-interaction half of T1. Thus, interactions help\nperformance even when there is no additional train-\ning. Protocol 2 also leads to improvements and\nshows how interactions (done on T1-1) allow us\nto learn a better model for when no interactions\nare done (dev. set performance was 43.45% Accu-\nracy). This further shows how interactions can help\nto build a stronger model, especially on emerging\nnews events. In addition, it is likely that more in-\nteractions would lead to more improvements, and\nwe leave this for future work.\nC Supplemental Material: Climate\nChange\nIn this section, we expand upon the Climate Change\n(CLM) dataset results discussed first in Sec 5. We\nfirst discuss what search terms we used to collect\nthe data for Climate Change in Sec C.1. Then, in\nSec C.2, we explain the interaction process that\nwas used for Climate Change, and the agreement\nstatistics associated with it. Finally, in Sec C.3,\nwe present detailed results for Climate Change,\nincluding simulated interactions. All results and\nconclusions are comparable with the Black Lives\nMatter results, showing that our approach general-\nizes across events.\nC.1 Data Collection\nWe used the same Data Collection process for Cli-\nmate Change as Black Lives Matter, discussed in\nSec 5.1 and Sec A.1. This means we have the same\nModel E1-1\nAccE1-1\nF1E1-2\nAccE1-2\nF1E2-1\nAccE2-1\nF1E2-2\nAccE2-2\nF1#\nEdges\nCLM No Interactions 40.16 32.77 39.65 31.86 34.88 30.93 - - -\nCLM Sim. Interactions on 100% of Data\nin E1-1 + E2-146.72 41.59 39.65 31.86 44.18 41.57 - - 12,602\nCLM Human Interactions in E1-1 + E2-1 46.72 43.94 39.65 31.86 39.53 36.95 - - 47\nCLM No Interactions Train - - 49.29 44.84 44.77 42.35 - - -\nCLM Sim. Interactions on 100% of Data\nin E1-1- - 56.33 50.02 44.18 43.10 - - 12,602\nCLM Human Interactions in E1-1 - - 53.52 44.53 40.29 46.38 - - 47\nCLM No Interactions Train - - 49.29 44.84 44.77 42.35 44.44 33.06 -\nCLM Sim. Interactions on 100% of Data\nin E1-1 + E1-2- - 56.33 50.02 41.86 36.42 34.04 24.93 12,602\nCLM Human Interactions in E1-1 + E1-2 - - 53.52 44.53 53.48 43.07 46.80 38.73 47\nTable 9: Climate Change Results: Key: E1 and E2 are the two inductive graphs. E1-1/E2-1 is the first half, and E1-2/E2-2 are\nthe second half. # Edges shows the number of edges added by interactions to E1-1. Protocol 1: The top third refers to Protocol\n1, where interactions result in performance improvements in the difficult, inductive, no training setting. In particular, we see\nimprovements of 6.56% Acc. and 11.17% F1 on E1-1. We do not evaluate on E2-2, as no interactions are done on that split, so\nperformance does not change. Protocol 2: The middle third refers to Protocol 2, where interactions result in performance\nimprovements when we train on the interactions, and then apply the model to a new event with no interactions done. We do not\nevaluate on E1-1, as it is the training set), and E2-2, as no interactions are done and performance does not change. Protocol 3:\nThe last third refers to Protocol 3, where interactions result in performance improvements when we train on the interactions and\nthen do more interactions in the inductive setting ( E2-1). We also see improvements in E2-2. We don\u2019t evaluate on E1-1as it is\nthe training set.\nDataset Low Mixed High\nE1-1 30 43 49\nE1-2 28 41 47\nE2-1 11 15 17\nE2-2 13 16 18\nTable 10: Number of sources in our dataset for climate\nchange.\n3 time periods for Climate Change as Black Lives\nMatter (BLM). The only difference between BLM\nand Climate Change are the search terms we used\nto search Twitter to collect the data. For Climate\nChange, we used the following search terms: frack-\ning,global warming ,climate change ,#savethep-\nlanet ,#savethetrees ,#climatechangeisreal ,#wa-\nterpollution , and #climatestrike . Statistics for the\nnumber of sources in each data split and their high,\nmixed, and low factuality distribution are shown in\nTable 10.\nC.2 Human Interaction Process\nFor the human interactions done on Climate\nChange, we used two male human interactors. Both\nare Computer Science P.h.D. students in Natural\nLanguage Processing of Asian descent. The inter-\nactions were done on 8 sub-graphs for each time\nperiod ( E1-1,E2-1, and the development set), for\na total of 24 sub-graphs interacted on. As withBlack Lives Matter, interactors spent an average of\nabout 3 minutes on each interaction sub-graph.\nC.3 Climate Change Results\nIn-depth results for climate change are presented\nin Table 9. In the main paper, due to lack of space,\nwe presented only baseline and human interaction\nresults, which we expand upon here also showing\nsimulated results. We can see that results improve\nand are consistent with Black Lives Matter Results\nfor Protocols 1, 2, and 3. Protocol 1 (top third of the\ntable) shows significant Accuracy and F1 improve-\nments in the fully inductive setting, showing the\npower of minimal human interactions in the right\nplaces to improve the model without any training.\nProtocol 2 (middle third of the table) shows how\ninteractions result in performance improvements\nwhen we train on interactions and then apply them\nin the fully inductive setting with no additional\ninteractions done. Finally, protocol 3 shows im-\nprovements when we train on the interactions and\nthen do more interactions in the inductive setting.\nThe results in this section, combined with the\nearlier results on Black Lives Matter, show that our\napproach can generalize across multiple datasets,\ntopics, and events.\nModel Embedding Change %\nP1: Inductive Human 75.39\nP2: Train Human 64.23\nP3: Train + Inter. Human 51.41\nTable 11: Change of node embeddings after interactions\ncompared to the no interaction model on E2-1. Interactions\naffect model representations (lower #= more change).\nD Discussion Continued\nD.1 Model Representations\nNow, in order to measure the impact of interactions\non our graph-based model, we evaluate how much\nmodel node embeddings change after they are in-\ncorporated. To do this, we compute the difference\nin the cosine similarity of the embedding of each\nuser node before and after interactions are done,\nand average the results. The results in Tab. 11 show\nthat even a small amount of interactions can make\na significant change in model representations. This\nshows why minimal amounts of interactions can\nlead to a strong performance increase.\nD.2 Discussion: Interaction Examples\nIn this section, we continue our discussion from\nSec 6.2 and provide more examples of nodes\nthat humans connected during the interaction pro-\ncess. We first show the connections humans make\n(Sec. D.2.1), and then discuss what trends we can\nlearn from these connections about our approach\n(Sec. D.2.2). The connections reveal interesting in-\nsights on how humans are connecting nodes based\non content preferences. Further, it shows that de-\nspite all the content being focused on one event,\nthere are lots of different relevant perspectives iden-\ntified by the model as realistic points of confusion.\nD.2.1 Interactions Made\nWe first show examples of pairs of users/articles\nthat were connected by human interactors, describ-\ning what they were about. This analysis was done\nby the authors based on the human interactions.\n1.A user with hashtags about taking back the\nUnited States by burning and destroying it,\nand also White Supremacy related hashtags,\nwas connected to an article saying the cur-\nrent President (Biden) was clueless and didn\u2019t\nknow what they were doing.\n2.Two users with random and unrelated hash-\ntags in their bio and extremely similar tweet\nlanguage were connected as they were identi-\nfied to likely both be bots.3.A user that was a sports fan was connected to\na source that reported sports media, but in this\ncase had posted an article about how certain\nraces have been negatively impacted from the\ncoronavirus despite being athletic.\n4.An article discussing how the Minnesota\nVikings Honored George Floyd\u2019s family at\ntheir season opener was connected to a source\nthat reported football sports articles that\nseemed factual.\n5.An atheist, socialist, songwriter, and musician\nstudent Twitter user was connected to a Bernie\nSanders supporter that wanted student loan\nforgiveness.\n6.An influencer who was the mayor of a major\ncity was connected to a seemingly politically\naligned news reporter for the same city.\nNext, we show snippets (to preserve anonymity)\nof user bios and articles that were connected, to\nshow how simple the process is. We also provide\nour explanations of why these users/articles were\nconnected. All of these examples are related to the\nClimate Change event and the text shown is snip-\npets of the actual text that was shown to humans:\n1.Bio 1: \u201cwhat makes you optimistic...sharing\noptimism of optimistic leaders\u201d Tweet 1: \u201ca\nmajority of young people are #optimistic that\nit\u2019s still possible to prevent the worst effects\nof #climatechange\u201d\nBio 2: \u201cChristian...#Goodnews seeker, ther\u2019s\nplenty of it!\u201d\nExplanation: These users were connected by\ninteractors likely because the second user likes\ngood news, and the first user is an optimist\nspecifically sharing good news about climate\nchange!\n2.Article 1: \u201c...San Diego May Get Climate\nUpdate After All..\u201d\nArticle 2: \u201cFish prices spike as ...face total\ndepletion\u201d\nExplanation : These articles were connected\nby interactors likely because they both are\nshowing the effects of climate change. It is\nchanging cities, and changing fish prices.\n3.Tweet 1: \u201cClimate Change...Biggest Hoax in\nHuman History\u201d\nTweet 2 : \u201cTrump is Hurting Climate Change\nby letting China take the lead...\u201d\nExplanation: These users were not connected\n(and so weren\u2019t the corresponding articles),\nand specifically marked different . This is\nlikely because the first user doesn\u2019t believe\nin climate change, while the second is dis-\nappointed that President Trump isn\u2019t taking\nmore action about it.\n4.Article 1: \u201cClimate Change...Biggest Hoax\nin Human History\u201d\nArticle 2: \u201cCalifornia bans sale on new gas-\npowered cars in 2035\u201d\nExplanation: These articles were not con-\nnected, and specifically marked different .\nThis is likely because the first doesn\u2019t believe\nin climate change, while the second one does,\nor at least enough to report on the ban of the\nsale of gas cars to protect the environment.\nD.2.2 Interactions Task Details and Trends\nWhile humans can be subjective and make mis-\ntakes, we specifically designed our interaction task\nto be simple to try and eliminate as much of this\nas possible. Humans were asked to determine user\nsimilarity based on how users are discussing certain\nevents, not in depth questions like if a text is factual\nor not. Determining this high level of user similar-\nity is fairly simple, especially for educated humans,\nwhom we envision performing the interactions.\nFrom these examples above, we can see that our\ngoal to reduce the subjectivity and increase sim-\nplicity of our interaction task holds true, at least\nin our experiments. This is why the entire inter-\naction process can be be done rapidly (humans\nspent 3 mins per interaction graph, leading to the\ncreation of 8 edges) and with high human inter-\nactor agreement. From the examples shown, it is\nclear that users/articles were connected based on\ncontent match, which was fairly simple for our ed-\nucated human interactors to tell. However, this is\nhard for models, particularly on emerging news\nevents, which is why our interaction setup leads to\nlarge performance improvements, even without any\ntraining. Also, we note that in most cases, the text\ndefining the user/article similarity was not very sub-\njective, and it is easy to determine the user/article\nperspective.\nIt is also possible, but unlikely, that two\nusers/articles making similar statements don\u2019t haveat least some similarity on an issue, and thus\nshouldn\u2019t be in the same information community.\nHowever, on a large scale over a lot of interac-\ntions, the text we show humans is likely to capture\nuser/article perspectives and thus content similarity\ntrends. Thus, even if there are a few rare cases\nin which users are connected but their statements\naren\u2019t representative of the community they belong\nto, it isn\u2019t likely to make a significant difference in\nour learned representation and thus source factual-\nity detection performance.\nFigure 2: Example of an interaction graph that has been anonymized. The two red nodes are the pairs of users\nthat were identified in Sec 4.1, shown by the Twitter usernames. The two orange nodes are the article nodes, and\nshown by their headlines without determiners. Blue nodes are other users that propagate the same articles (could be\ncelebrities - users with over 1000 followers, and purple nodes are sources)\n.\nFigure 3: Example of an interaction graph where we can see metadata about an article, by clicking on the article\nnode. This would be filled in during real human interactions, to allow humans to analyze the article and the context\naround it, but is currently anonymized.\n.\nFigure 4: Example of an interaction graph where we can see metadata about a user, by clicking on the user node.\nThis would be filled in (with data from Twitter) during real human interactions, to allow humans to analyze the user\nand the context around it, but is currently anonymized. Source nodes with Twitter profiles would appear with the\nsame metadata.\n.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Interactively learning social media representations improves news source factuality detection", "author": ["N Mehta", "D Goldwasser"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2309.14966", "abstract": "The rise of social media has enabled the widespread propagation of fake news, text that is  published with an intent to spread misinformation and sway beliefs. Rapidly detecting fake"}, "filled": false, "gsrank": 307, "pub_url": "https://arxiv.org/abs/2309.14966", "author_id": ["HxebdycAAAAJ", "u8358QgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:fxCqVcq9BlAJ:scholar.google.com/&output=cite&scirp=306&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D300%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=fxCqVcq9BlAJ&ei=OrWsaI6ND8DZieoPqdqh8QU&json=", "num_citations": 5, "citedby_url": "/scholar?cites=5766505049612750975&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:fxCqVcq9BlAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2309.14966"}}, {"title": "Finding fake news websites in the wild", "year": "2024", "pdf_data": "Finding Fake News Websites in the Wild*\nLeandro Araujo\nUniversidade Federal de Minas Gerais\nBelo Horizonte, Brazil\nleandroaraujo@dcc.ufmg.brJo\u00e3o M. M. Couto\nUniversidade Federal de Minas Gerais\nBelo Horizonte, Brazil\njoaocouto@dcc.ufmg.brLuiz Felipe Nery\nUniversidade Federal de Minas Gerais\nBelo Horizonte, Brazil\nluiznery@dcc.ufmg.br\nIsadora Rodrigues\nUniversidade Federal de Minas Gerais\nBelo Horizonte, Brazil\nisadoracmr4@gmail.comJussara M. Almeida\nUniversidade Federal de Minas Gerais\nBelo Horizonte, Brazil\njussara@dcc.ufmg.brJulio C. S. Reis\nUniversidade Federal de Vi\u00e7osa\nVi\u00e7osa, Brazil\njreis@ufv.br\nFabricio Benevenuto\nUniversidade Federal de Minas Gerais\nBelo Horizonte, Brazil\nfabricio@dcc.ufmg.br\nABSTRACT\nThe battle against the spread of misinformation on the Internet\nis a daunting task faced by modern society. Fake news content\nis primarily distributed through digital platforms, with websites\ndedicated to producing and disseminating such content playing\na pivotal role in this complex ecosystem. Therefore, these web-\nsites are of great interest to misinformation researchers. However,\nobtaining a comprehensive list of websites labeled as producers\nand/or spreaders of misinformation can be challenging, particu-\nlarly in developing countries. In this study, we propose a novel\nmethodology for identifying websites responsible for creating and\ndisseminating misinformation content, which are closely linked\nto users who share confirmed instances of fake news on social\nmedia. We validate our approach on Twitter by examining vari-\nous execution modes and contexts. Our findings demonstrate the\neffectiveness of the proposed methodology in identifying misinfor-\nmation websites, which can aid in gaining a better understanding\nof this phenomenon and enabling competent entities to tackle the\nproblem in various areas of society.\nCCS CONCEPTS\n\u2022Human-centered computing \u2192Social media; \u2022Applied com-\nputing\u2192Sociology;\nKEYWORDS\nFake News, Misinformation, Credibility, Websites, Social Media,\nTwitter\n1 INTRODUCTION\nIn recent times, society has been faced with an unprecedented\nscale of misinformation campaigns, covering highly sensitive top-\nics including vaccines [ 13], climate change [ 22], scientific informa-\ntion [ 25], and politics [ 16]. The negative effects of misinformation\ncampaigns are numerous, as they undermine the key processes used\n*This is a preprint version of a submitted paper on WebMedia. Please, consider to cite the\nconference version instead of this one.\n.to acquire and share information, posing a significant challenge for\nsociety as a whole. Addressing this issue has become part of our\ndaily lives, and must be tackled.\nIn the fight against misinformation, the complexity of the prob-\nlem has emerged as one of the greatest challenges faced by modern\nsociety. The issue manifests itself in any digital platform where\nusers consume or exchange information, including video platforms\n[11], social networks [ 3,8,9], messaging applications [ 10,17], ded-\nicated websites, blogs, and forums [ 20]. The complexity of the\nmisinformation ecosystem is further compounded by content rec-\nommendation algorithms employed by many of these platforms,\nwhich often prioritize user engagement over the accuracy of the\ninformation presented [ 12]. These factors can give rise to echo\nchambers, leading to polarization [ 6] and even the radicalization of\nusers [ 19]. Additionally, social platforms allow advertisers to target\nusers based on detailed behavioral information, allowing misin-\nformation campaigns to target specific and sometimes vulnerable\nsegments of a population [18].\nOne of the key features of this intricate ecosystem is the utiliza-\ntion of websites dedicated to the production and dissemination of\nfabricated news content. These sites meticulously mimic the ap-\npearance and function of conventional and dependable news outlets.\nWhen intertwined with misinformation campaigns, they frequently\nattempt to manipulate public opinion, propagating widespread\nsuspicion and distrust of credible news sources. By positioning\nthemselves as alternative, and claiming to be more trustworthy in-\nformation sources, they contribute to the creation of an alternative\nreality where a specific narrative and world view go unchallenged.\nWith such a strategy, misinformation campaigns can effectively\ninfluence increasingly radicalized segments of society, serving the\ninterests of specific political entities.\nIdentifying these websites and distinguishing them from their\ncredible counterparts poses one of the most daunting challenges\nto the misinformation research community. Despite its undeni-\nable significance, obtaining lists of websites that are identified as\nfake news sites, particularly for tackling misinformation in spe-\ncific countries like Brazil, is far from a trivial task. This challenge\nis partially explained by the fact that misinformation campaignsarXiv:2407.07159v2  [cs.CY]  15 Jul 2024\nare often orchestrated and supported by organizations with well-\ndefined objectives. Those who propose to publish such lists are\nvulnerable to intimidation, whether by digital militias1or through\nlegal harassment, involving vexatious litigation and other forms of\ncostly legal action2.\nThis study proposes a novel approach to detecting fake news\nwebsites by leveraging user behavior rather than relying solely on\nwebsite characteristics. Specifically, we hypothesize that users who\nshare instances of fake news are likely to have shared additional\nones. Our methodology identifies such users, ranks additional web-\nsites shared by them based on a specific criterion, and expands the\nsearch using articles pertaining to the newly identified websites. To\nvalidate our approach, we applied it to Twitter and compared our\nfindings with a curated list of low-credibility websites published by\nan established American fact-checking website. We further applied\nour methodology to the Brazilian misinformation ecosystem, where\nwe identified numerous previously unknown fake news websites.\nOur results demonstrate that our approach performs best when\nusing a sorting criterion that accounts for both website impact and\nproductivity within the relevant misinformation ecosystem and\nwhen initiated with a fake news URL checked by a recognized fact-\nchecking entity such as the International Fact-Checking Network\n(IFCN3). Moreover, our study shows that users identified through\nour methodology are indeed more likely to post instances of fake\nnews, thereby reducing the need for manual evaluations per identi-\nfication of a low-credibility portal. We anticipate that our results\nwill contribute to a better understanding of this phenomenon and\nhelp competent entities to address the problem in various spheres\nof our society.\nThe remainder of this paper is structured as follows: In Section\n2, we provide a brief overview of previous approaches taken to\naddress the issue of identifying low-credibility content and the\nwebsites that disseminate them. Section 3 outlines the proposed\nmethodology for identifying websites that spread misinformation.\nWe then discuss the application of this methodology on Twitter in\nthe American context, including details on the execution process, in\nSection 4.3. Section 4 presents the findings of this execution, which\nare compared to the ground truth provided by a renowned American\nfact-checking website to assess the efficacy of our approach. In\nSection 6, we perform a \"field test\" of the methodology in the context\nof misinformation in Brazil. Finally, Section 7 concludes the paper\nby highlighting its contributions and outlining future directions for\nresearch.\n2 RELATED WORK\nIn recent times, there has been a significant body of literature that\ndelves into various approaches to identifying websites that are in-\nvolved in creating and disseminating fake news. In this section,\nwe aim to summarize the research that is most pertinent to our\nmethodology, with a particular focus on three key dimensions: (i)\nthe dynamics underlying the spread of fake news; (ii) the monetiza-\ntion of fake news; and (iii) network aspects of domains associated\nwith fake news.\n1https://www.latimes.com/91910540-132.html\n2https://www.abraji.org.br/entenda-o-que-e-assedio-judicial (in Portuguese)\n3https://www.poynter.org/ifcn/2.1 Fake News Spreading Dynamics\nA number of noteworthy studies have been conducted on the\ndynamics of fake news on social media platforms. For instance,\nVosoughi et al. [24] carried out a seminal work by analyzing rumor\ncascades on Twitter from 2006 to 2017. Their findings reveal that\nfake news reached a wider audience and spread more rapidly than\naccurate information. More recently, Singh et al. [21] investigated\nthe spread of URLs on Twitter during the COVID-19 pandemic.\nThey classified URLs into different categories, such as high-quality\nhealth sources, traditional news sources, and misinformation web-\nsites, which were identified as such by the Media Bias/Fact Check\n(MBFC)[ 14] and other similar sources. Their results indicated that\nthe spread of news formed a network with a sub-network of high\nand low credible sources. The structure of the network showed\nthat both high and low credible sources were connected to tradi-\ntional news sources, which played a critical role in bridging the\ntwo groups and facilitating the spread of information from low to\nhigh quality.\n2.2 Fake News Monetization\nBozarth and Budak [ 4] have shown that a significant number of\nfake news websites, extracted from a carefully curated list, receive\nsubstantial support from reputable ad servers. This observation\nraises the possibility that leading ad firms could potentially help\ncombat fake news by ceasing to provide monetization services to\nsuch websites. Meanwhile, Vekaria et al. [23] investigated how mis-\ninformation websites deceive ad server policies by pooling their\nad inventory with unrelated sites in order to circumvent brand\nsafety policies. Using a curated list of misinformation websites,\nthey showed that misinformation websites deceptively monetize\ntheir ad inventory by exploiting a complex ad supply chain. This\nfinding suggests that monitoring ads on misinformation websites\nand exposing the brands that unwittingly fund them could be po-\ntential solutions. In this regard, a recent study has characterized the\neffectiveness of the Sleeping Giants Brazil initiative in demonetizing\nfake news websites[7].\n2.3 Network Aspects of Fake News Web\nDomains\nDrawing on a curated list of websites and their corresponding\ncredibility assessments, the study conducted by Couto et al. [5]\nleveraged computer network attributes to reveal that fake news\nwebsites exhibit a range of content-agnostic characteristics that\ndistinguish them from their credible counterparts. Specifically, they\ntend to be registered more recently, operate for shorter periods, and\nhave certificates that expire more quickly. These findings suggest\nthat fake news websites in Brazil are often designed to be fleeting\nand ephemeral, allowing them to operate with greater impunity\nand evade detection by authorities and fact-checkers. The study\nalso shows that fake news websites are more likely to be hosted on\nforeign territories, suggesting a deliberate attempt to avoid scrutiny\nand regulation by local authorities. The use of computer network\nattributes provides an efficient and scalable addition to the toolkit\nof researchers working to combat the spread of misinformation.\nDespite their contributions in understanding different aspects\nof fake news websites, such as their dynamics of dissemination,\nmonetization methods, and network characteristics, these studies\nprovide only a narrow glimpse into the intricate ecosystem in which\nthese websites thrive. Moreover, the majority of these studies have\nmainly targeted websites from the United States, despite the world-\nwide scope of the misinformation problem. Therefore, our research\naims to supplement existing literature by introducing a methodol-\nogy that can be easily applied by researchers and practitioners in\ndiverse regions and contexts to construct their own curated lists of\nwebsites dedicated to producing and circulating fake news on the\nInternet.\n3 PROPOSED METHODOLOGY\nThis section outlines the proposed methodology for detecting fake\nnews in the wild. The underlying hypothesis is that users who\nhave shared news articles confirmed to be instances of fake news or\nmisinformation, based on the verdict provided by an internationally\nrecognized fact-checking agency, are more likely to have done so\non other occasions compared to users who have not. While this\nmay not always be the case, exploring the timelines of such users,\nmoving from one user to another based on their mutual shared\ncontent, is expected to effectively navigate the space of shared fake\nnews articles in a given social network and identify websites closely\nassociated with them. Our methodology consists of five main steps,\nas illustrated in Figure 1.\n(1)Starting point: The proposed methodology begins by\nidentifying a single \"seed\" news article URL that is asso-\nciated with misinformation content, i.e., fake news. This\ncan be accomplished in two ways: (i) by identifying a fact-\ncheck that directly disproves information or claims made\nin the article, thereby establishing the article as a fake\nnews instance, or (ii) by determining that the article was\npublished by a low credibility website. In both cases, the\ncredibility label must have been produced by an interna-\ntionally recognized fact-checking agency such as IFCN to\nensure the reliability of the seed URL.\n(2)User identification: The next step is to identify users\nwho have shared the seed news article on a social media\nplatform of choice. To validate the methodology, this study\nexplores Twitter, which is well-suited to the target phe-\nnomenon of users sharing news articles and offers an API4\nthat enables easy retrieval of these users\u2019 timelines.\n(3)URL collection: All publicly available posts made by the\nusers identified in Step 2 are collected. From these posts,\nURLs are identified and extracted. The URLs are then fil-\ntered by removing those that belong to websites known\nnot to host news articles from external sources. Examples\nof such websites include social networks and government\nwebsites.\n(4)Ranking: The websites hosting the filtered URLs are\nranked according to a measure of relevance that captures\ntheir importance among the fake news-sharing users iden-\ntified in Step 2. In this study, the H-Index [ 2] is proposed\n4https://developer.twitter.com/as the metric of relevance. The websites are treated as au-\nthors, their news article URLs are treated as publications,\nand a user sharing one of those publications is considered a\ncitation. The URLs contained within each of these websites\nare also ranked according to their importance, which is\nmeasured by a total count of shares by the users identified\nin Step 2.\n(5)New seed selection: The top-ranked news article URLs\nassociated with the top-ranked websites are presented as\ncandidates for addition as seeds. In this step, the URLs\nincluded in a given website\u2019s H-Index set are presented in\naccordance with the website standings. For instance, if the\ntop-ranked website has an H-Index of 4, the candidates\nare its top-4 shared URLs. Once the entity executing the\nmethodology selects a new seed URL, Steps 2 through 5 are\nrepeated. This loop is referred to as a cycle . Note that once\na website\u2019s URL has been picked as a new seed on a given\ncycle, other URLs from the same website are no longer\nconsidered for addition in future cycles. This ensures that\nthe methodology discovers a distinct set of news websites\nwith each cycle.\nDuring the execution of the proposed methodology, at the end of\neach cycle, a list of new websites can be generated. This list is com-\nposed of the websites associated with the URLs selected as seeds\nthroughout the execution cycles. This list of websites constitutes\nthe final output of the methodology. It is important to note that the\nauthors do not intend to release a public list of websites obtained\nthrough this methodology. The purpose of this methodology is\nnot to accuse any website of spreading misinformation, but rather\nto provide a proven idea that enables researchers and competent\nbodies to effectively navigate fake news ecosystems by identifying\nwebsites that are closely associated with users who act as vectors\nfor this type of content. Additionally, the proposed methodology fa-\ncilitates novel research and misinformation prevention by enabling\nresearchers to obtain their own lists of suspicious websites, which\ncan then be evaluated for factual accuracy through fact-checks\nconducted by internationally recognized agencies5or agencies that\nassess the factuality of websites as a whole. In the following section,\nwe present a strategy to validate the proposed methodology.\n4 VALIDATION STRATEGY\nTo the best of our knowledge, this methodology is unlike previ-\nously proposed approaches in the existing literature. To validate its\ncapabilities, we investigate the effective of it at finding fake news\nwebsites, validate premise that a user that has posted a fake news\ninstance likely posts additional ones. Also, we analyze how well the\nproposed methodology hold true as additional cycles are run and\nlast, investigate if is H-Index capable of properly ranking suspicious\nwebsites for analysis, as described next.\n4.1 Finding Ground Truth\nThe validation process of our methodology poses a significant chal-\nlenge, which is the establishment of a ground truth for comparison\nagainst the obtained results. In Brazil, the absence of a curated list\n5https://www.poynter.org/ifcn/\nStarting Point User Identification URL Collection\nRanking New Seed Selection1 2 3\n4 5\nFigure 1: Overview of the proposed methodology for identifying fake news websites in the wild.\nof active fake news websites of sufficient size hinders the feasibility\nof convincing analysis. Conversely, in the United States, the Media\nBias/Fact Check [ 14] (henceforth, MBFC) offers a potential solution.\nMBFC is an autonomous website that assigns high, medium, and\nlow credibility labels, as well as political leanings, to a range of\nnews outlets operating in the US and beyond. MBFC identifies\nas an independent online media outlet \u201cdevoted to educating the\npublic on media bias and deceptive news practices\u201d. Although its\nassessments are less comprehensive than those of NewsGuard [ 15],\nthe assigned attributes to each news source are publicly available.\nIn this study, we utilize the factuality labels associated with the\nindexed websites by MBFC.\nThus, we compiled a dataset of websites whose credibility has\nbeen evaluated by MBFC, where each website is assigned a credibil-\nity label. In this study, we analyzed MBFC\u2019s methodology and defi-\nnitions in detail and considered websites with low and questionably\nlow credibility labels as low credibility websites. All subsequent\nanalyses presented in the forthcoming sections were carried out\nbased on this definition. Our dataset contains evaluations of 3,510\ndistinct websites. It is worth noting, however, that while the dataset\ncovers a broad range of websites, it is limited by the dynamic nature\nof the fake news ecosystem, which sees the continual emergence\nof new fake news websites.\n4.2 Setup\nAs previously stated (refer to Section 3), the proposed methodology\nnecessitates specific input parameters and definitions for its execu-\ntion. Consequently, in this section, we present the configuration of\nour validation strategy.\n4.2.1 Sets of initial seeds. To validate the effectiveness of our\nmethodology, it is crucial to examine its performance under various\ninitial seed conditions. The choice of initial seed plays a critical\nrole in determining the path of website discovery throughout the\nexecution cycles. To this end, we conduct multiple executions of\nthe proposed methodology, each time using a different initial seed.\nWe consider three different sets of seeds for each execution: (i)\nnews articles derived exclusively from high-credibility websites, (ii)\nnews articles derived from an equal proportion of fake and high-\ncredibility websites, and (iii) news articles derived exclusively from\nfake news websites. Seeds from sets (i), (ii), and (iii) have 0%, 50%,\nand 100% likelihood, respectively, of originating from fake news\ninstances, as classified by MBFC. Through this approach, we cancompare the effectiveness of our methodology in navigating the\nsocial media URL sharing ecosystem when presented with actual\nfake news instances versus when provided with high-credibility\ninstances, while also validating several design decisions. The sub-\nsequent sections present the findings obtained from this setup.\n4.2.2 Automated execution and experimental setup. In order to\nassess the efficacy of our methodology, it is necessary to compare\nit against alternative baseline approaches. For instance, we can\ncompare the ranking of websites by their total share against the\nproposed H-Index method. This comparison allows us to measure\nthe effect of the methodology\u2019s design decisions on the purpose of\nidentifying fake news websites.\nHowever, generating enough data points to make a thorough\nassessment of these effects can be costly. One of the main cost\nfactors is Step 5 in the methodology (Figure 1), where a human\nmust manually select a new URL to be used as seed for the next\ncycle of execution. To address this issue, we propose an \u201cautomated\u201d\nexecution of the methodology: in this approach, the algorithm is fed\nwith a random single initial seed from one of the three sets presented\nin the previous section (0%, 50%, and 100% fake probability). From\nthat point forward, the most shared URL from the top ranking\nwebsite, as described in Step 4, is always the one added as new seed\nfor the following steps. Although this automation is suboptimal, as\nhumans are better equipped to identify actual fake news instances\nin each cycle, it provides a lower bound for the quality of results\nthat can be obtained in real-world usage.\n4.3 Twitter Execution\nIn order to assess the potential of the methodology in practical set-\ntings, we have applied it to Twitter within the experimental frame-\nwork presented previously. Through this application, we generated\na dataset of results that allowed us to measure the methodology\u2019s\nability to identify fake news websites, as well as to determine its\nproperties and behavior. Twitter is a widely adopted platform for\ndiscussions on a broad range of topics, and is notorious for its use as\na medium for the dissemination of misinformation campaigns [ 3,8].\nAlthough users on this platform interact with each other in various\nways (e.g., follow, retweet, comment), we only considered tweets\nposted by users in their feeds in our work. The data was limited to\ntweets published in 2022. Notably, publications on Twitter may con-\ntain links to external news websites, which is precisely the domain\nof news content explored in this effort. The steps taken for this\nexecution are described below. It is worth mentioning that many of\nthese steps were only implemented to facilitate the execution of the\nmethodology at scale, in accordance with the proposed validation\nstrategy.\n4.3.1 Selection of initial seeds. To begin the execution of our\nmethodology (see Figure 1), the first step requires the identifica-\ntion of a seed fake news article from which novel misinformation\nwebsites may be discovered. To gather a sizable collection of initial\nseeds, we utilized Twitter\u2019s search feature with the query \"lang:en\"\nwhich is a way of filtering tweets associated exclusively with the\nEnglish language. Using the query format \"max-dt:YYYY-MM-DD, \"\nwe extracted a sample of tweets published between January 2022\nand December 2022. This process was carried out using a newly\ncreated account to prevent the results from being biased by any\nuser activity or recommendation algorithms.\nFrom the resulting dataset of tweets, we identified those con-\ntaining URLs. Subsequently, we filtered the URLs to extract only\nthe ones belonging to news websites labeled in MBFC, i.e., news\narticles originating from sources that have a factuality label.\nHenceforth, the methodology was executed strictly following\nthe protocol outlined in Section 3. Specifically, the following steps\nwere carried out: (i) identification of users who have tweeted the\ninitial seed, (ii) collection of additional URLs tweeted by these users,\n(iii) ranking of websites associated with these URLs according to a\nspecified criterion, and (iv) automatic addition of the most shared\nlink of the top-ranked website to the list of ongoing seeds. It should\nbe emphasized that, in each cycle, users who have shared previously\nselected seeds were also considered for future H-index calculations.\nTo generate a sufficient quantity of data points, the automated\nmethodology was executed up to cycle 30, a total of 360times\nper website ranking criterion, each one under slightly different\nconditions, to validate our design decisions, as discussed in the\nfollowing sections.\n5 EXPERIMENTAL RESULTS\nTo evaluate the impact of the initial seed on the results of our\nmethodology, we conducted an analysis of the ranking quality under\ndifferent scenarios. Specifically, we investigated the effect of using\ninitial seeds with 0%, 50%, and 100% probability of being fake, as\nwell as replacing the H-Index with two alternative ranking criteria:\n(i) the number of shares in the most shared URL and (ii) random\nranking of websites. It is worth noting that regardless of the ranking\ncriteria used, the most shared URL of the top-ranked website was\nalways added to the ongoing set of seeds. By observing the pattern\nof ranking quality across the different initial seed scenarios, we can\nassess the impact of the credibility nature of the initial seed on the\nmethodology\u2019s performance.\n5.1 Importance of the Initial Seed\nThe subfigures depicted in Figure 2 present the quantity of known\nfake news websites per MBFC observed in the top position up to\neach cycle over a total of 30 cycles, each ranked by a specific ranking\ncriterion and a varying initial set of seeds (0%, 50%, and 100% fake).\nFor each subfigure, each data point denotes the average of this\nquantity over 40 automated executions of each labeled scenario. For\nexample, a data point on cycle 15 and average 10 on the 100% curvefor the \u201cSorting Criteria: hindex\u201d graph indicates that, on average,\nbased on the 40 executions, among the first 15 websites observed\nin the top-1 spot, 10 of them were fake news websites. Figure\n3a presents a juxtaposition of the 100% fake set execution curves\nfrom the aforementioned individual average fake news websites\namounts graphs, so that we may better compare the differences in\nperformance between the ranking criteria.\nFinally, we conducted 3distinct runs of 40executions up to cycle\n30for each scenario, which consists of a combination of one rank-\ning methodology and type of initial seed, as described in Section\n4.2. Note that each run used a unique initial seed derived from its\nassigned set of seeds. Notably, we found that in every cycle, even\nthe worst of the three 40-execution runs performed under the 100%\ndataset yielded a better ranking than the best performance obtained\nunder other initial seed datasets. These results suggest that, regard-\nless of the ranking criteria, fake news websites are consistently\nmore likely to be ranked in the top positions throughout the cycles\nwhen the initial seed is more closely associated with misinforma-\ntion. Figure 2, on \u201cSorting Criteria: hindex\u201d, shows that the median\nsubset performance under 0% probability would need 30 cycles so\nthat 2.38 websites could be observed, against just 5 cycles under\n100% probability. This finding highlights that our methodology\nis capable of navigating the URL sharing landscape effectively by\nleveraging users with mutually shared fake news instances, result-\ning in the discovery of news portals of similar credibility nature to\nthe seed.\n5.2 Website Ranking Criteria\nHaving demonstrated the significance of an adequate initial seed,\nall subsequent analyses will be carried out assuming a 100% fake\nnews seed dataset, as this more closely resembles the actual im-\nplementation of our methodology, where a human is responsible\nfor determining which URLs are added to the ongoing set of seeds,\nfrom which additional users are identified.\nIn Figure 2, we have presented a side-by-side comparison of\nthe performance of the three different ranking criteria used in our\nstudy. The three lines in the graph represent the average number of\nknown fake news websites observed in the top 1 position, plotted\nover a total of 30 cycles, with each cycle representing an execution\nof our methodology. As indicated in the previous paragraph, all\nof these executions have been performed using a 100% fake set of\nseeds.\nOne important observation from this figure is the increasing\ndetachment between the H-index curve and the other two curves\nas more cycles are completed. In other words, over time, H-index\npresents a significantly better ability to steer the execution towards\nportals that share content with a similar credibility nature as the\nseed. This finding is consistent with our hypothesis that H-index\nis a more effective metric for ranking websites in this context, as\nit takes into account both the popularity of the website and the\ndiversity of the sources that link to it. The other two criteria, by\ncontrast, are less effective at distinguishing between credible and\nnon-credible sources.\n0 5 10 15 20 25 30\n# cycles02468101214Avg. Low Credibility\nRank-1 Incidency\nSorting Criteria: random\n100%\n50%\n0%\n0 5 10 15 20 25 30\n# cycles02468101214\nSorting Criteria: mostpop\n100%\n50%\n0%\n0 5 10 15 20 25 30\n# cycles02468101214\nSorting Criteria: hindex\n100%\n50%\n0%Figure 2: Average rank 1 incidence of low credibility websites over 40 executions with varying ranking criteria and seed dataset.\n0 5 10 15 20 25 30\n# cycles02468101214Avg. Low Credibility\nRank-1 Incidency\nFake News Odds: 100%\nhindex\nmostpop\nrandom\n(a)\n0 5 10 15 20 25 30\n# cycles0102030405060708090100Perc. Low Credibility\nRank-1 Incidency at Cycle\nFake News Odds: 100%\nhindex\nmostpop\nrandom (b)\n0 5 10 15 20 25 30\n# cycles0102030405060708090100Percentage of Optimal\nWebsite DiscoveryFake News Odds: 100%\nhindex\nmostpop\nrandom (c)\nFigure 3: (a) Performance for different ranking criteria when seeds are URLs of known low-credibility websites; (b) Percentage\nof successfully selected websites for different ranking criteria when seeds are URLs of known low-credibility websites, and; (c)\nRecall for different ranking criteria normalized by the best possible scenario.\n5.3 Fake News Website Discovery\nIt is worth noting that, at the end of a cycle \ud835\udc65, the methodology can,\nat most, have identified x fake news websites that were introduced\nto the set of ongoing seeds. In this regard, Figure 3c displays the\naverage percentage of optimal execution achieved over the course\nof the cycles. Specifically, if a given cycle \ud835\udc65is linked with an average\nof 0.7, it implies that on cycle \ud835\udc65, a total of 70% of the \ud835\udc65websites\nranked at the top position throughout the execution were fake news\nwebsites. Consequently, 0.7* \ud835\udc65fake news websites were discovered\nuntil this cycle.\nThe H-index curve hovering a median of approximately 50%\nperformance level across the 30 cycles implies that in half of the\ncycles, a human evaluator would have been able to identify a new\nlow-credibility website by manually inspecting only the top-ranked\nwebsite. It should be noted that this estimate represents a lower\nlimit on the potential performance of our methodology because (1)\nthe top-ranked website might be of low-credibility and not indexed\nby MBFC, and (2) human evaluators are expected to outperform our\nautomated executions, especially if they choose seeds that are more\nstrongly associated with misinformation than just the most shared\nURL from the top-ranked website. This difference arises from the\nfact that our automated executions are designed to replicate the\nreal-world execution of our methodology, as described in Section4.2. Thus, it is reasonable to expect better results from human\nevaluators in practice.\nThe outcome demonstrates that our proposed methodology,\nwhich incorporates H-index, commences with a low credibility seed,\nand restricts each website to have a single seed included through-\nout the cycles, enables the detection of new fake news websites\nwithout the necessity of manually verifying numerous websites\nbefore finding a single discovery. Instead, it smartly navigates the\nURL sharing ecosystem by leveraging the overlap of users sharing\nURLs associated with various fake news websites and ranks them\nby a metric that considers the productivity and impact of these\nwebsites. This approach results in a curated list of websites, among\nwhich a human-in-the-loop can identify new fake news websites\nwith significantly fewer manual inspections.\n5.4 Dimishing Returns\nFigure 3b shows the percentage of websites ranked at the top spot\nthat are fake news, for each individual cycle, rather than the cu-\nmulative results shown in previous graphs. Our methodology\u2019s\nability to navigate the URL sharing ecosystem is reflected in the\ninitial cycle, where the performance of the mostpop and h-index\nranking criteria are similar, with both hovering around 70% in terms\nof the percentage of websites on rank 1 that are fake news across\nthe independent executions. However, as the cycles progress the\n0 20 40 60 80 100\nTop % Popular20406080100CDF (%) of Low-\nCredibility PortalsOdds: 100%\nhindex\nmostpopFigure 4: Cumulative distribution function (CDF) of fake\nnews websites considering their popularity based on PageR-\nank.\nperformance of the different ranking criteria begins to diverge, with\nthe h-index curve consistently outperforming the other criteria by\na significant margin. By cycle 30, the performance of all ranking\ncriteria converge to low 10\u2019s percentage, indicating the diminishing\nreturns of the methodology as the more readily reachable websites\nare identified. As such, on automated executions context, it proves\nefficient to stop the methodology after a certain number of cycles\nand restart with a different set of initial seeds, highlighting the\nimportance of a human-in-the-loop to provide feedback, keep the\nseeds closely related to fake news instances through the cycles and\nadjust the methodology to target the most promising areas for the\ndiscovery of novel fake news websites.\n5.5 Discovery of Impactful Fake News Websites\nIn order to further evaluate the potential of our methodology, we\naimed to assess its ability to discover the most relevant fake news\nwebsites in a given time frame. To do so, we obtained the popularity\nranking for each fake news website listed in MBFC by fetching\ntheir corresponding Open Pagerank value from DomCop.org\u2019s 10\nmillion website dataset. The Open Pagerank score represents the\nimportance and popularity of a website based on various factors\nsuch as the number and quality of backlinks, social media mentions,\nand overall web presence.\nUsing the obtained Open Pagerank scores, we constructed a cu-\nmulative distribution of the popularity rankings for the fake news\nwebsites discovered by our methodology. The resulting plot is\nshown in Figure 4. As can be seen, 60% of the fake news websites\ndiscovered by our methodology fall within the 15% most popu-\nlar fake news websites indexed by MBFC. This indicates that our\nmethodology by identifying and prioritizing the most influential\nand widely disseminated fake news websites enables more targeted\nand efficient interventions in the fight against spread of misinfor-\nmation.\n6 GATHERING FAKE NEWS WEBSITES IN\nBRAZIL\nFinally, in order to assess the generalizability of our proposed\nmethodology, we applied it to the Brazilian context, ultimately\nidentifying 75fake news websites. For this purpose, we adoptedthe same criteria used in our previous experiments to classify a\nwebsite as a \u201cfake news website\u201d, namely, if the news published on\nthe evaluated URL was fact-checked by an internationally recog-\nnized agency and deemed to be fake. Additionally, we collected a\nlist of 99news websites belonging to ANJ, the Brazilian national\nnewspaper association responsible for defining rules and standards\non news quality and factualness, in order to compare the identified\nfake news websites with high-credible ones. The details of our ap-\nplication of the methodology in the Brazilian scenario, such as the\nnews article used as a seed and the number of cycles, are presented\nin another publication by our research group [1].\n6.1 Relevance of Identified Websites on Social\nPlatforms\nIt is noteworthy to mention that fake news websites rely heavily on\ndigital platforms such as Twitter and Facebook to gain traction for\ntheir publications. Consequently, it is common for them to establish\nan official presence on these social networks. The practicality of\nsharing a URL, which acts as a gateway to content hosted on an\nexternal vehicle, rather than relying on that content being available\non a third-party platform, greatly enhances the websites\u2019 ability\nto reach a larger portion of their target audiences and establishes\nthem as misinformation vectors worth highlighting.\nIn light of this, we conducted an investigation to assess the rele-\nvance of misinformation websites identified through our method-\nology in the context of Brazil. Specifically, we set out to find the\ncorresponding Facebook pages of each website and measure their\nspread. To accomplish this, we queried the name of each website on\nFacebook\u2019s search feature. As a result, we were able to identify 63\nwebsites with a clearly corresponding Facebook page (e.g., sporting\nthe exact same name and logo). For the remaining 13websites,\nwe were unable to establish a clear mapping between them and\ncorresponding Facebook pages.\nFinally, we employed CrowdTangle6, a social media analytics\ntool, to obtain information about the popularity of each Facebook\npage over a period of 12months (from December 2021 to November\n2022). We were able to retrieve CrowdTangle data for 61Facebook\npages out of the 63previously mentioned, taking into consideration\n5websites that are linked to two active pages each. Additionally,\nwe retrieved data from 82pages associated with ANJ in order to\ncompare the results. An overview of these findings is presented in\nTable 1.\nOverall, publications by the 61 Facebook pages received 23,580,129\nshares and 160,387,038reactions, indicating that the identified fake\nnews websites were able to reach approximately 30million users on\nFacebook alone. It is important to note that this number represents\na lower bound for the websites identified through our proposed\nmethodology, as we were unable to fetch the Facebook page and the\nCrowdTangle information for all websites. Furthermore, Crowd-\nTangle only makes available public information about the pages,\nso content shared in private groups is not accounted for in our\nmeasurement. However, this experiment suggests that the set of\nwebsites discovered through the proposed methodology is highly\nrelevant to the Brazilian fake news ecosystem.\n6https://www.crowdtangle.com/\nTable 1: Comparison of Facebook data for fake news websites that were found from the proposed methodology and credible\nnews outlets based on ANJ.\nFeature Fake News Websites High-Credible Sources Total\nAll Reactions 160,387,038 (43.93%) 204,691,475 (56.07%) 365,078,513\nComments 36,188,143 (39.44%) 55,558,913 (60.56%) 91,747,056\nLikes 129,658,929 (48.19%) 139,381,506 (51.81%) 269,040,435\nOwned Post Views 770,778,110 (56.62%) 590,538,483 (43.38%) 1,361,316,593\nOwned Total Views 818,999,144 (56.24%) 637,270,102 (43.76%) 1,456,269,246\nOwned Views from Shares 48,221,034 (50.78%) 46,731,619 (49.22%) 94,952,653\nPage Follower Growth 886,397 (46.67%) 1,013,009 (53.33%) 1,899,406\nPage Followers 31,944,505 (34.09%) 61,764,855 (65.91%) 93,709,360\nPage Likes 27,119,133 (32.09%) 57,402,458 (67.91%) 84,521,591\nShares 23,580,129 (62.61%) 14,084,141 (37.39%) 37,664,270\nTotal Interactions 220,155,313 (44.52%) 274,334,538 (55.48%) 494,489,851\nTotal Posts 225,756 (23.33%) 741,757 (76.67%) 967,513\nViews on Shared Posts 27,241,954 (92.74%) 2,131,818 (7.26%) 29,373,772\n7 CONCLUSION AND FUTURE WORK\nIn this study, a novel methodology for identifying websites ded-\nicated to the production and dissemination of fake news on the\ninternet is proposed. The approach presented is designed to be\neasily applicable by research and competent authorities across var-\nious geographic locations. It is worth mentioning that the current\nwork refrains from providing a ready-made list of such websites in\nthe interest of avoiding potential legal repercussions. Accusations\ndirected towards specific entities regarding their involvement in the\ndissemination of fake news are avoided, and instead, the method-\nology is provided to enable research and government entities to\nassemble their own lists of websites. With this approach, the risk\nof judicial harassment is minimized, while the ability to identify\nfake news websites is retained. Finally, some potential research\ndirections in this context are discussed below.\n7.1 Fake News in Different Contexts\nIt is our hope that the present research serves as a catalyst for\nfuture studies on the issue of fake news worldwide. Our proposed\nmethodology offers a comprehensive framework that enables a\ndeeper understanding of the dissemination of misinformation on\ndigital platforms that extends beyond Twitter analysis, including\nmessaging apps like WhatsApp and Telegram. Our methodology\ntakes a unique approach to this issue by targeting a common vec-\ntor across all digital platforms: users sharing external fake news\nwebsites. We believe that the incidental lists generated from our\nmethod provide an opportunity for investigating various facets of\nfake news websites.\n7.2 Government Action\nOur proposed methodology presents a valuable tool for regulatory\nentities seeking to investigate the source of funding and the benefi-\nciaries of the publication of fake news through websites. As part of\nour research efforts, our group is currently engaged in a collabo-\nrative initiative with the Public Ministry of Minas Gerais (MPMG)\nin Brazil, providing them with sufficient material to warrant an\ninvestigation of these websites.ACKNOWLEDGMENTS\nThis work was partially supported by grants from MPMG, CNPQ,\nFAPEMIG, and FAPESP.\nREFERENCES\n[1] Leandro Araujo, Luiz Felipe Nery, Isadora C Rodrigues, Joao MM Couto, Julio CS\nReis, Ana PC Silva, Jussara M Almeida, and Fabricio Benevenuto. 2022. Identifi-\ncando websites de desinforma\u00e7ao no brasil. In Proc. of the Brazilian Symposium\non Data Bases (SBBD) . 355\u2013360.\n[2] Lutz Bornmann and Hans-Dieter Daniel. 2007. What do we know about the h\nindex? Journal of the American Society for Information Science and technology 58,\n9 (2007), 1381\u20131385.\n[3] Alexandre Bovet and Hern\u00e1n A Makse. 2019. Influence of fake news in Twitter\nduring the 2016 US presidential election. Nature communications 10, 1 (2019),\n1\u201314.\n[4]Lia Bozarth and Ceren Budak. 2020. Market forces: Quantifying the role of\ntop credible ad servers in the fake news ecosystem. In The International AAAI\nConference on Web and Social Media .\n[5] Joao MM Couto, Julio CS Reis, Italo Cunha, Leandro Araujo, and Fabricio Ben-\nevenuto. 2022. Characterizing Low Credibility Websites in Brazil through Com-\nputer Networking Attributes. In 2022 IEEE/ACM International Conference on\nAdvances in Social Networks Analysis and Mining (ASONAM) (Istanbul, Turkey).\nIEEE/ACM.\n[6] Venkata Rama Kiran Garimella and Ingmar Weber. 2017. A long-term analysis\nof polarization on Twitter. In Eleventh international AAAI conference on web and\nsocial media .\n[7]B\u00e1rbara Gomes Ribeiro, Manoel Horta Ribeiro, Virgilio Almeida, and Wagner\nMeira Jr. 2022. Analyzing the \u201cSleeping Giants\u201d Activism Model in Brazil. In\n14th ACM Web Science Conference 2022 (Barcelona, Spain) (WebSci \u201922) . ACM,\nNY, USA, 87\u201397. https://doi.org/10.1145/3501247.3531563\n[8]Nir Grinberg, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson, and\nDavid Lazer. 2019. Fake news on Twitter during the 2016 US presidential election.\nScience 363, 6425 (2019), 374\u2013378.\n[9] Andrew Guess, Jonathan Nagler, and Joshua Tucker. 2019. Less than you think:\nPrevalence and predictors of fake news dissemination on Facebook. Science\nadvances 5, 1 (2019), eaau4586.\n[10] Mohamad Hoseini, Philipe Melo, Manoel J\u00fanior, Fabr\u00edcio Benevenuto, Balakrish-\nnan Chandrasekaran, Anja Feldmann, and Savvas Zannettou. 2020. Demystifying\nthe Messaging Platforms\u2019 Ecosystem Through the Lens of Twitter. In IMC\u201920,\n20th ACM Internet Measurement Conference (2020). ACM, Virtual Event, USA,\n345\u2013359. https://doi.org/10.1145/3419394.3423651\n[11] Eslam Hussein, Prerna Juneja, and Tanushree Mitra. 2020. Measuring misinfor-\nmation in video search platforms: An audit study on YouTube. Proceedings of\nthe ACM on Human-Computer Interaction 4, CSCW1 (2020), 1\u201327.\n[12] Juhi Kulshrestha, Muhammad Zafar, Lisette Noboa, Krishna Gummadi, and\nSaptarshi Ghosh. 2015. Characterizing information diets of social media users. In\nProceedings of the international AAAI conference on web and social media , Vol. 9.\n218\u2013227.\n[13] Sahil Loomba, Alexandre de Figueiredo, Simon J Piatek, Kristen de Graaf, and\nHeidi J Larson. 2021. Measuring the impact of COVID-19 vaccine misinformation\non vaccination intent in the UK and USA. Nature human behaviour 5, 3 (2021),\n337\u2013348.\n[14] Media Bias/Fact Check. 2015. https://mediabiasfactcheck.com/. Accessed 30 Nov\n2022.\n[15] Newsguard. 2022. https://www.newsguardtech.com/. Accessed 30 Nov 2022.\n[16] Julio CS Reis, Philipe Melo, Fabiano Bel\u00e9m, Fabricio Murai, Jussara M Almeida,\nand Fabricio Benevenuto. 2023. Helping Fact-Checkers Identify Fake News\nStories Shared through Images on WhatsApp. In Proceedings of the 29th Brazilian\nSymposium on Multimedia and the Web . 159\u2013167.\n[17] Gustavo Resende, Philipe Melo, Hugo Sousa, Johnnatan Messias, Marisa Vas-\nconcelos, Jussara Almeida, and Fabr\u00edcio Benevenuto. 2019. (Mis)Information\nDissemination in WhatsApp: Gathering, Analyzing and Countermeasures. In\nThe World Wide Web Conference (San Francisco, CA, USA) (WWW \u201919) . As-\nsociation for Computing Machinery, New York, NY, USA, 818\u2013828. https:\n//doi.org/10.1145/3308558.3313688\n[18] Filipe N Ribeiro, Koustuv Saha, Mahmoudreza Babaei, Lucas Henrique, Johnnatan\nMessias, Fabricio Benevenuto, Oana Goga, Krishna P Gummadi, and Elissa M\nRedmiles. 2019. On microtargeting socially divisive ads: A case study of russia-\nlinked ad campaigns on facebook. In Proceedings of the conference on fairness,accountability, and transparency . 140\u2013149.\n[19] Manoel Horta Ribeiro, Raphael Ottoni, Robert West, Virg\u00edlio AF Almeida, and\nWagner Meira Jr. 2020. Auditing radicalization pathways on YouTube. In Proceed-\nings of the 2020 conference on fairness, accountability, and transparency . 131\u2013141.\n[20] Vinay Setty and Erlend Rekve. 2020. Truth be Told: Fake News Detection Using\nUser Reactions on Reddit. In Proceedings of the 29th ACM International Conference\non Information & Knowledge Management . 3325\u20133328.\n[21] Lisa Singh, Leticia Bode, Ceren Budak, Kornraphop Kawintiranon, Colton Padden,\nand Emily Vraga. 2020. Understanding high-and low-quality URL Sharing on\nCOVID-19 Twitter streams. Journal of Computational Social Science 3, 2 (2020),\n343\u2013366.\n[22] Kathie M d\u2019I Treen, Hywel TP Williams, and Saffron J O\u2019Neill. 2020. Online\nmisinformation about climate change. Wiley Interdisciplinary Reviews: Climate\nChange 11, 5 (2020), e665.\n[23] Yash Vekaria, Rishab Nithyanand, and Zubair Shafiq. 2022. The Inventory is\nDark and Full of Misinformation: Understanding the Abuse of Ad Inventory\nPooling in the Ad-Tech Supply Chain. arXiv preprint arXiv:2210.06654 (2022).\n[24] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false\nnews online. science 359, 6380 (2018), 1146\u20131151.\n[25] Jevin D West and Carl T Bergstrom. 2021. Misinformation in and about science.\nProceedings of the National Academy of Sciences 118, 15 (2021), e1912444117.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Finding fake news websites in the wild", "author": ["L Araujo", "JMM Couto", "LF Nery", "IC Rodrigues"], "pub_year": "2024", "venue": "arXiv preprint arXiv \u2026", "abstract": "The battle against the spread of misinformation on the Internet is a daunting task faced by  modern society. Fake news content is primarily distributed through digital platforms, with"}, "filled": false, "gsrank": 310, "pub_url": "https://arxiv.org/abs/2407.07159", "author_id": ["1YEBhngAAAAJ", "2J0S38YAAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:PATzabGuAVsJ:scholar.google.com/&output=cite&scirp=309&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D300%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PATzabGuAVsJ&ei=OrWsaI6ND8DZieoPqdqh8QU&json=", "num_citations": 2, "citedby_url": "/scholar?cites=6557714609438131260&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:PATzabGuAVsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2407.07159"}}, {"title": "Understanding online news behaviors", "year": "2019", "pdf_data": "Understanding Online News Behaviors\nFrank Bentley\nYahoo/Oath\nSunnyvale, CA\nfbentley@oath.comKatie Quehl\nYahoo/Oath\nSunnyvale, CA\nkatiequehl@oath.comJordan Wirfs-Brock\nYahoo/Oath\nSunnyvale, CA\njordan.wirfs-brock@\ncolorado.eduMelissa Bica\nYahoo/Oath\nSunnyvale, CA\nmelissa.bica@colorado.edu\nABSTRACT\nThe news landscape has been changing dramatically over\nthe past few years. Whereas news once came from a small\nset of highly edited sources, now people can find news from\nthousands of news sites online, through a variety of chan-\nnels such as web search, social media, email newsletters, or\ndirect browsing. We set out to understand how Americans\nread news online using web browser logs collected from 174\ndiverse participants. We found that 20% of all news sessions\nstarted with a web search, that 16% started from social me-\ndia, that 61% of news sessions only involved a single news\ndomain, and that 47% of our participants read news from\nboth sides of the political spectrum. We conclude with key\nimplications for online news, social media, and search sites\nto encourage more balanced news browsing.\nCCS CONCEPTS\n\u2022Human-centered computing \u2192Empirical studies in HCI ;\nSocial media; \u2022Applied computing \u2192Media arts ;\nKEYWORDS\nNews; Web Search; Log Analysis; Polarization; Bias\nACM Reference Format:\nFrank Bentley, Katie Quehl, Jordan Wirfs-Brock, and Melissa Bica.\n2019. Understanding Online News Behaviors. In CHI Conference\non Human Factors in Computing Systems Proceedings (CHI 2019),\nMay 4\u20139, 2019, Glasgow, Scotland UK. ACM, New York, NY, USA,\n11 pages. https://doi.org/10.1145/3290605.3300820\n1 INTRODUCTION\nTraditionally, if one wanted to read news they could turn to\ntheir local newspaper of record. These papers were highly\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear\nthis notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with\ncredit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request\npermissions from permissions@acm.org.\nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK\n\u00a92019 Association for Computing Machinery.\nACM ISBN 978-1-4503-5970-2/19/05. . . $15.00\nhttps://doi.org/10.1145/3290605.3300820edited and typically produced daily. While sometimes these\nsources represented the opinions or political views of the\neditor, they were generally seen as a trusted source of truth\nto understand what was happening in the community and\nthe world. From the 1666 publication of the London Gazette\nto Publick Occurrences, America\u2019s first newspaper in 1690,\nthrough the local and regional newspapers that remained\nstrong through most of the 20th century, when it came to\nreading written news, very little changed.\nHowever, over the past few decades the news landscape in\nAmerica has changed dramatically. The web and alternative\nnews sources have added many choices to the ways that\npeople can find and consume news. In addition, the collapse\nof local, daily newspapers [ 2] and the growing 24-hour cable\nnews cycle have provided additional changes.\nThere are now thousands of news sources available at any\ntime online, representing a wide variety of political view-\npoints and regional, national, or international focus. Now,\nusers can find a single article in isolation, through a web\nsearch, social media post, email newsletter, or other direct\nlinks from the web or from a friend. Browsing through all\nof the top stories of the day, as one would read a newspaper,\nis becoming less common as news arrives in different ways\nthrough direct article links [21].\nThese changing practices highlight a number of questions\naround how news is consumed in 2018. Although we have\nconducted hundreds of qualitative interviews about news be-\nhavior over the years, we wanted to more deeply understand\nactual behaviors in news consumption over remembered\ninteractions. We wanted to quantify the role of different re-\nferring sites (e.g. social networks, search, email) in prompting\nnews consumption as well as explore temporal and session-\nbased statistics about news consumption on the web \u2014 topics\nthat are not well covered in the existing news literature.\nSpecifically, we had the following research questions:\n(1)How do people get to news articles on the web? What\npercent are reached through search vs. social media?\n(2)What temporal patterns exist in browsing news on\nthe web? Are there particular types of news that are\nconsumed most often in the morning? On weekends?\n(3)How many different news domains do people visit? Do\npeople focus their attention on one end of the political\nspectrum? Or do they seek broad viewpoints?\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 1\nTo answer these questions, we collected complete web\nbrowsing logs from the computers of 174 diverse Americans,\ncovering an average of 138 days of browsing. We then ana-\nlyzed these logs to identify web sessions that included news,\nthe referring source that led to news articles, the topics of\narticles that were read, and the political biases of the sources\nthat participants turned to. This data has helped us to more\ndeeply understand news browsing behaviors in 2018.\nOur contribution lies in quantifying how participants get\nto news and the prevalence of different sources. We also\nshow the diversity of bias in the sources that people turn\nto and temporal patterns throughout the day in the topics\nthat people are reading. This data is important for the design\nof future news platforms, social networks, search engines,\nand email newsletters, as well as for the American political\nprocess itself.\n2 RELATED WORK\nResearchers have been studying how people receive news\ninformation for quite some time. Modern research into this\ntopic in the 1980s and 90s focused on the role of TV broadcast\nnews versus newspapers in how people receive news. Chaf-\nfee and Frank [ 5] explored the differing roles that TV news\nand newspapers played in bringing information to different\naudiences, with newspapers being read by people more ac-\ntively seeking news and television reaching groups that were\nmore lacking in political information.\nPrior [ 20] pointed to the effects of many of these changes\nin the news media landscape. Cable news contributes to\npolarization in political opinions, and viewing habits vary\ngreatly, with some households watching many hours a day\nbut most households not watching at all. He also showed that\naccess to the Internet had \u201cwidened gaps in news exposure\n[and] political knowledge\u201d with some engaging much more\nthan others with online news.\nTewksbury [ 24] found two different types of news con-\nsumers, one group that actively attended to a small number\nof topics, and a larger group that browsed a wider variety of\ntopics. Looking deeper at the people who do not engage with\nthe news, Eliasoph [ 9] wrote the stigma Americans have\naround talking about politics at work or in public has led to\ndiminished awareness of political issues and general apathy\ntowards much of the news and politics in the country.\nOnline News Consumption\nThe Internet brought new ways for people to get their news,\nchanging the paradigm of broadcast and print to include\non-demand access to individual articles. Goel et al. [ 15] con-\nducted a study in 2012 analyzing how people browse the\nweb online. Interestingly, in this study, they found that the\naverage user only browsed five news pages per month. Wefind this number surprisingly low, but do not have the au-\nthors\u2019 definition of a news site to know if it included celebrity,\nsports, or local news.\nOther researchers specifically explored news browsing in\nmore detail. Tewksbury [ 23] analyzed web browsing logs\nfrom 13 specific news sites using data from 2000. They an-\nalyzed the specific topics of news that users viewed (e.g.\nsports, politics, weather, etc.) finding that 54% of users only\nbrowsed news in a single topic over the two months of data\nthat they collected.\nPurcell et al. [ 21] conducted a survey of news behaviors,\nfinding that American news habits are based on \u201cforaging\nand opportunism\u201d and that Americans report visiting be-\ntween two and five online news sources. Kleppe and Otte\n[16] studied the news browsing behaviors of young Dutch\nparticipants and found the majority of news browsing session\nstarted on news home pages. Flaxman et al. [ 11] explored the\nnews behaviors of participants who more heavily engaged\nin news, finding that the majority of their browsing started\non a news home page and that only 6% of sessions started\nfrom social media sites. We expected things to have changed\ndramatically since their 2013 data, with the rise of social\nmedia potentially driving users to a broader set of sites.\nSocial Media and the Filter Bubble\nMore recent changes in online news occurred through the\ndevelopment of social media platforms as a place to share and\ndiscuss news. This opened up many new ways for people to\ndiscover a news article online. Instead of needing to actively\nchoose to go to a news website or explicitly search for a news\ntopic, now news began to passively arrive on social media in\nposts shared from friends and family or from news sources\nthat a user follows.\nIn 2013, Weeks and Holbert [ 25] studied social media news\nusers, finding them to be largely young, technologically lit-\nerate, and infrequent consumers of newspapers or television\nnews. They also found that political partisans share news on\nsocial media more often than moderates, potentially leading\nto a more biased news experience for those who follow them.\nLottridge and Bentley [ 18] studied the wider variety of\nways that people could share news with each other \u2013 in-\ncluding privately in text messaging, semi-publicly on social\nmedia, or publicly on sites such as Twitter or Reddit. They\nfound differences in the types of news shared on each plat-\nform, with the most polarizing political content shared more\npublicly. This has clear implications for the types of news\npeople receive if they are tuned into these social sources.\nSocial media platforms have led to what has been termed\nthe \u201cfilter bubble,\u201d [ 19] where users are said to receive news\nof a particular political bias due the the accounts that they\nfollow and the friends that they have on social media.\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 2\nMultiple studies have explored partisanship online and the\npolitical leanings of certain news publications. Pew Research\nhas tracked political polarization of both news sources and\nthe general population over time with reports in 2014 [ 7]\nand 2017 [ 8]. The 2017 study shows a large-scale shift in the\npolitical leanings of Americans to the left over time.\nVarious sites such as All Sides1and Media Bias/Fact Check2\nmaintain ratings of news sources and their biases. A recent\nstudy from the Harvard Berkman Center [ 10] also explored\nthe political biases of a number of sources based on how they\nwere shared online. Researchers such as Resnick et al. [ 22]\nhave explored strategies for one to expand their filter bubble\nto be exposed to articles from more diverse viewpoints.\nIn addition is the rise of so-called \u201cfake news\u201d \u2014 stories\nthat are published but not true. Flintham et al. [ 12] explored\npeople\u2019s ability to identify \u201cfake news\u201d online and found that\none third of their respondents had been fooled by fake news\nin the past.\nThis related work raised more questions for us than it an-\nswered. Platforms such as Facebook or Twitter have changed\nthe way that news is presented and sorted in the feed over\nthe years, which could also have a large impact on how peo-\nple get to news from social media sites. We wanted to take a\nfresh look at how people browse news on their computers,\nhow they get to news articles (e.g. via search, social media,\nor browsing), and how users engage with multiple news sites\nwithin a news session. This would enable us to develop a\nbroad understanding of current news practices on the web\nin America, as well as how news sites and search engines\ncan adapt to these current practices.\n3 METHODS\nIn order to broadly understand how people are consuming\nnews on the web, we collected a set of complete web browser\nhistories from the computers of a diverse set of Americans.\nParticipants were recruited on Amazon Mechanical Turk.\nAfter agreeing to participate, users were directed to an online\nsurvey which provided a detailed explanation of the data we\nwere collecting and why, followed by instructions for how\nto find one\u2019s own browser history file (for either Chrome or\nFirefox) stored locally on their computer. The files contained\na timestamped entry for each webpage viewed for either the\nlast 3 months (Chrome) or since the user first started using\nthe browser (Firefox), in addition to the URL and page title.\nWe paid participants $5 for their browser history files, and\nreceived valid data from 174 participants, totaling nearly 10\nmillion unique page views over an average of 138 days of his-\ntory per participant. This amounted to an average $60/hour\n1https://www.allsides.com/media-bias/media-bias-ratings\n2https://mediabiasfactcheck.com/wage and is in line with existing research that shows brows-\ning history being valued at about the price of a Big Mac [ 4].\nThese participants are representative of the general US adult\npopulation in terms of age (18-72), gender (49% female), and\nhousehold income (median $50k), and reside in 39 distinct\nUS states. Previous studies have shown that MTurk samples\ncan be quite accurate when studying technology use in the\nbroader American population [3].\nWe then created a list of 1,160 unique news domains. We\nbegan with the list of most trafficked news sites from the\ncomScore Media Metrix [ 6] and added the local news sites\nof major television affiliates (ABC, NBC, CBS, Fox) and local\nnewspapers that are a part of the ten largest media conglom-\nerates. The analysis below will count any page view from\none of these domains as a \u201cnews page.\u201d Any page in this set\nwith a URL longer than 50 characters was labeled as an \u201car-\nticle page.\u201d We manually checked several hundred URLs and\nfound no misclassifications on articles given this approach.\nTo understand the topics of articles, we ran each article\nthrough the Yahoo Content Analysis Service.3This system\nreturned Yahoo Content Taxonomy (YCT) and Wikipedia\ntags for each article. YCT is a hierarchical classification sys-\ntem for news content, with top level tags such as \u201cnews,\u201d\n\u201centertainment, \u201d and \u201csports, \u201d and lower-level categories such\nas \u201cpolitics,\u201d \u201cmovies,\u201d and \u201cfootball.\u201d\nTo understand the political bias of news sources that par-\nticipants visited, we utilized the classification from Media\nBias/Fact Check.4This was the largest database of sources\nthat we could find, with 1,434 sources listed in five cate-\ngories from Left Bias (-2), Left-Center Bias (-1), Least Biased\n(0), Right-Center Bias (1) and Right Bias (2). All domains that\nusers visited were tagged according to this taxonomy.\nWhile other lists of bias exist from sources such as Pew [ 1],\nthese lists contain far fewer sources. In general, these lists\nhighly agree on their ratings, with sources such as HuffPost\nand Mother Jones on the far left, National Public Radio (NPR)\nand the New York Times to the center-left, Reuters and the\nAssociated Press (AP) as unbiased, the New York Post and\nForbes as center-right, and Breitbart and Fox News on the\nfar right.\nWe compared the Media Bias/Fact Check list with a list of\n115 sources from a recent paper from the Berkman Center\nat Harvard [ 10] and found a 0.77 Pearson correlation with\np<2.2\u221710\u221216when comparing bias ratings for all 87 sources\nthat the lists had in common. We also correlated the list\nfrom Media Bias/Fact Check with 105 sources listed in the\nMedia Bias Chart from Ad Fontes Media5. We found a 0.92\nPearson correlation with p<2.2\u221710\u221216for the 85 sources\n3https://developer.yahoo.com/search/content/V2/contentAnalysis.html\n4https://mediabiasfactcheck.com/\n5https://www.adfontesmedia.com\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 3\nthese lists shared. Finally, we compared the larger list with\na set of 200 matching sources from the AllSides Media Bias\nRatings.6Here, we found a Pearson correlation of 0.81 with\np<2.2\u221710\u221216. These correlations are strong enough for us\nto trust the larger partisanship classification of 1,434 sources\nfor our analysis. It is important to have such a large set of\nsources in order to accurately determine the broader media\nconsumption diets of our participants \u2014 as described below\nour participants visited hundreds of these sources.\nWe analyzed the web history data in terms of web \u201cses-\nsions.\u201d We used a one-hour-idle session delimiter to break\nweb browsing activity into distinct sessions of interaction.\nThis is standard practice, following guidance in Lalmas et al.\n[17] and is widely used throughout the Internet industry to\nsegment online behavior.\nAll research was approved by our institutional processes\nfor conducting work with human subjects and log data. Par-\nticipants were clearly informed about our institutional iden-\ntity, the exact data that was being collected, and our data\nretention policies.\n4 FINDINGS\nOur dataset contained 9,487,564 total page views from our\n174 participants. Using one hour idle session delimiters, there\nwere 43,415 total web browsing sessions in this dataset. In\nthis section, we will explore general news reading behaviors,\nhow users arrived at news articles, temporal patterns, and\nbehaviors within sessions.\nTo check the representative nature of our dataset, we com-\npared visitation rates with audience data from the ComScore\nMedia Metrix [ 6] from June 2018 (the month of our study) in\nthe \u201cNews/Information\u201d category. This report includes the\nnumber of visitors for the each of the top news sites in the\nUnited States. We performed a Pearson correlation between\nthe audience numbers for the top 100 sites and the number\nof users in our sample who visited each site. The correlation\nwas quite strong, at 0.87 (p<0.001), showing that our partici-\npants visited the same news sites in similar proportions to\nthe overall US population.\nGeneral News Behaviors\nWithin our dataset, there were 126,298 news page views in\n10,026 total sessions (an average of 5.3 news pages in 0.4\nsessions per day). Interestingly, 23% of all web browsing ses-\nsions contained news page views, even though news pages\nonly accounted for 1.3% of all web page views. For our partic-\nipants, news was a frequent activity, but not one that often\ninvolved deep exploration. There were a total of 83,164 news\narticle views in the dataset, at at average of 3.6 per user per\nday. However, the median number of articles per day was\n6https://www.allsides.com/media-bias/media-bias-ratingsFigure 1: Total number of articles viewed (left) and unique\nnews domains visited (right) per participant.\nFigure 2: Histogram of mean media bias scores for the arti-\ncles that each user read.\n0.8, showing a definite skew in news reading across the pop-\nulation, aligning with findings from Prior [ 20] about the vast\ndifferences in news consumption in America.\nParticipants visited a mean of 25 different news domains in\nthe average of 138 days of data that we collected, with a me-\ndian of 19. Figure 1 illustrates the wide range of unique news\nsources visited by each participant. Our dataset includes vis-\nits to a broad range of sources\u2014everything from HuffPost on\nthe left to The Drudge Report on the right. Figure 2 illustrates\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 4\nFigure 3: The percentage of news that a user receives from\ntheir top ten sources. The median user receives 47% of their\nonline news from just a single source.\nthat mean media bias scores for articles that each user read,\nshowing a range of left and right leaning sources, with a ma-\njority falling moderately left of center. We find it interesting\nthat every participant visited at least one news site, with 75%\nof participants viewing more than eight distinct sites and\n25% of participants viewing more than 34. One participant\nvisited 120 distinct news sites in their dataset. This is much\nhigher than the two to five sites reported in previous survey-\nbased studies [ 21] and illustrates why behavioral studies are\nnecessary to gain an accurate ground truth in topics where\nusers might not consider or remember each interaction. In\naddition, as mentioned in the Introduction, there are more\nnews sites available online today than in the past.\nExploring the domains further, we found that the median\nparticipant read 47% of their news articles from a single\nsource. Figure 3 shows the distribution of news read from\na user\u2019s top ten news sources. By the second source, the\nmedian user has read 66% of all of the news articles that they\nconsume. This increases to 87% by the fifth source and 96%\nby the tenth source.\nNext, we explored the variation of sources visited per\nparticipant. Were users in their own \u201cfilter bubbles\u201d or didFigure 4: Mean (circle) and standard deviation (lines) of me-\ndia bias scores for the articles that each user read. Users are\narranged by increasing mean score.\nthey view a variety of sources? Figure 4 shows the mean\nmedia bias scores of each participant in our study based on\nall articles read. Error bars indicate the standard deviation.\nThe majority of participants read articles from sources that\nleaned to the left \u2013 87% of participants had a mean media\nbias score less than zero. When taking into account stan-\ndard deviation, only 48% received the vast majority of their\nnews from left-leaning sources. Only 5% of participants had a\n(mean\u2212standardde viation)score above zero, with the vast\nmajority of their news coming from right-leaning sources.\nThe relatively high average standard deviation (0.66) shows\nthat most participants took in news from at least some dif-\nfering perspectives. In fact, 47% of participants had standard\ndeviation lines that crossed the center line. Perhaps the po-\nlarization is not as strong as some would indicate, although\nwe do see the general left-leaning bias in the articles read,\nwhich matches similar data from Pew about the American\npopulation as a whole [ 8] and matches behaviors seen in\nthe broader population through the ComScore Media Metrix\ndata [ 6] where only one of the top ten online news sources\nwas right-leaning (foxnews.com) as of June, 2018. Our data\nalso aligns with the political views of the general popula-\ntion: 38% of our participants viewed at least one article on\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 5\nFigure 5: The origin of the first article view in a news session.\nBrowsing for news stories represents only 34% of the ways\nparticipants landed on an article.\nfoxnews.com, compared to Donald Trump\u2019s 41% approval\nrating at the time of the study [ 14] and 11 percentage points\nlarger than the size of the Republican base (27% in June 2018)\n[13].\nHow People Get to News Articles\nNews sessions can start in many ways. Historically, news\nwas something that one browsed for or received passively.\nOne could read through a newspaper and stop on articles that\nwere interesting or listen to the evening news on the radio\nor TV absorbing the stories that were shared, but with no\ncontrol over what was broadcast. The Internet brought many\nnew ways to discover news content. Now, people can browse\nthe news on a news website or portal, similar to browsing a\nnewspaper. But they can also get to articles through social\nmedia posts, web searching, email links, and other online\nsources such as Reddit, YouTube, or Wikipedia.\nWe were interested in examining the ways that users\nstarted a news session. We took the first news article pageview\nin each news session and found the referring page in the\nbrowser logs. Figure 5 shows the different ways that our\nparticipants arrived at on the first news article of a session.\nAlthough it\u2019s the most frequent single way to get to an arti-\ncle, only 34% of articles were reached through browsing on a\nnews site or portal (such as going to http://www.nytimes.com\nand clicking on a story). Given that this was the original way\nthat news was read, this relatively small percentage repre-\nsents a massive change to the way that news is consumed.The remaining two-thirds of the time, users reached a\nstory by a link from another site or shared to them by a\nfriend. Web search represented the largest portion of these\ndirect links, with 20% of news sessions starting from the\nresult of an online search. Links from Social Media sites (e.g.\nFacebook, Twitter, LinkedIn) led to 16% of news sessions,\nshowing the growing importance of these sites in shaping\none\u2019s media diet compared to the 6% observed in 2013 [ 11].\nOther online sites such as Reddit (5%), YouTube (2%) and\nWikipedia (0.4%) also led users to the news, in addition to\nemail (including Gmail, Yahoo Mail, and Outlook/Hotmail\ndomains) at 5%. We find the high volume of news preceded\nby a search at 20% to be quite high, a point we will return to\nin the discussion.\nWe observed some variation in how users arrived at news\nstories of different types. Table 1 shows the breakdown of\ndifferent referral mechanisms for different types of news\ncontent. Finance, Sports, and Travel news had the highest\npercentage of searches leading to an article. Health and Poli-\ntics led social referrals and were also at the top for email re-\nferrals. Technology, Politics, and Sports led in articles found\nvia browsing a news site. Entertainment, Health, and Finance\nwere the least likely to be found via browsing on a news site.\nWe will now turn to media bias scores by referring source.\nThe mean absolute value of the bias score from all articles\nread was 1.02. The most biased articles came from social\nmedia (1.07) and email (1.04), with the least biased articles\ncoming from search results (0.92) and Reddit (0.93). We find\nthe lower bias scores from search results to be interesting,\nand will return to implications for search in the Discussion.\nWe also find the higher bias in email and social media to\nbe interesting, likely because users receive email update\nnewsletters from more biased sources (e.g. the daily \u201cHuff-\nPost Morning Email\u201d) As has been shown by Weeks et al.\n[25], partisan users share more frequently on social media.\nTemporal Patterns of News Reading\nNext, we were interested in the temporal patterns of news\nreading on the web. Do people not want to wake up to serious\nnews? Or do they catch up on celebrity news in the evening?\nWe used our behavioral data from the logs to confirm or deny\nthese and other statements about news reading. All analysis\nwas conducted in the local time zone of the user, and we\nsegmented all news articles by hour of day and day of week.\nFigure 6 shows the number of news sessions observed by\nhour of day across all of our participants. Interestingly, the\nhighest news consumption occurs in the evening, with the\nthree highest points being from 6\u20138pm. There is another\nsmall peak around noon and one at 7am. Overall, news con-\nsumption stays quite high from 6am through 9pm. This is in\ninteresting contrast to historical patterns of news consump-\ntion, where one would wake up to the morning paper and\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 6\nCategory Search Social Reddit Email YouTube Wikipedia Other Link Browsing\nNews 23.7% 15.5% 1.4% 6.4% 0.9% 0.7% 33.9% 17.4%\nEntertainment 25.1% 15.7% 1.5% 5.0% 0.8% 0.7% 37.2% 13.9%\nTechnology 17.3% 8.5% 2.5% 0.7% 1.1% 0.5% 41.8% 27.7%\nSports 27.0% 14.3% 1.8% 4.6% 0.4% 0.2% 29.8% 22.0%\nPolitics 23.1% 16.9% 0.9% 6.9% 0.7% 0.4% 27.1% 24.1%\nTravel 28.3% 11.8% 1.2% 5.6% 1.6% 0.3% 33.0% 18.1%\nFinance 38.8% 13.3% 0.8% 6.1% 0.0% 0.0% 26.3% 14.6%\nHealth 27.4% 18.6% 5.2% 5.7% 1.0% 0.2% 27.6% 14.3%\nTable 1: How participants arrived at news articles of various types at the start of sessions containing news.\nFigure 6: Total news sessions by hour of day.\nFigure 7: Total news sessions by day of week.\nunless they also purchased an evening paper, took care of\nmost of their written news consumption in the morning.Figure 8: Topics of news articles views by hour of day.\nWe were also interested in news consumption by day of\nweek. Were there particular days with more news consump-\ntion than others? Figure 7 shows that news consumption is\nfairly flat, with a slight decreasing trend as the week goes\non from Monday to Saturday, but only a difference of 15%\nbetween the highest (Monday) and lowest (Saturday) days.\nAlthough the total number of news sessions remains fairly\nstable, it is interesting to note that weekends showed 50%\nfewer total web page views than the highest weekdays (Tues-\nday and Wednesday), making news a much higher percent\nof total web browsing on weekends.\nWe were further interested in the topics of articles that\nwere read throughout the day and by day of week. As dis-\ncussed in the Methods section, we obtained YCT categories\nfor each article. We then looked at topics by time of day and\nday of week to see if there were specific temporal dynamics\nto reading news on particular topics. Figure 8 shows the\ntop five news topics (hard news, entertainment, technology,\nsports, and politics) by the hour of day that the article was\nread. At the 8am hour, harder news is the most common\ntype of news read. However, entertainment news surpasses\nhard news for the 10am, 11am, 1pm, and 2pm hours, likely\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 7\nFigure 9: Number of news articles viewed in a session. 20%\nof all news sessions contain just one article that was read.\nfor a momentary break and distraction during the workday.\nEntertainment news peaks at 1pm. Hard news then regains\nthe lead from 3pm through midnight with it\u2019s daily peak at\n10pm.\nSports news reading peaks at 8pm and 11pm, just as the\nevening games are kicking off and ending (the study was\nconducted during baseball season in America). Political news\nalso peaks at 8pm, surpassing technology and sports read-\ning for the 8pm and 9pm hours whereas technology news\nsurpasses both sports and politics for much of the workday.\nThese patterns illustrate the overall popularity of news\nand entertainment news, which track each other for much of\nthe day. It also shows that entertainment news is not more\npopular during the morning waking-up hours.\nWithin-Session Behavior\nWe now turn to look within sessions to understand how par-\nticipants consumed multiple news stories within a session.\nParticularly, we explored if participants were viewing mul-\ntiple articles on the same topics as well as the diversity of\nsources within the session.\nFigure 9 shows the number of news articles viewed in each\nnews session. Overall, 20% of news sessions involved only\na single article, with an additional 13% containing just two\narticles. 43% of all news sessions had over five articles viewed.\nInterestingly, the source of the news session had a significant\nimpact on the number of news articles viewed in that session.\nSessions started from email links to the news resulted in the\nmost news browsed (at an average of 14 pages). Search and\nReddit both led to an average of 12 news pages being viewed,\nwhile social links to news led to an average of 11 news pages\nviewed within that session. All of these are larger than theFigure 10: Number of distinct news domains browsed within\na news session.\naverage news session of 9.5 pages viewed, given a much\nsmaller number of articles read when directly browsing news\nsites. This can seem counter-intuitive, but often users arrive\non news portals just to browse the headlines or on their way\nto read their email without clicking on any articles.\nThe largest number of sessions with news (61%) involved\njust a single domain, as shown in Figure 10. Yahoo News,\nThe New York Times, CNN, MSN, and BuzzFeed were the\nmost popular sources viewed in sessions with no other news\ndomains. Sessions with two domains comprised 22% of news\nsessions, with the most common pairing being CNN and Ya-\nhoo, occurring 179 times. Both of these sources score as fairly\nunbiased in the center-left category (-1). The New York Times\nand Politico were the next most common pairing, occurring\n102 times in the dataset. These are also both categorized\nas center-left. Eight percent of sessions contained three do-\nmains, 4% contained four, and 5% of sessions contained five\nor more news domains.\nAs the number of domains visited increases, the trend of\nbrowsing sites with a similar bias score continues. Overall,\nthe news sites that are browsed together within a session\nhave an average variance of 0.29 points of bias. Only 7.7% of\nsessions include sites with a bias score variance greater than\none. Participants were not frequently going out of their way\nto find diverse accounts of a story.\nOf sessions that contained articles where we could ex-\ntract Wikipedia entities for people or places mentioned in\nthe article, 36% contained more than one domain browsed.\nOf these sessions, 70% contained multiple articles with the\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 8\nsame Wikipedia entity. The most common Wikipedia en-\ntities where users viewed articles from multiple domains\nwithin the same session included: Donald Trump, White\nHouse, Melania Trump, Kim Kardashian, Catherine Zeta-\nJones, Anthony Bourdain, and Star Trek. This represents a\nmix of political and celebrity/entertainment news similar to\nthe overall trends across all articles viewed.\nIn summary, we have seen that 61% of all news sessions\nonly involve a single domain and 20% only involve a single\narticle. When users do branch out, they most often seek sites\nwith similar political bias, however 7.7% of the time they\nlook for a news source with a different viewpoint. 70% of the\ntime that users visit multiple news domains in a session, they\nread a story on the same topic on multiple sites, representing\n25% of all news sessions. This analysis has allowed us to\nmore deeply understand news browsing behaviors and how\npeople get to and explore news on a variety of topics.\n5 LIMITATIONS\nWhile this study enabled us to get a deep, behavioral look\ninto current news consumption in the United States, there\nare some limitations. We are reliant on the Mechanical Turk\nuserbase for our data, which may be more likely to use desk-\ntop computers to take their HITs. However, previous research\nhas shown large agreement between the behaviors of this\npanel and the broader US population [ 3]. Our sample only\ncontains data from 174 participants. While we have a high\ndegree of diversity in the panel that matches the US popula-\ntion (ages 18-72, 49% female, $50k median household income,\nand 39 distinct US states), this may not be enough to capture\nthe very diverse user behaviors across over one thousand\nnews sites. Larger samples should be studied by companies\nwho have access to this much larger browser history data.\nWe were unable to capture mobile browsing behavior for\nseveral reasons. Most mobile applications (e.g. Facebook,\nTwitter) use their own embedded browsers, so news page\nviews in these applications are not captured in mobile brows-\ning logs. As it is also not possible to get browsing log data\nfrom within dedicated news apps (e.g. The NYT app), we\nfocused on the desktop web for our analysis, where we could\nget complete logs of user behavior over months of interac-\ntions.\nFinally, this dataset was collected in late June 2018. With\nan average of 138 days of data per participant, this means\nthat almost all data was from the Spring. There are likely\nseasonal differences in use (e.g. sports during the NFL season)\nand conducting studies with larger log sets or at other times\nof the year can be useful future work.\n6 DISCUSSION\nBy analyzing the behavioral data of a broad range of Ameri-\ncans and how they browse news on the web, we have beenFigure 11: The current search experience on Google (top) and\nYahoo (bottom), highlighting news results in boxes on top of\nalgorithmic search results.\nable to more deeply understand news reading behaviors in a\nway that avoids the bias of self-reporting. We have explored\nhow users get to news articles via search, social media, email,\nand other sources as well as how they interact within news\nsessions in terms of the political bias of the news sites visited\nand topics viewed by time of day.\nThrough this analysis, several larger themes have emerged,\nwith key implications for the design of news platforms, as\nwell as for the understanding of news consumption in gen-\neral. These include the importance of search, ways to address\ntemporal browsing preferences, and a reflection on news po-\nlarization and filter bubbles.\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 9\nSearch and News\nOne of the most interesting findings to us was discovering\nthat 20% of all news sessions begin with a web search, as we\ndid not anticipate so much traffic driven this way. We also\nobserved that news sessions that start from search have the\nmost neutral partisan bias of all types of news sessions.\nCurrently, when searching for news topics or celebrities\non Google or Yahoo, a direct display box is shown with top\nnews stories, as shown in Figure 11. Based on the findings\nof our analysis, we know that users seek multiple stories on\nthe same topic in 25% of news sessions. Search engines can\nmake this experience easier by aggregating news stories on\nparticular topics (e.g. in the Obama example above, showing\nstories about Senator John McCain together and stories about\nhis trip to Chicago together) so that users can easily find\ndifferent viewpoints on the same topic.\nIn addition, search engines can indicate the political bias\nof sources and explicitly include results that lean left, right,\nand center so that readers can understand a breadth of opin-\nions on a topic. Boxes might also summarize the different\nviewpoints based on articles of differing biases to get a quick\nview of the diversity of angles on a topic. For McCain, a\nlong-serving moderate Republican senator and former POW\nin Vietnam who recently died, this might include centrist\narticles praising his service and bipartisanism, left-leaning\narticles on his support of healthcare and refusal to support\ntorture, and right-leaning articles on times he has strayed\nfrom the republican mainstream or defending the White\nHouse in not keeping the flag lowered after his death. This\ncan help users to quickly understand complex topics.\nTemporal News Browsing\nAlso interesting to us were the temporal patterns that we ob-\nserved, highlighting a peak in news browsing in the evening\nand harder news being more frequent than celebrity in the\nmorning. The peaks mid-day are most often for celebrity and\nentertainment news.\nNews sites can explicitly design for these temporal pat-\nterns. They can choose the types of news that are editorially\nselected to be at the top of the page to match the news that\npeople are seeking at different times. Early morning might\nbe a summary of what happened in harder news overnight.\nMid-day might include top celebrity or entertainment stories,\nwith more breaking news at the lunch hour. The evening can\nhighlight more sports and other general news. This can help\npeople find the content that they are most open to reading\nat a given time.\nFilter Bubbles\nWe have observed a large amount of polarization, or a \u201cfilter\nbubble\u201d effect in the news habits of our 174 participants.Almost half (48%) of participants received the vast majority\n(mean + standard deviation) of their news from left-biased\nsources while 5% received the vast majority of their news\nfrom right-biased sources. While the US-population overall is\nleaning farther left [ 8], the fact that people are not exposed to\nideas from different viewpoints can lead to a deeper \u201cbubble\u201d\nwhere people are not aware of the ideas of other portions of\nthe population.\nOne way to help with this problem is to improve search\n(as described above) to focus on showing a wider variety of\nresults. But search only makes up 20% of all news sessions.\nNews portals, such as yahoo.com, msn.com, or news.google.\ncom can use many of the same techniques suggested for\nsearch engines to show a broader diversity of viewpoints for\naggregated articles on specific topics. News sites that give\nrewards points for viewing articles can give additional points\nfor reading stories on different sides of the political spectrum,\nor can give bonuses for reading stories from mostly unbiased\nsources to disincentivize reading heavily-biased sources.\nWe do find it heartening that 7.7% of all news sessions\ncontained multiple news domains with different political\nbias scores. In addition, 47% of participants had a distribution\nof news sources that crossed the center. Users are seeking\nto break out of their bubbles at least a little bit, and this\nbehavior can be encouraged through new features of major\nnews portals.\n7 CONCLUSION\nThis exploration of behavioral data of news browsing, from\n174 diverse Americans over an average of 138 days, has\nhighlighted several important trends in news consumption\nin 2018. Most notably, users are frequently reading news on\nthe web, with 23% of all web browsing sessions containing\nnews. Users are reading from a wide variety of sources with\nthe median user visiting 19 distinct sources. The majority\nof users, 52%, did not receive significant amounts of news\nfrom opposing right or left leaning sources; they were in a\nfilter bubble. We have also seen that how people are getting\nto news is changing and diverse \u2014 20% of all news sessions\ncame from search, 16% from social media, only 34% from\ndirect browsing.\nThese findings have implications for the design of search\nand news portals and helping users to get a more balanced\nview of the world. We hope future work seeks to replicate\nthese findings in other cultural contexts and in other times\nof the year. Logs, such as these, can also be used to examine\nhow people explore the news around specific types of events,\nsuch as the death of a celebrity or a major political story. The\nnews ecosystem is complex and changing rapidly, and more\nwork that explores actual human behaviors as opposed to\nidealized answers in surveys or interviews is deeply needed\nat this time.\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 10\nREFERENCES\n[1]Rachel Weisel Amy Mitchell. 2014. Political Polarization\nand Media Habits: From Fox News to Facebook, How Lib-\nerals and Conservatives Keep Up with Politics. (2014).\nhttp://assets.pewresearch.org/wp-content/uploads/sites/13/2014/10/\nPolitical-Polarization-and-Media-Habits-FINAL-REPORT-7-27-15.\npdf\n[2]Michael Barthel. 2017. Despite subscription surges for largest\nU.S. newspapers, circulation and revenue fall for industry over-\nall. (2017). http://www.pewresearch.org/fact-tank/2017/06/01/\ncirculation-and-revenue-fall-for-newspaper-industry/\n[3]Frank R. Bentley, Nediyana Daskalova, and Brooke White. 2017. Com-\nparing the Reliability of Amazon Mechanical Turk and Survey Mon-\nkey to Traditional Market Research Surveys. In Proceedings of the\n2017 CHI Conference Extended Abstracts on Human Factors in Com-\nputing Systems (CHI EA \u201917). ACM, New York, NY, USA, 1092\u20131099.\nhttps://doi.org/10.1145/3027063.3053335\n[4]Juan Pablo Carrascal, Christopher Riederer, Vijay Erramilli, Mauro\nCherubini, and Rodrigo de Oliveira. 2013. Your Browsing Behavior for\na Big Mac: Economics of Personal Information Online. In Proceedings\nof the 22Nd International Conference on World Wide Web (WWW \u201913).\nACM, New York, NY, USA, 189\u2013200. https://doi.org/10.1145/2488388.\n2488406\n[5]Steven Chaffee and Stacey Frank. 1996. How Americans get political\ninformation: Print versus broadcast news. The Annals of the American\nAcademy of Political and Social Science 546, 1 (1996), 48\u201358.\n[6]ComScore. 2018. ComScore Media Metrix report for News/Information.\n(6 2018). https://mymetrix.comscore.com\n[7]Michael Dimock. 2014. Political Polarization in the Ameri-\ncan Public. (2014). http://www.people-press.org/2014/06/12/\npolitical-polarization-in-the-american-public/\n[8]Carol Dougherty. 2017. Political Polarization, 1994-\n2017. (2017). http://www.people-press.org/interactives/\npolitical-polarization-1994-2017/\n[9]Nina Eliasoph. 1998. Avoiding politics: How Americans produce apathy\nin everyday life. Cambridge University Press.\n[10] Robert Faris, Hal Roberts, Bruce Etling, Nikki Bourassa, Ethan Zucker-\nman, and Yochai Benkler. 2017. Partisanship, propaganda, and disin-\nformation: Online media and the 2016 US presidential election. (2017).\n[11] Seth Flaxman, Sharad Goel, and Justin M Rao. 2016. Filter bubbles,\necho chambers, and online news consumption. Public opinion quarterly\n80, S1 (2016), 298\u2013320.\n[12] Martin Flintham, Christian Karner, Khaled Bachour, Helen Creswick,\nNeha Gupta, and Stuart Moran. 2018. Falling for Fake News: In-\nvestigating the Consumption of News via Social Media. In Proceed-\nings of the 2018 CHI Conference on Human Factors in Computing Sys-\ntems (CHI \u201918). ACM, New York, NY, USA, Article 376, 10 pages.https://doi.org/10.1145/3173574.3173950\n[13] Gallup. 2018. Party Affiliation. (2018). https://news.gallup.com/poll/\n15370/party-affiliation.aspx\n[14] Gallup. 2018. Presidential Approval Ratings - Donald\nTrump. (2018). https://news.gallup.com/poll/203198/\npresidential-approval-ratings-donald-trump.aspx\n[15] Sharad Goel, Jake M Hofman, and M Irmak Sirer. 2012. Who Does\nWhat on the Web: A Large-Scale Study of Browsing Behavior.. In\nICWSM.\n[16] Martijn Kleppe and Marco Otte. 2017. Analysing and understanding\nnews consumption patterns by tracking online user behaviour with a\nmultimodal research design. Digital Scholarship in the Humanities 32,\nsuppl_2 (2017), ii158\u2013ii170.\n[17] Mounia Lalmas, Heather O\u2019Brien, and Elad Yom-Tov. 2014. Measuring\nUser Engagement. Morgan & Claypool Publishers. Synthesis Lectures\non Information Concepts, Retrieval, and Services.\n[18] Danielle Lottridge and Frank R. Bentley. 2018. Let\u2019s Hate Together:\nHow People Share News in Messaging, Social, and Public Networks. In\nProceedings of the 2018 CHI Conference on Human Factors in Computing\nSystems (CHI \u201918). ACM, New York, NY, USA, Article 60, 13 pages.\nhttps://doi.org/10.1145/3173574.3173634\n[19] Eli Pariser. 2011. The filter bubble: How the new personalized web is\nchanging what we read and how we think. Penguin.\n[20] Markus Prior. 2007. Post-broadcast democracy: How media choice in-\ncreases inequality in political involvement and polarizes elections. Cam-\nbridge University Press.\n[21] Kristen Purcell, Lee Rainie, Amy Mitchell, Tom Rosenstiel, and Kenny\nOlmstead. 2010. Understanding the participatory news consumer. Pew\nInternet and American Life Project 1 (2010), 19\u201321.\n[22] Paul Resnick, R. Kelly Garrett, Travis Kriplean, Sean A. Munson, and\nNatalie Jomini Stroud. 2013. Bursting Your (Filter) Bubble: Strategies\nfor Promoting Diverse Exposure. In Proceedings of the 2013 Conference\non Computer Supported Cooperative Work Companion (CSCW \u201913). ACM,\nNew York, NY, USA, 95\u2013100. https://doi.org/10.1145/2441955.2441981\n[23] David Tewksbury. 2003. What do Americans really want to know?\nTracking the behavior of news readers on the Internet. Journal of\ncommunication 53, 4 (2003), 694\u2013710.\n[24] David Tewksbury, Michelle L Hals, and Allyson Bibart. 2008. The\nefficacy of news browsing: The relationship of news consumption\nstyle to social and political efficacy. Journalism & Mass Communication\nQuarterly 85, 2 (2008), 257\u2013272.\n[25] Brian E Weeks and R Lance Holbert. 2013. Predicting dissemination\nof news content in social media: A focus on reception, friending, and\npartisanship. Journalism & Mass Communication Quarterly 90, 2 (2013),\n212\u2013232.\nCHI 2019 Paper \nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\nPaper 590\nPage 11", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Understanding online news behaviors", "author": ["F Bentley", "K Quehl", "J Wirfs-Brock", "M Bica"], "pub_year": "2019", "venue": "Proceedings of the 2019 CHI \u2026", "abstract": "The news landscape has been changing dramatically over the past few years. Whereas  news once came from a small set of highly edited sources, now people can find news from"}, "filled": false, "gsrank": 311, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3290605.3300820", "author_id": ["zK33NPkAAAAJ", "JILnyK0AAAAJ", "sHB-4YEAAAAJ", "T4PCkQUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:vavN885Tb1YJ:scholar.google.com/&output=cite&scirp=310&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=vavN885Tb1YJ&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 85, "citedby_url": "/scholar?cites=6228288957995396029&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:vavN885Tb1YJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.melissabica.com/assets/files/CHI2019-UnderstandingOnlineNewsBehaviors.pdf"}}, {"title": "Intermedia Agenda Setting during the 2016 and 2020 US Presidential Elections", "year": "2024", "pdf_data": "Intermedia Agenda Setting during the 2016 and 2020 U.S. Presidential Elections\nYijing Chen1, Yaguang Liu2, Lisa Singh2, Ceren Budak3\n1Central European University\n2Georgetown University\n3University of Michigan\nchen yijing@phd.ceu.edu, lisa.singh@georgetown.edu, cbudak@umich.edu\nAbstract\nIntermedia agenda setting (IAS) theory suggests that differ-\nent news sources can in\ufb02uence each other\u2019s agenda. Whilethis theory has been well-established in existing literature,whether it still holds in today\u2019s high-choice media environ-ment that includes news producers of different credibility andideology dispositions, is an open question. Through two casestudies\u2013the 2016 and 2020 U.S. presidential elections\u2013weshow that media are still largely aligned, especially in broadtopics they choose to cover, and that the level of alignmentalong the credibility dimension is comparable to that alongthe ideology dimension. Comparing agendas across differentmedia types, we \ufb01nd that the coverage of the Republican can-didate is better aligned than the coverage of the Democraticcandidate, and that agenda divergence has increased alongboth dimensions from 2016 to 2020. Finally, we demonstratethat high-credibility media still plays a dominant role in theIAS process, yet with a cautious warning of its declining IASpower for the Democratic candidate over the course of fouryears.\nIntroduction\nHow do news media select the coverage they present to their\naudience? Intermedia agenda setting (IAS) theory identi\ufb01esone important force setting the agenda of a given news pro-ducer, that is, other news producers. While this theory iswell-established, with a signi\ufb01cant amount of early theoreti-cal and empirical support (McCombs and Valenzuela 2020),its stability is in question in today\u2019s high-choice media en-vironment (Chaffee and Metzger 2001). Theoretically, onecan make a case for either divergence or convergence. Newsorganizations might diverge in their coverage by catering todifferent audience segments (Gentzkow, Shapiro, and Stone2015). However, commonalities in journalistic training andthe broader social context (e.g., events happening in the realworld) can lead to convergence despite economic pressures(Shoemaker and Reese 2013). Empirical evidence is simi-larly mixed, with support for both divergence (e.g., Baumand Groeling 2008; Stroud 2011; Muddiman, Stroud, andMcCombs 2014) and convergence (e.g., Maier 2010; Lee2007) of media agendas.\nCopyright \u00a9 2024, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.Past work has examined agenda alignment across vari-\nous media categories such as distribution channels (e.g., TV,\nnewspapers, online news) (Lee 2007) and ideology (Baumand Groeling 2008; Stroud 2011; Muddiman, Stroud, andMcCombs 2014). Investigations related to ideology are par-ticularly pertinent and common, given the signi\ufb01cant roleideology plays in the U.S. political system and audiencepreferences. Yet, ideology is no longer the only elementthat activates the selective news coverage adapted for a seg-mented audience base. Today\u2019s high-choice media environ-ment includes low-credibility news producers that deviatefrom traditional journalistic standards, at times explicitlyproviding a \u201ccritical meta-discourse on traditional journal-ism\u201d (Eldridge 2019). This might pose a more fundamentalthreat to the stability of IAS. It is this threat that motivatesour study. We ask: To what extent does the news agendabetween low- and high-credibility media diverge? Further-more, is IAS more signi\ufb01cant along the credibility dimen-sion than the ideology dimension? We answer these ques-tions by re-examining IAS across media with varying credi-bility levels and different partisan leanings.\nIn this paper, we present two important case studies, the\n2016 and 2020 U.S. presidential elections. We determine thedegree to which different media types (low-credibility vs.high-credibility and left-leaning vs. right-leaning) align interms of the candidate attributes they focus on. We exam-ine two types of attributes: keywords (e.g., how often theword \u201cliar\u201d is associated with Clinton) and topics (e.g., howoften the topic \u201chealthcare\u201d is associated with Trump). Wefocus on the 2016 and 2020 presidential elections for threereasons. First, these case studies are consequential. Duringnationally pertinent events such as presidential elections,the news agenda can shape the public political discourse,potentially impacting voting behaviors and, ultimately, theelection outcome (Nicholson 2021). Second, the similar na-ture of these case studies helps us determine the degree towhich \ufb01ndings from one IAS analysis generalize to othersimilar contexts. Finally, the four-year course from 2016 to2020 has witnessed fundamental shifts in the news ecosys-tem with the growing prominence of and public attention onlow-credibility media (Guo and Vargo 2020), on top of thelongstanding partisan division in the contemporary U.S. me-dia environment (Levendusky 2013). Up-to-date studies areneeded to refresh our understanding of the impact brought\nProceedings of the Eighteenth International AAAI Conference on Web and Social Media (ICWSM 2024)\n254\nby these shifts.\nOur examination of IAS theory is carried out in two\nstages. First, we show how media agendas align with one\nanother concurrently in their coverage of each presidentialcandidate. We measure the degree of alignment by correlat-ing the distributions of the overall attention on various at-tributes across media of different credibility and ideology.We \ufb01nd that the level of agenda alignment between low-and high-credibility media is comparable to that betweenleft- and right-leaning media. Moreover, we observe (i) abetter-aligned coverage for the Republican candidate thanthe Democratic candidate in general and (ii) an increasinglevel of divergence from 2016 to 2020. We explain the vari-ation in alignment by highlighting the crucial role controver-sial candidate attributes play in agenda divergence.\nSecond, we look into the temporal dynamics of IAS and\nidentify the agenda leader and follower for speci\ufb01c attributesassociated with a given candidate. We primarily focus ontopic attributes and determine which media type leads thechanges in topic coverage. We see that high-credibility me-dia is the dominant agenda setter in general, leading theagenda on more attributes and for longer periods of time thanlow-credibility media. Meanwhile, we notice the decline inIAS power of high-credibility media for the Democratic can-didate, as well as the increased interactions between low-and high-credibility media from 2016 to 2020. Althoughwe observe similar patterns between high-credibility (low-credibility) media and left-leaning (right-leaning) media,there are still subtle differences between these two lines ofcomparison. For instance, while low-credibility media nevertakes a persistent agenda leader role, right-leaning media hasled a few topics for Trump in 2020.\nFinally, although we adopt terms such as \u201cagenda setter\u201d\nand \u201cGranger causality\u201d, it is crucial to bear in mind the con-straints of relying solely on temporal correlations to assesscausal relationships. Thus, we suggest taking our study assuggestive insights rather than de\ufb01nitive causal assertions.\nRelated Work\nIntermedia Agenda Setting\nAgenda setting theory suggests that news media shape pub-lic opinions on issue salience through their coverage\u2013themore media cover a topic, the more important that topic be-comes in the public agenda (McCombs and Shaw 1972).Alongside the inquiry of agenda \ufb02ows between media andthe public, intermedia agenda setting (IAS) theory looks intothe agenda dynamics among media and suggests that differ-\nent news sources can in\ufb02uence one another.\nPrevious studies have explored the IAS process with these\nquestions: who takes the lead, on what speci\ufb01c issues, andin what time frames? Regarding the agenda leader/follower,researchers have identi\ufb01ed the powerful role of elite newsmedia in setting the agenda for others (Reese and Danielian2012; McCombs 2005), the tendency of junior newspapersto follow the lead of senior ones (Breed 1955), and morerecently, the potential of emerging online media to partic-ipate in IAS (Vargo and Guo 2017). The rising prevalenceof fake and partisan news media has motivated research ef-forts to examine IAS through lenses of credibility and ideol-ogy. Most relevant to our study, Vargo, Guo, and Amazeen(2018) found a reciprocal relationship in the network issueagenda between fake news and fact-based news, as well asbetween fake news and partisan news from 2014 to 2016;Guo and Vargo (2020) further pointed out the difference inIAS dynamics between two presidential candidates in 2016,that (a) compared to attributes associated with Clinton, thoseassociated with Trump were tied closer between fake newsand fact-based news, and that (b) partisan media were ableto lead the agenda for fake news media on attributes associ-ated with Trump, whereas in Clinton\u2019s case, the interactionbetween partisan and fake news media was much weaker. Interms of the temporality of the IAS process, researchers havedistinguished between breaking stories and ongoing debates(Vargo, Basilaia, and Shaw 2015), discussed cases of break-ing news being manipulated by false reporting (Hermann,Svrluga, and Miller 2016), and called for future work to ad-dress the nuances in the time scale of the IAS process (Vargoand Guo 2017). Because IAS can happen through linkedtemporary spikes and correlated ongoing \ufb02uctuations, un-derstanding these dynamics requires us to examine the tem-poral aspect of convergence or divergence with \ufb02exible timescales.\nOur study contributes to this line of research in the follow-\ning aspects. First, instead of focusing on a single election, westudy two elections to determine the consistency of IAS pat-terns. Second, the parallel analysis for two media pairingsallows us to benchmark the IAS process between low- andhigh-credibility media, compared to that between left- andright-leaning media. Through this comparative perspective,we are able to re\ufb02ect upon the signi\ufb01cance of agenda diver-gence, as well as the positioning of agenda leader/followeralong the credibility dimension, with respect to a longer-standing media segmentation along the ideology dimension.Third, as we will discuss in the next section, we introduceand validate a dictionary-based topic model that automatestext coding and allows for IAS analysis at two different lev-els of granularity (i.e., aspects and central themes). Com-bining expert-curated and data-driven attribute schemes, ourstudy outlines an interpretable and well-performing pipelinefor computational studies of IAS.\nSecond-level Agenda Setting and Candidate\nAttributes\nBoth agenda setting and intermedia agenda setting can be\nexamined at three different levels, each corresponding to dis-tinct units for comparisons of agenda. The \ufb01rst level focuseson broad issues; the second level examines attributes usedto describe issues (McCombs and Reynolds 2009; Muddi-man, Stroud, and McCombs 2014); and the third level inves-tigates the linkages, or co-occurrences, among various issuesor attributes (Guo 2012). Here, we focus on the second-levelagenda setting; that is, we take each presidential candidateas a single issue and ask whether and how the attributes as-sociated with these candidates are aligned and \ufb02ow betweendifferent media types.\nIn previous studies that also conceptualize political \ufb01g-\nures as issues, scholars have explored various dimensions of\n255\nmedia types by credibility media types by ideology\nyear high-credibility low-credibility left-leaning right-leaning total # of domains (coverage \u000050%)\n2016 362 (81.7%) 47 (10.6%) 185 (41.8%) 83 (18.7%) 443\n2020 504 (62.6%) 222 (27.6%) 249 (30.9%) 233 (28.9%) 805\nTable 1: Number of domains included in our analysis and group size for each domain category.\ntheir attributes, the very basic application being the shap-\ning of \u201ccandidate image\u201d during political campaigns (e.g.,Kiousis et al. 2006; Guo and Vargo 2020). Among dimen-sions of attributes compositing such a \u201ccandidate image\u201d,McCombs et al. (1997) speci\ufb01ed two fundamental dimen-sions: the substantive dimension and the affective dimen-sion. The former dimension organizes the candidate imagewith a set of relevant subtopics (e.g., personality, issue posi-tions); and the latter dimension focuses on sentimental ele-ments (i.e., positive, negative, or neutral) linked to the candi-date. As the varying salience of linkages between attributesand a given candidate provides a cognitive frame throughwhich a candidate is portrayed, researchers have connectedframing theory with the second-level agenda setting (Mc-Combs et al. 1997; Kiousis, Bantimaroudis, and Ban 1999;Golan and Wanta 2001). In our study, we inherit this the-oretical connection and model the candidate frame usingthree main groups of substantive attributes: (i) attributes thatdiscuss general government operations (including electioncampaigns), (ii) attributes that describe a particular policy-making aspect, and (iii) attributes that mention candidate-related controversies.\nIn terms of the \u201cgranularity\u201d of the frame, scholars have\ndistinguished between two types of attributes\u2013aspects andcentral themes\u2013when investigating the second and the thirdlevel of agenda setting (McCombs 2005). An aspect is \u201camicro attribute with a lower level of abstractness\u201d and a cen-tral theme is a \u201cmacro-level attribute\u201d that \u201cdescribes a moreabstract conceptual category\u201d (Kim and Min 2015). Withexisting studies suggesting a higher level of fragmentationat the aspect level than at the central theme level (Budaket al. 2023b; McCombs and Valenzuela 2020), we considerit necessary to keep incorporating both levels of granular-ity when examining IAS. Our work measures the degree towhich different media types are aligned in terms of both thecentral themes (e.g., how much do low- and high-credibilitymedia align when associating Trump with various themes?)and the speci\ufb01c aspects of those central themes (e.g., howmuch do left- and right-leaning media align when associ-ating Biden with various aspects?). We operationalize thisdual-level measurement using a dictionary-based approachfor text coding. Speci\ufb01cally, we capture aspects by detect-ing phrases (i.e., keywords) that occur in texts (e.g., \u201cvote\u201d,\u201cbank\u201d, \u201ctax\u201d), and capture central themes by identifyingbundles of phrases (i.e., topics) that correspond to a particu-lar candidate attribute (e.g., the topic \u201ccivil rights\u201d includeskeywords such as \u201cvote\u201d and \u201cdiscrimination\u201d).\nDataset and Preprocessing\nWe start our examination by identifying a set of low- andhigh-credibility online news outlets. We borrow the listof news domains from Bozarth and Budak (2021) thatcombines \ufb01ve sources of domain credibility labels (Coutsand Wyrich 2016; Van Zandt 2015; Gillin 2017; Allcott,Gentzkow, and Yu 2019; Zimdars 2016). In our study, adomain belongs to the low-credibility class if it is explic-itly marked as \u201cfake\u201d or \u201clow-credibility\u201d by any of the\ufb01ve sources. We then \ufb01lter out domains that contain satireor mixed-factual content and group the remaining domainsinto the high-credibility class. We also assign ideology la-bels (i.e., left-leaning, right-leaning) to these news domainsbased on the bias rating tags assigned by Media Bias FactCheck (mediabiasfactcheck.com). Note that ideology labelsonly cover approximately 60% of all domains, with an im-balanced distribution across low- and high-credibility cate-gories (the left-to-right ratio is 0.28 for the low-credibilitygroup and 2.67 for the high-credibility group). Thus, dimen-sions of ideology and credibility present two overlapping butnot entirely aligned grouping structures.\nNext, we collect the headline corpus of the aforemen-\ntioned news domains. Using Wayback Machine, a web-page scraping API provided by Internet Archive, we retrievehomepage snapshots from 5521 low- and high-credibilitynews domains\n1during \ufb01ve-month periods of the 2016 and\n2020 election seasons (i.e., from July 1 to November 30).From these timestamped snapshots, we extract news head-lines that mention the \ufb01rst or the last name of at least onepresidential candidate for the corresponding election\n2.T o\nmake candidate-wise comparisons in the IAS analysis, wesplit the headlines into two candidate groups for each year;headlines in a given candidate group capture the media cov-erage of the corresponding candidate in a certain election.\nGiven that the snapshotting frequency varies greatly\nacross domains and across days, we assign a multiplicationindex to each snapshot, which will be used as a weight whenwe aggregate topic and keyword counts. The multiplicationindex equals the inverse of the number of snapshots for agiven domain in a given day. This allows us to make surethat each domain will have at most one \u201caverage snapshot\u201dper day that describes its overall agenda. We also \ufb01lter outdomains without suf\ufb01cient snapshot coverage\n3to avoid tem-\nporal patterns being distorted by exogenous factors related tothe Wayback scraping jobs (e.g., \ufb01le size, number of parallelongoing crawls). We report the number of quali\ufb01ed domainsand the group sizes for each category in Table 1).\n1Note that not all domains have snapshots for both years. There\nare 4540 unique domains for 2016 and 3109 for 2020.\n2Our data extraction does not include dynamic or nested con-\ntent.\n3Domains that do not have at least one snapshot for at least 50%\nof the days are dropped in downstream analysis.\n256\nMethods\nIn this section, we elaborate on speci\ufb01c steps of the\ndictionary-based topic modeling: how we construct the topicdictionary, how the model computes topic and keyword vec-tors for each input, and how we validate the model out-put with crowd-sourced labels collected from Amazon Me-chanical Turk (MTurk). Then, we explain how we utilizethe model output for downstream analysis, \ufb01rst to measureagenda alignment and then to identify agenda leaders andfollowers.\nDictionary-based Topic Modeling\nConstructing Topic Dictionaries For each of the 2016\nand 2020 election seasons, we construct a customized dictio-nary by merging (1) a highly reliable\n4base dictionary (Bu-\ndak et al. 2023b) that uses the Comparative Agendas Project(CAP) taxonomy (Hearings 2017), and (2) an extended dic-tionary customized for each election season. The extendeddictionaries are curated by political communication expertsthrough consensus labeling (Bode et al. (2019) for 2016and Agiesta (2020) for 2020). These dictionaries containcontext-speci\ufb01c keywords (e.g., catchphrases, names of po-litical elites) that not only improve keyword coverage in theheadline data but also better capture the election-related ex-pressions in both years. The dictionary merging proceedsas follows. We preserve the topic taxonomy established bythe CAP codebook, match topic categories from the ex-tended dictionary to the base dictionary, and create a newtopic if there exists no reasonable match. After the initialmerge, the 2016 dictionary includes 1340 phrases from 26topics, and the 2020 dictionary contains 1405 phrases from26 topics. The topics include \u201cgovernment operation\u201d thatencompass general administrations and election campaigns,policy-related categories such as \u201chealthcare\u201d, \u201ceconomy\u201dand \u201cinternational affairs\u201d (included in the CAP taxonomy),as well as scandals-related categories such as \u201cTrump con-troversies\u201d, \u201cBiden controversies\u201d and \u201cClinton controver-sies\u201d (added after merging the extended dictionary).\n5\nTo further enrich the dictionary, we use a semi-supervised\ntopic model, Guided Topic-noise Model (GTM) (Churchillet al. 2022), to identify additional keywords and topics thatare salient in the context of presidential elections. GTM uti-lizes an input dictionary that contains keywords for topicsof interest to guide the topic-generation process. It expandsthe provided lists of keywords using a generalized genera-tive model called Generalized Polya Urn (GPU) (Churchillet al. 2022) to iteratively enhance existing topics and gen-erate new topics containing new keywords and associatedweights. Based on previous practices and preliminary runs\n4Krippendorff alpha was 0.84 across trained coders construct-\ning the dictionary.\n5Note that both candidates have \u201cDEM candidate controver-\nsies\u201d and \u201cREP candidate controversies\u201d in their own attribute lists,\nsince it is possible to mention one candidate within the contextof a controversial issue associated with the other candidate (e.g.,Trump discusses Clinton\u2019s email scandals). Keeping the topic listsconsistent across candidates also allows for more convenient com-parisons.on our data samples, we set the number of topics to 50;\nwe then inspect all new keyword-topic pairs generated byGTM and score the degree of relevance for each pair (i.e.,0 for non-relevant, 1 for weakly-relevant, and 2 for highly-relevant), given the possible contexts of a keyword in ourdataset. The complete inspection is performed by one au-thor, after two authors reach an acceptable level of inter-raterreliability on their independently-assigned relevance scoresfor dictionary samples from both years (Krippendorff\u2019s al-pha = 0.81 for 2016 and 0.7 for 2020). After the inspection,we drop non-relevant keyword-topic pairs and evaluate threestrategies of keyword \ufb01ltering/weighting: (i) only includingthe highly relevant phrases, (ii) including both the highly andweakly relevant phrases, (iii) including both while givinghigher weight to highly relevant phrases. We discuss how weevaluate these strategies in the subsection Validating Out-\nput. The \ufb01nal model uses only the highly relevant phrases,consisting of 1426 keywords in 2016 and 1453 keywords in2020.\nIdentifying Topics The core idea of dictionary-based\ntopic modeling is to detect keywords that occur in a given\ntext, bin those keywords into their corresponding topic cate-gories, and record the count of topics. Given Kunique top-\nics,Wunique keywords, and text i, we \ufb01rst generate an as-\npect (keyword) vector ~x\niof length W, where each element\n~xi,wequals the raw count of keyword win text i. Then, we\ngroup those identi\ufb01ed keywords by topic to obtain a cen-tral theme (topic) vector of length Kfor text i. Finally, the\nmodel \ufb01lters the topic counts and generates a normalizedtopic vector ~y\niof length K, where each element ~yi,kequals\nthe probability of topic kfor text i.\nThe topic-count \ufb01ltering controls the number of topic(s)\nwe assign to a single text. We have explored three options:(a) the \u201cprimary\u201d option treats this as a single-label classi-\ufb01cation task, in which each text gets one topic label that ismost frequently mentioned and obtains a one-hot ~y\niwith a\nsingle non-zero element, (b) the \u201cprimary + secondary\u201d op-tion assigns the \ufb01rst and the second most frequent topic toa text, with topic weights corresponding to the relevant fre-quency, and (c) the \u201call\u201c option includes all topics identi\ufb01edin a text, weighting topics based on relevant frequencies.\nValidating Output We \ufb01nalize and validate our model\noutput by comparing model-human agreement against\nhuman-human agreement. Our evaluation rests on the fol-lowing premise: If the dictionary-based model performs asreliably as a human labeler, the extent to which the modelagrees with a random human labeler should be compara-ble to the extent to which two random human labelers agreewith each other. To perform the aforementioned evaluation,we collect human labels through a topic-labeling task onAmazon Mechanical Turk (MTurk), in which we ask MTurkworkers to select the primary, secondary and all relevant top-ics applicable for each of the 10 texts displayed per HumanIntelligence Task (HIT). We describe details of the MTurktask in Supplementary Materials (SM) Collecting Human\nLabels from MTurk.\nOur evaluation proceeds as follows. For each text input,\nwe use the model plus a random human labeler as the model-\n257\nFigure 1: Agreement scores for model-human and human-\nhuman pairs. The random baseline adopts the topic distri-bution generated by the best-performing topic model andshuf\ufb02es the topic label per text. \u201crnd\u201d refers to the baselinemodel that randomly assigns a topic label; \u201cpw\u201d refers to themodel using the original CAP dictionary; \u201cpw + bt\u201d refers tothe version after the initial merge with the extended dictio-nary; \u201cpw + bt + gtm\u201d refers to the \ufb01nal version that includedGTM keywords.\nhuman pair and randomly select two human labelers as the\nhuman-human pair. For the single-label case (i.e., model op-tion (a)), the agreement score equals the number of timeswe receive two identical labels divided by the total numberof text inputs evaluated; for multi-label cases (i.e., model op-tion (b) and (c)), we compute the Jaccard similarity for eachpair of labels and obtain the average. We compare agreementscores between model-human and human-human for ninemodel variants with (1) different keyword \ufb01ltering/weight-ing strategies and (2) varying numbers of topics per text, andchoose the one producing the highest and closest agreementscore for the model-human pair compared to the human-human pair.\nWe \ufb01nd that the best performance is achieved when us-\ning only the strongly relevant keywords and limiting ourattention to the primary topic. Details of the overall eval-uation are given in SM Table 4. Using this model version,we show the progression of model-human agreement in Fig-ure 1 as we update the topic dictionary. The \ufb01gure showsthat the worker-model agreement scores are comparable toworker-worker agreement scores, especially for the newsmedia and survey data. We also see that the progressionis consistent across the two elections, allowing us to makereliable comparisons between the two elections. Althoughthe suboptimal level of overall human-human agreement re-\ufb02ects the inherent dif\ufb01culty of the labeling task itself, themodel does identify meaningful topical cues from the textthat make sense to humans in a considerable proportion oftexts. In circumstances of con\ufb02icts between human-modelpairs, roughly 42% of the texts have at least one matchingpair of human and model labels, and 57% have at least onehuman including the primary model topic in their expandedtopic list (i.e., primary, secondary or relevant topics). Fortopics that have low agreement levels between the model andworkers and occur rarely in our data\n6, we drop them in the\ndownstream analysis.\nDownstream Analysis\nMeasuring Agenda Alignment We \ufb01rst assess agenda\nalignment by comparing the aggregated attention distribu-tion between different media types. The attention distribu-tion can be described at both the keyword level and the topiclevel. At the keyword level, we compute an aggregated key-word vector ~x\nAfor media type Aby adding up7keyword\nvectors ~xifor each text ifrom media type A, and normaliz-\ning the output by its sum. Similarly, at the topic level, we ob-tain an aggregated topic vector ~y\nAfor media type A, which\nsums up all topic vectors of texts from media type Aand nor-\nmalizes the output by its sum. An aggregated topic or key-word vector is essentially a probability vector that sums upto 1. With these aggregated vectors, we use Pearson correla-tion coef\ufb01cient, a widely-adopted metric in previous agenda-setting studies (e.g., Sweetser, Golan, and Wanta 2008; Guo2012) to quantify the degree to which the priorities of can-didate attributes align between media type AandB, i.e.,\n\u21e2(~x\nA,~xB)for the alignment at the aspect (keyword) level\nand\u21e2(~yA,~yB)at the central theme (topic) level. The higher\nthe correlation, the better the agendas align.\nSince all domain snapshots are timestamped, we can de-\n\ufb01ne the time frame of inputs when aggregating topic or key-word vectors and measure the degree of alignment over time(i.e., temporal alignment). For instance, we can measure thedaily level of temporal alignment using aggregated topic(keyword) vectors generated from headlines on a given day.\nIdentifying Agenda Leader and Follower Agenda align-\nment reveals how much the priorities of candidate attributes\nmatch between two media within concurrent time frames,yet it does not capture the dynamics of agenda \ufb02ow overtime or assess the IAS power of a given media type. Thus,a natural next step is to explore the temporal relationship ofmedia agendas and assess the degree to which a given mediatype serves as a leading/following actor in the IAS process.\nWe perform Granger causality tests for daily time series of\nattribute proportions. Granger causality analysis is a classicapproach to evaluate the (intermedia) agenda-setting powerusing time series (e.g., Brosius and Kepplinger 1990; Meraz2011; Groshek and Clough Groshek 2013; Vargo, Guo, andAmazeen 2018; Guo and Vargo 2020). It allows us to statis-tically assess the temporal \u201ccausation\u201d between two time se-ries with varying time lags\n8. Let\u2019s say we focus on attribute\nk(e.g., topic \u201chealthcare\u201d for Trump), and extract the time\nseries of its attention proportion in media type A (e.g., low-credibility media) and B (e.g., high-credibility media), X\nA,k\n6Topics excluded downstream: \u201cforestry\u201d, \u201cland water manage-\nment\u201d, \u201cagriculture\u201d, \u201chousing\u201d, \u201ctransportation\u201d, \u201cculture\u201d.\n7As mentioned in Section Data and Preprocessing, this step\ncomputes a weighted sum of all input vectors. The topic (keyword)\nvectors for individual texts are weighted by the multiplication indexassigned to each snapshot to avoid over-counting (under-counting)domains that have too many (few) snapshots per day.\n8We apply time lags of 1, 2, 3, 4, 5 days for individual topic\ntime series.\n258\n\t\u0007\b\u000b\n\u000e\u0015\u0010\u000f\t\u0007\t\u0007\n\u000e\u0015\u0010\u000f\t\u0007\b\u000b\n\u0011\u000f\u0010\u0013\t\u0007\t\u0007\n\u0011\u000f\u0010\u0013\u0007\u0006\n\u0007\u0006\u000b\u0007\u0006\f\b\u0006\u0007\u0014\u001a\u0017\"# \u001f\u0004#\u0003\u0015\u0016 !\u001c\u0018\u0005\u001d\u001a%\u001a\u001d\u0003\r\u001d\u001c\u001b\u001f\u001e\u001a\u001f$\n\u0015\u0010\u0014\u0003\u0018\u0017\u001f\u0019\n\u000f\u0010\u0012\u0003\u0018\u0017\u001f\u0019\n\t\u0007\b\u000b\n\u000e\u0016\u0010\u000f\t\u0007\t\u0007\n\u000e\u0016\u0010\u000f\t\u0007\b\u000b\n\u0011\u000f\u0010\u0014\t\u0007\t\u0007\n\u0011\u000f\u0010\u0014\u0007\u0006\n\u0007\u0006\u000b\u0007\u0006\f\b\u0006\u0007\u0015\u001a\u0017!\" \u001f\u0004\"\u0003\u0016\u0012\u001a&% !\u0019\u0005\u001d\u001a$\u001a\u001d\u0003\r\u001d\u001c\u001b\u001f\u001e\u001a\u001f#\n\u0016\u0010\u0015\u0003\u0018\u0017\u001f\u0019\n\u000f\u0010\u0013\u0003\u0018\u0017\u001f\u0019\nFigure 2: Agenda alignment for the 2016 and 2020 election seasons, at the topic level (left) and at the keyword level (right). We\nkeep the top 18 topics that occur frequently and meaningfully in the data, and keep the top 500 keywords with high frequencies.CRED refers to media types by credibility (i.e., low- and high-credibility media), and IDEO refers to media types by ideology(i.e., left- and right-leaning media).\nandX\nB,k. If regressing the past of XA,kandXB,kyields\na better prediction for XB,kthan regressing only the past\nofXB,k, we say XA,k\u201cGranger causes\u201d XB,kand in our\ncontext, we identify media type A as the agenda leader and\nB as the agenda follower on attribute k. Before being fed\ninto the Granger causality tests, all time series have beendetrended by \ufb01rst-level differencing and have passed aug-mented Dickey-Fuller (ADF) tests, which indicate that theyare stationary.\nFinally, we collapse the results yielded by different time\nlags into four categories: (i) led by media type A if we only\nsee signi\ufb01cant results in cases of B lagging A; (ii) led by me-dia type B in the reversed situation; (iii) mutual interactionif we see signi\ufb01cant results in both directions; and (iv) norelationship if we do not see signi\ufb01cant results in either di-rection. We consider a collapsed result to be signi\ufb01cant androbust if (i) the Granger causality test returns p< 0.05, so\nwe can reject the null hypothesis that changes of attention onattribute kin media type A fail to Granger cause the changes\nof attention in B; and (ii) the same result category appearsconsistently in at least 95% of the bootstrapping runs. Apartfrom performing the test on the full time series, we also testa shorter time window of 90 days and slide it by daily unit.The daily sliding allows us to distinguish the persisting rolesof agenda leaders/followers from \ufb02ashing patterns boostedby momentary and spurious correlations.\nResults and Discussions\nWe provide two views when comparing agendas across dif-ferent media types: (1) static alignment, which examines thesimilarity of aggregate agendas, and (2) temporal dynamics,which characterizes the extent to which a given media typeleads the other type in a lagged time frame.\nStatic Alignment: Divergence or Convergence of\nMedia Agenda?\nWe start by presenting the aggregate alignment in Figure\n2. The \ufb01rst striking \ufb01nding is the similarity in patterns ob-served for ideology and credibility. Past work that comparesthe role ideology and credibility play in news productionhas found that credibility plays a more signi\ufb01cant mediafragmentation role (Budak et al. 2023a). Based on this, wewould have expected the media to be more fragmented alongthe credibility dimension. However, surprisingly, we see thatmedia are no more divided along the credibility line com-pared to ideology. This could be because ideology is one ofmany factors that shape broader news production, while it isthedecisive factor in election campaign coverage. This high-\nlights the enduring role ideology plays in election coverage.\nAt the topic level, agendas of different media types are\nstill largely aligned in both years (r> 0.8), with a slight\ndecrease from 2016 to 2020 (average \u0000r=\u00000.041). In\ncontrast, at the keyword level, the correlations for both can-didates have dropped dramatically (average \u0000r=\u00000.350),\nreaf\ufb01rming previous \ufb01ndings of a more severe fragmenta-tion at the aspect level than the central theme level (Stroud2011; McCombs and Valenzuela 2020; Budak et al. 2023b).The downtrend in keyword alignment is more pronouncedfor the Republican candidate (average \u0000r=\u00000.399per\nmedia pairing) than for the Democratic candidate (average\u0000r=\u00000.302per media pairing), evincing partisan asym-\nmetries in agenda fragmentation at the keyword level.\nCandidate-wise, the coverage of the Republican candidate\nis generally better aligned than that of the Democratic candi-date. As shown in Figure 2, at the topic level, low- and high-credibility media share highly similar priorities for Trump\u2019sattributes in both years (r =0.997in 2016 and r=0.946\nin 2020); so do left- and right-leaning media (r =0.991\nin 2016 and r=0.956in 2020). For his opponent candi-\ndate, the correlations between these two media pairings areweaker (r =0.891in 2016 and 0.845in 2020 across credi-\nbility types; r=0.902in 2016 and 0.869in 2020 across ide-\nology types). Interestingly, in 2020, the coverage of Trumpachieves a higher level of alignment than that of Biden atthe topic level ( \u00afr=0.951per media pairing for Trump\nand\u00afr=0.857for Biden), but not at the keyword level\n(\u00afr=0.538per media pairing for Trump and \u00afr=0.602\nfor Biden). This reveals the level at which media diverge fora given candidate. Different types of media organize similarpriorities for Trump-related topics, but the speci\ufb01c keywordsused in their discussions are poorly coordinated. Whereasfor Biden, although the topic-level agendas are not as wellaligned as his Republican counterparts, the keywords used\n259\n\b\u00073\n\b\u00073\t\b\u00073\b\b\u0007\u0007\n\u001d+,'\"\u0003\u0004\u0003'*\u0003(+1\u0005\"-$#\u0003#+)!'*.\b\u00073\n\b\u00073\t\b\u00073\b\b\u0007\u0007\u001d+,'\"\u0003\u0004\u0003'*\u0003&'%&\u0005\"-$#\u0003#+)!'*.\n\u001c\u0019 \u0016\u0011\u0018\u001f\u001b\n\u0011\u0018\u001b\u0013\u0012\u001b\u001d\u001b\u0016\r\u000e\u001b\n\u0011\u0010\u001e\u000f\u001b\u0011\u0016\u0013\u0015\u0017\u0017\u0015\u000f\u0016\u0015\u000f\u0010\u0011\u0012\u000f\u0014\u0016\u001d\u0014\u0011\u000f\u0019\u0018\n\u000f\u001b\u0015\u0017\u001c\u001c\u001d\u000f\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\u001d\u001b\u001e\u000f\u0013\u001f\u0019\u001a\n\u001c\u0019 \u0016\n\u0011\u0018\u001f\u001b\u0011\u0018\u001b\u0013\u0012\u001b\u001d\u001b\n\u0016\r\u000e\u001b\u0011\u0010\u001e\u000f\n\u001b\u0011\u0016\u0013\u0015\u0017\u0017\u0015\u000f\u0016\u0015\u000f\n\u0010\u0011\u0012\u000f\u0014\u0016\u001d\u0014\u0011\u000f\u0019\u0018\u000f\u001b\u0015\u0017\n\u001c\u001c\u001d\u000f\n\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\n\u001d\u001b\u001e\u000f\u0013\u001f\u0019\u001a\t\u0007\b\u000b\n-$\f\u0003\u001b\u0011\u001a\u0003\"!*#\n-$\f\u0003\u0010\u0011\u0017\u0003\"!*#\n,+('\"2\u0005-$(!/$#\n\"+*/-+0$-.'$.\n$($\"/'+*\u0003\u0006\u0003%+0*)/\u0003+,.\n\b\u00073\n\b\u00073\t\b\u00073\b\b\u0007\u0007\n\u001d+,'\"\u0003\u0004\u0003'*\u0003(+1\u0005\"-$#\u0003#+)!'*.\u001d+,'\"\u0003\u0004\u0003'*\u0003&'%&\u0005\"-$#\u0003#+)!'*.\u001c\u0019 \u0016\u0012\u001b\u001d\u001b\n\u001b\u0011\u0016\u0013\u0011\u0018\u001f\u001b\u0016\r\u000e\u001b\u000e\u0015\u0010\u000f \u0011\u0018\u001b\u0013\u0011\u0010\u001e\u000f\u0015\u0017\u0017\u0015\u0010\u0011\u0012\u000f\u0011\u000f\u0019\u0018\n\u001c\u001c\u001d\u000f\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\u000f\u001b\u0015\u0017\u001d\u001b\u001e\u000f\u0014\u0016\u001d\u0014\u0013\u001f\u0019\u001a\n\u001c\u0019 \u0016\u0012\u001b\u001d\u001b\u001b\u0011\u0016\u0013\u0011\u0018\u001f\u001b\u0016\r\u000e\u001b\u000e\u0015\u0010\u000f\n\u0011\u0018\u001b\u0013\n\u0011\u0010\u001e\u000f\n\u0015\u0017\u0017\u0015\u0010\u0011\u0012\u000f\u0011\u000f\u0019\u0018\n\u001c\u001c\u001d\u000f\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\n\u000f\u001b\u0015\u0017\n\u001d\u001b\u001e\u000f\u0014\u0016\u001d\u0014\u0013\u001f\u0019\u001a\t\u0007\t\u0007\nFigure 3: Comparisons of topic proportion between low- and high-credibility domains in 2016 (left) and 2020 (right). Please\nrefer to SM Table 3 for the list of topics the acronyms in the \ufb01gure stand for.\n.\n0\u0007\u0005\u0006 0\u0006\u0005\t \u0006\u0005\u0006 \u0006\u0005\t \u0007\u0005\u0006\n\r*++#'\u001f-&*)\u0003&)\u0003\b\u0006\u0007\n0\u0007\u0005\u00060\u0006\u0005\t\u0006\u0005\u0006\u0006\u0005\t\u0007\u0005\u0006\r*++#'\u001f-&*)\u0003&)\u0003\b\u0006\b\u0006\u000f\u0016\u0019\u0011\n\u000f\u0016\u001d\u0019\n\u001a\u0017\u001e\u0014\u0010\u0019\u001b\u0019\n\u000f\u000e\u001c\r\n\u0019\u000f\u0014\u0011\n\u0014\u000b\f\u0019\u0013\u0015\u0015\u0013\u0012\u0014\u001b\u0012\n\u000f\r\u0017\u0016\n\u000e\u000f\u0015\r\u000e\u000f\u0010\r\u0013\u0016\u001b\u0014\n\r\u0019\u0013\u0015\n\u001a\u001a\u001b\r\r\u0013\u001d\u0019\n\u0019\u000f\u0018\r\u0011\u001d\u0017\u0018\u0019\u000f\u0018\u0003!\u001f)\"&\"\u001f-#\n0\u0007\u0005\u0006 0\u0006\u0005\t \u0006\u0005\u0006 \u0006\u0005\t \u0007\u0005\u0006\n\r*++#'\u001f-&*)\u0003&)\u0003\b\u0006\u0007\n\r*++#'\u001f-&*)\u0003&)\u0003\b\u0006\b\u0006\u000f\u0016\u0019\u0011\u000f\u0016\u001d\u0019\n\u001a\u0017\u001e\u0014\u000f\u000e\u001c\r\u0019\u000f\u0014\u0011\n\u0014\u000b\f\u0019\u0013\u0015\u0015\u0013\u0012\u0014\u001b\u0012\n\u000f\r\u0017\u0016\u000e\u000f\u0015\r\n\u000e\u000f\u0010\r\n\u0013\u0016\u001b\u0014\n\r\u0019\u0013\u0015\u001a\u001a\u001b\r\r\u0013\u001d\u0019\n\u0019\u000f\u0018\r\u0011\u001d\u0017\u0018\u000e\u000f\u0015\u0003!\u001f)\"&\"\u001f-#\r*++#'\u001f-&*),\u0003 #-.##)\u0003'*.\u0004\u0003\u001f)\"\u0003%&$%\u0004!+#\"& &'&-/\u0003(#\"&\u001f\nFigure 4: By-topic alignment of top 500 keywords across years between low- and high-credibility news media in 2016 (left)\nand 2020 (right). Dot size is a function of the overall frequency of the corresponding topic.\nin different media types have relatively greater overlaps.\nCandidate Controversies: Key Attributes as\nDivergence Drivers\nAfter observing a higher level of agenda divergence for the\nDemocratic candidate (as opposed to the Republican candi-date) and for 2020 (as opposed to 2016), we question thesource of these differences. On what attributes do media di-verge the most? Is the overall pattern of divergence dom-inated by the divergence on a few attributes or, more orless equally by the divergence on most attributes? Thus, weextend candidate-wise and election-wise comparisons intotopic-level and keyword-level breakdowns.\nCandidate-wise, we \ufb01nd that higher proportions of at-tention on \u201cDEM candidate controversies\u201d (topic related toClinton controversies in 2016 and Biden controversies in2020) from low-credibility and right-leaning media are themain source of salient agenda divergence for the Democraticcandidate. Focusing on blue dots in Figure 3, we see that thetwo largest topics that deviate signi\ufb01cantly from the diag-onal line are \u201cDEM candidate controversies\u201d and \u201cgovern-ment operations\u201d. Low-credibility and right-leaning mediahighlight \u201cDEM candidate controversies\u201d more than theircounterparts, limiting the attention devoted to \u201cgovernmentoperations\u201d. Such deviations have become more salient in2020. We again observe similar patterns for the credibilityand ideology divide. The plot summarizing the ideology re-sults is omitted here for brevity (see SM Figure 9).\n260\n\n\b\t\u000e\u0006\b\u000f \n\b\t\u000e\u0006\b\u0010 \n\b\t\u000e\u0006\b\u0011 \n\b\t\u000e\u0006\t\b \n\b\t\u000e\u0006\t\t \n\b\t\u000e\u0006\t\n\b\u0007\t\b\u0007\n\b\u0007\u000b\b\u0007\f\b\u0007\r\"\u001e\u001f\u001a\u0014\u0003\u001f \u001e\u001f\u001e \"\u001a\u001e\u001d\" #\u001c\u001f\u0013\u0014\u001e\u001d\" \u001e$\u0016 !\u001a\u0016!\u0003\u0017\u001e \u0003\u0012 #\u001c\u001f\u0003\u0004\n\b\t\u000e\u0005\n\u001b\u001e%\u0006\u0014 \u0016\u0015\n\u0019\u001a\u0018\u0019\u0006\u0014 \u0016\u0015\n\n\b\n\b\u0006\b\f \n\b\n\b\u0006\b\r \n\b\n\b\u0006\b\u000e \n\b\n\b\u0006\t\b \n\b\n\b\u0006\t\t \n\b\n\b\u0006\t\n\b\u0007\b\u000b\b\u0007\t\b\b\u0007\t\u000b\b\u0007\n\b\b\u0007\n\u000b\u001f\u001b\u001c\u0017\u0011\u0003\u001c\u001d\u001b\u001c\u001b\u001d\u001f\u0017\u001b\u001a\u001f\u001d \u0019\u001c\u0010\u0011\u001b\u001a\u001f\u001d\u001b!\u0013\u001d\u001e\u0017\u0013\u001e\u0003\u0014\u001b\u001d\u0003\u000f\u001d \u0019\u001c\u0003\u0004\n\b\n\b\u0005\n\u0018\u001b\"\u0006\u0011\u001d\u0013\u0012\n\u0016\u0017\u0015\u0016\u0006\u0011\u001d\u0013\u0012\n\n\b\t\u000e\u0006\b\u000f \n\b\t\u000e\u0006\b\u0010 \n\b\t\u000e\u0006\b\u0011 \n\b\t\u000e\u0006\t\b \n\b\t\u000e\u0006\t\t \n\b\t\u000e\u0006\t\n\b\u0007\t\b\u0007\n\b\u0007\u000b\b\u0007\f\b\u0007\r\b\u0007\u000e!\u001d\u001e\u001a\u0014\u0003\u001e\u001f\u001d\u001e\u001d\u001f!\u001a\u001d\u001c\u0014\u001b\u001a\u001c!\u001d\u001c\u0013\u0014\u001d\u001c!\u001f\u001d\"\u0016\u001f \u001a\u0016 \u0003\u0017\u001d\u001f\u0003\u0012\u001b\u001a\u001c!\u001d\u001c\u0003\u0004\n\b\t\u000e\u0005\n\u001b\u001d#\u0006\u0014\u001f\u0016\u0015\n\u0019\u001a\u0018\u0019\u0006\u0014\u001f\u0016\u0015\n\n\b\n\b\u0006\b\r \n\b\n\b\u0006\b\u000e \n\b\n\b\u0006\b\u000f \n\b\n\b\u0006\t\b \n\b\n\b\u0006\t\t \n\b\n\b\u0006\t\n\b\u0007\b\b\u0007\t\b\u0007\n\b\u0007\u000b\b\u0007\f \u001c\u001d\u0019\u0013\u0003\u001d\u001e\u001c\u001d\u001c\u001e \u0019\u001c\u001b\u0012\u0019\u0014\u0015\u001b\u0011\u0013\u001c\u001b \u001e\u001c!\u0015\u001e\u001f\u0019\u0015\u001f\u0003\u0016\u001c\u001e\u0003\u0010\u0019\u0014\u0015\u001b\u0003\u0004\n\b\n\b\u0005\n\u001a\u001c\"\u0006\u0013\u001e\u0015\u0014\n\u0018\u0019\u0017\u0018\u0006\u0013\u001e\u0015\u0014\nFigure 5: Time series of the topic \u201cREP/DEM candidate controversies\u201d from low- and high-credibility media in 2016 (left) and\n2020 (right). Blue rectangle boxes in the second row highlight a few periods with drastic drops in overall topic alignment, whenlow- and high-credibility media have different spotlighting intensity or attention spans on \u201cDEM candidate constroversies\u201d.\nThe attention on \u201cDEM candidate controversies\u201d not only\ndiverges at the aggregated level but also signals the speci\ufb01cpoint in time when different media types will diverge. To il-lustrate this, we examine the temporal dependence betweenthe attention disparity on \u201cDEM candidate controversies\u201dand the temporal \ufb02uctuations in overall topic alignment.Speci\ufb01cally, we apply a uni-variate ordinary least squares(OLS) model for topic k, using the time series of temporal\nalignment as the dependent variable Y, and the time seriesof the temporal difference in the proportional attention on\ntopic kbetween a given media pairing as the independent\nvariable X. We \ufb01nd that regressing the difference in \u201cDEMcandidate controversies\u201d can explain more of the variance(i.e., achieve the highest R-squared values) than any othertopic, especially for Biden in 2020 between left- and right-leaning media (R-squared = 0.7565). We report the full re-sults in SM Table 2. Comparing the time series of \u201cDEMcandidate controversies\u201d between low- and high-credibilitymedia (see Figure 5) with that of temporal topic alignmentbetween low- and high-credibility media (blue lines in SMFigure 11 A1 and A2), we see that agenda divergence isbrought forward by the misaligned attention spans or thedifferent spotlighting intensity on \u201cDEM candidate contro-versies\u201d. For Clinton\u2019s case in 2016, for instance, we canlink some dramatic drops in temporal alignment to the timeperiods when low-credibility media discussed \u201cClinton con-troversies\u201d much longer than high-credibility media afterbreaking events such as Bill Clinton and Loretta Lynch\u2019smeeting in early July and Hillary Clinton fainting in mid-September.\nFurthermore, at the keyword level, we notice that the drop\nin keyword alignment for \u201cREP candidate controversies\u201dcontributes greatly to the drop in overall keyword alignmentfrom 2016 to 2020. As shown in Figure 4, \u201cREP candidatecontroversies\u201d is among the noteworthy topics that have adramatic drop in keyword alignment from 2016 to 2020and that occur frequently enough to have a sizable impacton the overall alignment. Looking closer at speci\ufb01c aspects(i.e., keywords) addressed for \u201cREP candidate controver-sies\u201d, we see that high-credibility media dedicate more at-tention to Trump\u2019s family members; and that low-credibilitymedia put the spotlight on the deep-state conspiracy, andpush stories co-mentioning Trump with \ufb01gures such as Jef-frey Epstein, Adam Schiff, and Roger Stone. While thereis a lack of consensus on central aspects of \u201cREP candi-date controversies\u201d across different media types in 2020, thedivergence of aspects for \u201cDEM candidate controversies\u201dis much weaker\n9. Conditioned on the topic \u201cDEM candi-\ndate controversies\u201d, we notice that controversies centeredaround Hunter Biden are heavily debated on both sides ofmedia with high occurrences of keywords \u201cHunter Biden\u201d,\u201claptop\u201d and \u201cUkraine\u201d. Here, we focused on the alignmentacross credibility groups. The patterns observed for ideologyare, again, similar and omitted for brevity (see SM Figure 10for ideology results).\nTemporal Dynamics: Who Leads and Who\nFollows?\nNext, we shift our focus from concurrent correlations within\nthe same time frame to temporal correlations betweenlagged time frames. We describe the IAS dynamics capturedbetween low- and high-credibility media, and brie\ufb02y con-trast it with the dynamics between the left- and right-leaningmedia as a reference system.\nWe assess the IAS power based on (i) the number of at-\ntributes one media type leads for the other, as well as (ii) the\n9Among the top 500 frequent keywords for Trump-related texts\nin 2020, we correlate keywords that belong to \u201cTrump controver-\nsies\u201d. Pearson\u2019s R = 0.1446 between low- and high-credibility me-dia; Pearson\u2019s R = 0.1139 between left- and right-leaning media. InBiden-related texts, the corresponding Pearson\u2019s Rs for keywordsbelonging to \u201cBiden controversies\u201d are 0.8095 between low- andhigh-credibility media, and 0.7597 between left- and right-leaningmedia.\n261\n\u000f\u0010\u0011\u000e\u0010\u000e\u0019\u0018\u0014\u0018\u001d\u0016\u001c\u001c\u001d\u000e\u0013\u0016\u001d\u0013\u000e\u001b\u0014\u0017\u000e\u0014\u001f\u001b\u001d\u001b\u001e\u000e\u000e\u0016\u0014\u000e\u0012\u001f\u0019\u001a\u001d25.1\n\u0007\u0005\u0006\b\u0004\u0005\t \u0007\u0005\u0006\b\u0004\u0005\n \u0007\u0005\u0006\b\u0004\u0005\u000b \u0007\u0005\u0006\b\u0004\u0006\u0005 \u0007\u0005\u0006\b\u0004\u0006\u0006 \u0007\u0005\u0006\b\u0004\u0006\u0007\u000f\u0010\u0011\u000e\u0010\u000e\u0019\u0018\u0014\u0018\u001d\u0016\u001c\u001c\u001d\u000e\u0013\u0016\u001d\u0013\u000e\u001b\u0014\u0017\u000e\u0014\u001f\u001b\u001d\u001b\u001e\u000e\u000e\u0016\u0014\u000e\u0012\u001f\u0019\u001a\u000e-+/40/\u001c#/&'23\u0003\u0010/&023'3\u0003\u000e-+/40/\n\u001a'/%'\u0003\u000e*03'/\u0003#3\u0003\u001b'1\u0003\u001f\u001a\u0003\u00180.+/''\n\u001b'15$-+%#/\u0003\u000e0/6'/4+0/\n\u0015#+/'\u0003\u000e*03'/\u0003#3\u0003\u000f'.\u0003\u001f\u001a\u0003\u00180.+/''\n +,+-'#,3\u0003\u001c#/&'23\u0003\u0010.#+-3\n\u000f'.0%2#4+%\u0003\u000e0/6'/4+0/\n\u001d25.1\u0003\f3,3\u0003\u001b533+#\u000340\u0003\u0013#%,\u0003\u0010.#+-3\n\u000e-+/40/\u0003\u0012'43\u0003\u001a/'5.0/+#\u0003#/&\u0003\u0011#+/43\n\r#3,'4\u00030(\u0003\u000f'1-02#$-'3\u0003\u000e0..'/4\n\u0011+234\u0003\u000f'$#4'\n\u001f\u001a\u0003\u000f'$#4'\n\f%%'33\u0003\u00130--8700&\u0003\u001d#1'3\n +,+-'#,3\u0003\u001a0&'34#\u0003\u0010.#+-3\n\u001c'%0/&\u0003\u000f'$#4'\n\u001d*+2&\u0003\u000f'$#4'\n\u000e0.'8\u0003\u0016'44'2\n\u0010-'%4+0/\u0003\u000f#8\n-'&\u0003$8\u0003*+)*\u0004%2'&\n-'&\u0003$8\u0003-07\u0004%2'&\n.545#-\u0003+/4'2#%4+0/\n/0\u00032'-#4+0/3*+1\n!34#24\"\u00030(\u00034*'\u0003\u000b\u0005\u0004&#8\u00037+/&07\n!+/4'26#-\"\u00030(\u00034*'\u0003\u000b\u0005\u0004&#8\u00037+/&07\n\u0010\u0011\u0012\u000f\u0011\u000f\u001b\u001a\u0015\u001a\u001f\u0018\u001e\u001e\u001f\u000f\u000f\u0015!\u001d\u001f\u001d \u000f\u000e\u0015\u0010\u000f\u000f\u001d\u0015\u0019\u0014\u0018\u001f\u0014\u0013!\u001b\u001c\u001f4703\n\t\u0007\t\u0007\u0006\u0007\n \t\u0007\t\u0007\u0006\u0007\u000b \t\u0007\t\u0007\u0006\u0007\f \t\u0007\t\u0007\u0006\b\u0007 \t\u0007\t\u0007\u0006\b\b \t\u0007\t\u0007\u0006\b\t\u0010\u0011\u0012\u000f\u0011\u000f\u001b\u001a\u0015\u001a\u001f\u0018\u001e\u001e\u001f\u000f\u000f\u0015!\u001d\u001f\u001d \u000f\u000e\u0015\u0010\u000f\u000f\u001d\u0015\u0019\u0014\u0018\u001f\u0014\u0013!\u001b\u001c\u000e-()1\u0012)()4%/\u0003\u001b**-')45\u0003\u001c2/-')\u0003 \u001e\u0003\u000f-6-)5\n\u0014%44-5\u0003\u000f,25)1\u0003%5\u0003\u0010)0\u0003!\u001c\u0003\u001a20-1))\n\u0010)02'4%6-'\u0003\u000f218)16-21\n\u0016%'2&\u0003\u000e/%.)\u0003\u001e,26\u0003-1\u0003\u0017)125,%\n\u001d)37&/-'%1\u0003\u000f218)16-21\n\u0017;/)\u0003\u001d-66)1,275)\u0003\u001e,2265\u0003\u001c426)56)45\n\u001f4703\u0003!-5-65\u0003\u0017)125,%\n\"22(9%4(\u0003\u001516)48-)9\n\u001d\u000e\u0013\u0003\u0010-)(\n\u000f21);\u0003\u000e%44)66\u0003\u001a20-1%6)(\n\u001f4703\u0003\u001f%:\u0003\u001d)67415\u0003\u001d)/)%5)(\n\u0012-456\u0003\u0010)&%6)\n\u001f4703\u0003\u0013)65\u0003\u000f\u001b!\u0015\u0010\n\u001f4703\u0003\u001d)67415\u000362\u0003\",-6)\u0003\u0014275)\n!\u001c\u0003\u0010)&%6)\n\u0014716)4\u0003\u000e-()1\u0003\u0018%3623\u0003\u001e624;\n\u000f%1(-(%6)\u0003\u001f291,%//5\u0003\u0004\u001d)3/%')(\u0003\t1(\u0003\u0010)&%6)\u0005\n\u0012-1%/\u0003\u0010)&%6)\n\u000f21);\u0003\u000e%44)66\u0003\r33428)(\n\u0011/)'6-21\u0003\u0010%;\n/)(\u0003&;\u0003,-+,\u0006'4)(\n/)(\u0003&;\u0003/29\u0006'4)(\n0767%/\u0003-16)4%'6-21\n12\u00034)/%6-215,-3\n#56%46$\u00032*\u00036,)\u0003\f\u0007\u0006(%;\u00039-1(29\n#-16)48%/$\u00032*\u00036,)\u0003\f\u0007\u0006(%;\u00039-1(29\nFigure 6: Granger causality results between low- and high-credibility media for 2016 (the \ufb01rst and second \ufb01gures) and 2020\n(the third and fourth \ufb01gures). We test Granger causalities in a sliding window of 90 days and display robust results that appearin more than 95% of the bootstrapping runs. Each plus sign marks the starting point of the 90-day sliding window with asigni\ufb01cant result. We include results for the top 10 topics that show frequently in all news headlines for a given election year.\nlength of time period during which such IAS power can per-\nsist. We summarize this information in the sliding-windowplots displayed in Figure 6, where the starting points ofall 90-day windows with a signi\ufb01cant and robust Grangercausality result are marked with plus signs (+). Each plussign is followed by 90 dots (\u00b7 ) colored the same as the plus\nsign to visually demonstrate the full length of sliding win-dows. For example, for Trump 2016 there is only one timewindow with signi\ufb01cant and robust results on the attribute\u201ceconomy (ECON)\u201d, spanning from early July to early Oc-tober.\nOverall, we see that high-credibility media serve as the\ndominant actor in IAS, setting the agenda for more candi-date attributes than low-credibility media. Out of the top10 attributes that appear frequently in a given year, high-credibility media lead the agenda of 5.5 attributes for the Re-publican candidate and 3 attributes for the Democratic can-didates on average, with varying window lengths\n10. Mean-\nwhile, we do not see low-credibility media persistentlyleading the agenda on any attribute in either election sea-son. Despite the encouraging results, we observe that high-credibility media\u2019s IAS power has declined from 2016 to2020 for the Democratic candidate, with a decrease in termsof the number of attributes it leads (from 4 to 2), and the totalnumber of windows it leads (from 165 to 60). Furthermore,agendas between high- and low-credibility media appear tobe more intertwined, mutually interacting with each other on3 attributes for Trump and 4 for Biden in 2020, but only 1for Clinton in 2016.\nNotably, while \u201ccandidate controversies\u201d acts as a cru-\n10We count attributes with at least three consecutive windows\nshowing consistent causality results.\n262\ncial attribute that drives the divergence of the media agenda,\ndiscussions of \u201cREP (DEM) candidate controversies\u201d in thecoverage of the Republican (Democratic) candidate are al-ways led by high-credibility media. Based on Figure 6, thelongest consecutive high-credibility-leading windows (i.e.,consecutive time windows with a signi\ufb01cant and robust re-sult of high-credibility media taking the lead) lasts for 135days (45 windows) for the Republican candidate and 134days (44 windows) for the Democratic candidate on aver-age\n11. Moreover, the election-wise comparison re-iterates\nthe diminishing IAS power of high-credibility media specif-ically on \u201cDEM/REP candidate controversies\u201d, as the lengthof the longest consecutive high-credibility-leading windowsshrinks from 141.5 days (51.5 windows) per candidate in2016 to 127.5 days (37.5 windows) per candidate in 2020.Such shrinking in window length happens more severely forthe Democratic candidate (\u0000L = -20 days) than the Repub-\nlican candidate (\u0000L = -8 days).\nTo sum up, high-credibility media is more powerful in\nIAS compared to low-credibility media, as it leads theagenda for more attributes and consistently for longer pe-riods of time; however, the IAS power of high-credibilitymedia has declined from 2016 to 2020, together with afew more attributes seeing mutually interacting agendasin 2020 (e.g., \u201ccrime\u201d for Trump, \u201cgovernment operation\u201dand \u201chealthcare\u201d for Biden). Contrasting these patterns withthe IAS dynamics between left- and right-leaning media(see SM Figure 13), we see shared patterns between high-credibility and left-leaning media in terms of their dominantrole in IAS in general, as well as their weakening leader ad-vantage from 2016 to 2020, especially for the Democraticcandidate. While some level of symmetry does exist betweencredibility and ideology, we see the value of separately ad-dressing IAS along these two dimensions. Right-leaning me-dia clearly take a more active role than low-credibility me-dia in 2020, persistently setting agenda for a few attributesof the Republican candidate (e.g., leading \u201ccivil rights\u201d and\u201cinternational affairs\u201d for Trump in 2020).\nConclusions and Limitations\nIn this paper, we re-examine IAS theory for news headlinesrelated to presidential candidates during the 2016 and 2020U.S. presidential elections.\nOverall, we observe a high level of agenda alignment in\ncandidate coverage between low- and high-credibility me-dia. The agenda convergence indicates that low- and high-credibility media still share a common ground for candidate-related discussions on broad issues; however, the initiatorof such assimilation remains unclear. Low-credibility me-dia could be borrowing stories from traditional players withhigher credibility levels, due to their limited resources toindependently produce impactful news stories in the \ufb01erceattention battleground. Alternatively, past work also showsthat traditional media can spread misinformation, especially\n11The length of a set of consecutive time windows equals the\nlength of one time window (i.e., 90 days) plus the number of con-\nsecutive time windows within the set, as the unit per slide is oneday.by indexing political elite talking points (Muddiman et al.\n2022). High-credibility media might be loosening their jour-nalistic standards in order to attract and retain their audi-ence, generating stories of disputable issues that are easier tobe re-packaged into low-credibility clickbaits, as we see inour results the signi\ufb01cant proportions of attention devoted to\u201ccandidate controversies\u201d rather than policy topics in high-credibility media.\nIn addition, our study adds to the growing body of litera-\nture that highlights partisan asymmetries in the news ecosys-tem (e.g., Budak 2019; Guess, Nyhan, and Rei\ufb02er 2020) bydemonstrating the stronger alignment in agendas for the Re-publican candidate compared to the Democratic candidates.Past work shows that media exhibit their bias largely throughnegative depictions of the opposing side, as opposed to pos-itive depictions of the preferred side (Soroka 2014; Budak,Goel, and Rao 2016). Here, the diverging agendas for theDemocratic candidate provide evidence that such bias mayextend to selective coverage of topics.\nWe also observe meaningful shifts in IAS when compar-\ning 2016 to 2020, which underscore two valuable insights.First, it is a caution against over-generalization from stud-ies focused on a single case study. Second, it shows thatthe U.S. news ecosystem is still in \ufb02ux, with IAS powersof different media types shifting. Our results thus motivatefuture researchers to carry out large-scale empirical studiesto examine well-established communication theories usingcontemporary datasets.\nThere are various limitations to this work. First and\nforemost, although we use terms such as \u201cin\ufb02uence\u201d and\u201cGranger causation\u201d when assessing IAS, the IAS processcaptured in our study is based on correlational analysis.While we follow the terminology used in scholarship andtheorize about setting the agenda, we caution the reader thatthe associations found here are not suf\ufb01cient evidence of acausal relationship. Secondly, our dictionary-based modelutilizes context-speci\ufb01c topics and keywords related to acertain issue (e.g., presidential candidates), which limits itsgeneralizability. While the dictionaries themselves are notgeneralizable, the pipeline we introduced for constructingand validating topic dictionaries is. Our modeling approachallows interpretability and cross-year comparisons. Finally,we use a set of existing source lists for determining the cred-ibility of different websites, where sizable disagreementsexist across lists constructed by different fact-checkers andscholars (Bozarth, Saraf, and Budak 2020). Furthermore, thelimited coverage of ideology labels has restricted our scopeof analysis when comparing left- and right-leaning media.We encourage future studies to explore more source lists ofdomain credibility and ideology, and incorporate a better-labeled dataset for such parallel analysis.\nOur \ufb01ndings also identify new directions for future work\nof IAS. First, it is worth following up with more recentdatasets to examine if the IAS trends identi\ufb01ed in 2016 and2020 continue in future elections. Second, we notice a fewsignals for the insuf\ufb01cient explanatory power of the currentmodels in capturing temporal \u201ccausation\u201d between left- andright-leaning media. For instance, in SM Figure 13, we seethe absence of signi\ufb01cant and robust IAS results in most 90-\n263\nday sliding windows, particularly for the Democratic can-\ndidate. This may be a substantive \ufb01nding: left- and right-wing media fail to set each other\u2019s agendas. Or, this maybe a result of linear regression models failing to capture theincreasingly complicated agenda interactions. Such obscu-rity invites future explorations of different methodologiesto validate or extend our \ufb01ndings. Third, our parallel anal-ysis points out that the divisions along ideology and credi-bility share some structural features but are not entirely over-lapping. Future work could look into the interplay betweenthese two dimensions.\nEthics Statement and Broader Impact\nGiven the political context of the case studies, we understandand try to minimize the risk of misinterpretation. We testthe signi\ufb01cance and robustness of the observed patterns bybootstrapping and de-noise the temporal volatility throughsliding-window analysis. We also re-iterate the correlationalbasis of our analysis.\nApart from cautiously deriving the implication, we have\nincorporated the following ethical considerations: (1) oncecollected and preprocessed, the headline dataset is stored onthe server with restricted access; (2) we remove personallyidenti\ufb01able information from the MTurk output; (3) we ac-tively communicate with MTurk workers who raise ques-tions or concerns, and make sure that those who attentivelywork on the labeling tasks are fairly compensated (even ifthey fail the screening); and (4) we release the dictionaryand the model source code in a GitHub repository\n12.\nIn an era marked by growing concerns of polarization and\nfake news, our study enhances the understanding of IASalong both the credibility and the ideology dimensions byproviding detailed comparisons at multiple levels of granu-larity. We hope to inspire open dialogues among media enti-ties, policymakers, and the public to address challenges ev-idenced by the alarming trend in our results\u2013the decline inthe IAS power of high-credibility media.\nAcknowledgements\nThis project was supported by the National Science Foun-dation awards #2045432 and #1934925/#1934494 and theCenter for Advanced Study in Behavioral Sciences.\nReferences\nAgiesta, J. 2020. Read: The methodology behind newpolling project The Breakthrough. CNN.\nAllcott, H.; Gentzkow, M.; and Yu, C. 2019. Trends in thediffusion of misinformation on social media. Research &\nPolitics, 6(2): 2053168019848554.\nBaum, M. A.; and Groeling, T. 2008. New media and the\npolarization of American political discourse. Political Com-\nmunication, 25(4): 345\u2013365.\nBode, L.; Budak, C.; Ladd, J. M.; Newport, F.; Pasek, J.;\nSingh, L. O.; Soroka, S. N.; and Traugott, M. W. 2019.Words that matter: How the news and social media shaped\n12https://github.com/yijingch/intermedia-agenda-settingthe 2016 Presidential campaign. Brookings InstitutionPress.\nBozarth, L.; and Budak, C. 2021. Market forces: Quanti-\nfying the role of top credible ad servers in the fake newsecosystem. In Proceedings of the International AAAI Con-\nference on Web and Social Media, volume 15, 83\u201394.\nBozarth, L.; Saraf, A.; and Budak, C. 2020. Higher ground?\nHow groundtruth labeling impacts our understanding of fakenews about the 2016 US presidential nominees. In Proceed-\nings of the International AAAI Conference on Web and So-cial Media, volume 14, 48\u201359.\nBreed, W. 1955. Newspaper \u2018opinion leaders\u2019 and processes\nof standardization. Journalism Quarterly, 32(3): 277\u2013328.\nBrosius, H.-B.; and Kepplinger, H. M. 1990. The agenda-setting function of television news: Static and dynamicviews. Communication research, 17(2): 183\u2013211.\nBudak, C. 2019. What happened? the spread of fake newspublisher content during the 2016 us presidential election.InThe World Wide Web Conference, 139\u2013150.\nBudak, C.; Bozarth, L.; Bond, R. M.; Margolin, D.; Jones,J. J.; and Garrett, R. K. 2023a. Bursts of contemporaneouspublication among high-and low-credibility online informa-tion providers. New Media & Society, 14614448231183617.\nBudak, C.; Goel, S.; and Rao, J. M. 2016. Fair and balanced?Quantifying media bias through crowdsourced content anal-ysis. Public Opinion Quarterly, 80(S1): 250\u2013271.\nBudak, C.; Jomini Stroud, N.; Muddiman, A.; Murray, C. C.;and Kim, Y. 2023b. The Stability of Cable and BroadcastNews Intermedia Agenda Setting Across the COVID-19 Is-sue Attention Cycle. Political Communication, 1\u201321.\nChaffee, S. H.; and Metzger, M. J. 2001. The end of masscommunication? Mass communication & society, 4(4): 365\u2013\n379.\nChurchill, R.; Singh, L.; Ryan, R.; and Davis-Kean, P. 2022.\nA Guided Topic-Noise Model for Short Texts. In Proceed-\nings of the ACM Web Conference 2022, 2870\u20132878.\nCouts, A.; and Wyrich, A. 2016. Here are all the \u2018fake news\u2019\nsites to watch out for on Facebook.\nEldridge, S. A. 2019. Thank god for Deadspin\u201d: Interlop-\ners, metajournalistic commentary, and fake news throughthe lens of \u201cjournalistic realization. New Media & Society,\n21(4): 856\u2013878.\nFORCE11. 2020. The FAIR Data principles. https://force11.\norg/info/the-fair-data-principles/. Accessed: 2024-03-31.\nGebru, T.; Morgenstern, J.; Vecchione, B.; Vaughan, J. W.;\nWallach, H.; Iii, H. D.; and Crawford, K. 2021. Datasheetsfor datasets. Communications of the ACM, 64(12): 86\u201392.\nGentzkow, M.; Shapiro, J. M.; and Stone, D. F. 2015. Me-dia bias in the marketplace: Theory. In Handbook of media\neconomics, volume 1, 623\u2013645. Elsevier.\nGillin, J. 2017. PolitiFact\u2019s guide to fake news websites and\nwhat they peddle.\nGolan, G.; and Wanta, W. 2001. Second-level agenda setting\nin the New Hampshire primary: A comparison of coveragein three newspapers and public perceptions of candidates.\n264\nJournalism & Mass Communication Quarterly, 78(2): 247\u2013\n259.\nGroshek, J.; and Clough Groshek, M. 2013. Agenda trend-\ning: Reciprocity and the predictive capacity of social net-work sites in intermedia agenda setting across issues overtime. Available at SSRN 2199144.\nGuess, A. M.; Nyhan, B.; and Rei\ufb02er, J. 2020. Exposureto untrustworthy websites in the 2016 US election. Nature\nhuman behaviour, 4(5): 472\u2013480.\nGuo, L. 2012. The application of social network analysis\nin agenda setting research: A methodological exploration.Journal of Broadcasting & Electronic Media, 56(4): 616\u2013631.\nGuo, L.; and Vargo, C. 2020. \u201cFake news\u201d and emerging\nonline media ecosystem: An integrated intermedia agenda-setting analysis of the 2016 US presidential election. Com-\nmunication Research, 47(2): 178\u2013200.\nHearings. 2017. The Policy Agendas Project at the Uni-\nversity of Texas at Austin. www.comparativeagendas.net,Accessed September 26, 2017.\nHermann, P.; Svrluga, S.; and Miller, M. E. 2016. Alleged\ngunman tells police he wanted to rescue children at DC pizzashop after hearing \ufb01ctional internet accounts. The Washing-\nton Post, 5.\nKim, J.; and Min, Y. 2015. An issue attention cycle analysis\nof the network agenda setting model. The power of informa-\ntion networks: New directions for agenda setting, 132.\nKiousis, S.; Bantimaroudis, P.; and Ban, H. 1999. Candidate\nimage attributes: Experiments on the substantive dimensionof second level agenda setting. Communication Research,\n26(4): 414\u2013428.\nKiousis, S.; Mitrook, M.; Wu, X.; and Seltzer, T. 2006.\nFirst-and second-level agenda-building and agenda-settingeffects: Exploring the linkages among candidate news re-leases, media coverage, and public opinion during the 2002Florida gubernatorial election. Journal of Public Relations\nResearch, 18(3): 265\u2013285.\nKrippendorff, K. 2018. Content analysis: An introduction to\nits methodology. Sage publications.Lee, J. K. 2007. The effect of the Internet on homogeneity of\nthe media agenda: A test of the fragmentation thesis. Jour-\nnalism & Mass Communication Quarterly, 84(4): 745\u2013760.\nLevendusky, M. 2013. How partisan media polarize Amer-\nica. University of Chicago Press.Lind, F.; Gruber, M.; and Boomgaarden, H. G. 2017. Con-\ntent analysis by the crowd: Assessing the usability of crowd-sourcing for coding latent constructs. Communication meth-\nods and measures, 11(3): 191\u2013209.\nMaier, S. 2010. All the news \ufb01t to post? Comparing\nnews content on the web to newspapers, television, and ra-dio.Journalism & Mass Communication Quarterly, 87(3-4):\n548\u2013562.\nMcCombs, M. 2005. A look at agenda-setting: Past, present\nand future. Journalism studies, 6(4): 543\u2013557.McCombs, M.; Llamas, J. P.; Lopez-Escobar, E.; and Rey, F.1997. Candidate images in Spanish elections: Second-levelagenda-setting effects. Journalism & Mass Communication\nQuarterly, 74(4): 703\u2013717.\nMcCombs, M.; and Reynolds, A. 2009. How the news\nshapes our civic agenda. In Media effects, 17\u201332. Routledge.\nMcCombs, M.; and Valenzuela, S. 2020. Setting the agenda:\nMass media and public opinion. John Wiley & Sons.\nMcCombs, M. E.; and Shaw, D. L. 1972. The agenda-setting\nfunction of mass media. Public opinion quarterly, 36(2):\n176\u2013187.\nMeraz, S. 2011. Using time series analysis to measure in-\ntermedia agenda-setting in\ufb02uence in traditional media andpolitical blog networks. Journalism & mass communication\nquarterly, 88(1): 176\u2013194.\nMuddiman, A.; Budak, C.; Murray, C.; Kim, Y.; and Stroud,\nN. J. 2022. Indexing theory during an emerging health cri-sis: how US TV news indexed elite perspectives and ampli-\ufb01ed COVID-19 misinformation. Annals of the International\nCommunication Association, 46(3): 174\u2013204.\nMuddiman, A.; Stroud, N. J.; and McCombs, M. 2014.\nMedia fragmentation, attribute agenda setting, and politicalopinions about Iraq. Journal of Broadcasting & Electronic\nMedia, 58(2): 215\u2013233.\nNicholson, S. P. 2021. Voting the agenda: Candidates, elec-\ntions, and ballot propositions. Princeton University Press.Reese, S. D.; and Danielian, L. H. 2012. Intermedia in\ufb02u-\nence and the drug issue: Converging on cocaine. In Commu-\nnication campaigns about drugs, 29\u201345. Routledge.\nShoemaker, P. J.; and Reese, S. D. 2013. Mediating the\nmessage in the 21st century: A media sociology perspective .\nRoutledge.Soroka, S. N. 2014. Negativity in democratic politics:\nCauses and consequences. Cambridge University Press.Stroud, N. J. 2011. Niche news: The politics of news choice.\nOxford University Press.Sweetser, K. D.; Golan, G. J.; and Wanta, W. 2008. Inter-\nmedia agenda setting in television, advertising, and blogsduring the 2004 election. Mass Communication & Society,\n11(2): 197\u2013216.\nVan Zandt, D. 2015. Media Bias / Fact Check.Vargo, C. J.; Basilaia, E.; and Shaw, D. L. 2015. Event ver-\nsus issue: Twitter re\ufb02ections of major news, a case study. InCommunication and information technologies annual, vol-ume 9, 215\u2013239. Emerald Group Publishing Limited.\nVargo, C. J.; and Guo, L. 2017. Networks, big data, and in-\ntermedia agenda setting: An analysis of traditional, partisan,and emerging online US news. Journalism & Mass Commu-\nnication Quarterly, 94(4): 1031\u20131055.\nVargo, C. J.; Guo, L.; and Amazeen, M. A. 2018. The\nagenda-setting power of fake news: A big data analysis ofthe online media landscape from 2014 to 2016. New media\n& society, 20(5): 2028\u20132049.\nZimdars, M. 2016. My \u201cfake news list\u201d went viral. But\nmade-up stories are only part of the problem. Washington\nPost.\n265\nEthics Checklist\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair pro\ufb01ling, exac-erbating the socio-economic divide, or implying disre-spect to societies or cultures? Yes. We\u2019re interested in\naddressing the divide across different news consump-tion niches by empirically measuring agenda align-ment, and we do not anticipate any of the aforemen-tioned harms.\n(b) Do your main claims in the abstract and introduction\naccurately re\ufb02ect the paper\u2019s contributions and scope?Yes. We cautiously use the term \u201cGranger causation\u201dto avoid overstating the temporal relationships we in-fer.\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes. We do\nthat by referencing widely tested approaches as well ascarefully validating the output generated by our topicmodel.\n(d) Do you clarify what are possible artifacts in the data\nused, given population-speci\ufb01c distributions? Yes. We\ndiscuss the de-biasing method implemented to mini-mize the potential bias introduced by varying snap-shotting frequencies of Wayback machine in SectionDataset and Preprocessing.\n(e) Did you describe the limitations of your work? Yes,\nplease refer to Section Limitations and Future Work.\n(f) Did you discuss any potential negative societal im-\npacts of your work? Yes, please refer to Section Ethics\nStatement and Broader Impact.\n(g) Did you discuss any potential misuse of your work?\nNo. We do not anticipate any direct misuse of our worksince the model and the results are only applicable ina speci\ufb01ed context. We try to minimize the possibilityof our results being misinterpreted by carefully fram-ing the conclusions and supplementing clari\ufb01cationswhen necessary (e.g., clarifying high-credibility me-dia\u2019s role in agenda divergence).\n(h) Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as dataand model documentation, data anonymization, re-sponsible release, access control, and the reproducibil-ity of \ufb01ndings? Yes, please refer to Section Ethics\nStatement and Broader Impact.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying\nall theoretical results? Not applicable. Our work is\ndriven by an open question instead of a theoreticallygrounded hypothesis.\n(b) Have you provided justi\ufb01cations for all theoretical re-\nsults? NA(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-sults? NA\n(d) Have you considered alternative mechanisms or expla-\nnations that might account for the same outcomes ob-served in your study? NA\n(e) Did you address potential biases or limitations in your\ntheoretical framework? NA\n(f) Have you related your theoretical results to the exist-\ning literature in social science? Yes. For instance, the\nlower degree of keyword-level alignment (comparedto topic-level alignment) is in line with previous work.\n(g) Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in thesocial science domain? Yes. We include these in the\nSection Ethics Statement and Broader Impact.\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? NA\n(b) Did you include complete proofs of all theoretical re-\nsults? NA\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-ther in the supplemental material or as a URL)? No.\nWe will publish the code upon acceptance.\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? Yes. For the\nhyperparameters, we did some sensitivity analysis andchose the ones that had the best results. For data splits,we randomly split them.\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?No, because it is of little relevance to our paper.\n(d) Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internalcluster, or cloud provider)? No, because the model\ndoes not require much computational resource. Boththe dictionary-based topic model and the guided topicmodel were run on a single CPU.\n(e) Do you justify how the proposed evaluation is suf\ufb01-\ncient and appropriate to the claims made? Yes, please\nrefer to Methods \u2013 Dictionary-based Topic Modeling\u2013 Validating Output.\n(f) Do you discuss what is \u201cthe cost\u201c of misclassi\ufb01cation\nand fault (in)tolerance? No. When comparing model\nlabels with human labels, we noticed that human la-belers are more likely to label a text as controversies-related more than the model, which means the down-stream counts of the topic \u201ccandidate controversies\u201dwould be rather conservative. However, after internalinspections of these text examples, we do not think theconservative perspective would signi\ufb01cantly misleadour \ufb01ndings because (1) the output time series of \u201ccan-didate controversies\u201d is able to capture major events\n266\nof candidate scandals and (2) we would caution read-\ners to take human labels as thegroundtruth, given the\nsuboptimal level of human-human agreement overall.\n5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets...\n(a) If your work uses existing assets, did you cite the\ncreators? Yes, we utilize lists of online news labels\nfrom existing studies and referenced them in SectionDataset and Preprocessing; we also leveraged GuidedTopic-Noise Model created by Churchill et al. (2022)and cited the work in Section Methods \u2013 Dictionary-\nbased Topic Modeling \u2013 Constructing topic dictionar-ies.\n(b) Did you mention the license of the assets? No. There\nis no existing license for the assets we utilize in thispaper.\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? No. We release the current ver-\nsion of topic dictionaries in a GitHub repository andwill update the repository if any future changes occur.The headline dataset is available upon request.\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you\u2019re using/curatingNA\n(e) Did you discuss whether the data you are using/curat-\ning contains personally identi\ufb01able information or of-fensive content? Yes. While the headline dataset does\nnot contain personally identi\ufb01able information, it maycontain low-credibility information. When releasing asample on MTurk for the topic labeling task, we ex-plained the context of the data and the task (e.g., thedata source, and the purpose of our research) to mini-mize the risk of misleading workers.\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR(see FORCE11 (2020))? Yes, please refer to Section\nEthics Statement and Broader Impact. More details re-garding how we conform to these guidelines will beincluded in the Datasheet released with the topic dic-tionary.\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset (see Gebru et al.(2021))? Yes. We release the topic dictionary with the\nDatasheet.\n6. Additionally, if you used crowdsourcing or conducted re-\nsearch with human subjects...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? Yes, please refer to SM\nFigure 7.\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-provals? Yes, please refer to Section Ethics Statement\nand Broader Impact.\n(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participantcompensation? Yes, we included it in our discussion ofthe MTurk task. Please refer to Methods \u2013 Dictionary-based Topic Labeling \u2013 Validating Output.\n(d) Did you discuss how data is stored, shared, and dei-\ndenti\ufb01ed? Yes, please refer to Section Ethics Statement\nand Broader Impact.\n267\nSupplementary Materials\nCollecting Human Labels from MTurk Our quality-control pipeline involves (a) selecting workers who have acquired a\nMasters quali\ufb01cation and reside in the U.S., and (b) blocking workers who fail to correctly label any of the two screening texts\nin a single HIT (see the full pipeline in SM Figure 8). We include detailed instructions on the top of the task page, describing the\ndata sources, the purpose of our study, as well as the quality assurance steps we take to decide whether to accept a submission(see the task interface in SM Figure 7). Workers are compensated 1.0 USD per HIT, achieving an hourly rate of 15 USD at arelaxing speed of 4 minutes per HIT.\nThe entire task costs 407 USD, providing labels for 240 news headlines, 240 survey responses, and 240 tweets sampled\nfrom our data\n13, with each text being read by three MTurk workers. In total, 40 workers are involved in our study, all of whom\nhave contributed at least one quali\ufb01ed assignment. 19 out of these workers were blocked from further submitting for failing thescreening questions. Out of 284 total submitted assignments, we use 263 quali\ufb01ed ones (93.36%) to generate labels for 718 textinputs. We assess the reliability of the workers by computing inter-rater reliability (Krippendorff\u2019s alpha =0.4385 for 2016 and\n0.4251 for 2020) for the primary topic, a commonly used measure in the literature (Krippendorff 2018). The reliability, while\nlow by traditional content analysis standards, is signi\ufb01cantly higher than accepted levels for crowd-sourced approaches (Lind,Gruber, and Boomgaarden 2017).\nPlease read instructions carefully before you start :)\nHi, we are a group of researchers from the University of Michigan, School of Information. Our current project is trying to understand the\ntopics covered in the news, social media, and responses to survey questions about the presidential candidates during the 2016\nand 2020 elections.\nParticipation is voluntary.\nThe University of Michigan Health Sciences and Behavioral Sciences Institutional Review Board has determined that this research is\nexempt from IRB oversight.\nPlease contact Yijing Chen (yijingch@umich.edu) or Prof. Ceren Budak (cbudak@umich.edu) for any questions or concerns.\nYour task: to assign topic labels for 10 candidate-related short texts we sampled from\n1. news headlines,\n2. tweets, and\n3. survey responses to \"what have you recently heard/read/seen about [CANDIDATE NAME]\" (if/when such text samples are included in theHIT, they will be pre-fixed with [about CANDIDATE NAME]).\nPlease assign the following three types of topic labels:\nTopic Type Guidance\nPrimary Topic the most relevant topic (if not listed, select \"not applicable\")\nSecondary Topic the second most relevant topic (if not listed, select \"not applicable\")Relevant Topic(s) all other topic(s) relevant (if any)\n*NOTES:\nIf there are multiple topics and you cannot decide which is more relevant, please rank topic relevance based on the order of keywords\nappearance, i.e., the first (second) keyword that shows up in the short text would link to the primary (secondary) topic.\n[IMPORTANT] Label quality assurance: A small portion of the texts are pre-labeled with the correct topics. You won't be able toparticipate in future labeling task if your labeling accuracy falls below a certain threshold for these pre-labeled texts, but you will stillreceive full payment for the HITs that you have attentively worked on.\n \nSome examples with suggested answers:\nExample Type Example(s) Suggested Answers\nOne dominant topic Biden's immigration  pick yields outrage on left Primary: immigration  \nSecondary: not\napplicable Relevant: blank\nOne dominant topic [about Trump] He doesn't want to support renewable\nenergy .Primary: energy  \nSecondary: notapplicable Relevant: blank\nMultiple relevant topics (with a clear focus) Canada  open to renegotiating free trade  with Trump. Primary: foreign trade  \nSecondary: international\naffairs  \nRelevant: blank\nMultiple relevant topics (with no clear ranking) Biden's covid-19  taskforce recommends withholding\nfood stamps , rent assistance , healthcare from vaccine\nrefusersPrimary: healthcare  \nSecondary: social\nwelfare  \nRelevant: housing\nNo relevant topic (candidate-related but nospecific topics are involved; expressing puresentiment)[About Trump] He's very good at being Donald Trump. [about Hillary] I don't trust her.Primary: not applicable Secondary: notapplicable Relevant: blank\nNo relevant topic (not candidate-related at all) BLM invades Trader Joe's to protest lack of black access\nto grocery stores.Primary: not applicable Secondary: notapplicable Relevant: blank\n \nPlease assign topic labels to the following 10 short texts.\n(Hover over topic descriptions to view some examples of short texts.)\n \n****{text1}****\n \nPrimary\nTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text2}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text3}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text4}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text5}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text6}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text7}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text8}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text9}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n****{text10}****\n \nPrimaryTopicSecondaryTopicRelevantTopic(s)Topic Description (guidance, or a few example sub-categories for each topic)\n  Submitnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/ospecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidate\nnot applicable: none of the following topics is relevant; pure sentiment (e.g., like/dislike) w/o\nspecific topics\nagriculture: agriculture policy, trade & marketing; farmers; fisheries & fishing; animal & crop\ndisease\ncivil rights: racial equality; gender equality; voting rights; freedom of speech; gun rights;\nright to privacy; age discrimination; anti-government activities\ncrime: law enforcement agencies; crimes & crime control; police; prisons; court\nadministration; child abuse & family issues\nculture: cultural policy; culture & entertainment\ndefence: defence alliance & agreement; military intelligence; nuclear arms; military aid;\nmilitary procurement; domestic security responses; foreign military operations\neconomy: banking; small businesses; disaster relief; tax policies; consumer finance;\ninsurance regulation; bankruptcy; corporate management; securities & commodities\neducation: education policy; elementary & primary schools; vocational education; higher\neducation, student loans; education of underprivileged students\nelection campaign: campaign-related events: conventions; debates; townhalls & rallies;\nrunning mate nomination\nenergy: energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable;\nconservation & efficiency; research & development\nenvironment: environmental policy; drinking water; waste disposal; hazardous waste; air\npollution; recycling; species & forest; land and water conservation\nforeign trade: trade agreements; exports; private investments; tariff & imports; exchange\nrates; competitiveness; trade policy\ngovernment operation: general governmental operations; intergovernmental relations;\nbureaucracy; census & statistics; postal service; procurement & contractors\nhealthcare: public health and candidates' health conditions; coronavirus spread & control;\nhealthcare reform; insurance; medical facilities; disease prevention; healthcare research &development; mental health; drug and alcohol abuse\nhousing: community development; urban development; rural housing; low-income assistance;\nhousing for veteran, the elderly & the homeless\nimmigration: immigration issues & policies; refugees; citizenship\ninternational affairs: international affairs & foreign aid; resources exploitation; developing\ncountries; international finance; human rights issues; terrorism; international organizations\nlabor: labour, employment & pensions; employee benefits; labor unions; fair labor standards;\nworker safety; employment training; youth employment\nreligion: general religious issues; religous groups; church activities; religious freedom\nsocial welfare: social welfare policy; low-income/elderly/disabled assistance; volunteer\nassociations; child care\nspace, science, technology, & communications: issues related to general space, science,\ntechnology & communications: mass/social media presence, space programs,\ntelecommunication regulation\ntransportation: mass transportation construction; highways, air & railroad travel; maritime\ntransportation; infrastructure\ntrump controversies: controversial topics related to Trump, such as family or personal\nscandal, health condition speculations and disputable remarks\nbiden controversies: controversial topics related to Biden, such as family or personal\nscandal, health condition speculations and disputable remarks\ngeneral controversies: general controversial topics with no main targeting candidatecontact removed for blind review\nFigure 7: Screenshots of labeling task interface we launched on Amazon Mturk.\n13The topic labeling task is designed for three datasets of short texts relevant to presidential candidates: (1) news headlines, (2) tweets that\nmentioned at least one candidate\u2019s last name, and (3) survey responses to the question \u201cwhat have you read/seen/heard about candidate X?\u201d.\nBecause we only analyze headline data for this paper, we skip the discussions of the other two datasets.\n268\nPre-task screening\n- has completed at least 1000 HITs\n- acceptance rate \u2265 98%- resides in US- has Masters  qualification\nqualified MTurkers\nFail to correctly label any screening text Correctly label at least one screening texts\nAccept\nReject without paying Reject and payif they spend less than \n30 seconds per HITif they spend at least 30 \nseconds per HIT\nFigure 8: Diagram of our quality-control pipeline on MTurk.\n\b\u00073\n\b\u00073\t\b\u00073\b\b\u0007\u0007\n\u001d,-(\"\u0003\u0004\u0003(+\u0003)$%0\u0003#,*!(+/\b\u00073\n\b\u00073\t\b\u00073\b\b\u0007\u0007\u001d,-(\"\u0003\u0004\u0003(+\u0003.(&'0\u0003#,*!(+/\n\u001c\u0019 \u0016\u0011\u0018\u001f\u001b\n\u0011\u0018\u001b\u0013\u0012\u001b\u001d\u001b\u0016\r\u000e\u001b\n\u0011\u0010\u001e\u000f\u001b\u0011\u0016\u0013\u0015\u0017\u0017\u0015\u000f\u0016\u0015\u000f\n\u0010\u0011\u0012\u000f\u0014\u0016\u001d\u0014\u0011\u000f\u0019\u0018\u000f\u001b\u0015\u0017\n\u001c\u001c\u001d\u000f\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\u001d\u001b\u001e\u000f\u0013\u001f\u0019\u001a\n\u001c\u0019 \u0016\u0011\u0018\u001f\u001b\u0011\u0018\u001b\u0013\u0012\u001b\u001d\u001b\u0016\r\u000e\u001b\u0011\u0010\u001e\u000f\u001b\u0011\u0016\u0013\u0015\u0017\u0017\u0015\u000f\u0016\u0015\u000f\n\u0010\u0011\u0012\u000f\u0014\u0016\u001d\u0014\n\u0011\u000f\u0019\u0018\u000f\u001b\u0015\u0017\n\u001c\u001c\u001d\u000f\n\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\u001d\u001b\u001e\u000f\u0013\u001f\u0019\u001a\t\u0007\b\u000b\n.$\f\u0003\u001b\u0011\u001a\u0003\"!+#\n.$\f\u0003\u0010\u0011\u0017\u0003\"!+#\n-,)(\"2\u0005.$)!0$#\n\",+0.,1$./($/\n$)$\"0(,+\u0003\u0006\u0003&,1+*0\u0003,-/\n\b\u00073\n\b\u00073\t\b\u00073\b\b\u0007\u0007\n\u001d,-(\"\u0003\u0004\u0003(+\u0003)$%0\u0003#,*!(+/\u001d,-(\"\u0003\u0004\u0003(+\u0003.(&'0\u0003#,*!(+/\n\u001c\u0019 \u0016\n\u0012\u001b\u001d\u001b\u001b\u0011\u0016\u0013\n\u0011\u0018\u001f\u001b\u0016\r\u000e\u001b\u000e\u0015\u0010\u000f\n\u0011\u0018\u001b\u0013\u0011\u0010\u001e\u000f\u0015\u0017\u0017\u0015\u0010\u0011\u0012\u000f\n\u0011\u000f\u0019\u0018\u001c\u001c\u001d\u000f\n\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\u000f\u001b\u0015\u0017\u001d\u001b\u001e\u000f\u0014\u0016\u001d\u0014\u0013\u001f\u0019\u001a\n\u001c\u0019 \u0016\u0012\u001b\u001d\u001b\u001b\u0011\u0016\u0013\n\u0011\u0018\u001f\u001b\u0016\r\u000e\u001b\u000e\u0015\u0010\u000f\n\u0011\u0018\u001b\u0013\n\u0011\u0010\u001e\u000f\u0015\u0017\u0017\u0015\u0010\u0011\u0012\u000f\u0011\u000f\u0019\u0018\u001c\u001c\u001d\u000f\n\u0015\u0018\u001d\u0016\u000f\u0015\u001f\u001b\u000f\u001b\u0015\u0017\n\u001d\u001b\u001e\u000f\u0014\u0016\u001d\u0014\u0013\u001f\u0019\u001a\t\u0007\t\u0007\nFigure 9: Comparisons of topic proportion between left- and right-leaning domains in 2016 (left) and 2020 (right).\n269\n0\u0007\u0005\u0006 0\u0006\u0005\t \u0006\u0005\u0006 \u0006\u0005\t \u0007\u0005\u0006\n\r+,,#(\u001f.'+*\u0003'*\u0003\b\u0006\u0007\n0\u0007\u0005\u00060\u0006\u0005\t\u0006\u0005\u0006\u0006\u0005\t\u0007\u0005\u0006\r+,,#(\u001f.'+*\u0003'*\u0003\b\u0006\b\u0006\u000f\u0016\u0019\u0011\u0010\u0019\u001b\u0019\n\u001a\u0017\u001e\u0014\u000f\u0016\u001d\u0019\u000f\u000e\u001c\r\n\u0019\u000f\u0014\u0011\n\u0014\u000b\f\u0019\u0012\u0014\u001b\u0012\n\u0013\u0015\u0015\u0013\n\u000e\u000f\u0015\r\u000e\u000f\u0010\r\n\u0013\u0016\u001b\u0014\n\u000f\r\u0017\u0016\r\u0019\u0013\u0015\n\u001a\u001a\u001b\r\r\u0013\u001d\u0019\n\u0019\u000f\u0018\r\u0011\u001d\u0017\u0018\u0019\u000f\u0018\u0003!\u001f*\"'\"\u001f.#\n0\u0007\u0005\u0006 0\u0006\u0005\t \u0006\u0005\u0006 \u0006\u0005\t \u0007\u0005\u0006\n\r+,,#(\u001f.'+*\u0003'*\u0003\b\u0006\u0007\n\r+,,#(\u001f.'+*\u0003'*\u0003\b\u0006\b\u0006\u000f\u0016\u0019\u0011 \u001a\u0017\u001e\u0014\u000f\u0016\u001d\u0019\n\u000f\u000e\u001c\r\u0019\u000f\u0014\u0011\n\u0014\u000b\f\u0019\u0012\u0014\u001b\u0012\u0013\u0015\u0015\u0013\n\u000e\u000f\u0015\r\u000e\u000f\u0010\r\n\u0013\u0016\u001b\u0014\u000f\r\u0017\u0016\n\r\u0019\u0013\u0015\u001a\u001a\u001b\r\r\u0013\u001d\u0019\n\u0019\u000f\u0018\r\u0011\u001d\u0017\u0018\u000e\u000f\u0015\u0003!\u001f*\"'\"\u001f.#\r+,,#(\u001f.'+*-\u0003 #./##*\u0003(#$.\u0004\u0003\u001f*\"\u0003,'%&.\u0004(#\u001f*'*%\u0003)#\"'\u001f\nFigure 10: By-topic alignment of top 500 keywords across years between left- and right-leaning news media in 2016 (left) and\n2020 (right). Dot size is a function of overall frequency of the corresponding topic.\n(A1) (B1)\n(A2) (B2)\nFigure 11: (A) Topic and (B) keyword alignment over time during in the 2016 (A1 and B1) and the 2020 (A2 and B2) U.S.\nPresidential Election campaign. Two pairings of media have been applied: (i) between low- and high-credibility news media,and (ii) between left- and right-leaning news media.\n270\nBetween low- and high-credibility media\nTrump 2016 Clinton 2016\nrank topic r squared coef\ufb01cient constant p-value rank topic r squared coef\ufb01cient constant p-value\n1 clinton controversies 0.0818 -0.3985 0.9783 0.0004 1 clinton controversies 0.3771 -0.8581 0.9519 0.0000\n2 healthcare 0.0463 0.3867 0.9734 0.0078 2 government ops 0.3415 0.7204 0.9767 0.0000\n3 government ops 0.0348 -0.0975 0.9739 0.0215 3 healthcare 0.3292 -1.0742 0.9188 0.0000\n4 religion 0.0347 0.5750 0.9738 0.0215 4 civil rights 0.1625 1.0886 0.8809 0.0000\n5 energy 0.0187 0.8224 0.9741 0.0925 5 defence 0.0485 1.3085 0.8693 0.0064\n6 immigration 0.0136 -0.2392 0.9739 0.1532 6 foreign trade 0.0439 4.3758 0.8706 0.0096\n7 environment 0.0130 -0.5692 0.9731 0.1618 7 environment 0.0377 4.9955 0.8741 0.0165\n8 sstc 0.0126 0.1448 0.9739 0.1694 8 trump controversies 0.0297 0.6729 0.8750 0.0336\n9 intl affairs 0.0115 0.1368 0.9724 0.1891 9 economy 0.0177 0.6136 0.8706 0.1022\n10 foreign trade 0.0108 0.5925 0.9723 0.2035 10 energy 0.0077 -2.2671 0.8713 0.2826\n11 defence 0.0027 0.1100 0.9731 0.5243 11 labour 0.0063 0.8403 0.8731 0.3298\n12 trump controversies 0.0026 0.0285 0.9746 0.5341 12 sstc 0.0038 -0.2669 0.8725 0.4481\n13 economy 0.0025 0.0698 0.9729 0.5430 13 intl affairs 0.0030 0.3211 0.8734 0.5031\n14 education 0.0021 0.2084 0.9734 0.5721 14 religion 0.0028 0.6867 0.8712 0.5182\n15 civil rights 0.0007 -0.0266 0.9734 0.7446 15 education 0.0010 -0.5998 0.8709 0.6997\n16 labour 0.0003 0.0644 0.9733 0.8464 16 crime 0.0010 0.0950 0.8699 0.6969\n17 social welfare 0.0001 -0.0875 0.9734 0.9063 17 social welfare 0.0006 -0.8843 0.8714 0.7598\n18 crime 0.0000 0.0007 0.9733 0.9945 18 immigration 0.0002 0.2195 0.8722 0.8507\nTrump 2020 Biden 2020\nrank topic r squared coef\ufb01cient constant p-value rank topic r squared coef\ufb01cient constant p-value\n1 healthcare 0.4583 0.4737 0.9459 0.0000 1 biden controversies 0.4331 -1.3262 1.0412 0.0000\n2 government ops 0.2056 -0.4172 0.9039 0.0000 2 healthcare 0.1132 0.5269 0.8452 0.0000\n3 sstc 0.1400 -0.8924 0.9735 0.0000 3 sstc 0.1115 -1.5748 0.9071 0.0000\n4 intl affairs 0.0631 -0.8651 0.9339 0.0018 4 economy 0.0608 1.0088 0.8434 0.0022\n5 labour 0.0593 -2.5242 0.9155 0.0025 5 social welfare 0.0288 3.3612 0.8529 0.0367\n6 education 0.0584 1.5050 0.9247 0.0027 6 defence 0.0245 1.3161 0.8400 0.0541\n7 energy 0.0389 -2.5416 0.9152 0.0149 7 immigration 0.0152 -1.7457 0.8364 0.1303\n8 social welfare 0.0379 4.8195 0.9195 0.0162 8 energy 0.0120 0.7488 0.8432 0.1798\n9 trump controversies 0.0332 -0.2389 0.9193 0.0246 9 foreign trade 0.0107 1.3465 0.8413 0.2040\n10 immigration 0.0315 1.7172 0.9131 0.0286 10 civil rights 0.0092 0.2771 0.8371 0.2405\n11 environment 0.0266 -1.2478 0.9129 0.0446 11 environment 0.0072 -0.5412 0.8334 0.2992\n12 biden controversies 0.0221 -1.6594 0.9462 0.0676 12 crime 0.0067 -0.2425 0.8412 0.3143\n13 civil rights 0.0211 -0.2589 0.9133 0.0742 13 intl affairs 0.0034 0.2468 0.8402 0.4745\n14 foreign trade 0.0201 -3.0306 0.9143 0.0818 14 trump controversies 0.0022 0.1638 0.8371 0.5654\n15 defence 0.0107 -0.4614 0.9224 0.2055 15 education 0.0012 0.4482 0.8399 0.6753\n16 economy 0.0019 0.1600 0.9190 0.5917 16 government ops 0.0011 0.0406 0.8460 0.6850\n17 crime 0.0013 0.0634 0.9177 0.6551 17 labour 0.0005 -0.2058 0.8399 0.7870\n18 religion 0.0000 -0.1049 0.9183 0.9344 18 religion 0.0002 -0.1412 0.8390 0.8626\nBetween left- and right-leaning media\nTrump 2016 Clinton 2016\nrank topic r squared coef\ufb01cient constant p-value rank topic r squared coef\ufb01cient constant p-value\n1 trump controversies 0.3421 0.2847 0.9884 0.0000 1 clinton controversies 0.5109 -0.8366 0.9702 0.0000\n2 government ops 0.2855 -0.2427 0.9773 0.0000 2 government ops 0.4927 0.7247 0.9977 0.0000\n3 sstc 0.0922 0.3410 0.9772 0.0001 3 healthcare 0.2963 -0.8535 0.9295 0.0000\n4 clinton controversies 0.0615 -0.3001 0.9797 0.0021 4 civil rights 0.1551 0.8905 0.8996 0.0000\n5 healthcare 0.0538 0.3623 0.9760 0.0040 5 defence 0.0303 0.8668 0.8905 0.0319\n6 environment 0.0267 -0.7085 0.9757 0.0443 6 trump controversies 0.0237 0.5026 0.8945 0.0585\n7 immigration 0.0231 -0.2711 0.9766 0.0618 7 environment 0.0229 3.2566 0.8937 0.0630\n8 religion 0.0224 0.4008 0.9763 0.0660 8 foreign trade 0.0093 1.6879 0.8918 0.2368\n9 economy 0.0209 -0.1762 0.9772 0.0756 9 economy 0.0072 0.3279 0.8916 0.2983\n10 education 0.0074 -0.3383 0.9759 0.2905 10 intl affairs 0.0021 0.2250 0.8933 0.5754\n11 foreign trade 0.0047 0.3403 0.9754 0.4012 11 education 0.0012 0.5600 0.8933 0.6672\n12 labour 0.0033 0.2042 0.9758 0.4789 12 religion 0.0010 0.3518 0.8919 0.6928\n13 energy 0.0031 0.2888 0.9763 0.4982 13 social welfare 0.0009 0.8794 0.8928 0.7166\n14 civil rights 0.0022 -0.0409 0.9761 0.5634 14 immigration 0.0008 -0.3322 0.8919 0.7338\n15 crime 0.0005 -0.0260 0.9762 0.7785 15 crime 0.0002 -0.0345 0.8930 0.8660\n16 defence 0.0005 -0.0400 0.9761 0.7898 16 labour 0.0001 0.0661 0.8924 0.9272\n17 social welfare 0.0002 0.1137 0.9759 0.8604 17 energy 0.0000 0.1051 0.8923 0.9526\n18 intl affairs 0.0001 -0.0114 0.9761 0.9003 18 sstc 0.0000 -0.0246 0.8923 0.9336\nTrump 2020 Biden 2020\nrank topic r squared coef\ufb01cient constant p-value rank topic r squared coef\ufb01cient constant p-value\n1 healthcare 0.4520 0.3817 0.9539 0.0000 1 biden controversies 0.7565 -1.5721 1.0982 0.0000\n2 government ops 0.2913 -0.4029 0.9178 0.0000 2 sstc 0.1202 -1.4664 0.9219 0.0000\n3 sstc 0.2464 -0.9607 0.9911 0.0000 3 healthcare 0.1155 0.4772 0.8642 0.0000\n4 education 0.1291 1.8162 0.9395 0.0000 4 foreign trade 0.0656 2.9863 0.8640 0.0014\n5 social welfare 0.0806 5.7017 0.9332 0.0004 5 social welfare 0.0512 4.0195 0.8752 0.0051\n6 labour 0.0713 -2.2454 0.9293 0.0009 6 government ops 0.0315 0.1947 0.8931 0.0286\n7 immigration 0.0548 1.8365 0.9261 0.0037 7 economy 0.0224 0.5495 0.8608 0.0656\n8 foreign trade 0.0403 -3.4842 0.9272 0.0132 8 defence 0.0201 1.0680 0.8593 0.0817\n9 energy 0.0353 -1.9664 0.9293 0.0204 9 immigration 0.0156 -1.5855 0.8561 0.1255\n10 intl affairs 0.0338 -0.5139 0.9409 0.0233 10 crime 0.0079 -0.2360 0.8606 0.2747\n11 environment 0.0244 -0.9693 0.9275 0.0547 11 energy 0.0074 0.5273 0.8614 0.2928\n12 civil rights 0.0232 -0.2202 0.9275 0.0611 12 civil rights 0.0071 0.2192 0.8570 0.3008\n13 economy 0.0227 0.4459 0.9340 0.0640 13 religion 0.0039 0.5572 0.8571 0.4460\n14 biden controversies 0.0168 -1.1736 0.9514 0.1116 14 environment 0.0034 -0.3347 0.8549 0.4745\n15 trump controversies 0.0092 -0.1019 0.9320 0.2405 15 labour 0.0025 0.4178 0.8558 0.5407\n16 crime 0.0003 -0.0262 0.9317 0.8198 16 intl affairs 0.0016 0.1527 0.8592 0.6218\n17 religion 0.0002 0.1607 0.9311 0.8765 17 trump controversies 0.0006 0.0763 0.8575 0.7653\n18 defence 0.0001 0.0442 0.9311 0.8814 18 education 0.0001 0.1030 0.8585 0.9146\nTable 2: Summary table of OLS results to model temporal alignment between low- and high-credibility media (top), and\nbetween left- and right-leaning media (bottom). The dependent variable is the time series of temporal alignment (Pearson\u2019sR) in the overall topic distribution between low- and high-credibility media, or between left- and right-leaning media; theindependent variable is the time series of the temporal difference in the proportional attention devoted to a certain topic (high-credibility subtracted by low-credibility, or right-leaning subtracted by left-leaning).\n271\nFigure 12: Granger causality between low- and high-credibility media (the left four columns) and between left- and right-leaning\nmedia (the right four columns). The cell values are the number of times a given type of IAS relationship appears signi\ufb01cantout of 200 bootstrapping runs (sampling 80% of the data). Types of IAS relationship (along the X-axis) are displayed inabbreviations: HC means led by high-credibility media; LC means led by low-credibility media; LF means led by left-leaningmedia; RT means led by right-leaning media; MT means we found signi\ufb01cant results (i.e., mutual interaction) in both directions;NA means we found no signi\ufb01cant results in either direction. Signi\ufb01cance threshold for p-value is 0.05. We include results forthe top 10 topics (in descending order) that show frequently in all news headlines for a given year.\n272\n\u000f\u0010\u0011\u000e\u0010\u000e\u0019\u0018\u0014\u0018\u001d\u0016\u001c\u001c\u001d\u000e\u0013\u0016\u001d\u0013\u000e\u001b\u0014\u0017\u000e\u0014\u001f\u001b\u001d\u001b\u001e\u000e\u000e\u0016\u0014\u000e\u0012\u001f\u0019\u001a\u001d25.1\n\u0007\u0005\u0006\b\u0004\u0005\t \u0007\u0005\u0006\b\u0004\u0005\n \u0007\u0005\u0006\b\u0004\u0005\u000b \u0007\u0005\u0006\b\u0004\u0006\u0005 \u0007\u0005\u0006\b\u0004\u0006\u0006 \u0007\u0005\u0006\b\u0004\u0006\u0007\u000f\u0010\u0011\u000e\u0010\u000e\u0019\u0018\u0014\u0018\u001d\u0016\u001c\u001c\u001d\u000e\u0013\u0016\u001d\u0013\u000e\u001b\u0014\u0017\u000e\u0014\u001f\u001b\u001d\u001b\u001e\u000e\u000e\u0016\u0014\u000e\u0012\u001f\u0019\u001a\u000e-+/40/\u001c#/&'23\u0003\u0010/&023'3\u0003\u000e-+/40/\n\u001a'/%'\u0003\u000e*03'/\u0003#3\u0003\u001b'1\u0003\u001f\u001a\u0003\u00180.+/''\n\u001b'15$-+%#/\u0003\u000e0/6'/4+0/\n\u0015#+/'\u0003\u000e*03'/\u0003#3\u0003\u000f'.\u0003\u001f\u001a\u0003\u00180.+/''\n +,+-'#,3\u0003\u001c#/&'23\u0003\u0010.#+-3\n\u000f'.0%2#4+%\u0003\u000e0/6'/4+0/\n\u001d25.1\u0003\f3,3\u0003\u001b533+#\u000340\u0003\u0013#%,\u0003\u0010.#+-3\n\u000e-+/40/\u0003\u0012'43\u0003\u001a/'5.0/+#\u0003#/&\u0003\u0011#+/43\n\r#3,'4\u00030(\u0003\u000f'1-02#$-'3\u0003\u000e0..'/4\n\u0011+234\u0003\u000f'$#4'\n\u001f\u001a\u0003\u000f'$#4'\n\f%%'33\u0003\u00130--8700&\u0003\u001d#1'3\n +,+-'#,3\u0003\u001a0&'34#\u0003\u0010.#+-3\n\u001c'%0/&\u0003\u000f'$#4'\n\u001d*+2&\u0003\u000f'$#4'\n\u000e0.'8\u0003\u0016'44'2\n\u0010-'%4+0/\u0003\u000f#8\n-'&\u0003$8\u0003-'(4\n-'&\u0003$8\u00032+)*4\n.545#-\u0003+/4'2#%4+0/\n/0\u00032'-#4+0/3*+1\n!34#24\"\u00030(\u00034*'\u0003\u000b\u0005\u0004&#8\u00037+/&07\n!+/4'26#-\"\u00030(\u00034*'\u0003\u000b\u0005\u0004&#8\u00037+/&07\n\u0010\u0011\u0012\u000f\u0011\u000f\u001b\u001a\u0015\u001a\u001f\u0018\u001e\u001e\u001f\u000f\u000f\u0015!\u001d\u001f\u001d \u000f\u000e\u0015\u0010\u000f\u000f\u001d\u0015\u0019\u0014\u0018\u001f\u0014\u0013!\u001b\u001c\u001f4703\n\t\u0007\t\u0007\u0006\u0007\n \t\u0007\t\u0007\u0006\u0007\u000b \t\u0007\t\u0007\u0006\u0007\f \t\u0007\t\u0007\u0006\b\u0007 \t\u0007\t\u0007\u0006\b\b \t\u0007\t\u0007\u0006\b\t\u0010\u0011\u0012\u000f\u0011\u000f\u001b\u001a\u0015\u001a\u001f\u0018\u001e\u001e\u001f\u000f\u000f\u0015!\u001d\u001f\u001d \u000f\u000e\u0015\u0010\u000f\u000f\u001d\u0015\u0019\u0014\u0018\u001f\u0014\u0013!\u001b\u001c\u000e-()1\u0012)()4%/\u0003\u001b**-')45\u0003\u001c2/-')\u0003 \u001e\u0003\u000f-6-)5\n\u0014%44-5\u0003\u000f,25)1\u0003%5\u0003\u0010)0\u0003!\u001c\u0003\u001a20-1))\n\u0010)02'4%6-'\u0003\u000f218)16-21\n\u0016%'2&\u0003\u000e/%.)\u0003\u001e,26\u0003-1\u0003\u0017)125,%\n\u001d)37&/-'%1\u0003\u000f218)16-21\n\u0017;/)\u0003\u001d-66)1,275)\u0003\u001e,2265\u0003\u001c426)56)45\n\u001f4703\u0003!-5-65\u0003\u0017)125,%\n\"22(9%4(\u0003\u001516)48-)9\n\u001d\u000e\u0013\u0003\u0010-)(\n\u000f21);\u0003\u000e%44)66\u0003\u001a20-1%6)(\n\u001f4703\u0003\u001f%:\u0003\u001d)67415\u0003\u001d)/)%5)(\n\u0012-456\u0003\u0010)&%6)\n\u001f4703\u0003\u0013)65\u0003\u000f\u001b!\u0015\u0010\n\u001f4703\u0003\u001d)67415\u000362\u0003\",-6)\u0003\u0014275)\n!\u001c\u0003\u0010)&%6)\n\u0014716)4\u0003\u000e-()1\u0003\u0018%3623\u0003\u001e624;\n\u000f%1(-(%6)\u0003\u001f291,%//5\u0003\u0004\u001d)3/%')(\u0003\t1(\u0003\u0010)&%6)\u0005\n\u0012-1%/\u0003\u0010)&%6)\n\u000f21);\u0003\u000e%44)66\u0003\r33428)(\n\u0011/)'6-21\u0003\u0010%;\n/)(\u0003&;\u0003/)*6\n/)(\u0003&;\u00034-+,6\n0767%/\u0003-16)4%'6-21\n12\u00034)/%6-215,-3\n#56%46$\u00032*\u00036,)\u0003\f\u0007\u0006(%;\u00039-1(29\n#-16)48%/$\u00032*\u00036,)\u0003\f\u0007\u0006(%;\u00039-1(29\nFigure 13: Granger causality results between low- and high-credibility media for 2016 (the \ufb01rst and second \ufb01gures) and 2020\n(the third and fourth \ufb01gures). We test Granger causalities in a sliding window of 90 days and display robust results that appearin more than 95% of the bootstrapping runs. Each plus sign marks the starting point of the 90-day sliding window with asigni\ufb01cant result. We include results for the top 10 topics that show frequently in all news headlines for a given year.\n273\nID Topic Fullname Topic Abbr. Topic Description (guidance, or a few example sub-categories for each topic)\n1 trump controversies TRUC / REPC controversial topics related to Trump, such as family or personal scandal, health condition speculations and disputable remarks\n2 clinton controversies CLIC / DEMC controversial topics related to Hillary, such as family or personal scandal, health condition speculations and disputable remarks\n3 biden controversies BIDC / DEMC controversial topics related to Biden, such as family or personal scandal, health condition speculations and disputable remarks\n5 agriculture AGRI agriculture policy, trade & marketing; farmers; \ufb01sheries & \ufb01shing; animal & crop disease\n6 civil rights CIVR racial equality; gender equality; voting rights; freedom of speech; gun rights; right to privacy; age discrimination; anti-government activities\n7 crime CRIM law enforcement agencies; crimes & crime control; police; prisons; court administration; child abuse & family issues\n8 culture CLTR cultural policy; culture & entertainment\n9 defence DEFC defence alliance & agreement; military intelligence; nuclear arms; military aid; military procurement; domestic security responses; foreign military operations\n10 economy ECON banking; small businesses; disaster relief; tax policies; consumer \ufb01nance; insurance regulation; bankruptcy; corporate management; securities & commodities\n11 education EDUC education policy; elementary & primary schools; vocational education; higher education, student loans; education of underprivileged students\n13 energy ENRG energy policy; nuclear; electricity; natural gas & oil; coal; alternative & renewable; conservation & ef\ufb01ciency; research & development\n14 environment ENVR environmental policy; drinking water; waste disposal; hazardous waste; air pollution; recycling; species & forest; land and water conservation\n15 foreign trade FRTR trade agreements; exports; private investments; tariff & imports; exchange rates; competitiveness; trade policy\n16 government operation GVOP general governmental operations; intergovernmental relations; bureaucracy; census & statistics; postal service; procurement & contractors\n17 healthcare HLTH public health and candidates\u2019 health conditions; coronavirus spread & control; healthcare reform; insurance; medical facilities; disease prevention; healthcare research & development\n18 housing HOUS community development; urban development; rural housing; low-income assistance; housing for veteran, the elderly & the homeless\n19 immigration IMMI immigration issues & policies; refugees; citizenship\n20 international affairs INTL international affairs & foreign aid; resources exploitation; developing countries; international \ufb01nance; human rights issues; terrorism; international organizations\n21 labor LABR labour, employment & pensions; employee bene\ufb01ts; labor unions; fair labor standards; worker safety; employment training; youth employment\n22 religion RELG general religious issues; religous groups; church activities; religious freedom\n23 social welfare SOWL social welfare policy; low-income/elderly/disabled assistance; volunteer associations; child care\n24 space, science, technology, & communications SSTC issues related to general space, science, technology & communications: mass/social media presence, space programs, telecommunication regulation\n25 transportation TRSP mass transportation construction; highways, air & railroad travel; maritime transportation; infrastructure\nTable 3: List of topics in our dictionary. \u201cCandidate controversies\u201d shows up in their corresponding election year (e.g., Biden controversies only show up in 2020).\n274\nModel variant Headline Survey Tweets Average across three sources\nyear keywords \ufb01ltering/weighting # of topics per text model-human human-human diff. model-human human-human diff. model-human human-human diff. model-human human-human diff.\n2016 strongly only primary only 0.4881 0.5653 -0.0771 0.5661 0.6311 -0.0650 0.3564 0.4591 -0.1028 0.4702 0.5519 -0.0816\n2016 strongly + weakly (equal weights) primary only 0.4566 0.5689 -0.1123 0.5537 0.6287 -0.0751 0.3068 0.4677 -0.1609 0.4390 0.5551 -0.1161\n2016 strongly + weakly (different weights) primary only 0.4876 0.5680 -0.0804 0.5419 0.6269 -0.0850 0.3118 0.4697 -0.1579 0.4471 0.5549 -0.1077\n2016 strongly only primary + secondary 0.2116 0.5993 -0.3877 0.3056 0.6337 -0.3282 0.2197 0.5026 -0.2829 0.2456 0.5785 -0.3329\n2016 strongly + weakly (equal weights) primary + secondary 0.1956 0.6015 -0.4059 0.2768 0.6331 -0.3563 0.1627 0.5021 -0.3394 0.2117 0.5789 -0.3672\n2016 strongly + weakly (different weights) primary + secondary 0.1989 0.6002 -0.4014 0.2739 0.6346 -0.3607 0.1646 0.5019 -0.3374 0.2124 0.5789 -0.3665\n2016 strongly only all included 0.2018 0.6619 -0.4601 0.3096 0.7023 -0.3927 0.2239 0.5914 -0.3675 0.2451 0.6519 -0.4068\n2016 strongly + weakly (equal weights) all included 0.1834 0.6646 -0.4813 0.2751 0.7036 -0.4285 0.1683 0.5896 -0.4213 0.2089 0.6526 -0.4437\n2016 strongly + weakly (different weights) all included 0.1846 0.6641 -0.4794 0.2748 0.7032 -0.4283 0.1679 0.5914 -0.4234 0.2091 0.6529 -0.4437\n2020 strongly only primary only 0.4570 0.5149 -0.0580 0.5426 0.6021 -0.0595 0.3725 0.4700 -0.0975 0.4573 0.5290 -0.0717\n2020 strongly + weakly (equal weights) primary only 0.4533 0.5116 -0.0583 0.5467 0.6015 -0.0549 0.3628 0.4704 -0.1077 0.4542 0.5279 -0.0736\n2020 strongly + weakly (different weights) primary only 0.4649 0.5133 -0.0484 0.5572 0.6039 -0.0467 0.3652 0.4716 -0.1065 0.4624 0.5296 -0.0672\n2020 strongly only primary + secondary 0.2252 0.5232 -0.2980 0.2650 0.6308 -0.3658 0.2226 0.4965 -0.2739 0.2376 0.5502 -0.3126\n2020 strongly + weakly (equal weights) primary + secondary 0.2105 0.5252 -0.3147 0.2457 0.6267 -0.3811 0.2024 0.4928 -0.2904 0.2195 0.5482 -0.3287\n2020 strongly + weakly (different weights) primary + secondary 0.2174 0.5272 -0.3099 0.2472 0.6263 -0.3791 0.1996 0.4944 -0.2948 0.2214 0.5493 -0.3279\n2020 strongly only all included 0.2272 0.6337 -0.4065 0.2657 0.6933 -0.4276 0.2235 0.5878 -0.3643 0.2388 0.6383 -0.3995\n2020 strongly + weakly (equal weights) all included 0.2198 0.6357 -0.4159 0.2407 0.6948 -0.4541 0.1899 0.5898 -0.3999 0.2168 0.6401 -0.4233\n2020 strongly + weakly (different weights) all included 0.2202 0.6339 -0.4137 0.2391 0.6944 -0.4552 0.1905 0.5891 -0.3986 0.2166 0.6391 -0.4225\nTable 4: Complete agreement scores for model-human and human-human comparisons.\n275", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Intermedia Agenda Setting during the 2016 and 2020 US Presidential Elections", "author": ["Y Chen", "Y Liu", "L Singh", "C Budak"], "pub_year": "2024", "venue": "\u2026 AAAI Conference on Web and Social \u2026", "abstract": "Intermedia agenda setting (IAS) theory suggests that different news sources can influence  each other's agenda. While this theory has been well-established in existing literature,"}, "filled": false, "gsrank": 312, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/31312", "author_id": ["QGVoI8wAAAAJ", "", "", "wIhJS60AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:kSLKYGtykOwJ:scholar.google.com/&output=cite&scirp=311&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=kSLKYGtykOwJ&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:kSLKYGtykOwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/31312/33472"}}, {"title": "Social chemistry 101: Learning to reason about social and moral norms", "year": "2020", "pdf_data": "SOCIAL CHEMISTRY 101:\nLearning to Reason about Social and Moral Norms\nMaxwell ForbesyzJena D. HwangzVered ShwartzyzMaarten SapyYejin Choiyz\nyPaul G. Allen School of Computer Science & Engineering, University of Washington\nzAllen Institute for AI\nfmbforbes,msap,yejin g@cs.washington.edu, fjenah,veredsg@allenai.org\nmaxwellforbes.com/social-chemistry\nAbstract\nSocial norms\u2014the unspoken commonsense\nrules about acceptable social behavior\u2014are\ncrucial in understanding the underlying causes\nand intents of people\u2019s actions in narratives.\nFor example, underlying an action such as\n\u201cwanting to call cops on my neighbor\u201d are so-\ncial norms that inform our conduct, such as \u201cIt\nis expected that you report crimes. \u201d\nWe present S OCIAL CHEMISTRY , a new con-\nceptual formalism to study people\u2019s everyday\nsocial norms and moral judgments over a rich\nspectrum of real life situations described in nat-\nural language. We introduce S OCIAL -CHEM -\n101, a large-scale corpus that catalogs 292k\nrules-of-thumb such as \u201cIt is rude to run\na blender at 5am\u201d as the basic conceptual\nunits. Each rule-of-thumb is further broken\ndown with 12 different dimensions of people\u2019s\njudgments, including social judgments of good\nand bad, moral foundations, expected cultural\npressure, and assumed legality, which together\namount to over 4.5 million annotations of cat-\negorical labels and free-text descriptions.\nComprehensive empirical results based on\nstate-of-the-art neural models demonstrate that\ncomputational modeling of social norms is\na promising research direction. Our model\nframework, N EURAL NORM TRANSFORMER ,\nlearns and generalizes S OCIAL -CHEM -101 to\nsuccessfully reason about previously unseen\nsituations, generating relevant (and potentially\nnovel) attribute-aware social rules-of-thumb.\n1 Introduction\nUnderstanding and reasoning about social situ-\nations relies on unspoken commonsense rules\nabout social norms , i.e., acceptable social behav-\nior (Haidt, 2012). For example, when faced with\nsituations like \u201c wanting to call the cops on my\nneighbors ,\u201d (Figure 1), we perform a rich variety\nof reasoning about about legality, cultural pressure,\nCultural Pressurecalling the cops on your neighborsnot being friends with your neighborstrying to make everyone comfortable in your home\n\u2026 wanting to call the cops on my neighbors \u2026\nreporting neighbors that are breaking minor lawscalling the cops on a stranger disturbing your neighborsAnticipated Agreement\ncalling the cops if someone is committing a crime\nLegalitystealing things from your neighborsmaking trouble in your neighborhoodletting the authorities know when you are in danger\ncalling the authorities if your neighbor is being rudecalling the cops when you see a crimehaving an open and honest dialogue with your neighbors.Social Judgment\nCONTROVERSIAL\nCOMMONUNIVERSALPRESSURE FORDISCRETIONARYPRESSURE AGAINST\nLEGALGOODEXPECTEDBAD\nTOLERATEDILLEGALAgency\nMoral FoundationFigure 1: This \ufb01gure illustrates an intuitive subset of\nour formalism to reason about social norms in lan-\nguage. Our approach centers around Rules-of-Thumb\n(RoTs; text in colored tubes), which describe social ex-\npectations given a situation (text in the center hexagon).\nRather than prescribing what is right or wrong, RoTs re-\nveal ethical judgments about social propriety from vary-\ning perspectives.1Structured categorical (in smaller\nhexagons; e.g., \u201csocial judgment\u201d and \u201ccultural pres-\nsure\u201c) annotations provide richer understanding. All\nRoTs shown here in tubes are generated by our N EU-\nRAL NORM TRANSFORMER conditioning on the cen-\nter situation and the categorical types.\nand even morality of the situation (here, \u201c report-\ning a crime \u201d and \u201c being friends with your neigh-\nbor\u201d are con\ufb02icting norms). Failure to account\n1Note that the social identities of the participants of sit-\nuations would further inform which social norms are mostarXiv:2011.00620v3  [cs.CL]  16 Aug 2021\nMultiple charactersDifferent perspectivesRich structureIt\u2019s not right to tell another person who to spend time with.Narrator:  asking  my boyfriend   to stop being friends with his exYou should make sure your SO doesn\u2019t feel like a lower priority than your ex.Narrator:  asking  my boyfriend   to stop being friends with his exYou should make sure your SO doesn\u2019t feel like a lower priority than your ex.Narrator:  asking my boyfriend to stop being friends with his exLEGALITYIt\u2019s not right to tell another person who to spend time with.\nbadIt's okay to ask your signi\ufb01cant other to stop doing something you're uncomfortable with.\nexpected/OK\ngood\nlegal\nloyalty/betrayal\ncare/harm\nstrongCULTURAL PRESSURE\ncommonANTICIPATEDAGREEMENTSOCIALJUDGMENTMORALFOUNDATIONSPERFORMINGACTION\nprobably not(b)(c)(a)Figure 2: Three different slices of a complete annotation for a single situation, meant to illustrate our approach.\nEach RoT (text in colored boxes, e.g., \u201cIt\u2019s not right to tell...\u201d) is written for a particular real life situation (text\nin pale grey boxes, e.g., \u201casking my boyfriend to stop being ...\u201d) and a speci\ufb01c person in that situation (\u201cnarrator\u201d\nvs \u201cmy boyfriend\u201d). (a)A situation often includes multiple people with distinct perspectives, evoking different\n(and possibly con\ufb02icting) RoTs. (b)Even a single person may have multiple, con\ufb02icting RoTs\u2014key ingredients\nfor moral dilemmas. (c)Each RoT is further broken down with categorical and free text annotations (shown in\ntiny colored buttons. e.g., \u201cstrong\u201d for cultural pressure ). The full de\ufb01nition of the low-level RoT attributes are in\nFigure 4.\nfor social norms could signi\ufb01cantly hinder AI sys-\ntems\u2019 ability to interact with humans (Pereira et al.,\n2016).\nIn this paper, we introduce SOCIAL CHEMISTRY\nas a new formalism to study people\u2019s social and\nmoral norms over everyday real life situations. Our\napproach based on crowdsourced descriptions of\nnorms is inspired in part by studies in descriptive\norapplied ethics (Hare, 1981; Kohlberg, 1976),\nwhich takes a bottom-up approach by asking peo-\nple\u2019s judgements on various ethical situations. This\nis in contrast to the top-down approach taken by\nnormative orprescriptive ethics to prescribe the\nkey elements of ethical judgements. The underly-\ning motivation of our study is that we, the NLP\n\ufb01eld, might have a real chance to contribute to\nthe studies of computational social norms and de-\nscriptive ethics through large-scale crowdsourced\nannotation efforts combined with state-of-the-art\nneural language models.\nTo that end, we organize descriptive norms via\nfree-text rules-of-thumb (RoTs) as the basic con-\nceptual units.\nRule-of-Thumb (RoT) \u2014 A descriptive cultural\nnorm structured as the judgment of an action . For\nexample, \u201cIt\u2019s rude to run the blender at 5am . \u201d\nEach RoT is further broken down with 12\ntheoretically-motivated dimensions of people\u2019s\njudgments such as social judgments of good and\nbad, theoretical categories of moral foundations,\nrelevant. For example, if the neighbors are African Ameri-\ncan, it might be worse to call the cops due to racial pro\ufb01ling\n(Eberhardt, 2020).expected cultural pressure, and assumed legality.\nAll together, these annotations comprise SOCIAL -\nCHEM -101 , a new type of NLP resource that cata-\nlogs 292k RoTs over 104k real life situations, along\nwith 365k sets of structural annotations, which\nbreak each RoT into 12 dimensions of norm at-\ntributes. Together, this amounts to over 4.5M cate-\ngorical and free-text annotations.\nWe investigate how state-of-the-art neural lan-\nguage models can learn and generalize out of\nSOCIAL -CHEM -101 to accurately reason about\nsocial norms with respect to a previously unseen\nsituation. We term this modeling framework NEU-\nRAL NORM TRANSFORMER , and \ufb01nd it is able\nto generate relevant (and potentially novel) rules-\nof-thumb conditioned on all attribute dimensions.\nEven so, this breadth of this task proves challeng-\ning to current neural models, with humans rating\nmodel\u2019s adherence to different attributes from 0.28\nto 0.91 micro-F1.\nIn addition, we showcase a potential practical\nuse case of computational social norms by analyz-\ning political news headlines through the lens of\nour framework. We \ufb01nd that our empirical results\nalign with the Moral Foundation Theory of Graham\net al. (2009); Haidt (2012) on how the moral norms\nof different communities vary depending on their\npolitical leanings and news reliability. Our empir-\nical studies demonstrate that computational mod-\neling of social norms is a feasible and promising\nresearch direction that warrants further investiga-\ntion. SOCIAL -CHEM -101 provides a new resource\nto teach AI models to learn people\u2019s norms, as well\nas to support novel interdisciplinary research across\nNLP, computational norms, and descriptive ethics.\n2 Approach\nThe study of social norms have roots in descrip-\ntive ethics and moral psychology. They tell us that\nsocial norms are culturally-sensitive standards of\nappropriate conduct. Alongside explicit laws and\nregulations that govern our society, social norms\nperform the role of providing guidelines on so-\ncially appropriate behaviors (Elster, 2006; Bow-\ndery, 1941; Kohlberg, 1976) and are responsible\nfor setting implicit expectations of what is socially\nright or wrong (Malle et al., 2014; Haidt, 2012;\nHare, 1981). They in\ufb02uence a wide-range of social\nfunctions such as preserving biological needs to\nsurvival (e.g., refraining from harming or killing),\nmaintaining social civility and order (e.g., maintain-\ning politeness, recognizing personal space), and\nproviding identity and belonging to a community\n(e.g., respecting the elderly). In turn, these social\nnorms in\ufb02uence how we judge, communicate, and\ninteract with each other.\nRoTs Our aim is then to forefront these implicit\nexpectations about social norms via RoTs. We\nformalize the de\ufb01nition of RoTs as situationally-\nrelevant evaluative judgments of social norm, and\nposit that for any given situation , one or more\nRoTs will be evoked in the minds of the interpreter.\nConsider the following situation and its RoT.\nPunching someone.\nRoT: It is unacceptable to injure a person.\nMost readers can instantly recognize the situation\nis in violation of an unspoken social rule: \u201cDo\nnot injure others. \u201d This rule is responsible for the\nseries of natural questions that probe at the moral-\nity of the action, like \u201cwhy did the narrator punch\nsomeone?\u201d \u201cwas the action justi\ufb01ed?\u201d and \u201cdo I\nwant to sympathize with the narrator?\u201d The role\nof the RoT is to identify the unspoken rule in the\nsituation by specifying the behavior or action (\u201cin-\njuring a person\u201d) and its acceptability judgment\n(\u201cit is unacceptable\u201d). More complex situations can\nbe associated with multiple RoTs, as seen in the\nexample below:\nPunching a friend who stole from me.\nRoT 1: It is unacceptable to injure a person.\nRoT 2: People should not steal from others.\nRoT 3: It is bad to betray a friend.\nRoT 4: It is OK to want to take revenge.\nThe RoTs represent a variety of social norms that\nelaborate on various perspectives available in the\nrocstoriesr/AITADA92k30k32k12k30k87k77k35k87k151kRoTs with structured annotations285k (98%)\n137k76k53k21k52k40k112k91k59kAnticipated agreement (RoT)\nRoT targetingAgencyYesNo252k151k18k123k74k112k236k51k33k\nLegalityCultural pressureHypotheticalNarratorUnclear\nAnother character\nLegalAction explicitly happensRules of Thumb (RoTs)\nSocial judgmentAnticipated agreement (action judgment)Expected / OKr/confessions\nExplicity not, probably not, hypothetically, probably happens12kStrong against (28k)Strong for (21k)Illegal (5k), tolerated (12k)Almost no one (1k), Occasional (5k), Controversial (36k)Common beliefUniversalVery bad (13k)BadGoodVery good (4k)UniversalCommon beliefAlmost no one (1k), Occasional (5k), Controversial (41k)\nNo one\nAgainstDiscretionaryForSituations:\nAdditional Structured Annotations5 per RoT for 8k RoTs (using 2k RoTs / domain)50 per RoT for 400 RoTs (using 100 RoTs / domain)40k20kRoT category (non-mutually-exclusive)Moral foundations (non-mutually-exclusive)Care/Harm (128k)Fairness/Cheating (48k)Loyalty/Betrayal (52k)Sanctity/Degradation (20k)Authority/Subversion (28k)Morality/Ethics (81k)Social Norms (105k)Advice (100k)\u201cIt is what it is\u201d (58k)Figure 3: S OCIAL -CHEM -101 Dataset statistics. Bars\nare drawn to scale. Individual values for all of the dif-\nferent attributes are also given in Figure 4.\nsituation: RoTs about stealing (RoT 1) vs. punch-\ning (RoT 2), RoTs targeting the different charac-\nters in the situation (RoTs 1, 4 target the narra-\ntor; RoTs 2, 3 target narrator\u2019s friend), and RoTs\nthat elaborate on additional social interpretation\nimplicit in the situation (RoT 3: theft from a friend\nis cast as an act of betrayal). Effectively, RoTs rep-\nresent evaluative judgments about a social situation\nin light of unspoken but accepted social norms.2\nFigure 2 shows three subsets of a situation\u2019s anno-\ntation to illustrate the perspectives RoTs capture.\nCultural Scope of this study We recognize that\nsocial norms are often culturally sensitive (Haidt\net al., 1993; Kagan, 1984) and judgments of moral-\nity and ethics concerning individuality, commu-\nnity and society do not always hold universally\n(Shweder, 1990). While some situations (e.g.,\n2Our de\ufb01nition of RoTs corresponds to the \ufb01rst of the two\nevaluative moral judgments de\ufb01ned in Malle et al. (2014).\n\u201cpunching someone\u201d) might have similar levels\nof acceptability across a number of cultures, oth-\ners might have drastically varied levels depend-\ning on the culture of its participants (e.g., \u201ckiss-\ning someone on the cheek as a greeting\u201d). As\na starting point, our study focuses on the socio-\nnormative judgments of English-speaking cultures\nrepresented within North America. While we \ufb01nd\nsome variation of judgments in our annotations\n(e.g., with respect to certain worker characteristics,\nsee \u00a7A.6), extending this formalism to other coun-\ntries and non-English speaking cultures remains a\ncompelling area of future research.\n3 S OCIAL -CHEM -101 Dataset\nWe obtained 104k source situations from 4 text\ndomains ( \u00a73.1), for which we elicited 292k RoTs\nfrom crowd workers ( \u00a73.2). We then de\ufb01ne a struc-\ntured annotation task where workers isolate the\ncentral action described by the RoT and provide a\nseries of judgments about the RoT and the action\n(\u00a73.3). In total, we collect 365k structured annota-\ntions, performing multiple annotations per RoT for\na subset of the RoTs to study the variance in anno-\ntations. Figure 3 illustrates our dataset statistics.\n3.1 Situations\nWe use a situation to denote the one-sentence\nprompt given to a worker as the basis for writ-\ning RoTs. We gather a total of 104k real life\nsituations from four domains: scraped titles of\nposts in the subreddits r/confessions (32k)\nandr/amitheasshole (r/AITA , 30k), which\nlargely focus on moral quandaries and interper-\nsonal con\ufb02icts; 30k sentences from the ROCSto-\nries corpus ( rocstories , Mostafazadeh et al.,\n2016); and scraped titles from the Dear Abby ad-\nvice column archives3(dearabby , 12k).4\n3.2 Rules-of-Thumb (RoTs)\nTo collect RoTs, we provide workers with a situ-\nation as a prompt and them to write 1 \u2013 5 RoTs\ninspired by that situation. From the 104k situations,\nwe elicit a total of 292k RoTs. Despite RoTs av-\neraging just 10 words, we observe that 260k/292k\nRoTs are unique across the dataset.\nFor the development of RoTs, we instruct the\nworkers to produce RoTs that explain the basics\n3https://www.uexpress.com/dearabby/archives\n4See Appendix A.1 for further data preprocessing details.\nROT BREAKDOWN\nSITUATIONNarrator:  Not wanting to be around  my GF  when she\u2019s sickIt's kind to sacri\ufb01ce your well-being to take care of a sick person.\nMorality /EthicsROT\nACTION BREAKDOWNROT CATEGORIZATIONMORAL FOUNDATIONSSocial NormsAdviceIt is what it is\nCare / HarmFairness /CheatingLoyalty /BetrayalAuthority /SubversionSanctity /Degradation\n< 1%~5% \u2013 25%~ 50%~ 75% \u2013 90%> 99%ANTICIPATED AGREEMENT (ROT)\nROT TARGETING\nnarratormy GFno one listedsacri\ufb01cing your well-being to take care of a sick personACTIONit\u2019s kindORIGINAL JUDGMENTAGENCY\nAgencyExperienceSOCIAL JUDGMENT\nVery badBadExpected / OKGoodVery good\n< 1%~5% \u2013 25%~ 50%~ 75% \u2013 90%> 99%ANTICIPATED AGREEMENT (SOCIAL JUDGMENT)\nIllegalToleratedLegalLEGALITY\nStrong pressureagainstPressureagainstDiscretionaryPressure forStrongpressure forCULTURAL PRESSURE\nProbably notExplicitly notHypotheticalProbableExplicitTAKING ACTIONACTION CANDIDATE\nnarratormy GFno one listed\nATTRIBUTE KEYGrounded\nSocialFigure 4: All attribute values for structured RoT anno-\ntations, with one complete example annotation \ufb01lled in.\nof social norms , just as one would instruct a \ufb01ve-\nyear-old child on the ABCs of acceptable conduct.\nRoTs are to be:\n1.inspired by the situation , to maintain a lower\nbound on relevance;\n2.self-contained , to be understandable without\nadditional explanation; and\n3.structured as judgment of acceptability (e.g.,\ngood/bad, (un)acceptable, okay) and an ac-\ntion that is assessed.\nIn order to encourage RoT diversity, we also\nask that an RoT should counterbalance vagueness\nagainst speci\ufb01city so that RoTs generalize across\nmultiple situations (e.g., \u201cIt is rude be sel\ufb01sh. \u201d )\nwithout being too speci\ufb01c (e.g., \u201cIt is rude not\nto share your mac\u2019n\u2019cheese with your younger\nbrother. \u201d ). We also ask workers to write RoTs il-\nlustrating distinct ideas andavoid trivial inversions\n\u201cminors smoking\u201d\n\u201cbeing excited about a new job\u201d\n\u201capologizing to others for something you did\u201d\n\u201cserving customers after close\u201d\n\u201cgiving ultimatums\u201d\n\u201cliving with your partner if you aren\u2019t married\u201d\n\u201cworking hard at your job\u201d\nFigure 5: Plotting the distribution of RoTs in S OCIAL -CHEM -101 along axes of moral judgment, agreement,\ncultural pressure, andlegality. Left: Moral judgment is scaled with agreement (how commonly held the belief is)\nand plotted against cultural pressure. Illegal activities fall in the bottom left: actions that are universally understood\nto be wrong and people feel negative cultural pressure for. Right: Moral judgment is plotted against agreement.\nDiscretionary actions span a range of moral values (yellow ranging horizontally) and fringe beliefs often evoke\nstrong negative cultural pressure even when morally neutral (bottom of plot).\nto prevent low-information RoTs that rephrase the\nsame idea or simply invert the judgement and ac-\ntion.\nCharacter Identi\ufb01cation. We ask workers to\nidentify phrases in each situation that refer to peo-\nple. For example, in a situation, like \u201cMy brother\nchased after the Uber driver , \u201dworkers mark the\nunderlined spans. We collect three workers\u2019 spans,\ncalling each span a character . All characters iden-\nti\ufb01ed become candidates for grounding RoTs and\nactions in the structured annotation. As such, we\noptimize for recall instead of precision by using the\nlargest set of characters identi\ufb01ed by any worker.\nWe also include a narrator character by default.\n3.3 RoT Breakdowns\nWe perform a structured annotation, which we term\nabreakdown , on each RoT. In an RoT breakdown,\na worker isolates the underlying action contained\nin the RoT. Then, they assign a series of categorical\nattributes to both the RoT and the action. These cat-\negorical annotations allow for additional analyses\nand experiments relative to the text-only RoTs.\nThe attributes fall into two categories corre-\nsponding to the central annotation goals. The \ufb01rst\ngoal is to tightly ground RoTs to their respective\nsituations. The second goal is to partition social ex-\npectations using theoretically motivated categories.A subset of the attributes are labeled on the RoT\n(e.g., \u201cIt is expected that you report a crime\u201d ),\nwhile others are on the action (e.g., \u201creporting a\ncrime\u201d ). Figure 4 provides the complete set of\nlabels available for an RoT breakdown.5\nGrounding Attributes We call three at-\ntributes grounding attributes . Their goal is to\nground the RoT and action to the situation and char-\nacters. At the RoT-level, workers mark which char-\nacter should heed the RoT with the RoT Targeting\nattribute. At the action level, workers \ufb01rst pick the\naction\u2019s best candidate character, for whom the\naction is most relevant. However, since RoTs can\nidentify actions that are both explicit and hypo-\nthetical in the situation, we additionally annotate\nwhether the candidate character is explicitly taking\nthe action in the situation.\nSocial Attributes The second set of attributes\ncharacterize social expectations in an RoT. The\n\ufb01rst two social attributes both label anticipated\nagreement . For an RoT, this attribute asks how\nmany people probably agree with the RoT as stated.\nAt the action level, it asks what portion of people\nprobably agree with the judgment given the action .\nFour social attributes relate to the theoretical\nunderpinnings of this work in \u00a72. An RoT-level\n5Workers are given the choice to mark the RoT as confus-\ning, vague, or low quality, and move on (2% of RoTs).\nattribute is the set of Moral Foundations , based\non a well-known social psychology theory that\noutlines culturally innate moral reasoning (Haidt,\n2012). The action-level attributes legality and\ncultural pressure are designed to re\ufb02ect the two-\ncoarse-grained categories proposed by the Social\nNorms Theory (Kitts and Chiang, 2008; Perkins\nand Berkowitz, 1986). Legality corresponds to pre-\nscriptive norms: what one ought to do. Cultural\npressure corresponds to descriptive norms: what\none is socially in\ufb02uenced to do. Finally, the social\njudgment aims to capture subjective moral judg-\nment. A base judgment of what is good or bad\nis thought to intrinsically motivate social norms\n(Malle et al., 2014; Haidt et al., 1993).\nThe \ufb01nal two attributes provide a coarse cate-\ngorization over RoTs and actions. The RoT Cate-\ngory attribute estimate distinctions between moral-\nity, social norms, and other kinds of advice. This\naims to separate moral directives from tips or gen-\neral world knowledge (e.g., \u201cIt is good to eat when\nyou are hungry\u201d). The attribute agency is designed\nto let workers distinguish RoTs that involve agen-\ntive action from those that indicate an an experience\n(e.g., \u201cIt is sad to lose a family member\u201d).\n3.4 Analysis\nWe brie\ufb02y highlight three key aspects of our for-\nmalism: social judgment, anticipated agreement,\nand cultural pressure. Figure 5 shows two plots\npartitioning RoTs based on these three attributes\n(with legality also highlighted in the left plot (a)).\nIn the left plot (Figure 5 (a)), the x-axis contains\na new quantity, where social judgment ( 2[\u00002;2])\nis multiplied by agreement ( 2[0;4]) to scale it.6\nThe result is that xvalues range from universally-\nagreed bad actions (-8) to universally-agreed good\nactions (+8). Intuitively, the bottom-left group\nshows illegal actions, which are both \u201cbad\u201d (left\nx) and people feel strong pressure not to do (bot-\ntomy). The data are generally distributed in a line\ntowards the top right, which are \u201cgood\u201d (right x)\nactions that people feel strong pressure to do (top\ny).\nHowever, the spread of the data in Figure 5 (a)\nillustrates the difference between morality and cul-\ntural pressure. There are a range of morally charged\n6Strict statisticians will note that plotting ordinal values\nnumerically is an abuse of notation, much less scaling two\nvalues together. We present these graphs for illustrative pur-\nposes to observe the strati\ufb01cation of our dataset, not to make\nquantitative claims.\nb1b2b3\u2026bm\u2026\u2026ss1s2s3sr1r2r3rnForward language modelingEncoder-DecoderSituationAttributes\u201cRunning the blenderat 5am\u201dFairness/CheatingControversial\u201cYou have the right to prepare food when you need to.\u201drRule-of-Thumbseparator tokens Figure 6: Illustration of modeling setup for the objec-\ntivep(rjs;~br).\nactions, but for which people don\u2019t feel cultural\npressure (the horizontal range in xvalues across\nthe centraly=Discretionary ). Conversely, we\nobserve actions that are morally neutral, but for\nwhich people do feel cultural pressure (the vertical\nrange inyvalues along the middle x= 0).\nThe right plot, Figure 5 (b), shows social judg-\nment against agreement, colored by cultural pres-\nsure. At high levels of agreement (top of graph),\ncultural pressure (color) follows social judgment\n(horizontal changes in xvalues). However, for\ncontroversially-held judgments (lower yvalues),\nwe see a range of cultural pressure. This includes\nmorally good or bad actions that are still discre-\ntionary (middle yvalues), as well as morally neu-\ntral actions for which people feel strong cultural\npressure (lower yvalues).\nThese plots illustrate two ways of stratifying\nactions along socially relevant dimensions. We\nanticipate considerable further dataset exploration\nremains.\n4 Model\nWe investigate neural models based on pre-trained\nlanguage models for learning various sub-tasks de-\nrived from S OCIAL -CHEM -101.\n4.1 Training Objectives\nOur main modeling formulation is straightforward.\nGiven a situation ( s), we wish to model the con-\nditional distribution of RoTs ( r), actions (a), and\nset of attributes from the breakdown ( ~b). We can\npartition the attributes ~b=f~br;~baginto disjoint\nsets relevant to the RoT and action, and write\np(r;a;~bjs) =p(a;~bajr;~br;s)|{z}\naction transcription\u0002p(r;~brjs)|{z}\nRoT prediction:(1)\nEquation 1 allows us to model all components\nof interest given a situation s. However, the action\ntranscription term is quite strongly conditioned,\nbecause actions are so closely related to their RoTs.\nObjective\nRoT Action Interpretation\np(rjs) p(ajs) Text-only generation\np(~brjs) p(~bajs) Attribute prediction\np(rjs;~br)p(ajs;~ba) Controlled generation\np(~brjs; r)p(~bajs; a) Attribute labeling\np(r;~brjs)p(a;~bajs) Model choice generation\nTable 1: Generative model objectives corresponding to\nthe training setups we consider. Each model (RoT or\naction) is trained on all objectives simultaneously.\nIn this paper, we instead focus our study of actions\non a more dif\ufb01cult distribution that conditions only\non the situation:\np(a;~bajr;~br;s)|{z}\naction transcriptionomit RoT\u0000\u0000\u0000\u0000!p(a;~bajs)|{z}\naction prediction: (2)\nWe model both the RoT prediction (Eq. 1)\nandaction prediction (Eq. 2) distributions with\nconditional forward language modeling. We tok-\nenize all quantities ( s;r;a;~b), creating unique to-\nkens for each attribute value bi, and concatenate\nthem together in a canonical order to form strings\np(xoutjxin). We then train to maximize the standard\nlanguage modeling objective:\nx= [xin;xout]; p(x) =nY\ni=1p(xijx<i):(3)\nBoth the RoT prediction (Eq. 1) and action pre-\ndiction (Eq. 2) distributions have similar forms\np(y;~byjs)fory2fr;ag. We take advantage of\nthis symmetry to study variations of both distribu-\ntions. Inspired by recent work (Zellers et al., 2019),\nwe construct permutations of our data that omit\ndifferent \ufb01elds while maintaining the canonical or-\nder. Table 1 shows the setups that we consider, and\nFigure 6 illustrates an example objective.\nWe train each model (either RoT or action) on\nall relevant objectives in Table 1 (i.e., one of the\ncolumns). Intuitively, this allows the model to con-\ndition on and generate a range of \ufb01elds.7We can do\nthis by simply treating each objective as de\ufb01ning\na subset of the \ufb01elds, as well as their ordering, for\neach data point. Then, we combine and shuf\ufb02e all\nobjectives\u2019 views of the data.\n7It is possible to remove the assumption that the situation\nis provided, which would allow the model to generate sas\nwell. We leave such experiments for future work.4.2 Architectures\nWe present results for the GPT and GPT-2 architec-\ntures (Radford et al., 2018, 2019), as well as two\nencoder-decoder language models (BART and T5,\nLewis et al., 2019; Raffel et al., 2019). We train\nforward language models with loss over the entire\nsequencex, whereas encoder-decoder models only\ncompute loss for the output sequence xout. Collec-\ntively, we term these architectures trained on our\nobjectives the N EURAL NORM TRANSFORMER .\n5 Experiments and Results\n5.1 Tasks\nWhile we train each model on all (RoT or action)\nobjectives at once, we pick two particular objec-\ntives to asses the models. The \ufb01rst is p(y;~byjs)\n\u2014\u201cmodel choice. \u201d In this setting, each model is\nallowed to pick the most likely attributes ~bygiven\na situations, and generate an RoT (or action) y\nthat adheres to those attributes. This setup should\nbe easier because a model is allowed to pick the\nconditions of its own generation ( ~by).\nThe second setting is p(yjs;~by)\u2014\u201cconditional. \u201d\nWe provide models with a set of attributes ~bythat\nthey must follow when generating an RoT (or ac-\ntion)y. This presents a more challenging setup,\nbecause models cannot simply condition on the set\nof attributes that they \ufb01nd most likely. We select\nsets of attributes ~byprovided by the human anno-\ntators for the situation sto ensure models are not\ntasked with generating from impossible constraints.\nSetup We split our dataset into 80/10/10%\ntrain/dev/test partitions by situation, such that each\ndomain\u2019s situations are proportionally distributed.\nThis guarantees previously unobserved dev and test\nsituations. For all models we use top- pdecoding\nwithp= 0:9(Holtzman et al., 2020).\nBaselines We use a Random RoT baseline to ver-\nify the dataset diversity (selections should have low\nrelevance to test situations) and evaluation setup\n(RoTs and actions should still be internally con-\nsistent). We also use a BERT-Score (Zhang et al.,\n2020) retrieval baseline that \ufb01nds the most simi-\nlar training situation. If attributes ~byare provided,\nthe retriever picks the RoT (or action) from the\nretrieved situation with the most similar attributes.\nAblations We report two model ablations. For\n-Small , we \ufb01netune GPT-2 Small with the same gen-\neral architecture. For -No pretrain , we randomly\n!RoT !Action\nCategory Moral F. Agree Relevance Agency Judgment Agree Pressure Legal Taking Relevance\nRandom RoT 0.73 0.84 0.48 1.25 0.90 0.57 0.55 0.53 0.80 0.04 1.22Model choice p(y;~byjs)BERT-Score (Z et al., 2020) 0.76 0.83 0.48 2.00 0.90 0.64 0.46 0.61 0.81 0.20 2.00\nGPT (R et al., 2018) 0.71 0.77 0.39 2.23 0.82 0.40 0.36 0.32 0.76 0.15 2.25\nBART (L et al., 2019) 0.69 0.79 0.49 2.60 0.91 0.55 0.54 0.46 0.80 0.18 2.52\nT5 (R et al., 2019) 0.62 0.85 0.42 2.78 0.78 0.36 0.36 0.23 0.56 0.23 2.73\nGPT-2 Small (R et al., 2019) 0.62 0.79 0.34 2.03 0.82 0.34 0.34 0.27 0.79 0.09 1.99\nGPT-2 XL - No pre-train 0.68 0.78 0.20 1.37 0.81 0.37 0.30 0.33 0.79 0.06 1.29\nGPT-2 XL 0.75 0.84 0.42 2.53 0.91 0.51 0.36 0.45 0.82 0.32 2.60\nRandom RoT 0.59 0.75 0.41 1.20 0.84 0.27 0.28 0.21 0.74 0.01 1.19Controlled p(yjs;~by)BERT-Score (Z et al., 2020) 0.66 0.78 0.41 2.00 0.87 0.40 0.45 0.34 0.76 0.16 1.97\nGPT (R et al., 2018) 0.64 0.79 0.36 2.21 0.83 0.46 0.36 0.38 0.74 0.17 2.26\nBART (L et al, 2019) 0.70 0.81 0.38 2.60 0.84 0.47 0.42 0.41 0.73 0.20 2.44\nT5 (R et al., 2019) 0.66 0.80 0.40 2.77 0.83 0.41 0.34 0.38 0.73 0.24 2.79\nGPT-2 Small (R et al., 2019) 0.64 0.78 0.30 2.10 0.78 0.38 0.30 0.27 0.71 0.10 1.97\nGPT-2 XL - No pre-train 0.67 0.79 0.23 1.35 0.83 0.36 0.32 0.26 0.73 0.04 1.33\nGPT-2 XL 0.71 0.79 0.38 2.65 0.90 0.51 0.38 0.42 0.74 0.28 2.54\nTable 2: Human evaluation results for conditionally generating RoTs and actions, either letting the models choose\nthe attributes (top half), or providing the attributes as input constraints (bottom half). All columns are micro-F1\nscores (0\u20131), except Relevance (1\u20133). Takeaway: While state-of-the-art models are able to generate relevant RoTs\nand actions that generally follow constraints (moderately high scores in some columns), correctly conditioning on\na complete set of attributes remains challenging (several columns show poor model performance in bottom half).\nModel Ppl. BLEU-4 Attr. \u0016F1\n!RoT\nGPT 1.81 5.41 0.42\nBart-large 1.76 6.65 0.47\nT5-large 1.94 10.79 0.34\nGPT-2 Small 1.97 4.97 0.38\nGPT-2 XL - No \ufb01ne-tune - 0.46 0.20\nGPT-2 XL - No pre-train 2.54 4.39 0.42\nGPT-2 XL 1.75 6.53 0.53\n!Action\nGPT 1.80 6.75 0.60\nBART-Large 1.72 8.34 0.66\nT5-Large 2.00 8.93 0.58\nGPT-2 Small 1.94 6.62 0.56\nGPT-2 XL - No \ufb01ne-tune - 0.25 0.52\nGPT-2 XL - No pre-train 2.51 5.43 0.55\nGPT-2 XL 1.73 7.98 0.68\nTable 3: Test set performance by automatic metrics, in-\ncluding an attribute classi\ufb01er. Perplexities are not com-\nparable between encoder-decoder models (Bart and T5,\nloss onxoutonly) and other models (loss on full se-\nquencex).Takeaway: Automatic metrics corrobo-\nrate human evaluation results: while T5 is most adept\nat BLEU, GPT-2 XL more consistently adheres to at-\ntributes (Attr. \u0016F1).\ninitialize the model\u2019s weights.8\n5.2 Results\nHuman Evaluation Table 2 presents a human\nevaluation measuring how effective models are at\ngenerating RoTs and actions for both task settings.\nWhile most columns measure attribute adherence,\ntheRelevance score is critical for distinguishing\n8We omit the evaluation of an \u201cout-of-the-box GPT2-XL\u201d\nbaseline (i.e. no \ufb01ne-tuning) whose outputs predictably do not\nresemble RoTs or actions.whether RoTs actually apply to the provided sit-\nuation (e.g., see low scores for the Random RoT\nbaseline). In both setups, T5\u2019s generations rank as\nmost tightly relevant to the situation. But in terms\nof correctly following attributes, GPT-2 is more\nconsistent, especially in the controlled task setup\n(lower; top scores on 5/9 attributes). However, no\nmodel is able to achieve a high score on all columns\nin the bottom half of the table. This indicates that\nfully constrained conditional generation may still\npresent a signi\ufb01cant challenge for current models.\nAutomatic Evaluation We also provide auto-\nmatic metrics of the generated outputs. We train\nattributes classi\ufb01ers using RoBERTa (Liu et al.,\n2019), and use them to classify the model outputs.9\nTable 3 presents test set model performance on\nperplexity, BLEU (Papineni et al., 2002), and at-\ntribute micro-F1 classi\ufb01er score. The automatic\nmetrics are consistent with human evaluation. T5\nis a strong generator overall, achieving the high-\nest BLEU score and the highest relevance score in\n\u00a75.2. However, GPT-2 more consistently adheres\nto attributes, outperforming T5 in attribute F1with\nnearly 20 points gap for RoTs, and over 10 points\nfor actions.\n6 Morality & Political Bias\nTo demonstrate a use case of our proposed formal-\nism, we analyze the social norms and expectations\nevoked in news headlines from news sources of\n9BERT and BART performed worse across attributes.\nLeft (-) or Right (+) Reliability\nAgreement -0.015\u0003\u0003-0.008\u0003ROT Cat.Morality / Ethics -0.069\u0003\u0003\u0003-0.022\u0003\u0003\u0003\nSocial Norms 0.019\u0003\u0003\u0003-0.006\u0003\nIt is what it is 0.039\u0003\u0003\u0003-0.007\u0003\u0003\nAdvice 0.031\u0003\u0003\u00030.033\u0003\u0003\u0003Moral F.Care / Harm -0.033\u0003\u0003\u0003-0.016\u0003\u0003\u0003\nAuthority / Subversion n.s. n.s.\nFairness / Cheating -0.050\u0003\u0003\u0003n.s.\nLoyalty / Betrayal 0.026\u0003\u0003\u0003-0.007\u0003\u0003\nSanctity / Degradation 0.014\u0003\u0003-0.017\u0003\u0003\u0003\nTable 4: Correlations between generated RoT attributes\nfor headlines and the news source\u2019s political leaning\n(left: neg., right: pos.) and reliability (controlled for\npolitical leaning). Results shown are signi\ufb01cant after\nHolm-correction for multiple comparisons (p < 0:001:\n\u0003\u0003\u0003,p < 0:01:\u0003\u0003,p < 0:05:\u0003,p > 0:05:n.s.).\nTakeaway: We see evidence that a model trained on\nthe S OCIAL -CHEM -101 Dataset can naturally uncover\nmoral and topical leanings in news sources, mirroring\nresults found in previous news studies.\nvarious political leanings and trustworthiness, us-\ning the NEURAL NORM TRANSFORMER (GPT-2\nXL). Speci\ufb01cally, we generate ROTs and attributes\nfor 50,000 news headlines randomly selected from\nN\u00f8rregaard et al. (2019), a large corpus of political\nheadlines from 2018 paired with news source rat-\nings of political leaning (5-point scale from left- to\nright-leaning) and factual reliability (5-point scale\nfrom least reliable to most reliable).10\nTable 4 shows the correlations between RoT at-\ntributes and the political leaning and reliability of\nsources. Our results strongly corroborate \ufb01ndings\nby Graham et al. (2009), showing that liberal head-\nlines evoke more \u201cfairness\u201d and \u201ccare,\u201d while right-\nleaning headlines evoke more \u201csanctity\u201d and \u201cloy-\nalty.\u201d Furthermore, in line with \ufb01ndings by V olkova\net al. (2017), more reliable news source tend to\nevoke more advice and less morality.\n7 Related Work\nOur formalism heavily draws from works in de-\nscriptive ethics and social psychology, but is also in-\nspired by studies in social implicatures and cooper-\native principles in pragmatics (Kallia, 2004; Grice,\n1975) and the theories of situationally-rooted evo-\ncation of frames (Fillmore and Baker, 2001).\nOur work adds to the growing literature con-\ncerned with distilling reactions to situations (Vu\net al., 2014; Ding and Riloff, 2016) as well as so-\n10We use the MediaBias/FactCheck ratings: https://\nmediabiasfactcheck.com .cial and moral dynamics in language (Van Hee\net al., 2015). Commonly used for coarse-grained\nanalyses of morality in text (Fulgoni et al., 2016;\nV olkova et al., 2017; Weber et al., 2018), Graham\net al. (2009) introduce the Moral Foundations lexi-\ncon, a dictionary of morality-evoking words (later\nextended by Rezapour et al., 2019).\nA recent line of work focused on representing\nsocial implications of everyday situations in free-\nform text in a knowledge graph (Rashkin et al.,\n2018; Sap et al., 2019). Relatedly, Sap et al. (2020)\nintroduce Social Bias Frames, a hybrid free-text\nand categorical formalism to reason about biased\nimplications in language. In contrast, our work\nformalizes a new type of reasoning around expec-\ntations of social norms evoked by situations.\nFinally, concurrent works have developed rich\nand exciting resources studying similar phenom-\nena. Tay et al. (2020) study Would you rather?\nquestions, and Acharya et al. (2020) investigate rit-\nual understanding across cultures. Hendrycks et al.\n(2020) study ethical questions, attempting to assign\na real-valued utility to scenarios across a range of\nethical cateogires. And Lourie et al. (2020) de\ufb01ne\nthe challenge of predicting the r/AITA task using\nthe full posts. In contrast to these studies, our work\naddresses norms by distilling cultural knowledge\nto a new conceptual level of Rules-of-Thumb and\ncorresponding structural annotations.\n8 Conclusion\nWe present SOCIAL -CHEM -101 , an attempt at pro-\nviding a formalism and resource around the study\nof grounded social, moral, and ethical norms. Our\nexperiments demonstrate preliminary success in\ngenerative modeling of structured RoTs, and cor-\nroborate \ufb01ndings of moral leaning in an extrinsic\ntask. Comprehensive modeling of social norms\npresents a promising challenge for NLP work in\nthe future.\nAcknowledgments\nThe authors would like to thank Nicholas Lourie,\nRowan Zellers, Chandra Bhagavatula, and Liwei\nJiang. This material is based upon work supported\nby the National Science Foundation Graduate Re-\nsearch Fellowship under Grant No. DGE1256082,\nand in part by NSF (IIS-1714566), DARPA CwC\nthrough ARO (W911NF15-1-0543), DARPA MCS\nprogram through NIWC Paci\ufb01c (N66001-19-2-\n4031), and the Allen Institute for AI.\nReferences\nAnurag Acharya, Kartik Talamadupula, and Mark A\nFinlayson. 2020. An atlas of cultural commonsense\nfor machine reasoning.\nGeorge J Bowdery. 1941. Conventions and norms. Phi-\nlosophy of Science , 8(4):493\u2013505.\nHaibo Ding and Ellen Riloff. 2016. Acquiring knowl-\nedge of affective events from blogs using label prop-\nagation. In AAAI .\nJennifer L Eberhardt. 2020. Biased: Uncovering the\nhidden prejudice that shapes what we see, think, and\ndo. Penguin Books.\nJon Elster. 2006. Fairness and norms. Social Research ,\npages 365\u2013376.\nCharles J Fillmore and Collin F Baker. 2001. Frame\nsemantics for text understanding. In Proceedings\nof WordNet and Other Lexical Resources Workshop,\nNAACL , volume 6.\nDean Fulgoni, Jordan Carpenter, Lyle Ungar, and\nDaniel Preot \u00b8iuc-Pietro. 2016. An empirical explo-\nration of moral foundations theory in partisan news\nsources. In LREC , pages 3730\u20133736.\nJesse Graham, Jonathan Haidt, and Brian A Nosek.\n2009. Liberals and conservatives rely on different\nsets of moral foundations. J. Pers. Soc. Psychol. ,\n96(5):1029\u20131046.\nHerbert P Grice. 1975. Logic and conversation. In\nSpeech acts , pages 41\u201358. Brill.\nJonathan Haidt. 2012. The righteous mind: Why good\npeople are divided by politics and religion . Vintage.\nJonathan Haidt, Silvia Helena Koller, and Maria G\nDias. 1993. Affect, culture, and morality, or is it\nwrong to eat your dog? Journal of personality and\nsocial psychology , 65(4):613.\nRichard Mervyn Hare. 1981. Moral thinking: Its levels,\nmethod, and point . Oxford: Clarendon Press; New\nYork: Oxford University Press.\nDan Hendrycks, Collin Burns, Steven Basart, Andrew\nCritch, Jerry Li, Dawn Song, and Jacob Steinhardt.\n2020. Aligning ai with shared human values.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2020. The curious case of neural text de-\ngeneration. In International Conference on Learn-\ning Representations .\nJerome Kagan. 1984. The nature of the child. Basic\nBooks.\nAlexandra Kallia. 2004. Linguistic politeness: The im-\nplicature approach. Multilingua , 23(1/2):145\u2013170.\nJames A Kitts and Yen-Sheng Chiang. 2008. Encyclo-\npedia of social problems,.Lawrence Kohlberg. 1976. Moral stages and moraliza-\ntion. Moral development and behavior , pages 31\u2013\n53.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Ves Stoyanov, and Luke Zettlemoyer. 2019.\nBart: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and\ncomprehension. arXiv preprint arXiv:1910.13461 .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv , abs/1907.11692.\nNicholas Lourie, Ronan Le Bras, and Yejin Choi. 2020.\nScruples: A corpus of community ethical judgments\non 32,000 real-life anecdotes. arXiv e-prints .\nBertram F Malle, Steve Guglielmo, and Andrew E\nMonroe. 2014. A theory of blame. Psychological\nInquiry , 25(2):147\u2013186.\nGeorge A Miller. 1995. Wordnet: a lexical database for\nenglish. Communications of the ACM , 38(11):39\u2013\n41.\nNasrin Mostafazadeh, Nathanael Chambers, Xiaodong\nHe, Devi Parikh, Dhruv Batra, Lucy Vanderwende,\nPushmeet Kohli, and James Allen. 2016. A cor-\npus and cloze evaluation for deeper understanding of\ncommonsense stories. In Proceedings of the 2016\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , pages 839\u2013849, San Diego,\nCalifornia. Association for Computational Linguis-\ntics.\nJ N\u00f8rregaard, B D Horne, and S Adal\u0131. 2019. NELA-\nGT-2018: A large multi-labelled news dataset for the\nstudy of misinformation in news articles. In AAAI .\nwvvw.aaai.org.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of\nthe 40th annual meeting on association for compu-\ntational linguistics , pages 311\u2013318. Association for\nComputational Linguistics.\nGonc \u00b8alo Pereira, Rui Prada, and Pedro A Santos. 2016.\nIntegrating social power into the decision-making of\ncognitive agents. Arti\ufb01cial Intelligence , 241:1\u201344.\nH Wesley Perkins and Alan D Berkowitz. 1986. Per-\nceiving the community norms of alcohol use among\nstudents: Some research implications for campus al-\ncohol education programming. International jour-\nnal of the Addictions , 21(9-10):961\u2013976.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog .\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2019. Exploring the limits\nof transfer learning with a uni\ufb01ed text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683 .\nHannah Rashkin, Maarten Sap, Emily Allaway,\nNoah A Smith, and Yejin Choi. 2018. Event2mind:\nCommonsense inference on events, intents, and reac-\ntions. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 463\u2013473.\nRezvaneh Rezapour, Saumil H Shah, and Jana Diesner.\n2019. Enhancing the measurement of social effects\nby capturing morality. In Workshop on Computa-\ntional Approaches to Subjectivity, Sentiment and So-\ncial Media Analysis , pages 35\u201345, Stroudsburg, PA,\nUSA. Association for Computational Linguistics.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\nsky, Noah A Smith, and Yejin Choi. 2020. Social\nbias frames: Reasoning about social and power im-\nplications of language. In ACL.\nMaarten Sap, Ronan LeBras, Emily Allaway, Chan-\ndra Bhagavatula, Nicholas Lourie, Hannah Rashkin,\nBrendan Roof, Noah A Smith, and Yejin Choi. 2019.\nATOMIC: An atlas of machine commonsense for if-\nthen reasoning. In AAAI .\nRichard A Shweder. 1990. In defense of moral re-\nalism: Reply to gabennesch. Child Development ,\n61(6):2060\u20132067.\nYi Tay, Donovan Ong, Jie Fu, Alvin Chan, Nancy\nChen, Anh Tuan Luu, and Christopher Pal. 2020.\nWould you rather? a new benchmark for learning\nmachine alignment with cultural values and social\npreferences. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics , pages 5369\u20135373.\nKristina Toutanova, Dan Klein, Christopher D Man-\nning, and Yoram Singer. 2003. Feature-rich part-of-\nspeech tagging with a cyclic dependency network.\nInProceedings of the 2003 conference of the North\nAmerican chapter of the association for computa-\ntional linguistics on human language technology-\nvolume 1 , pages 173\u2013180. Association for Compu-\ntational Linguistics.\nCynthia Van Hee, Els Lefever, Ben Verhoeven, Julie\nMennes, Bart Desmet, Guy De Pauw, Walter Daele-\nmans, and Veronique Hoste. 2015. Detection and\n\ufb01ne-grained classi\ufb01cation of cyberbullying events.\nInProceedings of the International Conference Re-\ncent Advances in Natural Language Processing ,\npages 672\u2013680, Hissar, Bulgaria. INCOMA Ltd.\nShoumen, BULGARIA.Svitlana V olkova, Kyle Shaffer, Jin Yea Jang, and\nNathan Hodas. 2017. Separating facts from \ufb01c-\ntion: Linguistic models to classify suspicious and\ntrusted news posts on twitter. In ACL, pages 647\u2013\n653, Stroudsburg, PA, USA. Association for Com-\nputational Linguistics.\nHoa Trong Vu, Graham Neubig, Sakriani Sakti,\nTomoki Toda, and Satoshi Nakamura. 2014. Acquir-\ning a dictionary of emotion-provoking events. In\nProceedings of the 14th Conference of the European\nChapter of the Association for Computational Lin-\nguistics, volume 2: Short Papers , pages 128\u2013132.\nSu Wang, Greg Durrett, and Katrin Erk. 2018. Model-\ning semantic plausibility by injecting world knowl-\nedge. In NAACL-HLT .\nRen\u00b4e Weber, J Michael Mangus, Richard Huskey, Fred-\neric R Hopp, Ori Amir, Reid Swanson, Andrew Gor-\ndon, Peter Khooshabeh, Lindsay Hahn, and Ron\nTamborini. 2018. Extracting latent moral informa-\ntion from text narratives: Relevance, challenges, and\nsolutions. Commun. Methods Meas. , 12(2-3):119\u2013\n139.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R\u2019emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface\u2019s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv , abs/1910.03771.\nRowan Zellers, Ari Holtzman, Hannah Rashkin,\nYonatan Bisk, Ali Farhadi, Franziska Roesner, and\nYejin Choi. 2019. Defending against neural fake\nnews. In NeurIPS .\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations .\nA Additional Dataset Details\nA.1 Situations\nDomains We provide here a more thorough de-\nscription how we collected situations from the four\ndomains we consider. Figure 7 gives more example\nsituations from each domain.\n1.r/amitheasshole (30k) \u2014 The Am I the Asshole?\n(AITA) subreddit. This posts of this subreddit pose moral\nquandries, such as \u201cAITA for wanting to uninvite an\n(ex?)-friend from my wedding for shit-talking our mar-\nriage?\u201d We use the data from Lourie et al. (2020). They\nscrape the titles of posts, omitting the preamble (e.g.,\n\u201cAITA for\u201d ), normalizing to present tense, and \ufb01ltering\nout administrative posts. We do not use any annotations\nprovided by that community (where other posters vote\nwho had the moral high ground).\n2.r/confessions (32k) \u2014 The Confessions subred-\ndit. This posts of this subreddit discuss personal stories,\n[r/amitheasshole]\n\u2013 telling my friend and her family to move out\n\u2013 choosing to spend time with my friends or boyfriend rather than\nmy family\n\u2013 not wanting to hangout with sick girlfriend\n\u2013 not wanting to do household chores\n\u2013 banning my ex from my Spotify account\n[r/confessions]\n\u2013 My SO thinks I hate pickles, I like pickles but he LOVES pick-\nles so I always pretend to hate them so he can have them.\n\u2013 Best friend just got engaged.\n\u2013 My girlfriend cheated and im cheating back on her\n\u2013 I hate myself because I couldn\u2019t save my mother\n\u2013 I\u2019m scared of being a dad\n[rocstories]\n\u2013 Clark Ryder was proud of his job as a photojournalist.\n\u2013 They had so many questions that I couldn\u2019t answer.\n\u2013 Her husband surprised her on her birthday with plane tickets!\n\u2013 She decided to wear slippers to protect her feet from Jason\u2019s\ntoys.\n\u2013 When he got to the assembled class he became very nervous.\n[dearabby]\n\u2013 Family of Six Tries Not to Be a Burden on Weekend Hosts\n\u2013 Breakup Letter to Soldier Could Jeopardize Comrades in Arms\n\u2013 Gentle Nudge Has Not Worked to Dislodge Mom From House\n\u2013 Planning Helps Students Get Good Letter of Recommendation\n\u2013 Man With Breast Cancer Experiences Extra Stress\nFigure 7: Five randomly sampled situations from each\nof the four domains we consider.\noften with interpersonal con\ufb02icts, such as \u201cI feel threat-\nened by women prettier than me. \u201d As with r/AITA ,\nwe scrape only the titles of these posts. This subreddit\ncontains a high volume of hateful or disturbing content;\nwe attempt to \ufb01lter the worst of this using keywords,\nand also allow annotators to mark dark or disturbing\nitems.\n3.rocstories (30k) \u2014 The ROCStories corpus from\n(Mostafazadeh et al., 2016). ROCStories involve stories\nabout everyday situations, and are generally less contro-\nversial than the other sources, e.g., \u201cThey weren\u2019t sure\neither so he started asking friends. \u201d. We select a subset\nof the sentences from ROCStories which are likely to\ninvolve two character references based on POS tagging\n(Toutanova et al., 2003), personal pronouns, and Word-\nNet (Miller, 1995). We then randomly sample to pick\n30k sentences.\n4.dearabby (12k) \u2014 Titles of the Dear Abby advice\ncolumn. These titles are usually information dense sum-\nmaries of interpersonal situations written in the style of\nnews headlines, e.g., \u201cPushy Party Guests Make Them-\nselves Too Much at Home. \u201d We scrape all of the titles\nfound in the archives, and use heuristics to attempt to\n\ufb01lter out all posts that do not match this style, such as\nannouncements and holiday greetings.\nWe attempt to balance the number of situations\ncollected for each domain. However, we are limited\nby the complete set of examples from dearabby\n(12k).\nAdditional Labels We allow annotators to mark\neach situation with any of the following labels that\napply.\n\u2022Unclear The situation was too simple, vague, or con-\nfusing to understand what happened.\u2022NSFW The situation contains suggestive or adult con-\ntent.\n\u2022Dark / disturbing / controversial. The situation con-\ntained content that may make folks uncomfortable, like\nsuicide, torture, or abuse.\nAnnotators may pass on writing RoTs for a situ-\nation marked with any of those boxes, or they may\nstill choose to do so. We keep all of the labels\ncollected. They are included in the dataset as ad-\nditional \ufb01elds. For example, they could be used to\nomit certain training data to keep a model biased\naway from potentially controversial subjects.\nA.2 Character Identi\ufb01cation\nOur goal during character identi\ufb01cation is to \ufb01nd\nthe most descriptive phrase referring to each unique\nnon-narrator person in the passage exactly once.\nThe reason for this goal is that always having a\nsingle, best reference to each person in the situation\nenables more consistent grounding.\nWhile this goal is relatively straightforward, we\n\ufb01nd many edge cases arise. In cases where it is\nunclear if a person should be marked, our central\ncriteria is whether someone might write RoTs\ninvolving that person . If so, that person should\nbe included so they are a candidate for grounding.\nWe found handling all of these edge cases com-\nplex enough to require human annotation instead\nof heuristics. We provide here the character identi-\n\ufb01cation guidelines that we give to the crowd worker\nannotators, along with an example illustrating each\none.\nCharacter Identi\ufb01cation Guidelines\n\u2013Don\u2019t include the (\ufb01rst person) narrator. For exam-\nple,\u201cI ate pizza\u201d would have no people highlighted.\n\u2013Only include people. For example, \u201cMy horse George\nprovides good conversation\u201d would have no people\nhighlighted.\n\u2013Only highlight each person once. For example, \u201cI\ngave my brother a hug, I like him, he\u2019s so nice\u201d , we\nwould only include my brother , not \u201chim\u201d or\u201che. \u201d\n\u2013Highlight the most descriptive mention of a person.\nFor example, \u201cI can\u2019t stand him, my brother is so\nmean. \u201d , we would pick my brother even though it comes\nafter \u201chim. \u201d\n\u2013Include the full phrase referring to the person. In-\nclude words like \u201ca\u201d,\u201cthe\u201d ,\u201cmy\u201d , and longer phrases.\nFor example, \u201cThe strange guy talked to my brother\nandmy oldest uncle , \u201dwe would pick The strange guy ,\nmy brother , and my oldest uncle , instead of just \u201cguy\u201d ,\n\u201cbrother\u201d , and \u201cuncle. \u201d\n\u2013Don\u2019t include phrases where a generic person-\nlooking word is used without referring to a particu-\nlar person. This often happens when describing a place\nor thing. For example, \u201cI walked into the men\u2019s room, \u201d\nwe would not pick anything, because \u201cmens\u2019 room\u201d is\na generic phrase. Similarly, we would not pick anything\nfor,\u201cI am a child, \u201d because \u201cchild\u201d is just used as a\ndescription. But for, \u201cI walked into my brother \u2019s room\u201d ,\nwe would pick my brother .\n\u2013Include people used to refer to someone. For exam-\nple,\u201cMy brother \u2019s girlfriend is so cool, \u201d we would pick\nboth my brother andmy brother\u2019s girlfriend .\n\u2013Include pronouns (she, her, hers, etc.) ifthey\u2019re the\nmost speci\ufb01c word available. For example, in a sen-\ntence like \u201cI love him, \u201dwe would pick him. However,\nfor a sentence like, \u201cI love my brother , I can always talk\nto him. \u201d we would instead pick my brother because it\u2019s\nmore speci\ufb01c.\n\u2013Include pronouns like \u201cthey\u201d and \u201cthem\u201d , also if\nthey\u2019re the most speci\ufb01c word available. For exam-\nple, if we had the sentence \u201cThey went to the party. \u201d\nwe would pick they. However, if we had the sentence\n\u201cMy friends went to the party and they had a good time. \u201d\nwe would instead pick My friends since it is more spe-\nci\ufb01c.\n\u2013Include plural \ufb01rst person pronouns (us, we, etc.)\nonce. For example, in a sentence like \u201cWewent to the\npark. \u201d we would pick we. Or for a sentence like \u201cThey\nspent hours talking to usand we had a good time. \u201d we\nwould pick they and us .\n\u2013Include other groups of people like \u201cher siblings,\u201d\n\u201ctheir class,\u201d and\u201chis team.\u201d For example, in a sen-\ntence like \u201cI talked to all of hisuncles for a while. \u201d we\nwould pick both his andhis uncles .\n\u2013Include proper names of people that aren\u2019t the nar-\nrator. For example, in a sentence like \u201cMary chased\nJohn at the park. \u201d we assume they are people (unless\notherwise speci\ufb01ed), and we would pick both Mary and\nJohn .\n\u2013Include people with titles like \u201cthe policeman\u201d and\n\u201cthe mailman.\u201d For example, in the sentence \u201cI chased\nthe store clerk . \u201dwe would select the store clerk .\n\u2013Include words like \u201csomeone\u201d and\u201ceveryone.\u201d For\nexample, in the sentence \u201cI am going to dinner with\nsomeone . \u201dwe would select someone.\nA.3 Rules-of-Thumb (RoTs)\nThis section provides more information on how\nRoTs are written. Figure 8 shows a sample of RoTs\norganized both by situation domain and topic.\nAs mentioned brie\ufb02y in Section 3.2 of the paper\nbody, we present workers with a series of guide-\nlines for how to write RoTs. All RoT writing guide-\nlines are in service of the goal that RoTs capture so-\ncial, ethical, moral, and cultural norms. Unlike the\nguidelines for character identi\ufb01cation, which are\nlargely syntactic, the guidelines for writing RoTsare semantic. This makes them more challenging\nboth to de\ufb01ne and check.\nTo motivate these guidelines, and to help readers\nintuitively characterize what RoTs are, we present\nthe RoT writing guidelines here at greater length,\nannotated with examples and explanations. For\neach guideline ( in bold ), we provide an example\nsituation ( in italics ) along with candidate RoTs that\nviolate orfollow the guideline.\nRoT Writing Guidelines\n\u2013Explain the basics of good and bad behavior. RoTs\nshould describe cultural expectations, as if to a \ufb01le-year-\nold child who doesn\u2019t yet know how the world works.\n\u2013Example situation: Not wanting to take tests to\napply for college\n\u2013 Violates: \u201cStudies have shown people perform\nbest on tests after sleeping at least seven hours\u201d\n\u2013 Follows: \u201cIt\u2019s normal to be stressed out by ex-\nams\u201d\n\u2013 Why: This broad guideline attempts to distin-\nguish RoTs from encyclopedic knowledge. In-\nstead, RoTs should contain everyday, common-\nsense knowledge about social norms and expecta-\ntions.\n\u2013Judgment and action. An RoT must comtain a judg-\nment and an action.\n\u2013Example situation: Telling my husband he\nshouldn\u2019t buy his dream boat\n\u2013 Violates: \u201cBoats are expensive\u201d\n\u2013 Follows: \u201cIt\u2019s mean to squash someone\u2019s dreams\u201d\n\u2013 Follows: \u201cPeople should be open to discussing\nbig purchases with their spouses\u201d\n\u2013 Why: Requiring an action helps ensure RoTs are\nabout things peoeple do. Requiring a judgment\npushes statements to contain some information\nabout norms and expectations.\n\u2013Self-contained. An RoT must be fully understandable\non its own, without the situation it came from.\n\u2013Example situation: Being angry at my sister for\nnot attending our fathers funeral because of his\ncriminal history.\n\u2013 Violates: \u201cIt makes them feel bad\u201d\n\u2013 Violates: \u201cThe father caused emotional distress\nto his daughter and the narrator should not judge\nher actions too harshly.\u201d\n\u2013 Follows: \u201cIf someone commits serious crimes,\nit\u2019s OK for family to cut off contact with them.\u201d\n\u2013 Why: Without this requirement, RoTs would not\nnaturally generalize to new situations, and would\ntrend too speci\ufb01c. The would also could contain\nmuch less information, as much of the semantic\ncontent could be left in the situation and only\nreferred to by the RoT.\n\u2013Inspired by situation. An RoT should be inspired by\nthe situation it came from.\n\u2013Example situation: Wanting to uninvite a friend\nfrom my wedding.\n\u2013 Violates: \u201cIt\u2019s rude to point at people you don\u2019t\nknow\u201d\n\u2013 Follows: \u201cIt\u2019s devastating to be excluded from a\nwedding you were invited to\u201d\n[r/amitheasshole]Wanting to uninvite an (ex?)-friend from my wedding for shit-talking our marriage  - When you are paying for a celebration, you are allowed to invite whoever you want.  - It is reasonable to rescind an invitation to a wedding if someone is no longer your friend.  - Telling someone they can't come to your wedding after they were already invited is tacky.[r/confessions]I feel threatened by women prettier than me  - It's bad to feel threatened.  - It's normal to feel intimidated by others.  - It's ok for someone to be prettier than you.   It's normal to compare yourself with others.[rocstories]They weren't sure either so he started asking friends.  - It's okay to ask your friends about something you need to know.  - It's understandable if you're uncertain of what to do.  - You should ask for advice when you aren't sure what the right course of action is.  - It's good to give your friend advice when they ask for it.  - It's okay to be scared when you're not sure what to do.[dearabby]Pushy Party Guests Make Themselves Too Much at Home  - You should respect other people's property.  - You should admit to breaking something rather than convering it up.  - It's OK to turn down an invitation if you're not interested in going.  - It's rude to exclude others from a get-together.- Trying to warn a coworker about the dangers of smoking is caring.- It's okay to ask someone not to smoke in your car.- It's wrong to pretend that you're smoking because it's unhealthy to smoke and you shouldn't idolize people that do.- You shouldn't accept cigarettes from friends when you don't smoke.- You should not smoke inside.- It is bad to expose others to second hand smoke- It's bad to smoke.- It's bad for your health to smoke cigarettes.- You shouldn't smoke weed.9/451 RoTs randomlysampled, searchingfor \u201csmok*\u201d acrossRoTs from all fourdomains.Figure 8: Top: An example situation (bold) and corresponding RoTs (bullets) from each of the four domains we\nconsider. Bottom: Random sample of RoTs about smoking, found by searching for smok* across the dataset.\n\u2013 Why: Maintaining a link between RoT and situa-\ntion allows for grounding RoTs during the struc-\ntured annotation. Furthermore, since a different\nworker will likely provides the structural annota-\ntion for an RoT, relevance to the source situation\nhelps ensure the worker understands the RoT\u2019s\ncontext and implications.\n\u2013Balance Speci\ufb01city and Vagueness. An RoT should\nbe inspired by, and relevant to, the provided situation.\nHowever, a rule-of-thumb should also give a general\nrule for how people behave in society, so should apply\nto more than just the given situation.\n\u2013Example situation: Not tipping my cashier last\nTuesday\n\u2013 Violates: \u201cNot tipping a cashier last Tuesday is\nrude\u201d\n\u2013 Violates: \u201cIt\u2019s rude to be cheap\u201d\n\u2013 Follows: \u201cIt\u2019s usually OK not to tip cashiers in\nretail or grocery stores\u201d\n\u2013 Why: This requirement can be the hardest to as-\nsess because of its subjectivity. RoTs that are too\nspeci\ufb01c are usually slight modi\ufb01cations of the sit-\nuation that include a judgment, and don\u2019t describe\nunderlying expectations. RoTs that are too vague\noften do describe norms, but the link to the situa-\ntion can be so distant as to be misleading. Good\nRoTs may be somewhat speci\ufb01c, but explain both\nthe underlying norms at play, and apply to other\nsituations.\n\u2013Distinct ideas. When multiple RoTs are provided for\na situation, each should contain a distinct idea. This\nincludes inversions of the same idea.\n\u2013Example situation: Never taking out the trash\n\u2013 Violates: \u201cIt\u2019s irresponsible to avoid the chores\nyou are assigned\u201d with \u201cIt\u2019s bad to not do chores\nyou\u2019re supposed to do\u201d\n\u2013 Violates: \u201cIt\u2019s irresponsible to avoid the chores\nyou are assigned\u201d with \u201cIt\u2019s responsible to do the\nchores you are assigned\u201d\n\u2013 Follows: \u201cIt\u2019s irresponsible to avoid the chores\nyou are assigned\u201d with \u201cYou\u2019re generally expected\nto have a clean home\u201d\n\u2013 Why: This requirement is to prevent merely col-\nlecting paraphrases of the same RoT. Furthermore,we assume that inversions are usually trivial se-\nmantic mutations, so they are also not worth col-\nlecting at scale.\nA.4 RoT Breakdowns\nIn this section, we provide more information about\nthe structural RoT annotations, which we call \u201cRoT\nBreakdowns.\u201d In particular, we illustrate the poten-\ntial values for each attribute with an example.\nA.4.1 RoT Categorization\nRoT categories are originally designed to dis-\ntinguish more desired annotation topics (moral-\nity/ethics, social norms) from less desired ones\n(advice and \u201cit is what it is\u201d statements). RoT cate-\ngories are not mutually-exclusive, and the lines are\nnot always clear. While we use all data regardless\nof RoT category in this paper\u2019s experiments, future\nwork using this dataset may consider \ufb01ltering based\non RoT category. Annotators are allowed to select\nfrom none through all, but are encouraged to select\nthe 1 \u2013 2 best.\nInformation\nType\n Social\nAnnotated RoT\nPrompt What category best \ufb01ts this RoT?\nValues\nLabel Description Example\nMorality/\nEthicsRules or guiding\nprinciples of right\nor wrong conductIt\u2019s wrong to turn\nyour back on your\nfriends who need\nyour help.\nSocial\nNormsStandards of\nappropriate behav-\nior in a society;\nemphasizes social\nconventionsIt\u2019s good to shake\nhands with your\nopponent even if\nyou lost.\nAdvice Prudent behaviors\nthat are aimed at\nimproving one\u2019s\nlifeIt\u2019s good to take\nmedicine your doc-\ntor prescribes.\nIt is what it\nisDescribes how\nthings are; avoids\nethics, morality or\nsocial normsIt is nice to be tall.\nA.4.2 Moral Foundations\nTo simplify the annotation, we label axes of moral\nfoundations. For example, Care/Harm are anno-\ntated together, rather than as Care andHarm sepa-\nrately. Other social attributes, such as social judg-\nment , attempt to explicitly capture the goodness\nor badness of the act. Additionally, we omit the\nsixth moral foundation, Liberty/Oppression , which\nwas later added to the formalism after the \ufb01rst \ufb01ve.\nSome examples are drawn from literature on Moral\nFoundations (Haidt, 2012). Note that these labels\nare not mutually exclusive, and annotators may\nchoose from none through all.\nInformation\nType\n Social\nAnnotated RoT\nPrompt Which moral foundations best \ufb01t this RoT?\nValues\nLabel Description Example\nCare/Harm Preventing or in-\n\ufb02icting pain or suf-\nferingIt\u2019s mean to tell\nsomeone they\naren\u2019t attractive\nas someone else.\nFairness/\nCheatingNotions of equity,\njustice, and rightsIt\u2019s wrong to copy\nsomeone else\u2019s an-\nswers in an exam.\nLoyalty/\nBetrayalObligations or\nconcerns for\ngroup, family, and\nnation.It\u2019s rude for a\ncheerleader to boo\ntheir own team.\nAuthority/\nSubversionSubmission and\ndeference to tradi-\ntions or legitimate\nauthority.It\u2019s rude to walk\naway from your\nboss while they\nare talking to you.\nSanctity/\nDegrada-\ntionAbhorrence for\ndisgusting things\nor actions; purityIt\u2019s disgusting to\npee into a public\npool full of people.A.4.3 Action and Judgment\nEach RoT should contain and action and a judg-\nment. An essential step in the RoT brekadown is to\nidentify the action so that it may be annotated with\naction attributes. We have annotators write both the\naction and the judgment, conjugating to the action\nto gerund tense, and rewriting when needed.\nIf the annotator is unable to clearly separate and\naction and a judgment from the RoT, they can sim-\nply mark the RoT as unclear and move on.\nWe provide here a few examples of RoTs along\nwith corresponding actions and judgments. Some\nare straightforward, while others require more sub-\nstantial rewriting.\n\u2013RoT: It\u2019s good to care for the elderly.\n\u2013 Action: caring for the elderly\n\u2013 Judgment: it\u2019s good\n\u2013RoT: It\u2019s okay to be angry if your friend talks to some-\none you used to date\n\u2013 Action: being angry when your friend talks to\nsomeone you used to date\n\u2013 Judgment: it\u2019s okay\n\u2013RoT: The holidays are expected to be especially dif\ufb01cult\nfor those that are grieving.\n\u2013 Action: \ufb01nding the holidays dif\ufb01cult while griev-\ning\n\u2013 Judgment: expected\nA.4.4 Agency\nIt can be challenging to distinguish agency from\nexperience in cases where the action involves think-\ning thoughts or feeling emotions. We provide the\nfollowing additional examples to workers for these\ncases, and allow their discretion during the annota-\ntion:\n\u2013Experience: Feeling upset when someone calls you a\nname\n\u2013Agency: Being mad for two days when someone calls\nyou a name\n\u2013Agency: Taking revenge on someone for calling you a\nname\nInformation\nType\n Social\nAnnotated Action\nPrompt Is the action $action something you do or\ncontrol, or is it something you experience?\nValues\nLabel Description Example\nAgency You can do this Doing the dishes\nExperience This happens to\nyou; you have no\ncontrolBeing stuck in an\nearthquake\nA.4.5 Social Judgment\nFor social judgment, we ask workers to tran-\nscribe the intent of RoT\u2019s original judgment,\nrather than pick their own. Then, workers can\nmark their disagreement through their anno-\ntation of the anticipated agreement attribute.\nThis allows us to faithfully capture controversial\nopinions, while also marking them as controversial.\nInformation\nType\n Social\nAnnotated Action\nPrompt Which best matches the RoT\u2019s original judg-\nment ( $judgmentSpan ) of $action ?\nValues\nLabel Description Example\nVery bad Spiteful, malicious,\nor insultingSlashing tires; De-\nstroying someone\u2019s\nphone\nBad Frowned upon,\nrude, unkind, badLittering; saying\nsomething mean to\na friend\nExpected /\nOKNormal; generally\nexpected by soci-\netyWearing clothes;\nshowing up to\nwork on time\nGood Kind of consider-\nateDriving a friend to\nthe airport\nVery good Generous, self-\nsacri\ufb01cing, per-\nhaps even heroicBuying groceries\nfor a \ufb01nancially\nstruggling neigh-\nbor\nA.4.6 Anticipated Agreement\nAnticipated agreement is theoretically continuously\nvalued, compared to other attributes that are more\nnaturally ordinal. Inspired by Wang et al. (2018),\nwe bin this attribute into intuitive ranges, primarily\nto reduce cognitive load during annotation.\nInformation\nType\n Social\nAnnotated RoT, Action\nPrompts RoT: What portion of people probably agree\nthat $RoT ?\nAction: What portion of people probably\nagree that $action is $socialJudgment ?Values\nLabel Description Example\n<1% Almost no one Murdering people\nis great\n\u00185\u201325% People occasion-\nally think this.Ghosts exist\n\u001850% Controversial\n(people naturally\ndisagree)It\u2019s okay to have\nan abortion\n\u001875\u201390% Common belief It\u2019s okay to try\nagain when you\nfail\n>90% Universally true It\u2019s bad to delib-\nerately hurt your\npets\nA.4.7 Legality\nAnnotations of legality are usually straightforward.\nWhether an action is illegal but tolerated can vary\ndepending on location and knowledge of the law.\nInformation\nType\n Social\nAnnotated Action\nPrompt Where you live, how legal is the action\n$action ?\nValues\nLabel Description Example\nIllegal Legal conse-\nquences if caughtTheft; murder\nDepends/\nToleratedGenerally \u201cille-\ngal\u201d, but often\nunenforced\ndepending on\ncircumstancesUsing a cellphone\nwhile driving\nLegal Not illegal Coughing without\ncovering one\u2019s\nmouth\nA.4.8 Cultural Pressure\nWe provide instructions that cultural pressure\ncould come from one\u2019s family, friends, community,\nculture, or society at large. We ask annotators to\nevaluate cultural pressure according to their own\nfeelings.\nInformation\nType\n Social\nAnnotated Action\nPrompt How much cultural pressure do you (or those\nyou know) feel about $action ?\nValues\nLabel Description Example\nStrong pres-\nsure againstCulture frowns\nupon this actionIntentionally\nharming an\nanimal\nPressure\nagainstCulture generally\ndiscourages this\nactionSpending money\non jewelry if you\ncan\u2019t afford it\nDiscretionary Culture has little\nor nothing to say\nabout this actionChoosing to read\nbefore bed\nPressure\nforCulture generally\nencourages this ac-\ntionBeing honest with\npeople\nStrong pres-\nsure forCulture strongly\npromotes this\nactionWearing clothes in\npublic\nA.4.9 Taking Action\nRoTs are written for a range of both hypothetical\nand actual actions related to the provided situation.\nFurthermore, sometimes the action is one that is\nexplicitly not happening. This attribute labels how\nlikely it is that the action is being taken by the\nrelevant character. Note: a subset of the r/AITA\nannotations were performed before the \u201cprobably\nnot\u201d label was introduced; for those, \u201chypothetical\u201d\nis marked instead.\nInformation\nType\n Grounded\nAnnotated Action\nPrompt Is$candidateCharacter explicitly doing the\naction $action ? Or is it the action might\nhappen?\nThe upcoming examples use narrator and the\nfollowing situation for context: Not tipping the\nbartender at the club.\nValues\nLabel Description Example\nExplicitly\nnotIt\u2019s explicitly writ-\nten that they don\u2019t\ndo thisTipping the bar-\ntender\nProbably\nnotMost likely not;\nthey probably\ndon\u2019t do thisEnjoying the\ndrinks\nHypothetical We can\u2019t say / no\nevidenceGoing clubbing ev-\nery day\nProbable Most likely; hints\nare writtenPaying for drinks\nExplicit It\u2019s written in the\nsituationGoing to the clubA.5 Crowdsourcing\nWorkers undergo an extensive vetting process be-\nfore working on RoTs. This includes a paid quali\ufb01-\ncation (qual) with a quiz on each of the guidelines\nand a manual review of sample RoTs. Workers then\npass the qual move to a staging pool where they\ncan work on a small number of situations, and all\nof their RoTs are manually reviewed for adherence\nto the guidelines. After graduating from the staging\npool, workers enter the main group of RoT writ-\ners and annotators. For every batch of data, we\nperform spot checks on the RoTs written and anno-\ntated by the main group, as well as send feedback\nto all of the workers answering any questions we\nreceive. We continuously update the instructions\nwith clari\ufb01cations, new examples, and answers to\nquestions.\nA.6 Annotator Demographics\nWith an extensive quali\ufb01cation process, 137 work-\ners participated in our tasks. Of those, 55% were\nwomen and 45% men. 89% of workers identi\ufb01ed\nas white, 7% as Black. 39% were in the 30-39 age\nrange, 27% in the 21-29 and 19% in the 40-49 age\nranges. A majority (53%) of workers were single,\nand 35% were married. 47% of workers considered\nthemselves as middle class, and 41% working class.\nIn terms of education level, 44% had a bachelor\u2019s\ndegree, 36% some college experience or an asso-\nciates degree. Two-thirds (63%) of workers had no\nchildren, and most lived in a single (25%) or two-\nperson (31%) household. Half (48%) our workers\nlived in a suburban setting, the remaining half was\nevenly split between rural and urban. Almost all\n(94%) of our workers had spent 10 or more years\nin the U.S.\nA.7 Demographics and Annotations\nWe analyze the demographic variation in RoT and\naction annotations, using a set of 400 RoTs that\nwere annotated by 50 workers each. In addition\nto the demographic variables described in \u00a7A.6,\nwe also consider the political leaning of the state\nin which the worker resides (self-reported), by as-\nsigning each state a value based on the state-level\nvoting patterns in the last four national elections\n(yielding \ufb01ve-point scale from 100% republican to\n100% democratic).\nFor our analyses, we run a generalized linear\nmodel regressing the RoT categories on all z-\nscored demographic variables, and report the \f\nRoT Agree-\nmentAction\nAgreementCultural\nPressureSocial Judg-\nment\nGender (M: 0, F: 1) 0.070\u0003\u0003\u00030.104\u0003\u0003\u0003n.s. n.s.\nUrbanness 0.065\u0003\u0003\u00030.085\u0003\u0003\u0003n.s. n.s.\nEducation 0.022\u0003\u00030.037\u0003\u0003\u0003n.s. 0.025\u0003\u0003\u0003\nPolitics (rep: 0, dem: 1) 0.052\u0003\u0003\u00030.075\u0003\u0003\u00030.023\u0003\u0003n.s.\nHousehold size 0.059\u0003\u0003\u00030.080\u0003\u0003\u0003n.s. n.s.\nSocial class n.s. n.s. n.s. n.s.\nIncome -0.027\u0003n.s. n.s. n.s.\nAge n.s. n.s. n.s. n.s.\nTable 5: Correlations between worker demographics and categorical RoT annotations, Bonferroni corrected for\nmultiple comparisons ( p<0:0001 :\u0003\u0003\u0003,p<0:001:\u0003\u0003,p<0:01:\u0003).\ncoef\ufb01cients from that model. In our action moral\njudgment analyses, we control for actions; for ac-\ntion agreement, we control for the action and the\nmoral judgement; for the RoT agreement and ac-\ntion pressure, we control for individual RoTs. Our\nresults for categorical RoT annotations are shown\nin Table 5.\nAgreement (RoT and Action) The projection of\nhow many people agree with the judgement is cor-\nrelated with various demographic characteristics.\nSpeci\ufb01cally, judgments of actions, being a woman\nand living in an urban setting was most strongly\ncorrelated with ascribing high agreement to the\njudgment. Other associations include higher educa-\ntion, household size, and inferred political leaning\nbased on state of residency.\nFor RoT agreement, we \ufb01nd similar but weaker\nassociations. Additionally, we \ufb01nd a small correla-\ntion between income and social class and ascribing\nhigher agreement.\nCultural Pressure The only variable correlated\nwith feeling culturally pressured is the political\nleaning of the state where workers are located,\nthough the effect is small.\nSocial Judgment Similar to action agreement.\nEffects are somewhat weaker, but workers being\nwomen, highly educated, or younger are associated\nwith selecting higher (better) judgment to actions.\nB Experimental details\nGenerative Models We use the Transformers\npackage (Wolf et al., 2019) to implement our\nmodels. We train all the models for a single\nepoch with a batch size of 64, with the ran-\ndom seed 42. Each input and output sequenceis pre\ufb01xed with a special token indicating its\ntype (e.g. [attrs], [rot], [action] ).\nWe also de\ufb01ne a special token for each attribute\nvalue (e.g.<morality-ethics >,<bad>,\n<all>,<against>). We initialize the spe-\ncial token embeddings with the embedding of\ntheir corresponding words, taking the average for\nmultiword expressions. For example, ~ v<bad>=\n~ vbad;~ v<morality-ethics >= (~ vmorality +~ vethics)=2.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Social chemistry 101: Learning to reason about social and moral norms", "author": ["M Forbes", "JD Hwang", "V Shwartz", "M Sap"], "pub_year": "2020", "venue": "arXiv preprint arXiv \u2026", "abstract": "Social norms -- the unspoken commonsense rules about acceptable social behavior -- are  crucial in understanding the underlying causes and intents of people's actions in narratives."}, "filled": false, "gsrank": 313, "pub_url": "https://arxiv.org/abs/2011.00620", "author_id": ["sF1vZ0oAAAAJ", "9QuMhLgAAAAJ", "bbe4ResAAAAJ", "gFN4QUYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:vAxICp_OFDkJ:scholar.google.com/&output=cite&scirp=312&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=vAxICp_OFDkJ&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 315, "citedby_url": "/scholar?cites=4113139542163721404&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:vAxICp_OFDkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2011.00620"}}, {"title": "Decoding Health-Seeking Queries Related to Antiretroviral Therapy in Philippine HIV Awareness Facebook Groups", "year": "2025", "pdf_data": "ISSN Print: 2984 -8288, ISSN Online: 2984 -8385 \nVol. 3 No. 9, pp. 447-456, September  2025 \n  \n \nThis work is licensed under a Creative Commons Attribution -Noncommercial 4.0 International License (CC BY -NC  4.0).  \n \n \nDecoding Health -Seeking Queries Related to Antiretroviral \nTherapy in Philippine HIV Awareness Facebook Groups   \n \nJhelsey Kane A. Ogaccan1, Eryll Shane D. Lantaen2, Jasmine P. Gados3, Karla Angeli P. Adaoag4,  \nWarell C. Tailan5, Anghello S. Chaangan6, Katrina Nicole E. Cosme7, Jenelyn A. Coop8, \n Christian E. Angga -o9, Karen B. Pandoyos10, and Jayson M. Bimuyag*11 \nDepartment of Nursing, Easter College, Baguio City, Philippines  \n \n*Corresponding Author Email: jaysonbimuyag@gmail.com     \n \nDate received : June 21 , 2025        Originality : 92% \nDate revised : August 1 , 2025        Grammarly Score : 99%  \nDate accepted : August 21, 2025        Similarity : 8% \n \nRecommended citation:   \nOgaccan, J.K., Lantaen, E.S., Gados, J., Adaoag, K.A., Tailan, W., Chaangan, A., Cosme, K.N., Coop, J., Angga -o, \nC., Pandoyos, K., & Bimuyag, J. (2025). Decoding health -seeking queries related to antiretroviral therapy in \nPhilippine HIV awareness Facebook groups . Journal of Interdisciplinary Perspectives , 3(9), 447-456. \nhttps://doi.org/10.69569/jip.2025.521      \n \nAbstract . This study explored how members of Philippine HIV awareness Facebook groups express health -\nseeking queries related to antiretroviral therapy. Despite widespread challenges in accessing and adhering \nto HIV treatment across the Philippines, limited research has examined online health queries within this \ncontext. A qualitative content analysis of 304 posts and 44 comments from two Facebook groups dedicated \nto raising HIV awareness was conducted, covering the period from January to December 2024. Data \nanalysis resulted in three key categories: Seeking Assurance, Seeking Guidance, and Seeking Access. The \nmembers' queries revealed prevalent anxiety about antiretroviral therapy side effects, alongside notable \ngaps in knowledge related to treatment effectiveness and  access challenges. These queries underscore the \nimportance of addressing both individual concerns and systemic barriers to enhance ART adherence and \nimprove health outcomes among people living with HIV in the Philippines.  \n \nKeywords:  Antiretroviral therapy; Facebook groups; Health -seeking queries; HIV awareness.  \n \n1.0 Introduction  \nAntiretroviral therapy (ART) plays an essential role in addressing the progression of HIV (Human \nImmunodeficiency Virus) by inhibiting virus replication, enhancing immune response, and lowering transmission \nrisk. Recently, evidence has firmly established t he concept of undetectable = untransmittable, or U=U, meaning \nthat people living with HIV (PLHIV) who are taking ART daily as prescribed can maintain and achieve an \nundetectable viral load and cannot transmit the virus to others ( NIAID, 2019; CDC, 2023; P AC, 2024). For ART to \nbe effective, it must be taken exactly as prescribed, with no missed doses, ensuring HIV does not multiply again \n(Fletcher & Sherrel, 2023). However, ART is not a cure for HIV, as the virus persists in the body tissues even when \nits lev els are undetectable; the drugs work together to inhibit its growth ( IAPAC , 2024).  \n \nThe Philippines presents an essential context for examining ART -related health -seeking behavior, as it currently \nexperiences the fastest -growing HIV epidemic in the Western Pacific region. Between 2012 and 2023, the daily \nincidence of HIV surged by an over whelming 411% (CDC, 2024). This surge is evidenced by a recent report from \n(HARP , 2024), which shows that as of March 2024, of the estimated PLHIV , 122, 241 cases (57%) have been \ndiagnosed or laboratory confirmed and are currently alive or have not been reported as deceased. Additionally, \n \n448 79, 643 PLHIV (65%) are receiving ART, with 35, 277 (44%) of them having undergone viral load (VL) testing in \nthe past 12 months; among those tested for VL, 30, 996 (88%) achieved viral suppression, but only 39% of PLHIV \non ART were found to be virally sup pressed. Data collected from the Department of Health (DOH, 2024) indicate \nthat from January to June 2024, 8,727 individuals were confirmed as PLHIV, of which 8,518 were enrolled in ART, \nwith 4,402 on first -line therapy, 11 on second -line therapy, and 105 on another line of treatment, while 84, 086 \nindividuals have continued on ART since 2002; these reports highlight the significant challenge of managing HIV \nin the Philippines and the need for effective strategies to address the growing number of cases. The  daily use of \ncombination HIV medications has contributed to longer, healthier lives and significantly reduced the risk of HIV \ntransmission ( NIH , 2021). The Philippines has 224 main HIV care facilities and treatment centers, according to \nDOH (2024). The need for more knowledge of the barriers to access and adherence is underscored by the disparity \nthat still exists between the population of PLHIV and those receiving ART on a national scale. This disparity \nhighlights the importance of examining the mechanics of ART and its limitations in achieving effective  use. \nAddressing the ongoing obstacles to ART access and adherence requires this knowledge.  \n \nDespite the apparent effectiveness of ART, PLHIV still encounter barriers when trying to get treatment and follow \ntheir medication regimens. Among these barriers are financial constraints and concerns about encountering \nfriends in the clinic (Abdulai et al ., 2023). Furthermore, according to the same study, specific  stakeholders \nmentioned in their interviews that treatment adherence and viral suppression were adversely affected when \npatients missed clinic appointments, resulting in non -adherence to medicatio n and ultimately harming viral \nsuppression. They credited this default response to factors such as stigma and non -disclosure. Additionally, the \npersistent stigma associated with HIV resulted in discrimination and other adverse social experiences, directly \nadding to the hesitation of people to seek treatment or continue their regimen (Gangcuangco, 2019). With 44% of \npatients who missed a dosage at some point stating that they did so to avoid being seen taking their prescription, \nO'Connor et al. (2021) demons trated that stigma was a significant factor impacting adherence. These challenges \nhighlight the need for innovative approaches to the difficulties that PLHIV face to this day.   \n \nConsidering these challenges, innovative approaches that utilize social media and technology may be crucial in \npromoting support and improving treatment adherence. According to Ibrahim et al. (2024), social media has \nbecome a vital platform for exchanging information, providing support, and fostering connections. Furthermore, \nonline communities give people with health issues \u2014like those who have HIV or AIDS \u2014the chance to ask peers \nfor information, counsel, and support (Coulson & Buchanan, 2022). Facebook gro ups serve as spaces for users to \ndiscuss sensitive health topics and inquire about health information while maintaining anonymity and managing \nstigma, particularly within HIV -focused Facebook groups in the Philippines. These platforms are significant given  \nthe stigma associated with HIV, which hinders individuals from seeking help and support.  \n \nAs Facebook is commonly used as a tool for sharing, it is also utilized for its innovative and widespread \nadvantages. Beyond its informational value, Facebook offers vital peer -to-peer support, meeting the demand for \nemotional understanding and camaraderie  among individuals facing similar health issues (Khan et al., 2022). \nSocial network sites like Facebook offer a convenient and familiar method for individuals to draw on coping \nresources; the use of these platforms is linked to higher levels of bridging so cial capital, allowing access to \ninformation and resources from a diverse range of acquaintances and bonding social capital, leading to the \nprovision of emotional support from close friends (Chen & Lemmer, 2024). As a result, many organizations utilize \nsocial media, particularly Facebook, to mobilize social change and raise awareness about important issues.  \n \nHowever, a significant challenge to the effectiveness of social media for health information is the prevalent \nmisinformation. A study by Th\u00e9ro and Vincent (2022) found that misinformation, including manipulated statistics, \nfake news, or altered images, pos es a significant challenge to the credibility of information. This misinformation \nmisleads users by presenting false contexts, potentially causing them to form incorrect beliefs or make uninformed \ndecisions. Between 2019 and 2021, websites flagged for repe atedly sharing misinformation on Facebook saw a \nmedian 41 \u201347% drop in engagements per article. Groups with a \"repeat offender\" label experienced a 31% decrease \nin engagement per post, while their posting behaviors remained essentially unchanged. The percen tage of posts \nassociated with low -credibility sources stayed around 10% both before and after warnings, according to \nmediabiasfactcheck.com, an independent website that rates the bias, factual accuracy, and credibility of media \nsources to raise awareness o f media bias and misinformation (Media Bias Check, 2024). Despite the potential \n \n449 advantages of social media for HIV treatment adherence, the abundance of false information presents a serious \nobstacle.   \n \nSocial media platforms, especially Facebook, despite the problems caused by false information, allow PLHIVs to \nreceive assistance. Social media has become an established public forum where people gather to exchange illness \nnarratives, information seeking, and engage in health -seeking activities (Zhang et al., 2020). This multifaceted idea \nhighlights the challenges faced by members in managing their medical needs. Recent research by Khan et al. (2022) \nexamined the use of social media in chronic pain manageme nt and health communication, as well as the health -\nseeking behaviors reflected in members' posts on COVID -19-themed Facebook groups (Sahin et al., 2021). \nMembers of these HIV awareness Facebook groups posted health queries regarding ART, but the context of  these \nposts was unclear. This lack of understanding highlighted the need for studies focusing on the unique \ncircumstances of Facebook groups in the Philippines that are related to HIV. Emphasizing the context of members' \nposts and comments, this study aim s to explore how members of Philippine HIV awareness Facebook groups \nexpress health -seeking queries related to ART, to inform health communication strategies that can reduce stigma \nand improve outcomes.  \n \n2.0 Methodology  \n2.1 Research Design  \nUsing qualitative content analysis, the researchers analyzed ART -related health -seeking queries in Philippine HIV \nawareness Facebook groups. They identified relationships between keywords and concepts related to ART and \nhealth -seeking queries by examining the co -occurrence of phrases from the Fa cebook group members' posts and \ncomments. This design, which highlights the relationships between concepts and their context, is suitable for \nanalyzing data from online communities (Jansen, 2025).  \n  \n2.2 Sources of Data  \nThis study utilized data from two Facebook groups in the Philippines dedicated to HIV awareness: \"HIV AIDS \nAwareness Philippines\" (originally public, but later became private, with 14,100 members) and \"HIV Awareness \nPhilippines\" (a private group with 36,30 0 members). These groups were selected due to their large membership, \nlively discussion forums, and diverse range of viewpoints on HIV, which contributed to the extensive dataset used \nto analyze ART \u2013related health -seeking queries. The analysis focused on the members\u2019 pre-existing posts and \ncomments from January to December 2024. Using easily accessible data to conduct a timely and cost -effective \nstudy, expanding upon existing knowledge in the field (Nieswiadomy & Bailey, 2018).  \n \n2.3 Data Gathering Procedures  \nThe researchers began gathering data by searching Facebook for relevant groups using keywords such as \"HIV \nAwareness Philippines.\" They screened 27 groups based on relevance, activity, and public accessibility, and six \ngroups were granted access. The resea rchers then excluded four groups due to insufficient relevant content, \nleaving two groups for analysis. Using Facebook's search feature and advanced filters, they identified relevant \nposts and comments from January to December 2024 within these groups. The y applied terms such as \"ART,\" \n\"ARV,\" \"Antiretroviral Therapy,\" and specific medicine names. They identified and reviewed a total of 3 04 posts \nand 4 4 comments to ensure alignment with the study's focus.  \n \n2.4 Data Analysis  \nThe researchers analyzed the identified posts and comments, adhering to the practical guidelines for content \nanalysis outlined by Erlingson and Bysiewicz (2017). Before beginning the study , they carefully considered their \npersonal biases to ensure objectivity. Following data collection, an initial review was conducted to identify and \ncondense meaning units \u2014brief segments of text conveying a single idea \u2014while preserving the core message  of \neach post and comment . From these condensed meaning units, codes were  developed to represent the contextual \nmeaning of the data. Two coding strategies \u2014a priori coding and emergent coding \u2014were employed to ensure the \nstudy's validity. A cod e book was developed through discussions and consultations among the research team and \nwith the research adviser.  \n \nInter-coder reliability  was also established to ensure consistency and accuracy. The researchers were divided into \nsubgroups. Guided by the developed coding scheme, e ach subgroup independently analyzed the same subset of \n \n450 data \u2014ten percent of the total data.  The subgroups reunited to compare their coding output and calculate inter -\ncoder reliability. They divided the number of agreed -upon codes by the total number of coded data items. This \nprocess provided an unbiased evaluation of coding consistency. An agreement  rate of 90 percent or higher is \nconsidered appropriate for post -positivist qualitative research  (Tracy , 2013). The achieved inter -coder reliability \nscore was 94.1%. This high level of agreement supported the assumption of consistent coding, enabling \nindependent analysis. To gain a deeper understanding of how Facebook group members expressed their ART -\nrelated  queries, these codes were organized into broader categories that captured the overall meaning. By \nclustering similar codes, the researchers interpreted the health -seeking queries related to ART. Concurrently, the \ncodes were tallied and presented in freque ncies and percentages (Java, 2024).  \n \nFinally, to enhance data accuracy, the results were disseminated and shared with two selected Facebook groups \nfor confirmation and refinement. The members provided positive feedback, and administrators from both groups \nconfirmed the researchers' categoriza tion of posts and comments related to ART queries.  \n \n2.5 Ethical Consideration  \nBefore data gathering, the researchers obtained formal permission from the Dean of the Department of Nursing \nof Easter College. Next, they communicated with the administrators or moderators of the Facebook groups, \nexplaining the study's purpose, discussing  its potential impact on the group, and requesting permission to collect \ndata. To protect privacy and ensure the anonymity of Facebook members, the researchers used pseudonyms. They \nparaphrased the posts and comments, as recommended by Zhang et al. (2024),  to prevent easy identification by \nsearch engines.  \n \n3.0 Results and Discussion  \nAnalysis of the health -seeking queries related to ART in Philippine HIV awareness Facebook groups revealed \nthree  key categories: Seeking Assurance, Seeking Guidance, and Seeking Access. Table 1 presents a detailed \ncategorization of the members\u2019 posts and comments across these categories.   \n \nTable 1. Categorization of health -seeking posts and comments related to  ART   \nCategory  Code  Posts  Comments  \nSeeking Reassurance  Side effect -related  anxiety  118 ( 38.82 %) 15 (34.09 %) \n Doubts and ART effectiveness  22 (7.24%) 2 (4.55%) \nSeeking Guidance  ART comparison s 30 (9.87%) 4 (9.09%) \n Worries about missed  dose s  28 (9.21%) 3 (6.82%) \n Correct ART intake practices  21 (6.91%) 1 (2.27%) \n ART and medication compatibility  22 (7.24%) 2 (4.55%) \n Food and ART restrictions  11 (3. 62%) 2 (4.55%) \n Clarification request s 0 (0.00%) 5 (11.36 %) \n ART formulation inquiries  1 (0.33%) 1 (2.27%) \nSeeking Access  ART and access challenges  51 (1 6.78%) 9 (20.45 %) \nTotal   304 (100.00 %)  44 (100.00%)  \n       \n3.1 Seeking Assurance   \nFrequent health -seeking queries related to ART were a  usual way members  sought assurance. Their posts and \ncomments often voiced concerns about ART side effects and doubts regarding the treatment's effectiveness .  \nSide effect -related  anxiety  \nBy far, anxiety related to ART side effects was the most common concern , with members expressing significant \nconcern about long -term implications and seeking assurance regarding their potential permanence . Examples of \nthese posts and comments are provided below:  \n\u201cI am about to start my ART today and would like to know the common side effects I might experience. It will help me prepare \nand understand what to expect during treatment. Thank you.\u201c ( Anonymous Post #50)   \n\u201cI recently switched from LamiZido Efavirenz to TLE 3 -in-1, and I am experiencing severe side effects, including headaches, \nbody aches, back pain, increased anxiety, and difficulty sleeping. These symptoms are much more intense than what I \nexperienced with  my previous medication. Is this normal?\u201d (Anonymous Post #87)   \n \n451 \u201cFor those of you who are HIV positive and taking ARVs, what side effects have you experienced? I have gained weight, felt \nbloated, and had frequent bowel movements. How about your experience, guys?\u201d (Identified Post #56)  \n\u201cI started LTE after a recent HIV diagnosis. I'm experiencing dizziness and difficulty standing. Is this a common side effect ?\u201d \n(Anonymous Post #148)  \n\u201cAm I the only one experiencing a rash from TLD? When can I expect these rashes to subside? I have been on medication for \na month, but still get new rashes, and I am also experiencing significant hair loss.\u201d (Anonymous Post #245)    \n\u201cI have noticed weight gain since starting TLD. Why does this happen?\u201d  (Identified Comment #33)   \n\u201cAre there any side effects from taking ART medications? I have been on it for two months and would like to know.\u201d \n(Anonymous Comment #19)  \n\"I have been on the TLE 3 -in-1 regimen for a year and have been experiencing side effects consistently. It  is starting to feel \nlike these side effects are becoming a normal part of my treatment, which is concerning.\" (Anonymous Comment #36)  \nDoubts and ART effectiveness  \nBeyond concerns about side effects, several posts and comments expressed doubts about ART's effectiveness, \nincluding questions about treatment in advanced HIV stages, transmission risk, time to undetectable viral load, \nand viral load fluctuations despite a dherence . Examples of these posts and comments are provided below:  \n\u201cCan someone in the final stage of HIV (AIDS) still receive ARV treatment? What are the chances of living for another 20 to \n30 years with this treatment?\u201d (Identified Post #282)   \n\u201cI have been on TLD for nearly two months and will soon reach three months. I recently had unprotected sex with someone. \nIs there a 100% chance they will get infected with HIV, considering my treatment status?\u201d (Anonymous Post #201)  \n\u201cI recently started ARV treatment and have been on it for five months. How long does it typically take for someone to achieve  \nan undetectable viral load?\u201d (Anonymous Post #223)   \n\u201cMy viral load increased despite my ARV treatment. What additional strategies can help me lower my viral load? \u201d \n(Anonymous Post #120)  \nThe notable prevalence of anxiety linked to ART use among the members aligns with recent reports of an increase \nin ART -related adverse events and treatment discontinuations (De Oliveira et al., 2024). The members' concerns \nranged from mild issues such as nausea to more severe effects, including persistent s kin reactions and significant \nweight gain, consistent with known clinical side effects of ART toxicity affecting gastrointestinal and \nneuropsychiatric systems. The study highlighted a substantial number o f treatment interruptions due to these side \neffects, underscoring the need for better patient support and management strategies. Additional literature \ncorroborated these observations, with Hurbans and Naidoo (2024) reporting high adverse event rates and Ei fa & \nKetema (2022) linking weight gain specifically to dolutegravir -based regimens. The impact of side effects on \nadherence was evident in the frequency of inquiries in the Facebook groups (Sombrea, 2024). Additionally, \nclarifications on ART terminology an d drug formulations reflected findings from Li et al. (2024), who noted \nindividual variability in responses to ART. Collectively, the study underscored the importance of proactively \naddressing patient concerns to improve ART adherence outcomes.  \n3.2 Seeking Guidance  \nMany queries focus on seeking guidance on a variety of ART -related topics , such as ART comparisons, correct \nART intake practices, missed doses, ART and food restrictions, clarification requests, and inquiries about ART \nformulation.  \n \nART comparison s \nDiscussions frequently involved comparisons between specific ART medications, particularly LTE and TLD, with \nmembers seeking clarification on their relative potency, distinctions, and appropriate use cases.  Examples of these \nposts and comments are provided below:  \n \n452 \u201cIs LTE a more potent medication than TLD?\u201d (Anonymous Post #128)   \n\u201cWhat are the key distinctions between ARV medications, LTE, and TLD?\u201d (Anonymous Post #139)   \n\u201cGood morning, I have a question regarding ARV medications. Is it true that LTE is prescribed for early HIV diagnoses, \nwhile TLD or LTD are used for later -stage diagnoses? Thank you.\u201d  (Anonymous Post #135)   \n\u201cWhat are the differences between LTD and LTE?\u201d (Anonymous Post #129)    \n\u201cWhat is the difference between TLD and general ARV medications?\u201d (Identified Comment #24)   \n\u201cWhat is LTE, and how does it differ from the TLD regimen I am currently on?\u201d (Anonymous Comment #38)   \nWorries about m issed doses  \nConcerns regarding missed ART doses and their potential consequences were also observed.  Examples of these \nposts and comments are provided below:  \n\u201cI missed my HIV medication for the first time in a year for 7 hours. What are the possible effects of missing a single dose?  Is \nit likely to cause significant issues? I would appreciate advice from anyone who has experienced a similar situation. Thank \nyou.\u201d (Identified Post #31)   \n\u201cI consistently take my ARV (TLD) at 11 a.m. and have not missed a dose in a year. However, today I got distracted and \nforgot to take it. After eating, I mistakenly took tomorrow's dose. I tried to vomit but could not. Should I skip tomorrow's \ndose at 11 a .m.? Generally, if you have taken an extra dose.\u201d (Anonymous Post #152)  \n\u201cI have run out of my medication and have not taken it for about 8 days. Is this okay, or should I be concerned about the gap  \nin treatment?\u201d (Identified Post #273)  \n\u201cI am concerned because I am unsure if I have already taken my ARV medication. I was interrupted by a phone call while \ngetting my medicine, and now I am worried that I might have taken a double dose. My main fear is not the potential side \neffects, but rath er the risk of developing drug resistance.\u201d (Anonymous Post #11)   \n\u201cI am feeling anxious because I forgot to take my ARV medication for one day. Could someone please help me understand \nwhat might happen? I am worried and hope someone can notice me.\u201d (Anonymous Post #124)   \nCorrect ART intake practices  \nSeveral posts and comments addressed correct ART intake practices, covering topics such as timing, scheduling, \nand managing potential errors, as well as preferences for day versus night dosing.  Examples of these posts and \ncomments are provided below:  \n\u201cHello, fellow HIV - positive individuals. I have a question about taking LTE/TLD (ARV pills). Is it advisable to take the \nmedication with or without food? I currently take it after supper, and I am seeking guidance on the most effective approach.\u201d  \n(Anonymous Post #200)   \n\u201cI have recently changed from LTE to TLD, and I am unsure about the ideal time to take it. Also, how can I adjust the time I \ntake it without missing a dose or disrupting  my medication schedule? Thanks!\u201d (Anonymous Post #203)   \n\u201cMy TB medication is at 6 a.m., and I take my TLD at 8 a.m., and then additional medications at night. I accidentally took \nmy TLD dose for tonight. Is it safe to have TLD twice today, considering I still need to take my evening medications? Will \nthis be ha rmful?\u201d  (Anonymous Post #94)   \n\u201cFor those of you taking TLD, do you prefer to take it during the day or at night? I currently take it around 9 a.m. due to \nconcerns about insomnia as a potential side effect. I am interested in hearing about other people's experiences and preferenc es. \nPlease share your thoughts. Thanks!\u201d (Identified Post #116)    \n\u201cDo you take ARV medication every day?\u201d (Identified Comment #14)   \n\u201cCan you take ARV TLD immediately after eating, or is there a waiting period required? I am aware that LTE needs a 2 -hour \nfast before intake.\u201d  (Identified Comment #25)   \n \n453 ART and medication compatibility  \nMembers also sought guidance regarding the compatibility of ART and other medications . Inquiries included the \nsafety of taking other drugs concurrently with ART and the permissibility of using food supplements while on \nART. Examples of these posts and comments are provided below:  \n\u201cIs it safe to take high blood pressure medication while taking ART drugs? I would like to know.\u201d  (Anonymous Post #117)   \n\u201cI have a routine where I must take glutathione and vitamin C supplements at 8 p.m. daily. I would like to know if it is safe  \nto take this while on antiretroviral therapy.\u201d  (Anonymous Post #125)   \n\u201cI would like to know if there are possible interactions between Celebrex and antiretroviral therapy medications because I ha ve \nbeen prescribed Celebrex for a shoulder injury, and my healthcare provider is not available now.\u201d (Anonymous Post #173)   \n\u201cI am wondering because some people said that glutathione is permitted.\u201d ( Identified Comment #11)   \nFood and ART restrictions  \nWhile not as prevalent as other concerns, me mbers also a sked about their dietary restrictions whi le on ART, \nseeking clarification on c onflicting information from different sources . Examples of these posts are provided \nbelow:   \n\u201cI have read that certain foods must be avoided. However, my healthcare provider told me that there are no dietary restrictio ns. \nCould someone enlighten me regarding this discrepancy?\u201d (Anonymous Post #66)   \n\u201cCan I consume alcohol while on ARY? Is it safe? Thank you.\u201d  (Anonymous Post #271)   \n\u201cGood day! My partner will be starting ARV therapy next week and will have dietary restrictions for two months. Could you \nplease share what foods you ate during this period? I appreciate any responses.\u201d (Anonymous Post #153)  \n\u201cTake my TLD medication during dinner and occasionally have coffee with my meal. Is it safe to consume coffee while taking \nTLD? Please advise. Thank you!\u201d (Anonymous Post #184)  \nClarification request s \nIn an effort to better understand ART, members requested clarifications on both general principles and specific \ntreatment regimens.  Examples of these comments are provided below:  \n\u201cWhat is ARV?\u201d (Identified Comment #42)  \n\u201cWhat is TLD?\u201d (Identified Comment #22)   \nART formulation inquiries  \nA few members inquired about injectable ART options, driven by swallowing difficulties and a desire for more \nconvenient formulations, though this was not a common concern.  Only one post and one comment specifically \nrefle cted this type of inquiry . They are provided below:  \n\u201cI am having trouble swallowing ARV tablets, and when I try crushing them, I vomit. Is there truly no injectable version of \nARV LTE available?\u201d (Anonymous Post #167)    \n\u201cIs there an injectable form of ARV available, and if so, is it approved for use?\u201d (Identified Comment #17)   \nThe prevalence of ART comparison queries within the Facebook group s\u2019 data mirrored the clinical realities of ART \nregimen changes, which often arise due to treatment simplification, viro -immunological failure, or management \nof adverse events (Loghin et al., 2024). The numerous queries about practices related to taking ART, including the \ntiming of meals, adjusting to schedule changes, and what to do in case of accidental double doses, highlight the \nneed for easy -to-access, practical guidance on medication adh erence \u2014a key factor influencing treatment success \n(Akahome, 2023). This finding aligned with the established role of social media platforms in facilitating \ninformation -seeking behaviors among patients navigating complex health decisions, as shown by Zhu et al. (2 019) \nin the context of pregnancy -related information. The anxieties that members express regarding ART effectiveness, \nespecially concerning late -stage treatment, transmission risk, and fluctuations in viral load, reflect systemic issues \n \n454 identified by Gamayo (2025). The Facebook posts and comments provided detailed, real -world examples of these \nanxieties, offering valuable insights into the experiences of individuals managing their HIV treatment.  \n3.3 Seeking Access  \nART and access challenges  \nConcerns about accessing ART emerged as the second most frequent type of inquiry in the Facebook groups. These \nconcerns included logistical issues like misplacing medication, exploring alternative access methods, and \nnavigating financial constraints and in consistent access. Examples of these posts and comments are provided \nbelow:     \n\u201cDo health clinics offer free antiretroviral therapy or HIV treatment?\u201d (Anonymous Post #208)    \n\u201cI am in a difficult situation due to financial constraints and a recent transfer from a hub in a city. My new hub only provi des \none bottle of TLD, while my previous one gave three. I borrowed a bottle from a friend, but now I am almost out of medication . \nI have tried explaining my situation to my current hub, but they will not provide extra bottles, citing missed doses. Does \nanyone have an extra bottle of TLD they could spare? I am down to my last two tablets and would greatly appreciate any \nhelp.\u201d (Anonym ous Post #187)   \n\u201cCould you please tell me where the nearest HIV testing center and treatment hub is located in a city?\u201d (Anonymous Post \n#20)  \n\u201cWhat is the usual cost of antiretroviral (ARV) medications?\u201d  (Identified Comment #7)   \n\u201cI need to purchase ARV medication while I am in the city. Can you recommend where I can get it?\u201d (Identified Comment \n#15)  \n\u201cHello, I need help. Since the hub was closed earlier, I am looking for someone in the provincial area who uses LTE or the 3 -\nin-1 medication. My spouse is on it, so maybe I can borrow two tablets for now. I promise to return them tomorrow.\u201d \n(Identified Comment #18)   \nChallenges accessing ART, as discussed by members, align with existing literature highlighting systemic barriers \nto HIV care. Robles and Canoy (2019) described unwelcoming care facilities, limited resources, and stigma as \nsignificant obstacles to treatment  access. Prinsloo et al. (2017) further demonstrated that healthcare neglect \nconstitutes a form of stigma. Group members also cited long distances to clinics, work commitments, \nforgetfulness, and drug shortages as barriers to adherence, findings consistent  with those of Torres et al. (2021). \nConcerns regarding ART effectiveness, particularly in later HIV stages, mirrored systemic challenges highlighted \nby Gamayo (2025), including drug shortages and inadequate infrastructure disrupting continuous treatment. \nHowever, these findings contrast with the work of Carandang et al. (2025), who found that positive provider -\npatient interactions and accessible facilities significantly contributed to patient satisfaction in primary HIV care. \nCarandang et al. (2025) partic ipants emphasized welcoming providers, convenient facility locations, and short \ntravel times as positive factors. In contrast, Facebook group members highlighted logistical problems, financial \ndifficulties, inconsistent medication supplies, and difficultie s locating facilities \u2014issues further supported by \nGangcuangco and Eustaquio (2023), who emphasized that ART is dispensed solely through approved facilities, \nthereby creating access barriers, particularly in rural areas. Travel restrictions further exacerba ted these \nchallenges.  \n \n4.0 Conclusion  \nThis qualitative content analysis revealed that members of HIV Awareness Facebook groups in the Philippines \nused these platforms to seek assurance, guidance, and access to related ART. Their queries reflect anxieties about \nART effectiveness and side effects, the need for a comprehensive understanding of drug interactions, intake, and \nscheduling, and challenges in accessing medications due t o shortages, financial constraints, and logistical issues. \nThe members' reliance on digital peer support alongside professional health services suggests a need for \nintegrated approaches. To address these issues, collaboration among HIV -focused organization s, healthcare \nproviders, and local health agencies could develop or enhance existing digital health services, such as online \ncounseling and medication access initiatives. In addition to developing resources, efforts should be made to \nensure that existing o nline services are readily accessible and effectively reach the target population. Further \n \n455 research, exploring multiple online platforms and incorporating other data collection methods, such as \ninterviews, could provide a deeper understanding of the health -seeking behaviors among PLHIV in the \nPhilippines and inform more effective approaches for both resource development and dissemination.  \n \n5.0 Contribution of Authors  \nAll authors contributed equally to the conception and design of the study; the collection, analysis, and interpretation of da ta; drafting and critically reviewing the manuscript\u2019s content; final \napproval of the version to be published; and agreement to be accountable for all aspects of the study, ensuring that questions related to the accuracy or integrity of any part of the wor k were \nappropriately addressed and resolved.  \n \n6.0 Funding  \nThis study did not receive a grant from any funding organization.  \n \n7.0 Conflict of Interest  \nAll authors confirm that they have no conflicts of interest.  \n \n8.0 Acknowledgment  \nThe authors would like to express their heartfelt gratitude to the administrators of HIV AIDS Awareness Philippines, HIV Awar eness Philippines, and the Department of Health, Center for \nHealth Development, Cordillera Administrative Region, as well as the De partment of Nursing of Easter College, for their essential support and guidance throughout the research process. \nTheir collaboration and steadfast help have played a vital role in the successful completion of this study.  \n \n9.0 References  \nAbdulai, M. A., Mevissen, F. E. F., Marien, V., Ruiter, R. A. C., Owusu -Agyei, S., & Bos, A. E. R. (2023). A qualitative analysis of factors influencing the implementation of antiretroviral \ntreatment adherence policies in Ghana: Stakeholders\u2019 perspectives.  Health Research Policy and  Systems,  21(1).  https://doi.org/10.1186/s12961 -023-01010 -9 \nAkahome, P. (2023, December). What should I do if I throw up after taking my HIV meds?  Aidsmap.  https://tinyurl.com/3yp5e7x8  \nCarandang, R. R. Z., Babasa, S. K. D., Hamor, A. D., Parangalan, D. S., Rizarie, S. F. V., Matibag, N. M., & Miranda, K. J. A. (2025). They did not judge me: A qualitative study on patient \nsatisfaction in public primary HIV care facilities in Metro Manila, Philippines.  Acta Medica Philippina. Advance online publication.  https://doi.org/10.47895/amp.vi0.11302  \nCenters for Disease Control and Prevention (CDC). (2023).  HIV Treatment as Prevention. https://www.cdc.gov/hiv/risk/art/index.html  \nChen, A., & Lemmer, K. (2024). Seeking social support on social media: A coping perspective.  Internet Research.  https://doi.org/10.1108/intr -05-2022 -0346  \nCoulson, N. S., & Buchanan, H. (2022). The role of online support groups in helping individuals affected by HIV and AIDS: Sco ping review of the literature.  Journal of Medical Internet \nResearch,  24(7), e27648.  https://doi.org/10.2196/27648  \nDe Oliveira, J. C., Alves, M. R., Lopes, L. P. N., Motter, F. R., Iwami, R. S., De C\u00e1ssia Bergamaschi, C., Silva, M. T., Scal co, D. L., De Souza Lucio, D., Mazzei, L. G., Derech, R. D., Itria, A., \nBarreto, J. O. M., & Lopes, L. C. (2024). Rates of adverse events of antiretroviral therapy in women living with HIV/AIDS: A systematic review and meta -analysis.  BMJ \nOpen,  14(7), e079292.  https://doi.org/10.1136/bmjopen -2023 -079292  \nEifa, A., & Ketema, W. (2022). Could a dolutegravir -based antiretroviral therapy lead to clinical obesity? A retrospective cohort study conducted at Hawassa University Comprehen sive \nSpecialized Hospital in Hawassa, Sidama, Ethiopia.  AIDS Research and Treat ment,  2022, Article 2965325.  https://doi.org/10.1155/2022/2965325  \nErlingsson, C., & Brysiewicz, P. (2017). A hands -on guide to doing content analysis.  African Journal of Emergency Medicine,  7(3), 93 \u201399. https://doi.org/10.1016/j.afjem.2017.08.001  \nFletcher, J., & Sherrel, Z. (2023, May 16). What to know about antiretroviral therapy for HIV.  Medical News Today.  https://www.medicalnewstoday.com/articles/323897  \nGamayo, G. V. F. (2025). S -T-I-G-M-A through the eyes of PLHIV: Deconstructing HIV and AIDS depiction in Batang Poz.  Jurnal Komunikasi: Malaysian Journal of Communication,  41(1), \n368-388.https://doi.org/10.17576/JKMJC -2025 -4101 -21 \nGangcuangco, L. M. A. (2019). HIV crisis in the Philippines: Urgent actions needed.  The Lancet Public Health,  4(2), e84.  https://doi.org/10.1016/s2468 -2667(18)30265 -2 \nGangcuangco, L. M. A., & Eustaquio, P. C. (2023). The state of the HIV epidemic in the Philippines: Progress and challenges i n 2023.  Tropical Medicine and Infectious Disease,  8(5), \n258. https://doi.org/10.3390/tropicalmed8050258  \nHIV Undetectable=Untransmittable (U=U), or treatment as prevention. (2019, May 21). NIAID: National Institute of Allergy and Infectious Diseases. https://tinyurl.com/449rendv  \nHIV/AIDS Data Hub for the Asia Pacific. (2024). HIV/AIDS Surveillance: Philippines Oct \u2013Dec 2023. https://tinyurl.com/2snckbpa   \nHurbans, N., & Naidoo, P. (2024). Efficacy, safety, and tolerability of dolutegravir -based ART regimen in Durban, South Africa: A cohort study.  BMC Infectious Diseases,  24(1). \nhttps://doi.org/10.1186/s12879 -024-09202 -6 \nIbrahim, K., Kahle, E., Christiani, Y., & Suryani, S. (2024). Utilization of social media for the prevention and control of H IV/AIDS: A scoping review.  Journal of Multidisciplinary \nHealthcare,  17, 2443 \u20132458.  https://doi.org/10.2147/jmdh.s465905  \nInternational Association of Providers of AIDS Care. (2024).  Antiretroviral Therapy (ART). https://www.iapac.org/fact -sheet/antiretroviral -therapy -art/ \nJansen, D. (2025, March 23). What (exactly) is thematic analysis?  Grad Coach.  https://gradcoach.com/what -is-thematic -analysis/  \nJava, A. (2024). Gendered language in Philippine newspapers. Journal of Interdisciplinary Perspectives, 2(10), 280 -287. https://doi.org/10.69569/jip.2024.0453  \nKhan, M. I., Ur Rahman, Z., Saleh, M. A., & Khan, S. U. Z. (2022). Social media and social support: A framework for patient s atisfaction in healthcare.  Informatics,  9(1),  \n22. https://doi.org/10.3390/informatics9010022  \nLal, I. (2025, February 7). How to create a qualitative research codebook (with example).  Marvin Resources & Blog.  https://heymarvin.com/resources/codebook -qualitative -research/  \nLi, N., Zheng, H., He, W., He, X., Li, R., Cui, W., Yang, W., Dong, X., Shen, Z., & Zheng, Y. (2024). Treatment outcomes amon gst older people with HIV infection receiving antiretroviral \ntherapy.  AIDS,  38(6), 803 \u2013 812. https://doi.org/10.1097/qad.0000000000003831  \nLoghin, I. I., Rusu, \u0218. A., V\u00e2\u0163\u0103, A., Cobaschi, M., Cecan, I., Manciuc, C., & Dorob\u0103\u0163, C. M. (2024). Antiretroviral therapy switch in HIV -infected adults from a regional HIV/AIDS center in \nNE Romania.  Medicina,  60(6), 854.  https://doi.org/10.3390/medicina60060854  \nMedia Bias Fact Check. (2024, February 19).  Media Bias/Fact Check news. Media Bias/Fact Check.  https://mediabiasfactcheck.com/  \nNational Institutes of Health. (2021).  HIV Treatment: The Basics.  https://hivinfo.nih.gov/understanding -hiv/fact -sheets/hiv -treatment -basics  \nNieswiadomy, R. M., & Bailey, C. (2018).  Foundations of nursing research  (7th ed.). Pearson.    \n O\u2019Connor, C., Leyritana, K., Calica, K., Gill, R., Doyle, A. M., Lewis, J. J., & Salva\u00f1a, E. M. (2021). Risk factors affectin g adherence to antiretroviral therapy among HIV patients \nin Manila, Philippines: A baseline cross -sectional analysis of the Philip pines Connect for Life Study.  Sexual Health,  18(1), 95. https://doi.org/10.1071/sh20028  \nPrevention Access Campaign. (2024).  Undetectable = Untransmittable (U=U). https://www.preventionaccess.org/undetectable  \nPrinsloo, C. D., Greeff, M., Kruger, A., & Khumalo, I. P. (2017). HIV stigma experiences and stigmatization before and after a HIV stigma -reduction community \u201chub\u201d intervention.  African \nJournal of AIDS Research,  16(3), 203 \u2013213. https://doi.org/10.2989/16085906.2017.1349683  \nPhilippine National AIDS Council. (2024, June). HIV/AIDS and ART Registry of the Philippines report. https://pnac.doh.gov.ph/hiv -aids-and-art-registry -of-the-philippines -report / \nRobles, A. M. Q., & Canoy, N. A. (2019). Putting the \u201cwhere\u201d in HIV care: Unpacking narratives of antiretroviral therapy adhe rence among HIV -positive men who have sex with \nmen.  Health & Place,  59, 102204.  https://doi.org/10.1016/j.healthplace.2019.102204  \nSahin, N. H., et al. (2021). Health information seeking behaviors related to COVID -19 among individuals using social media.  International Journal of Health Research and \nBiotechnology,  5(1), 1 \u201310. https://brieflands.com/articles/ijhrba -105863  \nSombrea, D. P., Santarin, S. L. M., Verde, T. G. M., Tidalgo, A. D., & Tolosa, C. S. (2024). The unheard stories: Experiences of young people living with human immunodeficiency virus in \ndealing with discrimination in the Philippines.  HIV/AIDS \u2013 Research and Palliative Care,  16, 33 -43. https://doi.org/10.2147/HIV.S438280  \nTh\u00e9ro, H., & Vincent, N. (2022). Investigating Facebook\u2019s interventions against accounts that repeatedly share misinformation . Information Processing & Management,  59(2), \n102804.  https://doi.org/10.1016/j.ipm.2021.102804  \nTorres, R. Q., Pacquiao, D. F., Ngaya -An, F. V., & Tuazon, J. A. (2021). Adherence to antiretroviral therapy and scheduled clinic visits of persons living with HIV  in the Philippines.  Journal \nof Nursing Practice Applications & Reviews of Research,  11(2), 1 9\u201330. https://doi.org/10.13178/jnparr.2021.11.02.1104  \nTracy, S.J. (2013). Qualitative research: Collecting evidence, crafting analysis, communicating impact. Wiley - Blackwell UNAIDS. (2024, November 22).  Philippines.  \n  https://www.unaids.org/en/regionscountries/countries/Philippines  \n \n456 Zhang, Q., Feng, S., Wong, I. O. L., Ip, D. K. M., Cowling, B. J., & Lau, E. H. Y. (2020). A population -based study on healthcare -seeking behaviour of persons with symptoms of respiratory \nand gastrointestinal -related infections in Hong Kong. BMC Public Hea lth, 20(1). https://doi.org/10.1186/s12889 -020-08555 -2  \nZhang, Y., Fu, J., Lai, J., Deng, S., Guo, Z., Zhong, C., Tang, J., Cao, W., & Wu, Y. (2024). Reporting of Ethical Considerat ions in Qualitative research utilizing social media data on public \nhealth care: Scoping review. Journal of Medical Internet Researc h, 26, e51496. https://doi.org/10.2196/51496   \nZhu, C., Zeng, R., Zhang, W., Evans, R., & He, R. (2019). Pregnancy -related information seeking and sharing in the social media Era among expectant Mothers: Qualitative study. Journal of \nMedical Internet Research, 21(12), e13694. https://doi.org/10.2196/13694  \n \n  \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Decoding Health-Seeking Queries Related to Antiretroviral Therapy in Philippine HIV Awareness Facebook Groups", "author": ["J Bimuyag", "JK Ogaccan", "ES Lantaen"], "pub_year": "2025", "venue": "Journal of \u2026", "abstract": "This study explored how members of Philippine HIV awareness Facebook groups express  health-seeking queries related to antiretroviral therapy. Despite widespread challenges in"}, "filled": false, "gsrank": 315, "pub_url": "https://jippublication.com/index.php/jip/article/view/1326", "author_id": ["", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:kwl6O25lZV4J:scholar.google.com/&output=cite&scirp=314&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=kwl6O25lZV4J&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:kwl6O25lZV4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://jippublication.com/index.php/jip/article/download/1326/970"}}, {"title": "ASSESSING BIAS IN PREDICTIONS OF REDDIT USERS'POLITICAL LEANING", "year": "NA", "pdf_data": "A S S E S S I N G B I A S I N P R E D I C T I O N S\nO F R E D D I T U S E R S \u2019 P O L I T I C A L\nL E A N I N G\nB E N W I T T E\nthesis submitted in partial fulfillment\nof the requirements for the degree of\nmaster of science in data science &society\nat the school of humanities and digital sciences\nof tilburg university\nstudent number\n1273208\ncommittee\ndr. Chris Emmery\ndr. Travis Wiltshire\nlocation\nTilburg University\nSchool of Humanities and Digital Sciences\nDepartment of Cognitive Science &\nArtificial Intelligence\nTilburg, The Netherlands\ndate\nMay 20th,2024\nword count\n8728\nacknowledgments\nI would like to thank my supervisor, Chris Emmery, for his guidance\nduring the thesis. Your feedback was always valuable and made the\nresearch process much easier. I would also like to thank my parents for\nalways supporting me, especially my father for his listening ear and\nsound advice. Lastly, I would like to thank Lu for being by my side\nevery step of the way.\nA S S E S S I N G B I A S I N P R E D I C T I O N S\nO F R E D D I T U S E R S \u2019 P O L I T I C A L\nL E A N I N G\nben witte\nAbstract\nPredicting political leanings on social media platforms is in-\ncreasingly important as global polarisation rises. These plat-\nforms can be leveraged by Machine Learning (ML) algorithms\nfor Author Profiling, inferring personal attributes from textual\ndata generated by authors. However, ML models risk perpetuat-\ning real-word biases that stem from the data they are trained on\nand the decision-making processes of the algorithms themselves.\nWhen predicting political leaning, this can create the problem of\nmarginalising groups associated with political leanings, which\nthe models are prejudiced against in terms of their bias. This\nstudy aims to contribute to the field of author profiling and\nbias assessment by providing insights into the decision-making\nprocesses of machine learning models that predict Reddit users\u2019\npolitical leaning and what role bias plays. To do so, it com-\npared the performance of Logistic Regression, Support Vector\nMachine (SVM), and fastText classifiers for predicting whether\nReddit users are left- or right-leaning. Three human evaluators\nwere then tasked with assessing bias by evaluating word fea-\ntures embedded in the statement that the Logistic Regression\nand SVM viewed as important for prediction on a 1-3scale.\nThe findings showed that the fastText classifier achieved the\nhighest accuracy at 85.32%, while Logistic Regression and SVM\nscored 80.94% and 80.64%, respectively. The overall bias score\nwas2.58, with left-leaning predictions showing more bias ( 2.67)\nthan right-leaning ones ( 2.5). The findings emphasise the im-\nportance of investigating machine learning algorithms\u2019 bias and\nencourage future research into studying mitigation measures\nto help reduce bias.\n1\n1 data source /code /ethics statement 2\n1 data source /code /ethics statement\nWork on this thesis did not involve collecting data from human participants\nor animals. The SOBR dataset was obtained from Dr. Chris Emery, the\nthesis supervisor (Emmery, 2024 ). The original owner of the data used in\nthis thesis retains ownership of the data during and after the completion\nof this thesis. The author of this thesis acknowledges that they do not\nhave any legal claim to this data. All tables and figures belong to the\nauthor. ChatGPT has been used as a debugging tool to resolve coding\nerrors (OpenAI, 2021 ). For assisting in academic writing and checking\nspelling and grammar the Quillbot AI software was used (QuillBot, 2024 ).\nThe code used in this thesis is available in the GitHub repository via the\nfollowing link: https://github.com/CoderBenW/MasterThesis.git.\n2 introduction\nThe research goal of this study aims to investigate the potential biases\nwhich may be present in machine learning algorithms predicting Reddit\nusers\u2019 political leaning based on the text from comments users\u2019 have posted.\n2.1Problem Statement\nSocial media has played an increasingly integral role in the way we dissemi-\nnate and perceive news and information with each other. Online discussion\nforums such as Reddit have millions of users who engage in a wide variety\nof discourses surrounding many topics and issues, especially those of a\npolitical nature (Feng et al., 2023 ). Whilst this has allowed for healthy\npublic debates to proliferate between diverse groups of people, by contrast,\nit also runs the risk of creating a division of political ideologies as people\nwill only be exposed to like-minded people within and between platforms\n(Baly et al., 2020 ; Conover et al., 2011 ; Hajare et al., 2021 ; K. Johnson et al.,\n2017 ; Stefanov et al., 2020 ). If certain ideologies become more dominant\non online platforms as a result of what is being discussed and even the\nlanguage being used in these discussions, it could pull the ideology of the\nplatform itself in a certain direction.\nAlthough it may seem strange to think of an online social media plat-\nform like Reddit as having a political ideology, it is not much different than\ntraditional news outlets, which convey political leanings in the articles they\npublish. The difference here is that a platform such as Reddit constantly\ngenerates a much richer source of data with the words its users use and\npost in comments. At the same time, the rapid development of machine\nlearning (ML) technologies and their application in the field of Natural\n2 introduction 3\nLanguage Processing (NLP) has enabled researchers to gain deeper insights\ninto such textual data and the individuals generating it. Using algorithms\nsuch as Logsitic Regression (LR), Support Vector Machines (SVM), and\nfastText, research conducting author profiling has leveraged textual data\nanalysis to predict personal attributes like personality, gender, nationality,\nand political orientation (Emmery et al., 2017 ; Gjurkovi\u00b4 c & \u0160najder, 2018 ;\nStefanov et al., 2020 ). This automated process has found applications in\nvarious domains such as political discourse analysis (K. Johnson et al.,\n2017 ), hate speech detection on social media (Mishra et al., 2018 ), and\nmarketing strategies (Matz et al., 2017 ).\nThe use of machine learning for making predictions about an author\u2019s\npersonal attributes has also sparked significant concerns. This includes\nproblems regarding the right to privacy being violated by textual data\nbeing analysed and used to potentially disclose personal information, not\neven beginning to mention whether these predictions result in misrep-\nresentations of an individual (Peters, 2022 ). Intertwined with many of\nthese issues is the problem of bias and the potential repercussions it may\nhave on individuals when inaccurate predictions are made about them\nbased on their writing style and choices of words. Bias in this case refers\nto the systematic errors inherent in machine learning algorithms and the\nsubsequent predictions they generate, potentially leading to unfair and\nprejudiced treatment of specific individuals, groups, or outcomes (Feng et\nal.,2023 ; Peters, 2022 ). For the case of using human-generated textual data\nfrom a platform like Reddit to train machine learning models, the problem\nthat can also arise is that real-world biases that are inherent in the users\nand are conveyed through their choice of words when commenting can be\nreinforced by the models (Feng et al., 2023 ). This is due to the process by\nwhich machine learning learning models learn from textual data, as certain\nfeatures (i.e., individual words) are more relevant for making predictions\nthan others (Wanner et al., 2017 ).\n2.2Motivation & Relevance\nTo prevent unfair representations of authors based on the predictions from\nthe texts they write as well as the reinforcement of real-world societal\nbiases, it\u2019s crucial to investigate biases in machine learning models that\nmake these predictions. The scientific relevance of this study was that,\nwhile past research has mainly focused on biases related to gender or race,\nlittle attention has been given to biases in predicting political leaning from\nauthor-generated text (de Vassimon Manela et al., 2021 ; Emmery et al., 2017 ;\nPeters, 2022 ). This oversight is problematic, as evaluating and addressing\nbiases against political leaning may differ significantly from biases related\n2 introduction 4\nto other dimensions of a person\u2019s social identity. Additionally, for research\nthat did investigate biases in predictions of political leaning, very few\nutilised Reddit as a source of data, as the current study did, mainly using\ndata extracted from Twitter (now X).\nThis study aimed to fill this gap by comparing Logistic Regression,\nSupport Vector Machine, and fastText classifiers with a baseline majority\nclass classifier to analyse their effectiveness in predicting Reddit users\u2019\npolitical leaning based on the choice of language and words they use\nin their comments. It also aimed to evaluate the role of bias in these\npredictions based on the word features the models identified as important.\nBy identifying and assessing biases in machine models predicting Reddit\nusers\u2019 political leaning, it addressed the lack of understanding of not only\nhow machine learning models predict political leaning but also what role\nbias plays. Through the analysis, the goal of the study was to contribute to\nenhancing fairness and transparency in machine learning decision-making\nprocesses.\n2.3Research Questions\nThe main research question which this thesis aimed to answer is as follows:\nTo what extent is bias present within Machine Learning mod-\nels when predicting Reddit users\u2019 political leaning based\non the textual features these algorithms identify from users\u2019\nposted comment history?\nThe following sub-research questions were asked to further elaborate\non the main research question:\nSub-RQ 1:Which textual features are most important for distin-\nguishing Reddit users\u2019 political leaning based on their comment\nhistory\nFeature extraction and analysis are key steps when conducting NLP\nfor the purpose of author profiling (Wanner et al., 2017 ). In this case,\nfeatures were in the form of words that were extracted from the trained\nLogistic Regression and SVM models in order to be able to conduct a bias\nassessment on them.\nSub-RQ 2:To what extent can Logistic Regression, Support Vector\nMachine, and fastText binary classifiers accurately predict Reddit\nusers\u2019 political leaning when compared to a baseline majority class\nclassifier?\n3 literature review 5\nBy comparing the performance of three machine learning models to\na baseline, this question intended to provide an understanding of how\nwell models can analyse the relevancy of different features in order to\naccurately predict political leaning. The inclusion of the fastText classifier\nwas to provide a potential upper bound in terms of what is possible\nperformance-wise.\nSub-RQ 3:Based on the qualitative evaluation of human evaluators,\nwhich features introduce the most bias when predicting Reddit users\u2019\npolitical leaning?\nThe answer to this question aimed to quantify a measure of bias that\nwas present in the models and their predictions. Using a qualitative\napproach similar in design to Raza et al. ( 2024 ) and Liang et al. ( 2021 ), three\ndomain experts evaluated statements with important identified features\nembedded in them that were extracted from the raw text corpus on a 1\u20133\nnumeric scale.\nThe findings of the study, obtained by answering the previous sub-\nresearch questions, are as follows: Using the Logistic Regression and SVM\nmodels, words deemed important for predicting right-leaning Reddit users\nincluded \"orthodox\", \"anarchist\", and \"vietnamese\". For left-leaning users,\nwords such as \"government\", \"cope\", and \"libertarian\" were ranked highly.\nThe fastText classifier was the best performing model, demonstrating an\naccuracy score of 85.40%, against that of 80.94% and 80.64% for Logistic\nRegression and Support Vector Machine, respectively. The left-leaning\nclass was perceived as having more bias than the right-leaning class by the\nevaluators, having an average bias score of 2.67.\n3 literature review\n3.1Author Profiling in Social Media\nAuthor profiling is the analysis of texts with the aim of attributing various\npersonal characteristics of an author based on their writing style. Advances\nwithin the field of NLP have led to it becoming a powerful tool that can\nhelp improve the performance of subsequent tasks such as sentiment anal-\nysis and text classification Mishra et al., 2018 . This analysis is commonly\napproached as a supervised learning task, where feature representations\nof words (i.e., words in numerical format) are created using techniques\nlike Term Frequency-Inverse Document Frequency (tf-idf) and word and\ncharacter embeddings to train models. In studies concerning social media,\nadditional features related to user activity and other domain-specific ele-\nments are often utilized. However, a major obstacle to conducting author\n3 literature review 6\nprofiling is the availability of labelled datasets. Creating these datasets\nis often costly and time-consuming, especially for social media, where\ndealing with very large datasets exacerbates the issue (Conover et al., 2011 ;\nGjurkovi\u00b4 c and \u0160najder, 2018 ).\nPrevious research in author profiling of text generated on social media\nplatforms has encompassed a wide range of topics, including predicting\nage, gender, personality traits, and hate speech detection (Emmery et al.,\n2017 ; Mishra et al., 2018 ; Volkova et al., 2015 ). These studies applied\nvarious machine learning algorithms, with certain ones being consistently\nused, lending to their suitability for the classification tasks at hand in this\nstudy.\nEarly seminal work that showed the potential for leveraging NLP and\nmachine learning techniques for predicting political leaning was conducted\nby Thomas et al. ( 2006 ). Their study aimed to classify speeches given during\nUS Congress debates as supporting or opposing a piece of legislation based\non the words used in the speeches. Relative to a majority class classifier\nbaseline achieving 62.67% accuracy, an SVM gave an accuracy score of\n70.81%. The results suggest the use of machine learning models such as an\nSVM for similar tasks, such as within the domain of social media, as well\nas the potential to improve the performance of these models. Furthermore,\nthe political bias may have been deduced if additional information about\nthe legislator\u2019s party affiliation who proposed the bill were available.\nTo this end, Conover et al. ( 2011 ) analysed data mined from the social\nmedia platform Twitter (now X). They performed binary classification for\nthe task of predicting whether Twitter users\u2019 are left- or right-leaning based\non their tweets leading up to the 2010 U.S. midterms. Comparing SVM\nmodels trained on weighted tf-idf n-grams based on the text and hashtags\nusers used in their tweets against a model that used additional latent\nfactors corresponding to political leaning identified by Latent Semantic\nAnalysis (LSA), accuracy scores upwards of 90% were achieved relative\nto a79.2% baseline. The study did not go beyond the scope of Twitter,\nthereby not considering the generalizability of their models with respect to\nother similar social media platforms, such as Reddit.\nIn a similar vein, Stefanov et al. ( 2020 ) developed a method that uses\nunsupervised learning to label the stance of Twitter users regarding po-\nlarising topics and then uses these labels to conduct supervised learning\nto determine the political leaning of online media and popular Twitter\nusers. After training a FastText classifier on this labelled dataset, the study\nachieved 95% accuracy. The study compared the bias scores of human eval-\nuators and average valence scores of users to \u2019gold labels\u2019 created by the\n3 literature review 7\nMedia Bias/Fact Check website1. The research highlighted the necessity\nof properly analysing bias in predictions based on text data generated on\nsocial media and showed a gap by only focusing on text that related to\npolarising topics.\nIn a study that conducted author profiling on textual data extracted\nfrom Reddit instead of Twitter, Gjurkovi\u00b4 c and \u0160najder ( 2018 ) compared\nthree models that predicted the four dimensions of personality from the\nMyers-Briggs Type Indictors (MBTI). Trained on a dataset derived from\nReddit users\u2019 post and comment history, authors were labelled by their self-\nreported MBTI personality types displayed as flairs. Using tf-idf-weighted\ncharacter n-grams and word n-grams, alongside user activity features,\nGjurkovi\u00b4 c and \u0160najder ( 2018 ) employed a SVM and Logistic Regression\n(LR) algorithms, in addition to a multi-layer perceptron (MLP). The LR\nmodel achieved macro F 1-scores of 81.6%,77.0%,67.2%, and 74.8% across\nthe four personality dimensions, with the SVM model always being within\nless than three percentage points for its F 1-scores. These results suggest\nthat both LR and SVM algorithms can achieve good performance when\nconducting an author profiling task on textual data taken from Reddit.\nHowever, their focus remained on reporting prediction results without\nexploring potential biases in the model\u2019s predictions.\n3.2Bias in Political Leaning Predictions\nEmphasising the need for further research into algorithmic bias against\npeople\u2019s political orientation, Peters ( 2022 ) argues that political biases can\nbe harder to detect and mitigate than biases against other dimensions of an\nindividual\u2019s social identity, which, as previously stated, have received far\nmore research attention, such as gender and racial biases. He highlights\nthe consequences that may occur when algorithms are able to infer the\npolitical leaning of individuals and make socially relevant decisions, such\nas in job recruitment, about them using their political leaning as a feature\nwhere this should be irrelevant.\nBaly et al. ( 2020 ) investigated bias in news articles when predicting their\npolitical leaning, applying two state-of-the art models in the form of a Long\nShort-Term Memory Network (LSTM) and a BERT transformer to classify\narticles as left-, right-, or center-leaning. Using a slightly imbalanced\ndataset (the centre class was unrepresented) and a baseline majority class\nclassifier achieving accuracy and macro F 1scores of 41.67% and 19.61%\nrespectively, the BERT transformers outperformed the LSTM.\n1An online platform that evaluates the bias and factual accuracy of news sources and media\noutlets. For reference, see: https://mediabiasfactcheck.com\n3 literature review 8\nHowever, of interest to the researchers was whether these models had\ninduced bias. They proposed that the sources of articles, namely media\noutlets, have a certain political leaning. Articles published by these outlets\nwill likely reflect the same political leaning. This line of thinking might\nalso apply to social media platforms, where users on one platform may be\nmore right-leaning than one another, and this sentiment is expressed in\nthe words they use in posts. Baly et al. ( 2020 ) believed that this can cause\nproblems when training models to predict the political leaning of articles,\nas they may overly emphasise features (such as writing patterns and styles)\nspecific to the media outlets where the articles are published. This can\ninduce bias in the models and reduce their generalizability for making\npredictions on articles not seen during training. This was confirmed since\nafter Baly et al. ( 2020 ) debiased the models, the macro F 1scores of both\nmodels improved by more than 12%.\nThe ease and speed with which information can be spread through\nvarious channels increases the risk with which political biases can aid in\nspreading misinformation. Baly et al. ( 2018 ) examined political bias within\nnews media by employing text analysis and social media content profiling.\nThey trained an SVM using diverse feature ensembles to predict political\nleaning across a spectrum, comparing it with a majority-class baseline.\nTheir top-performing model, integrating linguistic and embedding features,\nachieved a macro F 1-score and accuracy of 81.27% and 81.83%, respectively.\nAlthough the study focused on bias analysis and utilised feature ensembles,\nit omitted comparing the performance of various machine learning models\nin predicting political leaning.\nTo be able to understand what role bias can play in the context of author\nprofiling for predicting political leaning, research designs are required to\nmeasure the phenomenon of bias. Caliskan et al. ( 2017 ) developed and\nemployed statistical methods to reveal human-like biases in word embed-\ndings, which are commonly used to train machine learning models. Their\nstudy demonstrated how models trained on human language replicate\nthese biases, potentially perpetuating cultural stereotypes and leading to\nprejudiced outcomes. They underscored the importance of further research\non fairness in machine learning, particularly in author profiling tasks,\nwhere biases beyond gender and race have received less attention (Peters,\n2022 ).\nAt the same time, qualitative methods have been developed and shown\nto be effective for assessing bias. Previous studies conducted by Liang et al.\n(2021 ) and Raza et al. ( 2024 ) both utilised human evaluators by asking\nevaluators to judge the bias they perceived in statements that were either\nhandcrafted by researchers or generated by large language models (LLMs).\nThis approach mainly involved the use of a numeric 1\u20135scale that the\n4 method 9\nevaluator used to indicate the level of bias they perceived in the statement.\nBoth studies used human evaluations of bias as a means to compare metrics\nfor bias detection in texts they had developed.\n3.3Research Gap\nAs global political polarisation escalates, discerning individuals\u2019 political\ninclinations grows increasingly crucial (Feng et al., 2023 ). This knowledge\nserves various purposes, including targeted campaigns for undecided\nvoters, informing policy development decisions, and researching public\nopinion trends (Peters, 2022 ). Leveraging machine learning techniques,\nunderstanding political leanings has become more attainable than ever.\nNonetheless, if machine learning models consistently misclassify certain\npolitical leanings and their associated groups, it could result in adverse\noutcomes such as reinforcing stereotypes, perpetuating real-world biases,\nand potentially marginalising political groups from significant decision-\nmaking processes due to being overlooked.\nThe aforementioned literature review showcases an existing gap in\nunderstanding machine learning models\u2019 predictions of Reddit users\u2019 po-\nlitical leaning and quantifying inherent biases through qualitative analysis.\nPrior research mostly focused on biases in race and gender predictions or\npolarising topics for political leaning. Also, when studies actually did aim\nto predict political leaning, they only used data based on text generated\nby users on platforms other than Reddit, mainly Twitter in this case. This\nstudy aims to fill this gap by exploring bias effects on political leaning pre-\ndictions of Reddit users\u2019 made by machine learning algorithms and their\nimplications, and potentially provide insights into whether bias in author\nprofiling should be analysed differently across social media platforms.\nThe literature also highlights progress in applying machine learning\nand NLP to author profiling and addressing bias and lends support for\nusing the Logistic Regression, Support Vector Machine, and fastText ma-\nchine learning algorithms as potentially effective models to help answer\nthe research questions of this study.\n4 method\nFor an overview of the research methodology and modelling pipeline see\nFigure 1. The software and hardware used for preprocessing the data and\nprogramming all models are detailed in Appendix A.\n4 method 10\n4.1Dataset Description\nThe SOBR dataset, derived from two years of Reddit activity ( 2020 -2022 ),\nwas sampled using author labels from attribute-related subreddits via flairs\n(Emmery et al., 2024 ). From this, a smaller dataset was used, focusing\non the political leaning attribute. This attribute was labelled from flairs\nsourced from self-reported Political Compass outcomes on the subred-\ndit r/PoliticalCompass. Post-corpus aggregation was executed per user,\nsegmenting each users\u2019 full post-history into 1500 -word instances. Users\nwith less than 1500 words per post were excluded, with excess words\ntrimmed from longer instances. Recurring author IDs across rows indicate\nusers with at least two instances totaling 3000 words or more. The dataset\nfeatures three columns: author_ID, posts, and political_leaning, containing\n57,231rows labelled for the target variable political leaning (left, center, or\nright).\nFigure 1: Research methodology and modeling pipeline\n4.2Data Preprocessing\n4.2.1Data cleaning\nThe raw dataset showed some class imbalance across the three classes,\nwith the center-leaning class being notably larger than the left-leaning and\nright-leaning classes. To aid in not just dealing with this imbalance but\nalso to conduct a sharper analysis, the center class and its corresponding\nrows were excluded. Doing so mitigates the complexities an intermediate\n4 method 11\nclass can introduce and is in line with the approach taken by Conover\net al. ( 2011 ) who removed observations that were too ambiguous in terms\nof being right- or left- leaning. This allowed for a direct examination of\nlinguistic patterns between these polarised classes and helped identify\ndiscriminative features better (Conover et al., 2011 ).\nSubsequently, the post column was cleaned by converting all the text\nto lowercase in addition to the removal of URLs, non-word and non-\nwhite space characters, and numbers using the regular expressions library\npackage regex. Non-word and non-white space characters refer to any\ncharacters that are not considered words, such as punctuation, exclamation,\nand question marks. Lower casing helps to maintain consistency when\nprocessing text, as it will ensure that words that only differ in whether or\nnot they contain capital letters will not be treated as two different words\n(Tabassum & Patil, 2020 ). The removal of URLs, non-word and non-white\nspace characters, and numbers is a highly common procedure in NLP with\nthe aim of reducing noise in data by eliminating characters and values that\ndo not carry much meaningful information for text analysis.2\nNext, the Natural Language Toolkit (NLTK) library was utilised to\ntokenize the cleaned post column, remove stopwords, and, using the Word-\nNetLemmatizer tool, perform lemmatization (Bird, 2006 ). Additionally,\none character-length tokens that still remained in the dataset were also\nremoved before lemmatization. The choice of performing lemmatization\nover stemming is motivated by the fact that lemmatization results in more\nproper, valid words than stemming (Balakrishnan & Lloyd-Yemoh, 2014 ).\nFor the current study, this is very important, as it is the features in the form\nof words that the models identify as important for prediction that will\nbe assessed for bias. If these features are mainly non-valid words due to\nhaving applied stemming, then it will be problematic to incorporate them\nin statements for bias assessment without first changing them manually.\nLemmatization will help prevent such issues as it brings words to their\nbase dictionary form and is better able to consider the context of words\nwhen transforming them (Balakrishnan & Lloyd-Yemoh, 2014 ).\n4.2.2Preprocessing and feature extraction\nTo prepare the \"post\" column of the cleaned dataset for machine learning\nalgorithms, it was converted into numerical format using TF-IDF (Term\nFrequency-Inverse Document Frequency) vectorization (Salton, 1983 ). Util-\nising unigram and bigram word n-grams, 5000 features were extracted\n(Manning et al., 2008 ). This feature limit was chosen to avoid computa-\ntional heaviness and time costs, as not setting a limit resulted in nearly\n2Examples of non-word and non-white space characters include: punctuation marks, mathe-\nmatical symbols, special characters (#, &, $), etc.\n4 method 12\n80,000features. Furthermore, a comparison between logistic regression\nmodels trained on 80,000features versus 5000 features showed a negligible\nperformance difference. Training and test set splitting were then conducted\non an 80/20ratio basis. Even though there was only a minimal class\nimbalance between the left- and right-leaning classes, stratification was\nstill applied when splitting the data. A random seed was also set when\nsplitting the data to ensure the reproducibility of the results.\nTable 1: Distribution of Political leaning across posts\nPolitical leaning Post Count Percentage\nLeft 14576 45 .51%\nRight 17454 54 .49%\n4.2.3Exploratory Data Analysis\nThe distribution of the political leaning classes in the final cleaned dataset\ncan be seen in Table 1(see Figure 8in Appendix A for figure of distribution).\nAdditionally, the Type Token Ratio (TTR) was calculated for each class\nbased on the post column. The TTR is a measure for evaluating the\ncomplexity of a text in terms of word use (Covington & McFall, 2010 ). It\ntakes the ratio of unique words in a given text to the total number of words\nused. Higher TTR values indicate the use of a wide vocabulary, while\nlower values suggest more repetition and less complex texts. The TTR for\nposts labelled as right-leaning was 0.0211 , while for left-leaning posts it\nwas0.0247 . Furthermore, Figures 2and3visualise the number of words by\nword length for each class. These plots match well with the average word\nlength by class, which was 5.67and5.63for the left- and right-leaning\nclasses, respectively. Appendix A also shows plots for the 50most common\nwords by political leaning (Figure 9).\n4.3Models\nAs mentioned previously, a total of four machine learning models were\nused, namely: a baseline model, Logistic Regression, Support Vector ma-\nchine, and a fastText classifier. The following sections will describe each\nmodel and the hyper-parameters that were tuned when training them.\nAdditionally, the procedure for extracting which features the models view\nas important for making their predictions will be detailed.\n4 method 13\nFigure 2: Word Length Distribution Left-leaning class\n4.3.1Baseline Model\nUtilising the Scikit-Learn Python library (Pedregosa et al., 2011 ), the\nDummyClassifier was used to establish a baseline performance metric.\nThis classifier employs the \"most frequent\" strategy, predicting the most\ncommon class in the training set for all instances, which, in this case, is the\nright-leaning class. This approach provides a reference point for comparing\nthe performance of more complex models, aligning with common practice\nin the literature (Baly et al., 2020 ; Gjurkovi\u00b4 c & \u0160najder, 2018 ; Stefanov et al.,\n2020 ). Additionally, in all models, the left-leaning class was considered the\npositive class, while the right-leaning class was the negative class.\n4.3.2Logistic Regression\nLR models have been applied to a wide range of binary classification prob-\nlems, including those involving textual data. They function by estimating\nthe probability that a given input belongs to a particular class, typically\nusing the logistic function to map input features to probabilities (Hosmer Jr\net al., 2013 ). This algorithm is suitable for conducting bias assessments\non textual data due to its transparency in interpreting the impact of each\nfeature on classification. This allows for a straightforward understanding\nof which features, or words in this case, contribute the most to the classifi-\ncation decision, enabling effective bias analysis. As discussed in Section\n3, this algorithm has been utilised in various previous research projects\nconducting author profiling tasks similar to the current one (Aksenov et al.,\n2021 ; Gjurkovi\u00b4 c & \u0160najder, 2018 ; Mishra et al., 2018 ).\n4 method 14\nFigure 3: Word Length Distribution Right-leaning class\n4.3.3Support Vector Machine SVM\nFirst used by Joachims ( 1998 ) for the task of document categorization,\nSVMs have seen widespread usage for other text classification problems.\nWith their ability to handle sparse and high-dimensional data, SVMs are\nwell-suited to deal with textual data, where each word can be represented\nas a unique feature in the dimensional space. The algorithm aims to find\nthe most optimal hyperplane (i.e., decision boundary) that maximises\nthe distance between it and the nearest data point of each class, thereby\nseparating the data by class (Boser et al., 1992 ). By leveraging the use of\na linear kernel, SVMs can map the data into a higher-dimensional space\nwhere it becomes possible to separate the data points linearly. Previous\nstudies performing similar classification tasks to the present one have also\nimplemented SVMs with high-performance metric scores as a result (Baly\net al., 2018 ; Conover et al., 2011 ; Gjurkovi\u00b4 c & \u0160najder, 2018 ; Thomas et al.,\n2006 ). The SVC(Support Vector Classification) package from Scikit-Learn\nwas used to train the model (Pedregosa et al., 2011 ).\n4.3.4fastText\nfastText, introduced by (Bojanowski et al., 2017 ), is a powerful tool com-\nmonly used for text classification tasks. It builds upon the concept of word\nembeddings but extends it to include sub-word information. fastText is\nthereby able to capture the nuances of language, especially in datasets\nwith rare or misspelt words. Despite being relatively new, fastText is a\npopular choice among researchers for text classification given its efficiency\n4 method 15\nin training and its ability to capture semantic information (Joulin et al.,\n2016 ; Stefanov et al., 2020 ). The fasttext open-source library, provided by\nFacebook AI Research lab, was used.\n4.3.5Hyper-parameter tuning\nFor this study, hyper-parameter tuning was performed on the models using\nthe Optuna library, an automatic hyper-parameter optimisation software\nthat chooses values for hyper-parameters based on the performance of\nmodels from previous trials, thereby being highly efficient in searching\nthe hyper-parameter space and significantly saving time with respect\nto traditional techniques such as gridsearch (Akiba et al., 2019 ). The\nregularisation parameter C, which controls for overfitting in the model,\nwas tuned for the LR and SVM models. For the LR, 10trials were run to\nfind the optimal parameter value, while for the SVM, 5trials were run;\nmainly due to time constraints, fewer trials were run on the SVM model.\nFor the fastText classifier, the hyper-parameters that were tuned included\nthe learning rate ( lr), number of epochs ( epoch ), and number of word\nn-grams ( wordNgrams ). The learning rate determines the amount by which\nweights in the model are adjusted with respect to a loss function through\neach iteration of training data to allow for the model to converge to an\noptimal solution (i.e., performance). epoch sets the number of iterations\ntaken through the training data, while wordNgrams controls the sequence\nlength of words that are captured. The number of trails was set to 10for\nfinding the optimal tuned values. The value of the hyper-parameters was\nselected based on the one that resulted in the best performance on the\nobjective function by the models, in this case, maximising accuracy.\n4.4Feature Importance and Statement Generation for Bias Assessment\nThe aim of this study was also to evaluate potential biases within these\nmodels and their predictions. To achieve this objective, first, the 30most\nimportant word features for predicting each political leaning class, as\nidentified by the LR and SVM models, would be extracted.\nDue to the complex neural network architecture of the fastText model\nand its lack of transparency, it was not utilised for word feature extraction\nand subsequent bias analysis. Instead, for both the LR and SVM models,\nthe TF-IDF vectors were reverted back to their original words. In the case\nof LR, the 30most positively and negatively weighted coefficients were\nthen extracted along with their corresponding word features, resulting in a\ncollection of 60word features and coefficients. These positive coefficient\nword features reveal the words that are important for predicting the positive\n4 method 16\nclass, in this case, the left-leaning class. Conversely, the negative coefficient\nword features show words that weigh more when predicting the right-\nleaning class (negative class). The SVM model underwent a similar process,\nalthough it was necessary to convert the coefficients into a dense array\nformat first.\nA subset of 20word features ( 10per political leaning class) was then\nchosen, and 30-50word long statements were extracted from the raw\ntext corpus. From these, 25statements per word feature were randomly\nselected. Finally, two diverse statements per word feature were chosen for\nthe final bias assessment.3\n4.5Bias Assessment and Metric\nIn order to assess bias in the generated statements, three human evaluators\nwere chosen. Each evaluator possessed experience in data science or\nlinguistics, but more importantly, they represented diverse demographics\nin terms of gender, ethnicity, and age. This approach aimed to mitigate the\ncommon WEIRD (Western, Educated, Industrialised, Rich, and Democratic)\nbias prevalent in academic research, as highlighted by Nielsen et al. ( 2017 ).\nAdditionally, by excluding researchers as evaluators, the study aimed to\nprevent the introduction of bias that may seek to confirm researchers\u2019\nexpectations. In an approach inspired by the research methods of Raza\net al. ( 2024 ) and (Liang et al., 2021 ), the evaluators were asked to score the\nbias of the generated statements based on a numeric grading scale metric\nfrom 1to3, with 1indicating no perceived bias and 3indicating a high\nlevel of bias.\n4.6Performance Metrics\nTo evaluate the performance of the models, it\u2019s crucial to employ ap-\npropriate metrics for assessing their results. This entails comparing the\npredictions made by the models for the target variables with their actual\ntrue values. Therefore, standard performance metrics such as accuracy, F 1\nscores, precision, recall, and the confusion matrix were utilized. Addition-\nally, the ROC curve (Receiver Operating Characteristic) and the AUC (Area\nUnder the ROC Curve) were leveraged (Bradley, 1997 ).\nDespite the dataset exhibiting only a slight class imbalance ( 54.49%\nright vs. 45.51% left), employing the ROC curve and AUC enables a\nstraightforward comparison between the models. Furthermore, 5-fold strat-\n3In the end, 40statements were selected, 20for each political leaning class.\n5 results 17\nified cross-validation was utilised to evaluate the robustness, performance\nconsistency, and generalizability of the models.\n5 results\n5.1Model Performance\nThe results of the analysis are compiled and presented. Since the baseline\nmodel was a majority class classifier, presenting its classification report\nis redundant. The tuned values for hyper-parameters of the Logistic\nRegression, Support Vector Machine, and fastText classifier can be seen\nin Table 8in Appendix A. All three models accuracy outperformed the\nmajority classifier baseline\u2019s score of 54.50% and did so to a high dree\ngiven that all had accuracy scores above 80%. This is comparable to the\nperformance of such algorithms in previous research (Conover et al., 2011 ;\nGjurkovi\u00b4 c & \u0160najder, 2018 ). With an accuracy score of 85.40%, the fastText\nclassifier performed considerably better than the LR and SVM, which\nachieved scores of 80.94% and 80.64% respectively. The 5-fold stratified\ncross-validation scores for each model shown in Table 2indicate that the\nmodels are not overfitting given the consistent performance across folds\nand that each fold score is always within 2% of the overall accuracy test\nscores mentioned previously.\nTable 2: Cross-Validation Accuracy Scores Model Comparison\nModel Fold 1Fold 2Fold 3Fold 4Fold 5\nLR 0.8068 0 .7961 0 .8055 0 .7988 0 .7976\nSVM 0.8051 0 .7940 0 .7947 0 .7891 0 .7916\nfastText 0.8658 0 .8486 0 .8618 0 .8579 0 .8329\n5.2Evaluation Metrics\n5.2.1Classification Reports\nGiven the slight class imbalance in the dataset, the F 1-scores can provide\na more accurate representation of how well the models performed on the\nclassification task. Both the left- and right-leaning classes are considered\nequally important for prediction, so the macro average F 1-score will be\nconsidered.\nSimilar to the pattern in accuracy score, Tables 3,4, and 5show that the\nfastText classifier outperformed both the LR ( 80.90%) and SVM ( 80.61%)\n5 results 18\nTable 3: Logistic Regression Classification Report\nClass Precision Recall F 1-Score Support\nleft 0.8038 0 .7688 0 .7859 2915\nright 0.8137 0 .8433 0 .8282 3491\nAccuracy 0.8094 6406\nMacro avg 0.8088 0 .8060 0 .8071 6406\nWeighted avg 0.8092 0 .8094 0 .8090 6406\nTable 4: Support Vector Machine Classification Report\nClass Precision Recall F 1-Score Support\nleft 0.7988 0 .7681 0 .7831 2915\nright 0.8124 0 .8384 0 .8252 3491\naccuracy 0.8064 6406\nmacro avg 0.8056 0 .8033 0 .8042 6406\nweighted avg 0.8062 0 .8064 0 .8061 6406\nwith a weighted macro F 1-score of 85.39%. Interestingly as well, for the\nF1-score per class, the right-leaning class score was consistently higher\nthan the left-leaning class across all machine learning algorithms. For the\nLR, SVM, and fastText classifiers, the models performed 4.2%,4.2%, and\n2.4% higher on the right-leaning class, respectively. This trend also held for\nTable 5: fastText Classification Report\nClass Precision Recall F 1-Score Support\nleft 0.8542 0 .8288 0 .8413 2991\nright 0.8539 0 .8761 0 .8649 3415\naccuracy 0.8540 6406\nmacro avg 0.8541 0 .8525 0 .8531 6406\nweighted avg 0.8540 0 .8540 0 .8539 6406\nthe precision and recall scores, with the only exception being the precision\nscores for the fastText classifiers, where the score for the left-leaning class\nwas0.04% higher than for the right-leaning class. The consistently higher\nperformance on the right-leaning class may suggest that the models are\nbiased towards predicting that class. However, it should be noted that the\nright-leaning class is the majority class with 17,454instances, compared\n5 results 19\nto14,576instances for the left-leaning class. This could explain why this\nslight discrepancy between the metric scores across classes is seen.\n5.2.2Confusion Matrix and ROC-AUC\nThe plotted confusion matrices for the three models, as seen in Figures 4,5,\nand6, visualise the number instances correctly and incorrectly classified\nby the three models. Comparing the predicted label (i.e., political leaning\nFigure 4: Logistic Regression Confusion Matrix\nclass) against the true label, we can see how the results in the previously\noutlined classification reports, the values of which are derived from the\nnumbers in confusion matrices, are consistent with what is reported below.\nThe fastText classifier (Figure 6) correctly classified the most instances,\nwith 2996 out of 3415 for the right-leaning class and 2475 out of 2915 for\nthe left-leaning class. The darker the shade of blue in the confusion matrix\ncells, the more instances were correctly classified. It can again be seen here\nthat across models, the right-leaning class was consistently predicted more\naccurately given the darker shading of the bottom right-hand cell reflecting\nthe number of true negatives (TN).\nFigure 7presents the receiver operating characteristic (ROC) curves plot-\nted for the LR and SVM models. This visual representation of the model\u2019s\nperformance shows relatively high recall given that both ROC curves are\nnear the upper-left corner. The area under the curve (AUC) values for both\nmodels are 0.89, indicating high accuracy when classifying political-leaning\n(Bradley, 1997 ). The exclusion of the fastText classifier from the plot is due\n5 results 20\nFigure 5: SVM Confusion Matrix\nFigure 6: fastText Confusion Matrix\n5 results 21\nto difficulties in extracting the probabilities for predicting each class from\nthe classifier.\nFigure 7: ROC curves for Logistic Regression & SVM\n5.3Feature Importance Scores\nThis section presents the feature importance scores that were extracted\nfrom the LR and SVM models. The scores reflect which word features are\nmost influential for determining the predictions made by the models for\neach of the political leaning classes. Appendix B shows the full list of the\n30most important word features for each class across models (Tables 13,\n14,15, and 16).\nTables 6and7present the top 10features and scores per class for\nboth the LR and SVM. For predicting the right-leaning class, the LR and\nSVM share 8of the same top 10word features in terms of importance,\nalbeit in a different order of importance rank. Likewise, for the left-leaning\nclass, the models share nine of the same word features. With scores of\n-6.42and - 5.85, the features \u2019orthodox\u2019 and \u2019vietnamese\u2019 have the strongest\ninfluence when predicting the right-leaning class for the LR and SVM,\nrespectively. The features \u2019government\u2019 and \u2019cope\u2019, with scores of 7.30and\n5.47, respectively, were the most significant for predicting the left-leaning\nclass between the models. Interestingly, the feature \u2019comrade\u2019 with the\nsecond highest importance score of - 5.0613 for predicting the right-leaning\nclass in the SVM is not even present in the top 10features for the LR when\npredicting right-leaning.\n5 results 22\nTable 6: Logistic Regression: Top 10Feature Importance Scores for Right-leaning\nand Left-leaning classes\nRight Class Feature Importance Score Left Class Feature Importance Score\northodox - 6.4170 government 7.3043\nempathy - 6.3885 commie 7.2161\nvietnamese - 6.3147 cope 6.6969\nanarchist - 6.1799 libertarian 6.5299\ncouncil - 5.7585 em 5.9159\nhonestly - 5.4398 ancap 5.7867\nfucking - 5.2946 disagree 5.6228\nauch - 5.2749 thier 5.5482\nmean - 5.0090 etc 5.2862\nimperialism - 4.9265 retarded 5.0803\n5.4Statements and Bias Metrics\nThe resultant statements that were generated and used to conduct bias\nassessment on the selected features can be seen in Tables 11and12of\nAppendix B, in addition to the corresponding features and bias scores.\nVery minor adjustments were made to the statements by the researcher for\nclarity. These include changing the feature \u2019ancap\u2019 into anarch-capitalism\nin the statements and interpreting the feature \u2019social medium\u2019 as \u2019social\nmedia\u2019. As explained in Section 4.5, three human evaluators were asked\nto score the statements for bias on a scale from 1to3, with 1indicating\nno perceived bias and 3high levels of bias. Across the political-leaning\nclasses, a total of 40bias scores were given, 20for each class. The overall\nmean bias score was 2.58. The left-leaning class mean bias score was 2.67,\nwhich was higher than the right-leaning mean bias score of 2.5.\nPer class, 10word features were assessed, so each word feature had two\ncorresponding statements and thereby two bias scores after assessment.\nThese bias scores were averaged per individual feature. Tables 9and10\n(see Appendix B) present the average bias scores given to the statements\nwith the corresponding feature per class. It can be seen that no statement,\nregardless of class, was perceived as having no bias, given that all average\nbias scores are above 1. For the right-leaning class, statements including the\nfeatures \u2019working class\u2019 and \u2019imperialism\u2019 were given the highest average\nbias score ( 3), whereas \u2019vietnamese\u20194received the lowest score of 1.5. The\n4Example statement: \"Lee, who had survived the Vietnam War and immigrated with his\nwife to the United States, was horrified when the explosions began on the Vietnamese\nvillage set, bringing back memories of the war.\"\n6 discussion 23\nTable 7: SVM: Top 10Feature Importance Scores for Right-leaning and Left-leaning\nclasses\nRight Class Feature Importance Score Left Class Feature Importance\nvietnamese - 5.8548 cope 5.4660\ncomrade - 5.0613 commie 5.3439\nempathy - 4.7747 government 4.7974\nanarchist - 4.7523 disagree 4.6520\northodox - 4.4768 etc 4.6397\nhonestly - 4.4540 ancap 4.6234\nauch - 4.1305 thier 4.5406\nfucking - 4.0347 retarded 4.2137\nimperialism - 4.0034 nyc 4.2132\nfavourite - 3.9840 libertarian 4.1671\nleft-leaning class had no bias score below 2across the statements, with\nthose including the features \u2019commie\u2019 and \u2019disagree\u2019 having maximum\nscores of 3.\n6 discussion\n6.1Results Discussion\nThe results demonstrated that the fastText classifier was the best-performing\nmodel. Across all performance metrics presented (see Tables 3,4, and 5),\nfastText outperformed all other models, achieving an 85.50% accuracy score\nand almost 5% higher than the Logistic Regression (LR) and Support Vector\nMachine (SVM). This is in line with previous studies shown in Section 3,\nwhich saw scores upwards of 90% for fastText classifiers (Stefanov et al.,\n2020 ). Nevertheless, all models showcased significant improvements over\nthe54.50% accuracy score of the majority class classifier baseline, with no\nmodel reporting accuracy scores below 80%. The performances of the LR\nand SVM were almost identical, with the LR\u2019s weighted macro F 1-score\nof80.90% only just edging out the SVM\u2019s of 80.61%. Such results for\nthe LR and SVM are comparable to those of previous findings made by\nGjurkovi\u00b4 c and \u0160najder ( 2018 ), who conducted author profiling to predict\nthe personality types of Reddit users, achieving macro F 1-scores of 81.60%\nand79.60% with the LR and SVM, respectively. However, it should be\nnoted that comparing the performance of the same models across studies\nis in general not always feasible due to differences in target variables being\n6 discussion 24\nstudied, input data used, the nature of the task (binary vs. multi-class\nclassification), and other methodological variations.\nConsistently across models, the right-leaning class was predicted to\nhave higher performance metrics than the left-leaning class. With F 1-scores\nalways at least 2% higher than for the left-leaning class, it seemed the\nmodels were already showing bias towards the right-leaning class before\nbias assessment of statements had even occurred. That being said, the\ndataset used was slightly imbalanced after the removal of the center-leaning\nclass, with the right-leaning class being in the majority ( 54.49% vs. 45.51%\nfor the left-leaning class). Machine learning models tend to display bias\ntowards the majority class, as predicting that class accurately can help\nreduce overall error (J. M. Johnson & Khoshgoftaar, 2019 ). This could\nexplain why the discrepancy was seen between the performances on the\ntwo classes.\nFurthermore, the bias assessment results of the statements and features\nreveal potential biases against political leanings present in the training\ndata and models. These biases can then be perpetuated in the models\u2019\npredictions. With an average bias score of 2.67, and conversely to the bias\nin terms of model performance as explained above, the left-leaning class\nwas evaluated as having more bias than the right-leaning class (average\nbias score: 2.5). The findings are in line with Feng et al. ( 2023 ), who\ndemonstrated that political biases propagated all throughout pre-training\ndata through classifications. They showed that models do indeed adopt\nthe political leanings of the data they are trained on, and that this can\neventually result in unfair and skewed predictions. Nonetheless, assessing\nbiases in machine learning models in the context of author profiling and\nNatural Language Processing (NLP) is an often subjective and complex\ntask due to the nature of language itself and how it is interpreted. In the\ncase of predicting political leaning, biases tend to be conveyed more subtly\nwith regards to lexical choices made by an author than for biases against\npersonal attributes such as gender, age, and race (Devatine et al., 2022 ;\nPeters, 2022 ).\n6.2Relevance\nThe findings of this study can contribute to the scientific research field by\nproviding a better understanding of how machine learning models can\nbe used for predicting the political leaning of online social media users\nand what role bias plays in these predictions. As previously mentioned,\nauthor profiling based on textual data extracted from social media plat-\nforms has in the past primarily focused on predicting personal attributes\n6 discussion 25\nsuch as gender, race, and personality type. citeppeters 2022 algorithmic,\ngjurkovic 2018 reddit.\nMoreover, the findings show that the machine learning algorithms Lo-\ngistic Regression, SVM, and fastText classifier can be utilised to accurately\npredict political leaning when conducting author profiling on such data.\nAdditionally, the Logistic Regression and Support Vector Machine models\nare used to identify which features are most important for predicting the\npolitical leaning of Reddit users. This improves the explainability of these\nmodels when performing such classification tasks and contributes to a\nbetter understanding of the decision-making process occurring behind the\nscenes of these algorithms (Burkart & Huber, 2021 ).\nFurthermore, the findings also have a wider societal impact. By gain-\ning insights into the bias against political leaning that may be present in\nmodels conducting author profiling, more fair and ethical representations\nof individuals can be made. As social media platforms such as Reddit are\nincreasingly becoming key sources of spreading political news, their use in\nthe analysis of public opinion surrounding engagement and discussions of\npolitical issues between platform users may become more prevalent (Feng\net al., 2023 ). Biased machine learning models could lead to incorrect fram-\ning of those issues and affect how the general public perceives them if they\nare used to analyse public sentiment by, for example, determining what\npercentage of users active in politically relevant topic-specific discussion\nforums are left- or right-leaning (Baly et al., 2020 ; Feng et al., 2023 ). Addi-\ntionally, groups with political leanings that are negatively impacted by the\nbias may experience increased marginalisation from public discourse and\nnot be correctly accounted for during policy decision-making processes.\n6.3Limitations\nThe current study had several limitations, primarily related to the ap-\nplied methodologies and results, which require acknowledgement. Firstly,\ngiven that the training data used was derived solely from Reddit and even\nfrom a sub-population of Reddit users who are active on the subreddit\nr/PoliticalCompass, it can limit the generalizability of the models across\ndifferent social media platforms such as Twitter (now X), Facebook, or tra-\nditional news media. These Reddit users are unlikely to be representative\nof the whole population of social media users, and therefore, inferences\nmade based on the results should be taken into context. Additionally, the\nuse of self-reports of the Political Compass Test via flairs for labelling users,\nwhilst an effective approach, can introduce unintended biases from the\nside of the makers of the test itself. By selecting which questions will be\n6 discussion 26\nasked to determine where one will end up on a political spectrum, the test\nmakers own bias could be introduced.\nSecondly, with regards to the applied methodologies, the choice to\ndrop the center-leaning class and convert the classification task from a\nmulti-class to a binary one could have conflated the overall performances\nof the models. As binary classification only has to distinguish between\ntwo classes, it often simplifies the task and leads to less complex decision\nboundaries. In contrast, given the relatively small size of the dataset used,\nthe performance of the models could be limited. Furthermore, as explained\nin6.1, not dealing with the class imbalance present in the dataset may have\nskewed predictions results in favour of the right-leaning class. However,\nthe performance results of the models overall still remain valid due to\noutperforming the baseline model.\nLastly, the methodology for conducting bias assessments of the models\nfaces a number of limitations. Only a small subset of 10features deemed\nimportant for prediction for each class by the LR and SVM models were\nused for generating statements for bias assessment. This can hinder the\nextent to which the eventual extracted bias score for each class is actually\nrepresentative of the true bias in the data and models. Additionally,\nresearcher bias was introduced when selecting the generated statements\nfor final bias assessment (see section 4.4for selection process). Likewise,\nthe three human evaluators likely introduced their own personal bias when\nassessing the statements.\n6.4Future Research\nFuture studies can pursue several approaches to overcome some of the\nearlier limitations and broaden the focus of this thesis. The methodology of\nthe research could be expanded to include a bigger dataset with a greater\nvariety of projected political leanings. To further evaluate the models\u2019\ngeneralizability, it would be beneficial to analyse how well they predict\npolitical leaning across various other online platforms and whether there\nare differences in bias. Facebook and Twitter (now X) are two previously\nstudied examples that could be used (Conover et al., 2011 ; K. Johnson et al.,\n2017 ; Stefanov et al., 2020 ). The challenge here is again finding a labelled\ndataset on which the algorithms can be trained.\nTo aid in doing a more thorough examination of bias, the method used\nfor feature selection and statement generation can be improved. Using sen-\ntiment analysis, the statements could be categorised using a larger number\nof generated statements. Next, statements would be chosen so that there\nis a corresponding statement from each category for every feature that\nis being evaluated. Hopefully, this would lead to a more comprehensive\n7 conclusion 27\nanalysis of bias. Additionally, future research could consider implement-\ning mitigation measures for bias and comparing results before and after\nimplementation.\n7 conclusion\nThe main research goal of this thesis was twofold. In order to contribute\nto the field of author profiling, which has primarily focused on predict-\ning other personal attributes, it first sought to analyse and compare the\nperformances of four machine learning models (including a baseline) in\nclassifying the political leanings of Reddit users. Second, it aimed to\nevaluate the bias that existed in some of these algorithms\u2019 predictions,\nimproving the understanding of the transparency and fairness of machine\nlearning decision-making processes. These contributions were realised by\nanswering the following research questions:\n7.1Sub-RQ 1: Which textual features are most important for distinguishing\nReddit users\u2019 political leaning based on their comment history?\nUsing the SOBR dataset and subsequent TF-IDF vectorization for training,\nfeatures were extracted from the trained Logistic Regression and Support\nVector Machine models. Considerable overlap was seen in the features\nthe models identified as being important for predicting the right- and\nleft-leaning classes. Words like \"orthodox,\" \"anarchist,\" and \"vietnamese\"\nwere found to be significant in predicting right-leaning. On the other hand,\nterms such as \"government,\" \"cope,\" and \"libertarian\" were frequently\nlinked in left-leaning predictions. A selection of 10features from the 30\nmost important would then be used to conduct a bias assessment.\n7.2Sub-RQ 2: To what extent can Logistic Regression, Support Vector Machine,\nand fastText binary classifiers accurately predict Reddit users\u2019 political\nleaning when compared to a baseline majority class classifier?\nWith macro average F 1and accuracy scores of 85.31% and 85.40% re-\nspectively, the fastText classifier achieved the best performance metrics,\nshowing what may be an upper bound in terms of performance for this\nclassification task. Logistic Regression and Support Vector Machine also\ndemonstrated high performance scores of 80.94% and 80.64% for accuracy,\nrespectively. Across other performance metrics, they were also almost iden-\ntical, with Logistic Regression being only minimally better. Every model\nperformed better than the baseline model, indicating that they were able\n7 conclusion 28\nto find meaningful patterns and connections in the data that went beyond\nsimply selecting the class that occurred most frequently. Additionally, the\nmodels consistently performed better when predicting the right-leaning\nclass than the left-leaning one.\n7.3Based on the qualitative evaluation of human evaluators, which features\nintroduce the most bias when predicting Reddit users\u2019 political leaning?\nBased on features identified by the machine learning models, three hu-\nman evaluators were asked to assess the inherent bias that was perceived\nacross the political-leaning class predictions. The evaluation was based on\nstatements that had features embedded in them that were identified by\nthe Logistic Regression and Support Vector Machine as important for pre-\ndicting each political-leaning class. Features for the left-leaning class that\nintroduced some of the most bias were \u2019commie\u2019, \u2019disagree\u2019, and \u2019amend-\nment\u2019. For right-leaning, \u2019imperialism\u2019, \u2019working class\u2019, and \u2019worker\u2019 were\nperceived to contribute the most bias.\n7.4Main RQ: To what extent is bias present within Machine Learning models\nwhen predicting Reddit users\u2019 political leaning based on the textual features\nthese algorithms identify from users\u2019 posted comment history?\nOverall, the findings of the study demonstrated that bias was present in\nthe Logistic Regression and Support Vector Machine models as a result\nof the features that are important for making their predictions. Using a\nnumeric grade scale metric from 1to3, where 1indicates no perceived\nbias and 3indicates a high level of bias, the overall mean bias score across\npolitical leaning classes was 2.58. The left-leaning class was perceived as\nexhibiting slightly more bias with a score of 2.67than the right-leaning\nclass ( 2.5). Seeing as these bias scores are based on statements generated\nfrom the raw text corpus, or rather, the training data, it is likely that\nthe models are perpetuating the real-word biases that are inherent in the\ndata that they have been trained on. In conclusion, the research goal was\nsatisfactorily accomplished, highlighting the need for further research into\nthe evaluation and mitigation of bias in machine learning algorithms.\nreferences 29\nreferences\nAkiba, T., Sano, S., Yanase, T., Ohta, T., & Koyama, M. ( 2019 ). Optuna: A\nnext-generation hyperparameter optimization framework. Proceed-\nings of the 25th ACM SIGKDD international conference on knowledge\ndiscovery & data mining ,2623 \u20132631 .\nAksenov, D., Bourgonje, P ., Zaczynska, K., Ostendorff, M., Schneider, J. M.,\n& Rehm, G. ( 2021 ). Fine-grained classification of political bias in\ngerman news: A data set and initial experiments. Proceedings of the\n5th Workshop on Online Abuse and Harms (WOAH 2021 ),121\u2013131.\nBalakrishnan, V ., & Lloyd-Yemoh, E. ( 2014 ). Stemming and lemmatization:\nA comparison of retrieval performances.\nBaly, R., Da San Martino, G., Glass, J., & Nakov, P . ( 2020 ). We can detect\nyour bias: Predicting the political ideology of news articles. Proceed-\nings of the 2020 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP) ,4982 \u20134991 .\nBaly, R., Karadzhov, G., Alexandrov, D., Glass, J., & Nakov, P . ( 2018 ).\nPredicting factuality of reporting and bias of news media sources.\narXiv preprint arXiv: 1810 .01765 .\nBird, S. ( 2006 ). Nltk: The natural language toolkit. Proceedings of the COL-\nING/ACL 2006 Interactive Presentation Sessions ,69\u201372.\nBojanowski, P ., Grave, E., Joulin, A., & Mikolov, T. ( 2017 ). Enriching word\nvectors with subword information. Transactions of the association for\ncomputational linguistics ,5,135\u2013146.\nBoser, B. E., Guyon, I. M., & Vapnik, V . N. ( 1992 ). A training algorithm for\noptimal margin classifiers. Proceedings of the fifth annual workshop on\nComputational learning theory ,144\u2013152.\nBradley, A. P . ( 1997 ). The use of the area under the roc curve in the\nevaluation of machine learning algorithms. Pattern recognition ,30(7),\n1145 \u20131159 .\nBurkart, N., & Huber, M. F. ( 2021 ). A survey on the explainability of\nsupervised machine learning. Journal of Artificial Intelligence Research ,\n70,245\u2013317.\nCaliskan, A., Bryson, J. J., & Narayanan, A. ( 2017 ). Semantics derived\nautomatically from language corpora contain human-like biases.\nScience ,356(6334 ),183\u2013186.\nConover, M. D., Gon\u00e7alves, B., Ratkiewicz, J., Flammini, A., & Menczer, F.\n(2011 ). Predicting the political alignment of twitter users. 2011 IEEE\nthird international conference on privacy, security, risk and trust and\n2011 IEEE third international conference on social computing ,192\u2013199.\nreferences 30\nCovington, M. A., & McFall, J. D. ( 2010 ). Cutting the gordian knot: The\nmoving-average type\u2013token ratio (mattr). Journal of quantitative lin-\nguistics ,17(2),94\u2013100.\nde Vassimon Manela, D., Errington, D., Fisher, T., van Breugel, B., &\nMinervini, P . ( 2021 ). Stereotype and skew: Quantifying gender\nbias in pre-trained and fine-tuned language models. Proceedings\nof the 16th Conference of the European Chapter of the Association for\nComputational Linguistics: Main Volume ,2232 \u20132242 .\nDevatine, N., Muller, P ., & Braud, C. ( 2022 ). Predicting political orientation\nin news with latent discourse structure to improve bias understand-\ning. 3rd Workshop on Computational Approaches to Discourse (CODI\n2022 ),77\u201385.\nEmmery, C., Chrupa\u0142a, G., & Daelemans, W. ( 2017 ). Simple queries as\ndistant labels for predicting gender on twitter. Proceedings of the 3rd\nWorkshop on Noisy User-generated Text ,50\u201355.\nEmmery, C., Miotto, M., Kramp, S., & Kleinberg, B. ( 2024 ). SOBR: A\ncorpus for stylometry, obfuscation, and bias on reddit. Proceedings\nof the 2024 Joint International Conference on Computational Linguistics,\nLanguage Resources, and Evaluation .\nFeng, S., Park, C. Y., Liu, Y., & Tsvetkov, Y. ( 2023 ). From pretraining\ndata to language models to downstream tasks: Tracking the trails\nof political biases leading to unfair nlp models. arXiv preprint\narXiv: 2305 .08283 .\nGjurkovi\u00b4 c, M., & \u0160najder, J. ( 2018 ). Reddit: A gold mine for personality pre-\ndiction. Proceedings of the second workshop on computational modeling\nof people\u2019s opinions, personality, and emotions in social media ,87\u201397.\nHajare, P ., Kamal, S., Krishnan, S., & Bagavathi, A. ( 2021 ). A machine learn-\ning pipeline to examine political bias with congressional speeches.\n2021 20 th IEEE International Conference on Machine Learning and Ap-\nplications (ICMLA) ,239\u2013243.\nHarris, C. R., Millman, K. J., Van Der Walt, S. J., Gommers, R., Virtanen, P .,\nCournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., et al.\n(2020 ). Array programming with numpy. Nature ,585(7825 ),357\u2013\n362.\nHosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. ( 2013 ).Applied logistic\nregression . John Wiley & Sons.\nHunter, J. D. ( 2007 ). Matplotlib: A 2d graphics environment. Computing in\nscience & engineering ,9(03),90\u201395.\nJoachims, T. ( 1998 ). Text categorization with support vector machines:\nLearning with many relevant features. European conference on ma-\nchine learning ,137\u2013142.\nreferences 31\nJohnson, J. M., & Khoshgoftaar, T. M. ( 2019 ). Survey on deep learning with\nclass imbalance. Journal of Big Data ,6(1),1\u201354.\nJohnson, K., Lee, I. -T., & Goldwasser, D. ( 2017 ). Ideological phrase indi-\ncators for classification of political discourse framing on twitter.\nProceedings of the Second Workshop on NLP and Computational Social\nScience ,90\u201399.\nJoulin, A., Grave, E., Bojanowski, P ., & Mikolov, T. ( 2016 ). Bag of tricks for\nefficient text classification. arXiv preprint arXiv: 1607 .01759 .\nLiang, P . P ., Wu, C., Morency, L. -P ., & Salakhutdinov, R. ( 2021 ). Towards\nunderstanding and mitigating social biases in language models.\nInternational Conference on Machine Learning ,6565 \u20136576 .\nManning, C. D., Raghavan, P ., & Sch\u00fctze, H. ( 2008 ).Introduction to informa-\ntion retrieval . Cambridge university press.\nMatz, S. C., Kosinski, M., Nave, G., & Stillwell, D. J. ( 2017 ). Psychologi-\ncal targeting as an effective approach to digital mass persuasion.\nProceedings of the national academy of sciences ,114(48),12714 \u201312719 .\nMcKinney, W., et al. ( 2010 ). Data structures for statistical computing in\npython. SciPy ,445(1),51\u201356.\nMishra, P ., Del Tredici, M., Yannakoudakis, H., & Shutova, E. ( 2018 ). Author\nprofiling for abuse detection. Proceedings of the 27th international\nconference on computational linguistics ,1088 \u20131098 .\nNielsen, M., Haun, D., K\u00e4rtner, J., & Legare, C. H. ( 2017 ). The persistent\nsampling bias in developmental psychology: A call to action. Journal\nof experimental child psychology ,162,31\u201338.\nOpenAI. ( 2021 ). Chatgpt: Language model for conversational agents.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V ., Thirion, B., Grisel,\nO., Blondel, M., Prettenhofer, P ., Weiss, R., Dubourg, V ., et al. ( 2011 ).\nScikit-learn: Machine learning in python. the Journal of machine\nLearning research ,12,2825 \u20132830 .\nPeters, U. ( 2022 ). Algorithmic political bias in artificial intelligence systems.\nPhilosophy & Technology ,35(2),25.\nPython Software Foundation. ( 2024 ).Python documentation . https://docs.\npython.org/ 3/library/re.html\nQuillBot. ( 2024 ). Quillbot: Ai software tool for academic writing.\nRaza, S., Garg, M., Reji, D. J., Bashir, S. R., & Ding, C. ( 2024 ). Nbias: A\nnatural language processing framework for bias identification in\ntext. Expert Systems with Applications ,237,121542 .\nSalton, G. ( 1983 ). Introduction to modern information retrieval. McGraw-\nHill.\nStefanov, P ., Darwish, K., Atanasov, A., & Nakov, P . ( 2020 ). Predicting the\ntopical stance and political leaning of media using tweets. Proceed-\nreferences 32\nings of the 58th Annual Meeting of the Association for Computational\nLinguistics ,527\u2013537.\nTabassum, A., & Patil, R. R. ( 2020 ). A survey on text pre-processing &\nfeature extraction techniques in natural language processing. Inter-\nnational Research Journal of Engineering and Technology (IRJET) ,7(06),\n4864 \u20134867 .\nThomas, M., Pang, B., & Lee, L. ( 2006 ). Get out the vote: Determining\nsupport or opposition from congressional floor-debate transcripts.\narXiv preprint cs/ 0607062 .\nVolkova, S., Bachrach, Y., Armstrong, M., & Sharma, V . ( 2015 ). Inferring\nlatent user properties from texts published in social media. Proceed-\nings of the AAAI Conference on Artificial Intelligence ,29(1).\nWanner, L., et al. ( 2017 ). On the relevance of syntactic and discourse fea-\ntures for author profiling and identification. Proceedings of the 15th\nConference of the European Chapter of the Association for Computational\nLinguistics: Volume 2, Short Papers ,681\u2013687.\nWaskom, M. L. ( 2021 ). Seaborn: Statistical data visualization. Journal of\nOpen Source Software ,6(60),3021 .\nAappendix a 33\na appendix a\na.1Software and hardware\nFor preprocessing the data and programming all models, the programming\nwas conducted in the Python language (version 3.11.5) using the Jupyter\nNotebook extension within the source-code editor Visual Studio Code. The\nfollowing libraries were used: Pandas (McKinney et al., 2010 ), Numpy\n(Harris et al., 2020 ), re (Python Software Foundation, 2024 ), NLTK (Bird,\n2006 ), Matplotlib (Hunter, 2007 ), Scikit-Learn (Pedregosa et al., 2011 ), Op-\ntuna (Akiba et al., 2019 ), Seaborn (Waskom, 2021 ), and fastText (Bojanowski\net al., 2017 ).\nFigure 8: Count of Posts by Political Leaning\nTable 8: Tuned Hyperparameters\nHyperparameter Values tuned on LR SVM fastText\nRegularization Between 0.1and10 3 .75 2 .20\nLearning rate Between 0.01and1.0 0 .61\nEpochs Between 5and50 34\nWord n-grams Between 1and5 2\nAappendix a 34\nFigure 9:50Most Common Words per Class\nBappendix b 35\nb appendix b\nTable 9: Right-leaning Average Bias Scores by Feature\nFeature Average Bias Score\nvietnamese 1.5\nanarchist 2.67\northodox 2.67\nworking class 3\nrepublican 2.17\nempathy 2.67\nimperialism 3\ncouncil 2.17\nworker 2.83\npandemic 2.33\nTable 10: Left-Average Bias Scores by Feature\nFeature Average Bias Score\ngovernment 2.67\ncommie 3\nlibertarian 2.5\nstate 2.33\nproperty right 2.67\nsocial media 2.33\nancap 2.83\namendment 2.83\nself defense 2.5\ndisagree 3\nBappendix b 36\nTable 11: Right-leaning Bias Scores by Statement Feature\nFeature Statement Bias Score\nvietnamese \"Lee, who had survived the Vietnam War and immigrated\nwith his wife to the United States, was horrified when the\nexplosions began on the Vietnamese village set, bringing\nback memories of the war.\"1.67\nanarchist \"I\u2019ve read him though, and he\u2019s the only thinker I\u2019ve seen\nwhose distilled Rothbard and Mises into a straightforward,\nactionable ethic of how societies would best be structured\nby anarchists.\"2.33\northodox \"If someone is born into an ultra-orthodox Jewish family,\ntheir environment is going to either lead them to a near-full\nscale acceptance of that identity, or it\u2019s going to lead to a\nnear-full scale rejection of it.\"2.67\nworking\nclass\"Part of me wants to watch the farmers and truckers and\nreal working class just go on strike and stop working, and\nwatch these social elites smart people just starve and suffer.\"3\nrepublican \"I personally think it is just as unfair to call your run of the\nmill Democrat a communist as it is to call your run of the\nmill Republican a fascist.\"1.67\nempathy \"You dawn the guise of empathy to make you appear as if\nyou\u2019re just \u2019helping out\u2019 but truly the end goal is complete\ncensorship and maintaining power/ the status quo.\"2.67\nimperialism \"A global collapse would end the very recent popularity\nof such ideas and bring back the ideals which guided Hu-\nmanity through the overwhelming majority of its History:\nReligion and tribalism/nationalism/imperialism.\"3\ncouncil \"The one thing that I couldn\u2019t stand was during the daily\ncouncil, where people were talking for the sake of talking\nand disagreeing with someone that was saying the exact\nsame thing, but with different words.\"1.67\nworker \"Of course this is based on the idea that immigration can\nnegatively impact workers conditions but I\u2019m not comment-\ning one way or the other on that as it wasn\u2019t my point to\nbegin with.\"2.67\nContinued on next page\nBappendix b 37\nTable 11continued from previous page\nFeature Statement Bias Score\npandemic \"I understand there are concerns about hospital capacities,\nbut I don\u2019t think this is as big of a concern as its made out\nto be and definitely is not as big of a problem as it was at\nthe start of the pandemic.\"2.67\nvietnamese \"The way at which I arrived to such a conclusion is based\non the fact that after we left, the Vietnamese were able to\nsort out their differences and become one nation.\"1.33\nanarchist \"Although the early West was not completely anarchistic,\nwe believe that government as a legitimate agency of co-\nercion was absent for a long enough period to provide\ninsights into the operation and viability of property rights\nin the absence of a formal state.\"3\northodox \"The Eastern Church emphasizes the unity of the One Holy\nCatholic and Apostolic Church, tracing its lineage back to\nJesus Christ and the apostles, a doctrine central to Eastern\nfaith.\"2.67\nworking\nclass\"I think many are just pretending they can mobilize the\nworking class without government intervention, but in real-\nity the ultimate goal is to replace the capitalist class with\nthemselves by any means necessary.\"3\nrepublican \"In both cases the Democrat that followed the Republican\ndoubled down on the interventionist\nempathy \"I\u2019m interested in whether a vegan should be able to breed,\nraise and kill chickens and cows to feed their cat, and not\nwhether we should feel some empathy for the cat or their\nowner.\"2.67\nimperialism \"They just look at our strange customs, weird laws, cultural\nimperialism, and especially our inflated patriotism and\nthink we\u2019re rude and hate everyone when that can\u2019t be\nfurther from the truth.\"3\ncouncil \"Again it\u2019s way more complicated but people focus too\nmuch on appraisals, yes they do go up way more than\nthey should for some and yes everyone should protest, but\npeople really need to start holding their city councils and\nschool boards accountable for setting their own budget.\"2.67\nContinued on next page\nBappendix b 38\nTable 11continued from previous page\nFeature Statement Bias Score\nworker \"Sure, a corporation might be able to function for longer\nwithout a CEO than without a workforce, but the CEO is\nwithout a doubt more important and more at risk of losing\nhis reputation and money through mistakes than 1random\nworker.\"3\npandemic \"These impacts are likely to be particularly damaging dur-\ning a pandemic, when supply and demand conditions\nchange drastically with lots of disruption to workplaces\nand supply chains that raise the costs of supplying goods\nin ways lawmakers might not observe.\"2\nBappendix b 39\nTable 12: Left-leaning Bias Scores by Statement Feature\nFeature Statement Bias Score\ngovernment \"Personally, I rather just my own government have access\nto that much data about me because at least then I can vote\nfor representatives who care about protecting that data (or,\ntry to).\"2.33\ncommie \"I\u2019ve played most of these and agree with good taste com-\nments. The thing about commies you\u2019ll never see in spaces\nlike this is we love making fun of and fighting amongst\nourselves and slightly different communists and this game\nhas some of my favorite leftists critique in this way.\"3\nlibertarian \"I for example would call what you just described libertar-\nian rather than liberal, I associate the economic system with\nliberal and the social aspects with libertarian rather than\nthe other way around.\"2.67\nstate \"The problem is y\u2019all are so blinded by your rage over\nBernie losing that you\u2019re ignoring state and local candidates\nand trying to justify staying home because you don\u2019t like\nsomeone who isn\u2019t actually up for election.\"2.67\nproperty\nright\"So to have ownership or any property rights at all there\nmust be mutually assured destruction at play to discourage\nignoring those property rights at the same scale as the\nthreat.\"3\nsocial\nmedia\"While I certainly understand skepticism towards influ-\nencing on several grounds\u2013including disclosure ethics and\nproblematic brands\u2013those issues don\u2019t change the fact that\n\u2019social media influencer\u2019 is a bona fide profession that re-\nquires some skill.\"2.33\nancap \"So what\u2019s your alternative, chaos? Are you an Anarcho-\ncapitalist? Are Sanders and AOC pathological liars? How\nabout the leadership of responsible social democracies? Is\nArderne a pathological liar? Was Pierre Trudeau? Lincoln?\nNihilism is what your current leaders want of you.\"3\namendment \"The modern american state wields far too much legitimacy\nand support for the populace to just go along with the\nresults of an armed coup by a bunch of second amend-\nmenters.\"3\nContinued on next page\nBappendix b 40\nTable 12continued from previous page\nFeature Statement Bias Score\nself defense \"When your argument is that all wars are unjust and\nshouldn\u2019t be fought, and I argue that wars can be a form\nof self defense, but you won\u2019t bend on that point because\nyou think wars are unjust, yeah I think you\u2019re making an\nargument against just self-defense.\"2.33\ndisagree \"How does your job lead you to disagree with the idea that\nemployers use the idea of unskilled work to keep wages\nlow? So \u2019unskilled labour\u2019 is not a myth because labour\ndemanding high skill exists? I am not following i think.\"3\ngovernment \"I don\u2019t think it\u2019s crazy to say that the government should\nregulate businesses when they prove time and time again\nthat they are incapable of operating in a responsible fash-\nion.\"3\ncommie \"I think a lot of this has to do with the fact that most of\nthese folks never opened a book and read the history of\nthese other nations when commie and marx views became\nuplifted.\"3\nlibertarian \"Libertarianism is centered around liberty. The less en-\nforcement there is, the more liberty there is. Therefore,\nenforcement is as central to libertarianism as liberty.\"2.33\nstate \"That\u2019s what the Roe vs. Wade decision determined previ-\nously, and now possibly since the decision isn\u2019t final and\nmay even just be a dissenting opinion, it looks like it\u2019s going\nto be up to each state to make the determination of that\nborder.\"2\nproperty\nright\"How much propagandized nationalism did your country\ngive to you? If we look at the places with the lowest levels of\nproperty rights, these are the places with the least economic\ndevelopment, the most poverty, and they\u2019re quite literally\nthe only places in the world not getting richer.\"2.33\nsocial\nmedia\"And while social media can be very negative, personally\nI\u2019ve never really felt the negative consequences people are\nalways on about? It\u2019s still just nice to be able to see like \u2019oh\nso and so had a baby\" or whatever.\"2.33\nancap \"It means they can save money just as well as in capitalism.\nAlso, I\u2019m failing to see where money even plays in in this so-\nciety, or what it means since most of the anarcho-capitalism\ncommunity seems against bitcoin.\"2.67\nContinued on next page\nBappendix b 41\nTable 12continued from previous page\nFeature Statement Bias Score\namendment \"If the 2nd Amendment exists so that citizens can stand\nagainst the US military, then we need radio jammers, en-\ncrypted communication networks, long range surveillance\nequipment, SAM systems, heavy artillery, tanks, stealth\ndrones, and god damn nukes.\"2.67\nself defense \"Self defense is for getting attacked while minding your\nown business, not for going out of your way to insert your-\nself into a dangerous situation where you\u2019re prone to panic.\"2.67\ndisagree \"Asking me to prove that we live under patriarchy is like\nasking me to prove that we live under capitalism; we just\ndo, no scholar anywhere on Earth would disagree and be\ntaken seriously, it\u2019s absurd.\"3\nBappendix b 42\nTable 13: Logistic Regression: Left-leaning Top 30Feature Importance Scores\nFeature Coefficient\ngovernment 7.304\ncommie 7.216\ncope 6.697\nlibertarian 6.530\nem 5.916\nancap 5.787\ndisagree 5.623\nthier 5.548\netc 5.286\nretarded 5.080\nreddit 5.003\nbuddy 4.941\nproperty right 4.901\nstate 4.756\nnyc 4.733\ncum cum 4.707\nsocial medium 4.593\nromania 4.518\nought 4.506\nalmost 4.375\nmag 4.315\nprobably 4.309\ngear 4.215\njag 4.200\natf 4.116\ntrek 4.109\nfed 4.071\nagent 4.055\nlogically 4.045\npara 3.987\nBappendix b 43\nTable 14: Logistic Regression: Right-leaning Top 30Feature Importance Scores\nFeature Coefficient\northodox - 6.417\nempathy - 6.388\nvietnamese - 6.315\nanarchist - 6.180\ncouncil - 5.759\nhonestly - 5.440\nfucking - 5.295\nauch - 5.275\nmean - 5.009\nimperialism - 4.926\ncomrade - 4.815\npandemic - 4.757\nsom - 4.628\nfavourite - 4.507\nyo - 4.466\nbernie - 4.443\nskin - 4.434\ndoesnt - 4.338\nrepublican - 4.335\nrealise - 4.309\nworking class - 4.260\nsa - 4.234\nworker - 4.222\nexcellent - 4.219\nretail - 4.213\nweird - 4.201\noften - 4.171\ninvestigation - 4.097\nvisual - 4.095\nmusk - 4.060\nBappendix b 44\nTable 15: SVM: Left-leaning Top 30Feature Importance Scores\nFeature Coefficient\ncope 5.466\ncommie 5.344\ngovernment 4.797\ndisagree 4.652\netc 4.640\nancap 4.623\nthier 4.541\nretarded 4.214\nnyc 4.213\nlibertarian 4.167\nsocial medium 4.043\nem 3.862\npray 3.811\nalmost 3.578\nbuddy 3.573\nreddit 3.551\nwir 3.514\njag 3.482\ntrek 3.454\nproperty right 3.447\nprobably 3.401\nlogically 3.317\nagent 3.177\nromania 3.177\nself defense 3.164\nought 3.153\nfrankly 3.107\natf 3.042\namendment 3.011\nstate 3.003\nBappendix b 45\nTable 16: SVM: Right-leaning Top 30Feature Importance Scores\nFeature Coefficient\nvietnamese - 5.855\ncomrade - 5.061\nempathy - 4.775\nanarchist - 4.752\northodox - 4.477\nhonestly - 4.454\nauch - 4.131\nfucking - 4.035\nimperialism - 4.003\nfavourite - 3.984\nyo - 3.978\nworking class - 3.615\nexcellent - 3.613\nmusk - 3.612\npandemic - 3.555\ndoesnt - 3.538\nmean - 3.536\nbernie - 3.521\nretail - 3.517\ncouncil - 3.514\nrepublican - 3.444\nsom - 3.338\nrealise - 3.338\ngay people - 3.297\nskin - 3.295\nvisual - 3.293\nunity - 3.278\nyikes - 3.256\nindustry - 3.248\nmean production - 3.242", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "ASSESSING BIAS IN PREDICTIONS OF REDDIT USERS'POLITICAL LEANING", "author": ["BEN WITTE"], "venue": "NA", "pub_year": "NA", "abstract": "Predicting political leanings on social media platforms is increasingly important as global  polarisation rises. These platforms can be leveraged by Machine Learning (ML) algorithms for"}, "filled": false, "gsrank": 317, "pub_url": "http://arno.uvt.nl/show.cgi?fid=182484", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:gsdQLhFu2XsJ:scholar.google.com/&output=cite&scirp=316&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=gsdQLhFu2XsJ&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:gsdQLhFu2XsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://arno.uvt.nl/show.cgi?fid=182484"}}, {"title": "Web retrieval agents for evidence-based misinformation detection", "year": "2024", "pdf_data": "Published as a conference paper at COLM 2024\nWeb Retrieval Agents\nfor Evidence-Based Misinformation Detection\nJacob-Junqi Tian\nMcGill |MilaHao Yu\nMcGill |MilaYury Orlovskiy\nUC BerkeleyTyler Vergho\nDartmouthMauricio Rivera\nMila\nMayank Goel\nIIT HyderabadZachary Yang\nMcGill |MilaJean-Franc \u00b8ois Godbout\nUniversit \u00b4e de Montr \u00b4eal|MilaReihaneh Rabbany\nMcGill |Mila\nKellin Pelrine\nMcGill |Mila\nkellin.pelrine@mila.quebec\nAbstract\nThis paper develops an agent-based automated fact-checking approach for detecting\nmisinformation. We demonstrate that combining a powerful LLM agent, which\ndoes not have access to the internet for searches, with an online web search agent\nyields better results than when each tool is used independently. Our approach\nis robust across multiple models, outperforming alternatives and increasing the\nmacro F1 of misinformation detection by as much as 20 percent compared to\nLLMs without search. We also conduct extensive analyses on the sources our\nsystem leverages and their biases, decisions in the construction of the system\nlike the search tool and the knowledge base, the type of evidence needed and its\nimpact on the results, and other parts of the overall process. By combining strong\nperformance with in-depth understanding, we hope to provide building blocks for\nfuture search-enabled misinformation mitigation systems.\n1 Introduction\nMisinformation and disinformation are significant societal challenges that threaten to intensify with\nprogress in generative AI (Chen & Shu, 2023). Recent work (Chen & Shu, 2023; Pelrine et al., 2023)\nhas shown that Large Language Models (LLMs) can effectively detect misinformation and provide a\npotential path to mitigate harm at scale. However, LLMs suffer from hallucinations and often lack\nknowledge of recent events due to a fixed training data window. These problems can be significantly\nmitigated if models have access to external sources of information. In this work, we propose a method\nto retrieve and leverage evidence from the web for misinformation detection .\nSurprisingly, there are relatively few tools for Retrieval-Augmented Generation (RAG) that combine\nexternal data sources with recent LLMs in the domain of misinformation detection (Chen & Shu,\n2023). In this study, we aim to build a strong, comprehensive approach that combines LLMs and\nRAG by integrating natural language understanding techniques for claim decomposition (Yao et al.,\n2022; Min et al., 2023; Chern et al., 2023; Zhang & Gao, 2023). In particular, we prompt an LLM to\ngenerate queries, and then answer them using another LLM connected to a web search engine. We\nevaluate the performance of this approach across a wide range of models: Vicuna, Mixtral, Claude,\nGPT-3.5, and two versions of GPT-4. We find that web-retrieval techniques improve the performance\nof all models except Vicuna; we also confirm that this improvement generally increases with the\nperformance of the underlying model. In addition, we compare two search approaches\u2014Cohere\nCoral with web connector, and DuckDuckGo with GPT-3.5 summarization\u2014and confirm that they\nare both effective. Thus, our results indicate that the fully customizable DuckDuckGo tool can be\nused in future work, along with the more locked-in Cohere one; they also suggest that our framework\ncan be generalized to other search engines as well. We then analyze the sources retrieved, showing\nOur code is available on GitHub: https://github.com/ComplexData-MILA/webretrieval\n1arXiv:2409.00009v2  [cs.IR]  9 Oct 2024\nPublished as a conference paper at COLM 2024\nthat: (1) having more sources is better; (2) the pipeline is not overly reliant on any one source; and (3)\nthe sources it naturally uses exhibit little bias overall and high credibility. We continue investigating\ndifferent components of the pipeline, including the summarizer and the knowledge base. We then\nturn to how and when web-searches are effective, showing that performance varies depending on\nthe missing information and that some types of missing information may even make web searches\ncounterproductive, which may point towards ways to improve both effectiveness and efficiency in\nRAG. We proceed to investigate uncertainty quantification, and how enabling web-search impacts\nthe system\u2019s calibration capabilities, through a direct confidence elicitation prompt. Finally, we\nexamine several datasets where web searches maintain but do not improve performance, showing its\nlimitations and highlighting how search can be useful even without performance improvements.\nOur key contributions are the following:\n\u2022We build a search framework that significantly improves performance for misinformation\ndetection across multiple models, up to 20% depending on the model used (Table 2),\noutperforming other search frameworks.\n\u2022We conduct extensive analyses of different options within this framework, showing effective\noptions (e.g., one can use either pre-built Cohere or customizable DuckDuckGo) and ones\nthat should be avoided (e.g., using Wikipedia instead of the open web as knowledge base).\n\u2022We go beyond pure performance with in-depth analysis of sources used, biases, different\ntypes of missing evidence, and other aspects of the pipeline. This analysis brings the system\ncloser to real-world viability and highlights limitations and opportunities for future work.\n2 Related work\nMany studies have shown the benefits of retrieving information to augment fact-checking and\nmisinformation detection (Bekoulis et al., 2021; Kondamudi et al., 2023; Zhou & Zafarani, 2020).\nHowever, much of this past work integrates retrieval with older models like BERT (Liao et al., 2023),\nBART (Sundriyal et al., 2022), and memory networks (Ebadi et al., 2021; Ying et al., 2021). We note\nthat these approaches have not demonstrated strong enough performance improvements to solve the\nproblem of misinformation detection. Indeed, the task of detecting fake news or false information is\nchallenging due to its ambiguous nature, where misinformation often contains a mix of true and false\nstatements, making it difficult to discern the truth. It also requires up-to-date knowledge of real-world\nevents and a nuanced understanding of deception techniques employed by malevolent actors who\nwant to avoid detection. Nevertheless, LLMs have emerged as very promising research avenues for\nthis task (Chen & Shu, 2023; Pelrine et al., 2023). Recent work has confirmed that these models\nstill struggle with insufficient context, ambiguous inputs and hallucinations (Pelrine et al., 2023; Hsu\net al., 2023; Orlovskiy et al., 2024), but identifying the missing information and providing additional\ncontext significantly improves the performance of these models on ambiguous statements (Orlovskiy\net al., 2024; Pelrine et al., 2023). There is, therefore, a need to integrate strong retrieval tools into the\nnew, LLM-based misinformation mitigation systems.\nOne particularly promising approach to LLM-based systems in the misinformation detection and\nfact-checking domains is decomposing inputs of uncertain veracity, such as statements or articles,\ninto smaller units like claims. This enables chain-of-thought (Wei et al., 2022) reasoning particularly\nadapted to these tasks. For example, the ReAct framework (Yao et al., 2022) improves performance\non the HotPotQA dataset (Yang et al., 2018) by decomposing its reasoning trace into a series of\nactions and observations traces for each thought generated (Yao et al., 2022). Likewise, the HiSS\nprompting method instructs the model to decompose a claim into several subclaims, that are then\nverified individually via multiple question-answering steps (Zhang & Gao, 2023). Three common\napproaches include \u2018FactScore\u2019, which decomposes claims into \u2018atomic facts\u2019 (Min et al., 2023),\nalong with \u2018FacTool\u2019 (Chern et al., 2023) and \u2018FOLK\u2019 (Wang & Shu, 2023), which are both designed\nto extract individual claims from longer statements.\nAlthough several studies have highlighted the benefits of using RAG for LLMs in general applications\n(Saad-Falcon et al., 2023; Bendersky et al., 2023; Wang et al., 2024; Gao et al., 2024), there are\nsurprisingly few analyses that apply this technique to misinformation detection and even fewer\nthat combine it with decomposition. In a survey of over 650 works related to misinformation and\nLLMs (Chen & Shu, 2023), only two RAG misinformation detection methods were discussed (Chern\n2\nPublished as a conference paper at COLM 2024\net al., 2023; Cheung & Lam, 2023). The first focused on factuality in more general problems\nlike mathematics and code generation, while the latter did not use decomposition. Given that\ndecomposition and RAG could provide both better reasoning and evidence, we believe that such an\napproach will greatly improve the performance of LLMs for misinformation detection.\nThe closest work to this approach is HiSS (Zhang & Gao, 2023). HiSS prompts the LLM to\ndecompose the claim with a few-shot demonstration, and triggers search if the LLM is not confident\nto answer directly. It outperforms other systems like ReACT (Yao et al., 2022) in this domain.\nHowever, we found that its effectiveness is inconsistent, particularly as its performance gets worse\nwith better models (GPT-3.5 vs. GPT-4; see Section 4). Thus, in this study, we aim to develop a stable\nframework that performs well across a range of models. We also seek a deeper understanding of the\nsearch process, including when it helps, what sources get used, and how different design choices\naffect it.\n3 Methodology\nWe enable information retrieval by explicitly permitting the main LLM agent to invoke search multiple\ntimes and encouraging the LLM to perform extensive reasoning before giving a prediction. This leads\nthe LLM to naturally produce an effective decomposition of the task, in contrast to pipelines like\nFactLlama (Cheung & Lam, 2023), which invoke search only on the input. We perform the search\nwith another LLM agent with a web connection and return the search agent\u2019s output to the main\nagent. The main agent repeatedly triggers this process until it decides to give a final prediction (for\nan example of a full input and output, see Appendix A.10). We test this pipeline across several recent\nmodels (GPT-4, GPT-3.5, Cohere Coral, Mixtral, Claude 3, and Vicuna-1.5), focusing particularly on\nthe LIAR-New dataset (Pelrine et al., 2023).\n3.1 Enabling search\nHere we describe how we enable instruction-tuned generative LLMs to \u201csearch\u201d online, especially\nthose that do not explicitly support function calling. In the prompt, we inform the model that it has\naccess to a search tool, and provide instructions on how to invoke it:\nYou have access to a search engine tool. To invoke search,\nbegin your query with the phrase \"SEARCH: \". You may\ninvoke the search tool as many times as needed.\nWe parse the generator LLM output to extract the prescribed pattern. While invoking the search\nfunction, we supply the text that comes right after \u201cSEARCH: \u201d to the search pipeline. That pipeline\ndoes not have access to the original statement that we want to verify.\nWe explored two different implementations of the search pipeline: with the Cohere \u201cChat with RAG\u201d\nAPI, and by summarizing the output of the DuckDuckGo search API.\nIn the Cohere pipeline, we invoke the Cohere Chat API with the official \u201cweb-search\u201d connector\nenabled. We ask it to \u201cLook up info\u201d with the following code and template:\nresponse = cohere.Client.chat(\nmodel=\"command\",\nmessage=\"Look up info about the following: {query}\",\nconnectors=[{\"id\": \"web-search\"}]\n)\nAbove, the placeholder \u201c {query}\u201d in the message to Cohere \u201cChat with RAG\u201d would be replaced\nwith the text extracted from the generator LLM output. The output of this search agent is a summary\nof the search results in natural language. We prepend the output with \u201cSearch result: \u201d and add it to\nthe conversation context as a new message with role user , then resume the main (offline) agent\u2019s\ngeneration. This results in interactions between the main agent and search agent as in Table 1.\n3\nPublished as a conference paper at COLM 2024\nComponent Description\nGenerator Analysis: Let\u2019s first search for the historical price of oil in June 2008 and March\n2022. SEARCH: Historical price of oil in June 2008\nQuery Historical price of oil in June 2008\nCohere\nResponseOil peaked at $126.33 (inflation-adjusted price of $177.26) in June 2008. The\nprice of Brent crude was $132.32 per barrel. This was the absolute peak, from\nwhich the price dropped sharply to $31.04 in February 2009. This was one of\nthe sharpest drops in oil history due to the financial crisis, which caused energy\nprices to fall due to diminishing demand, contraction of credit with which to\nmake purchases, and lower corporate earnings which led to layoffs and increased\nunemployment.\nSummarized\nDuckDuckGo\nResponseSearch result: The search results provide information on the price of oil in June\n2008. CNN Business reported that oil prices settled above $140 a barrel for the\nfirst time on June 27, 2008, during a thinly traded session. This was influenced\nby a selloff on Wall Street that sent the Dow into bear market territory . . .The\nspecific price of Brent crude in June 2008 is mentioned in one search result as\n$132.32 per barrel. Overall, the search results provide diverse information about\nthe price of oil in June 2008. However, not all results mention the specific price\nfor that month, and some focus more on the broader context and impact of the\n2008 financial crisis on oil prices.\nTable 1: Example of parsed search query and response from Cohere \u201cChat with RAG\u201d API.\nDuckDuckGo As an alternative to the Cohere service, we utilize the DuckDuckGo search engine\nthrough its web search API.1We chose this search engine because there is a free API, unlike, for\nexample, Google and Bing. We gather the titles and content of the top 10 search results of the query\nand use GPT-3.5 Turbo to summarize the content with the following prompt.\nPlease summarize the searched information for the query. Summarize\nyour findings, taking into account the diversity and accuracy\nof the search results. Ensure your analysis is thorough and\nwell-organized.\nQuery: {query}\nSearch results: {results}\nWikipedia retrieval with local embeddings We also implemented a local retrieval system contain-\ning all Wikipedia English pages (cutoff at 2023.11) with the bge-large-en-v1.5 embedding model.\nThe embeddings of all chunks are indexed with the FAISS (Douze et al., 2024) library. The queries\nare generated with the same offline agent setup, and the retrieved chunks are passed through the\nsummarization system and then back to the offline agent, as described above. This dense retrieval\nsystem provides an alternative to DuckDuckGo and similar search engines. In particular, it provides a\ncomparison of open web search, which is increasingly popular and enabled by recent LLMs, with\nmore traditional fixed knowledge base retrieval mechanisms, using one of the most widely leveraged\nknowledge bases for such systems.\n3.2 Extracting predictions\nWe prompt the main agent to return a binary number as the prediction:\n... state \"True statement; Factuality: 1\" if you think the\nstatement is factual, or \"False statement; Factuality: 0\"\notherwise.\nWe repeat each experiment 5 times and report the 95% confidence interval over the five F1 scores\n(this generally gives a larger but more thorough interval than the commonly reported standard error).\n1Python Package: duckduckgo search\n4\nPublished as a conference paper at COLM 2024\n3.3 Baselines\nOffline models We compare the baseline \u201coffline\u201d performance of the models with our own search\nenabled framework. The prompt for the offline version is as follow:\nYour task is to analyze the factuality of the given statement.\nAfter providing all your analysis steps, summarize your\nanalysis and state \"True statement; Factuality: 1\" if you\nthink the statement is factual, or \"False statement;\nFactuality: 0\" otherwise. You should begin your summary with\nthe phrase \"Summary: \". Statement: {statement}\nCohere Chat with RAG Note that in the main experiment setup, we do not provide the Cohere\n\u201cChat with RAG\u201d model access to the original statement that we seek to verify. Similarly, for\nDuckDuckGo, we also just prompt the modified query, instead of the original statement. In both\ncases, this ensures we are leveraging our decomposition framework. However, the Cohere model\nwhich has been set up for web search could potentially do it effectively on its own, without the help\nof the generator LLM, if it were given the original statement. Hence, we implement it as a baseline\nto determine if the \u201csearch\u201d pipeline adds any benefit beyond just invoking Cohere Chat with RAG\ndirectly. To do this, we query Cohere \u201cChat with RAG\u201d with the same prompt given to other generator\nLLMs when the search action is disabled (see the above prompt).\nHiSS We selected this baseline as it provided the state-of-the-art decomposition and web search\napproach in this domain. We implemented HiSS (Zhang & Gao, 2023) using the updated code\nprovided by the authors. We test both the original version which predicted 6-way labels (also\nconverted to binary to match our other evaluation) and a direct binary version where we minimally\nchanged the prompt by replacing the part that lists the 6 labels with \u201ctrue and false\u201d. As the underlying\nmodel, we use GPT-3.5 like the original paper, and we also test GPT-4. We use the most recent\nversion of both at the time of this writing, 0125.\nWikiChat We implement WikiChat (Semnani et al., 2023), a model grounded on the English\nWikipedia that outperforms other models on factual accuracy retrieval baselines, using the code\nprovided in the original repository.2However, instead of using text-davinci-003 as the engine model\nlike in the original paper, we use GPT-3.5-turbo-instruct because text-davinci-003 was deprecated by\nOpenAI. We follow the configuration suggested in their code repository to obtain results comparable\nto the GPT-3.5 results reported in their original paper. The prompt used for WikiChat is as follows:\nYour task is to analyze the factuality of the given statement.\nAfter providing all your analysis steps, summarize your\nanalysis and state \"True statement; Factuality: 1\" if you\nthink the statement is factual, or \"False statement;\nFactuality: 0\" otherwise. You should begin your summary with\nthe phrase \"Summary: \" and conclude your response with \"\nFactuality: 1\" or \"Factuality: 0\". Statement: {statement}\nThis matches the original except we explicitly specify concluding with \u201dFactuality: 1\u201d or \u201dFactuality:\n0\u201d, because we noticed that without this, the refining step would strip the score from the end of the\nmodel\u2019s response and lead to parsing errors.\n3.4 Uncertainty quantification\nWe investigated the system\u2019s uncertainty quantification performance through a direct confidence\nelicitation methodology (Lin et al., 2022), which has been previously demonstrated to be effective\nin the misinformation detection context (Pelrine et al., 2023; Rivera et al., 2024). Specifically, we\nprompted the generative LLMs to provide an uncertainty estimation of its analysis once we extracted\nthe system\u2019s analysis and predictions:\n2https://github.com/stanford-oval/WikiChat\n5\nPublished as a conference paper at COLM 2024\nStatement: {misinformation statement}\nProposed analysis: {web-retrieval agent\u2019s analysis}\nYour task is to rate the uncertainty of the proposed analysis on a\nscore from 0 to 100, where 0 represents definitely\nuncertainty and 100 represents definitely certain. Please,\nonly answer with your score.\n3.5 Datasets\nOur main dataset is LIAR-New (Pelrine et al., 2023). This dataset consists of statements from the\nfact-checking website PolitiFact.org. It was chosen because in addition to statements and factuality\nlabels, it also contains labels on examples that are missing context. In particular, statements are\nclassified as Possible, Hard, or Impossible based on whether it should be possible to evaluate the\nfactuality without additional input context.\nWhile the raw LIAR-New dataset provides six factuality categories, we follow common practice\n(Pelrine et al., 2023) and map the \u201chalf-true\u201d, \u201cmostly-true\u201d, as well as \u201ctrue\u201d levels as 1 (\u201cTrue\u201d).\nThe other three factuality categories \u2013 \u201cfalse\u201d, \u201cbarely-true\u201d, and \u201cpants-fire\u201d \u2013 are labelled as 0\n(\u201cFalse\u201d). Given that the resulting dataset is skewed towards label 0, we report macro F1 instead\nof accuracy for each experiment. We randomly sample 588 examples from the larger dataset to\nreduce compute and API costs.3The label distribution of the sample, before binarizing, is given in\nAppendix A.1.\nBesides LIAR-New, we also test performance on FEVER-v2 (Thorne et al., 2019), which is a fact-\nchecking dataset based on Wikipedia claims but constructed to be more challenging and adversarial\nthan the original FEVER dataset (Thorne et al., 2018). On this dataset we compare with the recent\nstate-of-the-art method of Zhang et al. (2024) which uses a multi-hop approach with a claim-evidence\ngraph. Additionally, we also evaluate performance on the FEVER, FaVIQ (Park et al., 2022) and\nX-FACT (Gupta & Srikumar, 2021) fact-checking datasets. The latter is multilingual.\n4 Results\nBaseline Model Search\nCohere Chat with RAG (3.3) 63.9%\u00b13.5%\nHiSS GPT-3.5 (Zhang & Gao, 2023) 60.6%\nHiSS GPT-3.5 Binary (Zhang & Gao, 2023) 62.7%\nHiSS GPT-4 (Zhang & Gao, 2023) 56.1%\nWikiChat GPT-3.5 (Semnani et al., 2023) 54.0%\nOur Model (Knowledge Cutoff) No SearchSearch via\nCohere RAG ( \u2191)\u2206F1\nvicuna-13b-v1.5 58.4%\u00b16.4% 57.5% \u00b12.1% \u22120.9%\nmixtral-8x7b-instruct 52.9%\u00b17.6% 58.6% \u00b17.6% +5.7%\ngpt-3.5-turbo (2021/03) 59.3%\u00b15.8% 64.7% \u00b15.3% +5.4%\ngpt-4-0613 (2021/03) 47.8%\u00b19.2% 68.3% \u00b114.5% +20.5%\ngpt-4-0125 (2023/12) 58.9%\u00b17.7% 71.7%\u00b14.5%+12.8%\nclaude3-haiku (2023/08) 64.1%\u00b13.6% 71.3% \u00b16.6% +7.2%\nTable 2: F1 score of models with and without search. Search performs substantially better.\nPerformance of search We see in Table 2 that when web searches are enabled, gpt-3.5-turbo ,\ngpt-4-0613 ,gpt-4-0125 , andclaude3-haiku all surpass the performance of the Cohere\n3Given the additional costs related to the non-turbo gpt-4-0613 (knowledge-cutoff 2021/03), we further\nsub-sample the dataset to keep only 100 examples in the two experiments involving this model, as well as with\nHiSS GPT-4.\n6\nPublished as a conference paper at COLM 2024\nChat baseline on the LIAR-New dataset. They likewise surpass the performance of WikiChat\n(Semnani et al., 2023) and HiSS (Zhang & Gao, 2023), the latter of which becomes worse with\nGPT-4 instead of GPT-3.5 (see also Appendix A.2 showing it is inconsistent in returning parsable\noutput). Performance of mixtral also improves substantially with our method. claude3-haiku\nshows the best performance without search, and is on-par with GPT-4 with search. Additionally, in\nAppendix A.7, we check sensitivity to some slight prompt variations, and find that search consistently\nimproves performance.\nIn Table 3, we see that the DuckDuckGo search pipeline also substantially improves the model\u2019s\nperformance. On average it is slightly worse than Cohere, but the results are close, especially with\ngpt-4-0125 .\nModel Name (Knowledge Cutoff) No SearchSummarized\nDuckDuckGo Search ( \u2191)\u2206F1\nmixtral-8x7b-instruct 52.9%\u00b17.6% 56.9% \u00b13.1% +4.0%\ngpt-3.5-turbo (2021/03) 59.3%\u00b15.8% 60.3% \u00b19.9% +1.0%\ngpt-4-0125 (2023/12) 58.9%\u00b17.7% 70.3%\u00b18.5% +11.4%\nclaude3-haiku (2023/08) 64.1%\u00b13.6% 67.1% \u00b16.6% +3.0%\nTable 3: F1 score of models with and without DuckDuckGo search + GPT-3.5 summary. Search\nagain improves performance substantially.\nMain Agent Model Name Duck +PF (k=10) Duck \u2212PF (k=10) Duck \u2212PF (k=5) Duck \u2212PF (k=2)\ngpt-3.5-turbo (2021/03) 60.3% \u00b1 9.9% 60.3% \u00b1 4.9% 58.7% \u00b1 4.7% 56.5% \u00b1 4.0%\ngpt-4-0125 (2023/12) 70.3% \u00b1 8.5% 66.9% \u00b1 6.5% 64.7% \u00b1 4.3% 63.7% \u00b1 3.4%\nTable 4: F1 scores on LIAR-New (subsampled to one third to reduce cost) with PolitiFact allowed\n(+PF) or disallowed ( \u2212PF) as a source. We vary numbers of DuckDuckGo search results (k=10,5,2).\nThe pipeline still performs well without PolitiFact. More search results increase performance.\nSources LIAR-New is collected from PolitiFact, raising a natural question about how much role\nPolitiFact plays when doing web search. In real-world applications, we would both like the system\nto take advantage of PolitiFact when it is available, and still do well when it is not (e.g., for new\nmisinformation that PolitiFact has not yet fact-checked). In Appendix A.4.1 we find that PolitiFact is\nthe most frequently used source, searched nearly as much as the rest of the top 10 sources combined.\nTo simulate PolitiFact not being available, in Table 4, we test blocking this website and relying\non other sources. This is done with the DuckDuckGo pipeline, where we have more control than\nthe Cohere one. We find that blocking PolitiFact does not degrade performance of GPT-3.5, and\nwhile performance of GPT-4 does drop a bit, it remains significantly better than without search. We\nalso perform an ablation on the number of results we set the search to return, and find performance\ndecreases monotonically with fewer results. Putting these results together, along with the fact that\nPolitiFact is the ideal source to provide evidence for this dataset, these findings suggest that no single\nsource is necessary for accuracy, but it is important to have enough sources to reduce noise and\nimprove the chances of finding the necessary evidence.\nIn Appendix A.4.2, we study the bias of the sources and input statements. We find that the sources\nused are slightly but not substantively left leaning (-0.54 on a scale from -3 to 3, putting it between\n1=\u201ccenter-left\u201d and 0=\u201ccenter\u201d), while the input statements are right leaning to an almost exactly\nequal degree (0.53 on the same scale). Thus, our system does not exhibit substantial bias in terms of\nsources used. To assess the overall quality of the sources, we evaluate the websites accessed by the\nweb retrieval system using the comprehensive media source evaluation database (Lin et al., 2023),\nnoting that the average quality of the sources is in the range of 0.76-0.80 for all models, roughly on\npar with the New York Times (0.87). In the same Appendix, we examine the bias and overall domain\nquality versus performance of our search systems, but do not find conclusive results there.\nSummarizer In Table 5 we perform an ablation on the summarizing model, comparing\nour default summarizer with gpt-3.5-turbo (GPT-3.5) against gpt-4-0125 (GPT-4) and\n7\nPublished as a conference paper at COLM 2024\nmixtral-8x7b-instruct (Mixtral). We see that GPT-4 outperforms GPT-3.5 which outper-\nforms Mixtral, suggesting that the more powerful the model used in the summarizer, the better the\nresult. With GPT-4, DuckDuckGo with Politifact blocked performs on par with Cohere with no\nrestrictions. Potentially, stronger summarizers are better at reconciling conflicting evidence \u2013 this\nmight be an interesting topic for future research.\nNo Search Action Cohere Search Duck \u2212PF GPT-3.5 Duck \u2212PF GPT-4 Duck \u2212PF Mixtral\n59.9% \u00b1 2.6% 65.1% \u00b1 4.4% 63.5% \u00b1 1.5% 64.8% \u00b1 9.0% 62.8% \u00b1 3.1%\nTable 5: F1 score on LIAR-New with GPT-3.5 main agent, varying the summarization model after\nDuckDuckGo retrieval. More powerful summarization improves performance.\nWiki Full Chunk k=10 WikiLocal k=10 WikiLocal k=20 WikiChat GPT-3.5 (2023) GPT-3.5 Duck \u2212PF\n50.1% \u00b1 11.0% 49.9% \u00b1 8.5% 48.9% \u00b1 3.4% 54.0% 60.3% \u00b1 4.9%\nTable 6: F1 score of models using local embedding-based retrieval from Wikipedia vs. web search.\nWe see these approaches are substantially worse than web search ones, suggesting Wikipedia is not\nan appropriate knowledge base for these types of data.\nKnowledge base Table 6 provides additional analysis on Wikipedia as knowledge base vs. the\nopen web. Specifically, we compare the performance of using Wikipedia retrieval systems with our\noffline GPT-3.5 agent (specifically, full chunks retrieval with k=10 and chunked articles retrieval with\nk=10 and k=20), the WikiChat system from the literature (Semnani et al., 2023), and our GPT-3.5 +\nDuckDuckGo search system. The chunk split uses an embedding collection for Wikipedia published\non HuggingFace.4We see that all the Wikipedia-based systems \u2013 both in our setups and in a leading\none from the literature (WikiChat) \u2013 provide inferior performance compared to our open web search\nsystems. These results confirm the value of open web search and the limitations of a fixed knowledge\nbase in this domain.\nFigure 1: F1 improvement from Cohere RAG Search by category of missing information for each\nmodel, for statements labeled as hard and impossible to evaluate. The columns represent the category\nof missing information in each statement.\nTypes of missing evidence We expect web retrieval to improve the factuality evaluation perfor-\nmance on statements that are missing a key piece of context. We leverage results from Orlovskiy et al.\n4Cohere/wikipedia-2023-11-embed-multilingual-v3\n8\nPublished as a conference paper at COLM 2024\n(2024) that classified Hard and Impossible statements (missing context) in this dataset by categories\nof missing information. We use these category labels to evaluate if the type of missing information in\na statement affects web retrieval performance. Our approach evaluates performance for the following\ncategories of missing information: speaker, location, textual evidence, non-textual evidence (photo,\nvideo, audio), and date. We calculate the difference between the F1 scores with and without web\nsearch for identical models, and analyze the improvement in performance by category. For this\nanalysis where the data is split into bins, we determine the F1 scores based on the model\u2019s majority\nprediction across five runs for each statement, reducing variance.\nAcross the 4 generator models ( vicuna-13b-v1.5, mixtral-8x7b-instruct-v0.1,\ngpt-3.5-turbo, gpt-4-0125-turbo ) we see the highest average improvement for textual\nevidence, where retrieval is helpful across all models. We also note some improvement for missing\nnon-textual evidence. This suggests retrieval can add some indirect multimodal capabilities to text-\nonly systems, but it still performs better with text. There are also some improvements in the date\ncategory. Other categories are more mixed, with some substantial drops in performance. We also\nsee no difference in F1 on statements that are labeled as having sufficient context (p) in LIAR-New\n(Appendix A.3). This result suggests that web retrieval does not improve performance when a\nstatement already has the necessary context to be evaluated for factuality.\nWe see particularly sharp drops in performance for some models with speaker and especially location\ncategories. We hypothesize that this is due to finding the wrong information; for instance, the dataset\nis US-centric, and it has previously been observed that GPT-4 may assume US context when detecting\nmisinformation (Pelrine et al., 2023). Therefore, we suspect that the performance drops when models\nretrieve incorrect context and stop assuming a US one. Speaker and location information might\nalso simply be more difficult to retrieve without direct specification, because they create a variety\nof scenarios a statement may refer to. In Appendix A.3, we also further break these results down\nby comparing across Possibility categories and comparing Cohere vs. DuckDuckGo. Based on all\nthese analyses, if we can selectively invoke web retrieval in the categories it is most effective with,\nwe might both improve the overall performance and reduce computational costs. We plan to examine\nthese possibilities in future work.\nUncertainty quantification Given perfect performance remains unachievable, it is valuable to have\nan estimate of the uncertainty in a system\u2019s predictions (Pelrine et al., 2023). One would hope that\nenabling web-search would enhance the stability and certainty of those predictions. In Table 7, we\ncompare the system\u2019s calibration performance with and without web-search through our confidence\nelicitation methodology. As hypothesized, for both gpt-3.5-turbo and gpt-4-0125 models, enabling\nweb-search improves the system\u2019s uncertainty quantification performance. See Appendix A.5 for a\nvisualization of the effect of web-search on the uncertainty scores. We also attempted to perform\nuncertainty quantification on the search results themselves, to create an estimator for whether they\ngave high quality and comprehensive information, but only found negative results (Appendix A.6).\nModel Name (with or without search) ECE Score Brier Score\ngpt-3.5-turbo (no web-search) 0.1600 \u00b10.0057 0.1557 \u00b10.002\ngpt-3.5-turbo (web-search enabled) 0.1093 \u00b10.0135 0.1322 \u00b10.001\ngpt-4-0125 (no web-search) 0.09\u00b10.0057 0.1237 \u00b10.0001\ngpt-4-0125 (web-search enabled) 0.0646 \u00b10.0035 0.1113 \u00b10.0007\nTable 7: Effect of enabling web-search on uncertainty quantification of GPT models on LIAR-New,\nquantified by expected calibration error (ECE) and Brier score (in both cases, lower is better).\nLimitations of search by data and task As seen in Table 8, there is no performance gain from\nsearch on the FEVER-v2 dataset. We hypothesize that the limited performance gain is largely because\nthe facts in this dataset are much simpler and constrained in scope, comprising solely information\nfrom Wikipedia, rather than real-world misinformation narratives. Thus, LIAR-New requires looking\nup sources from a range of news websites. In comparison, FEVER-v2 is constructed entirely around\narticles on Wikipedia\u2014a single, well-known website that is very likely to be part of the training set of\nthe models we tested. We note that all the LLM-based approaches, search or not, greatly outperform\nrecent state-of-the-art approaches like (Zhang et al., 2024). We also find similar results on FEVER\n9\nPublished as a conference paper at COLM 2024\nBaseline Model Search\nCausal Walk (Zhang et al., 2024) 62.1\nCohere Chat with RAG (3.3) 72.0%\u00b12.0%\nOur Model (Knowledge Cutoff) No SearchSearch via\nCohere RAG ( \u2191)\u2206F1\ngpt-3.5-turbo (2021/03) 75.9%\u00b12.0% 71.0% \u00b11.2% \u22124.9%\ngpt-4-0125 (2023/12) 84.7% 84.6 \u22120.1%\nTable 8: F1 score of models with and without search on FEVER-v2.\n(v1), FaVIQ and X-FACT (Appendix A.9). Thus, our search system is still valuable in contexts like\nthese because it enables one to integrate the best performing model with verifiable evidence and\ncitations. At the same time, we also find substantial variation in the average number of searches\nperformed per example over the different datasets (Appendix A.8), with the system using less on\nother datasets than on LIAR-New, which might be a fruitful area for future research.\nLimitations of understanding by model Pairing the \u201cChat with RAG\u201d model from Cohere with\na more powerful main agent enabled us to exceed the performance of both Chat with RAG and the\nmain LLM agent itself. We hypothesize that compared to mixtral-instruct-8x7B-v0.1 or\nthe model behind Cohere\u2019s Chat with RAG (Command R, in our experiments), the OpenAI LLMs\nare capable of doing a better job at decomposing the statement and generating queries. By asking\nbetter questions, the models retrieved information that was more relevant, which led to a better\noverall performance. In future work, we plan to test the effect of decomposition and query generation\nversus final evaluation by taking the decomposition and search results of GPT-4 and making a final\nprediction with weaker models.\nWe observe that the capability of the generator model might create a bottleneck for the overall\nperformance of the pipeline. For instance, while both gpt-3.5-turbo andgpt-4-0613 had\nthe same knowledge cutoff, gpt-4-0613 demonstrated a significantly better performance gain. A\npreliminary review of the model generations suggested that queries from gpt-4-0613 were more\nconcise, allowing it to retrieve more relevant results from web searches. While additional analyses\nare required, we note that the quality of the generated search queries might be the reason why adding\nsearch to vicuna-13b-v1.5 did not improve overall performance by much.\nAdditionally, we note that the performance gain from search is more pronounced with\ngpt-4-turbo-0125 (+12.8% F1, 2023/12 cutoff) as the generator model than with\ngpt-3.5-turbo (+5.4% F1, 2021/03 cutoff). We find this result surprising, especially given\nthat when compared with gpt-3.5-turbo ,gpt-4-turbo-0125 has a more recent knowledge\ncutoff. Specifically, the LIAR-New dataset includes only statements from fact-checking articles from\nOctober 2021 and later, meaning the world knowledge of gpt-4-turbo-0125 (up to 2023/12)\nencompasses the dataset\u2019s entire time span, while that of gpt-3.5-turbo (up to 2021/03) includes\nnone of it. Our initial hypothesis was that this model would benefit less from web search, but that\nwas not the case. We suspect that this unexpected trend might be related to the relative differences\nbetween the logic capabilities of these two LLMs, as well as the limited capacity of the models\nto comprehensively memorize and retrieve facts from training. However, additional work will be\nrequired to fully understand this difference.\n5 Conclusion\nWe have described a framework for leveraging web retrieval to detect misinformation that substantially\nimproves performance. We have also confirmed its flexibility and customizability by showing that\nit works with multiple models and search tools. Finally, we have explored numerous parts of the\nprocess, including the sources and their biases, how different levels of search and summarizing affect\nthe results, the impact of open web vs. restricted knowledge base, when search is effective and when\nit is not, and more. Taken together, we hope this line of work will lead to a practical understanding of\nhow to build better, more evidence-based misinformation mitigation tools.\n10\nPublished as a conference paper at COLM 2024\n6 Acknowledgements\nThis work was partially funded by the CIFAR AI Chairs Program and the Centre for the Study of\nDemocratic Citizenship. We also thank Berkeley SPAR for connecting collaborators and funding\nsupport. Kellin Pelrine was supported by funding from IV ADO and by the Fonds de recherche du\nQueb \u00b4ec.\n7 Author Contributions\nJacob Tian proposed the initial two-agent architecture, built the core pipeline, and performed nu-\nmerous experiments and analyses. He also took a leading role in the team to execute the project,\nand wrote large portions of the paper. Hao Yu set up and tested DuckDuckGo, blocking PolitiFact,\ndifferent summarizers, and made a number of other substantial contributions to the experiments,\nwriting, and analysis. Yury Orlovskiy performed extensive analysis of the sources and the effects\nof different missing information, and led the writing of those sections. Tyler Vergho ran the HiSS\nand WikiChat baselines, and contributed to the writing. Mauricio Rivera developed the uncertainty\nquantification method for the overall results, and compared the performance with and without search.\nMayank Goel performed experiments on uncertainty quantification of search itself. Zachary Yang\ncontributed suggestions, feedback, and helped write the paper. Jean-Fran c \u00b8ois Godbout and Reihaneh\nRabbany advised the project, contributing wide-ranging ideas and feedback. Kellin Pelrine supervised\nthe project, providing guidance and feedback across all stages and all components of the project.\nReferences\nGiannis Bekoulis, Christina Papagiannopoulou, and Nikos Deligiannis. A review on fact extraction\nand verification. ACM Computing Surveys (CSUR) , 55(1):1\u201335, 2021.\nMichael Bendersky, Danqi Chen, Fernando Diaz, and Hamed Zamani. SIGIR 2023 Workshop\non Retrieval Enhanced Machine Learning (REML @ SIGIR 2023). In Proceedings of the 46th\nInternational ACM SIGIR Conference on Research and Development in Information Retrieval ,\nSIGIR \u201923, pp. 3468\u20133471, New York, NY , USA, July 2023. Association for Computing Machinery.\nISBN 9781450394086. doi: 10.1145/3539618.3591925. URL https://dl.acm.org/doi/\n10.1145/3539618.3591925 .\nCanyu Chen and Kai Shu. Combating misinformation in the age of llms: Opportunities and challenges.\narXiv preprint arXiv:2311.05656 , 2023.\nI Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham\nNeubig, Pengfei Liu, et al. Factool: Factuality detection in generative ai\u2013a tool augmented\nframework for multi-task and multi-domain scenarios. arXiv preprint arXiv:2307.13528 , 2023.\nTsun-Hin Cheung and Kin-Man Lam. Factllama: Optimizing instruction-following language models\nwith external knowledge for automated fact-checking. In 2023 Asia Pacific Signal and Information\nProcessing Association Annual Summit and Conference (APSIPA ASC) , pp. 846\u2013853. IEEE, 2023.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel\nMazar \u00b4e, Maria Lomeli, Lucas Hosseini, and Herv \u00b4e J\u00b4egou. The faiss library. 2024.\nNima Ebadi, Mohsen Jozani, Kim-Kwang Raymond Choo, and Paul Rad. A memory network\ninformation retrieval model for identification of news misinformation. IEEE Transactions on Big\nData , 8(5):1358\u20131370, 2021.\nYunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu\nGuo, Meng Wang, and Haofen Wang. Retrieval-Augmented Generation for Large Language\nModels: A Survey. Technical report, January 2024. URL http://arxiv.org/abs/2312.\n10997 . arXiv:2312.10997 [cs] type: article.\nAshim Gupta and Vivek Srikumar. X-FACT: A New Benchmark Dataset for Multilingual Fact\nChecking. In Proceedings of the 59th Annual Meeting of the Association for Computational\nLinguistics , Online, July 2021. Association for Computational Linguistics.\n11\nPublished as a conference paper at COLM 2024\nYi-Li Hsu, Shih-Chieh Dai, Aiping Xiong, and Lun-Wei Ku. Is explanation the cure? misinformation\nmitigation in the short term and long term. In Findings of the Association for Computational\nLinguistics: EMNLP 2023 , pp. 1313\u20131323, 2023.\nMedeswara Rao Kondamudi, Somya Ranjan Sahoo, Lokesh Chouhan, and Nandakishor Yadav.\nA comprehensive survey of fake news in social networks: Attributes, features, and detection\napproaches. Journal of King Saud University-Computer and Information Sciences , 35(6):101571,\n2023.\nHao Liao, Jiahao Peng, Zhanyi Huang, Wei Zhang, Guanghua Li, Kai Shu, and Xing Xie. Muser: A\nmulti-step evidence retrieval enhancement framework for fake news detection. In Proceedings of\nthe 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , pp. 4461\u20134472,\n2023.\nHause Lin, Jana Lasser, Stephan Lewandowsky, Rocky Cole, Andrew Gully, David G Rand, and\nGordon Pennycook. High level of correspondence across different news domain quality rating sets.\nPNAS nexus , 2(9):pgad286, 2023.\nStephanie Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in\nwords. arXiv preprint arXiv:2205.14334 , 2022.\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,\nLuke Zettlemoyer, and Hannaneh Hajishirzi. Factscore: Fine-grained atomic evaluation of factual\nprecision in long form text generation. arXiv preprint arXiv:2305.14251 , 2023.\nYury Orlovskiy, Camille Thibault, Anne Imouza, Jean-Fran c \u00b8ois Godbout, Reihaneh Rabbany,\nand Kellin Pelrine. Uncertainty resolution in misinformation detection. arXiv preprint\narXiv:2401.01197 , 2024.\nJungsoo Park, Sewon Min, Jaewoo Kang, Luke Zettlemoyer, and Hannaneh Hajishirzi. FaVIQ: Fact\nverification from information seeking questions. In ACL, 2022.\nKellin Pelrine, Meilina Reksoprodjo, Caleb Gupta, Joel Christoph, and Reihaneh Rabbany. To-\nwards reliable misinformation mitigation: Generalization, uncertainty, and gpt-4. arXiv preprint\narXiv:2305.14928 , 2023.\nMauricio Rivera, Jean-Fran c \u00b8ois Godbout, Reihaneh Rabbany, and Kellin Pelrine. Combining con-\nfidence elicitation and sample-based methods for uncertainty quantification in misinformation\nmitigation. In Proceedings of the 1st Workshop on Uncertainty-Aware NLP (UncertaiNLP 2024) ,\npp. 114\u2013126, 2024.\nJon Saad-Falcon, Omar Khattab, Christopher Potts, and Matei Zaharia. ARES: An Automated\nEvaluation Framework for Retrieval-Augmented Generation Systems. Technical report, November\n2023. URL http://arxiv.org/abs/2311.09476 . arXiv:2311.09476 [cs] type: article.\nSina Semnani, Violet Yao, Heidi Zhang, and Monica Lam. Wikichat: Stopping the hallucination of\nlarge language model chatbots by few-shot grounding on wikipedia. In Findings of the Association\nfor Computational Linguistics: EMNLP 2023 , pp. 2387\u20132413, 2023.\nMegha Sundriyal, Ganeshan Malhotra, Md Shad Akhtar, Shubhashis Sengupta, Andrew Fano, and\nTanmoy Chakraborty. Document retrieval and claim verification to mitigate covid-19 misinforma-\ntion. In Proceedings of the Workshop on Combating Online Hostile Posts in Regional Languages\nduring Emergency Situations , pp. 66\u201374, 2022.\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-\nscale dataset for fact extraction and VERification. In Marilyn Walker, Heng Ji, and Amanda Stent\n(eds.), Proceedings of the 2018 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) , pp.\n809\u2013819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi:\n10.18653/v1/N18-1074. URL https://aclanthology.org/N18-1074 .\n12\nPublished as a conference paper at COLM 2024\nJames Thorne, Andreas Vlachos, Oana Cocarascu, Christos Christodoulopoulos, and Arpit Mit-\ntal. The FEVER2.0 shared task. In James Thorne, Andreas Vlachos, Oana Cocarascu, Christos\nChristodoulopoulos, and Arpit Mittal (eds.), Proceedings of the Second Workshop on Fact Ex-\ntraction and VERification (FEVER) , pp. 1\u20136, Hong Kong, China, November 2019. Association\nfor Computational Linguistics. doi: 10.18653/v1/D19-6601. URL https://aclanthology.\norg/D19-6601 .\nPetter T \u00a8ornberg. Chatgpt-4 outperforms experts and crowd workers in annotating political twitter\nmessages with zero-shot learning. arXiv preprint arXiv:2304.06588 , 2023.\nHaoran Wang and Kai Shu. Explainable claim verification via knowledge-grounded reasoning with\nlarge language models. arXiv preprint arXiv:2310.05253 , 2023.\nLiang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei. Large\nSearch Model: Redefining Search Stack in the Era of LLMs. Technical report, January 2024. URL\nhttp://arxiv.org/abs/2310.14587 . arXiv:2310.14587 [cs] type: article.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\nZhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\nNeural Information Processing Systems , 35:24824\u201324837, 2022.\nKai-Cheng Yang and Filippo Menczer. Large language models can rate news outlet credibility. arXiv\npreprint arXiv:2304.00228 , 2023.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov,\nand Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question\nanswering. arXiv preprint arXiv:1809.09600 , 2018.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\nReact: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 ,\n2022.\nLong Ying, HUI Yu, Jinguang Wang, Yongze Ji, and Shengsheng Qian. Fake news detection via\nmulti-modal topic memory network. IEEE Access , 9:132818\u2013132829, 2021.\nHao Yu, Zachary Yang, Kellin Pelrine, Jean Francois Godbout, and Reihaneh Rabbany. Open, closed,\nor small language models for text classification? arXiv preprint arXiv:2308.10092 , 2023.\nCongzhi Zhang, Linhai Zhang, and Deyu Zhou. Causal walk: Debiasing multi-hop fact verification\nwith front-door adjustment. In Proceedings of the AAAI Conference on Artificial Intelligence ,\nvolume 38, pp. 19533\u201319541, 2024.\nXuan Zhang and Wei Gao. Towards llm-based fact verification on news claims with a hierarchical\nstep-by-step prompting method. In Proceedings of the 13th International Joint Conference on\nNatural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association\nfor Computational Linguistics (Volume 1: Long Papers) , pp. 996\u20131011, 2023.\nXinyi Zhou and Reza Zafarani. A survey of fake news: Fundamental theories, detection methods,\nand opportunities. ACM Computing Surveys (CSUR) , 53(5):1\u201340, 2020.\nA Appendix\nA.1 Label distribution\nThe label distribution is shown in Table 9.\n13\nPublished as a conference paper at COLM 2024\nMapped Label Original Label Count\nFalse (0) \u201cPants-Fire\u201d 103\nFalse (0) \u201cFalse\u201d 323\nFalse (0) \u201cBarely True\u201d 69\nTrue (1) \u201cHalf-True\u201d 49\nTrue (1) \u201cMostly-True\u201d 26\nTrue (1) \u201cTrue\u201d 18\nTable 9: LIAR-New Label Distribution.\nA.2 Parsability of returned outputs\nIn Table 10, we reprint the main results of Table 2, with the addition of percentage (%) parsed which\nreflects how many of the outputs contain the necessary information to parse them and compare with\nthe ground truth. Most models have a high parsability rate, which is slightly improved by adding the\nsearch option. Previous research (Pelrine et al., 2023) has observed LLMs like GPT-4 occasionally\nrefusing to answer when it is not confident, so we hypothesize that the evidence found with search\nmakes the models more confident about answering.\nSome versions of HiSS, notably the GPT-4 one, suffer from a lower parsability rate.\nBaseline Model (Knowledge Cutoff) Search %parsed\nCohere Chat with RAG (3.3) 63.9%\u00b13.5% 99.7%\nHiSS GPT-3.5 (Zhang & Gao, 2023) 60.6% 91.3%\nHiSS GPT-3.5 Binary (Zhang & Gao, 2023) 62.7% 99.2%\nHiSS GPT-4 (Zhang & Gao, 2023) 56.1% 91.0%\nWikiChat GPT-3.5 (Semnani et al., 2023) 54.0% 95.1%\nOur Model (Knowledge Cutoff) No Search %parsedSearch via\nCohere RAG ( \u2191)%parsed \u2206F1\nvicuna-13b-v1.5 58.4%\u00b16.4% 99.8% 57.5% \u00b12.1% 95.5%\u22120.9%\nmixtral-8x7b-instruct 52.9%\u00b17.6% 99.1% 58.6% \u00b17.6% 99.4%+5.7%\ngpt-3.5-turbo (2021/03) 59.3%\u00b15.8% 96.7% 64.7% \u00b15.3% 99.4%+5.4%\ngpt-4-0613 (2021/03) 47.8%\u00b19.2% 90.2% 68.3% \u00b114.5% 98.4%+20.5%\ngpt-4-0125 (2023/12) 58.9%\u00b17.7% 98.8% 71.7%\u00b14.5% 98.6%+12.8%\nTable 10: F1 score of models with and without search, including % parsed \u2013 i.e., how many of the\noutputs can be parsed for comparison with the ground truth.\nA.3 Additional F1 difference heatmaps\nIn the following figures, we show additional heatmaps illustrating differences in performance for the\nsearch-enabled system versus the offline model. We omit categories with less than 20 samples.\nFor example, in figures 2a and 2b, we present F1 differences in gpt-4-0125 with and without\nsearch. We also break the results down by Possibility label. While often similar, we find some\ndiscrepancies. For example, with Cohere versus DuckDuckGo search for gpt-4-0125 , there is\na substantial difference in the location and date categories, where DuckDuckGo performs poorly.\nWe suspect Cohere might also be US-centric, and DuckDuckGo less so, which would explain the\nlocation difference. We do not yet have a clear explanation for the difference in the date category.\nWe believe further analysis of this type could help optimize different search engine queries, or even\nchoose the optimal search engine for each type of query.\nA.4 Additional source and performance analysis\nA.4.1 Source frequency analysis\nWe analyze the most frequently accessed sources by the web retrieval agent when using the Cohere\nsearch system on the LIAR-New dataset. First, in Table 11, we look at the top 10 most used sources\n14\nPublished as a conference paper at COLM 2024\n(a) F1 improvement with Cohere.\n (b) F1 improvement with DuckDuckGo.\nFigure 2: Improvement with Cohere vs. DuckDuckGo: gpt-4-turbo-0125 . The rows corre-\nspond to Possibility label (i = Impossible, h = Hard, p = Possible).\n(a) F1 improvement with Cohere: gpt-3.5-turbo.\n(b) F1 improvement with DuckDuckGo: gpt-3.5-\nturbo.\nFigure 3: Improvement with Cohere vs. DuckDuckGo: gpt-3.5-turbo .\nby GPT-3.5 and GPT-4. We note the counts are lower for GPT-4 compared to GPT-3.5, as GPT-3.5\nwas run on the entire dataset, while GPT-4 was run on a random third of this content to reduce costs.\nWe see though that the sources used are very similar. PolitiFact dominates, followed by Wikipedia,\nand the rest of the top 10 comprise a mix of news and fact-checking websites. There are slight\ndifferences in the order, for instance, for GPT-3.5 CNN comes in at number 8, while for GPT-4 it\nis number 11 (not shown in table). But overall this confirms that the differences between the two\nsystems in terms of which sources they examine are very small.\nGPT-3.5 Count GPT-4 Count\npolitifact.com 10475 politifact.com 3690\nen.wikipedia.org 2924 en.wikipedia.org 648\nusatoday.com 1321 reuters.com 477\nreuters.com 1204 usatoday.com 340\nstatesman.com 1171 apnews.com 318\napnews.com 1116 statesman.com 280\nsnopes.com 806 nytimes.com 262\ncnn.com 741 snopes.com 199\nnytimes.com 718 checkyourfact.com 198\ncheckyourfact.com 607 washingtonpost.com 155\nTable 11: Top 10 sources used by GPT-3.5 and GPT-4 with Cohere Search.\n15\nPublished as a conference paper at COLM 2024\n(a) F1 improvement with Cohere: mixtral-8x7b-\ninstruct-v0.1-1.\n(b) F1 improvement with DuckDuckGo: mixtral-\n8x7b-instruct-v0.1-1.\nFigure 4: Improvement with Cohere vs. DuckDuckGo: mixtral-8x7b-instruct-v0.1-1 .\nFigure 5: F1 improvement: vicuna-13b-v1.5-1.\nA.4.2 Bias, credibility, and factuality analysis\nWe next go deeper on the quality and ideology of the sources used, as well as the input statements.\nFirst, we evaluate sources using Media Bias Fact Check (MBFC),5a non-partisan media assessment\norganization, which labels news websites according to their ideological biases. We used an API to\nretrieve the most current labels.6The bias ratings are as follows:\nBias:\n-3 indicates an extreme left-wing favoring\n-2 indicates a left favoring\n-1 indicates a center-left wing favoring\n0 indicates center favoring\n1 indicates a center-right wing favoring\n2 indicates a right favoring\n3 indicates an extreme right-wing favoring\nAnalyzing the results with GPT-3.5, we find that 78% of the sources used are present in the MBFC\ndatabase (55% if we exclude PolitiFact), meaning the database provides reasonable if not perfect\ncoverage. We also note that it covers all of the top 10 sources discussed above, except for Wikipedia.\nOn average, the leaning of the sources used is -0.54. This is between center and center-left. We note\nthat PolitiFact is rated at -1.\n5https://mediabiasfactcheck.com/\n6https://rapidapi.com/albertoescobar/api/political-bias-database/\n16\nPublished as a conference paper at COLM 2024\nWe pair this with an analysis of the leaning of the input statements, using evaluation by GPT-4. GPT-4\nhas been shown to effectively measure ideology (T \u00a8ornberg, 2023; Yu et al., 2023) and source overall\ndomain quality (Yang & Menczer, 2023), with high alignment to MBFC. We prompt it as follows:\nGiven the following statement, analyze and determine the\npolitical ideology the information would favor if true.\nNote that the information may be false; this should not\ninfluence your rating, we want to assess the political\nfavoring, not the veracity. Consider the use of language,\nthemes, and any eplicit or implicit political references\nor endorsements. Provide an estimate of the poltical\nfavoring on a scale of -3 to 3, where\n-3 indicates an extreme left-wing favoring,\n-2 indicates a left favoring,\n-1 indicates a center-left wing favoring,\n0 inciates center favoring,\n1 indicates a center-right wing favoring,\n2 indicates a right favoring,\n3 indicates an extreme right-wing favoring\nStatement: {statement}\nReply with just the score, do not include any additional\ninformation.\nThis produces an average rating (\u201cGPT Bias Score\u201d) of 0.53, which is almost exactly complimentary\nto the -0.54 of the sources used and might suggest some relationship. We also note the average\ndomain quality for the sources is in the 0.76-0.80 out of 1.00 for all models, indicating that the\nsources our agent accesses are mostly factual, and highly credible (For reference, New York Times\nhas a rating of 0.87) (Lin et al., 2023). When looking at the distribution of sources for each input\nleaning, however, we do not find a clear pattern (Figures 6 and 7).\nFigure 6: Distribution of source bias, divided by leaning of the input statements as assessed by GPT-4.\nWe next seek to understand the effects of bias, and overall domain quality of the sources used, and\nhow they relate to bias of the input statement. We again use the MBFC bias ratings for sources. For\n17\nPublished as a conference paper at COLM 2024\nFigure 7: Distribution of source bias, divided by leaning of the input statements as assessed by GPT-4,\nwith PolitiFact excluded.\noverall domain quality, we use an aggregate measure of domain quality (Lin et al., 2023) which uses\na wisdom of experts approach to evaluate sources, with MBFC being one of multiple sources for\ndomain quality ratings. We analyze cases where the web retrieval agent outperforms the offline model\n(i.e., the agent without web search capabilities) and cases where web retrieval yields less accurate\nresults compared to the offline model. In particular, we consider the offline model\u2019s evaluation to be\naccurate if the majority of its 5 evaluation trials on a given statement are accurate. Note that we use\nthe same standard for the online (search-enabled) model. We look at cases where the online model\nis accurate and the offline one is not (i.e., where search is improving performance) and vice versa\n(where search is worsening performance).\nFigures 8 and 9 show the normalized distributions of total average bias and domain quality respectively\nfor GPT-3.5. The green bars represent cases where web retrieval improves performance, while the\nred bars represent cases where web retrieval worsens performance compared to the offline model.\nThe results are divided by the leaning of the input, assessed by GPT-4 as described above. Similarly,\nFigures 10 and 11 show the same distributions for GPT-4.\nWe hoped this analysis might point to a way to improve performance or show other clear patterns, but\nunfortunately, these results are not conclusive.\nIn summary, these additional analyses reveal that the sources used are slightly left-leaning, while the\ninput statements\u2014if they were true\u2014are slightly right-leaning. Thus, our system does not appear\nto have a strong bias in this dimension. We believe these results are valuable for evaluating and\ncomparing different evidence retrieval systems. On the other hand, we did not find clear patterns in\nbias, credibility, or factuality of sources and inputs that might point to ways to improve performance.\nA.5 Reliability diagrams\nWe illustrate the effect of enabling web-search on the system\u2019s calibration performance through\nreliability diagrams. Comparing figures 12a and 12b, and 13a and 13b, we observe how enabling\nweb-search increases our system\u2019s uncertainty scores, in parallel with its improvement on calibration.\n18\nPublished as a conference paper at COLM 2024\nFigure 8: Normalized distribution of total average bias for GPT-3.5 with varying GPT bias scores.\nA.6 Confidence in search results vs accuracy\nWe also attempted to perform confidence measures on the search results themselves, and analyze the\ncorrelation between those scores versus correctness of the prediction. The hypothesis is that from\nsearch results that the model is more confident about, we will get a higher accuracy. Conversely, if\nthe model is less confident about a search query\u2019s results, it will have a lower chance of correctly\nevaluating the veracity of the statement for which the search was conducted. To test this, we use\nthe dataset of duckduckgo search result summaries (Duck \u2013PF GPT 4). We prompt the gpt-4-0125-\npreview model (with a default temperature of 1) to get confidence scores on a search summary given\nthe original statement and search query, to assess if the result of the search query made was accurate\nand comprehensive.\nWe attempted a few prompts. These were put as the system prompts, with the statement being the\nuser prompt.\nPrompt 1:\nOn a scale of 0-100, output your confidence that the information\nfound in the overall statement is accurate and comprehensive.\nOnly give the output.\n19\nPublished as a conference paper at COLM 2024\nFigure 9: Normalized distribution of average domain quality for GPT-3.5 with varying GPT bias\nscores.\nPrompt 2:\nOn a scale of 0-100, where 0 is highly uncertain and 100 is fully\ncertain, output your confidence that the information found in\nthe overall result to the search query is accurate and\ncomprehensive. Only give the output.\nBased on negative results from the above attempts, we tried another prompt with additional context,\nthis time mentioning both the original statement and search query along with the search summary,\nand emphasizing the role the model should play (reflecting the confidence that the search summary\nmatches the search query).\nPrompt 3:\nBased on the following information, output your confidence, on a\nscale of 0-100 where 0 is highly uncertain and 100 is fully\ncertain, that the result of the search query made was\naccurate and comprehensive with regard to the topic queried.\nDon\u2019t write an explanation, only give the number.\n20\nPublished as a conference paper at COLM 2024\nFigure 10: Normalized distribution of total average bias for GPT-4.0 with varying GPT bias scores.\nThe search query was made as one part of a process to evaluate the\nveracity of this statement: {statement}\n{query}\nThe analysis of the search results by the searching agent was: {\nresult_summary}\nNote that your score should reflect confidence in the accuracy and\ncomprehensiveness with regard to the topic of the search\nquery. In other words, the extent to which it found the\ninformation it sought. It should not reflect whether it\ncomprehensively answered everything about the statement,\nbecause there can be other search queries and other analysis\ntaking place too.\nWith all these prompts, the model outputs a confidence score between 0-100, which can be correlated\nto correctness of the prediction obtained in the final evaluation for each of those search results. The\nviolin plot for Prompt #3 (Figure 14) obtained shows no clear difference between confidence scores\non accurate and inaccurate predictions, and the data had a very low correlation score of -0.02. Thus,\n21\nPublished as a conference paper at COLM 2024\nFigure 11: Normalized distribution of average domain quality for GPT-4.0 with varying GPT bias\nscores.\nthese results did not provide effective quantification of the quality or comprehensiveness of search\nresults. We pose such uncertainty quantification as an open problem.\nA.7 Sensitivity to variations in prompt template\nLLMs can sometimes be sensitive to variations in prompt templates and formatting changes. To test\nwhether our pipeline is robust and whether the reported metrics provide solid conclusions irrespective\nof the exact prompt template, we repeated the experiments across five different paraphrased versions\nof the task instruction. In table 12, we report the performance of both Cohere Search and No Search\non a randomly selected 50-example subset of the full LIAR-New dataset. We find that while there\ncan indeed be some variation between different prompts, our search setup successfully improves\nperformance in every case.\nA.8 Search tool usage statistics\nIn our pipeline, we provide the LLM the option to invoke search as many times as needed (up to ten\ntimes per query). We also allow the LLM to not execute any query at all. In table 13, we report the\n22\nPublished as a conference paper at COLM 2024\n(a) Reliability diagram for gpt-3.5-turbo without\nsearch on LIAR-New.\n(b) Reliability diagram for gpt-3.5-turbo with search\non LIAR-New.\nFigure 12: Comparison of reliability diagrams for gpt-3.5-turbo with and without search on LIAR-\nNew.\n(a) Reliability diagram for gpt-4-0125 without search\non LIAR-New.\n(b) Reliability diagram for gpt-4-0125 with search on\nLIAR-New.\nFigure 13: Comparison of reliability diagrams for gpt-4-0125 with and without search on LIAR-New.\naverage number of search requests per query on LIAR-New, grouped by whether the model produced\nthe correct prediction. We see slightly more queries on examples that ended in incorrect predictions,\nwhich could suggest those examples are more complex or otherwise more difficult to retrieve the\nright information.\n23\nPublished as a conference paper at COLM 2024\nFigure 14: Violin plot of confidence scores over accuracy (Prompt #3).\nParaphrased Instruction No Search Cohere Search\nYour task is to analyze the factuality of the given\nstatement. Once you have detailed your analysis process,\nconclude with a summary. If you determine the statement\nis accurate, state \u201dTrue statement; Factuality: 1.\u201d If you\nfind the statement to be inaccurate, state \u201dFalse statement;\nFactuality: 0.\u201d Start your summary with the word\n\u201dSummary: \u201d.50.0%\u00b117.7% 63.3% \u00b125.3%\nYour job is to evaluate the accuracy of the provided\nstatement. \\n\\n Once you have detailed your analysis\nprocess, conclude with a summary. If you determine the\nstatement is accurate, state \u201d Summary: True statement;\nFactuality: 1 \u201d. If the statement is inaccurate , state\n\u201dSummary: False statement; Factuality: 0 \u201d.57.3%\u00b113.4% 69.6% \u00b128.5%\nYour job is to evaluate the accuracy of the provided\nstatement. \\n\\n Once you have detailed your analysis\nprocess, conclude with a summary. If you determine the\nstatement is accurate, state \u201dTrue statement; Factuality:\n1.\u201d If it is not accurate , state \u201dFalse statement; Factuality:\n0.\u201d Start your summary with the phrase \u201dSummary: \u201d.52.9%\u00b115.5% 68.1% \u00b115.2%\nYour job is to evaluate the accuracy of the provided\nstatement. \\n\\n Once you have detailed all the steps of\nyour analysis, conclude with a summary. If you determine\nthe statement is accurate, state \u201dTrue statement;\nFactuality: 1.\u201d If you find the statement to be inaccurate,\nstate \u201dFalse statement; Factuality: 0.\u201d Start your summary\nwith the word \u201dSummary: \u201d.62.8%\u00b18.8% 61.9% \u00b118.5%\nYour job is to evaluate the accuracy of the provided\nstatement. \\n\\n Once you have detailed all the steps of\nyour analysis, conclude with a summary. If you determine\nthe statement is accurate, state \u201dTrue statement;\nFactuality: 1.\u201d If you find the statement to be inaccurate,\nstate \u201dFalse statement; Factuality: 0.\u201d Start your summary\nwith the word \u201dSummary: \u201d.53.1%\u00b112.7% 59.1% \u00b115.4%\nTable 12: Instruction paraphrasing impact on performance.\nA.9 Results on datasets within training knowledge cutoff\nUnlike many other fact-checking datasets, LIAR-New is unique in that it contains exclusively\nfact-checks collected outside the training knowledge cutoff of GPT-3.5 and the older GPT-4 LLM\n(gpt-4-0613 ). Performance on such datasets provide hints at the effectiveness of our pipeline in\nverifying novel claims if a system like ours is deployed in the real world.\n24\nPublished as a conference paper at COLM 2024\nModelLiar-New\nIncorrect Correct\nvicuna 1.2 1.1\nmixtral 1.7 1.4\nhaiku 1.6 1.6\ngpt-3.5 1.4 1.2\ngpt-4 1.2 1.1\nTable 13: Average number of model requests to Cohere-RAG search per query for Liar-New.\nIn Table 14, we report results on the older datasets FaVIQ, X-FACT, FEVER-v1, and the validation\nset of FEVER-v2. In all these datasets, search appears to yield a performance improvement but\nonly a very marginal one. This is nonetheless a positive result because retrieving evidence without\ncompromising performance provides its own benefit, since it enables citing sources and providing\nusers followup materials. We hypothesize that the performance benefit is low because many questions\nin these datasets appear too easy to the model, either due to the knowledge cutoff and perhaps\nappearing in the training data, or just the overall perceived difficulty of the questions themselves.\nFor instance, we observed the model explicitly saying search was not necessary on some examples,\nand the rates of search are low compared to LIAR-New. Thus, the current system seems to yield a\nconsistent benefit, but the degree - and whether it is in performance or primarily adding evidence -\nvaries depending on the dataset. In future work we plan to investigate if pushing the system to search\nmore on these datasets would yield a larger increase in performance.\nDatasetNo Search Search via Cohere RAG\u2206F1F1 F1 Incorrect/Search Correct/Search\nfaviq 77.7%\u00b11.9% 78.0%\u00b12.6% 0.54 per example 0.61 per example +0.3%\nx-fact 56.8%\u00b11.9% 57.3%\u00b11.6% 0.43 per example 0.45 per example +0.5%\nfever 93.3%\u00b11.0% 93.7%\u00b11.4% 0.64 per example 0.38 per example +0.4%\nfever-v2-validation 84.6%\u00b10.0% 84.7%\u00b10.2% 0.90 per example 0.91 per example +0.1%\nTable 14: F1 score of gpt-4-0125 (2023/12) with and without search on FaVIQ and X-Fact.\nA.10 Example of multi-step claim decomposition\nAs seen in the prompt template, we did not explicitly prompt the main agent LLM to decompose the\ninput statement that needs to be verified. Nevertheless, when prompted to provide analysis steps and\nto make use of a search engine to look up relevant sources, we observed that in quite a few instances,\nthe LLM decomposed the input statement into a number of sub-claims. As seen in the following\nexample, the sub-queries are typically more self-contained and hence potentially easier to look up\nusing the search tool than the original statement. We hypothesize that this capability might explain at\nleast in part why main agents that are more powerful seem to yield greater performance gain from the\nuse of the search tool.\nA.11 LIAR-New F1 for each label class\nIn Table 15, we present a per-class view into how the addition of Cohere Search affects the F1 scores\non Liar-New, depending on whether the given statement is true or false. The information below is\nproduced using scikit-learn.7\n7https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification report.html\n25\nPublished as a conference paper at COLM 2024\n\u2022User: Your task is to analyze the factuality of the given statement. You have access to a\nsearch engine tool. To invoke search, begin your query with the phrase \u201dSEARCH: \u201d. You\nmay invoke the search tool as many times as needed.\nAfter providing all your analysis steps, summarize your analysis and state \u201dTrue statement;\nFactuality: 1\u201d if you think the statement is factual, or \u201dFalse statement; Factuality: 0\u201d\notherwise. You should begin your summary with the phrase \u201dSummary: \u201d.\nStatement: Comparing the price of oil and gas in June 2008 to March 2022 shows that oil\ncompanies are price gouging.\n\u2022Assistant: To analyze the factuality of the statement, I will first need to gather data on the\nprices of oil and gas in June 2008 and March 2022. Then, I will need to understand the\ndefinition of \u201dprice gouging\u201d to see if the pricing behavior by oil companies during these\nperiods qualifies.\nSEARCH: price of oil June 2008\n\u2022Cohere Search Connector: Search result: I found multiple prices for oil in June 2008. One\nsource stated that oil prices fell from a high of $133.88 per barrel in June 2008 to a low of\n$39.09 per barrel in February 2009.\nHowever, another source stated that on June 30th, 2008, the price of Brent Crude was\n$132.32 per barrel, but the price on June 27th was $140.21 per barrel, while the price was\n$122.8 dollars per barrel in May 2008. These figures represent the price of oil per barrel,\nand not the price per gallon. Unfortunately, I was unable to find information regarding the\nprice of oil in June 2008 in USD/gallon.\n\u2022Assistant: Given the search result, we have a general understanding of the price of oil in\nJune 2008, which fluctuated around $132 to $140 per barrel. For a comprehensive analysis,\nwe also need the prices in March 2022.\nSEARCH: price of oil March 2022\n\u2022Cohere Search Connector: Search result: Oil prices soared to heights not seen since\n2008 due to the Russia-Ukraine war, with ICE Brent oil futures sliding to around $100/bbl\nintraday.\nOther sources:\n- US Energy Information Administration, Short-Term Energy Outlook, March 2022: Brent\ncrude oil is expected to be $116 per barrel for the second quarter of 2022.\n- Daily Oil Price: March 31, 2022, Crude Oil: 100.28 (-7.54).\n\u2022Assistant: With the provided information, we can compare the price of oil in June 2008\nand March 2022. In June 2008, the price of oil per barrel was around $132 to $140, and in\nMarch 2022, it ranged from around $100 to $116 per barrel according to different sources.\nThe prices in both periods were high, partially due to geopolitical tensions (2008 and 2022\nrespectively).\nTo determine if this constitutes \u201dprice gouging,\u201d we need to understand the term. Price goug-\ning typically refers to when a seller increases the prices of goods, services, or commodities\nto a level much higher than is considered reasonable or fair, often during a demand surge or\nsupply constraint. It\u2019s crucial to note that the concept of price gouging is often related to\nlegal and ethical considerations, which may vary by jurisdiction.\nGiven the information, the statement connects high oil prices directly to \u201dprice gouging\u201d by\noil companies. However, determining price gouging involves an analysis of various factors,\nincluding production costs, market demand, and geopolitical contexts, among others. The\nhigh prices in both 2008 and 2022 are attributed to significant geopolitical events that likely\naffected global supply and demand, rather than direct evidence of oil companies engaging in\nprice gouging.\nSummary: The statement simplistically attributes the high prices in June 2008 and March\n2022 directly to price gouging by oil companies without considering the complexities\nsurrounding global oil prices, including major geopolitical events and supply-demand\ndynamics. While the prices were indeed high in both periods, attributing these solely to\nprice gouging without further evidence oversimplifies the issue. False statement; Factuality:\n0.\n26\nPublished as a conference paper at COLM 2024\nMain Model (Knowledge cutoff)No Search Cohere Search\nFalse True False True\nvicuna-13b-v1.5 87.86 32.40 88.80 (+0.94) 34.48 (+2.08)\nmixtral-8x7b-instruct-v0.1 91.11 11.21 91.18 (+0.07) 14.55 (+3.34)\ncommand search connector 90.14 38.27 91.92 (+1.78) 53.18 (+14.91)\ncommand no connector 81.33 39.13 85.63 (+4.30) 30.69 (-8.44)\ngpt-3.5-turbo (2021/03) 91.55 27.64 92.13 (+0.58) 44.90 (+17.26)\ngpt-4-0613 (2021/03) 93.05 0.00 93.10 (+0.05) 53.85 (+53.85)\ngpt-4-0125-preview (2023/12) 91.60 23.93 92.76 (+1.16) 51.95 (+28.02)\nclaude-3-haiku (2023/08) 90.10 38.79 91.54 (+1.44) 50.29 (+11.50)\nTable 15: Per-class F1 scores (scaled by 100) for different models with and without search, with\ndifferences relative to \u201dNo Search\u201d. gpt-4-0613 (2021/03) is evaluated on a subsampled set of 100\nexamples (89 False, 11 True). All other models are evaluated on a randomly selected subset of 588\nexamples (495 False, 93 True, 30% of liar-new), which encompasses the 100 examples mentioned\nabove.\n27", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Web retrieval agents for evidence-based misinformation detection", "author": ["JJ Tian", "H Yu", "Y Orlovskiy", "T Vergho", "M Rivera"], "pub_year": "2024", "venue": "arXiv preprint arXiv \u2026", "abstract": "This paper develops an agent-based automated fact-checking approach for detecting  misinformation. We demonstrate that combining a powerful LLM agent, which does not have"}, "filled": false, "gsrank": 318, "pub_url": "https://arxiv.org/abs/2409.00009", "author_id": ["Bkl3SakAAAAJ", "5Z10ts4AAAAJ", "Z_ca7-0AAAAJ", "", "IICNLB0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:vfNN31qwfsgJ:scholar.google.com/&output=cite&scirp=317&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=vfNN31qwfsgJ&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 8, "citedby_url": "/scholar?cites=14447178558991102909&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:vfNN31qwfsgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2409.00009?"}}, {"title": "Deploying artificial intelligence to combat disinformation warfare", "year": "2019", "pdf_data": " Deploying Artific ial Intelligence to Combat Disinformation Warfare  \nIdentifying and Interdicting Disinformation Attacks Against Cloud -based Social Media Platforms  \nBarry Cartwright  \nSchool of Criminology  \nSimon Fraser University  \nBurnaby, Canada  \nEmail: bcartwri@sfu.ca  George R. S. Weir  \nDepartment of Computer & Information Sciences  \nUniversity of Strathclyde  \nGlasgow, Scotland, UK  \nEmail: george.weir@strath.ac.uk\nRichard Frank  \nKarmvir Padda  \nSchool of Criminology  \nSimon Fraser University  \nBurnaby, Canada  \nEmail: {rfrank; karmvir_padda} @sfu.ca  \n \n \nAbstract \u2014Disinformation  attacks that make use of Cloud -\nbased social media platforms, and in particular , the attacks \norchestrated by the Russian \u201cInternet Research Agency ,\u201d \nbefore, during and after  the 2016 U .S. Presidential election \ncampaign and the 2016 Brexit referendum in the U .K., have \nled to increasing demand s from governmental agencies for \ntechnological tools that are capable of identify ing such attacks  \nin the ir earliest stages, rather than identifying and responding \nto them in retrospect . This paper reports on the interim results \nof an ongoing  research project that was sponsored by the \nCanadian government\u2019s Cyber Security Directorate . The \nresearch is being conducted by the International CyberCrime \nResearch Centre (ICCRC) at Simon Fraser University \n(Canada) , in cooperation with the Department of Information \nand Computer Sciences at the Un iversity of Strathclyde  \n(Scotland) . Our ultimate objective is the development of a  \n\u201ccritical content toolkit,\u201d which will mobilize artificial \nintelligence to identif y hostile disinformation activities in \n\u201cnear -real-time.\u201d Employing the ICCRC\u2019s Dark Crawler , \nStrathclyde\u2019s Posit Toolkit, Google Brain\u2019s TensorFlow, plus \nSentiStrength  and a short -text classification program known as \nLibShor tText, we have analy zed a wide sample of social media \nposts  that exemplify  the \u201cfake news\u201d that was disseminated by \nRussia\u2019s Internet Research Agency, comparing them to \u201creal \nnews\u201d posts in order to develop an automated means of \nclassification. To date, we have been able to classify posts as \n\u201creal news\u201d or \u201cfake news\u201d with an accuracy rate of 90.7%, \n90.12%, 89.5%, and 74.26% using LibShortText, Posit , \nTensorFlow and SentiStrength respectively.   \nKeywords -Social media ; disinformation  warfare; machine \nlearning . \nI.  INTRODUCTION  \nThis paper elaborates on an earlier paper on the subject \nof fighting disinformation warfare through the use of \nartificial intelligence, presented at the Tenth International \nConference on Cloud Computing, GRIDs, and Virtualization, held in Venice, Italy , in May 2019  [1]. As \nobserved in our earlier conference paper, the key challenges \nfacing law enforcement agencies, intelligence agencies , \ncybersecurity personnel and business owners -operators \nworldwide are how to monitor and effectively respond to \ndynamic and  emerging cybersecurity threats, with increasing \nattention being paid to hostile disinformation activities in \nCloud -based social media platforms  [1]. To illustrate, \nCambridge Analytica, through an app that it developed, \nmanaged to scrape data from over 80 million Facebook \npages worldwide. This information was in turn used to \nmicro -target voters through Facebook advertisements, which \nwere premised upon the demographic profiles and known \npolitical leanings of those voters , in turn based upon \ninformation which  had been extracted with the help of the \nCambridge Analytica app [2], [3]. In July 2018, Facebook \nwas fined \u00a3500,000 \u2014the maximum allowable under British \nlaw\u2014for its mishandling of data in the Cambridge Analytica \nscandal [4]. In July 2019, the US Federal Tr ade Commission \nfined Facebook five billion USD for its failure to protect user \nprivacy [5]. The nexus between Cambridge Analytica, \nWikiLeaks, and Russia n interference in the 2016 U.S. \nPresidential election remained under investigation by the \nU.S. Congress as recently as the Summer of 2019 [ 6].  \nAccording to a 2017 Intelligence Community \nAssessment , prepared jointly by the Central Intelligence \nAgency  (CIA) , the Federal Bureau of Investigation (FBI) and \nthe National Security Agency  (NSA) , a number of other \nCloud -based social media, including Twitter and Instagram, \nhave also been implicated as (possibly unaware)  participants \nin the hosting and dissemination of disinformation attacks  \nassociated with the Russian \u201cInternet Research Agency\u201d \n(IRA) [7]. According to Special Counsel Robert Mueller\u2019s \nrecently released report into Russian interference in the U.S. \nPresidential election [8], Facebook and Twitter accounts \ntargeted certain groups, such as Blacks (through the \nBlacktivist Facebook page), Southern Whites (through the \n203International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n Patriototus Facebook page), and the right -wing anti -\nimmigration movement (through the Secured Borders \nFacebook page), as well as through Twitter fe eds such as \n@TEN_GOP (which falsely claimed to have a connection to \nthe Republican Party of Tennessee), and @America_ 1st (an \nanti-immigration account). In the U.K., the \u201cfake news\u201d \u2014\nwhich primarily stoked Islamaphobic and anti -immigration \npassions \u2014made exte nsive use of Twitter, employing Twitter \nhandles such as ReasonsToLeaveEU, or #voteleave [ 9], [10], \n[11], [12] . Evidence also indicates that the Russian  IRA \nmaximized use of social media bots in their 2016 assaults on \nthe U.S. Presidential election and the U.K. Brexit referendum  \n[9], [10], [13], [14], thus amplifying  the content in order to \nreach and influence a much wider audience. More will be \nsaid about Russian involvement in disinformation warfare in \nSection II of this paper, wherein we present our l iterature \nreview.  \nOur research, sponsored by the Canadian government\u2019s \nCyber Security Cooperation Program, and conducted by the \nInternational CyberCrime Research Centre at Simon Fraser \nUniversity , in cooperation with the Department of \nInformation and Comp uter Sciences at the University of \nStrathclyde, involves the development of a tool for \nidentifying hostile disinformation activities in the Cloud.  \nThis research project commenced with a dataset of 2,946,219 \n\u201cfake news\u201d Twitter messages (tweets), identified  as \nemanating from the Russian IRA. Later, our research came \nto include datasets that combined both Twitter and Facebook \n\u201cfake news\u201d messages, eventually includ ing a number of \ncomparator datasets of \u201creal news\u201d messages, plus a \npotential \u201ctraining\u201d dataset  for machine learning  that we \nhave not yet explored fully , the latter consisting of a wide \nrange of \u201creal news\u201d and \u201cfake news\u201d [15]. It is anticipated \nthat t he knowledge generated by this research will establish \nthe foundation for more advanced work, even tually \nculminating in the construction of a \u201ccritical content toolkit,\u201d \nwhich  will aid governmental agencies in the rapid and \naccurate pinpoint ing of disinformation attacks in their very \nearly stages.   \nThe research team has several years of collaborative \nexperience in collecting and analyzing data from online \nextremist forums, child pornography websites, social media \nfeeds and the Dark Web.  Our previous experience in data \nclassification has demonstrated tha t we are able, through \nautomation, to achieve predictive accuracy in the 90 -95% \nrange when it comes to detecting the nuanced text found in \nextremist content on the Web  [1], [16], [17], [18]. From this \nbackground, we have a methodology that is applicable to  the \nanalysis and classification of data from Cloud -based social \nmedia platforms.  In the past, our predictive accuracy was \naccomplished by applying a combination of technologies, \nincluding the Dark Crawler, SentiStrength , and Posit  [1]. For \nthe present stu dy, we have employed the Dark Crawler, \nPosit , SentiStrength, TensorFlow, and LibShortText. \nAdditional information on these research tools is provided in \nSection III, where in we set out our methodology.  Our \nresearch results  are reported in Section IV, and e lucidated \nfurther in Sections V and V I, wherein we discuss our results, set out the directions that our future research endeavors are \nexpected to take, and present our interim  conclusions.  \nII. LITERATURE REVIEW  \nAs noted in our introductory comments in Section I,  \nCloud -based social media platforms have come under \nincreasing scrutiny for permitting hostile foreign actors to \nmanipulate public opinion through the creation of fake social \nmedia accounts  that disseminat e false information, often \nreferred to as  \u201cfake news\u201d [19], [20], [21]. This false \ninformation, or fake news, can be broken down into two \nbroader categories : misinformation and disinformation. The \nless sinister of the two, m isinformation , is simply in accurate \nor false information . Misinformation may be based upon a \ngenuine misapprehension of the facts, as opposed to having \nbeen created with any particular intention of deceiving or \nmanipulating people  [22], [23], [24] . Disinformation, on the \nother hand, especially when employed by hostile foreign \nactors, is information that is created and spread intentionally, \nfor the express purpose of deception and manipulati on of \npublic opinion  [22], [24], [25] .  \nThe activities of Russia\u2019s IRA during the 2016 U.S. \nPresidential election would be a prime example of  a \ndisinformation campaign mounted by a hostile foreign actor \n[10], [13], [26], [27]. In February 2108, U.S. Special Counsel \nRobert Mueller, duly appointed to investigate Russian \ninterference in the U.S. election, obtained a grand jury \nindictment against t he IRA ( which was bankrolled by \nYevgeniy Prigozhin, often referred to as \u201cPutin\u2019s chef\u201d), plus \nPrigozhin\u2019s American -based companies Concord \nManagement and Consulting LLC and Concord Catering  as \nwell as Prigozhin himself, along with a dozen Russian \n\u201ctrolls\u201d  who were employed by Prigozhin\u2019s IRA. The \nindictment stated that the accused had \u201c operated social media \npages and groups designed to attract U.S. audiences \u201d in order \nto advance divisive issues and create dissension, falsely \nclaiming that those pages and groups were controlled by \nAmerican activists  [9], [28].  \nThe dozen Internet \u201ctrolls\u201d who were described in the \nindictment obtained by Mueller belonged to an id entifiable \nsub-group  of a much larger workforce , comprised of 1,000 or \nmore Russian trolls, all employed by Prigozhin\u2019s IRA  [29], \n[30], [31] . These IRA employees, working in a building in \nthe Russian city of St. Petersburg, toiled around the clock in \ntwo, 12-hour shifts  (a day shift and a night shift) , with the \nobjective of fomenting division, distrust, dissent, and \nhostility within and between targeted groups in the American \npopulace  [32], [33], [34] . In particular, it has been said that \nthese IRA trolls w ere instructed to spread disinformation that \nwould  buttress Donald Trump\u2019s campaign for the U.S. \nPresidency, and at the same time , undermine the campaign of \nHillary Clinton [7], [ 30], [34], [35] .  \nThe Computational Propaganda Project, a multi -national \nproject housed primarily in the Oxford Internet Institute , has \nreported that 19 million identifiable \u201cbot\u201d accounts tweeted \nin support of Trump or Clinton in the week leading up to the \n2016 Presidential election, with 55.1% of those in favour of \nTrump, and only 19.1% in favour of Clinton [3 6], [37], [38] . \nThe evident disparity in Twitter support would seem  difficult \n204International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n to account for , other than in terms of highly -orchestrated and \ndeliberate political interference, given that Hillary Clinton \nreceived 65,844,954  votes, compared to 62,979,879 votes for \nDonald Trump [3 9].  \nA 2017 study by Zannettou et al. revealed that 71% of \nthese \u201cfake\u201d accounts were created prior to the 2016  election \n[34]. In fact, the 2017 Intelligence Community Assessment, \nprepared jointly by the CIA, FBI and NSA , indicated that \nRussian operatives had begun researching U.S. electoral \nprocesses and election -related technology and equipment as \nearly as 2014, two years prior  to the election, and that the  \nPrigozhin -led IRA had started advocating on  behalf of \nDonald Trump\u2019s candidacy as early as 2015, one year prior \nto the election [7]. Zannettou et al. reported that 24 accounts \nwere created on July 12, 2016, approximately one week \nbefore the Republican National Conference (at which Donald \nTrump was formally nominated as the Republican candidate \nfor the 2016 Presidential election) [34]. The study also found \nthat the Russian Internet trolls attempted to mask their \ndisinformation campaign by adopting different identities, \nchanging their screen names and  profile information, and in \nsome cases, deleting their previous tweets. In their \nexamination of tweets posted between January 2016 and \nSeptember 2017, for example, Zannettou et al. found that \n19% of the accounts operated by IRA trolls changed their \nscreen names as many as 11 times,  and unlike other Twitter \nusers, often deleted their tweets in large batches, in order to \nstart again with a clean slate [34].  \nMuch has be en said about the use of social media bots in \nthe U.S. Presidential election and the U.K. Brexit referendum \n[9], [10], [13], [14]. Briefly, t he transfer and transformation \nof information on the Internet is not accomplished by people, \nbut rather, by algorit hms\u2014scripts which convert \nmathematical expressions into instructions for the Internet \n[37]. The Internet Relay Chat System would be an early \nexample of where bots were  being used to manage and \nregulate social interaction on the Internet. These  bots, which \nstill comprise an integral part of the architecture of Cloud -\nbased social media sites such as Twitter and Facebook, are \ncapable of interacting with Internet users, answering simple \nquestions, and collecting data. More sophisticated bots can \nalso be deploye d to crawl the Web, scrape social media sites \nfor data, parse the information gleaned, and even manipulate \npolitical opinion  [37]. Some online stores/companies, such as \nAliExpress, use these AI bots for managing the extensive \nhelp systems on their site. If  you have an issue, you chat with \nthe bot. The Cambridge Analytica app, which attracted so \nmuch negative attention to Facebook in the aftermath of the \n2016 U.S. Presidential election and the 2016 U.K. Brexit \nreferendum, would be an example of an algorithm that was \ndesigned for the express purpose of collecting and evaluating \nbehavioral data such as the likes, dislikes and political \nproclivities of the Facebook users  whose data it harvested  \n[40]. \nTo express it differently, the bots (robots) described \nherein are Cloud -based social media accounts that are \ncontrolled by software, rather than by real people.  These \nsocial media bots are estimated to comprise between 5 -9% of \nthe overall Twitter population, and to account for approximately 24% of all tweets  [41]. Users of social media \nmay spend considerable time liking and disliking bots, \nsometimes arguing with (or even flirting with) bots, all the \nwhile thinking that they are interacting with a real person. \nStories that \u201cgo viral\u201d \u2014i.e., that rise to the top of Twitt er \nfeeds \u2014are often pushed there by these social media bots \nthrough manipulation of the social media platform\u2019s \nalgorithms [41].  \nThe main problem with \u201cfake news\u201d is that its consumers \ntend to accept what they read at face value. According to The \nPew Research Center , 12% of Americans get their news \nfrom Twitter  [42]. Of those who use the platform regularly, \nclose to 60% depend on Twitter as their source of news [26], \n[42], [43]. With respect to the type of \u201cfake news\u201d that is the \nsubject of this present study,  it can be said that the frequent \ntweeting and re -tweeting by bots leads to ever-increas ing \nexposure, resulting in an \u201cecho chamber effect\u201d [33]. To add \nto the mix , eviden ce suggests that many individuals are \nunable to distinguish between factual and non -factual content \nfound on Twitter  and Facebook [44], [45] . Indeed, according \nto a Stanford University study, far too many are inclined to \naccept images or statements that th ey come across on social \nmedia at face value, without questioning the source of those \nimages or statements, or for that matter, asking whether they \neven represent what they purport to represent  [9], [44], [45].  \nRussian interference in the U.S. Presidential  election and \nthe U.K Brexit referendum has been well documented, and \nhas been the subject of considerable governmental and \nacademic research, e.g., [7], [8], [9], [10], [12], [13], [14], \n[20], [27], [34].  However, such Russian interference is by no \nmeans restricted to the U.S. and the U.K. To illustrate, in \n2019, the European Commission \u2014along with the European \nExternal Action Service and other EU institutions and \nmember states \u2014released a progress report on its Action Plan \nAgainst Disinformation. According to the Commission\u2019s \nprogress report, evidence gathered throughout 2018 and \nearly 2019 confirmed ongoing disinformation activities \noriginating from Russian sources, believed to b e undertaken \nfor the purpose of influencing voter preferences and \nsuppressing voter turnout in the EU Parliamentary elections \n[23], [46] .  \nMoreover, a recent study of Canadian Twitter data \nsuggests that Russian trolls were behind \u201cfake news\u201d stories \nthat a ttempted to stoke fear and distrust  between Muslims \nand non -Muslims following the 2017 shooting deaths of six \nworshippers at a mosque in Quebec City , leading to renewed \nconcerns that Russian trolls might attempt  to interfere in the \nFall 2019 Canadian feder al election  [47]. With this in mind, \nthe research team recently collected a sample of 3,500 tweets \nfrom hashtags such as #TrudeauMustGoToJail , \n#TrudeauMustGo, and #TrudeauMustResign, some  of which \nwere suspected of contain ing \u201cfake news\u201d which was \nintended  to influence the outcome of the 2019  Canadian \nfederal election . In addition, we are currently focusing our \nefforts on collecting Canadian -specific \u201cfake news\u201d \nFacebook items, from The Buffalo Chronicle -Canadian \nEdition , Canadian Truth Seekers, Million Can adian March, \nThe Canadian Defence League, The Silent Majority Canada, \nThe Angry Cousin, Proud Canadians, and Canada Proud. \n205International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n This Facebook dataset presently consists of 3,737 discrete \ndata items.   \nRussian -orchestrated disinformation campaigns  are long -\nstanding in nature . The Kremlin reportedly founded a school \nfor bloggers as far back as 2009 , apparently foreseeing the \nlong-range possibilities of utilizing Cloud -based social media \nin political influence campaigns  [48]. In fact, Russian \ndisinfo rmation activities have been documented in the Czech \nRepublic and Slovakia as far back as 2013 [49], and in the \n2014 election in the Ukraine, which itself followed shortly \nafter Russia\u2019s annexation of the Crimea n Peninsula  [50], \n[51]. This is not to sugges t that all known disinformation \ncampaigns have been launched by Russia, or that such \ncampaigns have been restricted only to th ose countries \nmentioned above. Using a combination of qualitative content \nanalysis, secondary literature reviews, country case stu dies \nand consultations with experts, a  2019 inventory compiled \nby the Oxford Internet Institute found evidence of \ndisinformation  campaigns in 70 different countries around \nthe world , including but by no means limited to Armenia, \nIndia, Malaysia, Mexico, Th e Philippines, Saudi Arabia, The \nUnited Arab Emirates and Venezuela  [52]. In many cases, \nhowever, the campaigns are spreading pro -party or pro -\ngovernment propaganda, or attacking the political \nopposition, and in the absence of evidence to the contrary, \nthey could well be mounted by local (rather than foreign) \nactors. That said, countries other than Russia, such as China \nand Saudi Arabia, are believed to be making increasing use \nof disinformation campaigns beyond their own borders [53].  \nIn any event, t he foc us of this present paper is the Russian -\norchestrated attacks on the 2016 U.S. Presidential election.   \nA number of researchers have mobilized artificial \nintelligence in an effort to counter the type of disinformation \nwarfare employed by Russia during the 2016 U .S. \nPresidential election and the 2016 U .K. Brexit referendum. \nIn 2017, Darren Linvill and John Walker (from Clemson \nUniversity) gathered and saved vast numbers of Twitter and \nFacebook postings  (prior to their removal from the Internet \nby the respective social media platforms ), thereby preserving \nthe evidence and making the data available to the academic, \ncyber -security and law enforcement communities for further \nstudy [ 54]. Linvill and Walker investigated the Twitter \nhandles used by the Russian IRA, both qualitatively and \nquantitatively, breaking them down into troll accounts and \nbot accounts, and into right trolls, left trolls, fear mongers, \nnews feeders and hash tag gamers. Our research team has \nmade extensive use of the IRA\u2019s Twitter and  Facebook \npostings that were gathered, saved and made available by \nLinvill and Walker. In 2017, William Yang Wan g from the \nUniversity of California at Santa Barbara released his LIAR \ndataset , which included 12,836 statements labeled for their \nsubject matte r, situational context, and truthfulness, broken \ndown into training, validation and test sets, along with  \ninstructions for automatic fake news detection [15]. In \naddition , William Wang reported that the open source \nsoftware toolkit, LibShortText, developed  by the Machine \nLearning Group at National Taiwan University, had been \nshown to perform well when it came to short text \nclassification [15], [5 5]. The dataset  provided by Linvill and Walker , and the suggestion by William Wang about using \nLibShortText,  have both been used by us to inform and \nrefine the machine learning and automated analysis \nprocesses  described in the following sections on \nMethodology  and Re search Results .  \nIn his above -mentioned study using  the LIAR dataset, \nWilliam Wang found that when it came to automatic \nlanguage detection, a hybrid, convoluted deep neural \nnetwork that integrated both meta -data and text , produced \nsuperior results to text -only approaches  [15]. We are \nemploying a somewhat similar appr oach to that of William \nWang, in that we are using a combination of deep neural \nnetworks (Tensor Flow)  [56], a text -reading program (Posit) \nthat also produces meta -data or mark -up [57], [58] , and the \nLibShortText  program developed by the Machine Learning \nGroup at National Taiwan University [55] . Employing \ntechniques of machine learning and natural language \nprocessing, a 2018 study of Twitter troll activity in the 2016 \nU.S. Presidential election found that a model blending \nmeasurements of \u201cprecision\u201d and \u201cre call\u201d failed to accurately \nclassify 34% of troll posts , suggesting that such models \ncould not be relied upon to identify and screen out fake news  \n[48]. However, a  2019  paper, entitled \u201cDefending Against \nNeural Fake News,\u201d reports on the development of \nGROV ER, a computer model that can both generate and \ndetect neural fake news, premised on the notion that while \nmost fake news is presently generated by humans, the fake \nnews of the future may be generated by machines. The \nauthors of this paper report additiona lly that they have been \nable to discriminate fake news with an accuracy of 92%, as \nopposed to the more standard 73% accuracy exhibited by \nother fake news discriminators  [59]. Our research results, \nreported below,  come much closer to approximating those \ndescribed in  this 2019 study.   \nSome  researchers have sought to identify disinformation \ncampaigns by employing \u201cbot\u201d detection , instead of  relying \nupon automated text -reading software . Essentially, much of \nwhat may be regarded as \u201cfake news\u201d is thought to be spread \nand/or amplified by the use of bots [37], [40], [41]. Thus, the \ngoal of bot detection is to discriminate accurately between \nbot-generated and human -generated activity on socia l media. \nMorstatter, Carley and Liu, for example, have proposed what \nthey call \u201ca new approach to bot detection,\u201d again blending \nmeasurements of \u201cprecision\u201d and \u201c recall\u201d  [41], similar to the \nmeasurements employed in the above -mentioned 2018 study \nof Twitte r troll activity in the 2016 U.S. Presidential election. \nIn their 2019 study, Morstatter et. al found that they could \nsuccessfully classify  bot activity in 76.55% of instances . \nAnother approach , outlined by Gorodnichenko, Pahm and \nTalavera, identifies susp ected bot activity in the Brexit \nreferendum and the U.S. Presidential election, by measuring \nsuch variables as when the Twitter account was first created, \nthe number of tweets per day, the tim ing of daily and hourly \ntweeting, and the number of tweets conta ining the same \ncontent . This is p remised on the understanding that many of \nthese bot accounts are created for the purpose of spreading \ndisinformation, and that bots send more messages  than \nhumans , at all times of the day (even when human activity is \nmuch r educed), and that they re -send the same messages \n206International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n over and over again [60]. Using this approach, \nGorodnichenko et. al found that they could classify bots and \nnon-bots with 90% accuracy. While we have not employed \nbot detection in this present study, it is a n avenue that we \nplan to explore as our work progresses.  \nIII. METHODOLOGY  \nOur analysis of \u201cfake news\u201d messages posted by the \nInternet Research Agency (IRA), before, during and after the \n2016 U.S. Presidential election, employed a variety of \napproaches, includin g collection of IRA posts and \u201creal \nnews\u201d dataset s using the Dark Crawler, plus machine \nanalysis of large samples of the posts using Posit, \nTensorFlow, SentiStrength and LibShortText  [55].  \nAlthough this research was geared primarily toward \nmachine learning and the development of an artificial \nintelligence tool to aid in the rapid and accurate pinpoint ing \nof disinformation attacks in their early stages , we also \nconducted qualitative, textual analysis of 1,250 of the IRA \n\u201cfake news\u201d Twitter posts, to  probe into the alleged degree \nof Russian involvement in the disinformation campaign  [8], \n[13], [26], [31] , assess the veracity of claims that the posts \nwere intended to support  Donald Trump\u2019s campa ign for the \nU.S. Presidency whilst simultaneously undermin ing the \ncampaign of Hillary Clinton  [7], [30], [34], [35], [36], [37], \n[38], and investigate the degree to which some of the posts \nwere grounded in \u201creal news,\u201d rather than in what is \ncommonly refer red to as \u201cfake news\u201d [9] , [19], [20], [21], \n[22].  \nA. Research Tools   \nThe Dark Crawler  is a custom -written , web-crawling \nsoftware  tool, developed by Richard Frank of Simon Fraser \nUniversity\u2019s International CyberCrime Research Centre. \nThis application can cap ture Web content from the open and \nDark Web, as well as structured content from online \ndiscussion forums and various social media platforms [61] \n[62], [63]. The Dark Crawler  uses key words, key  phrases, \nand other syntax to retrieve relevant pages from the Web. \nThe Crawler analyze s them, and recursively follow s the links \nout of those pages. Statistics are automatically collected and \nretained for each webpage extracted, including frequency of \nkeywords and the number of images and videos (if any are \npresent). The entire content of each webpage is also \npreserved for further manual and automated textual analysis. \nContent retrieved by the Dark Crawler is parsed into an \nExcel -style worksheet, with each data  element being \nidentified and extracted. In previous studies of this nature, \nwe have employed  this same procedure to collect over 100 \nmillion forum posts from across a vast number of hacking \nand extremist forums , to be used  for later analysis  [61], [62].  \nThe Posit toolkit was deve loped by George Weir of the \nDepartment of Computer and Information Sciences at the \nUniversity of Strathclyde. Posit generates frequency data and \nPart-of-Speech (POS) tagging while accommodating large \ntext corpora. The data output from Posit includes values  for \ntotal words (tokens), total unique words (types), type/token \nratio, number of sentences, average sentence length, number \nof characters, average word length, noun types, verb types, adjective types, adverb types, preposition types, personal \npronoun typ es, determiner types, possessive pronoun types, \ninterjection types, particle types, nouns, verbs, prepositions, \npersonal pronouns, determiners, adverbs, adjectives, \npossessive pronouns, interjections, and particles, for a total \nof 27 features in all  [9], [57], [58]. This process generate s a \ndetailed frequency analysis of the syntax, including multi -\nword units and associated part -of-speech components.  \nAs it was configured  for previous studies , the Posit \ntoolkit  create d data on the basis of word -level information ; \nthus, the limited content o f the Russian IRA tweets that we \nwere examining mean t that many of the original features \nmight have zero values. For this particular research project, \nPosit was extended to include analysis of character -level \ncontent , to assist with the analysis of short t exts. To this end, \nthe system supplement ed the standard word -level statistics , \ngenerating an additional 44-character  features for each \ninstance of text data. These new features include d \nquantitative information on individual alphanumeric \ncharacters, plus a subset of special characters \u2014specifically,  \nexclamation marks, question marks, periods , asterisks and \ndollar signs. The extension of Posit to embrace character -\nlevel as well as word -level data maintain ed the domain -\nneutral nature of Posit analysis.  As a re sult of this extended \nPosit analysis, each data item (tweet) was represented by a \nset of 7 1 features , rather than the usual twenty -seven  [1]. \nTensorFlow, originally developed by the Google Brain \nTeam , is a machine learning system that employs  deep \nneural networks [ 56], inspired by real -life neural systems. \nThe learning algorithms are designed to excel in  pattern  \nrecognition and knowledge -based prediction by training \nsensory data through an artificial network structure of \nneurons (nodes) and ne uronal connections (weights). The \nnetwork structure is usually constructed with an input layer, \none or more hidden layers, and an output layer. Each layer \ncontains multiple nodes, with connections between the nodes \nin the different layers. As data is fed i nto this neural system, \nweights are calculated and repeatedly changed for each \nconnection [ 63]. \nTextual content was further analyzed using \nSentiStrength, which assigns positive or negative values to \nlexical units in the text  [61], [62], [64]. This value is  a \nmeasure that provides a quantitative understanding of the \ncontent of information being found online \u2014specifically, the \nextent to which positive and negative sentiment is present. \nThe program automatically extracts the emotions or attitude \nof a text and a ssigns them a value that ranges from \n\u201cnegative\u201d to \u201cneutral\u201d to \u201cpositive .\u201d \nIn the case of Posit and SentiStrength, the resultant data \nwere input to the Waikato Environment for Knowledge \nAnalysis (WEKA) data analysis application [ 65]. For \nSenti Strength, th e data, comprised of the noun keywords for \neach textual item , along with the associated sentiment score \nand the manual classification for that page, then employed \nWEKA\u2019s standard J48 tree classification method with ten-\nfold cross -validation. In this cross -validation, 10% of the \ndata was hidden, and conditions were sought that would split \nthe remaining 90% of the dataset in two, with each part \nhaving as many data -points as possible belonging to a single \n207International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n class. Accuracy of the tree was then considered relativ e to \nthe hidden 10% of the data. This process was repeated 10 \ntimes, each time with a different hidden 10% subset. WEKA \nproduced a measure of how many of the pages were \ncorrectly classified.  \nFor Posit, we applied the standard J48 tree WEKA \nclassification method , plus the Random Forest classification \nmethod [65], [66], both with ten -fold validation  (as described \nabove) . WEKA then produce d a measure of how many of the \ntext items were correctly classified.  In the Random Forest  \nmethod, classification trees (of the type found in WEKA) are \nindependently constructed, by employing a bootstrap sample \nof the entire dataset , and then relying on a simple majority \nvote for predictive purposes, rather than relying on earlier \ntrees to boost  the weight of successive trees [ 67].  \nFinally, to better enhance the machine learning process, \nand to improve our future classification accuracy, we turned \nour attention to the LibShortText toolkit , as William Yang \nWang of the University of California at Santa Barbara had \nindicated that this tool produced superior results when it \ncame to the accurate classification of shorter items of text, \nsuch as tweets or brief Facebook posts  [15]. LibShortText, \nan open source software package developed  by the Machine \nLearning Group at National Taiwan University, is said to be \nmore efficient and more extensible than other generalized \ntext-mining tools, allowing for the conversion of short texts \ninto sparse feature vectors [ 68].  \nB. Research Sample   \nAt the beginning of the p roject, the research team \ndownloaded a dataset  of 2,946,219 Twitter messages \n(tweets) from git.hub, which had been posted online by \nfivethirtyeight.com. This dataset  of tweets was collected and \nassembled by the afore mentioned professors from Clemson \nUniver sity, Darren Linvill and Patrick Warren [ 54]. These \ntweets were described as originating from the Russian IRA, \nalso referred to in common parlance as the Russian troll \nfactory, a hostile foreign agency that was believed to have \nintentionally interfered in the 2016 U.S. Presidential election \nand the 2016 U.K. Brexit referendum  [7], [8], [9], [10], [13], \n[14], [26], [27], [28], [29], [30], [31], [33] . \nAs the various approaches used in our research (i.e., \nqualitative analysis, Posit, TensorFlow, SentiStrength  and \nLibShortText ) were designed to read English text, a  decision \nwas made to extract only those entries that were labeled as \nbeing \u201cEnglish,\u201d so in the process, we exclud ed languages \nsuch as Albanian, Bulgarian, Catalan, Croatian, Dutch, \nEstonian, French, German, Italian, Russian, Ukrainian, \nUzbek, Vietnamese. As a consequence, 13 new Excel \nspreadsheets were created, with 2,116,904 English -speaking \ntweets remaining in the dataset  following the removal of all \nnon-English tweets .  \nHaving acquire d the Russian  (IRA) Twitter data, we then \nsought a second Twitter dataset  that would allow us to \ndevelop a classification model based upon comparison \nbetween \u201creal news\u201d and what has often been referred to \nsimply as \u201cfake news\u201d [1 9], [20], [21], [22], [24] , [25], [30] . \nTo this end, we analyzed the textual content from the full set of IRA tweets (or \u201cfake news\u201d) using Posit, in order to \nidentify frequently occurring terms, and more specifically , \nnouns.  The resultant \u201ckeyword \u201d list was used by the \nInternational CyberCrime Research Centre\u2019s Dark Crawler , \nin order to retrieve a set of matching \u201creal news\u201d Twitter \nposts from legitimate news sites.   \nThe Dark Crawler harvested Twitter feeds maintained by \nmore \u201ctraditional,\u201d mainstream news sources, such as the \nGlobe and Mail , CBC News , CTV News , the BBC, the New \nYork Times , the Daily Telegraph , the Wall Street Journal , \nAsahi Shim -Bun, Times of India , the Washington Post , the \nGuardian , and Daily Mail Online , collecting tweets posted \nbetween the beginning of January 2015 and the end of \nAugust 2018 ( within the approximate  time frame of the IRA \ntweets). Tweets from the \u201creal news\u201d dataset  that were \nposted after August 2018 were removed, as the data from the \nIRA tweets did not extend beyond that time  frame. We \nstarted with 90,605 tweets, but with the removal of 10,602 \ntweets that had been posted in late 2018  and early 2019 , we \nwere left with 80,003 individual cases or tweets that \nexemplified \u201creal\u201d or \u201clegitimate\u201d news sources. For the \npurpose of Posi t, SentiStrength and LibShortText  analysis, a \nfurther research decision was made to random sample both \ndataset s, creating two dataset s of equal size, each consisting \nof 2,500 tweets, or roughly .001% of the larger \u201cfake news\u201d \ndataset , and 3% of the \u201creal n ews\u201d dataset . Unique identifiers \nwere assigned to each of the data items, to ensure a means of \nfixed reference . \nA somewhat different sample was assembled for the \nTensorFlow analysis , because for TensorFlow to operate \neffectively, a larger dataset  is desira ble. To achieve this, we \ncombined the 2,116,904 English -speaking \u201cfake news\u201d \ntweets that remained (following the removal of all non -\nEnglish cases ) with the 90,605 \u201creal news\u201d tweets that were \ndownloaded by the Dark Crawler (prior to removal of tweets \nthat extended beyond the time frame of the IRA activities). \nThis dataset  was supplemented with 2,500 Facebook \nmessages posted by the IRA, plus an additional \u201creal news\u201d \nset of Facebook  items. Thus, a large dataset  of 2,709,204 \nmillion tweets and Facebook posts was analyzed  in \nTensorFlow following the merging of these multiple \ndataset s.  \nFor Senti Strength  analysis  and LibShortText analysis,  \nwe consolidated four smaller , 2,500 item dataset s into one \nlarger , 10,000 item  dataset . This larger, 10,000 item dataset  \nconsisted of the above -mentioned set of 2,500 randomly \nsampled \u201cfake news\u201d Twitter messages  derived from the \ndataset  of 2,946,219 Twitter messages collected by Clemson \nUniversity professors Linvill and Warren, the above -\nmentioned set of 2,500 randomly sampled \u201creal news\u201d \nTwitter messages derived from the 90,605 tweets collected \nby the Dark Crawle r from traditional, mainstream news \nsources, plus 2,500 \u201cfake news\u201d posts from Facebook and \n2,500 comparator \u201creal news\u201d posts  [9]. The 2,500 \u201cfake \nnews\u201d Facebook messages that formed part of this larger, \n10,000 item dataset  were posted on Facebook by Russ ia\u2019s \nInternet Research Agency between 2015 and 2017, and were \n208International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n again collected and made available by Clemson University \nprofessors Linvill and Warren [ 54]. To secure a source of \n\u201creal news\u201d data for our comparison with the Facebook \n\u201cfake news ,\u201d we obtained a second \u201creal news\u201d dataset , this \ntime of actual Facebook posts made available at github.com \nby data scientist Max Woolf. The data that we retrieved was \noriginally comprised of 164 sets of publicly  accessible \nFacebook status posts. From these status posts , we manually \nselected Facebook IDs that appeared to be associated with \ntraditional news sources, such as USA Today , the New York \nTimes , and CNBC . From these, we randomly selected 2,500 \n\u201creal news\u201d Facebook posts to serve as our comparator \ndataset  [9].  \nC. Data Analysis  \n1) Qualtiative  Textual Analysis  \nQualitative textual analysis was conducted on the first \n1,250 messages appearing in the above -mentioned set of \n2,500 randomly sampled \u201cfake news\u201d Twitter posts, these \n2,500 posts having been derived (winnowed down) from the \ndataset  of 2,946,219 Twitter posts  collected by Clemson \nUniversity professors Linvill and Warren [ 54]. To express it \ndifferently, one ha lf of the  2,500 randomly sampled \u201cfake \nnews\u201d Twitter posts  were read and classified manually . This \nprocess involved two experienced qualitative researchers, \nsitting side -by-side, reading each of the posts  together , in \nmany cases several times, until agreem ent on an appropriate \nclassification was reached. Where there was disagreement, or \nwhere there was insufficient information upon which to \narrive at a conclusion , the classification was designated as \n\u201cundetermined.\u201d  The classification for each of the 1,250 \nTwitter post s was recorded carefully in an Excel spreadsheet, \nwith both researchers watching  over each other\u2019s shoulder, to \nensure the integrity of the data entry.  \nIn a number of cases, th e qualitative classification \nprocess included a Google search, to determine whether or \nnot the content of the post was entirely fictional, partially \ntrue, or mostly  true (i.e., grounded in \u201creal news\u201d ). The two \nresearchers were already familiar with some of the \u201creal \nnews\u201d events that appeared and re -appeared in these posts, \nhaving conducted previous qualitative research on a different \n\u201cfake news\u201d dataset  of messages emanating from the Russian \nInternet Research Agency, in this other case  investigating \nfake Facebook accou nts, rather than Twitter has htags [9]. \n  \n2) Posit  \nFollowing the creation and cleansing of the dataset s, we \nextract ed features from the text s using  Posit , which is \ndesigned to generate quantitative data at the level of word \nand part -of-speech content of texts.  Posit analysis was \napplied to each of the 5, 000 tweets in order to produce a 27 -\nitem feature list for each tweet. This was supplemented by an \nadditional feature, to indicate the \u201creal\u201d or \u201cfake\u201d \ncharacteristic of each tweet.   \nPrevious research has indicated that Posit\u2019s domain -\nindependent meta -data can be effective as a feature set for \nuse in  such text classification tasks  [16], [17], [18] . In the \npresent study, however, the target textual data was made up entirely of tweets. T hese have a limited maximum length of \n280 characters, so they are inherently short and contain \nrelatively few words.  To illustrate, one of the tweets said \nonly: \u201c @realDonaldTrump True ,\u201d while another said only: \n\u201cStay strong! #MAGA .\u201d With this shorter conte nt in mind, \nPosit was extended s uch that the system supplement ed the \nstandard word -level statistics by generat ing an additional 44-\ncharacter  features for each instance of text data. As noted \nabove, the result of this extended Posit analysis  was that each \ndata item ( tweet ) was represented by a set of 71 features, \nrather than the standard 27 features [1], [9].  \nThe list of tweet features generated by Posit was \nformulated as an arff file format, suitable for direct input to \nthe Waikato Environm ent for Knowledge Analysis ( WEKA ) \ndata analysis application [ 65]. In WEKA, we applied the \nstandard J48 tree classification method  and the Random \nForest classification method [ 66], [67], both with ten -fold \nvalidation. WEKA produce d a measure of how many of the \ntweets  were correctly classified.  \n3) TensorFlow  \nIn this project, TensorFlo w was used for processing the \ndata with a Deep Neural Network  (DNN)  [56], [63]. A large \ndataset  was initially fed into TensorFlow , in order  to conduct \nDNN learning . The DNN results either updated an existing \nmodel or created a new model. TensorFlow then compared \nthe same data against the constructed  DNN model , and \nutilized th at model to predict the category  for each data \nentry.  \nIn order to build an initial TensorFlow model, a large \ndataset  of 2,709,204  million tweets was created by merging \nmultiple dataset s. The more data that could be collected for \ntraining a model, the better the accuracy should be. However, \nthe individual data files were inconsistent , since they wer e \ncollected from various online resources, and were formatted \nin very different ways. Thus, in the process of combining \nthem into a single dataset , we opted for Microsoft Access, \nwhich allowed us to create a large, unified  database table. All \nof the datase ts were merged into th is Access database, after \nwhich a class label column \u201c category \u201d was defined, denoting \nwhether the data represented \u201cfake\u201d or \u201creal\u201d news.  \nThe model was evaluated for its accuracy in predicting \nclass values for the \u201cfake\u201d or \u201creal\u201d new s category. To \nsimplify the analysis,  we decided to build our DNN model \nbased on the content of the 2,709 ,204 tweets, without any \nfurther pre -processing.  The DNN model used was a \nTensorFlow Estimator.DNNClassifier.  \nIn the early stages of experimentation, we employed \nTensorFlow  with default settings for the parameters \npertaining to the number of partitions, epochs, layers, \nlearning rate, and regulari zation . With respect to \nregularization , data was partitioned into grou ps according to \nthe order in which it appeared in the dataset. Thus, if the \nmajority of \u201cfake news \u201d appeared in the beginning of the \ndataset, it would be difficult to maintain consistent accuracy \nwhen conducting X -fold cross validation. To overcome this \nissue, the data was randomized as it became partitioned. \nFurthermore, each partition maintained the same data across \nall X -fold cross validation tests, so that the accuracy  of the \nresults could be compared properly . \n209International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n With TensorFlow, e pochs refer to the numbe r of times \nthe dataset is processed during training. The greater the \nnumber of epochs, the higher the accuracy tends to be.  The \nlearning rate determines the rate at which the model \nconverges to the local minima. Usually, a smaller learning \nrate means it that it would take longer for the model to \nconverge at the local minima  [69]. With a larger learning \nrate, the model would get closer to this convergence point \nmore quickly . The values for these parameter s\u2014i.e., the \nnumber of partitions, epochs, layers, learning rate, and \nregularization (L1 & L2) \u2014were then tested to identify an \noptimal set of parameter values.  \n4) SentiStrength  \nFor the SentiStrength analysis  [61], [64], the general \nsentiment of the consolidated, 10,000 item dataset  was first \ncalculate d without using any keywords. As there were no \nimmediate trends identified between the \u201cfake news \u201d and \n\u201creal news\u201d  items, keywords were generated using the top \n100 nouns that appeared in the 10,000 posts. This produced a \n100 x 10,000 matrix, against which we ran various \nalgorithms in WEKA [56], again in an effort to distinguish \nbetween the \u201cfake news\u201d and \u201creal news\u201d items. This \nanalysis included an examination of WEKA\u2019s decision trees, \nNa\u00efve Bayes, BayesNet, and Multilayer Perceptron, the latter \nbeing a de ep neural net algorithm, similar to that found in \nTensorFlow , in that it employs neurons , weights,  and hidden \nlayers [56], [63], [70], [71].  \n5) LibShortText  \nAs noted earlier, LibShortText is an open source software \npackage, developed by the Machine Learning Group at \nNational Taiwan University. The use of LibShortText was \nrecommended in a 2018 paper by William Yang Wang of the \nUniversity of California at Santa Barbara, wherein h e also \ndescribed (and provided access to) his benchmark LIAR \ndataset . This LIAR dataset , which included 12,836 \nstatements labeled for their subject matter, situational \ncontext, and truthfulness, was broken down into training, \nvalidation and test sets, and accompanied by instructions for \nautomatic fake news detection [15] . For this particular \nresearch project, we employed LibShortText, but did not \nmake use of William Wang\u2019s LIAR dataset . We  plan to \nreturn to the LIAR dataset  for purposes of additional \nmachin e training on short text items, as we progress in the \ndevelopment of our critical content toolkit.  \nLibShortText is said to be more efficient and more \nextensible than other generalized text -mining tools, allowing \nfor the conversion of short texts into spars e feature vectors , \nand also for micro - and macro -level error analysis [59]. For \nour research project, we built a model using the default \nsettings that came with the LibShortText software. We \nemployed the \u201c $ python text -train.py trainfile\u201d  command  \nwhich gen erated a \u201ctrainfile.model\u201d for our given training \nfile ( \u201ctrainfile\u201d ). Working with this previously built model, \nwe set out to predict the classification labels of the test set, or \n\u201ctrainfile\u201d using the instructions: \u201c$ python text -predict.py -f \ntestfile tr ainfile.model predict_result,\u201d followed by \u201cOption -\nf\u201d to overwrite the existing model file and predict_result. The \nLibShortText software is available for free download from the National Taiwan  University at: \nhttps://www.csie.ntu.edu.tw/~cjlin/libshorttext/ .  \nIV. RESEARCH RESULTS  \nA. Qualitative (Textual)  Analysis  \nAs discussed in Section III  (above) , qualitative textual \nanalysis was conducted on the first 1,250 messages that \nappeared in the set of 2,500 randomly sampled \u201cfake news\u201d \ntweets posted by the Internet Research Agency (IRA). These \ntweets were read and classified manually by two experienced \nqualitative researchers, who read the posts together, and \njointly assigned an appropriate classification for each \nindividual tweet. The classification for each of these 1,250 \ntweets was recorded in an Excel spreadsheet.  \nOne of the patterns that became appar ent early in the \nprocess was that close to  one-third (31.92%, n = 399) of the \n1,250 tweets that were read manually consisted of what \ncould best be described as \u201capolitical chatter\u201d (see Table I, \nbelow). Tweets that were c lassified as apolitical chatter did \nnot appear to be re-circulating \u201creal news ,\u201d either to targeted \nor untargeted audiences . Moreover, they  did not appear to be \nsupporting the candidacy of either Donald Trump or Hillary \nClinton, nor were they overtly attempting to advance divisive \nissues, create dissension, or otherwise undermine democratic \nprocesses. Examples of apolitical chatter would include \ntweets such as: \u201c#TerribleHashTagIdeas  \nMostRomanticKissAfterVomiting ,\u201d \u201c#ToFeelBetterI  get \nhigh,\u201d \u201c #ThingsYouCantIgnore  Christmas sales ,\u201d and \n\u201c#DontTellAnyoneBut I prefer sex with the lights on .\u201d \nThere are a number of possible explanations when trying \nto account for the presence of so much apolitical chatter. One \nexplanation could be that t he Russian IRA simply did not get \nits money\u2019s worth when hiring some of these Internet trolls. \nTo illustrate,  whichever  troll (or group of trolls) was \nresponsible for the IRA hashtag BOOTH_PRINCE  \ngenerated a disproportionate number of apolitical tweets, fo r \nexample: \u201c #ThereIsAlwaysRoomInMyLifeForDrake ,\u201d \n\u201c#tofeelbetteri think about Iphone 7S \u201d and \n\u201c#MyAmazonWishList  FEMBOTS .\u201d On the other hand, the \nhashtag BOOTH_PRINCE also produced  some Anti -Clinton \ntweets , such as: \u201c A plastic fork too cut a steak \n#ThingsMor eTrustedThanHillary ,\u201d and another referring \nsarcastically to then -Democratic President Barack Obama , \nand to Hillary Clinton\u2019s opponent in the Democratic \nprimaries, Bernie Sanders: \u201c #ObamasWishList Bernie, \nactually. \u201d Thus, it seems more likely that the poli tical \nmessaging was intentionally interspersed with a lot of \napolitical chatter , in an effort to make these IRA -sponsored \nhashtags and tweets appear more akin to the type of \ndiscourse typically found on social media . \nAnother possible explanation for the high number of \nmessages that we found necessary to classify as \u201capolitical \nchatter\u201d would be the difficulties we e ncountered when \ntrying to retrieve the videos or twitter feeds that were linked  \nto these IRA tweets. While the tweets themselves seemed  \nrelatively innocuous, at least on the surface, it is conceivable \n210International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n that they m ay have been targeted toward specific, pre -\nidentified groups, and may have included links to political \nmessaging and political advertising , as has be en suggested \nby various other observers [7], [8], [9], [10],[11], [12], [13], \n[14], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], \n[38].  \n \nTABLE I. RESULTS OF QUALITATIVE, TEXTUAL ANALYSIS  \nClassification  Frequency  % \nApolitical Chatter  399 31.92  \nPro-Trump/Anti -Clinton  328 26.24  \nUndetermined  171 13.68  \nReal News  152 12.16  \nPro-Clinton/Anti -Trump  81 6.48 \nRacist  57 4.56 \nHelpful Advice  35 2.80 \nAnti -Racist  27 2.16 \nTotal  1250  100.00  \n \nA similar explanation might apply to the 171 tweets \n(13.68%)  where we could not arrive at a classification \ndecision, and where the intent of th ose tweets thus ended up \nbeing classified as \u201cundetermined\u201d (see Table I, above). To \nillustrate  the difficulties in the cla ssification process , \namongst the 1,250 tweets that we read  manually , there were \nseven that contained a link to \u201c#RejectedDebateTopics,\u201d and \nthree that contained a link to \n\u201c#BetterAlternativesToDebates,\u201d both of which were \nreportedly subsidiary hashtags created by the Russian troll \narmy [72], [73]. An examination of what little remain ed of \nthe Internet content from  these two hashtags suggested that \nthey were mostly pro -Trump or anti-Clinton, but there were \nembarrassing images of \u2014and embarrassing statements \nabout\u2014Trump as well as Clinton ; therefore , it was \nimpossible to determine with certainty to which variety of \nInternet content the reader s were being directed.   \nDespite the pro -Trump bias of \u201c#RejectedDebateTopics ,\u201d \none of the Russian IRA tweets that we examined that w as \nlinked to this hashtag could safely be classified as being Pro-\nClinton/ Anti-Trump,  because it irreverently asked: \u201cWhich \nEastern European country will Trump's next wife come \nfrom? \u201d However, another  one from the same hashtag, \n#RejectedDeba teTopics asked: \u201c which Kardashian is least \nlikely to have an STD ?\u201d The Kardashians were supporters of \nHillary Clinton during the 2016 U.S. Presidential election , \nwhich allowed us to classify this second tweet as pro-Trump , \nanti-Clinton . On the other hand,  one tweet that was linked to \n#RejectedDebateTopics asked simply: \u201cwho killed the \nKennedy\u2019s ?\u201d [sic], presumably referring to the Kennedy \nfamily, famous for producing Democratic President John F. \nKennedy, Democratic Presidential candidate Robert \nKennedy, an d Democratic Senator Ted Kennedy. A nother \ntweet, this time linked to #BetterAlternativesToDebates , \ntalked about \u201csmoke signaling using Bill\u2019s special cigars,\u201d \nperhaps referring to Bill Clinton,  the former Democratic \nPresident of the United States, and the husband of Hillary \nClinton . It is conceivable that both of the above -mentioned \ntweets were pro-Trump  or anti-Clinto n, but it was agreed that \nthere was insufficient information  to arrive at a decision in this regard . Thus, to  err on the side of caution, bot h were \nassigned to the \u201cundetermined\u201d category.  \nMany of the 1,250 tweets that were read and classified \nmanually were actually engaged in the re -circulation (or \nregurgitation) of \u201creal news\u201d stories, and thus ended up being \nclassified as \u201creal news.\u201d These \u201creal news\u201d tweets \naccounted for 12.16% (n = 152) of the dataset . This is \ncomparable to our findings in a companion research project \nthat involve d the analysis of a sample of 2,500 Russian -\ngenerated Facebook posts, wherein we learned that 13.5% of \nthe Face book posts were based to one extent or another on \nrecognizable, named entities, such as people , places, and \nspecific dates or events [9]. Many of the \u201creal news \u201d tweets \nthat are reported in this present paper were innocuous  news \nstories  and did not appear to be either pro -Trump or pro -\nClinton. Examples of such tweets include: \u201c The Latest: \nSister says crash victim was retired from FBI,\u201d \u201cSan Antonio \nloses another popular radio star after on -air announcement \n#art,\u201d \u201c University of Texas -Arlington police consider \nroaming robot \u201d and \u201c Texas appeals court overturns ex -\nBaylor player's conviction .\u201d Again, there are a couple of \npossible explanations, one being that the Russian IRA did \nnot get its money\u2019s worth from  these trolls, the other being \nthat there was a concerted effort to make these IRA -\nsponsored hashtags and tweets look more like the typical \ndiscourse found on social media, the latter being the more \nlikely of the two. To express it differently, they could be \ndescribed as \u201cbackground noise, \u201d intended to obfuscate the \nreal motivation behind this online activity.  \nThere were also 35 tweets that appeared to be providing \n\u201chelpful advice. \u201d Examples of such \u201chelpful advice\u201d tweets \nwould include: \u201c Free And Cheap Things To Do In #London \n27-28 January  2017 More Info Here ,\u201d \u201cHow to Get \nMagazines to Review Your Music ,\u201d and \u201cQ&A: \u201cWhat are \ntrans fats and why are they unhealthful? #news .\u201d Again, it is \nentirely possible that there was a concerted effort to make \nthese IRA -sponsored hashtags and tweets look m ore like the \ntypical discourse found on social media , by throwing in \nsome \u201cchaff\u201d with the \u201cwheat ,\u201d or that they were put in \nsimply to create background noise.  In any event, tweets that \nwere classified as providing \u201chelpful advice\u201d were few and \nfar between , comprising only 2.8% of the 1,250 \u201cfake news\u201d \nmessages that were read and classified manually.  \nOf the 1,250 tweets analyzed manually, the 328 tweets \nthat overtly supported the presidential candidacy of Donald \nTrump , or that were blatantly anti-Clinton , comprised the \nsecond largest group overall (after \u201capolitical chatter\u201d), and \nvastly outnumbered the 81 tweets that supported the \ncandidacy of Hillary Clinton  (or in the alternative, were anti -\nTrump ), by a ratio of four to one (see Table I, above). An \nexam ple of a pro-Trump tweet that attempt ed to cover all of \nthe main talking points of Trump and his supporters in one \nshot would be: \u201c OUR MAN \u2013He will get us out of the last 8 \nyear mess against our Religion, Jobs, Illegal & Refugee \nOverkill, Homeless Vets & mo re\u2013NEED HIM! .\u201d Other \nexemplars of unabashedly Pro -Trump tweets would be: \u201c I \njust spoke to @realDonaldTrump and he fully supports my \nplan to replace Obamacare the same day we repeal it. The \ntime to act is now ,\u201d \u201cBecause all legal citizens vote Trump! \n211International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n #VoteT rump ,\u201d and \u201cTrump is making manufacturing great \nagain .\u201d  \nTweets that were intended to undermine the campaign of \nHillary Clinton , whilst simultaneously buttressing the \ncampaign of Donald Trump , were in abundance: \u201c Hillary \nClinton to Fundraise with Anti -Christ (No, not Obama a \ndifferent one) ,\u201d \u201c@SheriffClarke: If Trump made me his FBI \nDirector I would be arresting Hillary Clinton today.  \n#Comey ,\u201d and \u201c BREAKING: Julian Assange Is Back! And \nHe Just Put The Nail In Hillary \u2019s Coffin .\u201d The latter tweet \nwas clearly referring to the hack of the Democratic  National \nCommittee\u2019s email server by Russia\u2019s General Main Staff \nIntelligence Unit (the GRU),  and to the subsequent leak of \npotentially embarrassing internal emails on WikiLeaks [7], \n[8]. Another tweet, again  related to WikiLeaks, stated that: \n\u201cWikiLeaks CONFIRMS Hillary Sold Weapons to ISIS... \nThen Drops Another BOMBSHELL! Breaking News .\u201d One \nanti-Clinton tweet targeted her daughter, saying: \u201c Chelsea \nClinton has received another award, this time for a day \u2019s \nworth of work .\u201d Yet another targeted Clinton\u2019s husband, \nsaying: \u201c Remember when Trump got a $1 million birthday \ngift from Saudi Arabia? Oh wait, that was Bill Clinton! \u201d \nThere were 81 tweets (6.48% of the 1,250 tweets that \nwere manually classified) that argua bly supported Hillary \nClinton, or in the alternative, talked negatively about Donald \nTrump, but most were not so blatantly in favo ur of one \ncandidate over the other as the tweets supporting Donald \nTrump , or those attacking Hillary Clinton . To illustrate, o ne \ntweet that was classified as being pro -Hillary, anti -Trump, \nannounced that: \u201c Keith Ellison Plays Race Card, Claims \nTrump Brings White Supremacy to the White House .\u201d This \ntweet could also have been classified as \u201creal news,\u201d in that \nit was reporting abou t Democrat Congressman Keith Ellison, \nwho was running in 2018 for the Attorney General position \nin the state of Minnesota [ 74]. This was evidently some time \nafter the 2016 Presidential campaign, but it has been widely \nreported that the Russia n IRA carried on with its pro -Trump, \npro-Republican, anti -Clinton, anti -Democrat agenda  \nthroughout 2017 and 2018  [75], [76]. The above tweet was \n\u201cgenerously\u201d classified as being anti -Trump, because it \nmentioned \u201cTrump\u201d and \u201cWhite Supremacy\u201d in the same \nbreath. However, a closer examination of the news of the day \nmight suggest that it could have been c lassified  as pro -\nTrump, given that Ellison\u2019s invocation of the \u201crace card\u201d was \nviewed by some as a sign of desperation on his part. But t o \nerr on the side of cautio n, and in view of the oft -repeated \nclaims  by Donald Trump that alleged Russian interference in \nthe 2016 Presidential election is \u201ca hoax\u201d or \u201cfake news\u201d \n[77], [78], this tweet was classified as being anti -Trump.  \nAnother example of erring on the side of ca ution would \nbe the following tweet: \u201c BEHNA: ABSURD! Secret Service \nAgent Declares She Wouldn \u2019t Take A Bullet For Trump .\u201d \nThis too was generously classified as being \u201canti -Trump,\u201d \nbecause it talked about a secret service agent who apparently \nwould not perfo rm her obligatory duties to protect the \nPresident, due to her personal animosity toward Donald \nTrump. It could just as well have been classified as \u201creal \nnews, \u201d because the story also appeared in mainstream news \nsources [ 79]. And it could arguably have bee n classified as \u201cpro-Trump,\u201d because the sender of the tweet appeared to be \nsaying that the behaviour of the secret agent was \u201cabsurd.\u201d \nHowever, we sought at all times to maintain a neutral stance \nin our qualitative textual analysis. In any event, if we ha d \ntaken in -between messages such as these, that seemed at \nleast on the surface to be saying something negative about \nDonald Trump, and classified them instead as \u201cpro -Trump,\u201d \nthen the four -to-one ratio of tweets in favour of Trump \nwould have widened measur ably.  \nIndeed, many of the tweets that were classified as pro-\nClinton  and/or  anti-Trump could have gone either way or \ncould have been classified as \u201cundetermined\u201d in their intent. \nThe following tweet serves to illustrate  this classification \nconundrum:  \u201cDonald Trump's Frog Meme \u2018SINISTER, \u2019 \nClinton Campaign Warns .\u201d This tweet talked  about a \nwarning from the Clinton campaign concerning \u201csinister\u201d \nactivity on the part of Donald Trump and was thus classified \nas being pro-Clinton. However, it may well have been \nintended as a sarcastic \u201cdig\u201d toward Hillary Clinton and her \nteam, or could e ven have been intended to direct the \nfollowers of the tweet to a video in which Donald Trump \nwas \u201cpoking fun\u201d at Clinton ( this was not possible to verify, \nas the attachment has since been removed from the Internet, \npresumably because of the political fallo ut and furor \nfollowing the detection of the Russian disinformation \ncampaign ). \nThis is not to say that there was a total dearth of pro-\nClinton, an ti-Trump messages. One example of a clearly pro -\nClinton tweet would be: \u201c #ImStillWithHer; She's \n#MyChoice #MyPr esident #MyHero .\u201d Another example of a \npro-Clinton tweet would be: \u201c I think people also assume that \nfolks who may vote for HRC won't push her. That couldn't \nbe further from the truth. \u201d There were also a number of \ntweets that were clearly anti -Trump, such a s: \u201cThe Latest: \nGOP senator says party has gone 'batshit crazy' #Texas ,\u201d \n\u201cProtesters in Texas seek release of Trump tax returns ,\u201d and \n\u201cDesigner of Make America Great Again dress is an \nimmigrant ,\u201d not to mention \u201c#anderr LOL : Mad Max \nReveals THE EXACT MONT H Trump Will be Impeached .\u201d \nBut such overtly pro-Clinton  or anti-Trump messages were \ncomparatively few and far between, and in many cases , had \nto be \u201cteased out\u201d of the dataset . \nThere were quite a few blatantly racist messages in the \nfirst 1,250 \u201cfake news\u201d tweets (4.56%, n = 57), some of \nwhich could arguably have been categorized as pro -Trump  \nand anti-Clinton, as they mimicked Donald Trump\u2019s \nportrayal of Mexicans as criminals, dr ug traffickers and \nrapists  [80], favoured his \u201cMuslim ban\u201d [ 81], supported his \nanti-immigration stance, and generally concurred with his \ndescription of Haiti, El Salvador and certain African nations \nas \u201cshithole countries\u201d [ 82], all of which was reportedly  \nintended by Trump \u2014and by the Russian IRA \u2014to foster an \natmosphere of distrust, divisiveness and fear  with respect to \nimmigrants and racial minorities , in order to \u201crile up\u201d \nTrump\u2019s  voter base  [7], [8], [32], [33], [34] . Examples of \nanti-Mexican or Anti -Central American tweets include: \u201c 11 \ndumped from Rio Grande raft rescued by Border Patrol ,\u201d and \n\u201cA mayor was just shot dead in Mexico on the day after she \ntook office .\u201d Messages targeting African -Americans were \n212International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n also in evidence, with exemplars including such tweets as: \n\u201cWhen a tall ass nigga, sees a short ass nigga w/ a tall \ngirlfriend ,\u201d or \u201c Young Black folks keep saying they're not \nlike the ancestors. And I keep saying that's the problem ,\u201d or \n\u201cThey steal everything. Black folks have to be wiser .\u201d Anti-\nMuslim messaging could be f ound in abundance, in tweets \nsuch as: \u201c\u2018 The Koran is a fascist book which incites \nviolence. This book, just like Main Kampf  [sic], must be \nbanned. \u2019- G. Wilders ,\u201d or \u201c5-year-old girl was raped by \nmuslim immigrants and nobo dy's talking about that! \n#IsalmIsTheProblem ,\u201d or \u201cDid you know that Muslims are \nnow allowed to have sex with slave woman even after their \ndeath?! #BanIslam .\u201d The overall thrust of these anti-Muslim , \nanti-immigration , anti -refugee  messages is best encapsula ted \nin the following tweet: \u201c See those countless women and \nchildren? Neither do I https://t.co/tZOkWo7OjZ #banIslam \n#Rapefugees https://t.co/XoETkXAidV .\u201d \nThe above -mentioned racist messages, many of which \nclearly supported the Trump political agenda, were counter -\nbalanced by approximately half as many anti -racist messages \n(2.16%, n = 27). Anti -racist tweets included the following: \n\u201cWe deserve to feel safe in our cars, our businesses, our \nparks, our homes and our churches. \n#BlackSkinIsNotACrime ,\u201d \u201cNew Mexico Store in Trouble \nfor Controversial Obama, Anti -Muslim Signs ,\u201d and \u201c 34-\nyear-old African -American man in Wisconsin brought 3 \ndifferent documents to DMV & still couldn \u2019t get voter ID .\u201d \nAgain, we imagine that the inclusion of this comparatively \nsmall number of anti -racist tweets was likely intended to \noffset the overtly pro -Trump, anti -immigration bias that was \nin evidence throughout the dataset , and to make these \nRussian -generated hasht ags and tweets look more like the \ntypical discourse found on social media.  Quite apart from \nthat, ostensibly anti -racist tweets such as these could actually \nhave been crafted in such a way as to stoke fear and distrust \namong immigrants and racial minoritie s (thereby suppressing \ntheir vote), with comments about their overall lack of safety, \nand the difficulties that they could expect to experience when \nattempting to register to vote.  \nThe findings of our qualitative textual analysis of the first \n1,250 messag es that appeared in the set of 2,500 randomly \nsampled \u201cfake news\u201d tweets posted by the Russian IRA  \nstrongly support the oft -reported conclusion that these \nTwitter feeds were intended to buttress the Presidential \ncampaign of Donald Trump, and to stoke disse nsion, distrust , \nanger  and fear in the American voting populace  [7], [8], [9], \n[13], [26], [28], [35], [36], [37], [38] . Although it was \nsometimes difficult to tease out, we also adduced evidence \nthat the hashtags and tweets were indeed generated by \nRussia n sources, which runs counter to the White House \nnarrative about \u201cthe Russian hoax\u201d [ 77], [78]. To illustrate, \none tweet announced: \u201c Nikolai Nikolaevich Ge - _ Russian \nrealist painter famous for his works on historical and \nreligious motifs - was born today .\u201d Another noted that \u201c The \nRussian band Leningrad is bringing its smashing program \ntitled '20 Years for Joy' to the US ,\u201d while still another \nreported that \u201c For the first time since 2010, the MoscowState \nUniversity has returned to the top 100 of QS World \nUniversity Rankings global ranking .\u201d While such news stories might have held some interest for the Russian Internet \ntrolls, it seems unlikely that they would have been of \nparticular interest to American users of Twitter .  \nB. Posit  Results  \nAs noted earlier, t he Posit toolkit generates frequency \ndata and Part -of-Speech (POS) tagging while \naccommodating large text corpora.  The Posit analysis \nproduced a feature set with corresponding values for each of \nthe 5,000 tweets , that is, the 2,500 \"fake news\u201d tweets and \nthe 2,500 \"real news\u201d tweets. The feature set was loaded into \nWEKA as a basis for testing the feasibility of classification \nagainst the predefined \u201cfake\u201d and \u201creal \u201d news categories. \nUsing the \u201cstandard\u201d set of 27 Posit features \u2014and the \ndefault WEKA settings w ith 10 -fold cross validation \u2014the \nJ48 and Random Forest classifiers gave 82.6% and 86.82% \ncorrectly classified instances respectively. The confusion \nmatrix for the latter performance is shown in Table II , below.  \n \nTABLE II. CONFUSION MATRIX FOR POSIT: 27 FEA TURES (RANDOM \nFOREST: DEFAULT WEKA SETTINGS)  \n \nn=5,000  Predicted:  \nNEGATIVE  Predicted:  \nPOSITIVE   \nActual:  \nNEGATIVE  2,190  310 2,500  \nActual:  \nPOSITIVE  340 2,160  2,500  \n \nAs indicated previously, Posit was enhanced with an \nadditional 44 character -based features , resulting in a total of \n71 features, rather than the standard 27 features [1] . This was \ndone in order to address the fact that tweets  have a limited \nmaximum length of 280 characters ; thus, they are inherently \nshort , and contain re latively few words . Using this extended \nfeature set on the 5,000 tweets \u2014and the default WEKA \nsettings with 10 -fold cross validation \u2014the J48 and Random  \nForest settings classifiers gave 81.52% and 89.8% correctly \nclassified instances respectively. The confus ion matrix for \nthe latter performance is shown in Table III , below.  \nChanging the number of instances (trees) from the \ndefault value of 100 to 211 in Random Forest provided a \nboost to the level of correctly classif ied instances to 90.12%. \nThe confusion matr ix for this performance is shown in Table \nIV, below . \n \nTABLE III. CONFUSION MATRIX FOR POSIT: 71 FEATURES (RANDOM \nFOREST: DEFAULT WEKA SETTINGS)  \n \nn=5,000  Predicted:  \nNEGATIVE  Predicted:  \nPOSITIVE   \nActual:  \nNEGATIVE  2,266  234 2,500  \nActual:  \nPOSITIVE  276 2,224  2,500  \n \n \n213International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n TABLE IV. CONFUSION MATRIX FOR POSIT: 71 FEATURES (RANDOM \nFOREST: INSTANCES AT 211 IN WEKA SETTINGS)  \nn=5,000  Predicted:  \nNEGATIVE  Predicted:  \nPOSITIVE   \nActual:  \nNEGATIVE  2,269  231 2,500  \nActual:  \nPOSITIVE  263 2,237  2,500  \n \nOur best performance results (90.12%) were obtained \nfrom the Posit classification using the 71-feature  set with \nRandom Forest (instances at 211). The \u201cdetailed accuracy by \nclass\u201d for this result is shown in Table V . \n \nTABLE V. DETAILED ACCURACY BY CLASS FOR  BEST POSIT RESULT  \n \nClass  TP Rate  FP Rate  Precision  Recall  F-Measure  \nNEGATIVE  0.908  0.105  0.896  0.908  0.902  \nPOS ITIVE  0.895  0.092  0.906  0.895  0.901  \nWeighted \nAvg.  0.901  0.099  0.901  0.901  0.901  \n  \nFollowing these classification efforts  using Posit , the two \ndatasets (the real and fake  tweets ) were subjected to further \nanalysis. The aim at this point was to determine whether any \nobvious characteristics in the data might skew the \nclassification results. Several checks were made on the \ncomp lexion of the two sets of data, focusing particularly on \ntheir relative content in terms of words and characters \u2014since \nthese features are the focus of the Posit analyses.  \nA comparison was made of the length of tweets in the \ntwo datasets. This revealed some  differences in the \ndistribution of tweets according to their length measured in \nwords (Figure 1). Generally, distribution by length in words \nfor the real news tweets rose above the curve for distribution \nby length in words for the fake tweets. Conceivably , this \nwould ease the challenge of discriminating between the two \ndatasets.  \n \n \nFigure  1. Comparison of Tweet Lengths ( Words)  \n \nSince tweets are limited to 280 characters in length, a \nnatural contrast was to consider the relative lengths of tweets \nby number of characters. This comparison (Figure 2), \nrevealed a further distinctive trend in the real as opposed to \nthe fake tweet conte nt.  \n  \nFigure 2.  Comparison of Tweet lengths ( Chars) \n \nFigure 2 indicates that, as with length measured in \nnumber of words, length as measured by number of \ncharacters showed a distinctive trend for the real tweet \ncontent above the fake tweet content. As before, this may \nreasonably ease the task of differentiating real from fake \ntweets . \nThis post -classification analysis revealed one further \nnotable insight on the character -lengths of real tweets. As \nshown in Figure 2 (above), some tweets with real content \nexceeded the 280 -character maximum size permitted on \nTwitter. In total, t welve tweets in the real category of tweets  \nwere found to exceed 280 characters. Upon further \ninvestigation, this was found to be due to the presence of \nappended URLs in these tweets that had not been removed \nduring the data cleaning stage. While this accounted for only \n0.48% of the total real tweets, the excessive length of these \ntweets single them out as different from every  example of \nfake tweet.  \nAdditional insi ght on data complexion was derived from \ncomparison of average and median values for length by \nwords and length by characters (Table VI). This showed little \ndifference in average and median tweet lengths in words and \na wider separation in terms of character s. \n \nTABLE VI. AVERAGE AND MEDIAN TWEET LENGTHS  \n  \nReal  Fake  \nAverage tweet length (words)  15 13 \nMedian tweet length (words)  14 12 \nAverage tweet length (chars)  130 102 \nMedian tweet length (chars)  125 104 \n \nA final contrast was made across the real and fake tweet \ndatasets in terms of the use of specific characters. Two \nfactors were considered: the presence of \u2018special characters\u2019 \nand the number of character types (i.e., unique characters) in \nthe tweets.  \nThe character -level Posit analysis generates severa l \nfeatures based upon use of special characters for each data \nitem. In this case, the special characters are full -stop, \nquestion mark, exclamation mark, dollar sign and asterisk, \ni.e., five possible special characters.  \nThe contrast between real and fake t weet content in terms \nof how many different special characters appear in each \ntweet is illustrated in Figure 3 (below).  This reveals notable \n214International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n differences between the two types of tweet. Fake tweets \navoid all special characters more commonly than real tweet s. \nWhile many of both types deploy one special character, \nmany more of the fake tweets deploy two special characters. \nThere is less difference between the varieties of tweet at the \nthree special character level  while no tweets combine use \nfour or five of t hese special characters.  \n \n \nFigure 3. Comparison of Special Character Usage  \nOur comparison of the number of unique characters \npresent across the tweet datasets, surveyed the presence of \nthe alphanumeric set of characters (not case -sensitive) and \nthe special characters noted above. This contrast is illustrated \nin Figure 4 (below) and further indicates a subtle difference \nbetween real and fake tweet content.  \nAs noted earlier, the classification performance using \nPosit as a basis for feature generation gave a best \nperformance match to the manual classification of 90.12%.  \nWhile balanced in sample size, classification performance on \nthis relatively small data  subset of 2,500 real and 2,500 fake \ntweets, may have been influenced positively by the data \ncharacteristics described above. As a step toward eliminating \nsuch a potential  anomaly, we deployed a much larger dataset \nwhen classifying with Tensorflow.  \n \n \nFigure 4. Comparison of Unique Character Usage \n \nC. TensorFlow  Results  \nRecall that i n this project, TensorFlo w (developed by \nGoogle  Brain) was used for processing the data with a Deep \nNeural Network  (DNN) [5 6], [63]. Posit analyzed a randomized sample of 5,000 tweets, that is, the 2,500 \"fake \nnews\u201d tweets, and the 2,500 \"real news\u201d tweets. A much \nlarge r dataset , consisting of 2,709,204 million tweets  and \nFacebook posts, was fed into TensorFlow  upon \ncommencement , in order  to conduct DNN learning . Then, \nthe DNN results either updated an existing model , or created \na new model. TensorFlow next compared the same data \nagainst the constructed  DNN model , and utilized th at model \nto predict the category  for each data entr y. In the early stages \nof experimentation, using default TensorFlow parameters for \nnumber of partitions, epochs, layers, learning rate, and \nregulari zation , the accuracy res ults y ielded an average of \naround 60% . Many parameter values (for each parameter: \nnumber of partitions, epochs, layers, learning rate, and \nregularization ) were then tested to identify an optimal set of \nparameter values. This resulted in a n increase in accuracy to \n89.5%, a substantial improvement from the earlier results . \nThese parameters are described below, with the post-training \noptimal values shown in Table VII. \nTo be able to run large numbers of experiments, we \nwrapped all code into a standalone function, so that large \nnumbers of various scenarios could be designed, set up, and \ntested continuously. These batch jobs allowed us to evaluate \ndifferent combinations of parameters. The parameters of \neach run, and the corresponding results, are also shown \nbelow . Tests  were run using 10 partitions, with training on \nthe first 5 partitions, and testing on the last 5 partitions . \n \nD. SentiStrength Results  \nSentiStrength assigns positive or negative values to \nlexical units in the text [61], [64]. Recall that this value is a \nmeas ure that provides a quantitative understanding of the \ncontent of information \u2014specifically, the extent to which \npositive and negative sentiment is present. The program \nautomatically extracts the emotions or attitude of a text and \nassigns a value that ranges  from \u201cnegative\u201d\u2019 to \u201cneutral\u201d to \n\u201cpositive.\u201d For SentiStrength analysis, we consolidated four \nsmaller, 2,500 item datasets into one larger, 10,000 item \ndataset. This larger, 10,000 item dataset consisted of the set \nof 2,500 randomly sampled \u201cfake news\u201d Tw itter messages, \nthe set of 2,500 randomly sampled \u201creal news\u201d Twitter \nmessages, the set of 2,500 \u201cfake news\u201d posts from Facebook, \nand the set of 2,500 comparator \u201creal news\u201d posts.  \nFor initial SentiStrength analysis, the \u201cgeneral sentiment\u201d \nwas calculated (i.e., without keywords), but all scores were \nnegative, without any apparent distinguishing trends \u2014\nbetween \u201cfake news\u201d and \u201creal news,\u201d or between Twitter \nitems and Facebook items. We then proceeded to use \nkeywords, by calculating the top 100 no uns out of the 10,000 \nposts, and running sentiment analysis again, this time with \nrespect to the 100 identified nouns. This produced a 10,000 x \n100 matrix (4 x 2 ,500 = 10,000 rows, one for each post, and \n100 columns for each noun, or keyword). On this matr ix, we \nran various algorithms using WEKA [65] and TensorFlow  \n[56], in an effort to differentiate between the four classes, \nthat is, \u201cfake news\u201d Twitter messages, \u201creal news\u201d Twitter \nmessages, \u201cfake news\u201d posts from Facebook, and the \ncomparator \u201creal news\u201d posts. This too proved to be futile, as \n215International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n there were too many missing values for the decision trees to \nhandle properly, and given that the reported predictive \naccuracy was not much better than a random guess.  \n \nTABLE VII. TENSORFLOW PERFORMANCE RESULTS  \n \nLayers  Learn \nRate  Partition  Size Time  Accuracy  \n \n[500, 500]  0.003  0 674941  44.683  0.873  \n[500, 500]  0.003  1 675072  48.102  0.873  \n[500, 500]  0.003  2 674613  45.654  0.873  \n[500, 500]  0.003  3 675109  45.638  0.873  \n[500, 500]  0.003  4 9479  2.562  0.871  \n[700, 700] 0.003  0 674941  217.444  0.873  \n[700, 700]  0.003  1 675072  57.929  0.874  \n[700, 700]  0.003  2 674613  59.508  0.873  \n[700, 700]  0.003  3 675109  58.923  0.873  \n[700, 700]  0.003  4 9479  3.020  0.872  \n[500, 500]  0.03 0 674941  128.865  0.882  \n[500, 500]  0.03 1 675072  59.551  0.882  \n[500, 500]  0.03 2 674613  60.684  0.881  \n[500, 500]  0.03 3 675109  61.396  0.882  \n[500, 500]  0.03 4 9479  3.205  0.895  \n  \nFinally, as were primarily interested in distinguishing \n\u201cfake news\u201d from \u201creal news,\u201d we collapsed the four dataset s \ninto two classes, \u201creal news\u201d and \u201cfake news,\u201d each \nconsisting of 5,000 items. The results of this final sentiment \nanalysis are shown in Table VI III (below). While the \nBayesNet  and Na\u00efve Bayes indicated 56.85% and 58.06% of  \ncorrectly classified instances respectively , these would be \nconsidered barely better than random guesses, at 50.00%. \nHowever, the MultiLayer Perceptron, a deep neural net \nalgorithm, similar to that found in Te nsorFlow, in that it \nemploys neurons, weights, and hidden layers [5 6], [63], [69], \n[71], yielded a classification accuracy of 74.26%. This would \nbe considered \u201cacceptable,\u201d or at least more acceptable than \nbarely better than random guess es, but not up to t he \nstandards that we are presently seeking.  \n \nTABLE VIII. DETAILED ACCURACY BY ALGORITHM FOR BEST \nSENTISTRENGTH RESULT  \n \nAlgorithm  Accuracy  \n \nRandom Guess  50.00%  \nDecision trees  50.33%  \nBayesNet  56.84%  \nNa\u00efve Bayes  58.06%  \nMultilayer Perceptron  74.26%  \n \nE. LibShortText Analysi s  \nFor LibShortText analysis, we again consolidated four \nsmaller, 2,500 item dataset s into one larger, 10,000 item \ndataset , identical to the one used for the SentiStrength \nanalysis (see above) . This 10,000 item dataset  was split into \ntwo randomly sorted 5,00 0 item dataset s, one for training \npurposes, and the other for testing purposes. For our \nresearch project, we built a model using the default settings \nthat came with the LibShortText software [ 68]. On the first \nattempt, our classification accuracy was 80.56%, \nsubstantially better than the accuracy yielded by the \nSentiStrength analysis. Our second attempt resulted in a \nclassification accuracy of 90.2%, comparable to the classification accuracy yi elded by Posit, at 90.12% , albeit \nusing a larger and more diverse dataset  than the one input to \nPosit .  \nV. DISCUSSION  \nWe were disappointed with the SentiStrength analysis, \ngiven that when we combined SentiStrength with the WEKA \nstandard J48 decision -tree classification method in an earlier \nstudy of online extremist content, we were able to correctly \nclassify 80.51% of the webpages [16]. In fact, with our \nearlier extremism study, t he binary anti-extremist and pro -\nextremist categories had  even highe r degrees  of correctly \nidentified pages , with 92.7% of the pro -extremist cases  and \n88% of the anti -extremist cases correctly identified. This \nindicated to us that the decision tree worked well when it \ncame to classifying extremist content [16]. In this present \nstudy, the MultiLayer Perceptron ( a deep neural net \nalgorithm) yielded a classification accuracy of 74.26%, \nwhich is comparable to the results of other studies that have \nemployed sentiment analysis on tweets [59], [83]. We are \nhoping that further machine training, perhaps enhanced by an \nexpanded list of keywords provided by the ongoing \nqualitative analysis, will improve upon these SentiStrength \nresults.  \nTensorFlow epitomizes machine -learning and artificial \nintelligence, in that it gradually teaches itself,  once provided \nwith sufficient data and the requisite training/learning \nepochs. It is anticipated that the predictive accuracy of the \nTensorFlow component will ultimately exceed 90% once it \nis fully trained and fully operational. In a current trial  \nexperim ent, we demonstrate d that the predictive accuracy of \nTensorFlow does indeed improve with the amount of \ninputted data. For the first round of analysis, we randomly \nselected 10,000 Facebook items from another \u201creal news\u201d \ndataset and 10,000 items from another  \u201cfake news\u201d dataset  \nthat we had recently generated using the Dark Crawler , next \nmerging and shuffling the two files to create one file \ncontaining 10,000 Facebook items. In this case, the \npredictive accuracy of TensorFlow was only 48.65% when \nanalyzing the  content alone, and 50.4% when analyzing the \ncontent along with tagged text generated by Posit. On the \nother hand. TensorFlow\u2019s predictive accuracy increased to \n79.84% and 79.94% (with the Posit features) when we used \n90,000 Facebook items from our \u201creal n ews\u201d dataset and \n10,000 items from our \u201cfake news\u201d dataset to create a larger \nfile containing 100,000 Facebook items.  \nThat said, TensorFlow requires big data and significant \nprocessing times. Thus, while TensorFlow will be \ninstrumental in analysing the mas sive amount of data to be \nharvested, it will likely not be capable of providing the type \nof near-real-time alerts on hostile information activities  \nrequired for our anticipated \u201ccritical content toolkit.\u201d  Rather, \nwe expect that it will provide ongoing, dee p-level analysis of \nall of the data as it is collected, and assist in the building of \nnew models in response to any changes in the strategies and \ntactics of hostile foreign actors. As a consequence, we \nanticipate that we will be turning to  other (companion ) \nmodels to enhance the prospects for near -real-time alerts.  \n \n216International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n  \nFigure  5. The Tenso rFlow Model  \n \nThe TensorFlow model on which we are presently \nworking (see  Figure 5, above ) commences with The Dark \nCrawler searching the Internet and downloading all relevant \ncontent onto The Dark Crawler server. The data from the \nstored content is then converted into an Excel file containing \nall of the pertinent information for each individua l data item \n(e.g., the time and date of the message, text, or post; the \nhashtag, Facebook page or publication source; the forum and \nsubforum, if taken from a forum; the Internet address, if \navailable; the title of the text or message, if any; the body of \nthe text or message; the number of likes, re -posts or re -\ntweets; etc.). This data is input to TensorFlow for deep \nneural network analysis, leading to the generation of a model \nfor measuring the presence of hostile information activities \non the Web \u2014a tool wh ich will then predict/classify social \nmedia messaging and other sources of online news as \u201cfake\u201d \nor \u201creal.\u201d  \nGiven the limited number of words and word varieties in \nmost tweets, the performance of the Posit analysis using the \ndefault 27 word -level features proved to be better than \nexpected , with  86.82% correctly classified instances using \nRandom Forest. The addition of character -level information \nenhanced this performance to a creditable 90.12% correctly \nclassified instances , again using Random Forest.  This result \nwas somewhat surprising , given that alphanumeric details \nseem far removed from tweet content -level  [1]. \nThe Posit toolkit is limited by the speed at which it can \nread and analyze large volumes of text. Posit is not as slow \nas TensorFlow, and when co mbined with WEKA, it has an \ninitial classification accuracy that exceeds that of \nTensorFlow and in some cases matches that of LibShortText.  \nNevertheless, while Posit does not excel in reading and \nanalyzing large text corpora as quickly as LibShortText, or in \nanalyzing the vast amounts of data that can be input into \nTensorFlow for machine learning purposes , it does bring an \nentirely different dimension to the model that we are \nbuilding, in that t he Posit toolkit generates frequency data \nand Part -of-Speech (P OS) tagging , with data output  \ninclud ing values for total words (tokens), total unique words \n(types), type/token ratio, number of sentences, average \nsentence length, number of characters, average word length, noun types, verb types, adjective types, adverb types, \npreposition types, personal pronoun types, determiner types, \npossessive pronoun types, interjection types, particle types, \nnouns, verbs, prepositions, personal pronouns, determiners, \nadverbs, adjectives, possessive pronouns, interjections \nparticles.  As Posit recognizes and records individual words \nand characters, it can aid significantly in the adaptation of \nthe overall model to the changing strategies and tactics of \nhostile foreign actors, and at the same time, glean unique \nkeywords or key phrases f rom incoming data so that the \nactivities of hostile foreign actors can be identified quickly \nand targeted more precisely.  \n \n \nFigure 6. The Posit/WEKA Model  \n \nThe Posit model that we envision (see Figure 6, above) \ndiffers from the TensorFlow Model, in that once the data is \nharvested, organized, and ready for input, it first goes into \nPosit for analysis, and then into WEKA for secondary \nassessment of classification accuracy. Posit (in combination \nwith WEKA) has at ti mes generated classification accuracy \nin the 98 -99% range when it comes to processing various of \nthe recently generated data sets  that we have on hand . \n The LibShortText results  were very encouraging, with a \ncreditable classification accuracy of 90.2%, com parable to \nthe 90.12% classification accuracy yielded by Posit.  \nRecently, in conjunction with our work with LibShortText, \nwe downloaded and configured LibLinear, a companion \nopen source software package, again developed by the same \nMachine Learning Group a t National Taiwan University  that \ndeveloped LibShortText  [84]. LibShortText is a text analysis \nprogram, while LibLinear is a classification program. \nLibLinear predicts the accuracy of the classification \nperformed by LibShortText, much like WEKA predicts th e \naccuracy of the classification performed by Posit. Another \nadvantage to LibLinear is that is supports incremental and \ndecremental learning, or to express it differently, the addition \nand removal of data in order to improve optimization and \ndecrease run t ime. LibShortText, on the other hand, does not \nreadily support updating of the model.  \n \n217International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n  \nFigure 7. The LibShortText/LibLinear Model  \n \nGenerally speaking, LibShortText and LibLinear have \nbeen outperforming TensorFlow and Posit in a number of \nour current trial experiments. To illustrate, when analyzing \n1,000 randomly selected data items taken from our more \nrecently generated \u201creal news\u201d da tasets, contrasted with \n1,000 randomly selected data items taken from our more \nrecently generated \u201cfake news\u201d dataset s, we found that \nLibShortText and LibLinear exhibited classification \naccuracies of 93% and 92% respectively, as opposed to Posit \nand WEKA a t 72.7%, TensorFlow (using Posit -generated \n.arff content at 54.5%, TensorFlow (using content only) at \n52.5%, and TensorFlow (using tagged text) at 48%. We \nwould consider these TensorFlow numbers to be no better \nthan tossing a coin, but these results were not entirely \nunexpected, as TensorFlow thrives on large data, and this \nexperiment was conducted using only 2,000 discrete data \nitems.  \nThis LibShortText/LibLinear M odel ( see Figure 7 , \nabove ) is essentially the same as the TensorFlow Model set \nout in Figure 5 (above), in that it commences with The Dark \nCrawler searching the Internet and downloading all relevant \ncontent onto The Dark Crawler server. The data from the \nstored content is then converted into an Excel file containing \nall of the pertinent infor mation for each individual data item. \nThis data is input to either LibShortText or LibLinear for the \ngeneration of a model for measuring the presence of hostile \ninformation activities on the Web \u2014a tool which will then \npredict/classify social media messagin g and other sources of \nonline news as \u201cfake\u201d or \u201creal,\u201d much more quickly than \nTensorFlow or Posit.  \nIn this model, LibShortText and LibLinear can be used \nalmost interchangeably, in most cases without unduly \naffecting the processing times or predictive acc uracy. We \ndid, however, encounter limitations with LibShortText on the \ntraining and testing file sizes when using only 4GB of RAM. \nWe received \u201cmemory exhausted\u201d notifications, and \ninstructions to \u201crestart python.\u201d After upgrading to 32GB of \nRAM, this prob lem was resolved. That said, the required \nRAM size is an issue to be borne in mind as we design the \nfinal model.  VI. CONCLUSION   \nThrough the research process outlined above, we have: 1) \ndevelop ed typologies of past and present hostile activities in \nCloud -based  social media platforms; 2) identif ied indicators \nof change in public opinion (as they relate to hostile \ndisinformation activities); 3) identifi ed the social media \ntechniques of hostile actors (and how best to respond to \nthem); and 4) undertak en cross -cultural analyses, to \ndetermine how hostile actors seek to fuel tensions and \nundermine social cohesion by exploiting cultural \nsensitivities.  \nOur current research will ultimately generate an \nalgorithm that can automatically detect hostile \ndisinformation conten t. In the longer term, we will use the \nknowledge generated by this research project to further \nexpand and integrate the capabilities of the Posit toolkit and \nthe Dark Crawler, in order to facilitate near -real-time \nmonitoring of disinformation activities in  the Cloud . Further, \nwe plan to add a feature that w ill permit us to capture \ndisinformation messages prior to their removal by social \nmedia organizations attempting to delete those accounts, \nand/or their removal by actors seeking to concea l their online \nidentities. Ideally, this integrated, \u201ccritical content t oolkit\u201d \nwill be able to recalibrate itself when confronted with ever -\nchanging forms of disinformation.  \nDuring the research process, we also downloaded 2,500 \n\u201cfake news \u201d Facebook messages  that had been posted by the \nIRA on Facebook pages known variously as  Blacktivist, \nPatriototus, LGBT United, Secured.Borders, and United \nMuslims of America. (These 2,500 Facebook messages were \nincluded in our TensorFlow , SentiStrength and LibShortText \nanalysis ). All 2,500 of these messages  have been subjected to \na prelimina ry review in the qualitative research tool, NVivo , \nand also, to preliminary review in Posit [9] . Early insights \nfrom this companion study revealed that many of the \nallegedly \u201cfake news\u201d items  were founded to one degree or \nanother in contemporaneous \u201creal news\u201d events.  \nFollowing the initial round s of data collection described \nearlier in this paper , we broadened and enriched our selection \nof data sources, focussing primarily on Facebook, Twitte r, \nand other web -based news sources. A \u201cfake news\u201d list of \nFacebook pages was generated by searching for Facebook \npages that belonged to websites described by \nMediaBiasFactCheck.com as coming from \u201cquestionable \nsources.\u201d MediaBiasFactCheck was founded and is edited by \nDr. David Van Zandt \u2014a professor, lawyer, and current \npresident of The New School \u2014along with his team of \nvolunteers.  In all, we harvested 96,219 Facebook \u201cfake \nnews\u201d items, posted between January 2014 and September \n2019. This was recently suppl emented by a set of 3,736 \nCanadian Facebook \u201cfake news\u201d items, posted from May \n2014 up to the present.  \n Data for the expanded Twitter data set, specifically \nassembled by the research team for this ongoing project, \nwere also extracted the same way as the se t of \u201cfake\u201d \nFacebook posts, that is, by using the list of 530 \u201cquestionable \nsources\u201d published by MediaBiasFactCheck.com. From this, \n181 Twitter accounts were identified for data collection, \n218International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n accounting for 43,193 data items posted between March \n2009 up to the present. Only Twitter accounts that contained \na link to the websites identified  as suspect  by \nMediaBiasFactCheck.com were included in this sample.  \nOur third category of \u201cfake news\u201d was recently derived \nfrom Web sites presenting themselves as legitimate sources \nof real news but considered \u201cfake.\u201d News articles were \ncollected from four publicly available datasets: (1) ISOT \nFake News , (2) Getting Real About Fake News , (3) Fake \nNews Corpus , and (4) FA-KES: A Fake News Dataset \naround the Syrian War . ISOT Fake News  was created by the \nInformation Security and Object Technology (ISOT) \nresearch lab at the University of Victoria [85]. The dataset \ncontains both fake and real news. The former was obtained \nfrom websites considered unreliable by Politifact, a website \ndedicated to fact -checking U.S. news. Real news was \nobtained from the website Reuters.com. In total, there were \n21,417 real news and 23,481 fake news items.  Getting Real \nAbout Fake News  was created in 2016 by Megan Risdal, a \nProduct Lead at Kaggle (an online data science community). \nThis dataset contains 12,999 news articles from 244 sources \nobtained from the BS Detector Chrome extension. The \narticles are labeled according to their credibility as fak e, \nconspiracy, hate, bias, satire, junk science, and \u201cbullshit.\u201d  \nFake News Corpus  is an open source dataset from 2018 \nthat contains 9,408,908 news articles, created by GitHub user \n\u201cseveral27.\u201d News articles were obtained from a list of 745 \ndomains from ww w.opensources.com, as well as the New \nYork Times  and webhose English news articles. For the \ncurrent project, after cleansing the dataset by removing \nunlabelled items, we have retained 779,882 fake news items \nand 1,783,529 credible news items.  Finally, the FA-KES \ndataset, created at the American University of Beirut with the \nintention of helping train machine learning models, contains \n805 news articles about the conflict in Syria, of which 46 are \nlabelled as \u201cfake,\u201d with the remaining 378 labell ed as \u201creal\u201d \n[86].  \nComparator \u201creal news\u201d Facebook and Twitter data sets \nhave been collected from official news sources representing \nthe top 24 Canadian newspapers in accordance with their \nknown circulation in 2016. We also included Huffington Post \nCanada  and two TV News sources with large online \nfollowings \u2014CBC News  and CTV News . Apart from the \nCBC , CTV and the Canadian edition of the Huffington Post , \nwe obtained data from 24 sources, for example, The Globe \nand Mail , The National Post , The Toronto Star , Le Journal \nde Montreal  (French), Le Journal de Quebec  (French), Le \nSoleil (French), The Vancouver Sun , The Toronto Sun , The \nCalgary Herald , The Winnipeg Free Press , The Ottawa \nCitizen , and The Montreal Gazette , to mention a few of the \nsources. In total, we recently collected 31,557 \u201creal news\u201d \nFacebook data items from these \u201ctrustworthy\u201d news sources, \ndating from July 2018 to the present. We also collected \n253,936 \u201creal news\u201d Twitter data items from these \n\u201ctrustw orthy\u201d news sources, dating from December 2013 \nthrough September 2019.  \nThis vast databank of recently acquired \u201creal news\u201d and \n\u201cfake news\u201d (and everything in between real and fake) has \nbeen assembled for use in conjunction with our ongoing qualitative ana lysis, as well as to provide a basis for our \nongoing quantitative analysis and machine -learning -based \nclassification.  In fact, data drawn from these new datasets \nwere used in our recent comparison tests involving Posit, \nTensorFlow, LibShortText and LibLine ar, as outlined above \nin our Discussion  section. The data collection and data \nanalysis processes are in progress and robust. We anticipate \ndeveloping a \u201cproof -of-concept\u201d model of our \u201ccritical \ncontent toolkit\u201d in the near future.  \nACKNOWLEDGMENTS  \nThis research project would not have been possible \nwithout funding from the Cyber Security Cooperation \nProgram, operated by the National Cyber Security \nDirectorate of Public Safety Canada. We would also like to \nthank our research assistants, Soobin Rim (Te nsorFlow) and \nAynsley Pescitelli  (NVivo).  \nREFERENCES  \n[1] B. Cartwright, G. R. S. Weir and R. Frank, \u201cFighting Disinformation \nWarfare with Artificial Intelligence: Identifying and Combatting \nDisinformation Attacks in Cloud -based Social Media Platforms,\u201d \nTenth International Conference on Cloud Computing, GRIDs, and \nVirtualization , pp. 73-77, May 2019.  URL: \nhttp://thinkmind.org/index.php?view=article&articleid=cloud_comput\ning_2019_5_30_28006  [Last accessed: 2019.07.28]  \n[2] D. Ebner and C. Freeze, \u201c AggregateIQ, Canadian data firm at centre \nof global controversy, was hired by clients big and small ,\u201d Globe and \nMail , April, 2018. URL: www.theglobeandmail.com/canada/article -\naggregateiq -canadian -data-firm-at-centre -of-global -controvery -was \n[Last accessed: 2019.04.8]  \n[3] R. Rathi, \u201c Effect of Cambridge Analytica\u2019s Facebook ads on the 2016 \nUS Presidential Election ,\u201d Towards Data Science , 2019. U RL: \nhttps://towardsdatascience.com/effect -of-cambridge -analyticas -\nfacebook -ads-on-the-2016 -us-presidential -election -dacb5462155d  \n[Last accessed: 2019:07.20]  \n[4] J. Russell, \u201c UK watchdog hands Facebook maximum \u00a3500K fine over \nCambridge Analytica data breach ,\u201d TechCrunch , 2018. URL: \nhttps://techcrunch.com/2018/10/25/uk -watchdog -hands -facebook -\n500k -fine/ [Last accessed: 2019.07.18]  \n[5] M. H. McGill and N. Scola, \u201c FTC approves $5B Facebook settlement \nthat Democrats label 'chump change ,'\u201d Politco , July 12, 2019 URL: \nhttps://www.politico.com/story/2019/07/12/facebook -ftc-fine-5-\nbillion -718953  [Last accessed: 2019.07.18]  \n[6] I. Lapowsky, \u201c House Probes Cambridge Analytica on Russia and \nWikileaks ,\u201d Wired , 2019. UR L: \nhttps://www.wired.com/story/congress -democrats -trump -inquiry -\ncambridge -analytica/  [Last accessed: 2019.07.20]  \n[7] Office of the Director of National Intelligence, \u201cAssessing Russian \nActivities and Intentions in Recent US Elections ,\u201d 2017. URL:  \nwww.dni.gov/files/documents/ICA_2017_01.pdf  [Last acce ssed: \n2019.0 7.28] \n[8] R. S. Mueller III, \u201cReport on the Investigation into Russian \nInterference in the 2016 Presidential Election, \u201d pp. 1 -448, 2019. \nURL: www.justsecurity.org/wp -content/uploads/2019/04/Muelller -\nReport -Redacted -Vol-II-Released -04.18.2019 -Word -Searchable. -\nReduced -Size.pdf [Last Accessed: 2019.0 7.28] \n[9] B. Cartwright, G. R. S. Weir, L. Nahar, K. Padda and R. Frank, \u201cThe \nWeaponization of Cloud -Based Social Media: Prospects for \nLegislation and Regulation,\u201d Tenth International Conference on \nCloud Computing, GRIDs, and Virtualization , pp. 7 -12, May 2019. \nURL:  \nhttp://thinkmind.org/index.php?view=article&articleid=cloud_comput\ning_2019_2_10_28021  [Last accessed:  2019.07.28 ] \n219International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n [10] M. T. Bastos and D. Mercea, \u201cThe Brexit botnet and user -generated \nhyperpartisan news ,\u201d Social Science Computer Review , \n0894439317734157 , 2017 . URL: https://journals -sagepub -\ncom.proxy.lib.sfu.ca/doi/pdf/10.1177/0894439317734157  [Last \nAccessed: 2019.07.2 8] \n[11] M. Field and M. Wright, \u201cRussian trolls sent thousands of pro -Leave \nmessages on day of Brexit referendum, Twitter data reveals: \nThousands of T witter posts attempted to influence the referendum and \nUS elections,\u201d The Telegraph , 2018 . URL : \nwww.telegraph.co.uk/technology/2018/10/17/russian -iranian -twitter -\ntrolls -sent-10-million -tweets -fake-news/ [Last accessed: 2019.04.8]  \n[12] G. Evolvi, \u201cHate in a Tweet: Exploring Internet -Based Islamophobic \nDiscourses ,\u201d Religions , 9(10), pp. 37 -51, 2018. URL: \nhttps://www.mdpi.com/2077 -1444/9/10/307  [Last accessed: \n2019.07.21]  \n[13] A. Badawy, E. Ferrara  and Lerman, K., \u201cAnalyzing the Digital Traces \nof Political Manipulat ion: The 2016 Russian Interference Twitter \nCampaign, \u201d arXiv , 2018 URL: https://arxiv.org/abs/1802.04291  [Last \naccessed: 2019.07.28 ]  \n[14] C. Shao, P. M.  Hui, L. Wang, X. Jiang, A. Flammini, F. Menczer  and \nand G. L. Ciampaglia, \u201cAnatomy of an online misinformati on \nnetwork ,\u201d PloS one , 13(4), e0196087 , 2018 . URL: \nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.019\n6087  [Last Accessed: 2019.07.2 8] \n[15] W. Y. Wang, \u201c\u2018 Liar, Liar Pants on Fire \u2019: A New Benchmark Dataset \nfor Fake News Detection ,\u201d arXiv preprint arXiv:1705.00648 , 2018. \nURL: https://arxiv.org/abs/1705.00648  [Last accessed:  2019. 07.15 ] \n[16] G. Weir, R. Frank, B. Cartwright and E. Dos Santos, \u201cPositing the \nproblem: enhancing classification of extremist web content through \ntextual analysis,\u201d Inter national Conference on Cybercrime and \nComputer Forensics (IEEE Xplore) , June 2016.  URL: \nhttps://ieeexplore -ieee-org.proxy.lib.sfu.ca/document/7740431 [Last \naccessed:  2019. 08.13 ] \n[17] G. Weir, K. Owoeye,  A. Oberacker and H. Alshahrani,  \u201cCloud -based \ntextual analysis as a basis for document classification,\u201d International \nConference on High Performance Computing & Simulation (HPCS) , \npp. 672 -676, July 2018. URL: https://ieeexplore -ieee-\norg.proxy.lib.sfu.ca/document/8514415  [Last accessed: 20 19.08.13]  \n[18] K. Owoeye and G. R. S. Weir, \u201cClassification of radical Web text \nusing a composite -based method, IEEE International Conference on \nComputational Science and Computational Intelligence , December \n2018.  URL: \nhttps://pure.strath.ac.uk/ws/portalfiles/p ortal/86519706/Owoeye_Wei\nr_IEEE_2018_Classification_of_radical_web_text_using_a_composit\ne_based.pdf  [Last accessed: 2019.08.13]  \n[19] H. Berghel, \u201cLies, damn lies, and fake news,\u201d Compu ter, 50(2), pp. \n80-85, 2017.  URL: \nhttps://www.computer.org/csdl/magazine/co/2017/02/mco201702008\n0/13rRUzp02jw  [Last accessed: 2019.07.29]  \n[20] N. W. Jankowski, \u201cResearching fake news: A selective examination \nof empirical studies,\u201d  Javnost -The Public , 25(1 -2), pp. 248 -255, \n2018.  URL: https://www -tandfonline -\ncom.proxy.lib.sfu.ca/doi/full/10.1080/13183222.2018.1418964  [Last \naccessed: 2019.07.29]  \n[21] E. C. Tandoc Jr, Z. W. Lim and R. Ling, \u201cDefining \u2018fake news\u2019: A \ntypology of scholarly definitions, \u201d Digital Journalism , 6(2), pp. 137 -\n153, 2018.  URL: \nhttps://www.researchgate.net/publication/319383049_Defining_Fake\n_News_A_typology_of_scholarly_definitions  [Last accessed: \n2019.07.29]  \n[22] D. M.  Lazer, M. A.  Baum, Y. Benkler, A. J.  Berinsky,  K. M.  \nGreenhill, F. Menczer  and M. Schudson , \u201cThe science of fake news ,\u201d \nScience , 359(6380), pp. 1094 -1096 , 2018.  URL: https://science -\nsciencemag -rg.proxy.lib.sfu.ca/content/359/6380/1094  [Last \nAccessed: 2019.07.21]  \n[23] M. de Cock Buning, L. Ginsbourg and S. Alexandra, Online \nDisinformation ahead of the European Parliament elections: toward \nsocietal resilience , European University Institute, School of Transnational Governance,  April 2019 URL: \nhttps://cadmus.eui.eu/bitstream/handle/1814/62426/STG_PB_2019_0\n3_EN.pdf?sequence=1&isAllowed=y  [Last accessed: 2019.07.15]  \n[24] S. Desai, H. Mooney and J.A. Oehrli, \"Fake News,\" Lies and \nPropaganda: How to Sort Fact from Fiction , 2018. URL: \nhttps://guides.lib.umich.edu/fakenews  [Last accessed: 2019.07.15]  \n[25] N. Kshetri  and J. Voas , \u201cThe Economics of \u2018Fake News ,\u2019\u201d IEEE \nComputer Societ y, pp. 8-12, (2017).  URL: https://ieeexplore -ieee-\norg.proxy.lib.sfu.ca/stamp/stamp.jsp?tp=&arnumber=8123490&tag=1  \n[Last accessed: 2019.07.15]  \n[26] H. Allcott and M. Gentzkow, \u201cSocial Media and Fake News in the \n2016 Election,\u201d Journal of Economic Perspectives , 31(2), pp. 211 -\n236, 2017. URL: \nhttps://web.stanford.edu/~gentzkow/research/fakenews.pdf  [Last \nAccessed: 2019.07.28]  \n[27] W. L. Bennett  and S. Livingston, \u201cThe disinformation order: \nDisruptive communication and the decline of democratic \ninstitutions ,\u201d European Journal of Communication , 33(2), pp. 122-\n139, 2018.  URL: https://journals -sagepub -\ncom.proxy.lib.sfu.ca/doi/pdf/10.1177/0267323118760317  [Last \naccessed:  2019.07.28 ] \n[28] United States v. Internet Research Agency LLC , Case 1:18 -cr-00032 -\nDLF, The United States District Court for the District Of Columbia , \nFebruary 26, 2018. URL: www.justice.gov/file/1035477/download  \n[Last accessed: 2019.04.8]  \n[29] J. J. Green, \u201cTale of a Troll: Inside the \u2018Internet Research Agency\u2019 in \nRussia,\u201d  WTOP , 2018. URL: https://wtop.com/j -j-green -\nnational/2018/09/tale -of-a-troll-inside -the-internet -research -agency -\nin-russia/  [Last accessed: 2019.07.15]  \n[30] L. Reston, \u201cHow Russia Weaponizes Fake News:  The Kremlin's \ninfluence campaign goes far beyond Trump's victory. Their latest \nunsuspecting targets: American conservatives, \u201d The New Republic,  \n2017. URL: https://newrepublic.com/article/142344/russia -\nweaponized -fake-news -sow-chaos  [Last accessed: 2019.07.20]  \n[31] K. Wagner, \u201cFacebook and Twitter worked just as advertised for \nRussia\u2019s troll army:  Social platforms are an effective tool for \nmarketers \u2014 and nation states that want to disrupt an election ,\u201d \nRecode Daily , 2018. URL: \nhttps://www.vox.com/2018/2/17/17023292/facebook -twitter -russia -\ndonald -trump -us-elect ion-explained  [Last accessed: 2019.07.20]  \n[32] A. Marwick and R. Lewis, Media Manipulation and Disinformation \nOnline , New York: Data & Society Research Institute , pp. 1 -106, \n2017 . URL: https://datasociety.net/output/media -manipulation -and-\ndisinfo -online/  [Last accessed: 2019.07.2 9] \n[33] K. Shu, A. Silva, S. H. Wang, J. Tang and H. Liu, \u201c Fake News \nDetection on Social Media: A Data Mining Perspective ,\u201d pp. 1 -15, \n2017. URL: https://arxiv.org/abs /1708.01967  [Last accessed: \n2019.07.2 9] \n[34] S. Zanettou, T. Caulfied, E. de Cristofaro, M. Sirivianos, G. \nStringhini and J. Blackburn, \u201c Disinformation Warfare: Understanding \nState -Sponsored Trolls on Twitter and Their Influence on the Web ,\u201d \npp. 1 -11, 2019. URL : https://arxiv.org/pdf/1801.09288.pdf  [Last \naccessed: 2019.07.2 9] \n[35] M. Papenfuss, \u201c1,000 Paid Russian Trolls Spread Fake News On \nHillary Clinton, Senate Intelligence Heads Told,\u201d  Huffington Post , \nMarch  2017.  URL: https://www.huffingtonpost.ca/entry/russian -\ntrolls -fake-news_n_58dde6bae4b08194e3b8d5c4  [Last accessed: \n2019.07.2 9] \n[36] The Computational Propaganda Project, \u201cResource for Understanding \nPolitical Bots,\u201d 2016. URL: \nhttps://comprop.oii.ox.ac.uk/research/public -scholarship/resource -for-\nunderstanding -political -bots/  [Last accessed: 2019.07.2 9] \n[37] P. N. Howard, S, Woolley and R. Calo , \u201cAlgorithms, bots, and \npolitical communication in the US 2016 election: The challenge of \nautomated political communication for election law and \nadministration ,\u201d Journal of Information Technology & Politics , 15(2), \n81-93, 2018. URL: https://www -tandfonline -\n220International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n com.proxy.lib.sfu.ca/doi/full/10.1080/19331681.2018.1448735  [Last \naccessed: 2019.07.18]  \n[38] G. Resnick, \u201cHow Pro -Trump Twitter Bots Spread Fake News,\u201d  The \nDaily Beast , July 2017. URL: https://www.thedailybeast.com/how -\npro-trump -twitter -bots-spread -fake-news  [Last accessed: 2019.07.2 9] \n[39] G. Krieg, \u201c It's official: Clinton swamps Trump in popular vote ,\u201d CNN \nPolitics Data , December 2016, URL : \nhttps://www.cnn.com/2016/12/21/politics/donald -trump -hillary -\nclinton -popular -vote-final-count/index.html  [Last accessed: \n2019.07.2 9] \n[40] L. Stark, \u201cAlorithmic psychometrics and the scalable subject,\u201d Social \nStudies of Science , 48(2), pp. 204 -231, 2018 URL: https://journals -\nsagepub -com.proxy.lib.sfu.ca/doi/pdf/10.1177/0306312718772094  \n[Last accessed:  2019.08.03]   \n[41] F. Morstatter, L. Wu, T. H. Nazer, K. N. Carley and H. Liu, \u201cA new \napproach to bot detection: Striking the balance between precision and \nrecall,\u201d  IEEE/ACM Conference on Advances in Social Networks \nAnalysis and Mining , pp. 553 -540, August 2016. URL: \nhttps://ieeexplore -ieee-org.proxy.lib.sfu.ca/document/7752287  [Last \naccessed: 2019.08.03]  \n[42] E. Shearer and K. E. Matsa, \u201cNews Use Across Social Me dia \nPlatforms 2018: Most Americans continue to get news on social \nmedia, even though many have concerns about its accuracy,\u201d Pew \nResearch Center, 2018. URL: www.journalism.org/2018/09/10/news -\nuse-across -social -media -platforms -2018/ [Last accessed: 2019.0 7.30] \n[43] J. Gottfried and E. Shearer, \u201c News Use Across Social Media \nPlatf orms 2016 ,\u201d Pew Research Center, URL: \nhttps://www.journalism.org/2016/05/26/news -use-across -social -\nmedia -platforms -2016/  [Last accessed: 2019.07. 30] \n[44] N. Kshetri  and J. Voas , \u201cThe Economics of \u2018Fake News ,\u2019\u201d IEEE \nComputer Society , pp. 8-12, (2017).  URL: https://ieeexplore -ieee-\norg.proxy.lib.sfu.ca/stamp/stamp.jsp?tp=&arnumber=8123490&tag=1  \n[Last accessed: 2019.07.15]  \n[45] S. Wineburg, S. McGrew, J. Breakstone  and T. Ortega,  \u201cEvaluating \nInformation: The Cornerstone of Civic Online Reasoning,\u201d Stanford \nDigital Repository, 2016. URL: \nhttps://stacks.stanford.edu/file/druid:fv751yt5934/SHEG%20Evaluati\nng%20Information%20Online.pdf [Last accessed: 2019.07.15]  \n[46] European Commission, A Europe that protects: EU reports on \nprogress in fighting disinformation ahead of European Council,  June \n2019 . URL: https://ec.europa.eu/commission/commissioners/2014 -\n2019/ansip/announcements/europe -protects -eu-reports -progress -\nfighting -disinformation -ahead -european -council_en  [Last accessed: \n2019.06.15]  \n[47] A. Al -Rawi and Y. Jiwani, \u201cTrolls Stoke Fear: Russian disruption a \nconcern in Fall vote,\u201d Vancouver Sun , p. G2, August 2016.  \n[48] C. Falk, \u201c Detecting Twitter Trolls Using Natural Language Processing \nTechniques Trained on Message Bodies ,\u201d July 2018. URL: \nhttp://www.infinite -machines.com/detecting -twitter -trolls.pdf  [Last \naccessed: [2019. 07.15 ] \n[49] I. Smole\u0148ov\u00e1,  \u201cThe pro -Russian disinformation campaign in the Czech \nRepublic and Slovakia ,\u201d Prague: Prague Sec urity Studies Institute , \n2015. URL: http://www.pssi.cz/download/docs/253_is -pro-russian -\ncampaign.pdf  [Last accessed: 2019. 07.21] \n[50] I. Khaldarova  and M. Pantti,  \u201cFake news: The narrative battle over \nthe Ukrainian conflict , \u201cJournalism Practice , 10(7), pp. 891-901, \n2016 . URL: https://www -tandfonline -\ncom.proxy.lib.sfu.ca/doi/full/10.1080/17512786.2016.1163237  [Last \naccessed: 2019. 07.21] \n[51] U. A. Mejias  and N. E.  Vokuev , \u201cDisinformation and the media: the \ncase of Russia and Ukraine. Media, \u201d Culture & Society , 39( 7), pp. \n1027 -1042 , 2017. URL: https://journals -sagepub -\ncom.proxy.lib.sfu.ca/doi/full/10.1177/0163443716686672  [Last \naccessed: 2019. 07.21] \n[52] S. Bradshaw and P. N. Howard, \u201cThe Global Disinformation Order: \n2019 Global Inventory of Organized Social Media Manipu lation.\u201d \nURL: https://comprop.oii.ox.ac.uk/wp -content/uploads/sites/93/2019/09/CyberTroop -Report19.pdf  [Last \nAccessed: 2019.11.16]  \n[53] D. Alba and A. Satariano, \u201cAt Least 70 Countries Have Had \nDisinformation Campaigns, Study Finds,\u201d New York Times , September \n2019. URL: \nhttps://www.nytimes.com/2019/09/26/technology/government -\ndisinformation -cyber -troops.html  [Last Accessed: 2019.11.16]  \n[54] D. L. Linvill and P. L. Warren, \u201cTroll factories: The Internet \nResearch Agency and state -sponsored agenda -building,\u201d  Resource \nCentre on Media,  2018.  URL: \nhttps://www.google.com/search?q=Troll+factories%3A+The+Internet\n+Research+Agency+and+state -sponsored+agenda -\nbuilding&oq=Troll+factories%3A+The+Internet+Research+Agency+\nand+state -sponsored+agenda -\nbuilding&aqs=chrome..69i57j69i60l3.354j0j7&sourceid=chrome&ie\n=UTF -8 [Last accessed: 2019. 07.21] \n[55] H. F. Yu, C. H. Ho, Y. C. Juan and C. J. Lin, \u201cLibShortT ext: A \nLibrary for Short -text Classification and Analysis\u201d, Department of \nComputer Science, National Taiwan University, 2013. URL: \nhttps://www.csie.ntu.edu.tw/~cjlin/papers/libshorttext.pdf  [Last \naccessed: 2019.08.4]  \n[56] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis,J. Dean, M. Devin, \nS. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. \nMonga, S. Moore, D. G. Murray, B. Steiner, P. Tucker,V. Vasudevan, \nP. Warden, M. Wicke, Y. Yu and X. Zheng, \u201cTensorFlow: A system \nfor large -scale machine learning,\u201d 12th USENIX Symposium on \nOperating Systems Design and Implementation , pp. 265 -283, \nNovember 2016.  URL: \nhttps://www.usenix.org/system/files/conference/osdi16/osdi16 -\nabadi.pdf  [Last accessed: 2019.08.4]  \n[57] G. R. S. Weir, \u201cThe posit text profiling toolset,\u201d 12th Conference of \nPan-Pacific Association of Applied Linguisitics , pp. 106 -109, 2007. \nURL: \nhttps://www.researchgate.net/publication/228740404_The_Posit_Text\n_Profiling_Toolset  [Last accessed: 2019.08.4]  \n[58] G. R. S. Weir, \u201cCorpus profiling with the Posit tools,\u201d Proceedings of \nthe 5th Corpus Linguistics Conference, July 2009.  URL: \nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.9606&\nrep=rep1&type=pdf  [Last accessed: 2019.08.4]  \n[59] R. Zellers, A. Holtzm an, H. Rashkin, Y. Bisk, A. Farhadi, F. Roesner  \nand Y. C hoi, \u201cDefending Against Neural Fake News ,\u201d arXiv preprint \narXiv:1905.12616 , 2019 . URL: https://arxiv.org/abs/1905.12616  \n[Last Accessed: 2019.11.17].  \n[60] Y. Gorodnichenko, T. Pham  and O.  Talavera , Social media, sentiment \nand public opinions: Evidence from# Brexit and# USElection , No. \nw24631 , National Bureau of Economic Research , 2018 . URL: \nhttps://www.nber.org/papers/w24631.pdf  [Last Accessed: \n2019.11.19].  \n[61] J. Mei and R. Frank, \u201cSentiment crawling: Extremist content \ncollection through a sentiment analysis guided webcrawler, \u201d 2015 \nIEEE/ACM International Conference on Advances in Social Networks \nAnalysis and Mining , pp. 1024 -1027, August 2015. URL: \nesearchgate.net/publication/301444687_Sentiment_Crawli ng_Extrem\nist_Content_Collection_through_a_Sentiment_Analysis_Guided_We\nb-Crawler  [Last accessed: 2019.08.4]  \n[62] A. T. Zulkarnine, R. Frank, B. Monk, J. Mitchell and G. Davies, \n\u201cSurfacing collaborated networks in dark web to find illicit and \ncriminal content,\u201d 2016 IEEE Confernce on Intelligence and Security \nInformatics (ISI),  pp. 109 -114, September  2016 . URL: \nhttps://ieeexplore -ieee-org.proxy.lib.sfu.ca/document/7745452  [Last \naccessed: 2019.08.4]  \n[63] T. C. Kietzmann, P. McClure and N. Kriegeskorte, \u201cDeep neural \nnetworks in computational neuroscience,\u201d bioRxiv , pp. 133504 -\n133527 , 2018 . URL: \nhttps://www.biorxiv.org/content/10.1101/133504v2  [Last accessed: \n2019.08.4]  \n[64] M. Thelwall, K. Buckley, G. Paltoglou,  D. Cai and A. Kappas, \n\u201cSentiment strength detection in short informal text,\u201d Journal of the \n221International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org\n American Society for Information Science and Technology , 61(12), \n2544 \u20132558, 2010.  URL: \nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.278.3863&\nrep=rep1&t ype=pdf  [Last accessed: 2019.08.4]  \n[65] M. Hall, E. Frank, H. Geoffrey, B. Pfahringer, P. Reutemann and I. \nWitten, \u201cThe Weka data mining software: an update, \u201d SIGKDD \nExplorations, vol. 11, pp. 10 -18, 2009 . URL: \nhttps://www.kdd.org/exploration_files/p2V D:\\BTSync \\Ricsi \\Academi\nc Work \\2019 \\20190508 - Venice Cloud Conference 11n1.pdf  [Last \naccessed: 2019.08.4]  \n[66] L. Breiman, \u201cRandom Forests, \u201d Machine Learning, vol. 45, pp. 5 -32, \n2001 . URL: \nhttps://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  [Last \naccessed: 2019.08.4]  \n[67] A. Liaw and M. Wiener, \u201cClassification and regression by \nrandomForest, \u201d R News , vol. 2, pp. 18 -22, 2002. URL: https://www.r -\nproject.org/doc/Rnews/Rnews_2002 -3.pdf  [Last accessed: 2019.08.4]  \n[68] H. F. Yu, C. H. Ho, Y. C. Juan and C. J. Lin, \u201cLibShortText: A \nLibrary for Short -text Classification and Analysis\u201d, Department of \nComputer Science, National Taiwan University, 2013. URL: \nhttps://www.csie.ntu.edu.tw/~cjlin/papers/libsho rttext.pdf  [Last \naccessed: 2019.08.4]  \n[69] Y. N. Dauphin, R. Pascanu, C. Gulcehre, K. Cho, S. Ganguli and Y. \nBengio, \u201cIdentifying and attacking the saddle point problem in high -\ndimensional non -convex optimization,\u201d Advances in neural \ninformation processing syst ems, pp. 2933 -2941, 2014.  URL: \nhttps://papers.nips.cc/paper/5486 -identifying -and-attacking -the-\nsaddle -point -problem -in-high-dimensional -non-convex -optimization  \n[Last accessed: 2019.08.4]  \n[70] D. R. Ruck, S. K. Rogers, M. Kabrisky, M. E. Oxley and B. W. Suter, \n\u201cThe Multilayer Perceptron as an Approximation to a Bayes Optimal \nDiscriminant Function,\u201d IEEE Transactions on Neural Networks , \n1(4), pp. 296 -298, 1990.  URL: https://ieeexplore -ieee-\norg.proxy.lib.sfu.ca/document/80266  [Last accessed: 2019.08.6]  \n[71] W. S. Sarle, \u201cNeural Networks and Statistical Models,\u201d Nineteenth \nAnnual SAS Users Group International Conference , April 1994. \nURL: https://people.orie.cornell.edu/davidr/or474/nn_sas.pdf  [Last \naccessed: 2019.08.6]  \n[72] S. Chadha, \u201cT ext Analytics on Russian Troll Tweets -Part 1,\u201d n.d., \nURL: https://www.kaggle.com/chadalee/text -analytics -on-russian -\ntroll-tweets -part-1 [Last accessed: 2019.08.7]  \n[73] CNN , \u201cBig Tech braces for first presidential debates, a target of \nRussian trolls in 2016 ,\u201d Ju ne 2019. URL: \nhttps://m.cnn.com/en/article/h_8d2922458b2b4c80698925b2be1ab87\n9 [Last accessed: 2019.08.7]  \n[74] M. Choi, \u201cKe ith Ellison reeling after abuse allegations: The No. 2 a t \nthe Democratic National Committee is running behind in his bid for \nMinnesota atto rney general ,\u201d Politico , October 2018. URL: \nhttps://www.politico.com/story/2018/10/27/keith -ellison -abuse -\nallegations -minnesota -ag-2018 -943086  [Last accessed: 2019.08.10]  \n[75] E. Nakashima, \u201cU.S. Cyber Command operation disrupted Internet \naccess of Russian troll factory on day of 2018 midterms,\u201d Washington \nPost, February 2019 . URL: \nhttps://www.washingtonpost.com/world/national -security/us -cyber -\ncommand -operation -disrupted -internet -access -of-russian -troll-\nfactory -on-day-of-2018 -midterms/2019/02/26/1827fc9e -36d6 -11e9 -\naf5b-b51b7ff322e9_story.html?noredirect=on  [Last accessed: \n2019.08.10]  [76] T. Starks, L. Cerulus and M. Scott, \u201c Russia's manipulation of Twitter \nwas far vaster than believed, \u201d Politico, June 2019. URL: \nhttps://www.politico.com/story/2019/06/05/study -russia -\ncybersecurity -twitter -1353543  [Last accessed: 2019.08.10]  \n[77] M. Lander, \u201cTrump Says He Discussed the \u2018Russian Hoax\u2019 in a \nPhone Call With Putin,\u201d  The New York Times , May 2019. URL: \nhttps://www.nytimes.com/2019/05/03/us/politics/trump -putin -phone -\ncall.html   \n[78] Baltimore Sun , \u201cEven if Trump is right about collusion, Russia story \nis big (not fake) news ,\u201d October 2017. URL: \nhttps://www.baltimoresun.com/opinion/editorial/bs -ed-1101 -trump -\nrussia -20171031 -story.html  [Last accessed: 2019.08.10]  \n[79] R. Dicker, \u201cSecret Service Agent Says She Wouldn't Take A Bullet \nFor Trump: Agency says it is taking quick action , \u201c Huffington Post , \nJanuary 2017 . URL: https://www.huffingtonpost.ca/entr y/secret -\nservice -agent -says-she-wouldnt -take-a-bullet -for-\ntrump_n_58887d4be4b0441a8f71e671  [Last accessed: 2019.08.10]  \n[80] M. Y.H. Lee, \u201c \u2018Rapists?\u2019 Criminals? Checking Trump\u2019s facts,\u201d The \nPhiladelphia Inquirer , July 2015. URL: \nhttps://www.inquirer.com/philly/news/politics/20150709__Rapists__\n_Criminals__Checking_Trump_s_facts.html  [Last accessed: \n2019.08.11]  \n[81] J. Hing, \u201c This Is the Beginning of Donald Trump\u2019s Muslim Ban: \nFriday\u2019s executive order extended to seven countries \u2014but that  list \ncould grow ,\u201d The Nation , January 2017 . URL: \nhttps://www.thenation.com/article/this -is-the-beginning -of-donald -\ntrumps -muslim -ban/ [Last accessed: 2019.08.11]  \n[82] L. Gambino, \u201cTrump pans immigration proposal as bringing people \nfrom 'shithole countries',\u201d The Guardian , January 2018. URL: \nhttps://www.theguardian.com/us -news/2018/jan/11/trump -pans-\nimmigration -proposal -as-bringing -people -from -shithole -countries  \n[Last accessed: 2019.08.11]  \n[83] M. Bouazizi and T . Ohtsuki , \u201cMulti -Class Sentiment Analysis on \nTwitter: Classification Performance and Challenges ,\u201d Big Data and \nMining Analytics , vol. 2, pp. 181 -194, 2019.  URL: \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8681053  \n[Last Accessed: 2019.11.24]  \n[84] C. H. Tsai, C. Y. Lin, and C. J. Lin, \u201cIncremen tal and decremental \ntraining for linear classification \u201d Proceedings of the 20th ACM \nSIGKDD international conference on Knowledge discovery and data \nmining , pp. 343 -352, 2014. URL: \nhttps://www.csie.ntu.edu.tw/~cjlin/papers/ws/inc -dec.pdf  [Last \nAccessed: 201 9.11.24]  \n[85] H. Ahmed , I. Traore and S.  Saad , \u201cDetecting opinion spams and fake \nnews using text classification ,\u201d Journal of Security and Privacy , vol. \n1, pp. 1 -15. URL: \nhttps://www.uvic.ca/engineering/ece/isot/assets/docs/SPY_Detecting\n%20opinion%20spams%20and%20fake%20news%20using%20text%\n20classification.pdf  [Last Accessed: 2019.11.24]  \n[86] F. K. A.  Salem, R. Al Feel, S. Elbassuoni, M. Jaber  and M. Farah , \n\u201cFA-KES: A Fake News Dataset around the Syrian War ,\u201d \nProceedings of the International AAAI Conference on Web and Social \nMedia , vol. 13, pp. 573 -582, 2019 . URL: \nhttps://aaai.org/ojs/index.php/ICWSM/article/view/3254/3122  [Last \nAccessed: 2019.11.24]  \n \n \n \n222International Journal on Advances in Security , vol 12no3&4, year 20 19,http://www.iariajournals.org/ security/\n2019, \u00a9 Copyright by authors, Published under agreement with IARIA -www.iaria.org", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Deploying artificial intelligence to combat disinformation warfare", "author": ["B Cartwright", "GRS Weir", "R Frank", "K Padda"], "pub_year": "2019", "venue": "public opinion", "abstract": "Disinformation attacks that make use of Cloud-based social media platforms, and in particular,  the attacks orchestrated by the Russian \u201cInternet Research Agency,\u201d before, during and"}, "filled": false, "gsrank": 319, "pub_url": "https://personales.upv.es/thinkmind/dl/journals/sec/sec_v12_n34_2019/sec_v12_n34_2019_5.pdf", "author_id": ["", "SBDcS-sAAAAJ", "1PeY2UUAAAAJ", "c1EEwQQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:PeZ8-LgdF6gJ:scholar.google.com/&output=cite&scirp=318&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D310%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PeZ8-LgdF6gJ&ei=PLWsaNOhFqzWieoPic2ZoAU&json=", "num_citations": 2, "citedby_url": "/scholar?cites=12112182403116361277&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:PeZ8-LgdF6gJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://personales.upv.es/thinkmind/dl/journals/sec/sec_v12_n34_2019/sec_v12_n34_2019_5.pdf"}}]