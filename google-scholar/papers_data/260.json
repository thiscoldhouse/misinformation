[{"title": "PROVENANCE: An intermediary-free solution for digital content verification", "year": "2021", "pdf_data": "PROVENANCE: An Intermediary-Free Solution for Digital\nContent Verification\nBilal Yousuf1,2, M. Atif Qureshi1,2, Brendan Spillane1, Gary Munnelly1, Oisin Carroll1,\nMatthew Runswick1, Kirsty Park3, Eileen Culloty3, Owen Conlan1and Jane Suiter3\n1ADAPT Centre, Trinity College Dublin\n2ADAPT Centre, Technological University Dublin\n3Institute for Future Media, Democracy and Society, Dublin City University\nAbstract\nThe threat posed by misinformation and disinformation is one of the defining challenges of the 21stcentury. Provenance\nis designed to help combat this threat by warning users when the content they are looking at may be misinformation or\ndisinformation. It is also designed to improve media literacy among its users and ultimately reduce susceptibility to the threat\namong vulnerable groups within society. The Provenance browser plugin checks the content that users see on the Internet\nand social media and provides warnings in their browser or social media feed. Unlike similar plugins, which require human\nexperts to provide evaluations and can only provide simple binary warnings, Provenance\u2019s state of the art technology does\nnot require human input and it analyses seven aspects of the content users see and provides warnings where necessary.\nKeywords\nMisinformation, Disinformation, Fake News, Social Media, Plugin, Browser Extension\n1. Introduction\nProvenance is an intermediary-free solution for digital\ncontent verification to combat misinformation and disin-\nformation on the Internet and social media. As per [ 1], it\nis designed to aid users by providing them with warning\nnotifications in their browser or social media feed when\nviewing content that may be dangerous or problematic.\nThe detailed warning notifications inform users which of\nthe seven criteria Provenance\u2019s state of the art technol-\nogy has detected an issue with and why. It significantly\nimproves upon all known similar solutions in two ways.\nFirstly, existing solutions do not analyse the content the\nuser is viewing and are thus limited to providing users\nwith warnings based on the news agencies historical pub-\nlication record and behaviour. Secondly, existing browser\nFourth Workshop On Knowledge-Driven Analytics And Systems\nImpacting Human Quality Of Life (KDAH-CIKM-2021), November\n01\u201305, 2021, Gold Coast, Queensland, Australia\n/envelope-openbilal.yousuf@adaptcentre.ie (B. Yousuf);\nmuhammad.qureshi@adaptcentre.ie (M. A. Qureshi);\nbrendan.spillane@adaptcentre.ie (B. Spillane);\ngary.munnelly@adaptcentre.ie (G. Munnelly);\noisin.carroll@adaptcentre.ie (O. Carroll);\nmatthew.runswick@adaptcentre.ie (M. Runswick);\nkirsty.park@dcu.ie (K. Park); eileen.culloty@dcu.ie (E. Culloty);\nowen.conlan@scss.tcd.ie (O. Conlan); jane.suiter@dcu.ie (J. Suiter)\n/orcid0000-0001-6024-9084 (B. Yousuf); 0000-0003-4413-4476\n(M. A. Qureshi); 0000-0001-5893-1340 (B. Spillane);\n0000-0002-7757-6142 (G. Munnelly); 0000-0001-9398-9388\n(O. Carroll); 0000-0002-0848-931X (M. Runswick);\n0000-0001-7960-8462 (E. Culloty); 0000-0002-9054-9747 (O. Conlan);\n0000-0002-2747-8069 (J. Suiter)\n\u00a92021 Copyright for this paper by its authors. Use permitted under Creative\nCommons License Attribution 4.0 International (CC BY 4.0).\nCEUR\nWorkshop\nProceedingshttp://ceur-ws.org\nISSN 1613-0073\nCEUR Workshop Proceedings (CEUR-WS.org)plugins only provide a single broad-spectrum warning\nabout the content users are viewing whereas Provenance\nis capable of evaluating content under seven criteria and\nproviding individual warnings for each. Provenance\u2019s\nwarning notifications are also educational and designed\nto inspire users to be more cautious and critical of the\ninformation they consume. Thus, it will improve media\nliteracy among users and make them less susceptible to\nthe influence of misinformation and disinformation by\nmaking them more critical and reflective of the content\nthey consume.\nThere are significant research challenges in the design\nand development of Provenance. The main challenges\ninclude the huge volume of news and other content pub-\nlished each day, the combination of multimedia formats\nin each article or story, the high churn-rate and short\nshelf-life of news, and the fact that news content is often\nrepublished from wire services or from other publishers.\nThese are compounded by the fact that misinformation\nand disinformation are often designed to masquerade as\nreal news. Many disinformation sources share character-\nistics with the Lernaean Hydra of Greek mythology and\nre-post problematic content through multiple easy to set\nup websites or social media groups and reappear under\ndifferent guises when they are identified and shut down.\nThere are also a range of individual challenges within\ncomponents of the Provenance platform. These include\nderiving a system to assign accurate writing quality\nscores for each piece of textual content, detecting when\nnew facts introduced in a news article are indicative of\ndisinformation or an evolution in an unfolding story, de-\ntecting image and video manipulations, or developingarXiv:2111.08791v1  [cs.CY]  16 Nov 2021\na system that can differentiate between anger and fear\nin disinformation and anger and fear in opinion news\narticles. There is also some difficulty in differentiating\nbetween news articles from alternative and independent\nagencies and news articles from disinformation sources\ndue to often lower quality writing, more emotive content,\nand the reuse of images and videos.\nThis paper provides an update on the ongoing progress\nof developing Provenance. The remainder of this paper\nis organised as follows. Section 2 Motivation and Back-\nground delves into the impetus for this project and sit-\nuates it within other recent EU disinformation projects.\nSection 3 Related Work provides a detailed overview of\nsimilar browser plugins and describes how Provenance\nadvances the state of the art. Section 4 Architecture\nOverview contains system architecture diagrams and de-\nscriptions of each component in the Provenance platform.\nSection 5 Provenance in Action provides a detailed expla-\nnation of how the Provenance browser plugin provides\nwarnings to the user. Section 6 Use Cases presents two\nuse cases for the Provenance plugin to show in what\nscenarios we envision it being used. Section 7 Evalua-\ntionbriefly describes plans to evaluate the tool. Finally,\nsection 8 Conclusions completes the paper with closing\nremarks.\n2. Motivation and Background\nThe proliferation of misinformation and disinformation\non social media has been described as a strategic threat\nto democracy and society in the European Union (EU)\n[2,3]. A recent EU study on the issue found that the com-\nmon narratives of society \"are being splintered by filter\nbubbles, and further ruined by micro-targeting.\" [4]. The\nreport points out that like a virus, misinformation and\ndisinformation spread throughout society through social\nmedia and other platforms in open and closed groups to\nthe detriment of democratic systems. This occurs when\n\"Susceptible users become weaponized as instruments for\ndisseminating disinformation and propaganda\" [4].\nThe Presidents of the European Council, Commission\nand Parliament have all made increasingly public calls for\nconcerted efforts to do more to combat the scourge of fake\nnews to protect democracy. The President of the Euro-\npean Parliament has been the most forthright in this with\na recent announcement that: \"We must nurture our democ-\nracy & defend our institutions against the corrosive power\nof hate speech, disinformation, fake news & incitement to\nviolence.\" [5]. As a result, the EU have funded a range of\nFP7, H2020 and other projects to combat misinformation\nand disinformation including WeVerify [ 6,7], SocialTruth\n[8], PHEME [ 9,10], EUNOMIA [ 11] Fandango [ 12,13]\nand the European Digital Media Observatory (EDMO)\n[14]. Many other international organisations have alsoidentified misinformation and disinformation as a threat\nand have increased efforts to combat it. These include the\nUnited Nations through its Verified platform [ 15] and the\nWorld Health Organisation [ 16]. More can be read about\nthese initiatives in the Poynter Institute\u2019s guide to na-\ntional and international efforts to combat misinformation\nand disinformation around the world [17].\nProvenance is a H2020 project1, however it differs from\nmany of the above as it is a user orientated intermediary-\nfree solution to help consumers identify misinformation\nand disinformation as they browse the Internet and social\nmedia. It is also designed to improve media literacy skills\nby equipping consumers with the tools, knowledge and\nknow-how to face this challenge now and into the future.\n3. Related Work\nThis review of related work will focus on comparable\nbrowser plugins designed to provide users with warning\nnotifications about disinformation or other problematic\ncontent and which are currently active or maintained.\nThe purpose of this review is to establish how Provenance\nadvances the state of the art.\nNewsGuard [18] provides \u2018nutrition\u2019 labels for news\nwebsites based on nine journalistic criteria. What differ-\nentiates it from many of the other fake news and bias\ndetection browser plugins is that it does not use auto-\nmated algorithms to assess news websites but rather re-\nlies on a team of journalists to conduct reviews. It comes\nas standard with Microsoft Edge, but a subscription is\nneeded for other Internet browsers. Its notification icons\nappear as a browser extension in the upper right corner\nand within third party search engines and social media\nplatforms. Clicking on its browser icon opens a nutrition\nlabel pane where users can quickly see whether the news\nwebsite passes or fails any of the nine criteria. A link\nis also available for users to see a more detailed report.\nVisually, NewsGuard employs simple but effective white\n\u2713on a green shield and red xiconography to denote\nwhen a website has passed or failed. NewsGuard\u2019s trans-\nparent methodology has resulted in their datasets being\nused for research [ 19]. While expert led analysis has\nits merits, it also has issues with scalability, personal bi-\nases, and response times. Aker also maintains that much\nof the credibility and transparency scoring provided by\nNewsGuard could be automated [20].\nD\u00e9codex [21] created by Le Monde originally started\nas an online search facility for users to check URLs\nagainst a list of known websites which spread misin-\nformation and disinformation. They have since released\na Facebook bot for users to directly chat to and a browser\nplugin that provides red, orange or blue notifications to\ndenote whether a website regularly disseminates false\n1https://cordis.europa.eu/project/id/825227\ninformation, whose reliability is doubtful, or if they are\na parody website. When installed, the D\u00e9codex icon be-\ncomes active when the website being viewed is listed in\ntheir database. It also produces a colour-coded popup\nwith one of three standard warnings. Users cannot ac-\ncess detailed information about warnings, nor does it\nappear to be integrated with well-known search engines,\nsocial media platforms or discussion boards. D\u00e9codex\u2019s\nallow/deny list approach means that scalability is difficult\nand the warnings it provides are based on the historical\npublication record of the website, not the content cur-\nrently being viewed. Transparency is also limited. While\nstill available, its development appears to be in stasis.\nMedia Bias Fact Check (MBFC)2[22] is an extensive\nmedia bias resource curated by a small team of journal-\nists and lay researchers who have undertaken detailed\nassessments of over 4000 media outlets. A transpar-\nent assessment methodology means that their datasets\nhave been used for several research projects [ 23,20].\nTheir team of researchers undertake in-depth analyses\nof news organisations and assess them using a standard-\nised methodology, with some subjective judgement, to\ncalculate a left/right bias score using their published for-\nmula. They also calculate scores for factual reporting\nand credibility. These reports are published on their web-\nsite and updated from time to time. Each news website\nin their database is categorised as: left bias, left-centre\nbias, least biased, right-centre bias, right bias, pro-science,\nconspiracy-pseudoscience, fake news, or satire. While\ntheir browser extension conveys limited details, further\ninformation about each news source is available on their\nwebsite. It draws on this dataset to inform users when\nthey click on the notification icon as to which of these\nnine categories the news website they are viewing be-\nlongs to, including a brief explanation of the category.\nIt also provides a link to the detailed MBFC report. The\nbrowser extension also provides Facebook and Twitter\nsupport by displaying a visual left/right bias scale on\nnews articles that appear in users feeds with links to the\nMBFC detailed report and Factual Search3so that the\nuser can investigate the topic further. While a valuable\nresource with considerable detail, MBFC\u2019s expert evalua-\ntions are based on the historical publication record of the\nnews website and not an evaluation of the content the\nuser is looking at. It is also a labour intensive and time\nconsuming process.\nStopaganda Plus4[24] is a browser extension that\nadds accuracy and bias decals to Facebook, Twitter, Red-\ndit, DuckDuckGo and Google. These visual indicators\nextend the functionality of MBFC (who determine the\nscores) to these common information portals so that\n2https://mediabiasfactcheck.com/\n3https://factualsearch.news\n4https://browserextension.dev/blog/stopagandaplus-helps-\nunderstanding-media-biases/users may more easily choose high-quality information\nresources. It should be noted that this extension is not\ndesigned to provide users with detailed warning notifi-\ncations when viewing a news website and thus is not\ndirectly comparable to the other systems or Provenance.\nIt is included here due to its use of MBFC, the fact that it\nconveys limited visual information/warnings before the\nuser visits an information source, and for plenitude.\n3.1. No Longer Active\nMany other projects and services related to this work,\nwhich have been reviewed in the literature, c.f. [ 25,26,\n27,11,28,29,30], now no longer appear to be active or\nworking. This is concerning as despite the fact that mis-\ninformation and disinformation have been recognised as\na threat to democracy and social cohesion, and the fact\nthat browser plugins are one of the few citizen-orientated\ndirect interventions which can help solve the problem at\nsource while increasing long term media literacy, very\nfew of the proposed solutions have been actively pro-\nmoted or maintained. The main reason for this appears to\nbe the fact that many of these plugins were developed by\nindividuals or small teams, or even as part of a hackathon,\nand were thus lacked the resources to be actively main-\ntained or updated to deal with changing technology such\nas browser updates or the rapidly evolving threats posed\nby misinformation and disinformation. The following\npresent those related projects found in the literature, but\nwhich now no longer appear to be actively maintained,\nthough some are still available to install. URLs have been\nincluded for posterity where possible as many do not\nhave peer-reviewed publications.\nB.S Detector5relied on matching the URLs of content\nin the news feed to a known allow/deny list of sources\nof fake news and misinformation.\nAreYouFakeNews.com6utilised Natural Language\nProcessing (NLP) and deep learning to identify patterns\nof bias on websites.\nFake News Detector AI7claimed to use a neural net-\nwork to detect similarity between submitted URLs and\nknown fake news websites.\nFake News Detector8was designed to learn from\nwebpages flagged by users to detect other similar fake\nnews webpages.\nTrusted News9is a browser plugin that was designed\nto assess the objectivity of news articles. Its functionality\nwas limited to \u2018long form\u2019 news articles and it does not\nwork with social media content.\n5https://www.producthunt.com/posts/b-s-detector\n6https://github.com/N2ITN/are-you-fake-news\n7https://www.fakenewsai.com/\n8https://fakenewsdetector.org/\n9https://trusted-news.com/\nFake News Guard10claimed to combine linguistic\nand network analysis techniques to identify fake news,\nhowever this can no longer be verified.\nFiB11A browser extension built in a hackathon which\nwas reviewed several times in the literature as a compa-\nrable system [31].\nTrustedNews12Trusted News used AI to help users\nevaluate news articles by scoring their objectivity [ 32].\nHowever, it does not work on social media and has issues\nwith analysing webpages that require scrolling.\nTrusty Tweet [26] was designed to help users deal\nwith fake news tweets and to increase media literacy.\nTheir transparent approach is designed to prevent reac-\ntance and increase trust. Early user evaluations showed\npromise.\nCheck-It [33] was designed to analyse a range of sig-\nnals to identify fake news. It was focused on user privacy\nwith computation undertaken locally. Their approach\nused a combination of linguistic models, fact checking,\nand website and social media user allow/deny lists.\n3.2. Out of Scope Approaches\nSome misinformation and disinformation detection tools\nwhich have been reviewed in other papers have not been\nincluded in this literature review. This is because they\nare not a browser plugin or they are a paid for b2b ser-\nvice (Fakebox [ 34]; AreYouFakeNews [ 35]), they are fo-\ncused on an aligned but separate issue e.g., detection of\nbias or detection of reused and or manipulated images\n(Ground.News [ 36]; SurfSafe [ 37]), they are specifically\nfor fact checking (BRENDA [ 38], CredEye [ 39]), they\nhave pivoted into a B2B platform (FightHoax [ 40]), they\nare not user orientated (Credible News [ 41,42]), or they\nare research systems and have not been made available to\nthe public [ 30,43]. While relevant to combating disinfor-\nmation, these are not directly comparable to Provenance.\n3.3. Advancing the State of the Art\nThis review demonstrates that browser plugins are a\ncommon user-orientated approach to combat misinfor-\nmation and disinformation. However, Provenance adopts\na significantly more advanced and granular methodol-\nogy than current or previous efforts in the domain. The\nwarnings provided by earlier plugins are often based on\nthe news website\u2019s history of publishing misinformation\nand disinformation. Thus, they are limited to provid-\ning a coarse-grained retrospective analysis of the news\nwebsite\u2019s publication history. In contrast, Provenance\u2019s\nfine-grained approach is designed to analyse the content\nof the news webpage or users\u2019 social media feeds and,\n10http://fakenewsguard.com/\n11https://projectfib.azurewebsites.net/\n12https://trusted-news.com/where necessary, provide an easy to understand warning\nto the user when the content they are viewing may be\nproblematic or symptomatic of disinformation. In the\ncases where linguistic analysis or other machine learn-\ning approaches have been utilized, the results are not\npresented to the user in an explainable or transparent\nway. Some of these methods have also proven susceptible\nto adversarial attacks, whereby text may be augmented\nslightly to fool pretrained models [44, 45].\nTwo factors differentiating Provenance from the plug-\nins described above are their limited reach and scalability.\nMany of the above plugins do not provide any informa-\ntion for some heavily trafficked news websites such as the\nLA Times, Al Jazeera, and the Independent.co.uk. This\nis likely due to limiting factors of time and labour of in-\ncluding humans in the disinformation judgement process.\nWhile no one doubts the benefits of highly trained expert\njudgement, the size and nature of the rapidly evolving\nmedia landscape, especially in regard to misinformation\nand disinformation in which publishers are prone to rapid\ngrowth, failure and re-branding, means that providing\nhuman ratings is a never ending game of whack-a-mole.\nCurrent solutions are only partially succeeding in pro-\nviding judgements of some news agencies. None have\nattempted to analyse the millions of pieces of content\nthey publish daily. Unlike each of the plugins described\nabove, Provenance does not require a human-in-the-loop,\nnor does it need to be backed by human-generated al-\nlow/deny lists. Its architecture supports fully automated\nand intermediary free analysis of news content.\nThe ability to evaluate news articles against seven\ncriteria and provide users with visual notifications and\ndeeper explanations is also a significant advancement on\nthe state of the art and a direct benefit to users in three\nways. First, and most importantly, users will be made\naware of individual issues with the content they are con-\nsuming and can thus decide whether they will continue\nviewing it or look for alternative sources. Second, it will\nhelp develop users\u2019 media literacy skills by making them\naware of the different caution worthy indicators and how\nto check them, making them less susceptible to misinfor-\nmation and disinformation in the future. Third, the na-\nture of these systems means that they cannot be properly\nexamined. In contrast, a full description of Provenance\u2019s\nsystem architecture is provided below. It is also currently\nundergoing evaluation and testing and the results will\nbe published in time.\n4. Architecture Overview\nThe system architecture for Provenance is shown in Fig-\nure 1. The components and services use REST APIs serv-\ning JSON for easy, reliable, and fast data exchanges across\ninternal subsystems.\nFigure 1: Provenance System Architecture: Dashed lines denote REST API calls, solid lines denote local access.\nData in the form of webpages or social media content is\ningested by Provenance either through the Social Network\nMonitor or by a Trusted Content Analyst (e.g., a journalist\nor fact checker). The Social Network Monitor service\ndiscovers content using NewsWhip\u2019s13social network\nmonitoring platform. The introduced asset is enriched\nwith social engagement data (e.g., likes and shares) and\nis forwarded to the Asset Workflow Handler service.\nTheAsset Workflow Handler separates the incoming\ndata (e.g., a news webpage) into individual assets such\nas images, video, text, etc. These assets are registered\nwith the Asset Fingerprinter before being disseminated to\nthe analytical components ( Video/Image Reverse-searcher ,\nVideo/Image Manipulation Detector ,Text Similarity Detec-\ntor,Text Tone Detector , and Writing Quality Detector ) to\ndetermine if they exhibit any features which normally\ncharacterise misleading, questionable, or unsubstantiated\ninformation. The output of each analytical service, and\nthe initial data passed from the Social Network Monitor\nare combined and sent to the Knowledge Graph where\nthey are stored.\nThe Knowledge Graph may be queried by the Prove-\nnance Query Service to retrieve the results of analysis for\na given webpage. The Provenance plugin, installed in the\nuser\u2019s browser, leverages this query service to retrieve\ninformation about webpages that a user is currently view-\ning. If the webpage has been analysed by Provenance,\nand exhibits questionable features, the plugin will issue\na warning to the user, indicating that they may want\n13https://www.newswhip.comto further investigate the claims made in the article\u2019s\ncontent. The Personalised Companion Service is used to\ndetermine how this information should be presented for\nan individual user.\n4.1. Key Components\n4.1.1. Social Network Monitor\nThe Social Network Monitor communicates with\nNewsWhip\u2019s Social Network API to identify assets\nwhich should be ingested by Provenance. Finding assets\ninvolves querying Newswhip\u2019s API with a parameterized\nsearch request. The call to NewsWhip\u2019s Social Network\nAPI is automatically invoked periodically to maintain\nan updated record of trending news articles and social\nmedia posts. Assets detected by NewsWhip are enriched\nthrough social scoring. The URL, titles, summaries, im-\nages and videos (if any), along with the enrichment data,\nis extracted from the article and provided to Provenance.\nAssets composed only of text, for example, are registered\nin fragments consisting of news feed/article title, the\nsummary, and user engagement data.\n4.1.2. Asset Registration\nA dedicated Asset Registration web interface also allows\nTrusted Content Analysts to add assets into the Asset Work-\nflow Handler .Trusted Content Analysts are stakeholders\nsuch as journalists and other representatives of news\nagencies and wire services, fact checkers, debunkers, and\noriginal content creators who may want to register their\nmultimedia content assets. In future, this facility will be\nmade more widely available to allow the general public\nto send content directly to Provenance. It may also be\nintegrated with news publication platforms and content\nmanagement systems so that content is automatically\nadded. The primary task of this component is to enable\nthird-parties to register assets that have not been discov-\nered by the Social Network Monitor .\n4.1.3. Asset Workflow Handler\nThe Asset Workflow Handler is the component of the\nProvenance Verification Layer that is responsible for or-\nchestrating the components and data within the layer.\nThis component\u2019s primary task is to distribute assets to\ndifferent components for further processing. It invokes\nthe service interfaces and handles the data flow between\nthe services. By utilising the Asset Workflow Handler ,\ncomponents are loosely coupled, thus mitigating direct\ncomponent-to-component communications. This will en-\nable Provenance to work with the variety of APIs exposed\nfrom the existing tools/components. Moreover, the APIs\ncan be adjusted to meet Provenance\u2019s specific needs. Due\nto this modular design, new components can be easily\nadded to the Provenance Verification Layer (e.g., detection\nof bias [ 46], tabloidization [ 47], and hate speech [ 48]),\nand connected to the Asset Workflow Handler .\n4.1.4. Video/Image Reverse Searcher\nThe Video/Image Reverse Searcher is a key component\nfor creating a large-scale annotated dataset for detect-\ning manipulated visual content. The dataset consists of\nthree distinct parts. The first part includes 45,000 images,\neach captured by a unique device (i.e., 45,000 different\ncameras have been used). Half of these images are real,\nand the other half has been digitally manipulated by ap-\nplying a random image processing operation to a local\narea of the image. Since the sensor pattern noise present\nin images is unique to each sensor (i.e., camera), this\ndataset introduces large diversity, such as noise. The\nsecond part of the dataset uses imaging software in cam-\neras to introduce a large diversity of artefacts in images.\nCommonly available camera brands and models were\nidentified and used to collect a dataset of 50,000 images.\nHalf of these images were digitally manipulated using\nan advanced image editing method based on Generative\nAdversarial Networks (GAN) [ 49]. Finally, the third part\nof the dataset consists of 2,000 images downloaded from\nthe Internet representing \u201creal-life\u201d (uncontrolled) ma-\nnipulated images created by random people. For all of\nthe manipulated samples collected for the third part of\nthe data, the matching unmanipulated image was also\ncollected. This component\u2019s primary task is to enablesearch operation for videos and images.\n4.1.5. Video/Image Manipulation Detector\nThe Provenance Video/Image Manipulation Detector iden-\ntifies if an image or video has been manipulated in com-\nparison to its source. This work is based on the PIZ-\nZARO14project. It utilises recent developments achieved\nby deep learning-based methods to enable an instant de-\ntection of manipulations in visual content. In addition,\nuse of the latest technologies based on Convolutional Net-\nworks will lead to tangible enhancements in integrity ver-\nification in visual content. The Video/Image Manipulation\nDetector increases trust and improves governance. The\nsolution is designed to build a web-based system to assess\nvisual content in a real-world setting. The Video/Image\nManipulation Detector will further support the develop-\nment of user skills in detecting false visual information\nthemselves by providing a world-class image forensic\ntechnology. The Video/Image Manipulation Detector has\na special focus on developing a solution that will be intu-\nitive and easy to understand and interpret for end-users,\nthereby increasing its uptake by the public and its impact\non the information system. This component\u2019s primary\ntask is to detect if the image and video are manipulated\nby comparing them with previously registered images\nand videos in the system.\n4.1.6. Asset Fingerprinter and Asset Registry\nTheAsset Fingerprinter and Asset Registry provide trace-\nability of registered content. It is based on Blockchain\ntechnology, making content immutable and enabling the\nverification of the sources and alterations to the content.\nRegistered assets are handed to the Asset Fingerprinter\nvia the Asset Workflow Handler . Due to the General Data\nProtection Regulation (GDPR) and the size of some assets,\nthe hash of the data is stored on Blockchain. Azure Stor-\nage is used as the Blockchain, and the assets themselves,\nincluding large files, are stored using an off-line storage\nservice available to store multimedia files. Blockchain is\nused due to its innate data integrity which is important\nto prove the traceability of registered content if the tool\nwas ever targeted as part of a combined disinformation\nand hacking campaign. This component\u2019s primary task\nis the traceability of registered content via Blockchain.\n4.1.7. Text Similarity Detector\nNews is regularly republished nationally and locally\nfrom international wire services such as Reuters, Agence\nFrance-Presse (AFP) and Associated Press (AP). In a bid\nto lower costs, many news agencies who are not in com-\npetition negotiate deals to republish each other\u2019s content.\n14http://zoi.utia.cas.cz/node/180/0459504\nSimilarly, less trustworthy news outlets often put \u2018spins\u2019\non existing articles, where correct articles are modified\nto contain false information.\nTo combat this, the Text Similarity Detector in Prove-\nnance attempts to verify the textual content of an article\nby comparing it to similar articles published elsewhere.\nA backlog of trustworthy articles is stored in an Elastic-\nsearch database with a BM25 similarity index [ 50]. As\nBM25 under-performs with very long documents [ 51],\nonly the title and first 10 sentences are used in the index.\nOnce similar articles have been found the component\nsearches for facts given in the query article in the similar\nones. Facts in an article are found by taking sentences\nwith a low subjectivity from TextBlob\u2019s sentiment analy-\nsis model [ 52]. The similarity of two facts is the cosine\nsimilarity of the vector embedding of both, which is pro-\nvided by Google\u2019s multilingual text model [ 53]. If enough\nof the article\u2019s factual content cannot be verified, the plu-\ngin displays a warning.\n4.1.8. Text Tone Detector\nIntuitively, one would expect that impartial news sources\nwould use impartial, unemotive language to convey the\nfacts of a story. Recent research has shown that emotions\nsuch as fear, anger, sadness, doubt, and the absence of\njoy and happiness are indicative of misinformation and\ndisinformation [ 54,55,56]. Provenance\u2019s Text Tone De-\ntector is designed to identify emotions in text which may\nindicate that the news source is unreliable. Threshold\nvalues are used to determine whether caution should be\nshown, and the degree of caution is determined by how\nfar the calculated value deviates from the threshold value.\n4.1.9. Writing Quality Detector\nProvenance\u2019s Writing Quality Detector computes a writ-\ning quality score (WQS) for the textual content the user\nis viewing and provides a warning when it falls below a\nthreshold value. Writing quality is closely related to cohe-\nsion and coherence [ 57]. Within the context of news, high\nquality writing is indicative of paid professional journal-\nism from mainstream, independent, and to a lesser degree,\nalternative news agencies, whereas low quality writing is\nindicative of amateur or unprofessional news production\nprocesses [ 58]. This high/low quality differentiation is\nalso apparent in other domains such as academia, pub-\nlishing, commercial, and blogs and information websites.\nWhile NLP techniques exist to derive writing quality [ 59],\nand others have called for it to be used to identify misin-\nformation and disinformation [ 60,61], only two examples\nof systems could be found in the literature which actually\ncalculate writing quality [62, 63].\nTo calculate WQSs for Provenance, a dataset of news\narticles, blog posts, and other website content, much ofwhich had characteristics symptomatic of disinforma-\ntion, was annotated in a crowdsourced study to identify\nterms and phrases indicative of low quality writing. A\nWQS for each piece of content was then derived using a\nstandard formula. This was subject to testing and expert\nevaluation to ensure the WQS the formula produced accu-\nrately reflected each piece of content. Models were then\ntrained on the dataset which showed that the WQS could\nbe automatically generated with a high degree of accu-\nracy. These models and the overall process are currently\nundergoing formal evaluation.\n4.1.10. Knowledge Graph and Knowledge Graph\nBuilder\nThe Provenance Knowledge Graph stores a record of all\nthe articles introduced to Provenance via the Social Net-\nwork Monitor service or via Asset Registration from a\nTrusted Content Analyst . It is also a record of all analysis\nperformed on said assets.\nThe content is organised according to concept, cate-\ngories and topics. For example, a news article discussing\npolitics can be categorised according to the left/right\npolitical spectrum followed by the topics discussed as\nshown in Figure 2. Each node at the article level is split\naccording to text, image and video.\nThe output of the Video/Image Reverse Searcher in-\ncludes the N most similar images/videos, distance mea-\nsures and geometric validation results. The data from the\nVideo/Image Manipulation Detector includes the probabil-\nity of manipulations and the area of polygons. These are\nsent as JSON objects to the Knowledge Graph where they\nare stored as entities in a triplestore.\nModelling of Provenance data is achieved using a com-\nbination of the RDF Data Cube vocabulary [ 64] to store\nstatistical information such as the outputs from the vari-\nous analytical components, and the Dublin Core/BIBO\nvocabularies [ 65] to model bibliographic information\nabout the assets themselves. Some use is also made of\nthe FOAF15vocabulary to model information such as\ncontent publishers, which are naturally represented as\nfoaf:Agent entities.\nThe Knowledge Graph Builder is responsible for ex-\nposing a REST API which the Asset Workflow Handler\nmay use to upload assets as JSON, and then transforming\nthe JSON into triples which are stored in a triplestore.\nIn Provenance, this is achieved using JOPA [ 66]: a Java\nlibrary which can be used to map POJOs to triples. Using\nSpring Boot16, a REST API accepting JSON is exposed.\nThe uploaded JSON is serialized into POJOs using Spring\nBoot\u2019s built-in version of Jackson. JOPA is then used to\nserialize the triples out to an RDF4J17instance.\n15http://xmlns .com/foaf/spec/\n16https://spring .io/projects/spring-boot\n17https://rdf4j .org/\nFigure 2: Knowledge Graph categorisations of assets.\nThe same serialization process works in reverse, al-\nlowing the Provenance Query Service to expose both a\nJSON REST endpoint which can produce JSON objects\nfrom the results of a canned SPARQL query exposed via a\nSpring Boot REST endpoint, and a much lower level raw\nSPARQL endpoint from the triplestore, for those who\nwant a high level of control over their queries.\n4.1.11. Provenance Query Service\nTheProvenance Query Service is the interface to the Verifi-\ncation Layer and offers external trusted services with the\nmeans to request verification information about a web-\npage or article. It will also allow trusted services with\na means to identify the relatedness of content (through\nsimilarity and the Knowledge Graph ) and determine if\ncontent has been modified. As the results of all analysis\nare stored in the Knowledge Graph , the Provenance Query\nService is effectively a proxy between the user-facing\nfront-end, and the query interface to whatever storage\nmedium is used to implement the Knowledge Graph.\nAs mentioned in Section 4.1.10, the Provenance Query\nService exposes both a raw SPARQL endpoint and a REST\nAPI which provides endpoints for a number of canned\nSPARQL queries which return JSON objects. It is envi-\nsioned that the vast majority of user cases will be covered\nby the REST API, making it easier for developers to access\ndata that is helpful to users. However, it is worthwhile to\nallow lower level access to the KG\u2019s contents in the event\nof unforeseen requirements being placed on the KG.\n4.1.12. Personalised Companion Service\nThePersonalised Companion Service manages the Prove-\nnance verification indicator, the minimal user model, and\nuser scrutability and control. The verification indicator\nis implemented as a Chrome Extension and works onthe Facebook and Twitter platforms and with articles\npublished by news agencies. The Personalised Compan-\nion Service uses the user\u2019s interests, domain knowledge,\ndigital literacy, and the warning preferences stored in\nthe Minimal User Model to determine whether to high-\nlight caution or show the verification indicator without\ncaution. The Personalised Companion Service uses the\ndata provided by the Asset Fingerprinter , the Video/Image\nReverse Searcher andVideo/Image Manipulation Detector ,\nand the Text Similarity, Tone and Writing Quality Detector\ncomponents to create the set of icons that are presented\nto users, who can explore the levels of verification pre-\nsented through the visual iconography.\n5. Provenance in Action\nThe Provenance browser plugin is designed to provide\nusers with easy to understand, granular and cautionary\nwarnings about the content they are consuming. These\nwarnings are provided via an in-browser icon beside the\naddress bar when the user is browsing the Internet, or\nwithin their Facebook and Twitter social media feeds\nbeside the content they are viewing. Figures 3 - 6 show\nhow Provenance and its visual warnings appear to a user\n- who has the Provenance plugin installed - within their\nFacebook social media feed. The Provenance icon appears\nas a small blue square with a white P above each content\nitem that it has checked. When the icon background\nturns red (with a small exclamation mark), it indicates to\nthe user that the content item is worthy of a cautionary\nwarning. The following presents the four main states of\nProvenance which a user will see.\nFigure 3 shows a user\u2019s Facebook feed who has the\nProvenance browser plugin installed. The Provenance\nicon is visible at the top of each news article in the user\u2019s\nfeed. In this image, the icon is blue which indicates that\nthere are no warnings with this particular news item.\nIn Figure 4, the background of the Provenance icon\nwithin the user\u2019s news feed has turned red to indicate\nthat this news item is worthy of one or more cautionary\nwarnings. A small black exclamation mark has been\nadded to the top right of the icon for colour blind users.\nIn Figure 5, the user has clicked on the red Provenance\nicon. A window has appeared beneath the Provenance\nicon to show the user which of the seven criteria the\nnews article was checked against that Provenance has de-\ntected an issue with. In this example, the red background\nand exclamation mark beneath the Writing Quality icon\nindicates that this aspect of the news article is worthy of\ncaution. The user may click on the downward arrow be-\nneath each icon for further information. In this example,\ntheTone icon is greyed out indicating that this could not\nbe assessed by Provenance in this instance.\nFigure 6 shows a detailed explanation of the Writing\nFigure 3: A user\u2019s Facebook feed showing the Provenance\nicon in blue indicating that there are no warnings.\nFigure 4: The Provenance icon in red (with exclamation mark)\nindicating that this article has one or more issues which are\nworthy of caution.\nQuality warning after the user clicked on the option to\nexpand it. It contains further information about how\nWriting Quality score is calculated and why low quality\nwriting is indicative of misinformation and disinforma-\ntion.\nFigure 5: An initial explanation pane appears when then user\nclicks on the Provenance icon in their social media feed.\nFigure 6: A detailed explanation pane appears when the user\nclicks on any of the seven categories Provenance analyses the\nnews item under.\n6. Use Cases: Provenance Plugin\n6.1. Social Media Timeline\nOn the recommendation of a friend, Mary installed the\nProvenance browser plugin due to increased concerns\nabout the spread of misinformation and disinformation.\nThe instructional video on the Provenance Chrome Ex-\ntension webpage explained that Provenance uses seven\ncriteria to verify digital content on the Internet and social\nmedia feeds. After installing the Provenance plugin, she\nnotices that the news items in her Facebook timeline now\ndisplay the Provenance icon beside the publisher\u2019s name.\nFor most of the news stories, the Provenance icon shows\na white P inside a white circle on a blue background.\nWhen she clicks on the blue Provenance icon, it opens a\nnotification pane showing the seven verification criteria,\nall of which display a green background with a white \u2713.\nShe is able to click on each of the seven verification\nicons to read a detailed explanation for each criterion,\nwhy failing the criterion is an indication that the webpage\nor social media post may be misinformation or disinfor-\nmation, and how the warning is derived. As all of the\nicons are green, she is reassured about the origin, ve-\nracity and overall quality of the news article. For some\nnews items displayed on her timeline, she notices that\nthe blue background of the Provenance icon has turned\nred. When she clicks on it, the same information pane\ndisplaying the same verification criteria appears, except\none or more of the seven verification criteria now display\na red background with an exclamation mark beneath.\nWhen she clicks on these, an additional detailed expla-\nnation pane appears underneath them to explain why it\nhas failed. Reading through each warning including their\ndetailed description, she gains a better understanding\nof how to identify misinformation and disinformation.\nIn both instances, Mary has become more aware of the\nneed to critically check the news she consumes and more\naware of good media literacy habits in general.\n6.2. News Websites\nMary regularly visits news websites to inform herself of\ncurrent affairs. Usually, the Provenance icon, which is\nvisible to the right of her browser\u2019s address bar, displays\na white P inside a white circle on a blue background.\nHowever, recently when she was visiting news websites\nto read more about a story relating to Covid 19 vaccina-\ntion, she noticed that the background of the Provenance\nicon would sometimes turn red. When she clicked on the\nicon, the verification criteria information pane showed\nthat Provenance had detected a problem with the image\nused in the news article she was reading. Clicking on\nthe arrow to open the drop-down explanation pane, she\nreads that Provenance has detected that the image has\nbeen used before in another article. The image in ques-\ntion shows a picture taken at a conference of the World\nHealth Organisation. Looking closely, she sees a credit\nto the Associated Press (AP). She knows that AP is an\ninternational news wire service, and that local and na-\ntional news agencies republish their articles, includingthe images. As this is just an image of a press conference,\nshe is confident that its use by multiple news agencies is\nnot an issue.\n7. Evaluation\nProvenance is under development and will shortly be un-\ndergoing human evaluation. Currently, five of the seven\nnews analysis functions have been implemented and have\nbeen integrated with the platform. These are undergoing\ntechnical evaluation while the final two analysis tools are\nbeing completed. When the tool is fully completed, a se-\nries of technical tests and human evaluation tests will be\nundertaken to evaluate basic functionality and to ensure\nthat it is providing the right warnings at the appropriate\ntime. Following this, a series of experiments will be un-\ndertaken to evaluate its effect on user behaviour. This\nwill include the likelihood of reading and sharing news\narticles that have cautionary warnings beside them. We\nwill also be analysing unintended effects of the tool. Fi-\nnally, a series of long term studies are planned to evaluate\nits effect on users\u2019 media literacy.\n8. Conclusions\nMisinformation and disinformation are significant issues\nthat have negatively affected public discourse, politics\nand social cohesion. The Internet and especially social\nmedia are the primary conduits for its growth and spread.\nExisting user-orientated browser plugins have limited\ncapabilities and only provide users with an historical rat-\ning of a website\u2019s propensity to publish misinformation\nand disinformation. They are also not capable of detailed\nanalysis of the content of news webpages or social me-\ndia feeds. The Provenance browser plugin significantly\nimproves upon existing user orientated solutions by pro-\nviding intermediary free analysis of webpage and social\nmedia content using seven criteria, and where necessary\nproviding cautionary warnings to users. The user can\nthen check the detailed explanatory warning notifica-\ntions to make their own judgement. This will improve\nusers\u2019 media literacy and reduce susceptibility to misin-\nformation and disinformation long term.\n9. Acknowledgements\nThe work has been supported by the PROVENANCE\nproject which has received funding from the European\nUnion\u2019s Horizon 2020 research and innovation pro-\ngramme under Grant Agreement No. 825227, and with\nthe financial support of Science Foundation Ireland under\nGrant Agreement No. 13/RC/2106_P2 at the ADAPT SFI\nResearch Centre.\nReferences\n[1]G. Rehm, An infrastructure for empowering in-\nternet users to handle fake news and other online\nmedia phenomena, in: G. Rehm, T. Declerck (Eds.),\nLanguage Technologies for the Challenges of the\nDigital Age, Lecture Notes in Computer Science,\nSpringer International Publishing, 2018, p. 216\u2013231.\ndoi:10 .1007/978-3-319-73706-5_19 .\n[2]E. Commission, Action plan against disinfor-\nmation (2018). URL: https://ec .europa .eu/digital-\nsingle-market/en/news/action-plan-against-\ndisinformation.\n[3]E. Commission, Tackling online disinformation,\n2017. URL: https://ec .europa .eu/digital-single-\nmarket/en/tackling-online-disinformation.\n[4]J. Bayer, N. Bitiukova, P. Bard, J. Szak\u00e1cs, A. Ale-\nmanno, E. Uszkiewicz, Disinformation and Propa-\nganda \u2013 Impact on the Functioning of the Rule of\nLaw in the EU and its Member States, 2019. URL:\nhttps://papers .ssrn .com/abstract=3409279.\n[5]2021. URL: https://twitter .com/vonderleyen/status/\n1354030170789834755.\n[6]A. Aker, A. Sliwa, F. Dalvi, K. Bontcheva, Rumour\nverification through recurring information and an\ninner-attention mechanism, Online Social Net-\nworks and Media 13 (2019) 100045. doi: 10 .1016/\nj.osnem .2019 .07 .001.\n[7]Z. Marinova, J. Spangenberg, D. Teyssou, S. Pa-\npadopoulos, N. Sarris, A. Alaphilippe, K. Bontcheva,\nWeverify: Wider and enhanced verification for\nyou project overview and tools, in: 2020 IEEE\nInternational Conference on Multimedia Expo\nWorkshops (ICMEW), 2020, p. 1\u20134. doi: 10 .1109/\nICMEW46912 .2020 .9106056 .\n[8]M. Chora\u015b, M. Pawlicki, R. Kozik, K. Demestichas,\nP. Kosmides, M. Gupta, Socialtruth project ap-\nproach to online disinformation (fake news) de-\ntection and mitigation, in: Proceedings of the\n14th International Conference on Availability, Re-\nliability and Security, ARES \u201919, Association for\nComputing Machinery, 2019, p. 1\u201310. URL: https:\n//doi .org/10 .1145/3339252 .3341497. doi: 10 .1145/\n3339252 .3341497 .\n[9]L. Derczynski, K. Bontcheva, Pheme: Veracity in\ndigital social networks (2014) 4.\n[10] P. K. Srijith, M. Hepple, K. Bontcheva, D. Preotiuc-\nPietro, Sub-story detection in twitter with hierar-\nchical dirichlet processes, Information Processing\n& Management 53 (2017) 989\u20131003. doi: 10 .1016/\nj.ipm .2016 .10 .004.\n[11] L. Toumanidis, R. Heartfield, P. Kasnesis, G. Loukas,\nC. Patrikakis, A prototype framework for assess-\ning information provenance in decentralised so-\ncial media: The eunomia concept, in: S. Kat-sikas, V. Zorkadis (Eds.), E-Democracy \u2013 Safeguard-\ning Democracy and Human Rights in the Digi-\ntal Age, Communications in Computer and In-\nformation Science, Springer International Publish-\ning, 2020, p. 196\u2013208. doi: 10 .1007/978-3-030-\n37545-4_13 .\n[12] D. Mart\u00edn-Guti\u00e9rrez, G. Hern\u00e1ndez-Pe\u00f1aloza, J. M.\nMen\u00e9ndez, F. \u00c1lvarez, A multi-modal approach for\nfake news discovery and propagation from big data\nanalysis and artificial intelligence operations (2020)\n3.\n[13] D. Mart\u00edn-Guti\u00e9rrez, G. Hern\u00e1ndez-Pe\u00f1aloza,\nA. B. Hern\u00e1ndez, A. Lozano-Diez, F. \u00c1l-\nvarez, A deep learning approach for robust\ndetection of bots in twitter using trans-\nformers, IEEE Access 9 (2021) 54591\u201354601.\ndoi:10 .1109/ACCESS .2021 .3068659 .\n[14] L. Ginsborg, P. Gori, Report on a survey for fact\ncheckers on COVID-19 vaccines and disinforma-\ntion, 2021. URL: https://cadmus .eui .eu//handle/\n1814/70917, accepted: 2021-04-26T08:57:47Z.\n[15] U. N. S. Verified, Shareverified, 2021. URL: https:\n//shareverified .com/en.\n[16] W. H. Organisation, 1st who infodemiology con-\nference, who infodemic management, 2020. URL:\nhttps://www .who .int/teams/risk-communication/\ninfodemic-management/1st-who-infodemiology-\nconference.\n[17] T. P. Institute, A guide to anti-misinformation\nactions around the world, 2021. URL: https:\n//www .poynter .org/ifcn/anti-misinformation-\nactions/.\n[18] 2021. URL: https://www .newsguardtech .com/.\n[19] J. N\u00f8rregaard, B. D. Horne, S. Adal\u0131, Nela-gt-2018:\nA large multi-labelled news dataset for the study\nof misinformation in news articles, Proceedings\nof the International AAAI Conference on Web and\nSocial Media 13 (2019) 630\u2013638.\n[20] A. Aker, V. Kevin, K. Bontcheva, Credibility and\ntransparency of news sources: Data collection and\nfeature analysis (2019) 6.\n[21] Le Monde.fr (2017). URL: https://www .lemonde .fr/\nles-decodeurs/article/2017/01/23/le-decodex-un-\npremier-premier-pas-vers-la-verification-de-\nmasse-de-l-information_5067709_4355770 .html.\n[22] 2021. URL: https://mediabiasfactcheck .com/.\n[23] V. Kevin, B. H\u00f6gden, C. Schwenger, A. \u015eahan,\nN. Madan, P. Aggarwal, A. Bangaru, F. Muradov,\nA. Aker, Information nutrition labels: A plugin for\nonline news evaluation, ACL, 2018. doi: 10 .18653/\nv1/W18-5505 .\n[24] 2020. URL: https://browserextension .dev/blog/\nstopagandaplus-helps-understanding-media-\nbiases/.\n[25] P. Nordberg, J. K\u00e4vrestad, M. Nohlberg, Au-\ntomatic detection of fake news, in: Proceed-\nings of the 6th International Workshop on Socio-\nTechnical Perspective in IS Development (STPIS\n2020), CEUR-WS, 2020, p. 168\u2013179. URL: http://\nurn .kb.se/resolve?urn=urn:nbn:se:his:diva-19356.\n[26] K. Hartwig, C. Reuter, Trustytweet: An indicator-\nbased browser-plugin to assist users in dealing with\nfake news on twitter (2019).\n[27] A. Gie\u0142czyk, R. Wawrzyniak, M. Chora\u015b, Evalua-\ntion of the existing tools for fake news detection,\nin: K. Saeed, R. Chaki, V. Janev (Eds.), Computer\nInformation Systems and Industrial Management,\nLecture Notes in Computer Science, Springer Inter-\nnational Publishing, 2019, p. 144\u2013151. doi: 10 .1007/\n978-3-030-28957-7_13 .\n[28] A. \u0160kolkay, J. Filin, A comparison of fake news de-\ntecting and fact-checking ai based solutions, Studia\nMedioznawcze 20 (2019) 365\u2013383.\n[29] K. Shu, A. Sliva, S. Wang, J. Tang, H. Liu, Fake\nnews detection on social media: A data mining per-\nspective, ACM SIGKDD Explorations Newsletter\n19 (2017) 22\u201336. doi: 10 .1145/3137597 .3137600 .\n[30] A. Hanselowski, A. PVS, B. Schiller, F. Caspel-\nherr, D. Chaudhuri, C. M. Meyer, I. Gurevych, A\nretrospective analysis of the fake news challenge\nstance-detection task, in: Proceedings of the 27th\nInternational Conference on Computational Lin-\nguistics, Association for Computational Linguistics,\n2018, p. 1859\u20131874. URL: https://www .aclweb .org/\nanthology/C18-1158.\n[31] A. Goel, ProjectFib - GitHub Repo, 2016. URL: https:\n//github .com/anantdgoel/ProjectFib.\n[32] Eyeo, 2020. URL: https://chrome .google .com/\nwebstore/detail/trusted-news/\nnkkghpncidknplmlkgemdoekpckjmlok?hl=en.\n[33] D. Paschalides, C. Christodoulou, R. Andreou,\nG. Pallis, M. D. Dikaiakos, A. Kornilakis,\nE. Markatos, Check-it: A plugin for detecting\nand reducing the spread of fake news and misin-\nformation on the web, in: 2019 IEEE/WIC/ACM\nInternational Conference on Web Intelligence (WI),\n2019, p. 298\u2013302.\n[34] V. Inc, Fakebox, 2021. URL: https://machinebox .io/.\n[35] Z. A. Estela, N2ITN/are-you-fake-news, 2021. URL:\nhttps://github .com/N2ITN/are-you-fake-news.\n[36] 2021. URL: https://ground .news/.\n[37] A. Bhat, SurfSafe, 2021. URL:\nhttps://chrome .google .com/webstore/\ndetail/surfsafe-join-the-fight-a/\nhbpagabeiphkfhbboacggckhkkipgdmh?hl=en.\n[38] B. Botnevik, E. Sakariassen, V. Setty, Brenda:\nBrowser extension for fake news detection, in:\nProceedings of the 43rd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, Association for Computing Ma-chinery, 2020, p. 2117\u20132120. URL: https://doi .org/\n10.1145/3397271 .3401396.\n[39] K. Popat, S. Mukherjee, J. Str\u00f6tgen, G. Weikum,\nCredeye: A credibility lens for analyzing and ex-\nplaining misinformation, in: Companion Pro-\nceedings of the The Web Conference 2018, WWW\n\u201918, International World Wide Web Conferences\nSteering Committee, 2018, p. 155\u2013158. URL: https:\n//doi .org/10 .1145/3184558 .3186967. doi: 10 .1145/\n3184558 .3186967 .\n[40] FightHoax, Fighthoax - unlock your programmatic\nadvertising, 2021. URL: http://34 .253 .212 .69/.\n[41] M. Hardalov, I. Koychev, P. Nakov, In search of cred-\nible news, in: C. Dichev, G. Agre (Eds.), Artificial\nIntelligence: Methodology, Systems, and Applica-\ntions, Lecture Notes in Computer Science, 2016.\ndoi:10 .1007/978-3-319-44748-3_17 .\n[42] M. Hardalov, mhardalov/news-credibility, 2019.\nURL: https://github .com/mhardalov/news-\ncredibility.\n[43] X. Zhou, A. Jain, V. V. Phoha, R. Zafarani, Fake news\nearly detection: A theory-driven model, Digital\nThreats: Research and Practice 1 (2020) 12:1\u201312:25.\ndoi:10 .1145/3377478 .\n[44] W. E. Zhang, Q. Z. Sheng, A. Alhazmi, C. Li, Adver-\nsarial attacks on deep learning models in natural\nlanguage processing: A survey, arXiv:1901.06796\n[cs] (2019). URL: http://arxiv .org/abs/1901 .06796,\narXiv: 1901.06796.\n[45] Z. Zhou, H. Guan, M. M. Bhat, J. Hsu, Fake\nnews detection via nlp is vulnerable to adver-\nsarial attacks, Proceedings of the 11th In-\nternational Conference on Agents and Artifi-\ncial Intelligence (2019) 794\u2013800. doi: 10 .5220/\n0007566307940800 , arXiv: 1901.09657.\n[46] B. Spillane, S. Lawless, V. Wade, The impact of\nincreasing and decreasing the professionalism of\nnews webpage aesthetics on the perception of bias\nin news articles, in: Proceedings of the 22nd\nInternational Conference On Human-Computer\nInteraction, Lecture Notes in Computer Science,\nSpringer, 2020. doi: https://doi .org/10 .1007/\n978-3-030-49059-1_50 .\n[47] B. Spillane, I. Hoe, M. Brady, V. Wade, S. Lawless,\nTabloidization versus credibility: Short term\ngain for long term pain, in: CHI \u201920: The ACM\nConference on Human Factors in Computing\nSystems, ACM, 2020. URL: https://dl .acm .org/\ndoi/abs/10 .1145/3313831 .3376388. doi: http:\n//dx .doi .org/10 .1145/3313831 .3376388 .\n[48] A. Schmidt, M. Wiegand, A survey on hate speech\ndetection using natural language processing, in:\nProceedings of the Fifth International Workshop\non Natural Language Processing for Social Media,\nAssociation for Computational Linguistics, 2017,\np. 1\u201310. URL: https://aclanthology .org/W17-1101.\ndoi:10 .18653/v1/W17-1101 .\n[49] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,\nD. Warde-Farley, S. Ozair, A. Courville, Y. Bengio,\nGenerative adversarial nets, in: Advances in\nNeural Information Processing Systems, vol-\nume 27, Curran Associates, Inc., 2014. URL:\nhttps://proceedings .neurips .cc/paper/2014/hash/\n5ca3e9b122f61f8f06494c97b1afccf3-Abstract .html.\n[50] S. E. Robertson, S. Walker, Some simple effective\napproximations to the 2-poisson model for proba-\nbilistic weighted retrieval, in: SIGIR\u201994, Springer,\n1994, pp. 232\u2013241.\n[51] Y. Lv, C. Zhai, When documents are very\nlong, bm25 fails!, in: Proceedings of the\n34th international ACM SIGIR conference on\nResearch and development in Information Re-\ntrieval, SIGIR \u201911, Association for Computing\nMachinery, 2011, p. 1103\u20131104. URL: https:\n//doi .org/10 .1145/2009916 .2010070. doi: 10 .1145/\n2009916 .2010070 .\n[52] S. Loria, textblob documentation (2020). URL:\nhttps://buildmedia .readthedocs .org/media/pdf/\ntextblob/latest/textblob .pdf, release 0.16.0.\n[53] Y. Yang, D. Cer, A. Ahmad, M. Guo, J. Law,\nN. Constant, G. H. Abrego, S. Yuan, C. Tar, Y.-H.\nSung, B. Strope, R. Kurzweil, Multilingual univer-\nsal sentence encoder for semantic retrieval, 2019.\narXiv:1907.04307 .\n[54] S. B. Parikh, V. Patil, P. K. Atrey, On the origin,\nproliferation and tone of fake news, in: 2019 IEEE\nConference on Multimedia Information Processing\nand Retrieval (MIPR), IEEE, 2019, p. 135\u2013140. URL:\nhttps://ieeexplore .ieee .org/document/8695387/.\ndoi:10 .1109/MIPR .2019 .00031 .\n[55] J. Paschen, Investigating the emotional appeal of\nfake news using artificial intelligence and human\ncontributions, Journal of Product & Brand Manage-\nment 29 (2019) 223\u2013233. doi: 10 .1108/JPBM-12-\n2018-2179 .\n[56] X. Zhang, J. Cao, X. Li, Q. Sheng, L. Zhong,\nK. Shu, Mining dual emotion for fake news\ndetection, Proceedings of the Web Con-\nference 2021 (2021) 3465\u20133476. doi: 10 .1145/\n3442381 .3450004 , arXiv: 1903.01728 version: 1.\n[57] I. Singh, D. P., A. K., On the coherence of fake\nnews articles, in: I. Koprinska, M. Kamp, A. Ap-\npice, C. Loglisci, L. Antonie, A. Zimmermann,\nR. Guidotti, O. \u00d6zg\u00f6bek, R. P. Ribeiro, R. Gavald\u00e0,\net al. (Eds.), ECML PKDD 2020 Workshops, Com-\nmunications in Computer and Information Science,\nSpringer International Publishing, 2020, p. 591\u2013607.\ndoi:10 .1007/978-3-030-65965-3_42 .\n[58] M. Chung, N. Kim, When i learn the news is\nfalse: How fact-checking information stems thespread of fake news via third-person perception,\nHuman Communication Research 47 (2021) 1\u201324.\ndoi:10 .1093/hcr/hqaa010 .\n[59] V. Klyuev, Fake news filtering: Semantic ap-\nproaches, in: 2018 7th International Conference\non Reliability, Infocom Technologies and Optimiza-\ntion (Trends and Future Directions) (ICRITO), 2018,\np. 9\u201315. doi: 10 .1109/ICRITO .2018 .8748506 .\n[60] M. Spradling, J. Straub, J. Strong, Protection from\n\u2018fake news\u2019: The need for descriptive factual label-\ning for online content, Future Internet 13 (2021)\n142. doi: 10 .3390/fi13060142 .\n[61] N. Fuhr, A. Giachanou, G. Grefenstette, I. Gurevych,\nA. Hanselowski, K. Jarvelin, R. Jones, Y. Liu,\nJ. Mothe, W. Nejdl, et al., An information nutritional\nlabel for online documents, ACM SIGIR Forum 51\n(2018) 46\u201366. doi: 10 .1145/3190580 .3190588 .\n[62] C. Fan, Classifying fake news, 2017. URL:\nhttps://www .conniefan .com/wp-content/uploads/\n2017/03/classifying-fake-news .pdf, connie Fan.\n[63] E. S. Jo, A. Muhamed, S. Nuthakki, A. Singhania,\nDeepNews: Detecting Quality in News, 2018.\n[64] W. W. W. Consortium, et al., The rdf data cube\nvocabulary (2014).\n[65] D. C. M. Initiative, et al., Dublin core metadata\nelement set, version 1.1 (2012).\n[66] M. Ledvinka, P. Kremen, Jopa: Accessing ontologies\nin an object-oriented way., in: ICEIS (2), 2015, pp.\n212\u2013221.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "PROVENANCE: An intermediary-free solution for digital content verification", "author": ["B Yousuf", "MA Qureshi", "B Spillane", "G Munnelly"], "pub_year": "2021", "venue": "arXiv preprint arXiv \u2026", "abstract": "The threat posed by misinformation and disinformation is one of the defining challenges of  the 21st century. Provenance is designed to help combat this threat by warning users when"}, "filled": false, "gsrank": 406, "pub_url": "https://arxiv.org/abs/2111.08791", "author_id": ["puaMYGEAAAAJ", "kVYjV4sAAAAJ", "auYYF8cAAAAJ", "61CFGhcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:9ajvf4DdmdsJ:scholar.google.com/&output=cite&scirp=405&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=9ajvf4DdmdsJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 10, "citedby_url": "/scholar?cites=15823922309714913525&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:9ajvf4DdmdsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2111.08791"}}, {"title": "Non-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites", "year": "2024", "pdf_data": "Non-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nPink slime news sites are politically polarized Web sites controlled by partisan national organizations that\nmasquerade as local news. Instead of authentic community reporting, these sites rely on automatedalgorithms and APIs to fill in news articles between their politically charged messaging aimed atinfluencing votes. Over 1,000 of these sites have been identified, and the creator of the largest pink slimeorganization, Metric Media, has a goal of adding 15,000 more. Current methods of discovering new pinkslime sites remain challenging and involves a tedious IP address lookup process to find new sites within analready existing network. This research proposes a semi-supervised learning methodology for detectingemerging pink slime sites within Facebook groups. It develops a non-credibility score as a metric torepresent the trustworthiness of a news domain. With assigned scores to news domain, this research thenanalyses the network analysis of the Facebook pages that share content linking to pink slime sites. The non-credibility score allows researchers to efficiently survey the social media landscape to find new sources ofpink slime as they emerge within the U.S. news landscape. This paper demonstrates the importance of anon-credibility score as a measure to determine the credibility of a news site through machine learningvalidation and then applies the methods to a recent dataset for the discovery of new pink slime sites.\nContentsIntroduction\nResearch questions\nLiterature review\nMethodology\nExploratory network analysis\nNon-credibility score (NCS)\nPredicting news category through machine learning\nResults\nExternal validation to 2022 U.S. midterm elections dataset\nU.S. 2022 midterm elections\nLimitations & future work\nImplications\nConclusions\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nIntroduction\nSince 2019, there has been a rapid spread of regional news sources that casual viewers have a hard time\ndifferentiating from reliable local news sources (Bengani, 2019). These news sources were dubbed \u201cpinkslime\u201d by the journalist Ryan Smith in 2012 drawing a comparison between the automated, low-quality,partisan reporting to meat producers adding cheap additives to beef (Tarkov, 2012). The term \u201cpink slimenews\u201d reflects adding cheap reporting to a self-reported news outlet. There is reason to be fearful of falsereporting that purports to serve a particular region: while one in five local newspapers have closed in thepast 15 years (Takenaga, 2019), American trust in local news organizations has remained higher than thatof national news organizations with at least 75 percent of people trusting the reporting of local newsorganizations (Gottfried and Liedke, 2021). This is exacerbated by the fact that half of all U.S. countieshave only one local newspaper (Abernathy, 2018). To exploit the trust in and dearth of local newsreporting, organizations like Metric Media LLC have created almost 1,000 local news sites (Bengani,2020), many times taking advantage of this trust by pushing national political agendas through whatordinary Americans would see as community news. Most of these low-credibility news are spread throughautomated means: at least 47 percent of stories shared on 189 Metric Media sites within a two-week spanwere attributed to automated means (Bengani, 2019).\nPink slime organizations, like Metric Media, that control vast swaths of pink slime sites do not appear to\nhave foreign ties (Bengani, 2021), but they are currently financed by political candidates and politicalaction committees with the hope of swaying election results. Alex Stamos, Director of the Stanford InternetObservatory, iterated that these domestic actors with questionable, undisclosed funding sources are aserious threat to an election\u2019s integrity and outcome (Murphy and Venkataramakrishnan, 2020).Unfortunately, not many methods exist to discover pink slime Web sites at scale besides a tedious IPaddress lookup process seeded by sites of an existing known network or manual discovery (Bengani, 2019).\nPink slime news sources do not exist in silos. Many of the known sources of pink slime have their own\nassociated social media accounts on social media platforms like Facebook to amplify the spread of themessaging to the community. The names of these sites frequently have the targeted community in thedomain name. Research shows that pink slime sites are spread on Twitter, Facebook, and Reddit (Lepird, et\nal., 2024). Three in ten Americans get their news from the social media platform Facebook (Schaeffer,2024), but not all of this news is coming from quality news sources; 15 percent of referrals to fake newssites are coming from Facebook (Guess, et al. , 2020). Therefore, in this paper, we focus on data from\nFacebook that links to externals URLs, which is an important way to find new pink slime sites.\nIn order to identify pink slime sites, this paper takes an algorithmic approach to determine the credibility of\nnews domains based on the network of the public Facebook pages that are sharing the links with theirfollowers. This study uses a dataset surrounding the 2020 U.S. presidential elections and the ReOpenmovement of the COVID-19 pandemic for the feature engineering within the algorithm and validate theimportance of the network features of shared domains. We further propose a non-credibility score (NCS) asa network feature, that can be used as a ranking statistic for a fast human-in-the-loop analysis of tens ofthousands of domains. Additional features, including reactions to the posts that share the news domain andhow frequently the domains appear in the dataset are included in a machine learning model to predict thelabels of the news sites shared ( i.e., pink slime, real news, low-credibility news). Finally, we apply our\nalgorithm to the 2022 U.S. midterm election dataset and analyze tens of thousands of news domains touncover new sources of pink slime.\nResearch questions\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nIn our study of the data acquired from Facebook, we use the following research questions to guide our\nanalysis:\n1.Can we use our insights into a pink slime\u2019s network spread to define a variable that captures a news\nWeb site\u2019s likelihood of actually being pink slime?\n2.Can we show that this new variable is effective at finding pink slime?\nLiterature review\nPink slime refers to a combination of algorithmic and manual journalism, mostly as news focused on a\nspecific geographic area (Cohen, 2015). Many of these news sites are algorithmically generated, boastingsimilar content, layouts, and origins, and their volume and spread are of concern for politicalmisinformation is spread through these sites (Burton and Koehorst, 2020).\nOne of the leading methodologies in pink slime research is developed by Priyanjana Bengani, a senior\nresearch fellow at Columbia Journalism School\u2019s Tow Center for Digital Journalism. In order to find pinkslime sites, she identified which Web sites used similar tracking identifiers, IP addresses, and servers(Bengani, 2019). The resulting list of pink slime sites is publicly available (Tow Center for DigitalJournalism, n.d.), and is used in this paper as a starting point for news category labeling.\nBengani mapped out the IP addresses and servers that these news domains utilized to find relationships\nbetween varied organizations. While she found it was less common for pink slime sites to share GoogleAnalytics IDs, a handful of Metric Media\u2019s sites shared three of these IDs. Franklin Archer, LocalGovernment Information Services (LGIS), and LocalityLabs shared three other unique identifiers. Otheridentifiers \u2014 like Quantcast and NewRelic IDs \u2014 were shared across various pink slime networks(Bengani, 2019). Other researchers have also uncovered campaigns of malicious actors using clusters ofseemingly unrelated Web sites that use the same third-party analytics trackers, thus systematically querying,identifying, and isolating identifiers from malicious pages to discover new domains (Starov, et al. , 2018).\nThe process of finding new pink slime sites involves manual entry of domains into platforms that clustersites with shared identifiers ( i.e., Google Analytics, ClickTale). This method would frequently lead to dead\nends and be limited to finding sites within the control of known pink slime organizations. Finding newsources of pink slime not controlled by the companies that Bengani identified in her research is anunanswered question.\nOther academic sources can serve as an inspiration to understanding methods to find relevant Web sites of\ninterest. PageRank has been adapted by other researchers to more generally find false news domains byusing similarity in the text content to other, known false news domains (Woloszyn and Nejdl, 2018). Othershave adapted this method to citation networks and ranking academic journals (Maslov and Redner, 2008) orTwitter users who serve as authorities to lend credibility to the events about which they tweet (Gupta, et al. ,\n2012).\nIn Kleinberg\u2019s HITS (Hyperlink-Induced Topic Search) algorithm, he established a model that analyzed\nWeb sites within a specific topic and, based on their linkages, assigned them values labeling them as anauthority (a site that links to other authorities) or a hub (a site that links to many related authorities)(Kleinberg, 1999). Broadly, the relationship between hubs and authorities is intertwined \u2014 a higher hubscore indicated that the sites pointing to it had a high authority score.\n\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nMethodology\nThis paper aims to find new sources of pink slime beyond the known set of organizations using network\nmeasures to expand the search space. We describe our data collection and annotation methodology, theproposed non-credibility score (NCS) for labeling unknown sites. We then construct machine learningmodels to see if the NCS is able to accurately classify sites.\nData descriptionIn this paper, we use data from Facebook pages that contain posts that were likely to be shared with a link\nto a pink slime Web site in 2020. This capitalizes from the surge of political discussion due to the U.S.elections, because many pink slime sites publish information about local politics (Moore, et al. , 2023). At\nthe start of the COVID-19 global pandemic, the \u201creopen\u201d phrase was used to protest establishments frombeing closed. Therefore, we searched for Facebook posts that used the keywords \u201creopen\u201d. We alsocollected another dataset with the keywords \u201celections\u201d to encompass the 2020 U.S. presidential electionsand the string of regional elections that coincided with it. We used the social monitoring tool CrowdTangle\n(Meta, 2024) to collect posts containing the phrase \u201creopen\u201d or \u201celections\u201d and having URLs that link toWeb sites outside the platform that were made on public Facebook pages for the entire year of 2020. Thisdataset includes 3,223,269 posts that link to 61,692 unique domains. It contains posts that were mostlyfocused within the United States.\nNews category annotationOnce the dataset of Facebook posts was acquired from CrowdTangle, we sought to label the news sites into\none of three categories: Real news, pink slime, and low-credibility news.\nReal news are news sites with professional journalistic practices, such as the BBC news site(University of California Berkeley Library, 2024).\nPink slime news are news that masks as local news, often publishing politically-related articles withthe use of some automation (Moore, et al. , 2023).\nLow credibility news are misleading news that can provide false information and thus deceive readers(Ng and Taeihagh, 2021).\nDue to the nature of our search and collection, each post has a URL to an external Web site. The links to theURLs were processed to extract the URL\u2019s domain using the tldextract package [1\n]. That is,\n\u201chttps://www.nytimes.com/section/politics\u201d would become \u201cnytimes.com\u201d. Each site is then annotated witha label representing one of the three news categories. These labels were added by matching the extracteddomain with a pre-compiled Media Thesaurus that labels known news domains with their news typeclassification via publicly available lists: (1) from Media Bias/Fact Check (Media bias/Fact check news,2023) which assigns ratings of a news outlet\u2019s factuality and credibility of reporting; (2) the Columbia\nJournalism Review  as a source for hundreds of pink slime news outlets (Tow Center for Digital Journalism,\nn.d.); (3) a Github Repository combining unreliable news sources form the Snopes Field Guide, Wikipedia,and other domains (hearvox, n.d.); (4) a Github Repository (Clemm von Hohenberg, et al. , 2021) with a list\nof the most commonly visited Web domains and most commonly tweeted news domains by U.S. politiciansand their news category labels. This Media Thesaurus was then deconflicted to resolve differences in labelsby labeling a news source with differing labels as low-credibility news. News sites that are not within theMedia Thesaurus were annotated as \u201cunlabeled.\u201d\nExploratory network analysis\nWe begin our analysis with an exploratory network analysis of the news domain sharing structure to better\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nunderstand how these sites are shared on Facebook. We aim to programmatically find pink slime sources in\nan efficient manner. We first extract the Facebook Pages that are sharing known sources of pink slime (Tow\nCenter for Digital Journalism, n.d.) from our dataset. Next we construct a network diagram, where there areparent organizations of pink slime domains represented as green nodes, and Facebook Pages sharing thosesites represented as grey nodes. This visualization is presented in Figure 1\n.\nThrough the network visualization, we observe that while most Facebook Pages share domains thatoriginate from a single parent organization, there are clusters of largely local community Facebook Pagesthat share multiple pink slime domains that originate from more than one parent organization. Overall, fromthe data collected, 20,065 Facebook pages shared over 1.4 million posts that linked to these five knownparent organizations. Overall, 13.4 percent of these Facebook pages shared news linking to more than onepink slime parent organization.\nFigure 1:  Network visual of pink slime domains. Grey nodes represent the Facebook Pages sharing pink\nslime Web sites under the control of the various pink slime parent organizations (green nodes).\nIn layman\u2019s terms, the kinds of people sharing pink slime from one parent company are likely to also besharing pink slime from other parent companies, a statement backed up by pink slime research (Lepird,  et\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nal., 2024). This exploratory background analysis informs the methodology in this paper that there are\nFacebook pages geared for local communities that share information originating from multiple pink slime\nparent organizations. In searching Facebook pages for topics pertaining to local communities, some of thesepink slime Web sites can be found. Using this knowledge, we develop a network-based scoring systemcalled the non-credibility score described in the next section to evaluate the credibility of a given newsdomain. We then put the score into a machine learning model to determine if it is a successful method forcategorizing news domains.\nNon-credibility score (NCS)\nIn order to address our first research question \u2014 \u201cCan we use our insights into a pink slime\u2019s network\nspread to define a variable that captures a news Web site\u2019s likelihood of actually being pink slime?\u201d, foreach unlabeled news site, we annotate it with a non-credibility score (NCS). This score ranges from [0,1]and provides an insight towards the extent of credibility of the news site, based on the other sites that arealso shared within the Facebook page that the news site came from.\nFigure 2\n illustrates how non-credibility scores for the news sites are assigned based on the known content\nshared by Facebook pages, which are characterized by a non-credible sharer score each. It borrows ideas\nfrom network science, constructing a network graph where there are two types of nodes: Facebook pagesand news sites. Links between Facebook pages and news sites indicates that the news site was shared on theFacebook page. Now if we collapse this view, constructing a network that linked news sites to news sites bythe Facebook pages that shared them (News sites x Facebook page x News site), the NCS for a givendomain represents the percentage of first-degree neighbors that are known sources of pink slime or low-credibility news. If we don\u2019t know if a Web site is pink slime, we check to see if the people sharing it arealso sharing known sources of pink slime.\nFigure 2:  Illustration of calculating non-credible sharer scores for Facebook pages and non-credibility scores\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nfor unlabeled news domains.\nOur proposed NCS algorithm adapts Kleinberg\u2019s HITS algorithm and sets about viewing certain Facebook\npages as hubs of credible news and building out the network of authorities that they share. Given the lowprevalence in pink slime sites in general social media sharing, finding pink slime sites via these routeswould be akin to finding an incredibly small needle in a haystack. An approach modeled off HITS lookingat relevant ( i.e., pertaining to local politics) social media sharing would be more amenable to a search for\npink slime sites than PageRank.\nThe methodology for calculating NCS involves creating network features of news domains to signal their\ncredibility, that is measuring hubs sharing authorities and what other authorities those hubs were sharing. Inour context, Facebook pages act as hubs and the domains that they share are the authorities.\nTo begin calculating the NCS, each Facebook page in the dataset was given a non-credible sharer score\n(NCSS). This score ranges from [0 to 1] and indicates the proportion of content shared on the page thatoriginated from a known source of low-credibility or pink slime news. The higher the NCSS, the lower thecredibility of the Facebook page. This equation is described below.\nNext, we score the unlabeled domains by averaging the NCSS of the pages that share the domain. This isdescribed in the equation below.\nPredicting news category through machine learning\nIn order to answer our second research question \u2014 \u201cCan we show that this new variable is effective at\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nfinding pink slime?\u201d, we verify the validity of using the NCS to find pink slime by constructing a machine\nlearning model to algorithmically differentiate between pink slime, low-credibility news, and real news;\nbased off our analysis of how pink slime spreads, we expect that the NCS will help assign correct newslabels to unknown news sites. To do so, we first perform feature engineering to extract input features. Table\n1 shows the features that are selected as inputs for the machine learning model. These features provide\nindications of the credibility and virality of news domains.\nFeatures that indicate virality include the average number of likes that the posts sharing the domain\nreceived, number of unique Facebook pages that share the domain, and number of occurrences the domainappears within the dataset.\nTable 1: List of features included in the model\nfor each domain.\nFeature Description Type\nCredibility-basedfeatures\nNon-\ncredibilityscore (NCS)Measure of credibility ofnews siteFloat\n[0,1]\nVirality-basedfeatures\nAverage\nnumber oflikesAverage number of likesposts sharing the domainreceivedFloat\n[0,inf)\nUnique pagesNumber of Facebook Pagesthat share the domainInteger\n[0,inf)\nNumber ofoccurrencesNumber of times thedomain appears in thedatasetInteger\n[0,inf)\nFor the machine learning experiments, the dataset was split into a 70:30 split using stratified sampling,which ensures the proportion of pink slime, real news, and low-credibility news are similar across thetraining:testing dataset. The features of the 70 percent training data describing the news domains are formedinto a series of vectors to see if they can accurately predict the legitimacy of the 30 percent withhelddomains. The output is a news category label: pink slime, real news, or low-credibility news. We perform aseries of experiments using sklearn machine learning package [2\n] in Python. Following the experiments, we\nthen analyze the feature importances using sklearn\u2019s feature_importance function to interpret the strength ofthe features in the classification tasks.\nResults\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nIn this paper, we analyzed news domains that posted on Facebook groups related to elections and the\nReOpen movement. By matching the domain names with a Media Thesaurus that we constructed, we\ndifferentiated the news domains into pink slime, low credibility news, real news, and unlabeled domains.Table 2\n shows the statistics of the collected dataset. ANOVA testing on the average number of times each\ndomain is shared and the average number of unique pages a site appears in reveals that the distribution ofthe news types are significantly different (F-score of 78.9 and 53.2, respectively, both resulting in p-values<0.0000.) A vast majority (96 percent) of the dataset is currently unknown or unlabeled news sites per theMedia Thesaurus, which is a compilation of lists of news sites labels from various online sources. Thisreiterates the difficulty in finding and identifying pink slime domains (or even low-credibility news) with avast swath of unlabeled domains, not knowing where to start, requiring manually reviewing tens ofthousands of URLs. Manually visiting each of these news sites would take an analyst weeks if not longer.\nTable 2: Statistics for input dataset.\nNumber\nof\nunique\ninstances\n(%)Average\nnumber of\ntimes each\ndomain is\nsharedAverage\nnumber of\nunique\npages a site\nappears in\nLabeledpink slime30 (0.05) 71.6 3.1\nLabeledlowcredibilitynews201\n(0.32)251.3 9.17\nLabeledreal news1,941\n(3.13)491.3 47.20\nUnlabeleddomains59,751\n(96.5)35.6 3.08\nThe vast majority (96 percent) of the domains in this dataset are to currently unknown or unlabeled newssites per the Media Thesaurus. This reiterates the problem of finding vast swaths of unlabeled domains andnot knowing where to start when manually reviewing tens of thousands of URLs to find a handful of pinkslime (or even low credibility news) sites. Of the labeled domains, only a small amount are known sourcesof pink slime or low credibility news, indicating the scale of the known versus the unknown. This indicatesthat while there are groups and researchers actively working to compile and label the credibility of sourcesof news, it is not sufficient, and thus an automatic labeling and search procedure needs to be developed,thus lending weight to our methodology.\nIn terms of domain sharing patterns, real news domains occur most frequently (492.3 times), with low-\ncredibility news domains occurring approximately half as many times (251.3 times), and pink slimedomains were embedded within an average of 71.6 posts on Facebook pages. The lower occurrence of pinkslime pages is likely due to more targeted, smaller audiences that this type of news is designed to attract.\nTo characterize the credibility of news sites, we introduced the new network-based feature called the non-\ncredibility score (NCS) for rating the credibility of a news domain. This feature is calculated based on theother news domains that are shared within the Facebook page that shared the news domain in focus. Wepresent the average NCS for different news types in Table 3\n. The average NCS value for pink slime and\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\n]low credibility news are very close. Pink slime overlaps a great deal with low credibility news: they are, by\ndefinition, low-credibility reporting that focuses on a specific geographical area (Cohen, 2015). With this\ndefinition as a backdrop, the calculation where pink slime and low-credibility news have very similar NCSlends weight to our NCS algorithm set-up and calculations.\nTable 3: Average non-credibility scores.\nNews domainsAverage non-\ncredibility score\n(NCS)Standard\ndeviationn\nLabeled pinkslime0.520 0.459\nLabeled lowcredibilitynews0.503 0.384\nLabeled realnews0.002 0.009\nUnlabeleddomains0.001 0.014\nTable 4\n presents the macro accuracy results of different variations of machine learning models that output\nnews category results, sorting a news domain into pink slime, real news, low-credibility news. The macroaccuracy score calculates the performance metrics of each class ( i.e., news category) and returns the\narithmetic mean of all classes. Unsurprisingly, assigning all of the values to the dominant class (real news),as the Naive Bayes classifier did, resulted in the lowest precision, recall, and F1 score. We use the macroscore because there is a huge class imbalance within the collected dataset, and the macro function accountsfor class imbalance, in which there are unequal number of each news category. By including the attributesin Table 2\n to the classifier, we find the precision more than doubles in classifiers like the\nRandomForestClassifier, GradientBoostingClassifier, and XGBoostClassifier. We observe modest increasesin recall when including the model attributes which would indicate that false negatives are a more commonoccurrence than false positives. While the overall accuracy value is about 64 percent, the intent of this\nclassifier is to use the classification as a start point of analysis to find higher likelihood domains faster,before performing deeper investigation.\nTable 4: Macro average accuracy results for\nnews category prediction model.\nPrecision RecallF1-\nscore\nNa\u00efve Bayes 0.30 0.33 0.32\nLogistic Regression 0.47 0.34 0.33\nRandom Forests 0.64 0.36 0.37\nGradient BoostedClassifier0.64 0.36 0.36\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nXGBoost 0.64 0.36 0.36\nAverage 0.60 0.36 0.36\nWe further extracted the strength of the best performing model, XGBoost, in classifying each news domain\ntype through the ROC curves. XGBoost is a model architecture that typically does well in data sciencesetting because it uses an efficient and optimized gradient boosting tree method to classify data. ROCcurves plots model sensitivity by showing the performances of the models across varying classificationthresholds, and curves with higher area under the curve indicate better performances. The curves arepresented in Figure 3\n. Overall, the Area Under the Curve (AUC) of 0.79 in classifying pink slime sites\nprovides an acceptable value (Hosmer and Lemeshow, 2000), lending weight to our model heuristic.\nFigure 3  illustrates the strength of the model in predicting pink slime (despite the low occurrence) through\nthe ROC curve. Overall its area under the curve (AUC) of 0.79 provides an acceptable value to use the\nnetwork features of the model as a ranking heuristic in large scale data analysis (Hosmer and Lemeshow,2000). The similarity in the AUC for all three news categories to be around 0.77 shows the ability of themodel to be generalizable to at least these three different news types. When looking at how well the modelcould predict the presence of real news, the ROC is slightly stronger with an AUC of 0.79.\nFigure 3:  ROC curves for the three classes of news types predicted in the XGBoost model.\nNote: Larger version of Figure 3 available here.\nThe best performing model is the XGBoost model. The feature importances are reflected in Table 5 . The\nstrongest feature is the NCS, indicating the influence of network features and domain similarity acrossFacebook pages. The other attribute, with 25 times less importance, is the average number of likes a postfrom the domain received. This top two features indicate how the combination of network and viralityfeatures are important to predict news labels. With the NCS combined with other features extracted fromthe posts, we can quickly ascertain whether a set of currently unlabeled news domains is likely to be pinkslime based on the type of news shared by the Facebook Pages sharing the site. This method thus reducesthe manual requirement for identifying and evaluating news categories, and thus speeds up the time taken toclassify news domains.\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nTable 5: Feature importance of the XGBoost\nmodel.\nFeature Importance\nNon-credibility score 9.0e10-3\nAverage number likes 9.8e10-4\nNumber of occurrences -8.4e10-4\nUnique pages -9.8e10-4\nExternal validation to 2022 U.S. midterm elections dataset\nFor an external validation, we applied our methods to a more recent dataset to prove the longevity of our\nfeature engineering technique. This dataset involves Facebook pages posting about the 2022 United Statesmidterm elections, which we analyzed to find new and emerging sources of pink slime. This datasetincluded 10,223 domains which would be challenging to analyze using visual inspection alone. We firstannotated the dataset for known news sites, then performed feature engineering to calculate the NCS andother credibility and virality features, before applying the machine learning model that we had trained in theprevious section. We then evaluated the labels of the machine learning model against the known labels.\nU.S. 2022 midterm elections\nThe top three labeled pink slime news articles in this dataset by number of likes included ones with the\nheadlines, \u201dTammy Baldwin Gets Republicans to Back a Marriage Equality Bill, Making Final ApprovalLikely\u201d (published on Up North News, a site owned by the Courier Newsroom that targets Wisconsin\nresidents), \u201cRepublicans Don\u2019t Want Black, Working-Class Voters To Turn Out\u201d (published on Cardinal\nand Pine , a North Carolina-focused site owned by the Courier Newsroom) , and \u201cA Victory Over\nExtremism: Josh Shapiro Wins Pa. Governor\u2019s Race\u201d (published on the Keystone Newsroom, another\nCourier Newsroom site). The Courier Newsroom appears to be a liberal response to some of the 2020 pinkslime organizations that were funded by political conservatives. While the number of pink slime sites with aconservative backing outnumber those with a liberal backing, the liberal sites are receiving the mostinteraction when their articles are shared on Facebook.\nTable 6: Most commonly shared sites and their characteristics.\nDiscovered domainTargeting\nAmerican\nregionNo\npaywall<50%\narticles\nhas\nauthors\nlistedOwned\nby\nlarger\nentityHas\noperations\nin other\nstates\nGeorgiastarnews.com \u2611 \u2611 \u2611\u2611 \u2611\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nColchestersun.com \u2611 \u2611 \u2611\nTexasscorecard.com \u2611 \u2611\nBaltimoresun.com \u2611\nCaliforniajournal.com \u2611\nShelbycountyreporter.com \u2611\nColoradosun.com \u2611\nBased on Table 6  of discovered domains and their characteristics, it\u2019s safe to assume that\ngeorgiastarnews.com should be included as a new source of pink slime. Further investigating on the site\nshows that it is owned by the same media group (Star News Digital Media) that owns The Tennessee Star,\nThe Ohio Star, The Michigan Star, The Minnesota Sun, The Virginia Star, The Georgia Star News, TheFlorida Capital Star, The Arizona Sun Times, The Wisconsin Daily Star, The Pennsylvania Daily Star , and\nThe Connecticut Star . The Georgia Star appeared in 27 Facebook posts, most of which received two or\nfewer interactions (likes, shares, or comments). The most interacted with post (five interactions) wassharing an article with the title, \u201cGeorgia Moves Forward with Plan to Implement Work Requirements forMedicaid Coverage.\u201d\nThe most prominent pink slime sites examples in the dataset are presented in Table 6\n. In addition to finding\npink slime sites that are targeting local regions within the U.S., this model can also find previously\nuncategorized domains that have similar characteristics as other low-credibility news sites. Therefore, ourconstructed machine learning model is useful to giving a first-cut prediction of the category of a given newssite, which will greatly aid analysts in narrowing down a list of domains for further investigation.\nLimitations & future work\nThe primary limitation of this research is that not all unlabeled news sites are of unknown credibility. In\norder to combat this, downstream work includes performing exploratory data analysis on the unlabeledshare sites in the dataset to identify any known sites, or cross-match sites with fact checking sites thenadding the new label into the labeled news source thesaurus. This process will remove the ambiguity of thesite label through consolidation of news labels from known sources.\nThis research is dependent upon a set of human labelers to \u201cseed\u201d the system with labels of low-credibility\nnews, real news, or pink slime for different domains. This list must be continually updated with thechanging news media landscape, to add newly created sites and drop non-functioning sites. Theseindividuals must also perform human-in-the-loop analysis once the scores are generated for the domains inorder to visit those sites with the highest non-credibility scores.\nAdditional limitations include the reliance on large data pulls from social media sites: recent events such as\na drastic increase in the cost of API pulls have called into question the future of the Twitter API, remindingresearchers that data sources like CrowdTangle should not be taken for granted nor assumed accessible forfuture research. Unfortunately, Meta recently announced that they will be discontinuing the CrowdTangleservice in favor of the Meta Content Library. Whether this new platform provides the necessary metadata toconduct these analyses remains to be seen. While this paper focused on Facebook data, future workincludes extending the methods to other types of aggregator sites (like Reddit) across a variety of casestudies. Additionally, any future news-sharing platform that has authors and news links shared could applythis methodology.\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nWhile the phenomenon of pink slime journalism is pronounced in the United States, pink slime journalism\npractices are not necessarily unique to the U.S. There are likely similar practices in other countries withtheir own cultural variations that should be investigated to provide insights into the extent of the practice oflow-credibility local news.\nFuture work will also include analysis of the directionality with which pink slime sites are spread across\ndifferent social media platforms, which provides insights on information spread through news acrossplatforms. While the platform we collected our data from, CrowdTangle is set to be discontinued in August2024, our methodology is generalizable, and should the replacement of CrowdTangle provide similarinformation, our scoring metric can still be used. In addition, this work uses a network-based scoringmethod, and thus is applicable to other platforms where similar network data can be retrieved.\nThe NCS is an important metric that can be expanded by researchers with a larger media thesaurus to seed\nmore news sites and continue to find these pink slime sites that infiltrate the news ecosystem. Furthermore,it can be applied professionally by social media platforms to downrank a news site that first appears on agiven platform with a low NCS.\nImplications\nThe non-credibility score improves our ability to identify pink slime news sites by providing a quantifiable\nmetric to evaluating the credibility of a site. While the dataset from CrowdTangle is a specific data format,the framework is meant to be generalizable. Any individual with a dataset of news sites shared by actorscan apply this framework to quickly sift through millions of news domains and rank the likelihood that agiven news site is low credibility or pink slime by sorting by descending NCS. For analysis overwhelmedby large datasets, they can perform the network calculation to find the most concerning websites toinvestigate. Beyond analysts wanting to searching for fake local news, the NCS provides the ability to alsofind any sort of potential low credibility news representing a threat to an online ecosystem (perhaps alsofiltering by an engagement metric if available to see how much impact the site has had).\nConclusions\nThis paper proposes a novel method to score and rank news domains posted on Facebook pages as\nmisinformation versus authentic. This method makes use of network analysis techniques and proposes anon-credibility score as a metric to indicate the authenticity of a domain based on other domains sharedwithin the same Facebook page. This paper then validates the importance of the metric through aclassification algorithm that categorizes news domains as real news, low-credibility news, or pink slimenews. It also applies the algorithms to a recent dataset set in the U.S. 2022 midterms elections to help ananalyst uncover previously unlabeled pink slime domains.\nThe primary function of developing a non-credibility score and performing feature engineering on the\ndatasets was to apply these measures to new datasets to quickly rank and assess probable new pink slimenews sites. As presented earlier, labeled pink slime sites are a small minority of labeled news sources in agiven dataset. Not only are pink slime news sites obscure, they are also good at masquerading as localnews. The general results for predicting pink slime news sites using our machine learning methods showspromising accuracy and AUC curves. The model itself is intended to apply the derived network attribute ofNCS to the dataset to be able to retrieve a more target list of potential new pink slime sites, much likeMaslov and Redner\u2019s (2008) urge for a human in the loop when applying PageRank to new systems. This\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nmetric provides a repeatable metric to compare the trustworthiness of news sites \u2014 in particular, sites for\nwhich this information does not exist by current formal means.\nThe main goal of this work is to find an efficient and repeatable methodology of identifying pink slime\nsources. We hope that the better and quicker identification of pink slime sources can facilitate furtherscholarship regarding local and low-credibility journalism and consumption patterns of this category ofnews sites. \nAbout the authors\nChristine Sowa Lepird is a Ph.D. student in Carnegie Mellon University\u2019s Software and Societal Systems\nDepartment (S3D) in the School of Computer Science.E-mail: csowa [at] andrew [dot] cmu [dot] edu\nLynnette Hui Xian Ng is a Ph.D .student in Carnegie Mellon University\u2019s Software and Societal Systems\nDepartment (S3D) in the School of Computer Science.E-mail: lynnetteng [at] cmu [dot] edu\nKathleen M. Carley  is a professor in the School of Computer Science in the Institute for Software\nResearch at Carnegie Mellon University, an IEEE Fellow, the Director of the Center for Computational\nAnalysis of Social and Organizational Systems (CASOS), and the CEO of Netanomics. She is the 2011winner of the Simmel Award from the International Network for Social Network Analysis and the 2018winner of the National Geospatial-Intelligence Agency Academic Award from GEOINT.E-mail: kathleen [dot] carley [at] cs [dot] cmu [dot] edu\nAcknowledgements\nThis work was supported in part by the U.S. Office of Naval Research (ONR) Award N00014182106,\nKnight Foundation, Center for Computational Analysis of Social and Organizational Systems (CASOS),and Center for Informed Democracy and Social-cybersecurity (IDeaS). The views and conclusionscontained in this paper are those of the authors and should not be interpreted as representing officialpolicies, either expressed or implied, of the ONR or the U.S. government.\nNotes\n1.\nhttps://pypi.org/project/tldextract/ , accessed 18 August 2024.\n2.https://scikit-learn.org/stable/ , accessed 18 August 2024.\nReferencesPenelope Muse Abernathy, 2018. The expanding news desert . Chapel Hill, N.C.: University of North\nCarolina Press; see also https://www.usnewsdeserts.com\n, accessed 18 August 2024.\nPriyanjana Bengani, 2021. \u201cThe Metric Media Network runs more than 1,200 local news sites. Here are\nsome of the non-profits funding them,\u201d Columbia Journalism Review  (14 October), at\nhttps://www.cjr.org/tow\\_center\\_reports/metric-media-lobbyists-funding.php/ , accessed 18 August 2024.\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nPriyanjana Bengani, 2020. \u201cAs election looms, a network of mysterious \u2018pink slime\u2019 local news outlets\nnearly triples in size,\u201d Columbia Journalism Review  (4 August), at https://www.cjr.org/analysis/as-election-\nlooms-a-network-of-mysterious-pink-slime-local-news-outlets-nearly-triples-in-size.php , accessed 17\nAugust 2023.\nPriyanjana Bengani, 2019. \u201cHundreds of \u2018pink slime\u2019 local news outlets are distributing algorithmic stories\nand conservative talking points,\u201d Columbia Journalism Review  (18 December), at\nhttps://www.cjr.org/tow\\_center\\_reports/hundreds-of-pink-slime-local-news-outlets-are-distributing-\nalgorithmic-stories-conservative-talking-points.php/ , accessed 18 August 2024.\nAnthony G. Burton and Dimitri Koehorst, 2020. \u201cResearch note: The spread of political misinformation ononline subcultural platforms,\u201d Harvard Kennedy School Misinformation Review  (25 September).\ndoi: https://doi.org/10.37016/mr-2020-40\n, accessed 18 August 2024.\nBernhard Clemm von Hohenberg, Ericka Menchen-Trevino, Andreu Casas, and Magdalena Wojcieszak,2021. \u201cA list of over 5000 US news domains and their social media accounts, GitHub.\ndoi: https://doi.org/10.5281/zenodo.7651047\n, accessed 18 August 2024.\nNicole S. Cohen, 2015. \u201cFrom pink slips to pink slime: Transforming media labor in a digital age,\u201dCommunication Review , volume 18, number 2, pp. 98\u2013122.\ndoi: https://doi.org/10.1080/10714421.2015.1031996\n, accessed 18 August 2024.\nManish Gupta, Peixiang Zhao, and Jiawei Han, 2012. \u2018Evaluating event credibility on Twitter,\u2019Proceedings of the 2012 SIAM International Conference on Data Mining , pp. 153\u2013164.\ndoi: https://doi.org/10.1137/1.9781611972825.14\n, accessed 16 October 2023.\nJeffrey Gottfried and Jacob Liedke. 2021. \u201cPartisan divides in media trust widen, driven by a decline amongRepublicans,\u201d Pew Research Center  (30 August), at https://www.pewresearch.org/fact-\ntank/2021/08/30/partisan-divides-in-media-trust-widen-driven-by-a-decline-among-republicans/ , accessed\n18 August 2024.\nAndrew M. Guess, Brendan Nyhan, and Jason Reifler. 2020. \u201cExposure to untrustworthy Web sites in the\n2016 US election,\u201d Nature Human Behaviour, volume 4, number 5 (2 March), pp. 472\u2013480.\ndoi: https://doi.org/10.1038/s41562-020-0833-x , accessed 18 August 2024.\nhearvox, n.d. \u201cUnreliable news sites (UNS),\u201d at https://github.com/hearvox/unreliable-\nnews/blob/master/README.md , accessed 18 August 2024.\nDavid W. Hosmer and Stanley Lemeshow, 2000. \u201cArea under the ROC curve,\u201d In: David W. Hosmer andStanley Lemeshow. Applied logistic regression . Second edition. New York: Wiley, pp. 160\u2013164.\ndoi: https://doi.org/10.1002/0471722146\n, accessed 18 August 2024.\nJon M. Kleinberg, 1999. \u201cAuthoritative sources in a hyperlinked environment,\u201d Journal of the ACM ,\nvolume 46, number 5, pp. 604\u2013632.doi: https://doi.org/10.1145/324133.324140\n, accessed 18 August 2024.\nChristine Sowa Lepird, Lynnette Hui Xian Ng, Anna Wu, and Kathleen M. Carley, 2024. \u201cWhat news isshared where and how: A multi-platform analysis of news shared during the 2022 U.S. midterm elections,\u201dSocial Media + Society  (18 April).\ndoi: https://doi.org/10.1177/20563051241245950\n, accessed 18 August 2024.\nSergei Maslov and Sidney Redner, 2008. \u201cPromise and pitfalls of extending Google\u2019s PageRank algorithmto citation networks,\u201d Journal of Neuroscience , volume 28, number 44, pp. 11,103\u201311,105.\ndoi: https://doi.org/10.1523/JNEUROSCI.0002-08.2008\n, accessed 18 August 2024.\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\n\u201cMedia bias/Fact check news,\u201d 2023. \u201cMedia bias/Fact check news,\u201d at https://mediabiasfactcheck.com/ ,\naccessed 18 August 2024.\nMeta, 2024. \u201cCrowdTangle\u201d (16 August), at https://www.crowdtangle.com/ , accessed 18 August 2024.\nRyan Moore, Ross Dahlke, Priyanjana Bengani, and Jeffrey Hancock. 2023. \u201cThe consumption of pink\nslime journalism: Who, what, when, where, and why?\u201d (3 December).doi: https://doi.org/10.31219/osf.io/3bwz6\n, accessed 18 August 2024.\nHanna Murphy and Siddharth Venkataramakrishnan, 2020. \u201cLocal news is drowning in \u2018pink slime\u2019 aheadof US election,\u201d Financial Times  (15 October), at https://www.ft.com/\n, accessed 18 August 2024.\nLynnette H.X. Ng and Araz Taeihagh, 2021. \u201cHow does fake news spread? Understanding pathways ofdisinformation spread through APIs,\u201d Policy & Internet , volume 13, number 4, pp. 560\u2013585.\ndoi: https://doi.org/10.1002/poi3.268\n, accessed 18 August 2024.\nKatherine Schaeffer, 2024. \u201c5 facts about how Americans use Facebook, two decades after its launch,\u201d Pew\nResearch Center  (2 February), at https://www.pewresearch.org/short-reads/2024/02/02/5-facts-about-how-\namericans-use-facebook-two-decades-after-its-launch/ , accessed 18 August 2024.\nOleksii Starov, Yuchen Zhou, Xiao Zhang, Najmeh Miramirkhani, and Nick Nikiforakis, 2018. \u201cBetrayedby your dashboard: Discovering malicious campaigns via Web analytics,\u201d WWW \u201918: Proceedings of the\n2018 World Wide Web Conference , pp. 227\u2013236.\ndoi: https://doi.org/10.1145/3178876.3186089\n, accessed 18 August 2024.\nLara Takenaga, 2019. \u201cMore than 1 in 5 U.S. papers has closed. This is the result,\u201d New York Times (21\nDecember), at https://www.nytimes.com/2019/12/21/reader-center/local-news-deserts.html , accessed 18\nAugust 2024.\nAnna Tarkov, 2012. \u201cJournatic worker takes \u2018This American Life\u2019 inside outsourced journalism,\u201d Poynter\n(30 June), at https://www.poynter.org/reporting-editing/2012/journatic-staffer-takes-this-american-life-\ninside-outsourced-journalism/ , accessed 18 August 2024.\nTow Center for Digital Journalism, n.d. \u201cDomains as of August 3, 2020,\u201d at\nhttps://datawrapper.dwcdn.net/TqILa/2/ , accessed 11 November 2022.\nUniversity of California Berkeley Library, 2024. \u201cReal news/fake news: Real news\u201d (15 August), athttps://guides.lib.berkeley.edu/c.php?g=620677&p=4333237\n, accessed 18 August 2024.\nVinicius Woloszyn and Wolfgang Nejdl, 2018. \u201cDistrustRank: Spotting false news domains,\u201d WebSci \u201918:\nProceedings of the 10th ACM Conference on Web Science , pp. 221\u2013228.\ndoi: https://doi.org/10.1145/3201064.3201083 , accessed 18 August 2024.\nEditorial history\n8 February 2024; revised 30 June 2024; accepted 20 August 2024.\nThis paper is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0\nInternational License .\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites\nNon-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime\nsites\nby Christine Sowa Lepird, Lynnette Hui Xian Ng, and Kathleen M. Carley.First Monday, volume 29, number 9 (September 2024).doi: https://dx.doi.org/10.5210/fm.v29i9.13544", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Non-credibility scores: Relative ranking of news sites shared on social media to identify new pink slime sites", "author": ["CS Lepird", "LHX Ng", "KM Carley"], "pub_year": "2024", "venue": "First Monday", "abstract": "Pink slime news sites are politically polarized Web sites controlled by partisan national  organizations that masquerade as local news. Instead of authentic community reporting, these"}, "filled": false, "gsrank": 407, "pub_url": "https://firstmonday.org/ojs/index.php/fm/article/view/13544", "author_id": ["bSk0ITcAAAAJ", "qcqOlfMAAAAJ", "KeJfN-IAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:WFGUpZr3hzwJ:scholar.google.com/&output=cite&scirp=406&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=WFGUpZr3hzwJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:WFGUpZr3hzwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://firstmonday.org/ojs/index.php/fm/article/download/13544/11676"}}, {"title": "Partisan asymmetries in exposure to misinformation", "year": "2022", "pdf_data": "1\nVol.:(0123456789) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreportsPartisan asymmetries in exposure \nto misinformation\nAshwin Rao1,2*, Fred Morstatter2 & Kristina Lerman 2\nOnline misinformation is believed to have contributed to vaccine hesitancy during the Covid-19 \npandemic, highlighting concerns about social media\u2019s destabilizing role in public life. Previous research \nidentified a link between political conservatism and sharing misinformation; however, it is not clear \nhow partisanship affects how much misinformation people see online. As a result, we do not know \nwhether partisanship drives exposure to misinformation or people selectively share misinformation \ndespite being exposed to factual content. To address this question, we study Twitter discussions \nabout the Covid-19 pandemic, classifying users along the political and factual spectrum based on the \ninformation sources they share. In addition, we quantify exposure through retweet interactions. We \nuncover partisan asymmetries in the exposure to misinformation: conservatives are more likely to \nsee and share misinformation, and while users\u2019 connections expose them to ideologically congruent \ncontent, the interactions between political and factual dimensions create conditions for the highly \npolarized users\u2014hardline conservatives and liberals\u2014to amplify misinformation. Overall, however, \nmisinformation receives less attention than factual content and political moderates, the bulk of users \nin our sample, help filter out misinformation. Identifying the extent of polarization and how political \nideology exacerbates misinformation can help public health experts and policy makers improve their \nmessaging.\nSocial media has become the main source of news for a large portion of the  population1, raising concerns about \nthe quality and reliability of information shared online. These concerns have only grown in urgency with the \nemerging evidence that social media enabled the spread of misinformation and politically polarized content \nabout the Covid-19 pandemic, its toll, mitigation measures, and the efficacy of interventions, therapies and \n vaccines2,3. According to a Pew  Report4, political ideology explains a partisan divide in attitudes about Covid-19 \nand compliance with health  guidelines5, and there is evidence that misinformation has contributed to vaccine \nhesitancy in the US, particularly in the politically conservative  communities6. Since effective response to the \npandemic requires collective action, e.g., mass vaccination to achieve herd immunity, social media can exacerbate \npublic health impacts of the pandemic by deepening societal divisions and amplifying health  misinformation7\u20139.\nResearchers have examined how misinformation and \u201cfake news\u201d are shared  online10,11, focusing on meth -\nods to automatically recognize  misinformation12 and characterize people who spread  it13. Social psychologists \nidentified individual psychological traits linked to susceptibility to misinformation: specifically, lack of relevant \n knowledge14 or emotional  reliance15, as well as religious  fundamentalism16. By focusing on assessing individual \npsycho-social characteristics, however, survey-based  experiments14 do not account for the influence of interper -\nsonal relationships. Peers play an important role in the formation of attitudes and beliefs, including individuals\u2019 \nperceptions of community\u2019s  norms17 and their propensity to believe misinformation. For example, discussing \nclimate change with friends and family helped improve acceptance of global  warming18. People also conform their \nmoral expressions of outrage to those of their peers within social  networks19. However, the structure of social \nconnections can distort perceptions of social  norms17, making it all the more important to quantify exposure to \nmisinformation through social networks.\nPolarization  describes the divergence of opinions along an ideological dimension, dividing a population \ninto two groups with sharply contrasting opinions or  beliefs20,21. Ideology and social networks interact: people \nseek out online contacts who share their  beliefs22, following and retweeting social media accounts with simi-\nlar  ideology23,24. These interactions facilitate the formation of \u201cecho chambers\u201d , which surround people with \nlike-minded peers who confirm their pre-existing beliefs, thereby amplifying polarization. While studies have \ndemonstrated the existence of partisan echo  chambers2,25\u201327, their role in exposing people to misinformation \nhas not been fully characterized.\nExisting methods to quantify exposure consider content shared by an individual\u2019s friends. However, at a time \nwhen recommendation engines control user engagement, it is critical to consider content external to friendships. OPEN\n1Department of Computer Science, University of Southern California, Los Angeles 90007, USA. 2Information \nSciences Institute, University of Southern California, Marina del Rey 90292, USA. *email: mohanrao@usc.edu\n2\nVol:.(1234567890) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/Not doing so puts analyses at the risk of under-estimating exposures. Individuals on Twitter can retweet content \ngenerated by accounts irrespective of whether or not they have a follow relationship. Prior to retweeting their \ncontent, individuals are certainly exposed to it.\nTo capture some of the complexity of polarization we project it on a two-dimensional space, with axes repre-\nsenting partisanship and factuality (or reliability) of information. Previous works have identified a link between \nthese dimensions: politically conservative social media users are more likely to share  misinformation10,27 and \nanti-science  content3. However, the interaction between partisanship and exposure to misinformation through \nsocial connections has not been fully characterized. As a result, we do not know whether partisanship drives \nselective exposure to misinformation or people selectively share misinformation despite being exposed to diverse \nand reliable information sources. We organize our research around the following questions: \nRQ1   How does the polarization of information (along the dimensions of partisanship and factuality) that \npeople see compare to the polarization of information that people share  online? (I.e., are echo chambers \ntwo-dimensional?)\nRQ2   How correlated are the dimensions of polarization, i.e., how much does partisanship correlate with \nfactuality?\nRQ3   Is there a partisan asymmetry in the exposure to misinformation?\nRQ4   Do partisans amplify misinformation? Is there a partisan asymmetry in the selective amplification or \nfiltering of misinformation?\nRQ5   Does factual content or misinformation receive more attention?\nOur study addresses these questions by examining online discussions about the Covid-19 pandemic. First, \nwe classify social media users ideologically along political and factual dimensions, assigning them a two-dimen-\nsional polarization score. Next, we quantify the polarization of the information users see in their friends\u2019 posts. \nAs a proxy of friends, i.e., accounts users follow, we take accounts users retweet. We identify two-dimensional \necho chambers that expose users to ideologically congruent information along political and factual dimensions. \nHowever, while social media users tend to surround themselves with peers who share similar views, there are \npartisan asymmetries in exposure to misinformation. Additionally, the substantial interaction between the two \ndimensions, also observed in earlier  studies10, creates conditions for ideologically polarized users to amplify \nmisinformation. These polarized users, who represent hardline partisans on both sides of the political spectrum, \nselectively share misinformation. However, such users receive less attention than those sharing factual content, \nand political moderates, who represent the bulk of users in our study, help filter out misinformation, reducing the \namount of unreliable content in the information ecosystem. Our study contributes to the understanding of factors \nshaping public\u2019s exposure to polarized information and misinformation, which could aid public health experts \nand policy makers in crafting messaging to facilitate consensus and compliance with public health measures.\nResults\nWe study polarization of online discussions about the Covid-19 pandemic, leveraging the data set of over 260M \nCovid-19 related tweets between January 21, 2020 and July 31, 2020 to characterize the relationship between \ninformation individuals see friends share online, i.e., their information exposure , and information individuals \nthemselves share .\nPolarization is two-dimensional. We quantify the ideology of information along the dimensions of par -\ntisanship and factuality, extracting Pay-Level Domains (PLDs) from URLs embedded in tweets and mapping \nthem to their political and factual scores (see \u201c Methods \u201d). In order to quantify exposures, we leverage inter -\nactions in the retweet network and extract PLDs shared by individuals who have been retweeted by the user \n(see \u201c Methods \u201d). Figure\u00a0 1 shows the joint distribution of the partisanship (Fig.\u00a0 1a) and factuality (Fig.\u00a0 1b) of \nthe information users see friends in their retweet neighborhood share and the information they themselves \nshare. The high density along the diagonal suggests the existence of echo chambers: many users are linked to \nfriends who expose them to ideologically similar information. The correlation between individual ideology and \nexposure ideology along the partisanship and factuality dimensions are 0.61(p<0.001)  and 0.50(p<0.001)  \nrespectively. There are no partisan asymmetries in the political echo chambers (Fig.\u00a0 1a), as both liberal and con-\nservative users are exposed to a similar variety of political content. There is some asymmetry in the factual echo \nchambers (Fig.\u00a0 1b), since there is much lower density of users in the misinformation bubble. Unlike previous \nworks, e.g.,25, the echo chambers we observe are more diffuse, with users linked to friends with more variable \nideologies. This is because previous works calculate the average polarization of friends, which gives equal weight \nto friends who share a lot or a little information, while we aggregate messages shared by all friends when measur -\ning the ideology of exposure.\nPrevious research has identified an interaction between political polarization and misinformation: conserva-\ntives share misinformation to a greater degree than  liberals10,11,27, and they also tend to share more anti-science \n sources3. Our results are consistent with these findings. Figure\u00a0 2 shows the distribution of user scores in the \npolitical-factual space. There is a strong negative correlation ( \u22120.198, p<0.001  ) between the two dimensions: \nusers sharing more conservative domains are more likely to share misinformation. However, the large variance \nmasks more nuanced positions. For example, the bright line in the upper-left quadrant shows a phenomenon \nalso observed  by27 that more extreme liberals have a greater propensity to share misinformation. This shows that \npolarization amplifies misinformation, a finding we explore in more depth below.\nSupplementary Fig.\u00a0S1 (Refer Supplementary file) contrasts popular topics (hashtags) discussed by \npeople sharing factual information and misinformation. While factual people post messages on health \n3\nVol.:(0123456789) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/topics (\u201cpandemic\u201d , \u201cwearamask\u201d , \u201cstayhome\u201d), people sharing misinformation are preoccupied with politics \n(\u201ctrump2020\u201d , \u201ckag2020\u201d , \u201cdemocrats\u201d , \u201cmaga\u201d) and conspiracies (\u201cplandemic\u201d , \u201cqanon\u201d , \u201cwwg1wga\u201d). Interest -\ningly, these users also mention media to a much greater extent, using topics like \u201cfoxnews\u201d , \u201c7news\u201d , \u201cfoxand-\nfriends\u201d , \u201cmorningjoe\u201d , and \u201cfakenews\u201d . This may suggest the greater role that media plays in agenda-setting for \npeople vulnerable to misinformation. Also, unlike factual users, people spreading misinformation also discuss \nunproven cures, like \u201chydroxychloroquine\u201d .\nPartisan asymmetries in exposure to misinformation. How does the interaction between partisan-\nship and factuality affect what information users are exposed to and, in turn, what information they share? Do \npeople effectively filter out misinformation they see by selectively sharing more factual content?\nFigure\u00a0 3 visualizes user exposure to polarized information. The top row shows user exposure to political and \nfactual information as a function of user political (Fig.\u00a0 3a) and factual (Fig.\u00a0 3b) scores. Note that while Fig.\u00a0 3a,b \nrepresents users in the same space as in Fig.\u00a0 1a,b, i.e., a user\u2019s political/factual scores vs the scores of their political/\nfactual exposures, the colors in the latter show density while the colors in the former show their factual and politi-\ncal opinions respectively. There are several regions of interest in Fig.\u00a0 3a. Liberal users ( pl<0.5 ) who are exposed \nto politically moderate content ( pe\u22480.5 ) see the most factual information (dark orange). Liberals ( pl<0.5 ) \nwho are exposed to liberal content (  pe<0.5 ) generally see more factual (orange) information, although as their \nexposure becomes more partisan, the share of factual content they see dwindles. Those exposed to extreme left  \nFigure\u00a01.  Two-dimensional echo chambers. Heatmap of user polarization scores shows the polarization of \ninformation users see and share along (a ) political (Pearson\u2019s correlation r=0.61 , p<0.001  ) and (b ) factual \n( r=0.50 , p<0.001  ) dimensions. Colors indicate the number of users given polarization scores.\nFigure\u00a02.  Relationship between dimensions of polarization. Color represents number of users given \npolarization scores along the political and factual dimensions (Pearson\u2019s correlation r=\u2212 0.198 (p<0.001) ).\n4\nVol:.(1234567890) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/content ( pe\u22480 ) see more misinformation (green hue). As liberals become more exposed to conservative content \n( pe\u21921 ) they see more and more misinformation. The same is not true of conservatives: conservative users \n( pl>0.5 ) who are exposed to right-wing information ( pe>0.5 ) tend to see more misinformation; however, \nas long as they are not too conservative, exposure to liberal information ( pe<0.5 ) allows them to receive more \nfactual information. Unlike liberals, exposure to politically moderate content ( pe\u22480.5 ) does not promote factual \ninformation among conservatives.\nTrends within misinformation echo chambers (Fig.\u00a0 3b) tell a similar story. Users who share misinformation \n( fl<0.4 ) and are exposed to misinformation (  fe<0.4 ) tend to see more conservative content (red), although \nthose who are exposed to more factual content (  fe\u21921 ) see more liberal information (blue dots). Among people \nsharing factual information ( fl>0.6 ), those who are exposed to more factual information ( fe\u21921 ) tend to see \npolitically moderate content (white). The box outline is an artifact of domain polarity scores. MBFC classifies \nmany information sources as \u201cmixed\u201d (0.4), leading to an overabundance of points near that value.\nSupplementary Fig.\u00a0S2 (Refer Supplementary File) visualizes two-dimensional polarization within the echo \nchambers. Again, the neighborhood exposure vs leaning space is the same as the row above, but the color in \neach plot shows user polarization or leaning along the alternate dimensions. Supplementary Fig.\u00a0S2a shows \nthat as partisanship becomes more extreme ( pl\u21920 or pl\u21921 ), people are more likely to share misinforma-\ntion (green). Interestingly, this trend does not strongly depend on partisanship of their exposure (  pe ). Overall, \nliberals ( pl<0.5 ) share more factual information, although those who are more moderate ( pl\u22480.5 ) tend to \nshare more misinformation (yellow/green) when exposed to more conservative content ( pe\u21921 ). As shown in \nFig.\u00a0 2b, misinformation-prone users (  fl<0.4 ) tend to post more hardline conservative content (darker red) as \nthey share more misinformation ( fl\u21920 ) regardless of their exposure; however, those who are most exposed \nto misinformation ( fe<0.2 ) tend to share more liberal views (blue dots). This is not true for factual users, who \ntend to share liberal content (blue) regardless of the factuality of their exposure (  fe).\nHardline partisans amplify misinformation. Do people amplify misinformation by selectively sharing \nfewer factual domains than what they are exposed to?\nThe off-diagonal elements in the echo chamber plots in Fig.\u00a0 1 suggest that a sizable fraction of social media \nusers share information that is more polarized and less factual than what they are exposed to, and an equally large \nnumber share information that is more factual than what they are exposed to. In other words, some people filter \nout misinformation from the information ecosystem, while others amplify it. To better understand how the inter -\nactions between polarization and misinformation affect how people react to exposure, we define two quantities:\nEquation\u00a0(1 ) quantifies excess factuality for a given user, i.e., how much more factual content the user shares \nrelative to their exposure. Equation\u00a0(2) measures excess partisanship, i.e., the relative partisanship of the content \nthe user shares compared to their exposure. Note that we had transformed scores so that instead of partisanship, \nthey measure the degree of political moderacy or extremism regardless of its polarity.(1) \ufffdf(u)=fl(u)\u2212fe(u)\n(2) \ufffdp(u)=|pl(u)\u22120.5|\u2212| pe(u)\u22120.5|\nFigure\u00a03.  Exposure within echo chambers. (a ) Color indicates the median factual exposure in each bin. \nIn general, as users share more conservative content while being exposed to more conservative content, \nthey also see more misinformation. Liberal users who are exposed to extreme liberal content also see more \nmisinformation. (b ) Color indicates the median political polarization score in each bin. Generally, as users \ngenerate more misinformation while being exposed to low factual content, they have a higher propensity to \nshare conservative content.\n5\nVol.:(0123456789) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/Figure\u00a0 4 shows the joint distribution of excess partisanship /Delta1p and excess factuality /Delta1 f . The negative cor -\nrelation (Pearson\u2019s correlation r=\u2212 0.38 , p<0.001  ) between the two dimensions suggests that not only do \npolitically hardline social media users (regardless of whether they are liberal or conservative) have a higher \npropensity for misinformation, but users who amplify politically polarized content also amplify misinforma-\ntion. The color shows partisanship. Interestingly, both hardline conservatives and hardline liberals are active in \namplifying partisanship \ufffdp>0 and misinformation \ufffd f<0 , with liberals playing a more active role in amplify-\ning misinformation. On the other hand, users who are less partisan than their friends ( \ufffdp<0 ) also share more \nfactual information than what they are exposed to ( \ufffd f>0 ). By filtering out misinformation, such users play an \nimportant role in the information ecosystem. They also tend to be politically moderate.\nPartisan asymmetries in activity. Are users sharing misinformation more active than users sharing \nmore factual content? Does aggressive sharing correlate with more attention? To answer these questions, we \ndefine a user\u2019s overall activity as the sum of their tweets T and retweets RT: A(u )=T(u)+RT(u) . To quantify \nthe attention the user u receives in response to their activity, we define retweet power  P(u) as the ratio of number \nof times u is retweeted R and their overall activity:\nBoxplots in Fig.\u00a0 5 visualize the differences in tweet and retweet activity of factual (fl\u22650.6) and misinformation \n(fl\u22640.4) users. To assess the significance of differences between the two groups, we use the Student\u2019s  t-test . This \nparametric test of difference between the means of two groups requires the corresponding distributions to be \nnormal. While our metrics (the number of tweets and retweets) have a skewed distribution, taking a log transform \nincreases normality. Table\u00a0 1 details the null and alternate hypotheses used in our t -tests.\nFrom Fig.\u00a0 5 and Table\u00a0 1, we see that users who share misinformation tweet and retweet more often and have \nhigher overall activity compared to users who share factual content. Statistically significant t -statistics for T , RT, \nand A in Table\u00a0 1 reinforce these findings.\nDespite their increased overall activity, users sharing misinformation are retweeted less often than factual \nusers (\u00b5(R M)<\u00b5 ( RF)) , significant at p<0.001  and have considerably lower retweet power (\u00b5(P M)<\u00b5 ( PF)) \nat p<0.001  (Fig.\u00a0 5d). These findings hint at an increased attention to factual users despite their lower overall \nactivity.\nDiscussion\nThe Covid-19 pandemic exposed societal divisions, with attitudes toward the pandemic and mitigation measures \nsplintering along partisan lines. To study these divisions, we quantified the ideology of information users see \nand the information they share on social media. Using retweet interactions to quantify exposures, our study \ngives much needed impetus to consider exposures in the study of online polarization. Although retweets only \ncapture a subset of the follower/friend relationships, they represent who users pay attention to, thereby defining \nthe most important aspect of exposure. A comparison of exposures from follow/friend relationships and retweet \ninteractions is out of scope of this study and provides an avenue for future work.\nAn important question that arises next is whether we observe echo chambers. Whether individuals share \ncontent (original tweets not including retweets) identical in ideological valence to their exposures? Across both \ndimensions, we find that sharing behaviors are strongly correlated with exposures using Pearson\u2019s correlation \nmetric. Conservatives see conservative content while liberals see liberal content. Similar polarization occurs \nalong the factual dimension. These findings show that echo chambers are two-dimensional.(3) P(u)=R(u)\nA(u )=R(u)\n[T(u)+RT(u)]\nFigure\u00a04.  Excess factuality /Delta1 f vs excess partisanship /Delta1p.\n6\nVol:.(1234567890) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/We then study the relationship between the two dimensions of polarization\u2014political partisanship and \npropensity for misinformation\u2014and how it asymmetrically affects exposure to misinformation. We find that \nliberals who are exposed to hardline liberal content see more misinformation, but liberals who are exposed to \npolitically moderate information see more factual content, an effect not seen for conservatives. Conservatives \nwho are exposed to more conservative content are exposed to more misinformation whereas, exposure to liberal \ncontent, exposes them to factual information. Moderate liberals share the most factual content irrespective of \ntheir exposures whereas, moderate conservatives only do so under liberal exposures. These asymmetries highlight \nthe subtleties of polarization overlooked by previous  studies28\u201330.\nLastly, we look at the relationship between partisan extremism and misinformation. We find that highly \npolarized users, who represent hardline partisans on both sides of the political spectrum, are most likely to \namplify partisan content and misinformation. However, such users get less attention than the bulk of users in Table 1.  Results of hypothesis testing for difference in means between the two groups of users along the \nfactuality dimension for various metrics. Significant values are in bold. Factual users (F) have high factuality \nscores ( fl\u22650.6 ) while misinformation users (M) have low scores ( fl\u22640.4 ). Metrics include: number of tweets \n(T) and retweets (RT ) generated by the user, the overall activity (A), number\u00a0of times the user is retweeted \n(R) and retweet power (P) which is the ratio of number of times retweeted and activity. We performed t-tests \nto assess the statistical significance of difference between the two distributions after log transforming the \nvariables. ***Denotes a statistically significant difference between the means of the two distributions with \np-value <0.001 .Metric (\u03b8 ) Factual ( \u00b5(\u03b8) F) Misinformation ( \u00b5(\u03b8)M) Hypotheses t-statistic\nT 38.93 57.01H0:\u00b5(log(T))M\u2264\u00b5(T)log(F) 16 .75\u2217\u2217\u2217\nHa:\u00b5(log(T))M> \u00b5(log(T))F\nRT 120.69 168.28H0:\u00b5(log(RT))M\u2264\u00b5(log(RT))F 27 .42\u2217\u2217\u2217\nHa:\u00b5(log(RT))M> \u00b5(log(RT))F\nA=T+RT 159.63 225.29H0:\u00b5(log(A))M\u2264\u00b5(log(A))F 28 .89\u2217\u2217\u2217\nHa:\u00b5(log(A))M> \u00b5(log(A))F\nR 61.97 48.82H0:\u00b5(log(R))F\u2264\u00b5(log(R))M 25 .64\u2217\u2217\u2217\nHa:\u00b5(log(R))F> \u00b5(log(R))M\nP=R/A 0.57 0.17H0:\u00b5(log(P))F\u2264\u00b5(log(P))M 32 .86\u2217\u2217\u2217\nHa:\u00b5(log(P)) F> \u00b5(log(P)) M\nFigure\u00a05.  Boxplots comparing activity and power of factual ( fl\u22650.6 ) and misinformative users ( fl\u22640.4 ). \nWhile we notice that misinformative users are more active both in terms of number of tweets and retweets \ngenerated, they are retweeted less com- pared to factual users. Subsequently, the ratio of retweets received to \noverall activity is significantly lower for misinformative users than factual ones.\n7\nVol.:(0123456789) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/our study who are political moderates who selectively share more factual content. Therefore, such users filter \nout misinformation.\nThere are several limitations to this study worth considering. First, we do not know the actual exposures and \nthus rely on the retweet network as a proxy. The retweet network provides a subset of relationships in the fol-\nlower graph. Given that individuals retweet tweets similar to the ones they post themselves, the echo chamber \neffect inferred by leveraging the retweet network may be overestimated in comparison to the follower network. \nWe have attempted to mitigate the overlap between individual user ideology and retweet exposures by excluding \nURLs in retweeted content from quantification of the former. Additionally, we also look at all tweets generated \nby retweeted individuals in our quantification of retweet exposures and do not limit the quantification to tweets \nthat were retweeted. Despite this, using retweet networks may still overestimate echo chamber effects. A natural \nalternative is the mentions network. It has been shown however, that the mentions network despite allowing \nindividuals to engage in cross-ideological dialogue, may not necessitate individuals to share cross-ideological \ncontent with others in their  community28. This increased heterogeneity of interactions could risk underesti-\nmating the echo chamber effect. However, exploring the mentions network as an additional quantification of \nexposures, one that could mitigate the overestimation of echo chamber effect in the retweet network, remains \nan interesting avenue for future work. Second, there could be factual/pro-science bias in the data due to the way \nit was collected. More generally, the keyword-based Twitter crawl used to produce this data could omit nuanced \nsubtopics related to Covid-19 discussions. Lastly, our study focuses on users in the United States. This decision \nwas made because of the United States\u2019 information environment, and due to the dominance of English keywords \nused to collect the dataset.\nThis work identifies important differences in the information space of polarized and partisan users. Better \nunderstanding of how information is received, and how it propagates, can help public health experts craft more \neffective messaging. With our work providing quantification for exposures and identifying latent asymmetries, \nunderstanding cognitive, social and affective factors driving them can be an interesting avenue for future work. \nOther important avenues for future work include designing effective interventions for misinformation, assessing \nthe relationship between partisan asymmetries and the binding dimensions of moral thinking such as loyalty, \nauthority and purity, and studying the temporal dynamics of these echo chambers.\nMethods\nData. In this study, we use the publicly available  dataset31 comprising of 260.6M tweets related to Covid-\n19 posted between January 21 and July 31, 2020. These tweets contain at least one of a predetermined set of \nCovid-19-related keywords (e.g., coronavirus, pandemic, Wuhan, etc.). However, less than 1% of the tweets have \ngeographic coordinates associated with them. We therefore rely on the geolocation method employed  in32 to \ndetermine if the user is within the US. The method works by first extracting the mentions of city or state users \nfrequently have in their profile before employing a fuzzy matching algorithm to match them to their respective \nstates in the US. A manual review of this approach found it to be effective in identifying user\u2019s home state. This \nleaves us with 48M tweets generated by 2.4M geolocated users in the United States.\nMeasuring polarization. We characterize the ideology of information along two dimensions: partisanship  \nor political ideology  and factuality . The partisanship dimension captures the source\u2019s political ideology, ranging \nfrom hardline liberal to hardline conservative, while the factuality dimension quantifies the source\u2019s predilec-\ntion for factual content or misinformation. With Media Bias-Fact Check (MBFC)33 providing an exhaustive list \nof media domains and their ideological polarities, previous studies have leveraged individual\u2019s domain shar -\ning behaviors on  Twitter3,25,34 to quantify ideological alignment. Media Bias-Fact Check lists over 2K pay-level \ndomains (PLDs) under five mutually exclusive categories along the political scale: Left, Center-Left, Least-Biased/\nCenter, Center-Right and Right . In addition, it also provides a measure of reporting quality for more than 3.5K \nPLDs along six factuality categories: Very Low, Low, Mixed , Mostly Factual , High  and Very High. PLDs generat-\ning pro-science content are categorized as High  or Very High while, PLDs sharing conspiracies, questionable or \nanti-science content are categorized as Low  or Very Low on the factuality scale. Highly partisan news sources \nsuch as foxnews.com, cnn.com, huffpost.com generally have a chequered quality of reporting and have been listed \nas Mixed . Table\u00a02 refers to the collection of information sources and their ideological biases.\nWe use tldextract35 to extract pay-level domains from URLs in tweets. We filter out tweets and retweets \ncontaining pay-level domains that are not categorized under either of the two ideological polarities of interest \n(Table\u00a0 2).\nWe measure the ideology of information individuals share and the information they see friends share by \nlooking at the political and factual scores of the shared domains.\nIndividual ideology.  Similar to previous  works3,25, we quantify an individual user\u2019s partisanship by averaging \nover the political scores of the PLDs the user shared. Likewise, we infer individual\u2019s preference for factual infor -\nmation by averaging the factual scores of the PLDs the user shared. This makes our measure of factuality similar \nto the propensity, or vulnerability, to misinformation used in previous  works10,27. It is important to note that \nindividual scores quantify the information that users share  within the online information ecosystem; therefore, \nusers with low factual scores produce more misinformation.\nWe calculate user u\u2019s scores along the political pl(u) and factual fl(u) dimensions using Eqs.\u00a0(4 ) and (5 ) \nrespectively. We denote the set of pay-level domains shared by user u  as D (u). These include only the domains \nappearing in u \u2019s original tweets (and not retweets). Functions \ufffd(d) and \ufffd(d) return the political and factual \nscores of each domain d .\n8\nVol:.(1234567890) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/Figure\u00a0 6 shows the distribution of user scores along partisanship and factuality dimensions. The partisanship dis -\ntribution is skewed to liberal domains, potentially indicating a bias in the Covid-19 data. Similarly, factual scores \nare skewed towards factuality, and there are relatively few users sharing misinformation or low-factuality content.\nIdeology of exposure. Understanding polarization people see  online is challenging for several reasons. On Twit-\nter, as on other social media platforms, users subscribe to accounts of other users to see the content they post. \nHowever, the follower graph is usually not available nor is it feasible to reconstruct it from the available APIs. \nEven when the follower graph is known, the platform\u2019s personalization algorithms may select only a subset of \nthe messages posted by friends, i.e., the accounts the user follows, in the user\u2019s  timeline26. This can dramatically \nchange the amount and the nature of the information people  see36,37.\nAs a proxy of the follower graph, we use the retweet graph, creating links to accounts a user retweets. We \nconsider the retweeted accounts as friends whose activity the user sees. We collect tweets and retweets shared by \nthese friends, extract PLDs and filter out ones that do not have a political or factual scores. In contrast to previous \n works25,27,38, however, which measure ideological polarization of information a user sees to by averaging over \nfriends\u2019 political scores, we aggregate over all tweets posted by friends and calculate political and factual scores \nof aggregated tweets. This approach factors in the large variation in friend activity: an active friend who posts \nmany messages will have a bigger effect on the user\u2019s information exposure than a less active friend.(4)pl(u)=1\n|D(u)|/summationdisplay\nd\u2208D(u)\ufffd(d)\n(5)fl(u)=1\n|D(u)|/summationdisplay\nd\u2208D(u)\ufffd(d)Table 2.  Curated pay-level domains and their polarity scores along political and factual dimensions. For the \npolitical dimension, {0, 0.25, 0.5, 0.75, 1}  represents Left, Center Left, Center/Unbiased, Center Right and Right  \nsources respectively. Along the factuality or misinformation dimension, Very Low, Low , Mixed , Mostly Factual , \nHigh  and Very High are quantified as {0, 0.2, 0.4, 0.6, 0.8, 1}  in the same order.Dimension Polarity Pay-level domains\nPoliticsLeft (0) cnn.com, huffpost.com, dailybeast.com, \u00b7\u00b7\u00b7 (350+ PLD s)\nCenter-Left (0.25) aljazeera.com, independent.co.uk, lincolnproject.us \u00b7\u00b7\u00b7 (500+ PLDs)\nCenter (0.5) gallup.com, pewresearch.co.uk, wikipedia.com \u00b7\u00b7\u00b7 (500+ PLDs)\nCenter-Right (0.75) bostonherald.com, chicagotribune.com, wsj.com \u00b7\u00b7\u00b7 (250+ PLDs)\nRight (1) foxnews.com, gppusa.com, thenationalherald.com \u00b7\u00b7\u00b7 (250+ PLDs)\nFactualityVery Low (0) counterthink.com, biggovernment.news, vaccines.news \u00b7\u00b7\u00b7 (180+ PLDs)\nLow (0.2) 911truth.org, althealth-works.com, naturalcures.com \u00b7\u00b7\u00b7 (600+ PLDs)\nMixed (0.4) breitbart.com, buzzfeed.com, independent.co.uk \u00b7\u00b7\u00b7 (1000+ PLDs)\nMostly Factual (0.6) drudgereport.com, washingtonpost.com, bloomberg.com \u00b7\u00b7\u00b7 (200+ PLDs)\nHigh (0.8) azcentral.com, bbc.com, nbcnews.com \u00b7\u00b7\u00b7 (1300+ PLDs)\nVery High (1) nationalacademyofsciences.org, nature.com, bmj.com \u00b7\u00b7\u00b7 (200+ PLDs)\nFigure\u00a06.  (a) Distribution of political leaning domain scores. (b ) Distribution of factual leaning domain scores.\n9\nVol.:(0123456789) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/Information exposure scores along political ( pe(u) ) and factual ( fe(u) ) dimensions are calculated using \nEqs.\u00a0(4 ) and (5 ), but now the set of pay-level domains D(u) corresponds to all domains user u sees, which we \nconstruct by aggregating over all PLDs shared by u \u2019s friends.\nAfter filtering out users who share or see two or fewer PLDs with political and factual scores, we are left with \na little over 350K users. Figure\u00a0 7 shows the distribution of the number of pay-level domains users share in their \nposts, as well as the distribution of the number of PLDs users see. The difference between the two distributions \nsuggests that some domains are seen much more than they are shared, likely because they are shared by influential \naccounts with many followers.\nPosts retweeted by individuals are ideologically similar to the content they  post39,40, creating an overlap \nbetween ideology and exposure. We mitigate the overlap by (i) not considering PLDs embedded in content \nretweeted by individuals when quantifying their own ideology, and (ii) when quantifying exposures, considering \nPLDs in all tweets posted by posted by accounts retweeted by an individual and not just in the content retweeted \nby the individual. In order to highlight the significance of (i) in mitigating overlap, we run a robustness check \nthat quantifies individual ideology using PLDs in the posts a user tweets and retweets. We find that while results \nfrom this robustness check (Refer Supplementary File S1: Accounting retweeted PLDs in quantifying individual \nideology) are similar to the ones seen above, we see significant increases in correlation between individual ideol-\nogy and exposures (Supplementary Figs.\u00a0S4, S5), as expected. The lower correlations in Figs.\u00a0 1 and 2  show that \nremoving PLDs embedded in retweets in quantifying individual ideology can mitigate the overlap.\nData availability\nAll datasets and code used to conduct experiments in this study are publicly available in the GitHub repository \nhttps://  github.  com/  ashwi  nshre  yas96/  Parti  san-  Asymm  etries . Owing to Twitter\u2019s terms of use and service, we are \nrestricted to sharing tweet IDs, which can be hydrated using the Twitter API or third-party hydration APIs. These \nIDs are accessible in the public repository https:// github. com/  echen  102/  COVID-  19- Tweet  IDs.\nReceived: 16 June 2022; Accepted: 5 September 2022\nReferences\n 1. Pew. Social media outpaces print newspapers in the u.s. as a news source (2018).\n 2. Jiang, J. et al.  Social media polarization and echo chambers in the context of covid-19: Case study. JMIRx Med.  2, e29570 (2021).\n 3. Rao, A. et al. Political partisanship and antiscience attitudes in online discussions about covid-19: Twitter content analysis. J. Med. \nInternet Res. 23, e26692 (2021).\n 4. Pew. Partisan differences over the pandemic response are growing (2020).\n 5. Gollwitzer, A. et\u00a0al. Partisan differences in physical distancing are linked to health outcomes during the covid-19 pandemic. Nat. \nHum. Behav. 1\u201312 (2020).\n 6. Pierri, F. et al. Online misinformation is linked to early covid-19 vaccination hesitancy and refusal. Sci. Rep.  12, 1\u20137 (2022).\n 7. Roozenbeek, J. et al.  Susceptibility to misinformation about covid-19 around the world. R. Soc. Open Sci. 7, 201199 (2020).\n 8. Chen, E. et\u00a0al. Covid-19 misinformation and the 2020 us presidential election. Harvard Kennedy School Misinformation Review \n(2021).\n 9. Memon, S.\u00a0A. & Carley, K.\u00a0M. Characterizing covid-19 misinformation communities using a novel twitter dataset. arXiv preprint \narXiv: 2008.  00791  (2020).\n 10. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on twitter during the 2016 u.s. presidential \nelection. Science  363, 374\u2013378 (2019).\n 11. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science  359, 1146\u20131151 (2018).\n 12. Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source quality. \nPNAS  116, 2521\u20132526 (2019).\n 13. Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced judgments of news source quality. \nPNAS  116, 2521\u20132526. https://  doi. org/ 10. 1073/  pnas. 18067  81116 (2019).\n 14. Pennycook, G. & Rand, D. G. The psychology of fake news. Trends Cogn. Sci. 25, 388\u2013402 (2021).Figure\u00a07.  Distribution of number of PLDs users generate (shown in blue) and are exposed to (shown in \norange).\n10\nVol:.(1234567890) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/ 15. Martel, C., Pennycook, G. & Rand, D. G. Reliance on emotion promotes belief in fake news. Cogn. Res. Principles Implications  5, \n1\u201320 (2020).\n 16. Bronstein, M. V ., Pennycook, G., Bear, A., Rand, D. G. & Cannon, T. D. Belief in fake news is associated with delusionality, dog-\nmatism, religious fundamentalism, and reduced analytic thinking. J. Appl. Res. Mem. Cogn.  8, 108\u2013117 (2019).\n 17. Alipourfard, N., Nettasinghe, B., Abeliuk, A., Krishnamurthy, V . & Lerman, K. Friendship paradox biases perceptions in directed \nnetworks. Nat. Commun.  11, 1\u20139 (2020).\n 18. Goldberg, M. H., van der Linden, S., Maibach, E. & Leiserowitz, A. Discussing global warming leads to greater acceptance of \nclimate science. Proc. Natl. Acad. Sci.  116, 14804\u201314805 (2019).\n 19. Brady, W .\u00a0J., McLoughlin, K., Doan, T.\u00a0N. & Crockett, M.\u00a0J. How social learning amplifies moral outrage expression in online social \nnetworks. Sci. Adv.  7, eabe5641 (2021).\n 20. Levy, R. Social media, news consumption, and polarization: Evidence from a field experiment. Am. Econ. Rev. 111, 831\u201370 (2021).\n 21. Van\u00a0Bavel, J.\u00a0J., Rathje, S., Harris, E., Robertson, C. & Sternisko, A. How social media shapes polarization. Trends Cognit. Sci. \n(2021).\n 22. Knobloch-Westerwick, S. & Meng, J. Looking the other way: Selective exposure to attitude-consistent and counterattitudinal \npolitical information. Commun. Res.  36, 426\u2013448 (2009).\n 23. Barber\u00e1, P ., Jost, J., Nagler, J., Tucker, J. & Bonneau, R. Tweeting from left to right: Is online political communication more than \nan echo chamber? Psychol. Sci. 26, 1531\u20131542 (2015).\n 24. Badawy, A., Ferrara, E. & Lerman, K. Analyzing the digital traces of political manipulation: The 2016 russian interference twitter \ncampaign. In ASONAM, 258\u2013265 (IEEE, 2018).\n 25. Cinelli, M., De\u00a0Francisci\u00a0Morales, G., Galeazzi, A., Quattrociocchi, W . & Starnini, M. The echo chamber effect on social media. \nPNAS  118 (2021).\n 26. Bakshy, E., Messing, S. & Adamic, L. A. Exposure to ideologically diverse news and opinion on facebook. Science  348, 1130\u20131132 \n(2015).\n 27. Nikolov, D., Flammini, A. & Menczer, F. Right and left, partisanship predicts (asymmetric) vulnerability to misinformation. Harvard \nKennedy School (HKS) Misinformation Review (2021).\n 28. Conover, M. et al. Political polarization on twitter. In Proceedings of the international aaai conference on web and social media  5, \n89\u201396 (2011).\n 29. Garimella, V . R.\u00a0K. & Weber, I. A long-term analysis of polarization on twitter. In Eleventh international AAAI conference on web \nand social media (2017).\n 30. Barber\u00e1, P ., Jost, J. T., Nagler, J., Tucker, J. A. & Bonneau, R. Tweeting from left to right: Is online political communication more \nthan an echo chamber?. Psychol. Sci.  26, 1531\u20131542 (2015).\n 31. Chen, E., Lerman, K. & Ferrara, E. Tracking social media discourse about the covid-19 pandemic: Development of a public coro-\nnavirus twitter data set. JMIR Public Health Surveill. 6, e19273 (2020).\n 32. Jiang, J., Chen, E., Lerman, K. & Ferrara, E. Political polarization drives online conversations about covid-19 in the United States. \nHum. Behav. Emerg. Technol.  (2020).\n 33. Zandt, D.\u00a0V . Website: Media bias-fact check. http:// media  biasf  actch  eck. com (2022).\n 34. Le, H. et\u00a0al. Measuring political personalization of google news search. In The World Wide Web Conference, 2957\u20132963 (2019).\n 35. Kurkowski, J. Python package tldextract. https:// pypi.  org/ proje  ct/ tldex  tract/  (2020).\n 36. Bartley, N., Abeliuk, A., Ferrara, E. & Lerman, K. Auditing algorithmic bias on twitter. In 13th ACM Web Science Conference, \n65\u201373 (Association for Computing Machinery, New Y ork, NY , USA, 2021).\n 37. Chen, W ., Pacheco, D., Y ang, K.-C. & Menczer, F. Neutral bots reveal political bias on social media. arXiv preprint arXiv: 2005.  \n08141 (2020).\n 38. Garimella, K., De\u00a0Francisci\u00a0Morales, G., Gionis, A. & Mathioudakis, M. Political discourse on social media: Echo chambers, \ngatekeepers, and the price of bipartisanship. In Proceedings of the 2018 World Wide Web Conference, 913\u2013922 (2018).\n 39. boyd, D., Golder, S. & Lotan, G. Tweet, tweet, retweet: Conversational aspects of retweeting on twitter. In 2010 43rd Hawaii inter -\nnational conference on system sciences, 1\u201310 (IEEE, 2010).\n 40. Metaxas, P .\u00a0T. et\u00a0al. What do retweets indicate? results from user survey and meta-review of research. In ICWSM, 658\u2013661 (Citeseer, \n2015).\nAcknowledgements\nThis project was funded in part by DARPA under contract HR001121C0168, and in part by Air Force Office of \nScientific Research under contract FA9550-20-1-0224. We are grateful to Emily Chen for granting us access to \nhydrated Covid-19 related tweets and Julie Jiang for the fuzzy-matching algorithm to identify user locations. We \nalso thank Dr. Pablo Barbera for his insights and discussions on analyses.\nAuthor contributions\nK.L. and F.M. conceptualized the study, A.R. collected and processed the data, A.R. performed the experiments, \nK.L., A.R and F.M. analysed the results. All authors wrote and reviewed the manuscript. All authors have agreed \nto the submitted version of the manuscript.\nCompeting interests  \nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at https:// doi. org/ \n10. 1038/ s41598- 022- 19837-7.\nCorrespondence and requests for materials should be addressed to A.R.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n11\nVol.:(0123456789) Scientific Reports  |        (2022) 12:15671  | https://doi.org/10.1038/s41598-022-19837-7\nwww.nature.com/scientificreports/Open Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article\u2019s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat  iveco  mmons. org/ licen  ses/ by/4. 0/.\n\u00a9 The Author(s) 2022", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Partisan asymmetries in exposure to misinformation", "author": ["A Rao", "F Morstatter", "K Lerman"], "pub_year": "2022", "venue": "Scientific reports", "abstract": "Online misinformation is believed to have contributed to vaccine hesitancy during the Covid-19  pandemic, highlighting concerns about social media\u2019s destabilizing role in public life."}, "filled": false, "gsrank": 408, "pub_url": "https://www.nature.com/articles/s41598-022-19837-7", "author_id": ["QovGNgYAAAAJ", "u-8h3HcAAAAJ", "PlAG11IAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ZFibJHbufpQJ:scholar.google.com/&output=cite&scirp=407&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZFibJHbufpQJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 48, "citedby_url": "/scholar?cites=10700251955866589284&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ZFibJHbufpQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-022-19837-7.pdf"}}, {"title": "A dataset for analysing news framing in Chinese media", "year": "2025", "pdf_data": "A Dataset for Analysing News Framing in Chinese Media\nOwen Cook*, Yida Mu*, Xinye Yang*, Xingyi Song and Kalina Bontcheva\nSchool of Computer Science, University of Sheffield\n{oscook1, x.song, k.bontcheva}@sheffield.ac.uk\nAbstract\nFraming is an essential device in news reporting, allow-\ning writers to influence public perceptions of current affairs.\nWhile automatic news framing detection datasets exist in var-\nious languages, none focus on news framing in the Chinese\nlanguage, which presents unique challenges with complex\ncharacter meanings and unique linguistic features. This study\nintroduces the first Chinese News Framing dataset, to be used\nas either a stand-alone dataset or a supplementary resource\nto the SemEval-2023 task 3 dataset. We detail its creation\nand conduct baseline experiments to demonstrate the need for\nsuch a dataset and create benchmarks for future research, pro-\nviding results obtained through fine-tuning XLM-RoBERTa-\nBase and using GPT-4o in the zero-shot setting. We find that\nGPT-4o performs significantly worse than fine-tuned XLM-\nRoBERTa across all languages. For the Chinese language,\nwe obtain an F1-micro (the performance metric for SemEval\ntask 3, subtask 2) score of 0.719 using only samples from our\nChinese News Framing dataset and a score of 0.753 when\nwe augment the SemEval dataset with Chinese news fram-\ning samples. With positive news frame detection results, this\ndataset is a valuable resource for detecting news frames in the\nChinese language and is a useful supplement to the SemEval-\n2023 task 3 dataset.\nIntroduction\nFraming is a fundamental process for understanding the\nworld. It occurs when people both communicate and receive\ninformation (Entman 1993) and it shapes a person\u2019s concep-\ntualisation of the world around them. While scholars do not\nagree on an exact definition (Hertog 2001; Van Dijk 2023),\nwe refer to that of Gamson et al. (1992), who define a frame\nas \u201ca central organising principle that holds together and\ngives coherence and meaning to a diverse array of symbols\u201d.\nA symbol may be anything from a small facial expression to\na group of words that are commonly used to evoke particular\nemotions. The interpretation of symbols by a receiver is in-\nfluenced by their existing knowledge and internal grouping\nof concepts, impacting their perception of information. The\ncommunicator also frames the symbols they project, allow-\ning them to influence the receiver\u2019s interpretation of them.\n*These authors contributed equally.\nCopyright \u00a9 2025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.In the news and media, framing is omnipresent; social me-\ndia content creators, journalists, and politicians particularly\ninfluence how the public views and feels about current af-\nfairs. D\u2019angelo (2018) refers to this as news framing (also\nknown as media framing): \u201chow journalists, their sources,\nand audiences work within conditions that shape the mes-\nsages they construct as well as the ways they understand and\ninterpret these messages\u201d.\nDue to the vastness of information available online, there\nis a desire for automatic news frame detection. Automatic\nnews frame detection refers to the use of computational\nmethods to identify news frames. It has a variety of appli-\ncations, such as understanding media bias (Morstatter et al.\n2018), providing balanced framing of articles at the infor-\nmation retrieval stage (Reiter-Haas et al. 2024), automat-\ning large-scale content analysis (Kwak, An, and Ahn 2020;\nAlonso del Barrio and Gatica-Perez 2023), and detecting\nmisinformation (Wang et al. 2024). Datasets available for\nthe development of language models capable of automati-\ncally detecting news frames span a number of languages, yet\nnews framing in the Chinese language is particularly under-\nexplored.\nThis work introduces the Chinese News Framing dataset,\nfacilitating research investigating the training of models ca-\npable of detecting news frames in Chinese. The dataset has\nbeen designed to also act as a complementary resource for\nthe SemEval-2023 task 3 dataset (Piskorski et al. 2023),\nwhich does not include any Chinese data points. We pro-\nvide baseline experiments highlighting the performance of\nthe multilingual language model XLM-RoBERTa (Conneau\n2019) on Chinese news framing samples, fine-tuned on the\nSemEval training set, our Chinese News Framing training\nset, and our augmented SemEval training set (a concatena-\ntion of both training sets). We also provide results obtained\nby GPT-4o in the zero-shot setting for all test samples in\neach language. We make our dataset and code available on\nZenodo1, and GitHub2with the CC-BY-NC-SA Licence.\n1Dataset: https://doi.org/10.5281/zenodo.14659362\n2Code: https://github.com/GateNLP/chinese-news-framing\nProceedings of the Nineteenth International AAAI Conference on Web and Social Media (ICWSM 2025)\n2402\nRelated Work\nNews Frames\nNews framing can emphasise certain aspects of an issue,\nshaping public perception and interpretation (De Vreese\n2005; Lecheler and De Vreese 2019) through the selective\nemphasis and organisation of specific elements within news\nstories.\nBy highlighting certain aspects of events while down-\nplaying others, frames can profoundly influence how peo-\nple think about issues, attribute responsibility, and evaluate\npotential solutions (Lecheler and de Vreese 2012). Frame\nanalysis reveals how media organisations in different coun-\ntries and languages present the same events through different\ncultural and ideological perspectives. Understanding these\nframing patterns also enables researchers to track how pub-\nlic discourse evolves over time on global issues such as cli-\nmate change, public health, and international conflicts (Card\net al. 2015b).\nNews Frame Detection\nIn an era of increasing digital news consumption, the abil-\nity to detect and analyse frames systematically has be-\ncome essential for understanding media influence and bias\nacross diverse platforms and contexts (Hamborg, Donnay,\nand Gipp 2019). To detect news frames, a number of ap-\nproaches have been employed. These include topic mod-\nelling (DiMaggio, Nag, and Blei 2013), hierarchical topic\nmodelling (Nguyen et al. 2015), cluster and sentiment analy-\nsis (Burscher, Vliegenthart, and Vreese 2016), and, more re-\ncently, neural network models, with transformer-based mod-\nels now highly performant and widely used (Liu et al. 2019;\nAky\u00a8urek et al. 2020; Piskorski et al. 2023). One of the most\ncommonly used models in the SemEval-2023 task 3 was the\nmultilingual BERT-based model XLM-RoBERTa (Wu et al.\n2023b; Jiang 2023; Liao, Lai, and Nakov 2023).\nTo achieve the automatic detection of news framing, Card\net al. (2015a) developed the first large-scale dataset, the\n\u201cMedia Frames Corpus\u201d, and the corresponding annotation\nframework. The Media Frames Corpus consists of 20k En-\nglish articles annotated into one or more frames from 15\ncategories introduced by Boydstun et al. (2014); the top-\nics in this dataset include immigration, smoking, and same-\nsex marriage. Liu et al. (2019) introduced the Gun Violence\nFrame Corpus (GVFC), focusing solely on gun violence and\nthe English language, using a different set of frames. Utilis-\ning the same frame definitions as Card et al. (2015b), Pisko-\nrski et al. (2023) introduced the first multilingual news fram-\ning dataset (SemEval-2023 task 3); the publicly available\ntraining and development sets contain samples in English,\nFrench, German, Italian, Polish, and Russian.\nThe lack of Chinese content in these existing datasets\npresents clear limitations for Chinese news framing analy-\nsis. The unique linguistic features of the Chinese language,\nsuch as the lack of explicit word boundaries, complex logo-\ngraphic character meanings and relationships, and a heavy\nreliance on context (Si et al. 2023; Gu et al. 2025), pose\nspecific challenges in natural language processing. One such\nchallenge is the tokenisation of Chinese text (Gu et al. 2025).The languages included in the SemEval-2023 task 3 dataset\nare primarily spoken in Western countries. This also high-\nlights a cultural gap in the dataset, with languages influenced\nby Eastern culture being under-represented.\nTo the best of our knowledge, a Chinese dataset for auto-\nmatic news framing detection has not yet been developed. To\naddress this gap, we introduce the first Chinese News Fram-\ning dataset. This resource enables the analysis of framing\npatterns in Chinese media discourse across a variety of news\nsources and contributes to multilingual and cross-cultural\nnews framing research.\nTask Description\nGiven a news article, the task is to determine one or more\nframes applied in the article from a set of 14 generic fram-\ning dimensions (Card et al. 2015a; Piskorski et al. 2023):\n(1) Economic, (2) Capacity and Resources, (3) Morality,\n(4) Fairness and Equality, (5) Legality, Constitutionality and\nJurisprudence, (6) Policy Prescription and Evaluation, (7)\nCrime and Punishment, (8) Security and Defence, (9) Health\nand Safety, (10) Quality of Life, (11) Cultural Identity, (12)\nPublic Opinion, (13) Political, and (14) External Regulation\nand Reputation. We frame our task as a multi-class, multi-\nlabel classification problem at the news article level. Table\n1 lists all the framing dimensions and their corresponding\ndefinitions.\nData\nTo annotate frames in Chinese articles, we use the pipeline\nadopted by Piskorski et al. (2023), which has been success-\nfully applied to various languages. Specifically, our dataset\ndevelopment framework is divided into three distinct steps:\n\u2022Data Collection. To support our document-level anno-\ntation task, we begin by gathering a dataset of Chinese\nnews articles T.\n\u2022Data Sampling. From T, we select a representative subset\nof articles, D, for annotation.\n\u2022Data Annotation. Lastly, we provide a detailed descrip-\ntion of the annotation process applied to D.\nData Collection\nNews sources. Following Piskorski et al. (2023), we col-\nlected Chinese news articles from 14 different websites\nspanning 5 countries. We also selected these news outlets\nto ensure a balance of political biases, as determined by the\nMedia Bias/Fact Check (MBFC) platform.3Table 2 presents\nthe specifications of each news outlet according to MBFC.\nTime and Topics. We collected Chinese news articles\npublished between 2020 and the end of 2024. Our collection\ncovers globally discussed events, including the COVID-19\nvaccine, Israeli\u2013Palestinian conflict, Russo\u2013Ukrainian war,\nand US election. In total, we obtained approximately 300k\nnews articles from 14 different news sites.\n3https://mediabiasfactcheck.com/\n2403\nCategory Definition\n1: EconomicThis\ntype identifies parts of the articles referring to costs, benefits, or other financial\nimplications.\n2:Capacity\nand ResourcesThis type identifies parts of the articles referring to the availability of physical, human,\nor financial resources, and the capacity of current systems.\n3:Morality This\ntype identifies parts of the articles referring to religious or ethical implications.\n4:F\nairness and EqualityThis type identifies parts of the articles referring to the balance or distribution of rights,\nresponsibilities, and resources.\n5:Legality\n, Constitutionality and\nJurisprudenceThis type identifies parts of the articles referring to rights, freedoms, and authority of\nindividuals, corporations, and government.\n6: P\nolicy Prescription and EvaluationThis type identifies parts of the articles referring to discussion of specific policies aimed\nat addressing problems.\n7:Crime\nand PunishmentThis type identifies parts of the articles referring to the effectiveness and the implica-\ntions of laws and their enforcement.\n8: Security\nand DefenceThis type identifies parts of the articles referring to threats to welfare of the individual,\ncommunity, or nation.\n9: Health\nand SafetyThis type identifies parts of the articles referring to health care, sanitation, and public\nsafety\n10: Quality\nof LifeThis type identifies parts of the articles referring to threats and opportunities for the\nindividual\u2019s wealth, happiness, and well-being.\n11:Cultural\nIdentityThis type identifies parts of the articles referring to traditions, customs, or values of a\nsocial group in relation to a policy issue.\n12:Public\nOpinionThis type identifies parts of the articles referring to attitudes and opinions of the general\npublic, including polling and demographics.\n13: P\noliticalThis type identifies parts of the articles referring to considerations related to politics\nand politicians, including lobbying, elections, and attempts to sway voters.\n14: Exter\nnal Regulation and ReputationThis type identifies parts of the articles referring to international reputation or foreign\npolicy.\nTable 1: Chinese news framing categories and definitions as used in Piskorski et al. (2023).\nNew Sources Country # of articles\nBBC Chinese UK 3k\nV oice of America USA 36k\nFinancial Times UK 3k\nReuters UK 23k\nDeutsche Welle Germany 24k\nChina Digital Times USA 14k\nThe New York Times Chinese USA 6k\nRadio France Internationale France 3k\nRadio Free Asia USA 11k\nNew Tang Dynasty USA 79k\nThe Epoch Times USA 100k\nChina Daily China 3k\nThe Paper China 2k\nXinhua News Agency China 1k\nTable 2: Chinese news outlets we collected data from. The\n\u201cCountry\u201d column indicates the media outlet\u2019s base location.\nData Sampling\nTo ensure class balance in the final annotated dataset, we\nsubsampled the collected news articles based on their topics.\nSpecifically, given the news corpus T={t1, t2, . . . , t n}, we\nfirst employed BERTopic (Grootendorst 2022) to assign a\nprimary topic to each article (t i). Next, we computed the co-\nsine similarity between the BERTopic-generated topic repre-\nsentation and each framing category, then pre-assigned the\narticle to the provisional framing category (f\u2217\nj) based onthe similarity between BERTTopic label and defined fram-\ning category. The BERTopic-generated topic representation\nand each framing category were encoded using the Sentence\nTransformer4(Reimers and Gurevych 2020).\nzi=SentenceTransformer(BERTopic( ti)) (1)\nfj=SentenceTransformer(f j), (2)\nwhere ziis the embedding of the BERTopic label for doc-\nument ti, and fjis embedding of framing category jand\nF={f1, f2, . . . , f k}.\u2200ti\u2208T, f j\u2208F.\nFraming Assignment. We assigned the most likely fram-\ning category f\u2217\njto each article tiby maximising the cosine\nsimilarity between the topic embedding ziand the framing\ncategory vectors fj:\nf\u2217\nj= arg max\nfjzi\u00b7fj\n\u2225zi\u2225\u2225fj\u2225. (3)\nStratified Sampling. Based on the pre-assigned topics,\nwe used a stratified method to sample a subset of 400 news\narticles (D ), which is used for the training session and final\nannotation. Note that we chose a size of 400, which is com-\nparable to the number of articles per language in Piskorski\net al. (2023).\n4https://huggingface.co/sentence-transformers/paraphrase-\nmultilingual-MiniLM-L12-v2\n2404\nFigure 1: GATE Teamware user interface. Annotators can\nleave comments (see the bottom of the figure), which are\nused by the expert annotator during the data adjudication\nprocess (see Data Adjudication).\nData Annotation\nAnnotation Tool. We annotated Chinese news articles us-\ning an open-source data annotation tool, GATE Teamware5\n(Wilby et al. 2023), which has been employed in similar\ncomputational social science annotation tasks (Mu et al.\n2023; Wu et al. 2023a; Cook et al. 2024).\nAnnotator Training. For annotation, we hired six native-\nChinese-speaking undergraduate and postgraduate students\nfrom the University of Sheffield at a rate of \u00a317 per hour.\nWe first provided a two-hour training session for all partic-\nipants, during which we: (i) introduced the task description\n(see Task Description), label definitions (see Table 1), and\nguidelines for using GATE Teamware (see Figure 1); and\n(ii) asked all participants to annotate 20 samples. Follow-\ning this, the senior annotator released the gold-standard la-\nbels and explained their decisions for each article. The gold-\n5https://github.com/GateNLP/gate-teamwareTrain set Dev set Test set All\nStatistics\n# of Samples 233 50 70 353\n#avg. Frames 3.17 3.0 3.1 3.13\n#Avg. Tokens 484 487 469 481\nBBC Chinese 2 1 3 6\nVOA 35 5 8 48\nReuters 21 8 7 36\nNYT Chinese 3 1 1 5\nDW 9 3 1 13\nFT 3 2 1 6\nRFA 3 1 1 5\nRFI 33 6 10 49\nCDT 2 1 1 4\nEpoch Times 34 9 11 54\nNew Tang Dynasty 50 3 16 69\nThe Paper 11 3 4 18\nXinhua News 11 5 4 20\nChina Daily 14 2 4 20\nTime\n2024 39 6 16 61\n2023 54 11 12 77\n2022 42 13 18 73\n2021 47 14 8 69\n2020 51 6 16 73\n# of Samples per Category\n1: Economic 71 19 21 111\n2: Capacity 70 15 17 102\n3: Morality 22 6 7 35\n4: Fairness 27 8 7 42\n5: Legality 58 9 8 75\n6: Policy 114 26 28 168\n7: Crime 57 7 22 86\n8: Security 75 15 23 113\n9: Health 42 5 15 62\n10: Life 41 10 10 61\n11: Cultural 25 4 10 39\n12: Public Opinion 33 4 11 48\n13: Political 28 4 13 45\n14: External 77 18 25 120\nTable 3: Statistics of three subsets.\nstandard labels for the annotator training set were created\nand validated by three expert annotators, all of whom are\nnative Chinese speakers and experienced NLP researchers\nwith expertise in media analysis.\nAll annotators were provided with an information sheet\ncontaining details about the task and signed consent forms\nin accordance with ethical guidelines.\nTask Allocation. Following Piskorski et al. (2023), in the\ninitial annotation stage, each news article was annotated by\ntwo different annotators. To distribute the samples among\nsix annotators, such that each sample had two unique an-\nnotators, we employed a modified version of the EffiARA\nannotation framework (Cook et al. 2024). Using the Effi-\nARA framework, we evenly distributed samples across an-\nnotators while maintaining the ability to assess inter- and\nintra-annotator agreement, as well as calculate a combined\n\u201cannotator reliability factor\u201d for each annotator.\nInter-annotator agreement can be assessed because each\n2405\nannotator shares their samples evenly with four other anno-\ntators. This provides sufficient overlap to calculate pairwise\ninter-annotator agreement, visualised in Figure 2. To assess\nintra-annotator agreement, we assign 20 duplicate samples\nto each annotator. Here, we diverge slightly from Cook et al.\n(2024) by randomly sampling from the complete set of an\nannotator\u2019s annotations, rather than from the set of single-\nannotated samples; this is because our dataset contains only\ndouble-annotated samples.\nIn the annotation process, we used the EffiARA annotator\nreliability score to filter out an annotator with a significantly\nlower reliability score than all other annotators. The annota-\ntions removed based on this were re-annotated by a highly\nreliable annotator according the EffiARA reliability scores.\nAnnotator Agreement and Reliability. Each annotator\u2019s\naverage inter-annotator agreement, intra-annotator agree-\nment, and reliability factor were calculated as described in\nCook et al. (2024). Figure 2 shows the annotator agreement\nwithin the dataset. Each node represents an annotator, the\nedges represent the pairwise inter-annotator agreement, and\nthe intra-annotator agreement value is displayed next to each\nnode. The agreement metric used in this study was the mean\nKrippendorff\u2019s alpha across each of the 14 news frames. For\neach pairwise agreement calculation, we computed the sum\nof agreement between two users per news frame and divide\nby the number of news frames. The average Krippendorff\u2019s\nalpha of all links (excluding annotations from annotator 5,\nthe least reliable annotator, as their annotations did not con-\ntribute to the gold standard) is 0.465. While this is lower\nthan the recommended level of 0.667, it is higher than that of\nPiskorski et al. (2023), who report an inter-annotator agree-\nment of 0.342 in their dataset.\nNote that there is an overlapping set of annotations be-\ntween annotator 2 and annotator 5, as shown in Figure 2.\nThis represents the complete set of annotations originally\nmade by annotator 5, re-annotated by annotator 2.\nAnnotation Adjudication. Once all samples had been\ndouble-annotated, the senior annotator reviewed the anno-\ntations, resolving any identified conflicts as suggested in\nPiskorski et al. (2023). Any overlapping labels were auto-\nmatically considered gold-standard, with the senior annota-\ntor using their discretion in cases of disagreement.\nChinese News Framing Dataset\nThe Chinese News Framing dataset consists of 353 Chinese\narticles from 14 different news sources, annotated with at\nleast one news frame. Following the structure of the Se-\nmEval dataset (Piskorski et al. 2023), the Chinese Framing\ndataset is split into three subsets: training set (233), devel-\nopment set (50) and test set (70).\nIn Table 3, we present detailed descriptive statistics for\nthe three subsets and the full dataset. For reference, we also\nprovide descriptive statistics of our dataset alongside the Se-\nmEval news framing dataset (Piskorski et al. 2023) in Table\n4.\nFigure 2: Inter- and intra-annotator agreement scores, with\nedges representing pairwise inter-annotator agreement be-\ntween two annotators and the values next to nodes represent-\ning the intra-annotator agreement score, using a multi-label\nvariant of Krippendorff\u2019s alpha. The reliability scores, us-\ning\u03b1= 0.5in the EffiARA reliability score calculation, are\n(from annotator 1 to 6): 1.309, 1.141, 0.945, 0.978, 0.576,\n1.051.\nExperimental Setup\nIn this section, we present experiments designed to evaluate\nthe quality of our dataset and the value of its integration into\nthe existing SemEval dataset.\nThe aims of our experiments are as follows:\n(i) Provide baseline results for each language when mod-\nels are fine-tuned in a multilingual setting, assessing\nthe value of the Chinese News Framing dataset;\n(ii) Provide baseline results for each language using\na state-of-the-art decoder model (GPT-4o (OpenAI\net al. 2024)) for comparison with fine-tuned XLM-\nRoBERTa models;\n(iii) Understand whether our Chinese News Framing\ndataset facilitates the creation of monolingually fine-\ntuned models capable of classifying articles into a set\nof given news frames;\n(iv) Understand the impact of augmenting the SemEval\ndataset with Chinese News Framing samples, using\nthe classification performance of each language as the\nperformance metric.\nAugmenting the SemEval Dataset\nAs shown above, our dataset was developed following a sim-\nilar methodology to that used to create the SemEval dataset\n(Piskorski et al. 2023). This suggests that our dataset can\nnot only be used as a stand-alone resource for Chinese news\nframing analysis but also as a complementary addition to the\nSemEval dataset.\nTo assess the value of our dataset, we experiment with\nthree training sets: the original SemEval dataset, our novel\nChinese News Framing dataset, and the augmented SemEval\ndataset containing Chinese news framing samples. In these\n2406\nMetric Chinese English French German Italian Polish Russian Geor gian Greek Spanish\n#docs 353 590 261 227 364 241 263 29 64 30\n#avg\n. Frames 3.1 4.0 3.0 4.7 3.8 5.2 2.1 1.7 2.9 2.3\n1:Economic 111 74\n79 108 142 144 68 2 14 4\n2: Capacity & Resources 102 56 62 104 120 88 34 4 10 44\n3: Morality 35 231 62 39 62 63 31 2 5 7\n4: Fairness & Equality 42 131 30 35 52 39 21 0 8 2\n5: Legality & Jurisprudence 75 281 41 65 73 56 44 0 23 7\n6: Policy Prescription 168 154 38 70 129 110 15 2 12 7\n7: Crime & Punishment 86 274 22 44 57 57 51 3 11 4\n8: Security & Defense 113 222 89 121 155 105 90 10 19 10\n9: Health & Safety 62 86 60 107 97 144 37 4 8 3\n10: Quality of Life 61 115 40 53 89 85 32 0 5 3\n11: Cultural Identity 39 42 34 46 43 48 13 1 8 0\n12: Public Opinion 48 68 34 50 58 74 22 4 10 3\n13: Political 45 343 108 130 178 144 55 10 43 6\n14: External Reputation 120 214 85 91 132 86 44 9 9 3\nTable 4: Descriptive statistics of the Chinese Framing dataset and the individual languages from the SemEval dataset (Piskorski\net al. 2023).\nexperiments, we treat the SemEval development set as the\ntest set because the official SemEval test set is not publicly\navailable. We consider all the available languages offered in\nthe SemEval training and development sets: English, French,\nGerman, Italian, Polish, and Russian. Statistics for the aug-\nmented SemEval dataset are shown in Table 4.\nModel\nWe conducted experiments using XLM-RoBERTa-base6\n(Conneau et al. 2020). XLM-RoBERTa was one of the most\nwidely used transformer-based multilingual models among\nSemEval participants (Piskorski et al. 2023; Jiang 2023;\nLiao, Lai, and Nakov 2023).\nExperimental Details\nText Pre-processing. To prepare the article text for clas-\nsification, following Wu et al. (2023b), we conducted the\nfollowing additional pre-processing steps:\n\u2022 Add a newline character between the news title and body;\n\u2022 Remove duplicate sentences occurring consecutively;\n\u2022 Remove hyperlinks to websites and images;\n\u2022 Remove strings detailing author biographies (such as\nnames and affiliations).\nModel Training. We fine-tuned XLM-RoBERTa-base for\n100 epochs, with 10 warm-up epochs, a batch size of 8, and a\nmax-sequence length of 512 tokens. We utilised the AdamW\noptimiser with a linear weight decay of 0.01. The loss func-\ntion used in this multi-class, multi-label classification task\nwas Binary Cross-Entropy with Logit Loss.\nThe learning rate was selected through initial experimen-\ntation on the Chinese News Framing development set, as our\ndataset offers train, development, and test splits. These ini-\ntial experiments involved fine-tuning over only 30 epochs,\nmaintaining a warm-up rate of 0.1. The learning rates tested\nwere those used by Wu et al. (2023b) across their experi-\nments: 1e-4, 5e-5, 3e-5, 2e-5, and 5e-6. The best-performing\n6https://huggingface.co/FacebookAI/xlm-roberta-baselearning rate, measured by the F1-micro score on the Chi-\nnese News Framing development set, was selected for the\nfinal set of experiments.\nAll models are trained three times with the set of three\nseeds{555, 666, 777}, using the highest-performing learn-\ning rate obtained using the Chinese-only development set as\ndescribed above. The key performance metric in this study,\nfollowing the official performance metric of SemEval-2023\ntask 3 subtask 2 (Piskorski et al. 2023), is the F1-micro\nscore; we report the mean and standard deviation across\nthe three seeds for each language. The code and configu-\nration files required to run all experiments are available at\nhttps://github.com/GateNLP/chinese-news-framing.\nAll experiments were run on an Nvidia RTX 4090 with\n24GB of VRAM.\nGPT-4o Experiments. We employed GPT-4o (OpenAI\net al. 2024) in a zero-shot setting to generate frame labels\nin a comma-separated format. The temperature parameter\nwas set to 0.0 for deterministic outputs. Following our su-\npervised experiments, we conducted three runs per language\nand report the mean F1-micro score with standard deviation.\nResults and Discussion\nTable 5 displays the experimental results of GPT-4o in the\nzero-shot setting and the results of XLM-RoBERTa-base\nfine-tuned on the three different datasets: the SemEval train-\ning set, our Chinese News Framing training set, and the Se-\nmEval training set augmented with Chinese news framing\nsamples.\nExperimental Results\nSemEval Baseline Performance. Our baseline results,\nusing XLM-RoBERTa-Base fine-tuned on the SemEval\ntraining set and tested over three random seeds on the de-\nvelopment set, closely align with the results obtained by Wu\net al. (2023b), with the only results differing by more than an\nF1-micro score of over 0.01being English, Polish, and Rus-\nsian, which have differences of +0.05,\u22120.018, and +0.035;\n2407\nTraining\nData Chinese English French German Italian Polish Russian\nZero-Shot\nGPT-4o 0.560\u00b10.004 0.603\u00b10.009 0.528\u00b10.001 0.541\u00b10.004 0.540\u00b10.002 0.575\u00b10.010 0.508\u00b10.002\nSemEval (Piskorski et al. 2023) 0.584\u00b10.016 0.733\u00b10.011 0.589\u00b10.017 0.643\u00b10.014 0.599\u00b10.011 0.647\u00b10.009 0.584\u00b10.014\nChinese News Framing 0.719\u00b10.012 0.570\u00b10.013 0.433\u00b10.011 0.515\u00b10.013 0.546\u00b10.003 0.516\u00b10.016 0.434\u00b10.024\nSemEval + Chinese News Framing 0.753\u00b10.015 0.739\u00b10.023 0.578\u00b10.007 0.639\u00b10.023 0.592\u00b10.004 0.670\u00b10.007 0.542\u00b10.008\nTable 5: Experimental results for GPT-4o in the zero-shot setting and for XLM-RoBERTa-base fine-tuned with three different\ntraining sets, trained for 100 epochs, with a learning rate of 5e-5.\na positive result indicates that our model performs better.\nIt is worth noting the difference in experimental setup. The\nexperiments conducted by Wu et al. (2023b) involve a 3-\nfold cross-validation on the development set to create three\ndifferent test sets, whereas we maintain the same test set\n(the SemEval development set) over three different random\nseeds.\nWhile not trained on Chinese news framing samples,\nthe model performs within 0.005 of the scores achieved\nfor French and Russian. The F1-micro score achieved on\nthe Chinese test set without explicit Chinese-language fine-\ntuning was 0.584.\nChinese News Framing Dataset Only. Training on the\nChinese News Framing dataset, as expected, significantly in-\ncreases the model\u2019s performance on Chinese news framing\ntest samples. By training on only the Chinese News Fram-\ning data, the Chinese test score increases to 0.719; this is a\nhigher performance than all languages except English in our\nSemEval baseline performance results. This positive perfor-\nmance on our dataset indicates that it is a valuable tool and\nbenchmark for the Chinese news framing task.\nAugmented SemEval Performance. After augmenting\nthe SemEval dataset with our Chinese News Framing\ndataset, we observe a further increase in performance for\nthe Chinese language, achieving an F1-micro score of 0.753,\nwhich is the highest score attained on any language in\nall of our experiments. While most languages show little\nchange (less than 0.01in F1-micro) in performance from our\nSemEval-only baseline experiments, the French news fram-\ning performance decreases by 0.011and Russian by 0.042;\nChinese classification performance increases by 0.171and\nPolish by 0.023.\nBy augmenting the SemEval dataset with our Chinese\nNews Framing dataset, we observe comparable classifica-\ntion performance in the majority of languages, with a signif-\nicant increase in performance for the Chinese language. This\nindicates that our Chinese News Framing dataset serves as a\nvaluable complementary addition to the SemEval dataset.\nGPT-4o Performance. The experimental results show\nthat GPT-4o achieves lower F1 scores than XLM-RoBERTa-\nBase (trained on the augmented SemEval set containing\nChinese news framing samples) in all languages. This per-\nformance gap arises from the distinct prediction pattern of\nGPT-4o; despite achieving higher recall, it suffers from sig-\nnificantly lower precision. As a generative large languageFrames P R F1 Support\n1: Economic 0.83 0.90 0.86 21\n2: Capacity & Resources 0.47 0.47 0.47 17\n3: Morality 1.00 0.71 0.83 7\n4: Fairness & Equality 0.71 0.71 0.83 7\n5: Legality 0.26 0.62 0.37 8\n6: Policy 0.69 0.71 0.70 28\n7: Crime & Punishment 0.94 0.73 0.82 22\n8: Security & Defence 0.82 0.78 0.80 23\n9: Health & Safety 1.00 0.67 0.80 15\n10: Quality of Life 0.83 0.50 0.62 10\n11: Cultural Identity 0.88 0.70 0.78 10\n12: Public Opinion 0.38 0.27 0.32 11\n13: Political 1.00 0.85 0.92 13\n14: External Regulation 0.84 0.84 0.84 25\nTable 6: Classification report on the Chinese News Framing\ndataset, using XLM-RoBERTa-Base trained exclusively on\nour dataset. It shows the precision, recall, F1 score and the\nsupport (or number of samples) for each class.\nmodel, GPT-4o tends to assign more labels to texts, inter-\npreting text-topic associations from an overly broad seman-\ntic perspective. This leads to the labelling of content that is\nonly superficially related to target categories. Although this\nover-generalised approach improves topic discovery, it in-\ntroduces numerous false positives, ultimately compromising\nclassification accuracy.\nError Analysis\nWe also provide further error analysis on the performance\nof XLM-RoBERTa-Base trained only on our Chinese News\nFraming dataset. We analyse the performance of this model\nto highlight trends within our dataset alone, including po-\ntential strengths and weaknesses for the model based on our\ntraining set.\nClassification Report. Table 6 shows the precision, re-\ncall, F1 score, and support for each individual class within\nthe Chinese News Framing test set. We observe that the\nmodel has particular issues in both precision and recall for\nthe frames (2) Capacity & Resources, (5) Legality, and (12)\nPublic Opinion. When comparing this to the same metrics\nfor the English language development samples in the Se-\nmEval dataset, we also observe that these frames are difficult\nfor the model to classify. A key exception to this is in En-\nglish and French, where (5) Legality is well classified with\nrespect to the other frames for those languages. For English,\n2408\nFigure 3: Co-occurrence Error Matrix on the Chinese News\nFraming dataset. Note that labels 1 to 14 denote the news\nframe orders as described in Task Description. Positive val-\nues represent over-prediction and negative values represent\nunder-prediction of the co-occurrence of two classes.\nthis can be explained by the large set of samples contain-\ning the frame Legality & Jurisprudence. The frames that are\nmost correctly identified are (1) Economic, (3) Morality, (4)\nFairness & Equality, (13) Political, and (14) External Regu-\nlation. This does not align with any of the other languages\nthat are trained only on the SemEval set and does not corre-\nspond to the number of samples supporting each class.\nIt is worth noting that with the Augmented SemEval set\ncontaining Chinese News Framing samples, similar trends\nare observed across languages. For the Chinese language,\nhowever, the performance of the model in identifying the\nframe (12) Public Opinion increases by an F1 score of\n0.35. Through the analysis of each language\u2019s F1-macro\nperformance, the Chinese language performs significantly\nbetter than other languages, achieving 0.74; the next best-\nperforming language, based on F1-macro, is Polish with a\nscore of 0.54. This indicates that our dataset is particularly\neffective for training models to successfully identify the ma-\njority of news frames as well as those with higher support\n(indicated by the high F1-micro). It is important to consider,\nhowever, that in downstream applications, such as balancing\nthe framing within a user\u2019s news feed, frequent misclassifi-\ncations could result in unintended bias or an imbalance in\nframe representation.\nCo-occurrence Error Matrix. We also conducted co-\noccurrence error analysis, shown in Figure 3. The co-\noccurrence error matrix is used to understand how well the\nmodel is able to capture the relationships between pairs of\nclasses in a multi-class, multi-label prediction task. As the\nco-occurrence matrix is symmetric, we display the number\nof true co-occurrences in the lower triangle and the differ-\nence in co-occurrences in the upper triangle; positive scores\nindicate that the model has over-predicted the co-occurrence\nof two news frames and negative scores indicate an under-prediction.\nOne class showing a number of over-predictions with\nother classes is (5) Legality. It is particularly overestimated\nto co-occur with (1) Economic, (6) Policy, (12) Public Opin-\nion, and (13) Political. This is likely due to the poor pre-\ncision identified for the (5) Legality news frame shown in\nTable 6.\nThe (13) Political news frame is shown to be under-\npredicted to co-occur with a number of news frames, in-\ncluding: (6) Policy, (11) Cultural Identity, (12) Public Opin-\nion, and (14) External Reputation. As the (13) Political news\nframe is successfully identified by the model but not very\nwell predicted with the correct co-occurring news frames, it\nindicates that the model does not capture the dependency be-\ntween news frames. Politics often influences policy, cultural\nidentity, public opinion, and external reputation, but this is\nnot captured very well by the model. Capturing this relation-\nship between news frames in the classification stage may be\nof interest in future research.\nConclusion\nIn this work, we have created and published the Chinese\nNews Framing dataset, facilitating news framing experi-\nments in the Chinese language and serving as a complemen-\ntary asset to the SemEval dataset (Piskorski et al. 2023). We\nhave demonstrated the need for Chinese news framing sam-\nples to be added to the SemEval set in order to effectively\ndetect news frames in the Chinese language. We have also\nreported benchmark results, training on only our Chinese\nNews Framing dataset and an augmented SemEval dataset\ncontaining Chinese news framing samples, achieving an F1-\nmicro score of 0.753 on our Chinese News Framing test set;\nthis score represents an improvement over training on only\nChinese News Framing samples. Augmenting the SemEval\ndataset maintains similar F1-micro performance on the Se-\nmEval development set, while improving the news framing\ndetection in the Chinese, English, and Polish languages.\nWhile this work provides experiments to demonstrate this\ndataset\u2019s efficacy as an addition to the SemEval set, it also\npresents experiments achieving high classification perfor-\nmance as a stand-alone dataset. With the additional meta-\ndata available about individual annotations, this work allows\nfor future research involving the development of advanced\nclassification methods, utilising annotator identities (Cook\net al. 2024).\nLimitations\nThe articles within this dataset were collected between 2020\nand 2024, offering news framing samples concerning a va-\nriety of topics. While this serves as a valuable resource, it\ndoes not allow for the analysis of news framing over time,\nallowing for future work to supplement this dataset with the\nannotation of articles from different time periods.\nAs the text is not directly made publicly available in the\ndataset, relying on the user retrieving content from a web\nlink, there is a risk that some article texts may become un-\navailable after the release of the dataset.\n2409\nAlthough we provided annotator guidelines and training,\nsubjective interpretations of news frames are likely to be\npresent in the dataset. We attempt to mitigate this by pro-\nviding each individual annotation in our dataset, rather than\nonly the aggregated \u201cgold-standard\u201d labels. This allows for\nfurther research investigating the uncertainty and subjectiv-\nity involved in this task.\nDataset Availability\nTo maximise the use of our dataset, we adhere to the FAIR\nprinciples (Wilkinson et al. 2016).\n\u2022Findable. Our dataset has been published to the Zenodo\ndataset sharing service: https://doi.org/10.5281/zenodo.\n14659362; our experimental code is also available at\nhttps://github.com/GateNLP/chinese-news-framing.\n\u2022Accessible. All data is publicly accessible through web\nlinks in the published dataset; we also provide a tool to\nobtain the news article text from the given link in our\ncode repository.\n\u2022Interoperable. The CSV format is widely accepted and\ncan be processed by a wide range of data processing\ntools.\n\u2022Reusable. The CSV format is widely accepted and can be\nprocessed by a wide range of data processing tools.\nReferences\nAky\u00a8urek, A. F.; Guo, L.; Elanwar, R.; Ishwar, P.; Betke, M.;\nand Wijaya, D. T. 2020. Multi-label and multilingual news\nframing analysis. In Proceedings of the 58th annual meeting\nof the association for computational linguistics, 8614\u20138624.\nAlonso del Barrio, D.; and Gatica-Perez, D. 2023. Framing\nthe news: from human perception to large language model\ninferences. In Proceedings of the 2023 ACM International\nConference on Multimedia Retrieval, 627\u2013635.\nBoydstun, A. E.; Card, D.; Gross, J. H.; Resnik, P.; and\nSmith, N. A. 2014. Tracking the development of media\nframes within and across policy issues. In APSA 2014 an-\nnual meeting paper.\nBurscher, B.; Vliegenthart, R.; and Vreese, C. H. d. 2016.\nFrames beyond words: Applying cluster and sentiment anal-\nysis to news coverage of the nuclear power issue. Social\nScience Computer Review, 34(5): 530\u2013545.\nCard, D.; Boydstun, A.; Gross, J. H.; Resnik, P.; and Smith,\nN. A. 2015a. The media frames corpus: Annotations of\nframes across issues. In Proceedings of the 53rd Annual\nMeeting of the Association for Computational Linguistics\nand the 7th International Joint Conference on Natural Lan-\nguage Processing (Volume 2: Short Papers), 438\u2013444.\nCard, D.; Boydstun, A. E.; Gross, J. H.; Resnik, P.; and\nSmith, N. A. 2015b. The Media Frames Corpus: Anno-\ntations of Frames Across Issues. In Zong, C.; and Strube,\nM., eds., Proceedings of the 53rd Annual Meeting of the As-\nsociation for Computational Linguistics and the 7th Inter-\nnational Joint Conference on Natural Language Processing\n(Volume 2: Short Papers), 438\u2013444. Beijing, China: Associ-\nation for Computational Linguistics.Conneau, A. 2019. Unsupervised cross-lingual representa-\ntion learning at scale. arXiv preprint arXiv:1911.02116.\nConneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V .;\nWenzek, G.; Guzm \u00b4an, F.; Grave, \u00b4E.; Ott, M.; Zettlemoyer,\nL.; and Stoyanov, V . 2020. Unsupervised Cross-lingual Rep-\nresentation Learning at Scale. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational Lin-\nguistics, 8440\u20138451.\nCook, O.; Grimshaw, C.; Wu, B.; Dillon, S.; Hicks, J.; Jones,\nL.; Smith, T.; Szert, M.; and Song, X. 2024. Efficient An-\nnotator Reliability Assessment and Sample Weighting for\nKnowledge-Based Misinformation Detection on Social Me-\ndia.arXiv preprint arXiv:2410.14515.\nDe Vreese, C. H. 2005. News framing: Theory and typology.\nInformation design journal+ document design, 13(1): 51\u2013\n62.\nDiMaggio, P.; Nag, M.; and Blei, D. 2013. Exploiting affini-\nties between topic modeling and the sociological perspective\non culture: Application to newspaper coverage of US gov-\nernment arts funding. Poetics, 41(6): 570\u2013606.\nD\u2019angelo, P. 2018. Doing news framing analysis II. Empir-\nical and Theoretical Perspectives.\nEntman, R. M. 1993. Framing: Toward clarification of a\nfractured paradigm. Journal of communication, 43(4): 51\u2013\n58.\nGamson, W. A.; Croteau, D.; Hoynes, W.; and Sasson, T.\n1992. Media images and the social construction of reality.\nAnnual review of sociology, 18(1): 373\u2013393.\nGrootendorst, M. 2022. BERTopic: Neural topic model-\ning with a class-based TF-IDF procedure. arXiv preprint\narXiv:2203.05794.\nGu, Y .; Huang, Z.; Zeng, M.; Qiu, M.; and Park, J. 2025. Im-\nproving Automatic Grammatical Error Annotation for Chi-\nnese Through Linguistically-Informed Error Typology. In\nProceedings of the 31st International Conference on Com-\nputational Linguistics, 2781\u20132798.\nGururangan, S.; Marasovi \u00b4c, A.; Swayamdipta, S.; Lo, K.;\nBeltagy, I.; Downey, D.; and Smith, N. A. 2020. Don\u2019t Stop\nPretraining: Adapt Language Models to Domains and Tasks.\nInProceedings of the 58th Annual Meeting of the Associa-\ntion for Computational Linguistics, 8342\u20138360.\nHamborg, F.; Donnay, K.; and Gipp, B. 2019. Automated\nidentification of media bias in news articles: an interdisci-\nplinary literature review. International Journal on Digital\nLibraries, 20.\nHertog, J. 2001. A multiperspectival approach to framing\nanalysis: A field guide. Framing public life/Erlbaum.\nJiang, Y . 2023. Team QUST at SemEval-2023 Task 3: A\nComprehensive Study of Monolingual and Multilingual Ap-\nproaches for Detecting Online News Genre, Framing and\nPersuasion Techniques. In Ojha, A. K.; Do \u02d8gru\u00a8oz, A. S.;\nDa San Martino, G.; Tayyar Madabushi, H.; Kumar, R.;\nand Sartori, E., eds., Proceedings of the 17th International\nWorkshop on Semantic Evaluation (SemEval-2023), 300\u2013\n306. Toronto, Canada: Association for Computational Lin-\nguistics.\n2410\nKwak, H.; An, J.; and Ahn, Y .-Y . 2020. A systematic media\nframe analysis of 1.5 million new york times articles from\n2000 to 2017. In Proceedings of the 12th ACM Conference\non Web Science, 305\u2013314.\nLecheler, S.; and de Vreese, C. H. 2012. News Framing\nand Public Opinion. Journalism & Mass Communication\nQuarterly, 89: 185 \u2013 204.\nLecheler, S.; and De Vreese, C. H. 2019. News framing ef-\nfects: Theory and practice. Taylor & Francis.\nLiao, Q.; Lai, M.; and Nakov, P. 2023. MarsEclipse at\nSemEval-2023 Task 3: Multi-lingual and Multi-label Fram-\ning Detection with Contrastive Learning. In Ojha, A. K.;\nDo\u02d8gru\u00a8oz, A. S.; Da San Martino, G.; Tayyar Madabushi,\nH.; Kumar, R.; and Sartori, E., eds., Proceedings of the 17th\nInternational Workshop on Semantic Evaluation (SemEval-\n2023), 83\u201387. Toronto, Canada: Association for Computa-\ntional Linguistics.\nLiu, S.; Guo, L.; Mays, K.; Betke, M.; and Wijaya, D. T.\n2019. Detecting frames in news headlines and its applica-\ntion to analyzing news framing trends surrounding US gun\nviolence. In Proceedings of the 23rd conference on compu-\ntational natural language learning (CoNLL), 504\u2013514.\nMorstatter, F.; Wu, L.; Yavanoglu, U.; Corman, S. R.; and\nLiu, H. 2018. Identifying framing bias in online news. ACM\nTransactions on Social Computing, 1(2): 1\u201318.\nMu, Y .; Jin, M.; Grimshaw, C.; Scarton, C.; Bontcheva, K.;\nand Song, X. 2023. Vaxxhesitancy: A dataset for studying\nhesitancy towards covid-19 vaccination on twitter. In Pro-\nceedings of the International AAAI Conference on Web and\nSocial Media, volume 17, 1052\u20131062.\nNguyen, V .-A.; Boyd-Graber, J.; Resnik, P.; and Miler, K.\n2015. Tea party in the house: A hierarchical ideal point\ntopic model and its application to republican legislators in\nthe 112th congress. In Proceedings of the 53rd Annual Meet-\ning of the Association for Computational Linguistics and\nthe 7th International Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), 1438\u20131448.\nOpenAI; Achiam, J.; Adler, S.; Agarwal, S.; and et al. 2024.\nGPT-4 Technical Report. arXiv:2303.08774.\nPiskorski, J.; Stefanovitch, N.; Da San Martino, G.; and\nNakov, P. 2023. SemEval-2023 Task 3: Detecting the Cate-\ngory, the Framing, and the Persuasion Techniques in Online\nNews in a Multi-lingual Setup. In Ojha, A. K.; Do \u02d8gru\u00a8oz,\nA. S.; Da San Martino, G.; Tayyar Madabushi, H.; Ku-\nmar, R.; and Sartori, E., eds., Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation (SemEval-\n2023), 2343\u20132361. Toronto, Canada: Association for Com-\nputational Linguistics.\nReimers, N.; and Gurevych, I. 2020. Making Monolingual\nSentence Embeddings Multilingual using Knowledge Distil-\nlation. In Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing. Association for\nComputational Linguistics.\nReiter-Haas, M.; Kl \u00a8osch, B.; Hadler, M.; and Lex, E. 2024.\nFrameFinder: Explorative Multi-Perspective Framing Ex-\ntraction from News Headlines. In Proceedings of the 2024Conference on Human Information Interaction and Re-\ntrieval, 381\u2013385.\nSi, C.; Zhang, Z.; Chen, Y .; Qi, F.; Wang, X.; Liu, Z.; Wang,\nY .; Liu, Q.; and Sun, M. 2023. Sub-character tokenization\nfor Chinese pretrained language models. Transactions of the\nAssociation for Computational Linguistics, 11: 469\u2013487.\nVan Dijk, T. A. 2023. Analyzing frame analysis: A criti-\ncal review of framing studies in social movement research.\nDiscourse Studies, 25(2): 153\u2013178.\nWang, G.; Frederick, R.; Haghighi, B. T.; Wong, B. W.; Ru-\npar, V .; Li, W.; and Bai, Q. 2024. FramedTruth: A Frame-\nBased Model Utilising Large Language Models for Misin-\nformation Detection. In Asian Conference on Intelligent In-\nformation and Database Systems, 135\u2013146. Springer.\nWilby, D.; Karmakharm, T.; Roberts, I.; Song, X.; and\nBontcheva, K. 2023. GATE Teamware 2: An open-source\ntool for collaborative document classification annotation. In\nProceedings of the 17th Conference of the European Chap-\nter of the Association for Computational Linguistics: System\nDemonstrations, 145\u2013151.\nWilkinson, M. D.; Dumontier, M.; Aalbersberg, I. J.; Apple-\nton, G.; Axton, M.; Baak, A.; Blomberg, N.; Boiten, J.-W.;\nda Silva Santos, L. B.; Bourne, P. E.; et al. 2016. The FAIR\nGuiding Principles for scientific data management and stew-\nardship. Scientific data, 3(1): 1\u20139.\nWu, B.; Li, Y .; Mu, Y .; Scarton, C.; Bontcheva, K.; and\nSong, X. 2023a. Don\u2019t waste a single annotation: improv-\ning single-label classifiers through soft labels. In Findings\nof the Association for Computational Linguistics: EMNLP\n2023, 5347\u20135355.\nWu, B.; Razuvayevskaya, O.; Heppell, F.; Leite, J. A.; Scar-\nton, C.; Bontcheva, K.; and Song, X. 2023b. Sheffield-\nVeraAI at SemEval-2023 Task 3: Mono and Multilingual\nApproaches for News Genre, Topic and Persuasion Tech-\nnique Classification. In Proceedings of the 17th Interna-\ntional Workshop on Semantic Evaluation (SemEval-2023) ,\n1995\u20132008.\nPaper Checklist\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes.\n(b) Do your main claims in the abstract and introduction\naccurately reflect the paper\u2019s contributions and scope?\nYes.\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes.\n(d) Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? Yes.\n(e) Did you describe the limitations of your work? Yes,\nsee Limitations.\n(f) Did you discuss any potential negative societal im-\npacts of your work? Yes, see Ethics Statement.\n2411\n(g) Did you discuss any potential misuse of your work?\nYes, see Ethics Statement.\n(h) Did you describe steps taken to prevent or mitigate\npotential negative outcomes of the research, such as\ndata and model documentation, data anonymization,\nresponsible release, access control, and the repro-\nducibility of findings? Yes, see Dataset Availability\nand Ethics Statement.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all\ntheoretical results? N/A.\n(b) Have you provided justifications for all theoretical re-\nsults? N/A.\n(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? N/A.\n(d) Have you considered alternative mechanisms or expla-\nnations that might account for the same outcomes ob-\nserved in your study? N/A.\n(e) Did you address potential biases or limitations in your\ntheoretical framework? N/A.\n(f) Have you related your theoretical results to the existing\nliterature in social science? N/A.\n(g) Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? N/A.\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? N/A\n(b) Did you include complete proofs of all theoretical re-\nsults? N/A\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-\nther in the supplemental material or as a URL)? Yes,\nsee the footnote on page 1.\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? Yes, see Ex-\nperimental Setup.\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nYes, see Table 5.\n(d) Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? Yes, see Experimental De-\ntails.\n(e) Do you justify how the proposed evaluation is suffi-\ncient and appropriate to the claims made? Yes, see Re-\nsults and Discussion.\n(f) Do you discuss what is \u201cthe cost\u201c of misclassification\nand fault (in)tolerance? Yes, see Classification Report.5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity...\n(a) If your work uses existing assets, did you cite the cre-\nators? Yes.\n(b) Did you mention the license of the assets? No, as all\nreferenced datasets and assets were publicly available\nand used in accordance with their respective licenses.\nAppropriate citations have been included throughout\nto ensure compliance.\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? Yes, see the footnote on page 1.\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you\u2019re using/curating?\nYes, see Ethics Statement.\n(e) Did you discuss whether the data you are using/cu-\nrating contains personally identifiable information or\noffensive content? Yes, see Ethics Statement.\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR?\nYes, see Dataset Availability.\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset? Yes, see the Zenodo\nlink in Dataset Availability.\n6. Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? Yes, see the Zenodo link\nin Dataset Availability.\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? Yes, see Ethics Statement.\n(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? Yes, see Data Annotation.\n(d) Did you discuss how data is stored, shared, and deiden-\ntified? Yes, see Dataset Availability and Ethics State-\nment.\nEthics Statement\nOur study has received ethical approval from the Univer-\nsity of Sheffield. All participants provided informed consent\nby signing the consent form after reviewing the information\nsheet detailing the annotation task. Annotator identities re-\nmain anonymous and any news content itself will not be in-\ncluded in the published dataset.\nThe potential use of this dataset by malicious actors has\nbeen considered, potentially allowing the generation of ma-\nliciously framed content; this behaviour is already possible\nwith existing Large Language Model technology (Gururan-\ngan et al. 2020). Proper use, however, has much more poten-\ntial for good in the form of understanding media bias, pro-\nviding balanced search results, and conducting large-scale\ncontent analysis in research.\n2412", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A dataset for analysing news framing in Chinese media", "author": ["O Cook", "Y Mu", "X Yang", "X Song"], "pub_year": "2025", "venue": "Proceedings of the \u2026", "abstract": "Framing is an essential device in news reporting, allowing writers to influence public  perceptions of current affairs. While automatic news framing detection datasets exist in various"}, "filled": false, "gsrank": 409, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35943", "author_id": ["A78rPvIAAAAJ", "WuS2yawAAAAJ", "", "7seaj48AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ZxIKIoDc9bwJ:scholar.google.com/&output=cite&scirp=408&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZxIKIoDc9bwJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 1, "citedby_url": "/scholar?cites=13616031491309572711&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ZxIKIoDc9bwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/35943/38097"}}, {"title": "A first look at COVID-19 information and misinformation sharing on Twitter", "year": "2020", "pdf_data": "A \frst look at COVID-19 information and misinformation sharing\non Twitter\nLisa Singha, Shweta Bansala, Leticia Bodea, Ceren Budakb, Guangqing Chic,\nKornraphop Kawintiranona, Colton Paddena, Rebecca Vanarsdalla, Emily Vragad,\nYanchen Wanga\naGeorgetown University;bUniversity of Michigan;\ncPennsylvania State University;dUniversity of Minnesota\nARTICLE HISTORY\nCompiled April 1, 2020\nABSTRACT\nSince December 2019, COVID-19 has been spreading rapidly across the world. Not\nsurprisingly, conversation about COVID-19 is also increasing. This article is a \frst\nlook at the amount of conversation taking place on social media, speci\fcally Twitter,\nwith respect to COVID-19, the themes of discussion, where the discussion is emerg-\ning from, myths shared about the virus, and how much of it is connected to other\nhigh and low quality information on the Internet through shared URL links. Our\npreliminary \fndings suggest that a meaningful spatio-temporal relationship exists\nbetween information \row and new cases of COVID-19, and while discussions about\nmyths and links to poor quality information exist, their presence is less dominant\nthan other crisis speci\fc themes. This research is a \frst step toward understanding\nsocial media conversation about COVID-19.\nKEYWORDS\nCOVID-19; coronavirus; twitter conversation; misinformation\n1. Introduction\nIn December 2019, a cluster of pneumonia cases caused by a novel coronavirus\n(COVID-19) was identi\fed in Wuhan, China. In the months since, the outbreak has\nrapidly spread around the world, leading to hundreds of thousands of cases in over 160\ncountries [1]. This unparalleled global health emergency has resulted in an unprece-\ndented political and social response, and is already having massive consequences on\nthe global economy. The avalanche of human response is being facilitated by the \row\nof information from the broadcast world of traditional media but, in particular, by the\nnetworked world of social media.\nSocial media is a signi\fcant conduit for news and information in the modern media\nenvironment, with one in three people in the world engaging in social media, and two\nthirds of those on the Internet using it [2]. The popularity is higher in the United\nStates with 68% of American adults reporting they get news on social media [3].\nThis is particularly true for health and science information, with a third of people\nreporting that social media are an important source of science news [4]. Twitter users,\nlisa.singh@georgetown.eduarXiv:2003.13907v1  [cs.SI]  31 Mar 2020\nin particular, are known for sharing and consuming news: 59% of Twitter users describe\nit as good or extremely good for sharing preventive health information [5].\nHowever, social media is also rife with health misinformation. Health misinforma-\ntion - often de\fned as information that counters best available evidence from medical\nexperts at the time ( [6] see also [7{10]) - has been documented across almost all\nsocial media platforms, including Facebook, Twitter, YouTube, Pinterest, and Insta-\ngram [11{16]. Moreover, health misinformation is not limited to any one issue, but\nincludes vaccination misinformation (both generally and speci\fc cases such as HPV\nor \ru), and misinformation about global health crises like the Ebola outbreak in 2014,\nand the spread of Zika in 2016.\nWhile past epidemics highlight the importance of studying infectious disease related\nsocial media content, there is a particular signi\fcance and urgency in studying social\nmedia content for COVID-19. First, we expect social media to play an even bigger\nrole in the spread of information about COVID-19; for example, there were 255 million\nactive Twitter users in February 2014 during the start of the Ebola outbreak [17]. This\nnumber topped 330 million in 2019 [18]. Put simply, a lot more people are connecting to\nothers online and getting their news through social media platforms such as Twitter [3,\n4]. Second, there is reason to be more concerned about the quality of such information\nin today's news ecosystem compared to that of earlier epidemics. As recent research\nshows, trust in institutions is eroding [19] and this is accompanied by an uptick in\nthe spread of misinformation online. Therefore, it is crucial to study and understand\nthe conversation surrounding the fast-moving COVID-19 pandemic through the lens\nof social media.\nThis article looks at the amount of conversation taking place on social media, specif-\nically Twitter, with respect to COVID-19, the themes of discussion, where the discus-\nsion is emerging from, and how much of it is connected to other high and low quality\ninformation on the Internet through shared URL links. We also identify and look at\nthe overall and temporal level of discussion of \fve speci\fc myths shared on Twitter.\nWe pause to mention that all of the signals we are measuring and using are, at best,\nmoderate quality indicators from social media to reported cases of COVID-19. But it\nis precisely because we do not have access to high quality indicators that we must take\nthe time to calibrate moderate and poor quality indicators, glean insight from these\nindicators, and understand their relationship to each other. While this paper will not\ntackle the measurement issues associated with indicators, we recognize its importance\nas part of our longer term research agenda.\nOur preliminary \fndings suggest that (1) conversation about the virus continues\nto grow, (2) for some countries, information \row leads new cases of COVID-19 by\n2-5 days, (3) predominant themes of conversation include health/the virus itself or\nthe global nature of the pandemic, and (4) misinformation and myths are discussed,\nbut at lower volume than other conversation. While many of these \fndings are not\nsurprising, they remind us of the importance of social media during times of crisis and\ngive preliminary support for using this open platform as a surveillance approach for\nunderstanding how people are impacted by a crisis.\n2. Size of COVID-19 Conversation\nConversation size gives us insight into the amount of attention placed on a topic. In\nthis section we measure the amount of conversation taking place about COVID-19 in\ngeneral and by language.\n2\n2.1. Description of Data Set\nUsing the Twitter Streaming API, we began collecting tweets related to COVID-\n19 on January 16, 2020. Data collection continues, but the data we present in this\nstudy is from January 16, 2020 to March 15, 2020. Table 6 in Appendix A shows the\nEnglish hashtags we used to collect data and the dates we began collecting data for\nthe hashtag. Most of the data collection began in January, and additional hashtags\nwere added in mid-March to re\rect the changing nature of the conversation around\nCOVID-19 online.1\n2.2. General Conversation Volume\nDuring the study period of January 16 through March 15, the overall number of tweets\nis 2,792,513, quotes are 456,878, and retweets are 18,168,161. Figure 1 shows the overall\nvolume of tweets, and the volume of tweets and retweets separately. Initial tweets\nabout COVID-19 were relatively infrequent. It is not surprising that both the tweet\nand retweet volume continue to increase as the epidemic unfolds. What is interesting\nis that there is no single event that has propelled the increase. The peak volume days\nmap to a series of events unfolding throughout the crisis.\nFigure 1.: Overall Volume of Tweets (1/16/20 { 3/15/20)\nThere was a signi\fcant ramping up in late January around the 25th. On January\n24th, multiple countries, including Japan, South Korea, and the United States, re-\nported cases, and the increasing number of cases in China led the Chinese government\nto begin a quarantine in the Hubei province [20]. On January 25th, Hong Kong de-\n1Note that due to a data collection glitch with the Twitter Streaming API, some of the hashtags were\nunavailable between March 13, 2020 and March 15, 2020.\n3\nFigure 2.: COVID-19 Tweets by Language (1/16/20 { 3/15/20)\nclared a state of emergency and the United States also announced plans to evacuate\nUS citizens from Wuhan [21]. This was followed by a tapering o\u000b in the \frst half of\nFebruary. During this time, the cases continued to grow around the world, but little\ngovernment action was taking place outside of Asia. At the end of February, another\nlarge increase in volume occurred. That was when the number of deaths in Iran and\nItaly grew over 30 and 20, respectively, and Switzerland banned all gatherings/events\nlarger than 1000 people. February 29th was also the date of the \frst death due to\nCOVID-19 in the United States [22]. Following that time period, there was an overall\nincreasing trend, with volume essentially doubling from the \frst to the second week\nin March.2Essentially, this suggests that attention to COVID-19 has increased sig-\nni\fcantly over the last two months, and is growing at a faster rate in March than in\nJanuary.\n2.3. Tweet Volume By Language\nTwitter speci\fes the language of each tweet when using its streaming API. To get\na better sense of the global nature of the conversation, we look at the proportion\nof tweets in di\u000berent languages over time in Figure 2. Not surprisingly, given world-\nwide Twitter usage, the majority of tweets (57.1%) are in English. This is followed\nby Spanish (11.6%), French (6.5%), and Italian (4.8%). While English and Spanish\nare generally dominant languages on Twitter (see Figure 3), we see that the language\ndistribution for COVID-19 tweets does vary from the overall Twitter population [23]\n2Again, recall that numbers for March 13 and 14 are lower due to an API glitch, so the signi\fcant dropo\u000b at\nthat point is merely an artifact\n4\nFigure 3.: Relationship Between COVID-19 Tweet Languages and Overall Twitter\nLanguage Distribution (1/16/20 { 3/15/20)\nfor English and other languages. The languages that are most prevalent are the pre-\ndominant languages in countries where many of the outbreaks have taken place during\nthis time, including the United States (1,678 con\frmed cases as of March 15), Spain\n(5,753 con\frmed cases), France (4,469 con\frmed cases), and Italy (21,157 con\frmed\ncases) [1]. Given their signi\fcant outbreaks, we might have expected more tweets in\nChinese (81,048 con\frmed cases) and German (3,795 con\frmed cases), although Twit-\nter use in both countries is relatively low (Twitter is blocked in China, although some\npeople use VPN to get around that limitation; Twitter is used by only 9.8% of adults\nin Germany [24]). The languages that are more prevalent on Twitter but not as repre-\nsented in the COVID-19 tweets when considering the overall distribution of language\non Twitter are Indonesian, Arabic, and Malay.\nFocusing in on the languages that are more prevalent in Figures 2 and 3, we look\nat how the volume changes from mid-January to mid-March in Figure 6. Figure 4a\nshows the higher volume of tweets in January and early February in Chinese, and a\ncontrasting view of volume for the tweets in English. For English, there is a small\nspike in January, with a decrease in volume until late February. This is when more\ncases began emerging in North America and Europe. The trend that English follows is\nsimilar for French, German, Italian, Spanish and Turkish - an initial increase followed\nby a period of low discussion followed by a large increase and spikes in March. This can\nbe seen in Figure 4b. Spanish, being spoken signi\fcantly in North America and Europe\nand having a large Twitter user base has the highest increase. Finally, Figure 4c shows\na contrast in two predominantly Asian Languages, Japanese and Thai. After an initial\nspike in January when initial cases were con\frmed in both these countries, the volume\nof Japanese conversation has been fairly constant. In contrast, the volume of Thai\ntweets had a very high spike in January and a high one in March. This di\u000berence in\ntrend may be related to doubling in the number of cases reported in Thailand between\nlate February and min-March and the \frst COVID-19 death in March [25].\n3. Location of Conversation and Its Relationship to COVID-19 Cases\nPrevious work has shown that social media can be used to help inform where people\nmay move during periods of forced migration [26]. In this section, we are interested in\n5\nFigure 4.: Tweet Volume By Language\n(a) Chinese and English\n(b) French, German, Italian, Spanish and Turkish\n(c) Japanese and Thai\n6\nextending this idea to see if social media can help inform the public about movement\nof a disease. To begin to understand the relationship between these di\u000berent signals,\nwe look at the relationship between where people tweet from, what locations people\ntweet about, and reported COVID-19 cases.\n3.1. Description of Data Sets\nWe use two sets of Twitter data to look into this. The \frst set is extracted from our\nTwitter data with location mentions; for example, if both China and COVID-19 are\nmentioned in a tweet, that tweet will be assigned to China regardless of where that\ntweet is sent from. We refer to this set of tweets as conversation location tweets. To\ndetermine the locations mentioned in the tweet, we compare the words in the tweet to\na location ontology we created using Wikipedia and Statoids [27] that contains cities,\nprovinces, states, and countries.3\nOur second data set contains geotagged tweets, which are tweets that users choose\nto tag with a longitude and latitude location (this is relatively rare, as it is not the\ndefault setting in Twitter). This allows us to track with greater con\fdence where\nthe tweets come from. We were able to collect 100% of the existing geotagged tweets\nmentioning any of our hashtags through the Twitter API. Our \fnal data set comes\nfrom the World Health Organization. It contains the number of con\frmed COVID-19\ncases in di\u000berent countries as of March 15, 2020 [1].\n3.2. Locations of Twitter conversation\nFigure 5 shows two maps each containing the COVID-19 reported case count and one of\nour Twitter location data sets. Figure 5a illustrates the number of con\frmed COVID-\n19 cases and the number of conversation location tweets by country. 217 countries were\nmentioned and 184 of them were mentioned at least 10 times. Overall, it appears that\nconversation location tweets and con\frmed cases of COVID-19 are highly correlated;\ncountries that have more cases also have more conversation location tweets (tweets\nthat mention the country itself or a location in that country). Among the conversation\nlocation tweets, COVID-19 was mentioned the most in China, followed by the USA,\nIndia, Iran, and Italy. It makes sense that China has the most COVID-19 mentions\nfrom January 16 to March 15, when China was the epicenter of COVID-19. The USA\nhas the second highest tweet mentions, although the USA ranks only 8th place in\nterms of cases by March 15; this is likely because the USA has the largest Twitter user\npopulation and the most Asian immigrants, who may have been following COVID-19\ntrends earlier than other population groups.\nFigure 5b maps the number of geotagged tweet mentions of COVID-19 by country.\nNote that these tweets were sent out from the corresponding countries and that so\nfar we have collected geotagged tweets in English only. The United States has the\nmost geotagged tweet mentions of COVID-19, followed by the United Kingdom, Italy,\nPoland, Nigeria, China, Spain, and India. It is not surprising that the United States and\nthe United Kingdom have the most geotagged tweet mentions since both are English\nspeaking countries and our geotagged tweets are limited to English only. During the\n3Wikipedia has a set of pages listing the major cities around the world by country. Statoids lists governorates\nand the governorates capitals for each country. Combining these two sources, we construct an ontology contain-\ning approximately 7,600 locations, including countries, governorates, governorates capitals, and other major\ncities.\n7\nFigure 5.: Tweet Volume and COVID-19 Cases\n(a) Conversation Location\n(b) Geo-tagged Location\n8\nstudy period, Italy has the second most COVID-19 cases and the third most geotagged\ntweet mentions. It is interesting that although Twitter is restricted in China and most\nChinese people speak Chinese only, China has the sixth most geotagged tweet mentions\nfrom January 16 to March 15, when China was the epicenter of the COVID-19. When\nwe compute the Pearson correlation between the volumes of the location conversation\ntweets and the geotagged tweets by countries, we get a correlation of 0.75, if we\nexclude China from the calculation. While not a perfect proxy for geotagged tweets,\nit is a reasonable one.\n3.3. Comparison between location conversation and COVID-19\nWe take a deeper dive into three countries (the United States, Italy, and China), chosen\nbecause 1) they each have a large number of con\frmed COVID-19 cases, 2) they are\neach on a di\u000berent continent, o\u000bering some variance in location and culture, and 3)\nthey are at di\u000berent stages of their epidemic trajectory, allowing some insight into how\nconversations might change over the course of an outbreak in a country.\nTable 1.: Pearson Correlations between Location Conversation and COVID Cases with\nDi\u000berent Leads and Lags in the USA, Italy, and China.\nLag/Lead US Italy China-A China-B\nLag = 5 days 0.492 0.645 0.037 0.295\nLag = 4 days 0.487 0.649 0.141 0.371\nLag = 3 days 0.458 0.698 0.156 0.488\nLag = 2 days 0.617 0.748 0.208 0.565\nLag = 1 day 0.667 0.724 0.275 0.610\nNo lag or lead 0.639 0.744 0.293 0.680\nLead = 1 day 0.693 0.699 0.283 0.720\nLead = 2 days 0.780 0.709 0.291 0.753\nLead = 3 days 0.645 0.837 0.344 0.771\nLead = 4 days 0.637 0.880 0.425 0.794\nLead = 5 days 0.649 0.885 0.391 0.803\naAll correlations for the United States, Italy, and China-B are statistically signi\fcant at p <= 0.05.\nThis initial analysis focuses on the time series of the location conversation tweets\nand the newly identi\fed and con\frmed COVID-19 cases each day. We compute the\nPearson correlation between time series of location conversation tweets and COVID-19\ncases with di\u000berent leads and lags to determine if a relationship exists between the\ntwo variables. We hypothesize that social media communications may be predictive of\ncases, creating opportunities for disease forecasting.\nThe cross-correlation analysis between location conversation and COVID cases is\npresented in Table 1. For China we have two columns, one with all the dates (China-A)\nand one that removes the single day spike on February 12, 2020 due to a change in\ntesting procedure (China-B) [28]. The numbers in bold are the highest correlations for\neach country. If the highest and second highest correlation values are within 0.01 of\neach other, we highlight both. A lead refers to the tweets occurring before the cases;\nfor example, a two-day lead means that we match the tweet conversations with the\nnumber of new cases two days later. In contrast, a lagrefers to the tweets occurring\nafter the cases; a two-day lag means that we match the tweet conversations with the\n9\nFigure 6.: The number of COVID-19 Cases and Location Conversation\n(a) United States: Lead = 2 Days\n(b) Italy: Lead = 4 Days\n(c) China: Lead = 4 Days\n10\nnumber of new cases from two days earlier.\nWe \fnd that social media conversations are more highly correlated with COVID-19\ncases with a lead than with a lag (Table 1). That is, it seems that tweets increase in\nvolume before con\frmed cases increase in a given country. This suggests that social\nmedia conversations may be a leading indicator of disease cases, which can be explained\nby the lag between symptom onset and the progression of severe symptoms leading\nto testing (though this might depend on di\u000berent protocols for testing implemented\nin di\u000berent countries). Additionally, we \fnd that conversations mentioning COVID-19\nand locations in the United States, Italy and China-B all show a strong association to\ncon\frmed cases. This result suggests that the association between conversations and\ncases is indicative of both a direct e\u000bect and an indirect e\u000bect given the lack of Twitter\nusage in China. We also \fnd that the lead time of 2 days for the US (Figure 6a), 4-\n5 days for Italy (Figure 6b), and 4-5 days for China-B (Figure 6c) demonstrate the\nstrongest correlations between location conversation mentions and con\frmed cases.\n4. Content of English Conversation\nWhat are the most prevalent words and themes of discussion taking place about\nCOVID-19? In this section, we take a \frst look at the content of the conversation\ntaking place on Twitter.\n4.1. Words Being Used\nWe begin by looking at the most frequent words in each tweet. Table 2 shows the\ntop 10 words, excluding stopwords, and the number of tweets they appear in. It is\nnot surprising that most of these words are very broad. To expand on this, Figure 7\nshows a word cloud containing words that appear in at least 150,000 tweets. Words\nare sized based on how frequently they appear with larger words appearing in more\ntweets. We see that the dominant words across our data set focus on the global nature\nof the virus, words describing the virus and its spread, and responses to the outbreak.\nA strong focus on China re\rects the focus of attention during the early phases of this\nepidemic.\nTable 2.: Top 10 Most Frequently Used Words in Tweets.\nWord Volume\nchina 1,412,521\npeople 1,155,989\ncases 929,914\nwuhan 841,901\ncoronavirus 821,484\nnew 793,917\nchinese 765,332\nwho 712,041\nvirus 615,342\ncon\frmed 585,393\n11\nFigure 7.: Word Cloud of Frequently Mentioned Words in COVID-19 Tweets\n4.2. Prevalent Themes\nSince words alone give us limited insight into peoples themes/topics of conversation,\nwe next identify common themes in tweets about COVID-19 and how the prevalence\nof these themes change over time.\n4.2.1. Methodology\nTo achieve this, we \frst identify the set of frequent words that are observed at least\n50,000 times in our tweets data set. This list includes 537 unique words. These words\nare then grouped into themes by three researchers through open coding. We identify\neight high level categories: Economy, Emotion, Illness, Global Nature, Information\nProviders, Social, Government Response, and Individual Response. We provide details\nabout these topics below in Table 3. After determining the set of themes, word-to-\ntheme mapping was constructed through majority voting{a word is assigned to a\ngiven topic if at least two out of the three researchers agreed that the assignment was\ncorrect. The words that do not belong in any of these categories (e.g. stop words) are\nremoved. Word variations were also added (e.g. plurals) to increase coverage. While\nthese themes are a reasonable \frst pass, we plan to improve these in the future using\nsemi-supervised, iterative topic modeling since fully automated topic modeling is less\ne\u000bective on tweets.\nFor each tweet, we identify the words that map from each theme and proportionally\nassign themes to the tweet. Then the proportions are summed together per day to\ndetermine the overall tweet volume of the di\u000berent themes. Approximately 80% percent\nof the tweets were labeled with one or more themes.\n4.2.2. Findings\nFigure 8 summarizes the overall distribution of the themes presented in Table 3. We\nobserve that most Twitter conversations are about one of two topics: either health/the\nvirus itself or the global nature of the pandemic. It is not surprising since these cate-\ngories contain a larger number of broader terms about the pandemic. The \frst category\nincludes conversations about the virus itself, broader health consequences, vaccines,\ntesting, and references to other epidemics. This accounts for 30% of the labeled con-\ntent. The second similarly-sized theme is the global nature of COVID-19. Twitter users\n12\nTable 3.: Summary of the themes identi\fed using most frequent words in tweets.\nThemeNumber\nof WordsExample words\nEconomy 12 Market, stocks, futures\nEmotion 24 Fear, joke, hope\nHealthcare/Illness/Virus 64 Patients, coronavirus, infected, vaccine, tested, sars\nGlobal Nature 75 Pandemic, international, China, Italy, travel\nInformation Providers 28 Media, CDC, WHO, experts\nSocial 6 Family, friends, community\nGovernment/ Government Response 28 Trump, senator, lockdown\nIndividual Concerns/Strategies 28 Disinfect, wash, facemasks\nFigure 8.: Distribution of Themes in Tweets\nare commonly referring to locations around the world where the disease is spreading\n(e.g. China, Italy) and referring to its scale (e.g. pandemic, worldwide). This theme\naccounts for 29% of labeled content. The next biggest theme is information providers\n(11%). This suggests that a sizable number of tweets are referring to or talking about\nsources of information about the disease (e.g. CDC or news media). In the time period\nwe consider, the economy theme was rather rare (3%). This fact might change over\ntime if disease control improves and the immediate e\u000bects of the disease are overshad-\nowed by secondary e\u000bects, including possible economic consequences. Finally, we note\nthat the emotion theme, containing words like fear, sad, hope, makes up 9% of the\nlabeled tweets. This is a signi\fcant fraction, and a reminder that attention needs to\nbe given to mental health needs during this crisis.\nAs the epidemic grows and evolves, it is plausible that the themes and their preva-\nlence will also evolve. Therefore, we next inspect the time series of the prevalence of\nthe top \fve themes. The results are summarized in Figure 9. We observe that all the\nthemes have a similar trend to the trend of the overall volume for COVID-19 hashtags.\nThe global nature of the disease and the health/virus themes are the most common\ntheme early on. This is likely due to tweets referring to China when talking about\nCOVID-19 and general conversation about the virus and cases. Starting with the last\nweek of February, as the reality sets in that COVID-19 is spreading in the United\nStates, all the themes become more popular, highlighting the continued diversity of\nthe conversation.\n13\nFigure 9.: Volume of Top 5 Themes in Tweets over Time\n5. Myths About the Virus\nA large number of myths have emerged during this crisis. In this analysis, we are\ninterested in determining how many tweets are discussing some of the most prevalent\nmyths.\n5.1. Methodology\nTo determine what myths to include in our analysis, we searched di\u000berent websites\nusing the search phrase Coronavirus Common Myths. Then we used the articles to\ndetermine the most common examples. We analyzed a variety of sources including\nblogs, newspapers/media, and medical organizations to get a variety of examples. We\nthen identi\fed common themes among the di\u000berent myths; for example, grouping\nweather and heat myths into a single category. From there, we manually chose the\n\fnal list of myths based on how frequently they appeared during the search process\nand how dangerous they were. For example, while rumors about certain celebrities\ntesting positive were common, they were not as dangerous to the public as myths\nabout treatments or vaccines. We initially identi\fed ten myths ranging from home\nremedies to conspiracy theories about the origin of the virus to misinformation about\nwarm weather killing the virus.\nTo understand how certain myths about COVID-19 gained traction on social media,\nwe searched for each of these myths in our tweet collection. We preprocessed the tweets\nto normalize capitalization and remove punctuation, and URLs. For each common\nmyth, our team identi\fed ten tweets that perpetuated the relevant myth. We identi\fed\nphrases and words from the tweets and broad descriptions of the myths from our\noriginal Google searches that described each myth. For each such word/phrase, we\nassign a weight to signify the expectation that a tweet including this word/phrase\nwould be about that given myth. For instance, the word bioweapon is a stronger\nsignal about a bioweapon myth compared to government lab which occurs in fewer\nbioweapon myth tweets.\nAfter completing the word/phrase list for each myth, we then searched for words and\n14\nFigure 10.: Myths about COVID-19\nphrases from each myth in each tweet, and proportionally assigned myths to tweets.\nThe proportions are then summed together per day to determine the tweet volume\nof each myth. The results presented focus on the \fve myths that we identify most\naccurately: Origin of COVID-19, Vaccine Development, Flu Comparison, Heat Kills\nDisease, Home Remedies. Figure 10 presents a description of each of these \fve myths.4\n5.2. Findings\nFocusing on the number of tweets originally containing one or more of these \fve myths,\nwe \fnd that approximately 16,000 tweets (just under 0.6% of the tweets) are discussing\none or more of the myths we consider. Figure 11 shows the distribution of the volume\nof each myth discussed.\nTweet volume associated with the myths in our sample has increased since January,\n4Given the simple approach, we recognize that some tweets with more noise will be missed. However, we are\nerroring on the side of being more conservative, i.e. optimizing for precision instead of recall. After applying this\napproach, we manually validated 250 tweets, 25 for each category, and 25 that were identi\fed as non-myths.\nFive of our categories had an overall test precision of 80% and our precision for identifying non-myths in our\ntest set was 100%. In other words, 80% of the hand-validated tweets belonged to the myths, and 100% of the\ntweets coded as not matching the myths did not contain the myths.\n15\nFigure 11.: Distribution of by Myths\nFigure 12.: Tweet Volume by Myths Over Time\nalthough this may re\rect the growing conversation surrounding COVID-19 generally,\nrather than a greater proportion of attention devoted to these topics (see Figure 12).\nHowever, some trends are growing more than others. Speci\fcally, the myth regard-\ning the origins of the virus dominated the myths present on Twitter in January and\nFebruary. By the end of February, however, the \ru comparison myth and the home\nremedy myth appear almost equally as often in our data set, although there is some\nsuggestive evidence that the \ru comparison myth may have dropped o\u000b at the end\nof our data collection in mid-March. While myths about heat killing COVID-19 and\nvaccine development also appear to rise over time in our data set, they maintain their\nrelative position compared to the other myths and may simply re\rect growing conver-\nsation surrounding the topic. It is important to note that tweets that are countering or\ndebunking a particular myth are also likely to be part of this set of identi\fed tweets.\nTherefore, the numbers we are reporting here likely capture tweets that perpetuate a\nmyth, as well as those combating it. In future analyses, we will use stance detection\nmethods to determine the position of the author with regards to the myth.\n6. Sharing of High vs Low Quality Information on Twitter\nSocial media users commonly rely on external information to convey ideas, support\nclaims, and serve information needs. Social media use around COVID-19 is no excep-\ntion. Our analysis of tweets related to the disease show that 40.5% of original tweet\n16\ncontent (5.1% of the retweet content and 9.6% of the overall content) includes a URL.\nOverall, we think the very high percentage of URLs re\rects the incredible need for\ninformation in this uncertain time. Uncertainty is strongly related to information seek-\ning, and this has been shown speci\fcally in the realm of health information seeking\nand sharing online[29].\n6.1. Popular domains\nWe begin by examining these shared links to determine the most popular domains.\nThere are over sixty thousand unique domains that people share in their tweets. Table 4\npresents the top-10 domains with respect to their frequency in tweets having more than\n100 user accounts tweeting the domain.\nTable 4.: Top-10 domains mentioned in tweets by over 100 handles.\nDomain Tweet Frequency\nyoutu.be 78,784\nyoutube.com 21,894\ninstagram.com 19,158\nnytimes.com 13,678\nbit.ly 12,816\nscmp.com 11,897\namzn.to 11,868\ntheguardian.com 11,671\nbbc.com 10,220\ngisanddata.maps.arcgis.com 9,181\nInspecting these top-10 domains reveals a number of important points. First, people\nare linking to YouTube a lot. The two di\u000berent manifestations of YouTube - youtu.be\nand youtube.com - are collectively linked to in almost 100,000 tweets. Top-10 sites\ninclude news media sites from the U.S. (the New York Times), news media sites\nfrom China (South China Morning Post, scmp.com), and retail sites (Amazon). This\nhighlights the diversity of the nature and quality of information shared from external\nsources on Twitter about COVID-19.\nIf we look at domains that have a similar volume to our top-10 domains, but are\ntweeted by a small number of handles, three domains fall into this category, indicating\nthat some domains/users are attempting to appear more relevant to the conversation.\nFor example, thepigeonexpress.com, a dubious site that claims to be focused on news\nthats not on mainstream media.5has almost as many shares as the New York Times,\nbut less than 20 accounts posting articles using this domain. Given this \fnding, we\nwant to better understand whether social media users are referencing reputable sources\nor questionable ones?\n6.2. High health and low quality information sources\nTo answer this question, we examine the URLs being shared in our data set to deter-\nmine whether or not more low quality links are being shared compared to high quality\nones.\n5https://thepigeonexpress.com/about/\n17\n6.2.1. Methodology\nWe begin by identifying a set of high quality health sources and a set of low-\nquality/questionable content providers.\nHigh Quality Health Sources (HQHS) : We identify the set of reputable web domains\nthat publish health information as follows. We \frst identify all countries identi\fed by\nthe CDC as a Level 3 travel health notice country (that is, with the recommendation\nto avoid all non-essential travel). For each of these countries, we identify the webpage\n(domain) of each countrys equivalent to a center for disease control. Next, we augment\nthis list by including top medical journals and hospitals, and by identifying additional\nUS government agencies that had o\u000ecial COVID-19 related recommendations (for\nexample, while not a public health organization, the EPA released information about\ndisinfectants that were e\u000bective). After the White House announcement regarding the\nAmericas Health Insurance Plans collaboration with the White House Coronavirus\nTask Force, the AHIP Statement page clarifying the free testing plan was also included\non this list.\nLow-quality Misinformation Sources (LQMS) : Misinformation is prevalent online.\nWhile the 2016 election brought attention to this issue, it is nothing new{especially\nin the health domain. For instance, a 2010 study by [30] examined 1000 randomly\nselected tweets mentioning antibiotics and found that 700 of them contained medical\nmisinformation or malpractice. We identify the set of low-quality/questionable sources\nof information using a list curated by NewsGuard [31]. NewsGuard is a journalistic\norganization that generally rates websites on their tendency to spread true or false\ninformation. Since the COVID-19 outbreak, they have kept a separate list of websites\nidenti\fed as propagating misinformation speci\fcally related to the virus.\n6.2.2. Findings\nTable 5 shows the number of tweets containing HQHS URL links and LQMS URL\nlinks. A small fraction of the urls shared come from one of the three categories listed\nabove. The tweets containing a link to a Reputable Health Sources account for 0.51%\nof tweets and 0.04% of retweets. Low-quality/Questionable Sources account for 0.4%\nof original tweets and 0.06% of retweets. We see that both HQHS and LQMS sites\nare shared very infrequently, with LQMS being tweeted at a lower rate than HQHS.\nLQMS are being retweeted at a rate higher than HQHS. This is concerning, but still\na small fraction of the overall conversation volume.\nTable 5.: Count of Tweets, Retweets, and Quote Tweets by Types of URLs.\nData set Tweet CountTweets\nwith URLsHQHS\nURL CountLQMS\nURL CountBoth Count\nOriginal Tweets 2,792,513 1,131,112 14,485 11,654 8\nQuotes 456,878 16,200 594 175 0\nRetweets 18,168,161 926,103 8,813 11,415 0\nCombined 21,417,552 2,073,415 23,892 23,244 8\n6.3. News media information sharing\nGiven the infrequency of links to HQHS sites and LQMS sites, we turn our attention\nto news sources. News media plays an important role in informing the public. This\n18\nrole is heightened in crisis events such as pandemics. These organizations employ fact\ncheckers, engage with experts with relevant expertise, and are therefore sources for\ntrustworthy information. As such, we expect them to play a signi\fcant role in the\ninformation produced and shared on social media platforms.\n6.3.1. Methodology\nTo identify reputable news sources, we adopt the de\fnition and list of traditional news\nsites shared by MediaBias/FactCheck an independent online media outlet maintained\nby a small team of researchers and journalists [32]. This list has over one thousand\nthree hundred web domains listed as reliable news sources.\nFor our twitter data set, we download all of the urls that are shared between January\n16, 2020 to March 15, 2020. We then download the news articles and scrape the web\ncontent to determine the sources the news articles are referencing by inspecting the\nlinks they include (e.g. a link to the CDC site in a particular New York Times article).\nWe then aggregate this information to determine the fraction of HQHS sites and LQMS\nsites referenced by the news media.\n6.3.2. Findings\nJust over 351,000 of the tweets contain links to news organizations. This represents\n13% of the original tweets in our sample.6When checking the news articles for links\nto high and low quality sources, we \fnd that over 63,000 of the tweets have links to\nhigh quality sources and over 1,000 have links to low quality sources (see Figure 13).\nThis indicates that 18% of the news shares are connected to HQHS sites and less than\n0.3% link to LQMS.\nFocusing on more frequently shared news sources (news domains), we \fnd that\n228 new-domains were mentioned in at least 100 tweets. Of those, there are 178 news\ndomains with at least one article that links to at least one HQHS site or LQMS site. We\ninspect this subset and see that 175 out of 178 are referring to HQHS site at least 80%\nof the time. There are only three sites that are below that 80% rate (newyorker.com\nwith a 0.17 high quality to high + low quality link ratio, liveleak.com with a 0.33 ratio,\nand thepostmillennial.com with a 0.5 ratio).\nFor the long tail of less popular domains, the results are somewhat comparable.\nThere are 352 domains with at least one article containing at least one link to a\nHQHS site or LQMS site. Out of those, only 16 have a high quality to high quality\n+ low quality ratio lower than 0.8. Overall, these numbers are encouraging. However,\nit is important to note that this analysis applies only to articles that link to other\nsources in our data set.\n7. Discussion and conclusions\nOur results provide important implications for understanding disease spread, informa-\ntion seeking behaviors during public health crises, and general communication patterns\nin this unprecedented combination of global pandemic and modern information envi-\nronment.\nFirst, our results show that the COVID-19 cases are highly correlated with Twitter\nconversations; and further, Twitter conversations led the COVID-19 cases by 2-5 days.\n6We were unable to download approximately 4% of the HTML content for the news links.\n19\nFigure 13.: Distribution of Links from News Articles\nThis is an important \fnding, suggesting that we can use Twitter conversations to help\npredict the spread and outbreak of COVID-19 when other reliable leading indicators\nare not available. While measurement error is of concern given this non-representative\npopulation, developing reliable ways to measure and re-weight for di\u000berent biases\npresent in these organic data sets is an important future direction.\nSecond, we have learned a great deal about how much, where, and how people are\ncommunicating about this pandemic. Attention to COVID-19 continues to grow on\nTwitter, and likely on other platforms as well. As we know from research, people tend\nto care about news that a\u000bects them personally [33], so it makes sense that relevant\nconversation would grow as the pandemic continues to a\u000bect more and more people on\na personal level. Likewise, attention is focused in the countries that have been hardest\nhit by the disease, again suggesting that attention, discussion, and information sharing\nare greatest for those who are most impacted.\nBut not all of this information is reliable - although people are sharing many URLs\n(with 40.5% of original tweets including a URL), they are sharing less from very cred-\nible health sources like the CDC and WHO than might be expected (only 14,485\noriginal tweets (0.4%) did so). However, sources that we can con\fdently label as pro-\nducers of misinformation (through domains identi\fed as purveyors of misinformation\nby a journalism organization) are also not shared in great numbers (11,654 original\ntweets linked to such a source), even though they are retweeted more often (11,415)\nthan credible health sources (8,813). Of course there may be - and likely are - pieces of\nmisinformation being shared without links, or with links outside of the list of con\frmed\ndubious URLs we used. This preliminary analysis, though, suggests that credible in-\nformation is roughly keeping pace with misinformation.\nThis \fnding is ampli\fed if we consider links to news sources as well. Linking to\nnews sources was much more common than sharing either high quality health sources\nor known low credibility sites, with over 350,000 tweets doing so. Consistent with our\nexpectations, these news links are much more likely to themselves link to credible\nsources like the WHO (63,352 news articles) than to misinformation sources (about\n1,135 news articles), meaning people are likely getting reliable information from these\ntweets. Future work will consider all the shared content through URLs to determine\nthe distribution of high and low quality links across all of the URL content.\nOur analysis of common myths about COVID-19 reveals a similar pattern. We\nstarted from a set of 10 di\u000berent themes of myths and were able to identify \fve with\nhigh precision. Analysis of the tweets that pertain to these myths show that they\naccount for a small fraction of Twitter content. While this \fnding is encouraging,\nthere are many more myths that needs to be analyzed to understand the total impact\nof myths on the COVID-19 conversation. In general, it is crucial to continually monitor\n20\nmyths in the conversation, di\u000berentiate those who are propagating the myth and those\nwho are debunking it, and build systems to combat them.\nWe pause to mention that many of the text analysis methods used were simple\nmethods. Because of the volume of data and in the interest of time, we chose to\nuse these simpler techniques in this \frst analysis. In future work, we will compare\nthese simple approaches to more robust analysis techniques to improve our overall\nunderstanding of these data.\nWhile we have mentioned future directions throughout the article, we highlight the\nones we are already making progress on. One direction of future work will focus on\nconducting a more re\fned spatio-temporal analysis of the \row of information and the\ntransmission of COVID-19. We also intend to use language models in conjunction with\nmachine learning models to identify myths and themes with high levels of recall and\nprecision. Finally, as the crisis continues to unfold, we will work to share results and\naggregate data sets through a web portal for those interested in advancing research\nrelated to COVID-19 and social media conversation.\nReferences\n[1] World Health Organization. Coronavirus disease 2019 (covid-19) situation re-\nport ; 2020. Available from: www.who.int/docs/default-source/coronaviruse/\nsituation-reports/20200315-sitrep-55-covid-19.pdf?sfvrsn=33daa5cb_ .\n[2] Ortiz-Ospina E. The rise of social media ; 2020. Available from: https://\nourworldindata.org/rise-of-social-media .\n[3] Matsa KE, Shearer E. News use across social media platforms 2018. Pew\nResearch Center. 2018;Available from: www.journalism.org/2018/09/10/\nnews-use-across-social-media-platforms-2018 .\n[4] Hitlin P, Olmstead K. The science people see on social media. Pew Re-\nsearch Center. 12/30/2019;Available from: www.pewresearch.org/science/2018/03/\n21/the-science-people-see-on-social-media .\n[5] Wilford J, Osann K, Wenzel L. Social media use among parents of young childhood cancer\nsurvivors. Journal of Oncology Navigation & Survivorship. 2018;9(1).\n[6] Vraga EK, Bode L. De\fning misinformation and understanding its bounded nature: Using\nexpertise and evidence for describing misinformation. Political Communication. 2020;\n37(1):136{144.\n[7] Garrett RK, Weeks BE, Neo RL. Driving a wedge between evidence and beliefs: How\nonline ideological news exposure promotes political misperceptions. Journal of Computer-\nMediated Communication. 2016;21(5):331{348.\n[8] Nyhan B, Rei\rer J. When corrections fail: The persistence of political misperceptions.\nPolitical Behavior. 2010;32(2):303{330.\n[9] Tan ASL, Lee Cj, Chae J. Exposure to health (mis)information: Lagged e\u000bects on\nyoung adults' health behaviors and potential pathways. Journal of Communication. 2015;\n65(4):674{698.\n[10] Southwell BG, Niederdeppe J, Cappella JN, et al. Misinformation as a misunderstood\nchallenge to public health. American journal of preventive medicine. 2019;57(2):282{285.\n[11] Briones R, Nan X, Madden K, et al. When vaccines go viral: an analysis of hpv vaccine\ncoverage on youtube. Health communication. 2012;27(5):478{485.\n[12] Broniatowski DA, Jamison AM, Qi S, et al. Weaponized health communication: Twitter\nbots and russian trolls amplify the vaccine debate. American Journal of Public Health.\n2018;108(10):1378{1384.\n[13] Dredze M, Broniatowski DA, Hilyard KM. Zika vaccine misconceptions: A social media\nanalysis. Vaccine. 2016;34(30):3441{3442.\n21\n[14] Guidry JPD, Carlyle K, Messner M, et al. On pins and needles: how vaccines are portrayed\non pinterest. Vaccine. 2015;33(39):5051{5056.\n[15] Oyeyemi SO, Gabarron E, Wynn R. Ebola, twitter, and misinformation: a dangerous\ncombination? BMJ (Clinical research ed). 2014;349:g6178.\n[16] Sharma M, Yadav K, Yadav N, et al. Zika virus pandemic-analysis of facebook as a\nsocial media health information platform. American journal of infection control. 2017;\n45(3):301{302.\n[17] Twitter. Twitter reports \frst quarter 2014 results ; April 29, 2014. Available from:\nhttps://s22.q4cdn.com/826641620/files/doc_financials/2014/q1/2014_Q1_\nEarnings_Release.pdf .\n[18] Twitter. Twitter reports \frst quarter 2019 results ; April 23, 2019. Avail-\nable from: fromhttps://s22.q4cdn.com/826641620/files/doc_financials/2019/q1/\nQ1-2019-Earnings-Release.pdf .\n[19] Swift A. Americans' trust in mass media sinks to new low.\nGallup. 2016;Available from: https://news.gallup.com/poll/195542/\namericans-trust-mass-media-sinks-new-low.aspx .\n[20] January 24 coronavirus news ; 01/24/2020. Available from: www.cnn.com/asia/\nlive-news/coronavirus-outbreak-hnk-intl-01-24-20/index.htm .\n[21] Hundreds more americans evacuated from china as coronavirus death toll\nrises ; 02/06/2020. Available from: https://www.cbsnews.com/live-updates/\ncoronavirus-usa-confirmed-cases-news-death-toll-latest-2020-02-04/ .\n[22] Holland S, Harte J. Gatherings banned, travel restricted\nas coronavirus cases grow worldwide. Reuters. 02/29/2020;\nAvailable from: www.reuters.com/article/us-china-health/\ngatherings-banned-travel-restricted-as-coronavirus-cases-grow-worldwide-idUSKBN20O14 .\n[23] Orcutt M. The many tongues of twitter ; 2013. Available from: www.technologyreview.\ncom/s/522376/the-many-tongues-of-twitter .\n[24] Statcounter GlobalStats. Social media stats germany [dataset] ; 2020. Available from:\nhttps://gs.statcounter.com/social-media-stats/all/germany .\n[25] Wongcha-um P, Thepgumpanat P. Thailand records \frst coro-\nnavirus death: health o\u000ecial. Reuters. 2020;Available from:\nhttps://www.reuters.com/article/us-china-health-thailand/\nthailand-records-first-coronavirus-death-health-official-idUSKBN20O1BC .\n[26] Singh L, Wahedi L, Wang Y, et al. Blending noisy social media signals with traditional\nmovement variables to predict forced migration. In: ACM International Conference on\nKnowledge Discovery & Data Mining. ACM; 2019. p. 1975{1983.\n[27] Statoids. Administrative divisions of countries ; 2016. Available from: http://www.\nstatoids.com .\n[28] Gunia A, Zennie M. China reported a huge increase in new covid-19 cases. here's why\nit's actually a step in the right direction. TIME. 02/13/2020;Available from: https:\n//time.com/5783401/covid19-hubei-cases-classification/ .\n[29] Lin WY, Zhang X, Song H, et al. Health information seeking in the web 2.0 age: Trust in\nsocial media, uncertainty reduction, and self-disclosure. Computers in Human Behavior.\n2016;56:289{294.\n[30] Scanfeld D, Scanfeld V, Larson EL. Dissemination of health information through social\nnetworks: twitter and antibiotics. American journal of infection control. 2010;38(3):182{\n188.\n[31] Newsguard. Coronavirus misinformation tracking center ; 2020. Available from: www.\nnewsguardtech.com/coronavirus-misinformation-tracking-center .\n[32] Media Bias/Fact Check. Media bias/fact check: The most comprehensive media bias re-\ncourse. ; 2018. Available from: https://mediabiasfactcheck.com/ .\n[33] Edgerly S. Young adults and the attitudes that resulted in news avoidance during the\n2016 election. In: International Communication Association; 2018.\n22\nAcknowledgements\nThis research was primarily supported by the Massive Data Institute at Georgetown\nUniversity. It was also supported by the Computational and Spatial Analysis Core\nat Pennsylvania State University, the National Science Foundation (Awards SES-\n1823633, SES-1934925, SES-1934494, CNS-1453392), the Eunice Kennedy Shriver Na-\ntional Institute of Child Health and Human Development (Awards P2C HD041025),\nthe USDA National Institute of Food and Agriculture and Multistate Research Project\n#PEN04623 (Accession #1013257).\nWe would also like to acknowledge the support of others on our team:\n- Junjun Yin at Penn State extracted geotagged tweets.\n- Yiqing Ren at Georgetown computed volumes.\n- Virinche Marwadi at Georgetown for adjusting infrastructure.\n- Robert Churchill helped with myth identi\fcation.\n23\n8. Appendix A\nTable 6.: Hashtags and Start Date of Collection.\nHashtagDate of First\nCollection\n#2019nCoV 1/16/2020\n#ChinaPneumonia 1/16/2020\n#ChinesePneumonia 1/16/2020\n#Corona 1/16/2020\n#SARI 1/16/2020\n#WuhanCoronavirus 1/16/2020\n#WuhanPneumonia 1/16/2020\n#CoronavirusOutbreak 1/20/2020\n#VirusChina 1/21/2020\n#Coronavirus* 1/23/2020\n#Wuhan 1/23/2020\n#CoronaOutbreak 3/02/2020\n#COVID 3/02/2020\n#CoronavirusUpdate 3/11/2020\n#COVID 19 3/11/2020\n#COVID19** 3/11/2020\n24", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A first look at COVID-19 information and misinformation sharing on Twitter", "author": ["L Singh", "S Bansal", "L Bode", "C Budak", "G Chi"], "pub_year": "2020", "venue": "arXiv preprint arXiv \u2026", "abstract": "Since December 2019, COVID-19 has been spreading rapidly across the world. Not  surprisingly, conversation about COVID-19 is also increasing. This article is a first look at the"}, "filled": false, "gsrank": 410, "pub_url": "https://arxiv.org/abs/2003.13907", "author_id": ["", "", "e0i3HvIAAAAJ", "wIhJS60AAAAJ", "5HRNTzAAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:rX-luSDkp0UJ:scholar.google.com/&output=cite&scirp=409&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D400%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=rX-luSDkp0UJ&ei=TrWsaOmxLKzWieoPic2ZoAU&json=", "num_citations": 386, "citedby_url": "/scholar?cites=5019231138932424621&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:rX-luSDkp0UJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2003.13907"}}, {"title": "Frappe: Framing, persuasion, and propaganda explorer", "year": "2024", "pdf_data": "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics\nSystem Demonstrations , pages 207\u2013213\nMarch 17-22, 2024 c\r2024 Association for Computational Linguistics\nFRAPPE: FRAming, Persuasion, and Propaganda Explorer\nAhmed Sajwani1,5\u2217\n, Alaa El Setohy10,5\u2217\n, Ali Mekky2,5\u2217\n, Diana Turmakhan3,5\u2217\n,\nLara Hassan2,5\u2217\n, Mohamed El Zeftawy2,5\u2217\n, Omar El Herraoui4,5\u2217\n,\nOsama Mohammed Afzal5, Qisheng Liao5, Tarek Mahmoud5,8,\nZain Muhammad Mujahid5, Muhammad Umar Salman5, Muhammad Arslan Manzoor5,\nMassa Baali5, Jakub Piskorski6, Nicolas Stefanovitch9, Giovanni Da San Martino7, Preslav Nakov5\n1Khalifa University of Science and Technology,2Alexandria University,3Nazarbayev University,4NYU Abu Dhabi,\n5MBZUAI,6Polish Academy of Sciences,7University of Padova,8Presight\n9European Commission Joint Research Centre,10Egypt Japan University of Science and Technology\nAbstract\nThe abundance of news sources and the urgent\ndemand for reliable information have led to se-\nrious concerns about the threat of misleading in-\nformation. In this paper, we present FRAPPE, a\nFraming, Persuasion, and Propaganda Explorer\nsystem. FRAPPE goes beyond conventional\nnews analysis of articles and unveils the intri-\ncate linguistic techniques used to shape read-\ners\u2019 opinions and emotions. Our system allows\nusers not only to analyze individual articles\nfor their genre, framings, and use of persua-\nsion techniques, but also to draw comparisons\nbetween the strategies of persuasion and fram-\ning adopted by a diverse pool of news outlets\nand countries across multiple languages for dif-\nferent topics, thus providing a comprehensive\nunderstanding of how information is presented\nand manipulated. FRAPPE1is publicly acces-\nsible at https://frappe.streamlit.\napp/ and a video explaining our system\nis available at https://www.youtube.\ncom/watch?v=3RlTfSVnZmk\n1 Introduction\nAs the digital age ushers in an era of unparalleled\nconnectivity and information dissemination, the\ntransition towards online news media has brought\nseveral changes in the way the news is produced,\nconsumed, and distributed. Although online news\noffers advantages such as increased accessibility\nand reduced cost of publishing, it has also brought\nseveral challenges such as the potential reinforce-\nment of biases and propaganda. Consequently, ana-\nlyzing news articles and offering an in-depth under-\nstanding beyond surface-level text has become piv-\notal for addressing these challenges. To get a global\npicture, there is also a need to analyze and to com-\npare entire news media as well as the news land-\nscape in different countries around a given topic.\n*Equal contribution.\n1This work was done during a summer internship at the\nNLP department, MBZUAI.A number of manual fact-checking initiatives\nhave been launched. For example, Media Bias/Fact\nCheck2and NewsGuard3offer assessments of the\nbiases and the factuality of reporting of entire news\noutlets. There have also been a number of initia-\ntives for fact-checking individual claims such as\nFactCheck,4PolitiFact,5and Snopes,6among many\nothers. However, they all require tedious manual\nwork by human fact-checkers, which does not scale\nand cannot cope with the volume of disinformation\nonline. Thus, automation has been proposed as a\npossible alternative. Recently, it has been further\nrealized that it is important to focus not only on\nfactuality, but also on the way the message is con-\nveyed, e.g., using subjectivity/humor, framing, and\npersuasion techniques.\nAs a parallel research line, a variety of research\nsystems have been developed for the purpose of\nnews analysis across several dimensions. For ex-\nample, the Prta system (Da San Martino et al.,\n2020) allows users to explore the use of 18 pro-\npaganda techniques in news articles. Another tool,\nNewsLens (Laban and Hearst, 2017), focuses on\nconstructing cohesive narrative threads that span\nseveral years and articles from approximately 20\nnews sources. Yet another system, Tanbih (Zhang\net al., 2019), offers a profiling mechanism that cov-\ners a substantial yet confined collection of a few\nthousand media sources, which it profiles for fac-\ntuality and bias of reporting. We can also mention\nNewsScan (Kevin et al., 2018), which is a plugin to\nprofile news articles on the basis of specific labels\nproviding information about the lexical properties\n(ease of reading), as well as some intrinsic proper-\nties (sentiment score, political bias), referred to as\nnutrition labels .\n2https://mediabiasfactcheck.com/\n3https://www.newsguardtech.com/\n4https://www.factcheck.org/\n5https://www.politifact.com/\n6https://www.snopes.com/207\nHowever, there is a lack of publicly accessible\ntools with the capability not only to analyze arti-\ncles, but also to systematically explore and to draw\ncomparisons between the strategies of persuasion\nand framing adopted by a diverse pool of news\noutlets and countries across many languages for a\nspecific topic. With the aim to bridge this gap, we\ndeveloped FRAPPE (FRAming, Persuasion, and\nPropaganda Explorer), an online news analysis plat-\nform that operates in a multilingual setup and pro-\nvides two main functionalities: on-the-fly analysis\nfor individual articles, and a user-friendly, interac-\ntive, and insightful Web interface for analyzing a\ndatabase of 2M+ articles from 8k+ different media\nsources around the globe, in a variety of languages,\ncovering two main topics: ( i) the Russia\u2013Ukraine\nconflict and ( ii) climate change. This enables users\nto gather insights about framing, persuasion, and\npropaganda at an aggregate level, by news outlet\nand by country, and also to compare different news\noutlets and different countries.\n2 Data and Models\n2.1 Data\nOur models were trained on a multilingual multi-\nfaceted dataset of news articles from SemEval-\n2023 task 3 on \u201cDetecting the Genre, the Framing,\nand the Persuasion Techniques in Online News in a\nMulti-Lingual Setup\u201d (Piskorski et al., 2023b). The\ndataset consists of 1,612 articles covering news on\ncurrent topics of public interest in six European\nlanguages (English, French, German, Italian, Pol-\nish, and Russian), with more than 37k annotated\nspans. Each news article was annotated for genre,\nframings, and persuasion techniques.\n2.2 Model\nOur system has trained on models for the three\nsubtasks of SemEval-2023 task 3, which we briefly\ndescribe below.\n2.2.1 Genre\nFor genre classification, our objective is to define\nthe intended nature of an article, distinguishing\nbetween opinion pieces, objective news reporting,\nand satire. This categorization follows a multi-class\nannotation scheme applied at the article level.\nWe used an advanced transformer-based pre-\ntrained multilingual language model, XLM-\nRoBERTa (Conneau et al., 2020), and in particular\nits base-sized model, which has 279M parameters.\nFigure 1: The architecture of our system for fram-\ning and propaganda. Each input generates two views\nof representations using dropout. The representations\ngenerated by the same text are positive pairs. The con-\ntrastive loss and the binary cross entropy loss are cal-\nculated separately by two heads and the classification\nresult is calculated after applying a threshold.\nThis model has excellent transfer learning capa-\nbilities. To tailor it specifically to our genre classi-\nfication task, we fine-tuned the model\u2019s last layer\nby adding a fully connected linear layer with three\nunits (representing the three classes) and applying\na softmax activation function.\nThe training dataset exhibits class imbalance,\nwherein the presence of satire articles is signifi-\ncantly limited in comparison to the abundance of\nopinion ones. Consequently, this introduced bias\nin the model\u2019s performance. To mitigate this issue,\nwe used a focal loss function (Mukhoti et al., 2020),\na specialized variant of the standard cross-entropy\nloss, which assigns higher weights to misclassi-\nfied minority class examples, thereby emphasizing\ntheir significance during training and improving\nthe model\u2019s ability to handle class imbalance.\nTable 1 shows the performance of our model on\nthe test sets for the six languages, with compari-\nson against the baselines and the best systems at\nSemEval-2023 task 3 subtask A.\nLanguage Baseline Our Sys Best Sys\nEnglish 0.288 0.533 0.784\nFrench 0.568 0.686 0.835\nGerman 0.630 0.726 0.819\nItalian 0.389 0.621 0.768\nPolish 0.490 0.682 0.785\nRussian 0.398 0.641 0.755\nTable 1: Genre analysis: Performance (macro-F1\nscore) of our system compared to the baselines and\nto the best systems for the six languages on the test data\nof SemEval-2023 task 3 subtask A.208\nLanguage Baseline Our Sys Best Sys\nEnglish 0.349 0.562 0.578\nFrench 0.328 0.552 0.552\nGerman 0.487 0.711 0.711\nItalian 0.485 0.617 0.617\nPolish 0.593 0.673 0.673\nRussian 0.229 0.449 0.449\nTable 2: Framing analysis: Performance (macro-F1\nscore) of our system compared to the baselines and to\nthe best systems for the six languages on the test data of\nSemEval-2023 task 3 subtask B.\n2.2.2 Framing\nFor news framing, we trained our models on the\ndata from SemEval-2023 task 3 subtask B (Pisko-\nrski et al., 2023a). This is a challenging task and\nit is more nuanced than mere topic classification\n(Card et al., 2015), e.g., while the topic of a news\narticle may be COVID-19, the framing could be\nfrom an economic, political, or/and health perspec-\ntive(s). The task can be formulated as a multilabel\ntext classification problem with fourteen possible\nlabels: Economic; Capacity and Resources; Moral-\nity; Fairness and Equality; Legality, Constitution-\nality, and Jurisprudence; Policy Prescription and\nEvaluation; Crime and Punishment; Security and\nDefense; Health and Safety; Quality of Life; Cul-\ntural Identity; Public Opinion; Political; External\nRegulation and Reputation . The performance of\nour model on the test data is shown in Table 2.\nOur model\u2019s architecture (Liao et al., 2023) is\nillustrated in Figure 1, featuring two heads: one for\ncontrastive loss and another one for binary entropy\nloss. During training, the focus is on optimizing\nthe contrastive loss, which is achieved by creating\ntwo positive examples from each training example\nusing dropout. Despite the dropout module altering\nthe embeddings of the same training sample, they\nare still considered positive examples, and their\ndistances are brought closer together. In the con-\ntext of being a multi-label classification model, any\nother examples within the same batch are deemed\npositive only if they have exactly the same target\nclasses. Otherwise, they are treated as negative\nexamples, and the distance between them is pushed\napart. Moreover, the loss of the negative examples\nis weighted, with higher weights assigned to ex-\namples containing more diverse classes. Finally,\nwe transform the multi-label classification task into\n14 binary classification ones: one for each frame\nlabel.Language Baseline Our Sys Best Sys\nEnglish 0.195 0.329 0.375\nFrench 0.240 0.436 0.468\nGerman 0.316 0.529 0.529\nItalian 0.397 0.548 0.550\nPolish 0.179 0.406 0.430\nRussian 0.207 0.395 0.395\nTable 3: Propaganda analysis: Performance (macro-F1\nscore) for our system compared to the baselines and the\nbest systems for the six languages on the test data of\nSemEval-2023 task 3 subtask C.\nAs a result, for each input, there are multiple log-\nits corresponding to each target class. The classifi-\ncation decision is made by predicting that a given\nexample belongs to a target class if the value of the\ncorresponding logit exceeds a specific threshold.\n2.2.3 Propaganda\nIn our propaganda model training, we used data\nfrom SemEval-2023 task 3 subtask C and the same\nmodel as before. The setup is comparable to the\nsecond subtask, with the distinction that the pre-\ndictions are made for each sentence of the arti-\ncle, rather than for the entire article as a whole.\nThus, the model generates predictions at the sen-\ntence level. After obtaining predictions for each\nindividual sentence of the article, we combined\nthese predictions to form the final multi-label pre-\ndiction. This allows us to make comprehensive\npredictions that take into account the information\nfrom each sentence within the article, leading to\na more nuanced and context-aware classification\nof propaganda elements in the text. There are 23\npersuasion techniques in total: appeal to authority;\nappeal to popularity; appeal to values; appeal to\nfear/prejudices; flag waving; causal oversimplifi-\ncation; false dilemma or no choice; consequen-\ntial oversimplification; straw man; red herring;\nwhataboutism; slogans; appeal to time; conversa-\ntion killer; loaded language; repetition; exagger-\nation or minimisation\u2019 obfuscation - vagueness or\nconfusion; name calling or labeling; doubt; guilt\nby association; appeal to hypocrisy; and ques-\ntioning the reputation . These 23 techniques are\ngrouped into 6 coarse-grained categories: Attack\non Reputation, Justification, Simplification, Dis-\ntraction, Calls, Manipulative Wording . The perfor-\nmance of our model on the test data is shown in\nTable 3.209\n3 System Architecture\nFRAPPE is a comprehensive system with two sub-\nsystems. The first one enables users to analyze\ndifferences in framings and propaganda techniques\nacross countries and media sources. The second\none allows users to explore the genre, the framings,\nand the propaganda techniques used in an individ-\nual custom article, which can be analyzed on the fly.\nWe implemented both subsystems using Streamlit,\na free and open-source framework for building and\nsharing machine learning and data science Web\napplications.\nNews Media Explorer We applied our custom-\ndeveloped models, focusing on framing and persua-\nsion techniques, to a dataset of 2,281,254 articles\nabout the Russia-Ukraine conflict, sourced from\n8,318 media outlets across 196 countries. These ar-\nticles were processed and indexed on our platform,\nutilizing the models converted to ONNX format\nand deployed on NVIDIA Triton for enhanced in-\nference speed, powered by two NVIDIA RTX 4090\nGPUs. The aggregated results can be explored us-\ning the demo, enabling users to conduct customized\nanalysis based on their preferences.\nCustom Article Analyzer Inference is done us-\ning the models uploaded on the server, and the user\nis prompted to enter either a news article\u2019s URL or\nthe text of an article. In the former case, we use\nTrafilatura, a Python package and command-line\ntool, to gather and to extract the article text from\nthe URL (Barbaresi, 2021). After the predictions\nare done, the genre of the article is displayed, as\nwell as the distribution of the framings and the\npropaganda techniques it uses.\n4 Interface\nOur system interface is designed with user friend-\nliness and accessibility in mind, and it offers an\nimmersive journey into the analysis of the two col-\nlections of articles we currently have loaded. The\ninterface is divided into two engaging subsections.\nThe News Media Explorer allows the user to ex-\nplore the analysis of a collection of articles conve-\nniently aggregated both by their source and country\nof origin, while the Custom Article Analysis offers\nreal-time processing capability for an individual\narticle.4.1 The News Media Explorer\nSetting sail on this analytical journey, users are wel-\ncomed by five interactive pages. Each page offers\na unique perspective visualizing the following:\n1.Framings and persuasion techniques for coun-\ntries;\n2. Framings for countries and sources;\n3.Persuasion techniques for countries and\nsources;\n4.Coarse-grained persuasion techniques for\ncountries and sources;\n5.Rhetorical propaganda techniques (ethos,\npathos, logos) for countries and sources.\nThe user can choose a country from a list of 186\ncountries, which are shown sorted by total num-\nber of articles. From here, she is guided through\na series of visualizations, each revealing detailed\ninsights into the distribution of framings and per-\nsuasion techniques across countries and sources.\nFigures 2 and 3 are the first landmarks on this\njourney, visualizing the distribution of framings by\ncountry and by source, respectively. The y-axis\nlists the countries/sources in descending order of\narticles, while the x-axis gives the percentage of\neach framing in each country/source. The legend, a\ncolorful tapestry of framings, aids in understanding\nthe chart.\nFigure 2: Visualization of framings by country.\nFigure 3: Visualization of framings by source.210\nThe percentage of framings in each coun-\ntry/source ( F) is calculated using the following\nformula:\nF=fs,c\nfT,c\u00d7100 (1)\nwhere fs,cis the frequency of a specific framing\nwithin all the articles in a given country/source,\nandfT,cis the total number of articles for that\ncountry/source.\nNext, Figures 4 and 5 unfold the story of persua-\nsion techniques by country and source, respectively.\nNote that we detect the persuasion techniques at\nthe sentence level, considering multiple instances\nwithin a single article. Thus, the percentage of\neach persuasion technique ( P) in each country is\ncalculated as follows:\nP=Ft,c\nFT,c\u00d7100 (2)\nwhere Ft,cis the frequency of a specific persuasion\ntechnique in all articles for a given country/news\nsource, and FT,cis the total frequency of all per-\nsuasion techniques in all articles from that coun-\ntry/source in our collection.\nFigure 4: Visualization of persuasion techniques by\ncountry.\nFigure 5: Visualization of persuasion techniques by\nnews medium.As the journey progresses, a graph displaying\nthe number of articles over time for each coun-\ntry/source emerges, as shown in Figure 6, shedding\nlight on the evolution of media trends.\nThe final stop within this subsection is an in-\nteractive pie chart that presents a global view of\nall framings in all the selected countries and their\nrespective continents, as shown in Figure 7. This\ninteractive feature invites users to click on parts\nof the pie chart to collapse or to expand sections,\noffering an exploratory experience.\nFigure 6: Visualization of the number of articles over\ntime by country and by media source.\nFigure 7: Pie chart of framings by country and conti-\nnent.\nThe user can choose to explore the persuasion\ntechniques at two coursers level (as opposed to\nthe original 23 fine-grained techniques) by media\nand by country. Figure 8 shows the distribution of\ncoarse-grained persuasion techniques across coun-\ntries, allowing for a higher-level understanding of\nthe prominent persuasion styles used. Figure 9\npresents the use of rhetorical techniques such as\nethos, pathos, and logos by country, highlighting\nthe variations in strategy and deepening our com-\nprehension of the media persuasion dynamics.211\nFigure 8: Visualization of coarse-grained persuasion\ntechniques by country.\nFigure 9: Visualization of rhetorical persuasion tech-\nniques by country.\n4.2 Custom Article Analysis\nThe second part of the system, Custom Article\nAnalysis, allows users to delve into a single ar-\nticle of their choice. Users can input their custom\narticle either by entering its URL or by pasting\nits text into a text box. Upon submission, the sys-\ntem presents three enlightening visualizations, as\nshown in Figures 10, 11, and 12:\nFigure 10: Classification of a custom article as reporting,\nopinion, or satire.\n1.A pie chart unveiling the article\u2019s classifica-\ntion as satire, reporting, or opinion. This of-\nfers clarity about the article\u2019s genre, as shown\nin Figure 10.\nFigure 11: Framings graph for a custom article.\n2.A bar chart revealing the framings in the ar-\nticle, offering a deeper understanding of the\narticle\u2019s perspectives, as shown in Figure 11.\nFigure 12: Persuasion techniques for a custom article.\n3.A visualization of the persuasion techniques\nin the article, offering granular insight into the\narticle\u2019s rhetoric. This tool is a valuable asset\nfor anyone studying or practicing journalism,\nas shown in Figure 12.\n5 Conclusion and Future Work\nWe presented FRAPPE, a system for analysis of\nthe news in terms of framing, persuasion, and pro-\npaganda techniques, which can be used to tackle\nthe challenge of misleading information in news\narticles and news outlets. It provides a deep under-\nstanding of news articles, allowing users to gain\ninsights into genre, framing, and propaganda tech-\nniques, and to perform comparison of media and\ncountries.\nIn future work, we aim to gather more data, to\nextend the analysis to other globally discussed top-\nics, and to update our visualizations with more\nin-depth analysis that goes down to the individual\narticle level. We further plan to create a database\nthat will automatically save every article that was\nanalyzed on the fly (in a separate collection). Fi-\nnally, we aim to improve our models\u2019 accuracy, and\nto add additional models and analysis.212\n6 Limitations\nWe acknowledge certain limitations that we plan\nto address in future work. First, we need to ex-\npand the training data to cover more languages as\npart of training, in order to improve our models\u2019\naccuracy when analyzing articles written in these\nlanguages (even though, thanks to the multilingual\nXLM-RoBERTa, we already cover 100 languages).\nSecond, our system does not cover all aspects of\nanalysis that an article can undergo; it currently\nonly unveils genre, framings, and persuasion tech-\nniques. Finally, our database is currently limited to\nour 2M+ articles, and does not automatically reflect\nfuture events. We plan continuous data addition\ncovering more topics and languages.\n7 Ethics and Broader Impact\nOne of the foremost ethical considerations is ensur-\ning the transparency and the unbiased analysis in\nFRAPPE. Users should be aware that our models\nuse neural networks, and as such, they lack explain-\nability. Another warning is that, despite our intent,\ndue to article selection biases, FRAPPE might be\nfavoring some political or social standpoints.\nFinally, FRAPPE has the potential to influence\nthe way news articles are perceived and consumed,\nand journalists may become more aware of the lan-\nguage they use and its potential impact on readers.\nReferences\nAdrien Barbaresi. 2021. Trafilatura: A web scraping\nlibrary and command-line tool for text discovery and\nextraction. In Proceedings of the Joint Conference\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing:\nSystem Demonstrations , ACL-IJCNLP \u201921, pages\n122\u2013131.\nDallas Card, Amber E. Boydstun, Justin H. Gross, Philip\nResnik, and Noah A. Smith. 2015. The media frames\ncorpus: Annotations of frames across issues. In Pro-\nceedings of the 53rd Annual Meeting of the Asso-\nciation for Computational Linguistics and the 7th\nInternational Joint Conference on Natural Language\nProcessing , NAACL-HLT\u201915, pages 438\u2013444, Bei-\njing, China.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Associa-tion for Computational Linguistics , ACL \u201920, pages\n8440\u20138451.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang,\nSeunghak Yu, Alberto Barr\u00f3n-Cede\u00f1o, and Preslav\nNakov. 2020. Prta: A system to support the analysis\nof propaganda techniques in the news. In Proceed-\nings of the 58th Annual Meeting of the Association for\nComputational Linguistics: System Demonstrations ,\nACL \u201920, pages 287\u2013293.\nVincentius Kevin, Birte H\u00f6gden, Claudia Schwenger,\nAli \u00b8 Sahan, Neelu Madan, Piush Aggarwal, Anusha\nBangaru, Farid Muradov, and Ahmet Aker. 2018. In-\nformation nutrition labels: A plugin for online news\nevaluation. In Proceedings of the First Workshop on\nFact Extraction and VERification , FEVER \u201918, pages\n28\u201333, Brussels, Belgium.\nPhilippe Laban and Marti Hearst. 2017. newsLens:\nbuilding and visualizing long-ranging news stories.\nInProceedings of the Events and Stories in the News\nWorkshop , pages 1\u20139, Vancouver, Canada.\nQisheng Liao, Meiting Lai, and Preslav Nakov. 2023.\nMarsEclipse at SemEval-2023 task 3: Multi-lingual\nand multi-label framing detection with contrastive\nlearning. In Proceedings of the the 17th International\nWorkshop on Semantic Evaluation , SemEval \u201923,\npages 83\u201387, Toronto, Canada.\nJishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stu-\nart Golodetz, Philip Torr, and Puneet Dokania. 2020.\nCalibrating deep neural networks using focal loss.\nAdvances in Neural Information Processing Systems ,\n33:15288\u201315299.\nJakub Piskorski, Nicolas Stefanovitch, Giovanni\nDa San Martino, and Preslav Nakov. 2023a.\nSemEval-2023 task 3: Detecting the category, the\nframing, and the persuasion techniques in online\nnews in a multi-lingual setup. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\nSemEval\u201923, pages 2343\u20132361, Toronto, Canada.\nJakub Piskorski, Nicolas Stefanovitch, Nikolaos Niko-\nlaidis, Giovanni Da San Martino, and Preslav Nakov.\n2023b. Multilingual multifaceted understanding of\nonline news in terms of genre, framing, and persua-\nsion techniques. In Proceedings of the 61st Annual\nMeeting of the Association for Computational Lin-\nguistics , ACL \u201923, pages 3001\u20133022. Association for\nComputational Linguistics.\nYifan Zhang, Giovanni Da San Martino, Alberto Barr\u00f3n-\nCede\u00f1o, Salvatore Romeo, Jisun An, Haewoon Kwak,\nTodor Staykovski, Israa Jaradat, Georgi Karadzhov,\nRamy Baly, Kareem Darwish, James Glass, and\nPreslav Nakov. 2019. Tanbih: Get to know what you\nare reading. In Proceedings of the 2019 Conference\non Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on\nNatural Language Processing: System Demonstra-\ntions , EMNLP-IJCNLP \u201919, pages 223\u2013228, Hong\nKong, China.213", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Frappe: Framing, persuasion, and propaganda explorer", "author": ["A Sajwani", "A El Setohy", "A Mekky"], "pub_year": "2024", "venue": "Proceedings of the \u2026", "abstract": "The abundance of news sources and the urgent demand for reliable information have led to  serious concerns about the threat of misleading information. In this paper, we present"}, "filled": false, "gsrank": 411, "pub_url": "https://aclanthology.org/2024.eacl-demo.22/", "author_id": ["", "", "V7PNJyoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:1Jqh05qzlSQJ:scholar.google.com/&output=cite&scirp=410&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D410%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=1Jqh05qzlSQJ&ei=ULWsaODNLLTWieoP1pCJ2AY&json=", "num_citations": 8, "citedby_url": "/scholar?cites=2636210634452212436&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:1Jqh05qzlSQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2024.eacl-demo.22.pdf"}}, {"title": "Iffy quotient: A platform health metric for misinformation", "year": "2018", "pdf_data": "Iffy\nQuotient:\nA\nPlatform\nHealth\nMetric\nfor\nMisinformation\nPaul\nResnick\n,\nAviv\nOvadya\n,\nand\nGarlin\nGilchrist\n1\n2\n3\nv1:\nOctober\n10,\n2018\n(\nlink\n)\nv2:\nJuly\n23,\n2019\n(\nlink\n)\nv3\n(this\nversion):\nJune\n29,\n2023\n(\nlink\n)\nLatest\nversion\ncan\nalways\nbe\naccessed\nat\nhttp://umsi.info/iffy-quotient-whitepaper\nWebsite\nwith\npublic\ndashboard:\nhttps://csmr.umich.edu/projects/iffy-quotient/\nExecutive\nSummary\nSocial\nmedia\nsites\nand\nsearch\nengines\nhave\nbecome\nthe\nde\nfacto\ngatekeepers\nof\npublic\ncommunication,\na\nrole\nonce\noccupied\nby\npublishers\nand\nbroadcasters.\nWith\nthis\nnew\nrole\ncome\npublic\nresponsibilities,\nincluding\nlimiting\nthe\nspread\nof\nmisinformation.\nExternally\nmaintained\nmetrics\noffer\na\nway\nto\nmeasure\nthe\nprogress\nof\nmedia\nplatforms\nat\nmeeting\ntheir\npublic\nresponsibilities.\nBy\ncontrast\nwith\nthe\ncurrent\nenvironment\nof\naccountability\nby\nanecdotes,\nPlatform\nHealth\nMetrics\ncan\nfocus\nattention\non\nthe\noverall\nperformance\nof\nplatforms\nrather\nthan\non\nbad\noutcomes\nin\nindividual\ncases.\nThe\nCenter\nfor\nSocial\nMedia\nResponsibility\nat\nthe\nUniversity\nof\nMichigan\nSchool\nof\nInformation\nhas\ndeveloped\nthe\nIffy\nQuotient,\na\nmetric\nfor\nhow\nmuch\ncontent\nfrom\n\u201cIffy\u201d\nsites\nhas\nbeen\namplified\non\nFacebook\nand\nTwitter.\nWe\nuse\nthe\nterm\n\u201cIffy\u201d\nto\ndescribe\nsites\nthat\nfrequently\npublish\nmisinformation.\nIt\nis\na\nlight-hearted\nway\nto\nacknowledge\nthat\nour\ncategorization\nof\nthe\nsites\nis\nbased\non\nimprecise\ncriteria\nand\nfallible\nhuman\njudgments.\nWe\nare\npublishing\na\nweb-based\ndashboard\nthat\ncharts\nthe\nIffy\nQuotient\nsince\nearly\n2016.\nThe\ndashboard\nenables\ncomparisons\nover\ntime\nand\nbetween\nplatforms.\nThis\nreport\ndescribes\nthe\ncalculation\nof\nthe\nIffy\nQuotient\nin\ndetail,\ndiscusses\nsome\nof\nits\npotential\nlimitations,\nand\nanalyzes\nsome\nof\nthe\ntrends.\n3\nGarlin\nGilchrist\nhelped\nto\ndraft\nthe\ninitial\nversion\nof\nthis\nreport\nwhile\nhe\nwas\nExecutive\nDirector\nof\nthe \nCenter\nfor\nSocial\nMedia\nResponsibility\nin\n2017-18.\nHe\ncurrently\nserves\nas\nLieutenant\nGovernor\nof\nthe \nState\nof\nMichigan.\n2\nAviv\nOvadya\nserved\nas\nChief\nTechnologist\nfor\nthe\nCenter\nfor\nSocial\nMedia\nResponsibility\nin\n2017-18, \nwith\nprimary\nresponsibility\nfor\narchitecting\nthe\nIffy\nQuotient.\n1\nPaul\nResnick\nis\na\nProfessor\nand\nAssociate\nDean\nfor\nResearch\nand\nInnovation\nat\nthe\nUniversity\nof \nMichigan\nSchool\nof\nInformation,\nand\nDirector\nof\nthe\nCenter\nfor\nSocial\nMedia\nResponsibility.\nHe\nwas\na \nconsultant\nto\nFacebook\nin\n2018-2020,\nbut\nthis\nwork\nis\nindependent.\n\nMajor\nChanges\nfor\nv3\nIn\n2023,\nfor\nv3,\nwe\nswitched\nfrom\ncalculating\nthe\nfraction\nof\nURLs\nthat\nwere\nfrom\nIffy\nsites\nto\ncalculating\nthe\nfraction\nof\ntotal\nengagement\non\nthose\nURLs\nthat\nwere\nfrom\nIffy\nsites.\nWe\nhad\npreviously\ndisplayed\nthe\nengagement-weighted\nIffy\nQuotient\nas\nan\nalternative\nmetric.\nIn\n2023,\nwe\nswitched\nto\nmake\nit\nour\nprimary\nmetric.\nSecond,\nwe\nswitched\nfrom\ncalculating\ndaily\nIffy\nQuotients\nto\nweekly,\nwith\nweeks\nrunning\nfrom\nMonday-Sunday.\nIn\nour\nhistorical\nchart\nwe\nwere\npreviously\nperforming\nseven-day\nsmoothing:\neach\nday\u2019s\nIffy\nQuotient\nwas\nreally\nthe\nIffy\nQuotient\nover\nthe\nprevious\nseven\ndays.\nThe\nnew\ninterface\nfor\nour\nweb\npage,\nallowing\nfor\ncomparisons\nbetween\ntime\nperiods,\ncame\nout\ncleaner\nwhen\nwe\njust\nreported\non\nweeks\ninstead\nof\nseven-day\nmoving\naverages.\nIf\nthe\nidea\nof\nseven-day\nmoving\naverages\nseems\ncomplicated\nto\nyou,\nthen\nyou\nare\nalready\nappreciating\nwhy\nswitching\nto\nreporting\non\nthe\nIffy\nQuotient\nfor\neach\nweek\nwas\na\ndesirable\nsimplification!\nThird,\nwe\nchanged\nour\n\u201cbackfill\u201d\npractice.\nPreviously,\nwe\nused\nany\nnew\nclassifications\nor\nclassification\nchanges\nto\nretroactively\nupdate\nthe\nIffy\nQuotient\ncalculations\nfor\nthe\nprevious\nthree\nmonths.\nThe\nmotivation\nfor\nthat\npractice\nwas\nthat\nnewly\npopular\nsites\nmight\nnot\nbe\nclassified\nimmediately\nby\nNewsGuard\nor\nMedia\nBias/Fact\nCheck.\nThe\nbackfill\nallowed\nus\nto\napply\nthe\nclassifications\nretroactively,\nonce\nthey\ncame\nin.\nHowever,\nthe\nchoice\nof\nthree\nmonths\nas\nthe\ntime\nperiod\nfor\nbackfill\nwas\nsomewhat\narbitrary.\nMoreover,\nit\nmeant\nthat\nall\nIffy\nQuotient\nvalues\nthat\nwe\npublished\nwere\nprovisional\nfor\na\nperiod\nof\nthree\nmonths.\nWe\nno\nlonger\napply\nsite\nclassifications\nretroactively.\nOnce\nwe\npublish\na\nchart\nwith\nthe\nIffy\nQuotient\nfor\na\ntime\nperiod,\nwe\nwill\nno\nlonger\nchange\nit\n(unless\nwe\ndiscover\na\ndata\nerror).\nFinally,\nwe\napplied\na\ncorrection\nfor\nnear-duplicate\nURLs.\nSometimes,\namong\nthe\ntop\n5000\nURLs\nreturned\nby\nNewsWhip\non\na\ngiven\nday,\nmultiple\nURLs\ndiffered\nonly\nin\nthe\n\u201cquery\nparameters,\u201d\nthe\npart\nof\nthe\nURL\npath\nafter\nthe\n\u201c?\u201d\ncharacter.\nFor\nsome\nsites,\nURL\npairs\ndiffering\nonly\nin\nthese\nquery\nparameters\nreflected\ndifferent\nnews\nstories.\nIn\nother\ncases,\nhowever,\nthey\nreflected\na\nsingle\nnews\nstory\nthat\nhad\nbeen\nretrieved\nby\nNewsWhip\nmultiple\ntimes,\nwith\ngrowing\nengagement\ncounts\nover\ntime\nbut\nslightly\ndifferent\nURLs.\nThrough\nmost\nof\nour\ndata\ncollection,\nthis\nhappened\nrarely,\nbut\nthere\nwas\na\ntime\nperiod\nwhen\nit\nhappened\nmore\nfrequently.\nWe\napplied\na\ncorrection\nto\naccount\nfor\nthese\nnear-duplicate\nURLs.\nDetails\nare\ndescribed\nbelow\nin\nStep\n1\n(data\ncollection)\nof\nour\ncalculation\nmethodology.\nCompared\nto\nnot\ncorrecting\nat\nall,\nthe\nmain\neffect\nof\nnoticing\nand\ncorrecting\nfor\nnear-duplicate\nURLs\nwas\nto\nreduce\nthe\nengagement\nattributed\nto\nsites\nunlabeled\nby\neither\nNewsGuard\nor\nMBFC\n(e.g.,\nnba.com),\nand\nthus\nit\nhad\nonly\nsmall\neffects\non\nthe\ncalculated\nIffy\nQuotient.\n-\n1\n-\n\nMajor\nChanges\nfor\nv2\nIn\n2019,\nwe\nchanged\nthe\nmethodology\nfor\ncalculating\nthe\nIffy\nQuotient.\nWe\nnow\ndeem\na\nsite\nas\nIffy\nor\nOK\nbased\non\nratings\nfrom\nNewsGuard,\nfalling\nback\non\nratings\nfrom\nMedia\nBias/Fact\nCheck\nonly\nfor\nsites\nnot\nrated\nby\nNewsGuard.\nIn\naddition,\nbecause\nNewsGuard\nhas\nhigher\ncoverage\nof\nsites\nthat\nwere\npopular\nin\n2019\nthan\nthose\nin\n2016,\nand\nfor\nsites\nthat\nwere\npopular\non\nFacebook\nthan\nthose\nthat\nwere\npopular\non\nTwitter,\nwe\nnow\ndefine\nthe\nIffy\nQuotient\nas\nthe\nfraction\nof\nURLs\nfrom\nrated\nsites\nrather\nthan\nthe\nfraction\nof\nURLs\nfrom\nall\nsites.\nThis\nhas\nincreased\nthe\nabsolute\nvalues\nof\nthe\nIffy\nQuotient\non\nparticular\ndays\nin\ncomparison\nto\nour\nversion\n1\nnumbers,\nbut\nthe\ntrends\nover\ntime\nremain\nlargely\nunchanged.\n-\n2\n-\n\nReport\nIntroduction\nSocial\nmedia\nsites\nand\nsearch\nengines\nhave\nbecome\nthe\nde\nfacto\ngatekeepers\nof\npublic\ncommunication,\na\nrole\nonce\noccupied\nby\npublishers\nand\nbroadcasters.\nWith\nthis\nnew\nrole\ncome\npublic\nresponsibilities,\nbeyond\nthe\ncommercial\nresponsibilities\nthat\na\ncompany\nhas\nto\nplease\ncustomers\nand\nreward\nshareholders.\nAmong\nthese\npublic\nresponsibilities\nare\nlimiting\nthe\nspread\nof\nmisinformation,\nensuring\na\nlevel\nplaying\nfield\nin\nthe\nfree\ncompetition\nof\nideas,\nand\npromoting\ninterpersonal\nconnections\nthat\nheal\nrather\nthan\naggravate\nsocietal\ndivisions.\nThe\nCenter\nfor\nSocial\nMedia\nResponsibility\nis\ndeveloping\nPlatform\nHealth\nMetrics,\nwhich\ntrack\nhow\nwell\nsocial\nmedia\nsites\nand\nsearch\nengines\n(which\nwe\nrefer\nto\ncollectively\nas\nmedia\nplatforms)\nare\nmeeting\nthese\npublic\nresponsibilities.\nA\nmetric\nreduces\nan\nabstract\nideal,\nsuch\nas\nlimiting\nthe\nspread\nof\nmisinformation,\nto\na\nconcrete\nmeasurement\nthat\ncan\nbe\ntaken\nrepeatedly,\nenabling\ncomparisons\nover\ntime\nand\nbetween\nplatforms.\nThis\nreport\nintroduces\nthe\nIffy\nQuotient,\none\nsuch\nmetric.\nIt\ncomputes\nthe\nfraction\nof\nthe\nmost\npopular\nURLs\nthat\ncome\nfrom\nIffy\nsites\n-\nsites\nthat\nhave\nfrequently\npublished\nmisinformation\nand\nhoaxes\nin\nthe\npast.\nOur\nwebsite\nreports\nthe\nIffy\nQuotient\nfor\nFacebook\nand\nTwitter\ngoing\nback\nto\n2016\nand\nit\nwill\nbe\nupdated\non\nan\nongoing\nbasis.\nKey\nPerformance\nMetrics\nare\npowerful\nmanagement\ntools\nfor\nmedia\ncompanies.\nMature\nconsumer-facing\ntechnology\nplatforms\nalready\nmaintain\ninternal\nsuites\nof\nmetrics,\nsuch\nas\nmonthly\npage\nviews,\nclickthrough\nrates,\ndwell\ntimes,\ncustomer\nacquisition\nand\nretention,\nand\nad\nrevenue.\nThese\nmetrics\nstrongly\ninfluence\ndecisions\nabout\nchanges\nto\nproducts\nand\npolicies.\nTypically,\nproduct\nmanagers\nare\nrewarded\nfor\nimproving\nsome\nprimary\nmetric,\nsubject\nto\nthe\nconstraint\nthat\nthere\nis\nat\nmost\na\nmodest\ndecline\nin\nother\nmetrics.\nExternally\nmaintained\nmetrics\noffer\ntwo\nadvantages\nover\ninternal\nmetrics\nmaintained\nby\nthe\nplatforms.\nFirst,\nthey\ncan\ndraw\nattention\nto\nissues\nthat\nplatforms\nmay\neither\nnot\nbe\ntracking\nthemselves\nor\nnot\nprioritizing\nas\nmuch\nas\nthe\npublic\nwould\nlike.\nThis\nform\nof\npublic\naccountability\nis\npreferable\nto\nthe\ncurrent\nenvironment\nof\naccountability\nby\n\u201cgotcha\u201d\nanecdotes.\nIt\nfocuses\nattention\non\nthe\noverall\nperformance\nof\nplatforms\nrather\nthan\nbad\noutcomes\nin\nindividual\ncases;\nsome\nbad\noutcomes\nmay\nbe\ninevitable\ngiven\nthe\nscale\non\nwhich\nthe\nplatforms\noperate.\nSecond,\nexternal\nmetrics\ncan\ncreate\npublic\nlegitimacy\nfor\nclaims\nthat\nplatforms\nmake\nabout\nhow\nwell\nthey\nare\nmeeting\npublic\nresponsibilities.\nEven\nif\nFacebook\nactually\nreduces\nthe\naudience\n-\n3\n-\n\nshare\nfor\nIffy\ncontent,\nthe\npublic\nmay\nbe\nskeptical\nif\nFacebook\ndefines\nthe\nmetric,\nconducts\nthe\nmeasurement\nwithout\naudit,\nand\nchooses\nwhether\nto\nreport\nit.\nOf\ncourse,\nmetrics\nare\nnot\na\npanacea.\nThe\nthing\nthat\nis\nmeasured\nis\noften\na\nproxy\nfor\nthe\nthing\nthat\nreally\nmatters.\nManagerial\nefforts\nto\nimprove\nthe\nmetric\n(the\nproxy)\nmay\nnot\nsimilarly\nimprove\nthe\ntrue\nquantity\nof\ninterest;\nin\nextreme\ncases\nthis\nis\nreferred\nto\nas\n\u201cgaming\nthe\nmetric.\u201d\nExternally\nmaintained\nmetrics\nmay\nbe\nespecially\nsusceptible\nto\nsuch\nproblems.\nDue\nto\nlimited\naccess\nto\nproprietary\ndata,\nan\nexternal\nmetric\nmay\ninvolve\ncompromises\nthat\nmake\nit\na\nweaker\nproxy.\nThis\nreport\nalso\ndescribes\nsome\nof\nthe\nlimitations\nand\ncompromises\ninvolved\nin\ndefining\nand\nmeasuring\nthe\nIffy\nQuotient\nand\nthe\npotential\nrisks\nthat\ncome\nfrom\nthem.\nLimiting\nthe\nReach\nof\nMisinformation\nis\na\nPublic\nResponsibility\nof\nMedia\nPlatforms\nMedia\nplatforms\nshould\nnot\nbe\nexpected\nto\nprevent\nthe\npublication\nof\nmisinformation\nor\nto\nprevent\npeople\nwho\nseek\naccess\nto\nit\nfrom\nfinding\nit\n(unless\nthe\nmisinformation\nis\nalso\nharmful\nin\nsome\nway\nthat\nis\nprohibited\nby\nlaw,\nsuch\nas\nby\ndirectly\ninciting\nviolence).\nWe\nthink,\nhowever,\nthat\nmedia\nplatforms\nshould\nnot\namplify\nmisinformation\u2014as\nRenee\nDiresta\nconcisely\nargues:\n\u201cFree\nspeech\nis\nnot\nthe\nsame\nas\nfree\nreach.\u201d\nMisinformation,\nif\nwidely\nshared,\ncan\ninfluence\npublic\n4\nopinion,\ncreate\nsocial\ndivisions,\nand\neven\nstir\nup\nviolence,\nas\nhas\nbeen\ndocumented\nin\nIndia,\nSri\nLanka,\nand\nMyanmar.\nIt\ncan\ndegrade\ntrust,\nwhich\nis\nnecessary\nfor\nsociety\nto\nfunction\nwell.\nAnd\n5\nit\ncan\ndrive\ngovernment\nactions\nthat\nbenefit\nspecial\ninterests\nrather\nthan\npublic\ninterests.\nIt\nis\nespecially\nimportant\nthat\nspecial\ninterests,\nincluding\nforeign\nactors,\nnot\nbe\nable\nto\nmanipulate\nmedia\nplatforms\nso\nthat\nthey\nspread\nmisinformation.\nFacebook\nand\nTwitter\nhave\naccepted\nresponsibility\nfor\ncountering\ndeliberate\nmanipulation.\nFor\nexample,\nTwitter\nexecutive\nColin\nCrowell\nwrote\non\nthe\ncompany\nblog\nin\n2017,\n\u201cWe\u2019re\nworking\nhard\nto\ndetect\nspammy\nbehaviors\nat\nsource,\nsuch\nas\nthe\nmass\ndistribution\nof\nTweets\nor\nattempts\nto\nmanipulate\ntrending\ntopics.\u201d\nFacebook\nreported\nthat\nit\nremoved\n583\nmillion\nfake\naccounts\nin\n6\nthe\nfirst\nquarter\nof\n2018.\nThe\ntwo\nseem\nto\ndiverge\nsomewhat,\nhowever,\nin\nwhether\nthey\naccept\n7\nresponsibility\nfor\nnot\namplifying\nmisinformation\nin\nthe\nabsence\nof\ndeliberate\nmanipulation.\nFacebook\nappears\nto\nimplicitly\naccept\nthis\nresponsibility,\nwith\ntheir\nannouncement\nthat\nthey\nwill\ntake\naction\nto\nreduce\nthe\naudience\nfor\nitems\nthat\njournalist\nfact-checkers\njudge\nto\nbe\nfalse.\n8\nCrowell\u2019s\npost,\non\nthe\nother\nhand,\ngoes\non\nto\nsuggest\nthat\nTwitter\nthinks\nits\nonly\nresponsibility\nis\nto\nensure\nthe\nspread\nof\ncounter-information\nto\nmisinformation.\n8\nhttps://www.facebook.com/help/1952307158131536\n7\nhttps://newsroom.fb.com/news/2018/05/enforcement-numbers/\n6\nhttps://blog.twitter.com/official/en_us/topics/company/2017/Our-Approach-Bots-Misinformation.html\n5\nhttps://www.nytimes.com/2018/07/18/technology/facebook-to-remove-misinformation-that-leads-to-violenc \ne.html\n4\nhttps://www.wired.com/story/free-speech-is-not-the-same-as-free-reach/\n-\n4\n-\n\nWhether\nor\nnot\nthey\naccept\nresponsibility\nfor\npreventing\nthe\namplification\nof\nmisinformation,\nexecutives\nfrom\nboth\nsites\nargue\nthat\nthey\nshould\nnot\nbecome\n\u201carbiters\nof\ntruth.\u201d\nThis\nstill\nleaves\nroom,\nhowever,\nfor\nother\nkinds\nof\ncounter-measures\nthat\ncould\nreduce\nthe\nplatforms\u2019\namplification\nof\nmisinformation.\nOne\napproach\nfocuses\nentirely\non\nprocess,\neschewing\nassessments\nof\ntruth\u2014for\nexample,\nidentifying\nand\neliminating\nbot\naccounts.\nAnother\nis\nto\noutsource\njudgments\nof\ninformation\nreliability\nto\njournalists,\nthird-party\nfact-checkers,\nmedia\nwatchdogs,\nor\nplatform\nusers.\nThis\nreport\ndoes\nnot\nargue\nfor\nor\nagainst\nany\nparticular\ncounter-measures;\nthe\nIffy\nQuotient\nmerely\nprovides\na\nway\nto\nmeasure\nthe\neffectiveness\nof\nany\ncounter-measures\nthat\nmay\nhave\nbeen\nimplemented.\nDefining\nMisinformation\nExactly\nwhat\ncounts\nas\nmisinformation\nhas\nbecome\npolitically\ncontested\nand\nis\nan\nactive\nfront\nin\nthe\nongoing\nculture\nwars.\nMany\nseemingly\nfactual\nclaims\nare\nin\nfact\ncontextual\nspin\nthat\nmay\ninvite\nmisinterpretation\nwithout\nactually\nmaking\nany\nfactual\nclaims.\nEven\nwith\nfactual\nclaims,\nonly\nlimited\nevidence\nmay\nbe\navailable.\nNot\neveryone\nmay\nagree,\ngiven\nthe\navailable\nevidence,\nwhether\nthe\nclaim\nis\ntrue\nor\nfalse.\nWe\nbegin\nwith\na\nrecipient-centric,\nsubjective\ndefinition\nof\nmisinformation:\ninformation\nthat\nthe\nrecipient\nwould\njudge\nto\nbe\nfalse\nor\nmisleading\nif\nthey\ntook\nthe\ntime\nto\ncarefully\nconsider\nall\nof\nthe\nevidence\nabout\nit\n.\nWith\nthat\nin\nmind,\nthe\nplatform\u2019s\nresponsibility,\nwe\nargue,\nshould\nbe\nto\nspread\na\npiece\nof\ninformation\nonly\nto\nthose\npeople\nwho\nwould,\nin\nfull\nknowledge\nof\navailable\nevidence,\naccess\nand\nspread\nit.\nHowever,\nmedia\nplatforms\ntake\nmany\nactions\nat\nan\naggregate,\nnon-personalized\nlevel.\nThat\nmakes\nit\nuseful\nto\nadopt\na\ncollective,\nbut\nstill\nsubjective,\ndefinition\nof\nmisinformation:\ninformation\nthat\nmost\nrecipients\nwould\njudge\nto\nbe\nfalse\nor\nmisleading\nafter\ntaking\nthe\ntime\nto\ncarefully\nconsider\nall\nof\nthe\nevidence\nabout\nit\n.\nWith\nthat\ndefinition,\nthe\nplatform\u2019s\nresponsibility\nis\nto\nsupport\nthe\namplification\nof\na\npiece\nof\ninformation\nif\na\nmajority\nof\nthe\npotential\naudience,\nin\nfull\nknowledge\nof\navailable\nevidence,\nwould\naccess\nand\nspread\nit.\nThese\ndefinitions\nare\nbased\non\na\ncounterfactual:\nhow\nindividuals\nwould\njudge\nan\nitem\nif\nthey\nconsidered\nthe\nevidence\nfor\nand\nagainst\nit.\nIn\nan\nideal\nworld,\nthere\nwould\nbe\na\nprocess\nthat\nresolved\nthat\ncounterfactual\nfor\nenough\npeople\nto\nyield\na\ngood\nestimate\nof\nthe\ncollective\njudgment.\nIn\nthe\nfuture,\nautomated\nclassifiers\nmight\nbe\nused\nas\na\nproxy,\nwith\nverification\nagainst\nhuman\njudgments\non\na\nsample\nof\nitems.\nIn\ncurrent\npractice,\nwe\nrely\non\nexternal\nentities\nas\na\nproxy\nto\nspeak\nfor\nwhat\nthe\ncollective\njudgment\nwould\nbe.\n-\n5\n-\n\nSite-level\nProxy\nJudgments\nIn\nour\ncase,\nwe\nrely\non\ntwo\nexternal\nentities,\nNewsGuard\nand\nMedia\nBias/Fact\nCheck.\nThey\n9\n10\nmake\njudgments\nnot\non\nindividual\nitems\nbut\non\nentire\nsites.\nWe\ntreat\ntheir\njudgments\nas\na\nproxy\nfor\nwhether\na\nparticular\ncontent\nsite\nfrequently\npublishes\ninformation\nthat\nthe\nmajority\nof\npeople\nwould\nconsider\nfalse\nor\nmisleading,\nafter\nconsidering\nall\nevidence.\nBecause\nthese\nexternal\nentities\nmake\ntheir\njudgments\nbased\non\nimprecise\ncriteria,\nwe\nadopt\nthe\nwhimsical\nterm\n\u201cIffy\u201d\nrather\nthan\nthe\nmore\ndefinitive\nterm\n\u201cmisinformation.\u201d\nSite-level\njudgments\nalone\nwould\nnot\nbe\nappropriate\nfor\nplatforms\nto\nuse\nin\nmaking\ndecisions\nabout\nwhether\nto\namplify\nthe\naudience\nfor\nparticular\nitems,\nfor\ntwo\nreasons.\nFirst,\neven\nsites\nthat\nfrequently\npublish\nmisinformation\nmay\nalso\npublish\nsome\nthings\nthat\nare\nnot\nmisleading.\nSecond,\nthe\njudgments\nmade\nby\nNewsGuard\nand\nMedia\nBias/Fact\nCheck,\naccording\nto\nthe\ncriteria\nthey\ndefine\nand\narticulate,\nmay\nnot\nmatch\nwhat\nthe\nmajority\nof\npeople\nwould\nconsider\nfalse\nor\nmisleading.\nThis\nreasoning\nis\nevident\nin\nthe\nannounced\npractices\nof\nmedia\nplatforms.\nFor\nexample,\nFacebook\ntakes\naction\nto\nreduce\nthe\naudience\nfor\nitems\nthat\njournalist\nfact-checkers\njudge\nto\nbe\nfalse,\nbut,\nto\nour\nknowledge,\ndoes\nnot\nrely\non\nthe\nsite-level\n11\njudgments\nof\nNewsGuard\nor\nMedia\nBias/Fact\nCheck.\nIt\nis\nreasonable,\nhowever,\nto\nuse\nsite-level\njudgments\nin\ncalculating\nthe\nIffy\nQuotient.\nTreating\nall\nitems\nfrom\na\nsite\nas\nIffy\nwill\ngive\nan\noverestimate\nof\nthe\nabsolute\namount\nof\nmisinformation\ndistributed\nby\nthe\nplatform.\nThe\namount\nof\noverestimation\nshould\nbe\nfairly\nstable,\nhowever,\nand\nthus\nshould\nnot\naffect\ncomparisons\nbetween\nsites\nand\ncomparisons\nover\ntime.\nSimilarly,\nmistaken\njudgments\nabout\nwhole\nsites\ncould\nlead\nto\nerrors\nin\nthe\nabsolute\npercentage\nof\nIffy\ncontent\nas\nrecorded\nin\nan\nIffy\nQuotient\nmeasurement,\nbut\nare\nunlikely\nto\nhave\na\nlarge\neffect\non\ncomparisons\nbetween\nmeasurements.\nThus,\nthe\nIffy\nQuotient\nis\nsuspect\nas\na\nmeasure\nof\nthe\nabsolute\namount\nof\nmisinformation\nthat\nis\nspread\nby\nplatforms,\nbut\nis\na\nreasonable\nway\nto\njudge\nwhether\nTwitter\nor\nFacebook\nspread\nmore\nmisinformation\nat\na\nparticular\npoint\nin\ntime,\nwhether\nTwitter\nspread\nmore\nor\nless\nIffy\ncontent\nin\nJuly\n2018\nvs.\nJuly\n2017,\nor\nwhether\na\nchange\nin\nmedia\nplatform\nmoderation\npolicy\nenacted\non\na\nparticular\ndate\nled\nto\nless\namplification\nof\nIffy\ncontent\nthe\nfollowing\nmonth.\nCalculating\nthe\nIffy\nQuotient\nfor\nEnglish\nLanguage\nNews\nFor\neach\nday,\nwe\ndownload\nthe\nmost\npopular\nURLs\non\nFacebook\nand\nTwitter\nfrom\nNewsWhip,\n12\na\ncommercial\nsocial\nmedia\nmonitoring\ncompany.\nWe\nalso\ndownload\nsite\njudgments\nfrom\nNewsGuard\nand\nMedia\nBias/Fact\nCheck\nabout\nwhich\nsites\nare\nIffy.\nFinally,\nwe\ncalculate\nthe\nfraction\nof\nengagement\nreceived\nby\nURLs\nfrom\nIffy\nsites.\nDetails\nfollow.\n12\nhttps://www.newswhip.com\n11\nhttps://www.facebook.com/help/1952307158131536\n10\nhttps://mediabiasfactcheck.com\n9\nhttps://www.newsguardtech.com/\n-\n6\n-\n\nNewsWhip\ntracks\nthe\ncreation\nof\nURLs\non\nmore\nthan\n400,000\nsites\nevery\nday.\nNewsWhip\nmaintains\na\nlist\nof\nsites\nthat\nit\nmonitors.\nThis\nincludes\ntraditional\nnews\nsites,\nsites\nthat\npeople\ntreat\nlike\nnews,\nand\nother\nsites\nthat\nare\nrelevant\nto\nNewsWhip's\nclients.\nThis\ndoes\nnot\ninclude\nall\nwebsites,\nbut\nit\nis\nquite\nbroad.\nLimitation:\nIt\nis\npossible\nthat\nthe\nincompleteness\nof\nNewsWhip\u2019s\ntracking\ncould\nlead\nto\nincorrect\nestimation\nof\nthe\ntrue\nIffy\nQuotient.\nFor\nexample,\nif\nNewsWhip\nis\nless\neffective\nat\ndiscovering\nhigh-engagement\nfly-by-night\nsites\n(e.g.,\nMacedonian\ntraffic\narbitrage)\nthan\nit\nis\nat\ntracking\nestablished\nreliable\nsources,\na\nhigher\nfraction\nof\nthe\nmissed\nsites\nmay\nbe\nIffy,\nleading\nto\nour\nmeasured\nvalue\nbeing\nan\nunderestimate.\nOr\nit\ncould\ngo\nthe\nother\nway,\nif\nNewsWhip\nmisses\nmore\nURLs\nfrom\nuntracked\nreliable\nsites\n(perhaps\nsmall\nniche\nsites)\nthan\nfrom\nIffy\nsites.\nFor\neach\nnews\nURL,\nNewsWhip\ngathers\nengagement\ndata\non\nFacebook\nand\nTwitter .\nNewsWhip\ntracks\nnew\nURLs\nadded\nto\nthe\nsites\nit\nmonitors.\nWhenever\na\nnew\npage\nis\nadded\nto\none\nof\nthese\nsites,\nNewsWhip\nchecks\nfor\nsocial\nengagement\nwith\nthat\nURL\non\nFacebook\nand\nTwitter\nas\ndescribed\nbelow.\nNewsWhip\nalso\ncontinues\nto\ncheck\nsocial\nengagement\nrepeatedly,\nthough\nmore\nand\nmore\nrarely\nas\nthe\nnumber\nof\nengagements\nappears\nto\nstabilize.\nNewsWhip\nprovides\na\nFacebook\nengagement\nscore\nfor\neach\nURL,\nwhich\nappears\nto\nclosely\ntrack\ndata\navailable\nthrough\nthe\npublic\nFacebook\nGraph\nAPI.\nIt\nprovides\nan\nindicator\nof\naggregate\nengagements\n(likes\nand\nother\nreactions,\nshares,\ncomments)\nwith\na\nURL\nwithout\nrevealing\nthe\nidentity\nof\nany\nparticular\nperson\nwho\nengages\nwith\nit.\nNewsWhip\nassociates\nall\nengagement\ndata\nwith\nthe\nURL\nand\nits\npublication\ndate,\nregardless\nof\nwhen\nthe\nengagement\noccurred\non\nFacebook.\n-\n7\n-\n\nNewsWhip\nalso\nprovides\na\n\"Twitter\nInfluencer\nShares\"\nvalue\nfor\nURLs.\nThis\nis\nthe\nsum\nof\ntweets\nmentioning\na\nURL\nby\nthe\n\"influencers\"\nthat\nNewsWhip\ntracks\nand\nthe\nretweet\ncounts\nfor\nthose\ntweets.\nNewsWhip\ntracks\nat\nleast\n300,000\naccounts,\nincluding\nverified\nTwitter\naccounts\nand\nother\naccounts\nthat\nare\nuseful\nto\nNewsWhip\u2019s\nclients.\nThis\napproach\nhas\nbeen\nused\nstarting\naround\nNovember\n27,\n2017.\nPrior\nto\nthat,\nNewsWhip\nused\na\ndifferent\nmethod\nto\nestimate\nthe\nnumber\nof\ntweets\nand\nretweets.\nExact\nnumbers\nbefore\nand\nafter\nthe\nchangeover\nmay\nnot\nbe\ncomparable.\nThe\nchange\nshould,\nhowever,\naffect\nURLs\nfrom\nIffy\nsites\nand\nother\nsites\nin\na\nsimilar\nway,\nand\nthus\nshould\nnot\nappreciably\naffect\nthe\nIffy\nQuotient.\nStep\n1.\nWe\nquery\nNewsWhip\nfor\neach\nday\u2019s\ntop\n5,000\nURLs\nfrom\neach\nsite.\nWe\nquery\nNewsWhip\nfor\n5,000\nURLs\npublished\non\neach\ndate.\nSince\nengagements\nare\nstill\ntrickling\nin\nfor\nrecently\npublished\ncontent,\nwe\ntreat\nthe\nengagement\ndata\nqueried\ntwo\ndays\nlater\nas\nthe\nofficial\nengagement\nscores\nand\ndo\nnot\nupdate\nbeyond\ntwo\ndays.\nWe\napplied\na\ncorrection\nto\ndiscard\nsome\nnear-duplicate\nURLs\nthat\ndiffered\nonly\nin\ntheir\nquery\nparameters.\nIn\nsome\ncases,\nNewsWhip\nretrieved\nengaged\ncounts\nmultiple\ntimes\nand\nprovided\nall\nof\nthose\nengagement\ncounts\nwith\nslightly\ndifferent\nURLs.\nUnfortunately,\nthe\ninformation\navailable\nto\nus\ndaily\nfrom\nNewsWhip\ndoes\nnot\nmake\nit\npossible\nto\ndistinguish\nthese\nerroneous\nnear-duplicates\nfrom\ngenuine\nnear-duplicates\nthat\nrefer\nto\ndistinct\nnews\narticles.\nNewsWhip\nprovided\nhistorical\ndata\nthat\nallowed\nus\nto\ndistinguish\nretrospectively.\nWe\nused\nthat\nto\nmake\na\ndetermination\nfor\neach\ndomain\nof\nwhether\nto\ntreat\nnear-duplicates\nas\ndistinct,\nor\nwhether\nto\ndiscard\nall\nbut\nthe\nlast,\nhighest\nengagement\nscore.\nWe\nfirst\ngrouped\npotential\nnear-duplicates\nbased\non\ntheir\nURL\naddress,\ntimestamp,\nheadline,\nand\nsummary.\nWe\nthen\nmaintained\na\nlookup\ntable\nof\ndomains\nto\ndetermine\nwhether,\nin\nthe\nfuture,\nto\napply\nthe\ncorrection\nof\ndiscarding\nall\nbut\nthe\nlast\nnear-duplicate\nURL\nin\nan\nidentified\ngroup.\nIn\nthe\nhistorical\ndata,\nsome\ndomains\nhad\nfewer\ngroups\nof\nnear-duplicates\nURLs\nthat\nreflected\ndifferent\nunderlying\narticles\nthan\ngroups\nthat\ndid\nnot.\nWe\ndecided\nto\napply\nthe\ncorrection\nto\nthose\ndomains.\nWe\nconducted\nsensitivity\nanalysis\nand\ndetermined\nthat,\non\nour\nhistorical\ndata,\nusing\nthe\nlookup\ntable\nto\ndetermine\nwhether\nto\napply\nthe\ncorrection\non\na\ndomain-by-domain\nbasis\nyielded\nvery\nsimilar\nfinal\nIffy\nQuotient\nestimates\nto\nwhat\nwould\nhave\nresulted\nfrom\ndetermining\nwhether\nto\napply\nthe\ncorrection\non\na\nper-news-article\nbasis.\n-\n8\n-\n\nCompared\nto\nnot\ncorrecting\nat\nall,\nthe\nmain\neffect\nof\nnoticing\nand\ncorrecting\nfor\nnear-duplicate\nURLs\nwas\nto\nreduce\nthe\nengagement\nattributed\nto\nsites\nunlabeled\nby\neither\nNewsGuard\nor\nMBFC\n(e.g.,\nnba.com),\nand\nthus\nit\nhad\nonly\nsmall\neffects\non\nthe\ncalculated\nIffy\nQuotient.\nLimitation:\nFake\naccounts\nmay\nbe\nused\nto\ninflate\nthe\nengagement\ncounts\non\nTwitter\nand\nFacebook,\nas\na\nway\nto\nmake\nthem\nappear\nmore\npopular\nand\nthus\ndrive\nreal\ntraffic.\nTwitter\nand\nFacebook\ntry\nto\nroot\nout\nsuch\nfake\naccounts,\nand\nNewsWhip\ntries\nto\navoid\ninclusion\nof\nfakes\namong\nthe\nTwitter\naccounts\nthat\nit\ntracks,\nbut\nthose\nattempts\ncan\nnever\nbe\ncompletely\nsuccessful.\nFake\naccounts\nare\nperhaps\nmore\nlikely\nto\nbe\nused\nfor\ncontent\nfrom\nIffy\nsites\nthan\nother\nsites.\nThis\ncould\nlead\nto\nan\noverestimate\nof\nthe\ntrue\nIffy\nQuotient,\nby\ncausing\nmore\nIffy\nsites\nto\ncreep\ninto\nthe\ntop\n5,000\nthan\nwould\nbe\nthere\nif\nno\nfake\naccounts\nwere\nincluded\nin\nengagement\nscores.\nStep\n2.\nWe\nclassify\neach\nURL\nbased\non\nits\nrating\nby\nNewsGuard\nand\nMedia\nBias/Fact\nCheck.\nGiven\na\nURL,\nwe\nclassify\nit\nby\ncomparing\nthe\nhostname\nto\nthe\nhostnames\nlisted\nin\nthe\nsource\nlists\ncurated\nand\nmaintained\nby\nNewsGuard\nand\nMedia\nBias/Fact\nCheck.\nStarting\nwith\nversion\n2,\nour\nprimary\nsource\nis\nnow\nNewsGuard,\nbecause\nit\nis\nrun\nby\ncareer\njournalists\nand\nis\nmore\ntransparent\nabout\nits\ncriteria\nand\njudgments\nof\nindividual\nsites.\nFor\nsites\nnot\nrated\nby\nNewsGuard,\nwe\nfall\nback\non\n13\nMedia\nBias/Fact\nCheck.\nIn\nversion\n1,\nwe\nreported\nthe\nIffy\nQuotient\nbased\non\nMedia\nBias/Fact\nCheck\nonly.\nSites\nrated\nby\nneither\nNewsGuard\nnor\nMedia\nBias/Fact\nCheck\nare\ntreated\nas\nUnknown.\nWe\nalso\ntreat\nas\nUnknown\nany\nURL\nfrom\na\nplatform\nsite\nthat\ndoes\nnot\npublish\nor\ncurate\nits\nown\nnews\ncontent,\nbecause\nthere\nis\nno\nsingle\nsite-level\nrating\nthat\nwould\nmeaningfully\napply\nto\nall\ncontent\non\nsuch\nsites.\nFor\nversions\n1\nand\n2,\nthe\nplatform\nlist\nwas\nYouTube\nand\nFacebook.\nFor\nversion\n3,\nthe\nlist\nis:\nGoogle,\nFacebook,\nInstagram,\nMedium,\nPinterest,\nTelegram,\nTikTok,\nTwitter,\nVimeo,\nWeibo,\nWhatsApp,\nand\nYouTube.\n14\nNewsGuard\nratings\nare\navailable\nfor\nany\nwebsite\nvia\na\nbrowser\nplugin.\nBy\nagreement\nwith\nNewsGuard,\nthey\nprovide\nus\nwith\nupdates\nof\ntheir\ncomplete\nlist\nof\nsite\nratings.\n14\nThe\nversion\n3\nexclusion\nlist\nis\nborrowed\nfrom \nhttps://www.propublica.org/article/google-ads-misinformation-methodology\nand\nslightly\namended.\n13\nhttps://www.newsguardtech.com/about/why-should-you-trust-us/ \nhttps://www.newsguardtech.com/ratings/criteria-for-and-explanation-of-ratings/\n-\n9\n-\n\nNewsGuard\u2019s\nReliability\nRatings\nare\nbased\non\nnine\napolitical\nand\nbasic\njournalistic\ncriteria\nthat\nassess\nthe\ncredibility\nand\ntransparency\nof\na\nnews\nor\ninformation\nsite,\nincluding\n\u201cDoes\nnot\nrepeatedly\npublish\nfalse\ncontent,\u201d\n\u201cRegularly\ncorrects\nor\nclarifies\nerrors,\u201d\nand\n\u201cAvoids\ndeceptive\nheadlines.\u201d\nNewsGuard\nawards\npoints\nfor\neach\ncriterion\nand\nsums\nthem\nup;\na\nscore\nless\nthan\n60\nearns\na\n\u201cgenerally\nunreliable\u201d\nrating;\n60\nand\nabove\nearns\na\n\u201cgenerally\nreliable\u201d\nrating.\nThey\nalso\nidentify\nsome\nsites\nas\n\u201cSatire\u201d.\nWe\ntreat\nsites\nwith\nscores\nof\n60\nand\nabove,\nor\n\u201csatire\u201d\nlabels,\nas\nOK,\nand\nother\nsites\nwith\nscores\nbelow\n60\nas\nIffy.\nMedia\nBias/Fact\nCheck\n(hereafter\n\u201cMBFC\u201d)\nevaluates\nsites\nand\nputs\nthem\non\none\nor\nmore\nof\nthe\nlists,\nbased\non\ncriteria\nthey\ndescribe\nfor\neach\nof\nthe\nlists.\nWe\nclassify\nas\nIffy\nany\nsite\nthat\nis\non\neither\nthe\n\u201cQuestionable\nSources\u201d\nlist\nor\nthe\n\u201cConspiracy-Pseudoscience\u201d\nlist.\nMBFC\u2019s\nwebsite\ndescribes\nthe\ncriteria\nfor\neach\nas\nfollows:\nA\nquestionable\nsource\nexhibits\none\nor\nmore\nof\nthe\nfollowing:\nextreme\nbias,\novert\npropaganda,\npoor\nor\nno\nsourcing\nto\ncredible\ninformation\nand/or\nis\nfake\nnews.\nFake\nNews\nis\nthe\ndeliberate\nattempt\nto\npublish\nhoaxes\nand/or\ndisinformation\nfor\nthe\npurpose\nof\nprofit\nor\ninfluence.\nSources\nlisted\nin\nthe\nQuestionable\nCategory\nmay\nbe\nvery\nuntrustworthy\nand\nshould\nbe\nfact\nchecked\non\na\nper\narticle\nbasis.\nSources\nin\nthe\nConspiracy-Pseudoscience\ncategory\nmay\npublish\nunverifiable\ninformation\nthat\nis\nnot\nalways\nsupported\nby\nevidence.\nThese\nsources\nmay\nbe\nuntrustworthy\nfor\ncredible/verifiable\ninformation,\ntherefore\nfact\nchecking\nand\nfurther\ninvestigation\nis\nrecommended\non\na\nper\narticle\nbasis\nwhen\nobtaining\ninformation\nfrom\nthese\nsources.\nMBFC\nalso\nprovides\nexplicit\nlistings\nof\nsites\nit\nhas\nevaluated\nand\njudged\nnot\nto\nbe\nappropriate\nfor\none\nof\nthose\nlists.\nOther\nlists\nthey\nprovide\ninclude\n\u201cLeft\nBias,\u201d\n\u201cLeft-Center\nBias,\u201d\n\u201cLeast\nBiased,\u201d\n\u201cRight-Center\nBias,\u201d\n\u201cRight\nBias,\u201d\n\u201cPro-Science,\u201d\nand\n\u201cSatire.\u201d\nWe\nclassify\nas\n\u201cOK\u201d\nany\nsite\nthat\nis\nnot\nIffy\nand\nis\non\none\nof\nthese\nother\nlists.\nIf\na\nsite\nis\nnot\non\nany\nof\nMBFC\u2019s\nlists,\nwe\nclassify\nit\nas\nUnknown.\nComplete\nlisting\nof\nthe\nMBFC\njudgments\nis\navailable\non\nits\nwebsite.\nTo\ngive\na\nflavor\nfor\nthe\njudgments:\n\u25cf\nVox\nand\nUpworthy\nare\nclassified\nas\nOK\n(Left\nBias)\nbut\nLearn\nProgress\nand\nOccupy\nDemocrats\nare\nIffy\n(Questionable\nSources).\n\u25cf\nFox\nNews\nand\nthe\nDrudge\nReport\nare\nclassified\nas\nOK\n(Right\nBias)\nbut\nBreitbart\nand\nTruthFeed\nare\nIffy\n(Questionable\nSources);\nFor\nthe\nfirst\nversion\nof\nthis\nreport,\nwe\nincluded\na\nrobustness\ntest\nusing\nOpen\nSources.\nHowever,\nOpen\nSources\nhas\nevaluated\nmany\nfewer\nsites,\nand\nthe\nlast\nupdate\nprior\nto\nthis\nreport\nwas\nApril\n28,\n2017.\nBeginning\nwith\nversion\n2,\nwe\nomit\nOpen\nSources\nentirely.\n15\n15\nhttps://github.com/BigMcLargeHuge/opensources/commits/master\n-\n10\n-\n\nPublishers\nsometimes\nchange\ntheir\ndomain\nnames.\nThis\nis\nespecially\ntrue\nfor\nIffy\npublishers\nwho\nmay\nchange\ndomain\nnames\nto\nget\na\nfresh\nstart\nwith\nsearch\nengines\nand\nsocial\nmedia\nsites\nthat\nmay\nhave\nstarted\nto\ndemote\nor\ndemonetize\nthem\nbased\non\nprior\ncomplaints\nand\ninvestigations.\nNewsGuard\nand\nMedia\nBias/Fact\nCheck\nmay\nnot\nalways\nnotice\nthese\nname\nchanges\nright\naway.\nMoreover,\nwhen\nthey\ndo,\nthey\nmay\nput\nthe\nnew\nsite\non\ntheir\nlists\nbut\nremove\nthe\nold\nsites.\nTo\naccount\nfor\nincompleteness\nof\nsome\nof\nour\nclassifications\nthat\nmight\nresult\nfrom\nsites\nchanging\ntheir\ndomain\nnames,\nfrom\n2016-2018\nwe\ntested\nfor\nautomatic\nredirects\nand\ncomputed\nsome\ninferred\nlabels.\nIn\nparticular,\nif\na\nURL\npublished\nsome\ntime\nago\nnow\nredirects\nto\na\nsite\nthat\nNewsGuard\nor\nMBFC\nhas\nlisted,\nwe\ngive\nit\nthe\nsame\nclassification\nas\nthe\nnew\nsite.\nIn\nour\nfirst\nrelease,\nwe\nalso\nwent\nthe\nother\ndirection,\napplying\nthe\nold\nlabel\nto\na\nnew\nsite\nthat\nthe\nold\nlabel\nredirects\nto;\nwe\ndiscontinued\nthat\npractice\nafter\nfinding\nthat\nsome\nIffy\nsites\nhave\nshut\ndown\nand\nredirect\nto\nmainstream\nsites.\nAfter\nJanuary\n1,\n2019,\nwe\ndiscontinued\nredirect\nprocessing\nentirely,\nbecause\nwe\nfound\nthat\nthere\nwere\nvery\nfew\nnewly\npopular\nURLs\nthat\nwere\ngetting\ninferred\nlabels\nas\na\nresult\nof\nthe\nredirect\nprocessing.\nStep\n3.\nSum\nthe\nengagement\nscores\nfor\nIffy\nURLs,\nand\nseparately\nfor\nOK\nURLs,\nacross\nall\ndays\nin\nthe\nselected\ntime\nperiod.\nFor\nversions\n1\nand\n2,\nwe\ncounted\nthe\nnumber\nof\nURLs\nfrom\nIffy\nand\nOK\nsites.\nThat\nyielded\na\ncount-based\nIffy\nQuotient.\nIt\ntreats\nall\nURLs\nin\nthe\ntop\n5000\nfor\neach\nday\nas\nequal,\neven\nif\nthe\ntop\nURL\ngets\na\nlot\nmore\nengagement\nthan\nthe\nbottom\none.\nFor\nversion\n3,\nwe\nswitched\nto\ncomputing\nan\nengagement-weighted\nversion\nof\nthe\nIffy\nQuotient.\nWe\nadd\nup\nthe\ntotal\nengagement\nscore\nof\nall\nURLs\nfrom\nIffy\nsites.\nSeparately,\nwe\nadd\nup\nthe\ntotal\nengagement\nscore\nof\nall\nURLs\nfrom\nOK\nsites.\nStep\n4.\nCompute\nthe\nIffy\nQuotient\nas\n.\ud835\udc3c\ud835\udc53\ud835\udc53\ud835\udc66\ud835\udc3c\ud835\udc53\ud835\udc53\ud835\udc66 + \ud835\udc42\ud835\udc3e\nWe\ndefine\nthe\nIffy\nQuotient\nas\nthe\nfraction\nof\ntotal\nengagement\nfor\nour\npool\nof\nURLs\nthat\nwent\nto\nIffy\nsites.\nWe\ncalculate\nthis\nseparately\nfor\nFacebook\nand\nTwitter.\nWe\ncompute\nthis\nfor\neach\nweek\n(Monday-Sunday),\nand\nalso\nfor\nmonths\nand\ncalendar\nyears.\nIn\nversions\n1\nand\n2,\nthe\nIffy\nand\nOK\nquantities\nin\nthe\nquotient\n(fraction)\nwere\ncounts\nof\nURLs\nrather\nthan\nsums\nof\nengagement\nscores.\nFor\nversion\n3,\nthe\nquantities\nare\nsums\nof\nengagement\nscores\nfor\nthe\nURLs.\nArguably,\nthis\nengagement-weighted\nversion\nis\na\ncloser\nproxy\nfor\nthe\nreal\nquantity\nof\nconcern,\nthe\nfraction\nof\nhuman\nattention\nto\nunreliable\ninformation.\nHowever,\nit\ndepends\nmore\nheavily\non\nthe\naccuracy\nof\nthe\nengagement\nestimates\nthan\nthe\ncount-based\nIffy\nQuotient,\nwhich\ndepends\non\nthe\nengagement\nestimates\nonly\nto\nselect\nthe\ntop\n5,000.\nIn\nversion\n1,\nthe\nIffy\nQuotient\nwas\ncomputed\nas\n,\nincluding\nUnknown\nURLs\nin\ud835\udc3c\ud835\udc53\ud835\udc53\ud835\udc66\ud835\udc3c\ud835\udc53\ud835\udc53\ud835\udc66 + \ud835\udc42\ud835\udc3e + \ud835\udc48\ud835\udc5b\ud835\udc58\ud835\udc5b\ud835\udc5c\ud835\udc64\ud835\udc5b\nthe\ndenominator.\nEssentially,\nthat\ntreated\nall\nUnknown\nsites\nas\nif\nthey\nwere\nOK.\nNewsGuard\nhas\n-\n11\n-\n\ngreater\ncoverage\nof\nsites\nthat\nwere\npopular\nin\n2019\nthan\nthose\nthat\nwere\npopular\nin\n2016,\nand\ngreater\ncoverage\nof\nsites\nwith\npopular\nURLs\non\nFacebook\nthan\nTwitter.\nTo\nfacilitate\ncomparison\nover\ntime\nand\nbetween\nsites,\nversion\n2\nexpresses\nthe\nIffy\nQuotient\nas\nthe\nfraction\nof\nrated\nsites.\nIn\nabsolute\nterms,\nthe\nIffy\nQuotient\nwas\nhigher\nin\nthe\nsecond\nversion\nthan\nthe\nfirst\nversion.\nWe\ncaution\nreaders\nthat\nthey\nstill\nshould\nnot\nplace\ntoo\nmuch\nemphasis\non\nthe\nabsolute\nvalue\nof\nthe\nIffy\nQuotient\nbut\ninstead\nshould\nuse\nit\nto\nmake\ncomparisons\nover\ntime\nand\nbetween\nplatforms.\nLimitation:\nSome\nof\nthe\nUnknown\nURLs\nmay\nbe\nfrom\nsites\nthat\nNewsGuard\nwould\njudge\nas\nIffy\nbut\nhasn\u2019t\ngotten\naround\nto\njudging\nyet.\nOur\ncurrent\napproach\nassumes\nthat\nthe\nunrated\nsites\nwould\nbe\nrated\nas\nIffy\nin\nthe\nsame\nproportion\nas\nthe\nrated\nones.\nThat\nis,\nif\n10%\nof\nthe\nURLs\nfrom\nrated\nsites\nare\nfrom\nIffy\nsites,\nthen\n10%\nof\nthe\nURLs\nfrom\nunrated\nsites\nare\nalso\nfrom\nIffy\nsites.\nIf,\nfor\nexample,\nthe\nunrated\nsites\nare\ndisproportionately\niffy,\nas\nNewsGuard\nrates\na\nlarger\nfraction\nof\nthem\nthe\nIffy\nQuotient\ncould\ngo\nup\nover\ntime\nwithout\nthere\nbeing\nany\nchange\nin\nthe\nfraction\nof\ncontent\nactually\nfrom\nIffy\nsites.\nThere\nis\nno\nway\nto\ncompletely\neliminate\nthis\npossibility\nthat\nimproved\nmeasurement\nover\ntime\ncould\nmake\nit\nlook\nlike\nthere\nis\na\nchange\nin\nthe\nIffy\nQuotient.\nOur\ndeep\ndive\npage\nshows\nfor\nany\ntime\nperiod\nthe\nmost\npopular\nURLs\nthat\nare\nclassified\nas\nIffy,\nOK,\nand\nUnknown.\nAnecdotally,\nmany\nof\nthe\npopular\nUnknown\nURLs\nare\nstories\nabout\nKorean\npop\nmusic.\nIn\nsummary,\nhere\u2019s\nhow\nwe\ncalculate\nthe\nIffy\nQuotient.\n1.\nNewsWhip\nprovides\nthe\n5,000\nmost\nengaged-with\nURLs\neach\nday,\non\nFacebook\nand\nTwitter.\n2.\nWe\ndefine\nas\nUnclassified\nany\nURLs\noriginating\nfrom\nplatform\nsites\nsuch\nas\nGoogle\nand\nFacebook.\n3.\nNewsGuard\nprovides\nlists\nof\ndomain\nnames\nthey\nhave\njudged.\na.\nWe\ndefine\nas\nIffy\nthose\nsites\nthat\nhave\na\nscore\nbelow\n60\nand\nare\nnot\nsatire\nor\na\nplatform.\nb.\nWe\ndefine\nas\nOK\nthose\nsites\nthat\nhave\nscores\nof\n60\nand\nabove\nor\nare\nsatire.\n4.\nFor\nsites\nunrated\nby\nNewsGuard,\nwe\ncheck\nwhether\nMedia\nBias/Fact\nCheck\nhas\nlabeled\nit.\na.\nWe\ndefine\nas\nIffy\nthose\nsites\nlisted\nas\nQuestionable\nSources\nor\nConspiracy/Pseudoscience\nb.\nWe\ndefine\nas\nOK\nthose\nsites\nlisted\nin\nother\ncategories,\nincluding\nLeft\nBias\nand\nRight\nBias\nc.\nWe\ndefine\nas\nUnclassified\nany\nURLs\nfrom\nall\nremaining\nsites.\n5.\nFor\neach\nday,\nwe\nsum\nup\nthe\nengagement\nwith\nURLs\nclassified\nas\nIffy\nand\nOK.\nThe\nIffy\nQuotient\nis\nthe\nfraction\nof\nuser\nengagement\n.\ud835\udc3c\ud835\udc53\ud835\udc53\ud835\udc66\ud835\udc3c\ud835\udc53\ud835\udc53\ud835\udc66 + \ud835\udc42\ud835\udc3e\nOur\nmain\npage\nreports\nthe\nIffy\nQuotients\nfor\nFacebook\nand\nTwitter\nfor\nthe\nprevious\nweek.\nOur\ndeep\ndive\npage\nlets\nanyone\nchoose\nany\nweek,\nmonth,\nquarter,\nor\nyear,\nand\nallows\nfor\ncomparisons\nbetween\ntime\nperiods.\n-\n12\n-\n\n-\n13\n-\n\nAnalysis\nFigure\n1.\nThe\nIffy\nQuotient\nfor\nFacebook\nand\nTwitter,\ndating\nback\nto\n2016,\ncomputed\non\na\nmonthly\nbasis.\nSee\nthe\nwebsite\nfor\nan\nup-to-date,\ndynamic\nversion\nwhere\nyou\ncan\nhover\nover\npoints\nto\nsee\ndata\nfor\nparticular\ndates.\nFigure\n1\nshows\nthe\nIffy\nQuotient\ndating\nback\nto\nearly\n2016,\nfor\nboth\nTwitter\nand\nFacebook.\nNote\nthat\nan\nIffy\nQuotient\nof\n10%\ndoes\nnot\nmean\nthat\n10%\nof\nall\nuser\nengagement\nwas\nwith\nstories\nthat\ncontain\nmisinformation.\nIt\nmeans\nthat\n10%\nof\nall\nuser\nengagement\nwas\nwith\nstories\nfrom\nsites\nthat\nNewsGuard\n(or\nMedia\nBias/Fact\nCheck)\njudged\nto\nbe\nin\na\ncategory\nthat\nwe\nhave\nlabeled\nIffy.\nThe\nIffy\nQuotient\nis\nmost\nuseful\nas\na\nway\nto\nmake\ncomparisons\nacross\ntime\nand\nbetween\nplatforms,\nespecially\nfocusing\non\nstable\ntrends\nrather\nthan\nsingle\ndates.\nFirst,\nnotice\nthe\ntemporal\ntrends.\nFor\nboth\nTwitter\nand\nFacebook,\nthere\nwas\nan\nincrease\nin\nattention\nto\nIffy\nsites\nin\nthe\nrun-up\nto\nthe\n2016\nU.S.\nelections\nand\nagain\nin\nthe\nrun-up\nto\nthe\n2020\nelections.\nThe\nIffy\nQuotient\nincreased\non\neach\nsite\nfrom\nApril\nto\nNovember,\npeaking\non\nor\nafter\nelection\nday.\nOn\nFacebook,\nthere\nwas\na\nclear\ndownward\ntrend\nfrom\nabout\nMarch\n2017,\nreaching\na\nlow\nof\n4.6%\nin\nAugust\n2019.\nIt\nagain\ntopped\n20%\nin\nthe\nsummer\nof\n2021\nbut\nhas\nbeen\nbelow\n5%\nfor\nmost\nof\n2023.\nOn\nTwitter,\nthe\nIffy\nQuotient\nhas\nbeen\neven\nmore\nvolatile,\nreaching\na\nhigh\nof\nnearly\n30%\nin\nNovember\n2020.\nIt\nreached\nits\nall-time\nlow\nin\nMarch\n2022,\nat\n5.4%,\nbut\nhas\nclimbed\ndramatically\nsince\nthen,\nreaching\n22.6%\nin\nJanuary\n2023.\nThere\nare\nseveral\nfactors\nthat\nplausibly\ncontribute\nto\nthese\ntemporal\ntrends.\nFirst,\nin\nthe\nrun-up\nto\nthe\n2016\nelections\nand\nthen\nafterwards,\nwhen\npeople\nwere\nunusually\npolitically\nactivated,\nthe\ngeneral\npublic\nhad\nmore\ninterest\nin\npolitical\nnews\u2014especially\nsensational\npolitical\nnews\u2014than\nin\nother\ntime\nperiods.\nURLs\nfrom\nIffy\nsites\nmay\nhave\nbeen\nable\nto\nappeal\nto\nthat\naudience\ninterest\n-\n14\n-\n\nbetter\nthan\nURLs\nfrom\nother\nsites.\nThis\nexplanation\nis\nconsistent\nwith\nreports\nof\nMacedonian\nsites\nwith\nno\npolitical\nagenda\nearning\nadvertising\nrevenue\nby\nposting\ninvented\nor\ncopied\npolitical\nstories.\nSecond,\nboth\ndomestic\nand\nforeign\npublishers\nwith\npolitical\nagendas\nmay\nhave\n16\nexpended\nmore\ntime\nand\nmoney\nto\nspread\nmisinformation\nduring\nthe\nrun-up\nto\nthe\nelection.\nWe\nnote,\nhowever,\nthat\nthere\nwere\nno\nsimilar\nincreases\nduring\nthe\n2018\nmidterm\nelections.\nAfter\nthe\n2016\nelection,\nin\naddition\nto\ndemand\nand\nsupply\ndeclining,\nthe\nplatforms\ntook\nsome\nactions\nto\nreduce\nthe\nspread\nof\nIffy\ncontent.\nFor\nexample,\nin\nDecember\n2016\nFacebook\nannounced\na\npartnership\nwith\nthird-party\nfact-checkers,\nsending\nthem\nquestionable\nstories\nand\nshowing\nlower\nin\nthe\nfeed\nthose\nthat\nthe\nfact-checkers\nlabeled\nas\nfalse.\nOn\nJanuary\n11,\n2018,\n17\nFacebook\nannounced\nthat\nit\nwould\nreduce\nthe\nreach\nof\nall\npublic\nexternal\ncontent\nin\nfavor\nof\nnative\nposts\nfrom\nfriends\nand\nfamily.\nOn\nits\nown,\nthat\nwouldn\u2019t\naffect\nthe\nIffy\nQuotient,\nwhich\nis\n18\nbased\non\nwhatever\npublic\ncontent\nis\nmost\npopular.\nHowever,\nthat\nannouncement,\nand\none\nthe\nfollowing\nweek,\nsignaled\nother\nchanges\nthat\nmight\nhave\naffected\nthe\nIffy\nQuotient.\nOne\nchange\n19\nwas\nto\nprioritize\ncontent\naround\nwhich\npeople\ninteracted\nwith\nfriends;\nit\ncould\nbe\nthat\npeople\ninteract\nless\naround\ncontent\nfrom\nIffy\nsites.\nAnother\nwas\nto\nprioritize\nnews\nthat\nthe\ncommunity\nrates\nas\ntrustworthy,\nthat\npeople\nfind\ninformative,\nand\nthat\nis\nlocal.\nWithout\nknowledge\nof\nexactly\nwhen\nparticular\nproduct\nfeatures\nor\npolicy\nchanges\nwere\nrolled\nout,\nwe\nare\nnot\nable\nto\nassess\nthe\nimpacts\nof\nparticular\ninitiatives\non\nthe\nIffy\nQuotient.\nYet\nthere\nwas\na\nlong-term\ndecline\nin\nFacebook\u2019s\nIffy\nQuotient\nfrom\nMarch\n2017\nthrough\nJuly\nof\n2019.\nOn\nAugust\n6,\n2018,\nFacebook\nannounced\na\nban\non\nseveral\npages\nassociated\nwith\nInfoWars\nhost\nAlex\nJones.\nThat\ndid\nnot\nhave\nan\nimmediate\nimpact\non\nthe\nIffy\nQuotient,\nwhich\nhovered\naround\n12%\nin\nthe\nweeks\nbefore\nand\nafter.\nTwitter\nwaited\nuntil\nSeptember\n6\nto\ntake\nsimilar\nsteps;\nsimilarly,\nthere\nwas\nnot\nan\nimmediate,\nmeasurable\neffect\non\nTwitter\u2019s\nIffy\nQuotient.\nNext,\nnotice\nthe\ndifference\nbetween\nTwitter\nand\nFacebook.\nFrom\n2016\nthrough\nthe\nend\nof\n2018,\nmore\nIffy\nsites\ngained\nattention\non\nFacebook\nthan\non\nTwitter.\nThis\npicture\nis\nconsonant\nwith\nthe\nfinding\nof\nAllcott,\nGentzkow,\nand\nYu.\nThey\nused\nanother\ncommercial\nservice,\nBuzzSumo,\nto\n20\nestimate\nthe\ntotal\nmonthly\ntweets\nand\nFacebook\nengagements\nfor\na\nset\nof\n570\nsites\nthat\n\u201chave\nbeen\nidentified\nas\nproducers\nof\nfalse\nstories,\u201d\nanalogous\nto\nour\nnotion\nof\nIffy\nsites.\nThey\nfound\nthat\ntotal\nFacebook\nengagements\ndropped\nby\nnearly\ntwo-thirds\nfrom\nthe\nend\nof\n2016\nto\nJuly\n2018,\nwhile\nthe\ntweets\nabout\nURLs\nfrom\nthose\nIffy\nsites\nincreased\nslightly.\nOne\nadvantage\nof\nour\napproach\nis\nthat\nby\nexpressing\nthe\nattention\nshare\nof\nIffy\nsites\nas\na\nfraction\nof\nthat\nfor\nall\npopular\nsites\non\neach\nplatform,\nwe\nare\nable\nto\ncompare\nthe\nIffy\nQuotient\nfor\nthe\ntwo\nplatforms\ndirectly\nat\nany\npoint\nin\ntime.\nBy\nearly\n2019,\nthe\ntwo\nsites\nhad\nequalized,\nand\nfor\nmost\nof\n2019\nTwitter\nhad\na\nhigher\nfraction\nof\nengagement\nwith\nURLs\ncoming\nfrom\nIffy\nsites\nthan\nFacebook\ndid.\nIt\nis\nnot\nentirely\nclear\nwhy\nthe\n20\nhttp://web.stanford.edu/~gentzkow/research/fake-news-trends.pdf\n19\nhttps://newsroom.fb.com/news/2018/01/trusted-sources/\n18\nhttps://newsroom.fb.com/news/2018/01/news-feed-fyi-bringing-people-closer-together/\n17\nhttps://newsroom.fb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake-news/\n16\nhttps://www.wired.com/2017/02/veles-macedonia-fake-news/\n-\n15\n-\n\ntwo\nplatforms\nchanged\npositions.\nPresumably,\nhowever,\nthere\nshould\nhave\nbeen\nsimilar\nfluctuations\nin\nsupply\nand\ndemand\nfor\nIffy\ncontent\nat\nthe\ntwo\nsites,\nwith\nthe\nmajor\ndifference\nbeing\npolicies\nand\ntechnical\nfeatures.\nFacebook\nmay\nhave\nbeen\nmore\nsuccessful\nat\ndetecting\nand\ncountering\nfake\naccounts\nand\nmanipulation\ncampaigns,\nmore\naggressive\nin\ndiscounting\nranking\nsignals\nthat\nare\nassociated\nwith\nIffy\nsites,\nor\nmore\naggressive\nin\ndemoting\nparticular\narticles\nand\nsources.\nFor\nmuch\nof\n2021,\nFacebook\nhad\na\nhigher\nIffy\nQuotient\nthan\nTwitter,\nand\nthe\nsites\nreversed\npositions\nagain\nin\nmid-2022;\nin\nmid-2023,\nTwitter\u2019s\nIffy\nQuotient\nwas\nmore\nthan\ntriple\nthat\nof\nFacebook.\nFigure\n2.\nEngagement-weighted\nvs.\ncount-based\nIffy\nQuotients.\nOn\nthe\nleft,\nthe\n(mostly\nhigher)\nlighter\nlavender\nline\nis\nthe\nsame\nas\nthe\ncorresponding\nline\nin\nFigure\n1,\nthe\nengagement-weighted\nIffy\nQuotient\nfor\nFacebook,\nwhile\nthe\ndarker\nviolet\nline\nshows\nthe\ncount-based\nIffy\nQuotient.\nOn\nthe\nright\nside,\nfor\nTwitter,\nthe\nlighter\ngreen\nline\nmatches\nthat\nin\nFigure\n1,\nthe\nengagement-weighted\nversion.\nFigure\n2\ncompares\nthe\nengagement-weighted\nand\ncount-based\nIffy\nQuotients\nfor\nFacebook\nand\nTwitter.\nThe\nengagement-weighted\nversion\nbecame\nthe\nprimary\nmeasure\nwith\nversion\n3.\nFor\nFacebook,\nin\n2016-17\nand\n2020-21\nthe\nengagement-weighted\nIffy\nQuotient\nwas\nnoticeably\nhigher\nthan\nthe\ncount-based.\nThis\nsuggests\nthat\nURLs\nfrom\nIffy\nsites\nwere\ngetting\nmore\nthan\nthe\naverage\nengagement\namong\nthe\n5,000\nmost\npopular\nURLs.\nFigure\n3:\nThe\nshare\nof\nOK\nand\nUnknown\nsites,\nas\nwell\nas\nIffy\nsites.\n-\n16\n-\n\nAs\ndescribed\nin\nthe\nprevious\nsection,\nan\nobserved\ndecline\nin\nthe\nIffy\nQuotient\ncould\nreflect\nthe\nURL\nlists\nbecoming\nstale.\nFigure\n3\nshows\nthat\nthe\ncoverage\nincreased\nsubstantially\nfrom\n2016-2022,\nwith\na\nlarger\nfraction\nof\npopular\nURLs\ncoming\nfrom\nsites\nrated\nby\nNewsGuard\nor\nMedia\nBias/Fact\nCheck.\nNote\nthat\nNewsGuard\nstarted\noperations\nin\n2018.\nIn\nlate\n2021,\nthere\nwas\na\njump\nin\nthe\nfraction\nof\nURLs\nfrom\nunrated\nsites\non\nFacebook;\nthis\ndid\nnot,\nhowever,\nlead\nto\na\ndecline\nin\nFacebook\u2019s\nIffy\nQuotient,\nwhich\nactually\nincreased\nduring\nthis\nperiod.\nThe\nfraction\nof\npopular\nURLs\non\nTwitter\nfrom\nunrated\nsites\non\nTwitter\ngrew\nsubstantially\nfrom\nmid-October\n2022\nto\nthe\nend\nof\nthe\nyear,\nfrom\n33%\nto\nmore\nthan\n50%;\nTwitter\u2019s\nIffy\nQuotient\nalso\nrose\nduring\nthis\nperiod.\nTracking\nChanges\nin\nthe\nIffy\nQuotient\nBeyond\nthe\nbasic\ntrends\nwe\nhave\nidentified\nabove,\nhow\nshould\nreaders\nmake\nuse\nof\nthe\nIffy\nQuotient?\nOne\nway\nis\nto\ntry\nto\ntrack\nthe\nimpact\nof\nexternal\nevents\nand\nof\nplatform\ntechnology\nand\npolicy\nchanges.\nThis\ncan\nbe\ndone\nretrospectively,\nas\nwe\ndid\nfor\nthe\n2016\nelections\nand\nFacebook\nand\nTwitter\u2019s\nsanctions\nagainst\nAlex\nJones.\nTracking\ncan\nalso\nbe\ndone\nprospectively.\nWhen\nTwitter\nor\nFacebook\nannounce\na\ncounter-measure,\nsuch\nas\ndeletion\nof\na\nlarge\nnumber\nof\nfake\naccounts,\njournalists\ncan\nstart\nto\ntrack\nthe\nIffy\nQuotient\nand\nsee\nif\nit\nchanges.\nOr\nyou\ncan\nsign\nup\nfor\nalerts.\nJoin\nour\nemail\nlist\nusing\nthe\nform\nat\nour\nwebsite:\nhttps://csmr.umich.edu/contact/\n.\nWe\nwill\nsend\nout\nan\nalert\nwhen\nthere\nis\na\nsignificant\nchange\nin\nthe\nIffy\nQuotient\nfor\neither\nFacebook\nor\nTwitter\nthat\nis\nsustained\nover\nseveral\ndays,\nas\nwell\nas\nother\ngeneral\nannouncements\nfrom\nthe\nCenter\nfor\nSocial\nMedia\nResponsibility,\nsuch\nas\nthe\nrelease\nof\nadditional\nPlatform\nHealth\nMetrics.\n-\n17\n-\n\nWhat\u2019s\nNext\nfor\nthe\nIffy\nQuotient?\nOur\nwebsite\nthat\ntracks\nthe\nIffy\nQuotient\nwill\nautomatically\nupdate\ndaily.\nWe\nwill\nbe\nmaking\niterative\nimprovements,\nand\nwe\nwelcome\npartnerships\nwith\norganizations\nthat\ncan\nhelp\nus\nvalidate\nor\nimprove\nthe\nmetric.\nIn\nthe\nURL\ncollection\nphase,\nwe\nwould\nwelcome\nother\nsources\nthat\ncould\nbe\ncombined\nwith\nwhat\nwe\nget\nfrom\nNewsWhip.\nIn\nthe\nclassification\nphase,\nwe\nwould\nlike\nto\nreduce\nthe\nlarge\nnumber\nof\nUnknown\nsites.\nWe\nare\npleased\nthat\nthe\nmove\nto\nNewsGuard\nin\nthe\nsecond\nversion\nreduced\nthe\nfraction\nof\nUnknown\nsites\nand\nhope\nthat\nit\nwill\nbe\nreduced\nfurther\nover\ntime.\nWe\nwould\nalso\nlike\nto\nbe\nable\nto\nfilter\nout\npopular\nURLs\nthat\nhave\nnothing\nto\ndo\nwith\nnews,\npolitics,\npublic\naffairs,\nscience,\nor\nhealth.\nThat\nwould\nmake\nthe\nabsolute\nvalue\nof\nthe\nIffy\nQuotient\na\nmore\nmeaningful\nquantity\u2014the\nfraction\nof\npopular\nURLs\nfrom\nIffy\nsites\namong\nthose\nwhere\nreliability\nof\nthe\ninformation\nmatters.\nIt\nwould\nbe\nespecially\nuseful\nto\nhave\nan\nautomated\nclassifier\nthat\noperated\non\nindividual\nURLs\nrather\nthan\nentire\nsites.\nWe\nwould\nbe\nhappy\nto\npartner\nwith\nanyone\nwho\nhas\ntrained\na\nnews\nand\npublic\naffairs\nclassifier.\nWe\nwould\nalso\nlike\nto\nexpand\nto\nother\nplatforms\nbeyond\nTwitter\nand\nFacebook.\nThese\ncould\ninclude\nGoogle\nsearch\nresults\nand\nYouTube\nsearch\nresults\nand\nrecommendations.\nIf\nyou\nhave\ndata\non\nanother\nplatform,\nor\neven\njust\na\nsuggestion\nof\nhow\nwe\nmight\ncollect\nit,\nwe\u2019d\nbe\nhappy\nto\nhear\nfrom\nyou.\nConclusion\nPlatform\nHealth\nMetrics\nare\na\nway\nto\nprovide\nconstructive\naccountability\nto\nthe\nmedia\nplatforms\nat\na\nmeaningful\nscale.\nThe\ncurrent\nenvironment,\nbased\non\nidentifying\nand\nreporting\nindividual\nbad\noutcomes,\nis\na\nless\nconstructive\nform\nof\naccountability\nfor\nthe\nplatforms\nbecause\nthey\ncan\nnever\nshow\nthat\nthey\nare\ndoing\nwell,\nonly\nmaking\nit\nharder\nfor\nwatchdogs\nto\ncatch\nmistakes.\nBy\ncontrast,\nthe\nIffy\nQuotient\ntracks\ntrends\nover\ntime\nrather\nthan\nreporting\non\nindividual\nproblems.\nIt\nprovides\nquantitative\nevidence\nin\nsupport\nof\nthe\nclaim\nthat\nFacebook\nand\nTwitter\ndid\na\npoor\njob\nduring\nthe\n2016\nelection\nseason;\nthey\namplified\nthe\ndistribution\nof\ninformation\nfrom\nIffy\nsites\nat\ndouble\nthe\nrate\nthat\nthey\ndid\nearlier\nthat\nyear.\nBut\nthe\nIffy\nQuotient\ncan\nalso\ntell\na\nmore\npositive\nstory\nof\nprogress\nwhen\nprogress\nis\nmade,\nas\nhappened\nfrom\nlate\n2017\nthrough\nmid-2019,\nespecially\non\nFacebook.\n-\n18\n-\n\nAcknowledgements\nWe\ngratefully\nacknowledge\nthe\nNewsWhip\nservice\nand\nthe\nwork\nof\nNewsGuard\nand\nMedia\nBias/Fact\nCheck\nto\nassess\nnews\nsites\nand\nshare\nthe\nassessments\npublicly.\nThe\nIffy\nQuotient\nis\nan\nadaptation\nof\nAviv\nOvadya\u2019s\nprevious\nwork\ntoward\na\ndashboard\nfor\nmeasuring\nattention\non\nunreliable\nsources,\nwhich\nhe\ndeveloped\nprior\nto\njoining\nthe\nCenter\nfor\nSocial\nMedia\nResponsibility.\nOvadya\u2019s\nwork\nbegan\nin\nlate\n2016\nand\nwas\nalso\nfunded\nthrough\nhis\n2017\nKnight\nNews\nInnovation\nFellowship\nat\nthe\nTow\nCenter\nfor\nDigital\nJournalism\nat\nColumbia\nUniversity.\nThe\nIffy\nQuotient\nwas\nalso\ninspired\nin\npart\nby\nCraig\nSilverman\u2019s\nanalysis\nof\nengagements\nfor\nthe\ntop\nstories\nfrom\nhoax\nand\nmainstream\nnews\nsites.\n21\nVitaliy\nLyapota\nwas\nthe\nprimary\nsoftware\ndeveloper\nfor\nthe\nIffy\nQuotient.\nYuncheng\nShen\ncreated\nimages\nand\nanimations\ndescribing\nthe\nsteps\nin\nthe\ncalculation\nof\nthe\nIffy\nQuotient,\nand\nSummer\nNguyen\nhelped\nto\nupdate\nthem\nfor\nthe\nsecond\nversion.\nFernand\nPajot\nand\nAshwin\nRajadesingan\nconducted\ndata\nanalyses\nthat\ncontributed\nto\nquality\nassurance.\nJames\nPark\ncontributed\nediting\nassistance\nto\nthe\nsecond\nversion\nof\nthis\nreport.\nChenxin\nHan\nredesigned\nthe\nvisual\ndisplay\nof\nthe\nIffy\nQuotient\nfor\nversion\n3\nand\nthe\nnew\nvisuals\non\nthe\nwebsite.\nSiqi\nWu\ncontributed\nto\nthe\nanalytics\naround\ndeduplication\nof\nURLs\nfor\nversion\n3.\nJames\nPark\nhelped\nto\nredesign\nthe\nwebsite\nand\nhelped\nedit\nversion\n3\nof\nthis\nreport.\n21\nhttps://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on \n-facebook\n-\n19\n-\n\nAppendix:\nArchival\nCharts\nFrom\nFirst\nVersion\nWe\ninclude\narchival\ncharts\nfor\nthe\nfirst\nversion\nof\nthe\nIffy\nQuotient,\nusing\nthe\nDecember\n6,\n2018\nversion\nof\nMedia\nBias/Fact\nCheck\nratings,\nthe\nlast\nthat\nwe\nused\non\nour\nlive\nsite.\n-\n20\n-\n\n-\n21\n-\n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Iffy quotient: A platform health metric for misinformation", "author": ["P Resnick", "A Ovadya", "G Gilchrist"], "pub_year": "2018", "venue": "Cent Soc Media Responsib", "abstract": "Social media sites and search engines have become the de facto gatekeepers of public  communication, a role once occupied by publishers and broadcasters. With this new role come"}, "filled": false, "gsrank": 412, "pub_url": "https://csmr.umich.edu/media/docs/UMSI-CSMR-Iffy-Quotient-Whitepaper-v3.pdf", "author_id": ["SftrEEMAAAAJ", "pxbhfqAAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:bx-grNKiV_kJ:scholar.google.com/&output=cite&scirp=411&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D410%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=bx-grNKiV_kJ&ei=ULWsaODNLLTWieoP1pCJ2AY&json=", "num_citations": 32, "citedby_url": "/scholar?cites=17967008264140889967&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:bx-grNKiV_kJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://csmr.umich.edu/media/docs/UMSI-CSMR-Iffy-Quotient-Whitepaper-v3.pdf"}}, {"title": "Controversy score calculation for news articles", "year": "2019", "pdf_data": "Controversy Score Calculation for News Articles\nPaul Kim, Ziyu Fan\u0003, Lance Fernando\u0003, Jacques Sham\u0003, Crystal Sun\u0003, Yixin Sun\u0003,\nBrian Wright\u0003, Xi Yang\u0003, Nicholas Ross, Diane Myung-kyung Woodbridge\nfykim57,zfan18,ljfernando,jjsham,xsun45,ysun84,bawright3,xyang68,ncross,dwoodbridge g@usfca.edu\nData Science Program\nUniversity of San Francisco\nAbstract \u2014From the 2016 election continuing to the present, a\nstrong focus has developed on the US news media landscape.\nFrom issues such as fake news to ideological wars between\nnews sources, helping readers become more discerning news\nconsumers remains a priority for technologists and journalists\nalike. This paper is a summary of our contribution to the\ncontinuing discussion of public empowerment towards making\nmore informed news consumption decisions. In this paper we\nintroduce NewsPhi, a news-feed application designed to provide\ntopic-based contextual information on a changing corpus of\ndaily news. NewsPhi\u2019s main contribution is a controversy score\nof news topics - a score that summarizes how controversial\na certain news topic is according to the larger news media\nenvironment. We \ufb01nd that this approach to building products\nfor news readers is both unique and in line with ongoing bias\nand opinion formation research in the social sciences. Rather\nthan seeking to correct or standardize news opinions, NewsPhi\nprovides important contextual information of opinions on existing\nand new topics while also lightly encouraging further exploration.\nIndex Terms \u2014Natural language processing, Unsupervised\nlearning, Information Science, Information retrieval\nI. I NTRODUCTION\nFollowing the 2016 U.S. presidential election, the meta-\nnarrative surrounding US news media environments became\nincredibly robust. Bad faith actors, domestic and international,\ngained political in\ufb02uence through the employment of news that\nis \u201cintentionally and veri\ufb01ably fake and could mislead readers\u201d\n[1] - a phenomenon otherwise known as \u201cfake news\u201d. It has\nbeen speculated that fake news, in conjunction with the clever\nusage of social media tactics, may have in\ufb02uenced the most\nrecent presidential election - and, perhaps more importantly,\nhow parts of the public interact with the news at large. The\ndiscovery and enlightening of these disinformation tactics has\nled to critical concerns regarding the US news media and\npolitical landscapes; namely, a growing distrust of mainstream\nmedia outlets and an unwillingness to seriously consider or\ncare for factual legitimacy [1]. These issues go hand in hand\nand often augment each other. A distrust for mainstream\nmedia (consisted of for the large part vetted, rigorous news\norganizations) leads to a reliance on alternative news sources;\nalternative news sources claim that their outsider status gives\naccess to certain truths that mainstream media sources will not\ndisclose out of either self-interest or ideologically conformist\nbehavior.Our interest in this crucial point in news history is not to\naddress fake news itself, though fake news is an important\nstarting point for understanding how political polarization\nlooks in 2019. We are concerned with the persistent ideological\nsplit that seemingly strengthened after the election, admittedly\npartially as a result of fake news and fake news-related\nconsequences.\nVarious studies have presented that fake news do have\na strong polarizing effect. Guess, Nyhan, and Rei\ufb02er found\nthat Trump supporters are \u201cdisproportionately more likely to\nconsume pro-Trump fake news and less likely to consume pro-\nClinton fake news relative to Clinton supporters, supporting a\nselective exposure account\u201d [2]. The same authors in 2018\nfound that, similar to in 2016, fake news consumption was\nconcentrated among the top 10% of Americans that consumed\nthe most conservative media. They also found that, overall,\nfake news readership decreased about 75% (About 1 in 4\nAmericans read a fake news article in fall 2016 compared\nto about 7% in fall 2018) [3]. Further, these authors found\nthat though a majority of the public were able to distinguish\nbetween authentic and fake news stories, a signi\ufb01cant mi-\nnority believed fake/hyperpartisan news were accurate. This\npercentage was higher when the partisanship of the news\nmatched that of the consumer (17 - 48% vs. 10 - 22% for\nwhen the partisanship did not match), hearkening the previous\nconcerns of extreme partisanship - but only for a minority\npopulation. Fake news indeed is the modern beginning point\nof how we have come to understand what now appears to be\nan unbridgeable gap between ideological groups; however, it\nremains to be proven that these extreme ideological groups are\nvery large, diverse, or even equal in size. One news-focused\napproach has been to attempt to bridge this gap by exposing\npeople to differing opinions from different sides of the left-\nright spectrum. We took a couple of issues with this approach.\nOur \ufb01rst issue concerns bias. Bias is not so easy to over-\ncome through this sort of meek exposure. Guess, Nyhan, and\nRei\ufb02er\u2019s research indicates that partisans are more likely to\nbelieve in partisan conspiracy theories and that fake news\nconsumption was mostly limited to a small outlier group [3].\nCon\ufb01rmation bias is a strong (and often rational, according\nto Susan and Jack Gorman [4]) instinct to overcome. Oswald\nand Grosjean acknowledge the effects of con\ufb01rmation bias\nwhen referring to af\ufb01rmation of \u201cmotivationally supported\u201d\nhypotheses [5]. Our approach then is not to combat fake news\nby providing a quantitative score on how credible a news\u0003These authors contributed equally.\nsource is. Consumer applications do not appear to show much\npromise in swaying those heavily set in opinions, rational or\nnot. There exist attempts to judge how reliable a news source\nis - our concern is not to sway people from their biases\nregarding news reliability or truthfulness, given the existing\nsocial science research. Fake news are highly unique and are\nconstructed to bene\ufb01t from existing social media infrastructure\n[6], thusly endemic to the information sharing ecosystem logic\nitself. It is dif\ufb01cult to introduce a new paradigm of news\nconsumption or to disrupt those existing, and to combat fake\nnews effectively, it is likely more important for social media\nsites to continue ongoing processes to mitigate disinformation\n(efforts which have taken and are currently taking place in bot\ndetection, content moderation, and more - [7]). Thus, we do\nnot try to prescribe news objectivity. Rather, we are interested\nin informing readers how the news media feels in aggregate\non speci\ufb01c topics. We are interested in providing topic-based\ncontext, especially for news topics that are potentially new to\nconsumers. This mission is born out of a twofold reasoning:\n\ufb01rst, a genuine interest and passion for news education, and\nsecond, further research on political opinion formation and\nchanging.\nOur approach to the current political landscape is informed\nby Carsey and Layman\u2019s 2006 study on changing party af\ufb01li-\nations [8]. There are two crucial elements to whether Carsey\nand Layman would consider an individual to possibly change\nparties: that individual\u2019s knowledge of party difference and\nissue-speci\ufb01c granularity. According to Carsey and Layman\u2019s\nwork, individuals that \ufb01nd certain issues very important are\nmore likely to change party identi\ufb01cation according to each\nparty\u2019s stance on those issues. Providing topic-based context\naggregated over a large number of publications of different\npolitical stances is, then, key. We are able to effectively display\nparty difference through the combination of reader knowl-\nedge/perception of a publication and our \u201ctopic controversy\nscore\u201d (to be discussed soon). If we consider topics as issues\n(as there were a signi\ufb01cant number of topics that could be\nconsidered policy issues in our modeling), we are able to\nprovide issue-level granularity to understanding of politics.\nOur second issue with the exposure approach we consider\nequally important but less immediately necessary is the com-\nplexity of assigning political bias. The allocation of news\nsources into \u201cliberal\u201d and \u201cconservative\u201d or \u201cleft\u201d and \u201cright\u201d\nbuckets does not provide distinction between vastly differing\npolitical stances within these general buckets. For example:\nthe Left is a broad political group that contains liberal inter-\nnationalism, anarchism, globalism, and other incongruous/less\ncongruous ideologies. There is a commonality in research\nand applications we reviewed that emphasized or reinforced\na binary understanding of political positioning. Though we\nacknowledge that this is a useful and necessary delineation,\nwe wanted to introduce a further level of nuance to news\ntopics. Our goal is to help readers understand that a certain\npublication may feel a certain way about a certain topic that\ngoes against the general opinion of its relative position on the\nleft-right spectrum, allowing for a multidimensional and richerunderstanding of the various pieces of the news media. As we\nare developing a customer product, there is an opportunity\navailable for us to paradigmatically in\ufb02uence how the public\nunderstands politics, political structure, and the news media.\nGuided by these dual goals, we created a web application\ncalled NewsPhi. NewsPhi is an interactive news-feed designed\nto help consumers better understand the overall context of the\nnews that they are reading. The main feature of NewsPhi is\nthe topic controversy score. Unlike scoring bias or veracity\nof news sites, our goal is to give an aggregated score of\nthe level of agreement/disagreement (thus, controversy) on\na given number of news topics per day. The driving idea\nis a summation of the above. It is useful and insightful for\nthe public to understand the full spectrum of opinion on\nnews topics, especially as new topics crop up. If we consider\ntopics as policies, there is an opportunity for a reduction in\npartisanship among non-outlier groups of news consumers.\nFinally, if we can successfully delineate topics, we can help\nthe public gain a more holistic understanding of news publi-\ncations. This approach requires a multitude of moving parts:\nnormal extract, transform and load (ETL) processes, topic\nmodelling, sentiment analysis, and the setting up of servers\nand user interface for web hosting. Explicitly, our product is\nan interactive news-feed that allows for \ufb01ltering by topics. It\ngives topic-level aggregate analysis - the previously mentioned\ncontroversy score - as well as a short article-level analysis -\nthe sentiment score of that speci\ufb01c article in comparison to\nthe whole. Figure 1 is what the front page of NewsPhi looks\nlike.\nII. R ELATED WORK\nThere are a number of existing applications that support ed-\nucational efforts surrounding modern news consumption. We\nacknowledge these existing efforts in the following similarities\nand dissimilarities:\nA. News credibility and bias\nMany technological efforts in the news space following the\ndiscovery of fake news were made towards identifying and\nquantifying objectivity. OwlFactor assigns a credibility score\nbased on four categories: \u201cSite quality\u201d, \u201cAuthor expertise\u201d,\n\u201cReferences quality\u201d, and \u201cTone\u201d [9]. NewsPhi operates sim-\nilarly to OwlFactor in that it relies on machine learning to\nassign attributes on an article basis. However, combating fake\nnews, again, is not explicitly the aim of NewsPhi, nor is it\nin NewsPhi\u2019s interests to quantitatively decide which sites are\nconsidered to be of a certain quality. Additionally, OwlFactor\nuses categorical methods to assign biases to news sources,\nrelying initially on binary bias ratings from Allsides [10] and\nMedia Bias Fact Check [11], then moving towards a machine\nlearning approach to identifying \u201cslant\u201d, guided by a paper by\nGentzkow and Shapiro [12]. Allsides employs a crowd-sourced\naggregation of blind bias ratings in addition to third party re-\nsearch (if available) in order to assign one of \ufb01ve bias ratings:\nLeft, Lean Left, Center, Lean Right, and Right. Media Bias\nFact Check uses a volunteer team of \ufb01ve to qualitatively assess\nFig. 1: An example of the NewsPhi interface. At the top is the drop down menu, which \ufb01lters the articles based on broader\ntopics. Individual articles can be seen on the left. Upon click, the right sidebar populates with the article hyperlink, the topic,\nand the controversy score of the topic. The donut chart indicates how \u201ccontroversial\u201d this topic is. Below the donut chart is\nthe sentiment score of that speci\ufb01c article, along with a visual of where the speci\ufb01c article sentiment lies on the spectrum of\ntopic-wise article sentiment. This spectrum of topic-wise article sentiment displays how, in general, the aggregate of our news\nsources feels about the topic. It should be noted that the controversy score for this particular topic, \u201cpolitical protests\u201d, has\nbeen updated.\na source\u2019s bias into the same categories (with the addition\nof Extreme Left and Extreme Right). OwlFactor is currently\ntransitioning into a machine learning approach of assigning\nbias based off of natural language processing methods outlined\nby Gentzkow and Shapiro [12]. Gentzkow and Shapiro identify\n\u201cmedia slant\u201d by comparing phrase frequencies in newspapers\nto phrase frequencies in the 2005 Congressional Records.\nAllSides itself also provides a news-feed in addition to\ntheir bias methodology [13]. The same categories described\nabove are employed in this feed, dividing news articles by\ntheir assigned bias categories. Each article has a display that\nshows where on this left-right spectrum its home publication\nlies. AllSides also lists topics for news articles, to be explored\nfurther in the following subsection.\nA couple reasons our approach avoided categorizing news\nsources into biases were the dif\ufb01culty and subjectivity of\nidentifying and labeling these biases as well as the suspect\nassumption that consumers will be swayed by exposure to\nopposing viewpoints in this unstructured approach. Regardingthe former concern: As Andrew Heywood argues, the left-right\nspectrum is restrictive as it does not allow for understanding\nof division within the left and right, respectively [14]. For\nexample, a publication could be considered \ufb01scally left but\nsocially right. This publication would have left views for\ncertain topics but right views for others. This nuance is\nhard to parse when using the previously mentioned political\ncategories. Our goal by not presenting a bias assessment\nis to complicate the common understanding of bias and its\nrelationship to institution and thusly introduce a more holistic\napproach to judging news media. As for the latter concern of\nthe ef\ufb01cacy of exposure: as discussed in the introduction, we\nbelieve that a topic-based (issue-speci\ufb01c) approach, rather than\nan ideologically-focused approach will be most successful in\npossibly reducing partisanship. Similar to OwlFactor and All-\nsides, NewsPhi is concerned with how opinions and ideologies\nare formed; however, our approach attempts to allow for more\nnuance while being less prescriptive with our user base.\nB. Topic Modelling\nA central feature to NewsPhi is its topic modelling. Owl-\nFactor and Allsides similarly create topics out of their news\narticles, sharing a common desire for consumers to explore\nnews based on groupings other than just bias. OwlFactor relies\non machine learning to generate the exact topics that are\nshown to consumers. One drawback, as expected with such\na dif\ufb01cult task as constant topic modelling with ever-changing\ncorpi and topics, is that an automated approach gives, in some\ncases, nonsensical or vague results. For example: a topic on\nAugust 1, 2019 on OwlFactor was \u201cForeign Minister\u201d. Though\ncertainly more useful than the lack of a topic, this is not\nfunctionally useful (which foreign minister, what happened,\netc.). This said: in general, the topics on OwlFactor change\ndynamically as new articles are pulled and they are fairly\ngranular and mostly make sense. However, as we considered\nconsistent and sensical granularity for topics crucial for the\nNewsPhi product, we relied on domain expertise to generate\ntopics instead. This has its advantages and disadvantages later\ndetailed in the evaluation section. Regardless, NewsPhi adds\nto this topic-allocated news-feed by providing aggregated and\nspeci\ufb01c analysis per topic and article.\nAllSides introduces a feature called the Headline Roundup,\nwhere it pulls 1-3 common headlines throughout the day and\npresents a summary of the topic. It further provides reporting\ntrends among the left, the center, and the right for these topics.\nThis kind of topic level analysis is akin to the work that\nNewsPhi accomplishes. Besides the Headline Roundup topics,\nthere exist other discrete topics that, if clicked upon, \ufb01lter news\narticles accordingly. The topics on Allsides indeed reach a\nlevel of granularity that matches those of NewsPhi\u2019s. However,\nAllsides does not provide topic-level analysis beyond the few\ndaily Headline Roundup topics and a few other selected topics.\nNewsPhi strikes a healthy medium between OwlFactor and\nAllsides, assigning topics by domain experts and automating\nthe aggregated contextual analysis. Further, NewsPhi places\neach individual article within the broader topic-level context,\nas opposed to Allsides that places articles within ideological\ncontext. Thus, through NewsPhi, one can develop speci\ufb01c\nunderstanding of all topics for each speci\ufb01c publication that we\nprovide, as well as understanding the distribution of opinions\non this topic across the broader news media environment.\nIII. S YSTEM OVERVIEW\nA. System Work\ufb02ow\nThe process of creating NewsPhi begins, broadly, with\ncreating a news-feed. The \ufb01rst step is data collection. As\nNewsPhi is designed to be a consumer facing app, news need\nto cycle in on a consistent basis. We built a script to pull news\nfrom a list of 26 unique sources listed in Table I from various\npoints on the economic-political axes using the webhose.io\nAPI [15]. Considering the driving motivation of this paper as\nexploring the American political landscape, we chose news\nsites that mostly wrote about politics and current events. The\ndata pulled using webhose.io contains \ufb01elds such as: headline,TABLE I: Sources by the count of articles\nSource Name Count of Articles\nForbes 5241\nCNBC 5158\nFox News 3580\nWall Street Journal 3048\nBusiness Insider 2758\nNPR 2346\nCNN 2275\nCNN International 2082\nNBC 1978\nDaily Wire 1574\nPolitico 1218\nAl Jazeera 1111\nNational Review 910\nThe Verge 891\nThe Daily Beast 829\nBBC 684\nNewsDay 471\nThe Economist 352\nSalon 269\nBloomberg 267\nMSNBC 210\nPBS 207\nTMZ 200\nForeign Policy 197\nProPublica 41\nHuf\ufb01ngton Post 1\nbyline, publication, publication date/time, URL, and the entire\narticle itself. The data were roughly 43,000 articles pulled from\na list of 26 sources over the 30-day period immediately prior to\nMay 1, 2019. After de-duplication and data quality processes,\nour total corpus amounted to 37,898 articles. These articles\nranged from reports to pro\ufb01les to reviews to opinion pieces\n(and more).\nThis data were stored between Amazon Web Service (AWS)\nRedshift[16] and S3 [17] - the articles themselves were stored\non S3 while the metadata were stored on Redshift. Our\nweb server was built on Flask and our user interface (UI)\nwas built using Vue.js. We performed topic modeling using\na Latent Dirichlet Allocation algorithm with the headline\nand the \ufb01rst paragraph (known as the lede) as our inputs.\nAs this is an unsupervised learning problem, there was no\nground truth to which we could compare our clustering results.\nTherefore, evaluation steps were mostly heuristic. After the\ntopic modelling was complete, we performed the controversy\nscore analysis using an aggregation of sentiment per topic. On\neach article is displayed the news topic, its controversy score,\nthe sentiment score of the speci\ufb01c article currently selected,\nand a visualization of the spectrum of sentiments expressed in\nthe aggregate of our sources on that topic.\nB. Algorithms\n1) Latent Dirichlet Allocation: The model we employed is\na Latent Dirichlet Allocation model (LDA). LDA, developed\nby Blei, Ng, and Jordan in 2002, can be described as a\n\u201cgenerative probabilistic model of a corpus\u201d [18]. LDA can\nbe understood as a probabilistic approach to processing large\nnumbers of documents in such a way that relationships can be\ndrawn in-between them. LDA is, then, suitable for the task of\ntopic modeling.\nWithin the text modeling context, we can take what is\nknown as a \u201cbag of words\u201d approach - where the order of\nwords in a document is considered to be unimportant - as well\nas an analogous \u201cbag of documents\u201d approach. Blei et al. refer\nto this as exchangeability, and their approach is built on this\nexchangeability assumption that leads to mixture distributions\nfor words/word units. Topics are chosen from a multinomial\ndistribution using probability vectors drawn from a Dirichlet\ndistribution as the parameter. This is slightly intuitive as topics\nare discrete and the Dirichlet distribution is conjugate to the\nmultinomial (along with some other advantages to using a\nDirichlet distribution). That is to say, in Bayesian terms, our\nprior distribution is the Dirichlet and our posterior distribution\nis the multinomial.\nThe \ufb01rst step in understanding LDA is to contextualize the\nDirichlet and multinomial distributions within topic modeling.\nThe Dirichlet distribution is the multivariate version of the beta\ndistribution. Dirichlet distributions have one parameter, \u000b, that\nis a vector comprised of positive real numbers \u000bi.\u000bcan be\nunderstood as a constant, \u000b0, multiplied by what is called a\nbase measure,h\u000b0\nii.\u000b0is the sum of \u000bi, andh\u000b0\niican be\nexpressed as the means for each topic i, and can thusly be\nrepresented as\u000bi\n\u000b0. The formulas for the mean and variance of\nthe Dirichlet distribution are as follows:\nMean =\u000bi\n\u000b0=\u000b0\ni (1)\nVariance =\u000b0\ni(1\u0000\u000b0\ni)\n\u000b0+ 1(2)\nAs\u000b0gets larger, the variance decreases and the draws\nfrom the Dirichlet distribution will be close to \u000b0\ni. As\u000b0\ngets smaller, however, the variance increases, resulting in\nextreme distributions. The multinomial distribution uses the\nprobability vector outputted by the Dirichlet distribution to\ndraw outcomes. If the probability vector is sparse, then the\nnumber of possible outcomes becomes small.\nUsing the above knowledge, one can devise an algorithmic\nprocess for writing a corpus of documents. Consider the\nfollowing hypothetical generative process for a corpus of D\ndocuments each of length N, given a user-inputted Kas\nnumber of topics:\nFirst, we select the topics, \u0012d, for each document d2D:\n\u0012d\u0018Dir(\u000b)where\u000bis sparse (so that each document\nis only possibly about a small number of topics and we are\nable to focus on a small number of highly relevant topics and\nwords).\nNext, we create the topics themselves, \u001ek, fork2K:\u001ek\u0018\nDir(\f)where\fis sparse (so that only relevant words are\nconsidered).\nNext, we assign the topic, zd;n, that thenth word in each\ndocument belongs to: zd;n\u0018Multinomial (\u0012)\nFinally, we generate the words, Wd;n, themselves: Wd;n\u0018\nMultinomial (\u001ezd;n).LDA assumes this simpli\ufb01ed corpus generative model, and\nthough it is a naive understanding of how articles are written,\nthis structure proves useful if reverse engineered to provide the\ntopics themselves [19]. The task at hand is then to compute the\nposterior distribution of our hidden variables. As expected, this\nis intractable and requires approximation. Our implementation\nof LDA uses Gibbs sampling [20] for this inference. Gibbs\nsampling is a speci\ufb01c implementation of MCMC methods\n[21], which are high volume sampling processes used in order\nto approximate these intractable posterior distributions. Gibbs\nsampling approximates these distributions by sampling and\nthen updating probabilities according to which of the possible\noutcomes were drawn. For example: when assigning words\nto a topics, we start with equal probabilities of assignment\nfor all words to all topics. After this initial allocation, we pass\nthrough and sample each topic for each word again, according\nto the underlying distribution. It is helpful to have the sparse\nparameter for the prior distribution so that we have only a few\npossible words per topic, and analogously a few possible topics\nper document. Through this sampling process, we eventually\nreach a state of convergence and the topics become stable.\nOur approach to topic modelling used MALLET [20] with\na combination of the headline and the lede as our input data.\nMALLET, short for MAchine Learning for LanguagE Toolkit,\nis a package that can be used in a variety of Natural Language\nProcessing (NLP) contexts, including topic modelling using\nLDA with Gibbs Sampling. In order to use MALLET for topic\nmodelling, we passed in a customized list of what is commonly\nreferred to as \u201cstop words\u201d particular to our news data. In\ntext processing, \u201cstop words\u201d are words that one chooses not\nto consider due to their likely unimportance. Common stop\nwords include generic direct/indirect articles, prepositions, and\npronouns such as \u201dthe\u201d, \u201dwhere\u201d, etc. A couple of modeling\niterations proved useful in determining words to add to our\ncustomized list of stop words in order to effectively topic\nmodel for the news. We found it useful to add all common\nwords related to time (days of the week, months of the year,\netc.). We also found it useful to add the names of all the\npublications we included in our source list, as webhose.io\noften included these names in the article data. Additionally,\nwe added bland adjectives and other generic words such as\n\u2019good\u2019, \u2019man\u2019, and \u2019woman\u2019. These words, though important\nfor other NLP tasks such as predictive text modelling, resulted\nin relatively useless keywords in our model. A crucial decision\nwas to not add proper nouns (capitalized nouns that refer to\nspeci\ufb01c nouns). Though this made our data at times less clean,\nespecially considering how webhose.io sends data (inclusion\nof source, author, etc. in some article data), proper nouns\nwere important for achieving the level of granularity desired.\nFor example, in many of our modeling iterations, the word\n\u201dBrexit\u201d was a keyword. If not for this word itself, the Brexit\ntopic would likely be both weaker and harder to interpret.\nC. Implementation of LDA using MALLET\nThe main hyperparameters of our model include the number\nof topics to return ( Kin the above generative model) and\nwhichn-gram to consider as word units. n-grams can be\nunderstood as linguistic units; for example, a unigram is a\nsingular word, a bigram is a pair of consecutive words, a\ntrigram is a trio of consecutive words, so on and so forth. An\nexample of a useful bigram could be something like \u201cclimate\nchange\u201d.\nThe introduction of n-grams higher than unigrams compli-\ncates the previous \u201cbag-of-words\u201d assumption; however, LDA\n(and MALLET speci\ufb01cally) allows for these larger linguistic\nunits. For NewsPhi, an iterative process resulted in a Kof 100,\nallowing for n-grams up to n= 2(considering both unigrams\nand bigrams as word units).\nAs standard with LDA, what is learned from our data is not\nthe topic itself explicitly but rather a list of keywords with\ncorresponding probabilities as possible topics. The following\nis an example of training data that was given as an input to\nour model:\n\u201cDemocrats excoriate Attorney General Bill Barr\u2019s han-\ndling of Mueller report - CNNPolitics (CNN) In the hours\nafter receiving the long-awaited report from special counsel\nRobert Mueller , some Democrats on Capitol Hill called not\nto impeach the President but for the removal of Attorney\nGeneral William Barr. \u201d [22]\nThis short text contains the headline and the lede for this\narticle. Both parts contain important information about the\nmain actors/subjects. Both parts contain important and distinct\nproper nouns. The amount of data to include per article was\nan exercise in balance- too little and topics would likely be\ntoo vague, too much and topics would likely be weaker (and\ntraining time would increase). Judging off of the contents of\njust the headline and the lede, effective topic modeling can\ntake place from a heuristic level.\nA good possible topic for the above article might be\n\u201cMueller Report\u201d or \u201cBill Barr\u201d. After topic modelling took\nplace with our training corpus, we had the following as a\nunique topic:\n(62;0:045\u0003\\Trump \" + 0:031\u0003\\report \" + 0:021\u0003\n\\Muellerreport \" + 0:020\u0003\\Mueller \" + 0:018\u0003\n\\AttorneyGeneral \" + 0:017\u0003\\specialcounsel \" +\n0:016\u0003\\RobertMueller \" + 0:016\u0003\\Barr \" + 0:014\u0003\n\\WilliamBarr \" + 0:013\u0003\\release \");\nWhere 62 indicates the cluster number and the words\nare the keywords off of which one could infer a topic. Each\nof these keywords have a corresponding probability that that\nword will be used in an article that is in that cluster. We could\nreasonably deduce that articles within cluster 62 were about\nthe Mueller report, and within these articles, we should see\nmentions of Bill Barr, Congress, Trump, an investigation of\nsome sort, etc. The article above did indeed fall into cluster\n62, which meant that our topic modelling was successful for\nat least this example.\nThe process of assigning topics to clusters remained\nmanual. This process was also a methodological choice. Aspreviously discussed, procuring sensical and speci\ufb01c topics\nfrom data purely using machine learning methods is dif\ufb01cult.\nManual work is seen as a distinct advantage for NewsPhi. A\nhuman domain expert will be able to conceptualize a topic\nfrom a group of related words that, put together in any given\npermutation, may not make a coherent or fully encompassing\ntopic. For example:\n(61;0:079\u0003\\Disney \" + 0:051\u0003\\StarWars \" +\n0:015\u0003\\film\" + 0:014\u0003\\series \" + 0:010\u0003\n\\streaming service \" + 0:010\u0003\\movie \" + 0:009\u0003\n\\trailer \" + 0:008\u0003\\Iger\" + 0:008\u0003\\Vogue \" + 0:008\u0003\n\\original \")\nIn cluster 61, we have a multitude of articles having to\ndo something with Disney. Heuristically, the topic seems\nto match; all but one of the terms are Disney and media\nrelated. A possible topic is indeed Disney - however, a human\nexpert was able to pull more from this list of keywords\nwith the knowledge that the Disney released news on April\n11 regarding the pushed-back launch of Disney+, its new\nstreaming service. In this sense, a newsfeed that tries to\nproduce topics bene\ufb01ts from a human labeler to create more\nspeci\ufb01c, time-relevant topics. The obvious tradeoff is the\ndecrease in automation ability, but this approach provides\nmore precise labels.\nD. Controversy Score\nThe controversy score methodology is rather simple. After\nthe articles are grouped into their respective topics, we call the\nvaderSentiment Python package [23] to give a sentiment score\nof all of the articles within each topic. Sentiment scores are the\nresult of sentiment analysis, which is an area of text analysis\nthat is concerned with calculating how positive or negative the\nsentiment of a text is. The resulting score is usually on a scale\nof -1 to 1, with -1 indicating an extreme negative sentiment and\n1 indicating an extreme positive sentiment. After the articles\nare grouped, we take the standard deviation of the sentiment\nscore of each topic and then normalize the results. The formula\nfor this is as follows:\ns=rX(X\u0000M)2\nn\u00001(3)\nwhereXis the sentiment score for each article in the topic, M\nis the mean sentiment score of the topic, and nis the number\nof articles in the topic.\nThe normalization process is a min-max scaling, which\ntakes the resulting list of standard deviations and scales them\nfrom 0 to 1. This formula is as follows:\nXsc=X\u0000Xmin\nXmax\u0000Xmin(4)\nwhereXscis the sentiment score scaled, X is the sentiment\nscore for each topic, and Xmax andXmin are the maximum\nand minimum sentiment scores, respectively.\nStandard deviation measures how far data points generally\nfall from the mean. The intuition is that the more controversial\nTABLE II: The number of notable topics correctly modeled\nand the percentage of articles in less useful topics, per K\nKNumber of notable topics\ncorrectly modeled (max 28)Percentage of articles\nin vague/non-newsworthy topics (%)\n60 15 9.70\n70 16 9.29\n80 22 9.10\n90 23 8.30\n100 24 6.89\na topic is, the higher the standard deviation of sentiment for\nthat topic should be. A higher standard deviation in our case\nwould indicate many articles that have very different opinions\nabout the topic. Thus, we used this standard deviation of\nsentiment as our controversy score. If we see a corpus of\narticles with generally uniformly neutral, positive, or negative\nfeelings towards a topic, we expect a lower controversy score.\nOn the other hand, if we see a corpus of articles with very\ndifferent, highly opinionated feelings towards a topic, we\nexpect a higher controversy score.\nIV. A NALYSIS AND EVALUATION\nThe main form of evaluation we employed was heuristic on\ntwo levels: How speci\ufb01c and useful is the topic modelling so\nthat the topic modeller can make meaningful, coherent topics;\nand, how sensical were the \ufb01nal controversy rankings?\nThe former was a process through which we modi\ufb01ed the\nlist of stop words, the n-grams to consider, and the Knumber\nof topics to model. These parameters and hyperparameters\nwere systematically changed until the list of keywords was\nsensible enough. Eventually, a stable list of stop words was\nreached. In addition, we found that considering up to bigrams\nsuf\ufb01ced, as trigrams tended to introduce too much nonsensical\ninformation. Once we settled on the list of stop words and\nwhichn-gram to consider, we began iterating through K\nvalues to consider. This evaluation process was a combination\nof qualitative and quantitative methods.\nFirst, we determined a list of notable and/or ongoing events\nthat were easy to glean from our article data. This was a list\nof 28 topics that included events such as Julian Assange\u2019s\nexpulsion from Ethiopian asylum on April 11, the 2020 US\npresidential elections, the Notre Dame cathedral \ufb01re, and the\nGame of Thrones \ufb01nal season, among other important and\ndistinct cultural and political events. For each Knumber of\ntopics considered, we tallied how many of these 28 topics\ncould be formed out of the results of the model.\nSecond, as we labeled the results, we kept track of the\nclusters that were heuristically too vague or not newsworthy\nenough to form useful topics. We then calculated the percent-\nage of articles that were in these clusters. Through this iterative\nprocess, we hoped to learn which Kvalue would result in the\nlowest percentage of articles that are assigned such topics.\nAs this evaluation process requires a fair amount of manual\nwork, we iterated through 5 numbers of topics: 60 through\n100 by increments of 10. The results of this iteration can be\nseen in Table II. We decided to model 100 topics through this\nevaluation process.TABLE III: The ten most controversial topics in April 2019\nTopic Controversy Score\nBorder crisis 0.900\nGame of Thrones 0.897\nRacial justice in America 0.888\nUS immigration 0.860\nNotre Dame \ufb01re 0.859\nUS-Russia relations 0.857\nPolitics in the Middle East 0.857\nRecent Supreme Court rulings 0.845\nClimate change 0.844\nUS Navy in the Paci\ufb01c 0.843\nTABLE IV: The ten least controversial topics in April 2019\nTopic Controversy Score\nArti\ufb01cial intelligence 0.443\nAmazon 0.416\nSkincare 0.415\nTravel 0.378\nFashion 0.350\nSocial media marketing and branding 0.348\nCredit card points 0.272\nSmart homes 0.245\nInvestment funds 0.201\nConsumer reports 0.186\nOnce modeled, we calculated the controversy scores for\neach topic and checked that each topic seemed to be in the\ncorrect general area. The ten most and least controversial\ntopics in April 2019, according to our methodology, are in\nTable III and Table IV respectively.\nThe main surprise from these lists is the Notre Dame\n\ufb01re as the \ufb01fth most controversial topic, as there is nothing\novertly controversial or political about the \ufb01re. However,\nafter reviewing several articles in the cluster, we found that\nthree historically black churches in Louisiana were burned\ndown a couple days prior due to the result of a racist hate\ncrime. After the Notre Dame \ufb01re took place, these churches\ngained a fair amount of publicity due to well organized social\nmedia campaigns that raised funding for their rebuilding. The\nconnection between these three churches and the Notre Dame\nis that the organizers believed that the Notre Dame would\neasily receive suf\ufb01cient funding for reconstruction but these\nchurches would not be able to similarly do so [22]. The Notre\nDame \ufb01re thusly became a launching point to raise awareness\nfor these churches. As a result, a signi\ufb01cant number of articles\nwith a wider range of sentiment were written about the Notre\nDame \ufb01re and the Louisiana churches hence resulting in a\nhigher controversy score.\nOverall, the list of topics were generally granular and\ninformative. For the utilized data, we had 8 similar topics that\nwere merged together for a resulting list of 92 distinct topics\nacross the cultural, political, and economic \ufb01elds. The order\nof controversy of these topics generally made sense. Almost\nall of the political topics were in the upper half, while the\nlower half was comprised of more of the lifestyle, sports, and\nbusiness topics.\nV. C ONCLUSION\nOur motivation behind NewsPhi was to create an app\nthat educates people in a non-prescriptive way, following the\nresearch of experts in political science and psychology. This\nfoundation we formed in the social sciences was important\nto us, as conjecturing about the news space could lead to\nsimpli\ufb01ed or misinformed assumptions. A prime example of\nthe assumptions we wanted to avoid is the over-emphasis of\nthe effects of fake news. Due to the works of Grinberg et\nal. [24] and Guess et al.[25], we came to understand that\nfake news do not pose as serious a problem as they may\nat \ufb01rst seem. Building on top of this, we used research\nfrom political scientists such as Carsey and Layman [8] to\ndetermine how party loyalty is formed. We also used research\non con\ufb01rmation bias and extreme news consumption to form\na hypothesis on how people react to news that is contrary\nto what they believe in. Based on this research, we presented\nan implementation of a topic-organized, less-ideologically pre-\nscriptive news-feed that attempts to de-emphasize conventional\nunderstandings of political bias and ideology formation while\nserving an educational purpose and possibly partially bridging\nthe ideological gap. We used a combination of unsupervised\nlearning including Latent Dirichlet Allocation (LDA), a home-\ngrown controversy score formula, and human labeling to\ncreate a consumer-facing product with a complete web-server,\ndatabase, and UI. The results are promising and contribute to\nthe existing contextual newsfeed efforts. To sum, we believe\nthat NewsPhi is just the beginning of more work that should\nbe done in exploring less-prescriptive yet still analytical news-\nfeeds.\nNewsPhi has multiple directions in which it could move\nfurther. There may exist other indicators of approval or disap-\nproval of a topic other than just sentiment. Across the topic-\nlevel, sentiment certainly is useful. Regardless of whether\nan article uses strong language in such a manner that either\nagrees or disagrees with its actual stance, that language likely\neither describes that article\u2019s stance or that of other writers\nor interviewed/quoted subjects. In aggregate, this sentiment\nscore should be at least a medium indicator of the actual\noverall opinion on a topic. However, further work should\nexplore additional indicators of opinion. Additionally, though\ntopic assignment is greatly aided by our topic modelling\napproach, the labeling process is still manual. Allsides appears\nto prevent this issue by \ufb01tting incoming articles into existing\ncategories and focusing on a small number of articles daily\nto break out into more speci\ufb01c topics (the Headline Roundup\nfeature). OwlFactor appears to use a different NLP approach\nthat at times serves less interpretable topics for incoming\narticles. Though NewsPhi brings a mixture of the two, further\nwork should focus on automating topic generation while still\nkeeping the same level of granularity accomplished by hand\nlabeling. Lastly, we believe further breakdown of articles by\nauthor would be useful. The challenge of tracking authors can\nbe seen in OwlFactor\u2019s implementation. Author expertise is\none of four elements of a news story\u2019s credibility score onOwlFactor; however, oftentimes the author is missing or does\nnot have a strong history. This problem does not exist solely\nin OwlFactor\u2019s implementation, as the problem of author-level\ncontextuality seems broadly complex. Authors may in fact\nbe guest writers, as is the case with many opinion writers.\nAuthors also may share names. If implemented correctly,\nauthor reputation could be useful in forming a more holistic\nview of the news media in general, past the publication-level\nunderstanding that currently persists.\nREFERENCES\n[1] H. Allcott and M. Gentzkow, \u201cSocial media and fake news in the 2016\nelection,\u201d Journal of economic perspectives , vol. 31, no. 2, pp. 211\u201336,\n2017.\n[2] A. Guess, B. Nyhan, and J. Rei\ufb02er, \u201cSelective exposure to misinforma-\ntion: Evidence from the consumption of fake news during the 2016 us\npresidential campaign,\u201d European Research Council , vol. 9, 2018.\n[3] A. Guess, B. Lyons, J. M. Montgomery, B. Nyhan, and J. Rei\ufb02er, \u201cFake\nnews, facebook ads, and misperceptions: Assessing information quality\nin the 2018 u.s. midterm election campaign,\u201d Public Report , 2018.\n[4] S. E. Gorman and J. M. Gorman, Denying to the grave: Why we ignore\nthe facts that will save us . Oxford University Press, 2016.\n[5] M. E. Oswald and S. Grosjean, R. Pohl, Ed. Pyschology Press, 2004.\n[6] S. V osoughi, D. Roy, and S. Aral, \u201cThe spread of true and false news\nonline,\u201d Science , vol. 359, no. 6380, pp. 1146\u20131151, 2018.\n[7] A. Mosseri, \u201cWorking to stop misinformation and false news,\u201d News-\nroom. fb. com , 2017.\n[8] T. M. Carsey and G. C. Layman, \u201cChanging sides or changing minds?\nparty identi\ufb01cation and policy preferences in the american electorate,\u201d\nAmerican Journal of Political Science , vol. 50, no. 2, pp. 464\u2013477, 2006.\n[9] CivikOwl Inc. (2019) Owlfactor : News on your terms. [Online].\nAvailable: https://www.owlfactor.com/news\n[10] Allsides.com. (2019) How allsides rates media bias: Our methods.\n[Online]. Available: https://www.allsides.com/media-bias/media-bias-\nrating-methods\n[11] Media Bias Fact Check, LLC. Methodology - media bias/fact check.\n[Online]. Available: https://mediabiasfactcheck.com/methodology/\n[12] M. Gentzkow and J. M. Shapiro, \u201cWhat drives media slant? evidence\nfrom u.s. daily newspapers,\u201d Econometrica , vol. 78, no. 1, pp. 36\u201337,\n2006.\n[13] Allsides.com. (2019) Allsides - balanced news via media bias ratings\nfor an unbiased news perspective. https://www.allsides.com/unbiased-\nbalanced-news.\n[14] A. Heywood, Political ideologies: An introduction . Macmillan Inter-\nnational Higher Education, 2017.\n[15] webhose.io. (2019) Tap into web content at scale - crawled web data -\nwebhose. [Online]. Available: https://webhose.io/\n[16] Amazon Web Services. (2019) Amazon redshift. [Online]. Available:\nhttps://aws.amazon.com/redshift/\n[17] Amazon Web Service . (2019) Amazon s3. [Online]. Available:\nhttps://aws.amazon.com/s3/\n[18] D. M. Blei, A. Y . Ng, and M. I. Jordan, \u201cLatent dirichlet allocation,\u201d\nJournal of Machine Learning Research , vol. 3, pp. 994\u2013996, 2003.\n[19] J. Boyd-Graber, Y . Hu, and D. Minmo, \u201cApplications of topic models,\u201d\nFoundations and Trends in Information Retrieval .\n[20] A. K. McCallum, \u201cMallet: A machine learning for language toolkit,\u201d\n2002, http://mallet.cs.umass.edu.\n[21] W. R. Gilks, S. Richardson, and D. Spiegelhalter, Markov chain Monte\nCarlo in practice . Chapman and Hall/CRC, 1995.\n[22] A. Rogers. (2019, apr) Democrats aim fury at attorney general\nbill barr\u2019s handling of mueller report. [Online]. Available: https:\n//www.cnn.com/2019/04/19/politics/democrats-barr-fury/index.html\n[23] E. Hutto, C.J. Gilbert. (2014) Vader: A parsimonious rule-based\nmodel for sentiment analysis of social media text. [Online]. Available:\nhttps://github.com/cjhutto/vaderSentiment#citation-information\n[24] N. Grinberg, K. Joseph, L. Friedland, B. Swire-Thompson, and D. Lazer,\n\u201cFake news on twitter during the 2016 u.s. presidential election,\u201d\nScience , vol. 363, pp. 374\u2013378, 2016.\n[25] A. Guess, B. Nyhan, and J. Rei\ufb02er, \u201cSelective exposure to misinforma-\ntion: Evidence from the consumption of fake news during the 2016 us\npresidential campaign,\u201d European Research Council , vol. 9, 2016.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Controversy score calculation for news articles", "author": ["P Kim", "Z Fan", "L Fernando", "J Sham"], "pub_year": "2019", "venue": "2019 First \u2026", "abstract": "From the 2016 election continuing to the present, a strong focus has developed on the US  news media landscape. From issues such as fake news to ideological wars between news"}, "filled": false, "gsrank": 413, "pub_url": "https://ieeexplore.ieee.org/abstract/document/8940409/", "author_id": ["", "", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:bia1sv8U0gUJ:scholar.google.com/&output=cite&scirp=412&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D410%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=bia1sv8U0gUJ&ei=ULWsaODNLLTWieoP1pCJ2AY&json=", "num_citations": 7, "citedby_url": "/scholar?cites=419420803746309742&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:bia1sv8U0gUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://p-kim.com/wp-content/uploads/2019/12/newsphi-1.pdf"}}, {"title": "Overview of the CLEF-2024 checkthat! lab task 3 on persuasion techniques", "year": "2024", "pdf_data": "Overview of the CLEF-2024 CheckThat! Lab Task 3 on\nPersuasion Techniques\nJakub Piskorski1, Nicolas Stefanovitch2, Firoj Alam3, Ricardo Campos4,5, Dimitar Dimitrov6,\nAl\u00edpio Jorge7,4, Senja Pollak8, Nikolay Ribin6, Zoran Fijav\u017e9,10, Maram Hasanain3,\nPurifica\u00e7\u00e3o Silvano7,12, Elisa Sartori11, Nuno Guimar\u00e3es7,4, Ana Zwitter Vitez8,13,\nAna Filipa Pacheco7, Ivan Koychev6, Nana Yu7, Preslav Nakov14and\nGiovanni Da San Martino11\n1Polish Academy of Sciences, Warsaw, Poland\n2European Commission Joint Research Centre, Ispra, Italy\n3Qatar Computing Research Institute, HBKU, Qatar\n4INESC TEC, Portugal\n5University of Beira Interior, Portugal\n6Sofia University, Bulgaria\n7University of Porto, Portugal\n8Jo\u017eef Stefan Institute, Ljubljana, Slovenia\n9Jo\u017eef Stefan International Postgraduate School, Ljubljana, Slovenia\n10Peace Institute, Ljubljana, Slovenia\n11University of Padova, Italy\n12CLUP, Portugal\n13University of Ljubljana, Slovenia\n14Mohamed bin Zayed University of Artificial Intelligence, UAE\nAbstract\nWe present an overview of CheckThat! Lab\u2019s 2024 Task 3, which focuses on detecting 23 persuasion techniques\nat the text-span level in online media. The task covers five languages, namely, Arabic, Bulgarian, English,\nPortuguese, and Slovene, and highly-debated topics in the media, e.g., the Isreali\u2013Palestian conflict, the Russia\u2013\nUkraine war, climate change, COVID-19, abortion, etc. A total of 23 teams registered for the task, and two of\nthem submitted system responses which were compared against a baseline and a task organizers\u2019 system, which\nused a state-of-the-art transformer-based architecture. We provide a description of the dataset and the overall\ntask setup, including the evaluation methodology, and an overview of the participating systems. The datasets\naccompanied with the evaluation scripts are released to the research community, which we believe will foster\nresearch on persuasion technique detection and analysis of online media content in various fields and contexts.\nKeywords\nPersuasion technique, media analysis, multilinguality.\n1. Introduction\nFact-checking, verification and analysis of multimodal and multigenre content are of paramount\nimportance for the reliability of information shared through various communication channels such as\nnews, political debates, and social media. It can help prevent the spread of misinformation and promote\ninformed decision-making. By verifying the claims in such content, individuals and organisations can\nmake well-informed judgments and contribute to a more trustworthy online discourse.\nCLEF 2024: Conference and Labs of the Evaluation Forum, September 09\u201312, 2024, Grenoble, France\n/envel\u2322pe-\u2322penjpiskorski@gmail.com (J. Piskorski); Nicolas.Stefanovitch@ec.europa.eu (N. Stefanovitch); fialam@hbku.edu.qa (F. Alam);\nricardo.campos@ubi.pt (R. Campos); ilijanovd@fmi.uni-sofia.bg (D. Dimitrov); amjorge@fc.up.pt (A. Jorge);\nsenja.pollak@ijs.si (S. Pollak); n.m.ribin@gmail.com (N. Ribin); zoran.fijavz@mirovni-institut.si (Z. Fijav\u017e);\nmhasanain@hbku.edu.qa (M. Hasanain); msilvano@letras.up.pt (P. Silvano); elisa.sartori.2@unipd.it (E. Sartori);\nnuno.r.guimaraes@inesctec.pt (N. Guimar\u00e3es); Ana.ZwitterVitez@ff.uni-lj.si (A. Zwitter Vitez);\nanafilipasrpacheco@gmail.com (A. F. Pacheco); koychev@fmi.uni-sofia.bg (I. Koychev); robertananayu@hotmail.com (N. Yu);\npreslav.nakov@mbzuai.ac.ae (P. Nakov); giovanni.dasanmartino@unipd.it (G. Da San Martino)\n\u00a92024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\nCEURWorkshopProceedingsceur-ws.orgISSN 1613-0073\nFigure 1: TheCheckThat! lab verification pipeline. The 2024 edition of the lab covers six tasks: ( T1) check-\nworthiness estimation, ( T2) subjectivity, ( T3) persuasion technique detection (this paper), ( T4) detecting hero,\nvillain, and victim from memes, ( T5) rumour verification using evidence from authorities, and ( T6) robustness of\ncredibility assessment with adversarial examples.\nThis paper offers an overview of the shared task on detecting teh use of persuasion techniques in\nmultilingual news which was organized as part of CheckThat! 2024 lab. The CheckThat! 2024 lab\nwas held in the framework of CLEF 2024 [ 1].1Figure 1 shows the full CheckThat! identification and\nverification pipeline, highlighting the six tasks targeted in this seventh edition of the lab: Task 1 on\ncheck-worthiness estimation, Task 2 on subjectivity, Task 3 on persuasion technique detection (this\npaper), Task 4 on detecting hero, villain, and victim in memes, Task 5 on rumor verification using\nevidence from authorities, and Task 6 on robustness of credibility assessment with adversarial examples.\nTask 3 focuses on the detection of 23 persuasion techniques at text-span level in online media. The\ntask covers 5 languages, namely, Arabic, Bulgarian, English, Portuguese, and Slovene and highly-debated\ntopics in the media. A total of 23 teams registered for the task, and two of them submitted systems,\nwhich were compared against a baseline and a task organizers\u2019 system, which uses a state-of-the-art\ntransformed-based architecture. The participating systems also used state-of-the-art transformer-based\narchitectures and data augmentation.\nThe remainder of this paper is organized as follows: Section 2 briefly presents the task. Section 3\ndescribes the datasets and the evaluation methodology. Section 5 gives an overview of the system\nsubmissions, the organizers\u2019 system, and the evaluation results. Section 6 presents related work, whereas\nSection 7 offers some final conclusions.\n2. Task\nThe goal of this task is to recognize and classify persuasion techniques in multilingual news at the text\nspan level. In particular, we exploit the two-tier persuasion technique taxonomy introduced in SemEval\n2023 Shared Task 3 on Detecting the Genre, the Framing, and the Persuasion Techniques in Online News in\na Multi-lingual Setup [2]. At the top level, there are 6 coarse-grained types of persuasion techniques:\nAttack on reputation ,Justification ,Simplification ,Distraction ,Call, and Manipulative wording . These\nsix main types are further subdivided into 23 fine-grained techniques. Figure 2 presents the entire\ntaxonomy. Figure 3 provides one example of persuasion technique per main category. Full definitions\nand further examples of persuasion techniques are given in Piskorski et al. [3] and Piskorski et al. [4].\nAs training and development data, we used the existing corpus from the aforementioned SemEval\n2023 task [ 2], which covers nine languages: English, German, Georgian, Greek, French, Italian, Polish,\nRussian, and Spanish. For test data, we developed an entirely new dataset that covers five languages:\nArabic, Bulgarian, English, Portuguese, and Slovene. English is the only language for which both\ntraining/development and test data exist.\n1https://checkthat.gitlab.io/\nATTACK ON REPUTATION DISTRACTION MANIPULATIVE WORDING\n- Name Calling or Labelling - Strawman - Loaded Language\n- Guilt by Association - Red Herring - Obfuscation, Intentional\n- Casting Doubt - Whataboutism Vagueness, Confusion\n- Appeal to Hypocrisy - Exaggeration or Minimisation\n- Questioning the Reputation - Repetition\nJUSTIFICATION SIMPLIFICATION CALL\n- Flag Waiving - Causal Oversimplification - Slogans\n- Appeal to Authority - False Dilemma or No Choice - Conversation Killer\n- Appeal to Popularity - Consequential - Appeal to Time\n- Appeal to Values Oversimplification\n- Appeal to Fear, Prejudice\nFigure 2: Two-tier persuasion technique taxonomy.\nName Calling or Labelling: \u2019Fascist\u2019 Anti-Vax Riot Sparks COVID Outbreak in Australia.\nAppeal to Authority: Since the Pope said that this aspect of the doctrine is true we should add it to the creed.\nStrawman: Referring to your claim that providing medicare for all citizens would be costly and a danger to the free market, I infer that you\ndon\u2019t care if people die from not having healthcare, so we are not going to support your endeavour .\nConsequential Oversimplification: If we begin to restrict freedom of speech, this will encourage the government to infringe\nupon other fundamental rights, and eventually this will result in a totalitarian state where citizens have little to no control\nof their lives and decisions they make\nSlogans: \"Immigrants welcome, racist not!\nExaggeration or Minimisation: From the seminaries, to the clergy, to the bishops, to the cardinals, homosexuals are present at all\nlevels, by the thousand\nFigure 3: Examples of text snippets with persuasion techniques. The text fragments highlighted in bold are the\nactual text spans annotated.\nThe test dataset covers highly-debated topics in the media, e.g., the Isreali-Palestian conflict, the\nRussia\u2013Ukraine war, climate change, COVID-19, abortion, etc. Except for the Israeli-Palestinian conflict,\nthe same topics are also covered in the training/development dataset. For Arabic, the dataset covers\nforteen broad topics such as news, politics, health, social, sports, arts and culture, religion, science and\ntechnology, human rights, and lifestyle. Among them, news andpolitics cover more than 50% of the\nparagraphs. More detail about the topic distribution can be found in [5].\nThe main difference between the Task 3 presented in this paper and the former competition on\npersuasion technique detection organized at SemEval 2023 [ 2] is that the latter focused on the detection\nof persuasion techniques at the paragraph level, while the current task aims at developing models to\ndetect and to classify persuasion techniques at the span level, which constitutes an additional challenge.\n3. Datasets\n3.1. Annotation Process\nEach language was annotated by a team of annotators fluent in the language and used to perform such\nannotations; the language leaders met regularly in order to discuss difficult cases with more experienced\nannotators having already taken part in previous annotations campaign using the same taxonomy. For\nall languages but Arabic, each document was annotated by two annotators, and one curator reconciled\nthe annotations. For the Arabic test dataset, each paragraph was annotated by three annotators, and\ntwo curators consolidated the annotations.\nWe followed the approach laid in [ 4] to train annotators, with the exception of Arabic: they were\nfirst given the comprehensive annotation guidelines, were further trained using two sets of flashcards\nof increasing complexity, and lastly had to annotate and to discuss with expert annotators five test\ndocuments whose ground-truth annotations were known.\n3.2. Quality and Coherence Assurance\nThe overal Inter-Annotator Agreement (IAA) as measured by the Krippendorff\u2019s \ud835\udefcis of 0.404, which\nis lower than the recommended value of 0.667. In Table 2, we also reported the \ud835\udefcfor each language\nindependently. One has to take into account that this measures coherence before curation, and that\nsignificant steps have been taken in order to improve the quality of the curated data, as described below.\nWe used the approach of [ 6], which facilitates the comparison of annotations across documents\nand across languages. This allowed us to cluster the annotations based on their semantic similarity,\nwhich was used to flag outliers for review, and allowed us to spot cross-lingual disagreements. Such\ndisagreements were either due to individual annotator differences or to a more fundamental different\nunderstanding of techniques\u2019 definitions across language-specific annotation teams. Such differences\ncould concern either nuances of the meaning of specific labels or the length of the span to be selected.\nWe further used the following additional measures to improve the quality of the dataset: (a) we\ncompared the distribution of labels to spot obvious cross-lingual inconsistencies, (b) we alphabetically\nsorted texts in order to make it easy to spot similar texts with different labels, and (c) finally the most\nexperienced annotators did random checks.\nAll these measures contributed to the increase of the coherence of the dataset, which could be\nmeasured for all languages except for Arabic using the \ud835\udc5cvalue as defined in [ 6] and using the same\nsettings: when ignoring the Loaded Language andName-Calling Labelling classes, the value goes from\n0.279to0.284, and when considering them it increases from 0.608to0.611; this increase is mostly\ndriven by improvement of the inter-language coherence.\n3.3. Statistics about the Datasets\n3.3.1. Training and Development Data\nThe overall statistics about the training and the development datasets are provided in Table 1. For more\ndetailed characteristics of these datasets, please refer to [2] and Piskorski et al. [3].\nTable 1\nTraining anddevelopment dataset statistics.\nTraining Development\nlanguage #documents #spans #documents #spans\nEnglish 536 9,002 54 1,775\nFrench 211 6,831 50 1,681\nGerman 177 5,737 50 1,904\nItalian 303 7,961 61 2,351\nPolish 194 3,824 47 1,491\nRussian 191 4,138 72 944\nGeorgian - - 29 218\nGreek - - 64 691\nSpanish - - 30 546\n3.3.2. Test Dataset\nAs part of Task 3, we created new labeled datasets for Arabic, Bulgarian, English, Portuguese, and\nSlovene. With the exception of the latter, this shared task is the first application of the framework for\nannotating persuasion techniques for the mentioned languages. News selection was delegated to the\nteams responsible for their respective languages, but they were expected to include a variety of topics,\nnews genres, and political stances, in addition to selecting texts where a high prevalence of persuasion\ntechniques was to be expected. To allow for comparability with previous datasets, the topics of the\nRussia\u2013Ukraine war, climate change, COVID-19, and abortion were covered in all test datasets except\nfor Arabic. In addition, a new topic, the Israeli\u2013Palestinian conflict, was added.\nThe number of included news articles and the topic distributions for the languages are presented\nin Tables 2 and 3, respectively. Overall, the most commonly annotated persuasion technique was\nLoaded language , followed by Name-calling ,Casting doubt andQuestioning the Reputation , although the\nspecific distribution varies across the datasets. The share of annotated persuasion technique classes\nacross the test datasets is presented in Table 4. The distribution of the frequency of the persuasion\ntechniques in the test dataset is to some degree similar and comparable to the datasets used in the\nSemEval 2023 Task on persuasion techniques [ 2], i.e., Loaded language andName-calling are the two\nmost prevalent fine-grained techniques, whereas Manipulative Wording andAttack on Reputation are\nthe two coarse-grained persuasion technique categories with highest share in both datasets.\nTable 2\nTest dataset statistics. Note that for Arabic, the number of articles does not directly reflect the number of\nparagraphs, as we only annotated soem selected paragraphs from them.\nTest\nlanguage #documents #paragraphs #spans \ud835\udefc\nArabic 1,527 1,642 2,197 -\nBulgarian 100 916 1,732 0.197\nEnglish 98 2,174 2,599 0.168\nSlovenian 100 1,478 4,591 0.470\nPortuguese 104 1,501 1,727 0.587\nTable 3\nTest dataset topic distributions.\nTopics (%)\nlanguage Israel-Palestine Ukraine-Russia Covid-19 Migration Climate Abortion Elections\nArabic - - - - - - -\nBulgarian 19.0 13.0 15.0 23.0 15.0 15.0 -\nEnglish 25.5 13.3 15.3 15.3 15.3 15.3 -\nSlovenian 20.0 20.0 16.0 15.0 15.0 14.0 -\nPortuguese 24.0 18.3 10.6 10.6 12.5 11.5 12.5\nThe Portuguese dataset was developed by manually selecting 104 articles from 28 European Portuguese\nnews media based on the main topics of the task. Moreover, a combination of news and opinion pieces\nwas selected to ensure a variety of annotation types. The Portuguese dataset consists of articles from 27\ndifferent news sources, where 25 articles are related to the Israeli\u2013Palestian conflict, 19 to the Russia\u2013\nUkraine war, 11 to COVID-19, 11 to migration, 13 to climate change, 12 to abortion and 13 to elections.\nThe election topic was included due to the large number of news and opinion articles released on this\ntopic during the extraction process. In addition, these articles are rich in persuasion techniques, making\nthem a good fit for the current task.\nThe Slovenian dataset included manually selected 100 news articles from 11 news channels and two\nblogs, with the latter being used to preserve a balance across political leanings and topics. Hard news\nconstituted 20% of the included text with the rest consisting of opinion articles. Topically, 20 of the\nannotated articles were related to the Israeli-Palestinian conflict, 20 to the Russia\u2013Ukraine war, 16 to\nCOVID-19, 15 to climate change, 15 to migration, and 14 to discussions on gender-related topics. The\nlatter was done as the right to abortion is contitutionally protected in Slovenia and rarely contested\ndirectly.\nThe English dataset has a total of 98 articles from 80 unique news sources. Of the 98 articles, 25\narticles concern the Israeli-Palestinian conflict, 15 the topic of climate change, 15 the abortion discussion,\n15 COVID-19, 15 migration, and 13 the Russia\u2013Ukraine war. The articles were collected manually using\nboth news and opinion articles from media outlets present in Media Bias/Fact Check2.\n2https://mediabiasfactcheck.com\nTable 4\nDistribution of persuasion technique labels in test dataset by language (percent). Color intensity represents the\nrelative frequency of labels for each language.\nPersuasion Techniques Distribution by Language (%)\nArabic Bulgarian English Slovenian Portuguese\nName-Calling Labeling 17,60 11,10 15,90 14,70 12,40\nGuilt by Association 0,20 2,90 1,70 1,40 0,60\nDoubt 1,40 10,20 8,60 12,70 6,30\nAppeal to Hypocrisy 0,30 0,90 1,50 0,30 1,00Attack on\nReputation\nQuestioning the Reputation 3,70 5,50 15,00 14,20 19,10\nFlag Waving 1,00 1,80 2,30 0,50 0,90\nAppeal to Authority 0,50 1,40 5,10 3,70 2,60\nAppeal to Popularity 0,10 0,90 1,00 0,90 0,60\nAppeal to Values 0,40 4,30 4,20 3,70 8,00Justification\nAppeal to Fear-Prejudice 0,50 8,40 7,00 5,00 7,20\nStrawman 0,10 2,00 0,70 1,90 0,30\nRed Herring 0,20 0,90 0,50 0,60 0,50 Distraction\nWhataboutism 0,00 1,10 1,70 0,10 0,20\nCausal Oversimplification 1,20 1,80 3,10 2,80 2,10\nFalse Dilemma-No Choice 0,10 2,70 4,80 3,40 3,00 Simplification\nConsequential Oversimplification 0,30 1,40 1,80 1,80 3,40\nLoaded Language 60,90 22,80 16,90 25,90 15,10\nObfuscation-Vagueness-Confusion 2,30 0,40 0,20 0,20 0,90\nExaggeration-Minimisation 7,30 8,10 0,90 1,50 2,70Manipulative\nWording\nRepetition 0,50 6,20 2,20 1,60 6,10\nSlogans 0,70 2,90 2,30 1,40 1,60\nConversation Killer 0,30 1,40 1,60 0,90 2,30 Call\nAppeal to Time 0,40 0,80 1,00 0,80 3,10\nThe Arabic dataset consists of Arabic news articles from AraFacts [ 7] and an in-house news article\ncollection. We split the articles into paragraphs and annotated them at the paragraph level. From the\nAraFacts news articles, we annotated all paragraphs, while from the in-house news article collection,\nwe randomly selected paragraphs by stratified sampling over news media, ensuring diversity in topics\nand news media. The dataset covers around 14 broad topics, with news and politics being the top most\nfrequently covered ones. More details about this dataset can be found in [5].\nThe Bulgarian dataset consists of 100 manually selected articles extracted from 9 different sources.\nThere are 19 articles on the Israeli-Palestinian conflict, 18 on COVID-19, 15 on climate change, 25 on\nthe Russia-Ukraine war, and 23 on migration.\n4. Evaluation Framework\nTask Organization\nFor the lab, we provided training and development datasets. The latter was intended to allow participants\nto validate their systems internally, while they could use the development set for hyper-parameter\ntuning and model selection. The test set was used for the final evaluation and ranking. The participants\nwere allowed to submit multiple runs on the test set (without seeing the scores), but only the last valid\nrun was considered as their official submission.\nEvaluation Measure\nThe task is defined as a multi-label multi-class sequence tagging problem, as such traditional evaluation\nmetrics tend to be too strict when scoring since they are based on exact matching. We analyzed\nseveral annotated articles and how the spans varied between different annotators and consolidators and\ndiscovered that most of the time there was agreement on the technique, but the spans differed slightly.\nIt is also important to emphasize that from the end-user perspective (e.g., analysts carrying out\ncomparative media analysis) partial matches with significant overlap could be considered as equally\ngood as exact matches. To address the limitations of exact matching scorers, we propose an adjustment\nto the traditional \ud835\udc391-score to take into account partial span matching. Let\n\u2022P = {p 1, ..., p n} be the set of predictions for one article, \ud835\udc5dP\ud835\udc43is a generic prediction which is\nrepresented as an ordered triple x\ud835\udc60\ud835\udc5d\ud835\udc4e\ud835\udc5b start, \ud835\udc60\ud835\udc5d\ud835\udc4e\ud835\udc5b end, \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59y\n\u2022G = {g 1, ..., g m} be the set of gold labels for one article, \ud835\udc54P\ud835\udc3ais a generic gold label which is\nrepresented as an ordered triple x\ud835\udc60\ud835\udc5d\ud835\udc4e\ud835\udc5b start, \ud835\udc60\ud835\udc5d\ud835\udc4e\ud835\udc5b end, \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59y\n\u2022\ud835\udc3f:p\ud835\udc5d, \ud835\udc54q\u00dd\u00d1t 0,1uis a function that measures the similarity of the labels of \ud835\udc5dand\ud835\udc54\n\ud835\udc3fp\ud835\udc5d, \ud835\udc54q\u201c#\n1,if the labels of p and g are identical\n0,otherwise\n\u2022\ud835\udc3c:p\ud835\udc5d, \ud835\udc54q\u00dd\u00d1r 0,1sis a function that measures the overlap rate of the spans of \ud835\udc5dand\ud835\udc54\n\ud835\udc3cp\ud835\udc5d, \ud835\udc54q\u201c$\n\u2019\u2019\u2019\u2019\u2019\u2019\u2019\u2019\u2019&\n\u2019\u2019\u2019\u2019\u2019\u2019\u2019\u2019\u2019%1, if|\ud835\udc5dX\ud835\udc54|\n|\ud835\udc54|\u011b0.5and|\ud835\udc5d|\u010f2\u00a8|\ud835\udc54|\n|\ud835\udc5dX\ud835\udc54|\n|\ud835\udc54|Pp0,1q,if|\ud835\udc5dX\ud835\udc54|\n|\ud835\udc54|Pp0,0.5qand|\ud835\udc5d|\u010f2\u00a8|\ud835\udc54|\n|\ud835\udc5dX\ud835\udc54|\n|\ud835\udc5d|Pp0,1q,if|\ud835\udc5dX\ud835\udc54|\n|\ud835\udc54|Pp0,1sand|\ud835\udc5d|\u01052\u00a8|\ud835\udc54|and|\ud835\udc5d|\u010f4\u00a8|\ud835\udc54|\n0, otherwise\n\u2022\ud835\udc46:p\ud835\udc5d, \ud835\udc54q\u00dd\u00d1r 0,1sis a similarity function of two spans \ud835\udc5dand\ud835\udc54. It is calculated as follows:\n\ud835\udc46p\ud835\udc5d, \ud835\udc54q\u201c\ud835\udc3fp\ud835\udc5d, \ud835\udc54q\u00a8\ud835\udc3cp\ud835\udc5d, \ud835\udc54q\nWe map each possible case into True Positive (T p), False Positive (F p), and False Negative (F n) values,\nand then compute the standard F 1-score. From the obtained values of \ud835\udc47p,\ud835\udc39p,\ud835\udc39n, we compute the\n\ud835\udc391-score of the example. Additionally, \ud835\udc391-score is computed for each persuasion technique. For all\ndatasets, the results are micro- and macro-averaged.\nThe pseudocode of the algorithm for computing True Positives, False Positives, and False Negatives is\ngiven in Algorithm 1.\nBaseline System\nWe opted for the most natural way to solve both a span identification task with a multi-label classification\ntask: to treat it as a token classification problem, i.e., for each token, we predicted the classes with a\ngiven probability threshold, and then merged adjacent tokens with the same class in a single span. We\nused XLM-RoBERTa-base [8] in a zero-shot setting.\n5. Results and Overview of the Systems\nThe task is a multi-label multi-class sequence tagging task. To measure the performance of the systems,\nwe modified the standard micro-averaged F1 to account for partial matching between the spans. In\naddition, an F1 value is computed for each persuasion technique.\nAlgorithm 1 Pseudocode for the evaluation measure of the task.\n1:Let\ud835\udc40be an empty list of pairs, where each element x\ud835\udc5d, \ud835\udc54yis a pair of prediction and a gold label\n2:while \ud835\udc43\u2030H and\ud835\udc3a\u2030H do\n3: findx\ud835\udc5d\u02da, \ud835\udc54\u02daywhich maximises \ud835\udc46p\ud835\udc5d, \ud835\udc54q\n4: \ud835\udc40\u00d0\ud835\udc40Yx\ud835\udc5d\u02da, \ud835\udc54\u02day\n5: \ud835\udc43\u00d0\ud835\udc43zt\ud835\udc5d\u02dau\n6: \ud835\udc3a\u00d0\ud835\udc3azt\ud835\udc54\u02dau\n7:end while\n8:\ud835\udc39n\u00d0|\ud835\udc3a| \u0179 gold labels left with no match are false negatives\n9:\ud835\udc39p\u00d0|\ud835\udc43|\u0179predictions left with no match (or already matched with the same or better similarity\nvalue) are false positives\n10:\ud835\udc47p\u00d00\n11:for eachx\ud835\udc5d, \ud835\udc54yP\ud835\udc40do\n12: \ud835\udc47p\u00d0\ud835\udc47p`\ud835\udc46p\ud835\udc5d, \ud835\udc54q\n13: \ud835\udc39p\u00d0\ud835\udc39p`p1\u00b4\ud835\udc46p\ud835\udc5d, \ud835\udc54qq\u0179 partial given credit affects the score depending on the prediction\nmistake\n14:end for\nTable 5\nTask 3: Overview of the approaches.\nTeam Language Models Misc\nAr Bg En Pt Sl mBERT DeBERTa Data aug\nMela 1 /check-square\nUniBO 2 2 1 2 2 /check-square /check-square\nTable 6\nTask 3: Results on persuasion techniques span identification. The team marked with * is a post competition\nexperiment from the organizers.\nRank Team F1 micro F1 macro Rank Team F1 micro F1 macro\nEnglish Portuguese\n1 UniBO 0.092 0.061 PersuasionMultiSpan* 0.132 0.120\nPersuasionMultiSpan* 0.078 0.086 1 UniBO 0.107 0.073\n2 Baseline 0.009 0.001 2 Baseline 0.002\nBulgarian Slovenian\nPersuasionMultiSpan* 0.132 0.128 PersuasionMultiSpan* 0.153 0.127\n1 UniBO 0.114 0.081 1 UniBO 0.123 0.075\n2 Baseline 0.009 0.002 2 Baseline 0.003 0.002\nArabic\n1 Mela 0.301 0.080\n2 UniBO 0.108 0.068\nPersuasionMultiSpan* 0.028 0.059\n3 Baseline 0.021 0.006\n5.1. Participating Systems\nIn Table 5, we provide an overview of the approaches, including the baseline. Only two teams submitted\nruns during the test phase (the organizers added a post competition submission), and two teams\nsubmitted system description papers. As shown in the table, the teams mostly fine-tuned transformer-\nbased models, including data augmentation. In Table 6, we report the results. Team UniBO participated\nin all languages but ranked first only for English. Team Mela participated only in Arabic and was the\ntop-ranked system, showing a significant improvement compared to other teams and the baseline.\nTeam UniBO [9] proposed a system consisting of a two-part pipeline for text processing and classifi-\ncation. The first part was a data augmentation module using a BERT-based model fine-tuned for word\nalignment to project labels from source texts onto machine-translated target texts. The second part was\na persuasion technique classification module, using two fine-tuned BERT-based models: a sequence\nclassifier for detecting sentences with persuasion techniques and a set of 23 token-level classifiers for\nidentifying specific techniques.\nTeam Mela [10] proposed a multilingual BERT-based system that incorporates both English and\nArabic knowledge during its pre-training stage. With this system, they achieved first place on the\nArabic leaderboard in the shared task.\n5.2. Organizer System\nFor the sake of comparison to state-of-the-art solutions, we as organizers developed (after the com-\npetition) a multi-lingual token-level multi-label classifier of persuasion techniques (referred to in the\ntable with evaluation results with PersuasionMultiSpan* ) based on XML-RoBERTa [ 11] trained on\nthe SemEval-2023 corpus [ 3], capable of processing arbitrarily long text using sliding window chunking\nwith 50% overlap. This classifier achieves state-of-the-art results on the SemEval 2023 Task 3 test\ndataset [ 2] for all six languages (oscillates around 1-3 rank across languages), both in terms of micro\nand macro \ud835\udc391scores. Further detail about this classifier can be found in [12].\n6. Related Work\nEarly work on persuasion techniques focused on one or a few specific ones: Habernal et al. [13,14]\ndeveloped a corpus with 1.3k arguments annotated with five fallacies. Da San Martino et al. [15], created\na corpus of news articles annotated with 18 techniques, considering separately the task of technique\nspans detection and classification. They further tackled a sentence-level propaganda detection task,\nand proposed a multi-granular gated deep neural network. The model was afterwards implemented\nin the Prta system [ 16], while the data was expanded to include nine languages [ 3]. Several models\nwere proposed to address the limitations of transformers [ 17], or looking into interpretable propaganda\ndetection [ 18]. Persuasion techniques are used also in memes, requiring complex multimodal models [ 19].\nThe survey on computational propaganda detection [ 20] highlights the need for models combining\nNLP and Network Analysis, which has been further analysed in Hristakieva et al. [21]. Other works\nanalysed also the use of persuasion techniques on social media posts about COVID-19 [22, 23].\nSeveral shared tasks on the detection of persuasion techniques have been organised through the\nyears: the NLP4IF-2019 task on Fine-Grained Propaganda Detection [24], which is based on a subset of the\ndata of this task; the SemEval-2020 task 11 on Detection of Persuasion Techniques in News Articles [25],\nwhich considers 14 techniques and split the task of identifying any persuasive span and, given the\nspan, identify the technique in it; the SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images focused on 22 techniques in memes [ 26]; the WANLP\u20192022 shared task asked to detect\nthe use of 20 propaganda techniques in Arabic tweets [ 27]; the SemEval-2023 Task 3 includes several\nlanguages and defines the problem as a multilabel classification one at paragraph level [ 2];Task 1 at the\nArAIEval shared task targets the same task and techniques of our shared task, covering multi-genre\nArabic content [ 28]. Further annotations in Spanish and English, although for different categories of\ntechniques, are provided by the DIPROMATS initiative [29].\n7. Conclusion and Future Work\nWe presented an overview of task 3 of the CLEF-2024 CheckThat! lab. The lab featured tasks that span\nthe full verification pipeline: from spotting check-worthy claims to claim verification. Task 3 focused\non the detection of 23 persuasion techniques at the text span level in online media, and covers five\nlanguages (Arabic, Bulgarian, English, Portuguese, and Slovene) and highly-debated topics in the media.\nThe task is a natural follow-up of the former competition on persuasion technique detection\norganized at SemEval-2023 [ 2], which focused on the detection of persuasion techniques at the\nparagraph level, while the task described in this paper aims at developing models to detect and to\nclassify persuasion techniques at the span level, constituting an additional complexity. The participating\nsystems used state-of-the-art transformer-based architectures and deployed data augmentation. The\nobtained results compared vis-a-vis the results reported in [ 2] confirm that the detection at the span\nlevel is a harder task, and leaves space for improvement. In future work, we plan to expand the task in\na variety of ways, e.g., by enlarging the dataset, by incorporating more languages, and by considering\nother text genre, e.g., parliamentary debates.\nLimitations While creating the test dataset used in this task, we strived to have a balanced represen-\ntation of the points of view on the various topics, but this was done on a best-effort basis, and the\ndata might not be fully representative for carrying out other type of research, e.g., comparative media\nanalysis, etc.\nAcknowledgments\nWe are greatly indebted to the following persons who contributed to the organization of this task:\nNikolaos Nikolaidis, Ivanka Mavrodieva, Desislava Angelova, Ana Rupnik, Anja Krivec, Ita Osredkar,\nKatja \u0160tefani\u010d, Lana Vali\u010d, Maja Habjani\u010d, Rok Drenik, \u0160pela Rot, Veronika Razpotnik, Zala Rogulji\u010d.\nThe work of F. Alam, M. Hasanain and G. Da San Martino is partially supported by NPRP 14C-0916-\n210015 from the Qatar National Research Fund, which is a part of Qatar Research Development and\nInnovation Council (QRDI). The findings achieved herein are solely the responsibility of the authors.\nThe work of R.Campos, A. Jorge, and P. Silvano was financed by National Funds through the FCT\n- Funda\u00e7\u00e3o para a Ci\u00eancia e a Tecnologia, I.P. (Portuguese Foundation for Science and Technology)\nwithin the project StorySense, with reference 2022.09312.PTDC (DOI 10.54499/2022.09312.PTDC).\nThe work of N. Guimar\u00e3es was financed by Component 5 - Capitalization and Business Innovation,\nintegrated in the Resilience Dimension of the Recovery and Resilience Plan within the scope of the\nRecovery and Resilience Mechanism (MRR) of the European Union (EU), framed in the Next Generation\nEU, for the period 2021 - 2026, within project HfPT, with reference 41.\nThe work of D. Dimitrov, N. Ribin, and I. Koychev is partially financed by the European Union-\nNextGenerationEU, through the National Recovery and Resilience Plan of the Republic of Bulgaria,\nproject SUMMIT, No BG-RRP-2.004-0008.\nThe work of S. Pollak, Z. Fijav\u017e, and A. Zwitter Vitez was supported by the Slovenian Research Agency\ngrants via the core research programmes Knowledge Technologies (P2-0103), Equality and Human\nRights in the Times of Global Governance (P5-0413) and Theoretical and Applied Linguistic Research:\nContrastive, Synchronic, and Diachronic aspects (P6-0218), and the projects Computer-assisted multi-\nlingual news discourse analysis with contextual embeddings (J6-2581), Embeddings-based techniques\nfor Media Monitoring Applications (L2-50070), Hate Speech in Contemporary Conceptualizations of\nNationalism, Racism, Gender and Migration (J5-3102). .\nReferences\n[1]A. Barr\u00f3n-Cede\u00f1o, F. Alam, J. M. Stru\u00df, P. Nakov, T. Chakraborty, T. Elsayed, P. Przyby\u0142a, T. Caselli,\nG. Da San Martino, F. Haouari, C. Li, J. Piskorski, F. Ruggeri, X. Song, R. Suwaileh, Overview of\nthe CLEF-2024 CheckThat! Lab: Check-worthiness, subjectivity, persuasion, roles, authorities\nand adversarial robustness, in: L. Goeuriot, P. Mulhem, G. Qu\u00e9not, D. Schwab, L. Soulier, G. M.\nDi Nunzio, P. Galu\u0161\u010d\u00e1kov\u00e1, A. Garc\u00eda Seco de Herrera, G. Faggioli, N. Ferro (Eds.), Experimental IR\nMeets Multilinguality, Multimodality, and Interaction. Proceedings of the Fifteenth International\nConference of the CLEF Association (CLEF 2024), 2024.\n[2]J. Piskorski, N. Stefanovitch, G. Da San Martino, P. Nakov, SemEval-2023 Task 3: Detecting the\ncategory, the framing, and the persuasion techniques in online news in a multi-lingual setup, in:\nA. K. Ojha, A. S. Do\u011fru\u00f6z, G. Da San Martino, H. Tayyar Madabushi, R. Kumar, E. Sartori (Eds.),\nProceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023), Toronto,\nCanada, 2023, pp. 2343\u20132361.\n[3]J. Piskorski, N. Stefanovitch, N. Nikolaidis, G. Da San Martino, P. Nakov, Multilingual multifaceted\nunderstanding of online news in terms of genre, framing, and persuasion techniques, in: A. Rogers,\nJ. Boyd-Graber, N. Okazaki (Eds.), Proceedings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers), Toronto, Canada, 2023, pp. 3001\u20133022.\n[4]J. Piskorski, N. Stefanovitch, V.-A. Bausier, N. Faggiani, J. Linge, S. Kharazi, N. Nikolaidis, G. Teodori,\nB. De Longueville, B. Doherty, J. Gonin, C. Ignat, B. Kotseva, E. Mantica, L. Marcaletti, E. Rossi,\nA. Spadaro, M. Verile, G. Da San Martino, F. Alam, P. Nakov, News Categorization, Framing and\nPersuasion Techniques: Annotation Guidelines, Technical Report, European Commission Joint\nResearch Centre, Ispra (Italy), 2023.\n[5]M. Hasanain, F. Ahmad, F. Alam, Can GPT-4 identify propaganda? annotation and detection of\npropaganda spans in news articles, in: Proceedings of the 2024 Joint International Conference on\nComputational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Torino,\nItalia, 2024, pp. 2724\u20132744.\n[6]N. Stefanovitch, J. Piskorski, Holistic inter-annotator agreement and corpus coherence estimation\nin a large-scale multilingual annotation campaign, in: Conference on Empirical Methods in Natural\nLanguage Processing, 2023.\n[7]Z. Sheikh Ali, W. Mansour, T. Elsayed, A. Al-Ali, AraFacts: the first large arabic dataset of naturally\noccurring claims, in: Proceedings of the Sixth Arabic Natural Language Processing Workshop,\n2021, pp. 231\u2013236.\n[8]A. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzm\u00e1n, \u00c9. Grave, M. Ott,\nL. Zettlemoyer, V. Stoyanov, Unsupervised cross-lingual representation learning at scale, in:\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020,\npp. 8440\u20138451.\n[9]P. Gajo, L. Giordano, A. Barron-Cede\u00f1o, UniBO at CheckThat! 2024: Multi-lingual and Multi-label\nPersuasion Technique Detection in News with Data Augmentation and Sequence-Token Classifiers,\nin: [30], 2024.\n[10] S. Nabhani, M. A. R. Riyadh, Mela at CheckThat! 2024: Transferring Persuasion Detection from\nEnglish to Arabic - A Multilingual BERT Approach, in: [30], 2024.\n[11] A. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzm\u00e1n, E. Grave, M. Ott,\nL. Zettlemoyer, V. Stoyanov, Unsupervised cross-lingual representation learning at scale, CoRR\nabs/1911.02116 (2019).\n[12] N. Nikolaidis, J. Piskorski, N. Stefanovitch, Exploring the usability of persuasion techniques for\ndownstream misinformation-related classification tasks, in: N. Calzolari, M.-Y. Kan, V. Hoste,\nA. Lenci, S. Sakti, N. Xue (Eds.), Proceedings of the 2024 Joint International Conference on\nComputational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Torino,\nItalia, 2024, pp. 6992\u20137006.\n[13] I. Habernal, R. Hannemann, C. Pollak, C. Klamm, P. Pauli, I. Gurevych, Argotario: Computational\nargumentation meets serious games, in: Proceedings of the 2017 Conference on Empirical Methods\nin Natural Language Processing: System Demonstrations, EMNLP \u201917, Copenhagen, Denmark,\n2017, pp. 7\u201312.\n[14] I. Habernal, P. Pauli, I. Gurevych, Adapting serious game for fallacious argumentation to German:\nPitfalls, insights, and best practices, in: LREC, 2018.\n[15] G. Da San Martino, S. Yu, A. Barron-Cedeno, R. Petrov, P. Nakov, Fine-grained analysis of\npropaganda in news articles, in: Proceedings of the 2019 Conference on Empirical Methods in\nNatural Language Processing, EMNLP \u201919, Hong Kong, China, 2019, pp. 5636\u20135646.\n[16] G. Da San Martino, S. Shaar, Y. Zhang, S. Yu, A. Barr\u00f3n-Cedeno, P. Nakov, Prta: A system to\nsupport the analysis of propaganda techniques in the news, in: ACL, 2020.\n[17] A. Chernyavskiy, D. Ilvovsky, P. Nakov, Transformers: \u201cThe end of history\u201d for NLP?, in:\nProceedings of the European Conference on Machine Learning and Principles and Practice of\nKnowledge Discovery in Databases, ECML-PKDD\u201921, 2021.\n[18] S. Yu, G. Da San Martino, M. Mohtarami, J. Glass, P. Nakov, Interpretable propaganda detection in\nnews articles, in: Proceedings of the International Conference on Recent Advances in Natural\nLanguage Processing, RANLP \u201921, 2021, pp. 1597\u20131605.\n[19] D. Dimitrov, B. B. Ali, S. Shaar, F. Alam, F. Silvestri, H. Firooz, P. Nakov, G. Da San Martino,\nDetecting propaganda techniques in memes, in: Proceedings of the Joint Conference of the 59th\nAnnual Meeting of the Association for Computational Linguistics and the 11th International Joint\nConference on Natural Language Processing, ACL-IJCNLP \u201921, 2021, pp. 6603\u20136617.\n[20] G. Da San Martino, S. Cresci, A. Barr\u00f3n-Cede\u00f1o, S. Yu, R. Di Pietro, P. Nakov, A survey on\ncomputational propaganda detection, in: C. Bessiere (Ed.), Proceedings of the International Joint\nConference on Artificial Intelligence, IJCAI-PRICAI \u201920, 2020, pp. 4826\u20134832.\n[21] K. Hristakieva, S. Cresci, G. Da San Martino, M. Conti, P. Nakov, The spread of propaganda\nby coordinated communities on social media, in: Proceedings of the 14th ACM Web Science\nConference, WebSci \u201922, Barcelona, Spain, 2022, pp. 191\u2013201.\n[22] P. Nakov, F. Alam, S. Shaar, G. Da San Martino, Y. Zhang, COVID-19 in Bulgarian social media:\nFactuality, harmfulness, propaganda, and framing, in: Proceedings of the International Conference\non Recent Advances in Natural Language Processing, RANLP \u201921, 2021.\n[23] P. Nakov, F. Alam, S. Shaar, G. Da San Martino, Y. Zhang, A second pandemic? Analysis of fake\nnews about COVID-19 vaccines in Qatar, in: Proceedings of the International Conference on\nRecent Advances in Natural Language Processing, RANLP \u201921, 2021.\n[24] G. Da San Martino, A. Barr\u00f3n-Cede\u00f1o, P. Nakov, Findings of the NLP4IF-2019 shared task on\nfine-grained propaganda detection, in: Proceedings of the Second Workshop on Natural Language\nProcessing for Internet Freedom: Censorship, Disinformation, and Propaganda, NLP4IF \u201919, Hong\nKong, China, 2019, pp. 162\u2013170.\n[25] G. Da San Martino, A. Barr\u00f3n-Cede\u00f1o, H. Wachsmuth, R. Petrov, P. Nakov, SemEval-2020 task\n11: Detection of propaganda techniques in news articles, in: Proceedings of the International\nWorkshop on Semantic Evaluation, SemEval \u201920, Barcelona, Spain, 2020.\n[26] D. Dimitrov, B. Bin Ali, S. Shaar, F. Alam, F. Silvestri, H. Firooz, P. Nakov, G. Da San Martino, Task\n6 at SemEval-2021: Detection of persuasion techniques in texts and images, in: Proceedings of the\n15th International Workshop on Semantic Evaluation, SemEval \u201921, Bangkok, Thailand, 2021.\n[27] F. Alam, H. Mubarak, W. Zaghouani, G. Da San Martino, P. Nakov, Overview of the WANLP 2022\nshared task on propaganda detection in Arabic, in: Proceedings of the Seventh Arabic Natural\nLanguage Processing Workshop, WANLP \u201922, Abu Dhabi, UAE, 2022.\n[28] M. Hasanain, M. A. Hasan, F. Ahmed, R. Suwaileh, M. R. Biswas, W. Zaghouani, F. Alam, ArAIEval\nShared Task: Propagandistic Techniques Detection in Unimodal and Multimodal Arabic Content,\nin: Proceedings of the Second Arabic Natural Language Processing Conference (ArabicNLP 2024),\nBangkok, 2024.\n[29] P. M. y Guillermo Marco y Julio Gonzalo y Jorge Carrillo-de-Albornoz y Iv\u00e1n Gonzalo-Verdugo,\nOverview of DIPROMATS 2023: automatic detection and characterization of propaganda tech-\nniques in messages from diplomats and authorities of world powers, Procesamiento del Lenguaje\nNatural 71 (2023) 397\u2013407.\n[30] G. Faggioli, N. Ferro, P. Galu\u0161\u010d\u00e1kov\u00e1, A. Garc\u00eda Seco de Herrera (Eds.), Working Notes of CLEF\n2024 - Conference and Labs of the Evaluation Forum, CLEF 2024, 2024.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Overview of the CLEF-2024 checkthat! lab task 3 on persuasion techniques", "author": ["J Piskorski", "A Jorge", "MP Silvano", "N Guimar\u00e3es"], "pub_year": "2024", "venue": "NA", "abstract": "We present an overview of CheckThat! Lab\u2019s 2024 Task 3, which focuses on detecting 23  persuasion techniques at the text-span level in online media. The task covers five languages,"}, "filled": false, "gsrank": 415, "pub_url": "https://ceur-ws.org/Vol-3740/paper-26.pdf", "author_id": ["xDQ3yuQAAAAJ", "wMjqg7QAAAAJ", "OFwPIwcAAAAJ", "1yxV2uwAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:fC0APAbpGA8J:scholar.google.com/&output=cite&scirp=414&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D410%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=fC0APAbpGA8J&ei=ULWsaODNLLTWieoP1pCJ2AY&json=", "num_citations": 4, "citedby_url": "/scholar?cites=1087875522995694972&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:fC0APAbpGA8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ceur-ws.org/Vol-3740/paper-26.pdf"}}, {"title": "Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media", "year": "2019", "pdf_data": "Multi-Task Ordinal Regression for Jointly Predicting\nthe Trustworthiness and the Leading Political Ideology of News Media\nRamy Baly1, Georgi Karadzhov2, Abdelrhman Saleh3,\nJames Glass1, Preslav Nakov4\n1MIT Computer Science and Arti\ufb01cial Intelligence Laboratory, MA, USA\n2SiteGround Hosting EOOD, Bulgaria,3Harvard University, MA, USA\n4Qatar Computing Research Institute, HBKU, Qatar\nfbaly, glassg@mit.edu ,georgi.m.karadjov@gmail.com\nabdelrhman saleh@college.harvard.edu ,pnakov@hbku.edu.qa\nAbstract\nIn the context of fake news, bias, and propa-\nganda, we study two important but relatively\nunder-explored problems: ( i)trustworthiness\nestimation (on a 3-point scale) and ( ii)po-\nlitical ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as op-\nposed to evaluating individual articles. In par-\nticular, we propose a multi-task ordinal re-\ngression framework that models the two prob-\nlems jointly. This is motivated by the obser-\nvation that hyper-partisanship is often linked\nto low trustworthiness, e.g., appealing to emo-\ntions rather than sticking to the facts, while\ncenter media tend to be generally more impar-\ntial and trustworthy. We further use several\nauxiliary tasks, modeling centrality, hyper-\npartisanship, as well as left-vs.-right bias on\na coarse-grained scale. The evaluation results\nshow sizable performance gains by the joint\nmodels over models that target the problems\nin isolation.\n1 Introduction\nRecent years have seen the rise of social media,\nwhich has enabled people to virtually share in-\nformation with a large number of users without\nregulation or quality control. On the bright side,\nthis has given an opportunity for anyone to be-\ncome a content creator, and has also enabled a\nmuch faster information dissemination. However,\nit has also opened the door for malicious users to\nspread disinformation and misinformation much\nfaster, enabling them to easily reach audience at\na scale that was never possible before. In some\ncases, this involved building sophisticated pro\ufb01les\nfor individuals based on a combination of psycho-\nlogical characteristics, meta-data, demographics,\nand location, and then micro-targeting them with\npersonalized \u201cfake news\u201d with the aim of achiev-\ning some political or \ufb01nancial gains (Lazer et al.,\n2018; V osoughi et al., 2018).A number of fact-checking initiatives have been\nlaunched so far, both manual and automatic, but\nthe whole enterprise remains in a state of cri-\nsis: by the time a claim is \ufb01nally fact-checked, it\ncould have reached millions of users, and the harm\ncaused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking\nentire news outlets, which can be done in advance.\nThen, we could fact-check the news before they\nwere even written: by checking how trustworthy\nthe outlets that published them are. Knowing the\nreliability of a medium is important not only when\nfact-checking a claim (Popat et al., 2017; Nguyen\net al., 2018), but also when solving article-level\ntasks such as \u201cfake news\u201d and click-bait detection\n(Brill, 2001; Finberg et al., 2002; Hardalov et al.,\n2016; Karadzhov et al., 2017; De Sarkar et al.,\n2018; Pan et al., 2018; P \u00b4erez-Rosas et al., 2018)\nPolitical ideology (or left/right bias) is a related\ncharacteristic, e.g., extreme left/right media tend\nto be propagandistic, while center media are more\nfactual, and thus generally more trustworthy. This\nconnection can be clearly seen in Figure 1.\nFigure 1: Correlation between bias and factuality for\nthe news outlets in the Media Bias/Fact Check website.arXiv:1904.00542v1  [cs.IR]  1 Apr 2019\nDespite the connection between factuality and\nbias, previous research has addressed them as in-\ndependent tasks, even when the underlying dataset\nhad annotations for both (Baly et al., 2018). In\ncontrast, here we solve them jointly. Our contri-\nbutions can be summarized as follows:\n\u000fWe study an under-explored but arguably im-\nportant problem: predicting the factuality of\nreporting of news media. Moreover, unlike\nprevious work, we do this jointly with the\ntask of predicting political bias.\n\u000fAs factuality and bias are naturally de\ufb01ned on\nan ordinal scale (factuality: from lowtohigh,\nand bias: from extreme-left toextreme-right ),\nwe address them as ordinal regression. Us-\ning multi-task ordinal regression is novel for\nthese tasks, and it is also an under-explored\ndirection in machine learning in general.\n\u000fWe design a variety of auxiliary subtasks\nfrom the bias labels: modeling centrality,\nhyper-partisanship, as well as left-vs.-right\nbias on a coarse-grained scale.\n2 Related Work\nFactuality of Reporting Previous work has\nmodeled the factuality of reporting at the medium\nlevel by checking the general stance of the tar-\nget medium with respect to known manually fact-\nchecked claims, without access to gold labels\nabout the overall medium-level factuality of re-\nporting (Mukherjee and Weikum, 2015; Popat\net al., 2016, 2017, 2018).\nThe trustworthiness of Web sources has also\nbeen studied from a Data Analytics perspective,\ne.g., Dong et al. (2015) proposed that a trust-\nworthy source is one that contains very few false\nclaims. In social media, there has been research\ntargeting the user, e.g., \ufb01nding malicious users\n(Mihaylov and Nakov, 2016; Mihaylova et al.,\n2018; Mihaylov et al., 2018), sockpuppets (Maity\net al., 2017), Internet water army (Chen et al.,\n2013), and seminar users (Darwish et al., 2017).\nUnlike the above work, here we study source\nreliability as a task in its own right, using man-\nual gold annotations speci\ufb01c for the task and as-\nsigned by independent fact-checking journalists.\nMoreover, we address the problem as one of ordi-\nnal regression on a three-point scale, and we solve\nit jointly with political ideology prediction in a\nmulti-task learning setup, using several auxiliary\ntasks.Predicting Political Ideology In previous work,\npolitical ideology, also known as media bias, was\nused as a feature for \u201cfake news\u201d detection (Horne\net al., 2018a). It has also been the target of\nclassi\ufb01cation, e.g., Horne et al. (2018b) predicted\nwhether an article is biased ( political orbias) vs.\nunbiased. Similarly, Potthast et al. (2018) classi-\n\ufb01ed the bias in a target article as ( i) left vs. right\nvs. mainstream, or as ( ii) hyper-partisan vs. main-\nstream. Left-vs-right bias classi\ufb01cation at the ar-\nticle level was also explored by Kulkarni et al.\n(2018), who modeled both the textual and the URL\ncontents of the target article. There has been also\nwork targeting bias at the phrase or the sentence\nlevel (Iyyer et al., 2014), focusing on political\nspeeches (Sim et al., 2013) or legislative docu-\nments (Gerrish and Blei, 2011), or targeting users\nin Twitter (Preot \u00b8iuc-Pietro et al., 2017). Another\nline of related work focuses on propaganda, which\ncan be seen as a form of extreme bias (Rashkin\net al., 2017; Barr \u00b4on-Cede \u02dcno et al., 2019a,b). See\nalso a recent position paper (Pitoura et al., 2018)\nand an overview paper on bias on the Web (Baeza-\nYates, 2018). Unlike the above work, here we fo-\ncus on predicting the political ideology of news\nmedia outlets.\nIn our previous work (Baly et al., 2018), we did\ntarget the political bias of entire news outlets, as\nopposed to working at the article level (we also\nmodeled factuality of reporting, but as a separate\ntask without trying multi-task learning). In addi-\ntion to the text of the articles published by the tar-\nget news medium, we used features extracted from\nits corresponding Wikipedia page and Twitter pro-\n\ufb01le, as well as analysis of its URL structure and\ntraf\ufb01c information about it from Alexa rank. In\nthe present work, we use a similar set of features,\nbut we treat the problem as one of ordinal regres-\nsion. Moreover, we model the political ideology\nand the factuality of reporting jointly in a multi-\ntask learning setup, using several auxiliary tasks.\nMultitask Ordinal Regression Ordinal regres-\nsion is well-studied and is commonly used for text\nclassi\ufb01cation on an ordinal scale, e.g., for senti-\nment analysis on a 5-point scale (He et al., 2016;\nRosenthal et al., 2017a). However, multi-task or-\ndinal regression remains an understudied problem.\nYu et al. (2006) proposed a Bayesian framework\nfor collaborative ordinal regression, and demon-\nstrated that modeling multiple ordinal regression\ntasks outperforms single-task models.\nWalecki et al. (2016) were interested in jointly\npredicting facial action units and their intensity\nlevel. They argued that, due to the high num-\nber of classes, modeling these tasks independently\nwould be inef\ufb01cient. Thus, they proposed the cop-\nula ordinal regression model for multi-task learn-\ning and demonstrated that it can outperform vari-\nous single-task setups. We use this model in our\nexperiments below.\nBalikas et al. (2017) used multi-task ordinal\nregression for the task of \ufb01ne-grained sentiment\nanalysis. In particular, they introduced an auxil-\niary coarse-grained task on a 3-point scale, and\ndemonstrated that it can improve the results for\nsentiment analysis on the original 5-point scale.\nInspired by this, below we experiment with dif-\nferent granularity for political bias; however, we\nexplore a larger space of possible auxiliary tasks.\n3 Method\nCopula Ordinal Regression We use the Cop-\nula Ordinal Regression (COR) model, which was\noriginally proposed by Walecki et al. (2016) to es-\ntimate the intensities of facial action units (AUs).\nThe model uses copula functions and conditional\nrandom \ufb01elds (CRFs) to approximates the learning\nof the joint probability distribution function (PDF)\nof the facial AUs (random variables), using the bi-\nvariate joint distributions capturing dependencies\nbetween AU pairs. It was motivated by the fact\nthat ( i) many facial AUs co-exist with different\nlevels of intensity, ( ii) some AUs co-occur more\noften than others, and ( iii) some AUs depend on\nthe intensity of other units.\nWe can draw an analogy between modeling fa-\ncial AUs and modeling news media, where each\nmedium expresses a particular bias (political ide-\nology) and can also be associated with a particu-\nlar level of factuality. Therefore, bias and factual-\nity can be analogous to the facial AUs in (Walecki\net al., 2016), and represent two aspects of news re-\nporting, each being modeled on a multi-point ordi-\nnal scale. In particular, we model bias on a 7-point\nscale ( extreme-left ,left,center-left ,center ,center-\nright ,right , and extreme-right ), and factuality on\na 3-point scale ( low,mixed , and high).\nIn our case, we train the COR model to predict\nthe joint PDF between political bias and factual-\nity of reporting. This could potentially work well\ngiven the inherent inter-dependency between the\ntwo tasks as we have seen on Figure 1.Auxiliary Tasks We use a variety of auxiliary\ntasks, derived from the bias labels. This includes\nconverting the 7-point scale to ( i) 5-point and 3-\npoint scales, similarly to (Balikas et al., 2017), and\nto (ii) a 2-point scale in two ways to model ex-\ntreme partisanship, and centrality. Here is the list\nof the auxiliary tasks we use with precise de\ufb01ni-\ntion of the label mappings:\n\u000fBias5-way: Predict bias on a 5-pt scale;\n1:extreme-left , 2:left, 3:fcenter-left, center,\ncenter-rightg, 4:right , and 5: extreme-right .\n\u000fBias3-way: Predict bias on a 3-pt scale;\n1:fextreme-left, leftg, 2:fcenter-left, center,\ncenter-rightg, and 3:fright, extreme-right g.\n\u000fBias-extreme: Predict extreme vs. non-\nextreme partisanship on a 2-pt scale;\n1:fextreme-left, extreme-right g, 2:fleft,\ncenter-left, center, center-right, right g.\n\u000fBias-center: Predict center vs. non-center\npolitical ideology on a 2-pt scale, ignoring\npolarity: 1:fextreme-left, left, right, extreme-\nrightg, 2:fcenter-left, center, center-right g.\nFeatures We used the features from (Baly et al.,\n2018)1. We gathered a sample of articles from the\ntarget medium, and we calculated features such as\nPOS tags, linguistic cues, sentiment scores, com-\nplexity, morality, as well as embeddings. We also\nused the Wikipedia page of the medium (if any)\nto generate document embedding. Then, we col-\nlected metadata from the medium\u2019s Twitter ac-\ncount (if any), e.g., whether is is veri\ufb01ed, num-\nber of followers, whether the URL in the Twitter\npage matches the one of the medium. Finally, we\nadded Web-based features that ( i) model the ortho-\ngraphic structure of the medium\u2019s URL address,\nand ( ii) analyze the Web-traf\ufb01c information about\nthe medium\u2019s website, as found in Alexa rank.2\n4 Experiments and Evaluation\nData We used the MBFC dataset (Baly et al.,\n2018) that has 1,066 news media manually anno-\ntated for factuality (3-pt scale: high,mixed ,low)\nand political bias (7-pt scale: from extreme-left to\nextreme-right ). This dataset was annotated by vol-\nunteers using a detailed methodology3that is de-\nsigned to guarantee annotation objectivity.\n1https://github.com/ramybaly/\nNews-Media-Reliability\n2https://www.alexa.com/siteinfo\n3For details, see https://mediabiasfactcheck.\ncom/methodology/\nName URL Bias Factuality Twitter Handle Wikipedia page\nLondon Web News londonwebnews.com Extreme Left Low @londonwebnews N/A\nDaily Mirror www.mirror.co.uk Left Mixed @DailyMirror \u02dc/Daily_Mirror\nNBC News www.nbcnews.com Center-Left High @nbcnews \u02dc/NBC_News\nAssociated Press apnews.com Center Very High @apnews \u02dc/Associated_Press\nGulf News gulfnews.com Center-Right High @gulf news \u02dc/Gulf_News\nRussia Insider russia-insider.com Right Mixed @russiainsider \u02dc/Russia_Insider\nBreitbart www.breitbart.com Extreme Right Low @BreitbartNews \u02dc/Breitbart_News\nTable 1: Examples of media and their labels for bias and factuality of reporting derived from MBFC.\nFurthermore, readers can provide their own feed-\nback on existing annotations, and in case of a large\ndiscrepancy, annotation is adjusted after a thor-\nough review. Therefore, we believe the annotation\nquality is good enough to experiment with. We\nnoticed that 117 media had lowfactuality because\nthey publish satire andpseudo-science , neither of\nwhich has a political perspective. Since we are in-\nterested in modeling the relation between factual-\nity and bias, we excluded those websites, thus end-\ning up with 949 news media. Some examples from\nthis dataset are shown in Table 1 with both factual-\nity and bias labels, in addition to their correspond-\ning Twitter handles and Wikipedia pages. Overall,\n64% of the media in our dataset have Wikipedia\npages, and 65% have Twitter accounts. Table 2\nfurther provides detailed statistics about the label\ndistribution in the MBFC dataset.\nFactuality Bias\nLow 198 Extreme-Left 23\nMixed 282 Left 151\nHigh 469 Center-Left 200\nCenter 139\nCenter-Right 105\nRight 164\nExtreme-Right 167\nTable 2: Labels counts in the MBFC dataset that we\nused in our experiments.\nExperimental Setup We used the implementa-\ntion4of the Copula Ordinal Regression (COR)\nmodel as described in (Walecki et al., 2016). In\nour experiments, we used 5-fold cross-validation,\nwhere for each fold we split the training dataset\ninto a training part and a validation part, and we\nused the latter to \ufb01ne-tune the model\u2019s hyper-\nparameters, optimizing for Mean Absolute Error\n(MAE). MAE is an appropriate evaluation mea-\nsure given the ordinal nature of the tasks.\n4https://github.com/RWalecki/copula_\nordinal_regressionThese hyper-parameters include the copula func-\ntion ( Gumbel vs.Frank ), the marginal distribution\n(normal vs.sigmoid ), the number of training it-\nerations, the optimizer ( gradient descent ,BFGS ),\nand the connection density of the CRFs. We report\nboth MAE and MAEM, which is a variant of MAE\nthat is more robust to class imbalance. See (Bac-\ncianella et al., 2009; Rosenthal et al., 2017b) for\nmore details about MAEMvs. MAE. We compare\nthe results to two baselines: ( i) majority class, and\n(ii) single-task ordinal regression.\nResults and Discussion Table 3 shows the eval-\nuation results for the COR model when trained\nto jointly model the main task ( shown in the\ncolumns ) using combinations of auxiliary tasks\n(shown in the rows ). We can see that the single-\ntask ordinal regression model performs much bet-\nter than the majority class baseline based on both\nevaluation measures. We can further see that\nthe performance on the main task improves when\njointly modeling several auxiliary tasks. This im-\nprovement depends on the auxiliary tasks in use.\nFor factuality prediction, it turns out that the\ncombination of bias-center +bias-extreme yields\nthe best overall MAE of 0.481. This makes sense\nand aligns well with the intuition that knowing\nwhether a medium is centric or hyper-partisan is\nimportant to predict the factuality of its reporting.\nFor instance, a news medium without a political\nideology tends to be more trustworthy compared\nto an extremely biased one, regardless of their po-\nlarity (left or right), as we should expect based on\nthe data distribution shown in Figure 1 above.\nFor bias prediction (at a 7-point left-to-right\nscale), a joint model that uses political bias at dif-\nferent levels of granularity (5-point and 3-point)\nas auxiliary tasks yields the best overall MAE of\n1.479. This means that jointly modeling bias with\nthe same information at coarser levels of granu-\nlarity, i.e., adding 3-point and 5-point as auxiliary\ntasks, reduces the number of gross mistakes.\nFactuality Bias\nAuxiliary Tasks MMAEM MMAEMM MAE MAEM\n(None) majority class . . . . . . . . . . . . . . . . . . . . . . . . . . . 0.714 1.000 1.798 1.857\n(None) single-task COR . . . . . . . . . . . . . . . . . . . . . . . . . 0.514 0.567 1.582 1.728\n+bias. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0.526 0.566 \u2013 \u2013\n+factuality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u2013 \u2013 1.584 1.695\n+bias5-way . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0.495 0.541 1.504 (1.485) 1.627 (1.647)\n+bias3-way . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0.497 0.548 1.528 (1.498) 1.658 (1.654)\n+bias-center . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0.509 0.561 1.594 (1.535) 1.745 (1.695)\n+bias-extreme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0.498 0.550 1.584 (1.558) 1.743 (1.726)\n+bias5-way +bias3-way . . . . . . . . . . . . . . . . . . . . . . . . . 0.493 0.541 1.479 (1.475 )1.637 (1.623 )\n+bias-center +bias-extreme . . . . . . . . . . . . . . . . . . . . . . 0.481 0.529 1.563 (1.526) 1.714 (1.672)\n+bias5-way +bias3-way +bias-center +bias-extreme 0.485 0.537 1.513 (1.504) 1.665 (1.677)\nTable 3: Evaluating the copula ordinal regression model trained to jointly model the main task ( shown in the\ncolumns ) and different auxiliary tasks ( shown in the rows ). The results in parentheses correspond to the case when\nfactuality is added as an additional auxiliary task (only applicable when the main task is bias prediction).\nE.g., predicting extreme-left instead of extreme-\nright , since the model is encouraged by the aux-\niliary tasks to learn the correct polarity, regard-\nless of its intensity. We can see that factuality\nis not very useful as an auxiliary task by itself\n(MAE=1.584 and MAEM=1.695). In other words,\na medium with low factuality could be extremely\nbiased to either the right or to the left. Therefore,\nrelying on factuality alone to predict bias might in-\ntroduce severe errors, e.g., confusing extreme-left\nwith extreme-right, thus leading to higher MAE\nscores. This can be remedied by adding factuality\nto the mix of other auxiliary tasks to model the\nmain task (7-point bias prediction). The results\nof these experiments, shown in parentheses in Ta-\nble 3, indicate that adding factuality to any combi-\nnation of auxiliary tasks consistently yields lower\nMAE scores. In particular, modeling the combi-\nnation of factuality +bias5-way +bias3-way yields\nthe best results (MAE=1.475 and MAEM=1.623).\nThis result indicates that factuality provides com-\nplementary information that can help predict bias.\nWe ran a two-tailed t-test for statistical signif-\nicance, which is suitable for an evaluation mea-\nsure such as MAE, to con\ufb01rm the improvements\nthat were introduced by the multi-task setup. We\nfound that the best models (shown in bold in Ta-\nble 3) outperformed both the corresponding major-\nity class baselines with a p-value \u00140.001, and the\ncorresponding single-task ordinal regression base-\nlines with a p-value \u00140.02.\nFinally, we compared the above results to our\nprevious work (Baly et al., 2018) by independently\ntraining a Support Vector Machine (SVM) classi-\n\ufb01er for each task, using the same features.The resulting MAE was 0.450 for factuality and\n1.184 for bias prediction, which is slightly better\nthen our results (yet, very comparable for factual-\nity). However, our goal here is to emphasize the\nadvantages of modeling the two tasks jointly.\n5 Conclusion and Future Work\nWe have presented a multi-task ordinal regres-\nsion framework for jointly predicting trustworthi-\nness and political ideology of news media sources,\nusing several auxiliary tasks, e.g., based on a\ncoarser-grained scales or modeling extreme parti-\nsanship. Overall, we have observed sizable per-\nformance gains in terms of reduced MAE by the\nmulti-task ordinal regression models over single-\ntask models for each of the two individual tasks.\nIn future work, we want to try more auxiliary\ntasks, and to experiment with other languages. We\nfurther plan to go beyond left vs. right , which is\nnot universal and can exhibit regional speci\ufb01city\n(Tavits and Letki, 2009), and to model other kinds\nof biases, e.g., eurosceptic vs. europhile ,national-\nistvs.globalist ,islamist vs. secular , etc.\nAcknowledgments\nThis research is part of the Tanbih project,5which\naims to limit the effect of \u201cfake news\u201d, propa-\nganda and media bias by making users aware\nof what they are reading. The project is de-\nveloped in collaboration between the MIT Com-\nputer Science and Arti\ufb01cial Intelligence Labora-\ntory (CSAIL) and the Qatar Computing Research\nInstitute (QCRI), HBKU.\n5http://tanbih.qcri.org/\nReferences\nStefano Baccianella, Andrea Esuli, and Fabrizio Sebas-\ntiani. 2009. Evaluation measures for ordinal regres-\nsion. In Proceedings of the 9th IEEE International\nConference on Intelligent Systems Design and Ap-\nplications , ISDA \u201909, pages 283\u2013287, Pisa, Italy.\nRicardo Baeza-Yates. 2018. Bias on the web. Com-\nmun. ACM , 61(6):54\u201361.\nGeorgios Balikas, Simon Moura, and Massih-Reza\nAmini. 2017. Multitask learning for \ufb01ne-grained\nTwitter sentiment analysis. In Proceedings of the\n40th International ACM SIGIR Conference on Re-\nsearch and Development in Information Retrieval ,\nSIGIR \u201917, pages 1005\u20131008, Tokyo, Japan.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing ,\nEMNLP \u201918, pages 3528\u20133539, Brussels, Belgium.\nAlberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019a. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the Thirty-Third AAAI Conference\non Arti\ufb01cial Intelligence , AAAI\u201919, Honolulu, HI,\nUSA.\nAlberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019b. Proppy: Or-\nganizing news coverage on the basis of their propa-\ngandistic content. Information Processing and Man-\nagement .\nAnn M Brill. 2001. Online journalists embrace new\nmarketing function. Newspaper Research Journal ,\n22(2):28.\nCheng Chen, Kui Wu, Venkatesh Srinivasan, and\nXudong Zhang. 2013. Battling the Internet Water\nArmy: detection of hidden paid posters. In Proceed-\nings of the 2013 IEEE/ACM International Confer-\nence on Advances in Social Networks Analysis and\nMining , ASONAM \u201913, pages 116\u2013120, Niagara,\nCanada.\nKareem Darwish, Dimitar Alexandrov, Preslav Nakov,\nand Yelena Mejova. 2017. Seminar users in the\nArabic Twitter sphere. In Proceedings of the\n9th International Conference on Social Informatics ,\nSocInfo \u201917, pages 91\u2013108, Oxford, UK.\nSohan De Sarkar, Fan Yang, and Arjun Mukherjee.\n2018. Attending sentences to detect satirical fake\nnews. In Proceedings of the 27th International\nConference on Computational Linguistics , COL-\nING \u201918, pages 3371\u20133380, Santa Fe, NM, USA.\nXin Luna Dong, Evgeniy Gabrilovich, Kevin Murphy,\nVan Dang, Wilko Horn, Camillo Lugaresi, Shao-\nhua Sun, and Wei Zhang. 2015. Knowledge-based\ntrust: Estimating the trustworthiness of web sources.\nProc. VLDB Endow. , 8(9):938\u2013949.Howard Finberg, Martha L Stone, and Diane Lynch.\n2002. Digital journalism credibility study. Online\nNews Association. Retrieved November , 3:2003.\nSean M. Gerrish and David M. Blei. 2011. Predict-\ning legislative roll calls from text. In Proceedings of\nthe 28th International Conference on International\nConference on Machine Learning , ICML \u201911, pages\n489\u2013496, Bellevue, Washington, USA.\nMomchil Hardalov, Ivan Koychev, and Preslav Nakov.\n2016. In search of credible news. In Proceedings\nof the 17th International Conference on Arti\ufb01cial In-\ntelligence: Methodology, Systems, and Applications ,\nAIMSA \u201916, pages 172\u2013180, Varna, Bulgaria.\nYunchao He, Liang-Chih Yu, Chin-Sheng Yang,\nK Robert Lai, and Weiyi Liu. 2016. YZU-NLP team\nat semeval-2016 task 4: Ordinal sentiment classi\ufb01-\ncation using a recurrent convolutional network. In\nProceedings of the 10th International Workshop on\nSemantic Evaluation , SemEval \u201916, pages 251\u2013255,\nSan Diego, CA, USA.\nBenjamin Horne, Sara Khedr, and Sibel Adali. 2018a.\nSampling the news producers: A large news and fea-\nture data set for the study of the complex media land-\nscape. In Proceedings of the Twelfth International\nConference on Web and Social Media , ICWSM \u201918,\npages 518\u2013527, Stanford, CA, USA.\nBenjamin D. Horne, William Dron, Sara Khedr, and\nSibel Adali. 2018b. Assessing the news landscape:\nA multi-module toolkit for evaluating the credibility\nof news. In Proceedings of the The Web Conference ,\nWWW \u201918, pages 235\u2013238, Lyon, France.\nMohit Iyyer, Peter Enns, Jordan Boyd-Graber, and\nPhilip Resnik. 2014. Political ideology detection us-\ning recursive neural networks. In Proceedings of the\n52nd Annual Meeting of the Association for Com-\nputational Linguistics , pages 1113\u20131122, Baltimore,\nMD, USA.\nGeorgi Karadzhov, Pepa Gencheva, Preslav Nakov, and\nIvan Koychev. 2017. We built a fake news & click-\nbait \ufb01lter: What happened next will blow your mind!\nInProceedings of the International Conference on\nRecent Advances in Natural Language Processing ,\nRANLP \u201917, pages 334\u2013343, Varna, Bulgaria.\nVivek Kulkarni, Junting Ye, Steven Skiena, and\nWilliam Yang Wang. 2018. Multi-view models for\npolitical ideology detection of news articles. In Pro-\nceedings of the Conference on Empirical Methods in\nNatural Language Processing , EMNLP \u201918, pages\n3518\u20133527, Brussels, Belgium.\nDavid M.J. Lazer, Matthew A. Baum, Yochai Ben-\nkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo\nMenczer, Miriam J. Metzger, Brendan Nyhan, Gor-\ndon Pennycook, David Rothschild, Michael Schud-\nson, Steven A. Sloman, Cass R. Sunstein, Emily A.\nThorson, Duncan J. Watts, and Jonathan L. Zit-\ntrain. 2018. The science of fake news. Science ,\n359(6380):1094\u20131096.\nSuman Kalyan Maity, Aishik Chakraborty, Pawan\nGoyal, and Animesh Mukherjee. 2017. Detection of\nsockpuppets in social media. In Proceedings of the\nACM Conference on Computer Supported Coopera-\ntive Work and Social Computing , CSCW \u201917, pages\n243\u2013246, Portland, OR, USA.\nTodor Mihaylov, Tsvetomila Mihaylova, Preslav\nNakov, Llu \u00b4\u0131s M `arquez, Georgi Georgiev, and Ivan\nKoychev. 2018. The dark side of news community\nforums: Opinion manipulation trolls. Internet Re-\nsearch , 28(5):1292\u20131312.\nTodor Mihaylov and Preslav Nakov. 2016. Hunting for\ntroll comments in news community forums. In Pro-\nceedings of the 54th Annual Meeting of the Associa-\ntion for Computational Linguistics , ACL \u201916, pages\n399\u2013405, Berlin, Germany.\nTsvetomila Mihaylova, Preslav Nakov, Llu \u00b4\u0131s M`arquez,\nAlberto Barr \u00b4on-Cede \u02dcno, Mitra Mohtarami, Georgi\nKaradjov, and James Glass. 2018. Fact checking in\ncommunity forums. In Proceedings of the Thirty-\nSecond AAAI Conference on Arti\ufb01cial Intelligence ,\nAAAI \u201918, pages 879\u2013886, New Orleans, LA, USA.\nSubhabrata Mukherjee and Gerhard Weikum. 2015.\nLeveraging joint interactions for credibility analy-\nsis in news communities. In Proceedings of the\n24th ACM International on Conference on Informa-\ntion and Knowledge Management , CIKM \u201915, pages\n353\u2013362, Melbourne, Australia.\nAn T. Nguyen, Aditya Kharosekar, Matthew Lease,\nand Byron C. Wallace. 2018. An interpretable joint\ngraphical model for fact-checking from crowds. In\nProceedings of the Thirty-Second AAAI Conference\non Arti\ufb01cial Intelligence , AAAI \u201918, New Orleans,\nLA, USA.\nJeff Z. Pan, Siyana Pavlova, Chenxi Li, Ningxi Li,\nYangmei Li, and Jinshuo Liu. 2018. Content based\nfake news detection using knowledge graphs. In\nProceedings of the International Semantic Web Con-\nference , ISWC \u201918, Monterey, CA, USA.\nVer\u00b4onica P \u00b4erez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In Proceedings of the 27th In-\nternational Conference on Computational Linguis-\ntics, COLING \u201918, pages 3391\u20133401, Santa Fe, NM,\nUSA.\nEvaggelia Pitoura, Panayiotis Tsaparas, Giorgos\nFlouris, Irini Fundulaki, Panagiotis Papadakos,\nSerge Abiteboul, and Gerhard Weikum. 2018. On\nmeasuring bias in online information. SIGMOD\nRec., 46(4):16\u201321.\nKashyap Popat, Subhabrata Mukherjee, Jannik\nStr\u00a8otgen, and Gerhard Weikum. 2016. Credi-\nbility assessment of textual claims on the web.\nInProceedings of the 25th ACM International\non Conference on Information and Knowledge\nManagement , CIKM \u201916, pages 2173\u20132178,\nIndianapolis, IN, USA.Kashyap Popat, Subhabrata Mukherjee, Jannik\nStr\u00a8otgen, and Gerhard Weikum. 2017. Where the\ntruth lies: Explaining the credibility of emerging\nclaims on the Web and social media. In Proceedings\nof the 26th International Conference on World Wide\nWeb Companion , WWW \u201917, pages 1003\u20131012,\nPerth, Australia.\nKashyap Popat, Subhabrata Mukherjee, Jannik\nStr\u00a8otgen, and Gerhard Weikum. 2018. CredEye: A\ncredibility lens for analyzing and explaining misin-\nformation. In Proceedings of The Web Conference\n2018 , WWW \u201918, pages 155\u2013158, Lyon, France.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2018. A stylo-\nmetric inquiry into hyperpartisan and fake news. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics , ACL \u201918,\npages 231\u2013240, Melbourne, Australia.\nDaniel Preot \u00b8iuc-Pietro, Ye Liu, Daniel Hopkins, and\nLyle Ungar. 2017. Beyond binary labels: Political\nideology prediction of Twitter users. In Proceed-\nings of the 55th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers) , ACL \u201917, pages 729\u2013740, Vancouver, Canada.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing , EMNLP \u201917, pages 2931\u20132937, Copen-\nhagen, Denmark.\nSara Rosenthal, Noura Farra, and Preslav Nakov.\n2017a. SemEval-2017 task 4: Sentiment analysis\nin Twitter. In Proceedings of the 11th International\nWorkshop on Semantic Evaluation , SemEval \u201917,\npages 502\u2013518, Vancouver, Canada.\nSara Rosenthal, Noura Farra, and Preslav Nakov.\n2017b. SemEval-2017 task 4: Sentiment analysis\nin Twitter. In Proceedings of the 11th International\nWorkshop on Semantic Evaluation , SemEval \u201917,\npages 502\u2013518, Vancouver, Canada.\nYanchuan Sim, Brice D. L. Acree, Justin H. Gross, and\nNoah A. Smith. 2013. Measuring ideological pro-\nportions in political speeches. In Proceedings of the\n2013 Conference on Empirical Methods in Natural\nLanguage Processing , EMNLP \u201913, pages 91\u2013101,\nSeattle, WA, USA.\nMargit Tavits and Natalia Letki. 2009. When left is\nright: Party ideology and policy in Post-Communist\nEurope. The American Political Science Review ,\n103(4):555\u2013569.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151.\nRobert Walecki, Ognjen Rudovic, Vladimir Pavlovic,\nand Maja Pantic. 2016. Copula ordinal regression\nfor joint estimation of facial action unit intensity. In\nProceedings of the IEEE Conference on Computer\nVision and Pattern Recognition , pages 4902\u20134910.\nShipeng Yu, Kai Yu, V olker Tresp, and Hans-Peter\nKriegel. 2006. Collaborative ordinal regression. In\nProceedings of the 23rd international conference on\nMachine learning , pages 1089\u20131096. ACM.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media", "author": ["R Baly", "G Karadzhov", "A Saleh", "J Glass"], "pub_year": "2019", "venue": "arXiv preprint arXiv \u2026", "abstract": "In the context of fake news, bias, and propaganda, we study two important but relatively  under-explored problems: (i) trustworthiness estimation (on a 3-point scale) and (ii) political"}, "filled": false, "gsrank": 416, "pub_url": "https://arxiv.org/abs/1904.00542", "author_id": ["zJuI3D8AAAAJ", "hK7sqzAAAAAJ", "_SV2VCYAAAAJ", "pfGI-KcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:iajohVQTm3UJ:scholar.google.com/&output=cite&scirp=415&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D410%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=iajohVQTm3UJ&ei=ULWsaODNLLTWieoP1pCJ2AY&json=", "num_citations": 89, "citedby_url": "/scholar?cites=8474388377572518025&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:iajohVQTm3UJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1904.00542"}}]