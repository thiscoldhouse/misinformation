[{"title": "Misinformation exploits outrage to spread online", "year": "2024", "pdf_data": " Submitted Manuscript: Confidential   \n \n0 \n \nThis is the author's version of the work. It is posted here by permission of the \nAAAS for personal use, not for redistribution. The definitive version was \npublished in Science on 11.28.24 , DOI: \nhttps://www.science.org/doi/10.1126/science.adl2829  \n 5 \nTitle:  Misinformation exploits outrage to spread online  \nAuthors:  Killian L. McLoughlin1,2\u2020, William J. Brady3*\u2020, Aden Goolsbee4, Ben Kaiser5, Kate \nKlonick6,7,8,9, M. J. Crockett1,10* \nAffiliations:   \n1Department of Psychology, Princeton University; Princeton, NJ 08544, USA.  10 \n2School of Public and International Affairs, Princeton University; Princeton, NJ 08544, USA.  \n3Kellogg School of Management, Northwestern University; Evanston, IL 60208, USA.  \n4Department of Psychology, Yale University; New Haven, 06520, USA.  \n5Center for Information Technology Policy, Princeton University; Princeton, NJ 08544, USA  \n6School of Law, St. John\u2019s University; Queens, New York, 11439, USA.  15 \n7Information Society Project, Yale University; New Haven, 06520, USA.  \n8Brookings Institution; Washington, DC 20036, USA.  \n9Berkman Klein Center, Harvard University; Cambridge, MA 02138, USA.  \n10University Center for Human Values, Princeton University; Princeton, NJ 08544, USA.  \n\u2020These authors contributed equally to this work. 20 \n*Corresponding author. Email: william.brady@kellogg.northwestern.edu and \nmj.crockett@princeton.edu  \n \nAbstract:  We test a hypothesis that misinformation exploits outrage to spread online, examining \ngeneralizability across multiple platforms, time periods, and classifications of misinformation. 25 \nOutrage is highly engaging and need not be accurate  to achieve its communicative goals, making \nit an attractive signal to embed in misinformation. In eight studies using U.S. data from \nFacebook ( N=1,063,298 links) and Twitter ( N=44,529  tweets , N=24,007 users ) and two \nbehavioral experiments ( N=1,475  participants ), we show that (1) misinformation  sources  evoke \nmore outrage than trustworthy news  sources ; (2) outrage facilitates the sharing of misinformation  30 \nat least as strongly as trustworthy news ; and (3) users are more willing to share outrage -evoking \nmisinformation without reading it first. Consequently, outrage -evoking misinformation may be \ndifficult to mitigate with interventions that assume users want to share  accurate information.  \n  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 1 Main Text:  Online sharing of misinformation \u2013 defined here as false and misleading information \n(1\u20134)\u2013 remains a major concern (5\u20138). Although estimates of the prevalence of misinformation \nvary widely (4, 9\u201311), it has been linked to increases in political polarization (12, 13), anti -\ndemocratic sentiment (14\u201316), and increased vaccine hesitancy (7, 17, 18). Yet despite investing \nin detecting and reducing misinformation, digital platforms have had only limited success in 5 \ncurbing its spread (19, 20). \nHere we investigate the relationship between misinformation and moral outrage, a mixture of \nanger and disgust triggered by perceived moral transgressions (21\u201325). Moral outrage \n(henceforth \u2018outrage\u2019) has several unique properties that could promote the spread of \nmisinformation. First, outrage is highly engaging: social media posts expressing outrage are liked 10 \nand shared more, training users to express more outrage and ranking algorithms to amplify it (26, \n27). Second, outrage expressions can serve communicative goals that do not depend on \ninformation accuracy, like signaling loyalty to a political group or broadcasting a moral stance \n(12, 27\u201335). Consequently, outrage -evoking misinformation may difficult to mitigate with  \ninterventions like fact -checking or accuracy prompts that assume users want to share accurate 15 \ninformation (12, 34, 36). Third, individuals who express outrage are seen as more trustworthy \n(32). This suggests  news sources might gain a credibility advantage by posting outrageous \ncontent. Collectively, these features provide strong incentives for misinformation purveyors to \ngenerate outrage -evoking content.  \nWe combined analyses of Twitter and Facebook data with behavioral experiments to test three 20 \nkey hypotheses about misinformation and outrage. First, does misinformation tend to evoke more \noutrage than trustworthy news? Past work is suggestive but suffers from several limitations. \nMisinformation triggers more emotion in general  than trustworthy news (16, 37\u201341), but it \nremains unclear whether this relationship holds for outrage, whose unique properties pose special \nchallenges for developing effective countermeasures. Moreover, prior studies of emotion and 25 \nmisinformation are limited to single platforms and time periods, raising questions about \ngeneralizability (39, 40, 42). We address this limitation by analyzing data from Facebook and \nTwitter across multiple time periods (Table 1). Because defining and classifying  misinformation  \nremains controversial  (1, 4, 11), generalizability is further limited for the majority of past studies \nrelying  on a single classification strategy (1, 4). Here we achieve robustness by testing our 30 \nhypothesis across multiple classification strategies. Finally, because misinformation and \ntrustworthy news tend to circulate in different networks , comparisons between them are often \nconfounded by audience characteristics  (43, 44). We address this limitation by analyzing outrage \nevoked by misinformation and trustworthy news shared within the same networks of users .   \nSecond, we test  whether outrage facilitates the spread of misinformation. While outrage 35 \nincreases sharing information in general (26), outrage  might have a more limited impact on \nmisinformation sharing because it is reputationally costly (45). Since outrage expressions will \ntend to reach a larger -than-average  audience, outrage might increase the reputational risks of \nsharing misinformation, making users more attentive to accuracy to mitigate these risks. \nAccordingly , emotional reactions to headlines increase discernment of misinformation from 40 \ntrustworthy news (42). Thus, the potential reputational costs of sharing outrage that turns out to \nbe false or misleading might outweigh the potential benefits of outrage for spreading \nmisinformation. Alternatively , the ability of outrage to signal trustworthiness (32) and group \nidentity (28) might provide some insurance for the potential reputational costs of sharing \nmisinformation. We address these possibilities by comparing the effects of outrage on sharing 45 \nmisinformation and trustworthy news.  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 2 Our third hypothesis investigates how outrage shapes psychological motives for sharing \nmisinformation. Past work on information sharing distinguishes between \u201cepistemic \u201d motives \n(i.e., motives to share accurate information) and \u201cnon-epistemic \u201d motives (i.e.,  any motives that \nare indifferent to accuracy, like expressing group loyalty or habitually responding to a familiar \nstimulus , 12, 34, 36, 46, 47). We leverage two kinds of data to examine how outrage impacts 5 \nthese motives: discernment of true from false headlines in a behavioral experiment and  sharing \nFacebook links without reading them first. Research on the reputational costs of sharing \nmisinformation suggests outrage could enhance epistemic motives  (45). If so, outrage should \nincrease discernment and reduce sharing without reading (since epistemically motivated users \nshould want to evaluate the information in the links they share). Alternatively, research on 10 \npolitical and intergroup communication suggests outrage could amplify non -epistemic motives  \n(12). If so, outrage should have no effect on discernment and increase sharing without reading.  \n \nOverview of studies   \nWe report 8 observational studies on Facebook and Twitter (total NFacebook =1,063,298 links, 15 \nNTwitter =44,529  tweets, NTwitter =24,007 users ) and 2 behavioral experiments in a simulated social \nmedia environment (total N=1,475). The Facebook and Twitter studies examined engagement \nwith social media posts containing web links that we classified as misinformation or trustworthy  \n(Fig. 1, Table 1). Following past work (2, 3, 10, 19, 35, 48\u201354), we classified links based on the \nquality of their source (i.e., the parent web domain of the link shared in the post , 19) as assessed 20 \nby professional organizations  (Materials and Methods (MM) , 2.1). In this \u2018source -classification\u2019 \napproach, social media posts sharing links originating in low vs. high quality sources are \nclassified as misinformation vs. trustworthy information, respectively. This approach has \npractical and theoretical advantages over fact -checking individual articles, which is costly, prone \nto selection bias,  difficult to scale, and focused on a tiny sliver of the broader misinformation 25 \necosystem ( 19). We found that sources we classified as misinformation were more likely to \nproduce content that was fact -checked as false or misleading, compared to sources we classified \nas trustworthy, validating our use of source classification as a proxy for misinforma tion (see \nSupplementary Text (ST), 5.1) . \nOur observational studies draw on three databases of parent web domains using  different criteria 30 \nfor classifying misinformation vs. trustworthy news sources (Table 1 ; MM, 2.1). We used each \ndatabase to curate pairs of datasets containing Facebook and Twitter posts linking to the same \narticles (Studies 1a -b) or parent domains (Studies 2a -b, 3a -b, 4a -b) over identical time periods in \n2017  and 2020 -2021 . This approach enabled robustness tests across definitions of \nmisinformation, platforms, and time periods. Studies 1 -3 classified misinformation and 35 \ntrustworthy domains categorically, while Study 4 assessed source quality on a continuous basis \nusing an existing dataset of news domains (55), enabling a more fine -grained test of the \nrelationship between source quality and outrage.  \nStudies 1 a-b, 2a -b contained links to misinformation and trustworthy articles and domains posted  \nby the Internet Research Agency (IRA), a Russian organization whose purpose was to sow  40 \ndisinformation and discord into American politics (54, 55; MM, 3.1). These studies provide \nconservative hypothesis tests by comparing  outrage responses to misinformation and trustworthy \nsources that presumably were all shared with provocative intent.  \nStudies 3a -b used an \u201caudience matching\u201d strategy to control for characteristics of networks that \ntend to circulate misinformation. We curated these datasets by identifying users who posted links 45 \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 3 from misinformation  sources , and subsequently identifying links from trustworthy sources \nposted by the same users. We then collected engagement data for Facebook and Twitter posts \nlinking to misinformation and trustworthy sources shared by the same users. (MM, 6.1.3 ). \nTo address the limitations of source -classification (most notably the imperfect correspondence \nbetween source quality and misinformation at the individual article level), our behavioral 5 \nexperiments (Studies 5a -b) examined responses to headlines individually fact -checked as true or \nfalse that we selected to evoke high or low outrage (MM, 7.1.2 ). These studies also enabled \ncausal inferences about the effects of outrage on sharing and discernment of true from false \nheadlines. In each study, American participants viewed 20 news headlines that varied on \ntrustworthiness  (true vs. false)  and outrage evocation (high vs. low)  and rated their likelihood of 10 \nsharing it (5a) or its perceived accuracy (5b).  \nAll Facebook studies draw on the URL Shares  dataset, which is privacy -protected using an \nimplementation of differential privacy that involves the addition of pseudo -random noise to the \ndata (58, 59). For such data it is not possible to extract traditional  estimates from our models, \ninclude interaction terms, or estimate p-values (58). Instead, we run regressions that simulate the 15 \nadded noise across tens of thousands of models by sampling values from a noise distribution \nwith a known variance, yielding average coefficient estimates across simulations as well as \nadjusted standard errors (we  calculate confidence intervals as +/- 1 adjusted standard error above \nand below the coefficient estimate (45; MM, 4.1.2 ). \n 20 \nStudy    Data Source  Time Period  News Source  Nlinks/tweets  Nusers/participants  \n1 a Facebook  Jan 2017 \u2013 \nJul 2017  IRA articles from \ndomains in \nDomain Dataset 1  9,026 links  - \n  b Twitter  3,329 tweets  1,656 users  \n2 a Facebook  Aug 2020 \u2013 \nFeb 2021  IRA domains in \nDomain Dataset 1  192,108 links  - \n  b Twitter  10,550 tweets  5,236 users  \n3 a Facebook  Aug 2020 \u2013 \nFeb 2021  Domain Dataset 2  211,535 links  - \n  b Twitter  16,617 tweets  7,485 users  \n4 a Facebook  Aug 2020 \u2013 \nFeb 2021  Domain Dataset 3  650,629 links  - \n  b Twitter  14,033 tweets  9,630 users  \n5 a Prolific  Jan 2020 \u2013 \nDec 2021  Snopes.com  - 730 participants  \n  b Prolific  - 745 participants  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 4 Table 1. Study overview . We curated parallel datasets from Facebook (Studies 1a, 2a, 3a, and \n4a) and Twitter (Studies 1b, 2b, 3b, and 4b), including data from 2017 (Studies 1a -b) and 2020 -\n2021 (Studies 2a -b, 3a -b, 4a -b). We also conducted two behavioral studies (Studies 5a -b). In our \nobservational studies (1 -4), we classified misinformation using  three separate  databases of news \ndomains assessed for source quality. In our behavioral studies (5a and 5b), we used headlines 5 \nfact-checked as true or false.  Note that the URL Shares dataset does not provide data at the \nindividual user level, and so the number of users is not available.  \n \nResults  \nMisinformation  sources  evoke more outrage than trustworthy news  sources  10 \nIn Studies 1a -4a (Facebook) we regressed the count of Anger Reactions for each link onto news \nsource , where news source was either dummy coded (misinformation versus trustworthy; Studies \n1a-3a) or continuous (low -high source quality; Study 4a). Across all studies, links from \nmisinformation sources were associated with more Anger Reactions than  links from  trustworthy \nsources : Study 1a: \ud835\udefd = 1.63, CI s = [1.58, 1.69]; Study 2a: \ud835\udefd = 2.33, CI s = [2.31, 2.34]; Study 3a: 15 \n\ud835\udefd = 1.23, CI s = [1.21, 1.24]; Study 4: \ud835\udefd = 1.97, CI s = [1.95, 1.98] (see Fig. 2), Mean \ud835\udefd = 1.79 . \nThis association remained when controlling for audience size (ST, 1.2). Links from \nmisinformation sources were more likely to evoke  Anger Reactions than other emotion s (Love, \nHappy, Sad, Wow, see ST, 1.1). \nIn Studies 1b -4b (Twitter), we regressed a binary variable denoting the presence or absence of 20 \noutrage in tweet responses onto  news source linked in the original tweet  (misinformation versus \ntrustworthy in Studies 1b, 2b, and 3b; low -high source quality in Study 4b). Responses to links \nfrom misinformation sources were significantly more likely to contain outrage across all studies; \nStudy 1b: Odds Ratio (OR) = 2.66, p = <.001, 95% CI = [ 2.28, 3.12 ]; Study 2b: OR = 1.87, p < \n.001, 95% CI = [1.72, 2.04]; Study 3b: OR = 1.57, p = <.001, 95% CI = [1.45, 1.71] ; Study 4b: 25 \nOR=1. 35, p=0.001, 95% CIs=[1.1 3, 1.62] (see Fig. 2B); Mean OR=1. 86. See ST , 1.3 for \ntabulated results and 1.4 and 1.5 for the results of alternative models. Complementing the \nFacebook results, links from misinformation sources were more likely to evoke  outrage than \nnegative sentiment in general  (ST, 2.5).  \n 30 \nOutrage facilitates the spread of misinformation  \nIn Studies 1a -3a (Facebook), we regressed the count of shares  for links on the number of Anger \nReactions  they received. The implementation of differential privacy  in the URL Shares dataset  \nprevented us from estimating interactions (MM, 4.1.2 ; 57), so we ran separate models for links to \ntrustworthy and misinformation sources . Anger Reactions were associated with increased shares 35 \nfor trustworthy sources , Study 1a: \ud835\udefd = 0.77, CI s = [0. 77, 0.78]; Study 2a: \ud835\udefd = 0.4 0, CIs = [0.4 0, \n0.40]; Study 3a: \ud835\udefd = 0.40, CIs = [0. 40, 0.40], Mean \ud835\udefd = 0.52, and for misinformation sources ,  \nStudy 1a: \ud835\udefd = 0.87, CIs = [0. 87, 0.87]; Study 2a: \ud835\udefd = 0.46, CIs = [0. 46 0.46]; Study 3a: \ud835\udefd = 0.44, \nCIs = [0. 44, 0.44], Mean \ud835\udefd = 0.59. The relationship between anger and sharing was robust to the \ninclusion of audience size as a covariate (ST, 1.2). The relationship was larger for 40 \nmisinformation compared to trustworthy sources in all studies (see ST, 2.1 for tabulated models).  \nIn Studies 1b -3b (Twitter), we estimated models predicting the count of shares the original \ntweets  received as a function of the presence of outrage in responses to the tweets , news source , \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 5 and their interaction. We found a main effect of outrage on sharing in each Twitter study: Study \n1b: OR=2.42, p<.001 , 95% CI=[ 1.91, 3.09]; Study 2b: OR =5.39, p=<.001, 95% CI=[ 4.91, 5.92]; \nStudy 3b: OR =10.15 , p=<.001, 95% CI=[ 9.43, 10.93 ],  Mean OR=5.99. This relationship was \nconfirmed for trustworthy sources , Study 1b: OR =2.42, p<.001 ; Study 2b: OR=5.39, p<0.001; \nStudy 3b: OR =10.15, p<.001, and misinformation sources , Study 1b: OR=3.31, p<.001 ; Study 5 \n2b: OR=9.05, p< .001; Study 3b: OR=6.89, p<.001. The interaction between outrage and news \ntype was inconsistent across studies. In Studies 1b and 2b, the effect of outrage on shares was \nstronger for misinformation  than trustworthy news  sources . In Study 3b, the effect was stronger \nfor trustworthy news  sources  compared to misinformation (ST, 2. 1). This pattern of results was \nrobust to the inclusion of negative sentiment as a covariate (ST, 2. 5). 10 \nStudy 5a tested whether outrage evocation causally increase d sharing intentions for \nmisinformation and trustworthy news. Participants were more likely to share high outrage -\nevoking headlines compared to low -outrage evoking headlines, \ud835\udefd=0.25, p=.003, 95% CIs=[ 0.09, \n0.40], and equally likely to share misinformation and trustworthy news, \ud835\udefd=-0.08, p=0.29, 95% \nCIs=[ -0.24, 0.07]. We found no interaction between outrage and news type, \ud835\udefd=-0.002, p=0.09, 15 \n95% CIs=[ -0.31, 0.31], suggesting that outrage -evoking headlines are shared more, regardless of \nwhether they are trustworthy or misinformation. These results were robust to controlling for \nparticipants\u2019 political ideology  (ST, 2. 7) and were replicated in a hierarchical logistic model that \nregressed binarized willingness to share ratings (likely versus unlikely to share) on outrage \nevocation, news type, and their interaction (ST, 2.6).  20 \n \nOutrage increases non -epistemic motives for sharing  \nNext, we investigated the effects of outrage on motives for sharing. We first examined our \nFacebook data (Studies 1a -3a) to test whether outrage -evoking links were shared more without \nbeing read first , compared to links that evoked relatively less outrage . Since it is difficult to 25 \nassess the accuracy of an article without reading it first, we take sharing -without -reading as an \nimperfect but informative proxy for the relative strength of non -epistemic (vs. epistemic) \nmotives. We regressed the count of sharing -without -reading on the c ount of Anger Reactions to \nlinks from misinformation and trustworthy sources . We found that Anger Reactions were a \npositive predictor of sharing -without -reading for links from misinformation sources (Study 1a: \ud835\udefd 30 \n= 0.63, 95% CI = [0.63, 0.63]; Study 2a: \ud835\udefd = 0.33, 95% CI = [0.33, 0.33]; Study 3a: \ud835\udefd  = 0.31, \n95% CI = [0.31, 0.31]) as well as trustworthy sources (Study 1a: \ud835\udefd = 0.50, 95% CI = [0.50, \n0.50]; Study 2a: \ud835\udefd = 0.31, 95% CI = [0.31, 0.31]; Study 3a: \ud835\udefd  = 0.30, 95% CI = [0.30, 0.30]).  \nAcross all studies, Anger Reactions more strongly predicted sharing -without -reading for \nmisinformation than trustworthy sources (Fig. 4 ; ST, 3.1 ). These results suggest that outrage 35 \nincreases the relative strength of non -epistemic (vs. epistemic) motives for sharing. We note, \nhowever, that we observe similar effects for all emotional reactions, suggesting that emotions in \ngeneral ( beyond  outrage in particular) impact non -epistemic motives for sharing (ST, 3.2)  \nAs an additional test of how outrage impacts motives for sharing, we turned to our behavioral \nexperiment (Study 5b) assessing the effects of outrage on discerning false from true headlines. 40 \nSince epistemically -motivated sharing depends on assessing information accuracy, we take \ndiscernment as an imperfect but informative proxy for epistemic motives. Participants accurately \ndiscerned false from true headlines: trustworthy news was rated as mor e accurate than \nmisinformation, \ud835\udefd=0.65, p< .001, 95% CI=[ 0.39, 0.91]. However, outrage did not significantly \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 6 impact discernment, \ud835\udefd=0.15, p=0.59, 95% CI=[ -0.38, 0.68] ( MM, 8.1). Thus, we do not find \nevidence that outrage influences epistemic motives for sharing.  \n \nDiscussion  \nAcross eight studies and two experiments spanning multiple platforms, time periods and 5 \ndefinitions of misinformation, our findings suggest  (1) misinformation sources evoke more \noutrage than trustworthy news  sources ; (2) outrage facilitates the spread of misinformation at \nleast as strongly as trustworthy news; and (3) outrage enhances non -epistemic motives for \nsharing misinformation.  \nOur results suggest that outrage -evoking misinformation may be difficult to mitigate with 10 \ncountermeasures that focus on increasing  epistemic motives, like reminders to consider accuracy \nbefore sharing content (47, 60\u201362). Instead, they are consistent with recent evidence that social \nmedia users sometimes share information they know is inaccurate to satisfy non -epistemic \nmotives like signaling their political affiliation or moral stance (12), despite potential \nreputational costs (45, 63). We speculate that outrage -evoking misinformation may be less 15 \nreputationally costly to share than other types of misinformation due to the signaling properties \nof outrage. If caught sharing misinformation, users can claim they merely intended to express \nthat the content is \u201coutrageous if true\u201d (64), preserving epistemic trust while bolstering their \nmoral trust. Future studies might test this possibility directly, with an eye towards developing \ninterventions that target non -epistemic (rather than epistemic) motives for sharing.  20 \nOur studies had several limitations. Many factors contribute to the spread of misinformation \n(43), while our work focused on moral outrage. We focused on US samples  on Facebook and \nTwitter,  and therefore our results might not generalize beyond this cultural setting  or other social \nmedia platforms, such as Reddit or TikTok. Our observational studies followed prior work (3, \n49, 50, 53) in classifying misinformation using professionally -assessed source quality ratings, 25 \nrather than relying on fact -checked classifications of articles as \u2018true\u2019 or \u2018false\u2019. A major \nlimitation of this \u2018source -classification\u2019 approach is that it requires inferring article quality from \nsource quality, which may not always be valid. Constraints on Facebook data required that we \noperationalize outrage as a count of Anger Reactions; future work would benefit from a more \nspecific measure of outrage, as with our Twitter analyses. Finally, future work should explore 30 \nalternative proxies for measuring epistemic and non -epistemic motives for sharing to further \nclarify their roles in spreading misinformation.  \nWe take \u201cnon-epistemic motives\u201d to broadly  include any motive for sharing information that is \nnot concerned with information accuracy. Recent work highlights habitual processes as a \npotential non -epistemic motive for sharing misinformation (26, 46). The observed association 35 \nbetween outrage and sharing -without reading is consistent with the possibility that outrage \npromotes habitual sharing that could inadvertently spread misinformation. This could arise \nbecause expressing outrage garners social rewards (26) that are delivered unpredictably, a \nschedule of reinforcement known to promote habit formation (65). Future work could examine \nthis possibility more directly, as well as investigating the effects of outrage on other non - 40 \nepistemic motives.  \nAn outstanding challenge for a science of online behavior is how to observe and measure the \ninfluence of ranking algorithms on user behaviors, such as sharing misinformation (11, 66\u201368). \nSince outrage is associated with increased engagement online, outrage -evoking misinformation \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 7 may be likely to spread farther in part because of the algorithmic amplification of engaging \ncontent. This is important because algorithms may up -rank news articles associated with outrage, \neven if a user intended to express outrage toward the article for containing misinformation. \nInvestigating this possibility is challenging, however, due to the opacity of platform algorithms \nand diminishing access to platform data (11).  5 \nMisinformation online remains a threat to a healthy public sphere and democracy (6, 14\u201316) and \nthus frequently the subject of legal and policy directives that aim to mitigate these harms . Our \nfindings suggest that misinformation exploits outrage to spread and offers concrete evidence for \npolicymakers to consider when attempting to craft effective and meaningful solutions.  \n 10 \nReferences  and Notes  \n1.  S. Altay, M. Berriche, H. Heuer, J. Farkas, S. Rathje, A survey of expert views on misinformation: \nDefinitions, determinants, solutions, and future of the field. Harvard Kennedy School Misinformation Review , \ndoi: 10.37016/mr -2020 -119 (2023).  \n2.  D. M. J. Lazer, M. A. Baum, Y. Benkler, A. J. Berinsky, K. M. Greenhill, F. Menczer, M. J. Metzger, B. 15 \nNyhan, G. Pennycook, D. Rothschild, M. Schudson, S. A. Sloman, C. R. Sunstein, E. A. Thorson, D. J. Watts, \nJ. L. Zittrain, The science of fake news. Science  359, 1094 \u20131096 (2018).  \n3.  G. Pennycook, D. G. Rand, Fighting misinformation on social media using crowdsourced judgments of news \nsource quality. Proceedings of the National Academy of Sciences  116, 2521 \u20132526 (2019).  \n4.  D. J. Watts, D. M. Rothschild, M. Mobius, Measuring the news and its impact on democracy. Proceedings of 20 \nthe National Academy of Sciences  118 (2021).  \n5.  A. Bovet, H. A. Makse, Influence of fake news in Twitter during the 2016 US presidential election. Nat \nCommun  10, 7 (2019).  \n6.  A. Deb, S. Donohue, T. Glaisyer, \u201cIs Social Media a Threat to Democracy?\u201d (The Omidyar Group, 2017).  \n7.  A. M. Enders, J. E. Uscinski, C. Klofstad, J. Stoler, The different forms of COVID -19 misinformation and 25 \ntheir consequences. Harvard Kennedy School Misinformation Review , doi: 10.37016/mr -2020 -48 (2020).  \n8.  A. Gollwitzer, C. Martel, W. J. Brady, P. P\u00e4rnamets, I. G. Freedman, E. D. Knowles, J. J. Van Bavel, Partisan \ndifferences in physical distancing are linked to health outcomes during the COVID -19 pandemic. Nat Hum \nBehav  4, 1186 \u20131197 (2020).  \n9.  A. Guess, J. Nagler, J. Tucker, Less than you think: Prevalence and predictors of fake news dissemination on 30 \nFacebook. Science Advances  5, eaau4586 (2019).  \n10.  R. C. Moore, R. Dahlke, J. T. Hancock, Exposure to untrustworthy websites in the 2020 US election. Nat \nHum Behav  7, 1096 \u20131105 (2023).  \n11.  C. Budak, B. Nyhan, D. M. Rothschild, E. Thorson, D. J. Watts, Misunderstanding the harms of online \nmisinformation. Nature  630, 45\u201353 (2024).  35 \n12.  M. Osmundsen, A. Bor, P. B. Vahlstrup, A. Bechmann, M. B. Petersen, Partisan Polarization Is the Primary \nPsychological Motivation behind Political Fake News Sharing on Twitter. American Political Science Review  \n115, 999 \u20131015 (2021).  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 8 13.  J. A. Tucker, A. Guess, P. Barbera, C. Vaccari, A. Siegel, S. Sanovich, D. Stukal, B. Nyhan, Social Media, \nPolitical Polarization, and Political Disinformation: A Review of the Scientific Literature. 3144139 [Preprint] \n(2018). https://doi.org/10.2139/ ssrn.3144139.  \n14.  C. Colomina, H. S. Margalef, R. Youngs, \u201cThe impact of disinformation on democratic processes and human \nrights in the world\u201d (PE 653.635, European Parliament, 2021).  5 \n15.  S. Lewandowsky, U. K. H. Ecker, J. Cook, S. van der Linden, J. Roozenbeek, N. Oreskes, Misinformation \nand the epistemic integrity of democracy. Current Opinion in Psychology  54, 101711 (2023).  \n16.  F. Wintterlin, T. Schatto -Eckrodt, L. Frischlich, S. Boberg, F. Reer, T. Quandt, \u201cIt\u2019s us against them up \nthere\u201d: Spreading online disinformation as populist collective action. Computers in Human Behavior  146, \n107784 (2023).  10 \n17.  J. Roozenbeek, C. R. Schneider, S. Dryhurst, J. Kerr, A. L. J. Freeman, G. Recchia, A. M. van der Bles, S. van \nder Linden, Susceptibility to misinformation about COVID -19 around the world. Royal Society Open Science  \n7, 201199 (2020).  \n18.  J. Allen, D. J. Watts, D. G. Rand, Quantifying the impact of misinformation and vaccine -skeptical content on \nFacebook. Science  384, eadk3451 (2024).  15 \n19.  J. Allen, A. A. Arechar, G. Pennycook, D. G. Rand, Scaling up fact -checking using the wisdom of crowds. \nScience Advances  7, eabf4393 (2021).  \n20.  Full Fact, \u201cReport on the Facebook Third -Party Fact -Checking Programme\u201d (Full Fact, 2020); \nhttps://fullfact.org/media/uploads/tpfc -2020.pdf.  \n21.  J. Haidt, \u201cThe moral emotions\u201d in Handbook of Affective Sciences  (Oxford University Press, New York, NY, 20 \nUS, 2003) Series in affective science , pp. 852 \u2013870. \n22.  E. J. Horberg, C. Oveis, D. Keltner, Emotions as Moral Amplifiers: An Appraisal Tendency Approach to the \nInfluences of Distinct Emotions upon Moral Judgment. Emotion Review  3, 237 \u2013244 (2011).  \n23.  C. A. Hutcherson, J. J. Gross, The moral emotions: a social -functionalist account of anger, disgust, and \ncontempt. J Pers Soc Psychol  100, 719 \u2013737 (2011).  25 \n24.  L. Montada, A. Schneider, Justice and emotional reactions to the disadvantaged. Soc Just Res  3, 313 \u2013344 \n(1989).  \n25.  J. M. Salerno, L. C. Peter -Hagene, The interactive effect of anger and disgust on moral outrage and \njudgments. Psychological Science  24, 2069 \u20132078 (2013).  \n26.  W. J. Brady, K. McLoughlin, T. N. Doan, M. J. Crockett, How social learning amplifies moral outrage 30 \nexpression in online social networks. Science Advances  7, eabe5641 (2021).  \n27.  S. Rathje, J. J. Van Bavel, S. van der Linden, Out -group animosity drives engagement on social media. \nProceedings of the National Academy of Sciences  118, e2024292118 (2021).  \n28.  W. J. Brady, J. J. V. Bavel, Social identity shapes antecedents and functional outcomes of moral emotion \nexpression in online networks. OSF Preprints [Preprint] (2021). https://doi.org/10.31219/osf.io/dgt6u.  35 \n29.  J. Galak, C. R. Critcher, Who sees which political falsehoods as more acceptable and why: A new look at in -\ngroup loyalty and trustworthiness. Journal of Personality and Social Psychology  124, 593 \u2013619 (2023).  \n30.  B. Gawronski, Partisan bias in the identification of fake news. Trends in Cognitive Sciences  25, 723 \u2013724 \n(2021).  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 9 31.  B. Gawronski, N. L. Ng, D. M. Luke, Truth sensitivity and partisan bias in responses to misinformation. \nJournal of Experimental Psychology: General  152, 2205 \u20132236 (2023).  \n32.  J. Jordan, D. G. Rand, Signaling When No One Is Watching: A Reputation Heuristics Account of Outrage and \nPunishment in One -shot Anonymous Interactions. 2969063 [Preprint] (2019). \nhttps://doi.org/10.2139/ssrn.2969063.  5 \n33.  M. A. Lawson, S. Anand, H. Kakkar, Tribalism and tribulations: The social costs of not sharing fake news. \nJournal of Experimental Psychology: General  152, 611 \u2013631 (2023).  \n34.  S. Rathje, J. Roozenbeek, J. J. Van Bavel, S. van der Linden, Accuracy and social motivations shape \njudgements of (mis)information. Nat Hum Behav  7, 892 \u2013903 (2023).  \n35.  R. E. Robertson, J. Green, D. J. Ruck, K. Ognyanova, C. Wilson, D. Lazer, Users choose to engage with more 10 \npartisan news than they are exposed to on Google Search. Nature  618, 342 \u2013348 (2023).  \n36.  S. van der Linden, Misinformation: susceptibility, spread, and interventions to immunize the public. Nat Med  \n28, 460 \u2013467 (2022).  \n37.  C. Carrasco -Farr\u00e9, The fingerprints of misinformation: how deceptive content differs from reliable sources in \nterms of cognitive effort and appeal to emotions. Humanit Soc Sci Commun  9, 1\u201318 (2022).  15 \n38.  Y. Chuai, J. Zhao, Anger can make fake news viral online. Frontiers in Physics  10 (2022).  \n39.  S. Stieglitz, L. Dang -Xuan, Emotions and Information Diffusion in Social Media \u2014Sentiment of Microblogs \nand Sharing Behavior. Journal of Management Information Systems  29, 217 \u2013248 (2013).  \n40.  S. Vosoughi, D. Roy, S. Aral, The spread of true and false news online. Science  359, 1146 \u20131151 (2018).  \n41.  B. E. Weeks, Emotions, Partisanship, and Misperceptions: How Anger and Anxiety Moderate the Effect of 20 \nPartisan Bias on Susceptibility to Political Misinformation. Journal of Communication  65, 699 \u2013719 (2015).  \n42.  S. Phillips, S. Y. N. Wang, K. M. Carley, D. Rand, G. Pennycook, Emotional language reduces belief in false \nclaims. OSF [Preprint] (2024). https://doi.org/10.31234/osf.io/jn23a.  \n43.  F. Zimmer, K. Scheibe, M. Stock, W. G. Stock, Fake News in Social Media: Bad Algorithms or Biased \nUsers? Journal of Information Science Theory & Practice  7, 40\u201353 (2019).  25 \n44.  F. Zimmer, K. Scheibe, W. Stock, \u201cEcho Chambers and Filter Bubbles of Fake News in Social Media. Man -\nmade or produced by algorithms?\u201d (2019).  \n45.  S. Altay, A. -S. Hacquin, H. Mercier, Why do so few people share fake news? It hurts their reputation. New \nMedia & Society  24, 1303 \u20131324 (2022).  \n46.  G. Ceylan, I. A. Anderson, W. Wood, Sharing of misinformation is habitual, not just lazy or biased. 30 \nProceedings of the National Academy of Sciences  120, e2216614120 (2023).  \n47.  G. Pennycook, Z. Epstein, M. Mosleh, A. A. Arechar, D. Eckles, D. G. Rand, Shifting attention to accuracy \ncan reduce misinformation online. Nature  592, 590 \u2013595 (2021).  \n48.  J. Allen, B. Howland, M. Mobius, D. Rothschild, D. J. Watts, Evaluating the fake news problem at the scale \nof the information ecosystem. Science Advances  6, eaay3539 (2020).  35 \n49.  S. Bhadani, S. Yamaya, A. Flammini, F. Menczer, G. L. Ciampaglia, B. Nyhan, Political audience diversity \nand news reliability in algorithmic ranking. Nat Hum Behav  6, 495 \u2013505 (2022).  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 10 50.  D. A. Broniatowski, D. Kerchner, F. Farooq, X. Huang, A. M. Jamison, M. Dredze, S. C. Quinn, J. W. Ayers, \nTwitter and Facebook posts about COVID -19 are less likely to spread misinformation compared to other \nhealth topics. PLOS ONE  17, e0261768 (2022).  \n51.  N. Grinberg, K. Joseph, L. Friedland, B. Swire -Thompson, D. Lazer, Fake news on Twitter during the 2016 \nU.S. presidential election. Science  363, 374 \u2013378 (2019).  5 \n52.  A. M. Guess, B. Nyhan, J. Reifler, Exposure to untrustworthy websites in the 2016 US election. Nat Hum \nBehav  4, 472 \u2013480 (2020).  \n53.  L. Singh, L. Bode, C. Budak, K. Kawintiranon, C. Padden, E. Vraga, Understanding high - and low -quality \nURL Sharing on COVID -19 Twitter streams. J Comput Soc Sc  3, 343 \u2013366 (2020).  \n54.  S. Baribi -Bartov, B. Swire -Thompson, N. Grinberg, Supersharers of fake news on Twitter. Science  384, 979 \u2013 10 \n982 (2024).  \n55.  H. Lin, J. Lasser, S. Lewandowsky, R. Cole, A. Gully, D. G. Rand, G. Pennycook, High level of \ncorrespondence across different news domain quality rating sets. PNAS Nexus  2, pgad286 (2023).  \n56.  C. A. Bail, B. Guay, E. Maloney, A. Combs, D. S. Hillygus, F. Merhout, D. Freelon, A. Volfovsky, Assessing \nthe Russian Internet Research Agency\u2019s impact on the political attitudes and behaviors of American Twitter 15 \nusers in late 2017. Proceedings of the National Academy of Sciences  117, 243 (2020).  \n57.  V. Gadde, Y. Roth, \u201cEnabling Further Research of Information Operations on Twitter\u201d (X, 2018); \nhttps://blog.twitter.com/en_us/topics/company/2018/enabling -further -research -of-informa.  \n58.  G. Evans, G. King, Statistically Valid Inferences from Differentially Private Data Releases, with Application \nto the Facebook URLs Dataset. Political Analysis  31, 1\u201321 (2023).  20 \n59.  S. Messing, C. DeGregorio, B. Hillenbrand, G. King, S. Mahanti, Z. Mukerjee, C. Nayak, N. Persily, B. State, \nA. Wilkins, \u201cFacebook Privacy -Protected Full URLs Data Set\u201d (2020).  \n60.  G. Pennycook, J. McPhetres, Y. Zhang, J. G. Lu, D. G. Rand, Fighting COVID -19 Misinformation on Social \nMedia: Experimental Evidence for a Scalable Accuracy -Nudge Intervention. Psychol Sci  31, 770 \u2013780 (2020).  \n61.  G. Pennycook, D. G. Rand, Accuracy prompts are a replicable and generalizable approach for reducing the 25 \nspread of misinformation. Nat Commun  13, 2333 (2022).  \n62.  J. Roozenbeek, A. L. J. Freeman, S. van der Linden, How Accurate Are Accuracy -Nudge Interventions? A \nPreregistered Direct Replication of Pennycook et al. (2020). Psychol Sci  32, 1169 \u20131178 (2021).  \n63.  I. Ghezae, J. J. Jordan, I. B. Gainsburg, M. Mosleh, G. Pennycook, R. Willer, D. G. Rand, Partisans neither \nexpect nor receive reputational rewards for sharing falsehoods over truth online. PNAS Nexus  3, pgae287 30 \n(2024).  \n64.  S. Altay, E. de Araujo, H. Mercier, \u201cIf This account is True, It is Most Enormously Wonderful\u201d: \nInterestingness -If-True and the Sharing of True and False News. Digital Journalism  10, 373 \u2013394 (2022).  \n65.  M. J. Crockett, Moral outrage in the digital age. Nat Hum Behav  1, 769 \u2013771 (2017).  \n66.  J. N. Matias, Influencing recommendation algorithms to reduce the spread of unreliable news by encouraging 35 \nhumans to fact -check articles, in a field experiment. Sci Rep  13, 11715 (2023).  \n67.  J. N. Matias, Humans and algorithms work together \u2014 so study them together. Nature  617, 248 \u2013251 (2023).  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 11 68.  A. Narayanan, Understanding Social Media Recommendation Algorithms, Knight First Amendment Institute  \n(2023). http://knightcolumbia.org/content/understanding -social -media -recommendation -algorithms.  \n \nAcknowledgments:  We would like to thank A. Guess and the members of the Crockett Lab for \ntheir helpful feedback on this project. We thank A. Blevins and D. Johnson for help designing 5 \nFigs. 1 and 3 (A). \nFunding:   \nDemocracy Fund grant R -201809 -03031 (WJB, MJC)  \nNational Science Foundation grant 1808868 (WJB)  \nSocial Science Research Council, Social Media & Democracy Research Grant 10 \n(WJB, MJC)  \nData -Driven Social Science Large Grant, Princeton University (KLM, MJC)  \nAuthor contributions:   \nConceptualization: KLM, WJB, AG, BK, KK, MJC  \nData curation: KLM, WJB, BK  15 \nFormal analysis: KLM, WJB  \nFunding acquisition: WJB, MJC  \nInvestigation: KLM, WJB, AG  \nMethodology: KML, WJB, AG, BK, MJC  \nProject administration: KML, MJC  20 \nSupervision: WJB, MJC  \nVisualization: KLM  \nWriting \u2013 original draft: KLM, WJB , MJC  \nWriting \u2013 review & editing: WJB, AG, BK, KK, MJC  \nCompeting interests:  Authors declare that they have no competing interests.  25 \nData and materials availability:  All data, code, and materials relating to Studies 5a&5b \n(behavioral studies) are available on OSF (osf.io, DOI: 10.17605/OSF.IO/MGVQ9) . \nRestrictions apply to the materials we can share from Studies 1 -4 (observational studies). \nSocial Science One and Meta prohibit the sharing of data or analysis output related to the \nURL Shares  dataset (57). Thus, for Studies 1a, 2a, 3a, and 4a we have only shared the 30 \nanalysis code. Researchers can apply for access to the URL Shares dataset here: \nhttps://developers.facebook.com/docs/url -shares -dataset/overview . X (formerly Twitter) also \nrestricts how data from its platform can be shared (58). To comply  with those restrictions, we \nhave shared our data  from  in Studies 1b - 4b without identifiable information about the tweets \nused. 35 \n \n  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 12 Figure s \n \n \nFig 1. Dataset curation.  We identified links to misinformation and trustworthy sources using \ndatabases of parent web domains that had been assessed for news quality (see MM, Section 2.1 5 \nfor details). We used the databases to curate pairs of datasets containing Facebook and Twitter \nposts linking to the same articles or parent domains over identical time periods in 2016 and 2020. \nWe then collected emotional responses to the links in each da taset. We quantified outrage on \nFacebook as a count of the Angry Reactions a link received and on Twitter as the proportion of \nresponses that contained expressions of moral outrage as determined by our Digital Outrage 10 \nClassifier (DOC; see MM, Section 5.1.2). We refer to \u2018Twitter\u2019 instead of \u2018X\u2019 because our data \nwere collected before the platform\u2019s name was changed.  \n \n  \n\nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 13  \n \n \nFig 2. (A) Results of Study 4a. (B) Results of Study 4b. (A) On Facebook, links with lower \nsource quality were associated with higher counts of Anger Reactions. None of the other emotion 5 \nreactions were as strongly associated with source quality. (B) On Twitter, links to domains with \nlower source quality had a higher probability of evoking outrage in responses. The relationship \nbetween source quality and negative sentiment was non -significant. Shaded areas represent 95% \nconfidence intervals from negati ve binomial models. n.s: not significant, *** p = 0.001.  \n10 \n  \nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 14  \n \nFig. 3. (A) Overview of the Design of Studies 5a & 5b, (B) Results of Study 5a, and (C) \nResults of Study 5b. (A) Participants read a series of news headlines that were fact -checked as \ntrue or false. The headlines had been pilot tested so that half of those that participants read were 5 \noutrage -evoking and the other half were not. After reading each headline, participants were \nasked how likely they would be to share it (Study 5a), and how accurate they thought it was \n(Study 5b). (B) Share ratings for high and low outrage -evoking headlines are shaded by news \ntype (misinformation versus trustworthy). Dots represent mean willingness to share and error \nbars depict the standard error of the mean. High outrage evocation led to higher willin gness to 10 \n\nSubmitted Manuscript: Confidential  \nTemplate revised November 202 3 \n \n 15 share ratings across misinformation and trustworthy news. (C) Accuracy judgements for high \nand low outrage -evoking headlines are shaded by news type (misinformation versus \ntrustworthy). Dots represent mean accuracy judgments and error bars depict the standard error of \nthe mean. The effect of outrage evocation on accu racy was non -significant for both \nmisinformation and trustworthy news.  5 \n \n \n \n \n 10 \nFig. 4. Effect Size Comparison for Anger Reactions Predicting Sharing -without -Reading \nfor Misinformation and Trustworthy Links. Effect size  estimates from models regressing the \ncount of shar ing-without -reading on the count of Anger Reactions for misinformation (orange) \nand trustworthy (green) links in Studies 1a, 2a, and 3a (Facebook). Error bars represent \nregression +/ - 1 SE around estimates from differentially private regressions.  15 \n \n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Misinformation exploits outrage to spread online", "author": ["KL McLoughlin", "WJ Brady", "A Goolsbee", "B Kaiser"], "pub_year": "2024", "venue": "Science", "abstract": "We tested a hypothesis that misinformation exploits outrage to spread online, examining  generalizability across multiple platforms, time periods, and classifications of misinformation."}, "filled": false, "gsrank": 628, "pub_url": "https://www.science.org/doi/abs/10.1126/science.adl2829", "author_id": ["Mzm8WosAAAAJ", "ysiWkJMAAAAJ", "", "wJ5NtLkAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:iC6EXKmhQ3oJ:scholar.google.com/&output=cite&scirp=627&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D620%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=iC6EXKmhQ3oJ&ei=d7WsaKCIGLXCieoP4PfQ0A8&json=", "num_citations": 28, "citedby_url": "/scholar?cites=8810063044840533640&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:iC6EXKmhQ3oJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://osf.io/ecxp4/download"}}, {"title": "ElectionRumors2022: A dataset of election rumors on Twitter during the 2022 US midterms", "year": "2024", "pdf_data": "ElectionRumors2022: A Dataset of Election Rumors on Twitter During\nthe 2022 US Midterms\nJOSEPH S. SCHAFER\u2217and KAYLA DUSKIN\u2217,University of Washington, USA\nSTEPHEN PROCHASKA, University of Washington, USA\nMORGAN WACK, Clemson University, USA\nANNA BEERS, University of North Carolina, USA\nLIA BOZARTH, University of Washington, USA\nTAYLOR AGAJANIAN, University of Washington, USA\nMIKE CAULFIELD, University of Washington, USA\nEMMA S. SPIRO, University of Washington, USA\nKATE STARBIRD, University of Washington, USA\nUnderstanding the spread of online rumors is a pressing societal challenge and an active area of research across domains. In\nthe context of the 2022 U.S. midterm elections, one influential social media platform for sharing information \u2014 including\nrumors that may be false, misleading, or unsubstantiated \u2014 was Twitter (now renamed X). To increase understanding of the\ndynamics of online rumors about elections, we present and analyze a dataset of 1.81 million Twitter posts corresponding to 135\ndistinct rumors which spread online during the midterm election season (September 5 to December 1, 2022). We describe how\nthis data was collected, compiled, and supplemented, and provide a series of exploratory analyses along with comparisons to\na previously-published dataset on 2020 election rumors. We also conduct a mixed-methods analysis of three distinct rumors\nabout the election in Arizona, a particularly prominent focus of 2022 election rumoring. Finally, we provide a set of potential\nfuture directions for how this dataset could be used to facilitate future research into online rumors, misinformation, and\ndisinformation.\nAdditional Key Words and Phrases: Twitter, rumors, midterm elections, elections, misinformation, social media\n1 Introduction\nOnline rumors, and related phenomena such as misinformation and disinformation, have become increasingly\nimportant to understand and address, with prior work framing misinformation and disinformation as urgent\nproblems [ 14] which need an interdisciplinary and integrated \u201ccrisis discipline\u201d approach to research [ 8]. Rumors\nare often a byproduct of collective sensemaking processes, whereby people come together, frequently in online\nspaces, to make sense of ambiguous and/or uncertain information [ 7,51]. Events such as natural hazards, public\nhealth crises, and elections are frequent catalysts for rumoring behavior, particularly given that they frequently\ndraw global attention and involve high levels of informational uncertainty. Unsurprisingly, a growing body of\nresearch has focused on understanding sensemaking, rumoring, and misinformation in the context of democratic\nelections, both within the United States (U.S.) [13, 31, 33, 38] and globally (e.g. [4, 36, 45]).\nIn the U.S. context, research on election-related misinformation and rumors has often focused on presidential\nelections, such as in 2016 and 2020 [ 13,27,28,33,37,38,49]. However, midterm elections are also sites of potential\nelection rumoring, and are of critical importance to governmental composition, despite typically commanding\nsomewhat less public attention and participation. The 2022 U.S. midterm elections consisted of nationwide\nelections for all members of the U.S. House of Representatives and a partial set of members of the U.S. Senate, as\n\u2217Both authors contributed equally to this research.\nAuthors\u2019 Contact Information: Joseph S. Schafer, schaferj@uw.edu; Kayla Duskin, kduskin@uw.edu, University of Washington, USA; Stephen\nProchaska, University of Washington, USA; Morgan Wack, Clemson University, USA; Anna Beers, University of North Carolina, USA; Lia\nBozarth, University of Washington, USA; Taylor Agajanian, University of Washington, USA; Mike Caulfield, University of Washington, USA;\nEmma S. Spiro, University of Washington, USA; Kate Starbird, University of Washington, USA.arXiv:2407.16051v1  [cs.SI]  22 Jul 2024\n2\u2022Schafer & Duskin et al.\nwell as for many state and local races (e.g. the governor\u2019s race in Arizona). Documenting election process-related\nrumors in this specific context allows for important gains to research understanding; not only can we better\nunderstand the dynamics of rumors online by expanding the cases studies within the research community, but we\ncan also consider whether phenomena observed in presidential elections apply to U.S. non-presidential election\ncontexts as well.\nIn this paper, we aggregate and describe a set of 135 rumors that spread on Twitter (now renamed X)1\u2014 at the\ntime, a notable social media platform for real-time information and news sharing in the U.S. \u2014 during the 2022\nU.S. midterm elections. We curate a set of posts that include original tweets, retweets, quote tweets, and reply\ntweets that correspond to each rumor, which in aggregate comprises 1.81 million posts. We additionally include\ninformation on the web domains that were cited in content pertaining to each rumor, and the geographical\nlocation (U.S. state or states) that is the focus of each rumor. We describe the process used for creating and\ncurating a comprehensive (high recall) and low-noise (high precision) sample of tweets for each rumor. We\npresent several empirical analyses of this data, first through five preliminary descriptive statistical analyses,\npositioned in comparison with a similar dataset on the 2020 U.S. elections, previously published in [ 33]. Next, to\ndemonstrate the utility of these data for more in-depth research, we feature a mixed-methods, case study analysis\nof three rumors focused on the state of Arizona. We conclude by outlining future work that could build off of this\ndataset and accompanying analyses, along with reflections on the ethical considerations and methodological\nlimitations of using and researching with these data.\nImportantly, given recent changes in data accessibility, it is increasingly difficult to study social media though\nlarge-scale observations and data analysis; it is now nearly impossible to estimate changes in online communi-\ncation patterns over time [ 19,61]. The time period of this study captured a high-impact public event while the\nTwitter platform still had comparatively open data accessibility, which makes observing and measuring rumors\nin this context even more compelling. As an important hub for discussion during the 2022 elections, Twitter\nprovides one window into online rumoring, complementing studies of other platforms. This study, when paired\nwith prior work, provides rare opportunity for insight into how online election-related discourse has changed\nover time, and offers implications for future election cycles.\n2 Background\nThroughout this paper, we use the framing of election-related rumors . In this section, we briefly define this\nterm and discuss how it relates to other forms of information \u2014 namely misinformation anddisinformation . We\nthen provide background regarding the study of rumors online and in the context of election administration.\n2.1 Terminology and Definitions\nRumors are stories that contain information that is unverified or incomplete at the time of dissemination.\nThey are a key component of conveying important information through a population [ 40]. From a sociological\nperspective, rumoring is a crucial social process \u2014 a form of collective problem-solving that has taken place\nconsistently throughout history [ 51]. Shibutani explains that rumors involve the pooling of intellectual resources\nto provide meaningful interpretation to an otherwise ambiguous situation [ 51]. Situations characterized by\nhigh uncertainty and elevated anxiety are the prime environment for rumors to emerge [ 5,47]. As situational\nuncertainty resolves, the information shared through rumors, while initially unverified, may later be shown to be\ntrue or false, or as time goes on may remain ambiguous \u2014 being neither substantiated nor disproven.\nRumors that turn out to be false or misleading can be considered misinformation . Misinformation is inaccurate\ninformation that may be shared without the intent to mislead or harm audiences, or potentially without awareness\nthat the message contains falsehoods [ 14,24,30]. Closely related is disinformation , denoting false or misleading\n1For clarity we will use terminology as it existed at the time of data collection, e.g. Twitter, tweets, retweets, quote tweets, and reply tweets\nElectionRumors2022 \u20223\ninformation that is shared deliberately to further a particular goal such as monetary profit or political gain [ 24,30].\nA disinformation campaign may consist of strategic amplification of a mixture of true, false, and misleading\ncontent that contributes to a desired narrative. Disinformation campaigns have been known to amplify organic\nrumors, as well as seed new rumors, as art of their aims. In these cases, disinformation may be spread unwittingly\nby audiences unaware of its deceptive nature [46].\nThe dataset described in this paper is comprised of a wide range of initially unverified content shared on Twitter\n\u2014 some posts contain early reports of real events related to the election, other posts include soundly disproven\nclaims, while some posts add misleading framing to factual events. Given this range, we find the term rumor to\nbe the most accurate and useful descriptor for the collection. Conceptualizing these election-related narratives as\nrumors serves to highlight the sensemaking aspect of online communication, even when the topic of discussion\nultimately turns out to be lacking veracity. This acknowledgment of uncertainty is key to understanding and\nproductively discussing modern information systems [52].\nWhile we use rumors as the conceptual framework for this work, we acknowledge connections to research in\nmis- and disinformation, particularly given that this work specifically focuses on rumors with a false, misleading,\nor unsubstantiated element. Given the fluctuating understandings of terms, previous work exploring false and\nmisleading online narratives use different terms for the mixed-veracity messages present in online social discourse.\nFor example, Kennedy et al. uses \u2018misinformation\u2019 as an umbrella term \u2014 inclusive of rumors, misinformation,\nand disinformation \u2014 in their study of stories shared online during the U.S. 2020 election [ 33]. Similarly, in their\nwork characterizing user engagement with conspiratorial topics on Twitter during the 2020 U.S. election, Sharma\net al. use \u2018disinformation\u2019 as term to capture what they call \u2018distorted narratives\u2019 which include unreliable or\nconspiratorial claims regardless of the intent of the content\u2019s author [ 49]. In this work we do not attempt to\ndistinguish individual pieces of content as true or false (e.g. to label posts as misinformation) nor as intentionally\nor unintentionally misleading (e.g. to label posts as disinformation). Rather, we organize content into distinct\nrumors, acknowledging the overlapping functions and understandings of rumor, stories, misinformation, and\ndisinformation.\n2.2 Online Rumoring\nOnline social media platforms have changed how people consume news, learn about crises, and keep up with\ncurrent events. In the digital age, rumors have the potential to spread faster than ever and reach broader audiences\n[21,56]. At the same time, analyzing the digital trace data available in these systems has allowed researchers to\ngain insight into how rumors spread through networked sociotechnical systems and populations. Research in\nthis space has focused heavily within the domain of crisis informatics \u2013 the study of how citizens respond to and\nmake sense of emerging crises through online communication [ 39]. Studies have helped illuminate online rumor\npropagation [ 7,63] and correction [ 6,53], along with their role in collective sensemaking [ 55] in the context of\ndiverse public crises ranging from natural hazards to acts of violence such as shootings or hostage situations.\nThe affordances of online social media platforms allow users to both share and seek out emerging information\nextremely rapidly, and without the gatekeeping mechanisms of traditional media communication (though these\nnetworks undoubtedly have their own access constraints [ 32]). In fact, [ 21] show that the very structure of online\nsocial networks (specifically Twitter) facilitates faster rumor propagation than other networks of similar size\nand density. Additionally, the novelty and salience of information contained in rumors may contribute to their\npropensity to spread rapidly online. In a large-scale study of online news, [ 58] show that false news travels farther,\nfaster, and more broadly on Twitter than true news and is also more novel and surprising to audiences than true\nnews. As online populations collectively seek to make sense of an uncertain, stressful, or novel situation, rumors\nemerge to provide explanation and fill information voids \u2013 even if their validity is unknown.\n4\u2022Schafer & Duskin et al.\n2.3 Election Administration Rumors\nOne context ripe for rumors is election administration, given the high degree of uncertainty and consequence\nassociated with them. As such, rumors during and about election administration have gained increased attention\nin the last decade in particular. In the U.S., there is a strong political element to the formation of collective\nidentity \u2013 one which relies on deep stories that resonate with their intended audience, regardless of factuality\n[42]. Deep stories of voter fraud and election malfeasance have become increasingly prominent in recent years\n[43]. In recent work, researchers also found that in states with more restrictive ballot counting laws, and therefore\nlonger periods of uncertainty, rumors and misinformation were more prevalent during the 2020 U.S. election\n[59]. This confluence of factors indicate that rumoring about the administration of elections is not likely to be a\ntemporary trend, but rather an expected element of information ecosystems that we seek to better describe and\nconceptualize.\nOther researchers have also focused on studying social media discussions of elections and election adminis-\ntration by compiling datasets of social media posts. Notable related datasets include the VoterFraud2020 dataset\nfocused on #VoterFraud and related hashtags during the 2020 election [ 2], the ElectionMisinfo2020 dataset focused\non 2020 election misinformation using mixed-methods curation described in [ 33], the #Election2020 dataset\nfocused on broad coverage of 2020 election discussions on Twitter in [ 16], and the MEIU22 dataset of posts broadly\nrelated to the 2022 U.S. midterm elections across multiple platforms in [ 3]. Our dataset adds to these resources\nby using a similar narrowly-scoped, low-noise dataset akin to ElectionMisinfo2020 [33], while being focused\non the particular time that MEIU22 [3] studies, filling an important gap that existing datasets do not cover. In\naddition to its utility for understanding discussions of election administration rumors during the 2022 midterms\non Twitter in isolation, our dataset is useful for comparative studies with either of those datasets \u2014 for example,\nto understand how rumor-based conversations differed from more general discourses as covered in MEIU22 [3],\nor how rumor-based online engagement evolved from 2020 to 2022 by comparing to ElectionMisinfo2020 [33].\nStudying Twitter during this time period is particularly important, as it was in the beginning stages of significant\nbusiness and ownership changes [ 18]. In our analysis section, we will demonstrate several of these comparative\nanalyses to ElectionMisinfo2020 [33].\n3 Tweet Collection & Rumor Identification\nIn this section we detail the collection of tweets broadly related to the midterm election, how we identified\nemergent election rumors in real time and matched tweets to their corresponding rumor, and finally how we\nevaluated quality at both the rumor and tweet level. Figure 1 depicts this iterative procedure wherein we employ\nempirical and qualitative evaluation to a broad dataset to create a rich dataset that enables assessment of rumoring\nabout the administration of the 2022 U.S. election.\n3.1 Collection of Election Tweets\nThroughout the months leading up to and following the 2022 U.S. midterm elections, our team collected a\nbroad set of election-related data using Twitter\u2019s V1.1 streaming API2. We did so using a list of keywords, phrases,\nand hashtags related to the election (e.g. ballot ,vote) as well as to narratives common in election rumoring\n(e.g. fraud ,tabulator ). These terms were selected by a team of researchers with contextual expertise studying\nprevious elections and informed by prior work conducted during the 2020 U.S. elections [ 33]. The keywords were\ndesigned to capture a comprehensive dataset of tweets related to voting, election materials, procedures, results,\nand claims of election fraud. The full list of keywords used in collecting the general election tweets is included in\nthe Appendix in Table A1. Modifications (additions and deletions of keywords) were made to this list to adapt to\nemerging trends and narratives, and these modifications are also noted in the Appendix in Table A1.\n2https://web.archive.org/web/20220307124146/https://developer.twitter.com/en/docs/twitter-api/v1\nElectionRumors2022 \u20225\nTo reduce the impact of rate-limiting, keywords were divided among nine separate collectors; each collector\nhad its own streaming credential attached to different members of our research team (Twitter\u2019s V1.1 API allowed\nup to max 50 tweets per second collection for any one credential). It is important to note that the collectors\nwere intermittently rate-limited in the two weeks prior to the 2022 Midterm election, and were consistently\nrate-limited on Nov 7th and Nov 8th. Additionally, one of the collectors went briefly down on Nov 2nd due to a\ncredential issue that was quickly resolved.\nWe approximate the comprehensiveness of the resulting dataset of collected election-related tweets using\nmissing retweets. That is, let tweet \ud835\udc56\u2208\ud835\udc46\u210e\ud835\udc4e\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc42\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc47\ud835\udc64\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc60 where\ud835\udc46\u210e\ud835\udc4e\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc42\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc47\ud835\udc64\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc60 contains all the original\ntweets that have at least 1 retweet in the dataset. We denote |\ud835\udc56|\ud835\udc5c\ud835\udc4f\ud835\udc60as the number of observed retweets of \ud835\udc56in\nthe dataset. Further, let |\ud835\udc56|\ud835\udc52\ud835\udc65\ud835\udc5dbe the expected number of retweets for tweet \ud835\udc56(i.e. the number of retweets that\nshould be present in the dataset). We derive |\ud835\udc56|\ud835\udc52\ud835\udc65\ud835\udc5dby taking the earliest and the latest versions (i.e., timestamped)\nof\ud835\udc56observed, and compute the difference in the recorded retweet counts (embedded in the meta-data) of the\ntwo versions. Finally, the fraction of missing retweets of \ud835\udc56is defined as the difference between |\ud835\udc56|\ud835\udc52\ud835\udc65\ud835\udc5dand|\ud835\udc56|\ud835\udc5c\ud835\udc4f\ud835\udc60.\nWe find that 12% of retweets were missing from the dataset overall; 20% of retweets were missing during the\nMidterm election week (11/02/2022 to 11/08/2022). This is consistent with prior literature which demonstrated\nthat the streaming API can miss significant portions of data [ 41,60]. However, missing data from the Streaming\nAPI should not significantly impact topic coverage [41].\nTo improve data comprehensiveness, for original tweets that have at least one retweet captured by our collectors\nbut are themselves missing from the dataset, we used a separate process to attempt to backfill these original\ntweets. We backfilled approximately 2.38 million tweets (of which approximately 1,450 were included in the final,\ncurated rumor dataset). This collection process resulted in an initial election tweet set of 446 million tweets.\n3.2 Identifying Rumor Leads\nDuring a period of ten weeks between 9/19/2022 and 12/01/2022, a team of 15 undergraduate research assistants\nworked in daily shifts to actively observe online discourse about the election and document instances of online\ncontent related to U.S. election integrity. Similar to the collection of the initial election-related tweet dataset, initial\nrumor leads were focused on enabling rapid, broad coverage of online discourse which could involve rumors\nrelated to the election (at this stage, the team emphasized coverage rather than precision, as we would curate\nthis set further at a later step). Researchers first conducted advanced search queries on Twitter using keyword\nqueries and made note of any content with the potential to be an election rumor. Some baseline keyword queries\nwere used daily throughout the data collection period (e.g. \u2018(ballot OR ballots)\u2019), while others were customized to\nexogenous events such as news articles or current events related to the election. Content containing potential\nrumors was logged if it met two scoping criteria: 1) the potential rumor contained a new (or newly prominent)\nclaim that hadn\u2019t been logged by the team previously and 2) the claim met one or more of the topical scope\ncriteria. Though the initial scope of our real-time analysis included other categories, such as threats to election\npersonnel, for this dataset, we focus on rumors which either are likely to deprive someone of their vote (which\nwould include procedural interference, participation interference, or solicitation of fraud), or to cast doubt on\nthe integrity of the election processes and/or the accuracy of election results. Once logged, the undergraduate\nassistants conducted initial manual analysis to identify any related content on Twitter (or other platforms)3and\nsummarize the claims present.\n3Searches of these other platforms, including Facebook, Instagram, TikTok, and Telegram, were used to inform related rapid-response work,\nbut was not used for the Twitter-focused dataset described in this paper.\n6\u2022Schafer & Duskin et al.\nFig. 1. A diagram showing the process of curating this dataset\n3.3 Constructing a Preliminary Rumor Pool\nDuring a period of eight weeks between 9/26/2022 and 11/22/2022 a group of 17 researchers, including nine of\nthe authors, worked in team shifts refining and investigating the logged rumor leads. Teams used qualitative and\nquantitative analysis to either flesh out the leads into preliminary rumors, or discard them for not meeting scope\n\u2014 the most common reasons for discarding a rumor were identification of a duplicate rumor, or having very low\nspread on Twitter. Qualitatively, teams searched for relevant news coverage, related social media content, and\nofficial sources or fact-checks when available. To scope each rumor, researchers used an iterative, manual process\nto develop search queries to identify tweets in the election tweet pool related to each rumor (this process is\nsimilar to that described in [ 33]). Researchers identified a date range and combined keywords, twitter IDs, and/or\nURLs connected to the rumor using boolean operators to construct queries that captured as much of the relevant\ndiscourse as possible while minimizing noise. This allowed for analyses of rumor virality, breadth of spread, and\nidentification of key messengers of each rumor. Key findings surfaced from these analyses were shared with\njournalists and the public during this time period through blog posts4and Twitter threads5.\n3.4 Rumor Criteria Coding\nFollowing the team\u2019s real-time daily analysis efforts, our team conducted post-hoc qualitative coding on the\nset of rumors during January and February, 2023 to further ensure de-duplication and consistency in meeting\nspecified inclusion criteria. This assessment of the rumors involved three members of the research team with\ndeep contextual knowledge of election related rumors, and high familiarity with the dataset. The key criteria met\nby all rumors included in the dataset presented here are as follows:\n\u2022Online discussion about the rumor on Twitter is primarily in English.\n\u2022The rumor pertains to the 2022 U.S. midterm election, rather than a prior election cycle or an election in\nanother country.\n\u2022The rumor is either unsubstantiated or contradicted by authoritative sources (discussed below).\n4https://www.eipartnership.net/blog\n5https://twitter.com/EI_Partnership\nElectionRumors2022 \u20227\n\u2022The rumor is likely to deprive a person of their vote (e.g. false information about where or how to vote)\nor likely to delegitimize election results.\n\u2022The rumor has non-trivial circulation on Twitter (e.g. more than one original tweet).\n\u2022The majority of discourse online relevant to this rumor occurred within the date range 9/5/2023 - 12/1/2023.\nNotably, the post-hoc rumor criteria coding included searching for relevant authoritative sources (e.g. fact-\nchecks, general reporting, official government communication) pertaining to each rumor. The purpose of this was\nto classify discourse around claims as either significantly substantiated, unsubstantiated, misleading/false, non-\nfalsifiable, or primarily fact-check/correction. This was important in revisiting claims that were uncorroborated\nat the time of initial analysis but that later were shown to be true or false. We only include rumors found to be\nfalse, misleading, or unsubstantiated in the final set included for publication.\n3.5 Tweet Quality Assurance\nWe evaluate the quality of each set of tweets associated with each rumor. First, we used the queries developed\nduring the real-time analysis of rumors to identify tweets related to each rumor. For each rumor, we consider two\ntweets samples: the ten most-retweeted tweets, and a random sample of size ten of all other tweets excluding\nretweets (i.e., original tweets, quote tweets, and reply tweets). The two first authors qualitatively coded each\ntweet in the samples as either related or unrelated to the rumor with which it was meant to be associated6. We\nset an acceptance criteria that nine out of the ten most-retweeted tweets returned by the query, and at least eight\nout of a random sample of ten non-retweet tweets must be related to the rumor. Any queries that did not meet\nthat threshold were iteratively updated, re-sampled, and re-coded until this criteria was met. We further adjusted\nthe queries based on temporal volume plots (for an illustration of such plots for individual rumors, see Figures\n10, 11, 12 later in our analysis), to make sure that we did not prematurely cut off a rumor before its spread had\nsignificantly diminished or died out, or begin it after significant discussion had already occurred. Queries were\nalso refined to minimize overlaps between rumors by identifying tweets that appeared in multiple rumors and\nupdating queries so that they only matched the relevant rumor, if only one should have been included. Some\noverlaps remain, as some tweets do reference multiple rumors and should therefore be associated with both.\nMost rumors exceeded the minimum threshold for tweet-level precision. Across all incidents and their respective\nfinal queries, 99% of the ten most-retweeted tweets were coded as correctly associated with the rumor, and 96%\nof the ten random tweets were found to be correctly associated.\n4 Data\nTo summarize, we collected tweets corresponding to a set of 135 rumors about the 2022 U.S. Midterm election\nfrom September 5th, 2022 to December 1st, 2022. The overall dataset contains approximately 1.81 million tweets\n(88.0% of which are retweets), and approximately 427,600 unique users. We also include several data enrichments,\ndetailed below.\nGeographic Location: To gauge where rumors were most concentrated geographically, we identify the state(s)\nof interest for each rumor. To do so, each rumor was coded with up to three states that were the focus of discussion\nwithin the narrative. If there were more than three states of equal relevance, or if the rumor did not have any\ngeographic components, the rumor is coded as \"General\". Three of the 135 rumors were coded as relevant to\nboth a specific state and as \"General\", as they had significant components related to particular states as well as to\nbroader narratives about the election.\nExternal Links: To understand what external sources were used in discussions of rumors we consider links\nto external sites using URLs present in each tweet; for each shortened link (e.g. https://t.co/xxxxx) we used the\n6Tweets consisting of corrections or fact-checks of a rumor were coded as relevant, though these types of content are rare in the dataset.\n8\u2022Schafer & Duskin et al.\nFig. 2. A diagram of the data and feature relations contained in our dataset. Columns that are joinable across tables are\nlinked via arrows.\npycurl library7to unravel it to obtain the complete URL. We also extract the domain name from the complete\nURL using a regular expression.\nMedia Coverage: For each rumor we sought out relevant media coverage or fact-checks identified during the\ncriteria coding. The included links are not an exhaustive list, and are included in the dataset to provide additional\ncontext for each rumor when possible. 12 of the 135 rumors did not have directly-identified sources linked during\ncriteria coding.\n4.1 Data Format\nThe dataset released in conjunction with this paper consists of three data types: rumors ,tweets , and URLs .\nFor each rumor , associated metadata include: an identifying number, the state(s) that the rumor was focused on,\na short title summarizing what the rumor was claiming, and one or more URLs of relevant news coverage or\nfact-checks regarding that rumor. For each tweet , metadata provided are: tweet ID (as provided by the Twitter\nAPI), a pseudonymized user ID, and the corresponding rumor ID number (3,640 tweets, (or 0.201% of the dataset)\nreferenced multiple rumors \u2014 as a result, the rumor ID number column is stored as a list). We also release\nequivalent IDs and user pseudo-ids for referenced tweets (tweets which were retweeted, quoted, and/or replied\nto), as well as if a tweet was collected solely off of location-based keywords or backfilling, for researchers needing\ndisaggregation of particular sources (for further discussion, see the appendix). For each URL, the associated tweet\nID is given. Figure 2 summarizes the dataset features visually.\n7http://pycurl.io/docs/latest/index.html\nElectionRumors2022 \u20229\n4.2 Data Sharing\nWe aim to make this dataset meet the FAIR principles [ 62], while also respecting both privacy concerns and the\nTwitter Terms of Service (at the time of collection). We make the dataset findable and accessible by hosting it in a\nZenodo repository [ 48], allowing researchers to easily access and cite this resource. We also make it interoperable\nby releasing the standard tweet IDs for all posts contained within, so that other Twitter collections during this\ntime (such as the Twitter component of [ 3]) can be cross-referenced. We hope to catalyze data reuse by outlining\nseveral ideas for other projects in the discussion section, and by documenting how this data was collected herein\nso that researchers can evaluate the utility of this data for their own projects. Due to the reduced access of\nthe Twitter API for rehydrating tweets, we will make subsets of hydrated data available to researchers upon\nreasonable request. However, both Twitter\u2019s Terms of Service and privacy concerns for those whose data we\ncompile here prevent release of a fully hydrated dataset.\n5 Quantitative Analyses\nWe perform five preliminary quantitative analyses, four of which include comparisons to a comparable dataset\nfocused on the 2020 U.S. presidential election [ 33]. First, we analyze basic descriptive features of the data such as\nthe temporal volume of tweets and largest rumors. We then conduct two analyses on the distribution of tweet\ntopics \u2014 by geographic focus and by user political partisanship. Next, we describe the prevalence of links to\nexternal domains, and differences in link-sharing behavior from the 2020 U.S. presidential election. Finally, we\nconduct an analysis of how heavily concentrated attention and activity were on the most-engaged-with and\nmost-active accounts.\n5.1 Descriptive Statistics\nFirst, we analyze the rate of tweets over time, with the daily count of rumor-related tweets presented in Figure\n3. The most striking feature is the pronounced spike in rumor circulation surrounding Election Day. Following\nElection Day, the rate of rumoring subsided quickly, with tweet volume dropping to less than a fifth of its Election\nDay spike in approximately 24 hours. By contrast, prior work in 2020, as shown in Figure 4 of [ 33]), demonstrated\nthat election rumors were highly engaged with for multiple weeks after Election Day.\nWe describe the top set of rumors by tweet volume, which is documented in Table 1. As this table illustrates, a\nsignificant number of the rumors which were most prevalent focused on the state of Arizona, prompting us to\ninvestigate how the geographic focus of rumor-related tweets were distributed.\n5.2 Geographic Distribution of Conversation\nWe explore the distribution of geographically-focused tweets with two approaches. First, we use the rumor-\nlevel coding to propagate state assignments to tweets. Second, we search for references to state names and\nabbreviations in the tweet text, using regular expressions to find matching substrings. This regular expression\nsearch process was also performed on the dataset from [ 33] regarding the 2020 U.S. presidential election, allowing\nfor comparison. The process used for finding these references is documented in greater detail in [ 59]. To be clear,\nthe goal of this process is to identify relevant geographic locations mentioned within discussions of the rumor\ntopic itself, not the geographic location of the account posting about the rumor. Table 2 shows the top eight\nmost-commonly-referenced states by approach.\nAs shown in Figure 4, the concentration of narratives on the state of Arizona is far higher in 2022 than it was\nin 2020, when the state was only ranked fifth and was mentioned in less than five percent of tweets directly\nreferencing a state. Additionally, Arizona in 2022 had a higher concentration than any state did in 2020, where\nthe top states of Michigan, Pennsylvania, and Georgia were far more comparable in terms of rumor volume. We\n10 \u2022Schafer & Duskin et al.\n# of Tweets Rumor ID Event of Rumor Focus AZ Specific\n1 224,384 66 Maricopa machines not scanning ballots,\nArizonaYes\n2 110,681 129 Kari Lake shares stories of election day vot-\ners experiencing issues, ArizonaYes\n3 105,951 106 Ballot counting speed comparisons be-\ntween Arizona, FloridaYes\n4 62,576 9 Konnech ties to China No\n5 58,505 126 Republicans win downballot but not guber-\nnatorial race, ArizonaYes\n6 54,905 64 DOJ will observe election in 24 states No\n7 51,312 44 Graphic showing election winner aired\nearly, ArizonaYes\n8 49,315 6 Louis DeJoy in charge of mail-in ballots No\n9 48,273 55 Milwaukee elections official fired for elec-\ntion fraud, WisconsinNo\n10 45,951 11 30,000 non-citizen voter registration no-\ntices, ColoradoNo\nTable 1. Top rumors by tweet volume. The top two (which account for over 18.5% of the data volume), and an additional\nthree of the top ten rumors are focused on Arizona.\n2022 Incidents 2022 References 2020 References\nRank State Percentage State Percentage State Percentage\n1 AZ 42.1% AZ 34.7% MI 22.0%\n2 General 16.7% FL 12.9% PA 21.0%\n3 FL 9.1% PA 9.7% GA 18.4%\n4 PA 6.8% MI 5.7% TX 5.6%\n5 TX 3.9% TX 5.3% AZ 4.7%\n6 MI 3.0% IN 4.9% NV 4.6%\n7 MO 2.7% GA 4.1% CA 3.9%\n8 WI 2.4% CO 3.8% IN 3.4%\nOther 13.4% 19.0% 16.4%\nTable 2. The distribution of rumor-related tweets referencing U.S. states, as calculated by both rumor-level state labels and\nby in-tweet references in 2022, and by in-tweet references in 2020. All states outside of the top eight for a particular year are\nbucketed into \"Other\". Note, the percentages for rumor-level labels are relative to all tweets, while for direct references they\nare only relative to all tweets containing a direct reference to a state.\nElectionRumors2022 \u202211\nFig. 3. A timeline plot showing the number of rumor tweets per day in the dataset. The start of Election Day (November 8,\n2022, at 7:00 UTC) is denoted with a red vertical dashed line.\ndiscuss possible explanations for Arizona\u2019s prominence in election rumoring in a section below, titled Arizona\nRumor Case Studies.\n5.3 Partisan Distribution of Conversation\nTo compare partisan splits within the data, we apply a network clustering method based on audience coen-\ngagement [ 10], similar to the approach used in [ 33]. In brief, we constructed a coengagement projection [ 10]8of\nthe full election tweet set (not just those connected to rumors), which identified a subset of highly-retweeted,\nprominent accounts; we then separate these accounts into clusters using the Louvain method [ 11]. The two large\nclusters identified align with the political left and political right, which we verify through manual inspection of a\nsample of the accounts in each cluster. This method provides a set of highly retweeted prominent left-leaning\nand prominent right-leaning accounts. We then propagate the partisan labels of these prominent account clusters\nout to the rest of the accounts in the dataset, using retweets as a signal of endorsement. Accounts were marked\nas likely left-leaning if over 80% of their retweets of identified prominent accounts were of left-leaning accounts,\nand right-leaning if over 80% of their retweets of prominent accounts were of right-leaning accounts. Users with\n8The coengagement projection results in a network where edges represent retweeting by at least 50 shared audience members between two\naccount nodes, and at least 2 retweets per audience member.\n12 \u2022Schafer & Duskin et al.\nFig. 4. Relative distribution of tweets about U.S. states in 2020 and in 2022 by both direct references through substring\nsearches and rumor-level coding. Each row is populated by its eight most frequently referenced states, with the rest bucketed\ninto other. Tweets mentioning multiple states were counted for each state. Note, the percentages for direct reference searches\nare relative to the total number of tweets referencing a state, not the entire dataset.\nPartisanship Posts Rumors Accounts\nLeft-Leaning 327,564 (18%) 22 (16%) 125,915 (29%)\nRight-Leaning 1,430,244 (79%) 109 (81%) 262,448 (61%)\nUndetermined 52,833 (3%) 4 (3%) 39,235 (9%)\nTable 3. The distribution of posts, rumors, and accounts by their assigned partisan affiliation.\nfewer than 80% of their retweets of prominent accounts linked to a specific partisan cluster were not designated\nas partisan-aligned.\nThis approach enabled us to assign partisanship labels to 388,401 accounts (91% of all accounts which account\nfor 97% of all posts in the dataset). We further designate a rumor as partisan-leaning if a majority (over 50%) of\ntweets related to that rumor came from users that partisan label. We find that in total 18% of all tweets and 16% of\nall rumors were linked to left-leaning accounts, while 79% of all posts and 81% of all 2022 rumors about election\nprocesses and results were linked to right-leaning accounts.\nAs Figure 5 illustrates, the spike in rumoring on Election Day seen in Figure 3 is present for both groups, but\nis particularly evident among right-leaning accounts. By the end of November 2022, most ongoing rumors had\ndissipated on the platform for both groups. Partisan differences in rumor-engagement are largely similar to those\ndocumented in the 2020 election, with right-leaning accounts showing more activity than left-leaning accounts\nor accounts of undetermined leaning. In this study, we additionally combine the partisan and geographic analyses\nwhich reveals another distinct difference between left-leaning and right-leaning groups in 2022. As illustrated\nin 6, a prominent difference is found in the level of attention given to rumors focused on voting processes and\noutcomes in the state of Arizona. Examining engagement of each partisan group separately, we find that over\nhalf of all posts from right-leaning users in our dataset are related to rumors focused on Arizona (as coded at the\nrumor level). In contrast, only 14.7% of posts by left-leaning users focused on that state. This chart also partially\nElectionRumors2022 \u202213\nFig. 5. A timeline showing the distribution of tweets authored by users in each partisan category. For readability, we\nrepresented left-leaning account activity with a downward-facing line, and right-leaning account activity with an upward-\nfacing line. The vertical dashed line represents the start of Election Day.\nexplains some of the discrepancies between partisan groups\u2019 participation in election rumors in 2022. When only\nlooking at tweets which reference general election rumors about the midterms, or are focused on other states, we\nsee somewhat closer partisan splits, though there are still more than twice as many posts from right-leaning\naccounts than left-leaning accounts.\n5.4 External Links and Media\nIn addition to text-based content, Twitter users may link to external websites or embed photos, videos, or GIFs\nin their posts. Users may be motivated to share links with their audience to inform them of breaking news, to\nconnect with like-minded users or to seek new information [ 29]. In this section, we analyze the prevalence of\nposts sharing links to external sources, the diversity and frequency of what domains are linked to, and note key\nchanges from link sharing behavior during the 2020 presidential election. We additionally assess the prevalence\nof embedded media in rumor-related tweets.\nWe find that 273,965 (15.13%) of the tweets within the dataset contain links to external websites. We identify\n8,779 unique URLs from 2,057 unique domains (process described in the \u201cExternal Links Enrichment\" section).\nOverall, we find that sharing links is highly skewed toward a few of the most popular sites, with the 10 most\npopular domains accounting for more than half (55.75%) of the tweets containing URLs. The most popular\ndomains, shown in Table 4, were a mix of news sites and government sites, along with one Republican fundraising\nplatform.\n14 \u2022Schafer & Duskin et al.\nFig. 6. A bar graph showing the relative prevalence of tweets in rumors focusing on Arizona in 2022, grouped by the\npartisanship of users.\nDomain Tweets Percent Type MBFC Bias\nthepostmillennial.com 45622 14.46 News Right\nthegatewaypundit.com 32077 10.16 News Extreme Right\nmaricopa.gov 22721 7.20 Local Gov.\nfoxnews.com 19176 6.08 News Right\nsecure.winred.com 12678 4.02 Fundraising\nwashoelife.washoecounty.gov 9800 3.11 Local Gov.\ndailysignal.com 9422 2.99 News Right\napnews.com 8188 2.59 News Left Center\nwashingtonpost.com 8175 2.59 News Left Center\njustice.gov 8053 2.55 Federal Gov.\nTable 4. Most linked domains in rumor-related tweets. The percentage column reports the prevalence of each domain in\nrelation to tweets containing an external link. The bias as listed by Media Bias Fact Check (MBFC)[ 1] are included for sources\nwhere that information is available.\nIt is important to note that links to external sites can play a variety of roles in relation to the rumor they are\nassociated with. In some cases, a linked source is in support or promotion of the rumor claims, while in other\nElectionRumors2022 \u202215\ncases an external source is linked to provide a correction or fact-check. In another scenario linked sources provide\na basis of information that the rumor builds upon. Here, we provide several examples of link-sharing behavior\nthat highlight how external links serve different purposes.\nFirst, is a rumor about the discrepancy between Election Day voter turnout and overall vote totals in Maricopa\nCounty, Arizona. The rumor suggests that the fact that Election Day voting had a low proportion of Democrats,\nbut the Democratic candidate for governor (Katie Hobbs) received higher overall vote totals indicates Democratic\nelection malfeasance. In reality, mail-in and early voting trends provide logical explanations as to why Election\nDay vote splits do not match overall vote splits. The tweet shown below is shared directly from the external\nsource ( thegatewaypundit.com ). In this case, the linked content is in direct support of the rumor with the article\ncasting the voting statistics as evidence of nefarious behavior.\n@USERNAME-REDACTED: IMPOSSIBLE: Despite Only 17% Democrat Turnout on Elec-\ntion Day - Katie Hobbs and Democrats Are Winning Over 50% of Maricopa County\nElection Day Totals https://t.co/jc7PRrWthy via @gatewaypundit\nIn a second example, we consider one of the three U.S. government ( .gov ) sites in the list of the ten most-shared\ndomains (Table 4). In the case of the maricopa.gov domain, the vast majority of links to the site were in relation\nto two rumors surrounding issues with in-person voting in Maricopa county on Election Day. One of these\nrumors (further detailed in Case Study 1) includes general speculation about the delays in vote tabulation. The\nother rumor specifically casts doubt on the policy of mitigating the machine issues by having voters place ballots\nin a secure drop box (called \u2018box 3\u2019 or \u2018door 3\u2019) to be counted later. Several highly retweeted tweets by prominent\naccounts included links to Maricopa\u2019s election site that provided information on the location of polling stations.\nThe text of the tweet supports the rumor that the voting procedures cannot be trusted while the link itself\nprovides trustworthy information about polling sites. We include one such example below:\n@kelliwardaz: BIG problems with @MaricopaVote. Tabulator \u201cmalfunctions\u201d at\nat least 6 places. DO NOT PUT YOUR BALLOT IN \u201cBOX 3\u201d TO BE \u201cTABULATED DOWN-\nTOWN.\u201d Maricopa will not be turning on the downtown tabulators today. Find\nyour next nearest polling place here: http://Maricopa.vote/\nFinally, we show an example where factual reporting about a mistake from Colorado\u2019s secretary of state office\nsparked widespread rumors. In this case, the Associated Press (AP) published an article about how a postcard\nencouraging recipients to register to vote was mistakenly sent to a group of Colorado residents that included a\nlarge number of non-citizens in addition to the U.S. citizens that should have received them. The AP shared the\narticle, which included reporting on how the error had occurred and clarified that this did not enable recipients\nto register unlawfully, on Twitter:\n@AP: Colorado\u2019s secretary of state office says it mistakenly sent postcards\nto about 30,000 noncitizens encouraging them to register to vote, blaming\nthe error on a database glitch related to the state\u2019s list of residents with\ndriver\u2019s licenses.\nhttps://t.co/dXWXDhwo83\nSome users retweeted the AP\u2019s post sharing the article, while other users added their own commentary via\nquote-tweeting the original AP tweet or others who shared the same article. Commentary ranged from criticism\nof the error, to questioning of circumstances, to conspiracy theorizing, as seen below.\nComment 1: @USERNAME-REDACTED: This oopsie could end up costing these folks\ntheir future citizenship. This is appalling and outrageous. Government should\ntake all means possible to inform and stop these noncitizens from wrongly\ncasting votes and jeopardizing their futures.\nComment 2: @USERNAME-REDACTED: Do we actually believe this was a mistake?\n16 \u2022Schafer & Duskin et al.\ndomain 2020 2022 Change\nthepostmillennial.com 0.11% 14.46% +14.35\nmaricopa.gov 0.42% 7.20% +6.78\nfoxnews.com 0.69% 6.08% +5.38\nsecure.winred.com 0.28% 4.02% +3.73\nwashoelife.washoecounty.gov 0.00% 3.11% +3.11\n.. .. .. ..\ninquirer.com 2.03% 0.02% -2.01\nnationalfile.com 2.44% 0.01% -2.43\nthegatewaypundit.co 13.65% 10.16% -3.49\nbreitbart.com 5.50% 0.59% -4.91\nyoutube.com 6.60% 0.71% -5.89\nTable 5. Domains with the largest change in relative popularity between 2020 and 2022. Change is presented as the raw\ndifference in proportion of tweets linking to the domain with positive change signifying an increase in popularity and negative\nvalues signifying a decrease.\nComment 3: @USERNAME-REDACTED: Intentional act by a Soros operative?\nThe above three quote tweets reveal a wider pattern of how rumoring interacts with news, where quoted\ntweets contain factual evidence about election-related events, and commenting tweets integrate that evidence\ninto false, misleading, or unsubstantiated rumors. Taken with the other two examples of shared external links,\nwe see how incorporation of exogenous sources can take a variety of forms in the creation and spread of online\nrumors.\nWhen compared to the 2020 election, the sharing of external links in rumor-related tweets was far less common.\nIn 2022, 15.14% of tweets included a link to an external site, compared to 30.33% of tweets linking to an external\nsite in the 2020 dataset. However, the general pattern of skewed attention to a small number of popular domains\nheld in both cases, as shown in Figure 7 where the a large number of domains receive a very small cumulative\nshare of tweets and a few popular domains receive the majority of the tweets. Calculating the Gini coefficient\nas a summary of how attention (via tweets) is split across domains, we find that there was only slightly less\ndomain-level inequality in link-sharing in 2022, with the Gini coefficient falling from 0.983 in 2020 to 0.965 in\n2022.\nIn Table 5 we show the domains with the most marked difference in popularity between 2020 and 2022. In right-\nbiased news sources, breitbart.com dropped notably in terms of the proportion of links and thepostmillenial.com ,\nwhich had essentially no references during the 2020 election, was the most popular site shared in 2022 election-\nrelated rumors. Interestingly, the official Twitter account for the thegatewaypundit.com was banned in February\nof 2021 following violations of Twitter\u2019s then-active civic integrity policy [ 57], and remained off the platform for\nthe duration of the 2022 election cycle. However, links to the site were still common; it was the second most\nshared domain in our dataset despite dropping slightly in relative popularity from 2020. Another notable change\nis the decrease in links to YouTube, which represented over 6% of links in 2020 and less than one percent of links\nin 2022.\nTwitter enables users to embed photos, videos and GIFs directly in their posts through the use of the \u2018native\u2019\nmedia affordance. Rather than linking to an external site that hosts images or videos, users can directly upload\nmedia content from their device into their posts. Shown in Figure 8, we assess the prevalence of these forms of\nElectionRumors2022 \u202217\nFig. 7. Lorenz curve for the popularity of domains shared within rumor or misinformation related tweets.\nFig. 8. Prevalence of embedded media in rumor-related tweets in 2020 and 2022.\n18 \u2022Schafer & Duskin et al.\ngini top 1% users top 0.1% users\nyear 2020 2022 2020 2022 2020 2022\nAll 0.97 0.96 86% 84% 58% 40%\nLeft-leaning 0.95 0.95 79% 81% 41% 35%\nRight-leaning 0.97 0.97 86% 85% 58% 41%\nTable 6. Measures of the level of concentration of retweets of a small number of users among all users, left-leaning users,\nand right-leaning users. Measurements are the gini coefficient of retweet counts, the proportion of retweets of the top 1%\nmost retweeted users, and proportion of retweets of the top 0.1% of users.\nmedia and find that more rumor-related posts contained \u2018native\u2019 media in 2022 than in 2020, increasing from\n6.52% to 11.54%. This increase in the use of embedded media may help explain the drop in link sharing, as well as\nthe decrease in links to YouTube, though future research designed to understand causal impacts, rather than just\nthe descriptive analysis done here, would be needed to confirm this.\n5.5 Concentration of Engagement\nOne of the key findings of [ 33] was that original posts from a small number of heavily retweeted and highly\nactive \u201crepeat spreader\" accounts had an outsized contribution to the overall volume of online discourse around\nfalse and misleading narratives in 2020. Here, we analyze whether a similar level of retweet concentration was\npresent in 2022. The content produced by relatively few users may receive a disproportionately large amount of\nengagement through retweets.\nTo measure this, we calculated the Gini coefficients for both 2020 and 2022 based on the number of retweets\nthat each user received. We also compute the proportion of total retweets for the top 1% most-retweeted users,\nand the top 0.1% of most-retweeted users, in both 2020 and 2022. These were calculated in aggregate, as well\nas for each identified partisan cluster;results are shown in Table 6. We observe that, overall, election rumors\nare highly skewed in their sources toward a relatively small proportion of users. There is no notable change\nin overall skew (gini coefficient) for any of the groups between 2020 and 2022, and very minor change in the\nproportion of retweets of the top 1% most-retweeted users between election cycles. For both left-leaning users\nand right-leaning users there is a drop in terms of the proportion of retweets of the very select few users who\nmake up the 0.1% most retweeted population.\n6 Arizona Rumor Case Studies\nIn this section, we feature in-depth mixed-methods analysis of three Arizona-based rumors, a prominent\nlocation in our geographic analysis. First, we provide some brief background to help explain why the state of\nArizona, and in particular the county of Maricopa, were so salient in our data.\n6.1 Context for Arizona\u2019s Prominence in Election Discourse\nIn recent elections, Arizona has been considered a \u201cpurple\u201d or \u201cswing state\u201d with fairly similar numbers\nof Republican and Democrat voters. This means that elections in Arizona are likely to be close, with results\npotentially impacting the balance of power at the national level. Close elections correlate with higher uncertainty\nabout outcomes, and uncertainty is known to lend itself to rumoring [ 12]. Additionally, issues with voting,\nintentional or not, have the potential to impact the results in close elections \u2014 indicating high relevance of the\ntopic for both sides.\nElectionRumors2022 \u202219\nIn 2020, Arizona \u2014 and in particular its most populous county, Maricopa County \u2014 became a flashpoint for\nrumors about election integrity, such as claims about Sharpie pens invalidating votes [ 34] and the Dominion\nvoting systems [ 15]9. A number of Arizona Republican political figures organized and/or participated in \u201cStop the\nSteal\u201d protests after the election [ 50]. Several political operatives and lawyers participated in \u2014 and were indicted\nfor \u2014 a \u201cfake elector\u201d scheme that attempted to change the results of the presidential election in Arizona from\nBiden to Trump [ 20]. In 2021, an unofficial \u201caudit\u201d of Arizona\u2019s 2020 general election drew national attention and\ncontributed to sustained distrust in election integrity within the state [17].\nIn 2022, gubernatorial candidate Kari Lake promoted theories that elections were rigged by Democrats, using\nrhetoric similar to Donald Trump (who endorsed her). Lake repeatedly criticized election officials, including her\ngubernatorial opponent, Katie Hobbs, who was then the Secretary of State of Arizona.\nGoing into the 2022 midterm election, this combination of factors likely contributed to widespread distrust,\nespecially among Republicans, in election integrity. Prior to Election Day, false and/or unsubstantiated claims\nabout different elements of the election were already spreading. Then, on Election Day, real problems with voting\nacross the state combined with existing distrust to catalyze dozens of rumors. Some of those rumors \u2014 e.g. that\nvoting machines were not working at many locations \u2014 were true. But others wove emerging news about real\nissues into unsubstantiated conspiracy theories, e.g. alleging that the problems were an intentional effort to\ndisenfranchise Republican voters.\nIn the following sections, we describe three related rumors that emerged from Maricopa County on and after\nElection Day. These case studies demonstrate the utility of the described dataset for thorough qualitative work in\naddition to quantitative methodologies. In Figure 9, we show a timeline of the relative timing and prevalence of\nall three rumors. Individual timelines for each specific rumor are shown in Figures 10, 11, and 12 to provide more\ndetail.\n6.2 Case Study 1: Tabulators not functioning\nOn Election Day in Arizona, issues with ballots scanners began to occur very early, with reports that scanners\nwere not accepting ballots as early as 6:20 AM local time [ 35]. Conversation on Twitter began with some limited\nuncertainty whereby members of the online audience and some Twitter influencers began posting as they\ndescribed what they knew. For example, one of the earliest highly spread tweets (4,138 retweets) in our dataset\ncame from conservative political operative and COO of Turning Point USA Tyler Bowyer10:\n@tylerbowyer: Long lines in Anthem, Arizona with Poll Workers explaining that\nthe @maricopacounty machines are not working. Do not get out of line!11\nBowyer\u2019s tweet embedded a video of a poll worker addressing a long line of voters, describing the issues the\npolling center was experiencing while also capturing the palpable frustration and skepticism of voters waiting in\nline. Although Bowyer\u2019s tweet primarily shared information about the emerging voting difficulties in Maricopa,\nmembers of the online audience commented on the tweet suggesting that the voting issues were evidence of\nfraud. For example, the following comments were made in response to Bowyer\u2019s tweet through the quote tweet\naffordance:\nComment 1: @USERNAME-REDACTED: I told yall. People looked at me crazy. But\nI told yall, to have a plan. Also, that if they are going to manipulate, they\n9Rumors in 2020 about Dominion Voting systems were prominent in Arizona as well as other swing states, including Pennsylvania and\nGeorgia.\n10Bowyer is one of eleven allegedly fraudulent electors in Arizona who have been indicted for falsely certifying Donald Trump as the winner\nof the 2020 election in Arizona [9].\n11In this and subsequent tweets, we have deleted excessive whitespace that made the manuscript unreadable, and added punctuation in\nbrackets if necessary to convey the appropriate meaning.\n20 \u2022Schafer & Duskin et al.\nFig. 9. A composite timeline of three AZ rumors illustrating their relative timing and volume. As seen, the three rumors show\npeak volume at different points in time, as well as differences in prominence and longevity.\nwill do it on election day when all yall are going to vote. The day you have\nyour only chance to vote.\nComment 2: @USERNAME-REDACTED: @RecordersOffice You people shouldn\u2019t be al-\nlowed to hold elections in your county. Imagine expecting us to believe this\nisn\u2019t intentional. Couldn\u2019t get away with the\nsharpies again?\nComment 3: @USERNAME-REDACTED: The steal is on where are the Attorneys and\nthe non-biased poll watchers\nIn each of the above comments, the commenter suggests that the election issues are evidence of a larger,\nintentional plan. Additionally, Comment 1 uses the fact that as rates of mail-in voting have risen in recent\nelections, Republican voters have voted disproportionately on Election Day to suggest the errors are targeted\nwhile Comment 2 refers to a previous, false rumor from 2020 in Maricopa County. Specifically, the rumor\nsuggested that Sharpies were being intentionally distributed to invalidate conservative ballots [50].\nThat video and other similar ones were shared in the early hours of rumoring. Initial posts sharing the videos\nwere often fairly neutral in tone, but the videos themselves showed voters who were frustrated and skeptical\nof the tabulator issues. For example, the most retweeted tweet (with 14,719 retweets in our dataset) within this\nElectionRumors2022 \u202221\nFig. 10. A temporal plot showing the number of tweets per minute related to the Arizona tabulator errors rumor. Note, unlike\nthe other case study plots, we use a y-axis of tweets per minute here, not per hour, to get a better sense of volume shifts as\nthis rumor had a shorter lifespan than the other cases.\nrumor came from Charlie Kirk, conservative influencer and founder of Turning Point USA, where he embeds the\nsame video Bowyer had shared just minutes earlier:\n@charliekirk11:\n A poll worker in all-important Maricopa\nCounty tells Election Day voters the machines are broken.\nOther than calling attention to Maricopa County\u2019s political importance, Kirk\u2019s tweet is fairly neutral in tone and\nmainly communicates part of an evolving situation using a video that highlights the frustration and skepticism of\nvoters waiting in line. As the poll worker describes the issues, he states that \u201cno one is trying to deceive\u201d and is\ninterrupted by sarcastic commentary from the person recording the event, as well as general groans from those\nwaiting in line. In addition, one voter leaves the line, saying explicitly that they do not trust putting their ballot\ninto the box that is set aside for votes to be tabulated later in the event of machine failure.\nAlthough Kirk\u2019s tweet above is relatively neutral at face value, the online audience did not interpret it as such,\nnor did Kirk and other conservative influencers and political elites shy away from more conspiratorial framing in\nsubsequent discourse. For example, in a tweet quoting Kirk\u2019s above tweet, one audience member associates the\nongoing tabulator issues with rumors of election fraud in 2020 (known colloquially as the \u201cBig Lie\u201d):\n22 \u2022Schafer & Duskin et al.\n@USERNAME-REDACTED: Preparing for the BIG LIE all over again. Explain what\u2019s\nhappening here if they don\u2019t plan to cheating? Just so happens tabulators\naren\u2019t working in AZ?\nSimilarly, in a later tweet, Kirk refers to the tabulator issues as \u201cmanufactured chaos\u201d and suggests that the\nresulting lines amount to voter suppression, calling for people to be arrested. This conspiratorial framing was\nechoed by audiences, influencers, and political elites alike. For example, the seventh most retweeted tweet in\nthe incident (with 6,372 retweets) came from Senator Ted Cruz, who insinuated that then-Secretary of State and\nDemocratic gubernatorial candidate Katie Hobbs was somehow intentionally responsible for the tabulator issues:\n@tedcruz: So, the Dem nominee for governor (who refused to debate her oppo-\nnent) is the current Secretary of State \u2013 in charge of running this election\n\u2013 and now... there are problems?\n#DemsHateDemocracy\nIn addition to suspicion around the origin of the errors, online audiences also expressed skepticism as to\nthe reliability of remedies. Maricopa County had backups in place in case of failures like those experienced on\nElection Day, and in the case of 2022 there was a box on the machines (labeled with the number 3 and referred\nto as \u201cBox 3\u201d) where voters were directed to drop their ballots if they were not able to be scanned. However,\nmany members of the online audience expressed skepticism as to whether vote in Box 3 would be accurately\nrecorded. For example, the following tweet insinuates that ballots counted \u201cdowntown\u201d won\u2019t be counted due to\ncorruption:\n@USERNAME-REDACTED Reports of machines not accepting ballots, and that those\nballots will be taken \"Downtown\"... right. Maricopa is as corrupt as they\ncome, and y\u2019all aren\u2019t even trying to hide it anymore.\nIt is important to note that although conspiratorial framing was a major part of the rumoring as it occurred\non Twitter, there were many users who simply noted how frustrating the widespread machine failures were\nbut didn\u2019t make accusations about fraud. In particular, they highlighted the unpreparedness of the election\ninfrastructure and/or administrators, often describing the failures as the result of incompetence with sentiments\nsimilar to the tweet below:\n@USERNAME-REDACTED Monday: Two hour press conference, everything is fine in\nMaricopa, we know what we\u2019re doing. Tuesday: Our machines are broken and we\ndon\u2019t know why, but trust our contingency plan. Incompetence is not fraud,\nbut come on with this shit.\nTaken together, rumoring on Election Day surrounding tabulator failures was founded on very real issues\nwith election infrastructure. These issues were then used as evidence to support interpretations ranging from\nsuggestions of benign incompetence to claims that the problems were intentional voter fraud perpetrated by\nDemocrats. In support of the conspiratorial interpretation, audiences and influencers highlighted: 1) how more\nRepublicans were voting in person on Election Day than Democrats and were therefore more impacted by\nmachine failures; 2) that the Democratic gubernatorial candidate was acting Secretary of State during her election,\ninsinuating a conflict of interest; 3) that the provided remedy of Box 3 was an attempt to manipulate votes offsite;\nand 4) that the resulting long lines disenfranchised conservative voters.\n6.3 Case Study 2: Ballot counting speed\nThe second incident we examine surrounds rumoring suggesting that counting ballots slowly is suspicious and\nallows for the Democratic manipulation of votes. In particular, the rumors center around a comparison between\nthe counting of votes in Florida versus in Arizona. Other states are visible in the data, but the vast majority of\nElectionRumors2022 \u202223\nFig. 11. A temporal plot showing the number of tweets per hour related to the Arizona ballot counting speed rumor.\ntweets compare Florida and Arizona, insinuating that it is suspicious that Florida can finish counting ballots\nmore quickly than Arizona despite having many more ballots to count. For example, conservative influencer Tim\nYoung (@TimRunsHisMouth) posted the following tweet:\n@TimRunsHisMouth: Florida not only had millions more ballots to count than\nArizona... but the state was also prepping for a hurricane at the same time\nAND got the counting done in hours.\nWhat\u2019s Arizona\u2019s excuse?\nThe above tweet highlights the difference in both counting speed and number of ballots counted between\nArizona and Florida, insinuating that it is suspicious for there to be discrepancies. One of the primary reasons\nthat Arizona counted votes more slowly was that voters changed their behavior regarding mail-in ballots; there\nwere over 290,000 mail in ballots dropped off on Election Day (rather than mailing them in prior) in Arizona in\n2022, more than a 70% increase than the number received in 2020 [ 23]. This may have occurred due to increased\nskepticism of the security of mail-in voting in general, and ballot drop boxes in particular in Arizona, which saw\nlarge amounts of rumoring suggesting \u201cballot mules\u201d were using drop boxes for fraud in the lead up to the 2022\ngeneral election [44].\n24 \u2022Schafer & Duskin et al.\nSimilar rumors circulated in 2020 as well, and largely converged on interpretations that ballots were intentionally\ncounted slowly so that Democrats could \u201cfind\u201d ballots to allow them to fraudulently win close elections. The\nincident in 2022 was similar, with many members of the online audience interpreting the delayed counts as an\nopportunity for election malfeasance, an example of which is visible below:\n@USERNAME-REDACTED: #Arizona is just corrupt to the core. #KariLake has ob-\nviously won, yet they are desperately searching for more magical ballots from\nunder tables, just like we saw in 2020. @KariLake is an enormous threat to\nthe establishment and will improve Arizona greatly.Don\u2019t let her down\nQuoted tweet: @EndWokeness: North Carolina: 98% counted [,] Population: 10.5\nmillion [.]Wisconsin: 99% counted [,] Population: 5.2 million [.] Florida:\n99% counted [,] Population: 22 million [.] Ohio: 97% counted [,] Population:\n12 million [.] Arizona: 66% counted [,] Population: 1.6 million\nAbove, it is clear that the commenter interpreted the speed of counting as evidence of corruption that allegedly\noccurred in both 2020 and 2022. Similar to the incidents described above, interpretations ranged from viewing\nthe slow counting as evidence of fraud to suggestions that those claiming fraud were just trying to sow doubt\nabout electoral processes. Between the two were some members of the audience who didn\u2019t necessarily view the\nslow counting as fraud, but instead viewed it as evidence that the election processes in Arizona were a mess and\nneeded to be reevaluated.\n6.4 Case Study 3: Kari Lake anecdotes\nOne of the primary reasons that Maricopa County, and Arizona in general, was likely a hotbed for electoral\nrumoring was because of the endorsement of election denialism by candidates running for office. Most notable of\nthis group was Republican gubernatorial candidate Kari Lake. Although Lake participated in numerous rumors\non Twitter to varying degrees, the final incident examined here is focused on a subset of tweets coming from\nKari Lake\u2019s account (@KariLake) or her campaign\u2019s account (@KariLakeWarRoom).\nThe primary behavior visible in these tweets was the amplification of individual voters\u2019 experiences on Election\nDay in the form of comments based on accompanying embedded videos from voters. The stories shared often\nincluded statements implicitly referring to previous rumors surrounding what has become known as the \u201cBig\nLie\u201d and connecting them to the events on the ground in 2022. For example, in her most retweeted tweet, Lake\namplifies the alleged experience of the son of a voter who ran into trouble voting:\n@KariLake: After registering at ASU, Tiffany\u2019s son received a text offering\nhim $250 to rally for Democrats In line to vote, he was told to leave & that\nhis vote would not be counted [.] Inside, he was told he was not registered,\ngiven a Sharpie, & told to drop a provisional ballot in box 3.\nIn this tweet, several themes are visible. First, Lake, pulling claims from the embedded video of a woman\ndescribing the experience of her son, claims that Democrats (the primary villains in rumors surrounding the Big\nLie) offered money to \u201crally for Democrats.\u201d Second, this was followed by the claim that the long lines catalyzed\nby the tabulator failures described above resulted in poll workers asking voters to leave, allegedly because he,\nand others, would be unable to vote by the deadline of 7:00 PM. Lastly, Lake highlights that poll workers tried to\ngive the son a Sharpie to fill out his ballot, referencing the previous rumor from 2020.\nIn addition to the content, the style of the above tweet and most of Lake\u2019s tweets in this incident is important\n\u2014 Lake makes few direct claims herself, instead relying on testimony from voters to interpret emergent events\nwithin a frame of voter fraud established in 2020 and amplified by Lake throughout her campaign in 2022. This\nprocess is described in more detail in other works [ 43,54], but at its core consists of establishing an expectation\nwithin conservative voters that Democrats will perpetrate fraud, which then causes audiences to organically\nElectionRumors2022 \u202225\nFig. 12. A temporal plot showing the number of tweets per hour related to the anecdotes posted by Kari Lake.\norganize and interpret otherwise ambiguous information as \u201cevidence\u201d of fraud instead of something more\nmundane such as an error in election administration. This \u201cevidence\u201d is amplified online, providing \u201cproof\u201d that\nis strategically amplified by political elites and influencers to support the ongoing conversations surrounding\nalleged voter fraud in U.S. elections.\nSeen from this perspective, the rumors spread are the product of an informal collaboration between political\nelites, influencers, and members of the public, all of whom play integral roles in the production and spread of\nrumors online. Although many members of the public participate in the production and dissemination of these\nrumors, the interpretations of Lake\u2019s tweets are not uniform. Within this incident, interpretations of Lake\u2019s\ntweets ranged from explicitly viewing the shared anecdotes as evidence of fraud to suggestions that the videos\nare evidence of the negative consequences of misleading rhetoric, visible in the example below:\n@USERNAME-REDACTED: Here\u2019s Larry\u2019s story, fresh from Kari Lake. Larry\u2019s story\nis genuinely sad. So spun up on Big Lie bullshit conspiracy theories he ap-\nparently refused to submit to put his ballot in the ballot box because he\nthought it would be thrown away.\nQuoted tweet: @KariLake: It took Larry an hour & a half to get into his polling\nlocation [.] Inside, Larry\u2019s ballot was repeatedly rejected by the tabula-\ntor. He was asked to put it in box\n26 \u2022Schafer & Duskin et al.\nthree so it could be counted downtown. He refused. Because he felt it meant\nthey would throw his vote in the trash.\nIn the above tweet, the poster highlights how election skepticism on the part of voters caused them to doubt the\nremedy in place in Maricopa County for tabulator issues, namely the use of \u201cBox 3\u201d for ballots to be counted at a\nseparate location in the event of machine issues. Although there were a noticeable number of responses countering\ninterpretations of the anecdotes, those interpreting them as evidence of fraud or disenfranchisement were more\nprominent. Within these responses, users often utilized other related rumors to support their interpretations,\nincluding suggestions that Katie Hobbs is too biased to be relied on as Secretary of State, claims that noncitizen\nvoters were voting illegally, that errors on Election Day were intentional, and that swing states are the primary\ntargets for Democrat-led voter fraud.\n6.5 Case study summary\nIn the above three cases, we have illustrated a selection of prominent rumors which spread during the 2022\nmidterms about the election in Arizona. These showed a variety of communicative and discursive practices being\ndeployed to facilitate the spread of these rumors, including differences in tone between influential amplifiers and\ntheir audience (Case 1) and the elevation and generalization of anecdotes (Case 3). These cases illustrate the need\nfor further qualitative work on election rumor discourses in future research.\n7 Limitations\nThis dataset attempts to comprehensively cover English-language tweets about false, misleading, and/or\nunsubstantiated rumors about the election process of the 2022 U.S. midterm elections. However, this scoping\nmeans that there are aspects of closely-related questions this dataset should not be used to address. Notably,\nit does not include non-English language rumors, nor rumors about candidates that are not tied to election\nprocesses. Discussions of rumors on platforms other than Twitter are not captured, as data collection access\nprevents coverage of other platforms with the same level of comprehensiveness. A further form of data missing is\nrumors which spread primarily through images with no (or minimal) in-text keywords. Additionally, this dataset,\nas it is focused on discussions of false and misleading rumors specifically, should not be used for more general\nanalyses of broad political discussions during this time, as large parts of political discourses are unaffiliated with\nthe kinds of rumors examined in this paper.\n8 Conclusion\nIn this paper, we have documented the collection, curation, and preliminary descriptive analysis of a dataset of\n1.81 million election administration-related rumors on Twitter posted around the 2022 U.S. midterms. This data\ncontributes to research into online rumoring around elections by looking into a comparatively under-studied\nmidterm election process rather than presidential elections. After providing detailed documentation of the process\nfor ensuring the reliability of the dataset, we conducted five descriptive analyses of this data, exploring overall\ntweet frequency, geographic and partisan distributions, the prevalence of external link-sharing, and the highly\nconcentrated nature of attention to a small number of users. We follow this with mixed-methods case studies of\nthree prominent rumors about election issues in Arizona, highlighting how this dataset could be used for both\nqualitative and mixed-methods future research in addition to the quantitative research styles contained in this\npaper.\nOur findings collectively demonstrate several interesting features of the dynamics of rumoring during the\nmidterm elections, and how these have changed since 2020 [ 33]. We do not make causal claims about these shifts,\nbut observe several changes including much higher concentration on one particular state and lower prevalence\nElectionRumors2022 \u202227\nof content linking to external domains. At the same time, we observe a similar partisan asymmetry to what [ 33]\nfound in 2020, particularly concentrated in Arizona, and similar levels of retweet concentration.\nThe spread of rumors online has been an area of ongoing interest for research and for society at large, and\nunderstanding the spread of rumors in the context of democratic elections is especially important. This dataset\ncan help support research in this area by providing a wide-ranging overview of rumors that spread within this\nU.S. election context.\nThis dataset could inform research which seeks to understand more granular levels of rumor spread. For\nexample, research into rumor spread in Arizona during the midterms could take the dataset as a starting point for\nareas to further investigate. Other studies of Twitter content in this period could also use this dataset to understand\nif and how prevalent these rumors are within their own observations or data. For example, algorithmic audits of\nTwitter conducted during the election period, such as [ 22], could use this dataset to estimate the frequency that\nobserved election rumors are shown to Twitter accounts.\nOur dataset of 1.81 million posts related to discussions of false, misleading, or unsubstantiated rumors sur-\nrounding the 2022 U.S. midterm elections on the Twitter/X platform provides a thoroughly scoped and curated\nview of these kinds of discussions on the platform at the time. This will provide utility to researchers seeking to\nconduct further research on these topics, as well as increase our understanding of election rumor discussions\nfrom our empirical findings.\nEthical statement.\nThis data was determined by the Human Subject Division at the University of Washington not to involve\nhuman subjects, as defined by federal and state regulations and therefore, did not require review and approval by\nthe IRB. In accordance with Twitter\u2019s Terms of Service at the time of collection, the only data that we released\nwhich came from the platform are user IDs and tweet IDs - this does not include tweet text, usernames, media, or\nother fields - and in fact we only release pseudonymized versions of the user IDs. Since the removal of the free\nresearch API by Twitter (now X) has made rehydrating potentially more difficult for researchers, we will make\nthe hydrated data available to researchers upon reasonable request, similar to prior datasets such as [ 3]. In this\npaper, analysis of inferred political leaning was conducted at an aggregated community level, which is in line\nwith prior work (see for examples, [2, 10, 49]).\nSimilarly to [ 26], we consider the ethical questions in Datasheets for Datasets [ 25]. While we did not get users\u2019\nconsent to collect these data, this is consistent with substantial amounts of prior work on public Twitter posts,\nand by only providing user ID and tweet ID numbers, users who wish to have their content anonymized can\ndelete their data from the platform and this would not be rehydratable. This is similar to other published datasets,\nincluding those related to similarly sensitive political topics, such as [2, 3].\nAcknowledgments\nFunding for this work has come from the University of Washington\u2019s Center for an Informed Public, the John S.\nand James L. Knight Foundation (G-2019-58788), Craig Newmark Philanthropies, the William and Flora Hewlett\nFoundation, the Election Trust Initiative, the National Science Foundation (grant #1749815 and grant #2120496)\nand NSF Graduate Research Fellowships under Grant No DGE-2140004, for both Joseph S. Schafer and Kayla\nDuskin. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the\nauthors and do not necessarily reflect the views of the National Science Foundation or other funders. We would\nalso like to acknowledge Alex Loddengaard for their infrastructural support for this project, and Kristen Engel\nand Ben Yamron for feedback on sections of the writing of this paper.\n28 \u2022Schafer & Duskin et al.\nReferences\n[1] 2024. Media Bias/Fact Check. https://mediabiasfactcheck.com/.\n[2]Anton Abilov, Yiqing Hua, Hana Matatov, Ofra Amir, and Mor Naaman. 2021. VoterFraud2020: a Multi-modal Dataset of Election Fraud\nClaims on Twitter. ICWSM 15 (May 2021), 901\u2013912.\n[3]Rachith Aiyappa, Matthew R DeVerna, Manita Pote, Bao Tran Truong, Wanying Zhao, David Axelrod, Aria Pessianzadeh, Zoher\nKachwala, Munjung Kim, Ozgur Can Seckin, Minsuk Kim, Sunny Gandhi, Amrutha Manikonda, Francesco Pierri, Filippo Menczer, and\nKai-Cheng Yang. 2023. A Multi-Platform Collection of Social Media Posts about the 2022 U.S. Midterm Elections. ICWSM 17 (June 2023),\n981\u2013989.\n[4]Syeda Zainab Akbar, Anmol Panda, and Joyojeet Pal. 2022. Political hazard: misinformation in the 2019 Indian general election campaign.\nSouth Asian History and Culture 13, 3 (July 2022), 399\u2013417.\n[5] Susan Anthony. 1973. Anxiety and rumor. The Journal of social psychology 89, 1 (1973), 91\u201398.\n[6]Ahmer Arif, John J Robinson, Stephanie A Stanek, Elodie S Fichet, Paul Townsend, Zena Worku, and Kate Starbird. 2017. A closer look\nat the self-correcting crowd: Examining corrections in online rumors. In Proceedings of the 2017 ACM conference on computer supported\ncooperative work and social computing . 155\u2013168.\n[7]Ahmer Arif, Kelley Shanahan, Fang-Ju Chou, Yoanna Dosouto, Kate Starbird, and Emma S. Spiro. 2016. How Information Snowballs:\nExploring the Role of Exposure in Online Rumor Propagation. In Proceedings of the 19th ACM Conference on Computer-Supported\nCooperative Work & Social Computing (CSCW \u201916) . Association for Computing Machinery, New York, NY, USA, 466\u2013477. https:\n//doi.org/10.1145/2818048.2819964\n[8]Joseph B Bak-Coleman, Mark Alfano, Wolfram Barfuss, Carl T Bergstrom, Miguel A Centeno, Iain D Couzin, Jonathan F Donges, Mirta\nGalesic, Andrew S Gersick, Jennifer Jacquet, Albert B Kao, Rachel E Moran, Pawel Romanczuk, Daniel I Rubenstein, Kaia J Tombak,\nJay J Van Bavel, and Elke U Weber. 2021. Stewardship of global collective behavior. Proc. Natl. Acad. Sci. U. S. A. 118, 27 (July 2021).\n[9]Stacey Barchenger. 2024. Grand jury indicts fake electors who falsely certified Donald Trump as 2020 winner in Arizona. https:\n//www.azcentral.com/story/news/politics/elections/2024/04/24/arizona-fake-electors-indictments/73184206007/\n[10] Andrew Beers, Joseph S Schafer, Ian Kennedy, Morgan Wack, Emma S Spiro, and Kate Starbird. 2023. Followback clusters, satellite\naudiences, and bridge nodes: Coengagement networks for the 2020 US election. Proceedings of the International AAAI Conference on\nWeb and Social Media 17 (June 2023), 59\u201371.\n[11] Vincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities in large networks.\nJournal of Statistical Mechanics: Theory and Experiment 2008, 10 (Oct. 2008), P10008. https://doi.org/10.1088/1742-5468/2008/10/P10008\n[12] Prashant Bordia and Nicholas DiFonzo. 2005. Psychological Motivations in Rumor Spread. In Rumor Mills . Routledge. Num Pages: 16.\n[13] Alexandre Bovet and Hern\u00e1n A Makse. 2019. Influence of fake news in Twitter during the 2016 US presidential election. Nat. Commun.\n10, 1 (Jan. 2019), 1\u201314.\n[14] Ryan Calo, Chris Coward, Emma S Spiro, Kate Starbird, and Jevin D West. 2021. How do you solve a problem like misinformation? Sci\nAdv 7, 50 (Dec. 2021), eabn0481.\n[15] Center for an Informed Public, Digital Forensic Research Lab, Graphika, and Stanford Internet Observatory. 2021. The Long Fuse:\nMisinformation and the 2020 Election (v1.3.0 ed.). Stanford Digital Repository: Election Integrity Partnership. https://purl.stanford.edu/\ntr171zs0069\n[16] Emily Chen, Ashok Deb, and Emilio Ferrara. 2022. #Election2020: the first public Twitter dataset on the 2020 US Presidential election.\nJournal of Computational Social Science 5, 1 (May 2022), 1\u201318. https://doi.org/10.1007/s42001-021-00117-9\n[17] Dartunorro Clark. 2022. Cyber Ninjas, company that led Arizona GOP election \u2019audit,\u2019 is shutting down. https://www.nbcnews.com/\npolitics/politics-news/cyber-ninjas-company-led-arizona-gop-election-audit-shutting-down-n1287145\n[18] Kate Conger and Lauren Hirsch. 2022. Elon Musk Completes $44 Billion Deal to Own Twitter. The New York Times (Oct. 2022).\nhttps://www.nytimes.com/2022/10/27/technology/elon-musk-twitter-deal-complete.html\n[19] Brittany I Davidson, Darja Wischerath, Daniel Racek, Douglas A Parry, Emily Godwin, Joanne Hinds, Dirk van der Linden, Jonathan F\nRoscoe, Laura Ayravainen, and Alicia G Cork. 2023. Platform-controlled social media APIs threaten open science. Nat Hum Behav 7, 12\n(Dec. 2023), 2054\u20132057.\n[20] S. Dev. 2024. 18 indicted in alleged 2020 fake Arizona elector scheme tied to Trump, AG announces. https://www.cbsnews.com/news/\narizona-alternate-electors-indictment/\n[21] Benjamin Doerr, Mahmoud Fouz, and Tobias Friedrich. 2012. Why rumors spread so quickly in social networks. Commun. ACM 55, 6\n(2012), 70\u201375.\n[22] Kayla Duskin, Joseph S. Schafer, Jevin D. West, and Emma S. Spiro. 2024. Echo Chambers in the Age of Algorithms: An Audit of Twitter\u2019s\nFriend Recommender System. https://doi.org/10.48550/arXiv.2404.06422\n[23] Jen Fifield. 2022. Why Arizona\u2019s ballot count takes longer than Florida\u2019s. https://www.votebeat.org/arizona/2022/11/10/23450191/\nmaricopa-election-result-delay-ballot-counting/\n[24] Deen Freelon and Chris Wells. 2020. Disinformation as Political Communication. Political Communication 37, 2 (March 2020), 145\u2013156.\nElectionRumors2022 \u202229\n[25] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daum\u00e9 Iii, and Kate Crawford.\n2021. Datasheets for datasets. Commun. ACM 64, 12 (Nov. 2021), 86\u201392.\n[26] Salvatore Giorgi, Sharath Chandra Guntuku, Mckenzie Himelein-Wachowiak, Amy Kwarteng, Sy Hwang, Muhammad Rahman, and\nBrenda Curtis. 2022. Twitter Corpus of the #BlackLivesMatter Movement and Counter Protests: 2013 to 2021. ICWSM 16 (May 2022),\n1228\u20131235.\n[27] Nir Grinberg, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson, and David Lazer. 2019. Fake news on Twitter during the 2016\nU.S. presidential election. Science 363, 6425 (Jan. 2019), 374\u2013378.\n[28] Andrew Guess, Jonathan Nagler, and Joshua Tucker. 2019. Less than you think: Prevalence and predictors of fake news dissemination\non Facebook. Sci Adv 5, 1 (Jan. 2019), eaau4586.\n[29] Avery E Holton, Kang Baek, Mark Coddington, and Carolyn Yaschur. 2014. Seeking and sharing: Motivations for linking on Twitter.\nCommunication research reports 31, 1 (2014), 33\u201340.\n[30] Caroline Jack. 2017. Lexicon of lies: Terms for problematic information . Technical Report. Data & Society Research Institute.\n[31] S Mo Jones-Jang, Dam Hee Kim, and Kate Kenski. 2021. Perceptions of mis- or disinformation exposure predict political cynicism:\nEvidence from a two-wave survey during the 2018 US midterm elections. New Media & Society 23, 10 (Oct. 2021), 3105\u20133125.\n[32] Brian Keegan and Darren Gergle. 2010. Egalitarians at the gate: one-sided gatekeeping practices in social media. In Proceedings of the\n2010 ACM conference on Computer supported cooperative work (CSCW \u201910) . Association for Computing Machinery, New York, NY, USA,\n131\u2013134. https://doi.org/10.1145/1718918.1718943\n[33] Ian Kennedy, Morgan Wack, Andrew Beers, Joseph S Schafer, Isabella Garcia-Camargo, Emma S Spiro, and Kate Starbird. 2022. Repeat\nspreaders and election delegitimization. Journal of Quantitative Description: Digital Media 2 (June 2022).\n[34] Rachel Leingang and McKenzie Sadeghi. 2020. Fact check: Arizona election departments confirm Sharpies can be used on ballots.\nhttps://www.usatoday.com/story/news/factcheck/2020/11/04/fact-check-sharpiegate-controversy-arizona-false-claim/6164820002/\n[35] Maricopa County Elections Department. 2022. Maricopa County Response. https://www.maricopa.gov/DocumentCenter/View/80026/\nMaricopa-County-Response-11-27-2022.\n[36] Gabrielle Ann S Mendoza, Kier Jesse Ballar, Jurel K Yap, and Imelda B Deinla. 2023. Accuracy or confidence? Analyzing the impact of\nonline misinformation on Filipino youth voting likelihood. Media Asia (Nov. 2023), 1\u201319.\n[37] Ryan C Moore, Ross Dahlke, and Jeffrey T Hancock. 2023. Exposure to untrustworthy websites in the 2020 US election. Nature Human\nBehaviour (April 2023), 1\u201310.\n[38] Axel Oehmichen, Kevin Hua, Julio Amador D\u00edaz L\u00f3pez, Miguel Molina-Solana, Juan G\u00f3mez-Romero, and Yi-Ke Guo. 2019. Not All\nLies Are Equal. A Study Into the Engineering of Political Misinformation in the 2016 US Presidential Election. IEEE Access 7 (2019),\n126305\u2013126314.\n[39] Leysia Palen, Sarah Vieweg, Jeannette Sutton, Sophia B Liu, and Amanda Hughes. 2007. Crisis informatics: Studying crisis in a networked\nworld. In Proceedings of the third international conference on E-Social Science . 7\u20139.\n[40] Susan Coppess Pendleton. 1998. Rumor research revisited and expanded. Language & Communication 18, 1 (1998), 69\u201386.\n[41] J\u00fcrgen Pfeffer, Angelina Mooseder, Jana Lasser, Luca Hammer, Oliver Stritzel, and David Garcia. 2023. This Sample Seems to Be Good\nEnough! Assessing Coverage and Temporal Reliability of Twitter\u2019s Academic API. Proceedings of the International AAAI Conference on\nWeb and Social Media 17 (June 2023), 720\u2013729. https://doi.org/10.1609/icwsm.v17i1.22182\n[42] Francesca Polletta and Jessica Callahan. 2017. Deep stories, nostalgia narratives, and fake news: Storytelling in the Trump era. American\nJournal of Cultural Sociology 5, 3 (Oct. 2017), 392\u2013408. https://doi.org/10.1057/s41290-017-0037-7\n[43] Stephen Prochaska, Kayla Duskin, Zarine Kharazian, Carly Minow, Stephanie Blucker, Sylvie Venuto, Jevin D. West, and Kate Starbird.\n2023. Mobilizing Manufactured Reality: How Participatory Disinformation Shaped Deep Stories to Catalyze Action during the 2020\nU.S. Presidential Election. Proceedings of the ACM on Human-Computer Interaction 7, CSCW1 (April 2023), 140:1\u2013140:39. https:\n//doi.org/10.1145/3579616\n[44] Stephen Prochaska, Kristen Engel, Taylor Agajanian, Joseph S. Schafer, Kayla Duskin, Rachel E. Moran, Christopher Giles, Frances\nSchroeder, Ilari Papa, Emma Lurie, Mishaela Robison, and Michal Skreta. 2022. Misinformed Monitors: How Conspiracy Theories\nSurrounding \u201cBallot Mules\u201d Led to Accusations of Voter Intimidation. https://www.eipartnership.net/blog/conspiracy-theories-ballot-\nmules-voter-intimidation\n[45] Raquel Recuero, Felipe Bonow Soares, and Anatoliy Gruzd. 2020. Hyperpartisanship, Disinformation and Political Conversations on\nTwitter: The Brazilian Presidential Election of 2018. ICWSM 14 (May 2020), 569\u2013578.\n[46] Thomas Rid. 2020. Active measures: The secret history of disinformation and political warfare. (April 2020).\n[47] Ralph L Rosnow. 1980. Psychology of rumor reconsidered. (1980).\n[48] Joseph S Schafer, Kayla Duskin, Stephen Prochaska, Morgan Wack, Anna Beers, Lia Bozarth, Taylor Agajanian, Mike Caulfield,\nEmma S Spiro, and Kate Starbird. 2024. ElectionRumors2022: A Dataset of Election Rumors on Twitter During the 2022 US Midterms.\nhttps://zenodo.org/doi/10.5281/zenodo.10714795\n[49] Karishma Sharma, Emilio Ferrara, and Yan Liu. 2022. Characterizing online engagement with disinformation and conspiracies in the\n2020 U.s. presidential election. Proceedings of the International AAAI Conference on Web and Social Media 16 (May 2022), 908\u2013919.\n30 \u2022Schafer & Duskin et al.\n[50] Katie Shepherd and Hannah Knowles. 2020. Driven by unfounded \u2018SharpieGate\u2019 rumor, pro-Trump protesters mass outside Arizona vote-\ncounting center. Washington Post (Nov. 2020). https://www.washingtonpost.com/nation/2020/11/05/arizona-election-protest-votes/\n[51] Tamotsu Shibutani. 1966. Improvised News: A Sociological Study of Rumor (first edition ed.). Irvington Pub, Indianapolis.\n[52] Emma Spiro and Kate Starbird. 2023. Rumors Have Rules. Issues Sci. Technol. 29, 3 (April 2023), 47\u201349.\n[53] Kate Starbird, Dharma Dailey, Owla Mohamed, Gina Lee, and Emma S. Spiro. 2018. Engage Early, Correct More: How Journalists\nParticipate in False Rumors Online during Crisis Events. In Proceedings of the 2018 CHI Conference on Human Factors in Computing\nSystems (, Montreal QC, Canada,) (CHI \u201918) . Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/\n3173574.3173679\n[54] Kate Starbird, Ren\u00e9e DiResta, and Matt DeButts. 2023. Influence and Improvisation: Participatory Disinformation during the 2020 US\nElection. Social Media + Society 9, 2 (April 2023), 20563051231177943.\n[55] Kate Starbird, Emma Spiro, Isabelle Edwards, Kaitlyn Zhou, Jim Maddock, and Sindhuja Narasimhan. 2016. Could This Be True? I Think\nSo! Expressed Uncertainty in Online Rumoring. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (San\nJose, California, USA) (CHI \u201916) . Association for Computing Machinery, New York, NY, USA, 360\u2013371.\n[56] Cass R Sunstein. 2009. On Rumors: How Falsehoods Spread, Why We Believe Them, and What Can Be Done . Princeton University Press.\n[57] Twitter. 2021. Civic integrity policy. https://web.archive.org/web/20210208080346/https://help.twitter.com/en/rules-and-policies/\nelection-integrity-policy\n[58] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science 359, 6380 (March 2018), 1146\u20131151.\n[59] Morgan Wack, Joseph S. Schafer, Ian Kennedy, Andrew Beers, Rachel Funk Fordham, Emma S. Spiro, and Kate Starbird. 2023. Working\nPaper: Legislating Uncertainty: Election Policies and the Amplification of Misinformation. https://static1.squarespace.com/static/\n6199b26290e39f273e2759a6/t/657dfd50a533d168d1d0b615/1702755667295/Main+Manuscript.pdf\n[60] Yazhe Wang, Jamie Callan, and Baihua Zheng. 2015. Should We Use the Sample? Analyzing Datasets Sampled from Twitter\u2019s Stream\nAPI. ACM Transactions on the Web 9, 3 (June 2015), 13:1\u201313:23. https://doi.org/10.1145/2746366\n[61] Jess Weatherbed. 2023. Twitter replaces its free API with a paid tier in quest to make more money. https://www.theverge.com/2023/2/2/\n23582615/twitter-removing-free-api-developer-apps-price-announcement. Accessed: 2024-3-17.\n[62] Mark D Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg,\nJan-Willem Boiten, Luiz Bonino da Silva Santos, Philip E Bourne, et al .2016. The FAIR Guiding Principles for scientific data management\nand stewardship. Scientific data 3, 1 (2016), 1\u20139.\n[63] Li Zeng, Kate Starbird, and Emma S Spiro. 2016. Rumors at the speed of light? Modeling the rate of rumor transmission during crisis. In\n2016 49th Hawaii International Conference on System Sciences (HICSS) (Koloa, HI, USA). IEEE.\nElectionRumors2022 \u202231\nAppendix\nBMD, BMDs, EVM, EVMs, HandMarkedPaperBallots, USPS, absentee, adjudication, arizona, audit, ballot, ballots, bmd,\nbmds, chain of custody, chicago, cisa, cochise, code, codes, color revolution, conservative ,conservatives , decertification,\ndecertify, dem,democrat ,democrats ,dems , desantis, detroit, DNC , dominion, drop box, drop boxes, dropbox, dropboxes,\nelection, election2022, electioneering, electionfraud, elections, elections2022, electors, electors, epoll, es&s, forensic,\nfortalice, fraud, fraudulent, fulton, GOP,GOPers , halderman, hand count, hand-count, hand-counted, hand-marked,\nhandcount, handcounted, handcounts, handmarked, imagecast, imagecastx, integrity, intimidation, lancaster, liberal ,\nliberals , machine, machines, mail, mail in, maricopa, michigan, midterm, midterms, midterms2022, mule, nomachines,\nnoncitizen, onenightcount, overvote, paperballots, pennsylvania, philadelphia, pima, pinal, poll, pollbook, pollbooks,\npolling, polls, pollwatcher, pollwatchers, pollworker, post office, postal, postoffice, precinct, racine, raffensperger,\nrecount, republican ,republicans , results, rigged, rigged voterfraud, risk-limiting audit, RNC, rolls, smartmatic, subver-\nsion, suppression, tabulator, tabulators, tallies, tamper, tampered, tampering, touchscreen, touchscreens, undervote,\nvote, votebymail, voted, voter, voterfraud, voters, votersuppression, votes, votesuppression, voting, vulnerabilities,\nvulnerability, yuma\nTable A1. The set of keywords used to create the initial election tweet pool. Terms listed in italics were removed from the\nkeyword list on 11/7/2022. The term \u2018desantis\u2019 was added on 11/15/2022.\nCode Description\nInsufficient Coverage Coverage could not be found on this specific event or class of events\nLargely Substantiated Coverage exists, and confirms the major elements of online narrative, including\nimpact and cause/motive.\nUnsubstantiated Coverage exists, but neither confirms or debunks major elements of\nonline narrative (if false/misleading elements, choose false/misleading)\nFalse/Misleading Coverage exists and highlights false, misleading, or unsubstantiated\nelements of online narrative.\nNo Central Claim The incident focuses on a piece of media that advances many claims (such as a\nlonger video or podcast) and no particular claim is central enough to rate.\nTable A2. Coding scheme for identifying the status of each rumor based on authoritative sources. The two in-scope categories,\nwhich were kept for analysis in this paper, are marked with bolded text.\nNote on Source Table Data\nTwo of our collection methods for posts were added to improve comprehensiveness \u2014 collections from\nback-filled tweets, and collections based on key location terms which we anticipated would be the site of\nsignificant election rumoring. However, including these slightly changes the composition of the dataset in\nskewing ways. Approximately 5.6% of our dataset came from the locations collector, while approximately 0.08%\ncame from the back-filling collector. In the analyses above, we chose to use the more comprehensive collection\nand include all tweets. We ran the geographic analysis without the tweets from the locations collector, and found\nno distinguishable changes in results. For other researchers focusing on different questions, excluding these\ntweets may be appropriate - we provide the data on tweets collected solely through these means in the source\ntable.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "ElectionRumors2022: A dataset of election rumors on Twitter during the 2022 US midterms", "author": ["JS Schafer", "K Duskin", "S Prochaska", "M Wack"], "pub_year": "2024", "venue": "arXiv preprint arXiv \u2026", "abstract": "Understanding the spread of online rumors is a pressing societal challenge and an active  area of research across domains. In the context of the 2022 US midterm elections, one"}, "filled": false, "gsrank": 629, "pub_url": "https://arxiv.org/abs/2407.16051", "author_id": ["O1h3-RIAAAAJ", "6EsQFT8AAAAJ", "", "AScyny0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:yHbjv27Dv1kJ:scholar.google.com/&output=cite&scirp=628&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D620%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=yHbjv27Dv1kJ&ei=d7WsaKCIGLXCieoP4PfQ0A8&json=", "num_citations": 5, "citedby_url": "/scholar?cites=6467102470360495816&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:yHbjv27Dv1kJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2407.16051"}}, {"title": "Cross-Partisan Discussions on YouTube: Conservatives Talk to Liberals but Liberals Don't Talk to Conservatives", "year": "2021", "pdf_data": "Cross-Partisan Discussions on YouTube:\nConservatives Talk to Liberals but Liberals Don\u2019t Talk to Conservatives\nSiqi Wu1,2, Paul Resnick1\n1University of Michigan\n2Australian National University\nfsiqiwu, presnickg@umich.edu\nAbstract\nWe present the \ufb01rst large-scale measurement study of cross-\npartisan discussions between liberals and conservatives on\nYouTube, based on a dataset of 274,241 political videos from\n973 channels of US partisan media and 134M comments from\n9.3M users over eight months in 2020. Contrary to a sim-\nple narrative of echo chambers, we \ufb01nd a surprising amount\nof cross-talk: most users with at least 10 comments posted\nat least once on both left-leaning and right-leaning YouTube\nchannels. Cross-talk, however, was not symmetric. Based on\nthe user leaning predicted by a hierarchical attention model,\nwe \ufb01nd that conservatives were much more likely to comment\non left-leaning videos than liberals on right-leaning videos.\nSecondly, YouTube\u2019s comment sorting algorithm made cross-\npartisan comments modestly less visible; for example, com-\nments from conservatives made up 26.3% of all comments on\nleft-leaning videos but just over 20% of the comments were in\nthe top 20 positions. Lastly, using Perspective API\u2019s toxicity\nscore as a measure of quality, we \ufb01nd that conservatives were\nnot signi\ufb01cantly more toxic than liberals when users directly\ncommented on the content of videos. However, when users\nreplied to comments from other users, we \ufb01nd that cross-\npartisan replies were more toxic than co-partisan replies on\nboth left-leaning and right-leaning videos, with cross-partisan\nreplies being especially toxic on the replier\u2019s home turf.\n1 Introduction\nPolitical scientists and communication scholars have raised\nconcerns that online platforms can act as echo chambers,\nreinforcing people\u2019s pre-existing beliefs by exposing them\nonly to information and commentary from other people with\nsimilar viewpoints (Iyengar and Hahn 2009; Flaxman, Goel,\nand Rao 2016). Echo chambers are concerning because they\ncan drive users to adopt more extreme positions and re-\nduce the chance for building the common ground and le-\ngitimacy of political compromises (Pariser 2011; Sunstein\n2018). While prior research has investigated the (negative)\neffects of echo chambers based on small-scale user surveys\nand controlled experiments (An, Quercia, and Crowcroft\n2014; Dubois and Blank 2018), one fundamental question\nstill remains unclear: to what degree do users experience\necho chambers in real online environments?\nCopyright c\r2021, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: There is a surprising amount of cross-talk between\nleft-leaning and right-leaning YouTube channels. Each node\nis a channel. Node size is proportional to the number of users\nwho comment. Edge width is scaled by the number of users\ncommenting on channels at both ends. This plot re\ufb02ects only\nactive users, those who posted at least 10 comments.\nOne countermeasure for mitigating echo chambers is to\npromote information exchange among individuals with dif-\nferent political ideologies. Cross-partisan communication,\nor cross-talk, has thus become an important research subject.\nResearchers have studied cross-partisan communication on\nplatforms such as Twitter (Lietz et al. 2014; Garimella et al.\n2018; Eady et al. 2019), Facebook (Bakshy, Messing, and\nAdamic 2015), and Reddit (An et al. 2019). However, little\nis known about YouTube, which has become an emerging\nsource for disseminating news and an active forum for dis-\ncussing political affairs. According to a recent survey from\nPew Research Center (Stocking et al. 2020), 26% Americans\ngot news on YouTube, and 51% of them primarily looked for\nopinions and commentary on the videos.\nTo \ufb01ll this gap, we curated a new dataset that tracked user\ncomments on YouTube videos from US political channels.\nFocusing on active users who posted at least 10 comments\neach, the top-line surprising result is that most commenters\ndid not con\ufb01ne themselves to just left-leaning or just right-\nleaning channels1. Figure 1 visualizes the shared audience\nnetwork between channels. The blue and red dashed circles\nrespectively enclose the left-leaning and right-leaning chan-\n1We replicated the analyses based on users with at least 2 com-\nments to users with at least 30 comments. The results are qualita-\ntively similar and supplemented in Appendix A.\nProceedingsoftheFifteenth InternationalAAAIConferenceonWebandSocial Media(ICWSM2021)\n808\nnels. In each circle, we show the top 3 most commented\nchannels. Edges represent audience overlap, i.e., the num-\nber of people who commented on both channels. We \ufb01nd\nthat 69.3% of commenters posted at least once on both left-\nleaning and right-leaning channels. Together, those users\u2019\ncomments made up 85.5% of all comments. This example\nillustrates that a signi\ufb01cant amount of YouTube users have\nparticipated in cross-partisan political discussions.\nIn this work, we tackled three open questions related\nto cross-partisan discussions on YouTube. First, what is\nthe prevalence of cross-talk? The theory of selective ex-\nposure suggests that people deliberately avoid information\nchallenging their viewpoints (Hart et al. 2009). Thus, one\nmight expect few interactions across political lines. How-\never, survey studies have found con\ufb02icting evidence that\npeople are aware of and sometimes even seek out counter-\narguments (Horrigan, Garrett, and Resnick 2004; An, Quer-\ncia, and Crowcroft 2014), and that political \ufb01lter bubbles are\nactually occurring to a limited extent (An et al. 2011; Dubois\nand Blank 2018). To address this question, we trained a hi-\nerarchical attention model (Yang et al. 2016) to predict a\nuser\u2019s political leaning based on the comment collection s/he\nposted. We \ufb01nd that cross-partisan communication was not\nsymmetric: on the user level, conservatives were more likely\nto post on left-leaning videos than liberals on right-leaning\nvideos; on the video level, especially on videos published by\nright-leaning independent media, there were relatively few\ncomments from liberals.\nSecond, does YouTube promote cross-talk? YouTube\u2019s\nrecommender system has been criticized for creating echo\nchambers in terms of which videos users would be rec-\nommended (Lewis 2018). Here, we examined whether the\nsorting of comments on the video pages tended to suppress\ncross-talk. We examined the fraction of cross-partisan com-\nments shown in the top 20 positions. While the position bias\nfor each successive position was small, overall comments\nfrom the opposite ideologies appeared less frequently among\nthe top positions than their total numbers would predict.\nThird, what is the quality of cross-talk? Discussions on\nYouTube are multifaceted \u2013 a user can reply to the content\nof videos, or reply to another user who commented before.\nThe conversation quality may differ depending on whom the\ncomments reply to and where the discussions take place.\nWe used toxicity as a measure of quality and used an open\ntool \u2013 Perspective API (Jigsaw 2021) \u2013 to classify whether\na comment is toxic or not. We \ufb01nd only small differences\nin toxicity of comments targeting the video content. We \ufb01nd\ncomments that reply to people with opposing views were\nmuch more frequently toxic than co-partisan replies. Fur-\nthermore, cross-partisan replies were especially more toxic\non a replier\u2019s home territory: i.e., when liberals replying to\nconservatives on left-leaning videos and when conservatives\nreplying to liberals on right-leaning videos.\nThe main contributions of this work include:\n\u000fa procedure for estimating the prevalence of cross-\npartisan discussions on YouTube;\n\u000fa \ufb01nding that cross-partisan comments are common, but\nmuch more frequently by conservatives on left-leaningvideos than by liberals on right-leaning videos;\n\u000fa \ufb01nding that cross-partisan comments are less likely to\nappear in the top positions on the video pages;\n\u000fa \ufb01nding that cross-partisan comments are more toxic, and\nfurther deteriorate when replying to users of the opposite\nideology on one\u2019s home turf;\n\u000fa new political discussion dataset that contains 274,241\npolitical videos published by 973 channels of US partisan\nmedia and 134M comments posted by 9.3M users.2\n2 Related Work\n2.1 Echo Chambers and Affective Polarization\nResearch on echo chamber dates back to cognitive disso-\nnance theory in the 1950s (Festinger 1957), which argued\nthat people tended to seek out information that they agreed\non in order to minimize dissonance. Since then, there have\nbeen persistent concerns that the advances of modern tech-\nniques may exacerbate the extent of ideological echo cham-\nbers by making it easier for users to receive a personalized\ninformation feed that Negroponte (1996) referred to as the\n\u201cDaily Me\u201d or even be automatically insulated inside the\n\u201c\ufb01lter bubbles\u201d by algorithms that feed users more things\nlike what they have seen before (Pariser 2011). Concerns\nhave been raised that isolation in echo chambers will drive\npeople towards more extreme opinions over time (Sunstein\n2018) and to heightened affective polarization \u2013 animosity\ntowards people with different political views.\nHowever, evidence is mixed on the extent to which peo-\nple really prefer to be in the echo chambers. Iyengar and\nHahn (2009) found partisan divisions in attention that peo-\nple gave to articles based on the ideological match with the\nmainstream news source (Fox News, NPR, CNN, BBC) to\nwhich articles were arti\ufb01cially attributed to. On the other\nhand, Garrett (2009) argued that people have a preference\nfor encountering some reinforcing information but not nec-\nessarily an aversion to challenging information, and Munson\nand Resnick (2010) found that some people showed a prefer-\nence for collections of news items that had more ideological\ndiversity. Gentzkow and Shapiro (2011) found that ideolog-\nical segregation of online news consumption was relatively\nlow and less than ideological segregation of face-to-face in-\nteractions, but higher than segregation of of\ufb02ine news con-\nsumption. Dubois and Blank (2018), in a survey of 2,000 UK\nInternet users, found that people who were more politically\nengaged reported more exposure to opinions that they dis-\nagreed with and more exposure to things that might change\ntheir minds. In a case study, Quattrociocchi, Scala, and Sun-\nstein (2016) found little overlap between the users who com-\nmented on Facebook posts articulating conspiracy narratives\nvs. on mainstream science narratives under the same topic.\nIn a study based on a sample of Twitter users, Eady et al.\n(2019) found that the most conservative \ufb01fth had more than\n12% of the media accounts that they followed at least as left\nas the New York Times; the liberal \ufb01fth had 4% of the media\naccounts that they followed at least as right as Fox News.\n2The code and anonymized data are publicly available at https:\n//github.com/avalanchesiqi/youtube-crosstalk.\n809\nEvidence is also mixed on the extent to which algorithms\nare promoting echo chambers, and whether they lead peo-\nple to more extreme opinions. An et al. (2011) found that\nmany Twitter users were indirectly exposed to media sources\nwith a different political ideology. In a large-scale brows-\ning behavior analysis, Flaxman, Goel, and Rao (2016) found\nthat people were less segregated in the average leaning of\nmedia sites that they accessed directly than those they ac-\ncessed through search and social media feeds, but there was\nmore variety in the ideologies of individuals who were ex-\nposed through search and social media. On Facebook, Bak-\nshy, Messing, and Adamic (2015) found substantial expo-\nsure to challenging viewpoints; more than 20% of news\narticles that liberal clicked on was cross-cutting (meaning\nit had a primarily conservative audience) and for conser-\nvatives, nearly 30% of news articles that they clicked on\nhad a primarily liberal audience. Hussein, Juneja, and Mitra\n(2020) audited \ufb01ve search topics on YouTube and found that\nwatching videos containing misinformation led to more mis-\ninformation videos being recommended to watch. Ribeiro\net al. (2020) found that users migrated over time from alt-\nlite channels to more extreme alt-right channels, but that the\nvideo recommender algorithm did not link to videos from\nthose more extreme channels; (Ledwich and Zaitsev 2020)\nalso found that the YouTube recommender pushed viewers\ntoward mainstream media rather than extreme content.\nFinally, there have also been studies with con\ufb02icting re-\nsults about whether exposure to diverse views increases or\ndecreases affective polarization. (Garrett et al. 2014) hypoth-\nesized that exposure to concordant news sources would ac-\ntivate partisan identity and thus increase affective polariza-\ntion, while exposure to out-party news sources will reduce\npartisan identity and thus affective polarization. They found\nevidence consistent with these hypotheses based on surveys\nof U.S. and Israeli voters. On the other hand, in a \ufb01eld ex-\nperiment, Bail et al. (2018) found that people who were paid\nto follow a bot account that retweeted opposing politicians\nand commentators became more extreme in their own opin-\nions, though it did not directly assess changes in affective\npolarization.\n2.2 The Nature of Cross-Talk\nThe impact of exposure to opposing opinions may well de-\npend on how that information is presented. This is espe-\ncially true for direct conversations between people. There is\na huge difference between a respectful conversation on the\n\u201d/r/changemyview\u201d subreddit and having a troll join a con-\nversation with the goal of trying to disrupt or elicit angry\nreactions (Phillips 2015; Flores-Saviaga, Keegan, and Sav-\nage 2018). Bail (2021) (Chapter 9) described an experiment\nwhere encounters with others of opposing views were struc-\ntured to hide some ideological and demographic character-\nistics; this led to more moderate political views and reduced\naffective polarization in a survey conducted a week later.\nSome but not all cross-cutting political discussion online\nis adversarial or from trolls. Hua, Ristenpart, and Naaman\n(2020) developed a technique for measuring the extent to\nwhich interactions with a particular political \ufb01gure were in-\ndeed adversarial. An et al. (2019) found that Reddit usersused more complex language and sophisticated reasoning,\nand more posing of questions in two cross-cutting subreddits\nthan those same users did in two homogenous subreddits.\nMore broadly, (Rajadesingan, Resnick, and Budak 2020) re-\nported that across a large number of political subreddits,\nmost individuals who participated in multiple subreddits ad-\njusted their toxicity levels to more closely match that of the\nsubreddits they participated in.\n2.3 Estimating User Political Ideology\nSemi-supervised label propagation is a popular method for\npredicting user political leaning (Zhou, Resnick, and Mei\n2011; Cossard et al. 2020). The core assumption of la-\nbel propagation is homophily \u2013 actions that form the base\nnetwork must be either endorsement or refutation, but not\nboth. However, commenting is ambiguous, which may ex-\npress attitudes of both agreement and disagreement. Some\nresearchers developed Monte Carlo sampling methods for\nclustering users (Barber \u00b4a 2015; Garimella et al. 2018), while\nothers tried to extract predictive textual features (Preot \u00b8iuc-\nPietro et al. 2017; Hemphill and Sch \u00a8opke-Gonzalez 2020).\nRecent advancements in language modeling allow us to in-\nfer user leaning directly from text embedding (Yang et al.\n2016). In this work, we implemented a hierarchical attention\nnetwork model for predicting user political leaning.\n3 YouTube Political Discussion Dataset\nWe constructed a new dataset by collecting user comments\non YouTube political videos. Our dataset consists of 274K\nvideos from 973 US political channels between 2020-01-\n01 and 2020-08-31, along with 134M comments from 9.3M\nusers. In this section, we \ufb01rst describe the collection of\nYouTube channels of US partisan media. We then introduce\nour scheme for coding these channels by types such as na-\ntional, local, or independent media. Lastly, we describe our\nprocedure for collecting videos and comments.\n3.1 YouTube Channels of US Partisan Media\nMBFC-matched YouTube channels. We scraped the bias\nchecking website Media Bias/Fact Check3(MBFC), which\nis a commonly used resource in scienti\ufb01c studies (Bovet and\nMakse 2019; Ribeiro et al. 2020). This yielded 2,307 web-\nsites with reported political leanings. MBFC classi\ufb01es the\nleanings on a 7-point Likert scale (extreme-left, left, center-\nleft, center, center-right, right, extreme-right). The exact de-\ntails of their procedure are not described, but the process\ntakes into account word choices, factual sourcing, story\nchoices, and political af\ufb01liation. Since our focus was on the\nextent of cross-partisan interactions, we collapsed this 7-\npoint classi\ufb01cation: we collapsed fextreme-left, left, center-\nleftg andfextreme-right, right, center-rightg each into one\nleft-leaning and one right-leaning group. We discarded 186\ncenter media. Additionally, the \ufb01rst author examined the ar-\nticles and \u201cabout\u201d page of each site to annotate the media\u2019s\ncountry. Because the ratings of MBFC were based on the US\npolitical scale, we only kept the 1,410 US websites.\n3https://mediabiasfactcheck.com/\n810\nNext, we scraped all those websites to detect YouTube\nlinks. This yielded 450 websites with YouTube channels. For\nthe unresolved websites, we queried the YouTube search bar\nwith their URLs. We crawled the channel \u201cabout\u201d pages of\nthe top 10 search results and retained the \ufb01rst channel with a\nhyperlink redirecting to the queried website. To improve the\nmatching quality, we used the SequenceMatcher Python\nmodule to compute a similarity score between the YouTube\nchannel title and website title. The score ranges from 0 to\n1, where 1 indicates exact match. The \ufb01rst author manually\nchecked and labeled any site with either similarity score be-\nlow 0.5 or with no search result. In total, this mapped 929\nYouTube channels to the corresponding US partisan web-\nsites, 640 of which published at least one video in 2020.\nAddition of channels featured on those channels. The\nMBFC website has good coverage of mainstream media\nand local newspapers, but not of YouTube political com-\nmentators. Studies have found that scholars, journalists, and\npundits regularly use YouTube to promote political posi-\ntions (Lewis 2018). To expand our dataset, we crawled the\n\u201cfeatured channels\u201d listed on the 640 MBFC-matched active\nYouTube channels. Channels choose which other channels\nthey want to feature in this way. We did not observe any\nchannel that was featured by both a left-leaning channel and\na right-leaning channel among our 640 channels. Therefore,\nwe added these featured channels to our dataset and labeled\nthem with the same political ideology as the channels featur-\ning it. Our approach was validated on the 62 MBFC-matched\nchannels that were also featured by some other MBFC-\nmatched channels. We compared their predicted leanings to\nthe MBFC labels and found that all 62 channels are correctly\npredicted. This yielded 637 additional channels.\nAddition of existing YouTube media bias datasets. We\nfurther augmented our list of channels with three existing\nYouTube media bias datasets (Lewis 2018; Ribeiro et al.\n2020; Ledwich and Zaitsev 2020). These datasets were an-\nnotated by the authors of corresponding papers. After dis-\ncarding the intersections and center channels, we obtained\n356 additional channels with known political leanings.\n3.2 Channel Coding Scheme\nThe \ufb01rst author manually coded the collected channels by\nassessing their descriptions on YouTube and Wikipedia.\nPew Research Center has also proposed a similar coding\nscheme (Stocking et al. 2020).\n\u000fNational media: channels of televisions, radios, or news-\npapers from major US news conglomerates (e.g., CNN,\nFox News, New York Times) and high pro\ufb01le politicians\n(e.g., Donald Trump and Joe Biden). They cover stories\nacross multiple areas and have national readership.\n\u000fLocal media: channels of media publishing or broadcast-\ning in small \ufb01nite areas. They usually focus on local news\nand have local readership (e.g., Arizona Daily Sun, Texas\nTribune, ABC11-WTVD, CBS Boston).\n\u000fOrganizations: channels of governments, NGOs, advo-\ncacy groups, or research institutions (e.g., White House,\nGOP War Room, Hoover Institution).left-leaning right-leaning total\n#channels 462 (47.5%) 511 (52.5%) 973\n#videos 195,482 (71.3%) 78,759 (28.7%) 274,241\n#views 13.4B (71.7%) 5.3B (28.3%) 18.7B\n#comments 79.5M (59.4%) 54.3M (40.6%) 133.8M\nTable 1: Statistics of YouTube political discussion dataset.\n\u000fIndependent media: channels that have no clear af\ufb01liation\nwith any organization (e.g., The Young Turks, Breitbart)\nand content producers who make political commentary\nvideos (e.g., Ben Shapiro, Paul Joseph Watson).\n3.3 Video and Comment Collection\nFiltering out non-political channels. We removed non-\npolitical channels (e.g., music, gaming) because comments\nby liberals and conservatives on these channels are often\nnot about politics and thus are not necessarily indicative of\ncross-partisan communication. On the channel level, since\nYouTube did not provide a category label, the \ufb01rst author\nmanually reviewed 10 random videos of each channel from\n2020. Channels were removed if they did not publish any\nvideo in 2020 or none of their 10 randomly selected videos\nwas relevant to US news and politics.\nFiltering out non-political videos. Political channels some-\ntimes published non-political videos, which we wanted to\nexclude from our dataset. Channels can tag each video with\none of 15 categories. We kept videos that were tagged with\nthe following six categories: \u201cNews & Politics, Nonpro\ufb01ts\n& Activism, Entertainment, Comedy, People & Blogs, Edu-\ncation\u201d. Categories such as Music, Sport, and Gaming were\nexcluded. We retained Entertainment and Comedy because\nwe found that independent media often used these tags even\nwhen the videos were clearly related to politics.\nCollecting video and comment metadata. Altogether, we\ncollected 274,241 political videos where commenting was\npermitted, and published by the 973 channels of US partisan\nmedia between 2020-01-01 and 2020-08-31. For each video,\nwe collected its title, category, description, keywords, view\ncount4, transcripts, and comments.\nYouTube provided two options for sorting video com-\nments \u2013 Top comments orNewest first (Figure 2a).\nWithout scrolling or clicking, the YouTube web interface\ndisplayed the top 20 root comments by default (Figure 2b),\nmaking them enjoy signi\ufb01cantly more exposure than the\ncollapsed replies (Figure 2c). We \ufb01rst queried the Top\ncomments tab to scrape the 20 root comments for inves-\ntigating the bias in YouTube\u2019s comment sorting algorithm\n(see Section 6). We also queried the Newest first tab\nto scrape all the root comments and replies. For each com-\n4Our data collection started on 2020-10-15 and took a week to\n\ufb01nish. All collected videos had been on YouTube for at least 45\ndays. A previous study of 459,728 political videos from a public\nYouTube dataset (Wu, Rizoiu, and Xie 2018) found that on average,\n90.6% of views were accumulated within the \ufb01rst 45 days. Thus,\nwe considered our observed video view counts as the \u201clifetime\u201d\nview counts.\n811\nFigure 2: Snapshot of the comment section of a CNN video\n(id:B2e35AbLP Y). (a) two options to sort comments. (b)\nroot comments. (c) replies under a root comment. (d) reply-\nto relation between comments, e.g., B replied to A, and C\nreplied to B. Usernames were shaded by their predicted po-\nlitical leanings. The two highest ranked root comments on\nthis left-leaning CNN video were from conservatives.\nFigure 3: (a) PDF of comments per video, disaggregated by\npolitical leanings. (b) CCDF of comments per user.\nment, we collected its comment id, author, and text. Note\nthat root comments and replies had distinct formats of com-\nment ids \u2013 let\u2019s assume the comment id of a root comment\nwas \u201cA\u201d, then its replies would have comment ids of the for-\nmat \u201cA.B\u201d. The comment ids allowed us to reconstruct the\nconversation threads under root comments, i.e., who replied\nto whom. For example, both \u201cB replied to A\u201d and \u201cC replied\nto B\u201d in Figure 2(d) were cross-partisan comments. In total,\nwe collected 133,810,991 comments from 9,304,653 users.\nTable 1 summarizes the dataset statistics. We collected\nmore right-leaning channels but they published fewer videos\non average. Left-leaning videos had similar average views\nbut fewer comments per video compared to right-leaning\nvideos. Figure 3(a) plots the probability density function\n(PDF) of comments per video. We observe a higher por-\ntion of right-leaning videos with large comment volume.\nIn Figure 3(b), we plot the complementary cumulative den-\nsity function (CCDF) of comments per user. 16.7% of users\nposted at least 10 comments.\n4 Predicting User Political Leaning\nIn this section, we \ufb01rst determined the ideological lean-\ning for a set of seed users based on (a) political hashtags\nand URLs in the comments, and (b) left-leaning and right-\nleaning channels that users subscribed to. Next, we trained\na hierarchical attention model based on the comment textsfrom seed users, and then predicted the political leaning for\nthe remaining users.\n4.1 Obtaining Labels for Seed Users\nPolitical hashtags and URLs. Hashtags are widely used to\npromote online activism. Research has shown that the adop-\ntion of political hashtags is highly polarized \u2013 users often use\nhashtags that support their ideologies and rarely use hash-\ntags from the opposite side (Hua, Ristenpart, and Naaman\n2020). We extracted 231,483 hashtags from all 134M com-\nments. The \ufb01rst author manually examined the 1,239 hash-\ntags appearing in at least 100 comments, out of which 306\nleft and 244 right hashtags were identi\ufb01ed as seed hashtags5.\nUsers sometimes shared URLs in the comments. If a\nURL redirected to a left-leaning MBFC website or a left-\nleaning YouTube video, we replaced the URL text in the\ncomment with a special token LEFT URL. We resolved to\nRIGHT URL in the same way.\nFor simplicity, we used the term \u201centity\u201d to refer to both\nhashtag and URL. We constructed a user-entity bipartitie\ngraph, in which each node was either a user or an entity.\nUndirected edges were formed only between users and enti-\nties. Next, we applied a label propagation algorithm on the\nbipartite graph (Liu et al. 2016). The algorithm was built\nupon two assumptions: (a) liberals (conservatives) mostly\nuse left (right) entities; (b) left (right) entities are mostly\nused by liberals (conservatives).\n.Step 1: from entities to users. For each user, we counted\nthe number of used left and right entities, denoted as Eland\nEr, respectively. Users who shared fewer than 5 entities, i.e.,\nEl+Er<5, were excluded. We used the following equation\nto compute a homogeneity score:\n\u000e(l;r) =r\u0000l\nr+l(1)\n\u000eranges from -1 to 1, where -1 (or 1) indicates that this\nuser exclusively used left (or right) entities. The same scor-\ning function has also been used by Robertson et al. (2018).\nSince we focused on the precision rather than recall in iden-\ntifying seed users, we considered a user to be liberal if\n\u000e(El;Er)\u0014\u00000:9and conservative if \u000e(El;Er)\u00150:9.\n.Step 2: from users to entities. We only propagated\nuser labels to hashtags, but not URLs because most URLs\napart from the MBFC websites were non-political. For each\nhashtag, we counted the number of liberals and conser-\nvatives who used it, denoted as HlandHr, respectively.\nWe excluded hashtags shared by fewer than 5 users, i.e.,\nHl+Hr<5. Using Equation (1), a hashtag was con-\nsidered left if \u000e(Hl;Hr)\u0014 \u0000 0:9and considered right if\n\u000e(Hl;Hr)\u00150:9.\nBeginning with the manually identi\ufb01ed 306 left and 244\nright hashtags, we repeatedly predicted user leanings in Step\n5We did not include hashtags that describe a person (e.g., #don-\naldtrump) or a social movement (e.g., #metoo) as they may be used\nby both liberals and conservatives. Instead, we considered hash-\ntags that posit clear stance towards political parties (e.g., #voteblue,\n#nevertrump), or hashtags that promote agendas mostly supported\nby one party (e.g., #medicareforall, #prolife).\n812\n1, and then updated the set of political hashtags in Step 2.\nWe repeated this process until no new user nor new hashtag\nwas obtained. This yielded 8,616 liberals and 8,144 conser-\nvatives, denoted as Seed ent, based on an expanded set of\n834 left and 717 right hashtags.\nUser subscriptions. For the 1,555,428 (16.7%) users who\nposted at least 10 comments, we scraped their subscrip-\ntion lists on YouTube, i.e., channels that a user subscribed\nto. A total of 476,701 (30.6%) users subscribed to at least\none channel. For each user, we counted the number of\nleft-leaning and right-leaning channels in their subscrip-\ntion list, denoted as SlandSr, respectively. We excluded\nusers who subscribed to fewer than 5 partisan channels, i.e.,\nSl+Sr<5. Using Equation (1), a user was considered\nliberal if\u000e(Sl;Sr)\u0014\u00000:9and considered conservative if\n\u000e(Sl;Sr)\u00150:9. This yielded 61,320 liberals and 86,134\nconservatives from subscriptions, denoted as Seed sub.\nValidation. We compared Seed enttoSeed sub. They had\nan intersection of 2,035 users, among which 1,958 (96.2%)\nusers had the same predicted labels, suggesting a very high\nagreement. Given this validation, we merged Seed entwith\nSeed sub, while removing the remaining 77 users with con-\n\ufb02icted labels. This leaves a total of 162,102 seed users\n(68,883 liberals and 93,219 conservatives).\nMentioning a hashtag, sharing an URL, and subscribing\nto a channel are all endorsement actions. They all satisfy the\nhomophily assumption of the label propagation algorithms.\nHowever, most users in our dataset did not have such en-\ndorsement behaviors. The coverage of identi\ufb01ed seed users\nwas low (162K out of 9.4M, 1.7%). For the remaining users,\nwe used methods that could infer user political leanings\nsolely based on the collection of comment texts.\n4.2 Classi\ufb01cation by Hierarchical Attention\nNetwork\nHierarchical Attention Network (HAN) is a deep learning\nmodel for document classi\ufb01cation (Yang et al. 2016). HAN\ndifferentiates itself from other text classi\ufb01cation methods in\ntwo ways: (a) it captures the hierarchical structure of text\ndata, i.e., a document consists of many sentences and a sen-\ntence consists of many words; (b) it implements an attention\nmechanism to select important sentences in the document\nand important words in the sentences. Researchers have ap-\nplied HAN in many classi\ufb01cation tasks on social media and\nshown that HAN is one of the top performers (Cheng et al.\n2019). HAN is a suitable choice for our task of predicting\nuser political leaning, because a user posts many comments\nand each comment consists of many words.\nExperiment setup. We used the 162K seed users as training\nset. For each user, we treated their comments as independent\nsentences, and we concatenated all comments into one doc-\nument. We replaced URLs by their primary domains. Punc-\ntuation and English stopwords were also removed. We em-\nployed 5-fold cross validation, which ensured that all seed\nusers will be estimated and evaluated once.\nPrediction results. The outputs of HAN are two normalized\nvaluesPlandPrvia the softmax activation (P l+Pr= 1).\nThe model classi\ufb01es a user as conservative if Pr>0:5,\nFigure 4: HAN classi\ufb01cation results of 162K seed users.\nThe x-axis is Prfrom the HAN model, which indicates how\nlikely a user to be conservative. (a) The HAN model is con-\n\ufb01dent (i.e.,Pr\u00140:05orPr\u00150:95) in predicting the ma-\njority of seed users. (b) When the HAN model is con\ufb01dent,\nit achieves very high accuracy. We classi\ufb01ed user political\nleaning as unknown if 0:05<P r<0:95.\notherwise as liberal. Figure 4(a) shows the frequency dis-\ntribution of Prfor the 162K seed users. We binarized Pr\ninto 20 buckets. 91.6% of seed users fell into the leftmost\n(Pr\u00140:05) or the rightmost (P r\u00150:95) buckets, suggest-\ning that our trained HAN was very con\ufb01dent about the pre-\ndiction results. We show the number of true liberals and true\nconservatives in each bucket as a stacked bar. In Figure 4(b),\nwe plot the accuracy of each bucket. The accuracy was 0.943\nwhen predicting liberal with Pr\u00140:05, and 0.969 when\npredicting conservative with Pr\u00150:95. The prediction\npower dropped signi\ufb01cantly when 0:05< P r<0:95, but\nthere were relatively few users in that range. The overall ac-\ncuracy was 0.929.\nIn practice, some users may have no comment that can re-\nveal their political leanings, e.g., comment spammers. Other\nusers may have a mixed ideology. We thus divided users into\nthree bins based on thresholds of our HAN model output: a\nuser is classi\ufb01ed as liberal if Pr\u00140:05, as conservative if\nPr\u00150:95, otherwise as unknown (see Figure 4b).\nAfter training, we had \ufb01ve HAN models, each trained on\none fold of 80% data. In the inference phase, if any two mod-\nels gave con\ufb02icting predictions for the same user, we set that\nuser to the unknown class. This yielded known classi\ufb01ca-\ntions for 6,370,150 users (3,738,714 liberals and 2,631,436\nconservatives). Combining with the 162K seed users, we\nassigned political leanings for 6.53M (69.7%) users, who\nposted 123M (91.9%) comments. For comparison, we also\nimplemented a Vanilla LSTM model, which achieved sim-\nilar overall accuracy of 0.922. However, after setting users\nwith0:05<P r<0:95to unknown, LSTM yielded a lower\ncoverage of classi\ufb01ed users. We thus used the classi\ufb01cation\nresults from HAN in the following analysis.\nVisualizing HAN. One advantage of HAN is that it can dif-\nferentiate important sentences and words. Figure 5 visual-\nizes the attention masks for comments from a liberal user.\nEach line is a separate comment. The top two comments\ncontribute the most to prediction result. Our model can select\nwords with correct political leaning. Those include existing\nwords in our expanded hashtag set such as joebiden2020 and\ntrumpvirus, as well as new words such as privilege, worst,\nandnightmare.\n813\nFigure 5: Visualizing HAN. Darker blue indicates important\ncomments, while darker red indicates important words.\n5 Prevalence Analysis\nWe studied three questions related to the prevalence of cross-\npartisan discussions between liberals and conservatives. We\n\ufb01rst quanti\ufb01ed the portions of cross-partisan comments from\na user-centric view, then and from a video-centric view. Fi-\nnally, we investigated whether the extent of cross-talk varied\non different media types.\n5.1 How Often Do Users Post on Opposing\nChannels?\nWe empirically measured how often a YouTube user com-\nmented on videos with opposite ideologies. For active users\nwith at least 10 comments, we counted the frequencies that\nthey posted on left-leaning and right-leaning videos. The\nHAN model classi\ufb01ed 90.1% of the active users as either lib-\neral or conservative. Among them, 62.2% of liberals posted\nat least once on right-leaning videos, while 82.3% conserva-\ntives posted at least once on left-leaning videos.\nFigure 6 plots the fraction of users\u2019 comments that were\ncross-partisan, as a function of how proli\ufb01c the users were\nat commenting. Overall, conservatives posted much more\nfrequently on left-leaning videos (median: 22.2%, mean:\n33.9%) than liberals on right-leaning videos (median: 4.8%,\nmean: 15.6%). The fractions of cross-partisan comments\nfrom liberals were largely invariant to user activity level\n(Figure 6a). By contrast, proli\ufb01c conservatives dispropor-\ntionately commented on left-leaning videos (Figure 6b). The\nfew most proli\ufb01c conservative commenters with more than\n10,000 comments made more than half their comments on\nleft-leaning videos, suggesting a potential trolling behavior.\nNevertheless, even for less proli\ufb01c conservatives, they still\ncommented on left-leaning videos far more frequently than\nliberals did on right-leaning videos.\n5.2 How Many Cross-Partisan Comments Do\nVideos Attract?\nWe also quanti\ufb01ed cross-partisan discussions on the video\nlevel. For videos with at least 10 comments, we counted the\nnumber of comments posted by liberals and posted by con-\nservatives. Figure 7 plots the fraction of cross-partisan com-\nments on (a) left-leaning and (b) right-leaning videos. We\nmake two observations here:\nFirst, higher fraction of cross-partisan comments occurred\non left-leaning videos (median: 28%, mean: 29.5%) than\non right-leaning videos (median: 8.6%, mean: 13.4%). This\nresult provides a new angle for explaining the creation\nof conservative echo chambers online (Garrett 2009; Lima\nFigure 6: Analysis of users\u2019 cross-partisan interaction: con-\nservatives were more likely to comment on left-leaning\nvideos than liberals on right-leaning videos. The x-axis\nshows the total number of comments from the user, split\ninto 21 equally wide bins in log scale. The y-axis shows the\npercentage of comments on videos with opposing ideolo-\ngies. Within each bin, we computed the 1st quartile, median,\nand 3rd quartile. The line with circles connects the medians,\nwhile the two dashed lines indicate the inter-quartile range.\nFigure 7: Analysis of videos: there were more cross-partisan\ncomments on left-leaning videos than these on right-leaning\nvideos. The x-axis shows the video view counts and it is\ndivided into 21 equally wide bins in log scale. Each bin con-\ntains 553 to 7,527 videos. The lines indicate median and\ninter-quartile range.\net al. 2018). For random viewers who watched right-leaning\nvideos and browsed the discussions there, they would be\nexposed to very few comments from liberals. On the other\nhand, users might experience relatively more balanced dis-\ncussions on the left-leaning videos since about one in three\ncomments there was made by conservatives.\nSecond, the correlations between video popularity and\ncross-partisan comments were opposite for left-leaning and\nright-leaning videos. When left-leaning videos attracted\nmore views, the fraction of comments from conservatives\nbecame lower. On the contrary, the fraction of comments\nfrom liberals was higher on right-leaning videos when the\nvideos attracted more views. This \ufb01nding reveals potentially\ndifferent strategies when politically polarized users carry out\ncross-partisan communication: while conservatives occupy\nthe discussion spaces in less popular left-leaning videos, lib-\nerals largely comment on high pro\ufb01le right-leaning videos.\n5.3 Which Media Types Attract More\nCross-Partisan Comments?\nUsing our media coding scheme introduced in Section 3.1,\nwe examined the extent of cross-talk in the four media types.\nWe excluded videos with less than 10 comments and then re-\nmoved channels with less than \ufb01ve videos. For each channel,\nwe computed the mean fraction of cross-partisan comments\n814\nFigure 8: Analysis of media types. Local news channels at-\ntracted balanced audiences. By contrast, on right-leaning in-\ndependent media, very few comments were posted by lib-\nerals. The outlines are kernel density estimates for the left-\nleaning and right-leaning channels. The center dashed line\nis the median, whereas the two outer lines denote the inter-\nquartile range.\nover all of its videos, dubbed \u0016\u0011(c). The metric \u0016\u0011(c)can be\ninterpreted as the expected rate of cross-talk appearing on an\naverage video of a given channel c.\nFigure 8 shows the distributions of \u0016\u0011(c)in a violin plot,\ndisaggregated by media types and political leanings. Right-\nleaning channels received relatively fewer cross-partisan\ncomments than the corresponding left-leaning channels\nacross all four media types (statistically signi\ufb01cant in one-\nsided Mann-Whitney U test at signi\ufb01cance level of 0.05).\nIn particular, half of right-leaning independent media had\nfewer than 10.7% comments from liberals, exposing their\naudience to a more homogeneous environment. For exam-\nple, \u201cTimcast\u201d, who was the most commented right-leaning\nindependent media in our dataset, had only 3.3 comments\nfrom liberals in every 100 comments. This phenomenon\nstresses the potential harm for those who engage with ring-\nwing political commentary, because the discussions there of-\nten happen within the conservative echo chambers, which\nmay in turn foster the circulation of rumors and misinfor-\nmation (Grinberg et al. 2019). On the other hand, the two\nprominent US news outlets \u2013 CNN and Fox News \u2013 were\nboth crucial ground for cross-partisan discussions, having\n\u0016\u0011(c)of 35.8% and 31%, respectively.\n6 Bias in YouTube\u2019s Comment Sorting\nWhile biases in YouTube\u2019s video recommendation algo-\nrithms have been investigated (Hussein, Juneja, and Mitra\n2020), potential bias in its comment sorting algorithm is still\nunexplored. Presumably, YouTube ranks comments on the\nvideo pages based on recency, upvotes, and perhaps some\nreputation measure of the commenters, but not explicitly on\nwhether the ideology of the commenter matches that of the\nchannel. However, the suppression of cross-partisan com-\nmunication may be a side effect of popularity bias (Wu, Ri-\nzoiu, and Xie 2019). For example, comments from the same\nideological group may naturally attract more upvotes. Since\nYouTube has become an emerging platform for online polit-\nical discussions to take place, it is important to understand\nthe impacts of the comment ranking algorithm.\nYouTube provides two options to sort the comments\n(see Figure 2a). While the Newest first displays com-\nments in a reverse-chronological order, Top comments is\nFigure 9: Root comments from conservatives on left-leaning\nvideos and liberals on right-leaning videos were less likely\nto appear among the top 20 positions. The line charts show\nthe fractions of cross-partisan comments at each position,\nwhile the bar charts show the overall fraction of cross-\npartisan comments.\na black box algorithm that sorts and initially displays 20 root\ncomments. The default view shows Top comments. In\nthis section, we investigated the likelihood of position bias\nboth (a) within the top 20 comments and (b) between the\ntop 20 and the remaining comments. We selected all videos\nwith more than 20 root comments6. This yielded 64,876 left-\nleaning and 44,253 right-leaning videos.\nFigure 9 shows the fraction of cross-partisan comments at\neach of the top 20 positions, as well as the overall prevalence\nover all sampled videos. We observe a subtle trend over\nthe top 20 successive positions. More prominently, cross-\npartisan comments among the top 20 were less than the\noverall rate. For example, for the 65K left-leaning videos,\nthe fraction of comments from conservatives increased from\n20.5% at position 1 to 22.8% at position 20. However, over-\nall 26.3% of comments there were from conservatives. With\nmore than 64K left videos and 44K right videos, the mar-\ngins of error for all estimates were less than 0.41%. Thus\nthe comparisons between the top 20 positions and all po-\nsitions were statistically signi\ufb01cant. This indicates that the\nsorting of Top comments creates a modest position bias\nagainst cross-partisan commentary, further diminishing the\nexposure of conservatives on left-leaning videos and liber-\nals on right-leaning videos.\n7 Toxicity as a Measure of Quality\nWhile many political theorists have argued that exposure to\ndiverse viewpoints has societal bene\ufb01ts, some researchers\nhave also called attention to potential negative effects of\ncross-partisan communication. Bail et al. (2018) showed that\nexposure to politically opposing views could increase polar-\nization. Even when the platforms can connect individuals\nwith opposing views, the conversation may be more about\nshouting rather than meaningful discussions. To this end, we\ncomplemented our prevalence analysis with a measure of the\ntoxicity in the comments. Toxicity is a vague and subjective\nconcept, operationalized as the fraction of human raters who\nwould label something as \u201ca rude, disrespectful, or unrea-\nsonable comment that is likely to make you leave a discus-\n6For videos with no more than 20 root comments, the Top\ncomments algorithm will show all their comments. Hence the dis-\nplay probability is 1 across all positions.\n815\nfromtoleft video right video\nliberal 15.73% 16.31%\nconservative 15.77% 14.44%\nTable 2: Percentage of root comments that are toxic. Bolded\nvalues are posts on opposite ideology videos.\nfromto lib. cons. lib. cons.\non left video on right video\nliberal 12.12% 18.24% 13.42% 15.31%\nconservative 15.24% 11.11% 17.15% 10.18%\nTable 3: Percentage of replies that are toxic. Bolded values\nare replies between two users of opposite ideologies.\nsion (Wulczyn, Thain, and Dixon 2017)\u201d.\nWe obtained the toxicity scores for YouTube comments\nby querying the Perspective API (Jigsaw 2021). The re-\nturned score ranges from 0 to 1, where scores closer to 1\nindicate that a higher fraction of raters will label the com-\nment as toxic. We used 0.7 as a threshold as suggested in\nprior work (Hua, Ristenpart, and Naaman 2020). For each\ncell of Table 2&3, we sampled 100K random comments that\nsatisfy corresponding de\ufb01nitions, and then counted the frac-\ntion of comments deemed toxic. Margins of error were less\nthan 0.24% with the sample size of 100K. The data subsam-\npling was to avoid making excessive API requests.\nSome YouTube comments are at the top level (i.e., root\ncomments, Figure 2b) and some are replies to other com-\nments (Figure 2c). This brings a challenge of assigning com-\nments to the correct targets. Fortunately, YouTube employs\nthe character \u201c@\u201d to specify the target (comment C in Fig-\nure 2d is such case). Hence we were able to curate two sets\nof comments: one contained root comments, the other con-\ntained replies to other users.\nResults. Table 2 reports the frequency of toxic root com-\nments. We \ufb01nd that liberals and conservatives\u2019 root com-\nments had about the same toxicity when posting on left-\nleaning videos. However, conservatives posted fewer toxic\nroot comments on right-leaning videos, and thus slightly\nfewer toxic root comments overall.\nTable 3 reports the frequency of toxic replies. We \ufb01nd\nthat replies to people of opposite ideology were much\nmore frequently toxic, for both liberals and conservatives.\nThere also appears to be a \u201cdefense of home territory\u201d phe-\nnomenon. Conservatives were signi\ufb01cantly more toxic in\ntheir replies to liberals on right-leaning videos (17.15%)\nthan on left-leaning videos (15.24%) and analogously for\nliberals responding to conservatives (18.24% on left-leaning\nvs. 15.31% on right-leaning videos). Commenting on an op-\nposing video generates more hostile responses than com-\nmenting on a same-ideology video. Interestingly, this holds\ntrue even for replies from people who share their ideology.\nFor example, liberals received more toxic replies from liber-\nals on right-leaning videos (13.42% toxic) than they did on\nleft-leaning videos (12.12% toxic).8 Privacy Considerations\nAll data that we gathered was publicly available on the\nYouTube website. It did not require any limited access that\nwould create an expectation of privacy such as the case of\nprivate Facebook groups. The analyses reported in this pa-\nper do not compromise any user identity.\nFor the public dataset that we are making available, how-\never, there are additional privacy concerns due to new forms\nof search that become possible when public data is made\navailable as a single collection. In our released dataset of\ncomments, we take efforts to make it dif\ufb01cult for someone\nwho starts with a known comment authored by a particular\nYouTube user to be able to search for other comments writ-\nten by the same user. Such a search is not currently possible\nwith the YouTube website or API, and so enabling it would\ncreate a privacy reduction for YouTube users. To prevent\nthis, we do not associate any user identi\ufb01er, even a hashed\none, with each comment text.\nWithout the ability to link comments by the authors, it will\nnot be possible for other researchers to reproduce the train-\ning process for our HAN model that predicts a user\u2019s politi-\ncal leaning. The released dataset also does not associate pre-\ndicted political leanings with YouTube user ids. The political\nleaning is a property predicted from the entire collection of\ncomments by a user, and thus is not something that would be\nreadily predicted from the user data that is easily available\nfrom YouTube. Furthermore, political leaning is considered\nsensitive personal information in some countries, including\nthe European Union, which places restrictions on the col-\nlection of such information under the General Data Protec-\ntion Regulation (GDPR 2016). Unfortunately, this limits the\nability of other researchers to produce new analyses of cross-\npartisan communication based on our released dataset.\nInstead, we are releasing our trained HAN model. This\nwill allow other researchers who independently collect a set\nof comments from a single user to predict the political lean-\ning of that user.\n9 Discussion\nThe results challenge, or at least complicate, several com-\nmon narratives about the online political environment.\nThe \ufb01rst is the echo chamber or \ufb01lter bubble hypothe-\nsis, which posits that as people have more options of in-\nformation sources and algorithm-assisted \ufb01ltering of those\nsources, they will naturally end up with exposure only to\nideologically-reinforcing information (Carney et al. 2008),\nas discussed in Section 2. We \ufb01nd that videos on left-leaning\nYouTube channels have a substantial number of comments\nposted by conservatives \u2013 26.2%. While upvoting and the\nYouTube comment sorting algorithm somehow reduce their\nvisibility, there are still more than 20% top comments posted\nby conservatives. On right-leaning videos, there is some-\nwhat less cross-talk, but even there on average nearly two\nof the top 20 comments are from liberals. Only on indepen-\ndent right-leaning channels such as \u201cTimcast\u201d do we see a\ncomment stream that approaches an echo chamber with only\nconservatives posting. Liberals who are concerned about\nthese channels serving as ideological echo chambers might\n816\ndo well to organize participation in them in an effort to di-\nversify the ideologies that are represented.\nOur results offer one direction for design exploration for\nplatforms that want to reduce the extent to which their al-\ngorithms contribute to ideological echo chambers. We have\nshown that user political leaning can be directly estimated\nby the textual features. Hence it is possible to directly in-\ncorporate political ideology into the comment sorting algo-\nrithm, not in order to \ufb01lter out ideologically disagreeable\ncontent but to increase exposure to it. One simple approach\nwould be to stratify sampling based on the fraction of cross-\npartisan comments, hence enforcing cross-talk to some ex-\ntent. A more palatable approach might be to give a boost in\nthe ranking only to those cross-partisan comments that re-\nceive a positive reaction in user upvoting.\nThe second narrative is that conservatives are less open\nto challenging political ideas, and more interested in staying\nin ideological echo chambers. On personality tests, conser-\nvatives score lower on openness to new experiences (Carney\net al. 2008). In a study of German speakers, openness to new\nexperiences was modestly associated with consuming more\nnews sources (Sindermann et al. 2020). In a study of Face-\nbook users, those with higher openness tended to participate\nin a greater diversity of Facebook groups (i.e., groups with\ndifferent central tendencies in the ideology of the partici-\npants) (Matz 2021).\nTo the contrary, we \ufb01nd that conservatives were far more\nlikely to comment on left-leaning videos than liberals were\nto comment on right-leaning videos. More conservatives\nmade at least one cross-partisan comment (82.3% vs. 62.2%)\nand the median fraction of cross-partisan comments among\nconservatives was 22.2%, while the median for liberals was\nonly 4.8%. One possible interpretation is that some of the\nleft-leaning channels that conservatives comment on are\nwhat are often considered as \u201cmainstream\u201d media, where\npeople go to get news regardless of ideology. However, there\nis some evidence from other platforms that conservatives\nmay, on average, seek out more counter-attitudinal informa-\ntion and interactions. On Facebook, Bakshy, Messing, and\nAdamic (2015) found that conservatives clicked on more\ncross-partisan content than liberal did. On Twitter, (Grinberg\net al. 2019) (see Figure 4) found that conservatives were\nmore likely to retweet URLs from left-leaning (non-fake)\nnews sources than liberals were to retweet URLs from right-\nleaning (non-fake) news sources. Also on Twitter, (Eady\net al. 2019) found that conservatives were more likely to fol-\nlow media and political accounts classi\ufb01ed as left-leaning\nthan liberals were to follow right-leaning accounts.\nAn alternative narrative is that conservatives enjoy dis-\nrupting liberal conversations for the \u201clulz\u201d, that they initi-\nate discord by eliciting strong emotional reactions (Phillips\n2015). Given prior research on the general tone of cross-\npartisan communication (Hua, Ristenpart, and Naaman\n2020), it is not surprising that we found cross-partisan com-\nments were on average more toxic. We found, though, that\nconservatives were not signi\ufb01cantly more toxic than liberals\nin their root comments on left-leaning channels, which casts\nsome doubt on the idea that most of their interactions on\nleft-leaning videos were trolling attempts. It is still possiblethat they were very strategic trolls, baiting liberals into toxic\nresponses without themselves posting comments that people\nwould judge as toxic. The conservative trolls story, however,\nis inconsistent with the \ufb01nding that conservatives were less\ntoxic in responses to liberals on left-leaning videos than they\nwere on right-leaning videos. While there may be some con-\nservative trolls who delight in disruption, there seems to be\nothers who change their style to be more accommodating\nwhen they know that they are on the liberals\u2019 home territory.\nThe reality is clearly more complicated than any of the\nexisting simple narratives. Further theorizing is necessary\nto provide a coherent story of when and how liberals and\nconservatives tend to consume challenging information and\nengage in cross-partisan political interaction. To move in\nthat direction, more interview and survey studies are needed\nto understand the motivations of why people participate in\ncross-partisan political online.\n10 Conclusion\nThis paper presents the \ufb01rst large-scale measurement study\nof cross-partisan discussions between liberals and conser-\nvatives on YouTube. We estimate the overall prevalence of\ncross-partisan discussions based on user political leanings\npredicted by a hierarchical attention model. We \ufb01nd a large\namount of cross-partisan commenting, but much more fre-\nquently by conservatives on left-leaning videos than by lib-\nerals on right-leaning videos. YouTube\u2019s comment sorting\nalgorithm further diminishes the visibility of cross-partisan\ncomments: they are somewhat less likely to appear among\nthe top 20 positions. Even so, readers of comments on left-\nleaning videos are quite likely to encounter comments from\nconservatives and readers of comments on right-leaning\nvideos from national and local media are likely to encounter\nsome comments from liberals. Only on right-leaning inde-\npendent media are the comments almost exclusively from\nconservatives. Lastly, we \ufb01nd that people tend to be slightly\nmore toxic when they venture into channels with oppos-\ning ideologies, however they also receive much more toxic\nreplies. The highest toxicity occurs when defending one\u2019s\nhome territory \u2013 liberals responding to conservatives on left-\nleaning videos and conservatives responding to liberals on\nright-leaning videos.\nAcknowledgments\nThis work is supported in part by the National Science\nFoundation under Grant No. IIS-1717688 and the AOARD\nproject FA2386-20-1-4064. We thank the Australia\u2019s Na-\ntional eResearch Collaboration Tools and Resources (Nec-\ntar) for providing computational resources.\nAppendix\nA Prevalence of Cross-Partisan Discussions\nFigure 10 shows the percentage of users who commented on\nboth left-leaning and right-leaning channels. For users who\nposted at least 2 (or at least 25) comments, 39% (or 80%) of\nthem commented on both partisan channels.\n817\nFigure 10: x-axis: minimal number of comments users\nposted; y-axis: percentage of users who commented on both\nleft-leaning and right-leaning channels.\nReferences\nAn, J.; Cha, M.; Gummadi, K.; and Crowcroft, J. 2011. Me-\ndia landscape in Twitter: A world of new conventions and\npolitical diversity. In ICWSM.\nAn, J.; Kwak, H.; Posegga, O.; and Jungherr, A. 2019. Polit-\nical discussions in homogeneous and cross-cutting commu-\nnication spaces. In ICWSM.\nAn, J.; Quercia, D.; and Crowcroft, J. 2014. Partisan sharing:\nFacebook evidence and societal consequences. In COSN.\nBail, C. 2021. Breaking the Social Media Prism: How to\nMake Our Platforms Less Polarizing. Princeton University\nPress.\nBail, C. A.; Argyle, L. P.; Brown, T. W.; Bumpus, J. P.; Chen,\nH.; Hunzaker, M. F.; Lee, J.; Mann, M.; Merhout, F.; and\nV olfovsky, A. 2018. Exposure to opposing views on social\nmedia can increase political polarization. PNAS .\nBakshy, E.; Messing, S.; and Adamic, L. A. 2015. Expo-\nsure to ideologically diverse news and opinion on Facebook.\nScience .\nBarber \u00b4a, P. 2015. Birds of the same feather tweet together:\nBayesian ideal point estimation using Twitter data. Political\nAnalysis .\nBovet, A.; and Makse, H. A. 2019. In\ufb02uence of fake news\nin Twitter during the 2016 US presidential election. Nature\nCommunications .\nCarney, D. R.; Jost, J. T.; Gosling, S. D.; and Potter, J. 2008.\nThe secret lives of liberals and conservatives: Personality\npro\ufb01les, interaction styles, and the things they leave behind.\nPolitical Psychology .\nCheng, L.; Guo, R.; Silva, Y .; Hall, D.; and Liu, H. 2019.\nHierarchical attention networks for cyberbullying detection\non the Instagram social network. In SDM.\nCossard, A.; Morales, G. D. F.; Kalimeri, K.; Mejova, Y .;\nPaolotti, D.; and Starnini, M. 2020. Falling into the echo\nchamber: The Italian vaccination debate on Twitter. In\nICWSM.\nDubois, E.; and Blank, G. 2018. The echo chamber is over-\nstated: The moderating effect of political interest and diverse\nmedia. Information, Communication & Society .Eady, G.; Nagler, J.; Guess, A.; Zilinsky, J.; and Tucker, J. A.\n2019. How many people live in political bubbles on social\nmedia? Evidence from linked survey and Twitter data. Sage\nOpen .\nFestinger, L. 1957. A theory of cognitive dissonance. Stan-\nford University Press.\nFlaxman, S.; Goel, S.; and Rao, J. M. 2016. Filter bubbles,\necho chambers, and online news consumption. Public Opin-\nion Quarterly .\nFlores-Saviaga, C.; Keegan, B.; and Savage, S. 2018. Mobi-\nlizing the Trump train: Understanding collective action in a\npolitical trolling community. In ICWSM.\nGarimella, K.; Morales, G. D. F.; Gionis, A.; and Math-\nioudakis, M. 2018. Quantifying controversy on social me-\ndia.ACM Transactions on Social Computing .\nGarrett, R. K. 2009. Echo chambers online?: Politically mo-\ntivated selective exposure among Internet news users. Jour-\nnal of Computer-Mediated Communication .\nGarrett, R. K.; Gvirsman, S. D.; Johnson, B. K.; Tsfati, Y .;\nNeo, R.; and Dal, A. 2014. Implications of pro-and counter-\nattitudinal information exposure for affective polarization.\nHuman Communication Research .\nGDPR. 2016. Regulation EU 2016/679 of the European Par-\nliament and of the Council of 27 April 2016. Of\ufb01cial Journal\nof the European Union .\nGentzkow, M.; and Shapiro, J. M. 2011. Ideological segrega-\ntion online and of\ufb02ine. The Quarterly Journal of Economics\n.\nGrinberg, N.; Joseph, K.; Friedland, L.; Swire-Thompson,\nB.; and Lazer, D. 2019. Fake news on Twitter during the\n2016 US presidential election. Science .\nHart, W.; Albarrac \u00b4\u0131n, D.; Eagly, A. H.; Brechan, I.; Lind-\nberg, M. J.; and Merrill, L. 2009. Feeling validated versus\nbeing correct: A meta-analysis of selective exposure to in-\nformation. Psychological Bulletin .\nHemphill, L.; and Sch \u00a8opke-Gonzalez, A. M. 2020. Two\nComputational Models for Analyzing Political Attention in\nSocial Media. In ICWSM.\nHorrigan, J.; Garrett, K.; and Resnick, P. 2004. The Internet\nand Democratic Debate. Pew Internet and American Life\nProject .\nHua, Y .; Ristenpart, T.; and Naaman, M. 2020. Towards\nmeasuring adversarial Twitter interactions against candi-\ndates in the US midterm elections. In ICWSM.\nHussein, E.; Juneja, P.; and Mitra, T. 2020. Measuring Mis-\ninformation in Video Search Platforms: An Audit Study on\nYouTube. In CSCW.\nIyengar, S.; and Hahn, K. S. 2009. Red media, blue media:\nEvidence of ideological selectivity in media use. Journal of\nCommunication .\nJigsaw. 2021. Perspective API. https://perspectiveapi.com.\nAccessed: 2021-04-14.\n818\nLedwich, M.; and Zaitsev, A. 2020. Algorithmic extremism:\nExamining YouTube\u2019s rabbit hole of radicalization. First\nMonday .\nLewis, R. 2018. Alternative in\ufb02uence: Broadcasting the re-\nactionary right on YouTube. Data & Society .\nLietz, H.; Wagner, C.; Bleier, A.; and Strohmaier, M. 2014.\nWhen politicians talk: Assessing online conversational prac-\ntices of political parties on Twitter. In ICWSM.\nLima, L.; Reis, J. C.; Melo, P.; Murai, F.; Araujo, L.;\nVikatos, P.; and Benevenuto, F. 2018. Inside the right-\nleaning echo chambers: Characterizing Gab, an unmoder-\nated social system. In ASONAM.\nLiu, Y .; Liu, Y .; Zhang, M.; and Ma, S. 2016. Pay Me and I\u2019ll\nFollow You: Detection of Crowdtur\ufb01ng Following Activities\nin Microblog Environment. In IJCAI.\nMatz, S. C. 2021. Personal echo chambers: Openness-to-\nexperience is linked to higher levels of psychological inter-\nest diversity in large-scale behavioral data. Journal of Per-\nsonality and Social Psychology .\nMunson, S. A.; and Resnick, P. 2010. Presenting diverse\npolitical opinions: How and how much. In CHI.\nNegroponte, N. 1996. Being Digital. Vintage.\nPariser, E. 2011. The \ufb01lter bubble: What the Internet is hid-\ning from you. Penguin UK.\nPhillips, W. 2015. This is why we can\u2019t have nice things:\nMapping the relationship between online trolling and main-\nstream culture. MIT Press.\nPreot \u00b8iuc-Pietro, D.; Liu, Y .; Hopkins, D.; and Ungar, L.\n2017. Beyond binary labels: Political ideology prediction\nof Twitter users. In ACL.\nQuattrociocchi, W.; Scala, A.; and Sunstein, C. R. 2016.\nEcho chambers on Facebook. Available at SSRN 2795110\n.\nRajadesingan, A.; Resnick, P.; and Budak, C. 2020. Quick,\nCommunity-Speci\ufb01c Learning: How Distinctive Toxicity\nNorms Are Maintained in Political Subreddits. In ICWSM.\nRibeiro, M. H.; Ottoni, R.; West, R.; Almeida, V . A.; and\nMeira Jr, W. 2020. Auditing radicalization pathways on\nYouTube. In FAccT.\nRobertson, R. E.; Jiang, S.; Joseph, K.; Friedland, L.; Lazer,\nD.; and Wilson, C. 2018. Auditing partisan audience bias\nwithin Google search. In CSCW.\nSindermann, C.; Elhai, J. D.; Moshagen, M.; and Montag, C.\n2020. Age, gender, personality, ideological attitudes and in-\ndividual differences in a person\u2019s news spectrum: how many\nand who might be prone to \u201c\ufb01lter bubbles\u201d and \u201cecho cham-\nbers\u201d online? Heliyon .\nStocking, G.; Van Kessel, P.; Barthe, M.; Matsa, K. E.; and\nKhuzam, M. 2020. Many Americans get news on YouTube,\nwhere news organizations and independent producers thrive\nside by side. Pew Research Center .\nSunstein, C. R. 2018. #Republic: Divided democracy in the\nage of social media. Princeton University Press.Wu, S.; Rizoiu, M.-A.; and Xie, L. 2018. Beyond views:\nMeasuring and predicting engagement in online videos. In\nICWSM.\nWu, S.; Rizoiu, M.-A.; and Xie, L. 2019. Estimating atten-\ntion \ufb02ow in online video networks. In CSCW.\nWulczyn, E.; Thain, N.; and Dixon, L. 2017. Ex machina:\nPersonal attacks seen at scale. In TheWebConf.\nYang, Z.; Yang, D.; Dyer, C.; He, X.; Smola, A.; and Hovy,\nE. 2016. Hierarchical attention networks for document clas-\nsi\ufb01cation. In NAACL.\nZhou, D. X.; Resnick, P.; and Mei, Q. 2011. Classifying the\npolitical leaning of news articles and users from user votes.\nInICWSM.\n819", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Cross-Partisan Discussions on YouTube: Conservatives Talk to Liberals but Liberals Don't Talk to Conservatives", "author": ["S Wu", "P Resnick"], "pub_year": "2021", "venue": "Proceedings of the International AAAI Conference on \u2026", "abstract": "We present the first large-scale measurement study of cross-partisan discussions between  liberals and conservatives on YouTube, based on a dataset of 274,241 political videos from"}, "filled": false, "gsrank": 631, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/18105", "author_id": ["xUgVEuAAAAAJ", "SftrEEMAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:BsI-249O8lsJ:scholar.google.com/&output=cite&scirp=630&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=BsI-249O8lsJ&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 44, "citedby_url": "/scholar?cites=6625444381581033990&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:BsI-249O8lsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/18105/17908"}}, {"title": "FAKE NEWS: NATIONAL SECURITY IN THE POST-TRUTH ERA.", "year": "2018", "pdf_data": "FAKE NEWS:\nNATIONAL SECURITY\nIN THE POST-TRUTH ERA\nPolicy Report\nJanuary 2018\nNorman Vasu, Benjamin Ang, \nTerri-Anne-Teo, Shashi Jayakumar, \nMuhammad Faizal, and Juhi Ahuja\n\nPOLICY REPORT\nFAKE NEWS:\nNATIONAL SECURITY\nIN THE POST-TRUTH ERA\nNorman Vasu, Benjamin Ang, \nTerri-Anne-Teo, Shashi Jayakumar, \nMuhammad Faizal, and Juhi Ahuja\nJanuary 2018\nContents\nExecutive Summary  3\nIntroduction  4\nUnpacking Fake News  5\n Disinformation Campaign to Undermine National Security  5\n Misinformation for Domestic Political Agenda  6\n Non-political Misinformation Gone Viral  7\n Falsehoods for Entertainment  8\n Falsehoods for Financial Gain  8\nDissemination Techniques in Disinformation Campaigns  9\n Russia  9\n China  12\nHuman Fallibility and Cognitive Predispositions  14\n Fallible Memory  14\n Illusory Truth Effect  15\n Primacy Effect and Confirmation Bias  16\n Access to Information  16\nInternational Responses to Fake News  18\n Counter Fake News Mechanisms  18\n Strategic Communications  19\n Self-Regulation by Technological Companies  20\n Reducing Financial Incentives in Advertisements  21\n Government Legislation  22\n Critical Thinking and Media Literacy  24\nConclusion  26\nAbout the Authors  29\nAbout the Centre of Excellence for National Security  32\nAbout the S. Rajaratnam School of International Studies  32\n3Executive Summary\nFake news is not a new issue, but it poses a greater challenge now. \nThe velocity of information has increased drastically with messages now \nspreading internationally within seconds online. Readers are overwhelmed \nby the flood of information, but older markers of veracity have not kept up, \nnor has there been a commensurate growth in the ability to counter false \nor fake news. These developments have given an opportunity to those \nseeking to destabilise a state or to push their perspectives to the fore. This \nreport discusses fake news concerning the ways that it may manifest, how \nits dissemination is enabled through social media and search engines, \nhow people are cognitively predisposed to imbibing it, and what are the \nvarious responses internationally that have been implemented or are being \nconsidered to counter it. This report finds that efforts to combat fake news \nmust comprise both legislative and non-legislative approaches as each has \nits own challenges. First, the approaches must factor in an understanding \nof how technology enables fake news to spread and how people are \npredisposed to believe it. Second, it would be helpful to make a distinction \nbetween the different categories of falsehoods that are being propagated \nusing social media. Third, efforts should go hand in hand with ongoing \nprogrammes at shoring up social resilience and national consensus. \nFourth, efforts need to move beyond bland rebuttal and statements, as \nthese may be counter-productive. Fifth, counter-narratives that challenge \nfake news must be released expeditiously as fake news can spread en \nmasse  at great speed due to technology. In sum, collaboration across the \nwhole of society, including good public-private partnership, is necessary \nin order to expose fake news and ensure better synergy of efforts in \ncountering it.\n4Introduction\nFake news is not new \u2013 consider for example the role played by the \nrumour of tallow and lard-greased cartridges in the Sepoy Mutiny of \n1857 in India. Notwithstanding this, the issue poses a more significant \nchallenge now. The velocity of information has increased drastically with \nmessages now spreading internationally within seconds online. With \ncountless photographs, opinions, and hours of footage published online, \nevery falsehood can proliferate rapidly. Readers are overwhelmed by the \nflood of information, but older markers of veracity (respected publications, \nofficial sources) have not kept up, nor has there been a commensurate \ngrowth in the ability to counter false or fake news. In many cases, new, \nvisually attractive, and sometimes false, sources of information are \neclipsing publications of records such as newspapers. All this has given \nan opportunity to those seeking to destabilise a state or to push their \nperspectives to the fore. Modern disinformation operations only need free \nTwitter or Facebook accounts or access to platforms such as WhatsApp or \nTelegram.\nThis report is divided into five parts. The first section offers a survey of \nthe various ways in which fake news may manifest. This unpacking of its \nvarious forms is essential for policy-making, as not all forms of fake news \nrequire the same attention of the state with regard to national security. The \nsecond section discusses how the dissemination of fake news is enabled \nby the manner in which social media platforms and search engines are \nprogrammed to offer curated information to what they consider are our \ninterests. In addition, this section shows how such platforms and search \nengines have been exploited in order to distribute false information. The \nthird section explains how we are cognitively predisposed to imbibing fake \nnews. If we are to tackle this issue, this section offers the lay of the land of \nwhat we are cognitively up against. The penultimate section offers a survey \nand assessment of various responses internationally that have been put in \nplace or are being considered to tackle fake news. The report concludes \nwith several considerations that should be taken into account when \ndeveloping approaches to counter the problem.\n5Unpacking Fake News\nThis section discusses how fake news may be understood as a range of \nphenomena. While there are many ways to categorise fake news1, fake \nnews is understood here as a medium for a spectrum of phenomena \ncomprising five categories:\n (i) Disinformation \u2013 falsehoods and rumours knowingly distributed to \nundermine national security, which can be part of state-sponsored \ndisinformation campaigns;\n (ii) Misinformation \u2013 falsehoods and rumours propagated as part of \na political agenda by a domestic group/the relativisation/differing \ninterpretation of facts based on ideological bias;\n (iii) Misinformation \u2013 falsehoods and rumours propagated without a broad \npolitical aim, either with or without malicious intent that achieves viral \nstatus;\n (iv) Entertainment \u2013 falsehoods used in parody, satire, or seemingly \nhumorous pieces; and\n (v) Falsehoods distributed for financial gain.\nDisinformation Campaign to Undermine National Security\nThe first category, which this report is primarily concerned with, refers to \nthe use of fake news as a medium for organised disinformation campaigns \nwith the aim of destabilising states through the subversion of societies (and \ndemocratic processes including elections). This category is most onerous \ngiven its impact on national security and social cohesion.\nIn recent times, for example, these campaigns were reportedly carried out \nby Russia \u2013 using technological platforms \u2013 as part of broader influence \noperations in areas ranging from the Baltics to Central Europe to France \nto the United States. The magnitude of the Russian campaign to divide \nthe American society was scrutinised in October/November 2017 during a \n1 Tambini, Damien. 2017. \u201cFake News: Public Policy Responses\u201d. Media Policy Brief 20. \nLondon: Media Policy Project, LSE.; and http://www.bbc.com/future/story/20170301-lies-\npropaganda-and-fake-news-a-grand-challenge-of-our-age\n6hearing where technological companies (Facebook, Twitter and Google) \nwere questioned by the Senate Intelligence Committee.2 More details are \ndiscussed in the third section of this report.\nMisinformation for Domestic Political Agenda\nThe second category covers a broad range. These include viral rumours or \nfalse information (or semi-truths) either shaping national opinion or affecting \nthe resilience of a polity by actors within a state, without an external malign \nactor involved. This was evident in the 2016 presidential campaign in the \nUnited States (particularly on the part of the Trump campaign).\nSeparately, another example of this form of falsehood may be found in \nthe lead up to the Brexit referendum in the United Kingdom. The \u201cLeave\u201d \ncampaign resorted to tactics ranging from warnings about a country \noverrun by refugees and asylum seekers, to exaggerated claims that a sum \nof \u00a3350 million a week was being sent to Brussels by the UK government \u2013 \nmoney according to the claim would be saved if the Leave vote won.3\nFinally, this form of falsehood has been seen in the growth of disinformation \nsources linked to groups from the alternative right (alt-right), with a \ndenominator being anti-globalism and a strong distrust of the western, \ndemocratic sociopolitical model and neo-liberalism.\nThis second category of fake news may on certain occasions overlap \nwith the first category. There is some suggestion, for example, that the \nLeave campaign in the UK may have received an impetus from Russian \ndisinformation efforts in the lead up to the Brexit vote.4\n2 Lapowsky, Issie. \u201cEight Revealing Moments from the Second Day of Russia Hearings.\u201d \nWIRED , November 1, 2017. www.wired.com/story/six-revealing-moments-from-the-\nsecond-day-of-russia-hearings/\n3 Smith, Mikey. \u201cHow Facebook, Fake News and Personalised Ads Could Swing the 2017 \nElection - And What You Can Do About It.\u201d The Mirror , May 8, 2017. https://www.mirror.\nco.uk/news/politics/how-facebook-fake-news-personalised-10382585\n4 Baylon, Caroline. \u201cIs the Brexit Vote Legitimate If Russia Influenced the Outcome?\u201d \nNewswee k, February 12, 2016. www.newsweek.com/brexit-russia-presidential-election-\ndonald-trump-hacker-legitimate-527260\n7Non-political Misinformation Gone Viral\nThe third category concerns viral falsehoods of an entirely different nature \u2013 \nfor example, those achieving widespread currency in the wake of a disaster \nor terror attack. This is the third onerous category given its impact on public \norder and safety.\nIn the immediate aftermath of the 22 May 2017 Manchester terrorist attack, \nthere was a significant circulation of fake news carried out by various \ngroups and individuals. These ranged from the malicious (trolls) to the \nignorant  and misinformed. There were hoaxes  of missing children (images \nof children pulled from the web) and also several other false stories, \nincluding claims of a man with a gun outside the Royal Oldham Hospital, \nsituated near the scene of the attack.5\nSeparately, the immediate aftermath of the 13 April 2013 Boston Marathon \nbombing saw an outbreak of viral vigilantism. Individuals (many of them \nwell-meaning), based on available images, attempted to crowdsource \ninformation and establish an identity on online bulletin boards. These \nindividuals, abetted by journalists chasing what seemed like a plausible \nstory, falsely identified a student who had been missing from Brown \nUniversity for a month. This student was later found dead in a completely \nunrelated suicide, but the viral online vigilantism (entirely without \nrepercussions to those who had made the accusations, or to the platform \nthat had hosted many of the accusations, Reddit) placed immense strain on \nthe grieving family.6\n5 Scott, Kellie and Lucia Stein. \u201cManchester Attack: Fake News Circulates after Bombing \nat Ariana Grande Concert.\u201d ABC, May 24, 2017. www.abc.net.au/news/2017-05-24/\nmanchester-attack-fake-socialmedia-news-missing-kids/8553452.\n6 Henn, Steve and Audie Cornish. \u201cSocial Media Vigilantes Cloud Boston Bombing \nInvestigation.\u201d NPR , April 22, 2013. www.npr.org/2013/04/22/178462380/social-media-\nvigilantes-cloud-boston-bombing-investigation\n Another example of vigilantism with real world consequences (this time with a political \nmotivation) concerns the case of Edgar Welch, who in December 2016 went to Comet \nPing Pong Pizza Restaurant in Washington DC and fired shots from his automatic rifle \nafter imbibing too deeply of the so-called \u201cPizzagate\u201d conspiracy theory. The theory was \ndreamed up by internet trolls and fringe rightwing media, asserting, on the basis of some \nof John Podesta\u2019s leaked e-mails, that the restaurant was the hub of an elite paedophile \nring.\n8Falsehoods for Entertainment\nThe fourth category is the creation of fake stories for entertainment. \nExamples would include the offerings in the UK\u2019s Punch magazine and \nonline site The Onion . A by-product of this form of fake news is that some \npeople may take the parody to be true. For example, China\u2019s People\u2019s \nDaily republished an Onion  article claiming North Korea\u2019s Kim Jong Un was \nvoted 2012\u2019s sexiest man alive.\nThis category might seem on the surface to be devoid of national security \nimplications. Notable, however, is how seemingly humorous or satirical \ninformation can sometimes serve a nefarious purpose. Recent research \nhas shown, for example, that there is an emerging form of fake news with a \npolitical purpose disguised as irony or satire/parody. People might try using \nirony to mainstream their extremist ideas or creeds by masquerading them \nas something else altogether.\nA recent example from the United States is the so-called alt-right advancing \nits position using humorous and ironical facades. For this far-right \nmovement, \u201cirony has a strategic function. It allows people to disclaim \na real commitment to far-right ideas while still espousing them \u2026 it also \nallows individuals to push boundaries in public, and to back away when \nthey meet resistance.\u201d7 A compounding difficulty for opponents of the \u201calt-\nright\u201d is that it is not always simple to differentiate between sincerity and \nsatirical online.8\nFalsehoods for Financial Gain\nThe fifth category concerns fake stories distributed in order to attain \nrevenue from advertising or swaying sentiments to manipulate the stock \nmarket. This category is perhaps the least onerous given its non-security/\nnon-political  motivation but is nonetheless important due to its potential \nimpact on social cohesion.\n7 Wilson, Jason. \u201cHiding in plain sight: how the \u2018alt-right\u2019 is weaponising irony to spread \nfascism.\u201d The Guardian , May 23, 2017. www.theguardian.com/technology/2017/may/23/\nalt-right-online-humor-as-a-weapon-facism\n8 ibid.\n9Profit is the key motivator behind the creation of \u201cnews\u201d in this category. \nExamples would be the Macedonian fake news \u201cboiler houses\u201d that \ninvented fake stories on the US presidential elections.\nIf left unchecked, these may have a deleterious effect on society. The creators \nbehind The Real Singapore (TRS), a socio-political Singapore website, began \ncreating anti-foreigner comments on their website in 2012. These were found \nto have netted them over half a million Singapore dollars over a three-year \nperiod in online advertising. In the words of the public prosecutor, they were \n\u201cwildly successful in their efforts to profit from the ill-will and hostility that they \nwere peddling.\u201d TRS\u2019 founders were found guilty of sedition and deliberately \nsowing discord between Singaporeans and foreigners.9\nDissemination Techniques in Disinformation Campaigns\nThis section discusses the techniques used to disseminate fake news in \ndisinformation campaigns (influence operations), particularly through the \nexploitation of social media platforms and search engines. The focus on \ndisinformation campaigns stems from its detriment to national security and \nthe possibility it could overlap with other (less onerous) categories of the \nfake news phenomena.\nRussia\nMany reports have discussed recent Russian influence operations attempting \nto manipulate democratic processes such as elections. These attempts were \nmost conspicuous in the US 2016 presidential campaign. A declassified US \nintelligence assessment maintained that Russia used professional trolls and \nRussian state broadcaster Russia Today  (RT) \u201cas part of its influence efforts\u201d. \nSuccumbing to pressure from the US Department of Justice (DOJ), RT in \nNovember 2017 registered itself as an agent of a foreign government as \n9 Lee, Pearl. \u201cThe Real Singapore Trial: Co-Founder Yang Kaiheng \u2018Controlled Bulk of \nAd Revenue Earnings\u2019.\u2019\u2019 Straits Times , January 25, 2016. http://www.straitstimes.com/\nsingapore/courts-crime/co-founder-controlled-bulk-of-the-ad-revenue-earnings; and Au-\nYong, Rachel. \u201cAi Takagi, Former Editor of The Real Singapore Website, to Plead Guilty \nto Sedition.\u201d Straits Times , March 7, 2016. www.straitstimes.com/singapore/courts-crime/\nduo-behind-the-real-singaporesociopolitical-website-in-court-to-face\n10required by the US Foreign Agents Registration Act (FARA).10\nRussia reportedly paid thousands of people to create and peddle fake anti-\nHillary Clinton news targeting key swing states. Russian hackers are also \nbelieved to be responsible for leaking e-mails from Democratic Party officials. \nSome credible experts have suggested that President Donald Trump and his \nteam promoted narratives, including false ones, serving Russian interests.11\nIt is worth considering how these influence operations took advantage \nof the most common ways for ordinary people to navigate the crowded \ninformation space: (i) search engines to look up information; and (ii) social \nmedia to find out what their social circles are saying, and/or to share their \nviews with their circles.  These systems have been developed over time, \nalso in response to the flood of information, to create filter bubbles.\nGoogle arranges and displays its search results based on an individual\u2019s \npreferences which Google determines based on e-mail conversations, \nprevious searches, viewing preferences on YouTube, and other personal \ndata gathered through other Google applications. When Facebook displays \nposts on News Feeds, it only shows posts consistent with the user\u2019s \nprevious behaviour such as \u201cliking\u201d or sharing\u201d other posts.\nAs a result, search results and social media feeds  only show us results \nthat cohere with what we already enjoy or believe hence creating filter \nbubbles or echo chambers. Fake news appearing to match or support \nthese preferences or beliefs spreads quickly and is believable in this \nenvironment. One expert, the chief of Oxford Information Labs, holds that \nFacebook has an \u201cinsidious\u201d effect on democratic societies, and also spoke \nof a \u201cdeeper, scarier, more insidious problem: we now exist in these curated \nenvironments, where we never see anything outside our own bubble \u2026 and \nwe don\u2019t realise how curated they are.\u201d12\n10 Pisnia, Natalka. \u201cWhy has RT registered as a foreign agent with the US?\u201d BBC News , \nNovember 15, 2017. www.bbc.com/news/world-us-canada-41991683\n11 Gilmer, Marcus. \u201cArmy of Russian Trolls Reportedly Targeted Swing States With Anti-\nClinton Fake News.\u2019\u2019 Mashable , March 31, 2017. http://mashable.com/2017/03/30/\nrussian-trolls-fake-news/#tBAkXr32oPqn; and Bentzen, Naja. \u201cFake News and the EU\u2019s \nResponse\u201d, European Parliament Think Tank , April 2017, http://www.europarl.europa.eu/\nRegData/etudes/ATAG/2017/599384/EPRS_ATA(2017)599384_EN.pdf\n12 Hern, Alex. \u201cHow Social Media Filter Bubbles and Algorithms Influence the Election.\u201d The \nGuardian , May 22, 2017. www.theguardian.com/technology/2017/may/22/social-media-\nelection-facebook-filter-bubbles\n11The creation of filter bubbles and echo chambers through the algorithms \nof search engines, and social media is further exploited by companies \ndeveloping a model to translate social media data into a personality profile \nused to predict, and then influence user behaviour. For example, by \ncorrelating subjects\u2019 Facebook Likes, building profiles, and data harvesting, \nCambridge Analytica (CA) apparently can identify an individual\u2019s gender, \nsexuality, political beliefs, and personality traits. This method also uses \nartificial intelligence (AI) to find out more about the individual, and is able \nto make accurate predictions on how to convince the individual to take \ncertain actions with the appropriate sort of advert, while also creating a viral \neffect as there could also be other people in the individual\u2019s network who \nsubsequently like the same advert. CA was used by the Trump Campaign. \nDuring the 2016 US Presidential Election campaign, it was believed that \nFacebook users in key constituencies were targeted with personalised \nmessages or fake news that played on their existing biases. This was just \none aspect of the Trump data analytics campaign.13\nRecent reports have suggested the FBI has collected data on (and is \ninvestigating) computer bots \u2013 programmes performing repetitive functions \nsuch as searches \u2013 allegedly linked to Russia and helped push negative \ninformation on Hillary Clinton and positive information on Donald Trump \nthrough Facebook and other social media platforms. This happened \nparticularly in key battleground states, and the Russian disinformation \napparatus was able to piggyback on it.14\nBots have also appeared elsewhere. Shortly before the French Presidential \nelection, Facebook disabled 30,000 fake accounts in France \u2013 deleting \nthem in some, but not all. Facebook (without assigning responsibility for \nthese accounts) said its objective behind these takedowns is to remove \nfake accounts with high volumes of posting activity and the most prominent \n13 Cambridge Analytica specialises in \u201celection management strategies\u201d and \u201cmessaging \nand information operations\u201d, refined over 25 years in places like Afghanistan and \nPakistan. There are also suggestions that  Cambridge Analytica was used (to some \neffect) by pro-Brexit forces in the UK. Cadwalladr, Carole. \u201cRobert Mercer: The Big Data \nBillionaire Waging War on Mainstream Media\u201d, The Guardian , February 26, 2017, https://\nwww.theguardian.com/politics/2017/feb/26/robert-mercer-breitbart-war-on-media-steve-\nbannon-donald-trump-nigel-farage\n14 Evan Perez et al., \u201cFBI Russia Investigation Looking at Kushner Role.\u201d CNN , May 26, \n2017. http://edition.cnn.com/2017/05/25/politics/fbi-russia-investigation-jared-kushner/\n12audiences.15 It appears, however, the bots will be a feature of the social \nmedia landscape in the medium-term. Innovations in parallel computation and \nimprovements to algorithm construction will make it harder to distinguish bots \nfrom humans. Some researchers believe that they have found fake Facebook \ngroups almost entirely populated by bots. These fake groups, convincingly \noperated and orchestrated, eventually attracted real fans. It is possible that \nmany Trump fans were emboldened to declare their support for the candidate \ndue to the artificially created perception of a swell in support for him. Moreover, \nin this way, some of these originally-fake pages or groups swelled with real \npeople, with the \u201cfake\u201d aspects of these groups withering away.16\nChina\nWhile far less has emerged from Chinese influence operations, the \nChinese state apparatus reportedly has its version of \u201cinformation troops\u201d \nat its disposal.17 The great majority of these troops \u2013 called by some as \nthe \u201c50-cent army\u201d \u2013 may not actually be part of the security apparatus, \nbut independent operators including student volunteers at universities, \nCommunist Youth League members, and government bureaucrats. They \nare also thought to be involved in faking several hundred million social \nmedia accounts.18 An example of the Chinese volunteer information \n15 Auchard, Eric and Joseph Menn. \u201cFacebook Cracks Down on 30,000 Fake Accounts in \nFrance\u201d. Reuters , April 13, 2017. www.reuters.com/article/us-france-security-facebook-\nidUSKBN17F25G\n16 Hern, Alex. \u201cHow Social Media Filter Bubbles and Algorithms Influence the Election\u201d. The \nGuardian, May 22, 2017. www.theguardian.com/technology/2017/may/22/social-media-\nelection-facebook-filter-bubbles\n17 U.S-China Economic and Security Review Commission, \u201cChina\u2019s Propaganda and \nInfluence Operations, Its Intelligence Activities That Target the United States, and \nthe Resulting Impact on U.S National Security.\u201d, April 20, 2009. https://www.uscc.\ngov/Hearings/hearingchina%E2%80%99s-propaganda-and-influence-operations-its-\nintelligence-activities-target\n18 \u201cHackers Leak Files Showing Inner Workings of \u201cChina\u2019s 50-Cent Army.\u2019\u2019 Radio Free \nAsia, May 20, 2015. www.rfa.org/english/news/china/files-05202015150018.html; Lau, \nJoyce. \u201cWho Are the Chinese Trolls of the \u201950 Cent Army\u2019.\u201d VOA News , October 7, 2016. \nwww.voanews.com/a/who-is-that-chinese-troll/3540663.html; \u201cThe Chinese Government \nFakes Nearly 450 Million Social Media Comments a Year. This Is Why.\u201d The Washington \nPost, May 19, 2016. https://www.washingtonpost.com/news/monkey-cage/wp/2016/05/19/\nthe-chinese-government-fakes-nearly-450-million-social-media-comments-a-year-this-\nis-why/?utm_term=.e185a7e48159. One worthwhile academic study of the Chinese \n\u201950-Cent Army\u2019 is Gary King, Jennifer Pan, and Margaret E Roberts, \u2018How the Chinese \nGovernment Fabricates Social Media Posts for Strategic Distraction, Not Engaged \nArgument\u2019, American Political Science Review Forthcoming (9 April 2017)\n13apparatus in action can be seen through the postings of Communist Youth \nLeague members in January 2017 when Tsai Ing-wen became the first \nfemale president elected in Taiwan. One analysis suggests a campaign \nstarted on a forum on Baidu to flood Tsai with anti-Taiwan comments. \nWithin 12 hours, there were 40,000 negative comments on Tsai\u2019s Facebook \npage, not done by any organised force, but by \u201cvolunteer armies of \nmobilised angry youth\u201d.19\nChina is also believed to use non-technological methods for influence \noperations.20 There are some suggestions that in certain locations, China \nhas attempted to infiltrate or influence organisations and individuals \nwith the aim of pushing specific lines that fit with Beijing\u2019s foreign policy \nor security objectives.21 For example, some analysts have suggested \nindependence activists in Okinawa (regarded by most commentators as a \nfringe group) are backed by Chinese universities and think tanks. These \nefforts have not simply relied on informal efforts of the \u201c50-cent army\u201d.22\nIn another example, amid growing concerns of China\u2019s influence operations \nin Australia, the Abbott government in early 2015 initiated a multi-agency \neffort to assess the magnitude of these operations.23 Among the conclusions \nfrom the assessment are that propaganda (e.g., pro-China publications) to \nshape the views of the general Australian public can be distributed through: \n(i) political donations to Australian politicians hence posing security risks to \nAustralian policymaking; (ii) Chinese state-owned-enterprises and privately-\n19 Dong, Yifu. \u201cLet the Cross-Strait Internet Trolling Commence.\u201d Foreign Policy , January \n20, 2016. http://foreignpolicy.com/2016/01/20/china-taiwan-tsai-ing-wen-facebook-troll-\nelection/\n20 Medcalf, Rory. \u201cChina\u2019s Economic Leverage: Perception and Reality.\u201d ANU National \nSecurity College  2 (2017). http://nsc.anu.edu.au/research-and-publications/policy-\npaper-2.php\n21 Parameswaran, Prashanth. \u201cBeware China\u2019s Political Warfare against U.S, Allies: \nExperts\u201d, The Diplomat , October 10, 2015. http://thediplomat.com/2015/10/beware-\nchinas-political-warfare-campaign-against-us-allies-experts/\n22 Reynolds, Isabel. \u201cJapan Sees Chinese Groups Backing Okinawa Independence \nActivists.\u2019\u2019 Bloomberg , December 26, 2016. https://www.bloomberg.com/politics/\narticles/2016-12-26/japan-sees-chinese-groups-backing-okinawa-independence-activists. \nSome analysts suggest that this support might be linked, in effect, to the longer-term \ndesire of Beijing to change or challenge \u201cfacts on the ground\u201d; in this case leaving the \ndoor open to challenging Japan\u2019s claim over Okinawa.\n23 Birtles, Bill. \u201cAustralian Media Playing into China\u2019s Grand Strategy.\u201d ABC, June 3, 2016. \nhttp://www.abc.net.au/news/2016-06-03/birtles-australian-media-playing-into-chinas-\ngrand-strategy/7472870\n14owned Chinese companies and associations; and (iii) engagements with \nnon-Chinese businesses that rely on the Chinese market.24\nHuman Fallibility and Cognitive Predispositions\nThis section discusses how we are cognitively predisposed to imbibing fake \nnews in general, and what we are cognitively up against. It is important to \nunderstand the issues of human fallibility and cognitive dispositions in order \nto develop approaches to counter fake news.25\nFallible Memory\nThe human memory is a fallible system, prone to error and distraction. \nThe brain remembers information regardless of whether it is true or false. \nIn this era of fake news and misinformation, individuals have a much \nmore difficult time judging what is correct and incorrect. Human fallibility is \nalso exacerbated by the technological landscape, with a growing body of \nscholarly work suggesting that the internet is changing the way we think, \nand making us more susceptible to irrelevance, rumour, and supposition. \nA 2009 meta-study by a development psychologist from the University of \nCalifornia, Los Angeles (UCLA) concluded that while the growing use of the \ninternet had led to \u201cnew strengths in visual-spatial intelligence\u201d, there had \nbeen a commensurate weakening of \u201cdeep processing\u201d that underpinned \n\u201cmindful knowledge acquisition, inductive analysis, critical thinking, \nimagination, and reflection.\u201d26\nLooking, searching and parsing information online have led to forms of \nshallowness. One study in 2009 saw Stanford researchers administering a \nbattery of cognitive tests to two groups: heavy multitaskers and relatively \nlight multitaskers. The former group was found to be much more easily \n24 Sheridan, Greg. \u201cChinese Influence Runs Deep to Favour Official Beijing Policy\u201d. \nThe Australian , September 10, 2016. www.theaustralian.com.au/opinion/columnists/\ngreg-sheridan/chinese-influence-runs-deep-to-favour-official-beijing-policy/news-story/\nf7e5d0befc24019bdd5a4f10bca54a8a\n25 Gilbert, Daniel T. \u201cHow Mental Systems Believe.\u201d American Psychologist 46, no. 2 (1991): \n114\n26 Greenfield, Patricia M. \u201cTechnology and Informal Education: What Is Taught, What Is \nLearned.\u201d Science 323, no. 5910 (2009): 69\u201371.\n15distracted by \u201cirrelevant environmental stimuli\u201d and had less ability to \nmaintain concentration on a particular task, with some suggestion that \nthose in this group may also have been \u201csacrificing performance on the \nprimary task to let in other sources of information.\u201d27\nResearchers also found that \u201cskimming activity\u201d was exhibited by individuals \nwho use online resources. A study, done by researchers from University \nCollege London (UCL) that concluded in 2008, examined computer logs \ndocumenting user behaviour on two popular research databases. Individuals \nwho used these databases quickly jumped from one source to another, only \nrarely returning to read in more depth a piece skimmed earlier.28\nIf these behaviours are also found to be present in the general population \nthat is receiving a significant proportion of their news from social media, it \ncould indicate that they are not applying critical thinking to what they read, \nleaving them highly vulnerable to believing fake news.\nIllusory Truth Effect\nThe illusory truth effect, as jointly examined by cognitive psychologists \nand neuroscientists, is the phenomena in which people, when exposed \nand then re-exposed to misinformation, would tend to believe that the \ninformation is more truthful because they cannot remember the original \nsource of that information.29 Importantly, if people can remember that the \noriginal source of the misinformation is not credible, they can disqualify \nthe information as being false. In the brain, these disqualification \nprocesses have been observed using neural signals found with both \nelectroencephalography and functional magnetic resonance imaging.30\n27 Ophir, Eyal, Clifford Nass, and Anthony D Wagner. \u201cCognitive Control in Media \nMultitaskers.\u201d Proceedings of the National Academy of Sciences  (2009) http://www.pnas.\norg/content/106/37/15583.full.pdf.; and Gorlick, Adam, \u201cMedia Multitaskers Pay Mental \nPrice, Stanford Study Shows,\u201d Stanford News , August 24, 2009. http://news.stanford.\nedu/2009/08/24/multitask-research-study-082409/\n28 Ian Rowlands, et al., \u201cThe Google Generation: Information Behaviour of the Researcher \nof the Future.\u201d University College London  (2008). http://www.emeraldinsight.com/doi/\npdfplus/10.1108/00012530810887953\n29 Rozenblit, Leonid and Frank Keil. \u201cThe Misunderstood Limits of Folk Science: An Illusion \nof Explanatory Depth.\u201d Cognitive Science 26  (2002): 521\u201362\n30 Uscinski, Joseph E, Casey Klofstad, and Matthew D Atkinson. \u201cWhat Drives \nConspiratorial Beliefs? The Role of Informational Cues and Predispositions\u201d, Political \nResearch Quarterly 69, no. 1 (2016): 57\u201371\n16Primacy Effect and Confirmation Bias\nThe primacy effect refers to the formative period where individuals form the \nmost conclusive opinions as a result of information that is first acquired. \nInitial opinions tend to shape information in their favour despite being \nconfronted by contesting and compelling evidence, which may not be \naccepted. This pattern of reinforcement is described as belief persistence, \nwhich involves \u201cthe mental representation and positive assessment of \nmeaningful information\u201d. Such behaviour is compounded by confirmation \nbias, which refers to the way in which individuals selectively seek or \ninterpret evidence aligned with existing beliefs, values and hypotheses. \nThis behaviour is conducted in an unwitting manner, which is a key \ncharacteristic of the bias.31\nAccess to Information\nIndividuals who are more exposed to fake news conveying messages \nabout politics and politicians in comparison to hard news show a higher \ntendency to believe the former as the reality. This effect was investigated \nby researchers in a study on the 2006 Israeli general election campaign. \nThe individuals\u2019 beliefs are maintained until hard news is conveyed to \nparticipants. The findings show that fake news only affects political attitudes \nif individuals believe that information conveyed within fake news accurately \nrepresents the political arena.32\nDue to other environmental factors that affect voting behaviour, the study \ncannot conclusively show that there is a direct relationship between the \nconsumption of fake news and election outcomes.\nHowever, the findings of this study are significant for political \ncommunications where they show how fake news viewership could affect \npolitical attitudes, enhancing negative attitudes of inefficacy, alienation and \ncynicism towards politicians regardless of party affiliations. Comparatively, \nindividuals who have a higher level of hard news consumption are better \n31 Nickerson, Raymond S. \u201cConfirmation Bias: A Ubiquitous Phenomenon in Many Guises.\u201d \nReview of General Psychology 2, no. 2 (1998): 175\n32 Balmas, Meital. \u201cWhen Fake News Becomes Real: Combined Exposure to Multiple News \nSources and Political Attitudes of Inefficacy, Alienation, and Cynicism.\u201d Communication \nResearch  41, no. 3 (2012): 430\u201354\n17attuned to recognise that it would be impossible for all politicians to be \npolitically inept and morally questionable as much as the fake news \nsuggests.\nIndividuals who already have set ideological predispositions are also more \nlikely to believe in fake news. This effect was investigated by researchers \nin a study that found that ideologically aligned articles are more likely to \nbe believed by heavy media consumers and those with segregated social \nnetworks because they are less likely to receive contradictory or opposing \ninformation from their peers. However, this study similarly could not make \na conclusive correlation between fake news consumption and voting \nbehaviour or voting patterns.33\nOverall, there is still insufficient research that examines the relationship \nbetween the growing quantities of information available and how it is \ncognitively processed by individuals.\nFirst, while past studies investigated the relationship between fake news \nconsumption, set ideological predispositions and the likelihood to believe \nthe information conveyed, it does not consider the cognitive abilities \nof media consumers, level of obligation to participate in elections and \npredispositions of cynicism.34\nSecond, the experience of information gathering may vary across \ngenerations. While the main unit of analysis in these studies is age, they \nshow that knowledge of and access to technology correlates to the ability \nto access and critically analyse information online, and are, as such more \nreflective of the differences between digital natives and non-digital natives, \nrather than generational differences as defined by age. For example, a \nstudy shows how youths\u2019 predilection for variety, fulfilled through online \nmedia, reflects an aversion to mainstream news such as televised networks \nor newspapers. Youths explain that the latter tend to be irrelevant to their \nneeds and interests, or one-dimensional, and therefore lacking in credibility. \nA preference for news to be accessed instantly is also different from the \n33 Allcott, Hunt and Matthew Gentzkow. \u201cSocial Media and Fake News in the 2016 Election.\u201d \nJournal of Economic Perspectives  31, no. 2 (2017): 230\n34 Fessler, Daniel M.T., Anne C Pisor, and Colin Holbrook. \u201cPolitical Orientation Predicts \nCredulity Regarding Putative Hazards.\u201d Psychological Science  28, no. 5 (2017): 651\u201360\n18previous generations which are used to accessing news at a fixed time of \nday.35\nInternational Responses to Fake News\nThis section assesses the various approaches that have been implemented \nor are being considered to counter fake news internationally. Countries \nhave different approaches based on the nature of fake news that affected \nthem, and their respective domestic and geopolitical considerations.\nCounter Fake News Mechanisms\nWebsites have been set up \u2013 by independent groups or states \u2013 as \nmechanisms to debunk fake news that constitute disinformation and other \nfalsehoods. There are several examples from across the globe.\nIn Europe, Stopfake.org is a crowdsourced journalism project that was \nlaunched in 2014 to combat fake news spreading across the internet during \nUkraine\u2019s crisis in Crimea. The site checks facts, verifies information, \nand refutes inaccurate reports and propaganda about events in Crimea, \nwhich are widely believed to originate from Russia. Separately, there \nare existing fact-checking sites such as (i) http://www.snopes.com/, (ii) \nhttp://fakenewswatch.com/, (iii) http://realorsatire.com/, and (iv) https://\nmediabiasfactcheck.com/.\nIn Qatar, \u201cLift the Blockade\u201d is a government website set up in September \n2017 to counter what Qatar regards as fake news distributed by geopolitical \nrivals to justify the imposition of economic sanctions amid the gulf crisis.36\nIn Singapore, \u201cFactually\u201d is a government website set up in 2012 to \u201cclarify \nwidespread misperceptions of government policy or incorrect assertions on \n35 Meijer, Irene Costera. \u201cThe Paradox of Popularity: How Young People Experience the \nNews.\u201d Journalism Studies  8, no. 1 (2007): 96\u2013116\n36 Scott, Victoria. \u201cQatar launches new website to counter \u2018fake news\u2019.\u201d Doha News , \nSeptember 18, 2017. https://dohanews.co/qatar-launches-new-website-to-counter-fake-\nnews/\n19matters of public concern that can harm Singapore\u2019s social fabric\u201d.37\nWhile important, these sites would not reach out to those who are not \npredisposed to fact-checking owing to their cognitive biases or due to \ndigital illiteracy. Moreover, this form of debunking is slow. It requires an \nindividual who is curious to uncover whether a news item is false by firstly, \nnot sharing the item further; and secondly, fact checking at one of these \nsites. It also assumes that the reader will trust the findings of the fact \ncheckers, whereas the fact checkers themselves are often accused of \nbeing biased; for example, Snopes has been labelled as \u201cliberal\u201d. Given \nthe challenges, such websites should be run in tandem with wider strategic \ncommunications efforts.\nStrategic Communications\nStrategic communications efforts at the national (and regional) levels have \nbeen ramped up to counter fake news that constitutes disinformation. \nIn Europe, the European Union\u2019s External Action Service set up the \nEast StratCom Task Force in September 2015, which runs the myth-\nbusting website euvsdisinfo.eu. The task force also releases a weekly \nDisinformation Review \u0012 a review of the latest cases of news articles \ncarrying key examples of how pro-Kremlin disinformation finds its way in \ninternational media, as well as news and analysis on the topic.38\nThe East StratCom Task Force operates on the existing EU strategic \ncommunication budget and is staffed by individuals from EU institutions \nor seconded from the EU Member States. It relies heavily on volunteers \nto both collect disinformation stories (more than 2,500 examples in 18 \nlanguages since 2015), and support the Disinformation Review.\nEurope\u2019s strategic communications efforts are also complemented by \nadvocacy work done by think tanks. Their activities include: (i) publicly \nchallenging supporters of Russian-sponsored disinformation; (ii) disclosing \nthe disinformation campaign substance/vehicles; and (iii) systematically \n37 Lee, Pearl. \u201cFactually Website Clarifies \u2018Widespread\u2019 Falsehoods.\u201d Straits Times , \nMarch 2, 2017. /www.straitstimes.com/singapore/factually-website-clarifies-widespread-\nfalsehoods\n38 \u201cFake News and the EU\u2019s Response\u201d, European Parliament Think Tank , March 31, 2017, \nhttps://epthinktank.eu/2017/11/20/disinformation-fake-news-and-the-eus-response/\n20building social resilience. This is important, as disinformation is most \neffective in states where citizens \u201cexit\u201d for political, economic, social, \ninformational and cultural reasons; and where people are  more vulnerable \n(to fake news) because they feel disenfranchised as the social contact \nbetween citizens and the state has weakened.\nThere can be merits in studying Europe\u2019s strategic communications with \nthe view of introducing similar efforts but tailored to other regions\u2019 cultural \nand political landscape. These efforts also put pressure on social media \ncompanies to do more to counter fake news.\nSelf-Regulation by Technological Companies\nThe current spread of fake news, especially when it constitutes \ndisinformation, is often attributed to social media platforms. Technological \ncompanies have long resisted being labelled as content publishers, but \ntheir ability to hold this line is weakening. Amid pressures from several \ngovernments, technological companies have instituted a mix of user-based \nand algorithmic-based initiatives since December 2016 for self-regulation.\nOne of the earlier measures is a tool enabling Facebook users to \u201cflag\u201d fake \nnews reports for review by third-party fact-checkers from the International \nFact Checking Network (IFCN). This initiative cooperates with media outlets \nin the EU Member States and became operational in March 2017. Similarly, \nChina\u2019s WeChat users can report other users and even entire chat groups \nfor sharing false information, harassment, or gambling, by clicking a button \non the profile page. The reports are examined by employees at WeChat \nwho maintain a database of fake news used to sieve similar content to \nbe blocked automatically if reposted in the future. WeChat has reportedly \nreceived 30,000 fake news reports and the system blocks about 2.1 million \nfalse rumour posts.39\nAhead of the April 2017 French presidential elections, Facebook took a \nmore proactive initiative of removing tens of thousands of fake accounts. \n39 Zhou, Viola. \u201cHow China\u2019s Highly Censored WeChat and Weibo Fight Fake News ...And \nOther Controversial Content\u2019\u2019, South China Morning Post , December 16, 2016, http://\nwww.scmp.com/news/china/policies-politics/article/2055179/how-chinas-highly-censored-\nwechat-and-weibo-fight-fake\n21The fake accounts were identified by analysing patterns of activity (without \nnecessarily assessing the content itself). In doing so, Facebook has \nemployed algorithmic techniques, including machine learning, to target fake \naccounts \u0012 looking for \u201cfalse amplifiers\u201d of political stances, coordinated \nattempts to share and like certain posts, online harassment or the creation \nof \u201cinflammatory or racist\u201d content. These fake accounts would also include \nautomated accounts (bots).40\nSelf-regulation initiatives that target content (and user accounts), however, \nhave its limitations given that it has not sufficiently slowed down the spread \nof fake news.\nReducing Financial Incentives in Advertisements\nSocial media companies are exploring other methods. As seen from \nFacebook\u2019s announcement, it will be hiring more than 1,000 people to \nreview political advertisement purchases in order to better protect the US \nfrom the threat of disinformation through fake news.41\nThe method of targeting advertisement purchases essentially aims to \nreduce the volume of fake news by removing the financial incentive for \nits creation. This method can be employed against fake news used for \ndisinformation campaigns and misinformation (propagated without a broad \npolitical aim, either with or without malicious intent and achieving viral \nstatus).\nThis method, however, requires the private and public sectors to \ncollaborate in exploring ways to alter the manner in which advertising \nrevenue is generated online. It should be highlighted here that the private \nindustry may not be averse to pulling out advertising from dubious \n40 Woollaston, Victoria. \u201cFacebook Shuts Down Thousands of UK Accounts in Clamp Down \non Fake News.\u201d Wired , May 8, 2017. http://www.wired.co.uk/article/facebook-fake-news; \nSeth Fiegerman, \u201cFacebook\u2019s Global Fight Against Fake News\u201d, CNN , May 9, 2017, \nhttp://money.cnn.com/2017/05/09/technology/facebook-fake-news/index.html; Castillo, \nMichelle. \u201cFacebook Goes Harder After \u2018Fake News\u2019 Accounts, Adding New Security Tools \nand Rooting Out Bad Actors\u201d, CNBC , April 28, 2017, https://sg.finance.yahoo.com/news/\nfacebook-goes-harderapos-fake-164705594.html\n41 Fandos, Nicholas, Cecilia Kang and Mike Isaac. \u201cHouse Intelligence Committee Releases \nIncendiary Russian Social Media Ads.\u201d New York Times , November 1, 2017. www.\nnytimes.com/2017/11/01/us/politics/russia-technology-facebook.html\n22websites as seen in cases of multinational companies that pulled their \nadvertisements from alt-right websites in the US after being alerted.\nIndustry standards and codes of ethics can be established in order to \ninstitute more social accountability in online advertising by the private \nindustry. This is one of the areas where legislation can give some teeth.\nGovernment Legislation\nSeveral governments are implementing or considering implementing \nnew laws as a key measure to counter fake news. For such cases, the \ngovernments assessed that existing laws and regulations as well other \napproaches (counter fake news websites, strategic communications and \nself-regulation by social media companies) are inadequate.\nLaws can hold technological companies accountable for the distribution \nof inaccurate information, and online advertisements that allow fake news \nto spread. For example, Germany, in October 2017, enacted a new law \u0012 \nThe Network Enforcement Act \u0012 that could impose fines on social media \ncompanies if they continuously fail to remove illegal content including those \nthat constitute hate speech and fake news. Israel is mooting the so-called \n\u201cFacebook Bill\u201d which would enable the state to issue injunctions to force \nsocial media companies to remove content that has been assessed by the \npolice to be inciting hatred and violence; the first reading of the bill was \npassed in Knesset  in March 2017.42 The US, in October 2017, announced \nthe mooting of the bipartisan Senate bill \u0012 Honest Ads Act \u0012 that would give \nthe state the power to compel companies to disclose information on buyers, \nand their expenditure and dissemination of online advertising that may be \npolitical43\nLaws can also hold social media users accountable for the spread of fake \nnews. For example, the Philippines, in August 2017, passed the Republic \nAct (RA) 10951, which gives the state the power (article 154) to penalise \n42 Solomon, Shoshanna. \u201cIsrael Getting Better Grip on Online Incitement, Justice Minister \nSays.\u201d The Times of Israel , June 25, 2017. https://www.timesofisrael.com/israel-getting-\nbetter-grip-on-online-incitement-justice-minister-says/\n43 Lecher, Colin. \u201cSenators Announce New Bill That Would Regulate Online Political Ads.\u201d \nThe Verge , October 19, 2017. https://www.theverge.com/2017/10/19/16502946/facebook-\ntwitter-russia-honest-ads-act\n23individuals who \u201cpublish false news by passing it off as legitimate news \nthrough print or other publication methods\u201d which \u201cmay endanger the public \norder, or cause damage to the interest or credit of the state\u201d.44\nAny state that seeks to criminalise the distribution of fake news or hold \ncontent providers responsible is bound to face certain challenges.\nFirst, the criminalisation of the distribution of fake news will encounter a \nminefield of legal issues stemming from definitional problems while content \nproviders, dependent upon where they are based, may attempt to evade \nnational  legislation. For example, Facebook has  responded that the new \nGerman law requires social media platforms to delete content that is not \nclearly illegal, and this may be non-compliant with EU law.45\nSecond, there may be more political than technical constraints. For \nexample, while German law is quite clear on what is hate speech, both the \npolitical left and right fear that the term \u201cfake news\u201d is open to exploitation, \nowing to its ambiguity. Moreover, there may be inherent biases when \nhumans and machines (algorithms) endeavour to judge whether content \nis \u201cmanifestly\u201d fake news. Hence, civil rights advocates and Facebook \nrepresentatives are concerned that the law could have opposing effects on \nthe freedom of expression.46\nThird, while legislation seeks to hold technological companies and users \naccountable, it remains to be seen how legislation can add value in existing \nefforts to remove and deter automated accounts (bots). Currently, social \nmedia companies have introduced measures such as Facebook\u2019s real-name \npolicy and a ban on fake profiles, and Twitter\u2019s bot policies to address the \n44\u0003 7DQ\u000f\u0003/DUD\u0011\u0003\u00b3<RX\u00030D\\\u0003%H\u0003)LQHG\u00038S\u00037R\u0003\u0b11\u0015\u0013\u0013\u000f\u0013\u0013\u0013 \u0003)RU\u00033XEOLVKLQJ \u0003)DOVH\u00031HZV\u0011\u00b4\u000f\u0003CNN \nPhillipines , September 1, 2017. http://cnnphilippines.com/news/2017/09/01/False-news-\njail-fine-Republic-Act-10951-Revised-Penal-Code.html\n45 Shead, Sam. \u201cFacebook Said Germany\u2019s Plan to Tackle Fake News Would Make Social \nMedia Companies Delete Legal Content\u201d, Business Insider , May 30, 2017. https://www.\nbusinessinsider.com.au/facebook-says-germany-fake-news-plans-comply-with-eu-law-\n2017-5?r=UK&IR=T\n46 Kinstler, Linda. \u201cCan Germany Fix Facebook?\u201d The Atlantic , November 2, 2017. www.\ntheatlantic.com/international/archive/2017/11/germany-facebook/543258/\n24problem.47 Moreover, there is also the technical challenge of distinguishing \nmalicious bots from those that spread legitimate information.48\nLegislation against fake news is thus an emergent research space that \nrequires further studies to assess its impact and possible amendments \nneeded to ensure its efficacy in the long term. Given the challenges, \nlegislation should be complemented with non-legislative measures; for \nexample, this was indicated in the results of a public survey on fake news \nby the Singapore government in May 2017.49\nCritical Thinking and Media Literacy\nWhile legislation defines the unlawfulness in and addresses the distribution of \nfake news, a long-term solution would also require building social resilience \nso that opinions and emotions cannot be easily swayed by falsehoods. This \nis where the non-legislative measures \u0012 critical thinking and media literacy \n\u0012 have a role as a bulwark against falsehoods in general. For example, the \nOrganisation for Economic Co-operation and Development\u2019s (OECD) Director \nfor Education has called for schools to teach children how to spot fake news \nand suggested that such skills be included in the criteria for PISA tests.50\nBoth critical thinking and media literacy entail teaching people to be more \njudicious in consuming information, including having the natural inclination \nto fact-check the materials they read. This encourages a culture shift: \nhighlighting blind spots and biases, inciting a curiosity for information from \na spectrum of sources, and training them to assess materials logically and \nconsider alternative viewpoints, before reaching a conclusion. Given that \n47 Meyer, David. \u201cCan the Law Stop Fake News and Hoax-Spreading Bots? These \nPoliticians Think So.\u201d ZDnet , January 24, 2017. www.zdnet.com/article/can-the-law-stop-\nfake-news-and-hoax-spreading-bots-these-politicians-think-so/\n48 \u201cFirst Evidence That Social Bots Play a Major Role in Spreading Fake News.\u201d MIT \nTechnology Review , August 7, 2017. www.technologyreview.com/s/608561/first-evidence-\nthat-social-bots-play-a-major-role-in-spreading-fake-news/\n49 Chan, Luo Er. \u201cNew Laws on Fake News to be Introduced Next Year: Shanmugam.\u201d \nChannel News Asia , June 19, 2017. /www.channelnewsasia.com/news/singapore/new-\nlaws-on-fake-news-to-be-introduced-next-year-shanmugam-8958048\n50 Coughlan, Sean. \u201cSchools Should Teach Pupils How to Spot \u2018Fake News\u2019.\u201d BBC, \nMarch 18, 2017. www.bbc.com/news/education-39272841; and Bentzen, Naja. \n\u201cDisinformation, \u2018Fake News\u2019 and the EU\u2019s Response.\u201d European Parliament Think Tank , \nApril 2, 2017. www.europarl.europa.eu/thinktank/en/document.html?reference=EPRS_\nATA(2017)608805\n25society today is highly digitised, technological tools such as apps (e.g., \nOpen Mind) can be developed to facilitate critical thinking by aiding people \nin understanding their online surfing habits and associated biases.51\nInstilling critical thinking skills in national education systems specifically \nwith the aim of countering fake news is a new concept, with very few extant \ncases studies. However, there may be lessons from the CVE (Countering \nViolent Extremism) experience, where critical thinking skills, which are \nuseful in steering youth away from radicalisation, can be applied to fake \nnews.52 In addition, there are existing media literacy programmes such as \nthe Safer Internet Day \u2013 promoting responsible use of digital technology \n\u2013 that is spearheaded in Singapore by the Media Literacy Council (MLC). \nFurther studies should be done to determine how these programmes could \nbe expanded to include fake news.\nIn the same vein as critical thinking, the CVE experience has shown that \nthe source (or messenger) of counter-narratives matters. Official sources \nare important for trusted facts and information but may at times be \ncounterproductive. For example, videos produced by the US Department \nof State (Centre for Strategic Counterterrorism Communications), to \ncounter extremist messages have marginal credibility among certain \ntarget audiences. Hence, official sources including media and online \nplatforms should be complemented by credible voices and face-to-face \nconversations. An example is the Our Singapore Conversation (OSC) \ninitiative (2012-2013) which brought together individuals from diverse \nbackgrounds and with different views to have dialogues on complex \nsocioeconomic issues that are of concern to Singapore\u2019s future.53\n51 King, Noel, and Steve Inskeep. \u201cYale University Hackathon Takes Aim at Fake News.\u201d \nNational Public Radio (NPR ), December 27, 2017. www.npr.org/2017/12/27/573739681/\nyale-university-hosts-hackathon-aimed-at-fake-news\n52 For upstream CVE and critical thinking, see Daily Times, \u201cCritical Thinking Is Crucial \nto Nation, Peace Building: Dutch Diplomat\u201d, July 19, 2016, http://dailytimes.com.pk/\nislamabad/19-Jul-16/critical-thinking-is-crucial-to-nation-peace-building-dutch-diplomat; \nHoria Ungureanu, \u201cFBI Has A New \u2018Don\u2019t Be A Puppet\u2019 Game-Like Website To Teach \nKids About Violent Extremism.\u201d Tech Times , February 10, 2016; and \u201cThink Critically to \nCounter Violent Extremism, Youth Advised.\u201d United Nations Radio , August 1, 2016. http://\nwww.unmultimedia.org/radio/english/2016/08/think-critically-to-counter-violent-extremism-\nyouthadvised/\n53 \u201cWhat Future Do We Want? How Do We Get There?\u201d Reflections of Our \nSingapore Conversation  August 2, 2013. https://www.reach.gov.sg/~/media/\noursingaporeconversation/oursingaporeconversationreflection.pdf\n26Conclusion\nThere is no silver bullet. Efforts to counter fake news must comprise both \nlegislative and non-legislative approaches \u2013 each has its own challenges \u2013 \nwhile taking into account several considerations.\nFirst, these approaches must be grounded in an understanding of how \ntechnology enables fake news to spread, factoring in research on human \npredisposition to believing fake news (as well as the changing media \nconsumption patterns of digital natives).\nSecond, it would help to make a distinction between the different categories \nof falsehoods that are being propagated using fake news as the medium. \nThis includes grappling with the possibility of influence operations \n(disinformation) as those conducting it would seek to adapt their tactics \nin the long run in order to circumvent these approaches. Conflating all \nfalsehoods as a homogeneous fake news phenomenon runs the risk of \ndeveloping ineffective approaches.\nThird, efforts to counter fake news should go hand in hand with ongoing \nprogrammes (e.g., critical thinking and media literacy) at shoring up social \nresilience and a national consensus. As UK political commentator and \njournalist, Matthew d\u2019Ancona notes, post-truth is \u201cwhat happens when a \nsociety relaxes its defence of the values that underpin its cohesion, order \nand progress: the values of veracity, honesty and accountability.\u201d54 Framing \nthe truth (or counter-messaging, as the case may be) is also important. \nUnpublished studies from Arizona State University (ASU), as an offshoot \nof work for the Defense Advanced Research Projects Agency (DARPA), \nmay be of help with regard to developing persuasive counter-narratives. \nStudies done at ASU\u2019s Department of Psychology and Department of \nHuman Communication have highlighted how narratives have to have \n\u201cfidelity\u201d in order to be persuasive.55 Expressed simply, subjects will be \nmore inclined to believe news if it corresponds to both their experiences \n54 d\u2019Ancona, Matthew. \u201cPost-Truth: The New War on Truth and How to Fight Back\u201d Ebury \nPress, 2017.\n55 Blumenfeld-Jones, Donald. \u201cFidelity as a criterion for practicing and evaluating narrative \ninquiry.\u201d International Journal of Qualitative Studies in Education  8 (1995): 25\u201335. http://\nwww.tandfonline.com/doi/abs/10.1080/0951839950080104?journalCode=tqse20\n27and, importantly, the stories they have heard before. Framing may be the \nkey to persuasion.56\nFourth, efforts need to move beyond bland rebuttals and statements. \nResearch suggests that direct contradiction can be counter-productive and \nmay instead cause individuals to become even more convinced of their \nbeliefs.57 Since individuals respond best to persons and groups perceived \nto be more similar to them, collaborating with existing alternative news \nmedia outlets and social media companies like Facebook, which are seen \nas \u201cauthentic\u201d, is an important step in gaining readership and credibility.58\nFifth, counter-narratives that challenge fake news must be released \nexpeditiously as fake news can spread en masse  at great speed due \nto technology.59 Hence, efforts must be supported with good public-\nprivate partnerships (including with non-governmental entities and \nresearch institutes), given that technological companies such as Google \nand Facebook are working on developing tools (policies and artificial \nintelligence) to help identify potential fake news and to flag them \naccordingly.60 These tools can complement efforts by state agencies in \nusing sentiment analysis and technology (data analytics and artificial \nintelligence) to identify potential flashpoints and develop counter-narratives.\nSuch partnerships require a collaborative rather than an adversarial \nrelationship between states and technological companies. The relationship \nwill become adversarial if states rely strictly on legislation to compel \ncompanies to counter fake news. This report has discussed the challenges \nwith relying on legislation only. Moreover, the CVE experience has \nshown that purveyors of harmful content would seek to adapt their tactics \nto circumvent legislation such as by migrating to encrypted or closed \n56 As D\u2019Ancona notes, facts are not enough. They need to be \u201ccommunicated in a way that \nrecognises emotional as well as rational imperatives.\u201d\n57 Leetaru, Kalev. \u201cThe Backfire Effect And Why Facebook\u2019s \u2018Fake News\u2019 Warning Gets It All \nWrong.\u201d Forbes , March 23, 2017. https://www.forbes.com/sites/kalevleetaru/2017/03/23/\nthe-backfire-effect-and-why-facebooks-fake-news-warning-gets-it-all-wrong/\n58 Ibid, As D\u2019Ancona notes, facts are not enough. They need to be \u201ccommunicated in a way \nthat recognises emotional as well as rational imperatives.\u201d\n59 Ball, James. Post-Truth: How Bullshit Conquered the World.  Bite back Publishing, 2017\n60 Experts and social scientists were recruited during the Second World War by the US \nmilitary machine in support of a psychological warfare campaign against the Nazi \npropaganda. American messaging was greatly enhanced by their input.\n28platforms (e.g., Telegram and WhatsApp) which are even harder to \nregulate.\nIn sum, fake news is a multidimensional problem, hence efforts to counter \nit must be multifaceted and grounded in a good understanding of the \nproblem. Collaboration across the whole of society is necessary in order to \nunravel the problem and work towards a better synergy of efforts.\n29About the Authors\nNorman Vasu  is Senior Fellow and Deputy Head of the Centre of \nExcellence for National Security (CENS) at the S. Rajaratnam School of \nInternational Studies (RSIS), Singapore. He received his MA from the \nUniversity of Glasgow in 1998, an MSc in International Relations from \nthe London School of Economics in 1999, and his PhD in International \nPolitics from the University of Wales at Aberystwyth in 2004. He is the \nauthor of  How Diasporic Peoples Maintain their Identity in Multicultural \nSocieties: Chinese, Africans, and Jews  (Edwin Mellen Press, 2008). \nEditor of  Social Resilience in Singapore: Reflections from the London \nBombings  (Select Publishing, 2007), and co-editor of  Nations, National \nNarratives and Communities in the Asia Pacific  (Routledge, 2014) as well \nas Immigration in Singapore  (Amsterdam University Press, 2015). His \nresearch on multiculturalism, ethnic relations, narratives of governance, \ncitizenship, immigration and national security have been published in \njournals such as  Asian Survey , Asian Ethnicity , Journal of Comparative \nAsian Development  and The Copenhagen Journal of Asian Studies  and a \nnumber of edited volumes. He was a Fulbright Fellow with the Center for \nStrategic Communication, Hugh Downs School of Human Communication, \nArizona State University in 2012.\nBenjamin Ang  joined the Centre of Excellence for National Security \n(CENS) at RSIS as a Senior Fellow in cybersecurity issues in February \n2016. Prior to this, he had a multi-faceted career that included time as \na litigation lawyer arguing commercial cases, IT director and general \nmanager of a major Singapore law firm, corporate lawyer specialising in \ntechnology law and intellectual property issues, in-house legal counsel in \nan international software company, Director-Asia in a regional technology \nconsulting firm, in-house legal counsel in a transmedia company, and \nsenior law lecturer at a local Polytechnic, specialising in data privacy, digital \nforensics, and computer misuse and cybersecurity. Benjamin graduated \nfrom Law School at the National University of Singapore, and has an MBA \nand Masters of Science in Management Information Systems (MS-MIS) \nfrom Boston University. He is qualified as an advocate and solicitor of \nthe Supreme Court of Singapore. He is also a Certified Novell Network \nadministrator.\n30Terri-Anne Teo  is a Research Fellow at the Centre of Excellence for \nNational Security (CENS), S. Rajaratnam School of International Studies, \nNanyang Technological University, Singapore. She holds a PhD in \nPolitics from the University of Bristol. Before joining RSIS, Terri-Anne \ntaught courses on Political Theory and World Politics at the University of \nBristol, and guest lectured at Singapore Management University (SMU), \non multiculturalism in Singapore. Her research focuses on the theory of \nmulticulturalism, citizenship and postcolonialism.\nShashi Jayakumar  assumed the appointment as Head, Centre of \nExcellence for National Security (CENS) on 1 April  2015, and the \nappointment of Executive Coordinator, Future Issues and Technology on \n1 August 2017. Dr Jayakumar was educated at Oxford University where \nhe studied History (BA 1997, D.Phil. 2001). He has published in various \npeer-reviewed journals and edited volumes on topics relating to medieval \nhistory (the focus of his doctorate). He was a member of the Singapore \nAdministrative Service from 2002-2017. During this time, he was posted \nto various ministries, including the Ministries of Defence, Manpower, \nInformation and the Arts, Community Development, and Youth and Sports. \nFrom August 2011-July 2014, he was a Senior Visiting Research Fellow at \nthe Lee Kuan Yew School of Public Policy. His research interests include \nextremism, social resilience, cyber, and homeland defence. He is currently \ncompleting a book relating to local (Singapore) politics (forthcoming, \nNational University of Singapore Press, 2018).\nMuhammad Faizal  is a Research Fellow with the Centre of Excellence \nfor National Security (CENS), at the S. Rajaratnam School of International \nStudies (RSIS). He holds a Bachelor of Business Administration (with \nMerit), from the National University of Singapore. Prior to joining RSIS, \nFaizal served with the Singapore Ministry of Home Affairs where he was a \ndeputy director and had facilitated international engagements with foreign \nsecurity counterparts. He also had postings in the Singapore Police Force \nwhere he supervised and performed intelligence analysis, achieving several \ncommendation awards including the Minister for Home Affairs National Day \nAward (2009), for operational and analysis efficiency; and in the National \nSecurity Research Centre (NSRC), at the National Security Coordination \nSecretariat (NSCS), where he led a team to research emergent trends in \ndomestic security and monitor terrorism-related developments. Faizal also \nhas certifications in Counter-Terrorism, Crime Prevention and Business \nContinuity Planning.\n31Juhi Ahuja  is a Senior Analyst at the Centre of Excellence for National \nSecurity (CENS) at the S. Rajaratnam School of International Studies \n(RSIS). Prior to joining CENS, Juhi was a Research Analyst with the \nStudies in Inter-Religious Relations in Plural Societies (SRP) Programme \nat RSIS. She holds an MSc in International Relations from RSIS, and was \nawarded the SRP Study Award. She previously worked at the Embassy of \nTimor-Leste in Singapore, as an Economic & Trade Officer. Her research \ninterests include religious violence and extremism, socio-cultural identity, \npostcolonial theory, and nationalism.\n32About the Centre of Excellence for National Security\nThe Centre of Excellence for National Security (CENS)  is a research \nunit of the S. Rajaratnam School of International Studies (RSIS) at the \nNanyang Technological University, Singapore.\nEstablished on 1 April 2006, CENS  raison d\u2019\u00eatre  is to raise the intellectual \ncapital invested in strategising national security. To do so, CENS is devoted \nto rigorous policy-relevant analysis across a range of national security \nissues.\nCENS is multinational in composition, comprising both Singaporeans and \nforeign analysts who are specialists in various aspects of national and \nhomeland security affairs. Besides fulltime analysts, CENS further boosts \nits research capacity and keeps abreast of cutting-edge global trends in \nnational security research by maintaining and encouraging a steady stream \nof Visiting Fellows.\nFor more information about CENS, please visit https://www.rsis.edu.sg/\nresearch/cens/ .\nAbout the S. Rajaratnam School of International Studies\nThe S. Rajaratnam School of International Studies (RSIS)  is a \nprofessional graduate school of international affairs at the Nanyang \nTechnological University, Singapore. RSIS\u2019 mission is to develop a \ncommunity of scholars and policy analysts at the forefront of security \nstudies and international affairs. Its core functions are research, graduate \neducation and networking. It produces cutting-edge research on Asia \nPacific Security, Multilateralism and Regionalism, Conflict Studies, Non-\nTraditional Security, International Political Economy, and Country and \nRegion Studies. RSIS\u2019 activities are aimed at assisting policymakers to \ndevelop comprehensive approaches to strategic thinking on issues related \nto security and stability in the Asia Pacific.\nFor more information about RSIS, please visit www.rsis.edu.sg .\n\nNanyang Technological University\nBlock S4, Level B3, 50 Nanyang Avenue, Singapore 639798\nTel: +65 6790 6982 | Fax: +65 6794 0617 | www.rsis.edu.sg", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "FAKE NEWS: NATIONAL SECURITY IN THE POST-TRUTH ERA.", "author": ["N Vasu", "B Ang", "TA Teo", "S Jayakumar", "M Raizal"], "pub_year": "2018", "venue": "NA", "abstract": "Fake news is not a new issue, but it poses a greater challenge now. The velocity of information  has increased drastically with messages now spreading internationally within seconds"}, "filled": false, "gsrank": 632, "pub_url": "http://journres1.pbworks.com/w/file/fetch/145878072/Fake_News_National_Security_in_the_Post.pdf", "author_id": ["kwn9efAAAAAJ", "", "9WO6hHYAAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:zahI54MV5JsJ:scholar.google.com/&output=cite&scirp=631&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=zahI54MV5JsJ&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 113, "citedby_url": "/scholar?cites=11233127026834057421&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:zahI54MV5JsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://journres1.pbworks.com/w/file/fetch/145878072/Fake_News_National_Security_in_the_Post.pdf"}}, {"title": "The devil is in the details: Analyzing the lucrative ad fraud patterns of the online ad ecosystem", "year": "2023", "pdf_data": "Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud\nin the Online Ad Ecosystem\nEmmanouil\nPapadogiannakis\nFORTH & University of Crete\nHeraklion, GreeceNicolas Kourtellis\nTelefonica Research\nBarcelona, SpainPanagiotis\nPapadopoulos\nFORTH\nHeraklion, GreeceEvangelos Markatos\nFORTH & University of Crete\nHeraklion, Greece\nAbstract\nThe online advertising market has recently reached the 500 billion\ndollar mark. To accommodate the need to match a user with the\nhighest bidder at a fraction of a second, it has moved towards a com-\nplex, automated and often opaque model that involves numerous\nagents and intermediaries. Stimulated by the lack of transparency,\nbut also the enormous potential profits, bad actors have found ways\nto circumvent restrictions, and generate substantial revenue that\ncan support websites with objectionable or even illegal content.\nIn this work, we evaluate transparency Web standards and show\nhow shady actors take advantage of gaps to absorb ad revenues\nwhile putting the brand safety of advertisers in danger. We collect\nand study a large corpus of thousands of websites and show how\nad transparency standards can be abused by bad actors to obscure\nad revenue flows. We show how identifier pooling can redirect ad\nrevenues from reputable domains to notorious domains serving\nobjectionable content, and that the phenomenon is underestimated\nby previous studies by a factor of 15. Finally, we publish a Web\nmonitoring service that enhances the transparency of supply chains\nand business relationships between publishers and ad networks.\nCCS Concepts\n\u2022Information systems \u2192World Wide Web ;Online advertising .\nKeywords\nDark Pooling; Hidden Intermediaries; Advertising; Web Monetiza-\ntion\nACM Reference Format:\nEmmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos,\nand Evangelos Markatos. 2025. Welcome to the Dark Side: Analyzing the\nRevenue Flows of Fraud in the Online Ad Ecosystem. In Proceedings of the\nACM Web Conference 2025 (WWW \u201925), April 28-May 2, 2025, Sydney, NSW,\nAustralia. ACM, New York, NY, USA, 14 pages. https://doi .org/10 .1145/\n3696410 .3714899\n1 Introduction\nLike any domain of economy in which hundreds of billions of dol-\nlars are moved [ 18,45], it is no surprise that with the widespread\nadoption of programmatic advertising, there has also been a surge\nin fraudulent activities. Considering the impersonal nature of the\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nWWW \u201925, Sydney, NSW, Australia\n\u00a92025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-1274-6/25/04\nhttps://doi .org/10 .1145/3696410 .3714899programmatic ad transactions, the complex and often opaque sup-\nply chains, the big number of intermediaries (who benefit from\nfraudulent traffic [ 26]) and the ecosystem\u2019s reliance on easily fid-\ndled metrics [ 85], it is apparent that digital advertising constitutes\na very vulnerable and very lucrative opportunity for fraudsters.\nStudies show that one out of every three dollars spent by adver-\ntisers is wasted due to ad fraud [ 80], when according to Google,\n56% of impressions served across its advertising platforms are not\nviewable for the users [ 82]. In fact, the global cost of ad fraud is\nexpected to continue growing exponentially to $100 billion [76].\nRecent examples of sophisticated ad fraud reveal that disinforma-\ntion websites manage to receive ads (and revenue) from respectable\ncompanies that would dread even the thought of seeing their brand\nname next to fake news [ 17,22]. Similarly, during the 2016 U.S. elec-\ntion campaign, hundreds of websites were created to spread fake\nnews via clickbait headlines and generate massive ad revenue [ 24].\nIn 2018, the 3vebotnet [ 57] was dismantled, consisting of 1.7 mil-\nlion infected PCs and 10,000 fake sites. It was generating 3-12 billion\ndaily bid requests, using over 60,000 seller IDs, thus receiving ad\nplacements which cost a whopping $29 million.\nOf course, we are not the first to identify that the lack of trans-\nparency in the supply chain creates the perfect field of action\nfor fraudsters. There were several attempts from policymakers\nand stakeholders to shed light to these processes [ 23,36,43], but\nthe mechanisms deployed were either inefficient or not widely\nadopted [ 25,27,38,81]. In [ 5,65,84], authors highlight the lack of\ntransparency in ad ecosystem, showing that inconsistencies encum-\nber automated processes. In [ 86] authors measure the efficiency of\nbrand safety tools and conduct an initial study of the prevalence\nof dark pooling in misinformation websites. However, since it was\nlimited to a much smaller number of websites, it significantly un-\nderestimated the magnitude of the problem by more than an order\nof magnitude (in this work we show that the average dark pool size\nis larger than what was reported by a factor of 15).\nIn this work, we shed light on the techniques that bad actors\ndeploy to abuse the online advertising ecosystem and absorb ad\nrevenue. We highlight how current Web standards are regularly\nmisused and how the lack of compliance with standards leaves room\nfor loss of advertisers\u2019 money. We show that both publishers and\nresellers pool their identifiers together to share the ad revenue they\ngenerate from unsuspecting advertisers, thus posing a significant\nrisk to their brand safety. We also discover that ad brokers disguise\nthemselves as publishers claiming a larger portion of the advertisers\u2019\nbudget, thus making the supply chain even more opaque.\nThe contributions of this work are summarized as follows:\n(1)We conduct the first, to our knowledge, large-scale sys-\ntematic study of state-of-the-art ad transparency standardsarXiv:2306.08418v3  [cs.CY]  9 Jul 2025\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\nacross more than 7 million websites and discuss their effec-\ntiveness. We find that these standards are regularly misused\nsince there is no verification of proper implementation, al-\nlowing bad actors to obscure ad revenue flows.\n(2)Our findings show that Web publishers are able to circum-\nvent restrictions of ad networks via identifier pooling and\nmonetize misinformation or pirated content. We estimate\nthat such bad actors are able to absorb thousands of dol-\nlars from the advertising ecosystem. Contrary to previous\nwork [ 86], we show that the average dark pool size is larger\nthan what was reported by a factor of 15, thus exposing the\nreal magnitude of dark pooling and show that it is more than\nan order of magnitude of what was thought before.\n(3)We uncover 30 cases of ad resellers that disguise themselves\nas content owners (i.e., Web publishers) in other ad networks\nand abuse ad-related standards to increase their profits. We\nshow that some of these resellers work with almost 200\nobjectionable or even illegal websites in total, and that their\nbehavior does not change in a 7-month period.\n(4)We build and publish AdSparency1: a Web monitoring ser-\nvice that aims to enhance transparency in the ad ecosystem.\nBy using data from millions of domains, it provides statistical\ninformation about the supply chains and a set of investigative\ntools to discover and analyze business relationships among\npublishers and ad networks.\n(5)We make the source code of our tools and our datasets pub-\nlicly available to support further research. See Appendix A.\n2 Background\nads.txt: Counterfeit inventory was once a common issue, with\nadvertisers unsure if their ads appeared as intended [ 40] and fraud-\nsters often selling ad space from unrelated websites [ 5]. The Internet\nAdvertising Bureau (IAB) Tech Lab introduced the ads.txt specifi-\ncation to prevent unauthorized ad inventory sales [ 43]. An ads.txt\nfile, placed at a domain\u2019s root, allows publishers to list authorized\naccounts for selling its ad inventory. Each entry, as shown in Fig-\nure 1, is a comma-separated record granting sales permission for a\nspecific entity (i.e., account). The mandatory fields of each record\nare: (i) the domain of the ad system that bidders connect to, (ii) an\nidentifier that uniquely identifies that account of the seller within\nthe ad system, (iii) the type of the account. The type of the account\ncan be either DIRECT , indicating that the web publisher directly\ncontrols the advertising account, or RESELLER , indicating that the\npublisher has authorized a third party to manage and (re)sell the ad\ninventory of the website. The ads.txt mechanism does not combat\nthe entire spectrum of ad fraud, and it relies on the assumption\nthat all involved entities respect the specification . Supply-Side Plat-\nforms (SSPs) are expected to ignore inventory they have not been\nauthorized to sell and, Demand-Side Platforms (DSPs) are expected\nto not buy ad inventory from unauthorized sellers. It is more than\ncommon for a website publisher to have more than one publisher\nIDs. Often, publishers create ad accounts with multiple ad networks\n(e.g., Google, Ezoic, Taboola, etc.) and have to place all of these IDs\nin their ads.txt file.\n1https://adsparency .ics .forth .gr/\ngoogle.com, pub-9435010515680227 , DIRECT, f08c47fec0942fa0\nrubiconproject.com, 20910, DIRECT, 0bfd66d529a55807\npubmatic.com,157150,RESELLER,5d62403b186f2ace\nopenx.com,540191398,RESELLER,6a698e2ec38604c6\n{\n    \"seller_id\": \" pub-9435010515680227 \",\n    \"seller_type\": \"PUBLISHER\",\n    \"name\": \"Quora Inc\",\n    \"domain\": \"quora.com\"\n},\n{\n    \"seller_id\": \"pub-6806024782369214\",\n    \"is_confidential\": 1,\n    \"seller_type\": \"PUBLISHER\"\n}sellers.jsonads.txtFigure 1: Snippets of the ads.txt file served by quora.com and\nsellers.json file served by Google . Each record represents a\nbusiness relationship.\nsellers.json: The IAB Tech Lab introduced sellers.json files to\nincrease the transparency of the ad ecosystem [ 41]. It is supplemen-\ntary to ads.txt files and helps discover and verify the entities in-\nvolved in ad inventory selling. Along with ads.txt ,sellers.json\nfiles oppose ad fraud. Each advertising system (i.e., SSP) is expected\nto publish a sellers.json file, explicitly listing all registered ad\ninventory sellers. Each sellers.json entry (Figure 1) contains\nan identifier that uniquely represents the seller within the respec-\ntive ad system. This is the same ID that websites disclose in their\nads.txt file. Optionally, the name of the legal entity, which gener-\nates revenue under the given ID, is also specified. Each entry must\nspecify the type of seller as one of: (i) PUBLISHER , indicating the\ndomain\u2019s ad inventory is sold by the domain owner and that the ad\nsystem directly pays the owner, (ii) INTERMEDIARY , indicating that\nad inventory is sold by an entity that does not own it but acts as an\nintermediary to sell it, or (iii) BOTH , when the account is both types.\n3 Methodology\nWe provide an overview of our methodology in Figure 2. To collect\nour dataset, we fetch and analyze ad-related files served by pub-\nlishers and ad networks. We implement two crawlers located in an\nEU-based institute and visit more than 7M distinct domains during\nFebruary-March 2023. First, we utilize the open-source ads.txt\nfetching and parsing module offered by IAB [ 42] to crawl and collect\nads.txt files served by millions of websites. In Section 4, through\nan offline analysis, we investigate Identifier Pooling : publishers\nthat share their identifiers with unrelated websites to share revenue.\nWe study the characteristics (e.g., size and composition) of pools of\nwebsites and demonstrate how this technique can fund objection-\nable content, such as fake news. In Section 5, we develop a recursive\ncrawler of sellers.json files in order to discover Hidden Inter-\nmediaries : ad networks that masquerade themselves as publishers.\nWe perform a graph-based analysis to uncover the business rela-\ntionships across ad networks and find that deceitful ad systems can\nforward ads to unknown entities while charging advertisers higher\nprices. We make both of our crawlers publicly available in [ 60] (see\nAppendix A). Finally, in Section 6, we utilize the collected data and\npresent, AdSparency : a Web service that illustrates the state of the\nonline ad ecosystem, and provides stakeholders with investigative\ntools to uncover business relationships among Web entities. We\ndiscuss ethical aspects of our work in Appendix B.\nWelcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nWebAds.txt ProcessingTXT\nData\nCollection\nSellers.json ProcessingJSONPublisher Identifier\nExtractionpub-123456789\n6a823ef6107\n8251642\nGraph AnalysisRevenue Pooling\nIdentity MasqueradeAdSparency\nFigure 2: Overall methodology of present study.\n4 Identifier Pooling\nAssume a website that sells books (e.g., example.com ) registers for\nan advertising account with Google. example.com will be reviewed\nto ensure that it does not violate any of Google\u2019s terms, and eventu-\nally be granted a publisher ID so that it can display ads. Now assume\nan affiliated website (e.g., fakenews.com ) that is notorious for pub-\nlishing misinformation. Since fakenews.com has attracted negative\nattention for its articles, popular advertisers have pulled away from\nit. Thus, while example.com receives ads from popular-brand.com\nvia programmatic ad processes (e.g., RTB, Header Bidding), fake-\nnews.com gets ads from click-bait.com . To increase the quantity but\nalso the quality (and price) of the ads it receives, fakenews.com can\nmake a backroom deal with example.com to pool their ad inven-\ntory, in exchange for a small fee that example.com gets for sharing\nits publisher ID [ 28]. By simply putting the publisher ID of exam-\nple.com in the ads.txt file served by fakenews.com and using it\nin bid requests, a \u201cdark pool\u201d is formed. The revenue generated\nfrom all advertisers (both popular-brand.com and click-bait.com )\nwill wind up at the same publisher account.\nPooling ad inventory keeps both advertisers and ad networks\nin the dark regarding where their money flows to. Advertisers\nthat appear on example.com will inadvertently have their money\nflow towards fakenews.com or other undesirable websites. To make\nmatters worse, fakenews.com can use the shared ID and lie about\nthe origin domain in the bid request, in order to directly get ads, and\nthus revenue, from popular advertisers. Because of pooling, almost\n1 billion ad impressions were attributed to just 30 websites [ 27]. In\nfact, Breitbart, an infamous misinformation website, was using this\ntechnique to bypass block lists and generate ad revenue [21, 28].\nEven though ads.txt files were introduced to tackle fraud, the\nlack of transparency makes it difficult to prevent revenue from\nbeing funneled to unrelated websites. Pooling identifiers is not\nnecessarily in violation of the standard or an abuse of the ad ecosys-\ntem. However, from its early stages, the ads.txt specification was\ncriticized and there were speculations that ad-related companies\nfacilitate dark pooling by forcing multiple publishers to use the\nsame identifiers [ 68,69]. Unsuspecting website publishers were in-\nstructed to declare identifiers they do not control in their ads.txt\nfiles [ 66,74], and had their ad inventory pooled with completely\nunrelated websites [ 21]. Advertisers rest assured that their money\nfunds specific websites while, due to identifier pooling, it can flow\ntowards unknown entities, threatening their brand safety. As a re-\nsult, simple block lists [ 9,79] are no longer sufficient to ensure that\nadvertisers do not fund objectionable content. Advertisers would\nnow need to block specific publisher IDs, something non-realistic\nbecause it is impossible to know where each identifier is used.Of course, shady websites can copy identifiers from other web-\nsites without permission to falsely indicate that a popular ad net-\nwork is an authorized seller of its inventory. This can boost the\nwebsite\u2019s reputation with other ad networks, increase their ad in-\nventory value, or even bypass review policies. There exist websites\nthat declare identifiers in their ads.txt files that the correspond-\ning ad networks do not even acknowledge (Appendix E). There is\nalready evidence that questionable websites can monetize their ad\ninventory using this technique [ 86]. Finally, if a less popular ad\nnetwork observes that a website uses publisher IDs from popular ad\nnetworks (e.g., Google), they might not perform a manual review.\n4.1 Data Collection\nTo study Identifier Pooling, one must have access to the identifiers\npublishers declare in their ads.txt files. To that extent, we utilize\nIAB\u2019s official ads.txt crawler [ 42]. We keep the implementation as-\nis and only change the user-agent header so that we are not blocked\nby websites. We extract almost 7 million websites from the Tranco\nlist [44] that aggregates the ranks of domains2and crawl them dur-\ning February 2023. The crawler successfully fetched the ads.txt\nfiles of 456,971 domains and extracted 81,985,768 valid entries that\nfollow the specification [ 43]. In these entries, we detect 591,546\ndistinct DIRECT publisher identifiers. DIRECT identifiers indicate\nthat the content owner directly controls the account responsible\nfor selling a website\u2019s ad inventory. We focus on such identifiers\nsince they indicate a direct business relationship between the ad\nnetwork and the publisher [ 5,43]. Sharing them with unrelated\nentities is in violation of the specification. RESELLER accounts are\nexpected to handle the ad inventory of multiple websites, form het-\nerogeneous pools and redistribute ad revenue [ 43]. Consequently,\nsuch identifiers are excluded from the analysis of this work.\n4.2 Pools Composition\nWe analyze the collected ads.txt records and, in Figure 3, we ob-\nserve that popular ad networks are equally represented in websites\nand share a similar portion of the market. Google is the only ex-\nception, since it evidently dominates the market. 92% of websites\nthat serve an ads.txt file contain at least one DIRECT publisher ID\nissued by Google for the monetization of the website\u2019s content.\nWe define that a DIRECT identifier is used to form a pool when\nthe same identifier is used in more than one website. Contrary to\nprevious work [ 86], we follow a stricter definition of pools by fo-\ncusing only on DIRECT identifiers. A publisher ID is not necessarily\nassociated with only one domain. Sharing a DIRECT identifier does\nnot inherently indicate an abuse of the ad ecosystem. Websites oper-\nated by the same entity are allowed (even expected) to use the same\nidentifier across websites [ 62]. Pooling violates the specification\nwhen an ID is shared among unrelated websites. Identifiers might\nalso be shared across websites due to intermediary publishing part-\nners [ 31,62]. These third-party services manage ad inventory of\nmultiple publishers to optimize their ad revenue. However, they\nshould not register their IDs as DIRECT and then distribute them to\ntheirs clients, since they do not own the ad inventory.\nOverall, we find 185,535 distinct pools. In Figure 4, we plot the\nmost popular ad networks whose DIRECT identifiers are used to\n2https://tranco-list.eu/list/998W2/full\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\n 0 20 40 60 80 100\nGoogleRubiconProjectIndexExchangeAppnexusPubmaticaps.amazonLijitOpenXSmartAdserverTriplelift091K182K274K365K456K% of websites with ads.txt \ufb01les\n# of websites with ads.txt \ufb01les\nFigure 3: Popular networks whose iden-\ntifiers are used by websites to monetize\ntheir content based on ads.txt records.\n 0 20 40 60 80 100\nEzoicGooglePubmineLijitTripleliftTaboolaOpenXIndexExchangeRubiconProjectPubmatic%\n%% of DIRECT IDs used to form pools\n% of pools formed by ad network IDs\n8%23%53%57%58%59%71%71%74%76%1%35%\n2%1%2%6%1%1%1%1%Figure 4: Popular networks whose iden-\ntifiers are used to form pools of websites\nsharing the same publisher identifier.\n 0.5 0.6 0.7 0.8 0.9 1\n5K10K 15K 20K 25K 30K 35K 40KCDF\nPool SizeAll Pools\nFake News Pools\nPiracy PoolsFigure 5: Distribution of pool sizes (i.e.,\nnumber of websites) based on the types\nof websites they contain.\nform pools. We plot (i) the percentage of all detected pools formed\nby identifiers of a specific ad network (green line), and (ii) the per-\ncentage of identifiers that each ad network has issued and are used\nto form pools (black bars). First, we observe that all ad networks\nthat dominate the market (Figure 3) also allow their identifiers to\nform pools. Most prominently, direct identifiers issued by Google\nform 35% of all pools in our dataset, while Taboola\u2019s identifiers form\n6% of all pools. This is not innately damaging for the ecosystem.\nNonetheless, we also observe that over 70% of the DIRECT identifiers\nfrom 4 popular ad networks are used to form pools. This suggests\nthat not all ad networks properly use ads.txt relationships or that\nthey do not properly monitor how their identifiers are used.\nInspired by previous work regarding monetization of fake news\nwebsites (e.g., [ 4,7,63]), we explore if objectionable websites partic-\nipate in identifier pooling. We form two lists of objectionable web-\nsites. First, we make use of MediaBias/FactCheck (MBFC) [ 10], an\nindependent organization that detects bias of information sources\nand extract 1,163 misinformation websites that are extremely biased\nand often promote propaganda or have failed fact-checks. We also\nform a list of known Web piracy websites. We utilize NextDNS\u2019\nPiracy Blocklist [ 56] and focus on 1,395 websites in the \u201ctorrent\u201d\nand \u201cwarez\u201d categories. We make both lists publicly available [ 60].\nWe acknowledge that other types of objectionable websites might\nalso deploy identifier pooling, but focus on misinformation and\npiracy websites because these websites are prone to committing ad\nfraud (e.g., [ 13,54,86,87]). We find that there are 211 fake news\nwebsites and 121 piracy websites that participate in pools of various\nad systems. Interestingly, there are over 5,000 and over 2,000 pools\nthat contain at least one misinformation or piracy website, respec-\ntively. This suggests that there are numerous benign websites found\nin the same pool (sharing revenue) with objectionable websites and\nthat, this can happen without their operators knowing.\nWe study the size of pools based on the type of websites they\ncontain. In Figure 5 we illustrate the distribution of pool sizes for\n(i) all pools, (ii) pools that contain at least one fake news website,\nand (iii) pools that contain at least one piracy website. We observe\nthat general pools are smaller than pools that contain objectionable\nwebsites. In fact, both the mean and the median general pool size\nis much smaller than for pools containing fake news or piracy\nwebsites. For general pools, the median pool size is 4, while the\nmean is\u223c122. Publishers often operate a few websites and use the\nsame identifier in order to monetize them and keep track of their\ntraffic [ 62]. On the other hand, the median and mean pool sizesfor pools with fake news websites are 336.5 and \u223c2,975, while for\npiracy pools they are 645 and \u223c4,915 respectively.\nWe conduct two-sample Kolmogorov\u2013Smirnov tests to compare\nall pools with fake news and piracy pools. The KS test scores 0.6\n(p-value 5.08e-320) between fake news and all pools and 0.77 (p-\nvalue 1.86e-320) between piracy and all pools, confirming these\npools differ significantly from general identifier pools. This suggests\nidentifiers might be falsely registered as DIRECT , with objectionable\nwebsites clustering in large pools and sharing the same identifier\nto receive ads, rather than a single entity controlling thousands of\nwebsites. We further investigate mis-registered IDs in Appendix C.\n4.3 Ecosystem Abuse\nWe investigate whether websites abuse the ad ecosystem by sharing\nidentifiers with unrelated websites. While identifier pooling isn\u2019t\ninherently harmful, issues arise when unrelated websites share the\nsame DIRECT IDs. To verify this, we use the WHOIS protocol [ 19]\nto identify owner organization of domains, following prior work [ 8,\n71]. We query registrars for each domain inside a pool and extract\nthe domain owner (i.e., registrant). To tackle the WHOIS privacy\nservice offered by registrars [ 48], we manually review all extracted\nrecords and create a list of 60 keywords that signify records have\nbeen redacted for privacy concerns. We make this list public [ 60]\nand exclude respective records from further analysis. In total, we\nretrieve owner data for 3,981 websites.\nWe analyze each pool, extracting owner organizations from\nWHOIS records and using case-insensitive matching to overlook\nany typos during WHOIS registration. Organizations with names\nunder three characters are also excluded because we believe they\ndo not represent actual entities. Surprisingly, we identify nearly\n15,000 distinct dark pools: groups of websites with different owners\nsharing at least one DIRECT ID, violating the ads.txt standard.\nSuch pools distort the ecosystem, making it practically impossible\nto understand where advertiser money is directed. To make matters\nworse, 59.6% of pools with at least one misinformation website\nare dark pools. For pools with piracy websites, this percentage\nrises to an astounding 82%. Despite privacy restrictions limiting\nour owner data, our findings represent a lower bound of the issue.\nPrivate WHOIS records do not impact the accuracy of our findings,\nensuring they are reflecting the actual state of the Web.\nNext, we investigate how the behavior of pooling changes based\non the size of the ecosystem one studies. We incrementally analyze\nlarger sub-portions of the ecosystem based on the popularity of the\nWelcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\n 0 500 1000 1500 2000 2500 3000\n0 1M 2M 3M 4M 5M 6M 7MAverage pool size\nPopularity cut-o\ufb00 pointAll Pools\nFake News Pools\nFigure 6: Average pool size for different\npopularity cut-off points. A larger set of\nwebsites reveals more aggressive pooling.\n0%10%20%30%40%50%60%70%\n0 1M 2M 3M 4M 5M 6M 7MDi\ufb00erential Percentage Increase\nPopularity cut-o\ufb00 pointFake News Pools\nPiracy PoolsFigure 7: Differential increase of average\npool size for different popularity cut-off\npoints.\n 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\n500K 1M1.5M 2M2.5M 3M3.5M 4M93 fake news pools\nwith an average rank\nless than 20K\n31 piracy pools\nwith an average rank\nless than 20KCDF\nAverage Pool RankFake News Pools\nPiracy PoolsFigure 8: Average rank of pools contain-\ning at least one objectionable website. A\nsmall rank value signifies a popular site.\nwebsites. For each sub-portion, we only study websites ranked up\nto that specific popularity, based on the Tranco list [ 44]. We use\nintervals of 100K ranks and plot in Figure 6 the average pool size\nfor general pools, and pools with at least one fake news website. We\nobserve, that even though the average pool size for general pools\nhas minimal increase, the average pool size of pools with fake news\nwebsites increases substantially. We compare the average fake news\npool size of our entire dataset (i.e., rightmost data point in the green\nline of Figure 6) with the average fake news pool size of the top\n100K most popular websites (i.e., leftmost data point in the green\nline) and find that it is 15 times larger.\nBy studying a larger portion of the Web, we gain a better under-\nstanding of identifier pooling, revealing that previous work focusing\nonly on popular sites [ 86] underestimates the problem by over an\norder of magnitude. Figure 7 shows the differential percentage in-\ncrease in average pool size across popularity cut-off points. We find\nthat after the top 1M most popular websites, this increase reaches\na plateau, indicating that after this point, pools remain stable and\nreinforcing our confidence in capturing the full scope of identifier\npooling. In fact, the rightmost points show an increase of less than\n1%, which aligns with the idea that including less popular sites\noffers little financial benefit.\nFinally, our findings indicate no correlation between website\npopularity and the extent of mis-registered identifiers (Pearson\ncoefficient: -0.05, p-value: 9e-129). However, there exist 40 highly\npopular websites (ranked in the top 50K most popular websites\nworldwide) that participate in an extreme amount of distinct pools.\nFor example, narod.ru is ranked 2,019thworldwide and serves an\nads.txt file of over 3,200 DIRECT Google identifiers.\n4.4 Revenue Generation\nThe total traffic of a website greatly affects its ad revenue. We plot\nin Figure 8 the average rank of pools that contain at least one fake\nnews or piracy website (i.e., average rank of websites it contains).\nWe find a lot of pools with a very high average popularity rank,\nmeaning that the websites in these pools attract heaps of visitors.\nSurprisingly, we find that there are 93 fake news pools and 31 piracy\npools with an average rank less than 20K, suggesting that they\ncontain extremely popular websites, have loads of daily visitors and\nare able to generate big amounts of ad revenue. Even if it is split\nacross multiple websites or reduced by handling fees, it can still be\na significant income for publishers of illicit or unethical content.To verify this, we extract from SimilarWeb [ 47] the sum of all\nvisits during September 2023 for websites in highly popular pools\n(i.e., average pool rank less than 20K). Indeed, we find that the\nmedian website in these pools had 6.7M visitors during September\n2023 and that there are 6 websites, which totaled over 100M visitors.\nIn an attempt to translate this vast amount of visitors to ad revenue,\nwe also extract the estimated annual revenue for each website.\nWe were able to extract revenue data for 16 websites, and their\nestimated annual revenue is in the millions. In fact, the lowest\nestimated revenue is 2M-5M$, with two websites found in fake\nnews pools having an estimated annual revenue of over 1B USD.\nIt is evident, that if websites have the right to get a share of the\nrevenue from each of the publisher IDs they use, they can generate\nrevenue from multiple sources. Figure 9 illustrates the revenue\nflow that originates from popular ad networks towards fake news\nwebsites, found in the most pools. When a website is part of a pool\nformed by an identifier of ad network \ud835\udc4c, then there is a flow from\nthat network towards the website. If a website appears in multiple\npools of a specific ad network, the flow between them carries greater\nweight. This figure illustrates only potential revenue flows. Due to\nthe complexity of the ad ecosystem and the various entities involved,\nads might be served to a website through a different route (i.e., ad\nnetwork). We find that misinformation websites can monetize their\ncontent and generate revenue from various sources, with Google\nand Lijit being the most prominent contributors. Fake news sites\noften participate in multiple pools formed by Lijit\u2019s identifiers.\nHowever, it should be noted that simply copying an ID from\nanother website does not provide any monetary benefit to the\nbad actor (i.e., they don\u2019t make any money out of it). In order for\nthe bad actor to gain revenue, there has to be an agreement with\nthe owner of the ID (e.g., associate the website with the ID in\nthe ad-management platform). As described, this happens either\nthrough deals with other publishers or through the facilitation by\nad networks. We provide examples to demonstrate the effect of\nidentifier pooling on the ad ecosystem in Appendix D.\n5 Hidden Intermediaries\nIt is important for advertisers to know where their ads will be\nrendered, not only to determine whether they reach their target\naudience, but to also ensure that their ads do not appear next to\n\u201cbad\u201d content. Due to the complexity of programmatic advertising,\neven reputable companies often have no control over where their\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\nLijit\nGoogle\nIndexExchange\nRubiconproject\nPubmaticvidmax\niharare\nredvoicemedia\ndailypoliticalnewswire\nrightnewswire\nblackeyepolitics\ngreatamericandaily\nworldstarhiphop\ntheunionjournal\nthelibertydaily\nFigure 9: Flow of revenue from the top 5 ad networks towards\nfake news websites that participate in inventory pooling.\nads appear [ 1]. This can be a very big hit for their reputation [ 78]\nand their brand\u2019s safety. As a result, they often prefer supplying ads\ndirectly to publishers and not via intermediaries [ 53]. Yet, previous\nstudies have shown that only half of the advertising budget reaches\nthe publishers themselves and that the other half is absorbed by\nintermediary entities [ 58]. To mitigate this, in the RTB ecosystem,\nadvertisers tend to prioritize buying ad inventory from IDs that\nhave been registered as PUBLISHER . This way, no intermediary en-\ntities are involved in reselling the ad inventory beyond advertisers\u2019\ncontrol, and they can better track the flow of their ad spending.\nIs it possible for some media companies to falsely register as a\npublisher in another ad network in order to abuse the ecosystem?\nSuch media companies would masquerade themselves as publishers\nwhile, in fact, they are intermediaries that manage the ad inventory\nof numerous websites or publishers. As a result, hidden interme-\ndiaries could charge higher (i.e., Cost Per Thousand Impressions)\nbecause they pretend to be publishers while rendering ads beyond\nthe control of the advertisers on questionable websites. Such be-\nhavior deteriorates the ecosystem\u2019s transparency since hidden in-\ntermediaries deceive buyers that prefer shorter supply chains, and\nresell ad slots to their own clients. In fact, due to complexity, one\nthird of the supply chain costs are unattributable [58].\n5.1 Data Collection\nTo study hidden intermediaries, we keep track of the relationships\nbetween ad systems and their clients by analyzing sellers.json\nfiles. We build a tool that fetches sellers.json files from domains\nand recursively crawls all domains listed within them. That is, if\nwe detect a sellers.json file, then we recursively visit all the do-\nmains listed in it and attempt to download their own sellers.json\nfile. Using the Tranco list3as a seed, we crawl 7,341,165 domains\non March 24, 2023, and detected sellers.json files in 2,682 do-\nmains. A small number of domains that serve sellers.json files\nis expected, since only ad systems should publish those. From the\ndetected files, we extract over 34 million sellers.json entries.\nWe analyze the sellers.json standard to understand its adop-\ntion, but find it is poorly implemented. We identify 26K publisher\nIDs with incorrect relationship types in ads.txt files across all ad\nnetworks. Additionally, ad networks seem to neglect sellers.json\nfiles, allowing users to claim any website, even popular ones, while\nthere exist domains that serve a sellers.json file of a completely\n3https://tranco-list.eu/list/998W2/fullunrelated ad network. Finally, we discover ad networks that dilute\nthe transparency of supply chains by hiding the entities that own\npublisher IDs. We analyze such violations in Appendix E.\n5.2 Ecosystem Abuse\nWe classify an ad network \ud835\udc4bas a hidden intermediary if (i) it serves\nasellers.json file, and (ii) has at least one named client (i.e., at\nleast one non-confidential entry in their sellers.json file), and\n(iii)\ud835\udc4bis registered in another ad network \ud835\udc4cas aPUBLISHER , and (iv)\n\ud835\udc4bis registered in another ad network \ud835\udc4das an INTERMEDIARY . This\ninconsistent behavior might be credited to human error, or it might\nsuggest mischievous motives. There have been cases where middle-\nmen were mislabeled as publishers [ 52] (i.e., hidden intermediaries),\nand were working with popular disinformation websites without\nthe advertisers or the issuing ad network having any control [55].\nWe attempt to discover hidden intermediaries through the in-\nferred relationships from the collected sellers.json files. To in-\ncrease the confidence of our findings, we only retain \u201cverified\u201d ad\nnetworks. IAB Tech Lab\u2019s ads.txt crawler [ 42] contains a list of\npopular ad system domains that they take into consideration when\nprocessing ads.txt records. This step is necessary to increase con-\nfidence that entities are indeed ad brokers due to the discrepancies\nand deviation from the specification (Appendix E).\nWe discover 33 ad networks that have been falsely registered as\npublishers even though they are in fact middlemen, and simultane-\nously, represent hundreds or even thousands of actual publishers.\nFor example, we find that Smaato, a popular ad platform that man-\nages the ad inventory of over 1 thousand publishers, is a hidden\nintermediary. In the sellers.json files that keenkale.com ,lkqd.com\nandadingo.jp serve, Smaato is wrongfully presented as a publisher.\nThis is a major issue for brand safety since Smaato is able to receive\nbids through these ad networks as a publisher and either charge for\nhigher CPM, or obfuscate the ad chain. We illustrate in Figure 10\nthe top cases of verified hidden intermediaries. Kiosked displays the\nmost extraordinary behavior, hiding as a publisher in 67 other ad\nnetworks. Finally, we uncover that \u201cThe Publisher Desk\u201d, \u201cFreestar\u201d,\n\u201cAditude\u201d and \u201cNext millennium Network\u201d are all still hidden in-\ntermediaries even though they have attracted attention for exactly\nthis practice in the past [55].\nWe acknowledge that this behavior can arise from simple human\nerrors when forming the sellers.json file or when registering for\nan ad account. To address this, we investigate how the identifiers\nissued to hidden intermediaries are used. We find 1,860 cases where\nan ad network has registered as a publisher in a different ad network,\nwas issued an identifier and then distribute this DIRECT identifier\nto more than 10 websites. For instance, Kiosked, was registered\nas a publisher to yahoo.com and was issued the identifier 56848 .\nHowever, there are almost 1,500 websites (even popular ones) that\ndisclose this identifier as DIRECT in their ads.txt .\nTo decrease the possibility of a human-error when forming\nsellers.json files, we perform a temporal analysis and re-crawl\nthe same list of 2,600 domains with sellers.json files from Sec-\ntion 5.1 on July and October 2023 (Figure 10). We find that there are\n34 \u201cverified\u201d ad networks hiding as publishers in July 2023, rising\nto 37 in October 2023 (increased by 4 during the past 7 months).\nIntermediaries, who are registered as publishers the most, have\nWelcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\n 0 10 20 30 40 50 60 70\nGumGumSmaatoTaboolaConnatixPixFutureSonobiSortableAdyoulikeBrightcomKioskedNumber of ad networks in\nwhich it is misregistered2023-03\n2023-07\n2023-10\nFigure 10: Extreme cases of ad networks that masquerade as\npublishers in other ad systems.\nnot greatly changed their behavior over the period of 7 months.\nIn fact, there is a significant change only in the case of Kiosked.\nWe recognize that not all cases of hidden intermediaries suggest a\nmischievous motive or active attempts to commit fraud. However, it\nis evident that ad standards do not work. We highlight that not only\nis the ecosystem unable to provide transparency and confidence, it\nalso enables bad actors to abuse it [55].\n5.3 Indirect Clients\nA major issue with hidden intermediaries is that they manage the\nad inventory of many publishers, connecting them to advertisers\nwho mistakenly bid on their identifiers. This poses a risk as these\npublishers may not be vetted, leading advertisers to fund websites\nwith poor reputations or that violate regulations. We investigate\nthe clients of hidden intermediaries listed in sellers.json and\nfind that they manage the ad inventory of several questionable\nwebsites, including fake news and piracy sites, which advertisers\nlikely would want to avoid [6].\nInterestingly, we discover that RevContent, a popular ad system,\nis hiding as a publisher in other ad networks (e.g., mowplayer.com ),\nwhile at the same time managing the ad inventory of 33 distinct\nfake news websites. RevContent is popular among fake news web-\nsites [ 63] and fake news websites rely on RevContent to generate\nrevenue [ 35]. In total, we find 8 ad networks that manage at least 10\nfake news websites each. Similarly, we discover that reklamstore.com\nand automattic.com managing the ad inventory of 3 websites of\nour piracy list each. To make matters worse, we discover 4 hidden\nintermediaries, teads.tv ,nsightvideo.com ,monetizemore.com andad-\ncolony.com that have approved the monetization of 4 illegal websites\nthrough their ad platforms. These websites have been marked as\nillegal gambling sites by the Belgian Gaming Commission [ 15] and\nadvertisers wouldn\u2019t want to see their brand next to such content.\nIn total, we find that there are 167 fake news websites, 19 piracy\nwebsites and 4 illegal websites that are managed by hidden interme-\ndiaries. All these websites are clients of hidden intermediaries that\ncan charge higher CPM rates and forward ads to websites operated\nby unknown entities. This can have negative effects for both the\nadvertisers and the ad ecosystem. Advertisers have their reputation\nat risk if their brand name appears next to misinformation or illicit\ncontent, while on the other hand, the entire ad ecosystem is funding\nobjectionable content without anyone knowing.\nTo translate how these findings can damage the ad ecosystem,\nwe study these websites in terms of internet traffic. SimilarWeb [ 47]provides website traffic data for 181 websites whose ad inventory\ncan be catered by hidden intermediaries. Additionally, we extract\ntheir popularity rank from the Tranco list4. We find that the median\nwebsite is ranked 152K, while on average, these websites are ranked\njust below 400K and have 10M distinct visitors per month. Each\nvisitor accounts for 2.33 pages per visit and an average visit of 2:40\nminutes, resulting in multiple ad renders. We estimate that clients of\nhidden intermediaries generate an average yearly revenue of 36K$\nand that hidden intermediaries can cost advertisers 5.3M$ annually.\nWe provide a detailed description of this analysis in Appendix F.\n6 AdSparency Service\nTo enhance the transparency in the online advertising ecosystem,\nwe develop and publish AdSparency5: a Web monitoring service\nthat utilizes information extracted from ads.txt andsellers.json\nfiles, and enables (i) stakeholders (e.g., advertisers, DSPs, Web pub-\nlishers) to better understand where their money is funneled and\nwhat content they support, and (ii) policymakers (e.g., IAB, WFA)\nto better understand ad revenue flows and business relationships.\nSpecifically, this service periodically crawls millions of domains,\naggregates files served by different domains and analyzes the cor-\nresponding entries. Then, it (i) provides important statistical infor-\nmation about Identifier Pooling and Hidden Intermediaries, and (ii)\nprovides a collection of investigative tools. Specifically, AdSparency\nprovides tools to (i) lookup identifier pooling, (ii) detect hidden inter-\nmediaries, (iii) study website partnerships, and (iv) reveal business\nrelationships among publishers and ad networks. By crawling large\nsets of websites, this service can zoom out and reveal to marketers,\npublishers, and ad agencies the bigger picture: how publisher IDs\nare used and what relationships are formed between the various\nWeb entities in a global scale. We thoroughly describe the function-\nality and utility of AdSparency in Appendix G.\n7 Countermeasures\nIdentifier pooling: Publisher IDs are a mechanism used in vari-\nous steps of the ad-serving pipeline. We propose techniques that\ncan help tackle dark pooling from different vantage points. First,\nwe propose that ad networks properly review and vet their clients\nand ensure that the identifiers are used properly. Ad networks\nshould have specific policies regarding ad inventory pooling and\nnot allow third-party entities to issue or handle identifiers on their\nbehalf [ 86]. Additionally, ad networks should focus more on detect-\ning ad fraud [ 28] and flag or even demonetize domains that have\nbeen found to participate in dark pools. Such a behavior ensures\nthat objectionable websites will not be able to circumvent policies\nand get funded through advertisements. Moreover, we propose a\nmodification of ad-related Web standards. Specifically, we propose\na strict adherence to the DIRECT definition, where each DIRECT\nidentifier will now be strictly associated with a finite set of web-\nsites, operated by the same entity. This set of websites should be\nexplicitly and publicly stated in the sellers.json domain field.\nThis way, all ad entities can have a clear understanding of what\nwebsites are being funded by a specific direct identifier. We also\n4https://tranco-list.eu/list/5Y9NN/full\n5https://adsparency .ics .forth .gr/\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\nargue that there should be an upper limit on the number of web-\nsites that can be associated with a DIRECT identifier. An unlimited\nnumber of websites would defeat the purpose and result in similar\nproblems as with the current state of the ad ecosystem. Finally, we\nbelieve AdSparency can help stakeholders gain insights on how\nwebsites are interconnected and where advertiser money could end\nup and enable work towards a more transparent ecosystem.\nHidden Intermediaries: Intermediaries can abuse the ecosystem\nif they are able to disguise themselves as publishers. The most\neffective countermeasure is for other ad networks to strictly review\ntheir clients and ensure that their identifiers are used in compliance\nwith the standard. Independent evaluation of the domains found\ninsellers.json files can also lead to the detection of hidden\nintermediaries [ 55]. AdSparency can help towards this direction.\nFinally, the main issue of hidden intermediaries is that there is no\nclear understanding of where advertiser money is directed to, who\nbenefits from this revenue and to what extent. We urge towards a\nmore transparent ecosystem and propose that ad networks strictly\nadhere to the ads.txt andsellers.json standards and that they\navoid using the confidentiality flag in sellers.json files unless\nstrictly necessary. At the very least, we argue that the domain that\nhas registered for an identifier should be a mandatory field and\nalways be visible. We support IAB Tech Lab\u2019s work towards new\nversions of ad standards that explicitly disclose who owns and who\nmanages ad inventory [ 39]. Such modifications can reveal the true\nrelationships between ad entities and stop the need for hidden\nintermediaries. Additionally, we argue that ad exchanges should\nonly accept ad networks with a valid sellers.json file.\n8 Related Work\nThe advertising ecosystem has been thoroughly investigated includ-\ning the cost of rendered ads [ 64], the advertising value of users [ 59]\nand how advertisers are paired with publishers [ 49]. In [ 5], authors\nperformed a study of ads.txt files standard and its adoption dur-\ning a 15-month period and found violations of the standard, and\nthat they are not fully integrated in the ad ecosystem. In [ 30], the\nauthors studied the advertising ecosystem and Google services and\nfocused on how revenue is generated across aggregators. In [ 86], au-\nthors studied the prevalence of dark pooling. They utilized ads.txt\nandsellers.json files to show how misinformation websites are\nable to deceptively monetize their content and how dark pooling\ncircumvents brand safety. Similar to our work, they find that misin-\nformation websites use dark pooling to abuse the ecosystem and\nmonetize their content. Contrary to this paper, their study is limited\nto a smaller number of websites and significantly underestimates\nthe prevalence of the problem by more than an order of magnitude.\nThe research community has dedicated significant effort to dis-\ncover, study and mitigate ad fraud [ 3]. Bad actors have devised var-\nious ad fraud techniques, including \u201cClick-Jacking\u201d [ 2,20,29,88]\nor content injection [ 75,83]. In [ 51], authors demonstrated an ad\nfraud attack where malicious publishers pollute the profile of vis-\nitors, compelling advertisers to pay more to reach users. Popular\nonline platforms have been used to either serve political ads that by-\npass policies [ 67] or even to generate ad revenue from copyrighted\ncontent [ 13]. Similarly, in [ 50], authors demonstrated that not all\nonline video platforms are able to discover ad fraud. In [ 77], authorsestablished how automated farms of real smartphone devices can\nbe used to commit ad fraud and generate substantial revenue, while\nin [89], authors studied ad fraud on Android applications focusing\non fake click actions. In [ 46], authors explored ad fraud attacks that\ncan take place in WebVR applications.\nIn [4], the authors discussed how the lack of understanding and\ncontrol advertisers have regarding where their ads appear, enables\nfake news websites to generate revenue. In [ 63], authors utilized\nads.txt andsellers.json files to reveal the business relation-\nships between fake news websites and ad networks, showing that\npopular ad networks inadvertently facilitate the proliferation of\nfake news content. In [ 87], the authors studied problematic ads and\ntheir prevalence across news and misinformation websites, as well\nas the ad platforms that serve them. In [ 7], authors explored the\nadvertising market and found that even though fake news publish-\ners interact with fewer ad servers, they still rely on credible ones\nto monetize their traffic. Similar results were found in [ 35], where\nthe authors studied how Web infrastructure supports misinforma-\ntion and hate speech websites. In [ 61], the authors studied a novel\ntechnique that bad actors deploy to mislead advertisers into paying\nfor ads next to pirated or illicit content. Finally, various works have\nstudied how the quality of content can affect the brand reputation\nof advertisers [6, 73].\n9 Discussion & Conclusion\nDue to the complex and often opaque supply chains, and the big\nnumber of intermediaries who benefit from inflated ad traffic, it is\napparent that digital advertising constitutes a very vulnerable and\nlucrative opportunity for bad actors. In this work, we present and\nstudy the mechanisms that bad actors deploy in order to bypass\nrestrictions policies of ad networks. We show how publishers of\nwebsites with questionable or even illegal content are able to in-\ncrease their ad revenue by pooling their ad identifiers together with\nthe ones of reputable websites. We also study the sellers.json\nstandard and show that not only it is not properly used on the Web,\nbut also that some intermediary ad brokers abuse it in order to\nmasquerade as publishers and make money from ads that they then\npush towards objectionable websites.\nThe primary takeaway from the work is that the lack of trans-\nparency in the online advertising ecosystem creates significant\nopportunities for bad actors to exploit vulnerabilities, leading to\nsubstantial ad revenue misdirection and brand safety risks. We\ndemonstrate that current ad standards are not enough to protect\nthe ad ecosystem. Currently, the ads.txt andsellers.json stan-\ndards are not legally mandated, but stakeholders follow them to\nprotect revenue, attract quality advertisers, and maintain their rep-\nutation. We hope this research and broader academic efforts will\nencourage regulatory action, similar to the EU\u2019s GDPR and DSA.\nSuch regulations could prohibit ad networks from working with\nwebsites with invalid ads.txt files and hold them accountable for\nidentifier pooling. Until then, we suggest modifying these standards\nto deal with current exploitations.\nAcknowledgments\nThe work was supported by the Foundation for Research and Tech-\nnology Hellas through grant DPA ESO00178.\nWelcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nReferences\n[1]Adalytics. 2023. Are Google\u2019s ad exchange & Fortune 500 advertisers working\nwith Treasury sanctioned websites in Russia, Iran, & Syria? https://adalytics .io/\nblog/adtech-sanctions.\n[2]Devdatta Akhawe, Warren He, Zhiwei Li, Reza Moazzezi, and Dawn Song. 2014.\nClickjacking revisited: A perceptual view of UI security. In 8th USENIX Workshop\non Offensive Technologies (WOOT 14) .\n[3]Jamil R Alzghoul, Emad E Abdallah, and Abdel-hafiz S Al-khawaldeh. 2022. Fraud\nin Online Classified Ads: Strategies, Risks, and Detection Methods: A Survey.\nJournal of Applied Security Research (2022), 1\u201325.\n[4]Vian Bakir and Andrew McStay. 2018. Fake news and the economy of emotions:\nProblems, causes, solutions. Digital journalism 6, 2 (2018), 154\u2013175.\n[5]Muhammad Ahmad Bashir, Sajjad Arshad, Engin Kirda, William Robertson,\nand Christo Wilson. 2019. A Longitudinal Analysis of the ads. txt Standard. In\nProceedings of the Internet Measurement Conference . 294\u2013307.\n[6]Steven Bellman, Ziad HS Abdelmoety, Jamie Murphy, Shruthi Arismendez, and\nDuane Varan. 2018. Brand safety: the effects of controversial video content on\npre-roll advertising. Heliyon 4, 12 (2018), e01041.\n[7]Lia Bozarth and Ceren Budak. 2021. Market Forces: Quantifying the Role of Top\nCredible Ad Servers in the Fake News Ecosystem.. In ICWSM . 83\u201394.\n[8]Frank Cangialosi, Taejoong Chung, David Choffnes, Dave Levin, Bruce M. Maggs,\nAlan Mislove, and Christo Wilson. 2016. Measurement and Analysis of Private\nKey Sharing in the HTTPS Ecosystem. In Proceedings of the 2016 ACM SIGSAC\nConference on Computer and Communications Security (Vienna, Austria) (CCS\n\u201916). Association for Computing Machinery, New York, NY, USA, 628\u2013640. https:\n//doi .org/10 .1145/2976749 .2978301\n[9]Google Help Center. 2022. Exclude specific webpages and videos. https:\n//support .google .com/google-ads/answer/2454012.\n[10] Media Bias/Fact Check. 2022. Search and Learn the Bias of News Media. https:\n//mediabiasfactcheck .com/.\n[11] Media Bias/Fact Check. 2023. GB News UK \u2013 Bias and Credibility. https://\nmediabiasfactcheck .com/gb-news-uk-bias/.\n[12] Media Bias/Fact Check. 2023. New Scientist \u2013 Bias and Credibility. https://\nmediabiasfactcheck .com/new-scientist/.\n[13] Andrew Chu, Arjun Arunasalam, Muslum Ozgur Ozmen, and Z Berkay Celik.\n2022. Behind the Tube: Exploitative Monetization of Content on YouTube. In\n31st USENIX Security Symposium (USENIX Security 22) . USENIX Association,\nBoston, MA, 2171\u20132188. https://www .usenix .org/conference/usenixsecurity22/\npresentation/chu\n[14] Credibility Coalition. 2021. Examining Opaque Programmatic Markets with the\nCredibility Coalition AdSellers Dataset. https://misinfocon .com/examining-\nopaque-programmatic-markets-with-the-credibility-coalition-adsellers-\ndataset-b9ff5d6781c4.\n[15] The Gaming Commission. 2023. The regulator of the gambling sector in Belgium.\nhttps://www .gamingcommission .be/en.\n[16] ConversantMedia. 2023. sellers.json. https://cpe .conversantmedia .com/assets/\nsellers/sellers .json.\n[17] Robert Cookson. 2016. Jihadi website with beheadings profited from Google ad\nplatform. https://www .ft.com/content/b06d18c0-1bfb-11e6-8fa5-44094f6d9c46/.\n[18] Ethan Cramer-Flood. 2022. Worldwide Ad Spending 2022. https://\nwww .insiderintelligence .com/content/worldwide-ad-spending-2022/.\n[19] Leslie Daigle. 2004. WHOIS Protocol Specification. http://www .ietf .org/rfc/\nrfc3912 .txt.\n[20] Vacha Dave, Saikat Guha, and Yin Zhang. 2013. ViceROI: Catching Click-Spam\nin Search Ad Networks. In Proceedings of the 2013 ACM SIGSAC Conference on\nComputer & Communications Security (Berlin, Germany) (CCS \u201913) . Association\nfor Computing Machinery, New York, NY, USA, 765\u2013776. https://doi .org/10 .1145/\n2508859 .2516688\n[21] Zach Edwards. 2020. Breitbart.com is Partnering with RT.com & Other Sites via\nMislabeled Advertising Inventory. https://medium .com/@thezedwards/breitbart-\ncom-is-partnering-with-rt-com-other-sites-via-mislabeled-advertising-\ninventory-6e7e3b5c3318.\n[22] John Ellis. 2018. Dear Google: Please stop using my advertising dollars to mon-\netize hate speech. https://qz .com/1177168/dear-google-please-stop-using-my-\nadvertising-dollars-to-monetize-hate-speech/.\n[23] Facebook Inc. 2019. Understand Why You\u2019re Seeing Certain Ads and How You\nCan Adjust Your Ad Experience. https://about .fb.com/news/2019/07/understand-\nwhy-youre-seeing-ads/.\n[24] Isa Soares Florence Davey-Attlee. 2017. The Fake news Machine: INSIDE A\nTOWN GEARING UP FOR 2020. https://money .cnn .com/interactive/media/the-\nmacedonia-story/.\n[25] Augustine Fou. 2020. Ads.txt The IAB\u2019s Magic Bullet That Wasn\u2019t Magi-\ncal. https://www .forbes .com/sites/augustinefou/2020/08/08/adstxt-the-iabs-\nmagic-bullet-that-wasnt-magical/.\n[26] Augustine Fou. 2020. The Cost-Performance Paradox Of Modern Digital\nMarketing. https://www .forbes .com/sites/augustinefou/2020/08/18/the-cost-\nperformance-paradox-of-modern-digital-marketing/.[27] Augustine Fou. 2020. Dark Pooling At-Scale With IAB\u2019s Ads.txt Proto-\ncol. https://www .forbes .com/sites/augustinefou/2020/11/25/dark-pooling-at-\nscale-with-iabs-adstxt-protocol/.\n[28] Augustine Fou. 2023. How bad guys get around blocks and avoid detection.\nhttps://www .linkedin .com/pulse/how-bad-guys-get-around-blocks-avoid-\ndetection-dr-augustine-fou-fqyoe?trk =article-ssr-frontend-pulse_more-\narticles_related-content-card.\n[29] Mona Gandhi, Markus Jakobsson, and Jacob Ratkiewicz. 2006. Badvertisements:\nStealthy click-fraud with unwitting accessories. Journal of Digital Forensic Practice\n1, 2 (2006), 131\u2013142.\n[30] Phillipa Gill, Vijay Erramilli, Augustin Chaintreau, Balachander Krishnamurthy,\nKonstantina Papagiannaki, and Pablo Rodriguez. 2013. Best Paper \u2013 Follow the\nMoney: Understanding Economics of Online Aggregation and Advertising. In\nProceedings of the 2013 Conference on Internet Measurement Conference (Barcelona,\nSpain) (IMC \u201913) . Association for Computing Machinery, New York, NY, USA,\n141\u2013148. https://doi .org/10 .1145/2504730 .2504768\n[31] Google. 2023. Certified Publishing Partner. https://www .google .com/ads/\npublisher/partners/.\n[32] Google. 2023. Identifying sellers through Sellers.json. https:\n//support .google .com/authorizedbuyers/answer/9895942.\n[33] Google. 2023. Multiple Customer Management. https://support .google .com/\nadmob/answer/9142605?hl =en.\n[34] Google. 2024. See how much you could earn from AdSense. https://\nadsense .google .com/intl/en_us/start/#calculator.\n[35] Catherine Han, Deepak Kumar, and Zakir Durumeric. 2022. On the Infrastructure\nProviders That Support Misinformation Websites. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media , Vol. 16. 287\u2013298.\n[36] Interactive Advertising Bureau (IAB). 2023. The Transparency & Consent Frame-\nwork (TCF) v2.2. https://iabeurope .eu/transparency-consent-framework/.\n[37] Erin Kenneally and David Dittrich. 2012. The menlo report: Ethical principles\nguiding information and communication technology research. Available at SSRN\n2445102 (2012).\n[38] Tami Kim, Kate Barasz, and Leslie K John. 2018. Why Am I Seeing This\nAd? The Effect of Ad Transparency on Ad Effectiveness. Journal of Con-\nsumer Research 45, 5 (05 2018), 906\u2013932. https://doi .org/10 .1093/jcr/ucy039\narXiv:https://academic.oup.com/jcr/article-pdf/45/5/906/50265325/ucy039.pdf\n[39] IAB Tech Lab. 2022. IAB Tech Lab Adds Ads.Txt Values To Help Buyers\nDetermine The Owner And Manager Of Inventory. https://iabtechlab .com/press-\nreleases/iab-tech-lab-ads-txt-values-to-help-buyers-determine-owner-\nmanager-of-inventory/.\n[40] IAB Tech Lab. 2023. About Ads.Txt. https://iabtechlab .com/ads-txt-about/.\n[41] IAB Technology Laboratory. 2019. sellers.json Specification. https://\niabtechlab .com/wp-content/uploads/2019/07/Sellers .json_Final .pdf.\n[42] IAB Technology Laboratory. 2020. ads.txt Crawler. https://github .com/\nInteractiveAdvertisingBureau/adstxtcrawler.\n[43] IAB Technology Laboratory. 2022. ads.txt Specification Version 1.1. https://\niabtechlab .com/wp-content/uploads/2022/04/Ads .txt-1 .1.pdf.\n[44] Victor Le Pochat, Tom Van Goethem, Samaneh Tajalizadehkhoob, Maciej Ko-\nrczy\u0144ski, and Wouter Joosen. 2019. Tranco: A Research-Oriented Top Sites\nRanking Hardened Against Manipulation. In Network and Distributed System\nSecurity Symposium (NDSS \u201921) .\n[45] Sara Lebow. 2023. Worldwide digital ad spend will top $600 billion this\nyear. https://www .insiderintelligence .com/content/worldwide-digital-ad-spend-\nwill-top-600-billion-this-year.\n[46] Hyunjoo Lee, Jiyeon Lee, Daejun Kim, Suman Jana, Insik Shin, and Sooel Son. 2021.\nAdCube: WebVR Ad Fraud and Practical Confinement of Third-Party Ads. In 30th\nUSENIX Security Symposium (USENIX Security 21) . USENIX Association, 2543\u2013\n2560. https://www .usenix .org/conference/usenixsecurity21/presentation/lee-\nhyunjoo\n[47] Similarweb LTD. 2023. Website Traffic - Check and Analyze Any Website. https:\n//www .similarweb .com/.\n[48] Chaoyi Lu, Baojun Liu, Yiming Zhang, Zhou Li, Fenglu Zhang, Haixin Duan,\nYing Liu, Joann Qiongna Chen, Jinjin Liang, Zaifeng Zhang, et al .2021. From\nWHOIS to WHOWAS: A Large-Scale Measurement Study of Domain Registration\nPrivacy under the GDPR. In NDSS .\n[49] Wenrui Ma and Haitao Xu. 2021. A study of the partnership between advertisers\nand publishers. In Passive and Active Measurement: 22nd International Conference,\nPAM 2021, Virtual Event, March 29\u2013April 1, 2021, Proceedings 22 . Springer, 564\u2013580.\n[50] Miriam Marciel, Rub\u00e9n Cuevas, Albert Banchs, Roberto Gonz\u00e1lez, Stefano\nTraverso, Mohamed Ahmed, and Arturo Azcorra. 2016. Understanding the detec-\ntion of view fraud in video content portals. In Proceedings of the 25th International\nConference on World Wide Web . 357\u2013368.\n[51] Wei Meng, Xinyu Xing, Anmol Sheth, Udi Weinsberg, and Wenke Lee. 2014. Your\nOnline Interests: Pwned! A Pollution Attack Against Targeted Advertising. In\nProceedings of the 2014 ACM SIGSAC Conference on Computer and Communications\nSecurity (Scottsdale, Arizona, USA) (CCS \u201914) . Association for Computing Ma-\nchinery, New York, NY, USA, 129\u2013140. https://doi .org/10 .1145/2660267 .2687258\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\n[52] Rocky Moss. 2021. Evaluating the Ecosystem: What We\u2019ve Learned by Match-\ning Ads.txt Entries to Sellers.json Files. https://deepsee .io/blog/evaluating-the-\necosystem.\n[53] Rocky Moss. 2021. Further Investigation Into the \u201cDark Pool Sales House\u201d Phe-\nnomenon. https://deepsee .io/blog/non-unique-pub-ids.\n[54] Rocky Moss and Antonio Torres. 2021. A Case Study in Monetizing Piracy: Man-\ngaOwl and Chessmoba.us. https://deepsee .io/blog/a-case-study-in-monetizing-\npiracy.\n[55] Jammi Nandini and Claire Atkin. 2021. Kargo\u2019s \"no fake news\" guarantee is fake\nnews. https://checkmyads .org/branded/kargos-no-fake-news-guarantee-is/.\n[56] NextDNS. 2022. Piracy Blocklists. https://github .com/nextdns/piracy-blocklists.\n[57] World Federation of Advertisers. 2018. WFA statement on the \u20193ve\u2019 ad\nfraud schemes takedown. https://wfanet .org/knowledge/item/2018/11/28/WFA-\nstatement-on-the-3ve-ad-fraud-schemes-takedown.\n[58] Incorporated Society of British Advertisers. 2020. Programmatic Supply\nChain Transparency Study. https://www .isba .org .uk/system/files?file =\nmedia%2Fdocuments%2F2020-12%2Fexecutive-summary-programmatic-\nsupply-chain-transparency-study .pdf.\n[59] Michalis Pachilakis, Panagiotis Papadopoulos, Nikolaos Laoutaris, Evangelos P.\nMarkatos, and Nicolas Kourtellis. 2022. YourAdvalue: Measuring Advertising\nPrice Dynamics without Bankrupting User Privacy. In Abstract Proceedings of the\n2022 ACM SIGMETRICS/IFIP PERFORMANCE Joint International Conference on\nMeasurement and Modeling of Computer Systems (Mumbai, India) (SIGMETRIC-\nS/PERFORMANCE \u201922) . Association for Computing Machinery, New York, NY,\nUSA, 41\u201342. https://doi .org/10 .1145/3489048 .3522629\n[60] Emmanouil Papadogiannakis. 2025. Open-Source Data and Source Code. https:\n//gitlab .com/papamano/welcome-to-the-dark-side.\n[61] Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos P. Markatos,\nand Nicolas Kourtellis. 2024. Ad Laundering: How Websites Deceive Advertisers\ninto Rendering Ads Next to Illicit Content. In Companion Proceedings of the ACM\non Web Conference 2024 (Singapore) (WWW \u201924) . Association for Computing Ma-\nchinery, New York, NY, USA, 782\u2013785. https://doi .org/10 .1145/3589335 .3651466\n[62] Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos P. Markatos,\nand Nicolas Kourtellis. 2022. Leveraging Google\u2019s Publisher-Specific IDs to Detect\nWebsite Administration. In Proceedings of the ACM Web Conference 2022 (Virtual\nEvent, Lyon, France) (WWW \u201922) . Association for Computing Machinery, New\nYork, NY, USA, 2522\u20132531. https://doi .org/10 .1145/3485447 .3512124\n[63] Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos P. Markatos,\nand Nicolas Kourtellis. 2023. Who Funds Misinformation? A Systematic Anal-\nysis of the Ad-related Profit Routines of Fake News sites. In Proceedings of the\nACM Web Conference 2023 (Austin, TX, USA) (WWW \u201923) . Association for Com-\nputing Machinery, New York, NY, USA, 2765\u20132776. https://doi .org/10 .1145/\n3543507 .3583443\n[64] Panagiotis Papadopoulos, Nicolas Kourtellis, Pablo Rodriguez Rodriguez, and\nNikolaos Laoutaris. 2017. If You Are Not Paying for It, You Are the Product:\nHow Much Do Advertisers Pay to Reach You?. In Proceedings of the 2017 Internet\nMeasurement Conference (London, United Kingdom) (IMC \u201917) . Association for\nComputing Machinery, New York, NY, USA, 142\u2013156. https://doi .org/10 .1145/\n3131365 .3131397\n[65] Antonio Pastor, Rub\u00e9n Cuevas, \u00c1ngel Cuevas, and Arturo Azcorra. 2021. Estab-\nlishing Trust in Online Advertising With Signed Transactions. IEEE Access 9\n(2021), 2401\u20132414. https://doi .org/10 .1109/ACCESS .2020 .3047343\n[66] Pixalate. 2017. Buyers are asking to be added to ads.txt files, and some publishers\nare doing it. https://www .pixalate .com/blog/ads-txt-thrive-plus-publisher-list.\n[67] Victor Le Pochat, Laura Edelson, Tom Van Goethem, Wouter Joosen, Damon\nMcCoy, and Tobias Lauinger. 2022. An Audit of Facebook\u2019s Political Ad Pol-\nicy Enforcement. In 31st USENIX Security Symposium (USENIX Security 22) .\nUSENIX Association, Boston, MA, 607\u2013624. https://www .usenix .org/conference/\nusenixsecurity22/presentation/lepochat\n[68] Reddit. 2017. Partners who give you long lists of entries that should be added\nto your ads.txt file. https://www .reddit .com/r/adops/comments/7k1lxl/adstxt_\nquestion/.\n[69] Reddit. 2018. Ads.txt Is Already A Complete Joke, Look At What RevContent\nRequires Publishers To Put Up. https://www .reddit .com/r/adops/comments/\n9uzv9r/adstxt_is_already_a_complete_joke_look_at_what/.\n[70] Caitlin M. Rivers and Bryan L. Lewis. 2014. Ethical research standards in a world\nof big. F1000Research 3 (2014). Issue 38. https://doi .org/10 .12688/f1000research .3-\n38.v2\n[71] Richard Roberts, Yaelle Goldschlag, Rachel Walter, Taejoong Chung, Alan Mislove,\nand Dave Levin. 2019. You Are Who You Appear to Be: A Longitudinal Study\nof Domain Impersonation in TLS Certificates. In Proceedings of the 2019 ACM\nSIGSAC Conference on Computer and Communications Security (London, United\nKingdom) (CCS \u201919) . Association for Computing Machinery, New York, NY, USA,\n2489\u20132504. https://doi .org/10 .1145/3319535 .3363188\n[72] Aksana Shakal. 2024. What is Tiers in affiliate marketing. https://richads .com/\nblog/what-is/tier-1-countries/.\n[73] Edlira Shehu, Nadia Abou Nabout, and Michel Clement. 2021. The risk of pro-\ngrammatic advertising: Effects of website quality on advertising effectiveness.International Journal of Research in Marketing 38, 3 (2021), 663\u2013677.\n[74] Sarah Sluis. 2017. Knock-Knock: How Companies Are Trying To Weasel Their\nWay Onto Publishers\u2019 Ads.txt Files. https://www .adexchanger .com/publishers/\nknock-knock-companies-trying-weasel-way-onto-publishers-ads-txt-files/.\n[75] Kevin Springborn and Paul Barford. 2013. Impression Fraud in On-line Advertis-\ning via Pay-Per-View Networks.. In USENIX Security Symposium . 211\u2013226.\n[76] Statista. 2023. Estimated cost of digital ad fraud worldwide from 2018 to 2023.\nhttps://www .statista .com/statistics/677466/digital-ad-fraud-cost/.\n[77] Suibin Sun, Le Yu, Xiaokuan Zhang, Minhui Xue, Ren Zhou, Haojin Zhu, Shuang\nHao, and Xiaodong Lin. 2021. Understanding and Detecting Mobile Ad Fraud\nThrough the Lens of Invalid Traffic. In Proceedings of the 2021 ACM SIGSAC\nConference on Computer and Communications Security (Virtual Event, Republic\nof Korea) (CCS \u201921) . Association for Computing Machinery, New York, NY, USA,\n287\u2013303. https://doi .org/10 .1145/3460120 .3484547\n[78] Joe Tacopino. 2017. Mercedes-Benz, Honda among companies with ads on\njihadist websites. https://nypost .com/2017/02/09/mercedes-benz-honda-among-\ncompanies-with-ads-on-jihadist-websites/.\n[79] Magnite Team. 2020. On Content Standards. https://www .magnite .com/blog/on-\ncontent-standards/.\n[80] Team ClickGUARD. 2023. 2023 Global Ad & PPC \u2013 Click Fraud Statistics (Updated.\nhttps://www .statista .com/statistics/677466/digital-ad-fraud-cost/.\n[81] The European Partnership for Democracy. 2023. Virtual Insanity? Transparency\nin digital political advertising. https://epd .eu/virtual-insanity/.\n[82] Think with Google. 2014. 5 factors of viewability. https://\nthink .storage .googleapis .com/docs/5-factors-of-viewability_infographics .pdf.\n[83] Kurt Thomas, Elie Bursztein, Chris Grier, Grant Ho, Nav Jagpal, Alexandros\nKapravelos, Damon McCoy, Antonio Nappa, Vern Paxson, Paul Pearce, et al .2015.\nAd injection at scale: Assessing deceptive advertisement modifications. In 2015\nIEEE Symposium on Security and Privacy . IEEE, 151\u2013167.\n[84] Sam Tingleff. 2019. THE THREE DEADLY SINS OF ADS.TXT AND HOW PUB-\nLISHERS CAN AVOID THEM. https://iabtechlab .com/blog/the-three-deadly-\nsins-of-ads-txt-and-how-publishers-can-avoid-them/.\n[85] Joe Toscano. 2023. Google\u2019s Ad Scam Eerily Similar To Facebook\u2019s Metric Inflation\nScam. https://www .forbes .com/sites/joetoscano1/2023/06/28/googles-ad-scam-\neerily-similar-to-facebooks-metric-inflation-scam/.\n[86] Yash Vekaria, Rishab Nithyanand, and Zubair Shafiq. 2022. The Inventory is Dark\nand Full of Misinformation: Understanding the Abuse of Ad Inventory Pooling\nin the Ad-Tech Supply Chain. arXiv preprint arXiv:2210.06654 (2022).\n[87] Eric Zeng, Tadayoshi Kohno, and Franziska Roesner. 2020. Bad news: Click-\nbait and deceptive ads on news and misinformation websites. In Workshop on\nTechnology and Consumer Protection .\n[88] Mingxue Zhang, Wei Meng, Sangho Lee, Byoungyoung Lee, and Xinyu Xing.\n2019. All Your Clicks Belong to Me: Investigating Click Interception on the Web.\nInUSENIX Security Symposium . 941\u2013957.\n[89] Tong Zhu, Yan Meng, Haotian Hu, Xiaokuan Zhang, Minhui Xue, and Haojin\nZhu. 2021. Dissecting Click Fraud Autonomy in the Wild. In Proceedings of the\n2021 ACM SIGSAC Conference on Computer and Communications Security (Virtual\nEvent, Republic of Korea) (CCS \u201921) . Association for Computing Machinery, New\nYork, NY, USA, 271\u2013286. https://doi .org/10 .1145/3460120 .3484546\nA Data & Code Availability\nTo support and enable further research and the extensibility of our\nwork, we make publicly available [60]:\n(1)Extensive lists of misinformation websites and websites as-\nsociated with pirated content.\n(2) List of keywords indicating private WHOIS records.\n(3)Source code of crawling tools for ads.txt andsellers.json\nfiles.\nB Ethical Considerations\nThis work has followed the principles and guidelines of how to\nperform ethical information research [ 37,70]. In accordance to the\nGDPR and ePrivacy regulations, we do not engage in collection\nof data from real users, neither do we share with other entities\nany data collected by our crawler. We only collect and analyze\ninformation served intentionally by Web entities and is designed\nto be collected in a programmatic fashion according to the spec-\nifications [ 41,43]. Concerning the analysis of Sections 4 and 5,\nwe minimize our intervention on the ecosystem by designing our\nWelcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nIssuing Ad Identifier Issued To Number of\nNetwork Websites\nconversantmedia.com 100141 33Across 42,412\nvi.ai 987349031605160 OutBrain 41,044\nadform.com 1942 Rich Audience 40,702\nTechnologies SL\nonetag.com 5d4e109247a89f6 ConnectAd Demand 40,660\nlijit.com 244287 ConnectAd Realtime 40,587\nindexexchange.com 190906 ConnectAd Realtime 40,061\nTable 1: DIRECT identifiers used in numerous websites.\ncrawlers to be as unintrusive as possible. We contact each domain\nand only issue a single HTTP(S) request to fetch either the ads.txt\nor the sellers.json file. Additionally, the collection of ads.txt\nandsellers.json files was done in separate periods of time, en-\nsuring that we only reach each domain once per month. Finally,\neven though we study the advertising ecosystem, we do not inter-\nact with ads displayed in websites in any way, thus not depleting\nadvertiser budgets.\nC Ads.txt Specification Violation\nFurther studying ads.txt records reveals that not all entities re-\nspect the ads.txt specification. We discover that there are multiple\nad networks that consistently re-use the same DIRECT identifier\nacross thousands of websites. Each adtarget.com.br identifier is\nused in 4,249 websites on average. Similarly, each DIRECT iden-\ntifier issued by reforge.in oradriver.ru is used in over 2,000 web-\nsites on average. These findings support our hypothesis that the\nads.txt standard is not properly implemented. DIRECT identifiers\nare shared across unrelated websites, thus ruining the ecosystem\u2019s\ntransparency. Most importantly, the DIRECT identifier 100141 is-\nsued by conversantmedia.com is found in 42,412 distinct websites.\nADIRECT identifier should indicate that the content owner (i.e.,\npublisher) directly controls the advertising account [ 43] but it\nseems extremely improbable that one single publisher manages\nthe content of over 42 thousand websites. ConversantMedia ex-\nplicitly states [ 16] that this identifier belongs to the ad network\n33Across and that it is in fact an intermediary. However, even popu-\nlar websites such as WikiHow and IGN list it as direct. The DIRECT\nrelationship indicates that the website publisher directly controls\nthe account and has a direct business contract with the ad network.\nThe fact that the majority of DIRECT identifiers are used to form\nvery large pools is an indication that identifiers are wrongly labeled.\nIt is important to notice that the blame for such behavior does\nnot always fall to the publishers themselves. It seems implausible\nthat over 42,000 website administrators conferred with each other\nand reached an agreement about how to use the identifier. Similar\nbehavior is observed for multiple other publisher IDs, as shown\nin Table 1. Closer inspection of these identifiers reveals that even\nthough they are labeled and used as DIRECT , they have been issued\nto media companies (i.e., resellers). For example, vi.ai clearly states\nthat the identifier 987349031605160 was issued to an intermediary,\nbut we find that publishers claim it as their own (i.e., DIRECT ).\nAltogether, there are strong indications that there are multiple ad\nresellers that provide their own direct identifiers to their clients,\nhaving them mark them as DIRECT . It is evident that ad networks\nplay an important role in identifier pooling. Not only some of\nthem facilitate pooling (Figures 3 and 4), but some resellers also\ndeliberately mislabel the ad inventory of their client publishers andabuse the ecosystem in an effort to increase their profits [ 21]. Rich\nAudience Technologies, which controls one of the largest dark pools\n(Table 1), has been promoting such bad practices for years [ 14,53].\nD Pooling of Conflicting Ad Inventory\nWe discover a pool of 14 websites sharing the same publisher ID\n(pub-3176064900167527 ) issued by Google in their ads.txt files.\nOf these, 3 websites ( sputniknews.com ,ria.ru andsnanews.de ) are\nlabeled as questionable by MediaBias/FactCheck due to poor sourc-\ning and multiple failed fact checks, contributing to misinforma-\ntion. These misinformation websites would most definitely not\nget approved by Google, but they can use the issued identifier to\nbypass blocklists and to receive ads even from very respectable\nwebsites [ 27]. Additionally, we discover that inosmi.ru , another\nnews website, is part of the same pool, uses the same identifier, and\naccording to SimilarWeb, achieves over 14 million monthly visits.\nGoogle\u2019s revenue calculator [ 34] estimates that such a website can\nhave an annual revenue of several hundred thousand dollars. It is ev-\nident that this revenue, even if split across 14 publishers (worst-case\nexample), is a substantial income for these publishers. The revenue\nthat inosmi.ru generates indirectly facilitates the proliferation of\nfake news content and advertisers that appear on a legitimate news\nwebsite, inadvertently support misinformation.\nWe also discover that the websites newscientist.com ,gbnews.com\nandgbnews.uk all disclose 2 distinct identifiers issued by SpotX.tv\nand Sovrn as DIRECT . This suggests that these websites have two\nshared ad revenue wallets (i.e., accounts that collect ad revenue).\nAdditionally, these websites seem to be unrelated and operated by\ndifferent entities. They disclose a different registered office address\nand a different company number in their websites\u2019 terms. Conse-\nquently, they form \u201cdark pools\u201d. GB News UK has been marked as a\n\u201cconspiracy theory\u201d, \u201cpseudoscience\u201d and \u201cpropaganda\u201d news source\nby MBFC since it has almost 10 failed fact checks [ 11] (almost all\nof them are related to COVID-19). On the other hand, we discover\nthat New Scientist is a pro-science website with very high factual\nreporting and high credibility [ 12]. By sharing a direct publisher ID,\nany ads that are rendered on these websites through this identifier\nwill result in revenue being aggregated to the same account. To\nmake matters worse, GB News can use the shared ID to directly re-\nceive ads from all sorts of brands, even popular ones. Even if this is\ndone without the website administrators being aware (e.g., through\nthe facilitation of ad networks [ 33,86]), advertisers unintentionally\nhave their money support a misinformation website.\nE Sellers.json Specification Violation\nE.1 Misrepresentation\nThe sellers.json standard is complementary to the ads.txt\nstandard, and together, they increase the transparency of the ecosys-\ntem and enable entities to discover the identity of ad inventory sell-\ners. In order for this to work, publishers\u2019 ads.txt files need to list\nthe ad systems they have authorized to serve ads on their websites,\nand ad systems need to publish a sellers.json file that confirms\nthat they have reviewed the website. As already discussed, various\nintermediaries might want to hide the actual type of their contract\nwith an ad network. We study the types of seller accounts declared\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\n{\n  \"domain\": \" facebook.com \",\n  \"is_confidential\": 0,\n  \"name\": \" malik\",\n  \"seller_id\": \"614c165d57a...\",\n  \"seller_type\": \" PUBLISHER \"\n}\n{\n  \"domain\": \" facebook.com \",\n  \"is_confidential\": 0,\n  \"name\": \" aliana\",\n  \"seller_id\": \"3648d3493...\",\n  \"seller_type\": \" PUBLISHER \"\n}{\n  \"domain\": \" facebook.com \",\n  \"is_confidential\": 0,\n  \"name\": \" la casa del \u00e1rbol \",\n  \"seller_id\": \"3df3a6197...\",\n  \"seller_type\": \" PUBLISHER \"\n}\n{\n  \"domain\": \" m.facebook.com \",\n  \"is_confidential\": 0,\n  \"name\": \" Barcelona \",\n  \"seller_id\": \"4ec7af59f4...\",\n  \"seller_type\": \" PUBLISHER \"\n}\nFigure 12: Snippets of the sellers.json file served by the ad\nnetwork adyoulike.com . There are multiple entries for the\nfacebook.com domain, all of which seem to be deceitful.\n 500 1000 1500 2000 2500 3000\nGoogleTripleliftOpenXIndexExchangeRubiconProjectPubmaticLijitTaboolaOnetagMedia.net# of issued identi\ufb01ers with\ninvalid type in ads.txt\nFigure 11: Number of identifiers that have been mistyped in\nads.txt files as a function of issuing ad systems.\ninads.txt andsellers.json files we have collected. When a pub-\nlisher identifier is listed as DIRECT in an ads.txt file, the respective\nsellers.json file of the ad network should list the same identi-\nfier as PUBLISHER [43]. Similarly, a RESELLER identifier in ads.txt\nshould be registered as INTERMEDIARY insellers.json .\nWe follow a graph-based approach to better understand and visu-\nalize the relationships between various domains. Specifically, every\nad network is represented as a node, and if there is a sellers.json\nentry indicating an authorized relationship, we introduce an edge\nconnecting the corresponding nodes. We analyze the collected\nads.txt andsellers.json files and find that there are over 26K\nidentifiers issued by 421 distinct advertising networks that have\nat least one relationship type mismatch. We detect cases of type\nmismatch even for popular ad networks, including Google, App-\nNexus, OpenX and IndexExchange. In Figure 11, we plot the number\nof identifiers with a type mismatch for popular ad networks. We\ndiscover that the problem of type mismatches is not unique to a net-\nwork, and that all of them suffer from it. Please note that for a type\nmismatch, both the ad network and the publisher might be at fault.\nSuch mismatches might derive from either a human error or from\na deliberate malicious action. To justify this opinion, we examine\nthe type mismatches from the publishers\u2019 perspective. We find that\nthere are numerous cases where publishers consistently mistype\nthe type of account they hold within an advertising network. For in-\nstance, mangaread.org has declared the wrong relationship type for681 distinct identifiers included in its ads.txt files. To give a better\nunderstanding, beachfront.com has issued the identifier 13310 for\nanINTERMEDIARY account. However, mangaread.org declares in\nitsads.txt file that this identifier is DIRECT . We find 14 websites\nthat repeatedly mis-classify the type of over 600 identifiers in their\nads.txt files.\nE.2 Misuse\nIn addition to the discrepancies described in Appendix E.1, we\nalso discover that there is wrong application of the sellers.json\nstandard. First, we discover that there are various domains that\ncopy and serve Google\u2019s sellers.json file without being affiliated\nin any way. We find 28 such domains that come from different\ncountries and represent various categories ranging from model\nagencies, to online shops and business websites. All of these do-\nmains serve a copy of Google\u2019s sellers.json file and inside this\nfile they even provide Google\u2019s contact information. We exclude the\nsellers.json files of these domains from any further analysis of\nSection 5 since they do not represent actual business relationships\nbetween websites and ad networks.\nIn addition to this, we discover multiple cases where entries listed\ninsellers.json files concern domains that the clients most likely\ndo not own, manage or are in any way related. For example, we\nfind that Reklamstore\u2019s sellers.json file contains over 25 entries\nfor the domain youtube.com . It is obvious that a lot of these entries\nare not valid because they have a PUBLISHER relationship and the\nregistered owner is a YouTube channel or some random names (e.g.,\n\u201cfkt\u201d). In general, we discover that in multiple ad networks, people\nare able to register popular domains (e.g., google.com ,twitter.com ,\nfacebook.com ) as their own, using their own names. In Figure 12,\nwe illustrate some examples, where multiple accounts have regis-\ntered Facebook in AdYouLike . This suggests that ad networks don\u2019t\nproperly review the information their clients submit, or that this\nprocess is highly automated.\nFinally, we find that there are almost 10,000 domains which\nare listed as an INTERMEDIARY in different sellers.json files, but\nthese domains do not seem to be ad networks and in fact do not\nserve a sellers.json file themselves. According to the specifica-\ntion [ 41], when the seller type property is set to INTERMEDIARY ,\nthe listed domain should point to the root domain name of the\nseller\u2019s sellers.json file. This is not the case for thousands of\nentries. Even if this listing is done by accident or if some enti-\nties simply do not fully adhere to the sellers.json standard, the\nfact is that this behavior deteriorates the ecosystem\u2019s transparency\nand makes the end-to-end verification of involved entities practi-\ncally impossible. In fact, even Google does not follow this rule and\nserves its own sellers.json file through a different domain (i.e.,\nhttp://realtimebidding.google.com/sellers.json ).\nE.3 Transparency\nThesellers.json standard is supposed to provide greater trans-\nparency to the online advertising ecosystem and a better under-\nstanding of how revenue flows across different entities. This is\nespecially useful for advertisers since they can keep track of where\ntheir money is going and who they effectively fund. Apart from the\nethical aspect, advertisers are eagerly interested in understanding\nWelcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem WWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia\nDistribution of estimated ad revenue0K10K20K30K40K50K60K70K80KYearly Ad Revenue\nMedian: 5050Mean: 36250.7\nFigure 13: Distribution of yearly ad revenue of hidden inter-\nmediaries clients based on Google\u2019s AdSense.\nwho they fund because they can increase their audience engage-\nment and get a better ROI. However, it is often the case that ad\nexchanges hide the required information through the confidential-\nity flag that the sellers.json specification describes [ 41]. In such\ncases, the ad networks only publish the seller ID and seller type,\nwhich are mandatory. Hiding this information makes it impossi-\nble for advertisers to quickly understand that their ad spending is\nfunding specific websites or know which entities are involved in\nthese ad transactions [58].\nTowards that extent, we examine all sellers.json files in our\ndataset. Unfortunately, we find that a lot of ad networks do not work\ntowards a more transparent ad ecosystem and that they actively try\nto hide or obfuscate their operations. Such ad networks have thou-\nsands of clients and hide all of their identities in the sellers.json\nfile they disclose. For example, MyTarget , a Russian ad network,\nhas issued 4,877 distinct identifiers for its clients but has marked\nall of them as confidential without showing any domain name or\nowner name. Similarly, Concept.dk ,Unibots andI-mobile Co.\nare all advertising networks with thousands of clients that have\ncompletely confidential sellers.json files and do not disclose the\nidentity of their clients.\nTo make matters worse, we observe that this behavior is even\ncommon among top ad networks that dominate the market. Adlib ,\nadreact and adstir are popular ad networks with a substan-\ntial amount of clients and in all cases, more than 94% of their\nsellers.json files are confidential. Similar behavior is observed in\nGoogle\u2019s sellers.json file, which we find is the biggest and more\nwidely used ad network. We observe that, as of March 2023, Google\nhas issued 1,277,156 identifiers, 75.53% of which are confidential.\nAccording to their official documentation [ 32], a lot of their en-\ntries are confidential (including the domain) in order to protect the\nprivacy of individual accounts that have registered to the service\nwith their personal name. Nonetheless, this intentional behavior\nmakes the ad ecosystem extremely unclear, thus beating the whole\npurpose of sellers.json files. On the other side of the spectrum,\nnetworks such as GumGum ,SmileWanted andSublime.xyz serve\ncompletely transparent sellers.json files, listing the domains\nand name of all of their clients.\nAltogether, the sellers.json standard is regularly misused. Ac-\ncording to the specification [ 41],sellers.json files are supposedto increase the transparency of the ad ecosystem and enable the\nidentification of the entities that participate in it. However, it looks\nlike it is not properly enforced and implemented and that both pub-\nlishers and ad systems are accountable. If the standard is constantly\nand to a large extent misused, then there is no trust or transparency,\nand sooner or later bad actors will devise new techniques to abuse\nthe ecosystem and elicit advertiser money.\nF Hidden Intermediaries Cost\nIn this section, we provide an estimation of the potential cost that\nhidden intermediaries can have on the advertising ecosystem. For\neach of the clients of hidden intermediaries discovered in Section 5,\nwe extract network and demographics data from SimilarWeb [ 47].\nWe are able to extract accurate data for 146 client websites of hidden\nintermediaries. We find that for 64% of these websites, the majority\nof the visitors come from the United States, an audience with great\ngeographic value for advertising [72].\nWe attempt to translate the network traffic of these websites\ninto ad revenue, using Google\u2019s ad revenue calculator [ 34]. We map\ninformation about the category of website and the country of origin\nof its audience to the respective taxonomy system that the revenue\ncalculator tool uses. Additionally, we round network traffic to the\nclosest accepted value if the reported monthly visits are less than\nthe minimum or greater than the maximum accepted value. We\nplot in Figure 13 the potential yearly earnings from ad revenue\nfor these websites. We discover that on average, a client website\ncan generate 36K USD from ads and that, in total, clients of hidden\nintermediaries can cost advertisers 5.3M USD.\nPlease note that the mentioned revenues are simple estimations.\nGoogle\u2019s tool estimates revenue based on the content category and\nthe location of traffic. The actual revenue of a website can vary\ngreatly based on various features, including the actual ad network\nthat delivers an ad, user demographics (e.g., age and gender) [ 59],\nuser interests and device type [64], and advertiser demand.\nG AdSparency: Investigative Tools &\nFunctionality\nWe develop and publish AdSparency: a Web monitoring service that\nunveils the business relationships among websites and ad networks,\nas well as potential revenue flows. AdSparency utilizes informa-\ntion extracted from ads.txt andsellers.json files, and enables\n(i) stakeholders (e.g., advertisers, DSPs, Web publishers) to better\nunderstand where their money is funneled and what content they\nsupport, and (ii) policymakers (e.g., IAB, WFA) to better under-\nstand ad revenue flows and business relationships. Specifically, this\nservice periodically crawls millions of domains, aggregates files\nserved by different domains and analyzes the corresponding en-\ntries. Then, it (i) provides important statistical information about\nIdentifier Pooling and Hidden Intermediaries, and (ii) provides a\ncollection of investigative tools. Specifically, AdSparency provides\ntools to (i) lookup identifier pooling, (ii) detect hidden interme-\ndiaries, (iii) study website partnerships, and (iv) reveal business\nrelationships among publishers and ad networks. By crawling large\nsets of websites, this service can zoom out and reveal to marketers,\npublishers, and ad agencies the bigger picture: how publisher IDs\nare used and what relationships are formed between the various\nWWW \u201925, April 28-May 2, 2025, Sydney, NSW, Australia Emmanouil Papadogiannakis, Nicolas Kourtellis, Panagiotis Papadopoulos, Evangelos Markatos\nWeb entities in a global scale. It should be noted that AdSparency\nprovides a systematic insight into the ad ecosystem without infer-\nring any findings with a makeshift methodology. All the provided\nevidence is reported by the publishers and the ad networks them-\nselves through ads.txt and sellers.json files. Our service is\naccessible via: https://adsparency .ics.forth .gr/\nIdentifier pooling lookup tool. This tool helps stakeholders un-\nderstand which publishers share the same \u201cwallet\u201d (i.e., use the\nsame account to aggregate ad revenue). Users provide a specific\npublisher ID and see which websites explicitly declare this ID as\nDIRECT (i.e., direct control of the account) in their ads.txt file. Ad-\nditionally, users can explore if the same ID is declared as RESELLER\nby other domains, suggesting a discrepancy in the way it is used.\nThis information is acquired from over 81M ads.txt entries.\nTool to detect hidden intermediaries. This tool aims to disclose\nthe business relationships that ad networks form. Specifically, users\nare able to query for a domain and discover if this domain has reg-\nistered as both a PUBLISHER and an INTERMEDIARY in multiple ad\nnetworks. We derive such information from the sellers.json files\nserved voluntarily by ad networks, thus increasing our confidence\nabout its correctness. We only report business relationships with\nunambiguous information. That is, we only process sellers.jsonentries that explicitly state the domain who registered for a spe-\ncific publisher identifier. Using such information, stakeholders can\ndeduce if specific ad networks display a suspicious behavior by\nsometimes registering as a content owner (i.e., publisher) and other\ntimes as the facilitator of ad impressions (i.e., intermediary). Note\nthat this information cannot constitute concrete evidence of an\nentity abusing the ad ecosystem, but rather an indication of misuse.\nTool to examine the behavior of websites in terms of part-\nnerships. This tool aims at enhancing the transparency regarding\nthe relationships or even ownership [ 62] of websites, thus help\nuncover potential dark pools as they were formed in the past [ 21].\nSpecifically, a user can query for a domain and discover with what\nother websites this domain shares DIRECT identifiers.\nTool to reveal business relationships among publishers and\nad networks. This tool, analyzes ads.txt andsellers.json en-\ntries and presents the relationships a publisher claims to have with\nvarious ad networks, as well as the ad networks that claim the\nprovided domain is a registered publisher within their network.\nPrevious work has demonstrated that such information can un-\ncover the facilitation of objectionable content on the Web [63].\nTool to fetch ads.txt /sellers.json .Finally, our service offers\nmodules to retrieve and display the ads.txt and/or sellers.json\nfiles for a specific domain.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The devil is in the details: Analyzing the lucrative ad fraud patterns of the online ad ecosystem", "author": ["E Papadogiannakis", "N Kourtellis"], "pub_year": "2023", "venue": "arXiv preprint arXiv \u2026", "abstract": "The online advertising market has recently reached the 500 billion dollar mark. To accommodate  the need to match a user with the highest bidder at a fraction of a second, it has moved"}, "filled": false, "gsrank": 633, "pub_url": "https://arxiv.org/abs/2306.08418", "author_id": ["YN01tBEAAAAJ", "Q5oWwiQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:-H-nsw802XIJ:scholar.google.com/&output=cite&scirp=632&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=-H-nsw802XIJ&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 2, "citedby_url": "/scholar?cites=8275703032313249784&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:-H-nsw802XIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2306.08418"}}, {"title": "Educators, solicitors, flamers, motivators, sympathizers: characterizing roles in online extremist movements", "year": "2021", "pdf_data": "111To cite: Shruti Phadke and Tanushree Mitra. 2021. Educators, Solicitors, Flamers, Motivators,\nSympathizers: Characterizing Roles in Online Extremist Movements. Proc. ACM Hum.-Comput.\nInteract. Computer Supported Cooperative Work (CSCW\u2019 21), (accepted May 2021).\nEducators, Solicitors, Flamers, Motivators, Sympathizers:\nCharacterizing Roles in Online Extremist Movements\nSHRUTI PHADKE, Information School, University of Washington, USA\nTANUSHREE MITRA, Information School, University of Washington, USA\nSocial media provides the means by which extremist social movements, such as white supremacy and anti-\nLGBTQ, thrive online. Yet, we know little about the roles played by the participants of such movements. In this\npaper, we investigate these participants to characterize their roles, their role dynamics, and their influence in\nspreading online extremism. Our participants\u2014online extremists accounts\u2014are 4,876 public Facebook pages or\ngroups that have shared information from the websites of 289 Southern Poverty Law Center (SPLC) designated\nextremist groups. Guided by theories of participatory activism, we map the information sharing features of\nthese extremists accounts. By clustering the quantitative features followed by qualitative expert validation, we\nidentify five roles surrounding extremist activism\u2014 educators ,solicitors ,flamers ,motivators ,sympathizers . For\nexample, solicitors use links from extremist websites to attract donations and participation in extremist issues,\nwhereas flamers share inflammatory extremist content inciting anger. We further investigate role dynamics\nsuch as, how stable these roles are over time and how likely will extremist accounts transition from one role\ninto another. We find that roles core to the movement\u2014 educators andsolicitors \u2014are more stable, while flamers\nandmotivators can transition to sympathizers with high probability. Finally, using a Hawkes process model,\nwe test which roles are more influential in spreading various types of information. We find that educators\nandsolicitors exert the most influence in triggering extremist link posts, whereas flamers are influential in\ntriggering the spread of information from fake news sources. Our results help in situating various roles on\nthe trajectory of deeper engagement into the extremist movements and understanding the potential effect\nof various counter-extremism interventions. Our findings have implications for understanding how online\nextremist movements flourish through participatory activism and how they gain a spectrum of allies for\nmobilizing extremism online.\nCCS Concepts: \u2022Human-centered computing \u2192Empirical studies in collaborative and social com-\nputing ; Social media; \u2022Social and professional topics \u2192Hate speech.\nAdditional Key Words and Phrases: online communities, extremist groups, social media, information sharing,\nparticipatory activism\nACM Reference Format:\nShruti Phadke and Tanushree Mitra. 2018. Educators, Solicitors, Flamers, Motivators, Sympathizers: Char-\nacterizing Roles in Online Extremist Movements. Proc. ACM Meas. Anal. Comput. Syst. 37, 4, Article 111\n(August 2018), 35 pages. https://doi.org/10.1145/1122445.1122456\nAuthors\u2019 addresses: Shruti Phadke, Information School, University of Washington, USA, Seattle, USA; Tanushree Mitra,\nInformation School, University of Washington, USA, Seattle, USA.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\u00a92018 Association for Computing Machinery.\n2476-1249/2018/8-ART111 $15.00\nhttps://doi.org/10.1145/1122445.1122456\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.arXiv:2105.08827v1  [cs.SI]  18 May 2021\n111:2 Anonymous Authors\n1 INTRODUCTION\nAccording to the Southern Poverty Law Center (SPLC)\u2014a non profit organization dedicated to\nmonitoring extremist activity in the United States\u2014Facebook groups serve as the primary avenue\nfor extremists to recruit new members and spread extremist propaganda [ 75]. Take for example,\nPissed off White Americans \u2014a Facebook group harboring 64K followers on their public Facebook\npage. It describes itself as: \u201cWe are the sons and daughters of European Heritage, and we are tired of\nbeing treated as second class citizens. LOUD, PROUD, and very PISSED OFF!. \u201d This page frequently\nposts links from a known white supremacy group, White Rabbit Radio\u2014a Southern Poverty Law\nCenter (SPLC) designated white nationalist group [ 40]. Their posts often contain calls for actions\nagainst white genocide\u2014a white supremacy belief that there is a deliberate attempt to wipe out\nthe white race to promote reproduction of other races. Another Facebook group, White Lives\nMatter Movement posts informational content explaining what it means to be white or \u201caryan\u201d\non their public Facebook page. Sharing links from the website of an SPLC designated neo-nazi\ngroup\u2014National Vanguard [ 74]\u2014they suggest norms for racial segregation and educate readers\nabout white identity. While the Pissed off White Americans page uses link sharing for soliciting their\nreaders\u2019 engagement, White Lives Matter Movement Facebook page educates their readers about\nwhite identity and cultural norms. In other words, both pages play different roles in advancing their\nwhite supremacy ideology online. Moreover, by sharing links from the websites of known extremist\norganizations, both pages become participants in the extremist ecosystem on Facebook. We call\nthem extremist accounts \u2014Facebook pages and groups involved in actively sharing information\nfrom any of the 289 Southern Poverty Law Center (SPLC) designated extremist groups, and thus,\noperating as key players in sustaining and growing the extremist movement.\nIn this work, we explore the ecosystem of such online extremist accounts through the lens\nof participatory activism\u2014the potential and magnitude of individuals and groups to engage in\nsociopolitical issues [ 57]. Previous scholars have largely studied the importance of participatory\nactivism in positive social justice movements, such as feminist practices [ 33,52] or raising awareness\nagainst police brutality [ 4]. On the contrary, only a handful of studies have highlighted how anti-\nsocial movements, also adopt similar participatory activism to promote a positive notion of their\nbrand [ 38]. For example, terrorist organizations such as ISIS used participatory activism practices\nto promote the caliphate as a way of life and recruited combatants [38]. Despite their clear presence\non social media, studies analyzing online anti-social movements are rare. In particular, U.S based\ndomestic extremist movements with white supremacy, anti-LGBTQ, or anti-Immigration agendas\nthat predominantly operate online, have not been investigated through the lens of participatory\nactivism. In our work, we bridge this gap. Using the lens of participatory activism, we consider\nextremist accounts to play various social roles towards advancing extremist movements online.\nSpecifically, we identify 4,876 extremist accounts involved in sharing links from 289 Southern\nPoverty Law Center (SPLC) designated extremist groups using Facebook\u2019s CrowdTangle API. We\nobtain the public Facebook activity of 4,876 extremist accounts over two years (Jan\u201918 to Dec\u201919) to\nmodel their online roles in extremist movements. We further study their role dynamics and assess\nhow influential roles are in spreading various types of information sources. We first ask:\nRQ1: What social roles are played by extremist accounts in online extremist movements?\nTo answer, we consider extremism as a social movement\u2014a collective effort by a group of people\naimed towards changing the society in a way that aligns with the movement\u2019s goals [13]. Guided\nby theories of participation in social movements, we explore underlying behaviors of the accounts\nacross three dimensions: drives for participation, engagement trends, and strategies of mobilization.\nUsing features informed from these dimensions and qualitative expert validation, we identify five\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:3\nroles played by extremist accounts in forwarding their social movements: solicitors \u2014who solicit\nparticipation and funds for the extremist movement, educators \u2014accounts that share intellectual\ncontent about extremism and prominently share and like extremist content, flamers \u2014accounts\nthat express and incite anger by posting inflammatory content, motivators \u2014who are achievement\noriented and go-getters of the extremist community and who post information that portrays a\npositive image of their extremist agenda, and sympathizers \u2014accounts that are fringe supporters of\nthe extremist movement who sparingly engage with links from the extremist websites.\nThese roles are based on the social media activities of the extremist accounts spanning over 6\nmonths. How do these roles change over time? Do sympathizers get more involved in extremist\nmovements and eventually become solicitors oreducators ? To understand, we investigate the role\ndynamics and ask:\nRQ2a: How long do the extremist accounts retain their original roles?\nRQ2b: How likely are the extremist accounts in one role to transition to other roles?\nUpon measuring role retention, we find that 66% of the solicitors and 70% of the educators retain\ntheir roles throughout our analysis window. When analyzing role transition, we find that motivators\nandflamers transition into sympathizers with high probability.\nAs illustrated in our opening examples of Pissed off White Americans and White Lives Matter\nMovement , information can be valuable in putting out call for action or educating the readers about\nextremist ideologies. Researchers argue that information, especially disinformation spreads by\nflowing strategically or organically through various accounts on social media [ 76]. Specifically,\nFacebook accounts involved in extremist activities were found to use fake news, biased information\nand conspiracy sources to promote fundamentalist views [58]. Hence, we finally ask:\nRQ3: How influential are the roles in spreading various types of information?\nTo answer, we first use Hawkes process to model the temporal and statistical characteristics of the\ninformation spread through the extremist accounts. Next, we use the parameters estimated from the\nHawkes process to measure the influence of roles across four types of information sources: extremist,\nbiased, fake news and conspiratorial sources. We consider a particular role to be influential in\nthe spread of information, when a link posted by that role induces an account in another role to\npost the same link with high probability. We find that for information originating from extremist\nsources, educators andsolicitors are the most influential in triggering other roles to also spread such\ncontent. Whereas, motivators influence other roles in spreading biased news, flamers are influential\nin the spread of fake news.\nOverall our work makes the following contributions:\n\u2022We offer a framework for systematic operationalization of theoretically motivated character-\nistics of social movement participation.\n\u2022We present a data-driven and expert validated taxonomy of social roles in online extremist\nmovements.\n\u2022Through a rigorous temporal statistical modeling of information flow, we reveal how different\nroles are influential in stimulating the spread of extremist, biased, fake and conspiratorial\ncontent on Facebook.\nOur results allow us to understand how theories of social movement participation are reflected\nin online extremist movements and where the various roles are located on the trajectories of\ndeeper engagement into extremism. Further, our work has implications in assessing which roles\nmight benefit, and which might not, from interventions targeted to counter online extremism.\nFinally, we discuss how participatory activism might be democratizing the extremist movement\nand empowering the supporters with the resources and affordances to spread extremism online.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:4 Anonymous Authors\n2 BACKGROUND\n2.1 Participatory Activism and Extremist Movements\nActivism means taking an action to effect social change [ 51]. Participatory activism is a kind of\nactivism that is grounded in communities organizing to increase popular support for sociopolitical\nissues by strategically engaging in both, online and offline mechanisms for participation [ 66].\nConsidering the expanse of social media, researchers have connected participatory activism to\nthe concept of \u201csmart mobs\u201d\u2014people who are able to act in concert even if they don\u2019t know each\nother [ 64,66]. Under this new age activism, diverse set of people with overlapping interests can\ncome together in solidarity and act without having to acknowledge who they are beyond what\nthey support [66].\nHow does online participatory activism advance social causes? Previous research presents\nopposing perspectives on the effectiveness and the legitimacy of the online participatory activism.\nResearchers specifically use the terms \u201cclicktivism\u201d or \u201cslacktivism\u201d that refer to social media\nengagement in political micro-action [85] through low cost activities such as liking or sharing the\ncontent in order to raise awareness [67]. Writers on popular press comment that \u201cclicktivism\u201d or\n\u201cslacktivism\u201d are largely unproductive and ephemeral\u2014an ideal type of activism for lazy generation\n[22, 47, 88] . However, communication and political science scholars argue that such low cost low\nrisk participation is not only widespread but is also becoming a legitimate channel for political\nactivism [24]. Specifically, Obar et. al. interviewed advocacy groups and found that all the groups\nviewed online participation as an effective tool for civic engagement and collective action [53].\nResearchers have mostly investigated participatory activism in the context of positive social change.\nFor example, in feminist movements, participatory activism resulted in enhanced understanding of\nfeminism [ 33] and facilitated legal and public policy discourse surrounding gender based violence\n[52]. In other examples, participatory activism increased the visibility of police brutality against a\ngroup of environmentalists [ 4] and enabled successful spread of information in an authoritarian\nregime [ 62]. While these studies demonstrate how participatory activism can empower populations\nin social justice causes on one hand, on the other, anti-social movements, for example those\nadvocating for terrorism and extremism, can also benefit from similar practices. One qualitative\nstudy emphasized the success of hashtag campaigns and information manifestos in ISIS\u2019s territorial\nexpansion in 2014 [ 38]. They argued that through numerous online accounts, or \u201cmedia operatives, \u201d\nISIS was simultaneously able to promote its positive self-image for recruiting combatants and elicit\nparticipation from distant supporters. In other words, the \u201cmedia operatives\u201d played crucial roles\nin spreading diverse sets of narratives to enable recruitment into ISIS. Moreover, they did so by\nbeing a part of strategic information campaigns [ 38]. For example, ISIS media operatives urged\ntheir followers to download videos containing ISIS propaganda and re-upload them on various\nplatforms so as to increase information dissemination while also evading content moderation [ 38].\nBased on these studies, it is clear that similar networking and information sharing affordances\ncontribute to both, positive social changes and anti-social movements. Yet, studies investigating the\ndarker side of participatory activism are rare. In this paper, we fill this gap by asking: What are the\ndifferent roles played by extremist accounts in extremist social movements? How stable or transitory\nare these roles? And how influential are these roles in spreading mis- and disinformation? We\nspecifically focus on U.S domestic extremism, such as white supremacy and anti-LGBT movements\nand identify various roles through the lens of social movement and resource mobilization theories.\n2.2 Extremism and Social Movements\nSocial movements are collective efforts to bring out the collective action fitting a specific goal or\nideology [ 45]. Social movements emerge when constitution and function of the society is misaligned\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:5\nwith the movement\u2019s goals [ 45]. By this logic, extremist movements, such as white supremacy,\nbecome more active and aggressive when there is increased racial diversity in the society [ 90]. To\nunderstand the factors that may lead to the success of extremist movements, we look at theories\nanalyzing the success of social movements. What makes social movements successful?\n2.2.1 Success of Social Movements: Researchers attribute the success of social movements\nto the availability of human, material, and monetary resources [ 46]. Human resources include\nlabor, experience, skills, and expertise of the members of the social movement. Material resources\ninclude property, office spaces supplies and monetary resources include funds contributed by\nthe members. In other words, by participating in the movement, individuals make their human,\nmaterial and monetary resources available to the movement [ 46]. These resources are are then\ndirected towards mobilizing supporters, transforming mass public into movement sympathizers\nand eventually bringing about the desired social change. However, the efficiency with which the\nresources are translated into action depends on various actors involved, such as volunteers offering\nhuman resources or supporters offering monetary resources through fundraising. Based on how\nvarious members are involved in the movement, researchers have proposed theoretical roles in\nsocial movements participation. Next, we summarize the theoretically proposed roles in social\nmovements and discuss the challenges in adapting them to the online setting.\n2.2.2 Theoretically Identified Roles in Social Movement Participation: Prior scholarly\nwork has described participants in social movements from various theoretical perspectives, such as\nparticipant\u2019s role in an organizational hierarchy (e.g., leaders and followers) [ 48], their involvement\nin resource mobilization (e.g., members who distribute resources versus members who consume\nresources ) [ 46] and whether they benefit from the social movement (e.g. stakeholders in the\nmovement) [ 15,46,55,86]. In organizational hierarchy, leaders are strategic decision-makers who\nmobilize followers [48]. Considering participants\u2019 involvement in resource mobilization, constituents\nprovide resources to mobilize adherents [46] and gain sympathy from bystanders [80]. Moreover,\nscholars dichotomize the stakeholders of social movements into potential beneficiaries : population\nthat directly benefit from the goals of social movement and conscience participants : supporters who\nmay not directly gain from the success of the movement [ 15,46,55,86]. How do these theoretically\nidentified roles describe participation on online social media? Can we directly adopt the theoretical\ntaxonomy (e.g., leaders ,followers ,constituents etc.) to describes roles in online extremist movements?\nWe identified two concerns with directly adopting a theoretical taxonomy, that consequently\nmotivate the methodologies of our first research question. First, the roles derived from theories\nof social movements are based on physical social movement participation, such as protest events\n[55,86]. Compared to online participation, physical participation requires increased commitment\nby members, such as on-the-ground physical presence at the protest events and significant time\ninvestment in the movement\u2019s activities [ 66]. On the contrary, in online activism, individuals\ncan become a part of the movement by simply clicking, re-posting or writing short messages on\nrelevant links [ 66]. Secondly, theoretically identified roles are harder to disambiguate from each\nother. Consider for example leaders defined as per the organizational hierarchy perspective and\nconstituents from the resource mobilization perspective. While leaders lead the followers, they can\nalso be constituents \u2014the distributors of resources. Similarly, both adherents andbystanders from\nresource mobilization perspective can be viewed as followers . Considering these two points, instead\nof directly adopting theoretical taxonomy of roles, we consider the underlying characteristics of\nparticipation. Based on the framework of features derived from the theories of social movement\nparticipation, we develop a new taxonomy of roles for the online setting. Next, we detail the\nunderlying characteristics that form a background for our role identification process.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:6 Anonymous Authors\n2.3 RQ1 Background: Characteristics of Social Movement Participation\nWe summarize the theories in social movement participation across three dimensions: drives for\nparticipation ,engagement in the movement ,strategies of mobilization . These three dimensions, and\nthe computational features derived from them, are at the crux of our methodology for identifying\nroles in the extremist movements. The first two columns in Table 2 summarize the models described\nin the next subsections.\n2.3.1 Drives for Social Movement Participation: Theories of drives behind social move-\nment participation can be broadly distilled in two groups\u2014expectancy-value models and social-\npsychological models [ 17]. The expectancy-value models stress on the rationality of the participants\nwhereby the individuals weigh costs and benefits of participation while decision making [ 36]. Par-\nticularly, they consider the risk-reward ratio of the involvement in the social movement before\ninvesting and mobilizing resources for their own benefit [ 44,54]. Scholars pointed out one limi-\ntation of expectancy-value model that it underestimates the role of ideological drives and shared\ngrievances in participants [ 36]. To fill this gap, social-psychological models attribute the movement\nparticipation to various psychological drives. Feelings of injustice, relative deprivation and moral\noutrage is at the heart of movement participation [ 83]. While such grievances related to social\nmovement issues are ubiquitous, not all of them turn into protests [ 82]. Hence, social movement\nscholars also consider the sense of efficacy or achievement that drives people to participate [ 82].\nFor example, people might participate because they believe that their collective action can actually\nachieve the social change [ 21]. Further, researchers also stress the importance of group identity.\nThe more people identify with the social groups involved in the movement, the more they are\ninclined towards participating in the movement [ 72]. Emotions also play an important role in\ndriving people into the social movements. For example, anger is considered as theprototypical\nemotion for protests [84].\n2.3.2 Engagement Trends in Social Movements: Various types of participants could adopt\ndifferent degrees of engagement and commitment to distributing social movement related resources.\nSpecifically based on the availability of resources, constituents actively distribute the resources\nin order to proselytize the adherents and bystanders [ 46]. Moreover, actors could participate in\nresource mobilization for a single or multiple social movements [ 46]. Another important aspect\nof the engagement is how it varies over time. People participate in the social movements with\nvarying degrees of continuity. Corrigall-Brown characterizes such periodic engagement across\nfour dimensions\u2014persistence, transfer, abeyance, disengagement [ 10]. This characterization of\nparticipation trajectories is especially important on social media because it accrues diverse group\nof individuals with varying degrees of interests and dedication.\n2.3.3 Strategies of Information Mobilization: Social movements are goal-oriented. Partici-\npants in the social movements strategize the distribution and uses of resources to induce collective\naction and gain support [ 46]. Specifically, core members of the social movement mobilize resources\nin order to recruit volunteers, collect funds, spread their agenda and hold gatherings. Other re-\nsearchers also find such solicitation strategies to be crucial for financing the social movements [ 6].\nWhile solicitation may directly affect the progress of the movement, researchers also highlight\nresources that can indirectly create opportunities for collective action. Specifically in the social\nmedia setting, expressing opinions, thoughts and beliefs around political events [ 81] and reporting\nevents to increase users\u2019 knowledge of public issues, political causes, and social movements [ 12,81]\nare considered as key strategies of online activism.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:7\nstatistics (per account) min max mean std.\nposts 71 932K 7,067 30,574\nlink posts 23 78,571 1,614 3,915\nextremist link posts 10 5,129 207 528\nengagement\npage likes 106 1.8M 7,241 36,576\ngroup members 35 2.2M 2,827 13,603\nTable 1. Descriptive statistics for extremist accounts in our dataset. There are a total of 4,876 extremist\naccounts in our dataset.\n2.4 Role of Information in Online Extremist Movements\nExtremist movements have started leveraging social media to increase their outreach [ 14,29].\nAccording to Anti Defamation League (ADL) [ 2]\u2014an anti-hate organization focusing on combating\nanti-semitism in USA\u20142018 was recorded at the most violent year in terms of deaths caused by\ndomestic extremism since 1995 [ 63]. Several popular social media platforms were criticized in\nthese attacks for enabling recruiting and spreading disinformation [ 19]. For example, the entire\nChristchurch mass shooting seemed to be orchestrated for the social media age [ 43]. The perpetrator\nof the mass shootings posted an 87 page manifesto on 8chan with anti-immigrant and anti-Muslim\nideas and directed readers to a Facebook page where the shootings were live streamed. This is one of\nthe many examples where extremists have used social media to broadcast their ideologies followed\nby violent events. Apart from educating the public about the extremist agenda, extremists also use\nonline platforms to promote action [ 49]. Recently, the right-wing extremists have started leveraging\nmeme and trolling culture to shape hate narratives [ 59]. Researchers found that extremist fringe\ngroups collaboratively launder information even on mainstream social media platforms to appeal\nto the mass [58]; especially to a young audience [11].\nDespite the strong visibility of extremist groups online, computational studies focusing on\ninformation operations of U.S. domestic extremist groups are rare. A recent qualitative work\ninvestigated information sharing by various extremist ideologies and find that hate groups use\ninformation sharing to recruit, radicalize and educate their follower base [ 58]. Specifically, they\nobserved the use of links shared from biased news sources by white supremacy groups and links\nfrom websites hosting conspiratorial content in anti-Muslim and religious supremacy groups. In\nthis paper we use rigorous temporal statistical models to quantify how influential various roles in\nextremist movements are in disseminating different types of information sources such as extremist\ncontent, fake news, biased news and conspiracies.\n3 DATA\nIn this work, we focus on identifying roles in online extremist movements and assess how influential\nvarious roles are in spreading information from extremist, biased, fake news and conspiratorial\ninformation sources. Specifically, we focus on extremist accounts \u2014public Facebook pages and\ngroups that share links from extremist websites. In this section we detail our process of identifying\nthe extremist accounts (Figure 1 (a) and (b)) and collecting their Facebook activity data. We first\nexplain the problem of extremism on Facebook and then describe the data collection and pre-\nprocessing steps.\n3.1 Extremism on Facebook Groups and Pages\nDespite the policies against extremist content, Facebook is still crowded with groups and pages\ncirculating and discussing violent ideas [ 34]. Very recently, Facebook banned a number of pages\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:8 Anonymous Authors\nand groups involved in the \u201cboogaloo movement\u201d\u2014an anti-government movement by right wing\nextremists organizing for armed revolt [ 35]. However, this ban was not as effective as initially\nperceived. The pages and groups related to the boogaloo movement simply renamed and rebranded\nthemselves with harmless-sounding names and continued their extremist activities [ 61]. According\nto the International Association of Chiefs of Police\u2014a non-profit organization that is the world\u2019s\nlargest professional association for police leaders\u2014Facebook groups and pages are at the center of\nextremist recruitment, radicalization, and mobilization [ 27]. They found that, by just re-posting\nand linking information from websites hosting graphic videos and other violent content, extremism\nrelated groups and pages are able to abide by Facebook\u2019s policies against hate speech and still\nspread relevant information. In our first research question, we identify the roles played by various\nsuch extremist accounts in advancing the extremist movements online. In order to model these roles,\nwe first need to identify the extremist websites, and then select the extremist accounts\u2014Facebook\npages/groups that share links from the extremist websites.\n3.2 Identifying Extremist Websites\nTo identify extremist websites, we take help of the resources published by external organizations\nwho are experts in social justice causes. Specifically, we refer to Southern Poverty Law Center\u2019s\n(SPLC) website1. SPLC is a non-profit organization engaged in legal advocacy for social justice\nissues. Every year, SPLC releases a extremist groups\u2019 dataset2that records the names, locations,\nand ideologies of extremist groups operating in the United States. We searched through SPLC\u2019s\n2018 and 2019 extremist groups datasets. For each listed extremist group, we manually searched for\ntheir official website. Note that each listed extremist group has physical headquarters across various\nstates in the USA. By searching for their websites we identify the home for the extremist groups\u2019\ncontent in the online world. We identified 289 websites hosted by the listed extremist groups. For\neach website, we also note the website domain\u2014hereafter referred to, as extremist domains. For\nexample, for Virginia Dare, a white supremacy group, we record vdare.com as a website domain and\nfor Alliance Defending Freedom\u2014anti-LGBTQ advocacy organization\u2014we record adflegal.org .\nAccording to the SPLC\u2019s policies, SPLC prioritizes identifying all U.S based hate groups regardless\nof the group\u2019s \u201cleft\u201d or \u201cright\u201d political leaning3. For example, the 2019 SPLC dataset contains 27\ngroups with Black Separatist ideology which is not on the far-right of the U.S political spectrum.\nHowever, we could identify websites for only 10 out of 27 Black Separatist groups. While we\ndid not set out to study online extremist groups only from the far-right political spectrum, our\ncollection of extremist websites largely belong to far-right groups representing anti-Immigration,\nanti-Muslim, White Supremacy and anti-LGBTQ ideologies. This skew towards far-right extremism\nis representative of the picture of domestic extremism in the United States. According to the Center\nfor Strategic and International Studies (CSIS),4far-right extremism has massively outpaced far-left\nand other types of extremism in the United States [30]. Another independent report on Global\nTerrorism Index produced by the Institute for Economics and Peace reports that the far-right attacks\nin In North America, Western Europe, and Oceania have increased by 250% since 2014, making it\nmore lethal than the far-left extremism [18]. While we believe that our dataset is reflective of the\necosystem of domestic extremism in the United States, we discuss this skew further with respect to\nextremism in other countries in the Limitations and Future Directions section.\n1https://www.splcenter.org/\n2see \u201cDOWNLOAD DATA\u201d in https://www.splcenter.org/hate-map\n3https://www.splcenter.org/20200318/frequently-asked-questions-about-hate-groups\n4CSIS conducts policy studies and strategic analyses of political, economic and security issues throughout the world. CSIS is\nlabeled as least biased and highly factual source of information by mediabiasfactcheck.com\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:9\n3.3 Identifying Extremist Accounts\nTo identify extremist accounts\u2014Facebook groups/pages that share links from extremist websites\u2014\nwe use the CrowdTangle Link Search API5. The CrowdTangle Link Search API retrieves posts\nby public Facebook groups and pages containing a certain link or the link domain. With the\n289 identified extremist domains, we query the Link Search API separately for every domain.\nFor extremist websites containing generic domains such as sites.google.com , we query the full\nlink with the sub-domain, for example, sites.google.com/site/newblackliberationinstitute . For\nevery queried domain, the API returns up to 1000 posts containing that link domain. Hence, to\nincrease the completeness of our data, we queried every extremist domain separately for every\ncalendar month starting from January 2018 to December 2019. For every queried domain in any\ncalendar month, the number of returned posts was always less than 1000. This indicates that we\nhave retrieved all public posts on Facebook available to CrowdTangle between 2018 and 2019\nthat share links from the identified extremist domains. Every post retrieved from CrowdTangle\ncontains the account (page or group) name, post text, embedded links, timestamp, reactions (e.g.,\nLike, Love, HaHa etc.), number of comments, number of public shares and 12 other fields. We\naggregate all returned posts (450K posts) and find that our data contains 71,430 unique Facebook\npages/groups accounts. In other words, 71,430 accounts shared at least one link from the extremist\ndomain. User activities on social media often follow skewed, long-tailed distributions where most\nusers contribute less frequently while fewer users are more active. We observe similar distribution\nwith extremist links posted per account. Previously, researchers have used activity thresholds\nto eliminate accounts or communities that are less active [25, 39] . For example, while studying\nWikipedia edits, Kumar et. al. remove the users that make less than 5 edits [39]. We decide the\nactivity threshold by analyzing the percentile values of the extremist links per account distribution.\nBased on the 95\ud835\udc61\u210epercentile cut-off, we remove all accounts that share less than 10 unique links\nfrom extremist domains. We provide additional details of the downstream analysis with various\nlink thresholds in the Appendix. The entire data collection process happened across three weeks in\nMay 2020. This means that the extremist accounts that were active in 2018 and 2019 but got banned\nbefore May 2020 are not included in the dataset.6Finally, we have 4,876 Facebook pages/groups\nremaining in our dataset. Table 1 displays the descriptive statistics for the accounts in our dataset.\n3.4 Qualitative Validation of the Extremist Accounts\nWhile we know that the extremist accounts posted 10 or more unique links from the extremist\nwebsites, do they promote extremist worldviews in general? In this subsection, we present our\nqualitative validation of the ideologies and the views promoted by the extremist accounts. To\nvalidate, we invited two experts from the Southern Poverty Law Center specializing in white\nsupremacy and anti-LGBTQ hate groups. We requested the experts to qualitatively analyze a\nrandom sample of extremist accounts. Specifically, we randomly sampled 20 extremist accounts that\nshare links from the white supremacy and 20 accounts that share links from anti-LGBTQ extremist\nwebsites. Next, we asked the experts to review Facebook timelines of the extremist accounts and\ndescribe their ideologies based on the content hosted and the page/group name and description.\n16 of the 20 accounts posting links from white supremacy extremist websites, generally promote\neither far-right conspiratorial views and racists or misinformative content. Similarly, 18 of the 20\naccounts posting links from anti-LGBTQ extremist websites usually peddle anti-choice, anti same\nsex marriage or anti-trans views. Only 2 of the 40 groups focused exclusively on memes without\n5https://github.com/CrowdTangle/API/wiki\n6As of January 2021, 207 extremist accounts from our dataset (156 Facebook groups and 51 Facebook pages) have been\nremoved from Facebook.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:10 Anonymous Authors\nactively promoting any aspect of the white nationalist or anti-LGBTQ rhetoric. The complete expert\nanalysis is available at the link in the footnote7.\nWhile the experts validated the extremist views and the content hosted by extremist accounts,\nthe 4,876 extremist accounts in our dataset consist of Facebook pages and groups that engage\nmultiple Facebook users. We treat every page or a group as one extremist account that hosts content\nposted by it\u2019s page owners or the group members. Who contributes to the content on these pages\nor groups? CrowdTangle, or any other Facebook API does not disclose personally identifiable\ninformation even in the public posts8 9. In other words, when requesting the content\u2019s of a post,\nthe response will not include the name of the member who created the post. This poses a challenge\nin understanding the agency of posts shared on the extremist accounts. While this is a limitation of\nthe Facebook dataset, we approximate the engagement with extremist accounts by reporting the\ndistribution of page likes and group members in Table 1.\n3.5 Extracting Information Shared by Extremist Accounts\nWe identified 4,876 extremist accounts. In our third research question, we assess how influential\nvarious accounts are in spreading links from biased, fake news and conspiracy domains in addition\nto the extremist domains. Towards this goal, we need all link posts \u2014posts with embedded links\u2014\nfrom the extremist accounts and not just the ones originating from extremist domains. Hence, next\nwe extract all link posts made by the extremist accounts between 2018 and 2019 and then group the\nlink posts by the link domain type. First, we use the CrowdTangle Post Search API to acquire all of\nthe Facebook link posts made by the 4,876 extremist accounts. In total, we obtain 223K link posts\nmade by extremist accounts across two years, 2018 and 2019. Next, we extract the links shared in\nthe posts along with the timestamps and the link domains. In total there are 74,314 unique links in\nour dataset spanning over 1,236 link domains.\n3.6 Data Slicing for the Downstream Analysis:\nOur role identification process discussed in next sections is based on the Facebook activity of\nextremist accounts. Recall that we have two years (2018 and 2019) of activity for each account. Here,\nwe determine the time unit of analysis in which we identify the roles, observe their dynamics and\nassess their influence in information sharing. To study the role stability over time, we need to divide\nthe two year timespan into smaller windows and analyze how extremist accounts transition into\ndifferent roles over successive time windows. We slice the data into four windows of six months\u2014 \ud835\udc471,\n\ud835\udc472,\ud835\udc473,\ud835\udc474\u2013from January 2018 to December 2019 (Figure 1 (b)). In RQ1, we identify the roles played\nby extremist accounts in \ud835\udc471and in RQ2, we track the role stability over \ud835\udc472,\ud835\udc473and\ud835\udc474. In RQ3, we\nmodel the information flow through the roles in \ud835\udc471. Does the choice of six-month time window\naffect our observations? We experimented with different length of time windows (specifically, 2\nmonths, 3 months and 12 months) obtaining similar results for the research questions.\n3.7 Identifying Domain Types for Extracted Links:\nIn the RQ3 analysis, we model the information flow and examine the influence of various roles in\nspreading content from mis and disinformation based sources. Specifically, we consider 57K link\nposts made in \ud835\udc471and identify domain types for the links. We are interested in identifying domains\nhosting extremist content, biased news, fake news and conspiracy content. We refer to the dataset\npublished by OpenSources10. OpenSources maintains a professionally curated list of online sources\n7https://www.dropbox.com/s/mf3jt9xbk9z9xfw/SPLC_annotations.pdf?dl=0\n8https://help.crowdtangle.com/en/articles/1140930-what-data-is-crowdtangle-tracking\n9https://developers.facebook.com/docs/groups-api/\n10https://github.com/BigMcLargeHuge/opensources\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:11\nSPLC extremist \ngroups datasets \n2018-2019Identifying\nextremist \nwebsites\nInferring Role In\ufb02uence based \non Pairwise Weight Matrix for \nvarious domain typesExtract temporally \nordered URL posts \nby roles\nFit Hawkes Process \nfor every URL based \non the extracted \nseries of posts\nextremist conspiracyfake biasBuilding \nfeature set\nRole RetentionRoles in Extremist MovementsClustering\naccounts based \non feature setIdentifying Extremist \nAccounts: Facebook \ngroups/pages sharing links \nfrom \nextremist domains Extracting \nAll Link PostsRemove accounts \nwith < 10  links from \nextremist domains\n223K posts\n74,314 unique URLs\n1,236 domains4,876 Extremist \nAccounts\nEducator\nEducatorSympathizer\nSympathizer\nMotivator Flamer\nFlamerSolicitorT1T1\nT4T3T2367 \n groups\n0.02\n0.07\n0.300.01Posts with links from \nextremist domains\nData slicing for RQ1 \nand RQ2Jan 2018- Dec 2019\nJan 2018- Jun 2018Jan 2018- Jun 2018\nJul 2018- Dec 2018\nJan 2019- Jun 2019\nJul 2019- Dec 2019Identify URL domain \ntype as extremist, bias, \nfake or conspiracy289\nextremist \ndomains\nfor each \nunique \nURL\nRole labeling \nwith expert \nevaluationDrives\nEngagement\nStrategies\nHow long do the accounts \nmaintain their initially identi\ufb01ed \nroles in T1 through T2, T3, T4?With what probability, accounts in one \nrole transition into another?Role TransitionRQ1\nRQ3\nRQ2\n(a)\n(b) (d) (e)(c)Jan 2018- Jun 2018\nrecruitersflamers\nFig. 1. Figure showing data preparation and method details for three research questions. (a) We first identify\nextremist websites (domains) and identify extremist accounts\u2014Facebook pages and groups that links from\nextremist domains. Next, we extract posts by the extremist accounts that contain links from the extremist\nwebsites and (b) slice the dataset into four time windows of 6 months each. (c) For role identification in RQ1\nwe cluster extremist accounts based on the features derived from the account activity in T1. (d) We use the\ncluster centers from T1 to re-cluster the extremist accounts and measure role retention and transition in RQ2\n(also see Figure 2 for more details). (e) For RQ3, we use the link posts by the extremist accounts made in \ud835\udc471,\ngroup the links based on their source type (extremist, biased, fake news and conspiracy) and measure the\ninfluence of various roles in link sharing based on Hawkes process.\ntowards the goal of empowering people with reliable information. With the help of professionals,\nthey annotate each source based on overall inaccuracy, extreme biases, lack of transparency, and\nwriting styles. We use the annotations from OpenSources, and our list of originally identified\nextremist domains (Section 3.2), to group links by their source type as extremist, fake news source,\nbiased source and conspiracy/pseudoscience source. For our RQ3 analysis, we remove all links that\ndo not belong to either of these four domain types. Removing the links with domains not included\nin the OpenSources or the original set of extremist domains, reduces our \ud835\udc471link post dataset by 24%.\nIn the Appendix, we provide the characterization of the frequent domains in the removed dataset.\n4 RQ1 METHOD: IDENTIFYING ROLES IN ONLINE EXTREMIST MOVEMENTS\nIn this research question, we identify roles played by extremist accounts in the extremist move-\nments based on theory guided characteristics of social movement participation. Specifically, we\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:12 Anonymous Authors\nCharacteristics of\nParticipationTheoretical Models References Behavior Operationalization\nDrives for\nparticipationExpectancy-value\nmodels[36, 44, 54] Risk Proportion of LIWC Risk words ( e.g., caution, crisis, failure )\n[36, 44, 54] Reward Proportion of LIWC Reward words ( e.g., benefit, bonus, award )\nSocial-psychology\nmodels[83] Injustice Proportion of MFD Fairness words ( e.g., parity, fair, justice )\n[21, 82] Achievement Proportion of LIWC Achievement words ( e.g., accomplish, ability, attain )\n[72] Group Identity Proportion of LIWC we words ( e.g., we, ours, us )\n[84] Anger Proportion of LIWC anger words ( e.g., resent, argue, angry )\nEngagement in\nthe movementDegrees of\nparticipation[46]Proportion of links\nfrom extremist domainsRatio of links from extremist domains\nto total link posts\nDegrees of\nparticipation (popularity)[46] LikesProportion of likes on extremist links\nto likes on the rest of the link posts\nSharesProportion of shares on extremist links\nto likes on the shares of the link posts\nCommentsProportion of comments on extremist links\nto comments on the rest of the link posts\nTrends in\nparticipation[10] TrendTrend line fitted on the number of extremist\nlinks posts per month\nStrategies of\nmobilizationOpinions [81] Expressions of opinionsProportion of extremist link posts\ncontaining opinion patterns (see Table 6 )\nSolicitation [6, 46] Expressions of solicitationProportion of extremist link posts\ncontaining solicitation patterns (see Table 7 )\nTable 2. Table summarizing features used to identify roles in online extremist movements on Facebook. We\nbuild the feature set based on underlying characteristics of participation and the theoretical models describing\nthem.\noperationalize drives for participation (Section 2.3.1),engagement in the movement (Section 2.3.2)\nandstrategies of mobilization (Section 2.3.3) based on the activity of extremist accounts in the six\nmonth time period \ud835\udc471(Jan 2018-Jun 2018) and build a feature set (Table 2) to identify roles. Next,\nwe represent every extremist account in our dataset with the derived features. To identify roles, we\ncluster the accounts based on the derived features. Finally, we qualitatively analyze and label each\ncluster as a role in extremist social movement with the help of experts in social psychology.\n4.1 Operationalizing Characteristics of Social Movement Participation\n4.1.1 Drives for Social Movement Participation (6 features). Theoretical models exploring\nthe drives for social movement participation consider two distinct perspectives: expectancy-value\nmodels , whereby participation is driven by perceived risk-reward assessments and social psychology\nmodels , where the psychological features are the core drivers of participation. Below we detail\nthe computational operationalizations of drives informed by these theoretical models explained in\nSection 2.3.1.\n\u2022Expectancy-value features: Participation in social movement could be driven by perceived\nrisk-reward assessment related to engagement in the movement [ 36,44,54]. Analyzing\nthe language used by the extremist accounts while sharing links from extremist websites,\nespecially the words related to cost-benefit, could indicate whether the accounts considered\nthe costs and benefits of participating in extremist movements. To operationalize these\nfeatures, we use risk and reward lexicons from the Linguistic Inquiry and Word Count (LIWC)\n2015 [ 79]. LIWC is designed to record words that reflect various psychological states and\nperceptions [ 79]. Specifically, we calculate the proportion of risk related words (e.g., caution,\ncrisis, failure) and reward related words (e.g., benefit, bonus, award) used by an extremist\naccount while sharing links from extremist websites.\n\u2022Social Psychology features: Guided by the social-psychology based theoretical models,\nhere we want to measure the feelings of injustice [ 83] , sense of achievement [ 21,82], group\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:13\nidentity [ 72] and anger [ 84] that could serve as potential drives for participation. To identify\nthe language related to injustice, we use Moral Foundations Dictionary that contains a\nsystematically derived list of words pertaining to moral foundations in political ideologies\n[78]. Specifically, we use the \u201cfairness\u201d lexicon which accommodates virtue words such as\nrights and equality, and vice related words such as bigot, favoritism, and prejudice [ 20].\nNext, to measure the sense of achievement, we use LIWC\u2019s [ 79] achievement category which\ncontains words such as \u201caccomplish\u201d, \u201cability\u201d, \u201cattain\u201d etc. Further, language related to\ngroup identity can be reflected by the use of third person pronouns such as \u201cwe\u201d, \u201cus\u201d, \u201cours\u201d\n[28,56,79]. Hence we measure the third-person pronoun usage by LIWC \u201cwe\u201d category.\nFinally, to measure anger related words, we use LIWC anger category containing words such\nas \u201cresent\u201d, \u201cargue\u201d, \u201cangry.\u201d For each of these lexicons, we calculate the proportion of words\nin each lexicon while sharing links from extremist websites.\n4.1.2 Engagement Trends in Social Movements: (5 features). As per the details described\nin Section 2.3.2, here we provide our methods to characterize engagement trends in the social\nmovements. Participants can engage with social movements in various degrees of interests and\ncontinuity [ 10,46]. Hence, we calculate proportion, popularity and trends in sharing links from\nextremist websites.\n\u2022Proportion of Links from Extremist Domains: Various degrees of participation in dis-\ntributing resources can reflect the involvement in social movement [ 46]. Hence, for every\nextremist account, we first calculate proportion of links from extremist domains \u2014proportion of\nlinks shared from extremist domains to all links shared by that account in a given time-frame.\n\u2022Popularity of Links from Extremist Domains: The amount of positive reactions and\ninteractions on the shared links could reflect how popular the posts containing extremist links\nare on a Facebook page/group. Hence, we calculate the average likes, shares and comments\nreceived on posts with links from extremist websites and divide it by the average likes, shares,\nand comments (respectively) on all links posted in a given time-frame. High values of these\nfeatures indicate that the extremist content is more popular compared to the rest of the\ncontent published on that page/group.\n\u2022Trends in Disseminating Links from Extremist Domains: We also account for the\nengagement trends. For each month within the six-month period, we calculate the number\nof links from extremist websites posted on an extremist account and fit a line via least-\nsquare regression. Least-square regression finds optimal fit for the line by minimizing the\nsum of squared residuals. We calculate the trend of this fitted line to measure engagement.\nSpecifically, positive values of trend can indicate increasing engagement and negative values\ncan indicate disengagement in posting links from extremist websites.\n4.1.3 Strategies of Information Mobilization: (2 features): As described in detail in Section\n2.3.3, core members of the social movements may strategically solicit participation through calls\nfor donations, volunteers and invitations for social gatherings [ 6,46]. Similarly, members can also\nstrategically create opportunities for collective action by expressing opinions, thoughts and beliefs\naround political events [ 81]. Hence, we build two features that capture the expressions of personal\nopinions and the language of solicitation used by extremist accounts while sharing links from\nextremist domains. For both features, we calculate the proportion of extremist link posts containing\nthe expressions of opinions and solicitations respectively.\n\u2022Expressions of Opinions in Posts with Links from Extremist Websites: By \u201copinions\u201d\nwe refer to the expression of thoughts, beliefs and personal opinions [ 68]. To calculate\nthe proportion of opinions present in posts, we extract phrases that signal expressions of\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:14 Anonymous Authors\npersonal opinions or private states [ 89]. Previously, researchers studying emotional and\ninformational support [ 5,87] relied on emotional and informational support related nouns,\nverbs and adjectives to extract phrases related to their task. For example, Wang et. al. [ 87]\nused<\ud835\udc66\ud835\udc5c\ud835\udc62+\ud835\udc40\ud835\udc42\ud835\udc37\ud835\udc34\ud835\udc3f\ud835\udc49\ud835\udc38\ud835\udc45\ud835\udc35 >pattern to extract phrases containing suggestions (\u201cyou should\u201d\nor \u201cyou must\u201d). We use similar methodology to extract phrases related to personal opinions.\nHow can we identify verbs, nouns and adjectives related to personal opinions? Chen et. al.\nargue that individuals form their opinions via cognition and internal perceptual cues [ 9].\nHence, we first look at LIWC 2015 cognitive processing lexicon and its subcategories that\nrecord words related to thinking, perception and expression. To construct phrase patterns, we\nfirst split all words from LIWC cognitive processing categories into their part of speech labels\n(verbs, nouns, adjectives). Consider the verb prefer and noun preference from LIWC cognitive\nprocessing category. Both words, when paired with different pronouns can form expressions\nof opinions. For example, \u201cI (first person subjective) prefer\u201d and\u201cMy (first person possessive)\npreference\u201d both indicate personal opinions. Moreover, variations such as negations ( \u201cI do\nnot prefer\u201d ) or adjectives ( \u201cMy strong preference\u201d ) also signal opinions. Hence, we build our\ninitial set of opinion patterns from LIWC\u2019s cognitive processing verbs, nouns and adjectives\nby pairing them with appropriate pronouns and variations. We iteratively improve upon\nthis list of phrase patterns by first, extracting sentences containing those patterns and then,\nmanually eliminating verbs, nouns and adjectives that do not signal opinions. Table 6 in the\nAppendix lists the final patterns and examples. Note that our opinion extraction method is\nbased on LIWC cognitive processing lexicon that contains limited number of words. Hence,\nit is possible that our opinion extraction misses out of some expressions of opinions.\n\u2022Expressions of Solicitation in Posts with Links from Extremist Websites: In solicita-\ntion, we want to identify expressions that demand some action on the reader\u2019s part. Here, we\nare looking for calls for donations, invitations for events and protests and participation in\npolicy advocacy (e.g., sign the petition, call your representative etc). To extract solicitation\npatterns, we follow similar procedure as opinion extraction but instead look at verbs, nouns\nand adjectives from LIWC\u2019s social and affiliation categories. LIWC social and affiliation\ncategories contain words such as sign,call,contact . We build phrase patterns and iteratively\nevaluate them using methods similar to opinion extraction and report final solicitation phrase\npatterns in Table 7 in the Appendix.\n4.2 Clustering Extremist Accounts Based on the Derived Features\nWe use the features described above, to cluster the extremist accounts and label each cluster as\na role in the extremist movement. We use the theory based features (described in the previous\nsubsection) representing drives, engagement and strategies to discriminate between different\nroles in meaningful way. For role identification, we first need to decide on the number of roles\nand then use a technique that integrates structural data (feature vectors for extremist accounts)\nwith interpretive analysis that will allow us to describe roles in a relevant way. We use K-Means\nclustering\u2014an unsupervised clustering algorithm commonly used by other CSCW scholars in role\nidentification studies [ 3]. For example, Arazy et. al. used K-Means to to identify emergent roles in\nWikipedia contributors [ 3]. We use the popular K-Means method with kmeans++ initialization to\ncluster the extremist accounts based on their activity in the six month time window \ud835\udc471(Figure 1\n(c)). Specifically, we represent every extremist account with a feature vector of length 13 (6 drives\n+5 engagement+2 strategies). Next, we perform a series of robustness checks to first, determine\nthe number of clusters in order to obtain the optimal separate between different roles and then,\nto check the stability of clusters. All features were standardized for the downstream analysis. In\nK-Means algorithm, the number of clusters , \ud835\udc3eis a free parameter. We first find the best value of\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:15\nRole Frequency Example texts used by the accounts while sharing links from extremist websites\nSolicitors 5.2%\"...Sign here to demand her [Rep. Maxine Waters] immediate resignation\"\n\"...Join us in signing thank you card for President Trump\"\n\"...Stand with us to take back our streets\"\nEducators 10.6%\"...Escaping from motherhood: how it destroys society\"\n\"...We believe that we have the duty to instruct people in the truth of Tradition. Even if it destroys their party\"\n\"...The need for an ethnocentric society amidst \"globalism\" \"\nFlamers 18.4%\"...genuine Christians know that homosexuality is an abomination before GOD! \"\n\"...MURDERED in cold blood. Emergency: Gunfire, bodies and BLM murderers\"\n\"...house democrats vote to allow female genital mutilation...\" (false information flag by Facebook pops up)\nMotivators 29.4%\"...Senator Dan Halls stands with us in a passionate commitment to strengthening religious freedom\"\n\"...FREE SPEECH WINS\u203c! Supreme court rules pregnancy centers can\u2019t be forced to advertise abortion\"\n\"...we WILL have the COURAGE to defend ourselves! borders, language and culture MATTER\"\nSympathizers 36.4%\"...White South Africans petition Trump to allow them to migrate to the US\"\n\"...A jihadi cult member running for Congress as Democrat from Alaska\"\n\"...They will only see Italy on postcard: Italy turns away another migrant ship\"\nTable 3. Roles and the corresponding percent of extremist accounts in the dataset. The examples are of the\ntexts written by the extremist accounts while sharing links from the extremist websites\n\ud835\udc3ewith an elbow analysis that offers a natural trade-off between the best separation between the\nclusters and the number of clusters. Specifically, we train the K-Means algorithm for number of\nclusters ranging from 2 to 20 and plot distortions\u2014sum of squared distances from each point to its\nassigned center. We observe the elbow at \ud835\udc3e=5(see Figure 7 (a) in the Appendix). Thus we assume\n5 as the optimal number of roles. We repeated the elbow experiment with other scoring parameters\nsuch as silhouette distance\u2014a measure of how similar a data point is to its own cluster compared to\nother clusters\u2014with similar results. We also check for the stability of final cluster assignments with\nvarious random seeds. Moreover, to check the robustness of our method, we perform the clustering\nwith alternate clustering methods observing similar elbow and cluster assignments. Section A.2\ncontains more details about the robustness checks used for the cluster analysis. We assume that\nevery cluster generated, represents a role in the online extremist movement. Next, we use expert\nguided interpretive analysis to label the roles and their descriptions.\n4.2.1 Role Labeling with Expert Evaluation .Do our quantitatively identified clusters repre-\nsent coherent roles in extremist movement participation? To evaluate, we invited a group of seven\nsocial psychology and social movement experts to first analyze and then label the clusters based\non their representative characteristics. This group consisted of one senior professor, one assistant\nprofessor, one post-graduate researcher and four senior doctoral students. To reduce bias in role\nlabeling, we selected the external evaluators who are not a part of the author group and were not\ninvolved in any of the work preceding or following this stage. We showed them mean feature\nvalues for every cluster. Additionally, we selected top 5 representative extremist accounts from\neach cluster\u2014accounts with closest distance to the cluster centers. We compiled the list of top\n10 most representative posts from each selected account ranked by post likes [ 26]. Based on this\ninformation, we asked the evaluators to come up with labels and descriptions for each cluster. In\nall, every evaluator looked at 250 Facebook posts (5 clusters \u00d75 accounts\u00d710 posts) and recorded\nthe possible labels and descriptions. Finally, the first author and the evaluators together, worked\nand selected the best label for every cluster. We present the identified roles and comments on the\nexpert evaluation process in the next section.\n5 RQ1 RESULTS: ROLES IN ONLINE EXTREMIST MOVEMENTS\nHere we describe the roles played by extremist accounts and their typical behaviors. Table 3\ndisplays the frequency of the roles in the dataset alongwith the example text written by the\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:16 Anonymous Authors\nextremist accounts while sharing links from extremist websites. We identified five roles in the\nonline extremist movements.\n(1)Solicitors: These are the accounts that solicit participation from their readers for signing\npetitions, attending rallies etc. On average, around 20% of their links come extremist domains\nand they post extremist content with fairly consistent trend throughout the six month period\n(trend feature values close to 0). These accounts use high group identity language such as\n\u201cwe\u201d, \u201cour\u201d, \u201cus\u201d compared to other roles. Evaluators also described them as \u201crecruiters.\u201d One\nevaluator mentioned:\n\u201cThese groups appear to be soliciting action for their hate. To some extent, they seem pretty\nkeen on doing something about the groups they hate and are actively sharing/liking posts to\npromote action\u201d\n(2)Educators: Educators have distinctively high amount of extremist content in their link\nsharing. On an average, 50% of their links come from extremist domains. Additionally, the\nextremist links posts get more likes and comments compared to other material on these\npages/groups. They post the extremist content with consistently high rates (trend feature > 0)\nthroughout the six months. In qualitative evaluation, the experts pointed out that these groups\nshare intellectual material and appear serious and sincere in propagating the fundamentals\nof extremist ideologies. The evaluators also suggested alternate labels such as \u201cpreachers\u201d\nand \u201cintellectuals.\u201d According to one evaluator:\n\u201c...they seem to take effort to make logical arguments. They are not necessarily showing\nanger towards other groups but are instead more focused on highlighting their own group\u2019s\nworth logically/analytically\u201d\n(3)Flamers: These accounts spew toxic and inflammatory content. Around 5% of their links\nbelong to extremist domains and the messages on the links and the link text itself often\ncontains language suggesting anger and injustice. In other words, these pages/groups have\nthe highest proportion of anger and injustice related words while disseminating extremist\ncontent. The extremist links posted on these accounts get higher number of shares compared\nto the rest of the content. The experts also described them them as \u201cfear mongerers\u201d for\nattempting to cause general outrage. Immediately after looking through the posts, one\nevaluator commented:\n\u201cthese are clearly very strong, divisive and toxic posts\u201d\n(4)Motivators: Around 7% of the links by motivators are sourced from extremist domains.\nEvaluators pointed out that motivators use exceptionally positive language. While posting\nextremist content, they stress on the achievements and rewards associated with extremist\nactivities. Motivators also express opinions with highest proportions compared to the other\nroles. Experts noted that these accounts engage in policy activism focusing on policies\nprotecting and defending cultural and moral values. Evaluators also mentioned:\n\u201cit almost looks like they are celebrating the in-group [people and organization involved in\nthe extremist movement] and the sensationalized news about the in-group\u201d\n(5)Sympathizers: These accounts post extremist content links with lowest rates (2% of their\nFacebook link posts) and sporadically throughout the six month period. They also show low\nengagement in terms of likes, shares and comments on the extremist link posts. According to\nthe experts, these groups are on the fringe of extremist ideology and might be only slightly\ninterested in extremist causes. Experts also referred to them as \u201cobservers.\u201d One evaluator\ndescribed sympathizers as:\u201cThey look more like general conservative interest groups\u201d\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:17\n0.30T1\nT2\nT3\nT4\nOriginal cluster \ncenters in T1Re-assigning roles to \naccounts in T2, T3, T4 \nseparately based on \noriginal cluster \ncenters in T1Role \nassignments for \nT1, T2, T3,T4Flamer\nFlamer\nFlamer\nsympathizer\nHow long do \naccounts retain \ntheir origin roles  ?18 \nmonthsFlamer\nFlamer\nFlamer\nsympathizer\nHow likely are the \naccounts to \ntransition into other \nroles?Flamer\nFlamer\nFlamer\nsympathizer\n(a) (e) (d) (c) (b)\nFig. 2. Figure showing method steps for analyzing role dynamics. (a) We identified cluster centers for each\nrole in RQ1 using the account activity in \ud835\udc471(Jan 2018-Jun 2018). (b) We use those cluster centers identified in\n\ud835\udc471and re-assign extremist accounts to roles based on their activity in \ud835\udc472,\ud835\udc473and\ud835\udc474. (c) For every account in\nthe dataset, we get cluster assignments for all time periods. (d) To measure role retention, we calculate the\nnumber of time periods for which the extremist accounts maintain their original roles from \ud835\udc471. (e) In role\ntransition, we calculate the probability with which the extremist accounts may transition to different roles.\nNotes on Expert Evaluation: Manually evaluating and labeling roles is a challenging but an\ninsightful task. Interpreting clusters and finalizing the role labels was an iterative, discursive process.\nSome roles were easy to identify and label (for example, solicitors ,educators andflamers ) while\nothers required going over additional details such as page/group names and their descriptions. For\nexample, while the experts reached at immediate consensus for the flamers role, they deliberated\nover the motivators category. However, qualitative evaluation provided additional insights about the\nclusters that were not apparent from the original feature set. For example, we found that accounts\nin the flamers category had higher amount of posts flagged as misinformation or violent/graphic\ncontent. Similarly, educators shared links containing material describing extremist philosophies\n(for example, white identity, ethnocentrism, political philosophy) than rest of the accounts. Note\nthat such nuances are harder to capture computationally and further extensive qualitative study of\nthese pages might provide new theoretical insights about actors in online extremist movements.\n6 RQ2 METHOD: MEASURING ROLE DYNAMICS\nThe roles we identify are data-driven. The underlying characteristics of the roles are derived mainly\nfrom the theoretical studies on physical protest events. Unlike physical social movements where\nmembers can commit to protests, meetings or other events, social media provides a dynamic,\nevolving space for members to engage or disengage from the social movement as they like without\nmuch accountability [ 10]. Hence, we also analyze the dynamics of roles based on how long the\naccounts retain their initial roles (role retention) and their transition probability to another role (role\ntransition). Figure 2 displays the method steps taken to measure role retention and role transition.\nRQ2a: Measuring Role Retention: By retention, we measure how long the extremist accounts\nadhere to their originally identified roles. Recall that our data spanning two years (Jan\u201918 to Dec\u201919)\nis sliced into four windows, each six months duration\u2014 \ud835\udc471,\ud835\udc472,\ud835\udc473,\ud835\udc474(Figure 1 (b)). We initially\nidentified roles in RQ1 using the account activity in the first time period, \ud835\udc471(Jan 2018 - Jun 2018).\nTo measure role retention, we use the cluster centers (mean values for each feature for each cluster)\nfrom\ud835\udc471and re-assign roles to the extremist accounts using their activity in \ud835\udc472,\ud835\udc473,\ud835\udc474. For every\nextremist account, we now have the role assignment for \ud835\udc471,\ud835\udc472,\ud835\udc473, and\ud835\udc474. For example in Figure 2\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:18 Anonymous Authors\n6% 25%\n19%32%26%12%\n37%9%21%9%\n42%2%4%70%66% 3%\n9%\n49%\n57%\n3%sympathizersmotivators\ufb02amerssolicitorseducators\nleast \nretentionmost \nretentionT1 T4 T1T3 T1T2 T1Percent accounts retaining their \nroles through:\n(a)\neducatorsrole in Tirole in Ti+1\neducatorssolicitors\nsolicitors\ufb02amers\n\ufb02amersmotivators\nmotivatorssympathizers\nsympathizers0.79\n0.730.660.390.29\n0.010.12 0.020.04\n0.13 0.180.100.160.090.03\n0.070.090.570.06\n0.01\n0.050.06\n0.010.01 0.30 (b)\nFig. 3. Figure presenting the results of RQ2. (a) indicates role retention\u2014proportion of extremist accounts\nthat retain their originally identified role through subsequent time windows in the dataset. For example, 70%\nof the solicitors retain their role throughout \ud835\udc471\u2192\ud835\udc474. Whereas 49% of flamers retain their roles for only the\ninitial\ud835\udc471period. (b) displays the role transition probability matrix. Rows indicate the role in \ud835\udc47\ud835\udc56and columns\nindicate the role in \ud835\udc47\ud835\udc56+1. The cells indicate the probability of transition from role in \ud835\udc47\ud835\udc56to\ud835\udc47\ud835\udc56+1. For example,\nsolicitors may transition to educators in the next time period with 0.29 probability.\n(c), an account stays in the flamer role for three consecutive time periods. That is, the role identified\nin\ud835\udc471is retained for (3 X 6) 18 months consecutive months. Note that all time windows \ud835\udc471,\ud835\udc472,\ud835\udc473,\nand\ud835\udc474represent distinct calendar months between 2018 and 2019 as displayed in Figure 1(b). Using\nthe initially defined cluster centers in \ud835\udc471allows us to compare the accounts\u2019 activities in \ud835\udc472,\ud835\udc473,\n\ud835\udc474with respect to their own past states. How long do extremist accounts adhere to their initially\nidentified role in \ud835\udc471over the subsequent future time windows? To answer, we calculate the number\nof continuous time windows across which an account retains its initially identified role. Finally, for\neach role, we calculate the proportion of accounts maintain their roles across just one ( \ud835\udc471), two\n(\ud835\udc471\u2192\ud835\udc472), three (\ud835\udc471\u2192\ud835\udc473) or all four ( \ud835\udc471\u2192\ud835\udc474) time windows.\nRQ2b: Measuring Role Transition: How likely are the extremist accounts to move from one role\nto another? For example, how likely are sympathizers \u2014fringe supporters of the extremist movement\u2014\nto transition to educators \u2014accounts that actively distribute large proportion of extremist content?\nFrom the role retention analysis, we know which role every extremist account plays in each of the\ntime windows\u2014 \ud835\udc471,\ud835\udc472,\ud835\udc473,\ud835\udc474. For every account, we consider the role played by that account in a\nparticular time window \ud835\udc47\ud835\udc56as the state\ud835\udc46\ud835\udc56that account is in. Consequently, for every account we have\nsequence of four states corresponding to each of the time windows. The example account in Figure 2\n(e) has states: flamer\u2192flamer\u2192flamer\u2192sympathizer . Using such state sequences of all extremist\naccounts, we then calculate the state transition, or the role transition probability. Specifically, we\ncalculate the pairwise transition probabilities for each pairs of roles. High probability of transition\nsolicitor\u2212\u2192educator will indicate that an account currently playing the role of solicitor is likely to\ntransition into educator in the next time window with high probability.\n7 RQ2 RESULTS: ROLE DYNAMICS\nRQ2a: Retention: Figure 3 (a) displays the initial roles (rows) and number of time periods ( \ud835\udc471,\ud835\udc472,\n\ud835\udc473,\ud835\udc474) for which the role was retained by an account. We find that 66% of the educators and 70%\nof the solicitors retain their initial role for all four time periods, that is for the entire two years.\nWhereas, 49% of the flamers and 57% of motivators transition to another role just after \ud835\udc471(6 months).\nEducators andsolicitors can be viewed as an elite group in extremist movements\u2014members who\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:19\nsolicitor\n\ufb01rst link postpage 1\ncontent of the link posted on Facebookpage 4\npage 3page 2\neducator\n\ufb02amer\nmotivator\nsympathizer\n9:59 PM\n(06/10/18)10:26 PM\n(06/10/18)10:11 PM\n(06/10/18)10:02 PM\n(06/10/18)\n(a) (b)William Gheen\nPresident of\nAmericans for Legal\nImmigration\nAgainst Amnesty\nWe support Anti-\nillegal Immigration\nLawsStop Utah's \nAmnesty for illegal\nAliens\nFig. 4. An example illustrating a series of link posting events by accounts playing various roles (a) Contents of\nthe link hosted on the website of an SPLC designated anti-Immigration group ALIPAC. This link contains call\nfor action against stopping immigrant amnesty deal in California (b) series of link posting events on Facebook\ndemonstrating how a link from an extremist website flows through various accounts playing roles in extremist\nmovements. The link was first posted on a Facebook page of the president of the ALIPAC (page 1). Next, the\nlink was posted by various accounts\u2014Against Amnesty (page 2), We support Anti-illegal Immigration Laws\n(page 3) and Stop Utah\u2019s Amnesty for illegal Aliens (page 4)\u2014playing various roles. This example demonstrates\na series of 4 events\u2014link posts by solicitor ,flamer ,sympathizer andsolicitor accounts.\ndistribute (information) resources and actively recruit others [ 46]. On the other hand, flamers and\nmotivators are supporters who exhibit low engagement with the links from extremist websites. Our\nresults suggest that roles more core to the extremist movement such as educators andsolicitors ) are\nmore stable. In other words, educators andsolicitors ) are more likely to maintain their roles and\nconsequently their behaviour surrounding the participation in extremist movements for longer\nperiods compared to others.\nRQ2b: Transition: Figure 3 (b) displays a transition matrix for roles. The values in the cell indicate\nthe probability by which an account in one role (row) would transition to another (column) in the\nnext six months. Based on the main diagonal, accounts in most role are more likely to retain the\nsame role in the next time window. For example, educators will stay educators in the next six months\nwith 0.79 probability. Similarly the probability of flamer\u2212\u2192 flamer is 0.57. Notably, solicitors\nandeducators \u2014roles with highest engagement with links from extremist websites\u2014have highest\ntransition probabilities with each other compared to any other roles ( solicitor\u2212\u2192educator =0.29\nandeducator\u2212\u2192solicitor =0.12). Moreover, flamers andmotivators can transition to sympathizers\nwith 0.30and 0.66probabilities respectively, indicating that roles with less engagement with\nextremist content are also less stable.\n8 RQ3 METHOD: INFLUENTIAL ROLES IN INFORMATION SHARING\nIn RQ1 we identified five roles in extremist movements\u2014 educators ,solicitors ,flamers ,motivators\nandsympathizers . In RQ2, we measured the dynamics of the roles over time. How influential are\nthese roles in disseminating information? Previous research suggests that terrorist organizations\nsuch as ISIS are able to mobilize information through series of online accounts that knowingly or\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:20 Anonymous Authors\nunknowingly play a role in advancing terrorist propaganda [ 38]. Researchers observed a similar\npattern of participatory information sharing in political disinformation campaigns [ 76]. In this\nresearch question, we model the information sharing by various roles to investigate how influential\ndifferent roles are in spreading extremist content, fake news, biased news and conspiracy sources. We\nopen up by a motivating example describing how information crucial to the extremist causes flows\nthrough various roles online. Next we describe the method details for modeling the information\nflow using Hawkes process and inferring influence.\n8.1 Call for Shutting Down the Amnesty Deal: A Motivating Example\nOn June 10th 2018, ALIPAC\u2014an anti-Immigration political action organization [ 69]\u2014put out a call\nfor action to stop amnesty deal for immigrants in California (Figure 4 (a)). This included call for\ndonations, and participation to help support ALIPAC\u2019s operational costs. A link containing this call\nfor action was posted on Facebook on the same day at 9:59 PM by a verified page managed by the\npresident of ALIPAC (page 1 in Figure 4 (b)). This Facebook verified page is also known for posting\nfake news from websites hosting plagiarized content [ 32]. According to our RQ1 analysis, this page\n(page 1) plays the role of solicitor . Three minutes after the initial post by page 1, another Facebook\npage\u2014identified as flamer \u2014posted the same link. Following the post by page 2, a sympathizer page\n(fringe supporter of the extremist content) as well as another recruiter page also posted the same\nlink. Following these four link posts, another 32 pages posted the same link containing the call for\naction by an anti-Immigration group over the period of next three days. How influential was page 1\nin spreading this link containing the call for action? How influential are recruiters or other roles in\nspreading the extremist content or other types of information? In the next section, we explain our\ninformation flow model that considers both temporal order of link posts and the time difference\nbetween consecutive link posts to statistically establish the influence of different roles in spreading\nlinks from various types of sources.\n8.2 Intuitive Background for Measuring Influence in Link Sharing\nOur primary goal here is to understand how influential roles are in spreading information from\nvarious types of sources. By influence , we measure the probability by which a link posting by one\nrole affects link posting by other roles in future. To measure the influence of various roles, we use\nmultivariate Hawkes process which is commonly used for modelling events on social media [ 23,91].\nFor example, Zannettou et. al. used Hawkes process to understand the influence of various online\nplatforms (Reddit, Twitter, 4chan) on each other in information sharing [ 91]. Hawkes processes are\npopularly used as a more sophisticated model for measuring influence compared to simple point\nprocesses [ 16,65]. Specifically, Hawkes process can account for various nuances in information\nsharing. For example, while calculating influence, Hawkes process considers the temporal flow of\nlink sharing, the time between consecutive link posts and the natural link posting tendencies of\nvarious roles involved. In its simplest form, modeling link sharing by different roles using Hawkes\nprocess can provide us with two parameters: (1) the natural link sharing tendency of the roles or\nbackground rate and (2) the pairwise influence that roles exert on each other in link sharing.\nMore formally, consider an event where a solicitor posts a link. This event can affect the proba-\nbility by which other roles (for example, symapathizers ) also post the same link in future. In other\nwords, link posting by one role might increase the probability of the link posting by another role.\nThe effect of previous events on the current event is additive and decaying. This means that, as\nmore time passes between two events, the lesser impact the previous events will have on the current\nevent. For each link, we extract such series of events (sequence of timestamps indicating the link\nposting by extremist accounts in various roles). Next, we provide the details for fitting Hawkes\nprocess on the extracted series of events.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:21\n8.3 Fitting Hawkes Process on Link Posting Events\nA multivariate Hawkes model consists of K processes each with a background rate of \ud835\udf060,\ud835\udc58. Fitting a\nHawkes model on link sharing by five roles will give us the background link posting rates for each\nrole\u2014probability of an event cased by external factors\u2014as well as the probabilistic estimate of the\neffect of the roles on each other. We use a discrete-time Hawkes model which is commonly used for\nmodeling information flow on social media [ 91]. For each link, the time of posting is divided into\ndiscrete time bins of duration \u0394\ud835\udc61, creating a series of events with time granularity of \u0394\ud835\udc61. Fitting\nHawkes model on this series of events will give us estimates for the background rate of \ud835\udf060,\ud835\udc58and\npairwise weight matrix \ud835\udc4a\ud835\udc3e\u00d7\ud835\udc3e. Appendix A.5 provides the formal mathematical representation of\nHawkes process along with its parameters.\nFor our analysis, the weight matrix \ud835\udc4a\ud835\udc3e\u00d7\ud835\udc3eis most relevant. Every value \ud835\udc64\ud835\udc56,\ud835\udc57in the weight matrix\n\ud835\udc4a\ud835\udc3e\u00d7\ud835\udc3esignifies the expected number of subsequent events that will be caused in the process \ud835\udc57after\nan event in the process \ud835\udc56. In other words, value in weight matrix \ud835\udc4ai\u2192jindicates the strength with\nwhich a link posting event by role \ud835\udc56can affect link posting by role \ud835\udc57[91]. We consider these weights\nas a proxy for influence of role\ud835\udc56on role\ud835\udc57. Note that weights from \ud835\udc4adescribe the expectations\nof event occurrence above the background rate \ud835\udf060,\ud835\udc58of the process where background rate \ud835\udf060,\ud835\udc58\naccounts for events due to external factors.\n8.4 Measuring Influence in Link Sharing\nTo understand the influence of roles, we consider the link posts made by the extremist accounts\nin\ud835\udc471(Jan 2018-Jun 2018) and consider the role identified for every extremist account in RQ1. We\nassess the influence of roles by using the weight matrix \ud835\udc4adescribed in the previous subsection.\nTo calculate the weight matrix, we first need to determine the number of processes ( \ud835\udc3e) and the\nlength of discrete time windows \u0394\ud835\udc61to bin every link posting event. Since we aim to examine how\ninfluential various roles are, we model the link postings with K=5 processes\u2014one for every role\nidentified in RQ1. To select \u0394\ud835\udc61, we plotted the distribution of inter arrival times\u2014time in seconds\nbetween two consecutive link posting events\u2014for all links. The goal for choosing \u0394\ud835\udc61is to have a\nseparate bin for most events. We decided \u0394\ud835\udc61=30\ud835\udc60\ud835\udc52\ud835\udc50based on the 10\ud835\udc61\u210epercentile cut-off of the\ndistribution. Choosing this percentile cut-off allows us to put approximately 91% of the link posting\nevents in the bin by themselves. To eliminate links that are shared less, we select links that are\nshared by atleast 10 different extremist accounts spanning over atleast 3 of the 5 identified roles.\nNext, we fit a Hawkes model for each link using a nonparametric Expectation Maximization (EM)\nfor parameter estimation [ 41]. With the EM algorithm we are able to get the background rate ( \ud835\udf060,\ud835\udc58)\nas well as the weight matrix \ud835\udc4adescribed in the previous subsection. Both, background rates for\neach role and the weight matrix, contain non-negative real values. We further row normalize the\nweight matrix to represent the influence of a role in a row on the role in a column with values bound\nbetween 0 to 1. Note that so far we have calculated the weight matrix \ud835\udc4afor each link separately.\nIn other words, for each unique link, we obtain pairwise influence values for roles. Remember that\nin Section 3.5, we recorded link domain types as extremist, biased, fake or conspiratorial based on\nthe OpenSources annotations. Here, we calculate the overall weight matrix for each domain type\nby averaging the weight matrices of links based on their domain types. For example, to obtain the\noverall influence of roles in spreading links from fake news domains, we consider all links that are\ngenerated from fake news domains and calculate the average of their weight matrices. In the next\nsection, we discuss our results and influential roles in spreading links from extremist, biased, fake\nnews and conspiracy domains.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:22 Anonymous Authors\nsource type#domains\nlabeled#labeled domains\npresent in\ud835\udc471#unique\nlinks#events\n(link posts)% link posts made by\nsolicitors educators flamers motivators sympathizers\nextremist 289 231 758 16,532 12% 28% 9% 5% 44%\nbiased 133 94 1279 13,290 11 9% 19% 23% 36%\nfake 304 107 380 3583 9% 20% 23% 13% 34%\nconspiracy 154 68 936 10,001 20% 20% 10% 21% 29%\nTable 4. Table describing link posting activities by various roles. We first report the number of labeled domains\nin each category\u2014extremist, biased, fake and conspiracy and also specify how many of those domains are\npresent in the link posts made in \ud835\udc471. Next, we list the number of unique links and the number of link posting\nevents for each source type. We also report what percent of such link posting events were made by various\nroles. For example, solicitors contribute to 12% of the link posts from the extremist domains.\n9 RQ3 RESULTS: INFLUENTIAL ROLES IN INFORMATION SHARING\nWe summarize the number of links and number of link posting events generated for each type of\ninformation in Table 4. Looking at the number of events, sympathizers make up largest percent of\nlink posting events in all source types. This is not surprising given that 36.4% of the accounts are\nsympathizers . Along the same lines, solicitors \u2014who actively solicit participation by posting extremist\nlinks and educators \u2014who share largest proportion of extremist links\u2014contribute to high percent of\nevents in posting extremist links. Interestingly, flamers \u2014accounts that often post inflammatory and\nviolent content\u2014are also second highest in posting links from the fake news sources. Moreover,\nmotivators \u2014who focus on efficacy of policy changes and use opinionated language, make up 23%\nof the biased news posting events. Interestingly, solicitors ,educators ,motivators andsympathizers ,\nall post links from conspiracy sources with similar rates.\nRemember that we obtained weight matrix \ud835\udc4aby fitting a Hawkes model for links from every\nsource type. We report the weight matrices for four source types in Figure 5. Value in weight\nmatrices, for example, ( \ud835\udc4asolicitor\u2192educator =0.11in Figure 5 (a)) indicates the strength with which\nsolicitors may trigger information sharing by educators account. For all source types, the self weights\nfor roles (for example, \ud835\udc4asolicitor\u2192solicitor =0.35in Figure 5 (a)) are highest. In other words, the main\ndiagonal in all weight matrices in Figure 5 have the highest values. This means that extremist\naccounts in one role are more likely to trigger information sharing by other extremist accounts in\nthe same role. This may be because the the accounts in the same role also share large number of\nsame links. Note that the values for weights reported in Figure 5 are typical of influence values\nobserved in information sharing on social media [91].\nExtremist Domains: In all, we had listed 289 extremist website domains. Here, we analyze how\nimportant every role is in posting links from extremist domains in Facebook. Figure 5(a) displays\npairwise influence of roles on each other. For example, the value of \ud835\udc4a\ud835\udc60\ud835\udc5c\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc56\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60\u2192\ud835\udc60\ud835\udc66\ud835\udc5a\ud835\udc5d\ud835\udc4e\ud835\udc61\u210e\ud835\udc56\ud835\udc67\ud835\udc52\ud835\udc5f\ud835\udc60 =0.21\nindicates how likely the link posting by solicitors will trigger the link posting by sympathizers .\nFrom RQ1 analysis, we know that solicitors and educators post large proportion of links from\nextremist websites. However, their higher influence on other roles indicates that they also trigger\nthe spread of extremist content by other roles. Figure 8 in Appendix displays a post by an educator\naccount citing a link from extremist domain discussing white identity. The link cited in this post is\nhighly education in that it describes the constructs of white identity and implores the reader to not\nengage in interracial relationships. Surprisingly, flamers also have higher influence compared to\nsympathizers (0.13) and motivators (0.11). Overall, these results indicate that solicitors ,educators ,\nandflamers are most influential in spreading links from extremist sources.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:23\n0.010.310.35\n0.30\n0.25\n0.20\n0.15\n0.10\n0.05\n0.010.020.350.010.03\n0.06\n0.370.010.02\n0.330.01 0.01\n0.110.14\n0.21\n0.130.240.11\n0.020.020.010.110.02educators\nsolicitors\nmotivators\nsympathizers\n\ufb02amerseducators solicitors motivators sympathizers \ufb02amers\n(a) Extremist sources\n0.040.240.35\n0.30\n0.25\n0.20\n0.15\n0.10\n0.05\n0.010.010.150.010.03\n0.01\n0.230.050.07\n0.220.06 0.04\n0.010.04\n0.03\n0.030.140.04\n0.010.030.070.020.02educators\nsolicitors\nmotivators\nsympathizers\n\ufb02amerseducators solicitors motivators sympathizers \ufb02amers (b) Biased sources\n0.020.140.35\n0.30\n0.25\n0.20\n0.15\n0.10\n0.05\n0.120.010.090.110.03\n0.01\n0.080.030.01\n0.230.01 0.01\n0.010.04\n0.01\n0.020.160.07\n0.060.10.020.010.09educators\nsolicitors\nmotivators\nsympathizers\n\ufb02amerseducators solicitors motivators sympathizers \ufb02amers\n(c) Fake news sources\n0.010.260.35\n0.30\n0.25\n0.20\n0.15\n0.10\n0.05\n0.010.010.260.020.02\n0.02\n0.340.020.01\n0.250.04 0.02\n0.020.05\n0.05\n0.030.230.07\n0.030.020.020.040.02educators\nsolicitors\nmotivators\nsympathizers\n\ufb02amerseducators solicitors motivators sympathizers \ufb02amers (d) Conspiracy sources\nFig. 5. Figure displaying the pairwise influence matrix for each type of source. The value of\n\ud835\udc4a\ud835\udc60\ud835\udc5c\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc56\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60\u2192\ud835\udc60\ud835\udc66\ud835\udc5a\ud835\udc5d\ud835\udc4e\ud835\udc61\u210e\ud835\udc56\ud835\udc67\ud835\udc52\ud835\udc5f\ud835\udc60 =0.21in (a) indicates how influential solicitors are in triggering extremist in-\nformation sharing by sympathizers . We have used divergent color palette to distinguish between the smaller\nnon-diagonal values that are of most relevance while discussing the results.\nBiased Domains: As per OpenSources, biased news category contains sources that hold a specific\npoint of view and may rely on propaganda, decontextualizing information and opinions distorted\nas facts11. For example, OpenSources.co lists 100percentfedup.com and dailywire.com as biased\nsources. While 100percentfedup.com selects stories with extreme right wing bias12,dailywire.com\nis strongly biased toward conservative causes and/or political affiliation13. Overall, the influence\nof all roles is lower while sharing links from the biased sources. However, in comparison to other\nroles, motivators are more influential in triggering biased information posting by other roles\n(\ud835\udc4a\ud835\udc5a\ud835\udc5c\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60\u2192\ud835\udc52\ud835\udc51\ud835\udc62\ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60 =0.07,\ud835\udc4a\ud835\udc5a\ud835\udc5c\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60\u2192\ud835\udc60\ud835\udc66\ud835\udc5a\ud835\udc5d\ud835\udc4e\ud835\udc61\u210e\ud835\udc56\ud835\udc67\ud835\udc52\ud835\udc5f\ud835\udc60 =0.05)\nFake News Domains: According to OpenSources, fake news sources entirely fabricate information\nor grossly distort actual news reports. In the qualitative evaluation with experts, we had observed\nthat flamers post links that are flagged as fake/misinformative by Facebook fact checkers. Through\nweight matrix in Figure 5 (c) we quantitatively observe that flamers have higher influence on\nsolicitors (0.12) in spreading links from fake news sources. Figure 9 in Appendix displays how\nflamers might be posting fake news to spread hate and outrage. Interestingly, educators are also\ninfluential in spreading fake news to solicitors (\ud835\udc4a\ud835\udc52\ud835\udc51\ud835\udc62\ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60\u2192\ud835\udc60\ud835\udc5c\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc56\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc60 =0.11). However, it should\nbe noted that fake news sources have lowest number of links and link posting events amongst\nall source types (Table 4). Overall, based on the weight matrix, flamers and educators are most\ninfluential in spreading links from fake news sources.\n11https://douglasducote.com/wp-content/uploads/2019/05/OpenSources.pdf\n12https://mediabiasfactcheck.com/100-percent-fed-up/\n13https://mediabiasfactcheck.com/the-daily-wire/\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:24 Anonymous Authors\nConspiratorial Domains: Sympathizers are most susceptible to conspiracy information from\nsolicitors (0.05) and educators (0.05). Similarly, flamers are susceptible to conspiratorial information\nsharing by motivators (0.07). The weights in the Figure 5 (d) indicate that solicitors ,educators and\nmotivators are most influential in disseminating links from conspiratorial sources.\n10 DISCUSSION AND IMPLICATIONS\nIn this work we identify 5 functional roles in online extremist movements and investigate which roles\nare influential in spreading links from extremist, biased news, fake news and conspiracy sources.\nOur results can offer insights into how participatory activism advances extremist movements, how\nvarious roles are located on the pathways to deeper engagement into extremism, and what could\nbe the possible effects of interventions in countering online extremism undertaken by these roles.\n10.1 Online Extremist Movements and Participatory Activism\nScholars have attributed the advancement of social movements to the successful distribution of\nresources through its participants [ 46]. We observe that through participatory activism, extremist\naccounts, in various roles, adequately use social media to spread various types of information\nresources. For example, educators andsolicitors dedicate a large proportion of their Facebook activity\nto distributing extremist content for educating and soliciting the readers into extremist movements.\nMoreover, the results of our third research question suggest that they also influence other roles\nin spreading information from extremist websites. In sum, by disseminating information through\ntheir Facebook accounts, mass educating the readers about their agenda, and soliciting funds and\nparticipation in the movements, educators andsolicitors are creating human and material resources\n[46]. Moreover, by prominently sharing misinformative content and using toxic language, flamers\nmay be raising emotional resources that create opportunities for public outrage and eventually,\ncollective action [ 84] to advance the hateful agendas of their extremists movements. This dis-\ntributed system of online information mobilization\u2014distribution of various information resources\nthrough various roles online\u2014can be compared to the democratization process in participatory\nactivism [ 38]. The digital democratization process specifically consists of more equitable sharing\nof informational resources amongst the participants [ 7]. For example, by influencing other roles\nin sharing links from extremist domains, solicitors andeducators are also empowering others with\nthose extremist information. Take for example, the Facebook page of Alliance Defending Freedom\n(ADF)\u2014an educator account in our study, representing a leading anti-LGBTQ organization [ 73]\nthat the Southern Poverty Law Center has tracked for decades. This organization started with a\nsmall group of christian leaders advocating for discredited practice of conversion therapy, crimi-\nnalization of LGBTQ sexual acts and opposition to the transgender rights. ADF started with 84K\nFacebook page likes in 2012. Today, ADF\u2019s Facebook page has over 1.7 million page likes and over\n1.6 million followers. Our dataset also revealed that over 1K other Facebook groups and pages\nhave already shared content linking to ADF\u2019s website. With 1.6 million direct followers on the\nADF\u2019s official Facebook page and an additional indirect exposure to users through shares on other\nFacebook pages, the material created by ADF is able to reach a vast audience. This may suggest\nthat, through participatory activism, the picture of online extremism has now shifted from a few\nselected radical websites and accounts to a spectrum of allies with access to extremist information\nand the affordances to share it with the mass.\n10.2 Theoretical Implications: Parallels Between Theoretical and Online Roles\nSome of our roles correspond to the categories of participants identified in theoretical research\nbased on physical protest events and social movements. For example, the educators \u2014accounts that\nprimarily focus on distributing links from extremist domains\u2014may correspond to \u201cconstituents\u201d as\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:25\ndescribed by McCarthy and Zald [ 46]; \u201cconstituents\u201d are primary distributors of resources. Similarly,\noursolicitors \u2014who actively solicit participation via donations and gatherings\u2014may correspond\nto \u201cbeneficiary constituents\u201d [ 46] who stand to gain from the success, funds, and connections\nemerging from the movement. The sympathizers category may be similar to \u201cbystanders\u201d\u2014a group\nof third-party participants, as defined by Turner et. al. [ 80], who might acknowledge grievances\nrelated to the issues of social movement and take a sympathetic stand. However, the motivator\nrole does not resemble any of the theoretically described categories. We believe that the motivator\nrole is specifically relevant in the online setting for relaying positive news and wins related to the\nextremist causes. Additionally, flamers also do not correspond to any theoretical roles. Through our\ndata driven methods, we are able to surface these new roles that characterize online participation\nin extremist social movements. We believe that our framework for identifying roles based on the\ncharacteristics of participation can be extended to other social movements as well. For example,\nstudies investigating positive social movements, such as environmentalist movement, can adopt\nour methodologies and identify roles and their influence in popularizing environmentalist agenda.\n10.3 Trajectories of Extremist Movement Participation\nKlandermans et. al. proposed a trajectory of social movement participation comprising four steps\n[36,37]. First, people must sympathize with the ideals and goals of the movement, thus turning\ninto potential targets for mobilization. Next, they must be targeted by core members\u2019 mobilization\nattempts. Next, they must develop motivation to participate in the movement and finally over-\ncome possible barriers and engage in collective action [ 77]. Through our analysis, we identify a\ngroup of accounts played the role of sympathizers \u2014pages/groups expressing sympathy towards\nthe extremist causes without getting heavily involved. 36.4% of the accounts in our dataset are\nsympathizers . Based on Klandermans\u2019s models, sympathizers can also be viewed as the biggest\npotential group of supporters for the extremist movements. Interestingly, we also see that educators ,\nsolicitors , and flamers have high influence on sympathizers in spreading extremist content (Figure 5\n(a)). This is the second step in the Klandermans\u2019s model, whereby sympathizers are targeted for\nmobilization. In other words, sympathizers may lie on the first two steps of the Klandermans\u2019s\ntrajectories of participation. The third step consists of participants who have developed motivation\nfor participating. The flamer andmotivator roles are primarily driven by motivating factors such as\nanger, injustice, and the sense of achievement. Hence, flamers andmotivators might be on the third\nstep of Klandermans\u2019s trajectory. Finally, we believe that solicitors andeducators are on the last\nstep of the participation trajectory as they actively try to educate and proselytize others through\ncollective action. In summary, based on Klandermans\u2019s comprising, developing sympathy \u2192getting\ntargeted by mobilization \u2192developing motivation \u2192collective action , is equivalent to the following\nrole transitions: sympathizers\u2192(flamers ormotivators )\u2192(educators orsolicitors ), which together\nrepresents a trajectory of deeper engagement into the extremist movements online. Can targeted\ninterventions for counter-extremism stop users from getting induced into the deep trenches of\nextremist movements? Below, we discuss which roles could potentially benefit from interventions\ndesigned for countering online extremism.\n10.4 Practical Implications: Interventions for Online Extremism Engagement\nWhile this study focuses on identifying roles, it can also inform the design of interventions for\ncountering extremism. Our results suggest that while accounts core to the extremist movements\u2014\neducators andsolicitors \u2014tend to retain their roles, others are more likely to transition to different\nroles. For example, flamers andmotivators become sympathizers with high probability. Flamers ,\nmotivators andsympathizers also show more sporadic engagement with sharing extremist links\ncompared to the educators and solicitors . A study by Siegel and Badaan revealed that targeted\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:26 Anonymous Authors\ninterventions against hate speech, such as sanctions on hateful messages, leads users to tweet less\nhateful content, especially if the individuals are less engaged with the hate speech in the first place\n[71]. On the other hand, accounts that frequently see or produce hostile language are less likely to\nget deterred by sanctions and may even express backlash [ 71]. Other researchers also report that\nrather than conforming to the community norms upon receiving sanctions, the producers of hostile\ncontent are more likely to move to other platforms [ 50] or find creative ways of continuing their\nhate speech [ 8]. For example, recall that the Facebook page, Pissed off White Americans , described\nin the Introduction, shared videos that are now banned on YouTube. However, they still made\nthe extremist videos available to the readers by hosting them on bitchute.com which has been\ndescribed as the \u201chotbed for violence and hate\u201d [ 1]. Considering this, our results suggest that\nflamers ,motivators andsympathizers \u2014accounts infrequently exposed to extremist content\u2014might\nbenefit most from targeted interventions designed to counter extremism. On the contrary, educators\nandsolicitors may retaliate or relocate to alternate platforms in response to an intervention.\n11 LIMITATIONS AND FUTURE DIRECTIONS\nOur work has some limitations which also open up promising future directions. First, our dataset\ncontains only US-based extremist websites and most hold far-right political ideology. However, this\nskew towards far-right might not correctly represent the political scenarios from other countries.\nFor example, unlike the U.S., Germany has observed increased political violence from both, far-left\nand far-right ideological groups [60]and is known to have a history of violence from both ends\nof the political spectrum [31]. Hence, while applying our study results in the context of other\ncountries, researchers need to be cautious about the distribution of extremist ideologies in our\ndataset. Next, we compiled extremist accounts based on their sharing behavior, specifically the\nnumber of unique links they shared from known SPLC-designated extremist websites. While this is\na common methodological choice made while choosing users/accounts for studying social media\nactivity, a stricter selection criteria can be beneficial. For example, in addition to the frequency of\nthe extremist link posts, extremist accounts can be selected based on the the topics discussed in\nthe posts. Moreover, while our data collection spans the activity of extremist accounts in 2018 and\n2019, it was collected post-hoc, in May 2020. Once a Facebook page/group is banned, its data is\nno longer accessible through CrowdTangle or any official Facebook API. Thus, considering the\nrecent Facebook bans on the white nationalist accounts, our study doesn\u2019t contain the data for\nthe extremist accounts that were active in 2018-2019 but got banned before May 2020. In future,\nresearchers can collect data in real time and extend our study to understand what roles among the\nextremist accounts face highest moderation. Additionally, our RQ2 analysis does not account for\npotential cohort effect. Specifically, in RQ2, we measure role transition for extremist accounts in\nvarious time periods, across 2018 and 2019. While we normalize the features to control for overall\ntrends happening on social media, external events happening between 2018 and 2019 (e.g., a sudden\npopularity of an extremist content or change in the language surrounding issues of extremism)\ncould affect different users differently introducing cohort effects. In future, researchers can adapt\nour methods and extend them to controlled experiments so as to mitigate period and cohort effects.\nMoreover, we observe the influence of various roles in spreading information on Facebook based on\nthe link posting activity in time. Naturally, this approach does not account for the various modes of\ninformation, such as images, memes, screenshots, videos, web articles etc. and how that might effect\nthe role dynamics. Measuring influence for various modes of information can lead to interesting\nfindings such as, which roles are influential in propagating memes related to extremist issues.\nMoreover, our influence measurement is based on the temporal characteristics of information flow.\nA deeper qualitative analysis of link chains and the comments on the links could help establish\ncausal relationship of influence between various roles. Finally, our results reveal the information\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:27\necosystem of extremist movements on just one platform\u2014Facebook. The problem of extremism\nis also evident on other platforms such as Twitter and Gab. Indeed, researchers have shown that\nthe extremist movements leverage different social media platforms towards different goals such as\nradicalization and mass education [ 58]. We encourage future researchers to extend our methods to\nmodel roles in extremist movements on other platforms or even, across the platforms.\n12 CONCLUSION\nIn this work we analyze the online ecosystem of extremist movements through the lens of partici-\npatory activism. Specifically, we identify five social roles in online extremist movements: educators\nsolicitors ,flamers ,motivators andsympathizers . We also investigate the role dynamics and influence\nexerted by roles in spreading links from extremist, fake news, biased, and conspiratorial sources.\nWe not only find that the roles core to the extremist movement ( educators andsolicitors ) are more\nstable but that they also have higher influence on other roles in spreading extremist content. Our\nfindings offer a perspective on how participatory activism might be advancing extremist movements\nand how various roles may be targeted for mobilization. Our results also have implications in\nextending theories of social movement participation and understanding the effectiveness of online\ncounter-extremism strategies.\n13 ACKNOWLEDGMENTS\nThis paper would not be possible without the expert feedback by the entire Pennebaker Language\nLab directed by Dr. James Pennebaker at University of Texas Austin. We also want to acknowledge\nthe valuable feedback from the members of Social Computing Lab at Virginia Tech and University\nof Washington, Seattle. This project was partially funded by the Minerva Research Initiative.\nREFERENCES\n[1]ADL. 2020. BitChute: A Hotbed of Hate | Anti-Defamation League. https://www.adl.org/blog/bitchute-a-hotbed-of-hate.\n(Accessed on 10/14/2020).\n[2]ADL. 2020. Who We Are | About Anti-Defamation League | ADL. https://www.adl.org/who-we-are. (Accessed on\n10/15/2020).\n[3]Ofer Arazy, Hila Liifshitz-Assaf, Oded Nov, Johannes Daxenberger, Martina Balestra, and Coye Cheshire. 2017. On\nthe\" how\" and\" why\" of emergent role behaviors in Wikipedia. In Proceedings of the 2017 ACM Conference on Computer\nSupported Cooperative Work and Social Computing . 2039\u20132051.\n[4]Balca Arda. 2015. The construction of a new sociality through social media: The case of the Gezi uprising in Turkey.\nConjunctions. Transdisciplinary Journal of Cultural Participation 2, 1 (2015), 72\u201399.\n[5]Prakhar Biyani, Cornelia Caragea, Prasenjit Mitra, and John Yen. 2014. Identifying emotional and informational support\nin online health communities. In Proceedings of COLING 2014, the 25th International Conference on Computational\nLinguistics: Technical Papers . 827\u2013836.\n[6]David G Bromley and Anson D Shupe Jr. 1980. Financing the new religions: A resource mobilization approach. Journal\nfor the Scientific Study of Religion (1980), 227\u2013239.\n[7]William K Carroll and Robert A Hackett. 2006. Democratic media activism through the lens of social movement theory.\nMedia, culture & society 28, 1 (2006), 83\u2013104.\n[8]Stevie Chancellor, Jessica Annette Pater, Trustin Clear, Eric Gilbert, and Munmun De Choudhury. 2016. # thyghgapp:\nInstagram content moderation and lexical variation in pro-eating disorder communities. In Proceedings of the 19th\nACM Conference on Computer-Supported Cooperative Work & Social Computing . 1201\u20131213.\n[9]Xi Chen, Shen Zhao, and Wei Li. 2019. Opinion dynamics model based on cognitive styles: field-dependence and\nfield-independence. Complexity 2019 (2019).\n[10] Catherine Corrigall-Brown. 2011. Patterns of protest: Trajectories of participation in social movements . Stanford University\nPress.\n[11] Jacob Davey and Julia Ebner. 2017. The Fringe Insurgency. Connectivity, Convergence and Mainstreaming of the\nExtreme Right. Institute for Strategic Dialogue (http://www. isdglobal. org/wp-content/uploads/2017/10/The-Fringe-\nInsurgency-221017. pdf) (2017).\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:28 Anonymous Authors\n[12] Claes H De Vreese and Hajo Boomgaarden. 2006. News, political knowledge and participation: The differential effects\nof news media exposure on political knowledge and participation. Acta Politica 41, 4 (2006), 317\u2013341.\n[13] Mario Diani. 1992. The concept of social movement. The sociological review 40, 1 (1992), 1\u201325.\n[14] Joan Donovan. 2019. Extremists Understand What Tech Platforms Have Built - The Atlantic. https://www.theatlantic.\ncom/ideas/archive/2019/03/extremists-understand-what-tech-platforms-have-built/585136/. (Accessed on 09/17/2020).\n[15] Bob Edwards and John D McCarthy. 2004. Resources and social movement mobilization. The Blackwell companion to\nsocial movements (2004), 116\u2013152.\n[16] Paul Embrechts, Thomas Liniger, and Lu Lin. 2011. Multivariate Hawkes processes: an application to financial data.\nJournal of Applied Probability 48, A (2011), 367\u2013378.\n[17] Myra Marx Ferree and Frederick D Miller. 1985. Mobilization and meaning: Toward an integration of social psychological\nand resource perspectives on social movements. Sociological Inquiry 55, 1 (1985), 38\u201361.\n[18] Institute for Economics and Peace. 2020. GTI-2020-web-1.pdf. https://www.visionofhumanity.org/wp-content/uploads/\n2020/11/GTI-2020-web-1.pdf. (Accessed on 01/11/2021).\n[19] Tony Formica. 2020. A Social (Media) Contract: Reconciling American Freedom and Security in an Age of Online\nRadicalization and Extremism. Yale J. Int\u2019l Aff. 15 (2020), 131.\n[20] JA Frimer, R Boghrati, J Haidt, J Graham, and M Dehgani. 2019. Moral foundations dictionary for linguistic analyses\n2.0.Unpublished manuscript (2019).\n[21] William A Gamson, William Anthony Gamson Gamson, William Anthony Gamson, and William A Gamson. 1992.\nTalking politics . Cambridge university press.\n[22] Malcolm Gladwell. 2010. Small change. The New Yorker 4, 2010 (2010), 42\u201349.\n[23] Rahul Goel, Sandeep Soni, Naman Goyal, John Paparrizos, Hanna Wallach, Fernando Diaz, and Jacob Eisenstein. 2016.\nThe social dynamics of language change in online networks. In International Conference on Social Informatics . Springer,\n41\u201357.\n[24] Max Halupka. 2018. The legitimisation of clicktivism. Australian Journal of Political Science 53, 1 (2018), 130\u2013141.\n[25] William L. Hamilton, Justine Zhang, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky, and Jure Leskovec. 2017. Loyalty\nin Online Communities. (2017). http://arxiv.org/abs/1703.03386\n[26] Benjamin D Horne, Sibel Adali, and Sujoy Sikdar. 2017. Identifying the social signals that drive online discussions: A\ncase study of reddit communities. In 2017 26th International Conference on Computer Communication and Networks\n(ICCCN) .\n[27] IACP. 2020. Facebook and Violent Extremism Awareness Brief. https://www.theiacp.org/resources/document/facebook-\nand-violent-extremism-awareness-brief. (Accessed on 10/15/2020).\n[28] Kirk Job-Sluder and Sasha A Barab. 2004. Shared\" we\" and shared\" they\" indicators of group identity in online teacher\nprofessional development. Designing for virtual communities in the service of learning (2004).\n[29] NF Johnson, R Leahy, N Johnson Restrepo, N Velasquez, M Zheng, P Manrique, P Devkota, and Stefan Wuchty. 2019.\nHidden resilience and adaptive dynamics of the global online hate ecology. Nature 573, 7773 (2019), 261\u2013265.\n[30] Seth G Jones, Catrina Doxsee, and Nicholas Harrington. 2020. The escalating terrorism problem in the United States.\n(2020).\n[31] Sebastian Jungkunz. 2019. Towards a measurement of extreme left-wing attitudes. German Politics 28, 1 (2019),\n101\u2013122.\n[32] Alex Kaplan. 2018. The head of an anti-immigration PAC runs Facebook pages that share fake news from plagiarized\nsites | Media Matters for America. https://www.mediamatters.org/facebook/head-anti-immigration-pac-runs-facebook-\npages-share-fake-news-plagiarized-sites. (Accessed on 10/15/2020).\n[33] Jessalynn Marie Keller. 2012. Virtual feminisms: Girls\u2019 blogging communities, feminist activism, and participatory\npolitics. Information, Communication & Society 15, 3 (2012), 429\u2013447.\n[34] Makena Kelly. 2020. Facebook still hosts boogaloo extremist groups, report finds - The Verge. https://www.theverge.com/\n2020/8/12/21365278/facebook-boogaloo-tech-transparency-right-wing-extremist-platform. (Accessed on 09/13/2020).\n[35] Makena Kelly. 2020. Facebook still hosts boogaloo extremist groups, report finds - The Verge. https://www.theverge.com/\n2020/8/12/21365278/facebook-boogaloo-tech-transparency-right-wing-extremist-platform. (Accessed on 10/15/2020).\n[36] Bert Klandermans. 1984. Mobilization and participation: Social-psychological expansisons of resource mobilization\ntheory. American sociological review (1984), 583\u2013600.\n[37] Bert Klandermans and Dirk Oegema. 1987. Potentials, networks, motivations, and barriers: Steps towards participation\nin social movements. American sociological review (1987), 519\u2013531.\n[38] Michael Krona. 2019. 5 ISIS\u2019s Media Ecology and Participatory Activism Tactics. The Media World of ISIS (2019), 101.\n[39] Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019. Predicting dynamic embedding trajectory in temporal interaction\nnetworks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining .\n1269\u20131278.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:29\n[40] Ryan Lenz. 2013. Following the White Rabbit | Southern Poverty Law Center. https://www.splcenter.org/fighting-\nhate/intelligence-report/2013/following-white-rabbit. (Accessed on 10/15/2020).\n[41] Erik Lewis and George Mohler. 2011. A nonparametric EM algorithm for multiscale Hawkes processes. Journal of\nNonparametric Statistics 1, 1 (2011), 1\u201320.\n[42] Scott Linderman and Ryan Adams. 2014. Discovering latent network structure in point process data. In International\nConference on Machine Learning . 1413\u20131421.\n[43] Jenni Marsh and Tara Mulholland. [n.d.]. How the Christchurch terrorist attack was made for social media - CNN.\nhttps://www.cnn.com/2019/03/15/tech/christchurch-internet-radicalization-intl/index.html. (Accessed on 09/23/2020).\n[44] Gary T Marx and James L Wood. 1975. Strands of theory and research in collective behavior. Annual review of sociology\n1, 1 (1975), 363\u2013428.\n[45] John McCarthy and Mayer N Zald. 2003. Social movement organizations. The social movements reader: Cases and\nconcepts (2003), 169\u2013186.\n[46] John D Mccarthy, Mayer N Zald, Gary Long, Anthony Oberschall, Anthony Orum, Kathy Pearce, Jack Seidman,\nand Benjamin Walter. [n.d.]. Resource Mobilization and Social Movements: A Partial Theory\u2019 . Technical Report.\nhttp://www.journals.uchicago.edu/t-and-c\n[47] Evgeny Morozov. 2009. The brave new world of slacktivism. Foreign policy 19, 05 (2009).\n[48] Aldon Morris. 2002. Leadership in Social Movements Aldon Morris and Suzanne Staggenborg. (2002).\n[49] Karsten M\u00fcller and Carlo Schwarz. 2020. Fanning the Flames of Hate: Social Media and Hate Crime. SSRN (2020).\n[50] Edward Newell, David Jurgens, Haji Mohammad Saleem, Hardik Vala, Jad Sassine, Caitrin Armstrong, and Derek Ruths.\n2016. User Migration in Online Social Networks: A Case Study on Reddit During a Period of Community Unrest.. In\nICWSM . 279\u2013288.\n[51] Permanent Culture Now. 2018. Introduction to activism. Recuperado de< http://www. permanentculturenow. com/what-\nis-activism (2018).\n[52] Sonia N\u00fa\u00f1ez Puente, Diana Fern\u00e1ndez Romero, and Susana V\u00e1zquez Cupeiro. 2017. Online feminist practice, participa-\ntory activism and public policies against gender-based violence in Spain. Feminist Theory 18, 3 (2017), 299\u2013321.\n[53] Jonathan A Obar, Paul Zube, and Clifford Lampe. 2012. Advocacy 2.0: An analysis of how advocacy groups in the\nUnited States perceive and use social media as tools for facilitating civic engagement and collective action. Journal of\ninformation policy 2 (2012), 1\u201325.\n[54] Anthony Oberschall. 1973. Social conflict and social movements . Prentice hall.\n[55] Nicholas Owen. [n.d.]. The conscience constituent reconsidered. In Other People\u2019s Struggles . Oxford University Press.\n[56] Umashanthi Pavalanathan and Munmun De Choudhury. 2015. Identity management and mental health discourse in\nsocial media. In WWW . ACM.\n[57] Tsveta Petrova and Sidney Tarrow. 2007. Transactional and participatory activism in the emerging European polity:\nThe puzzle of East-Central Europe. Comparative political studies 40, 1 (2007), 74\u201394.\n[58] Shruti Phadke and Tanushree Mitra. 2020. Many Faced Hate: A Cross Platform Study of Content Framing and\nInformation Sharing by Online Hate Groups. In Proceedings of the 2020 CHI Conference on Human Factors in Computing\nSystems (Honolulu, HI, USA) (CHI \u201920) . Association for Computing Machinery, New York, NY, USA, 1\u201313. https:\n//doi.org/10.1145/3313831.3376456\n[59] Whitney Phillips. 2018. Data & Society \u2014 The Oxygen of Amplification. https://datasociety.net/library/oxygen-of-\namplification. (Accessed on 09/23/2020).\n[60] Counter Extremism Project. 2020. Germany: Extremism & Counter-Extremism | Counter Extremism Project. https:\n//www.counterextremism.com/countries/germany. (Accessed on 01/14/2021).\n[61] The Tech Transparency Project. 2020. Facebook\u2019s Boogaloo Problem: A Record of Failure | Tech Transparency\nProject. https://www.techtransparencyproject.org/articles/facebooks-boogaloo-problem-record-failure. (Accessed on\n10/15/2020).\n[62] Babak Rahimi. 2016. Vahid Online: Post-2009 Iran and the Politics of Citizen Media Convergence. Social Sciences 5, 4\n(2016), 77.\n[63] ADL Reports. 2019. Right-Wing Extremism Linked to Every 2018 Extremist Murder in the U.S., ADL Finds | Anti-\nDefamation League. https://www.adl.org/news/press-releases/right-wing-extremism-linked-to-every-2018-extremist-\nmurder-in-the-us-adl-finds. (Accessed on 09/23/2020).\n[64] Howard Rheingold. 2007. Smart mobs: The next social revolution . Basic books.\n[65] Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, and Lexing Xie. 2017. A tutorial on hawkes processes for events in\nsocial media. arXiv preprint arXiv:1708.06401 (2017).\n[66] Debbie Rodan and Jane Mummery. 2017. Activism and digital culture in Australia . Rowman & Littlefield.\n[67] Dana Rotman, Sarah Vieweg, Sarita Yardi, Ed Chi, Jenny Preece, Ben Shneiderman, Peter Pirolli, and Tom Glaisyer.\n2011. From slacktivism to activism: participatory culture in the age of social media. In CHI\u201911 Extended Abstracts on\nHuman Factors in Computing Systems . 819\u2013822.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:30 Anonymous Authors\n[68] Roser Saur\u0131. 2008. A factuality profiler for eventualities in text . Ph.D. Dissertation. Ph. D. thesis, Brandeis University.\n[69] Swathi Shanmugasundaram. 2018. Anti-immigrant roundup: 7/6/18 | Southern Poverty Law Center. https://www.\nsplcenter.org/hatewatch/2018/07/06/anti-immigrant-roundup-7618. (Accessed on 10/15/2020).\n[70] Simon Sheather. 2009. A modern approach to regression with R . Springer Science & Business Media.\n[71] Alexandra A Siegel and Vivienne Badaan. 2020. # No2Sectarianism: Experimental Approaches to Reducing Sectarian\nHate Speech Online. American Political Science Review 114, 3 (2020), 837\u2013855.\n[72] Bernd Simon and PG Klandermans. 2001. Toward a social psychological analysis of politicized collective identity:\nConceptualization, antecedents and consequences. American Psychologist 56 (2001), 319\u2013331.\n[73] SPLC. 2020. Alliance Defending Freedom | Southern Poverty Law Center. https://www.splcenter.org/fighting-\nhate/extremist-files/group/alliance-defending-freedom. (Accessed on 10/15/2020).\n[74] SPLC. 2020. National Vanguard | Southern Poverty Law Center. https://www.splcenter.org/fighting-hate/extremist-\nfiles/group/national-vanguard. (Accessed on 10/15/2020).\n[75] Hatewatch Staff. 2020. Facebook\u2019s Strategy for Taking Down Hate Groups is Spotty and Ineffective | Southern Poverty\nLaw Center. https://www.splcenter.org/hatewatch/2020/04/07/facebooks-strategy-taking-down-hate-groups-spotty-\nand-ineffective. (Accessed on 09/15/2020).\n[76] Kate Starbird, Ahmer Arif, and Tom Wilson. 2019. Disinformation as collaborative work: Surfacing the participatory\nnature of strategic information operations. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019),\n1\u201326.\n[77] Stefan St\u00fcrmer, Bernd Simon, Michael Loewy, and Heike J\u00f6rger. 2003. The dual-pathway model of social movement\nparticipation: The case of the fat acceptance movement. Social Psychology Quarterly (2003), 71\u201382.\n[78] Hiroki Takikawa and Takuto Sakamoto. 2019. The moral\u2013emotional foundations of political discourse: a comparative\nanalysis of the speech records of the US and the Japanese legislatures. Quality & Quantity (2019), 1\u201320.\n[79] Yla R Tausczik and James W Pennebaker. 2010. The psychological meaning of words: LIWC and computerized text\nanalysis methods. Journal of language and social psychology 29, 1 (2010), 24\u201354.\n[80] Ralph H Turner. 1969. The public perception of protest. American Sociological Review (1969), 815\u2013831.\n[81] Sebasti\u00e1n Valenzuela. 2013. Unpacking the use of social media for protest behavior: The roles of information, opinion\nexpression, and activism. American behavioral scientist 57, 7 (2013), 920\u2013942.\n[82] Jacquelien van Stekelenburg and Bert Klandermans. 2013. Social psychology of movement participation. The Wiley-\nBlackwell Encyclopedia of Social and Political Movements (2013).\n[83] Jacquelien Van Stekelenburg and Bert Klandermans. 2013. The social psychology of protest. Current Sociology 61, 5-6\n(2013), 886\u2013905.\n[84] Jacquelien Van Stekelenburg and Bert Klandermans. 2017. Individuals in movements: A social psychology of contention.\nInHandbook of social movements across disciplines . Springer, 103\u2013139.\n[85] Ariadne Vromen. 2017. Digital citizenship and political engagement. In Digital Citizenship and Political Engagement .\nSpringer, 9\u201349.\n[86] Mattias Wahlstr\u00f6m, Abby Peterson, and Magnus Wennerhag. 2018. \u201cCONSCIENCE ADHERENTS\u201d REVISITED:\nNON-LGBT PRIDE PARADE PARTICIPANTS. Mobilization: An International Quarterly 23, 1 (2018), 83\u2013100.\n[87] Yi-Chia Wang, Robert Kraut, and John M Levine. 2012. To stay or leave? The relationship of emotional and informational\nsupport to commitment in online health support groups. In Proceedings of the ACM 2012 conference on computer supported\ncooperative work . 833\u2013842.\n[88] Micah White. 2010. Clicktivism is ruining leftist activism. The Guardian 12, August (2010), 2010.\n[89] Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language.\nLanguage resources and evaluation 39, 2-3 (2005), 165\u2013210.\n[90] Mayer N Zald and Roberta Ash. 1966. Social movement organizations: Growth, decay and change. Social forces 44, 3\n(1966), 327\u2013341.\n[91] Savvas Zannettou, Tristan Caulfield, Emiliano De Cristofaro, Nicolas Kourtelris, Ilias Leontiadis, Michael Sirivianos,\nGianluca Stringhini, and Jeremy Blackburn. 2017. The web centipede: understanding how web communities influence\neach other through the lens of mainstream and alternative news sources. In Proceedings of the 2017 Internet Measurement\nConference . 405\u2013417.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:31\nthreshold for\nextremist linksaccounts added\nbecause of the new thresholdclustering of additional accounts with original cluster centers\nsympathizers motivators flamers educators solicitors\n>8 links 536 86% 7% 4% 2% 1%\n>6 links 1023 81% 5% 10% 2% 2%\n>4 links 9278 75% 12% 9% 3% 1%\nTable 5. Table showing the number of new accounts that could be added in the dataset with various thresholds\nfor the number of extremist links. Our analysis is based on the threshold of >10 extremist links per account.\nThe table also describes what percent of the new accounts fall across various roles using the cluster centers\nobtained in RQ1. The majority of the new accounts fall under the sympathizer role.\nA APPENDIX\nA.1 Cluster Analysis with Various Link Thresholds\nIn RQ1, we select extremist accounts that post atleast 10 unique extremist links in the analysis time\nwindow. While we select this threshold due to the 95th percentile of the extremist link posting\ndistributions across all the accounts, here we present analysis for different thresholds. Specifically,\nwe consider accounts that would have been added to the dataset if the threshold was >8, >6 and\n>4 extremist links posted. We find that the majority of the new accounts would have been added\nto the sympathizers category. This is not surprising as sympathizers have lowest proportion of\nextremist links compared to other roles. We also experimented with keeping all the accounts; i.e,\naccounts that post atleast 1 extremist link in two years. Keeping all accounts added great amount\nof noise in the feature calculation process. This may be because many defining clustering features\n(opinions, solicitations, popularity, proportion, trends) are calculated explicitly on the text and\nfrequency of the extremist links and the accounts with only one or two extremist links may not have\nany words or phrases related to solicitation, opinions or any reactions on the posts. Overall, our\npost-hoc analysis suggests that even by lowering the threshold to >4 extremist links per account,\nthe constitution of the educators or solicitors\u2014roles core to the extremist movements\u2014does not\nchange significantly.\nA.2 Robustness Tests for Clustering\nA.2.1 Feature Correlation .We first report the pairwise correlation values between different\nfeatures used in clustering in Figure 6. Most feature pairs have low correlation. Only pairs of reward,\nachievement and group identity, opinions are moderately correlated. We further test for multi-\ncolinearity using Variance Inflation Factor (VIF). VIF values of >5indicate high multi-colinearity\n[70]. All of our features have a VIF <2indicating low or no multi-colinearity\nA.2.2 Finding Number of Roles .In order to determine the number of roles, we performed\nelbow analysis with KMeans algorithm. We used two metrics\u2014inertia and distortions\u2014and plotted\ntheir values across different number of clusters (or roles). Distortions are calculated as the average\nof the squared distances from the cluster centers and inertia is the sum of the squared distance\nfrom the cluster centers. Figure 7(a) displays inertia and distortion plots for the KMeans algorithm\nwhere elbow can be observed at \ud835\udc5b=5indicating that 5 is the optimal number of roles.\nA.2.3 Cluster Assignments Overlap .We obtained role assignment for every extremist account\nusing KMeans algorithm. As a further robustness test, we also compare the role assignments done by\nKMeans with a different algorithm\u2014Agglomerative clustering. We selected Agglomerative clustering\nas it is hierarchical clustering algorithm operating on a different clustering mechanism compared to\nKMeans. Note that since KMeans and Agglomerative clustering are inherently motivated by different\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:32 Anonymous Authors\nInjustice\nAchievement\nGroup_identity\nAnger\nRisk\nReward\nHate_links\nLikes\nShares\nComments\nTrend\nOpinions\nSolicitationInjustice\nAchievement\nGroup_identity\nAnger\nRisk\nReward\nHate_links\nLikes\nShares\nComments\nTrend\nOpinions\nSolicitation0.03\n-0.02 0.01\n0.07 -0.03 -0.03\n0.06 0.08 00.12\n00.32 0.04 0.01 0.06\n-0.02 0.02 0.04 -0.04 -00.01\n0.04 0.01 -0.03 0.01 -0.01 0.02 0.1\n0.04 -0.02 -0.02 0.07 0.01 -0.04 00.23\n0.03 -0.04 00.11 -0-0.01 -0.06 0.2 0.21\n-0 00.01 -0-0.01 0.01 0.04 0.02 0.03 -0.01\n-0.01 0.01 0.31 -0.03 -00.04 0.05 0.1 0.01 0.12 0.01\n-0.03 -00.26 -0.1 0.05 0.02 0.09 0.01 -0.05 -0.06 0.01 0.22\n0.08\n0.000.080.160.24\n(a)Features VIF\nInjustice 1.099729\nAchievement 1.882811\nGroup_identity 1.611063\nAnger 1.547119\nRisk 1.375777\nReward 1.707319\nHate_links 1.161227\nLikes 1.946095\nShares 1.444380\nComments 1.356092\nTrend 1.003054\nOpinions 1.671187\nSolicitation 1.254916\n(b)\nFig. 6. (a) Figure showing pairwise Pearson correlation coefficients for all features used in the clustering. Most\nof the features have low correlation. Reward is moderately correlated with Achievement and Group identity\nis moderately correlated with Opinions. There are no high correlations. (b) Table displaying the Variance\nInflation Factor (VIF) for all features. VIF is used to detect multi-colinearity. VIF exceeding 5 indicates high\nmulti-colinearity [ 70] between that feature and the others. All our features have VIF < 2 indicating low or no\nmulti-colinearity.\n2 3 4 5 6 7 8 910 11 12 13 14\nn20003000400050006000inertias\n5678910\ndistortions\n(a)cluster (role in KMeans) Jaccard(KMeans, Agglo)\nA(Solicitors) 0.87\nB(Educators) 0.83\nC(Flamers) 0.79\nD(Motivators) 0.67\nE(Sympathizers) 0.71\n(b)\nFig. 7. Figure presenting the elbow analysis using different algorithms. (a) Plots showing distortion and\ninertia across different number of clusters. Optimal number of clusters can be determined by the \u201celbow\u201d\nof the curves. (b) Jaccard similarity scores between corresponding clusters of KMeans and Agglomerative\nclustering algorithms.\nworking principles, it is harder to achieve perfect similarity between cluster assignments. However,\nwe present Jaccard similarity scores for cluster assignments using KMeans and Agglomerative\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:33\nclustering to provide an estimate of overlap between the two algorithms. We fist cluster extremist\naccounts using KMeans algorithm and record cluster assignments. We then cluster the accounts\nusing Agglomerative clustering and record the cluster assignments. For every cluster in the KMeans\n(eg., KMeans_A), we find corresponding cluster in the Agglomerative clustering (eg., Agglo_A) and\ncalculate Jaccard similarity score using common extremist accounts in both clusters. Specifically,\nwe calculate the number of common extremist accounts in Kmeans_A and Agglo_A and divide it\nby total number of unique accounts in Kmeans_A and Agglo_A combined. Figure 7(b) provides the\nJaccard similarity values for similar clusters obtained by two different algorithms. On an average\nthe two algorithms have 0.77 similarity in cluster assignments.\nA.3 Tables for Opinion and Solicitation Expressions\nPronoun POS Variation Examples\nFirst person subjective\n(I , we)LIWC cogproc verbs\n(believe, think, infer, propose)With and without auxiliary verbs,\nadverbs, negationsI believe..\nWe don\u2019t think..\nI really don\u2019t understand..\nFirst person possessive\n(my, mine, our, ours)LIWC cogproc nouns\n(opinion, understanding)With or without adjectivesMy strong opinion. . .\nOur shared understanding of the issue...\nFirst person subjective\n(I , we)LIWC cogproc adjectives\n(positive, confused, unclear,\nhopeful)With and without auxiliary verbs,\nadverbs, negationsI am hopeful. . .\nWe are really confused. . .\nI might not be supportive..\nThird person\n(he, she it, they, theirs,\nhis, hers, its)Modal verbs\n(should, must, can , could,\nwill, might)With ot without nouns, negations,\nadverbs in the middleThey should...\nHe should...\nThey definitely must...\nHis incomplete understanding must...\nProper nounsModal verbs\n(should, must, can , could,\nwill, might)With ot without nouns, negations,\nadverbs in the middleHillary must...\nTrump should...\nCAIR actually can...\nTable 6. Table listing phrase patterns used to extract opinions. We pair various LIWC cognitive processing\n(cogproc) nouns, verbs and adjectives with pronouns. The last column also lists examples for each pattern.\nPronouns/POS Pronouns/POS Variation Examples\npleaseLIWC social verbs\n(donate, call , register)With and without\nauxiliary verbs,\nadverbsPlease donate. . .\nPlease consider registering..\nLIWC social verbs LIWC social nounsWith or without article,\nadjective, prepositionSign the petition...\nRegister for this beautiful event...\nLIWC social verbs First person pronounWith or without\nprepositionsContact us..\nRegister with our...\nSecond person\n(you, yours)Modal verbs\n(should, must, can ,\ncould, will, might)With or without nouns,\nnegations, adverbsYou should..\nYou really must..\nYou can..\nSecond person\n(you, yours)LIWC social nounWith or without negations,\nadjectives in the middleYour wonderful donation. . .\nYour timely call..\nVerbs used in requests\n(will, could, can, would)Second personWill you..(sign this petition)?\nCan you . . . (call your senator?)\nTable 7. Table listing phrase patterns used to extract expressions of solicitation. We pair various LIWC social\ncategory nouns, verbs and adjectives with pronouns. The last column also lists examples for each pattern.\nA.4 Analysis of the Domains removed in RQ3\nFor our RQ3 analysis, we removed all links in time period \ud835\udc471sourced from domains not present in\nthe OpenSources dataset or our list of extremist websites. Specifically, we removed 24% of the link\nposts. It is possible that some of the removed domains could contain extremist, fake news, biased\nor conspiratorial content. In order to estimate how many of the removed domains could potentially\nfall under extremist, fake news, biased or conspiratorial content categories, we report 100 most\nfrequently shared domains from the removed links (See Table 8). For each of the 100 domains, we\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:34 Anonymous Authors\nsearched for the bias and credibility ratings using mediabiasfactcheck.com and allsides.com . In\nTable 8we highlight domains that have moderate to extreme political bias (left or right), low or\nvery low factuality rating and strong conspiracy or pseudoscience rating. 20 out of 100 domains\nare either strongly biased, have factuality or strong conspiratorial content.\nfoxnews.com kirkreview.com bible.com cbsnews.com jwatch.us\nmsn.com newsweek.com israelnationalnews.com cbn.com strangesounds.org\nthehill.com iheart.com bloomberg.com nationalpost.com beecatholic.com\nwashingtonpost.com hannity.com themaven.net haaretz.com medium.com\ncnn.com freebeacon.com wsj.com rushlimbaugh.com globalnews.ca\nwashingtontimes.com endtimeheadlines.org torontosun.com foxbusiness.com verelq.am\nnytimes.com gatestoneinstitute.org politico.com nydailynews.com davidharrisjr.com\ntheguardian.com independent.co.uk businessinsider.com enlacejudio.com snopes.com\njpost.com atheistrepublic.com dmlnews.com eventbrite.com realclearpolitics.com\ntimesofisrael.com whitehouse.gov forbes.com rightspeak.net vox.com\nnypost.com bbc.com wikipedia.org time.com whoobazoo.com\nelderstatement.com patheos.com gofundme.com mckoysnews.com deborahhbateman.com\nrt.com dailymail.co.uk globalskywatch.com patriotbeat.com ch7.io\ntownhall.com fenixx.org telegraph.co.uk thetrumptimes.com observador.pt\ngellerreport.com voiceofeurope.com apple.news aljazeera.com algemeiner.com\nfreespeechtime.net soundcloud.com change.org therebel.media godaddy.com\nhuffingtonpost.com latimes.com npr.org chicagotribune.com aleteia.org\nreuters.com thefederalist.com ynetnews.com mirror.co.uk cbslocal.com\nusatoday.com spencerfernando.com palinfo.com cnsnews.com tapwires.com\nnbcnews.com cnbc.com bizpacreview.com msnbc.com bitchute.com\nTable 8. Table with 100 most frequent domains in URLs removed in the RQ3 analysis. We highlight domains\nthat have moderate to extreme political bias (left or right), low or very low factuality rating and strong\nconspiracy or pseudoscience rating.\nA.5 Mathematical Formulation for Hawkes Process\nConsider a series of link posting events divided into the time bins \u0394t This series is a Hawkes process\nif the rate of each process has the parameterized form:\n\ud835\udf06\ud835\udc61,\ud835\udc58=\ud835\udf060,\ud835\udc58+\ud835\udc3e\u2211\ufe01\n\ud835\udc58\u2032=1\ud835\udc61\u22121\u2211\ufe01\n\ud835\udc61\u2032=1\ud835\udc60\ud835\udc61\u2032,\ud835\udc58\u2032\u00b7\u210e\ud835\udc58\u2032\u2192\ud835\udc58[\ud835\udc61\u2212\ud835\udc61\u2032] (1)\nwhere\ud835\udf060,\ud835\udc58is the background rate, \ud835\udc60is the matrix of events generated from common link sharing\nand\u210eis an impulse response function describing the amplitude of influence that events on process\n(or role)\ud835\udc58\u2032have on the rate of process (or role) \ud835\udc58. Guided by the descriptions in [ 42,91], we can\nfurther decompose \u210einto the weight matrix \ud835\udc4aand probability mass function \ud835\udc3a. We use the the\nweight matrix \ud835\udc4aof the shape \ud835\udc4a\ud835\udc3e\u00d7\ud835\udc3eto infer pairwise influence of roles.\nA.6 Example Links from Various Source Types Posted by Influential Roles\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.\nEducators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing Roles in Online Extremist Movements 111:35\nFig. 8. Example of link posted by educators from an extremist domain about white identity. The content of\nthe link is highly educational in that, it explains the constructs of the Aryan identity and emphasizes on\navoiding interracial relations.\nFig. 9. Example of links posted by flamers from fake news domain. The first link presents false information to\nalarm and mobilize readers against the Democratic party. Second link uses false information alongwith fear\nbased narratives to present anti-LGBTQ agenda.\nProc. ACM Meas. Anal. Comput. Syst., Vol. 37, No. 4, Article 111. Publication date: August 2018.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Educators, solicitors, flamers, motivators, sympathizers: characterizing roles in online extremist movements", "author": ["S Phadke", "T Mitra"], "pub_year": "2021", "venue": "Proceedings of the ACM on Human-computer \u2026", "abstract": "Social media provides the means by which extremist social movements, such as white  supremacy and anti-LGBTQ, thrive online. Yet, we know little about the roles played by the"}, "filled": false, "gsrank": 634, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3476051", "author_id": ["2ntdPF4AAAAJ", "5q_BkVAAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:z5Gl4dw0LQUJ:scholar.google.com/&output=cite&scirp=633&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=z5Gl4dw0LQUJ&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 31, "citedby_url": "/scholar?cites=373012467424793039&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:z5Gl4dw0LQUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2105.08827"}}, {"title": "A unified graph-based approach to disinformation detection using contextual and semantic relations", "year": "2022", "pdf_data": "A Unified Graph-Based Approach to Disinformation Detection Using Contextual\nand Semantic Relations\nMarius Paraschiv,1Nikos Salamanos,2Costas Iordanou,2Nikolaos Laoutaris,1Michael Sirivianos2\n1IMDEA Networks, Madrid, Spain\n2Cyprus University of Technology\nmarius.paraschiv@imdea.org, nik.salaman@cut.ac.cy, costas.iordanou@eecei.cut.ac.cy, nikolaos.laoutaris@imdea.org,\nmichael.sirivianos@cut.ac.cy\nAbstract\nAs recent events have demonstrated, disinformation spread\nthrough social networks can have dire political, economic\nand social consequences. Detecting disinformation must in-\nevitably rely on the structure of the network, on users particu-\nlarities and on event occurrence patterns. We present a graph\ndata structure, which we denote as a meta-graph, that com-\nbines underlying users\u2019 relational event information, as well\nas semantic and topical modeling. We detail the construction\nof an example meta-graph using Twitter data covering the\n2016 US election campaign and then compare the detection\nof disinformation at cascade level, using well-known graph\nneural network algorithms, to the same algorithms applied\non the meta-graph nodes. The comparison shows a consistent\n3%-4% improvement in accuracy when using the meta-graph,\nover all considered algorithms, compared to basic cascade\nclassification, and a further 1% increase when topic model-\ning and sentiment analysis are considered. We carry out the\nsame experiment on two other datasets, HealthRelease and\nHealthStory, part of the FakeHealth dataset repository, with\nconsistent results. Finally, we discuss further advantages of\nour approach, such as the ability to augment the graph struc-\nture using external data sources, the ease with which multiple\nmeta-graphs can be combined as well as a comparison of our\nmethod to other graph-based disinformation detection frame-\nworks.\nIntroduction\nSocial media have become a primary medium of interaction\nin modern society \u2013 having started as a place for casual dis-\ncussion and exchange of ideas. Their massive outreach and\nadaptability to individual users\u2019 preferences have made so-\ncial networks indispensable for a wide range of political and\nactivist groups, companies, governments, and mainstream\nnews outlets. The social importance of these networks stems\nfrom the fact that they are more than just a space for public\ndiscussion. Social networks such as Twitter and Facebook\nhave become the primary source of information on a global\nscale (Westerman, Spence, and Van Der Heide 2014). How-\never, the spread of disinformation can have a severe negative\nsocial (Chenzi 2020), political (Safieddine 2020), and eco-\nnomic impact (Visentin, Pizzi, and Pichierri 2019; Cheng\nCopyright \u00a9 2022, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.and Chen 2020), thus it is currently treated as a fast-growing\ncyberthreat (Belova and Georgieva 2018).\nCurrent disinformation detection methods on social me-\ndia primarily rely on using part of the available information\neither regarding users or local network structure (see Sec-\ntion \u201cRelated Work\u201d), in order to perform the required anal-\nysis. Treating such features in isolation may lead to poor re-\nsults as the manifestation of disinformation is characterized\nby a plethora of factors, both internal (user characteristics)\nand external (network characteristics and tweet content).\nIn this paper, we set out to improve our capacity to de-\ntect disinformation in social media by proposing a uni-\nfied methodology for both internal and external factors. To\ndemonstrate the value of the proposed method, we focus on\nTwitter content. The primary action on Twitter is message\nposting by registered users (tweets) or message sharing by\nothers within the platform (retweets). As such, posting infor-\nmation on a particular topic results in a root\u2013tweet (the orig-\ninal tweet that has been retweeted), followed by a series of\nretweets by other users. This series of retweet events forms\na tree\u2013graph structure which is known as retweet cascade.\nMoreover, we construct and analyse a very large dataset re-\nlated to 2016 US Presidential Election, consisting of 152.5M\ntweets by 9.9M users; In addition, we evaluate our method\non the HealthRelease and HealthStory datasets, part of the\nFakeHealth repository (Dai, Sun, and Wang 2020).\nIn summary, we propose a graph data structure, named\nmeta-graph having the retweet cascades as nodes. Each cas-\ncade disseminates a root\u2013tweet together with the web and/or\nmedia URL(s) embedded in that tweet. The node features\ncontain: (i) information about the cascade graph structure,\nobtained by applying a graph embedding algorithm to each\nindividual cascade; (ii) relational user information, extracted\nfrom the social network. The edges of the meta-graph repre-\nsent relationships between cascades, such as structural sim-\nilarity, number of common users (possibly indicating that\nthe cascades originate from the same community), or con-\ntent similarity (URL or text of the root tweet). One of the\nadvantages of this approach is that it can be easily expanded\nwith additional information from other datasets. Finally, in\nthe US Elections dataset, many URLs corresponding to the\nretweet cascades that have been manually labeled as fake or\nnon-fake, by several external fact-checkers (MBFC 2020;\nPolitiFacts 2020; FactCheck 2020; Snopes 2020), resulting\nProceedings of the Sixteenth International AAAI Conference on Web and Social Media (ICWSM 2022)\n747\nin a total of 43,989 labeled data points (see Table 4).\nThe construction of the meta-graph poses a series of non\ntrivial challenges, such as the choice of content-embedding\nand graph-embedding algorithms, the selection of relevant\nfeatures from the raw data or the filtering of initial edges \u2013 all\nof which are described in detail in Section \u201cThe Meta-Graph\nApproach\u201d. By using the meta-graph approach, we trans-\nform the cascade classification problem into a node classifi-\ncation task. In case retweet cascades are treated as indepen-\ndent graphs, then we are dealing with a graph classification\ntask. Data points are represented by individual cascades, la-\nbeled by their content. The similarity between cascades is\nthus a learned feature, inherent to the model itself. There are\nhowever advantages to making these relations explicit, such\nas biasing the algorithm in the desired direction, as well as\nthe capacity to provide additional, external, information to\nthe meta-graph edges, otherwise unavailable to a classifica-\ntion algorithm.\nIn Section \u201cEvaluation of Performance Benefits\u201d we show\na comparison between (i) classifying cascades in isolation\n(graph classification); (ii) classifying cascades as nodes of\nthe mentioned meta-graph. We demonstrate that the addi-\ntional relational information contained in the meta-graph\nleads to consistently higher classification results. For the\ngraph and node classification tasks, we apply four well-\nknown graph neural network algorithms, as they currently\nrepresent the state of the art in terms of graph analysis and\nprediction. For an overview of graph neural networks, we\nrefer the reader to some of the recent review papers, such\nas (Wu et al. 2020; Zhou et al. 2020; Zhang et al. 2019).\nAs an additional step, to the initial cascade or meta-graph\nfeatures we append the sentiment analysis scores, as well\nas the predicted sentiment. This is done so as to avoid in-\nstances where a cascade is classified as disinformation, even\nthough the root tweet is highlighting the possible issues with\na piece of information, showing clear disagreement. A final\nset of features comes from topic modeling, where we de-\ntect topics, among all tweet texts in the dataset, and assign\ntheir corresponding identifier to each cascade or meta-graph\nnode. This provides additional information to the classifica-\ntion algorithm, and we show that this approach offers 1%\nconsistent improvements.\nData availability: Part of the US Elections dataset is pub-\nlicly available (Salamanos et al. 2021) under proper restric-\ntions for compliance with Twitter\u2019s Terms of Service (Tos),\nGeneral Data Protection Regulation (GDPR). The Fake-\nHealth repository is publicly available (Dai, Sun, and Wang\n2020).\nRelated Work\nSubstantial effort has been put into studying false infor-\nmation detection in social media. A first set of approaches\nconcerns performing feature-based detection at user level.\n(Ahmed, Traore, and Saad 2017) apply various feature ex-\ntraction methods to the content of social media posts to de-\ntect stylistic characteristics that may give away posts con-\ntaining disinformation. While this is a significant intermedi-\nary step, it does not consider relational information between\nsources and platform users (in the case of Twitter). (GhoshWork (User, Net, Content)\n(Ahmed, Traore, and Saad 2017) (\u2212,\u2212,+)\n(Ghosh and Shah 2018) (\u2212,\u2212,+)\n(Zhang, Zhao, and Lecun 2015) (\u2212,\u2212,+)\n(Kaliyar, Goswami, and Narang 2021) (\u2212,\u2212,+)\n(Castillo, Mendoza, and Poblete 2011) (+,\u2212,+)\n(Shu et al. 2019c) (+,\u2212,\u2212)\n(Tacchini et al. 2017) (+,\u2212,\u2212)\n(Guo et al. 2018) (+,\u2212,\u2212)\n(Jin et al. 2017) (+,\u2212,\u2212)\n(Gupta, Zhao, and Han 2012) (+,+,\u2212)\n(Shu et al. 2019a) (\u2212,+,+)\n(Wu and Liu 2018) (\u2212,+,\u2212)\n(Shu, Wang, and Liu 2019) (+,+,\u2212)\n(Shu et al. 2019b) (\u2212,+,+)\nThis Work (+,+,+)\nTable 1: Summary of the related work based on differ-\nent detection methodologies (user feature-based; network-\nbased; content-based) that they utilize/combine to identify\nfake news in social media.\nand Shah 2018) use a similar approach to split the problem\ninto feature extraction and classification steps, while (Zhang,\nZhao, and Lecun 2015) use character-level convolutional\nnetworks that combine the two. A more recent approach is\nthat by (Kaliyar, Goswami, and Narang 2021), which uses\nthe BERT language model (Devlin et al. 2019) to perform\nfeature extraction. A detailed overview of similar methods\ncan be found in (Zhou and Zafarani 2020). (Castillo, Men-\ndoza, and Poblete 2011) assess the credibility of posts based\non the past behavior of users, the tweet content, and other ex-\nternal sources. (Shu et al. 2019c) extract features based on\nparticular users\u2019 profiles and determine which type of profile\nis more inclined to share false information. This is similar to\nthe methods in (Tacchini et al. 2017; Guo et al. 2018; Jin\net al. 2017) for exploiting user-type characteristics to clas-\nsify posted messages as false or not.\nSocial context-based methods deal both with relations be-\ntween users sharing news as well as with information re-\nlated to the user and the news itself (for example, the num-\nber of similar postings made by the said user in the past).\n(Gupta, Zhao, and Han 2012) propose studying the prob-\nlem from a credibility perspective by performing credibility\npropagation along a network that comprises events, tweets,\nand users. The events in this case roughly correspond to the\nroot tweet in our approach. However, their approach does\nnot consider the rich structural information of the cascades\nas well as cascade similarity. (Shu et al. 2019a) propose a\nsentence-comment co-attention sub-network, aiming to ex-\nplain why a piece of news has been detected by an algorithm\nas false. At the same time, (Wu and Liu 2018) take the ap-\nproach of detecting false information based on its propaga-\ntion patterns through the network.\nA similar method to the one discussed in this paper is pre-\nsented by (Shu, Wang, and Liu 2019). The authors use an\n748\nRoot T\nweets 46,409 Root Users 8204\nRetweets 19,588,072 Retweeters 3,630,992\nURLs (web and media) 43,989\nTable 2: US Elections dataset: Retweet cascades with at least\n100 unique retweeters\nHeathRelease HealthStory\ntweets 43,245 357,851\nreplies 1418 23,632\nretweets 15,343 105,712\nTotal 60,006 487,195\nTable 3: FakeHealth repository: Tweets, replies and retweets\nin the collected datasets\nembedding framework dubbed TriFN, modelling publisher-\nnews relations and users\u2019 interaction with the particular\npieces of news simultaneously. Compared to our proposal,\nit misses relational information between events (cascades),\nwhich can prove essential in assessing a user\u2019s past behav-\nior, as well as the semantic features added by topic mod-\neling and sentiment analysis. Another interesting approach\nis presented in (Shu et al. 2019b) where the authors build a\nhierarchical propagation network for false information and\nperform a comparative analysis between false and real news\nbased on linguistic, structural and temporal perspectives.\nThe methods outlined above roughly fall into three cat-\negories: a) user feature-based detection in which the aim\nis to use information at the user level (be it contextual or\nbehavioral) to assess the type of content a user publishes;\nb)network-based detection in which the relational context\nis used for content classification; and c) and tweet content-\nbased detection, in which linguistic features are exploited\nfor performing classification at the text level. Our proposed\nmeta-graph data structure provides an effective means to\ncombine all three methodologies, fully utilizing content,\ncontext, and source information simultaneously, as depicted\nin Table 1.\nSocial Media Data Structure\nUS Elections Dataset\nTo analyze disinformation on Twitter, we collected a large\nnumber of tweets related to the 2016 US presidential\nelection. During that period, state\u2013sponsored disinformation\ncampaigns are believed to have operated by spreading\nmillions of tweets with ambiguous political content. Hence,\nTwitter account activity from that period provides us with\nvaluable information for the analysis of disinformation\nspread in social media. The belief that many of the tweets\nfrom that period were spreading fake news has been\nfurthered validated by the fact that Twitter has permanently\ndeleted lots of them as part of its continuous efforts against\ndisinformation and malicious activities on the platform1.\n1https://about.twitter.com/en/our-priorities/civic-integrityCrawling: In the period up to the 2016 US presidential elec-\ntion \u2013 from September 21stto November 7th, 2016 (with\nthe exception of October 2nd2016) we collected 152.5M\ntweets (by 9.9M users) using the Tweepy2Python library\nfor accessing the Twitter streaming API. To consider tweets\nto be politically related, they need to include words from a\nlist of 77track terms used for the crawling. Track terms as\n\u201chillary2016\u201d, \u201cclinton2016\u201d, \u201ctrump2016\u201d, \u201celection2016\u201d\netc. would, with a large degree of confidence, return tweets\nthat were indeed part of the intense political polarization and\ndebate that took place during the election period. For each\ntweet, we stored 27 features related to a tweet (tweet\u2013ID,\ntweet\u2013text etc.), and to the Twitter account (user\u2013ID, user\nscreen name, number of followers, etc.) who posted that\ntweet. Moreover, we collected the \u201cEntities\u201d section, which\ncontains several metadata such as the \u201cmentions\u201d and the\nURLs embedded in the text.\nWe note that, in this dataset, we have already identified\n35.5K tweets from 822 state\u2013sponsored Twitter accounts\nbased on ground\u2013truth data provided by Twitter itself \u2013 a\nlarge sample of state\u2013sponsored disinformation campaigns\nfrom \u201ctroll\u201d accounts which operated during that period. Let\nus note that \u201ctroll\u201d is any account that deliberately spreads\ndisinformation, tries to inflict conflict or causes extreme\nemotional reactions. Hence, our dataset contains valuable in-\nformation of ground\u2013truth malicious activities which in fact\nwere the subject of a previous study regarding the trolls\u2019\nactivities during the 2016 US elections (Salamanos et al.\n2021).\nIn the retweeting process, there are two actors; (i) the\nretweeter ; (ii) the root\u2013user, i.e., the user who posted the\noriginal tweet (root\u2013tweet ). We concentrate our attention on\nretweets that are sufficiently rich in terms of the information\ntransmitted and the population of users that acted as retweet-\ners. For this reason, we concentrate on cascades for which\nthe root\u2013tweet contains at least one web or media URL. We\nalso dropped cascades with less than 100 retweeters. Tweets\nthat very few users have retweeted do not provide enough\ninformation, even collectively, regarding their political po-\nsitions. Following this approach, we analyse 46.4K retweet\ncascades consisting of 19.6M tweets (Table 2).\nLabeling URLs To perform supervised/semi-supervised\nlearning, we need to label the collected URLs as \u201cfake\u201d,\n\u201cnon-fake\u201d or\u201cunknown\u201d. Towards that end, we apply the\nfollowing methodology:\nStep 1 - Unshortening URLs: The first step involves ex-\npanding URLs created from URL shortening services, such\nas bitly (Bitly 2021), tinyurl (TinyURL 2021), etc. This step\nis required to identify different short URLs that correspond\nto the same expanded URL. This step increases the proba-\nbility of having a URL match with pre-existing annotated\nURLs from other research projects related to the 2016 US\nelections, as we explain in the next step. During this step,\nwe use the unshrtn3tool to expand the URLs.\n2https://www.tweepy.org/\n3https://github.com/DocNow/unshrtn\n749\nLabel Initial Labeling Manual Labeling Difference\nFake 4,386 4,556 +170\nNon Fake 915 1,969 +1,054\nUnknown 38,688 37,464 -1,224\nTotal 43,989 43,989\nTable 4: US Elections dataset: The number of labeled URLs\nobtained at each step of the labeling methodology.\nLabel HeathRelease HealthStory\nFake 198 374\nNon Fake 231 1036\nTotal News 429 1410\nTable 5: FakeHealth repository: Number of news along with\ntheir labels in the collected datasets\nStep 2 - Pre-existing Labels: Our dataset includes web-\npages related to the 2016 US elections, a well-studied\ndataset with many related research projects available in\nopen-source version control systems, such as GitHub and\nGitLab. Thus, during this step, we aggregate more than 25\nrelated projects with annotated URLs and combine them into\na single database with \u22480.5M labeled URLs. Note that we\nonly focused on the \u201cfake\u201d and \u201cnon-fake\u201d labels and ex-\nclude any other labeling schemes (i.e., humor, satire, etc.)\npresent in the other open-source projects.\nStep 3 - Labeling Consistency check: During this step we\nexamine the labeling consistency across all the datasets we\ncombine during Step 2. We have kept only consistent labels,\nwhile leaving the inconsistent ones for manual validation, as\nwe will explain in the next step.\nStep 4 - Matching URLs and Labels: During this step, we\nperform a URL match between the URLs that we extract\nfrom our dataset and the one we created by aggregating la-\nbels from other open datasets related to the 2016 US elec-\ntions (Davis 2016; Szpakowski 2020; Macinec 2021). The\noutput of this step is depicted in Table 4 (second column)\n\u201cInitial Labeling\u201d.\nStep 5 - Manual Labeling / FactCheck: To increase the to-\ntal number of labeled URLs, we then turn our attention to\nthe \u201cUnknown\u201d URLs of the Initial Labeling phase. We use\nfour different FactChecking tools, 1. PolitiFacts (PolitiFacts\n2020), 2. Media Bias/Fact Check (MBFC) (MBFC 2020), 3.\nFactCheck (FactCheck 2020), 4. Snopes (Snopes 2020), and\nwe manually annotate a subset of the unknown URLs. Since\nthis step is very time-consuming, we only focused on ex-\npanded URLs that correspond to more than one short URL\n(see Step 1 above) in our dataset.\nThe final number of each label is depicted in Table 4\n(third column - \u201cManual Labeling\u201d), while the final column\n(\u201cDifference\u201d) depicts the difference between the Initial\nLabeling and the Manual Labeling steps.FakeHealth Datasets\nIn order to evaluate our method we utilize two datasets of the\nFakeHealth repository (Dai, Sun, and Wang 2020). Due to\nthe twitter policy of protecting user privacy, the full content\nof user engagement and network are not allowed to be pub-\nlished by the authors, instead, the authors provide a useful\nAPI available at https://github.com/EnyanDai/FakeHealth.\nThe API provides the code and details on how to download\nthe full content of users social engagements and network.\nUsing the provided API we collect all related information,\na summary is depicted in Tables 3 and 5. Note that the final\nnumbers reported in the above tables is lower by \u22481.1%\nthan the numbers reported by the original authors. This can\nbe attributed (1) to changes on behalf of the twitter users\nthat choose to disallow public access of there tweets, (2) the\ntweeter itself delete the tweet due to some internal policies,\n(3) or the tweeter user account has been deleted.\nThe Meta-Graph Approach\nBefore we give the meta-graph\u2019s construction details, we\nfirst provide a formal definition of the data structure.\nDefinition 0.1 (Meta-graph). LetG= (V, E )be a graph\nwith vertex set Vand edge set E. Let also XviandRei,jbe\nthe feature vectors of node viand of edge ei,jrespectively.\nWe call Gameta-graph constructed from a set of events in a\nsocial network, if each event corresponds to a vertex vi\u2208V,\nand the feature vectors XvandRei,jencode both user and\nevent relational information.\nThe node feature vectors in Definition 0.1 encode three\ntypes of features: user attributes, tweet content, and cascade\nstructural information. A minimalist node feature vector Xv\ncan be described as\nXv= (Cemb||Xu||Temb||S...), (1)\nwhere \u201d|| \u201d is the vector concatenation operation, Cembis the\ncascade embedding vector (obtained by using some graph\nembedding method, in our case DeepWalk (Perozzi, Al-\nRfou, and Skiena 2014)), Xuare the concatenated feature\nvectors of all users present in the cascade, and Tembis the\ntext embedding vector (Devlin et al. 2019), provided that\nthe tweet also has the text content. Sis a vector of senti-\nment analysis scores if one such vector can be constructed,\ndepending on the presence of text within the cascade tweets.\nThe user feature vectors concatenated into Xucontain infor-\nmation related to the user account itself, such as date of cre-\nation, number of followers, number of tweets, geolocation\ndata, topic categories, sentiment analysis label and scores,\netc. This formulation allows trivial expansion of node fea-\ntures by concatenating representative vectors from other\nsources when available.\nThe meta-graph\u2019s edges are initially constructed based on\ncommon users or a common topic (URL or tweet text). The\ncorresponding edge feature attributes encode cascade sim-\nilarity and tweet content similarity, once more defined in a\nvery general manner. An example of a cascade feature vector\nis:\nRei,j= (Nui,j||Vi,j||Hi,j...), (2)\n750\n, where Nui,jrepresents a one-element vector containing\nthe number of common users in cascades iandj,Vi,jis\nthe value of a graph similarity metric (Zager and Verghese\n2008; Blondel et al. 2004; Zhao et al. 2020; Bisseling 2020)\napplied to the two cascades. Hi,jstands for a content simi-\nlarity metric (Gomaa and Fahmy 2013) between the contents\nof the original root tweets (and possibly retweets) of the two\ncascades, if available. The edge feature vector can, similar\nto the node feature vector, be trivially expanded to include\nadditional relational information between cascades.\nThe Meta-Graph Construction\nThere are two main obstacles to be addressed in order to ap-\nply our methodology to the data provided by Twitter. First,\nthe actual social network \u2013 the follower graph \u2013 is mostly\nunknown; the users\u2019 follower lists are not always accessi-\nble. Second, the raw data returned by the Twitter API have\nlimited information (by design) regarding the source of in-\nfluence in a given retweet cascades. The only available in-\nformation provided is the root\u2013tweet and the root\u2013user for\na given retweet. In other words, all the retweeters are con-\nnected with the root\u2013user. This star\u2013like cascade structure\n(Figure 1(a)) does not depict the true chain of retweet events,\nwhich in fact is a tree, like the one presented in Figure 1(b).\nWe use the following steps to address the above issues:\nStep 1: Construct a graph that approximates the Twitter so-\ncial network.\nStep 2: Map a cascade to social affiliations of the users that\nparticipate in the cascade. The resulted graph is a subgraph\nof the social network. Then, we compute its embedding in a\nlow dimensional space.\nStep 3: Construct the final meta-graph.\nWe have to note that, we concentrate our analysis on\npure retweet cascades, only. In this way, we ensure that the\ntext that has been diffused by a given cascade (a chain of\nretweets) was exactly the same with the original/root tweet-\ntext. For this reason, we have excluded the \u201cquotes\u201d from the\nmeta-graph construction. A quoted-tweet is a special case\nof retweet, where the retweeter has added an additional text\nabove the original one.\nThe Social Network We leverage the users\u2019 activity as\nit is recorded in the data to construct an approximation of\nthe follower graph \u2013 the true social network which is not\npublicly available to a large extent. In the Twitter platform,\nthe interactions between users belong in three categories;\nreplies, retweets, and quotes \u2013 a special form of retweet\n\u2013 and mentions. Based on these actions, we construct a\ngraph/network of interactions between the users. We map\nusers to nodes and directed edges to interactions. For exam-\nple, if a user\u2013i has replied to a user tweet\u2013j, then we add\nthe edge (i, j). The direction of the edge implies that iis\nafollower ofj, while the reverse direction represents the\ninformation flow from jtoi. In conclusion, we map users\nto nodes and use the interactions between users to define\nthe edges. This process outputs a multi\u2013graph, where many\nedges may connect the same pair of users. For this reason,\nwe discard the duplicate edges keeping only the earliest one.\nUS Elections dataset: The overall graph has 9.32Musers/nodes connected with 84.1M directed edges. For the\npurpose of our analysis, the final social network is repre-\nsented by the induced subgraph formed from the 3.63M\nusers \u2013 retweeters and root-users who participated in the\nretweet cascades \u2013 who are connected with 61.05M directed\nedges.\nRegarding the two FakeHealth datasets: In the HealthRe-\nlease we have 9,055 total users that participate in the retweet\ncascades. The corresponding social network counts 8,218\nusers (nodes) connected by 10,510 edges. In the HealthStory\nthe total number of users is 64,593. The corresponding so-\ncial network consists of 57,851 users and 88,750 edges.\nThe FakeHealth repository includes the user-following\nadjacency lists who represent the ground-truth social net-\nworks. Specifically, in the HealthRelease we have 8,566\nusers connected by 177,866 edges. The HealthStory con-\nsists of 62,011 users and 3,402,241 edges. Having this in-\nformation available, We compare the \u201cempirical\u201d social net-\nworks which we constructed based on the users\u2019 actions with\nthe ground user-following relations that are available for the\nHealthRelease and HealthStory. In short, for both datasets,\nwe constructed the \u201cempirical\u201d social network based on the\nactions between the users (mentions, replies, retweets). We\nrestrict our attention only to those users who participated in\nretweet cascades, since only this graph region is involved in\nthe meta-graph method. Then, we compared the \u201cempirical\u201d\nedges (i.e. relations) with the ground-truth ones. The 65%\nand 59% of the \u201cempirical\u201d edges for the HealthRelease\nand HealthStory respectively, appear in the ground-truth. Al-\nthough these numbers are not very high they do not affect the\noverall validity of the meta-graph method. Our goal is not to\npredict the ground-truth social network but to use past inter-\nactions among the users in order to construct a small graph\n(per cascade) where we can compute the DeepWalk embed-\nding.\nFrom Cascades to Graph Embeddings As we men-\ntioned previously, a retweet cascade is a series of chain\nevents upon the same root\u2013tweet. Some of the users have di-\nrectly retweeted the root\u2013tweet, whereas some others have\nretweeted a retweet of a friend on the same root\u2013tweet\n(retweet of a retweet). This tree\u2013like structure is the true\nretweet cascade (see Figure 1(b)) and reflects the diffusion\npath of information that has been transmitted by the users\nin the social network. The problem we face here is that the\ndata provided by Twitter do not represent the true cascades.\nThe raw data contain only the retweet & retweeter IDs and\nthe root\u2013tweet & the root\u2013user IDs. Hence, it is unknown\nwho was influenced by whom during the retweeting process.\nThe raw\u2013data correspond to a star\u2013like graph where all the\nretweeters are connected with the root\u2013user. As a result, this\nform does not provide sufficient structural information. This\nis a well-known problem in the literature and many methods\nhave been proposed to estimate the true diffusion path (Goel\net al. 2015).\nTo address this problem, we leverage the social network\nwe have constructed. We construct a subgraph formed by\nthe interactions that the retweeters of this cascade have had\nin the past. Specifically, for a given retweeter iwho per-\n751\nFigure 1: (a) The raw data that are provided by Twitter API correspond to a star graph structure. (b) The true retweet cascade\ntree, which is actually unknown, highlights the root tweet and subsequent retweets i.e the true series of retweet events. (c) The\nproposed meta-graph data structure: every node represents a Twitter cascade. The cascade features are given by the cascade\nvector embedding; the user features vector; the tweet text embedding and sentiment analysis scores (if retweet text is available).\nThe edge features represent cascade structural similarity, i.e number of common users. This can easily be expanded with\nadditional attributes, either from current or external datasets.\nformed her retweet at date t, we identify which friends she\nhad before the date tand which of them belong to the set of\nretweeters of this cascade. Then we append this set of edges\n(if any) with the star\u2013like structure, where each retweeter\nis connected with the root\u2013user. Finally, we discard any du-\nplicate edges and produce the undirected version. By this\nmethod, the subgraph is always connected. The extreme case\noccurs when the retweeters did not have any previous inter-\naction. Then, the resulted graph coincides with the raw data\ncollected from Twitter. In summary, the subgraph is just the\nstar\u2013like graph (i.e., the raw Twitter data) enhanced by the\nretweeters\u2019 social relations. This construction per cascade\nrepresents the social structure that the participants of the cas-\ncade had before being activated and be able to perform their\nretweet.\nEach cascade should use the corresponding subgraph\nas a feature that will reflect the structural (social) relation\nthat the cascades\u2019 participants had. To achieve that, in\na consistent way, we produce the embedding of each\nsubgraph to a low dimensional space. We use the Deep-\nWalk algorithm (Perozzi, Al-Rfou, and Skiena 2014) and\nspecifically the Karate Club extension library\u2019s imple-\nmentation for NetworkX (Rozemberczki, Kiss, and Sarkar\n2020). The DeepWalk embedding is a N\u00d7128 matrix,\nwhere Nis the number of users that participated in the\ncascade. We applied the default parameters of this im-\nplementation, that is: (i) Number of random walks =\n10; (ii) Length of random walks = 80 ; (iii)\nDimensionality of embedding = 128.\nTopics and Sentiment Analysis While the previous set of\nfeatures were concerned with user similarity and relational\ninformation extracted from the social network, the final fea-\ntures, which complete the meta-graph, are focused on se-\nmantics and subject-based grouping of tweet-retweet cas-\ncades. For this purpose we carry out two tasks, topic de-\ntection (on the US Elections dataset) and sentiment analy-sis of the root-tweet content. For the former, as the initial\nnumber of topics covered by our dataset is unknown, we\nemploy a Hierarchical Dirichlet Process (HDP) (Teh et al.\n2005; Newman et al. 2009), using the Tomotopy library\n(bab2min and Fenstermacher 2021). Three parameters of the\nHDP model are changed from the default values, namely\nmin cf= 5, gamma = 1 and alpha = 0. 1, as these pro-\nduce the best results. For term weighing, we produce three\ninstances of the model with equal term weighing, Point-wise\nMutual Information-based weighing and Inverse Frequency\nterm weighing (low weights for terms with high occurrence\nand vice-versa). After training the three versions of the HDP\nmodel on our tweet content, we use them in order to assign\na topic ID to each tweet-retweet cascade.\nThe second step in the process is to perform sentiment\nanalysis on the root-tweet of each cascade. This is done us-\ning a pre-trained BERT language model, with the help of\nthe Transformers library (Wolf et al. 2020). Along with the\nthree topic identifiers obtained above, the sentiment label\nand sentiment score form the semantic features used in our\napproach.\nThe semantic information, together with the embeddings\nobtained in the previous section, represent the features of\neach individual cascade, in the case of graph-level classi-\nfication, or of each individual node, in the meta-graph, for\nthe node-classification task. In the case of cascades, it is as-\nsumed that retweets share the topic and sentiment of the root\ntweet.\nThe Meta-graph The final step is the construction of the\nmeta-graph itself. That is, a meta\u2013structure represented by\na graph that has the retweet cascades as nodes. The edges\nof the meta-graph are defined by the proximity among the\ncascades in terms of their retweeter population.\nIn particular, two cascades iandjare connected by\nan edge if |RTi\u2229RTj| \u2265 1, where RTiandRTjare\nthe set of retweeters of iandj. In other words, two cas-\n752\nFigure 2: Meta-graph visualization for the US Elections\ndataset: Giant component of the meta-graph produced by\nthe disparity filtering with \u03b1=0.1. \u201cFake\u201d nodes/cascades\nhave been colored red, while the \u201cnon\u2013fake\u201d nodes are\ngreen. The meta-graph consists of 8291 cascades connected\nby 1,363,702 undirected edges and it has 3 connected\ncomponents. The giant component counts 8282 nodes and\n1,363,680 edges.\ncades are connected by an edge when they share at least\none retweeter. In conclusion, the meta-graph is always an\nundirected weighted graph, where the weight of each edge\nis equal to the number of retweeters that participate in\nboth nodes/cascades. In case that the meta-graph is very\ndense, we apply the disparity filtering method for undirected\nweighted graphs (Serrano, Bogu \u02dcn\u00b4a, and Vespignani 2009).\nGiven a significance level \u03b1, the disparity filter identifies\nwhich edges should be preserved in the graph (see Equation-\n2 in (Serrano, Bogu \u02dcn\u00b4a, and Vespignani 2009)).\nUS Elections dataset: The meta-graph of 8323 la-\nbeled cascades counts 8323 nodes/cascades connected by\n15,946,910 undirected edges. Since the graph is extremely\ndense, we apply the disparity filter. In particular, we evalu-\nate this approach for several \u03b1values by producing first the\ncorresponding filtered meta-graphs and then by performing\nthe classification in each one independently. For \u03b1 > 0.1,\nthe classification accuracy does not change significantly (see\nTable 6) even when only the 16% of the edges are present\n(\u03b1= 0.2). We get the best accuracy 87.70 for \u03b1= 0.5\n(49% of the edges survived the significance test) which for\ndemonstration purposes we also present later on, in the final\nevaluation section.\nAs an example, Figure 2 presents the giant component of\nthe meta-graph that has been produced by the disparity fil-\nter for \u03b1= 0.1. 8291 nodes/cascades out of the 8323 are\nconnected by 1,363,702 undirected edges. The graph has 3\nconnected components. The giant component counts 8282\nnodes and 1,363,680 edges.\nFakeHealth datasets: In the HealthRelease the full ver-\nFigure 3: Giant components of the HealthRelease (upper\nfigure) and HeathStory meta-graphs (lower figure). \u201cFake\u201d\nnodes/cascades have been colored red, while the \u201cnon\u2013fake\u201d\nnodes are green. Both are connected graphs.\nsion of the meta-graph counts 1969 cascades connected by\n11,581 undirected edges (Figure 3, upper figure). In the\nHealthStory the full meta-graph consists of 13,263 cascades\nconnected by 100,001 edges (Figure 3, lower figure). Since\nthese graphs are not very large, We use the full version for\nthe classification.\nNode features: The features of a given node/cascade with\nNusers (the retweeters plus the root\u2013user) are the follow-\ning: (1) The DeepWalk embedding of the correspondent\nsubgraph \u2013 a N\u00d7128matrix; (2) The dates of users\u2019 ac-\ncount creation; (3) The maximum value of users\u2019 followers\ncount; (4) The maximum value of users\u2019 friends count; (5)\nThe maximum value of users\u2019 statuses count; (6) The maxi-\nmum value of users\u2019 favorites count; (7) A Boolean identifier\nwhether the users\u2019 account is verified; (8) The language of\nthe users\u2019 account. Note that features 2 to 8 comprise an ar-\nray of length N. The maximum values per user are based on\nthe retweets that the user has posted; (9) The most represen-\ntative topic of the root\u2013tweet based on the three topic mod-\nels \u2013 three values. Regarding the two FakeHealth datasets,\nwe set as topics the news\u2019 \u201ctags\u201d and \u201ccategory\u201d. This in-\nformation is provided by the \u201creviews\u201d in the FakeHealth\nrepository; (10) The sentiment (label, score) of the root\u2013\ntweet \u2013 two values, either (2, score )for \u2019Positive\u2019 label or\n(1, score )\u2019Negative\u2019 label.\nRegarding the US Elections dataset, we note that we anal-\nyse the retweet cascades in which at least one URL is em-\nbedded in the root\u2013tweet. Since the labeled part of the data\nis the URLs, we use these labels as ground\u2013truth. We fo-\ncus our attention on the 6525 URLs that have been labeled\nas \u201cfake\u201d and \u201cnon\u2013fake\u201d (Table 4). For each URL, we col-\nlect the cascades that had this URL embedded in their root-\n753\n\u03b1Number\nof NodesNumber\nof EdgesAccuracy of\nGCNConv (%)\n0.01 8171 300,330 83.96\n0.02 8221 434,643 84.06\n0.03 8246 555,934 84.20\n0.04 8260 673,595 84.46\n0.05 8262 788,212 84.44\n0.06 8268 902,797 84.56\n0.07 8277 1,016,344 84.68\n0.08 8285 1,131,124 85.04\n0.09 8290 1,247,597 85.17\n0.1 8291 1,363,702 85.34\n0.2 8310 2,606,347 86.52\n0.3 8311 4,079,032 86.60\n0.4 8315 5,742,849 87.64\n0.5 8319 7,763,018 87.70\n0.6 8319 9,899,401 87.66\n0.7 8319 12,536,442 86.91\n0.8 8320 14,866,835 87.12\n0.9 8320 15,829,764 86.45\nTable 6: US Elections dataset: GCNConv performance on\nmeta-graphs produced by the disparity-filter for different\nvalues of the significance level \u03b1.\ntweets. Moreover, there is no one\u2013to\u2013one correspondence\nbetween the cascades and the URLs \u2013 multiple cascades may\nhave spread the same URL. This is why the number of la-\nbeled cascades is larger than the number of labeled URLs.\nMoreover, a cascade might contain several URLs, \u201cfake\u201d and\n\u201cnon\u2013fake\u201d ones. In this case, we discard these cascades.\nEvaluation of Performance Benefits\nIn order to evaluate the benefits of the meta-graph method,\nwe perform a series of experiments aiming to address the\nfollowing research questions: How effective is the meta-\ngraph structure for the cascade classification? Will the topics\n(broad subject shared by a set of tweets) and sentiment labels\n(positive or negative sentiment, together with the confidence\nscore) improve the separation of classes if they are included\nin the features?\nIn order to address these questions, we follow two classi-\nfication strategies: (1) First, we ignore the information that\nis represented by the meta-graph edges and we reduce the\nproblem to a graph classification task. Each retweet cascade\nis represented by a subgraph of the social network (see Sub-\nsection \u201cThe Meta-Graph Construction\u201d), namely a small\ngraph which consists of those users who have been involved\nin the cascade. The users\u2019 features are those we presented in\nSubsection \u201cThe Meta-Graph Construction\u201d. Moreover, we\nassume that each user inherits the topic and sentiment label\nfrom the root\u2013tweet. In other words, for a given cascade, all\nusers have the same topic and sentiment label as feature. (2)\nThe second classification approach is node-classification in\nthe meta-graph level, where each node corresponds to a cas-\ncade (see Figure 1(c)). In other words, we classify the nodes\nof the meta-graph based on the meta-graph structure to-\ngether with the nodes/cascades features. Now the nodes cor-\nrespond to individual cascades. In both approaches, we relyModelCascade\nClassificationMeta-graph\nNode Classification\n2016 US Presidential Election Dataset\nWithout Topics\nand Sentiment\nAnalysisAccuracy\n(%)F1\nScoreAccuracy\n(%)F1\nScore\nGCNConv 83.30 0.721 86.75 0.812\nGATConv 83.28 0.716 85.52 0.793\nHypergraphConv 82.17 0.693 85.67 0.791\nSAGEConv 82.23 0.702 85.12 0.787\nWith Topics\nand Sentiment\nAnalysisAccuracy\n(%)F1\nScoreAccuracy\n(%)F1\nScore\nGCNConv 84.23 0.748 87.70 0.830\nGATConv 83.74 0.732 86.62 0.822\nHypergraphConv 83.91 0.731 86.67 0.825\nSAGEConv 83.42 0.727 86.84 0.810\nHealth Release Dataset\nWith Topics\nand Sentiment\nAnalysisAccuracy\n(%)F1\nScoreAccuracy\n(%)F1\nScore\nGCNConv 86.54 0.890 88.07 0.936\nGATConv 84.43 0.753 87.81 0.903\nHypergraphConv 85.76 0.794 86.60 0.892\nSAGEConv 84.82 0.758 86.74 0.896\nHealth Story Dataset\nWith Topics\nand Sentiment\nAnalysisAccuracy\n(%)F1\nScoreAccuracy\n(%)F1\nScore\nGCNConv 59.23 0.616 60.16 0.751\nGATConv 60.18 0.632 61.03 0.757\nHypergraphConv 56.80 0.587 58.70 0.735\nSAGEConv 57.36 0.590 57.36 0.726\nTable 7: Classification results obtained with four different\ngraph neural network types, on three datasets: the 2016 Pres-\nidential Election dataset and the FakeHealth package, com-\nposed of the Health Release and Health Story datasets.\non the same subgraphs from the constructed meta-graph. In\naddition to these and in order to justify the need for topic\nmodeling and sentiment analysis, we compare the two clas-\nsification strategies with and without the use of topics and\nsentiments as nodes features. The intuition is that the topic\nmodeling and sentiment analysis introduce semantic infor-\nmation in the meta-graph structure, providing a quantifiable\nmeasure of agreement as well as topical relational informa-\ntion to other nodes.\nOur findings show that: (1) This method of connecting\ncascades/nodes is effective enough to improve by 3%\u20134%\nthe classification accuracy. In the meta-graph two cascades\nare connected by an edge if they have at least one retweeter\nin common. (2) When we include the topics and sentiment\nlabels as features, the accuracy of all classifiers is increased\nby approximately 1%.\nRegarding the actual methods, we applied the follow-\ning state-of-the-art graph neural networks (GNNs) for both\ngraph and node classification: GCNConv (Kipf and Welling\n2016), SAGEConv (Hamilton, Ying, and Leskovec 2017),\nHypergraphConv (Bai, Zhang, and Torr 2021) and GAT-\n754\n#Ne\nws Article Title Source\n1Clinton:\nPlanned Parenthood videos \u2019disturbing\u2019 https://edition.cnn.com/2015/07/29/politics/hillary-clinton-planned-parenthood-anti-abortion/index.\nhtml\n2 Hillary Clinton Email Archive - Wikileaks https://wikileaks.org/clinton-emails/\n3 4 key moments from tonight\u2019s messy debate https://edition.cnn.com/politics/live-news/presidential-debate-coverage-fact-check-09-29-\n20/index.html\n4 Transcript of the Second Debate https://www.nytimes.com/2016/10/10/us/politics/transcript-second-debate.html\n5 FBI probing new emails related to Clinton case https://www.cnbc.com/2016/10/28/fbi-probing-new-clinton-emails.html\n6 Emails Related to Clinton Case Found in Anthony Weiner Inves-\ntigationhttps://www.nbcnews.com/news/us-news/fbi-re-open-investigation-clinton-email-server-n674631\n7 Hillary Clinton Leads Donald Trump by 14 Points Nationally in\nNew Pollhttps://time.com/4546942/hillary-clinton-donald-trump-lead-poll/\n8 John Podesta email article https://en.wikipedia.org/wiki/Podesta\\ emails\n9Are\nFake News Polls Hiding a Potential Trump Landslide? https://www.americanthinker.com/articles/2020/07/are fak\nenewspolls hiding apotential trump\nlandslide.html\n10Russian\ntrolls\u2019 chief target was \u2019black US voters\u2019 in 2016 https://www.bbc.com/news/technology-49987657\nFigure 4: US Elections dataset: Top: The top-10 Topics by the Hierarchical Dirichlet Process (HDP) when all terms weighted\nequally. Bottom: The corresponding web-articles of each topic.\nConv (Veli \u02c7ckovi \u00b4c et al. 2017).\nFor the graph classification task, we have applied the al-\ngorithms to the 8318 subgraphs (after filtering contradictory\nlabels). As the treated graphs are relatively small, and GNNs\ngenerally do not benefit from an increase in the number of\nlayers (Oono and Suzuki 2020; Li, Han, and Wu 2018; NT\nand Maehara 2019; Alon and Yahav 2020), we restrict the\nmodels to one graph feature extraction layer and one dense\nlayer. We also use a 60-20-20 train-validation-test split. The\nGNNs have been implemented in PyTorch Geometric (Fey\nand Lenssen 2019), maintaining the following hyperparam-\neters constant across experiments:\n# of epochs = 50,dropout = 0.8,learning rate = 10\u22124\nIn Table 7 we present the obtained results, which show a\n3%-4% gain in accuracy in favor of the meta-graph method,\ni.e. for the node classification task. We get the best perfor-\nmance when we include the topics and sentiment labels. For\nstate-of-the-art algorithms this represents a significant gain,\nand primarily depends on the inclusion of relational infor-\nmation between retweet cascades. Regarding the topic mod-\neling and sentiment analysis, we observe that the 1% gain\nin accuracy, is nonetheless an indicator that the discoveredtopics and sentiment labels indeed lead to an improvement\nto the separation of the classes.\nDue to the imbalance of the dataset, we also present F1\nscores for all our experiments. We observe a general consis-\ntency in terms of the advantage provided by the meta-graph\nmethod compared to regular cascade classification. In par-\nticular, the extra relational information present in the meta-\ngraph does contribute to the reduction of the number of false\npositives and false negatives.\nIn Table 7 we also present results for two health-related\nmisinformation datasets, namely HealthRelease and Health-\nStory. These smaller datasets have the added disadvantage\nof simpler cascade structures. While most cascades present\ncontain a small number of users (sometimes just a tweet-\nretweet pair), larger cascades tend to have a star-graph\nshape. This reduces the structural information that our pro-\nposed method uses, with the help of graph embedding algo-\nrithms, such as DeepWalk.\nWe conclude the analysis by portraying a representative\nsample of the topic modeling in order to emphasize the ef-\nfectiveness of this approach. Figure 4 depicts the top\u201310\ntopics based on the HDP-model (Hierarchical Dirichlet Pro-\n755\ncess) when all terms weighted equally. For each topic in the\ntop\u201310 we plot the top\u201310 terms by their log-likelihood val-\nues. In addition, in Figure 4 (Bottom), for each top\u201310 topic\nwe show a representative news article related to the period of\nthe 2016 Presidential elections. For instance, the top terms\nof Topic-1 and Topic-2 reflect the \u201dPlanned Parenthood\u201d de-\nbate and the Wikileaks source related to Hillary\u2019s Clinton\nleaked emails, respectively.\nDiscussion\nOur proposed method addresses the detection of disinfor-\nmation in social networks, by exploiting network structure\nas well as post content and user sentiment. The example\ndatasets focus on the Twitter social network, whose char-\nacteristic is given by the shortness of exchanged user mes-\nsages. This has an effect on two components of our method:\nthe sentiment analysis component and the text embedding.\nAs some tweets may not contain any original content, and\nrepresent just links (retweets) to other user\u2019s posts, we have\ndesigned our method to be robust to this particular type of\ninformation scarcity, by exploiting network structure wher-\never possible.\nNetwork structure is an important aspect with a clear im-\npact on classification results. The meta-graph is constructed\nfrom individual tweet-retweet cascades. As such, the struc-\ntural information of the cascade is contained within a part\nof the corresponding features of the meta-graph node. These\nfeatures are obtained by using graph embedding algorithms,\nfor example DeepWalk, in order to capture cascade structure\nand connectivity patterns. In the case of very small cascades,\nor when the majority of cascades have star-graph shapes, the\nembedding vectors are very similar. The effects of this on\nthe performance of our method are visible in Table 7, for the\nspecific case of HealthStory.\nIn the present paper we adopt a simple method for trans-\nferring the URL labels, namely the labels of the root tweet\ncontent, to the entire cascade, by assuming that the label of\nthe cascade is given by the label of the content of its root\ntweet. This can, in some situations, create problems, for in-\nstance if the root tweet and all following retweets share a\nURL containing false information, with the explicit purpose\nof exposing it, the entire cascade will be labeled as disinfor-\nmation. We deal with this potential issue by removing \u201dquote\ntweets\u201d, containing additional text. If retweet contents are\navailable, then one can easily expand this trivial labeling to\ntake the already computed sentiment analysis scores into ac-\ncount. If the sentiment scores are strongly negative, a dis-\nagreement between the tweets and URL content can be de-\ntected and the label of the cascade can be adjusted accord-\ningly.\nDue to the nature and structure of our considered datasets,\na direct benchmark comparison with similar algorithms such\nas FANG (Nguyen et al. 2020) and Hierarchical Propaga-\ntion Networks (Shu et al. 2019b) is not possible, as the men-\ntioned algorithms require the construction of different types\nof graphs, for which the considered datasets do not contain\nthe relevant information. An example is the heterogeneous\ngraph required for the FANG algorithm, where both arti-\ncles/posts and users are interconnected nodes.The strength of our method relies on it\u2019s capacity to treat\ninformation-scarce datasets as long as structure can be ex-\nploited, due to the graph embedding features playing a cen-\ntral role. This also displays the inadequacy of the method to\ndatasets which have very limited graph structure, such as the\nHealthStory dataset, on which the performance both in terms\nof accuracy and F1 score is very low. In limit-cases, for ex-\nample in treating isolated nodes, the node classification task\nnaturally reduces to a simple graph (cascade) classification\ntask. As such, the meta-graph approach does not need to re-\nmove or provide special treatment to isolated nodes.\nConclusion\nRecent false information detection and classification\nmethodologies rely on user features extracted from the so-\ncial network, network structure, or the posting (in our case,\ntweet) content itself. This paper aims to unify these ap-\nproaches via the use of a single data structure, which we\ncall a meta-graph. The meta-graph node features represent\nretweet cascades, containing information about the tweet-\nretweet event and the individual users taking part in it. En-\ncoded within the node features, we also add the tweet con-\ntent, where available. At the same time, the edge features\ncontain feature vectors whose elements are similarity met-\nrics between cascades. This information is beneficial when\nonly a small number of cascades in the meta-graph are la-\nbeled.\nBy combining all available information about a social-\nnetwork event into a single data structure, we pro-\nvide a graph-specific classification algorithm with an\ninformational-rich data format that allows it to outperform,\nin terms of classification accuracy values, approaches based\non isolated elements (such as individual graphs). The ad-\nditional similarity information among pairs of cascades is\nbeneficial in semi-supervised classification settings because\nlabels are routinely hard to obtain, and only a small fraction\nof the data may have them.\nAnother advantage of the method is the size of the dataset\nitself. Even if the meta-graph contains considerably more in-\nformation than the individual constituent cascades, the stor-\nage cost is not prohibitive. In our case, the largest con-\nstructed meta-graph occupies approximately 3 GB.\nThe presented formalism opens the door for a wide range\nof future extensions. The meta-graph can be generalized\nto include not just bipartite relations between events (cas-\ncades), but also multipartite ones, thus converting the data\nstructure into a hypergraph. Another possible research di-\nrection is concerned with finding the optimal features to in-\nclude for nodes and edges. This is far from trivial, as there\nis a large variety of parameters available, characterizing a\ntweet or a particular user, as well as many ways in which\nthe graph structure of the cascades can be encoded. Finally,\nrelation learning, similar to the case of knowledge graphs,\ncan be considered, and learned edge features be added to\nexisting ones.\n756\nAcknowledgement\nThis project has been funded by: (i) the European Union\u2019s\nHorizon 2020 Research and Innovation program under\nthe Cybersecurity CONCORDIA project (Grant Agree-\nment No. 830927) and under the Marie Sk\u0142odowska\u2013\nCurie INCOGNITO project (Grant Agreement No. 824015);\n(ii) the TV-HGGs project (OPPORTUNITY/0916/ERC-\nCoG/0003), co-funded by the European Regional Develop-\nment Fund and the Republic of Cyprus through the Research\nand Innovation Foundation.\nReferences\nAhmed, H.; Traore, I.; and Saad, S. 2017. Detection of\nOnline Fake News Using N-Gram Analysis and Machine\nLearning Techniques. doi:10.1007/978-3-319-69155-8 9.\nAlon, U.; and Yahav, E. 2020. On the Bottleneck of Graph\nNeural Networks and its Practical Implications URL arXiv:\n2006.05205.\nbab2min; and Fenstermacher, D. 2021. bab2min/tomotopy.\ndoi:10.5281/zenodo.4719813.\nBai, S.; Zhang, F.; and Torr, P. 2021. Hypergraph convo-\nlution and hypergraph attention. Pattern Recognition 110:\n107637. doi:10.1016/j.patcog.2020.107637.\nBelova, G.; and Georgieva, G. 2018. Fake News as\na Threat to National Security. International conference\nKNOWLEDGE-BASED ORGANIZATION 24: 19\u201322. doi:\n10.1515/kbo-2018-0002.\nBisseling, R. 2020. Graph matching, 291\u2013358. ISBN\n9780198788348. doi:10.1093/oso/9780198788348.003.\n0005.\nBitly. 2021. Bitly - A URL shortener. https://bitly.com/.\nAccessed: 2021-10-01.\nBlondel, V .; Gajardo, A.; Heymans, M.; Senellart, P.; and\nVan Dooren, P. 2004. A Measure of Similarity between\nGraph Vertices: Applications to Synonym Extraction and\nWeb Searching. SIAM Review 46: 647\u2013666. doi:10.2307/\n20453570.\nCastillo, C.; Mendoza, M.; and Poblete, B. 2011. Informa-\ntion credibility on Twitter. 675\u2013684. doi:10.1145/1963405.\n1963500.\nCheng, Y .; and Chen, Z. F. 2020. The Influence of Presumed\nFake News Influence: Examining Public Support for Corpo-\nrate Corrective Response, Media Literacy Interventions, and\nGovernmental Regulation. Mass Communication & Society\ndoi:10.1080/15205436.2020.1750656.\nChenzi, V . 2020. Fake news, social media and xenophobia\nin South Africa. African Identities doi:10.1080/14725843.\n2020.1804321.\nDai, E.; Sun, Y .; and Wang, S. 2020. Ginger Cannot Cure\nCancer: Battling Fake Health News with a Comprehensive\nData Repository. Proceedings of the International AAAI\nConference on Web and Social Media 14(1): 853\u2013862.\nDavis, M. 2016. BuzzFeed News - Facebook Pages\nAre Publishing False And Misleading Information At AnAlarming Rate. https://www.buzzfeednews.com/article/\ncraigsilverman/partisan-fb-pages-analysis. Accessed: 2022-\n02-11.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In Proceedings of the 2019 Con-\nference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technolo-\ngies, NAACL-HLT.\nFactCheck. 2020. FactCheck.org - A Project of The An-\nnenberg Public Policy Center. https://www.factcheck.org/.\nAccessed: 2022-01-21.\nFey, M.; and Lenssen, J. E. 2019. Fast Graph Representation\nLearning with PyTorch Geometric. In ICLR Workshop on\nRepresentation Learning on Graphs and Manifolds.\nGhosh, S.; and Shah, C. 2018. Towards automatic fake news\nclassification. Proceedings of the Association for Informa-\ntion Science and Technology 55: 805\u2013807.\nGoel, S.; Anderson, A.; Hofman, J.; and Watts, D. J. 2015.\nThe structural virality of online diffusion. Management Sci-\nence 62(1).\nGomaa, W.; and Fahmy, A. 2013. A Survey of Text Similar-\nity Approaches. international journal of Computer Applica-\ntions 68. doi:10.5120/11638-7118.\nGuo, H.; Cao, J.; Zhang, Y .; Guo, J.; and Li, J. 2018. Rumor\nDetection with Hierarchical Social Attention Network. 943\u2013\n951. doi:10.1145/3269206.3271709.\nGupta, M.; Zhao, P.; and Han, J. 2012. Evaluating Event\nCredibility on Twitter. Proceedings of the 12th SIAM Inter-\nnational Conference on Data Mining, SDM 2012 153\u2013164.\nHamilton, W.; Ying, Z.; and Leskovec, J. 2017. Inductive\nRepresentation Learning on Large Graphs. In Guyon, I.;\nLuxburg, U. V .; Bengio, S.; Wallach, H.; Fergus, R.; Vish-\nwanathan, S.; and Garnett, R., eds., Advances in Neural In-\nformation Processing Systems, volume 30.\nJin, Z.; Cao, J.; Guo, H.; Zhang, Y .; and Luo, J. 2017. Mul-\ntimodal Fusion with Recurrent Neural Networks for Rumor\nDetection on Microblogs. 795\u2013816. doi:10.1145/3123266.\n3123454.\nKaliyar, R.; Goswami, A.; and Narang, P. 2021. FakeBERT:\nFake news detection in social media with a BERT-based\ndeep learning approach. Multimedia Tools and Application .\nKipf, T.; and Welling, M. 2016. Semi-Supervised Classi-\nfication with Graph Convolutional Networks. arXiv. URL\nhttps://arxiv.org/abs/1609.02907.\nLi, Q.; Han, Z.; and Wu, X.-M. 2018. Deeper Insights into\nGraph Convolutional Networks for Semi-Supervised Learn-\ning URL arXiv:1801.0760.\nMacinec, P. 2021. Fake News Datasets. https://github.com/\npmacinec/fake-news-datasets. Accessed: 2021-12-05.\nMBFC. 2020. Media Bias/Fact Check (MBFC) - The most\ncomprehensive media bias resource on the internet. https:\n//mediabiasfactcheck.com/. Accessed: 2021-11-05.\n757\nNewman, D.; Asuncion, A.; Smyth, P.; and Welling, M.\n2009. Distributed algorithms for topic models. 1801\u20131828.\nNguyen, V .-H.; Sugiyama, K.; Nakov, P.; and Kan, M.-Y .\n2020. FANG: Leveraging Social Context for Fake News\nDetection Using Graph Representation, 1165\u20131174. ACM.\nURL https://doi.org/10.1145/3340531.3412046.\nNT, H.; and Maehara, T. 2019. Revisiting Graph Neural\nNetworks: All We Have is Low-Pass Filters URL arXiv:\n1905.09550.\nOono, K.; and Suzuki, T. 2020. Graph Neural Networks Ex-\nponentially Lose Expressive Power for Node Classification.\nInInternational Conference on Learning Representations.\nPerozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. DeepWalk:\nOnline Learning of Social Representations. In Proceedings\nof the 20th International Conference on Knowledge Discov-\nery and Data Mining, KDD \u201914, 701\u2013710. ACM.\nPolitiFacts. 2020. The Principles of the Truth-O-Meter: Poli-\ntiFact\u2019s methodology for independent fact-checking. https:\n//www.politifact.com/. Accessed: 2021-10-11.\nRozemberczki, B.; Kiss, O.; and Sarkar, R. 2020. Karate\nClub: An API Oriented Open-source Python Framework\nfor Unsupervised Learning on Graphs. In Proceedings of\nthe 29th ACM International Conference on Information and\nKnowledge Management (CIKM \u201920), 3125\u20133132. ACM.\nSafieddine, F. 2020. Political and Social Impact of digi-\ntal Fake news in an era of Social Media, 43\u201358. ISBN\n9781786614223.\nSalamanos, N.; Jensen, M. J.; Iordanou, C.; and Sirivianos,\nM. 2021. Did State-sponsored Trolls Shape the 2016 US\nPresidential Election Discourse? Quantifying Influence on\nTwitter. CoRR URL https://arxiv.org/abs/2006.09938.\nSerrano, M. \u00b4A.; Bogu \u02dcn\u00b4a, M.; and Vespignani, A. 2009. Ex-\ntracting the multiscale backbone of complex weighted net-\nworks. Proceedings of the National Academy of Sciences\n106(16): 6483\u20136488. doi:10.1073/pnas.0808904106.\nShu, K.; Cui, L.; Wang, S.; Lee, D.; and Liu, H. 2019a.\ndEFEND: Explainable Fake News Detection. doi:10.1145/\n3292500.3330935.\nShu, K.; Mahudeswaran, D.; Wang, S.; and Liu, H. 2019b.\nHierarchical Propagation Networks for Fake News Detec-\ntion: Investigation and Exploitation.\nShu, K.; Wang, S.; and Liu, H. 2019. Beyond News Content:\nThe Role of Social Context for Fake News Detection. doi:\n10.1145/3289600.3290994.\nShu, K.; Zhou, X.; Wang, S.; Zafarani, R.; and Liu, H.\n2019c. The role of user profiles for fake news detection.\n436\u2013439. doi:10.1145/3341161.3342927.\nSnopes. 2020. Snopes - Snopes is the internet\u2019s defini-\ntive fact-checking resource. https://www.snopes.com/. Ac-\ncessed: 2022-01-12.\nSzpakowski, M. 2020. Fake News Corpus. https://github.\ncom/several27/FakeNewsCorpus. Accessed: 2022-01-15.Tacchini, E.; Ballarin, G.; Della Vedova, M.; Moret, S.; and\nAlfaro, L. 2017. Some Like it Hoax: Automated Fake News\nDetection in Social Networks.\nTeh, Y . W.; Jordan, M. I.; Beal, M. J.; and M., B. D. 2005.\nSharing clusters among related groups: Hierarchical Dirich-\nlet processes. NIPS\u201905, 1385\u20131392. Advances in Neural In-\nformation Processing Systems.\nTinyURL. 2021. TinyURL - Making over a billion long\nURLs usable! https://tinyurl.com/. Accessed: 2021-05-04.\nVeli\u02c7ckovi \u00b4c, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio,\nP.; and Bengio, Y . 2017. Graph Attention Networks. arXiv.\nURL https://arxiv.org/abs/1710.10903.\nVisentin, M.; Pizzi, G.; and Pichierri, M. 2019. Fake News,\nReal Problems for Brands: The Impact of Content Truthful-\nness and Source Credibility on consumers\u2019 Behavioral In-\ntentions toward the Advertised Brands. Journal of Interac-\ntive Marketing 45: 99\u2013112.\nWesterman, D.; Spence, P. R.; and Van Der Heide, B. 2014.\nSocial Media as Information Source: Recency of Updates\nand Credibility of Information. J. Comp.-Med. Commun.\n19(2): 171\u2013183. doi:10.1111/jcc4.12041.\nWolf, T.; Debut, L.; Sanh, V .; Chaumond, J.; Delangue, C.;\nMoi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; Davi-\nson, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y .; Plu, J.;\nXu, C.; Scao, T. L.; Gugger, S.; Drame, M.; Lhoest, Q.; and\nRush, A. M. 2020. Transformers: State-of-the-Art Natural\nLanguage Processing. In Proceedings of the 2020 Confer-\nence on Empirical Methods in Natural Language Process-\ning: System Demonstrations, 38\u201345. Online: Association for\nComputational Linguistics.\nWu, L.; and Liu, H. 2018. Tracing Fake-News Footprints:\nCharacterizing Social Media Messages by How They Prop-\nagate. doi:10.1145/3159652.3159677.\nWu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; and Yu, P.\n2020. A Comprehensive Survey on Graph Neural Networks.\nIEEE Transactions on Neural Networks and Learning Sys-\ntems PP: 1\u201321. doi:10.1109/TNNLS.2020.2978386.\nZager, L.; and Verghese, G. 2008. Graph similarity scoring\nand matching. Applied Mathematics Letters 21: 86\u201394.\nZhang, S.; Tong, H.; Xu, J.; and Maciejewski, R. 2019.\nGraph convolutional networks: a comprehensive review.\nComputational Social Networks 6.\nZhang, X.; Zhao, J.; and Lecun, Y . 2015. Character-\nlevel Convolutional Networks for Text Classification. In\nAdvances in Neural Information Processing Systems, vol-\nume 28. Curran Associates, Inc.\nZhao, C.; Yin, Z.; Wang, H.; Zhao, X.; and Niu, D. 2020. A\nNovel Method for Graph Matching. 177\u2013181. doi:10.1145/\n3422713.3422730.\nZhou, J.; Cui, G.; Hu, S.; Zhang, Z.; Yang, C.; Liu, Z.; Wang,\nL.; Li, C.; and Sun, M. 2020. Graph Neural Networks: A\nReview of Methods and Applications. AI Open 1: 57\u201381.\nZhou, X.; and Zafarani, R. 2020. A Survey of Fake News:\nFundamental Theories, Detection Methods, and Opportuni-\nties. ACM Computing Surveys 53. doi:10.1145/3395046.\n758", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A unified graph-based approach to disinformation detection using contextual and semantic relations", "author": ["M Paraschiv", "N Salamanos", "C Iordanou"], "pub_year": "2022", "venue": "Proceedings of the \u2026", "abstract": "As recent events have demonstrated, disinformation spread through social networks can  have dire political, economic and social consequences. Detecting disinformation must"}, "filled": false, "gsrank": 637, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/19331", "author_id": ["lNYCkhQAAAAJ", "Ssu-f-sAAAAJ", "Nxo-Yp8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:xRelWHwRAWgJ:scholar.google.com/&output=cite&scirp=636&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=xRelWHwRAWgJ&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 14, "citedby_url": "/scholar?cites=7494290480682047429&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:xRelWHwRAWgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/19331/19103"}}, {"title": "Psychological interventions countering misinformation in social media: A scoping review", "year": "2023", "pdf_data": "fpsyt-13-974782 December 23, 2022 Time: 20:47 # 1\nTYPE Systematic Review\nPUBLISHED 05 January 2023\nDOI10.3389/fpsyt.2022.974782\nOPEN ACCESS\nEDITED BY\nMonica Izvercianu,\nPolitehnica University of Timi\u00b8 soara,\nRomania\nREVIEWED BY\nYajun Zhao,\nSouthwest Minzu University, China\nJon Roozenbeek,\nUniversity of Cambridge,\nUnited Kingdom\n*CORRESPONDENCE\nJan Piasecki\njan.piasecki@uj.edu.pl\nSPECIALTY SECTION\nThis article was submitted to\nDigital Mental Health,\na section of the journal\nFrontiers in Psychiatry\nRECEIVED 21 June 2022\nACCEPTED 30 November 2022\nPUBLISHED 05 January 2023\nCITATION\nGwia \u2019zdzi \u2019nski P, Gundersen AB,\nPiksa M, Krysi \u00b4nska I, Kunst JR,\nNoworyta K, Olejniuk A, Morzy M,\nRygula R, W\u00f3jtowicz T and Piasecki J\n(2023) Psychological interventions\ncountering misinformation in social\nmedia: A scoping review.\nFront. Psychiatry 13:974782.\ndoi: 10.3389/fpsyt.2022.974782\nCOPYRIGHT\n\u00a9 2023 Gwia \u2019zdzi \u2019nski, Gundersen,\nPiksa, Krysi \u2019nska, Kunst, Noworyta,\nOlejniuk, Morzy, Rygula, W\u00f3jtowicz\nand Piasecki. This is an open-access\narticle distributed under the terms of\nthe Creative Commons Attribution\nLicense (CC BY). The use, distribution\nor reproduction in other forums is\npermitted, provided the original\nauthor(s) and the copyright owner(s)\nare credited and that the original\npublication in this journal is cited, in\naccordance with accepted academic\npractice. No use, distribution or\nreproduction is permitted which does\nnot comply with these terms.Psychological interventions\ncountering misinformation in\nsocial media: A scoping review\nPawe\u0142 Gwia\u00b4 zdzi \u00b4nski1,2, Aleksander B. Gundersen3,\nMichal Piksa4, Izabela Krysi \u00b4nska5, Jonas R. Kunst3,\nKarolina Noworyta4, Agata Olejniuk5, Miko\u0142aj Morzy5,\nRafal Rygula4, Tomi W\u00f3jtowicz5and Jan Piasecki1*\n1Department of Philosophy and Bioethics, Faculty of Health Sciences, Jagiellonian University\nMedical College, Krak\u00f3w, Poland,2Consciousness Lab, Institute of Psychology, Jagiellonian\nUniversity, Krak\u00f3w, Poland,3Department of Psychology, University of Oslo, Oslo, Norway,4Affective\nCognitive Neuroscience Laboratory, Department of Pharmacology, Maj Institute of Pharmacology\nof the Polish Academy of Sciences, Krak\u00f3w, Poland,5Pozna \u2019n University of Technology, Pozna \u2019n,\nPoland\nIntroduction: The rise of social media users and the explosive growth\nin misinformation shared across social media platforms have become a\nserious threat to democratic discourse and public health. The mentioned\nimplications have increased the demand for misinformation detection\nand intervention. To contribute to this challenge, we are presenting\na systematic scoping review of psychological interventions countering\nmisinformation in social media. The review was conducted to (i)\nidentify and map evidence on psychological interventions countering\nmisinformation, (ii) compare the viability of the interventions on social\nmedia, and (iii) provide guidelines for the development of effective\ninterventions.\nMethods: A systematic search in three bibliographic databases (PubMed,\nEmbase, and Scopus) and additional searches in Google Scholar and reference\nlists were conducted.\nResults: 3,561 records were identi\ufb01ed, 75 of which met the eligibility\ncriteria for the inclusion in the \ufb01nal review. The psychological\ninterventions identi\ufb01ed during the review can be classi\ufb01ed into three\ncategories distinguished by Kozyreva et al.: Boosting, Technocognition,\nand Nudging, and then into 15 types within these. Most of the\nstudied interventions were not implemented and tested in a real\nsocial media environment but under strictly controlled settings\nor online crowdsourcing platforms. The presented feasibility\nassessment of implementation insights expressed qualitatively and\nwith numerical scoring could guide the development of future\ninterventions that can be successfully implemented on social media\nplatforms.\nDiscussion: The review provides the basis for further research on\npsychological interventions counteracting misinformation. Future research on\nFrontiers in Psychiatry 01 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 2\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\ninterventions should aim to combine effective Technocognition and Nudging\nin the user experience of online services.\nSystematic review registration: [https://\ufb01gshare.com/], identi\ufb01er [https://doi.\norg/10.6084/m9.\ufb01gshare.14649432.v2].\nKEYWORDS\nmisinformation, social media, scoping review, systematic review, psychological\ninterventions, Facebook, Twitter, Reddit\n1. Introduction\nThe world has witnessed an unprecedented spread of\nmisinformation in recent years (1\u20133). Waves of misinformation\nare responsible for diminishing social trust in public health\nagencies, sowing social discord, encouraging, and strengthening\nxenophobic, homophobic, and nationalistic stances, and\nundermining popular con\ufb01dence in the benevolence\nof democratic institutions (4\u20136). Misinformation is an\numbrella term which encompasses several similar phenomena:\nintentional and unintentional spreading of false information,\ndisseminating urban legends, sharing fake news, unveri\ufb01ed\ninformation, and rumor, as well as crowdtur\ufb01ng, spamming,\ntrolling, and propagating hate speech, or being involved\nin cyberbullying (7, 9\u201312). Detection of fake news and\nrumors is attracting signi\ufb01cant attention from the research\ncommunity (13). Similarly, many studies aim to understand\nthe psychological factors that contribute to the individuals\u2019\nincreased susceptibility to misinformation. Given this scienti\ufb01c\ne\ufb00ort, a comparison of various psychological interventions\n(for the de\ufb01nition of \u201cpsychological intervention, \u201d see section\n\u201c2 Materials and methods\u201d) to immunize individuals against\nmisinformation is of both theoretical and practical importance.\nA psychological intervention that protects online users\nagainst misinformation can take many forms. The most\nstraightforward intervention is manipulating the user interface\nby adding warnings (14), tags (15), credibility scores (16), or\nfact-checks (17). Another possibility is to display information\nin the social context (e.g., by showing indicators of peer\nacceptance or rejection of information) (16). Another solution is\nto inoculate users by teaching them to recognize misinformation\n(18) or improving their media (19) and science literacy (20) or\nengaging users using gami\ufb01cation (21). The question remains:\nwhich type, and modality of psychological intervention is most\nlikely to succeed in a given context? This scoping review\nprovides an overview of existing psychological interventions\ndesigned to \ufb01ght the spread of misinformation, compare\nthem, and provide design guidelines to maximize their\ne\ufb00ectiveness. While the underlying psychological mechanisms\nof misinformation are beyond the scope of this manuscript, we\nhope it can serve as a useful starting point for future analysis\nin this respect.We followed the PRISMA Extension for Scoping\nReviews [PRISMA-ScR (22)] to identify recent research\non psychological interventions countering misinformation\nspread. The initial pool of studies identi\ufb01ed via database\nsearch or manual citation search via Google Scholar\nconsisted of 4279 publications. After removing duplicates,\nwe screened 3,561 publications by titles and abstracts.\nFinally, the application of the eligibility criteria reduced\nthe pool of studies to 75 publications selected for information\nextraction. While reviewing the papers, we focused on types\nof interventions, not types of studies, as the latter would\nlean more toward the goals of a meta-analysis rather than a\nscoping review.\nThree \ufb01ndings stand out as the main result of the scoping\nreview. We identi\ufb01ed \ufb01ve major types of study designs and\nassessed the e\ufb03cacy of psychological interventions that\nwere based on them. We further developed a typology\nof 15 distinct subtypes nested within three broader\nclassi\ufb01cations of psychological interventions. We also\ndesigned an intervention viability assessment score survey\n(see Table 3 inSupplementary material ) to evaluate the\npossible reach and overall cost of their implementation on\nthe existing social media (Facebook, Twitter, etc.), and we\napplied this assessment score to all the studies included\nin this scoping review. The results revealed the two most\npromising types in terms of viability of psychological\ninterventions: Message from a trusted organization\nand Source rating.\n2. Materials and methods\nThis scoping review is reported according to the PRISMA-\nScR (see Figure 1 ) reporting criteria for scoping reviews\n(see Table 2 inSupplementary material ). The protocol was\npre-registered and published in the Jagiellonian University\nRepository (30).\n2.1. Eligibility criteria\nThe process of developing the eligibility criteria was inspired\nby both the classical approach to systematic reviews (31)\nFrontiers in Psychiatry 02 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 3\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nFIGURE 1\nPRISMA work\ufb02ow of scoping review.\nand by more modern approaches, focused on the qualitative\nmethods of reviews (32). However, PICO is more sensitive\nthan modi\ufb01ed strategies and it is recommended for systematic\nreviews (33). Thus, the eligibility criteria were based on the\nPICO (Population, Intervention, Comparison, and Outcome)\ncomponents and the speci\ufb01cation of the types of studies\nsuch as publication status and language. After adjusting the\nPICO scheme to the requirements of the scoping review,we formulated the eligibility criteria in terms of the PIO\n(Population, Intervention, \u201cOutcome) scheme\u201d ( Table 2 ).\n\u000fPopulation: In order to be included in the review, a study\nhad to focus on one of the forms of misinformation (i.e.,\nthe spread of false information, urban legends, fake news,\nfake science) or address the issues of misinformation\nin social media (e.g., Facebook, Twitter, Instagram,\nFrontiers in Psychiatry 03 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 4\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nTABLE 1 Glossary of key terms used in current study, (see Figure 2 ).\nTypes of study designs\n\u000fEcological \u2013 Study design that evaluates the in\ufb02uence of environmental factors on individual behavior and mental health (23)\n\u000fNon-ecological \u2013 Study design that does not account for the in\ufb02uence of environmental factors on individual behavior and mental health\n\u000fMimical \u2013 Study design that employs stimuli closely resembling a social media UX design while still being heavily controlled and performed in a lab or online setting\n\u000fGame \u2013 Study design that tests gami\ufb01ed approaches to \ufb01ghting misinformation in social media\n\u000fMixed methods \u2013 Study design that uses multiple types of study designs\nCategories and types of psychological interventions\n\u000fBoosting \u2013 Cognitive interventions and tools that aim to foster people\u2019s cognitive and motivational competencies (e.g., simple rules for online reasoning) (24)\n\u000fInoculation \u2013 Inoculation theory is a framework originating from social psychology. It posits that it is possible to preemptively confer psychological resistance\nagainst (malicious) persuasion attempts (18, 25). It is a kind of deliberate action aimed at improving the latent ability to spot misinformation techniques, as opposed\nto just individual instances of misinformation (18, 21, 26, 27). Usually, it is done by exposing participants to misinformation in order to teach them its structures\nand mechanisms\n\u000fFact-checking \u2013 Based on confronting misinformation online with factual information from credible sources, which is done, for instance, by webpages whose goal is\ndebunking misinformation, such as snopes.com\n\u000fMedia literacy \u2013 Educational intervention aimed at increasing the subject\u2019s knowledge about misinformation risks in social media and training the ability to\nrecognize misinformation\n\u000fScience literacy \u2013 Educational intervention aimed at increasing the subject\u2019s knowledge about scienti\ufb01c conduct, discerning good science from bad, and training to\nrecognize scienti\ufb01c misinformation\n\u000fPublic pledge to the truth \u2013 Pro-truth pledge is an initiative that tries to incentivize misinformation protecting behaviors by encouraging subjects to make a public\nvow to commit to truth-oriented behaviors and protect facts and civility\n\u000fAnti-cyberbullying video \u2013 Educational videos designed to sensitize subjects to the issues regarding cyberbullying\n\u000fTechnocognition \u2013 Cognitively inspired technological interventions in information architectures (e.g., introducing friction in the sharing of o\ufb00ensive material) (28)\n\u000fUX manipulation \u2013 Utilizing manipulations to user\u2019s interface and ways they interact with social media to \ufb01ght misinformation online.\n\u000fDeliberation \u2013 The process of carefully considering the content before sharing, rating, or commenting on it. These kinds of interventions are meant to incentivize\nsubjects to take time to deliberately process content.\n\u000fSource rating \u2013 Based on grading systems used to evaluate the credibility of an information source that is then displayed to users.\n\u000fNudging \u2013 Behavioral interventions in the choice architecture that alter people\u2019s behavior in a predictable way (e.g., automatic [default] privacy-respecting settings)\n(29)\n\u000fWarning \u2013 Based on notifying the subject beforehand that the online content they are about to consume might contain misinformation\n\u000fTagging \u2013 Aimed at detecting and tagging misinformative content, usually with some visual sign or noti\ufb01cation\n\u000fSocial correction \u2013 An intervention enacted by a group, demanding appropriate behavior from an individual. On the contrary, in normative and empathy nudges,\nthe subject is messaged privately by a single person (or a bot)\n\u000fCorrection \u2013 Aimed at correcting inaccurate information (mostly in the scienti\ufb01c domain). Correction is usually embedded in the content, for instance, at the\nbeginning or at the end of an article\n\u000fEmpathy nudge \u2013 An intervention in which another person\u2019s pressure elicits a more empathetic stance on the subject\n\u000fMessage from a trusted organization \u2013 Based on sending corrective, fact-checking messages from a widely trusted organization\u2019s account\nor pairings of those). In de\ufb01ning misinformation,\nwe utilize Wu et al.\u2019s de\ufb01nition (7) which lists kinds\nof misinformation as: intentional and unintentional\nspreading of false information, disseminating urban\nlegends, sharing fake news, unveri\ufb01ed information,\nand rumor, as well as crowdtur\ufb01ng [the term means:\nleveraging human-powered crowdsourcing platforms to\nspread malicious URLs in social media and manipulate\nsearch engines, ultimately degrading the quality of online\ninformation and threatening the usefulness of these\nsystems (8)], spamming, trolling, and propagating hate\nspeech, or being involved in cyberbullying (7, 9\u201312). This\nde\ufb01nition allowed us to operationalize the \u201cPopulation\u201d\npart of the search query.\n\u000fIntervention: Interventions eligible for the review must be\npsychological interventions that counter misinformation.\nA psychological intervention is understood here as an\nintervention and/or experimental manipulation that targetspsychological, intermediary, or cognitive processes or\nactual behavior (23). An example of a psychological\nintervention might be asking subjects to pause to consider\nwhy a headline is true or false before sharing. An\nintervention is not psychological when it targets, e.g., either\nbiochemical functions of a body (e.g., pharmacological\nintervention) or the functions of a computer/phone\n(e.g., computer processing information on a phone).\nA compatible de\ufb01nition of the intervention considered\nin this review is the one that can be found in the\nAPA Dictionary of Psychology: \u201cstrategies and processes\ndesigned to measure the change in a situation or\nindividual after a systematic modi\ufb01cation (diet, therapeutic\ntechnique) has been imposed or to measure the e\ufb00ects\nof one type of intervention program as compared to\nthose of another program. Experimentation is the most\ncommon type of intervention research, but clinical trials\nand qualitative studies may also be used.\u201d (23). As\nFrontiers in Psychiatry 04 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 5\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nTABLE 2 Inclusion criteria for scoping review.\nThe paper focuses on some form of misinformation\nThe paper is empirical\nThe paper addresses the issues of misinformation in the social media context\nThe paper was published after 2004\nThe paper proposes a psychological intervention\nThe paper is peer-reviewed\nThe paper is published in English\nThe paper presents experimental manipulations aimed at reducing\nsusceptibility to misinformation in social media\nsuch, experimental manipulations to reduce susceptibility\nto misinformation in social media will be included\nin this review. Interventions eligible for the review\ncannot be speculative or impossible to employ in a\nsocial media environment: for instance, interventions\nrequiring the involvement of highly trained specialists\nshould be excluded.\n\u000fOutcome: To be included in the review, a study also must\nbe empirical, i.e., present primary data obtained through\na qualitative and/or quantitative research methodology,\nwhich implies that reviews, meta-analyses, theoretical, or\nother non-empirical papers have to be excluded.\n\u000fAdditional criteria: The scoping review included only\npeer-reviewed studies published after 2004. The choice of\nthe date is deliberate as it corresponds to the launching\nof Facebook, the oldest modern-scale social network. In\naddition, we consider only peer-reviewed studies published\nin English.\nWhen screening studies to ful\ufb01ll the eligibility criteria,\nwhenever relevant information was missing from studies, the\nreviewers attempted to contact the study authors to obtain the\nrequired information.\n2.2. Study selection\nThe search strategy protocol was developed based on the\nJoanna Briggs Institute recommendations that assume a three-\nstep strategy: preliminary search, the \ufb01rst phase, and the second\nphase (31).\nPreliminary search : The preliminary search was aimed at\nselecting the keywords and index terms for constructing a\nsearch query that drives the prime search. For this purpose, the\nauthors searched three databases: Scopus, PubMed, and later,\non Google Scholar from 01/01/2004 to present with a set of\nkeywords. The search was limited to English language studies\nas per the eligibility criteria. The search was conducted on\n03/12/2020. The authors manually analyzed the retrieved studies\nto identify candidate search terms by looking at the terminology\nused and the subject indexing in the records. The \ufb01nal query\nwas constructed using a PICO-style approach. Table 3 presentssearch terms related to each component of the PICO framework.\nIn the preliminary searches, we also tested di\ufb00erent bases (APA\nPsycInfo, Sage, Google Scholar); the \ufb01nal list of three data\nbases (PubMed, Embase, and Scopus) was chosen for the \ufb01rst\nsearch because they returned a large number of records, enabled\ntransparent and replicable searches, as well as enabled the use of\nBoolean operators.\nThe \ufb01nal query ( Table 3 and see Supplementary material )\nwas formulated according to the PICO formula: (P) AND (I)\nAND (C) AND (O).\nThe search query was validated by testing whether it could\nidentify the two known relevant studies (34, 35) as part of the\nsearch strategy development process.\nFirst phase : In the \ufb01rst phase, the search query was issued to\nthree databases: PubMed, Embase, and Scopus. The query was\nissued on 08/03/2021.\nSecond phase : In the second phase, all references cited in\nthe studies meeting the criteria returned from the \ufb01rst phase\nwere screened for inclusion concerning the eligibility criteria. In\naddition, a simpli\ufb01ed search query (Query 2) was issued to the\nGoogle Scholar search engine on 28/07/2021.\nThe date coverages and query execution dates are given in\nTable 4 . The \ufb01nal search results were exported into the EndNote\ntool. A detailed description of the search strategy can be found\nin the Table 3 inSupplementary material .\n2.3. Data extraction\nEligible studies were equally assigned to pairs of\ncontributors for data extraction. Each contributor collected\nthe data independently and discussed inconsistencies until\nconsensus was reached within the pair. In case of unreported\nor inaccessible data, the contributors tried to obtain this\ninformation from the study\u2019s authors.\nThe following data items have been extracted from each\nstudy included in the review:\n\u000fBibliographic data: authors, publication venue, year of\npublication, funding, type of publication, con\ufb02ict of\ninterest, corresponding author a\ufb03liation,\n\u000fStudy metadata: inclusion and exclusion criteria for\nparticipants, risk of bias,\n\u000fCohort data: demographic data describing the population\nundergoing psychological intervention,\n\u000fStudy design: type of misinformation addressed by a study,\nstudy design and study methodology, social media being\nstudied,\n\u000fInterventions and outcome: description of the\nintervention, the time it takes for an intervention to\nbe successful, the viability of the intervention application,\nand eventual follow-up study outcomes (to establish\nFrontiers in Psychiatry 05 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 6\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nFIGURE 2\nMisinformation psychological interventions typology based on Kozyreva et al. (38).\nwhether an intervention has left persisting e\ufb00ects among\nusers).\nAll the collected details of studies are included in Table 1\nandData Sheet inSupplementary material . For the detailed\nPRISMA Scoping Review Work\ufb02ow see Figure 1 .\n2.4. Data synthesis\nQualitative data concerning study design, intervention\noutcomes, and types of interventions was synthetized usinginductive methods inspired by the constant comparative\nmethod: similar study designs, intervention outcomes, and types\nof interventions were joined into one category (36, 37). The\ninductive process was conducted by four coders who agreed to\nthe \ufb01nal version of the qualitative categories. Moreover, after\ndistinguishing 15 di\ufb00erent types of psychological intervention,\nwe used a broad categorization developed by Kozyreva et al.\nand we sorted our 15 types into those three general intervention\ncategories (38).\nThe intervention assessment score (IAS) was a measure\ndeveloped to merely supplement the narrative synthesis of\nthe paper, and its methodology is based on the grounded\nFrontiers in Psychiatry 06 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 7\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nTABLE 3 Patient, Intervention, Comparison, and Outcome (PICO) search strategy disambiguation.\nP \u2013 patient (\u201cdisinformation\u201d OR \u201cmisinformation\u201d OR \u201cfake news\u201d OR \u201cconspiracy theor*\u201d OR \u201curban legend*\u201d OR \u201crumor*\u201d OR \u201chate speech\u201d OR\n\u201ccyberbullying\u201d OR \u201cfake science\u201d OR \u201cmislead*\u201d OR \u201cfake source*\u201d OR \u201cpropagand*\u201d) AND (\u201csocial media\u201d OR \u201cfacebook\u201d OR \u201cinstagram\u201d OR\n\u201ctwitter\u201d OR \u201ctiktok\u201d OR \u201cyoutube\u201d OR \u201cmessenger\u201d OR \u201cwhatsapp\u201d OR \u201ctelegram\u201d OR \u201cinternet\u201d OR \u201cmedia\u201d OR \u201cblog*\u201d OR \u201creddit\u201d OR\n\u201c4chan\u201d)\nI \u2013 intervention (\u201cintervent*\u201d OR \u201ctag*\u201d OR \u201cfactcheck*\u201d OR \u201cfalse-tag\u201d OR \u201crefutation\u201d OR \u201ccorrect*\u201d OR \u201cretraction\u201d OR \u201c\ufb02ag*\u201d OR \u201cheadline*\u201d OR\n\u201ccounter*\u201d OR \u201crated false\u201d OR \u201cdisrupted\u201d OR \u201cquestionnaire*\u201d OR \u201csurvey*\u201d OR \u201cinterview*\u201d OR \u201cfocus group*\u201d OR \u201ccase stud*\u201d OR\n\u201cobserv*\u201d OR \u201cexperiment*\u201d OR \u201cqualitative\u201d OR \u201cquantitative\u201d OR \u201cmixed method*\u201d OR \u201cexperiment*\u201d)\nC \u2013 comparison (\u201cview*\u201d OR \u201cexperienc*\u201d OR \u201copinion*\u201d OR \u201cattitude*\u201d OR \u201cperce*\u201d OR \u201cbelie*\u201d OR \u201cjudge*\u201d OR \u201cfeel*\u201d OR \u201cknow*\u201d OR \u201cunderstand*\u201d OR\n\u201cassess*\u201d OR \u201cexpect*\u201d OR \u201ctenden*\u201d)\nO \u2013 outcome (\u201cshare*\u201d OR \u201cverify\u201d OR \u201cfollo*\u201d OR \u201cunfollo*\u201d OR \u201csubscrib*\u201d OR \u201cunsubscrib*\u201d OR \u201cclick*\u201d OR \u201cinduc*\u201d OR \u201ctrust*\u201d OR \u201cdistrust*\u201d OR\n\u201ccheck*\u201d OR \u201creduc*\u201d OR \u201cjudge*\u201d OR \u201cinferenc*\u201d OR \u201ccorrect*\u201d OR \u201cre\ufb02ect*\u201d OR \u201creliance\u201d OR \u201cresist*\u201d OR \u201cback-\ufb01re\u201d OR \u201cin\ufb02ue*\u201d OR \u201clike\u201d)\ntheory and abductive method (39). In this line of work, inter-\nrater reliability (IRR) is not something that is desired. As\nMcDonald et al. (40) point out for grounded theories, codes\nare \u201cmerely\u201d an interim product that supports the development\nof a theory, not a \ufb01nal result that requires testing. We treated\nthe rating codes of interventions as an ethnography performed\nby an interdisciplinary team of experts, and di\ufb00ering scores are\nsomething that is expected here by design, as it is impossible\nto take the preliminary experiences out of the ethnographer, as\nBarkhuus and Rossitto point out (41).\n3. Results\n3.1. Study selection\nThe selection consisted of two phases. The \ufb01rst phase\ninvolved searching PubMed, Embase, and Scopus databases,\nwhich resulted in the identi\ufb01cation of 2,267 records.\nDeduplication excluded 718 records, and screening, according\nto the inclusion criteria (see section \u201c2.1 Eligibility criteria\u201d),\nrejected 1,501 records. Thus, the \ufb01rst phase resulted in the\nselection of 48 eligible records. The second phase included\n1,912 publications cited in the eligible records identi\ufb01ed in the\n\ufb01rst phase. The second phase also included 100 papers from a\nSupplementary Google Scholar search. Screening, according to\nTABLE 4 Query execution dates.\nStage Database Coverage Query\nexecution date\nPreliminary search PubMed NA \u2013 02/12/2020 03/12/2020\nScopus NA \u2013 02/12/2020 03/12/2020\nGoogle Scholar NA \u2013 14/07/2021 31/07/2021\nFirst phase PubMed 2004 \u2013 08/03/2021 08/03/2021\nScopus 2004 \u2013 08/03/2021 08/03/2021\nEmbase 2004 \u2013 08/03/2021 08/03/2021\nSecond phase Google Scholar 2004 \u2013 28/07/2021 28/07/2021the inclusion criteria, rejected 1,985 records. Thus, the second\nphase resulted in the selection of 27 eligible records. In total,\nthe selection process yielded 75 eligible records (for details, see\nTable 1 inSupplementary material ).\n3.2. Types of study design\nWe have identi\ufb01ed \ufb01ve distinct types of study designs:\necological, non-ecological, mimical, game, and mixed\nmethods. Ecological studies were conducted within the\nsocial media environment, and participants were often\nunaware of either the study\u2019s objective or the fact of\nbeing studied (42). Non-ecological studies were usually\nconducted in a heavily controlled laboratory setting (34).\nAlternatively, non-ecological studies were performed\nonline using carefully prepared interfaces, often bearing\nlittle resemblance to the social media user experience\ndesign [UX design, e.g., (20)]. Mimical studies employed\nstimuli closely resembling social media UX design, e.g.,\nscrolling a website resembling the Facebook timeline, while\nbeing conducted in a heavily controlled environment (35).\nSeveral studies tested gami\ufb01ed approaches to \ufb01ghting\nmisinformation in social media (43). Finally, mixed\nmethods encompass studies using multiple approaches and\nexperiments within one study (44). Non-ecological and\nmimical studies are the dominant type of study designs.\nEcological studies, which provide insight into the more\n\u201cnatural\u201d behavior of users of social networks, are still scarce\n(Figure 3 ).\n3.3. Types of psychological\ninterventions\nWe used a general typology of psychological interventions\nproposed by Kozyreva et al. (38), dividing interventions into\nthree categories and 15 types ( Figure 2 ). The categories\nFrontiers in Psychiatry 07 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 8\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nFIGURE 3\nStudy design types distribution in the sample.\nrefer to di\ufb00erent evidence-based behavioral and cognitive\ninterventions that can be applied to the digital world.\nTechnocognition refers to interventions that change how\nusers experience and consume content in social media,\nfor instance, by introducing some friction in the way\nuser shares information. This includes UX manipulation,\nDeliberation, Source rating. Boosting interventions are cognitive\ninterventions and tools that aim to foster people\u2019s cognitive\nand motivational competencies (24) and include the following:\nInoculation, Fact-checking, Science literacy, Public pledge to\nthe truth, Media literacy, Anti-cyberbullying video. Nudging\nincludes behavioral interventions in the choice architecture that\nalter people\u2019s behavior in a predictable way (e.g., default privacy-\nrespecting settings (29)). They include: Correction, Warning,\nSocial correction, Empathy nudge, Tagging, Message from a\ntrusted organization.\n3.4. Publications by year\nWe did not \ufb01nd any studies on psychological interventions\ncounteracting the spread of misinformation in social networks\nprior to 2013. We \ufb01nd this surprising as the topic of \u201cfake news\u201d\nwas present in both public and scienti\ufb01c discourse already in the\n\ufb01rst decade of the century. This is perhaps caused by the fact that\nthe public awareness of the problem is still growing. In 2016, the\nterm \u201cpost-truth\u201d was included in the Oxford English Dictionary\nand chosen as Word of the Year (45). The narrative of people\nliving in the \u201cpost-truth era\u201d gained momentum at that point.\nWe are also observing a rapid increase in the number of studies\npublished in the years following this event (see Figure 4 ). In our\nopinion, this trend yields evidence of the urgency of \ufb01ghting the\nmisinformation circulating in online social networks.\n3.5. Psychological intervention\noutcomes\nFor each study, we extracted the description of the outcome\nand conclusions drawn by the authors of the study regarding the\nFIGURE 4\nSocial media misinformation year of publications distribution in\nthe sample.\nsuccessfulness of the implemented intervention. We identi\ufb01ed\nsix possible outcomes: successful, partially successful, mixed\nresult, unclear result, ine\ufb00ective, and counterproductive (i.e., an\nintervention increased the susceptibility to misinformation) (see\nFigure 5 ). The majority of studies (46) included in the review\nreported a successful outcome of the intervention tests. For 10\nstudies, the authors concluded that the results were unclear,\nand more research was needed to evaluate the e\ufb00ectiveness of\nthe given intervention. The interventions which were successful\nin general but either could be further improved, or whose\npositive e\ufb00ect was weak, are classi\ufb01ed as \u201cpartially successful\u201d;\nwe found 7 of these. Finally, the authors of 5 studies did not\n\ufb01nd any evidence of a positive e\ufb00ect of an intervention, and two\ninterventions were deemed counterproductive.\n3.6. Psychological intervention\nassessment score\nTo gain further insight into the viability and practical use\nof psychological interventions, we computed an intervention\nassessment score (IAS) for each study included in the review\n(see Figure 6 ). IAS was designed not to score e\ufb00ectiveness,\nbut viability, which e\ufb00ectiveness is just part of. This score was\nbased on ratings on a 5-point Likert scale (for details, see\nTable 3 inSupplementary material ). Each item was designed\nto rate, as follows: the successfulness of the intervention, the\ntechnical ease of implementation, the amount of resources\nFrontiers in Psychiatry 08 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 9\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nFIGURE 5\nAuthor\u2019s intervention test conclusion in the sample.\nneeded for intervention to be implemented, whether it requires\nmotivated participants, whether it requires massive change to\nthe way social media currently work. The rating was performed\nby the raters: PG, JP , MP , and AG. The team of raters\nwas interdisciplinary and included researchers with di\ufb00erent\nviews on each rated item. This approach was intentional, as\nopposed to traditional expert rating, where it is assumed that\nthere is only one good rating for each item. As the subject\nof misinformation-countering interventions is complex, there\nmight be varying views on the viability of di\ufb00erent aspects\nof such interventions. For instance, in Item 2, the raters\nwere asked to evaluate whether \u201cThis intervention seems to\nbe technically easy to implement in social media, based on\nyour knowledge.\u201d For a rater with a cognitive science and\nprogramming background, this statement might be interpreted\nas \u201ceasy to code and implement, \u201d whereas a rater with a\npsychological background might rate this item having the users\u2019\nperspectives and their underlaying psychological mechanisms\nin mind. We think that both views are valid and by averaging\nthese di\ufb00ering ratings, we obtain a score that is more general\nrather than limited to a speci\ufb01c \ufb01eld, as it encompasses broader\naspects of the interventions. Taking the above into account,the inter-rater reliability scores such as Cohen\u2019s kappa would\nbe meaningless in this case, as they require experts from\nheterogenous \ufb01elds, trained to interpret material in the same\nmanner.\n3.7. Social media and topics\nFacebook and Twitter are the primary targets for\npsychological intervention (see Figure 7 ). Interestingly, we\ndid not \ufb01nd studies on psychological interventions in video-\nbased social networks (TikTok, YouTube). Possibly, the form\nof the text-based social media made it easier to implement\npsychological interventions. Figure 8 presents the distribution\nof topics considered for psychological intervention. We found\nhealth and politics to be the primary areas of misinformation\nresearch.\n3.8. Demographics\nThe mean age of the reviewed study participants was\n35.05 years. The age of the participants in this \ufb01eld\nis surprisingly low, as it has been suggested that older\nadults are more vulnerable to misinformation and are more\noften responsible for spreading it (47). Judging from the\ncorresponding author location, we can say that by far most\nresearch on misinformation in social media has been conducted\nin the USA (43 papers). The UK and Germany are a far second\n(six papers each), followed by the Netherlands (\ufb01ve papers).\nIn the analyzed sample, three teams emerge as those most\npublished. The most published team is led by E.K. Vraga and\npublished ten papers on the e\ufb00ectiveness of social correction\nand media literacy promotion. The second most published team\nis Roozenbeek-van der Linden\u2019s team with six publications.\nThe team has a very concentrated focus on the theory of\ninoculation and game interventions. Finally, there is a team led\nby Pennycook, which published \ufb01ve papers that test the e\ufb00ects\nof deliberation, accuracy nudge, and tagging.\nFIGURE 6\nMean viability score by intervention type.\nFrontiers in Psychiatry 09 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 10\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nFIGURE 7\nNumber of papers published by type of social media studied in\nthe sample.\nFIGURE 8\nNumber of publications by misinformation types in the sample.\n4. Discussion\nThe purpose of the scoping review was to provide an\noverview of the existing psychological interventions designed\nto combat the spread of misinformation in social media and to\ncompare them with respect to their viability. We classi\ufb01ed the\npsychological interventions into three broader categories after\nKozyreva et al.: Boosting, Technocognition, Nudge, out of which\nfour types were rated as the most viable: Source rating, Message\nfrom a trusted organization, UX manipulation, and Tagging.\nIn those intervention types, the subject is not required to be\na highly motivated fact-checker and, depending on the design,\nthey can encompass a wide variety of misinformation aspects\n[for instance, they can incorporate a non-binary approach to\nthe truth of a given article (15)]. Those intervention types\nhave already found their use in social media, e.g., via browser\nextensions.1Technicognition and Nudging interventions can\nusually be automated with the help of chatbots, and they\nhave been proven e\ufb00ective (44, 48, 49), as opposed to\nBoosting interventions, which require vast resources and highly\nmotivated participants, therefore, they were rated as least viable\n(they might be most e\ufb00ective in the long run, however). It\nis also important to note that all the studies included in the\nscoping review are relatively new. Half of the papers have been\npublished in the last 3 years, which seems to coincide with the\n1 https://mediabiasfactcheck.com/appsextensions/need for misinformation-related research due to the events that\nare taking place in Western Europe and the USA, both in terms\nof the political scene and the COVID-19 pandemic.\nOne important limitation of the results of the scoping\nreview is the fact that the reviewed studies under-represent\nolder participants, in particular, people older than 65 years.\nAnother limitation is the almost exclusive focus on text-based\nsocial media such as Facebook and Twitter, excluding the newer,\nmore visually focused media, such as TikTok, You Tube, and\nInstagram. Unfortunately, the review does not allow us to\nconclude that the types of psychological interventions that are\nsuccessful for more traditional social media would be equally\nsuccessful for more image-based or video-based media. On the\ncontrary, introducing corrections or peer and social pressure\nmarkers may be much more di\ufb03cult in the latter case, if the\npsychological intervention is performed via text (e.g., adding a\nlink to a fact-checking website). However, a study testing the\ne\ufb00ectiveness of psychological inoculation by means of short\nYouTube clips which has been published recently, after the\nconclusion of our review, shows some promising results (46).\nOur review provides the basis for further research\non psychological interventions counteracting the spread of\nmisinformation. Future research on interventions should aim\nto combine e\ufb00ective Technocognition with various types of\nNudging, e.g., seamlessly immersing normative, peer, and social\npressure indicators in the user experience of online services.\nFuture interventions should also focus on areas culturally\ndi\ufb00erent from Western Europe and the US where most of\nthe studies have been conducted. Cultural di\ufb00erences and\nclass divisions play an important role in misinformation\nsusceptibility. Users originating from vulnerable or excluded\ngroups interact with misinformation di\ufb00erently than cohorts\nstudied in the scoping review (50, 51). Diversi\ufb01cation of research\nperspectives may be essential when designing psychological\ninterventions for these users. Moreover, scoping reviews\nand, even more importantly, systematic reviews with meta-\nanalysis measuring the e\ufb00ectiveness of interventions should be\nconducted to catch up with continuously published new studies\n(27, 52\u201355) and to supplement the results of traditional reviews\n(56) which have been recently published on this issue.(57, 58).\n4.1. Risk of bias\nIn terms of selection bias, two factors should be considered:\nrestraining searches to a limited number of databases and the\nrapidly growing number of studies on mitigating social media\nmisinformation published after conducting searches (27, 52\u2013\n55). In order to mitigate the risk of selection bias, the authors\nconducted a supplementary search consisting of an additional\nGoogle Scholar search and a bibliographic search. To reduce\nthe risk of rejecting relevant studies, all the records retrieved\nfrom the searches were screened against the eligibility criteria\nFrontiers in Psychiatry 10 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 11\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\nindependently by two reviewers. It is also worth stressing that\nthe design choices behind the IAS, while encompassing the\nbroad spectrum of views on the matter, do not allow using any\nstatistical tools to exclude the possibility of bias.\nAuthor contributions\nPG and JP: conceptualization, methodology, search strategy,\nvalidation, data acquisition, and supervision. PG, JP , MP , and\nAG: data extraction and investigation. PG: data curation and\nwriting \u2013 original draft. JP , MM, IK, TW, MP , AG, RR, JK,\nand KN: writing \u2013 review and editing. JP: supervision. JP , MM,\nJK, and RR: project administration and funding acquisition.\nAll authors have read and agreed to the published version\nof the manuscript.\nFunding\nThis research leading to these results has received funding\nfrom the EEA Financial Mechanism 2014-2021. Project\nregistration number: 2019/35/J/HS6/03498.\nAcknowledgments\nWe thank Ositadima Chukwu and \u0141ucja Zaborowska for\ntheir contribution to data acquisition, Martyna Szczepaniak-\nWo\u00b4znikowska (Translatorion) for editing this manuscript,and Agnieszka Masson Lempart for preparing data\nmanagement tools.\nCon\ufb02ict of interest\nThe authors declare that the research was conducted\nin the absence of any commercial or \ufb01nancial relationships\nthat could be construed as a potential con\ufb02ict of\ninterest.\nPublisher\u2019s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their a\ufb03liated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed\nor endorsed by the publisher.\nSupplementary material\nThe Supplementary Material for this article can be\nfound online at: https://www.frontiersin.org/articles/10.3389/\nfpsyt.2022.974782/full#supplementary-material\nReferences\n1. World Health Organization [WHO]. Call for action: managing the infodemic .\nGeneva: World Health Organization (2020).\n2. Orso D, Federici N, Copetti R, Vetrugno L, Bove T. Infodemic and the spread\nof fake news in the COVID-19-era. Eur J Emerg Med. (2020) 27:327\u20138. doi: 10.1097/\nMEJ.0000000000000713\n3. Jolley D, Paterson J. Pylons ablaze: examining the role of 5G COVID-19\nconspiracy beliefs and support for violence. Br J Soc Psychol. (2020) 59:628\u201340.\ndoi: 10.1111/bjso.12394\n4. Rodgers K, Massac N. Misinformation: a threat to the public\u2019s health and the\npublic health system. J Public Health Manag Pract. (2020) 26:294\u20136. doi: 10.1097/\nPHH.0000000000001163\n5. Gamir-R\u00edos J, Tarullo R, Ib\u00e1 \u00b4nez-Cuquerella M. Multimodal disinformation\nabout otherness on the internet. The spread of racist, xenophobic and islamophobic\nfake news in 2020. An\u00e0lisi. (2021) 64:49\u201364.\n6. Chambers S. Truth, deliberative democracy, and the virtues of accuracy: is fake\nnews destroying the public sphere? Polit Stud. (2021) 69:147\u201363.\n7. Wu L, Morstatter F, Carley K, Liu H. Misinformation in social media:\nde\ufb01nition, manipulation, and detection. ACM SIGKDD Explor Newsl. (2019)\n21:80\u201390.\n8. Lee K, Tamilarasan P , Caverlee J. Crowdturfers, campaigns, and social media:\ntracking and revealing crowdsourced manipulation of social media. Proceedings of\nthe international AAAI conference on web and social media . Menlo Park, CA. (2013)\n7:331\u201340.9. Bittman L. The use of disinformation by democracies. Int J Intell CounterIntell.\n(1990) 4:243\u201361.\n10. Kragh M, \u00c5sberg S. Russia\u2019s strategy for in\ufb02uence through public diplomacy\nand active measures: the Swedish case. J Strateg Stud. (2017) 40:773\u2013816.\n11. Wardle C. Fake news. It\u2019s complicated. First Draft. (2017) 16:1\u201311.\n12. Althuis, L, Haiden L. Fake news. a roadmap. riga: NATO strategic\ncommunications centre of excellence . (2018). Available online at: https:\n//stratcomcoe.org/publications/fake-news-a-roadmap/137 (accessed March\n10, 2021).\n13. Bondielli A, Marcelloni F. A survey on fake news and rumour detection\ntechniques. Inf Sci. (2019) 497:38\u201355.\n14. Chua A, Banerjee S. Intentions to trust and share online health rumors: an\nexperiment with medical professionals. Comput Hum Behav. (2018) 87:1\u20139.\n15. Figl K, Kie\u00dfling S, Rank C, Vakulenko S. Fake news \ufb02ags, cognitive\ndissonance, and the believability of social media posts. Fortieth international\nconference on information systems . Munich (2019). p. 2019.\n16. Brashier N, Pennycook G, Berinsky A, Rand D. Timing matters when\ncorrecting fake news. Proc Natl Acad Sci USA. (2021) 118:e2020043118. doi: 10.\n1073/pnas.2020043118\n17. Hameleers M, Van der Meer T. Misinformation and polarization in a high-\nchoice media environment: how e\ufb00ective are political fact-checkers? Commun Res.\n(2020) 47:227\u201350.\nFrontiers in Psychiatry 11 frontiersin.org\nfpsyt-13-974782 December 23, 2022 Time: 20:47 # 12\nGwia \u2019zdzi \u2019nski et al. 10.3389/fpsyt.2022.974782\n18. Roozenbeek, J, Linden S, Nygren T. Prebunking interventions based on the\npsychological theory of \u201cinoculation\u201d can reduce susceptibility to misinformation\nacross cultures. Harv Kennedy Sch Misinformation Rev. (2020) 1:1\u201323.\n19. Lutzke L, Drummond C, Slovic P , \u00c1rvai J. Priming critical thinking: simple\ninterventions limit the in\ufb02uence of fake news about climate change on facebook.\nGlob Environ Chang. (2019) 58:101964.\n20. Van Stekelenburg A, Schaap G, Veling H, Buijzen M. Investigating and\nimproving the accuracy of US citizens\u2019 beliefs about the COVID-19 pandemic:\nlongitudinal survey study. J Med Internet Res. (2021) 23:e24069. doi: 10.2196/24069\n21. Maertens R, Roozenbeek J, Basol M, van der Linden S. Long-term\ne\ufb00ectiveness of inoculation against misinformation: three longitudinal\nexperiments. J Exp Psychol. (2021) 27:1\u201316. doi: 10.1037/xap0000315\n22. Moher D, Shamseer L, Clarke M, Ghersi D, Liberati A, Petticrew M,\net al. Preferred reporting items for systematic review and meta-analysis protocols\n(PRISMA-P) 2015 statement. Syst Rev. (2015) 4:1.\n23. VandenBos G, Association A, Fund S. APA dictionary of psychology .\nWashington, DC: American Psychological Association (2007).\n24. Hertwig R, Gr\u00fcne-Y ano\ufb00 T. Nudging and boosting: steering or\nempowering good decisions. Perspect Psychol Sci. (2017) 12:973\u201386.\ndoi: 10.1177/1745691617702496\n25. Shen L, Bigsby E, Dillard J, Shen L. The SAGE handbook of persuasion\ndevelopments in theory and practice . Thousand Oaks, CA: Sage (2012).\n26. Cook J, Lewandowsky S, Ecker U. Neutralizing misinformation through\ninoculation: exposing misleading argumentation techniques reduces their\nin\ufb02uence. PLoS One. (2017) 12:e0175799. doi: 10.1371/journal.pone.0175799\n27. Lewandowsky S, Yesilada M. Inoculating against the spread of islamophobic\nand radical-Islamist disinformation. Cogn Res. (2021) 6:57. doi: 10.1186/s41235-\n021-00323-z\n28. Lewandowsky S, Ecker U, Seifert C, Schwarz N, Cook J. Misinformation\nand its correction: continued in\ufb02uence and successful debiasing. Psychol Sci Public\nInterest. (2012) 13:106\u201331. doi: 10.1177/1529100612451018\n29. Thaler R, Sunstein C. Nudge: improving decisions about health. Wealth\nHappiness. (2008) 6:14\u201338.\n30. Gwiazdzinski P , Kunst JR, Gundersen AB, Noworyta K, Olejniuk A, Piasecki,\nJ. Psychological interventions countering misinformation in social media?: a\nscoping review?: research protocol. Figshare . (2021) 1\u20139. doi: 10.6084/m9.\ufb01gshare.\n14649432.v2\n31. Peters M, Godfrey C, Khalil H, McInerney P , Parker D, Soares C. Guidance\nfor conducting systematic scoping reviews. JBI Evid Implement. (2015) 13:141\u20136.\n32. Methley A, Cooke A, Smith D, Booth A, Cheraghi-Sohi S. Beyond PICO: the\nSPIDER tool for qualitative evidence synthesis. Qual Health Res. (2012) 22:1435\u201343.\ndoi: 10.1177/1049732312452938\n33. Methley A, Campbell S, Chew-Graham C, McNally R, Cheraghi-Sohi S.\nPICO, PICOS and SPIDER: a comparison study of speci\ufb01city and sensitivity in\nthree search tools for qualitative systematic reviews. BMC Health Serv Res. (2014)\n14:579. doi: 10.1186/s12913-014-0579-0\n34. Kim A, Moravec P , Dennis A. Combating fake news on social media with\nsource ratings: the e\ufb00ects of user and expert reputation ratings. J Manag Inf Syst.\n(2019) 36:931\u201368.\n35. Vraga E, Bode L. Addressing COVID-19 misinformation on social media\npreemptively and responsively. Emerg Infect Dis. (2021) 27:396. doi: 10.3201/\neid2702.203139\n36. Boeije H. A purposeful approach to the constant comparative method in the\nanalysis of qualitative interviews. Qual Quant. (2002) 36:391\u2013409.\n37. Dye J, Schatz I, Rosenberg B, Coleman S. Constant comparison method: a\nkaleidoscope of data. Qual Rep. (2000) 4:1\u20139.\n38. Kozyreva A, Lewandowsky S, Hertwig R. Citizens versus the internet:\nconfronting digital challenges with cognitive tools. Psychol Sci Public Interest.\n(2020) 21:103\u201356. doi: 10.1177/152910062094670739. Thompson JA. Guide to abductive thematic analysis. Qual Rep. (2022)\n27:1410\u201321.\n40. McDonald N, Schoenebeck S, Forte A. Reliability and inter-rater reliability\nin qualitative research: norms and guidelines for CSCW and HCI practice.\nProceedings of the ACM on human-computer interaction . New York, NY (2019)\n3:1\u201323.\n41. Barkhuus L, Rossitto C. Acting with technology: rehearsing for mixed-media\nlive performances. Proceedings of the 2016 CHI Conference on Human Factors in\nComputing Systems . San Jose, CA: Association for Computing Machinery (2016). p.\n864\u201375.\n42. Bhuiyan M, Zhang K, Vick K, Horning M, Mitra T. FeedRe\ufb02ect: a tool\nfor nudging users to assess news credibility on twitter. Companion of the 2018\nACM conference on computer supported cooperative work and social computing .\nNew York, NY (2018). p. 205\u20138.\n43. Roozenbeek J, van der Linden S. Breaking harmony square: a game that\n\u201cinoculates\u201d against political misinformation. Harv Kennedy Sch Misinformation\nRev. (2020) 8:1\u201326.\n44. Pennycook G, Epstein Z, Mosleh M, Arechar A, Eckles D, Rand D. Shifting\nattention to accuracy can reduce misinformation online. Nature. (2021) 592:590\u20135.\n45.Oxford word of the year 2016 . (2016). Available online at: https://languages.\noup.com/word-of-the-year/2016/\n46. Roozenbeek J, van der Linden S, Goldberg B, Rathje S, Lewandowsky\nS. Psychological inoculation improves resilience against misinformation\non social media. Sci Adv. (2022) 8:eabo6254. doi: 10.1126/sciadv.abo\n6254\n47. Brashier N, Schacter D. Aging in an era of fake news. Curr Dir Psychol Sci.\n(2020) 29:316\u201323. doi: 10.1177/0963721420915872\n48. Ecker U, O\u2019Reilly Z, Reid J, Chang E. The e\ufb00ectiveness of short-format\nrefutational fact-checks. Br J Psychol. (2020) 111:36\u201354. doi: 10.1111/bjop.12383\n49. Vraga E, Bode L. I do not believe you: how providing a source corrects health\nmisperceptions across social media platforms. Inf Commun Soc. (2018) 21:1337\u201353.\ndoi: 10.2174/1874285800802010115\n50. Roozenbeek J, Schneider C, Dryhurst S, Kerr J, Freeman A, Recchia G, et al.\nSusceptibility to misinformation about COVID-19 around the world. R Soc Open\nSci.(2020) 7:201199.\n51. Bago B, Rand D, Pennycook G. Fake news, fast and slow: deliberation reduces\nbelief in false (but not true) news headlines. J Exp Psychol. (2020) 149:1608. doi:\n10.1037/xge0000729\n52. Roozenbeek J, van der Linden S. How to combat health misinformation:\na psychological approach. Am J Health Promot. (2022) 36:569\u201375. doi: 10.1177/\n08901171211070958\n53. Piltch-Loeb R, Su M, Hughes B, Testa M, Goldberg B, Braddock K, et al.\nTesting the E\ufb03cacy of attitudinal inoculation videos to enhance COVID-19 vaccine\nacceptance: quasi-experimental intervention trial. JMIR Public Health Surveill.\n(2022) 8:e34615. doi: 10.2196/34615\n54. Roozenbeek J, van der Linden S. How to combat health misinformation:\na psychological approach . Los Angeles, CA: SAGE Publications (2022).\np. 569\u201375.\n55. Roozenbeek J, Traberg C, van der Linden S. Technique-based inoculation\nagainst real-world misinformation. R Soc Open Sci. (2022) 9:211719. doi: 10.1098/\nrsos.211719\n56. Albanese M, Norcini J. Systematic reviews: what are they and why should\nwe care? Adv Health Sci Educ Theory Pract. (2002) 7:147\u201351. doi: 10.1023/a:\n1015786920642\n57. Altay S. How e\ufb00ective are interventions against misinformation? PsyArXiv.\n[Preprint]. (2022). doi: 10.31234/osf.io/sm3vk\n58. Roozenbeek J, Suiter J, Culloty E. Countering misinformation: evidence,\nknowledge gaps, and implications of current interventions. PsyArXiv. [Preprint].\n(2022). doi: 10.31234/osf.io/b52um\nFrontiers in Psychiatry 12 frontiersin.org", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Psychological interventions countering misinformation in social media: A scoping review", "author": ["P Gwia\u017adzi\u0144ski", "AB Gundersen", "M Piksa"], "pub_year": "2023", "venue": "Frontiers in \u2026", "abstract": "Introduction The rise of social media users and the explosive growth in misinformation shared  across social media platforms have become a serious threat to democratic discourse and"}, "filled": false, "gsrank": 638, "pub_url": "https://www.frontiersin.org/articles/10.3389/fpsyt.2022.974782/full", "author_id": ["TXVQ0kAAAAAJ", "8riqG7kAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:h_AZI149Qh4J:scholar.google.com/&output=cite&scirp=637&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=h_AZI149Qh4J&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 34, "citedby_url": "/scholar?cites=2180372644125864071&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:h_AZI149Qh4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2022.974782/pdf"}}, {"title": "Semeval-2023 task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multi-lingual setup", "year": "2023", "pdf_data": "SemEval-2023 Task 3: Detecting the Category, the Framing,\nand the Persuasion Techniques in Online News in a Multi-lingual Setup\nJakub Piskorski1, Nicolas Stefanovitch2, Giovanni Da San Martino3, Preslav Nakov4\n1Institute of Computer Science, Polish Academy of Science, Poland jpiskorski@gmail.com\n2European Commission Joint Research Centre, Italy nicolas.stefanovitch@ec.europa.eu\n3Department of Mathematics, University of Padova, Italy dasan@math.unipd.it\n4Mohamed bin Zayed University of Artificial Intelligence, UAE preslav.nakov@mbzuai.ac.ae\nAbstract\nWe describe SemEval-2023 task 3 on Detect-\ning the Category, the Framing, and the Per-\nsuasion Techniques in Online News in a Multi-\nlingual Setup : the dataset, the task organization\nprocess, the evaluation setup, the results, and\nthe participating systems. The task focused on\nnews articles in nine languages (six known to\nthe participants upfront: English ,French ,Ger-\nman,Italian ,Polish , and Russian ), and three ad-\nditional ones revealed to the participants at the\ntesting phase: Spanish ,Greek , and Georgian ).\nThe task featured three subtasks: (1) determin-\ning the genre of the article (opinion, reporting,\nor satire), (2) identifying one or more frames\nused in an article from a pool of 14 generic\nframes, and (3) identify the persuasion tech-\nniques used in each paragraph of the article,\nusing a taxonomy of 23 persuasion techniques.\nThis was a very popular task: a total of 181\nteams registered to participate, and 41 even-\ntually made an official submission on the test\nset.\n1 Introduction\nThe widespread use of Internet and the advances in\nInternet-related technologies paved the way to eas-\nily create direct communication channels between\ninformation producers and consumers, potentially\nleaving the latter exposed to manipulative, propa-\ngandistic, and deceptive content. Given the poten-\ntially huge audience that can be reached through\nonline channels, major public events and debates re-\nvolving around relevant topics could be influenced\nas a result. Therefore, there is an ever-growing\nneed to develop automated tools supporting experts\nin analysing the news ecosystem and identifying\nlarge-scale manipulation attempts, and facilitating\nthe study of how different events, global topics,\nand policies are being embraced by media in var-\nious countries, in order to carry out cross-country\nanalysis and to gather knowledge on the ways how\nmedia informs public opinion, i.e., what aspectsare being highlighted and linked to a topic, what\npros and cons are mentioned, the way opinions are\nconveyed, and what rhetorical devices, i.e., logical\nfallacies and appeal to emotions, are used to sup-\nport flawed argumentation, potentially leading to\nmanipulation.\nTo foster research in this direction, there have\nbeen several shared tasks asking to detect the use of\nspecific propaganda techniques in text, as well as\nthe specific span of each instance. This includes the\nNLP4IF-2019 shared task on Fine-Grained Propa-\nganda Detection (Da San Martino et al., 2019),\nSemEval-2020 task 11 on Detection of Persua-\nsion Techniques in News Articles (Da San Martino\net al., 2020a), SemEval-2021 task 6 on Detection of\nPersuasion Techniques in Texts and Images (Dim-\nitrov et al., 2021b), and WANLP-2022 Shared Task\non Propaganda Detection in Arabic (Alam et al.,\n2022).\nOur task is an extension of the above ones and\nintroduces several novelties. First, it is multilin-\ngual, covering nine languages. Second, it adds ad-\nditional dimensions for better news understanding,\ni.e., framing and news genre detection. Finally, our\ntaxonomy of persuasion techniques is an extension\ncompared to previous inventories, and it contains\n23 techniques organised in a two-tier hierarchy.\n2 The Tasks\nThe shared task comprises three subtasks:\nSubtask 1 (ST1): News Genre Categorization.\nGiven a news article, determine whether: (a) it\nis an opinion piece, (b) aims at objective news\nreporting , or (c) is satirical .1This is a multi-class\nclassification task at the article level.\nSubtask 2 (ST2): Framing Detection. Given a\nnews article, identify one or more frames used in\n1A satirical piece is a factually incorrect article, with the\nintent not to deceive, but rather to call out, ridicule, or expose\nbehaviours considered \u2018bad\u2019. It deliberately exposes real-\nworld individuals, organisations and events to ridicule.\nthe article from a pool of 14 generic framing dimen-\nsions (introduced in Card et al. (2015)): Economic ,\nCapacity and resources ,Morality ,Fairness and\nequality ,Legality, constitutionality and jurispru-\ndence ,Policy prescription and evaluation ,Crime\nand punishment ,Security and defense ,Health and\nsafety ,Quality of life ,Cultural identity ,Public\nopinion ,Political ,External regulation and reputa-\ntion. This is a multi-class multi-label classification\ntask at the article level.\nSubtask 3 (ST3): Persuasion Techniques Detec-\ntion. Given a news article, identify the persuasion\ntechniques used in each paragraph of the article.\nThe pool of persuasion techniques consists of 23\ntechniques, and is an extension of the taxonomy\nintroduced in Da San Martino et al. (2019); Dim-\nitrov et al. (2021b)2. This is a multi-class multi-\nlabel classification task at the paragraph level. The\npersuasion techniques are grouped into six main\ncategories:\nAttack on reputation: The argument does not\naddress the topic, but rather targets the participant\n(personality, experience, deeds) in order to question\nand/or to undermine their credibility. The object of\nthe argumentation can also refer to a group of indi-\nviduals, an organization, an object, or an activity.\nJustification: The argument is made of two parts,\na statement and an explanation or an appeal, where\nthe latter is used to justify and/or to support the\nstatement.\nSimplification: The argument excessively simpli-\nfies a problem, usually regarding the cause, the\nconsequence or the existence of choices.\nDistraction: The argument takes the focus away\nfrom the main topic or argument to distract the\nreader.\nCall: The text is not an argument, but an encour-\nagement to act or to think in a particular way.\nManipulative wording: the text is not an argument\nper se, but uses specific language, which contains\nwords or phrases that are either non-neutral, confus-\ning, exaggerating, loaded, etc., in order to impact\nthe reader emotionally.\nFigure 1 gives an overview of the two-tier per-\nsuasion techniques taxonomy.\n3 Related Work\nThis section discusses prior work related to each of\nthe subtasks of the shared task.\n2the second paper has five additional techniques with re-\nspect to the previous oneATTACK ON REPUTATION\nName Calling or Labelling [AR:NCL]: a form of argument in which\nloaded labels are directed at an individual, group, object or activity,\ntypically in an insulting or demeaning way, but also using labels the target\naudience finds desirable.\nGuilt by Association [AR:GA]: attacking the opponent or an activity by\nassociating it with another group, activity, or concept that has sharp\nnegative connotations for the target audience.\nCasting Doubt [AR:D]: questioning the character or the personal\nattributes of someone or something in order to question their general\ncredibility or quality.\nAppeal to Hypocrisy [AR:AH]: the target of the technique is attacked\nbased on their reputation by charging them with hypocrisy/inconsistency.\nQuestioning the Reputation [AR:QR]: the target is attacked by making\nstrong negative claims about it, focusing specially on undermining its\ncharacter and moral stature rather than relying on an argument about the\ntopic.\nJUSTIFICATION\nFlag Waiving [J:FW]: justifying an idea by exhaling the pride of a group\nor highlighting the benefits for that specific group.\nAppeal to Authority [J:AA]: a weight is given to an argument, an idea or\ninformation by simply stating that a particular entity considered as an\nauthority is the source of the information.\nAppeal to Popularity [J:AP]: a weight is given to an argument or idea by\njustifying it on the basis that allegedly \u201ceverybody\u201d (or the large majority)\nagrees with it or \u201cnobody\u201d disagrees with it.\nAppeal to Values [J:A V]: a weight is given to an idea by linking it to\nvalues seen by the target audience as positive.\nAppeal to Fear, Prejudice [J:AF]: promotes or rejects an idea through the\nrepulsion or fear of the audience towards this idea.\nDISTRACTION\nStrawman [D:SM]: consists in making an impression of refuting an\nargument of the opponent\u2019s proposition, whereas the real subject of the\nargument was not addressed or refuted, but instead was replaced with a\nfalse one.\nRed Herring [D:RH]: consists in diverting the attention of the audience\nfrom the main topic being discussed, by introducing another topic, which\nis irrelevant.\nWhataboutism [D:W]: a technique that attempts to discredit an\nopponent\u2019s position by charging them with hypocrisy without directly\ndisproving their argument.\nSIMPLIFICATION\nCausal Oversimplification [S:CaO]: assuming a single cause or reason\nwhen there are actually multiple causes for an issue.\nFalse Dilemma or No Choice [S:FDNC]: a logical fallacy that presents\nonly two options or sides when there are many options or sides. In\nextreme, the author tells the audience exactly what actions to take,\neliminating any other possible choices.\nConsequential Oversimplification [S:CoO]: is an assertion one is\nmaking of some \u201cfirst\u201d event/action leading to a domino-like chain of\nevents that have some significant negative (positive) effects and\nconsequences that appear to be ludicrous or unwarranted or with each step\nin the chain more and more improbable.\nCALL\nSlogans [C:S]: a brief and striking phrase, often acting like an emotional\nappeal, that may include labeling and stereotyping.\nConversation Killer [A:CK]: words or phrases that discourage critical\nthought and meaningful discussion about a given topic.\nAppeal to Time [C:AT]: the argument is centred around the idea that time\nhas come for a particular action.\nMANIPULATIVE WORDING\nLoaded Language [MW:LL]: use of specific words and phrases with\nstrong emotional implications (either positive or negative) to influence and\nconvince the audience that an argument is valid.\nObfuscation, Intentional Vagueness, Confusion [MW:OVC]: use of\nwords that are deliberately not clear, vague, or ambiguous so that the\naudience may have its own interpretations.\nExaggeration or Minimisation [MW:EM]: consists of either\nrepresenting something in an excessive manner or making something seem\nless important or smaller than it really is.\nRepetition [MW:R]: the speaker uses the same phrase repeatedly with the\nhope that the repetition will lead to persuade the audience.\nFigure 1: Persuasion techniques taxonomy. The six\ncoarse-grained techniques are subdivided into 23 fine-\ngrained ones. An acronym for each technique is given\nin squared brackets.\n3.1 News Genre Categorization\nRashkin et al. (2017) developed a corpus with\ndocument-level annotations into four classes\n(trusted ,satire ,hoax , and propaganda ), annotated\nusing distant supervision. Horne and Adali (2017)\nstudied the relationship between fake news, real\nnews, and satire with focus on style. They found\nthat fake news is more similar to satire than to real\nnews. Golbeck et al. (2018) developed a dataset\nof fake news and satire stories and analyzed and\ncompared their thematic content. Satire was also\none of the categories in the NELA-GT-2018 dataset\n(N\u00f8rregaard et al., 2019), as well as in its extended\nversion NELA-GT-2019 (Gruppi et al., 2020).\nThe set up of our shared task is different, and\nfocusing on distinguishing between objective news\nreporting vs. opinion piece vs. satire.\n3.2 Framing Detection\nFraming is a strategic device and a central con-\ncept in political communication for representing\ndifferent salient aspects and perspectives for the\npurpose of conveying the latent meaning about an\nissue (Entman, 1993). It is important for news\nmedia as the same topics can be discussed from\ndifferent perspectives. There has been work on\nautomatically identifying media frames, including\nannotation schemes and datasets such as the Media\nFrames Corpus (Card et al., 2015), systems to au-\ntomatically detect media frames (Liu et al., 2019;\nZhang et al., 2019), large-scale automatic analysis\nof New York Times Articles (Kwak et al., 2020),\nand a semi-supervised approach to detecting frames\nin online news sources (Cheeks et al., 2020).\nIn our shared task, we adopt the frame inventory\nof the Media Frames Corpus.\n3.3 Persuasion Techniques Detection\nWork on persuasion detection overlaps to a large\nextent with work on propaganda detection, as there\nare many commonalities between the two.\nEarly work on propaganda detection focused on\ndocument-level analysis. Rashkin et al. (2017) pre-\ndicted four classes ( trusted ,satire ,hoax , and propa-\nganda ), labeled using distant supervision. Barr\u00f3n-\nCedeno et al. (2019) developed a corpus with two\nlabels (i.e., propaganda vs.non-propaganda ) and\nfurther investigated writing style and readability\nlevel. Their findings confirmed that using distant\nsupervision, in conjunction with rich representa-\ntions, might encourage the model to predict thesource of the article, rather than to discriminate\npropaganda from non-propaganda.\nAn alternative line of research focused on de-\ntecting the use of specific propaganda techniques\nin text, e.g., Habernal et al. (2017, 2018) devel-\noped a corpus with 1.3k arguments annotated with\nfive fallacies that directly relate to propaganda tech-\nniques. A more fine-grained analysis was done by\nDa San Martino et al. (2019), who developed a cor-\npus of news articles annotated for 18 propaganda\ntechniques, considering separately the task of tech-\nnique spans detection and classification. They fur-\nther tackled a sentence-level propaganda detection\ntask, and proposed a multi-granular gated deep\nneural network. Subsequently, the Prta system was\nreleased (Da San Martino et al., 2020c), and im-\nproved models were proposed addressing the limi-\ntations of transformers (Chernyavskiy et al., 2021),\nor looking into interpretable propaganda detection\n(Yu et al., 2021). Finally, there is work addressing\nthe detection of use of propaganda techniques in\nmemes (Dimitrov et al., 2021a), the relationship\nbetween propaganda and coordination (Hristakieva\net al., 2022), and work studying COVID-19 related\npropaganda in social media (Nakov et al., 2021a,b).\nSee (Da San Martino et al., 2020b) for a survey on\ncomputational propaganda detection.\nSeveral shared tasks on propaganda detecting in\ntext were also organized. SemEval-2020 task 11\non Detection of Persuasion Techniques in News Ar-\nticles (Da San Martino et al., 2020a) focused on\nnews articles, and asked to detect the text spans\nwhere propaganda techniques are used, and to pre-\ndict their type (14 techniques). Closely related to\nthat is the NLP4IF-2019 task on Fine-Grained Pro-\npaganda Detection (Da San Martino et al., 2019),\nwhich asked to detect the spans of use in news ar-\nticles of each of 18 propaganda techniques. The\nSemEval-2021 task 6 on Detection of Persuasion\nTechniques in Texts and Images focused on 22\npropaganda techniques in memes (Dimitrov et al.,\n2021b), while WANLP\u20192022 shared task asked to\ndetect the use of 20 propaganda techniques in Ara-\nbic tweets (Alam et al., 2022). Here, we extend\nand redesign the above annotation schemes.\n4 The Dataset\nThis section provides a brief description of the\ndataset, whereas detailed guidelines, definitions\nand examples are provided in a separate technical\nreport (Piskorski et al., 2023).\nWe collected articles in nine languages: En-\nglish, French, German, Georgian, Greek, Italian,\nPolish, Russian, and Spanish published in the pe-\nriod between 2020 and mid-2022, and revolving\naround various globally discussed topics, including\nthe COVID-19 pandemic, abortion-related legisla-\ntion, migration, Russo-Ukrainian war, some local\nevents such as parliamentary elections, etc. We con-\nsidered both mainstream media and \u201calternative\u201d\nmedia sources that could potentially spread mis-\n/disinformation. For the former, we used various\nnews aggregation engines, e.g., Google News3and\nEurope Media Monitor4, etc., which cover sources\nwith different political orientation, whereas for the\nlatter, we used online services such as MediaBias-\nFactCheck5and NewsGuard.6We extracted the ar-\nticle texts either using Trafilatura (Barbaresi, 2021)\nor, in few cases, ad hoc procedures.\nWe annotated each text for genre, framing, and\npersuasion techniques using the taxonomy de-\nscribed in Section 2. While genre and framing\nwere annotated at the document level, we anno-\ntated the persuasion techniques at the span level.\nWe had about 40 annotators, who were either media\nanalysts, disinformation specialists or NLP experts,\nmost of which had prior experience in performing\nlinguistic annotations. All annotators were either\nnative or near-native speakers of the language they\nannotated for. We used the INCEpTION (Klie et al.,\n2018) platform for carrying out the annotations.\nThe annotation interface for an example document\nusing INCEpTION is shown in Figure 2.\nFigure 2: Example of a multi-label annotation using In-\nception: news genre is annotated as document metadata\n(left), while the persuasion techniques and the framings\nare highlighted in blue and green, respectively.\nAs regards English, we exploited the texts from\nDa San Martino et al. (2019), but the annotations\n3https://news.google.com\n4https://emm.newsbrief.eu\n5https://mediabiasfactcheck.com\n6https://www.newsguardtech.comfor persuasion techniques have been slightly modi-\nfied in order to match the extended taxonomy, most\nnotably Whataboutism included two meanings: dis-\ntracting from the main argument and calling the\nhypocrisy of the speaker; the latter meaning is\nnow covered by the technique Appeal to Hypocrisy .\nMoreover, we added annotations for framing and\nnews genre.\ntrain\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 446 2,431K 7201 9498 3.7 16.1\nFrench 158 737K 5,595 2196 3.0 35.4\nGerman 132 581K 4,501 1484 4.3 34.1\nItalian 227 927K 6,027 2552 3.8 26.6\nPolish 145 765K 2,839 2294 5.0 19.6\nRussian 143 590K 3,399 1876 2.5 23.8\ndevelopment\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 90 403K 1,801 3,127 5.1 20.0\nFrench 53 222K 1,586 610 3.0 29.9\nGerman 45 171K 1,236 522 4.6 27.5\nItalian 76 287K 1,934 882 3.9 25.4\nPolish 49 264K 985 800 4.9 20.1\nRussian 48 163K 739 515 2.3 15.4\ntest\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 54 228K 1,775 910 4.7 32.9\nFrench 50 181K 1,681 510 3.1 33.6\nGerman 50 259K 1,904 790 5.7 38.1\nItalian 61 245K 2,351 593 3.8 38.5\nPolish 47 349K 1,491 1006 5.9 31.7\nRussian 72 161K 944 601 1.2 13.1\nGeorgian 29 46K 218 161 1.7 7.5\nGreek 64 248K 691 947 2.9 10.8\nSpanish 30 109K 546 330 2.3 18.2\nTable 1: Statistics about the training , the development ,\nand the testdatasets: total number of documents (#docs),\ntotal number of characters (#chars), total number of text\nspans annotated (#spans), total number of non-empty\nparagraphs (#ne-par), average number of frames per\ndocument (#avg-fr), and average number of persuasion\ntechniques per document (#avg-pt).\ntrain dev test\nlang op rep sat op rep satire op rep sat\nEnglish 382 41 10 20 54 9 32 17 5\nFrench 103 43 11 35 15 4 37 7 6\nGerman 86 27 19 29 9 7 33 12 5\nItalian 174 44 8 59 15 3 41 13 7\nPolish 104 25 15 35 9 6 35 10 2\nRussian 93 41 8 32 14 3 45 18 9\nGeorgian - - - - - - 19 10 0\nGreek - - - - - - 39 22 3\nSpanish - - - - - - 14 9 7\nall 942 221 71 210 116 32 295 118 44\nTable 2: Number of documents from each genre across\nthe languages: opinion (op), reporting (rep), satire (sat).\nEach document was annotated by at least two\nannotators. Once the individual annotations for a\ndocument have been accomplished, a curator (an\nexperienced annotator) with the help of annotators\nconsolidated the final annotation. The consolida-\ntion consisted of: (a) merging complementary an-\nnotations (tagged only by one annotator), (b) decid-\ning whether overlapping annotations are to be kept\nas they are (multi-labels) or joined into a single-\nlabeled annotation, and (c) carrying out global con-\nsistency analysis. The detailed description of the\nannotation and the consolidation process are de-\nscribed in a detailed technical report (Piskorski\net al., 2023). In order to assess the annotation qual-\nity, we computed the Inter-Annotator Agreement\n(IAA) using Krippendorf\u2019s \u03b1: the value was 0.342,\nwhich is lower than the recommended threshold\nof 0.667, but we should note that this value repre-\nsents the agreement before the consolidation, and\nas such, it is more representative of the consoli-\ndation difficulty rather than of the quality of the\nfinal consolidated annotations. Actually, we used\nIAA to allocate consolidation roles and to eliminate\nlow-performing annotators.\nWe further studied the IAA by ranking the an-\nnotators by their performance with respect to the\nground truth on the subset of documents they anno-\ntated. We then split them into two groups, topand\nlow, based on the median micro- F1scores. Their\nrespective \u03b1scores were 0.415 and 0.250. Finally,\nwe considered the value of \u03b1of the group of anno-\ntators, based on Italian, the only language with two\ncurators, achieving 0.588, which is lower but close\nto the recommended value.\nThe annotated data, consisting of 2,049 docu-\nments in total, were divided into train ,dev, and test\ndatasets, whose high-level statistics are provided in\nTable 1. Georgian, Greek, and Spanish-annotated\ndata was used only for testing (surprise languages).\nTable 2 shows the distribution of articles per lan-\nguage in terms of genre. Detailed statistics about\nthe fine-grained persuasion techniques are shown\nin Table 17 in Annex A.\n5 Evaluation Framework\n5.1 Evaluation Measures\nSubtask 1 is a multi-class classification problem.\nWe used macro F 1as the official evaluation mea-\nsure, but we also computed micro F 1.\nSubtask 2 is a multi-label multi-class classification\nproblem. We used micro F 1as the official evalua-\ntion measure, but we also computed macro F 1.\nSubtask 3 is a multi-label multi-class classification\nproblem. We used micro F 1as the official eval-\nuation measure. The official score was computedusing the 23 fine-grained persuasion technique la-\nbels. We also computed macro F 1.\n5.2 Task Organization\nThe shared task was run in two phases:\nDevelopment Phase: initially, only training and\ndevelopment data were made available to the par-\nticipants, and no gold labels were provided for the\nlatter. The participants competed against each other\nto achieve the best performance on the develop-\nment set. They could make an unlimited number\nof submissions, and the best score for each team,\nregardless of the submission time, was shown in\nreal time on a public leaderboard.\nTest Phase: in the second phase, the gold labels\nfor the development and the testsets were released,\nand the participants were given a week to submit\ntheir final predictions on the testset. It is impor-\ntant to note that the test data contained news in\nthree additional languages, i.e., Georgian, Greek,\nand Spanish, which were not known upfront to the\nparticipants (surprise languages). The participants\ncould again submit multiple runs, but they would\nnot get any feedback on their performance. Only\nthe latest submission of each team was considered\nas official and was used for the final team ranking.\nOverall, 41 teams made official submissions to all\nthe tasks, where 27, 22, and 22 teams submitted\nresults for ST1, ST2, ST3, respectively. Moreover,\n13, 14, and 14 teams submitted results for all lan-\nguages for ST1, ST2, ST3, respectively.\nThe results for the development and the test\nphases are available on the leaderboard7page. Af-\nter the competition was over, we left the submission\nsystem open for the test dataset for post-shared task\nevaluations and to monitor the state of the art for\nthe different subtasks across the languages.\n6 Participants and Results\n6.1 Subtask 1: News Genre Categorization\nThe full results for Subtask 1 are shown in Tables 3\nand 4 (surprise languages). We used a linear SVM8\nwith class balancing, trained on 5-char n-grams as a\nbaseline (highlighted in blue in the tables). Table 5\nshows an overview of the approaches. Almost all\nparticipants used transformers. The scarcity of the\nannotated data was dealt with either by combining\nthe datasets for all languages, e.g., via multilingual\n7https://propaganda.math.unipd.it/\nsemeval2023task3/leaderboard.php\n8https://scikit-learn.org\nEnglish Italian Russian French German Polish\nTEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic\nMELODI .784 .815 Hitachi .768 .852 Hitachi .755 .750 UMUTeam .835 .880 UMUTeam .820 .820 FTD .786 .936\nMLModeler5 .616 .630 QUST .767 .836 SheffieldVeraAI .729 .722 QCRI .767 .800 SheffieldVeraAI .820 .820 Hitachi .779 .872\nSheffieldVeraAI .613 .704 DSHacker .720 .836 FTD .668 .694 Hitachi .744 .780 DSHacker .813 .820 SheffieldVeraAI .765 .851\nHHU .594 .611 SheffieldVeraAI .720 .836 UMUTeam .645 .681 DSHacker .710 .720 SinaAI .782 .760 MELODI .709 .851\nDSHacker .591 .630 MELODI .587 .754 MELODI .586 .625 SheffieldVeraAI .682 .740 MELODI .779 .780 UMUTeam .664 .809\nUnisa .586 .611 UnedMediaBias .584 .623 QCRI .567 .653 FTD .671 .780 Hitachi .777 .760 SinaAI .663 .809\nHitachi .553 .593 UMUTeam .553 .754 DSHacker .559 .597 MELODI .656 .740 FTD .713 .720 DSHacker .661 .809\nUnedMediaBias .524 .574 QCRI .541 .787 Spoke .490 .653 SinaAI .638 .680 QCRI .667 .660 kb .653 .809\nSinaAI .506 .667 FTD .517 .754 QUST .472 .514 QUST .621 .700 SATLab .644 .700 SATLab .571 .830\nQUST .506 .630 SinaAI .502 .738 SinaAI .443 .472 Baseline .568 .740 Baseline .630 .760 QCRI .571 .830\nUMUTeam .413 .593 HHU .455 .639 HHU .426 .472 UnedMediaBias .465 .480 QUST .626 .660 QUST .528 .596\nUM6P .394 .519 Riga .436 .574 Baseline .398 .653 SATLab .447 .640 HHU .611 .740 UnedMediaBias .507 .553\nRiga .349 .537 Baseline .389 .672 UnedMediaBias .365 .444 Riga .356 .580 FramingFreaks .569 .700 Baseline .490 .830\nFTD .329 .463 FramingFreaks .360 .656 Riga .271 .389 JUSTR00 .347 .660 Riga .412 .480 Riga .433 .468\nkb .299 .574 SATLab .319 .623 MaChAmp .256 .625 FramingFreaks .341 .660 UnedMediaBias .362 .420 MaChAmp .285 .745\nBaseline .288 .611 JUSTR00 .317 .574 FramingFreaks .236 .319 MaChAmp .284 .740 JUSTR00 .265 .660 FramingFreaks .282 .702\nQCRI .281 .593 MaChAmp .268 .672 E8IJS .175 .306 E8IJS .080 .120 MaChAmp .265 .660 E8IJS .063 .085\nSpoke .265 .444 E8IJS .121 .164 E8IJS .118 .180\nJUSTR00 .257 .370\nFramingFreaks .248 .593\nMaChAmp .248 .593\nssnNlp .248 .593\nSATLab .243 .574\nUTB-NLP .243 .574\nE8IJS .075 .093\nTable 3: Results for Subtask 1 for the six main languages: macro F 1(mac), micro F 1(mic), ordered by the former,\nwhich is the official score.\nlanguage models or by automatic translation, or\nby looking for similar datasets in the literature;\nensemble methods have also been very popular.\nSpanish Greek Georgian\nTEAM mac mic TEAM mac mic TEAM mac mic\nDSHacker .563 .567 SinaAI .806 .813 Riga 1,000 1,000\nQUST .552 .633 UMUTeam .767 .797 SheffieldVeraAI .963 .966\nQCRI .489 .567 HHU .750 .750 FTD .888 .897\nSheffieldVeraAI .443 .500 QCRI .708 .813 QCRI .622 .897\nMELODI .443 .600 FTD .698 .766 DSHacker .597 .862\nUMUTeam .438 .500 SheffieldVeraAI .687 .734 UMUTeam .582 .862\nFTD .400 .433 MELODI .637 .703 QUST .537 .690\nRiga .385 .500 DSHacker .593 .641 SATLab .519 .724\nUnedMediaBias .336 .367 UnedMediaBias .521 .563 MELODI .490 .724\nHHU .327 .433 QUST .492 .609 UnedMediaBias .486 .690\nSinaAI .323 .433 Riga .412 .578 SinaAI .468 .690\nFramingFreaks .317 .467 SATLab .254 .406 MaChAmp .396 .655\nSATLab .282 .433 MaChAmp .252 .609 Baseline .256 .345\nE8IJS .235 .300 FramingFreaks .234 .344 FramingFreaks .255 .621\nMaChAmp .212 .467 Baseline .171 .344 E8IJS .000 .000\nBaseline .154 .300 E8IJS .057 .063\nTable 4: Results for Subtask 1 for the three surprise\nlanguages: macro F 1(mac), micro F 1(mic), ordered\nby the former, which is the official score.\nBelow, we give a short description of the sys-\ntem papers that were top-ranked for at least one\nlanguage.\nSinaAI (EL) used multilingual languages mod-\nels, XLM, mBERT and LABSE, and ensembles\nthereof. They further used data augmentation by\nselecting 30% of the sentences of each document\nto create new synthetic examples.\nDSHacker (ES) created synthetic texts for each\nclass using the OpenAI GPT-3 Davinci language\nmodel. Each language was augmented by approxi-\nmately 500 articles per genre, producing roughly\n13,500 artificially generated articles. Then, they\nfine-tuned a single XLM-RoBERTalarge on theTeam Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nDSHacker \u2713 \u2713 \u2713 \u2713\nFTD \u2713 \u2713 \u2713 \u2713 \u2713\nHHU \u2713 \u2713 \u2713 \u2713 \u2713\nHitachi \u2713 \u2713 \u2713 \u2713\nMELODI \u2713 \u2713 \u2713\nMLModeler5 \u2713 \u2713 \u2713 \u2713\nMaChAmp \u2713 \u2713 \u2713\nNLUBot101\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nRiga \u2713 \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nUM6P \u2713 \u2713 \u2713\nUMUTeam \u2713 \u2713 \u2713 \u2713\nUTB-NLP \u2713 \u2713 \u2713 \u2713\nUnedMediaBiasTeam \u2713 \u2713 \u2713\nUnisa \u2713 \u2713 \u2713 \u2713\nkb \u2713\nTable 5: ST1: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\noriginal and the augmented data.\nFTD (PL): They experimented with monolin-\ngual and multilingual models, ensembles, addi-\ntional data, and uncertainty estimation. For Russian\nand English, they fine-tuned models pretrained on\nthe FTD dataset for genre classification. For En-\nglish, they added 1,000 reporting texts from Giga-\nword. For Polish and German, their best results\nwere achieved by fine-tuning a monolingual Polish\nBERT and a monolingual German Electra, respec-\nEnglish Italian Russian French German Polish\nTEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac\nSheffieldVeraAI .579 .539 MarsEclipse .617 .545 MarsEclipse .450 .303 MarsEclipse .553 .537 MarsEclipse .711 .660 MarsEclipse .673 .638\nTeamAmpa .567 .510 QCRI .599 .479 SheffieldVeraAI .441 .356 BERTastic .537 .520 QCRI .660 .606 SheffieldVeraAI .645 .603\nMarsEclipse .562 .490 Hitachi .598 .515 QCRI .434 .364 SheffieldVeraAI .534 .520 SheffieldVeraAI .653 .601 QCRI .642 .599\nHitachi .543 .472 TeamAmpa .597 .483 TeamAmpa .409 .294 Hitachi .514 .488 TeamAmpa .632 .573 UMUTeam .642 .593\nmCPT .535 .482 mCPT .584 .469 mCPT .409 .367 TeamAmpa .506 .479 Hitachi .629 .567 Hitachi .634 .584\nQUST .513 .462 UMUTeam .576 .447 BERTastic .393 .265 TheSyllogist .486 .462 mCPT .622 .564 SATLab .620 .570\nQCRI .513 .419 SheffieldVeraAI .571 .491 TheSyllogist .385 .290 QCRI .480 .430 QUST .616 .545 TeamAmpa .614 .555\nBERTastic .512 .446 TheSyllogist .554 .444 UMUTeam .385 .288 UMUTeam .477 .438 UMUTeam .614 .565 MaChAmp .597 .582\nUMUTeam .508 .415 BERTastic .545 .469 Hitachi .370 .326 mCPT .469 .429 BERTastic .603 .562 mCPT .597 .555\nACCEPT .507 .502 QUST .502 .465 Riga .315 .222 ACCEPT .456 .443 MaChAmp .582 .564 Baseline .594 .532\nMaChAmp .506 .493 Riga .499 .321 ACCEPT .254 .249 QUST .447 .438 SATLab .572 .519 QUST .591 .533\nTheSyllogist .487 .409 ACCEPT .495 .439 QUST .250 .213 Riga .376 .287 FTD .555 .299 FTD .588 .516\nMLModeler5 .477 .427 Baseline .486 .372 Baseline .230 .218 SATLab .375 .352 FramingFreaks .545 .496 BERTastic .587 .535\nFTD .453 .362 SATLab .474 .416 FramingFreaks .219 .159 MaChAmp .359 .355 TheSyllogist .537 .465 FramingFreaks .560 .460\nJUSTR00 .443 .363 FTD .459 .227 FTD .198 .117 Baseline .329 .276 Riga .509 .375 TheSyllogist .553 .501\nRiga .420 .313 FramingFreaks .452 .355 MaChAmp .161 .151 FramingFreaks .327 .300 ACCEPT .496 .460 Riga .542 .412\nSATLab .378 .317 MaChAmp .424 .403 SinaAI .113 .128 FTD .255 .105 Baseline .487 .418 ACCEPT .510 .490\nBaseline .350 .274 SinaAI .251 .200 DigDemLab .070 .055 DigDemLab .220 .192 DigDemLab .335 .279 SinaAI .475 .446\nUTB-NLP .341 .309 DigDemLab .237 .173 SinaAI .187 .157 SinaAI .302 .265 DigDemLab .392 .348\nIA2022Grupa1 .326 .265\nSinaAI .266 .226\nDigDemLab .207 .172\nFramingFreaks .196 .142\nTable 6: Results for Subtask 2 for the six main languages: micro F 1(mic), macro F 1(mac), ordered by the former,\nwhich is the official score.\nSpanish Greek Georgian\nTEAM mic mac TEAM mic mac TEAM mic mac\nmCPT .571 .455 SheffieldVeraAI .546 .454 SheffieldVeraAI .654 .679\nUMUTeam .558 .465 TeamAmpa .544 .444 MarsEclipse .645 .639\nSheffieldVeraAI .508 .432 UMUTeam .534 .404 TheSyllogist .561 .493\nTeamAmpa .506 .387 TheSyllogist .530 .440 BERTastic .552 .408\nRiga .489 .426 BERTastic .526 .444 UMUTeam .529 .411\nQCRI .488 .390 QCRI .519 .400 QCRI .517 .457\nMarsEclipse .477 .404 mCPT .516 .410 TeamAmpa .517 .379\nBERTastic .477 .428 MarsEclipse .498 .402 Riga .424 .381\nTheSyllogist .473 .387 QUST .414 .392 mCPT .400 .291\nACCEPT .388 .387 FramingFreaks .380 .154 FramingFreaks .352 .344\nMaChAmp .385 .269 Riga .377 .195 MaChAmp .313 .225\nSATLab .383 .293 ACCEPT .355 .370 QUST .311 .260\nQUST .374 .353 Baseline .345 .057 Baseline .260 .251\nFTD .265 .201 MaChAmp .293 .206 ACCEPT .220 .290\nFramingFreaks .215 .211 SinaAI .140 .123 SinaAI .133 .205\nSinaAI .181 .163 SATLab .068 .037 SATLab .053 .184\nBaseline .120 .095\nTable 7: Results for Subtask 2 for the three surprise\nlanguages: micro F 1(mic), macro F 1(mac), ordered\nby the former, which is the official score.\ntively. For the other languages, their best systems\nused multilingual BERT, XLM-RoBERTa, or en-\nsembles thereof. In all cases, they truncated the\ninput to the first 510 tokens. They further upsam-\npled the data to balance the distribution between\nthe classes (the results without upsampling were\nlow).\nHitachi (IT, RU) augmented the dataset for sub-\ntask 1 by collecting labelled examples from simi-\nlar datasets. They pretrained (XLM-)RoBERTa in\nmulti-task (one language, subtasks 1 and 2), multi-\nlingual (one subtask, all languages), and multilin-\ngual multi-task (subtasks 1 and 2 in all languages)\nsettings. Besides using the single models, they re-\nport experiments with ensembles of base models\nand different hyper-parameter values.\nMELODI (EN) fine-tuned the domain-specificlanguage model trained on English data, POLI-\nTICS, on the English input articles and on the\narticles in all other languages, which were auto-\nmatically translated. In addition, in order to use\nwhole articles as input, they used a sliding win-\ndow and aggregated each window representation\nusing mean-pooling. They also tested other multi-\nlingual approaches, such as XLM-RoBERTa, and\nwere able to process long documents (Longformer),\nwhich were generally less effective.\nUMUTeam (FR, DE) used a multilingual model\nbased on XML-RoBERTa, which was fine-tuned\non all languages at once and a sentence transformer\nmodel to extract the most important chunk of text.\nThe input data was truncated to 200 tokens with 50\noverlaps using the sentence-transformer model to\nobtain the subset of text most related to the article\u2019s\ntitle.\nSheffieldVeraAI (DE) deployed an ensemble of\nthree fine-tuned mBERT models and one mBERT\nmodel with a bottleneck adapter. All used bert-\nbase-multilingual-cased. The pool of training data\nwas also extended by integration additional \u201csatire\u201d\nresources for English. The final predictions were\ndrawn as a majority-voting predicted class.\n6.2 Subtask 2: Framing\nThe full results for subtask 2 on framing classifi-\ncation are provided in Table 6 and 7 (surprise lan-\nguages). We used linear SVM trained using word\nunigrams and bigrams as a baseline (highlighted in\nblue in the tables). Table 8 shows an overview\nof the approaches. Since the models were all\ntransformer-based, what differentiated the partici-\npating systems were once again the pre-processing\nand the data augmentation techniques. The vast\nmajority of teams trained their systems on all lan-\nguages and used ensembles.\nTeam Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nACCEPT \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nBERTastic \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713\nHitachi \u2713 \u2713 \u2713\nMLModeler5 \u2713 \u2713 \u2713 \u2713\nMaChAmp \u2713\nMarsEclipse \u2713 \u2713 \u2713\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nRiga \u2713 \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nTheSyllogist \u2713 \u2713 \u2713\nUMUTeam \u2713 \u2713 \u2713\nUTB-NLP \u2713 \u2713 \u2713 \u2713\nmCPT \u2713 \u2713\nTable 8: ST2: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\nMarsEclipse (IT, RU, FR, DE, PL): This team\nused a multi-label contrastive loss for fine-tuning\nXLM-RoBERTa using SimCLR and SimCSE and\nadapting the loss function to a multilabel setup.\nmCPT (ES): This team used a two-phase train-\ning procedure of a transformer model, first by pre-\ntraining jointly on all the languages and then by\nfine-tuning for each language. In both phases, a\nmulti-label contrastive loss was used.\nSheffieldVeraAI (EN, EL, KA): The team\nachieved the best average rank score over all the\nlanguages. They used two different ensembles of\nMUPPET large and of XLM-RoBERTa large with\nadapters and task-adaptive MLM pretraining on the\ntrain+dev+test data. Their data was preprocessed\nand truncated. The models were trained both with\nand without class weighting.\n6.3 Subtask 3: Persuasion Techniques\nDetection\nThe full results for subtask 3 on persuasion tech-\nniques detection are given in Tables 9 and 10 (sur-\nprise languages). We used linear SVM trained\nusing word uni-grams and bigrams as a baseline\n(highlighted in blue in the tables). Table 11 shows\nan overview of the approaches used by the partic-ipating systems. The big picture is very similar\nto the previous subtasks: multilingual transformer\nmodels were used by all participants, and what\ndifferentiated the approaches was again the pre-\nprocessing and data augmentation strategies, for\nexample, a few teams made use of the span-level\nannotations.\nAPatt (EN): The team combined different fine-\ntuned transformer models (XLNet, RoBERTa,\nBERT, ALBERT, and DeBERTa) through a\nweighted average. For English, they weighted the\npredictions of the models to give higher importance\nto certain models.\nKInITVeraAI (IT, RU, DE, PL, EL, KA): This\nteam performed overall the best, using a fine-tuned\nXLM-RoBERTa-large transformer model trained\non all the input data. They carefully adjusted the\nprediction threshold for each language using a prin-\ncipled approach. They truncated the input, and also\nfound that preprocessing did not impact the quality\nmuch.\nNAP (FR): The team presented an approach\ncombining predictions of several models in an en-\nsemble, which differ in three main aspects: a)\ntraining data, b) model architecture, and c) in-\nput format to the model. They leveraged trans-\nlation as data augmentation strategies using avail-\nable MarianMT models. Model architectures in-\ncluded XLM-RoBERTa models, Adapters, SetFit,\nand linguistically-informed heuristics for under-\nrepresented techniques which were fine-tuned on\ndifferent combinations of original and augmented\ndata. They fine-tuned models on both paragraph-\nand span-level information.\nTeamAmpa (ES): The team used different over-\nsampling strategies, data truncation, and monolin-\ngual and multilingually trained models, combined\nin an ensemble for the English Task 3 data. The\nsurprise languages were handled using the mul-\ntilingual model only, which where trained using\nXLM-R on all languages with oversampling, for\none of these languages the team ranked first.\n6.4 Aggregated results\nTables 12-14 report the average micro F 1scores of\nthe teams who, for each subtask, submitted solu-\ntions for multiple languages: the 6 for which we\nprovided training data (6L), the 3 surprise ones\n(3L), all of them (9L). Results are ranked by de-\ncreasing value on all.\nEnglish Italian Russian French German Polish\nTEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac\nAPatt .376 .129 KInITVeraAI .550 .214 KInITVeraAI .387 .189 NAP .469 .322 KInITVeraAI .513 .233 KInITVeraAI .430 .179\nSheffieldVeraAI .368 .172 NAP .539 .266 TeamAmpa .378 .227 TeamAmpa .434 .305 NAP .510 .272 NAP .422 .246\nAppealForAtt .363 .166 SheffieldVeraAI .525 .282 QCRI .361 .182 KInITVeraAI .432 .214 QCRI .498 .231 DSHacker .390 .170\nKInITVeraAI .362 .133 TeamAmpa .521 .264 NLUBot101 .323 .201 SheffieldVeraAI .414 .324 APatt .484 .177 TeamAmpa .389 .236\nNLUBot101 .361 .197 FTD .516 .176 SheffieldVeraAI .318 .205 QCRI .401 .226 TeamAmpa .476 .266 QCRI .378 .156\nFTD .346 .088 QCRI .513 .209 AppealForAtt .312 .173 NLUBot101 .396 .254 SheffieldVeraAI .447 .237 APatt .366 .150\nTeamAmpa .325 .158 DSHacker .496 .153 APatt .306 .117 DSHacker .388 .201 NLUBot101 .420 .179 SheffieldVeraAI .347 .191\nQCRI .320 .133 ReDASPersuasion .448 .106 NAP .305 .193 APatt .384 .191 AppealForAtt .418 .218 AppealForAtt .344 .201\nDSHacker .320 .140 APatt .441 .166 MaChAmp .271 .148 AppealForAtt .374 .203 DSHacker .408 .154 FTD .327 .122\nCLaC .309 .071 Riga .436 .092 DSHacker .257 .083 kb .362 .266 MaChAmp .405 .178 NLUBot101 .320 .169\nNL4IA .308 .142 NLUBot101 .435 .164 kb .253 .117 MaChAmp .345 .207 ReDASPersuasion .384 .078 kb .314 .179\nUnisa .298 .109 SATLab .433 .183 Riga .252 .064 SATLab .338 .241 kb .373 .201 MaChAmp .307 .170\nMaChAmp .295 .149 AppealForAtt .431 .211 FTD .235 .058 Riga .306 .078 Riga .373 .060 SATLab .300 .143\nRiga .280 .062 MaChAmp .422 .166 ReDASPersuasion .219 .050 ReDASPersuasion .301 .115 FTD .363 .110 ReDASPersuasion .238 .112\nNAP .263 .082 kb .399 .201 Baseline .207 .086 FTD .298 .126 SATLab .355 .163 UnedMediaBias .237 .103\nSATLab .259 .103 Baseline .397 .122 CLaC .193 .057 Baseline .240 .099 UnedMediaBias .318 .106 Riga .228 .038\nReDASPersuasion .251 .045 UnedMediaBias .317 .111 UnedMediaBias .183 .100 CLaC .239 .066 Baseline .317 .083 CLaC .190 .050\nUnedMediaBias .241 .078 CLaC .313 .063 SinaAI .139 .057 UnedMediaBias .236 .121 CLaC .248 .055 Baseline .179 .059\nBaseline .195 .069 QUST .213 .155 QUST .100 .080 QUST .209 .164 QUST .153 .112 QUST .097 .074\nIA2022Grupa1 .193 .072 SinaAI .203 .064 SinaAI .195 .063 SinaAI .042 .034 SinaAI .064 .025\nSinaAI .141 .022\nQUST .135 .103\nkb .060 .031\nTable 9: Results for subtask 3 for the six main languages: micro F 1(mic), macro F 1(mac), ordered by the former,\nwhich is the official score.\nSpanish Greek Georgian\nTEAM mic mac TEAM mic mac TEAM mic mac\nTeamAmpa .381 .244 KInITVeraAI .267 .126 KInITVeraAI .457 .328\nKInITVeraAI .380 .155 QCRI .265 .129 QCRI .414 .339\nNAP .370 .181 NAP .258 .164 NAP .413 .306\nQCRI .350 .157 TeamAmpa .238 .171 TeamAmpa .408 .259\nAppealForAtt .317 .139 MaChAmp .215 .129 Riga .362 .209\nNLUBot101 .305 .151 AppealForAtt .206 .119 MaChAmp .301 .221\nFTD .281 .074 SheffieldVeraAI .174 .110 AppealForAtt .280 .261\nMaChAmp .276 .139 Riga .164 .036 CLaC .271 .199\nSheffieldVeraAI .275 .130 CLaC .156 .055 NLUBot101 .254 .172\nCLaC .267 .048 NLUBot101 .150 .097 SheffieldVeraAI .249 .296\nBaseline .248 .020 kb .150 .121 UnedMediaBias .180 .221\nkb .245 .143 SinaAI .114 .029 kb .150 .100\nUnedMediaBias .227 .078 UnedMediaBias .106 .026 SinaAI .139 .040\nRiga .199 .045 Baseline .088 .006 Baseline .138 .141\nSATLab .193 .057 QUST .057 .047 QUST .091 .115\nSinaAI .178 .028 SATLab .000 .000 SATLab .076 .158\nQUST .126 .099\nTable 10: Results for Subtask 3 for the three surprise\nlanguages: micro F 1(mic), macro F 1(mac), ordered\nby the former, which is the official score.\n7 Conclusions and Future Work\nWe presented SemEval-2023 Task 3 on Detecting\nthe Category, the Framing, and the Persuasion\nTechniques in Online News in a Multi-lingual Setup .\nThe task attracted a lot of attention: 181 teams reg-\nistered for the task, 41 teams eventually madevan\nofficial submission on the test set, and 32 teams\nalso submitted a task description paper.\nIn future work, we plan to further increase the\ndata size, cover additional languages, and explore\ndifferent ways of evaluation of the persuasion\ntechnique detection, e.g., by changing the focus\n(sentence- and text span-level evaluation).\n8 Limitations\nDataset Representativeness Our dataset covers\na range of topics of public interest (COVID-19,Team Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nAPatt \u2713 \u2713\nAppealForAtt \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nDSHacker \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713\nKInITVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNAP \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNL4IA \u2713 \u2713\nNLUBot101 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nReDASPersuasion \u2713 \u2713\nRiga \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713\nUnedMediaBiasTeam \u2713 \u2713 \u2713\nUnisa \u2713 \u2713 \u2713\nkb \u2713 \u2713\nTable 11: ST3: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\nclimate change, abortion, migration, the Russo-\nUkrainian war, and local elections) as well as media\nfrom all sides of the political spectrum. However,\nit should not be seen as representative of the media\nin any country, nor should it be seen as perfectly\nbalanced in any specific way.\nBiases Human data annotation involves some de-\ngree of subjectivity. To mitigate this, we created\na comprehensive 60-page guidelines document,\nwhich we updated from time to time to clarify\nnewly arising important cases during the annota-\ntion process. We further had quality control steps\nteam 6L 3L 9L\nSheffieldVeraAI 0.779 0.733 0.764\nHitachi 0.768 - -\nMELODI 0.761 0.676 0.732\nUMUTeam 0.756 0.720 0.744\nDSHacker 0.735 0.690 0.720\nFTD 0.725 0.699 0.716\nQCRI 0.720 0.759 0.733\nBaseline 0.711 0.330 0.584\nSinaAI 0.688 0.645 0.673\nMaChAmp 0.672 0.577 0.641\nQUST 0.656 0.644 0.652\nFramingFreaks 0.605 0.477 0.562\nUnedMediaBiasTeam 0.516 0.540 0.524\nRiga 0.505 0.693 0.567\nE8IJS 0.158 0.121 0.146\nTable 12: Average macro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 1.\nteam 6L 3L 9L\nMarsEclipse 0.594 0.540 0.576\nSheffieldVeraAI 0.571 0.570 0.570\nQCRI 0.555 0.508 0.539\nTeamAmpa 0.554 0.522 0.543\nHitachi 0.548 - -\nmCPT 0.536 0.496 0.523\nUMUTeam 0.534 0.541 0.536\nBERTastic 0.530 0.518 0.526\nTheSyllogist 0.500 0.521 0.507\nQUST 0.486 0.366 0.446\nACCEPT 0.453 0.321 0.409\nRiga 0.444 0.430 0.439\nMaChAmp 0.438 0.330 0.402\nFTD 0.418 - -\nBaseline 0.412 0.242 0.356\nFramingFreaks 0.383 0.316 0.361\nSinaAI 0.266 0.151 0.227\nDigDemLab 0.244 - -\nTable 13: Average micro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 2.\nin the data annotation process, and we have been\nexcluding low-performing annotators. Despite all\nthis, we are aware that some degree of intrinsic\nsubjectivity will inevitably be present in the dataset\nand will eventually be learned by models trained\non it.\nAcknowledgments\nWe are greatly indebted to all the annotators from\ndifferent organisations, including, i.a., the Euro-\npean Commission, the European Parliament, the\nUniversity of Padua, and the Qatar Computing Re-\nsearch Institute, HBKU, who took part in the anno-team 6L 3L 9L\nKInITVeraAI 0.446 0.368 0.420\nTeamAmpa 0.420 0.343 0.395\nNAP 0.418 0.347 0.394\nQCRI 0.412 0.343 0.389\nSheffieldVeraAI 0.403 0.233 0.346\nAPatt 0.393 - -\nDSHacker 0.376 - -\nNLUBot101 0.376 0.236 0.329\nAPatt 0.374 0.268 0.338\nFTD 0.347 - -\nMaChAmp 0.341 0.264 0.315\nRiga 0.312 0.242 0.289\nReDASPersuasion 0.307 - -\nkb 0.294 0.182 0.256\nBaseline 0.256 0.158 0.223\nUnedMediaBias 0.255 0.171 0.227\nCLaC 0.249 0.231 0.243\nQUST 0.151 0.091 0.131\nSinaAI 0.131 0.144 0.135\nTable 14: Average micro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 3.\ntations, and notably to the language curators whose\npatience and diligence have been fundamental for\nthe quality of the dataset. We are also thankful\nto Nikolaidis Nikolaos for the preparation of the\nbaseline models and for sharing various ideas.\nPart of this work was supported by IDKT Fund\nTDF 03-1209-210013: Tanbih: Get to Know What\nYou Are Reading .\nReferences\nAhmed Al-Qarqaz and Malak Abdullah. 2023. Team\njustr00 at semeval-2023 task 3: Transformers for\nnews articles classification. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\npages 1213\u20131216, Toronto, Canada. Association for\nComputational Linguistics.\nFiroj Alam, Hamdy Mubarak, Wajdi Zaghouani, Gio-\nvanni Da San Martino, and Preslav Nakov. 2022.\nOverview of the WANLP 2022 shared task on pro-\npaganda detection in Arabic. In Proceedings of the\nSeventh Arabic Natural Language Processing Work-\nshop , Abu Dhabi, UAE.\nHamza Alami, Abdessamad Benlahbib, Abdelkader\nEl Mahdaouy, and Ismail Berrada. 2023. Um6p at\nsemeval-2023 task 3: News genre classification based\non transformers, graph convolution networks and\nnumber of sentences. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n856\u2013861, Toronto, Canada. Association for Compu-\ntational Linguistics.\nSergiu Amihaesei, Laura Cornei, and George Stoica.\n2023. Appeal for attention at semeval-2023 task 3:\nData augmentation extension strategies for detection\nof online news persuasion techniques. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 616\u2013623, Toronto, Canada. Asso-\nciation for Computational Linguistics.\nMicaela Bangerter, Giuseppe Fenza, Mariacristina\nGallo, Vincenzo Loia, Alberto V olpe, Carmen De\nMaio, and Claudio Stanzione. 2023. Unisa at\nsemeval-2023 task 3: A shap-based method for pro-\npaganda detection. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , pages\n885\u2013891, Toronto, Canada. Association for Compu-\ntational Linguistics.\nKatarzyna Baraniak and M Sydow. 2023. Kb at semeval-\n2023 task 3: On multitask hierarchical bert base neu-\nral network for multi-label persuasion techniques de-\ntection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 1395\u20131400,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAdrien Barbaresi. 2021. Trafilatura: A Web Scrap-\ning Library and Command-Line Tool for Text Dis-\ncovery and Extraction. In Proceedings of the Joint\nConference of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing: System Demonstrations , pages 122\u2013131.\nAssociation for Computational Linguistics.\nAlberto Barr\u00f3n-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nRosina Baumann and Sabrina Deisenhofer. 2023. Fram-\ningfreaks at semeval-2023 task 3: Detecting the cate-\ngory and the framing of texts as subword units with\ntraditional machine learning. In Proceedings of the\n17th International Workshop on Semantic Evalua-\ntion, pages 922\u2013926, Toronto, Canada. Association\nfor Computational Linguistics.\nFabian Billert and Stefan Conrad. 2023. Hhu at semeval-\n2023 task 3: An adapter-based approach for news\ngenre classification. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1166\u20131171, Toronto, Canada. Association for Com-\nputational Linguistics.\nDallas Card, Amber E. Boydstun, Justin H. Gross,\nPhilip Resnik, and Noah A. Smith. 2015. The Media\nFrames Corpus: Annotations of frames across issues.\nInProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and the\n7th International Joint Conference on Natural Lan-\nguage Processing , ACL-IJCNLP \u201915, pages 438\u2013444,\nBeijing, China.\nLoretta H Cheeks, Tracy L Stepien, Dara M Wald, and\nAshraf Gaffar. 2020. Discovering news frames: An\napproach for exploring text, content, and concepts inonline news sources. In Cognitive Analytics: Con-\ncepts, Methodologies, Tools, and Applications , pages\n702\u2013721. IGI Global.\nAnton Chernyavskiy, Dmitry Ilvovsky, and Preslav\nNakov. 2021. Transformers: \u201cThe end of history\u201d\nfor NLP? In Proceedings of the European Confer-\nence on Machine Learning and Principles and Prac-\ntice of Knowledge Discovery in Databases , ECML-\nPKDD\u201921.\nNelson Filipe Costa, Bryce Hamilton, and Leila Kos-\nseim. 2023. Clac at semeval-2023 task 3: Language\npotluck roberta detects online persuasion techniques\nin a multilingual setup. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1613\u20131618, Toronto, Canada. Association for Com-\nputational Linguistics.\nJuan Cuadrado, Elizabeth Martinez, Anderson Morillo,\nDaniel Pe\u00f1a, Kevin Sossa, Juan Carlos Martinez-\nSantos, and Edwin Puertas. 2023. Utb-nlp at semeval-\n2023 task 3: Weirdness, lexical features for detecting\ncategorical framings, and persuasion in online news.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 1551\u20131557, Toronto,\nCanada. Association for Computational Linguistics.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020a. SemEval-2020 task 11: Detection\nof propaganda techniques in news articles. In Pro-\nceedings of the International Workshop on Semantic\nEvaluation , SemEval \u201920, Barcelona, Spain.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and\nPreslav Nakov. 2019. Findings of the NLP4IF-2019\nshared task on fine-grained propaganda detection. In\nProceedings of the Second Workshop on Natural Lan-\nguage Processing for Internet Freedom: Censorship,\nDisinformation, and Propaganda , NLP4IF \u201919, pages\n162\u2013170, Hong Kong, China.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00f3n-Cede\u00f1o, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020b. A survey on computa-\ntional propaganda detection. In Proceedings of the\nInternational Joint Conference on Artificial Intelli-\ngence , IJCAI-PRICAI \u201920, pages 4826\u20134832.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang,\nSeunghak Yu, Alberto Barr\u00f3n-Cedeno, and Preslav\nNakov. 2020c. Prta: A system to support the analysis\nof propaganda techniques in the news. In Proceed-\nings of the 58th Annual Meeting of the Association for\nComputational Linguistics: System Demonstrations,\nACL 2020, Online, July 5-10, 2020 , pages 287\u2013293.\nAssociation for Computational Linguistics.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarron-Cedeno, Rostislav Petrov, and Preslav Nakov.\n2019. Fine-grained analysis of propaganda in news\narticles. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing ,\nEMNLP \u201919, pages 5636\u20135646, Hong Kong, China.\nNicolas Devatine, Philippe Muller, and Chlo\u00e9 Braud.\n2023. Melodi at semeval-2023 task 3: In-domain\npre-training for low-resource classification of news\narticles. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 108\u2013113,\nToronto, Canada. Association for Computational Lin-\nguistics.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021a. De-\ntecting propaganda techniques in memes. In Pro-\nceedings of the Joint Conference of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing , ACL-IJCNLP \u201921,\npages 6603\u20136617.\nDimiter Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021b. Task\n6 at SemEval-2021: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the\n15th International Workshop on Semantic Evalua-\ntion, SemEval \u201921, Bangkok, Thailand.\nRobert M Entman. 1993. Framing: Towards clarifica-\ntion of a fractured paradigm. McQuail\u2019s reader in\nmass communication theory , pages 390\u2013397.\nNeele Falk, Annerose Eichel, and Prisca Piccirilli. 2023.\nNap at semeval-2023 task 3: Is less really more?\n(back-)translation as data augmentation strategies for\ndetecting persuasion techniques. In Proceedings of\nthe 17th International Workshop on Semantic Evalua-\ntion, pages 1433\u20131446, Toronto, Canada. Association\nfor Computational Linguistics.\nJennifer Golbeck, Matthew Mauriello, Brooke Aux-\nier, Keval H. Bhanushali, Christopher Bonk, Mo-\nhamed Amine Bouzaghrane, Cody Buntain, Riya\nChanduka, Paul Cheakalos, Jennine B. Everett,\nWaleed Falak, Carl Gieringer, Jack Graney, Kelly M.\nHoffman, Lindsay Huth, Zhenya Ma, Mayanka Jha,\nMisbah Khan, Varsha Kori, Elo Lewis, George Mi-\nrano, William T. Mohn IV , Sean Mussenden, Tam-\nmie M. Nelson, Sean Mcwillie, Akshat Pant, Priya\nShetye, Rusha Shrestha, Alexandra Steinheimer,\nAditya Subramanian, and Gina Visnansky. 2018.\nFake news vs satire: A dataset and analysis. In Pro-\nceedings of the 10th ACM Conference on Web Sci-\nence, WebSci \u201918, page 17\u201321, Amsterdam, Nether-\nlands. Association for Computing Machinery.\nMaur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adali.\n2020. NELA-GT-2019: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. arXiv , 2003.08444.\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings of\nthe 2017 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations ,\nEMNLP \u201917, pages 7\u201312, Copenhagen, Denmark.Ivan Habernal, Patrick Pauli, and Iryna Gurevych. 2018.\nAdapting serious game for fallacious argumentation\nto German: Pitfalls, insights, and best practices. In\nLREC . European Language Resources Association\n(ELRA).\nMaram Hasanain, Ahmed Oumar El-Shangiti, Ra-\nbindra Nath Nandi, Preslav Nakov, and Firoj Alam.\n2023. Qcri at semeval-2023 task 3: News genre,\nframing and persuasion techniques detection using\nmultilingual models. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1237\u20131244, Toronto, Canada. Association for Com-\nputational Linguistics.\nPhilipp Heinisch, Moritz Plenz, Anette Frank, and\nPhilipp Cimiano. 2023. Accept at semeval-2023\ntask 3: An ensemble-based approach to multilingual\nframing detection. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , pages\n1347\u20131358, Toronto, Canada. Association for Com-\nputational Linguistics.\nBenjamin Horne and Sibel Adali. 2017. This just in:\nFake news packs a lot in title, uses simpler, repetitive\ncontent in text body, more similar to satire than real\nnews. arXiv , 1703.09398.\nKristina Hristakieva, Stefano Cresci, Giovanni\nDa San Martino, Mauro Conti, and Preslav Nakov.\n2022. The spread of propaganda by coordinated\ncommunities on social media. In Proceedings of the\n14th ACM Web Science Conference , WebSci \u201922,\npages 191\u2013201, Barcelona, Spain.\nTimo Hromadka, Timotej Smolen, Tomas Remis,\nBranislav Pecher, and Ivan Srba. 2023. Kinitveraai at\nsemeval-2023 task 3: Simple yet powerful multilin-\ngual fine-tuning for persuasion techniques detection.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 629\u2013637, Toronto,\nCanada. Association for Computational Linguistics.\nYe Jiang. 2023. Team qust at semeval-2023 task 3:\nA comprehensive study of monolingual and multi-\nlingual approaches for detecting online news genre,\nframing and persuasion techniques. In Proceedings\nof the 17th International Workshop on Semantic Eval-\nuation , pages 300\u2013306, Toronto, Canada. Association\nfor Computational Linguistics.\nArjun Khanchandani, Nitansh Jain, and Jatin Bedi. 2023.\nMlmodeler5 at semeval-2023 task 3: Detecting the\ncategory and the framing techniques in online news in\na multi-lingual setup. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1096\u20131101, Toronto, Canada. Association for Com-\nputational Linguistics.\nJan-Christoph Klie, Michael Bugert, Beto Boullosa,\nRichard Eckart de Castilho, and Iryna Gurevych.\n2018. The inception platform: Machine-assisted and\nknowledge-oriented interactive annotation. In Pro-\nceedings of the 27th International Conference on\nComputational Linguistics: System Demonstrations ,\npages 5\u20139. Association for Computational Linguis-\ntics. Event Title: The 27th International Conference\non Computational Linguistics (COLING 2018).\nYuta Koreeda, Ken-ichi Yokote, Hiroaki Ozaki, Atsuki\nYamaguchi, Masaya Tsunokake, and Yasuhiro So-\ngawa. 2023. Hitachi at semeval-2023 task 3: Explor-\ning cross-lingual multi-task strategies for genre and\nframing detection in online news. In Proceedings of\nthe 17th International Workshop on Semantic Evalua-\ntion, pages 1702\u20131711, Toronto, Canada. Association\nfor Computational Linguistics.\nHaewoon Kwak, Jisun An, and Yong-Yeol Ahn. 2020.\nA systematic media frame analysis of 1.5 million\nNew York Times articles from 2000 to 2017. In\nProceedings of the 12th ACM Conference on Web\nScience , WebSci \u201920, pages 305\u2013314, Southampton,\nUnited Kingdom.\nMikhail Lepekhin and Serge Sharoff. 2023. Ftd at\nsemeval-2023 task 3: News genre and propaganda de-\ntection by comparing mono- and multilingual models\nwith fine-tuning on additional data. In Proceedings of\nthe 17th International Workshop on Semantic Evalu-\nation , pages 549\u2013555, Toronto, Canada. Association\nfor Computational Linguistics.\nQisheng Liao, Meiting Lai, and Preslav Nakov. 2023.\nMarseclipse at semeval-2023 task 3: Multi-lingual\nand multi-label framing detection with contrastive\nlearning. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 83\u201387,\nToronto, Canada. Association for Computational Lin-\nguistics.\nGenglin Liu, Yi Fung, and Heng Ji. 2023. Nlubot101 at\nsemeval-2023 task 3: An augmented multilingual nli\napproach towards online news persuasion techniques\ndetection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 1636\u20131643,\nToronto, Canada. Association for Computational Lin-\nguistics.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and\nDerry Tanti Wijaya. 2019. Detecting frames in news\nheadlines and its application to analyzing news fram-\ning trends surrounding US gun violence. In Proceed-\nings of the 23rd Conference on Computational Natu-\nral Language Learning , CoNLL \u201919, pages 504\u2013514,\nHong Kong, China.\nTarek Mahmoud and Preslav Nakov. 2023. Bertastic at\nsemeval-2023 task 3: Fine-tuning pretrained multilin-\ngual transformers \u2013 does order matter? In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 58\u201363, Toronto, Canada. Associa-\ntion for Computational Linguistics.\nArkadiusz Modzelewski, Witold Sosnowski, Magdalena\nWilczynska, and Adam Wierzbicki. 2023. Dshacker\nat semeval-2023 task 3: Genres and persuasion tech-\nniques detection with multilingual data augmenta-\ntion through machine translation and text generation.\nInProceedings of the 17th International Workshopon Semantic Evaluation , pages 1582\u20131591, Toronto,\nCanada. Association for Computational Linguistics.\nOsama Mohammed Afzal and Preslav Nakov. 2023.\nTeam thesyllogist at semeval-2023 task 3: Language-\nagnostic framing detection in multi-lingual online\nnews: A zero-shot transfer approach. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 2058\u20132061, Toronto, Canada. As-\nsociation for Computational Linguistics.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021a. COVID-\n19 in Bulgarian social media: Factuality, harmfulness,\npropaganda, and framing. In Proceedings of the Inter-\nnational Conference on Recent Advances in Natural\nLanguage Processing , RANLP \u201921.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021b. A second\npandemic? Analysis of fake news about COVID-19\nvaccines in Qatar. In Proceedings of the International\nConference on Recent Advances in Natural Language\nProcessing , RANLP \u201921.\nJeppe N\u00f8rregaard, Benjamin D. Horne, and Sibel Adali.\n2019. NELA-GT-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. In Proceedings of the Thirteenth International\nConference on Web and Social Media , ICWSM \u201919,\npages 630\u2013638, Munich, Germany. AAAI Press.\nRonghao Pan, Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Miguel \u00c1n-\ngel Rodr\u00edguez-Garc\u00eda, and Rafael Valencia-Garc\u00eda.\n2023. Umuteam at semeval-2023 task 3: Multilin-\ngual transformer-based model for detecting the genre,\nthe framing, and the persuasion techniques in on-\nline news. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 609\u2013615,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAmalie Pauli, Rafael Pablos Sarabia, Leon Derczynski,\nand Ira Assent. 2023. Teamampa at semeval-2023\ntask 3: Exploring multilabel and multilingual roberta\nmodels for persuasion and framing detection. In Pro-\nceedings of the 17th International Workshop on Se-\nmantic Evaluation , pages 847\u2013855, Toronto, Canada.\nAssociation for Computational Linguistics.\nJakub Piskorski, Nicolas Stefanovitch, Valerie-Anne\nBausier, Nicolo Faggiani, Jens Linge, Sopho Kharazi,\nNikolaos Nikolaidis, Giulia Teodori, Bertrand\nDe Longueville, Brian Doherty, Jason Gonin,\nCamelia Ignat, Bonka Kotseva, Eleonora Mantica,\nLorena Marcaletti, Enrico Rossi, Alessio Spadaro,\nMarco Verile, Giovanni Da San Martino, Firoj Alam,\nand Preslav Nakov. 2023. News categorization, fram-\ning and persuasion techniques: Annotation guide-\nlines. Technical Report JRC-132862, European Com-\nmission Joint Research Centre, Ispra (Italy).\nAlbert Pritzkau. 2023. Nl4ia at semeval-2023 task 3:\nA comparison of sequence classification and token\nclassification to detect persuasive techniques. In Pro-\nceedings of the 17th International Workshop on Se-\nmantic Evaluation , pages 794\u2013799, Toronto, Canada.\nAssociation for Computational Linguistics.\nAntonio Purificato and Roberto Navigli. 2023. Apatt\nat semeval-2023 task 3: The sapienza nlp system for\nensemble-based multilingual propaganda detection.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 382\u2013388, Toronto,\nCanada. Association for Computational Linguistics.\nFatima Zahra Qachfar and Rakesh Verma. 2023.\nRedaspersuasion at semeval-2023 task 3: Persua-\nsion detection using multilingual transformers and\nlanguage agnostic features. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\npages 2124\u20132132, Toronto, Canada. Association for\nComputational Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and politi-\ncal fact-checking. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP \u201917, pages 2931\u20132937, Copenhagen,\nDenmark.\nMarkus Reiter-Haas, Alexander Ertl, Kevin Innerhofer,\nand Elisabeth Lex. 2023. mcpt at semeval-2023 task\n3: Multilingual label-aware contrastive pre-training\nof transformers for few- and zero-shot framing de-\ntection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 941\u2013949,\nToronto, Canada. Association for Computational Lin-\nguistics.\nFrancisco-Javier Rodrigo-Gin\u00e9s, Laura Plaza, and Jorge\nCarrillo-de Albornoz. 2023. Unedmediabiasteam\n@ semeval-2023 task 3: Can we detect persuasive\ntechniques transferring knowledge from media bias\ndetection? In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 787\u2013793,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAryan Sadeghi, Reza Alipour, Kamyar Taeb, Parimehr\nMorassafar, Nima Salemahim, and Ehsaneddin As-\ngari. 2023. Sinaai at semeval-2023 task 3: A multilin-\ngual transformer language model-based approach for\nthe detection of news genre, framing and persuasion\ntechniques. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 2168\u20132173,\nToronto, Canada. Association for Computational Lin-\nguistics.\nBen Wu, Olesya Razuvayevskaya, Freddy Heppell,\nJo\u00e3o Leite, Carolina Scarton, Kalina Bontcheva, and\nXingyi Song. 2023. Sheffieldveraai at semeval-2023\ntask 3: Mono and multilingual approaches for news\ngenre, topic and persuasion technique classification.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 1995\u20132008, Toronto,\nCanada. Association for Computational Linguistics.Seunghak Yu, Giovanni Da San Martino, Mitra Mo-\nhtarami, James Glass, and Preslav Nakov. 2021. In-\nterpretable propaganda detection in news articles.\nInProceedings of the International Conference on\nRecent Advances in Natural Language Processing ,\nRANLP \u201921, pages 1597\u20131605.\nYifan Zhang, Giovanni Da San Martino, Alberto Barr\u00f3n-\nCede\u00f1o, Salvatore Romeo, Jisun An, Haewoon Kwak,\nTodor Staykovski, Israa Jaradat, Georgi Karadzhov,\nRamy Baly, Kareem Darwish, James Glass, and\nPreslav Nakov. 2019. Tanbih: Get to know what\nyou are reading. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on\nNatural Language Processing: System Demonstra-\ntions , EMNLP-IJCNLP \u201919, pages 223\u2013228, Hong\nKong, China.\nA Supplementary Corpus Information\nA.1 Statistics\nThis section contains additional statistical informa-\ntion related to the corpus.\nTable 15 provides the statistics for genre for all\nlanguages. One can observe that opinion andsatire\nare the most and least populated classes across the\nlanguages respectively.\nAnalogously, Table 16 shows the number of dif-\nferent framing dimensions per language. Political\nandSecurity and Defense framings constitute the\ntwo most frequent ones across all languages. The\ndistribution of the different framings varies across\nthe languages though.\nFinally, Table 17 reports the exact count of fine-\ngrained persuasion techniques per language for\nthe entire dataset. The two most frequent tech-\nniques irrespective of the language are Loaded\nLanguage andName Calling-Labelling , which ac-\ncount for 18.5% and 23.7% of the dataset, trump-\ning by several order of magnitude the lower popu-\nlated classes. They are followed by Casting Doubt\n(12.5%), Questioning the Reputation (7.6%), Ap-\npeal to Fear-Prejudice (4.8%), and Exageration-\nMinimisation (4.7%). These six classes together\nrepresent 71.8% of the entire dataset.\nB Participant Systems\nIn the following we list the systems of all partic-\nipants who submitted a system description paper.\nThe team name used for the submission is in bold;\nin case the team used a different name on the leader-\nboard, it is appended in parentheses; the list of sub-\ntasks the team participated in is also given in brack-\nets; in case the team was ranked first for at least\nopinion reporting satire\nEnglish 434 112 24\nFrench 175 65 21\nGerman 148 48 31\nItalian 274 72 18\nPolish 174 44 23\nRussian 170 73 20\nGeorgian 19 10 0\nGreek 39 22 3\nSpanish 14 9 7\nALL 1447 455 147\nTable 15: Statistics for the genre labels for all languages\nand the entire dataset.\na subtask-language pair, the list of all such pairs\nwhere it is ranked first is given; a list of keywords;\nand finally, a short description of the system.\nACCEPT [ST2] (Heinisch et al., 2023) (Key-\nwords: XLM-RoBERTa, ConceptNet ) They used an\nensemble combining XLM-RoBERTa with static\nmultilingual and monolingual word embeddings;\nfor the latter, they translated the non-English-texts\nto English using Google Translate. They further\nexperimented with external common sense knowl-\nedge graphs, specifically ConceptNet.\nAPatt [ST3] (Purificato and Navigli, 2023) (first\nfor: ST3:EN) (Keywords: XLNet, RoBERTa, BERT,\nALBERT, DeBERTa ) They used an ensemble of\npre-trained language models fine-tuned on the pro-\npaganda dataset: BERT, RoBERTa, ALBERT, XL-\nNet, DistilBERT, and HerBERT. Whenever more\nLLMs for the same language were available, their\noutput is combined through a weighted average.\nAppeal for attention (AppealForAtt) [ST3]\n(Amihaesei et al., 2023) (Keywords: XLM-\nRoBERTa-Large, WordNet, data augmentation )\nThey focused on data augmentation techniques.\nThey translated the datasets from each language\ninto all other languages using the DeepTranslator\nAPI, and they extracted synonyms from WordNet\nto generate new sentences. Finally, they trained\nXLM-RoBERTa-large on that augmented data.\nBERTastic [ST2] (Mahmoud and Nakov, 2023)\n(Keywords: mBERT, XLM-RoBERTa ) They used\ncross-lingual transformers, mBERT and XLM-\nRoBERTa, using different orderings of the lan-\nguages when doing fine-tuning. They further used\ntest data augmentation via translation of both the\ntraining and the test sets.\nCLaC (CLAC) [ST3] (Costa et al., 2023) (Key-\nwords) RoBERTa augmented the dataset translat-\ning examples from other languages, focusing on\narticles having least represented techniques in orderto balance the dataset. They used a RoBERTa-base\nmodel trained on the English language and made\npredictions on the other languages by first trans-\nlating the text into English. They report better F 1\nscores with such approach on French and German\nthan using Large Language Models trained directly\non the target language.\nDSHacker [ST1, ST3] (Modzelewski\net al., 2023) (first for: ST1:ES) (Keywords:\nXLMRoBERTa-large, GPT3-Davinci, sequence\nclassification, text generation, Ensemble Learning,\nXGBoost, Logistic Regression, LightGBM, BERT,\nData Augmentation, Summarization ) created,\nfor ST1, synthetic texts for each class using the\nOpenAI GPT-3 Davinci language model. Each\nlanguage was augmented by approximately 500\narticles per genre, producing roughly 13,500\nartificially generated articles. Single XLM-\nRoBERTa-large model was trained using the\noriginal and augmented data. For ST3 they\ndeveloped for Polish an ensemble consisting of\nthree one-vs-rest classifiers: eXtreme Gradient\nBoosting, Logistic Regression and Light Gradient-\nBoosting Machine with HerBERT embeddings\nand various stylometric features using StyloMetrix\nlibrary. For all other languages BERT-based\npre-trained models were deployed and they used\nsummarization applied to longer paragraphs.\nFurthermore, training data was augmented through\nmachine translation utilizing the DeepL API.\nFramingFreaks [ST1, ST2] (Baumann and\nDeisenhofer, 2023) (Keywords: SVM, Logistic Re-\ngression ) classified texts by splitting them into sub-\nwords and then using these tokens as input to a\nSupport Vector Machines for ST1 and to Logistic\nregression for ST2.\nFTD [ST1, ST2, ST3] (Lepekhin and Sharoff,\n2023) (first for: ST1:PL) (Keywords: SLM-\nRoBERTa, multilingual BERT, Electra, monolin-\ngual BERT-based models, fine-tuning, uncertainty\nestimation, ensembles ) focused on ST1, where they\nexperimented with monolingual and multilingual\nmodels, ensembles, additional data, and uncertainty\nestimation. For Russian and English, they fine-\ntuned models pre-trained on the FTD dataset for\ngenre classification. For English, they added 1,000\nreporting texts from Gigaword. For Polish and Ger-\nman, their best results were achieved by fine-tuning\na monolingual Polish BERT and a monolingual\nGerman Electra, respectively. For the other lan-\nguages, their best systems used multilingual BERT,\nFraming English French German Italian Polish Russian Georgian Greek Spanish ALL\nCapacity and resources 56 62 104 120 88 34 1 10 11 486\nCrime and punishment 274 22 44 57 57 51 3 11 4 523\nCultural identity 42 34 46 43 48 13 1 8 0 235\nEconomic 74 79 108 142 144 68 2 14 4 635\nExternal regulation and reputation 214 85 91 132 86 44 9 9 3 673\nFairness and equality 131 30 35 52 39 21 0 8 2 318\nHealth and safety 86 60 107 97 144 37 4 8 3 546\nLegality, Constitutionality, jurisprudence 281 41 65 73 56 44 0 23 7 590\nMorality 231 62 39 62 63 31 2 5 7 502\nPolicy prescription and evaluation 154 38 70 129 110 15 2 12 7 537\nPolitical 343 108 130 178 144 55 10 43 6 1017\nPublic opinion 68 34 50 58 74 22 4 10 3 323\nQuality of life 115 40 53 89 85 32 0 5 3 422\nSecurity and defense 222 89 121 155 105 90 10 19 10 821\nTable 16: Statistics for the framing labels for all languages and the entire dataset.\nPersuasion technique English French German Italian Polish Russian Georgian Greek Spanish ALL\nName Calling-Labeling 1,945 903 2,818 1,470 1,391 483 42 37 42 9,131\nGuilt by Association 84 210 216 98 234 59 4 8 12 925\nDoubt 887 679 606 2,295 574 957 40 129 37 6,204\nAppeal to Hypocrisy 82 220 307 149 329 167 1 77 14 1,346\nQuestioning the Reputation 162 662 837 819 555 598 23 35 66 3,757\nFlag Waving 434 87 100 72 176 152 3 19 6 1,049\nAppeal to Values 47 219 163 264 246 93 6 26 14 1,078\nAppeal to Popularity 76 149 119 79 86 38 0 7 11 565\nAppeal to Fear-Prejudice 554 443 339 589 245 135 1 12 41 2,359\nAppeal to Authority 207 175 377 118 133 22 2 5 6 1,045\nCausal Oversimplification 265 228 62 88 22 65 2 29 9 770\nFalse Dilemma, No Choice 241 169 55 149 28 59 2 10 22 735\nConsequential Oversimplification 21 215 50 53 47 110 8 33 7 544\nStrawman 64 242 27 111 25 46 2 13 6 536\nRed Herring 97 72 52 48 23 6 10 19 4 331\nWhataboutism 25 93 33 11 22 17 0 13 7 221\nConversation Killer 176 352 235 468 126 172 12 24 26 1,591\nSlogans 234 230 176 122 64 113 3 15 16 973\nAppeal to Time 4 71 33 53 24 41 0 3 8 237\nLoaded Language 3,467 2,533 604 2,878 654 1,347 26 88 134 11,731\nObfuscation-Vagueness-Confusion 37 185 108 42 66 62 6 34 9 549\nExaggeration-Minimisation 730 527 307 261 197 225 5 37 35 2,324\nRepetition 938 198 17 75 48 115 20 18 14 1,443\nTable 17: Statistics for the fine-grained persuasion techniques for all languages and the entire dataset.\nXLM-RoBERTa, or ensembles thereof. In all cases,\nthey truncated the input to the first 510 tokens.\nThey further upsampled the data to balance the\ndistribution between the classes (the results with-\nout upsampling were low). For English they fur-\nther, experimented with uncertainty estimation, and\nshowed that replacing the model predictions that\nhave high uncertainty with the majority class on the\ntraining data was helpful on the dev set. For ST2,\nfor each language, they used the model and the\nsetup that worked best for ST1, and just retrained\nit on the ST2 data.\nHHU [ST1] (Billert and Conrad, 2023): (Key-\nwords: XLM-RoBERTa, Adapters, AdapterFusion )\nused an Adapter-based configuration: Using XLM-RoBERTa as a base, they stacked first a language-\nspecific adapter and then a task-specific adapter on\ntop of it. Moreover, they augmented each dataset\nby translating the articles from the datasets in the\nother languages.\nHitachi [ST1, ST2] (Koreeda et al., 2023) (first\nfor: ST1:IT, ST1:RU) (Keywords: XLM-RoBERTa,\nRoBERTa ) augmented the dataset for ST1 by col-\nlecting labelled examples from similar datasets.\nThey pretrained (XLM-)RoBERTa in multi-task\n(one language, ST1 and ST2), multilingual (one\nsubtask, all languages) and multilingual multi-task\n(ST1 and ST2 in all languages) settings. Besides\nusing the single models, they report experiments\nwith ensemble of base models with different hyper-\nparameters.\nJUSTR00 [ST1, ST2] (Al-Qarqaz and Abdullah,\n2023): (Keywords: LongFormer, BERT, RoBERTa,\nmBERT, XLM-RoBERTa, BigBird experimented\nwith many state-of-the-art transformer-based lan-\nguage models, both monolingual and multilingual.\nTheir top performing model is based on a trans-\nformer called \u201cLongformer\u201d.\nkb[ST1, ST3] (Baraniak and Sydow, 2023)\n(Keywords: BERT, Bert, hierarchical learning,\nmultitask learning ) tackled ST3 by training a BERT\nmodel to identify the start of a text fragment with a\ntechnique, then the first index of predicted span was\nused to get the BERT embedding for classification.\nKInITVeraAI (KInIT) [ST3] (Hromadka et al.,\n2023): (first for: ST3:IT, ST3:RU, ST3:DE,\nST3:PL, ST3:EL, ST3:KA) (Keywords: XLM-\nRoBERTa large and base, mBERT base, monolin-\ngual RoBERTa base and large, monolingual BERT\nbase, distilBERT, language model fine-tuning with\ndifferent layer freezing strategies ) used a fine-tuned\nXLM-RoBERTa-large transformer model trained\non all the input data. They carefully adjusted the\nprediction threshold for each language using a prin-\ncipled approach. They truncated the input, and also\nfound that pre-processing did not impact the quality\nmuch.\nMarsEclipse [ST2] (Liao et al., 2023): (first for:\nST2:IT, ST2:RU, ST2:FR, ST2:DE, ST2:PL) (Key-\nwords: XLM-RoBERTa, mBERT, SimCSE, Sim-\nCLR) used a multi-label contrastive loss for fine-\ntuning pre-trained language models in a multi-\nlingual setting. They followed the general archi-\ntecture of SimCLR and SimCSE to do contrastive\nlearning, but modified the contrastive loss to make\nit fit for a multi-label setup. This yielded very com-\npetitive results for ST2, and this was the winning\nsystem for five of the languages.\nmCPT (PolarIce) [ST2] (Reiter-Haas et al.,\n2023) (first for: ST2:ES) (Keywords: paraphrase-\nmultilingual-MiniLM-L12-v2, contrastive pre-\ntraining ) used a two-phase training procedure of a\ntransformer model, first by pre-training jointly on\nall the languages and then by fine-tuning for each\nlanguage. In both phases, a multi-label contrastive\nloss was used.\nMELODI [ST1] (Devatine et al., 2023): (first\nfor: ST1:EN) (Keywords: Translation + POLI-\nTICS (RoBERTa) ) fine-tuned the domain-specific\nlanguage model trained on English data, POLI-\nTICS, on the English input articles and on the arti-cles in all other languages automatically translated.\nIn addition, in order to use whole articles as input,\nthey used a sliding window approach and aggre-\ngated each window representation with mean pool-\ning. They also tested other multilingual approaches,\nsuch as XLM-RoBERTa, and approaches able to\nprocess long documents (Longformer), which were\nin general less effective.\nMLModeler5 [ST1, ST2] (Khanchandani et al.,\n2023) (Keywords: RoBERTa, ALBERT ) provided a\nsolution for English only. For ST1 they pre-trained\nthe RoBERTa, ALBERT and other deep learning\nmodels using the original training data in English\nand translated versions of the data in other lan-\nguages and performed NLP augmentation using\nNLPAUG library on it. For ST2 a similar-in-nature\napproach was used.\nNAP [ST3] (Falk et al., 2023) (first for: ST3:FR)\n(Keywords: XLM-RoBERTa (base and large),\nsetfit, adapters, translation and backtranslation\nof paragraphs ) presented an approach combin-\ning predictions of several models in an ensem-\nble, which differ in three main aspects: a) train-\ning data, b) model architecture, and c) input\nformat to the model. They leveraged (back-\n)translation as data augmentation strategies using\navailable MarianMT models. Model architectures\nincluded XLM-RoBERTa models, Adapters, SetFit,\nand linguistically-informed heuristics for under-\nrepresented techniques which were fine-tuned on\ndifferent combinations of original and augmented\ndata. They fine-tuned models on both paragraph-\nand span-level information.\nNL4IA [ST3] (Pritzkau, 2023) (Keywords:\nRoBERTa ) used RoBERTa and exploited the span\nlevel annotations framing ST3 as a token-level clas-\nsification one, but report better results when treat-\ning the subtask as a sequence classification one.\nNLUBot101 [ST1,ST3] (Liu et al., 2023) (Key-\nwords: mDeBERTa ) built, for ST3, a solution on\ntop of mDeBERTa NLI model and exploit cross-\nlingual data augmentation. The performance could\nbe improved through the exploitation of the ex-\npanded definitions of the persuasion technique\nguidelines from the official annotation guidelines\nvis-a-vis the usage of single words or phrases.\nTheir system achieved the highest macro F1score\nfor the English language.\nQCRI (QCRITeam) [ST1, ST2, ST3] (Hasanain\net al., 2023) (Keywords: XLM-RoBERTa, French\nEuropeana BERT, Gottbert-base, Italian BERT,\nHerBERT ) used, for all subtasks, data augmenta-\ntion and then fine-tuned a BERT model specifically\nfor each language, in addition to fine-tuning XLM-\nRoBERTa on all languages at once.\nQUST [ST1,ST2,ST3] (Jiang, 2023): (Key-\nwords) XLM-RoBERTa Their model is build on top\nof XLM-RoBERTa, which is fine-tuned with the\npre-calculated class weights and sample weights\nto combat the imbalanced data. The class weights\nare multiplied by the loss to make the model focus\nmore on the minority class. The sample weights are\ncombined with a weighted sampler to resample the\ndistribution of the training batch. In addition, two\ntypes of fine-tuning strategies, the task-agnostic\nand the task-dependent, where the latter proved\nto help the multilingual model to learn the shared\ninformation between subtasks. The submitted sys-\ntem achieves the second best result for Italian and\nSpanish (zero-shot) in ST1.\nReDASPersuasion [ST3] (Qachfar and Verma,\n2023) (Keywords: XLM-RoBERTa ) uses XLM-\nRoBERTa as a backbone model, incorporating lan-\nguage agnostic features, computed over the articles\ntranslated using Google translation. Such features\ntarget specific techniques, including sentiment- and\npolarity- based features targeting appeal to fear and\nslogans, indefinite pronouns indicative of exagger-\nation and minimisation, a profanity language detec-\ntion to capture loaded language. XLM-RoBERTa\nhas been proved to be a powerful multilingual pre-\ntrained language model compared against other\nmodels like Multilingual BERT (M-BERT).\nSheffieldVeraAI (vera) [ST1, ST2, ST3] (Wu\net al., 2023) (first for: ST1: DE, ST2:EN, ST2:EL,\nST2:KA) (Keywords: mBERT, adapters, text pre-\nprocessing, upsampling, XLM-Roberta, Pfeiffer\nAdapters, MUPPET, Task-adaptive Pre-training,\nRoBERTa, class weighting ) deployed an ensem-\nble of three fine-tuned mBERT models and one\nmBERT model with a bottleneck adapter for ST1.\nAll used bert-base-multilingual-cased. For the fine-\ntuned mBERT models, they pre-processed the data\nby filtering out non-informative sentences. The\npool of training data was also extended by integra-\ntion additional \u201csatire\u201d resources for English. In\nthe cases where the length of the tokenised arti-\ncle was more than 512 tokens, an equal number of\nsentences from the beginning and the end of the\narticle was selected until the size of 512 tokens in a\nconcatenated text is reached. The final predictions\nwere drawn as a majority-voting predicted classFor ST2 they used two different ensembles of\nMUPPET large, and of XLM-R with adapters\nand task-adaptive MLM pre-training on the\ntrain+dev+test data. Their data was pre-processed\nand truncated. The models were trained both with\nand without class weighting.\nFor ST3 they trained a monolingual RoBERTa-\nBase model for English and a multilingual mBERT-\ncased model for the remaining languages. They\nused class weighting to account for class imbal-\nance. They also experimented with augmenting\ndata through translation, which improved the per-\nformance for the surprise languages.\nSinaAI (SinaaAI) [ST1, ST2, ST3] (Sadeghi\net al., 2023) (first for: ST1:EL) (Keywords: XLM,\nmBERT, LaBSE ) used multilingual languages mod-\nels such as XLM, mBERT and LaBSE, which they\ncombined in an ensemble. For ST1 and ST2, they\nfurther used data augmentation by selecting 30%\nof the sentences of each document to create new\nsynthetic examples.\nTeamAmpa [ST2, ST3] (Pauli et al., 2023) (first\nfor: ST3:ES) (Keywords: RoBERTa, XML-R, en-\nsemble models) used different oversampling strate-\ngies, data truncation, and multilingual and mono-\nlingually trained models, combined in an ensem-\nble for the English data. The surprise languages\nwere handled using the multilingual model with\noversampling on English data and data from low-\nrepresented classes.\nTheSyllogist [ST2] (Mohammed Afzal and\nNakov, 2023): (Keywords: BERT ) participated\nin ST2, and experimented with zero-shot transfer:\ntranslating the data for all languages into English\n(using Google Translate), and then training and ap-\nplying an English system. They used fine-tuned\nBERT (bert-base-uncased) with mean-pooling.\nUM6P [ST1, ST3] (Alami et al., 2023): (Key-\nwords: Longformer, RoBERTa, GCN ) fine-tuned\nLongformer and RoBERTa transformers for both\nST1 and ST3. They further added a graph convolu-\ntion network, and a classifier based on the number\nof sentences in each document. Finally, they used\nan ensemble to combine the predictions of these\nmodels.\nUMUTeam [ST1, ST2] (Pan et al., 2023) (first\nfor: ST1:FR, ST1:DE) (Keywords: Sentence\ntransformers, XML-RoBERTa ) used a multilingual\nmodel based on XML-RoBERTa, which they fine-\ntuned on all languages at once and a sentence trans-\nformer to extract the most important chunk of text\nfor ST1 and ST2. They further truncated the input\ndata to 200 tokens with 50 tokens of overlap using\nthe sentence-transformer model to obtain the subset\nof text most related to the article title.\nUnedMediaBiasTeam [ST1, ST3] (Rodrigo-\nGin\u00e9s et al., 2023) (Keywords: XLM-RoBERTa,\nbert-base-multilingual-cased ) solutions are based\non two-stage fine-tuned multilingual models. For\nST1 they exploit the media bias detection datasets\ncalled BABE and MBIC and XLM-RoBERTa\nmodel fine-tuned in two stages: first with the BABE\nand MBIC datasets, and later with the data pro-\nvided for the task. For ST3 a similar approach is\ndeployed, where instead of training a single model\nin two phases, two models are trained and the cas-\ncading inference is carried out.\nUnisa [ST1, ST3] (Bangerter et al., 2023) (Key-\nwords: DistilBert, SHAP ) built solutions on top\nof DistilBert and leverage the application of the\neXplainable Artificial Intelligence (XAI) method,\nShapley Additive Explanations (SHAP). In ST1,\ndata augmentation was exploited through transla-\ntion data to the target language (English) on top\nof which the model was trained with only the first\n512 tokens of the articles being considered as input\nto the model. SHAP was used to understand what\nwas driving the model to fail so that it could be\nimproved.\nIn ST3, a re-calibration of the Attention Mech-\nanism is realized by extracting critical tokens for\neach technique. XAI is exploited for countering the\noverfitting of the resulting model and attempting to\nimprove the performance when there are few train-\ning samples. First, a binary model first processes\na new incoming paragraph to predict whether it\ncontains any persuasion attempt. If the text is pre-\ndicted to be propaganda, it is compared with SHAP\nV ocabularies previously created, which represent\nthe most important words associated with each per-\nsuasion technique. Such comparison defines the ad-\nditional input to pass to the final multi-class model\ntrained to focus on the span that identifies the text\nthat characterizes the persuasion technique.\nUTB-NLP (UTBNLP) [ST1, ST2] (Cuadrado\net al., 2023) (Keywords: ) used a feature-based\nrepresentation: they extracted noun phrases and\nrepresented them as tf-idf vectors; they consid-\nered several features specific for each of the three\nclasses of ST1, such as psycholinguistic, writing\nstyle, readability, structural characteristics, concep-\ntual embeddings and argumentation-based features.In addition, they used SMOTE to oversample the\nminority classes.\nST2 was tackled by collecting extra texts from\nWikipedia related to the frames, pre-processing\nthem to create a frame-related lexicon and then to\nuse it to create a bag-of-words representation for\neach input article.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Semeval-2023 task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multi-lingual setup", "author": ["J Piskorski", "N Stefanovitch"], "pub_year": "2023", "venue": "Proceedings of the \u2026", "abstract": "We describe SemEval-2023 task 3 on Detecting the Category, the Framing, and the Persuasion  Techniques in Online News in a Multilingual Setup: the dataset, the task organization"}, "filled": false, "gsrank": 639, "pub_url": "https://aclanthology.org/2023.semeval-1.317/", "author_id": ["xDQ3yuQAAAAJ", "Tqg6X5cAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:A5KuPzxp7dIJ:scholar.google.com/&output=cite&scirp=638&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D630%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=A5KuPzxp7dIJ&ei=eLWsaIbeMOHUieoP9LKZ6AI&json=", "num_citations": 144, "citedby_url": "/scholar?cites=15198920024932651523&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:A5KuPzxp7dIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2023.semeval-1.317.pdf"}}, {"title": "A Mixed Model for Identifying Fake News in Tweets from the 2020 US Presidential Election.", "year": "2021", "pdf_data": "A Mixed Model for Identifying Fake News in Tweets from the 2020 U.S.\nPresidential Election\nV\u00b4\u0131tor Bernardes1\naand \u00b4Alvaro Figueira2\nb\n1Faculty of Sciences, University of Porto, Rua do Campo Alegre, Porto, Portugal\n2CRACS / INESCTEC, University of Porto, Porto, Portugal\nKeywords: Fake News, Social Media, Machine Learning, NLP.\nAbstract: The recent proliferation of so called \u201cfake news\u201d content, assisted by the widespread use of social media plat-\nforms and with serious real-world impacts, makes it imperative to \ufb01nd ways to mitigate this problem. In this\npaper we propose a machine learning-based approach to tackle it by automatically identifying tweets asso-\nciated with questionable content, using newly-collected data from Twitter about the 2020 U.S. presidential\nelection. To create a sizable annotated data set, we use an automatic labeling process based on the factual\nreporting level of links contained in tweets, as classi\ufb01ed by human experts. We derive relevant features from\nthat data and investigate the speci\ufb01c contribution of features derived from named entity and emotion recogni-\ntion techniques, including a novel approach using sequences of prevalent emotions. We conclude the paper by\nevaluating and comparing the performance of several machine learning models on different test sets, and show\nthey are applicable to addressing the issue of fake news dissemination.\n1 INTRODUCTION\nThe issue of fake news is by no means recent, with\naccounts of lies, propaganda and misinformation at\nleast as old as 3,000 years ago (Weir, 2009). Fake\nnews can be broadly de\ufb01ned as misleading informa-\ntion presented as news. It has also been used to denote\nany kind of misinformation, often published with the\ngoal of promoting a political or personal agenda, or\nfor \ufb01nancial gain through advertising revenues (Sam-\nple et al., 2019).\nThe recent surge in the use of the term \u201cfake news\u201d\nhas been attributed to former U.S. president Donald\nTrump, who popularized the term during the 2016\nelection campaign, though, when he did so, he often\nreferred to negative press coverage of himself. Since\nthen, we have seen the proliferation of websites dedi-\ncated to publishing false or misleading information,\nwhich are also replicated by users or bots on sev-\neral different social media platforms. These platforms\nthemselves play a signi\ufb01cant part in spreading these\narticles due to their algorithms which are in many\ncases optimized for maximizing user engagement.\nFake news have a number of de\ufb01ning attributes\na\nhttps://orcid.org/0000-0002-5142-3818\nb\nhttps://orcid.org/0000-0002-0507-7504that can be leveraged when trying to \ufb01nd solutions\nto the problem of their dissemination. The \ufb01rst is, of\ncourse, that they must present inaccurate information,\nwhich can range from a small imprecision to a com-\nplete fabrication. Another attribute of fake news con-\ntent is its appeal to emotions, exploiting existing prej-\nudices or biases in the reader to elicit a strong emo-\ntional response (Sample et al., 2019). That can be ac-\ncomplished in a number of ways, from using captivat-\ning pictures to employing linguistic features, such as\nexcessive use of adverbs. Fake news is also optimized\nfor sharing, and often spread in short bursts (Shu\net al., 2020) at a higher diffusion rate than real news\nonce they become viral (Guimar \u02dcaes et al., 2021a).\nThe deluge of information conveyed on social net-\nworks makes it increasingly hard and in many cases\ninfeasible for an individual to verify sources and con-\n\ufb01rm content reliability, creating an opportunity to em-\nploy automated methods to assist in that task. Even\nthough a purely mechanical solution to this problem\nis not likely to completely eliminate it, any tool that\ncan aid readers in distinguishing between legitimate\ncontent and misinformation can help mitigate the is-\nsue. To that end, this research has a number of related\ncontributions. One is creating an annotated data set of\nfake news and legitimate content from Twitter, with\nattributes for each tweet. We also implement differ-Bernardes, V. and Figueira, \u00c1.\nA Mixed Model for Identifying Fake News in Tweets from the 2020 U.S. Presidential Election.\nDOI: 10.5220/0010660500003058\nInProceedings of the 17th International Conference on Web Information Systems and Technologies (WEBIST 2021) , pages 307-315\nISBN: 978-989-758-536-4; ISSN: 2184-3252\nCopyright c/circlecopyrt2021 by SCITEPRESS \u2013 Science and Technology Publications, Lda. All rights reserved307\n\nent machine learning models for automatically iden-\ntifying tweets associated with fake content, and com-\npare and discuss their results. Finally, we investigate\nthe enhancement provided by features derived from\nnamed entities and emotion recognition in the auto-\nmatic identi\ufb01cation of fake news, and demonstrate\ntheir applicability to help address that issue.\nFor the sake of brevity and consistency, we use\nthe term \u201cfake tweets\u201d to denote tweets that are as-\nsociated with misleading or unreliable content, while\nthe term \u201cnon-fake tweets\u201d denotes tweets associated\nwith reliable content.\n2 THE DATA\nSince the U.S. elections are an event with global im-\nplications, we expected there would be many exam-\nples of fake news dissemination around it, as was the\ncase with the 2016 presidential election. Furthermore,\nthe volume of fake news posts tends to increase during\nelections (Guimar \u02dcaes et al., 2021a). For that reason,\nwe opted to use the 2020 U.S. presidential elections as\na case study, speci\ufb01cally with data posted on Twitter.\n2.1 Data Collection\nThe data were collected in two different phases and\napproaches. First, we used keywords and select ac-\ncounts (from the main candidates and their parties)\nto collect data over a period of around three months,\nfrom late September to late December in 2020, which\namounted to 21,675,705 unique tweets. That ap-\nproach allowed us to gather data during the campaign,\nthrough the voting period, and after the results were\ncerti\ufb01ed. In order to test the generalization of our re-\nsults, we also collected tweets during May 2021. For\nthe second collection we did not use keywords, col-\nlecting instead tweets from four reputable U.S. and\nU.K. news sources and from three accounts known for\npublishing fake news content. This was done to verify\nhow well our solution was able to generalize to tweets\ngathered in another context, and with potentially dif-\nferent content. The two reputable U.S. sources se-\nlected were The New York Times and the Washing-\nton Post1, the two most frequent sources on the 2020\ndata set. No U.K. news outlets \ufb01gured among the\nmost frequent sources. The Financial Times and The\nEconomist were chosen due to their factual reputation\nand focus on economic and business issues, enabling\n1Since the initial data collection and labeling, the Wash-\nington Post\u2019s factual reporting level from MBFC was re-\nduced from \u201chigh\u201d to \u201cmostly factual\u201d due to 2 recent failed\nfact-checks.us to verify model applicability beyond its original\ncontext. The questionable outlets picked were the\nthree most frequent sources of fake news from the\n2020 data set, namely The Gateway Pundit (by it-\nself accounting for 48% of all fake news shared in\nthat data set), The Daily Mail (U.K.), and National\nFile. The Gateway Pundit is a popular website known\nfor publishing false information and conspiracy theo-\nries. It features in lists of fake news websites, such\nas OpenSources2and PolitiFact3, and its founder\u2019s\naccount was suspended by Twitter on February 6,\n2021 due to posting misinformation about the 2020\nU.S. presidential election. The Daily Mail is an es-\ntablished British tabloid, with the highest circulation\namong daily newspapers in the United Kingdom. It\nhas been criticized for publishing sensationalist and\ninaccurate information, and has been banned as an un-\nreliable source by Wikipedia. National File is a web-\nsite founded in 2019 that reports conspiracy and pseu-\ndoscience stories4. Its collaborators have been associ-\nated with several known fake news websites, such as\nBreitbart, InfoWars, and The Gateway Pundit.\n2.2 Data Preparation\nSince this research involved performing several nat-\nural language processing (NLP) tasks to identify lin-\nguistics attributes on tweet content, we selected only\ntweets written in English. We also \ufb01ltered for a min-\nimum length of 100 characters or 20 words, values\nclose to the median values from the initial collection.\nAfter applying these conditions, the data set was re-\nduced from 21,675,705 to 13,060,234 tweets.\nWe also performed sentiment analysis on\nthe tweets using three different Python libraries:\nTextBlob (Loria, 2018), V ADER (Hutto and Gilbert,\n2014), and Stanza (Qi et al., 2020). TextBlob is an\nNLP library that provides a simple API for ease of\nuse, V ADER is a sentiment analysis tool speci\ufb01cally\nattuned to sentiments from social media posts, and\nstanza is an NLP library maintained by the Stanford\nNLP Group, with state-of-the-art accuracy on several\nNLP tasks and trained on data sets including Twitter\nposts for sentiment analysis.\nOne of the most elementary tasks in sentiment\nanalysis is classifying the polarity of a given piece of\ntext. Polarity is a measure that represents the senti-\nment of a piece of text, and ranges from negative, to\nneutral, to positive. TextBlob and V ADER provide a\ncompound score, from -1 to 1, indicating how nega-\n2https://github.com/OpenSourcesGroup/opensources\n3https://infogram.com/politifacts-fake-news-almanac-\n1gew2vjdxl912nj\n4https://mediabiasfactcheck.com/national-\ufb01leWEBIST 2021 - 17th International Conference on Web Information Systems and Technologies\n308\n\ntive or how positive the input text is. In order to stan-\ndardize the classi\ufb01cation of positive, neutral, and neg-\native text, we used typical threshold values (Hutto and\nGilbert, 2014): a polarity greater than or equal to 0.05\nindicates positive text and a polarity less than or equal\nto -0.05 indicates negative text, while values between\n-0.05 and 0.05 indicate neutral text.\nThe result of the sentiment analysis was uneven,\nwith only 24.9% of tweets classi\ufb01ed the same by all\nlibraries. Thus, to ensure consistency and to pro-\nvide security that sentiment-based features would re-\n\ufb02ect the actual meaning contained in tweets, the 2020\ndata set was \ufb01ltered to tweets where the same polarity\ncategory was identi\ufb01ed by all three libraries, leaving\n3,252,751 tweets in the data set.\n2.3 Data Labeling\nOne of the major challenges faced when dealing with\nthe fake news problem is obtaining a sizable anno-\ntated data set. Some annotated data sets have been\npublished, for different platforms, but not many use\ndata from Twitter. They are undoubtedly useful tools\nbut many are limited in a number of ways. The\nPHEME rumor data set (Zubiaga et al., 2016) con-\ntains Twitter data annotated by journalists, however it\nis relatively small (4,842 tweets in total) and focused\non rumors, not fake news. CREDBANK (Mitra and\nGilbert, 2015) is a collection of around 60 million\ntweets from October 2014 to February 2015, manu-\nally annotated via Amazon Mechanical Turk. Those\ntweets were grouped into events, which were then an-\nnotated with the aim of assessing general event cred-\nibility, not \ufb01ne-grained tweets associated with fake\nnews content. FakeNewsNet (Shu et al., 2020) was\ncreated in 2018 as an attempt to consolidate fake news\ncontent, and the social context and spatiotemporal in-\nformation of users sharing this content. It uses an au-\ntomatic process for extracting fake news stories based\non rankings by fact-checking websites PolitiFact and\nGossipCop, and obtaining the Twitter posts associated\nwith these stories. However, due to tweet decay, as of\nNovember 2019, only 33% of news stories from Gos-\nsipCop still had related tweet data available5.\nThe \u201cdata set decay problem\u201d, described above,\nis a common challenge to be faced in this \ufb01eld of\nstudy. Tweets are removed over time, either by their\nown authors or, more recently, by Twitter in its efforts\nto counter the spread of fake news and misuse of its\nplatform6. Since Twitter terms of service restrict the\n5https://github.com/KaiDMML/FakeNewsNet/issues/37\n6https://help.twitter.com/en/rules-and-\npolicies/platform-manipulationredistribution of tweet content to third parties7, and\nonly allow distributing data sets composed of iden-\nti\ufb01er codes, these data sets have to be \u201chydrated\u201d to\nprovide the complete data, which makes it important\nto work with recently collected data in order to access\nas much of it as possible. Even in our 2020 data set,\nby the end of December (approximately three months\nafter the beginning of the data collection), approxi-\nmately 19% of the tweets had already been deleted or\ncame from subsequently suspended accounts.\nCollecting data ourselves provided more \ufb02exibil-\nity in how that data were obtained, enabling keyword-\nbased collection or account-based collection in re-\nsponse to different needs, as well as changing the col-\nlection context as necessary.\nManually annotating tweets for the reliability of\ntheir contents is a massive undertaking with substan-\ntial effort and, in many cases, expert knowledge re-\nquired in order to create a sizable data set. There-\nfore, we adopted a common approach to overcome\nthese scale challenges, by leveraging a curated list\nof websites classi\ufb01ed according to the their trustwor-\nthiness to label tweets, as done in previous research\n(Bovet and Makse, 2019; Guimar \u02dcaes et al., 2021b;\nGuess et al., 2019). Our systematic labeling pro-\ncess is described in the following steps. First, only\ntweets that contained links were selected. Then, the\ndomains those links pointed to were compared against\ntheir level of factual reporting as determined by Me-\ndia Bias Fact Check (MBFC) (Zandt, 2021). MBFC is\nan independent fact-checking organization that classi-\n\ufb01es news outlets in one of 6 levels of factual reporting,\nranging from \u201cvery low\u201d to \u201cvery high\u201d. Our criterion\nwas to consider tweets with links to websites classi-\n\ufb01ed as \u201cvery low\u201d or \u201clow\u201d to be associated with ques-\ntionable content, while we considered tweets with\nlinks to websites classi\ufb01ed as \u201chigh\u201d or \u201cvery high\u201d\nto be associated with reliable content. This approach\nallowed us to obtain a data set with 150,677 labeled\ntweets, described in table 1. The imbalance seen in\nthe classes winds up re\ufb02ecting the actual imbalance\nof these types of posts in the real world. Approxi-\nmately 5% of tweets with links were associated with\nquestionable content, a proportion similar to the 2016\nelection (Grinberg et al., 2019).\nTable 1: Number of labeled tweets.\nLink domain Total Excluding retweets\nQuestionable 7,057 3,613\nReliable 143,620 37,702\n7https://developer.twitter.com/en/developer-\nterms/agreement-and-policyA Mixed Model for Identifying Fake News in Tweets from the 2020 U.S. Presidential Election\n309\n\nThe evolution of the data set size with the applica-\ntion of the processing steps is shown in \ufb01gure 1.\nFigure 1: Changes in data set size (in thousands of tweets).\nFor the data collected during May 2021, such pro-\ncessing was not necessary, as we chose tweets only\nfrom known reliable or questionable sources.\n2.4 Identi\ufb01cation of Features\nOnce the data were gathered, processed, and labeled,\nwe went through the process of deriving features to\nbe used in our classi\ufb01cation model. Since one of\nour stated goals is to investigate the contribution of\nnamed entities and emotion recognition to the identi\ufb01-\ncation of fake news, the features will be split into two\ngroups: a baseline set of features, and an \u201cextended\u201d\nset, containing all features present on the baseline set\nplus features based on named entities and emotions.\nThe baseline features can be further divided into\nthree main groups: metadata from the author pro-\n\ufb01le, metadata from the tweet itself, and linguistic at-\ntributes derived from the tweet content. These fea-\ntures are described in detail in table 2.\n2.4.1 Named Entity Recognition\nBefore trying to distinguish what constitutes real and\nfabricated information, which is composed of facts,\none question must be answered \ufb01rst: What is a fact?\nOne simple answer is that a fact is something that oc-\ncurs at a given time, somewhere, and with or to some-\nthing or someone (Figueira and Oliveira, 2017). In\nother words, a fact should answer the questions of\n\u201cwho,\u201d \u201cwhere,\u201d and \u201cwhen\u201d. These answers can be\nassociated with named entities in the text, which are,\nsimply put, real-world objects that can be indicated\nby a proper name. They are classi\ufb01ed into different\ncategories, such as person, organization, or location,\nand therefore can help provide the aforementioned an-\nswers that characterize a fact.\nThere are automated ways of extracting named en-\ntities from the text. We used two Python libraries for\nthat: spaCy (Honnibal et al., 2020), a Python NLP li-\nbrary built for speed, with high accuracy on named\nentity recognition (NER) tasks, and models pre-\ntrained on text written for the web (blogs, news, and\ncomments). The other library was stanza (Qi et al.,2020), described in section 2.2, with models pre-\ntrained on the comprehensive OntoNotes (Weischedel\net al., 2013) data set. These libraries provided similar\nresults, with the major difference being on classifying\nmentions to Donald Trump. While spaCy had Trump\nrecognized as a person almost as often as it recog-\nnized him as an organization, stanza was more consis-\ntent, correctly identifying him as a person 94% of the\ntime. Regarding the remaining types of entities, both\nlibraries identi\ufb01ed a similar number of occurrences.\nFor creating features, the results from both libraries\nwere compared and the entities recognized by stanza\nwere chosen, since they provided more concise and\naccurate entities on the evaluated samples.\nAfter the entities were extracted from the text,\nthey were grouped into \ufb01ve categories: who, where,\nwhen, quantity, and other. This helped indicate\nwhether the tweets contained the information that\ncharacterizes a fact, as discussed above. This group-\ning also helped reduce feature dimensionality by com-\nbining the original 18 entity types (Weischedel et al.,\n2013) into 5 different categories (table 3).\nBased on that information, a number of features\nwere selected for the classi\ufb01cation model. These in-\ncluded the number of mentions of each entity cate-\ngory in each tweet. In addition, upon observing that\ntweets associated with fake news content potentially\nmade repeated mentions to the same entity per tweet,\nthe entity entropy was also computed to quantify the\nvariability of the entity set contained in each tweet.\nWe used the Shannon entropy (Shannon, 1948) with\na logarithm base of 2. Also, between the two most\ncommon types of entities (person and organization,\nrespectively), it was observed that fake tweets tend to\nfavor mentions of person entities in contrast with non-\nfake tweets. This observation led to a feature com-\nputing the difference between the number of person\nversus organization mentions.\n2.4.2 Emotion Recognition\nWe also investigated the application of emotion\nrecognition to fake news identi\ufb01cation. Our goal was\ntwofold: \ufb01rst, to investigate if any emotions were\nmore prevalent on tweets associated with fake news\nthan with reliable content, and also to investigate if\nthere were any sequences of emotions typical of one\nof those classes.\nTo compute the emotions, we used the NRCLex8\nPython library. The library makes use of the National\nResearch Council Canada (NRC) word-emotion as-\nsociation lexicon (Mohammad and Turney, 2013),\nwhich contains associations of words with eight emo-\n8https://github.com/metalcorebear/NRCLexWEBIST 2021 - 17th International Conference on Web Information Systems and Technologies\n310\n\nTable 2: Baseline features for each tweet.\nFeature Description Feat. group\nuser statuses count Number of posts by tweet author.\nUser pro\ufb01leuser friends count Number of users tweet author follows.\nuser followers count Number of users followed by tweet author.\nuser favourites count Number of tweets marked as favorite by tweet author.\nuser listed count Number of public lists that contain tweet author.\nuser veri\ufb01ed Flag indicating author\u2019s account is veri\ufb01ed by Twitter.\nisRT Indicates if tweet is a retweet.\nTweet\nmetadatahasmedia Indicates if tweet contains media (image or video).\nfavorite count Number of times tweet was marked as favorite.\nretweet count Number of times tweet was retweeted.\ncontains profanity Flags profanity/offensive content (as predicted by the profanity-check library).\nDerived\nfrom text\ncontentproportion allcaps Proportion of words with all capital letters, excluding usernames, hashtags\nand entities recognized by NER (e.g. acronyms).\nexclamation count Number of exclamation points contained in tweet text.\nadverb proportion Proportion of adverbs to words in tweet, excluding usernames and hashtags.\nmention proportion Proportion of username mentions to words in tweet, excluding links.\npolarity Polarity computed by the V ADER library.\nTable 3: Description of entity types and groups.\nEntity group Entity type\nWho ORGANIZATION, PERSON\nWhen DATE, TIME\nWhere EVENT, GPE (Geopolitical entity),\nLOCATION\nQuantity CARDINAL, ORDINAL, PERCENT,\nQUANTITY\nOther FACILITY , LANGUAGE, LAW,\nMONEY , NORP (Nationalities or reli-\ngious or political groups), PRODUCT,\nWORK OF ART\ntions ( anger ,anticipation ,disgust ,fear,joy,sadness ,\nsurprise , and trust) and two sentiments ( negative and\npositive ). This lexicon was manually annotated by\ncrowdsourcing. On top of the 10,000 words in the\nNRC lexicon, the NRCLex library uses NLTK Word-\nNet synonyms to reach a total of 27,000 words.\nBefore computing the emotions, the text in each\ntweet was pre-processed by being converted to lower\ncase, lemmatized using spaCy, had its links removed,\nand hashtags converted to words by removing the\nleading \u201c#\u201d character. A \ufb01nal step of pre-processing,\nneeded in this speci\ufb01c case study, was to remove\nthe word \u201cTrump\u201d. Due to the context of our case\nstudy and data collection process, that word, refer-\nring to Donald Trump, is very common in the data\nset. That proper noun is neutral and indicates no emo-\ntion, however it is mistakenly recognized as the verb\n\u201cto trump\u201d by the NRCLex library, resulting in a mis-\nleading prevalence of the \u201csurprise\u201d affect associated\nwith that word in the emotion lexicon.\nThe computed emotions were used as the basis for\na number of features. Each word represents a num-\nber of emotions. For each emotion, its proportion\namong all emotion indicators that were recognizedwas computed. For example, let us suppose a sen-\ntence contains two words with which emotions were\nassociated: \u201ccommitted\u201d (emotion trust), and \u201cfore-\nsight\u201d (emotions trust andanticipation ). There were\n3 emotion indicators recognized in total, with a pro-\nportion of 2 =3 oftrust and 1 =3 ofanticipation . These\nwould be the emotion proportion feature values for\nthis hypothetical sentence (with the proportion of the\nremaining emotions set to zero). Differences were ob-\nserved between the mean proportion of emotions for\nfake tweets and reliable tweets (\ufb01gure 2), therefore\nthat proportion was used as a feature.\nIn addition, the raw emotion count was also used,\nwhich means how many times in total any emotion\nwas recognized in the text. For example, a tweet with\n3 words indicating fear and 2 words indicating anger\nhas a raw emotion count of 5. Since words can con-\nvey more than one emotion at once, this value not only\nrepresents how emotionally charged a tweet is, but it\nalso helps capture the intensity of emotions. When\ncomparing the distribution of raw emotion counts of\nfake and non-fake tweets, tweets associated with re-\nliable content surprisingly displayed a larger median\nFigure 2: Mean emotion proportions.A Mixed Model for Identifying Fake News in Tweets from the 2020 U.S. Presidential Election\n311\n\nvalue both of raw emotion counts and of the num-\nber of emotion-carrying words. This is unexpected as\nfake news are often designed to elicit a strong emo-\ntional response in the reader, resorting to several lin-\nguistic resources to accomplish that goal.\n2.4.3 Emotion n-Grams\nThe in\ufb02uence of the sequence of prevalent emotions\nin a tweet was also investigated. For each sentence the\nmost frequent emotion was computed, resulting in a\nsequence of prevailing emotions in a tweet. Then, se-\nquences analogous to n-grams were extracted, where\neach prevalent emotion represents one item in the se-\nquence. Due to the short length of tweets, these se-\nquences were limited to bigrams and trigrams of emo-\ntions. The sequences represent the \ufb02ow of emotions\nthrough a piece of text, more precisely between one\nsentence and the next in the case of bigrams. In case\nof ties, where more than one emotion was prevalent\nin a sentence, these were combined in a \u201ccomposite\u201d\nemotion. For example, in case a sentence contained\nthe emotions fear andsadness with equal frequency,\nthese were combined into fear sadness . These com-\nposite emotions were limited to a maximum of three\nsingle emotions. In case more than three emotions\nwere the most frequent in a sentence, we considered\nit was not possible to systematically determine the ac-\ntual prevalent emotion in that sentence.\nThe n-grams were identi\ufb01ed as tuples of emotions.\nTo illustrate, let us suppose a given tweet is composed\nof three sentences. The \ufb01rst sentence has a prevalent\nemotion of surprise , the second sentence has a preva-\nlent emotion of anger , and the third, fear. In that\ncase, the tweet contains two corresponding emotion\nbigrams, identi\ufb01ed as ( surprise ,anger ) and ( anger ,\nfear). With the goal of identifying which n-grams,\nif any, are typical of fake or non-fake tweets, the 20\nmost frequent n-grams were computed for each of\nthose classes in the training set (described below in\nsection 3.1). Out of the top bigrams for each class, in\nmany cases there was no overlap in the most frequent\nn-grams in fake and non-fake tweets. These were con-\nsidered typical of the respective class. In case the\nfrequent n-grams for fake and non-fake tweets over-\nlapped, n-grams were considered typical if they were\nat least 50% more frequent in one of the classes.\nDue to the short length in tweets, usually trigrams\nwere infrequent and thus deemed not to be represen-\ntative, so most of the analysis focused on bigrams.\nThis process resulted in two sets: bigrams consid-\nered typical of fake tweets and, conversely, bigrams\ntypical of non-fake tweets. The fake bigrams set in-\ncluded 6 bigrams, while the non-fake set included 13\nbigrams. For each tweet, we counted how many of itsbigrams belonged to the fake and non-fake bigrams\nsets, and these two were used as extended features.\n3 CLASSIFICATION MODEL\n3.1 Samples\nDue to the nature of the fake news problem, an imbal-\nanced volume of reliable versus questionable content\nis to be expected. In the keyword-based data set col-\nlected from September to December 2020, the pro-\nportion of fake tweets was approximately 5%. This\nis common to many real-world data sets and consti-\ntutes a problem to many machine learning algorithms\nwhen attempting to learn a concept from an underrep-\nresented class (Lema \u02c6\u0131tre et al., 2017).\nIn order to mitigate that problem, a balanced ran-\ndom sample S1 was taken from the initial labeled data\nset. It is composed of 6,000 tweets, with an equal\namount from each class, and was further split into\ntraining and test sets with an 80%-20% division.\nIn order to avoid any data leakage (Kaufman et al.,\n2012), which might lead to overestimating perfor-\nmance on new data in a production environment, only\ndata from the training set was used when computing\nsummaries and deriving features. Also, all retweets\n(which contain the same text content) were removed\nfrom the data set before extracting the sample and\nsplitting the between the training and test sets. If\nthey had been kept, the features set would contain\nrepeated values for several instances of tweets on\ncontent-derived features. Therefore, the model would\nbe trained on instances with the same feature values\nas some values on the test set, again overestimating\nits performance on data it has not seen before. Figure\n3 presents the data sampling process.\nFigure 3: Obtaining training and test sets from S1.\nIn addition to the test set obtained from S1, a few\nother sets were used for testing purposes. These were\nderived from the May 2021 data set, and their primary\ngoal was to assess how well the classi\ufb01cation model\ncould generalize its results to data temporally spaced\nfrom the data the model was trained on. These ad-\nditional test sets are described in table 4. They were\nalso created maintaining class balance.WEBIST 2021 - 17th International Conference on Web Information Systems and Technologies\n312\n\nTable 4: Additional test sets.\nSet Description\nT1 400 tweets from 2021.\nT2 300 retweets from 2020 removed during training.\nT3 150 tweets from 2020, 150 tweets from 2021.\n3.2 Methodology\nFive different algorithms were selected for evaluation,\nwhich included Naive Bayes, Decision Trees, Ran-\ndom Forest, Support Vector Machines, and AdaBoost.\nAlso, we tested all models on two different feature\nsets: baseline and extended (cf. section 2.4).\nFirst, the S1 sample was split into training and test\nsets with the proportions of 0.8 and 0.2, respectively.\nThen the features from both sets were standardized by\nremoving the mean and scaling to unit variance (based\non the training set). The next step was running 5-fold\ncross-validation on the training set for hyperparam-\neter tuning. Using the hyperparameter values which\nprovided the best results on the validation set, we re-\ntrained the models on the whole training set. They\nwere then evaluated on the test set for an estimate of\ntheir performance on new data. Finally, we also tested\nthe models on the T1,T2, and T3 sets (table 4).\n4 RESULTS\nThe main metrics used to evaluate the models\u2019 per-\nformances were the F-measure, the precision, and the\nrecall. The metrics obtained from running the tuned\nmodels against the test sets are presented on table 5.\nWe also compared the ROC curves of all models and\nthe respective AUC values (\ufb01gure 4).\nThe algorithm with the best general performance\nwas the Random Forest. Even though the F-measure\nwas similar for the baseline and extended feature sets,\nthe information from the extended set enabled a 4%\nincrease in the precision, which was the highest for\nS1. The most balanced result in terms of precision and\nrecall was provided by AdaBoost, which also saw an\nincrease in performance by using extended features.\nFigure 4: ROC curves of tested models on S1.The best overall results from the Random Forest is\nalso re\ufb02ected in its AUC value (\ufb01gure 4). Also, while\nthe simplest models (Naive Bayes and Decision Tree)\nsaw a decrease in the AUC with the extended features,\nthe AUC for the three models which provided the best\nresults increased with those features.\nWe also analyzed the F-measures on learning\ncurves based on the training set, which showed that\nAdaBoost was quick to arrive at a performance close\nto its \ufb01nal results, maintaining a similar F-measure\nvalue after 2,000 samples. Other algorithms, though,\nshowed signs an overall ascending F-measure in the\nvalidation sets, meaning they would likely bene\ufb01t\nfrom having more data available for training.\nRegarding test sets T1,T2, and T3, the results\nparticularly for the T1 set are noteworthy, with an\nimprovement in all models in comparison to S1, es-\npecially for AdaBoost and Naive Bayes. This indi-\ncates the models generalized well their performance\nto other criteria of identifying fake news content. Per-\nformance on T2 was slightly inferior to that on S1,\nwhich is somewhat unexpected as both are balanced\nsubsets from the 2020 data set. The results from the\nT3 set were as expected, intermediate values in accor-\ndance with the results from the two previous sets.\nOne limitation we dealt with is that it was not pos-\nsible to use links in tweets, i.e. the news source, as\nbasis for any features. The reputation of a source has\nbeen considered by human evaluators as the most im-\nportant factor in assessing tweet credibility (Ito et al.,\n2015). In fact it is such a strong indicator that it\nformed the basis for our automatic labeling process.\nOn the other hand, the features derived from tweets la-\nbeled based on links generalized well to tweets with-\nout regards to the presence of links, and also with\nother contents not related to the U.S. election.\n5 DISCUSSION\nWith the goal of further comparing the baseline and\nextended sets, we assessed the relative contribution\nof each individual feature by considering the mean\ndecrease in impurity (MDI) to estimate their impor-\ntance in three of the tested algorithms: Decision Tree,\nRandom Forest, and AdaBoost. The feature with the\nmost consistently large contribution was the propor-\ntion of words in all capital letters, by itself responsi-\nble for 37% of the MDI in the baseline Decision Tree,\nfor example. Next, some features derived from the\nuser pro\ufb01le ranked with high importance, including a\nuser\u2019s number of posts and the number of people they\nfollow. Along with other features based on linguistic\nqualities and the tweet content, such as sentiment po-A Mixed Model for Identifying Fake News in Tweets from the 2020 U.S. Presidential Election\n313\n\nTable 5: Metrics obtained for each test set.\nNaive Bayes Decision Tree Random Forest SVM AdaBoost\nbase. ext. base. ext. base. ext. base. ext. base. ext.\nS1f1 0.68 0.68 0.68 0.66 0.73 0.74 0.69 0.72 0.72 0.73\nprecision 0.54 0.57 0.76 0.68 0.79 0.83 0.75 0.75 0.74 0.75\nrecall 0.91 0.85 0.62 0.64 0.68 0.68 0.64 0.69 0.69 0.72\nT1f1 0.94 0.91 0.77 0.78 0.89 0.86 0.85 0.75 0.91 0.91\nprecision 0.99 0.99 0.81 0.79 1.00 0.99 0.96 0.73 0.99 0.98\nrecall 0.90 0.83 0.73 0.77 0.80 0.76 0.76 0.77 0.85 0.85\nT2f1 0.67 0.64 0.62 0.60 0.71 0.73 0.59 0.63 0.71 0.65\nprecision 0.51 0.51 0.72 0.67 0.70 0.76 0.60 0.52 0.62 0.53\nrecall 0.95 0.88 0.55 0.55 0.72 0.69 0.58 0.78 0.82 0.83\nT3f1 0.79 0.79 0.69 0.67 0.76 0.80 0.67 0.69 0.79 0.79\nprecision 0.68 0.69 0.74 0.69 0.79 0.86 0.74 0.60 0.77 0.71\nrecall 0.93 0.91 0.64 0.65 0.74 0.75 0.62 0.80 0.82 0.88\nlarity, proportion of adverbs, and number of username\nmentions, these accounted for 86% of the MDI in the\nbaseline Random Forest, for example.\nWhen considering the extended set of features, we\nobserved the baseline features described above were\nstill the major contributors in MDI. The baseline Ran-\ndom Forest had the same top 7 features ranked for im-\nportance as the model with extended features. How-\never, with extended features they accounted of 45% of\nthe MDI, instead of 86%. A major part of the remain-\ning contribution was provided by features based on\nemotion recognition, most notably emotion frequen-\ncies. Collectively, their highest contribution among\nthe three models was a 34% MDI with Random For-\nest. Among entity-based features, entropy had the sin-\ngle highest contribution in the three models.\nTherefore, while the top baseline features still\nranked higher on the extended models, the contribu-\ntion of the extended features was evident when assess-\ning their importance, supporting the results discussed\non section 4. It is also interesting to note that roughly\nthe same features, both on the baseline and extended\nsets, ranked similarly on different algorithms, attest-\ning to the validity of their general importance.\nThere are several promising possibilities for ex-\ntending this work. One option we plan to explore\nis narrowing down the emotions recognized for each\nword. Since the NRC lexicon usually identi\ufb01es sev-\neral emotions per word, when computing emotion fre-\nquencies in a sentence, these emotions often overlap,\npotentially diluting some of the information. Being\nable to precisely identify a single prevalent emotion\nin a word would likely lead to a clearer representation\nof the overall prevalent emotions in a sentence. One\npossible approach to tackle this problem is leverag-\ning the context each word appears in. For example,\nif a word that conveys the emotions of fear andsad-\nness appears between two segments with the prevail-\ning emotion fear, that word could be deemed to ex-\npress the fear as well, helping to \ufb01lter out extraneousemotions and provide a more precise identi\ufb01cation.\nOne additional possibility for enhancing the emo-\ntion recognition precision is leveraging the context\nspeci\ufb01c to the investigated data. In the 2020 data\nset, the most frequent emotion is trust. Upon ana-\nlyzing the words associated with that emotion, most\nwere recognized to relate to the election or to of\ufb01cial\nauthorities. As our main data set relates to the U.S.\nelections, that behavior is to be expected, and dimin-\nishes the level of information conveyed by identifying\nthe emotion trust, analogous to stop words in NLP.\n6 CONCLUSIONS\nSince the popularization of the term \u201cfake news\u201d by\nformer U.S. president Donald Trump in 2016, the\nproblem of their proliferation has been nothing but\nampli\ufb01ed, going so far as to potentially affect elec-\ntion outcomes, in\ufb02uence economic decisions, neg-\natively impact public health and the public debate,\nmine trust in news organizations, and ultimately skew\npeople\u2019s perceptions about the world. This is a se-\nrious collective problem which requires a multidis-\nciplinary approach to its mitigation, from reeducat-\ning readers about news consumption to technologi-\ncal solutions that help reduce the reach of misinfor-\nmation. As the widespread use of social media has\ncontributed to the dissemination of fake news in ever-\nincreasing volumes, any tool that helps identify these\nitems, hopefully automatically, is an important asset\nin the arsenal against fake news.\nTo that end, in this paper we propose a machine\nlearning-based model to automatically identify posts\nassociated with fake news on Twitter. We provide an\noverview of the data sets created for evaluating the\nautomatic identi\ufb01cation of fake news, using the 2020\nU.S. presidential election as the main context, and\nalso describe the data processing and the automatedWEBIST 2021 - 17th International Conference on Web Information Systems and Technologies\n314\n\nlabeling approach used. We present and compare the\nresults of applying different machine learning mod-\nels to that data, further comparing two different sets\nof features. We demonstrate the satisfactory perfor-\nmance of many models, notably based on Random\nForest and AdaBoost, on different test sets, generated\nwith different approaches. This shows the model is\ncapable of generalizing to other contexts of identify-\ning fake news. In the mainly keyword-based S1 data\nset, our models achieved a best F-measure of 0.74. In\nother test sets, results were as high as 0.94.\nWe investigated and showed the contribution of\nemploying features derived from named entities and\nemotion recognition in enhancing the automatic iden-\nti\ufb01cation of fake news. In the three algorithms which\nconsistently provided the best overall results, these\nfeatures helped improve the F-measure in three of the\nfour test sets used. We believe such a model is an im-\nportant tool with several possibles uses, from alerting\nend users about potentially unreliable content to as-\nsisting organizations in automatically \ufb01ltering ques-\ntionable content for screening, and can contribute to\nthe mitigation of this problem that affects us all.\nACKNOWLEDGEMENTS\nThis work is \ufb01nanced by National Funds through\nthe Portuguese funding agency, FCT \u2013 Fundac \u00b8 \u02dcao\npara a Ci \u02c6encia e a Tecnologia, within project\nUIDB/50014/2020.\nREFERENCES\nBovet, A. and Makse, H. A. (2019). In\ufb02uence of fake news\nin twitter during the 2016 us presidential election. Na-\nture communications , 10(1):1\u201314.\nFigueira, \u00b4A. and Oliveira, L. (2017). The current state of\nfake news: challenges and opportunities. Procedia\nComputer Science , 121:817\u2013825.\nGrinberg, N., Joseph, K., Friedland, L., Swire-Thompson,\nB., and Lazer, D. (2019). Fake news on twitter\nduring the 2016 us presidential election. Science ,\n363(6425):374\u2013378.\nGuess, A., Nagler, J., and Tucker, J. (2019). Less than you\nthink: Prevalence and predictors of fake news dissemi-\nnation on facebook. Science advances , 5(1):eaau4586.\nGuimar \u02dcaes, N., Figueira, \u00b4A., and Torgo, L. (2021a). An or-\nganized review of key factors for fake news detection.\narXiv preprint arXiv:2102.13433 .\nGuimar \u02dcaes, N., Figueira, \u00b4A., and Torgo, L. (2021b). To-\nwards a pragmatic detection of unreliable accounts on\nsocial networks. Online Social Networks and Media ,\n24:100152.Honnibal, M., Montani, I., Van Landeghem, S., and Boyd,\nA. (2020). spaCy: Industrial-strength Natural Lan-\nguage Processing in Python.\nHutto, C. and Gilbert, E. (2014). Vader: A parsimonious\nrule-based model for sentiment analysis of social me-\ndia text. In Proceedings of the International AAAI\nConference on Web and Social Media , volume 8.\nIto, J., Song, J., Toda, H., Koike, Y ., and Oyama, S. (2015).\nAssessment of tweet credibility with lda features. In\nProceedings of the 24th International Conference on\nWorld Wide Web , pages 953\u2013958.\nKaufman, S., Rosset, S., Perlich, C., and Stitelman, O.\n(2012). Leakage in data mining: Formulation, detec-\ntion, and avoidance. ACM Transactions on Knowledge\nDiscovery from Data (TKDD) , 6(4):1\u201321.\nLema \u02c6\u0131tre, G., Nogueira, F., and Aridas, C. K. (2017).\nImbalanced-learn: A python toolbox to tackle the\ncurse of imbalanced datasets in machine learning. The\nJournal of Machine Learning Research , 18(1):559\u2013\n563.\nLoria, S. (2018). textblob documentation. Release 0.15 , 2.\nMitra, T. and Gilbert, E. (2015). Credbank: A large-scale\nsocial media corpus with associated credibility an-\nnotations. In Proceedings of the International AAAI\nConference on Web and Social Media , volume 9.\nMohammad, S. M. and Turney, P. D. (2013). Crowdsourc-\ning a word\u2013emotion association lexicon. Computa-\ntional intelligence , 29(3):436\u2013465.\nQi, P., Zhang, Y ., Zhang, Y ., Bolton, J., and Manning, C. D.\n(2020). Stanza: A Python natural language processing\ntoolkit for many human languages. In Proceedings of\nthe 58th Annual Meeting of the Association for Com-\nputational Linguistics: System Demonstrations .\nSample, C., Justice, C., and Darraj, E. (2019). A model\nfor evaluating fake news. The Cyber Defense Review ,\npages 171\u2013192.\nShannon, C. E. (1948). A mathematical theory of communi-\ncation. The Bell system technical journal , 27(3):379\u2013\n423.\nShu, K., Mahudeswaran, D., Wang, S., Lee, D., and Liu,\nH. (2020). Fakenewsnet: A data repository with news\ncontent, social context, and spatiotemporal informa-\ntion for studying fake news on social media. Big Data ,\n8(3):171\u2013188.\nWeir, W. (2009). History\u2019s Greatest Lies: The Startling\nTruths Behind World Events Our History Books Got\nWrong . Fair Winds Press.\nWeischedel, R., Palmer, M., Marcus, M., Hovy, E., Prad-\nhan, S., Ramshaw, L., Xue, N., Taylor, A., Kaufman,\nJ., Franchini, M., et al. (2013). Ontonotes release 5.0\nldc2013t19. Linguistic Data Consortium, Philadel-\nphia, PA , 23.\nZandt, D. V . (2021). Media Bias/Fact Check\nMethodology. Accessed June, 2021 from\nhttps://mediabiasfactcheck.com/methodology/.\nZubiaga, A., Liakata, M., Procter, R., Wong Sak Hoi, G.,\nand Tolmie, P. (2016). Analysing how people orient\nto and spread rumours in social media by looking at\nconversational threads. PloS one , 11(3):e0150989.A Mixed Model for Identifying Fake News in Tweets from the 2020 U.S. Presidential Election\n315\n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A Mixed Model for Identifying Fake News in Tweets from the 2020 US Presidential Election.", "author": ["V Bernardes", "\u00c1 Figueira"], "pub_year": "2021", "venue": "WEBIST", "abstract": "The recent proliferation of so called \u201cfake news\u201d content, assisted by the widespread use of  social media platforms and with serious real-world impacts, makes it imperative to find ways"}, "filled": false, "gsrank": 642, "pub_url": "https://pdfs.semanticscholar.org/660d/555174ab6fb77bee23f463590b89c225637c.pdf", "author_id": ["Twrg9-sAAAAJ", "JcDha_wAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:qkbsmCSLd4UJ:scholar.google.com/&output=cite&scirp=641&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D640%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=qkbsmCSLd4UJ&ei=erWsaPG6EvnSieoPxKLpgQ0&json=", "num_citations": 2, "citedby_url": "/scholar?cites=9617308518573688490&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:qkbsmCSLd4UJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://pdfs.semanticscholar.org/660d/555174ab6fb77bee23f463590b89c225637c.pdf"}}]