[{"title": "News consumption and social media regulations policy", "year": "2021", "pdf_data": "1\nNews consumption\nand social media regulations policy\nGabriele Etta, Matteo Cinelli, Alessandro Galeazzi, Carlo Michele Valensise, Walter Quattrociocchi, Mauro Conti,\nSenior Member, IEEE\nAbstract \u2014Users online tend to consume information adhering\nto their system of beliefs and to ignore dissenting information.\nDuring the COVID-19 pandemic, users get exposed to a massive\namount of information about a new topic having a high level of\nuncertainty. In this paper, we analyze two social media that en-\nforced opposite moderation methods, Twitter and Gab, to assess\nthe interplay between news consumption and content regulation\nconcerning COVID-19. We compare the two platforms on about\nthree million pieces of content analyzing user interaction with\nrespect to news articles. We \ufb01rst describe users\u2019 consumption\npatterns on the two platforms focusing on the political leaning\nof news outlets. Finally, we characterize the echo chamber effect\nby modeling the dynamics of users\u2019 interaction networks. Our\nresults show that the presence of moderation pursued by Twitter\nproduces a signi\ufb01cant reduction of questionable content, with a\nconsequent af\ufb01liation towards reliable sources in terms of engage-\nment and comments. Conversely, the lack of clear regulation on\nGab results in the tendency of the user to engage with both types\nof content, showing a slight preference for the questionable ones\nwhich may account for a dissing/endorsement behavior. Twitter\nusers show segregation towards reliable content with a uniform\nnarrative. Gab, instead, offers a more heterogeneous structure\nwhere users, independently of their leaning, follow people who\nare slightly polarized towards questionable news.\nIndex Terms \u2014COVID-19, Social Media, News Consumption,\nFake news, Echo Chambers.\nI. I NTRODUCTION\nThe COVID-19 outbreak [1], which was declared as a\npandemic by the World Health Organization (WHO) on 11\nMarch 2020 [2], changed several aspects of our everyday\nlife both in the online and of\ufb02ine sphere. For instance, the\nnews diet of users was remarkably modi\ufb01ed in its structure by\nintroducing a considerable amount of information referring to\na new topic. This phenomenon was accelerated by social media\nplatforms, which are known for shaping discussions on a wide\nrange of issues, including politics, climate change, economics,\nmigration, and health [3]\u2013[6].\nThe arising of the pandemic generated an overabundant\n\ufb02ow of information and news, whose trustworthiness may not\nalways be guaranteed, especially online. This phenomenon,\nreferred as infodemic [7], [8] reportedly affect people\u2019s be-\nhavior [9] in a harmful way. This aspect calls for urgent\ninvestigations of the turbulent dynamics of the online info-\nsphere, complementary to the monitoring of the spreading of\ninfections [10]\u2013[12]. Indeed, the current infodemic may foster\nthe tendency of users a) to acquire information adhering to\ntheir system of beliefs [13], b) to ignore dissenting information[14], c) to form polarized groups around a shared narrative\n[15]. Two common factors to such behaviors carried on by\nusers are opinion polarization [16], one of the dominating\ntraits of online social dynamics, and echo chambers [17].\nDivided into echo chambers, users account for the coherence\nwith their preferred narrative rather than the actual value of\nthe information [18]\u2013[20]. Such evidence for polarization and\nonline echo chambers seems to be related to a feedback loop\nbetween individual choices and algorithm recommendations\ntowards like-minded contents [17], [21], [22]. However, other\npresumably harmless factors like the enforcement of content\nregulation may play a role in increasing online polarization.\nIndeed, it was recently observed that moderation policies\nand removal actions/bans of users produce adverse effects in\nterms of online polarization [23]\u2013[25]. Users who got banned\noften consider this action as a badge of honor, rejoining the\nsame social media under new identities or migrating to more\ntolerant platforms. The result could be either a reinforcement\nof their (extreme) opinion or reduced exposure to opposing\nvoices. Therefore, raising awareness about the collateral costs\nof content policy and other interventions is crucial for making\nsocial media a less toxic environment.\na) Contribution: This work provides a comparative anal-\nysis between two social media platforms that differ on how\ncontent moderation is applied. We select Twitter as a repre-\nsentative of content-regulated social media and Gab, a social\nnetwork known for its willingness to ensure free speech by\nusing little to no content moderation [26], like its counterpart.\nDespite their differences in how content policy is applied,\nboth platforms are characterized by a similar platform design.\nUsers are allowed to post and interact with content, together\nwith their ability to create connections with other users. We\nperform our analysis on a timespan between 1=1=2020 and\n30=09=2020 , covering the \ufb01rst global wave of COVID-19.\nThe dataset includes about three million posts and comments\nrelated to the COVID-19 topic expressed from more than one\nmillion users. We investigate consumption patterns from a user\nand post perspective on the two social media, assessing differ-\nences in terms of engagement. We extend this analysis by tak-\ning into account the trustworthiness of the contents published,\nclassifying news sources accordingly to a categorization based\non Media Bias/Fact Check [27] and NewsGuard [28]. An\nakin type of classi\ufb01cation was exploited in several papers [5],\n[12], [14], [17] bringing essential insights on the circulation of\nmisinformation online. Therefore, we employ this dichotomy\nby classifying posts as Questionable orReliable depending\non their credibility. The same labeling was used to model thearXiv:2106.03924v1  [cs.SI]  7 Jun 2021\n2\npersistence of users repeatedly commenting under a post of\nthe same outlet category. Finally, we investigate the presence\nof homophily, i.e., the tendency of users to aggregate around\ncommon interests, by measuring the relationship between users\nand their tendency to post questionable content. We \ufb01nd\nthat the content moderation imposed by Twitter promotes the\nexistence of two echo chambers of radically different sizes.\nIn summary, the bulk of users on Twitter seems to share and\ninteract with veri\ufb01ed content.\nOppositely, users on Gab show a lack of a clear preference\nbetween the two types of outlets. Questionable posts are pre-\nferred in terms of commenting persistence. However, reliable\nposts are more likely to be commented on as time passes.\nCoherently, the existence of echo chambers on Gab is not as\nevident as observed in the case of Twitter due to the presence\nof users with a relatively heterogeneous leaning. We conclude\nthat a valid content regulation policy produces tangible results\nin contrasting misinformation spreading.\nb) Organization: This work is organized as follows.\nSection II-A describes the recent developments in the study of\nmisinformation dynamics and their relationship with the phe-\nnomenon of polarization. Section II-B introduces the structure\nof Gab, providing an overview of this particular social media.\nSection II-C describes the recent advances in the study of\nmisinformation related to COVID-19 from a social dynamics\nand machine learning perspective. Section III introduces the\nmethodology and the theoretical tools applied for this study.\nSection IV describes the results obtained from the experi-\nments. Section V provides the \ufb01nal remarks of this work,\nsummarizing the results obtained and the future developments.\nFinally, Section A provides additional information on the\nresults presented in the paper.\nII. R ELATED WORKS\nA. Misinformation and polarization\nThe study of misinformation and the spreading of fake news\nhas received increasing interest in recent years, disentangling\nthe role of news consumption on mainstream and niche social\nmedia [5], [12], [19], [29], [30]. The presence of psychological\nmechanisms that affect the way users choose which news\nto consume [9] has been attributed to the effect of online\npolarization [16], [19] and, consecutively, to the creation of\nthe so-called echo chambers [17], [31]\u2013[35].\nB. The role of Gab\nGab [36] is an online social platform that aroused much\ncontroversy in recent years. It describes itself as \u201cA social\nnetwork that champions free speech, individual liberty and the\nfree \ufb02ow of information online. All are welcome\u201d [36]. Such\na claim, together with the political leaning of its founders and\ndevelopers, made Gab a safe place for the alt-right movement,\nplaying a central role in the organizations of actions to harm\nthe of\ufb02ine world [37]. The lack of content regulation within\nGab helped the proliferation of hate speech and fake news.\nThe risks associated with this content policy led to a series of\nsuspensions by its former service provider and the ban of its\napplication from online stores [26]. Gab attracted the interestof researchers due to its permissive content regulatory policy\nand the political leaning of its users. In Lima et al. [38],\nauthors analyzed the content shared on Gab and the leaning\nof users, \ufb01nding a homogeneous environment prone to share\nright biased content. Zannettou et al. [26] characterized Gab in\nterms of user leanings and their contents, suggesting that this\nplatform better suits for a safe place for right-wing extremists\nrather than an environment where free speech is protected.\nMoreover, a topological analysis performed by Cinelli et al.\n[17] reveals that Gab users form one relevant cluster biased\nto the right.\nOverall, all these studies suggest that Gab can be considered\nas a homogeneous environment where biased content and\nmisinformation may easily proliferate.\nC. Recent advances in COVID-19 misinformation studies\nResearch against misinformation during the COVID-19 out-\nbreak produced a series of results to limit the spreading of\nharmful information.\nCinelli et al. [12] analyzed posts obtained from 5 different\nsocial media platforms (Facebook, Twitter, Instagram, Gab,\nand Reddit), \ufb01nding out that the spreading of information is\nmainly driven by the peculiar structure of the social media\nin exam that in turn shapes the interaction patterns between\nusers.\nIn the \ufb01eld of machine learning, Elhadad et al. [39] in-\ntroduced a framework that can identify, through a composed\nmachine leaning approach, misleading health-related informa-\ntion based on a ground-truth dataset. Since their use case\nis related to COVID-19, the ground-truth dataset contained\nboth epidemiological and textual data from organizations like\nWHO, UNICEF, UN and a range of fact-checking websites.\nSear et al. [40] provided a result that does not depend on\na classi\ufb01cation approach. Instead, they employed LDA-based\nalgorithm to identify similar topics related to posts obtained\nfrom Facebook Pages belonging to pro-vax and anti-vax com-\nmunities. Their \ufb01ndings describe how the anti-vax community\ndevelops a less focused debate on COVID-19 compared with\nthe pro-vax counterpart. However, anti-vax seems to be more\nspread on the COVID-19 debate, with the result of being\nmore positioned to attract new supporters than the pro-vax\ncommunity.\nIn the context of Twitter, Jiang et al. [41] proposed a machine-\nlearning model based on BERT architecture which estimated\nuser polarity within the U.S. debate by employing features\nrelated to language and network structures. They found that\nusers belonging to the right-leaning are more active in the\ncreation and spreading of news af\ufb01liated with their echo\nchamber if compared with their counterparts from the left-\nleaning.\nIII. P RELIMINARIES AND DEFINITIONS\nIn this section, we present the methodology applied in this\nstudy. We start by introducing the data collection process of\nposts from Twitter and Gab together with its categorization.\nThen, we describe the theoretical tools behind the analysis of\nengagement patterns, homophily and survival lifetime.\n3\nA. Data Collection\nThe collection of all posts concerning the COVID-19 was\ndesigned to capture its corresponding debate on social media,\ngathering posts and comments from both platforms. Therefore,\nas the \ufb01rst step of this process, we analyzed the most searched\nterms worldwide related to the aforementioned pandemic on\nGoogle Trends. The analysis period ranges from 1=1=2020\nto30=09=2020 . We selected four terms based on their inter-\nest and signi\ufb01cance over time, namely: coronavirus, corona,\ncovid, covid19 . Those terms served as a proxy, in the form of\nhashtags, to retrieve posts on the two social media.\nThe collection of Twitter posts related to the COVID-19\npandemic relied on the existence of a public dataset [42]\ncovering this speci\ufb01c topic. It includes a collection of tweet\nIDs, starting from 28=01=2020 , posted by accounts with a\nrecognized in\ufb02uence or including representative keywords. To\nprovide a categorization of the reliability of the tweets, we\nre\ufb01ned this dataset by retaining only those posts with a link,\nreducing the dimension to 1:1M posts.\nThe same strategy was applied in the case of Gab. We\nqueried their API to obtain posts that included at least one of\nthe search hashtags. Due to some modi\ufb01cations made by the\nplatform during the study, the API stopped providing results\nin chronological order since June 2020. Therefore, we started\ncollecting all posts from the general stream until the end\nof the analysis period, \ufb01ltering by hashtag as we previously\ndescribed. This process produced a dataset of \u0018130K posts\ncontaining a link.\nB. Questionable and Reliable Sources\nTo evaluate the reliability of information circulating on both\nsocial media, we employed a source-based approach. We built\na dataset of news outlets\u2019 domains from our dataset where each\ndomain is labeled either as Questionable orReliable . The clas-\nsi\ufb01cation relied on two fact-checking organizations called Me-\ndiaBias/FactCheck (MBFC, https://mediabiasfactcheck.com)\nand NewsGuard (NG, https://www.newsguardtech.com/). On\nMBFC, each news outlet is associated with a label that refers\nto its political bias, namely: Right, Right-Center, Least-Biased,\nLeft-Center, and Left . Similarly, the website also provides a\nsecond label that expresses its reliability, categorizing outlets\nasConspiracy-Pseudoscience, Pro-Science orQuestionable .\nNoticeably, the Questionable set includes a wide range of\npolitical biases, from Extreme Left toExtreme Right . For\ninstance, the Right label is associated with Fox News, the\nQuestionable label to Breitbart (a famous right extremist out-\nlet), and the Pro-Science label to Science . MBFC also provides\na classi\ufb01cation based on a ranking bias score that depends on\nfour categories: Biased Wording/Headlines, Factual/Sourcing,\nStory Choices, andPolitical Af\ufb01liation . Each category is rated\non a 0\u000010scale, with 0indicating the absence of bias and\n10indicating the presence of maximum bias. The bias outlet\nscore is computed as the average of the four score categories.\nLikewise, NG classi\ufb01es news outlets into four categories based\non nine journalistic criteria, each of them having a speci\ufb01c\nscore whose sum ranges between 0and100. Outlets with a\nscore of at least 60points are considered compliant with thebasic standards of credibility and transparency. Otherwise, they\nare recognized as outlets that lack of credibility. A different\ncharacterization is provided for humor and platforms websites,\nnot accounting for the categorization process.\nGiven the different ways of classifying information sources\nfrom the two organizations, the following heuristic was ap-\nplied. On MBFC, all the outlets already classi\ufb01ed as Question-\nable or belonging to the category Conspiracy-Pseudoscience\nwere labeled as Questionable . The remaining categories were\nlabeled as Reliable . Coherently, outlets on NG were classi\ufb01ed\nbased on their score, maintaining the dichotomy provided by\nthe website. We choose a score of 60 as threshold to consider\nan outlet as Reliable (score>60), otherwise it is referred as\nQuestionable (score\u001460).\nConsidering a total of 2738 news outlets provided by the\ntwo organizations, 2701 belonging to MBFC and 37to NG, we\nend up with 814 outlets classi\ufb01ed as Questionable and 1924\noutlets classi\ufb01ed as Reliable.\nC. User Leaning\nTo measure the extent to which a user is associated with the\nconsumption of questionable or reliable contents, we introduce\ntheuser leaning q. We de\ufb01ne it in the range q2[0;1], where\n0means that a user posts contents exclusively associated with\nreliable sources, and 1means that a user puts into circulation\nonly questionable posts.\nFormally, the user leaning can be de\ufb01ned as follows: let P\nbe the set of all posts with a URL matching a domain in our\ndataset andUthe set containing all the users with at least\na categorized post. At each element pj2 P is associated\na binary value lj2 f0;1gbased on the domain of the\nlink contained: if the URL refers to a domain classi\ufb01ed as\nquestionable then lj= 1, otherwise lj= 0. Considering a\nuseruiin a bipartite network between users and posts, then\nthe user leaning qiof a useruican be de\ufb01ned as:\nqi=1\nkikiX\nj=1lj; (1)\nwhereljis the leaning score of the j-th neighbor of the user\nui, andkiis the number of categorized contents that the user\nposted.\nD. Comparison of power law distributions\nMost quantities related to the activity of users on social\nmedia show a heavy tailed distribution of discrete variables.\nGiven the discrete nature of such distributions, we could\nnot rely on Kolmogorov-Smirnov [43] test to assess whether\ntwo distributions present signi\ufb01cant differences between each\nother. Indeed, such a test assumes that distributions must be\ncontinuous, and the presence of a large number of ties in the\nlong-tailed distributions that we want to compare may lead to\nthe computation of biased p-values. To overcome this issue,\nwe employed a methodology proposed in Zollo et al. [14]\nwhich makes use of a Wald Test [44] to assess signi\ufb01cant\ndifferences between the scaling parameters of two long-tailed\ndistributions.\n4\n100101102103104105\n100101102103104105N. of Posts\n100101102103104\nN. of Interactions\n100101102103104105106\n100101102103104105106Cumulative N. of Interactions\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTime\nLikes Reblogs Replies\n100101102103104105\n100101102103104105N. of Users\nGab\nTwitter100101102103104\nN. of Interactions\nFig. 1: Representation of the engagement collected on Gab (upper panel) and Twitter (bottom panel). Left column : frequency\ndistribution of the interactions for posts, de\ufb01ned as Likes ,Reblogs (orRetweets) andReplies . A like is generally considered\npositive feedback on a news item. A reblog indicates a desire to spread a news item to friends. A reply can have multiple\nfeatures and meanings and can generate collective debate. Both social media shows a heavy-tailed distribution that allows room\nfor large deviations, i.e., some posts go viral. Middle column : evolution of the cumulative number of interactions over time.\nThe general trend shows a rapid increase during February 2020, in parallel with the spreading of the COVID-19 outbreak.\nThe absence of replies on Twitter is due to the limitations provided by their API. Right column: frequency distribution of\ninteractions received by users. Similarly to posts, the distribution is heavy-tailed, describing how users tend to collect similar\nvalues of different interactions as their number increases.\nE. Kaplan-Meier Estimator for lifetime analysis\nLetT2[0;+1]be a random variable which represents\nthe time an event takes place. The probability that a randomly\nselected subject lives up to time tis called Survival Function\nS(t) =P(T\u0014t). The estimation of this probability is\nprovided by the Kaplan-Meier estimator [45], de\ufb01ned as\n^S(t) =Y\nti\u0014t\u0012\n1\u0000di\nni\u0013\n; (2)\nwherediis the number of events that happened at time ti\nandniare the numbers of subjects who survived up to time\nti. In user lifetime analysis, we de\ufb01ne as dithe number of\nusers who have been commenting on a post up to tidays\nandnithe number of users who stopped commenting after\ntidays. Similarly, in post lifetime analysis, we de\ufb01ne as di\nthe number of posts that have been receiving a comment up\ntotidays andnithe number of posts that stopped receiving\ncomments at tidays. In both cases, our Ndistinct events times\nt1;t2;:::;t N\u00150are independent, which is required by the\nassumptions of the Kaplan-Meier estimator.\na) Homophily Analysis in User Following Networks:\nResults from the computation of the user leaning qwere\ngeneralized to measure user homophily based on his news\nconsumption. This phenomenon was modeled from a network\nperspective based on the work originally proposed by Cota\net al. [46]. We considered a new network in which a user is\nrepresented as a node iwith a given leaning qi. Each nodecan be connected to others through a following relationship:\nif userifollows user jon the social media in exam, their\ncorresponding representation in the adjacency matrix Ais\nAij= 1, meaning that there is a directed edge between i\nandj. In case of no relationship between the two users, we\nhaveAij= 0. This representation allows the computation of a\nmeasure called average neighborhood leaning that quanti\ufb01es\nthe mean leaning from all those users followed by a given one.\nIt is de\ufb01ned as\nqN\ni=1\nk!\niX\njAijqj; (3)\nwherek!\ni=P\njAijis the out-degree of node i, i.e., the\nnumber of users followed by user i.\nIV. R ESULT AND DISCUSSION\nThis work aims at performing a comparative analysis of\ntwo social media, namely Twitter and Gab, in order to under-\nstand how news consumption and social dynamics change in\npresence of two radically different types of content regulation\npolicies (more stringent in the case of Twitter, almost absent\nin the case of Gab). The following results will provide insights\nto explain this behavior from different perspectives. At \ufb01rst,\nwe analyze the engagement of users with posts, which we\nconsider as separated into two categories named questionable\nand reliable. Then, we quantify the commenting behavior of\nusers and posts. Lastly, we provide a network analysis to\n5\n100101102103104105\n100101102103104105N. of Posts\n100\n101\n102\n103\n104\nN. of Likes\n101102103104105106\n101102103104105106Cumulative N. of Likes\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTime\n100101102103104105\n100101102103104105N. of Posts\n100\n101\n102\n103\n104\nN. of Reblogs\n100101102103104105106\n100101102103104105106Cumulative N. of Reblogs\nGab\nTwitterJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTime\nOutlet Leaning Questionable ReliableA B C D\nFig. 2: Column A-B : categorized distribution of the number of posts against the number of likes they received with its cumulative\nevolution. The distributions show some evidence about content preference on both platforms. Users on Gab show signs of better\nappreciation toward questionable posts, supported by the lack of clear content regulation. Twitter, oppositely, shows strong\nevidence towards the appreciation of reliable content, with a remarkable gap between the two categories. From a cumulative\nperspective, the regulation imposed by Twitter results in an increasing divergence between questionable and reliable posts,\nshowing how the latter category is the most preferred one. The same does not apply to Gab, whose divergence seems not\nto increase during the analysis period. Column C-D: categorized distribution of the number of posts against the number of\nreblogs or retweets they received with its cumulative evolution. The previous considerations also apply to this kind of interaction,\ndescribing the willingness of users to inject the contents they support into the news feed of their followers.\nmeasure the tendency of users to aggregate with like-minded\npeers, describing how the presence of content regulation may\nbe correlated with the polarization towards speci\ufb01c narratives.\nA. Consumption Patterns\nWe investigate how the engagement on the two social\nmedia differs in relationship with the COVID-19 topic. Fig. 1\ncompares the engagement distribution for posts and users.\nDespite the differences in terms of scale that are attributable\nto the size of the platforms\u2019 user base, we observe that both\nfrequency distributions are long-tailed. This feature provides a\n\ufb01rst evidence in the consumption of news, showing that inter-\naction patterns are similar regardless of the content moderation\nimposed.\nNext, we extend the analysis of consumption patterns by\ncategorizing posts, based on their outlet leaning, into Ques-\ntionable or Reliable. The resulting distributions from the ap-\nplication of this dichotomy are represented in Fig. 2 and 3. Fig.\n2 displays the distribution of the number of likes and shares\n(reblogs or retweets) obtained by posts in our dataset, together\nwith the corresponding cumulative. Similarly, Fig. 3 describes\nthe frequency distribution of the same kind of interactions from\na user perspective. In general, we observe how Twitter users\nshow a larger appreciation of reliable posts, establishing a clear\ngap from questionable ones that increases during the analysis\nperiod. This difference can be attributed to the commitment of\nTwitter to limit the spreading of unveri\ufb01ed contents [47]. Theopposite scenario happens on Gab, in which the consumption\npatterns do not show a clear sign of polarization towards a\nspeci\ufb01c kind of narrative. This provides some evidence of\nhow users belonging to segregated environments like Gab are\nnot interested in the origin of the content itself. Instead, they\ntend to self-segregate within environments in which they can\nconsume and spread questionable content. Therefore, the lack\nof regulation on this platform may allow them to perform\ninformation operations [48], i.e., a category of actions taken by\norganized actors (governments or non-state actors) to distort\ndomestic or foreign political sentiment, against other users\nwho do not share the mainstream system of beliefs of the\ncommunity.\nIn order to assess the similarity between the distributions\nderiving from the consumption patterns of questionable and\nreliable posts, we \ufb01t power-law distributions to such data and\nperform a statistical evaluation of their scaling parameters\nusing the Wald test. For Gab, all the obtained p-values were\nsigni\ufb01cantly higher than 0:05, describing how questionable\nand reliable distributions are comparable in terms of the\nengagement produced. The same behavior is found on Twitter,\nexcept for the likes distribution whose p-value is less than\n0:001, describing a signi\ufb01cant difference in the way users\nengage with questionable and reliable content.\nWe can conclude that the presence of content moderation\nis associated with a signi\ufb01cant reduction of the \ufb02owing of\nmisinformation. The avoidance of these countermeasures, as\n6\n100101102103\n100101102103N. of Users\n100102104106108\nN. of Total Likes\n100101102103104105\n100101102103104105N. of Users\nGab\nTwitter100101102103104\nN. of Total Reblogs\nOutlet Leaning Questionable Reliable\nFig. 3: Distribution of likes (left column) and reblogs (right\ncolumn) received by users posting Questionable or Reliable\ncontents on Gab (upper panel) and Twitter (bottom panel).\nThe \ufb01gure shows how the presence of content regulations,\nperformed by Twitter, results in a greater appreciation towards\nusers who post reliable content. Gab, instead, shows a mixed\nendorsement pattern in which the appreciation towards users\ndoes not depend on the category of the content they post.\nreported on Gab, seems to be associated with more het-\nerogeneous news consumption in terms of outlet category.\nThis particular shape of the news diet may be exploited to\nconduct information operations. Statistical tests indicate how\nquestionable and reliable contents produce similar engagement\nbehaviors within the same social media. In the end, such\nmoderation helps the emergence of segregation, a condition\nin which users are affected by the restriction applied in terms\nof accessibility to the contents they are af\ufb01liated with but not\nin their engagement behaviors.\nB. Characterizing Commenting Behavior for Questionable\nand Reliable posts\nTo quantify the persistence of comments concerning users\nand posts, we employed Kaplan-Meier estimates of two sur-\nvival functions. The \ufb01rst accounts for the period between\nthe \ufb01rst and last comment received from posts. The second\ninstead considers the period between the \ufb01rst and last comment\nmade by a user. To characterize any signi\ufb01cant difference\nin the two survival functions, we perform the Peto & Peto\n[49] test. The upper panel of Figure 4 shows the Kaplan-\nEstimates computed on Gab, grouped by outlet category. The\ntest performed on its post and user lifetimes produces a p-\nvalue of 0:026 and0:001, respectively. Therefore, we can\nconclude that the commenting persistence on Gab may be\nsubjected to the outlet category of the post commented. Indeed,\npost lifetime on questionable posts reports a lower probability\nof being commented as time increases despite its longer\npersistence, reaching a maximum 340days. Results from user\nlifetime estimation, instead, describe how users are more likely\nto comment on questionable posts for the \ufb01rst 240days after\n10\u2212310\u2212210\u22121100S(t)\n0\n40\n80\n120\n160\n200\n240\n280\n320\n360\n400DaysPost Lifetime\n10\u2212310\u2212210\u22121100S(t)\nGab0\n40\n80\n120\n160\n200\n240\n280\n320\n360\n400DaysUser Lifetime\n10\u2212310\u2212210\u22121100S(t)\n0\n40\n80\n120\n160\n200\n240\n280\n320\n360\n400Days\n10\u2212410\u2212310\u2212210\u22121100S(t)\nTwitter0\n40\n80\n120\n160\n200\n240\n280\n320\n360\n400Days\nOutlet Leaning Questionable ReliableFig. 4: Kaplan-Meier estimates for Gab (upper panel) and\nTwitter (lower panel), grouped by outlet category.\nLeft column : estimates obtained through the computation\nof post lifetime, i.e., the period between the \ufb01rst and last\ncomment a post received. Right column : estimates obtained\nthrough the computation of post lifetime, i.e., the period\nbetween the user\u2019s \ufb01rst and last comment.\nGab shows how the lack of content regulation is associated\nwith a commenting behavior that underlines a preference\ntowards questionable content. This behavior is characterized\nby a discrepancy between the outlet category with the highest\ncommenting persistence both on user and post lifetimes. By\ncontrast, the introduction of content policies from Twitter\nmakes reliable content those with the highest commenting\npersistence, which does not depend on the lifetime perspective.\npost creation. After that time, the survival probability becomes\nhigher on reliable posts.\nIn the end, we can conclude that the commenting behaviors\non Gab re\ufb02ect the general leaning of its community. Users\nare more likely to comment on questionable posts since their\ncontents adhere to a common system of beliefs oriented to\nconspiracy theories. Coherently, the signi\ufb01cant commenting\npersistence reported on reliable posts may describe the desire\nof users to express their dissent against the narratives intro-\nduced from such posts.\nNext, we examine the commenting persistence on Twitter.\nResults from Peto & Peto test on the post and user lifetimes\nreport a p-value equal to 0:011and0:0055 respectively, stating\nhow the survival functions on both lifetimes differentiate\nwith respect to the outlet category of the posts commented.\nIndeed, such estimations on Twitter describe a uniformity in\nthe commenting behavior for the reliable category. This fact\nalso provides further evidence about how content moderation\ncan discourage users from expressing their views under posts\nwhose authority is not veri\ufb01ed.\nIn summary, Gab demonstrates how the lack of content\n7\npolicy helps the emergence of the narratives that characterize\nthis environment, resulting in a discrepancy between the outlet\ncategories with the most commenting persistence on the two\nlifetimes. However, when the content policy is applied, like on\nTwitter, such discrepancy dissolves, resulting in a commenting\nbehavior that favors reliable content.\nC. Quantifying Polarization\nThe presence of content moderation may affect how users\ndevelop homophily, i.e., the tendency to surround themselves\nwith other peers who share the same narratives or system of\nbeliefs. To quantify this phenomenon, we build a network\nin which the nodes represent the users iwith their corre-\nsponding leaning xi, while the edges represent the following\nrelationship with other users that occurs on the social media.\nThis representation allows us to measure the neighborhood\nleaningxN\ni, i.e., a measure of the characteristic leaning of\nthe network surrounding user i. Figure 5 displays the joint\ndistribution between the individual leaning of a user xiand\nits corresponding neighborhood leaning xN\ni, on Twitter and\nGab. In addition to this, the marginal probability distributions\nP(x)andPN(x), referring to the individual and average\nneighborhood leaning, are represented on their corresponding\naxis. Lastly, the density of users at point (x;xN)is represented\nas a contour map: the brighter the color in that point, the higher\nthe user density. Results described in Figure 5a show the\npresence of homophily on Twitter, characterized by a strong\ncorrelation of leanings in correspondence of low values. The\nexistence of a second echo chamber of incomparable size\nmade of users with high individual leaning, and therefore\nnot represented in the main \ufb01gure but only visible in the\nmarginal distributions, signals strong segregation between two\ncommunities. This \ufb01nding also indicates how content regula-\ntions actively affect the shape of the news diet of users in the\ncontext of the COVID-19 pandemic. Indeed, the concentration\naround small values for both leanings provides evidence about\nthe effectiveness of the moderation imposed by the platform\nagainst posts and users that promote questionable content. On\nthe other side, Gab shows a more heterogeneous behavior, as\nrepresented in Figure 5b. Indeed, the joint distribution spreads\nover different values of the individual leaning domain, with\nthe highest mode represented in correspondence of the point\n(0:6;0:6). We observe that on average users, regardless of their\nleaning, are surrounded by a neighborhood skewed towards\nquestionable contents. Only very few users have a reliable-\nbased leaning, who are also likely to be those with a weaker\nactivity since they could be on Gab just for curiosity or dissing.\nFurthermore, the outlet category of the news that users post\nis not relevant anymore since the user\u2019s peers share a leaning\nwith a high value. Finally, these \ufb01ndings may suggest that\nquestionable news is employed to support the narrative of the\nenvironment, whilst reliable ones are only used to perform\ninformation operations by changing the original meaning of\nthe posts through a comment.\nV. C ONCLUSIONS\nIn this work, we compared two social media, Twitter and\nGab, to investigate the interplay between content regula-\n(a) Twitter\n (b) Gab\nFig. 5: Joint distribution between individual and average\nneighborhood leaning of all users posting classi\ufb01able contents\nat least three times on Twitter (left) and Gab (right). The\n\ufb01gure shows further evidence about the regulation imposed\nby Twitter which results in the creation of a unique echo\nchamber of users with strong posting habits towards reliable\ncontent. Oppositely, Gab shows the presence of an echo\nchamber in which both individual and neighborhood leanings\nare concentrated around high values of the intervals, with a\ngreater dispersion due to the mixed posting habits of users.\ntion policies and news consumption. We provide quantitative\nmeasures of such differences by evaluating the engagement\nof users and posts. These measures are then extended by\nproviding a categorization of news outlets. Next, we measure\nthe commenting persistence of users and posts to describe\ntheir ability to express themselves under posts belonging to\na speci\ufb01c outlet category. In the end, we characterize the\npresence of homophily, investigating how users with a speci\ufb01c\nleaning are more likely to surround themselves with users who\nshare the same narratives.\nOur results show how the application of content regulation,\nperformed by Twitter, limits the diffusion of fake news and\nconspiracy theories, shaping the news consumption and the\npolarization of users towards reliable content. The avoidance\nof these countermeasures, carried on by Gab, provides results\nthat underline the presence of patterns related to information\noperations. Indeed, users tend to engage with questionable\nand reliable content comparably. However, their commenting\nbehavior and the assessment of the homophily in this envi-\nronment describe a systematic af\ufb01liation towards questionable\ncontents.\nWe conclude that content policies cover an important role\nagainst the circulation of harmful content, especially in the\ncontext of the COVID-19 pandemic. Our work provides mean-\ningful evidence in this direction, indicating how a lack of\ncontent policy is associated with the emergence of harmful\nnarratives that promote questionable content and mistrust\neverything that goes against them.\nFuture implementations of this work may focus on the\ndissing/endorsement behavior promoted by users in segregated\nenvironments like Gab, analyzing those mechanisms from a\ntextual perspective. Furthermore, a topological analysis of\nusers who perform information operations in such environ-\n8\nments may be relevant to understand their inner dynamics and\nto promote speci\ufb01c countermeasures.\nREFERENCES\n[1] W. H. Organization, \u201cCoronavirus disease (covid-19) pan-\ndemic.\u201d [Online]. Available: https://www.who.int/emergencies/diseases/\nnovel-coronavirus-2019?adgroupsurvey= fadgroupsurvey g\n[2] \u201cWho director-general\u2019s opening remarks at the media brie\ufb01ng on covid-\n19 - 11 march 2020.\u201d\n[3] A. Bessi, F. Zollo, M. Del Vicario, A. Scala, G. Caldarelli, and\nW. Quattrociocchi, \u201cTrend of narratives in the age of misinformation,\u201d\nPloS one , vol. 10, no. 8, 2015.\n[4] W.-Y . S. Chou, A. Oh, and W. M. Klein, \u201cAddressing health-related\nmisinformation on social media,\u201d Jama , vol. 320, no. 23, pp. 2417\u2013\n2418, 2018.\n[5] A. Bovet and H. A. Makse, \u201cIn\ufb02uence of fake news in twitter during the\n2016 us presidential election,\u201d Nature communications , vol. 10, no. 1,\npp. 1\u201314, 2019.\n[6] M. Del Vicario, S. Gaito, W. Quattrociocchi, M. Zignani, and F. Zollo,\n\u201cNews consumption during the italian referendum: A cross-platform\nanalysis on facebook and twitter,\u201d in 2017 IEEE International Confer-\nence on Data Science and Advanced Analytics (DSAA) . IEEE, 2017,\npp. 648\u2013657.\n[7] J. Zarocostas, \u201cHow to \ufb01ght an infodemic,\u201d The lancet , vol. 395, no.\n10225, p. 676, 2020.\n[8] \u201cOrganization, w. h. director-general\u2019s remarks at the media\nbrie\ufb01ng on 2019 novel coronavirus on 8 february 2020.\u201d [On-\nline]. Available: https://www.who.int/docs/default-source/coronaviruse/\nsituation-reports/20200202-sitrep-13-ncov-v3.pdf?sfvrsn=195f4010 6\n[9] T. Sharot and C. R. Sunstein, \u201cHow people decide what they want to\nknow,\u201d Nature Human Behaviour , vol. 4, no. 1, pp. 14\u201319, Jan 2020.\n[Online]. Available: https://doi.org/10.1038/s41562-019-0793-1\n[10] L. Kim, S. M. Fast, and N. Markuzon, \u201cIncorporating media\ndata into a model of infectious disease transmission,\u201d PLOS\nONE , vol. 14, no. 2, pp. 1\u201313, 02 2019. [Online]. Available:\nhttps://doi.org/10.1371/journal.pone.0197646\n[11] C. Viboud and A. Vespignani, \u201cThe future of in\ufb02uenza forecasts,\u201d\nProceedings of the National Academy of Sciences , vol. 116, no. 8, pp.\n2802\u20132804, 2019. [Online]. Available: https://www.pnas.org/content/\n116/8/2802\n[12] M. Cinelli, W. Quattrociocchi, A. Galeazzi, C. M. Valensise,\nE. Brugnoli, A. L. Schmidt, P. Zola, F. Zollo, and A. Scala, \u201cThe\ncovid-19 social media infodemic,\u201d Scienti\ufb01c Reports , vol. 10, no. 1, Oct\n2020. [Online]. Available: https://doi.org/10.1038/s41598-020-73510-5\n[13] A. Bessi, M. Coletto, G. A. Davidescu, A. Scala, G. Caldarelli, and\nW. Quattrociocchi, \u201cScience vs conspiracy: Collective narratives in the\nage of misinformation,\u201d PloS one , vol. 10, no. 2, p. e0118093, 2015.\n[14] F. Zollo, A. Bessi, M. Del Vicario, A. Scala, G. Caldarelli, L. Shekht-\nman, S. Havlin, and W. Quattrociocchi, \u201cDebunking in a world of tribes,\u201d\nPloS one , vol. 12, no. 7, 2017.\n[15] M. Del Vicario, G. Vivaldo, A. Bessi, F. Zollo, A. Scala, G. Caldarelli,\nand W. Quattrociocchi, \u201cEcho chambers: Emotional contagion and group\npolarization on facebook,\u201d Scienti\ufb01c reports , vol. 6, p. 37825, 2016.\n[16] M. D. Vicario, W. Quattrociocchi, A. Scala, and F. Zollo, \u201cPolarization\nand fake news: Early warning of potential misinformation targets,\u201d ACM\nTransactions on the Web (TWEB) , vol. 13, no. 2, pp. 1\u201322, 2019.\n[17] M. Cinelli, G. De Francisci Morales, A. Galeazzi, W. Quattrociocchi, and\nM. Starnini, \u201cThe echo chamber effect on social media,\u201d Proceedings\nof the National Academy of Sciences , vol. 118, no. 9, 2021.\n[18] M. Cinelli, M. Conti, L. Finos, F. Grisolia, P. K. Novak, A. Peruzzi,\nM. Tesconi, F. Zollo, and W. Quattrociocchi, \u201c(mis)information\noperations: An integrated perspective,\u201d Journal of Information Warfare ,\nvol. 18, no. 3, pp. 83\u201398, 2019. [Online]. Available: https:\n//www.jstor.org/stable/26894683\n[19] M. Del Vicario, A. Bessi, F. Zollo, F. Petroni, A. Scala, G. Caldarelli,\nH. E. Stanley, and W. Quattrociocchi, \u201cThe spreading of misinformation\nonline,\u201d Proceedings of the National Academy of Sciences , vol. 113,\nno. 3, pp. 554\u2013559, 2016. [Online]. Available: https://www.pnas.org/\ncontent/113/3/554\n[20] M. Conti, D. Lain, R. Lazzeretti, G. Lovisotto, and W. Quattrociocchi,\n\u201cIt\u2019s always april fools\u2019 day!: On the dif\ufb01culty of social network\nmisinformation classi\ufb01cation via propagation features,\u201d in 2017 IEEE\nWorkshop on Information Forensics and Security (WIFS) . IEEE, 2017,\npp. 1\u20136.[21] E. Bakshy, S. Messing, and L. A. Adamic, \u201cExposure to ideologically\ndiverse news and opinion on facebook,\u201d Science , vol. 348, no. 6239, pp.\n1130\u20131132, 2015.\n[22] M. Cinelli, E. Brugnoli, A. L. Schmidt, F. Zollo, W. Quattrociocchi, and\nA. Scala, \u201cSelective exposure shapes the facebook news diet,\u201d PloS one ,\nvol. 15, no. 3, p. e0229129, 2020.\n[23] J. Berger and H. Perez, \u201cOccasional paper the islamic state\u2019s diminishing\nreturns on twitter: How suspensions are limiting the social networks\nof english-speaking isis supporters,\u201d GW Program on Extremism and\nEl Akkad, Omar (2012)\u201cWhy Twitter\u2019s censorship plan is better than\nyou think\u201d. The Globe and Mail. Berger, Morgan (2015)\u201cDe\ufb01ning and\ndescribing the population of ISIS supporters on Twitter\u201d. The Brookings\nInstitution , 2016.\n[24] S. Hughes and L. Vidino, \u201cIsis in america: From retweets to raqqa,\u201d Pro-\ngram on Extremism, George Washington University.[online] https://cchs.\ngwu. edu/sites/cchs. gwu. edu/\ufb01les/downloads/ISIS (Rev. 03.03. 2016) ,\n2015.\n[25] A. A. Siegel, \u201cOnline hate speech,\u201d Social Media and Democracy , p. 56,\n2019.\n[26] S. Zannettou, B. Bradlyn, E. De Cristofaro, H. Kwak, M. Sirivianos,\nG. Stringini, and J. Blackburn, \u201cWhat is gab,\u201d Companion of the The\nWeb Conference 2018 on The Web Conference 2018 - WWW \u201918 , 2018.\n[Online]. Available: http://dx.doi.org/10.1145/3184558.3191531\n[27] M. B. Check, \u201cMbfc.\u201d [Online]. Available: https://mediabiasfactcheck.\ncom/\n[28] N. Technologies, \u201cNg.\u201d [Online]. Available: https://www.newsguardtech.\ncom/\n[29] S. V osoughi, D. Roy, and S. Aral, \u201cThe spread of true and false news\nonline,\u201d Science , vol. 359, no. 6380, pp. 1146\u20131151, 2018. [Online].\nAvailable: https://science.sciencemag.org/content/359/6380/1146\n[30] D. M. J. Lazer, M. A. Baum, Y . Benkler, A. J. Berinsky, K. M.\nGreenhill, F. Menczer, M. J. Metzger, B. Nyhan, G. Pennycook,\nD. Rothschild, M. Schudson, S. A. Sloman, C. R. Sunstein, E. A.\nThorson, D. J. Watts, and J. L. Zittrain, \u201cThe science of fake news,\u201d\nScience , vol. 359, no. 6380, pp. 1094\u20131096, 2018. [Online]. Available:\nhttps://science.sciencemag.org/content/359/6380/1094\n[31] K. H. Jamieson and J. N. Cappella, Echo chamber: Rush Limbaugh and\nthe conservative media establishment . Oxford University Press, 2008.\n[32] R. K. Garrett, \u201cEcho chambers online?: Politically motivated selective\nexposure among internet news users,\u201d Journal of computer-mediated\ncommunication , vol. 14, no. 2, pp. 265\u2013285, 2009.\n[33] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis,\n\u201cPolitical discourse on social media: Echo chambers, gatekeepers, and\nthe price of bipartisanship,\u201d in Proceedings of the 2018 World Wide Web\nConference , 2018, pp. 913\u2013922.\n[34] \u2014\u2014, \u201cThe effect of collective attention on controversial debates on\nsocial media,\u201d in Proceedings of the 2017 ACM on Web Science\nConference , 2017, pp. 43\u201352.\n[35] W. Cota, S. C. Ferreira, R. Pastor-Satorras, and M. Starnini, \u201cQuantifying\necho chamber effects in information spreading over political communi-\ncation networks,\u201d EPJ Data Science , vol. 8, no. 1, pp. 1\u201313, 2019.\n[36] \u201cGab.\u201d [Online]. Available: https://gab.com/\n[37] CNN, \u201cGab, the social network used by the pittsburgh suspect, has\nbeen taken of\ufb02ine,\u201d 2018. [Online]. Available: https://edition.cnn.com/\n2018/10/29/tech/gab-of\ufb02ine-pittsburgh/index.html\n[38] L. Lima, J. C. Reis, P. Melo, F. Murai, L. Araujo, P. Vikatos, and\nF. Benevenuto, \u201cInside the right-leaning echo chambers: Characterizing\ngab, an unmoderated social system,\u201d in 2018 IEEE/ACM International\nConference on Advances in Social Networks Analysis and Mining\n(ASONAM) . IEEE, 2018, pp. 515\u2013522.\n[39] M. K. Elhadad, K. F. Li, and F. Gebali, \u201cDetecting misleading informa-\ntion on covid-19,\u201d IEEE Access , vol. 8, pp. 165 201\u2013165 215, 2020.\n[40] R. F. Sear, N. Vel \u00b4asquez, R. Leahy, N. J. Restrepo, S. E. Oud, N. Gabriel,\nY . Lupu, and N. F. Johnson, \u201cQuantifying covid-19 content in the online\nhealth opinion war using machine learning,\u201d IEEE Access , vol. 8, pp.\n91 886\u201391 893, 2020.\n[41] J. Jiang, X. Ren, and E. Ferrara, \u201cSocial media polarization and echo\nchambers: A case study of covid-19,\u201d 2021.\n[42] E. Chen, K. Lerman, and E. Ferrara, \u201cTracking social media discourse\nabout the covid-19 pandemic: Development of a public coronavirus\ntwitter data set,\u201d JMIR Public Health and Surveillance , vol. 6, no. 2, p.\ne19273, 2020.\n[43] A. Clauset, C. R. Shalizi, and M. E. J. Newman, \u201cPower-law distri-\nbutions in empirical data,\u201d SIAM Review , vol. 51, no. 4, pp. 661\u2013703,\n2009.\n9\n[44] A. Wald, \u201cTests of statistical hypotheses concerning several parameters\nwhen the number of observations is large,\u201d Transactions of the\nAmerican Mathematical Society , vol. 54, no. 3, pp. 426\u2013482, 1943.\n[Online]. Available: http://www.jstor.org/stable/1990256\n[45] E. L. Kaplan and P. Meier, \u201cNonparametric estimation from incomplete\nobservations,\u201d Journal of the American Statistical Association , vol. 53,\nno. 282, pp. 457\u2013481, 1958.\n[46] W. Cota, S. C. Ferreira, R. Pastor-Satorras, and M. Starnini,\n\u201cQuantifying echo chamber effects in information spreading over\npolitical communication networks,\u201d EPJ Data Science , vol. 8, no. 1,\np. 35, Dec 2019. [Online]. Available: https://doi.org/10.1140/epjds/\ns13688-019-0213-9\n[47] Twitter, \u201cUpdates to our work on covid-19 vaccine misinformation.\u201d\n[Online]. Available: https://blog.twitter.com/en us/topics/company/\n2021/updates-to-our-work-on-covid-19-vaccine-misinformation.html\n[48] J. Weedon, W. Nuland, and A. Stamos, \u201cInformation operations and face-\nbook,\u201d Retrieved from Facebook: https://fbnewsroomus. \ufb01les. wordpress.\ncom/2017/04/facebook-and-information-operations-v1. pdf , 2017.\n[49] R. Peto and J. Peto, \u201cAsymptotically ef\ufb01cient rank invariant test proce-\ndures,\u201d Journal of the Royal Statistical Society. Series A (General) , vol.\n135, no. 2, pp. 185\u2013207, 1972.\n[50] Twitter, \u201cAcademic research program.\u201d [Online]. Available: https:\n//developer.twitter.com/en/solutions/academic-research\n10\n100101102103\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTimeN. of Posts\n100101102103104105\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTimeCumulative N. of Posts100101102103\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTimeN. of Users\n101102103104105\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nTimeCumulative N. of UsersGab\nTwitter\nFig. 6: Upper panel: Time series evolution of new posts (left)\nand users posting for the \ufb01rst time (right) on Gab and Twitter.\nLower panel: cumulative evolution of new posts (left) and\nusers posting of the \ufb01rst time (right) on Gab and Twitter.\nAPPENDIX A\nSUPPORTING INFORMATION\nHere we provide further details about the datasets employed\nfor the study, the cumulative and daily evolution of posts and\nnew users posting and the numerical results of the statistical\ntests performed. The description of the dataset is reported in\nSection A-A, the representation of the time series is reported in\nSection A-B while the results of the statistical test performed\nare described in Section A-C.\nA. Data breakdown\nHere we report the composition of the dataset for Gab\nand Twitter employed for the study, described in Table I and\nTable II respectively. Each dataset represents the number of\nunique posts, users and comments, as well as their engagement\nquantities over the different data collection and processing\nsteps. Due to Twitter API limitations, posts were initially\ngathered without any information about their number of com-\nments. The collection of this quantity was performed after the\ncategorization of the news outlets through the employment of\nspeci\ufb01c APIs provided from Twitter as part of its Academic\nResearch Program [50].\nB. Time Series Evolution\nHere we report the evolution of posts and new users\ncollected on Twitter and Gab during the analysis time. Figure\n6 shows the overall evolution of such quantities, while Figure\n7 shows the previous evolution after performed the categoriza-\ntion of the news outlets. Figure 6 describes a spike on Gab\nin the number of posts and users in correspondence of June.\nThis was due to the change of the collecting method. Indeed,\nthe lack of chronological order of posts reported on Gab APIs\nsince June required the gathering of all posts from the general\nstream, which was then \ufb01ltered by the search hashtags in order\nto be compliant with the data collection process.\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct100101102103\n100101102103\nTimeN. of Posts\nGab\nTwitter\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct101102103104105\n101102103104105\nTimeCumulative N. of Posts\nOutlet Leaning Questionable ReliableFig. 7: Evolution of posts based on their outlet leaning,\ncategorized as Questionable orReliable .\nUpper panel: Time series evolution of new posts (left) together\nwith its cumulative representation (right) on Gab.\nLower panel: Time series evolution of new posts (left) together\nwith its cumulative representation (right) on Twitter.\nC. Results of Comparison between power law distributions\nHere we report the information related to the comparison\nof the power law \ufb01ts described in Section IV-A by means of\nthe Wald test. Tables III - VI report the estimated coef\ufb01cients\nof each power law \ufb01t, i.e., ^\u000band^xmin, depending on the\nengagement and news outlet category. Furthermore, the results\nof the Wald test score applied on the previous engagement\ncategories are reported, together with the corresponding p-\nvalues.\n11\nCategory Overall Containing search hashtags Categorized Questionable Reliable\nNumber of Posts 205 458 130 864 83 784 49 772 34 012\nNumber of users 11 063 8 194 5 681 4 660 3 289\nNumber of Likes 234 255 117 281 72 435 53 154 19 281\nNumber of Reblogs 138 793 75 250 48 172 34 960 13 212\nNumber of Comments 42 993 22 287 14 165 9 489 4 676\nTABLE I: Composition of Gab Dataset where each column represents the quantities of collected posts collected during the\npreprocessing phase.\nCategory Overall Containing search hashtags Categorized Questionable Reliable\nNumber of Posts 2 668 286 1 110 030 244 430 25 121 219 309\nNumber of users 1 185 541 382 449 118 635 13 711 108 153\nNumber of Likes 18 610 555 5 885 562 1 422 629 141 273 1 281 356\nNumber of Reblogs 7 753 971 2 862 098 703 765 68 609 635 156\nNumber of Comments NA NA 30 262 8771 21 491\nTABLE II: Composition of Twitter Dataset where each column represents the quantities of collected posts collected during the\npreprocessing phase.\nLikes Reblogs\n^\u000b ^xmin ^\u000b ^xmin\nQuestionable 1.32 1 Questionable 1.31 1\nReliable 1.37 1 Reliable 1.33 1\nWald test score 0.22 Wald\u2019s test score 0.034\np-value 0.64 p-value 0.85\nTABLE III: Power law \ufb01ts of Likes and Reblogs for post consumption patterns on Gab, together with the result of Wald test\nbetween the scaling parameters of each outlet category.\nLikes Reblogs\n^\u000b ^xmin ^\u000b ^xmin\nQuestionable 1.52 1 Questionable 1.57 1\nReliable 1.55 1 Reliable 1.55 1\nWald test score 0.15 Wald\u2019s test score 0.05\np-value 0.70 p-value 0.83\nTABLE IV: Power law \ufb01ts of Likes and Reblogs for post consumption patterns on Twitter, together with the result of Wald\ntest between the scaling parameters of each outlet category.\nLikes Reblogs\n^\u000b ^xmin ^\u000b ^xmin\nQuestionable 1.81 1 Questionable 1.83 1\nReliable 1.83 1 Reliable 1.83 1\nWald test score 0.015 Wald\u2019s test score 0.0004\np-value 0.90 p-value 0.98\nTABLE V: Power law \ufb01ts of Likes and Reblogs for user consumption patterns on Gab, together with the result of Wald test\nbetween the scaling parameters of each outlet category.\nLikes Reblogs\n^\u000b ^xmin ^\u000b ^xmin\nQuestionable 3.33 1 Questionable 1.75 1\nReliable 2.21 1 Reliable 1.67 1\nWald test score 1286.34 Wald\u2019s test score 1.06\np-value <0.001 p-value 0.30\nTABLE VI: Power law \ufb01ts of Likes and Reblogs for user consumption patterns on Twitter, together with the result of Wald\ntest between the scaling parameters of each outlet category.\n12\nGabriele Etta Gabriele Etta received his MSc de-\ngree in Data Science from the University of Padua,\nItaly, in 2020. He is currently a Ph.D. student from\nSapienza University of Rome, Italy, working on Data\nDriven Modeling of Social Dynamics. His research\ninterests include complex networks, information dif-\nfusion, and computational social science.\nMatteo Cinelli Matteo Cinelli is a post-doc re-\nsearcher at Ca\u2019 Foscari, University of Venice and\nassociate researcher at ISC-CNR. His background is\nin Management Engineering and he obtained a PhD\nin Enterprise Engineering from the University of\nRome \u201cTor Vergata\u201d. His research interests include\nnetwork science, computational social science and\nbig data.\nMauro Conti Mauro Conti is Full Professor at the\nUniversity of Padua, Italy. He is also af\ufb01liated with\nTU Delft and University of Washington, Seattle.\nHe obtained his Ph.D. from Sapienza University of\nRome, Italy, in 2009. After his Ph.D., he was a Post-\nDoc Researcher at Vrije Universiteit Amsterdam,\nThe Netherlands. In 2011 he joined as Assistant\nProfessor the University of Padua, where he became\nAssociate Professor in 2015, and Full Professor in\n2018. He has been Visiting Researcher at GMU,\nUCLA, UCI, TU Darmstadt, UF, and FIU. He has\nbeen awarded with a Marie Curie Fellowship (2012) by the European Commis-\nsion, and with a Fellowship by the German DAAD (2013). His research is also\nfunded by companies, including Cisco, Intel, and Huawei. His main research\ninterest is in the area of Security and Privacy. In this area, he published\nmore than 400 papers in topmost international peer-reviewed journals and\nconferences. He is Area Editor-in-Chief for IEEE Communications Surveys &\nTutorials, and has been Associate Editor for several journals, including IEEE\nCommunications Surveys & Tutorials, IEEE Transactions on Dependable\nand Secure Computing, IEEE Transactions on Information Forensics and\nSecurity, and IEEE Transactions on Network and Service Management. He\nwas Program Chair for TRUST 2015, ICISS 2016, WiSec 2017, ACNS 2020,\nand General Chair for SecureComm 2012, SACMAT 2013, CANS 2021, and\nACNS 2022. He is Senior Member of the IEEE and ACM. He is a member\nof the Blockchain Expert Panel of the Italian Government. He is Fellow of\nthe Young Academy of Europe.\nAlessandro Galeazzi Alessandro Galeazzi obtained\nthe B.Sc. in Information Engineering in 2016 from\nthe University of Padua. In 2016 he enrolled in the\nM.Sc. course of ICT for Internet and Multimedia\nat the University of Padova and in 2017 he joined\nthe double degree program between National Taiwan\nUniversity and the University of Padova. In 2018 he\nreceived the M.Sc. in Communication Engineering\nfrom National Taiwan University and the M.Sc. in\nICT for Internet and Multimedia from the University\nof Padova. In 2018 he joined the Ph.D. course at\nthe University of Brescia. His interests include human behavior on online\nsocial media, information and misinformation spreading, and social feedback\nalgorithm effects on users\u2019 choices.\nWalter Quattrociocchi Walter Quattrociocchi is\nAssociate Professor at Sapienza University of Rome\nwhere he leads the Center of Data Science and\nComplexity for Society (CDCS. His research inter-\nests include data science, network science, cognitive\nscience, and data-driven modeling of dynamic pro-\ncesses in complex networks. His activity focuses on\nthe data-driven modeling of social dynamics such\nas (mis)information spreading and the emergence of\ncollective phenomena. Dr Quattrociocchi has pub-\nlished extensively in peer reviewed conferences and\njournals including PNAS. The results of his research in misinformation\nspreading have informed the Global Risk Report 2016 and 2017 of the\nWorld Economic Forum and have been covered extensively by international\nmedia including Scienti\ufb01c American, New Scientist, The Economist, The\nGuardian, New York Times, Washington Post, Bloomberg, Fortune, Poynter\nand The Atlantic). He published two books: \u201cMisinformation. Guida alla\nsociet `a dell\u2019informazione e della credulit `a\u201d (Franco Angeli) and \u201cLiberi di\nCrederci. Informazione, Internet e Post Verit `a\u201d with Codice Edizioni for the\ndissemination of his results.\nIn 2017 Dr Quattrociocchi was the coordinator of the round table on\nFake News and the role of Universities and Research to contrast fake\nnews chaired by the President of Italy\u2019s Chamber of Deputies Mrs Laura\nBoldrini. Since 2018 he is Scienti\ufb01c Advisor of the Italian Communication\nAuthority (AGCOM) and currently Member of the Task Force to contrast Hate\nSpeech nomianted by the Minister of Innovation. Professor Quattrociocchi is\nregularly invited for keynote speeches and guest lectures at major academic\nand other organizations, having presented among others at CERN, European\nCommission, the University of Cambridge, Network Science Institute, Global\nSecurity Forum etc.\nCarlo Michele Valensise Carlo Michele Valen-\nsise received in 2017 the M.S. degree in Physics\nfrom Sapienza University of Rome, and the Ph.D.\ndegree in Physics in 2021, working on ultrafast\nspectroscopy, and application of Arti\ufb01cial Intelli-\ngence to Optics experiments. Besides that, he was\nResearch Fellow of Ca\u2019 Foscari University of Venice\nin Data Science for Complexity and Computational\nSocial Science. He is currently post-doc researcher\nat Centro Ricerche Enrico Fermi in Rome, working\non Computational Social Science.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "News consumption and social media regulations policy", "author": ["G Etta", "M Cinelli", "A Galeazzi", "CM Valensise"], "pub_year": "2021", "venue": "arXiv preprint arXiv \u2026", "abstract": "Users online tend to consume information adhering to their system of beliefs and to ignore  dissenting information. During the COVID-19 pandemic, users get exposed to a massive"}, "filled": false, "gsrank": 249, "pub_url": "https://arxiv.org/abs/2106.03924", "author_id": ["izHUn34AAAAJ", "3qOq_28AAAAJ", "DK0tXAIAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:Vqbp-D4-6W4J:scholar.google.com/&output=cite&scirp=248&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D240%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Vqbp-D4-6W4J&ei=L7WsaN_xNZXUieoPmrax2A8&json=", "num_citations": 2, "citedby_url": "/scholar?cites=7991987453930612310&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Vqbp-D4-6W4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2106.03924"}}, {"title": "Assessing effectiveness of using internal signals for check-worthy claim identification in unlabeled data for automated fact-checking", "year": "2021", "pdf_data": "Assessing Effectiveness of Using Internal Signals for Check-Worthy Claim\nIdenti\ufb01cation in Unlabeled Data for Automated Fact-Checking\nArchita Pathak\nUniversity at Buffalo (SUNY)\nNew York, USA\narchitap@buffalo.eduRohini K. Srihari\nUniversity at Buffalo (SUNY)\nNew York, USA\nrohini@buffalo.edu\nAbstract\nWhile recent work on automated fact-checking\nhas focused mainly on verifying and explain-\ning claims, for which the list of claims is read-\nily available, identifying check-worthy claim\nsentences from a text remains challenging.\nCurrent claim identi\ufb01cation models rely on\nmanual annotations for each sentence in the\ntext, which is an expensive task and challeng-\ning to conduct on a frequent basis across mul-\ntiple domains. This paper explores methodol-\nogy to identify check-worthy claim sentences\nfrom fake news articles, irrespective of do-\nmain, without explicit sentence-level annota-\ntions. We leverage two internal supervisory\nsignals - headline and the abstractive sum-\nmary - to rank the sentences based on seman-\ntic similarity. We hypothesize that this rank-\ning directly correlates to the check-worthiness\nof the sentences. To assess the effectiveness\nof this hypothesis, we build pipelines that\nleverage the ranking of sentences based on ei-\nther the headline or the abstractive summary.\nThe top-ranked sentences are used for the\ndownstream fact-checking tasks of evidence\nretrieval and the article\u2019s veracity prediction\nby the pipeline. Our \ufb01ndings suggest that the\ntop 3 ranked sentences contain enough infor-\nmation for evidence-based fact-checking of a\nfake news article. We also show that while the\nheadline has more gisting similarity with how\na fact-checking website writes a claim, the\nsummary-based pipeline is the most promising\nfor an end-to-end fact-checking system.\n1 Introduction\nWith the rise of social media in recent years, it has\nbecome possible to disseminate fake news to mil-\nlions of people easily and quickly. An MIT media\nlab study (V osoughi et al., 2018) from two years\nago showed that false information goes six times\nfarther and spreads much faster than real informa-\ntion. Additionally, personalization techniques haveenabled targetting people with speci\ufb01c types of\nfake news based on their interests and con\ufb01rma-\ntion biases. In response, there has been an increase\nin the number of fact-checking organizations that\nmanually identify check-worthy claims and correct\nthem based on evidence (Graves and Cherubini,\n2016). However, a study shows that 50% of the\nlifetime spread of some very viral fake news hap-\npens in the \ufb01rst 10 minutes, which limits the ability\nof manual fact-checking - a process that takes a\nday or two, sometimes a week1. Automating any\npart of the fact-checking process can help scale up\nthe fact-checking efforts. Additionally, end-to-end\nautomation can also enable human fact-checkers\nto devote more time to complex cases that require\ncareful human judgment (Konstantinovskiy et al.,\n2021).\nEnd-to-end automated fact-checking systems in-\nvolve three core objectives - (1) identifying check-\nworthy claims, (2) verifying claims against authori-\ntative sources, and (3) delivering corrections/ expla-\nnations on the claims (Graves, 2018). The majority\nof the recent work focuses on veri\ufb01cation and ex-\nplanation objectives for which a list of claims is\nreadily available (Thorne et al., 2018; Thorne and\nVlachos, 2018; Augenstein et al., 2019; Atanasova\net al., 2020; Kazemi et al., 2021). Identifying\ncheck-worthy claims, which is a critical \ufb01rst step\nfor fact-checking, remains a challenging task.\nClaimBuster is the \ufb01rst work to target check-\nworthiness (Hassan et al., 2017). It is trained\non transcripts of 30 US presidential elections de-\nbates. Each sentence of the transcripts is anno-\ntated for three categories - non-factual sentence,\nunimportant factual sentence, and check-worthy\nfactual sentence. They then build classi\ufb01ers to\nclassify sentences into these three labels. Another\nclassi\ufb01cation-based approach is to predict whether\n1https://www.technologyreview.com/2021/05/03/1023908/machine-\nlearning-project-takes-aim-at-disinformation/arXiv:2111.01706v1  [cs.CL]  2 Nov 2021\nthe content of a given statement makes \u201dan asser-\ntion about the world that is checkable\u201d (Konstanti-\nnovskiy et al., 2021). This approach utilizes anno-\ntations for sentences extracted from subtitles of UK\npolitical shows. The models are trained to classify\nstatements into binary labels - claim or non-claim.\nFinally, a system called ClaimRank (Jaradat et al.,\n2018) aims to prioritize the sentences that fact-\ncheckers should consider \ufb01rst for fact-checking.\nClaimRank is trained on pre-existing annotations\non political debates from 9 fact-checking organiza-\ntions. This approach \ufb01rst classi\ufb01es the statement\nas check-worthy or not. The statements are then\nranked based on the probabilities that the model as-\nsigns to a statement to belong to the positive class.\nWhile these works are fundamental towards ap-\nproaching the problem of check-worthy claim iden-\nti\ufb01cation, the focus is only on a single domain (pol-\nitics). Additionally, the models rely on sentence-\nlevel human annotations, which is an expensive\ntask, challenging to conduct regularly for multiple\ndomains, and subject to personal bias. In this work,\nwe try to overcome these limitations by exploring\nthe effectiveness of using internal signals from un-\nlabeled data. We focus on fake news articles and\nexperiment with two types of internal signals for\noverall supervision - headline and abstractive sum-\nmary. We make two hypotheses regarding these sig-\nnals - \ufb01rst, these two elements of an article contain\nthe gist of the content. To support this hypothesis,\nwe evaluate the headline and the abstractive sum-\nmary against the manually written Snopes claims\nfor news articles. Claims that Snopes write con-\ntain the salient factual idea of the source article.\nSecond, sentences that are semantically close to\nthe headline or the summary are check-worthy. To\nassess this hypothesis, we experiment with end-to-\nend fact-checking pipelines. The pipelines lever-\nage the top-ranked sentences relevant to the head-\nline/summary for the downstream fact-checking\ntasks of evidence retrieval and veracity prediction.\nThe dataset used for these experiments contains\narticles from multiple domains, such as medical,\ncrime, politics, technology. Through comparative\nexperiments, we \ufb01nd that the top-3 ranked sen-\ntences contain enough information for evidence-\nbased fact-checking of a fake news article. We\nalso observe that the summary-based pipeline is\nthe most promising for an end-to-end automated\nfact-checking system2.\n2Code and data will be available on github upon accep-Table 1: ROUGE scores of generated summaries and\nheadline with the manually written Snope\u2019s claim (sam-\nple size = 1000 news article)\nModel ROUGE-1 ROUGE-L\nBART summary 9.70 70.03\nPEGASUS summary 9.77 7.32\nT5 summary 17.71 13.34\nHeadline 19.02 16.46\n2 Headline and Summary for\nCheck-Worthiness Identi\ufb01cation\nHypothesis: The headline and the abstractive sum-\nmary of the content contain the gist of the article.\nTo analyze this hypothesis, we leverage Snopes\ndataset3which contains metadata relevant to news\narticles on a variety of topics and Snope\u2019s verdict\non them. Snope is a popular fact-checking web-\nsite that has been working for debunking a wide\nvariety of online fake news since 19944. A typi-\ncal Snope\u2019s verdict usually consists of a manually\nwritten \u201cClaim\u201d which mentions the main gist of\na news article, a veracity rating, and the origin of\nthe claim. We sample 1000 articles from Snope\u2019s\ndataset and calculate ROUGE-1 and ROUGE-L\nscores to measure the similarity of headline and ab-\nstractive summary with manually written Snope\u2019s\nclaim. These scores are presented in Table-1. For\nabstractive summary generation, we compare the\nresults on three state-of-the-art transformer-based\nmodels - BART (Lewis et al., 2020), PEGASUS\n(Zhang et al., 2020), and T5 (Raffel et al., 2020).\nLeveraging Huggingface transformer library (Wolf\net al., 2020), we use \u201cbart-large-cnn\u201d model and\ntokenizer for BART implementation; for PEGA-\nSUS implementation, we use \u201cpegasus-reddit-tifu\u201d;\nand for T5 we have used \u201ct5-base\u201d. The generated\nsummary consists of 60-180 tokens.\nWhile abstractive summary is expected to cap-\nture the salient ideas of the article\u2019s content, the\nscores in Table-1 show that the headline has the\nmost gisting similarity with the manually written\nSnope\u2019s claim. This could also imply that Snope\u2019s\nclaim resembles the article\u2019s headline, probably be-\ncause the readers mostly remember the headline\nwhen searching for fact-checks on Snopes. Nev-\ntance.\n3https://www.kaggle.com/liberoliber/\nonion-notonion-datasets?select=snopes_\nphase2_clean_2018_7_3.csv\n4https://www.snopes.com/about/\nertheless, since the scores indicate that the head-\nline contains some amount of gist of the article,\nwe include it for further downstream experiments.\nAmong various summaries, the T5 summary outper-\nforms others on this metric. Therefore, we select\nthe T5 summary and the headline as the two ap-\nproaches to identify check-worthy sentences from\na news article.\n3 FACSYS: An End-to-end\nFact-Checking System\nHypothesis: Sentences that are semantically close\nto the headline or summary are check-worthy and\ncan be used for fact-checking.\nTo test this hypothesis, we build three separate\nend-to-end fact-checking pipelines - P1: FAC-\nSYS HL: check-worthy claim sentences are re-\ntrieved based on the headline of the article. P2:\nFACSYS T5: check-worthy claim sentences are\nretrieved based on the T5 summary of the article.\nP3: FACSYS HL+Summ : headline and summary\nare concatenated and used directly for the down-\nstream fact-checking tasks. The P3 pipeline is cre-\nated to check the effectiveness of using only the gist\nof the article for the fact-checking process and com-\nparing it with the other two pipelines. As shown\nin Figure-1, the pipelines consist of the following\nthree stages:\n1. Check-worthy claim sentences identi\ufb01ca-\ntion: Given an article Acontaining set of sentences\nsiwhere i2[1; n], we \ufb01rst use S-BERT(Reimers\nand Gurevych, 2020) to encode sifor all i, and the\ninternal signal headline/summary. We then rank\nthe sentences siby calculating the cosine distance\nbetween the encoding of each sentence and the in-\nternal signal - the lesser the distance, the better the\nranking. Through heuristic analyses of the con-\ntent\u2019s quality, we use the top 3 ranked sentences,\nfc1; c2; c3g, as check-worthy claim sentences. We\nobserved the relevance of the sentences to the super-\nvisory signals reduces for lower ranked sentences\nwhich may introduce noise in the model.\nf(c1; c2; c3g=Rank (sim cfSBERT (IS);\nSBERT (si)gn\ni=1)[: 3]g(1)\nwhere IS2fheadline; summary gis internal\nsignal. The check-worthy sentences fc1; c2; c3g\nare concatenated as Cand supplied as input to the\nevidence gathering stage of the P1 and P2 pipelines.C=c1\bc2\bc3 (2)\nFor the P3 pipeline, the headline and summary\nare concatenated and supplied directly to the evi-\ndence gathering stage.\n2. Evidence gathering: This stage retrieves\nevidence articles EAfrom the web. It \ufb01lters them\nbased on the date of publication and the credibility\nof sources. The query for web search is formulated\nthrough simple concatenation:\nquery =headline\bCfor pipelines P1 and P2,\n(3)\nquery =headline\bsummary for pipeline P3\n(4)\nThe \ufb01nal query string is cut short to 40 words\ndue to API limits. We use Bing Search API for\n\ufb01ring the query on the web to retrieve the top 35\narticles. The \ufb01ltering of the articles is based on two\nconditions: (1) the date of publication is within\nthe three months before and after Awas published,\nand (2) the article is from a credible source. For\nthe latter, we use the list of credible sources con-\ntaining 407 domains rated as \u201cLeast Biased\u201d by\nMedia Bias/Fact Check5. These sources have been\nacknowledged by the journalistic community as\nbeing factual and well-sourced. We also added a\nfew more left, left-center, right-center, and right\nnews sources to this list based on our own research.\nFor our experiments, we use at most three evidence\narticlesfEA 1; EA 2; EA 3g, for computational ef-\n\ufb01ciency. Finally, we extract sentences from each\nevidence article that are most semantically similar\nto the concatenated check-worthy claim sentences\nCand rank them using the same process as men-\ntioned in equation 1. Based on the heuristics used\nto select top 3 sentences as claim, we also use se-\nlect top 3 ranked evidence sentences for the next\nstage.\n3. Veracity Prediction: This task is similar to\nthe RTE task on fact-veri\ufb01cation of FEVER dataset\nde\ufb01ned by (Thorne et al., 2018). Given the concate-\nnated check-worthy claim sentences C, and three\nevidence sentences [e1; e2; e3]concatenated as E,\nthe main goal is to learn a classi\ufb01er,\ng:model (C; E)!y (5)\nwhere y2ffalse (0), partial true (1), true (2), NEI\n(3)g\n5https://mediabiasfactcheck.com/center/\nFigure 1: End-to-end fact-checking pipelines used to test the hypothesis: sentences that are semantically close to\nthe headline or summary are check-worthy and can be used for fact-checking an article.\n3.1 Datasets\nFigure 2: Label distribution of each of the three\npipelines for the veracity prediction stage.\nWe combine articles from two datasets for fact-\nchecking experiments: (1) Snopes dataset contain-\ning articles on various topics published from 1996-\n2018, and (2) DNF-300 dataset (Pathak et al., 2021)\ncontaining 300 articles from the 2016 US presiden-\ntial election. Both datasets contain news articles\nalong with fact-checking ratings. For the Snopes\ndataset, we kept only those articles that are labeled\nas \u2018true\u2019, \u2018mostly true\u2019, \u2018mixture\u2019, \u2018mostly false\u2019,\n\u2018false\u2019. We have grouped \u2018mostly true\u2019, \u2018mixture\u2019,\n\u2018mostly false\u2019 articles under the single label \u2018partial\ntrue\u2019 for our experiments. In the DNF-300 dataset,\nwe removed the articles labeled as \u201cOpinion\u201d. Ad-\nditionally, articles for which no evidence article\nwas found after evidence gathering stage were la-\nbeled as NEI. Figure-2 shows the label distribution\nfor articles after the evidence gathering stage for\neach of the three pipelines. Most articles for which\nno evidence was found (labeled as NEI) are for\npipeline P3, showing that the quality of query that\ncontains keywords from the abstractive summary\nis not good. Having keywords from check-worthyclaim sentences helps gather good evidence articles\nas indicated by the NEI label of pipelines P1 and\nP2.\n3.2 Models\nFor the \ufb01nal veracity prediction stage of the\npipeline, we use a simple baseline model as fol-\nlows:\nf:MLP (BERT (n))!y (6)\nwhere n = 500 words of the content of the article.\nWe use BERT (Devlin et al., 2019) to encode the\nwords, and the [CLS] token is supplied to the multi-\nlayer perceptron layer for 4-way softmax classi\ufb01-\ncation. Note that this classi\ufb01cation is only based\non the content of the article, irrespective of the ev-\nidence. For evidence-based classi\ufb01cation, we use\nthe following models:\n1. BERT Concat (Zhou et al., 2019): for each\npair(EA; C ), this approach concatenates evidence\nsentences EwithC. BERT is used to perform\nthe natural language inference (NLI) prediction\nfor the \ufb01nal veracity label. Hence, as per BERT\u2019s\nrequirement, a separator is used between EandC\nfor the NLI task.\n2. KGAT (CorefBERT BASE ) (Ye et al., 2020):\nKGAT (Liu et al., 2020) conducts a \ufb01ne-grained\ngraph attention network with kernels, developed\nfor FEVER dataset. While the original KGAT\nmodel uses BERT, we use this model with\nCorefBERT BASE in our experiments. CorefBERT\n(Ye et al., 2020) is a novel language representation\nmodel that can capture the coreferential relations\nin context. The KGAT with CorefBERT BASE has\nshown a signi\ufb01cant improvement over KGAT with\nBERT BASE on the FEVER dataset.\nTable 2: Evaluation of fact-checking pipelines for veracity prediction. Summary based pipeline (pipeline 2) out-\nperforms all other pipelines using a simple BERT Concat model.\nPipelines Models F1 LA\nBaseline (Content-Classi\ufb01cation) BERT 43.57 47.74\nP1: FACSYS HLBERT Concat 64.86 68.3\nKGAT (CorefBERT BASE ) 60.04 63.39\nKGAT (CorefRoBERTa LARGE ) 64.08 66.55\nP2: FACSYS T5BERT Concat 67.31 70.34\nKGAT (CorefBERT BASE ) 61.65 65.43\nKGAT (CorefRoBERTa LARGE ) 62.24 67.39\nP3: FACSYS HL+SUMMBERT Concat 51.36 54.06\nKGAT (CorefBERT BASE ) 44.95 50.81\nKGAT (CorefRoBERTa LARGE ) 54.08 54.44\n3. KGAT (CorefRoBERTa LARGE ) (Ye\net al., 2020): The current state-of-the-art\nmodel on the FEVER dataset is KGAT with\nCorefRoBERTa LARGE . CorefBERT, which incorpo-\nrates coreference information in distant-supervised\npre-training, contributes to verifying if the claim\nand evidence discuss the same mentions, such as a\nperson or an object.\nWe use the same con\ufb01gurations as speci\ufb01ed in\nthe previous papers for these models. Train, vali-\ndation, and test sets are created by taking 80:10:10\nsplits. All models are trained for three epochs.\n3.3 Evaluation Metrics\nThe of\ufb01cial evaluation metrics6for the FEVER\nRTE task include Label Accuracy (LA) and\nFEVER score. In our work, since we do not have\nground-truth evidence (whether a sentence is an ev-\nidence or not), we discard the FEVER score metric\nand only use classi\ufb01cation metric F1 along with\nLA.\n3.4 Results and Discussion\nAs shown in Table-2, incorporating evidence im-\nproves the classi\ufb01cation results by over 20% as\ncompared to the baseline content-based classi\ufb01-\ncation. This suggests that converting the entire\narticle into an embedding might be lossy. Focusing\nonly on the check-worthy claim sentences and rel-\nevant evidence helps build embedding well-suited\nto learn the article\u2019s main idea for the classi\ufb01cation\ntask. Additionally, results on pipeline P3 show that\nthe evidence articles are not at par as compared to\n6https://github.com/shef\ufb01eldnlp/fever-scorerpipelines P1 and P2. The reason behind this could\nbe because P3 uses the generated summary in the\nquery string. The generated summary may not con-\ntain the same entities as mentioned in the original\ntext. Hence, leading to substandard quality of web\narticles in the evidence gathering stage.\nFurther, since the headline of the article is shown\nto have the best ROUGE scores with the manu-\nally written claims by Snopes (Table-1), it is ex-\npected that the check-worthy sentences identi\ufb01ed\nusing the headline will have better performance in\ntheevidence gathering and the veracity prediction\nstages. However, the P2 pipeline based on the sum-\nmary outperforms all other pipelines in predicting\nveracity labels. This indicates that the T5-based\nabstractive method generates a high-quality sum-\nmary that helps in determining better ranking of\ncheck-worthy claim sentences from the content of\nthe article. While our evaluation shows that this\nranking has potential in automated fact-checking\nof article without any sentence-level annotations,\nit can also assist human fact-checkers in identify-\ning important sentences from the article for their\nmanual evaluation. In terms of models, a simple\nBERT Concat model obtains better results than\nthe heavy, graph attention-based models, achieving\n\u001923% improvement on the baseline F1 score and\nover 30% improvement on the baseline LA score.\n4 Conclusion\nWe explore identi\ufb01cation of check-worthy claim\nsentences from a news article without any sentence-\nlevel annotation. We show experiments leveraging\ntwo internal signals - headline and abstractive sum-\nmary of the article. We test two hypotheses - (1)\nheadline/abstractive summary contains the gist of\nthe article, and (2) sentences of the content seman-\ntically relevant to the headline/summary are check-\nworthy claim sentences. We build fact-checking\npipelines for this purpose and show that the check-\nworthy claim sentences identi\ufb01ed based on the sum-\nmary of the article are adequate for downstream\ntasks of evidence gathering and veracity predic-\ntion of the article. Our experiments use articles\nranging on a variety of topics and associated with\nfour veracity labels. For future work, we aim to\nuse the abstractive-summary-based methodology\nfor fact-checking of other types of textual data -\nonline discourse, debate transcripts, etc. We be-\nlieve that leveraging topic detection along with\nthe summary-based check-worthiness identi\ufb01cation\ncan help overcome the issues and biases introduced\ndue to sentence-level manual annotations.\nReferences\nPepa Atanasova, Jakob Grue Simonsen, Christina Li-\noma, and Isabelle Augenstein. 2020. Generating\nfact checking explanations. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics , pages 7352\u20137364, Online. As-\nsociation for Computational Linguistics.\nIsabelle Augenstein, Christina Lioma, Dongsheng\nWang, Lucas Chaves Lima, Casper Hansen, Chris-\ntian Hansen, and Jakob Grue Simonsen. 2019.\nMultiFC: A real-world multi-domain dataset for\nevidence-based fact checking of claims. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP) , pages 4685\u20134697, Hong\nKong, China. Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171\u20134186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nD Graves. 2018. Understanding the promise and limits\nof automated fact-checking.\nLucas Graves and Federica Cherubini. 2016. The rise\nof fact-checking sites in europe.\nNaeemul Hassan, Fatma Arslan, Chengkai Li, and\nMark Tremayne. 2017. Toward automated fact-\nchecking: Detecting check-worthy factual claimsby claimbuster. In Proceedings of the 23rd\nACM SIGKDD International Conference on Knowl-\nedge Discovery and Data Mining , KDD \u201917, page\n1803\u20131812, New York, NY , USA. Association for\nComputing Machinery.\nIsraa Jaradat, Pepa Gencheva, Alberto Barr \u00b4on-Cede \u02dcno,\nLlu\u00b4\u0131s M `arquez, and Preslav Nakov. 2018. Claim-\nRank: Detecting check-worthy claims in Arabic\nand English. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associa-\ntion for Computational Linguistics: Demonstrations ,\npages 26\u201330, New Orleans, Louisiana. Association\nfor Computational Linguistics.\nAshkan Kazemi, Zehua Li, Ver \u00b4onica P \u00b4erez-Rosas, and\nRada Mihalcea. 2021. Extractive and abstractive ex-\nplanations for fact-checking and evaluation of news.\nInProceedings of the Fourth Workshop on NLP for\nInternet Freedom: Censorship, Disinformation, and\nPropaganda , pages 45\u201350, Online. Association for\nComputational Linguistics.\nLev Konstantinovskiy, Oliver Price, Mevan Babakar,\nand Arkaitz Zubiaga. 2021. Toward automated\nfactchecking: Developing an annotation schema and\nbenchmark for consistent automated claim detection.\nDigital Threats: Research and Practice , 2(2).\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics , pages 7871\u20137880, Online. Association\nfor Computational Linguistics.\nZhenghao Liu, Chenyan Xiong, Maosong Sun, and\nZhiyuan Liu. 2020. Fine-grained fact veri\ufb01cation\nwith kernel graph attention network. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics , pages 7342\u20137351, On-\nline. Association for Computational Linguistics.\nArchita Pathak, Mohammad Abuzar Shaikh, and Ro-\nhini K. Srihari. 2021. Self-supervised claim iden-\nti\ufb01cation for automated fact checking. CoRR ,\nabs/2102.02335.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring\nthe limits of transfer learning with a uni\ufb01ed text-to-\ntext transformer. Journal of Machine Learning Re-\nsearch , 21(140):1\u201367.\nNils Reimers and Iryna Gurevych. 2020. Making\nmonolingual sentence embeddings multilingual us-\ning knowledge distillation. In Proceedings of the\n2020 Conference on Empirical Methods in Natu-\nral Language Processing . Association for Computa-\ntional Linguistics.\nJames Thorne and Andreas Vlachos. 2018. Automated\nfact checking: Task formulations, methods and fu-\nture directions. In Proceedings of the 27th Inter-\nnational Conference on Computational Linguistics ,\npages 3346\u20133359, Santa Fe, New Mexico, USA. As-\nsociation for Computational Linguistics.\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFEVER: a large-scale dataset for fact extraction\nand VERi\ufb01cation. In Proceedings of the 2018\nConference of the North American Chapter of\nthe Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long\nPapers) , pages 809\u2013819, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R \u00b4emi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020.\nTransformers: State-of-the-art natural language pro-\ncessing. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing:\nSystem Demonstrations , pages 38\u201345, Online. Asso-\nciation for Computational Linguistics.\nDeming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng\nLi, Maosong Sun, and Zhiyuan Liu. 2020. Corefer-\nential Reasoning Learning for Language Represen-\ntation. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Process-\ning (EMNLP) , pages 7170\u20137186, Online. Associa-\ntion for Computational Linguistics.\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and\nPeter Liu. 2020. PEGASUS: Pre-training with ex-\ntracted gap-sentences for abstractive summarization.\nInProceedings of the 37th International Conference\non Machine Learning , volume 119 of Proceedings\nof Machine Learning Research , pages 11328\u201311339.\nPMLR.\nJie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng\nWang, Changcheng Li, and Maosong Sun. 2019.\nGEAR: Graph-based evidence aggregating and rea-\nsoning for fact veri\ufb01cation. In Proceedings of the\n57th Annual Meeting of the Association for Compu-\ntational Linguistics , pages 892\u2013901, Florence, Italy.\nAssociation for Computational Linguistics.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Assessing effectiveness of using internal signals for check-worthy claim identification in unlabeled data for automated fact-checking", "author": ["A Pathak", "RK Srihari"], "pub_year": "2021", "venue": "arXiv preprint arXiv:2111.01706", "abstract": "While recent work on automated fact-checking has focused mainly on verifying and explaining  claims, for which the list of claims is readily available, identifying check-worthy claim"}, "filled": false, "gsrank": 251, "pub_url": "https://arxiv.org/abs/2111.01706", "author_id": ["2MvNbL0AAAAJ", "Uttu9kkAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:NBIyA2jJDrEJ:scholar.google.com/&output=cite&scirp=250&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D250%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=NBIyA2jJDrEJ&ei=MrWsaIHlAr_SieoPzJnloAQ&json=", "num_citations": 4, "citedby_url": "/scholar?cites=12758356242954588724&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:NBIyA2jJDrEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2111.01706"}}, {"title": "Specious sites: Tracking the spread and sway of spurious news stories at scale", "year": "2024", "pdf_data": "Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale\nHans W. A. Hanley\nhhanley@cs.stanford.edu\nStanford UniversityDeepak Kumar\nkumarde@cs.stanford.edu\nStanford UniversityZakir Durumeric\nzakir@cs.stanford.edu\nStanford University\nAbstract \u2014Misinformation, propaganda, and outright lies pro-\nliferate on the web, with some narratives having dangerous\nreal-world consequences on public health, elections, and indi-\nvidual safety. However, despite the impact of misinformation,\nthe research community largely lacks automated and program-\nmatic approaches for tracking news narratives across online\nplatforms. In this work, utilizing daily scrapes of 1,334 unre-\nliable news websites, the large-language model MPNet, and\nDP-Means clustering, we introduce a system to automati-\ncally identify and track the narratives spread within online\necosystems. Identifying 52,036 narratives on these 1,334 web-\nsites, we describe the most prevalent narratives spread in\n2022 and identify the most influential websites that originate\nand amplify narratives. Finally, we show how our system\ncan be utilized to detect new narratives originating from\nunreliable news websites and to aid fact-checkers in more\nquickly addressing misinformation. We release code and data\nat https://github .com/hanshanley/specious-sites.\n1. Introduction\nOver the last decade, spurious, misleading, and out-\nright false information has spread throughout online ecosys-\ntems [1]. Digital misinformation has influenced elec-\ntions [2], promoted bogus health cures leading to unnec-\nessary deaths [3], and incited mob violence throughout the\nworld [4], [5]. Worsening the problem, misleading stories\nhave been shown to spread at over ten times the rate of true\ninformation [6].\nThe security community, likening disinformation to an\nattack similar to spam, phishing, and censorship [7], [8],\nhas applied a range of methodologies to ameliorate its\nspread [9]\u2013[14]. For example, by examining features similar\nto those used to identify spam accounts, researchers have\nidentified networks of state-propagandists throughout Reddit\nand Twitter [11], [15]. However, despite these advances,\nmost investigations into false narratives remain limited in\nscope and retroactive, primarily conducted through time-\nconsuming, qualitative approaches [16], [17]. To make fun-\ndamental progress in combating the threat posed by dis-\ninformation, we argue that the security community must\nbuild approaches for tracking the spread of false narratives\nglobally and in real time.In this work, we present an NLP-based approach for\nprogrammatically identifying and tracking the spread of\nnarratives and stories across unreliable news websites and\nsocial media platforms. Between January 1 and November 1,\n2022, we crawl a set of 1,334 known misinformation, state-\npropaganda, biased, and otherwise unreliable news websites\nas well as two fringe forums, 8kun and 4chan. We extract\npassages from these news articles, which we embed using an\nMPNet model [18] fine-tuned with contrastive learning on\nthe semantic textual similarity task. Employing a modified\nversion of the nonparametric algorithm DP-Means, we clus-\nter these embeddings to identify specific narratives/stories.\nOur approach enables us to isolate and track 52,036 nar-\nrative threads that spread on unreliable news websites during\n2022. We do not attempt to determine whether individual\nstories are factual, which is a qualitative task that ML-\nbased approaches have failed to reliably achieve. Rather,\nwe track all narratives from these specious sites across\nonline ecosystems and quantify these websites\u2019 influence.\nWe find, unsurprisingly, that many of the most prominent\nnarratives in 2022 concerned the Russo-Ukrainian War and\ninflation, with websites like southfront.org, rt.com, and ze-\nrohedge.com dominating these topics. Identifying which\nwebsites play outsized roles in originating andamplifying\nnarratives across our set of unreliable news websites, we find\nthat a website\u2019s popularity has a small correlation with its\nability to propagate narratives with seemingly minor web-\nsites like infostormer.com or barenakedislam.com playing\nmassive roles in popularizing stories.\nNext, we investigate how our method can be used to\nfocus limited investigative resources on the most pernicious\nnarratives. We show that, like an early detection alarm,\nour approach can identify when new narratives emerge.\nComparing when popular false narratives appeared to when\nthree major organizations (AP News, Reuters, and Politifact)\nfact-checked them, we show that our system can prioritize\nchecking misleading narratives months before their peak\nwhen they first start to gain traction. We hope that this\ntype of real-time visibility can enable fact-checkers and\njournalists to more efficiently track and respond to new,\npotentially problematic narratives as soon as they emerge.\nSimilar to past large-scale empirical analysis in the\nsecurity community ( e.g., [19]\u2013[28]), our work shows that\na programmatic approach to tracking narratives at scale\nuncovers a set of online propagation patterns that wouldarXiv:2308.02068v3  [cs.SI]  3 Feb 2024\nNews Article Daily Document StreamArticle T ext and Date\nExtraction \nCalculate Passage\nEmbeddingsUpdate Cluster\nKeywords with\nPointwise Mutual\nInformation and Extract\nBART SummaryNews\nArticle\nWebsites\nSeparate Document into\nPassages Narrative 1\nNarrative 3 Narrative 2\nUpdate Cluster Centers or Create New\nCluster based on Semantic Similarity\nto Current ClustersCommon\nCrawl Website\nScrapes, RSS\nfeeds\nNarrative 4New Narrative02-24-22Russia\nattacked...\nUkraine\nresponded ...\nRussia\nattacked...\nFigure 1: Our pipeline for identifying and labeling narrative clusters from the daily publications of unreliable news websites.\nhave been difficult to uncover through manual, small-scale\ninvestigations. We also discuss how having a continuous\ntracking process can help analysts uncover and track the\nmost worrisome influence operations. We stress that our\napproach does not make factual judgments on individual\nstories or on the reliability of websites. Indeed, our sys-\ntem takes as input websites that human experts previously\nlabeled as unreliable. Rather, our approach provides the\ncritical, real-time visibility into the spread of news narratives\nonline that human experts need to effectively identify and\nrespond to misinformation.\n2. Background\nUnreliable information often spreads through multiple\navenues as individual users, state-supported actors, and even\nentire platforms participate in the dissemination of falsities.\nUnreliable information can take the form of misinformation ,\ndisinformation ,fake-news ,propaganda , among others [29].\nMisinformation is any information that is false or inaccurate\nregardless of the author\u2019s intent [29]\u2013[32]. The term \u201cfake\nnews\u201d is often used interchangeably with misinformation.\nDisinformation, in contrast, is inaccurate information spread\nwith the deliberate purpose to mislead [29], [33]. Similar to\ndisinformation, propaganda refers to \u201cdeliberate, systematic\ninformation campaigns, usually conducted through mass\nmedia forms\u201d regardless of whether the information is true\nor false [29]. A single narrative can be considered disinfor-\nmation when spread by a state actor and as misinformation\nwhen spread by users. Individual websites can have mixtures\nof misinformation, disinformation, propaganda, and true\ninformation [34]. We refer readers to Jack et al. [29] for\na more detailed taxonomy.\n3. Methodology\nThe goal of our work is to programmatically track how\nnarratives spread amongst \u201c unreliable \u201d news websites. In\nthis section, we define a narrative and then describe how wecollect news articles and extract narratives. We emphasize\nthat while we focus on websites known to publish mislead-\ning, false, or state-controlled narratives, we do not assume\nthat all narratives from these sites are \u201cmisinformation\u201d.\nIndeed, many stories are not [34]. We do not label new\nnarratives as \u201cmisinformation\u201d, which is a qualitative, inves-\ntigative task. As such, we refer to only individual stories that\nhave been previously identified by experts as misinformation\nordisinformation , as false. We label the websites that spread\nthese verified false narratives as unreliable .\n3.1. Narrative Definition\nTracking misinformation narratives requires a high de-\ngree of specificity. Unlike traditional topic modeling, which\nseeks to identify themes and/or statistical word correla-\ntions [35]\u2013[37], misinformation tracking requires distin-\nguishing between specific narratives and stories. Within this\nwork, we define a narrative/story using the same definition\nas the Event Registry [38], Hanley et al. [39], and Miranda\net al. [40]: collections of documents that seek to address\nthe same event orissue . For example, two example events\nin the Event Registry are \u201cFelix Baumgartner\u2019s jump from\na helium balloon on October 14, 2012\u201d and \u201cbombings\nduring the Boston Marathon on April 15, 2013.\u201d Within our\ndataset, events constitute ideas like \u201celection fraud in the\n2020 US election\u201d and \u201cthe COVID-19 vaccine leading to\nmass death.\u201d An example of two ideas\u2014while related\u2014that\nwe do not consider to be the same narrative are \u201cUS funds\nUkrainian War\u201d and \u201cRussia attacks Ukraine.\u201d\n3.2. System Architecture\nAs shown in Figure 1, our system (1) collects news\narticles from unreliable news sites through web scraping on\na daily basis and from Common Crawl data [41]; (2) parses\nout the news articles, extracting article text and segment-\ning articles into constituent passages; and (3) embeds text\npassages into a shared subspace utilizing the large language\nmodel MPNet [18]. To track the spread of narratives, our\nsystem then (4) clusters semantically similar content using\nDP-means, and (5) extracts keywords and generates sum-\nmaries of the clusters.\nWe opt for this LLM-based approach because our system\nneeds to track specific narratives. Prior approaches that\nutilize simpler, more generic keyword-based topic modeling\ntools like LDA fall short in identifying specific narratives\nacross different news websites [42]. Furthermore, keyword-\nbased approaches often rely on pre-existing expert knowl-\nedge of disinformation campaigns and largely cannot adapt\nto the rapid pace of the news ecosystem [43]. By utilizing\nthis new approach, our system can update and track news\nstories without a priori or domain-specific knowledge in an\nefficient and fine-grained manner.\nFor this paper, we use data from January 1 to November\n1, 2022, but we emphasize that our system runs continu-\nously, enabling us to identify new narratives in near real\ntime. In the rest of this section, we detail each step of our\nmethodology and validate that our system captures specific\nand coherent narratives.\n3.3. Data Collection\nOur study is based on scraping and parsing articles from\nwebsites known to spread unreliable information.\nUnreliable News Websites. We collect articles from\n2,514 candidate websites that have been labeled as \u201cpo-\nlitically biased\u201d, \u201cmisinformation\u201d, \u201cdisinformation\u201d, \u201ccon-\nspiracy\u201d, \u201cfake news\u201d, or \u201cstate-based propaganda\u201d by past\nstudies (Iffy Index [44], OpenSources [45], Politifact [46],\nSnopes [47], Melissa Zimdars [48], and Hanley et al. [49]).\nThis list includes politically-biased websites like daily-\nwire.com, conspiracy-oriented websites like x22report.com,\nand state-propaganda outlets like rt.com.\nScraping Articles. We crawl websites using Colly1and\nHeadless Chrome orchestrated with Python Selenium. For\neach website, we collect the homepage and linked pages\ndaily from January 1 to November 1, 2022. To ensure full\ncoverage of each site\u2019s published articles, we additionally\ngather the HTML pages indexed by Common Crawl [50]\nfor each site during this same period. We emphasize that\nunder 1% of articles were found only in the Common\nCrawl dataset, indicating that our scrapes found the vast\nmajority of published content on each site. We then parse\neach HTML page to collect the published articles using\nthe Python libraries newspaper3k andhtmldate . There\nwere several instances ( e.g., sputniknews.com) where this\napproach failed; in these cases, we built custom parsers\nbased on site-specific HTML elements.\nOf our 2,514 candidate websites, 1,334 were operational\nand published articles during our 2022 measurement period\n(many sites that spread unreliable information are short-\nlived [12], [51]). Altogether, we collect 1,915,449 articles.\nWe provide the URL data to researchers upon request.\n1. https://github.com/gocolly/collyGloVe BERT USE All-MPNet Our Model\n0.580 0.464 0.749 0.840 0.856\nTABLE 1: Evaluation\u2013based on Pearson Correlation\u2014of our\nMPNet-contrastive model and other models on the SemEval STS-\nbenchmark [54]. Data for GloVe [55], BERT [56], the Universal\nSentence Encoder (USE) [57] is from Reimers et al. [58].\n0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80\nCosine Similarity Threshold0.00.10.20.30.40.50.60.70.80.91.0Metric on STS22-ENPrecision\nRecall\nF1-Score\nFigure 2: Evaluation of our model\u2019s precision, recall, and F1scores\non the English portion of the SemEval22 dataset [61] (using 3.0 as\nthe cut-off for the two articles being about the same event [53]).\n3.4. Preprocessing and Embedding\nTo prepare data for embedding, we first remove any non-\nEnglish articles using the Python langdetect library and\nthen remove URLs, emojis, and HTML tags. We then seg-\nment each article into its constituent paragraphs by splitting\narticle text based on newline and tab characters. Then, in line\nwith prior work, we subsequently divide these paragraphs\ninto 100-word article passages [39], [52], [53].\nAfter preprocessing, we embed the constituent passages\nthat make up each article. Embedding passages rather than\nentire articles is in line with prior work [52] for topic\nanalysis as articles often address multiple narratives but\nembeddings should represent only a single narrative or\nidea [39], [52], [53]. We thus embed passages to capture\ncontext while also obtaining an embedding for the (often)\none narrative/idea present within the passage.\nWe specifically embed passages using a version of MP-\nNet that we fine-tune on the semantic text similarity (STS)\ntask [39], [59] using unsupervised contrastive learning for\nsentence embeddings as specified in Gao et al. [60] on a\nrandom assortment of passages from January 2022 from\nour websites. We perform this fine-tuning with the default\nhyperparameters (learning rate 3\u00d710\u22125, batch size=128,\nand 1M examples) specified in Gao et al. and by freezing\nall but the last two layers of a public version of MPNet.2\nSee Appendix A for details. This ensures that our model\nis attuned to the language present on our set of websites.\nAs seen in Table 1, despite not being trained on the Se-\nmEval STS Benchmark [54], a benchmark for measuring the\nquality of text embeddings, our model outperforms the fine-\ntuned publicly released version of MPNet. After fine-tuning\nour model, from the 1.9M articles, we embed 25,337,614\npassages (10 hours on an Nvidia RTX A6000).\n2. https://huggingface .co/sentence-transformers/all-mpnet-base-v2\n0.45 Thresh. 0.50 Thresh. 0.55 Thresh. 0.60 Thresh.\n80.6%\u00b16.33% 85 .7%\u00b18.29% 94 .7%\u00b16.94% 96 .29%\u00b17.12%\nTABLE 2: Evaluation of the precision of embedded messages hav-\ning the same narrative at various thresholds utilizing 2000 random\npassages. We provide 95% Normal confidence intervals.\nPASSAGE 1: The MaraLago search warrant served Monday was part of an ongoing Justice Department investigation\ninto the discovery of classified White House records recovered from Trump\u2019s home earlier this year. The Archives\nhad asked the department to investigate after saying 15 boxes of records it retrieved from the estate included classified\nrecords.\nPASSAGE 2: The FBI raided Donald Trump\u2019s estate in MaraLago using the pretext of Trump supposedly violating\nthe Presidential Records Act by keeping documents after he left office to initiate a siege to terrorize Joe Biden\u2019s\nchief political rival.\nFigure 3: Passage pair at our selected similarity threshold (0.60).\n3.5. Comparing Semantic Content\nWe compare the semantic content of our embeddings\nutilizing cosine similarity [18]. Prior work [39], [62], [63]\nhas found that a cosine similarity threshold of 0.60\u20130.80\ncan be used to determine whether two pieces of text are\nabout the same topic. However, to ensure that we select a\nminimum threshold that accurately models whether passages\nare about the same narrative as defined in Section 2, we:\n(1) benchmark our model on the English portion of the\nMultilingual SemEval2022 dataset [61], and (2) manually\nvalidate the coherency of a random sample of passage pairs.\nAs seen in Figure 2, on the SemEval22 [61] dataset,\nas the similarity threshold increases, our model\u2019s precision\nin determining whether two passages are about the same\nnarrative increases while the corresponding recall decreases,\nreaching a peak F1score near 0.60 cosine similarity.\nTo confirm this result, we perform a manual evaluation\nby selecting 2,000 random passage pairs from our dataset\nwith similarities at varying thresholds and have two experts\ndetermine whether the passage pairs are about the same\nnarrative (per our definition), determining the corresponding\nprecision at various thresholds. We calculate a Cohen\u2019s\nKappa of 0.80 between our two raters, indicating a high\ndegree of agreement. As seen in Table 2, as the threshold\nused to determine similarity increases, we see an increase in\nprecision. We choose a threshold of 0.60 (as a lower bound)\nas it has acceptable manually calculated precision (96.29%)\nandF1score on the SemEval22 [61] dataset (0.809). We\npresent an example passage pair at our selected threshold\nof 0.60 in Figure 3 and at other thresholds in Appendix B.\n3.6. Identifying Narratives\nTo identify narrative/stories in our dataset, we cluster\nour passage embeddings using cosine similarity and DP-\nMeans, a non-parametric version of K-means (Appendix C).\nPrior work has identified narratives using a similar high-\nlevel approach [17], [39], but our methodology differs in\nseveral ways based on our unique requirements. First, our\napproach must be highly scalable . While Hanley et al. [39]\nutilize a BERTopic-based method [64], we find that this does\nnot scale to the approximately 100K embeddings per day in\nour dataset. Second, we need to update our clusters on a\ndaily basis as new news articles are published, which pastapproaches like BERTopic do not allow. Third, since the\nnumber of narratives is unknown a priori , the methodology\nmust automatically infer the number of clusters, which\nprecludes parametric algorithms like incremental K-means\nclustering.\nWe specifically adapt Dinari et al.\u2019s efficient and paral-\nlelizable version of DP-Means [65] (Appendix C), making\nfour alterations. First, we cluster embeddings based on their\ncosine similarity rather than their Euclidean distance. We\nset\u03bb= 0.60(the minimum cosine distance an embedding\ncan be from a cluster before a new cluster is created) to\nensure that clusters have high semantic similarity, informed\nby our prior manual investigation (Table 2). Second, we\nperform partial fits over each day\u2019s worth of news article\nembeddings. Specifically, on each day throughout 2022, we\nembed that day\u2019s passages and update the previous day\u2019s\ncluster centers ( i.e.,we update our given clusters on a daily\nbasis with the DP-Means algorithm until convergence uti-\nlizing that day\u2019s article embeddings). Third, we remove the\nrandom reinitialization of clusters added by Dinari et al. [65]\nfrom the algorithm; we find that this step often led to\nover-clustering given that many website passages are slight\nvariations of each other. Lastly, we note that rather than\nrelying on Dinari et al.\u2019s released code, we re-implement\ntheir algorithm to take advantage of the matrix multipli-\ncation speedups that come from utilizing a GPU (3 times\nspeedup with an Nvidia RTX A6000).\nFor this work, we utilize the clusters from November 1,\n2022. From January 1 to November 1, clustering all em-\nbeddings required the equivalent of 1.5 days. We filter out\nclusters where 50% or more of the passages are from only\none website ( e.g., author bios) or there were fewer than\n25 articles to remove spam, similar to the methodology\nspecified by Leskovec et al. [17]. After this removal, we\nidentify 52,036 narrative clusters. Each article\u2019s passages are\npart of an average of 5.12 narrative clusters (4.0 median).\nOn average, each embedding has an average similarity of\n0.688 to its cluster center, which shows that our embeddings\nare assigned to clusters with high semantic similarity. Each\nnarrative cluster has an average cosine similarity of 0.016\nwith other identified narrative clusters, which indicates that\nour approach identified distinct narratives.\n3.7. Interpretability and Narrative Specificity\nWe create human-interpretable identities for our narra-\ntive clusters using two approaches. First, we extract the most\ndistinctive and representative keywords of the cluster us-\ning pointwise mutual information [66], [67] (Appendix D).\nPointwise mutual information (PMI) is an information-\ntheoretic measure for discovering the associations amongst\ndifferent entities [67]. As in Kessler et al. [68], rather than\nfinding the pointwise mutual information between different\nwords, we utilize the measure to understand individual\nwords\u2019 association with narrative clusters. In this manner,\nwe find the set of words most distinctive to/associated\nwith each cluster. Second, after identifying the top five\npassages closest ( i.e., with the largest cosine similarity) to\nPassages\nNarr. Keywords Checked Prec.\n1 kiril, patriarch, orthodox, church, putin 427 99.53%\n2 abbott, texas, border, greg, lone 500 99.40%\n3 sinema, manchin, filibuster, kyrsten, senate 500 100.00%\n4 hurricane, atlantic, storm, tropic, season 500 99.80%\n5 balloon, leaflet, korea, korean, north 100 100.00%\n6 monkeypox, york, nyc, outbreak, city 385 96.62%\n7 johnson, resign, poll, boris, tory 500 95.20%\n8 antibody, monoclon, regeneron, omicron, variant 302 100.00%\n9 fauci, anthoni, kennedy, pharma, gate 384 100.00%\n10 nucleic, acid, test, shanghai, province 500 99.40%\n11 finland, sweden, nato, deploy, nuclear 133 100.00%\n12 windfall, profit, tax, oil, barrell 379 99.21%\n13 energy, europe, crisis, price, electric 500 100.0%\n14 pen, macron, le, french, marin 500 99.20%\n15 protein, spike, mrna, inject, cell 173 100.00%Passages\nNarr. Keywords Checked Prec.\n16 peterson, suspend, rubin, jordan, elliot 252 100.00%\n17 norwegian, ellingsen, feminist, lesbian, norway 108 100.00%\n18 lantsman, trudeau, melissa, mp, swastika 127 100.00%\n19 polio, 1979, eradicate, virus, disease 109 99.08%\n20 humanitarian, aid, shelter, refuge, relief 500 100.00%\n21 kiev, coup, nationalist, neonazi, nazi 143 98.60%\n22 noah, flood, ark, wives, genesis 155 90.97%\n23 fda, prescribe, offlabel, drug, treatment 195 100.00%\n24 refugee, asylum, persecute, seeker, migrant 192 100.00%\n25 swift, sanction, bank, sberbank, vtb 500 100.00%\n26 orban, fidesz, viktor, hungary,victory 469 99.60%\n27 unvaccined, infection, recipe, covid19, covid 167 100.00%\n28 nuclear, closer, brink, cuban, war 364 96.43%\n29 alexandra, pelosi, footage, nancy, daughter 100 100.00%\n30 civilian, kabul, afghan, drone, strike 500 94.00%\nPrec. 98.90%\nTABLE 3: Evaluation of the precision of our narrative analysis model on a random set of 30 stories/narratives derived from the articles\nin our dataset. Keywords were extracted utilizing pointwise mutual information. We checked all available passages in cases where there\nare fewer than 500 passages in the story/narrative cluster.\nthe center of the cluster, we use an off-the-shelf state-of-the-\nart BART [69] summarization tool from Huggingface fine-\ntuned on news data to summarize the cluster. We utilize this\napproach because while keywords provide an identifiable\n\u201chandle\u201d for each cluster, keywords typically do not fully\ncapture the full semantic meaning or the specificity of our\nnarrative clusters. For example, the auto-generated summary\nfor the cluster with keywords Age, Pfizer, Booster, Children,\nVaccine is:\nThe U.S. Food and Drug Administration FDA in Octo-\nber 2021 authorized the PfizerBioNTech COVID vaccine\nfor children 5 through 11. Children under 5 remain the\nonly segment of the US population that isn\u2019t eligible for\none of the COVID vaccines.\nwhere a random passage from the cluster states:\nAs of now, U.S. children aged five and older are eligible\nfor the COVID19 vaccine, though only Pfizer\u2019s shot has\nreceived authorization. The Pfizer jab is also available\nas a booster for children 12 and older.\nHowever, the auto-generated summary for a similar cluster\nwith keywords Children, Risk, Adult, Covid, Immunity is:\nChildren have a minuscule risk of COVID mortality.\nThere is very limited safety data for vaccines from the\ntrials on children. If the risk of adverse reactions is the\nsame as for adults, the harms outweigh the risks.\nwhere a random passage from the cluster states:\nCOVID poses no danger to children. They have a sta-\ntistically zero chance of dying from that disease. The\nCOVID shots, however, are already linked to innumer-\nable adverse reactions, and their longterm side effects\nare unstudied.\nThis illustrates the need for further specificity using sum-\nmarization to understand the narratives being spread. We\nprovide several additional examples in Appendix F.\n3.8. Validating Narrative Clusters\nWe evaluate our narrative clustering technique by vali-\ndating whether a random sample of 500 passages (or max-\nimum present) for a random set of 30 narrative clusters\nare about the same narrative using the methodology out-\nlined in Section 3.5. Our methodology identifies coherentstory/narrative clusters with an overall 98.9% precision and\na minimum precision of 90.97% for Topic 22 (Table 3).\n3.9. Ethical Considerations\nOur analysis is based on analyzing publicly posted news\narticles. We limit the load that each news site experiences\nby checking for new articles daily at a maximum rate of one\nrequest every 10 seconds. We further follow the guidelines\nas outlined by prior work for scraping data [5], [19]. The\nhosts that we scan from are identifiable through WHOIS,\nreverse DNS, and an HTTP landing page explaining how to\nreach us if they would like to be removed from the study.\nWe received no requests from websites to opt-out.\n3.10. Positionality Statement\nThe misinformation websites we study often covered\ncontentious political issues including election denial, the\nRusso-Ukrainian War, and US abortion rights. As US-based\nEnglish-speaking researchers, we inevitably bring some bi-\nases to discussing these issues. We attempt to remain as neu-\ntral as possible. We do not take any stance on political issues\nand when labeling specific stories as being misinformation,\nwe rely fully on cited prior work from other researchers\nand/or news groups.\n4. Narratives on Unreliable News Sites\nIn the last section, we presented and validated our\nmethodology for programmatically extracting the narra-\ntives promoted by unreliable news websites. Here, we\ndescribe the most prolific narratives, trace three misin-\nformation/propaganda stories, and derive communities of\ntopically-related websites.\n4.1. The Largest Narratives\nWe start by analyzing the narratives most prolifically\ncovered by our set of unreliable news sites in 2022. As can\nNarr. Keywords Articles Websites Most Profilic Domains Auto-Generated Summary\n1 ukraine, troop, kyiv,\nrussian, donbas9,579 378 express.co.uk (626),\nsouthfront.org (523),\ndailymail.co.uk (464)The Russian military has not been able to fully encircle and neutralize the\ngrouping of Kyiv s forces in the Donbass so far. At the same time, the Russians\nmanaged to liberate a number of important territories and towns.\n2 zelensky, volodymyr,\nukraine, kyiv, president8,705 392 dailymail.co.uk (548),\nnypost.com (466), ex-\npress.co.uk (411)Ukrainian President V olodymyr Zelensky has accused Russian forces of com-\nmitting genocide in his country. He also slammed the West.\n3 index, consumer, infla-\ntion, cpi, price7,240 444 shorenewsnetwork.com\n(963), theep-\nochtimes.com (514),\ndailymail.co.uk (336)The consumer price index climbed 0.6 percent from a month before. Compared\nwith January of last year, consumer prices are up 7.5 percent. The Consumer\nPrice Index increased 9.1 percent in the year through June.\n4 musk, elon, twitter,\nplatform, tesla7,196 335 nypost.com (364),\ndailymail.co.uk (281),\ntheepochtimes.com\n(222)Tech Mogul and Tesla Boss Elon Musk is wellknown for his wisecracks and\nwitty posts he shares on Twitter. Musk has been critical of social media,\nparticularly Twitter, over its enforcement of rules that critics say targets\nconservative voices.\n5 germany, europe, oil,\nsanction, energy6,812 362 express.co.uk (355),\nzerohedge.com (323),\nrt.com (283)Russia has been hit by sweeping sanctions on its economy and trade since\nthe start of Putin\u2019s war in Ukraine. But measures by EU governments have\nnot targeted oil and gas contracts with Moscow. Europe is heavily reliant on\nRussia for its energy needs.\nTABLE 4: Top 5 narratives\u2014by number of articles\u2014in our 2022 dataset.\nChina recently staged livefiremilitary drills in the airspace and waters surrounding Taiwan from August 4 to August 7. The action marked a significant escalation in Beijing s military actions toward the island nation and came in direct response to a visit to TaipeiTech Mogul and Tesla Boss Elon Musk is wellknownfor his wisecracks and witty posts he shares on Twitter. Musk has been critical of social media, particularly Twitter, over its enforcement of rules that critics say targets conservative voiceThe consumer price index climbed 0.6 percent from a month before, the Department of Labor said Thursday. Compared with January of last year, consumer prices are up 7.5 percent. Last week, the Labor Department said the consumer priceThis is in tandem with educators growing obsession with teaching sexual and gender identity curriculum to students at as young of an age as possible. This gender fluid indoctrination of children worldwide is a pedophile push to justify pushing adult sexual thinking and expressionsThe Russian military has not been able to fully encircle and neutralize the grouping of Kyiv s forces in the Donbass so far. At the same time, the Russians managed to liberate a number ofimportant territories and towns\nWe are on the precipice of a global food crisis. The global food shortage is about to explode into a fullblowncrisis that will lead to pockets of mass starvation and will even affect firstworldcountries around the globe.The Supreme Court on Friday overturned Roe v. Wade, effectively ending recognition of a constitutional right to abortion. This gives individual states the power to allow, limit, or ban the practice altogether.On Monday evening, a draft opinion document was leaked from the Supreme Court in the United States saying that the court has voted to overturn Roe v Wade. In May, Politico published a leaked draft of a U.S. Supreme Court opinionFormer President Donald Trump said in a statement Monday that his home at MaraLagoin Palm Beach, Florida, was \"raided\" by \"a large group of FBI agents\" According to Trump, the raiding agents even entered his personal safeI suspect that leftists are not fully opposed to the idea of gun ownership as they often pretend to be. I think they would actually liketo retain their own gunsif possible, they just don't want people like you and I to haveWhite House press secretary Jen Psaki issued a statement following the press conference attempting to clean up Biden s mess. Psaki addressed the situation in a subsequent interview.United States Customs and Border Patrol reported a record 2.3 million migrant encounters in the fiscal year 2022. The figure is far higher when counting getaways and illegal aliens who remain undetected.\nBoris Johnson has been told to resign by Conservative party members. Johnson was facing pressure from members of his own party to resign.Cases of inflammation of the heart called myocarditis or pericarditis have been reported very rarely after both the Pfizer and Moderna COVID19 vaccines. These cases have been seen mostly in younger men and within several days\nChina Covid19 Lockdowns Hit Factories, Ports in Latest Knock to Supply Chains. The prospect of more Chinese supply logjams is heightening fears that the disruptions will ripple through the global economy.\nFigure 4: Article volume of popular narratives from January 1, 2022, to November 1, 2022.\nbe seen in Table 4, the most popular narratives concerned the\nRusso-Ukrainian War, inflation, and Elon Musk\u2019s criticism\nand later acquisition of the social media platform Twitter.\nAs can be seen in Figure 4, we observe peaks in coverage\nof specific stories, as well as narratives that maintained\nconsistent coverage throughout our study. For example,\nstories about abortion peak both before the US Supreme\nCourt decision (Dobbs v. Jackson) about federal abortion\nrights was leaked and following the official decision [70].\nIn contrast, a narrative about the EU\u2019s role in NATO saw a\nsteady stream of articles throughout the year, with a slight\nuptick following the Russian invasion of Ukraine. Analyzing\nthe specific news sites that post about each narrative, wefind that many Russian-backed and controlled websites [71]\nsuch as rt.com and southfront.org, in addition to several\nUK-based tabloids express.co.uk and dailymail.co.uk were\nthe most prolific in writing about the Russian invasion\nof Ukraine (Narratives 1, 2, 5 in Table 4). This largely\nmatches previous studies of the Russian-controlled media\nin influencing discussions on the war [39].\n4.2. Misinformation/Propaganda Case Studies\nAs seen in the last section, many of the most common\nnarratives are mainstream news topics. However, one of our\ngoals is to track the spread of misinformation narratives.\nIn this section, we show that our technique is capable of\ntracking known unreliable narratives by investigating the\nevolution of one confirmed propaganda and two confirmed\nmisinformation stories.\nUkrainian Nazis (Keywords: Azov, Battalion, Regiment,\nFar-right, Ukraine): One of the most prominent propaganda\nnarratives utilized by Russian media in justifying the Rus-\nsian Federation\u2019s invasion of Ukraine was that the Ukrainian\ngovernment was controlled by \u201cneo-nazis\u201d [66]. This is\ndespite Ukraine\u2019s relatively low level of antisemitism [72].\nOur method is able to find that even before the Russian\ninvasion of Ukraine on February 24, 2022, there were heavy\nreferences to Nazism in Ukraine by Russian-controlled or\ninfluenced outlets. For example, on January 27, gloablre-\nsearch.ca penned:3\nIf we are to draw parallels between the current crisis\non the Ukraine border and WW2 we should compare\nthe Neo-Nazi ideology which dominates Ukrainian na-\ntionalism with that of Nazi Germany.\nHowever, as seen in Figure 5, the major increase in the num-\nber of articles promoting this narrative occurred in the weeks\nprior to the Russo-Ukrainian War (specifically jumping in\nvolume on February 8, 2022). The most prominent websites\nthat pushed this narrative were unsurprisingly known Rus-\nsian propaganda outlets including globalresearch.ca (68 arti-\ncles), sputniknews.com (55), and rt.com (46). Beyond these\nknown pro-Russian websites, we find US-based websites\nlike veteranstoday.com (64 articles), sott.net (62), and the-\ngatewaypundit.com (21) repeating this narrative.\nKiller Covid-19 Vaccines (Keywords: Vaccine, Safe, Ad-\nverse, MRNA, Effect): One prominent misinformation nar-\nrative about COVID-19 that we identify is that COVID-19\nvaccines are \u201ckiller vaccines\u201d and a major cause of death\naround the world. For example on lewrockwell.com, an\nauthor wrote:4\nWhatever they may be, these vaccines are most definitely\nnot safe. We can very clearly see this from the explo-\nsion of reports of death to the Vaccine Adverse Event\nReporting System (VAERS), which coincided with the\nintroduction of the Covid injections in late 2020.\nAs seen in Figure 5, stories about \u201ckiller vaccines\u201d have\nremained prominent throughout 2022, increasing in popu-\nlarity several times throughout the year. The sites that most\nprominently echoed this narrative were theepochtimes.com\n(53 articles), pandemic.news (36), and vaccines.news (31).\nThis is consistent with prior studies [73], [74].\n2020 Election Denialism (Keywords: Fraud, Election, 2020,\nIrregular, V oter): The narrative that the presidential elec-\ntion was stolen and that current President Biden is illegit-\nimate [75] spread throughout social media and was a key\n3. https://web .archive .org/web/20220127162858/https://\nwww .globalresearch .ca/war-fever-air-west-confuses-russia-nazi-germany/\n5768335\n4. https://web .archive .org/web/20220120061509/https://\nwww .lewrockwell .com/2022/01/vasko-kohlmayer/dangerous-and-deadly-\nover-1000-scientific-studies-referencing-injuries-and-deaths-from-covid-\nvaccines/\nThe Azov Regiment is reviled by Putin s Kremlin as a band of Russia-hating neo-Nazis. The battalion denies allegations of fascism, Nazism and racism and says Ukrainians from various backgrounds serve in Azov.There is no evidence the new vaccines are safe, while there is limited evidence that they may be more harmful than earlier COVID19 vaccines. In the absence of human testing, there is no way to truly predict their safety.Voting fraud is real. And there was a lot of it in the 2020 election. Since 2020, the election system in the United States has been plagued with overwhelming reports of fraud on almost every level.Figure 5: V olume over time for case-study narratives of Ukrainian\nNazis, Killer COVID-19 vaccines, and 2020 Election Denialism.\naspect of the January 6, 2021 attack on the US Capitol [5].\nWe see in our dataset that this false narrative maintained\na substantial presence amongst unreliable news sites (Fig-\nure 5). For example, the fringe website thetrumpet.com\nwrote on January 6, 2022:5\nThe insurrection hoax is a cover-up for the stolen\nelection\nThe websites that most prominently repeated this narra-\ntive were welovetrump.com (143 articles), thegatewaypun-\ndit.com (55), and votefraud.news (14).\n4.3. Communities of Unreliable News Websites\nTo begin to capture the semantic communities that exist\nwithin the unreliable news ecosystem, we utilize each web-\nsite\u2019s distinct distribution of articles among our discovered\nset of 52,036 stories/narratives. To compare each website\u2019s\nreporting choices and semantic content, we represent each\nwebsite\u2019s narratives as a multinomial distribution. For ex-\nample, if we had three narratives (rather than 52.0K) and\na website that wrote five articles about Narrative 1, four\narticles about Narrative 2, and one article about Narrative\n3, the website\u2019s distribution would be [0.5, 0.4, 0.1]. We\ndo this for all 52,036 narratives and 1,334 websites, thus\nrepresenting each website as a 52,036-dimensional vector of\nprobabilities. We then use Jensen-Shannon Divergence [76]\n(detailed in Appendix E) to compare websites\u2019 probabil-\nity vectors. For example, the JS-Divergence of rt.com and\nsputniknews.com.com, two Russian state-sponsored web-\nsites [39], [71] is 0.412 while the JS-Divergence of rt.com\nand nypost.com, a US-based website, is 0.605.\nAfter calculating each website\u2019s narrative similarities\nusing JS-Divergence with every other website in our dataset,\nwe build an undirected graph with edge weights based on\nthese values ( i.e.,an edge between a website PandQis\ngiven a weight of 1\u2212JS(P||Q)) where JS(P||Q)is the\nJS-Digerence between websites PandQ. We determine\ncommunities of websites using the Louvain clustering al-\ngorithm [77]. Louvain clustering identified 3 communities,\n5. https://web .archive .org/web/20220107091002/https://\nwww .thetrumpet .com/stephen-flurry/25070-the-insurrection-hoax-is-\na-cover-up-for-the-stolen-election\nand from these communities, we qualitatively identified\nthe corresponding three semantic communities: US-focused ,\nInternational , and Conspiratorial . We label these clusters\nbased on the top topics found within each cluster, with the\nUS-focused cluster writing about Abortion and the Biden\nAdministration, the International cluster about the Russo-\nUkrainian War, and the Conspiratorial cluster heavily writ-\ning about COV1D-19 vaccines.\nUS-focused Community. 696 websites fall into our US-\nfocused community including sites like dailywire.com, bre-\nitbart.com, and welovetrump.com. The most common nar-\nrative in the community concerned the US Supreme Court\nDobbs v. Jackson decision to overturn the 1973 Roe v. Wade\ndecision that provided the federal right to abortion (Key-\nwords: Roe, Abortion, Wade, Overturn, 1973). To further\nexamine the role of this website community, particularly in\nregard to its most prominent narrative, we collect a larger set\nof narratives that more broadly relate to the topic of abortion\nby aggregating all 121 narrative clusters whose centers have\na 0.50 similarity to the Abortion/Roe cluster.\nWe consider a website to originate a narrative if they\npublished an article about the narrative on the first day\nthat the narrative appeared in our dataset (more than one\nwebsite can originate a narrative). Altogether, we find that\n66.1% of Roe/Abortion narratives originated from this com-\nmunity, with the website rawstory.com originating the most\nRoe/Abortion narratives (24). In addition to originating most\nof the narratives about abortion, these websites contributed\n77.0% of the articles on the 121 narratives about abor-\ntion; theepochtimes.com (1,330 articles) and breitbart.com\n(1,264 articles) had the most. Largely expected, many In-\nternational websites such as dailymail.co.uk (1,104 articles)\nand Conspiratorial websites like evil.news (65 articles) also\npicked up on these US-centered political narratives, evidenc-\ning the spread of stories from this community.\nInternational Community. 405 websites fall into our In-\nternational community including rt.com and dailymail.co.uk.\nThe top story was one of our top overall narratives: the Rus-\nsian invasion of Ukraine (Keywords: Ukraine, Kyiv, Troop,\nRussian, Donbas). We gather a larger set of 432 narrative\nclusters that discuss the Russo-Ukrainian War using the\nsame methodology outlined in the prior section.\nWe find that 42.4% of Russo-Ukrainian War narra-\ntives started from the International community of websites\nwith 4.6% of these narratives specifically starting on nine\npro-Russian propaganda websites [71]. Globalresearch.ca\n(19 narratives, tt.com (9 Ukraine narratives) and tass.com\n(10 Ukraine narratives) originate the most narratives among\nthese Russian websites. We again find that this cluster\nof websites is responsible for a large portion (56.12%)\nof articles about the war. Again, largely expected, other\nwebsites such as nypost.com (2,934 articles) or treason.news\n(32 articles) write extensively about the conflict as well.\nConspiratorial Community. 233 websites belong to our\nConspiratorial community, including popular sites known\nfor spreading conspiracy theories about QAnon and COVID-\n19 [5], [49] like unz.com, qresear.ch, and radiopatriot.net.Unsurprisingly, the top narrative within this community con-\ncerns COVID-19 (Keywords: Children, Risk, Adult, Covid,\nImmunity). We gather a more extensive set of narrative clus-\nters that discuss the COVID-19 and/or COVID-19 vaccines\nusing the same methodology outlined before; altogether\ngathering 146 narratives. Most prominently, the website\nchildrenshealthdefense.org, the nonprofit run by Robert F.\nKennedy Jr., wrote about nearly every COVID-19 story in\nour dataset (1,774 articles).\nWe find that our set of Conspiratorial websites originate\n38.3% of narratives about COVID-19, the most prominent\nof these being nvic.org (15 COVID narratives) and covidref-\nerence.com (11 COVID narratives). We note that COVID-19\nnarratives originated not only from these websites but from\nour International (28.0%) and US-focused cluster (33.3%)\nas well. However, despite this, we find that this cluster is\nonly responsible for 17.8% of the articles about COVID-19.\nThis shows that COVID-19 narratives came from multiple\nsources and spread throughout the misinformation news\necosystem.\n5. Originating and Amplifying Narratives\nAs seen throughout the last section, several websites play\ndominant roles in perpetuating and promoting certain types\nof stories. In this section, we identify and quantify which\nwebsites have pivotal roles in originating and amplifying\nnarratives throughout the ecosystem of unreliable websites.\nAs before, we consider a website to originate a narrative if it\npublished an article about the narrative on the first day that\nthe narrative appeared in our dataset (more than one website\ncan originate a narrative). We consider a website to have\namplified (i.e., increased the popularity of) a narrative if it\n(1) posted an article about the narrative before the narrative\npeaked in popularity, (2) did not originate the narrative, and\n(3) if the posted article appeared in the first 15% of the\ntotal volume of that given narrative. We utilize the 15%\ncutoff as it ensures that the vast majority of a narrative\u2019s\narticles have not been published yet ( i.e., the story has not\ndramatically increased in popularity already), allowing us to\nobserve how amplification affects the narrative\u2019s popularity.\nThis threshold is consistent with prior work [17].\nWith this approach, we investigate how the popularity\nof a website influences its effectiveness in originating and\namplifying narratives using website rank data provided by\nthe Google Chrome User Report (CrUX) from October\n2022, which Ruth et al. showed to be the most reliable\nwebsite popularity metric [78].\n5.1. Originating Narratives\nTo measure the efficacy of websites in originating narra-\ntives, we perform a correlational comparison of the number\nof external non-origin articles that are written about a given\nnarrative in the week after a given website originated a\nnarrative vs. the number of non-origin external articles that\nare written in the week after origination if the website did\nnot originate the narrative but still eventually wrote about\nCrUX Wtd. Ext. Cohen\u2019s To Peak Cohen\u2019s\nDomain Rank Art. \u2206 D \u2206(Days) D\ndailymail.co.uk <1K 0.301 0 .679 -20.23 -0.376\nexpress.co.uk <1K 0.161 -0.026\u2217-7.86 0 .040\u2217\nbreitbart.com 1K\u20135K 0.388 1 .075 -54.89 -0.877\nnypost.com 1K\u20135K 0.362 0 .819 -45.47 -0.736\nzerohedge.com 1K\u20135K 0.180 0 .628 -34.18 -0.614\nthegatewaypundit.com 5K\u201310K 0.300 1 .045 -62.32 -0.980\nnewsmax.com 5K\u201310K 0.306 0 .832 -32.58 -0.690\ndailystar.co.uk 5K\u201310K 0.193 0 .213\u2217-41.12 -0.540\nredstate.com 10K\u201350K 0.502 1 .413 -69.0-1.129\ntwitchy.com 10K\u201350K 0.454 1 .390 -71.89 -1.318\ndailywire.com 10K\u201350K 0.453 1 .345 -73.45 -1.316\ntheconservativetreehouse.com 50K\u2013100K 0.628 1 .969 -79.13 -1.612\nhalturnerradioshow.com 50K\u2013100K 0.475 1 .578 -51.22 -0.987\njustthenews.com 50K\u2013100K 0.811 1 .206 -71.62 -1.218\n\u2013 \u2013 \u2013 \u2013 \u2013 \u2013CrUX Wtd. Ext. Cohen\u2019s To Peak Cohen\u2019s\nDomain Rank Art. \u2206 D \u2206(Days) D\ntherightscoop.com 100K\u2013500K 0.684 1 .758 -82.53 -1.791\nweaselzippers.us 100K\u2013500K 0.674 1 .519 -81.88 1 .786\u2217\ntoddstarnes.com 100K\u2013500K 0.576 1 .475 -70.96 -1.434\nnationalfile.com 500K\u20131M 0.406 1 .306 -70.21 -1.341\ngellerreport.com 500K\u20131M 0.359 1 .259 -141.96 -2.279\u2217\nussanews.com 500K\u20131M 0.300 1 .238 -121.92 -2.567\ninfostormer.com 1M\u20135M 0.763 2.514 -154.65 -4.212\nprojectveritas.com 1M\u20135M 0.617 2 .112 -62.98 -1.199\npacificpundit.com 1M\u20135M 0.711 1 .711 -11.10 -2.139\nanonhq.com 5M\u201310M 1.152 1.614 -93.18 -2.703\nredstatenation.com 5M\u201310M 0.502 1 .219 -71.13 -1.218\nthejeffreylord.com 5M\u201310M 0.554 1 .185 -61.55 -1.133\nthefreedomtimes.com 10M\u201350M 0.530 1 .610 -58.44 -1.174\npresscorp.org 10M\u201350M 0.554 1 .460 -85.46 -1.462\ntrueviralnews.com 10M\u201350M 0.218 0 .598 -52.85 -0.746\nTABLE 5: We present the weighted average change (and effect-sizes) in the number of external articles that are published by a random\nsubset of 100 external domains in the week after the website publishes the narrative ( i.e., articles not written by the origin domain)\nand the average change in time (and effect-sizes) for a story to peak in popularity when a website originates a narrative. We utilize\nthe Mann-Whitney U-test for significant differences in the means. After applying the Bonferroni correction, we conclude that a value is\nsignificant if the p-value is <0.0017 (i.e., 0.05/29). We star values that are not significant .\nCrUX Wtd. Ext. Cohen\u2019s To Peak Cohen\u2019s\nDomain Rank Art. \u2206D \u2206(Days) D\ndailymail.co.uk <1K 0.626 1 .546 -14.59 -0.102\nexpress.co.uk <1K 0.513 0 .745 -16.52 -0.187\nbreitbart.com 1K\u20135K 0.821 1 .726 -21.73 -0.176\nnypost.com 1K\u20135K 0.739 1 .617 -16.55 -0.076\nzerohedge.com 1K\u20135K 0.531 1 .188 -28.57 -0.291\nthegatewaypundit.com 5K\u201310K 0.754 1 .519 -23.13 -0.192\nnewsmax.com 5K\u201310K 0.649 1 .331 -25.75 -0.261\nrawstory.com 5K\u201310K 0.540 1 .080 -16.03 -0.192\nredstate.com 10K\u201350K 0.657 1 .955 -21.22 -0.171\nbabylonbee.com 10K\u201350K 1.726 1 .750 -31.20 -0.380\u2217\ntwitchy.com 10K\u201350K 1.111 1 .698 -18.52 -0.095\nrumormillnews.com 50K\u2013100K 1.427 2 .035 -17.12 0.164\u2217\nbeforeitsnews.com 50K\u2013100K 0.894 1 .989 -32.46 -0.312\nbrighteon.com 50K\u2013100K 0.520 1 .700 -40.79 -0.479\n\u2013 \u2013CrUX Wtd. Ext. Cohen\u2019s To Peak Cohen\u2019s\nDomain Rank Art. \u2206 D \u2206(Days) D\npopulistpress.com 100K\u2013500K 1.425 1 .861 -43.32 -0.389\u2217\nhenrymakow.com 100K\u2013500K 1.148 1 .831 -17.18 -0.190\u2217\nsgtreport.com 100K\u2013500K 0.593 1 .739 -27.24 -0.320\nussanews.com 500K\u20131M 0.972 2 .084 -9.08 -0.113\npoliticalflare.com 500K\u20131M 2.011 1.917 -1.86 -0.022\u2217\nyournews.com 500K\u20131M 1.064 1 .762 -39.37 -0.434\namericafirstreport.com 1M\u20135M 0.611 2.406 -16.84 -0.157\nsurvivethenews.com 1M\u20135M 0.897 1 .890 -26.40 -0.260\nbarenakedislam.com 1M\u20135M 1.518 1 .670 -32.95 -0.207\npatriotjournal.org 5M\u201310M 1.129 1 .864 -15.68 -0.064\u2217\nlegitgov.org 5M\u201310M 1.156 1 .530 -26.13 -0.263\u2217\ngopdailybrief.com 5M\u201310M 0.813 1 .444 -31.51 -0.377\nroguereview.net 10M\u201350M 0.976 1 .378 -20.78 -0.222\u2217\ntrueviralnews.com 10M\u201350M 0.815 1 .310 -27.59 -0.315\nthefreedomtimes.com 10M\u201350M 0.641 1 .187 -14.31 -0.006\u2217\nTABLE 6: e present the weighted average change (and effect-sizes) in the external articles that are published by a random subset of 100\nexternal domains for a given domain\u2019s amplified narratives ( i.e.,articles not written by the origin domain) and the average change in\ntime (and effect-sizes) for a story to peak in popularity when a website amplifies a narrative. We utilize the Mann-Whitney U-test for\nsignificant differences in the means. After applying the Bonferroni correction, we conclude that a value is significant if the p-value is\n<0.0017 (i.e., 0.05/29). We star values that are not significant .\nthat narrative. We note that for this analysis, we weight the\nnumber of articles by the log inverse of its CrUX popularity\nranking [79], [80] to ensure that we do not consider an\narticle from a highly popular website such as breitbart.com\nthe same as from a relatively obscure website such as\nwelovetrump.com.\nTo ensure each website has a marked effect on the full\nunreliable news ecosystem and to improve the robustness\nof our approach, we utilize a bootstrapping procedure [81]\n(B= 250 ) to measure the influence of each website by\ntaking a random subset of 100 websites in each bootstrap\nand then measuring the weighted increase in the number\nof articles across this set of a random set of 100 websites.\nWe provide the average effect size (Cohen\u2019s D)/statistical\nmeasure of the increase in articles and the p-value to check\nfor the significance (using Mann-Whitey U-tests) for the\nchange in the number of external articles in Table 5. For this\nsection, we limit our analysis to websites that consistently\noriginate articles by only considering websites with at least\n25 instances of originating an article.\nWe observe only a small correlation (Pearson correlation\n\u03c1= 0.229) between a website\u2019s popularity and its ability to\noriginate and perpetuate narratives amongst other unreliable\nnews websites. For example, considering express.co.uk and\ndailymail.co.uk, two tabloids known to engage in sensation-\nalism and biased reporting with the highest CrUX popular-ities, while dailymail.co.uk is fairly effective at originating\nnarratives (Cohen\u2019s D = 0.679), express.co.uk is one of the\nworst at originating new narratives (Cohen\u2019s D = -0.026).\nFurther, a seemingly unpopular website, infostormer.com,\nis one of the best at propagating narratives it originates to\nother sites. This illustrates many different types of websites\ncan originate and propagate narratives in the misinformation\nnews ecosystem. Infostormer.com, with a header labeled\nthe\u201cJewish Problem\u201d , writes heavily sensationalist and\nantisemitic perspectives on the news that is taken up by other\nwebsites. For example, after writing an article on how the\nCNBC news host Jim Cramer was promoting Meta stock,6\nthis news story was later covered by more popular websites\nlike activistpost.com7and hannity.com.8\nIn addition to quantifying each website\u2019s efficacy in orig-\ninating narratives, we determine how quickly after a website\noriginates a narrative that the story peaks in popularity.\nHere, a negative Cohen\u2019s D indicates that the \u201ctime for\n6. http://web .archive .org/web/20221028232854/https://infostormer .com/\njew-jim-cramer-cries-and-apologizes-for-hyping-metas-stock/\n7. https://web .archive .org/web/20221028014725/https://\nwww .activistpost .com/2022/10/the-big-tech-companies-are-telling-us-\nexactly-where-the-economy-is-headed-in-2023 .html\n8. http://web .archive .org/web/20220901000000*/https://hannity .com/\nmedia-room/sad-money-jim-cramer-in-tears-after-meta-stock-nosedives-\ni-made-a-mistake/\na narrative to peak\u201d occurs faster. This metric, combined\nwith the previous metric, describes how effective a website\nis at reorienting online conversations to its own narratives.\nWe see only a slight correlation ( \u03c1= 0.164) with a web-\nsite\u2019s CrUX-defined popularity. Rather, we again see that\nseveral small websites are highly effective in originating\nnarratives that peak quickly ( i.e., writing about narratives\nthat become of immediate interest). For example, when the\nsmall website infostormer.com originates narratives, those\nnarratives peak in popularity 155 days earlier than when\ninfostormer.com does not originate narratives (Table 5).\nWe similarly observe that the right-wing and conspiratorial\nwebsites ussanews.com and gellerreport.com, which often\nwrote about QAnon [5] are also highly effective at quickly\nlanding their narratives on other websites, with some of the\nlowest \u201ctime to peak\u201d in our dataset.\n5.2. Amplifying Narratives\nTo understand how effective websites are at amplify-\ning narratives, we correlationally compare the number of\nexternal non-origin articles that are written about a given\nnarrative when a given website amplifies the narrative versus\nwhen the website does not amplify the narrative but still\neventually wrote about that narrative. We utilize the same\nweighting and bootstrapping procedure as in the previous\nsection, again limiting our analysis to websites that am-\nplify at least 25 narratives across our period of study. We\nagain observe only a slight correlation between a website\u2019s\npopularity and its ability to amplify narratives (Pearson\ncorrelation \u03c1= 0.302). As before, we see in Table 6 that\nwebsites across different CrUX popularities excel at am-\nplifying narratives. For example, One of the most effective\nwebsites is barenakedislam.com, an anti-Islam website with\nthe slogan \u201cIt isn\u2019t Islamaphobia when they really ARE\ntrying to kill you. \u201d For example, after echoing a narrative\nabout how Muslim men were targeting Ukrainian refugees,9\nthis news story traveled to an additional 12 other unreli-\nable news websites including more popular websites like\namericanthinker.com10and breitbart.com.11This illustrates\nhow different types of websites can amplify and propagate\nnarratives in the misinformation news ecosystem.\nFinally, we determine the effect of narrative amplifica-\ntion by each website on how quickly the narrative peaks.\nThere is again a small correlation between website pop-\nularity and amplification (Pearson correlation \u03c1= 0.152).\nAs seen in Table 6, the most effective website at quickly\namplifying narratives to their peak popularity is populist-\npress.com, a drudge-style news website that hosts hyperlinks\n9. https://web .archive .org/web/20220422091130/https://\nbarenakedislam .com/2022/03/21/what-a-surprise-not-ukrainian-female-\nrefugees-say-they-dont-feel-safe-in-multicultural-sweden/\n10. http://web .archive .org/web/20220619083901/https://\nwww .americanthinker .com/articles/2022/06/the only rape where the\nleftsays victimblaming isokay .html\n11. https://web .archive .org/web/20220527122734/https://\nwww .breitbart .com/europe/2022/05/27/sweden-asylum-home-tells-\nukrainian-women-dress-modestly-to-not-provoke-migrant-men/\n6\n 4\n 2\n 0 2 4 6\nDays Relative to Peak0.000.020.040.060.080.10Proportion of Total VolumeRank < 10k\nRank < 100K\nRank < 1M\nRank < 50MFigure 6: Time lag for differently ranked websites. The most\npopular websites write more of their articles prior to the peak of\na narrative\u2019s popularity. In contrast, less popular websites tend to\nrespond to narratives and write most of their articles after the peak.\nSocial Media Posts With Corresponding\nPlatform Posts News Article Narrative\n8kun.top 632,091 34,959 (5.53%)\n4chan.org 4,690,669 450,027 (9.59%)\nTABLE 7: Our dataset of social media posts and their relationship\nto the narratives published by unreliable news websites.\nto different news articles. Despite not hosting many articles\nitself, we see that when it does mention a narrative, this news\nstory is more likely to more quickly peak in popularity.\nTrend Setting. Despite not seeing clear discernible patterns\nin how website popularity correlates with a website\u2019s ability\nto originate and amplify narratives, we do observe differ-\nences in when these websites write about given narratives.\nAs seen in Figure 6, across all narratives, more popular\nwebsites tend to write fewer articles (as a proportion) on the\nday that a given narrative peaks. A slightly higher percentage\n(37.37%) of articles from websites with a CrUX rank <10K\ncome before the peak versus the 31.39% of articles with a\nrank above 1M. This indicates, as also found by Leskovec\net al. [17], popular websites have some ability to set the\nagenda for the topic smaller websites write.\n5.3. The Role of Fringe Forums/Social Media\nWe now analyze the relationship between our set of\nunreliable news websites and the fringe social media sites\n8kun and 4chan. As with our set of unreliable news websites,\nwe scrape 8kun and 4chan /pol posts published between\nJanuary 1 and November 1, 2022 (Section 3.4). 8kun data\nis readily available on their website 8kun.top; 4chan /pol\nposts are archived through the website archive.4plebs.org.\nAltogether, we gather 632,091 posts from 8kun.top and\n4.69 million posts from 4chan (Table 7).\nTo find the correspondence of 8kun and 4chan comments\nbetween news narratives, we preprocess, embed, and assign\neach 8kun post to its most similar narrative cluster. As\nbefore, we utilize a threshold of 0.60 for matching a com-\nment to its corresponding news article narrative. Altogether,\nwe find that 34,959 (5.53%) of comments on 8kun.top and\n450,027 (9.59%) of comments from 4chan.org correspond to\na narrative on our set of unreliable news websites (Table 7).\nTop Narratives on 8kun Comments\nukraine, nato, putin, russia, war 625\nhillary, collusion, clinton, mueller, lie 454\nantisemit, jew, israel, zionist, israel 373\ntrucker, trudeau, canadian, ottawa, convoy 365\nukraine, kyiv, troop, russia, donbas 286\nTop Narratives on 4chan Comments\nukraine, kyiv, troop, russia, donbas 4,361\nvolodymyr, zelenskyy, ukrainie, kyiv, president 3,003\nukraine, conflict, war, escalation, tension 2,792\nrace, white, theory, black, crt 2,134\njew, white, supremacy, goyim, zionist 2,079\nTABLE 8: The top topics from our set of unreliable news websites\npresent on 8kun and 4chan /pol.\nNarratives Wtd. Ext. Cohen\u2019s To Peak Cohen\u2019s\nPlatform Originated Art. \u2206 D\u2206(Days) D\n8kun 392 0.400 1 .759 -73.92 -1.117\n4chan 2,455 0.394 0 .842 -29.45 -0.434\nNarratives Wtd. Ext. Cohen\u2019s To Peak Cohen\u2019s\nPlatform Amplified Art. \u2206 D\u2206(Days) D\n8kun 2,728 0.760 0.283 -19.82 -0.353\n4chan 12,164 0.327 0.913 1.19 0 .017\u2217\nJS-Sim.\nPlatform to News Most Similar News Sites\n8kun 0.240 lucianne.com, radiopatriot.net, americanthinker.com\n4chan 0.248 unz.com, beforeitsnews.com, thetruthseeker.co.uk\nTABLE 9: The influence of 8kun and 4chan on the ecosystem of\nunreliable news websites and their similarity (by JS-Divergence)\nto the unreliable news dataset. We star values were not found to\nbe significant according to the Mann-Whitney U-test.\n5.3.1. 8kun. Examining the top narratives posted on 8kun\nthat correspond with a news narrative (Table 8), we see that\nthe most commonly shared narratives on 8kun.top concern\nthe Russo-Ukrainian war, the investigation of Donald Trump\nby Special Counsel Robert Mueller [82], antisemitic beliefs,\nand the 2022 Trucker Convoy in Ottawa Canada [83]. This\nlargely corresponds with 8kun being known as the home\nof hard-right, conspiratorial, and antisemitic posts [84]. As\nin Section 4.3, we determine the distribution of narratives\nfrom our set of unreliable websites that are present on\n8kun to understand the similarity between 8kun and the\ncollective narratives on our set of unreliable news websites.\nAltogether, 8kun has a JS-Divergence of 0.240 with the\ncollective narrative distribution of unreliable news websites\n(Table 9). Performing this on an individual site level, we ob-\nserve several of the websites with the most similar narrative\ndistributions prominently discuss conspiratorial ideas ( e.g.,\nlucianne.com and radiotpatriot.net) [5]. Having examined\nsimilarities between the narratives discussed on 8kun and\nthose on particular websites in our dataset, we next deter-\nmine the influence of 8kun on our unreliable news website\necosystem. We utilize the same definitions of originate and\namplify as well as the same methodology as in Sections 5.1\nand 5.2. As seen in Table 9, 8kun originating or amplifying\na particular narrative has a modest effect on the number of\narticles written about that narrative. In the week after 8kun\noriginates a given narrative, we see an average Cohen\u2019s D\nof 1.759. In contrast, in the week after 8kun users amplifya narrative, we observe a Cohen\u2019s D of 0.283, illustrating\nthat 8kun is somewhat better at originating narratives than\namplifying narratives. Thus, while not as effective as some\nof the websites in our dataset (Tables 5 and 6), when 8kun\nusers comment on narratives, this correlates with a slight\nincrease in the narrative\u2019s popularity. We see this further\nmirrored in the effect that 8kun has in expediting narratives\nto peak earlier. On average, if 8kun originates a narrative,\nit peaks in popularity 73.9 days earlier than if 8kun did\nnot originate the narrative. Similarly, if 8kun amplifies a\nnarrative it peaks in popularity 19.8 days earlier on average.\n5.3.2. 4chan /pol. Looking at the top corresponding shared\nnarratives on 4chan /pol, we see several that target Judaism\nand the Jewish people (Table 8). As with 8kun, 4chan has a\nreputation for antisemitism and racist language. Besides the\nnarratives that center on the Russo-Ukrainian war, we see\nthis racism and antisemitism reflected in the top shared nar-\nratives on the website [85]. Determining the distribution of\nnarratives from our set of unreliable news websites that are\npresent on 4chan, altogether, 4chan has a JS-Divergence of\n0.248 with the collective narrative distribution of unreliable\nnews websites (Table 9). Examining the most similar web-\nsites to 4chan, we observe several with known conspiratorial\nreputations. As documented by Medias-Bias/FactCheck, the\nmost similar website to 4chan, unz.com is a conspiratorial\nand hate-oriented website that often cites white nationalist\ngroups in its articles [86]. Similarly, beforeitsnews.com [87]\nand thetruthseeker.co.uk [88] are known to \u201cpromote con-\nspiracy theories and pseudoscience.\u201d\nFinally, we determine the role 4chan has in promoting\nand amplifying narratives within our ecosystem of unreliable\nnews websites. We observe a similar effect to 8kun, in terms\nof the weighted increase of articles when 4chan originates\na narrative compared to when it does not (Cohen\u2019s D of\n0.438). However, unlike 8kun, we do observe that 4chan\nis better at amplifying narratives, with an effect size of\nCohen\u2019s D of 0.913 (Table 9). However, in contrast to 8kun,\n4chan is relatively less effective at getting the narrative to\npeak earlier. If 4chan users originate a narrative, it peaks in\npopularity 29.5 days earlier compared to 73.9 days earlier\nwhen 8kun originates a narrative. When 4chan amplifies a\nnarrative, it has little effect on when that narrative peaks.\n6. Detecting Narratives and Fact-Checking\nIn the last two sections, we analyzed the narratives and\nbehavior of unreliable news websites during 2022. In this\nsection, we present two case studies that highlight how our\nprogrammatic approach can also identify new narratives and\nassist in focusing fact-checking efforts.\n6.1. Identifying New Trending Narratives\nBy examining the week-over-week percentage increases\nin story volumes, we programmatically determine which\nnarratives are receiving new or renewed focus on unreli-\nable news websites, which is imperative for ameliorating\nthe spread of specious information [9]\u2013[11]. The narratives\nthat increased most in volume during the last week of our\nexperiment (October 26 to November 1, 2022) were:\nThe Attack of Paul Pelosi, Keywords: Pelosi, Depap,\nhammer, Nancy, Paul. On October 28, 2022, the hus-\nband of Congresswoman Nancy Pelosi was attacked in his\nhome [89]. Largely due to the proximity of the time of the\nattack to the 2022 US midterm elections, the attack became\na source of conspiracy theories and wild speculation. For\nexample, one user wrote on thegatewaypundit.com:12\nWhenever bad things happen to Paulie P , his wife\nalways manages to have an alibi.\n364 articles (compared to zero the week before) were written\nabout the event within our dataset across 175 websites. The\nthegatewaypundit.com had 44 articles, dailymail.co.uk.com\nhad 40, and nypost.com had 37.\nThe Seoul Halloween Stampede, Keywords: Halloween,\nSeoul, Itaewon, Festivity, Stampede. On October 29, 2022,\na crowd rush in the Seoul neighborhood of Itaewon resulted\nin the death of 158 people. Across our dataset, we see\n132 articles across 46 websites written about this event,\nwith 18 articles from dailymail.co.uk, 11 from republic-\nworld.com, and 8 from mirror.co.uk.\nElon Musk\u2019s First Visit to Twitter Headquarters, Key-\nwords: Sink, Headquarters, Musk, Carry, Twitter. After\nofficially purchasing the social media company Twitter, on\nhis first visit to the company on October 26, Elon Musk car-\nried a sink into the headquarters with him. This prop humor\nby Musk was supposed to be a play on \u201clet that sink in\u201d but\nwith a real sink. We see 176 articles from 84 domains about\nthe story, with 10 articles from the dailymail.co.uk, 9 from\nwesternjournal.com, and 8 from conservativeangle.com.\n6.2. Fact-Checking\nOne approach to combating the spread of new misin-\nformation stories that many organizations have adopted is\nfact-checking. Fact-checking a story requires hours to deeply\nunderstand its context and nuance [90]. Unfortunately, this\nmeans that propaganda and misinformation often spread\nwidely in a rapidly evolving media landscape before jour-\nnalists can respond. Our approach can serve as a way to\nprogrammatically identify new misinformation narratives as\nthey appear and begin to gain traction, ideally reducing the\namount of time from when a story is published to when a\nfact-checker can respond.\nTo show how our system might be useful to fact-\nchecking organizations, we utilize our approach to analyze\nthe behaviors of particular narratives before being fact-\nchecked by three organizations: Politifact, Reuters, and AP-\nNews [91]\u2013[93]. For the three agencies, we gathered the\nset of fact-checking articles that each published in 2022.\nAltogether we scraped 1,524, 3,090, and 140 articles from\n12. https://web .archive .org/web/20221028130434/https://\nwww .thegatewaypundit .com/2022/10/breaking-pelosis-home-broken-\nearly-morning-san-francisco-paul-pelosi-violently-beaten-taken-hospital/Narr. Med. Med. Med.\nFact- Art. Prior Days to Days from 0-Day\nChecked Fact-Check Fact-Check Narr. Peak Fact-Checks\nPolitifact 6,231 6 55.0 4.0 110\nReuters 9,604 3 49.0 0.0 647\nAP News 230 15 83.0 3.0 8\nTABLE 10: Efficacy of fact-checking websites. All three websites\nmost commonly fact-check\u2014by the number of articles with the\nsame narrative as the fact-check\u2014the articles of resear.ch (433 ar-\nticles), gatesofvienna.net (414), dailymail.co.uk (406).\nPolitifact [94], Reuters [95], and APNews [96], respectively.\nTo augment our system to perform fact-checking ( i.e., deter-\nmine whether a fact-check article refutes a given narrative),\nwe additionally train a DeBERTa-based [97] classifier on\nthe FEVER [98] dataset that takes a claim ( i.e., an article)\nand a query ( i.e., a fact-check) and labels the query as\neither supporting the claim, refuting the claim, or not having\nenough information to say anything about the claim. Using\n10% of the FEVER dataset as a held-out test set, our\nDeBERTa-based model achieves an overall 90.7% accuracy\non this test set (90.5% precision in labeling refutations).\nFor each fact-checking article, as with articles from\nunreliable websites, we divide the article into its constituent\npassages and embed them utilizing our MPNet model. We\nconsider a narrative to have been addressed by a fact-checker\nif the fact-checker writes about the narrative. We note that\narticles frequently \u201cfact-check\u201d or \u201cadd context\u201d to multiple\nnarratives. To provide fact checkers with the greatest number\nof \u201copportunities\u201d to fact-check a narrative, we map each\nfact-check passage to allarticles above our cosine similarity\nthreshold of 0.60 rather than map the fact-check passage\nto only the single closest narrative. After mapping these\nfact-checking passages to our set of articles, we utilize our\nDeBERTa-based fact-checking classifier to ensure that the\ncorresponding \u201cfact-check\u201d refutes the information of the\ncorresponding unreliable news article passage. We provide\nan example of an identified fact-check below. To ensure that\nour model is able to properly identify \u201cfact-checks\u201d, we\nmanually validate 100 random fact-check-article refutation\npairs, finding that 94% of them are indeed refutations.\nArticle Passage: This is a shining example and a small part of why it is so vitally\nimportant to find the underlying cause of the fraud that took place both in November\n2020 and the lead-up to that election.\nFact-Check: THE FACTS: To be clear, no widespread corruption was found and\nno election was stolen from Trump.\nAs seen in Table 10, on average, narratives can spread\none to two months before being fact-checked by these\nreputable websites. Furthermore, on average both Politifact\nand AP News write about stories after they have peaked\nin popularity; AP News, with the fewest fact-checks, writes\nabout narratives right as they peak in popularity. We fur-\nther see a heavy overlap between the narratives that each\nwebsite fact-checks. Reuters and Politifact have an overlap\nof 2,646 stories/narratives; AP News and Politifact, have an\noverlap of 137 narratives; and Reuters and AP News have\nan overlap of 141 narratives. Furthermore, the unreliable\nwebsites that have articles most commonly fact-checked\nby the three fact-checking organizations are the same: qre-\nsear.ch (433 articles), gatesofvienna.net (414), and daily-\nmail.co.uk (406). This underscores that these fact-checking\nwebsites are duplicating effort, often fact-checking the same\nnarratives [99]. We note, however, that while narratives\noften spread for long periods before being fact-checks, the\nnumber of articles, on average, is often low (3\u201315 articles).\nWe thus see that many fact-checkers areeffective at fact-\nchecking narratives when they peak in popularity, but often\nunderstandably do not fact-check narratives that have just\nbegun to spread among different unreliable news websites.\nWe see that many narratives spread for long periods\non unreliable news websites before they are fact-checked\nnear their narrative peak. However, our system can surface\nthese narratives to fact-checkers long before they peak in\npopularity, aiding in the fact-checking organizations\u2019 typi-\ncal workflow in identifying potential misinformation. This\ncan enable fact-checkers to identify and address misleading\nnarratives concurrent to when they first rise in popularity.\n7. Related Work\nOur study builds on considerable prior work on both the\nspread of misinformation online and language models. There\nhave been several past quantitative studies of the spread\nof information online. Leskovec et al. identify the trends\nin the propagation of \u201cmemes\u201d [17]. They find that while\nthe majority of memes originate from mainstream websites,\nkey phrases that start on smaller blogs are often adopted by\nlarger platforms. Gomez-Rodriguez et al. adopt a cascade\ntransmission model and identify how best to estimate the\nrelative influence of different news outlets in spreading\nstories [100]. Similar to our use of DP-Means, prior works\nhave utilized CluStream among other clustering techniques\nto track information or news over time [101]\u2013[103]. For\nexample, Curiskis et al. [104] utilize document clustering\nbased on dictionaries to track topics.\nAnalyzing the Spread of Misinformation. Several works\nhave tracked the spread and impact of misinformation. Shu\net al. [105] present the largest overall overview of mis-\ninformation detection issues, presenting various paradigms\nfor tracking and labeling misinformation. These include\ntracking news content features and social content features.\nFor example, Cao et al. [106] and Meel et al. [107] explore\nutilizing image and text-based features to label misinforma-\ntion. Abdali et al., in contrast, use screenshots of websites\nto identify the trustworthiness of websites and label mis-\ninformation [108]. Extensive work has studied individual\ncampaigns that spread unreliable information, on topics like\nQAnon [5], [49], Syrian White Helmets [34], the Russo-\nUkrainian War [39], [66], and COVID-19 [109].\nRecent work from the security community has focused\non identifying and curbing misinformation. Kaiser et al. [13]\nstudied how borrowing techniques from the security warning\nlandscape might help to inform mis/disinformation warn-\nings. Paudel et al. [14] recently demonstrated how tech-\nniques like Learning To Rank (LTR) can be used to soft-\nmoderate misinformation on Twitter. On the human-level,Sharevski et al. identified folk models of misinformation on\nsocial media that could inform potential defenses [110].\nLanguage Models, Semantic Search, and Topic Analysis.\nMany previous topic analysis methods have been built on\nLatent Dirichlet Allocation (LDA). Albalawi et al. show\nthat LDA is one of the most effective methodologies for\nextracting topics from short text data compared to other\ncomputationally light alternatives proposed within the last\ndecade ( e.g., LSA, LDA, NMF, PCA, RP) [111]. Meng\net al. [112], Angelov [113], and Grootendorst [64] have\nenabled users to perform topic modeling utilizing large\nlanguage models. Utilizing these techniques and online doc-\nument clustering [114], [115], others have performed robust,\nbut smaller scoped semantic analysis (e.g., on Russian dis-\ninformation campaigns [39], [53]).\n8. Discussion and Conclusion\nIn this work, we introduced and validated a new, scalable\nmethodology for tracking news narratives online. Applying\nthe methodology to study the stories published on 1,334 un-\nreliable news websites during 2022, our work shows how\na large-scale, quantitative analysis can identify propagation\npatterns and significant players that may otherwise have\nbeen difficult to uncover through qualitative investigations\nof individual disinformation campaigns. Specifically, we\nshowed that less frequented websites and fringe social me-\ndia platforms can have marked effects on amplifying the\nnarratives discussed on unreliable news websites.\nOur study also highlights the need to programmatically\ndetect the rise of false narratives in real time. Prior work\nhas shown that misinformation can spread ten times faster\nthan legitimate news [6] and our analysis finds that false\nnarratives can often start on small, seemingly unpopular\nwebsites. In many cases, these false narratives spread for\nmonths online before being fact-checked. As such, we are\nexploring how best to publicly and continuously release\nreal-time updates of our narrative analyses on an online\ndashboard while protecting against misuse ( e.g., use in AI\ntraining models [116] or targeted misinformation chatbots).\nWhile our study illustrates the potential for program-\nmatically tracking news narratives, it also simultaneously\nsurfaces areas for further research. For example, as found\nin past works [39], [117], though our approach can identify\nprecise stories/narratives within our dataset, medical infor-\nmation poses challenges for large language models like MP-\nNet. For example, one of the misclassifications (Narrative 6\nin Table 3) concerned COVID-19 rather than Monkeypox.\nGiven the high knowledge level needed in understanding\nmedical misinformation, past works have recommended uti-\nlizing models specifically trained for medical misinforma-\ntion for topic analysis of these stories [117]. We hope that\nthe potential of and demonstrated need for programmatic\napproaches for tracking news narratives and misinformation\nonline motivates further work on these topics.\nReferences\n[1] Z. Stanton, \u201cYou\u2019re living in the golden age of\nconspiracy theories - politico,\u201d 6 2020. [Online]. Available:\nhttps://www .politico .com/news/magazine/2020/06/17/conspiracy-\ntheories-pandemic-trump-2020-election-coronavirus-326530\n[2] A. Bovet and H. A. Makse, \u201cInfluence of fake news in twitter during\nthe 2016 us presidential election,\u201d Nature Communications , 2019.\n[3] P. Ball and A. Maxmen, \u201cThe epic battle against coronavirus mis-\ninformation and conspiracy theories.\u201d Nature , 2020.\n[4] S. Banaji, R. Bhat, A. Agarwal, N. Passanha, and M. Sad-\nhana Pravin, \u201cWhatsapp vigilantes: An exploration of citizen re-\nception and circulation of whatsapp misinformation linked to mob\nviolence in india,\u201d 2019.\n[5] H. W. Hanley, D. Kumar, and Z. Durumeric, \u201cNo calm in the storm:\ninvestigating qanon website relationships,\u201d in International AAAI\nconference on Web and social media , 2022.\n[6] S. V osoughi, D. Roy, and S. Aral, \u201cThe spread of true and false\nnews online,\u201d Science , vol. 359, no. 6380, pp. 1146\u20131151, 2018.\n[7] K. Thomas, D. Akhawe, M. Bailey, D. Boneh, E. Bursztein, S. Con-\nsolvo, N. Dell, Z. Durumeric, P. G. Kelley, D. Kumar et al. , \u201cSoK:\nHate, harassment, and the changing landscape of online abuse,\u201d in\nIEEE Symposium on Security and Privacy , 2021.\n[8] M. E. Zurko, \u201cDisinformation and reflections from usable security,\u201d\nIEEE Security & Privacy , vol. 20, no. 3, pp. 4\u20137, 2022.\n[9] M. Rajdev and K. Lee, \u201cFake and spam messages: Detecting mis-\ninformation during natural disasters on social media,\u201d in Intl. Conf.\non Web Intelligence and Intelligent Agent Technology , 2015.\n[10] L. Wu, F. Morstatter, K. M. Carley, and H. Liu, \u201cMisinforma-\ntion in social media: definition, manipulation, and detection,\u201d ACM\nSIGKDD Explorations Newsletter , vol. 21, no. 2, pp. 80\u201390, 2019.\n[11] M. H. Saeed, S. Ali, J. Blackburn, E. De Cristofaro, S. Zannettou,\nand G. Stringhini, \u201cTrollmagnifier: Detecting state-sponsored troll\naccounts on reddit,\u201d in IEEE Symposium on Security and Privacy .\n[12] A. Hounsel, J. Holland, B. Kaiser, K. Borgolte, N. Feamster, and\nJ. Mayer, \u201cIdentifying disinformation websites using infrastructure\nfeatures,\u201d in USENIX Workshop on Free and Open Communications\non the Internet , 2020.\n[13] B. Kaiser, J. Wei, E. Lucherini, K. Lee, J. N. Matias, and J. Mayer,\n\u201cAdapting security warnings to counter online disinformation,\u201d in\n30th USENIX Security Symposium , 2021.\n[14] P. Paudel, J. Blackburn, E. De Cristofaro, S. Zannettou, and\nG. Stringhini, \u201cLambretta: learning to rank for twitter soft mod-\neration,\u201d in IEEE Symposium on Security and Privacy , 2023.\n[15] S. Zannettou, T. Caulfield, E. De Cristofaro, M. Sirivianos,\nG. Stringhini, and J. Blackburn, \u201cDisinformation warfare: Under-\nstanding state-sponsored trolls on twitter and their influence on the\nweb,\u201d in World wide web conference , 2019.\n[16] F. Plasser, \u201cFrom hard to soft news standards? how political jour-\nnalists in different media systems evaluate the shifting quality of\nnews,\u201d Harvard International Journal of Press/Politics , 2005.\n[17] J. Leskovec, L. Backstrom, and J. Kleinberg, \u201cMeme-tracking and\nthe dynamics of the news cycle,\u201d in 15th ACM SIGKDD interna-\ntional conference on Knowledge discovery and data mining , 2009.\n[18] K. Song, X. Tan, T. Qin, J. Lu, and T.-Y . Liu, \u201cMpnet: Masked and\npermuted pre-training for language understanding,\u201d Adv. in Neural\nInformation Processing Systems , 2020.\n[19] Z. Durumeric, E. Wustrow, and J. A. Halderman, \u201cZMap: fast\ninternet-wide scanning and its security applications,\u201d in 22nd\nUSENIX Security Symposium , 2013.\n[20] D. Moore, V . Paxson, S. Savage, C. Shannon, S. Staniford, and\nN. Weaver, \u201cInside the slammer worm,\u201d IEEE Security & Privacy ,\n2003.[21] S. Meiklejohn, M. Pomarole, G. Jordan, K. Levchenko, D. McCoy,\nG. M. V oelker, and S. Savage, \u201cA fistful of bitcoins: characterizing\npayments among men with no names,\u201d in ACM Internet measure-\nment conference , 2013.\n[22] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. V oelker,\nV . Paxson, and S. Savage, \u201cSpamalytics: An empirical analysis of\nspam marketing conversion,\u201d in 15th ACM conference on Computer\nand communications security , 2008.\n[23] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M.\nV oelker, \u201cAn analysis of underground forums,\u201d in ACM Internet\nmeasurement conference , 2011.\n[24] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,\nJ. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallit-\nsiset al. , \u201cUnderstanding the mirai botnet,\u201d in 26th USENIX security\nsymposium , 2017.\n[25] D. McCoy, A. Pitsillidis, J. Grant, N. Weaver, C. Kreibich, B. Krebs,\nG. V oelker, S. Savage, and K. Levchenko, \u201cPharmaLeaks: Under-\nstanding the business of online pharmaceutical affiliate programs,\u201d\nin21st USENIX Security Symposium .\n[26] S. Afroz, A. C. Islam, A. Stolerman, R. Greenstadt, and D. McCoy,\n\u201cDoppelg \u00a8anger finder: Taking stylometry to the underground,\u201d in\nIEEE Symposium on Security and Privacy , 2014.\n[27] E. Zeng, T. Kohno, and F. Roesner, \u201cBad news: Clickbait and\ndeceptive ads on news and misinformation websites,\u201d in Workshop\non Technology and Consumer Protection , 2020.\n[28] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman,\n\u201cMining your Ps and Qs: Detection of widespread weak keys in\nnetwork devices,\u201d in 21st USENIX Security Symposium , 2012.\n[29] C. Jack, \u201cLexicon of lies: Terms for problematic information,\u201d Data\n& Society , vol. 3, no. 22, pp. 1094\u20131096, 2017.\n[30] S. Jiang and C. Wilson, \u201cLinguistic signals under misinformation\nand fact-checking: Evidence from user comments on social media,\u201d\nACM CSCW , 2018.\n[31] S. Lewandowsky, U. K. Ecker, C. M. Seifert, N. Schwarz, and\nJ. Cook, \u201cMisinformation and its correction: Continued influence\nand successful debiasing,\u201d Psychological science in the public in-\nterest , vol. 13, no. 3, pp. 106\u2013131, 2012.\n[32] H. Allcott, M. Gentzkow, and C. Yu, \u201cTrends in the diffusion of\nmisinformation on social media,\u201d Research & Politics , 2019.\n[33] S. Z. Akbar, A. Panda, D. Kukreti, A. Meena, and J. Pal, \u201cMisinfor-\nmation as a window into prejudice: Covid-19 and the information\nenvironment in india,\u201d CSCW , 2021.\n[34] K. Starbird, A. Arif, T. Wilson, K. Van Koevering, K. Yefimova,\nand D. Scarnecchia, \u201cEcosystem or echo-system? exploring content\nsharing across alternative media domains,\u201d in International AAAI\nConference on Web and Social Media , 2018.\n[35] J. Allan, \u201cDetection as multi-topic tracking,\u201d Information Retrieval ,\nvol. 5, no. 2-3, pp. 139\u2013157, 2002.\n[36] P. Devine and K. Blincoe, \u201cUnsupervised extreme multi label clas-\nsification of stack overflow posts,\u201d in 1st International Workshop on\nNatural Language-based Software Engineering , 2022.\n[37] H. Jelodar, Y . Wang, C. Yuan, X. Feng, X. Jiang, Y . Li, and L. Zhao,\n\u201cLatent dirichlet allocation (lda) and topic modeling: models, appli-\ncations, a survey,\u201d Multimedia Tools and Applications , 2019.\n[38] G. Leban, B. Fortuna, J. Brank, and M. Grobelnik, \u201cEvent registry:\nlearning about world events from news,\u201d in 23rd International\nConference on World Wide Web , 2014.\n[39] H. W. Hanley, D. Kumar, and Z. Durumeric, \u201cHappenstance: Utiliz-\ning semantic search to track russian state media narratives about the\nrusso-ukrainian war on reddit,\u201d in International AAAI conference on\nweb and social media , 2023.\n[40] S. Miranda, A. Znotin \u00b8 \u02c7s, S. B. Cohen, and G. Barzdins, \u201cMultilingual\nclustering of streaming news,\u201d in Conference on Empirical Methods\nin Natural Language Processing , 2018.\n[41] C. Crawl, \u201cCommon crawl,\u201d 10 2022. [Online]. Available:\nhttps://commoncrawl .org/\n[42] W. Min, B.-K. Bao, C. Xu, and M. S. Hossain, \u201cCross-platform\nmulti-modal topic modeling for personalized inter-platform recom-\nmendation,\u201d IEEE Transactions on Multimedia , 2015.\n[43] R. Bal, S. Sinha, S. Dutta, R. Joshi, S. Ghosh, and R. Dutt,\n\u201cAnalysing the extent of misinformation in cancer related tweets,\u201d\ninInternational AAAI Conference on Web and Social Media , 2020.\n[44] Barret Golding, \u201cIffy index of unreliable sources,\u201d https://iffy .news/\nindex/, 2022.\n[45] M. Szpakowski, \u201cFake news corpus,\u201d https://github .com/several27/\nFakeNewsCorpus/, 2020.\n[46] P. Staff, \u201cPolitifact\u2019s guide to fake news websites and what they\npeddle,\u201d https://www .politifact .com/article/2017/apr/20/politifacts-\nguide-fake-news-websites-and-what-they/, 2017.\n[47] Aloisius Regen, \u201cfake-news,\u201d https://github .com/Aloisius/fake-news,\n2017.\n[48] Melissa Zidmars, \u201cMisinformation and news literacy: Home,\u201d https:\n//library .athenstech .edu/fake, 2017.\n[49] H. W. Hanley, D. Kumar, and Z. Durumeric, \u201cA golden age: Conspir-\nacy theories\u2019 relationship with misinformation outlets, news media,\nand the wider internet,\u201d CSCW , 2023.\n[50] J. Smith, H. Saint-Amand, M. Plamad \u02d8a, P. Koehn, C. Callison-\nBurch, and A. Lopez, \u201cDirt cheap web-scale parallel text from\nthe common crawl,\u201d in 51st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) , 2013.\n[51] R. Dahlke, D. Kumar, Z. Durumeric, and J. Hancock, \u201cPie metrics:\nquantifying the systematic bias in the ephemerality and inaccessi-\nbility of web scraping content from url-logged web-browsing digital\ntrace data,\u201d 2023.\n[52] A. Piktus, F. Petroni, V . Karpukhin, D. Okhonko, S. Broscheit,\nG. Izacard, P. Lewis, B. O \u02d8guz, E. Grave, W.-t. Yih et al. , \u201cThe\nweb is your oyster\u2013knowledge-intensive nlp against a very large\nweb corpus,\u201d arXiv preprint arXiv:2112.09924 , 2021.\n[53] H. W. Hanley and Z. Durumeric, \u201cPartial mobilization: Tracking\nmultilingual information flows amongst russian media outlets and\ntelegram,\u201d arXiv preprint arXiv:2301.10856 , 2023.\n[54] D. Cer, M. Diab, E. Agirre, I. Lopez-Gazpio, and L. Specia,\n\u201cSemeval-2017 task 1: Semantic textual similarity multilingual and\ncrosslingual focused evaluation,\u201d in 11th International Workshop on\nSemantic Evaluation , 2017.\n[55] J. Pennington, R. Socher, and C. D. Manning, \u201cGlove: Global vectors\nfor word representation,\u201d in Empirical Methods in Natural Language\nProcessing (EMNLP) , 2014.\n[56] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u201cBert: Pre-\ntraining of deep bidirectional transformers for language understand-\ning,\u201d in North American Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies, Volume 1 , 2019.\n[57] D. Cer, Y . Yang, S.-y. Kong, N. Hua, N. Limtiaco, R. S. John,\nN. Constant, M. Guajardo-Cespedes, S. Yuan, C. Tar et al. , \u201cUni-\nversal sentence encoder,\u201d arXiv preprint arXiv:1803.11175 , 2018.\n[58] N. Reimers and I. Gurevych, \u201cSentence-bert: Sentence embeddings\nusing siamese bert-networks,\u201d in Conference on Empirical Methods\nin Natural Language Processing and the 9th International Joint\nConference on Natural Language Processing , 2019.\n[59] A. Rondinelli, L. Bongiovanni, and V . Basile, \u201cZero-shot topic\nlabeling for hazard classification,\u201d Information , 2022.\n[60] T. Gao, X. Yao, and D. Chen, \u201cSimCSE: Simple contrastive learning\nof sentence embeddings,\u201d in Empirical Methods in Natural Lan-\nguage Processing (EMNLP) , 2021.\n[61] N. Goel and R. Reddy, \u201cSemeval-2022 task 8: Multi-lingual news\narticle similarity,\u201d arXiv preprint arXiv:2208.09715 , 2022.[62] D. Vetter, J. J. Tithi, M. Westerlund, R. V . Zicari, and G. Roig,\n\u201cUsing sentence embeddings and semantic similarity for seeking\nconsensus when assessing trustworthy ai,\u201d arXiv:2208.04608 , 2022.\n[63] G. Bernard, C. Suire, C. Faucher, A. Doucet, and P. Rosso, \u201cTracking\nnews stories in short messages in the era of infodemic,\u201d in Inter-\nnational Conference of the Cross-Language Evaluation Forum for\nEuropean Languages , 2022.\n[64] M. Grootendorst, \u201cBertopic: Neural topic modeling with a class-\nbased tf-idf procedure,\u201d arXiv preprint arXiv:2203.05794 , 2022.\n[65] O. Dinari and O. Freifeld, \u201cRevisiting dp-means: fast scalable algo-\nrithms via parallelism and delayed cluster creation,\u201d in Uncertainty\nin Artificial Intelligence , 2022.\n[66] H. W. Hanley, D. Kumar, and Z. Durumeric, \u201c\u201cA Special Operation\u201d:\nA quantitative approach to dissecting and comparing different media\necosystems\u2019 coverage of the Russo-Ukrainian war,\u201d in International\nAAAI Conference on Web and Social Media , 2023.\n[67] G. Bouma, \u201cNormalized (pointwise) mutual information in colloca-\ntion extraction,\u201d Proceedings of GSCL , 2009.\n[68] J. Kessler, \u201cScattertext: a browser-based tool for visualizing how\ncorpora differ,\u201d in ACL, System Demonstrations , 2017.\n[69] M. Lewis, Y . Liu, N. Goyal, M. Ghazvininejad, A. Mohamed,\nO. Levy, V . Stoyanov, and L. Zettlemoyer, \u201cBart: Denoising\nsequence-to-sequence pre-training for natural language generation,\ntranslation, and comprehension,\u201d in 58th Annual Meeting of the\nAssociation for Computational Linguistics , 2020.\n[70] W. P. Staff, \u201cRead the full opinion in dobbs v.\njackson women\u2019s health o - washington post,\u201d 6 2022.\n[Online]. Available: https://www .washingtonpost .com/politics/\ninteractive/2022/roe-wade-decision-pdf/\n[71] G. E. Center, \u201cPillars of russia\u2019s disinformation and propaganda\necosystem,\u201d 2020.\n[72] D. Masci, \u201cMost poles accept jews as fellow citizens and neighbors\n\u2014 pew research center,\u201d 3 2018. [Online]. Available: https:\n//www .pewresearch .org/fact-tank/2018/03/28/most-poles-accept-\njews-as-fellow-citizens-and-neighbors-but-a-minority-do-not/\n[73] A. Perrone and D. Loucaides, \u201cA key source for covid-\nskeptic movements, the epoch times yearns for a global\naudience - coda story,\u201d 3 2022. [Online]. Available: https:\n//www .codastory .com/disinformation/epoch-times/\n[74] T. Daigle, \u201cCanadian professor\u2019s website helps russia spread\ndisinformation, says u.s. state department \u2014 cbc news,\u201d 4\n2021. [Online]. Available: https://www .cbc .ca/news/science/russian-\ndisinformation-global-research-website-1 .5767208\n[75] P. Baker and M. Haberman, \u201cIn torrent of falsehoods, trump\nclaims election is rigged,\u201d 11 2020. [Online]. Available: https:\n//www .nytimes .com/2020/11/05/us/politics/trump-presidency .html\n[76] F. Nielsen, \u201cOn a generalization of the jensen\u2013shannon divergence\nand the jensen\u2013shannon centroid,\u201d Entropy , 2020.\n[77] X. Que, F. Checconi, F. Petrini, and J. A. Gunnels, \u201cScalable com-\nmunity detection with the louvain algorithm,\u201d in IEEE International\nParallel and Distributed Processing Symposium , 2015.\n[78] K. Ruth, D. Kumar, B. Wang, L. Valenta, and Z. Durumeric, \u201cTop-\npling top lists: Evaluating the accuracy of popular website lists,\u201d in\n22nd ACM Internet Measurement Conference , 2022.\n[79] K. Ruth, A. Fass, J. Azose, M. Pearson, E. Thomas, C. Sadowski,\nand Z. Durumeric, \u201cA world wide view of browsing the world wide\nweb,\u201d in 22nd ACM Internet Measurement Conference , 2022.\n[80] K. J \u00a8arvelin and J. Kek \u00a8al\u00a8ainen, \u201cCumulated gain-based evaluation of\nir techniques,\u201d ACM Transactions on Information Systems , 2002.\n[81] M. A. Little and R. Badawy, \u201cCausal bootstrapping,\u201d arXiv preprint\narXiv:1910.09648 , 2019.\n[82] M. Zapotosky and S. S. Hsu, \u201cMueller prosecutor says special\ncounsel \u2018could have done more\u2019 to hold trump accountable,\u201d\n09 2020. [Online]. Available: https://www .washingtonpost .com/\nnational-security/andrew-weissmann-book-mueller-trump/2020/09/\n21/6a7967e8-fc10-11ea-b555-4d71a9254f4b story .html\n[83] J. Murphy, \u201cEmergencies act: Us was \u2019worried\u2019 over canada\nfreedom convoy protests,\u201d 11 2022. [Online]. Available: https:\n//www .bbc .com/news/world-us-canada-63736482\n[84] A. Glaser, \u201c8chan is back as 8kun, but its racist users found\nother places to go.\u201d https://slate .com/technology/2019/11/8chan-\n8kun-white-supremacists-telegram-discord-facebook .html, 2019.\n[85] A. Zelenkauskaite, P. Toivanen, J. Huhtam \u00a8aki, and K. Valaskivi,\n\u201cShades of hatred online: 4chan duplicate circulation surge during\nhybrid media events,\u201d First Monday , 2021.\n[86] D. V . Zandt, \u201cMedia Bias Fact Check,\u201d https:\n//mediabiasfactcheck .com/the-unz-report/, 2022.\n[87] \u2014\u2014, \u201cMedia Bias Fact Check,\u201d https://mediabiasfactcheck .com/\nbefore-its-news/, 2022.\n[88] \u2014\u2014, \u201cMedia Bias Fact Check,\u201d https://mediabiasfactcheck .com/\nthe-truth-seeker/, 2022.\n[89] T. N. Y . Times, \u201cThe facts about the attack on paul pelosi,\naccording to prosecutors - the new york times,\u201d 11 2022.\n[Online]. Available: https://www .nytimes .com/article/pelosi-paul-\nnancy-attack-facts .html\n[90] G. Kessler, \u201cFact-checking movement grapples with a world awash\nin false claims,\u201d https://www .washingtonpost .com/politics/2022/\n06/29/fact-checking-movement-grapples-with-world-awash-false-\nclaims/, 2022.\n[91] D. Zlatkova, P. Nakov, and I. Koychev, \u201cFact-checking meets faux-\ntography: Verifying claims about images,\u201d in Conf. on Empirical\nMethods in NLP and the 9th Intl. Joint Conf. on NLP , 2019.\n[92] B. Nyhan and J. Reifler, \u201cWhen corrections fail: The persistence of\npolitical misperceptions,\u201d Political Behavior , 2010.\n[93] H. Rashkin, E. Choi, J. Y . Jang, S. V olkova, and Y . Choi, \u201cTruth\nof varying shades: Analyzing language in fake news and political\nfact-checking,\u201d in Proceedings of the 2017 conference on empirical\nmethods in natural language processing , 2017, pp. 2931\u20132937.\n[94] Politifact Staff, \u201cPolitifact latest fact checks,\u201d https:\n//www .politifact .com/factchecks/list/, 2022.\n[95] Retuers Staff, \u201cReuters fact check,\u201d https://www .reuters .com/fact-\ncheck, 2022.\n[96] \u201cAP Fact Check,\u201d https://apnews .com/hub/ap-fact-check, 2022.\n[97] P. He, J. Gao, and W. Chen, \u201cDebertav3: Improving deberta us-\ning electra-style pre-training with gradient-disentangled embedding\nsharing,\u201d in 11th Intl. Conf. on Learning Representations , 2022.\n[98] J. Thorne, A. Vlachos, C. Christodoulopoulos, and A. Mittal, \u201cFever:\na large-scale dataset for fact extraction and verification,\u201d in Con-\nference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies , 2018.\n[99] D. Graves, \u201cUnderstanding the promise and limits of automated fact-\nchecking,\u201d 2018.\n[100] M. Gomez-Rodriguez, J. Leskovec, and A. Krause, \u201cInferring net-\nworks of diffusion and influence,\u201d ACM Transactions on Knowledge\nDiscovery from Data (TKDD) , vol. 5, no. 4, pp. 1\u201337, 2012.\n[101] H. Tajalizadeh and R. Boostani, \u201cA novel stream clustering frame-\nwork for spam detection in twitter,\u201d IEEE Transactions on Compu-\ntational Social Systems , 2019.\n[102] A. Alsayat and H. El-Sayed, \u201cSocial media analysis using optimized\nk-means clustering,\u201d in IEEE 14th International Conference on Soft-\nware Engineering Research, Management and Applications , 2016.[103] W. Fan, Z. Guo, N. Bouguila, and W. Hou, \u201cClustering-based online\nnews topic detection and tracking through hierarchical bayesian non-\nparametric models,\u201d in 44th International ACM SIGIR Conference\non Research and Development in Information Retrieval , 2021.\n[104] S. A. Curiskis, B. Drake, T. R. Osborn, and P. J. Kennedy, \u201cAn\nevaluation of document clustering and topic modelling in two online\nsocial networks: Twitter and reddit,\u201d Information Processing &\nManagement , 2020.\n[105] K. Shu, A. Sliva, S. Wang, J. Tang, and H. Liu, \u201cFake news detec-\ntion on social media: A data mining perspective,\u201d ACM SIGKDD\nexplorations newsletter , 2017.\n[106] J. Cao, P. Qi, Q. Sheng, T. Yang, J. Guo, and J. Li, \u201cExploring\nthe role of visual content in fake news detection,\u201d Disinformation,\nMisinformation, and Fake News in Social Media , pp. 141\u2013161, 2020.\n[107] P. Meel, H. Agrawal, M. Agrawal, and A. Goyal, \u201cAnalysing tweets\nfor text and image features to detect fake news using ensemble\nlearning,\u201d in Intl. Conf. on Intelligent Computing and Smart Com-\nmunication , 2020.\n[108] S. Abdali, R. Gurav, S. Menon, D. Fonseca, N. Entezari, N. Shah,\nand E. E. Papalexakis, \u201cIdentifying misinformation from website\nscreenshots,\u201d arXiv preprint arXiv:2102.07849 , 2021.\n[109] G. Madraki, I. Grasso, J. M. Otala, Y . Liu, and J. Matthews, \u201cChar-\nacterizing and comparing covid-19 misinformation across languages,\ncountries and platforms,\u201d in The web conference , 2021.\n[110] F. Sharevski, A. Devine, E. Pieroni, and P. Jachim, \u201cFolk models of\nmisinformation on social media,\u201d 2023.\n[111] R. Albalawi, T. H. Yeap, and M. Benyoucef, \u201cUsing topic modeling\nmethods for short-text data: A comparative analysis,\u201d Frontiers in\nartificial intelligence , vol. 3, p. 42, 2020.\n[112] Y . Meng, Y . Zhang, J. Huang, Y . Zhang, and J. Han, \u201cTopic\ndiscovery via latent space clustering of pretrained language model\nrepresentations,\u201d in ACM Web Conference , 2022.\n[113] D. Angelov, \u201cTop2vec: Distributed representations of topics,\u201d 2020.\n[114] J. Yin, D. Chao, Z. Liu, W. Zhang, X. Yu, and J. Wang, \u201cModel-\nbased clustering of short text streams,\u201d in 24th ACM SIGKDD\ninternational conference on knowledge discovery & data mining ,\n2018.\n[115] D. M. Blei, T. L. Griffiths, and M. I. Jordan, \u201cThe nested chinese\nrestaurant process and bayesian nonparametric inference of topic\nhierarchies,\u201d Journal of the ACM (JACM) , 2010.\n[116] E. David, \u201cNews outlets demand new rules for ai training data,\u201d\n4 2023. [Online]. Available: https://www .theverge .com/2023/8/10/\n23827316/news-transparency-copyright-generative-ai\n[117] S. L. Isaac, G. Irving, and I. Gabriel, \u201cEthical and social risks of\nharm from language models,\u201d 2021.\n[118] B. Liang, Q. Zhu, X. Li, M. Yang, L. Gui, Y . He, and R. Xu, \u201cJointcl:\nA joint contrastive learning framework for zero-shot stance detec-\ntion,\u201d in 60th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , 2022.\n[119] B. Kulis and M. I. Jordan, \u201cRevisiting k-means: New algorithms via\nbayesian nonparametrics,\u201d arXiv:1111.0352 , 2011.\n[120] P. D. Turney, \u201cMining the web for synonyms: Pmi-ir versus lsa on\ntoefl,\u201d in European conference on machine learning , 2001.\n[121] A. Aizawa, \u201cAn information-theoretic perspective of tf\u2013idf mea-\nsures,\u201d Information Processing & Management , 2003.\nAppendix A.\nTraining with Unsupervised Contrastive Loss\nTo train our MPNet model, we utilize unsupervised\ncontrastive learning to better the quality of our embed-\ndings [60]. For training, this is such that we embed each\nexample xi= (texti)\u2208DNews (where textiis the text)\ntwice (with dropout both times) using MPNet by inputting\n[CLS ]texti[SEP ]and averaging the contextual word vec-\ntors of the resulting output as a hidden vector hiand\u02dchi\nfortextias its representations. Then, given a set of hidden\nvectors {hi}Nb\ni=0and{\u02dchj}Nb\nj=0(different dropout), where Nb\nis the size of the batch, we perform a contrastive learning\nstep on that batch. This is such that for each Batch B, for\nananchor hidden embedding hiwithin the batch, the set of\nhidden vectors hi,\u02dchj\u2208 B, vectors where i=jare positive\npairs. Other pairs where i\u0338=jare considered negative pairs.\nWithin each batch B, the contrastive loss is computed across\nall positive pairs in the batch such that:\nLcontrastive =\u22121\nNbX\nhi\u2208Blc(hi)\nlc(hi) =logP\nj\u2208B1[i=j]exp(h\u22a4\ni\u02dchj\n\u03c4||hi||||\u02dchj||)\nP\nj\u2208Bexp(h\u22a4\ni\u02dchj\n\u03c4||hi||||\u02dchj||)\nwhere, as in prior work [118], we utilize a temperature \u03c4=\n0.07.\nAppendix B.\nPassage Pairs\n0.45 Similarity\nPASSAGE 1: The growing possibility that nuclear weapons might be used, as hostilities in Ukraine continue to\nescalate, merits your full attention.\nPASSAGE 2: Raising the alert level of Russian nuclear forces is a bonechilling development, Guterres declared.\nThe prospect of nuclear conflict, once unthinkable, is now back within the realm of possibility.\n0.50 Similarity\nPASSAGE 1: When you actually look at the bill and it says no sexual instruction to kids preK through three, how\nmany parents want their kids to have transgenderism or something injected into classroom instruction? DeSantis\nsaid earlier this month.\nPASSAGE 2: Parents watchdog group Parents Defending Education PDE has warned that a school district in\nMinnesota is pushing transgender and pride books and materials on to children as young as three years old.\n0.55 Similarity\nPASSAGE 1: Protests in the Netherlands became violent with police cars being set ablaze as the public grows angry\nwith their enforcement of COVID edicts to restrict their civil liberties:\nPASSAGE 2: Thousands of Dutch citizens lined up in the streets defiantly even after government officials banned\nprotest, using the neverending pandemic as an excuse to brutally crackdown on civil liberties.\n0.60 Similarity\nPASSAGE 1: The raid by over 30 plain clothes agents from the Southern District of Florida and the FBI s Washington\nField Office extended through the Trump family s entire 3,000squarefoot private quarters, as well as to a separate\noffice and safe, and a locked basement storage room in which 15 cardboard boxes of material from the White House\nwere stored.\nPASSAGE 2: Donald Trump lamented Wednesday that the FBI blocked his lawyers from the property during the\nraid at his Palm Beach, Florida residence and suggested that agents may have \u2019planted\u2019 evidence.\nFigure 7: Example of passage pairs at different levels of cosine\nsimilarities.Appendix C.\nDP-Means Algorithm\nDP-Means [119] is a non-parametric extension of the\nK-means algorithm that does not require the specification\nof the number of clusters a priori . Within DP-Means, when\na given datapoint is a chosen parameter \u03bbaway from the\nclosest cluster, a new cluster is formed. Dinari et al. [65]\nparallelize this algorithm by delaying cluster creation until\nthe end of the assignment step. Namely, instead of creating\na new cluster each time a new datapoint is discovered,\nthe algorithm instead determines which datapoint is furthest\nfrom the current set of clusters and then creates a new cluster\nwith that datapoint. By delaying cluster creation, the DP-\nmeans algorithm can be trivially parallelized. Furthermore,\nby delaying cluster creation, this version of DP-Means\navoids over-clustering the data ( i.e.,only the most disparate\ndatapoints create new clusters) [65].\nAppendix D.\nPointwise Mutual Information\nThe PMI of a particular word word iin a cluster Cjis\ncalculated as:\nPMI (word i, Cj) =log2P(word i, Cj)\nP(word i)P(ci)\nwhere Pis the probability of occurrence and a scaling\nparameter \u03b1is added to the counts of each word. This\nscaling parameter \u03b1prevents single-count or one-off words\nin each cluster from having the highest PMI values. Given\nthe scale of our dataset and the number of clusters within\nour dataset, we determine that a baseline count of 1 ( \u03b1\n=1) for each word in the full dictionary in each cluster led\nto the best results [120]. We utilize this approach rather\nthan cluster-normalized TF-IDF as in other works [39], [64]\nbecause class TF-IDF is dependent on document classes\nbeing similar in length [64], [121] and the number of\narticles within each of our clusters varies widely. PMI finds\nthe distinct characteristics of individual clusters and is not\ndependent on how often words appear in other individual\nclusters, avoiding this issue.\nAppendix E.\nJS-Divergence\nFormally JS-Divergence between two distributions P and\nQ is calculated as follows:\nJS(P||Q) =1\n2KL(P||(P+Q)\n2) +1\n2KL(Q||(P+Q)\n2)\nKL(P||Q) =X\nxP(x) log(P(x)\nQ(x))\nFor our purposes, given that every website does not address\nevery topic, as recommended in other works, we add a small\nvalue \u03f5= 0.1to the counts of every website\u2019s topics before\ncalculating each website\u2019s probability distribution.\nAppendix F.\nAuto-Generated Summaries and Cluster Specificity\nNarr. Keywords Auto-Generated Summary Random Sample Passage\n1 trudeau, motion,\n151, 185,\nemergency,The Canadian Parliament voted Monday night to approve Prime Minister Justin Trudeau\u2019s\nmotion to invoke the Emergencies Act by a vote of 185 for and 151 against.On Monday night, Canada\u2019s parliament voted to confirm Prime Minister Trudeau\u2019s\ndeclaration of the Emergencies Act in response to the freedom protests that have swept\nacross the nation for three weeks.\n2 manchin, filibuster,\nschumer, sinema,\nsenateRepublicans and other critics immediately started to wonder: If Democrats extract what\nthey want out of Manchin, couldn\u2019t even a small number of them promptly refuse to go\nalong with the secondary assurances he\u2019s been promised?[The pipeline Manchin was promised] would require passage of legislation that would\noverhaul the permitting process for energy infrastructure, according to The American\nProspect, a liberal website. Apparently, progressives in the House are not keen on\nsupporting a measure that could undercut the IRA s down payment on clean energy by\naccelerating approval for energy projects that could ramp up U.S. fossil fuel production\nand exports of natural gas, The American Prospect reported.\n3 agrawal, musk,\nparag, ceo, twitterTwitter CEO Parag Agrawal tweeted he was \u201dexcited\u201d that Musk would join Twitter\u2019s\nboard after it was revealed that Musk bought a 9.2 percent stake in the company, and in\ndoing so became its largest shareholder.When Musk\u2019s takeover of Twitter became official, Agrawal and Bret gave comments\nalongside the Tesla CEO.\n4 capitol, committe,\nhearing, select,\njanuaryThe House of Representatives committee investigating the Jan. 6, 2021, attack on the\nU.S. Capitol is planning to hold its next hearing on Sept. 28.The U.S. House of Representatives select committee investigating the deadly Jan. 6, 2021,\nattack on the Capitol will conduct its next hearing on Oct. 13, the panel said in a statement\non Thursday.\n5 smith, slap, black,\noscar, rockApparently, whites can\u2019t be outraged by Will Smith s slap without being racist. And never\nmind that plenty of blacks including Kareem Abdul-Jabbar were also outragedI elaborated that Will Smith proved he believes violence is the way to handle disagreement.\nHe makes blacks look bad his slap reinforces the widely held stereotype that blacks are\nviolent. He shamed AMPAS before the world.\n6 extremist,\nmaryland, walkby,\nvirginia, protestThe group that calls itself Ruth Sent Us announced its plans on a website to harass the\njustices. It said: Announcing Walkby Wednesday, May 11, 2022!At the homes of the six\nextremist justices, three in Virginia and three in Maryland.RSU subsequently announced a WalkBy Wednesday protest on May 11, to be held in\nfront of the homes of the six extremist justices\n7 cornyn, boo, con-\nvent, texas, gopU.S. Senator John Cornyn RTexas was loudly booed at the Republican Party of Texas\nConvention in Houston, where the state GOP adopted a resolution condemning the\nbipartisan gun control framework he has negotiated in the Senate.Very loud boos for John Cornyn as he takes the stage at the TexasGOP convention. Cornyn\nhas faced opposition within the party for working with Democrats on a gun package after\nthe shooting in Uvalde.\n8 threat, truss, china,\nuk, britainPrime Minister Liz Truss is for the first time due to officially declare China a threat to the\nUK within days. The designation would be a formal update to former PM Boris Johnson\ns Integrated Review of Defense and Foreign Policy published in March 2021.On October 11, The Guardian reported that the Liz Truss government is going to\nformally designate China a national \u201dthreat\u201d to Britain in its upcoming strategic defense\nreview. Under former Prime Minister Boris Johnson, China was named just a \u201dsystemic\ncompetitor.\n9 lithuania, vilniu,\nbaltic, beijing,\nexportChina has called for a corporate boycott of the small Baltic nation. The move is in\nretaliation for Lithuania\u2019s decision to open a Taiwanese representative office in its capital\nof Vilnius in November 2021.In a letter last month, the GermanBaltic Chamber of Commerce demanded that Lithuania\ncome to a constructive solution with the communist nation, saying per Reuters: The basic\nbusiness model of the companies is in question and some will have no other choice than\nto shut down production in Lithuania.\n10 curfew, quebec,\nprovince, legault,\nmontrealQuebec first imposed a COVID curfew on January 9, 2021, which was lifted on May 28.\nQuebec is the only province in Canada to have imposed a curfew during the pandemicQuebec is the first province to impose such a system on its citizens. It \u00b4s also the only\nprovince in Canada that has a curfew in place.\nExample of the auto-generated summaries and passages from a set of 10 random narrative clusters to illustrate the specificity and the precision of our approach.\nAppendix G.\nPaper Reviews\nG.1. Summary of Paper\nThis paper introduced a system to automatically track\nnews narratives spread online. The paper analyzed news\nacross over 1334 unreliable news sites and identified 52K\nnarratives. Using the data, the authors examined news sites\nthat amplify the narratives and showed how the information\ncan be used to help with fact-checking.\nG.2. Scientific Contributions\n1) Creates a New Tool to Enable Future Science\n2) Provides a Valuable Step Forward in an Established\nField\nG.3. Reasons for Acceptance\n1) The paper provides a valuable step forward in an\nestablished field. The paper shows an end-to-end\nsystem to keep track of narratives of (fake) news\nover a large number of unreliable news websites.\nThe authors collected months of data across more\nthan 1334 news websites and identified over 52K\nnarratives. The analysis provided new insights into\nthe impact of the characteristics of the outlets on\nthe efficacy of the propagation of narratives in terms\nof origination and amplification and the roles that\nsocial media sites (8kun and 4chan) play.\n2) The paper creates a new tool to enable future\nscience. The narrative tracking system leverages a\nrange of NLP and clustering tools. The ability to\ntrack different narratives can potentially help with\nidentifying new misinformation for fact-checkers to\naudit. The authors plan to make the data available\nto researchers (and fact-checkers).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Specious sites: Tracking the spread and sway of spurious news stories at scale", "author": ["HWA Hanley", "D Kumar"], "pub_year": "2024", "venue": "2024 IEEE Symposium on \u2026", "abstract": "Misinformation, propaganda, and outright lies proliferate on the web, with some narratives  having dangerous real-world consequences on public health, elections, and individual safety."}, "filled": false, "gsrank": 253, "pub_url": "https://ieeexplore.ieee.org/abstract/document/10646651/", "author_id": ["ewdWfOoAAAAJ", "JoKEquUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:j_3snB34aWAJ:scholar.google.com/&output=cite&scirp=252&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D250%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=j_3snB34aWAJ&ei=MrWsaIHlAr_SieoPzJnloAQ&json=", "num_citations": 16, "citedby_url": "/scholar?cites=6947356706266217871&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:j_3snB34aWAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2308.02068"}}, {"title": "Predicting the politics of an image using webly supervised data", "year": "2019", "pdf_data": "Predicting the Politics of an Image Using Webly\nSupervised Data\nChristopher Thomas Adriana Kovashka\nDepartment of Computer Science\nUniversity of Pittsburgh\nPittsburgh, PA 15213\n{chris,kovashka}@cs.pitt.edu\nAbstract\nThe news media shape public opinion, and often, the visual bias they contain is\nevident for human observers. This bias can be inferred from how different media\nsources portray different subjects or topics. In this paper, we model visual political\nbias in contemporary media sources at scale, using webly supervised data. We\ncollect a dataset of over one million unique images and associated news articles\nfrom left- and right-leaning news sources, and develop a method to predict the\nimage\u2019s political leaning. This problem is particularly challenging because of\nthe enormous intra-class visual and semantic diversity of our data. We propose\na two-stage method to tackle this problem. In the \ufb01rst stage, the model is forced\nto learn relevant visual concepts that, when joined with document embeddings\ncomputed from articles paired with the images, enable the model to predict bias.\nIn the second stage, we remove the requirement of the text domain and train a\nvisual classi\ufb01er from the features of the former model. We show this two-stage\napproach facilitates learning and outperforms several strong baselines. We also\npresent extensive qualitative results demonstrating the nuances of the data.\n1 Introduction\nOne of the goals of the media is to inform, but in practice, the media also shapes opinions [ 23,\n53,2,20,57,44]. The same issue can be presented from multiple perspectives, both in terms of\nthe text written in an article, and the visual content chosen to illustrate the article. For example,\nwhen speaking of immigration, left-leaning sources might showcase the struggles of well-meaning\nimmigrants, while right-leaning sources might portray the misdeeds of criminal immigrants. The\ntype of topics portrayed is also strong cue for the left or right bias of the source media (e.g. tradition\nis primarily seen as a value on the right, while diversity is seen as a value on the left [15]).\nIn this paper, we present a method for recognizing the political bias of an image, which we de\ufb01ne\nas whether the image came from a left- or right-leaning media source. This requires understanding:\n1) what visual concepts to look for in images, and 2) how these visual concepts are portrayed\nacross the spectrum. Note that this is a very challenging task because many of the concepts that we\naim to learn show serious visual variability within the left and right. For example, the concept of\n\u201cimmigration\u201d can be illustrated with a photo of a border wall, children crying behind bars while\ndetained, immigration agents, protests and demonstrations about the issue, politicians giving speeches,\netc. Human viewers account for such within-class variance by generalizing what they see into broader\nsemantic concepts or themes using prior knowledge, deduction, and reasoning.\nOn the other hand, modern CNN architectures learn by discovering recurring textures or edges\nrepresenting objects in the images through backpropagation. However, the same objects might appear\nand be discussed across the political spectrum, meaning that the simple presence or absence of objects\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nis not a good indicator of the politics of an image. Thus, model training may fall into poor local\nminima due to the lack of a recurring discriminative signal. Further, it is not merely the presence or\nabsence of objects that matters, but rather how they are portrayed, often in subtle ways.\nIn order to capture the visual concepts necessary to predict the politics of an image, we propose a\nmethod which uses an auxiliary channel at training time, namely the article text that the image is\npaired with. Our method contains two stages. In the \ufb01rst one, we learn a document embedding model\non the articles, then train a model to predict the bias of the image, given the image and the paired\ndocument embedding. To be successful on this task, the model learns to recognize visual cues which\ncomplement the textual embedding and suggest the politics of the image-text pair. At test time, we\nwant to recognize bias from images alone, without any article text. Thus, in the second training stage\nof the model, we use the \ufb01rst stage model as a feature extractor and train a linear bias classi\ufb01er on\ntop. The article text serves as a type of privileged information to help guide learning.\nSince recognizing the right semantic and visual concepts amidst intra-class variance requires large\namounts of data, we train our approach on webly supervised data: the only labels are in the form of\nthe political leaning of the source that the image came from. However, for testing purposes, we collect\nhuman annotations and test on images where annotators agreed on the label. We experimentally show\nthat our method outperforms numerous baselines on both a large held-out webly supervised test set,\nand the set of crowdsourced annotations.\nWe believe that recognizing the political bias of a photograph is an important step towards building\nsocially-aware computer vision systems. Such awareness is necessary if we hope to use computer\nvision systems to automatically tag or describe images (e.g. for the visually impaired) or to summarize\nlarge collections of potentially biased visual content. Social media companies or search engines may\ndeploy such techniques to automatically identify the political bent of images or even entire news\nsites being spread or linked to. Progress has already been made in this space in other domains. For\nexample, Facebook automatically determines users\u2019 political leanings from site activity and pages\nliked [ 40]. Other works have studied predicting political af\ufb01liation from text [ 11,73,68] or even\nMRI scans [ 58]. However, visual bias understanding has been greatly underexplored. While some\nwork examines visual persuasion [31, 26], none analyzes political leaning as we do.\nOur contributions are as follows:\n\u000fWe propose and make available1a very large dataset of biased images with paired text, and\na large amount of diverse crowdsourced annotations regarding political bias.\n\u000fWe propose a weakly supervised method for predicting the political leaning of an image by\nusing noisy auxiliary textual data at training time.\n\u000fWe perform a detailed experimental analysis of our method on both webly supervised and\nhuman annotated data, and demonstrate the factors humans use to predict bias in images.\n\u000fWe show qualitative results that demonstrate the relationship between images and semantic\nconcepts, and the variability in how faces of the same person appear on the left or the right.\n2 Related Work\nWeakly supervised learning. Our work is in the weakly supervised setting, in the sense that other\nthan noisy left/right labels, our method does not receive information about what makes an image left-\nor right-leaning. This is challenging because there is signi\ufb01cant variety in the type of content that can\nbe left-leaning or right-leaning. Thus, our method needs to identify relevant visual concepts based on\nwhich to make its predictions. Recently, weakly supervised approaches have been proposed for classic\ntopics such as object detection [ 45,8,78,72,75], action localization [ 69,56], etc. Researchers have\nalso developed techniques for learning from potentially noisy web data, e.g. [ 7]. Also related is work\nin unsupervised discovery of patterns and topic modeling, e.g. [ 37,38,61,62,79,27,13,63,18]. In\ncontrast to these works, our problem exhibits much larger within-class variance (with left and right\nbeing the classes of interest). Unlike objects and actions, the differences between left and right live in\nsemantic space as much as they do in visual space, hence our use of auxiliary training inputs.\nCurriculum learning. Also relevant are self-paced and curriculum learning approaches [ 28,51,\n76,77,29]. These attempt to simplify learning by \ufb01nding \u201ceasy\u201d examples to learn with \ufb01rst. We too\n1Our dataset, code, and additional materials are available online for download here:\nhttp://www.cs.pitt.edu/ \u0018chris/politics\n2\nemploy a type of curriculum learning. We \ufb01rst train a multi-modal classi\ufb01er to predict bias, using the\nassumption that the relation between text and bias is more direct. We then leverage this model as a\nfeature extractor by adding an image-only politics classi\ufb01er on top of it. Thus, our method focuses\nthe model on relevant visual concepts using text.\nPrivileged information. Our method also exploits a similar intuition as privileged information\nmethods [ 65,60,25,43,17,22,4,35] that use an extra feature input at training time. These\napproaches use tied weights [ 4], computing summary statistics [ 60,35], or multitask training [ 17] to\nguide learning. The closest such method to ours is [ 22] which uses an approach trained to predict\ntext embeddings from images. The features are then applied on visual-only data. However, in early\nexperiments we showed directly predicting text embeddings from images is much more challenging\non our data because of the many-to-many relationship of images with topics (e.g. image of the White\nHouse can be paired with text about Trump\u2019s children, border control, LGBT rights, etc.).\nConnecting images and text. To learn the meaning of the images, we elevate the image represen-\ntation to a semantic one, by connecting images and text. However, because our texts contain a lot\nof information not relevant to the image, our main method does not predict text from the image.\nThe latter task has received sustained interest [ 67,14,30,66,48,6,12,1,16,74] but our domain is\nunique in that articles that are paired with our images are orders of magnitude longer.\nVisual rhetoric. Our work also belongs to a recent trend of developing algorithms to analyze visual\nmedia and the strategies that a media creator uses to convey a message. [ 31,32] analyze the skills and\ncharacteristics that a politician is implied to have through a photo, e.g. \u201ccompetent\u201d; we adapt their\nmethod as a baseline in our setting. [ 49] study differences in facial portrayals between presidential\ncandidates, and [ 70,71] examine visual differences between supporters of the left or right. We learn\ntogenerate faces from the left and right. Further, we examine differences in general images rather\nthan just faces. [ 26,74] predict the persuasive messages of advertisements, but persuasion in political\nimages is more subtle. These works are based on careful and expensive human annotations, while we\naim to discover facets of bias in a weakly supervised way.\nBias prediction in language. Prior work in NLP has discovered indicators of biased language and\npolitical framing (i.e. presenting an event or person in a positive or negative light). For example,\n[54,3] use carefully designed dictionary, lexical, grammatical and content features to detect biased\nlanguage, using supervision over short phrases. Others [ 50,9,10,11,73,68] have studied predicting\npolitics from text. In contrast, it is not clear what \u201clexicon\u201d of biased content to use for images.\n3 Dataset\nBecause no dataset exists for this problem, we assembled a large dataset of images and\ntext about contemporary politically charged topics. We got a list of \u201cbiased\u201d sources from\nmediabiasfactcheck.com which places news media on a spectrum from extreme left to extreme\nright. We used [ 47] to get a list of current \u201chot topics\u201d e.g. immigration, LGBT rights, welfare,\nterrorism, the environment, etc. We crawled the media sources that were labeled left/right or extreme\nleft/right for images using each of these topics as queries. After identifying images associated with\neach keyword and the pages they were on, we used [ 52] to extract articles. We obtained 1,861,336\nimages total and 1,559,004 articles total. We manually removed boilerplate text (headers, copyrights,\netc.) which leaked into some articles.\n3.1 Data deduplication\nBecause sources cover the same events, some images are published multiple times. To prevent models\nfrom \u201ccheating\u201d by memorization, all experiments are performed on a \u201cdeduplicated\u201d subset of our\ndata. We extract features from a Resnet [ 24] model for all images. Because computing distances\nbetween all pairs is intractable, we use [ 39] for approximate kNN search ( k= 200 ). We set a\nthreshold on neighbors\u2019 distances to \ufb01nd duplicates and near-duplicates. We determine the threshold\nempirically by examining hundreds of kNN matches to ensure all near-duplicates are detected. From\neach set of duplicates, we select one image (and its associated article) to remain in our \u201cdeduplicated\u201d\ndataset while excluding all others. If the same image appeared in both left and right media sources,\nwe keep it on the side where it was more common, e.g. one left source and three right sources would\nresult in preserving one of the image-text pairs from the right sources. After removing duplicates, we\nare left with 1,079,588 unique images and paired text on which the remainder of this paper is based.\n3\nMajority Agree No Consensus\n Unanimous\nFigure 1: We asked workers to predict the political leaning of images. We show examples here where\nall annotators agree, the majority agree, and where there was no consensus.\n3.2 Crowdsourcing annotations\nWe treat the problem of predicting bias as a weakly supervised task. For training, we assume all\nimage-text pairs have the political leaning of the source they come from. In Sec. 5.3 we show that\nthis assumption is reasonable by leveraging human labels, though it is certainly not correct for all\nimages / text, e.g. a left-leaning source may publish a right-leaning image to critique it. In order\nto better explore this assumption and understand human conceptions of bias, we ran a large-scale\ncrowdsourcing study on Amazon Mechanical Turk (MTurk). We asked workers to guess the political\nleaning of images by indicating whether the image favored the left, right, or was unclear. In total,\nwe showed 3,237 images to at least three workers each. We show examples of different levels of\nagreement in Fig. 1. In total, 993 were labeled with a clear L/R label by at least a majority. We also\nasked what image features were used to make their guess. The features workers could choose (and the\ncount of each agreed upon) was: closeup-90 (closeup of speci\ufb01c person\u2019s face), known person-409\n(portrays public \ufb01gure in political way), multiple people-237 (group or class of people portrayed in\npolitical way), no people-81 (scenes or objects associated with parties, e.g. windmill/left, gun/right),\nsymbols-104 (e.g. swastika, pride \ufb02ag), non-photographic-130 (cartoons, charts, etc.), logos-77 (logo\nof e.g. CNN, FOX, etc.), and text in image-267 (e.g. text on protest signs, captions, etc.).\nWe also showed workers the image\u2019s article and asked a series of questions about the image-text\npair, such as the political leaning of the pair (as opposed to image only), the topic (e.g. terrorism,\nLGBT) the pair is related to, and which article text best aligned with the image. We computed\nagreement scores and found that 2.45 out 3 annotators agreed on bias label on average, while 1.71 out\nof 3 agreed on topic, on average. Finally, we asked workers to provide a free-form text explanation\nof their politics prediction for a small number of images. We extracted semantic concepts from\nthese explanations and later use them to train one of our baseline methods (Sec. 5.1). Humans often\nmentioned using the positive/negative portrayal of public \ufb01gures and the gender, race and ethnicity of\nphoto subjects. We provide a demonstration of differences in portrayal across L/R in Sec. 5.5. Absent\nthese cues, workers used stereotypical notions of what issues the left/right discuss or their values. For\nexample, for images of protests or college women, annotators might guess \u201cleft\u201d.\nTo ensure quality, we used validation images with obvious bias to disqualify careless workers. We\nrestricted our task to US workers who passed a quali\ufb01cation test, had \u001598% approval rate, and\nwho had completed \u00151,000 HITs. In total, we collected 14,327 sets of annotations (each containing\nimage bias label, image-text pair bias label, topic, etc.) at a cost of $4,771. We include a number of\nexperimental results on this human annotated set of images in Sec. 5.3.\n4 Approach\nWe hypothesize that the complementary textual domain provides a useful cue to guide the training of\nour visual bias classi\ufb01er. The text of the articles includes words that clearly correlate with political\nbias, e.g. \u201cunite\u201d, \u201cmedicaid\u201d, \u201cdonations\u201d, \u201chomosexuality\u201d, \u201cPutin\u201d, \u201cAntifa\u201d and \u201cbrutality\u201d\nstrongly correlate with left bias according to our model, while \u201cdefend\u201d, \u201cretired\u201d, \u201cNRA\u201d, \u201cminister\u201d\nand \u201ccooperation\u201d strongly correlate with right bias. By factoring out these semantic concepts into the\nauxiliary text domain, we enable our model to learn complementary visual cues. We use information\n\ufb02owing from the visual pipeline, and fuse it with the document embedding as an auxiliary source of\ninformation. Because we are primarily interested in visual political bias, we next remove our model\u2019s\nreliance on textual features, but keep all convolutional layers \ufb01xed. We train a linear bias classi\ufb01er on\ntop of the \ufb01rst model, using it as a feature extractor. Thus, at test time, our model predicts the bias of\nan image without using any text . We illustrate our method in Fig. 2.\n4\nResnet\n500 D\nFusionStep 1 \u2013Feature LearningPaired textBlack lives \nmatter \nprotestors \nmarched\u2026\n\ud835\udc30t\u2212k\ud835\udc30t+k\u2026\ud835\udc1dMLP\ud835\udc30t\nDocument \nEmbeddingModelLR\ud835\udf15\ud835\udc3f\n\ud835\udf15\ud835\udf03\nClassification\nLossStep 2 \u2013Train Classifier\nFeaturesPretrained\nmodelRemove fusion\nLayers \nfrozen\nNo text used\n\ud835\udf15\ud835\udc3f\n\ud835\udf15\ud835\udf03\nFeatures\nClassifierLRTrain classifier using extracted features\nClassification\nLossFigure 2: We propose a two-stage approach. In stage 1, we learn visual features jointly with paired\ntext for bias classi\ufb01cation. In stage 2, we remove the text dependency by training a classi\ufb01er on top\nof our prior model using purely visual features. We show that this approach signi\ufb01cantly outperforms\ndirectly training a model to predict bias. See Sec. 4.1 for details.\n4.1 Method details\nWe wish to capture the implicit semantics of an image by leveraging the association between images\nand text. More speci\ufb01cally, letD=fxi;ai;yigN\ni=1(1)\ndenote our dataset D, where xirepresents image i,ai, represents the textual article associated with\ntheithimage, and yirepresents the political leaning of the image. In the \ufb01rst stage of our method,\nwe seek the following function:\nf\u0012(xi;\n (ai)) =yi (2)\nwhere \n (:)represents transforming the article text into a latent feature space. We train Doc2Vec\n[36] of\ufb02ine on our train set of articles to parameterize \n. Speci\ufb01cally, \nis trained to maximize the\naverage log probability\n1\nTTX\nt=1logp(wtjd;wt\u0000k;:::; wt+k) (3)\nwhereTis the number of words in article a(we omit the index ito simplify notation), prepresents\nthe probability of the indicated word, wtis the learned embedding for word tof article a,dis\nthe learned document embedding of a(200D), and kis the window around the word to look when\ntraining the model. We use hierarchical softmax [ 42] to compute p. We train Doc2Vec on our corpus\nof news articles, and observe more intuitive embeddings than from a pretrained model.\nAfter training, we compute \nfor a given article aby \ufb01nding the embedding dthat maximizes Eq. 3.\n\nthus projects each article into a space where the resulting vector captures the overall latent context\nand topic of the article. We provide \n (a)to our model\u2019s fusion layer for each train image. The\nfusion layer is a linear layer which receives concatenated image and text features and learns to project\nthem into a multimodal image-text embedding space which is \ufb01nally used by the classi\ufb01er.\nThe formulation of f\u0012(:)described above requires that the ground-truth text be available at test time\nand also does not ensure that our model is learning visual bias (i.e. the classi\ufb01er may be relying\nprimarily on text features and ignoring the visual channel completely). To address this problem, in the\nsecond stage of our method, we \ufb01netune f\u0012to directly predict the politics of an image only , without\nthe text, as follows: f0\n\u0012;\u00120(xi) =yi. Speci\ufb01cally, we freeze the trained convolutional parameters of\nf\u0012and add a \ufb01nal linear classi\ufb01er layer to the network, whose parameters are denoted \u00120. Because\nf\u0012\u2019s convolutional layers have already been trained jointly with text features, they have already\nlearned to extract visual features which complemented the text domain; we now learn to use those\nfeatures alone for bias prediction, as shown in Fig. 2.\n4.2 Implementation details\nAll methods use the Resnet-50 [ 24] architecture and are initialized with a pretrained Imagenet model.\nWe train all models using Adam [ 34], with learning rate of 1.0e-4 and minibatch size of 64 images.\nWe use cross-entropy loss and apply class-weight balancing to correct for slight data imbalance\nbetween L/R. We use an image size of 224x224 and random horizontal \ufb02ipping as data augmentation.\nWe use Xavier initialization [ 21] for non-pretrained layers. We use PyTorch [ 46] to train all image\n5\nmodels. For our text embedding, we use [55], with d2R200\u00021and train using distributed memory\n[36] for 20 epochs with window size k= 20 , ignoring words which appear less than 20 times.\n5 Experiments\nIn this section, we demonstrate our method\u2019s performance at predicting left/right bias. We show\nresults on a large held-out test set from our dataset, whose left/right labels come from the leaning\nof the news source containing the image. We also show results on test images for which a majority\nof human annotators agreed on the bias and show how humans reason about visual bias. We show\nthat seeing the complementary text information helped humans become more accurate at this task,\nmuch like seeing the text at training time helps our algorithm. We also show the challenge of\nour task through across-class nearest-neighbors, how the portrayal of politicians differs from the\nleft to the right, images that best match various words from articles, and visualize how our model\nmakes decisions about visual bias. Our supp. contains additional results such as results per-media\nsource / per-political issue, an exploration of the learned text embedding space, failure cases for\nmachines/humans, humans\u2019 reasoning behind their bias decisions, and examples from our dataset.\n5.1 Methods compared\nFor quantitative results, we show the accuracy of each method on predicting left/right bias. We\ncompare against the following baselines:\n\u000fRESNET [24] - A standard 50-layer classi\ufb01cation Resnet.\n\u000fJOO[31]- Adaptation of Joo et al.\u2019s method for our task. We use [ 31]\u2019s dataset to train predictors\nfor 15 attributes and nine \u201cintents\u201d (qualities the photo subject is estimated to have, e.g. trustwor-\nthiness, competence). We then use the predictions for these attributes and intents on images from\nour dataset as additional features to a Resnet to predict a left/right leaning.\n\u000fHUMAN CONCEPTS - We use the manually extracted vocabulary of bias-related concepts (e.g.\n\u201cconfederate\u201d, \u201cAfrican-American\u201d) from the human-provided explanations (Sec. 3.2) and download\ndata for each from Google Image Search. We train a separate Resnet to predict concepts, and use it\non each image in our dataset: p(cjjxi)denotes the probability that image xiexhibits concept cj.\nWe then use the con\ufb01dence of each detected concept, as a feature vector to predict bias.\n\u000fOCR - We use [ 41] to recognize free-form scene text in images. Because images contain words\nnot found in the default lexicon (e.g. Manafort), we create our own lexicon from the 100k most\ncommon words in our articles. We use [ 19] for spelling correction. We represent each recognized\nword as its learned word embedding, denoted w0\ni, weighed by the con\ufb01dence of the recognition\np(w0\ni)as provided by the recognition model. The feature is thus given by1\nnPn\ni=1p(w0\ni)w0\ni.\nAll methods use the same residual network architecture. For methods relying on additional features,\nwe use the fusion architecture in Fig. 2. For reference, we also show an upper-bound method OURS\n(GT) which uses the Ground Truth text paired with the images at test time (to compute a document\nembedding), in addition to the image. We thus consider it an upper-bound to the task of visual only\nprediction. OURS (GT) is the same as the \ufb01rst stage of our approach (see Fig. 2, left), without the\naddition of the image classi\ufb01er layer in step 2.\n5.2 Evaluating on weakly supervised labels\nIn Table 1, we show the results of evaluating our methods on 75,148 held-out images with weakly\nsupervised labels. Our method performs best overall. The top two performing methods rely on\nsemantics discovered in the text domain ( OURS andOCR ).OCR is unique in that it is able to\nexplicitly use text information at test time, by discovering text within the image and then using word\nembeddings. OURS improves over OCR by 2.6% (relative 3.8%, reduction in error of 8%). The\nimprovement of OURS over RESNET is 3.4% (relative 5%, error reduction of 11%). This amounts to\nclassifying an additional \u00182,555 images correctly. Relying on the concepts humans identi\ufb01ed actually\nslightly hurt performance compared to RESNET . This may be because of a disconnect between\nhumans\u2019 preconceived notions about L/R and those required by the dataset. We \ufb01nally observe JOO\nperforms the weakest, likely because [ 31]\u2019s data mainly features closeups of politicians, while ours\ncontains a much broader image range.\n6\nMethod RESNET JOO HUMAN CONCEPTS OCR OURS OURS(GT)\nAccuracy 0.678 0.670 0.675 0.686 0.712 0.803\nTable 1: Accuracy on weakly supervised labels with the best visual-only prediction method in bold.\nFeature/Method RESNET JOO HUMAN CONCEPTS OCR OURS OURS(GT)\nCloseup 0.567 0.544 0.622 0.578 0.656 0.578\nKnown Person 0.567 0.550 0.570 0.560 0.521 0.575\nMultiple People 0.722 0.671 0.688 0.730 0.768 0.705\nNo People 0.556 0.605 0.494 0.580 0.593 0.667\nSymbols 0.558 0.596 0.548 0.577 0.606 0.587\nNon-Photographic 0.577 0.569 0.584 0.577 0.585 0.654\nLogos 0.545 0.584 0.597 0.662 0.623 0.584\nText in Image 0.629 0.625 0.596 0.637 0.607 0.659\nAverage 0.590 0.593 0.587 0.613 0.620 0.626\nTable 2: Accuracy on human consensus labels with the best visual-only prediction method in bold.\n5.3 Evaluating on human labels\nWe next tested our methods on test images which at least a majority of MTurkers labeled as having\nthe same bias, i.e. those that humans agreed had a particular label. We describe this dataset in\nSec. 3.2. Because workers also labeled images with what features of the image they used to make\ntheir prediction, we also break down each method\u2019s performance by feature. We show this result in\nTable 2. OURS performs best on average across all categories and performs best on four out of eight\ncategories. Categories where OURS is outperformed on are reasonable: OCR performs best when\ntext can be relied on in the image, i.e. \u201clogos\u201d and \u201ctext in image\u201d. We note that while the overall\nresult for OCR approaches OURS,OURS works better on a broader set of images than OCR and\nis thus a more general method for predicting visual bias. OURS is also outperformed by HUMAN\nCONCEPTS when humans relied on a known face (politician, celebrity, etc.). This may be because\nHUMAN CONCEPTS relies on external training data (Sec. 5.1) which feature many known individuals,\ne.g. \u201crappers\u201d and \u201cfounding fathers\u201d. JOOoutperforms our method when the prediction depends on\nscene context (\u201cno people\u201d), again likely because JOOuses an external human-labeled dataset to learn\nfeatures, including scene attributes (e.g. indoor, background, national \ufb02ag, etc.). We note OURS (GT)\nperforms sig. worse on human labels vs. weakly-supervised labels. This is likely because OURS (GT)\nhas learned to exploit dataset-speci\ufb01c features (e.g. author names, header text, etc.) for prediction,\nwhich does not actually translate into humans\u2019 commonsense understanding of political bias.\nWe next test whether our assumption that all images harvested from a right- or left-leaning source\nexhibit that type of bias is reasonable. Several results computed from our ground-truth human study\nsuggest that our web labels are a reasonable approximation of bias. First, we observe that the relative\nperformance of the methods across Table 1 and 2 is roughly maintained; OURS is best, followed by\nOCR , and the other methods essentially tied. The results are also sound, e.g. when humans used text,\nOCR tends to do better, which indicates the model\u2019s concept of bias correlates with humans\u2019.\nWe also performed two other experiments to verify our conclusions. First, we explored the difference\nbetween the performance of our method on images on which the majority of humans agreed vs. those\non which humans unanimously agreed. We found that our method worked better when humans\nunanimously labeled the images vs. simple majority (gain of 4.4%). This suggests that as humans\nbecome more certain of bias, our model (trained on noisy data) also performs better. Next, we\nevaluated the impact of text on humans\u2019 bias predictions. We compared how humans changed their\npredictions (made originally using the image only) after they saw the text paired with the image.\nWe found that when workers picked a L/R label, the label was strongly correlated with the weakly\nsupervised label. Moreover, after seeing the text, humans became even more correct with respect to\nthe noisy labels, switching many \u201cunclear\u201d predictions to the \u201ccorrect\u201d label (i.e. the noisy label).\nThis indicates that: 1) our noisy labels are a good approximation of the true bias of the images; and 2)\nthe paired text is useful for predicting bias (a result also borne out by our experiments).\n5.4 Quantitative ablations\nIn order to test the soundness of our method and our experimental design, we performed several\nablations. We \ufb01rst tested the importance of the second stage of our method (right side of Fig. 2). To\ndo so, we used OURS (GT) , the result of the \ufb01rst stage of our method and instead of performing\n7\nOriginal Reconst . Far left Far right Original Reconst . Far left Far right Original Reconst . Far left Far rightFigure 3: We modi\ufb01ed photos to be more left/right. We show the model\u2019s \u201creconstruction\u201d of each\nface next to the original sample, followed by the sample transformed to the far left and right.\n(L) BORDER CONTROL (R) (L) BLACK LIVES MATTER (R) (L) CLIMATE CHANGE (R)\n (L) TERRORISM (R)\nFigure 4: For a set of topics (e.g. LGBT, climate change), we show the closest pair of images across\nthe left/right divide. In each pair, the image on the left is from a left-leaning source, and the one on\nthe right is from a right-leaning source. Note how similar the images in each pair are on the surface.\nstage 2, we removed the dependency on text by zeroing out all text embedding weights in the fusion\nlayer. We evaluated on our weakly supervised test set and obtained 0.677, a result sig. worse than\nour full method, underscoring the importance of stage 2. We next tested how the performance of\nour method varied given the length of the article text. We thus trained our method with the \ufb01rst k\nsentences of the article and obtained these results: k= 1!0:672,k= 2!0:669,k= 5!0:668,\nk= 10!0:669. All choices of ktested performed sig. worse than using the full article (0.712).\nWe \ufb01nally examined how reliant our method was on images from a particular media source being in\nour train set (i.e. to test if the model was learning non-generalizable, source-speci\ufb01c features). We\nexperimented with leaving out all training data harvested from a few popular sources. The result\nwas (before excluding !after excluding): Breitbart (0.607 !0.566), CNN (0.873 !0.866), Com-\nmonDreams (0.647 !0.636), DailyCaller (0.703 !0.667), DemocraticUnderground (0.713 !0.700),\nNewsMax (0.685!0.628), and TheBlaze (0.746 !0.742). We observed only a slight decrease for all\nsources we tested, suggesting our method is not dependent on seeing the source at train time.\n5.5 Qualitative results\nModeling facial differences across politics: Many workers noted how politicians were portrayed\nin making their decision (Sec. 3.2). To visualize the differences in how well-known individuals are\nportrayed within our dataset, we trained a generative model to modify a given Trump/Clinton/Obama\nface, and make it appear as if it came from a left/right leaning source. We use a variation of\nthe autoencoder-based model from [ 64], which learns a distribution of facial attributes and latent\nfeatures on ads, not political images. We train the model using the features from the original\nmethod on faces of Trump/Clinton/Obama detected in our dataset using [ 33]. We use [ 59] for face\nrecognition. To modify an image, we condition the generator on the image\u2019s embedding and modify\nthe distribution of attributes/expressions for the image to match that person\u2019s average portrayal on the\nleft/right, following [ 64]\u2019s technique. We show the results in Fig. 3. Observe that Trump and Clinton\nappear angry on the far-left/right (respectively) end of the spectrum. In contrast, all three appear\nhappy/benevolent in sources supporting their own party. We also observe Clinton appears younger in\nfar-left sources. In far-right sources, Obama appears confused or embarrassed. These results further\nunderscore that our weakly supervised labels are accurate enough to extract a meaningful signal.\nNearest neighbors across issues and politics: In Fig. 4, we show the challenge of classifying in\nvisual space only. We compute the distance between images from the left and right, and show L/R\npairs that have a small distance in feature space within topics. For BLM, the left image is serious,\nwhile the right image is whimsical. For climate change, one presents a more negative vision, while\nthe other is picturesque. Both border control images show \ufb01re, but the left one is of a Trump ef\ufb01gy.\nFor terrorism, the left image shows a white domestic terrorist while the right shows Middle-Eastern\nmen. These pairs highlight how subtle the distinctions between L/R are for some images.\n8\nLGBT\n Immigrant\n Antifa\n Brutality\nFigure 5: We train a model to predict words from images. The model learns relevant visual cues for\neach word, demonstrating the utility of exploiting text, even for purely visual classi\ufb01cation.\nIMAGEHEATMAP OVERLAY HEATMAP OVERLAY\nOURS RESNET\nFigure 6: We show visual explanations using [ 5]. We note that our model looks to logos and faces of\npublic \ufb01gures, while the baseline uses objects (e.g. mic.) and scene type (e.g. city in background).\nVisualizing image-text alignment: We wanted to see how well our model could align images\nand concepts from text. We formulated a variation of our method which, instead of predicting bias,\npredicted relevant words. We chose a set of 1k words that had the lowest average distance between\ntheir images\u2019 features (i.e. were visually consistent on avg.) from the 10k most frequent words. The\nmodel is trained to predict whether each word is/is not present in the image\u2019s article given the image\nand text embedding. In Fig. 5, we show examples of images that were among the top-100 strongest\npredictions for that word. We see that the model strongly predicts \u201cantifa\u201d for black-clad protestors,\n\u201cbrutality\u201d for police scenes and protests, \u201cimmigrant\u201d for the border wall and Hispanics, and \u201cLGBT\u201d\nfor pride \ufb02ags. Though the image may only relate to a small portion of the lengthy text, there is\nenough visual signal present for the model to learn, demonstrating the bene\ufb01t of leveraging text to\ncomplement the model\u2019s training.\nVisual explanations: We wanted to see whether we could interpret how our model learned to\nperform bias classi\ufb01cation. We used Grad-CAM++ [ 5] to compute attention maps on images that\nhumans annotated. We show the result in Fig. 6. We observe that our model pays the most attention\nto logos and faces of public \ufb01gures. We see the model only focuses on the \u201cPBS\u201d logo in the \ufb01rst row\n(and ignores the face of the lesser known person), but pays attention to both the \u201cFox News\u201d logo\nand the face of the well-known commentator in the second row. We believe that because our model\nwas trained with the topic information provided via the text embedding during stage one, the visual\ncomponent of the model learned to focus on learning visual features that complemented the text (such\nas logos and faces). Ultimately these features work better even without the text.\n6 Conclusion\nWe assembled a large dataset of biased images and paired articles and presented a weakly supervised\napproach for inferring the political bias of images. Our method leverages the image\u2019s paired text to\nguide the model\u2019s training process towards relevant semantics in a way which ultimately improves\nbias classi\ufb01cation. We demonstrate the contribution of our method and dataset both quantitatively and\nqualitatively, including on a large crowdsourced dataset. Use cases of our work include: inferring the\nbias of new media sources, constructing balanced \u201cnews feeds,\u201d or detecting political ads. Broadly\nspeaking, our method demonstrates the potential of using an auxiliary semantic space, e.g. for abstract\ntasks such as video summarization and visual commonsense reasoning.\nAcknowledgement: This material is based upon work supported by the National Science Foundation under\nGrant Number 1566270. It was also supported by an NVIDIA hardware grant. We thank the reviewers for their\nconstructive feedback.\n9\nReferences\n[1]P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang. Bottom-up and top-down\nattention for image captioning and visual question answering. In Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR) , June 2018.\n[2]M. C. Angermeyer and B. Schulze. Reinforcing stereotypes: how the focus on forensic cases in news\nreporting may in\ufb02uence public attitudes towards the mentally ill. International Journal of Law and\nPsychiatry , 2001.\n[3]E. Baumer, E. Elovic, Y . Qin, F. Polletta, and G. Gay. Testing and comparing computational approaches for\nidentifying the language of framing in political news. In Proceedings of the 2015 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies ,\npages 1472\u20131482, 2015.\n[4]G. Borghi, S. Pini, F. Grazioli, R. Vezzani, and R. Cucchiara. Face veri\ufb01cation from depth using privileged\ninformation. In British Machine Vision Conference (BMVC) . Springer, 2018.\n[5]A. Chattopadhay, A. Sarkar, P. Howlader, and V . N. Balasubramanian. Grad-cam++: Generalized gradient-\nbased visual explanations for deep convolutional networks. In 2018 IEEE Winter Conference on Applica-\ntions of Computer Vision (WACV) , pages 839\u2013847. IEEE, 2018.\n[6]T.-H. Chen, Y .-H. Liao, C.-Y . Chuang, W.-T. Hsu, J. Fu, and M. Sun. Show, adapt and tell: Adversarial\ntraining of cross-domain image captioner. In Proceedings of the IEEE International Conference on\nComputer Vision (ICCV) , Oct 2017.\n[7]X. Chen and A. Gupta. Webly supervised learning of convolutional networks. In Proceedings of the IEEE\nInternational Conference on Computer Vision (ICCV) , pages 1431\u20131439, 2015.\n[8]R. G. Cinbis, J. Verbeek, and C. Schmid. Weakly supervised object localization with multi-fold multiple\ninstance learning. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) , 39(1):189\u2013203,\n2016.\n[9]R. Cohen and D. Ruths. Classifying political orientation on twitter: It\u2019s not easy! In Seventh International\nAssociation for the Advancement of Arti\ufb01cial Intelligence (AAAI) Conference on Weblogs and Social Media ,\n2013.\n[10] E. Colleoni, A. Rozza, and A. Arvidsson. Echo chamber or public sphere? predicting political orientation\nand measuring political homophily in twitter using big data. Journal of communication , 64(2):317\u2013332,\n2014.\n[11] M. D. Conover, B. Gon\u00e7alves, J. Ratkiewicz, A. Flammini, and F. Menczer. Predicting the political\nalignment of twitter users. In IEEE Third International Conference on Privacy, Security, Risk and Trust\n(PASSAT) and IEEE Third International Conference on Social Computing (SocialCom) , pages 192\u2013199.\nIEEE, 2011.\n[12] B. Dai, S. Fidler, R. Urtasun, and D. Lin. Towards diverse and natural image descriptions via a conditional\ngan. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) , 2017.\n[13] C. Doersch, S. Singh, A. Gupta, J. Sivic, and A. Efros. What makes paris look like paris? ACM Transactions\non Graphics , 31(4), 2012.\n[14] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell.\nLong-term recurrent convolutional networks for visual recognition and description. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2015.\n[15] T. B. Edsall. Studies: Conservatives are from mars, liberals are from venus,\nFebruary 2012. https://www.theatlantic.com/politics/archive/2012/02/\nstudies-conservatives-are-from-mars-liberals-are-from-venus/252416/ .\n[16] A. Eisenschtat and L. Wolf. Linking image and text with 2-way nets. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition (CVPR) , 2017.\n[17] D. Elliott and \u00c1. K\u00e1d\u00e1r. Imagination improves multimodal translation. In Proceedings of the Eighth\nInternational Joint Conference on Natural Language Processing (Volume 1: Long Papers) , pages 130\u2013141,\n2017.\n[18] L. Fei-Fei and P. Perona. A bayesian hierarchical model for learning natural scene categories. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , volume 2,\npages 524\u2013531. IEEE, 2005.\n[19] W. Garbe. Symspell. https://github.com/wolfgarbe/SymSpell .\n[20] M. Gilens. Race and poverty in americapublic misperceptions and the american news media. Public\nOpinion Quarterly , 60(4):515\u2013541, 1996.\n[21] X. Glorot and Y . Bengio. Understanding the dif\ufb01culty of training deep feedforward neural networks. In\nProceedings of the Thirteenth International Conference on Arti\ufb01cial Intelligence and Statistics (AISTATS) ,\npages 249\u2013256, 2010.\n[22] L. Gomez, Y . Patel, M. Rusinol, D. Karatzas, and C. V . Jawahar. Self-supervised learning of visual features\nthrough embedding images into text topic spaces. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR) , 2017.\n10\n[23] C. Happer and G. Philo. The role of the media in the construction of public belief and social change.\nJournal of Social and Political Psychology , 1(1):321\u2013336, 2013.\n[24] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 770\u2013778, 2016.\n[25] J. Hoffman, S. Gupta, and T. Darrell. Learning with side information through modality hallucination. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 826\u2013834.\nIEEE, 2016.\n[26] Z. Hussain, M. Zhang, X. Zhang, K. Ye, C. Thomas, Z. Agha, N. Ong, and A. Kovashka. Automatic\nunderstanding of image and video advertisements. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR) , July 2017.\n[27] Y . Jae Lee, A. A. Efros, and M. Hebert. Style-aware mid-level representation for discovering visual\nconnections in space and time. In Proceedings of the IEEE International Conference on Computer Vision\n(ICCV) , pages 1857\u20131864, 2013.\n[28] L. Jiang, D. Meng, Q. Zhao, S. Shan, and A. G. Hauptmann. Self-paced curriculum learning. In\nTwenty-Ninth Association for the Advancement of Arti\ufb01cial Intelligence (AAAI) Conference on Arti\ufb01cial\nIntelligence , volume 2, page 6, 2015.\n[29] L. Jiang, Z. Zhou, T. Leung, L.-J. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very\ndeep neural networks on corrupted labels. In Proceedings of the International Conference on Machine\nLearning (ICML) , pages 2309\u20132318, 2018.\n[30] J. Johnson, A. Karpathy, and L. Fei-Fei. Densecap: Fully convolutional localization networks for dense\ncaptioning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,\nJune 2016.\n[31] J. Joo, W. Li, F. F. Steen, and S.-C. Zhu. Visual persuasion: Inferring communicative intents of images. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2014.\n[32] J. Joo, F. F. Steen, and S.-C. Zhu. Automated facial trait judgment and election outcome prediction: Social\ndimensions of face. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) ,\n2015.\n[33] D. E. King. Dlib-ml: A machine learning toolkit. Journal of Machine Learning Research , 10:1755\u20131758,\n2009.\n[34] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. Proceedings of the International\nConference on Learning Representations (ICLR) , 2015.\n[35] J. Lambert, O. Sener, and S. Savarese. Deep learning under privileged information using heteroscedastic\ndropout. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,\nJune 2018.\n[36] Q. Le and T. Mikolov. Distributed representations of sentences and documents. In Proceedings of the\nInternational Conference on Machine Learning (ICML) , pages 1188\u20131196, 2014.\n[37] H. Li, J. G. Ellis, L. Zhang, and S.-F. Chang. Patternnet: Visual pattern mining with deep neural network.\nInProceedings of the 2018 ACM on International Conference on Multimedia Retrieval , pages 291\u2013299.\nACM, 2018.\n[38] Y . Li, L. Liu, C. Shen, and A. Van Den Hengel. Mining mid-level visual patterns with deep cnn activations.\nInternational Journal of Computer Vision (IJCV) , 121(3):344\u2013364, 2017.\n[39] Y . A. Malkov and D. A. Yashunin. Ef\ufb01cient and robust approximate nearest neighbor search using\nhierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence\n(PAMI) , 2016.\n[40] J. B. Merrill. Liberal, moderate or conservative? see how facebook labels you. The New York Times , Aug\n2016.\n[41] B. S. Minghui Liao and X. Bai. TextBoxes++: A single-shot oriented scene text detector. IEEE Transactions\non Image Processing , 27(8):3676\u20133690, 2018.\n[42] F. Morin and Y . Bengio. Hierarchical probabilistic neural network language model. In Tenth International\nWorkshop on Arti\ufb01cial Intelligence and Statistics (AISTATS) , volume 5, pages 246\u2013252. Citeseer, 2005.\n[43] S. Motiian, M. Piccirilli, D. A. Adjeroh, and G. Doretto. Information bottleneck learning using privileged\ninformation for visual recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR) , pages 1496\u20131505. IEEE, 2016.\n[44] C. L. Mu\u00f1oz and T. L. Towner. The image is the message: Instagram marketing and the 2016 presidential\nprimary season. Journal of Political Marketing , 16(3-4):290\u2013318, 2017.\n[45] M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Is object localization for free?-weakly-supervised learning\nwith convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition (CVPR) , pages 685\u2013694, 2015.\n[46] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and\nA. Lerer. Automatic differentiation in pytorch. In Advances in Neural Information Processing Systems\nWorkshops (NIPS-W) , 2017.\n[47] T. Peck and N. Boutelier. Big political data. https://www.isidewith.com/polls . Accessed 2018.\n11\n[48] M. Pedersoli, T. Lucas, C. Schmid, and J. Verbeek. Areas of attention for image captioning. In Proceedings\nof the IEEE International Conference on Computer Vision (ICCV) , Oct 2017.\n[49] Y . Peng. Same candidates, different faces: Uncovering media bias in visual portrayals of presidential\ncandidates with computer vision. Journal of Communication , 68(5):920\u2013941, 2018.\n[50] M. Pennacchiotti and A.-M. Popescu. A machine learning approach to twitter user classi\ufb01cation. In Fifth\nInternational Association for the Advancement of Arti\ufb01cial Intelligence (AAAI) Conference on Weblogs\nand Social Media , 2011.\n[51] A. Pentina, V . Sharmanska, and C. H. Lampert. Curriculum learning of multiple tasks. In Proceedings of\nthe IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 5492\u20135500, 2015.\n[52] M. E. Peters and D. Lecocq. Content extraction using diverse feature sets. In Proceedings of the 22nd\nInternational Conference on World Wide Web (WWW) , pages 89\u201390. ACM, 2013.\n[53] G. Philo. Active audiences and the construction of public knowledge. Journalism Studies , 9(4):535\u2013544,\n2008.\n[54] M. Recasens, C. Danescu-Niculescu-Mizil, and D. Jurafsky. Linguistic models for analyzing and detecting\nbiased language. In Proceedings of the 51st Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , volume 1, pages 1650\u20131659, 2013.\n[55] R.\u02c7Reh\u02da u \u02c7rek and P. Sojka. Software Framework for Topic Modelling with Large Corpora. In Proceedings of\nthe LREC 2010 Workshop on New Challenges for NLP Frameworks , pages 45\u201350, Valletta, Malta, May\n2010. ELRA. http://is.muni.cz/publication/884893/en .\n[56] A. Richard, H. Kuehne, and J. Gall. Weakly supervised action learning with rnn based \ufb01ne-to-coarse\nmodeling. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,\npages 754\u2013763, 2017.\n[57] D. Schill. The visual image and the political image: A review of visual communication research in the\n\ufb01eld of political communication. Review of Communication , 12(2):118\u2013142, 2012.\n[58] D. Schreiber, G. Fonzo, A. N. Simmons, C. T. Dawes, T. Flagan, J. H. Fowler, and M. P. Paulus. Red brain,\nblue brain: Evaluative processes differ in democrats and republicans. PLOS ONE , 8(2):1\u20136, 02 2013.\n[59] F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A uni\ufb01ed embedding for face recognition and\nclustering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,\npages 815\u2013823, 2015.\n[60] V . Sharmanska, N. Quadrianto, and C. H. Lampert. Learning to rank using privileged information. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 825\u2013832.\nIEEE, 2013.\n[61] R. Sicre, Y . S. Avrithis, E. Kijak, and F. Jurie. Unsupervised part learning for visual recognition. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 3116\u2013\n3124, 2017.\n[62] S. Singh, A. Gupta, and A. A. Efros. Unsupervised discovery of mid-level discriminative patches. In\nProceedings of the European Conference on Computer Vision (ECCV) , pages 73\u201386. Springer, 2012.\n[63] J. Sivic, B. C. Russell, A. A. Efros, A. Zisserman, and W. T. Freeman. Discovering objects and their\nlocation in images. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) ,\nvolume 1, pages 370\u2013377. IEEE, 2005.\n[64] C. Thomas and A. Kovashka. Persuasive faces: Generating faces in advertisements. In Proceedings of the\nBritish Machine Vision Conference (BMVC) , 2018.\n[65] V . Vapnik and R. Izmailov. Learning using privileged information: similarity control and knowledge\ntransfer. Journal of Machine Learning Research (JMLR) , 16(2023-2049):2, 2015.\n[66] S. Venugopalan, L. Anne Hendricks, M. Rohrbach, R. Mooney, T. Darrell, and K. Saenko. Captioning\nimages with diverse objects. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR) , July 2017.\n[67] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and tell: A neural image caption generator.\nInProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages\n3156\u20133164, 2015.\n[68] S. V olkova, G. Coppersmith, and B. Van Durme. Inferring user political preferences from streaming\ncommunications. In Proceedings of the 52nd Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , volume 1, pages 186\u2013196, 2014.\n[69] L. Wang, Y . Xiong, D. Lin, and L. Van Gool. Untrimmednets for weakly supervised action recognition and\ndetection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,\npages 4325\u20134334, 2017.\n[70] Y . Wang, Y . Feng, Z. Hong, R. Berger, and J. Luo. How polarized have we become? a multimodal\nclassi\ufb01cation of trump followers and clinton followers. In International Conference on Social Informatics ,\n2017.\n[71] Y . Wang, Y . Li, and J. Luo. Deciphering the 2016 us presidential campaign in the twitter sphere: A\ncomparison of the trumpists and clintonists. In Tenth International Association for the Advancement of\nArti\ufb01cial Intelligence (AAAI) Conference on Web and Social Media , pages 723\u2013726, 2016.\n12\n[72] Y . Wei, Z. Shen, B. Cheng, H. Shi, J. Xiong, J. Feng, and T. Huang. Ts2c: Tight box mining with\nsurrounding segmentation context for weakly supervised object detection. In Proceedings of the European\nConference on Computer Vision (ECCV) , pages 434\u2013450, 2018.\n[73] F. M. F. Wong, C. W. Tan, S. Sen, and M. Chiang. Quantifying political leaning from tweets, retweets, and\nretweeters. IEEE Transactions on Knowledge and Data Engineering , 28(8):2158\u20132172, 2016.\n[74] K. Ye, N. Honarvar Nazari, J. Hahn, Z. Hussain, M. Zhang, and A. Kovashka. Interpreting the rhetoric\nof visual advertisements. To appear, IEEE Transactions on Pattern Analysis and Machine Intelligence\n(PAMI) , 2019.\n[75] K. Ye, M. Zhang, A. Kovashka, W. Li, D. Qin, and J. Berent. Cap2det: Learning to amplify weak caption\nsupervision for object detection. In Proceedings of the IEEE International Conference on Computer Vision\n(ICCV) , Oct 2019.\n[76] A. R. Zamir, T.-L. Wu, L. Sun, W. B. Shen, B. E. Shi, J. Malik, and S. Savarese. Feedback networks.\nInProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages\n1808\u20131817. IEEE, 2017.\n[77] Y . Zhang, P. David, and B. Gong. Curriculum domain adaptation for semantic segmentation of urban scenes.\nInProceedings of the IEEE International Conference on Computer Vision (ICCV) , pages 2020\u20132030, 2017.\n[78] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning deep features for discriminative\nlocalization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,\npages 2921\u20132929, 2016.\n[79] F. Zhou, F. De la Torre, and J. F. Cohn. Unsupervised discovery of facial events. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2574\u20132581. IEEE, 2010.\n13", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Predicting the politics of an image using webly supervised data", "author": ["C Thomas", "A Kovashka"], "pub_year": "2019", "venue": "Advances in neural information \u2026", "abstract": "The news media shape public opinion, and often, the visual bias they contain is evident for  human observers. This bias can be inferred from how different media sources portray"}, "filled": false, "gsrank": 256, "pub_url": "https://proceedings.neurips.cc/paper/2019/hash/e4dd5528f7596dcdf871aa55cfccc53c-Abstract.html", "author_id": ["16r7ZhsAAAAJ", "Dl949GoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:MX1ts9JZ9AsJ:scholar.google.com/&output=cite&scirp=255&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D250%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=MX1ts9JZ9AsJ&ei=MrWsaIHlAr_SieoPzJnloAQ&json=", "num_citations": 29, "citedby_url": "/scholar?cites=861412190222908721&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:MX1ts9JZ9AsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://proceedings.neurips.cc/paper/2019/file/e4dd5528f7596dcdf871aa55cfccc53c-Paper.pdf"}}, {"title": "Fake news w polityce. Studia przypadk\u00f3w", "year": "2019", "pdf_data": "Mediatization StudieS 3/2019  DOI: 10.17951/ms.2019.3.137-150\nMarek PalczewSki\nSWPS U niWerSytet  HUmani Styczno SPo\u0142eczny\nmpalczewski @swps .edu.pl\nORcid : https ://orcid .org/0000-0002-6980-8353\nFake news w polityce. Studia przypadk\u00f3w\nStreszczenie. Celem niniejszego artyku\u0142u jest analiza politycznych fake news\u00f3w w kontek\u015bcie proces\u00f3w \nmediatyzacji. Analizie poddano trzy fa\u0142szywe wiadomo\u015bci: o posiadaniu broni masowego ra\u017cenia przez \nre\u017cim Saddama Husajna; o sprzeda\u017cy broni terrorystom z ISIS przez Hillary Clinton; o rzekomym zab\u00f3j-\nstwie rosyjskiego dziennikarza Arkadija Babczenki. Ponadto om\u00f3wiono: specyfik\u0119, genez\u0119, rodzaje, rol\u0119 \ni znaczenie fake news\u00f3w w kszta\u0142towaniu opinii publicznej oraz w dzia\u0142aniach politycznych. Na podsta-\nwie przedstawionych case studies mo\u017cna wnioskowa\u0107, \u017ce geneza politycznego fake newsa zwi\u0105zana jest \nzawsze z potrzebami i interesami politycznymi, a jego celem jest walka z wrogiem lub eskalacja konfliktu. \nAutorami fake news\u00f3w s\u0105 najcz\u0119\u015bciej organizacje polityczne, agencje wywiadu wojskowego, tajne s\u0142u\u017cby \nspecjalne itp. Fake newsy silnie oddzia\u0142uj\u0105 na nastroje i  opini\u0119 publiczn\u0105 oraz cz\u0119sto prowadz\u0105 do zmiany \nsytuacji spo\u0142eczno-politycznej, a w sytuacjach ekstremalnych \u2013 do dzia\u0142a\u0144 wojennych.\nS\u0142owa kluczowe: fake news; polityka; mediatyzacja polityki; propaganda medialna\nWprowadzenie\nManuel Castells napisa\u0142, \u017ce \u017cyjemy z\u00a0mediami i\u00a0poprzez media, natomiast Ni -\nklas Luhmann stwierdzi\u0142, \u017ce wszystkie informacje o\u00a0\u015bwiecie czerpiemy z\u00a0medi\u00f3w. Te \nwypowiedzi wskazuj\u0105 na moc i\u00a0znaczenie medi\u00f3w w\u00a0konstruowaniu naszej wiedzy \no\u00a0\u015bwiecie. Dotyczy to kwestii zwi\u0105zanych m.in. z\u00a0politycznym obrazem \u015bwiata, kt\u00f3ry \ntworzymy na podstawie przekaz\u00f3w medialnych. Ogromne znaczenie w\u00a0kszta\u0142towaniu \ntego obrazu i\u00a0naszych przekona\u0144 maj\u0105 przekazy informacyjne. Dzi\u0119ki nim mo\u017cemy \npodejmowa\u0107 wa\u017cne decyzje dotycz\u0105ce naszego \u017cycia i\u00a0dokonywa\u0107 wybor\u00f3w. Od ja -\nko\u015bci tego przekazu zale\u017cy wi\u0119c w\u00a0du\u017cym stopniu jako\u015b\u0107 \u017cycia spo\u0142ecznego i\u00a0politycz -\nnego, a\u00a0tak\u017ce stan umys\u0142\u00f3w i\u00a0demokracji. Dlatego tak wa\u017cne jest zrozumienie zjawi -\nska fake news\u00f3w, dostrze\u017cenie ich obecno\u015bci w\u00a0przestrzeni medialnej, umiej\u0119tno\u015b\u0107 rozr\u00f3\u017cnienia fa\u0142szywych informacji od news\u00f3w opartych na faktach oraz znalezienie antidotum przeciwko rozpowszechnianiu nieprawdziwych informacji.Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 138\nCelem niniejszego artyku\u0142u jest analiza politycznych fake news\u00f3w w\u00a0kontek\u015bcie \nproces\u00f3w mediatyzacji oraz poszukiwanie odpowiedzi na pytania o\u00a0specyfik\u0119 fake \nnews\u00f3w w\u00a0dziedzinie polityki, przyczyny i\u00a0konteksty ich powstawania, ich autor\u00f3w \nb\u0105d\u017a \u017ar\u00f3d\u0142a, spos\u00f3b produkcji, struktur\u0119 i\u00a0warto\u015bci informacyjne, funkcj\u0119 i\u00a0rol\u0119 w\u00a0po -\nlityce oraz skutki, jakie wywo\u0142uj\u0105. Punktem wyj\u015bcia analizy jest wprowadzenie nast\u0119 -\npuj\u0105cych poj\u0119\u0107: \u201emediatyzacja\u201d , \u201emediatyzacja polityki\u201d oraz \u201efake news\u201d . W\u00a0drugiej \ncz\u0119\u015bci opracowania zaprezentowano konkretne fake newsy (w\u00a0formie case studies), \nkt\u00f3re sta\u0142y si\u0119 g\u0142o\u015bne ze wzgl\u0119du na sw\u00f3j potencja\u0142 informacyjny oraz wp\u0142yw, jaki \nwywar\u0142y na \u017cycie polityczne i\u00a0stosunki mi\u0119dzynarodowe. Przedstawi\u0142em r\u00f3wnie\u017c \ndyskurs politycznego fake newsa (czyli jego genez\u0119, struktur\u0119, konteksty spo\u0142eczno -\n-polityczne itd.) i\u00a0dokona\u0142em podsumowania g\u0142\u00f3wnego nurtu rozwa\u017ca\u0144. Metod\u0105 \nanalizy, kt\u00f3ra zosta\u0142a zastosowana w\u00a0niniejszym artykule, jest studium przypadk\u00f3w i\u00a0ich odniesienie do proces\u00f3w mediatyzacji polityki.\nMediatyzacja polityki\nMa\u0142gorzata Mol\u0119da-Zdziech w\u00a0ksi\u0105\u017cce Czas celebryt\u00f3w. Mediatyzacja \u017cycia publicz -\nnego  zauwa\u017ca, \u017ce wsp\u00f3\u0142cze\u015bnie media staj\u0105 si\u0119 najwa\u017cniejszym narratorem (Mol\u0119da -\n-Zdziech 2013, s. 27). Badaczka przytacza pogl\u0105d Stiga Hjarvarda, wed\u0142ug kt\u00f3rego me -\ndia s\u0105 rozumiane jako kana\u0142y przekazu, j\u0119zyki i\u00a0\u015brodowiska. Samo poj\u0119cie mediatyzacji \nHjarvard opisuje jako \u201edwustronny proces p \u00f3\u017anej nowoczesno\u015bci, w\u00a0kt \u00f3rym media \n\u2013 z\u00a0jednej strony wy\u0142aniaj\u0105 si\u0119 jako niezale\u017cna instytucja, z\u00a0w\u0142asn \u0105 logik\u0105, do kt\u00f3rej \npozosta\u0142e instytucje spo\u0142eczne musz\u0105 si\u0119 dostosowa\u0107. Z\u00a0drugiej strony media staj \u0105 \nsi\u0119 integraln \u0105 cz\u0119\u015bci\u0105 innych instytucji, takich jak: polityka, praca, rodzina i\u00a0religia\u201d \n(Hjarvard 2008, s. 105, cyt. za: Mol\u0119 da-Zdziech 2013, s. 13). Z\u00a0kolei Friedrich Krotz \nokre\u015bla mediatyzacj\u0119 jako \u201ehistoryczny, ci\u0105g\u0142y, d\u0142ugotrwa\u0142y proces, w\u00a0kt\u00f3rym pojawia \nsi\u0119 coraz wi\u0119cej medi\u00f3w i\u00a0s\u0105 one zinstytucjonalizowane\u201d (Krotz 2008, s. 24, cyt. za: Mol\u0119da-Zdziech 2013, s. 51). Wed\u0142ug Soni Livingston \u201eMediatyzacja oznacza proces spo\u0142eczny, w\u00a0czasie kt\u00f3rego kluczowe elementy spo\u0142ecznej i\u00a0kulturowej aktywno\u015bci (np. polityki, nauczania, religii itp.) przybieraj\u0105 medialn\u0105 form\u0119\u201d (Livingstone 2009, \ns. 6, cyt. za: Mol\u0119da-Zdziech 2013, s. 36). Winfried Schulz pisa\u0142 natomiast o\u00a0r\u00f3\u017cnych \nkoncepcjach relacji pomi\u0119dzy mediami i\u00a0polityk\u0105, w\u00a0tym m.in. o\u00a0zale\u017cno\u015bci polityki od medi\u00f3w masowych oraz o\u00a0instrumentalizacji medi\u00f3w masowych przez polityk\u0119 (Schulz 2006, s. 11 i\u00a0nast.).\nBogus\u0142awa Dobek-Ostrowska mediatyzacj\u0119 umieszcza w\u00a0kontek\u015bcie politycznym, \nzaznaczaj\u0105c, \u017ce mediatyzacja \u017cycia politycznego polega na transformacji i\u00a0modernizacji \nsfery publicznej oraz na zmianie zachowa\u0144 uczestnik\u00f3w komunikowania politycznego pod wp\u0142ywem dw\u00f3ch typ\u00f3w medi\u00f3w: klasycznych \u015brodk\u00f3w masowego przekazu oraz \nnowych \u015brodk\u00f3w sieciowych (Dobek-Ostrowska 2006, s. 158\u2013159). Skutki mediaty -\nzacji mo\u017cna podzieli\u0107 na systemowe i\u00a0personalne (Oniszczuk 2011). Do tych drugich Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\n139 Fake news w polityce. Studia przypadk\u00f3w\nnale\u017cy zalicz\u0107 m.in. wizerunek polityk\u00f3w w\u00a0aspekcie politycznym, etycznym itp., a\u00a0do \npierwszych \u2013 wp\u0142yw na elity polityczne, proces podejmowania decyzji politycznych \noraz zmiany wewn\u0105trz systemu politycznego i\u00a0kszta\u0142towanie wizerunku tego systemu. \nZbigniew Oniszczuk zwraca uwag\u0119 na dwa subsystemy systemu spo\u0142ecznego: polityczny \ni\u00a0medialny, kt\u00f3re funkcjonuj\u0105 w\u00a0symbiozie, aczkolwiek \u2013 jak twierdzi autor \u2013 przewa -\nga w\u00a0pa\u0144stwie demokratycznym jest po stronie \u015brodk\u00f3w masowego komunikowania. \nOniszczuk wyr\u00f3\u017cnia trzy paradygmaty zale\u017cno\u015bci pomi\u0119dzy sfer\u0105 polityki a\u00a0media -\nmi masowymi. S\u0105 to: paradygmat udzia\u0142u we w\u0142adzy (media s\u0105 tutaj pojmowane jako \nczwarta w\u0142adza); paradygmat instrumentalizacji (istnieje dominacja systemu politycz -\nnego nad medialnym lub odwrotnie); paradygmat niezale\u017cno\u015bci i\u00a0symbiozy. Mamy \nzatem relacje symbiotyczne, mediatyzacj\u0119 polityki (dominacja medi\u00f3w) i\u00a0polityzacj\u0119 \nmedi\u00f3w (dominacja polityki). Ta ostatnia wynika z\u00a0d\u0105\u017ce\u0144 systemu politycznego do \ninstrumentalnego wykorzystania medi\u00f3w. Media w\u00a0tym systemie nie s\u0105 autonomiczne.\nZ\u00a0przedstawionego przegl\u0105du sposob\u00f3w rozumienia mediatyzacji i\u00a0mediatyzacji \npolityki wyp\u0142ywaj\u0105 wa\u017cne dla dalszych rozwa\u017ca\u0144 wnioski metodologiczne. Ot\u00f3\u017c fake \nnewsy wytwarzane przez polityk\u00f3w lub inne podmioty, odnosz\u0105ce si\u0119 do polityki \ni\u00a0polityk\u00f3w, nale\u017cy traktowa\u0107 w\u00a0kategoriach dzia\u0142a\u0144 politycznych, kt\u00f3re wp\u0142ywaj\u0105 na rzeczywisto\u015b\u0107 spo\u0142eczno-polityczn\u0105 poprzez media. Oddzia\u0142uj\u0105 one zatem na system polityczny, jego wizerunek, wizerunek polityk\u00f3w i\u00a0podejmowane przez nich dalsze \ndzia\u0142ania, finalnie za\u015b wywo\u0142uj\u0105 skutki o\u00a0charakterze politycznym. Spos\u00f3b ich u\u017cycia \npozwala stwierdzi\u0107, jakie relacje pomi\u0119dzy mediami a\u00a0polityk\u0105 (politykami) kszta\u0142tuj\u0105 \nfake newsy, jaka jest ich polityczna sprawczo\u015b\u0107 i\u00a0w\u00a0jakim stopniu wp\u0142ywaj\u0105 one na \nkszta\u0142towanie okre\u015blonej kultury przekazu i\u00a0kultury politycznej.\nFake news. Kr\u00f3tka historia i definicje\nProblem fejk\u00f3w (fake news\u00f3w) nale\u017cy do og\u00f3lniejszej kategorii oszustwa (journali -\nstic deception ), cho\u0107 nie tylko dziennikarskiego. Deni Elliot i\u00a0Charles Culver (1992, s. \n69\u201374) zdefiniowali oszustwo dziennikarskie jako \u201eakt przekazywania wiadomo\u015bci nie \ntylko przez k\u0142amstwo, ale tak\u017ce przez ukrywanie informacji, aby doprowadzi\u0107 kogo\u015b \ndo fa\u0142szywego przekonania\u201d1. Z\u00a0kolei Wikipedia definiuje fake news jako \u201ewiadomo\u015b\u0107 \npublikowan\u0105 z\u00a0zamiarem wprowadzenia odbiorcy w\u00a0b\u0142\u0105d w\u00a0celu osi\u0105gni\u0119cia korzy\u015bci finansowych i\u00a0politycznych, cz\u0119sto z\u00a0sensacyjnymi, przesadnymi czy fa\u0142szywymi na\n-\ng\u0142\u00f3wkami, kt\u00f3re maj\u0105 przyci\u0105gn\u0105\u0107 uwag\u0119\u201d2. W\u00a0dniu 18 czerwca 2018 r. wyszukiwarka \ninternetowa Google przynios\u0142a oko\u0142o 742 mln wynik\u00f3w z\u00a0fraz\u0105 \u201efake news\u201d .\n1  \u201e(\u2026) an act of communicating messages not only by lying by also by withholding information, \nas to lead someone to have a\u00a0false belief \u201d (t\u0142umaczenie w\u0142asne).\n2  \u201eFake news is written and published with the intent to mislead in order to gain financially \nor politically, often with sensationalist, exaggerated, or patently false headlines that grab attention\u201d (t\u0142umaczenie w\u0142asne).Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 140\nFake newsy istniej\u0105 od pocz\u0105tku dziennikarstwa. Ju\u017c w\u00a0pierwszej gazecie rzymskie -\ngo imperium \u201eActa Diurna\u201d , wydawanej w\u00a0czasach panowania Juliusza Cezara i\u00a0jego \nnast\u0119pc\u00f3w, pojawi\u0142y si\u0119 sensacyjne wiadomo\u015bci o\u00a0wydarzeniach, kt\u00f3rych zwi\u0105zek z\u00a0rze -\nczywisto\u015bci\u0105 by\u0142 w\u0105tpliwy. Mitchell Stephens w\u00a0ksi\u0105\u017cce A\u00a0History of News przywo\u0142u -\nje opowie\u015b\u0107 o\u00a0mitycznym ptaku \u2013 feniksie, kt\u00f3ry jakoby zosta\u0142 wystawiony na pokaz \nw\u00a0Rzymie. Pisze te\u017c o\u00a0pewnym \u017co\u0142nierzu, kt\u00f3ry wr\u00f3ci\u0142 z\u00a0wojny trzydziestoletniej w\u00a0Euro -\npie w\u00a0brzemiennym stanie (Stephens 2007, s. 57, 66). W\u00a0ci\u0105gu ostatnich trzydziestu kilku \nlat ameryka\u0144scy dziennikarze (Janet Cooke, Stephen Glass czy Jayson Blair) wymy\u015blali \nwydarzenia i\u00a0opisywali nieprawdziwe historie. Wiele kontrowersji wzbudza\u0142y informacje \ndotycz\u0105ce broni masowej zag\u0142ady, rzekomo znajduj\u0105cej si\u0119 w\u00a0r\u0119kach irackiego dyktatora \nHusajna. W\u00a02016 r. w\u00a0zwi\u0105zku z\u00a0wyborami prezydenckimi w\u00a0USA pojawi\u0142o si\u0119 mn\u00f3stwo \nfake news\u00f3w o\u00a0g\u0142\u00f3wnych kandydatach do urz\u0119du. H. Clinton zosta\u0142a oskar\u017cona m.in. \no\u00a0sprzeda\u017c broni terrorystom z\u00a0ISIS. Ludzie cz\u0119\u015bciej czytali fake newsy (oko\u0142o 8,7 mln) \nni\u017c prawdziwe informacje (7,3 mln) (Levinson 2016\u20132017), a\u00a0news dezinformuj\u0105cy, \n\u017ce papie\u017c Franciszek popar\u0142 kandydatur\u0119 Donalda Trumpa, zosta\u0142 przeczytany przez oko\u0142o milion ludzi (zob. Evon 2016). W\u00a0Polsce te\u017c wielokrotnie pojawia\u0142y si\u0119 fa\u0142szywe informacje, m.in. o\u00a0\u015bmierci znanych os\u00f3b (np. gen. Wojciecha Jaruzelskiego czy aktora \nAndrzeja Grabowskiego) lub takie, kt\u00f3rych celem by\u0142a kompromitacja przeciwnika \npolitycznego (np. informacja o\u00a0dziadku Donalda Tuska w\u00a0Wehrmachcie).\nPrzyk\u0142ady politycznych fake news\u00f3w\nDo fake news\u00f3w w\u00a0dziedzinie polityki, a\u00a0wi\u0119c takich, kt\u00f3re mia\u0142y polityczn\u0105 ge -\nnez\u0119 lub charakteryzowa\u0142y si\u0119 politycznym sprawstwem, mo\u017cna z\u00a0pewno\u015bci\u0105 zaliczy\u0107 \nwiele mniej lub bardziej znanych dezinformacji, uchodz\u0105cych pierwotnie za prawdzi -\nwe3. W\u00a0rozmaitych zestawieniach fake news\u00f3w najwa\u017cniejsze spo\u015br\u00f3d nich dotycz\u0105 \nzdarze\u0144 z\u00a0obszaru tzw. wielkiej polityki. S\u0105 to np. fa\u0142szywe wiadomo\u015bci \u015bwiadomie i\u00a0celowo rozpowszechniane przez s\u0142u\u017cby specjalne, agencje rz\u0105dowe czy nawet rz\u0105dy \nkonkretnych kraj\u00f3w, kt\u00f3re mia\u0142y wp\u0142ywa\u0107 na zmian\u0119 postaw (lub ich ugruntowanie, \nje\u015bli by\u0142y przychylne nadawcom komunikat\u00f3w) opinii publicznej i\u00a0wywo\u0142a\u0107 przychyl -\nne reakcje na podj\u0119te przez polityk\u00f3w dzia\u0142ania, s\u0142u\u017c\u0105ce niekiedy jako pretekst do \nprzeprowadzenia powa\u017cnych zmian na arenie mi\u0119dzynarodowej, a\u00a0niekiedy zamie -\nniaj\u0105ce napi\u0119cie i\u00a0s\u0142own\u0105 agresj\u0119 w\u00a0wojn\u0119.\nPolitycy nieraz usprawiedliwiali g\u0142oszone przez siebie k\u0142amstwa, np. prezydent Ri -\nchard Nixon 8 lat po skandalu zwi\u0105zanym z\u00a0w\u0142amaniem do kompleksu Watergate, pr\u00f3 -\nbach tuszowania \u015bledztwa i\u00a0rezygnacji z\u00a0urz\u0119du zaprzeczy\u0142, \u017ce k\u0142ama\u0142 w\u00a0sprawie swojego \n3  Unia Europejska opracowa\u0142a w\u00a02018 r. definicj\u0119 dezinformacji, wed\u0142ug kt\u00f3rej jest to \u201efa\u0142szywa, \nniedok\u0142adna lub wprowadzaj\u0105ca w\u00a0b\u0142\u0105d informacja, stworzona, zaprezentowana i\u00a0rozpowszechniana \ndla zysku lub rozmy\u015blnego spowodowania szkody publicznej\u201d (Mandes 2018).Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\n141 Fake news w polityce. Studia przypadk\u00f3w\nudzia\u0142u w\u00a0aferze, ale przyzna\u0142 w\u00a0rozmowie dla \u201eSan Francisco Chronicle\u201d (28 pa\u017adzier -\nnika 1982 r.), \u017ce tak jak inni politycy musia\u0142 udawa\u0107 (Ekman 2006, s. 26). W\u00a0\u015bwietle \npublikacji Boba Woodwarda z\u00a02005 r. (Secret Man), kt\u00f3ry ujawni\u0142 zapis rozm\u00f3w z\u00a0ta\u015bmy \nw\u00a0Gabinecie Owalnym prezydenta z\u00a0tamtego okresu, nale\u017cy stwierdzi\u0107, \u017ce Nixon k\u0142ama\u0142 \nzar\u00f3wno w\u00a0latach 1972\u20131974, jak i\u00a0wtedy, gdy udziela\u0142 wywiadu wspomnianej gazecie. \nJody Powell, sekretarz prasowy prezydenta Jimmy\u2019 ego Cartera, powiedzia\u0142 wprost, \u017ce \nrz\u0105d ma prawo k\u0142ama\u0107 i\u00a0doda\u0142: \u201e W\u00a0pewnych okoliczno\u015bciach rz\u0105d ma nie tylko prawo, \nale i\u00a0obowi\u0105zek k\u0142ama\u0107\u201d , np. w\u00a0sprawie wojskowego planu uwolnienia zak\u0142adnik\u00f3w \nameryka\u0144skich w\u00a0Iranie (Mearsheimer 2012, s. 66). Przy takiej postawie nie dziwi\u0105 \nk\u0142amstwa, kt\u00f3re doprowadzi\u0142y do wywo\u0142ania wojny ameryka\u0144sko-hiszpa\u0144skiej w\u00a01898 \nr., wojny wietnamskiej w\u00a01964 r. czy wojny z\u00a0Irakiem w\u00a02003 r. Kiedy Daniel Ellsberg doprowadzi\u0142 do ujawnienia w\u00a0czerwcu 1970 r. na \u0142amach \u201eNew Y ork Timesa\u201d tajnego \nraportu o\u00a0ameryka\u0144skim zaanga\u017cowaniu w\u00a0Indochinach w\u00a0ostatnich trzech dekadach, \nkomentatorzy pisali, \u017ce administracja Bia\u0142ego Domu ok\u0142amywa\u0142a przez 30 lat media \ni\u00a0spo\u0142ecze\u0144stwa. W\u00a0tym kontek\u015bcie nale\u017ca\u0142oby przypomnie\u0107 ma\u0142o znan\u0105 (przynajmniej \nw\u00a0Polsce) definicj\u0119 newsa podan\u0105 przez ameryka\u0144skiego socjologa i\u00a0propagandyst\u0119 \nrz\u0105dowego Waltera Lippmanna: \u201eNews i\u00a0prawda nie s\u0105 tym samym (\u2026). Funkcj\u0105 newsa \njest sygnalizowanie wydarzenia, funkcj\u0105 prawdy jest wydobycie na \u015bwiat\u0142o ukrytych \nfakt\u00f3w, po\u0142\u0105czenie je w\u00a0relacje ze sob\u0105 i\u00a0stworzenie obrazu rzeczywisto\u015bci, w\u00a0kt\u00f3rej \ncz\u0142owiek mo\u017ce dzia\u0142a\u0107\u201d (Lippmann 1922, s. 215). Ta definicja pokazuje, \u017ce pomi\u0119dzy \nprawd\u0105 a\u00a0newsem znajduje si\u0119 przestrze\u0144, kt\u00f3ra mo\u017ce by\u0107 wype\u0142niona przez byty po -\n\u015brednie, nieto\u017csame z\u00a0prawd\u0105, ale te\u017c nieb\u0119d\u0105ce k\u0142amstwem. Takim niejasnym bytem, cho\u0107 w\u00a0zasadzie fake newsem, by\u0142a np. informacja o\u00a0incydencie w\u00a0Zatoce Tonki\u0144skiej, a\u00a0tak\u017ce pierwsze relacje ukrywaj\u0105ce, co si\u0119 naprawd\u0119 sta\u0142o w\u00a0wiosce My Lai, czy pro\n-\npagandowe informacje o\u00a0broni masowej zag\u0142ady posiadanej przez irackiego dyktatora. Do kategorii fake news\u00f3w nale\u017cy zaliczy\u0107 r\u00f3wnie\u017c wyre\u017cyserowane i\u00a0zainscenizowane rzekome zab\u00f3jstwo rosyjskiego dziennikarza Arkadija Babczenki w\u00a0Kijowie. Stanowi\n-\nsko Lippmanna jest interesuj\u0105ce dla naszych rozwa\u017ca\u0144, poniewa\u017c twierdzi\u0142, \u017ce \u015brodki masowego przekazu maluj\u0105 w\u00a0naszych g\u0142owach obrazy \u015bwiata, kt\u00f3re wp\u0142ywaj\u0105 na nasze my\u015bli i\u00a0zachowania, a\u00a0przecie\u017c mog\u0105 one by\u0107 oparte na fikcjach. Z\u00a0ksi\u0105\u017cki Wiek pro\n-\npagandy  Anthony\u2019 ego Pratkinsa i\u00a0Elliota Aronsona pochodzi przyk\u0142ad dezinformacji \nwytworzonej w\u00a0okresie poprzedzaj\u0105cym wybuch pierwszej wojny w\u00a0Zatoce Perskiej. \nW\u00a0dniu 15 pa\u017adziernika 1990 r. prezydent George Bush o\u015bwiadczy\u0142, \u017ce codziennie \nprzybywa informacji o\u00a0okrucie\u0144stwach, kt\u00f3rych dopuszczaj\u0105 si\u0119 wojska Husajna, m.in. \npolegaj\u0105ce na wyrzucaniu noworodk\u00f3w z\u00a0inkubator\u00f3w (Pratkins, Aronson 2003, s. \n82). Te doniesienia nie zosta\u0142y p\u00f3\u017aniej potwierdzone przez niezale\u017cne \u017ar\u00f3d\u0142a, a\u00a0by\u0142y \nwy\u0142\u0105cznie pog\u0142oskami pochodz\u0105cymi ze \u017ar\u00f3de\u0142 prokuwejckich.\nFake news jako element propagandy by\u0142 i\u00a0pozosta\u0142 do dzi\u015b bardzo u\u017cytecznym \nnarz\u0119dziem wojny informacyjnej. Przyk\u0142ad\u00f3w jego zastosowania w\u00a0codziennej prak -\ntyce propagandy medialnej wci\u0105\u017c przybywa, czego najlepszym dowodem jest ostatnio \nsprawa Babczenki.Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 142\nPrzyk\u0142ady fake news\u00f3w \u2013 studia przypadk\u00f3w\nCzas na zbadanie konkretnych przyk\u0142ad\u00f3w politycznych fake news\u00f3w. W\u00a0niniej -\nszej analizie wyodr\u0119bniam trzy modele u\u017cycia fake news\u00f3w w\u00a0dziedzinie polityki. Po \npierwsze, fake newsy przygotowane przez rz\u0105dy, s\u0142u\u017cby specjalne i\u00a0kontrwywiady \npa\u0144stw w\u00a0celu zaognienia sytuacji mi\u0119dzynarodowej oraz \u2013 w\u00a0ostateczno\u015bci \u2013 s\u0142u\u017c\u0105ce \njako pretekst do rozpocz\u0119cia dzia\u0142a\u0144 wojennych (np. incydent w\u00a0Zatoce Tonki\u0144 -\nskiej, oskar\u017cenia Husajna o\u00a0posiadanie WMD \u2013 broni masowego ra\u017cenia). Po drugie, \nfake newsy stosowane jako \u201ebro\u0144\u201d s\u0142u\u017c\u0105ca do wyeliminowania z\u00a0walki politycznej \nkonkurent\u00f3w (np. fake newsy odnosz\u0105ce si\u0119 do George\u2019a\u00a0W . Busha, Hillary Clinton, \nEdmunda Muskiego i\u00a0innych). I\u00a0po trzecie, newsy niezwi\u0105zane bezpo\u015brednio z\u00a0po -\nlityk\u0105, ale maj\u0105ce znacz\u0105cy wp\u0142yw na relacje w\u00a0stosunkach mi\u0119dzynarodowych (np. pseudoinformacje o\u00a0poparciu papie\u017ca Franciszka dla kandydatury Trumpa czy fake \nnews o\u00a0rzekomym zab\u00f3jstwie rosyjskiego dziennikarza Babczenki, kt\u00f3ry z\u00a0pewno\u015bci\u0105 \nodnosi\u0142 si\u0119 w\u00a0szerszym kontek\u015bcie do napi\u0119tych stosunk\u00f3w politycznych pomi\u0119dzy \nUkrain\u0105 a\u00a0Rosj\u0105). G\u0142ebszej analizie zostan\u0105 poddane trzy wybrane fake newsy do -\ntycz\u0105ce:\n1. Broni masowego ra\u017cenia w\u00a0Iraku (WMD).2. Sprzeda\u017cy broni terrorystom z\u00a0ISIS.\n3. \u201e\u015amierci\u201d Babczenki.\nAd. 1. Analiza przypadku o\u00a0 WMD. W\u00a0dniu 20 marca 2003 r. Stany Zjed -\nnoczone rozpocz\u0119\u0142y operacj\u0119 militarn\u0105 \u201eIraqi freedom\u201d . Po oko\u0142o 3 tygodniach si\u0142y \nmi\u0119dzynarodowej koalicji (na czele z\u00a0USA i\u00a0Wielk\u0105 Brytani\u0105) zaj\u0119\u0142y wi\u0119ksz\u0105 cz\u0119\u015b\u0107 \nIraku. Pretekstem do wojny by\u0142o oskar\u017cenie dyktatora Iraku Husajna o\u00a0posiadanie \nbroni masowego ra\u017cenia (a\u00a0weapon of mass destruction  \u2013 WMD) i\u00a0sprzyjanie Al-Ka -\nidzie oraz o\u00a0wsp\u00f3\u0142prac\u0119 z\u00a0ni\u0105 w\u00a0ataku na Ameryk\u0119 dokonanym 11 wrze\u015bnia 2001 r. Do najazdu na Irak dosz\u0142o 12 lat po zako\u0144czeniu pierwszej wojny w\u00a0Zatoce Perskiej, \npo kt\u00f3rej Husajn pozosta\u0142 przy w\u0142adzy. W\u00a01998 r. Kongres ameryka\u0144ski przeg\u0142osowa\u0142 \nustaw\u0119 Iraq Liberation Act, w\u00a0kt\u00f3rej zalegalizowano finansowe i\u00a0polityczne wspieranie \nopozycji irackiej, skupionej w\u00a0organizacji o\u00a0nazwie Narodowy Kongres Iraku, kt\u00f3ra \nd\u0105\u017cy\u0142a do obalenia Husajna. Po ataku z\u00a011 wrze\u015bnia w\u00a0USA zosta\u0142a wprowadzona \nzasada ataku prewencyjnego na kraj pos\u0105dzany o\u00a0terroryzm. W\u015br\u00f3d ewentualnych cel\u00f3w wymieniono rz\u0105d Husajna. W\u00a02002 r. Bush uzyska\u0142 od Senatu i\u00a0Izby Repre\n-\nzentant\u00f3w prawo do u\u017cycia si\u0142y przeciwko Irakowi. Rada Bezpiecze\u0144stwa nakaza\u0142a Irakowi pozbycie si\u0119 WMD i\u00a0przedstawienie dowod\u00f3w, \u017ce tak si\u0119 sta\u0142o. Pod koniec \n2002 r. Amerykanie jako g\u0142\u00f3wne powody ewentualnego ataku na Irak podawali gro\u017ab\u0119 \nu\u017cycia broni masowego ra\u017cenia przez irackiego dyktatora, powi\u0105zania rz\u0105du Husajna \nz\u00a0mi\u0119dzynarodowym terroryzmem oraz wielokrotne naruszenia praw cz\u0142owieka. Co najmniej od wrze\u015bnia 2002 r. trwa\u0142a akcja medialna przygotowuj\u0105ca spo\u0142ecze\u0144stwo \nameryka\u0144skie do wojny. Husajn by\u0142 nazywany wsp\u00f3\u0142czesnym Hitlerem, oskar\u017cano go \no\u00a0zbrodnie ludob\u00f3jstwa na Kurdach i\u00a0zagazowanie kobiet i\u00a0dzieci (1988 r. \u2013 operacja Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\n143 Fake news w polityce. Studia przypadk\u00f3w\nAnfal). Gazety w\u00a0USA codziennie przynosi\u0142y kolejne informacje o\u00a0zbrodniach Hu -\nsajna i\u00a0nawo\u0142ywa\u0142y ustami polityk\u00f3w do rozprawy z\u00a0nim. Kiedy teren Iraku opu\u015bcili \ninspektorzy ONZ, Amerykanie wezwali dyktatora do rezygnacji z\u00a0w\u0142adzy i\u00a0wyjazdu \nz\u00a0kraju, stawiaj\u0105c mu 48-godzinne ultimatum, a\u00a0gdy ten odm\u00f3wi\u0142, rozpocz\u0119li inwazj\u0119. \n\u00d3wczesny sekretarz obrony USA, Donald Rumsfeld, za najwa\u017cniejsze cele ataku uzna\u0142: \nznalezienie i\u00a0eliminacj\u0119 broni masowego ra\u017cenia oraz baz terroryst\u00f3w; zdobycie infor -\nmacji na temat powi\u0105za\u0144 mi\u0119dzynarodowych organizacji terrorystycznych; zako\u0144cze -\nnie sankcji ekonomicznych na\u0142o\u017conych na Irak i\u00a0dostarczenie do tego kraju pomocy humanitarnej (operacja \u201ewyzwolenie Iraku\u201d). Do dalszych cel\u00f3w zaliczono usuni\u0119cie rz\u0105du nieprzychylnego Izraelowi i\u00a0wprowadzenie demokracji w\u00a0Iraku. Celem bardzo wa\u017cnym, aczkolwiek nie tak mocno deklarowanym, jak te wy\u017cej wymienione, by\u0142o \nobjecie kontroli nad irackimi polami naftowymi i\u00a0zapewnienie dop\u0142ywu \u015brodk\u00f3w \nfinansowych do ameryka\u0144skiego sektora militarno-zbrojeniowego.\nTakie by\u0142o t\u0142o i\u00a0kontekst wydarze\u0144. Ameryka\u0144skie media powtarza\u0142y argumenty \nBia\u0142ego Domu, ros\u0142o poparcie spo\u0142eczne dla akcji zbrojnej, panowa\u0142o powszechne \nprzekonanie o\u00a0istnieniu WMD na terytorium Iraku, aczkolwiek jeszcze 6 wrze\u015bnia \n2002 r. gen. Tommy Frank, dow\u00f3dca United States Central Commands, m\u00f3wi\u0142 Busho -\nwi, \u017ce na terenie Iraku nie znaleziono \u017cadnej broni tego typu, a\u00a0komisja ds. zamach\u00f3w \n11 wrze\u015bnia nie stwierdzi\u0142a powi\u0105za\u0144 mi\u0119dzy Osam\u0105 bin Ladenem a\u00a0Husajnem. Mimo \nto wiceprezydent Dick Cheney i\u00a0sekretarz stanu Colin Powell wci\u0105\u017c powtarzali, \u017ce Hu -\nsajn ma WMD (Mearsheimer 2012, s. 93). Po rozpocz\u0119ciu wojny prasa, radio i\u00a0telewi -\nzja nadawa\u0142y bezpo\u015brednie relacje dziennikarzy z\u00a0woz\u00f3w bojowych jad\u0105cych w\u00a0stron\u0119 \nBagdadu (tzw. embedded journalism ). Ameryka\u0144scy dziennikarze uwierzyli w\u00a0histori\u0119 \no\u00a0WMD; telewizje pokazywa\u0142y podziemne tunele, kt\u00f3rymi rzekomo transportowano bro\u0144, a\u00a0znany reporter i\u00a0anchorman stacji CBS Dan Rather, tu\u017c przed rozpocz\u0119ciem wojny, pyta\u0142 Husajna w\u00a0wywiadzie telewizyjnym: \u201eMr . Hussein, czy Pan zniszczy te \npociski?\u201d , na co dyktator odpowiedzia\u0142: \u201eJakie pociski, nie mam tych pocisk\u00f3w\u201d (Dan \nRather interview\u2026 2003). W\u00a0poszukiwanie tej broni zaanga\u017cowa\u0142o si\u0119 r\u00f3wnie\u017c polskie \nwojsko i\u00a0mia\u0142o sw\u00f3j epizod, poniewa\u017c minister Jerzy Szmajdzi\u0144ski ujawni\u0142 w\u00a0dniu, \nw\u00a0kt\u00f3rym obalony Husajn stan\u0105\u0142 przed irackim trybuna\u0142em specjalnym, \u017ce Polacy zna -\nle\u017ali kilkana\u015bcie pocisk\u00f3w broni chemicznej. Wcze\u015bniej poinformowa\u0142 o\u00a0tym Rumsfeld \n(Polacy znale\u017ali w\u00a0Iraku bro\u0144\u2026 2004). Jednak w\u00a0Iraku nie znaleziono w\u00f3wczas broni masowego ra\u017cenia, kt\u00f3rej rzekoma obecno\u015b\u0107 mia\u0142a by\u0107 jednym z\u00a0powod\u00f3w wojny. Wed\u0142ug raportu Charlesa A. Duelfera (dla CIA) z\u00a0wrze\u015bnia 2004 r. \u201eSaddam Hussein \nnie posiada\u0142 zapas\u00f3w nielegalnej broni w\u00a0czasie inwazji USA w\u00a0marcu 2003 r. i\u00a0nie \nrozpocz\u0105\u0142 \u017cadnego programu ich produkcji\u201d (Report: No WMD stockpiles\u2026 2004).\nWed\u0142ug Johna Mearsheimera Administracja Busha pos\u0142u\u017cy\u0142a si\u0119 czterema k\u0142am\n-\nstwami: wskaza\u0142a, \u017ce Irak ma bro\u0144 masowego ra\u017cenia; twierdzi\u0142a, \u017ce posiada niezbite dowody, i\u017c Husajn jest powi\u0105zany z\u00a0bin Ladenem; sugerowa\u0142a, \u017ce dyktator jest odpo\n-\nwiedzialny za ataki z\u00a011 wrze\u015bnia; utrzymywa\u0142a do ko\u0144ca, \u017ce Bia\u0142y Dom jest got\u00f3w na \npokojowe rozwi\u0105zanie sporu, podczas gdy decyzja o\u00a0wojnie ju\u017c zapad\u0142a (Mearsheimer Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 144\n2012, s. 18\u201319). Media ameryka\u0144skie zosta\u0142y wykorzystane w\u00a0tej grze Busha z\u00a0Husaj -\nnem. Powtarza\u0142y argumenty Administracji, nawet nie pr\u00f3buj\u0105c ich weryfikowa\u0107. Za -\nbrak\u0142o reakcji sceptycznych i\u00a0poszukiwa\u0144 odpowiedzi na wa\u017cne pytania o\u00a0zasadno\u015b\u0107 \nrozpocz\u0119cia wojny z\u00a0Irakiem. Dziennikarze przyj\u0119li postaw\u0119 aprobatywn\u0105, koopera -\ntywn\u0105 i\u00a0patriotyczn\u0105; na wozach bojowych wjechali do Bagdadu, \u201ewyzwalaj\u0105c\u201d Irak.\nOpisany fake news w\u00a0\u015bwietle paradygmat\u00f3w przedstawionych przez Oniszczuka \npokazuje instrumentalne wykorzystanie medi\u00f3w przez si\u0142y polityczne, jednocze\u015bnie mistyfikuj\u0105c te wp\u0142ywy i\u00a0sugeruj\u0105c symbioz\u0119 pomi\u0119dzy \u015bwiatem polityki a\u00a0\u015bwiatem dziennikarzy i\u00a0medi\u00f3w. Przyczyna powstania tego fake newsa mia\u0142a charakter poli\n-\ntyczny, a\u00a0sam \u201enews\u201d zosta\u0142 opakowany w\u00a0ramy konfliktu i\u00a0odpowiedzialno\u015bci, przy czym wskazywa\u0142, \u017ce osob\u0105 odpowiedzialn\u0105 za konflikt i\u00a0wybuch wojny by\u0142 Husajn. \nTaka interpretacja odpowiada\u0142a skryptom poznawczym ameryka\u0144skiego odbiorcy, \nprzekonanego o\u00a0z\u0142ej woli Husajna i\u00a0o\u00a0jego zbrodniczej polityce, kszta\u0142towanym przez \nameryka\u0144skie media we wsp\u00f3\u0142pracy z\u00a0Administracj\u0105 Bia\u0142ego Domu. \u0179r\u00f3d\u0142em \u201enewsa\u201d \nby\u0142a Administracja waszyngto\u0144ska. Fake news o\u00a0posiadaniu przez Husajna niebez -\npiecznej dla \u015bwiata broni masowego ra\u017cenia spe\u0142ni\u0142 sw\u0105 funkcj\u0119 \u2013 sta\u0142 si\u0119 pretekstem do rozpocz\u0119cia wojny z\u00a0Irakiem. Jego szybk\u0105 konsekwencj\u0105 by\u0142o obalenia irackiego \ndyktatora, a\u00a0skutkiem d\u0142u\u017cej trwaj\u0105cym \u2013 destabilizacja sytuacji politycznej i\u00a0mili\n-\ntarnej w\u00a0tym rejonie \u015bwiata.\nAd. 2. Analiza przypadku \u201eHillary Clinton sprzedawa\u0142a bro\u0144 terrory -\nstom\u201d. H. Clinton, sekretarz stanu USA w\u00a0latach 2009\u20132013, by\u0142a kandydatk\u0105 Partii \nDemokratycznej w\u00a0wyborach prezydenckich. W\u00a0tym okresie sta\u0142a si\u0119 przedmiotem \nwielu fake news\u00f3w, z\u00a0kt\u00f3rych najg\u0142o\u015bniejsze dotyczy\u0142y rzekomej sprzeda\u017cy broni \ndla ISIS (Lacapria 2016; Ritchie 2016), wezwania lider\u00f3w ISIS do g\u0142osowania na H. Clinton oraz afery zwanej Pizzagate, w\u00a0kt\u00f3r\u0105 by\u0142 zamieszany by\u0142y szef jej kampanii wyborczej John Podesta.\nPrzedmiotem analizy b\u0119dzie fake news o\u00a0sprzeda\u017cy broni dla ISIS. W\u00a0klasyfikacji \nbussinessinsider.com zaj\u0105\u0142 on pi\u0105te miejsce na li\u015bcie najwi\u0119kszych fake news\u00f3w w\u00a0cza -\nsie kampanii prezydenckiej w\u00a0USA (Roberts 2016). Mia\u0142 przynajmniej 789 tys. wej\u015b\u0107 na Facebooku, a\u00a0pierwotnie zosta\u0142 opublikowany na prawicowym portalu thepoliti\n-\ncalinsider.com (dla por\u00f3wnania \u201enews\u201d o\u00a0poparciu papie\u017ca Franciszka dla Trumpa mia\u0142 ponad 961 tys. ods\u0142on). Wpis zosta\u0142 usuni\u0119ty ze strony portalu i\u00a0dzi\u015b nie jest na \nniej dost\u0119pny.\nOmawiany fake news WikiLeaks Confirms Hillary Sold Weapons to ISIS zosta\u0142 opu\n-\nblikowany 4 sierpnia przez The Political Insider po tym, jak za\u0142o\u017cyciel WikiLeaks, Julian \nAssange, w\u00a0trakcie wywiadu udzielonego 25 lipca 2016 r. dla democracynow.org \u2013 nie -\nzale\u017cnego portalu informacyjnego za\u0142o\u017conego przez dwoje dziennikarzy \u015bledczych: \nAmy Goodman i\u00a0Juana Gonzalesa \u2013 wyg\u0142osi\u0142 komentarz na temat H. Clinton (Assange: \nWhy I\u00a0Created WikiLeaks\u2019 Searchable\u2026 2016; Y ouTube, 2016). Rzekomo Assange mia\u0142 \npowiedzie\u0107, \u017ce \u201eHillary Clinton i\u00a0jej departament stanu aktywnie zbroili islamskich Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\n145 Fake news w polityce. Studia przypadk\u00f3w\nd\u017cihadyst\u00f3w, w\u00a0tym ISIS (\u2026)\u201d . Komentarz w\u00a0tej formie \u2013 bez sprawdzenia, co naprawd\u0119 \npowiedzia\u0142 Assange \u2013 zosta\u0142 powielony przez wiele portali internetowych.\nInformacja o\u00a0sprzeda\u017cy broni dla ISIS zosta\u0142a poddana weryfikacji przez wyspe -\ncjalizowane w\u00a0fact-checkingu redakcje cnbc.com i\u00a0snopes.com. Wed\u0142ug pierwszej \nz\u00a0nich Assange naprawd\u0119 powiedzia\u0142, \u017ce Departament Stanu pod kierownictwem \nClinton zatwierdzi\u0142 dostawy broni do Libii podczas interwencji w\u00a02011 r. i\u00a0\u017ce p\u00f3\u017aniej \nta bro\u0144 trafi\u0142a w\u00a0r\u0119ce d\u017cihadyst\u00f3w (Ritchie 2016). Po zbadaniu e-maili opublikowa -\nnych przez WikiLeaks portal snopes.com stwierdzi\u0142, \u017ce \u201e\u017badne e-maile WikiLeaks nie \npotwierdzaj\u0105, \u017ce Hillary Clinton bezpo\u015brednio i\u00a0\u015bwiadomie sprzedawa\u0142a bro\u0144 ISIS\u201d . \nArtyku\u0142 w\u00a0politicalinsider.com zdaniem snopes.com nie m\u00f3wi\u0142 wprost, \u017ce Clinton \nsprzedawa\u0142a bro\u0144 ISIS, lecz przekazywa\u0142 opini\u0119 Assange\u2019a, \u017ce \u201eHillary Clinton i\u00a0jej \nDepartament Stanu aktywnie zbroili islamskich d\u017cihadyst\u00f3w\u201d (Lacapria 2016). By\u0107 \nmo\u017ce \u2013 jak zauwa\u017ca snopes.com \u2013 \u201ejej niedba\u0142a postawa w\u00a0kszta\u0142towaniu dzia\u0142a\u0144 \nStan\u00f3w Zjednoczonych w\u00a0zwi\u0105zku z\u00a0interwencj\u0105 libijsk\u0105 i\u00a0trwaj\u0105c\u0105 syryjsk\u0105 wojn\u0105 \ndomow\u0105 pozwoli\u0142a, by bro\u0144 wpad\u0142a w\u00a0r\u0119ce \u00bbd\u017cihadyst\u00f3w\u00ab, ale to nie jest to samo, co \u00bbsprzeda\u017c broni ISIS\u00ab\u201d .\nJak ju\u017c wcze\u015bniej wspomniano, Clinton w\u00a0trakcie kampanii prezydenckiej spotka\u0142a \nsi\u0119 z\u00a0silnym atakiem przeciwnik\u00f3w politycznych wykorzystuj\u0105cych przeciwko niej \nfake newsy. Wiele z\u00a0nich \u201ewyprodukowali\u201d m\u0142odzi ludzie z\u00a0macedo\u0144skiego miastecz -\nka We\u0142es. Nale\u017ca\u0142oby zbada\u0107, jaka dok\u0142adnie by\u0142a rola tej grupy internaut\u00f3w, kt\u00f3rzy stworzyli ponad 100 stron oferuj\u0105cych zmistyfikowane tre\u015bci ([adso] 2016). W\u00a0roz\n-\nmowie z\u00a0portalem BuzzFeed jeden ze student\u00f3w t\u0142umaczy\u0142: \u201eTak, te informacje s\u0105 \nfa\u0142szywe, z\u0142e, wprowadzaj\u0105 w\u00a0b\u0142\u0105d, ale racjonalne ich uzasadnienie jest takie, \u017ce skoro \nludzie chc\u0105 w\u00a0to klikn\u0105\u0107 i\u00a0si\u0119 w\u00a0t\u0119 tre\u015b\u0107 zaanga\u017cowa\u0107, to wykorzystajmy to\u201d ([adso] \n2016). Fake newsy skierowane przeciwko Clinton nale\u017cy jednak postrzega\u0107 w\u00a0szerszej \nperspektywie, a\u00a0w\u0142a\u015bciwym kontekstem by\u0142a kampania prezydencka w\u00a0USA, w\u00a0czasie \nkt\u00f3rej (przynajmniej na pocz\u0105tku) Clinton mia\u0142a sonda\u017cow\u0105 przewag\u0119 nad Trum -\npem. W\u00a0lipcu 2016 r. WikiLeaks  ujawni\u0142a 20 tys. e-maili Komitetu Krajowego Partii Demokratycznej, z\u00a0kt\u00f3rych wynika\u0142o, \u017ce w\u00a0czasie prawybor\u00f3w cz\u0142onkowie komitetu potajemnie wspierali jej kandydatur\u0119. Clinton oskar\u017cy\u0142a rz\u0105d Rosji o\u00a0zaaran\u017cowanie ujawnienia tych e-maili. Jej oskar\u017cenia wspar\u0142 Barack Obama, a\u00a0\u015bledztwo prowadzo\n-\nne przez FBI ujawni\u0142o, \u017ce 13 Rosjan by\u0142o zaanga\u017cowanych w\u00a0agitacj\u0119 i\u00a0ingerencj\u0119 \nw\u00a0ameryka\u0144skie wybory. Rosjanie kupowali polityczne reklamy i\u00a0organizowali wiece, \npodaj\u0105c si\u0119 za ameryka\u0144skich aktywist\u00f3w. Tworzyli te\u017c strony internetowe, fa\u0142szy -\nwe postaci i\u00a0podejmowali akcje w\u00a0mediach spo\u0142eczno\u015bciowych, propaguj\u0105c fa\u0142szywe \nzarzuty pod adresem Demokrat\u00f3w (13 Rosjan oskar\u017conych o\u00a0ingerencj\u0119 w\u00a0wybory \nprezydenckie\u2026  2018).\nOpisany wy\u017cej fake news ma oczywi\u015bcie pod\u0142o\u017ce i\u00a0skutki polityczne, aczkolwiek \njego geneza jest inna ni\u017c fake newsa o\u00a0WMD. Wydaje si\u0119, \u017ce w\u00a0tym przypadku jego \nprodukcja, aktywizacja i\u00a0rozpowszechnianie zale\u017ca\u0142y od wielu czynnik\u00f3w. W\u0142a\u015bciwym \ntw\u00f3rc\u0105 fake newsa by\u0142 portal politicalinsider.com, okre\u015blony przez za\u0142o\u017cony w\u00a02015 r. Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 146\nniezale\u017cny portal fact-checkingu mediabiasfactcheck.com jako ekstremalnie prawico -\nwy, jako \u201epolityczna strona z\u00a0wiadomo\u015bciami i\u00a0opiniami o\u00a0silnym konserwatywnym \nnastawieniu. Relacje tam zamieszczane zawsze faworyzuj\u0105 prawic\u0119 i\u00a0mog\u0105 by\u0107 nie -\nwiarygodne, je\u015bli chodzi o\u00a0fakty, a\u00a0czasami publikacje te s\u0105 prawicowymi teoriami spi -\nskowymi. To \u017ar\u00f3d\u0142o mo\u017ce by\u0107 kwestionowane i\u00a0powinno by\u0107 sprawdzane\u201d (Political\u2026  \n[b.d.]). Spos\u00f3b produkcji analizowanego fake newsa polega\u0142 na \u201eprzekr\u0119ceniu\u201d s\u0142\u00f3w Assange\u2019a. Trudno jednoznacznie okre\u015bli\u0107, czy ten i\u00a0podobne fake newsy przes\u0105dzi\u0142y \no\u00a0zwyci\u0119stwie Trumpa w\u00a0wyborach 2016 r. (przestrzega\u0142 przed takimi jednoznacz\n-\nnymi wnioskami Paul Levinson [2016\u20132017]), jednak\u017ce nale\u017cy zaznaczy\u0107, \u017ce fa\u0142szy -\nwe informacje dotar\u0142y do milion\u00f3w ameryka\u0144skich wyborc\u00f3w. W\u00a0tym konkretnym \nprzypadku fake news by\u0142 przekazywany przede wszystkim przez portale internetowe i\u00a0na Facebooku, dlatego jego szybka weryfikacja zosta\u0142a powstrzymana przez poja\n-\nwiaj\u0105ce si\u0119 r\u00f3\u017cnorodne interpretacje i\u00a0dopiero udzia\u0142 serwis\u00f3w fact-checkingowych pozwoli\u0142 na jego sfalsyfikowanie. Mo\u017cna powiedzie\u0107, \u017ce niejednoznaczno\u015b\u0107 i\u00a0swego rodzaju otwarto\u015b\u0107 na r\u00f3\u017cne interpretacje zwi\u0119kszy\u0142y jego moc oddzia\u0142ywania. Nawet kiedy ju\u017c dowiedziono fa\u0142szywo\u015bci tej informacji, du\u017ca grupa internaut\u00f3w i\u00a0portali \nnadal powtarza\u0142a to k\u0142amstwo, sugeruj\u0105c, \u017ce informacja o\u00a0fa\u0142szywo\u015bci tego \u201enewsa\u201d \njest celowym dzia\u0142aniem stronnik\u00f3w Clinton, co kolei utwierdza\u0142o jej przeciwnik\u00f3w w\u00a0przekonaniu o\u00a0prawdziwo\u015bci owej wiadomo\u015bci. Na tym przyk\u0142adzie mo\u017cna zrozu\n-\nmie\u0107 mechanizm dzia\u0142ania teorii spiskowych: im bardziej s\u0105 obalane, tym bardziej ich zwolennicy s\u0105 przekonani o\u00a0ich s\u0142uszno\u015bci.\nAd. 3. Zainscenizowane zab\u00f3jstwo Arkadija Babczenki. W\u00a0dniu 29 maja \n2018 r. \u015bwiat obieg\u0142a wiadomo\u015b\u0107 o\u00a0zastrzeleniu w\u00a0Kijowie rosyjskiego dziennikarza Babczenki. O\u00a0jego zamordowanie obwiniano osoby rzekomo powi\u0105zane z\u00a0Kremlem. Wiadomo\u015b\u0107 powtarza\u0142y za mediami ukrai\u0144skimi wielkie agencje prasowe, powa\u017cne media i\u00a0portale internetowe. TVN24 poda\u0142 w\u00a0tytule: Us\u0142ysza\u0142a strza\u0142y, wysz\u0142a i\u00a0zo\n-\nbaczy\u0142a m\u0119\u017ca w\u00a0ka\u0142u\u017cy. Nast\u0119pnie portal donosi, \u017ce do Babczenki strzelano z\u00a0broni palnej w\u00a0jego w\u0142asnym mieszkaniu. Dziennikarz zmar\u0142 w\u00a0karetce, w\u00a0drodze do szpi\n-\ntala. W\u00a0materiale cytowani s\u0105 rzecznik policji i\u00a0ukrai\u0144skie media. Portal, opisuj\u0105c \nt\u0142o wydarze\u0144, przypomina inne zab\u00f3jstwa w\u00a0Kijowie, o\u00a0kt\u00f3re oskar\u017cano rosyjskich zleceniodawc\u00f3w ([PTD/tr] 2018). Informacj\u0119 t\u0119 poda\u0142y wszystkie wa\u017cniejsze media, \nw\u00a0tym m.in. BBC, CNN, \u201eNew Y ork Times\u201d i\u00a0\u201eThe Independent\u201d . NYT napisa\u0142, \u017ce \nby\u0142y uczestnik wojny w\u00a0Czeczenii i\u00a0korespondent wojenny uciek\u0142 z\u00a0Rosji, poniewa\u017c ba\u0142 si\u0119 o\u00a0swoje \u017cycie, a\u00a0nast\u0119pnie skomentowa\u0142, \u017ce \u201ejego zab\u00f3jstwo jest najnowszym z\u00a0serii atak\u00f3w, wielu z\u00a0nich \u015bmiertelnych, na jawnych wrog\u00f3w Putina, zar\u00f3wno w\u00a0Ro\n-\nsji, jak i\u00a0poza jej granicami\u201d (Higgins 2018). Wspomniano, \u017ce Babczenko krytykowa\u0142 \nw\u00a0swoich artyku\u0142ach przej\u0119cie Krymu przez Rosj\u0119 i\u00a0kwestionowa\u0142 militarn\u0105 rol\u0119 Rosji \nw\u00a0Syrii. Ministerstwo Spraw Wewn\u0119trznych w\u00a0Kijowie opublikowa\u0142o portret domnie -\nmanego zab\u00f3jcy \u2013 brodatego m\u0119\u017cczyzny w\u00a0wieku 40\u201345 lat. Ukrai\u0144ski prawnik Anton \nGeraszenko powiedzia\u0142, \u017ce \u015bledczy zbadaj\u0105 dzia\u0142ania rosyjskich agencji wywiadow -\nczych, kt\u00f3re pozbywaj\u0105 si\u0119 tych, kt\u00f3rzy pr\u00f3buj\u0105 m\u00f3wi\u0107 prawd\u0119. Z\u00a0kolei w\u00a0Moskwie Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\n147 Fake news w polityce. Studia przypadk\u00f3w\n\u2013 jak pisa\u0142 NYT \u2013 o\u00a0\u015bmier\u0107 dziennikarza urz\u0119dnicy i\u00a0prawnicy obwiniali Ukrain\u0119, \na\u00a0rosyjski komitet \u015bledczy rozpocz\u0105\u0142 w\u0142asne \u015bledztwo (Higgins 2018). Podobn\u0105 relacj\u0119 \nzamie\u015bci\u0142 brytyjski \u201eThe Independent\u201d , aczkolwiek wi\u0119cej miejsca ni\u017c NYT po\u015bwi\u0119ci\u0142 \nna om\u00f3wienie reakcji w\u0142adz Rosji. Wspomniano w\u00a0niej, \u017ce minister spraw zagranicz -\nnych tego kraju, Siergiej \u0141awrow, nazwa\u0142 ukrai\u0144skie oskar\u017cenia cz\u0119\u015bci\u0105 antyrosyjskiej \nkampanii (Carroll 2018). Brytyjska stacja telewizyjna BBC w\u00a0rozbudowanej relacji \nreporterskiej przytoczy\u0142a wypowied\u017a ukrai\u0144skiego premiera Wo\u0142odymyra Hjorsmana, \n\u017ce zab\u00f3jca musi by\u0107 ukarany (Russia\u2019s opposition journalist\u2026  2018). Agencje infor -\nmacyjne podawa\u0142y te\u017c wiadomo\u015b\u0107 o\u00a0tym, \u017ce minister spraw zagranicznych Wielkiej Brytanii, Boris Johnson, z\u0142o\u017cy\u0142 kondolencje \u017conie Babczenki.\nPo 24 godzinach ca\u0142a historia okaza\u0142a si\u0119 nieprawdziwa i\u00a0wymy\u015blona przez ukra\n-\ni\u0144skie s\u0142u\u017cby SBU w\u00a0celu schwytania os\u00f3b, kt\u00f3re chcia\u0142y rzekomo zamordowa\u0107 Bab -\nczenk\u0119. Tajna operacja trwa\u0142a 2 miesi\u0105ce i\u00a0wzi\u0119li w\u00a0niej udzia\u0142 m.in. sam Babczenko i\u00a0jego \u017cona. Podobno nie wiedzia\u0142 o\u00a0niej nawet premier Ukrainy. Zab\u00f3jc\u0105 mia\u0142 by\u0107 \nOleg/Oleksy Cymbaluk, cz\u0142onek nacjonalistycznego batalionu Prawego Sektora, \nuczestnicz\u0105cego w\u00a0walkach w\u00a0Donbasie (Rybczy\u0144ski 2018), niegdy\u015b mnich i\u00a0diakon \nukrai\u0144skiego ko\u015bcio\u0142a prawos\u0142awnego (MacFarquahar 2018). Wed\u0142ug ukrai\u0144skiej pro -\nkuratury zab\u00f3jstwo zleci\u0142 biznesmen ukrai\u0144ski zaopatruj\u0105cy w\u00a0bro\u0144 armi\u0119 ukrai\u0144sk\u0105, \nBorys Herman. Cymbaluk za zabicie dziennikarza mia\u0142 otrzyma\u0107 28 tys. dolar\u00f3w, ale \nzg\u0142osi\u0142 si\u0119 do SBU i\u00a0zosta\u0142 informatorem s\u0142u\u017cby. Wed\u0142ug zezna\u0144 Hermana oferowa\u0142 on \npieni\u0105dze Cymbalukowi za wiedz\u0105 SBU. Herman, kt\u00f3ry wed\u0142ug ukrai\u0144skich urz\u0119dni -\nk\u00f3w mia\u0142 list\u0119 trzydziestu innych os\u00f3b, kt\u00f3re Moskwa chcia\u0142a zabi\u0107 na Ukrainie, opo -\nwiedzia\u0142 o\u00a0obywatelu ukrai\u0144skim Wieczes\u0142awie Piwowarniku, mieszkaj\u0105cym obecnie \nw\u00a0Moskwie, kt\u00f3ry si\u0119 z\u00a0nim skontaktowa\u0142. Piwowarnik, powi\u0105zany z\u00a0prokremlowsk\u0105 \nfundacj\u0105, mia\u0142 przygotowywa\u0107 pucz na Ukrainie i\u00a0werbowa\u0107 ochotnik\u00f3w do zab\u00f3jstw \nna terenie tego kraju (Rybczy\u0144ski 2018).\nOpublikowany przez BBC fake news o\u00a0\u015bmierci Babczenki by\u0142 zgodny z\u00a0klasycznym \nschematem newsa opisanym przez holenderskiego badacza dyskursu newsa Teuna \nA. van Dijka (1983, s. 37). Je\u015bli chodzi o\u00a0autor\u00f3w tego fake newsa, to z\u00a0pewno\u015bci\u0105 \nzosta\u0142 on sfabrykowany przez ukrai\u0144skie s\u0142u\u017cby specjalne. Z\u00a0prowokacj\u0105 SBU by\u0142 \nzaznajomiony prezydent Petro Poroszenko. Media ukrai\u0144skie by\u0142y jedynie pasem \ntransmisyjnym dla informacji wcze\u015bniej przygotowanych i\u00a0przekazanych mediom \nprzez organizator\u00f3w prowokacji. Zosta\u0142y wykorzystane i\u00a0zmanipulowane dla cel\u00f3w \noperacji s\u0142u\u017cb specjalnych. Informacja o\u00a0rzekomej \u015bmierci Babczenki pojawi\u0142a si\u0119 \nw\u00a0szerokim kontek\u015bcie napi\u0119tych stosunk\u00f3w ukrai\u0144sko-rosyjskich, natomiast nieco \nw\u0119\u017cszym kontekstem by\u0142y zab\u00f3jstwa na Ukrainie (dokonane przez nieustalonych \nsprawc\u00f3w) opozycjonist\u00f3w polityki W\u0142adimira Putina. Funkcj\u0105 tego fake newsa by\u0142o potwierdzenie odpowiedzialno\u015bci Rosji za destabilizacj\u0119 polityczn\u0105 i\u00a0militarn\u0105 Ukra\n-\niny, dlatego by\u0142 on prezentowany w\u00a0trzech g\u0142\u00f3wnych wymiarach (ramach): tragedii, konfliktu i\u00a0odpowiedzialno\u015bci. Jednak jego skutki wci\u0105\u017c trudno oszacowa\u0107. Wydaje si\u0119, \u017ce racj\u0119 maj\u0105 ci komentatorzy, kt\u00f3rzy uwa\u017caj\u0105, \u017ce o\u00a0ile nie zostanie dowiedziony Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 148\nudzia\u0142 Rosji w\u00a0planowanym zamachu, to wymowa ca\u0142ego wydarzenia b\u0119dzie nieko -\nrzystna dla Ukrainy. W\u00a0przypadku tego fake newsa mamy do czynienia z\u00a0dwoma \nparadygmatami relacji pomi\u0119dzy politykami a\u00a0mediami. Z\u00a0jednej strony zachodzi \npomi\u0119dzy nimi symbioza (w\u00a0warstwie jawnej, powierzchniowej), z\u00a0drugiej za\u015b do -\nchodzi do manipulacji i\u00a0instrumentalizacji medi\u00f3w (w\u00a0warstwie g\u0142\u0119bszej, ukrytej). \nOstatecznie nast\u0119puje wyja\u015bnienie ukrytych relacji i\u00a0synteza obu poziom\u00f3w. Trudno \njednak powiedzie\u0107, w\u00a0jakim stopniu odczytanie tych relacji jest poprawne, nie mamy \nbowiem mo\u017cliwo\u015bci oceny rzeczywistych intencji s\u0142u\u017cb specjalnych Ukrainy i\u00a0brakuje \nnam informacji o\u00a0ich faktycznych dzia\u0142aniach.\nKonkluzje\nTrzy analizowane przypadki r\u00f3\u017cni\u0105 si\u0119 mi\u0119dzy sob\u0105. Pierwszy jest charaktery -\nstyczny dla medi\u00f3w tradycyjnych, drugi \u2013 dla medi\u00f3w spo\u0142eczno\u015bciowych (szerzej: internetowych), a\u00a0trzeci m\u00f3wi wi\u0119cej o\u00a0dzia\u0142aniach tajnych s\u0142u\u017cb ni\u017c o\u00a0pracy samych dziennikarzy. Niemniej na ich podstawie mo\u017cna wyci\u0105gn\u0105\u0107 wnioski dotycz\u0105ce istoty \npolitycznego fake newsa jako takiego. Ot\u00f3\u017c geneza politycznego fake newsa zawsze \njest zwi\u0105zana z\u00a0potrzebami i\u00a0interesami politycznymi i\u00a0ma s\u0142u\u017cy\u0107 szkodzeniu, znisz\n-\nczeniu lub pokonaniu wroga politycznego b\u0105d\u017a eskalacji konfliktu. Autorami takich \n\u201enews\u00f3w\u201d s\u0105 albo organizacje polityczne (partie, komitety wyborcze, tajne grupy \noperacyjne), albo agencje wywiadu, kontrwywiadu, s\u0142u\u017cby specjalne itd., przy czym cz\u0119sto prawdziwy autor pozostaje w\u00a0ukryciu i\u00a0nie jest znany. Rzadko zdarza si\u0119, \u017ce ich \nw\u0142a\u015bciwymi tw\u00f3rcami s\u0105 sami dziennikarze. G\u0142\u00f3wnymi warto\u015bciami informacyjnymi \nfake news\u00f3w s\u0105: konflikt, negatywizm, personalizacja, sensacyjno\u015b\u0107, dramatyzm, tra -\ngedia. Fake newsy silnie oddzia\u0142uj\u0105 na nastroje i\u00a0opini\u0119 publiczn\u0105 i\u00a0cz\u0119sto prowadz\u0105 do zmiany sytuacji spo\u0142eczno-politycznej, a\u00a0nawet \u2013 w\u00a0przypadkach ekstremalnych \n\u2013 do rozpocz\u0119cia lub eskalacji dzia\u0142a\u0144 wojennych.\nWp\u0142yw fake news\u00f3w na bieg historii trudno przeceni\u0107. Przytoczone i\u00a0przeanali\n-\nzowane wy\u017cej przyk\u0142ady pokazuj\u0105, \u017ce fa\u0142szywe wiadomo\u015bci stanowi\u0105 pot\u0119\u017cn\u0105 bro\u0144 \npropagandow\u0105. Mog\u0105 one wp\u0142yn\u0105\u0107 na wybuch wojny, wyniki wybor\u00f3w czy zaostrzenie \nstosunk\u00f3w mi\u0119dzy zwa\u015bnionymi pa\u0144stwami. Najbardziej niebezpieczne wydaj\u0105 si\u0119 te \nfake newsy, kt\u00f3re s\u0105 \u201eprodukowane\u201d z\u00a0polecenia lub na zam\u00f3wienie agend rz\u0105dowych \ni\u00a0s\u0142u\u017cb specjalnych oraz te, kt\u00f3re powstaj\u0105 w\u00a0kooperacji pomi\u0119dzy tajnymi s\u0142u\u017cbami \ni\u00a0dziennikarzami, nie zawsze \u015bwiadomymi swojej roli w\u00a0przygotowywanej prowoka -\ncji. Unaocznia to szczeg\u00f3lnie trzeci analizowany przypadek, czyli casus Babczenki, kt\u00f3rego postawa \u2013 wed\u0142ug standard\u00f3w etyki dziennikarskiej obowi\u0105zuj\u0105cych w\u00a0de\n-\nmokratycznych krajach na ca\u0142ym \u015bwiecie \u2013 jest nie do zaakceptowania.\nPrzeprowadzona w\u00a0niniejszym artykule analiza dowodzi, \u017ce fake newsy wp\u0142ywaj\u0105 \nnie tylko na procesy podejmowania politycznych decyzji, lecz r\u00f3wnie\u017c na kszta\u0142to -\nwanie postaw spo\u0142ecznych zgodnych z\u00a0oczekiwaniami polityk\u00f3w. Logika medi\u00f3w Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\n149 Fake news w polityce. Studia przypadk\u00f3w\nzostaje zinstrumentalizowana i\u00a0s\u0142u\u017cy osi\u0105ganiu politycznych cel\u00f3w. Jest to koherentne \nz\u00a0odmian\u0105 paradygmatu instrumentalizacji, w\u00a0kt\u00f3rym system polityczny dominuje \nnad systemem medialnym.\nBibliografia\n13 Rosjan oskar\u017conych o\u00a0 ingerencj\u0119 w\u00a0 wybory prezydenckie. Trump pisze: Nie by\u0142o zmowy \n(2018, 17 lutego). Dziennik.pl, http://wiadomosci.dziennik.pl/swiat/artykuly/568948,ros -\njanie-oskarzeni-ingerencja-w-wybory-prezydenckie.html, 5.10.2018.\n[adso] (2016, 18 listopada). Jak Macedo\u0144czycy oszukali wyborc\u00f3w Trumpa. I\u00a0zarobili fortun\u0119.  \nTVN24, https://www.tvn24.pl/wiadomosci-ze-swiata,2/macedonczycy-zarobili-na-wybo -\nrach-w-usa,692896.html, 5.10.2018.\nAssange: Why I\u00a0Created WikiLeaks\u2019 Searchable Database of 30,000 Emails from Clinton\u2019s Pri -\nvate Server (2016, 25 July). democracynow.org , https://www.democracynow.org/2016/7/25/\nassange_why_i_created_wikileaks_searchable, 5.10.2018.\nCarroll O. (2018, 29 May). Russian journalist and Kremlin critic Arkady Babczenko killed in Kiev. \nIndependent , https://www.independent.co.uk/news/world/europe/russian-journalist-killed-\nukraine-arkady-babchenko-kiev-kremlin-wife-a8374976.html, 5.10.2018.\nDan Rather interview with Saddam Hussein (2003, February 24). Youtube.com , https://www.you-\ntube.com/watch?v=Ro519RAtE_M&list=RDRo519RAtE_M&t=3, 5.10.2018.\nDijk T.A. van (1983). Discourse analysis: Its developments and application to the structure of news. \nJournal of Communication , Vol. 33(3), s. 20\u201343. \nDobek-Ostrowska B. (2006). Komunikowanie publiczne i\u00a0polityczne. Wydawnictwo Naukowe PWN: \nWarszawa.\nEkman P . (2006). K\u0142amstwo i\u00a0jego wykrywanie w\u00a0biznesie, polityce i\u00a0ma\u0142\u017ce\u0144stwie. Wydawnictwo \nNaukowe PWN: Warszawa.\nElliot D., Culver Ch. (1992). Defining and analyzing journalistic deception. Journal of Mass Media \nEthics , Vol. 7(2), s. 69\u201384.\nEvon D. (2016, 10 lipca). Pope Francis Shocks World, Endorses Donald Trump for President, Snopes.\ncom, https://www.snopes.com/fact-check/pope-francis-donald-trump-endorsement, 5.10.2018.\nFake news (b.d.). Wikipedia , https://en.wikipedia.org/wiki/Fake_news, 31.05.2018.\nHiggins A. (2018, 29 May). Arkady Babchenko, Russian Journalist, Shot and Killed in Kiev. The New \nYork Times , https://www.nytimes.com/2018/05/29/world/europe/russian-journalist-killed-kiev.\nhtml, 5.10.2018.\nLacapria K. (2016, 13 October). WikiLeaks Confirms Hillary Clinton Sold Weapons to ISIS? Snopes.\ncom, https://www.snopes.com/fact-check/wikileaks-cofirms-hillary-clinton-sold-weapons-to-\nisis, 5.10.2018.\nLevinson P . (2016\u20132017). Fake News in Real Context. Connected Editions Inc.: New Y ork.\nLippmann W . (1922). Public Opinion . New Y ork: Macmillan. \nMacFarquahar N. (2018, June 1). After the Faked Journalist Killing in Ukraine, the Murk Deep-\nens. The New York Times , https://www.nytimes.com/2018/06/01/world/europe/ukraine-ark -\nady-babchenko.html, 5.10.2018.\nMandes R. (2018, 12 marca). Unia Europejska ustali\u0142a definicj\u0119 dla Fake News. Radio Zet Biznes, \nhttps://biznes.radiozet.pl/Newsy/Definicja-Dezinformacja-FAKE-NEWS, 18.09.2018.\nMearsheimer J.J. (2012). Dlaczego politycy k\u0142ami\u0105. Ca\u0142a prawda o\u00a0k\u0142amstwie w\u00a0polityce mi\u0119dzyna-\nrodowej . Wydawnictwo Naukowe PWN: Warszawa.Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nMarek Palczewski 150\nMol\u0119da-Zdziech M. (2013). Czas celebryt\u00f3w. Mediatyzacja \u017cycia publicznego. Difin: Warszawa.\nOniszczuk Z. (2011). Mediatyzacja polityki i\u00a0polityzacja medi\u00f3w. Dwa wymiary wzajemnych relacji. \nStudia Medioznawcze , t. 4(47), s. 11\u201322.\nPolacy znale\u017ali w\u00a0Iraku bro\u0144 chemiczn\u0105 (2004, 2 lipca). RMF24, https://www.rmf24.pl/fakty/\npolska/news-polacy-znalezli-w-iraku-bron-chemiczna,nId,194073, 5.10.2018.\nPolitical Insider (b.d.). https://mediabiasfactcheck.com/political-insider, 5.10.2018.\nPratkins A., Aronson E. (2003). Wiek propagandy. U\u017cywanie i\u00a0nadu\u017cywanie perswazji na co dzie\u0144. \nWydawnictwo Naukowe PWN: Warszawa.\n[PTD/tr] (2018, 29 maja). Us\u0142ysza\u0142a strza\u0142y, wysz\u0142a i\u00a0zobaczy\u0142a m\u0119\u017ca w\u00a0ka\u0142u\u017cy krwi. TVN24, \nhttps://www.tvn24.pl/rosyjski-dziennikarz-arkadij-babczenko-zastrzelony-w-kijow -\nie,841104,s.html, 5.10.2018.\nReport: No WMD stockpiles in Iraq (2004, 7 October). CNN.com International, http://edition.\ncnn.com/2004/WORLD/meast/10/06/iraq.wmd.report, 5.10.2018.\nRitchie H. (2016, 30 December). Read all about it: the fakest news stories of 2016. CNBC.com, \nhttps://www.cnbc.com/2016/12/30/read-all-about-it-the-biggest-fake-news-stories-of-2016.\nhtml, 5.10.2018.\nRoberts H. (2016, 17 November). This is what fake news looks like\u2026 Business Insider , http://\nwww.businessinsider.com/fake-presidential-election-news-viral-facebook-trump-clinton-\n2016-11?IR=T, 5.10.2018.\nRussia\u2019s opposition journalist Arkady Babchenko shot dead in Kiev (2018, 29 May). BBC, https://\nwww.bbc.com/news/world-europe-44296672, 5.10.2018.\nRybczy\u0144ski A. (2018). Zmartwychwstanie dziennikarza. Historia z\u00a0wieloma niewiadomymi. \nGazeta Polska , (24), s. 68\u201370.\nSchulz W . (2006). Komunikacja polityczna. Koncepcje teoretyczne i\u00a0wyniki bada\u0144 empirycznych na \ntemat medi\u00f3w masowych w\u00a0polityce. Wydawnictwo Uniwersytetu Jagiello\u0144skiego: Krak\u00f3w.\nStephens M. (2007). A\u00a0History of News. Oxford University Press: New Y ork.Pobrane z czasopisma Mediatizations Studies http://mediatization.umcs.pl\nData: 18/03/2020 11:56:42\nUMCS\nPowered by TCPDF (www.tcpdf.org)", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fake news w polityce. Studia przypadk\u00f3w", "author": ["M Palczewski"], "pub_year": "2019", "venue": "Mediatization Studies", "abstract": "Celem niniejszego artyku\u0142u jest analiza politycznych fake news\u00f3w w kontek\u015bcie proces\u00f3w  mediatyzacji. Analizie poddano trzy fa\u0142szywe wiadomo\u015bci: o posiadaniu broni masowego"}, "filled": false, "gsrank": 257, "pub_url": "https://bibliotekanauki.pl/articles/691334.pdf", "author_id": ["YfhYKRAAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:12y4CGuxdTgJ:scholar.google.com/&output=cite&scirp=256&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D250%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=12y4CGuxdTgJ&ei=MrWsaIHlAr_SieoPzJnloAQ&json=", "num_citations": 11, "citedby_url": "/scholar?cites=4068352911665032407&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:12y4CGuxdTgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://bibliotekanauki.pl/articles/691334.pdf"}}, {"title": "Echo tunnels: Polarized news sharing online runs narrow but deep", "year": "2023", "pdf_data": "Echo Tunnels: Polarized News Sharing Online Runs Narrow but Deep\nLillio Mok1, Michael Inzlicht2, Ashton Anderson1\n1Department of Computer Science, University of Toronto\n2Department of Psychology, University of Toronto\n{lillio, ashton}@cs.toronto.edu, inzlicht@utoronto.com\nAbstract\nOnline social platforms afford users vast digital spaces to\nshare and discuss current events. However, scholars have\nconcerns both over their role in segregating information ex-\nchange into ideological echo chambers, and over evidence\nthat these echo chambers are nonetheless over-stated. In this\nwork, we investigate news-sharing patterns across the entirety\nof Reddit and find that the platform appears polarized macro-\nscopically, especially in politically right-leaning spaces. On\ncloser examination, however, we observe that the majority of\nthis effect originates from small, hyper-partisan segments of\nthe platform accounting for a minority of news shared. We\nfurther map the temporal evolution of polarized news shar-\ning and uncover evidence that, in addition to having grown\ndrastically over time, polarization in hyper-partisan commu-\nnities also began much earlier than 2016 and is resistant to\nReddit\u2019s largest moderation event. Our results therefore sug-\ngest that social polarized news sharing runs narrow but deep\nonline. Rather than being guided by the general prevalence\nor absence of echo chambers, we argue that platform policies\nare better served by measuring and targeting the communities\nin which ideological segregation is strongest.\nIntroduction\nThe rapid adoption of online platforms has helped people\nconnect, converse, and share information with each other\nacross social and geographical boundaries (Bakshy et al.\n2012; Ellison et al. 2014). At the same time, these plat-\nforms have also become a key means of disseminating and\nconsuming news from traditional media sources in differ-\nent social contexts. A majority of people in the USA obtain\nnews from some form of social media (Shearer and Gottfried\n2017); 31% of adults in the USA, for example, regularly\nget their news from Facebook (Walker and Matsa 2021).\nMore broadly, social media platforms allow users to gen-\nerally be exposed to more and wider sources of news than\nnon-users (Fletcher and Nielsen 2018).\nHowever, online platforms are increasingly scrutinized\nfor potentially causing or exacerbating societal problems\nsurrounding the news consumption cycle. There are con-\ncerns that online news is largely hyper-partisan and filled\nwith polarizing political biases (Budak, Goel, and Rao 2016;\nCopyright \u00a9 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.Bakshy, Messing, and Adamic 2015; Weld, Glenski, and Al-\nthoff 2021). Many have argued that this leads to \u201cecho cham-\nbers\u201d (Flaxman, Goel, and Rao 2016; Boutyline and Willer\n2017) that reinforce existing social silos (Stroud 2008) and\nlimit the extent to which conflicting viewpoints can be rec-\nonciled (Sunstein 2018; Pariser 2011). Indeed, news pre-\nsenting congruent, \u201cco-partisan\u201d attitudes with the reader\u2019s\nown political affiliation (Hasell and Weeks 2016) and hostile\nsentiment against opposing groups (Rathje, Van Bavel, and\nvan der Linden 2021; Schmitz, Burghardt, and Muric 2022)\nis associated with both antagonistic affect and elevated en-\ngagement online.\nDespite this widespread public apprehension around echo\nchambers (Sunstein 2018; Pariser 2011), however, large-\nscale evidence for their existence in and impact on organic\nnews sharing patterns remains mixed. On the one hand,\nsome studies have shown that people tend to be selectively\nexposed to co-partisan, offline news sources (Stroud 2008)\nand interact more with politically like-minded individu-\nals (Boutyline and Willer 2017). Others, however, suggest\nthat the effects of selective exposure to news sources are ei-\nther moderate (Flaxman, Goel, and Rao 2016) or overridden\nby other social determinants (Messing and Westwood 2014),\nand that people generally consume cross-cutting news con-\ntent online (Dubois and Blank 2018; Nelson and Webster\n2017; Barber \u00b4a et al. 2015; Guess et al. 2018; Cinelli et al.\n2021; Gentzkow and Shapiro 2011). Indeed, it even remains\nunclear whether cross-cutting content would alleviate (Bak-\nshy, Messing, and Adamic 2015; Pariser 2011; Sunstein\n2018) or worsen (Bail et al. 2018; Rathje, Van Bavel, and\nvan der Linden 2021) polarized behaviors online.\nThus, to what extent does the sharing of news on online\nplatforms fall within partisan, ideologically-isolated social\ncontexts? To address this research question, we quantify the\nrelationship between the partisan biases present in both news\nproducers, for which we study articles from Allsides-rated\nnews sources, and news consumers, for which we investi-\ngate users of the Reddit platform. Our work presents a large-\nscale analysis of how partisanship in social news-sharing has\nevolved over 8.5 million articles shared on Reddit leading\nup to June 2021, for which we combine measures of parti-\nsan ideologies across established media organizations pro-\nvided by Allsides (Rathje, Van Bavel, and van der Linden\n2021; Ribeiro et al. 2018; Robertson et al. 2018; Baly et al.\nProceedings of the Seventeenth International AAAI Conference on Web and Social Media (ICWSM 2023)\n662\n2020) and Reddit\u2019s user communities derived from a neu-\nral embedding technique (Waller and Anderson 2021). To\nour knowledge, this is the first complete, longitudinal study\nof news consumption on the platform that considers every\ncommunity\u2019s partisan affiliation, both explicitly stated and\nimplicitly imputed via the embedding method.\nOverview of results. We observe three key characteristics\nof polarized news sharing. From a macroscopic perspective,\nwe find that news is shared in asymmetrically co-partisan\nsocial contexts, with right-leaning news being shared dis-\nproportionately more in right-leaning communities. This is\nconsistent with existing findings of asymmetric polarization\nin online news, both real and fake (Gonz \u00b4alez-Bail \u00b4on et al.\n2022; Rao et al. 2021; Rao, Morstatter, and Lerman 2022).\nHowever, at a more granular level, these behaviors are con-\ncentrated in a small fraction of the platform. A handful of\nexplicitly hyper-partisan communities accounts for the ma-\njority of segregated news sharing, suggesting that the most\nextreme echo chambers are likely narrow and deep (Guess,\nNyhan, and Reifler 2018, 2020). Furthermore, we map the\nprocess of polarization, i.e. how co-partisanship has evolved\nover time, and find that it rose sharply in late 2015 to a peak\nin 2017. There is evidence that polarization began earlier in\n2012 for right-leaning news and is unaffected by platform\nmoderation events. Nonetheless, like our findings on hyper-\npartisan communities, this also occurs mainly for the most\nhyper-partisan news sources.\nOur work thus supports claims that the aggregate effects\nof echo chambers on online platforms are limited. How-\never, it also provides crucial context that polarization runs\ndeep within narrow, hyper-partisan spaces, to the extent that\npolitical news sharing on the platform appears deceptively\npolarized at the macroscopic level. Thus, although Reddit\ndoes not consist of a singular echo chamber (c.f. De Fran-\ncisci Morales, Monti, and Starnini 2021), ideologically-\nsimilar news is still echoed within hyper-partisan tunnels\nrunning under the platform\u2019s surface. Taken together, our\nfindings suggest that platform policies may be better in-\nformed by the existence of these strands of deeply polarized\nnews-sharing patterns, rather than the absence of universally\nco-partisan behaviors.\nBackground\nOur work builds on a growing body of research on the soci-\netal implications of online news sharing. For instance, there\nis widespread concern that hyper-partisan news sharing may\nlead to polarized communities and ideological echo cham-\nbers (Bakshy, Messing, and Adamic 2015; Weld, Glenski,\nand Althoff 2021; Flaxman, Goel, and Rao 2016; Boutyline\nand Willer 2017; Sunstein 2018; Pariser 2011). However, ev-\nidence for the prevalence of echo chambers is inconsistent,\nwith the maxim that they threaten societal cohesion punctu-\nated by claims that they are actually over-stated (Dubois and\nBlank 2018; Nelson and Webster 2017; Cinelli et al. 2021;\nDe Francisci Morales, Monti, and Starnini 2021). In parallel\nto this inconsistent descriptive evidence of echo chambers\nonline, there is also no general consensus on whether pro-\nmoting cross-cutting content \u2013 i.e. opposing ideologies \u2013 isnormatively desirable. While some assume that exposure to\ndiverse viewpoints may help reduce extreme attitudes (Bak-\nshy, Messing, and Adamic 2015; Pariser 2011; Sunstein\n2018), other studies also show that cross-cutting and out-\ngroup content may actually increase polarization (Bail et al.\n2018; Rathje, Van Bavel, and van der Linden 2021).\nFurthermore, concerns about news sharing online extend\nbeyond political and ideological segregation. For instance,\nresearch has also highlighted the threats of online misin-\nformation (Grinberg et al. 2019; Allcott, Gentzkow, and Yu\n2019) and provided evidence for negative effects on well-\nbeing (Boukes and Vliegenthart 2017; Allcott et al. 2020).\nAnd yet, while reducing social media usage can help moder-\nate polarization and well-being, it does so at the expense of\nfactual knowledge about political issues (Allcott et al. 2020).\nTogether, this literature on the societal implications of on-\nline news highlights the need to form a clearer understanding\nof how people read and share news in situ on social plat-\nforms. On the one hand, we have an imperfect understand-\ning of whether echo chambers are widespread online. On the\nother, it is unknown whether this is a result of limited gen-\neralizability in existing work. For example, phenomena ob-\nserved in self-reported news readership habits at small scales\noften do not align with what people actually consume online\nin general (Konitzer et al. 2021).\nWe therefore measure partisanship in news sharing on\ntheentire Reddit platform, described as the \u201cFront Page\u201d\nof the Internet (Singer et al. 2014). On Reddit, millions of\nusers organize themselves into thousands of discrete on-\nline communities sharing common interests and modera-\ntion norms (Chandrasekharan et al. 2018). Here, we quantify\ntheimplicit partisanship of communities by how much they\nshare similar user-bases with political communities (Waller\nand Anderson 2021). This contrasts with other methods con-\nsidering only explicit partisanship via community names\nliker/democrats and their \u201cAbout\u201d information (Soliman,\nHafer, and Lemmerich 2019; An et al. 2019; Cinelli et al.\n2021; De Francisci Morales, Monti, and Starnini 2021).\nSimilarly, partisanship on Twitter is often quantified by\nnetworks formed by sampling followers of political fig-\nures (Boutyline and Willer 2017) and retweets of on- and\noff-platform content (Barber \u00b4a et al. 2015). On Facebook,\npartisanship can be inferred from samples of users\u2019 self-\nreported affiliation (Bakshy, Messing, and Adamic 2015).\nMethod\nWe obtained all user activity on Reddit between January\n2008 and June 2021 via Pushshift.io. Users interact with\nthe platform by posting top-level content (\u201csubmissions\u201d)\ninto individual communities (\u201csubreddits\u201d), on which users\ncan post shorter \u201ccomments\u201d in threads of discussion. To\nidentify news-sharing behaviors, we obtained a list of news\nsources labelled by Allsides.com, an organization that pro-\nvides fact-checking and ideological bias ratings for com-\nmon media sources (Rathje, Van Bavel, and van der Lin-\nden 2021; Ribeiro et al. 2018; Robertson et al. 2018; Baly\net al. 2020). We match Allsides-rated Web domains to Red-\ndit submissions linking directly to external websites, such as\nnytimes.com, mobile.nytimes.com, and nytimes.com for New\n663\nLeft (-2) Lean Left (-1) Center (0) Lean Right (+1) Right (+2)\nAlternet ABC News Associated Press The Epoch Times The Blaze\nBuzzfeed The Atlantic Axios New York Post Breitbart News\nCNN Bloomberg The BBC Newsmax The Daily Caller\nThe Daily Beast CBS News CS Monitor Reason The Daily Mail\nDemocracy Now The Economist Forbes Washington Examiner The Daily Wire\nHuffPost The Guardian The Hill Washington Times The Federalist\nThe Intercept NBC News Newsweek Fox News\nJacobin The New York Times NPR Fox News Insider\nMother Jones Politico Reuters National Review\nMSN Time Wall Street Journal One America News\nThe New Yorker USA Today The Spectator\nSlate Washington Post\nV ox\nTable 1: Overview of news sources submitted to Reddit and their Allsides ratings at time of analysis (2022).\nYork Times articles. In total, we considered 177 websites\nthat matched to 53 news organizations.\nWe further attenuate automated activity in two steps. We\nfirst under-sample commenting activity of users whose com-\nment frequencies are in the top 0.1%of Redditors so that\nthey remain within the remaining 99.99% (in our data, sam-\npling up to 141 comments each month from users with\n>141comments per month). We then discard submissions\nwith fewer than 2 comments and a upvote-to-downvote score\nof 2. This ignores posters who comment on and upvote their\nown posts, further limiting our dataset to news articles that\nhave been exposed to other Reddit users. Altogether, our re-\nsulting dataset contains 4.97M unique URLs from Allsides-\nrated sources across 8.50M submissions.\nCommunity embedding. We further use a community em-\nbedding developed to model community relationships from\nuser behaviors in a high-dimensional space (Waller and An-\nderson 2021; Kumar et al. 2018; Martin 2017). While ex-\nisting work often focuses solely on explicitly political com-\nmunities (An et al. 2019; Rajadesingan, Resnick, and Bu-\ndak 2020; De Francisci Morales, Monti, and Starnini 2021),\nthis embedding method applies to the entirety of Reddit and\nenables us to characterize the political biases of seemingly\napolitical communities like r/technology and mildly right-\nleaning subreddits like r/malelifestyle. This embedding is\nalso granular, whereas existing work often can only binarize\nifa subreddit is right- or left-leaning, and not measure how\nright- or left-leaning it is. Thus, to this end, we use a modi-\nfied version of word2vec for word embeddings that allows\nfor arbitrary word contexts, instead of only a fixed-sized\nwindow (Levy and Goldberg 2014). Conceptually, textual\ndocuments in word2vec are replaced with user commenting\ntraces such that users are \u201csentences\u201d forming contexts for\nsubreddits as \u201cwords\u201d. Thus, two communities are closer in\nthis embedding if they share more users who participate in\nboth of them by posting comments.\nHyper-parameters are then tuned using community analo-\ngies, specifically sports teams to their respective sports,\nteams to their cities, and universities to cities; e.g. queryingr/columbia:r/nyc::USC :? should yield r/LosAngeles. This\nfollows established work on community embeddings adapt-\ning analogy-based tuning methods from language models,\nwhich are known to effectively capture semantic relations\nbetween communities (Martin 2017; Waller and Anderson\n2021). The training process led to an alpha of 0.18, a\nnegative-sampling parameter of 35, sampling rate of 0.0043,\ndimensionality of 150with shuffled comment ordering. Note\nthat the embedding is trained using allReddit comments in\nthe 10k communities with the most activity, and not just the\nsubmission histories linking to Allsides mentioned above.\nThis allows the embedding to more holistically capture be-\nhavioral patterns beyond those containing news links.\nMeasuring Ideological Biases\nWe consider two aspects of ideological biases in news shar-\ning: partisanship in the sources from which news is pro-\nduced, and partisanship in the social communities in which\nnews is consumed. We use Allsides ratings and embedding\npartisanship scores respectively to measure these biases in\nnews articles shared on Reddit.\nMedia partisanship. To operationalize ideological partisan-\nship in news coverage \u2013 or producer-side news contexts \u2013\nwe directly use the bias labels lAfrom Allsides for each fea-\ntured news association A, which ranges from \u22122to+2for\nthe US political left to the US political right (Table 1). For\nan article a\u2208A, its media partisanship lais therefore de-\nfined directly by the Allsides rating of its publishing orga-\nnization A. This has been used throughout existing work on\nideological biases in sociotechnical systems (Ribeiro et al.\n2018; Robertson et al. 2018), and recent evidence suggests\nthat different choices of news labels generally yield similar\nresults for fact-checking tasks1(Bozarth, Saraf, and Budak\n1We also ran a secondary set of analyses using Media Bias Fact\nCheck ratings (https://mediabiasfactcheck.com) and found qualita-\ntively almost identical results. The main differences were in smaller\nnews sources on Reddit (Figure 1) being labelled as more partisan\nby MBFC than Allsides. Newsmax, the Epoch Times, the Washing-\nton Examiner are rated +1by Allsides but +2by MBFC; Forbes,\n664\n2020; Weld, Glenski, and Althoff 2021).\nSocial partisanship. To operationalize ideological biases in\nsocial settings \u2013 or consumer-side news contexts \u2013 we addi-\ntionally compute a social \u201cpartisanship\u201d score for each com-\nmunity by using the community embedding. We first com-\npute the cosine similarity between each community\u2019s em-\nbedded vector and an \u201cindex\u201d vector between polar opposite\npartisan communities, specifically r/progressive andr/Con-\nservative. This pair was chosen as they have identical inter-\nests (American politics) but differ only in one aspect (par-\ntisanship), and the resulting cosine similarities are highly\ncorrelated to cosine similarities when using other pairs like\nr/askhillarysupporters and r/AskTrumpSupporters (Waller\nand Anderson 2021).\nFormally, given a community cin the set of 10k com-\nmunities C, its embedded vector \u20d7 c, and the partisan vector\n\u20d7 v,c\u2019s partisanship z-score is given by zc=\u03b3c\u2212\u00af\u03b3\n\u03c3(\u03b3)where\n\u03b3c=cossim (\u20d7 c,\u20d7 v), and \u00af\u03b3and\u03c3(\u03b3)are respectively the\nmean and standard deviation of the cosine similarities across\nC. This is equivalent to answering: how many standard de-\nviations to the political left or right is community c, relative\nto the mean subreddit? For context, the three closest com-\nmunities to z= 0 are respectively r/UWMadison, r/matt (a\nsubreddit dedicated to mentions of Matt or Matthew), and\nr/ukulele. In comparison, r/Conservative (z= 5.82) and\nr/democrats (z=\u22124.67) are the most partisan communi-\nties on either side of the spectrum.\nA news article\u2019s social partisanship is therefore given by\na weighted mean over the partisanship scores of the em-\nbedded communities in which it appears. Given an article\nafrom a news source Aappearing na,ctimes in a commu-\nnitycwith score zc, its article-level social partisanship is\ngiven by \u03d5a=1\nNaP\nc\u2208Cna,czcwhere Na=P\nc\u2208Cna,c.\nCorrespondingly, we also measure the source-level social\npartisanship \u03d5Aof each news association Aas a sum over\nits articles \u03d5A=1\nNP\nc\u2208CP\na\u2208Ana,czc, where N=P\nc\u2208CP\na\u2208Ana,c. The interpretation of \u03d5aand\u03d5A, respec-\ntively, is therefore: how many standard deviations to the po-\nlitical left or right are the communities cin which a(orA)\nappears, on expectation?\nTemporal metrics. In addition to these static measures of\nnews and social partisanship, we also trialled dynamic ver-\nsions for temporal analyses. For social partisanship, we\ncompute individual partisan scores \u03d5A,tper news source,\nper month, by re-weighting using na,c,t each tth month,\nwhich replaces na,cin the definition of \u03d5a. Note that we use\nthe same z-scores from the single embedding generated by\nall Reddit comments described above, rather than methods\nlike diachronic embeddings that embed individual timeslices\nseparately (Hamilton, Leskovec, and Jurafsky 2016). This\nenables us to quantify the partisanship of articles at each\ntrelative to all of Reddit at all times, rather than relative\nto Reddit at the tth month only. Additionally, a single em-\nWall Street Journal, and Newsweek are rated 0by Allsides but +1\nby MBFC. Using MBFC thus increases the number of dark red\npoints in Figure 2 and lowers the +1line in Figure 5(a), but does\nnot change our overall findings on polarization.bedding using all data will be less susceptible than temporal\nembeddings to confounders in, for example, transient activ-\nity surges in topical subreddits. For news partisanship, we\nexperimented with yearly Allsides ratings to capture fluctu-\nations in how, e.g., CNN shifted towards the political left\nin recent years. This led to qualitatively very similar results\nto using static news labels, so for ease of interpretation we\npresent findings with static labels2.\nResults\nBefore considering the individual subreddits in which arti-\ncles appear, we first characterize the distribution of differ-\nent news sources on Reddit as a single community. How\ndo news-sharing behaviors on Reddit overall differ between\ntime frames and news sources? Figure 1(a) depicts the dis-\ntribution of submissions across months on the platform, the\ncumulative fractions for which are shown in (b). We find\nseveral general patterns. Firstly, after rapid activity growth\nending in mid-2017, news articles on Reddit from Allsides-\nrated sources have been submitted at a stable, consistent rate\non aggregate. Secondly, centrist and moderately left-leaning\nsources make up the bulk of news sharing on Reddit, to-\ngether accounting for more than 60% of articles on Reddit.\nThirdly, despite making up fewer than 10% of news prior to\n2016, moderately and explicitly right-leaning news sources\ngrew to 20% of news shared on Reddit between 2016 and\n2020. Although they still form a much smaller fraction than\nthe grey and light-blue area in Figure 1, the growth in the\nlight-red and red area diluted the presence of explicitly left-\nleaning, blue news sources.\nThese observations about news on Reddit provide a base-\nline for the amount of news shared on the platform that\nare generated by different news producers and, therefore,\nare published in different media contexts. Based purely\non the amount of partisan news from left-leaning sources\nshared on Reddit, the platform appears to be moderately\nleft-leaning. Considering Reddit\u2019s generally liberal demo-\ngraphics as measured by recent surveys (Walker and Matsa\n2021; V ogels, Auxier, and Anderson 2020), this suggests\nthat news-sharing by Redditors \u2013 as a singular left-leaning\npopulation \u2013 is co-partisan. Nonetheless, such a conclusion\nignores the vast diaspora of political ideologies housed by\nthe platform, especially when subreddits can be explicitly\nantithetical (e.g. r/The Donald andr/hillaryclinton).\nPartisan News in Partisan Social Contexts\nThus, how are news articles from different established me-\ndia organizations shared across the different social contexts\n2See https://www.allsides.com/blog/how-allsides-media-bias-\nratings-have-changed-over-time. The main noticeable difference\nin our experiments is that the +2line in Figure 5(a) does not re-\ncede as much after late 2017, which we find is because the Epoch\nTimes, Newsmax, the New York Post, and Washington Examiner\ndropped from +2to+1, leaving more extreme sources in the +2\ngroup. Additionally, Fox News was considered +1between 2017\nand 2020, removing another source of decline in the +2line (see\nFox line in Figure 5(b)). Beyond this, however, our results and their\ninterpretation do not change substantially.\n665\n100101102103104Yearly Submissions (Log Scale)Allsides Rating\n-2.0\n-1.0\n0.0\n1.0\n2.0\n2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021\nYear0.00.20.40.60.81.0Fraction of Allsides Submissions\ncnn\nhuffpost\nmsn\nthedailybeast\nslate\nvox\ntheintercept\nalternet\nmotherjones\nnewyorker\njacobin\ndemocracynow\nbuzzfeed0100000200000300000400000500000600000700000800000T otal Submission Count\ntheguardian\nnytimes\nwashingtonpost\nnbcnews\nbloomberg\npolitico\nusatoday\nabcnews\ntheatlantic\ncbsnews\ntime\neconomist\nbbc\nreuters\nthehill\nnpr\napnews\nforbes\nwsj\nnewsweek\naxios\ncsmonitor\nnypost\nwashingtonexaminer\nwashingtontimes\nreason\ntheepochtimes\nnewsmax\nbreitbart\nfoxnews\ndailymail\ndailycaller\ndailywire\nnationalreview\ntheblaze\nthefederalist\nspectator\noann\nfoxnewsinsiderFigure 1: Top (a): Number of articles (non-unique) from Allsides-rated sources shared to Reddit each month. Middle (b):\nMonthly share of news articles on Reddit by sources under each Allsides label. Bottom (c): Total number of submissions\nlinking directly to an Allsides source grouped by Allsides label.\non Reddit? We turn to our main analysis: the relationship be-\ntween news producer and news consumer ideological biases\non Reddit. Figure 2 depicts each news source\u2019s ideological\nbiases, measured by Allsides, and social biases, measured by\nthe partisanship of the communities in which they appear.\nWe find two consistent patterns. Firstly, with media parti-\nsanship measured through Allsides ratings labeing strongly\ncorrelated to the embedding social partisanship metric \u03d5a\n(r= 0.92), there is a substantial amount of co-partisan\nnews sharing globally across all of Reddit. In other words,\nbiases in news sources lAand biases in online communities\n\u03d5Aagree \u2013 left-leaning news is more likely to be consumed\nby left-leaning communities, and likewise for right-leaning\nnews. Visually, this is evident by the split of red and blue\ndots respectively to the right and left of \u03d5= 0. Note that\nthis does not account for actual content, i.e. what is written\ndirectly in articles. Nonetheless, assuming that both news\nsources and online laypeople frame current events within\ntheir partisan viewpoints, our results suggest that where\nnews is produced and consumed may form echo chambers\non the basis of co-partisan discursive norms.A second pattern in Figure 2 is that co-partisan news\nconsumption is heavily asymmetrical between the political\nleft and right on Reddit. While left-leaning news sources\nall appear in contexts that are within one standard devia-\ntion to the left of center (except Mother Jones, \u03d5=\u22121.04),\nright-leaning news sources are consumed in extremely right-\nleaning social contexts. Only New York Post (\u03d5 = 0.66),\nReason (\u03d5 = 0.80), and The Daily Mail (\u03d5 = 0.82) fall\nwithin one standard deviation to the right of center. Because\nz\u2212scores are calculated relative to all of Reddit (such that\nif a specific community\u2019s score were z= 1, then it is one\nstandard deviation to the right of all communities\u2019 mean\npartisanship score), this demonstrates the extreme skew in\nright-leaning co-partisan news-sharing contexts. In other\nwords, the consumption of news from moderately right- and\nfar right-leaning outlets occurs within right-leaning social\ncontexts that are relatively extreme compared to the rest\nof Reddit. There is no left-leaning equivalent of Breitbart\nand The Daily Wire on this account of producer-consumer,\ntraditional-social media co-partisanship. These results sug-\ngest that purely producer-side partisanship ratings that label,\n666\n\u22124 \u22122 0 2 4\nWeighted Embedding Partisanship z-Scoredailywire\nthefederalist\nfoxnewsinsider\ndailycaller\nbreitbart\nnationalreview\nspectator\nnewsmax\nwashingtonexaminer\ntheepochtimes\nwashingtontimes\nfoxnews\ntheblaze\noann\ndailymail\nreason\nnypost\nwsj\nreuters\nforbes\nbbc\napnews\nbloomberg\nusatoday\nabcnews\ntheguardian\neconomist\nmsn\nnbcnews\ncbsnews\nthehill\ntime\ncsmonitor\ncnn\nnytimes\nnpr\ntheintercept\nnewsweek\npolitico\ntheatlantic\naxios\ndemocracynow\nnewyorker\nhuffpost\nwashingtonpost\nbuzzfeed\nslate\nthedailybeast\nvox\nalternet\nmotherjones\njacobin\nMedia Organizations in Social Contexts\nAllsides Rating\n-2.0\n-1.0\n0.0\n1.0\n2.0Figure 2: Traditional media organizations by the aggregated\npartisanship scores of the communities in which they are\nshared. Communities are given individual z-scores normal-\nized over all of Reddit before aggregating by news source.\nsay, The Huffington Post as the polar opposite of Breitbart\nmay not sufficiently capture skewed ideological biases in ac-\ntual news consumer contexts.\nHow do these two patterns of news consumption on Red-\ndit relate to existing evidence about potential ideological\necho chambers on online platforms more broadly? Our work\nprovides additional large-scale, empirical support both to ex-\nisting work on co-partisan consumption of news (Flaxman,\nGoel, and Rao 2016; Boutyline and Willer 2017; Hasell and\nWeeks 2016) and to recent studies on asymmetric online be-\nhaviors among the political right (Eady et al. 2019; Soli-\nman, Hafer, and Lemmerich 2019; Rao et al. 2021). In this\nsense, the news consumption patterns we uncover are there-\nfore consistent with echo chambers formed by people dis-\ncussing news with similar ideological biases.\nHowever, this co-partisanship may not apply evenly\nacross the entire online platform beyond its explicitly po-\nlitical spaces. If ideological echo chambers were to exist,\ndo they arise homogeneously across Reddit as a whole?\nWhile Figure 2 corroborates existing evidence of co-partisan\nnews-sharing behaviors, it does not distinguish, for in-\nstance, between posting behaviors in partisan and non-\npartisan communities. We therefore disaggregate our co-\npartisanship analysis by separating explicitly partisan com-\nmunities from non-partisan communities. We considered the\n\u22126 \u22124 \u22122 0 2 4 6\nWeighted Embedding Partisanship z-Scoredailywire\ntheblaze\nnationalreview\nthefederalist\nspectator\ntheepochtimes\nnewsmax\nbreitbart\nfoxnews\ndailycaller\nwashingtontimes\nnypost\nwashingtonexaminer\noann\nfoxnewsinsider\ndailymail\nreason\nwsj\nbbc\nforbes\nreuters\nusatoday\napnews\ncbsnews\neconomist\nabcnews\nthehill\nbloomberg\nmsn\ntime\nnbcnews\ncsmonitor\npolitico\ntheguardian\nnpr\naxios\nnytimes\ntheintercept\nnewsweek\ncnn\ntheatlantic\nnewyorker\nbuzzfeed\nwashingtonpost\ndemocracynow\njacobin\nslate\nthedailybeast\nhuffpost\nvox\nmotherjones\nalternet\nNews in Partisan vs Nonpartisan Contexts\nContext\nPartisan\nNonpartisanFigure 3: Disaggregation of Figure 2 by news sources shared\nin explicitly partisan versus nonpartisan communities.\n50 communities with the highest and lowest partisanship\nscores, and manually checked whether their Reddit descrip-\ntions contain either explicit support for or rejection of ei-\nther 1. the Republican or Democrat parties, or 2. Republi-\ncan or Democrat politicians (including affiliated individuals\nlike Bernie Sanders). This yielded 32 explicitly left-wing\nsubreddits, e.g. r/hillaryclinton (z=\u22124.09) and r/Rus-\nsiaLago (z=\u22121.65), and 18 explicitly right-wing subred-\ndits, e.g. r/HillaryMeltdown (z= 2.74) and r/The Donald\n(z= 4.37). Together, these partisan communities account\nfor 10.4% of Allsides-linked submissions on Reddit.\nFigure 3 illustrates the social biases of news sources,\nsplit by whether communities are explicitly partisan (tri-\nangles) or not (crosses). Although we still find co-partisan\nmedia-social ideological alignment in non-partisan commu-\nnities, the range of scores is substantially curtailed with\nReason (\u03d5 = 1.25) and Mother Jones (\u03d5 =\u22120.95) be-\ning the furthest poles. However, partisan news sharing is\ndrastically amplified in partisan communities, with every\nright-leaning source scoring above \u03d5= 4 and The Daily\nWire reaching \u03d5= 5.24. Of all news sources, only 9 out\nof 48 had partisanship scores within 1 standard deviation\nof the center when only considering partisan communities.\nIn non-partisan communities, all sources except Breitbart\n(\u03d5= 1.04), The Daily Wire (\u03d5 = 1.11), The Federalist\n(\u03d5= 1.14), and Reason (\u03d5 = 1.25) fell within 1 standard\ndeviation.\n667\n\u22122.0 \u22121.5 \u22121.0 \u22120.5 0.0 0.5 1.0 1.5 2.0\nWeighted Allsides Rating\u22126\u22124\u221220246Embedding Partisan z-Score\nReddit Communities by Media and Social Partisanship\n0.51.01.52.02.53.0Number of Allsides Submissions (Log 100)Figure 4: Communities with at least 10 submissions linking\nto Allsides news articles, scattered by their Allsides media\npartisanship (x -axis) and embedded social partisanship (y -\naxis). Partisan communities shown as blue triangles; means\nshown in dotted grey.\nThus, while news sharing on the platform appears to be\npartisan and polarized from the bird\u2019s eye view of Figure 2,\nthis is largely mild in the majority of communities without\nobvious partisan affiliation. However, co-partisan news shar-\ning is pervasive within the narrower space of hyper-partisan\ncommunities, to the extent that they distort Reddit from a\nmacroscopic perspective. This occurs despite partisan com-\nmunities only accounting for 10.4% of all news shared, and\nis asymmetrically larger for right-leaning media organiza-\ntions and social contexts.\nCommunities by partisan news sharing. Our analyses thus\nfar highlight the asymmetric, co-partisan relationship in the\nideological biases surrounding each news source on Red-\ndit, both with respect to the publishing organization and to\nthe communities of news readers. Nonetheless, these results\nonly measure media and social partisan biases for news pub-\nlishers. One may expect that news consumers would also\nshare co-partisan news articles. A complementary question\nis therefore: to what extent do different communities of news\nreaders share co-partisan news sources?\nIn order to address this question, we consider commu-\nnities, instead of news sources, by their media and social\npartisanship metrics. To measure media partisanship for a\ngiven community c, we use a mean over the Allsides labels\nlaof each article aposted in the community weighted by\nnumber of submissions. In other words, for each commu-\nnityc, its media partisanship is lc=1\nNcP\nalana,c, where\nNc=P\nana,c3. To measure social partisanship we directly\nuse the embedding partisan scores zcfor each community c.\n3Note that media partisanship in communities is measured anal-\nogously to social partisanship of news sources, i.e. \u03d5a, but with em-\nbedding scores zcswapped for Allsides labels laand news sources\naswapped for subreddits c.Figure 4 illustrates communities with at least 10 submis-\nsions linking to Allsides-rated news sources (N = 4409)\nscattered according to both of these partisanship measures.\nWe find there to be a vast amount of variance in the weighted\nAllsides metric and embedding scores, leading to only a\nslight correlation at the community level (r= 0.36). How-\never, this relationship is significantly closer (r = 0.86) for\nthe 50 explicitly partisan communities previously identified.\nThis again reinforces our previous findings: there is substan-\ntial co-partisan, polarized sharing of news online, but co-\npartisanship is only concentrated within a minority of polit-\nical communities.\nFurthermore, we find additional evidence of asymmetric\nco-partisanship between the political left and right at the\ncommunity level. Consider r/Conservative and r/progres-\nsive, the polar communities used to determine the partisan-\nship vector in the Reddit embedding, which respectively\nscore z= 5.82andz=\u22124.05on the social partisan-\nship score. Here, they respectively obtain l= 1.21andl=\n\u22121.24on the media partisanship measure. Against a mean\nmedia partisanship of l=\u22120.59,r/Conservative lies2.76\nstandard deviations to the right of the mean compared to\nandr/progressive\u2019s \u22121.09standard deviations. This further\nhighlights the skewed media co-partisanship for the right-\nmost community. Similarly, r/The Donald andr/hillaryclin-\ntonrespectively have media partisanship scores of l= 1.08\nandl\u22120.86, representing 2.62and\u22120.78standard de-\nviations respectively. Thus, co-partisan news consumption\nis most prevalent among both strongly right-leaning news\nsources and strongly right-leaning communities, relative to\nleft-leaning sources and communities.\nThis is reflected in the likelihood of exposure to sources\nwith similar ideologies in the most partisan communities.\nFor example, the probability of a random news article drawn\nfrom r/Conservative being from a far-right source is 0.61,\nwhereas the probability of a random far-left article drawn\nfrom r/progressive is0.43. Indeed, the odds of sharing ex-\ntreme co-partisan news is generally asymmetric, with news\nin right-wing communities being more likely to be far-right\n(odds of 0.45) than news in left-wing communities being\nfar-left (odds of 0.33;p= 0.002in an unpaired t-test).\nTogether, these findings of co-partisanship based on in-\ndividual online communities reinforce our results for in-\ndividual news sources. Co-partisanship patterns are, again,\nmore evident in right-leaning social contexts. Outside of the\nhyper-partisan segments of Reddit, however, co-partisanship\nis mild. This provides further evidence that echo chambers\nare unlikely to be pervasive, and instead run deep in nar-\nrower, hyper-partisan spaces of the platform.\nThe Evolution of Polarization\nOur results so far paint a static picture of how traditional me-\ndia sharing in online social contexts can be colored by co-\npartisan ideological biases. News-sharing behaviors, how-\never, are dynamic and often change in complex ways over\ntime. To investigate the evolution of partisan social con-\ntexts around news sharing, we compute monthly partisan-\nship scores \u03d5A,tfor news source on the platform. The result-\ning temporal scores indexed by month are shown in Figure 5,\n668\n\u22122\u2212101234Sharing of News Sources in Social Contexts Over Time\nAllsides Rating\n-2.0 -1.0 0.0 1.0 2.0\n2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021\nYear012News Source IQRMonthly Weighted Embedding Partisanship (z) Score\n2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021\nYear\u22124\u22122024Monthly Weighted Embedding Partisanship (z) Score\nSharing of News Sources in Social Contexts Over Time\nNews Source\ndailymail\nfoxnews\nbreitbart\nwashingtontimes\nwashingtonexaminernypost\nbbc\nthehill\nreuters\nnytimeswashingtonpost\ntheguardian\nmsn\ncnn\nhuffpostFigure 5: Left(a): Temporal patterns in news sharing contexts. Monthly embedding partisanship scores are aggregated by news\norganizations under the same Allsides label with a 95% CI. Right (b): The same patterns disaggregated into the three most\nshared news sources within each Allsides label.\nsplit respectively by Allsides rating (a) and the top 3 news\nsources per Allsides rating by appearances (b). We again ob-\nserve skewed co-partisan news-sharing behaviors that persist\nover time, with right-leaning news sources being asymmetri-\ncally shared in more right-leaning social contexts. However,\nwe find three additional dynamics in these patterns.\nIncreasing and asymmetric polarization. Firstly, co-\npartisan news consumption increases across our trace, indi-\ncating that the platform became polarized over time. In Fig-\nure 5, each group of news sources with an Allsides-labelled\npartisan bias shifts outwards over time, culminating in max-\nimal displacement from y= 0 in late 2017 and early 2018.\nVery left-leaning news sources were, at the most extreme,\nconsumed by people in communities scoring \u03d5=\u22120.99to\nthe left of center on Reddit in August 2017, compared to\n\u03d5=\u22120.77and\u03d5=\u22120.62a year and two years before\nrespectively. Very right-leaning sources similarly, but asym-\nmetrically, peaked at \u03d5= 2.81in December 2017 compared\nto\u03d5= 2.58and\u03d5= 1.67the two Decembers before.\nAs an aggregate measure of polarization, consider the\ninter-quartile range (IQR) of the partisan scores between in-\ndividual news sources (green line in Figure 5, represented as\na delta between \u03d5). Until December 2015, the partisanship\nIQR remained within \u2206\u03d5= 1.00, indicating that most news\nsources were shared in communities that fall within a narrow\nideological band. In contrast, the IQR peaks at \u2206\u03d5= 2.44\nin February 2017 coinciding with then-President Donald\nTrump\u2019s assumption of office and the formation of his cab-\ninet. This indicates a dramatic partisan widening of media\norganizations over time: 50% of sources were shared in con-\ntexts separated by a partisanship gap of more than 2 standard\ndeviations. Right-wing news sources contribute most to thispolarization, with outlets like Breitbart being consumed in\nvery right-leaning communities across most of this period in\nFigure 5(b). Thus, we find that the news-sharing behaviors\nin Figure 2 become increasingly co-partisan and asymmet-\nric on the political right when they are broken down by time\nframes.\n2016-17 as a (misleading) focal point. It would there-\nfore appear that 2016 is a focal point for polarization\nin news consumption because co-partisanship increases\nsharply leading up to the US Presidential Election. And yet,\nFigure 5(a) provides some evidence that far-right sources\nalready began appearing in seemingly polarized co-partisan\ncontexts in late 2012. We find that this is likely due to\nthe early growth of the r/Conservative community, illus-\ntrated as the uppermost, most socially right-leaning point at\nx= 1.21, y = 5.82in Figure 2(b). From January to October\n2012, links to Allsides-rated news sources in the subreddit\ngrew almost monotonically from 402 to 3950, with Breit-\nbart links specifically jumping from 3 to 206 per month. In\ncomparison, Breitbart articles were only shared 19 times in\nr/POLITIC in October, at the time the subreddit with the\nsecond most Breitbart submissions.\nThus, the role of r/Conservative as the community with\nboth the most right-leaning partisan score and most of the\nshares of Breitbart articles in 2012 drove the sharp spike\nvisible in Figure 5(b). These observations show that polar-\nization of news consumption may significantly predate the\n2016 election (Moody and Mucha 2013), which may other-\nwise be seen as an catalyzing point for ideological division\nin US politics. However, they again show that early polariza-\ntion is not broadly prevalent across the platform, and is in-\nstead driven by skewed sharing of (at the time) fringe news\n669\nsources in a relatively fringe subreddit with extreme parti-\nsanship. Like our results about the heterogeneously partisan\nnews sharing on Reddit in Figures 2 and 3, our current find-\nings also illustrate that polarized news sharing occurs het-\nerogeneously early in those communities.\nIn spite of this, however, our results in Figure 5(a) also\nsuggest that the polarized, partisanship gap in news shar-\ning has receded since its peak in February 2017. We tested\nthis using piece-wise regressions between partisan scores\nand month indices around February 2017. Positive regres-\nsion coefficients indicate that social partisanship scores grew\nwith the same sign as news sources\u2019 Allsides ratings \u2013 i.e.,\nthat they became shared in increasingly polarized social con-\ntexts. For example, if \u03b2= 0.1for a news source, then that\nnews source was shared in increasingly co-partisan subred-\ndits at the rate of 0.1 standard deviations each month.\nAs expected, co-partisan sharing of far-right news sources\nbecame more polarized leading up to February (\u03b2 = 0.02,\np < 0.001), and then decreased afterwards (\u03b2 =\u22120.02,\np < 0.001). Co-partisan sharing of far-left news sources\nalso followed similar patterns but with a much smaller ef-\nfect size(\u03b2 = 0.003,p < 0.001before and \u03b2=\u22120.008,\np < 0.001 after February 2017). Indeed, the partisanship\nIQR metric for polarization also decreased to below \u2206z=\n1.5after May 2019 from its peak of \u2206z= 2.44in February\n2017. These patterns thus suggest that, in addition to being\nrestricted to a small subset of the platform, polarized news-\nsharing behaviors may have already reached a peak on the\nReddit platform.\nBehavioral fluctuations around platform moderation.\nFinally, polarized news sharing appears to be surpris-\ningly robust to platform moderation efforts. Consider the\nr/The Donald community, which accounts for a plurality of\nall far right-leaning news links on Reddit from January 2016\nto January 2020 (34.0% vs 6.9% in r/Conservative, which\nhas the second highest share). Having started in June 2015\nafter Donald Trump announced his Presidential candidacy,\nthe community was quarantined in June 2019 with a dis-\nclaimer on its landing page for repeatedly violating Reddit\u2019s\ncontent policies. It was subsequently restricted in February\n2020 and fully banned in June 2020 (Horta Ribeiro et al.\n2021; Chandrasekharan et al. 2022).\nWe find that the resulting abandonment of r/The Donald\nand its role as the largest community of right-wing news\nsharers led to a reduction of 30% of right-wing news be-\ntween February and March 2020. However, despite being an\nobvious visual drop in Figure 5(a), the red line for far-right\nnews recovered almost immediately in May 2020 to post-\n2016 levels after this point (z = 0.51before 2016, z= 2.34\nbetween 2016 and February 2020, and z= 2.04from May\n2020 onward). Furthermore, far-right news also remained\npresent across the entirety of Reddit, as shown in Figure 1\n(6.5% of all news on Reddit before 2016, 14.0% between\n2016 and February 2020, and 10.4% after May 2020). Thus,\nsharing of e.g. Breitbart and Fox News returned to hyper par-\ntisan contexts on Reddit almost immediately after the ban-\nning of r/The Donald, as shown in Figure 5(b).\nTo what may the robustness of polarized news sharing beattributed to? Although speculative, we find evidence that\nsharing of far-right news simply shifted from r/The Donald\ntor/Conservative. While news naturally disappeared from\nthe former when it was banned, the percentage of far-right\nnews appearing in the latter jumped from 15% in Febru-\nary 2020 to 39% in May. Furthermore, r/Conservative is\nthe only subreddit that is socially even more right-wing than\nr/The Donald \u2013 it is the uppermost triangle in Figure 2(b).\nThis facilitates the reappearance of far right news in hyper\npartisan contexts in May 2020. Thus, the polarized sharing\nof right-wing news on Reddit, in this case, appears nearly\nunaffected by the deplatforming of r/The Donald. Our find-\nings indicate that more work into causal mechanisms and\ngeneralizability to other interventions is needed to under-\nstand how polarized news consumption on online platforms\nis affected by moderation strategies.\nIn summary, our temporal results illustrate the growing\nco-partisan consumption of traditional news in social con-\ntexts, across the history of the Reddit platform. They also\nsuggest that news-sharing polarization on Reddit began be-\nfore salient events like the 2016 Election, but is skewed\nheavily towards and restricted mostly within hyper-partisan,\nright-wing news publishers and right-wing online commu-\nnities. Despite being narrow, however, this polarization also\nappears deep \u2013 to the extent that the banning of Reddit\u2019s\nlargest far-right community had little long-term effect on the\nsharing of far-right news.\nDiscussion\nTogether, our results paint a picture of polarized news-\nsharing behaviors that are narrow but deep on Reddit. On\nthe one hand, co-partisan patterns of news consumption\noccur largely within the hyper-partisan spaces of the plat-\nform, which accounts only for 10.4% of articles overall, and\nis skewed especially towards right-leaning news publishers\nand social contexts. On the other, the effects of this partisan-\nship are very strong \u2013 to the extent that the entire platform\nappears macroscopically polarized at a bird\u2019s eye view. Fur-\nthermore, polarization of far-right news sources appears to\nhave started much earlier than the 2016 Election, and is fur-\nther only mildly affected by platform moderation.\nOur findings are therefore consistent with claims that\nthe pervasiveness of online echo chambers is over-\nstated (Dubois and Blank 2018; Nelson and Webster 2017;\nBarber \u00b4a et al. 2015; Guess et al. 2018; Cinelli et al. 2021;\nGentzkow and Shapiro 2011; Muise et al. 2022). Nonethe-\nless, our work also suggests that these claims need to be con-\ntextualized by the extreme partisanship in the smaller spaces\nthat are most likely to contain echo chambers. While narra-\ntives positing that online interactions occur largely in echo\nchambers may risk over-regulation, arguments against their\nexistence risk overlooking the subspaces in which they area\nconcern. If fringe news (KhudaBukhsh et al. 2022) and com-\nmunities (Armaly, Buckley, and Enders 2022) can drive tu-\nmultuous events like the January 2021 US Capitol riot, then\nplatform policies may be better informed by the presence\nof narrow and deep echo tunnels on online platforms rather\nthan the absence of a singular, broad echo chamber.\n670\nWhat could potential policies look like? Our results hint at\ntwo concrete opportunities for further investigation. Firstly,\nthe apparent polarization of right-wing news in 2012 indi-\ncates that heterogeneous and heterogeneously early partisan\nactivity on online platforms may contain information about\nthe health of political interactions. Secondly, the seeming\nresistance of polarized news-sharing to Reddit\u2019s largest de-\nplatforming intervention, which itself led to increased rad-\nicalization (Horta Ribeiro et al. 2021), indicates that alter-\nnative ways of moderating the platform need to be explored\nbefore hyper-partisan behaviors become difficult to mitigate.\nBoth suggest paths of research into pro-actively regulating\nplatforms using behavioral news sharing patterns, i.e. from\nwhich sources and to which communities news is shared,\nalongside lingual information (Cheng et al. 2017). Nonethe-\nless, these approaches also need to be balanced against the\nrisk of driving polarized news-sharing to even more extreme\nwebsites (Johnson et al. 2019). Another possibility could\nbe that moderation moves article-level anti-partisan content\naround the platform, such as articles criticizing opposing\npoliticians, while reducing source-level co-partisanship.\nLimitations. As with all studies that observe user behav-\niors online, these findings need to be interpreted with sev-\neral caveats. Firstly, our claims are correlational; much more\nwork remains to understand the mechanisms underpinning,\nfor example, the asymmetric polarization of news between\ndifferent political poles. Furthermore, we intentionally stud-\nied metadata, i.e. from and to where news is shared, allow-\ning us to quantify behavioral polarization. However, more\nresearch is needed to understand how this impacts the rela-\ntionship between article content and readers\u2019 affective po-\nlarization. For instance, although we find news is shared in\nco-partisan communities, the actual news articles may be\nheavily anti-partisan by being antagonistic against opposing\npolitical figures. This could, in turn, drive animosity when\nin-group news readers share articles about and discuss the\npolitical out-group (Rathje, Van Bavel, and van der Linden\n2021; Schmitz, Burghardt, and Muric 2022).\nEthics Statement\nBecause of the political nature of our work, we recognize\nthe need to protect the privacy of users engaged with par-\ntisan content on the platform. We used publicly available,\npseudonymous Reddit data from PushShift, through which\nindividuals may request to delete their Reddit histories at\nany time. In addition, we used additional measures to pro-\ntect user privacy: our study presents only aggregated results,\ndoes not identify nor analyze individual histories, and stored\ndata in a secure server to which only members of our re-\nsearch team had access.\nReferences\nAllcott, H.; Braghieri, L.; Eichmeyer, S.; and Gentzkow, M.\n2020. The welfare effects of social media. American Eco-\nnomic Review, 110(3): 629\u201376.\nAllcott, H.; Gentzkow, M.; and Yu, C. 2019. Trends in the\ndiffusion of misinformation on social media. Research &\nPolitics, 6(2): 2053168019848554.An, J.; Kwak, H.; Posegga, O.; and Jungherr, A. 2019. Polit-\nical discussions in homogeneous and cross-cutting commu-\nnication spaces. In Proceedings of the International AAAI\nConference on Web and Social Media, volume 13, 68\u201379.\nArmaly, M. T.; Buckley, D. T.; and Enders, A. M. 2022.\nChristian nationalism and political violence: victimhood,\nracial identity, conspiracy, and support for the capitol at-\ntacks. Political behavior, 44(2): 937\u2013960.\nBail, C. A.; Argyle, L. P.; Brown, T. W.; Bumpus, J. P.; Chen,\nH.; Hunzaker, M. F.; Lee, J.; Mann, M.; Merhout, F.; and\nV olfovsky, A. 2018. Exposure to opposing views on social\nmedia can increase political polarization. Proceedings of the\nNational Academy of Sciences, 115(37): 9216\u20139221.\nBakshy, E.; Messing, S.; and Adamic, L. A. 2015. Expo-\nsure to ideologically diverse news and opinion on Facebook.\nScience, 348(6239): 1130\u20131132.\nBakshy, E.; Rosenn, I.; Marlow, C.; and Adamic, L. 2012.\nThe role of social networks in information diffusion. In The\nWorld Wide Web Conference.\nBaly, R.; Da San Martino, G.; Glass, J. R.; and Nakov, P.\n2020. We Can Detect Your Bias: Predicting the Political\nIdeology of News Articles. In EMNLP (1).\nBarber \u00b4a, P.; Jost, J. T.; Nagler, J.; Tucker, J. A.; and Bon-\nneau, R. 2015. Tweeting from left to right: Is online political\ncommunication more than an echo chamber? Psychological\nscience, 26(10): 1531\u20131542.\nBoukes, M.; and Vliegenthart, R. 2017. News consumption\nand its unpleasant side effect: Studying the effect of hard and\nsoft news exposure on mental well-being over time. Journal\nof Media Psychology: Theories, Methods, and Applications .\nBoutyline, A.; and Willer, R. 2017. The social structure of\npolitical echo chambers: Variation in ideological homophily\nin online networks. Political psychology, 38(3): 551\u2013569.\nBozarth, L.; Saraf, A.; and Budak, C. 2020. Higher ground?\nHow groundtruth labeling impacts our understanding of fake\nnews about the 2016 US presidential nominees. In Proceed-\nings of the International AAAI Conference on Web and So-\ncial Media, volume 14, 48\u201359.\nBudak, C.; Goel, S.; and Rao, J. M. 2016. Fair and balanced?\nQuantifying media bias through crowdsourced content anal-\nysis. Public Opinion Quarterly, 80(S1): 250\u2013271.\nChandrasekharan, E.; Jhaver, S.; Bruckman, A.; and Gilbert,\nE. 2022. Quarantined! Examining the effects of a\ncommunity-wide moderation intervention on Reddit. ACM\nTransactions on Computer-Human Interaction (TOCHI) ,\n29(4): 1\u201326.\nChandrasekharan, E.; Samory, M.; Jhaver, S.; Charvat, H.;\nBruckman, A.; Lampe, C.; Eisenstein, J.; and Gilbert, E.\n2018. The Internet\u2019s hidden rules: An empirical study of\nReddit norm violations at micro, meso, and macro scales.\nProceedings of the ACM on Human-Computer Interaction ,\n2(CSCW): 1\u201325.\nCheng, J.; Bernstein, M.; Danescu-Niculescu-Mizil, C.; and\nLeskovec, J. 2017. Anyone can become a troll: Causes of\ntrolling behavior in online discussions. In Proceedings of the\n2017 ACM conference on computer supported cooperative\nwork and social computing, 1217\u20131230.\n671\nCinelli, M.; Morales, G. D. F.; Galeazzi, A.; Quattrocioc-\nchi, W.; and Starnini, M. 2021. The echo chamber effect\non social media. Proceedings of the National Academy of\nSciences, 118(9).\nDe Francisci Morales, G.; Monti, C.; and Starnini, M. 2021.\nNo echo in the chambers of political interactions on Reddit.\nScientific Reports, 11(1): 1\u201312.\nDubois, E.; and Blank, G. 2018. The echo chamber is over-\nstated: the moderating effect of political interest and diverse\nmedia. Information, communication & society, 21(5).\nEady, G.; Nagler, J.; Guess, A.; Zilinsky, J.; and Tucker, J. A.\n2019. How many people live in political bubbles on social\nmedia? Evidence from linked survey and Twitter data. Sage\nOpen, 9(1): 2158244019832705.\nEllison, N. B.; Vitak, J.; Gray, R.; and Lampe, C. 2014. Cul-\ntivating social resources on social network sites: Facebook\nrelationship maintenance behaviors and their role in social\ncapital processes. Journal of Computer-Mediated Commu-\nnication, 19(4): 855\u2013870.\nFlaxman, S.; Goel, S.; and Rao, J. M. 2016. Filter bubbles,\necho chambers, and online news consumption. Public opin-\nion quarterly, 80(S1): 298\u2013320.\nFletcher, R.; and Nielsen, R. K. 2018. Are people inciden-\ntally exposed to news on social media? A comparative anal-\nysis. New media & society, 20(7): 2450\u20132468.\nGentzkow, M.; and Shapiro, J. M. 2011. Ideological segrega-\ntion online and offline. The Quarterly Journal of Economics.\nGonz \u00b4alez-Bail \u00b4on, S.; d\u2019Andrea, V .; Freelon, D.; and\nDe Domenico, M. 2022. The advantage of the right in social\nmedia news sharing. PNAS Nexus, 1(3).\nGrinberg, N.; Joseph, K.; Friedland, L.; Swire-Thompson,\nB.; and Lazer, D. 2019. Fake news on Twitter during the\n2016 US presidential election. Science, 363(6425).\nGuess, A.; Nyhan, B.; Lyons, B.; and Reifler, J. 2018. Avoid-\ning the echo chamber about echo chambers. Knight Founda-\ntion.\nGuess, A.; Nyhan, B.; and Reifler, J. 2018. Selective expo-\nsure to misinformation: Evidence from the consumption of\nfake news during the 2016 US presidential campaign. Euro-\npean Research Council, 9(3): 4.\nGuess, A. M.; Nyhan, B.; and Reifler, J. 2020. Exposure\nto untrustworthy websites in the 2016 US election. Nature\nhuman behaviour, 4(5): 472\u2013480.\nHamilton, W. L.; Leskovec, J.; and Jurafsky, D. 2016. Di-\nachronic Word Embeddings Reveal Statistical Laws of Se-\nmantic Change. In Proceedings of the ACL.\nHasell, A.; and Weeks, B. E. 2016. Partisan provocation:\nThe role of partisan news use and emotional responses in\npolitical information sharing in social media. Human Com-\nmunication Research, 42(4): 641\u2013661.\nHorta Ribeiro, M.; Jhaver, S.; Zannettou, S.; Blackburn, J.;\nStringhini, G.; De Cristofaro, E.; and West, R. 2021. Do plat-\nform migrations compromise content moderation? evidence\nfrom r/the donald and r/incels. Proceedings of the ACM on\nHuman-Computer Interaction, 5(CSCW2): 1\u201324.Johnson, N. F.; Leahy, R.; Restrepo, N. J.; Vel \u00b4asquez, N.;\nZheng, M.; Manrique, P.; Devkota, P.; and Wuchty, S. 2019.\nHidden resilience and adaptive dynamics of the global on-\nline hate ecology. Nature, 573(7773): 261\u2013265.\nKhudaBukhsh, A. R.; Sarkar, R.; Kamlet, M. S.; and\nMitchell, T. M. 2022. Fringe news networks: dynamics of\nUS news viewership following the 2020 presidential elec-\ntion. In 14th ACM Web Science Conference 2022, 269\u2013278.\nKonitzer, T.; Allen, J.; Eckman, S.; Howland, B.; Mobius,\nM.; Rothschild, D.; and Watts, D. J. 2021. Comparing esti-\nmates of news consumption from survey and passively col-\nlected behavioral data. Public Opinion Quarterly, 85(S1).\nKumar, S.; Hamilton, W. L.; Leskovec, J.; and Jurafsky, D.\n2018. Community interaction and conflict on the web. In\nThe World Wide Web Conference.\nLevy, O.; and Goldberg, Y . 2014. Dependency-based word\nembeddings. In Proceedings of the 52nd Annual Meeting\nof the Association for Computational Linguistics (Volume 2:\nShort Papers), 302\u2013308.\nMartin, T. 2017. community2vec: Vector representations of\nonline communities encode semantic relationships. In Pro-\nceedings of the Second Workshop on NLP and Computa-\ntional Social Science, 27\u201331.\nMessing, S.; and Westwood, S. J. 2014. Selective expo-\nsure in the age of social media: Endorsements trump partisan\nsource affiliation when selecting news online. Communica-\ntion research, 41(8): 1042\u20131063.\nMoody, J.; and Mucha, P. J. 2013. Portrait of political party\npolarization1. Network Science, 1(1): 119\u2013121.\nMuise, D.; Hosseinmardi, H.; Howland, B.; Mobius, M.;\nRothschild, D.; and Watts, D. J. 2022. Quantifying partisan\nnews diets in Web and TV audiences. Science advances.\nNelson, J. L.; and Webster, J. G. 2017. The myth of partisan\nselective exposure: A portrait of the online political news\naudience. Social media+ society, 3(3).\nPariser, E. 2011. The filter bubble: How the new personal-\nized web is changing what we read and how we think. Pen-\nguin.\nRajadesingan, A.; Resnick, P.; and Budak, C. 2020.\nQuick, community-specific learning: How distinctive toxi-\ncity norms are maintained in political subreddits. In Pro-\nceedings of the International AAAI Conference on Web and\nSocial Media, volume 14, 557\u2013568.\nRao, A.; Morstatter, F.; Hu, M.; Chen, E.; Burghardt, K.;\nFerrara, E.; Lerman, K.; et al. 2021. Political partisan-\nship and antiscience attitudes in online discussions about\nCOVID-19: Twitter content analysis. Journal of Medical\nInternet Research.\nRao, A.; Morstatter, F.; and Lerman, K. 2022. Partisan asym-\nmetries in exposure to misinformation. Scientific Reports,\n12(1): 15671.\nRathje, S.; Van Bavel, J. J.; and van der Linden, S. 2021.\nOut-group animosity drives engagement on social media.\nProceedings of the National Academy of Sciences, 118(26).\nRibeiro, F.; Henrique, L.; Benevenuto, F.; Chakraborty, A.;\nKulshrestha, J.; Babaei, M.; and Gummadi, K. 2018. Media\n672\nbias monitor: Quantifying biases of social media news out-\nlets at large-scale. In Proceedings of the International AAAI\nConference on Web and Social Media, volume 12.\nRobertson, R. E.; Jiang, S.; Joseph, K.; Friedland, L.; Lazer,\nD.; and Wilson, C. 2018. Auditing partisan audience bias\nwithin google search. Proceedings of the ACM on Human-\nComputer Interaction, 2(CSCW): 1\u201322.\nSchmitz, M.; Burghardt, K.; and Muric, G. 2022. Quanti-\nfying How Hateful Communities Radicalize Online Users.\narXiv:2209.08697.\nShearer, E.; and Gottfried, J. 2017. News use across\nsocial media platforms 2017. https://www.pewresearch.\norg/journalism/2017/09/07/news-use-across-social-media-\nplatforms-2017. Accessed: 2023-04-01.\nSinger, P.; Fl \u00a8ock, F.; Meinhart, C.; Zeitfogel, E.; and\nStrohmaier, M. 2014. Evolution of reddit: from the front\npage of the internet to a self-referential community? In The\nWorld Wide Web Conference, 517\u2013522.\nSoliman, A.; Hafer, J.; and Lemmerich, F. 2019. A charac-\nterization of political communities on reddit. In Proceedings\nof the 30th ACM conference on hypertext and Social Media .\nStroud, N. J. 2008. Media use and political predispositions:\nRevisiting the concept of selective exposure. Political Be-\nhavior, 30(3): 341\u2013366.\nSunstein, C. R. 2018. # Republic. Princeton university press.\nV ogels, E. A.; Auxier, B.; and Anderson, M. 2020. Partisan\ndifferences in social media use show up for some platforms,\nbut not Facebook. Pew Research Center, 2\u201319.\nWalker, M.; and Matsa, K. E. 2021. News consumption\nacross social media in 2021. Pew Research Center.\nWaller, I.; and Anderson, A. 2021. Quantifying social orga-\nnization and political polarization in online platforms. Na-\nture, 600(7888): 264\u2013268.\nWeld, G.; Glenski, M.; and Althoff, T. 2021. Political bias\nand factualness in news sharing across more than 100,000\nonline communities. In Proceedings of the International\nAAAI Conference on Web and Social Media, volume 15,\n796\u2013807.\n673", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Echo tunnels: Polarized news sharing online runs narrow but deep", "author": ["L Mok", "M Inzlicht", "A Anderson"], "pub_year": "2023", "venue": "\u2026 of the International AAAI Conference on \u2026", "abstract": "Online social platforms afford users vast digital spaces to share and discuss current events.  However, scholars have concerns both over their role in segregating information exchange"}, "filled": false, "gsrank": 258, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/22177", "author_id": ["Ku0onEIAAAAJ", "z7DDahYAAAAJ", "FMSltawAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:LgJrL2KaIgUJ:scholar.google.com/&output=cite&scirp=257&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D250%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=LgJrL2KaIgUJ&ei=MrWsaIHlAr_SieoPzJnloAQ&json=", "num_citations": 13, "citedby_url": "/scholar?cites=370027865890816558&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:LgJrL2KaIgUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/22177/21956"}}, {"title": "On factuality in neural language models", "year": "2021", "pdf_data": "On Factuality in Neural Language Models\nby\nMoin Nadeem\nSubmitted to the Department of Electrical Engineering and Computer\nScience\nin partial ful\ufb01llment of the requirements for the degree of\nMaster of Engineering in Electrical Engineering and Computer Science\nat the\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nFebruary 2021\n\u00a9 Massachusetts Institute of Technology 2021. All rights reserved.\nAuthor. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nDepartment of Electrical Engineering and Computer Science\nJanuary 15, 2021\nCerti\ufb01ed by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nDr. James Glass\nSenior Research Scientist\nThesis Supervisor\nAccepted by. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nDr. Katrina LaCurts\nChair, Master of Engineering Thesis Committee\n2\nOn Factuality in Neural Language Models\nby\nMoin Nadeem\nSubmitted to the Department of Electrical Engineering and Computer Science\non January 15, 2021, in partial ful\ufb01llment of the\nrequirements for the degree of\nMaster of Engineering in Electrical Engineering and Computer Science\nAbstract\nIn the past several years, language modeling has made signi\ufb01cant advances on arti\ufb01cial\nbenchmarks. However, despite these advancements, language models still face signi\ufb01cant\nissues when deployed in real-world settings. In particular, these models tend to hallucinate\nfacts and demonstrate signi\ufb01cant harmful societal biases that render them impractical in the\nreal-world. This thesis introduces datasets, models, and methodologies for studying how\nlanguage models incorporate world factuality into their decision making processes. First, I\nstudy how neural language models can be used to prove or disprove facts. Motivated by the\nresults, I subsequently study how the choice of training tasks affects the stance detection\nmodel. In order to study the acquisition of harmful knowledge, I build a dataset to probe\nmodels for their societal stereotypes. Finally, I extend this evaluation to a generative setting,\nand study how the choice of sampling algorithm affects model factuality. Taken together, this\nthesis provides a comprehensive analysis of how language models capture world factuality\nvia the pre-training process.\nThesis Supervisor: Dr. James Glass\nTitle: Senior Research Scientist\n3\n4\nAcknowledgments\nFirst and foremost, I would like to thank my advisor, Jim Glass , whose intelligence, wisdom,\nand warmth I will remember long after I have written this thesis. Often, after signi\ufb01cant\nexploration, I found that Jim\u2019s advice was precisely the direction I needed to undertake.\nWhen I have brought research ideas to Jim, he taught me to connect them to real-world\nproblems and helped me simmer down a myriad of ideas into a concrete proposal. Looking\nback, joining Spoken Language Systems was one of the best decisions that I made at MIT.\nI am indebted to my labmates and co-authors: in particular, Mitra Mohtarami, Wei\nFang, Seunghak Yu, and Tianxing He . Mitra and Wei introduced me to the world of\nacademic research, and taught me how to think critically about research ideas. Mitra\npushed me to make time for my research amongst a busy undergraduate semester, and I\u2019m\nsigni\ufb01cantly better off because of her guidance.\nWhen a researcher is starting out, they often lose the forest for the trees. Seunghak\ntaught me to keep an eye on the bigger picture, and helped me realize when the minutiae\ndoesn\u2019t matter. Similarly, when I was stuck, Tianxing always proved to be an invaluable\nasset. Tianxing is one of the most proli\ufb01c researchers that I have met, and has an infectious\nenergy that made our collaborations full of joy. I\u2019d also like to thank DSTA Singapore and\nthe United States Air Force Research Laboratory for sponsoring part of this research; the\nAir Force meetings always provided an external perspective that helped ground my research\nquestions.\nA life in research (where failure is the norm) leads to many \"highs\", but just as many\n\"lows\". I could not have had my research \"highs\" without my professors and labmates,\nbut during my research \"lows\", it was my amazing friends who reminded me that sunny\ndays (metaphorically speaking in Boston) were just around the corner. In particular, I have\nbeen blessed to \ufb01nd true friendship in Ethan Weber andAvery Lamp . College provides a\nunique opportunity to live close to your best friends, and they animated my MIT experience\nwith life and humor.\nWhile I originally joined the Machine Intelligence Community for an intellectual interest,\nI stumbled upon something much more valuable. Nikhil Murthy , who originally was my\n5\nco-president, became a lasting friend worthy of the name. Our conversations never cease\nto \ufb01ll me with delight. Ishani Thakur , a friendship almost by chance encounter, has\ncontinually impressed me with her quick wit and limitless kindness; late-night conversations\nin the Maseeh 5 stairwell have proven to be the most gratifying.\nIn the Muslim Student Association, I am surprised to admit that I had found a family.\nIhssan Tinawi took me in as a freshman, and became a trusted companion with whom I\nbanter every day; I look forward to the many escapades we have in San Fransisco together.\nAli Zartash fueled me to become a better researcher, and can take credit for the motivation\nto complete many of the papers highlighted in this thesis; not only has he shown to be\ngreat counsel, but he never fails to make those around him laugh. Aleena Shabbir was\nthe most unexpected companion of all, but has demonstrated an unwaivering support and\ncommitment to her friends that leave her deserving of the same. I hope I have been as good\nof a friend to her as she has been to me.\nMost importantly, a special thank you goes out to my family. My parents, Basit Nadeem\nandLubna Firdous have been the rock throughout my undergraduate and graduate years,\nand have sacri\ufb01ced far more than I can ever know how to repay. Maria Nadeem has been\nthe sibling I\u2019ve always wanted, and I deeply cherish our time together. I dedicate this thesis\nto them.\n6\nContents\n1 Introduction 15\n1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n1.2 Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n1.3 Related Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n2 Fact-Checking with Neural Language Models 19\n2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.2 FAKTA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.2.1 Document Retrieval & Re-ranking Model . . . . . . . . . . . . . . 21\n2.2.2 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.3 Stance Detection & Evidence Extraction . . . . . . . . . . . . . . . 22\n2.2.4 Linguistic Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.2.5 Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.3 Evaluation and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 The System in Action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.5 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.6 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3 Multi-task learning for Factuality 29\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.2 Multi-task Learning Framework . . . . . . . . . . . . . . . . . . . . . . . 30\n3.2.1 Model Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3.2.2 Unsupervised Pre-training . . . . . . . . . . . . . . . . . . . . . . 31\n7\n3.2.3 Multi-task Supervised Pre-training . . . . . . . . . . . . . . . . . . 32\n3.2.4 Training Procedure and Details . . . . . . . . . . . . . . . . . . . . 32\n3.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3.1 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3.2 Evaluation Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.3.3 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.3.4 Results and Discussion . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.5 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4 Stereotypical Bias in Pretrained Language Models 39\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n4.2 Task Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.2.1 Intrasentence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.2.2 Intersentence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.3.1 Bias in word embeddings . . . . . . . . . . . . . . . . . . . . . . . 43\n4.3.2 Bias in pretrained language models . . . . . . . . . . . . . . . . . 44\n4.3.3 Measuring bias through extrinsic tasks . . . . . . . . . . . . . . . . 44\n4.4 Dataset Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.4.1 Target terms selection . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.4.2 CATs collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.4.3 CATs validation . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.4.4 Dataset analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.5 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n4.5.1 Development and test sets . . . . . . . . . . . . . . . . . . . . . . 48\n4.5.2 Evaluation Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n4.5.3 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.6 Main Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n4.6.1 BERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n8\n4.6.2 R OBERT A. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n4.6.3 XLN ET. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n4.6.4 GPT2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n4.7 Results and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n4.8 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n5 Sampling Algorithms for Language Generation 57\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n5.2 Sampling Algorithms for\nAutoregressive Language Models . . . . . . . . . . . . . . . . . . . . . . . 59\n5.2.1 Autoregressive Language Modeling . . . . . . . . . . . . . . . . . 59\n5.2.2 Existing Sampling Algorithms . . . . . . . . . . . . . . . . . . . . 60\n5.3 Properties of Sampling Algorithms . . . . . . . . . . . . . . . . . . . . . . 61\n5.3.1 Identifying Core Properties . . . . . . . . . . . . . . . . . . . . . . 62\n5.3.2 Designed Sampling Algorithms . . . . . . . . . . . . . . . . . . . 62\n5.4 Experiment Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n5.4.1 Evaluation via the Q-D Trade-off . . . . . . . . . . . . . . . . . . 65\n5.4.2 Model and Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n5.5 Empirical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n5.5.1 Comparison of Existing Algorithms . . . . . . . . . . . . . . . . . 67\n5.5.2 Property-violating Algorithms . . . . . . . . . . . . . . . . . . . . 70\n5.5.3 Property-satisfying Algorithms . . . . . . . . . . . . . . . . . . . . 70\n5.5.4 Qualitative Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 72\n5.6 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.7 Limitations and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . 75\n5.8 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n6 Conclusion 77\n6.1 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n9\nA Supplementary Materials for Sampling Algorithms for Language Generation 81\nA.1 Auxiliary Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nA.2 Proof for Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nA.3 Mechanical Turk Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\nA.4 Convergence of Human Evaluation . . . . . . . . . . . . . . . . . . . . . . 86\nA.5 Additional Model-Generated Samples . . . . . . . . . . . . . . . . . . . . 87\nA.6 Human Evaluation with Self-BLEU as Diversity Metric . . . . . . . . . . . 89\nB Supplementary Materials for Stereotypical Bias in Pretrained Language Mod-\nels 91\nB.1 Data Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\nB.2 Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\nB.2.1 Detailed Results . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\nB.2.2 List of Target Words . . . . . . . . . . . . . . . . . . . . . . . . . 93\nB.2.3 General Methods for Training a Next Sentence Prediction Head . . 93\nB.2.4 Fine-Tuning BERT for Sentiment Analysis . . . . . . . . . . . . . 94\nB.2.5 Reproducibility Checklist . . . . . . . . . . . . . . . . . . . . . . 95\nB.2.6 Collecting Neutral Associations . . . . . . . . . . . . . . . . . . . 95\nB.2.7 Motivating the ICAT score . . . . . . . . . . . . . . . . . . . . . . 96\n10\nList of Figures\n2-1 FAKTA consists of three submodules: a document retrieval model, a neural\nre-ranker, and a stance detection model. . . . . . . . . . . . . . . . . . . . 20\n2-2 A user interface depicting stance detection and linguistic analysis for the\nclaim \u201cISIS in\ufb01litrates the United States.\", with interactive features to\nprovide interpretability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n3-1 Our multi-task learning model consists of a Transformer encoder that takes\nin a claim/paragraph tuple and outputs a similarity score for stance prediction. 30\n4-1 Context Association Tests (CATs) measure both bias and language modeling\nability of language models. . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n5-1 Human evaluation (y-axis: quality, x-axis: diversity, both are the bigger\nthe better) shows that the generation performance of existing sampling\nalgorithms are on par with each other. . . . . . . . . . . . . . . . . . . . . 58\n5-2 The performance (x-axis: quality, y-axis: diversity, both are the smaller the\nbetter) of top- \ud835\udc58, nucleus, tempered and tempered top- \ud835\udc58sampling are on par\non the Gigaword dataset, as shown by automatic evaluation. . . . . . . . . . 68\n5-3 Automatic evaluation of the noised top- \ud835\udc58, target entropy, and random mask\nsampling proposed to validate the necessity of the identi\ufb01ed properties.\nThe results show that violation of entropy reduction and slope preservation\ncould lead to drastic performance degradation, while the order preservation\nproperty could be further relaxed. . . . . . . . . . . . . . . . . . . . . . . 69\n11\n5-4 The proposed random top- \ud835\udc58and max entropy schedulers, which meet the\nidenti\ufb01ed properties, are on par in performance with existing methods in\nautomatic evaluation on the Gigaword dataset. . . . . . . . . . . . . . . . . 72\n5-5 Human evaluation also shows that the proposed sampling algorithms has\nperformance on par with the existing methods on the Gigaword dataset.\nAppendix A.6 repeats this plot with self-BLEU. . . . . . . . . . . . . . . . 73\n5-6 Automatic evaluation on the Wikitext-103 dataset: The performance of\nproposed sampling algorithms are on par with top- \ud835\udc58, nucleus, and tempered\nsampling. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n6-1 Illustrating how Euclidean embeddings cause distortion for hierarchical\nrelationships. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\nA-1 The random mask-all sampling, where \ud835\udc5d1is allowed to be masked, is shown\nto have worse performance than the random mask sampling. The dataset is\nGiagword. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\nA-2 Our instructions for crowdworker task. . . . . . . . . . . . . . . . . . . . . 86\nA-3 An example of the task given to crowdworkers. . . . . . . . . . . . . . . . 86\nA-4 We see that we obtain a reasonable estimate of sample quality around 150\nsamples per con\ufb01guration. . . . . . . . . . . . . . . . . . . . . . . . . . . 87\nA-5 We see that we obtain a reasonable estimate of sample quality with around\n15 ratings per sample. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\nA-6 Using self-BLEU as a diversity metric provides similar conclusions as to\nusing n-gram entropy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\nB-1 The range of the idealized CAT score as a function of the LM score and SS\nscore. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\nB-2 A screenshot of our intrasentence task collection interface. . . . . . . . . . 98\nB-3 A screenshot of our intersentence task collection interface. . . . . . . . . . 104\n12\nList of Tables\n2.1 FEVER Document Retrieval results, which highlight that re-ranking queries\nwith a tuned DFR algorithm can outperform Google Search. . . . . . . . . 25\n2.2 FAKTA full pipeline results on FEVER show that it is dif\ufb01cult to ascertain\ndiscuss labels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n3.1 Results on the FNC test data. TransLinear, TransSAN and MTransSAN\nshow our model where the \ufb01rst two are based on a transformer followed by\na MLP or neural model, and the later further uses multi-task learning. . . . 35\n4.1 Statistics of StereoSet\u2019s dataset show the data distribution between genders,\nprofessions, races, and religions. . . . . . . . . . . . . . . . . . . . . . . . 47\n4.2 Percentage of positive and negative sentiment instances in StereoSet. . . . . 47\n4.3 The frequent keywords that characterize each domain. . . . . . . . . . . . . 48\n4.4 Performance of pretrained language models on the StereoSet test set. . . . . 52\n4.5 Domain-wise results of the ENSEMBLE model, along with most and least\nstereotyped terms per domain. . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.6 Performance on the Intersentence and Intrasentence CATs on the StereoSet\ntest set. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n5.1 Generated sequences with the same pre\ufb01x steven spielberg\u2019s dreamworks\nmovie studio by different sampling algorithms. The hyperparameters are\nchosen such that the algorithms yield roughly the same diversity measured\nby self-BLEU. The poor-quality spans are higlighted in red. . . . . . . . . . 71\n13\nA.1 The samples conditioned on as the rest of his denver broncos teammates ,\nand the hyperparameters for a given sampling algorithm. The poor quality\nspans are higlighted in red. . . . . . . . . . . . . . . . . . . . . . . . . . . 88\nB.1 A collection of neutral associations from crowdworkers. . . . . . . . . . . 96\nB.2 \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61scores of pretrained language models on the StereoSet test set. . . . . . 98\nB.3 Domain-wise \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 scores of the ENSEMBLE model, along with most and\nleast stereotyped terms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\nB.4 \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61scores on the Intersentence and Intrasentence CATs on the StereoSet\ntest set. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nB.5 Performance of pretrained language models on the StereoSet development set. 101\nB.6 The per-domain performance of pretrained language models on the develop-\nment set. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\nB.7 The per-domain performance of pretrained language models on the test set. 103\nB.8 The set of terms that were used to collect StereoSet, ordered by frequency\nin the dataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n14\nChapter 1\nIntroduction\n\u201cThe greatest enemy of knowledge is not ignorance, it is the illusion of\nknowledge.\u201c\n- Stephen Hawking\n1.1 Motivation\nIf one believes that benchmarks are a reasonable measure of progress, then Natural Lan-\nguage Processing (NLP) has exhibited record progress over the past several years. The\nGeneral Language Understanding Evaluation (GLUE) benchmark (Wang et al., 2019b) is a\ncompilation of ten datasets that collectively measure language understanding capabilities.\nWithin a year, the state-of-the-art model improved from a macro-average 60.3 points to 90.6\npoints, notably outperforming the human-level performance of 87.1 points. Afterwards, the\ncommunity introduced the more dif\ufb01cult SuperGLUE benchmark in May 2019 (Wang et al.,\n2019a). For SuperGLUE, models had achieved human-level performance by December\n2020, slightly more than a year after its introduction.\nHowever, despite the signi\ufb01cant increase in accuracy of these systems on arti\ufb01cial\nleaderboards, they still present signi\ufb01cant problems when deployed in real-world settings.\nIn particular, these models exhibit signi\ufb01cant hallucation of facts (Rohrbach et al., 2018)\nand demonstrate signi\ufb01cant harmful societal biases (Nadeem et al., 2020a). Motivated by\n15\nthis gap, this thesis examines how neural language models incorporates world factuality in\ntheir decision making processes. We explore how models can help prove real-world facts\n(Chapter 1), how multi-task learning can improve factuality (Chapter 2), and how large-scale\nlanguage models learn undesirable facts (Chapter 3).\nWhile all of these problems tackle factuality in natural language understanding, there\nare equivalent problems that surround natural language generation, in particular, how can\nwe make generative models factual? We examine how sampling algorithms can impact\ngeneration performance, and thereby factuality, in Chapter 4. Taken together, these chapters\nprovide a multi-faceted analysis of how language models capture knowledge from the\nsurrounding world.\n1.2 Thesis Outline\nEach chapter begins by examining a different approach to incorporating factuality into\nlanguage models, which brings its own set of challenges. Concretely, we organize the\nchapters as follows:\n\u2022Chapter 2 explores how automated fact-checking can be performed with neural\nlanguage models.\n\u2022Chapter 3 considers a multi-task learning approach to improve factual language\nunderstanding.\n\u2022Chapter 4 investigates how biased training procedures may introduce undesirable facts\ninto language models.\n\u2022Chapter 5 examines how sampling algorithms may affect language generation perfor-\nmance, with downstream implications on factual language generation.\n1.3 Related Publications\nPortions of this thesis appears in the following publications:\n16\n\u2022Chapter 2: M Nadeem, W Fang, B Xu, M Mohtarami, J Glass. \"FAKTA: An automatic\nend-to-end fact checking system,\" In Proceedings of NAACL 2019.\n\u2022Chapter 3: W Fang, M Nadeem, M Mohtarami, J Glass. \"Neural multi-task learning\nfor stance prediction,\" In Proceedings of the Second Workshop on Fact Extraction\nand Veri\ufb01cation at EMNLP 2019.\n\u2022Chapter 4: M Nadeem, A Bethke, S Reddy. \"StereoSet: Measuring stereotypical bias\nin pretrained language models,\" Under submission to EACL 2021.\n\u2022Chapter 5: M Nadeem, T He, K Cho, J Glass. \"A Systematic Characterization of\nSampling Algorithms for Open-ended Language Generation,\" In Proceedings of the\nAACL 2020.\n17\nTHIS PAGE INTENTIONALLY LEFT BLANK\n18\nChapter 2\nFact-Checking with Neural Language\nModels\n\u201cFacts are stubborn things; and whatever may be our wishes, our inclina-\ntions, or the dictates of our passion, they cannot alter the state of facts and\nevidence.\u201c\n- John Adams\n2.1 Introduction\nWith the rapid increase of fake news in social media and its negative in\ufb02uence on people\nand public opinion (Mihaylov et al., 2015; Mihaylov and Nakov, 2016; V osoughi et al.,\n2018), various organizations are now performing manual fact checking on suspicious claims.\nHowever, manual fact-checking is a time consuming and challenging process. As an alter-\nnative, researchers are investigating automatic fact checking which is a multi-step process\nand involves: ( i) retrieving potentially relevant documents for a given claim (Mihaylova\net al., 2018; Karadzhov et al., 2017), ( ii) checking the reliability of the media sources from\nwhich documents are retrieved, ( iii) predicting the stance of each document with respect to\nthe claim (Mohtarami et al., 2018a; Xu et al., 2018), and \ufb01nally ( iv) predicting factuality\nThis chapter was based in part on Nadeem et al. (2019).\n19\nFigure 2-1: FAKTA consists of three submodules: a document retrieval model, a neural\nre-ranker, and a stance detection model.\nof given claims (Mihaylova et al., 2018). While previous works separately investigated\nindividual components of the fact checking process, in this work, we present a uni\ufb01ed\nframework titled FAKTA that integrates these components to not only predict the factuality\nof given claims, but also provide evidence at the document and sentence level to explain\nits predictions. To the best of our knowledge, FAKTA is the only system that offers such a\ncapability.\n2.2 FAKTA\nFigure 2-1 illustrates the general architecture of FAKTA. The system is accessible via a Web\nbrowser and has two sides: client and server. When a user at the client side submits a textual\nclaim for fact checking, the server handles the request by \ufb01rst passing it into the document\nretrieval component to retrieve a list of top-K relevant documents (see Section 2.2.1) from\nfour types of sources: Wikipedia, highly-reliable, mixed reliability and low reliability\nmainstream media (see Section 2.2.2). The retrieved documents are passed to the re-ranking\nmodel to re\ufb01ne the retrieval result (see Section 2.2.1). Then, the stance detection component\ndetects the stance/perspective of each relevant document with respect to the claim, typically\nmodeled using labels such as agree ,disagree anddiscuss . This component further provides\nrationales at the sentence level for explaining model predictions (see Section 2.2.3). Each\ndocument is also passed to the linguistic analysis component to analyze the language of the\ndocument using different linguistic lexicons (see Section 2.2.4). Finally, the aggregation\ncomponent combines the predictions of stance detection for all the relevant documents and\n20\nmakes a \ufb01nal decision about the factuality of the claim (see Section 2.2.5). We describe the\ncomponents below.\n2.2.1 Document Retrieval & Re-ranking Model\nWe \ufb01rst convert an input claim to a query by only considering its verbs, nouns and adjec-\ntives Potthast et al. (2013). Furthermore, claims often contain named entities (e.g., names of\npersons and organizations). We use the NLTK package to identify named entities in claims,\nand augment the initial query with all named entities from the claim\u2019s text. Ultimately,\nwe generate queries of 5\u201310tokens, which we execute against a search engine. If the\nsearch engine does not retrieve any results for the query, we iteratively relax the query by\ndropping the \ufb01nal tokens one at a time. We also use Apache Lucene1to index and retrieve\nrelevant documents from the 2017 Wikipedia dump (see our experiments in Section 2.3).\nFurthermore, we use the Google API2to search across three pre-de\ufb01ned lists of media\nsources based on their factuality and reliability as explained in Section 2.2.2. Finally, the\nre-ranking model of Lee et al. (2018) is applied to select the top-K relevant documents. This\nmodel uses all the POS tags in a claim that carry high discriminating power (NN, NNS,\nNNP, NNPS, JJ, CD) as keywords. The re-ranking model is de\ufb01ned as follows:\n\ud835\udc53\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc58=|\ud835\udc5a\ud835\udc4e\ud835\udc61\ud835\udc50\u210e|\n|\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc56\ud835\udc5a|\u00d7|\ud835\udc5a\ud835\udc4e\ud835\udc61\ud835\udc50\u210e|\n|\ud835\udc61\ud835\udc56\ud835\udc61\ud835\udc59\ud835\udc52|\u00d7\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 \ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61, (2.1)\nwhere|\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc56\ud835\udc5a|,|\ud835\udc61\ud835\udc56\ud835\udc61\ud835\udc59\ud835\udc52|, and|\ud835\udc5a\ud835\udc4e\ud835\udc61\ud835\udc50\u210e|are the counts of such POS tags in the claim, title of\na document, both claim and title respectively, and \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 \ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61is the initial ranking score\ncomputed by Lucene or ranking from Google API.\n2.2.2 Sources\nWhile current search engines (e.g., Google, Bing, Yahoo) retrieve relevant documents for\na given query from any media source, we retrieve relevant documents from four types\nof sources: Wikipedia, and high, mixed and low factual media. Journalists often spend\n1https://lucene.apache.org\n2https://developers.google.com/custom-search\n21\nFigure 2-2: A user interface depicting stance detection and linguistic analysis for the claim\n\u201cISIS in\ufb01litrates the United States.\", with interactive features to provide interpretability.\nconsiderable time verifying the reliability of their information sources Popat et al. (2017);\nNguyen et al. (2018), and some fact-checking organizations have been producing lists of\nunreliable online news sources speci\ufb01ed by their journalists. FAKTA utilizes information\nabout news media listed on the Media Bias/Fact Check (MBFC) website3, which contains\nmanual annotations and analysis of the factuality of 2,500news websites. Our list from\nMBFC includes 1,300websites annotated by journalists as high orvery high ,700websites\nannotated as lowandlow-questionable , and 500websites annotated as mixed (i.e., containing\nboth factually true and false information). Our document retrieval component retrieves\ndocuments from these three types of media sources (i.e., high,mixed andlow) along with\nWikipedia that mostly contains factually-true information.\n2.2.3 Stance Detection & Evidence Extraction\nIn this work, we use our best model presented in Xu et al. (2018) for stance detection. To the\nbest of our knowledge, this model is the current state-of-the-art system on the Fake News\nChallenge (FNC) dataset.4Our model combines Bag of Words (BOW) and Convolutional\n3https://mediabiasfactcheck.com\n4http://www.fakenewschallenge.org\n22\nNeural Networks (CNNs) in a two-level hierarchy scheme, where the \ufb01rst level predicts\nwhether the label is related orunrelated (see Figure 2-2, the top-left pie chart in FAKTA),\nand then related documents are passed to the second level to determine their stances, agree ,\ndisagree , and discuss labels (see Figure 2-2, the bottom-left pie chart in FAKTA). Our model\nis further supplemented with an adversarial domain adaptation technique which helps it\novercome the limited size of labeled data when training through different domains.\nTo provide rationales for model prediction, FAKTA further processes each sentence in\nthe document with respect to the claim and computes a stance score for each sentence. The\nrelevant sentences in the document are then highlighted and color coded with respect to\nstance labels (see Figure 2-2). FAKTA provides the option for re-ordering these rationales\naccording to a speci\ufb01c stance label.\n2.2.4 Linguistic Analysis\nWe analyze the language used in documents using the following linguistic markers:\n\u2014Subjectivity lexicon Riloff and Wiebe (2003): which contains weak and strong subjective\nterms (we only consider the strong subjectivity cues),\n\u2014Sentiment cues Liu et al. (2005): which contains positive andnegative sentiment cues, and\n\u2014Wiki-bias lexicon Recasens et al. (2013): which involves bias cues and controversial\nwords (e.g., abortion andexecute ) extracted from the Neutral Point of View Wikipedia\ncorpus Recasens et al. (2013).\nFinally, we compute a score for the document using these cues according to Equa-\ntion equation 2.2, where for each lexicon type \ud835\udc3f\ud835\udc56and document \ud835\udc37\ud835\udc57, the frequency of the\ncues for \ud835\udc3f\ud835\udc56in\ud835\udc37\ud835\udc57is normalized by the total number of words in \ud835\udc37\ud835\udc57:\n\ud835\udc3f\ud835\udc56(\ud835\udc37\ud835\udc57) =\u2211\ufe00\n\ud835\udc50\ud835\udc62\ud835\udc52\u2208\ud835\udc3f\ud835\udc56\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61 (\ud835\udc50\ud835\udc62\ud835\udc52, \ud835\udc37 \ud835\udc57)\n\u2211\ufe00\n\ud835\udc64\ud835\udc58\u2208\ud835\udc37\ud835\udc57\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61 (\ud835\udc64\ud835\udc58, \ud835\udc37\ud835\udc57)(2.2)\nThese scores are shown in a radar chart in Figure 2-2. Furthermore, FAKTA provides\nthe option to see a lexicon-speci\ufb01c word cloud of frequent words in each documents (see\nFigure 2-2, the right side of the radar chart which shows the word cloud of Sentiment cues\nin the document).\n23\n2.2.5 Aggregation\nStance Detection and Linguistic Analysis components are executed in parallel against all\ndocuments retrieved by our document retrieval component from each type of sources. All\nthe stance scores are averaged across these documents, and the aggregated scores are shown\nfor each agree ,disagree anddiscuss categories at the top of the ranked list of retrieved\ndocuments. Higher agree score indicates the claim is factually true, and higher disagree\nscore indicates the claim is factually false.\n2.3 Evaluation and Results\nWe use the Fact Extraction and VERi\ufb01cation (FEVER) dataset (Thorne et al., 2018a) to\nevaluate our system. In FEVER, each claim is assigned to its relevant Wikipedia documents\nwith agree/disagree stances to the claim, and claims are labeled as supported (SUP, i.e.\nfactually true), refuted (REF, i.e. factually false), and not enough information (NEI, i.e.,\nthere is not any relevant document for the claim in Wikipedia). The data includes a total of\n145K claims, with around 80K,30K and 35K SUP, REF and NEI labels respectively.\nDocument Retrieval: Table 2.1 shows results for document retrieval. We use various\nsearch and ranking algorithms that measure the similarity between each input claim as\nquery and Web documents. Lines 1\u201311 in the table show the results when we use Lucene\nto index and search the data corpus with the following retrieval models: BM25 (Robert-\nson et al., 1994) (Line 1), Classic based on the TF.IDF model (Line 2), and Divergence\nfrom Independence (DFI) (Kocaba\u00b8 s et al., 2014) (Line 3). We also use Divergence from\nIndependence Randomness (DFR) (Amati and Van Rijsbergen, 2002) with different term\nfrequency normalization, such as the normalization provided by Dirichlet prior (DFR \ud835\udc3b3)\n(Line 4) or a Zip\ufb01an relation prior (DFR \ud835\udc67) (Line 5). We also consider Information Based\n(IB) models (Clinchant and Gaussier, 2010) with Log-logistic (IB \ud835\udc3f\ud835\udc3f) (Line 6) or Smoothed\npower-law (IB \ud835\udc46\ud835\udc43\ud835\udc3f) (Line 7) distributions. Finally, we consider LMDirichlet (Zhai and\nLafferty, 2001) (Line 8), and LMJelinek (Zhai and Lafferty, 2001) with different settings\nfor its hyperparameter (Lines 9\u201311). According to the resulting performance at different\nranks {1\u201320}, we select the ranking algorithm DFR \ud835\udc67(Lucene \ud835\udc37\ud835\udc39\ud835\udc45 \ud835\udc4d) as our retrieval model.\n24\nModel R@1 R@5 R@10 R@20\n1. BM25 28.84 38.66 62.34 70.10\n2. Classic 9.14 23.10 31.65 40.70\n3. DFI 40.93 66.98 74.84 81.22\n4. DFR H3 43.67 71.18 78.32 83.16\n5. DFR Z 43.14 71.17 78.60 83.88\n6. IB LL 41.86 68.02 75.46 81.13\n7. IB SPL 42.27 69.55 77.03 81.99\n8. LMDirichlet 39.00 68.86 77.39 83.04\n9. LMJelinek 0.0537.39 59.75 67.58 74.15\n10. LMJelinek 0.1037.30 59.85 67.58 74.44\n11. LMJelinek 0.2037.01 59.60 67.60 74.62\nusing Query Generation\n12. Lucene \ud835\udc37\ud835\udc39\ud835\udc45 Z 40.70 68.48 76.21 81.93\n13. Google API 56.62 71.92 73.86 74.89\nusing Re-ranking Model\n14. Lucene \ud835\udc37\ud835\udc39\ud835\udc45 Z 62.37 78.12 80.84 82.11\n15. Google API 57.80 72.10 74.15 74.89\nTable 2.1: FEVER Document Retrieval results, which highlight that re-ranking queries with\na tuned DFR algorithm can outperform Google Search.\nIn addition, Lines 12\u201313 show the results when claims are converted to queries as\nexplained in Section 2.2.1. The results (Lines 5 and 12) show that Lucene performance\ndecreases with query generation. This might be because the resulting queries become more\nabstract than their corresponding claims which may introduce some noise to the intended\nmeaning of claims. However, Lines 14\u201315 show that our re-ranking model, explained in\nSection 2.2.1, can improve both Lucene and Google results.\nFAKTA Full Pipeline: The complete pipeline consists of document retrieval and re-\nranking model (Section 2.2.1), stance detection and rationale extraction5(Section 2.2.3) and\naggregation model (Section 2.2.5). Table 2.2 shows the results for the full pipeline. Lines\n1\u20133 show the results for all three SUP, REF, and NEI labels (3lbl) and Randomly Sampled\n(RS) documents from Wikipedia for the NEI label. We label claims as NEI if the most\nrelevant document retrieved has a retrieval score less than a threshold, which was determined\nby tuning on development data. Line 1 is the multi-layer perceptron (MLP) model presented\nin (Riedel et al., 2017a). Lines 2\u20133 are the results for our system when using Lucene (L)\nand Google API (G) for document retrieval. The results show that our system achieves the\nhighest performance on both F 1(\ud835\udc40\ud835\udc4e\ud835\udc50\ud835\udc5f\ud835\udc5c )and accuracy (Acc) using Google as retrieval engine.\nWe repeat our experiments when considering only SUP and REF labels (2lbl) and the results\n5We used Intel AI\u2019s Distiller (Zmora et al., 2018) to compress the model.\n25\nModel Settings F 1(\ud835\udc46\ud835\udc48\ud835\udc43/\ud835\udc45\ud835\udc38\ud835\udc39/\ud835\udc41\ud835\udc38\ud835\udc3c )F1(\ud835\udc40\ud835\udc4e\ud835\udc50\ud835\udc5f\ud835\udc5c )Acc.\n1. MLP 3lbl/RS - - 40.63\n2. FAKTA L/3lbl/RS 41.33/23.55/44.79 36.56 38.76\n3. FAKTA G/3lbl/RS 47.49/43.01/28.17 39.65 41.21\n4. FAKTA L/2lbl 58.33/57.71/- 58.02 58.03\n5. FAKTA G/2lbl 58.96/59.74/- 59.35 59.35\nTable 2.2: FAKTA full pipeline results on FEVER show that it is dif\ufb01cult to ascertain discuss\nlabels.\nare signi\ufb01cantly higher than the results with 3lbl (Lines 4\u20135).\n2.4 The System in Action\nThe current version of FAKTA6and its short introduction video7and source code8are\navailable online. FAKTA consists of three views:\n\u2014The text entry view : to enter a claim to be checked for factuality.\n\u2014Overall result view : includes four lists of retrieved documents from four factuality types\nof sources: Wikipedia, and high-, mixed-, and low-factuality media (Section 2.2.2). For\neach list, the \ufb01nal factuality score for the input claim is shown at the top of the page\n(Section 2.2.5), and the stance detection score for each document appears beside it.\n\u2014Document result view : when selecting a retrieved document, FAKTA shows the text of\nthe document and highlights its important sentences according to their stance scores with\nrespect to the claim. The stance detection results for the document are further shown as pie\nchart at the left side of the view (Section 2.2.3), and the linguistic analysis is shown at the\nbottom of the view (Section 2.2.4).\n2.5 Related Work\nAutomatic fact checking (Xu et al., 2018) centers on evidence extraction for given claims,\nreliability evaluation of media sources (Baly et al., 2018a), stance detection of documents\nwith respect to claims (Mohtarami et al., 2018a; Xu et al., 2018; Baly et al., 2018b), and fact\n6http://fakta.mit.edu\n7http://fakta.mit.edu/video\n8https://github.com/moinnadeem/fakta\n26\nchecking of claims (Mihaylova et al., 2018). These steps correspond to different Natural\nLanguage Processing (NLP) and Information Retrieval (IR) tasks including information\nextraction and question answering (Shiralkar et al., 2017). Veracity inference has been\nmostly approached as text classi\ufb01cation problem and mainly tackled by developing linguistic,\nstylistic, and semantic features (Rashkin et al., 2017; Mihaylova et al., 2018; Nakov et al.,\n2017), as well as using information from external sources (Mihaylova et al., 2018; Karadzhov\net al., 2017).\nThese steps are typically handled in isolation. For example, previous works (Wang, 2017;\nO\u2019Brien et al., 2018) proposed algorithms to predict factuality of claims by mainly focusing\non only input claims (i.e., step ( iv) and their metadata information (e.g., the speaker of the\nclaim). In addition, recent works on the Fact Extraction and VERi\ufb01cation (FEVER) (Thorne\net al., 2018a) has focused on a speci\ufb01c domain (e.g., Wikipedia).\nTo the best of our knowledge, there is currently no end-to-end systems for fact checking\nwhich can search through Wikipedia and mainstream media sources across the Web to fact\ncheck given claims. To address these gaps, our FAKTA system covers all fact-checking\nsteps and can search across different sources, predict the factuality of claims, and present a\nset of evidence to explain its prediction.\n2.6 Chapter Summary\nThis chapter has presented FAKTA\u2013an online system for automatic end-to-end fact checking\nof claims. FAKTA can assist individuals and professional fact-checkers to check the\nfactuality of claims by presenting relevant documents and rationales as evidence for its\npredictions. In the next chapter, we attempt to improve FAKTA\u2019s stance detection system by\npre-training on multiple tasks.\n27\nTHIS PAGE INTENTIONALLY LEFT BLANK\n28\nChapter 3\nMulti-task learning for Factuality\n3.1 Introduction\nFor journalists and news agencies, fact checking is the task of assessing the veracity of\ninformation and claims. Due to the large volume of claims, automating this process is of\ngreat interest to the journalism and NLP communities. A main component of automated\nfact-checking is stance detection which aims to automatically determine the perspective\n(stance) of given documents with respect to given claims as agree ,disagree ,discuss , or\nunrelated .\nPrevious work (Riedel et al., 2017b; Hanselowski et al., 2018; Baird et al., 2017; Chopra\net al., 2017; Mohtarami et al., 2018b; Xu et al., 2018) presented various neural models\nfor stance prediction, including Chapter 2. One of the challenges for these models is the\nlimited size of human-labeled data, which can adversely affect the resulting performance for\nthis task. To overcome this limitation, we propose to supplement data from other similar\nNatural Language Processing (NLP) tasks. However, this is not a straightforward process\ndue to differences between NLP tasks and data sources. We address this problem using an\neffective multi-task learning approach which shows sizable improvement for the task of\nstance prediction on the Fake News Challenge benchmark dataset. The contributions of this\nchapter are as follows:\nThis chapter was based in part on Fang et al. (2019).\n29\nFigure 3-1: Our multi-task learning model consists of a Transformer encoder that takes in a\nclaim/paragraph tuple and outputs a similarity score for stance prediction.\n\u2022To the best of our knowledge, we are the \ufb01rst to apply multi-task learning to the\nproblem of stance prediction across different NLP tasks and data sources.\n\u2022We present an effective multi-task learning model, and investigate the effectiveness of\ndifferent NLP tasks for stance prediction.\n\u2022Our model outperforms the state-of-the-art baselines on a publicly-available bench-\nmark dataset with a substantial improvement.\n3.2 Multi-task Learning Framework\nWe propose a multi-task learning framework which utilizes the commonalities and differ-\nences across existing NLP datasets and tasks to improve stance prediction performance.\nMore speci\ufb01cally, we use both unsupervised and supervised pre-training on multiple tasks,\nand then \ufb01ne-tune the resulting model on our target stance prediction task.\n30\n3.2.1 Model Architecture\nThe architecture of our model is shown in Figure 3-1. We use a transformer encoder (Vaswani\net al., 2017) that is shared across different tasks to encode the inputs before feeding the\ncontextualized embeddings into task-speci\ufb01c output layers. In what follows, we explain\ndifferent components of our model.\nInput Representation The input sequence \ud835\udc65={\ud835\udc651, . . . , \ud835\udc65 \ud835\udc59}of length \ud835\udc59is either a single\nsentence or multiple texts packed together. The input is \ufb01rst converted to word piece\nsequences (Wu et al., 2016) and, in the case of multiple texts, a special token [SEP] is\ninserted between the tokenized sequences. Another special token [CLS] is inserted at the\nbeginning of the sequence, which corresponds to the representation of the entire sequence.\nTransformer Encoder We use a bidirectional Transformer encoder that takes \ud835\udc65as in-\nput and produces contextual embedding vectors C\u2208R\ud835\udc51\u00d7\ud835\udc59via multiple layers of self-\nattention (Devlin et al., 2019a).\nTask-speci\ufb01c Output Layers For single-sentence classi\ufb01cation tasks, we take the vector\nfrom the \ufb01rst column in C, corresponding to the special token [CLS] , as the semantic\nrepresentation of the input sentence \ud835\udc65. We then feed this vector through a linear layer\nfollowed by softmax to obtain the prediction probabilities.\nFor pairwise classi\ufb01cation tasks, we use the answer module from the stochastic answer\nnetwork (SAN) (Liu et al., 2018) as the output classi\ufb01er. It performs \ud835\udc3e-step reasoning\nover the two pieces of text with bi-linear attention and a recurrent mechanism, producing\noutput predictions at each step and iteratively re\ufb01ning its predictions. At training time,\nsome predictions are randomly discarded (stochastic dropout) before averaging, and during\ninference all output probabilities are utilized.\n3.2.2 Unsupervised Pre-training\nTo utilize large amounts of text data, we use the BERT model which pre-trains the trans-\nformer encoder parameters with two unsupervised learning tasks: masked language model-\n31\ning, for which the model has to predict a randomly masked out word in the sequence, and\nnext sentence prediction, where two sentences are packed and fed into the encoder and the\nembedding corresponding to the [CLS] token is used to predict whether they are adjacent\nsentences (Devlin et al., 2019a).\n3.2.3 Multi-task Supervised Pre-training\nIn addition to learning contextual representations under an unsupervised setting with large\ndata, we investigate whether existing NLP tasks that are conceptually similar to stance\nprediction can improve performance. We introduce four types of such tasks for pre-training:\nTextual Entailment: Given two sentences, a premise and an hypothesis, the model deter-\nmines whether the hypothesis is an entailment ,contradiction , orneutral with respect to the\npremise. Since stance prediction could be cast as a textual entailment task, we investigate if\nthe addition of this task will bene\ufb01t our model.\nParaphrase Detection: Given a pair of sentences, the model should predict whether they\nare semantically equivalent. This task is considered because we may be able to bene\ufb01t from\ndetecting document sentences that are equivalent to claims.\nQuestion Answering: Question answering is similar to the stance prediction task in that\nthe model has to make a prediction given a question and a passage containing several\nsentences.\nSentiment Analysis: Fake claims or articles may exhibit stronger sentiment, thus we\nexplore if pre-training on this task would be bene\ufb01cial.\n3.2.4 Training Procedure and Details\nThere are two stages in our training procedure: multi-task supervised pre-training, and \ufb01ne-\ntuning on stance prediction. Before the training stages, the transformer encoder is initialized\nwith pre-trained parameters to take advantage of knowledge learned from unlabeled data1.\nDuring multi-task pre-training, we randomly pick an ordering on tasks between each\nepoch, and train on 10% of a task\u2019s training data for each task in that order. This process\n1In this work we use the pre-trained BERT weights released by the authors.\n32\nis repeated 10times in each epoch so that all the training examples are trained once. The\nshared encoder is learned over all tasks while each task-speci\ufb01c output layer is learned only\nfor its corresponding task.\nFor \ufb01ne-tuning, the task-speci\ufb01c output layers for pre-training are discarded, and a\nrandomly initialized output layer is added for stance prediction. Then the entire model is\n\ufb01ne-tuned over the training set for stance prediction.\nFor both multi-task pre-training and \ufb01ne-tuning, we train with cross-entropy loss at each\noutput layer. We use the Adam optimizer (Kingma and Ba, 2014) with learning rate of 3\ud835\udc52-5,\n\ud835\udefd1= 0.9,\ud835\udefd2= 0.999, and mini-batch size of 16for10epochs. For the SAN answer module\nwe set \ud835\udc3e= 5and use stochastic dropout rate of 0.1.\n3.3 Experiments\n3.3.1 Data\nThe BERT model was pre-trained on the BooksCorpus (Zhu et al., 2015a) and English\nWikipedia. For multi-task pre-training, we use the following datasets:\nSNLI Stanford Natural Language Inference is the standard entailment classi\ufb01cation task\nthat contains 549K training sentence pairs after removing examples with no gold labels (Bow-\nman et al., 2015). The relation labels are entailment ,contradiction , and neutral .\nMNLI Multi-genre Natural Language Inference is a large-scale entailment classi\ufb01cation\ntask from a diverse set of sources with the same relation classes as SNLI (Williams et al.,\n2018). We use its training set that contains 393K pairs of sentences.\nRTE Recognizing Textual Entailment is a binary entailment task with 2.5K training\nexamples (Wang et al., 2019b).\nQQP Quora Question Pairs2is a QA dataset for binary classi\ufb01cation where the goal is\nto predict whether two questions are semantically equivalent. We use its 364K training\nexamples for pre-training.\nMRPC Microsoft Research Paraphrase Corpus consists of automatically extracted sen-\n2https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs\n33\ntence pairs from new sources, with human annotations for whether the pairs are semantically\nequivalent (Dolan and Brockett, 2005). The training set used for pre-training contains 3.7K\nsentence pairs.\nQNLI Question Natural Language Inference (Wang et al., 2019b) is a QA dataset which\nis derived from the Stanford Question Answering Dataset (Rajpurkar et al., 2016) and used\nfor binary classi\ufb01cation. For a given question-sentence pair, the task is to predict whether\nthe sentence contains the answer to the question. QNLI contains 108K training pairs.\nSST-2 Stanford Sentiment Treebank is used for binary classi\ufb01cation for sentences extracted\nfrom movie reviews (Socher et al., 2013). We use the GLUE version that contains 67K\ntraining sentences (Wang et al., 2019b).\nIMDB The Large Movie Review Dataset contains 50K movie reviews which are catego-\nrized as either positive ornegative in terms of sentiment orientation (Maas et al., 2011).\nFor \ufb01ne-tuning on stance prediction, we use the dataset provided by the Fake News\nChallenge Stage 1(FNC-1 )3, consisting of a total of 75K claim-document pairs collected\nfrom a variety of sources such as rumor sites and social media. The claim-document relation\nclasses are: agree ,disagree ,discuss , and unrelated . The FNC-1 dataset has an imbalanced\ndistribution over stance labels, especially lacking data for agree (7.3%), and disagree (1.7%)\nclasses.\n3.3.2 Evaluation Metrics\nFor evaluation, the standard measures of accuracy andmacro-F1 are used. Additionally,\nas per previous work, weighted accuracy is also reported, which is a two-level scoring\nscheme that gives 0.25weight to predicting examples as related v.s.unrelated correctly, and\nan additional 0.75weight to classifying related examples as agree ,disagree , and discuss\ncorrectly.\n3http://www.fakenewschallenge.org\n34\nModel Auxiliary Data Weigh. Acc. Acc. Macro-F1\n1 Gradient Boosting - 75.2 86.3 46.1\n2 TALOS - 82.0 89.1 57.8\n3 UCL - 81.7 88.5 57.9\n4 Memory Network - 81.2 88.6 56.9\n5 Adversarial Adaptation FEVER 80.3 88.2 60.0\n6 TransLinear - 84.9 89.3 66.3\n7 TransSAN - 85.1 90.3 67.9\nTextual Entailment\n8 MTransSAN SNLI 86.7 91.9 72.3\n9 MTransSAN MNLI 86.4 90.8 71.0\n10 MTransSAN RTE 85.6 90.7 69.3\n11 MTransSAN SNLI, MNLI, RTE 86.1 91.3 71.6\nParaphrase Detection\n12 MTransSAN QQP 87.6 92.1 74.1\n13 MTransSAN MRPC 87.0 92.0 73.5\n14 MTransSAN QQP, MRPC 88.0 92.3 74.4\nQuestion Answering\n15 MTransSAN QNLI 86.5 91.2 71.9\nSentiment Analysis\n16 MTransSAN SST 86.7 91.8 70.0\n17 MTransSAN IMDB 85.6 91.2 70.4\n18 MTransSAN SST, IMDB 86.5 91.7 71.1\nJoint\n19 MTransSAN SNLI, MNLI, QNLI 84.7 90.6 70.1\n20 MTransSAN MNLI, RTE, QQP, MRPC, QNLI, SST 87.0 91.6 71.8\n21 MTransSAN SNLI, MNLI, RTE, QQP, 86.5 91.6 72.1\nMRPC, QNLI, SST, IMDB\nTable 3.1: Results on the FNC test data. TransLinear, TransSAN and MTransSAN show our\nmodel where the \ufb01rst two are based on a transformer followed by a MLP or neural model,\nand the later further uses multi-task learning.\n3.3.3 Baselines\nWe compare our model with existing state-of-the-art stance prediction models including the\ntop-ranked models from FNC-1 and neural models:\nGradient Boosting This baseline4uses a gradient-boosting classi\ufb01er with hand-crafted\nfeatures including \ud835\udc5b-gram features, and indicator features for polarity and refutation.\nTALOS (Baird et al., 2017) An ensemble of gradient-boosted decision trees and a convo-\nlutional neural network.\n4https://github.com/FakeNewsChallenge/fnc-1-baseline\n35\nUCL (Riedel et al., 2017b) A Multi-Layer Perceptron (MLP) with Bag-of-Words and\nsimilarity features extracted from claims and documents.\nMemory Network (Mohtarami et al., 2018b) A feature-light end-to-end memory network\nthat attends over convolutional and recurrent encoders.\nAdversarial Domain Adaptation (Xu et al., 2018) This baseline uses a domain classi\ufb01er\nwith gradient reversal on top of a convolutional network and TF-IDF features to perform\nadversarial domain adaptation from another fact-checking dataset (Thorne et al., 2018b) to\nFNC.\n3.3.4 Results and Discussion\nThe performance of the existing models are shown in Table 3.1 from rows 1\u20135, and our\nmodels (MTransSAN) are in rows 8\u201321. All variants of MTransSAN consistently outperform\nexisting models on all three metrics by a considerable margin. In particular, our best\nMTransSAN (row 14)achieves 6.0and14.4points of absolute improvement in terms\nof weighted accuracy and macro-F1, respectively, over existing state-of-the-art results.\nWe also compare MTransSAN versus a model with the same architecture but without pre-\ntraining on the NLP tasks (TransSAN), shown in row 7, and another version of that model\nwith a linear layer instead of the SAN answer module (TransLinear), shown in row 6. Using\nthe SAN answer module improves over a linear layer for all three metrics, and generally most\nMTransSAN models outperform the TransSAN model. Our best MTransSAN model exceeds\nTransSAN by 3.1and6.5points in weighted accuracy and macro-F1, respectively, justifying\nthe effectiveness of model pre-training with NLU tasks. Note that even the TransLinear\nmodel outperforms previously state-of-the-art models by a wide margin, suggesting that\na neural model pre-trained on large amounts of unlabeled data and \ufb01ne-tuned on stance\nprediction is superior to models that require hand-crafted features.\nAdditionally, we conduct experiments where we use different combinations of language\nunderstanding tasks for pre-training. We pre-train with single tasks, multiple tasks with the\nsame task type, and joint learning across multiple task types. For textual entailment (rows 8\u2013\n11), we see that pre-training on SNLI gives us best improvement, and that pre-training across\n36\nall three entailment tasks did not improve compared to just training on SNLI. However, for\nparaphrase detection (rows 12\u201314) the combination of QQP and MRPC gives us the best\nresults across all MTransSAN models. This suggests that the paraphrase detection might\nbe the most useful task type among the NLP tasks in terms of boosting stance prediction\nperformance. Question answering and sentiment analysis (rows 15\u201318), on the other hand,\ngive lower performance improvements compared to paraphrase detection. Models trained\non joint tasks (rows 19\u201321) do not outperform our best model either.\nOverall, we \ufb01nd that utilizing the BERT model results in large improvements compared\nto the baselines, which is not unexpected given the success of BERT. We also show that\nour multi-task learning approach gives even further improvements upon BERT by a wide\nmargin.\n3.4 Related Work\nStance Prediction. This task is an important component for fact checking and veracity\ninference. To address stance prediction, (Riedel et al., 2017b) used a Multi-Layer Per-\nceptron (MLP) with bag-of-words and similarity features extracted from input documents\nand claims, and (Hanselowski et al., 2018) presented a deep MLP trained using a rich\nfeature representation, based on unigrams, non-negative matrix factorization, latent semantic\nindexing. (Baird et al., 2017) presented an ensemble of gradient-boosted decision trees\nand a deep convolutional neural network, while (Chopra et al., 2017) proposed a model\nbased on bi-directional LSTM and attention mechanism. While, these works utilized a\nrich hand\u2013crafted features, (Mohtarami et al., 2018b, 2019) proposed strong end-to-end\nfeature-light memory networks for stance prediction in mono- and cross-lingual settings.\nRecently, (Xu et al., 2018) presented a state-of-the-art model based on adversarial domain\nadaptation with more labeled data, but they limited their model to only using data from the\nsame stance prediction task. In this work, we remove this limitation and used labeled data\nfrom other tasks that are similar to stance prediction through multi-task learning.\n37\nMulti-task and Transfer Learning. Multi-task and transfer learning have been long-\nstudied problems in machine learning and NLP (Caruana, 1997; Collobert and Weston,\n2008; Pan and Yang, 2010). More recently, numerous methods on unsupervised pre-training\nof deep contextualized models for transfer learning have been proposed (Peters et al., 2018a;\nDevlin et al., 2019a; Yang et al., 2019; Radford et al., 2019a; Dai et al., 2019; Liu et al.,\n2019), and (Conneau et al., 2017; McCann et al., 2017) presented supervised pre-training\nmethods for NLI and translation. Recent work on multi-task learning has focused on\ndesigning effective neural architectures (Hashimoto et al., 2017; S\u00f8gaard and Goldberg,\n2016; Sanh et al., 2018; Ruder et al., 2017). Combining these two lines of work, (Liu\net al., 2019; Clark et al., 2019) explored \ufb01ne-tuning the contextualized models with multiple\nnatural language understanding tasks. In this work, we depart from previous works by\nspeci\ufb01cally studying the effects of multi-task \ufb01ne-tuning for the stance prediction task with\npre-trained models.\n3.5 Chapter Summary\nIn this chapter, we present an effective multi-task learning model that transfers knowledge\nfrom existing NLP tasks to improve stance prediction. Our model outperforms state-of-\nthe-art systems by 6.0 and 14.4 points in weighted accuracy and macro-F1 respectively\non the FNC-1 benchmark dataset. In future, we plan to further investigate our model to\nmore speci\ufb01cally identify and illustrate its source of improvement, improve our transfer\nlearning approach for better \ufb01ne-tuning, and investigate the utility of our model in other\nfact-checking sub-problems such as evidence extraction.\nUntil now, we have studied how we can use language models to extract facts about the\nworld, but these facts may cause harm. The next chapter studies the scenarios where harmful\nfacts are contained in the model, and to what extent these can be quanti\ufb01ed.\n38\nChapter 4\nStereotypical Bias in Pretrained\nLanguage Models\n\u201cWe all see only that which we are trained to see.\u201c\n- Robert Wilson\n4.1 Introduction\nA key idea behind the current success of neural network models for language is pretrained\nrepresentations such as word embeddings (Mikolov et al., 2013; Pennington et al., 2014) and\npretrained language models (Peters et al., 2018b; Howard and Ruder, 2018; Devlin et al.,\n2019b; Radford et al., 2019b; Liu et al., 2019). These are widely used to initialize neural\nmodels, which are then \ufb01ne-tuned to perform a task at hand. Typically, these are learned\nfrom massive text corpora using variants of language modeling objective (i.e., predicting a\nword given its surrounding context). In the recent years, these representations empowered\nneural models to attain unprecedented levels of performance gains on multiple language\ntasks. These models are being deployed as services on platforms like Google Cloud and\nAmazon AWS to serve millions of users.\nWhile this growth is commendable, there are concerns about the fairness of these models.\nThis chapter was based in part on Nadeem et al. (2020a).\n39\nChoose the appropriate word:\nDomain: Gender Target: Girl\nContext: Girls tend to be more ____ than boys\nOption 1: soft (stereotype)\nOption 2: determined (anti-stereotype)\nOption 3: \ufb01sh (meaningless)\n(a) The Intrasentence Context Association Test\nChoose the appropriate sentence:\nDomain: Race Target: Arab\nContext: He is an Arab from the Middle East.\nOption 1: He is probably a terrorist with bombs.\n(stereotype)\nOption 2: He is a paci\ufb01st. (anti-stereotype)\nOption 3: My dog wants a walk. (meaningless)\n(b) The Intersentence Context Association Test\nFigure 4-1: Context Association Tests (CATs) measure both bias and language modeling\nability of language models.\nSince pretrained representations are obtained from learning on massive text corpora, there is\na danger that stereotypical biases in the real world are re\ufb02ected in these models. For example,\nGPT2 (Radford et al., 2019b) has shown to generate unpleasant stereotypical text when\nprompted with context containing certain races such as African-Americans (Sheng et al.,\n2019). In this chapter, we assess the stereotypical biases of popular pretrained language\nmodels. We de\ufb01ne a stereotype to be an over-generalized belief about a particular group of\npeople, e.g., Asians are good at math .\nThe seminal works of Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word\nembeddings such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014)\ncontain stereotypical biases using diagnostic methods like word analogies and association\ntests. For example, Caliskan et al. show that male names are more likely to be associated\nwith career terms than female names where the association is measured using embedding\nsimilarity.\nRecently, studies have attempted to evaluate bias in contextual word embeddings where\na word is provided with arti\ufb01cial context (May et al., 2019; Kurita et al., 2019), e.g., the\n40\ncontextual embedding of man is obtained from the embedding of man in the sentence This\nis a man . However, these have a few limitations. First, the context does not re\ufb02ect the\nnatural usage of a word. Second, they require stereotypical attribute terms to be prede\ufb01ned\n(e.g., pleasant and unpleasant terms). Third, they focus on single word terms and attributes\nand ignore multiword terms like construction worker . Lastly, they study bias of a model\nindependent of its language modeling ability which could lead to misleading trust on a\nmodel even if it is a poor language model.\nIn this chapter, we propose methods to evaluate stereotypical bias of pretrained language\nmodels. These methods do not have the aforementioned limitations. Speci\ufb01cally, we design\ntwo different association tests, one for measuring bias at sentence level ( intrasentence ), and\nthe other at discourse level ( intersentence ) as shown in Figure 4-1.. In these tests, each target\nterm (e.g., Arab) is provided with a natural context in which it appears, along with three\npossible associative contexts. The associative contexts help us to evaluate the biases of the\nmodel, as well as measure its language modeling performance. We crowdsource StereoSet ,\na dataset for associative contexts in English containing 4 target domains, 321 target terms\nand 16,995 test instances (triplets).\n4.2 Task Formulation\nWe design our formulation around the desiderata of an ideal language model. An ideal\nlanguage model should be able to perform the task of language modeling, i.e., it should\nrank meaningful contexts higher than meaningless contexts. For example, it should tell us\nthatOur housekeeper is a Mexican is more probable than Our housekeeper is a banana .\nSecond, it should not exhibit stereotypical bias, i.e., it should avoid ranking stereotypical\ncontexts higher than anti-stereotypical contexts, e.g., Our housekeeper is a Mexican andOur\nhousekeeper is an American should be equally possible. We desire equally possible instead\nof anti-stereotype over stereotype because any kind of overgeneralized belief is known\nto hurt target groups (Czopp et al., 2015). If the model consistently prefers stereotypes\nover anti-stereotypes, we can say that the model exhibits stereotypical bias. An alternative\napproach would be to rank a neutral context higher over stereotypical or anti-stereotypical\n41\ncontext. In practice, we found that collecting neutral contexts are prone to implicit biases\nand has low inter-annotator agreement (Section 4.4).\nBased on these observations, we develop the Context Association Test (CAT), a test\nthat measures the language modeling ability as well as the stereotypical bias of pretrained\nlanguage models. Although language modeling has standard evaluation metrics such as\nperplexity, due to varying vocabulary sizes of different pretrained models, this metric\nbecomes incomparable across models. In order to analyse the relationship between language\nmodeling ability and stereotypical bias, we de\ufb01ne a simple metric that is appropriate for our\ntask. Evaluating the full language modeling ability of models is beyond the scope of this\nwork.\nIn CAT, given a context containing a target group (e.g., housekeeper), we provide\nthree different ways to instantiate this context. Each instantiation corresponds to either\na stereotypical, anti-stereotypical, or a meaningless association. The stereotypical and\nanti-stereotypical associations are used to measure stereotypical bias, and the meaningless\nassociation is used to measure language modeling ability.\nSpeci\ufb01cally, we design two types of association tests, intrasentence and intersentence\nCATs , to assess language modeling and stereotypical bias at sentence level and discourse\nlevel. Figure 4-1 shows an example for each.\n4.2.1 Intrasentence\nOur intrasentence task measures the bias and the language modeling ability at sentence-level.\nWe create a \ufb01ll-in-the-blank style context sentence describing the target group, and a set of\nthree attributes, which correspond to a stereotype, an anti-stereotype, and a meaningless\noption (Figure 4-1a). In order to measure language modeling and stereotypical bias, we\ndetermine which attribute has the greatest likelihood of \ufb01lling the blank, i.e., which of the\ninstantiated contexts is more likely.\n42\n4.2.2 Intersentence\nOur intersentence task measures the bias and the language modeling ability at the discourse-\nlevel. The \ufb01rst sentence contains the target group, and the second sentence contains an\nattribute of the target group. Figure 4-1b shows the intersentence task. We create a\ncontext sentence with a target group that can be succeeded with three attribute sentences\ncorresponding to a stereotype, an anti-stereotype and a meaningless option. We measure the\nbias and language modeling ability based on which attribute sentence is likely to follow the\ncontext sentence.\n4.3 Related Work\nOur work is inspired from related attempts that aim to measure bias in pretrained representa-\ntions such as word embeddings and language models.\n4.3.1 Bias in word embeddings\nThe two popular methods of testing bias in word embeddings are word analogy tests and\nword association tests. In word analogy tests, given two words in a certain syntactic or\nsemantic relation ( man\u2192king), the goal is generate a word that is in similar relation to a\ngiven word ( woman\u2192queen ). Mikolov et al. (2013) showed that word embeddings capture\nsyntactic and semantic word analogies, e.g., gender, morphology etc. Bolukbasi et al. (2016)\nbuild on this observation to study gender bias. They show that word embeddings capture\nseveral undesired gender biases (semantic relations) e.g. doctor :man ::woman :nurse .\nManzini et al. (2019) extend this to show that word embeddings capture several stereotypical\nbiases such as racial and religious biases.\nIn the word embedding association test (WEAT, Caliskan et al. 2017), the association\nof two complementary classes of words, e.g., European and African names, with two other\ncomplementary classes of attributes that indicate bias, e.g., pleasant and unpleasant attributes,\nare studied to quantify the bias. The bias is de\ufb01ned as the difference in the degree with\nwhich European names are associated with pleasant and unpleasant attributes in comparison\n43\nwith African names being associated with those attributes. Here, the association is de\ufb01ned\nas the similarity between the name and attribute word embeddings. This is the \ufb01rst large\nscale study that showed word embeddings exhibit several stereotypical biases and not just\ngender bias. Our inspiration for CAT comes from WEAT.\n4.3.2 Bias in pretrained language models\nMay et al. (2019) extend WEAT to sentence encoders, calling it the Sentence Encoder\nAssociation Test (SEAT). For a target term and its attribute, they create arti\ufb01cial sentences\nusing generic context of the form \"This is [target].\" and \"They are [attribute].\" and obtain\ncontextual word embeddings of the target and the attribute terms. They repeat Caliskan et al.\n(2017)\u2019s study using these embeddings and cosine similarity as the association metric but\ntheir study was inconclusive. Later, Kurita et al. (2019) show that cosine similarity is not\nthe best association metric and de\ufb01ne a new association metric based on the probability of\npredicting an attribute given the target in generic sentential context, e.g., [target] is [mask] ,\nwhere [mask] is the attribute. They show that similar observations of Caliskan et al. (2017)\nare observed on contextual word embeddings too. We also go beyond intrasentence to\npropose intersentence CATs, since language modeling is not limited at sentence level.\n4.3.3 Measuring bias through extrinsic tasks\nAnother method to evaluate bias in pretrained representations is to measure bias on extrinsic\ntasks like coreference resolution (Rudinger et al., 2018; Zhao et al., 2018) and sentiment\nanalysis (Kiritchenko and Mohammad, 2018). This method \ufb01ne-tunes pretrained repre-\nsentations on the target task. The bias in pretrained representations is estimated by the\ntarget task\u2019s performance. However, it is hard to segregate the bias of task-speci\ufb01c training\ndata from the pretrained representations. Our CATs are an intrinsic way to evaluate bias in\npretrained models.\n44\n4.4 Dataset Creation\nIn StereoSet, we select four domains as the target domains of interest for measuring bias:\ngender, profession, race and religion. For each domain, we select terms (e.g., Asian)\nthat represent a social group. For collecting target term contexts and their associative\ncontexts, we employ crowdworkers via Amazon Mechanical Turk.1We restrict ourselves to\ncrowdworkers in USA since stereotypes could change based on the country. Table 4.1 shows\nthe overall statistics of StereoSet. We also provide a full data statement in Appendix B.1\n(Bender and Friedman, 2018).\n4.4.1 Target terms selection\nWe curate diverse set of target terms for the target domains using Wikidata relation triples\n(Vrande \u02c7ci\u00b4c and Kr\u00f6tzsch, 2014). A Wikidata triple is of the form <subject, relation, object >\n(e.g., <Brad Pitt, P106, Actor >). We collect all objects occurring with the relations P106\n(profession), P172 (race), and P140 (religion) as the target terms. We manually \ufb01lter terms\nthat are either infrequent or too \ufb01ne-grained ( assistant producer is merged with producer ).\nWe collect gender terms from Nosek et al. (2002). A list of target terms is available in\nAppendix B.2.2.\n4.4.2 CATs collection\nIn the intrasentence CAT, for each target term, a crowdworker writes attribute terms that\ncorrespond to stereotypical, anti-stereotypical and meaningless associations of the target\nterm. Then, they provide a context sentence containing the target term. The context is a\n\ufb01ll-in-the-blank sentence, where the blank can be \ufb01lled either by the stereotype term or the\nanti-stereotype term but not the meaningless term.\nIn the intersentence CAT, they \ufb01rst provide a sentence containing the target term. Then,\nthey provide three associative sentences corresponding to stereotypical, anti-stereotypical\nand meaningless associations. These associative sentences are such that the stereotypical\n1Screenshots of our Mechanical Turk interface and details about task setup are available in the Ap-\npendix B.1.\n45\nand the anti-stereotypical sentences can follow the target term sentence but the meaningless\nones cannot follow the target term sentence.\nWe also experimented with a variant that asked crowdworkers to provide a neutral\nassociation for the target term, but found that crowdworkers had signi\ufb01cant trouble remaining\nneutral. In the validation step (next section), we found that many of these neutral associations\nare often classi\ufb01ed as stereotype or anti-stereotype by multiple validators. We conjecture\nthat attaining neutrality is hard is due to anchoring bias (Tversky and Kahneman, 1974),\ni.e., stereotypical associations are easy to think and access and could implicitly affect\ncrowdworkers to tilt towards them. Therefore, we discard the notion of neutrality. Some\nexamples are shown in Appendix B.2.6.\n4.4.3 CATs validation\nIn order to ensure that stereotypes re\ufb02ect common views, we validate the data collected in\nthe above step with additional workers. For each context and its associations, we ask \ufb01ve\nvalidators to classify each association into a stereotype, an anti-stereotype or a meaningless\nassociation. We only retain CATs where at least three validators agree on the labels.\nThis \ufb01ltering results in selecting 83% of the CATs, indicating that there is regularity in\nstereotypical views among the workers.\n4.4.4 Dataset analysis\nAre people prone to view stereotypes negatively? To answer this question, we classify\nstereotypes into positive and negative sentiment classes using a two-class sentiment classi\ufb01er\n(details in Appendix B.2.4). As evident in Table 4.2, people do not always associate\nstereotypes with negative associations (e.g., Asians are good at math has positive sentiment).\nHowever, people associate stereotypes with relatively more negative associations than\nanti-stereotypes (41% vs. 33%).\nWe also extract keywords in StereoSet to analyze which words are most commonly\nassociated with the target groups. We de\ufb01ne a keyword as a word that is relatively frequent\nin StereoSet compared to the natural distribution of words (Kilgarriff, 2009; Jakubicek et al.,\n46\nDomain # Target # CATs Avg Len\nTerms (triplets) (# words)\nIntrasentence\nGender 40 1,026 7.98\nProfession 120 3,208 8.30\nRace 149 3,996 7.63\nReligion 12 623 8.18\nTotal 321 8,498 8.02\nIntersentence\nGender 40 996 15.55\nProfession 120 3,269 16.05\nRace 149 3,989 14.98\nReligion 12 604 14.99\nTotal 321 8,497 15.39\nOverall 321 16,995 11.70\nTable 4.1: Statistics of StereoSet\u2019s dataset show the data distribution between genders,\nprofessions, races, and religions.\nPositive Negative\nStereotype 59% 41%\nAnti-Stereotype 67% 33%\nTable 4.2: Percentage of positive and negative sentiment instances in StereoSet.\n2013). Table 4.3 shows the top keywords of each domain. These keywords indicate that\ntarget terms in gender and race are associated with physical attributes such as beautiful ,\nfeminine ,masculine , etc., professional terms are associated with behavioural attributes such\naspushy, greedy, hardwork , etc., and religious terms are associated with belief attributes\nsuch as diety, forgiving, reborn , etc. This falls in line with our expectations and indicates\nthat multiple annotators use similar attributes.\n4.5 Experimental Setup\nIn this section, we describe the data splits, evaluation metrics and the baselines.\n47\nGender\nstepchild masculine bossy ma\nuncare breadwinner immature naggy\nfeminine rowdy possessive manly\npolite studious homemaker burly\nProfession\nnerdy uneducated bossy hardwork\npushy unintelligent studious dumb\nrude snobby greedy sloppy\ndisorganize talkative uptight dishonest\nRace\npoor beautiful uneducated smelly\nsnobby immigrate wartorn rude\nindustrious wealthy dangerous accent\nimpoverish lazy turban scammer\nReligion\ncommandment hinduism savior hijab\njudgmental diety peaceful unholy\nclassist forgiving terrorist reborn\natheist monotheistic coworker devout\nTable 4.3: The frequent keywords that characterize each domain.\n4.5.1 Development and test sets\nWe split StereoSet based on the target terms: 25% of the target terms and their instances for\nthe development set and 75% for the hidden test set. We ensure terms in the development\nset and test set are disjoint. We do not have a training set since this defeats the purpose of\nStereoSet, which is to measure the biases of pretrained language models (and not the models\n\ufb01ne-tuned on StereoSet).\n4.5.2 Evaluation Metrics\nOur desiderata of an ideal language model is that it excels at language modeling while\nnot exhibiting stereotypical biases. In order to determine success at both these goals, we\nevaluate both language modeling and stereotypical bias of a given model. We pose both\nproblems as ranking problems.\nLanguage Modeling Score ( lms)In the language modeling case, given a target term con-\ntext and two possible associations of the context, one meaningful and the other meaningless,\nthe model has to rank the meaningful association higher than meaningless association. The\n48\nmeaningful association corresponds to either the stereotype or the anti-stereotype option.\nWe de\ufb01ne the language modeling score ( \ud835\udc59\ud835\udc5a\ud835\udc60) of a target term as the percentage of\ninstances in which a language model prefers the meaningful over meaningless association.\nWe de\ufb01ne the overall \ud835\udc59\ud835\udc5a\ud835\udc60 of a dataset as the average \ud835\udc59\ud835\udc5a\ud835\udc60 of the target terms in the split.\nThe\ud835\udc59\ud835\udc5a\ud835\udc60 of an ideal language model is 100, i.e., for every target term in a dataset, the model\nalways prefers the meaningful association of the term.\nAs discussed in Section 4.2, the goal of this metric is not to evaluate the full scale\nlanguage modeling ability, but only to provide an reasonable metric that allows comparison\nbetween different models to analyze the relationship between language modeling ability and\nstereotypical bias.\nStereotype Score ( ss)Similarly, we de\ufb01ne the stereotype score ( \ud835\udc60\ud835\udc60) of a target term as\nthe percentage of examples in which a model prefers a stereotypical association over an\nanti-stereotypical association. We de\ufb01ne the overall \ud835\udc60\ud835\udc60of a dataset as the average \ud835\udc60\ud835\udc60of the\ntarget terms in the dataset. The \ud835\udc60\ud835\udc60of an ideal language model is 50, i.e., for every target\nterm, the model prefers neither stereotypical associations nor anti-stereotypical associations.\n4.5.3 Baselines\nIDEAL LM We de\ufb01ne this model as the one that always picks correct associations for a\ngiven target term context. It also picks equal number of stereotypical and anti-stereotypical\nassociations over all the target terms. So the resulting \ud835\udc59\ud835\udc5a\ud835\udc60 and\ud835\udc60\ud835\udc60scores are 100 and 50\nrespectively.\nSTEREOTYPED LM We de\ufb01ne this model as the one that always picks a stereotypical\nassociation over an anti-stereotypical association. So its \ud835\udc60\ud835\udc60is 100 irrespective of its \ud835\udc59\ud835\udc5a\ud835\udc60.\nRANDOM LM We de\ufb01ne this model as the one that picks associations randomly, and\ntherefore its \ud835\udc59\ud835\udc5a\ud835\udc60 and\ud835\udc60\ud835\udc60scores are both 50.\n49\nSENTIMENT LM In Section 4.4.4, we saw that stereotypical instantiations are more\nfrequently associated with negative sentiment than anti-stereotypes. In this baseline, we\nassess if sentiment can be used to detect a stereotypical association. For a given a pair\nof context associations, the model always picks the association with the most negative\nsentiment.\n4.6 Main Experiments\nIn this section, we evaluate popular pretrained models such as BERT (Devlin et al., 2019b),\nROBERT A(Liu et al., 2019), XLN ET(Yang et al., 2019) and GPT2 (Radford et al., 2019b)\non StereoSet.\n4.6.1 BERT\nIn the intrasentence CAT (Figure 4-1a), the goal is to \ufb01ll the blank of a target term\u2019s context\nsentence with an attribute term. This is a natural task for BERT since it is pretrained in a\nsimilar fashion. We use BERT to compute the log probability of an attribute term \ufb01lling the\nblank. If the term consists of multiple subwords, in order to compute a subword\u2019s probability,\nwe unmask all its left subwords, and compute the average log probability over all subwords.\nWe rank a given pair of attribute terms based on these probabilities.\nFor intersentence CAT (Figure 4-1b), the goal is to select a follow-up attribute sentence\ngiven the target term sentence. This is similar to the next sentence prediction (NSP) task of\nBERT . While BERT includes a pre-trained NSP head, the other models do not. In order\nto provide a consistent experimental setup between models, we train a classi\ufb01cation head\nourselves on common data (details in Appendix B.2.3). Resultingly, any differences in\nresults between models will be due to the representational differences of the original models.\nOur NSP classi\ufb01cation head achieves an accuracy of 97.2% using BERT -base, and 97.9%\nusing BERT -large. Finally, given a pair of attribute sentences, we rank them based on the\nprobability of an attribute sentence to follow a target term sentence.\n50\n4.6.2 R OBERT A\nSince ROBERT Ais based off of BERT, the corresponding scoring mechanism remains\nremarkably similar. Similar to BERT , we pretrain a NSP classi\ufb01cation head (details in\nAppendix B.2.3). Our NSP classi\ufb01cation head achieves a 94.6% accuracy with ROBERT A-\nbase, and a 97.1% accuracy with ROBERT A-large on a held-out test set.2We follow the\nsame ranking procedure as BERT for both intrasentence and intersentence CATs.\n4.6.3 XLN ET\nFor the intrasentence CAT, we use the pretrained XLN ETmodel. For the intersentence CAT,\nwe train an NSP head (Appendix B.2.3) which obtains a 93.4% accuracy with XLN ET-base\nand 94.1% accuracy with XLN ET-large.\n4.6.4 GPT2\nUnlike above models, GPT2 is a generative model in an auto-regressive setting. For\nthe intrasentence CAT, we instantiate the blank with an attribute term and compute the\nprobability of the full sentence. Given a pair of associations, we rank each association\nusing this score. For the intersentence CAT, we train a NSP classi\ufb01cation head on the\nmean-pooled representation (Appendix B.2.3). Our NSP classi\ufb01er obtains a 92.5% accuracy\nwith GPT2-small, 94.2% with GPT2-medium, and 96.1% with GPT2-large.\n4.7 Results and Discussion\nTable 4.4 shows the overall results of baselines and models on StereoSet test set (development\nresults are in Appendix B.2.1). The results exhibit similar trends on the development and\ntest sets.\nBaselines vs. Models As seen in Table 4.4, all pretrained models have higher \ud835\udc59\ud835\udc5a\ud835\udc60 values\nthan RANDOM LMindicating that these are better language models as expected. Among\n2For reference, BERT -base obtains an accuracy of 97.8%, and BERT -large obtains an accuracy of 98.5%.\nOur test set consists of 3.5M Wikipedia sentence pairs.\n51\nModel Language Stereotype\nModel Score Score ( \ud835\udc60\ud835\udc60)\n(\ud835\udc59\ud835\udc5a\ud835\udc60)\nTest set\nIDEAL LM 100 50.0\nSTEREOTYPED LM - 100\nRANDOM LM 50.0 50.0\nSENTIMENT LM 65.1 60.8\nBERT-base 86.4 60.4\nBERT-large 86.5 59.3\nROBERT A-base 68.2 50.5\nROBERT A-large 75.8 54.8\nXLN ET-base 67.7 54.1\nXLN ET-large 78.2 54.0\nGPT2 83.6 56.4\nGPT2-medium 85.9 58.2\nGPT2-large 88.3 60.1\nENSEMBLE 90.5 62.5\nTable 4.4: Performance of pretrained language models on the StereoSet test set.\nmodels, GPT2 -large is the best performing language model (88.3) followed by GPT2 -\nmedium (85.9).\nComing to stereotypical bias, all pretrained models demonstrate more stereotypical\nbehavior than RANDOM LM. While GPT2 -large is the most stereotypical model of all\npretrained models (60.1), ROBERT A-base is the least stereotypical model (50.5). SEN-\nTIMENT LM achieves the highest stereotypical score compared to all pretrained models,\nindicating that sentiment can indeed be exploited to detect stereotypical associations. How-\never, its language model performance is worse, which is expected, since sentiment alone\nisn\u2019t suf\ufb01cient to distinguish meaningful and meaningless sentences.\nRelation between lms andss All models exhibit a strong correlation between \ud835\udc59\ud835\udc5a\ud835\udc60and\n\ud835\udc60\ud835\udc60. As the language model becomes stronger, its stereotypical bias ( \ud835\udc60\ud835\udc60) does too. We build\nthe strongest language model, ENSEMBLE , using a linear weighted combination of BERT -\nlarge, GPT2 -medium, and GPT2 -large, which is also found to be the most biased model\n52\nDomain Language Stereotype\nModel Score Score ( \ud835\udc60\ud835\udc60)\n(\ud835\udc59\ud835\udc5a\ud835\udc60)\nGENDER 92.4 63.9\nmother 97.2 77.8\ngrandfather 96.2 52.8\nPROFESSION 88.8 62.6\nsoftware developer 94.0 75.9\nproducer 91.7 53.7\nRACE 91.2 61.8\nAfrican 91.8 74.5\nCrimean 93.3 50.0\nRELIGION 93.5 63.8\nBible 85.0 66.0\nMuslim 94.8 46.6\nTable 4.5: Domain-wise results of the ENSEMBLE model, along with most and least stereo-\ntyped terms per domain.\n(\ud835\udc60\ud835\udc60= 62.5). The correlation between \ud835\udc59\ud835\udc5a\ud835\udc60 and\ud835\udc60\ud835\udc60is unfortunate and perhaps unavoidable\nas long as we rely on the real world distribution of corpora to train language models since\nthese corpora are likely to re\ufb02ect stereotypes (unless carefully selected).\nImpact of model size For a given architecture, all of its pretrained models are trained on\nthe same corpora but with different number of parameters. For example, both BERT -base\nandBERT -large are trained on Wikipedia and BookCorpus (Zhu et al., 2015b) with 110M\nand 340M parameters respectively. As the model size increases, we see that its language\nmodeling ability ( \ud835\udc59\ud835\udc5a\ud835\udc60) increases, and correspondingly its stereotypical score.\nImpact of pretraining corpora BERT ,ROBERT A,XLN ETandGPT2 are trained on\n16GB, 160GB, 158GB and 40GB of text corpora. Surprisingly, the corpora size does not\ncorrelate with either \ud835\udc59\ud835\udc5a\ud835\udc60 or\ud835\udc60\ud835\udc60. This could be due to the differences in architectures and\ncorpora types. A better way to verify this would be to train the same model on increasing\namounts of corpora. Due to lack of computing resources, we leave this work for the\ncommunity. We conjecture that the high performance of GPT2 (high \ud835\udc59\ud835\udc5a\ud835\udc60 and low \ud835\udc60\ud835\udc60) is due\nto the nature of its training data. GPT2 is trained on documents linked from Reddit. Since\n53\nReddit is moderated and has several subreddits related to target terms in StereoSet (e.g.,\nrelationships, religion), GPT2 is likely to be exposed to unbiased contextual associations.\nDomain-wise bias Table 4.5 shows domain-wise results of the ENSEMBLE model on the\ntest set. The model is relatively less biased on race than on others ( \ud835\udc60\ud835\udc60= 61.8). We also\nshow the most and least biased target terms for each domain from the development set. We\nconjecture that the most biased terms are the ones that have well established stereotypes in\nsociety and are also frequent in language. This is the case with mother (attributes: caring,\ncooking), software developer (attributes: geek, nerd), and Africa (attributes: poor, dark).\nThe least biased are the ones that do not have well established stereotypes, for example,\nproducer andCrimean . The outlier to this observation is Muslim which we requires further\ninvestigation.\nIntrasentence vs Intersentence CATs Table 4.6 shows the results of intrasentence and\nintersentence CATs on the test set. Since intersentence tasks has more number of words per\ninstance, we expect intersentence language modeling task to be harder than intrasentence.\nThis is the case with most models (except BERT).\nWhich model to choose? StereoSet motivates a question around how practitioners should\nprefer models for real-world deployment. Just because a model has low stereotypical bias\ndoes not mean it is preferred over others. For example, although RANDOM LMexhibits the\nlowest stereotypical bias ( \ud835\udc60\ud835\udc60= 50) it is the worst language model ( \ud835\udc59\ud835\udc5a\ud835\udc60 = 50). While model\nselection desiderata is often task-speci\ufb01c, we introduce a simple point-estimate called the\nidealized CAT (\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)score for model comparison assuming equal importance to language\nmodeling ability and stereotypical bias. We de\ufb01ne the \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 score as \ud835\udc59\ud835\udc5a\ud835\udc60*\ud835\udc5a\ud835\udc56\ud835\udc5b(\ud835\udc60\ud835\udc60,100\u2212\ud835\udc60\ud835\udc60)\n50\ncentered around the idea that an ideal language model has an \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 score of 100 and a\nstereotyped model has a score of 0. Appendix B.2.7 presents a detailed formulation. Among\nthe models, GPT2 exhibits more unbiased behavior than other models ( \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 score of 73.0 as\nshown in Table B.2 of Appendix B.2.7). This metric is not intended to be used as the sole\ncriteria for model selection. Further research is required in designing better metrics.\n54\n4.8 Chapter Summary\nIn this chapter, we study how language models could learn harmful facts during the training\nprocedure. We develop the Context Association Test (CAT) to measure the stereotypical\nbiases of pretrained language models in contrast with their language modeling ability. We\ncrowdsource StereoSet , a dataset containing 16,995 CATs to test biases in four domains:\ngender, profession, race and religion. We show that current pretrained language models\nexhibit strong stereotypical biases. We also \ufb01nd that language modeling ability correlates\nwith the degree of stereotypical bias. This dependence has to be broken if we are to achieve\nunbiased language models. We hope that StereoSet will spur further research in evaluating\nand mitigating bias in language models.\n55\nModel Language Stereotype\nModel Score Score ( \ud835\udc60\ud835\udc60)\n(\ud835\udc59\ud835\udc5a\ud835\udc60)\nIntrasentence Task\nBERT-base 82.5 57.5\nBERT-large 82.9 57.6\nROBERT A-base 71.9 53.6\nROBERT A-large 72.7 54.4\nXLN ET-base 70.3 53.6\nXLN ET-large 74.0 51.8\nGPT2 91.0 60.4\nGPT2-medium 91.2 62.9\nGPT2-large 91.8 63.9\nENSEMBLE 91.7 63.9\nIntersentence Task\nBERT-base 88.3 61.7\nBERT-large 90.0 60.6\nROBERT A-base 64.4 47.4\nROBERT A-large 78.8 55.2\nXLN ET-base-cased 65.0 54.6\nXLN ET-large-cased 82.5 56.1\nGPT2 76.3 52.3\nGPT2-medium 80.5 53.5\nGPT2-large 84.9 56.1\nENSEMBLE 89.4 60.9\nTable 4.6: Performance on the Intersentence and Intrasentence CATs on the StereoSet test\nset.\n56\nChapter 5\nSampling Algorithms for Language\nGeneration\n\u201cIn God we trust. All others must bring data.\u201c\n- W. Edwards Deming\n5.1 Introduction\nWhile our previous chapters have studied how language models may store facts in their pa-\nrameters, we have not studied how a sampling algorithm may affect generation performance,\nand thereby factuality. In this chapter, we focus on examining the role of the sampling\nalgorithm for such tasks.\nGiven a trained LM, \ufb01nding the best way to generate a sample from it has been an\nimportant challenge for NLG applications. Decoding, i.e., \ufb01nding the most probable output\nsequence from a trained model, is a natural principle for generation. The beam-search\ndecoding algorithm approximately \ufb01nds the most likely sequence by performing breadth-\n\ufb01rst search over a restricted search space. It has achieved success in machine translation,\nsummarization, image captioning, and other sub\ufb01elds.\nHowever, in the task of open-ended language generation (which is the focus of this\nThis chapter was based in part on Nadeem et al. (2020b).\n57\nFigure 5-1: Human evaluation (y-axis: quality, x-axis: diversity, both are the bigger the\nbetter) shows that the generation performance of existing sampling algorithms are on par\nwith each other.\nwork), a signi\ufb01cant degree of diversity is required. For example, conditioned on the prompt\n\u201cThe news says that ... \u201d, the LM is expected to be able to generate a wide range\nof interesting continuations. While the deterministic behavior of decoding algorithms could\ngive high-quality samples, they suffer from a serious lack of diversity.\nThis need for diversity gives rise to a wide adoption of various sampling algorithms.\nNotably, top- \ud835\udc58sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2020),\nand tempered sampling (Caccia et al., 2020) have been used in open-ended generation\n(Radford et al., 2018; Caccia et al., 2020), story generation (Fan et al., 2018), and dialogue\nresponse generation (Zhang et al., 2020b). However, the sampling algorithm and the\nhyperparameter are usually chosen via heuristics, and a comprehensive comparison between\nexisting sampling algorithm is lacking in the literature. More importantly, the underlying\n58\nreasons behind the success of the existing sampling algorithms still remains poorly\nunderstood .\nIn this chapter, we begin by using the quality-diversity (Q-D) trade-off (Caccia et al.,\n2020) to compare the three existing sampling algorithms. For automatic metrics, we use the\nBLEU score for quality and n-gram entropy for diversity. We also correlate these automatic\nmetrics with human judgements. The \ufb01rst observation we draw is that top- \ud835\udc58, nucleus and\ntempered sampling perform on par in the Q-D trade-off, as shown in Figure 5-1. Motivated\nby this result, we extract three key properties by inspecting the transformations de\ufb01ned\nby the sampling algorithms: (1) entropy reduction , (2) order preservation and (3) slope\npreservation . We prove all three properties hold for the three existing sampling algorithms.\nWe then set out to systematically validate the importance of the identi\ufb01ed properties.\nTo do so, we design two sets of new sampling algorithms in which each algorithm either\nviolates one of the identi\ufb01ed properties, or satis\ufb01es all properties. Using the Q-D trade-off,\nwe compare their ef\ufb01cacy against existing algorithms, and \ufb01nd that violating these identi\ufb01ed\nproperties could result in signi\ufb01cant performance degradation. More interestingly, we \ufb01nd\nthat the set of sampling algorithms that satis\ufb01es these properties has generation performance\nthat matches the performance of existing sampling algorithms.\n5.2 Sampling Algorithms for\nAutoregressive Language Models\n5.2.1 Autoregressive Language Modeling\nThe task of autoregressive language modeling is to learn the probability distribution of the\n(\ud835\udc59+1)-th word \ud835\udc4a\ud835\udc59+1in a sentence \ud835\udc4aconditioned on the word history \ud835\udc4a1:\ud835\udc59:= (\ud835\udc4a1, . . . , \ud835\udc4a \ud835\udc59)\nand context \ud835\udc36. Here, we use \ud835\udc4a\ud835\udc56\u2208\ud835\udc49to denote a discrete random variable distributed\nacross a \ufb01xed vocabulary \ud835\udc49. In this work, the vocabulary is constructed on sub-word level\n(Sennrich et al., 2016).\nGiven a training set \ud835\udc37, maximum likelihood estimation (MLE) has been the most popular\nframework to train an autoregressive LM (Mikolov et al., 2010). MLE training minimizes\n59\nthe negative log-likelihood (NLL) objective below:\n\ud835\udc3fMLE=1\n|\ud835\udc37|\u2211\ufe01\n(\ud835\udc4a,\ud835\udc36)\u2208\ud835\udc37\u2212\u03a3\ud835\udc3f\u22121\n\ud835\udc59=0log\ud835\udc43\ud835\udf03(\ud835\udc4a\ud835\udc59+1|\ud835\udc4a1:\ud835\udc59, \ud835\udc36),(5.1)\nwhere \ud835\udf03denotes model parameters, and \ud835\udc43\ud835\udf03(\u00b7|\ud835\udc4a1:\ud835\udc59)denotes the conditional model distri-\nbution of \ud835\udc4a\ud835\udc59+1given a pre\ufb01x \ud835\udc4a1:\ud835\udc59. For simplicity, we assume all sentences are of length\n\ud835\udc3fin the formulations. Since this work focuses on sampling from a given model instead of\ntraining it, in the rest of the paper, we abbreviate \ud835\udc43\ud835\udf03(\u00b7)as\ud835\udc43(\u00b7)for brevity.\n5.2.2 Existing Sampling Algorithms\nGiven a trained LM and a context \ud835\udc36, an ancestral sampling algorithm seeks to generate\na sequence from \ud835\udc43(\ud835\udc4a|\ud835\udc36)by sampling token-by-token from a transformed version of\n\ud835\udc43(\ud835\udc4a\ud835\udc59+1|\ud835\udc4a1..\ud835\udc59, \ud835\udc36). We now review and formulate three popular sampling algorithms: top- \ud835\udc58\n(Fan et al., 2018), nucleus (Holtzman et al., 2020), and tempered (Ackley et al., 1985; Caccia\net al., 2020) sampling.\nWe view these algorithms as different transformations applied to the distribution \ud835\udc43(\ud835\udc4a\ud835\udc59+1|\ud835\udc4a1..\ud835\udc59, \ud835\udc36).\nFirst, we treat the conditional distribution \ud835\udc43(\ud835\udc4a\ud835\udc59+1|\ud835\udc4a1..\ud835\udc59, \ud835\udc36)as asorted vector \ud835\udc5dof length\n|\ud835\udc49|. By sorting, we rearrange the elements such that if \ud835\udc56 < \ud835\udc57\u2192\ud835\udc5d\ud835\udc56>=\ud835\udc5d\ud835\udc57.1We list the\ntransformations and their intuition below:\nDe\ufb01nition 5.2.1. (Top-\ud835\udc58) In top- \ud835\udc58sampling, we only sample from the top \ud835\udc3etokens:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\ud835\udc56\u00b7 1{\ud835\udc56\u2264\ud835\udc3e}\u2211\ufe00\ud835\udc3e\n\ud835\udc57=1\ud835\udc5d\ud835\udc57, (5.2)\nwhere 1is the indicator function, and \ud835\udc3e(1\u2264\ud835\udc3e\u2264|\ud835\udc49|) is the hyperparameter.\nDe\ufb01nition 5.2.2. (Nucleus ) With a hyperparameter \ud835\udc43(0< \ud835\udc43\u22641), in nucleus sampling,\nwe sample from the top- \ud835\udc43mass of \ud835\udc5d:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\u2032\n\ud835\udc56\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1\ud835\udc5d\u2032\n\ud835\udc57, (5.3)\n1The token indexes are also permutated accordingly.\n60\nwhere \ud835\udc5d\u2032\n\ud835\udc56=\ud835\udc5d\ud835\udc56\u00b7 1{\u2211\ufe00\ud835\udc56\u22121\n\ud835\udc57=1\ud835\udc5d\ud835\udc57< \ud835\udc43}.\nDe\ufb01nition 5.2.3. (Tempered ) In tempered sampling, the log probabilities are scaled by1\n\ud835\udc47:\n^\ud835\udc5d\ud835\udc56=exp(log( \ud835\udc5d\ud835\udc56)/\ud835\udc47)\n\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1exp(log( \ud835\udc5d\ud835\udc57)/\ud835\udc47). (5.4)\nIn this work, we assume 0< \ud835\udc47 < 1, i.e., the distribution is only made sharper2.\nWe additionally experiment with a combined version of top- \ud835\udc58and tempered sampling:\nDe\ufb01nition 5.2.4. (Tempered Top- \ud835\udc58) We combine the transformation de\ufb01ned by top- \ud835\udc58and\ntempered sampling:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\u2032\n\ud835\udc56\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1\ud835\udc5d\u2032\n\ud835\udc57, (5.5)\nwhere \ud835\udc5d\u2032\n\ud835\udc56= exp(log( \ud835\udc5d\ud835\udc56)/\ud835\udc47)\u00b7 1{\ud835\udc56\u2264\ud835\udc3e}. We set 1\u2264\ud835\udc3e\u2264|\ud835\udc49|and0< \ud835\udc47 < 1.\nThroughout this work we use ^\ud835\udc5dto denote the normalized version of the transformed\ndistribution. All algorithms have hyperparameters to control the entropy of the transformed\ndistribution. For example, \ud835\udc3ein top- \ud835\udc58sampling controls the size of the support of the\nresulting distribution. We will formalize this statement in Property 1 below.\n5.3 Properties of Sampling Algorithms\nAs we will show in Section 5.5.1 (also Figure 5-1), top- \ud835\udc58, nucleus and tempered sampling\nperform on par with each other under our evaluation. This key observation makes us\nquestion: What are the core principles underlying the different algorithms that lead to their\nsimilar performance?\nTo answer this question, in this section, we identify three core properties that are provably\nshared by the existing sampling algorithms. We then design experiments to validate their\nimportance.\n2One could also use \ud835\udc47 >1, but it does not work well in practice.\n61\n5.3.1 Identifying Core Properties\nBy inspecting the transformations listed in De\ufb01nition 5.2.1, 5.2.2 and 5.2.3, we extract the\nfollowing three properties:\nProperty 1. (Entropy Reduction) : The transformation strictly decrease the entropy of the\ndistribution. Formally, \u210b(^\ud835\udc5d)<\u210b(\ud835\udc5d), where\u210b(\ud835\udc5d) =\u2212\u2211\ufe00|\ud835\udc49|\n\ud835\udc56=1\ud835\udc5d\ud835\udc56log\ud835\udc5d\ud835\udc56.\nProperty 2. (Order Preservation) : The order of the elements in the distribution is pre-\nserved. Formally, \ud835\udc5d\ud835\udc56\u2265\ud835\udc5d\ud835\udc57\u2192^\ud835\udc5d\ud835\udc56\u2265^\ud835\udc5d\ud835\udc57.\nProperty 3. (Slope Preservation) : The \u201cslope\u201d of the distribution is preserved. Formally,\n\u2200^\ud835\udc5d\ud835\udc56>^\ud835\udc5d\ud835\udc57>^\ud835\udc5d\ud835\udc58>0(i.e., they are not truncated), we havelog\ud835\udc5d\ud835\udc56\u2212log\ud835\udc5d\ud835\udc57\nlog\ud835\udc5d\ud835\udc57\u2212log\ud835\udc5d\ud835\udc58=log ^\ud835\udc5d\ud835\udc56\u2212log ^\ud835\udc5d\ud835\udc57\nlog ^\ud835\udc5d\ud835\udc57\u2212log ^\ud835\udc5d\ud835\udc58.\nThe order preservation property implies that truncation can only happen in the tail of the\ndistribution, which aligns with top- \ud835\udc58and nucleus sampling. The slope preservation property\nis stronger than the order preservation property in that not only the ordering, but also the\nrelative magnitude of the elements in the distribution needs to be somewhat preserved by\nthe transformation.\nAll these three properties are shared by the three existing sampling algorithms:\nProposition 1. Property 1, 2 and 3 hold for the top- \ud835\udc58, nucleus and tempered sampling\ntransformations formulated in De\ufb01nitions 5.2.1, 5.2.2 and 5.2.3.\nProof. See Appendix A.2.\nWe then set out to validate the importance of these identi\ufb01ed properties in the aspects of\nnecessity andsuf\ufb01ciency . To do so, we design two sets of new sampling algorithms in which\neach algorithm either violates one of the identi\ufb01ed properties, or satis\ufb01es all properties. We\nlist them in the next section.\n5.3.2 Designed Sampling Algorithms\nProperty-violating algorithms To validate the necessity of each property, we design\nseveral sampling algorithms which violate at least one of the identi\ufb01ed properties . In\n62\nour experiments, we check whether that violation leads to a signi\ufb01cant degradation in\nperformance. We list them below:\nDe\ufb01nition 5.3.1. (Target Entropy) Based on tempered sampling, target entropy sampling\ntunes the temperature \ud835\udc61such that the transformed distribution has entropy value equal to the\nhyperparameter \ud835\udc38(0< \ud835\udc38\u2264log|\ud835\udc49|). We formulate it below:\n^\ud835\udc5d\ud835\udc56=exp(log( \ud835\udc5d\ud835\udc56)/\ud835\udc61)\n\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1exp(log( \ud835\udc5d\ud835\udc57)/\ud835\udc61), (5.6)\nwhere \ud835\udc61is selected such that \ud835\udc3b(^\ud835\udc5d) =\ud835\udc38.\nTarget entropy sampling violates entropy reduction, because when \ud835\udc3b(\ud835\udc5d)< \ud835\udc38 , the\nentropy will be tuned up (i.e., \ud835\udc3b(^\ud835\udc5d)> \ud835\udc3b(\ud835\udc5d)).\nDe\ufb01nition 5.3.2. (Random Mask) In random mask sampling, we randomly mask out\ntokens in the distribution with rate \ud835\udc45. We formluate it below:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\u2032\n\ud835\udc56\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1\ud835\udc5d\u2032\n\ud835\udc57, (5.7)\nwhere \ud835\udc5d\u2032\n\ud835\udc56=\ud835\udc5d\ud835\udc56\u00b7 1{\ud835\udc56= 1or\ud835\udc62\ud835\udc56> \ud835\udc45}and\ud835\udc62\ud835\udc56\u223c\ud835\udc48(0,1). The hyperparameter \ud835\udc45(0< \ud835\udc45\u22641)\ncontrols the size of the support of the resulting distribution. In Appendix A.1, we show it is\ncrucial that the token which is assigned the largest probability ( \ud835\udc5d1) is never be masked.\nRandom mask sampling is different from top- \ud835\udc58or nucleus sampling in that the masking\nnot only happens in the tail of the distribution. Therefore, it violates the order preservation\nproperty.\nDe\ufb01nition 5.3.3. (Noised Top- \ud835\udc58) We add a sorted noise distribution to the result from top-\n\ud835\udc3etransformation, and the weight of the noise distribution is controlled by a hyperparameter\n\ud835\udc4a(0\u2264\ud835\udc4a\u22641). We formulate it below:\n^\ud835\udc5d= (1\u2212\ud835\udc4a)^\ud835\udc5dtop-K+\ud835\udc4a\ud835\udc5dnoise-K, (5.8)\nwhere \ud835\udc5dnoise-Kis a uniformly sampled sorted K-simplex , which satis\ufb01es\u2211\ufe00\ud835\udc3e\n\ud835\udc56=1\ud835\udc5dnoise-K\n\ud835\udc56 = 1\nand\ud835\udc56 < \ud835\udc57\u2192\ud835\udc5dnoise-K\n\ud835\udc56\u2265\ud835\udc5dnoise-K\n\ud835\udc57\u22650.\n63\nThe sorted nature of the noise distribution \ud835\udc5dnoise-Kmaintains order preservation. However,\nit violates slope preservation, and the noise weight \ud835\udc4acontrols the degree of the violation.\nProperty-satisfying algorithms To validate the suf\ufb01ciency of the identi\ufb01ed properties,\nwe design two new sampling algorithms for which all three properties hold . And in our\nexperiments we check whether their performance is on par with the existing sampling\nalgorithms. We list them below:\nDe\ufb01nition 5.3.4. (Random Top- \ud835\udc58) We design a randomized version of top- \ud835\udc58sampling: At\neach time step, we sample a uniformly random \ufb02oat number \ud835\udc62\u223c\ud835\udc48(0,1), and use it to\nspecify a top- \ud835\udc58truncation:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\ud835\udc56\u00b7 1{\ud835\udc56\u2264\ud835\udc58}\u2211\ufe00\ud835\udc58\n\ud835\udc57=1\ud835\udc5d\ud835\udc57, (5.9)\nwhere \ud835\udc58=\u230a1 +\ud835\udc40\u00b7\ud835\udc62\u230b. The hyperparameter \ud835\udc40(1\u2264\ud835\udc40 <|\ud835\udc49|) controls the maximum\ntruncation threshold.\nDe\ufb01nition 5.3.5. (Max Entropy ) Max entropy sampling is similar to target entropy sam-\npling (De\ufb01nition 5.3.1). However to match entropy reduction (Property 1), we only tune the\ntemperature when\u210b(\ud835\udc5d)> \ud835\udc38, where \ud835\udc38is the hyperparameter ( 0< \ud835\udc38\u2264log|\ud835\udc49|):\n^\ud835\udc5d\ud835\udc56=\u23a7\n\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23a9exp(log( \ud835\udc5d\ud835\udc56)/\ud835\udc61)\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1exp(log( \ud835\udc5d\ud835\udc57)/\ud835\udc61),if\u210b(\ud835\udc5d)> \ud835\udc38\n\ud835\udc5d\ud835\udc56, otherwise, (5.10)\nwhere \ud835\udc61is selected so that\u210b(^\ud835\udc5d) =\ud835\udc38.\nIt is easy to prove that Property 1, 2, and 3 holds for the transformations de\ufb01ned by\nrandom top- \ud835\udc58and max entropy sampling, and we omit the proof for brevity.\n5.4 Experiment Setup\nIn this section, we \ufb01rst establish evaluation protocols, and then describe the model and data\nwe use for the open-ended language generation task.\n64\n5.4.1 Evaluation via the Q-D Trade-off\nHow to ef\ufb01ciently measure the generation performance of a NLG model has been an\nimportant open question. Most existing metrics either measure the quality aspect (e.g.\nBLEU score) or the diversity (e.g. n-gram entropy) aspect. To make the situation more\ncomplicated, each sampling algorithm has its own hyperparameters which controls the\ntrade-off between quality and diversity.\nTo address the challenges above, we adopt the quality-diversity trade-off proposed by\nCaccia et al. (2020). In the Q-D trade-off, we perform a \ufb01ne-grained sweep of hyperpa-\nrameters for each sampling algorithm, and compute the quality and diversity score for each\ncon\ufb01guration. We report two pairs of Q/D metrics, with one pair using automatic evaluation\nand the other using human evaluation. In the next two sections, we describe the metrics we\nuse, and refer readers to Caccia et al. (2020) for more intuition behind the Q-D trade-off.\nAutomatic Evaluation\nFor automatic metrics, we adopt the corpus-BLEU (Yu et al., 2016) metric to measure\nquality and the self-BLEU (Zhu et al., 2018) metric to measure diversity. We formulate\nthem below.\nGiven a batch of generated sentences \ud835\udc46genand a batch of sentences from ground-truth\ndata as references \ud835\udc46ref, corpus-BLEU returns the average BLEU score (Papineni et al., 2002)\nof every model generated sentence against the reference set:\ncorpus-BLEU (\ud835\udc46gen, \ud835\udc46ref) =1\n|\ud835\udc46gen|\u2211\ufe01\n\ud835\udc4a\u2208\ud835\udc46genBLEU (\ud835\udc4a, \ud835\udc46 ref).(5.11)\nA higher corpus-BLEU score means that the generated sequences has better quality in that it\nhas higher ngram-level overlap with the reference data. Based on the same intuition, we\nde\ufb01ne the self-BLEU metric to quantify the diversity aspect:\nself-BLEU (\ud835\udc46gen) =corpus-BLEU (\ud835\udc46gen, \ud835\udc46gen), (5.12)\nwhere a lower self-BLEU score means that the samples have better diversity.\nIn our experiments, we feed the \ufb01rst ten subwords of every sample from test set to\nthe model, and compare the model-generated sequences to the reference samples in the\n65\nvalidation set. We use 10,000 samples to compute corpus-BLEU or self-BLEU, i.e., |\ud835\udc46gen|=\n|\ud835\udc46ref|= 10,000.\nAutomatic evaluation enables us to do a \ufb01ne-grained sweep of the hyperparameters for\neach sampling algorithm, and compare them in the quality-diversity trade-off. However,\nobservations from automatic evaluation could be misaligned with human evaluation (Belz\nand Reiter, 2006). Therefore, we con\ufb01rm our key observations with human evaluation.\nHuman Evaluation\nQuality We ask a pool of 602 crowdworkers on Amazon Mechanical Turk to evaluate\nvarious sampling con\ufb01gurations in the quality aspect. Each worker is presented a set of\nten samples along with the prompts (pre\ufb01xes). They are then asked to rate how likely the\nsentence would appear in a news article between 0 and 5 (Invalid, Confusing, Unspeci\ufb01c,\nAverage, Expected, and Very Expected respectively).\nWe focus on the Gigaword dataset for human evaluation since news articles are ubiqui-\ntous and do not often require expert knowledge for quality judgement. For each con\ufb01guration\n(sampling algorithm and hyperparameter pair) we ask crowdworkers to rate 200 samples in\ntotal. To get an accurate rating for each sample, we enlist 25 different crowdworkers to rate\neach sample. We report mean and standard deviation from 5 independent runs (each with 40\nsamples) as error bar.\nBy manual inspection, we \ufb01nd that the time spent in the annotations is a good indicator\nof the quality of the rating. Therefore, we estimate the human judgement score for a sample\nas the average rating of the 20 crowdworkers (out of 25) who took the most time to rate the\nsamples. We provide further details about our setup in Appendix A.3 and A.4.\nDiversity It is dif\ufb01cult for human annotators to estimate diversity of text Hashimoto et al.\n(2019). Therefore, we use the n-gram entropy metric (Zhang et al., 2018; He and Glass,\n2019) . Given \ud835\udc46genwhich contains a large number of samples, we measure its diversity using\nthe following formulation:\n\u210b\ud835\udc5b-gram(\ud835\udc46gen) =\u2211\ufe01\n\ud835\udc54\u2208\ud835\udc3a\ud835\udc5b\u2212\ud835\udc5f(\ud835\udc54) log\ud835\udc5f(\ud835\udc54), (5.13)\n66\nwhere \ud835\udc3a\ud835\udc5bis the set of all n-grams that appeared in \ud835\udc46gen, and \ud835\udc5f(\ud835\udc54)refers to the ratio (fre-\nquency) of n-gram \ud835\udc54w.r.t. all n-grams in the \ud835\udc46gen. For the estimation of n-gram entropy, we\ngenerate 50,000 samples from each sampling con\ufb01guration.\nWe will report human quality score either paired with n-gram entropy or with self-BLEU\nas diversity metric. We \ufb01nd they give similar observations.\n5.4.2 Model and Datasets\nWe separately \ufb01ne-tune GPT2-small Radford et al. (2018); Wolf et al. (2019) (110M\nparameters) on the Gigaword (Graff et al., 2003; Napoles et al., 2012) and the Wikitext-103\n(Merity et al., 2017) datasets. We use the same tokenization as GPT-2, and add additional\npadding and end-of-sequence tokens ( [EOS] ) to the sentences.\nTo generate a sequence, we feed a length-10 pre\ufb01x from test data into the \ufb01ne-tuned\nGPT-2 model, and use a sampling algorithm to complete the sentence. Since shorter samples\nare more dif\ufb01cult to judge in quality (Ippolito et al., 2020), we \ufb01lter all generated sentence\ncompletions to be between 40 and 50 subwords, and \ufb01lter our validation and test set to meet\nthe same requirements. To permit validation and test sets that are large enough to pre\ufb01x\n10,000 sentences for the corpus-BLEU metric, we re-chunk the \ufb01rst 80% of the Gigaword\ndataset for the training set, 15% for validation, and the last 5% for the test set. Similarly, we\nre-chunk the \ufb01rst 97% of the Wikitext-103 dataset for training, and leave 1.5% for validation\nand 1.5% for test.\n5.5 Empirical Results\nFirst, we compare existing sampling algorithms, and then move on to validate the necessity\nand suf\ufb01ciency of the identi\ufb01ed properties.\n5.5.1 Comparison of Existing Algorithms\nWe compare top- \ud835\udc58, nucleus, and tempered sampling via automatic and human evaluation. We\ndo a \ufb01ne-grained sweep of hyperparameters for each sampling algorithm on the Gigaword\n67\nFigure 5-2: The performance (x-axis: quality, y-axis: diversity, both are the smaller the\nbetter) of top- \ud835\udc58, nucleus, tempered and tempered top- \ud835\udc58sampling are on par on the Gigaword\ndataset, as shown by automatic evaluation.\n68\nFigure 5-3: Automatic evaluation of the noised top- \ud835\udc58, target entropy, and random mask\nsampling proposed to validate the necessity of the identi\ufb01ed properties. The results show\nthat violation of entropy reduction and slope preservation could lead to drastic performance\ndegradation, while the order preservation property could be further relaxed.\ndataset. The results are shown in Figure 5-1 (human evaluation) and Figure 5-2 (automatic\nevaluation). We also show the quality and diversity score for human text in the test data for\nreference, which is labeled as gold.\nBoth automatic and human evaluations demonstrate that the performance of top- \ud835\udc58,\nnucleus and tempered sampling are on par with each other, with no signi\ufb01cant gap. When\nthe hyperparameters ( \ud835\udc3e,\ud835\udc43and\ud835\udc47) are tuned so that different sampling has the same diversity\n(measured by self-BLEU or n-gram entropy), their quality (measured by corpus-BLEU or\nhuman rating) are close.\nAdditionally, we compare tempered top- \ud835\udc58sampling with the existing algorithm also in\nFigure 5-2. We \ufb01nd that adding the tempered transformation only moves top- \ud835\udc58sampling\nalong the Q-D trade-off, instead of yielding a better or a worse sampling algorithm. For\nexample, the performance of the \ud835\udc3e= 500 , \ud835\udc47= 0.8con\ufb01guration for tempered top- \ud835\udc58\nsampling is very close to the \ud835\udc3e= 30 con\ufb01guration for the top- \ud835\udc58sampling.\n69\nMotivated by these observations, we identify three core properties (elaborated in Section\n5.3.1) that are shared among the sampling algorithms: entropy reduction ,order preservation\nandslope preservation . In the following two sections, we present experiments validating the\nnecessity or suf\ufb01ciency aspect of the properties.\n5.5.2 Property-violating Algorithms\nIn Figure 5-3, we compare the generation performance of the property-violating sampling\nalgorithms (designed in Section 5.3.2), against the existing algorithms using automatic\nevaluation on the Gigaword dataset. We make the following observations: First, the target\nentropy sampling, which violates entropy reduction, has signi\ufb01cantly worse performance;\nSecond, even with small noise weight \ud835\udc4a, the performance of noised top- \ud835\udc58sampling degrades\nfrom the original top- \ud835\udc58sampling, and the gap becomes larger as \ud835\udc4aincreases; Last, the\nrandom mask sampling is on par with the existing sampling algorithms in performance. We\nfurther con\ufb01rm this observation with human evaluation in Figure 5-5.\nThese results suggest that the violation of entropy reduction or slope preservation could\nlead to drastic performance degradation. On the other hand, the competitive performance of\nrandom mask sampling suggests that order preservation could be further relaxed.\nIn the next section, we investigate the suf\ufb01ciency aspect of the identi\ufb01ed properties.\n5.5.3 Property-satisfying Algorithms\nWe now compare the generation performance of the property-satisfying sampling algorithms\n(designed in Section 5.3.2) with the existing sampling algorithms. The results from the\nGigaword dataset are shown in Figure 5-3 (for automatic evaluation) and Figure 5-5 (for\nhuman evaluation). For completeness, we also replicate Figure 5-5 with self-BLEU as the\ndiversity measure in Appendix A.6. We also present results from automatic evaluation on\nthe Wikitext-103 dataset in Figure 5-6, with consistent observations.\nThe evaluations consistently show that the performance of random top- \ud835\udc58and max entropy\nsampling (and random mask sampling in last section) is on par with top- \ud835\udc58, nucleus, and\ntempered sampling. These results strengthen the importance of the identi\ufb01ed properties in\n70\nSampling Conditional Samples\nExisting Sampling Algorithms\nTop-\ud835\udc58\n(K = 30)steven spielberg\u2019s dreamworks movie studio said monday it was \ufb01ling a lawsuit,\naccusing us studio executives of defrauding hundreds of thousands of dollars in\nrefunds and other damages.\nNucleus\n(P = 0.80)steven spielberg\u2019s dreamworks movie studio has failed to attract the kind of business\nand development investors that jeffrey hutchinson dreamed up in the past.\nTempered\n(T = 0.85)steven spielberg\u2019s dreamworks movie studio plans to spend the rest of the year pro-\nducing the high-speed thriller \"the earth\u2019s path\" and an upcoming sequel, the studio\nannounced on wednesday.\nProperty-satisfying Sampling Algorithms\nRandom Top-\n\ud835\udc58\n(R = 90)steven spielberg\u2019s dreamworks movie studio is planning to make a movie about a\nyoung man who is a <unk>, a man who has a dream of being the \ufb01rst man to be born\nwith the ability to walk on water.\nMax Entropy\n(E = 2.75)steven spielberg\u2019s dreamworks movie studio has agreed to pay $ #.# million to director\njohn nichols (\u00a3 #.# million, ###, a record in the studio circulation ), the studio\nannounced sunday..\nProperty-violating Sampling Algorithms\nRandom\nMask\n(R = 0.75)steven spielberg\u2019s dreamworks movie studio scored a big win with a $ ##.# million (\neuro ##.# million ) direct-to-video ( dvds ) deal to develop the #### short story \"the\nrose garden\".\nNoised Top- \ud835\udc58\n(K=50,\nW=5e-3)steven spielberg\u2019s dreamworks movie studio is in disarray and has a few directors and\na lot of stock involved, leaving it only a matter of time before spielberg\u2019s departure\nfrom the nobel peace prize.\nTarget En-\ntropy\n(E = 2.75)steven spielberg\u2019s dreamworks movie studio production scored an action boost m\nboom, nabbing an \u2019d after the ##th instal specialization with nominations of fritz, ika,\nivan english ape and evlyn mcready.\nTable 5.1: Generated sequences with the same pre\ufb01x steven spielberg\u2019s dreamworks movie\nstudio by different sampling algorithms. The hyperparameters are chosen such that the\nalgorithms yield roughly the same diversity measured by self-BLEU. The poor-quality spans\nare higlighted in red.\n71\nFigure 5-4: The proposed random top- \ud835\udc58and max entropy schedulers, which meet the\nidenti\ufb01ed properties, are on par in performance with existing methods in automatic evaluation\non the Gigaword dataset.\nthat, new sampling algorithms could get competitive generation performance as long as they\nmeet the identi\ufb01ed properties.\n5.5.4 Qualitative Analysis\nWe list samples from the proposed sampling algorithms and compare them with the existing\nones in Table 5.1. We choose the hyperparameter of each sampling algorithm so that each\nalgorithm exhibits a similar level of diversity (as measured by self-BLEU). By manual\ninspection, we \ufb01nd that the quality of samples from property-satisfying sampling algorithms\nis on par with samples from the existing algorithms. In particular, the samples from random\ntop-\ud835\udc58, max entropy, and random masked sampling are all coherent and informative.\nIn contrast, the samples from noised top- \ud835\udc58and target entropy algorithms, tend to be less\n72\nFigure 5-5: Human evaluation also shows that the proposed sampling algorithms has\nperformance on par with the existing methods on the Gigaword dataset. Appendix A.6\nrepeats this plot with self-BLEU.\nsemantically and syntatically coherent. In particular, the target entropy sampling algorithm,\nwhich obtains the lowest quality score measured by corpus-BLEU, lacks basic language\nstructure. In comparison to target entropy, noised top- \ud835\udc58is syntatically coherent, but exhibits\nlogical and factual inconsistencies. These observations aligns with the results we get from\nautomatic evaluation.\n5.6 Related Work\nDespite the popularity of sampling algorithms in natural language generation, a rigorous\ncomparison or scrutiny of existing algorithms is lacking in the literature. Holtzman et al.\n(2020) proposes nucleus sampling, and compare it with top- \ud835\udc58sampling (Fan et al., 2018).\nHowever, only a few hyperparameter con\ufb01gurations are tested. In Hashimoto et al. (2019)\n73\nFigure 5-6: Automatic evaluation on the Wikitext-103 dataset: The performance of proposed\nsampling algorithms are on par with top- \ud835\udc58, nucleus, and tempered sampling.\nand Caccia et al. (2020), temperature sampling is used and the hyperparameter \ud835\udc47is tuned\nto trade-off between diversity and quality, but it lacks comparisons with other sampling\nalgorithms. Welleck et al. (2020) studies the consistency of existing sampling and decoding\nalgorithms, without comparing the generation performance.\nIn this chapter we mainly use the quality-diversity trade-off (Caccia et al., 2020) to\nconduct a comparison of different sampling algorithms. Parallel to our work, Zhang et al.\n(2020a) also uses the quality-diversity trade-off to compare top- \ud835\udc58, nucleus, and tempered\nsampling. Their observation is similar to ours: The performance of the existing algorithms\nare close with no signi\ufb01cant gap.\nMore importantly, the underlying reasons for the success of various sampling algorithms\nremain poorly understood. Zhang et al. (2020a) proposes the selective sampling algorithm,\nwhich fails to outperform existing approaches. This failed attempt suggests the need for a\n74\nbetter understanding of the strengths and weaknesses of existing methods. To the best of our\nknowledge, our work provides the \ufb01rst systematic characterization of sampling algorithms,\nwhere we attribute the success of existing sampling algorithms to a shared set of properties.\nWe show that we can propose novel sampling algorithms based on the identi\ufb01ed properties,\nand reach competitive generation performance as measured by both automatic and human\nevaluation.\n5.7 Limitations and Future Work\nOur core contribution is the three properties of sampling algorithms that we conjecture are\ncrucial for competitive generation performance. While we design a set of experiments to\nvalidate their necessity and suf\ufb01ciency, the observations we make are still empirical. We\nemphasize that it is completely possible that there exists some crucial property, that\nis yet to be discovered, and can lead to signi\ufb01cantly better generation performance .\nTherefore, the exploration of novel sampling algorithms (Zhang et al., 2020a) should still be\nencouraged.\nOn the other hand, to provide a comprehensive study, we focus on the open-ended\nlanguage generation task with the GPT-2 model. As future work, it would be interesting to\ncheck whether our observations also hold on other tasks such story generation or dialogue\nresponse generation, or with weaker language models in low-resource setting.\n5.8 Chapter Summary\nIn this chapter, we study sampling algorithms for the open-ended language generation task.\nWe show that the existing algorithms, namely top- \ud835\udc58, nucleus, and tempered sampling, have\nsimilar generation performance as measured by the quality-diversity trade-off evaluation.\nMotivated by this result, we identify three key properties that we prove are shared by the\nexisting algorithms. To validate the importance of these identi\ufb01ed properties, we design a\nset of new sampling algorithms, and compare their performance with the existing sampling\nalgorithms. We \ufb01nd that violation of the identi\ufb01ed properties may lead to drastic performance\n75\ndegradation. On the other hand, we propose several novel algorithms, namely random top- \ud835\udc58\nand max entropy sampling, that meet the identi\ufb01ed properties. We \ufb01nd that their generation\nperformance is on par with the existing algorithms.\n76\nChapter 6\nConclusion\nThis work was concerned with ascertaining how language models capture facts about the\nreal-world. We started by understanding the intrinsic ability for pretrained language models\nto capture factuality when augmented with an external knowledge base (Chapter 2). The\nbody of this work focused on understanding how this factuality changes under various\nexperimental settings. Chapter 3 studies how various pre-training tasks affect memorization\nand retrieval of knowledge. In order to understand how much harmful knowledge is\ncaptured, Chapter 4 studies how language models may learn stereotypical biases with\nharmful impacts on the population. Finally, with a nod towards generative language models,\nChapter 5 dissects how the choice of sampling algorithms may affect downstream generation\nperformance, with BLEU score serving as a proxy for factuality.\nThe combined results of these three chapters suggest that language models intrinsically\ncapture a signi\ufb01cant amount of world knowledge. However, these methods are not without\ntheir faults. In closing, I would like to entertain several directions for future study that\naddress the limitations of these models.\n6.1 Future Work\nSampling from Human-Feedback for Natural Language Generation Chapter 5 exam-\nined desirable properties for sampling from an autoregressive language model for language\ngeneration. However, there seems to be an inherent misalignment between the language\n77\nFigure 6-1: Illustrating how Euclidean embeddings cause distortion for hierarchical relation-\nships.\nmodeling objective function (greedily maximizing the probability of the next token) and\nthe desired probability distribution for generation. Instead of attempting to \ufb01nd a universal\nobjective funcion, one could train a policy agent that resamples from the LM. This policy\nagent would be trained via reinforcement learning by providing model samples and corre-\nsponding human rating of the sample (for instance, on a Likert scale), and the agent would\nlearn a \"human-aligned\" probability distribution.\nSplitting Up Pre-Training The Scaling Law Hypothesis (Kaplan et al., 2020) argues\nthat language models will continually achieve lower perplexities as model size increases.\nWhile this has been shown to be true, it is undesirable for deployment of these models in\npractical settings. Instead of pretraining an extremely large model on an LM loss function,\nwe should disentangle the knowledge of a model from its cognition . In practice, this will\ncreate a parametric model (such as a language network) that is responsible for cognition,\nand a non-parametric datastore that is responsible for knowledge.\nFurthermore, there needs to be signi\ufb01cant interplay between the cognition model and\nthe datastore. One method to accomplish this is via a graph-based structure, where graph\nattention networks can be viewed as iteratively reasoning over data, and nodes can be\ndirectly updated without requiring re-training from the model. Since models have to\nexplicitly retrieve data, this paradigm should avoid hallucination.\nHyperbolic Embeddings for Hierarchical Data For explicit graph structures, adding\nnew data requires traversing all existing nodes in order to predict new edges. While\n78\nembedding nodes permits clustering algorithms for link prediction, these methods fail when\ndistances between embeddings becomes meaningless. To highlight such a scenario, consider\nthat the leaf nodes in tree-like structures have inadvertently small distances between them, as\nillustrated in Figure 6-1. However, the vast majority of the literature predominantly explores\nknowledge graphs in Euclidean space.\nIn contrast, hyperbolic embeddings do not suffer from distortion due to inherent proper-\nties of the space, and could prove fruitful for knowledge graphs. This requires signi\ufb01cant\nfundamental work: for instance, Query2Box (Ren et al., 2020) provides the ability for\nmodels to reason over embedding spaces when links between embeddings are non-explicit.\nDeveloping equivalent embedding-based frameworks for hyperbolic spaces might prove to\nbe a challenging task.\n79\nTHIS PAGE INTENTIONALLY LEFT BLANK\n80\nAppendix A\nSupplementary Materials for Sampling\nAlgorithms for Language Generation\nA.1 Auxiliary Plots\nWe show the importance of preserving the token with the largest probability ( \ud835\udc5d1) in the\nproposed random mask sampling. For comparison, we relax the constraint and de\ufb01ne the\nrandom mask-all sampling:\nDe\ufb01nition A.1.1. (Random Mask-all ) The only difference between random mask-all sam-\npling and random mask sampling is that we allow the \ud835\udc5d1token to be masked. We formulate\nit below:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\u2032\n\ud835\udc56\u2211\ufe00|\ud835\udc49|\n\ud835\udc57=1\ud835\udc5d\u2032\n\ud835\udc57, (A.1)\nwhere \ud835\udc5d\u2032\n\ud835\udc56=\ud835\udc5d\ud835\udc56\u00b7 1{\ud835\udc62\ud835\udc56> \ud835\udc45}and\ud835\udc62\ud835\udc56\u223c\ud835\udc48(0,1).\nIn Figure A-1, we show that if \ud835\udc5d1is allowed to be masked, the generation performance\nwill be seriously degraded.\nA.2 Proof for Proposition 1\nIn this section we prove Proposition 1.\n81\nFigure A-1: The random mask-all sampling, where \ud835\udc5d1is allowed to be masked, is shown to\nhave worse performance than the random mask sampling. The dataset is Giagword.\nFirstly, it is straightforward to prove that Property 2 (order preservation) holds for the\ntop-\ud835\udc58, nucleus and tempered sampling and we omit the proof here.\nFor Property 3 (slope preservation), it holds trivially for nucleus and top- \ud835\udc58sampling.\nWe prove it for tempered sampling in the following lemma:\nLemma A.2.1. Property 3 holds for tempered sampling (De\ufb01nition 5.2.3).\nProof. Remember that the tempered sampling with hyperparameter \ud835\udc47de\ufb01nes the follow\ntransformation: ^\ud835\udc5d\ud835\udc56=\ud835\udc5d\u2032\n\ud835\udc56\u2211\ufe00\n\ud835\udc57\ud835\udc5d\u2032\n\ud835\udc57, where \ud835\udc5d\u2032\n\ud835\udc56= exp(log( \ud835\udc5d\ud835\udc56)/\ud835\udc47). We set \ud835\udc4d=\u2211\ufe00\n\ud835\udc57\ud835\udc5d\u2032\n\ud835\udc57, then\n82\n\u2200^\ud835\udc5d\ud835\udc56>^\ud835\udc5d\ud835\udc57>^\ud835\udc5d\ud835\udc58>0we have\nlog ^\ud835\udc5d\ud835\udc56\u2212log ^\ud835\udc5d\ud835\udc57\nlog ^\ud835\udc5d\ud835\udc57\u2212log ^\ud835\udc5d\ud835\udc58\n=log\ud835\udc5d\u2032\n\ud835\udc56\u2212log\ud835\udc4d\u2212log\ud835\udc5d\u2032\n\ud835\udc57+ log \ud835\udc4d\nlog\ud835\udc5d\u2032\n\ud835\udc57\u2212log\ud835\udc4d\u2212log\ud835\udc5d\u2032\n\ud835\udc58+ log \ud835\udc4d\n=log\ud835\udc5d\u2032\n\ud835\udc56\u2212log\ud835\udc5d\u2032\n\ud835\udc57\nlog\ud835\udc5d\u2032\n\ud835\udc57\u2212log\ud835\udc5d\u2032\n\ud835\udc58(log\ud835\udc4dis cancelled)\n=log(\ud835\udc5d\ud835\udc56)/\ud835\udc47\u2212log(\ud835\udc5d\ud835\udc57)/\ud835\udc47\nlog(\ud835\udc5d\ud835\udc57)/\ud835\udc47\u2212log(\ud835\udc5d\ud835\udc58)/\ud835\udc47\n=log(\ud835\udc5d\ud835\udc56)\u2212log(\ud835\udc5d\ud835\udc57)\nlog(\ud835\udc5d\ud835\udc57)\u2212log(\ud835\udc5d\ud835\udc58)(A.2)\nOnly Property 1 (entropy reduction) is left. We now prove it holds for top- \ud835\udc58/ nucleus\nsampling:\nLemma A.2.2. Property 1 holds for transformations de\ufb01ned by top- \ud835\udc58or nucleus sampling\n(De\ufb01nition 5.2.1 and 5.2.2).\nProof. We \ufb01rst consider the change of entropy when the token with the smallest probability\n83\n(\ud835\udc5d|\ud835\udc49|) is removed from the original distribution ( ^\ud835\udc5d\ud835\udc56=\ud835\udc5d\ud835\udc56\u2211\ufe00|\ud835\udc49|\u22121\n\ud835\udc57=1\ud835\udc5d\ud835\udc56,1\u2264\ud835\udc56 <|\ud835\udc49|):\n\u2212\u210b(\ud835\udc5d) =\ud835\udc49\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56log\ud835\udc5d\ud835\udc56\n=\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56log\ud835\udc5d\ud835\udc56+\ud835\udc5d|\ud835\udc49|log\ud835\udc5d|\ud835\udc49|\n= (1\u2212\ud835\udc5d|\ud835\udc49|)\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56\n1\u2212\ud835\udc5d|\ud835\udc49|log\ud835\udc5d\ud835\udc56+\ud835\udc5d|\ud835\udc49|log\ud835\udc5d|\ud835\udc49|\n=\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56\n1\u2212\ud835\udc5d|\ud835\udc49|log\ud835\udc5d\ud835\udc56\n1\u2212\ud835\udc5d|\ud835\udc49|+ log(1\u2212\ud835\udc5d|\ud835\udc49|)\n\u23df \u23de \n<0\n+\ud835\udc5d|\ud835\udc49|\u239b\n\u239dlog\ud835\udc5d|\ud835\udc49|\u2212\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56\n1\u2212\ud835\udc5d|\ud835\udc49|log\ud835\udc5d\ud835\udc56\u239e\n\u23a0\n<\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1^\ud835\udc5d\ud835\udc56log ^\ud835\udc5d\ud835\udc56+\ud835\udc5d|\ud835\udc49|\u239b\n\u239c\u239dlog\ud835\udc5d|\ud835\udc49|\u2212\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56\n1\u2212\ud835\udc5d|\ud835\udc49|log\ud835\udc5d\ud835\udc56\u23df \u23de \n>\ud835\udc5d|\ud835\udc49|\u239e\n\u239f\u23a0\n<\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1^\ud835\udc5d\ud835\udc56log ^\ud835\udc5d\ud835\udc56+\ud835\udc5d|\ud835\udc49|\u239b\n\u239c\u239c\u239c\u239c\u239c\u239dlog\ud835\udc5d|\ud835\udc49|\u2212\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56\n1\u2212\ud835\udc5d|\ud835\udc49|log\ud835\udc5d|\ud835\udc49|\n\u23df  \u23de  \n=log \ud835\udc5d|\ud835\udc49|\u239e\n\u239f\u239f\u239f\u239f\u239f\u23a0\n=\ud835\udc49\u22121\u2211\ufe01\n\ud835\udc56=1^\ud835\udc5d\ud835\udc56log ^\ud835\udc5d\ud835\udc56=\u2212\u210b(^\ud835\udc5d)(A.3)\nTherefore, we get\u210b(^\ud835\udc5d)<\u210b(\ud835\udc5d).\nBy induction (iteratively removing the last token), it is now easy to see that the top- \ud835\udc58or\nnucleus transformation strictly decrease the entropy of the sampling distribution.\nFinally, we prove Property 1 (entropy reduction) holds for tempered sampling:\nLemma A.2.3. Property 1 holds for the transformation de\ufb01ned by tempered sampling\n(De\ufb01nition 5.2.3).\nProof. For convenience, we \ufb01rst rewrite the Temperature transformation:\n^\ud835\udc5d\ud835\udc56=\ud835\udc5d\ud835\udefc\n\ud835\udc56=exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)(A.4)\n84\nwhere \ud835\udc52\ud835\udc56=\u2212log(\ud835\udc5d\ud835\udc56)and\ud835\udefc=1\n\ud835\udc47. The entropy can be written as:\n\u210b(\ud835\udc5d\ud835\udefc) =\u2212\u2211\ufe01\n\ud835\udc56exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)logexp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)\n= log\u2211\ufe01\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57) +\ud835\udefc\u2211\ufe01\n\ud835\udc56\ud835\udc52\ud835\udc56exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)(A.5)\nNext, we take derivative w.r.t \ud835\udefc:\n\ud835\udf15\u210b\n\ud835\udf15\ud835\udefc=\u2212\u2211\ufe01\n\ud835\udc56\ud835\udc52\ud835\udc56exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)+\u2211\ufe01\n\ud835\udc56\ud835\udc52\ud835\udc56exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)\n\u23df  \u23de  \n=0\n+\ud835\udefc\ud835\udf15\n\ud835\udf15\ud835\udefc\u2211\ufe01\n\ud835\udc56\ud835\udc52\ud835\udc56exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)\n=\ud835\udefc\u2211\ufe01\n\ud835\udc56\ud835\udc52\ud835\udc56[\ufe03\n\ud835\udf15\n\ud835\udf15\ud835\udefclogexp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)]\ufe03[\ufe03\nexp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)]\ufe03\n\u23df  \u23de  \nlog-derivative trick\n=\ud835\udefc\u2211\ufe01\n\ud835\udc56\ud835\udc52\ud835\udc56\u23a1\n\u23a3\u2212\ud835\udc52\ud835\udc56+\u2211\ufe01\n\ud835\udc57\u2032\ud835\udc52\ud835\udc57\u2032exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)\u23a4\n\u23a6\n[\ufe03\nexp(\u2212\ud835\udefc\ud835\udc52\ud835\udc56)\u2211\ufe00\n\ud835\udc57exp(\u2212\ud835\udefc\ud835\udc52\ud835\udc57)]\ufe03\n=\u2212\ud835\udefcE\ud835\udc5d\ud835\udefc[\ufe01\n\ud835\udc522\n\ud835\udc56\u2212\ud835\udc52\ud835\udc56E\ud835\udc5d\ud835\udefc[\ud835\udc52\ud835\udc56]]\ufe01\n=\u2212\ud835\udefc\u23df \u23de \n>0(\ufe01\nE\ud835\udc5d\ud835\udefc[\ud835\udc522\n\ud835\udc56]\u2212E\ud835\udc5d\ud835\udefc[\ud835\udc52\ud835\udc56]2)\ufe01\n\u23df  \u23de  \n=Var\ud835\udc5d\ud835\udefc[\ud835\udc52\ud835\udc56]\u22650\n<0(A.6)\nWe can now easily get\ud835\udf15\u210b\n\ud835\udf15\ud835\udc47=\ud835\udf15\u210b\n\ud835\udf15\ud835\udefc\ud835\udf15\ud835\udefc\n\ud835\udf15\ud835\udc47>0. Therefore, when we apply a tempered transforma-\ntion with \ud835\udc47 < 1, the entropy will strictly decrease comaparing to the original distribution\n(where \ud835\udc47= 1).\nA.3 Mechanical Turk Setup\nOur crowdworkers were required to have a HIT acceptance rate higher than 95%, and be\nlocated in the United States. In total, 602 crowdworkers completed our tasks. In order to\nensure that we had quality data, we \ufb01ltered the crowdworker annotations for workers that\nspent at least 45 seconds on the aggregate task (or 4.5 seconds rating each sentence). 51\n85\ncrowdworkers were \ufb01ltered out through this process. Screenshots of our instructions and\ntask are available in Figure(s) A-2 and A-3 respectively.\nFigure A-2: Our instructions for crowdworker task.\nFigure A-3: An example of the task given to crowdworkers.\nA.4 Convergence of Human Evaluation\nWhen we conduct human evaluation, we provide crowdworkers with 200 generated samples\nfor some con\ufb01guration, and ask 25 different crowdworkers to evaluate the same sample.\nHowever, a reasonable question is whether our human evaluations are converging to some\nunderlying true rating, or whether we need more samples or replicas.\nFigure A-4 and A-5 show that the average scores have roughly converged around 150\nsamples per con\ufb01guration, or around 15 replicas per sample. The two \ufb01gures demon-\n86\nstrate this for nucleus sampling, and this holds true for human evaluations of all sampling\nalgorithms.\nFigure A-4: We see that we obtain a reasonable estimate of sample quality around 150\nsamples per con\ufb01guration.\nA.5 Additional Model-Generated Samples\nTable A.1 shows some additional samples from each of the sampling algorithms described in\nthe paper. Similarly, we have chosen hyperparameters for each sampling method that yields\na similar diversity (measured by self-BLEU) to the top- \ud835\udc58con\ufb01guration where \ud835\udc3e= 15 . We\nobserve that all sampling algorithms except for noised top- \ud835\udc58and target entropy, yield similar\nquality samples. For noised top- \ud835\udc58and target entropy, we see that these samples tend to\ndegenerate towards the end of the sentence, indicating violation of the identi\ufb01ed properties\nmay possibly lead towards degraded performance.\n87\nSampling Conditional Samples\nExisting Sampling Algorithms\nTop-K\n(K = 15)as the rest of his denver broncos teammates prepared for the game against denver,\njay kasey could not help but think of his teammates and friends who worked hard in\npreparation for that night\u2019s game.\nNucleus\n(P = 0.65)as the rest of his denver broncos teammates slumped and buried themselves in their\nwork, broncos quarterback leon johnson moved to the locker room monday and called\nhis parents.\nTemperature\n(T = 0.7)as the rest of his denver broncos teammates gathered in an auditorium to watch more\nstretching drills, ben holtz gave an emotional speech : we\u2019re running out of time to\nwin a championship ring.\nProperty-satisfying Sampling Algorithms\nRandom Top-\nK\n(R = 30)as the rest of his denver broncos teammates battled through their own stretch of the n\ufb02\nplayoffs, the quarterback began throwing the ball in the fourth quarter.\nMax Entropy\n(E = 2.75)steven spielberg\u2019s dreamworks movie studio has agreed to pay $ #.# million to director\njohn nichols (\u00a3 #.# million, ###, a record in the studio circulation ), the studio\nannounced sunday..\nProperty-violating Sampling Algorithms\nRandom\nMask\n(R = 0.75)as the rest of his denver broncos teammates connect with a player that the team didn\u2019t\nexpect to become a starter, quarterback james crosby speaks out about colin peterson\u2019s\npassion for the game.\nNoised Top-K\n(K=20,\nW=5e-3)as the rest of his denver broncos teammates start making room for nerdy bundles or\ntwiggy pitchers, coach william perez might have to cut a big, bold note cut ready to\nconsole wife join them in iraq.\nTarget En-\ntropy\n(E = 2.5)as the rest of his denver broncos teammates scratched out their locker rooms, clean-\nDeath Yo Communities wander edge extingustretched cords429 Mohnegie wild\ufb01res.\nTable A.1: The samples conditioned on as the rest of his denver broncos teammates , and the\nhyperparameters for a given sampling algorithm. The poor quality spans are higlighted in\nred.\n88\nFigure A-5: We see that we obtain a reasonable estimate of sample quality with around 15\nratings per sample.\nA.6 Human Evaluation with Self-BLEU as Diversity Met-\nric\nFigures 5-1 and 5-5 measures diversity in terms of 3-gram entropy, while the rest of our\nwork measures diversity in terms of self-BLEU. For completeness, we provide Figure A-6\nwhere self-BLEU is used for diversity metric. This \ufb01gure demonstrates that similar trends\ncan be observed using either 3-gram entropy or self-BLEU.\n89\nFigure A-6: Using self-BLEU as a diversity metric provides similar conclusions as to using\nn-gram entropy.\n90\nAppendix B\nSupplementary Materials for\nStereotypical Bias in Pretrained\nLanguage Models\nB.1 Data Statement\nCuration Rationale\nStereoSet is a crowdsourced dataset that was created as a benchmark for stereotypical biases\nin pretrained language models. This dataset consists of 4 target domains, 321 target terms,\nand 16,995 test instances. StereoSet is in English and is tailored for the stereotypes that\nexist in the United States. The data was explicitly curated with a goal of creating a set of\nstereotypical and anti-stereotypical examples, and therefore is highly offensive.\nEach example in the dataset consists of a triple. Each triple consists of a target con-\ntext, with a corresponding stereotypical, anti-stereotypical, or unrelated association that\nstereotypes the target or combats stereotypes about the target.\nWe collected this data via Amazon Mechanical Turk (AMT), where each example was\nwritten by one crowdworker and validated by four other crowdworkers. We required all\ncrowdworkers to be in the United States and have a HIT acceptance rate greater than 97%.\nWe paid all workers with a minimum wage of $15 an hour in compliance with our funding\n91\nagencies\u2019 AMT policy.\nLanguage Variety\nWe require crowdworkers to be within the United States, and therefore all examples are\nwritten in US English (en-US). However, we do not enforce any constraints on, nor do we\ncollect, the dialect that is used. An inspection of the dataset by the authors has shown no\nsingle dialect to dominate the annotations.\nSpeaker & Annotator Demographic\nOur speakers and annotators (validators) came from Amazon Mechanical Turk (AMT), and\nwe provided no \ufb01lters beyond the 97% HIT acceptance rate. Difallah et al. (2018) shows\nthat the Amazon Mechanical Turk population is 55% women and 45% men, with 80% of the\npopulous under the age of 50. The median income of workers on AMT is $47k; in contrast,\nthe United States has a median income of $57k.\nSpeech Situation\nAll speech was written in English, and was never edited after the speaker wrote it. The time\nand place were unconstrained. We prompted the speaker to stereotype and anti-stereotype a\ngiven target word. We informed them that their work would be used for a scienti\ufb01c study\nand they were encouraged to explicitly stereotype target groups.\nText Characteristics\nStereoSet measures stereotypical biases in gender, profession, race, and religion. The\nintrasentence task (Figure B-2) lends itself to a \"\ufb01ll-in-the-blank\" nature, while the intersen-\ntence task (Figure B-3) asks annotators to contextualize a pair of sentences. We have found\nthat the type of task has in\ufb02uenced the choice of vocabulary.\nRecording Quality\nThe data was only written, and never recorded.\n92\nOther\nIn total, 475 and 803 annotators completed the intrasentence and intersentence tasks respec-\ntively. Restricting crowdworkers to the United States helps account for differing de\ufb01nitions\nof stereotypes based on regional social expectations, though limitations in the dataset remain\nas discussed in Section 4.8. Screenshots of our Mechanical Turk interface are available in\nFigure B-2 and B-3.\nWe strongly caution against the misuse of this dataset for any purpose other than as a\nbenchmark of stereotypical biases in pretrained language models. We remind users that\ndecreased scores on our benchmarks does not imply that bias is mitigated, but rather that\nStereoSet cannot detect it.\nProvenance Appendix\nThis dataset was not built out of existing datasets.\nB.2 Appendix\nB.2.1 Detailed Results\nTable B.5 presents the overall results of models on the StereoSet development set. Table B.6\nand Table B.7 show detailed results on the Context Association Test for the development\nand test sets respectively.\nB.2.2 List of Target Words\nTable B.8 list our target terms used in the dataset collection task.\nB.2.3 General Methods for Training a Next Sentence Prediction Head\nGiven some context \ud835\udc50, and some sentence \ud835\udc60, our intersentence task requires calculating the\nlikelihood \ud835\udc5d(\ud835\udc60|\ud835\udc50), for some sentence \ud835\udc60and context sentence \ud835\udc50.\n93\nWhile BERT has been trained with a Next Sentence Prediction classi\ufb01cation head to\nprovide \ud835\udc5d(\ud835\udc60|\ud835\udc50), the other models have not. In this section, we detail our creation of a Next\nSentence Prediction classi\ufb01cation head as a downstream task.\nFor some sentences \ud835\udc34and\ud835\udc35, our task is simply determining if Sentence \ud835\udc34follows\nSentence \ud835\udc35, or if Sentence \ud835\udc35follows Sentence \ud835\udc34. We trivially generate this corpus from\nWikipedia by sampling some \ud835\udc56\ud835\udc61\u210esentence, \ud835\udc56+ 1\ud835\udc61\u210esentence, and a randomly chosen negative\nsentence from any other article. We maintain a maximum sequence length of 256 tokens,\nand our training set consists of 9.5 million examples.\nWe train with a batch size of 80 sequences until convergence (80 sequences / batch *\n256 tokens / sequence = 20,480 tokens/batch) for 10 epochs over the corpus. For BERT,\nWe use BertAdam as the optimizer, with a learning rate of 1e-5, a linear warmup schedule\nfrom 50 steps to 500 steps, and minimize cross entropy for our loss function. Our results are\ncomparable to Devlin et al. (2019b), with each model obtaining 93-98% accuracy against\nthe test set of 3.5 million examples.\nAdditional models maintain the same experimental details. Our NSP classi\ufb01er achieves\nan 94.6% accuracy with ROBERT A-base, a 97.1% accuracy with ROBERT A-large, a 93.4%\naccuracy with XLN ET-base and 94.1% accuracy with XLN ET-large.\nIn order to evaluate GPT-2 on intersentence tasks, we feed the mean-pooled represen-\ntations across the entire sequence length into the classi\ufb01cation head. Our NSP classi\ufb01er\nobtains a 92.5% accuracy on GPT2 -small, 94.2% on GPT2 -medium, and 96.1% on GPT2 -\nlarge. In order to \ufb01ne-tune GPT2 -large on our machines, we utilized gradient accumulation\nwith a step size of 10, and mixed precision training from Apex.\nB.2.4 Fine-Tuning BERT for Sentiment Analysis\nIn order to evaluate sentiment, we \ufb01ne-tune BERT Devlin et al. (2019b) on movie reviews\nMaas et al. (2011) for seven epochs. We used a maximum sequence length of 256 Word-\nPieces, batch size 32, and used Adam with a learning rate of 1e\u22124. Our \ufb01ne-tuned model\nachieves an 92% test accuracy on the Large Movie Review dataset. It is important to note\nthat the classi\ufb01er also classi\ufb01es neutral sentiment such as My housekeeper is a Mexican as\n94\npositive.\nB.2.5 Reproducibility Checklist\nWe used 2 RTX 2080 Ti to \ufb01ne-tune all of the models for the next sentence prediction task,\nalthough this could have been done with one GPU as well. The only exception to this is\nGPT2 -large, which required 2 Tesla V100s (with 32GB of RAM) to \ufb01ne-tune. We will\nrelease all pretrained models to encourage reproducibility, and each model\u2019s biases is able\nto be evaluated within 5 minutes.\nSince we are using standardized models, the sizes of every single model is available\nonline. For convenience, we report it here:\n1. BERT-base: 110M parameters\n2. BERT-large: 340M parameters\n3. GPT2-small: 117M parameters\n4. GPT2-medium: 345M parameters\n5. GPT2-large: 774M parameters\n6. R OBERT A-base: 125M parameters\n7. R OBERT A-large: 355M parameters\n8. XLN ET-base: 110M parameters\n9. XLN ET-large: 340M parameters\nB.2.6 Collecting Neutral Associations\nWe also experimented with testing whether models endorse a contextually neutral association\nover the stereotypical or anti-stereotypical context. However, we found that crowd workers\nhad a poor inter-annotator agreement when asked to write neutral continuations. Table B.1\nhighlights some collected sentences that were neutral.\n95\nTarget Neutral Sentence\nEthiopia The Ethiopian woman had never\nbeen so angry.\nChess player The chess player was bearded.\nSchoolgirl Schoolgirls are so cute in every\nmovie I watch.\nAfghanistan People from Afghanistan are\ncurious.\nTailor A tailor is relaxed when talking\nto me.\nTable B.1: A collection of neutral associations from crowdworkers.\nMany of the contextually neutral associations in Table B.1 show highly stereotypical\nbehavior. For instance, \"the ethiopian woman had never been so angry\" characterizes\nthe Angry Black Woman stereotype Collins (2004). Furthermore, we hold that some of\nthese neutral sentences aren\u2019t truly neutral; the chess player was bearded may inadvertently\nconceal stereotypes, since both chess players and bearded men are commonly seen as wise.\nHence, a model may endorse a neutral sentence for the wrong reasons.\nB.2.7 Motivating the ICAT score\nTo address situations where a point estimate that combines \ud835\udc59\ud835\udc5a\ud835\udc60 and\ud835\udc60\ud835\udc60is required (ie.\nranking models), we develop the idealized CAT ( \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61) score. We recognize that various\napplications have different trade-offs between fairness and accuracy. We address a generic\ncase where accuracy and fairness are equally important. We derive the \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61score from the\nfollowing axioms:\n\u2022An ideal model has an \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 score of 100, i.e., when its \ud835\udc59\ud835\udc5a\ud835\udc60 is 100 and \ud835\udc60\ud835\udc60is 50, its\n\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61score is 100.\n\u2022A fully biased model has an \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 score of 0, i.e., when its \ud835\udc60\ud835\udc60is either 100 (always\nprefer a stereotype over an anti-stereotype) or 0 (always prefer an anti-stereotype over\na stereotype), its \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61score is 0.\n\u2022A random model has an \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 score of 50, i.e., when its \ud835\udc59\ud835\udc5a\ud835\udc60 is 50 and \ud835\udc60\ud835\udc60is 50, its \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61\nscore must be 50.\n96\n50\n52\n54\n56\n58\n60\n62\n64\n66\n68\n70\n72\n74\n76\n78\n80\n82\n84\n86\n88\n90\n92\n94\n96\n98\n100\nLM Score0\n4\n8\n12\n16\n20\n24\n28\n32\n36\n40\n44\n48\n52\n56\n60\n64\n68\n72\n76\n80\n84\n88\n92\n96\n100Stereotype ScoreCharacterizing the ICAT Score\n020406080100\nICAT ScoreFigure B-1: The range of the idealized CAT score as a function of the LM score and SS\nscore.\nTherefore we de\ufb01ne \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61score as\n\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61=\ud835\udc59\ud835\udc5a\ud835\udc60*\ud835\udc5a\ud835\udc56\ud835\udc5b(\ud835\udc60\ud835\udc60,100\u2212\ud835\udc60\ud835\udc60)\n50\nThis equation satis\ufb01es all the axioms. Here\ud835\udc5a\ud835\udc56\ud835\udc5b(\ud835\udc60\ud835\udc60,100\u2212\ud835\udc60\ud835\udc60)\n50\u2208[0,1]is maximized when the\nmodel prefers neither stereotypes nor anti-stereotypes for each target term and is minimized\nwhen the model favours one over the other. We scale this value using the language modeling\nscore. An interpretation of \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 is that it represents the language modeling ability of a model\nto behave in an unbiased manner while excelling at language modeling.\nFigure B-1 depicts the values that the \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61score may take on. We include Tables B.2,\nB.3, and B.4 as replicas of Tables 4.4, 4.5, 4.6 with the inclusion of an optional \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61score.\n97\nFigure B-2: A screenshot of our intrasentence task collection interface.\nModel Language\nModel\nScore\n(\ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore\n(\ud835\udc60\ud835\udc60)Idealized\nCAT\nScore\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)\nTest set\nIDEAL LM 100 50.0 100\nSTEREOTYPED LM - 100 0.0\nRANDOM LM 50.0 50.0 50.0\nSENTIMENT LM 65.1 60.8 51.1\nBERT-base 86.4 60.4 68.3\nBERT-large 86.5 59.3 70.4\nROBERT A-base 68.2 50.5 67.5\nROBERT A-large 75.8 54.8 68.5\nXLN ET-base 67.7 54.1 62.1\nXLN ET-large 78.2 54.0 72.0\nGPT2 83.6 56.4 73.0\nGPT2-medium 85.9 58.2 71.7\nGPT2-large 88.3 60.1 70.5\nENSEMBLE 90.5 62.5 68.0\nTable B.2: \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61scores of pretrained language models on the StereoSet test set.\n98\nDomain Language\nModel\nScore\n(\ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore\n(\ud835\udc60\ud835\udc60)Idealized\nCAT\nScore\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)\nGENDER 92.4 63.9 66.7\nmother 97.2 77.8 43.2\ngrandfather 96.2 52.8 90.8\nPROFESSION 88.8 62.6 66.5\nsoftware developer 94.0 75.9 45.4\nproducer 91.7 53.7 84.9\nRACE 91.2 61.8 69.7\nAfrican 91.8 74.5 46.7\nCrimean 93.3 50.0 93.3\nRELIGION 93.5 63.8 67.7\nBible 85.0 66.0 57.8\nMuslim 94.8 46.6 88.3\nTable B.3: Domain-wise \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61scores of the ENSEMBLE model, along with most and least\nstereotyped terms.\n99\nModel Language\nModel\nScore\n(\ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore\n(\ud835\udc60\ud835\udc60)Idealized\nCAT\nScore\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)\nIntrasentence Task\nBERT-base 82.5 57.5 70.2\nBERT-large 82.9 57.6 70.3\nROBERT A-base 71.9 53.6 66.7\nROBERT A-large 72.7 54.4 66.3\nXLN ET-base 70.3 53.6 65.2\nXLN ET-large 74.0 51.8 71.3\nGPT2 91.0 60.4 72.0\nGPT2-medium 91.2 62.9 67.7\nGPT2-large 91.8 63.9 66.2\nENSEMBLE 91.7 63.9 66.3\nIntersentence Task\nBERT-base 88.3 61.7 67.6\nBERT-large 90.1 60.6 71.0\nROBERT A-base 64.4 47.4 61.0\nROBERT A-large 78.8 55.2 70.6\nXLN ET-base-cased 65.0 54.6 59.0\nXLN ET-large-cased 82.5 56.1 72.5\nGPT2 76.3 52.3 72.8\nGPT2-medium 80.5 53.5 74.9\nGPT2-large 84.9 56.1 74.5\nENSEMBLE 89.4 60.9 69.9\nTable B.4: \ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61 scores on the Intersentence and Intrasentence CATs on the StereoSet test set.\n100\nModel Language\nModel\nScore\n(\ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore\n(\ud835\udc60\ud835\udc60)Idealized\nCAT\nScore\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)\nDevelopment set\nIDEAL LM 100 50.0 100\nSTEREOTYPED LM - 100 0.0\nRANDOM LM 50.0 50.0 50.0\nSENTIMENT LM 65.5 60.2 52.1\nBERT-base 86.2 60.1 68.7\nBERT-large 87.0 60.6 68.4\nROBERT A-base 69.0 49.9 68.8\nROBERT A-large 76.6 56.0 67.4\nXLN ET-base 67.3 54.2 61.6\nXLN ET-large 78.0 54.4 71.2\nGPT2 83.7 57.0 71.9\nGPT2-medium 87.1 59.0 71.5\nGPT2-large 88.9 61.9 67.8\nENSEMBLE 90.7 62.0 69.0\nTable B.5: Performance of pretrained language models on the StereoSet development set.\n101\nIntersentence Intrasentence\nModel Domain Language\nModel\nScore ( \ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore ( \ud835\udc60\ud835\udc60)Idealized\nCAT Score\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)Language\nModel\nScore ( \ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore ( \ud835\udc60\ud835\udc60)Idealized\nCAT Score\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)\nSENTIMENT LM gender 85.78 58.76 70.75 36.45 42.02 30.64\nprofession 80.70 65.20 56.16 45.61 45.28 41.31\nrace 84.90 70.48 50.13 49.10 70.14 29.32\nreligion 87.35 68.79 54.53 44.78 50.62 44.23\noverall 83.51 66.93 55.24 46.01 56.40 40.12\nBERT-base gender 92.86 59.74 74.77 82.50 61.48 63.56\nprofession 86.15 61.82 65.79 82.31 60.85 64.45\nrace 88.84 62.16 67.22 83.82 56.30 73.27\nreligion 95.52 60.98 74.56 82.16 56.28 71.85\noverall 88.66 61.69 67.92 83.02 58.68 68.61\nBERT-large gender 94.37 61.04 73.54 83.10 64.04 59.77\nprofession 88.94 62.66 66.42 83.04 60.30 65.94\nrace 89.90 62.60 67.26 84.02 57.27 71.80\nreligion 95.53 58.54 79.22 85.98 50.16 85.70\noverall 90.36 62.21 68.30 83.60 59.01 68.54\nGPT2 gender 85.95 53.38 80.14 93.28 62.67 69.65\nprofession 72.79 52.39 69.31 92.29 63.97 66.50\nrace 76.50 51.49 74.22 89.76 60.35 71.18\nreligion 75.83 56.93 65.33 88.46 58.02 74.27\noverall 76.26 52.28 72.79 91.11 61.93 69.37\nGPT2-medium gender 86.76 52.80 81.89 93.58 65.58 64.42\nprofession 79.95 60.83 62.63 91.76 63.37 67.22\nrace 82.20 50.93 80.68 92.36 61.44 71.22\nreligion 86.45 60.80 67.78 90.46 62.57 67.71\noverall 82.09 55.30 73.38 92.21 62.74 68.71\nGPT2-large gender 89.91 60.72 70.62 95.32 65.29 66.17\nprofession 84.88 61.73 64.97 92.36 65.68 63.39\nrace 84.21 57.02 72.38 91.89 63.00 67.99\nreligion 88.50 62.98 65.53 91.61 61.61 70.34\noverall 85.35 59.50 69.12 92.49 64.26 66.12\nXLN ET-base gender 75.27 59.33 61.22 69.57 46.54 64.76\nprofession 67.53 52.66 63.93 67.75 58.47 56.27\nrace 61.25 55.13 54.97 69.19 52.14 66.22\nreligion 69.54 51.66 67.22 74.90 55.72 66.32\noverall 65.72 54.59 59.69 68.91 53.97 63.43\nXLN ET-large gender 89.87 57.61 76.18 74.16 53.99 68.23\nprofession 79.98 55.05 71.90 73.15 56.05 64.30\nrace 81.90 54.92 73.84 73.64 50.42 73.02\nreligion 87.51 66.68 58.31 77.95 49.61 77.34\noverall 82.39 55.76 72.90 73.68 52.98 69.29\nROBERT A-base gender 59.62 46.76 55.76 71.36 54.21 65.35\nprofession 69.75 45.31 63.21 72.49 55.94 63.87\nrace 66.80 43.28 57.82 70.03 56.07 61.52\nreligion 60.55 50.15 60.37 70.60 40.83 57.65\noverall 66.78 44.75 59.77 71.15 55.21 63.74\nROBERT A-large gender 80.98 56.49 70.47 75.63 56.99 65.06\nprofession 76.21 57.21 65.21 73.71 55.42 65.72\nrace 82.45 56.73 71.36 71.71 56.34 62.63\nreligion 91.23 49.48 90.29 69.93 39.86 55.75\noverall 80.23 56.61 69.63 72.90 55.45 64.96\nENSEMBLE gender 93.42 63.10 68.94 95.19 64.18 68.19\nprofession 86.19 63.52 62.87 92.34 65.44 63.83\nrace 89.49 57.44 76.17 92.47 62.20 69.91\nreligion 90.11 56.74 77.96 91.61 59.13 74.89\noverall 88.76 60.44 70.22 92.73 63.56 67.57\nTable B.6: The per-domain performance of pretrained language models on the development\nset.102\nIntersentence Intrasentence\nModel Domain Language\nModel\nScore ( \ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore ( \ud835\udc60\ud835\udc60)Idealized\nCAT Score\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)Language\nModel\nScore ( \ud835\udc59\ud835\udc5a\ud835\udc60)Stereotype\nScore ( \ud835\udc60\ud835\udc60)Idealized\nCAT Score\n(\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61)\nSENTIMENT LM gender 86.11 57.59 73.03 40.69 47.16 38.39\nprofession 80.69 61.32 62.42 46.07 43.41 40.00\nrace 84.45 70.32 50.13 49.57 69.16 30.57\nreligion 89.36 71.54 50.86 42.78 57.17 36.64\noverall 83.44 65.44 57.67 46.92 56.41 40.90\nBERT-base gender 91.44 58.82 75.30 82.78 61.23 64.19\nprofession 86.06 62.52 64.51 82.89 57.32 70.75\nrace 88.43 61.05 72.09 82.14 57.02 70.61\nreligion 93.66 65.91 63.87 82.86 52.69 78.40\noverall 88.28 61.68 67.64 82.52 57.49 70.16\nBERT-large gender 93.53 60.68 73.21 82.80 61.23 64.21\nprofession 88.51 61.83 67.57 82.55 57.33 70.45\nrace 89.86 59.73 72.37 83.10 57.00 71.47\nreligion 93.04 59.04 76.21 84.30 56.04 74.11\noverall 90.01 60.58 70.97 82.90 57.61 70.29\nGPT2 gender 84.68 49.62 84.03 92.01 62.65 68.74\nprofession 72.03 53.22 67.39 90.74 61.31 70.22\nrace 76.72 52.24 73.28 90.95 58.90 74.76\nreligion 85.21 52.04 81.74 91.21 63.26 67.02\noverall 76.28 52.27 72.81 91.01 60.42 72.04\nGPT2-medium gender 84.47 49.17 83.07 91.65 66.17 62.01\nprofession 78.93 56.65 68.43 90.03 63.04 66.55\nrace 80.40 52.12 77.00 91.81 61.70 70.33\nreligion 85.44 53.64 79.23 93.43 65.83 63.85\noverall 80.55 53.49 74.92 91.19 62.91 67.65\nGPT2-large gender 88.43 54.52 80.44 92.92 67.64 60.13\nprofession 84.66 59.33 68.86 90.40 64.43 64.31\nrace 83.87 53.77 77.55 92.41 62.35 69.58\nreligion 88.57 59.46 71.82 93.69 66.35 63.06\noverall 84.91 56.14 74.47 91.77 63.93 66.21\nXLN ET-base gender 74.26 54.80 67.14 72.09 54.75 65.24\nprofession 67.99 54.18 62.30 69.73 55.31 62.33\nrace 60.14 54.75 54.42 70.34 52.34 67.04\nreligion 65.58 57.30 56.00 70.61 49.00 69.20\noverall 65.01 54.64 58.98 70.34 53.62 65.25\nXLN ET-large-cased gender 87.07 54.99 78.39 74.85 56.69 64.84\nprofession 81.90 55.59 72.75 74.20 52.61 70.33\nrace 81.24 56.24 71.10 73.43 50.11 73.27\nreligion 89.23 62.04 67.74 75.96 49.40 75.05\nkj R OBERT A-base gender 56.86 45.96 52.27 73.90 53.54 68.66\nprofession 67.97 48.46 65.87 71.07 52.63 67.33\nrace 63.37 46.99 59.55 72.16 54.59 65.54\nreligion 66.15 46.74 61.83 71.23 51.79 68.69\noverall 64.38 47.40 61.02 71.94 53.63 66.72\nROBERT A-large gender 81.50 52.00 78.23 75.34 53.58 69.94\nprofession 75.75 54.12 69.52 72.69 54.79 65.73\nrace 79.40 56.94 68.38 72.16 54.73 65.33\nreligion 93.70 56.08 82.32 71.88 49.32 70.91\noverall 78.84 55.24 70.57 72.74 54.41 66.33\nENSEMBLE gender 92.59 60.68 72.82 92.15 67.12 60.61\nprofession 87.26 60.84 68.34 90.40 64.29 64.56\nrace 90.00 61.08 70.06 92.41 62.45 69.40\nreligion 92.78 60.88 72.58 94.30 66.70 62.80\noverall 89.40 60.93 69.86 91.70 63.87 66.26\nTable B.7: The per-domain performance of pretrained language models on the test set.\n103\nFigure B-3: A screenshot of our intersentence task collection interface.\n104\nGender\nstepfather male she stepmother ladies man\nbrother female woman mother grandfather girl\nfather gentlemen grandmother boy schoolboy wife\nbride sir groom her lady mommy\nhim son boyfriend himself gentleman hers\ngirlfriend he husband his sister daddy\ndaughter herself ma\u2019am schoolgirl\nProfession\nbarber coach businessperson football player construction worker manager\nCEO accountant commander \ufb01re\ufb01ghter mover software developer\nguard baker doctor athlete artist dancer\nmathematician janitor carpenter mechanic actor handyman\nmusician detective politician entrepreneur model opera singer\nchief lawyer farmer writer librarian army\nreal-estate developer broker scientist butcher electrician prosecutor\nbanker cook hairdresser prisoner plumber attourney\nboxer chess player priest swimmer tennis player supervisor\nattendant housekeeper maid producer researcher midwife\njudge umpire bartender economist physicist psychologist\ntheologian salesperson physician sheriff cashier assistant\nreceptionist editor engineer comedian painter civil servant\ndiplomat guitarist linguist poet laborer teacher\ndelivery man realtor pilot professor chemist historian\npensioner performing artist singer secretary auditor counselor\ndesigner soldier journalist dentist analyst nurse\ntailor waiter author architect academic director\nillustrator clerk policeman chef photographer drawer\ncleaner pharmacist pianist composer handball player sociologist\nRace\nNigerian Ethiopia Europe European Russian Ukraine\nSudan Afghanistan Iraq Yemen Ukrainian Russia\nItaly Somali Iran Afghan Indian Italian\nAustralian Spanish Guatemalan Hispanic Venezuela Sudanese\nOman Finnish Swedish Venezuelan Puerto Rican Ghanaian\nMoroccan Somalia Saudi Arabian Syria Chinese Pakistani\nChina India Irish Britain France Greece\nScotland Mexican Paraguayan Brazil African Eritrean\nSierra Leonean Africa Jordan Indonesia Vietnam Pakistan\nGerman Romania Brazilian Ecuadorian Mexico Puerto Rico\nKenyan Liberian Cameroonian African Americans Kenya Liberia\nSierra Leon Qatari Syrian Arab Saudi Arabia Lebanon\nIndonesian French Norweigan South Africa Jordanian Korea\nSingapore Romanian Crimean Native American Germany Ireland\nEcuador Morocco Omani Iranian Iraqi Qatar\nTurkey Vietnamese Nepali Laos Bangladesh British\nPolish Greek Scottish Bolivian Guatemala Ghana\nCameroon Japanese Taiwanese Bengali Nepal Albanian\nAlbania Columbian Peruvian Argentian Spain Paraguay\nEthiopian Egyptian Persian people Sweden Crimea Portuguese\nArgentina Chile Cape Verdean Turkish Yemeni Taiwan\nAustrian White people Finland Australia South African Eriteria\nEgypt Korean Dutch people Peru Poland Chilean\nColumbia Bolivia Laotian Lebanese Japan Norway\nCape Verde Portugal Austria Singaporean Netherlands\nReligion\nSharia Jihad Christian Muslim Islam Hindu\nMohammed church Bible Quran Brahmin Holy Trinity\nTable B.8: The set of terms that were used to collect StereoSet, ordered by frequency in the\ndataset.\n105\nTHIS PAGE INTENTIONALLY LEFT BLANK\n106\nBibliography\nDavid H. Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski. 1985. A Learning\nAlgorithm for Boltzmann Machines , volume 9, pages 147\u2013169.\nGianni Amati and Cornelis Joost Van Rijsbergen. 2002. Probabilistic models of information\nretrieval based on measuring the divergence from randomness. ACM Transactions on\nInformation Systems (TOIS) , 20(4):357\u2013389.\nSean Baird, Doug Sibley, and Yuxi Pan. 2017. Talos targets disinformation with fake\nnews challenge victory. https://blog.talosintelligence.com/2017/06/ talos-fake-news-\nchallenge.html.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov, James Glass, and Preslav Nakov. 2018a.\nPredicting factuality of reporting and bias of news media sources. In Proceedings of\nthe 2018 Conference on Empirical Methods in Natural Language Processing , pages\n3528\u20133539. Association for Computational Linguistics.\nRamy Baly, Mitra Mohtarami, James Glass, Llu\u00eds M\u00e0rquez, Alessandro Moschitti, and\nPreslav Nakov. 2018b. Integrating stance detection and fact checking in a uni\ufb01ed corpus.\nInProceedings of the 16th Annualw Conference of the North American Chapter of the\nAssociation for Computational Linguistics , NAACL-HLT \u201918, New Orleans, LA, USA.\nAnja Belz and Ehud Reiter. 2006. Comparing automatic and human evaluation of NLG\nsystems. In Proceedings of European Chapter of the Association for Computational\nLinguistics , Trento, Italy. Association for Computational Linguistics.\nEmily M. Bender and Batya Friedman. 2018. Data statements for natural language pro-\ncessing: Toward mitigating system bias and enabling better science. Transactions of the\nAssociation for Computational Linguistics , 6:587\u2013604.\nTolga Bolukbasi, Kai-Wei Chang, James Y . Zou, Venkatesh Saligrama, and Adam T. Kalai.\n2016. Man is to computer programmer as woman is to homemaker? debiasing word\nembeddings. In Proceedings of Neural Information Processing Systems (NeurIPS) , pages\n4349\u20134357.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015.\nA large annotated corpus for learning natural language inference. In Proceedings of the\n2015 Conference on Empirical Methods in Natural Language Processing , pages 632\u2013642,\nLisbon, Portugal. Association for Computational Linguistics.\n107\nMassimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, and\nLaurent Charlin. 2020. Language gans falling short. In Proceedings of the International\nConference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,\n2020 . OpenReview.net.\nAylin Caliskan, Joanna J. Bryson, and Arvind Narayanan. 2017. Semantics derived automat-\nically from language corpora contain human-like biases. Science , 356(6334):183\u2013186.\nRich Caruana. 1997. Multitask learning. Mach. Learn. , 28(1):41\u201375.\nSahil Chopra, Saachi Jain, and John Merriman Sholar. 2017. Towards automatic identi\ufb01ca-\ntion of fake news: Headline-article stance detection with lstm attention models.\nKevin Clark, Minh-Thang Luong, Christopher D. Manning, and Quoc V . Le. 2019. Bam!\nborn-again multi-task networks for natural language understanding. In ACL.\nSt\u00e9phane Clinchant and Eric Gaussier. 2010. Information-based models for ad hoc ir.\nInProceedings of the 33rd International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval , SIGIR\u201910, pages 234\u2013241, New York, NY , USA.\nACM.\nPatricia Hill Collins. 2004. Black sexual politics: African Americans, gender, and the new\nracism . Routledge.\nRonan Collobert and Jason Weston. 2008. A uni\ufb01ed architecture for natural language\nprocessing: Deep neural networks with multitask learning. In Proceedings of the 25th\nInternational Conference on Machine Learning , ICML \u201908, pages 160\u2013167, New York,\nNY , USA. ACM.\nAlexis Conneau, Douwe Kiela, Holger Schwenk, Lo\u00efc Barrault, and Antoine Bordes. 2017.\nSupervised learning of universal sentence representations from natural language inference\ndata. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language\nProcessing , pages 670\u2013680, Copenhagen, Denmark. Association for Computational\nLinguistics.\nAlexander M Czopp, Aaron C Kay, and Sapna Cheryan. 2015. Positive stereotypes are\npervasive and powerful. Perspectives on Psychological Science , 10(4):451\u2013463.\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc Le, and Ruslan Salakhutdi-\nnov. 2019. Transformer-XL: Attentive language models beyond a \ufb01xed-length context. In\nProceedings of the 57th Annual Meeting of the Association for Computational Linguistics ,\npages 2978\u20132988, Florence, Italy. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019a. BERT: Pre-\ntraining of deep bidirectional transformers for language understanding. In Proceedings of\nthe 2019 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.\n108\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019b. BERT: Pre-\ntraining of deep bidirectional transformers for language understanding. In Proceedings\nof North American Chapter of the Association for Computational Linguistics , pages\n4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.\nDjellel Difallah, Elena Filatova, and Panos Ipeirotis. 2018. Demographics and dynamics of\nmechanical turk workers. In Proceedings of the ACM International Conference on Web\nSearch and Data Mining , WSDM \u201918, pages 135 \u2013 143, New York, NY , USA. Association\nfor Computing Machinery.\nBill Dolan and Chris Brockett. 2005. Automatically constructing a corpus of sentential para-\nphrases. In Third International Workshop on Paraphrasing (IWP2005) . Asia Federation\nof Natural Language Processing.\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical neural story generation. In\nProceedings of the Association for Computational Linguistics , pages 889\u2013898, Melbourne,\nAustralia. Association for Computational Linguistics.\nWei Fang, Moin Nadeem, Mitra Mohtarami, and James Glass. 2019. Neural multi-task learn-\ning for stance prediction. In Proceedings of the Second Workshop on Fact Extraction and\nVERi\ufb01cation (FEVER) , Hong Kong, China. Association for Computational Linguistics.\nDavid Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2003. English gigaword. Linguistic\nData Consortium, Philadelphia , 4(1):34.\nAndreas Hanselowski, Avinesh PVS, Benjamin Schiller, Felix Caspelherr, Debanjan Chaud-\nhuri, Christian M. Meyer, and Iryna Gurevych. 2018. A retrospective analysis of the\nfake news challenge stance-detection task. In Proceedings of the 27th International\nConference on Computational Linguistics , pages 1859\u20131874, Santa Fe, New Mexico,\nUSA. Association for Computational Linguistics.\nKazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, and Richard Socher. 2017. A\njoint many-task model: Growing a neural network for multiple NLP tasks. In Proceedings\nof the 2017 Conference on Empirical Methods in Natural Language Processing , pages\n1923\u20131933, Copenhagen, Denmark. Association for Computational Linguistics.\nTatsunori Hashimoto, Hugh Zhang, and Percy Liang. 2019. Unifying human and statistical\nevaluation for natural language generation. In Proceedings of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies , pages\n1689\u20131701, Minneapolis, Minnesota. Association for Computational Linguistics.\nTianxing He and James R. Glass. 2019. Negative training for neural dialogue response\ngeneration. CoRR , abs/1903.02134.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case\nof neural text degeneration. In Proceedings of the International Conference on Learning\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 . OpenReview.net.\n109\nJeremy Howard and Sebastian Ruder. 2018. Universal Language Model Fine-tuning for Text\nClassi\ufb01cation. In Proceedings of the Association for Computational Linguistics , pages\n328\u2013339, Melbourne, Australia. Association for Computational Linguistics.\nDaphne Ippolito, Daniel Duckworth, Chris Callison-Burch, and Douglas Eck. 2020. Auto-\nmatic detection of generated text is easiest when humans are fooled. In Proceedings of\nthe Association for Computational Linguistics , pages 1808\u20131822, Online. Association for\nComputational Linguistics.\nMilos Jakubicek, Adam Kilgarriff, V ojtech Kovar, Pavel Rychly, and Vit Suchomel. 2013.\nThe tenten corpus family. In Proceedings of the International Corpus Linguistics Confer-\nence CL .\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon\nChild, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for\nneural language models.\nGeorgi Karadzhov, Preslav Nakov, Llu\u00eds M\u00e0rquez, Alberto Barr\u00f3n-Cede\u00f1o, and Ivan Koy-\nchev. 2017. Fully automated fact checking using external sources. In Proceedings of\nthe International Conference Recent Advances in Natural Language Processing, RANLP\n2017 , pages 344\u2013353. INCOMA Ltd.\nAdam Kilgarriff. 2009. Simple maths for keywords. In Proceedings of the Corpus Linguistics\nConference 2009 (CL2009) , page 171.\nDiederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization.\narXiv e-prints , page arXiv:1412.6980.\nSvetlana Kiritchenko and Saif Mohammad. 2018. Examining Gender and Race Bias in Two\nHundred Sentiment Analysis Systems. In Proceedings of Joint Conference on Lexical\nand Computational Semantics , pages 43\u201353.\n\u02d9Ilker Kocaba\u00b8 s, Bekir Taner Din\u00e7er, and Bahar Karao \u02d8glan. 2014. A nonparametric term\nweighting method for information retrieval based on measuring the divergence from\nindependence. Inf. Retr. , 17(2):153\u2013176.\nKeita Kurita, Nidhi Vyas, Ayush Pareek, Alan W Black, and Yulia Tsvetkov. 2019. Measur-\ning bias in contextualized word representations. In Proceedings of the First Workshop on\nGender Bias in Natural Language Processing , pages 166\u2013172, Florence, Italy. Association\nfor Computational Linguistics.\nNayeon Lee, Chien-Sheng Wu, and Pascale Fung. 2018. Improving large-scale fact-checking\nusing decomposable attention models and lexical tagging. In Proceedings of the 2018\nConference on Empirical Methods in Natural Language Processing , pages 1133\u20131138.\nAssociation for Computational Linguistics.\nBing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: Analyzing and\ncomparing opinions on the web. In Proceedings of the 14th International Conference on\nWorld Wide Web , pages 342\u2013351, Chiba, Japan.\n110\nXiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019. Multi-task deep\nneural networks for natural language understanding. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Linguistics , pages 4487\u20134496, Florence,\nItaly. Association for Computational Linguistics.\nXiaodong Liu, Yelong Shen, Kevin Duh, and Jianfeng Gao. 2018. Stochastic answer\nnetworks for machine reading comprehension. In Proceedings of the 56th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1694\u2013\n1704. Association for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy,\nMike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly\nOptimized BERT Pretraining Approach. arXiv e-prints , page arXiv:1907.11692.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy,\nMike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly\noptimized bert pretraining approach. arXiv preprint arXiv:1907.11692 .\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y . Ng, and Christo-\npher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the\n49th Annual Meeting of the Association for Computational Linguistics: Human Language\nTechnologies , pages 142\u2013150, Portland, Oregon, USA. Association for Computational\nLinguistics.\nThomas Manzini, Lim Yao Chong, Alan W Black, and Yulia Tsvetkov. 2019. Black is\nto criminal as caucasian is to police: Detecting and removing multiclass bias in word\nembeddings. In Proceedings of the North American Chapter of the Association for\nComputational Linguistics , pages 615\u2013621, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nChandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, and Rachel Rudinger. 2019.\nOn measuring social biases in sentence encoders. In Proceedings of the North American\nChapter of the Association for Computational Linguistics , pages 622\u2013628, Minneapolis,\nMinnesota. Association for Computational Linguistics.\nBryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. 2017. Learned\nin translation: Contextualized word vectors. In I. Guyon, U. V . Luxburg, S. Bengio,\nH. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural\nInformation Processing Systems 30 , pages 6294\u20136305. Curran Associates, Inc.\nStephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2017. Pointer\nsentinel mixture models. In Proceedings of the International Conference on Learning\nRepresentations . OpenReview.net.\nTodor Mihaylov, Georgi Georgiev, and Preslav Nakov. 2015. Finding opinion manipulation\ntrolls in news community forums. In Proceedings of the Nineteenth Conference on Com-\nputational Natural Language Learning , pages 310\u2013314. Association for Computational\nLinguistics.\n111\nTodor Mihaylov and Preslav Nakov. 2016. Hunting for troll comments in news community\nforums. In Proceedings of the 54th Annual Meeting of the Association for Computational\nLinguistics , pages 399\u2013405, Berlin, Germany.\nTsvetomila Mihaylova, Preslav Nakov, Lluis Marquez, Alberto Barron-Cedeno, Mitra\nMohtarami, Georgi Karadzhov, and James Glass. 2018. Fact checking in community\nforums. In Proceedings of the Thirty-Second AAAI Conference on Arti\ufb01cial Intelligence ,\npages 5309\u20135316, New Orleans, LA, USA.\nTomas Mikolov, Martin Kara\ufb01\u00e1t, Luk\u00e1s Burget, Jan Cernock\u00fd, and Sanjeev Khudanpur. 2010.\nRecurrent neural network based language model. In Proceedings of the International\nSpeech Communication Association , pages 1045\u20131048.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Dis-\ntributed representations of words and phrases and their compositionality. In Proceedings\nof Neural Information Processing Systems (NeurIPS) , NIPS 13, pages 3111 \u2013 3119, Red\nHook, NY , USA. Curran Associates Inc.\nMitra Mohtarami, Ramy Baly, James Glass, Preslav Nakov, Llu\u00eds M\u00e0rquez, and Alessandro\nMoschitti. 2018a. Automatic stance detection using end-to-end memory networks. In\nProceedings of the 16th Annualw Conference of the North American Chapter of the\nAssociation for Computational Linguistics , NAACL-HLT \u201918, New Orleans, LA, USA.\nMitra Mohtarami, Ramy Baly, James Glass, Preslav Nakov, Llu\u00eds M\u00e0rquez, and Alessandro\nMoschitti. 2018b. Automatic stance detection using end-to-end memory networks. In\nProceedings of the 2018 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) ,\npages 767\u2013776, New Orleans, Louisiana. Association for Computational Linguistics.\nMitra Mohtarami, James Glass, and Preslav Nakov. 2019. Contrastive language adaptation\nfor cross-lingual stance detection. In Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) , Hong Kong, China.\nMoin Nadeem, Anna Bethke, and Siva Reddy. 2020a. Stereoset: Measuring stereotypical\nbias in pretrained language models.\nMoin Nadeem, Wei Fang, Brian Xu, Mitra Mohtarami, and James Glass. 2019. Fakta: An\nautomatic end-to-end fact checking system.\nMoin Nadeem, Tianxing He, Kyunghyun Cho, and James Glass. 2020b. A systematic\ncharacterization of sampling algorithms for open-ended language generation.\nPreslav Nakov, Tsvetomila Mihaylova, Llu\u0131s Marquez, Yashkumar Shiroya, and Ivan Koy-\nchev. 2017. Do not trust the trolls: Predicting credibility in community question answering\nforums. In Proceedings of the International Conference Recent Advances in Natural\nLanguage Processing (RANLP) , pages 551\u2013560.\n112\nCourtney Napoles, Matthew Gormley, and Benjamin Van Durme. 2012. Annotated Gigaword.\nInProceedings of the Joint Workshop on Automatic Knowledge Base Construction and\nWeb-scale Knowledge Extraction (AKBC-WEKEX) , pages 95\u2013100, Montr\u00e9al, Canada.\nAssociation for Computational Linguistics.\nAn Nguyen, Aditya Kharosekar, Matthew Lease, and Byron Wallace. 2018. An interpretable\njoint graphical model for fact-checking from crowds. In AAAI Conference on Arti\ufb01cial\nIntelligence .\nBrian Nosek, Mahzarin Banaji, and Anthony Greenwald. 2002. Math = male, me = female,\ntherefore math != me. Journal of personality and social psychology , 83:44\u201359.\nNicole O\u2019Brien, Sophia Latessa, Georgios Evangelopoulos, and Xavier Boix. 2018. The\nlanguage of fake news: Opening the black-box of deep learning based detectors. In\nProceedings of the Thirty-second Annual Conference on Neural Information Processing\nSystems (NeurIPS)\u2013AI for Social Good .\nSinno Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. IEEE Trans. on\nKnowl. and Data Eng. , 22(10):1345\u20131359.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method\nfor automatic evaluation of machine translation. In Proceedings of the Association for\nComputational Linguistics , pages 311\u2013318, Philadelphia, Pennsylvania, USA. Association\nfor Computational Linguistics.\nJeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vec-\ntors for word representation. In Proceedings of Empirical Methods in Natural Language\nProcessing (EMNLP) , pages 1532\u20131543.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton\nLee, and Luke Zettlemoyer. 2018a. Deep contextualized word representations. In\nProceedings of the 2018 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) ,\npages 2227\u20132237, New Orleans, Louisiana.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee,\nand Luke Zettlemoyer. 2018b. Deep Contextualized Word Representations. In Proceed-\nings of the North American Chapter of the Association for Computational Linguistics) ,\npages 2227\u20132237. Association for Computational Linguistics.\nKashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, and Gerhard Weikum. 2017. Where\nthe truth lies: Explaining the credibility of emerging claims on the web and social media.\nInProceedings of the 26th International Conference on World Wide Web Companion ,\nWWW \u201917 Companion, pages 1003\u20131012, Republic and Canton of Geneva, Switzerland.\nMartin Potthast, Matthias Hagen, Tim Gollub, Martin Tippmann, Johannes Kiesel, Paolo\nRosso, Efstathios Stamatatos, and Benno Stein. 2013. Overview of the 5th international\ncompetition on plagiarism detection. In Working Notes for CLEF 2013 Conference ,\nValencia, Spain, September 23-26, 2013.\n113\nAlec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019a.\nLanguage models are unsupervised multitask learners.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever.\n2018. Language models are unsupervised multitask learners.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever.\n2019b. Language models are unsupervised multitask learners. OpenAI Blog , 1(8).\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD:\n100,000+ questions for machine comprehension of text. In Proceedings of the 2016\nConference on Empirical Methods in Natural Language Processing , pages 2383\u20132392,\nAustin, Texas. Association for Computational Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana V olkova, and Yejin Choi. 2017.\nTruth of varying shades: Analyzing language in fake news and political fact-checking.\nInProceedings of the 2017 Conference on Empirical Methods in Natural Language\nProcessing , pages 2921\u20132927.\nMarta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic\nmodels for analyzing and detecting biased language. In Proceedings of the 51st Annual\nMeeting of the Association for Computational Linguistics , pages 1650\u20131659, So\ufb01a,\nBulgaria.\nHongyu Ren, Weihua Hu, and Jure Leskovec. 2020. Query2box: Reasoning over knowledge\ngraphs in vector space using box embeddings.\nBenjamin Riedel, Isabelle Augenstein, Georgios P. Spithourakis, and Sebastian Riedel.\n2017a. A simple but tough-to-beat baseline for the fake news challenge stance detection\ntask. CoRR , abs/1707.03264.\nBenjamin Riedel, Isabelle Augenstein, Georgios P Spithourakis, and Sebastian Riedel.\n2017b. A simple but tough-to-beat baseline for the Fake News Challenge stance detection\ntask. ArXiv:1707.03264 .\nEllen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions.\nInProceedings of the Conference on Empirical Methods in Natural Language Processing ,\npages 105\u2013112, Sapporo, Japan.\nStephen E. Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, and Mike\nGatford. 1994. Okapi at trec-3. In TREC , pages 109\u2013126. National Institute of Standards\nand Technology (NIST).\nAnna Rohrbach, Lisa Anne Hendricks, Kaylee Burns, Trevor Darrell, and Kate Saenko.\n2018. Object hallucination in image captioning. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language Processing , pages 4035\u20134045, Brussels,\nBelgium. Association for Computational Linguistics.\n114\nSebastian Ruder, Joachim Bingel, Isabelle Augenstein, and Anders S\u00f8gaard. 2017. Latent\nmulti-task architecture learning.\nRachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van Durme. 2018.\nGender bias in coreference resolution. In Proceedings of North American Chapter of the\nAssociation for Computational Linguistics (NAACL) , pages 8\u201314.\nVictor Sanh, Thomas Wolf, and Sebastian Ruder. 2018. A hierarchical multi-task approach\nfor learning embeddings from semantic tasks. CoRR , abs/1811.06031.\nRico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine translation\nof rare words with subword units. In Proceedings of the Association for Computa-\ntional Linguistics , pages 1715\u20131725, Berlin, Germany. Association for Computational\nLinguistics.\nEmily Sheng, Kai-Wei Chang, Premkumar Natarajan, and Nanyun Peng. 2019. The woman\nworked as a babysitter: On biases in language generation. In Proceedings of the Empirical\nMethods in Natural Language Processing and the International Joint Conference on\nNatural Language Processing (EMNLP-IJCNLP) , pages 3407\u20133412, Hong Kong, China.\nAssociation for Computational Linguistics.\nPrashant Shiralkar, Alessandro Flammini, Filippo Menczer, and Giovanni Luca Ciampaglia.\n2017. Finding streams in knowledge graphs to support fact checking. arXiv preprint\narXiv:1708.07239 .\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew\nNg, and Christopher Potts. 2013. Recursive deep models for semantic compositional-\nity over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical\nMethods in Natural Language Processing , pages 1631\u20131642, Seattle, Washington, USA.\nAssociation for Computational Linguistics.\nAnders S\u00f8gaard and Yoav Goldberg. 2016. Deep multi-task learning with low level tasks\nsupervised at lower layers. In Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 2: Short Papers) , pages 231\u2013235, Berlin, Germany.\nAssociation for Computational Linguistics.\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018a.\nFever: a large-scale dataset for fact extraction and veri\ufb01cation. In Proceedings of the\n2018 Conference of the North American Chapter of the Association for Computational\nLinguistics (HLT-NAACL) , pages 809\u2013819.\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018b.\nFEVER: a large-scale dataset for fact extraction and VERi\ufb01cation. In Proceedings of the\n2018 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long Papers) , pages 809\u2013819,\nNew Orleans, Louisiana. Association for Computational Linguistics.\n115\nAmos Tversky and Daniel Kahneman. 1974. Judgment under uncertainty: Heuristics and\nbiases. science , 185(4157):1124\u20131131.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N\nGomez, \u0141 ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In I. Guyon,\nU. V . Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett,\neditors, Advances in Neural Information Processing Systems 30 , pages 5998\u20136008. Curran\nAssociates, Inc.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online.\nScience , 359(6380):1146\u20131151.\nDenny Vrande \u02c7ci\u00b4c and Markus Kr\u00f6tzsch. 2014. Wikidata: A free collaborative knowledge-\nbase. Commun. ACM , 57(10):78\u201385.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. 2019a. Superglue: A stickier benchmark for\ngeneral-purpose language understanding systems. In Advances in Neural Information\nProcessing Systems , volume 32, pages 3266\u20133280. Curran Associates, Inc.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R.\nBowman. 2019b. GLUE: A multi-task benchmark and analysis platform for natural\nlanguage understanding. In the Proceedings of ICLR.\nWilliam Yang Wang. 2017. \u201cliar, liar pants on \ufb01re\u201d: A new benchmark dataset for fake\nnews detection. In Proceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics (Volume 2: Short Papers) , pages 422\u2013426. Association for\nComputational Linguistics.\nSean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, and Kyunghyun Cho.\n2020. Consistency of a recurrent language model with respect to incomplete decoding.\nCoRR , abs/2002.02492.\nAdina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge\ncorpus for sentence understanding through inference. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Papers) , pages 1112\u20131122.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, An-\nthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, and Jamie Brew.\n2019. Huggingface\u2019s transformers: State-of-the-art natural language processing. CoRR ,\nabs/1910.03771.\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V . Le, Mohammad Norouzi, Wolfgang\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva\nShah, Melvin Johnson, Xiaobing Liu, \u0141ukasz Kaiser, Stephan Gouws, Yoshikiyo Kato,\nTaku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff\nYoung, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff\n116\nHughes, and Jeffrey Dean. 2016. Google\u2019s Neural Machine Translation System: Bridging\nthe Gap between Human and Machine Translation. arXiv e-prints , page arXiv:1609.08144.\nBrian Xu, Mitra Mohtarami, and James Glass. 2018. Adversarial doman adaptation for\nstance detection. In Proceedings of the Thirty-second Annual Conference on Neural\nInformation Processing Systems (NIPS)\u2013Continual Learning .\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V .\nLe. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding.\narXiv e-prints , page arXiv:1906.08237.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V\nLe. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In\nH. Wallach, H. Larochelle, A. Beygelzimer, F. d\u2019e Buc, E. Fox, and R. Garnett, editors,\nProceedings of Neural Information Processing Systems (NeurIPS) , pages 5753\u20135763.\nCurran Associates, Inc.\nLantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2016. Seqgan: Sequence generative\nadversarial nets with policy gradient. CoRR , abs/1609.05473.\nChengxiang Zhai and John Lafferty. 2001. A study of smoothing methods for language\nmodels applied to ad hoc information retrieval. In Proceedings of the 24th Annual\nInternational ACM SIGIR Conference on Research and Development in Information\nRetrieval , SIGIR\u201901, pages 334\u2013342, New York, NY , USA. ACM.\nHugh Zhang, Daniel Duckworth, Daphne Ippolito, and Arvind Neelakantan. 2020a. Trading\noff diversity and quality in natural language generation.\nYizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett, and Bill\nDolan. 2018. Generating informative and diverse conversational responses via adversarial\ninformation maximization. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-\nBianchi, and R. Garnett, editors, Proceedings of Neural Information Processing Systems\n31, pages 1810\u20131820. Curran Associates, Inc.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng\nGao, Jingjing Liu, and Bill Dolan. 2020b. DIALOGPT : Large-scale generative pre-\ntraining for conversational response generation. In Proceedings of the Association for\nComputational Linguistics: System Demonstrations , pages 270\u2013278, Online. Association\nfor Computational Linguistics.\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gen-\nder Bias in Coreference Resolution: Evaluation and Debiasing Methods. In Proceedings\nof North American Chapter of the Association for Computational Linguistics , pages\n15\u201320.\nYaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu.\n2018. Texygen: A benchmarking platform for text generation models. In Proceedings of\nthe Conference on Research & Development in Information Retrieval , pages 1097\u20131100.\nACM.\n117\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio\nTorralba, and Sanja Fidler. 2015a. Aligning books and movies: Towards story-like\nvisual explanations by watching movies and reading books. In The IEEE International\nConference on Computer Vision (ICCV) .\nYukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio\nTorralba, and Sanja Fidler. 2015b. Aligning books and movies: Towards story-like visual\nexplanations by watching movies and reading books.\nNeta Zmora, Guy Jacob, and Gal Novik. 2018. Neural network distiller. Available at\nhttps://doi.org/10.5281/zenodo.1297430.\n118", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "On factuality in neural language models", "author": ["M Nadeem"], "pub_year": "2021", "venue": "NA", "abstract": "In the past several years, language modeling has made significant advances on artificial  benchmarks. However, despite these advancements, language models still face significant"}, "filled": false, "gsrank": 260, "pub_url": "https://dspace.mit.edu/handle/1721.1/130705", "author_id": ["elGHiKkAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:s3JrCOn_dw8J:scholar.google.com/&output=cite&scirp=259&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D250%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=s3JrCOn_dw8J&ei=MrWsaIHlAr_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:s3JrCOn_dw8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://dspace.mit.edu/bitstream/handle/1721.1/130705/1251800584-MIT.pdf?sequence=1&isAllowed=y"}}, {"title": "Team Howard Beale at SemEval-2019 Task 4: hyperpartisan news detection with BERT", "year": "2019", "pdf_data": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019) , pages 1007\u20131011\nMinneapolis, Minnesota, USA, June 6\u20137, 2019. \u00a92019 Association for Computational Linguistics1007Team Howard Beale at SemEval-2019 Task 4: Hyperpartisan News\nDetection with BERT\nOsman Mutlu\u0003\nKoc \u00b8 University\n\u02d9Istanbul, Sar\u0131yer\nomutlu@ku.edu.trOzan Arkan Can\u0003\nKoc \u00b8 University\n\u02d9Istanbul, Sar\u0131yer\nocan13@ku.edu.trErenay Dayan\u0131k\nUniversity of Stuttgart\nStuttgart\nerenaydayanik@gmail.com\nAbstract\nThis paper describes our system for SemEval-\n2019 Task 4: Hyperpartisan News Detection\n(Kiesel et al., 2019). We use pretrained BERT\n(Devlin et al., 2018) architecture and investi-\ngate the effect of different \ufb01ne tuning regimes\non the \ufb01nal classi\ufb01cation task. We show that\nadditional pretraining on news domain im-\nproves the performance on the Hyperpartisan\nNews Detection task. Our system1ranked 8th\nout of 42 teams with 78.3% accuracy on the\nheld-out test dataset.\n1 Introduction\nWith the rapid spread of the Internet and next-\ngeneration media development, people started to\nfollow news through the Internet by abandoning\nde facto sources such as television and radio. Re-\ncent studies reveal that 43% of Americans report\noften getting news online (Shearer and Gottfried,\n2017). In parallel with that, there also has been\na massive improvement in the NLP research in\nnews domain to keep the content true, fair and\nunbiased. SemEval-2019 Task 4: Hyperpartisan\nNews Detection, is yet another attempt under this\nobjective. Hyperpartisan is de\ufb01ned as being ex-\ntremely biased in favor of a political party (Bastos\nand Mercea, 2017) and the aim of the shared task\nis to detect hyperpartisan argumentation in news\ntext. Though it is an important task by itself, hy-\nperpartisan argument detection is also considered\nas a very \ufb01rst step (or even replacement) of fake\nnews detection, because it has been shown by (Pot-\nthast et al., 2018) that there is a high positive cor-\nrelation between having a hyperpartisan argumen-\ntation and being fake for news items.\nIn this shared task, we seek to model this prob-\nlem as a text classi\ufb01cation task. In general, the\n\u0003equal contribution\n1https://github.com/ozanarkancan/hyperpartisantask aims to label the text in the question with\none or more classes or categories. The main ques-\ntion of text classi\ufb01cation is how to mathematically\nrepresent the words/tokens such that they retain\ntheir original meaning in the context they appear.\nThis question has been tried to be answered in\nmany different ways so far. In earlier work, peo-\nple mainly used the \u201dbag of words\u201d approach in\nalgorithms such as Naive Bayes, Decision Tree,\nand SVM. Then, (Mikolov et al., 2013) advanced\nthe \ufb01eld further by introducing word embeddings,\ncapturing a somewhat meaningful representation\nof words. However, recent studies (Peters et al.,\n2018; Radford et al., 2018; Devlin et al., 2018)\nshowed that contextual word embeddings perform\nquite better than traditional word embeddings in\nmany different NLP tasks as a result of their supe-\nrior capacity of meaning representation. Among\nthose, BERT attracts researchers most because\nof (i) its transformer based architecture enabling\nfaster training and (ii) state of the art results in\nmany different tasks.\nThough it is quite new, BERT has been tried in\nmany different domains than the one proposed in\nDevlin et al. (2018). However, almost all of these\nstudies have two things in common: they don\u2019t\nstart training BERT from scratch and the target do-\nmain contains very limited data (Zhu et al., 2018;\nYang et al., 2019; Alberti et al., 2019). In this\nstudy, on the other hand, we address (1) the per-\nformance of BERT by comparing its domain spe-\nci\ufb01c pre-trained and \ufb01ne-tuned performances, and\n(2) in the setting where the target domain has ex-\ntensively more data. In the following sections, we\n\ufb01rst summarize the BERT architecture, then give\ndetails of shared task data set, and then describe\nexperimental setups we used to train BERT model.\nIn the results section, we compare the performance\nof BERT under different settings and share our\nsubmission results for the shared task.\n10082 Method\nTransformer2(Vaswani et al., 2017) originally\ncame out as a machine translation architecture and\nit uses the idea of self attention mechanism (Parikh\net al., 2016; Lin et al., 2017). It has an encoder-\ndecoder design and both parts use the same novel\nmulti-head attention mechanism. The encoder part\ntakes an input sentence and derives a representa-\ntion from it using this attention mechanism. Af-\nterwards, the decoder generates the target sentence\nby performing multi-headed attention over the en-\ncoder stack.\nFigure 1: BERT Architecture (Devlin et al., 2018).\nFigure 1 illustrates the architecture of the\nmodel. BERT learns bidirectional representations\njointly on both left and right context of text mak-\ning use of the encoder part of the Transformer.\nDevlin et al. (2018) introduced two unsupervised\ntasks to pretrain this architecture, Next Sentence\nPrediction and Masked Language Modeling. In\nNext Sentence Prediction task, the goal is to deter-\nmine whether the sentence comes after the spec-\ni\ufb01ed previous sentence or not. It takes two sen-\ntences as input, the latter being in its original form\n50% of the time, while other times it can be any\nrandom sentence from the corpus. In Masked Lan-\nguage Modeling task, 15% of the words in the in-\nput sentences are masked and the model tries to\npredict these words. Training takes place with the\ncombined loss of these two unsupervised tasks.\nResulting representations can be further \ufb01ne-tuned\nwith a task speci\ufb01c layer on the top for a number\nof NLP tasks using appropriate supervised data.\n2http://nlp.seas.harvard.edu/2018/04/03/attention.htmlIn this study, we use an open source PyTorch\nimplementation3of BERT architecture. We make\nuse of BERT-Base pretrained model provided by\nDevlin et al. (2018) in order to avoid pretraining\nfrom scratch. Similar to Devlin et al. (2018), we\nuse the representation obtained from the last layer\nfor the \ufb01rst token (i.e. \u201d[CLS]\u201d) for the sentence\nrepresentation and a softmax classi\ufb01er on top of it\nfor predicting hyperpartisanship.\n3 Experiments\nIn this section, we \ufb01rst introduce data provided\nby the shared task and the data preprocessing\nstep. Then, we give the details of our experiments\nand results with BERT under pretraining and \ufb01ne-\ntuning settings.\n3.1 Data\nTask provides data that consist of 750.000 articles\nlabelled portal-wise and 645 articles labelled man-\nually, and they divide the former into 600.000 and\n150.000 as train and development set. Portal-wise\ndata is labelled as hyperpartisan or not, according\nto publishers known af\ufb01nities provided by Buz-\nzFeed journalists or MediaBiasFactCheck.com. In\nour experiments, we \ufb01rst shuf\ufb02ed and then split\nthe portal-wise data into three: 705.000, 40.000,\n5.000 articles for train, development and test re-\nspectively.\n3.2 Preprocessing\nFor all our experiments we remove some un-\nwanted text from the articles. We replaced HTML\ncharacter reference for ampersand and numeric\nentity reference, and removed adjacent underscore\ncharacters which is possibly used as a replace-\nment for classi\ufb01ed information in data. We also\nremoved lines, solely containing \u201d*\u201d characters,\nused for separation of different news in the same\narticle.\n3.3 Input Representation\nBERT restricts the input length to a maximum of\n512 tokens. We select the \ufb01rst ntokens from\nthe beginning of the article, because using the\nlead sentences of a news article has been found\nto be more effective for some NLP tasks (Wasson,\n1998). We use the same tokenization method and\nembeddings as Devlin et al. (2018) to represent the\nwords.\n3https://github.com/huggingface/pytorch-pretrained-\nBERT\n10093.4 Fine-tuning Only\nIn order to show how BERT performs in news do-\nmain, our \ufb01rst attempt was to use the training data\nto only \ufb01ne-tune the pretrained model for classi-\n\ufb01cation. We used BERT-Base which consists of\n12 transformer blocks on top of each other apply-\ning 12 headed attention mechanism, hidden size\nof 768 and a total of 110 million parameters. We\nset 16 as our batch size and 2e-5 as our learning\nrate as recommended by Devlin et al. (2018) for\n\ufb01ne-tuning on classi\ufb01cation tasks.\nMax Length Dev Test\nAccuracy F1 Accuracy F1\n128 84.99 84.91 84.40 84.36\n256 88.91 88.89 88.31 88.31\n512 89.12 89.09 88.15 88.14\nTable 1: Classi\ufb01cation results on our portal-wise data\nsplits with \ufb01ne-tuned BERT.\nWe performed experiments using 128, 256 and\n512 as our maximum sequence lengths and found\nout that 256 gives us the best test results, as shown\nin Table 1. Although the results for experiments\nwith maximum sequence lengths of 256 and 512\nare relatively close to each other, we chose 256\nfor computational ef\ufb01ciency. From these results,\nwe can argue that for news articles, the \ufb01rst 128\ntokens do not carry enough information.\n3.5 Pretraining + Fine-tuning\nFor the pretraining step, the data used by two unsu-\npervised tasks need to be generated. For the Next\nSentence Prediction task, originally, one would go\nover the articles sentence by sentence to gener-\nate pretraining data, but our data is not made of\nsplit sentences. To avoid using a tool for sentence\nsplitting, as it would take too much time in large\nscale, for each document from the training data,\nwe extract a chunk of text with a random length\nsampled from a uniform distribution de\ufb01ned as\nan interval between %15 and %85 of the maxi-\nmum sequence length. The reason for this is to\nmake the model more robust to non-sentential in-\nput and leave space for the second sentence. As\nthe second sentence, 50% of the time, we select\nthe chunk following the original one with a length\nthat is complementing the \ufb01rst chunk\u2019s length up\nto maximum sequence length. Other times, when\nwe need the next sentence to be random, we take\na random chunk from other documents. We ex-\ntract more than one sample from a single docu-Model Combined Loss\nBERT-Base 3.65\nOur Version 1.79\nTable 2: Results on the held-out dataset for pretraining\ntasks.\nment, avoiding overlapping between chunks. For\nMasked LM task, we follow the same approach\nwith Devlin et al. (2018).\nAt the end of pretraining data generation pro-\ncess, we accumulated near 3.5 million samples,\nonly running the process once on our train split, so\nwithout any duplication unlike Devlin et al. (2018)\nbecause of time restrictions. We also generated a\nsmall held-out dataset using our test split to use\nin evaluation. Starting from the pretrained model\nof BERT-Base instead of a cold start, we trained\nthe model with a learning rate of 3e-5 and 256\nas the maximum sequence length for 290k itera-\ntions. Table 2 presents the combined loss of two\nunsupervised tasks on the held-out data for origi-\nnal BERT-Base and further pretrained model with\nthe generated data. Results show that pretraining\nBERT further with data from an unseen domain\ngreatly increases its representational power.\nModel Dev Test\nAccuracy F1 Accuracy F1\nFine-Tuning\nOnly88.91 88.89 88.31 88.31\nPretraining\n+Fine-Tuning89.69 89.67 89.30 89.29\nTable 3: Comparison of \ufb01ne-tuning only and pretrain-\ning + \ufb01ne-tuning models.\nAfter this step, we applied the same \ufb01ne-tuning\nas previous section with the same parameters. Ta-\nble 3 demonstrates that pretraining BERT with do-\nmain speci\ufb01c data using unsupervised tasks im-\nproves the performance of the model on the su-\npervised classi\ufb01ciation task.\n4 Shared Task Results\nThe evaluation of SemEval-2019 Task 4, Hyper-\npartisan News Detection task is done through the\nonline platform of TIRA ( ?). It serves as a means\nof blind evaluation of the submitted model. Accu-\nracy is used as the of\ufb01cial evaluation metric and\nthe deciding test set is an another manually la-\nbelled news articles set named \u201dby-article-test-set\u201d\nwhich was kept hidden from the participants.\n1010Model article-test publisher-test\nAccuracy Precision Recall F1 Accuracy Precision Recall F1\nFine-Tuning (publisher)\n+ Fine-Tuning (article)78.3 83.71 70.38 76.5 63.45 67.98 50.85 58.18\nPretraining (publisher)\n+ Fine-Tuning (publisher)\n+ Fine-Tuning (article)73.4 66.81 92.99 77.76 64.15 60.64 80.6 69.21\nPretraining (publisher)\n+Fine-Tuning (publisher)60.82 57.11 86.94 68.93 67.25 62.45 86.5 72.53\nTable 4: Shared task results.\nIn our \ufb01rst attempt, we \ufb01ne-tuned BERT with\nportal-wise train split using development set to get\nthe best model. After this we further train it with\n645 manually labeled data (i.e. \u201dby-article-train-\nset\u201d), because it comes from the same sample as\ntest data.\nIn our last attempt, we pretrained BERT with\nour portal-wise train split, and then \ufb01ne-tune it as\ndescribed before. Again, we further \ufb01ne-tune our\nmodel with \u201dby-article-train-set\u201d data. The results\nof our two attempts can be seen in Table 4. The\nthird model in the table is to show the effect of the\nlast \ufb01ne-tuning step on \u201dby-article-train-set\u201d.\nLooking at the results of second and third mod-\nels on \u201dby-article-test-set\u201d shows us, although\nwe \ufb01ne-tune BERT with supervised data for\nthe same classi\ufb01cation task, \ufb01ne-tuning on \u201dby-\narticle-train-set\u201d improves the results drastically.\nThis may be rooted from the domain difference in\nbetween \u201dby-article-test-set\u201d and portal-wise train\ndata.\nAlthough our experiments (Table 3) show us\nthat pretraining BERT further with data from news\ndomain has a positive effect on overall accuracy,\nwe are not able to observe the similar effect on\n\u201dby-article-test-set\u201d. The second model adapts to\nthe publisher domain more than the \ufb01rst model\ndoes because of the extensive pretraining before\n\ufb01ne-tuning. As the difference between publisher\nand article is highly notable from the \ufb01ndings be-\nfore, over\ufb01tting to the publisher domain might end\nup hurting the generalization of the model. So,\nthis would explain the unexpected drop of per-\nformance between the second model and the \ufb01rst\nmodel.\n5 Conclusion\nWe presented a BERT baseline for the Hyperpar-\ntisan News Detection task. We demonstrated that\npretraining BERT in an unseen domain improvesthe performance of the model on the domain spe-\nci\ufb01c supervised task. We also showed that the dif-\nference in news source affects the generalization.\nOur best performing system ranked 8th out of 42\nteams with 78.3% accuracy on the held-out test\ndataset. From our \ufb01ndings, we believe that domain\nadaptation is important for the BERT architecture\nand we would like to investigate the effect of from\nscratch unsupervised pretraining on the supervised\ntask as future work.\nAcknowledgments\nWe would like to thank task organizers for their\nsupport. The study is funded by the European Re-\nsearch Council (ERC) Starting Grant 714868.\nHoward Beale\nFigure 2: Howard Beale delivering his \u201dI\u2019m as mad as\nhell\u201d speech.\nBeale4is a news anchor who decides to commit\nsuicide on live air. Instead, he gives his famous\nspeech about modern American life and convinces\nAmerican people to scream his words: \u201dI\u2019m as\nmad as hell, and I\u2019m not going to take this any\nmore!\u201d. But the media sees his breakdown as an\nopportunity for huge ratings. We believe that the\nspeech is now more than ever relevant to our me-\ndia. Choosing \u201dHoward Beale\u201d as the team name\nis our scream from the windows of Academia.\n4https://www.imdb.com/title/tt0074958/\n1011References\nChris Alberti, Kenton Lee, and Michael Collins. 2019.\nA bert baseline for the natural questions. arXiv\npreprint arXiv:1901.08634 . Version 1.\nMarco T Bastos and Dan Mercea. 2017. The\nbrexit botnet and user-generated hyperpartisan\nnews. Social Science Computer Review , page\n0894439317734157.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning.arXiv preprint arXiv:1810.04805 . Version 1.\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\nBenno Stein, and Martin Potthast. 2019. SemEval-\n2019 Task 4: Hyperpartisan News Detection. In\nProceedings of The 13th International Workshop on\nSemantic Evaluation (SemEval 2019) . Association\nfor Computational Linguistics.\nZhouhan Lin, Minwei Feng, Cicero Nogueira dos San-\ntos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua\nBengio. 2017. A structured self-attentive sentence\nembedding. arXiv preprint arXiv:1703.03130 . Ver-\nsion 1.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jef-\nfrey Dean. 2013. Ef\ufb01cient estimation of word\nrepresentations in vector space. arXiv preprint\narXiv:1301.3781 . Version 3.\nAnkur Parikh, Oscar T \u00a8ackstr \u00a8om, Dipanjan Das, and\nJakob Uszkoreit. 2016. A decomposable attention\nmodel for natural language inference. In Proceed-\nings of the 2016 Conference on Empirical Methods\nin Natural Language Processing , pages 2249\u20132255.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. In Proceedings of the 2018 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long Papers) , volume 1,\npages 2227\u20132237.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz, Ja-\nnek Bevendorff, and Benno Stein. 2018. A Stylo-\nmetric Inquiry into Hyperpartisan and Fake News.\nIn56th Annual Meeting of the Association for Com-\nputational Linguistics (ACL 2018) , pages 231\u2013240.\nAssociation for Computational Linguistics.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training. URL https://s3-\nus-west-2. amazonaws. com/openai-assets/research-\ncovers/languageunsupervised/language under-\nstanding paper. pdf .\nElisa Shearer and Jeffrey Gottfried. 2017. News use\nacross social media platforms 2017.Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , pages 5998\u20136008.\nMark Wasson. 1998. Using leading text for news sum-\nmaries: Evaluation results and implications for com-\nmercial summarization applications. In COLING\n1998 Volume 2: The 17th International Conference\non Computational Linguistics , volume 2.\nWei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen\nTan, Kun Xiong, Ming Li, and Jimmy Lin. 2019.\nEnd-to-end open-domain question answering with\nbertserini. arXiv preprint arXiv:1902.01718 . Ver-\nsion 1.\nChenguang Zhu, Michael Zeng, and Xuedong Huang.\n2018. Sdnet: Contextualized attention-based deep\nnetwork for conversational question answering.\narXiv preprint arXiv:1812.03593 . Version 5.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Team Howard Beale at SemEval-2019 Task 4: hyperpartisan news detection with BERT", "author": ["O Mutlu", "OA Can", "E Dayan\u0131k"], "pub_year": "2019", "venue": "Proceedings of the 13th \u2026", "abstract": "This paper describes our system for SemEval-2019 Task 4: Hyperpartisan News Detection (Kiesel  et al., 2019). We use pretrained BERT (Devlin et al., 2018) architecture and"}, "filled": false, "gsrank": 265, "pub_url": "https://aclanthology.org/S19-2175/", "author_id": ["jjv4kagAAAAJ", "IN-CnBUAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:87Bd49Cqo3oJ:scholar.google.com/&output=cite&scirp=264&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D260%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=87Bd49Cqo3oJ&ei=M7WsaKqxMrXCieoP4PfQ0A8&json=", "num_citations": 5, "citedby_url": "/scholar?cites=8837094707975532787&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:87Bd49Cqo3oJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/S19-2175.pdf"}}, {"title": "Examining Partisan Reporting of Critical Race Theory Using Meta's Crowd Tangle.", "year": "2023", "pdf_data": "5DOI: 10.24193/jmr.45.1\nPublished First Online: March 2023Examining Partisan Reporting\nof Critical Race \ue049eory\nUsing Meta\u2019s CrowdTangle\nChrysalis L. WRIGHT\nUniversity of Central Florida, United States of America\nE-mail: Chrysalis.Wright@ucf.edu\nBeatriz COELHO\nUniversity of Central Florida, United States of America\nCaitlyn KOERNER\nUniversity of Central Florida, United States of America\nCristina FERRER\nUniversity of Central Florida, United States of America\nCaitlin RECHDAN\nUniversity of Central Florida, United States of America\nDonna LARSON\nUniversity of Central Florida, United States of America\nAbstract.  Mainstream news media outlets can influence the opinions and attitudes \nof their audience based on how they frame information. This framing can also to polarization. Presently there exists partisan controversies and state-level legislation in the United States regarding Critical Race Theory (CRT). W e examined partisan reporting related to CRT using Meta\u2019s metrics platform, CrowdTangle and tracked Facebook posts by news media outlets from January 30, 2020, to January 30, 2022. W e \nJournal of Media Research,\nVol. 16, Issue 1(45) / 2023, pp. 5\u201332\n\n6were interested in how mainstream news media reported on CRT and wanted \nto examine significant differences in consumers interactions with posts and page following from right-leaning, left-leaning, and neutral news media outlets. W e also examined the overperformance of posts. W e identified social media accounts \nthat played a vital role in sharing content related to CRT and determined the \npotential impact of posts. W e found that right-leaning news media were more likely to post about CRT, compared to left-leaning and neutral news media out-lets, with reporting beginning in June 2020. Neutral and left-leaning news me-dia outlets began reporting on CRT months later. Our results demonstrated that right-leaning news media outlets had more followers and more post interactions. W e also found variations in user interactions based on the partisan nature of the news media. Additionally, neutral news media had higher overperformance scores compared to other outlets. Our findings will be beneficial to those involved in policy making regarding social media, media distrust, and race relations within the United States.\nKeyword:  Partisan reporting; CrowdT angle; Critical Race Theory (CR T).\nINTRODUCTION\nThe United States is currently more politically polarized than it has been during the \npast twenty years, and it is growing far more polarized than any other democracy in the world (Boxell  et al ., 2020; Pew, 2021). This divide, although seemingly just on an inter-\npersonal level, is also evident in major institutions, such as mainstream news media. As partisan lines deepen, the way in which mainstream news media reports information shifts accordingly. A single story could be bent in a multitude of directions, depending on where a news source falls on partisan lines. This can have a direct impact on the attitudes and opinions of their audience (Estrada  et al ., 2016; McKeever  et al ., 2012; Steinberg, 2004) \nbut can also lead consumers to shift towards alternative news outlets that contradict what is being shown via mainstream news out of distrust. \nThroughout the last few years, the topic of passing state-level legislation that would \nallow critical race theory (CR T) to be taught in schools took center stage in mainstream news media (Awtrey, 2021; The Economist, 2021). This topic seems to further polarize and divide citizens, leading to the importance and current relevance of examining the phe-nomenon related to mainstream news reporting on the topic. \nThe current study is unique in that we examined partisan news reporting related to CR T \nfrom right-leaning, left-leaning, and neutral mainstream news media outlets in the United States using social media data obtained from Meta\u2019s metrics platform, CrowdT angle. W e focused on a two-year period of posts on Facebook from mainstream news media outlets and examined consumer interactions with such posts as well as audience reach. W e also \n7examined differences in audience interaction with posts based on partisan stance. Our \nfindings should be beneficial to those involved in policy making regarding social media, media distrust, and race relations within the United States.\nDe\ufb01ning CRT\nIn order to properly understand CR T and its goals, one must understand what critical \ntheory as a whole stands for. Critical theory can be traced back to the Frankfurt School, a collection of German social theorists and philosophers who were influenced by Karl Marx and Sigmund Freud (Cole, 2019). What separates critical theory from traditional theory is that it takes an active stance against oppression and is fueled by the motivation to trans-form conditions that inhibit people from getting their basic needs met (Bohman, 2005). Additionally, critical theorists aim to be practical, explanatory, and normative in their ap-proach; they diagnose what is wrong with social society, identify the means to change it, and finally provide points of counterarguments against it and suggest realistic goals for transformation (Bohman, 2005). Thus, critical theory does not want to be passive and make commentary about social issues and inequalities, it is fully invested in curing societal ills and eliminating domination in all parts of life through an applied lens. \nCritical theory, however, is not solely connected to W estern European scholars. Any \napproach that aligns with the aims of critical theory is considered to be a \u201ccritical theory\u201d. Racism can be defined as prejudiced patterns of discrimination to oppress racial groups. It can be found in any institutional system, such as politics, schools, and the judicial system, as it has been ingrained in American society as a way to dismantle racial desegregation ef-forts. Thus, CR T as an academic concept was born in an attempt to dismantle racial ine-qualities and discover the intersecting aspects of race, class, and gender within these systems (Gilborn, 2015). The birth of CR T was incited by Black scholars and others in legal stud-ies, specifically at the time of the renowned American Civil Rights movements, around the 1970s and 80s (Mills & Unsworth, 2018). The coined term entailed action to dispute and alter racial politics and power relations in structural systems. Four widely accepted tenets of CR T are as follows (Beyer, 2019; George, 2021): \n1. The belief that race is not biological, but has been socially constructed and is therefore socially significant.\n2. The belief that racism has been embedded in society and its institutions; racism is a normal feature of society.\n3. The rejection of popular ideas surrounding racism, such as limiting racism to \u201ca few bad apples\u201d or using colorblind frameworks to overcome racism.\n4. The belief that scholarship needs to be connected to people\u2019s lived experiences; this could look like listening to the stories and accounts of Black people and rejecting re-search (and research methods) that exclude them. \nThough CR T has been an academic concept for 40 years, it has only recently gained \ntraction and has become a popular topic of discussion. The 1619 project, winner of the \n82020 Pulitzer Prize, was a journalistic venture that aimed to place the consequences of slav-\nery and the contributions of Black Americans in American History (Barrus, 2020), and the Zinn Education Project, which emphasizes the role of Black Americans and organized social movements that have changed the course of history (Zinn Education Project, 2023) are two recent examples of CR T in educational materials. However, neither are taught in public educational settings and are free resources accessible online. Additionally, race-based news like the rise of Black Lives Matter protests also indicates a higher trend in topics re-lated to CR T. \nCRT in the classroom \nThe emergence of CR T in the field of education started with examining the role of soci-\noeconomic status and race as it relates to inequalities presented within education (Lynn & Parker, 2006). Conversations regarding topics of CR T can be classified as taboo for many people, let alone engaging in discourse about it in a classroom setting. However, it is limited in the perspective that while race is a more than salient characteristic in the U.S., scholarly analysis and conversations pertaining to it in an educational sense remains scarce (Ladson-Billings & T ate IV , 1995). Even so, CR T has gained some traction in recent years, in which talks of equity and social justice are steadily acquiring increased attention within math-ematics education scholarship and practice (Larnell  et al ., 2016). According to Kaplan and \nOwings (2021), CR T\u2019s framework is currently being implemented in higher education, which examines and confronts issues of systematic racism in the education system, specifi-cally as they relate to colorblindness, the racial climate on campus, and selective admissions policy (Lynn & Parker, 2006). \nDiscourse about CR T\u2019s implementation in the K-12 curriculum has been contested, \nscholars tend to focus on topics regarding the curriculum, pedagogy, learning through teaching, schooling, and finance and policy as they relate to engagement in the community (Lynn & Parker, 2006). Public controversies arise in the social studies curriculum, in which CR T places importance on the inclusion of diverse perspectives in the telling of history (Kaplan & Owings, 2021). They infer that the lack of a CR T lens will lead to limitations of the truth about marginalized and muted discourse regarding CR T. Furthermore, Ledesma and Calder\u00f3n (2015) advocate for CR T in the classroom as subjects to discuss and urge the idea for more communication about social justice from a critical race point of view. With dialogue concerning CR T on the rise, it is imperative that conversations regarding the significance of teaching students the relationship between racism\u2019s detrimental effects as it pertains to law persist for progression to take place (Kaplan & Owings, 2021; Lynn & Parker, 2006).\n9Criticisms of CRT \nWhile CR T received immense support among the scholars in academia, it has also been \nheavily criticized. For instance, Subotnik (1998) discussed how Black Americans may not \u201cfare well\u201d with middle class values, such as entrepreneurship, opportunity for personal and financial development, etc., in American culture if the ideas of CR T were promoted as the truth of American society. Instead, those values would be deemed as \u201cWhite val-ues,\u201d which could lead to oppositional culture (Ogbu & Simons, 1998) where minoritized groups devalue any behavior or goal viewed as representing the majority group. More re-cent research, however, has dismantled the notion of oppositional culture, concluding that cultural agency, instead, is associated with Black students resisting \u201cacting White\u201d (Garvey, 2016).\nIn the legal system, Litowitz (1997) showcased how CR T advocates, or critics of lib-\neralism, argued that the state cannot remain neutral when it comes to free speech protec-tion since it would be considered authorizing hate speech. However, this would indicate that any ideology outside of CR T could be deemed as \u201chate speech\u201d and therefore limit freedom of speech itself by considering perspectives that only align with CR T. This idea confuses tolerance for such hate speech with the promotion of it (Litowitz, 1997). \nCritics of CR T also argued that American educational systems should focus on qualifi-\ncation and performance rather than racial status (Subotnik, 1998). This message attempts to challenge whether the implementation of affirmative action in colleges would lead to a future with qualified and successful physicians and attorneys. A common criticism in regard to CR T is the idea that racism is part of everyday life, which leads some critics to claim that the theory stands for the discrimination against White people in order to obtain equity. This is a fairly popular criticism that has been going around for centuries, where people believe that those fighting for equality are discriminating against White people (Sawchuk, 2022). \nSawchuk (2022) discussed the insecurity that comes from those on the top that feel \nthreatened by a group of people making noise and asking for change, which causes them to criticize the theory that is taking place. Overall, critics of CR T emphasize how the concept would influence underrepresented and marginalized groups to believe that they are op-pressed under the current U.S. system and teach them to reject American values because of it (Subotnik, 1998). The thought of being challenged, threatened, scared of change, and having feelings of insecurity may also contribute to some of the criticisms surrounding CR T that are primarily held by White people (Sawchuk, 2022). \nPartisan views on CRT \nPartisanship can influence the way in which CR T is portrayed in mainstream news me-\ndia. There is an ongoing debate in the current partisanship surrounding the relevance of CR T, especially in the field of education. Both the left and the right use racial profiling in \n10public policy but in different ways. The left tends to use racial profiling when it comes to \neducation (e.g., affirmative action), whereas the right tends to use racial profiling in law enforcement policies (Romero, 2003). However, compared to the right, the left is more predisposed to supporting the views held by CR T. Critical race theorists prefer to focus on liberal critiques on the status quo, involving progressive works the left usually promotes (Bracey, 2015). Similar to the left, critical race theorists favor the addition of affirmative action to educational institutions since they believe that Black Americans are actively dis-criminated against in higher education (Romero, 2003). \nOn the contrary, the right is more inclined to oppose CR T since it does not align with \ntheir individualistic traditional values, particularly in education (Han  et al ., 2018; Romero, \n2003). Those values are aligned with the aforementioned entrepreneurship, opportunity for personal and financial development, and other middle-class values (Subonik, 1998). T ate (1997) mentioned that the current education system outside of research omits ra-cial discussion and mechanisms. Therefore, there is a need for theoretical perspectives that would surpass traditional paradigmatic boundaries. Furthermore, the right tends to reject this type of ideology. Han and colleagues (2018) found that there were unequal power rela-tions between faculty of color (FOC) and the White governance in rural red-states. FOC received lower ratings from their students compared to White faculty. Additionally, the right wants to limit the government\u2019s involvement in education (Han  et al. , 2018; Romero, \n2003). They believe that the implementation of critical race teachings would require gov-ernment intervention. The right also believes that the implementation of affirmative ac-tion would strip away individual equality of opportunity. \nMETHODOLOGY \nW e examined potential partisan reporting regarding CR T via mainstream news media \nutilizing the social media platform Facebook to share news information with their online audience. Considering mainstream news often frames information presented to their audi-ence along political party lines, which can impact the opinions and attitudes of their audi-ence ( Estrada  et al ., 2016; McKeever  et al ., 2012; Steinberg, 2004), we aimed to determine \nthe current potential influence of partisan reporting related to CR T. \nW e obtained our data from CrowdT angle, Meta\u2019s metrics platform, and focused on \nreporting in the United States spanning from January 30, 2020, until January 30, 2022. We specifically focused on the United States considering the current controversies that ap-pear to be based along partisan lines as well as state-level legislation sweeping the country to combat CR T (Awtrey, 2021; The Economist, 2021). W e focused on the top five social media news outlets based on the number of posts according to CrowdT angle data for right-leaning (i.e., Daily Wire, Fox News, Breitbart, The Daily Caller, Newsmax), left-leaning (i.e., MSNBC, ABC News, HuffPost, CNN, and CBS News and USA today [tied for fifth place]), and neutral news media outlets (i.e., Newsweek, AllSides, The W all Street Journal, Axios, HILL TV) to assess specific characteristics of partisan reporting and interactions \n11with such posts. Research questions specific to the aims of this study included:\n1. What was the prevalence of online news posts related to CR T?\n2. What were the features and characteristics of the top-rated CR T news posts?\n3. How did users interact with the top-rated CR T posts?\n4. How biased was reporting on CR T from right-leaning, left-leaning, and neutral main-\nstream news outlets?\n5. How did users interact with partisan reporting related to CR T (likes, comments, shares, love, wow, haha, sad, angry, care)?\n6. What was the size of the social media audience for partisan reporting outlets?\n7. W ere there significant differences in consumer interactions based on right-leaning, left-leaning, and neutral news outlets?\n8. W ere there indications of overperformance (i.e., a post\u2019s performance relative to the number of interactions received over time compared to the account\u2019s average post performance) of social media news posts related to CR T based on right-leaning, left-leaning, and neutral news outlets?\nMethodological design\nCrowdT angle is Meta\u2019s metrics platform that was used to derive the data for this study. \nCrowdT angle gives researchers the opportunity to explore and examine public content on many social media platforms such as Facebook, Reddit, and Instagram, while being a free public insights tool from Meta (CrowdT angle, n.d.a.). It includes public posts and pages as well as profiles that have been verified on the platform. Although it gives insight to many public pages and posts, it does not allow access to posts via private groups, direct messag-ing, and private or partially private personal profiles. CrowdT angle has been able to main-tain the privacy and anonymity of its platform users while allowing us to analyze public trends of Facebook posts related to CR T. \nBetween the dates of January 30, 2020, and January 30, 2022, we searched the phrase \n\u201cCritical Race Theory\u201d on CrowdT angle to identify posts on public pages, groups, and verified user profiles that may have used the phrase. For exclusionary measures we only used posts that were published in English. W e wanted to focus on social media posts creat-ed by mainstream news platforms, achieving this via filtering posts based on page category. The page category we used to filter mainstream news outlets in CrowdT angle was \u201cMedia/News Company,\u201d which is one of the major categories that can be selected by Facebook Page administrators to self-determine their standing (Crowdtangle, n.d.b.). Facebook page categories are intended to help viewers have a better understanding of the intent of the page. Facebook Page administrators can select up to three categories when they create their Facebook page (Social Apps, n.d.). After obtaining the query, we discarded posts that ac-quired less than 30 interactions and were not in the English language.\n12Analysis\nThe analysis in the current study focused on the time frame of our searches, which \ncovered the time when CR T became well-known on social media platforms and was being reported via mainstream news media outlets. This does not mean that social media users or news media outlets have stopped posting about CR T or that they were not reporting on CR T prior to our time frame for searching. \nFor the current study, we were interested in how mainstream news media reported \non issues related to CR T and analyzed data obtained from CrowdT angle using SPSS. W e conducted a multivariate analysis of variance (MANOV A) to determine if there were any significant differences in consumers interactions with posts and page following from right-leaning, left-leaning, and neutral news media outlets. Mainstream news media outlets were classified along partisan lines based on ratings from Media Bias/Fact Check, which focuses on bias and overall factual reporting (2021a; 2021b). Media Bias/Fact Check generates a bias score and factual reporting score for each source considering political bias, factual in-formation, and the use of verifiable sources. \nIn our analysis, we examined posts related to CRT, paying attention to the news source \nof the initial post (right-leaning, left-leaning, neutral news media outlets). Consistent with previous research (Wright  et al ., 2022), this highlights the way in which news media outlets \ncan amplify online politicized content based on their partisan frame, in much the same way that partisan framing is utilized in offline mainstream media news reporting, lead-ing to polarization among consumers (see also Benedictis-Kessner  et al ., 2019). W e also \nexamined the overperformance of posts, which is a measure generated by CrowdT angle that is calculated by comparing expected post benchmarks to new posts created by the page (CrowdT angle, n.d.c). \nWhile our analysis summarizes trends regarding posts related to CR T from mainstream \nnews media outlets, we also included direct quotes and screen shots from online social media posts as well as outside resources the posts may have linked to. W e identified specific social media accounts that played a vital role in sharing content related to CR T. W e also fo-cused on the number of followers of specific social media pages, groups, and verified pro-files at the time of posting to determine the potential impact of specific posts. While this does not provide an exact account of the number of consumers who saw a particular post, it does provide a general overview of the potential impact of a specific post. Because of this and other shortcomings related to CrowdT angle, our results will likely underestimate the impact of specific social media posts. \nResults\nRight-Learning News Media\nCrowdT angle identified 1,906 posts from right-leaning mainstream news media com-\npany accounts related to CR T, with a total of 8,539,354 interactions between January 30, 2020, and January 30, 2022. It is important to note that while our start date was January \n1330, 2020, right-leaning media outlets did not begin posting about CR T until June 2020. \nInteractions with posts gradually increased from June 2020 until January 2022 (see Figure 1). The top five social media posts based on post interactions can be found in Images 1\u20134 (see Appendix).\nFigure 1 . Post Interactions and Creation Date\nThe top social media post related to CR T from right-leaning news media outlets came \nfrom Newsmax (see Image 1). The post focused on a school board meeting where a parent strongly objected to CR T in the classroom. The title of the news article was \u201cMom tears \napart school board over Critical Race Theory\u201d and the post received 348,647 total inter-\nactions among viewers. Breitbart news had the second top social media post (see Image 2). The post focused on sexual assault on a public-school campus and received 102,663 viewer interactions. The third top social media post related to CR T came from Fox News with 91,378 viewer interactions (see Image 3). The post focused on a Virginia Governor, Y oungkin, who immediately banned CR T once taking office. The fourth leading social media post also came from Fox News. The topic of this post was on Florida Governor, DeSantis, who condemned CR T (see Image 4). The post generated 83,738 viewer interac-tions. Finally, the fifth leading post was also from Fox News, with 75,003 viewer interac-tions (see Image 5). This post focused on former United States Vice President, Pence, and his statement claiming that CR T was racism. \nThe mean number of likes per post was 2,690. The page most commonly posting con-\ntent related to CR T was Daily Wire, a far-right media outlet with mixed factual reporting and known propaganda reporting (Media Bias/Fact Check, 2022a). However, posts with the most likes from viewers originated from Fox News, a right reporting outlet with mixed factual reporting and medium credibility (Media Bias/Fact, 2022b). Figure 2 shows likes \n14on posts from viewers during this time frame for right-leaning news media outlets. The \ntop five right-leaning news media outlets and information about their posts, such as likes at post, page followers at post, and overperformance measures of posts can be found in T able 1. T able 2 summarizes the interactions from viewers (i.e., likes, comments, shares, love, wow, haha, sad, angry, and care reactions) from the top five right-leaning news media outlets.\nFigure 2 . Likes on Posts from Right-Leaning News Media Outlets\nTable 1. Top Five Right-Leaning News Media Outlets\nPage Name N Posts % of PostsLikes at Post\nM (SD)Followers at Post\nM (SD)Overperformance\nM (SD)\nDaily Wire 493 25.92323231.09 \n(63367.10)3060787.03 \n(126711.74).94 (6.15)\nFox News 245 12.918759061.46 \n(55944.87)22692114.26 \n(162282.90).29 (4.15)\nBreitbart 225 11.84505478.83 \n(23049.42)5181961.68 \n(42892.38)-.89 (3.45)\nThe Daily Caller 224 11.85461968.88 \n(8398.83)6042745.59 \n(70780.70)1.34 (6.76)\nNewsmax 212 11.13323508.71 \n(145171.42)4112132.83 \n(205607.06).70 (13.46)\nTotal 1,399 73.5\n15Table 2. Interactions with Top Five Right-Leaning News Media Outlets\nPage NameTotal Interactions Likes Comments Shares Loves\nM S D M S D MS DMS DMS D\nBreitbart 7,305.96 10,717.53 4,106.20 6,696.29 844.72 1,631.54 819.61 1,817.66 396.41 802.67Daily Wire 1,705.17 3,110.51 1,061.15 2,087.12 117.44 247.87 217.80 675.23 157.85 425.69Fox News 12,060.33 15,774.62 7,748.30 11,333.97 1,466.02 1,446.60 915.77 1,621.98 1,074.74 2,328.62Newsmax 7,068.45 24,774.14 4,149.04 9,978.10 509.31 1,827.74 1,209.43 9,937.50 754.12 3,673.82The Daily Caller 3,947.71 7,133.79 2,151.46 3,832.71 384.47 723.64 585.30 1,883.28 311.62 803.47\n Wow HaHa Sad Angry Care\nM S D M S D MS DMS DMS D\nBreitbart 80.81 220.87 220.51 963.95 46.47 129.41 780.51 2,097.60 10.72 19.49\nDaily Wire 16.72 39.53 34.49 119.22 10.28 56.17 83.89 206.76 5.56 28.32Fox News 70.88 168.10 255.71 564.12 50.40 150.12 446.90 1037.63 31.61 59.71Newsmax 38.52 119.56 75.28 231.72 22.80 70.16 293.36 898.36 16.59 75.09The Daily Caller 38.43 84.47 205.62 1693.32 16.85 32.97 244.63 578.99 9.32 19.45\n16Left-Leaning News Media \nCrowdT angle identified 285 posts from left-leaning news media company accounts \nrelated to CR T, with a total of 599,292 interactions between January 2020 and January 2022. It is important to note that while our start date was January 2020, left-leaning me-dia outlets did not begin posting about CR T until September 2020, three months after right-leaning media outlets began reporting on CR T. Posts began with high interactions, followed by a decline, and then increased in January 2022 (see Figure 3). The top five social media posts based on post interactions can be found in Images 6\u201310 (see Appendix).\nFigure 3 . Post Interactions and Creation Date\nThe top social media post on CR T from left-leaning news media outlets came from \nCBS News and received 49,951 total interactions (see Image 6). The topic of the post was Virginia\u2019s governor, Y oungkin\u2019s executive actions on CR T. The second leading CR T relat-ed post was from the New Y ork Times with 33,633 total interactions. This post focused on General Milley defending military teaching related to CR T (see Image 7). The third lead-ing post was also from the New Y ork Times and received 31,684 total interactions. This post was also about General Milley and his push back regarding accusations of a \u201cwoke\u201d military (see Image 8). The fourth leading post was also a post about General Milley and came from CNN (see Image 9). This post received 24,510 total interactions from viewers. The fifth leading post related to CR T came from CNN (see Image 10) and received 17,569 total interactions. This post focused on teachers\u2019 unions defending teaching \u201chonest his-tory\u201d in the classroom.\nThe mean number of likes per post was 951.84. The page most commonly posting \ncontent related to CR T was MSNBC, a far-left media outlet with mixed factual reporting (Media Bias/Fact Check, 2022c). However, posts with the most likes originated from The \n17New Y ork Times, a left-central reporting outlet with high factual reporting (Media Bias/\nFact Check, 2022d). Figure 4 shows likes on posts from viewers during this time frame from left-leaning news media outlets. The top five left-leaning news media outlets and information about their posts, such as likes at post, page followers at post, and overper-formance measures of posts can be found in T able 3. T able 4 summarizes the interactions from viewers (i.e., likes, comments, shares, love, wow, haha, sad, angry, and care reactions) from the top five left-leaning news media outlets.\nFigure 4 . Likes on Posts from Left-Leaning News Media Outlets\nTable 3. Top Five Left-Leaning News Media Outlets\nPage Name N Posts % of PostsLikes at Post\nM (SD)Followers at Post\nM (SD)Overperformance\nM (SD)\nMSNBC 141 49.52,480,325.79 \n(815.22)2,588,998.41 \n(3,916.21)-1.03 (3.02)\nABC News 24 8.414,860,175.88 \n(60,539.26) 16,755,250.75 \n(119,090.06).90 (4.64) \nHuffPost 24 8.412,262,242.71\n(51,492.04) 12,132,507.54\n(37,087.58)  1.39 (3.56)\nCNN 23 8.134,519,833.13 \n(218,614.25) 38,398,544.65\n(417,192.32).94 (3.49)\n*CBS News 19 6.76,016,852.37 \n(9,613.59)6,916,558.68 \n(53,174.35) 5.82 (11.33) \n*USA Today 19 6.78,443,641.84 \n(50,174.87) 9,122,326.05 \n(60,069.78) -.42 (2.79) \nTotal 250 87.88,460,638.6 \n(9,128,080.24)9,166,576.51 \n(10,092,267.79).53 (5.50)\n18Table 4. Interactions with Top Five Left-Leaning News Media Outlets\nPage NameTotal Interactions Likes Comments Shares Loves\nM SD M SD M SD M SD M SD\nMSNBC 928.09 1,056.03 371.26 663.76 297.74 238.20 56.11 74.54 56.66 15.10ABC News 1,534.42 3,033.06 644.33 1,827.78 398.92 448.11 127.00 337.48 146.92 485.45HuffPost 2,268.67 2,931.43 771.38 1,704.01 651.67 605.06 176.46 357.26 92.33 301.02CNN 5,668.13 6,203.84 2,317.61 3,558.84 1,489.43 1051.35 315.70 506.42 423.09 1,009.08*CBS News 5,297.58 9,321.68 2,890.89 5,935.35 525.95 384.77 66.79 93.09 746.79 2,013.33*USA Today 1,633.74 1,776.58 779.53 660.54 346.53 401.34 134.47 126.39 74.00 128.99\nWow HaHa Sad Angry Care\nM SD M SD M SD M SD M SD\nMSNBC 8.72 13.85 40.21 62.97 21.65 62.45 73.00 149.84 2.74 4.38ABC News 11.33 21.11 21.92 21.88 9.38 18.22 170.13 432.56 4.50 10.43HuffPost 40.29 83.86 302.63 662.47 16.75 23.24 211.13 322.37 6.04 15.64CNN 88.26 147.60 304.91 273.73 157.13 295.60 551.70 1,141.62 20.30 33.38\n*CBS News 44.84 55.12 139.21 177.73 53.89 85.47 806.00 1,190.54 23.21 51.24\n*USA Today 24.53 64.32 47.05 87.31 38.32 97.67 185.47 510.88 3.84 6.32\n*Tied for 5\nth place\n19Neutral News Media\nCrowdT angle identified 196 posts from neutral news media company accounts related \nto CR T, with a total of 279,159 interactions between January 2020 and January 2022. It is important to note that while our start date was January 2020, neutral media outlets did not begin posting about CR T until September 2020, three months after right-leaning media outlets began reporting on CR T. Posts began with little interactions, followed by an increase in interactions in June 2021 and then peaking in November 2021 (see Figure 5). The top five social media posts based on post interactions can be found in Images 11\u201315 (see Appendix).\nFigure 5 . Post Interactions and Creation Date\nThe top post from neutral news media outlets related to CR T was from Newsweek and \nreceived 25,853 total interactions (see Image 11). This post focused on Bill Maher defend-ing parents\u2019 objection to the teaching of CR T. The second leading post also came from Newsweek (see Image 12) and focused on Florida\u2019s Governor, DeSantis, pushing his \u2018Stop W oke\u2019 Act. This post received 18,366 total interactions from viewers. The third leading post also focused on Florida\u2019s Governor, DeSantis, but came from Axios (see Image 13) and received 16,454 total interactions. The fourth top post came from Reuters (see Image 14) and received 14,174 total interactions. This post focused on the American public\u2019s false belief regarding CR T. The fifth top post came from Newsweek and received 10,365 total interactions (see Image 15). This post focused on Georgia\u2019s U.S. Representative, Marjorie T aylor Greene, and her stance on making CR T illegal. \nThe mean number of likes per post was 756.93. The page most commonly posting \ncontent related to CR T was Newsweek, a left-center media outlet with high factual re-porting (Media Bias/Fact Check, 2022e). However, posts with the most likes originated from Axios, a left-center media outlet with high factual reporting (Media Bias/Fact Check, 2022f). Figure 6 shows likes from viewers on posts during this time frame from neutral \n20news media outlets. The top five neutral news media outlets and information about their \nposts, such as likes at post, page followers at post, and overperformance measures of posts can be found in T able 5. T able 6 summarizes the interactions from viewers (i.e., likes, com-ments, shares, love, wow, haha, sad, angry, and care reactions) from the top five neutral news media outlets.\nFigure 6 . Likes on Posts from Neutral News Media Outlets\nTable 5. Top Five Neutral News Media Outlets\nPage Name N Posts % of PostsLikes at Post\nM (SD)Followers at \nPost\nM (SD)Overperformance\nM (SD)\nNewsweek 92 46.91,371,601.49 \n(2247.49) 1,387,902.16 \n(16004.19) 6.97 (25.71) \nAllSides 49 25.044,981.80 \n(2139.44) 49,538.00 \n(2349.35) 2.91 (2.14) \nThe Wall Street Journal 24 12.26,578,320.79 \n(22639.54) 6,780,604.92 \n(77752.69)5.07 (4.76) \nAxios 16 8.2425,893.56 \n(4838.86) 466,985.13 \n(6227.07) 2.88 (4.28) \nHILL TV 9 4.672,643.00 \n(2549.42) 235,133.33 \n(18292.79) -1.69 (2.18) \nTotal 190 96.91,898,074.95 \n(4252071.16)1,978,432.30 \n(4481416.69)5.04 (18.00)\n21Table 6. Interactions with Top Five Neutral News Media Outlets\nPage NameTotal Interactions Likes Comments Shares Loves\nM SD M SD M SD M SD M SD\nNewsweek 7068.45 2,4774.14 4,149.04 9,978.10 509.31 1,827.74 209.43 9,937.50 754.12 3,673.82AllSides 133.67 80.55 34.37 20.92 67.63 48.44 6.78 8.49 3.45 5.06The Wall Street Journal 1459.67 1,343.01 590.67 869.26 520.83 308.27 56.63 49.45 76.54 194.03Axios 4943.25 3,961.98 2,739.88 2,578.30 425.13 266.13 112.19 91.45 582.31 726.93HILL TV 281.33 250.43 133.56 148.69 60.67 42.11 37.00 41.03 13.22 19.69\nWow HaHa Sad Angry Care\nM SD M SD M SD M SD M SD\nNewsweek 38.52 119.56 75.28 231.72 22.80 70.16 293.36 898.36 16.59 75.09\nAllSides 1.33 2.25 9.04 9.62 1.94 2.76 8.94 13.73 .20 .46The Wall Street Journal 9.79 12.15 118.21 103.65 5.79 8.83 78.50 180.96 2.71 4.29Axios 36.44 27.67 188.94 292.40 71.00 82.41 771.94 785.89 15.44 17.05HILL TV 4.44 7.14 11.11 11.47 1.33 1.41 19.44 43.57 .56 .73\n22Comparing News Media Outlets\nA MANOV A was conducted to determine if there were any significant differences in \nconsumer interactions with posts and page following from right-leaning, left-leaning, and neutral reporting news media outlets. Results can be found in T able 7.\nTable 7. Significant Differences based on News Media Outlet\n Fn2News Media Outlet MS D\nLikes at Posting66.59***.05 Neutral 1,898,074.95 4,252,071.16\nRight-Leaning 5,477,580.14 5,750,396.43\nLeft-Leaning 8,460,638.63 9,128,080.24\nFollowers at Posting57.10***.05 Neutral 1,978,432.30 4,481,416.69\nRight-Leaning 6,466,706.42 6,981,196.60\nLeft-Leaning 9,166,576.51 10,092,267.79\nTotal Interactions12.23***.01 Neutral 1,424.28 3,151.88\nRight-Leaning 4,480.25 11,709.38\nLeft-Leaning 2,102.78 4,477.52\nLikes18.34***.02 Neutral 756.93 2,157.33\nRight-Leaning 2,689.60 6,465.91\nLeft-Leaning  951.84 2,761.25\nComments6.07**.01 Neutral 195.49 300.17\nRight-Leaning 460.18 1,120.05\nLeft-Leaning 467.48 554.39\nShares3.57*.00 Neutral 42.67 122.23\nRight-Leaning 517.98 3,519.53\nLeft-Leaning 124.41 367.16\nLove4.49**.00 Neutral 112.01 346.90\nRight-Leaning 373.09 1586.77\nLeft-Leaning 185.11 797.70\nWow4.63**.00 Neutral 13.46 29.99\nRight-Leaning 35.37 113.88\nLeft-Leaning 25.29 67.46\nSad3.38*.00 Neutral 18.45 73.12\nRight-Leaning 22.39 82.88\nLeft-Leaning 35.65 107.79\nCare3.95*.00 Neutral 3.84 9.53\nRight-Leaning 10.81 41.48\nLeft-Leaning 6.89 20.36\n*p< .05, ** p< .01, *** p <.001\ndf for all variables (2, 2384)\n23W e found significant differences based on news media outlet for page likes at posting, \npage followers at posting, total post interactions, post likes, post comments, post shares, love reactions, wow reactions, sad reactions, and care reactions. No significant differences were found for haha reactions to posts or angry reactions to posts. W e found that in terms of page following and interactions with posts, right-leaning news media outlets had the highest scores on all measures. \nDISCUSSION\nIn summary, the purpose of the current study was to examine the potential partisan re-\nporting on Facebook regarding CR T. Specifically, we were interested in how right-leaning, left-leaning, and neutral mainstream news media outlets reported on news stories concern-ing CR T on their Facebook pages. Meta\u2019s CrowdT angle was utilized to collect and examine data obtained from the top five right-leaning, left-leaning, and neutral mainstream news media outlets for posts on CR T between January 30, 2020, and January 30, 2022, due to this being the time period in which CR T was well reported on. \nOur study was exploratory in nature and aimed to address several goals. Amongst them \nwere the pervasiveness of news posts about CR T on social media, partisan reporting on social media relating to CR T mainstream news posts, the features and characteristics of the top posts regarding CR T, interactions with CR T posts by users, user interactions (e.g., likes, comments, shares, loves, wow, haha, sad, angry, care), differences in user interactions based on right-leaning, left-leaning, and neutral news media channels, the audience of par-tisan reporting channels on social media, and signs of overperformance in the different news posts (i.e., right-leaning, left-leaning, neutral) on social media concerning CR T.\nOverall,  we found that right-leaning news media outlets were more likely to post about \nCR T compared to left-leaning and neutral news media outlets. Out of all 1,845 posts we examined, nearly 76% of them were posted by right-leaning outlets. Left-leaning outlets contributed to almost 14% of posts, shortly followed by neutral-media outlets who were responsible for a meager 11%. The Daily Wire was the news media outlet that had the high-est number of posts, while Fox News had the greatest number of total interactions. \nThe first post from right-leaning news media outlets related to CR T was in June 2020. \nThe reporting took place nearly one month after the death of George Floyd (McGreal  et \nal., 2021) and during Black Lives Matter (BLM) protests that were surging within the \nUnited States and around the world (Silverstein, 2021). Both the timing of and language used (e.g., \u201cCritical race theory is racism, pure and simple\u2026\u201d) in the right-leaning reporting on CR T makes it appear as though the posts were racially motivated. Right-leaning news media outlets consistently reported on CR T for several months, even while neutral and left-leaning news media were not reporting on the topic, indicating that such posts were incendiary and fomenting. \nBoth neutral and left-leaning news media outlets reported on CR T for the first time in \nSeptember 2020, which gave right-leaning news media roughly three months of reporting \n24without any contradictions. While this was at the same time that the BLM protests entered \ntheir 100th night of protests (Johnson, 2021), it appears that both neutral and left-leaning \nnews media outlets were compelled to finally report on CR T after months of consistent reporting on the topic by right-leaning news media outlets.  Both right-leaning and left-leaning news media outlets experienced a peak in posts related to CR T in June 2021, when Juneteenth was declared a national holiday (W agner  et al ., 2021). However,  the language \nused in both types of reporting demonstrate the racial bias of reporting by right-leaning news media outlets, compared to left-leaning news media reporting. While neutral news media posts related to CR T peaked in November 2021, as the investigation of the January 6 insurrection was underway (Berman, 2021), all three reporting outlet types (right-lean-ing, left-leaning, neutral) experienced another peak in reporting of CR T in January 2022, the last month we included in our data collection for the current study. \nW e also measured user interaction of right-leaning, left-leaning, and neutral news me-\ndia outlet posts related to CR T. In terms of page following and interactions with posts, we found that right-leaning news media outlets had the highest scores in all categories. Right-leaning outlets had two major user interaction spikes in the time spans of May-June 2020. Considering the race-based framing of CR T posts by right-leaning news media outlets, the large audience is concerning but demonstrates the long-standing issues with race relations in the United States (Hicken  et al ., 2021; Patterson, 2020). For left-leaning outlets, March-\nJune 2021 had the most significant user interaction spikes, while neutral news outlets had the most interaction the last couple of months in 2021. All news outlets also experienced a major spike in January 2022. \nW e also found that there were variations in how users interacted with posts based on \nif it was from a right-leaning, left-leaning, or neutral news media outlet. For example, Fox News had the most followers and received the most likes for their CR T posts out of all the right-leaning outlets. Their posts also elicited the most user interactions (i.e., likes, com-ments, shares, loves, wow, haha, sad, angry, care) compared to other right-leaning outlets. These stronger reactions to posts related to CR T could be explained by the clash between contemporary conservative values and the tenets of CR T (Han  et al ., 2018; Subotnik, \n1998). CNN was the most influential outlet within the left-leaning outlet category, having the most followers and user interactions. CBS News followed closely behind, obtaining the highest overperformance rate, even compared to right-leaning media outlets. However, left-leaning outlets were not nearly as successful in terms of performance as right-leaning ones. This could be explained by left-leaning news outlets favoring government reform that could benefit the livelihood of and promote the experiences of Black people (Han  et al. , \n2018; Romero, 2003). Thus, since there is not a lot of conflict about this topic within the left-leaning sphere, they may be inclined to post about it less, or at least mostly post in re-sponse to right-leaning articles or other forms of news media.\nThe interactions on neutral news media platforms were particularly interesting. While \nThe W all Street Journal had the most followers and the highest like and comment count of all outlets, Newsweek produced the greatest number of posts related to CR T, contribut-ing nearly half of all posts in the neutral media source category, and further obtaining the \n25highest overperformance score and total interaction count. These two outlets dominated \nthe other three in terms of user interactions. Axios, however, obtained the highest amount of sad, angry, and care reactions to posts. The high overperformance on Newsweek posts could be linked to the world\u2019s growing desire to have unbiased news coverage in a highly polarized world (Pew, 2018). It is important to note that while neutral news media sources are growing in popularity, they are still outmatched by partisan news sources. Previous re-search has also observed similar patterns regarding neutral news media outlets having high-er overperformance rates, while having a smaller following and lower engagement (Wright  \net al ., 2022). This leads us to believe that it will still be a long way for neutral news media \noutlets to gain the same amount of influence in the public sphere as partisan sources.\nCONCLUSION\nBased on the findings of our study, it seems evident that the way in which mainstream \nnews media outlets frame information can influence the opinions and attitudes of their audience (Estrada  et al ., 2016; McKeever  et al ., 2012; Steinberg, 2004). This appears to lead \nto greater polarization among consumers (Benedictis-Kessner  et al ., 2019). Additionally, \nwhile social media users have pre-existing views that lead them to self-select the news media to which they are exposed, it also seems evident that race laden and biased reporting, such as those from right-leaning news media outlets as indicated in this study, \u201cfan the flames,\u201d so to speak, of those pre-existing views (see Jones, 2019). Not only did right-leaning main-stream news outlets begin posting about CR T on social media months before left-leaning and neutral news media outlets, but they also posted more frequently, and demonstrated racially motivated posting (e.g., timing of posts, language used in posts). Right-leaning mainstream news outlets had a larger audience, demonstrating the pre-existing opinions and attitudes of their audience, and received more interactions for their posts, highlighting the perpetual potential toward audience polarization. Our findings highlight the need for more stringent policy regarding content and methods of reporting on social media plat-forms as well as the continuous existence of strained race relations within the United States. Furthermore, considering the overperformance ratings of neutral news outlets, our find-ings also demonstrate the increased media distrust that is developing among social media users. Ensuring that news reporting is unbiased and focused on factual information can help rebuild trust in the news media.\nLimitations and Future Research\nAlthough this study demonstrates the partisan reporting of CR T and the potential in-\nfluence that this type of reporting can have on social media users, our study is based on data retrieved from Meta\u2019s CrowdT angle. Within this study, we cannot fully elaborate on the growing consumer distrust based solely on customer interaction and following alone. \n26This type of research requires intensive measures such as analyzing individual user com-\nments, which CrowdT angle does not provide the means to do. W e specifically analyzed social media posts from Facebook. The data obtained from CrowdT angle includes public groups and pages, as well as verified profiles on the app, meaning that we were not able to access posts that originated from private groups, private or even partially private personal profiles, and direct messages. This means that we had limited access within the platform and the data that we accessed was only what was made public. Facebook groups and pages are designed for users to share their opinions and common interests together (Facebook, 2010). W e believe that future research should be conducted to provide a broader and more complex comparison between social media content and its interactions as well as main-stream news that are framed via social media. \nW e conducted a MANOV A to determine if there were any significant differences in \nconsumers interactions with posts and page following from right-leaning, left-leaning, and neutral news media outlets. W e also included n\n2 as a measure of effect size. While some of \nour findings (i.e., page likes at posting, page followers at posting) approached a medium effect size (close to .06), many others had a small effect size (.01) (i.e., total post interac-tions, post likes, post comments, post shares, love reactions, wow reactions, sad reactions, care reactions), indicating that the partisan nature of the news media outlet may not be the only aspect associated with consumer interactions with posts. This may indicate that social media users had pre-existing beliefs and opinions that led them to seek news infor-mation from their preferred news media outlet. Even so, small effects can have important real-world implications (McCartney & Rosenthal, 2000), which may help explain the cur-rent controversies based along partisan lines and state-level legislation regarding CR T that is currently taking place in the United States (Awtrey, 2021; The Economist, 2021). \nReferences\n1. Awtrey, J. (2021, July 16). Texas Senate passes Hughes bill banning teaching of critical race theory\nin public schools . Retrieved from https://web.archive.org/web/20211023205225/https://www.\nkltv.com/2021/07/16/texas-senate-passes-hughes-bill-banning-teaching-critical-race-theory-public-schools/\n2. Barrus, J. (2020, May 4). Nikole Hannah-Jones wins Pulitzer Prize for 1619 Project . Retrieved \nfrom https://pulitzercenter.org/blog/nikole-hannah-jones-wins-pulitzer-prize-1619-project\n3. Benedictis-Kessner, B., Berinsky, A. J., & Y amamoto, T. (2019). Persuading the enemy: Estimating the persuasive effects of partisan media with the preference-incorporating choice and assignment design. The American Political Science Review , 113(4), 902\u2013916. https://doi.\norg/10.1017/S0003055419000418\n4. Berman, D. (2021, November 28). The latest in the January 6 investigation . CNN Politics.\nRetrieved       from       https://www.cnn.com/2021/11/28/politics/january-6-investigation/index.html\n5. Beyer, R. (2019). Engaging in critical conversations about race . The Record \u2013 News & Stories \nfrom BU Law. Retrieved from https://www.bu.edu/law/record/articles/2019/engaging-in-cri\n27tical-conversations-about-race/#:~:text=Bridges%20identifies%20four%20basic%20tenets,\nnormal%20feature%20of%20US%20society\n6. Bohman, J. (2005).  Critical theory. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy  \n(Spring 2021 ed.). https://plato.stanford.edu/archives/spr2021/entries/critical-theory/\n7. Boxell, L., Gentzkow, M., & Shapiro, J. (2020). Cross-country trends in affective polarization. National Bureau of Economic Research . https://doi.org/10.3386/w26669\n8. Bracey, G. E. (2015). T oward a critical race theory of state. Critical Sociology,  41(3), 553\u2013572. \nhttp://doi.org/10.1177/0896920513504600\n9. Cole, N. L. (2019, October 15). The Frankfurt School of Critical Theory . Retrieved from https://\nwww.thoughtco.com/Frankfurt-school-3026079\n10. CrowdT angle (n.d.a). About us . Retrieved from https://help.crowdtangle.com/en/articles/420\n1940-about-us\n11. CrowdT angle (n.d.b.). FAQ: Page category filter.  Retrieved from https://help.crowdtangle.com/\nen/articles/5367790-faq-page-category-filter\n12. CrowdT angle (n.d.c.). How is overperforming calculated?  Retrieved from https://help.crowd\ntangle.com/en/articles/1141056-how-is-overperforming-calculated\n13. Estrada, E. P., Ebert, K., & Lore, M. H. (2016). Apathy and antipathy: Media coverage of restric-tive immigration legislation and the maintenance of symbolic boundaries. Sociological Forum, \n31(3), 555\u2013576. 12262. http://doi.org/10.1111/socf\n14. George, J. (2021, January 11). A Lesson on Critical Race Theory.  American Bar Association.\nRetrieved from https://www.americanbar.org/groups/crsj/publications/human_rights_magazine_home/civil-rights-reimagining-policing/a-lesson-on-critical-race-theory/ \n15. Facebook (2010). Facebook tips: What\u2019s the difference between a Facebook page and group?\nRetrieved from https://www.facebook.com/notes/facebook/facebook-tips-whats-the-difference-between-a-facebook-page-and-group/324706977130\n16. Gillborn D. (2015). Intersectionality, critical race theory, and the primacy of racism: Race, class, gender, and disability in education, Qualitative Inquiry , 21(3), 277\u2013287. http://doi.\norg/10.1177/1077800414557827\n17. Garvey, F. L. (2016). The myths of oppositional culture. Journal of Black Studies, 33, 450\u2013467.\n18. Han, K. T., Scull, W . R., Nganga L., & Kambutu, J. (2018). V oices from the red states: challeng-\ning racial positioning in some of the most conservative communities in America. Race Ethnicity \nand Education , 23(1), 74\u201393 http://doi.org/10.1080/13613324.2018.1468751\n19. Hicken, M., Miles, L., Haile, S., & Esposito, M. (2021). Linking history to contemporary state-\nsanctioned slow violence through cultural and structural racism. The ANNALS of the American \nAcademy of Political and Social Science, 694, 48\u201358. http://doi.org/10.1177/00027162211005690\n20. Johnson, D. (2021, September 5). Riot declared as protesters march to Portland police East \nPrecinct on the 100th night of protest . KGW8. Retrieved from https://www.kgw.com/article/\nnews/local/protests/several-demonstrations-across-portland-as-it-enters-its-100th-night-of-protest/283-13f4034b-1965-41a2-85f0-c59cc5baf872\n21. Jones, O. (2019, March 28). Why we need to talk about the media\u2019s role in far-right radicalisa-\ntion. Retrieved from https://www.theguardian.com/commentisfree/2019/mar/28/media-far-\nright-radicalisation-politics-hatred\n22. Kaplan, L., & Owings, W . A. (2021). Countering the furor around critical race theory. NASSP \nBulletin , 105(3), 200\u2013218. https://doi.org/10.1177/01926365211045457\n2823. Ladson-Billings, G., & T ate, W . (1995). T oward a critical race theory in education. Teachers \nCollege Record, 97 (1), 47\u201368.\n24. Larnell, G. V ., Bullock, E. C., & Jett, C. C. (2016). Rethinking teaching and learning mathemat-\nics for social justice from a critical race perspective. Journal of Education, 196 (1), 19\u201329. https://\ndoi.org/10.1177/002205741619600104\n25. Ledesma, M. C., & Calder\u00f3n, D. (2015). Critical race theory in education: A review of past literature and a look to the future. Qualitative Inquiry , 21(3), 206\u2013222. http://doi.\norg/10.1177/1077800414557825\n26. Litowitz, D.E. (1997) Some critical thoughts on critical race theory. Notre Dame Law Review , \n72(2), 503\u2013529. http://scholarship.law.nd.edu/ndlr/vol72/iss2/5 \n27. Lynn, M., & Parker, L. (2006). Critical race studies in education: Examining a decade of \nResearch on US schools. The Urban Review, 38 (4), 257\u2013290. https://doi.org/10.1007/s1125\n6-006-0035-5\n28. McCartney, K., & Rosenthal, R. (2000). Effect size, practical importance, and social policy for children. Child Development, 71 (1), 173\u2013180. https://doi.org/doi:https://doi.org/10.1111/14\n67-8624.00131\n29. McKeever, B. W ., Riffe, D., & Carpentier, F. D. (2012). Perceived hostile media bias, presumed media influence, and opinions about immigrants and immigration. Southern Communication \nJournal, 77 (5), 420\u2013437. http://doi.org/10.1080/1041794X.2012.691602\n30. McGreal, C., Beckett, L., Laughland, O., & Ajasa, A. (2021, April 21). Derek Chauvin found \nguilty of murder of George Floyd. The Guardian. Retrieved from https://www.theguardian.\ncom/us-news/2021/apr/20/derek-chauvin-verdict-guilty-murder-george-floyd\n31. Media Bias/Fact Check. (2021a ). Media bias fact check . Media Bias/Fact Check. Retrieved from \nhttps://mediabiasfactcheck.com/\n32. Media Bias/Fact Check. (2021b). Methodology . Media Bias/Fact Check. Retrieved from https://\nmediabiasfactcheck.com/methodology/\n33. Media Bias/Fact Check (2022a). Daily Wire . Media Bias/Fact Check. Retrieved from https://\nmediabiasfactcheck.com/the-daily-wire/\n34. Media Bias/Fact Check (2022b). Fox News.  Media Bias/Fact Check. Retrieved from https://\nmediabiasfactcheck.com/fox-news-bias/\n35. Media Bias/Fact Check (2022c). MSNBC.  Media Bias/Fact Check. Retrieved from https://me\ndiabiasfactcheck.com/msnbc/\n36. Media Bias/Fact Check (2022d). The New York Times . Media Bias/Fact Check. Retrieved from \nhttps://mediabiasfactcheck.com/new-york-times/\n37. Media Bias/Fact Check (2022e). Newsweek.  Media Bias/Fact Check. Retrieved from https://\nmediabiasfactcheck.com/newsweek/\n38. Media Bias/Fact Check (2022f). Axios.  Media Bias/Fact Check. Retrieved from https://media\nbiasfactcheck.com/axios/\n39. Mills, K. A., & Unsworth, L. (2018) The multimodal construction of race: A review of critical race theory research. Language and Education, 32 (4), 313\u2013332. http://doi.org/10.1080/09500\n782.2018.1434787\n40. Ogbu, J., & Simons, H. (1998). V oluntary and involuntary minorities: A cultural-ecological theory of school performance with some implications for education. Anthropology & Education \nQuarterly, 29, 155\u2013188.\n2941. Patterson, O. (2020, June 5). The long reach of racism in the U.S. The W all Street Journal . Retrieved \nfrom https://www.wsj.com/articles/the-long-reach-of-racism-in-the-u-s-11591372542\n42. Pew Research Center. (2018, January 11). People around world want unbiased news . Pew \nResearch Center . Retrieved from https://www.pewresearch.org/global/2018/01/11/publics-\nglobally-want-unbiased-news-coverage-but-are-divided-on-whether-their-news-media-deliver/\n43. Pew Research Center. (2021, April 9). Political polarization in the American public.  Pew \nResearch Center. Retrieved from https://www.pewresearch.org/politics/2014/06/12/political-polarization-in-the-american-public/ \n44. Romero, V .C. (2003). Critical race theory in three acts: Racial profiling, affirmative action, and the diversity visa lottery. Albany Law Review , 66, 375\u2013386. https://elibrary.law.psu.edu/cgi/\nviewcontent.cgi?article=1088&context=fac_works\n45. Sawchuk, S. (2022). What is critical race theory, and why is it under attack?  Education\nWee k .   Retrieved       from       https://www.edweek.org/leadership/what-is-critical-race-theory-and-why-\nis-it-under-attack/2021/05\n46. Social Apps. (n.d.). Facebook page categories list in 2023-Complete Facebook business page category list. Retrieved from https://www.socialappshq.com/facebook/fb-page-categories-list/\n47. Silverstein, J. (2021, June 4). The global impact of George Floyd: How Black Lives Matter protests \nshaped movements around the world . CBS News. Retrieved from https://www.cbsnews.com/\nnews/george-floyd-black-lives-matter-impact/\n48. Steinberg, S. (2004). Undocumented immigrants or illegal aliens? Southwestern media portray-als of Latino immigrants. Humboldt Journal of Social Relations, 28 (1), 109\u2013133.\n49. Subotnik, D. (1998). What\u2019s wrong with critical race theory?: Reopening the case for middle \nclass values. Cornell Journal of Law and Public Policy , 7, 681\u2013756.\n50. T ate, W .F. (1997). Critical race theory and education: History, theory, and implications. Review \nof Research in Education , 22, 195\u2013247. https://doi.org/10.2307/1167376\n51. The Economist. (2021, June 17). Americans who have heard of critical race theory don\u2019t like it . \nRetrieved from https://www.economist.com/graphic-detail/2021/06/17/americans-who-have-heard-of-critical-race-theory-dont-like-it\n52. W agner, M., Mahtani, M., Macaya, M., Rocha, V ., & Alfonso III, F. (2021, June 17). Juneteenth \nbecomes a federal holiday . CNN Politics. Retrieved from https://www.cnn.com/politics/live-\nnews/biden-signs-juneteenth-bill/index.html\n53. Wright, C., Larson, C., & Reichdan, C. (2022). Let\u2019s Go, Brandon: An expression of disap-pointment, partisan reporting, and distrust in news media. Media Psychology Review , 14(1).\n54. Zinn Education Project. (2023). About the Zinn education project . Retrieved from https://www.\nzinnedproject.org/about/\n30Appendix\nImage 1 . Newsmax Image 2 . Breitbart\nImage 3 . Fox News Image 4 . Fox News\nImage 5 . Fox News Image 6 . CBS News\n31\nImage 7 . New York Times Image 8 . New York Times\nImage 9 . CNN Image 10 . CNN\nImage 11 . Newsweek Image 12 . Newsweek\n32\nImage 13 . Axios Image 14.  Reuters \nImage 15 . Newsweek", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Examining Partisan Reporting of Critical Race Theory Using Meta's Crowd Tangle.", "author": ["CL Wright", "B Coelho", "C Koerner", "C Ferrer"], "pub_year": "2023", "venue": "Journal of Media \u2026", "abstract": "Mainstream news media outlets can influence the opinions and attitudes of their audience  based on how they frame information. This framing can also lead to polarization. Presently"}, "filled": false, "gsrank": 266, "pub_url": "https://www.ceeol.com/search/article-detail?id=1112990", "author_id": ["", "", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:v4284dha91sJ:scholar.google.com/&output=cite&scirp=265&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D260%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=v4284dha91sJ&ei=M7WsaKqxMrXCieoP4PfQ0A8&json=", "num_citations": 2, "citedby_url": "/scholar?cites=6626865264245640639&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:v4284dha91sJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.mrjournal.ro/docs/R2/45jmr1.pdf"}}, {"title": "Fact-checking meets fauxtography: Verifying claims about images", "year": "2019", "pdf_data": "Fact-Checking Meets Fauxtography: Verifying Claims About Images\nDimitrina Zlatkova\nSo\ufb01a University\n\u201cSt. Kliment Ohridski\u201d\nSo\ufb01a, Bulgaria\ndvzlatkova@uni-sofia.bgPreslav Nakov\nQatar Computing Research Institute,\nHBKU\nDoha, Qatar\npnakov@qf.org.qaIvan Koychev\nSo\ufb01a University\n\u201cSt. Kliment Ohridski\u201d\nSo\ufb01a, Bulgaria\nkoychev@fmi.uni-sofia.bg\nAbstract\nThe recent explosion of false claims in social\nmedia and on the Web in general has given\nrise to a lot of manual fact-checking initia-\ntives. Unfortunately, the number of claims that\nneed to be fact-checked is several orders of\nmagnitude larger than what humans can han-\ndle manually. Thus, there has been a lot of\nresearch aiming at automating the process. In-\nterestingly, previous work has largely ignored\nthe growing number of claims about images.\nThis is despite the fact that visual imagery\nis more in\ufb02uential than text and naturally ap-\npears alongside fake news. Here we aim at\nbridging this gap. In particular, we create a\nnew dataset for this problem, and we explore\na variety of features modeling the claim, the\nimage, and the relationship between the claim\nand the image. The evaluation results show\nsizable improvements over the baseline. We\nrelease our dataset, hoping to enable further re-\nsearch on fact-checking claims about images.\n1 Introduction\nAs social media become a bigger part of our daily\nlives, their in\ufb02uence over the way people think and\nmake decisions increases. Inevitably, this has of-\nfered opportunities for fake content to arise and to\nspread faster than ever, e.g., recent research has\nshown that fake news spreads six time faster than\nreal news (V osoughi et al., 2018). Sometimes such\ncontent is created for pure entertainment or for \ufb01-\nnancial gain from advertisement shown alongside\nthe fake content, but more often and especially re-\ncently it has been used to spread disinformation,\ne.g., with the aim to in\ufb02uence political elections\n(Atanasov et al., 2019). To deal with the prob-\nlem, a number of manual fact-checking initiatives\nhave been launched, but they remain insuf\ufb01cient\nto cope with the ever growing number of check-\nworthy claims. Thus, automated methods have\nbeen proposed as a more scalable solution.\n(a) A series of images show\na Tesla vehicle in space.\n(b) Photograph shows a \ufb01re\nrainbow over Idaho.\nFigure 1: Examples of Real images and True claims.\nRecently, a growing number of claims have\nbeen about images. The word Fauxtography has\nbeen used to describe images, especially news\nphotographs, that convey a questionable, or out-\nright false, sense of the events they seem to depict.\nThe term was coined over a decade ago (Cooper,\n2007), and there is growing research interest in the\ntopic in the Computer Vision community (Bayar\nand Stamm, 2016; de Carvalho et al., 2016). Given\nthe recent proliferation of fake news, and given\nthat many of the questionable claims are about im-\nages, it would be natural to expect similar interest\nin the Computational Linguistics community, es-\npecially given the fact that visual imagery is more\nin\ufb02uential than text and naturally appears along-\nside fake news. Yet, computational fact-checking\nhas mostly ignored the growing number of claims\nabout images. Here we aim at bridging this gap.\nIn particular, we create a new dataset for this prob-\nlem, and we explore a variety of features modeling\nthe claim, the image, and the relationship between\nthe claim and the image.\nLet us look at some examples. Figure 1 shows\ntwo images that look surrealistic, and thus spark\ninterest and raise natural suspicion. Yet, they are\nin fact real.1;2\n1http://www.snopes.com/fact-check/\ntesla-car-really-space\n2http://www.snopes.com/fact-check/\nfire-rainbowarXiv:1908.11722v1  [cs.CL]  30 Aug 2019\n(a) A photograph shows a\nmountain resembling a tur-\ntle.\n(b) A photograph shows\nRussian president Vladimir\nPutin aggressively pulling\non U.S. president Barack\nObama\u2019s tie.\nFigure 2: Examples of Fake images and False claims.\nFigure 2 contains fake images accompanied by\nfalse claims. On the left, in Figure 2a, we see an\nimage from a Facebook page that claims to show\na turtle mountain. It turns out that this is not a\ngenuine photograph of a real-world location, but\na digital artwork comprising altered versions of\nat least two different photographs.3On the right,\nFigure 2b displays an image purportedly showing\nPutin aggressively grabbing President Obama by\nthe tie and pulling him close. This image has been\ndigitally manipulated.4\nFinally, Figure 3 shows original photographs\nwith false claims about them. The image in Fig-\nure 3a shows Trump with his \ufb01sts in the air, but\nhis gesture is not a greeting to a cancer victim as\nthe claim states. The real image was used as a part\nof a meme5that was designed to make it seem that\nway. The photo in Figure 3a was posted by a Twit-\nter account in an attempt to go viral, claiming that\nit shows a real bunny sitting in the palm of some-\none\u2019s hand. It actually shows a plush doll.6\nAs we have seen above, there are a number of\nreasons why an image may be deemed fake. In\nmost cases, this involves some kind of digital ma-\nnipulation, e.g., cropping, splicing, etc. However,\nthere are cases when an image is completely legit-\nimate, but it is published alongside some text that\ndoes not re\ufb02ect its content accurately. This is our\nmain focus here: we study the factuality of image-\nclaim pairs.\n3http://www.snopes.com/fact-check/\nturtle-mountain-photo/\n4http://www.snopes.com/fact-check/\nputin-obama-tie-pull/\n5http://www.snopes.com/fact-check/\ntrump-fistpump-cancer-greeting/\n6http://www.snopes.com/fact-check/\nbunny-toy-photograph/\n(a) President Trump\u2019s notorious\n\u2018\ufb01st pump\u2019 at a Pennsylvania\nairport on 9/11 was offered as a\ngreeting to a cancer victim.\n(b) A photograph shows\na palm-sized rabbit.\nFigure 3: Examples of True images and False claims.\nThe contributions of this paper can be summa-\nrized as follows:\n\u000fWe study a new problem: predict the factual-\nity of a claim with respect to an image.\n\u000fWe create a new dataset for this problem,\nwhich we release to the research community\nin order to enable further work.\n\u000fWe explore a variety of features, and we\ndemonstrate sizable improvements over the\nbaseline.\nThe remainder of this paper is organized as fol-\nlows: Section 2 presents some relevant related\nwork. Section 3 describes in depth our method and\nthe various features we experimented with. Sec-\ntion 4 gives details about the datasets we created\nand used. Section 5 describes our experimental\nsetup and presents the evaluation results. Section 6\ngives additional details about the performance of\nthe individual features, both in isolation and in\nvarious combinations, and further describes some\nunsuccessful attempts at extracting better features.\nFinally, Section 7 presents our conclusions and\nsome ideas for future work.\n2 Related Work\n2.1 Fact-checking Claims\nThere has been a lot of research in the last few\nyears in automatic fact-checking of claims and ru-\nmors, which can be classi\ufb01ed into two general cat-\negories. The \ufb01rst approach focuses on the social\naspects of the claim and how users in social me-\ndia react to it (Canini et al., 2011; Castillo et al.,\n2011; Ma et al., 2016; Zubiaga et al., 2016; Ma\net al., 2017; Dungs et al., 2018). This is re\ufb02ected\nby user comments, likes/dislikes, views and other\ntypes of reactions, which are collected and used as\nfeatures.\nOther methods use the Web and try to \ufb01nd in-\nformation that proves or disproves the claim\n(Mukherjee and Weikum, 2015; Popat et al., 2017;\nKaradzhov et al., 2017; Mihaylova et al., 2018;\nBaly et al., 2018b). In either case, what is impor-\ntant is the stance (Riedel et al., 2017; Thorne et al.,\n2017; Hanselowski et al., 2018; Mohtarami et al.,\n2018, 2019): whether the opinion expressed in a\ntweet or in an article by a particular user/source\nagrees/disagrees with the claim, and the reliability\nof the source, i.e., can we trust this source (Baly\net al., 2018a, 2019).\nWe should note that all these approaches are\nlimited to textual claims, while we are interested\nin claims about images.\n2.2 Detecting Fake/Manipulated Images\nThe task of detecting fabricated images falls under\nthe area of image forensics. Such tasks are usually\nsolved using traditional statistical methods mod-\neling color, shape, and texture features (Bayram\net al., 2006; Stamm and Liu, 2010; de Carvalho\net al., 2016). More recently, with the rise of\nDeep Learning, modern approaches and architec-\ntures have been applied to tackle the problem (Ba-\nyar and Stamm, 2016). However, most existing\nwork uses datasets with generic images and very\nfew papers specialize in the area of news and so-\ncial media (Jin et al., 2016). Detecting manipu-\nlation in the images is relevant for us, but is not\nenough, since often the image is original, but the\nclaim about it is false.\n2.3 Fact-Checking Claims about Images\nLittle research exists on the topic of fact-checking\nclaims about images, where the input to be an-\nalyzed is an image-claim pair. To the best of\nour knowledge, there is only one work closely re-\nlated to ours: a recent paper (Zhang et al., 2018)\npresents a system called FauxBuster which aims to\n\ufb01ght against Fauxtography. We differ from them\nin that we use the Web as a source of information.\nIn contrast, they focus on the social aspects of the\nproblem and use comments on Twitter and Reddit\nto extract features, which makes our work com-\nplementary to theirs. Unfortunately, direct com-\nparison to their approach is not feasible, as their\ndataset is not freely accessible.3 Method\nThis section describes the different approaches we\napplied towards engineering and extracting fea-\ntures from the image-claim pair.\nWe start with reverse image search . The classi-\ncal image search allows users to search for images\nbased on a text with speci\ufb01c words or phrases. In\ncontrast, reverse image search takes as input an\nimage and returns Web pages that include this ex-\nact image or images that are very similar to it. This\nprocess can be easily automated and applied to a\nlarge number of images via Google\u2019s Vision API.7\nIt can also return other information related to the\nimage, e.g., tags, the text on the image, some ob-\nject detection, explicit content, etc.\nUsing reverse image search, for each image we\nobtain a maximum of 50 Web pages that con-\ntain it. We remove pages that are known to be\nfrom fact-checking Web sites such as snopes.com,\nfactcheck.org, using open-source code.8For the\nremaining Web pages, we crawl the article and we\nget its title and text.\n3.1 Features about the Image\nGoogle tags : This is a list of tags that Google as-\nsociates with the image. We decided to use this list\nbecause it contains words and phrases about events\nand people related to the image, which might give\nus an insight about what the image contains and\nwhat it is about. For example, the image in Fig-\nure 1a has the following tags: SpaceX, Falcon\nHeavy, Rocket, Rocket launch, Falcon, Company,\nLaunch pad, Booster, Thrust, Entrepreneur, Elon\nMusk . After lowercasing them and removing stop\nwords, we use them directly as bag-of-words fea-\ntures.\nURL domains : The Web pages that contain\nthe image usually come from media sources and\nrepresent articles on a topic related to the image\nand/or the claim attached to it. However, in some\ncases they might point to an image-hosting ser-\nvice or a social network Web site such as Pinterest,\nImgur, Twitter, etc. In an effort to use this fact, we\nextracted the top-level domain names from the list\nof URLs and we used them as TF.IDF features.\nURL categories : In order to get more insight\nabout what types of websites write about fake and\ngenuine images, we classify them in several pre-\nde\ufb01ned URL categories.\n7http://cloud.google.com/vision/\n8github.com/clef2018-factchecking\nWe use open-source code9to classify URLs,\nwhich performs rule-based matching of tokens\nfrom the URL against a prede\ufb01ned list of words.\nGiven a URL, it assigns it a tuple of one higher-\nlevel and one lower-level category. For example,\nwhen we run the algorithm on the Web sites re-\nturned for the image in Figure 1a we get category\ntuples such as: (\u2018arts & entertainment\u2019, \u2018general\u2019),\n(\u2018sports\u2019, \u2018general\u2019), (\u2018society\u2019, \u2018general\u2019), (\u2018tech-\nnology & computing\u2019, \u2018general\u2019), (\u2018science\u2019, \u2018gen-\neral\u2019), (\u2018automotive\u2019, \u2018general\u2019) and (\u2018business\u2019,\n\u2018marketing\u2019). To transform those into features, we\ntake all Web sites returned by the reverse image\nsearch for the image, and we merge the lists of\ntheir category tuples. We do not differentiate be-\ntween high- and low-level categories; rather, we\njust apply TF.IDF on the combined list.\nTrue/False/Mixed media percentage : In order\nto determine whether an image is fake or not, we\ncan also check the reliability of the sources that\nwrote about it. Media Bias/Fact Check10(MBFC)\nis a Web site that provides factuality information\nabout 2700+ media sources. We use their database\nto classify each Web page that is returned by the\nreverse image search into the following categories:\nTrue (high factuality), False (low factuality) and\nMixed (mixed factuality). Then, we use the per-\ncentage of Web pages from each category returned\nby the reverse image search as a feature.\nKnown media percentage : If a URL is not on\nthe MBFC list, we label it as Unknown and we use\nthe percentage of known Web pages as a feature.\nTrue/False/Mixed media titles : We use the ti-\ntles of the articles from a True, False or Mixed me-\ndia as bag-of-words features.\n3.2 Features about the Claim\nSo far, in our feature extraction process we have\nonly used the image from the image-claim pair,\nwhich means we might be missing crucial infor-\nmation. After manual inspection of a few exam-\nples, we realized that about half of them can be\nclassi\ufb01ed only using the image, e.g., because it is\na collage, was photoshopped, or manipulated in\nsome way. The other half contain legitimate im-\nages that might appear on trustworthy Web sites,\nbut the claim associated with them was false.\nClaim text : We transform the text of the claim\ninto a TF.IDF vector, which we use as a feature.\n9http://github.com/matthewruttley/\nmozclassify\n10http://mediabiasfactcheck.com/3.3 Features about the Image-Claim pair\nIn addition to using the claim text, we want to\ncheck how it is related to the image and whether\nthe claim is true with respect to it. We model that\nby comparing the text of the claim to the articles\nreturned by the Reverse Image Search of the im-\nage. We use only the articles from trustworthy me-\ndia sources, according to our MBFC labels. We\napproach the task of computing the similarity of\nthose texts in two different ways.\nCosine similarity : We perform the compari-\nson on the TF.IDF representations of the claim and\neach article\u2019s title. We compute a smoothed aver-\nage on the list of cosine similarities to get the \ufb01nal\nfeature value.\nEmbedding similarity : We use pretrained em-\nbeddings of size 512 (Cer et al., 2018) as a way to\nvectorize the claim and the title sentences. Then, it\nis trivial to calculate the similarity as a dot product,\nas they are already in a normalized form. Again,\nwe use a smoothed average to reduce the list of\nsimilarities to a single number.\n4 Data\nAs we have a new task, we needed to create our\nown dataset. In fact, we created two datasets from\ntwo separate sources, but with similar qualities and\nformat. The main idea behind the data collec-\ntion process was to \ufb01nd viral, interesting and even\ncontradictory images with some text that describes\nthem, i.e., the claim . Both datasets are in English.\n4.1 The Snopes Dataset\nSnopes.com is arguably the oldest and the largest\nfact-checking Web site online. It aims to \ufb01ght\nmisinformation by investigating different pieces of\nnews. The site has a special section for image-\nrelated fact-checking, called Fauxtography11. It\nuses an extensive list of labels to classify each\npiece of news as True,False ,Miscaptioned ,Mix-\nture,Undetermined ,Unproven ,Outdated , etc. For\nthe purpose of our dataset, we gather only image-\nclaim pairs that were labeled as either True or\nFalse . The collected data consists of 838 exam-\nples of which 197 True and 641 False . The huge\nimbalance of the classes might be surprising at\n\ufb01rst, but it makes sense for fact-checkers to pre-\nfer to spend their time fact-checking news pieces\nthat have a higher chance of being fake.\n11http://www.snopes.com/fact-check/\ncategory/photos\n(a) South Korean President\nMoon Jae-in and North Ko-\nrean leader Kim Jong Un\nshake hands at the truce vil-\nlage of Panmunjom inside\nthe demilitarized zone sepa-\nrating the two Koreas.\n(b) Lava erupts from a \ufb01s-\nsure east of the Leilani Es-\ntates subdivision during on-\ngoing eruptions of the Ki-\nlauea V olcano.\nFigure 4: Examples of image-claim pairs from The\nReuters Dataset.\nYet, this lack of True-labeled examples can pose\nsome challenges for classi\ufb01cation models and the\nevaluation process as well. This is why we de-\ncided to invest some time in gathering more True\nexamples as we explain below.\n4.2 The Reuters Dataset\nAt the end of each year, Reuters publishes a list of\nabout 100 photos, called Pictures of the Year . Con-\nveniently for us, each photo comes with a short\ntextual description, which we can use as a claim .\nWe collected all of these pictures from four con-\nsecutive years: 2015, 2016, 2017, and 2018. As a\nresult, we ended up with a total of 395 True image-\nclaim pairs. Some examples are shown in Fig-\nure 4. We further performed close manual inspec-\ntion, and we did not \ufb01nd any obvious differences\nbetween these images compared to the ones from\nThe Snopes Dataset . In terms of the claim, texts\nfrom Reuters seem to be longer, but this should\nnot be a problem, since we do not use the length\nas a feature.\n5 Experiments and Evaluation\n5.1 Setup\nNote that the above two datasets contain 1,233\nexamples combined, and these examples are rel-\natively well-balanced: 592 True and 641 False .\nAs this is a small size, we chose to test the per-\nformance of the models using cross-validation. If\nwe mix the data from the two sources having in\nmind that the Reuters dataset has examples from\ntheTrue class only, we fear that the models might\nimplicitly learn each example\u2019s source, not its fac-\ntuality. Hence, we designed the following two\ncross-validation experiments:Testing on Snopes-only data. Ten times, using\na different random seed, we do the following:\n1. Randomly choose 50 True and 50 False\nSnopes examples and use them as a test set.\n2. Use the rest of the True Snopes data plus all\nReuters data as True training examples.\n3. Randomly sample the necessary number of\nexamples from the False Snopes data, so that\nthe training set is balanced.\nFinally, we compute the average of the evalua-\ntion measures for all ten folds.\nTesting on Snopes + Reuters data. Ten times,\nusing a different random seed, we perform the fol-\nlowing steps:\n1. Combine all Snopes and Reuters data into a\nsingle dataset.\n2. Balance the resulting dataset by randomly\nchoosing the necessary number of False ex-\namples.\n3. Do a random train-test split, so that the test\nset contains 100 examples.\nAs in the previous experiment, we compute\nthe average of the evaluation measures for all ten\nfolds.\n5.2 Classi\ufb01cation model\nWe used a Linear SVM with the default value of\nC=1. We trained a separate SVM model for each\nfeature type, then we applied a softmax to normal-\nize the values, and \ufb01nally we averaged the con\ufb01-\ndences of the classi\ufb01ers to make the \ufb01nal decision.\n5.3 Results\nWe used the following evaluation measures:\n\u000fAccuracy , because the classes are balanced,\nand the majority-class baseline for all experi-\nments is 50.0.\n\u000fAverage Precision , since it is useful if we\nwant to have a ranking task, e.g., to priori-\ntize which claims about images human fact-\ncheckers should check \ufb01rst. Again, the ran-\ndom baseline for all experiments is 50.0.\nFeature Acc (S) AP (S) Acc (S+R) AP (S+R)\nAll 63.2 73.0 80.1 90.3\nTrue media percentage 62.1 59.3 74.6 69.8\nEmbedding similarity of claim & true media titles 61.1 62.5 74.0 69.0\nCosine similarity of claim & true media titles 61.1 58.4 73.8 69.0\nKnown media percentage 60.4 58.6 74.6 71.9\nURL domains 60.3 67.3 78.6 89.7\nGoogle tags 58.5 63.9 71.5 82.1\nMixed media percentage 58.0 56.1 62.4 60.8\nClaim text 57.1 60.8 74.9 83.8\nTrue media titles 55.8 63.1 73.6 81.4\nMixed media titles 55.4 58.5 63.1 67.2\nURL categories 53.7 56.0 70.3 76.2\nFalse media titles 50.3 50.8 50.6 50.4\nFalse media percentage 49.9 51.1 50.4 50.4\nBaseline 50.0 50.0 50.0 50.0\nTable 1: Accuracy and Average Precision for individual feature types, calculated using 10-fold cross-validation\nusing the Snopes dataset ( S), and the Snopes+Reuters dataset ( S+R).\nTable 1 illustrates the importance of each fea-\nture type in isolation. We can see that almost all\nindividual feature types manage to outperform the\ntwo 50% baselines. The only weak features are\nthose related to false sources of information: per-\ncentage of unreliable media writing about the im-\nage and the words used in the titles of the articles.\nMoreover, using all features (with a model com-\nbination as explained above) works best: 63.2%\nand 80.1% Accuracy, 73.0% and 90.3% Average\nPrecision for S and S+R, respectively. The top-3\nfeature types for the Snopes test set are true me-\ndia percentage (62.1% for S and 74.6% for S+R),\nembedding similarity (61.1% for S and 74.0%\nfor S+R), and cosine similarity (61.1% for S and\n73.8% for S+R). In either experiment, Average\nPrecision is higher than Accuracy. Larger im-\nprovements are achieved for the Snopes + Reuters\ntest set, which could be due to the model making\nmore mistakes on the True examples from Snopes\nand being better on True examples from Reuters.\nFigure 5 shows combinations of the top- nfea-\ntures using each feature\u2019s performance in terms\nof Average Precision. Note that these top fea-\ntures for the two experiments are different: we use\nthe scores in the AP(S) column in Table 1 for the\nSnopes dataset, and the AP(S+R) column for the\nSnopes+Reuters dataset. We can see that selecting\nthe top 4 to 5 features works best, yielding 65.4%,\n75.1%, 84.1% and 92.5%.Note that the Average Precision scores are\nhigher than those for Accuracy, and the scores for\nthe Snopes+Reuters dataset are higher.\n6 Discussion\n6.1 Most Important Individual Features\nAbove, we explored the performance of individ-\nual feature groups. Here we try to understand\nwhat the most important individual features are.\nFor this purpose, we trained a model on all fea-\ntures, and then we analyzed the weight of each fea-\nture in this full model. Note that this is different\nfrom the setup in the previous section, where we\ntrained a separate model for each feature group,\nand then we combined the predictions of these\nmodels in an ensemble; in contrast, here we just\nput all features from all groups together. The re-\nsults are visualized in Figure 6. We can see that\nsome of them seem random, e.g., adventures of\nhuckleberry \ufb01n oreverything trump touches dies .\nHowever, there are a few that signal false infor-\nmation, e.g., words like fake andviral mentioned\nin the title of a trustworthy medium, or tags like\nhoax andfact-checking . The existence of images\nin the dataset that were modi\ufb01ed for artistic pur-\nposes can explain tags such as artand\ufb01lm. Also,\naccording to our best features, we should not trust\nmuch images that appear on Twitter or ones related\nto sensitive topics like african americans orislam .\nFigure 5: Accuracy and Average Precision on 10-fold cross-validation using top- nfeatures.\nFigure 6: The most informative features: 20 positive\nand 20 negative. Pre\ufb01xes indicate feature types.6.2 What Did Not Work\nMetadata from images : In an attempt to capture\npossible manipulation of the input image, we gath-\nered meta information using an open-source tool12\nfor image forensics. The tool extracts metadata in\nthe form of about 100 features such as size, reso-\nlution, GPS location. However, most of this meta-\ndata turns out to be missing from our images: only\n\ufb01ve features could be extracted for more than half\nof the images from the Snopes dataset.\nImage Splice Detection : As we have already\nmentioned, one of the reasons why an image could\nbe fake is that it has been digitally manipulated.\nA common manipulation is splicing, i.e., cropping\nand stitching together parts of the same image or\nmultiple different images. We explored an ap-\nproach that looks for the lack of self-consistency\nin images and outputs clusters of the predicted im-\nage parts using two algorithms: MeanShift and\nDBSCAN (Huh et al., 2018). An illustration on\nhow it works is shown in Figure 7. We decided to\nvalidate the method by using a pretrained model,13\nwhich we applied to some images from the Snopes\ndataset that were obvious cases of splicing.\n12http://github.com/redaelli/\nimago-forensics\n13http://github.com/minyoungg/\nselfconsistency\nFigure 7: Predicted clusters for one of the images in\nthe Self-Consistency paper. Keanu Reeves has been\nspliced into the photo and his body was separated cor-\nrectly by both MeanShift and DBSCAN.\nFigure 8: Predicted clusters for one of the images in\nthe Snopes Dataset. The original image depicts an ele-\nphant; the lion and the cub have been photoshopped on\ntop (Source). The clustering algorithms did not detect\nthis splicing.\nUnfortunately, this seemed not to work for us.\nFigure 8 shows an example where the model could\nnot \ufb01nd the spliced regions. Eventually, we aban-\ndoned this direction as the inference time and the\nrequired resources were signi\ufb01cant, and the per-\nformance was not very good on our dataset.\nError Level Analysis : Error Level Analysis\n(ELA) helps to identify areas within an image that\nare at different compression levels. With JPEG\nimages such as the ones in our Snopes and Reuters\ndatasets, the entire image should be at roughly the\nsame level. If a section of the image is at a signif-\nicantly different error level, this would indicate a\nlikely digital modi\ufb01cation.\nELA works by intentionally resaving the image\nat a known error rate such as 95%, and then com-\nputing the difference between the images. If there\nis virtually no change, then the cell has reached its\nlocal minima for error at that quality level. How-\never, if there is a large change, then the pixels are\nnot at their local minima and are effectively origi-\nnal. This method can be used to identify splicing,\nbecause stitched regions will appear brighter on\nthe ELA version of the image. This is illustrated\nin Figure 9. After manual inspection of ELA ver-\nsions of images from our dataset, we did not \ufb01nd\nthe method to be very promising, see Figure 10.\nFigure 9: One of the ELA examples on http://\nfotoforensics.com . The part of the image with a\n\ufb02oppy disk appears brighter on the ELA map, as it was\nspliced on top of the original.\nFigure 10: ELA applied to one of the images from the\nSnopes dataset. The spliced regions, i.e., the lion and\nthe cub, could not be identi\ufb01ed.\n6.3 Testing on New Data\nAll of the experiments described so far were per-\nformed on claim-image pairs from Snopes that\nwere published in the period between November\n20, 2000 and February 1, 2019. The data from\nFebruary up until April 29, 2019 has been left un-\ntouched, which makes it suitable for performing\none \ufb01nal test of the developed system. In these\nthree months, 64 articles were published in the\nFauxtography section, of which 14 were labeled as\nTrue and 25 as False . To balance this new test set,\nwe subsampled 14 False examples randomly. The\ntraining was performed on all previously collected\ndata from Snopes and Reuters, balanced in the\nsame way. For better certainty of the performance,\nwe sampled randomly the training and the test sets\nten times, and we report the average scores.\nThe results when using the top features based\non the Average Precision for the Snopes dataset\nare shown in Table 2. We can see that the best\nAverage Precision is achieved by using the single\ntop feature of URL domains: 71.7%. When we\nadd to this the second best one, i.e., the Google\ntags, we get an Accuracy of 64.3%. The scores of\nthe models that use more than three features are\nnot displayed since they were not as good.\nThe best-performing features across the exper-\niments differ, but as Table 1 shows, the URL do-\nmains are top-1 in three out of four experiments,\nandclaim text is top-2 in two out of four experi-\nments.\nFeatures Acc AP\nAll 59.3 69.7\nTop 1 62.9 71.7\nTop 2 64.3 70.4\nTop 3 57.5 70.6\nBaseline 50.0 50.0\nTable 2: Accuracy and Average Precision on the New\ntest dataset.\n7 Conclusion and Future Work\nWe have presented our efforts towards \ufb01ghting\nFauxtography, namely detecting fake claims about\nimages, which is an under-explored research di-\nrection. In particular, we created a new dataset\nfor this problem, and we explored a variety of fea-\ntures modeling the claim, the image, and the rela-\ntionship between the two. The evaluation results\nhave shown sizable improvements over the base-\nline. We release our dataset,14hoping to enable\nfurther research on fact-checking claims about im-\nages.\nIn future work, we plan to extend the dataset\nwith more examples, to try other features,\ne.g., from social media and from metadata,15and\nto adapt the system to work with other languages.\nWe further plan experiments with fact-checking\nclaims about videos.\nAcknowledgements\nThis research is part of the Tanbih project,16which\naims to limit the effect of \u201cfake news\u201d, propa-\nganda and media bias by making users aware of\nwhat they are reading. The project is developed\nin collaboration between the Qatar Computing\nResearch Institute (QCRI), HBKU and the MIT\nComputer Science and Arti\ufb01cial Intelligence Lab-\noratory (CSAIL).\n14http://gitlab.com/didizlatkova/\nfake-image-detection\n15The lack of metadata that we observed can be explained\nby the fact that Snopes.com is not the original source of the\nimage \ufb01les; it collected images from various external sources.\nThose sources might not be the original creator either and\nmultiple downloading and uploading of \ufb01les, with possible\nreformatting could mean loss of metadata as many Web sites\nreformat images and/or delete/change the metadata of the im-\nages uploaded to it. Finally, we could not extract any EXIF\nmetadata for the Reuters images, even though we got them\nfrom Reuters. Yet, maybe the metadata can be recovered us-\ning Reverse Image Search.\n16http://tanbih.qcri.org/References\nAtanas Atanasov, Gianmarco De Francisci Morales,\nand Preslav Nakov. 2019. Understanding the roles\nof political trolls in social media. In Proceed-\nings of the 2019 SIGNLL Conference on Compu-\ntational Natural Language Learning , CoNLL \u201919,\nHong Kong, China.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018a. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing ,\nEMNLP \u201918, pages 3528\u20133539, Brussels, Belgium.\nRamy Baly, Georgi Karadzhov, Abdelrhman Saleh,\nJames Glass, and Preslav Nakov. 2019. Multi-task\nordinal regression for jointly predicting the trustwor-\nthiness and the leading political ideology of news\nmedia. In Proceedings of the 17th Annual Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201919, pages 2109\u2013\n2116, Minneapolis, MN, USA.\nRamy Baly, Mitra Mohtarami, James Glass, Llu \u00b4\u0131s\nM`arquez, Alessandro Moschitti, and Preslav Nakov.\n2018b. Integrating stance detection and fact check-\ning in a uni\ufb01ed corpus. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , NAACL-HLT \u201918, pages\n21\u201327, New Orleans, LA, USA.\nBelhassen Bayar and Matthew C. Stamm. 2016. A\ndeep learning approach to universal image ma-\nnipulation detection using a new convolutional\nlayer. In Proceedings of the 4th ACM Workshop\non Information Hiding and Multimedia Security ,\nIH&MMSec \u201916, pages 5\u201310, Vigo, Spain.\nSevinc \u00b8 Bayram, Ismail Avcibas, B \u00a8ulent Sankur, and\nNasir D Memon. 2006. Image manipulation detec-\ntion. Journal of Electronic Imaging , 15(4):041102.\nKevin R. Canini, Bongwon Suh, and Peter L. Pirolli.\n2011. Finding credible information sources in so-\ncial networks based on content and social structure.\nInProceedings of the IEEE International Confer-\nence on Privacy, Security, Risk, and Trust, and the\nIEEE International Conference on Social Comput-\ning, SocialCom/PASSAT \u201911, pages 1\u20138, Boston,\nMA, USA.\nTiago Jose de Carvalho, F \u00b4abio Augusto Faria, H \u00b4elio\nPedrini, Ricardo da Silva Torres, and Anderson\nRocha. 2016. Illuminant-based transformed spaces\nfor image forensics. IEEE Transactions on Informa-\ntion Forensics and Security , 11:720\u2013733.\nCarlos Castillo, Marcelo Mendoza, and Barbara\nPoblete. 2011. Information credibility on Twitter. In\nProceedings of the 20th International Conference on\nWorld Wide Web , WWW \u201911, pages 675\u2013684, Hy-\nderabad, India.\nDaniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua,\nNicole Limtiaco, Rhomni St. John, Noah Constant,\nMario Guajardo-Cespedes, Steve Yuan, Chris Tar,\nBrian Strope, and Ray Kurzweil. 2018. Universal\nsentence encoder for English. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing , EMNLP \u201918, pages 169\u2013174,\nBrussels, Belgium.\nStephen Cooper. 2007. A concise history of the faux-\ntography blogstorm in the 2006 Lebanon war. Amer-\nican Communication Journal , 9.\nSebastian Dungs, Ahmet Aker, Norbert Fuhr, and\nKalina Bontcheva. 2018. Can rumour stance alone\npredict veracity? In Proceedings of the 27th In-\nternational Conference on Computational Linguis-\ntics, COLING \u201918, pages 3360\u20133370, Santa Fe, NM,\nUSA.\nAndreas Hanselowski, Avinesh PVS, Benjamin\nSchiller, Felix Caspelherr, Debanjan Chaudhuri,\nChristian M. Meyer, and Iryna Gurevych. 2018. A\nretrospective analysis of the fake news challenge\nstance-detection task. In Proceedings of the 27th\nInternational Conference on Computational Lin-\nguistics , COLING \u201918, pages 1859\u20131874, Santa Fe,\nNM, USA.\nMinyoung Huh, Andrew Liu, Andrew Owens, and\nAlexei A. Efros. 2018. Fighting fake news: Im-\nage splice detection via learned self-consistency. In\nComputer Vision \u2013 ECCV 2018 , pages 106\u2013124,\nCham. Springer International Publishing.\nZhiwei Jin, Juan Cao, Yongdong Zhang, Jianshe Zhou,\nand Qi Tian. 2016. Novel visual and statistical im-\nage features for microblogs news veri\ufb01cation. IEEE\nTransactions on Multimedia , PP:1\u20131.\nGeorgi Karadzhov, Preslav Nakov, Llu \u00b4\u0131s M `arquez,\nAlberto Barr \u00b4on-Cede \u02dcno, and Ivan Koychev. 2017.\nFully automated fact checking using external\nsources. In Proceedings of the Conference on Re-\ncent Advances in Natural Language Processing ,\nRANLP \u201917, pages 344\u2013353, Varna, Bulgaria.\nJing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon,\nBernard J. Jansen, Kam-Fai Wong, and Meeyoung\nCha. 2016. Detecting rumors from microblogs with\nrecurrent neural networks. In Proceedings of the\n25th International Joint Conference on Arti\ufb01cial In-\ntelligence , IJCAI \u201916, pages 3818\u20133824, New York,\nNY , USA.\nJing Ma, Wei Gao, and Kam-Fai Wong. 2017. De-\ntect rumors in microblog posts using propagation\nstructure via kernel learning. In Proceedings of the\n55th Annual Meeting of the Association for Compu-\ntational Linguistics , ACL \u201917, pages 708\u2013717, Van-\ncouver, Canada.\nTsvetomila Mihaylova, Preslav Nakov, Llu \u00b4\u0131s M`arquez,\nAlberto Barr \u00b4on-Cede \u02dcno, Mitra Mohtarami, Georgi\nKaradjov, and James Glass. 2018. Fact checking incommunity forums. In Proceedings of the Thirty-\nSecond AAAI Conference on Arti\ufb01cial Intelligence ,\nAAAI \u201918, pages 879\u2013886, New Orleans, LA, USA.\nMitra Mohtarami, Ramy Baly, James Glass, Preslav\nNakov, Llu \u00b4\u0131s M `arquez, and Alessandro Moschitti.\n2018. Automatic stance detection using end-to-\nend memory networks. In Proceedings of the 16th\nAnnual Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , NAACL-HLT \u201918,\npages 767\u2013776, New Orleans, Louisiana, USA.\nMitra Mohtarami, James Glass, and Preslav Nakov.\n2019. Contrastive language adaptation for cross-\nlingual stance detection. In Proceedings of the 2019\nConference on Empirical Methods in Natural Lan-\nguage Processing , EMNLP \u201919, Hong Kong, China.\nSubhabrata Mukherjee and Gerhard Weikum. 2015.\nLeveraging joint interactions for credibility analy-\nsis in news communities. In Proceedings of the\n24th ACM International on Conference on Informa-\ntion and Knowledge Management , CIKM \u201915, pages\n353\u2013362, Melbourne, Australia.\nKashyap Popat, Subhabrata Mukherjee, Jannik\nStr\u00a8otgen, and Gerhard Weikum. 2017. Where the\ntruth lies: Explaining the credibility of emerging\nclaims on the Web and social media. In Proceedings\nof the 26th International Conference on World Wide\nWeb Companion , WWW \u201917, pages 1003\u20131012,\nPerth, Australia.\nBenjamin Riedel, Isabelle Augenstein, Georgios P Sp-\nithourakis, and Sebastian Riedel. 2017. A simple but\ntough-to-beat baseline for the Fake News Challenge\nstance detection task. ArXiv:1707.03264 .\nMatthew C Stamm and KJ Ray Liu. 2010. Forensic\ndetection of image manipulation using statistical in-\ntrinsic \ufb01ngerprints. IEEE Transactions on Informa-\ntion Forensics and Security , 5(3):492\u2013506.\nJames Thorne, Mingjie Chen, Giorgos Myrianthous,\nJiashu Pu, Xiaoxuan Wang, and Andreas Vlachos.\n2017. Fake news stance detection using stacked en-\nsemble of classi\ufb01ers. In Proceedings of the EMNLP\nWorkshop on Natural Language Processing meets\nJournalism , pages 80\u201383, Copenhagen, Denmark.\nSoroush V osoughi, Deb Roy, and Sinan Aral.\n2018. The spread of true and false news online.\n359(6380):1146\u20131151.\nDaniel Yue Zhang, Lanyu Shang, Biao Geng, Shuyue\nLai, Ke Li, Hongmin Zhu, Md Tanvir Amin, and\nDong Wang. 2018. Fauxbuster: A content-free faux-\ntography detector using social media comments. In\n2018 IEEE International Conference on Big Data ,\nBigData \u201918, pages 891\u2013900. IEEE.\nArkaitz Zubiaga, Maria Liakata, Rob Procter, Geral-\ndine Wong Sak Hoi, and Peter Tolmie. 2016.\nAnalysing how people orient to and spread rumours\nin social media by looking at conversational threads.\nPLoS ONE , 11(3):1\u201329.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fact-checking meets fauxtography: Verifying claims about images", "author": ["D Zlatkova", "P Nakov", "I Koychev"], "pub_year": "2019", "venue": "arXiv preprint arXiv:1908.11722", "abstract": "The recent explosion of false claims in social media and on the Web in general has given rise  to a lot of manual fact-checking initiatives. Unfortunately, the number of claims that need to"}, "filled": false, "gsrank": 268, "pub_url": "https://arxiv.org/abs/1908.11722", "author_id": ["lqrAOcYAAAAJ", "DfXsKZ4AAAAJ", "o5YAI9wAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:OktUlLXJbY0J:scholar.google.com/&output=cite&scirp=267&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D260%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=OktUlLXJbY0J&ei=M7WsaKqxMrXCieoP4PfQ0A8&json=", "num_citations": 125, "citedby_url": "/scholar?cites=10191023313524116282&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:OktUlLXJbY0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1908.11722"}}]