[{"title": "GREENER: Graph neural networks for news media profiling", "year": "2022", "pdf_data": "GREENER: Graph Neural Networks for News Media Pro\ufb01ling\nPanayot Panayotov\nSo\ufb01a University\np.d.panayotov09@gmail.comUtsav Shukla\nTIETHusrev T. Sencar\nQCRI, HBKU\nhsencar@hbku.edu.qa\nMohamed Nabeel\nQCRI, HBKU\nmnabeel@hbku.edu.qaPreslav Nakov\nMohamed bin Zayed University of Arti\ufb01cial Intelligence\npreslav.nakov@mbzuai.ac.ae\nAbstract\nWe study the problem of pro\ufb01ling news me-\ndia on the Web with respect to their factual-\nity of reporting and bias. This is an important\nbut under-studied problem related to disinfor-\nmation and \u201cfake news\u201d detection, but it ad-\ndresses the issue at a coarser granularity com-\npared to looking at an individual article or an\nindividual claim. This is useful as it allows\nto pro\ufb01le entire media outlets in advance. Un-\nlike previous work, which has focused primar-\nily on text (e.g., on the text of the articles pub-\nlished by the target website, or on the textual\ndescription in their social media pro\ufb01les or in\nWikipedia), here our main focus is on model-\ning the similarity between media outlets based\non the overlap of their audience. This is mo-\ntivated by homophily considerations, i.e., the\ntendency of people to have connections to peo-\nple with similar interests, which we extend to\nmedia, hypothesizing that similar types of me-\ndia would be read by similar kinds of users.\nIn particular, we propose GREENER (GRaph\nnEural nEtwork for News mEdia pRo\ufb01ling), a\nmodel that builds a graph of inter-media con-\nnections based on their audience overlap, and\nthen uses graph neural networks to represent\neach medium. We \ufb01nd that such representa-\ntions are quite useful for predicting the factu-\nality and the bias of news media outlets, yield-\ning improvements over state-of-the-art results\nreported on two datasets. When augmented\nwith conventionally used representations ob-\ntained from news articles, Twitter, YouTube,\nFacebook, and Wikipedia, prediction accuracy\nis found to improve by 2.5-27 macro-F1 points\nfor the two tasks.\n1 Introduction\nThe problem of news media pro\ufb01ling with respect\nto their factuality of reporting and political bias is\nimportant but under-studied. It is related to disin-\nformation and \u201cfake news\u201d detection, but it is of\ndifferent granularity compared to looking at an indi-\nvidual article or at an individual claim. This kind ofpro\ufb01ling can be done by professional fact-checkers,\nwho inspect the articles and the multimedia mate-\nrial published by the target news outlet.\nHowever, doing this automatically while solely\nrelying on text features is a very challenging task as\nprevious work has shown (Baly et al., 2018, 2020).\nIt gets even more complicated when considering\nnews sources where only limited amount of content\nis available for evaluation. Therefore, not only is\nthere a need to more thoroughly characterize news\nmedia, but there is also a need to be able to do so\nin a predictive fashion using limited information.\nA crucial consideration is the need to comple-\nment the textual representation with other elements\nof a news medium that may serve as reliable indi-\ncators of its factuality of reporting and bias. These\nmay relate to multimedia creation and curation pro-\ncesses (Jin et al., 2016; Huh et al., 2018), to its\nunderlying infrastructure and technological com-\nponents used to serve its content (Fairbanks et al.,\n2018; Castelo et al., 2019; Hounsel et al., 2020),\nand, more critically, to characteristics of its audi-\nence (Baly et al., 2020; Chen and Freire, 2020).\nHere, we explore ways to augment the textual\nrepresentations from the articles published by a tar-\nget news medium by introducing new information\nsources that relate to media audience homophily,\naudience engagement, and media popularity. In par-\nticular, we propose the GREENER (GRaph nEural\nnEtwork for News mEdia pRo\ufb01ling) model, which\nbuilds graph neural networks that model the audi-\nence overlap between websites, which we further\ncomplement with other state-of-the-art representa-\ntions. Our contributions are as follows:\n\u2022We propose a novel model, based on graph\nneural networks that models the audience over-\nlap between media in order to predict the fac-\ntuality and the bias of entire news outlets.\n\u2022We show that the information in our graph is\ncomplementary to other information sourcesarXiv:2211.05533v1  [cs.LG]  10 Nov 2022\nsuch as the text of the articles by the target\nnews outlet, as well as to information from\nTwitter, Youtube, Facebook, and Wikipedia.\n\u2022We report sizable improvements over the state\nof the art on two standard datasets and for two\ntasks: predicting the factuality of reporting\nand the bias of news outlets.\n\u2022We release the code, the data, the processed\nfeatures, and the representations used in our\nexperiments.\n2 Related Work\nPrevious work on automating the process of charac-\nterizing news sites based on the factuality of their\nreporting and on their political bias has mainly\nfocused on analysis of the textual content of the\nrespective website (Afroz et al., 2012; Rubin et al.,\n2015; Rashkin et al., 2017; Potthast et al., 2018;\nBaly et al., 2018; P\u00e9rez-Rosas et al., 2019). Al-\nthough style-based analysis of the text can help\nreveal the intent of an article, it cannot ultimately\nevaluate the authenticity and the objectivity of the\nclaims stated in that article. In fact, as demon-\nstrated by the results in (Baly et al., 2020) on\na manually fact-checked and categorized dataset,\nstate-of-the-art textual representations can only\nachieve a prediction accuracy around 65-71% for\nfactuality and 70-85% for bias depending on the\ndatasets. Thus, several approaches have been pro-\nposed to supplement the content-level analysis with\nother contextual and relational information avail-\nable about the target news outlet.\nMultimedia has been an important element of\nconveying news and information by all news me-\ndia. Due to its prevalence, tampering detection and\nidenti\ufb01cation of processing related traces in photos\nand videos have long been a focus of study (Sen-\ncar et al., 2021). The fact that multimedia editors\nof a news site follow a work\ufb02ow when creating,\nacquiring, editing, and curating content for their\npages makes it possible to characterize a website\nbased on multimedia content. Therefore, visual\nfeatures are increasingly being explored and used\nto predict the factuality of reporting of news media\n(Jin et al., 2016; Huh et al., 2018; Khattar et al.,\n2019; Zlatkova et al., 2019; Qi et al., 2019; Singhal\net al., 2019).\nBeyond textual and visual features, news sites\nalso exhibit distinct characteristics in the way theyset up their infrastructure to serve content. To de-\ntect low-factuality news sites, it was proposed to\nuse features that relate to network, web design, and\ndata elements of the target website. At the network\nlevel, it was shown that a website\u2019s domain, certi\ufb01-\ncate, and hosting properties can serve as reliable\nidenti\ufb01ers (Hounsel et al., 2020). Concerning the\nweb design aspect, several features capturing the\npattern of elements that govern the structure and the\nstyle of a web page have been also used (Castelo\net al., 2019). Finally, at the data level, shared con-\ntent among web sites and mutually linked sites\nwere used to identify similar sites (Fairbanks et al.,\n2018). Overall, a major advantage of using infras-\ntructure features is their content-agnostic nature.\nAnother set of features used to estimate the fac-\ntuality and the bias of a news source is based on\naudience characteristics following the homophily\nprinciple, which simply states that similar individ-\nuals interact with each other at a higher rate than\nwith dissimilar ones. In the context of social me-\ndia platforms, several approaches were proposed\nto infer the similarity between news media through\nobtaining and comparing descriptive characteris-\ntics of the followers of a news medium (Baly et al.,\n2020) and by pro\ufb01ling how these followers respond\nto the content of the target news medium in their\ncomments and with their posting and sharing behav-\nior (Wong et al., 2013; Chen and Freire, 2020). In\nthis regard, a more reliable indicator for similarity\nof news sites is how much the followers of different\nnews media overlap (Darwish et al., 2020).\nUltimately, these features were all obtained from\ndisparate data sources and are all complementary\nin nature. Therefore, a more accurate characteriza-\ntion of the news reporting practice of a given news\nmedium can be achieved by deploying more com-\nprehensive heterogeneous learning approaches. To\nthis objective, in this work, we propose to use graph\nneural networks to model the audience homophily\nrelations based on audience overlap and engage-\nment statistics from Alexa. In order to provide a\nmore holistic view, our representation is also cou-\npled with state-of-the-art textual representations\nextracted from media articles, as well as on other\naudience characteristics proposed in the context of\nsocial media platforms.\n3 Method\nTo characterize the similarity between news me-\ndia in terms of their factuality of reporting and\npolitical bias, we mainly rely on audience over-\nlap, which is based on the idea that if a group of\nvisitors have a common interest in some websites,\nthen those websites must be similar in some respect.\nWith this idea, we create an undirected Web audi-\nence overlap graph, where nodes represent news\nmedia sites and edges indicate that that two news\nsites have an overlapping set of visitors, as well as\nthe degree of overlap. The graph is created using\na seed list of news sites for which factuality and\nbias ratings are manually annotated by professional\nfact-checkers1. This initial graph only captures the\nrelation between websites due to visitors that are\ninterested in a pair of sites, and it cannot represent\nindirect relations where visitors might have com-\nmon taste in their news consumption, but do not\nnecessarily visit the same websites.\nIn order to also identify such connections be-\ntween news sites, we iteratively expand the graph\nby adding new neighboring nodes for a more com-\nprehensive representation of the audience overlap,\nwhich is discussed in detail in section 3.2. The\ngraph is further enhanced by incorporating user en-\ngagement statistics as node attributes in order to\nmodel the relation between a site and its visitors\nbetter. We then use graph neural networks to en-\ncode these relations and to obtain node embeddings\nrepresenting different categories of news sites. We\nfurther combine these embeddings with textual rep-\nresentations from articles from each news website.\n3.1 Alexa Metrics\nAlexa is a web traf\ufb01c analysis company that pro-\nduces statistics about the browsing behavior of In-\nternet users. These statistics are computed over\na rolling three-month window; they are updated\ndaily, and are either obtained directly from sites\nthat choose to install a tracking script on their web\npages or are estimated from a sample of data gener-\nated by millions of users using browser extensions\nand plug-ins related to Alexa.2Figure 1 shows a\nsample Alexa page providing web traf\ufb01c and do-\nmain statistics for the website wsj.com.\nWe used the Alexa Audience Overlap Tool to\nextract statistics, which we used to build our Web\naudience overlap graph: links and node attributes.\nAudience Overlap: This includes a list of web-\nsites most similar to the target. Alexa calculates the\n1The annotation of the seed nodes in the graph comes\nfrom factuality and the bias ratings provided at http://\nmediabiasfactcheck.com\n2www.alexa.com/find-similar-sites\nFigure 1: Alexa Rank information for wsj.com .\nsimilarity between two websites based on shared\nvisitors and overlap in the keywords used in their\nwebpages. For each pair of overlapping sites, a\nscore is computed to quantify the degree of over-\nlap. Preliminary analysis of Alexa Rank has shown\nthat a highly factual site, such as reuters.com,\nhas sizable audience overlap with other factual\nsites. Similarly, a low-factuality website such\nasinfowars.com , shares audience with other low-\nfactulity websites. The audience homophily also\nholds for political bias, e.g., foxnews.com and\ncnn.com share audience primarily with other right-\nand left-leaning websites, respectively.\nFigure 2 shows the overlapping websites for\nwsj.com, where we can see its homophily with\nother high-factuality websites. A similar pattern is\nobserved for bias, where left/right-leaning websites\noverlap with other left/right-leaning websites.\nFigure 2: Audience overlap graph for The Wall Street\nJournal , showing that most of its neighboring nodes\nhave the same factuality label: high.\nTraf\ufb01c Rank: A site\u2019s rank is a measure of its\npopularity, which is computed based on the number\nof unique users that visit it and on the total number\nof URL requests they made on a single day. Page\nviews corresponding to different URL requests are\ncounted separately only if they are 30 minutes apart\nfrom each other. We logarithmically scale this rank\nfor a more compact representation.\nSites Linking In: This is the number of websites\nin the Common Crawl corpus that link to a given\nwebsite. The list excludes links placed to in\ufb02uence\nsearch engine rankings of the linked page.\nBounce Rate: Bounce rate is an engagement\nstatistic showing the level of interest visitors have\nin the content of a website. It is measured as the per-\ncentage of visits that consist of a single pageview,\ni.e., when the visitor does not click on any of the\nlinks on the landing page.\nDaily Pageviews per Visitor: This is the average\nnumber of pages viewed (or refreshed) by visitors.\nDaily Time on Site: This is another engagement\nstatistics, which shows the average time, in min-\nutes and seconds, that a visitor spends on a target\nwebsite each day. We convert it to seconds.\nBinarized Alexa Metrics: Among the above-\ndescribed Alexa site metrics, Sites Linking In pro-\nduces a list of websites through analysis of web\ncrawled data. Therefore, the completeness of the\nlist depends on the crawling coverage. The last\nthree metrics, ( i.e., daily page views, bounce rate,\nand daily time on site) measure the level of user\nengagement with the website. If users bounce at\na higher rate, do not stay very long, or only view\na few pages, they are likely less interested in that\nwebsite. Hence, the reliability of these three met-\nrics depends on the size of the sample of users that\nwas used for the measurements. Due to these limita-\ntions, not all sites have such corresponding metrics\ncalculated by Alexa Rank. Table 6 shows statistics\nabout the overall availability of these metrics for\nwebsites in the two datasets. Therefore, as a more\ncrude measure of site popularity and engagement,\nwe also use the binary versions of these four met-\nrics as features showing whether Alexa was able to\nprovide these metrics for the target website. These\nare given in rows 8\u201311 of Table 6.\n3.2 Audience Overlap Graph Construction\nWhen queried with a target news site\u2019s address,\nthe Alexa siteinfo3tool returns a list of 4-5 sites\nthat are most similar to the queried website based\non audience overlap. For example, for wsj.com ,\nwe obtain the following list of similar web-\nsites and similarity scores: marketwatch.com\n39.4, cnbc.com 39.4, bloomberg.com 35.9,\nreuters.com 34.5. We use these pairs of web-\nsites and overlap scores to build the edges of our\ngraph, as shown in Figure 2. Given a set of web-\nsites, we repeatedly query for each website and we\ngrow our graph by adding new nodes and edges.\nThe resulting graph, obtained after performing this\n3http://www.alexa.com/siteinfotask for every site in our dataset, is referred to as\nlevel 0 audience overlap graph.\nFor richer and denser representations, we then\nexpand our overlap graph to higher levels. For this,\nwe repeat the aforementioned steps of connecting\nwebsite nodes according to audience overlap for the\nnew websites identi\ufb01ed during building the level-\n0 overlap graph, which were not initially in our\nseed list of websites. This yields to level-1 over-\nlap graph as displayed in Figure 3, where the dis-\ntinction between low-factuality and high-factuality\nnodes can be clearly observed. The same proce-\ndure is repeated until obtaining level-4 graphs. We\nobserve that the performance gain is marginal be-\nyond level-4. We attribute this observation to the\nweaker in\ufb02uence of the nodes towards the leaf to\nthe labeled nodes as well as decreasing popularity\nof domains associated with the leaf nodes. Thus,\nwe limit the expansion to level-4.\nFigure 3: Bird\u2019s eye view of our overlap graph. Nodes\nrepresent news sites and colors code site factuality: red\ncorresponds to low-factuality, green to high-factuality,\nand white to mixed factuality and unknown sites.\n3.3 Representation Learning on Graphs\nIn recent years, graph learning algorithms have\nbeen extensively used to model dependencies and\nrelations between entities and to learn representa-\ntions that embed graph nodes in a low-dimensional\nembedding space. We observe that different graph\nlearning models learn different aspects of nodes in\na graph. Thus, to get representations for news me-\ndia in our overlap graphs, we use both random-walk\nbased shallow graph embedding methods, such as\nnode2vec (Grover and Leskovec, 2016), and graph\nneural networks (GNNs) such as Graph Convolu-\ntional Networks (GCN) (Kipf and Welling, 2017)\nand GraphSAGE (Hamilton et al., 2017).\nIn essence, Node2Vec (Grover and Leskovec,\n2016) is one of the earliest graph learning frame-\nworks. The model is inspired by Word2Vec\n(Mikolov et al., 2013), but instead of using se-\nquences of words and optimizing the proximity\nloss, sequences for graph are generated by sam-\npling random walks of a \ufb01xed maximum length\nfor each node. These sequences of random walks\nare then used with a skip-gram model, just as\nwith Word2Vec, to learn representations for the\nnodes. While Node2Vec produces embeddings\nsolely based on the graph structure, GNN models,\nGCN and GraphSAGE, capture both the structure\nas well as their node/edge attributes. The latter\nmodels perform graph convolution operations over\nthe computation graph of each node in the graph.\nA key difference between GCN and GraphSAGE is\nhow they perform the convolution operation: GCN\nutilizes spectral operations whereas GraphSAGE\nutilizes spatial operations. Further, GCN consid-\ners all neighboring nodes whereas GraphSAGE is\n\ufb02exible to consider only a sampled subset of neigh-\nboring nodes. These differences in their construc-\ntions result in slightly different representations for\ndifferent graph learning algorithms.\nUsing these three graph representation learning\nalgorithms, we obtain low-dimensional vector rep-\nresentations (512 for Node2Vec, 128 for GCN, and\n128 for GraphSAGE) of each node (website) in our\ngraph. We empirically \ufb01nd that these embedding\ndimensions for respective algorithms yield the best\ndownstream classi\ufb01cation performance with a rea-\nsonable amount of computing resources. We will\nrefer to these representations as graph embeddings\nthroughout the paper. When creating our models,\n80% of each dataset is assigned to the training set\nand 20% to the test set, and for model evaluation\nwe performed \ufb01ve-fold random cross validation.\nFurther, we tune our GNN models to use the fol-\nlowing hyperparameters: number of epochs = 1000,\nnumber of layers = 4, learning rate = 0.01, weight\ndecay = 0.0005 and dropout = 0.5. We tune our\nNode2Vec model to use the following hyperparam-\neters: number of walks = 10, walk length = 100,\nnumber of dimensions = 512, return parameter (p)\n= 0.5 and in-out parameter (q) = 2.\nEMNLP-2018 ACL-2020\nPolitical Bias Factuality Political Bias Factuality\nLeft 189 High 256 Left 243 High 162\nCentre 564 Mixed 268 Centre 272 Mixed 249\nRight 313 Low 542 Right 349 Low 453\nTable 1: Label distribution for the two datasets.4 Experiments and Evaluation\nDatasets To evaluate our system, we use two\ndatasets from previous work: (Baly et al., 2018)\nand (Baly et al., 2020). We will refer to them as\nEMNLP-2018 dataset andACL-2020 dataset , re-\nspectively. Both datasets contain lists of media\ndomains along with their bias and factuality labels\nfrom Media Bias/Fact Check,4which is an indepen-\ndent journalism outlet. Factuality is modeled on a\nthree-point scale, i.e.,high,mixed , and low. Origi-\nnally, political bias was modeled on a seven-point\nscale, but previous work has merged the fringe la-\nbels together and converted it into a three-point\nscale, i.e.,left,centre , and right . Table 1 shows the\nlabel distribution of the two datasets.\nGeneration of Graph Embeddings We use the\naudience overlap graph constructed above along\nwith the all the Alexa site metrics as node fea-\ntures. We then impute the missing features by\ntaking the average of the \ufb01ve nearest neighbors.\nBoth GCN and GraphSAGE are executed under\nthe semi-supervised setting and the representations\nof the last hidden layer in the respective models\nare obtained as the node embeddings. Node2vec\ntakes the graph structure as the input and produces\na node embedding for each node in an unsupervised\nsetting.\nExperimental Setup The predictive capability\nof the node-level representations obtained using\nthe three graph learning models are evaluated both\nindividually and in combination in a supervised\nsetting. For this, we used \ufb01ve-fold cross-validation\nto train and to evaluate an SVM model using the\nthe node embeddings along with their factuality\nand bias labels. We performed grid search to tune\nthe values of the hyper-parameters of our SVM\nmodel with an RBF kernel. As the datasets for both\nyears and for both tasks are imbalanced, we opti-\nmized macro-F1 using grid search. We evaluated\nour model on the remaining unseen fold, and we\nreport both macro-F1 score and accuracy.\nWhen combining the three representations, we\nadopt a late-fusion strategy. To this end, we train\nseparate classi\ufb01ers for each type of representation,\nand then we train an ensemble by averaging the pos-\nterior probabilities obtained by each model. This al-\nlows the ensemble model to learn different weights,\nthereby ensuring that more attention is paid to the\nprobabilities produced by better models.\n4http://mediabiasfactcheck.com/\n# Model F1 Acc.\n1 Majority class baseline 22.47 50.84\nPrevious work: (Baly et al., 2018)\n2 Articles (GloVe) 58.02 64.35\n3 Best overall model (Articles + Twitter + Wikipedia + URL analysis + Alexa Rank) 59.91 65.48\nOur results\n4 Node2Vec 60.60 68.19\n5 GCN 72.23 75.94\n6 Supervised GraphSage 86.04 87.55\n7 Node2Vec+ Supervised GraphSage + GCN (late fusion) 86.97 88.49\n8 Node2Vec + Supervised GraphSage + GCN + Articles + AlexaMetrics (late fusion) 87.20 88.58\nTable 2: Factuality prediction on the EMNLP-2018 dataset.\n# Model F1 Acc.\n1 Majority class baseline 22.93 52.43\nPrevious work: (Baly et al., 2020)\n2 Best \u201cWho Read It\u201d model 42.48 58.76\n3 Articles (BERT) 61.46 67.94\n4 Best overall model (Articles + Twitter + YouTube) 67.25 71.52\nOur results\n5 Node2Vec 59.70 67.20\n6 GCN 53.76 61.47\n7 Supervised GraphSage 56.22 63.45\n8 Node2Vec + Supervised GraphSage + GCN (late fusion) 63.48 69.27\n9 Node2Vec + Supervised GraphSage + GCN + Articles + Twitter + YouTube + 69.61 74.27\nFacebook + AlexaMetrics (late fusion)\nTable 3: Factuality prediction on ACL-2020 dataset.\nFinally, to evaluate the complementary nature\nof the audience homophily and characteristics ex-\nhibited in the textural content of media websites\nand descriptions of their audience in social media\nplatforms, these two sources of information are\ncombined to make predictions. For this purpose,\nwe utilized the sentence representations of the news\narticles and Wikipedia descriptions associated with\neach news medium as well as the Twitter, YouTube,\nand Facebook audience representations available\nin the repository of (Baly et al., 2020). Further\ndetails on these features are provided in Sec.B of\nthe Appendix.\nFor studying the ef\ufb01cacy of our system, we com-\npare the results of EMNLP-2018 dataset to the best\nprevious overall models and with models using\nonly textual representations (which was the best-\nperforming single feature and included GloVe (Pen-\nnington et al., 2014) representations for the arti-\ncles). As our audience overlap graph falls under\ntheWho Read It category of features in (Baly et al.,\n2020), for the 2020 tasks, in addition to the best\nprevious model and the best model using textual\nrepresentations (based on average RoBERTa sen-tence representations), we also compare to the best\nWho Read It model.\nWe used Nvidia\u2019s K80 GPUs to train the graph\nembeddings, which took around 30 minutes. The\nneural network training and inference phases were\nboth carried out on the CPU. In our repository\nwe\u2019ve documented every package version for easy\nreplication of our results.\nFactuality Prediction Table 2 shows our results\nfor factuality prediction task on the EMNLP-2018\ndataset. (In the table, each group of embeddings\nare referred to by the name of graph learning al-\ngorithm used in their generation.) We can see that\nall three types of graph embeddings (rows 4-6) out-\nperform the Articles representations (row 2) and\nthe best result from previous work (row 3), which\ncombines representations from several sources. As\nexpected, the combination of the graph embeddings\nperform as a more powerful predictor improving\nthe macro-F1 score by more than 17 points ab-\nsolute (row 7). We then incorporated our graph\nrepresentations with a subset of earlier introduced\nfeatures that yielded the best performance (row 8).\nThis provided an additional improvement of +0.23\n# Model F1 Acc.\n1 Majority class baseline 22.61 51.33\nPrevious work: (Baly et al., 2018)\n2 Articles (GloVe; our rerun) 61.64 68.01\n3 Best overall model (Articles + Wikipedia + URL analysis + Alexa Rank) 63.27 69.89\nOur results\n4 Node2Vec 67.64 73.55\n5 GCN 52.62 60.28\n6 Supervised GraphSage 52.18 64.81\n7 Node2Vec + Supervised GraphSage + GCN (late fusion) 65.97 73.20\n8 Node2Vec + GCN + Supervised GraphSage + Articles + AlexaMetrics (late fusion) 72.44 76.98\nTable 4: Bias prediction on EMNLP-2018 dataset.\n# Model F1 Acc.\n1 Majority Class 19.18 40.39\nPrevious work: (Baly et al., 2020)\n2 Articles (BERT) 79.34 79.75\n3 Best \u201cWho Read it\u201d model 65.12 66.44\n4 Best overall model (Articles + Wikipedia + Twitter + YouTube) 84.77 85.29\nOur results\n5 Node2Vec 75.70 76.95\n6 GCN 77.81 78.81\n7 Supervised GraphSage 88.50 88.59\n8 Node2Vec + GCN + Supervised GraphSage (late fusion) 89.59 89.76\n9 Node2Vec + GCN + Supervised GraphSage + Articles + Wikipedia + Twitter + YouTube + 91.93 92.08\nAlexaMetrics (late fusion)\nTable 5: Bias Prediction on ACL-2020 dataset.\nmacro-F1 points.\nTable 3 shows our results on the ACL-2020\ndataset for the factuality prediction task. Here our\ngraph embeddings (rows 5-7) perform comparable\nto the best text representation from previous work\n(row 3), i.e., the Articles representation obtained\nusing \ufb01ne-tuned BERT. Comparing the graph em-\nbeddings with other audience characteristics (the\nWho Read It category of features), we can see that\nthe discrimination power inherent to the audience\noverlap feature is much higher (by around 14-17\nmacro-F1 points absolute) than that of the latter fea-\ntures. Unlike the EMNLP-2018 dataset, however,\nnone of the graph embeddings outperformed the\nbest model that combines different versions of tex-\ntual representations (row 4). Further, we observed\nthat Node2Vec representations yielded more accu-\nrate predictions than GCN and GraphSAGE repre-\nsentations on this dataset. When graph embeddings\nare combined with earlier introduced representa-\ntions, those associated with Articles and descriptive\ncharacteristics of Twitter, YouTube, and Facebook\naudiences, we obtain a signi\ufb01cantly better result\nthat outperforms the previous best result by a mar-\ngin of +2.36 macro-F1 score (row 9). This resultalso con\ufb01rms that graph embeddings are comple-\nmentary to the textual representations.\nBias Prediction Table 4 shows evaluation results\nfor bias detection on the EMNLP-2018 dataset.\nHere, we observe that among the three graph em-\nbeddings (rows 4-7), only Node2Vec embeddings\noutperformed the previous best overall model (row\n3). The ensemble classi\ufb01er\u2019s accuracy (row 7) was\nexpectedly very similar to that of the top perform-\ning classi\ufb01er. Although the graphs embeddings\ncould not produce superior performance, their com-\nbination with textual and other audience features\nyielded a substantial increase of +9.17 macro-F1\npoints absolute over the best previous result (row\n8). This further con\ufb01rms the complementarity of\naudience homophily and textual representations on\nthe bias detection task.\nTable 5 shows the corresponding results for the\nACL-2020 dataset. For this setting GraphSage em-\nbeddings (row 7) are determined to produce signif-\nicantly more accurate predictions than both other\nembeddings (rows 5-6) and the previous best over-\nall model (row 4). The ensemble system was also\nable to leverage the strengths of the three types\nof graph embeddings and yielded the best perfor-\nmance (row 8). When the graph embeddings cap-\nturing the audience homophily characteristics are\ncombined with other representations (row 9), the\nimprovement in performance is further enhanced\nby an overall increase of +7.16 macro-F1 score\npoints over the previous best overall result.\n5 Discussion\nOther Features Tested Alexa Site Info main-\ntains a wide array of audience centric statistics\nfor the websites. Apart from audience overlap, we\nalso experimented with other features: Alexa Rank ,\nTotal Sites Linking In ,Daily Page Views per Visi-\ntor,Bounce Rate ,Average Daily Time per Visitor .\nTable 6 shows that these features performed bet-\nter than the majority class baselines, they are not\nvery strong. Note that most of these features were\nheavily unpopulated for a substantial part of our\nwebsite dataset, which could be the reason for their\nmediocre performance. Regardless, site popularity\nand engagement metrics are potentially very use-\nful for bias and factuality prediction. In fact, as\nour results show, even their binarized versions are\nhelpful, even on top a very a strong system.\nVarying Predictive Power of Graph Learning\nMethods Our results show that none of the three\ngraph learning approaches perform consistently\nbetter than the others. Most surprisingly, we de-\ntermined that Node2Vec algorithm yielded better\npredictions than the two GNN models, GCN and\nGraphSAGE, in two settings. We believe an im-\nportant factor contributing to this result is the spar-\nsity of node features. As can be seen in Table 6,\namong all news media websites comprising our\nauidence overlap graph, just three Alexa metrics\nwere available for more than 94% of the websites.\nWhereas four metrics were available only for less\nthan 40% of the websites. Since GNNs\u2019 superior\nperformance primarily stem from their ability to\ncombine graph structure and node information, the\nmissing features likely curtailed their performance\nsigni\ufb01cantly. In fact, our earlier tests performed\nwithout imputing missing features yielded a much\nlower accuracy results. Therefore, it is plausible to\nassume that the performance of GNN models will\nincrease in the presence of more discriminant node\nfeatures.\nFurther, our analysis revealed that the features\nSites Linking In ,Alexa Rank andDaily Time on\nSiteare more important than the other two features\nBounce Rate andDaily Pageviews per Visitor forboth tasks of factuality and bais prediction. How-\never, there is a slight variation in the order of impor-\ntance for these tasks. For example, Alexa Rank was\nthe most important feature for factuality prediction\nwhereas Sites Linking In was the most important\nfeature for bias prediction. Combining the features\ntogether with the graph structure assisted in im-\nproving the performance of both tasks.\nDifferent Levels Our preliminary experiments\nhave shown that, as we use embeddings from higher\nlevel graphs, performance improves. Table 7 shows\nour results on incremental levels of graphs on the\nEMNLP-2018 factuality dataset. We can notice a\njump of +15.40 macro-F1 points absolute when go-\ning from a level-0 to a level-4 graph. This increase\nin performance can be attributed to the addition\nof more nodes and denser connections between\nthem in the graph, which enhances our graph em-\nbeddings. Based on these preliminary results, we\ndecided to use level 4 embeddings as our overlap\ngraph embeddings in all our experiments.\nWho Read It vs.What Was Written Features\nWith the introduction of graph embeddings in the\nWho Read It feature category, we narrowed the\ngap between What Was written andWho Read It\nfeatures, as reported in (Baly et al., 2020).\n# Model % Pop. F1 Acc.\n1 Majority class baseline \u2013 22.47 50.84\n2 Alexa Rank (reciprocal) 99.92 22.46 50.75\n3 Alexa Rank (logarithm) 99.92 44.81 55.07\n4 Total Sites Linking In 94.98 45.28 55.72\n5 Bounce Rate 31.09 44.70 55.25\n6 Average Daily Time 36.27 44.13 56.10\n7 Daily Pageviews 61.08 44.93 56.85\n8 Has Total Sites Linking In 94.98 23.03 50.94\n9 Has Bounce Rate 31.09 42.70 59.38\n10 Has Average Daily Time 36.27 42.50 59.47\n11 Has Daily Pageviews 61.08 37.19 56.10\n12 Combination of 3\u20137 \u2013 48.14 57.50\n13 Combination of 8\u201311 \u2013 43.08 59.19\nTable 6: Factuality prediction on the EMNLP-2018\ndataset using different statistics from Alexa. Line 2\nshows a result from (Baly et al., 2018). Line 12 com-\nbines lines 3\u20137, and line 13 combines lines 8\u201311. For\nmissing values, we take the mean value of the feature.\nAlternatives to Alexa Siteinfo Alexa siteinfo\nservice was discontinued in May 2022. While our\napproach relies on Alexa siteinfo to obtain the au-\ndience overlapping information and Alexa matri-\nces for domains, we believe that our approach is\ngeneric in that one may utilize an alternative SEO\nModel Nodes Edges F1 Acc.\nMajority \u2013 \u2013 22.47 50.84\nlevel 0 1,062 4,837 45.20 57.50\nlevel 1 4,238 20,335 55.80 64.70\nlevel 2 11,867 57,320 56.78 65.01\nlevel 3 30,889 149,110 57.70 66.10\nlevel 4 78,429 377,260 60.60 68.19\nTable 7: Ablation study: factuality prediction on the\nEMNLP-2018 data using Node2Vec graph embeddings\nfrom graphs of different levels of expansion.\ndata source such as Ahref, Semrush, Similarweb\nor Moz to obtain similar information to construct\nthe audience overlap graph and extract features for\nthe websites under consideration. We leave it as a\nfuture direction to explore these alternative sources.\nFurther different SEO sources have different cov-\nerage of websites, one may combine multiple such\nsources to not only address the missing features\nbut also to increase the number of websites our\napproach connects leading to the discovery of addi-\ntional biased or low factual websites.\n6 Conclusion and Future Work\nWe studied the problem of media pro\ufb01ling with\nrespect to their factuality of reporting and bias.\nMotivated by homophily considerations, we built\na graph of inter-media connections based on the\naudience overlap for the target pair of news me-\ndia, and then we used graph neural networks to\ncome up with representations for each medium. We\nfound that such representations, especially when\naugmented with Alexa Metrics and additional infor-\nmation sources from Twitter, Facebook, YouTube,\nand Wikipedia, are quite useful, yielding state-of-\nthe-art results on four standard datasets for predict-\ning the factuality and the bias of news media.\nIn future work, we plan to experiment with other\nkinds of graph neural networks. We further want\nto integrate additional information sources.\nLimitations\nOur work relies on the Alexa website ranking and\ntraf\ufb01c information to build the input graphs, but\nAlexa is to be discontinued in the future. How-\never, we envision that one may use similar alterna-\ntive tools such as Semrush, Ahrefs or SimilarWeb\nto build similar graphs and use the proposed ap-\nproach.\nOur work excludes isolated nodes (websites) in\nthe constructed graph. Such isolated nodes couldoccur when a website is either relative new or not\npro\ufb01led in Alexa due to insuf\ufb01cient traf\ufb01c. This in\nturn results in some websites not being able to be\nclassi\ufb01ed. The datasets used in this work have only\none such isolated website, but we suggest utilizing\nnon-graph information, as used in prior approaches,\nto classify them.\nEthics and Broader Impact\nData Collection We collected the data for our\ngraph using the Alexa Audience Overlap Tool.5\nAlthough obtained Alexa statistics provide an ex-\ntensive view of audience overlap across media sites,\nit is not comprehensive as they are only limited to\ntop-\ufb01ve sites for each query. Further, sites with\nfewer audience are likely to be more prone to mea-\nsurement error, therefore inferring factuality and\nbias ratings of those sites is more challenging.\nBiases There might be biases in our gold labels\nfrom Media Bias/Fact Check, as in some judgments\nfor factuality and bias might be subjective. These\nbiases, in turn, will likely be exacerbated by the\nsupervised models trained on them (Waseem et al.,\n2020). This is beyond our control, as are the poten-\ntial biases in pre-trained large-scale transformers\nsuch as BERT and RoBERTa, which we use in our\nexperiments.\nIntended Use and Potential Misuse Our mod-\nels can enable analysis of entire news outlets, which\ncould be of interest to fact-checkers, journalists, so-\ncial media platforms, and policymakers. Yet, they\ncould also be misused for malicious attacks like\ntargeting speci\ufb01c parts of the audience with misin-\nformation news. We, therefore, ask researchers to\nexercise caution.\nEnvironmental Impact We would also like to\nwarn that the use of large-scale Transformers re-\nquires a lot of computations and the use of GPUs/T-\nPUs for training, which contributes to global warm-\ning (Strubell et al., 2019). This is a bit less of an\nissue in our case, as we do not train such models\nfrom scratch; rather, we \ufb01ne-tune them on rela-\ntively small datasets. Moreover, running on a CPU\nfor inference, once the model is \ufb01ne-tuned, is per-\nfectly feasible, and CPUs contribute much less to\nglobal warming.\n5http://alexa.com/marketing-stack/\naudience-overlap-tool\nReferences\nSadia Afroz, Michael Brennan, and Rachel Greenstadt.\n2012. Detecting hoaxes, frauds, and deception in\nwriting style online. In 2012 IEEE Symposium on\nSecurity and Privacy , pages 461\u2013475. IEEE.\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing ,\nEMNLP \u201918, pages 3528\u20133539, Brussels, Belgium.\nRamy Baly, Georgi Karadzhov, Jisun An, Haewoon\nKwak, Yoan Dinkov, Ahmed Ali, James Glass, and\nPreslav Nakov. 2020. What was written vs. who\nread it: News media pro\ufb01ling using text analysis and\nsocial media context. In Proceedings of the 2020 An-\nnual Meeting of the Association for Computational\nLinguistics .\nSonia Castelo, Thais Almeida, Anas Elghafari, A\u00e9cio\nSantos, Kien Pham, Eduardo Nakamura, and Juliana\nFreire. 2019. A topic-agnostic approach for identi-\nfying fake news pages. In Companion proceedings\nof the 2019 World Wide Web conference , pages 975\u2013\n980.\nZhouhan Chen and Juliana Freire. 2020. Proactive dis-\ncovery of fake news domains from real-time social\nmedia feeds. In Companion Proceedings of the Web\nConference 2020 , pages 584\u2013592.\nKareem Darwish, Peter Stefanov, Micha\u00ebl Aupetit, and\nPreslav Nakov. 2020. Unsupervised user stance de-\ntection on twitter. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\nvolume 14, pages 141\u2013152.\nJames Fairbanks, Natalie Fitch, Nathan Knauf, and Er-\nica Briscoe. 2018. Credibility assessment in the\nnews: do we need to read. In Proc. of the MIS2\nWorkshop held in conjuction with 11th Int\u2019l Conf. on\nWeb Search and Data Mining , pages 799\u2013800.\nAditya Grover and Jure Leskovec. 2016. node2vec:\nScalable feature learning for networks. In Proceed-\nings of the 22nd ACM SIGKDD international con-\nference on Knowledge discovery and data mining ,\npages 855\u2013864.\nW. Hamilton, Z. Ying, and J. Leskovec. 2017. In-\nductive representation learning on large graphs. In\nNIPS .\nAustin Hounsel, Jordan Holland, Ben Kaiser, Kevin\nBorgolte, Nick Feamster, and Jonathan Mayer. 2020.\nIdentifying disinformation websites using infrastruc-\nture features. In 10th fUSENIX gWorkshop on Free\nand Open Communications on the Internet ( fFOCI g\n20).\nMinyoung Huh, Andrew Liu, Andrew Owens, and\nAlexei A. Efros. 2018. Fighting fake news: Imagesplice detection via learned self-consistency. In Pro-\nceedings of the European Conference on Computer\nVision (ECCV) .\nZhiwei Jin, Juan Cao, Yongdong Zhang, Jianshe Zhou,\nand Qi Tian. 2016. Novel visual and statistical im-\nage features for microblogs news veri\ufb01cation. IEEE\ntransactions on multimedia , 19(3):598\u2013608.\nDhruv Khattar, Jaipal Singh Goud, Manish Gupta, and\nVasudeva Varma. 2019. Mvae: Multimodal varia-\ntional autoencoder for fake news detection. In The\nWorld Wide Web Conference , pages 2915\u20132921.\nT. Kipf and M. Welling. 2017. Semi-Supervised Clas-\nsi\ufb01cation with Graph Convolutional Networks. In\nICLR .\nTomas Mikolov, Kai Chen, Greg Corrado, and Jef-\nfrey Dean. 2013. Ef\ufb01cient estimation of word\nrepresentations in vector space. arXiv preprint\narXiv:1301.3781 .\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014. GloVe: Global vectors for word\nrepresentation. In Proceedings of the 2014 Confer-\nence on Empirical Methods in Natural Language\nProcessing (EMNLP) , pages 1532\u20131543, Doha,\nQatar. Association for Computational Linguistics.\nV P\u00e9rez-Rosas, B Kleinberg, A Lefevre, and R Mihal-\ncea. 2019. Automatic detection of fake news. Asso-\nciation for Computational Linguistics.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2018. A stylo-\nmetric inquiry into hyperpartisan and fake news. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) , pages 231\u2013240.\nPeng Qi, Juan Cao, Tianyun Yang, Junbo Guo, and Jin-\ntao Li. 2019. Exploiting multi-domain visual infor-\nmation for fake news detection. In 2019 IEEE Inter-\nnational Conference on Data Mining (ICDM) , pages\n518\u2013527. IEEE.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 con-\nference on empirical methods in natural language\nprocessing , pages 2931\u20132937.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nbert: Sentence embeddings using siamese bert-\nnetworks. arXiv preprint arXiv:1908.10084 .\nVictoria L Rubin, Niall J Conroy, and Yimin Chen.\n2015. Towards news veri\ufb01cation: Deception detec-\ntion methods for news discourse. In Hawaii Interna-\ntional Conference on System Sciences , pages 5\u20138.\nHusrev T. Sencar, Luisa Verdoliva, and Nasir Memon,\neditors. 2021. Multimedia Forensics . Springer, New\nYork, NY .\nShivangi Singhal, Rajiv Ratn Shah, Tanmoy\nChakraborty, Ponnurangam Kumaraguru, and\nShin\u2019ichi Satoh. 2019. Spotfake: A multi-modal\nframework for fake news detection. In 2019 IEEE\nFifth International Conference on Multimedia Big\nData (BigMM) , pages 39\u201347. IEEE.\nEmma Strubell, Ananya Ganesh, and Andrew McCal-\nlum. 2019. Energy and policy considerations for\ndeep learning in NLP. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics , pages 3645\u20133650, Florence, Italy.\nAssociation for Computational Linguistics.\nZeerak Waseem, Smarika Lulz, Joachim Bingel, and\nIsabelle Augenstein. 2020. Disembodied machine\nlearning: On the illusion of objectivity in NLP.\nFelix Ming Fai Wong, Chee Wei Tan, Soumya Sen, and\nMung Chiang. 2013. Quantifying political leaning\nfrom tweets and retweets. In Proceedings of the In-\nternational AAAI Conference on Web and Social Me-\ndia, volume 7.\nDimitrina Zlatkova, Preslav Nakov, and Ivan Koychev.\n2019. Fact-checking meets fauxtography: Verify-\ning claims about images. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP) , pages 2099\u20132108.\nAppendix\nA Alexa Audience Overlap Scores\nFigures 4\u20137 show the information provided by\nAlexa\u2019s Audience Overlap tool for reuters.com ,\nfoxnews.com ,cnn.com , and infowars.com . We can\nsee that a highly factual site, such as reuters.com,\nhas sizable audience overlap with other factual\nsites. Similarly, a low-factuality website such\nasinfowars.com , shares audience with other low-\nfactuality websites. The audience homophily also\nholds for political bias as can be seen in cases of\nfoxnews.com andcnn.com .\nFigure 4: Alexa Rank audience overlap for\nreuters.com .\nFigure 5: Alexa Rank audience overlap for\nfoxnews.com .\nB Supplementary Data Sources\nIn addition to characterizing audience homophily,\nwe also consider textual information sources about\nnews media available on the Web and the audi-\nence characteristics of their social media platforms.\nThese include the following.\nNews Articles and Wikipedia: Previous work on\nthe task used either GloVe (Baly et al., 2018) or\n\ufb01ne-tuned BERT encodings (Baly et al., 2020) of\nthe news articles, and averaged these encodings\nFigure 6: Alexa Rank audience overlap for cnn.com .\nFigure 7: Alexa Rank audience overlap for in-\nfowars.com .\nacross articles by the website to obtain a textual\nrepresentation for the website/domain. Similarly,\nGloVe and pre-trained BERT were used to get en-\ncodings for the Wikipedia descriptions of media.\nThus, we also used articles and Wikipedia descrip-\ntions to obtain site-level textual representations.\nFor the EMNLP-2018 Bias and Factuality tasks, we\nused the averaged GloVe encodings of the articles\npresent on the website. For the ACL-2020 Bias\nand Factuality tasks, we used sentence encoders\nbased on RoBERTa (Reimers and Gurevych, 2019)\nto encode the text, i.e., the articles or Wikipedia\ndescriptions. For news media without a Wikipedia\npage, we used a vector of zeroes. We refer to these\ntextual representations as Articles andWikipedia .\nAudience Characteristics: To model the simi-\nlarity between news media in terms of the overlap\nof their audience and of quantifying the level of\nengagement between a medium and its followers,\nwe also obtained an audience-centric representation\nfor each medium, by considering the users of social\nmedia platforms that have interest in the content\ncreated by these news sources. For this purpose,\nwe considered three features that were reported to\nperform well in characterization of followers of a\nnews medium (Baly et al., 2020).\nThe \ufb01rst feature is based on how Twitter users\nfollowing the account of the medium self-describe\nin their publicly accessible Twitter pro\ufb01les. For\neach medium, this is obtained by encoding the bi-\nographic descriptions of 5,000 English-speaking\nTwitter followers, using BERT and obtaining an av-\nerage representation. The second feature involves\nhow audience of the medium\u2019s YouTube channel\nrespond to each video in terms of the number of\ncomments, views, likes and dislikes; by averaging\nthese statistics over all videos, another medium-\nlevel representation is generated. The last feature\nincludes audience estimates from Facebook\u2019s ad-\nvertising platform which is used to obtain demo-\ngraphic information for the audience interested in\neach medium; this data is used to obtain the audi-\nence distribution over the political spectrum, the\ndistribution is then divided into \ufb01ve categories, and\neach medium is labeled accordingly. These three\nfeatures are referred to as Twitter ,YouTube , and\nFacebook audience representations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "GREENER: Graph neural networks for news media profiling", "author": ["P Panayotov", "U Shukla", "HT Sencar", "M Nabeel"], "pub_year": "2022", "venue": "arXiv preprint arXiv \u2026", "abstract": "We study the problem of profiling news media on the Web with respect to their factuality of  reporting and bias. This is an important but under-studied problem related to disinformation"}, "filled": false, "gsrank": 113, "pub_url": "https://arxiv.org/abs/2211.05533", "author_id": ["S8-Ng-kAAAAJ", "l-bHLCUAAAAJ", "KGxrG0YAAAAJ", "Lka4RwsAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:MozvutF_3WUJ:scholar.google.com/&output=cite&scirp=112&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D110%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=MozvutF_3WUJ&ei=GLWsaJ-LII6IieoP0sKRuAk&json=", "num_citations": 21, "citedby_url": "/scholar?cites=7340163506444930098&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:MozvutF_3WUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2211.05533"}}, {"title": "Automatically neutralizing subjective bias in text", "year": "2020", "pdf_data": "The Thirty-Fourth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-20)\nAutomatically Neutralizing Subjective Bias in Text\nReid Pryzant,1Richard Diehl Martinez,1Nathan Dass,1\nSadao Kurohashi,2Dan Jurafsky,1Diyi Yang3\n1Stanford University\n{rpryzant, rdm, ndass, jurafsky }@stanford.edu\n2Kyoto University\nkuro@i.kyoto-u.ac.jp\n3Georgia Institute of Technology\ndiyi.yang@cc.gatech.edu\nAbstract\nTexts like news, encyclopedias, and some social media strive\nfor objectivity. Yet bias in the form of inappropriate subjectiv-\nity \u2014 introducing attitudes via framing, presupposing truth,\nand casting doubt \u2014 remains ubiquitous. This kind of biaserodes our collective trust and fuels social con\ufb02ict. To address\nthis issue, we introduce a novel testbed for natural language\ngeneration: automatically bringing inappropriately subjective\ntext into a neutral point of view (\u201cneutralizing\u201d biased text).\nWe also offer the \ufb01rst parallel corpus of biased language. Thecorpus contains 180,000 sentence pairs and originates from\nWikipedia edits that removed various framings, presupposi-\ntions, and attitudes from biased sentences. Last, we proposetwo strong encoder-decoder baselines for the task. A straight-\nforward yet opaque\nCONCURRENT system uses a BERT en-\ncoder to identify subjective words as part of the generationprocess. An interpretable and controllable\nMODULAR algo-\nrithm separates these steps, using (1) a BERT-based classi\ufb01er\nto identify problematic words and (2) a novel join embed-\nding through which the classi\ufb01er can edit the hidden states\nof the encoder. Large-scale human evaluation across four do-\nmains (encyclopedias, news headlines, books, and political\nspeeches) suggests that these algorithms are a \ufb01rst step to-\nwards the automatic identi\ufb01cation and reduction of bias.\n1 Introduction\nWriters and editors of texts like encyclopedias, news, and\ntextbooks strive to avoid biased language. Yet bias remainsubiquitous. 62% of Americans believe their news is biased(Gallup 2018) and bias is the single largest source of distrustin the media (Foundation 2018).\nThis work presents data and algorithms for automati-\ncally reducing bias in text. We focus on a particular kind ofbias: inappropriate subjectivity (\u201csubjective bias\u201d). Subjec-\ntive bias occurs when language that should be neutral andfair is skewed by feeling, opinion, or taste (whether con-sciously or unconsciously). In practice, we identify subjec-tive bias via the method of Recasens, Danescu-Niculescu-Mizil, and Jurafsky (2013): using Wikipedia\u2019s neutral point\nCopyright c/circlecopyrt2020, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: Example output from our MODULAR algorithm.\n\u201cExposed\u201d is a factive verb that presupposes the truth of itscomplement (that McCain is unprincipled). Replacing \u201cex-posed\u201d with \u201cdescribed\u201d neutralizes the headline because itconveys a similar main clause proposition (someone is as-serting McCain is unprincipled), but no longer introducesthe authors subjective bias via presupposition.\nof view (NPOV) policy.\n1This policy is a set of principles\nwhich includes \u201cavoiding stating opinions as facts\u201d and\u201cpreferring nonjudgemental language\u201d.\nFor example a news headline like \u201cJohn McCain exposed\nas an unprincipled politician\u201d (Figure 1) is biased becausethe verb expose is a factive verb that presupposes the truth\nof its complement; a non-biased sentence would use a verblike describe so as not to presuppose the subjective opinion\nof the writer. \u201cPilfered\u201d in \u201cthe gameplay is pilfered from\nDDR\u201d (Table 1) subjectively frames the shared gameplay asa kind of theft. \u201cHis\u201d in \u201ca lead programmer usually spendshiscareer\u201d again introduces a biased and subjective view-\npoint (that all programmers are men) through presupposi-tion.\nWe aim to debias text by suggesting edits that would make\nit more neutral. This contrasts with prior research which hasdebiased representations of text by removing dimensions\nof prejudice from word embeddings (Bolukbasi et al. 2016;Gonen and Goldberg 2019) and the hidden states of predic-tive models (Zhao et al. 2018; Das, Dantcheva, and Bremond2018). To avoid overloading the de\ufb01nition of \u201cdebias,\u201d werefer to our kind of text debiasing as neutralizing that text.\nFigure 1 gives an example.\nWe introduce the Wiki Neutrality Corpus (WNC). This is\n1https://en.wikipedia.org/wiki/Wikipedia:Neutral point of\nview\n480\nSource Target Subcategory\nA new downtown is being developed which A new downtown is being developed which Epistemological\nwill bring back... which its promoters hope will bring back..\nThe authors\u2019 expos \u00b4eon nutrition studies The authors\u2019 statements on nutrition studies Epistemological\nHe started writing books revealing a vast world conspiracy He started writing books alleging a vast world conspiracy Epistemological\nGo is the deepest game in the world. Go is one of the deepest games in the world. Framing\nMost of the gameplay is pilfered from DDR. Most of the gameplay is based on DDR. Framing\nJewish forces overcome Arab militants . Jewish forces overcome Arab forces . Framing\nA lead programmer usually spends Lead programmers often spend Demographic\nhis career mired in obscurity. their careers mired in obscurity.\nThe lyrics are about mankind \u2019s perceived idea of hell. The lyrics are about humanity \u2019s perceived idea of hell. Demographic\nMarriage is a holy union of individuals. Marriage is a personal union of individuals. Demographic\nTable 1: Samples from our new corpus. 500 sentence pairs are annotated with \u201csubcategory\u201d information (Column 3).\na new parallel corpus of 180,000 biased and neutralized sen-\ntence pairs along with contextual sentences and metadata.The corpus was harvested from Wikipedia edits that weredesigned to ensure texts had a neutral point of view. WNCis the \ufb01rst parallel corpus of biased language.\nWe also de\ufb01ne the task of neutralizing subjectively biased\ntext. This task shares many properties with tasks like de-tecting framing or epistemological bias (Recasens, Danescu-Niculescu-Mizil, and Jurafsky 2013), or veridicality as-sessment/factuality prediction (Saur \u00b4\u0131 and Pustejovsky 2009;\nMarneffe, Manning, and Potts 2012; Rudinger, White, andV an Durme 2018; White et al. 2018). Our new task ex-tends these detection/classi\ufb01cation problems into a gener-ation task: generating more neutral text with otherwise sim-ilar meaning.\nFinally, we propose a pair of novel sequence-to-sequence\nalgorithms for this neutralization task. Both methods lever-\nage denoising autoencoders and a token-weighted loss func-tion. An interpretable and controllable\nMODULAR algorithm\nbreaks the problem into (1) detection and (2) editing, using(1) a BERT-based detector to explicitly identify problematicwords, and (2) a novel join embedding through which the\ndetector can modify an editors\u2019 hidden states. This paradigmadvances an important human-in-the-loop approach to biasunderstanding and generative language modeling. Second,an easy to train and use but more opaque\nCONCURRENT sys-\ntem uses a BERT encoder to identify subjectivity as part ofthe generation process.\nLarge-scale human evaluation suggests that while not\nwithout \ufb02aws, our algorithms can identify and reduce biasin encyclopedias, news, books, and political speeches, anddo so better than state-of-the-art style transfer and machinetranslation systems. This work represents an important \ufb01rststep towards automatically managing bias in the real world.We release data and code to the public.\n2\n2 Wiki Neutrality Corpus (WNC)\nThe Wiki Neutrality Corpus consists of aligned sentencespre and post -neutralization by English Wikipedia editors\n(Table 1). We used regular expressions to crawl 423,823Wikipedia revisions between 2004 and 2019 where editorsprovided NPOV-related justi\ufb01cation (Zanzotto and Pennac-\nchiotti 2010; Recasens, Danescu-Niculescu-Mizil, and Ju-\n2https://github.com/rpryzant/neutralizing-biasData Sentence Total Seq length # revised\npairs words (mean) words (mean)\nBiased-full 181,496 10.2M 28.21 4.05\nBiased-word 55,503 2.8M 26.22 1.00\nNeutral 385,639 17.4M 22.58 0.00\nTable 2: Corpus statistics.\nrafsky 2013; Yang et al. 2017). To maximize the precision\nof bias-related changes, we ignored revisions where\n\u2022More than a single sentence was changed.\n\u2022Minimal edits (character Levenshtein distance <4).\n\u2022Maximal edits (more than half of the words changed).\n\u2022Edits where more than half of the words were proper\nnouns.\n\u2022Edits that \ufb01xed spelling or grammatical errors.\n\u2022Edits that added references or hyperlinks.\n\u2022Edits that changed non-literary elements like tables or\npunctuation.\nWe align sentences in the pre and post text by computing\na sliding window (size k=5 ) of pairwise BLEU (Papineni\net al. 2002) between sentences and matching sentences withthe biggest score (Faruqui et al. 2018; Tiedemann 2008).Last, we discarded pairs whose length ratios were beyondthe 95th percentile (Pryzant et al. 2017).\nCorpus statistics are given in Table 2. The \ufb01nal data are\n(1) a parallel corpus of 180k biased sentences and their neu-tral counterparts, and (2) 385k neutral sentences that wereadjacent to a revised sentence at the time of editing but werenot changed by the editor. Note that following Recasens,Danescu-Niculescu-Mizil, and Jurafsky (2013), the neutral-izing experiments in Section 4 focus on the subset of WNCwhere the editor modi\ufb01ed or deleted a single word in thesource text (\u201cBiased-word\u201d in Table 2).\nTable 1 also gives a categorization of these sample\npairs using a slight extension of the typology of Recasens,Danescu-Niculescu-Mizil, and Jurafsky (2013). They de-\ufb01ned framing bias as using subjective words or phrases\nlinked with a particular point of view (using words like best\nordeepest or using pilfered from instead of based on ), and\nepistemological bias as linguistic features that subtly (often\nvia presupposition) modify the believability of a proposition.We add to their two a third kind of subjectivity bias thatalso occurs in our data, which we call demographic bias ,\n481\ntext with presuppositions about particular genders, races,\nor other demographic categories (like presupposing that all\nprogrammers are male).\nSubcategory Percent\nEpistemological 25.0\nFraming 57.7Demographic 11.7Noise 5.6\nTable 3: Proportion of bias subcategories in Biased-full.\nThe dataset does not include labels for these categories,\nbut we hand-labeled a random sample of 500 examples toestimate the distribution of the 3 types. Table 3 shows thatwhile framing bias is most common, all types of bias arerepresented in the data, including instances of demographicbias.\n2.1 Dataset Properties\nWe take a closer look at WNC to identify characteristics ofsubjective bias on Wikipedia.\nTopic. We use the Wikimedia Foundation\u2019s categoriza-\ntion models (Asthana and Halfaker 2018) to bucket articlesfrom WNC into a 44-category ontology,\n3then compare the\nproportions of NPOV-driven edits across categories. Sub-jectively biased edits are most prevalent in history ,politics ,\nphilosophy ,sports , and language categories. They are least\nprevalent in the meteorology ,science ,landforms ,broadcast-\ning, and arts categories. This suggests that there is a relation-\nship between a text\u2019s topic and the realization of bias. We usethis observation to guide our model design in Section 3.1.\nTenure. We group editors into \u201cnewcomers\u201d (less than\na month of experience) and \u201cexperienced\u201d (more than amonth). We \ufb01nd that newcomers are less likely to performneutralizing edits (15% in WNC) compared to other edits(34% in a random sample of 685k edits). This differenceis signi\ufb01cant ( \u02dc\u03c7\n2p=0.001), suggesting the complexity of\nneutralizing text is typically reserved for more senior edi-tors, which helps explain the performance of human evalua-tors in Section 6.1.\n3 Methods for Neutralizing Text\nWe propose the task of neutralizing text, in which the algo-rithm is given an input sentence and must produce an outputsentence whose meaning is as similar as possible to the inputbut with the subjective bias removed.\nWe propose two algorithms for this task, each with its own\nbene\ufb01ts. A\nMODULAR algorithm enables human control and\ninterpretability. A CONCURRENT algorithm is simple to train\nand operate.\nWe adopt the following notation:\n\u2022s=[ws\n1,...,ws\nn]is a source sequence of subjectively bi-\nased text.\n\u2022t=[wt\n1,...,wt\nm]is a target sequence and the neutralized\nversion of s.\n3https://en.wikipedia.org/wiki/Wikipedia:WikiProject\nCouncil/Directory\nFigure 2: The detection module uses discrete features fiand\nBERT embedding bito calculate logit yi.\n3.1 MODULAR\nThe \ufb01rst algorithm we are proposing is called MODULAR .\nIt has two stages: BERT-based detection and LSTM-basedediting. We pretrain a model for each stage and then com-bine them into a joint system for end-to-end \ufb01ne tuning onthe overall neutralizing task. We proceed to describe eachmodule.\nDetection Module The detection module is a neural se-\nquence tagger that estimates p\ni, the probability that each in-\nput word ws\niis subjectively biased (Figure 2).\nModule description. Eachpiis calculated according to\npi=\u03c3(biWb+eiWe+b) (1)\n\u2022bi\u2208Rbrepresents ws\ni\u2019s semantic meaning. It is a\ncontextualized word vector produced by BERT, a trans-former encoder that has been pre-trained as a masked lan-guage model (Devlin et al. 2019). To leverage the bias-topic relationship uncovered in Section 2.1, we prependa token indicating an article\u2019s topic category ( <arts> ,\n<sports> , etc) tos. The word vectors for these tokens\nare learned from scratch.\n\u2022e\nirepresents expert features of bias proposed by (Re-\ncasens, Danescu-Niculescu-Mizil, and Jurafsky 2013):\nei=ReLU(fiWin) (2)\nWin\u2208Rf\u00d7his a matrix of learned parameters, and fiis\na vector of discrete features4.\n\u2022Wb\u2208Rb,We\u2208Rh, andb\u2208R are learnable parame-\nters.\nModule pre-training. We train this module using diffs5be-\ntween the source and target text. A label p\u2217\nii s1i fws\niwas\ndeleted or modi\ufb01ed as part of the neutralizing process. Alabel is 0 if the associated word was unchanged during edit-ing, i.e. it occurs in both the source and target text. The lossis calculated as the average negative log likelihood of thelabels:\nL=\u22121\nnn/summationdisplay\ni=1/bracketleftBig\np\u2217\nilogpi+(1\u2212p\u2217\ni)log(1\u2212pi)/bracketrightBig\n4Such as lexicons of hedges, factives, assertives, implicatives,\nand subjective words; see code release.\n5https://github.com/paulgb/simplediff\n482\nFigure 3: The MODULAR system uses join embedding vto\nreconcile the detector\u2019s predictions with an encoder-decoderarchitecture. The greater a word\u2019s probability, the more of v\nis mixed into that word\u2019s hidden state.\nEditing Module The editing module takes a subjective\nsource sentence sand is trained to edit it into a more neutral\ncompliment t.\nModule description. This module is based on a\nsequence-to-sequence neural machine translation model(Luong, Pham, and Manning 2015). A bi-LSTM encoderturnssinto a sequence of hidden states H=(h\n1,...,hn)\n(Hochreiter and Schmidhuber 1997). Next, an LSTM de-coder generates text one token at a time by repeatedly at-tending to Hand producing probability distributions over\nthe vocabulary. We also add two mechanisms from the sum-marization literature (See, Liu, and Manning 2017). The \ufb01rstis a copy mechanism, where the model\u2019s \ufb01nal output fortimestepibecomes a weighted combination of the predicted\nvocabulary distribution and attentional distribution from thattimestep. The second is a coverage mechanism which incor-porates the sum of previous attention distributions into the\ufb01nal loss function to discourage the model from re-attendingto a word and repeating itself.\nModule pre-training. We pre-train the decoder as a lan-\nguage model of neutral text using the neutral portion of\nWNC (Section 2). Doing so expresses a data-driven priorabout how target sentences should read. We accomplish thiswith a denoising autoencoder objective (Hill, Cho, and Ko-rhonen 2016) and maximizing the conditional log probabil-ity of reconstructing a sequence xfrom a corrupted ver-\nsion of itself /tildewidexusing noise model C(logp(x|/tildewidex)where\n/tildewidex=C(x)).\nOurCis similar to (Lample et al. 2018). We slightly shuf-\n\ufb02exsuch that x\ni\u2019s index in /tildewidexis randomly selected from\n[i\u2212k,i+k]. We then drop words with probability p.F o r\nour experiments, we set k=3 andp=0.25.\nFinal System Once the detection and editing modules\nhave been pre-trained, we join them and \ufb01ne-tune togetheras an end to end system for translating sintot.\nThis is done with a novel join embedding mechanism that\nlets the detector control the editor (Figure 3). The join em-bedding is a vector v\u2208R\nhthat we add to each encoderhidden state in the editing module. This operation is gated\nby the detector\u2019s output probabilities p=(p1,...,p n). Note\nthat the same vis applied across all timesteps.\nh/prime\ni=hi+pi\u00b7v (3)\nWe proceed to condition the decoder on the new hidden\nstatesH/prime=(h/prime1,...,h/prime\nn)which have varying amounts of\nvin them. Intuitively, vis enriching the hidden states of\nwords that the detector identi\ufb01ed as subjective. This tells thedecoder what language should be changed and what is safeto be be copied during the neutralization process.\nError signals are allowed to \ufb02ow backwards into both the\nencoder and detector, creating an end-to-end system fromthe two modules. To \ufb01ne-tune the parameters of the jointsystem, we use a token-weighted loss function that scalesthe loss on neutralized words (i.e. words unique to t)b ya\nfactor of\u03b1:\nL(s,t)=\u2212\nm/summationdisplay\ni=1\u03bb(wt\ni,s)logp(wt\ni|s,wt\n<i)+c\n\u03bb(wt\ni,s)=/braceleftbigg\n\u03b1:wt\ni/negationslash\u2208s\n1 : otherwise\nNote that cis a term from the coverage mechanism (Sec-\ntion 3.1). We use \u03b1=1.3in our experiments. Intuitively,\nthis loss function incorporates an inductive bias of the neu-tralizing process: the source and target have a high degreeof lexical similarity but the goal is to learn the structure oftheir differences , not simply copying words into the output\n(something a pre-trained autoencoder should already haveknowledge of). This loss function is related to previous workon grammar correction (Junczys-Dowmunt et al. 2018), andcost-sensitive learning (Zhou and Liu 2006).\n3.2 CONCURRENT\nOur second algorithm takes the problematic source sand di-\nrectly generates a neutralized \u02c6t. While this renders the sys-\ntem easier to train and operate, it limits interpretability andcontrollability.\nModel description . The\nCONCURRENT system is an\nencoder-decoder neural network. The encoder is BERT. Thedecoder is the same as that of Section 3.1: an attentionalLSTM with copy and coverage mechanisms. The decoder\u2019sinputs are set to:\n\u2022Hidden states H=W\nHB, whereB=(b1,...,bn)\u2208\nRb\u00d7nis the BERT-embedded source and WH\u2208Rh\u00d7bis\na matrix of learned parameters.\n\u2022Initial states c0=Wc0/summationtextbi/n andh0=\nWh0/summationtextbi/n.Wc0\u2208Rh\u00d7bandWh0\u2208Rh\u00d7bare\nlearned matrices.\nModel training . The CONCURRENT model is pre-trained\nwith the same autoencoding procedure described in Section3.1. It is then \ufb01ne-tuned as a subjective-to-neutral translationsystem with the same loss function described in Section 3.1.\n4 Experiments\n4.1 Experimental Protocol\nImplementation. We implemented nonlinear models with\nPytorch (Paszke et al. 2017) and optimized using Adam\n483\nMethod BLEU Accuracy Fluency Bias Meaning\nSource Copy 91.33 0.00 -- -\nDetector (always delete biased word) 92.43* 38.19* -0.253* -0.324* 1.108*\nDetector (predict substitution from biased word) 92.51 36.57* -0.233* -0.327* 1.139*\nDelete Retrieve (ST) (Li et al. 2018) 88.46* 14.50* -0.209* -0.456* 1.294*\nBack Translation (ST) (Prabhumoye et al. 2018) 84.95* 9.92* -0.359* -0.390* 1.126*\nTransformer (MT) (V aswani et al. 2017) 86.40* 24.34* -0.259* -0.458* 0.905*\nSeq2Seq (MT) (Luong, Pham, and Manning 2015) 89.03* 23.93 -0.423* -0.436* 1.294*\nBase 89.13 24.01 -- -\n+ loss 90.32* 24.10 -- -\n+ loss + pretrain 92.89* 34.76* -- -\n+ loss + pretrain + detector (MODULAR ) 93.52* 45.80 * -0.078 -0.467 * 0.996*\n+ loss + pretrain + BERT (CONCURRENT ) 93.94 44.87 0.132 -0.423* 0.758 *\nTarget copy 100.0 100.0 -0.077 -0.551* 1.128*\nTable 4: Bias neutralization performance. ST indicates a style transfer system. MT indicates a machine translation system. For\nquantitative metrics, rows with asterisks are signi\ufb01cantly different than the preceding row. For qualitative metrics, rows withasterisks are signi\ufb01cantly different from zero. Higher is preferable for \ufb02uency , while lower is preferable for bias and meaning .\n(Kingma and Ba 2014) as con\ufb01gured in (Devlin et al. 2019)\nwith a learning rate of 5e-5. We used a batch size of 16. Allvectors were of length h= 512 unless otherwise speci\ufb01ed.\nWe use gradient clipping with a maximum gradient normof 3 and a dropout probability of 0.2 on the inputs of eachLSTM cell (Srivastava et al. 2014). We initialize the BERTcomponent of the tagging module with the publicly-releasedbert-base-uncased parameters. All other parameters\nwere uniformly initialized in the range [\u22120.1,0.1].\nProcedure. Following Recasens, Danescu-Niculescu-\nMizil, and Jurafsky (2013), we train and evaluate our systemon a subset of WNC where the editor changed or deleted asingle word in the source text. This yielded 53,803 trainingpairs (about a quarter of the WNC), from which we sam-pled 700 development and 1,000 test pairs. For fair compar-ison, we gave our baselines additional access to the 385,639neutral examples when possible. We pretrained the tagging\nmodule for 4 epochs. We pretrained the editing module ontheneutral portion of our WNC for 4 epochs. The joint sys-\ntem was trained on the same data as the tagger for 25,000steps (about 7 epochs). We perform interference using beamsearch and a beam width of 4. All computations were per-formed on a single NVIDIA TITAN X GPU; training thefull system took approximately 10 hours.\nEvaluation. We evaluate our models according to \ufb01ve\nmetrics. BLEU (Papineni et al. 2002) and accuracy (theproportion of decodings that exactly matched the editorschanges) are quantitative. We report statistical signi\ufb01cancewith bootstrap resampling and a 95% con\ufb01dence level(Koehn 2004; Efron and Tibshirani 1994).\nWe also hired \ufb02uent English-speaking crowdworkers on\nAmazon Mechanical Turk for qualitative evaluation. Work-\ners were shown the Recasens, Danescu-Niculescu-Mizil,\nand Jurafsky (2013) and Wikipedia de\ufb01nition of a \u201cbiasedstatement\u201d and six example sentences, then subjected to a\ufb01ve-question quali\ufb01cation test where they had to identifysubjectivity bias. Approximately half of the 30,000 work-ers who took the quali\ufb01cation test passed. Those who passedwere asked to compare pairs of original and edited sentences(not knowing which was the original) along three criteria:\n\ufb02uency, meaning preservation, and bias. Fluency and biaswere evaluated on a Semantic Differential scale from -2 to2. Here, a semantic differential scale can better evaluate at-titude oriented questions with two polarized options (e.g.,\u201cis text A or B more \ufb02uent?\u201d). Meaning was evaluated ona Likert scale from 0 to 4, ranging from \u201cidentical\u201d to \u201cto-tally different\u201d. Inter-rater agreement was fair to substantial(Krippendorff\u2019s alpha of 0.65 for \ufb02uency, 0.33 for meaning,and 0.51 for bias)\n6. We report statistical signi\ufb01cance with a\nt-test and 95% con\ufb01dence interval.\n4.2 Wikipedia (WNC)\nResults on WNC are presented in Table 4. In addition tomethods from the literature we include (1) a BERT-basedsystem which simply predicts and deletes subjective words,and (2) a system which predicts replacements (includingdeletion) for subjective words directly from their BERT em-beddings. All methods appear to successfully reduce biasaccording to the human evaluators. However, many meth-ods appear to lack \ufb02uency. Adding a token-weighted loss\nfunction and pretraining the decoder help the model\u2019s coher-ence according to BLEU and accuracy. Adding the detector(\nMODULAR ) or a BERT encoder ( CONCURRENT ) provide\nadditional bene\ufb01ts. The proposed models retain the strong\neffects of systems from the literature while also producing\ntarget-level \ufb02uency on average. Our results suggest there isno clear winner between our two proposed systems.\nMOD -\nULAR is better at reducing bias and has higher accuracy,\nwhile CONCURRENT produces more \ufb02uent responses, pre-\nserves meaning better, and has higher BLEU.\nTable 5 indicates that BLEU is more correlated with \ufb02u-\nency but accuracy is more correlated with subjective bias re-duction. The weak association between BLEU and humanevaluation scores is corroborated by other research (Cha-\n6Rule of thumb: k <0 \u201cpoor\u201d agreement, 0 to .2 \u201cslight\u201d, .21\nto .40 \u201cfair\u201d, .41 to .60 \u201cmoderate\u201d, .61 - .80 \u201csubstantial\u201d, and .81\nto 1 \u201cnear perfect\u201d (Gwet 2011).\n484\nMetric Fluency Bias Meaning\nBLEU 0.65 0.34 0.16\nAccuracy 0.56 0.52 0.20\nTable 5: Spearman correlation ( R2) between quantitative\nand qualitative metrics.\nganty, Mussman, and Liang 2018; Mir et al. 2019). We con-\nclude that neither automatic metric is a true substitute for\nhuman judgment.\n4.3 Real-world Media\nTo demonstrate the ef\ufb01cacy of the proposed methods on sub-jective bias in the wild, we perform inference on three out-of-domain datasets (Table 6). We prepared each dataset ac-cording to the same procedure as WNC (Section 2). After in-ference, we enlisted 1800 raters to assess the quality of 200randomly sampled datapoints. Note that for partisan datasetswe sample an equal number of examples from \u201cconserva-tive\u201d and \u201cliberal\u201d sources. These data are:\n\u2022The Ideological Books Corpus (IBC) consisting of parti-\nsan books and magazine articles (Sim et al. 2013; Iyyer etal. 2014).\n\u2022Headlines of partisan news articles identi\ufb01ed as biased ac-\ncording to mediabiasfactcheck.com.\n\u2022Sentences from the campaign speeches of a prominent\npolitician (United States President Donald Trump).\n7We\n\ufb01ltered out dialog-speci\ufb01c artifacts (interjections, phatics,etc) by removing all sentences with less than 4 tokens be-fore sampling a test set.\nOverall, while\nMODULAR does a better job at reducing\nbias, CONCURRENT appears to better preserve the mean-\ning and \ufb02uency of the original text. We conclude that theproposed methods, while imperfect, are capable of provid-ing useful suggestions for how subjective bias in real-worldnews or political text can be reduced.\n5 Error Analysis\nTo better understand the limits of our models and the pro-posed task of bias neutralization, we randomly sample 50errors produced by our models on the Wikipedia test set andbin them into the following categories:\n\u2022No change. The model failed to remove or change the\nsource sentence.\n\u2022Bad change. The model modi\ufb01ed the source but intro-\nduced an edit which failed to match the ground-truth tar-get (i.e. the Wikipedia editor\u2019s change).\n\u2022Dis\ufb02uency. Errors in language modeling and text genera-\ntion.\n\u2022Noise. The datapoint is noisy and the target text is not a\nneutralized version of the source.\n7Transcripts from www.kaggle.com/binksbiz/mrtrumpIBC Corpus\nMethod Fluency Bias Meaning\nMODULAR -0.041 -0.509* 0.882*\nCONCURRENT -0.001 -0.184 0.501*\nOriginal Activists have \ufb01led a lawsuit...\nMODULAR Critics of it have \ufb01led a lawsuit...\nCONCURRENT Critics have \ufb01led a lawsuit...\nNews Headlines\nMethod Fluency Bias Meaning\nMODULAR -0.46* -0.511* 1.169*\nCONCURRENT -0.141* -0.393* 0.752*\nOriginal Zuckerberg claims Facebook can...\nMODULAR Zuckerberg stated Facebook can...\nCONCURRENT Zuckerberg says Facebook can...\nTrump Speeches\nMethod Fluency Bias Meaning\nMODULAR -0.353* -0.563* 1.052*\nCONCURRENT -0.117 -0.127 0.757*\nOriginal This includes amazing Americans like...\nMODULAR This includes Americans like...\nCONCURRENT This includes some Americans like...\nTable 6: Performance on out-of-domain datasets. Higher is\npreferable for \ufb02uency , while lower is preferable for bias\nand meaning . Rows with asterisks are signi\ufb01cantly different\nfrom zero\nError Type Proportion (%) Valid (%)\nNo change 38 0\nBad change 42 80\nDis\ufb02uency 12 0\nNoise 88 7\nTable 7: Distribution of model errors on the Wikipedia test\nset. We also give the percent of errors that were valid neu-tralizations of the source despite failing to match the targetsentence.\nThe distribution of errors is given in Table 7. Most er-\nrors are due to the subtlety and complexity of language un-derstanding required for bias neutralization, rather than thegeneration of \ufb02uent text. These challenges are particularlypronounced for neutralizing edits that involve the replace-ment of factive and assertive verbs. As column 2 shows, alarge proportion of the errors, though disagreeing with theedit written by the Wikipedia editors, nonetheless succeededin neutralizing the source.\nExamples of each error type are given in Table 9 (two\npages away). As the examples show, our models have have atendency to simply remove words instead of \ufb01nding a goodreplacement.\n6 Algorithmic Analysis\nWe proceed to analyze our algorithm\u2019s ability to detect andcategorize bias as well as the ef\ufb01cacy of the proposed joinembedding.\n485\nMethod Accuracy\nLinguistic features 0.395*\nBag-of-words 0.584*\n+Linguistic features 0.617\n(Recasens, 2013)\nBERT 0.744*\n+Linguistic features 0.752\n+Linguistic features + Category 0.759\n(MODULAR detector)\nCONCURRENT encoder 0.745\nHuman 0.543*\nTable 8: Performance of various bias detectors. Rows with\nasterisks are statistically different than the preceding row.\n6.1 Detecting Subjectivity\nIdentifying subjectivity in a sentence (explicitly or implic-itly) is prerequisite to neutralizing it. We accordingly eval-uate our model\u2019s (and 3,000 crowdworker\u2019s) ability to de-tect subjectivity using the procedure of Recasens, Danescu-Niculescu-Mizil, and Jurafsky (2013). We use the same 50ktraining examples as Section 4 (Table 8). For each sentence,we select the word with the highest predicted probability andtest whether that word was in fact changed by the editor. Theproportion of correctly selected words is the system\u2019s \u201caccu-racy\u201d. Results are given in Table 8.\nNote that\nCONCURRENT lacks an interpretive window\ninto its detection behavior, so we estimate an upper bound onthe model\u2019s detection abilities by (1) feeding the encoder\u2019shidden states into a fully connected + softmax layer that pre-dicts the probability of a token being subjectively biased,and (2) training this layer as a sequence tagger according tothe procedure of Section 3.1.\nThe low human performance can be attributed to the dif-\n\ufb01culty of identifying bias. Issues of bias are typically re-served for senior Wikipedia editors (Section 2.1) and un-trained workers performed worse (37.39%) on the sametask in (Recasens, Danescu-Niculescu-Mizil, and Jurafsky2013) (and can struggle on other tasks requiring linguis-tic knowledge (Callison-Burch 2009)).\nCONCURRENT \u2019s en-\ncoder, which is architecturally identical to BERT, had simi-lar performance to a stand-alone BERT system. The linguis-tic and category-related features in the\nMODULAR detector\ngave it slight leverage over the plain BERT-based models.\n6.2 Join Embedding\nWe continue by analyzing the abilities of the proposed joinembedding mechanism.\nJoin Embedding Ablation The join embedding combines\ntwo separately pretrained models through a gated embed-ding instead of the more traditional practice of stripping offany \ufb01nal classi\ufb01cation layers and concatenating the exposedhidden states (Bengio et al. 2007). We ablated the join em-bedding mechanism by training a new model where the pre-trained detector is frozen and its pre-output hidden statesb\niare concatenated to the encoder\u2019s hidden states before\ndecoding. Doing so reduced performance to 90.78 BLEUand 37.57 Accuracy (from the 93.52/46.8 with the join em-\nbedding). This suggests learned embeddings can be a high-performance and end-to-end conduit between sub-modulesof machine learning systems.\nJoin Embedding Control We proceed to demonstrate\nhow the join embedding creates controllability in the neu-tralization process. Recall that\nMODULAR relies on a proba-\nbility distribution pto determine which words require edit-\ning (Equation 3). Typically, this distribution comes from thedetection module (Section 3.1), but we can also feed in user-speci\ufb01ed distributions that force the model to target partic-ular words. This can let human advisors correct errors orpush the model\u2019s behavior towards some desired outcome.We \ufb01nd that the model is indeed capable of being controlled,letting users target speci\ufb01c words for rewording in case theydisagree with the model\u2019s output or seek recommendationson speci\ufb01c language. However, doing so can also introduceerrors into downstream language generation (Table 9, nextpage).\n7 Related Work\nSubjectivity Bias. The study of subjectivity in NLP was\npioneered by the late Janyce Wiebe and colleagues (Bruceand Wiebe 1999; Hatzivassiloglou and Wiebe 2000). Sev-eral studies develop methods for highlighting subjectiveor persuasive frames in a text (Rashkin et al. 2017; Tsur,Calacci, and Lazer 2015), or detecting biased sentences(Hube and Fetahu 2018; Morstatter et al. 2018; Yang et al.2017; Hube and Fetahu 2019) of which the most similarto ours is Recasens, Danescu-Niculescu-Mizil, and Juraf-sky (2013), whose early, smaller version of WNC and lo-gistic regression-based bias detector inspired our study.\nDebiasing. Many scholars have worked on remov-\ning demographic prejudice from meaning representations\n(Manzini et al. 2019; Zhao et al. 2017; 2018; Bordia andBowman 2019; Wang et al. 2018, inter alia). Such studies be-gin with identifying a direction or subspace that capture thebias and then removing this bias component to make repre-sentations fair across attributes like gender and age (Boluk-basi et al. 2016; Manzini et al. 2019). For instance, Bor-dia and Bowman (2019) introduced a regularization termfor the language model to penalize the projection of theword embeddings onto that gender subspace, while Wang\net al. (2018) used adversarial training to squeeze directions\nof bias out of hidden states.\nNeural Language Generation. Several studies propose\nstepwise or modular procedures for text generation, includ-ing sampling from a corpus (Guu et al. 2018) and identify-ing language ripe for modi\ufb01cation (Leeftink and Spanakis2019). Most similar to us is Li et al. (2018) who local-ize a text\u2019s style to a fraction of its words. Our\nMODU -\nLAR detection module performs a similar localization in a\nsoft manner, but our steps are joined by a smooth conduit(the join embedding) instead of discrete logic. There is alsowork related to our\nCONCURRENT model. The closest is\nDun, Zhu, and Zhao (2019), where a decoder was attachedto BERT for question answering, or Lample et al. (2018),where machine translation systems are initialized to LSTM\n486\nError Type Source, Output, then Target\nNo change Existing hot-mail accounts were upgraded to outlook.com on April 3, 2013.\nExisting hot-mail accounts were upgraded to outlook.com on April 3, 2013.\nExisting hot-mail accounts were changed to outlook.com on April 3, 2013.\nBad change His exploitation of leased labor began in 1874 and continued until his death in 1894...\nHis actions of leased labor began in 1874 and continued until his death in 1894...\nHis use of leased labor began in 1874 and continued until his death in 1894...\nDis\ufb02uency Right before stabbing a cop, \ufb02int attacker shouted one thing that proves terrorism is still here.\nRight before stabbing a cop, \ufb02int attacker shouted one thing that may may terrorism is still here.\nRight before stabbing a cop, \ufb02int attacker shouted one thing that may prove terrorism is still here.\nNoise ...then whent to war with him in the Battle of Bassorah , and ultimately left that battle.\n...then whent to war with him in the Battle of Bassorah , and ultimately left that battle.\n...then whent to war with him in the Battle of the Camel , and ultimately left that battle.\nRevised Word Source, Output, then Target\nMagni\ufb01cent After a dominant performance, Joshua...with a magni\ufb01cent seventh-round knockout win.\nAfter a dominant performance, Joshua...with a seventh-round knockout win.\nAfter a dominant performance, Joshua...with a seventh-round knockout win.\nDominant Jewish history is...interacted with other dominant peoples, religions and cultures.\nJewish history is...other peoples, religions and cultures.\nJewish history is...other peoples, religions and cultures.\nSelected Word Output\n(input) In recent years, the term has often been misapplied to those who are merely clean-cut.\nmerely In recent years, the term has often been misapplied to those who are clean-cut.\nmisapplied In recent years, the term has often been shown to those who are merely clean-cut.\n(input) He was responsible for the assassination of Carlos Marighella, and for the Lapa massacre .\nassassination He was responsible for the killing of Carlos Marighella, and for the Lapa massacre .\nmassacre He was responsible for the assassination of Carlos Marighella, and for the Lapa incident .\n(input) Paul Ryan desperately searches for a new focus amid Russia scandal .\ndesperately Paul Ryan searches for a new focus amid Russia scandal .\nscandal Paul Ryan desperately searches for a new focus amid Russia.\nTable 9: Top : examples of model errors from each error category. Middle : the model treats words differently based on their\ncontext; in this case, \u201cdominant\u201d is ignored when it accurately describes an individual\u2019s winning performance, but deleted whenit describes a group of people in arbitrary comparison. Bottom : the\nMODULAR model can sometimes be controlled, for example\nby selecting words to change, to correct errors or otherwise change the model\u2019s behavior.\nand Transformer-based language models of the source text.\n8 Conclusion and Future Work\nThe growing presence of bias has marred the credibility of\nour news, educational systems, and social media platforms.Automatically reducing bias is thus an important new chal-lenge for the Natural Language Processing and Arti\ufb01cial In-telligence community. This work represents a \ufb01rst step inthe space. Our results suggest that the proposed models are\ncapable of providing useful suggestions for how to reducesubjective bias in real-world expository writing like news,books, and encyclopedias. Nonetheless our scope was lim-ited to single-word edits, which only constitute a quarter of\nthe edits in our data, and are probably among the simplestinstances of bias. We therefore encourage future work totackle broader instances of multi-word, multi-lingual, and\ncross-sentence bias. Another important direction is integrat-ing aspects of fact-checking (Mihaylova et al. 2018), sincea more sophisticated system would be able to know when apresupposition is in fact true and hence not subjective. Fi-nally, our new join embedding mechanism can be applied toother modular neural network architectures.\n9 Acknowledgements\nWe thank the Japan-United States Educational Commis-sion (Fulbright Japan) for their generous support. We thankChris Potts, Hirokazu Kiyomaru, Abigail See, Kevin Clark,the Stanford NLP Group, and our anonymous reviewersfor their thoughtful comments and suggestions. We grate-fully acknowledge support of the DARPA Communicating\n487\nwith Computers (CwC) program under ARO prime contract\nno. W911NF15-1-0462 and the NSF via grant IIS-1514268.\nDiyi Yang is thankful for support by a grant from Google.\nReferences\nAsthana, S., and Halfaker, A. 2018. With few eyes, all hoaxes are\ndeep. Proceedings of the ACM on Human-Computer Interaction\n2(CSCW):21.\nBengio, Y .; Lamblin, P .; Popovici, D.; and Larochelle, H. 2007.\nGreedy layer-wise training of deep networks. In Advances in neu-\nral information processing systems , 153\u2013160.\nBolukbasi, T.; Chang, K.-W.; Zou, J. Y .; Saligrama, V .; and Kalai,\nA. T. 2016. Man is to computer programmer as woman is to home-maker? debiasing word embeddings. In Advances in neural infor-\nmation processing systems , 4349\u20134357.\nBordia, S., and Bowman, S. R. 2019. Identifying and reducing gen-\nder bias in word-level language models. In NAACL 2019 Student\nResearch Workshop .\nBruce, R. F., and Wiebe, J. M. 1999. Recognizing subjectivity:\na case study in manual tagging. Natural Language Engineering\n5(2):187\u2013205.\nCallison-Burch, C. 2009. Fast, cheap, and creative: Evaluating\ntranslation quality using amazon\u2019s mechanical turk. In Proceedings\nof EMNLP , 286\u2013295.\nChaganty, A. T.; Mussman, S.; and Liang, P . 2018. The price\nof debiasing automatic metrics in natural language evaluation. In\nProceedings of ACL .\nDas, A.; Dantcheva, A.; and Bremond, F. 2018. Mitigating bias\nin gender, age and ethnicity classi\ufb01cation: a multi-task convolution\nneural network approach. In Proceedings of the European Confer-\nence on Computer Vision (ECCV) , 0\u20130.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019. Bert:\nPre-training of deep bidirectional transformers for language under-standing.\nDun, P .; Zhu, L.; and Zhao, D. 2019. Extending answer prediction\nfor deep bi-directional transformers. 32nd Conference on Neural\nInformation Processing Systems (NIPS) .\nEfron, B., and Tibshirani, R. J. 1994. An introduction to the boot-\nstrap . CRC press.\nFaruqui, M.; Pavlick, E.; Tenney, I.; and Das, D. 2018. Wiki-\natomicedits: A multilingual corpus of wikipedia edits for modelinglanguage and discourse. Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing .\nFoundation, O. S. 2018. Indicators of news media trust.\nhttps://kf-site-production.s3.amazonaws.com/media\nelements/\n\ufb01les/000/000/216/original/KnightFoundation Panel4 Trust\nIndicators FINAL.pdf.\nGallup. 2018. Americans: Much misinformation, bias, inac-\ncuracy in news. https://news.gallup.com/opinion/gallup/235796/\\\\americans-misinformation-bias- \\\\inaccuracy-news.aspx.\nGonen, H., and Goldberg, Y . 2019. Lipstick on a pig: Debiasing\nmethods cover up systematic gender biases in word embeddings butdo not remove them. North American Chapter of the Association\nfor Computational Linguistics (NAACL) .\nGuu, K.; Hashimoto, T. B.; Oren, Y .; and Liang, P . 2018. Gener-\nating sentences by editing prototypes. Transactions of the Associ-\nation of Computational Linguistics 6:437\u2013450.\nGwet, K. L. 2011. On the krippendorff\u2019s alpha coef\ufb01-\ncient. Manuscript submitted for publication. Retrieved October\n2(2011):2011.Hatzivassiloglou, V ., and Wiebe, J. M. 2000. Effects of adjective\norientation and gradability on sentence subjectivity. In Proceedings\nof COLING 2000 , 299\u2013305.\nHill, F.; Cho, K.; and Korhonen, A. 2016. Learning distributed\nrepresentations of sentences from unlabelled data. arXiv preprint\narXiv:1602.03483 .\nHochreiter, S., and Schmidhuber, J. 1997. Long short-term mem-\nory. Neural computation 9(8):1735\u20131780.\nHube, C., and Fetahu, B. 2018. Detecting biased statements in\nwikipedia. In The Web Conference , 1779\u20131786. International\nWorld Wide Web Conferences Steering Committee.\nHube, C., and Fetahu, B. 2019. Neural based statement classi-\n\ufb01cation for biased language. In Proceedings of the Twelfth ACM\nInternational Conference on Web Search and Data Mining , 195\u2013\n203. ACM.\nIyyer, M.; Enns, P .; Boyd-Graber, J.; and Resnik, P . 2014. Political\nideology detection using recursive neural networks. In Proceedings\nof ACL , 1113\u20131122.\nJunczys-Dowmunt, M.; Grundkiewicz, R.; Guha, S.; and Hea\ufb01eld,\nK. 2018. Approaching neural grammatical error correction as a\nlow-resource machine translation task. In Proceedings of NAACL .\nKingma, D. P ., and Ba, J. 2014. Adam: A method for stochastic op-\ntimization. International Conference for Learning Representations\n(ICLR) .\nKoehn, P . 2004. Statistical signi\ufb01cance tests for machine transla-\ntion evaluation. In Conference on Empirical Methods in Natural\nLanguage Processing .\nLample, G.; Ott, M.; Conneau, A.; Denoyer, L.; and Ranzato, M.\n2018. Phrase-based & neural unsupervised machine translation.\nLeeftink, W., and Spanakis, G. 2019. Towards controlled trans-\nformation of sentiment in sentences. International Conference on\nAgents and Arti\ufb01cial Intelligence (ICAART) .\nLi, J.; Jia, R.; He, H.; and Liang, P . 2018. Delete, retrieve, generate:\nA simple approach to sentiment and style transfer. In Proceedings\nof NAACL .\nLuong, M.-T.; Pham, H.; and Manning, C. D. 2015. Effective\napproaches to attention-based neural machine translation. In Pro-\nceedings of EMNLP .\nManzini, T.; Lim, Y . C.; Tsvetkov, Y .; and Black, A. W. 2019.\nBlack is to criminal as caucasian is to police: Detecting and re-moving multiclass bias in word embeddings. In NAACL 2019 .\nMarneffe, M.-C. d.; Manning, C. D.; and Potts, C. 2012. Did it hap-\npen? the pragmatic complexity of veridicality assessment. Compu-\ntational Linguistics 38(2):301\u2013333.\nMihaylova, T.; Nakov, P .; Marquez, L.; Barron-Cedeno, A.; Mo-\nhtarami, M.; Karadzhov, G.; and Glass, J. 2018. Fact checking in\ncommunity forums. In Thirty-Second AAAI Conference on Arti\ufb01-\ncial Intelligence .\nMir, R.; Felbo, B.; Obradovich, N.; and Rahwan, I. 2019. Evaluat-\ning style transfer for text. In Proceedings of NAACL .\nMorstatter, F.; Wu, L.; Yavanoglu, U.; Corman, S. R.; and Liu, H.\n2018. Identifying framing bias in online news. ACM Transactions\non Social Computing 1(2):5.\nPapineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J. 2002. Bleu:\na method for automatic evaluation of machine translation. In Pro-\nceedings of ACL , 311\u2013318.\nPaszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.; DeVito,\nZ.; Lin, Z.; Desmaison, A.; Antiga, L.; and Lerer, A. 2017. Auto-\nmatic differentiation in pytorch.\n488\nPrabhumoye, S.; Tsvetkov, Y .; Salakhutdinov, R.; and Black, A. W.\n2018. Style transfer through back-translation. Association for\nComputational Linguistics (ACL) .\nPryzant, R.; Chung, Y .; Jurafsky, D.; and Britz, D. 2017. Jesc:\nJapanese-english subtitle corpus. 11th edition of the Language Re-\nsources and Evaluation Conference (LREC) .\nRashkin, H.; Choi, E.; Jang, J. Y .; V olkova, S.; and Choi, Y . 2017.\nTruth of varying shades: Analyzing language in fake news and po-litical fact-checking. In Proceedings of EMNLP , 2931\u20132937.\nRecasens, M.; Danescu-Niculescu-Mizil, C.; and Jurafsky, D.\n2013. Linguistic models for analyzing and detecting biased lan-\nguage. In Proceedings of ACL , 1650\u20131659.\nRudinger, R.; White, A. S.; and V an Durme, B. 2018. Neural\nmodels of factuality. In Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Computational Lin-\nguistics: Human Language Technologies, V olume 1 (Long Papers) ,\n731\u2013744.\nSaur \u00b4\u0131, R., and Pustejovsky, J. 2009. Factbank: a corpus anno-\ntated with event factuality. Language resources and evaluation\n43(3):227.\nSee, A.; Liu, P . J.; and Manning, C. D. 2017. Get to the point:\nSummarization with pointer-generator networks. Proceedings of\nACL .\nSim, Y .; Acree, B. D.; Gross, J. H.; and Smith, N. A. 2013. Measur-\ning ideological proportions in political speeches. In Proceedings of\nEMNLP , 91\u2013101.\nSrivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; and\nSalakhutdinov, R. 2014. Dropout: a simple way to prevent neu-\nral networks from over\ufb01tting. The Journal of Machine Learning\nResearch 15(1):1929\u20131958.\nTiedemann, J. 2008. Synchronizing translated movie subtitles. In\nLanguage Resources and Evaluation Conference (LREC) .\nTsur, O.; Calacci, D.; and Lazer, D. 2015. A frame of mind: Us-\ning statistical models for detection of framing and agenda setting\ncampaigns. In Proceedings of ACL , 1629\u20131638.\nV aswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.;\nGomez, A. N.; Kaiser, \u0141.; and Polosukhin, I. 2017. Attention is\nall you need. In Advances in Neural Information Processing Sys-\ntems , 5998\u20136008.\nWang, T.; Zhao, J.; Chang, K.-W.; Yatskar, M.; and Ordonez, V .\n2018. Adversarial removal of gender from deep image representa-\ntions. arXiv preprint arXiv:1811.08489 .\nWhite, A. S.; Rudinger, R.; Rawlins, K.; and V an Durme, B. 2018.\nLexicosyntactic inference in neural models. In Proceedings of the\n2018 Conference on Empirical Methods in Natural Language Pro-\ncessing , 4717\u20134724.\nYang, D.; Halfaker, A.; Kraut, R.; and Hovy, E. 2017. Identify-\ning semantic edit intentions from revisions in wikipedia. In Con-\nference on Empirical Methods in Natural Language Processing ,\n2000\u20132010.\nZanzotto, F. M., and Pennacchiotti, M. 2010. Expanding textual\nentailment corpora from wikipedia using co-training. In The Peo-\nple\u2019s Web Meets NLP Workshop (COLING) , 28\u201336.\nZhao, J.; Wang, T.; Yatskar, M.; Ordonez, V .; and Chang, K.-W.\n2017. Men also like shopping: Reducing gender bias ampli\ufb01cation\nusing corpus-level constraints. arXiv preprint arXiv:1707.09457 .\nZhao, J.; Wang, T.; Yatskar, M.; Ordonez, V .; and Chang, K.-W.\n2018. Gender bias in coreference resolution: Evaluation and debi-\nasing methods. arXiv preprint arXiv:1804.06876 .Zhou, Z.-H., and Liu, X.-Y . 2006. Training cost-sensitive neural\nnetworks with methods addressing the class imbalance problem.\nTransactions of IEEE .\n489", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Automatically neutralizing subjective bias in text", "author": ["R Pryzant", "RD Martinez", "N Dass", "S Kurohashi"], "pub_year": "2020", "venue": "Proceedings of the aaai \u2026", "abstract": "Texts like news, encyclopedias, and some social media strive for objectivity. Yet bias in the  form of inappropriate subjectivity\u2014introducing attitudes via framing, presupposing truth, and"}, "filled": false, "gsrank": 114, "pub_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5385", "author_id": ["FkufKDgAAAAJ", "E9HDYC4AAAAJ", "pr4Mca8AAAAJ", "gpKS5P0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:bmQ046VjQn0J:scholar.google.com/&output=cite&scirp=113&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D110%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=bmQ046VjQn0J&ei=GLWsaJ-LII6IieoP0sKRuAk&json=", "num_citations": 212, "citedby_url": "/scholar?cites=9025886167336510574&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:bmQ046VjQn0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aaai.org/ojs/index.php/AAAI/article/view/5385/5241"}}, {"title": "Linguistic Bias in News Media on Anti-Pipeline Protests in Canada", "year": "2024", "pdf_data": "  \n \n  \n  \n \n \n \nLINGUISTIC BIAS IN NEWS MEDIA ON ANTI-PIPELINE PROTESTS IN CANADA \n \n \nA Thesis Submitted to the  \nCollege of Graduate and Postdoctoral Studies  \nIn Partial Fulfillment of the Requirements  \nFor the Degree of Master of Arts in Applied Social Psychology \nIn the Department of Psychology and Health Studies \nUniversity of Saskatchewan \n \n \nBy  \n \nTraci-lee D. Christianson \n \n \n \n \n \n \n\u00a9 Copyright Traci-lee D. Christianson, September 2024. All rights reserved. Unless otherwise \nnoted, copyright of the material in this thesis belongs to the author.\n  \n \ni \n PERMISSION TO USE  \nAs the author, I give my permission to the University of Saskatchewan Library to make this \nthesis available for inspection and permit copying of this thesis in any manner, in whole or in \npart, for scholarly purposes only. It is understood that due recognition shall be given to me and to \nthe University of Saskatchewan in any scholarly use which may be made of any material in my \nthesis.  \nDISCLAIMER \nReference in a thesis or dissertation to any specific commercial product, process, or service by \ntrade name, trademark, manufacturer, or otherwise, does not constitute or imply its endorsement, \nrecommendation, or favouring by the University of Saskatchewan, and shall not be used for \nadvertising or product endorsement purposes.  \nRequests for permission to use the material in this thesis should be sent to:  \nDepartment of Psychology and Health Studies  \n9 Campus Drive  \n154 Arts  \nSaskatoon, Saskatchewan, S7N 5A5, Canada  \nor  \nDean  \nCollege of Graduate and Postdoctoral Studies  \nUniversity of Saskatchewan  \n116 Thorvaldson Building, 110 Science Place  \nSaskatoon, Saskatchewan, S7N 5C9, Canada  \n  \n  \n \nii \n Abstract  \nProtests give rise to social change, often advancing the rights of minority groups. However, their \nsuccess hinges on public opinion, which can be influenced by news media (e.g., Detenber et al., \n2007). Most research on this topic has demonstrated that protests that seek to disrupt the status \nquo are negatively framed in news media (e.g., Boyle et al., 2004), which inhibits their success. \nOthers have found that the language used to describe minority groups in the news is often \nnegatively biased (e.g., Dragojevic et al., 2017) and that this maintains harmful stereotypes \n(Beukeboom, 2014). However, no research has investigated the linguistic mechanisms used to \ndescribe protests in news media. Given this, the aim of this study was to determine whether news \nsources exhibit linguistic bias about protests that corresponds to regional differences, which are \nknown to influence media bias. To do this, we examined articles published in news sources from \ndifferent regions of Canada for linguistic bias in the description of Indigenous-led anti-pipeline \nprotests. We found that the language used differed by region, such that news sources from the \nPrairies used more abstract language than news sources from the Central region. However, when \nconsidering both abstraction and valence, neither source exhibited a bias. This research is \nsignificant in that it demonstrates that regional differences in the way protests are framed extend \nto linguistic differences, but that negative framing may not. \nKeywords:  Language, implicit bias, protests, news media bias, linguistic bias \n  \n  \n \niii \n Acknowledgements \nFirst, I\u2019d like to acknowledge my thesis supervisor, Dr. Katherine A. Collins, who has \nprovided me with endless guidance and support, without which this thesis would not have been \npossible. Words cannot express my gratitude for her mentorship over the years. In addition, \nwhile I am fortunate to have many friends and family who have played a role in this thesis, I owe \nit to my partner, Josh, who has held my hand through it all. \n  \n  \n \niv \n Table of Contents \n  \nPermission to Use ............................................................................................................................i \nAbstract ..........................................................................................................................................ii \nAcknowledgments .........................................................................................................................iii  \nTable of Contents ..........................................................................................................................iv \nList of Tables ..................................................................................................................................v  \nList of Figures ................................................................................................................................vi \n1. Introduction ................................................................................................................................1 \n1.1 Literature Review...........................................................................................................1 \n1.2 Study Overview.............................................................................................................5 \n2. Method ........................................................................................................................................6 \n2.1 Search.............................................................................................................................8 \n2.2 Sample............................................................................................................................9 \n2.3 Coding..........................................................................................................................12 \n2.4 Resolution....................................................................................................................13 \n2.5 Reduction in Scope......................................................................................................14 \n3. Results .......................................................................................................................................16 \n4. Discussion .................................................................................................................................18 \n4.1 Limitations and Future Directions...............................................................................19  \nReferences .....................................................................................................................................22 \nAppendix .......................................................................................................................................28 \n  \n  \n \nv \n List of Tables \nTable 2.1.1: Search Terms..................................................................................................7 \nTable 2.1.2: Inclusion Criteria............................................................................................8 \nTable 2.2.1: Total Counts Across Political Bias, Region, Province, and Publication  \n Title....................................................................................................................................10 \nTable 2.2.2: Ideal Sample Description...............................................................................11 \nTable 2.3.1: Example Coding Spreadsheet........................................................................12 \nTable 2.5.1: Final Sample Description..............................................................................14 \nTable 3.1: Means for Positive and Negative Abstraction Scores by Region.....................16 \nTable A.1 Example Coding Spreadsheet...........................................................................33 \n \n \n \n \n \n  \n  \n \nvi \n List of Figures \nFigure 2.2.1: Searching, Screening, and Sample Diagram.................................................9 \nFigure 3.1: Regional Differences in Abstraction...............................................................17 \nFigure 3.2: Interaction Between Valence and Region.......................................................16 \n \n  \n \n1 \n 1. Introduction  \nProtests often originate from issues relevant to minority status groups. For example, the \nworldwide Black Lives Matter protests of 2020 originated with systematic and government \nsanctioned violence against Black people (Black Lives Matter, 2024) and protests opposing the \nDakota Access pipeline stemmed from settler colonial violence against Indigenous Peoples \n(Grote & Johnson, 2021). While protests can give voice to underrepresented groups and advance \nimportant social movements, their impact depends on public perception, which can be shaped by \nnews media (Detenber et al., 2007; Dragojevic et al., 2017; Harlow et al., 2017; Hester & \nGibson, 2007; Tewksbury et al., 2000). Most research in this domain has focused on how these \nprotests are framed (McCurdy, 2012). Specifically, framing research has demonstrated that \nprotests that seek to advance the rights of minority status groups are most often framed as violent \nand confrontational rather than legitimate (Boyle et al., 2004; Gitlin, 1980; McCurdy, 2012; \nMcLeod & Hertog, 1992). This biased framing can impact the success of the protests and thus \nperpetuates inequity. In addition to biased framing, the language used in news media can be \nbiased (Dragojevic et al., 2017; Mastro et al., 2014). Importantly, exposure to biased language \nhas been found to maintain stereotypes of minority status groups (Beukeboom, 2014; Graf et al., \n2012; Maass et al., 1989), which could include those who lead protests. However, there is no \nresearch on the specific linguistic mechanisms used to describe protests in news media. As such, \nthis study aims to determine whether Canadian news sources exhibit linguistic bias regarding \nprotests \u2013 specifically, the anti-pipeline protests led by Indigenous Peoples. \n1.1 Literature Review \nThroughout history, protests have led to the advancement of human, animal, and \nenvironmental rights, with success depending heavily on media support. Following successful \nprotests, American women won the right to vote in 1920 (Leininger & Gupta, 2020), animal \nrights activists put a stop to inhumane animal experiments in 1978 (Finsen & Finsen, 1994), and \nenvironmentalists and Indigenous Peoples halted the construction of the Keystone XL pipeline as \nof 2021 (Government of Alberta, 2021). The media played a key role in the success of these \nprotests. As an example, the suffrage movement lasted decades but it was only after national \nmedia support that women won the constitutional right to vote (Harvey, 2001; Lumsden, 2000). \nWithout national news media attention, the movement had only marginal success at the state \nlevel (Lumsden, 2000). Recognizing the need for country-wide publicity to bolster their bid for a \n  \n \n2 \n constitutional amendment, suffragists orchestrated their first national spectacle - the women\u2019s \nsuffrage parade of 1913 (Harvey, 2001; Lumsden, 2000). While the event was notable in a \nvariety of ways, it was the riot that ensued when drunken men attacked the mass of paraders that \ndrew the national media\u2019s attention (Harvey, 2001; Lumsden, 2000). Following the event, the \nmedia wrote empathetically about the gender-based violence faced by the paraders and the \nhearings that followed (Lumsden, 2000). This media framing legitimized suffragist\u2019s concerns, \nencouraged a national debate regarding women\u2019s rights, and shifted public opinion. Ultimately, \nthis led to the 19th constitutional amendment that guaranteed women the right to vote.  \nThe power of news media to influence the outcome of protests comes not only from a \nwide audience but from their belief, and trust, that the information provided will be objective. \nWhen nearly all members of a group are exposed to the same biased information, it is more \nlikely that the underlying biased belief will become shared among them (Holtgraves & Kashima, \n2008; Tindale & Kameda, 2000). This issue is exacerbated by the fact that people are often \nunable to accurately discern reputable information in the news (Williams & Nettlefold, 2018; \nPennycook & Rand, 2021). This means that when an audience is exposed to biased information, \nthey often accept it, and the underlying belief it reflects, without first considering the reliability \nof the source. Considering that we use our beliefs to guide our decisions and actions, such as \nwho to associate with and support, this phenomenon can have substantial impacts on the lives \nand experiences of minority group members (Haslam et al., 2002; Tindale & Kameda; Wan, \n2012). \nGiven news media\u2019s considerable influence, coverage is often sought by those who \ninitiate protests. However, systemic racism is widespread in news media. This is evidenced by a \nbody of research that has demonstrated that coverage of protests regarding issues relevant to \nminority status groups is biased (Boyle et al., 2004; McCurdy, 2012; Mcleod & Hertog, 1992). \nProtests that challenge an existing hierarchy within society receive delegitimizing coverage that \nfocuses on sensationalism and violence (Boyle et al., 2004; McCurdy, 2012; Mcleod & Hertog, \n1992). This is especially true for protests regarding Indigenous issues (Baylor, 1996; Grote & \nJohnson, 2021; Kilgo & Harlow, 2019; Miller, 2005). Providing strong support for this assertion, \nKilgo and Harlow (2019) found that anti-pipeline protests, which involve both the issue of \nIndigenous rights and environmental concerns, received coverage that was more delegitimizing \nthan protests focused solely on environmental concerns. That is, media reports framed the anti-\n  \n \n3 \n pipeline protests as confrontations, emphasizing the conflict between police and protesters, more \nthan any other type of protest included in the sample. Further, anti-pipeline protesters were \nrarely, if ever, quoted. This contrasts with environmental protesters, who were frequently quoted, \ngiving voice to their demands. These protests were also framed as a debate, including a balance \nof information and concerns from both sides. This framing suggests to the audience that \nIndigenous concerns are illegitimate and unimportant while environmental concerns are \nlegitimate and important. Thus, while integral to a protest\u2019s success, media coverage is often \nbiased against those who seek it out. \nNews media bias, and its power to influence, is rooted in its adaptation to the audience. \nAs a capitalist endeavour, news media necessarily reflects commonly held beliefs to appeal to \ntheir audience and maintain readership, thus reinforcing said beliefs (Collins & Christianson, \n2024). Supporting this claim, scholars have found that coverage varies by region (Griffin & \nDunwoody, 1997; Harlow et al., 2017; Hester & Gibson, 2007). For example, Griffin and \nDunwoody (1997) investigated the coverage of environmental contaminants and found that an \noutlet is more likely to report scientific information, rather than governmental perspectives, when \nthe audience is larger and more diverse, as compared to when an audience is small and \nhomogenous. Relatedly, Harlow et al. (2017) found that North American news sources tended to \nemploy frames that legitimized the concerns of anti-Mexican government protesters more than \nLatin American sources. Broadly, these studies suggest that news media coverage varies \nsystematically depending on regional factors such as the size and diversity of the audience and \nthe issue's locality. \nFurther, researchers have demonstrated that regional differences correspond to the \npolitical ideology of both the audience and media outlet (Dragojevic et al. 2017; Grote & \nJohnson, 2021; Weaver & Scacco, 2013). According to MediaBiasFactCheck.com (n.d.), left \nbiased or liberal ideology is collectivist. Liberals tend to prioritize equality, environmental \nprotection, education, and social services. In contrast, right biased or conservative ideology is \nindividualist. Conservatives tend to prioritize competition, personal property, and individual \nfreedom through limited government. Dragojevic et al. (2017) found that there were more \nnegative statements made about immigrants in news published in a conservative state than in \nnews published in a liberal state. Likewise, Weaver and Scacco (2013) found that liberal news \nsources were more likely than conservative news sources to marginalize a conservative \n  \n \n4 \n movement in the United States by maligning their intelligence and stating that the movement was \nfractured or fake. Liberal sources emphasized the racism inherent in the movement while \nconservative sources suggested that opponents were exaggerating and argued that the movement \nwas, in fact, not racist.  \nImportantly, Grote and Johnson (2021) found ideological differences in the coverage of \nanti-pipeline protests specifically. They found that liberal outlets published more frequently and \nconsistently on the anti-Dakota Access Pipeline protests than did conservative outlets. \nParticularly, liberal outlets published most often during human rights abuses and victories for the \nprotesters, whereas conservative outlets touted a pro-pipeline message by publishing more during \nperiods of victory for those in support of the pipeline. Additionally, conservative outlets \nemphasized the litter left by protesters, in attempt to both invoke and contradict stereotypes of \nIndigenous Peoples as environmentalists and to detract from the argument that the construction \nof pipelines is an environmental issue. Thus, it can be argued that news media are not only \npushing a political agenda that affects their coverage of specific issues but that, for conservative \nnews sources, this manifests as implicit racism against Indigenous Peoples.   \nHowever, the regional factors that influence media coverage are still unclear. For \nexample, one study by Kilgo and Harlow (2019) found that region predicted which issues \nreceived coverage, but the framing of those issues was consistent across regions in contrast to \nprior research. This inconsistency may indicate that the regions used in the study (state-wide or \ncity-wide media markets in Texas) were not distinct enough to influence coverage. Given this, it \nis not clear what the boundary conditions are for regional differences, suggesting a need for \nfurther research.  \nIn addition to biased framing, researchers have also found that there are specific linguistic \nmechanisms used in news media to convey bias about social groups (Beukeboom, et al., 2014; \nDragojevic et al., 2017; Mastro et al., 2014). More specifically, journalists transmit their biased \nbeliefs automatically and without awareness through their differential use of linguistic \nabstraction (Douglas et al., 2008; Franco & Maass, 1996;1999). This is measured using the \nLinguistic Category Model (LCM; Semin & Fiedler, 1988), which divides words into one of four \ncategories based on their level of abstraction: Descriptive Action Verbs (DAVs), Interpretive \nAction Words (IAVs), State Verbs (SVs), and Adjectives (ADJs). In addition, nouns (NNs) have \nbeen added to the LCM (Carnaghi et al., 2008). As one moves from DAVs to NNs, the \n  \n \n5 \n categories become less concrete and more abstract. At the most concrete end of the spectrum, we \nreceive information about the behavior (e.g., kick), which limits it to the specific situation. IAVs \nprovide an interpretation of a behaviour (e.g. hurts ) and could encapsulate a number of physical \nbehaviours or DAVs (e.g. kick, hit, punch, bite, slap , etc.). SVs involve even more interpretation, \noften referring to mental states (e.g. hates ) that have no defined beginning or end. ADJs describe \na trait of a person (e.g. violent ), and, at the most abstract end, NNs provide information about \nwho the person performing the behaviour is (e.g., bully ), which generalizes the original \nbehaviour to other contexts and across time. Thus, we communicate different implicit \ninformation when we use varying levels of linguistic abstraction to describe the same behaviour. \nWhen we do this automatically, but systematically and based on our beliefs about the group to \nwhich the actor belongs, it becomes linguistic bias.   \nConcerningly, linguistic bias is prevalent in news media and research has demonstrated \nthat it contributes to stereotype formation. For example, both Mastro et al. (2014) and Dragojevic \net al. (2017) examined news articles and found that abstract terms were used to describe a \nminority group\u2019s negative behaviour and a majority group\u2019s positive behaviour. This implies that \nnegative behaviour is expected of the minority group and positive behaviour is expected of the \nmajority group. In addition, they found that positive minority group behaviour and negative \nmajority group behaviour were described concretely, suggesting that these behaviours were \nunexpected. Importantly, Mastro et al. (2014) and Geschke et al. (2010) exposed participants to \nlinguistic bias in news media and demonstrated the consequences. They found that exposure to \nthe linguistically biased media descriptions of negative minority group behaviour led those \nexposed to it to stereotype and evaluate the minority group unfavorably in comparison to the \nmajority group. For example, Geschke et al. (2010) found that biased descriptions of minority \ngroup criminal behaviour led those exposed to it to produce high estimates of future criminal \nbehaviour and perceived cultural differences. Consequently, it can be argued that biased \nlanguage in news media contributes to the biased beliefs about minority groups that underly the \njustification and perpetuation of discrimination and inequity in society, which is particularly \nrelevant for news coverage of protests. \n1.2 Study Overview  \nThe purposes of this study were to determine whether Canadian news sources exhibit \nlinguistic bias that corresponds to (1) known ideological positions held by readers from different \n  \n \n6 \n regions, and (2) the political bias of the news source. To do this, we will examine news coverage \nof anti-pipeline protests led by Indigenous Peoples. These protests were widely covered in \nCanadian news media, ensuring an adequate sample of relevant articles, and were led by an \nidentifiable minority group, which is necessary for the coding of linguistic bias. While it is \nknown that Indigenous-led protests are frequently framed in the news in a negatively biased \nmanner, with a focus on illegal behaviour and conflict rather than an objective representation of \nthe protesters concerns and demands (Baylor, 1996; Grote & Johnson, 2021; Kilgo & Harlow, \n2019; Miller, 2005), most research occurs within the American context (e.g., Dragojevic et al., \n2017; Grote & Johnson, 2021; Kilgo & Harlow, 2019; Mastro et al., 2014) and there is no \nresearch on the presence of linguistic bias in news coverage of protests. Yet, linguistic bias is \nparticularly relevant to descriptions of behaviour by minority groups and has been shown to \nimpact attitudes towards them in other types of news coverage (Geschke et al., 2010; Mastro et \nal., 2014). \nIt has also been established that media bias often reflects regional differences, such as \npolitical ideology (Dragojevic et al. 2017; Weaver & Scacco, 2013), with liberal news sources \nexhibiting less bias towards Indigenous protests than conservative news sources (Grote & \nJohnson, 2021). Given this, we have selected various news sources from three regions within \nCanada. The Prairies are a typically conservative region whose economy is dependent upon the \noil and gas industry which relies on pipelines, the Central region is home to the Canadian federal \ngovernment which is charged with representing the interests of diverse Canadians, and the West \nCoast is a liberal region known to lead the country in sustainable environmental management. \nWe expect that news sources from each region will exhibit linguistic bias to different degrees \nsuch that the Prairies will be negatively biased, the Central region will be neutral, and the West \nCoast will be positively biased. In addition, within each province, we have selected news sources \nthat vary in terms of their ideological bias. We expect that news sources rated as right biased will \nexhibit a negative linguistic bias to a greater extent than news sources rated as center or left \nbiased.   \n \n \n \n \n  \n \n7 \n 2. Method \n2.1 Search \n For the purposes of this study, our intention was to identify a large sample of articles \nabout pipeline protests that were published in Canada. To do this, we searched the ProQuest \ndatabase Canadian Major Dailies (CMD), which was available and accessed through the \nUniversity of Saskatchewan library. CMD provides access to an archive of past and current full-\ntext newspaper articles from 35 Canadian news sources. The systematic search was developed in \ncollaboration with the University of Saskatchewan Psychology subject librarian for psychology.  \nTo ensure adequate and relevant coverage, we conducted some initial testing of search \nterms. We searched for the terms everywhere (i.e., article subject, title, abstract, URL, and full \ntext; FULL) and everywhere but the full text (NOFT). Given that both searches reliably captured \nall relevant results, the final search was limited to NOFT. The final search terms presented in \nTable 2.1.1 were generated by reviewing online publications (e.g., Wikipedia and news articles) \nregarding anti-pipeline protests in Canada, drafting a comprehensive list of concepts for protests \n(e.g., demonstration), crime (e.g., police), and specific pipeline protests (e.g., Coastal GasLink), \nand excluding as many redundant terms as possible while maintaining adequate coverage. \nTable 2.1.1 \nSearch Terms \nProtest  Crime Specific Protest \nConvoy* Crim* Pipeline \nProtest* Arrest* \u201cTrans Mountain\u201d \nRall* Police \u201cKinder Morgan\u201d \nMovement* Charge* \u201cCoastal GasLink\u201d \nBlock* Harass* Tyendinaga \nDemonstrat* Arm*  \nMarch*  Danger*  \nVandal* Violen*  \nEncampment* Alleg*  \nCamp* Assault*  \nBarricade* Unlawful*  \nDisrupt* Illegal*  \n  \n \n8 \n Occup* Attack*  \nRiot* Investigate*  \n Prosecute*  \n Trespass*  \n Weapon*  \n Civil disobedience  \n Threat*  \n Injur*  \n Conspir*  \n Commit*  \n RCMP  \n Fine*  \n Injunction  \n Ticket*  \n Infraction*  \n Law  \n Bylaw  \n Security  \n Contempt  \n Emergenc*  \nNote: The asterisks at the end of some of the search terms indicate a wild card that can represent \nany one or a combination of letters. For example, ticket* may return ticket, tickets, or ticketing.  \nInclusion criteria, outlined in Table 2.1.2, included: making at least one reference to a \npipeline protest or protesters in Canada, including a reference to criminal behaviour (e.g., civil \ndisobedience), the full text being within the character limit for Microsoft Excel (32 767); being \nindexed on CMD, and written in English. We included a reference to criminal behaviour in our \ninclusion criteria in order to ensure that the behaviour reported in each article was suitable for \nlinguistic bias coding, which requires the description of specific behaviours. \nTable 2.1.2 \nInclusion Criteria \nInclude at least one reference to a pipeline protest or protesters \n  \n \n9 \n The protest event must have occurred in Canada  \nInclude a reference to criminal behaviour \nFull text must be within the character limit for Microsoft Excel  \nIndexed on CMD \nWritten in English \n \nThe goal of the research was not to be comprehensive but to maximize identifying \nrelevant articles suitable for the analysis of linguistic bias. Through reviewing the oldest \npublished articles first, we found that there was a pipeline bombing on October 12, 2008, that \nwas reported on into 2009. Given that the incident occurred at the end of 2008, we opted to limit \nthe search to articles published after December 31, 2008, to avoid collecting irrelevant articles \npublished in 2008. The final search was conducted on January 23, 2024. As such, there are no \narticles published after this date included in the sample.  \n2.2 Sample \nAs shown in Figure 2.2.1, the search returned 2681 articles. The articles were exported \nfrom CMD in plain text (.txt) format. R version 4.1.1 (R Core Team, 2021b) with tidyverse \n(Wickham et al., 2019), stats (R Core Team, 2024), and readxl (Wickham & Bryan, 2023) \nlibraries were used to format the text into comma separated value (.csv) format, so the data could \nbe analyzed. This involved formatting the data into rows (one row per article) and columns (one \ncolumn per variable) and removing white space.  \nFigure 2.2.1   \nSearching, Screening, and Sample Diagram \n  \n \n10 \n  \nFour articles exceeded the character limit for Microsoft Excel and were therefore \nexcluded. Removing exact duplicates by title and full text using the Remove Duplicates Data \nTool in Microsoft Excel reduced the sample to 1957 and 1903, respectively. Next, we identified \narticles that were within scope. First, we screened article titles to identify those that were \nobviously relevant (e.g., \u201cCoastal GasLink Pipeline Protester Found Not Guilty\u201d). When it was \nnot clear whether an article was within scope based on the title, we reviewed the full text. After \nremoving articles that were out of scope, there remained 852 articles. The article counts across \npolitical bias, region, province, and publication title can be seen in Table 2.2.1. \nTable 2.2.1   \nTotal Counts Across Political Bias, Region, Province, and Publication Title \nPolitical Bias Region Province Publication Title n \nLeft-Center Central Ontario Toronto Star 54 \nLeft-Center West Coast British Columbia Times Colonist 49 \nRight-Center Central Ontario Globe and Mail 146 \n\n  \n \n11 \n Right-Center Central Ontario National Post 97 \nRight-Center Central Ontario Ottawa Citizen 20 \nRight-Center Central Ontario Windsor Star 6 \nRight-Center Central Ontario Sudbury Star 9 \nRight-Center Central Quebec Montreal Gazette 46 \nRight-Center Prairies Alberta Calgary Herald 72 \nRight-Center Prairies Alberta Edmonton Journal 53 \nRight-Center Prairies Saskatchewan Leader Post 12 \nRight-Center Prairies Saskatchewan Star Phoenix 12 \nRight-Center West Coast British Columbia Vancouver Sun 164 \nRight-Center West Coast British Columbia Province 75 \nRight-Center Atlantic Nova Scotia Chronicle Herald 8 \nRight-Center Atlantic New Brunswick Telegraph-Journal 5 \nCenter Prairies Manitoba Winnipeg Free Press 18 \nNot Rated Central Ontario Kingston Whig Standard  6 \nTotal    852 \nNote: MediaBiasFactCheck.Com , the most comprehensive and freely accessible media bias \nresource available, was used to determine political bias. Green rows indicate overrepresented \npublications, and red rows indicate excluded publications. \nTo identify suitable regions and news sources for comparison, we reviewed the \ndispersion of articles across region and news source. News sources with too few relevant articles \nremaining (i.e., those that would result in a ratio of less than one to four; Tabachnick & Fidell, \n2019) were excluded unless they were integral to the study (red rows in Table 2.2.1). Articles \npublished in some right-center biased publications from the West Coast and Central regions were \noverrepresented (green rows in Table 2.2.1). Given their overrepresentation, we randomly \nselected a subset of articles published in The Vancouver Sun, The Province, The Globe and Mail, \nand The National Post to create approximately equal groups suitable for analysis of variance. \nThis resulted in an ideal sample of 506 articles as outlined in Table 2.2.2. \nTable 2.2.2  \nIdeal Sample Description   \nPolitical Bias  Region  Province  Publication Title  n \n  \n \n12 \n Left-Center Central Ontario Toronto Star 54 \nLeft-Center West Coast British Columbia Times Colonist 49 \nRight-Center Central Ontario Globe and Mail 25 \nRight-Center Central Ontario National Post 25 \nRight-Center Central Ontario Ottawa Citizen 20 \nRight-Center Central Quebec Montreal Gazette 46 \nRight-Center Prairies Alberta Calgary Herald 72 \nRight-Center Prairies Alberta Edmonton Journal 53 \nRight-Center Prairies Saskatchewan Leader Post 12 \nRight-Center Prairies Saskatchewan Star Phoenix 12 \nRight-Center West Coast British Columbia Vancouver Sun 60 \nRight-Center West Coast British Columbia Province 60 \nCenter Prairies Manitoba Winnipeg Free Press 18 \nTotal    506 \n \n2.3 Coding \nThe next stage was manually coding the identified articles. This involved selecting \nrelevant sentences, determining if the meaning of included words was positive, negative, or \nneutral, then identifying the level of abstraction. Five independent raters, two per article, coded \nall statements about pipeline protests and protesters using a modified LCM manual (see \nAppendix; Coenen et al., 2006; Dragojevic et al., 2017; Johnson-Grey et al., 2019; Schmid et al, \n2017). All coded information was entered into a spreadsheet. For illustrative purposes, an \nexample spreadsheet is included in Table 2.3.1.  \nTable 2.3.1 \nExample Coding Spreadsheet   \nArticle Sentence Word or Phrase Score Valence \n1 Protesters are well within their \nrights but are very disruptive. Protesters 5 Positive  \n1 Protesters are well within their \nrights but are very disruptive. well within their rights 4 Positive \n  \n \n13 \n 1 Protesters are well within their \nrights but are very disruptive. disruptive 4 Negative \n \nRaters were advised to select only sentences referring to pipeline protests in Canada or \nthose who protest for or against pipelines in Canada. Sentences that did not address either were \nnot coded. Direct quotes from protesters were not coded, given that we were interested in the \ndescriptions of behaviours by protesters. In addition, the actions of politicians or journalists were \nnot coded unless politicians or journalists were explicitly described as protesters. This instruction \nwas provided as their professional roles either require them to take a stance on pipelines or to \nreport on the issue, however, this would not be considered a protest.  \nAfter selecting the relevant sentence, raters determined the valence of the selected word \nor phrase. Valence refers to positivity, negativity, or neutrality toward the referenced event, \nindividual, or group. If the text was sympathetic, supportive, non-threatening, concerned, \nsensitive, well-meaning, agreeable, understanding, or compassionate, raters were advised to code \nit as positive. If the text was unsympathetic, unsupportive, threatening, unconcerned, hostile, \naggressive, insensitive, or antagonistic raters were advised to code it as negative. Lastly, if the \ntext was unbiased, impartial, evenhanded, or neither positive nor negative, raters were advised to \ncode it as neutral.  \nNext, raters determined the level of linguistic abstraction of each word or phrase, \naccording to a modified LCM coding manual (see Appendix A; Coenen et al., 2006; Dragojevic \net al., 2017; Johnson-Grey et al., 2019; Schmid et al, 2017). They were advised to rate DAVs \none, IAVs two, SVs three, ADJs four, and NNs five. Thus, linguistic abstraction can range from \n1 to 5, with a higher number indicating greater abstraction or generalization. \n2.4 Resolution \nThe coding differences between the raters were then reconciled. This means that if raters \nselected different words, the text coded by one and not the other was sent to another rater to be \ncoded. Once all text had been coded by two raters, the datasets were combined using R version \n1.4.1717 (R Core Team, 2021a) with tidyverse (Wickham et al., 2019), dplyr (Wickham et al., \n2023), and readr (Wickham et al., 2024) libraries. After the datasets were combined, there were \n1765 coded words, with 1078 from the Central region and 687 from the Prairies. Any words that \nreferred to pro-pipeline protest(er)s (32), were unclear as to whether they referred to pro- or anti-\n  \n \n14 \n pipeline protest(er)s (73), or were unanimously coded as neutral (376) were excluded. \nDifferences in valence were resolved by excluding ambivalently rated words (759; Fiedler et al., \n1993). This left a final sample of 525 words, with 307 from the Central region and 218 from the \nPrairies. Differences in abstraction scores were reconciled by using the mean of the two scores \n(Hunt, 2011; Maass et al., 1998; Menegatti & Rubini, 2012). Interrater reliability for abstraction \nwas high (\u03ba = .70; Landis & Koch, 1977). \nThe final dataset included the following variables: Article number, article title, \npublication title, region, province, city of publication, valence, and mean abstraction scores for \npositive and negative content. Linguistic bias is a function of both valence and abstraction: A \nhigher abstraction score for negative content and lower abstraction score for positive content \nindicates a negative bias, while a higher abstraction score for positive content and lower \nabstraction score for negative content indicates a positive bias. \n2.5 Reduction in Scope   \nDuring data preparation, we encountered unforeseen issues that required us to make \nsignificant amendments to the dataset. This was necessitated by the time constraints of the \nmaster's thesis and the complexity and time and resource intensive nature of manually coding for \nlinguistic bias. Specifically, we were unable to identify enough research assistants with the \nability and capacity to complete coding the entire sample prior to the thesis defence. However, \nour initial sample was ambitious in contrast to most research within the linguistic bias paradigm. \nResearch in this field typically consists of the analysis of a few short texts or participant selection \nfrom pre-determined responses that vary by valence and level of linguistic abstraction (e.g., \nDouglas et al., 2008; Maass et al., 1989; 1995; 1996; Menegatti & Rubini, 2012) rather than \nmanually coding hundreds of real news articles (but see Dragojevic et al., 2017, for an \nexception).  \nFor these reasons, and for the purposes of the master\u2019s thesis, we limited our scope and \nfurther reduced our sample. This means our final thesis sample consisted of 20 articles from just \ntwo regions in Canada, as shown in Table 2.5.1.   \nTable 2.5.1 \nFinal Sample Description   \nPolitical Bias Region Province Publication Title n \nRight-Center Central Quebec Montreal Gazette 10 \n  \n \n15 \n Right-Center Prairies Saskatchewan Leader Post 10 \n \nWe limited our focus to regional differences between Montreal, a large city in Central \nCanada, and Regina, a smaller city in the Prairies. We opted to focus on right-centered news \nsources published in these cities for three reasons: (1) to maximize the use of articles that had \nalready been manually coded, (2) their geographical location, a factor indicative of regional \ndifferences that may (Dragojevic et al. 2017; Harlow et al., 2017; Hester & Gibson, 2007) or \nmay not (Kilgo & Harlow, 2019) correspond to media bias, and (3) differences in the diversity of \ntheir populations, as indicated by population size, another regional factor known to correspond \nwith media bias (Griffin & Dunwoody, 1997). As of 2021, Montreal had a population of 1 762 \n949 and Regina had a population of 226 404 (Statistics Canada, 2023b).  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n16 \n 3. Results   \nThe abstraction scores were analyzed using a 2 Region (Central or Prairie) x 2 Valence \n(Positive and Negative) mixed analysis of variance to investigate whether regional news sources \nvary in the presence or form of linguistic bias in the description of anti-pipeline protests.  \nThere was no main effect for valence, F(1, 18) = 0.975, p = 0.336, \u03b72 = .03, but there was \na significant main effect for region, F(1, 18) = 4.970, p = 0.039, \u03b72 = .08. As shown in Figure \n3.1, News sources from the Prairies used significantly more abstract language (M = 3.53, SE = \n0.19) to describe the anti-pipeline protests than news sources from the Central region ( M = 2.92, \nSE = 0.19). The effect size was .08, which means that region accounted for 8% of the variance in \nabstraction (Fritz et al., 2012; Levine & Hullett, 2002).   \nFigure 3.1 \nRegional Differences in Abstraction \n                   \nAlthough the interaction between valence and region, shown in Figure 3.2, was not \nsignificant, F(1, 18) = 1.193, p = 0.289, \u03b72 = .04, we examined the pattern of means because of \nits theoretical importance. The distribution of means in Table 3.1 suggests that anti-pipeline \nprotest reporting was relatively neutral in the Central region whereas it was slightly positively \nbiased in the Prairies. \nFigure 3.2 \nInteraction Between Valence and Region  \n\n  \n \n17 \n  \nTable 3.1 \nMeans for Positive and Negative Abstractions Scores by Region \nRegion Positive Abstraction Negative Abstraction Bias \nCentral 2.90 2.94 -0.03 \nPrairies 3.92 3.13 0.79 \n \nIn a simplified alternative analysis, we first calculated a bias index for each article by \nsubtracting the abstraction score for negative content from the abstraction score for positive \ncontent. The resulting bias index ranges from \u20135 to +5, with positive scores indicating a positive \nbias, negative scores indicating a negative bias, and scores around zero indicating neutrality \n(Maass et al., 1996).  \nWe conducted an independent samples t-test to investigate the effect of region on bias \nindex scores. As shown in Table 3.1, the Central region was linguistically neutral whereas the \nPrairies exhibited a slight positive linguistic bias. However, there was no significant difference \nbetween regions on bias, t(18) = -1.090, p = .289. \n \n \n \n \n \n\n  \n \n18 \n 4. Discussion   \nIn this study, we examined articles published in news sources from the Prairies and \nCentral regions of Canada for linguistic bias in the description of anti-pipeline protests led by \nIndigenous Peoples. There was a main effect of region such that the news source from the \nPrairies exhibited a higher level of linguistic abstraction than the news source from the Central \nregion. This extends research that finds regional differences in news media\u2019s framing of protests \n(Grote & Johnson, 2021; Weaver & Scacco, 2013) to include linguistic differences. The Central \nregion news source\u2019s use of less abstract language indicates that they are not generalizing, or \nadding their own interpretation, of the protest(er)s actions. Rather, by using more concrete \nlanguage, they are providing information that is potentially more verifiable and factual. Thus, \nthese findings are in line with our hypothesis that they would provide more neutral coverage of \nthe protests. This could be explained by news sources in the Central region catering to a wider, \npotentially more diverse, audience than news sources from the Prairies (Griffin & Dunwoody, \n1997).  \nIn contrast, the higher level of linguistic abstraction exhibited by news sources published \nin the Prairies indicates that they are generalizing about the protest(er)s. This is partially in line \nwith our hypothesis that Prairie news sources would exhibit a negative linguistic bias. The higher \nlevel of abstraction suggests to readers that the trait or action being described is expected and is \nlikely to occur again in the future and in other contexts (Maass et al., 1989). With a smaller, \nmore homogenous population to accommodate, it could be that news sources from the Prairies \nare confident enough in their understanding of their audience to offer an inoffensive \ninterpretation.  \nHowever, the meaning of this generalization is not clear given that the meaning of \nabstraction depends on valence, and the interaction with valence was not significant. It could be \nthat higher abstraction indicates a negative generalization about the Indigenous protester(s), \ngiven that all articles involved criminal behaviour, or it could be that higher abstraction indicates \na positive generalization, given that the majority of coded words were determined to be positive \nby the independent raters and it is possible that the protests were framed more positively as an \nenvironmental issue. What we can conclude is that news sources from the Prairies are \nsignificantly more likely to describe an interpretation, as compared to sources from the Central \n  \n \n19 \n region, which are significantly more likely to describe behaviours or the concrete actions of the \nprotester(s).  \nAs expected, news sources published in the Central region were linguistically neutral in \ntheir description of anti-pipeline protests. Contrary to our expectations, news sources published \nin the Prairies also used largely neutral rather than negatively biased language. Even neutral \nlanguage, however, would contradict previous research that suggests that protests regarding \nissues relevant to minority groups generally (Boyle et al., 2004; McCurdy, 2012; Mcleod & \nHertog, 1992), and Indigenous Peoples specifically (Baylor, 1996; Grote & Johnson, 2021; Kilgo \n& Harlow, 2019; Miller, 2005) will be described negatively in the news.  \nThe lack of negative linguistic bias in describing the protests may have influenced their \nsuccess, in line with previous research (Harvey, 2001; Lumsden, 2000). That is, it may be that \nsome or all of the described anti-pipeline protests were ultimately successful. In support of this, \nseveral of the pipelines being protested were either significantly delayed (e.g., Coastal GasLink, \nTrans Mountain Expansion) or cancelled (e.g., Keystone XL, Enbridge Northern Gateway, \nEnergy East). This suggests that neutral language, or lack of a negative bias, to describe anti-\npipeline protests may have influenced, or at least reflects, real-world decisions to halt pipeline \nconstructions in some instances.  \nIn summary, these findings demonstrate that regional differences influence the level of \nlinguistic abstraction used to describe protests and suggest that the pattern of use may correlate \nwith public opinion regarding social movements. They also provide preliminary evidence that \nnegative framing of protests does not extend to the specific linguistic mechanisms used in \ndescriptions.  \n4.1 Limitations and Future Directions  \n This study was necessarily limited to 20 anti-pipeline protest articles published within \ntwo mainstream news sources in Canada due to the time and resource intensive nature of coding \nfor linguistic bias. Thus, we have both a limited sample size and limited range of variability in \nour independent variables, which limits our ability to draw conclusions. Future research should \nexplore options for the automated coding of linguistic bias, which would allow for greater \nregional and ideological differences from a wider variety of Canadian news sources, with \nconsiderably lower cost, time, and effort. \n  \n \n20 \n It is possible that our dataset was skewed due to the inclusion of crime synonyms in our \nsearch terms. Articles about anti-pipeline protests with no mention of crime synonyms may not \nshow the same pattern of results. However, previous research has shown that news coverage of \nsocial movements does tend to skew towards sensational, violent, and confrontational events \n(Boyle et al., 2004; Gitlin, 1980; McCurdy, 2012; McLeod & Hertog, 1992) and the inclusion of \ncrime synonyms ensured that articles were suited to the coding of linguistic bias, which requires \nthe description of behaviour. Future research may include the description of more neutral \nbehaviour in news sources across regions to address this limitation. \nOur sample was also limited, by chance, to protests that were largely successful. This \nprevents us from drawing conclusions about how linguistically biased news media coverage \nimpacts the success of protests. To address this limitation, future research could selectively \nchoose their sample according to outcome, so that they can compare the descriptions of \nsuccessful versus unsuccessful protests. Researchers could also carry out a longitudinal analysis, \nto investigate how linguistic bias manifests over time and how this might correspond with \nchanging public support. \nUnfortunately, our linguistic analysis does not allow us to make inferences about, or \nunderstand, the relationship between framing and linguistic bias. For example, it could be, and \nmay in fact be likely (Grote & Johnson, 2021), that anti-pipeline protests are reported through a \ncolonial lens that reduces it to an environmental issue only rather than a complex issue related to \nIndigenous sovereignty, treaty and land rights, and spiritual connections to land among other \nthings. In reading the Prairie articles in our sample, we found that when Indigenous groups \nopposing the pipelines are explicitly mentioned, words like \u201ctreaty\u201d, \u201creconciliation\u201d, and \u201cland \nback\u201d are sometimes included. However, the complex relationship between pipeline construction \nand Indigenous sovereignty is rarely explicated. In some cases, the Indigenous groups opposing \nthe pipelines are not even mentioned, reducing the opposition to pipelines to just \u201cenvironmental \ngroups and allies\u201d. As described earlier, environmental issues are portrayed more positively in \nthe news than Indigenous issues (Kilgo & Harlow, 2019). This would align with the lack of a \nnegative bias by news sources from the Prairies. However, as we did not systematically \ninvestigate how the issue was framed within our sample, we can only speculate. Future research \ncould address this limitation by conducting both a linguistic and framing analysis to understand \nhow biased reporting on anti-pipeline protests manifests. \n  \n \n21 \n Lastly, our sample may not reflect current media consumption habits. For example, the \ntypical audience for right-centered written news media is older (Elvestad & Blekesaune, 2008) \nand conservative (Stroud, 2008). While investigating linguistic differences in written mainstream \nnews media was our ultimate purpose, Canadians most commonly follow the news on the \ninternet (80%) or television (87%; Statistics Canada, 2023a). These platforms often include \nmultimedia (e.g., videos, memes) which has been shown to impact the framing of protests \n(Harlow et al., 2017). This would suggest that newspapers are not the most popular news source, \nand as such they may not reflect popular beliefs.  \nDespite these limitations, this study is valuable in that it demonstrates that regional \ndifferences in the way protests are framed extend to linguistic differences, but that negative \nframing may not. Prior to this study, there was no research on the specific linguistic mechanisms \nused to describe protests in the news, though research has demonstrated that these mechanisms \ncontribute to the perpetuation of widely shared beliefs about minority status groups (Beukeboom, \n2014; Graf et al., 2012; Maass et al., 1989) in other types of news coverage (Dragojevic et al., \n2017; Mastro et al., 2014). We found that regional differences influence the level of linguistic \nabstraction used in the description of anti-pipeline protests in news articles. Given that the \nlanguage used by both sources was largely neutral rather than negatively biased, and many of the \nreported anti-pipeline protests were successful, it could be that linguistic abstraction, in addition \nto framing, influences the outcome of social protests. Thus, the language used in news media \nreflects regional differences and can therefore be studied to provide insight into regional beliefs \nabout protests. \n  \n  \n \n22 \n References  \nBaylor, T. (1996). Media framing of movement protest: The case of American Indian protest. \nThe Social Science Journal, 33 , 241\u2013255. \nBeukeboom, C. J. (2014). Mechanisms of linguistic bias: How words reflect and maintain \nstereotypic expectancies (Chapt.). In J. Laszlo, J. Forgas, & O. Vincze (Eds.), Social  \nCognition and Communication (pp. 313-330). New York, NY: Psychology Press.   \nBlack Lives Matter. (2024, March 19). Our history . https://blacklivesmatter.com/our-history/. \nBoyle, M. P., McCluskey, M. R., Devanathan, N., Stein, S. E., & McLeod, D. (2004). The \ninfluence of level of deviance and protest type on coverage of social protest in \nWisconsin from 1960 to 1999. Mass Communication & Society , 7(1), 43\u201360. \nhttps://doi.org/10.1207/s15327825mcs0701_4 \nCarnaghi, Maass, A., Gresta, S., Bianchi, M., Cadinu, M., & Arcuri, L. (2008). Nomina sunt \nomina. Journal of Personality and Social Psychology, 94 (5), 839\u2013859. \nhttps://doi.org/10.1037/0022-3514.94.5.839  \nCoenen, L., Hedebouw, L., & Semin G. R. (2006). Measuring abstraction: The linguistic \ncategory model. Available online at  www.cratylus.com  (resources). \nCollins, K., & Christianson, T. (2024). The relationship between language and bias. In S. \nCroucher & E. Nshom (Eds.). Research handbook on communication and prejudice.  \nEdward Elgar Publishing Ltd. \nDetenber, B. H., Gotlieb, M. R., McLeod, D. M., & Malinkina, O. (2007). Frame Intensity \nEffects of Television News Stories About a High-Visibility Protest Issue. Mass  \nCommunication & Society , 10(4), 439\u2013460. https://doi.org/10.1080/15205430701580631  \nDouglas, K. M., Sutton, R. M., & Wilkin, K. (2008). Could You Mind Your Language?: An \nInvestigation of Communicators' Ability to Inhibit Linguistic Bias. Journal of Language  \nand Social Psychology , 27(2), 123\u2013139. https://doi.org/10.1177/0261927X07313655 \nDragojevic, M., Sink, A., & Mastro, D. (2017). Evidence of Linguistic Intergroup Bias in U.S. \nPrint News Coverage of Immigration. Journal of Language and Social Psychology, \n36(4),462- 472. https://doi.org/10.1177/0261927X16666884  \nElvestad, E., & Blekesaune, A. (2008). Newspaper Readers in Europe: A Multilevel Study of \nIndividual and National Differences. European Journal of Communication \n(London) , 23(4), 425\u2013447. https://doi.org/10.1177/0267323108096993  \n  \n \n23 \n Fiedler, K., Semin, G. R., & Finkenauer, C. (1993). The battle of words between gender \nGroups: A language-based approach to intergroup processes. Human Communication \nResearch, 19( 3), 409\u2013441. https://doi.org/10.1111/j.1468-2958.1993.tb00308.x  \nFinsen, L., & Finsen, Susan. (1994). The animal rights movement in America: From compassion  \nto respect . Twayne Publishers. \nFranco, F. M., & Maass, A. (1996). Implicit Versus Explicit Strategies of Out-Group \nDiscrimination: The Role of Intentional Control in Biased Language Use and Reward \nAllocation. Journal of Language and Social Psychology , 15(3), 335\u2013359. \nhttps://doi.org/10.1177/0261927X960153007  \nFranco, F. M., & Maass, A. (1999). Intentional control over prejudice: When the choice of the \nmeasure matters. European Journal of Social Psychology , 29(4), 469-477. \nFritz, C. O., Morris, P. E., & Richler, J. J. (2012). Effect size estimates: Current use, \ncalculations, and interpretation. Journal of Experimental Psychology. General , \n141(1), 2\u201318. https://doi.org/10.1037/a0024338 \nGeschke, D., Sassenberg, K., Ruhrmann, G., & Sommer, D. (2010). Effects of Linguistic \nAbstractness in the Mass Media: How Newspaper Articles Shape Readers' Attitudes \nToward Migrants. Journal of Media Psychology , 22(3), 99\u2013104. \nhttps://doi.org/10.1027/1864-1105/a000014  \nGitlin, T. (1980). The whole world is watching: Mass media in the making and unmaking of the  \nnew left . University of California Press. \nGorham, B. W. (2006). News Media's Relationship With Stereotyping: The Linguistic  \nIntergroup Bias in Response to Crime News. Journal of Communication , 56(2), 289\u2013308. \n https://doi.org/10.1111/j.1460-2466.2006.00020.x  \nGovernment of Alberta. (2021, June 9). Pipeline Project \u2013 Keystone XL . \nhttps://www.alberta.ca/keystone-xl-pipeline-project \nGraf, S., Bilewicz, M., Finell, E., & Geschke, D. (2013). Nouns cut slices: Effects of \nlinguistic forms on intergroup bias. Journal of Language and Social Psychology , 32(1), \n62\u201383. https://doi.org/10.1177/0261927X12463209 \nGriffin, R. J., & Dunwoody, S. (1997). Community Structure and Science Framing of News \nAbout Local Environmental Risks. Science Communication , 18(4), 362\u2013384. \nhttps://doi.org/10.1177/1075547097018004005  \n  \n \n24 \n Grote, K. M., & Johnson, J. T. (2021). Pipelines, protectors, and settler colonialism: Media \nrepresentations of the Dakota Access Pipeline protest. Settler Colonial Studies , 11(4), \n487\u2013511. https://doi-org.cyber.usask.ca/10.1080/2201473X.2021.1999008 \nHarlow, S., Salaverr\u00eda, R., Kilgo, D. K., & Garc\u00eda-Perdomo, V. (2017). Protest paradigm in  \nmultimedia: Social media sharing of coverage about the crime of Ayotzinapa, \nMexico. Journal of Communication , 67(3), 328\u2013349. https://doi.org/10.1111/jcom.12296  \nHarvey, S. (2001, June 28). Marching for the vote: Remembering the woman suffrage parade of \n1913 . Library of Congress. https://guides.loc.gov/american-women-essays/marching-for  \nthe-vote \nHaslam, S. A., Turner, J. C., Oakes, P. J., Reynolds, K. J., & Doosje, B. (2002). From personal \npictures in the head to collective tools in the world: How shared stereotypes allow \n groups to represent and change social reality. In C. McGarty, R. Spears, V.Y. Yzerbyt \n(Eds.), Stereotypes as explanations: The formation and meaningful beliefs about social  \nGroups (pp. 157-185). Cambridge University Press. Doi: \n10.1017/cbo9780511489877.009 \nHester, J. B., & Gibson, R. (2007). The agenda-setting function of national versus local media: A \n time-series analysis for the issue of same-sex marriage. Mass Communication & Society , \n10(3), 299\u2013317. https://doi.org/10.1080/15205430701407272  \nHoltgraves, T. M., & Kashima, Y. (2008). Language, Meaning, and Social Cognition. \nPersonality and Social Psychology Review , 12(1), 73\u201394.   \nhttps://doi.org/10.1177/1088868307309605  \nHunt, A. (2011). The linguistic expectancy bias and the American mass media  (Publication No. \n3477764) [Doctoral Dissertation, Temple University]. ProQuest Dissertations & Theses. \nJohnson-Grey, K. M., Boghrati, R., Wakslak, C. J., & Dehghani, M. (2020). Measuring abstract \nmind-sets through syntax: Automating the linguistic category model. Social  \nPsychological and Personality Science , 11(2), 217-225. \nKilgo, D. K. & Harlow, S. (2019). Protests, media coverage, and a hierarchy of social struggle. \nThe International Journal of Press/Politics, 24 (4), 508\u2013530. \nhttps://doi.org/10.1177/1940161219853517  \nLandis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for categorical \ndata. Biometrics , 33(1), 159\u2013174. https://doi.org/10.2307/2529310 \n  \n \n25 \n Leininger, W. M., & Gupta, P. (2020). One hundred years of women\u02bcs suffrage: Health care \nadvocacy, and why we vote. Obstetrics and Gynecology (New York. 1953) , 136(2), \n349\u2013353. https://doi.org/10.1097/AOG.0000000000004009  \nLevine, T. R., & Hullett, C. R. (2002). Eta Squared, Partial Eta Squared, and misreporting of \neffect Size in communication Research. Human Communication Research , 28(4), 612 \n625. https://doi.org/10.1111/j.1468-2958.2002.tb00828.x \nLumsden, L. J. (2000). Beauty and the beasts: Significance of press coverage of the 1913 \nnational suffrage parade.  Journalism and Mass Communication Quarterly, 77 (3), 593- \n611.  \nMaass, A., Ceccarelli, R., & Rudin, S. (1996). Linguistic intergroup bias: Evidence for in-group \nprotective motivation. Journal of Personality and Social Psychology , 71(3), 512. \nMaass, A., Milesi, A., Zabbini, S., & Stahlberg, D. (1995). Linguistic intergroup bias: \nDifferential expectancies or in-group protection?. Journal of personality and social \npsychology, 68 (1), 116. \nMaass, A., Montalcini, F., & Biciotti, E. (1998). On the (dis-)confirmability of stereotypic \nattributes. European Journal of Social Psychology , 28(3), 383\u2013402. \nhttps://doi.org/10.1002/(SICI)1099-0992(199805/06)28:3<383::AID-     \nEJSP870>3.0.CO;2Q \nMaass, A., Salvi, D., Arcuri, L., & Semin, G. (1989). Language use in intergroup contexts. \nJournal of Personality and Social Psychology, 57 (6), 981\u2013993. \nhttps://doi.org/10.1037/0022  3514.57.6.981 \nMastro, D., Tukachinsky, R., Behm-Morawitz, E., & Blecha, E. (2014). News coverage of \nimmigration: The influence of exposure to linguistic bias in the news on consumer's \nracial/ethnic cognitions. Communication Quarterly , 62(2), 135\u2013154. \nhttps://doi.org/10.1080/01463373.2014.890115 \nMcCurdy, P. (2012). Social movements, protest and mainstream media. Sociology Compass , \n6(3), 244\u2013255. https://doi.org/10.1111/j.1751-9020.2011.00448.x  \nMcLeod, D. M., & Hertog, J. K. (1992). The manufacture of 'public opinion' by reporters: \ninformal cues for public perceptions of protest groups. Discourse & Society , 3(3), 259 \n275. https://doi.org/10.1177/0957926592003003001  \nMediaBiasFactCheck.com. (n.d.). Left vs. Right bias: How we rate the bias of media sources.  \n  \n \n26 \n  https://mediabiasfactcheck.com/left-vs-right-bias-how-we-rate-the-bias-of-media  \nsources/ \nMenegatti, M., & Rubini, M. (2012). From the individual to the group: The enhancement of \nlinguistic bias. European Journal of Social Psychology , 42(1), 36\u201340. \nhttps://doi.org/10.1002/ejsp.856 \nMiller, J. (2005). Ipperwash and the media: A critical analysis of how the story was covered. \nReport submitted to Aboriginal Legal Services of Toronto . \nPennycook, G. and Rand, D. G. (2021). The psychology of fake news. Trends in cognitive \nsciences, 25(5):388\u2013402. \nR Core Team (2021a). R: A language and environment for statistical computing (Version  \n1.4.1717) [Computer software]. R Foundation for Statistical Computing.  \nhttps://www.R-project.org/ . \nR Core Team (2021b). R: A language and environment for statistical computing (Version  \n4.1.1) [Computer software]. R Foundation for Statistical Computing.  \nhttps://www.R-project.org/ . \nR Core Team (2024). The R Stats Package  (Version 4.5.0) [Computer Software]. R Foundation \nfor Statistical Computing.  \nhttps://stat.ethz.ch/R-manual/R-devel/library/stats/html/00Index.html \nSchmid, J., Fiedler, K., Semin, G., & Englich, B. (2017). Measuring implicit causality: The \nlinguistic category model. Unpublished manuscript . \nSemin, G., & Fiedler, K. (1988). The cognitive functions of linguistic categories in \ndescribing persons. Journal of Personality and Social Psychology, 54 (4), 558 \n568. https://doi.org/10.1037/0022-3514.54.4.558  \nStatistics Canada. (2023a, March 28). Media consumption habits in Canada: Are Canadians in \nthe know? https://www150.statcan.gc.ca/n1/pub/11-627-m/11-627-m2022055-eng.htm \nStatistics Canada. (2023b, November 25). Census profile: 2021 census of population . \nhttps://www12.statcan.gc.ca/census-recensement/2021/dp-pd/prof/index.cfm?Lang=E \nStroud, N. J. (2008). Media Use and Political Predispositions: Revisiting the Concept of \nSelective Exposure. Political Behavior , 30(3), 341\u2013366. https://doi.org/10.1007/s11109  \n007-9050-9 \nTabachnick, B. G., & Fidell, Linda S. (2019). Using multivariate statistics  (7th ed.). Pearson  \n  \n \n27 \n Education.  \nTewksbury, D., Jones, J., Peske, M. W., Raymond, A., & Vig, W. (2000). The interaction of \nnews and advocate frames: Manipulating audience perceptions of a local public policy \nissue. Journalism & Mass Communication Quarterly , 77(4), 804\u2013829. \nhttps://doi.org/10.1177/107769900007700406  \nTindale, R. S., & Kameda, T. (2000). \u2018Social sharedness\u2019 as a unifying theme for information \nprocessing in groups. Group Processes & Intergroup Relations, 3, 123-140. \ndoi:10.1177/1368430200003002002 \nWan, C. (2012). Shared knowledge matters: Culture as intersubjective representations. Social \nand personality psychology compass, 6(2):109\u2013125. \nWeaver, D. A., & Scacco, J. M. (2013). Revisiting the Protest Paradigm: The Tea Party as \nFiltered through Prime-Time Cable News. The International Journal of  \nPress/Politics , 18(1), 61\u201384. https://doi.org/10.1177/1940161212462872 \nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L.D., Fran\u00e7ois, R., Grolemund G., \nHayes A., Henry, L., Hester J., Kuhn, M., Pedersen, T.L., Miller, E., Bache, S.M., \nM\u00fcller, K., Ooms, J., Robinson, D., Seidel, D.P....(2019). Welcome to the tidyverse.  \nJournal of Open Source Software, 4 (43), 1686, https://doi.org/10.21105/joss.01686  \nWickham, H., & Bryan, J. (2023). readxl: Read Excel files [Version 1.4.3]  (Computer \nSoftware). https://readxl.tidyverse.org. https://github.com/tidyverse/readxl . \nWickham, H., Fran\u00e7ois, R., Henry, L., M\u00fcller, K., & Vaughan, D. (2023). Dplyr: A grammar of  \ndata manipulation . [Version 1.1.4] (Computer Software).  \nWickham, H., Hester, J., & Bryan, J. (2024). readr: Read rectangular text data . [Version 2.1.5] \n(Computer Software). https://github.com/tidyverse/readr. https://readr.tidyverse.org . \nWilliams, K., & Nettlefold, J. (2018, September 9). Can you tell fact from fiction in the news? \nMost students can\u2019t. Retrieved from  https://theconversation.com/can-you-tell-fact-from  \nfiction-in-thenews- most-students-cant-102580 \n  \n  \n \n28 \n Appendix \nCoding Manual: Spring 2024 \n \nIn analyzing these articles, we are looking for reliability in coding for:  \n\uf0b7 Text Selected (text referring to pipeline protests or protesters) \n\uf0b7 Linguistic Abstraction (NN, ADJ, SV, IAV, DAV) \n\uf0b7 Valence (positive, negative, neutral) \nThe amount of time it will take to code each article will vary due to article length, complexity, \netc. Some articles may take only a few minutes while others could take up to half an hour. The \ngoal is not speed; it is accuracy. So, take your time when coding the articles.  \n \nArticle Level Information \n \nArticles will be assessed on a sentence-by-sentence basis. Only sentences referring to the \npipeline protests  IN CANADA or those who protest for or against pipelines  IN CANADA \nshould be coded. Sentences not addressing either should not be coded. Please take note of \narticles that do not contain any sentences within the scope. For example, if the article is a \nduplicate or only refers to a USA event, you will not add it to the coding sheet, but you will \nrecord the article number for our records. The activity, person, or group may be the subject  or \nobject  of the sentence (see section titled, Supplemental Definitions, for more information on \nsubjects and objects in sentences). NOTE: you will not code direct quotes from protesters or the \nactions of politicians or journalists unless they are explicitly described as protesters. Many \npoliticians take a stance on pipelines as part of their role as politicians, however, this would not \nbe considered a protest. As such, you would not code these instances. While journalists often \ncover protests, you will only code their actions or traits if it is explicitly mentioned that they are \nthere to support or oppose a pipeline. Otherwise, you will not code journalist traits or actions.  \n  \nPipeline protests  - In the current study pipeline protests  are defined as support for, or \nopposition to, the expansion or construction of a pipeline in Canada. A Protest may be referred to \nas a/an: \n\uf0b7 Convoy \n  \n \n29 \n \uf0b7 Rally \n\uf0b7 Movement \n\uf0b7 Blockade \n\uf0b7 Demonstration \n\uf0b7 March  \n\uf0b7 Vandalism \n\uf0b7 Encampment \n\uf0b7 Camp \n\uf0b7 Barricade \n\uf0b7 Disruption \n\uf0b7 Occupation \n\uf0b7 Riot \n  \nThose who protest pipelines  - In the current study, pipeline protesters  are defined as any \nperson or group who protests or has protested for or against the construction or expansion of a \npipeline in Canada. Protesters may be referred to as: \n  \n\uf0b7 Activists or activist groups (e.g., Extinction Rebellion, Unist'ot'en camp) \n\uf0b7 Environmentalists \n\uf0b7 Organizers \n\uf0b7 Demonstrators \n\uf0b7 Vandals \n\uf0b7 Rioters \n\uf0b7 Protesters \n\uf0b7 Land Defenders (Note: this term often refers to American protesters) \n\uf0b7 Tiny House Warriors  \n\uf0b7 Indigenous, belonging to an Indigenous group (e.g., Wet'suwet'en Nation, \nTyendinaga, Mohawks, Tsleil-Waututh), supporting Indigenous groups  \n\uf0b7 Regional collectives (e.g., British Columbians, etc.) \n  \n \n30 \n \uf0b7 Individual, representative, or spokesperson representing the group or individual \nposition against pipelines \n\uf0b7 Any pronoun used to reflect the above types of groups/individuals (we, us, I)   \n  \nPipelines  - In the current study, pipelines commonly protested about include but are not limited \nto: \n\uf0b7 Coastal GasLink, CGL, GasLink  \n\uf0b7 Enbridge Northern Gateway, Enbridge, Gateway, Line 9 \n\uf0b7 Keystone XL, KXL (Note: most protests against this pipeline were in the United \nStates) \n\uf0b7 Trans Mountain, Trans Mountain Pipeline Expansion, TMX \n\uf0b7 Kinder Morgan  \n\uf0b7 Generic (e.g., pipeline, oil and gas, bitumen)  \n  \nOnce this content has been identified, you will then code each reference for valence. \n  \nValence \u2013 Valence refers to positivity , negativity , or neutrality  toward the referenced cause, \nindividual, or group. Code the valence of each description referring to either the protest(s) or \nprotester(s).   \n  \nPositive (P):  sympathetic, supportive, nonthreatening, concerned, sensitive, well-\nmeaning, agreeable, understanding, compassionate \nNegative (N):  unsympathetic, unsupportive, threatening, unconcerned, hostile, \naggressive, insensitive, antagonistic  \nNeutral (U):  unbiased, impartial, evenhanded, neither positive nor negative  \n  \nTo determine whether the identified reference describes the cause, individual, or group \npositively, negatively, or in a neutral way you will have to look at the verb or adjective being \nused. More complex sentences may have positive and negative descriptions. In these cases, each \npart should be coded separately. \n  \n  \n \n31 \n General example: \n\u201cProtesters  (P) are simply marching for their rights (P)\u201d  \n\u201cProtesters  (P) are destroying the economy (N)\u201d  \n\u201cProtesters  (P) are well within their rights  (P), but are very disruptive  (N)\u201d \n\u201cProtesters  (P) parked along the street  (U)\u201d \n \nWe have determined the valence in each example, now we have to code for level of \nlanguage abstraction .  \n  \nLanguage Abstraction -  Language abstraction in the current study is measured using the \nlinguistic category Model (LCM).  This model explains the psychological properties of language. \nThe LCM works by identifying each noun, adjective, and verb in a target text (in this case, news \narticle references to protests and protesters). Verbs are split up into three distinct categories: \ndescriptive action verbs (DAV), interpretative action verbs (IAV), and state verbs (SV). \nAdjectives (ADJ) and Nouns (NN) are the most abstract and descriptive action verbs are the \nmost concrete. The level of abstraction/concreteness has important implications for the \ninterpretations of messages.  \n  \nNouns (NN)  \n\uf0b7 Nouns refer to the class to which a given object belongs, i.e., they categorize people by \nassigning to a specific group or type. They should be given a score of 5. Examples: \nprotester, organizer, crook, criminal, disaster, riot. \n  \n\u201cHis father is a thief.\u201d \n  \n\u201cHeavy rainfall made the party tent collapse. It became a mess.\u201d \n  \n\u201cThe bike her father bought for her is a gem.\u201d \n  \nAdjectives (ADJ) \n\uf0b7 Adjectives refer to qualities or properties of a person. They should be given a score of 4. \n  \n \n32 \n Examples: social, aggressive, nice, honest, reliable, friendly, loving, old, busy. \n  \n \u201cShe is helpful.\u201d \n  \n\uf0b7 Adjectives can also modify, qualify, or refer to a relevant object, action, or situation. \n  \n \u201cHe dropped the letter in the wrong mailbox.\u201d \n  \n\u201cShe, friendly though firmly, asked him to go away.\u201d \n  \n\u201cWe went to a fun party.\u201d \n  \nState Verbs (SV) \n\uf0b7 State Verbs refer to enduring  psychological states of a person in relation to another \nperson . They do not refer to single event. They have no clear beginning or end. They \ncannot be objectively verified. They can be cognitive (e.g., to think) or affective (e.g., to \nhate). They should be given a score of 3. Examples: think, admire, hate, appreciate, \nunderstand, love, see, hear. \n  \n\u201cShe loves her mother.\u201d \n  \nInterpretive Action Verbs (IAV) \n\uf0b7 Interpretive Action Verbs refer to a multitude  of different behaviors/actions that have the \nsame meaning but do not share an invariant physical aspect. They do not allow clear \nvisualization of the behavior or action they refer to. They refer to actions with a clearly \ndefined beginning and end. They have a positive or negative value. Their meaning is not \nentirely dependent on context of action. They should be given a score of 2. Examples: \nhelp, tease, avoid, cheat, encourage, bully. \n  \n\u201cShe helped her friend.\u201d \n  \n  \n \n33 \n \u201cShe cheated on the exam.\u201d \n  \n\uf0b7 State Action Verbs (SAV) express an emotional consequence  of a specific action but do \nnot refer to the action itself. They have a specific cause and clearly defined beginning and \nend. They have positive or negative value and should be coded as IAVs. Examples: \namazed, surprised, angered, ashamed. \n  \n\u201cShe was saddened by the news.\u201d \n  \nDescriptive Action Verbs (DAVs) \n\uf0b7 Descriptive Action Verbs refer to single specific action with a clear beginning and end. \nThey provide concrete descriptions.  They have physically invariant features and allow \nunambiguous visualization of specific action. They gain an evaluative component \ndepending on the context (e.g., push someone toward  bus vs. away  from bus). They \nshould be given a score of 1. Examples: walk, hit, speak, yell, phone, kiss, kick, run, ask, \ncross a street. \n  \n\u201cHe yelled at the police.\u201d \n  \nFor the previous example, then, the correct coding would be: \n\u201cProtesters  (P, NN) are simply marching for their rights (P, DAV)\u201d  \n\u201cProtesters  (P, NN) are destroying the economy (N, IAV)\u201d  \n\u201cProtesters  (P, NN) are well within their rights (P, ADJ), but are very disruptive  (N, \nADJ)\u201d \n\u201cProtesters  (P) parked along the street  (U, DAV)\u201d \n  \nUsing the 3rd sentence, this would be recorded in the coding sheet as (see coding sheet for \nclarification): \n Table A.1 \nExample Coding Spreadsheet   \nArticle Sentence Word or Phrase Score Valence \n  \n \n34 \n 1 Protesters are well within their \nrights but are very disruptive. Protesters 5 Positive  \n1 Protesters are well within their \nrights but are very disruptive. well within their rights 4 Positive \n1 Protesters are well within their \nrights but are very disruptive. disruptive 4 Negative \n  \nNote that you will extract each relevant sentence from each article, record the article \nnumber and sentence for EVERY word or phrase coded.  \n  \nFurther Distinctions  \n  \nWhen coding compound verbs, only code the verb that carries the meaning of the action. \n  \n\u201cHer mother was still impressed with her helpful behavior.\u201d \n\u2018Was\u2019 does not refer to an action and should not be coded. \u2018Impressed\u2019 refers to \nemotional consequence of action and should be coded as IAV. \n  \n\u201cThey went to do something pleasant.\u201d \n\u2018Went\u2019 is an auxiliary verb, has no meaning alone, and should not be coded. \u2018Do\u2019 has \nno meaning without \u2018something pleasant.\u2019 \u2018Pleasant\u2019 qualifies the action but does not \nmake it more concrete. So, code \u2018pleasant\u2019 as ADJ and \u2018do something\u2019 is IAV. \nNever code verbs that have no meaning if not used with another verb . Example verbs that are \nalways auxiliary and don\u2019t carry meaning alone: shall, will, should, could, would, can, might, \nmay. \n\u201cShe can take care of her mother who is ill.\u201d \nDo not code \u2018can.\u2019 Code \u2018take care\u2019 as IAV. \n  \n\u201cThey were just standing there and laughing.\u201d \nDo not code \u2018were.\u2019 Code \u2018laughing\u2019 and \u2018standing\u2019 as DAVs. \n  \n \n35 \n   \nQuantifiers are words like \u201calways,\u201d \u201cnever,\u201d \u201cmany,\u201d etc., that refer to a quantity. Quantifiers \nshould not be coded. \n  \n\u201cShe always helps those who are in need.\u201d \nDo not code \u2018always\u2019 \n\u201cHe talks a lot\u201d \nDo not code \u2018a lot\u2019 \n  \u201cHe negotiates very well\u201d \nDo not code \u2018very\u2019   \n  \nIn unusual cases such as metaphors, idioms, or other figurative expressions, you should refer to \nthe LCM Coding Manual section 2, General Classification Criteria, and 4, Coding Instructions, \nto verify your interpretation.  \n  \n\"Protesters are just standing up for their rights!\u201d  \n\u2018standing up for their rights\u2019 should not be interpreted literally as a DAV. \nInstead, it is figurative language and should be coded as an IAV. \n  \nSupplemental Definitions \n  \nSubject - The subject is the part of a sentence or clause that commonly indicates: (a) what the \nsentence is about or (b) who/what performs the action. The subject is typically a noun or \npronoun. Examples include: \n  \nJake never smiles. \n  \n  Genevieve  will return soon. \n  \nDoes Jake ever smile? \n  \n  \n \n36 \n Will Genevieve  return soon? \n \n[You] Come back here. \n  \nObject - The object  is the person/thing (typically a noun or pronoun) that: (a) receives the action \nand/or (b) is  affected by  the action. Examples include:  \n  \nI saw the film.  \n * film is the object, sensed by the subject seeing it.  \n  \nHe opened the door.  \n* Here the door is the direct object as it is the thing being affected by the verb to open. \n  \nI gave him the book.  \n* Here him (he) is the indirect object as he is the beneficiary of the action. \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Linguistic Bias in News Media on Anti-Pipeline Protests in Canada", "author": ["TD Christianson"], "pub_year": "2024", "venue": "NA", "abstract": "Protests give rise to social change, often advancing the rights of minority groups. However,  their success hinges on public opinion, which can be influenced by news media (eg,"}, "filled": false, "gsrank": 116, "pub_url": "https://harvest.usask.ca/items/d5f20947-575c-439a-bd66-1625fd5578ed", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:4Z5U3A8PgXcJ:scholar.google.com/&output=cite&scirp=115&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D110%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=4Z5U3A8PgXcJ&ei=GLWsaJ-LII6IieoP0sKRuAk&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:4Z5U3A8PgXcJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://harvest.usask.ca/bitstreams/05c4fda9-1c01-448f-bf99-aed91fe169ce/download"}}, {"title": "Attention-grabbing news coverage: Violent images of the Black Lives Matter movement and how they attract user attention on Reddit", "year": "2023", "pdf_data": "ZK[KF ZIN FZ\\OIS K\nFttoztt{z/r~klltzr zow\u20ac m{vo~kro> ^t{wozt\ntykro\u20ac {qtsoGwkmv Stvo\u20ac Tktto~ y{voyozt\nkzn s{w tsoy ktt~kmt u\u20aco~ kttoztt{z {zZonntt\n\\so~o\ufffdk Nozz. Vwt\ufffdo~ W{\ufffdorrk OJ\n*\nJo|k~\ufffdyoz\ufffd {qOzq{~yk\ufffdt{ z[\ufffd\ufffd\ufffdoy\ufffd kzn[{mtkw Uo\ufffd\ufffd{~v\ufffd. ]zt\ufffdo~\ufffdt\ufffd\ufffd {qGkylo~ r.Gkylo~r. Mo~yk z\ufffd\n*{wt\ufffdo~1| {\ufffdorrkE\ufffdz t/lkylo~r1no\nFl\u20act~kmt\nW{~\ufffd~k\ufffdkw\ufffd {q\ufffdt{wozmo k~om{yy{z tzm{z\ufffdoy|{~k~\ufffd yontk ~o|{~\ufffdtzr? \ufffdso\ufffd k\ufffd\ufffd~km\ufffd |\ufffdlwtm\nk\ufffd\ufffdoz\ufffdt{z kzntzqw\ufffdozmo \ufffdso~okno~)\ufffd {|tzt{z1 Oz\ufffdso|k~\ufffdtm\ufffdwk~ m{z\ufffdo\ufffd\ufffd {qk\ufffd{mtkw y{\ufffdoyoz\ufffd\n\ufffd\ufffdms k\ufffdGwkmv St\ufffdo\ufffd Tk\ufffd\ufffdo~ *GST+. \ufffdso|{~\ufffd~k\ufffdkw {q\ufffdt{wozmo tzzo\ufffd\ufffd m{\ufffdo~kro k\ufffd\ufffd~km\ufffd\ufffd |\ufffdlwtm\nk\ufffd\ufffdoz\ufffdt{z kznmkzkqqom\ufffd \ufffdsoy{\ufffdoyoz\ufffd)\ufffd no\ufffdow{|yoz\ufffd. \ufffd\ufffd||{~\ufffd. kzn|\ufffdlwtm |o~mo|\ufffdt{z1\nZo\ufffdok~ms {z\ufffdso~owk\ufffdt{z\ufffdst| lo\ufffd\ufffdooz ntrt\ufffdkw zo\ufffd\ufffd m{z\ufffdoz\ufffd qok\ufffd\ufffd~tzr \ufffdt{wozmo kzn\ufffd\ufffdo~\nk\ufffd\ufffdoz\ufffdt{z {z\ufffd{mtkw yontk sk\ufffdlooz \ufffdmk~mo1 \\st\ufffd |k|o~ kzkw\ufffd\ufffdo\ufffd \ufffdso~owk\ufffdt{z\ufffdst| lo\ufffd\ufffdooz\n\ufffdt{wozmo tz{zwtzo ~o|{~\ufffdtzr {zGST kznt\ufffd\ufffdoqqom\ufffd {z\ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {z\ufffdso\ufffd{mtkw yontk |wk\ufffd/\nq{~y Zonnt\ufffd1 \\so kzkw\ufffd\ufffdt\ufffd q{m\ufffd\ufffdo\ufffd {z\ufffdso|{~\ufffd~k\ufffdkw {q\ufffdt{wozmo tztykro\ufffd \ufffd\ufffdon tzGST/\n~owk\ufffdon ntrt\ufffdkw zo\ufffd\ufffd m{\ufffdo~kro \ufffdsk~on {zZonnt\ufffd1 \\so nk\ufffdk\ufffdo\ufffd t\ufffdm{y|~t\ufffdon {q9.<;6 zo\ufffd\ufffd\nk~\ufffdtmwo\ufffd \ufffdt\ufffds tykro\ufffd1 \\so mwk\ufffd\ufffdtqtmk\ufffdt{z {q\ufffdt{woz\ufffd tykro\ufffd t\ufffdlk\ufffdon {zk^MM4= m{z\ufffd{w\ufffd\ufffdt{zkw\nzo\ufffd~kw zo\ufffd\ufffd{~v *IUU+ \ufffd~ktzon {zkm{y|~osoz\ufffdt\ufffdo nk\ufffdk\ufffdo\ufffd1 \\so ~o\ufffd\ufffdw\ufffd\ufffd \ufffd\ufffdrro\ufffd\ufffd \ufffdsk\ufffd\ufffdsk\ufffd\n\ufffdtrztqtmkz\ufffdw\ufffd kqqom\ufffd\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z tzntrt\ufffdkw zo\ufffd\ufffd m{z\ufffdoz\ufffd t\ufffdz{\ufffd\ufffdsont\ufffd|wk\ufffd {q\ufffdt{wozmo tz\ntykro\ufffd? ~k\ufffdso~. t\ufffdt\ufffdzork\ufffdt\ufffdo k~\ufffdtmwo \ufffdt\ufffdwo\ufffd. \ufffdsozo\ufffd\ufffd {\ufffd\ufffdwo\ufffd)\ufffd |{wt\ufffdtmkw wokztzr\ufffd kznwo\ufffdow {qqkm/\n\ufffd\ufffdkw~o|{~\ufffdtzr. kzn|wk\ufffdq{~y kqq{~nkzmo\ufffd \ufffdsk\ufffd\ufffdtrztqtmkz\ufffdw\ufffd kqqom\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z1 \\s\ufffd\ufffd. \ufffdst\ufffd\n|k|o~ knn\ufffd \ufffd{\ufffdso\ufffdzno~\ufffd\ufffdkzntzr {q\ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z nt\ufffd\ufffd~tl\ufffd\ufffdt{z\ufffd {zwtzo kzn|k\ufffdo\ufffd \ufffdso\ufffdk\ufffd q{~\nq\ufffd\ufffd\ufffd~o ~o\ufffdok~ms tz\ufffdst\ufffdqtown1\nOz\ufffd~{n\ufffdm\ufffdt{z\nO\ufffdt\u20actznt\u20ac|\ufffd\ufffdklwo \ufffdsk\ufffd \ufffdd\ufffdfso yktz\u20ac\ufffd~oky kn{|\ufffdt{z {q\u20ac{mtkw yontk k||wtmk\ufffdt{z\u20ac sk\u20acmk\ufffd\u20acon k\n|k~kntry \u20acstq\ufffd tzs{\u00d0 |o{|wo m{yy\ufffdztmk\ufffdo. m{wwkl{~k\ufffdo. m~ok\ufffdo. kzn m{z\u20ac\ufffdyo tzq{~yk\ufffdt{z\ufffd\nd4f1\\st\u20ac |k~kntry \u20acstq\ufffd sk\u20ackw\u20ac{ kqqom\ufffdon \ufffdsom{z\u20ac\ufffdy|\ufffdt{z {qkzn m{zq~{z\ufffdk\ufffdt{z \u00d0t\ufffds zo\u00d0\u20ac d5f.\nk\u20ac\ufffd\u20aco~\u20ac k~otzm~ok\u20actzrw\u00de \ufffd~okntzr \ufffdsozo\u00d0\u20ac \ufffds~{\ufffdrs \u20ac{mtkw dyontkf |wk\ufffdq{~y\u20ac\ufffd d6f1J\ufffd~tzr \ufffdso\nwk\u20ac\ufffd\ufffdoz\u00deok~\u20ac. \u20ac{mtkw yontk |wk\ufffdq{~y\u20ac sk\ufffdo ~t\u20acoz \ufffd{{zo{q\ufffdsoy{\u20ac\ufffd |~{ytzoz\ufffd \u20ac{\ufffd~mo\u20ac q{~zo\u00d0\u20ac\nm{z\u20ac\ufffdy|\ufffdt{z d6.7f. \u00d0t\ufffds zok~w\u00de skwq {q\ufffdso]1[1 |{|\ufffdwk\ufffdt{z ~omot\ufffdtzr zo\u00d0\u20ac q~{y \u20ac{mtkw yontk\n\u00d0ol\u20act\ufffdo\u20ac tz5354 d9f1\\s\ufffd\u20ac. t\ufffdlom{yo\u20ac tzm~ok\u20actzrw\u00de ty|{~\ufffdkz\ufffd \ufffd{\ufffdzno~\u20ac\ufffdkzn s{\u00d0 zo\u00d0\u20ac k\ufffd\ufffd~km\ufffd\n\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z tzk\u20ac{mtkw yontk m{z\ufffdo\u00f0\ufffd \u20actzmo \ufffdsoo\u00f0|{\u20ac\ufffd~o \ufffd{zo\u00d0\u20ac \u20acsk~on {z\u20ac{mtkw yontk mkz\nsk\ufffdo \u20aco\ufffdo~o {qqwtzo m{z\u20aco}\ufffdozmo\u20ac d:f.kzn zo\u00d0\u20ac \u20acsk~on {zwtzo t\u20ackztz\ufffdor~kw |k~\ufffd {q\ufffdzno~\u20ac\ufffdkzn/\ntzr\ufffd{nk\u00de)\u20ac yontk \u20ac\u00de\u20ac\ufffdoy d;.<f1 \\so kzkw\u00de\u20act\u20ac {qzo\u00d0\u20ac \u20acsk~on {zwtzo sk\u20ac\ufffds\ufffd\u20ac lom{yo kz\nPLOS ONE\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 425=k4444444444\nk4444444444\nk4444444444\nk4444444444\nk4444444444\nOPEN ACCESS\nIt\ufffdk\ufffdt{z> Nozz \\.W{\ufffdorrk V*5356+ F\ufffd\ufffdoz\ufffdt{z/\nr~klltzr zo\ufffd\ufffd m{\ufffdo~kro> ^t{woz\ufffd tykro\ufffd {q\ufffdso\nGwkmv St\ufffdo\ufffd Tk\ufffd\ufffdo~ y{\ufffdoyoz\ufffd kzns{\ufffd\ufffdso\ufffdk\ufffd\ufffd~km\ufffd\n\ufffd\ufffdo~k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd1 WS{[ VUK4<*<+>\no35<<=:51 s\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1\n|{zo135<<=: 5\nKnt\ufffd{~> Lklt{ [k~kmm{. )Kz~tm{ Lo~yt) Zo\ufffdok~m s\nIoz\ufffdo~. O\\FSb\nZomot\ufffdon> Q\ufffdw\ufffd47.5355\nFmmo|\ufffdon> Q\ufffdw\ufffd:.5356\nW\ufffdlwt\ufffdson> F\ufffdr\ufffd\ufffd\ufffd =.5356\nI{|\ufffd~trs\ufffd> \u00a95356 Nozz. W{\ufffdorrk1 \\st\ufffdt\ufffdkz{|oz\nkmmo\ufffd\ufffd k~\ufffdtmwo nt\ufffd\ufffd~tl\ufffd\ufffdon \ufffdzno~ \ufffdso\ufffdo~y\ufffd {q\ufffdso\nI~ok\ufffdt\ufffdo I{yy{z\ufffd F\ufffd\ufffd~tl\ufffd\ufffdt{z Stmoz\ufffdo. \ufffdstms\n|o~yt\ufffd\ufffd \ufffdz~o\ufffd\ufffd~tm\ufffdo n\ufffd\ufffdo.nt\ufffd\ufffd~tl\ufffd \ufffdt{z.kzn\n~o|~{n\ufffdm\ufffdt{z tzkz\ufffdyont\ufffdy. |~{\ufffdtnon \ufffdso{~trtzkw\nk\ufffd\ufffds{~ kzn\ufffd{\ufffd~mo k~om~ont\ufffdon1\nJk\ufffdk F\ufffdktwkltwt\ufffd \ufffd[\ufffdk\ufffdoyoz\ufffd> \\som{y|wo\ufffdo\n{\ufffdo~\ufffdto\ufffd {q\ufffdsonk\ufffdk\ufffd\ufffdon tz\ufffdst\ufffd\ufffd\ufffd\ufffdn\ufffd t\ufffd|~{\ufffdtnon\ntz\ufffdsonk\ufffdkk\ufffdktwkltwt\ufffd\ufffd \ufffd\ufffdk\ufffdoyoz\ufffd tzmw\ufffdnon tz\ufffdst\ufffd\n\ufffd\ufffdlyt\ufffd\ufffdt{z 1\\sonk\ufffdk\ufffd\ufffdon tz\ufffdst\ufffd\ufffd\ufffd\ufffdn\ufffd m{y|~t\ufffdo\ufffd\n\ufffds~oo |k~\ufffd\ufffd> 41Oykro nk\ufffdk> #]ISF W~{\ufffdo\ufffd\ufffd Oykro\nJk\ufffdk\ufffdo\ufffd# *\ufffd~ktztzr nk\ufffdk+ \\sonk\ufffdk\ufffdo\ufffd t\ufffdk\ufffdktwklwo\nq~{y \ufffdso{~trtzkw m\ufffd~k\ufffd{~\ufffd {q\ufffdso#]ISF W~{\ufffdo\ufffd\ufffd\nOykro Jk\ufffdk\ufffdo\ufffd# d4f1Fwwtzq{~yk\ufffdt{z \ufffd{{l\ufffdktz kzn\n|~o|k~o \ufffdsonk\ufffdk\ufffdo\ufffd mkzlo{l\ufffdktzon q~{y \ufffdsot~\n|\ufffdlwtm Mt\ufffdN\ufffdl ~o|{\ufffdt\ufffd{~\ufffd d5f151Oykro nk\ufffdk> \\o\ufffd\ufffd\nnk\ufffdk\ufffd{o\ufffdkw\ufffdk\ufffdo \ufffdso|o~q{~yk zmo{q\ufffdsotykro\nmwk\ufffd\ufffdtqto~ \\sonk\ufffdkmkzz{\ufffd lo\ufffdsk~on |\ufffdlwtmw\ufffd\no\u20ac\u20acoz\ufffdtkw |~om\ufffd~\u20ac{~ \ufffd{ty|~{\ufffdtzr {\ufffd~\ufffdzno~\u20ac\ufffdkzntzr {qs{\u00d0 \u20ac{mtkw yontk zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z\ntzqw\ufffdozmo\u20ac \ufffdmt\ufffdtm k\u00d0k~ozo\u20ac\u20ac kzn ozrkroyoz\ufffd tzmt\ufffdtm kzn |{wt\ufffdtmkw wtqo\ufffd d=f1\n_t\ufffds \ufffdst\u20ac|k|o~. \u00d0okty \ufffd{m{z\ufffd~tl\ufffd\ufffdo \ufffd{\ufffdst\u20acwtzo{q~o\u20acok~ms l\u00dekzkw\u00de\u00fetzr s{\u00d0 \ufffdsoviolent\nm{\ufffdo~kro {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac kqqom\ufffd\u20ac \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {z\u20ac{mtkw yontk1 \\so |{~\ufffd~k\u00dekw {q\ufffdt{wozmo\ntz\ufffd~knt\ufffdt{zkw yontk \ufffd\u00de|o\u20ac \u20ac\ufffdms k\u20ac\ufffd\ufffdowo\ufffdt\u20act{z. ~knt{ zo\u00d0\u20ac|k|o~\u20ac. ykrk\u00fetzo\u20ac 444{~tz{\ufffdso~\n\u00d0{~n\u20ac. kz\u00deq{~y {qyk\u20ac\u20ac m{yy\ufffdztmk\ufffdt{z k\ufffdktwklwo loq{~o \ufffdsokn\ufffdoz\ufffd {qntrt\ufffdkw yontk\ufffd d43f sk\u20ac\nlooz \u20ac\ufffd\ufffdnton \ufffds{~{\ufffdrsw\u00de d44.45f1 Zo\u20acok~ms qtzn\u20ac \ufffdsk\ufffd \ufffd~knt\ufffdt{zkw yontk q~o}\ufffdoz\ufffdw\u00de qok\ufffd\ufffd~o \ufffdt{/\nwoz\ufffd m{z\ufffdoz\ufffd k\u20ack\u00d0k\u00de {qoz\ufffdo~\ufffdktztzr \ufffdsot~ k\ufffdntozmo\u20ac kzn. \ufffds\ufffd\u20ac. k\ufffd\ufffd~km\ufffdtzr |\ufffdlwtm k\ufffd\ufffdoz\ufffdt{z d44\u02d8\n46f. \u00d0stms \u00detown\u20ac r~ok\ufffdo~ ~o\ufffdoz\ufffdo\u20ac d47.49f1 O\ufffd~oyktz\u20ac \ufffdzmo~\ufffdktz. \ufffds{\ufffdrs. \u00d0so\ufffdso~ \ufffdst\u20acwtzv\nlo\ufffd\u00d0ooz \ufffdso|{~\ufffd~k\u00dekw {q\ufffdt{wozmo kzn \ufffdsok\ufffd\ufffd~km\ufffdt{z {qk\ufffd\ufffdoz\ufffdt{z mkzkw\u20ac{ lo\ufffd~kz\u20acqo~~on \ufffd{\ufffdso\n{zwtzo \u20ac|so~o1 Ozt\ufffdtkw kzkw\u00de\u20aco\u20ac m{zmw\ufffdnon \ufffdsk\ufffd \u20acsk~tzr tykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo l\u00detznt\ufffdtn\ufffdkw\n\ufffd\u20aco~\u20ac {z\u20ac{mtkw yontk ntnz{\ufffdwokn \ufffd{r~ok\ufffdo~ \ufffd\u20aco~ ozrkroyoz\ufffd d4:.4;f. l\ufffd\ufffd\ufffdsooqqom\ufffd\u20ac {q{zwtzo\nzo\u00d0\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo {z\u20ac{mtkw yontk \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z ~oyktz \ufffdzmwok~1 \\so~oq{~o. \u00d0o\u20acoo\ufffdso\nzoon \ufffd{q\ufffd~\ufffdso~ {\ufffd~\ufffdzno~\u20ac\ufffdkzntzr {q\ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdt{wozmo qok\ufffd\ufffd~on tz\ufffdsontrt\ufffdkw\nzo\u00d0\u20ac m{z\ufffdoz\ufffd \u20acsk~on {z\u20ac{mtkw yontk |wk\ufffdq{~y\u20ac kzn t\ufffd\u20acoqqom\ufffd\u20ac {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1\n\\{knn~o\u20ac\u20ac \ufffdst\u20ac~o\u20acok~ms rk|. \u00d0okzkw\u00de\u00feo \ufffdso|{~\ufffd~k\u00dekw {z\u20ac{mtkw yontk {q\ufffdso\u20ac{mtkw y{\ufffdo/\nyoz\ufffd Gwkmv St\ufffdo\u20ac Tk\ufffd\ufffdo~ *GST+ kzn s{\u00d0 \ufffdsk\ufffd k\ufffd\ufffd~km\ufffd\u20ac \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 Fmm{~ntzr \ufffd{Jtkzt d4<f.\nky{\ufffdoyoz\ufffd mkzlonoqtzon k\u20ack\u20ac{mtkw y{\ufffdoyoz\ufffd tqt\ufffd)\u20aclk\u20acon {z\ufffdzo\ufffd\u00d0{~v\u20ac {qtzq{~ykw tz\ufffdo~/\nkm\ufffdt{z\u20ac lo\ufffd\u00d0ooz k|w\ufffd~kwt\ufffd\u00de {qtznt\ufffdtn\ufffdkw\u20ac. r~{\ufffd|\u20ac kzn2{~ {~rkzt\u20ack\ufffdt{z\u20ac. ozrkron tzk|{wt\ufffdtmkw\nkzn2{~ m\ufffdw\ufffd\ufffd~kw m{zqwtm\ufffd. {z\ufffdsolk\u20act\u20ac {qk\u20acsk~on m{wwom\ufffdt\ufffdo tnoz\ufffdt\ufffd\u00de1\ufffd _omsk~km\ufffdo~t\u00feo GST k\u20ack\n\u20ac{mtkw y{\ufffdoyoz\ufffd lomk\ufffd\u20aco t\ufffdt\u20acknomoz\ufffd~kwt\u00feon \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {qzo\ufffd\u00d0{~von tznt\ufffdtn\ufffdkw\u20ac d4=f qtrs\ufffdtzr\nq{~|{wt\ufffdtmkw. \u20ac\ufffd~\ufffdm\ufffd\ufffd~kw. kzn m\ufffdw\ufffd\ufffd~kw mskzro d4=f \u00d0stwo m{wwom\ufffdt\ufffdow\u00de tnoz\ufffdtq\u00detzr kzn {~rkzt\u00fetzr\n\ufffdzno~ \ufffdso\ufffdyl~owwk {q\u20ac\u00deyl{w\u20ac \u20ac\ufffdms k\u20ac\ufffdsosk\u20acs\ufffdkr $GwkmvSt\ufffdo\u20acTk\ufffd\ufffdo~ d53f1\n\\so GST y{\ufffdoyoz\ufffd lorkz \u00d0t\ufffds k\u20ac{mtkw yontk sk\u20acs\ufffdkr kq\ufffdo~ \ufffdsokm}\ufffdt\ufffd\ufffdkw {q\ufffdsoykz\nmsk~ron tz\ufffdso\u20acs{{\ufffdtzr nok\ufffds {qGwkmv \ufffdoozkro~ \\~k\u00de\ufffd{z Tk~\ufffdtz tzLw{~tnk tz5345 d54f. r~o\u00d0\nzk\ufffdt{zkww\u00de tz5347 kq\ufffdo~ \ufffdsonok\ufffds\u20ac {qTtmskow G~{\u00d0z tzTt\u20ac\u20ac{\ufffd~t kzn K~tm Mk~zo~ tzUo\u00d0\nb{~v d4=f. kzn \u00d0k\u20ac~otrzt\ufffdon l\u00de\ufffdsonok\ufffds {qMo{~ro Lw{\u00den. kGwkmv ykz y\ufffd~no~on l\u00dek\u00d0st\ufffdo\n|{wtmo {qqtmo~ {zTk\u00de 59.5353. tzTtzzok|{wt\u20ac d54f1 Wo{|wo kww{\ufffdo~ \ufffdso\u00d0{~wn \u00d0oz\ufffd tz\ufffd{ \ufffdso\n\u20ac\ufffd~oo\ufffd\u20ac \ufffd{\u20acs{\u00d0 \u20ac{wtnk~t\ufffd\u00de kzn u{tz \ufffdsoy{\ufffdoyoz\ufffd)\u20ac qtrs\ufffd krktz\u20ac\ufffd \ufffd~kmtkw tzu\ufffd\u20ac\ufffdtmo kzn |{wtmo l~\ufffd/\n\ufffdkwt\ufffd\u00de\ufffd d54f1\n_okzkw\u00de\u00feo \ufffdsozo\u00d0\u20ac m{\ufffdo~kro {q\ufffdst\u20ac\u20ac|omtqtm \u20ac{mtkw y{\ufffdoyoz\ufffd q{~\ufffd\u00d0{~ok\u20ac{z\u20ac1 Lt~\u20ac\ufffd. \ufffdso\nGST y{\ufffdoyoz\ufffd rktzon km{z\u20actno~klwo ky{\ufffdz\ufffd {qyontk k\ufffd\ufffdoz\ufffdt{z \ufffdsk\ufffd \ufffdnowort\ufffdtyt\u00feon kzn\n~kmtkwt\u00feon \ufffdsoy{\ufffdoyoz\ufffd l\u00dekmmoz\ufffd\ufffdk\ufffdtzr m{zqwtm\ufffd kzn \ufffdt{wozmo\ufffd d55f. \u00d0stms kwtrz\u20ac \u00d0t\ufffds kz\no\u20ac\ufffdklwt\u20acson wtzo{q~o\u20acok~ms \ufffdsk\ufffd \u20ac\ufffd~o\u20ac\u20aco\u20ac \ufffdsk\ufffd yontk m{\ufffdo~kro {q\ufffdoz q{m\ufffd\u20aco\u20ac {z\ufffdt{woz\ufffd kzn nt\u20ac/\n~\ufffd|\ufffdt\ufffdo k\u20ac|om\ufffd\u20ac {qky{\ufffdoyoz\ufffd)\u20ac |~{\ufffdo\u20ac\ufffd ~k\ufffdso~ \ufffdskz t\ufffd\u20acr{kw\u20ac kzn \u20ac{mtkw m~t\ufffdtmt\u20acy d55\u02d859f1 [tzmo\n|\ufffdlwtm {|tzt{z kzn \u20ac\ufffd||{~\ufffd {qk\u20ac{mtkw y{\ufffdoyoz\ufffd no|ozn strsw\u00de {zs{\u00d0 \ufffdsk\ufffd y{\ufffdoyoz\ufffd t\u20ac\n|{~\ufffd~k\u00deon tzzo\u00d0\u20ac ~o|{~\ufffdtzr d5:\u02d85<f. o\u20ac|omtkww\u00de \u00d0soz \ufffdt{wozmo t\u20actz\ufffd{w\ufffdon d56f. t\ufffdt\u20ac|k~\ufffdtm\ufffdwk~w\u00de\ntz\ufffdo~o\u20ac\ufffdtzr \ufffd{kzkw\u00de\u00feo \ufffdsozo\u00d0\u20ac |{~\ufffd~k\u00dekw {q\ufffdsoGST y{\ufffdoyoz\ufffd. k\u20acl{\ufffds |~{\ufffdo\u20ac\ufffd{~\u20ac kzn |{wtmo\nsk\ufffdo m{yyt\ufffd\ufffdon km\ufffd\u20ac {q\ufffdt{wozmo d5=f1 [om{zn. \ufffdsoGST y{\ufffdoyoz\ufffd \ufffdsk\u20ac noo| \ufffdto\u20ac\ufffd{\u20ac{mtkw\nyontk\ufffd d54f. \u00d0t\ufffds sk\u20acs\ufffdkr\u20ac \u20ac\ufffdms k\u20ac$GwkmvSt\ufffdo\u20acTk\ufffd\ufffdo~ \u20ac|k~vtzr m{z\ufffd~{\ufffdo~\u20actkw {zwtzo nt\u20acm\ufffd\u20ac/\n\u20act{z\u20ac kzn q\ufffdowtzr \u00d0{~wn\u00d0tno |~{\ufffdo\u20ac\ufffd\u20ac kzn |{wt\ufffdtmkw \ufffdz~o\u20ac\ufffd d54f1 \\so m{z\u20aco}\ufffdozmo {q\ufffdso|\ufffdlwtm\nlotzr n~k\u00d0z \ufffd{\ufffdt{woz\ufffd yontk m{z\ufffdoz\ufffd {zwtzo m{\ufffdwn lokzork\ufffdt\ufffdo |\ufffdlwtm ltk\u20ac \ufffd{\u00d0k~n \ufffdsoy{\ufffdo/\nyoz\ufffd. \u00d0stms yk\u00de o\u20acmkwk\ufffdo \ufffdso\ufffdoz\u20aco |{wt\ufffdtmkw \u20act\ufffd\ufffdk\ufffdt{z \u20ac\ufffd~~{\ufffdzntzr \ufffdsk\ufffd y{\ufffdoyoz\ufffd d5=f1\nOz|k~\ufffdtm\ufffdwk~. \u00d0oo\u00f0kytzo \ufffdsooqqom\ufffd {qtykro\u20ac \ufffdsk\ufffd no|tm\ufffd \ufffdt{wozmo kzn z{z\ufffdt{wozmo kzn k~o\n\ufffd\u20acon tzzo\u00d0\u20ac k~\ufffdtmwo\u20ac \u20acsk~on {z\ufffdso\u20ac{mtkw yontk |wk\ufffdq{~y Zonnt\ufffd. k\u20actykro\u20ac |wk\u00de k\u20actrztqtmkz\ufffd\n~{wo tzs{\u00d0 zo\u00d0\u20ac k~\ufffdtmwo\u20ac \u20acsk|o \ufffd\ufffdso |\ufffdlwtm)\u20ac \ufffdzno~\u20ac\ufffdkzntzr {qt\u20ac\u20ac\ufffdo\u20ac kzn o\ufffdoz\ufffd\u20ac\ufffd d63f *q{~ k\ny{~o no\ufffdktwon no\u20acm~t|\ufffdt{z {q\u20ac\ufffdl~onnt\ufffd\u20ac kzn \ufffdso\ufffd\u00de|o\u20ac {q\u20ac\ufffdlyt\u20ac\u20act{z \u00d0okzkw\u00de\u00feo. \u20acoo\u20acom\ufffdt{z\n\ufffd[{mtkw yontk |wk\ufffdq{~y Zonnt\ufffd\ufffd+1 \\so\u20aco tykro\u20ac k~oot\ufffdso~ |s{\ufffd{\u20ac {~\u20ac\ufffdtwwtykro\u20ac q~{y \ufffdtno{\u20ac\n\ufffdsk\ufffd k~o|k~\ufffd {q\ufffdsozo\u00d0\u20ac k~\ufffdtmwo\u20ac wtzvon tz\u20ac\ufffdlyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon {zZonnt\ufffd *sozmoq{~\ufffds. \u00d0o~oqo~\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 525=lomk\ufffd\ufffdo {qm{|\ufffd~trs\ufffd t\ufffd\ufffd\ufffdo\ufffd1 _o|~{\ufffdtno k\nm{y|wo\ufffdo no\ufffdm~t|\ufffd t{z{qs{\ufffd\ufffd{~om~ok\ufffdo \ufffdsonk\ufffdk\ufffdo\ufffd\n\ufffd\ufffdtzr |\ufffdlwtmw\ufffd k\ufffdktwklwo ~o\ufffd{\ufffd~mo\ufffd kzn\ufffdso]ISF\nW~{\ufffdo\ufffd\ufffd Oykro Jk\ufffdk\ufffdo \ufffdtz\ufffdsonk\ufffdkk\ufffdktwkltw t\ufffd\ufffd\n\ufffd\ufffdk\ufffdoyoz\ufffd1 61Uo\ufffd\ufffdT\\[I nk\ufffdk\\sonk\ufffdk\ufffdo\ufffd t\ufffd\nk\ufffdktwklwo q~{y N\ufffdrrtzr Lkmo d6.7f171Zonnt\ufffd nk\ufffdk>\nZonnt\ufffd \ufffd\ufffdlyt\ufffd\ufffdt{z\ufffd kzn\ufffdsoqtzkwnk\ufffdk\ufffdo\ufffd \\so\n|~tyk~\ufffd nk\ufffdk\ufffdo\ufffd \ufffdzno~w\ufffdtzr {\ufffd~y{now\ufffd t\ufffdk\ufffdktwklwo\n\ufffdtkV[L*s\ufffd\ufffd|\ufffd>22{\ufffd q1t{27n~5\ufffd2D\ufffdto \ufffdi{zw\ufffdB\n6=qq9ml6= m597l:m=6o l45q=m539k=74 +q{~|oo~\n~o\ufffdto\ufffd |\ufffd~|{\ufffdo\ufffd kzn\ufffdtwwloykno |\ufffdlwtmw\ufffd k\ufffdktwklwo\ntzmk\ufffdo {qkmmo|\ufffdkzm o1d4f_{z J.[\ufffdotzo~\ufffd/\n\\s~owvown cI.Q{{Q1W~{\ufffdo\ufffd\ufffd km\ufffdt\ufffdt\ufffd\ufffd no\ufffdom\ufffdt{z kzn\n|o~mot\ufffdon \ufffdt{wozmo o\ufffd\ufffdtyk\ufffdt{z q~{y \ufffd{mtkw yontk\ntykro\ufffd1 TT534; /W~{m1 534; FIT T\ufffdw\ufffdtyon1\nI{zq1. 534;1 s\ufffd\ufffd|\ufffd>22n{ t1{~r24314479264 565::1\n64565<51 d5fs\ufffd\ufffd|\ufffd>22rt\ufffds\ufffd l1m{y2\ufffd{zn{z rs\ufffdo{z2\n|~{\ufffdo\ufffd\ufffd/no\ufffdo m\ufffdt{z/\ufffdt{wozm o/o\ufffd\ufffdtyk\ufffdt{z d6fNkyl{~ r\nL.J{zzk\ufffd R1Uo\ufffd\ufffdT\\[I> knk\ufffdk\ufffdo\ufffd q{~*y\ufffdw\ufffdt/+\n\ufffdk~ro\ufffd/no|o znoz\ufffd \ufffdoz\ufffdtyoz\ufffd mwk\ufffd\ufffdtqtmk \ufffdt{ztz\n|{wt\ufffdtmkw zo\ufffd\ufffd k~\ufffdtmwo\ufffd 1W~{moontzr \ufffd{q\ufffdso4:\ufffds\nI{zqo~ozm o{q\ufffdsoK\ufffd~{|okz Isk|\ufffdo~ {q\ufffdso\nF\ufffd\ufffd{mtk\ufffdt{z q{~I{y|\ufffd\ufffdk\ufffdt{zk wStzr\ufffdt\ufffd\ufffdtm\ufffd1\n53541 ||14::6\u02d84:;9 1n{t>43194: ;2\ufffd\ufffds/53;4<6 d7f\nUo\ufffd\ufffdT\\[ Ink\ufffdk\ufffdo\ufffd 1Oz>N\ufffdrrtzr Lkmo1 5355 dmt\ufffdon\n:Q\ufffdz5356f1 F\ufffdktwklwo> s\ufffd\ufffd|\ufffd>22s\ufffdrrtzr qkmo1m{2\nnk\ufffdk\ufffdo\ufffd\ufffd2q skyl{~r2zo\ufffd \ufffdi\ufffdoz\ufffdtyoz\ufffd izo\ufffd\ufffdy\ufffd\ufffdm 1\nL\ufffdzntzr> \\sok\ufffd\ufffds{~*\ufffd+ ~omot\ufffdon z{\ufffd|omtqtm\nq\ufffdzntzr q{~\ufffdst\ufffd\ufffd{~v1\nI{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd >\\sok\ufffd\ufffds{~\ufffd sk\ufffdo nomwk~on\n\ufffdsk\ufffdz{m{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd o\ufffdt\ufffd\ufffd1\n\ufffd{l{\ufffds k\u20ac\ufffdtykro\u20ac\ufffd+1 \\so\u20aco wtzvon zo\u00d0\u20ac k~\ufffdtmwo\u20ac k~oot\ufffdso~ s{\u20ac\ufffdon l\u00de\ufffdsontrt\ufffdkw o\u00f0\ufffdoz\u20act{z {q\n\ufffd~knt\ufffdt{zkw yontk q{~yk\ufffd\u20ac. \u20ac\ufffdms k\u20ac{z\ufffdso\u00d0ol\u20act\ufffdo {q\ufffdsoNewYorkTimes zo\u00d0\u20ac|k|o~ {~k~o\ns{\u20ac\ufffdon l\u00dentrt\ufffdkw/l{~z yontk. \u20ac\ufffdms k\u20aclw{r\u20ac {~|\ufffd~o {zwtzo zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac d64.65f1\nF\u20act\ufffdt\u20ac\ufffdzmwok~ \u00d0so\ufffdso~ ok~wto~ qtzntzr\u20ac q~{y yontk ~o\u20acok~ms mkzlo\ufffd~kz\u20acqo~~on \ufffd{\u20ac{mtkw\nyontk oz\ufffdt~{zyoz\ufffd\u20ac d66f. \u00d0oq{m\ufffd\u20ac z{\ufffd{zw\u00de {z\ufffdsooqqom\ufffd\u20ac {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {qtykro\u20ac qok\ufffd\ufffd~/\ntzr\ufffdt{wozmo l\ufffd\ufffdkw\u20ac{ o\ufffdkw\ufffdk\ufffdo \ufffdsoty|km\ufffd {q{\ufffdso~ k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q\u20acsk~on ntrt\ufffdkw zo\u00d0\u20ac m{z\ufffdoz\ufffd \ufffdsk\ufffd\n~o\u20acok~ms sk\u20ac\u20acs{\u00d0z \ufffd{lo\u20actrztqtmkz\ufffd |~ontm\ufffd{~\u20ac {q\ufffd\u20aco~ ozrkroyoz\ufffd *q{~ y{~o tzq{~yk\ufffdt{z. \u20acoo\n\u20acom\ufffdt{z \ufffd\\so{~\u00de kzn s\u00de|{\ufffdso\u20aco\u20ac\ufffd+1 _o\u20ac\ufffd~\ufffdm\ufffd\ufffd~o \ufffdso\u20aco k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac tz\ufffd{ \ufffds~oo mk\ufffdor{~to\u20ac> *4+k\ufffd\ufffd~t/\nl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy *tz{\ufffd~mk\u20aco. \ufffdso\u20ac\ufffdlyt\u20ac\u20act{z qok\ufffd\ufffd~tzr kwtzvon zo\u00d0\u20ac k~\ufffdtmwo+.\n\u20ac\ufffdms k\u20ac\ufffdso\u20acoz\ufffdtyoz\ufffd o\u00f0|~o\u20ac\u20acon tzkzo\u00d0\u20ac k~\ufffdtmwo)\u20ac \ufffdt\ufffdwo? *5+k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q\ufffdsozo\u00d0\u20ac |~{\ufffdtno~ *tz\n{\ufffd~mk\u20aco. \ufffdsontrt\ufffdkw o\u00f0\ufffdoz\u20act{z {q\ufffd~knt\ufffdt{zkw yontk q{~yk\ufffd\u20ac {~ntrt\ufffdkw/l{~z zo\u00d0\u20ac yontk+. \u20ac\ufffdms\nk\u20ac\ufffdso{\ufffd\ufffdwo\ufffd)\u20ac |{wt\ufffdtmkw wokztzr\u20ac {~wo\ufffdow {qqkm\ufffd\ufffdkw ~o|{~\ufffdtzr? kzn *6+k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac m{zmo~ztzr \ufffdso\nm{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn |wk\ufffdq{~y kqq{~nkzmo\u20ac {q\ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac kzkw\u00de\u00feon. \u20ac\ufffdms k\u20ac\ufffdsoqwkrrtzr {q\n\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffdsk\ufffd \ufffdt{wk\ufffdo \u20ac\ufffdlyt\u20ac\u20act{z r\ufffdtnowtzo\u20ac1 G\u00dem{z\u20actno~tzr \ufffdst\u20acy\ufffdw\ufffdt\ufffd\ufffdno {qk\ufffd\ufffd~tl\ufffd\ufffdo\u20ac \ufffdsk\ufffd\nmkzkqqom\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. {\ufffd~kzkw\u00de\u20act\u20ac kmm{\ufffdz\ufffd\u20ac q{~\ufffdsom{y|wo\u00f0t\ufffd\u00de {q\u20ac{mtkw yontk wkzn\u20acmk|o\u20ac.\n\u00d0t\ufffds \ufffdsot~ \ufffdk~t{\ufffd\u20ac. y\ufffd\ufffd\ufffdkww\u00de no|oznoz\ufffd owoyoz\ufffd\u20ac d4f1\nF\u20ac{\ufffd~{luom\ufffdt\ufffdo t\u20ac\ufffd{ow\ufffdmtnk\ufffdo \u00d0so\ufffdso~ \ufffdso|{~\ufffd~k\u00dekw {q\ufffdt{wozmo {~{\ufffdso~ k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {qntrt/\n\ufffdkwzo\u00d0\u20ac m{z\ufffdoz\ufffd \u20acsk~on {zZonnt\ufffd sk\ufffdo k\u20actrztqtmkz\ufffd ty|km\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. \u00d0o|{\u20aco \ufffdsoq{w/\nw{\u00d0tzr \ufffd\u00d0{~o\u20acok~ms }\ufffdo\u20ac\ufffdt{z\u20ac \u20ac|omtqtm \ufffd{GST. \u00d0stms t\u20ac\ufffdso\u20ac{mtkw y{\ufffdoyoz\ufffd {z\u00d0stms \u00d0o\nq{m\ufffd\u20ac tz{\ufffd~kzkw\u00de\u20act\u20ac>\nRQ1>Howdoesthevisualportrayal ofviolenceinBLM-related newsarticlessharedonReddit\naffectuserattentionD\nRQ2>Howdootherattributes ofdigitalBLM-related newscontentsharedonRedditimpactuser\nattentionD\n\\s\ufffd\u20ac. {\ufffd~|k|o~ m{z\ufffd~tl\ufffd\ufffdo\u20ac \ufffd{\ufffdso\ufffdzno~\u20ac\ufffdkzntzr {q\ufffdsowtzv lo\ufffd\u00d0ooz \ufffdso\ufffd\u00de|o {q{zwtzo\nzo\u00d0\u20ac m{\ufffdo~kro *\ufffdt{woz\ufffd kzn z{z\ufffdt{woz\ufffd+ {qk|{|\ufffdwk~ \u20ac{mtkw y{\ufffdoyoz\ufffd d5=f kzn \ufffdsok\ufffd\ufffdoz\ufffdt{z\n|ktn \ufffd{t\ufffd{z\ufffdso\u20ac{mtkw yontk |wk\ufffdq{~y Zonnt\ufffd1 G\u00dekzkw\u00de\u00fetzr \u20aco\ufffdo~kw k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q{zwtzo zo\u00d0\u20ac\n~o|{~\ufffdtzr \ufffdsk\ufffd ty|km\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. {\ufffd~\u00d0{~v z{\ufffd{zw\u00de \ufffdo\u20ac\ufffd\u20ac \ufffdsooqqom\ufffd {qtykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{/\nwozmo {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z l\ufffd\ufffdkw\u20ac{ kmm{\ufffdz\ufffd\u20ac q{~k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy. zo\u00d0\u20ac |~{\ufffdtno~.\nkzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn |wk\ufffdq{~y kqq{~nkzmo\u20ac \ufffdsk\ufffd ytrs\ufffd tzqw\ufffdozmo \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 [tzmo\nzo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z \ufffds~{\ufffdrs \u20ac{mtkw yontk m{z\ufffdtz\ufffdo\u20ac \ufffd{r~{\u00d0 d6.7f. \ufffdst\u20ac\u00d0{~v m{z\ufffd~tl\ufffd\ufffdo\u20ac \ufffd{\ufffdso\n\ufffdzno~\u20ac\ufffdkzntzr {qzo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z tzkztzm~ok\u20actzrw\u00de ntrt\ufffdt\u00feon \u00d0{~wn1\n\\st\u20ac |k|o~ t\u20ac\u20ac\ufffd~\ufffdm\ufffd\ufffd~on k\u20acq{ww{\u00d0\u20ac1 Lt~\u20ac\ufffd. \u00d0ol~toqw\u00de \u20ac\ufffdyyk~t\u00feo \ufffdsoyktz \u20ac\ufffdo|\u20ac kzn qtzntzr\u20ac\n{q\ufffdso~o\u20acok~ms \ufffd{strswtrs\ufffd {\ufffd~\u20ac\ufffd\ufffdn\u00de)\u20ac m{z\ufffd~tl\ufffd\ufffdt{z1 [om{zn. \u00d0ont\ufffdo noo|o~ tz\ufffd{ |~o\ufffdt{\ufffd\u20ac\n~o\u20acok~ms kzkw\u00de\u00fetzr \ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz zo\u00d0\u20ac m{\ufffdo~kro {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac kzn k\ufffd\ufffdoz\ufffdt{z\nnt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac \u00d0stwo ntqqo~oz\ufffdtk\ufffdtzr lo\ufffd\u00d0ooz \ufffd~knt\ufffdt{zkw. ntrt\ufffdkw. kzn \u20ac{mtkw yontk1 \\st~n. \u00d0o\n|~o\u20acoz\ufffd {\ufffd~\ufffdso{~o\ufffdtmkw lkmvr~{\ufffdzn kzn s\u00de|{\ufffdso\u20aco\u20ac tzno\ufffdktw. r~{\ufffdznon tz\ufffdso\ufffdzork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac\ufffd\nkzn \ufffdso\ufffd|tm\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd1\ufffd L{\ufffd~\ufffds. \u00d0ono\ufffdktw {\ufffd~yo\ufffds{n{w{r\u00de. tzmw\ufffdntzr \ufffdso{|o~k\ufffdt{/\nzkwt\u00fek\ufffdt{z {q{\ufffd~vo\u00de\ufffdk~tklwo\u20ac. kno\u20acm~t|\ufffdt{z {q{\ufffd~nk\ufffdk m{wwom\ufffdt{z {zZonnt\ufffd. kzn \ufffdso\ufffd~kz\u20acqo~\nwok~ztzr kzn |o~q{~ykzmo {q\ufffdso^MM4= m{z\ufffd{w\ufffd\ufffdt{zkw zo\ufffd~kw zo\ufffd\u00d0{~v *IUU+ \ufffdsk\ufffd \u00d0o\ufffd~ktzon\n\ufffd{mwk\u20ac\u20actq\u00de \ufffdt{wozmo tztykro\u20ac1 Fq\ufffdo~ m{zn\ufffdm\ufffdtzr {\ufffd~nk\ufffdk kzkw\u00de\u20act\u20ac. \u00d0ont\u20acm\ufffd\u20ac\u20ac {\ufffd~qtzntzr\u20ac.\nstrswtrs\ufffd \ufffdsowtyt\ufffdk\ufffdt{z\u20ac {q{\ufffd~\u00d0{~v. kzn |~{\ufffdtno kz{\ufffd\ufffdw{{v q{~q\ufffd\ufffd\ufffd~o ~o\u20acok~ms1\n[\ufffdyyk~\ufffd {qyktz \ufffd\ufffdo|\ufffd kzn qtzntzr\ufffd\n\\so |k|o~)\u20ac yktz r{kw t\u20ac\ufffd{kzkw\u00de\u00feo \ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz zo\u00d0\u20ac tykro\u20ac \ufffdsk\ufffd qok\ufffd\ufffd~o \ufffdt{wozmo\nkzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z tz\ufffdsom{z\ufffdo\u00f0\ufffd {qGST {zZonnt\ufffd *ZY4+. k\u20ac\ufffdso~o sk\u20aclooz {zw\u00de \u20acmk~mo\n~o\u20acok~ms {z\ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz ntrt\ufffdkw zo\u00d0\u20ac m{z\ufffdoz\ufffd qok\ufffd\ufffd~tzr \ufffdt{wozmo kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 625=\n{z\u20ac{mtkw yontk1 Gk\u20acon {z\ufffdso\ufffdso{~o\ufffdtmkw m{zmo|\ufffd\u20ac \ufffdzork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac\ufffd d67.69f kzn \ufffdso\ufffd|tm\ufffd\ufffd~o\n\u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd\ufffd d6:f. \u00d0ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd \ufffdso~o \u20acs{\ufffdwn lok|{\u20act\ufffdt\ufffdo oqqom\ufffd lo\ufffd\u00d0ooz tykro\u20ac qok\ufffd\ufffd~/\ntzr\ufffdt{wozmo kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 Ozknnt\ufffdt{z. \u00d0o\ufffdo\u20ac\ufffdq{~\u20aco\ufffdo~kw {\ufffdso~ k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q{zwtzo zo\u00d0\u20ac\n~o|{~\ufffdtzr \ufffdsk\ufffd |{\ufffdoz\ufffdtkww\u00de ty|km\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z *ZY5+ kzn \u20ac\ufffdlnt\ufffdtno \ufffdsoy tz\ufffd{ *4+k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac\n~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy. *5+k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q\ufffdsozo\u00d0\u20ac |~{\ufffdtno~. kzn *6+k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac m{zmo~ztzr\nm{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac1 L{~kwwk\ufffd\ufffd~tl\ufffd\ufffdo\u20ac. \u00d0o\ufffdso{~o\ufffdtmkww\u00de no~t\ufffdo kzn \ufffdo\u20ac\ufffds\u00de|{\ufffdso\u20aco\u20ac oy|t~tmkww\u00de\n*\\klwo 4t\u20ackz{\ufffdo~\ufffdto\u00d0 {q\ufffdsos\u00de|{\ufffdso\u20aco\u20ac kzn \ufffdsot~ kmmo|\ufffdkzmo {~~ouom\ufffdt{z+1\nL{~\ufffdsooy|t~tmkw kzkw\u00de\u20aco\u20ac. \u00d0o|~{moonon k\u20acq{ww{\u00d0\u20ac1 _o\ufffd\u20acon \ufffdsoW\ufffd\u20acs\u20acstq\ufffd \u20ac\ufffdlyt\u20ac\u20act{z\nn\ufffdy|\u20ac \ufffd{n{\u00d0zw{kn \u20ac\ufffdlyt\u20ac\u20act{z\u20ac q~{y \ufffdso\ufffds~oo |{|\ufffdwk~ zo\u00d0\u20ac/\u20acsk~tzr \u20ac\ufffdl~onnt\ufffd\u20ac. ~2|{wt\ufffdtm\u20ac. ~2\nzo\u00d0\u20ac. kzn ~2\u00d0{~wnzo\u00d0\u20ac1 _oqtw\ufffdo~on \ufffdsonk\ufffdk \ufffd{yk\ufffdms {\ufffd~\ufffd{|tm *GST+. |o~t{n {qkzkw\u00de\u20act\u20ac\n*Tk\u00de 59.5353. \ufffdsonk\u00de{qMo{~ro Lw{\u00den)\u20ac y\ufffd~no~. \ufffd{Tk\u00de 59.5354+. kzn \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffdsk\ufffd\n~omot\ufffdon kytzty\ufffdy {qk\ufffd\ufffdoz\ufffdt{z *~oy{\ufffdkw {q\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds \u00feo~{ m{yyoz\ufffd\u20ac+1 \\{m{y|wo\ufffdo\n\ufffdsonk\ufffdk\u20aco\ufffd \u00d0t\ufffds \ufffdk~tklwo\u20ac zomo\u20ac\u20ack~\u00de q{~\ufffdo\u20ac\ufffdtzr {\ufffd~s\u00de|{\ufffdso\u20aco\u20ac. \u00d0o\ufffdzno~\ufffd{{v \ufffds~oo yo\ufffds{n{/\nw{rtmkw \u20ac\ufffdo|\u20ac> *4+q{~\ufffdsok\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q\ufffdsozo\u00d0\u20ac |~{\ufffdtno~. \u00d0oknnon tzq{~yk\ufffdt{z ~ork~ntzr \ufffdso\nwtzvon zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac |{wt\ufffdtmkw wokztzr. qkm\ufffd\ufffdkw ~o|{~\ufffdtzr. \ufffd~kqqtm. kzn \ufffd\u00de|o {qyontk {\ufffd\ufffdwo\ufffd q~{y\n\ufffdsom{yy{zw\u00de \ufffd\u20acon \u00d0ol\u20act\ufffdo yontkltk\u20acqkm\ufffdmsomv1m{y .\u00d0stms t\u20ac\u00d0tnow\u00de k||wton tz~o\u20acok~ms d6;f?\n*5+q{~okms \u20ac\ufffdlyt\u20ac\u20act{z. \u00d0on{\u00d0zw{knon. tq|{\u20ac\u20actlwo. \ufffdsoqt~\u20ac\ufffd tykro {q\ufffdsowtzvon zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\nkzn k\ufffd\ufffd{yk\ufffdtmkww\u00de mwk\u20ac\u20actqton t\ufffdk\u20ac\ufffdt{woz\ufffd {~z{z\ufffdt{woz\ufffd \u00d0t\ufffds k^MM4= IUU \ufffdsk\ufffd \u00d0o\ufffd~ktzon {z\nkm{y|~osoz\u20act\ufffdo kzn m{z\ufffdo\u00f0\ufffd/\u20ac|omtqtm nk\ufffdk\u20aco\ufffd? kzn *6+\ufffd{no\ufffdom\ufffd \ufffdso\u20acoz\ufffdtyoz\ufffd {qkzo\u00d0\u20ac \ufffdt\ufffdwo\n*k\ufffd\ufffd~tl\ufffd\ufffdo ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy+. \u00d0o\ufffd~ktzon kGtnt~om\ufffdt{zkw Kzm{no~ Zo|~o\u20acoz\ufffdk\ufffdt{z q~{y\n\\~kz\u20acq{~yo~\u20ac *GKZ\\+ y{now kzn mwk\u20ac\u20actqton okms \ufffdt\ufffdwo k\u20acot\ufffdso~ |{\u20act\ufffdt\ufffdo {~zork\ufffdt\ufffdo1 _o~omot\ufffdon\ntzq{~yk\ufffdt{z {zkww{\ufffdso~ \ufffdk~tklwo\u20ac ~owk\ufffdon \ufffd{k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {qm{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac q~{y \ufffdsoW\ufffd\u20acs\u20acstq\ufffd\n\u20ac\ufffdlyt\u20ac\u20act{z n\ufffdy|\u20ac1 _om{zn\ufffdm\ufffdon kzork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z \ufffd{kzkw\u00de\u00feo \ufffdso~owk\ufffdt{z\u20acst|\nlo\ufffd\u00d0ooz \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z *yok\u20ac\ufffd~on tzz\ufffdylo~ {qm{yyoz\ufffd\u20ac+ kzn {\ufffd~tzno|oznoz\ufffd kzn m{z\ufffd~{w\n\ufffdk~tklwo\u20ac \ufffdsk\ufffd \u00d0ono~t\ufffdon \ufffdso{~o\ufffdtmkww\u00de q~{y \ufffdsoo\u00f0t\u20ac\ufffdtzr wt\ufffdo~k\ufffd\ufffd~o1\nGk\u20acon {z\ufffdso~o\u20ac\ufffdw\ufffd\u20ac {q{\ufffd~kzkw\u00de\u20act\u20ac. \u00d0omkzkz\u20ac\u00d0o~ \ufffdso\ufffd\u00d0{~o\u20acok~ms }\ufffdo\u20ac\ufffdt{z\u20ac1 _t\ufffds ~o\u20ac|om\ufffd\n\ufffd{ZY4. t\ufffdt\u20acz{\ufffdtykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo \ufffdsk\ufffd kqqom\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z tz\ufffdsomk\u20aco {qGST ~o|{~\ufffd/\ntzr{zZonnt\ufffd1 Zk\ufffdso~. \u00d0t\ufffds ~o\u20ac|om\ufffd \ufffd{ZY5. \u00d0oqtzn \ufffdsk\ufffd *4+\ufffdso|{wt\ufffdtmkw wokztzr {qkzo\u00d0\u20ac\n\\klwo 41V\ufffdo~\ufffdto\u00d0 {qs\u00de|{\ufffdso\u20ac o\u20ackzn \ufffdsot~ kmmo|\ufffdkzmo {~~ouom\ufffdt{z1\nN\u00de|{\ufffdso\u20aco \u20ac Fmmo|\ufffdkz moZouom\ufffdt{z\nH1>Userswillpaygreaterattention tosubmissions thatfeatureimagesdepicting violence\nthansubmissions thatdonot1a\nH2>Asubmission withatitleconveying anegativesentiment willreceivegreateruser\nattention thanasubmission withapositivetitle1a\nH3>Asubmission\u2019s linkedimagewillhaveamoresubstantial effectonuserattention than\nthesentiment ofasubmission\u2019s title1a\nH4>Asubmission thatincludesalinktoaconservative newsoutletwillreceivegreateruser\nattention thanasubmission thatincludesalinktoaliberalorneutralnewsoutlet1a\nH5>Asubmission thatincludesalinktoaless-factual newsoutletwillreceivegreateruser\nattention thanasubmission thatincludesalinktoahighlyfactualnewsoutlet1a\nH6>Asubmission thatincludesalinktoapopularnewsoutletwithhightrafficwillreceive\ngreateruserattention thanasubmission withalinktoaless-popular newsoutletwith\nminimal ormediumtraffic1a\nH7>Asubmission postedinr/politics willreceivegreateruserattention thanasubmission\npostedinr/newsorr/worldnews1a\nH8>Userswillpaygreaterattention tosubmissions flaggedas\u201cNSFW\u201d thantononflagged\nsubmissions1a\nH9>Asubmission withaflairtagwillreceivelessuserattention thanasubmission withouta\nflairtag1a\nH10>Thenumberofasubmission\u2019s cross-posts willpositively affectuserattention1 a\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o135<<=:51\ufffd33 4\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 725=\n{\ufffd\ufffdwo\ufffd *|{wt\ufffdtmkww\u00de zo\ufffd\ufffd~kw zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac sk\ufffdo k|{\u20act\ufffdt\ufffdo oqqom\ufffd m{y|k~on \ufffd{m{z\u20aco~\ufffdk\ufffdt\ufffdo {~wtlo~kw\n{\ufffd\ufffdwo\ufffd\u20ac+? *5+t\ufffd\u20acwo\ufffdow {qqkm\ufffd\ufffdkw ~o|{~\ufffdtzr *strs qkm\ufffd\ufffdkw ~o|{~\ufffdtzr t\u20ac|{\u20act\ufffdt\ufffdow\u00de k\u20ac\u20ac{mtk\ufffdon. w{\u00d0qkm/\n\ufffd\ufffdkw ~o|{~\ufffdtzr t\u20aczork\ufffdt\ufffdow\u00de k\u20ac\u20ac{mtk\ufffdon m{y|k~on \ufffd{yt\u00f0on qkm\ufffd\ufffdkw ~o|{~\ufffdtzr+? *6+Zonnt\ufffd m{y/\ny\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn kqq{~nkzmo\u20ac *\ufffdso \u20ac\ufffdl~onnt\ufffd\u20ac ~2zo\u00d0\u20ac kzn ~2\u00d0{~wnzo\u00d0\u20ac k~o|{\u20act\ufffdt\ufffdow\u00de k\u20ac\u20ac{mtk\ufffdon\nm{y|k~on \ufffd{~2|{wt\ufffdtm\u20ac. wtzv qwkt~ t\u20aczork\ufffdt\ufffdow\u00de m{~~owk\ufffdon. \ufffdsoz\ufffdylo~ {qm~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac sk\u20ack|{\u20act/\n\ufffdt\ufffdooqqom\ufffd+. kzn *7+\ufffdsozork\ufffdt\ufffdo \ufffdt\ufffdwo\u20ac {qzo\u00d0\u20ac \u20actrztqtmkz\ufffdw\u00de m{~~owk\ufffdo \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z tz\ufffdso\nmk\u20aco {qGST ~o|{~\ufffdtzr {zZonnt\ufffd1\nOz\ufffdsoq{ww{\u00d0tzr. \u00d0o|~{\ufffdtno k\ufffds{~{\ufffdrs o\u00f0|wkzk\ufffdt{z {q{\ufffd~\ufffdso{~o\ufffdtmkw lkmvr~{\ufffdzn kzn\nyo\ufffds{n{w{rtmkw |~{mon\ufffd~o kzn nt\u20acm\ufffd\u20ac\u20ac {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac tzno\ufffdktw1\n\\so{~o\ufffdtmkw lkmvr~{\ufffdzn\nZowk\ufffdon wt\ufffdo~k\ufffd\ufffd~o\nOz\ufffdso|k\u20ac\ufffd. \ufffd~knt\ufffdt{zkw yontk \u20ac\ufffdms k\u20aczo\u00d0\u20ac|k|o~\u20ac. \ufffdowo\ufffdt\u20act{z. kzn ~knt{\u02d8 vz{\u00d0z q{~\ufffdsot~ rk\ufffdo/\nvoo|tzr q\ufffdzm\ufffdt{z. kroznk/\u20aco\ufffd\ufffdtzr |{\u00d0o~. kzn {zo/\u00d0k\u00de m{yy\ufffdztmk\ufffdt{z\u02d8 sk\ufffdo looz \ufffdso|~o/\nn{ytzkz\ufffd \u20ac{\ufffd~mo q{~zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z d6<f1 \\so yontk \u20ac\u00de\u20ac\ufffdoy. s{\u00d0o\ufffdo~. sk\u20acmskzron d<f.\nkzn kntrt\ufffdkw \ufffd~kz\u20acq{~yk\ufffdt{z sk\u20acwon\ufffd~knt\ufffdt{zkw yontk \ufffd{oz\ufffdo~ \ufffdso{zwtzo \u20ac|kmo kzn nt\u20ac\ufffd~tl\ufffd\ufffdo\nzo\u00d0\u20ac \ufffds~{\ufffdrs \ufffdsot~ {\u00d0z ntrt\ufffdkw mskzzow\u20ac *o1r1. \ufffdso{zwtzo \ufffdo~\u20act{z {qTheNewYorkTimes+1\n\\so\u20aco \ufffd~knt\ufffdt{zkw \ufffd\u00de|o\u20ac {qyontk sk\ufffdo looz m{y|woyoz\ufffdon l\u00dentrt\ufffdkw/l{~z yontk \u20ac\ufffdms k\u20aclw{r\u20ac\n{~|\ufffd~o {zwtzo zo\u00d0\u20ac|k|o~\u20ac \ufffdsk\ufffd \ufffd|~{n\ufffdmo k\u00d0tno \ufffdk~to\ufffd\u00de {qm{z\ufffdoz\ufffd. q~{y tz/no|\ufffds tz\ufffdo\u20ac\ufffdtrk\ufffdt\ufffdo\nu{\ufffd~zkwt\u20acy \ufffd{o\u00deolkww/mk\ufffdmstzr mwtmvlkt\ufffd\ufffd d<f1\n\\so tz\ufffd~{n\ufffdm\ufffdt{z {q\u20ac{mtkw yontk zo\ufffd\u00d0{~v\u20ac \u20ac\ufffdms k\u20acZonnt\ufffd. \\\u00d0t\ufffd\ufffdo~. kzn Lkmol{{v. \u00d0stms\nq\ufffdzm\ufffdt{z k\u20actz\ufffdo~yontk~to\u20ac q{~zo\u00d0\u20ac o\u00f0|{\u20ac\ufffd~o kzn m{z\u20ac\ufffdy|\ufffdt{z d6=f. t\u20ackz{\ufffdso~ knnt\ufffdt{z \ufffd{\n\ufffdst\u20acr~{\u00d0tzr ntrt\ufffdkw \u20actno {q\ufffdsoyontk \u20ac\u00de\u20ac\ufffdoy1 Vz\ufffdso\u20aco |wk\ufffdq{~y\u20ac. ntrt\ufffdkw zo\u00d0\u20ac mkzlo|~{n\ufffdmon\nkzn \u20acsk~on l\u00del{\ufffds tznt\ufffdtn\ufffdkw \ufffd\u20aco~\u20ac kzn wk~ro zo\u00d0\u20ac {~rkzt\u00fek\ufffdt{z\u20ac. oy|sk\u20act\u00fetzr \ufffdso\u20actrztqtmkz\ufffd\n\u20acstq\ufffd tz|{\u00d0o~ \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac tzzo\u00d0\u20ac |~{n\ufffdm\ufffdt{z1 \\s\ufffd\u20ac. \u20ac{mtkw yontk zo\ufffd\u00d0{~v\u20ac \ufffdk~o lom{ytzr\ny{~o kzn y{~o tz\ufffdor~kw \ufffd{s{\u00d0 |o{|wo qtzn tzq{~yk\ufffdt{z dkzn zo\u00d0\u20acf\ufffd d73f l\u00dekw\u20ac{ ozklwtzr |o{/\n|wo\ufffd{|~{n\ufffdmo. \u20acsk~o. kzn nt\u20acm\ufffd\u20ac\u20ac tzq{~yk\ufffdt{z kzn zo\u00d0\u20ac \u00d0t\ufffds \ufffdsot~ zo\ufffd\u00d0{~v\u20ac {q{\ufffdso~ |o{|wo1\n\\st\u20ac tz\ufffdo~|wk\u00de lo\ufffd\u00d0ooz ntrt\ufffdkw yontk *m{y|~t\u20acon {q\ufffdsontrt\ufffdkw o\u00f0\ufffdoz\u20act{z\u20ac {q\ufffd~knt\ufffdt{zkw\nyontk kzn ntrt\ufffdkw/l{~z yontk? sozmoq{~\ufffds ~oqo~~on \ufffd{k\u20ac\ufffdntrt\ufffdkw yontk\ufffd+ kzn \u20ac{mtkw yontk |wk\ufffd/\nq{~y\u20ac k~o\ufffdsoq{m\ufffd\u20ac {q{\ufffd~kzkw\u00de\u20act\u20ac1 \\{ro\ufffdso~ \u00d0t\ufffds \ufffd~knt\ufffdt{zkw yontk. \ufffdso\u00de m{z\u20ac\ufffdt\ufffd\ufffd\ufffdo \ufffdso\u20ac{/\nmkwwon \ufffds\u00del~tn yontk \u20ac\u00de\u20ac\ufffdoy\ufffd d;f1\n\\so ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz yontk kzn \ufffdsot~ ~o|{~\ufffdtzr {z\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac sk\u20ackw{zr st\u20ac\ufffd{~\u00de\ntz~o\u20acok~ms d5;.5<.74\u02d877f1 _soz ~o|{~\ufffdtzr {z\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac. l{\ufffds ntrt\ufffdkw kzn \ufffd~knt\ufffdt{zkw\nyontk {\ufffd\ufffdwo\ufffd\u20ac zoon \ufffd{nomtno \u00d0stms o\ufffdoz\ufffd\u20ac \ufffd{tzmw\ufffdno tz\ufffdsot~ zo\u00d0\u20ac m{\ufffdo~kro kzn s{\u00d0 \ufffd{|{~/\n\ufffd~k\u00de \ufffdso\u20ac{mtkw y{\ufffdoyoz\ufffd d\u20acoo. o1r1. 5;.74.75f1 [tzmo \u20ac{yo o\ufffdoz\ufffd\u20ac k~o~ork~non k\u20acy{~o \ufffdzo\u00d0\u20ac/\n\u00d0{~\ufffds\u00de\ufffd \ufffdskz {\ufffdso~\u20ac d75f. k\u20ac\ufffdso\u00de \ufffd~o\u20ac{zk\ufffdo \u00d0t\ufffds y{~o rozo~kw \u20ac{mtkw m{zmo~z\u20ac\ufffd d76f. yontk\n{\ufffd\ufffdwo\ufffd\u20ac ~o|{~\ufffd {z\u20ac|omtqtm o\ufffdoz\ufffd\u20ac ~k\ufffdso~ \ufffdskz {\ufffdso~\u20ac. \u00d0stms t\u20ackw\u20ac{ ~oqo~~on \ufffd{k\u20ac\ufffd\u20acowom\ufffdt{z ltk\u20ac\ufffd\ntzyontk ~o\u20acok~ms d75.76f1 F|k~\ufffdtm\ufffdwk~ \u20acowom\ufffdt{z m~t\ufffdo~t{z tz\ufffdst\u20acm{z\ufffdo\u00f0\ufffd t\u20ac\ufffdso~o|{~\ufffdtzr {z\nzork\ufffdt\ufffdo o\ufffdoz\ufffd\u20ac. o\u20ac|omtkww\u00de tzk|{wt\ufffdtmkw {~\u20ac{mtkw y{\ufffdoyoz\ufffd m{z\ufffdo\u00f0\ufffd d\u20acoo. o1r1. 77.79f. k\u20aczork/\n\ufffdt\ufffdt\ufffd\u00de. tzrozo~kw. sk\u20acw{zr looz |~o\ufffdkwoz\ufffd tz\ufffdsozo\u00d0\u20ac m{\ufffdo~kro {ql{\ufffds \ufffd~knt\ufffdt{zkw kzn ntrt\ufffdkw\nyontk d7:.7;f1\nZo|{~\ufffdtzr kl{\ufffd\ufffd \ufffdt{wozmo t\u20ack\u20ac|omtqtm \ufffd\u00de|o {qzork\ufffdt\ufffdo zo\u00d0\u20ac m{\ufffdo~kro d7<f1 [{mtkw y{\ufffdo/\nyoz\ufffd\u20ac. tz|k~\ufffdtm\ufffdwk~. sk\ufffdo looz \u20ac\ufffdluom\ufffdon \ufffd{\ufffdst\u20ac\ufffd\u00de|o {qzork\ufffdt\ufffdo zo\u00d0\u20ac m{\ufffdo~kro do1r1. 7=.93f\n\ufffdoy|sk\u20act\u00fetzr \ufffdt{wozmo kzn no\ufffdtkz\ufffd losk\ufffdt{\ufffd~\ufffd d55f. \u00d0stms \ufffdozn\u20ac \ufffd{tzm~ok\u20aco \ufffdsok\ufffdntozmo \u20act\u00feo\nk\u20act\ufffd\ufffdm{z\ufffd~tl\ufffd\ufffdo\u20ac \ufffd{\ufffdsoyontk \u20ac|om\ufffdkmwo 444k~{\ufffdzn |~{\ufffdo\u20ac\ufffd o\ufffdoz\ufffd\u20ac\ufffd d4:f1 bo\ufffd. \ufffdst\u20acnowort\ufffdtyt\u00fe/\ntzrzo\u00d0\u20ac m{\ufffdo~kro kzn q{m\ufffd\u20ac {z\ufffdt{wozmo \ufffdsk\ufffd ky|wtqto\u20ac \ufffdso\u20acoz\u20ack\ufffdt{zkwt\u20ac\ufffd k\u20ac|om\ufffd\u20ac {q|~{\ufffdo\u20ac\ufffd t\u20ac\n\ufffd{q\ufffdoz \ufffd{\ufffdsono\ufffd~tyoz\ufffd {q\ufffdso\u20ac{mtkw mk\ufffd\u20aco {~y{\ufffdoyoz\ufffd 444\ufffdd5:f? t\ufffdt\u20ac~oqo~~on \ufffd{tz~o\u20acok~ms\nk\u20ac\ufffdso\ufffd|~{\ufffdo\u20ac\ufffd |k~kntry\ufffd d56.59f1 \\s\ufffd\u20ac. yontk ~o|{~\ufffdtzr m{z\u20ac\ufffd~\ufffdm\ufffd\u20ac kmo~\ufffdktz tz\ufffdo~|~o\ufffdk\ufffdt{z {q\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 925=\n\ufffdso|~{\ufffdo\u20ac\ufffd o\ufffdoz\ufffd. kw\u20ac{ mkwwon \ufffdno\u20acm~t|\ufffdt{z ltk\u20ac\ufffd d\u20acoo. o1r1. 5<f. \ufffd\ufffdsk\ufffd ntqqo~\u20ac q~{y l{\ufffds \ufffdso{luom/\n\ufffdt\ufffdo\u20ac {q|~{\ufffdo\u20ac\ufffd{~\u20ac kzn tz\ufffdo~|~o\ufffdk\ufffdt{z\u20ac {q{\ufffdso~ {l\u20aco~\ufffdo~\u20ac\ufffd d5<f. \u00d0stms tz\ufffd\ufffd~z strsw\u00de ty|km\ufffd\u20ac\n\ufffdso|\ufffdlwtm |o~mo|\ufffdt{z {q\ufffdso\u20ac{mtkw y{\ufffdoyoz\ufffd do1r1. 56.59.5:f1 \\so~oq{~o. t\ufffdt\u20acty|{~\ufffdkz\ufffd \ufffd{q\ufffd~/\n\ufffdso~ {\ufffd~vz{\u00d0wonro {qyontk ~o|{~\ufffdtzr {z\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo kzn \ufffdsok\ufffd\ufffdoz/\n\ufffdt{z t\ufffdk\ufffd\ufffd~km\ufffd\u20ac1\n\\{\ufffds{~{\ufffdrsw\u00de \ufffdzno~\u20ac\ufffdkzn \ufffdsooqqom\ufffd\u20ac {q\ufffdt{wozmo tzyontk ~o|{~\ufffdtzr kzn t\ufffd\u20acty|km\ufffd {z\nk\ufffd\ufffdoz\ufffdt{z. \u00d0ozoon \ufffd{ntqqo~oz\ufffdtk\ufffdo lo\ufffd\u00d0ooz \ufffd~knt\ufffdt{zkw kzn ntrt\ufffdkw yontk zo\u00d0\u20ac ~o|{~\ufffdtzr1\n_so~ok\u20ac tzk\u20ac{mtkw y{\ufffdoyoz\ufffd m{z\ufffdo\u00f0\ufffd \ufffdso~{wo {q\ufffdt{wozmo tz\ufffd~knt\ufffdt{zkw yontk m{\ufffdo~kro sk\u20ac\nlooz \u20ac\ufffd\ufffdnton \ufffds{~{\ufffdrsw\u00de. \ufffds{\ufffdrs wt\ufffd\ufffdwo k\ufffd\ufffdoz\ufffdt{z sk\u20aclooz |ktn \ufffd{t\ufffd\u20acoqqom\ufffd\u20ac tzntrt\ufffdkw zo\u00d0\u20ac\n~o|{~\ufffdtzr *\u20acoo zo\u00f0\ufffd |k~kr~k|s\u20ac+1 \\s\ufffd\u20ac. {\ufffd~|k|o~ kzkw\u00de\u00feo\u20ac \u00d0so\ufffdso~ qtzntzr\u20ac q~{y \ufffd~knt\ufffdt{zkw\nyontk ~o\u20acok~ms mkzlo~o|wtmk\ufffdon q{~\ufffdsontrt\ufffdkw zo\u00d0\u20ac m{\ufffdo~kro1\n\\so wt\ufffdo~k\ufffd\ufffd~o \u20acs{\u00d0\u20ac \ufffdsk\ufffd \ufffd~knt\ufffdt{zkw yontk)\u20ac zo\u00d0\u20ac m{\ufffdo~kro q~o}\ufffdoz\ufffdw\u00de qok\ufffd\ufffd~o\u20ac \ufffdt{woz\ufffd\nk\u20ac|om\ufffd\u20ac {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac d\u20acoo. o1r1. 56.74.94f \ufffd{k\ufffd\ufffd~km\ufffd k\ufffd\ufffdoz\ufffdt{z. k\u20ac\ufffddlf\ufffd~ztzr l\ufffdtwntzr\u20ac\nkzn l\ufffd~ztzr \ufffdt~o\u20ac ykvo lo\ufffd\ufffdo~ \ufffdowo\ufffdt\u20act{z \ufffdskz |okmoq\ufffdw \ufffdtrtw\u20ac kzn {~no~w\u00de yk~mso\u20ac\ufffd d74f1 L{~\ntz\u20ac\ufffdkzmo. G{\u00dev{qq d95f \u20acs{\u00d0on \ufffdsk\ufffd tzqw\ufffdoz\ufffdtkw zo\u00d0\u20ac|k|o~\u20ac. tz|k~\ufffdtm\ufffdwk~. \ufffd\u00de|tmkww\u00de k||w\u00de q~ky/\ntzr\ufffdsk\ufffd qok\ufffd\ufffd~o\u20ac \ufffdt{woz\ufffd k\u20ac|om\ufffd\u20ac {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac lomk\ufffd\u20aco t\ufffd\u20aco~\ufffdo\u20ac k\u20ack|~{ytzoz\ufffd no\ufffdtmo\nq{~k\ufffd\ufffd~km\ufffdtzr ~okno~\u20ac) k\ufffd\ufffdoz\ufffdt{z1 TmLk~wkzo kzn Nk\u00de d94f o\ufffdkw\ufffdk\ufffdon \ufffdsozo\u00d0\u20ac|k|o~ ~o|{~\ufffdtzr\n{z\ufffdso|~{\ufffdo\u20ac\ufffd\u20ac krktz\u20ac\ufffd \ufffdso6~n_{~wn \\~kno V~rkzt\u00fek\ufffdt{z *_\\V+ Ttzt\u20ac\ufffdo~tkw I{zqo~ozmo tz\n4===. \u00d0stms |{~\ufffd~k\u00deon |~{\ufffdo\u20ac\ufffd\u20ac \ufffd444\u00d0t\ufffdstz kzjkzk~ms\u00de kzn \ufffdt{wozmo) zk~~k\ufffdt\ufffdo \u20ac\ufffd~\ufffdm\ufffd\ufffd~o tz\n\u00d0stms ~o|ok\ufffdon ~oqo~ozmo \u00d0k\u20acykno \ufffd{|~{|o~\ufffd\u00de no\u20ac\ufffd~\ufffdm\ufffdt{z l\u00de|~{\ufffdo\u20ac\ufffd{~\u20ac. \ufffd{\ufffdsot~ km\ufffd\u20ac {q\ufffdt{/\nwozmo. kzn \ufffd{\ufffdso|~o\u20acozmo {qjyk\u20acvon kzk~mst\u20ac\ufffd\u20ac n~o\u20ac\u20acon tzlwkmv)\ufffd d94f1 \\st\u20ac |k~\ufffdtm\ufffdwk~ q~ky/\ntzr\u00d0k\u20ack||wton \ufffd{~o\u20ac{zk\ufffdo \u00d0t\ufffds \ufffdsozo\u00d0\u20ac) ~okno~\u20acst| kzn ~omot\ufffdo k\ufffd\ufffdoz\ufffdt{z \u00d0stwo\nnowort\ufffdtyt\u00fetzr \ufffdso|~{\ufffdo\u20ac\ufffd kzn r\ufffdtntzr \ufffd~okno~\u20ac \ufffd{\u00d0k~n\u20ac k|{\u20act\ufffdt{ztzr \u20ac\ufffd||{~\ufffdtzr \ufffdso_\\V\ufffd\nd94f1\nOzk\u20actytwk~ \ufffdotz. tzst\u20ac\u20ac\ufffd\ufffdn\u00de kl{\ufffd\ufffd \ufffdso|~o\u20ac\u20ac ~o|{~\ufffdtzr {z\ufffdso4=:< S{zn{z kz\ufffdt/\u00d0k~ ~kww\u00de.\nT\ufffd~n{mv d93f \u20acs{\u00d0on \ufffdsk\ufffd \ufffdso|~o\u20ac\u20ac q~kyon \ufffdsoy{\ufffdoyoz\ufffd \ufffd{k\ufffdto\u00d0|{tz\ufffd \ufffdkw~okn\u00de qkytwtk~ \ufffd{\n\ufffdso~okno~\ufffd d93f l\u00de|{~\ufffd~k\u00detzr \ufffdso|~{\ufffdo\u20ac\ufffd{~\u20ac k\u20acytwt\ufffdkz\ufffd o\u00f0\ufffd~oyt\u20ac\ufffd\u20ac {~kzk~mst\u20ac\ufffd\u20ac ~okn\u00de \ufffd{\ufffd\u20aco\n\ufffdt{wozmo1 \\st\u20ac q~kytzr ykno \ufffdsozo\u00d0\u20ac m{\ufffdo~kro y{~o k||okwtzr \ufffd{\ufffdsok\ufffdntozmo kzn \ufffdso~oq{~o\nknnon \ufffd{t\ufffd\u20ac~omot\ufffdon k\ufffd\ufffdoz\ufffdt{z1 Stvo\u00d0t\u20aco. G{\u00dewo o\ufffdkw1d56f q{\ufffdzn \ufffdsk\ufffd zo\u00d0\u20ac|k|o~\u20ac {q\ufffdoz oy|sk/\n\u20act\u00feo\ufffdso\ufffdt{woz\ufffd km\ufffdt{z\u20ac {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac nt\u20ac|~{|{~\ufffdt{zkww\u00de \u00d0soz ~o|{~\ufffdtzr {z\ufffdsoy.\n~ork~nwo\u20ac\u20ac {qm{\ufffdz\ufffd~\u00de kzn km~{\u20ac\u20ac \ufffdtyo1 [\ufffdms \ufffdt{woz\ufffd q~kytzr {qky{\ufffdoyoz\ufffd \ufffdmkz sk\ufffdo k|{\u00d0o~/\nq\ufffdwtzqw\ufffdozmo {zs{\u00d0 k\ufffdntozmo yoylo~\u20ac |o~mot\ufffdo t\u20ac\u20ac\ufffdo\u20ac kzn |k~\ufffdto\u20ac \ufffd{km{zqwtm\ufffd. tzmw\ufffdntzr |o~/\nmo|\ufffdt{z\u20ac {q|~{\ufffdo\u20ac\ufffd{~\u20ac\ufffd d56f1 TmSo{n kzn Jo\ufffdozlo~ d96f \u00d0o~o ky{zr \ufffdsoqt~\u20ac\ufffd \ufffd{kzkw\u00de\u00feo \ufffdso\nty|km\ufffd {q\ufffdowo\ufffdt\u20act{z m{\ufffdo~kro {z\ufffdt{woz\ufffd |~{\ufffdo\u20ac\ufffd\u20ac kzn \ufffdsooqqom\ufffd\u20ac {z|\ufffdlwtm tnoz\ufffdtqtmk\ufffdt{z \u00d0t\ufffds k\ny{\ufffdoyoz\ufffd1 \\so k\ufffd\ufffds{~\u20ac \u20acs{\u00d0on \ufffdsk\ufffd zo\u00d0\u20ac \u20ac\ufffd{~to\u20ac \u20acsk~on {z\ufffdowo\ufffdt\u20act{z sk\ufffdo \ufffdso|{\u00d0o~ \ufffd{wort\ufffdt/\nyt\u00feo {~nowort\ufffdtyt\u00feo \ufffdsomk\ufffd\u20aco \ufffdsk\ufffd y{\ufffdt\ufffdk\ufffdo\u20ac |~{\ufffdo\u20ac\ufffd kzn \ufffds\ufffd\u20ac \u20ac\u00d0k\u00de \ufffdso|\ufffdlwtm tzqk\ufffd{~ {q{~\nkrktz\u20ac\ufffd k\u20ac{mtkw y{\ufffdoyoz\ufffd1 ^wtoroz\ufffdsk~\ufffd kzn _kwr~k\ufffdo d97f \u20ac\ufffdyyon \ufffd|\ufffdsoqtzntzr\u20ac {q\u20aco\ufffdo~kw\nntqqo~oz\ufffd k\ufffd\ufffds{~\u20ac \u00d0s{ m{zmw\ufffdnon. ky{zr {\ufffdso~ qtzntzr\u20ac. \ufffdsk\ufffd k\u20ac{mtkw y{\ufffdoyoz\ufffd |~{\ufffdo\u20ac\ufffd t\u20ac\ny{~o wtvow\u00de \ufffd{~omot\ufffdo \ufffd~knt\ufffdt{zkw yontk m{\ufffdo~kro tqt\ufffdtzmw\ufffdno\u20ac km\ufffd\u20ac {q\ufffdt{wozmo? \ufffdst\u20acwokn\u20ac \ufffd{\nr~ok\ufffdo~ k\ufffdntozmo o\u00f0|{\u20ac\ufffd~o kzn \ufffds\ufffd\u20ac r~ok\ufffdo~ k\ufffd\ufffdoz\ufffdt{z1\n\\so z{\ufffdt{z {q\ufffdt{wozmo kzn \u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac kw\u20ac{ |wk\u00de\u20ac k~{wo {z\u20ac{mtkw yontk1 [{yo \u20ac\ufffd\ufffdn/\nto\u20acsk\ufffdo kzkw\u00de\u00feon s{\u00d0 km\ufffdt\ufffdt\u20ac\ufffd\u20ac \ufffdsoy\u20acow\ufffdo\u20ac \ufffd\u20aco\ufffdt{wozmo tz\ufffdsot~ \u20ac{mtkw yontk |{\u20ac\ufffdtzr *\ufffd\u00d0oo\ufffd\u20ac.\n\ufffdtno{\u20ac. kzn |s{\ufffd{\u20ac+ k\u20ackyokz\u20ac {qn~k\u00d0tzr k\ufffd\ufffdoz\ufffdt{z \ufffd{\ufffdsot~ mk\ufffd\u20aco d99f1 [tzmo \ufffdso\u20acsk~tzr {q\ntykro\u20ac kqqom\ufffd\u20ac \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zwtzo d55.9:f. kzn \u20ac\ufffdms tykro\u20ac k~onomt\u20act\ufffdo q{~s{\u00d0 \u20ac{mtkw y{\ufffdo/\nyoz\ufffd\u20ac k~o|o~mot\ufffdon d9;.9<f. t\ufffdt\u20acty|{~\ufffdkz\ufffd \ufffd{kzkw\u00de\u00feo \ufffdso\ufffdt\u20ac\ufffdkw |{~\ufffd~k\u00dekw {q\ufffdt{wozmo tz\ufffdso\n\u20ac{mtkw yontk m{yy\ufffdztmk\ufffdt{z {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac1\nUo\ufffdyk\u00deo~ kzn Z{\u20ac\u20act d9=f m{z\ufffd~k\u20ac\ufffdon s{\u00d0 ntqqo~oz\ufffd km\ufffd{~\u20ac. \u20ac\ufffdms k\u20ac|{wtmo. u{\ufffd~zkwt\u20ac\ufffd\u20ac. kzn\nkm\ufffdt\ufffdt\u20ac\ufffd\u20ac. \u20acsk~on tykro\u20ac \u00d0t\ufffds \ufffdk~\u00detzr wo\ufffdow\u20ac {q\ufffdt{wozmo {z\ufffdso\u20ac{mtkw yontk |wk\ufffdq{~y \\\u00d0t\ufffd\ufffdo~ k\u20ac\nk\u00d0k\u00de {qm{yy\ufffdztmk\ufffdtzr \ufffdsot~ t\u20ac\u20ac\ufffdo\u20ac1 \\so\u00de m{zmw\ufffdnon \ufffdsk\ufffd km\ufffdt\ufffdt\u20ac\ufffd\u20ac {q\ufffdoz \u20ac\ufffd~\ufffdrrwo \ufffd{rk~zo~\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 :25=\n\ufffdt\u20actltwt\ufffd\u00de q{~\ufffdsot~ r~to\ufffdkzmo\u20ac lomk\ufffd\u20aco tykro\u20ac |{\u20ac\ufffdon l\u00de{\ufffdso~ km\ufffd{~\u20ac *o1r1. \ufffdso|{wtmo+ \ufffdsk\ufffd qok/\n\ufffd\ufffd~o \ufffdt{wozmo {\ufffdo~\u20acskn{\u00d0 \ufffdsomk\ufffd\u20aco {q\ufffdsoy{\ufffdoyoz\ufffd1 \\s~{\ufffdrs kykz\ufffdkw tykro m{z\ufffdoz\ufffd kzkw\u00de/\n\u20act\u20ac{z\\\u00d0t\ufffd\ufffdo~. Rsk~~{\ufffdl kzn Gk\u20acd4;f q{\ufffdzn \ufffdsk\ufffd tz\ufffdso5344 Kr\u00de|\ufffdtkz ~o\ufffd{w\ufffd\ufffdt{z. t\ufffd\u00d0k\u20acz{\ufffd\noy{\ufffdt{zkww\u00de k~{\ufffd\u20actzr tykro\u20ac *qok\ufffd\ufffd~tzr. o1r1. \ufffdt{wozmo+ |{\u20ac\ufffdon l\u00dekm\ufffd{~\u20ac \u20ac\ufffdms k\u20ackm\ufffdt\ufffdt\u20ac\ufffd\u20ac {~\ufffdso\n|{wtmo \ufffdsk\ufffd m{y|owwon \ufffd\u20aco~\u20ac \ufffd{~o\ufffd\u00d0oo\ufffd yo\u20ac\u20ackro\u20ac l\ufffd\ufffd~k\ufffdso~ oqqtmkm\u00de/owtmt\ufffdtzr tykro\u20ac *qok\ufffd\ufffd~tzr.\no1r1. zk\ufffdt{zkw {~~owtrt{\ufffd\u20ac \u20ac\u00deyl{w\u20ac+1 Z{\u20ac\u20act o\ufffdkw1d4:f \ufffdzno~\ufffd{{v \ufffdsoqt~\u20ac\ufffd wk~ro/\u20acmkwo \u20ac\ufffd\ufffdn\u00de tz\ufffdst\u20ac\nqtown. o\ufffdkw\ufffdk\ufffdtzr \ufffdsom{~~owk\ufffdt{z lo\ufffd\u00d0ooz tykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo |{\u20ac\ufffdon l\u00dentqqo~oz\ufffd \ufffd\u00de|o\u20ac {q\n\ufffd\u20aco~\u20ac. \u20ac\ufffdms k\u20ackm\ufffdt\ufffdt\u20ac\ufffd\u20ac. zo\u00d0\u20ac krozmto\u20ac. kzn \ufffdso|{wtmo. kzn \ufffdsot~ |~{|krk\ufffdt{z {z\\\u00d0t\ufffd\ufffdo~ n\ufffd~tzr\n\ufffdsoM53 \u20ac\ufffdyyt\ufffd |~{\ufffdo\u20ac\ufffd\u20ac tzNkyl\ufffd~r. Mo~ykz\u00de. tz534;1 _t\ufffdstz \ufffdsoqt\ufffdonk\u00de\u20ac {q\ufffdsot~ \u20ac\ufffd\ufffdn\u00de\nm{z\ufffdo\u00f0\ufffd. \ufffdso\u00de q{\ufffdzn \ufffdsk\ufffd \ufffdso\ufffdt\u20ac\ufffdkw |{~\ufffd~k\u00dekw {q\ufffdt{wozmo ntnz{\ufffdkqqom\ufffd \ufffdsoz\ufffdylo~ {q~o\ufffd\u00d0oo\ufffd\u20ac\n{~yoz\ufffdt{z\u20ac1\nOz\ufffdsokq{~oyoz\ufffdt{zon \u20ac\ufffd\ufffdnto\u20ac. \ufffdso|{~\ufffd~k\u00dekw {q\ufffdt{wozmo {z\u20ac{mtkw yontk ntnz{\ufffdkqqom\ufffd \ufffd\u20aco~\nozrkroyoz\ufffd \ufffd{\ufffdsoo\u00f0|om\ufffdon o\u00f0\ufffdoz\ufffd1 \\so\u20aco \u20ac\ufffd\ufffdnto\u20ac. s{\u00d0o\ufffdo~. o\ufffdkw\ufffdk\ufffdon tykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{/\nwozmo \ufffdsk\ufffd sknlooz \u20acsk~on l\u00de\ufffdk~t{\ufffd\u20ac \ufffd\u20aco~ \ufffd\u00de|o\u20ac. \u20ac\ufffdms k\u20ackm\ufffdt\ufffdt\u20ac\ufffd\u20ac. |{wtmo. kzn u{\ufffd~zkwt\u20ac\ufffd\u20ac1 V\ufffd~\nkzkw\u00de\u20act\u20ac. l\u00dem{z\ufffd~k\u20ac\ufffd. q{m\ufffd\u20aco\u20ac o\u00f0mw\ufffd\u20act\ufffdow\u00de {zs{\u00d0 ntrt\ufffdkwnewscoverage {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac kzn\n\ufffdt{wozmo kqqom\ufffd\u20ac \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {z\u20ac{mtkw yontk |wk\ufffdq{~y\u20ac1 Ozknnt\ufffdt{z. \u00d0om{z\ufffd~{w q{~{\ufffdso~\n|{\ufffdoz\ufffdtkw k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {qntrt\ufffdkw zo\u00d0\u20ac ~o|{~\ufffdtzr \ufffdsk\ufffd m{\ufffdwn tzqw\ufffdozmo \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\s\ufffd\u20ac. {\ufffd~\n|k|o~ {qqo~\u20ac \ufffds~oo \ufffdzt}\ufffdo m{z\ufffd~tl\ufffd\ufffdt{z\u20ac1 Lt~\u20ac\ufffd. \u00d0oo\ufffdkw\ufffdk\ufffdo \u00d0so\ufffdso~ |~o\ufffdt{\ufffd\u20acw\u00de o\u20ac\ufffdklwt\u20acson qtzn/\ntzr\u20ac q~{y \ufffd~knt\ufffdt{zkw yontk ~o\u20acok~ms mkzlo\ufffd~kz\u20acqo~~on \ufffd{\ufffdso{zwtzo \u00d0{~wn. k\u20ac~o\u20acok~ms \u20ac\ufffdr/\nro\u20ac\ufffd\u20ac \u00d0t\ufffds ~o\u20ac|om\ufffd \ufffd{{qqwtzo zo\u00d0\u20ac sklt\ufffd\u20ac d:3.:4f1 \\s\ufffd\u20ac. \u00d0o\ufffdo\u20ac\ufffd\u00d0so\ufffdso~ \u20acsk~on {zwtzo zo\u00d0\u20ac\nk~\ufffdtmwo\u20ac qok\ufffd\ufffd~tzr \ufffdt\u20ac\ufffdkw nt\u20ac|wk\u00de\u20ac {q\ufffdt{wozmo ~omot\ufffdo tzm~ok\u20acon \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd1 [om{zn.\n\u00d0okzkw\u00de\u00feo \ufffdsomk\u20aco {qk|~{ytzoz\ufffd kzn m{z\ufffdoy|{~k~\u00de \u20ac{mtkw y{\ufffdoyoz\ufffd \u00d0t\ufffds k\u20ac\ufffd~{zr ntrt\ufffdkw\n|~o\u20acozmo {\ufffdo~ k|~{w{zron |o~t{n {q\ufffdtyo *{zo \u00deok~+ {z\ufffdso\u20ac{mtkw yontk |wk\ufffdq{~y Zonnt\ufffd.\n\u00d0stms s{\u20ac\ufffd\u20ac \u20ac\ufffdl~onnt\ufffd\u20ac \u00d0t\ufffds kzo\u00f0|wtmt\ufffd q{m\ufffd\u20ac {z\u20acsk~tzr kzn nt\u20acm\ufffd\u20ac\u20actzr {zwtzo zo\u00d0\u20ac m{z\ufffdoz\ufffd1\n\\st~n. \u20actzmo \u20ac{mtkw yontk t\u20ackm{y|wo\u00f0 m{yy\ufffdztmk\ufffdt{z oz\ufffdt~{zyoz\ufffd d4fkzn \ufffdsooqqom\ufffd {qntrt/\n\ufffdkwzo\u00d0\u20ac m{\ufffdo~kro {q\ufffdt{wozmo {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z t\u20ac\ufffdzmwok~. \u00d0oo\u00f0\ufffdozn {\ufffd~tykro kzkw\u00de\u20act\u20ac l\u00dekzk/\nw\u00de\u00fetzr {\ufffdso~ k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {q\ufffdso\u20acsk~on ntrt\ufffdkw zo\u00d0\u20ac m{z\ufffdoz\ufffd *k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac {qzo\u00d0\u20ac t\ufffdoy. zo\u00d0\u20ac\n|~{\ufffdtno~. kzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn |wk\ufffdq{~y kqq{~nkzmo\u20ac+1 G\u00den{tzr \u20ac{.\u00d0om~ok\ufffdo kzo\u00f0\ufffdoznon\n\u20ac\ufffdk\ufffdt\u20ac\ufffdtmkw y{now \ufffdsk\ufffd kmm{\ufffdz\ufffd\u20ac q{~\u20aco\ufffdo~kw |wk\ufffd\u20actlwo qkm\ufffd{~\u20ac \ufffdsk\ufffd kqqom\ufffd {zwtzo \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1\n\\so{~\u00de kzn s\u00de|{\ufffdso\u20aco\u20ac\n[{/mkwwon \ufffdzork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac\ufffd t\u20ac{zol~{knw\u00de kmvz{\u00d0wonron m{zmo|\ufffd \ufffd\u20acon \ufffd{o\u00f0|wktz |o{|wo)\u20ac \ufffdoz/\nnozm\u00de \ufffd{lon~k\u00d0z \ufffd{zork\ufffdt\ufffdo zo\u00d0\u20ac. \u00d0stms t\u20ack\ufffd\ufffd~tl\ufffd\ufffdon \ufffd{k|\u20ac\u00dems{w{rtmkw ~oyzkz\ufffd {qs\ufffdykz\no\ufffd{w\ufffd\ufffdt{z d\u20acoo. o1r1. 69f1 Z{\u00fetz kzn Z{\u00de\u00feykz d67f no\u20acm~tlo \ufffdsom{zmo|\ufffd k\u20ac\ufffdkrozo~kw ltk\u20ac. lk\u20acon\n{zl{\ufffds tzzk\ufffdo |~ont\u20ac|{\u20act\ufffdt{z\u20ac kzn o\u00f0|o~tozmo. tzkztykw\u20ac kzn s\ufffdykz\u20ac. d\u00d0stmsf rt\ufffdod\u20acf r~ok\ufffdo~\n\u00d0otrs\ufffd \ufffd{zork\ufffdt\ufffdo oz\ufffdt\ufffdto\u20ac1\ufffd Nozmo. zork\ufffdt\ufffdo tzq{~yk\ufffdt{z t\u20aco\u00f0|o~tozmon y{~o tz\ufffdoz\u20acow\u00de. wok\ufffd/\ntzrky{~o |o~\u20act\u20ac\ufffdoz\ufffd ty|~o\u20ac\u20act{z tz|o{|wo)\u20ac yoy{~to\u20ac \ufffdskz |{\u20act\ufffdt\ufffdo tzq{~yk\ufffdt{z d:5f1 \\st\u20ac\nyomskzt\u20acy |k~\ufffdtkww\u00de o\u00f0|wktz\u20ac \u00d0s\u00de \u00d0ok~ozk\ufffd\ufffd~kww\u00de n~k\u00d0z \ufffd{zork\ufffdt\ufffdo d7;f kzn kw\u20ac{ \ufffdt{woz\ufffd\nyontk m{z\ufffdoz\ufffd> {\ufffd~\ufffdl~ktz t\u20ac\u20acty|w\u00de l\ufffdtw\ufffd \u00d0t\ufffds kr~ok\ufffdo~ \u20acoz\u20act\ufffdt\ufffdt\ufffd\u00de \ufffd{\ufffdz|wok\u20ackz\ufffd zo\u00d0\u20ac\ufffd dW~{q1\nQ{sz \\1Ikmt{||{ mt\ufffdon tz:6f1 \\st\u20ac t\u20ac.tz|k~\ufffd. kzo\u00f0|wkzk\ufffdt{z q{~\ufffdso|~on{ytzkzmo {qzork\ufffdt\ufffdo\nzo\u00d0\u20ac ~o|{~\ufffdtzr tz\ufffd~knt\ufffdt{zkw yontk d:7f1 Gk\u20acon {z\ufffdso\u20aco qtzntzr\u20ac kzn \ufffdso\u20ac\ufffdrro\u20ac\ufffdt{z \ufffdsk\ufffd {qq/\nwtzozo\u00d0\u20ac sklt\ufffd\u20ac mkzlo\ufffd~kz\u20acqo~~on \ufffd{ntrt\ufffdkw zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z d:3.:4f. \u00d0os\u00de|{\ufffdso\u20act\u00feo \ufffdsk\ufffd\nntrt\ufffdkw zo\u00d0\u20ac m{z\ufffdoz\ufffd no|tm\ufffdtzr \ufffdt{wozmo tz\ufffdsom{z\ufffdo\u00f0\ufffd {q\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac \u20acs{\ufffdwn kw\u20ac{ ~omot\ufffdo\nr~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \u00d0soz \u20acsk~on {z\u20ac{mtkw yontk1\nL\ufffd~\ufffdso~. tzwtzo\u00d0t\ufffds \ufffdso\u20ack\u00detzr \ufffdsk\ufffd \ufffdk|tm\ufffd\ufffd~o t\u20ac\u00d0{~\ufffds k\ufffds{\ufffd\u20ackzn \u00d0{~n\u20ac.\ufffd \u00d0ok~r\ufffdo \ufffdsk\ufffd\n\ufffdso\ufffdt\u20ac\ufffdkw nt\u20ac|wk\u00de {q\ufffdt{wozmo \u20acs{\ufffdwn rk~zo~ o\ufffdoz r~ok\ufffdo~ k\ufffd\ufffdoz\ufffdt{z d63f1 Wtm\ufffd\ufffd~o\u20ac sk\ufffdo ky{~o\n\u20actrztqtmkz\ufffd ty|km\ufffd {z\ufffdsos\ufffdykz l~ktz \ufffdskz \ufffdo\u00f0\ufffd\ufffdkw ~o|~o\u20acoz\ufffdk\ufffdt{z\u20ac {qtzq{~yk\ufffdt{z. \u00d0stms mkz\nlokl\u20ac{~lon y{~o ~k|tnw\u00de \ufffds~{\ufffdrs \ufffdt\u20ac\ufffdkw \u20ac\ufffdty\ufffdwt? \ufffdsom{z\ufffdoz\ufffd {qtykro\u20ac t\u20acy{~o wtvow\u00de \ufffdskz \ufffdo\u00f0\ufffd\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 ;25=\n\ufffd{lo~oyoylo~on d6:f? kzn oy{\ufffdt{zkww\u00de msk~ron tykro\u20ac. tz|k~\ufffdtm\ufffdwk~. \ufffdozn \ufffd{k\ufffd\ufffd~km\ufffd r~ok\ufffdo~\nk\ufffd\ufffdoz\ufffdt{z \ufffdskz \ufffds{\u20aco wkmvtzr tzoy{\ufffdt{z d:9f1 \\st\u20ac |soz{yoz{z t\u20ackw\u20ac{ ~oqo~~on \ufffd{k\u20ac\ufffdso\ufffd|tm/\n\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd\ufffd d6:f1 [{mtkw yontk |wk\ufffdq{~y\u20ac sk\ufffdo tzm~ok\u20actzrw\u00de lom{yo k\ufffd\ufffdt\u20ac\ufffdkw\nyont\ufffdy\ufffd d::f. k\u20actrz {q\ufffdsor~{\u00d0tzr ty|{~\ufffdkzmo {qtykro\u20ac tz{zwtzo m{z\ufffdo\u00f0\ufffd\u20ac d:;f1 Ww\ufffd\u20ac. t\ufffdsk\u20ac\nlooz \u20acs{\u00d0z \ufffdsk\ufffd \ufffdso\u00d0twwtzrzo\u20ac\u20ac {q\u20ac{mtkw yontk \ufffd\u20aco~\u20ac \ufffd{\u20acsk~o *kzn \ufffds\ufffd\u20ac ozrkro \u00d0t\ufffds+ kntrt\ufffdkw\nzo\u00d0\u20ac k~\ufffdtmwo kl{\ufffd\ufffd \u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac tzm~ok\u20aco\u20ac {zmo \ufffdt\u20ac\ufffdkw\u20ac k~otzmw\ufffdnon d55f1 \\s\ufffd\u20ac. \u00d0okzkw\u00de\u00feo\n\ufffdsooqqom\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {qtykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo \u20actzmo \u20acsk~tzr tykro\u20ac strsw\u00de m{~~owk\ufffdo\u20ac\n\u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zwtzo d55.9:f1\n\\st\u20ac |k|o~ noqtzo\u20ac \ufffdt{wozmo k\u20ac\ufffdtz\ufffdoz\ufffdt{zkww\u00de mk\ufffd\u20acon {~mk~owo\u20ac\u20acw\u00de kmmo|\ufffdon nkykro \ufffd{2\nno\u20ac\ufffd~\ufffdm\ufffdt{z {q|~{|o~\ufffd\u00de {~\ufffdsotzu\ufffd~tzr2vtwwtzr {q|o{|wo\ufffd d:<f1 G\u00dek||w\u00detzr \ufffdst\u20ac\u20ac\ufffd~tm\ufffd noqtzt\ufffdt{z\n{q\ufffdt{wozmo l\u00deZ\ufffdms\ufffd d:<f. {\ufffd~kzkw\u00de\u20act\u20ac q{m\ufffd\u20aco\u20ac {z\ufffdsont\u20ac|wk\u00de {q|s\u00de\u20actmkw \ufffdt{wozmo kzn tz\ufffdoz/\n\ufffdt{zkww\u00de o\u00f0mw\ufffdno\u20ac {\ufffdso~ q{~y\u20ac {q\ufffdt{wozmo. \u20ac\ufffdms k\u20ac\ufffdo~lkw k\u20ac\u20ack\ufffdw\ufffd1 _onomtnon {z\ufffdst\u20ac~owk\ufffdt\ufffdow\u00de\nm{z\u20aco~\ufffdk\ufffdt\ufffdo noqtzt\ufffdt{z {q\ufffdt{wozmo lomk\ufffd\u20aco \u00d0okty \ufffd{yok\u20ac\ufffd~o \ufffdsooqqom\ufffd {q\ufffdo\u00f0\ufffd~oyo\ufffd q{~y\u20ac {q\n\ufffdt{wozmo. \u00d0stms \u00d0ok\u20ac\u20ac\ufffdyo ~omot\ufffdo\u20ac y{~o \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \ufffdskz y{~o \ufffdytz{~\ufffd \ufffd\u00de|o\u20ac {q\ufffdt{wozmo\n*\u20acoo \u20acom\ufffdt{z \ufffdV|o~k\ufffdt{zkwt\u00fek\ufffdt{z {q\ufffdk~tklwo\u20ac\ufffd q{~q\ufffd~\ufffdso~ tzq{~yk\ufffdt{z+1\nGk\u20acon {z\ufffdst\u20ac\ufffdso{~o\ufffdtmkw lkmvr~{\ufffdzn. {\ufffd~qt~\u20ac\ufffd s\u00de|{\ufffdso\u20act\u20ac t\u20ac>\nH1>Userswillpaygreaterattention tosubmissions thatfeatureimagesdepicting violencethan\nsubmissions thatdonot1\nF\u20ac\u20ac\ufffdk\ufffdon loq{~o. \u00d0okzkw\u00de\u00feo \ufffdsooqqom\ufffd\u20ac {q{\ufffdso~ GST/~owk\ufffdon zo\u00d0\u20ac m{z\ufffdoz\ufffd k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac \u20acsk~on\n{zZonnt\ufffd1 _oq{m\ufffd\u20ac qt~\u20ac\ufffd {zk\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy1 _oo\u00f0kytzo \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffd{\n\u20ac\ufffdl~onnt\ufffd\u20ac \ufffdsk\ufffd m{z\u20act\u20ac\ufffd {q\ufffdso\ufffdt\ufffdwo {qkzo\u00d0\u20ac k~\ufffdtmwo kzn kwtzv \ufffd{kntrt\ufffdkw \u20ac{\ufffd~mo zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\n*sozmoq{~\ufffds. \u00d0o~oqo~ \ufffd{l{\ufffds ntrt\ufffdkw o\u00f0\ufffdoz\u20act{z\u20ac {q\ufffd~knt\ufffdt{zkw yontk kzn ntrt\ufffdkw/l{~z yontk k\u20ac\n\ufffdzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\ufffd+ kzn m{zmw\ufffdno \ufffdsk\ufffd okms \u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\ufffdwo t\u20ackztz\ufffdor~kw |k~\ufffd {qk\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac\nm{z\ufffdoz\ufffd kzn mkz. \ufffds\ufffd\u20ac. kqqom\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z d:=f1 Gomk\ufffd\u20aco kzk~\ufffdtmwo)\u20ac \ufffd{zo mkztzqw\ufffdozmo \ufffd\u20aco~\u20ac)\n|o~mo|\ufffdt{z\u20ac {qkzn ~okm\ufffdt{z\u20ac \ufffd{\ufffdsom{z\ufffdoz\ufffd d;3f. \u00d0om{z\ufffd~{w q{~\ufffdso\u20acoz\ufffdtyoz\ufffd {q\ufffdt\ufffdwo\u20ac1 [tzmo\n|~o\ufffdt{\ufffd\u20ac ~o\u20acok~ms o\u20ac\ufffdklwt\u20acson k|{\u20act\ufffdt\ufffdo ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz zork\ufffdt\ufffdo \ufffdt\ufffdwo\u20ac kzn zo\u00d0\u20ac ~okno~/\n\u20acst| {zwtzo d;4f. \u00d0okw\u20ac{ k\u20ac\u20ac\ufffdyo \ufffdsk\ufffd zork\ufffdt\ufffdo \ufffdt\ufffdwo\u20ac \u00d0twwloy{~o k\ufffd\ufffd~km\ufffdt\ufffdo \ufffdskz |{\u20act\ufffdt\ufffdo {zo\u20ac.\n\u00d0stms kw\u20ac{ kwtrz\u20ac \u00d0t\ufffds \ufffdsozork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac1 L~{y \ufffdst\u20ac. \u00d0ono~t\ufffdo {\ufffd~\u20acom{zn s\u00de|{\ufffdso\u20act\u20ac>\nH2>Asubmission withatitleconveying anegativesentiment willreceivegreateruserattention\nthanasubmission withapositivetitle1\nOzwtzo\u00d0t\ufffds \ufffdso|tm\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd. No\u20ac\u20acow o\ufffdkw1d:;f sk\ufffdo \u20acs{\u00d0z \ufffdsk\ufffd \ufffdtykro qok\ufffd\ufffd~o\u20ac\nkw\u00d0k\u00de\u20ac {\ufffd\ufffd|o~q{~y \ufffdo\u00f0\ufffdqok\ufffd\ufffd~o\u20ac\ufffd tz\ufffdsot~ oqqom\ufffd\u20ac {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z *\u20acoo kw\u20ac{ d55f+1 \\so~oq{~o. \u00d0o\nk~r\ufffdo \ufffdsk\ufffd \ufffdsoty|km\ufffd {qtykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo {\ufffd\ufffd\u00d0otrs\u20ac \ufffdsooqqom\ufffd {q\ufffdt\ufffdwo\u20ac m{z\ufffdo\u00detzr k\nzork\ufffdt\ufffdo \u20acoz\ufffdtyoz\ufffd1 \\s\ufffd\u20ac. {\ufffd~\ufffdst~n s\u00de|{\ufffdso\u20act\u20ac \u20ac\ufffdk\ufffdo\u20ac>\nH3>Asubmission\u2019s linkedimagewillhaveamoresubstantial effectonuserattention thanthe\nsentiment ofasubmission\u2019s title1\nV\ufffdso~ m~t\ufffdtmkw k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac \ufffdsk\ufffd ytrs\ufffd tzqw\ufffdozmo \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z mkzlo~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac |~{/\n\ufffdtno~1 \\s\ufffd\u20ac. \u00d0oo\ufffdkw\ufffdk\ufffdo \ufffdso|{wt\ufffdtmkw wokztzr\u20ac {q\ufffdsozo\u00d0\u20ac {\ufffd\ufffdwo\ufffd ~oqo~ozmon l\u00dek\u20ac\ufffdlyt\u20ac\u20act{z1\n\\so~o t\u20ackzo\u00f0\ufffdoz\u20act\ufffdo l{n\u00de {q~o\u20acok~ms kzkw\u00de\u00fetzr \ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz |{wt\ufffdtmkw tno{w{r\u00de\nkzn \u20ac\ufffd\u20acmo|\ufffdtltwt\ufffd\u00de \ufffd{\ufffdsozork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac d;5.;6f1 O\ufffdt\u20ack~r\ufffdon \ufffdsk\ufffd |o{|wo \u00d0s{ tnoz\ufffdtq\u00de k\u20ac\ufffdm{z/\n\u20aco~\ufffdk\ufffdt\ufffdo\u20ac\ufffd *k\u20ac\ufffdzno~\u20ac\ufffd{{n tz\ufffdso]1[1 m{z\ufffdo\u00f0\ufffd+ k~oy{~o ~omo|\ufffdt\ufffdo \ufffd{zork\ufffdt\ufffdt\ufffd\u00de m{y|k~on \ufffd{\n\ufffds{\u20aco \u00d0s{ tnoz\ufffdtq\u00de k\u20acwtlo~kw\u20ac *k\u20ac\ufffdzno~\u20ac\ufffd{{n tz\ufffdso]1[1 m{z\ufffdo\u00f0\ufffd+ d;5f. kw\ufffds{\ufffdrs \u20ac{yo ~omoz\ufffd\n\u20ac\ufffd\ufffdnto\u20ac sk\ufffdo mskwwozron \ufffdso\u20aco qtzntzr\u20ac d;6f1 Gk\u20acon {z\ufffdso\u20aco m{z\u20actno~k\ufffdt{z\u20ac. \u00d0ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd\nm{z\u20aco~\ufffdk\ufffdt\ufffdo zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac m{\ufffdo~ r~ok\ufffdo~ ky{\ufffdz\ufffd\u20ac {q\ufffdt{woz\ufffd kzn zork\ufffdt\ufffdo m{z\ufffdoz\ufffd \ufffdskz {\ufffdso~\n{\ufffd\ufffdwo\ufffd\u20ac \u20actzmo \ufffdso\u00de kwtrz \u00d0t\ufffds \ufffdsot~ k\ufffdntozmo)\u20ac o\u00f0|om\ufffdk\ufffdt{z\u20ac {qzo\u00d0\u20ac ~o|{~\ufffdtzr d;7f *{|ozzo\u20ac\u20ac \ufffd{\nzork\ufffdt\ufffdo zo\u00d0\u20ac+1 Ozwtzo\u00d0t\ufffds \ufffdsozork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac. \u00d0ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd \ufffdst\u20ac\ufffd\u00de|o {q~o|{~\ufffdtzr \u20acs{\ufffdwn\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 <25=\nwokn \ufffd{kstrso~ wo\ufffdow {q\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y|k~on \ufffd{wtlo~kw {~zo\ufffd\ufffd~kw ~o|{~\ufffdtzr1 Nozmo. {\ufffd~\nq{\ufffd~\ufffds s\u00de|{\ufffdso\u20act\u20ac t\u20ac>\nH4>Asubmission thatincludesalinktoaconservative newsoutletwillreceivegreateruseratten-\ntionthanasubmission thatincludesalinktoaliberalorneutralnewsoutlet1\nStvo\u00d0t\u20aco. kzo\u00d0\u20ac k~\ufffdtmwo)\u20ac wo\ufffdow {q\ufffd~\ufffd\ufffdsq\ufffdwzo\u20ac\u20ac sk\u20ackyku{~ oqqom\ufffd {z\ufffd\u20aco~ ozrkroyoz\ufffd kzn\nk\ufffd\ufffdoz\ufffdt{z {z\u20ac{mtkw yontk1 Zo\u20acok~ms sk\u20ac\u20acs{\u00d0z \ufffdsk\ufffd qkw\u20aco zo\u00d0\u20ac. tz|k~\ufffdtm\ufffdwk~. \ufffdntqq\ufffd\u20acon \u20actrztqt/\nmkz\ufffdw\u00de qk~\ufffdso~. qk\u20ac\ufffdo~. noo|o~. kzn y{~o l~{knw\u00de\ufffd d;9f {z\u20ac{mtkw yontk. \ufffds\ufffd\u20ac ~okmstzr kl~{kno~\nk\ufffdntozmo kzn ~omot\ufffdtzr r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 Gk\u20acon {z\ufffdst\u20acnt\u20acm~o|kzm\u00de lo\ufffd\u00d0ooz \ufffd~\ufffdo kzn\nqkw\u20aco zo\u00d0\u20ac. \u00d0ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd kzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac wo\ufffdow {qqkm\ufffd\ufffdkw ~o|{~\ufffdtzr \u00d0twwtzqw\ufffdozmo \ufffd\u20aco~ k\ufffd\ufffdoz/\n\ufffdt{z1 \\s\ufffd\u20ac. zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac \ufffdsk\ufffd k~ovz{\u00d0z q{~kwo\u20ac\u20ac/qkm\ufffd\ufffdkw ~o|{~\ufffdtzr \u20ac\ufffd\u00dewo *\ufffdqkw\u20aco zo\u00d0\u20ac\ufffd+ \u00d0tww\n~omot\ufffdo r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \ufffdskz {\ufffd\ufffdwo\ufffd\u20ac \ufffdsk\ufffd knso~o \ufffd{ky{~o qkm\ufffd\ufffdkw \u20ac\ufffd\u00dewo {q~o|{~\ufffdtzr\n*\ufffd\ufffd~\ufffdo zo\u00d0\u20ac\ufffd+1 V\ufffd~ qtq\ufffds s\u00de|{\ufffdso\u20act\u20ac t\u20ac>\nH5>Asubmission thatincludesalinktoaless-factual newsoutletwillreceivegreateruseratten-\ntionthanasubmission thatincludesalinktoahighlyfactualnewsoutlet1\nT{~o{\ufffdo~. kzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac rozo~kw wo\ufffdow {q|~{ytzozmo m{\ufffdwn kqqom\ufffd \ufffdsowo\ufffdow {qk\ufffd\ufffdoz\ufffdt{z k\n\ufffd\u20aco~ |k\u00de\u20ac \ufffd{k\u20ac\ufffdlyt\u20ac\u20act{z \ufffdsk\ufffd ~oqo~ozmo\u20ac t\ufffd1\\so~oq{~o. \u00d0okw\u20ac{ \ufffdo\u20ac\ufffdq{~\ufffdsowtzvon zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac\n\ufffd~kqqtm l\u00dek\u20ac\u20ac\ufffdytzr \ufffdsk\ufffd \ufffds{\u20aco \u00d0t\ufffds y{~o \ufffd~kqqtm k~oy{~o |{|\ufffdwk~ kzn \ufffds\ufffd\u20ac ~omot\ufffdo r~ok\ufffdo~ \ufffd\u20aco~\nk\ufffd\ufffdoz\ufffdt{z1 Nozmo. {\ufffd~\u20act\u00f0\ufffds s\u00de|{\ufffdso\u20act\u20ac \u20ac\ufffdk\ufffdo\u20ac>\nH6>Asubmission thatincludesalinktoapopularnewsoutletwithhightrafficwillreceive\ngreateruserattention thanasubmission withalinktoaless-popular newsoutletwithmini-\nmalormediumtraffic1\nLtzkww\u00de. \u00d0oo\u00f0kytzo k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{Zonnt\ufffd/\u20ac|omtqtm m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn|wk\ufffdq{~y kqq{~/\nnkzmo\u20ac \ufffd\ufffdsk\ufffd \u20acsk|o s{\u00d0 |o{|wo ozrkro \u00d0t\ufffds d{zwtzof oz\ufffdt~{zyoz\ufffd\u20ac\ufffd d;:f kzn \ufffds\ufffd\u20ac m{\ufffdwn sk\ufffdo kz\noqqom\ufffd {zk\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\u20actltwt\ufffd\u00de kzn. tz\ufffd\ufffd~z. \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 Oz{\ufffd~kzkw\u00de\u20act\u20ac. \u00d0oo\ufffdkw\ufffdk\ufffdo nk\ufffdk\nq~{y \ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac ~2|{wt\ufffdtm\u20ac. ~2zo\u00d0\u20ac. kzn~2\u00d0{~wnzo\u00d0\u20ac1 Vq\ufffdso\u20aco. {zw\u00de ~2|{wt\ufffdtm\u20ac kww{\u00d0\u20ac\n\ufffdso|{\u20ac\ufffdtzr {q\ufffds\ufffdylzktw tykro\u20ac. kzn\u20ac{\u00d0ok\u20ac\u20ac\ufffdyo\u02d8tz wtzo\u00d0t\ufffds {\ufffd~k\u20ac\u20ac\ufffdy|\ufffdt{z\u20ac ~ork~ntzr \ufffdso\n|tm\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd\u02d8\ufffdsk\ufffd \u20ac\ufffdlyt\u20ac\u20act{z\u20ac tz\ufffdst\u20ac\u20ac\ufffdl~onnt\ufffd ~omot\ufffdo r~ok\ufffdo~ k\ufffd\ufffdoz\ufffdt{z \ufffdskz \u20ac\ufffdl/\nyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon tz\ufffdso{\ufffdso~ \ufffd\u00d0{*q{~y{~o tzq{~yk\ufffdt{z ~ork~ntzr \ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac kzkw\u00de\u00feon. \u20acoo\n\u20acom\ufffdt{z \ufffd[{mtkw yontk |wk\ufffdq{~y Zonnt\ufffd\ufffd+1 G\u00dem{z\ufffd~{wwtzr q{~\ufffdso\u20ac\ufffdl~onnt\ufffd tz\u00d0stms k\u20ac\ufffdlyt\u20ac\u20act{z\n\u00d0k\u20ac|{\u20ac\ufffdon. \u00d0okw\u20ac{ kmm{\ufffdz\ufffd q{~ntqqo~oz\ufffd m{yy\ufffdzt\ufffd\u00de \u20act\u00feo\u20ac. kzn\ufffdsk\ufffd |{\u20ac\ufffdtzr tzy{~o |{|\ufffdwk~\n\u20ac\ufffdl~onnt\ufffd\u20ac m{\ufffdwn wokn \ufffd{r~ok\ufffdo~ o\u00f0|{\u20ac\ufffd~o kzn. \ufffdso~oq{~o. r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z\u02d8{~. tzm{z\ufffd~k\u20ac\ufffd.\n\ufffd{wo\u20ac\u20ac\ufffdt\u20actltwt\ufffd\u00de n\ufffdo\ufffd{r~ok\ufffdo~ m{y|o\ufffdt\ufffdt{z q{~k\ufffd\ufffdoz\ufffdt{z \u00d0t\ufffds {\ufffdso~ |{\u20ac\ufffd\u20ac d:=f1\n_okw\u20ac{ tzmw\ufffdno \u00d0so\ufffdso~ k\u20ac\ufffdlyt\u20ac\u20act{z t\u20acqwkrron k\u20ac\ufffdU{\ufffd [kqo q{~_{~v *U[L_+.\ufffd \u00d0stms. tz\n{\ufffd~m{z\ufffdo\u00f0\ufffd. wtvow\u00de ty|wto\u20ac \ufffdsono|tm\ufffdt{z {qkstrso~ nor~oo {q*|s\u00de\u20actmkw+ \ufffdt{wozmo \u00d0t\ufffdstz \ufffdso\nk\ufffd\ufffdkmson zo\u00d0\u20ac wtzv1 Gk\u20acon {z{\ufffd~|~o\ufffdt{\ufffd\u20ac k\u20ac\u20ac\ufffdy|\ufffdt{z\u20ac ~ork~ntzr \ufffdsooqqom\ufffd {q\ufffdt{wozmo {z\ufffd\u20aco~\nk\ufffd\ufffdoz\ufffdt{z. \u00d0oo\u00f0|om\ufffd k|{\u20act\ufffdt\ufffdo ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdU[L_\ufffd \u20ac\ufffdlyt\u20ac\u20act{z\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1\nL\ufffd~\ufffdso~. \u00d0oknn\u00d0so\ufffdso~ k\u20ac\ufffdlyt\u20ac\u20act{z ~omot\ufffdo\u20ac \u00d0sk\ufffd Zonnt\ufffd mkww\u20ac k\ufffdqwkt~ \ufffdkr.\ufffd \u00d0stms. tz{\ufffd~\nmk\u20aco. tzntmk\ufffdo\u20ac \ufffdsk\ufffd \ufffdso\u20ac\ufffdl~onnt\ufffd)\u20ac y{no~k\ufffd{~\u20ac m{yyoz\ufffdon {z\ufffdso\u20ac\ufffdlyt\u20ac\u20act{z1 I{z\u20actno~tzr\n\ufffdsk\ufffd {\ufffd~\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac k~ovz{\u00d0z \ufffd{q{ww{\u00d0 \u20ac\ufffd~tm\ufffd \u20ac\ufffdlyt\u20ac\u20act{z r\ufffdtnowtzo\u20ac *\u20acoo \ufffdsoq~{z\ufffd |kro\n{qokms \u20ac\ufffdl~onnt\ufffd+. \u00d0ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds kqwkt~ \ufffdkrsk\ufffdo \u20ac{yos{\u00d0 \ufffdt{wk\ufffdon \ufffdso\u20ac\ufffdl/\nyt\u20ac\u20act{z r\ufffdtnowtzo\u20ac l\u00de.q{~o\u00f0ky|wo. lotzr {\ufffd\ufffd{qnk\ufffdo {~t~~owo\ufffdkz\ufffd \ufffd{\ufffdso\u20ac\ufffdl~onnt\ufffd1 Gk\u20acon {z\n\ufffdso\u20aco m{z\u20actno~k\ufffdt{z\u20ac. \u00d0ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds kqwkt~ \ufffdkr~omot\ufffdo wo\u20ac\u20ac\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1\nLtzkww\u00de. \u00d0om{z\ufffd~{w s{\u00d0 {q\ufffdoz k\u20ac\ufffdlyt\u20ac\u20act{z sk\u20aclooz m~{\u20ac\u20ac/|{\u20ac\ufffdon. \ufffdsk\ufffd t\u20ac.|{\u20ac\ufffdon k\u20ackzo\u00d0\n\u20ac\ufffdlyt\u20ac\u20act{z \ufffd{{\ufffdso~ \u20ac\ufffdl~onnt\ufffd\u20ac1 O\ufffd\u20acooy\u20ac |wk\ufffd\u20actlwo \ufffd{k\u20ac\u20ac\ufffdyo \ufffdsk\ufffd o\u00f0|{\u20ac\ufffd~o \ufffd{kl~{kno~ k\ufffdnt/\nozmo kw\u20ac{ k\ufffd\ufffd~km\ufffd\u20ac r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \ufffd{\ufffdsotzt\ufffdtkw \u20ac\ufffdlyt\u20ac\u20act{z1 _o. \ufffdso~oq{~o. k\u20ac\u20ac\ufffdyo k|{\u20act/\n\ufffdt\ufffdo~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdsoz\ufffdylo~ {qm~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 =25=\n[\ufffdyyk~t\u00fetzr \ufffdso\u20aco k\u20ac\u20ac\ufffdy|\ufffdt{z\u20ac ~ork~ntzr \ufffdsoZonnt\ufffd/\u20ac|omtqtm kqq{~nkzmo\u20ac kzn m{yy\ufffdzt\ufffd\u00de\n~\ufffdwo\u20ac. {\ufffd~qtzkw q{\ufffd~ s\u00de|{\ufffdso\u20aco\u20ac k~o>\nH7>Asubmission postedinr/politics willreceivegreateruserattention thanasubmission posted\ninr/newsorr/worldnews1\nH8>Userswillpaygreaterattention tosubmissions flaggedas\u201cNSFW\u201d thantononflagged\nsubmissions1\nH9>Asubmission withaflairtagwillreceivelessuserattention thanasubmission withoutaflair\ntag1\nH10>Thenumberofasubmission\u2019s cross-posts willpositively affectuserattention1\n_otzmw\ufffdno knnt\ufffdt{zkw m{z\ufffd~{w \ufffdk~tklwo\u20ac \ufffd{m{z\ufffd~{w q{~m{z\ufffdo\u00f0\ufffd\ufffdkw qkm\ufffd{~\u20ac \ufffdsk\ufffd m{\ufffdwn kqqom\ufffd\n\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zwtzo1 _om{z\ufffd~{w q{~\ufffdso\ufffdtytzr kzn nk\ufffdo {qk\u20ac\ufffdlyt\u20ac\u20act{z. k\u20acZonnt\ufffd t\u20ack\nn\u00dezkytm oz\ufffdt~{zyoz\ufffd \u00d0t\ufffds \ufffdk~\u00detzr k\ufffd\ufffdoz\ufffdt{z nt\u20ac\ufffd~tl\ufffd\ufffdt{z {\ufffdo~ \ufffdtyo d:;f1 L\ufffd~\ufffdso~. \u00d0o\ufffdo\u20ac\ufffd\n\u00d0so\ufffdso~ \ufffdso\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd ~oqo~ozmon tzk\u20ac\ufffdlyt\u20ac\u20act{z tzqw\ufffdozmo\u20ac \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 _ontq/\nqo~oz\ufffdtk\ufffdo lo\ufffd\u00d0ooz ntrt\ufffdkw/l{~z zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac *\u00d0ol\u20act\ufffdo\u20ac+ kzn \ufffdsontrt\ufffdkw o\u00f0\ufffdoz\u20act{z {q\ufffd~knt\ufffdt{zkw\nzo\u00d0\u20ac yontk *o1r1. \\^\u20ac\ufffdk\ufffdt{z\u20ac kzn zo\u00d0\u20ac|k|o~\u20ac+ \u20actzmo\u02d8rozo~kww\u00de \u20ac|okvtzr\u02d8l{\ufffds \ufffd\u00de|o\u20ac {qyontk\nwtvow\u00de nt\u20ac|wk\u00de kntqqo~oz\ufffd wo\ufffdow {q|~{qo\u20ac\u20act{zkwt\u20acy kzn q{ww{\u00d0 kntqqo~oz\ufffd w{rtm {qzo\u00d0\u20ac ~o|{~\ufffdtzr\n*\u20acoo \u20acom\ufffdt{z \ufffdZowk\ufffdon wt\ufffdo~k\ufffd\ufffd~o\ufffd+. \u00d0stms ytrs\ufffd ty|km\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z ntqqo~oz\ufffdw\u00de1\nTk\ufffdo~tkw\ufffd kzn yo\ufffds{n\ufffd\nV|o~k\ufffdt{zkwt\u00fek\ufffdt{z {q\ufffdk~tklwo\u20ac\nF\ufffd\ufffdoz\ufffdt{z t\u20ackl~{kn m{zmo|\ufffd l\ufffd\ufffdmkzlonoqtzon rozo~kww\u00de k\u20ac>\ufffdU{\ufffdtmo \ufffdkvoz {q\u20ac{yo{zo {~\n\u20ac{yo\ufffdstzr? \ufffdso~ork~ntzr {q\u20ac{yo{zo {~\u20ac{yo\ufffdstzr k\u20actz\ufffdo~o\u20ac\ufffdtzr {~ty|{~\ufffdkz\ufffd\ufffd d;;f1 \\so~o\nk~o\u20aco\ufffdo~kw \u00d0k\u00de\u20ac \ufffd{tz\ufffdo~km\ufffd \u00d0t\ufffds |{\u20ac\ufffd\u20ac kzn \ufffd\ufffdkvo z{\ufffdtmo\ufffd {qk|k~\ufffdtm\ufffdwk~ \u20ac\ufffdlyt\u20ac\u20act{z {z\u20ac{mtkw\nyontk1 Oz\ufffdsomk\u20aco {qZonnt\ufffd. \u00d0o{|o~k\ufffdt{zkwt\u00feo {\ufffd~no|oznoz\ufffd \ufffdk~tklwo. \ufffd\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z.\ufffd \u00d0t\ufffds\n\ufffdsoz\ufffdylo~ {qm{yyoz\ufffd\u20ac |{\u20ac\ufffdon {zokms \u20ac\ufffdlyt\u20ac\u20act{z1 \\st\u20ac |~{\u00f0\u00de {qqo~\u20ac kztzntmk\ufffdt{z {q\n\u00d0so\ufffdso~ \ufffd\u20aco~\u20ac tz\ufffdo~km\ufffdon \u20ac\ufffdl\u20ac\ufffdkz\ufffdtkww\u00de \u00d0t\ufffds k\u20ac\ufffdlyt\u20ac\u20act{z d55f \ufffdsk\ufffd \u20acooy\u20ac \ufffd{lo|k~\ufffdtm\ufffdwk~w\u00de |{|/\n\ufffdwk~ tzk|{wt\ufffdtmkw zo\u00d0\u20ac m{z\ufffdo\u00f0\ufffd d;<f kzn \ufffds\ufffd\u20ac |ktn k\ufffd\ufffdoz\ufffdt{z \ufffd{t\ufffd1V\ufffdso~ k\ufffd\ufffdoz\ufffdt{z yok\u20ac\ufffd~o\u20ac.\n\u20ac\ufffdms k\u20ac\ufffd|/{~n{\u00d0z\ufffd{\ufffdtzr {zk\u20ac\ufffdlyt\u20ac\u20act{z. mkzlo\u20acooz k\u20ackzo\u00f0|~o\u20ac\u20act{z {q\u00d0so\ufffdso~ k\u20ac\ufffdlyt\u20ac/\n\u20act{z)\u20ac m{z\ufffdoz\ufffd kwtrz\u20ac \u00d0t\ufffds \ufffdsom{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac {qk\u20ac\ufffdl~onnt\ufffd d;=f kzn \ufffds\ufffd\u20ac tzntmk\ufffdo\u20ac }\ufffdkwt\ufffd\u00de\nm{z\ufffd~{w ~k\ufffdso~ \ufffdskz lotzr kyok\u20ac\ufffd~o {q\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\so~oq{~o. \u00d0o{|o~k\ufffdt{zkwt\u00feo {\ufffd~no|oz/\nnoz\ufffd \ufffdk~tklwo. \ufffd\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z.\ufffd \u00d0t\ufffds \ufffdsont\u20acm~o\ufffdo \ufffdk~tklwo. \ufffdz\ufffdylo~ {qm{yyoz\ufffd\u20ac1\ufffd *\\{\u20ac\ufffd\u20ac\ufffdktz\n{\ufffd~~o\u20ac\ufffdw\ufffd\u20ac. s{\u00d0o\ufffdo~. \u00d0okw\u20ac{ ~kzkzork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now \ufffdsk\ufffd \ufffdkvo\u20ac tz\ufffd{ kmm{\ufffdz\ufffd\n\ufffdsoz\ufffdylo~ {q\ufffd|/kzn n{\u00d0z\ufffd{\ufffdo\u20ac k\u20ackzo\u00f0|~o\u20ac\u20act{z {q\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 bo\ufffd. kw\u20ac{ \u00d0t\ufffds \ufffdst\u20acyok/\n\u20ac\ufffd~o. \ufffdsoyktz oqqom\ufffd\u20ac ~oyktz \ufffdso\u20ackyo1 L{~y{~o tzq{~yk\ufffdt{z. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk/\n\ufffdt{z. Uork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now\u20ac+1\n_o\ufffd\u20aco\ufffdsom{z\u20aco~\ufffdk\ufffdt\ufffdo noqtzt\ufffdt{z l\u00deZ\ufffdms\ufffd tz\ufffd~{n\ufffdmon tz\u20acom\ufffdt{z \ufffd\\so{~\u00de kzn s\u00de|{\ufffdso/\n\u20aco\u20ac\ufffd \ufffd{mk|\ufffd\ufffd~o \ufffdsom{y|wo\u00f0 m{zmo|\ufffd {q\ufffdt{wozmo *H1+1 Nozmo. \ufffd{lomwk\u20ac\u20actqton k\u20ac\ufffd\ufffdt{woz\ufffd.\ufffd kz\ntykro y\ufffd\u20ac\ufffd \u20acs{\u00d0 |s\u00de\u20actmkw sk~y \ufffd{|~{|o~\ufffd\u00de {~|o{|wo *tz\ufffdsomk\u20aco {q\ufffdsoGST y{\ufffdoyoz\ufffd. o1r1.\nw{{\ufffdtzr \u20acs{|\u20ac {~\ufffd\u20actzr |o||o~ \u20ac|~k\u00de krktz\u20ac\ufffd |~{\ufffdo\u20ac\ufffd{~\u20ac+1 Oykro\u20ac \u20acs{\u00d0tzr {zw\u00de \ufffdytz{~\ufffd \ufffdt{/\nwozmo. \u20ac\ufffdms k\u20ac\ufffdo~lkw k\u20ac\u20ack\ufffdw\ufffd {~|~{\ufffd{mk\ufffdt\ufffdo ro\u20ac\ufffd\ufffd~o\u20ac. k~oz{\ufffdm{non k\u20ac\ufffd\ufffdt{woz\ufffd1\ufffd F\u20ac\u20ac\ufffdk\ufffdon\nloq{~o. \u00d0otz\ufffdoz\ufffdt{zkww\u00de k||w\u00de \ufffdst\u20acm{z\u20aco~\ufffdk\ufffdt\ufffdo noqtzt\ufffdt{z {q\ufffdt{wozmo lomk\ufffd\u20aco. qt~\u20ac\ufffd. tz\ufffdso\nGST m{z\ufffdo\u00f0\ufffd. \ufffdso~o \u00d0o~o \u20actrztqtmkz\ufffd km\ufffd\u20ac {q\ufffdt{wozmo l\u00de|~{\ufffdo\u20ac\ufffd{~\u20ac \u00d0s{ w{{\ufffdon \u20acs{|\u20ac kzn |{wtmo\n{qqtmo~\u20ac k\ufffd\ufffdkmvtzr \ufffdso|~{\ufffdo\u20ac\ufffd{~\u20ac \u00d0t\ufffds \ufffd|o||o~ \u20ac|~k\u00de. \ufffdok~ rk\u20ac.kzn ~\ufffdllo~ l\ufffdwwo\ufffd\u20ac\ufffd d5=f1 Nozmo.\n\u00d0ok~o{|\ufffdtyt\u20ac\ufffdtm kl{\ufffd\ufffd rk\ufffdso~tzr oz{\ufffdrs yokztzrq\ufffdw nk\ufffdk1 _okw\u20ac{ kz\ufffdtmt|k\ufffdo \ufffdsk\ufffd \ufffdsom{z\u20aco~/\n\ufffdk\ufffdt\ufffdo noqtzt\ufffdt{z {q\ufffdt{wozmo \u00d0twwwokn \ufffd{y{~o |~omt\u20aco ~o\u20ac\ufffdw\ufffd\u20ac l\u00dek\u20ac\u20ac\ufffdytzr \ufffdsk\ufffd ky{~o o\u00f0\ufffd~oyo\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4325=\n\ufffdt\u20ac\ufffdkw nt\u20ac|wk\u00de {q\ufffdt{wozmo k\ufffd\ufffd~km\ufffd\u20ac r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 L{~{\ufffd~k\ufffd\ufffd{yk\ufffdon tykro mwk\u20ac\u20actqtmk/\n\ufffdt{z. \u00d0ontms{\ufffd{y{\ufffd\u20acw\u00de m{no k\ufffdt{woz\ufffd tykro k\u20ac\ufffd4\ufffdkzn kz{z\ufffdt{woz\ufffd tykro k\u20ac\ufffd31\ufffd\nF\u20acH2tzntmk\ufffdo\u20ac. \ufffdt\ufffdwo\u20ac {q\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds zork\ufffdt\ufffdo m{zz{\ufffdk\ufffdt{z\u20ac m{\ufffdwn |{\u20act\ufffdt\ufffdow\u00de ty|km\ufffd\n\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\{mwk\u20ac\u20actq\u00de \ufffdsom{zz{\ufffdk\ufffdt{z {qokms \u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\ufffdwo k\u20acot\ufffdso~ \ufffdzork\ufffdt\ufffdo\ufffd {~\n\ufffd|{\u20act\ufffdt\ufffdo.\ufffd \u00d0o\ufffd\ufffdtwt\u00feo kGKZ\\ y{now d<3f k\u20act\ufffdno|tm\ufffd\u20ac {zo{q\ufffdsoy{\u20ac\ufffd |~{ytzoz\ufffd kzn \u20ac\ufffdk\ufffdo/{q/\n\ufffdso/k~\ufffd wkzr\ufffdkro y{now\u20ac q{~\u20acoz\ufffdtyoz\ufffd kzkw\u00de\u20act\u20ac d\u20acoo. o1r1. <4f1 GKZ\\ t\u20ack\ufffd~kz\u20acq{~yo~ y{now\n\ufffdsk\ufffd mkzmk|\ufffd\ufffd~o \ufffdsom{z\ufffdo\u00f0\ufffd {qk\u20acoz\ufffdozmo l\u00dem{z\u20actno~tzr \ufffdsoltnt~om\ufffdt{zkw no|oznozmto\u20ac\nlo\ufffd\u00d0ooz \u00d0{~n\u20ac \u00d0t\ufffdstz k\u20acoz\ufffdozmo d<3f1 \\s\ufffd\u20ac. \ufffdsoy{now {\ufffd\ufffd|o~q{~y\u20ac \u20acty|wo~ k||~{kmso\u20ac \u20ac\ufffdms\nk\u20aclkr/{q/\u00d0{~n y{now\u20ac \ufffdsk\ufffd k~ontm\ufffdt{zk~\u00de/lk\u20acon kzn n{z{\ufffdkmm{\ufffdz\ufffd q{~\ufffdsom{z\ufffdo\u00f0\ufffd {q\ufffdso\nmwk\u20ac\u20actqton \u20acoz\ufffdozmo d\u20acoo. o1r1. <4f1 L{~{\ufffd~kzkw\u00de\u20act\u20ac. \u00d0o\ufffd\u20aco\ufffdso\ufffdGKZ\\ lk\u20aco y{now \ufffdzmk\u20acon.\ufffd\n\u00d0stms \u00d0ono~t\ufffdon q~{y \ufffdsoN\ufffdrrtzr Lkmo |wk\ufffdq{~y d<5f1 \\so y{now t\u20ac\ufffd~ktzon {zKzrwt\u20acs _tvt/\n|ontk kzn \ufffdsoG{{vI{~|\ufffd\u20ac nk\ufffdk d<3f kzn m{z\ufffdktz\u20ac 443ytwwt{z |k~kyo\ufffdo~\u20ac1 \\{m\ufffd\u20ac\ufffd{yt\u00feo \ufffdso\ny{now q{~mwk\u20ac\u20actq\u00detzr \ufffdso\u20acoz\ufffdtyoz\ufffd {qzo\u00d0\u20ac k~\ufffdtmwo\u20ac. \u00d0o\ufffd~ktzon \ufffdsoy{now \u00d0t\ufffds \ufffdsoUo\u00d0\u20acT\\[I\nnk\ufffdk\u20aco\ufffd d<6f. kwklowon nk\ufffdk\u20aco\ufffd q{~\u20acoz\ufffdtyoz\ufffd mwk\u20ac\u20actqtmk\ufffdt{z {q|{wt\ufffdtmkw zo\u00d0\u20ac k~\ufffdtmwo\u20ac m{z\ufffdktztzr\n\ufffdsomk\ufffdor{~to\u20ac |{\u20act\ufffdt\ufffdo. zork\ufffdt\ufffdo. kzn zo\ufffd\ufffd~kw1 [tzmo \u00d0ok~otz\ufffdo~o\u20ac\ufffdon tz|{\u20act\ufffdt\ufffdo kzn zork\ufffdt\ufffdo\n\u20acoz\ufffdtyoz\ufffd mwk\u20ac\u20actqtmk\ufffdt{z. \u00d0on~{||on \ufffdsozo\ufffd\ufffd~kw \u20acky|wo\u20ac q~{y \ufffdso\ufffd~ktztzr. \ufffdkwtnk\ufffdt{z. kzn \ufffdo\u20ac\ufffd\nnk\ufffdk\u20aco\ufffd1 Fq\ufffdo~ \ufffd~ktztzr. \ufffdsoy{now ~omot\ufffdo\u20ac k\ufffd~ktztzr kmm\ufffd~km\u00de {q==14;&. k\ufffdkwtnk\ufffdt{z kmm\ufffd~km\u00de\n{q<;1::&. kzn k\ufffdo\u20ac\ufffdkmm\ufffd~km\u00de {q<;173& *q{~ y{~o tzq{~yk\ufffdt{z {z\ufffdsonk\ufffdk ~on\ufffdm\ufffdt{z. \ufffdso\n\ufffd~ktztzr. kzn \ufffdkwtnk\ufffdt{z {q\ufffdsoy{now. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. [oz\ufffdtyoz\ufffd y{now+1\nOzknnt\ufffdt{z. \ufffd{o\ufffdkw\ufffdk\ufffdo \ufffdsooqqom\ufffd {q\u20acoz\ufffdtyoz\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z o\ufffdoz y{~o r~kz\ufffdwk~w\u00de. \u00d0o~kz\nkz{\ufffdso~ zork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now \u00d0t\ufffds ntqqo~oz\ufffd \u20acoz\ufffdtyoz\ufffd \ufffdk~tklwo\u20ac. \u00d0stms. s{\u00d0/\no\ufffdo~. \u00detown\u20ac kwy{\u20ac\ufffd \u20actytwk~ ~o\u20ac\ufffdw\ufffd\u20ac *q{~ y{~o tzq{~yk\ufffdt{z. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z.\nUork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now\u20ac+1\n\\{wklow \ufffdsomk\ufffdor{~tmkw \ufffdk~tklwo\u20ac ~owk\ufffdon \ufffd{wtzvon zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac. \u00d0o\ufffd\u20acotzq{~yk\ufffdt{z\n~o\ufffd~to\ufffdon q~{y \ufffdso\u00d0ol\u20act\ufffdo yontkltk\u20acqkm\ufffdmsomv1m{y. \u00d0stms t\u20ac\u00d0tnow\u00de k||wton tz~o\u20acok~ms d6;f1\n_oykz\ufffdkww\u00de wklow okms zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac \ufffd|{wt\ufffdtmkw wokztzr\ufffd *H4+. \ufffdqkm\ufffd\ufffdkw ~o|{~\ufffdtzr\ufffd *H5+. kzn\n\ufffd\ufffd~kqqtm\ufffd *H6+ kmm{~ntzr \ufffd{\ufffdso~o\u20ac|om\ufffdt\ufffdo mwk\u20ac\u20actqtmk\ufffdt{z\u20ac l\u00deyontkltk\u20acqkm\ufffdmsomv1m{y 1Oq\u00d0on{\nz{\ufffdqtzn kwwtzq{~yk\ufffdt{z {z\ufffdsozo\u00d0\u20ac {\ufffd\ufffdwo\ufffd. \u00d0om{no \ufffdso{l\u20aco~\ufffdk\ufffdt{z k\u20acyt\u20ac\u20actzr kzn n~{| \ufffdso\n\u20ac\ufffdlyt\u20ac\u20act{z1\nFq\ufffdo~ m{ntzr {\ufffd~nk\ufffdk. \u00d0oyo~ro \u20ac{yo wklow\u20ac \ufffd{k\ufffd{tn \u20acykwwnnt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac \u00d0t\ufffdstz kmk\ufffdor{~\u00de\nkzn {l\ufffdktz y{~o \u20ac{\ufffdzn ~o\u20ac\ufffdw\ufffd\u20ac1 \\s\ufffd\u20ac. {\ufffd~\ufffdk~tklwo \ufffd|{wt\ufffdtmkw wokztzr\ufffd t\u20acm{y|~t\u20acon {q\ufffdsowklow\u20ac\n\ufffdwtlo~kw\ufffd *yo~rtzr \ufffdso\ufffdwoq\ufffd.\ufffd \ufffdwoq\ufffd/moz\ufffdo~.\ufffd kzn \ufffdqk~woq\ufffd\ufffd mk\ufffdor{~to\u20ac+. \ufffdm{z\u20aco~\ufffdk\ufffdt\ufffdo\ufffd *yo~rtzr\n\ufffdso\ufffd~trs\ufffd.\ufffd \ufffd~trs\ufffd/moz\ufffdo~.\ufffd \ufffdqk~~trs\ufffd.\ufffd \ufffdo\u00f0\ufffd~oyo ~trs\ufffd.\ufffd kzn \ufffdqk~~trs\ufffd m{z\u20ac|t~km\u00de |\u20aco\ufffdn{\u20acmt/\nozmo\ufffd mk\ufffdor{~to\u20ac+. \ufffdm{z\u20ac|t~km\u00de\ufffd *yo~rtzr \ufffdso\ufffdm{z\u20ac|t~km\u00de.\ufffd \ufffdu\ufffdzv zo\u00d0\u20ac.\ufffd kzn \ufffdm{z\u20ac|t~km\u00de |\u20aco\ufffd/\nn{\u20acmtozmo\ufffd mk\ufffdor{~to\u20ac+. kzn \ufffdzo\ufffd\ufffd~kw\ufffd *yo~rtzr \ufffdso\ufffdwok\u20ac\ufffd ltk\u20ac\ufffd kzn \ufffd|~{/\u20acmtozmo\ufffd mk\ufffdor{~to\u20ac+1\n\\so \ufffdk~tklwo \ufffdqkm\ufffd\ufffdkw ~o|{~\ufffdtzr\ufffd m{z\u20act\u20ac\ufffd\u20ac {q\ufffdsowklow\u20ac \ufffdstrs\ufffd *yo~rtzr \ufffdstrs\ufffd kzn \ufffd\ufffdo~\u00de strs\ufffd+.\n\ufffdyt\u00f0on\ufffd *yo~rtzr \ufffdyt\u00f0on\ufffd kzn \ufffdy{\u20ac\ufffdw\u00de\ufffd+. kzn \ufffdw{\u00d0\ufffd *yo~rtzr \ufffdw{\u00d0\ufffd kzn \ufffd\ufffdo~\u00de w{\u00d0\ufffd+1 Ltzkww\u00de.\n\ufffdso\ufffdk~tklwo \ufffd\ufffd~kqqtm\ufffd t\u20ac\u20ac|wt\ufffd tz\ufffd{ \ufffdsowklow\u20ac \ufffdstrs.\ufffd \ufffdyont\ufffdy.\ufffd kzn \ufffdytztykw1\ufffd\n\\so ~oyktztzr Zonnt\ufffd/\u20ac|omtqtm m{yy\ufffdzt\ufffd\u00de kzn kqq{~nkzmo \ufffdk~tklwo\u20ac k~om{non k\u20acq{ww{\u00d0\u20ac>\n\ufffdsomk\ufffdor{~tmkw \ufffdk~tklwo \ufffd\u20ac\ufffdl~onnt\ufffd\ufffd *H7+ t\u20acnt\ufffdtnon tz\ufffd{ \ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac. \ufffd~2|{wt\ufffdtm\u20ac.\ufffd \ufffd~2\nzo\u00d0\u20ac.\ufffd kzn \ufffd~2\u00d0{~wnzo\u00d0\u20ac\ufffd? l{\ufffds \ufffdk~tklwo\u20ac \ufffdU[L_\ufffd *H8+ kzn \ufffdwtzv qwkt~\ufffd *H9+ k~oltzk~\u00de kzn\nm{non k\u20ac\ufffd3\ufffdtq\ufffdso\u20ac\ufffdlyt\u20ac\u20act{z \u00d0k\u20acz{\ufffdqwkrron kzn k\u20ac\ufffd4\ufffdtqt\ufffd\u00d0k\u20ac? kzn \ufffdso\ufffdk~tklwo \ufffdz\ufffdylo~ {q\nm~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac\ufffd *H10+ t\u20acnt\u20acm~o\ufffdo1\n\\{{|o~k\ufffdt{zkwt\u00feo {\ufffd~\ufffdtyo/m{z\ufffd~{w \ufffdk~tklwo\u20ac. \u00d0o|~{moon k\u20acq{ww{\u00d0\u20ac> Zonnt\ufffd \u20ac\ufffdlyt\u20ac\u20act{z\u20ac k~o\n\ufffdtyo\u20ac\ufffdky|on tz\ufffdso]\\I q{~yk\ufffd \u00d0soz ~o\ufffd~to\ufffdon q~{y \ufffdsoW\ufffd\u20acs\u20acstq\ufffd \u20ac\ufffdlyt\u20ac\u20act{z n\ufffdy|\u20ac. l\ufffd\ufffd\u00d0o\n~om{no \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds {\ufffd~\ufffdtyo/m{z\ufffd~{wwtzr mk\ufffdor{~tmkw \ufffdk~tklwo\u20ac \ufffd\u00d0oovnk\u00de2\u00d0oovozn\ufffd kzn\n\ufffd\ufffdtyo {qnk\u00de\ufffd \ufffd\u20actzr ]1[1 Wkmtqtm \ufffdtyo1 _on{\u20ac{q{~\ufffd\u00d0{~ok\u20ac{z\u20ac> knt\u20ac|~{|{~\ufffdt{zk\ufffdow\u00de strs\nz\ufffdylo~ {qZonnt\ufffd \ufffd\u20aco~\u20ac wt\ufffdotzk]1[1 \ufffdtyo \u00fe{zo d<7f? kzn \u20aco\ufffdo~kw \ufffdt{woz\ufffd GST o\ufffdoz\ufffd\u20ac sk||ozon\n{z\ufffdso_o\u20ac\ufffd I{k\u20ac\ufffd. o\u20ac|omtkww\u00de tzW{~\ufffdwkzn. V~or{z. yk~vtzr t\ufffdkzty|{~\ufffdkz\ufffd k~ok q{~*\ufffdt{woz\ufffd+\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4425=\nGST |~{\ufffdo\u20ac\ufffd d<9f1 L{~\ufffdso\ufffdk~tklwo \ufffd\u00d0oovnk\u00de2\u00d0oovozn.\ufffd \u00d0omwk\u20ac\u20actq\u00de [k\ufffd\ufffd~nk\u00de kzn [\ufffdznk\u00de k\u20ac\n\ufffd\u00d0oovozn\ufffd kzn kww{\ufffdso~ nk\u00de\u20ac {q\ufffdso\u00d0oov k\u20ac\ufffd\u00d0oovnk\u00de1\ufffd _om{no \ufffdso\ufffdk~tklwo \ufffd\ufffdtyo {qnk\u00de\ufffd k\u20ac\n\ufffdy{~ztzr\ufffd q{~\u20ac\ufffdlyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon lo\ufffd\u00d0ooz 7ky kzn 45|y. k\u20ac\ufffdkq\ufffdo~z{{z2o\ufffdoztzr\ufffd q{~\ufffds{\u20aco\n|{\u20ac\ufffdon lo\ufffd\u00d0ooz 45|y kzn <|y. kzn k\u20ac\ufffdztrs\ufffd\ufffd q{~\ufffds{\u20aco |{\u20ac\ufffdon lo\ufffd\u00d0ooz <|y kzn 7ky1\nL{~m{ntzr {\ufffd~{\ufffdso~ m{z\ufffd~{w \ufffdk~tklwo. \ufffd\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd.\ufffd \u00d0okw\u20ac{ \ufffd\u20acotzq{~yk\ufffdt{z\n~o\ufffd~to\ufffdon q~{y \ufffdso\u00d0ol\u20act\ufffdo yontkltk\u20acqkm\ufffdmsomv1m{y kzn k||w\u00de \ufffdsomk\ufffdor{~tmkw wklow\u20ac \ufffdzo\u00d0\u20ac|k/\n|o~.\ufffd \ufffdykrk\u00fetzo\ufffd *yo~rtzr \ufffdykrk\u00fetzo\ufffd kzn \ufffdu{\ufffd~zkw\ufffd+. \ufffdzo\u00d0\u20ac krozm\u00de.\ufffd \ufffd{~rkzt\u00fek\ufffdt{z2q{\ufffdznk/\n\ufffdt{z.\ufffd \ufffd~knt{ \u20ac\ufffdk\ufffdt{z\ufffd *yo~rtzr \ufffd~knt{\ufffd kzn \ufffd~knt{ \u20ac\ufffdk\ufffdt{z\ufffd+. \ufffd\\^ \u20ac\ufffdk\ufffdt{z\ufffd *yo~rtzr \ufffd\\^\n\u20ac\ufffdk\ufffdt{z\ufffd kzn \ufffd\\^ \u20ac\ufffdk\ufffdt{z2\u00d0ol\u20act\ufffdo\ufffd+. kzn \ufffd\u00d0ol\u20act\ufffdo\ufffd *yo~rtzr \ufffd\u00d0ol\u20act\ufffdo.\ufffd \ufffdk||2\u00d0ol\u20act\ufffdo.\ufffd \ufffd\u00d0ol/\n\u20act\ufffdo2zo\u00d0\u20ac|k|o~.\ufffd kzn \ufffd\u00d0ol\u20act\ufffdo2\ufffdtno{\ufffd+1 Oz{\ufffd~kzkw\u00de\u20act\u20ac. \ufffdsowk\ufffd\ufffdo~ {zot\u20acm{z\u20actno~on \ufffd{lontrt/\n\ufffdkw/l{~z yontk. kzn \ufffdso{\ufffdso~\u20ac k~om{z\u20actno~on \ufffd{lontrt\ufffdkw o\u00f0\ufffdoz\u20act{z\u20ac {q\ufffd~knt\ufffdt{zkw yontk1\n*L{~ y{~o tzq{~yk\ufffdt{z ~ork~ntzr \ufffdso\ufffdk~tklwo nt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk/\n\ufffdt{z. Jo\u20acm~t|\ufffdt\ufffdo {\ufffdo~\ufffdto\u00d0 {q\ufffdk~tklwo\u20ac1+\nJk\ufffdk m{wwom\ufffdt{z kzn ^MM4= tykro mwk\u20ac\u20actqto~\n[{mtkw yontk |wk\ufffdq{~y Zonnt\ufffd1 Fw\ufffds{\ufffdrs \ufffd~knt\ufffdt{zkw yontk \u20ac\ufffdtww\u20aco~\ufffdo k\u20acty|{~\ufffdkz\ufffd zo\u00d0\u20ac\n\u20ac{\ufffd~mo\u20ac. m{z\u20ac\ufffdytzr zo\u00d0\u20ac \ufffds~{\ufffdrs \u20ac{mtkw yontk \u00d0ol\u20act\ufffdo\u20ac sk\u20aclom{yo tzm~ok\u20actzrw\u00de ty|{~\ufffdkz\ufffd k\u20ac\n\u20ac{\ufffd~mo\u20ac {qzo\u00d0\u20ac d9.<:f. o\ufffdoz lortzztzr \ufffd{~o|wkmo \ufffd~knt\ufffdt{zkw yontk d<;f1 \\s\ufffd\u20ac. kzkw\u00de\u00fetzr \ufffdso\n~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz ntrt\ufffdkw zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z kzn k\ufffd\ufffdoz\ufffdt{z nt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac {z\u20ac{mtkw yontk\n\u00d0ol\u20act\ufffdo\u20ac t\u20aco\u20ac\u20acoz\ufffdtkw q{~\ufffdzno~\u20ac\ufffdkzntzr {zotz\ufffdor~kw |k~\ufffd {q\ufffd{nk\u00de)\u20ac s\u00del~tn yontk \u20ac\u00de\u20ac\ufffdoy d;.<f1\nOz{\ufffd~kzkw\u00de\u20act\u20ac. \u00d0oq{m\ufffd\u20ac {zZonnt\ufffd lomk\ufffd\u20aco t\ufffdt\u20ac{q\ufffdoz ~ork~non k\u20ac\ufffd\ufffdso q~{z\ufffd |kro {q\ufffdsoOz\ufffdo~/\nzo\ufffd\ufffd d<<f kzn t\u20ac{zo{q\ufffdsoy{\u20ac\ufffd |{|\ufffdwk~ \u20ac{mtkw yontk zo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac d9f.vz{\u00d0z k\u20ack|wkmo \ufffd{\n\u20acsk~o zo\u00d0 \u20ac{mtkw \ufffd~ozn\u20ac. |{wt\ufffdtmkw {|tzt{z\u20ac. kzn tzz{\ufffdk\ufffdt\ufffdo tnok\u20ac d<=f1 T{~o{\ufffdo~. Zonnt\ufffd sk\u20ack\n\ufffdzt}\ufffdo \u20ac\ufffd~\ufffdm\ufffd\ufffd~o m{y|k~on \ufffd{{\ufffdso~ \u20ac{mtkw yontk |wk\ufffdq{~y\u20ac1 O\ufffdt\u20acnt\ufffdtnon tz\ufffd{ \ufffdk~t{\ufffd\u20ac \u20ac\ufffdl~on/\nnt\ufffd\u20actz\u00d0stms \ufffd\ufffd\u20aco~\u20ac km\ufffdt\ufffdow\u00de ms{{\u20aco \ufffd{|k~\ufffdtmt|k\ufffdo tz\u20ac|omtqtm nt\u20acm\ufffd\u20ac\u20act{z r~{\ufffd|\u20ac \ufffdsk\ufffd tz\ufffdo~o\u20ac\ufffd\n\ufffdsoy 444~k\ufffdso~ \ufffdskz m~ok\ufffdtzr q~tozn zo\ufffd\u00d0{~v\u20ac\ufffd d<=f1 \\s\ufffd\u20ac. \ufffd\u20ac{mtkw m{zzom\ufffdt{z\u20ac k~owo\u20ac\u20ac\u20ackwtoz\ufffd\n{zZonnt\ufffd. \u00d0stms \u20acooy\u20ac y{~o moz\ufffdo~on {z\ufffdsom{z\ufffdoz\ufffd\ufffd d:;f. ykvtzr \ufffdso|wk\ufffdq{~y k|k~\ufffdtm\ufffd/\nwk~w\u00de r{{n ms{tmo k\u20ac\ufffdsoq{\ufffdznk\ufffdt{z q{~{\ufffd~kzkw\u00de\u20act\u20ac {q\ufffdsont\u20acm{\ufffd~\u20aco {zkzn k\ufffd\ufffdoz\ufffdt{z |ktn \ufffd{\n\ufffdsoGST y{\ufffdoyoz\ufffd1\n_soz o\ufffdkw\ufffdk\ufffdtzr Zonnt\ufffd)\u20ac m{yy\ufffdztmk\ufffdt{z kzn tz\ufffdo~km\ufffdt{z wkzn\u20acmk|o. t\ufffdt\u20acm~t\ufffdtmkw \ufffd{\n~oyoylo~ \ufffdsk\ufffd t\ufffd\u20ack\ufffdntozmo {q\ufffd\u20aco~\u20ac t\u20ac\u20acvo\u00d0on tzmo~\ufffdktz \u00d0k\u00de\u20ac \ufffdsk\ufffd m{\ufffdwn kqqom\ufffd ~o\u20ac\ufffdw\ufffd\u20ac? q{~\no\u00f0ky|wo. \ufffdso\u20ac{mtkw m{y|{\u20act\ufffdt{z t\u20acltk\u20acon \ufffd{\u00d0k~n Fyo~tmkz yoz {qytnnwo kro\u00d0t\ufffds woq\ufffd/wokz/\ntzr|{wt\ufffdtmkw \ufffdto\u00d0\u20ac d<7f1 \\{kmm{\ufffdz\ufffd q{~\ufffdso\u20aco ltk\u20aco\u20ac \ufffd{knor~oo \u00d0onooy |{\u20ac\u20actlwo. \u00d0okzkw\u00de\u00feo\n\ufffds~oo ~owk\ufffdt\ufffdow\u00de |{wt\ufffdtmkww\u00de zo\ufffd\ufffd~kw \u20ac\ufffdl~onnt\ufffd\u20ac \ufffdsk\ufffd k~ostrsw\u00de |{|\ufffdwk~ q{~\u20acsk~tzr zo\u00d0\u20ac {zZon/\nnt\ufffdkzn k~om{yy{zw\u00de \ufffd\u20acon k\u20ac\u20ac\ufffdl~onnt\ufffd\u20ac {qkzkw\u00de\u20act\u20ac tz\ufffdst\u20acm{z\ufffdo\u00f0\ufffd d\u20acoo. o1r1. =3f1 T{~o{\ufffdo~.\n\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de kty\u20ac \ufffd{kzkw\u00de\u00feo \ufffdsooqqom\ufffd {qyktz\u20ac\ufffd~oky zo\u00d0\u20ac ~o|{~\ufffdtzr {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \ufffd{mk|\ufffd\ufffd~o\n\ufffdsorozo~kw ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \u20acsk~on zo\u00d0\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\so~oq{~o. \u00d0otz\ufffdoz\ufffdt{zkww\u00de\nq{m\ufffd\u20ac {z\ufffdsoy{\u20ac\ufffd |~{ytzoz\ufffd \u20ac\ufffdl~onnt\ufffd\u20ac q{~\u20acsk~tzr zo\u00d0\u20ac \u00d0t\ufffds \u20ac\ufffd~tm\ufffd m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac. yktzw\u00de\nqok\ufffd\ufffd~tzr yktz\u20ac\ufffd~oky yontk {\ufffd\ufffdwo\ufffd\u20ac d=4f1 _ont\u20ac~ork~n y{~o ~kntmkw {~q~tzro zo\u00d0\u20ac \u20ac\ufffdl~onnt\ufffd\u20ac\n{zZonnt\ufffd k\u20ac\ufffdso\u00de k\ufffd\ufffd~km\ufffd kntqqo~oz\ufffd k\ufffdntozmo. {|o~k\ufffdo kmm{~ntzr \ufffd{ntqqo~oz\ufffd m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac.\n\u20acsk~o ntqqo~oz\ufffd \ufffd\u00de|o\u20ac {qm{z\ufffdoz\ufffd. kzn. \ufffdso~oq{~o. m{z\ufffdktz kntqqo~oz\ufffd w{rtm {qk\ufffd\ufffdoz\ufffdt{z nt\u20ac\ufffd~tl\ufffd/\n\ufffdt{z d=5f1\n\\so qt~\u20ac\ufffd \ufffd\u00d0{\u20ac\ufffdl~onnt\ufffd\u20ac k~o~2\u00d0{~wnzo\u00d0\u20ac. \u00d0t\ufffds 5<1: ytwwt{z \ufffd\u20aco~\u20ac *k\u20ac{qF|~tw 4:.5355+. kzn\n~2zo\u00d0\u20ac. \u00d0t\ufffds 5719 ytwwt{z \u20ac\ufffdl\u20acm~tlo~\u20ac? l{\ufffds k~o|~oyto~ \u20ac\ufffdl~onnt\ufffd\u20ac q{~o\u00f0mskzrtzr kzn nt\u20acm\ufffd\u20ac\u20ac/\ntzrtz\ufffdo~zk\ufffdt{zkw zo\u00d0\u20ac1 _okw\u20ac{ tzmw\ufffdno \ufffdso\u20ac\ufffdl~onnt\ufffd ~2|{wt\ufffdtm\u20ac. \u00d0t\ufffds <ytwwt{z yoylo~\u20ac? t\ufffdt\u20ac\nnontmk\ufffdon o\u00f0mw\ufffd\u20act\ufffdow\u00de \ufffd{]1[1/\u20ac|omtqtm zo\u00d0\u20ac1 \\so\u20aco \ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac sk\ufffdo \u20actytwk~ m{yy\ufffdzt\ufffd\u00de\n~\ufffdwo\u20ac kzn \u20ac\ufffdkznk~n\u20ac q{~\ufffd\u20aco~ \u20ac\ufffdlyt\u20ac\u20act{z\u20ac *~ork~ntzr \ufffdt\ufffdwo wozr\ufffds. \ufffdt\ufffdwo m{z\ufffdoz\ufffd. kzn \ufffdtyowtzo\u20ac\u20ac {q\nzo\u00d0\u20ac k~\ufffdtmwo\u20ac? \u20acoo\u20ac\ufffdlyt\u20ac\u20act{z r\ufffdtnowtzo\u20ac {qokms \u20ac\ufffdl~onnt\ufffd+1 [\ufffdlyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon tzkww\ufffds~oo\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4525=\n\u20ac\ufffdl~onnt\ufffd\u20ac m{z\u20act\u20ac\ufffd {qkwtzv \ufffd{kzo\u00d0\u20ac k~\ufffdtmwo kzn k\ufffdt\ufffdwo yk\ufffdmstzr \ufffdso\ufffdt\ufffdwo {q\ufffdsozo\u00d0\u20ac k~\ufffdtmwo.\n\u00d0stms kww{\u00d0\u20ac q{~knt~om\ufffd m{y|k~t\u20ac{z? {zw\u00de {zo. ~2|{wt\ufffdtm\u20ac. kww{\u00d0\u20ac \ufffdso|{\u20ac\ufffdtzr {q\ufffds\ufffdylzktw\u20ac1\n[tzmo kww\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac k~onontmk\ufffdon \ufffd{\u20acsk~tzr zo\u00d0\u20ac k~\ufffdtmwo\u20ac {zw\u00de. k\u20actytwk~ \ufffd\u00de|o {qtykro\nk\ufffd\ufffdkmson \ufffd{k\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac wtzvon k~\ufffdtmwo mkzloo\u00f0|om\ufffdon1 \\st\u20ac. tz\ufffd\ufffd~z. ozskzmo\u20ac \ufffdsom{y|k~k/\nltwt\ufffd\u00de {qkww\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac kzn \ufffdso\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffd{\ufffdsoy kzn |k\ufffdo\u20ac \ufffdso\u00d0k\u00de q{~km{~~om\ufffd mk\ufffdo/\nr{~t\u00fek\ufffdt{z {q\ufffdsotykro mwk\u20ac\u20actqto~. \u00d0stms t\u20ackw\u20ac{ \ufffd~ktzon {z|~{\ufffdo\u20ac\ufffd/~owk\ufffdon zo\u00d0\u20ac tykro\u20ac1\nZonnt\ufffd GST nk\ufffdk\u20aco\ufffd1 _o\ufffd\u20aco\ufffdsoy{z\ufffdsw\u00de W\ufffd\u20acs\u20acstq\ufffd \u20ac\ufffdlyt\u20ac\u20act{z n\ufffdy|\u20ac d<<f \ufffd{rk\ufffdso~ \ufffdso\nnk\ufffdk {q\ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac. \u00d0stms t\u20ac~or\ufffdwk~w\u00de n{zo q{~m{wwom\ufffdtzr Zonnt\ufffd nk\ufffdk do1r1. =6f1 _o\nn{\u00d0zw{knon \ufffdsoW\ufffd\u20acs\u20acstq\ufffd \u20ac\ufffdlyt\u20ac\u20act{z n\ufffdy|\u20ac q{~Tk\u00de 5353 \ufffd{Tk\u00de 5354 *439MG+ {zTk\u00de =.\n5356. kzn qtw\ufffdo~on \ufffdsonk\ufffdk ~ork~ntzr \ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac {qtz\ufffdo~o\u20ac\ufffd ~2\u00d0{~wnzo\u00d0\u20ac. ~2|{wt\ufffdtm\u20ac.\nkzn ~2zo\u00d0\u20ac *<63TG+. \u00d0stms won\ufffd{4.<<;.535 \u20ac\ufffdlyt\u20ac\u20act{z\u20ac1 _t\ufffds {\ufffd~{luom\ufffdt\ufffdo {qo\ufffdkw\ufffdk\ufffdtzr \ufffdso\nGST y{\ufffdoyoz\ufffd ~otrzt\ufffdon tz5353. \u00d0o~on\ufffdmon \ufffdsonk\ufffdk \ufffd{\u00d0k~n \ufffdso|o~t{n {qkzkw\u00de\u20act\u20ac q~{y\nTk\u00de 59.5353. \ufffdsonk\u00de{qMo{~ro Lw{\u00den)\u20ac y\ufffd~no~. \ufffd{Tk\u00de 59.53541 \\st\u20ac \u00detownon 4.;:6.:9= \u20ac\ufffdl/\nyt\u20ac\u20act{z\u20ac1 _o~oy{\ufffdon kww\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0s{\u20aco \ufffdt\ufffdwo\u20ac ntnz{\ufffdyk\ufffdms {zo{q\ufffdso\ufffds~oo vo\u00de\u00d0{~n\u20ac.\n\ufffdlwkmv wt\ufffdo\u20ac yk\ufffd\ufffdo~.\ufffd \ufffdro{~ro qw{\u00den.\ufffd {~\ufffdlwy.\ufffd wok\ufffdtzr k\ufffd{\ufffdkw {q4;.3<6 \u20ac\ufffdlyt\u20ac\u20act{z\u20ac ~owo\ufffdkz\ufffd \ufffd{\n{\ufffd~kzkw\u00de\u20act\u20ac1\nU{\ufffdo \ufffdsk\ufffd \u00d0okw\u20ac{ \ufffdo\u20ac\ufffdon s{\u00d0 kztzm~ok\u20acon vo\u00de\u00d0{~n \u20aco\ufffd~owk\ufffdon \ufffd{{\ufffd~kzkw\u00de\u20act\u20ac \ufffd{|tm \u00d0{\ufffdwn\ntzm~ok\u20aco {\ufffd~nk\ufffdk m{~|\ufffd\u20ac1 _o. \ufffdso~oq{~o. knnon \ufffdsoGST/\u20ac|omtqtm vo\u00de\u00d0{~n\u20ac \ufffd|{wtmo \ufffdt{wozmo.\ufffd\n\ufffdl~o{zzk \ufffdk\u00dew{~.\ufffd kzn \ufffd~k\u00de\u20acsk~n l~{{v\u20ac\ufffd \ufffd{{\ufffd~vo\u00de\u00d0{~n \u20aco\ufffd?\ufffdst\u20ac. s{\u00d0o\ufffdo~. ntnz{\ufffd~o\u20ac\ufffdw\ufffd tzk\n\u20actrztqtmkz\ufffd tzm~ok\u20aco tz\u20ac\ufffdlyt\u20ac\u20act{z\u20ac kzn knnon y{~o z{t\u20aco \ufffd{\ufffdsonk\ufffdk\u20aco\ufffd *q{~ y{~o tzq{~yk\ufffdt{z.\n\u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Jk\ufffdk k\ufffdktwkltwt\ufffd\u00de \u20ac\ufffdk\ufffdoyoz\ufffd+1 _o\ufffds\ufffd\u20ac nomtnon \ufffd{m{z\ufffdtz\ufffdo \u00d0{~v/\ntzr\u00d0t\ufffds \ufffdsotzt\ufffdtkw vo\u00de\u00d0{~n \u20aco\ufffd1\nL{~{\ufffd~nk\ufffdk mwokztzr |~{mo\u20ac\u20ac. \u00d0o~oy{\ufffdon k|k~\ufffdtm\ufffdwk~ \ufffd\u00de|o {q\u20ac\ufffdlyt\u20ac\u20act{z q~{y {\ufffd~nk\ufffdk\u20aco\ufffd.\n\u20ac{/mkwwon \ufffdyork\ufffds~okn\u20ac.\ufffd \u00d0stms \u20ac\ufffdyyk~t\u00feo\u20ac ky\ufffdw\ufffdt\ufffd\ufffdno {q\u20ac\ufffdlyt\u20ac\u20act{z\u20ac kl{\ufffd\ufffd strsw\u00de |{|\ufffdwk~\no\ufffdoz\ufffd\u20ac kzn \ufffd\u00de|tmkww\u00de ~omot\ufffdo\u20ac knt\u20ac|~{|{~\ufffdt{zk\ufffdo ky{\ufffdz\ufffd {qk\ufffd\ufffdoz\ufffdt{z? \ufffdst\u20ac~on\ufffdmon \ufffdsoz\ufffdylo~\n{q\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffd{4;.3:=1 Fq\ufffdo~ n~{||tzr kwwyt\u20ac\u20actzr\u20ac ~ork~ntzr {\ufffd~m{z\ufffd~{w \ufffdk~tklwo\u20ac q~{y\nyontkltk\u20acqkm\ufffdmsomv1m{y *\ufffd|{wt\ufffdtmkw wokztzr\ufffd *H4+. \ufffdqkm\ufffd\ufffdkw ~o|{~\ufffdtzr\ufffd *H5+. \ufffd\ufffd~kqqtm\ufffd *H6+. kzn\n\ufffd\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\ufffd+. \u00d0o~omot\ufffdon 44.<46 \u20ac\ufffdlyt\u20ac\u20act{z\u20ac1\nMt\ufffdoz {\ufffd~r{kw \ufffd{kzkw\u00de\u00feo \ufffdsoty|km\ufffd {qtykro\u20ac nt\u20ac|wk\u00detzr \ufffdt{wozmo. \ufffdsozo\u00f0\ufffd \u20ac\ufffdo| t\u20ac\ufffd{m{wwom\ufffd\n\ufffdsotykro\u20ac q~{y \ufffdsozo\u00d0\u20ac k~\ufffdtmwo\u20ac ~oqo~ozmon tz{\ufffd~nk\ufffdk\u20aco\ufffd)\u20ac \u20ac\ufffdlyt\u20ac\u20act{z\u20ac1 _o\ufffd\u20aco\ufffdsotykro\u20ac\nq~{y \ufffdsowtzvon zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac lomk\ufffd\u20aco \ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac kww{\u00d0 {zw\u00de \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds zo\u00d0\u20ac\n\ufffdt\ufffdwo\u20ac kzn zo\u00d0\u20ac k~\ufffdtmwo wtzv\u20ac. \ufffds\ufffd\u20ac \u20aco\ufffd\ufffdtzr \ufffdsoq{m\ufffd\u20ac {z\ufffdso{~trtzk\ufffdtzr zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd kzn t\ufffd\u20ac\ntykro\u20ac1 _ok\u20ac\u20ac\ufffdyo \ufffdsk\ufffd \ufffd\u20aco~\u20ac \u00d0s{ ozrkro \u00d0t\ufffds \ufffdso\u20ac\ufffdlyt\u20ac\u20act{z kw\u20ac{ mwtmv {z\ufffdso]ZS wtzv. k\u20act\ufffd\nt\u20ac\ufffdso|~tyk~\u00de |\ufffd~|{\u20aco {q\ufffdso\u20ac\ufffdlyt\u20ac\u20act{z t\ufffd\u20acowq1 _o\ufffd\u20aco\ufffdsoW\u00de\ufffds{z wtl~k~\u00de \ufffdUo\u00d0\u20ac|k|o~6v\ufffd \ufffd{\no\u00f0\ufffd~km\ufffd \ufffdsoyktz tykro\u20ac *kw\u20ac{ \ufffd\u20acon k\u20ac\ufffds\ufffdylzktw\u20ac tz~2|{wt\ufffdtm\u20ac+ q~{y okms zo\u00d0\u20ac k~\ufffdtmwo tz{\ufffd~\nnk\ufffdk\u20aco\ufffd1 \\so \ufffdyktz tykro\ufffd {qkzk~\ufffdtmwo t\u20acnoqtzon \u00d0t\ufffdstz \ufffdso\u20ac{\ufffd~mo m{no {qokms \u00d0ol\u20act\ufffdo kzn\n\ufffd\u00de|tmkww\u00de m{~~o\u20ac|{zn\u20ac \ufffd{\ufffdsoqt~\u20ac\ufffd tykro {z\ufffdso\u00d0ol\u20act\ufffdo1 U{\ufffdo \ufffdsk\ufffd tqUo\u00d0\u20ac|k|o~6v m{\ufffdwn z{\ufffd\no\u00f0\ufffd~km\ufffd kztykro n\ufffdo\ufffd{.q{~o\u00f0ky|wo. mk|\ufffdmsk\u20ac {qkzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac \u00d0ol\u20act\ufffdo. \u00d0oykz\ufffdkww\u00de\no\u00f0\ufffd~km\ufffdon \ufffdsoyktz tykro tz\ufffdsomk\u20aco\u20ac |{\u20ac\u20actlwo1 \\{\ufffdo\u20ac\ufffds{\u00d0 \u00d0oww Uo\u00d0\u20ac|k|o~6v o\u00f0\ufffd~km\ufffdon \ufffdso\nm{~~om\ufffd yktz tykro {qkzo\u00d0\u20ac k~\ufffdtmwo. \u00d0oykz\ufffdkww\u00de o\ufffdkw\ufffdk\ufffdon 533~kzn{y tykro\u20ac ~o\ufffd~to\ufffdon l\u00de\nUo\u00d0\u20ac|k|o~6v1 Vq533tykro\u20ac. 495\u00d0o~o m{~~om\ufffdw\u00de no\ufffdom\ufffdon k\u20ac\ufffdsoyktz tykro *;:13&+1 F\u20ac\nzok~w\u00de kww{\ufffdso~ tykro\u20ac \ufffdsk\ufffd \u00d0o~o z{\ufffdwklowon k\u20ac\ufffdsoyktz tykro \u00d0o~o \u20ac\ufffdtww|k~\ufffd {q\ufffdsozo\u00d0\u20ac k~\ufffdt/\nmwokzn y{\u20ac\ufffd {q\ufffdoz \ufffdso\u20acom{zn {~\ufffdst~n tykro {z\ufffdso\u00d0ol\u20act\ufffdo. \u00d0onooyon \ufffdst\u20ac~o\u20ac\ufffdw\ufffd kmmo|\ufffdklwo\nkzn m{z\ufffdtz\ufffdon \u00d0{~vtzr \u00d0t\ufffds \ufffds{\u20aco tykro\u20ac1 Fq\ufffdo~ n{\u00d0zw{kntzr \ufffdsotykro\u20ac no\ufffdom\ufffdon l\u00deUo\u00d0\u20ac|k/\n|o~6v kzn ykz\ufffdkww\u00de knnon l\u00de\ufffd\u20ac.\u00d0o~o\ufffd~to\ufffdon =.6;6 tykro\u20ac q{~{\ufffd~nk\ufffdk\u20aco\ufffd *z{tykro \u00d0k\u20ac\nk\ufffdktwklwo q{~5.773 \u20ac\ufffdlyt\u20ac\u20act{z\u20ac+1\nL{~{\ufffd~kzkw\u00de\u20act\u20ac. \u00d0ok~otz\ufffdo~o\u20ac\ufffdon tz\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffdsk\ufffd ~omot\ufffdon k\ufffdwok\u20ac\ufffd kytzty\ufffdy {qk\ufffd\ufffdoz/\n\ufffdt{z kzn \ufffds\ufffd\u20ac sk\ufffdo looz ~om{rzt\u00feon l\u00deZonnt\ufffd \ufffd\u20aco~\u20ac1 _o. \ufffdso~oq{~o. ~oy{\ufffdon kww\u20ac\ufffdlyt\u20ac\u20act{z\u20ac\n\ufffdsk\ufffd ~omot\ufffdon \u00feo~{ m{yyoz\ufffd\u20ac \u00d0stms ~on\ufffdmon \ufffdsonk\ufffdk\u20aco\ufffd \ufffd{9.<;: \u20ac\ufffdlyt\u20ac\u20act{z\u20ac *\u00deo\ufffd. \ufffd{\u20ac\ufffd\u20ac\ufffdktz\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4625=\n{\ufffd~~o\u20ac\ufffdw\ufffd\u20ac. \u00d0okw\u20ac{ ~kzkzork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now \ufffdsk\ufffd tzmw\ufffdnon \u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0t\ufffds\n\u00feo~{ m{yyoz\ufffd\u20ac. \u00detowntzr \u20actytwk~ ~o\u20ac\ufffdw\ufffd\u20ac q{~\ufffdsoyktz oqqom\ufffd\u20ac? q{~y{~o tzq{~yk\ufffdt{z. \u20acoo[\ufffd|/\n|{~\ufffdtzr Ozq{~yk\ufffdt{z. Uork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now\u20ac+1 Fq\ufffdo~ n~{||tzr kwwyt\u20ac\u20actzr \ufffdkw\ufffdo\u20ac\n{q\ufffdso{\ufffdso~ \ufffdk~tklwo\u20ac ~owk\ufffdon \ufffd{{\ufffd~kzkw\u00de\u20act\u20ac. {\ufffd~qtzkw nk\ufffdk\u20aco\ufffd m{z\u20act\u20ac\ufffd\u20ac {q9.<;6 {l\u20aco~\ufffdk\ufffdt{z\u20ac1\n\\~ktztzr nk\ufffdk\u20aco\ufffd q{~tykro mwk\u20ac\u20actqto~\nW~owklowon \ufffd~ktztzr kzn \ufffdkwtnk\ufffdt{z nk\ufffdk\u20aco\ufffd\u20ac k~ozomo\u20ac\u20ack~\u00de \ufffd{l\ufffdtwn kzk\ufffd\ufffd{yk\ufffdon tykro mwk\u20ac\u20actqto~\n\ufffdsk\ufffd mkzwklow kztykro k\u20ac\ufffdt{woz\ufffd *B4+{~z{z\ufffdt{woz\ufffd *B3+1\\so~oq{~o. \u00d0o\ufffd\u20acotykro\u20ac q~{y \ufffdso\n\ufffd]ISF W~{\ufffdo\u20ac\ufffd Oykro Jk\ufffdk\u20aco\ufffd\ufffd {q_{z o\ufffdkw1d=7f. k|~owklowon |~{\ufffdo\u20ac\ufffd/~owk\ufffdon nk\ufffdk\u20aco\ufffd {q\n73.;:7 tykro\u20ac1 Oz\ufffdst\u20acnk\ufffdk\u20aco\ufffd. \ufffd\ufffdt{wozmo\ufffd t\u20ac{|o~k\ufffdt{zkwt\u00feon k\u20ackm{z\ufffdtz\ufffd{\ufffd\u20ac \ufffdk~tklwo? \u00d0o\ufffd~kz\u20ac/\nqo~\ufffdsk\ufffd wklowtzr \ufffd{{\ufffd~ntms{\ufffd{y{\ufffd\u20ac m{ntzr \u20acmsoyo l\u00deykz\ufffdkww\u00de k||w\u00detzr Z\ufffdms\ufffd)\u20ac d:<f \ufffdt{/\nwozmo noqtzt\ufffdt{z \ufffd{\ufffdsotykro\u20ac1 ]\u20actzr \ufffdsot~ nk\ufffdk\u20aco\ufffd)\u20ac y{\u20ac\ufffd/ kzn wok\u20ac\ufffd/\ufffdt{woz\ufffd tykro\u20ac. \u00d0oozn \ufffd|\n\u00d0t\ufffds 5.9:: tykro\u20ac tz\ufffdso\ufffd~ktztzr nk\ufffdk\u20aco\ufffd kzn ;33tz\ufffdso\ufffdo\u20ac\ufffdnk\ufffdk\u20aco\ufffd1 T{~o{\ufffdo~. \ufffd{\ufffd~ktz {\ufffd~\ntykro mwk\u20ac\u20actqto~ \u00d0t\ufffds rozo~kw |~{\ufffdo\u20ac\ufffd tykro\u20acand GST/\u20ac|omtqtm tykro\u20ac. \u00d0ok\ufffd\ufffd{yk\ufffdtmkww\u00de n{\u00d0z/\nw{kn tykro\u20ac \ufffdtk\ufffdso\u20acok~ms ozrtzo \ufffdGtzr.\ufffd oy|w{\u00detzr 59GST kzn |~{\ufffdo\u20ac\ufffd/~owk\ufffdon ~owk\ufffdon vo\u00de/\n\u00d0{~n\u20ac tzKzrwt\u20acs kzn Mo~ykz *q{~ \ufffdsooz\ufffdt~o vo\u00de\u00d0{~n \u20aco\ufffd.\u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Jk\ufffdk\nk\ufffdktwkltwt\ufffd\u00de \u20ac\ufffdk\ufffdoyoz\ufffd+1 _omwk\u20ac\u20actq\u00de \ufffdsoy q{ww{\u00d0tzr \ufffdso\u20ackyo |~{mon\ufffd~o {\ufffd\ufffdwtzon kl{\ufffdo1 Ltzkww\u00de.\n\u00d0oozwk~ro {\ufffd~nk\ufffdk\u20aco\ufffd \ufffd\u20actzr tykro k\ufffdryoz\ufffdk\ufffdt{z. ~o\u20ac\ufffdw\ufffdtzr tz;.=;5 \ufffdt{woz\ufffd tykro\u20ac kzn <.=<:\nz{z\ufffdt{woz\ufffd tykro\u20ac tz\ufffdso\ufffd~ktztzr nk\ufffdk\u20aco\ufffd kzn 5.<97 \ufffdt{woz\ufffd tykro\u20ac kzn 7.3<< z{z\ufffdt{woz\ufffd\ntykro\u20ac tz\ufffdso\ufffdkwtnk\ufffdt{z nk\ufffdk\u20aco\ufffd *q{~ y{~o tzq{~yk\ufffdt{z ~owk\ufffdon \ufffd{\ufffdsonk\ufffdk\u20aco\ufffd m~ok\ufffdt{z. |wok\u20aco\n\u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Jk\ufffdk k\ufffdktwkltwt\ufffd\u00de \u20ac\ufffdk\ufffdoyoz\ufffd+1\n\\~kz\u20acqo~ wok~ztzr \u2019|o~q{~ykzmo {q^MM4= tykro mwk\u20ac\u20actqto~\n_o\ufffd\u20acokm{z\ufffd{w\ufffd\ufffdt{zkw zo\ufffd~kw zo\ufffd\u00d0{~v k~mst\ufffdom\ufffd\ufffd~o \ufffd{mwk\u20ac\u20actq\u00de \ufffdt{woz\ufffd tykro\u20ac q{~\ufffd\u00d0{~ok\u20ac{z\u20ac>\n\ufffdsom{y|\ufffd\ufffdk\ufffdt{zkw |{\u00d0o~ kzn yoy{~\u00de \u20ac|kmo {qIUU\u20ac k~o~owk\ufffdt\ufffdow\u00de tzo\u00f0|oz\u20act\ufffdo n\ufffdo\ufffd{|k~ky/\no\ufffdo~ \u20acsk~tzr? kzn IUU\u20ac k\ufffd\ufffd{z{y{\ufffd\u20acw\u00de \u20acowom\ufffd ty|{~\ufffdkz\ufffd tykro qok\ufffd\ufffd~o\u20ac lk\u20acon {zk\ufffd\ufffd{yk\ufffdt\u00feon\nqok\ufffd\ufffd~o o\u00f0\ufffd~km\ufffdt{z kzn \u00d0t\ufffds{\ufffd\ufffd s\ufffdykz \u20ac\ufffd|o~\ufffdt\u20act{z. \ufffds\ufffd\u20ac kmsto\ufffdtzr \u20ac\ufffdk\ufffdo/{q/\ufffdso/k~\ufffd ~o\u20ac\ufffdw\ufffd\u20ac \u00d0stwo\nk\ufffd{tntzr s\ufffdykz ltk\u20aco\u20ac d=9f *\u20acoo [\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Oykro mwk\u20ac\u20actqto~\u20ac. q{~ntqqo~oz\ufffd y{n/\now\u20ac\ufffdsk\ufffd \u00d0o\ufffdo\u20ac\ufffdon l\ufffd\ufffd\ufffdsk\ufffd |o~q{~yon \u00d0{~\u20aco \ufffdskz IUU\u20ac+1\nZo\u20acok~ms sk\u20ac~o|ok\ufffdonw\u00de \u20acs{\u00d0z \ufffdsk\ufffd \ufffd\u20actzr kIUU |~o/\ufffd~ktzon {zrozo~kw tykro qok\ufffd\ufffd~o\u20ac\ntzm~ok\u20aco\u20ac \ufffdsoy{now |o~q{~ykzmo {zmo qtzo\ufffd\ufffdzon \ufffd{\ufffdso\u20ac|omtqtm mwk\u20ac\u20actqtmk\ufffdt{z \ufffdk\u20acv \ufffds~{\ufffdrs\n\ufffd~kz\u20acqo~ wok~ztzr d\u20acoo. o1r1. =:f1 _oq{ww{\u00d0 \ufffdst\u20ackn\ufffdtmo kzn k||w\u00de \ufffdso\ufffds~oo \u20ac\ufffdk\ufffdo/{q/\ufffdso/k~\ufffd IUU\nk~mst\ufffdom\ufffd\ufffd~o\u20ac ^MM4=. Zo\u20acUo\ufffd93. kzn Kqqtmtoz\ufffdUo\ufffdG7 d=;.=<f |o~\ufffdktzon {z\ufffdsoOykroUo\ufffd/4v\nnk\ufffdk\u20aco\ufffd d==f q~{y \ufffdsoW\u00de\ufffds{z noo| wok~ztzr wtl~k~to\u20ac \ufffd\\oz\u20ac{~Lw{\u00d0\ufffd kzn \ufffdRo~k\u20ac1\ufffd Ozknnt\ufffdt{z.\n\u00d0om~ok\ufffdo {\ufffd~{\u00d0z IUU k~mst\ufffdom\ufffd\ufffd~o k\u20ackq{\ufffd~\ufffds y{now q{~m{y|k~t\u20ac{z1 F\u20ac\ufffdso^MM4= y{now\n|o~q{~yon lo\u20ac\ufffd kq\ufffdo~ qtzo\ufffd\ufffdztzr kzn ~\ufffdzztzr \ufffdsontqqo~oz\ufffd y{now\u20ac. \u00d0om{z\ufffdtz\ufffdo \ufffd\ufffdtwt\u00fetzr \ufffdst\u20ac\nIUU k~mst\ufffdom\ufffd\ufffd~o q{~{\ufffd~kzkw\u00de\u20act\u20ac1 Oz\ufffdsoq{ww{\u00d0tzr. \u00d0or{tz\ufffd{ y{~o no\ufffdktw ~ork~ntzr \ufffdso\ufffd~ktz/\ntzrkzn |o~q{~ykzmo {q\ufffdso^MM4= y{now *q{~ y{~o tzq{~yk\ufffdt{z ~ork~ntzr \ufffdsok~mst\ufffdom\ufffd\ufffd~o.\n\ufffd~ktztzr. kzn o\ufffdkw\ufffdk\ufffdt{z {q\ufffdso{\ufffdso~ y{now\u20ac. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Oykro\nmwk\u20ac\u20actqto~\u20ac+1\n_o\ufffd\u20aco\ufffd~kz\u20acqo~ wok~ztzr \ufffd{knu\ufffd\u20ac\ufffd \ufffdso^MM4= y{now \ufffd{{\ufffd~mwk\u20ac\u20actqtmk\ufffdt{z m{z\ufffdo\u00f0\ufffd {qmwk\u20ac\u20actq\u00de/\ntzrtykro\u20ac k\u20ac\ufffdt{woz\ufffd *4+{~z{z\ufffdt{woz\ufffd *3+1\\so~oq{~o. \u00d0oq~oo\u00feo kwwwk\u00deo~\u20ac o\u00f0mo|\ufffd q{~\ufffdsowk\u20ac\ufffd\nq\ufffdww\u00de m{zzom\ufffdon wk\u00deo~ {q\ufffdso|~o/\ufffd~ktzon y{now. k\u20ac\ufffdzq~oo\u00fetzr y{~o wk\u00deo~\u20ac n{o\u20ac z{\ufffd\u00detown lo\ufffd\ufffdo~\n\ufffd~ktztzr ~o\u20ac\ufffdw\ufffd\u20ac1 _o~o|wkmo \ufffdsowk\u20ac\ufffdq\ufffdww\u00de m{zzom\ufffdon wk\u00deo~ \u00d0t\ufffds knoz\u20aco wk\u00deo~ \ufffdsk\ufffd k||wto\u20ac k\u20actr/\ny{tn q\ufffdzm\ufffdt{z k\u20ackzkm\ufffdt\ufffdk\ufffdt{z. \u00d0stms ~o\ufffd\ufffd~z\u20ac kz\ufffdylo~ lo\ufffd\u00d0ooz 3kzn 4kzn t\u20ac.\ufffdso~oq{~o. \u20ac\ufffdt\ufffd/\nklwo q{~{\ufffd~ltzk~\u00de tykro mwk\u20ac\u20actqtmk\ufffdt{z1 _om{y|two \ufffdsoy{now \u00d0t\ufffds \ufffdsoknky {|\ufffdtyt\u00feo~. k\nwok~ztzr ~k\ufffdo {q31334. kzn kltzk~\u00de m~{\u20ac\u20ac/oz\ufffd~{|\u00de *GIK+ w{\u20ac\u20acq\ufffdzm\ufffdt{z. ~o\u20ac\ufffdw\ufffdtzr tzkltzk~\u00de\nmwk\u20ac\u20actqtmk\ufffdt{z m{~~o\u20ac|{zntzr \ufffd{{\ufffd~mwk\u20ac\u20actqtmk\ufffdt{z {q\ufffd\ufffdt{woz\ufffd\ufffd kzn \ufffdz{z\ufffdt{woz\ufffd1\ufffd _o\u20ac|wt\ufffd \ufffdso\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4725=\n\ufffd~ktztzr nk\ufffdk tz\ufffd{ ;3& \ufffd~ktztzr tykro\u20ac kzn 63& \ufffdkwtnk\ufffdt{z tykro\u20ac1 _okw\u20ac{ ty|woyoz\ufffd kz\nok~w\u00de \u20ac\ufffd{| mkwwlkmv q\ufffdzm\ufffdt{z \u00d0t\ufffds kytzty\ufffdy now\ufffdk {q314& kzn k|k\ufffdtozmo |k~kyo\ufffdo~ {q43\n\u00d0t\ufffdstz {\ufffd~\ufffd~ktztzr |~{mo\u20ac\u20ac \ufffd{|~o\ufffdoz\ufffd {\ufffdo~qt\ufffd\ufffdtzr1 \\s\ufffd\u20ac. {\ufffd~\ufffd~ktztzr \u00d0tww\u20ac\ufffd{| tq{\ufffd~\ufffdkwtnk\ufffdt{z\nw{\u20ac\u20acn{o\u20ac z{\ufffdty|~{\ufffdo \u00d0t\ufffdstz \ufffdozo|{ms\u20ac l\u00dek\ufffdwok\u20ac\ufffd 314& m{y|k~on \ufffd{t\ufffd\u20aclo\u20ac\ufffd \ufffdkw\ufffdo1 _o\u20ac\ufffdk~\ufffd\n\ufffd~ktztzr \ufffdsoy{now \u00d0t\ufffds 73o|{ms\u20ac kzn klk\ufffdms \u20act\u00feo{q651F\u20ac\ufffdsoy{now)\u20ac \ufffdkwtnk\ufffdt{z w{\u20ac\u20acm{z\ufffdtz/\n\ufffd{\ufffd\u20acw\u00de ty|~{\ufffdo\u20ac l\u00dek\ufffdwok\u20ac\ufffd 314&. \ufffdso\ufffd~ktztzr ozn\u20ac kq\ufffdo~ 73o|{ms\u20ac1\nV\ufffd~ ^MM4= tykro mwk\u20ac\u20actqto~ kmsto\ufffdo\u20ac kzkmm\ufffd~km\u00de \ufffdkw\ufffdo {q=41:9& {z\ufffdso\ufffd~ktztzr nk\ufffdk kzn\n=315=& {z\ufffdso\ufffdkwtnk\ufffdt{z nk\ufffdk1 _soz k\u20ac\u20aco\u20ac\u20actzr \ufffdso|o~q{~ykzmo {z\ufffdso\ufffdo\u20ac\ufffdnk\ufffdk\u20aco\ufffd. \ufffdsomwk\u20ac\u20act/\nqto~kmsto\ufffdo\u20ac kzkmm\ufffd~km\u00de {q=41<7&. \u00d0stms t\u20acm{y|k~klwo \ufffd{\ufffdso\ufffd~ktztzr kzn \ufffdkwtnk\ufffdt{z kmm\ufffd/\n~km\u00de1 \\so mwk\u20ac\u20actqto~ kmsto\ufffdo\u20ac k|~omt\u20act{z \u20acm{~o {q<;1;<&. k~omkww \u20acm{~o {q=6146&. kzn kzL4\n\u20acm{~o {q=316;& {z\ufffdso\ufffdo\u20ac\ufffdnk\ufffdk\u20aco\ufffd1 T{~o{\ufffdo~. \u00d0soz k\u20ac\u20aco\u20ac\u20actzr \ufffdso|o~q{~ykzmo {q{\ufffd~GIK w{\u20ac\u20ac\nq\ufffdzm\ufffdt{z. l{\ufffds \ufffdso\ufffd~ktztzr kzn \ufffdkwtnk\ufffdt{z w{\u20ac\u20acm{z\ufffdtz\ufffd{\ufffd\u20acw\u00de nom~ok\u20acon. \u00d0stms t\u20ack\u20actrz \ufffdsk\ufffd \ufffdso\ny{now |tmv\u20ac \ufffd|o\u20ac\u20acoz\ufffdtkw tykro qok\ufffd\ufffd~o\u20ac \u00d0t\ufffds{\ufffd\ufffd {\ufffdo~qt\ufffd\ufffdtzr \ufffdsonk\ufffdk *tzo|{ms 73.kw{\u20ac\u20ac{q3155\n{z{\ufffd~\ufffd~ktztzr nk\ufffdk kzn 3157 {z{\ufffd~\ufffdkwtnk\ufffdt{z nk\ufffdk+1 \\s\ufffd\u20ac. \ufffdsomwk\u20ac\u20actqto~)\u20ac |o~q{~ykzmo t\u20ac\n\u20ac{\ufffdzn kzn kww{\u00d0\u20ac q{~k\ufffdkwtn tykro mwk\u20ac\u20actqtmk\ufffdt{z *q{~ y{~o tzq{~yk\ufffdt{z {z\ufffdso^MM4= y{now\n|o~q{~ykzmo. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Oykro mwk\u20ac\u20actqto~\u20ac+1\nZo\ufffd\ufffdw\ufffd\ufffd\nF\u20ackqt~\u20ac\ufffd \u20ac\ufffdo|. \u00d0omwk\u20ac\u20actq\u00de {\ufffd~GST tykro\u20ac \u00d0t\ufffds {\ufffd~^MM4= tykro mwk\u20ac\u20actqto~. ~o\u20ac\ufffdw\ufffdtzr tz9.7<:\ntykro\u20ac mwk\u20ac\u20actqton k\u20ac\ufffdz{z\ufffdt{woz\ufffd\ufffd *=617&+ kzn 6<;k\u20ac\ufffd\ufffdt{woz\ufffd\ufffd *:1:&+1 \\{\ufffdkwtnk\ufffdo \u00d0so\ufffdso~ {\ufffd~\ntykro mwk\u20ac\u20actqto~ |o~q{~y\u20ac k\u20ac\u00d0oww {z{\ufffd~GST nk\ufffdk\u20aco\ufffd k\u20ac{z\ufffdso\ufffd~ktztzr. \ufffdkwtnk\ufffdt{z. kzn \ufffdo\u20ac\ufffdtzr\n\u20aco\ufffd.\u00d0oykz\ufffdkww\u00de wklow 533~kzn{y GST tykro\u20ac kzn m{y|k~o {\ufffd~mwk\u20ac\u20actqtmk\ufffdt{z ~o\u20ac\ufffdw\ufffd \u00d0t\ufffds \ufffdso\nmwk\u20ac\u20actqto~)\u20ac ~o\u20ac\ufffdw\ufffd\u20ac1 Vq533tykro\u20ac. 4<3k~om{~~om\ufffdw\u00de wklowon *=313&+. \u00d0stms kwtrz\u20ac \u00d0t\ufffds \ufffdso|~o/\n\ufffdt{\ufffd\u20ac \ufffdkwtnk\ufffdt{z yo\ufffd~tm\u20ac kzn \ufffdso~oq{~o \u20ac\ufffd||{~\ufffd\u20ac \ufffdsomwk\u20ac\u20actqto~)\u20ac |o~q{~ykzmo tz{\ufffd~GST |~{\ufffdo\u20ac\ufffd\nm{z\ufffdo\u00f0\ufffd1 T{~o{\ufffdo~. \u00d0soz mkwm\ufffdwk\ufffdtzr \ufffdso\u20acoz\ufffdtyoz\ufffd {qk\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\ufffdwo \u00d0t\ufffds \ufffdsoGKZ\\\ny{now. \u00d0o~omot\ufffdo 4.596 *5416&+ |{\u20act\ufffdt\ufffdow\u00de m{zz{\ufffdon \ufffdt\ufffdwo\u20ac kzn 7.:53 *;<1;&+ zork\ufffdt\ufffdow\u00de m{zz{/\n\ufffdk\ufffdon \ufffdt\ufffdwo\u20ac1 \\{\ufffdkwtnk\ufffdo \ufffdso\u20aco mwk\u20ac\u20actqtmk\ufffdt{z ~o\u20ac\ufffdw\ufffd\u20ac. \u00d0on~k\u00d0 k~kzn{y \u20acky|wo {q533\u20ac\ufffdlyt\u20ac\u20act{z\n\ufffdt\ufffdwo\u20ac kzn ykz\ufffdkww\u00de wklow \ufffdsoy k\u20ac\ufffd|{\u20act\ufffdt\ufffdo\ufffd {~\ufffdzork\ufffdt\ufffdo1\ufffd \\so ykz\ufffdkw kzn k\ufffd\ufffd{yk\ufffdtm \u20acoz\ufffdt/\nyoz\ufffd mwk\u20ac\u20actqtmk\ufffdt{z yk\ufffdmso\u20ac tz4:<{\ufffd\ufffd{q533mk\u20aco\u20ac *<713&+1 \\st\u20ac \ufffdkw\ufffdo t\u20actzwtzo\u00d0t\ufffds \ufffdso|~o\ufffdt/\n{\ufffd\u20ac\ufffdkwtnk\ufffdt{z kzn \ufffdo\u20ac\ufffdkmm\ufffd~km\u00de {q\ufffdsoGKZ\\ y{now. \u20ac\ufffd||{~\ufffdtzr \ufffdsoy{now)\u20ac \u20ac{\ufffdzn\n|o~q{~ykzmo {z{\ufffd~Zonnt\ufffd GST nk\ufffdk1 _o\ufffds\ufffd\u20ac sk\ufffdo kww\ufffdsozomo\u20ac\u20ack~\u00de nk\ufffdk \ufffd{~\ufffdz{\ufffd~nk\ufffdk\nkzkw\u00de\u20act\u20ac *q{~ kno\u20acm~t|\ufffdt{z {qkww\ufffdk~tklwo\u20ac. \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Jo\u20acm~t|\ufffdt\ufffdo {\ufffdo~\ufffdto\u00d0 {q\n\ufffdk~tklwo\u20ac+1\n\\so m{\ufffdz\ufffd zk\ufffd\ufffd~o {q{\ufffd~no|oznoz\ufffd \ufffdk~tklwo. \ufffdz\ufffdylo~ {qm{yyoz\ufffd\u20ac.\ufffd ykvo\u20ac kW{t\u20ac\u20ac{z {~\nzork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now y{\u20ac\ufffd \u20ac\ufffdt\ufffdklwo q{~\ufffdsokzkw\u00de\u20act\u20ac1 \\{\ufffdo\u20ac\ufffd\u00d0so\ufffdso~ kW{t\u20ac\u20ac{z {~\nzork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z \u00d0{\ufffdwn loy{~o k||~{|~tk\ufffdo q{~{\ufffd~nk\ufffdk. \u00d0om{zn\ufffdm\ufffd kwtvowts{{n\n~k\ufffdt{ \ufffdo\u20ac\ufffdq{~{\ufffdo~nt\u20ac|o~\u20act{z tzm{\ufffdz\ufffd nk\ufffdk *\ufffd{n\\o\u20ac\ufffd\ufffd q\ufffdzm\ufffdt{z q~{y \ufffdsoZ|kmvkro \ufffd|\u20acmw\ufffd+1 \\so\nwtvowts{{n ~k\ufffdt{ \ufffdo\u20ac\ufffdo\u20ac\ufffdtyk\ufffdo\u20ac \u00d0so\ufffdso~ \ufffdsonk\ufffdk)\u20ac \ufffdk~tkzmo o}\ufffdkw\u20ac t\ufffd\u20acyokz. \u00d0stms t\u20ac\ufffdsok\u20ac\u20ac\ufffdy|/\n\ufffdt{z {qkW{t\u20ac\u20ac{z y{now1 \\so \ufffdo\u20ac\ufffd~o\u20ac\ufffdw\ufffd\u20ac \u20acs{\u00d0 \ufffdsk\ufffd {\ufffd~y{now)\u20ac nk\ufffdk)\u20ac \ufffdk~tkzmo t\u20acr~ok\ufffdo~ \ufffdskz\n\ufffdsoyokz *\u00d0stms t\u20ackw\u20ac{ \u20ac\ufffd||{~\ufffdon l\u00de\ufffdso|{\u20act\ufffdt\ufffdow\u00de \u20acvo\u00d0on nk\ufffdk nt\u20ac\ufffd~tl\ufffd\ufffdt{z {q{\ufffd~no|oznoz\ufffd\n\ufffdk~tklwo \ufffdz\ufffdylo~ {qm{yyoz\ufffd\u20ac\ufffd+. ty|w\u00detzr k\u20actrztqtmkz\ufffd nk\ufffdk {\ufffdo~nt\u20ac|o~\u20act{z1 \\s\ufffd\u20ac. kzork\ufffdt\ufffdo\nltz{ytkw ~or~o\u20ac\u20act{z. \u00d0stms ~owk\u00f0o\u20ac \ufffdsok\u20ac\u20ac\ufffdy|\ufffdt{z ~ork~ntzr \ufffdk~tkzmo o}\ufffdkwtzr yokz. t\u20ack\ny{~o \u20ac\ufffdt\ufffdklwo y{now ms{tmo q{~{\ufffd~nk\ufffdk dq{~ y{~o tzq{~yk\ufffdt{z. \u20acoo433f *q{~ y{~o tzq{~yk/\n\ufffdt{z ~ork~ntzr {\ufffd~y{now ms{tmo. |wok\u20aco \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Uork\ufffdt\ufffdo ltz{ytkw\n~or~o\u20ac\u20act{z y{now\u20ac+1\n\\{~\ufffdz\ufffdsozork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z. \u00d0o\ufffd\u20aco\ufffdso\ufffdrwy1zl\ufffd q\ufffdzm\ufffdt{z q~{y \ufffdsoZ|kmvkro\n\ufffdTF[[1\ufffd U{\ufffdo \ufffdsk\ufffd \u00d0ontnz{\ufffd\u20ac\ufffdkznk~nt\u00feo \ufffdso\ufffdk~tklwo\u20ac loq{~o ~\ufffdzztzr \ufffdsoy{now\u20ac. k\u20ac\u00d0ontn\nz{\ufffdtzmw\ufffdno kz\u00detz\ufffdo~km\ufffdt{z \ufffdo~y\u20ac kzn sk\ufffdo {zw\u00de {zoz\ufffdyo~tm m{z\ufffd~{w \ufffdk~tklwo. \ufffdz\ufffdylo~ {q\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4925=\nm~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac1\ufffd Stvo\u00d0t\u20aco. \u20ac\ufffdkznk~nt\u00fetzr \ufffdso\ufffdk~tklwo\u20ac l\u00de\u20ac\ufffdl\ufffd~km\ufffdtzr \ufffdsoyokz kzn nt\ufffdtntzr \ufffdsoy\nl\u00de\ufffdso\u20ac\ufffdkznk~n no\ufffdtk\ufffdt{z loq{~o ~\ufffdzztzr kzork\ufffdt\ufffdo ltz{ytzkw ~or~o\u20ac\u20act{z ty|ono\u20ac \ufffdso\ntz\ufffdo~|~o\ufffdkltwt\ufffd\u00de {q\ufffdso~o\u20ac\ufffdw\ufffd\u20ac1 \\s\ufffd\u20ac. t\ufffdt\u20ac{q\ufffdoz {yt\ufffd\ufffdon \u00d0soz |o~q{~ytzr \ufffdst\u20ac\ufffd\u00de|o {qkzkw\u00de\u20act\u20ac\ndq{~ y{~o tzq{~yk\ufffdt{z. \u20acoo.o1r1. 434f1 \\{q\ufffd~\ufffdso~ msomv \ufffdso\u20ac\ufffdt\ufffdkltwt\ufffd\u00de {q{\ufffd~y{now. \u00d0om{z\ufffd~{w\nq{~y\ufffdw\ufffdtm{wwtzok~t\ufffd\u00de \u00d0t\ufffdstz {\ufffd~y{now \ufffds~{\ufffdrs \ufffdso\ufffdk~tkzmo tzqwk\ufffdt{z qkm\ufffd{~ *^OL+1 J{tzr \u20ac{.\n\u00d0ono\ufffdom\ufffd z{\u00d0{~~t\u20ac{yo m{~~owk\ufffdt{z lo\ufffd\u00d0ooz {\ufffd~\ufffdk~tklwo\u20ac *kww\ufffdkw\ufffdo\u20ac {q^OLD9.\u00d0t\ufffds \ufffdso\ufffdk~t/\nklwo\u20ac \ufffd\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\ufffd nt\u20ac|wk\u00detzr \ufffdsostrso\u20ac\ufffd \ufffdkw\ufffdo\u20ac {q41<+1 T{~o{\ufffdo~. \u00d0omsomv q{~{\ufffd\ufffdwt/\no~\u20actz{\ufffd~nk\ufffdk \u00d0stms m{\ufffdwn ltk\u20ac \ufffdso~o\u20ac\ufffdw\ufffd\u20ac1 \\so~oq{~o. \u00d0ok||w\u00de I{{v)\u20ac nt\u20ac\ufffdkzmo l\ufffd\ufffdno\ufffdom\ufffd z{\nnk\ufffdk |{tz\ufffd \ufffdsk\ufffd \u20ac\ufffd~|k\u20ac\u20aco\u20ac \ufffdsom~t\ufffdtmkw \ufffdkw\ufffdo {q4d435f1 \\s\ufffd\u20ac. {\ufffd~y{now t\u20ac\u20ac\ufffdt\ufffdklwo q{~{\ufffd~kzkw\u00de/\n\u20act\u20acl\u00de|~{\ufffdtntzr yokztzrq\ufffdw ~o\u20ac\ufffdw\ufffd\u20ac1\n\\klwo 5\u20acs{\u00d0\u20ac \ufffdso~o\u20ac\ufffdw\ufffd\u20ac {q{\ufffd~zork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z kzkw\u00de\u20act\u20ac *\ufffd{\ufffdo\u20ac\ufffd\ufffdso~{l\ufffd\u20ac\ufffdzo\u20ac\u20ac\n{q{\ufffd~y{now ~o\u20ac\ufffdw\ufffd\u20ac. \u00d0o~kzntqqo~oz\ufffd zork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now\u20ac lk\u20acon {z\ufffdk~tk\ufffdt{z\u20ac\n{q\ufffdsonk\ufffdk\u20aco\ufffd kzn \ufffdk~tklwo\u20ac? \u00d0soz m{y|k~tzr \ufffdso~o\u20ac\ufffdw\ufffd\u20ac. {zw\u00de \u20acykww no\ufffdtk\ufffdt{z\u20ac q~{y {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac\nmkzlono\ufffdom\ufffdon. \u20ac\ufffd\u20ac\ufffdktztzr {\ufffd~qtzntzr\u20ac? q{~y{~o tzq{~yk\ufffdt{z. \u20acoo[\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z.\nUork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now\u20ac+1\nU{\ufffdo \ufffdsk\ufffd \ufffdsoq{ww{\u00d0tzr tz\ufffdo~|~o\ufffdk\ufffdt{z {q\ufffdsotznt\ufffdtn\ufffdkw m{oqqtmtoz\ufffd\u20ac k\u20ac\u20ac\ufffdyo\u20ac \ufffdsk\ufffd kww{\ufffdso~\n\ufffdk~tklwo\u20ac k~osown m{z\u20ac\ufffdkz\ufffd1 Fw\u20ac{. \ufffdsozk\ufffd\ufffd~o {q\u20ac{mtkw yontk nk\ufffdk {zw\u00de kww{\u00d0\u20ac q{~m{~~owk\ufffdt\ufffdo\nk\u20ac\u20ac{mtk\ufffdt{z\u20ac lo\ufffd\u00d0ooz \ufffdso\ufffdk~tklwo\u20ac kzn mkzz{\ufffd lomk\ufffd\u20ackw1 \\s\ufffd\u20ac. \ufffdsoq{ww{\u00d0tzr ~o\u20ac\ufffdw\ufffd \u00d0twwlo\ntz\ufffdo~|~o\ufffdon krktz\u20ac\ufffd \ufffdst\u20aclkmvr~{\ufffdzn1\n_soz o\ufffdkw\ufffdk\ufffdtzr \ufffdsom{oqqtmtoz\ufffd {q{\ufffd~yktz tzno|oznoz\ufffd \ufffdk~tklwo. \ufffd\ufffdt{woz\ufffd tykro\ufffd\n*/31345+. \u00d0oqtzn\u02d8m{z\ufffd~k~\u00de \ufffd{{\ufffd~k\u20ac\u20ac\ufffdy|\ufffdt{z\u02d8\ufffdsk\ufffd tykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo k~ozork\ufffdt\ufffdow\u00de\nk\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds \ufffdsoz\ufffdylo~ {qm{yyoz\ufffd\u20ac. \u00deo\ufffdz{\ufffd{zk\u20ac\ufffdk\ufffdt\u20ac\ufffdtmkww\u00de \u20actrztqtmkz\ufffd lk\u20act\u20ac *H1+1\n\\so~oq{~o. \ufffdst\u20acqtzntzr mkzz{\ufffd lorozo~kwt\u00feon1 _soz kzkw\u00de\u00fetzr \ufffdso~o\u20ac\ufffdw\ufffd\u20ac {qk\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon\n\ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy. \ufffdsom{oqqtmtoz\ufffd {q{\ufffd~\ufffdt\ufffdwo)\u20ac \u20acoz\ufffdtyoz\ufffd kzkw\u00de\u20act\u20ac \u00d0t\ufffds GKZ\\ \ufffd\ufffd~z\u20ac {\ufffd\ufffd\ufffd{lo\u20actr/\nztqtmkz\ufffd *H2+. \u00d0t\ufffds k|/\ufffdkw\ufffdo {q3134. noy{z\u20ac\ufffd~k\ufffdtzr \ufffdsk\ufffd zork\ufffdt\ufffdo \ufffdt\ufffdwo\u20ac tzm~ok\u20aco \ufffdsow{rron\nm{\ufffdz\ufffd {qz\ufffdylo~ {qm{yyoz\ufffd\u20ac l\u00de314651 \\s\ufffd\u20ac. {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac \u20acs{\u00d0 \ufffdsk\ufffd k\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\ufffdwo z{\ufffd\n{zw\u00de sk\u20ack\u20actrztqtmkz\ufffd *\u20acoo |\ufffdkw\ufffdo+ l\ufffd\ufffdkw\u20ac{ kr~ok\ufffdo~ *\u20acoo m{oqqtmtoz\ufffd+ oqqom\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z\nm{y|k~on \ufffd{tykro\u20ac *H3+1\n_soz o\ufffdkw\ufffdk\ufffdtzr \ufffdsooqqom\ufffd\u20ac {qk\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac |~{\ufffdtno~. m{z\u20aco~\ufffdk\ufffdt\ufffdo kzn wtl/\no~kwzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac \u20actrztqtmkz\ufffdw\u00de zork\ufffdt\ufffdow\u00de ty|km\ufffd {\ufffd~no|oznoz\ufffd \ufffdk~tklwo m{y|k~on \ufffd{zo\ufffd\ufffd~kw\nzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac *|B3134 kzn |B314.~o\u20ac|om\ufffdt\ufffdow\u00de. m{oqqtmtoz\ufffd {q/31544 kzn /313==. ~o\u20ac|om\ufffdt\ufffdow\u00de+\n*H4+1 G{\ufffds strs kzn w{\u00d0qkm\ufffd\ufffdkw ~o|{~\ufffdtzr {qkzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd \u20actrztqtmkz\ufffdw\u00de ty|km\ufffd \ufffdsono|oznoz\ufffd\n\ufffdk~tklwo m{y|k~on \ufffd{yt\u00f0on qkm\ufffd\ufffdkw ~o|{~\ufffdtzr *H5+1 Ntrs qkm\ufffd\ufffdkw/~o|{~\ufffdtzr zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac |{\u20act/\n\ufffdt\ufffdow\u00de kqqom\ufffd \ufffdsow{rron m{\ufffdz\ufffd {qz\ufffdylo~ {qm{yyoz\ufffd\u20ac l\u00de313<6 m{y|k~on \ufffd{yt\u00f0on qkm\ufffd\ufffdkw/\n~o|{~\ufffdtzr {\ufffd\ufffdwo\ufffd\u20ac1 Ozm{z\ufffd~k\u20ac\ufffd. w{\u00d0qkm\ufffd\ufffdkw/~o|{~\ufffdtzr zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac k~ozork\ufffdt\ufffdow\u00de m{~~owk\ufffdon \u00d0t\ufffds\nkm{oqqtmtoz\ufffd {q/41339 *|\ufffdkw\ufffdo B3139 kzn 31334. ~o\u20ac|om\ufffdt\ufffdow\u00de+ m{y|k~on \ufffd{yt\u00f0on qkm\ufffd\ufffdkw\n~o|{~\ufffdtzr {\ufffd\ufffdwo\ufffd\u20ac1 Fzkw\u00de\u00fetzr \ufffdsooqqom\ufffd\u20ac {qkzo\u00d0\u20ac \u00d0ol\u20act\ufffdo)\u20ac \ufffd~kqqtm *H6+. l{\ufffds zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac \u00d0t\ufffds\nstrs kzn ytztykw \ufffd~kqqtm k~ozork\ufffdt\ufffdow\u00de k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds \ufffdsow{rron m{\ufffdz\ufffd {qz\ufffdylo~ {qm{y/\nyoz\ufffd\u20ac m{y|k~on \ufffd{zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac \u00d0t\ufffds yont\ufffdy \ufffd~kqqtm *l{\ufffds \u00d0t\ufffds k|\ufffdkw\ufffdo {q31334 kzn km{oqqt/\nmtoz\ufffd {q/3157: kzn /414=<. ~o\u20ac|om\ufffdt\ufffdow\u00de+1\n_soz o\u00f0kytztzr \ufffdso\ufffdk~tklwo\u20ac ~owk\ufffdon \ufffd{Zonnt\ufffd/\u20ac|omtqtm kqq{~nkzmo\u20ac kzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac.\n\ufffdso\ufffd\u00de|o {q\u20ac\ufffdl~onnt\ufffd *H7+ |wk\u00de\u20ac k\u20actrztqtmkz\ufffd ~{wo1 G{\ufffds ~2zo\u00d0\u20ac kzn ~2\u00d0{~wnzo\u00d0\u20ac |{\u20act\ufffdt\ufffdow\u00de m{~/\n~owk\ufffdo \u00d0t\ufffds \ufffdsow{rron m{\ufffdz\ufffd {qz\ufffdylo~ {qm{yyoz\ufffd\u20ac m{y|k~on \ufffd{~2|{wt\ufffdtm\u20ac *l{\ufffds k|\ufffdkw\ufffdo {q\n31334 kzn km{oqqtmtoz\ufffd {q31=;; kzn 31;:7. ~o\u20ac|om\ufffdt\ufffdow\u00de1 _so\ufffdso~ k\u20ac\ufffdlyt\u20ac\u20act{z t\u20acU[L_ *H8+\nn{o\u20ac z{\ufffd\u20ac\ufffdl\u20ac\ufffdkz\ufffdtkww\u00de ty|km\ufffd \ufffdsono|oznoz\ufffd \ufffdk~tklwo1 bo\ufffd. wtzv qwkt~ *H9+ kzn \ufffdsoz\ufffdylo~ {q\nm~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac *H10+ \ufffd\ufffd~z {\ufffd\ufffd\ufffd{lostrsw\u00de \u20actrztqtmkz\ufffd. \u00d0t\ufffds k|/\ufffdkw\ufffdo {q313341 Oqk\u20ac\ufffdlyt\u20ac\u20act{z t\u20ac\n\ufffdkrron \u00d0t\ufffds kwtzv qwkt~. t\ufffdzork\ufffdt\ufffdow\u00de m{~~owk\ufffdo\u20ac \u00d0t\ufffds \ufffdsow{rron m{\ufffdz\ufffd {qz\ufffdylo~ {qm{yyoz\ufffd\u20ac\nl\u00de/319::. \u00d0so~ok\u20ac \ufffdsoz\ufffdylo~ {qm~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac t\u20ac|{\u20act\ufffdt\ufffdow\u00de k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds \ufffdsono|oznoz\ufffd \ufffdk~t/\nklwo \u00d0t\ufffds 31<=:1\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4:25=\n\\klwo 51Uork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now *\u20ac\ufffdkznk~ no~~{~\u20ac tz|k~oz\ufffdso\u20aco\u20ac. |\ufffdkw\ufffdo\u20ac tz\u20ac}\ufffdk~o l~kmvo\ufffd\u20ac+1\nno|oznoz\ufffd m{\ufffdz\ufffd \ufffdk~tklwo >\nz\ufffdylo~ {qm{yyoz\ufffd\u20ac\n\ufffdt{woz\ufffd tykro /31345\n*313;5+\nd31<::f\nGKZ\\ \u20acoz\ufffdtyoz\ufffd zork\ufffdt\ufffdo 31465**\n*31377+\nd31336f\n|{wt\ufffdtm kwwokztzr m{z\u20aco~\ufffdk\ufffdt \ufffdo /31544**\n*313;6+\nd31337f\n|{wt\ufffdtmkw wokztzr m{z\u20ac|t~km\u00de /31549\n*31==3+\nd31<5<f\n|{wt\ufffdtmkw wokztzr wtlo~kw /313==\u02dd\n*3139<+\nd313<;f\nqkm\ufffd\ufffdkw ~o|{~\ufffdtzr strs 313<6*\n*31375+\nd3137:f\nqkm\ufffd\ufffdkw ~o|{~\ufffdtzr w{\u00d0 /41339***\n*31457+\nd31333f\n\ufffd~kqqtm strs /3157:***\n*313::+\nd31333f\n\ufffd~kqqtm ytztykw /414=<***\n*3154<+\nd31333f\n\u20ac\ufffdl~onnt\ufffd zo\u00d0\u20ac 31=;;***\n*3137<+\nd31333f\n\u20ac\ufffdl~onnt\ufffd \u00d0{~wnzo\u00d0\u20ac 31;:7***\n*313:=+\nd31333f\nU[L_ /415:7\n*31<37+\nd3144:f\nwtzv qwkt~ /319::***\n*3136;+\nd31333f\nz\ufffdylo~ {qm~{\u20ac\u20ac/|{\u20ac \ufffd\u20ac 31<=:***\n*31347+\nd31333f\n\u00d0oovozn ][|kmtqtm 3157=***\n*31375+\nd31333f\ny{~ztzr ][|kmtqtm /31339\n*3136=+\nd31<=<f\nztrs\ufffd ][|kmtqtm /313=;\u02dd\n*31393+\nd31397f\n\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd ykrk\u00fetzo 315:6**\n*313<:+\nd31335f\n*Continued +\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4;25=\nLtzkww\u00de. \u00d0soz o\ufffdkw\ufffdk\ufffdtzr \ufffdsooqqom\ufffd\u20ac {q{\ufffd~m{z\ufffd~{w \ufffdk~tklwo\u20ac. t\ufffd\ufffd\ufffd~z\u20ac {\ufffd\ufffd\ufffdsk\ufffd tqk\u20ac\ufffdlyt\u20ac\u20act{z\nt\u20ac|{\u20ac\ufffdon {zk\u00d0oovozn m{y|k~on \ufffd{k\u00d0oovnk\u00de. \ufffdsow{rron m{\ufffdz\ufffd z\ufffdylo~ {qm{yyoz\ufffd\u20ac t\u20ac|{\u20ac/\nt\ufffdt\ufffdow\u00de kqqom\ufffdon l\u00de3157= *|\ufffdkw\ufffdo B31334+1 \\so \ufffdtytzr {q|{\u20ac\ufffdtzr k\u20ac\ufffdlyt\u20ac\u20act{z kw\u20ac{ \u20acs{\u00d0\u20ac k\u20actr/\nztqtmkz\ufffd oqqom\ufffd1 [\ufffdlyt\u20ac\u20act{z\u20ac |\ufffdlwt\u20acson k\ufffdztrs\ufffd zork\ufffdt\ufffdow\u00de ty|km\ufffd \ufffdsono|oznoz\ufffd \ufffdk~tklwo l\u00de\n/313=; *|\ufffdkw\ufffdo {q314+ m{y|k~on \ufffd{\u20ac\ufffdlyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon n\ufffd~tzr \ufffdsokq\ufffdo~z{{z2o\ufffdoztzr *z{\ufffdo\n\ufffdsk\ufffd q{~]\\I. ]1[1 Ioz\ufffd~kw. ]1[1 Kk\u20ac\ufffdo~z \ufffdtyo\u20ac. kzn Ioz\ufffd~kw K\ufffd~{|okz \ufffdtyo\u20ac. \u00d0o~omot\ufffdo \ufffdso\n\u20ackyo oqqom\ufffd\u20ac q{~\ufffdso\u00d0oovozn+1 _soz o\u00f0kytztzr \ufffdsooqqom\ufffd {q\ufffdso\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd. ntrt\ufffdkw/\nl{~z yontk \ufffd\u00de|o\u20ac\u02d8zkyow\u00de \u00d0ol\u20act\ufffdo\u20ac\u02d8kzn ntrt\ufffdkw o\u00f0\ufffdoz\u20act{z\u20ac {q\ufffd~knt\ufffdt{zkw yontk. zkyow\u00de. ykrk/\n\u00fetzo\u20ac. zo\u00d0\u20ac krozmto\u20ac. kzn ~knt{ \u20ac\ufffdk\ufffdt{z\u20ac\u02d8sk\ufffdo k\u20actrztqtmkz\ufffd oqqom\ufffd m{y|k~on \ufffd{\ufffdso~oqo~ozmo\nmk\ufffdor{~\u00de zo\u00d0\u20ac|k|o~ *\u00d0stms low{zr\u20ac \ufffd{\ufffdsomk\ufffdor{~\u00de ntrt\ufffdkw o\u00f0\ufffdoz\u20act{z {q\ufffd~knt\ufffdt{zkw yontk {\ufffd\ufffd/\nwo\ufffd\u20ac+1 _ol\u20act\ufffdo\u20ac sk\ufffdo k\u20actrztqtmkz\ufffd |{\u20act\ufffdt\ufffdo k\u20ac\u20ac{mtk\ufffdt{z \u00d0t\ufffds 313=: kzn k|\ufffdkw\ufffdo {q3141[\ufffdlyt\u20ac/\n\u20act{z\u20ac \ufffdsk\ufffd qok\ufffd\ufffd~o wtzv\u20ac \ufffd{zo\u00d0\u20ac krozmto\u20ac {~~knt{ \u20ac\ufffdk\ufffdt{z\u20ac \u20actrztqtmkz\ufffdw\u00de zork\ufffdt\ufffdow\u00de m{~~owk\ufffdo \u00d0t\ufffds\n\ufffdsono|oznoz\ufffd \ufffdk~tklwo *m{oqqtmtoz\ufffd {q/31;:: kzn /316;9. ~o\u20ac|om\ufffdt\ufffdow\u00de. kzn k|\ufffdkw\ufffdo {q31334\nkzn 3139. ~o\u20ac|om\ufffdt\ufffdow\u00de+1 Ozm{z\ufffd~k\u20ac\ufffd. \u20ac\ufffdlyt\u20ac\u20act{z\u20ac qok\ufffd\ufffd~tzr wtzv\u20ac \ufffd{ykrk\u00fetzo\u20ac sk\ufffdo k|{\u20act\ufffdt\ufffdo\nty|km\ufffd {q315:6 kzn k|\ufffdkw\ufffdo {q3134 m{y|k~on \ufffd{zo\u00d0\u20ac|k|o~\u20ac *z{\ufffdo \ufffdsk\ufffd zo\u00d0\u20ac|k|o~ \u00d0k\u20acms{/\n\u20acozk\u20ack~oqo~ozmo mk\ufffdor{~\u00de lomk\ufffd\u20aco t\ufffdsk\u20ac\ufffdsor~ok\ufffdo\u20ac\ufffd z\ufffdylo~ {q{l\u20aco~\ufffdk\ufffdt{z\u20ac+1\n_soz m{y|k~tzr \ufffdsoFOI *Fvktvo Ozq{~yk\ufffdt{z I~t\ufffdo~t{z+ \ufffdkw\ufffdo {q{\ufffd~y{now \u00d0t\ufffds \ufffds{\u20aco {q\n\ufffdso{\ufffdso~ m{z\ufffd~{w y{now\u20ac *\u20acoo [\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Uork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z y{now\u20ac+.\n{\ufffd~y{now t\u20acot\ufffdso~ k\u20ac\u20ac\ufffdt\ufffdklwo {~qk~y{~o \u20ac\ufffdt\ufffdklwo q{~~o|~o\u20acoz\ufffdtzr \ufffdsonk\ufffdk *FOI \ufffdkw\ufffdo t\u20acm{z/\n\u20actno~klw\u00de \u20acykwwo~ m{y|k~on \ufffd{\ufffd\u00d0{y{now\u20ac kzn zok~w\u00de k\u20acltrk\u20ac\ufffdsoFOI {qkz{\ufffdso~ y{now+1\n\\s\ufffd\u20ac. {\ufffd~y{now qt\ufffd\u20ac\ufffdsonk\ufffdk \u00d0oww m{y|k~on \ufffd{\ufffdso{\ufffdso~ y{now\u20ac. ykvtzr t\ufffdk~owtklwo ms{tmo\nq{~kzkw\u00de\u00fetzr {\ufffd~nk\ufffdk1 Fw\u20ac{. k\u20ac\ufffdso~o\u20actn\ufffdkw no\ufffdtkzmo t\u20ac\u20actrztqtmkz\ufffdw\u00de \u20acykwwo~ \ufffdskz \ufffdsoz\ufffdww\\klwo 51*I{z\ufffdtz\ufffd on+\nno|oznoz\ufffd m{\ufffdz\ufffd \ufffdk~tklwo >\nz\ufffdylo~ {qm{yyoz\ufffd\u20ac\n\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd zo\u00d0\u20ac krozm\u00de /31;::***\n*31435+\nd31333f\n\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd {~rkzt\u00fek\ufffd t{z2q{\ufffdznk\ufffdt{z /31456\n*314<5+\nd31934f\n\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd ~knt{ /316;9*\n*31497+\nd31349f\n\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd \\^\u20ac\ufffdk\ufffdt{z 31395\n*3137;+\nd315::f\n\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd \u00d0ol\u20act\ufffdo 313=:\u02dd\n*313:7+\nd313:7f\nI{z\u20ac\ufffdkz\ufffd 615;:***\n*313=6+\nd31333f\nVl\u20aco~\ufffdk\ufffdt{z \u20ac\nU\ufffdww no\ufffdtkzm o\nZo\u20ac1 no\ufffdtkzmo\nFOI\n\\so\ufffdk\n[\ufffdn1 K~~{~9.<;6\n47.454 {z9.<;5 nq\n:.=36 {z9.<7= nq\n93.74:\n3199;\n3133=\nU{\ufffdo> \u02dd|D314?*|D3139? **|D3134. ***|D313341\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o135<<=:51\ufffd33 5\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4<25=\nno\ufffdtkzmo. \u00d0omkztzqo~ \ufffdsk\ufffd {\ufffd~y{now o\u00f0|wktz\u20ac k\u20actrztqtmkz\ufffd ky{\ufffdz\ufffd {q\ufffdso\ufffdk~tk\ufffdt{z tz\ufffdsonk\ufffdk\nm{y|k~on \ufffd{\ufffdsoz\ufffdww y{now1\nJt\ufffdm\ufffd\ufffd\ufffdt{z\nGk\u20acon {zkzo\ufffdkw\ufffdk\ufffdt{z {q{\ufffd~oy|t~tmkw ~o\u20ac\ufffdw\ufffd\u20ac. \u00d0omkz\u20ac\ufffdyyk~t\u00feo \ufffdsokz\u20ac\u00d0o~ \ufffd{{\ufffd~~o\u20acok~ms\n}\ufffdo\u20ac\ufffdt{z\u20ac k\u20acq{ww{\u00d0\u20ac> \ufffdt{woz\ufffd tykro\u20acdonotkqqom\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd. \u00d0so~ok\u20ac {\ufffdso~ k\ufffd\ufffd~t/\nl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{zo\u00d0\u20ac ~o|{~\ufffdtzr\u02d8\u20ac\ufffdms k\u20ac\ufffdso|{wt\ufffdtmkw wokztzr\u20ac kzn qkm\ufffd\ufffdkw ~o|{~\ufffdtzr {qkzo\u00d0\u20ac\n{\ufffd\ufffdwo\ufffd. kzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac \ufffdt\ufffdwo. Zonnt\ufffd m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn \u20ac\ufffdl~onnt\ufffd\u20ac. \ufffdso\ufffdtytzr {qk\u20ac\ufffdlyt\u20ac/\n\u20act{z. kzn kzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac yontk \ufffd\u00de|o\u02d8k~o significantly m{~~owk\ufffdon1 Oz\ufffdst\u20ac\u20acom\ufffdt{z. \u00d0ont\u20acm\ufffd\u20ac\u20ac\n\ufffdso\u20aco ~o\u20ac\ufffdw\ufffd\u20ac tz\ufffdsom{z\ufffdo\u00f0\ufffd {q{\ufffd~s\u00de|{\ufffdso\u20aco\u20ac l\u00de|~{\ufffdtntzr \ufffdso{~o\ufffdtmkw kzn |~km\ufffdtmkw\nty|wtmk\ufffdt{z\u20ac1\nOzwtrs\ufffd {q{\ufffd~oy|t~tmkw qtzntzr\u20ac. \u00d0omkzz{\ufffd \ufffdo~tq\u00de \ufffdsk\ufffd k\ufffdt{woz\ufffd \ufffdt\u20ac\ufffdkw ~o|~o\u20acoz\ufffdk\ufffdt{z wokn\u20ac\n\ufffd{r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z kzn y\ufffd\u20ac\ufffd \ufffdso~oq{~o ~ouom\ufffdH11V\ufffd~ qtzntzr\u20ac kwtrz \u00d0t\ufffds |~o\ufffdt{\ufffd\u20ac \u20ac\ufffd\ufffdnto\u20ac\n\ufffdsk\ufffd m{\ufffdwn z{\ufffdno\ufffdom\ufffd k\u20actrztqtmkz\ufffd ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz {zwtzo tykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo kzn\nk\ufffd\ufffdoz\ufffdt{z tzk|~{\ufffdo\u20ac\ufffd m{z\ufffdo\u00f0\ufffd d4:.4;f1 O\ufffdyk\u00de lo\ufffdsk\ufffd \ufffdt{woz\ufffd tykro\u20ac no|tm\ufffd kq{~y {qzork\ufffdt\ufffdt\ufffd\u00de\n\ufffdsk\ufffd t\u20ac\ufffd{{tz\ufffdoz\u20act\ufffdo q{~\u20ac{mtkw yontk \ufffd\u20aco~\u20ac \u00d0s{ |~oqo~ wo\u20ac\u20aczork\ufffdt\ufffdt\ufffd\u00de tz\ufffdsot~ zo\u00d0\u20ac m{z\u20ac\ufffdy|/\n\ufffdt{z d6f{~|~oqo~ \u20acskww{\u00d0 \u20ac{mtkw m{z\ufffdoz\ufffd q{~oz\ufffdo~\ufffdktzyoz\ufffd |\ufffd~|{\u20aco\u20ac d::f1 \\s\ufffd\u20ac. {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac\nm{zqt~y \ufffdsk\ufffd tykro \ufffdt~kwt\ufffd\u00de {z\u20ac{mtkw yontk\u02d8\u20ac\ufffdms k\u20ac\ufffdsotykro\u20ac {qmk\ufffd\u20ac \ufffdsk\ufffd ozu{\u00de \u20ac\ufffdms \ufffd~oyoz/\nn{\ufffd\u20ac |{|\ufffdwk~t\ufffd\u00de d:;f\u02d8 t\u20acstrsw\u00de m{z\ufffdo\u00f0\ufffd/\u20acoz\u20act\ufffdt\ufffdo1\nOzknnt\ufffdt{z. \u00d0ozoon \ufffd{voo| tzytzn \ufffdsk\ufffd tz{\ufffd~m\ufffd~~oz\ufffd \ufffdk\ufffd\ufffdoz\ufffdt{z om{z{y\u00de\ufffd d436f. \ufffdso~o\nt\u20ackzkl\ufffdznkzmo {q\u20ac{mtkw yontk m{z\ufffdoz\ufffd m{y|o\ufffdtzr q{~\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. \u00d0stms ytrs\ufffd ntytzt\u20acs\n\ufffdsooqqom\ufffd {qtykro\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo1 \\s\ufffd\u20ac. {\ufffd~kzkw\u00de\u20act\u20ac \u20acs{\u00d0\u20ac \ufffdsk\ufffd t\ufffdt\u20acntqqtm\ufffdw\ufffd \ufffd{~o|wtmk\ufffdo\no\u00f0t\u20ac\ufffdtzr qtzntzr\u20ac q~{y \ufffd~knt\ufffdt{zkw yontk ~o\u20acok~ms ~ork~ntzr \ufffdsooqqom\ufffd\u20ac {qzo\u00d0\u20ac qok\ufffd\ufffd~tzr \ufffdt{/\nwozmo {zk\ufffd\ufffdoz\ufffdt{z \ufffd{\ufffdso{zwtzo \u00d0{~wn1 Fw\ufffds{\ufffdrs |~o\ufffdt{\ufffd\u20ac ~o\u20acok~ms sk\u20ac\u20acs{\u00d0z \ufffdsk\ufffd {qqwtzo\nzo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z sklt\ufffd\u20ac mkzlo\ufffd~kz\u20acqo~~on {zwtzo d:3f. {zoy\ufffd\u20ac\ufffd ~oyoylo~ \ufffdsk\ufffd |~o\ufffdt{\ufffd\u20ac\n~o\u20acok~ms q{m\ufffd\u20acon {z\ufffdso\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd ~okno~\u20ac |~oqo~1 \\s\ufffd\u20ac. {\ufffd~qtzntzr\u20ac \u20acs{\ufffdwn z{\ufffdlo\n\u20acooz k\u20ackm{z\ufffd~kntm\ufffdt{z \ufffd{ok~wto~ qtzntzr\u20ac l\ufffd\ufffd~k\ufffdso~ k\u20ack\u20ac\ufffd||woyoz\ufffd q{m\ufffd\u20actzr {z\ufffdso\ufffd\u00de|o {q\n~o|{~\ufffdtzr1\nT{~o{\ufffdo~. {zoy\ufffd\u20ac\ufffd z{\ufffdo \ufffdsk\ufffd zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z {z\u20ac{mtkw yontk q{ww{\u00d0\u20ac kzoz\ufffdt~ow\u00de ntqqo~/\noz\ufffdw{rtm \ufffdskz \ufffdsowtzok~ zo\u00d0\u20ac o\u00f0|{\u20ac\ufffd~o {q\ufffd~knt\ufffdt{zkw yontk d437f1 \\st\u20ac m{\ufffdwn |k~\ufffdtkww\u00de o\u00f0|wktz\n\ufffdsont\ufffdo~roz\ufffd oqqom\ufffd\u20ac {qzo\u00d0\u20ac qok\ufffd\ufffd~tzr \ufffdt{wozmo tzntqqo~oz\ufffd yontk \u20aco\ufffd\ufffdtzr\u20ac1 L\ufffd\ufffd\ufffd~o ~o\u20acok~ms\nm{\ufffdwn o\u00f0|kzn \ufffdso\u20aco tz\u20actrs\ufffd\u20ac l\u00dem{yltztzr }\ufffdkz\ufffdt\ufffdk\ufffdt\ufffdo kzn }\ufffdkwt\ufffdk\ufffdt\ufffdo k||~{kmso\u20ac. k\u20ac|~{|{\u20acon\nl\u00deTt\ufffdmsow\u20ac\ufffdotz kzn G{m\u00fev{\u00d0\u20acvt d:4f1\nGo\u00de{zn \ufffdso\u20aco \ufffdso{~o\ufffdtmkw o\u00f0|wkzk\ufffdt{z\u20ac q{~{\ufffd~z{z/m{zqt~yk\ufffdt\ufffdo qtzntzr\u20ac. \u00d0okw\u20ac{ zoon \ufffd{\nm{z\u20actno~ \u20ac{yo oy|t~tmkw ~o\u20acok~ms no\u20actrz nomt\u20act{z\u20ac \ufffdsk\ufffd yk\u00de sk\ufffdo kqqom\ufffdon {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac1 Lt~\u20ac\ufffd. \ufffdso\n{|o~k\ufffdt{zkwt\u00fek\ufffdt{z {q\ufffd\ufffdt{wozmo\ufffd kmm{~ntzr \ufffd{Z\ufffdms\ufffd)\u20ac d:<f noqtzt\ufffdt{z t\u20ac}\ufffdt\ufffdo \u20ac\ufffd~tm\ufffd1 _soz ykz/\n\ufffdkww\u00de k\u20ac\u20aco\u20ac\u20actzr \ufffdsoGST tykro nk\ufffdk. \u00d0oqtzn \ufffdsk\ufffd \u20aco\ufffdo~kw tykro\u20ac m{\ufffdwn lotnoz\ufffdtqton k\u20ac\ufffd\ufffdt{woz\ufffd\ufffd\n\u00d0o~o \u00d0o\ufffd{kn{|\ufffd k~ok\u20ac{zklw\u00de \u20ac\ufffd~tm\ufffd l\ufffd\ufffdy{~o tzmw\ufffd\u20act\ufffdo noqtzt\ufffdt{z1\n[om{zn. kltzk~\u00de {|o~k\ufffdt{zkwt\u00fek\ufffdt{z t\u20ac|~{zo \ufffd{mwk\u20ac\u20actqtmk\ufffdt{z o~~{~\u20ac1 \\so |{~\ufffd~k\u00dekw {q\ufffdt{/\nwozmo tztykro\u20ac t\u20ackz\ufffdkzmon kzn m{y|wo\u00f0 m{zmo|\ufffd kzn {|o~k\ufffdt{zkwt\u00fetzr t\ufffdl\u00de\ufffd\ufffdtwt\u00fetzr km{z\ufffdtz/\n\ufffd{\ufffd\u20ac \ufffdk~tklwo \u00d0{\ufffdwn |~o\u20aco~\ufffdo knnt\ufffdt{zkw tzq{~yk\ufffdt{z. \u00d0stms ytrs\ufffd ty|~{\ufffdo {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac1\n\\st~n. \u00d0okzkw\u00de\u00feon \ufffdsoyktz tykro\u20ac \ufffd\u20acon tz\ufffdsozo\u00d0\u20ac k~\ufffdtmwo\u20ac \u20ac\ufffdlyt\ufffd\ufffdon \ufffd{Zonnt\ufffd1 _stwo\n\u00d0om{z\u20actno~ \ufffdst\u20ack~ok\u20ac{zklwo ms{tmo. o\u20ac\u20acoz\ufffdtkww\u00de ~o\u20ac\ufffd~tm\ufffdtzr {\ufffd~kzkw\u00de\u20act\u20ac \ufffd{\ufffdso\u20ac\ufffd~{zro\u20ac\ufffd k\ufffdktw/\nklwo \u20actrzkw q{~\ufffdso\ufffdt\u20ac\ufffdkw |{~\ufffd~k\u00dekw {q\ufffdt{wozmo tztykro\u20ac. o\u00f0\ufffdozntzr {\ufffd~~o\u20acok~ms \ufffd{knnt\ufffdt{zkw\n\ufffdt\u20ac\ufffdkw no|tm\ufffdt{z\u20ac {q\ufffdt{wozmo {z\u00d0ol\u20act\ufffdo\u20ac wtzvon tz\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \u00d0{\ufffdwn lotz\ufffdo~o\u20ac\ufffdtzr1 Stvo\u00d0t\u20aco.\n\ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac \ufffd\ufffdtwt\u00feon q{~{\ufffd~kzkw\u00de\u20act\u20ac |~{stlt\ufffd nt~om\ufffdw\u00de |{\u20ac\ufffdtzr tykro\u20ac \u00d0t\ufffdstz \u20ac\ufffdlyt\u20ac\u20act{z\u20ac1 F\u20ac\n\ufffdso\u20aco \u20ac\ufffdl~onnt\ufffd\u20ac k~o\ufffdsoy{\u20ac\ufffd |~{ytzoz\ufffd q{~zo\u00d0\u20ac \u20acsk~tzr kzn. \ufffds\ufffd\u20ac. k~oty|{~\ufffdkz\ufffd q{~kzkw\u00de\u00fe/\ntzr\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z tz~owk\ufffdt{z \ufffd{zo\u00d0\u20ac k~\ufffdtmwo\u20ac. \u00d0om{z\u20actno~ \ufffdst\u20acms{tmo k||~{|~tk\ufffdo1 bo\ufffd. lk\u20acon\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 4=25=\n{z\ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac) ~o\u20ac\ufffd~tm\ufffdt{z\u20ac {znt~om\ufffdw\u00de |{\u20ac\ufffdtzr tykro\u20ac. \u00d0ok~owtvow\u00de \ufffdzno~o\u20ac\ufffdtyk\ufffdtzr \ufffdso\noqqom\ufffd {q*\ufffdt{woz\ufffd+ tykro\u20ac1 _otz\ufffdt\ufffdo q\ufffd\ufffd\ufffd~o ~o\u20acok~ms \ufffd{o\u00f0\ufffdozn {\ufffd~kzkw\u00de\u20act\u20ac l\u00detzmw\ufffdntzr \u20ac\ufffdl~on/\nnt\ufffd\u20ac~owk\ufffdon \ufffd{\ufffdso\u20acsk~tzr {qzo\u00d0\u20ac \ufffdsk\ufffd kww{\u00d0 q{~\ufffdsont~om\ufffd |{\u20ac\ufffdtzr {qtykro\u20ac1\nLtzkww\u00de. \ufffdso{|o~k\ufffdt{zkwt\u00fek\ufffdt{z {q\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{\ufffdwn loo\u00f0\ufffdoznon l\u00de.q{~o\u00f0ky|wo. o\ufffdkw\ufffdk\ufffd/\ntzr\ufffdsom{z\ufffdoz\ufffd {qm{yyoz\ufffd\u20ac ykno \ufffd{\ufffdsokzkw\u00de\u00feon \u20ac\ufffdlyt\u20ac\u20act{z\u20ac1 \\sk\ufffd \u00d0{\ufffdwn kww{\u00d0 q{~\ufffdsokzkw/\n\u00de\u20act\u20ac{qtz\ufffdo~km\ufffdt{z n\u00dezkytm\u20ac \ufffd~trro~on l\u00de\ufffdt{woz\ufffd m{z\ufffdoz\ufffd1\n_stwo \u00d0on{z{\ufffdqtzn k\u20actrztqtmkz\ufffd oqqom\ufffd {q\ufffdso|{~\ufffd~k\u00dekw {q\ufffdt{wozmo tztykro\u20ac. \u20aco\ufffdo~kw {q\n{\ufffd~{\ufffdso~ zo\u00d0\u20ac/~owk\ufffdon k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac \u20acs{\u00d0 |~{yt\u20actzr ~o\u20ac\ufffdw\ufffd\u20ac1 L{~oy{\u20ac\ufffd ky{zr \ufffdso\u20aco. \u00d0oqtzn\n\u00d0soz kzkw\u00de\u00fetzr k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy \ufffdsk\ufffd zork\ufffdt\ufffdo \ufffdt\ufffdwo\u20ac m{~~owk\ufffdo \u20actrztqtmkz\ufffdw\u00de\n\u00d0t\ufffds \ufffdsok\ufffd\ufffdoz\ufffdt{z |ktn \ufffd{k\u20ac\ufffdlyt\u20ac\u20act{z {zZonnt\ufffd tz\ufffdsom{z\ufffdo\u00f0\ufffd {q{\ufffd~\u20ac\ufffd\ufffdn\u00de1 Nozmo. \u00d0omkz\nm{zqt~yH2kzn \ufffdsoty|wtmk\ufffdt{z\u20ac {q\ufffdsozork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac s{wn q{~\ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdo\u00f0\ufffd\n\u00d0t\ufffds kzork\ufffdt\ufffdo \u20acoz\ufffdtyoz\ufffd kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\st\u20ac qtzntzr kwtrz\u20ac \u00d0t\ufffds |~o\ufffdt{\ufffd\u20ac ~o\u20ac\ufffdw\ufffd\u20ac {z\ufffdso\n|{\u20act\ufffdt\ufffdo ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz zork\ufffdt\ufffdo oy{\ufffdt{zkw wkzr\ufffdkro kzn tzq{~yk\ufffdt{z \u20ac|~okn {zwtzo\nd6.439f1 Ozknnt\ufffdt{z. t\ufffdoy|sk\u20act\u00feo\u20ac \ufffdsoty|{~\ufffdkzmo {q\ufffdzork\ufffdt\ufffdt\ufffd\u00de\ufffd \u00d0soz ~o|{~\ufffdtzr zo\u00d0\u20ac d:7f1\nbo\ufffd. \u00d0soz o\ufffdkw\ufffdk\ufffdtzr \ufffdso\u20aco qtzntzr\u20ac. \ufffdsotz\ufffdo~zkw \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {q\ufffdsom{z\u20actno~on \u20ac\ufffdl~onnt\ufffd\u20ac zoon\u20ac\n\ufffd{lo\ufffdkvoz tz\ufffd{ kmm{\ufffdz\ufffd1 Fmm{~ntzr \ufffd{\ufffdso~\ufffdwo\u20ac {q\ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac \u00d0okzkw\u00de\u00feon. k\ufffdkwtn \u20ac\ufffdlyt\u20ac/\n\u20act{z qok\ufffd\ufffd~o\u20ac k\ufffdt\ufffdwo kzn kwtzv \ufffd{kzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac \u00d0ol\u20act\ufffdo1 [\ufffdlyt\u20ac\u20act{z\u20ac z{\ufffdq{ww{\u00d0tzr \ufffdso\u20aco ~\ufffdwo\u20ac\nk~o~oy{\ufffdon tyyontk\ufffdow\u00de. tzntmk\ufffdtzr \ufffdsk\ufffd Zonnt\ufffd kzn t\ufffd\u20acm{yy\ufffdzt\ufffdto\u20ac yontk\ufffdo kzn ~o\u20ac\ufffd~tm\ufffd \ufffdso\ntzq{~yk\ufffdt{z o\u00f0mskzron1 \\so\u20aco y{no~k\ufffdtzr ~\ufffdwo\u20ac oy|sk\u20act\u00feo k\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\ufffdwo. |{\ufffdoz\ufffdtkww\u00de\nozskzmtzr t\ufffd\u20acoqqom\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\st\u20ac qtzntzr krktz strswtrs\ufffd\u20ac \ufffdsoty|{~\ufffdkzmo {qm{z\u20actn/\no~tzr \ufffdsow{rtm {qk\u20ac\ufffdl~onnt\ufffd)\u20ac kqq{~nkzmo\u20ac kzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac \ufffd{kzkw\u00de\u00feo \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z d:=f1\nOzm{z\ufffd~k\u20ac\ufffd \ufffd{{\ufffd~k\u20ac\u20ac\ufffdy|\ufffdt{z\u20ac. \u00d0omkzz{\ufffd m{zqt~y \ufffdsk\ufffd tykro\u20ac \u20actrztqtmkz\ufffdw\u00de ty|km\ufffd \ufffd\u20aco~\nk\ufffd\ufffdoz\ufffdt{z y{~o \ufffdskz \u00d0~t\ufffd\ufffdoz \ufffdo\u00f0\ufffd1 I{z\u20actno~tzr \ufffdsk\ufffd {\ufffd~\u20ac\ufffd\ufffdn\u00de \u20acs{\u00d0\u20ac \ufffdsk\ufffd k\u20ac\ufffdlyt\u20ac\u20act{z \ufffdt\ufffdwo)\u20ac\nzork\ufffdt\ufffdo \u20acoz\ufffdtyoz\ufffd sk\u20ackr~ok\ufffdo~ m{oqqtmtoz\ufffd kzn y{~o \u20actrztqtmkz\ufffd oqqom\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \ufffdskz\n\ufffdt{wozmo qok\ufffd\ufffd~on tz\ufffdsokmm{y|kz\u00detzr tykro\u20ac. \ufffdso|tm\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd n{o\u20ac z{\ufffds{wn tz\n{\ufffd~kzkw\u00de\u20act\u20ac1 \\s\ufffd\u20ac. \u00d0oy\ufffd\u20ac\ufffd ~ouom\ufffdH31V\ufffdso~ \u20ac\ufffd\ufffdnto\u20ac sk\ufffdo m{yo \ufffd{\u20actytwk~ m{zmw\ufffd\u20act{z\u20ac \ufffdsk\ufffd\nkw\ufffds{\ufffdrs zo\u00d0\u20ac \u20acsk~on {zk\ufffdzo\u00d0\u20ac krr~ork\ufffd{~ \u00d0ol\u20act\ufffdo\ufffd qok\ufffd\ufffd~tzr tykro\u20ac |{\u20act\ufffdt\ufffdow\u00de kqqom\ufffd\u20ac \ufffdso\n~okno~\u20acst|. tykro\u20ac zork\ufffdt\ufffdow\u00de kqqom\ufffd \ufffdsoz\ufffdylo~ {qm{yyoz\ufffd\u20ac kzk~\ufffdtmwo ~omot\ufffdo\u20ac n\ufffdo\ufffd{\ufffdsot~\nnt\u20ac\ufffd~km\ufffdtzr msk~km\ufffdo~ d43:f1 [tzmo Zonnt\ufffd t\u20ack\u20ac{mtkw yontk \u00d0ol\u20act\ufffdo vz{\u00d0z q{~ozm{\ufffd~krtzr \ufffdso\n|{\u20ac\ufffdtzr {qm{yyoz\ufffd\u20ac kzn \ufffdsont\u20acm\ufffd\u20ac\u20act{z ky{zr\u20ac\ufffd \ufffd\u20aco~\u20ac d43;f. t\ufffd{|o~k\ufffdo\u20ac oz\ufffdt~ow\u00de ntqqo~oz\ufffdw\u00de\n\ufffdskz zo\u00d0\u20ac krr~ork\ufffd{~ \u00d0ol\u20act\ufffdo\u20ac1 \\s\ufffd\u20ac. \u00d0om{z\u20actno~ {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac k\u20acm{y|woyoz\ufffdk~\u00de \ufffd{|~o\ufffdt{\ufffd\u20ac\n~o\u20acok~ms1 F\u20ackzo\u00f0\ufffdoz\u20act{z {q{\ufffd~\u00d0{~v. q\ufffd\ufffd\ufffd~o ~o\u20acok~ms m{\ufffdwn kzkw\u00de\u00feo \u20ac\ufffdl~onnt\ufffd\u20ac \u00d0t\ufffds nt\ufffdo~rtzr\nm{yy\ufffdzt\ufffd\u00de r\ufffdtnowtzo\u20ac. \u00d0stms m{\ufffdwn ty|km\ufffd \ufffdso|~{ytzozmo {qtykro\u20ac kzn. \ufffds\ufffd\u20ac. \ufffdsok\ufffd\ufffdoz\ufffdt{z\n|ktn \ufffd{\ufffdsoy1\n_o{l\u20aco~\ufffdo \u20aco\ufffdo~kw tz\ufffdo~o\u20ac\ufffdtzr oqqom\ufffd\u20ac \u00d0soz kzkw\u00de\u00fetzr \ufffdsoty|km\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {qk\ufffd\ufffd~t/\nl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac |~{\ufffdtno~1 Ozm{z\ufffd~k\u20ac\ufffd \ufffd{|~o\ufffdt{\ufffd\u20ac ~o\u20acok~ms \ufffdsk\ufffd q{\ufffdzn z{~owk\ufffdt{z\u20acst|.\ntz\ufffdsom{z\ufffdo\u00f0\ufffd {qzork\ufffdt\ufffdo zo\u00d0\u20ac. lo\ufffd\u00d0ooz kzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac |{wt\ufffdtmkw \u20ac\ufffdkzmo kzn \ufffd\u20aco~ ozrkroyoz\ufffd\nd439f. \u00d0ok~oklwo \ufffd{\u20acs{\u00d0 \ufffdsk\ufffd m{z\u20aco~\ufffdk\ufffdt\ufffdo kzn wtlo~kw zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac m{~~owk\ufffdo \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz/\n\ufffdt{z zork\ufffdt\ufffdow\u00de m{y|k~on \ufffd{zo\ufffd\ufffd~kw ~o|{~\ufffdtzr\u02d8m{z\ufffd~k~\u00de \ufffd{{\ufffd~k\u20ac\u20ac\ufffdy|\ufffdt{z\u20ac1 \\s\ufffd\u20ac. \u00d0oy\ufffd\u20ac\ufffd\n~ouom\ufffdH41\\so~oq{~o. {\ufffd~qtzntzr\u20ac tzntmk\ufffdo \ufffdsk\ufffd \ufffd\u20aco~\u20ac tz\ufffdo~o\u20ac\ufffdon tzGST qk\ufffd{~ k|{wt\ufffdtmkww\u00de zo\ufffd/\n\ufffd~kw~o|{~\ufffdtzr \u20ac\ufffd\u00dewo \u00d0soz tzq{~ytzr \ufffdsoy\u20acow\ufffdo\u20ac kl{\ufffd\ufffd zo\u00d0\u20ac |{\u20ac\ufffdon tz\ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac {q\nkzkw\u00de\u20act\u20ac1 [tzmo k\ufffdoz\u20aco |{wt\ufffdtmkw mwtyk\ufffdo \u20ac\ufffd~~{\ufffdzn\u20ac GST d5=f. {zo~ok\u20ac{z q{~\ufffdst\u20acqtzntzr m{\ufffdwn\nlo\ufffdsk\ufffd \ufffd\u20aco~\u20ac |~oqo~ \ufffdsot~ tzq{~yk\ufffdt{z m{z\u20ac\ufffdy|\ufffdt{z \ufffd{lowo\u20ac\u20ac|{wt\ufffdtmkww\u00de msk~ron1\n]zwtvo |~o\ufffdt{\ufffd\u20ac ~o\u20acok~ms d;9f. \u00d0ontnqtzn k\u20actrztqtmkz\ufffd |{\u20act\ufffdt\ufffdo m{~~owk\ufffdt{z lo\ufffd\u00d0ooz strs\nqkm\ufffd\ufffdkw ~o|{~\ufffdtzr *\ufffd\ufffd~\ufffdo zo\u00d0\u20ac\ufffd+ kzn kzork\ufffdt\ufffdo m{~~owk\ufffdt{z lo\ufffd\u00d0ooz w{\u00d0qkm\ufffd\ufffdkw ~o|{~\ufffdtzr *\ufffdqkw\u20aco\nzo\u00d0\u20ac\ufffd+ kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y|k~on \ufffd{yt\u00f0on qkm\ufffd\ufffdkw ~o|{~\ufffdtzr1 I{z\u20aco}\ufffdoz\ufffdw\u00de. \u00d0oy\ufffd\u20ac\ufffd ~ouom\ufffd\nH51Vzo |{\u20ac\u20actlwo o\u00f0|wkzk\ufffdt{z t\u20ac\ufffdsk\ufffd |~o\ufffdt{\ufffd\u20ac ~o\u20acok~ms q{m\ufffd\u20acon {z\ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdso\n~k|tn \u20ac|~okn {q\ufffd\u00d0oo\ufffd\u20ac qok\ufffd\ufffd~tzr yt\u20actzq{~yk\ufffdt{z kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z d;9f. \u00d0so~ok\u20ac \u00d0oq{m\ufffd\u20ac {z\n\ufffdsooqqom\ufffd\u20ac {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {qkntrt\ufffdkw zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd)\u20ac ~o|{~\ufffdtzr \u20ac\ufffd\u00dewo1 \\s\ufffd\u20ac. t\ufffd\u20acooy\u20ac \ufffdsk\ufffd \ufffdso\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5325=\nk\ufffdntozmo q{~zo\u00d0\u20ac kl{\ufffd\ufffd GST t\u20acy{~o tz\ufffdo~o\u20ac\ufffdon tzqkm\ufffd\ufffdkw ~o|{~\ufffdtzr. \u00d0stms m{\ufffdwn lok\ufffd\ufffd~tl/\n\ufffd\ufffdon \ufffd{\ufffdso\ufffd{|tm)\u20ac |{wt\ufffdtmkw ~owo\ufffdkzmo kzn \ufffdsono\u20act~o \ufffd{m{\ufffdz\ufffdo~ o\u00f0t\u20ac\ufffdtzr |{wk~t\u00feon |{\u20act\ufffdt{z\u20ac\nd5=f1 \\st\u20ac qtzntzr kw\u20ac{ kwtrz\u20ac \u00d0t\ufffds \ufffdsoty|~o\u20ac\u20act{z \ufffdsk\ufffd \ufffd\u20aco~\u20ac tz\ufffdo~o\u20ac\ufffdon tzGST {zZonnt\ufffd qk\ufffd{~\nwo\u20ac\u20ac|{wt\ufffdtmkww\u00de msk~ron zo\u00d0\u20ac m{z\ufffdoz\ufffd1 L\ufffd\ufffd\ufffd~o ~o\u20acok~ms m{\ufffdwn l\ufffdtwn \ufffd|{z \ufffdso\u20aco tzt\ufffdtkw qtzntzr\u20ac\nkzn nt\ufffdo noo|o~ tz\ufffd{ ~o|{~\ufffdtzr)\u20ac wo\ufffdow {qqkm\ufffd\ufffdkwt\ufffd\u00de kzn k\ufffd\ufffdoz\ufffdt{z n\u00dezkytm\u20ac {z\u20ac{mtkw yontk1\nOzH6.\u00d0ok\u20ac\u20ac\ufffdyon k|{\u20act\ufffdt\ufffdo ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \ufffdso|{|\ufffdwk~t\ufffd\u00de {qkzo\u00d0\u20ac \u00d0ol\u20act\ufffdo kzn \ufffdso\nk\ufffd\ufffdoz\ufffdt{z ~omot\ufffdon l\u00de\u20ac\ufffdlyt\u20ac\u20act{z\u20ac \ufffd{t\ufffd1V\ufffd~ nk\ufffdk. s{\u00d0o\ufffdo~. ~o\ufffdokw kzork\ufffdt\ufffdo m{~~owk\ufffdt{z\nlo\ufffd\u00d0ooz \ufffdo~\u00de |{|\ufffdwk~ kzn \ufffdo~\u00de \ufffdz|{|\ufffdwk~ zo\u00d0\u20ac \u00d0ol\u20act\ufffdo\u20ac \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 \\so~oq{~o. \u00d0o\n~ouom\ufffdH61\\st\u20ac qtzntzr mkzlo\u20acooz k\u20actzwtzo\u00d0t\ufffds \ufffdsoqtzntzr\u20ac ~ork~ntzr qkm\ufffd\ufffdkw ~o|{~\ufffdtzr kzn\n|{wt\ufffdtmkw wokztzr> _soz w{{vtzr tz\ufffd{ {\ufffd~nk\ufffdk. |{|\ufffdwk~ zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac {q\ufffdoz qok\ufffd\ufffd~o kw{\u00d0/ \ufffd{\nyt\u00f0on qkm\ufffd\ufffdkw ~o|{~\ufffdtzr \u20ac\ufffd\u00dewo kzn \ufffdozn \ufffd{lo|{wt\ufffdtmkww\u00de msk~ron *o1r1. L{\u00f0 Uo\u00d0\u20ac. Jktw\u00de Tktw. {~\n\\so M\ufffdk~ntkz+1 \\s\ufffd\u20ac. \u00d0o{l\u20aco~\ufffdo k\ufffdoznozm\u00de \ufffdsk\ufffd \ufffd\u20aco~\u20ac |~oqo~ yont\ufffdy |{|\ufffdwk~ {\ufffd\ufffdwo\ufffd\u20ac \ufffdsk\ufffd k~o\n\ufffdt\u20actlwo *z{\ufffd ytztykw \ufffd~kqqtm+. \u00d0t\ufffds qkm\ufffd\ufffdkw kzn |{wt\ufffdtmkww\u00de \ufffdzltk\u20acon ~o|{~\ufffdtzr *o1r1. G~tzr To\n\\so Uo\u00d0\u20ac {~RT[W L{\u00f0 =+1\n\\so oqqom\ufffd\u20ac {q{\ufffd~k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{Zonnt\ufffd/\u20ac|omtqtm \ufffdk~tklwo\u20ac kw\u20ac{ wokn \ufffd{tz\ufffdo~o\u20ac\ufffdtzr qtzn/\ntzr\u20ac \ufffdsk\ufffd strswtrs\ufffd \ufffdsoty|{~\ufffdkzmo {qk|wk\ufffdq{~y)\u20ac kqq{~nkzmo\u20ac kzn m{yy\ufffdzt\ufffd\u00de y{no~k\ufffdtzr\n~\ufffdwo\u20ac1 _stwo \u00d0omkzz{\ufffd m{zqt~y \ufffdsk\ufffd \ufffdsok\ufffd\ufffdkmsyoz\ufffd {qkU[L_ \ufffdkr*H8+ \u20actrztqtmkz\ufffdw\u00de m{~~o/\nwk\ufffdo\u20ac \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. \u00d0o\u20acoo\ufffdsk\ufffd k\u20ac\ufffdl~onnt\ufffd tz\u00d0stms k\u20ac\ufffdlyt\u20ac\u20act{z t\u20ac|{\u20ac\ufffdon *H7+. \ufffdsoqwkt~\n\ufffdkr*H9+ k\ufffd\ufffdkmson \ufffd{k\u20ac\ufffdlyt\u20ac\u20act{z. kzn \ufffdsoz\ufffdylo~ {qm~{\u20ac\u20ac/|{\u20ac\ufffdtzr\u20ac *H10+ n{o\u20ac m{~~owk\ufffdo \u00d0t\ufffds\n\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 Gk\u20acon {z\ufffdso\u20aco qtzntzr\u20ac. \u00d0okrktz mkzz{\ufffd m{zqt~y \ufffdsk\ufffd y{~o \ufffdt{wozmo *U[L_+\nwokn\u20ac \ufffd{r~ok\ufffdo~ \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 _o~oq~ktz. \ufffds{\ufffdrs. q~{y {\ufffdo~\u20ac\ufffdk\ufffdtzr \ufffdso\u20actrztqtmkzmo {q\ufffdst\u20ac\nqtzntzr n\ufffdo\ufffd{\ufffdso\ufffdk~tklwo)\u20ac strsw\u00de \u20acvo\u00d0on nt\u20ac\ufffd~tl\ufffd\ufffdt{z *\u20acoo [\ufffd||{~\ufffdtzr Ozq{~yk\ufffdt{z. Jo\u20acm~t|/\n\ufffdt\ufffdo{\ufffdo~\ufffdto\u00d0 {q\ufffdk~tklwo\u20ac+1\nStvo\u00d0t\u20aco. \ufffdso|tm\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd kw\u20ac{ n{o\u20ac z{\ufffds{wn q{~\ufffdso|{\u20ac\ufffdtzr {q\ufffds\ufffdylzktw\u20ac *~2\n|{wt\ufffdtm\u20ac+. \u00d0stms strswtrs\ufffd\u20ac krktz \ufffdso|~{ytzozmo {qk\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac \ufffdt\ufffdwo kzn \ufffdso|k~\ufffdtm\ufffdwk~\n\u20ac\ufffd~\ufffdm\ufffd\ufffd~o {q\ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac \u00d0om{z\u20actno~on1 O\ufffdt\u20actz\ufffdo~o\u20ac\ufffdtzr \ufffd{{l\u20aco~\ufffdo \ufffdsk\ufffd ~2zo\u00d0\u20ac kzn ~2\u00d0{~wn/\nzo\u00d0\u20ac m{~~owk\ufffdo |{\u20act\ufffdt\ufffdow\u00de \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y|k~on \ufffd{~2|{wt\ufffdtm\u20ac1 \\st\u20ac m{\ufffdwn lok\u20actrz \ufffdsk\ufffd\n\ufffd\u20aco~\u20ac tz\ufffdo~o\u20ac\ufffdon tzGST k~o~k\ufffdso~ w{{vtzr q{~kztz\ufffdo~zk\ufffdt{zkw |o~\u20ac|om\ufffdt\ufffdo {zGST *~2zo\u00d0\u20ac. ~2\n\u00d0{~wnzo\u00d0\u20ac+ k\u20act\ufffdt\u20ack\u00d0{~wn\u00d0tno |~{\ufffdo\u20ac\ufffd d54f m{y|k~on \ufffd{\u20ac{wow\u00de ~okntzr GST zo\u00d0\u20ac ~owk\ufffdon \ufffd{\n\ufffdso][m{z\ufffdo\u00f0\ufffd *~2|{wt\ufffdtm\u20ac+1\nLtzkww\u00de. k\u20ac\ufffdl~onnt\ufffd)\u20ac m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn y{no~k\ufffdt{z *wtzv qwkt~+ \u20actrztqtmkz\ufffdw\u00de kqqom\ufffd\n\u00d0so\ufffdso~ k|{\u20ac\ufffd \u00d0twwlo\ufffdt\u20actlwo \ufffd{Zonnt\ufffd \ufffd\u20aco~\u20ac kzn \ufffds\ufffd\u20ac ~omot\ufffdo k\ufffd\ufffdoz\ufffdt{z1 \\so |{\u20act\ufffdt\ufffdo ~owk\ufffdt{z/\n\u20acst| lo\ufffd\u00d0ooz m~{\u20ac\u20ac/|{\u20ac\ufffd\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z kw\u20ac{ m{zqt~y\u20ac \ufffdst\u20acoqqom\ufffd {q\ufffdt\u20actltwt\ufffd\u00de {z\ufffd\u20aco~ k\ufffd\ufffdoz/\n\ufffdt{z1 \\so~oq{~o. \ufffdzno~\u20ac\ufffdkzntzr Zonnt\ufffd)\u20ac \u20ac|omtqtm kqq{~nkzmo\u20ac kzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac *\u00d0stms\nntqqo~ strsw\u00de lo\ufffd\u00d0ooz \ufffdsoy\ufffdw\ufffdt\ufffd\ufffdno {q\u20ac\ufffdl~onnt\ufffd\u20ac s{\u20ac\ufffdon {zZonnt\ufffd+ t\u20acty|{~\ufffdkz\ufffd q{~mk|\ufffd\ufffd~tzr\nk\ufffd\ufffdoz\ufffdt{z nt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac {z\ufffdso|wk\ufffdq{~y1 [\ufffdyyk~t\u00fetzr \ufffdso\u20aco qtzntzr\u20ac. \u00d0oy\ufffd\u20ac\ufffd ~ouom\ufffdH7kzn\nH8.l\ufffd\ufffd\u00d0om{zqt~yH9kznH101\n_soz o\ufffdkw\ufffdk\ufffdtzr \ufffdsooqqom\ufffd\u20ac {q{\ufffd~\ufffdtyo m{z\ufffd~{w\u20ac. \ufffd\u00d0oovozn\ufffd kzn \ufffd\ufffdtyo {qnk\u00de\ufffd \ufffd\ufffd~z {\ufffd\ufffd\ufffd{\nlo\u20actrztqtmkz\ufffd1 V\ufffd~ ~o\u20ac\ufffdw\ufffd\u20ac \u20acs{\u00d0 \ufffdsk\ufffd Zonnt\ufffd \ufffd\u20aco~\u20ac k~oy{~o km\ufffdt\ufffdo n\ufffd~tzr \ufffdso\u00d0oovozn kzn \ufffdso\nkq\ufffdo~z{{z2o\ufffdoztzr. ~o\u20ac\ufffdw\ufffdtzr tzstrso~ k\ufffd\ufffdoz\ufffdt{z |ktn \ufffd{\u20ac\ufffdlyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon {z\ufffdso\u00d0oovozn\nkzn n\ufffd~tzr \ufffdsk\ufffd |o~t{n *45|y \ufffd{<|y+ \ufffdskz \ufffds{\u20aco |{\u20ac\ufffdon k\ufffdztrs\ufffd1 \\so qt~\u20ac\ufffd qtzntzr t\u20ac\ufffdz\u20ac\ufffd~/\n|~t\u20actzr. k\u20ac\ufffd\u20aco~\u20ac \ufffdozn \ufffd{sk\ufffdo y{~o \ufffdtyo {z\u00d0oovozn\u20ac \ufffd{ozrkro \u00d0t\ufffds \u20ac{mtkw yontk \ufffdskz {z\n\u00d0oovnk\u00de\u20ac1 Ozm{z\ufffd~k\u20ac\ufffd. t\ufffdt\u20ac\u20ac{yo\u00d0sk\ufffd \u20ac\ufffd~|~t\u20actzr \ufffdsk\ufffd \ufffd\u20aco~\u20ac \ufffdozn \ufffd{m{z\u20ac\ufffdyo kzn m{yyoz\ufffd {z\nzo\u00d0\u20ac y{~o {q\ufffdoz n\ufffd~tzr \ufffdsonk\u00dem{y|k~on \ufffd{\ufffdsoztrs\ufffd *zork\ufffdt\ufffdo oqqom\ufffd {q\u20ac\ufffdlyt\u20ac\u20act{z\u20ac |{\u20ac\ufffdon\nn\ufffd~tzr \ufffdsoztrs\ufffd+1 bo\ufffd. \ufffdst\u20acqtzntzr kwtrz\u20ac \u00d0t\ufffds {\ufffd~ty|~o\u20ac\u20act{z \ufffdsk\ufffd \ufffd\u20aco~\u20ac {q\ufffdso\u20ac\ufffdl~onnt\ufffd\u20ac \u00d0o\nkzkw\u00de\u00feon \u00d0s{ k~otz\ufffdo~o\u20ac\ufffdon tzGST |~oqo~ \ufffd{m{z\u20ac\ufffdyo \ufffdsot~ zo\u00d0\u20ac tzkz{~rkzt\u00feon qk\u20acst{z *\u20actr/\nztqtmkzmo {q~or\ufffdwk~ \u00d0{~vtzr s{\ufffd~\u20ac kzn z{\ufffdk\ufffdztrs\ufffd+1 N{\u00d0o\ufffdo~. \ufffdso\u20aco ~o\u20ac\ufffdw\ufffd\u20ac lk\u20acon {z]1[1\n\ufffdtyo \u00fe{zo\u20ac y\ufffd\u20ac\ufffd lo\ufffd~ok\ufffdon \u00d0t\ufffds mk\ufffd\ufffdt{z \u20actzmo GST t\u20ackztz\ufffdo~zk\ufffdt{zkw y{\ufffdoyoz\ufffd \u00d0t\ufffds kz\nk\ufffdntozmo \ufffdsk\ufffd wtvow\u00de ozrkro\u20ac \u00d0t\ufffds GST zo\u00d0\u20ac m{z\ufffdoz\ufffd q~{y ntqqo~oz\ufffd \ufffdtyo \u00fe{zo\u20ac km~{\u20ac\u20ac \ufffdso\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5425=\nrw{lo1 Uo\ufffdo~\ufffdsowo\u20ac\u20ac. \ufffdso\u20aco ]1[1/moz\ufffdo~on qtzntzr\u20ac k~o\u20ac\ufffdtwwtz\ufffdo~o\u20ac\ufffdtzr \ufffd{\ufffdkvo tz\ufffd{ kmm{\ufffdz\ufffd. o\u20ac|o/\nmtkww\u00de rt\ufffdoz \ufffdsk\ufffd y{\u20ac\ufffd Zonnt\ufffd \ufffd\u20aco~\u20ac k~o]1[1/lk\u20acon kzn \ufffdsoGST y{\ufffdoyoz\ufffd {~trtzk\ufffdo\u20ac q~{y \ufffdso\n]zt\ufffdon [\ufffdk\ufffdo\u20ac1\nZork~ntzr \ufffdso\ufffd\u00de|o {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd. \u00d0okw\u20ac{ qtzn \u20actrztqtmkz\ufffd oqqom\ufffd\u20ac {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 Oz{\ufffd~\nkzkw\u00de\u20act\u20ac. \u00d0ol\u20act\ufffdo\u20ac m{z\u20actno~on ntrt\ufffdkw/l{~z zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac kzn ykrk\u00fetzo\u20ac. zo\u00d0\u20ac krozmto\u20ac. kzn\n~knt{ \u20ac\ufffdk\ufffdt{z\u20ac m{z\u20actno~on ntrt\ufffdkw o\u00f0\ufffdoz\u20act{z\u20ac {q\ufffd~knt\ufffdt{zkw yontk \u20actrztqtmkz\ufffdw\u00de m{~~owk\ufffdo \u00d0t\ufffds\n\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y|k~on \ufffd{zo\u00d0\u20ac|k|o~\u20ac1 _omkz{l\u20aco~\ufffdo \ufffdsk\ufffd ok\u20ac\u00de/\ufffd{/~okn zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac \u20ac\ufffdms k\u20ac\nykrk\u00fetzo\u20ac *o1r1.Newsweek. RollingStone+ kzn \u20ac|omtqtm \u00d0ol\u20act\ufffdo\u20ac *o1r1. G\ufffd\u00fe\u00feqoon Uo\u00d0\u20ac+ k~o|{\u20act/\n\ufffdt\ufffdow\u00de k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y|k~on \ufffd{zo\u00d0\u20ac|k|o~\u20ac1 T{~o{\ufffdo~. zo\u00d0\u20ac krozmto\u20ac \u20ac\ufffdms\nk\u20acZo\ufffd\ufffdo~\u20ac k~ozork\ufffdt\ufffdow\u00de m{~~owk\ufffdon \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. \u00d0stms t\u20acz{\ufffd\u20ac\ufffd~|~t\u20actzr rt\ufffdoz \ufffdsk\ufffd \ufffdso\n|~tyk~\u00de ~{wo {qzo\u00d0\u20ac krozmto\u20ac t\u20ac\ufffd{nt\u20ac\ufffd~tl\ufffd\ufffdo zo\u00d0\u20ac \ufffd{\ufffdsot~ m\ufffd\u20ac\ufffd{yo~\u20ac m{y|k~on \ufffd{|\ufffdlwt\u20acstzr\nzo\u00d0\u20ac \ufffdsoy\u20acow\ufffdo\u20ac1 Stvo\u00d0t\u20aco. \ufffd\u20aco~\u20ac \u20acooy \ufffd{|~oqo~ \u00d0~t\ufffd\ufffdoz m{z\ufffdoz\ufffd m{y|k~on \ufffd{k\ufffdnt{ m{z\ufffdoz\ufffd\n*zork\ufffdt\ufffdo k\u20ac\u20ac{mtk\ufffdt{z \u00d0t\ufffds ~knt{ \u20ac\ufffdk\ufffdt{z\u20ac+1 \\so\u20aco qtzntzr\u20ac tzntmk\ufffdo \ufffdsk\ufffd \ufffdso\ufffd\u00de|o\u20ac {qzo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac\n\ufffd\u20aco~\u20ac qk\ufffd{~ \u00d0soz tzq{~ytzr \ufffdsoy\u20acow\ufffdo\u20ac kl{\ufffd\ufffd GST {zZonnt\ufffd \u20acs{\ufffdwn loqkm\ufffd\ufffdkw l\ufffd\ufffdz{\ufffd\ufffd{{\nm\ufffdylo~\u20ac{yo \ufffd{~okn1 ]\u20aco~\u20ac sk\ufffdo k|{\u20act\ufffdt\ufffdo ~owk\ufffdt{z\u20acst| \u00d0t\ufffds ntrt\ufffdkw/l{~z zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac. \u00d0so~ok\u20ac\n\ufffdso\u00de sk\ufffdo yt\u00f0on qoowtzr\u20ac ~ork~ntzr \ufffdsontrt\ufffdkw o\u00f0\ufffdoz\u20act{z {q\ufffd~knt\ufffdt{zkw yontk. k\u20aczo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac\nm{~~owk\ufffdo |{\u20act\ufffdt\ufffdow\u00de kzn zork\ufffdt\ufffdow\u00de \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1\n_o\u00d0kz\ufffd \ufffd{\u20ac\ufffd~o\u20ac\u20ac \ufffdsk\ufffd \ufffdso\u20aco qtzntzr\u20ac ~owk\ufffdo \u20ac{wow\u00de \ufffd{\ufffdso\ufffds~oo \u20ac\ufffdl~onnt\ufffd\u20ac kzkw\u00de\u00feon \u00d0t\ufffdstz\n\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de kzn k~o.\ufffdso~oq{~o. z{\ufffdrozo~kwt\u00feklwo \ufffd{{\ufffdso~ \u20ac\ufffdl~onnt\ufffd\u20ac {~\u20ac{mtkw yontk |wk\ufffdq{~y\u20ac1\nZonnt\ufffd)\u20ac \u20ac\ufffdlnt\ufffdt\u20act{z tz\ufffd{ ntqqo~oz\ufffd \u20ac\ufffdl~onnt\ufffd\u20ac ykvo\u20ac t\ufffd\u20ac\u20ac\ufffd~\ufffdm\ufffd\ufffd~o strsw\u00de ntqqo~oz\ufffd \ufffdskz {\ufffdso~\n\u20ac{mtkw yontk |wk\ufffdq{~y\u20ac \u20ac\ufffdms k\u20acOz\u20ac\ufffdkr~ky kzn \\tv\\{v1 \\s\ufffd\u20ac. {zoy\ufffd\u20ac\ufffd voo| tzytzn \ufffdsk\ufffd okms\n\u20ac\ufffdl~onnt\ufffd kzn \u20ac{mtkw yontk |wk\ufffdq{~y t\u20acntqqo~oz\ufffdw\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~on. {|o~k\ufffdo\u20ac kmm{~ntzr \ufffd{ntqqo~oz\ufffd\nm{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac. kzn oz\ufffdktw\u20ac nt\ufffdo~roz\ufffd |wk\ufffdq{~y kqq{~nkzmo\u20ac d43<f. \u00d0stms ty|km\ufffd\u20ac \ufffdso\u20ackwtozmo\n{qntqqo~oz\ufffd zo\u00d0\u20ac \ufffd{|tm\u20ac \u20acsk~on kzn \ufffdso\ufffd\u20aco~ ozrkroyoz\ufffd kzn k\ufffd\ufffdoz\ufffdt{z |ktn \ufffd{\ufffdsoy d43=f1\nI{zmw\ufffd\ufffdt{z kzn wtyt\ufffdk\ufffdt{z\ufffd\nV\ufffd~ \u00d0{~v m{z\ufffd~tl\ufffd\ufffdo\u20ac \ufffd{~o\u20acok~ms {z\ufffdson\u00dezkytm\u20ac {q\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {z\u20ac{mtkw yontk tz\ufffdso\nm{z\ufffdo\u00f0\ufffd {qntrt\ufffdkw zo\u00d0\u20ac ~o|{~\ufffdtzr {z\ufffdsoGST y{\ufffdoyoz\ufffd {zZonnt\ufffd1 \\st\u20ac \u00d0{~v t\u20ackqt~\u20ac\ufffd ty|{~/\n\ufffdkz\ufffd \u20ac\ufffdo| q{~ty|~{\ufffdtzr {\ufffd~rozo~kw \ufffdzno~\u20ac\ufffdkzntzr {qk\ufffd\ufffdoz\ufffdt{z n\u00dezkytm\u20ac {z\u20ac{mtkw yontk tz\n\ufffdsom{z\ufffdo\u00f0\ufffd {qntrt\ufffdkw zo\u00d0\u20ac ~o|{~\ufffdtzr. o\u20ac|omtkww\u00de \ufffdt{woz\ufffd zo\u00d0\u20ac ~o|{~\ufffdtzr. kl{\ufffd\ufffd \u20ac{mtkw y{\ufffdo/\nyoz\ufffd\u20ac. \u00d0stms tz\ufffd\ufffd~z mkztzqw\ufffdozmo \ufffdso|o~mo|\ufffdt{z {qkzn \u20ac\ufffd||{~\ufffd q{~\u20ac\ufffdms ky{\ufffdoyoz\ufffd d55\u02d8\n57.5:f1 [tzmo \ufffdsom{z\u20ac\ufffdy|\ufffdt{z {qzo\u00d0\u20ac {z\u20ac{mtkw yontk |wk\ufffdq{~y\u20ac sk\u20aclom{yo y{~o ty|{~\ufffdkz\ufffd\n\ufffdskz o\ufffdo~ loq{~o d6\u02d89f. \ufffdst\u20ackzkw\u00de\u20act\u20ac |~{\ufffdtno\u20ac \ufffdkw\ufffdklwo tz\u20actrs\ufffd\u20ac tz\ufffd{ kr~{\u00d0tzr zo\u00d0\u20ac yk~vo\ufffd\n\ufffdsk\ufffd t\u20ackzo\u20ac\u20acoz\ufffdtkw |k~\ufffd {q\ufffdsos\u00del~tn yontk \u20ac\u00de\u20ac\ufffdoy d;.<f1\nV\ufffd~ \u20act\u00f0vo\u00de\ufffdkvok\u00d0k\u00de\u20ac k~o>\n\u02ddLtzntzr\u20ac q~{y \ufffd~knt\ufffdt{zkw yontk ~o\u20acok~ms mkzz{\ufffd lont~om\ufffdw\u00de ~o|wtmk\ufffdon \u00d0t\ufffdstz \ufffdso{zwtzo\n\u00d0{~wn1 Fw\ufffds{\ufffdrs ~o\u20acok~ms \u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd {qqwtzo kzn {zwtzo zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z\u20ac {q\ufffdoz q{ww{\u00d0\n\u20actytwk~ |k\ufffd\ufffdo~z\u20ac d:3.:4f. {zoy\ufffd\u20ac\ufffd \ufffdkvo tz\ufffd{ kmm{\ufffdz\ufffd \ufffdsk\ufffd l{\ufffds oz\ufffdt~{zyoz\ufffd\u20ac q{ww{\u00d0 ntqqo~oz\ufffd\nw{rtm\u20ac d437f1 Vz\u20ac{mtkw yontk. tz|k~\ufffdtm\ufffdwk~. kzkl\ufffdznkzmo {qm{z\ufffdoz\ufffd m{y|o\ufffdo\u20ac q{~\ufffd\u20aco~\nk\ufffd\ufffdoz\ufffdt{z d436f. \u00d0stms ntqqo~\u20ac q~{y \ufffdsowtzok~ zo\u00d0\u20ac o\u00f0|{\u20ac\ufffd~o tz\ufffd~knt\ufffdt{zkw yontk1\n\u02ddOz{\ufffd~kzkw\u00de\u20act\u20ac. t\ufffdt\u20acz{\ufffdk\u20actzr\ufffdwk~ oqqom\ufffd *\ufffdt{wozmo tztykro\u20ac+ l\ufffd\ufffd\ufffdsotz\ufffdo~|wk\u00de {q\u20aco\ufffdo~kw k\ufffd\ufffd~t/\nl\ufffd\ufffdo\u20ac ~owk\ufffdon \ufffd{\ufffdsozo\u00d0\u20ac t\ufffdoy. zo\u00d0\u20ac |~{\ufffdtno~. kzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kzn |wk\ufffdq{~y kqq{~/\nnkzmo\u20ac \ufffdsk\ufffd k~oo\u20ac\u20acoz\ufffdtkw q{~mk|\ufffd\ufffd~tzr k\ufffd\ufffdoz\ufffdt{z nt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac {zZonnt\ufffd1 \\st\u20ac strswtrs\ufffd\u20ac \ufffdso\nm{y|wo\u00f0t\ufffd\u00de {q\ufffdso\u20ac{mtkw yontk wkzn\u20acmk|o1\n\u02dd[\ufffdlyt\u20ac\u20act{z \ufffdt\ufffdwo\u20ac \u00d0t\ufffds zork\ufffdt\ufffdo m{zz{\ufffdk\ufffdt{z\u20ac m{~~owk\ufffdo |{\u20act\ufffdt\ufffdow\u00de \u00d0t\ufffds \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y/\n|k~on \ufffd{\ufffdt\ufffdwo\u20ac \u00d0t\ufffds |{\u20act\ufffdt\ufffdo \u20acoz\ufffdtyoz\ufffd1 \\s\ufffd\u20ac. \u00d0oqtzn tzntmk\ufffdt{z\u20ac q{~kzork\ufffdt\ufffdt\ufffd\u00de ltk\u20ac \u00d0t\ufffds\n~o\u20ac|om\ufffd \ufffd{\u00d0~t\ufffd\ufffdoz m{z\ufffdoz\ufffd1\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5525=\n\u02dd\\so |tm\ufffd\ufffd~o \u20ac\ufffd|o~t{~t\ufffd\u00de oqqom\ufffd mkzz{\ufffd lom{zqt~yon tz{\ufffd~kzkw\u00de\u20act\u20ac. rt\ufffdoz \ufffdsk\ufffd k\u20ac\ufffdlyt\u20ac\u20act{z)\u20ac\nsoknwtzo sk\u20ackr~ok\ufffdo~ m{oqqtmtoz\ufffd kzn k\u20actrztqtmkz\ufffd ty|km\ufffd {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z m{y|k~on \ufffd{\n\u20ac\ufffdlyt\u20ac\u20act{z\u20ac qok\ufffd\ufffd~tzr \ufffdt{woz\ufffd tykro\u20ac1 Oz{\ufffd~nt\u20acm\ufffd\u20ac\u20act{z. \u00d0o|{tz\ufffd \ufffd{\u20aco\ufffdo~kw |{\ufffdoz\ufffdtkw o\u00f0|wk/\nzk\ufffdt{z\u20ac q{~\ufffdst\u20acqtzntzr1\n\u02dd]\u20aco~\u20ac m{z\u20ac\ufffdytzr GST/~owk\ufffdon zo\u00d0\u20ac \ufffdozn \ufffd{o\u00f0stlt\ufffd \u20ac|omtkw msk~km\ufffdo~t\u20ac\ufffdtm\u20ac l\u00de|~oqo~~tzr zor/\nk\ufffdt\ufffdow\u00de m{zz{\ufffdk\ufffdon \u00deo\ufffd|{wt\ufffdtmkww\u00de z{z/ltk\u20acon. qkm\ufffd\ufffdkw. kzn ok\u20ac\u00de/\ufffd{/~okn zo\u00d0\u20ac |\ufffdlwt\u20acson n\ufffd~/\ntzr\ufffdsonk\u00dekzn {z\u00d0oovozn\u20ac1 \\s\ufffd\u20ac. \ufffdkvtzr kzo\u00d0\u20ac \ufffd{|tm)\u20ac k\ufffdntozmo tz\ufffd{ kmm{\ufffdz\ufffd t\u20acstrsw\u00de\nty|{~\ufffdkz\ufffd q{~\ufffdzno~\u20ac\ufffdkzntzr \ufffdso|{|\ufffdwk~t\ufffd\u00de {qzo\u00d0\u20ac m{z\ufffdoz\ufffd1\n\u02ddWwk\ufffdq{~y/tzso~oz\ufffd kqq{~nkzmo\u20ac kzn m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac ykvo o\u20ac\u20acoz\ufffdtkw m{z\ufffd~tl\ufffd\ufffdt{z\u20ac \ufffd{\ufffdso\n\ufffdzno~\u20ac\ufffdkzntzr {q\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z n\u00dezkytm\u20ac. noy{z\u20ac\ufffd~k\ufffdtzr \ufffdsk\ufffd \ufffdl{\ufffds m~{\u00d0n\u20ac kzn \u20ac\u00de\u20ac\ufffdoy\u20ac\n\u00d0{~v \ufffd{ro\ufffdso~ \ufffd{ykvo nomt\u20act{z\u20ac {z\u00d0sk\ufffd tzq{~yk\ufffdt{z t\u20acty|{~\ufffdkz\ufffd\ufffd d6f1\n\\so\u20aco qtzntzr\u20ac oy|sk\u20act\u00feo \ufffdsozoon \ufffd{o\u00f0|kzn {\ufffd~\ufffdzno~\u20ac\ufffdkzntzr {qzo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z kzn\nk\ufffd\ufffdoz\ufffdt{z nt\u20ac\ufffd~tl\ufffd\ufffdt{z\u20ac tzkztzm~ok\u20actzrw\u00de ntrt\ufffdkwt\u00feon \u00d0{~wn \u20actzmo \ufffdkz{|o~k\ufffdt{zkw kzn \ufffd\u20acoq\ufffdw\nnoy{m~km\u00de ~owto\u20ac {zkzon\ufffdmk\ufffdon kzn \u00d0oww/tzq{~yon |{|\ufffdwk\ufffdt{z\ufffd d443f1 \\st\u20ac |k|o~ m{z\ufffd~tl\ufffd\ufffdo\u20ac\nkz{\ufffdso~ owoyoz\ufffd \ufffd{\ufffdst\u20acqtown {q~o\u20acok~ms kzn |k\ufffdo\u20ac \ufffdso\u00d0k\u00de q{~|{\ufffdoz\ufffdtkww\u00de o\u00f0|w{~tzr l~{kno~\n}\ufffdo\u20ac\ufffdt{z\u20ac. \u20ac\ufffdms k\u20ac\u00d0so\ufffdso~ \ufffdsono\ufffdom\ufffdon oqqom\ufffd\u20ac {q\ufffdst\u20ac|k|o~ kw\u20ac{ s{wn q{~\ufffdsontrt\ufffdkw zo\u00d0\u20ac m{\ufffd/\no~kro {q{\ufffdso~ \u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac {z{\ufffdso~ \u20ac{mtkw yontk |wk\ufffdq{~y\u20ac1\n_stwo \ufffdsoqtzntzr\u20ac |~o\u20acoz\ufffdon tz\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de {qqo~ ty|{~\ufffdkz\ufffd \ufffdso{~o\ufffdtmkw kzn |~km\ufffdtmkw tz\u20actrs\ufffd\u20ac.\n\ufffdso\u00de kw\u20ac{ sk\ufffdo \ufffd{lo\u20acooz tz\ufffdsowtrs\ufffd {q\ufffdsot~ wtyt\ufffdk\ufffdt{z\u20ac\u0152\u00d0stms {|oz \ufffd|\u20aco\ufffdo~kw |~{yt\u20actzr\nk\ufffdoz\ufffdo\u20ac q{~q\ufffd\ufffd\ufffd~o ~o\u20acok~ms1 Lt~\u20ac\ufffd. t\ufffd\u00d0{\ufffdwn lotz\ufffdo~o\u20ac\ufffdtzr \ufffd{yok\u20ac\ufffd~o \ufffdson\u00dezkytm\u20ac {q\ufffd\u20aco~\nk\ufffd\ufffdoz\ufffdt{z tzkzo\u00d0\u20ac m{z\ufffdo\u00f0\ufffd {\ufffdo~ \ufffdtyo1 J{tzr \u20ac{\u00d0{\ufffdwn kww{\u00d0 q{~o\ufffdkw\ufffdk\ufffdtzr \u20ac{mtkw yontk)\u20ac oqqom\ufffd\n{zntrt\ufffdkw zo\u00d0\u20ac m{z\u20ac\ufffdy|\ufffdt{z n\u00dezkytm\u20ac l\u00de~o\ufffdokwtzr \u00d0sk\ufffd vtzn {qzo\u00d0\u20ac k\ufffd\ufffd~km\ufffd\u20ac \ufffdsor~ok\ufffdo\u20ac\ufffd\n\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z kzn \u00d0soz1\n[om{zn. \u00d0stwo \u00d0onooy {\ufffd~ms{tmo {q\u20ac\ufffdl~onnt\ufffd\u20ac k\u20acku\ufffd\u20ac\ufffdtqtklwo qt~\u20ac\ufffd \u20ac\ufffdo| q{~kzkw\u00de\u00fetzr \ufffdso\n~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz zo\u00d0\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z \u20actzmo \ufffdso\u00de ~o|~o\u20acoz\ufffd \ufffdo~\u00de ty|{~\ufffdkz\ufffd \u20ac\ufffdl~onnt\ufffd\u20ac\nq{~\u20acsk~tzr zo\u00d0\u20ac {zZonnt\ufffd. \ufffdso\u00de k~oz{\ufffdq~oo {qltk\u20aco\u20ac \ufffdsk\ufffd kqqom\ufffd {\ufffd~\u20ac\ufffd\ufffdn\u00de1 F\u20ac\ufffdso\ufffds~oo \u20ac\ufffdl/\n~onnt\ufffd\u20ac n{z{\ufffdkww{\u00d0 q{~\ufffdsont~om\ufffd |{\u20ac\ufffdtzr {qtykro\u20ac. \u00d0o~om{rzt\u00feo \ufffdsk\ufffd \u00d0ok~o\ufffdzno~o\u20ac\ufffdtyk\ufffdtzr\n\ufffdsooqqom\ufffd {q*\ufffdt{woz\ufffd+ tykro\u20ac {z\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z1 L\ufffd\ufffd\ufffd~o ~o\u20acok~ms t\u20actz\ufffdt\ufffdon \ufffd{knnq\ufffd~\ufffdso~ zo\u00d0\u20ac/\n~owk\ufffdon \u20ac\ufffdl~onnt\ufffd\u20ac \u00d0t\ufffds wo\u20ac\u20ac\u20ac\ufffd~tm\ufffd m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac kww{\u00d0tzr q{~\ufffdsont~om\ufffd |{\u20ac\ufffdtzr {qtykro\u20ac1\nL\ufffd~\ufffdso~. \u00d0stwo \u00d0otz\ufffdoz\ufffdt{zkww\u00de q{m\ufffd\u20acon {zyktz\u20ac\ufffd~oky zo\u00d0\u20ac {\ufffd\ufffdwo\ufffd\u20ac tz{\ufffd~kzkw\u00de\u20act\u20ac \ufffd{mk|\ufffd\ufffd~o\n\ufffdsorozo~kw ~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz \u20acsk~on zo\u00d0\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z. t\ufffd\u00d0{\ufffdwn lotz\ufffdo~o\u20ac\ufffdtzr \ufffd{\no\u00f0|kzn {\ufffd~kzkw\u00de\u20act\u20ac \ufffd{y{~o ~kntmkw \u20ac\ufffdl~onnt\ufffd\u20ac \u00d0t\ufffds ntqqo~oz\ufffd m{yy\ufffdzt\ufffd\u00de ~\ufffdwo\u20ac. k\ufffdntozmo\u20ac. kzn\nm{z\ufffdoz\ufffd m{y|k~on \ufffd{yktz\u20ac\ufffd~oky \u20ac\ufffdl~onnt\ufffd\u20ac. tzmw\ufffdntzr \ufffds{\u20aco \ufffdsk\ufffd ozm{\ufffd~kro \ufffdso\u20acsk~tzr {q\nm{z\u20ac|t~k\ufffdt{zkw kzn q~tzro zo\u00d0\u20ac1 \\st\u20ac o\u00f0\ufffdoz\u20act{z \u00d0{\ufffdwn |~{\ufffdtno knnt\ufffdt{zkw kzn tz\ufffdo~o\u20ac\ufffdtzr\ntz\u20actrs\ufffd\u20ac ~ork~ntzr \ufffdso~owk\ufffdt{z\u20acst| lo\ufffd\u00d0ooz zo\u00d0\u20ac kzn \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd1 Go\u00de{zn tzmw\ufffdn/\ntzry{~o kzn nt\ufffdo~\u20aco \u20ac\ufffdl~onnt\ufffd\u20ac. knntzr {\ufffdso~ \u20ac{mtkw yontk |wk\ufffdq{~y\u20ac kzn nk\ufffdk kl{\ufffd\ufffd ntqqo~oz\ufffd\n\u20ac{mtkw y{\ufffdoyoz\ufffd\u20ac. k\u20ac\u00d0oww k\u20actzmw\ufffdntzr knnt\ufffdt{zkw o\u00f0|wkzk\ufffd{~\u00de k\ufffd\ufffd~tl\ufffd\ufffdo\u20ac q{~\ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z.\n\u00d0{\ufffdwn o\u00f0\ufffdozn \ufffdso\u20acm{|o {q\ufffdst\u20ac~o\u20acok~ms kzn knn\ufffd{t\ufffd\u20acrozo~kwt\u00fekltwt\ufffd\u00de1\n\\st~n. kzkw\u00de\u00fetzr \ufffdsom{yyoz\ufffd \u20ac\ufffd~\ufffdm\ufffd\ufffd~o kzn \ufffd\u20aco~/rozo~k\ufffdon m{z\ufffdoz\ufffd tz~o\u20ac|{z\u20aco \ufffd{k\u20ac\ufffdl/\nyt\u20ac\u20act{z m{\ufffdwn lok\u00d0owm{yo knnt\ufffdt{z \ufffd{tz\ufffdo\u20ac\ufffdtrk\ufffdo \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z q\ufffd~\ufffdso~1 L{m\ufffd\u20actzr {ztz\ufffdo~km/\n\ufffdt{z n\u00dezkytm\u20ac lo\ufffd\u00d0ooz \ufffd\u20aco~\u20ac tz\ufffdsom{z\ufffdo\u00f0\ufffd {qm{z\ufffdoz\ufffd qok\ufffd\ufffd~tzr \ufffdt{wozmo m{\ufffdwn noo|oz {\ufffd~\n\ufffdzno~\u20ac\ufffdkzntzr {q\ufffd\u20aco~ ~okm\ufffdt{z\u20ac \ufffd{\ufffdt{wozmo |{~\ufffd~k\u00deon {zwtzo1\n[\ufffd||{~\ufffdtzr tzq{~yk\ufffdt{z\n[4Ltr1 Nt\u20ac\ufffd{r~ky {qy{z\ufffdsw\u00de nt\u20ac\ufffd~tl\ufffd\ufffdt{z {qZonnt\ufffd GST \u20ac\ufffdlyt\u20ac\u20act{z\u20ac1\n*\\OL+\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5625=\n[5Ltr1 Nt\u20ac\ufffd{r~ky {qno|oznoz\ufffd \ufffdk~tklwo z\ufffdylo~ {qm{yyoz\ufffd\u20ac1\n*\\OL+\n[6Ltr1 \\~ktztzr kzn \ufffdkwtnk\ufffdt{z kmm\ufffd~km\u00de {qGKZ\\ y{now1\n*\\OL+\n[7Ltr1 Fmm\ufffd~km\u00de {qIUU y{now\u20ac1\n*\\OL+\n[9Ltr1 Fmm\ufffd~km\u00de {q^O\\ y{now\u20ac1\n*\\OL+\n[:Ltr1 ^MM4= y{now w{\u20ac\u20ac q\ufffdzm\ufffdt{z1\n*\\OL+\n[;Ltr1 ^MM4= y{now |~omt\u20act{z. ~omkww. kzn L4/[m{~o1\n*\\OL+\n[<Ltr1 ^MM4= y{now ~omot\ufffdo~ {|o~k\ufffdtzr msk~km\ufffdo~t\u20ac\ufffdtm *ZVI+ m\ufffd~\ufffdo1\n*\\OL+\n[=Ltr1 ^MM4= y{now m{zq\ufffd\u20act{z yk\ufffd~t\u00f0 {q\ufffdo\u20ac\ufffd nk\ufffdk\u20aco\ufffd ~owk\ufffdt\ufffdo \ufffdkw\ufffdo\u20ac1\n*\\OL+\n[43 Ltr1 ^MM4= y{now m{zq\ufffd\u20act{z yk\ufffd~t\u00f0 {q\ufffdo\u20ac\ufffd nk\ufffdk\u20aco\ufffd kl\u20ac{w\ufffd\ufffdo \ufffdkw\ufffdo\u20ac1\n*\\OL+\n[4\\klwo1 Jo\u20acm~t|\ufffdt\ufffdo {\ufffdo~\ufffdto\u00d0 {q\ufffdk~tklwo\u20ac1\n*JVIa+\n[5\\klwo1 V\u00d0z m{z\ufffd{w\ufffd\ufffdt{zkw zo\ufffd~kw zo\ufffd\u00d0{~v k~mst\ufffdom\ufffd\ufffd~o1\n*JVIa+\n[6\\klwo1 Uork\ufffdt\ufffdo ltz{ytkw ~or~o\u20ac\u20act{z ~o\u20ac\ufffdw\ufffd\u20ac {qy{now\u20ac \u00d0t\ufffds ntqqo~oz\ufffd nk\ufffdk\u20aco\ufffd\u20ac kzn \ufffdk~t/\nklwo\u20ac *\u20ac\ufffdkznk~n o~~{~ tz|k~oz\ufffdso\u20aco\u20ac. |\ufffdkw\ufffdo\u20ac tz\u20ac}\ufffdk~o l~kmvo\ufffd\u20ac+1\n*JVIa+\n[4Ltwo1 F||oznt\u00f0\u02d8F\ufffd\ufffdoz\ufffdt{z/r~kllt zrzo\u00d0\u20ac m{\ufffdo~kro> ^t{woz\ufffd tykro\u20ac {q\ufffdsoGwkmv St\ufffdo\u20ac\nTk\ufffd\ufffdo~ y{\ufffdoyoz\ufffd kzn s{\u00d0 \ufffdso\u00de k\ufffd\ufffd~km\ufffd \ufffd\u20aco~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd1\n*JVIa+\n[5Ltwo1\n*cOW+\nF\ufffd\ufffds{~ I{z\ufffd~tl\ufffd\ufffdt{z\ufffd\nI{zmo|\ufffd\ufffdkwt\u00fek\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nJk\ufffdk m\ufffd~k\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nL{~ykw kzkw\u00de\u20act\u20ac> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nL\ufffdzntzr km}\ufffdt\u20act\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nOz\ufffdo\u20ac\ufffdtrk\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nTo\ufffds{n{w{r\u00de> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nW~{uom\ufffd knytzt\u20ac\ufffd~k\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5725=\nZo\u20ac{\ufffd~mo\u20ac> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\n[{q\ufffd\u00d0k~o> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\n[\ufffd|o~\ufffdt\u20act{z> Vwt\ufffdo~ W{\u20acorrk1\n^kwtnk\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\n^t\u20ac\ufffdkwt\u00fek\ufffdt{z> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\n_~t\ufffdtzr \u02d8{~trtzkw n~kq\ufffd> \\so~o\u20ack Nozz1\n_~t\ufffdtzr \u02d8~o\ufffdto\u00d0 \u2019ont\ufffdtzr> \\so~o\u20ack Nozz. Vwt\ufffdo~ W{\u20acorrk1\nZoqo~ozmo\ufffd\n41 [\ufffdtorwt\ufffd\ufffd [.Jkzr/a \ufffdkzS.G~\ufffdz\ufffd F.Uo\ufffdlo~r o~I1[{mtkw Tontk Fzkw\ufffd\ufffdtm\ufffd> FzOz\ufffdo~nt\ufffdmt| wtzk~\ufffd\nF||~{kms kznO\ufffd\ufffdOy|wtmk\ufffdt{z\ufffd q{~Ozq{~yk\ufffdt{ z[\ufffd\ufffd\ufffdoy\ufffd1 G\ufffd\ufffdtzo\ufffd\ufffd \u2019Ozq{~yk\ufffdt{ z[\ufffd\ufffd\ufffdoy\ufffd Kzrtzoo~t zr1\n5347?:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431433 ;2\ufffd459== /347/3649 /;\n51 Uo\ufffdykz U.Lwo\ufffdmso~ Z.So\ufffd\ufffd JFS. Utow\ufffdoz ZR1Zo\ufffd\ufffdo~\ufffd Oz\ufffd\ufffdt\ufffd\ufffd\ufffdo Jtrt\ufffdkw Uo\ufffd\ufffd Zo|{~\ufffd 534:1 V\ufffdq{~n>\nZo\ufffd\ufffdo~\ufffd Oz\ufffd\ufffdt\ufffd\ufffd\ufffdo q{~\ufffdso[\ufffd\ufffdn\ufffd {qQ{\ufffd~zkw t\ufffdy? 534: |14571\n61 N{~zo GJ.Fnkwt\ufffd [1\\so Oy|km\ufffd {qI~{\ufffdn\ufffd {zUo\ufffd\ufffd Kzrkroyoz\ufffd >FZonnt\ufffd Ik\ufffdo [\ufffd\ufffdn\ufffd1 \\so _{~v/\n\ufffds{|\ufffd {q\ufffdsoKwo\ufffdoz\ufffds Oz\ufffdo~zk \ufffdt{zkw FFFO I{zqo~ozmo {z_ol kzn[{mtkw Tontk1 FFFO \\omsztmkw\nZo|{~\ufffd? 534;1 ||1;94\u02d8;9<1 s\ufffd\ufffd|\ufffd>22n {t1{~r24314:3 =2tm\ufffd\ufffdy1\ufffd 44t4147=;;\n71 Tt\ufffdmsoww F.[tyy{z\ufffd R.Tk\ufffd\ufffdk RK.[tw\ufffdo~ S1W\ufffdlwtm\ufffd Mw{lkww\ufffd _kz\ufffd ]zltk\ufffdon Uo\ufffd\ufffd I{\ufffdo~kro. l\ufffd\ufffdF~o\nJt\ufffdtnon {z_so\ufffdso~ \\sot~ Uo\ufffd\ufffd Tontk Jowt\ufffdo~1 Wo\ufffd Zo\ufffdok~ms Ioz\ufffdo~1 534< ||16\u02d8761\n91 _kwvo~ T.Tk\ufffd\ufffdk RK1Uo\ufffd\ufffd I{z\ufffd\ufffdy |\ufffdt{z Fm~{\ufffd\ufffd [{mtkw Tontk tz53541 Oz>Wo\ufffd Zo\ufffdok~ms Ioz\ufffdo~\ndOz\ufffdo~zo\ufffdf1 5354 dmt\ufffdon :Q\ufffdz5356f1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1|o\ufffd~o\ufffdok~ ms1{~r2u{\ufffd ~zkwt\ufffdy253542 3=2\n532zo\ufffd\ufffd/m{z\ufffd \ufffdy|\ufffdt{z/km ~{\ufffd\ufffd/\ufffd{mtkw/y ontk/tz/53 5421\n:1 G~tnrykz F.To~vwo\ufffd K.S{o\ufffdoz WQ.V\ufffdoz \\.Z\ufffd\ufffds\ufffd J.\\otmsykzz S.o\ufffdkw1\\so mk\ufffd\ufffdo\ufffd kznm{z\ufffdo/\n}\ufffdozmo\ufffd {qIV^OJ/4= yt\ufffd|o~mo|\ufffdt {z\ufffd> ]zno~\ufffd\ufffd kzntzr \ufffdso~{wo{qzo\ufffd\ufffd kzn\ufffd{mtkw yontk1 Nk~\ufffdk~n\nRozzon\ufffd [ms{{w Tt\ufffdtzq{~y k\ufffdt{z Zo\ufffdto\ufffd1 5353?41 s\ufffd\ufffd|\ufffd>22n{t1{~ r24316;3 4:2y~/5353/ 35<\n;1 Iskn\ufffdtmv F1\\so N\ufffdl~tn Tontk [\ufffd\ufffd\ufffdoy >W{wt\ufffdtm\ufffd kznW{\ufffdo~1 V\ufffdq{~n ]zt\ufffdo~\ufffdt\ufffd\ufffd W~o\ufffd\ufffd? 53461\n<1 Q\ufffdzrso~~ F.W{\ufffdorrk V.FzQ1Jt\ufffdm\ufffd~\ufffdt\ufffdo W{\ufffdo~ tzI{z\ufffdoy|{~k ~\ufffdTontk [\ufffd\ufffd\ufffdoy\ufffd> FI{y| k~k\ufffdt\ufffdo\nL~kyo\ufffd{~v1 Oz\ufffdo~zk\ufffd t{zkw Q{\ufffd~zkw {qW~o\ufffd\ufffd2W{ wt\ufffdtm\ufffd1 534=1 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;24=734:454= <74976\n=1 G{\ufffdwtkzzo [1Vzwtzo zo\ufffd\ufffd. mt\ufffdtm k\ufffdk~ozo\ufffd\ufffd. kznozrkroy oz\ufffdtzmt\ufffdtm kzn|{wt\ufffdtmkw wtqo1Uo\ufffd Tontk kzn\n[{mto\ufffd\ufffd1 534:?4<1 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;247:4777<49 :4:555\n431 Ik\ufffdkwkz/Tk \ufffdky{~{\ufffd J.Wo\u00f1kqtow /[kt\ufffd I1N{\ufffd t\ufffdm{yy\ufffdztm k\ufffdt{z {q\ufffdkmmtzo\ufffd tz\ufffd~knt\ufffdt{zkw yontk> k\ufffd\ufffd\ufffd/\n\ufffdoyk\ufffdtm ~o\ufffdto\ufffd1 Wo~\ufffd|om\ufffdt\ufffdo \ufffdtzW\ufffdlwtm Nokw\ufffds1 534=?46 =1s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;24;9;=46=4< ;<3475\nWTOJ> 5=<;;455\n441 [msk~~o~ K1Tontk o\ufffd|{\ufffd\ufffd~o kzn\ufffdoz\ufffdt\ufffdt\ufffdt\ufffd\ufffd \ufffd{\ufffdt{wozmo tzzo\ufffd\ufffd ~o|{~\ufffd\ufffd >K\ufffdtnozmo {qno\ufffdoz\ufffdt\ufffdt\ufffdk\ufffdt {zD\nQ{\ufffd~zkwt\ufffdy kznTk\ufffd\ufffd I{yy\ufffdz tmk\ufffdt{z Y\ufffdk~\ufffdo~w\ufffd1 533<? <9>5=4\u02d86431 s\ufffd\ufffd|\ufffd>22n{t1 {~r243144;;2\n43;;:==33<3 <933539\n451 Gk~\ufffds{w{\ufffd GJ.JtwwRK.Fzno~\ufffd{z RG.Stzn\ufffdk\ufffd QQ1\\so W~{wtqo~k\ufffdt{ z{qTontk ^t{wozm okznO\ufffd\ufffdKm{z{ytm\n]zno~|tzztzr\ufffd 1Tontk \ufffdt{wozmo kznmstwn~oz> Fm{y|wo\ufffdo r\ufffdtno q{~|k~oz\ufffd \ufffdkzn|~{qo\ufffd\ufffdt{z kw\ufffd1 _o\ufffd\ufffd/\n|{~\ufffd> M~ooz\ufffd{{n W\ufffdlwt\ufffdstzr ?53361 ||14\u02d84<1\n461 Gk~lo~ U1_s\ufffd \ufffdsoUo\ufffd\ufffd t\ufffdS{knon \ufffdt\ufffds ^t{wozmo1 Oz>W\ufffd\ufffdms{ w{r\ufffd \\{nk\ufffd dOz\ufffdo~zo\ufffdf1 534: dmt\ufffdon :Q\ufffdz\n5356f1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1|\ufffd\ufffdms{w{r\ufffd \ufffd{nk\ufffd1m{y2\ufffd \ufffd2lw{r2\ufffdso/s\ufffdy kz/lok\ufffd\ufffd2 534:342\ufffds \ufffd/\ufffdso/\nzo\ufffd\ufffd/t\ufffd/w{ knon/\ufffdt{wozmo1\n471 Fl\ufffdlkvk~ F\\1Uo\ufffd\ufffd ^kw\ufffdo\ufffd kzn\ufffdsoK\ufffdstmkw Jtwoyyk\ufffd {qI{\ufffdo~tzr ^t{woz\ufffd K\ufffd\ufffd~oyt\ufffdy1 Q{\ufffd~zkw t\ufffdykzn\nTk\ufffd\ufffd I{yy\ufffdz tmk\ufffdt{z Y\ufffdk~\ufffdo~w\ufffd1 5353? =;>5;<\u02d85=<1 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;243;;:==34= <7;59<\n491 Nkytw\ufffd{z Q\\1Iskzzowtzr \ufffdt{wozmo> \\so om{z{y tmyk~vo\ufffd q{~\ufffdt{woz\ufffd \ufffdowo\ufffdt\ufffdt{z |~{r~kyy tzr1 W~tzmo/\n\ufffd{z]zt\ufffdo~\ufffdt\ufffd\ufffd W~o\ufffd\ufffd? 53331\n4:1 Z{\ufffd\ufffdt S.Uo\ufffdyk\ufffd o~I.Noz~tms\ufffdoz Q.Gomv SR1Tok\ufffd\ufffd~tzr ^t{wozm o>FI{y|\ufffd\ufffdk\ufffdt{zk wFzkw\ufffd\ufffdt\ufffd {q^t{/\nwozmo kznW~{|krk\ufffdt{ z{qOykro \\\ufffdoo\ufffd\ufffd L~{y W{wt\ufffdtmkw W~{\ufffdo\ufffd\ufffd1 [{mtkw [mtozmo I{y|\ufffd\ufffdo~ Zo\ufffdto\ufffd1\n5355? 74>=39\u02d8=591 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144;;23 <=776=65443 9975=\n4;1 Rsk~~{\ufffdl \\.Gk\ufffd V1[{mtkw yontk kzn|~{\ufffdo\ufffd\ufffd\ufffd> Fzo\ufffdkytzk\ufffdt{ z{q\\\ufffdt\ufffd\ufffdo~ tykro\ufffd {q\ufffdso5344 Kr\ufffd|\ufffdtkz\n~o\ufffd{w\ufffd\ufffdt{z1 Uo\ufffd Tontk kzn[{mto\ufffd\ufffd1 534:? 4<>4=;6\u02d84 ==51 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;2\n47:4777<499 ;4=47\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5925=\n4<1 Jtkzt T1\\so m{zmo|\ufffd {q\ufffd{mtkw y{\ufffdoyoz\ufffd 1\\so [{mt{w{rtm kwZo\ufffdto\ufffd1 4==5? 73>4\u02d8591 s\ufffd\ufffd|\ufffd>22n{t1{~ r2\n43144442u147:; /=97a14 ==51\ufffdl35=761\ufffd\n4=1 Iso~zork Q1Gwkmv St\ufffdo\ufffd Tk\ufffd\ufffdo~> Zkmtkwt\ufffdon W{wtmtzr tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\ufffd1 I{y|k~k\ufffdt\ufffd oFyo~tmkz [\ufffd\ufffdn/\nto\ufffd1534:? 47>567\u02d85791 s\ufffd\ufffd|\ufffd>22n{t1{~ r243143< 3247;;9;33153 4:145:;655\n531 Zk\ufffd Z.G~{\ufffdz T.L~kt\ufffd\ufffdk\ufffd U.[\ufffdyyo~\ufffd K1Lo~r\ufffd\ufffd{z kzn\ufffdsonok\ufffds {qTtmskow G~{\ufffdz {z\\\ufffdt\ufffd\ufffdo ~>\n$GwkmvSt\ufffdo \ufffdTk\ufffd\ufffdo~. $\\IV\\. kzn\ufffdsoo\ufffd{w\ufffd\ufffdt{z {qm{wwom\ufffdt\ufffdo tnoz\ufffdt\ufffdto\ufffd 1K\ufffdsztm kznZkmtkw [\ufffd\ufffdnto\ufffd1 534;?\n73>4;=;\u02d84<461 s\ufffd\ufffd|\ufffd>22 n{t1{~r243143 <323474= <;31534;14669 755\n541 Wk\ufffdzk\ufffdno S.S{ykvtzk I^.Wk\ufffdow F.Gt\ufffdow M1W\ufffdlwtm Ky{\ufffdt{zk wZo\ufffd|{z\ufffdo {z\ufffdsoGwkmv St\ufffdo\ufffd Tk\ufffd\ufffdo~\nT{\ufffdoyoz\ufffd tz\ufffdso[\ufffdyyo~ {q5353 k\ufffdFzkw\ufffd\ufffdon \\s~{\ufffdrs \\\ufffdt\ufffd\ufffdo~1 Oz\ufffdo~zk\ufffdt{zkw Q{\ufffd~zkw {qTk~vo\ufffdtzr\n[\ufffd\ufffdnto\ufffd1 5354? 46>:=1s\ufffd\ufffd|\ufffd>22n{t1{~ r2431996 =2tuy\ufffd1\ufffd46z4| :=\n551 T{\ufffd~\u00e3{ ZZ. G~{\ufffdz JR1Gwkmv St\ufffdo\ufffd Tk\ufffd\ufffdo~ I{\ufffdo~kro> N{\ufffd W~{\ufffdo\ufffd\ufffd Uo\ufffd\ufffd L~kyo\ufffd kznF\ufffd\ufffdt\ufffd\ufffdntzkw\nIskzro Fqqom\ufffd [{mtkw Tontk Kzrkroy oz\ufffd1Jtrt\ufffdkw Q{\ufffd~zkw t\ufffdy1 5355? 43>:5:\u02d8:7:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431\n43<3254:;3<4 41535414 =64=33\n561 G{\ufffdwo TW. TmSo{n JT. F~y\ufffd\ufffd~{zr IS1Fnso~ozmo \ufffd{\ufffdso|~{\ufffdo\ufffd\ufffd |k~kntry >\\so tzqw\ufffdozmo {q|~{\ufffdo\ufffd\ufffd\nr{kw\ufffd kzn\ufffdkm\ufffdtm\ufffd {zzo\ufffd\ufffd m{\ufffdo~kro tz]1[1 kzntz\ufffdo~zk\ufffdt{zk wzo\ufffd\ufffd|k|o~ \ufffd1Oz\ufffdo~zk\ufffdt{zkw Q{\ufffd~zkw {q\nW~o\ufffd\ufffd2W{wt\ufffdtm \ufffd15345? 4;>45;\u02d84771 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;24=734:4544 766<6;\n571 No~\ufffd{r QR.TmSo{n JT1 Fzk~mst\ufffd\ufffd \ufffd_~okv Nk\ufffd{m OzJ{\ufffdz\ufffd{ \ufffdzTtzzok| {wt\ufffd> FT\ufffdw\ufffdt/wo\ufffdo w[\ufffd\ufffdn\ufffd {q\nTontk I{\ufffdo~kro {qZkntmkw W~{\ufffdo\ufffd\ufffd1 Q{\ufffd~zkwt\ufffdy \u2019Tk\ufffd\ufffd I{yy\ufffdz tmk\ufffdt{z T{z{r~ k|s\ufffd1 4==9?49 41\n591 Iskz QT.SooI/I1 Q{\ufffd~zkw t\ufffd\ufffdtm |k~kntry {zmt\ufffdtw|~{\ufffdo\ufffd\ufffd\ufffd> Fmk\ufffdo \ufffd\ufffd\ufffdn\ufffd {qN{zr R{zr1 \\so zo\ufffd\ufffd\nyontk tzzk\ufffdt{zkw kzntz\ufffdo~zk\ufffd t{zkw m{zqwtm\ufffd1 _o\ufffd\ufffd\ufffdto\ufffd W~o\ufffd\ufffd? 4=<71 ||14<6\u02d85351\n5:1 TmI\ufffd~n\ufffd W1[{mtkw y{\ufffdoyoz\ufffd\ufffd .|~{\ufffdo\ufffd\ufffd kznyktz\ufffd\ufffd~ok yyontk1 [{mt{w{ r\ufffdI{y|k\ufffd \ufffd15345? :>577\u02d8\n5991 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431444 42u14;94/=35 31534413 377<1\ufffd\n5;1 R{{|ykz\ufffd Z1T{\ufffdoy oz\ufffd\ufffd kznyontk> [owom\ufffdt{z |~{mo\ufffd\ufffd o\ufffdkzno\ufffd{w\ufffd\ufffdt{z k~\ufffdn\ufffdzkytm\ufffd tz\ufffdso|\ufffdlwtm\n\ufffd|so~o1 \\so{~\ufffd kzn\ufffd{mto\ufffd\ufffd1 5337? 66>6:;\u02d86=41 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431435 62G>Zb[V133 3336<:36167= :61\nno\n5<1 [yt\ufffds Q.TmIk~\ufffds\ufffd QJ.TmWsktw I.F\ufffdr\ufffd\ufffd\ufffd\ufffdz G1L~{y W~{\ufffdo\ufffd\ufffd \ufffd{Froznk G\ufffdtwntzr> Jo\ufffdm~t|\ufffd t{zGtk\ufffd tz\nTontk I{\ufffdo~kro {qW~{\ufffdo\ufffd\ufffd K\ufffdoz\ufffd\ufffd tz_k\ufffdstzr\ufffd{ z.J1I1 [{mtkw L{~mo\ufffd1 5334? ;=>46=;\u02d847561 s\ufffd\ufffd|\ufffd>22\nn{t1{~r243146 962\ufffd{q15334 13396\n5=1 Jk\ufffdo J.L~ton\ufffd{z F.Tk\ufffd\ufffd\ufffd\ufffdk\ufffdk R.[kltk Q.[kqq{~ n[1Gwkmv St\ufffdo\ufffd Tk\ufffd\ufffdo~ W~{\ufffdo\ufffd\ufffd\ufffd. [{mtkw Jt\ufffd\ufffdkzmtzr.\nkznIV^OJ/4= 1Ikyl~tnro >Uk\ufffdt{zkw G\ufffd~ok\ufffd {qKm{z{ytm Zo\ufffdok~ms? 53531\n631 I{~~trkww/G ~{\ufffdz I1\\so W{\ufffdo~ {qWtm\ufffd\ufffd~o\ufffd> Oykro\ufffd {qW{wt\ufffdtm\ufffd kznW~{\ufffdo\ufffd\ufffd1 Fyo~tmkz Gosk\ufffdt{~kw [mtoz/\n\ufffdt\ufffd\ufffd15345? 9:>464\u02d84671 s\ufffd\ufffd|\ufffd>22n{t1 {~r243144;;23 335;:75 4474=69<\n641 Utms{ww\ufffd \\.[skllt~ U.Utow\ufffdoz ZR1Jtrt\ufffdkw/l {~zUo\ufffd\ufffd Tontk tzK\ufffd~{|o\u0152Jtrt \ufffdkwUo\ufffd\ufffd W~{uom\ufffd 534:1\nV\ufffdq{~n> Zo\ufffd\ufffdo~\ufffd Oz\ufffd\ufffdt\ufffd\ufffd\ufffdo? 534:1\n651 ^k~k/Ttr\ufffdo wF1I~{\ufffd\ufffd/zk\ufffdt{ zkw\ufffdtytwk~t\ufffdto \ufffdkznntqqo~ozm o\ufffdlo\ufffd\ufffdooz workm\ufffd kznntrt\ufffdkw/l{~ zzo\ufffd\ufffd\nyontk k\ufffdntozm o\ufffd1Tontk kznI{yy\ufffdztm k\ufffdt{z1 5353? <>4:\u02d85;1 s\ufffd\ufffd|\ufffd>22n{t1{~ r24314;: 792ykm1\ufffd<t51\n5;66\n661 To~k\ufffd [1\\so qtrs\ufffd q{~\ufffds{\ufffd \ufffd{\ufffdstzv\ufffd> \\~knt\ufffdt{zkw yontk. \ufffd{mtkw zo\ufffd\ufffd{~v\ufffd. kznt\ufffd\ufffd\ufffdo tz\ufffdo~|~o\ufffdk\ufffdt{ z1Q{\ufffd~/\nzkwt\ufffdy1 5344? 45>43;\u02d845;1 s\ufffd\ufffd|\ufffd>22 n{t1{~r243144 ;;247:7 <<7=436<94= 6\n671 Z{\ufffdtz W.Z{\ufffd\ufffdykz KG1Uork\ufffdt\ufffd t\ufffd\ufffdltk\ufffd. zork\ufffdt\ufffdt\ufffd\ufffd n{ytzkzmo .kznm{z\ufffdkrt{z 1Wo~\ufffd{zkwt\ufffd\ufffd kzn[{mtkw\nW\ufffd\ufffdms{w{r\ufffd Zo\ufffdto\ufffd1 5334? 9>5=:\u02d865 31s\ufffd\ufffd|\ufffd>22n{t1{~ r2431453;2 [4965;=9;W [WZ3937i 5\n691 [s{oykvo ~WQ1Nk~n\ufffdt~on q{~zo\ufffd\ufffd> ]\ufffdtzr lt{w{rtmkw kznm\ufffdw\ufffd\ufffd~kw o\ufffd{w\ufffd\ufffdt{z \ufffd{o\ufffd|wktz \ufffdso\ufffd\ufffd~\ufffdotwwkzm o\nq\ufffdzm\ufffdt{z1 Q{\ufffd~zkw {qI{yy\ufffdz tmk\ufffdt{z1 4==:? 7:>65\u02d87;1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431444 42u147:3/57: :14==:1\n\ufffdl347<;1\ufffd\n6:1 [\ufffdozlo~r M1I{zmo|\ufffd\ufffdkw kzn|o~mo|\ufffd\ufffd kwqkm\ufffd{~\ufffd tz\ufffdso|tm\ufffd\ufffd~o \ufffd\ufffd|o~t{~t\ufffd\ufffd oqqom\ufffd1 K\ufffd~{|okz Q{\ufffd~zkw {q\nI{rzt\ufffdt\ufffdo W\ufffd\ufffdms{w{r\ufffd1 533:? 4<><46\u02d8<7;1 s\ufffd\ufffd|\ufffd>22n{ t1{~r243143<3 23=9747 739337456:4\n6;1 [\ufffdoqkz{\ufffd W.Jk~\ufffdt\ufffds R.F\ufffdkzk\ufffd{\ufffd F.Ukv{\ufffd W1W~ontm\ufffdtzr \ufffdso\\{|tmkw [\ufffdkzmo kznW{wt\ufffdtmkw Sokztzr {q\nTontk \ufffd\ufffdtzr \\\ufffdoo\ufffd\ufffd1 W~{moontzr\ufffd {q\ufffdso9<\ufffds Fzz\ufffdkw Too\ufffdtzr {q\ufffdsoF\ufffd\ufffd{mtk\ufffd t{zq{~I{y|\ufffd\ufffdk\ufffdt{zk w\nStzr\ufffdt\ufffd\ufffdtm\ufffd1 53531 ||195;\u02d896 ;1s\ufffd\ufffd|\ufffd>22n{t1{~ r24314<: 962\ufffd42535 31kmw/yktz1 93\n6<1 Fswo~\ufffd J1Uo\ufffd\ufffd m{z\ufffd\ufffdy|\ufffd t{zkzn\ufffdsozo\ufffd owom\ufffd~{z tmyontk1 Nk~\ufffdk~n Oz\ufffdo~zk\ufffdt{zkw Q{\ufffd~zkw {qW~o\ufffd\ufffd2\nW{wt\ufffdtm\ufffd1 533:? 44>5=\u02d8951 s\ufffd\ufffd|\ufffd>22n{t1 {~r243144;;24 3<44<3a395 <764;\n6=1 [msk~v{\ufffd T.Tkzr{wn L.[\ufffdto~ [.G~o\ufffdo~ Q1N{\ufffd \ufffd{mtkw zo\ufffd\ufffd{~v \ufffdt\ufffdo\ufffd kzn{\ufffdso~ {zwtzo tz\ufffdo~yon tk~to\ufffd\ntzm~ok\ufffdo o\ufffd|{\ufffd\ufffd~o \ufffd{zo\ufffd\ufffd1 W~{moo ntzr\ufffd {q\ufffdsoUk\ufffdt{zkw Fmknoy\ufffd {q[mtozmo\ufffd {q\ufffdso]zt\ufffdon [\ufffdk\ufffdo\ufffd {q\nFyo~tmk1 5353? 44;> 5;:4\u02d85;:61 s\ufffd\ufffd|\ufffd>22 n{t1{~r243143 ;62|zk\ufffd14 =4<5;=44; WTOJ> 64=<<455\n731 Utow\ufffdoz ZR1Uo\ufffd\ufffd yontk. \ufffdok~ms ozrtzo\ufffd kzn\ufffd{mtkw zo\ufffd\ufffd{~vtzr \ufffdt\ufffdo\ufffd k\ufffd\ufffdk~to\ufffdto\ufffd {q{zwtzo rk\ufffdovoo| /\no~\ufffd1Zo\ufffdstzvtzr Q{\ufffd~zkwt\ufffd yFrktz> [{mto\ufffdkw Z{wo kznW\ufffdlwtm Zowo\ufffdkzmo tzkJtrt\ufffdkw Fro1 Z{\ufffd\ufffdwonro ?\n534:1 ||1=6\u02d843<1\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5:25=\n741 Mky\ufffd{z _F. _{wq\ufffdqown M1T{\ufffdoyoz\ufffd\ufffd kznyontk k\ufffdtz\ufffdo~km\ufffdtzr \ufffd\ufffd\ufffd\ufffdoy\ufffd1 \\so Fzzkw\ufffd {q\ufffdsoFyo~tmkz\nFmknoy\ufffd {qW{wt\ufffdtmkw kzn[{mtkw [mtozmo1 4==6? 95<> 447\u02d84591\n751 TmIk~\ufffds\ufffd QJ.TmWsktw I.[yt\ufffds Q1Oykro\ufffd {qW~{\ufffdo\ufffd\ufffd> Jtyoz\ufffdt{z \ufffd{q[owom\ufffdt{ zGtk\ufffd tzTontk I{\ufffdo~kro\n{q_k\ufffdstzr\ufffd{ zJoy{z\ufffd\ufffd ~k\ufffdt{z\ufffd. 4=<5 kzn4==41 Fyo~tmkz [{mt{w{ rtmkw Zo\ufffdto\ufffd1 4==:? :4>7;<\u02d87==1\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431563;2 53=:6:3\n761 Kk~w Q.Tk~\ufffdtz F.TmIk~\ufffds \ufffdQJ.[{\ufffdwo [F1\\so \ufffd\ufffdo{qzo\ufffd\ufffd|k|o~ nk\ufffdk tz\ufffdso\ufffd\ufffd\ufffdn\ufffd {qm{wwom\ufffdt\ufffd okm\ufffdt{z1\nFzz\ufffd Zo\ufffd [{mt{w1 5337? 63>:9\u02d8<31 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431447 :2kzz\ufffd~o\ufffd1\ufffd {m1631345 ;361443:36\n771 Vwt\ufffdo~ WK.Tkzo\ufffd MT1 W{wt\ufffdtmkw |~{mo\ufffd\ufffdo\ufffd kznw{mkw zo\ufffd\ufffd|k|o~ m{\ufffdo~kro {q|~{\ufffdo\ufffd\ufffd o\ufffdoz\ufffd\ufffd> L~{y\n\ufffdowom\ufffdt{z ltk\ufffd \ufffd{\ufffd~tkntm tz\ufffdo~km\ufffdt {z\ufffd1 Fyo~tmkz Q{\ufffd~zkw {q[{mt{w{ r\ufffd15333? 43:> 7:6\u02d89391 s\ufffd\ufffd|\ufffd>22n{t1\n{~r243143<:26 4:=:7\n791 _{\ufffd\ufffdo~\ufffd Z1L~{y \ufffdso\ufffd\ufffd~oo\ufffd \ufffd{\ufffdso\ufffdm~ooz> Isk~km\ufffdo~t\ufffd \ufffdtm\ufffd{q|~{\ufffdo\ufffd\ufffd o\ufffdoz\ufffd\ufffd k\ufffdno\ufffdo~ytzkz\ufffd\ufffd {q\ufffdowo\ufffdt/\n\ufffdt{z zo\ufffd\ufffd m{\ufffdo~kro 1T{ltwt\ufffdk\ufffdt{ z>FzOz\ufffdo~zk\ufffdt{zkw Y\ufffdk~\ufffdo~w\ufffd1 5346? 4<><6\u02d84391 s\ufffd\ufffd|\ufffd>22n{ t1{~r2431\n4;<462yk t}14<141\ufffd:3 :;;64u7<773 :;\n7:1 Rz{lw{ms/_o\ufffd \ufffdo~\ufffdtmv [.T{\ufffdso\ufffd I.W{wk\ufffdtz U1I{zqt~yk\ufffdt{ zGtk\ufffd. Ozr~{\ufffd| Gtk\ufffd. kznUork\ufffdt\ufffdt\ufffd\ufffd Gtk\ufffd tz\n[owom\ufffdt\ufffdo K\ufffd|{\ufffd\ufffd~o \ufffd{W{wt\ufffdtmk wOzq{~yk\ufffdt{ z1I{yy\ufffdz tmk\ufffdt{z Zo\ufffdok~ms1 5353? 7;>437\u02d84571 s\ufffd\ufffd|\ufffd>22n{t1\n{~r243144;;23 3=6:93 54;;4=9=:\n7;1 Sozrk\ufffdo~ M.K\ufffd\ufffdo~ L.Go~rkz\ufffd kZ1Uork\ufffdt\ufffd t\ufffd\ufffdtz|{wt\ufffdtmkw zo\ufffd\ufffd> F~o\ufffdto\ufffd {qm{zmo|\ufffd\ufffd .{|o~k\ufffdt{zkw t\ufffdk/\n\ufffdt{z\ufffd kznvo\ufffdqtzntzr\ufffd1 Q{\ufffd~zkwt\ufffdy 15345? 46>4;=\u02d853 51s\ufffd\ufffd|\ufffd>22n{t1{~ r243144;; 247:7<<7=447 5;<33\n7<1 [{~{vk [U1Uork\ufffdt\ufffd t\ufffd\ufffdtznoy{m~k\ufffdt m|{wt\ufffdtm\ufffd> Ik\ufffd\ufffdo\ufffd kznm{z\ufffdo}\ufffdoz mo\ufffd1 Ikyl~tnro ]zt\ufffdo~\ufffdt\ufffd\ufffd\nW~o\ufffd\ufffd? 53471\n7=1 I~ktr M1\\so \ufffd|om\ufffdkm wo{q\ufffdso\ufffd\ufffd~oo\ufffd> kzkzkw\ufffd\ufffdt\ufffd {qyontk m{\ufffdo~kro {q|~{\ufffdo\ufffd\ufffd\ufffd k\ufffd\ufffdso5333 Towl{\ufffd~zo\n_{~wn Km{z{ytm L{~\ufffdy1dF~ \ufffdtmwo lk\ufffdon {zk|k|o~ rt\ufffdoz k\ufffd\ufffdsoI{zqo~oz mo{q\ufffdsoF\ufffd\ufffd\ufffd~kwtkz kznUo\ufffd\ncokwkzn I{yy\ufffdz tmk\ufffdt{z F\ufffd\ufffd{mtk\ufffdt{z *5334> Wo~\ufffds. _F+1f1 F\ufffd\ufffd\ufffd~kwtkz Q{\ufffd~zkw {qI{yy\ufffdztm k\ufffdt{z1\n5335? 5=>6=\u02d8951\n931 T\ufffd~n{mv M1W{wt\ufffdtmkw no\ufffdtkzmo> \\so |~o\ufffd\ufffd |~o\ufffdoz\ufffdk\ufffd t{z{qkytwt\ufffdkz\ufffd yk\ufffd\ufffd noy{z\ufffd\ufffd~k \ufffdt{z1 \\so Tkz\ufffd/\nqkm\ufffd\ufffd~o {qUo\ufffd\ufffd> Jo\ufffdtkzmo .[{mtkw W~{lwoy\ufffd kzn\ufffdsoTk\ufffd\ufffd Tontk S{zn{z >I{z\ufffd\ufffdklwo1 S{zn{z> I{z/\n\ufffd\ufffdklwo? 4=;61 ||153:\u02d85591\n941 TmLk~wkzo \\.Nk\ufffd O1\\so lk\ufffd\ufffdwo q{~[ok\ufffd\ufffdwo> |~{\ufffdo\ufffd\ufffd kzn|{|\ufffdwk~ ro{|{wt\ufffdtm\ufffd tz\\so F\ufffd\ufffd\ufffd~kwtkz zo\ufffd\ufffd|k/\n|o~1 W{wt\ufffdtmkw Mo{r~k|s \ufffd15336? 55>544\u02d85651 s\ufffd\ufffd|\ufffd>22n{t1{ ~r2431434:2[ 3=:5/:5=<* 35+333=3/ 5\n951 G{\ufffdv{qq Q1L~kytzr nt\ufffd\ufffdoz\ufffd> Tk\ufffd\ufffd/yontk m{\ufffdo~kro {q\ufffdsorw{lkw u\ufffd\ufffd\ufffdtmo y{\ufffdoy oz\ufffd1Uo\ufffd W{wt\ufffdtmk w[mt/\nozmo1 533:? 5<>534\u02d855<1 s\ufffd\ufffd|\ufffd>22n{t1{ ~r243143<323; 6=6473:3 3:;==:;\n961 TmSo{n JT. Jo\ufffdozlo~ GN1L~kytzr oqqom\ufffd\ufffd {q\ufffdowo\ufffdt\ufffdt{z zo\ufffd\ufffd m{\ufffdo~kro {q\ufffd{mtkw |~{\ufffdo\ufffd\ufffd1 Q{\ufffd~zkw {q\nI{yy\ufffdztm k\ufffdt{z1 4===? 7=>6\u02d8561 s\ufffd\ufffd|\ufffd>22n{t1{~ r24314444 2u147:3/57:: 14===1\ufffdl3 5<351\ufffd\n971 ^wtoroz\ufffdsk~ \ufffdZ._kwr~k \ufffdo[1\\so tz\ufffdo~no| oznozm\ufffd {qyk\ufffd\ufffd yontk kzn\ufffd{mtkw y{\ufffdoy oz\ufffd\ufffd1 Oz>[mky/\nyoww T.[oyo\ufffdv{ NF.ont\ufffd{~\ufffd1 \\so [FMK Nkznl{{v {qW{wt\ufffdtmkw I{yy\ufffdz tmk\ufffdt{z1 [FMK W\ufffdlwtmk\ufffdt{z \ufffd?\n53451 ||16<;\u02d86=<1 s\ufffd\ufffd|\ufffd>22n{t1{~ r243174692= ;<477:53434 91z64\n991 W{oww \\.G{~~k K1\\\ufffdt\ufffd\ufffdo ~.b{\ufffd\\\ufffdlo. kznLwtmv~ k\ufffd|wk\ufffdq{~y\ufffd {qkw\ufffdo~zk\ufffdt\ufffd ou{\ufffd~zkwt\ufffdy> \\so \ufffd{mtkw yontk\nkmm{\ufffdz\ufffd {q\ufffdso5343 \\{~{z\ufffd{ M53 |~{\ufffdo\ufffd\ufffd\ufffd1 Q{\ufffd~zkw t\ufffdy1 5345? 46>:=9\u02d8;461 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144;;2\n47:7<<7=447 64966\n9:1 Rotl R.K\ufffd|tzk I.SoobO._{un\ufffdz\ufffdvt G_. Is{t J.Gkzr N1Wtm\ufffd\ufffd~o \\st\ufffd> \\so Ozqw\ufffdozmo {qKy{\ufffdt{zk ww\ufffd\n^kwozmon Oykro\ufffd. VzF\ufffd\ufffdoz\ufffdt{ z.[owom\ufffdt{z. kzn[sk~tzr {q[{mtkw Tontk Uo\ufffd\ufffd1 Tontk W\ufffd\ufffdms{w{r\ufffd 1\n534<? 54>535\u02d85541 s\ufffd\ufffd|\ufffd>22n{t1{~ r243143<324 95465:=1534; 146;<43 <\n9;1 Tk\ufffd\ufffd{zt F.\\o\ufffdzo [1^t\ufffdt{z\ufffd {qW~{\ufffdo\ufffd\ufffd1 FTontk/Nt\ufffd\ufffd {~tmWo~\ufffd|om\ufffdt\ufffdo {zOykro\ufffd tz[{mtkw T{\ufffdoyo z\ufffd\ufffd1\n[{mt{w{r\ufffd I{y|k \ufffd\ufffd15347? <><;:\u02d8<<;1 s\ufffd\ufffd|\ufffd>22n{t1 {~r243144442\ufffd {m71454;6\n9<1 Jowwk W{~\ufffdk J.Jtkzt T.J{o~~ U.Tk\ufffd\ufffd{zt F.\\o\ufffdzo [1^t\ufffd\ufffdkw\ufffd tz[{mtkw T{\ufffdoyoz\ufffd \ufffd1\\so V\ufffdq{~n Nkzn/\nl{{v {q[{mtkw T{\ufffdoy oz\ufffd\ufffd1 53471 s\ufffd\ufffd|\ufffd>22n{t1{~ r243143= 62{\ufffdq{~nsl2 =;<34==:;<7 35134617 <\n9=1 Uo\ufffdyk\ufffdo~ I.Z{\ufffd\ufffdt S1Oykro\ufffd {q|~{\ufffdo\ufffd\ufffd tz\ufffd{mtkw yontk> [\ufffd~\ufffdrrwo {\ufffdo~ \ufffdt\ufffdtltwt\ufffd\ufffd kzn\ufffdt\ufffd\ufffdkw zk~~k\ufffdt\ufffdo\ufffd 1\nUo\ufffd Tontk kzn[{mto\ufffd\ufffd1 534<? 53>75=6\u02d876431 s\ufffd\ufffd|\ufffd>22 n{t1{~r243144 ;;247:4 777<4<;;3:3 5\n:31 SooFT. Ik~|tzt TaJ1 Uo\ufffd\ufffd I{z\ufffd\ufffdy |\ufffdt{z Zo\ufffdt\ufffdt\ufffdo n>K\ufffdkytztzr \ufffdsoW{\ufffdo~ {qNklt\ufffd\ufffd tz\ufffdso54\ufffd\ufffd Ioz/\n\ufffd\ufffd~\ufffd1 44\ufffds Oz\ufffdo~zk \ufffdt{zkw [\ufffdy|{\ufffdt\ufffdy {zVzwtzo Q{\ufffd~zkw t\ufffdy1 F\ufffd\ufffd\ufffdtz. \\o\ufffdk\ufffd? 53431 ||14\u02d8651\n:41 Tt\ufffdmsow\ufffd\ufffdotz K.G{m\ufffdv{\ufffd \ufffdvtWQ1Vzwtzo zo\ufffd\ufffd m{z\ufffd\ufffdy|\ufffdt{z ~o\ufffdok~ms >Fzk\ufffd\ufffdo\ufffd\ufffdyoz \ufffd{q|k\ufffd\ufffd \ufffd{~v kzn\nkzkroznk q{~\ufffdsoq\ufffd\ufffd\ufffd~o1 Uo\ufffd Tontk kzn[{mto\ufffd\ufffd1 5343? 45>43<9\u02d844351 s\ufffd\ufffd|\ufffd>22n{t1 {~r243144;;2\n47:4777<3=6 934=6\n:51 ^kt\ufffds F.M~{\ufffd\ufffdykz z\\._{{n\ufffdk~n F1U{\ufffdFwwKy{\ufffdt{z\ufffd F~oI~ok\ufffdon K}\ufffdkw> \\so Uork\ufffdt\ufffdt\ufffd\ufffd Gtk\ufffd tz\n[{mtkw/Ky{\ufffdt{ zkwJo\ufffdow{|y oz\ufffd1W\ufffd\ufffdms{w{rt mkwG\ufffdwwo\ufffdtz1 533<? 467> 6<61 s\ufffd\ufffd|\ufffd>22 n{t1{~r243143 6;23366 /\n5=3=14671616<6 WTOJ> 4<777;35\n:61 Tk~kz{ NK1_s\ufffd _oS{\ufffdo Gkn Uo\ufffd\ufffd1 Oz>W\ufffd\ufffdms{w{r\ufffd \\{nk\ufffd dOz\ufffdo~zo \ufffdf15336 dmt\ufffdon 4:F|~5355f1\nF\ufffdktwklwo> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1|\ufffd\ufffdms{w{r\ufffd \ufffd{nk\ufffd1m{y2 \ufffd\ufffd2k~\ufffdtmwo\ufffd253 36392\ufffds\ufffd/\ufffd o/w{\ufffdo/lkn/ zo\ufffd\ufffd1\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5;25=\n:71 Nk~m\ufffd| \\V)Uotww J1_sk\ufffd O\ufffdUo\ufffd\ufffdD Mkw\ufffd\ufffdzr kznZ\ufffdro ~o\ufffdt\ufffdt\ufffdon1 Q{\ufffd~zkwt\ufffdy [\ufffd\ufffdnto\ufffd1 5334? 5>5:4\u02d8\n5<31 s\ufffd\ufffd|\ufffd>22n{t1{~ r243143< 3247:4:;3344 <77=\n:91 Skzr F.Uo\ufffdskroz Q.Zoo\ufffdo\ufffd G1Uork\ufffdt\ufffdo \ufffdtno{ k\ufffd\ufffd\ufffd~\ufffdm\ufffd\ufffd~o> Ky{\ufffdt{z. k\ufffd\ufffdoz\ufffdt{z. mk|kmt\ufffd\ufffd .kznyoy/\n{~\ufffd1Q{\ufffd~zkw {qG~{knm k\ufffd\ufffdtzr \u2019Kwom\ufffd~{ztm Tontk1 4==:? 73>7:3\u02d87;;1 s\ufffd\ufffd|\ufffd>22n{t1 {~r243143<32\n3<<6<49=:3= 6:76:=\n::1 Tk~\ufffdtmv FK1Oz\ufffd\ufffdkqky o>S\ufffd\ufffd\ufffd~\ufffd \ufffdowqto\ufffd tz\ufffdsok\ufffd\ufffdoz\ufffdt{z om{z{y\ufffd1 W\ufffdlwtm I\ufffdw\ufffd\ufffd~o1 5349? 5;>46;\u02d84:31\ns\ufffd\ufffd|\ufffd>22n{t1{~ r243145492 3<==56:6/5 ;=<6;=\n:;1 No\ufffd\ufffdow Q.SooS.Ttyz{ J1Ik\ufffd\ufffd kznmk|\ufffdt{z\ufffd \ufffd\ufffd1m~ok\ufffd{~ \ufffdkzn\ufffdsomw{mv> I{y| k~tzr y\ufffdw\ufffdty{ nkwm{z/\n\ufffdoz\ufffd\ufffd{m{z\ufffdo\ufffd\ufffd tz|~ontm\ufffdt zr~owk\ufffdt\ufffdo |{|\ufffdwk~t\ufffd\ufffd1 5:\ufffds Oz\ufffdo~zk\ufffdt{zkw _{~wn _tno _ol I{zqo~oz mo1\n534;1 ||1=5;\u02d8=6:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431447926 36<=4516395: <7\n:<1 ^t{wozmo Z\ufffdms\ufffd J1kznUo\ufffd [{mtkw T{\ufffdoy oz\ufffd\ufffd1 Oz\ufffdo~zk \ufffdt{zkw Nkznl{{v {q^t{wozm oZo\ufffdok~ms1 J{~/\nn~oms\ufffd> [|~tzro~ Uo\ufffdso~wkz n\ufffd?53361 ||16:=\u02d86<51 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431433 ;2=;</3/63 :/7<36=/6 i53\n:=1 Skvvk~ku\ufffd N.TmF\ufffdwo\ufffd Q.So\ufffdv{\ufffdom Q1_sk\ufffd)\ufffd tzkzkyoD ]zno~\ufffd\ufffdkzn tzr\ufffdsotz\ufffdo~|wk\ufffd lo\ufffd\ufffdooz \ufffdt\ufffdwo\ufffd.\nm{z\ufffdoz\ufffd. kznm{yy\ufffdzt\ufffdto\ufffd tz\ufffd{mtkw yontk1 W~{moontzr\ufffd {q\ufffdso;\ufffdsOz\ufffdo~zk\ufffdt{zkw I{zqo~oz mo{z_ol/\nw{r\ufffd kzn[{mtkw Tontk1 53461 ||1644\u02d865 31s\ufffd\ufffd|\ufffd>22n{t1{~ r24314:3 =2tm\ufffd\ufffdy1\ufffd;t4 14773<\n;31 ]swT_1 K\ufffd|wktztzr ]1[1 m{z\ufffd\ufffdy o~losk\ufffdt{ ~\ufffdt\ufffds zo\ufffd\ufffd \ufffdoz\ufffdtyoz\ufffd 1FIT \\~kz\ufffdkm\ufffdt{z \ufffd{zTkzkro/\nyoz\ufffd Ozq{~yk\ufffdt{ z[\ufffd\ufffd\ufffdoy\ufffd1 5344? 5>4\u02d84<1 s\ufffd\ufffd|\ufffd>22n{t1{~ r24314479 24=<967;14=<9 693\n;41 M\ufffdQ.\\tkz Q._kzr a.Stzr N1J{o\ufffd zork\ufffdt\ufffdo zo\ufffd\ufffd \ufffd~k\ufffdow qk\ufffd\ufffdD o\ufffd|w{~tzr \ufffdsooqqom\ufffd {qzo\ufffd\ufffd \ufffdoz\ufffdtyoz\ufffd\n{ztz\ufffdo~km\ufffdt\ufffdo \ufffd|t~kw1 Oz\ufffdo~zk\ufffdt{zkw I{zqo~oz mo{zN\ufffdyk z/I{y|\ufffd\ufffdo~ Oz\ufffdo~km\ufffdt{z1 534;1 ||1769\u02d87751\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431433;2 =;</6/64= /9<;93/=i: 3\n;51 Ntlltzr QZ.[yt\ufffds RG.Fwq{~n QZ1Jtqqo~ozmo\ufffd tzzork\ufffdt\ufffdt\ufffd\ufffd ltk\ufffd \ufffdzno~wto \ufffdk~tk\ufffdt{ z\ufffdtz|{wt\ufffdtmkw tno{w{r \ufffd1\nGosk\ufffdt{~kw kznG~ktz [mtozmo\ufffd1 5347? 6;>5=;\u02d863 ;1s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434; 2[3473959a 463344=5\nWTOJ> 57=;375<\n;61 L{\ufffd~zto~ W.[{~{vk [.Ut~S1Uork\ufffdt\ufffdt\ufffd \ufffdGtk\ufffdo\ufffd kznW{wt\ufffdtmkw Ono{w{r\ufffd> FI{y|k~k\ufffdt\ufffdo \\o\ufffd\ufffd km~{\ufffd\ufffd 4;\nI{\ufffdz\ufffd~to\ufffd1 Fyo~tmkz W{wt\ufffdtmk w[mtozmo Zo\ufffdto\ufffd1 5353? 447> ;;9\u02d8;=41 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434 ;2\n[333639975 3333464\n;71 O\ufffdozrk~ [.Nksz R[1Zon yontk. lw\ufffdo yontk> K\ufffdtnozmo {qtno{w{rtmkw \ufffdowom\ufffdt\ufffdt\ufffd\ufffd tzyontk \ufffd\ufffdo1 Q{\ufffd~zkw\n{qI{yy\ufffdztm k\ufffdt{z1 533=? 9=>4=\u02d86=1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431444 42u147:3/57: :1533<13 47351\ufffd\n;91 ^{\ufffd{\ufffdrst [.Z{\ufffd J.F~kw [1\\so \ufffd|~okn {q\ufffd~\ufffdo kznqkw\ufffdo zo\ufffd\ufffd {zwtzo1 [mtozmo1 534<? 69=> 447:\u02d84 4941\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431445:2 \ufffdmtozmo1kk|= 99=WTOJ> 5=9=33 79\n;:1 G{\ufffdn J1[{mtkw Uo\ufffd\ufffd{~v [t\ufffdo\ufffd k\ufffdUo\ufffd\ufffd{~vo nW\ufffdlwtm\ufffd> Fqq{~nkzmo\ufffd .J\ufffdzkytm\ufffd. kznOy|wtmk\ufffdt{z\ufffd 1Uo\ufffd/\n\ufffd{~von [owq> Onoz\ufffdt\ufffd\ufffd. I{yy\ufffdzt\ufffd\ufffd .kznI\ufffdw\ufffd\ufffd~o {z[{mtkw Uo\ufffd\ufffd{~v [t\ufffdo\ufffd1 Z{\ufffd\ufffdwonro ?53431 ||17;\u02d8::1\n;;1 So\ufffdtm{ Jtm\ufffdt{zk ~to\ufffd1 F\ufffd\ufffdoz\ufffdt{z \ufffdJoqtzt\ufffdt{z {qF\ufffd\ufffdoz\ufffdt{ zl\ufffdV\ufffdq{~n Jtm\ufffdt{zk~\ufffd {zSo\ufffdtm{1m{y1 So\ufffdtm{ Jtm/\n\ufffdt{zk~to\ufffd1 53551 F\ufffdktwkl woq~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd \ufffd1wo\ufffdtm{1m{ y2noqtzt\ufffdt{ z2k\ufffd\ufffdoz\ufffdt{z1\n;<1 \\ozozl{ty V.I{soz FF1_sk\ufffd |~{y|\ufffd\ufffd \ufffd\ufffdo~\ufffd \ufffd{mwtmv kznm{yyo z\ufffd>Fw{zrt\ufffd\ufffdntzkw \ufffd\ufffd\ufffdn\ufffd {q{zwtzo\nzo\ufffd\ufffd1 Q{\ufffd~zkwt\ufffdy 15349? 4:>4=<\u02d854 ;1s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;247:7<<7=46 946==:\n;=1 Zonnt\ufffd1 Zonnt}\ufffdo\ufffd\ufffd odOz\ufffdo~zo\ufffdf1 5354 dmt\ufffdon 63F|~5355f1 F\ufffdktwkl woq~{y> s\ufffd\ufffd|\ufffd>22~onn t\ufffd1\ufffdozno\ufffd v1m{y2\nsm2oz/\ufffd\ufffd2k~\ufffd tmwo\ufffd2539= 5:76=/Zonnt} \ufffdo\ufffd\ufffdo1\n<31 Jo\ufffdwtz Q.Iskzr T/_. SooR.\\{\ufffd\ufffdkz{\ufffdk R1GKZ\\> W~o/\ufffd~ktz tzr{qJoo| Gtnt~om\ufffdt{zk w\\~kz\ufffdq{~ yo~\ufffd q{~\nSkzr\ufffdkro ]zno~\ufffd\ufffdkzn tzr1k~at\ufffd? 534=1 s\ufffd\ufffd|\ufffd>22n{t1{~ r24317<9 932k~at\ufffd14<43 137<39\n<41 _kzvskno T.Zk{ FI[. R\ufffdwvk~ ztI1F\ufffd\ufffd~\ufffdo\ufffd {z\ufffdoz\ufffdtyoz\ufffd kzkw\ufffd\ufffdt\ufffd yo\ufffds{n\ufffd .k||wtmk\ufffdt{z\ufffd .kznmskw/\nwozro\ufffd1 F~\ufffdtqtmtkw Oz\ufffdowwtr ozmo Zo\ufffdto\ufffd1 5355? 99>9;64\u02d89; <31s\ufffd\ufffd|\ufffd>22n{t1{~ r2431433 ;2\ufffd437:5/355/\n43477/4\n<51 N\ufffdrrtzr Lkmo1 lo~\ufffd/lk\ufffdo /\ufffdzmk\ufffdon1 Oz>N\ufffdrrtzr Lkmo dOz\ufffdo~zo\ufffd f15356 dmt\ufffdon 5Q\ufffdz5356f1 F\ufffdktwklwo\nq~{y> s\ufffd\ufffd|\ufffd>22s\ufffdr rtzrqkmo1m{ 2lo~\ufffd/lk\ufffdo/\ufffd zmk\ufffdon1\n<61 Nkyl{~r L.J{zzk\ufffd R1Uo\ufffd\ufffdT\\ [I>knk\ufffdk\ufffdo\ufffd q{~*y\ufffdw\ufffdt/+\ufffdk~r o\ufffd/no|oznoz \ufffd\ufffdoz\ufffdtyoz \ufffdmwk\ufffd\ufffdtqtmk\ufffdt{z tz\n|{wt\ufffdtmkw zo\ufffd\ufffd k~\ufffdtmwo\ufffd1 W~{moo ntzr\ufffd {q\ufffdso4:\ufffds I{zqo~oz mo{q\ufffdsoK\ufffd~{|okz Isk|\ufffdo~ {q\ufffdsoF\ufffd\ufffd{m tk\ufffdt{z\nq{~I{y|\ufffd\ufffdk\ufffdt{zk wStzr\ufffdt\ufffd\ufffdt m\ufffd153541 ||14::6\u02d84:;91 s\ufffd\ufffd|\ufffd>22 n{t1{~r243194 :;2\ufffd\ufffds/5 3;4<6\n<71 Stzb143Zonnt\ufffd [\ufffdk\ufffdt\ufffd\ufffdtm\ufffd K\ufffdo~\ufffd Tk~vo\ufffdo~ [s{\ufffdwn Rz{\ufffd Oz53541 Oz>Vlo~w{ dOz\ufffdo~zo\ufffd f15354 dmt\ufffdon 4:\nF|~5355f1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1{lo~w{1m{y 2lw{r2~onnt\ufffd/ \ufffd\ufffdk\ufffdt\ufffd\ufffdtm\ufffd1\n<91 F~yon I{zqwtm\ufffd S{mk\ufffdt{z \u2019K\ufffdoz\ufffd Jk\ufffdk W~{uom\ufffd1 Joy{z\ufffd \ufffd~k\ufffdt{z\ufffd \u2019W{wt\ufffdtmk w^t{wozm otzFyo~tmk1 ][\nI~t\ufffdt\ufffd T{zt\ufffd{~ dOz\ufffdo~zo \ufffdf15354 dmt\ufffdon 63F|~5355f1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22kmwon1 rt\ufffds\ufffdl1t{2][ 21\n<:1 Go~r\ufffd\ufffd~{ \u00c6yF.Qo~\ufffdow\ufffdm voGowq~kro T1Uo\ufffd\ufffd tz[{mtkw Tontk> Ozmtnoz\ufffdkw m{z\ufffd\ufffdy|\ufffdt{z kzn\ufffdso~{wo{q\n{|tzt{z wokno~\ufffd1 Jtrt\ufffdkw Q{\ufffd~zkwt\ufffdy 1534<? :>9<6\u02d89= <1s\ufffd\ufffd|\ufffd>22n{t1{~ r243143<3 254:;3<441534 <1\n4756:59\n<;1 G~\ufffdsz T.[ms{oz y\ufffdowwo~ ^.[msk\u00c6qo~JG1F~o\ufffd{mtkw yontk ~o|wkmtzr \ufffd~knt\ufffdt{zkw yontk tz\ufffdo~y\ufffd {ql~kzn\no}\ufffdt\ufffd\ufffd m~ok\ufffdt{z DTkzkroyoz \ufffdZo\ufffdok~ms Zo\ufffdto\ufffd1 5345? 69>;;3\u02d8;= 31s\ufffd\ufffd|\ufffd>22n{t1{~ r2431443 <2\n3473=4;4544 599=7<\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5<25=\n<<1 Gk\ufffdyrk~\ufffdzo~ Q.ckzzo\ufffd\ufffd{\ufffd [.Roorkz G.[}\ufffdt~o T.Gwkmvl\ufffd~z Q1\\so |\ufffd\ufffds\ufffdstq\ufffd ~onnt\ufffd nk\ufffdk\ufffdo\ufffd1 47\ufffds\nOz\ufffdo~zk\ufffdt{zkw I{zqo~oz mo{z_ol kzn[{mtkw Tontk1 53531 ||1<63\u02d8<6=1 s\ufffd\ufffd|\ufffd>22n{t1{~ r24314:3=2\ntm\ufffd\ufffdy1\ufffd47t4 1;67;\n<=1 Gk~\ufffdsow T.[\ufffd{mvtzr M.N{wm{y Q.Tt\ufffdmsoww F1[o\ufffdoz/tz/\\o zZonnt\ufffd ]\ufffdo~\ufffd Mo\ufffdUo\ufffd\ufffd {z\ufffdso[t\ufffdo1 Oz>\nWo\ufffd Zo\ufffdok~ms Ioz\ufffdo~ dOz\ufffdo~zo \ufffdf1534: dmt\ufffdon 4:F|~5355f1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1|o\ufffd~o\ufffdok~ ms1\n{~r2u{\ufffd~zk wt\ufffdy2534:23 52592\ufffdo\ufffdoz/ tz/\ufffdoz/~on nt\ufffd/\ufffd\ufffdo~\ufffd/ro\ufffd/ zo\ufffd\ufffd/{z/ \ufffdso/\ufffdt\ufffdo21\n=31 J\ufffdr\ufffdk\ufffd WF1Zokn t\ufffd{zZonnt\ufffd> N{y{rozot \ufffd\ufffdkzntno{w{rtmkw \ufffdor~ork \ufffdt{ztz\ufffdsokro{q\ufffd{mtkw zo\ufffd\ufffd1 [{mtkw\n[mtozmo I{y|\ufffd\ufffdo~ Zo\ufffdto\ufffd 15355? 73>44<:\u02d84535 1s\ufffd\ufffd|\ufffd>22n{t1 {~r243144;;2 3<=776=65443 34396\n=41 ckzzo\ufffd\ufffd{\ufffd [.Ik\ufffdwqtown \\.JoI~t\ufffd\ufffd{qk~{ K.R{\ufffd~\ufffdow~t\ufffd U.So{z\ufffdtknt\ufffd O.[t~t\ufffdtkz{\ufffd T.o\ufffdkw1\\so \ufffdol moz\ufffdt/\n|ono> \ufffdzno~\ufffd\ufffdkzn tzrs{\ufffd \ufffdol m{yy\ufffdzt\ufffdto\ufffd tzqw\ufffdozmo okms {\ufffdso~ \ufffds~{\ufffdrs \ufffdsowoz\ufffd {qyktz\ufffd\ufffd~ok ykzn\nkw\ufffdo~zk\ufffdt\ufffdo zo\ufffd\ufffd \ufffd{\ufffd~mo\ufffd1 W~{moo ntzr\ufffd {q\ufffdso534; tz\ufffdo~zo \ufffdyok\ufffd\ufffd~oyoz \ufffdm{zqo~oz mo1534;1 ||1739\u02d8\n74;1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431447 9264646:91646 46=3\n=51 [{wtykz F.Nkqo~ Q.Soyyo~tms L1Fmsk~km\ufffdo~t\ufffd k\ufffdt{z {q|{wt\ufffdtmkw m{yy\ufffd zt\ufffdto\ufffd {z~onnt\ufffd1 W~{moo ntzr\ufffd\n{q\ufffdso63\ufffds FIT m{zqo~oz mo{zs\ufffd|o~\ufffdo\ufffd\ufffd kzn[{mtkw Tontk1 534=1 ||159=\u02d85:61 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431\n447926675553 16676:: 5\n=61 Uknt~t F.\\kvo\ufffd L_1 Fwk~ro/\ufffdmkwo \ufffdoy|{~kw kzkw\ufffd\ufffdt\ufffd {q\ufffd\ufffdo~ wtqo\ufffd|kz n\ufffd~kltwt\ufffd\ufffd {z\ufffdsoZonnt\ufffd \ufffd{mtkw\nyontk |wk\ufffdq{~y1 I{y|kzt{z W~{moontzr\ufffd {q\ufffdso_ol I{zqo~ozmo 53551 53551 ||1:;;\u02d8:< 91s\ufffd\ufffd|\ufffd>22\nn{t1{~r243144 79267<; 99616957:==\n=71 _{z J.[\ufffdotzo~\ufffd/\\s~ owvown cI.Q{{Q1W~{\ufffdo\ufffd\ufffd km\ufffdt\ufffdt\ufffd\ufffd no\ufffdom\ufffdt{z kzn|o~mot\ufffdon \ufffdt{wozmo o\ufffd\ufffdtyk\ufffdt{z q~{y\n\ufffd{mtkw yontk tykro\ufffd1 TT534;\u0152W~{ moontzr\ufffd {q\ufffdso534; FIT T\ufffdw\ufffdtyontk I{zqo~oz mo1534;1 ||1\n;<:\u02d8;=71 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431447 9264565::16 4565<5\n=91 St\ufffd\\.Lkzr [.csk{ b._kzr W.cskzr Q1Oy|woyoz\ufffdk \ufffdt{z{q\\~ktztzr I{z\ufffd{w\ufffd\ufffdt{z kwUo\ufffd~kw Uo\ufffd\ufffd{~v\ufffd1\nk~at\ufffd? 53491 s\ufffd\ufffd|\ufffd>22n{t1{~ r2493:13 44=9\n=:1 N\ufffd\ufffd\ufffdktz T.Gt~n QQ.Lk~tk JZ1 F\ufffd\ufffd\ufffdn\ufffd {zmzz\ufffd~kz\ufffdqo~ wok~ztzr q{~tykro mwk\ufffd\ufffdt qtmk\ufffdt{z1 Fn\ufffdkzmo\ufffd tz\nI{y|\ufffd\ufffdk\ufffdt{zk wOz\ufffdowwtrozm o[\ufffd\ufffd\ufffdoy\ufffd1 U{\ufffd\ufffdtzrsky. ]R>[|~tzro~? 534=1 ||14=4\u02d85351 s\ufffd\ufffd|\ufffd>22n{t1{~ r2\n431433;2=;</ 6/64=/=;= <5/6i4:\n=;1 \\kz T.SoY1Kqqtmtoz\ufffdz o\ufffd>Zo\ufffdstzvtzr y{now \ufffdmkwtzr q{~m{z\ufffd{w\ufffd\ufffdt{ zkwzo\ufffd~kw zo\ufffd\ufffd{~v\ufffd1 Oz\ufffdo~zk \ufffdt{zkw\nm{zqo~ozm o{zykmstzo wok~ztzr1 WTSZ? 534=1 ||1:439\u02d8:44 71\n=<1 Stc.St\ufffdL.bkzr _.Wozr [.cs{\ufffd Q1F\ufffd\ufffd~\ufffdo\ufffd {qm{z\ufffd{w\ufffd\ufffdt{ zkwzo\ufffd~kw zo\ufffd\ufffd{~v\ufffd> kzkw\ufffd\ufffdt\ufffd. k||wtmk\ufffdt {z\ufffd.\nkzn|~{\ufffd|om\ufffd\ufffd1 OKKK \ufffd~kz\ufffdkm\ufffdt{z \ufffd{zzo\ufffd~kw zo\ufffd\ufffd{~v\ufffd kznwok~ztzr \ufffd\ufffd\ufffd\ufffdoy\ufffd1 5355? 66>:===\u02d8; 34=1\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431443=2 \\UUS[1535416 3<7<5; WTOJ> 6744433=\n==1 Ztnztv \\.Goz/Gk~\ufffd msK.U{\ufffd F.cowztv/Tk z{~S1OykroUo\ufffd/54 RW~o\ufffd~ktztz rq{~\ufffdsoTk\ufffd\ufffdo\ufffd1 k~at\ufffd?\n53541 s\ufffd\ufffd|\ufffd>22n{t1{~ r24317<9 932k~at\ufffd15437 143=;5\n4331 Ntwlo QT1Uork\ufffdt\ufffdo ltz{ytk w~or~o\ufffd\ufffdt{z1 Ikyl~tnro ]zt\ufffdo~\ufffd t\ufffd\ufffdW~o\ufffd\ufffd? 53441\n4341 Ikyo~{z FI.\\~t\ufffdont WR1Zor~o\ufffd\ufffdt{z kzkw\ufffd\ufffdt\ufffd {qm{\ufffdz\ufffd nk\ufffdk1 Ikyl~tnro \ufffdzt\ufffdo~\ufffdt\ufffd\ufffd |~o\ufffd\ufffd? 53461\n4351 I{{v ZJ. _ot\ufffdlo~r [1I~t\ufffdtmt\ufffdy kznOzqw\ufffdozmo Fzkw\ufffd\ufffdt\ufffd tzZor~o\ufffd\ufffdt{z1 [{mt{w{ rtmkw To\ufffds{n{w {r\ufffd1\n4=<5? 46>646\u02d86:41 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431563;25 ;3;57\n4361 N\ufffdlo~ykz GF1[{mtkw I{y|\ufffd\ufffdtzr kzn\ufffdsoF\ufffd\ufffdoz\ufffdt{z Km{z{y\ufffd1 Q{\ufffd~zkw {q[\ufffdk\ufffdt\ufffd\ufffdtmkw Ws\ufffd\ufffdtm\ufffd1 5346?\n494> 65=\u02d866=1 s\ufffd\ufffd|\ufffd>22n {t1{~r2431433 ;2\ufffd43=99 /345/39=: /9\n4371 \\~twwtzr JI1 L{ww{\ufffdtzr \ufffdsozo\ufffd\ufffd> Wk\ufffd\ufffdo~z\ufffd {q{zwtzo kzn{qqwtzo zo\ufffd\ufffd m{z\ufffd\ufffdy|\ufffd t{z1 ]zt\ufffdo~\ufffdt\ufffdot\ufffd \ufffdkz\nFy\ufffd\ufffdo~nky1 53461\n4391 Goww{\ufffdk~\ufffd FR.b{\ufffdzr UF.M{wnozlo~ rF1Soq\ufffd/ kznZtrs\ufffd/Sok ztzr Uo\ufffd\ufffd V~rkzt\ufffdk\ufffdt{ z\ufffd]\ufffdo Uork\ufffdt\ufffdo\nKy{\ufffdt{zkw I{z\ufffdoz\ufffd kznKwtmt\ufffd ]\ufffdo~ Kzrkroy oz\ufffd[tytwk~w\ufffd 1Fqqom\ufffdt\ufffdo [mtozmo1 5354? 5>6=4\u02d86=:1 s\ufffd\ufffd|\ufffd>22\nn{t1{~r243143 3;2\ufffd75;: 4/354/333 7:/\ufffd WTOJ> 67756644\n43:1 Tkb1Ikz T{~o Wtm\ufffd\ufffd~o\ufffd G~tzr T{~o Zokno~\ufffdst |D>FzK\ufffdkytzk\ufffdt {z{q\ufffdso\ufffdWtm\ufffd\ufffd~o [\ufffd|o~t{~t \ufffd\ufffdKqqom\ufffd\ufffd\ntz\ufffdsoUo\ufffd\ufffd I{z\ufffd\ufffdy |\ufffdt{z W~{mo\ufffd\ufffd1 W~{montk\u0152[ {mtkw kznGosk\ufffdt{~kw [mtozmo\ufffd1 534:? 56:> 67\u02d86<1\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431434:2 u1\ufffdl\ufffd|~{153 4:1451345\n43;1 [s~o\ufffd\ufffdsk W.[k\ufffdskz\ufffd~ F.Tksk~uk z[.[kwnkzsk K.F~ozn\ufffd J.^{wv{\ufffdk [1T\ufffdw\ufffdt|wo \ufffd{mtkw |wk\ufffdq{~ y\ufffd\n~o\ufffdokw km\ufffdt{zklwo \ufffdtrzkw\ufffd q{~\ufffd{q\ufffd\ufffdk~o \ufffd\ufffdwzo~k ltwt\ufffd\ufffd k\ufffdk~ozo \ufffd\ufffd>F\ufffd\ufffd\ufffdn\ufffd {qMt\ufffdN\ufffdl. \\\ufffdt\ufffd\ufffdo~ kznZonnt\ufffd1\nWS{[ VUK1 5353?491 s\ufffd\ufffd|\ufffd>2 2n{t1{~r243146 ;42u{\ufffd~zkw1| {zo13563593 WTOJ> 6553<7 64\n43<1 G\ufffdmso~ \\.Nowy{zn F1\\so kqq{~nkzmo\ufffd {q\ufffd{mtkw yontk |wk\ufffdq{~y\ufffd1 \\so [FMK skznl{{v {q\ufffd{mtkw\nyontk1 534<1 ||1566\u02d85971\n43=1 Fwn{\ufffd\ufffd RR.FzQ.Qkz\ufffdoz GQ1^to\ufffd. wtvo. m{yyoz\ufffd. |{\ufffd\ufffd> Fzkw\ufffd\ufffdtzr \ufffd\ufffdo~ ozrkroy oz\ufffdl\ufffd\ufffd{|tm k\ufffd7wo\ufffd/\now\ufffdkm~{\ufffd\ufffd 9\ufffd{mtkw yontk |wk\ufffdq{~y\ufffd q{~96zo\ufffd\ufffd {~rkzt\ufffdk\ufffd t{z\ufffd1 W~{moontzr\ufffd {q\ufffdsoOz\ufffdo~zk\ufffd t{zkw FFFO\nI{zqo~ozmo {z_ol kzn[{mtkw Tontk1 534=1 ||17;\u02d89;1 s\ufffd\ufffd|\ufffd>22n{t1{~ r24314:3 =2tm\ufffd\ufffdy1\ufffd46t 341653<\n4431 So\ufffdkzn{\ufffd\ufffdv \ufffd[.Kmvo~ ]RN. I{{v Q1Go\ufffd{zn yt\ufffdtzq{~yk\ufffdt {z>]zno~\ufffd\ufffdk zntzr kznm{|tzr \ufffdt\ufffds \ufffdso\n\ufffd|{\ufffd\ufffd/\ufffd~\ufffd\ufffds\ufffd o~k1 Q{\ufffd~zkw {qF||wton Zo\ufffdok~ms tzToy{~\ufffd kznI{rzt\ufffdt{z 1534;? :>696\u02d86:=1 s\ufffd\ufffd|\ufffd>22n{t1\n{~r2431434:2u 1uk~ykm1534 ;13;133<\nPLOS ONE^t{woz\ufffd tykro\ufffd {q\ufffdsoGST y{\ufffdoy oz\ufffdkzns{\ufffd \ufffdso\ufffd k\ufffd\ufffd~km\ufffd \ufffd\ufffdo~ k\ufffd\ufffdoz\ufffdt{z {zZonnt\ufffd\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo135<<= :5 F\ufffdr\ufffd\ufffd\ufffd =.5356 5=25=", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Attention-grabbing news coverage: Violent images of the Black Lives Matter movement and how they attract user attention on Reddit", "author": ["T Henn", "O Posegga"], "pub_year": "2023", "venue": "PLoS one", "abstract": "Portrayals of violence are common in contemporary media reporting; they attract public  attention and influence the reader\u2019s opinion. In the particular context of a social movement such"}, "filled": false, "gsrank": 122, "pub_url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288962", "author_id": ["ObKIOw8AAAAJ", "enrrxO8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:UL42zDe6C9IJ:scholar.google.com/&output=cite&scirp=121&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D120%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=UL42zDe6C9IJ&ei=GrWsaJ6pKcDZieoPqdqh8QU&json=", "num_citations": 9, "citedby_url": "/scholar?cites=15135395721520791120&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:UL42zDe6C9IJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0288962&type=printable"}}, {"title": "Machine-made media: Monitoring the mobilization of machine-generated articles on misinformation and mainstream news websites", "year": "2024", "pdf_data": "Machine-Made Media: Monitoring the Mobilization of Machine-Generated\nArticles on Misinformation and Mainstream News Websites\nHans W. A. Hanley and Zakir Durumeric\nStanford University\nhhanley@cs.stanford.edu, zakir@cs.stanford.edu\nAbstract\nAs large language models (LLMs) like ChatGPT have gained\ntraction, an increasing number of news websites have begun\nutilizing them to generate articles. However, not only can\nthese language models produce factually inaccurate articles\non reputable websites but disreputable news sites can utilize\nLLMs to mass produce misinformation. To begin to under-\nstand this phenomenon, we present one of the first large-scale\nstudies of the prevalence of synthetic articles within online\nnews media. To do this, we train a DeBERTa-based syn-\nthetic news detector and classify over 15.46 million articles\nfrom 3,074 misinformation and mainstream news websites.\nWe find that between January 1, 2022, and May 1, 2023, the\nrelative number of synthetic news articles increased by 57.3%\non mainstream websites while increasing by 474% on misin-\nformation sites. We find that this increase is largely driven by\nsmaller less popular websites. Analyzing the impact of the re-\nlease of ChatGPT using an interrupted-time-series, we show\nthat while its release resulted in a marked increase in syn-\nthetic articles on small sites as well as misinformation news\nwebsites, there was not a corresponding increase on large\nmainstream news websites.\n1 Introduction\nSince the release of ChatGPT in November 2022, hundreds\nof millions of Internet users have used the large language\nmodel (LLM) to efficiently compose letters, write essays,\nand ask for advice (Hu 2023). However, LLMs have also\nbeen shown to produce factually erroneous text. In one ex-\nample, CNET, a reputable website that reviews of consumer\nelectronics, published articles generated by OpenAI\u2019s Chat-\nGPT that were rife with factual errors (Leffer 2023). Beyond\ninaccurate text, recent research has shown LLMs can be used\nto effectively spread misinformation (Tang, Chuang, and Hu\n2023). Yet, despite the widespread adoption of LLMs and\ntheir potential to accelerate the spread of misinformation,\nthere has not been any study of whether LLMs like Chat-\nGPT have been broadly used to produce news articles on\nmainstream or fringe/unreliable websites.\nIn this work, we present a large-scale study of the rel-\native increase inmachine-generated/synthetic articles from\n3,074 news websites (1,059 misinformation/unreliable web-\nsites and 2,015 mainstream/reliable news websites) between\nCopyright \u00a9 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.January 1, 2022, and May 1, 2023. To do this, we utilize\ntraining data from 19 open-source LLMs, as well as ad-\nversarial data from article perturbation/re-writes and para-\nphrases, to train a DeBERTa-based model (He et al. 2021)\nto detect English-language synthetic news articles. We sub-\nsequently benchmark this classifier on eight test sets of\nmachine-generated news articles, including two from real-\nworld companies (Pu et al. 2023) and one containing human-\nwritten real-world articles. Across these test datasets, our\nmodel, at a false positive rate (FPR) of 1%, achieves an av-\nerage precision score of 0.992. With this model, we classify\nover 15.46M articles published between January 1, 2022,\nand May 1, 2023, from our set of 3,074 news websites.1\nWe find that among reliable/mainstream news websites,\nsynthetic articles increased in prevalence by 57.3% (0.88%\nof news articles in January 2022 to 1.39% in May 2023)\nwhile among unreliable/misinformation websites, the preva-\nlence increased by 474% (0.39% of news articles in January\n2022 to 2.22% in May 2023). Examining the content of syn-\nthetic articles, we find that while mainstream/reliable news\nwebsites have largely utilized synthetic articles to report on\nfinancial and business-related news, misinformation/unreli-\nable news websites have reported on a wide range of topics\nranging from world affairs (e.g., the Russo-Ukrainian War)\nto human health (e.g., COVID-19). Examining the impact of\nChatGPT on the prevalence of synthetic content, we further\nfind that its release coincided with significant increases in\nmachine-generated articles on misinformation websites and\nunpopular mainstream news websites.\nOur work presents one of the first in-depth analyses of\nthe growth of synthetic articles across the news ecosystem.\nWe show that throughout 2022 and 2023, particularly af-\nter the release of ChatGPT, many misinformation websites\nhave rapidly increased the amount of synthetic content on\ntheir websites. As misinformation websites increasingly uti-\nlize synthetic articles, we hope that our work can serve as the\nbasis for identifying the use of LLMs and for helping enable\nfuture studies on the spread of misinformation.\n1We release the weights of our model and the URLs used in this\nstudy at https://github.com/hanshanley/machine-made-media.\nProceedings of the Eighteenth International AAAI Conference on Web and Social Media (ICWSM 2024)\n542\n2 Background and Related Work\nRecent advances in large language models (LLMs) have\nresulted in impressive performance on a variety of tasks,\nmost notably convincing text generation (Brown et al. 2020;\nChowdhery et al. 2023; AI 2022; Zellers et al. 2019). Since\n2022, models such as Open AI\u2019s ChatGPT, Meta\u2019s LLaMa,\nand Google\u2019s Gemini have largely democratized LLMs\u2019\nuse. However, despite their popularity, the widespread avail-\nability of LLMs can be problematic. For example, Zeller\net al. (2019) showed that even the older GPT-2 LLM can cre-\nate convincing articles, often with factual errors, that evoke\nmore trust than human-written articles.\nDefinition: Synthetic Articles Within this work, we\nconsider news articles largely generated by LLMs\nand other automated software to be synthetic/machine-\ngenerated (Gagiano et al. 2021). For instance, an article\nproduced by directly prompting the API for OpenAI\u2019s\nGPT-3.5 davinici LLM would be considered syn-\nthetic. We note, however, as shown in prior work (Mitchell\net al. 2023; Uchendu et al. 2021), heavily human-edited\nmachine-generates news articles are difficult to detect, often\nbeing indistinguishable from human-written news articles.\nAs such, within this work, we further define synthetic news\narticles as those that are largely if not completely generated\nby LLMs without significant human modification.\nReal-World Use of Synthetic News Media. While the\nlarge-scale democratization of generative models is new, the\nuse of machine-generated or synthetic articles by news web-\nsites is not. Since as early as 2019, Bloomberg has used the\nservice Cyborg to automate the creation of nearly one-third\nof their articles (Peiser 2019). Similarly, since 2019, other\nreputable news sources including The Associated Press, The\nWashington Post, and The Los Angeles Times, have used\nmachine-generation services to write articles on topics that\nrange from minor league baseball to earthquakes (Peiser\n2019). However, articles that contain machine-generated\ncontent from services such as Cyborg, BERTie, or Chat-\nGPT, while reducing the workload of reporters, have also\nbeen shown to often contain factual errors (Alba 2023; Lef-\nfer 2023). As a result, much research has focused on de-\ntecting machine-generated news articles (Zellers et al. 2019;\nUchendu et al. 2020; He et al. 2023; Ippolito et al. 2020).\nDetecting Machine-Generated Media. Several approaches\nhave been developed to detect machine-generated text.\nBERT-defense (Ippolito et al. 2020) for instance uses a\nBERT-based (Devlin et al. 2019) model to identify machine-\ngenerated texts. DetectGPT (Mitchell et al. 2023) approxi-\nmates the probabilistic curvature of specific LLMs for zero-\nshot detection. Mitchell et al. show that if the specific model\nused to generate text is known and can be readily queried to\nobtain the log probabilities of pieces of text, then it is pos-\nsible to easily differentiate synthetic articles from human-\nwritten news articles, with their approach achieving a 0.97\nAUROC for the XSum dataset. Zhong et al. (2020) propose\na graph-based approach that considers the factual structure\nof articles to detect machine-generated text.\nOur work depends on accurately identifying machine-\ngenerated articles across news websites. As shown in previ-ous works, however, many machine learning models trained\nto detect synthetic texts overfit to their training domain, the\ntoken distribution of the model used to generate the synthetic\ntexts, and the topics that they were trained on (Mitchell\net al. 2023; Uchendu et al. 2020; Lin, Hilton, and Evans\n2022). For example, models trained to detect synthetic\nnews articles, often fail to detect shorter machine-generated\ntweets. Despite these shortcomings, as illustrated by Pu et\nal. (2023), classifiers focused on only one domain can of-\nten perform exceedingly well on datasets seen \u201cin-the-wild.\u201d\nAdversarially training a RoBERTa (Liu et al. 2019) based\nclassifier, Pu et al. achieve an F1-classification score of\n87.4\u201391.4 on a test dataset made up of synthetic news ar-\nticles purchased from AI Forger and Article Forge. Unlike\nin other domains, such as tweets or comments, news arti-\ncles tend to be longer, allowing for greater precision in their\nclassification (Pu et al. 2023; Sadasivan et al. 2023).\nReliable and Unreliable News Websites. In this work, we\nanalyze how both reliable/mainstream and unreliable/misin-\nformation news websites have published machine-generated\narticles throughout 2022 and 2023. Unreliable information\ncan take the form of misinformation, disinformation, and\npropaganda, among other types (Jack 2017). Within this\nwork, we refer to websites that have been labeled by other\nresearchers as generally spreading false or unreliable infor-\nmation as misinformation/unreliable news websites (includ-\ning both websites labeled as misinformation anddisinfor-\nmation within this label). As in prior work, we consider reli-\nable/mainstream news websites as \u201coutlets that generally ad-\nhere to journalistic norms including attributing authors and\ncorrecting errors; altogether publishing mostly true informa-\ntion\u201d (Hounsel et al. 2020).\n3 Detecting Machine-Generated Articles\nAs described in Section 2, several approaches have been de-\nveloped for identifying synthetic articles, with some of the\nmost successful being transformer-based methodologies (Pu\net al. 2023; Gehrmann, Strobelt, and Rush 2019). How-\never, given that past models were trained to (1) only de-\ntect text from particular models (Zellers et al. 2019), (2)\nare deeply vulnerable to adversarial attacks (Pu et al. 2023),\n(3) or have unreleased weights (Zhong et al. 2020), we de-\nsign and benchmark our own transformer-based machine-\nlearning classifiers to identify synthetic articles in the wild.\nIn addition to training three transformer architectures\n(BERT, RoBERTa, DeBERTa) on a baseline training dataset\n(detailed below), we further train these models on datasets\ngenerated by two common adversarial attacks (Krishna et al.\n2024; Mitchell et al. 2023). To benchmark and understand\nthe generalization of our approach, we test our new models\nagainst datasets of articles generated by two companies, AI\nWriter and AI Forger provided to us by Pu et al. (2023), the\nTuring Benchmark (Uchendu et al. 2021), four distinct GPT-\n3.5 generated datasets (OpenAI 2022), and finally a dataset\nof human-written articles from 2015 (Corney et al. 2016).\nWe now describe our training and test datasets, the architec-\ntures of our models, and finally our models\u2019 performances\non our benchmarks.\n543\nBaseline Training Datasets. To train a classifier to detect\nmachine-generated/synthetic news articles found in the wild,\nwe require a diverse dataset of articles from a wide array of\ngenerative models. Thus, for our baseline training dataset,\nwe take training data of machine-generated/synthetic arti-\ncles from three primary sources: the Turing Benchmark,\nGrover, and articles generated from GPT-3.5.\nMachine-Generated Training Articles: For much of our\ntraining data, we utilize the Turing Benchmark (Uchendu\net al. 2021), which contains news articles generated by\n10 different generative text architectures including GPT-\n1 (Radford et al. 2019a), GPT-2 (Radford et al. 2019b),\nGPT-3 (Brown et al. 2020), CTRL (Keskar et al. 2019),\nXLM (Conneau and Lample 2019), Grover (Zellers et al.\n2019), XLNet (Yang et al. 2019), Transformer-XL (Dai et al.\n2019), and FAIR/WMT (Ng et al. 2019; Chen et al. 2020).\nWe note that given the different settings and trained weights\nprovided by the authors of these respective works, the Turing\nBenchmark altogether includes articles generated from 19\ndifferent models. We randomly subselect 1000 articles from\nwithin the Turing benchmark generated by each of these dif-\nferent models as training data.\nIn addition to the Turing Benchmark training dataset, we\nuse the training dataset of Zellers et al. (2019), which con-\ntains realistic, often long-form articles, that mimic the fash-\nion of popular news websites such as cnn.com, nytimes.com,\nand the washingtonpost.com. Unlike the Grover-generated\narticles from the Turing Benchmark dataset, which are gen-\nerated using a prompt of just the title of potential articles,\nthese Grover articles are generated in an unconditional set-\ntingandfrom prompting the Grover model with metadata\n(i.e., title, author, date, website). As found by Zellers et al.,\nmany of the articles produced by their models were convinc-\ning to human readers, and we thus include 11,930 machine-\ngenerated articles from the base model of Grover (across\ndifferent Grover decoding settings [e.g., p=1.00, p= 0.96,\np=0.92 (nucleus/top-p), k=40 (top-k), etc... settings ]) in our\ntraining dataset.\nFinally, given the popularity of the GPT-3.5 model (Hu\n2023), with it being the basis of the February 2023 re-\nleased version of ChatGPT, and GPT-3.5 being one of the\nmost powerful released models, we add 3,516 articles gen-\nerated from the GPT-3.5 davinici model. To create\nthese articles, we prompt the public API of GPT-3.5\ndavinici with the first 10 words of 3,516 real news ar-\nticles from 2018 (see Section 4; while scraping our news\ndataset, we acquired several million articles from 2018). For\nGPT-3.5 davinici model, we use a nucleus decoding\nsetting of p=1.00, p=0.96, and p=0.92 (some of the most\ncommon (Mitchell et al. 2023; Zellers et al. 2019)).\nWe finally note that, as found in prior work (Pu et al. 2023;\nUchendu et al. 2021; Zellers et al. 2019), machine-generated\nnews articles are often shorter in length than human-written\narticles. While training, to ensure that our models do not\nsimply distinguish between longer human-written articles\nand those generated by generative transformers by their dif-\nferent lengths, we ensure that our machine-generated and\nhuman-written articles are of similar lengths (median train-\ning synthetic article length of 210 words and median train-Human Machine\nTraining Dataset Written Generated\nBaseline 33,446 33,446\nPert. 33,446 44,003\nPara. 33,446 41,498\nPerturb + Para. 33,446 52,055\nTable 1: The number of machine-generated and human-\nwritten articles within the Baseline, Pert, Para, and\nPert.+Para. training datasets.\nHuman Machine\nTest Dataset Written Generated\nTuring Benchmark 975 18,076\nGPT-3.5 1,000 243\nGPT-3.5 w/ Pert. 1,000 241\nGPT-3.5 w/ Para. 1,000 118\nArticle Forger 1,000 1,000\nAI Writer 1,000 1,000\nTable 2: The number of machine-generated and human-\nwritten articles within our test datasets.\ning human article length of 224 words). Furthermore, as\nfound by past work, predictions for particularly short texts,\ntend to be unreliable (Kirchner et al. 2023; Zellers et al.\n2019; Pu et al. 2023); conversely, as shown by Sadasivan\net al. (2023), as the lengths of texts increase the variance\nbetween human and machine-generated texts increases. As\nsuch, for our training and our generated test data (GPT 3.5\ndataset), we exclude texts shorter than 1,000 characters (140\nwords) (OpenAI 2022). We note as a result, we do not use\nevery trained model\u2019s articles from the Turing Benchmark;\ngiven that WMT-20/FAIR articles within this dataset are\nall shorter than 1000 characters, we do not include them\nwithin our training dataset. Altogether our training dataset\nthus only includes data from 19 different models (18 from\nTuring Benchmark and GPT-3.5 davinici).\nHuman-Written Training Articles: For our set of human-\ngenerated articles, as in Zellers et al. (2019), we utilize news\narticles published in 2018. Specifically, we use 28,446 arti-\ncles from 2018 from our set of news websites that we later\nmeasure (see Section 4; while scraping our news dataset, we\nacquired several million articles from 2018), 2,500 articles\nfrom the human split of the Grover dataset, and 2,500 ar-\nticles from the human-train-split within the Turing Bench-\nmark dataset.\nWe present an overview of our complete Baseline\ndataset in Table 1.\nBaseline Test Datasets. For our baseline test datasets (Ta-\nble 2), we utilize the validation split from the Turing Bench-\nmark (the labels from the test split were unavailable to us),\nand another test dataset consisting of 243 additional GPT-\n3.5 articles that we created by again prompting GPT-3.5\ndavinici, and 1000 human-written articles from 2018\n(see Section 4; as with our training data, while scraping our\nnews dataset, we acquired several million articles from be-\nfore 2019). Further, to ensure our models generalize and\n544\nhandle articles seen in the wild, we utilize the In-the-Wild\ndataset provided to us by Pu et al. (2023). This dataset con-\nsists of news articles created using generative LLMs from\ntwo independent companies, Article Forger and AI Writer.\nBy testing against these outside datasets, we validate our ap-\nproach against articles generated by (1) models not within\nour dataset and (2) by generative news article services avail-\nable to the public. We provide details in Table 2.\nTraining and Test Dataset using Perturbations and Para-\nphrases. Transformer-based classifiers are often particularly\nsusceptible to adversarial attacks, particularly attacks that\nrewrite sections of the generated article (Mitchell et al. 2023;\nPu et al. 2023) and paraphrase attacks (i.e., where a generic\nmodel is used to paraphrase the output of a different gen-\nerative model (Krishna et al. 2024)). To guard against these\nweaknesses, we take two approaches (1) perturbing our set\nof synthetic articles by rewriting at least 25% of their content\nusing the generic T5-1.1-XL model2and (2) paraphrasing\narticles with the T5-based Dipper model.3\nConstructing Perturbed Synthetic Articles. To pertur-\nb/rewrite sections of our machine-generated articles, as in\nMitchell et al. (2023), we randomly MASK 5-word spans\nof text in each article until at least 25% of the words in\nthe article are masked. Then, using the text-to-text gener-\native model T5-1.1-XL (Raffel et al. 2020), we fill in these\nspans, perturbing our original generated articles. As shown\nby Mitchell et al. (2023), large generic generative models\nsuch as T5 can apply perturbations that roughly capture\nmeaningful variations of the original passage rather than\narbitrary edits. This enables us to model divergences from\nthe distributions of texts created by our 19 different genera-\ntive models (18 from Turing Benchmark and GPT-3.5). We\nthus utilize T5-1.1-XL to perturb a portion of the machine-\ngenerated articles of our Baseline train dataset. In addi-\ntion, we create a separate test dataset by perturbing our GPT-\n3.5 test dataset (Table 2). We note that after perturbing our\ndatasets, we filter to ensure all articles used for training con-\ntain at least 1000 characters. We annotate training and test\ndatasets containing synthetic articles perturbed with T5-1.1-\nXL with the suffix Pert. After perturbation we still con-\nsider these articles to be synthetic.\nConstructing Paraphrased Synthetic Articles. To para-\nphrase each of the machine-generated articles within\nour dataset, we use the approach outlined by Krishna\net al. (2024). Specifically, as in their work, we utilize Dip-\nper, a version of the T5 generative model fine-tuned on\nparagraph-level paraphrases, that outputs paraphrased ver-\nsions of the inputted text. We use the default and recom-\nmended parameters4as in Krishna et al. to paraphrase a por-\ntion of the text within our original training dataset as well as\nour GPT-3.5 test dataset (Krishna et al. 2024). We note that\nafter paraphrasing our datasets, we again filter to ensure all\narticles utilized for training contain at least 1000 characters\n(Table 2). We annotate training and test datasets containing\n2https://huggingface.co/google/t5-v1 1-large\n3https://huggingface.co/kalpeshk2011/dipper-paraphraser-xxl\n4We use a lexical diversity parameter of 60. For more details on\nthe Dipper model see Krishna et al. (2024)articles paraphrased with Dipper with the suffix Para. After\nparaphrasing we still consider these articles to be synthetic.\nDetection Models. Having described our training test sets,\nwe now detail our models and evaluate their performance\non our 6 test datasets (Turing Benchmark, GPT-3.5, GPT-\n3.5 w/ Pert, GPT-3.5 w/ Para, Article Forger, AI Writer).\nSpecifically, we fine-tune three pre-trained transformers,\nBERT-base (Devlin et al. 2019), RoBERTa-base (Liu et al.\n2019), and DeBERTa-v3-base (He et al. 2021).567For each\narchitecture, we train 4 models to detect machine-generated\nnews articles using our Baseline, Perturb, Para, and\nPerturb+Para training datasets. For each architecture,\nwe build a classifier by training an MLP/binary classifica-\ntion layer on top of the outputted [CLS] token. We use a max\ntoken length of 512 (Ippolito et al. 2020; Pu et al. 2023),\na batch size of 32, and a learning rate of 1\u00d710\u22125. Each\nmodel took approximately 2 hours to train using an Nvidia\nRTX A6000 GPU. After training, as in Pu et al. (2023),\nwe determine each model\u2019s binary F1-scores, precision, and\nrecall for each test dataset and rank each model using its\naverage F1-score. We classify each text based on its out-\nputted softmax probability (>0.5 being classified as syn-\nthetic). For a baseline comparison for our trained models, we\nfurther test the Roberta-based classifier released by Open AI\nin 2019 (Solaiman et al. 2019) on each of our test datasets.\nConsistent with prior works (Veselovsky, Ribeiro, and\nWest 2023; Mitchell et al. 2023; Gagiano et al. 2021), due to\ntraining our model on synthetic articles from a wide variety\nof sources, and due to our model\u2019s focus on news articles,\nwe observe that all our trained models perform markedly\nbetter than Open AI\u2019s 2019 released detection model. We\npresent the full table of results in Appendix A in Table 11.\nWe further observe, as aggregated in the Avg. F1-score\ncolumn, that our set of DeBerta models performs the best in\nclassifying machine-generated/synthetic content, all achiev-\ning an average F1-score greater than 0.959. In particular,\nwe observe that our DeBERTa model trained on a dataset\nthat includes our set of adversarial data Pert +Para, per-\nforms the best at an average F1-score of 0.977. This partic-\nular model further achieves the best respective F1-scores in\nclassifying the set of articles from Article Forger and AI-\nwriter provided by Pu et al., achieving F1-scores of 0.968\nand 0.979 on the two datasets respectively. We note that\nour model, in addition to performing better than Open AI\u2019s\nRoberta, also outperforms all models benchmarked by Pu et\nal. (2023) on the AI Forger and the AI Writer test datasets,\nwhich achieved F1-scores ranging from 1.6 to 94.9. This\nillustrates that our model can generalize to other types of\nmachine-generated articles from models not included in our\ndataset.\nIn addition to testing our models on these six datasets, to\nfurther ensure that our approach generalizes well, we test our\nmodels in two additional settings: (1) a setting where Chat-\nGPT is utilized to rewrite a given human-written article, (2)\na setting that includes articles not from the year of train-\n5https://huggingface.co/bert-base-uncased\n6https://huggingface.co/roberta-base\n7https://huggingface.co/microsoft/deberta-v3-base\n545\nChatGPT Rewrite Signal Art.\nF1 Prec. Recall Accuracy\nOpenAI Roberta 0.002 0.200 0.001 0.997\nBERT+Para 0.905 0.978 0.842 0.766\nRoBERTa+Pert.+Para. 0.937 0.964 0.912 0.820\nDeBERTa+Pert.+Para. 0.892 0.979 0.820 0.942\nTable 3: We benchmark our BERT +Para,\nRoBERTa+Pert+Para, and DeBERTa +Pert+Para\nmodels, and the OpenAI RoBERTa model on a dataset of\n1,000 articles from 2018 rewritten by ChatGPT (along with\nthe original 1,000 human-written articles) and a dataset of\n10,000 human-written articles from 2015 chosen randomly\nfrom the Signal article dataset.\ning (2018) and from websites not in our original dataset. As\nsuch, we finally test the OpenAI Roberta classifier as well as\nthe best BERT, RoBERTa, and DeBERTa models on (1) a set\nof 1,000 articles from our dataset of 2018 news articles that\nwere rewritten8by ChatGPT (OpenAI 2022) as well as the\ncorresponding set original news articles, and (2) 10,000 ran-\ndomly selected human-written articles from 2015 from the\nSignal Media news article dataset. As seen in Table 3, our\nDeBERTa+Pert+Para model achieved the highest accu-\nracy on the Signal dataset and the second highest precision\non the ChatGPT Rewrite dataset, with scores of 94.2% ac-\ncuracy and 97.9% precision respectively.\nSelecting a classification threshold for synthetic articles.\nGiven its performance across all eight of our datasets, we\nuse our DeBERTa+Pert+Para trained model as our de-\ntection model for the rest of this work. However, as noted\nin prior research (Krishna et al. 2024), a realistic low false\npositive rate (FPR) would be near 1%. Given our model\nonly achieves an average FPR of 5.8% on our Signal arti-\ncle dataset at a softmax probability threshold of 0.50, when\nclassifying articles within this work, we raise our softmax\nprobability classification threshold to 0.98, allowing us to\nachieve a 1% FPR/accuracy on the Signal article dataset.\nAt this threshold, our model achieves a 0.993/0.972 preci-\nsion/recall on our original six datasets with an FPR of 0.7%.\nSimilarly, at this threshold, our model reaches a precision\nof 0.989 on our ChatGPT rewrite test set at the expense of\nonly reaching a 0.639 recall. We thus find that by increas-\ning our threshold to 0.98, we can achieve a realistic FPR at\nthe expense of recall. For the rest of this work, we utilize a\nsoftmax probability threshold of 0.98. Our work thus likely\nrepresents a conservative estimate of the amount of synthetic\narticles online.\n4 News Dataset and Classification Pipeline\nHaving described the DeBERTa-based model that we use\nto identify machine-generated/synthetic articles, we now de-\nscribe our datasets of scraped news articles.\n8We had ChatGPT rewrite each article by supplying the prompt\n\u201cRewrite the following news article in your own words:\u201d followed\nby the article.Website List. Between January 1, 2022, and May 1, 2023,\nwe gather all articles published from 3,074 news websites.9\nOur list of websites consists of domains labeled as \u201cnews\u201d\nby Media Bias Fact Check10and by prior work (Hanley, Ku-\nmar, and Durumeric 2023). Within our list of news sites,\nwe differentiate between \u201cunreliable news websites\u201d and\n\u201creliable news websites.\u201d Our list of unreliable news web-\nsites includes 1,059 domains labeled as \u201cconspiracy/pseu-\ndoscience\u201d by mediabiasfactcheck.com as well as those la-\nbeled as \u201cunreliable news\u201d, misinformation, or disinforma-\ntion by prior work (Hanley, Kumar, and Durumeric 2023;\nBarret Golding 2022; Szpakowski 2020). Our set of \u201cun-\nreliable\u201d or misinformation news websites includes web-\nsites like realjewnews.com, davidduke.com, thegatewaypun-\ndit.com, and breitbart.com. We note that despite being la-\nbeled unreliable every article from each of these websites is\nnotnecessarily misinformation.\nOur set of \u201creliable\u201d/mainstream news websites consists\nof the news websites that were labeled as belonging to the\n\u201ccenter\u201d, \u201ccenter-left\u201d, or \u201ccenter-right\u201d by Media Bias Fact\nCheck as well as websites labeled as \u201creliable\u201d or \u201cmain-\nstream\u201d by other works (Hanley, Kumar, and Durumeric\n2023; Barret Golding 2022; Szpakowski 2020). This set\nof \u201creliable news websites\u201d includes websites like wash-\ningtonpost.com, reuters.com, apnews.com, cnn.com, and\nfoxnews.com. Altogether after removing duplicates and un-\navailable websites, we scraped 2,015 \u201creliable news\u201d or\nmainstream websites.\nWe note that to later understand how websites of vary-\ning popularity/size have used machine-generated articles on\ntheir websites, we striate our list of websites by their pop-\nularity using ranking data provided by the Google Chrome\nUser Report (CrUX) (Ruth et al. 2022). We note that the\nCrUX dataset, rather than providing individual popularity\nranks for each website, instead provides rank order mag-\nnitude buckets (e.g., top 10K, 100K, 1M, 10M websites).\nAs such, we analyze our set of websites in the following\nbuckets: Rank <10K (125 websites), 10K <Rank<100K\n(511 websites), 100K <Rank<1M (1,164 websites), 1M\n<Rank<10M (802 websites), and finally Rank >10M+\n(472 websites).\nArticle Collection. To collect the articles published by our\nset of news websites, we queried each website\u2019s RSS feeds\n(if available) and crawled the homepages of each website\ndaily from January 1, 2022, to May 1, 2023. Upon identify-\ning newly published articles, we subsequently scraped web-\nsites using Colly11and Headless Chrome, orchestrated with\nPython Selenium. To extract the article text and publication\ndate from each HTML page, we parsed the scraped HTML\nusing the Python libraries newspaper3k andhtmldate.\nGiven that many of our websites (e.g., cnn.com) have\nmultilingual options, we use the Python langdetect li-\nbrary to filter out all non-English articles. To prepare data\n9We note that while this study focuses on the release of Chat-\nGPT as a possible focal point, our data collection for this project\nactually began in January 2022.\n10https://mediabiasfactcheck.com/\n11https://github.com/gocolly/colly\n546\nfor classification, we remove boilerplate language using the\nPython justext library and then remove URLs, emojis,\nand HTML tags. Further, to ensure the reliability of our\nclassifications, we only classify news articles that are at\nleast 1000 characters (approximately 140 words) long. Al-\ntogether, from our selection of 3,074 websites, we gath-\nered 15.46M articles (12.06M from mainstream websites\nand 3.39M from misinformation websites) that were pub-\nlished between January 1, 2022, and May 1, 2023. Finally,\nwe utilize our DeBERTa+Pert+Para model at a soft-\nmax classification threshold of 0.98 to classify each article\nas either human-written or machine-generated. Classifying\nall 15.46M articles took approximately 65.8 hours using an\nNvidia RTX A6000 GPU.\nEthical Considerations. With the rise of LLMs, many\ncompanies have widely scraped and gathered data from web-\nsites to fuel their models (Schappert 2023). As a result, web-\nsites ranging from Twitter to Reddit have begun to set up\nrestrictions to ensure the privacy of their users and to pro-\ntect their content from being used in other private compa-\nnies\u2019 generative models. While we do not train a generative\nmodel that could artificially produce convincing and seem-\ningly unique reproductions of the texts that we utilize, we\nnote the concern that our work raises.\nOur work, however, only studies the texts of our set\nof 15.46 million articles and classifies them as machine-\ngenerated or human-written. We do not seek to generate\nsummaries or artificial rewrites of this content. In terms\nof web crawling for this data, as noted elsewhere (Singro-\ndia, Mitra, and Paul 2019; Hanley, Kumar, and Durumeric\n2023; Smith et al. 2013), website crawling and scraping re-\nmain pivotal for understanding and documenting what oc-\ncurs on the Internet. Without scraping, understanding trends\nand how the Internet could potentially affect real life be-\ncomes impossible. As decided in Van Burn v. United States,\npublically accessible information can be legally scraped as\nlong as it is done ethically and does not harm the site (Emily\nR. Lowe and Katrina Slack 2022). As such, we collect only\npublicly available data from our set of websites and follow\nthe best practices for web crawling as in Acar et al. (2014).\nWe limit the load that each news site experiences by check-\ning for new articles daily at a maximum rate of one request\nevery 10 seconds. The hosts that we scan from are identifi-\nable through WHOIS, reverse DNS, and an HTTP landing\npage explaining how to reach us if they would like to be\nremoved from the study. During our crawling period, we re-\nceived no requests from websites to opt out.\n5 The Rise of Machine-Generated Media\nHaving described our detection model and datasets, in this\nsection, we analyze the relative change in the levels of syn-\nthetic content across our set of websites between January\n1, 2022, and May 1, 2023. Specifically, we determine (1)\nwhether there has been an increase in the use of synthetic\narticles, (2) if there has been an increase in their use, which\nsets of websites are driving this increase, (3) what synthetic\narticles are topically about, and (4) whether the introduction\nof ChatGPT has changed the prevalence of synthetic articles.\n2022-02-01 2022-03-18 2022-05-02 2022-06-16 2022-07-31 2022-09-14 2022-10-29 2022-12-13 2023-01-27 2023-03-13 2023-04-270.000.501.001.502.002.503.003.50% Synthetic ArticlesChatGPT \nReleasedall\nmainstream\nmisinfoFigure 1: The average percentage of synthetic articles for all,\nmisinformation, and mainstream websites. We provide 95%\nNormal confidence intervals.\nSnippet from Reuters The S&P 500 (.SPX) and Nasdaq (.IXIC) added to losses,\nwhile the Dow (.DJI) turned negative on Wednesday after the release of the latest\nFOMC meeting minutes showed that officials said the central bank may need to\nraise interest rates sooner than expected and reduce asset holdings quickly.\nFigure 2: Example first paragraph of an article classified by\nour system as machine-generated/synthetic.\nLarge-Scale Trends in Machine-Generated Media. To be-\ngin, we plot the average percentage of synthetic news ar-\nticles per website across our dataset between January 1,\n2022, and May 1, 2023, in Figure 1. In aggregate, across\nall 3,074 sites, we see that 1.07% of all articles published\nin January 2022 (12,984 of 1,213,983 articles) were syn-\nthetically generated. However, by May 2023, the fraction\nof synthetic articles nearly went up to 1.78% (25,561 of\n1,439,812 articles), a 66.0% relative increase (nearly dou-\nbling in raw amount).\nWe observe that our set of reliable/mainstream websites\ntypically had a greater percentage of synthetic articles at the\nbeginning of 2022 compared with misinformation/unreliable\nnews websites. While only 0.39% of articles on average per\ndomain from our set of misinformation websites were clas-\nsified as machine-generated in January 2022, 0.88% of arti-\ncles on average from our set of mainstream/reliable web-\nsites were classified as machine-generated. This result is\nconsistent with prior observations that many news websites\nhave begun to use automated services to write quick, often\nfinancial-related articles (Section 2). For example, the begin-\nning of one of the articles from Reuters (Figure 2) classified\nby our system as being machine-generated simply contained\nsimple information about the direction of particular markets\nand funds.\nHowever, despite reliable/mainstream websites initially\nhaving higher levels of synthetic text, misinformation web-\nsites had marked increases in levels of machine-generated\ncontent during 2022 and 2023 (Figure 1). While between\nJanuary 1, 2022, and May 1, 2023, reliable/mainstream news\nwebsites had a 57.3% relative increase (0.51% absolute per-\ncentage increase) in their levels of synthetic content, mis-\ninformation websites had a 474% relative increase (1.85%\nabsolute percentage increase). Starting from a lower base,\n547\n2022-02-01 2022-03-18 2022-05-02 2022-06-16 2022-07-31 2022-09-14 2022-10-29 2022-12-13 2023-01-27 2023-03-13 2023-04-27200400600800# Sites Using Synthetic Art.ChatGPT \nReleasedmainstream\nmisinfoFigure 3: The number of websites that published at least one\nsynthetic article over a 30-day time span.\n2022-01-31 2022-03-17 2022-05-01 2022-06-15 2022-07-30 2022-09-13 2022-10-28 2022-12-12 2023-01-26 2023-03-12 2023-04-260123456# of ArticlesChatGPT \nReleased\nFigure 4: The number of articles that contained a common\nChatGPT error message over time.\nwe thus see a substantial increase in the prevalence of syn-\nthetic articles on unreliable/misinformation websites. Fur-\nthermore, as seen in Figure 3, we further observe that an in-\ncreasing number of news outlets published at least one syn-\nthetic article within any given 30-day time frame. Across\nour period of study, the number of mainstream websites that\npublished at least one synthetic article increased from 697\n(34.6% of mainstream websites) in January 2022 to 940\n(46.6%) in April 2023. Similarly, the number of misinfor-\nmation websites that published at least one synthetic article\nincreased from 110 (10.4% of misinformation websites) to\n179 (16.9%).\nTo confirm these initial findings, we further examine the\nincrease in common idiosyncratic error messages often re-\nMisinformation Mainstream\nAbs. Rel. Abs Rel.Rank % Inc % Inc % Inc % Inc\nAll 1.85% 474% 0.51% 57.3%\nRk<10K 0.70% 175% 0.36% 27.0%\n10K<Rk<100K 1.77% 221% 0.26% 27.3%\n100K <Rk<1M 1.38% 349% 0.23% 30.1%\n1M<Rk<10M 1.55% 646% 0.14% 15.4%\nRk>10M+ 3.42% 736% 2.13% 423%\nTable 4: Estimated absolute percentage increase in machine-\ngenerated/synthetic articles between January 1, 2022 and\nMay 1, 2023.Jan.2022 % Syn. CrUX Rank\nopensecrets.org 42.5% <100K\ntheodysseyonline.com 26.2% <1M\nlogically.ai 17.2% <10M\nchina.org.cn 16.3% <1M\nglobaltimes.cn 16.0% <100K\negypttoday.com 15.0% <1M+\nsourcewatch.org 14.4% <1M\nbleacherreport.com 9.84% <100K\nthequint.com 9.81% <10K\nafricanews.com 9.64% <1M\nTable 5: Websites with the largest percentage of synthetic\ncontent (with at least 100 articles in that month) in January\n2022.\nApril 2023 % Syn. CrUX Rank\nchina.org.cn 34.9% <1M\nglobaltimes.cn 26.3% <100K\nthelist.comm 26.0% <1Mbjreview.com 26.0% >10M+\nthefrisky.com 23.6% <1M\nnorthkoreatimes.com 23.1% >10M+egypttoday.com 21.0% <1M\nwaynedupree.com 20.1% <1M\nancient-origins.net 15.3% <100K\nentrepreneur.com 15.0% <100K\nTable 6: Websites with the largest percentage of synthetic\ncontent (with at least 100 articles in that month) in April\n2023.\nturned by ChatGPT. Specifically using a list of error mes-\nsages including \u201cmy cutoff date in September 2021\u201d, \u201cas an\nAI language model\u201d, and \u201cI cannot complete this prompt\u201d\nthat the company News Guard (Sadeghi and Arvanitis 2023)\nhas used to detect AI-generated websites, we gather ev-\nery article among our 15.46 million articles that utilized\nsuch message: altogether 570 articles from 280 domains.\nAmongst these websites, the top domains of these articles in-\ncluded forbes.com (32 articles), dailymail.co.uk (29), fairob-\nserver.com (19), theregister.com (13), and patheos.com (13).\nAs seen in Figure 4, we find that while at the beginning of\n2022, there were seemingly no such error messages within\nour set of articles, by the end of April 2023, there were\nnearly six of these articles each day. We note that this graph\nalso mirrors the behavior of the percentage of machine-\ngenerated articles that our DeBERTa detector found amongst\nall of our websites. Together, these results confirm that there\nhasbeen a noted increase in the use of synthetic content gen-\neration by our set of news websites in 2022 and 2023.\nWe finally note that we observe a small but noticeable dip\nin the percentage and amount of synthetic content in Fig-\nures 1 and 4 (particularly among misinformation websites)\nbetween February and March 2023. We find, as seen in Fig-\nure 1, that unreliable websites such as foreignpolicyi.org,\nprophecynewswatch.com, and awarenessact.com, in partic-\nular, drove the initial increase in machine-generated con-\ntent in January and February 2022, before dramatically de-\ncreasing their amount of synthetic content in the following\nmonth. Examining Google trends data, we also observe that\nChatGPT experienced a noticeable dip/decline (from 87% of\npeak search traffic on February 5 to 75% peak search traffic\n548\n2022-02-012022-04-022022-06-012022-07-312022-09-292022-11-282023-01-272023-03-2800.51.01.52.02.53.03.5% Synthetic ArticlesChatGPT \nReleasedRank < 10K \n Misin. N = 11, Main. N = 114\nmainstream\nmisinfo\n2022-02-012022-04-022022-06-012022-07-312022-09-292022-11-282023-01-272023-03-2800.51.01.52.02.53.03.5\nChatGPT \nReleased10K < Rank < 100K \n Misin. N = 63, Main. N = 448\nmainstream\nmisinfo\n2022-02-012022-04-022022-06-012022-07-312022-09-292022-11-282023-01-272023-03-2800.51.01.52.02.53.03.5\nChatGPT \nReleased100K < Rank < 1M \n Misin. N = 195, Main. N = 969\nmainstream\nmisinfo\n2022-02-012022-04-022022-06-012022-07-312022-09-292022-11-282023-01-272023-03-2800.51.01.52.02.53.03.5\nChatGPT \nReleased1M < Rank < 10M \n Misin. N = 406, Main. N = 396\nmainstream\nmisinfo\n2022-02-012022-04-022022-06-012022-07-312022-09-292022-11-282023-01-272023-03-280246810\nChatGPT \nReleasedRank > 10M+ \n Misin. N = 384, Main. N = 88\nmainstream\nmisinfoFigure 5: The average percentage of machine-generated/synthetic articles for misinformation/unreliable and mainstream/reli-\nable news websites at different striations of popularity according to Google Chrome User Report (CrUX) from October 2022.\nAll striations of misinformation websites experienced a small uptick of machine-generated content around November 30, 2022,\nthe release date of OpenAI\u2019s ChatGPT. We note that the scale of synthetic content is much larger for websites with popularity\nrank>10M+.\non March 5) in popularity in the United States during this\nperiod perhaps (but not definitively) explaining this small\ndecline.\nTrends Among Popular and Unpopular Websites. To\nunderstand how popularity and website size correlated\nwith the near doubling of machine-generated content in\n2022 and 2023, we plot the percentage of machine-\ngenerated/synthetic articles over time in Figure 5 for web-\nsites within different rank buckets and striated by whether\nthey are considered unreliable/misinformation or reliable/-\nmainstream. As seen in Figure 5, there is a general upward\ntrend in the amount of machine-generated articles across ev-\nery popularity stratum.\nExamining these increases within particular brackets of\npopularity, we see (as pictured in Figure 5 and calculated in\nTable 4) that the least popular websites saw the largest per-\ncentage increase in the use of synthetic articles. For both un-\nreliable/misinformation and reliable/mainstream categories,\nwe observe that for websites that rank >10M+ in popu-\nlarity, the percentage of their articles that were synthetic\nincreased by 3.42% (736% relative increase) and 2.13%\n(423%) on average, respectively. By contrast, among the\nmost popular misinformation/unreliable websites (e.g., bre-\nitbart.com, zerohedge.com) and mainstream/reliable web-\nsites (e.g., cnn.com, foxnews.com), synthetic articles had\na smaller 0.70% (175% relative increase) and a 0.36%\n(27.0%) increase overall. Indeed, calculating the websites\nwith the most machine-generated content, we again observe\nin Tables 5 and 6 that the websites that had the largest\namounts of synthetic content were all fairly small or unpop-\nular small.\nTopics Addressed by Synthetic Articles. While misinfor-\nmation websites and less popular websites have seen the\nlargest increase in the use of synthetic articles, many reliable\nand large news websites also heavily use synthetic articles.\nHowever, as noted in Section 2, many reliable news sites\nhave acknowledged their use of these machine-generated ar-\nticles and utilize them in a benign manner. To understand\ndifferent websites\u2019 use of synthetic articles, in this section,Topic Odds Ratio Topic Odds Ratio\nEntertainment 0.68 Science 1.58\nBusiness 0.61 Sports 0.23\nHealth 2.06 Technology 0.21\nNation 0.77 World 1.56\nTable 7: Odds Ratio for the amounts of synthetic articles\nand human-written articles from misinformation websites\nfor each topic category.\nwe analyze the topics addressed by synthetic articles among\ndifferent types of websites and how this has changed be-\ntween January 2022 and May 2023.\nTo identify the topics within our identified set of machine-\ngenerated articles, we train a DeBERTa-based classifier to\nidentify the topic of an article based on its text. As training\ndata, we utilize the News Catcher Topic Labelled dataset,12\nwhich contains topic labels for 106,395 different articles\nas belonging to 8 different categories {Business, Entertain-\nment, Health, US/Nation, Science, Sports, Technology, and\nWorld}. We note while the original dataset only contained\nthe title of each article, the dataset also included the origi-\nnal URL. As such, using the method outlined in section 4,\nwe gather the set of articles listed in the dataset and sub-\nsequently train a DeBERTa-based classifier to correctly la-\nbel articles based on their content. We note that a signifi-\ncant portion of these URLs were not available; as a result,\nwe trained our model on a subset of 79,000 articles from\nthe original dataset, further removing articles that were less\nthan 1000 characters. Keeping out a 10% of this dataset as\na test dataset, upon training, we achieve a 0.819 F1score an\naverage of 0.819 precision across the eight categories. Once\ntrained, we finally categorize the topic of each of the 15.46\nmillion articles within our dataset.\nPlotting the proportion of each topic amongst synthetic ar-\nticles from misinformation websites, as seen in Figure 6a, a\nsignificant portion of synthetic articles from misinformation\n12https://www.kaggle.com/datasets/kotartemiy/topic-labeled-\nnews-dataset\n549\n2022-01-30 2022-03-31 2022-05-30 2022-07-29 2022-09-27 2022-11-26 2023-01-25 2023-03-260.00.20.40.60.81.0Misinfo. Websites- Topic ProportionsENTERTAINMENT\nBUSINESS\nHEALTH\nNATION\nSCIENCE\nSPORTS\nTECHNOLOGY\nWORLD(a) Misinfo Synthetic Topics\n2022-01-30 2022-03-31 2022-05-30 2022-07-29 2022-09-27 2022-11-26 2023-01-25 2023-03-260.00.20.40.60.81.0Main. Websites- Topic ProportionsENTERTAINMENT\nBUSINESS\nHEALTH\nNATION\nSCIENCE\nSPORTS\nTECHNOLOGY\nWORLD (b) Mainstream Synthetic Topics\nFigure 6: The plurality of synthetic articles from mainstream/reliable websites is related to the Business topic. In contrast, the\nmajority of synthetic articles from misinformation/unreliable websites are related to Entertainment.World affairs, and US/Nation\ncurrent events.\nTopic Odds Ratio Topic Odds Ratio\nEntertainment 0.59 Science 1.48\nBusiness 1.53 Sports 0.85\nHealth 0.89 Technology 0.66\nNation 1.14 World 0.80\nTable 8: Odds Ratio for the amounts of synthetic articles and\nhuman-written articles from mainstream websites for each\ntopic category.\nwebsites concerned World affairs, Nation/US -current events,\nScience, and Entertainment. For example, among our set of\nsynthetic articles from misinformation websites, we identify\na variety of articles about concerns about tensions between\nRussia and Ukraine, COVID-19 vaccines, and updates about\nthe love life of Ed Sheeran. Calculating the odds ratio be-\ntween the number of synthetic and human-written articles\nfor each of our topic categories, as seen in Table 7, among\nour selection of misinformation websites, relative to their\nown topic proportions, misinformation websites were most\nlikely to utilize synthetic articles for Health andScience\nrelated topics. This suggests that misinformation websites\nhave proportionally utilized synthetic articles for both mun-\ndane topics like Entertainment andmore serious topics such\nas Health (Peiser 2019).\nPlotting the proportion of each topic amongst synthetic\narticles from mainstream websites, as seen in Figure 6b, the\nplurality of synthetic articles concern Business. Indeed, as\ndiscussed previously, websites ranging from Bloomberg to\nReuters have utilized synthetic articles to give updates on\nfinancial markets (Figure 2). Furthermore, again calculating\nthe odds ratio between the number of synthetic and human-\nwritten articles for each of our topic categories, as seen in\nTable 8, among our set of mainstream websites, relative to\ntheir own topic proportions, mainstream websites are most\nlikely to utilize synthetic articles for Science andBusiness\ntopics. This again reinforces prior reporting about the use of\nsynthetic articles among mainstream websites.\nFinally, calculating the odds ratio (Table 9) between the\nrates of usage of synthetic articles per category between\nmainstream and misinformation websites, we further ob-\nserve that misinformation news and mainstream websites,Topic Odds Ratio Topic Odds Ratio\nEntertainment 2.96 Science 1.91\nBusiness 0.13 Sports 0.06\nHealth 1.67 Technology 0.11\nNation 1.02 World 2.75\nTable 9: Odds Ratio for the amounts of synthetic arti-\ncles between misinformation and mainstream websites for\neach topic category. As seen above, misinformation websites\nare more likely to have synthetic articles about Entertain-\nment, Health, Science, and World -related topics compared\nto mainstream websites. We observe similar proportions of\nUS/Nation topics between misinformation and mainstream\nwebsites.\nthroughout our period of study were more likely to utilize\nsynthetic articles on topics related to Entertainment, Health,\nandScience, and World affairs. In contrast, mainstream web-\nsites were more likely to utilize synthetic articles for Busi-\nness, Technology (very small proportion), and Sports. We\nobserve similar proportions of US/Nation topics between\nmisinformation and mainstream websites.\nEstimating the Impact of ChatGPT. As seen in the pre-\nvious sections, misinformation websites and less popu-\nlar websites saw the largest increases in the use of syn-\nthetic articles. In order to estimate how the introduction of\nChatGPT specifically may have affected the levels of syn-\nthetic content on news websites, we now utilize an ARIMA\nmodel (Zhang 2003) to perform an interrrupted-time-series\nanalysis. Namely, we examine whether there was a direct\njump in the number of synthetic articles above expecta-\ntion following the release of ChatGPT on November 30,\n2022 (OpenAI 2022).\nAs seen in Table 10, after the release of ChatGPT on\nNovember 30, 2022, we observe a noted jump (0.50%)\nabove expectation in the number of synthetic articles from\nmisinformation websites. Many of the popularity ranking\nbrackets of misinformation websites saw a statistically sig-\nnificant increase in the absolute percentage of their articles\nthat were synthetic, with misinformation websites in the\nRank>10M+ popularity bracket seeing the highest jump of\n550\nMisinformation Mainstream\nAbs. Trend Abs. TrendRank % Inc. % Inc. % Inc. % Inc.\nAll 0.50%\u2217\u2217\u22170.006%\u2217\u22170.04% 0.001%\nRk<10K 0.10%\u2217\u2217\u22170.004%\u2217\u2217\u22170.03% 0.003%\u2217\u2217\u2217\n10K<Rk<100K 0.10% 0.01% 0.03% 0.001%\n100K <Rk<1M 0.41%\u2217\u2217\u22170.007%\u22170.007% 0.0005%\n1M<Rk<10M 0.12% 0.006%\u22170.19%\u2217\u2217\u22170.002\u2217%\nRk>10M+ 1.68%\u2217\u2217\u22170.004% 0.79%\u2217\u2217\u22170.004%\u2217\u2217\u2217\n\u2217p < 0.05;\u2217\u2217p < 0.01;\u2217\u2217\u2217p < 0.001\nTable 10: Estimated absolute percentage increase immedi-\nately following the release of ChatGPT on November 30,\n2022, in machine-generated articles (determined using an\nARIMA-based interrupted time series analysis).\n1.68%. This was visually seen in Figure 5. We similarly ob-\nserve that websites in every popularity bracket except those\nwith Rank >10M+ saw the rate at which the percentage of\nsynthetic articles increases, also increase (i.e., increase in the\nrate of increase).\nWe further find that the groups of mainstream websites\nwith popularity ranks >1M saw a marked increase in syn-\nthetic articles immediately following the release of ChatGPT\non November 30, 2022. In addition, we observe a trend in-\ncrease for several mainstream website popularity brackets.\nCombined with our misinformation website results, this sug-\ngests that smaller, less popular, and otherwise less monitored\nwebsites were the ones that saw the biggest increase in syn-\nthetic articles following the release of ChatGPT. Indeed, the\nnumber of synthetic articles among allgroups of websites\nhas been increasing and was at its highest levels on May 1,\n2023 (Figure 5). We see this mirrored in the overall increase\nin the trend of mainstream websites\u2019 use of synthetic arti-\ncles (increase in the rate of increase) in Table 10. We note\nthat while this analysis is notcausal, it illustrates the notice-\nable increase in the percentage of synthetic articles among\nmisinformation websites immediately following the release\nof ChatGPT.\n6 Discussion and Conclusion\nIn this work, we implement a DeBERTa-based model to\nclassify 15.46 million articles from 3,074 news websites as\nhuman-written orsynthetic. We find that between January 1,\n2022, and May 1, 2023, the percentage of synthetic articles\nproduced by mainstream/reliable news increased by 57.3%\nwhile the percentage produced by misinformation/unreliable\nnews websites increased by 474%. Estimating the effect of\nChatGPT, we observe a noticeable jump in the percentage of\nsynthetic articles from misinformation websites and unpop-\nular mainstream news around its release. We now discuss\nseveral limitations and implications of this work.\nLimitations. We note that while we sampled our dataset\nfrom a large set of 3,074 news websites and gathered over\n15.46M articles, we did not gather articles from every news\nwebsite and focused on English-language media. As such,\nour results largely do not apply to non-English media. Sim-\nilarly, because we used pre-defined lists of misinformation\nwebsites, our work largely misses the probable existence ofnew misinformation websites that appeared since the launch\nof ChatGPT.\nBecause we take a conservative approach to our estima-\ntion of machine-generated/synthetic texts and due to our re-\nmoval of articles with characters lengths less than 1000 char-\nacters, the absolute numbers presented in this paper are only\nrough estimates of the percentage of articles on a given web-\nsite that are machine-generated. As illustrated by Sadasivan\net al. (2023), reliable detection of these short texts is near\nimpossible/largely impractical as large language models be-\ncome more complex. As shown by Sadasivan et al. (2023),\nas LLMs come to more closely match the distribution of\nwritten human language, the distinction between human-\nwritten and machine-generate texts disappears. As such, we\nnote that while we manage to create a somewhat reliable de-\ntector in this work for longer articles for several released and\npublic models, as more advanced and powerful models are\ndeveloped, effective detection will be more difficult. Simi-\nlarly, it has been shown that heavily human-edited machine-\ngenerated similarly are very difficult to detect as machine-\ngenerated (Mitchell et al. 2023) and in this work, we do not\nseek to detect these instances. As such, due to our conserva-\ntive approach, our absolute percentage estimates are likely\nunderestimates.\nFurthermore, due to the limitations of our approach\nin building a model to estimate the relative increase in\nmachine-generated texts on news websites, our models are\nnot universal classifiers for synthetic texts. Most newspapers\nand outlets (as of early 2023), are not trying to purpose-\nfully evade AI detectors. Our models, which were trained\non newspaper data from a given set of websites, are built for\na particular context and cannot serve to universally detect\nsynthetic texts.\nDetection of Machine-Generated Media. We find that by\ntraining on data from a wide variety of generative models,\nwe were able to outperform Open AI\u2019s released RoBERTa\ndetector as well as several other released detectors (Pu et al.\n2023). Furthermore, we find, as in prior works (Gagiano\net al. 2021; Pu et al. 2023), that including data from com-\nmon attacks can increase overall detection accuracy. We ar-\ngue that future detectors applied to real-world data should\naccount for these techniques.\nSmall Websites and Synthetic Articles. As seen through-\nout this work, while larger more popular websites have been\nslower to adopt the use of AI-generated and synthetic con-\ntent, smaller less popular websites in particular have shown\nthe greatest relative increase in the use of synthetic (736%\nincrease among the least popular misinformation websites\nand 423% increase among the least popular mainstream\nwebsites). We thus find that to fully understand the in-\nfluence of synthetic media, as similarly argued by News\nGuard (Sadeghi and Arvanitis 2023), researchers must doc-\nument and study these less popular websites rather than just\nconcentrating on the top and most frequently visited do-\nmains.\nThe Rise of Synthetic Misinformation. We found that\nthroughout 2022 and 2023, as LLMs became more widely\naccessible, the percentage of machine-generated content on\n551\nmisinformation sites had a 474% relative increase. While at\nthe beginning of 2022, a lower percentage of misinforma-\ntion/unreliable news websites\u2019 content was synthetic (0.39%\nvs. 0.88%), we find that by May 2023, across all popularity\nbrackets examined, misinformation websites had closed this\ngap (2.22% vs. 1.39%). Unlike popular mainstream web-\nsites, misinformation websites and unpopular mainstream\nwebsites experienced a noticeable jump in synthetic con-\ntent after the release of ChatGPT (as determined by our\ninterrupted-time-series analysis). Furthermore, as shown by\nour topic analysis, misinformation websites have utilized\nthese synthetic articles to address world affairs and health-\nrelated news more often than mainstream websites. While\nnot every article posted on an unreliable/misinformation\nnews website is necessarily misinformation, the rapid adop-\ntion of synthetic methods by misinformation websites for ar-\nticles addressing world affairs and health news by these web-\nsites could have downstream negative effects. As such given\nthe rapid adoption of the use of synthetic articles by mis-\ninformation and unpopular websites, in particular, we argue\nfor future studies of how misinformation websites have uti-\nlized these technologies and how the content of these types\nof articles spread to social media and the broader Internet.\nReferences\nAcar, G.; Eubank, C.; Englehardt, S.; Juarez, M.;\nNarayanan, A.; and Diaz, C. 2014. The Web Never For-\ngets: Persistent Tracking Mechanisms in the Wild. In ACM\nConference on Computer and Communications Security.\nAI, O. 2022. ChatGPT: Optimizing Language Models\nfor Dialogue. http://web.archive.org/web/20230109000707/\nhttps://openai.com/blog/chatgpt/. Accessed: 2023-05-01.\nAlba, D. 2023. AI Chatbots Have Been Used to Cre-\nate Dozens of News Content Farms - Bloomberg.\nhttps://www.bloomberg.com/news/articles/2023-05-01/ai-\nchatbots-have-been-used-to-create-dozens-of-news-\ncontent-farms. Accessed: 2023-05-01.\nBarret Golding. 2022. Iffy Index of Unreliable Sources.\nhttps://iffy.news/index/. Accessed: 2023-05-01.\nBrown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; et al. 2020. Language models are few-shot learners. Ad-\nvances in neural information processing systems, 33.\nChen, P.-J.; Lee, A.; Wang, C.; Goyal, N.; Fan, A.;\nWilliamson, M.; and Gu, J. 2020. Facebook AI\u2019s WMT20\nNews Translation Task Submission. In Proceedings of the\nFifth Conference on Machine Translation, 113\u2013125.\nChowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\nG.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\nGehrmann, S.; et al. 2023. Palm: Scaling language model-\ning with pathways. Journal of Machine Learning Research ,\n24(240): 1\u2013113.\nConneau, A.; and Lample, G. 2019. Cross-lingual language\nmodel pretraining. Advances in neural information process-\ning systems, 32.\nCorney, D.; Albakour, D.; Martinez, M.; and Moussa, S.\n2016. What do a Million News Articles Look like? InProceedings of the First International Workshop on Re-\ncent Trends in News Information Retrieval co-located with\n38th European Conference on Information Retrieval (ECIR\n2016), Padua, Italy, March 20, 2016., 42\u201347.\nDai, Z.; Yang, Z.; Yang, Y .; Carbonell, J. G.; Le, Q.; and\nSalakhutdinov, R. 2019. Transformer-XL: Attentive Lan-\nguage Models beyond a Fixed-Length Context. In 57th An-\nnual Meeting of the Assoc. for Computational Linguistics.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In Conference of the North Amer-\nican Chapter of the Association for Computational Linguis-\ntics: Human Language Technologies.\nEmily R. Lowe and Katrina Slack. 2022. Data Scraping\nDeemed Legal in Certain Circumstances. https://www.\nmorganlewis.com/blogs/sourcingatmorganlewis/2022/04/\ndata-scraping-deemed-legal-in-certain-circumstances.\nAccessed: 2023-05-01.\nGagiano, R.; Kim, M. M.-H.; Zhang, X. J.; and Biggs, J.\n2021. Robustness analysis of grover for machine-generated\nnews detection. In 19th Annual Workshop of the Aus-\ntralasian Language Technology Association.\nGehrmann, S.; Strobelt, H.; and Rush, A. M. 2019. GLTR:\nStatistical Detection and Visualization of Generated Text.\nInProceedings of the 57th Annual Meeting of the Associa-\ntion for Computational Linguistics: System Demonstrations ,\n111\u2013116.\nHanley, H. W.; Kumar, D.; and Durumeric, Z. 2023. A\nGolden Age: Conspiracy Theories\u2019 Relationship with Mis-\ninformation Outlets, News Media, and the Wider Internet.\nACM Computer-Supported Cooperative Work And Social\nComputing.\nHe, P.; Liu, X.; Gao, J.; and Chen, W. 2021. DeBERTa:\nDecoding-enhanced BERT with disentangled attention. In\nInternational Conference on Learning Representations.\nHe, X.; Shen, X.; Chen, Z.; Backes, M.; and Zhang, Y . 2023.\nMGTBench: Benchmarking Machine-Generated Text De-\ntection. arXiv preprint arXiv:2303.14822.\nHounsel, A.; Holland, J.; Kaiser, B.; Borgolte, K.; Feamster,\nN.; and Mayer, J. 2020. Identifying Disinformation Websites\nUsing Infrastructure Features. In USENIX Workshop on Free\nand Open Communications on the Internet.\nHu, K. 2023. ChatGPT sets record for fastest-growing user\nbase - analyst note \u2014 Reuters. Accessed: 2023-05-01.\nIppolito, D.; Duckworth, D.; Callison-Burch, C.; and Eck,\nD. 2020. Automatic Detection of Generated Text is Easiest\nwhen Humans are Fooled. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics.\nJack, C. 2017. Lexicon of lies: Terms for problematic infor-\nmation. Data & Society, 3(22): 1094\u20131096.\nKeskar, N. S.; McCann, B.; Varshney, L. R.; Xiong, C.;\nand Socher, R. 2019. Ctrl: A conditional transformer lan-\nguage model for controllable generation. arXiv preprint\narXiv:1909.05858.\nKirchner, J. H.; Ahmad, L.; Aaronson, S.; and Leike, J.\n2023. New AI classifier for indicating AI-written text. Ope-\nnAI blog.\n552\nKrishna, K.; Song, Y .; Karpinska, M.; Wieting, J.; and Iyyer,\nM. 2024. Paraphrasing evades detectors of ai-generated text,\nbut retrieval is an effective defense. Advances in Neural In-\nformation Processing Systems, 36.\nLeffer, L. 2023. CNET\u2019s AI-Written Articles Are Riddled\nWith Errors. https://gizmodo.com/cnet-ai-chatgpt-news-\nrobot-1849996151. Accessed: 2023-05-01.\nLin, S.; Hilton, J.; and Evans, O. 2022. TruthfulQA: Measur-\ning How Models Mimic Human Falsehoods. In 60th Annual\nMeeting of the Assoc. for Computational Linguistics.\nLiu, Y .; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;\nLevy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V .\n2019. Roberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nMitchell, E.; Lee, Y .; Khazatsky, A.; Manning, C. D.; and\nFinn, C. 2023. Detectgpt: Zero-shot machine-generated text\ndetection using probability curvature. In International Con-\nference on Machine Learning, 24950\u201324962. PMLR.\nNg, N.; Yee, K.; Baevski, A.; Ott, M.; Auli, M.; and Edunov,\nS. 2019. Facebook FAIR\u2019s WMT19 News Translation Task\nSubmission. In Fourth Conference on Machine Translation.\nOpenAI. 2022. Introducing ChatGPT. https://openai.com/\nblog/chatgpt. Accessed: 2023-05-01.\nPeiser, J. 2019. The Rise of the Robot Reporter -\nThe New York Times. https://www.nytimes.com/2019/\n02/05/business/media/artificial-intelligence-journalism-\nrobots.html. Accessed: 2023-05-01.\nPu, J.; Sarwar, Z.; Abdullah, S. M.; Rehman, A.; Kim, Y .;\nBhattacharya, P.; Javed, M.; and Viswanath, B. 2023. Deep-\nfake text detection: Limitations and opportunities. In 2023\nIEEE Symposium on Security and Privacy (SP), 1613\u20131630.\nIEEE.\nRadford, A.; Narasimhan, K.; Salimans, T.; and Sutskever,\nI. 2019a. Improving Language Understanding by Genera-\ntive Pre-Training. https://cdn.openai.com/research-covers/\nlanguage-unsupervised/language understanding paper.pdf.\nRadford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.;\nSutskever, I.; et al. 2019b. Language models are unsuper-\nvised multitask learners. OpenAI blog, 1(8): 9.\nRaffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.;\nMatena, M.; Zhou, Y .; Li, W.; and Liu, P. J. 2020. Explor-\ning the limits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research, 21(1).\nRuth, K.; Kumar, D.; Wang, B.; Valenta, L.; and Durumeric,\nZ. 2022. Toppling top lists: Evaluating the accuracy of popu-\nlar website lists. In ACM Internet Measurement Conference.\nSadasivan, V . S.; Kumar, A.; Balasubramanian, S.; Wang,\nW.; and Feizi, S. 2023. Can AI-Generated Text be Reliably\nDetected? arXiv preprint arXiv:2303.11156.\nSadeghi, M.; and Arvanitis, L. 2023. Rise of the\nNewsbots: AI-Generated News Websites Proliferating\nOnline. https://www.newsguardtech.com/special-reports/\nnewsbots-ai-generated-news-websites-proliferating/. Ac-\ncessed: 2023-05-01.Schappert, S. 2023. Twitter blocks non-users.\nhttps://cybernews.com/news/twitter-blocks-non-users-\nreading-tweets-ai-scraping/. Accessed: 2023-05-01.\nSingrodia, V .; Mitra, A.; and Paul, S. 2019. A review on web\nscrapping and its applications. In 2019 international confer-\nence on computer communication and informatics (ICCCI) ,\n1\u20136. IEEE.\nSmith, J. R.; Saint-Amand, H.; Plamada, M.; Koehn, P.;\nCallison-Burch, C.; and Lopez, A. 2013. Dirt cheap web-\nscale parallel text from the common crawl. Association for\nComputational Linguistics.\nSolaiman, I.; Brundage, M.; Clark, J.; Askell, A.; Herbert-\nV oss, A.; Wu, J.; Radford, A.; Krueger, G.; Kim, J. W.;\nKreps, S.; et al. 2019. Release strategies and the social im-\npacts of language models. arXiv preprint arXiv:1908.09203.\nSzpakowski, M. 2020. Fake News Corpus. https://github.\ncom/several27/FakeNewsCorpus/. Accessed: 2023-05-01.\nTang, R.; Chuang, Y .-N.; and Hu, X. 2023. The sci-\nence of detecting llm-generated texts. arXiv preprint\narXiv:2303.07205.\nUchendu, A.; Le, T.; Shu, K.; and Lee, D. 2020. Authorship\nattribution for neural text generation. In Conference on Em-\npirical Methods in Natural Language Processing (EMNLP) .\nUchendu, A.; Ma, Z.; Le, T.; Zhang, R.; and Lee, D. 2021.\nTURINGBENCH: A Benchmark Environment for Turing\nTest in the Age of Neural Text Generation. In Findings of\nthe Association for Computational Linguistics: EMNLP.\nVeselovsky, V .; Ribeiro, M. H.; and West, R. 2023. Artificial\nArtificial Artificial Intelligence: Crowd Workers Widely Use\nLarge Language Models for Text Production Tasks. arXiv\npreprint arXiv:2306.07899.\nYang, Z.; Dai, Z.; Yang, Y .; Carbonell, J.; Salakhutdinov,\nR. R.; and Le, Q. V . 2019. Xlnet: Generalized autoregressive\npretraining for language understanding. Advances in neural\ninformation processing systems, 32.\nZellers, R.; Holtzman, A.; Rashkin, H.; Bisk, Y .; Farhadi,\nA.; Roesner, F.; and Choi, Y . 2019. Defending Against Neu-\nral Fake News. Advances in Neural Information Processing\nSystems, 32.\nZhang, G. P. 2003. Time series forecasting using a hybrid\nARIMA and neural network model. Neurocomputing, 50.\nZhong, W.; Tang, D.; Xu, Z.; Wang, R.; Duan, N.; Zhou,\nM.; Wang, J.; and Yin, J. 2020. Neural Deepfake Detection\nwith Factual Structure of Text. In Conference on Empirical\nMethods in Natural Language Processing (EMNLP).\nPaper Checklist\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying dis-\nrespect to societies or cultures? Yes, our work largely\nfocuses on uncovering the rate of usage of synthetic\n553\narticles. Our work does not invade the privacy of indi-\nviduals, collects only public data, and does not focus\non any particular culture.\n(b) Do your main claims in the abstract and introduction\naccurately reflect the paper\u2019s contributions and scope?\nYes. Our abstract is largely reflective of our work.\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes. Given\nour need to understand the use of synthetic articles\non news websites, in Section 3 we outline how our\nmethodology precisely identifies synthetic articles.\n(d) Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? Yes, we\nnote that specific data peculiar to given websites may\nbe part of the data collected. We note that this data is\nall public, however, and does not reveal the personal\ndata of any given individual.\n(e) Did you describe the limitations of your work? Yes,\nand we detail them in the Discussion.\n(f) Did you discuss any potential negative societal im-\npacts of your work? No, we do not believe that there\nare any immediate negative social repercussions\n(g) Did you discuss any potential misuse of your work?\nNo; our work seeks to detect synthetic articles at a\nlarge scale. While potentially our system could be uti-\nlized to overly penalize those that publish synthetic\narticles, we have noted in our work that we focus on\ntrends in the use of synthetic articles, not on predict-\ning whether any specific article is synthetic\n(h) Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, re-\nsponsible release, access control, and the reproducibil-\nity of findings? Yes, for the articles scraped we only\nrelease their URLs and not their texts. We also release\nour model to GitHub to allow for reproducibility.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes and we\nhave made sure that it is clear.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all\ntheoretical results? Yes, and where appropriate we\nhave interpreted what these results mean.\n(b) Have you provided justifications for all theoretical re-\nsults? NA\n(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? NA\n(d) Have you considered alternative mechanisms or ex-\nplanations that might account for the same outcomes\nobserved in your study? Yes, in our limitations sec-\ntion, we discuss several alternative explanations for\nour data.\n(e) Did you address potential biases or limitations in your\ntheoretical framework? Yes, we addressed the poten-\ntial biases and limitations of our classifier in Section 4.(f) Have you related your theoretical results to the existing\nliterature in social science? Yes, see Section 2.\n(g) Did you discuss the implications of your theoretical re-\nsults for policy, practice, or further research in the so-\ncial science domain? Yes, we discussed how research\nshould inform future AI detection systems and dis-\ncussed the need to understand the growth of websites\nthat primarily publish synthetic data.\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? NA\n(b) Did you include complete proofs of all theoretical re-\nsults? NA\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-\nther in the supplemental material or as a URL)? Yes,\nwe have included a GitHub link.\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? Yes, we\nhave outlined these details in Section 3.\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nYes, we benchmark and test our models across mul-\ntiple datasets to better indicate the robustness of our\nresults. We further include error bars for our results.\n(d) Did you include the total amount of compute and\nthe type of resources used (e.g., type of GPUs, inter-\nnal cluster, or cloud provider)? Yes, we have outlined\nthese details in Section 3\n(e) Do you justify how the proposed evaluation is suffi-\ncient and appropriate to the claims made? Yes, we have\noutlined these details in Section 3.\n(f) Do you discuss what is \u201cthe cost\u201c of misclassification\nand fault (in)tolerance? Yes, we have outlined these\ndetails in Section 3.\n5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets...\n(a) If your work uses existing assets, did you cite the cre-\nators? Yes, we have cited Pu et. al\u2019s work (Pu et al.\n2023).\n(b) Did you mention the license of the assets? NA\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? Yes, we have included a GitHub\nlink to the URLs used in this project.\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you\u2019re using/curating?\nYes, we have cited Pu et. al\u2019s work (Pu et al. 2023) and\noutlined how we have obtained data from them.\n(e) Did you discuss whether the data you are using/cu-\nrating contains personally identifiable information or\noffensive content? NA\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR?\nYes, our dataset is findable, accessible, interoperable,\n554\nand reusable as we post in on GitHub and it consists of\na list of URLs.\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset? Yes, we outline in\nour GitHub page which domains are included within\nour dataset, (the methodology for collection is listed\nin the paper), and we document how it is supposed to\nbe used. We note that our dataset just consists of a list\nof URLs as we do not release the news article contents.\n6. Additionally, if you used crowdsourcing or conducted re-\nsearch with human subjects...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? NA\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? NA\n(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? NA\n(d) Did you discuss how data is stored, shared, and dei-\ndentified? NA\n555\nTuring Benchmark GPT-3.5 GPT-3.5 w/ Pert GPT-3.5 w/ Para Article Forger AI Writer Avg.\nF1 Prec. Recall F1 Prec. Recall F1 Prec. Recall F1 Prec. Recall F1 Prec. Recall F1 Prec. Recall F1\nOpenAI Roberta 0.717 0.997 0.560 0.092 0.684 0.049 0.022 0.375 0.011 0.309 0.950 0.185 0.750 1.000 0.600 0.881 1.000 0.787 0.462\nBERT 0.988 0.998 0.978 0.941 0.911 0.973 0.901 0.905 0.898 0.931 0.889 0.976 0.855 0.809 0.905 0.779 0.929 0.670 0.899\nBERT+ Pert. 0.995 0.992 0.998 0.898 0.817 0.996 0.896 0.816 0.992 0.872 0.777 0.995 0.808 0.681 0.994 0.892 0.771 0.995 0.894\nBERT + Para. 0.995 0.992 0.998 0.937 0.896 0.981 0.915 0.892 0.939 0.930 0.822 0.995 0.839 0.763 0.931 0.856 0.888 0.826 0.912\nBERT+Pert.+Para. 0.995 0.994 0.997 0.939 0.897 0.985 0.937 0.896 0.981 0.925 0.871 0.985 0.854 0.903 0.913 0.809 0.909 0.729 0.910\nRoBERTa 0.998 0.997 0.998 0.956 0.929 0.985 0.952 0.928 0.977 0.949 0.911 0.990 0.856 0.857 0.872 0.951 0.933 0.971 0.943\nRoBERTa + Pert. 0.993 1.000 0.986 0.979 0.981 0.977 0.975 0.981 0.977 0.968 0.975 0.961 0.748 0.977 0.606 0.820 0.997 0.696 0.914\nRoBERTa + Para 0.998 0.998 0.998 0.940 0.902 0.981 0.932 0.901 0.966 0.934 0.880 0.995 0.903 0.849 0.965 0.958 0.927 0.991 0.944\nRoBERTa+Pert.+Para. 0.995 0.991 0.999 0.956 0.923 0.992 0.960 0.923 1.000 0.947 0.903 0.995 0.912 0.859 0.972 0.951 0.913 0.991 0.954\nDeBERTa 0.995 0.997 0.993 0.961 0.935 0.989 0.952 0.934 0.970 0.958 0.920 1.000 0.959 0.951 0.968 0.986 0.982 0.989 0.969\nDeBERTa + Pert. 0.996 0.995 0.996 0.943 0.895 0.996 0.945 0.895 1.000 0.930 0.869 1.000 0.956 0.927 0.987 0.985 0.975 0.996 0.959\nDeBERTa + Para. 0.996 0.993 0.999 0.941 0.892 0.996 0.943 0.892 1.000 0.928 0.866 1.000 0.965 0.940 0.991 0.983 0.967 1.000 0.959\nDeBERTa+Pert.+Para. 0.995 0.994 0.996 0.970 0.949 0.992 0.972 0.949 0.996 0.967 0.936 1.000 0.968 0.948 0.989 0.990 0.979 1.000 0.977\nTable 11: Binary F1-Score/Precision/Recall of our models on various benchmarks (machine-generated/synthetic being posi-\ntive). We bold the best score in each column. As seen, our set of DeBERTa models performs the best across many of the test\ndatasets, with DeBERTa+Pert+Para having the highest average F-1 score across all six datasets.\nA Performance of Classifiers\n556", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Machine-made media: Monitoring the mobilization of machine-generated articles on misinformation and mainstream news websites", "author": ["HWA Hanley", "Z Durumeric"], "pub_year": "2024", "venue": "\u2026 of the international AAAI conference on \u2026", "abstract": "As large language models (LLMs) like ChatGPT have gained traction, an increasing number  of news websites have begun utilizing them to generate articles. However, not only can"}, "filled": false, "gsrank": 123, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/31333", "author_id": ["ewdWfOoAAAAJ", "TxPSRHIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ryLkayQURykJ:scholar.google.com/&output=cite&scirp=122&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D120%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ryLkayQURykJ&ei=GrWsaJ6pKcDZieoPqdqh8QU&json=", "num_citations": 53, "citedby_url": "/scholar?cites=2974368225562993327&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ryLkayQURykJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/31333/33493"}}, {"title": "Can Community Notes Replace Professional Fact-Checkers?", "year": "2025", "pdf_data": "Can Community Notes Replace Professional Fact-Checkers?\nNadav Borenstein\u2217Greta Warren\u2217Desmond Elliott Isabelle Augenstein\nUniversity of Copenhagen\nnb@di.ku.dk grwa@di.ku.dk\nde@di.ku.dk augenstein@di.ku.dk\nAbstract\nTwo commonly employed strategies to combat\nthe rise of misinformation on social media are\n(i) fact-checking by professional organisations\nand (ii) community moderation by platform\nusers. Policy changes by Twitter/X and, more\nrecently, Meta, signal a shift away from part-\nnerships with fact-checking organisations and\ntowards an increased reliance on crowdsourced\ncommunity notes. However, the extent and\nnature of dependencies between fact-checking\nandhelpful community notes remain unclear.\nTo address these questions, we use language\nmodels to annotate a large corpus of Twitter/X\ncommunity notes with attributes such as topic,\ncited sources, and whether they refute claims\ntied to broader misinformation narratives. Our\nanalysis reveals that community notes cite fact-\nchecking sources up to five times more than pre-\nviously reported. Fact-checking is especially\ncrucial for notes on posts linked to broader\nnarratives, which are twice as likely to refer-\nence fact-checking sources compared to other\nsources. Our results show that successful com-\nmunity moderation relies on professional fact-\nchecking and highlight how citizen and profes-\nsional fact-checking are deeply intertwined.\n1 Introduction\nThe proliferation of misinformation on social me-\ndia (Arnold, 2020; Diakopoulos, 2020), along with\nthe rise of generative AI (Augenstein et al., 2024)\nhave led to increasing concerns about people\u2019s\nability to access trustworthy and credible informa-\ntion, leading to potential harms to public health\n(Clemente et al., 2022), democracy, and political\nstability (Reglitz, 2022). Fact-checkers play a cru-\ncial role in combatting misinformation (Graves,\n2017), and in recent years, have partnered with so-\ncial media platforms, e.g., Meta, YouTube, and\n* Equal contribution.\nFigure 1: An example of a community note. Notice the\nfact-checking link and rating.\nTikTok, to tackle its spread on these platforms.\nHowever, due to the scale of misleading content\nshared online, community moderation (e.g., op-\ntions to flag potential misinformation, group/server\nmoderators) is often employed in parallel (Morrow\net al., 2022), as a complementary approach (e.g.,\n(Google, 2025; TikTok, 2025); see also the practice\nofsnoping (Pilarski et al., 2024)). The expansion of\nfact-checking projects in the last decade (Lauer and\nGraves, 2024), alongside their broader initiatives\nto curb misinformation (e.g., citizen media literacy\nprogrammes (Juneja and Mitra, 2022)) have been\naided by partnerships with social media platforms\nsuch as Meta and Google (Graves and Anderson,\n2020), which fund independent fact-checking agen-\ncies to fact-check potentially false claims on their\nplatform.1However, political pressure and accu-\nsations of bias and censorship, and most recently,\nMeta\u2019s announcement of its plans to end its part-\nnerships with fact-checkers in the U.S. and imple-\nment a community moderation model (Meta, 2025),\nthreatens the financial stability of fact-checking or-\nganisations, and hence, their ability to keep up\nwith the increasing volume and sophistication of\n1Fact-checkers provide a judgment of claim veracity and\nexert no influence on the platforms\u2019 content moderation poli-\ncies (Catalanello and Sanders, 2025).arXiv:2502.14132v2  [cs.CL]  27 May 2025\nmisinformation spread (Stencel et al., 2024; IFCN,\n2024).\nMeta\u2019s recent policy shift also implies that these\ntwo strategies (fact-checking and community notes)\nare independent and in opposition, rather than two\ncomplementary strategies of tackling online mis-\ninformation. In this paper, we examine Twitter/X\ncommunity notes as a case study to understand how\nfact-checking is used in community notes . Specifi-\ncally, we investigate the following two questions:\n(RQ1) To what extent do community notes rely\non the work of professional fact-checkers? and\n(RQ2) What are the traits of posts and notes\nthat rely on fact-checking sources? Studying\nthe relationship between fact-checking and com-\nmunity notes is vital for understanding the shared\nrole of expert and citizen-driven fact-checking in\nthe global information ecosystem.\nWe find that at least 1 in 20 community notes rely\nexplicitly on the work of professional fact-checkers,\nwhile this reliance is higher still for high-stakes top-\nics such as health and politics. Our experiments\nalso show that fact-checking is vital for debunk-\ning misleading content linked to broader narratives\nor conspiracy theories. These findings imply that\nhigh-quality community notes cannot be produced\nindependently of professional fact-checking. They\nfurther suggest that the pressure on fact-checkers\nexerted by platforms and politicians by defunding\nand discrediting fact-checking organisations will\nhave corrosive effects on the quality of notes and\ndestructive implications for information integrity\nmore widely.\n2 Background\nDue to space constraints, only the most relevant\nrelated work is provided here. Additional relevant\nstudies and background can be found in App. A.\n2.1 Community notes\nCommunity moderation has been proposed as a\nmeans of addressing the scalability (Martel et al.,\n2024) and cross-partisanship trust (Flamini, 2019)\nchallenges associated with fact-checking. Twit-\nter/X\u2019s Community Notes programme (piloted in\n2021 and publicly launched in October 2022 (Twit-\nter/X, 2021)) is a notable example of such a system.\nAny platform user may volunteer as a Community\nNotes contributor, although they must achieve a\nparticular \u2018rating impact score\u2019 before they can\nwrite notes (Twitter/X, 2024b). Notes that achievea \u2018helpful\u2019 rating appear underneath the post, ex-\nplaining why the post is misleading (see Fig. 1).\nTo be rated \u2018helpful\u2019, a note must receive similar\nlevels of helpfulness rating from users with diverse\nviewpoints (Twitter/X, 2024a).\n2.1.1 Characteristics of Community Notes\nA small but growing body of work has analysed\nTwitter/X\u2019s Community Notes dataset, focusing on\nthe targets, sources, and limitations of notes.\nTargets of notes. Community notes tend to focus\non misleading posts from large accounts (Pilarski\net al., 2024), focusing on posts that lack impor-\ntant content or present unverified claims as facts\n(Pr\u00f6llochs, 2022; Drolsbach and Pr\u00f6llochs, 2023).\nSources in notes. Analyses have showed that notes\nwere rated more helpful if they link to \u2018trustworthy\u2019\nsources and that the majority of sources cited by\nnotes were \u2018trustworthy\u2019 left-leaning news outlets\n(Pr\u00f6llochs, 2022). A recent study finds that 55%\nof URLs used in notes were related to news web-\nsites, 18% to research, 9% to social media, 9% to\nencyclopedic sources, but just 1% to fact-checking\nsources (Kangur et al., 2024).\nLimitations of notes. Only 11% of submitted\nnotes reach \u2018helpful\u2019 status (i.e., shown to users)\nby achieving a cross-perspective (Renault et al.,\n2024; Wirtschafter and Majumder, 2023), and the\ntime frame for notes to reach the algorithm\u2019s re-\nquired agreement level (15.5 hours on average)\nlimits its capacity to halt misinformation spread\n(Renault et al., 2024). Posts related to partisan is-\nsues are particularly affected by these challenges\n(Allen et al., 2022). Additional concerns about the\nnotes\u2019 efficacy highlight their indifference to the\nexpertise needed for certain claims and reliance on\nsubjective helpfulness rather than objective facts,\nfree labour and inadequate support and guardrails\nregarding explicit content (Gilbert, 2025).\nOur work provides novel insights into the tar-\ngets, sources and limitations of community notes\nby shedding light on the relationship between notes\nand professional fact-checking. Closest to our work\nis a recent analysis of community notes written\nin 2024 by the fact-checking organisation Maldita\n(2025), who also studied the reliance of community\nnotes on professional fact-checkers. They discover\nthat fact-checking organisations are widely used as\na reference by notes\u2019 authors. The current work\nprovides a more fine-grained analysis by studying\nthe extent to which fact-checking sources form the\nbasis of note-writers\u2019 efforts to counter misinfor-\nmation and identifying the strategies they employ.\n3 Dataset\nWe download files containing all community notes\nand their metadata from the official website,2which\namounts to 1.5M notes authored between January\n28th 2021 and January 6th 2025. Of these, a total of\n135K are rated by the community as \u2018Helpful\u2019, 51K\nare rated \u2018Not helpful\u2019, and 1.3M are unpublished,\ni.e., did not receive enough community ratings to\nreach a verdict. See Fig. 6 in App. B for statistics.\nWe filter the notes as follows. First, we re-\nmove 526K non-English notes, which we identify\nby applying the language detection library fast-\nlangdetect.3Then, we further filter 268K \u2018unnec-\nessary\u2019 notes\u2014notes attached to tweets that are\nclassified by the community as \u2018not misleading\u2019.\nFinally, to focus only on notes that are used to ad-\ndress misinformation, we filter out 44K notes that\ncontain one of the words \u2018ad\u2019, \u2018spam\u2019, or \u2018phish-\ning\u2019. Following these filtration steps, we are left\nwith a dataset containing 664K notes.\nThe next step involves categorising the sources\nthat the note authors use to support their claims.\nFirst, we use regex to extract all the URLs found\nin the notes. Importantly, a single note can include\nmultiple external URLs as evidence. See Tab. 2\nin App. B for a list of the top-100 most common\ndomains. We classify each URL in our dataset of\n664K notes into one of 13 categories (detailed in\nFig. 2) using the pipeline described below.\n1.Check whether the domain name of the URL\nis found in a manually curated list of domains\nof professional fact-checking organisations\n(See Tab. 3 in App. B for the full list). If\nso, classify the URL as \u2018fact-checking\u2019.\n2.Otherwise, search for paraphrases of the word\n\u2018fact-check\u2019 in the URL,4and classify it as\n\u2018fact-checking\u2019 if a match was found.\n3.Otherwise, check whether the domain name\nis found in Tab. 2, which the authors of this\npaper manually annotated.\n4.Otherwise, use GPT-45to classify the domain\nname into one of the 13 categories. Listing 1\n2https://communitynotes.x.com/guide/e\nn/under-the-hood/download-data\n3https://github.com/LlmKira/fast-langd\netect\n4These URLs mostly link to the fact-checking divisions of\nnews outlets, e.g., https://apnews.com/article/f\nact-checking-909101991741 .\n5Version gpt-4o-2024-08-06 .in App. C details the prompt we used.\n5.Finally, if GPT-4 fails or outputs an unknown\ncategory, label the URL as \u2018unknown\u2019.\nUsing this pipeline, we successfully classify 95%\nof the URLs to one of the 13 categories.\nMoreover, we further subsample the notes for\nperforming the in-depth analysis required for an-\nswering RQ2 (\u00a74.2). From the notes rated as \u2018help-\nful\u2019, we sample 3.5K notes with a \u2018fact-checking\u2019\nsource and a random sample of 22K additional\nnotes. We then used web crawling to scrape the\ntext of the posts to which these notes were attached.\nWe name this subset Stextfor simplicity.\n4 Analysis\nWe analyse the dataset prepared in \u00a73 to answer the\ntwo research questions defined in \u00a71.\n4.1 RQ1: To what degree do community notes\nrely on fact-checkers?\nAccording to Fig. 2.a at least 5% of all English\ncommunity notes contain an external link to pro-\nfessional fact-checkers. This number grows to\n7% when only considering notes rated as \u2018help-\nful\u2019 (Fig. 2.b). Conversely, only 1% of notes rated\nas \u2018not helpful\u2019 contain a fact-checking source\n(Fig. 2.c). These figures are significantly larger\nthan what was reported in some previous studies\n(1.2% (Kangur et al., 2024)), possibly because Kan-\ngur et al. (2024) utilise a smaller dataset of fact-\nchecking agencies and classify fact-checking divi-\nsions of popular journals as \u2018news\u2019. The results im-\nply that notes incorporating fact-checking sources\nare generally considered more helpful.\nWe further assess whether notes with fact-\nchecking sources are perceived to be of higher\nquality by analysing individual user ratings of notes\nboth with and without such sources. Specifically,\nwe collect user ratings for a balanced (i.e., includ-\ning of a fact-checking source or not) sample of\n20K notes rated by at least 50 users, and calcu-\nlated the average ratings for the notes. As can be\nseen in Fig. 7 in App. B, community notes with\nfact-checking sources are generally rated higher\nthan their counterparts. Interestingly, while notes\nwith fact-checking links are more likely to be re-\ngarded as having a good source (higher HelpfulGo-\nodSources ), they are also more likely to be rated as\nnotHelpfulSourcesMissingOrUnreliable . Tab. 5 in\nApp. B contains a sample of such notes.\nFigure 2: The categories of links used by Community notes\u2019 authors as a source. a) all community notes; b)\nCommunity notes rated as \u2018helpful\u2019; c) community notes rated as \u2018unhelpful\u2019. Notice the \u2018fact-checking\u2019 category.\nFigure 3: Mean scores of community annotations of\nmisleading posts.\nFigure 4: (a) strategies in debunking claims related to\nbroader narratives. (b) the different ways in which fact-\nchecking sources are used to debunk claims.FC source\n\u2713 \u2717Conspi-\nracy\u2713 22% 11%\n\u2717 28% 39%\nTable 1: Percentage of samples related to a broader\nnarrative or conspiracy vs. have a fact-checking source.\n4.2 RQ2: What are the traits of posts and\nnotes that rely on fact-checking sources?\nWe begin by performing a topic analysis, com-\nparing topics of posts whose notes reference fact-\nchecking sources to those citing other sources. To\nthis end, we apply a strong zero-shot text clas-\nsification model6to our Stextsubset by classify-\ning spans of the form \u201c Tweet:<POST TEXT>;\nNote <NOTE TEXT> \u201d into one of 13 classes.\nThe authors manually evaluated the quality of the\nclassification results and considered it satisfactory,\nwith the model predicting the correct class in 90%\nof the cases. Most of the incorrect predictions in-\nvolved the \u2018technology\u2019 category, with sentences\nsuch as \u201c this is a fake image that was created with\nAI\u201d incorrectly labelled as \u2018technology\u2019. Notably\n(Fig. 5), fact-checking sources are more likely to\nbe included in posts related to high-stakes issues\nsuch as health, science, and scams and less likely\nto be included in posts on tech or sports.\nWe then analyse annotations (binary attributes\nexplaining the warrant for the note) by commu-\nnity note authors. Fig. 3 contains the full break-\ndown of annotations for notes with and without\nfact-checking sources. Notes containing a link to\n6https://huggingface.co/r-f/ModernBER\nT-large-zeroshot-v1 with default settings.\nfact-checking sources are overrepresented in posts\nwhere unverified information is presented as a fact\nor when the post contains a factual error. Con-\nversely, they are under-represented in posts with\noutdated information or satirical content. Tab. 4 in\nApp. B contains a sample of such notes.\nThese results indicate that community note-\nwriters adapt their strategies based on the stakes\nand scope of the claim, and the depth of research\nneeded to counter misinformation. We hypothesise\nthat they are more likely to rely on external fact-\nchecking when refuting complex or unverifiable\nclaims (Wuehrl et al., 2024), as well as claims re-\nlated to conspiracy theories7or broader narratives8\nwhich cannot be fully addressed in the scope of\na note. Conversely, claims involving misleading\nmedia can often be debunked with examples alone,\nmaking fact-checking sources unnecessary. To in-\nvestigate this hypothesis, the authors of this paper\nmanually annotated 400 <post, note >pairs from\nStextwith attributes related to the complexity of\nthe claims and how community notes address them.\n(see App. C.1 for annotation guidelines). The re-\nsults (Fig. 4.a) support our hypothesis. Claims re-\nlated to broader narratives or conspiracy theories9\nare much more likely to include a link to a fact-\nchecking source. In contrast, other types of claims\nare more likely to be addressed by providing miss-\ning context or by invalidating the credibility of the\nclaim\u2019s source. Additionally, Fig. 4.b depicts the\ndifferent ways in which fact-checking sources are\nused to debunk claims. It demonstrates how such\nsources are rarely used to provide missing context\nbut rather focus on discrediting sources of claims\nand providing scientific evidence.\nWe extend the manual annotation to an LLM-\nbased analysis of 8K balanced <post, note >pairs\nfromStext. We task OpenAI\u2019s GPT-410with deter-\nmining whether a pair relates to a broader narrative\nor a conspiracy theory. Listing 2 in App. C details\nthe prompt we used. To evaluate model accuracy,\ntwo authors independently labelled 100 balanced\npairs, achieving an agreement rate of 0.88and re-\nsolving disagreements through discussion. The\n7For example, the claim \u201cMichelle Obama is a male\u201d.\n8These are tweets that perpetuate broader misinformation\nnarratives but do not necessarily contain an explicit conspiracy\ntheory, e.g., the false claim \u201cmost immigrants remain firmly\ndependent on Welfare\u201d.\n9We condense broader narratives and conspiracy theories\ntogether for simplicity. Similar trends can be seen when they\nare analysed separately.\n10Version gpt-4o-2024-08-06 .\nFigure 5: Distribution of notes\u2019 topics, with and without\na fact-checking source.\nmodel attained an F1score of 0.85\u2014strong per-\nformance for this challenging task. The results\n(Tab. 1) support our hypothesis: <post, note >pairs\nrelated to a broader narrative or conspiracy theory\naretwice as likely to cite fact-checking sources\ncompared to other sources. In contrast, other pairs\nare nearly 30% less likely to do so. These findings\nalso highlight the prevalence of such claims and\nfurther underscore the importance of fact-checking\nin combating complex misinformation narratives.\n5 Conclusion\nIn this work, we annotate a large corpus of Twit-\nter community notes with attributes such as topic,\ncited sources, and whether they refute claims tied\nto broader misinformation narratives. We find that\neffective community moderation depends on pro-\nfessional fact-checking to an extent far greater than\npreviously reported. We find that community notes\nlinked to broader narratives or conspiracy theories\nare particularly reliant on fact-checking.\nOur results reveal that community notes\nand professional fact-checking are deeply\ninterconnected\u2014fact-checkers conduct in-depth\nresearch beyond the reach of amateur platform\nusers, while community notes publicise their work.\nThe move by platforms to end their partnerships\nand funding for fact-checking organisations will\nhinder their ability to fact-check and pursue\ninvestigative journalism, which community note\nwriters rely on. This, in turn, will limit the efficacy\nof community notes, especially for high-stakes\nclaims tied to broader narratives or conspiracies.\nLimitations\nThe main limitations of our work concern the char-\nacteristics of the dataset we analyse. First, we\nrestrict our analysis to notes written in English, ex-\ncluding over half a million notes in other languages.\nThis decision was made to avoid potential noise and\nbiases arising from the authors\u2019 unfamiliarity with\npublic discourse in different regions and reliance\non machine translation. In future work, we aim to\nextend our analysis to other languages.\nMoreover, except for a small subset of notes,\nwe did not have access to the original tweets they\nwere written for. Even when the tweet text was\navailable, many contained non-text media, were\nwritten in internet vernacular that was challenging\nto interpret, or lacked important context. These\nfactors limit the accuracy and effectiveness of our\nmodels and analysis.\nFinally, due to resource constraints, our manual\nannotation study was limited to a relatively small\nsample of tweets and notes. In future work, we\nwish to utilise crowd workers to not only annotate\na larger dataset but also increase the diversity and\nperspective of the annotators.\nBroader Impact and Ethical\nConsiderations\nCommunity notes have been proposed as a replace-\nment for professional fact-checkers and a salve to\nsome of the issues encountered by fact-checking.\nHowever, our findings support the view that neither\ncommunity notes nor professional fact-checkers\nalone are sufficient to combat the spread of misin-\nformation on social media. Rather, a combination\nof these two strategies could prove a much more\neffective approach to addressing the full range of\nfalse content shared online, for example, by lever-\naging community notes to identify new checkwor-\nthy claims for professional fact-checkers, or relying\non fact-checkers\u2019 expertise to resolve disputed un-\npublished notes (see Augenstein et al. (2025) for\nfurther recommendations in this vein). In particular,\nas discussed above, professional fact-checking or-\nganisations are especially vital for verifying claims\nrelated to broader narratives and conspiracy theo-\nries. Moreover, professional fact-checkers remain\nthe only viable strategy currently available for ad-\ndressing partisan issues, where community notes\nfall short. Finally, we highlight the potential for\nincorporating automated, human-in-the-loop fact-\nchecking models to assist professional and com-\nmunity fact-checkers alike in reckoning with vast\namounts of both human- and machine-generated\ncontent.\nGiven that this work analyses real-world posts,\nethical concerns may arise from using this datafor research purposes. Posts from non-protected\naccounts and Community Notes on Twitter/X are\npublicly available, however, we acknowledge that\nthey may contain sensitive personal information.\nTo minimise any breach of anonymity and privacy,\nwe anonymised links to individual accounts, and\nwe do not publicly release this information. We do\nnot analyse the posts or notes by individual users,\nand instead examine aggregated data in the form of\ntopics and sources cited.\nAlthough the Community Notes dataset rep-\nresents attempts to curb harmful misinformation\nand conspiracies, given the intense partisanship in-\nvolved (Allen et al., 2022; Draws et al., 2022), as\nwell as the explicit content of some claims, some\ninstances may be considered offensive. We also ac-\nknowledge that our own perspectives and biases as\nauthors shape the impact of our findings in certain\nways. For example, as mentioned in the previous\nsection, we were unable to analyse non-English\nposts in-depth, so our conclusions are likely some-\nwhat focused on discourse in the Anglosphere\n(e.g., the US, UK, Ireland, Canada, Australia, New\nZealand etc.). Furthermore, although we based our\ncriteria for conspiracy theories on well-established\nsources, e.g., AP News, FactCheck.org, the Eu-\nropean Commission, and identified conspiratorial\nnarratives from both left- and right-wing sources,\nour own perspectives (i.e., as scientists from West-\nern countries) may also have impacted what we\nconsidered to be conspiracy theories.\nAcknowledgements\nThis research was co-funded by the Euro-\npean Union (ERC, ExplainYourself, 101077481),\nby the European Union\u2019s Horizon 2020 research\nand innovation program under grant agreement No.\n101135671 (TrustLLM), and by the Pioneer Centre\nfor AI, DNRF grant number P1.\nReferences\nJennifer Allen, Cameron Martel, and David G. Rand.\n2022. Birds of a Feather Don\u2019t Fact-Check Each\nOther: Partisanship and the Evaluation of News in\nTwitter\u2019s Birdwatch Crowdsourced Fact-Checking\nProgram. In Proceedings of the 2022 CHI Confer-\nence on Human Factors in Computing Systems , CHI\n\u201922, New York, NY , USA. Association for Computing\nMachinery.\nPhoebe Arnold. 2020. The Challenges of Online Fact\nChecking: How Technology Can (and Can\u2019t) Help.\nTechnical report, Full Fact.\nIsabelle Augenstein, Michiel Bakker, Tanmoy\nChakraborty, David Corney, Emilio Ferrara, Iryna\nGurevych, Scott Hale, Eduard Hovy, Heng Ji, Irene\nLarraz, Filippo Menczer, Preslav Nakov, Paolo\nPapotti, Dhruv Sahnan, Greta Warren, and Giovanni\nZagni. 2025. Community moderation and the new\nepistemology of fact checking on social media.\nIsabelle Augenstein, Timothy Baldwin, Meeyoung Cha,\nTanmoy Chakraborty, Giovanni Luca Ciampaglia,\nDavid Corney, Renee DiResta, Emilio Ferrara, Scott\nHale, Alon Halevy, Eduard Hovy, Heng Ji, Filippo\nMenczer, Ruben Miguez, Preslav Nakov, Dietram\nScheufele, Shivam Sharma, and Giovanni Zagni.\n2024. Factuality Challenges in the Era of Large Lan-\nguage Models and Opportunities for Fact-Checking.\nNature Machine Intelligence , pages 1\u201312.\nRebecca Catalanello and Katie Sanders. 2025. Meta\nis Ending Its Third-Party Fact-Checking Partnership\nwith US Partners. Here\u2019s How That Program Works.\nYuwei Chuai, Moritz Pilarski, Gabriele Lenzini, and\nNicolas Pr\u00f6llochs. 2024a. Community Notes Reduce\nthe Spread of Misleading Posts on X.\nYuwei Chuai, Anastasia Sergeeva, Gabriele Lenzini, and\nNicolas Pr\u00f6llochs. 2024b. Community Fact-Checks\nTrigger Moral Outrage in Replies to Misleading Posts\non Social Media. ArXiv:2409.08829 [cs].\nYuwei Chuai, Haoye Tian, Nicolas Pr\u00f6llochs, and\nGabriele Lenzini. 2024c. Did the Roll-Out of Com-\nmunity Notes Reduce Engagement With Misinfor-\nmation on X/Twitter? Proceedings of the ACM on\nHuman-Computer Interaction , 8(CSCW2):1\u201352.\nSu\u00e1rez Vicente Javier Clemente, Eduardo Navarro-\nJim\u00e9nez, Juan Antonio Sim\u00f3n-Sanjurjo, Ana Isabel\nBeltran-Velasco, Carmen Cecilia Laborde-C\u00e1rdenas,\nJuan Camilo Benitez-Agudelo, \u00c1lvaro Bustamante-\nS\u00e1nchez, and Jos\u00e9 Francisco Tornero-Aguilera. 2022.\nMis\u2013Dis Information in COVID-19 Health Crisis: A\nNarrative Review. International Journal of Environ-\nmental Research and Public Health , 19(9).\nNicholas Diakopoulos. 2020. Computational News Dis-\ncovery: Towards Design Considerations for Editorial\nOrientation Algorithms in Journalism. Digital jour-\nnalism , 8(7):945\u2013967.\nTim Draws, David La Barbera, Michael Soprano, Kevin\nRoitero, Davide Ceolin, Alessandro Checco, and Ste-\nfano Mizzaro. 2022. The Effects of Crowd Worker\nBiases in Fact-Checking Tasks. In 2022 ACM Confer-\nence on Fairness, Accountability, and Transparency ,\npages 2114\u20132124, Seoul Republic of Korea. ACM.\nChiara Patricia Drolsbach and Nicolas Pr\u00f6llochs. 2023.\nDiffusion of Community Fact-Checked Misinforma-\ntion on Twitter. Proceedings of the ACM on Human-\nComputer Interaction , 7(CSCW2):1\u201322.\nChiara Patricia Drolsbach, Kirill Solovev, and Nicolas\nPr\u00f6llochs. 2024. Community Notes Increase Trust in\nFact-Checking on Social Media. PNAS Nexus .Daniela Flamini. 2019. Most Republicans Don\u2019t Trust\nFact-Checkers, and Most Americans Don\u2019t Trust the\nMedia.\nYang Gao, Maggie Zhang, and Huaxia Rui. 2024. Can\nCrowdchecking Curb Misinformation? Evidence\nfrom Community Notes.\nSarah Gilbert. 2025. Three Reasons Meta Will Struggle\nwith Community Fact-Checking. MIT Technology\nReview .\nGoogle. 2025. Misinformation Policies - Youtube Help.\nLucas Graves. 2017. Anatomy of a Fact Check: Ob-\njective Practice and the Contested Epistemology of\nFact Checking. Communication, culture & critique ,\n10(3):518\u2013537.\nLucas Graves and C.W. Anderson. 2020. Discipline\nand Promote: Building Infrastructure and Managing\nAlgorithms in a \u201cStructured Journalism\u201d Project by\nProfessional Fact-Checking Groups. New Media &\nSociety , 22(2):342\u2013360.\nJordyn Haime. 2022. Taiwan\u2019s Amateur Fact-Checkers\nWage War on Fake News from China.\nIFCN. 2024. State of the Fact-Checkers Report. Tech-\nnical report, International Fact-Checking Network.\nPrerna Juneja and Tanushree Mitra. 2022. Human\nand Technological Infrastructures of Fact-Checking.\nProc. ACM Hum.-Comput. Interact. , 6(CSCW2).\nUku Kangur, Roshni Chakraborty, and Rajesh Sharma.\n2024. Who Checks the Checkers? Exploring\nSource Credibility in Twitter\u2019s Community Notes.\nArXiv:2406.12444 [cs].\nSarawut Kankham and Jian-Ren Hou. 2024. Com-\nmunity Notes vs. Related Articles: Assessing Real-\nWorld Integrated Counter-Rumor Features in Re-\nsponse to Different Rumor Types on Social Media.\nInternational Journal of Human\u2013Computer Interac-\ntion, pages 1\u201315.\nLaurens Lauer and Lucas Graves. 2024. How to Grow\na Transnational Field: A Network Analysis of the\nGlobal Fact-Checking Movement. New Media &\nSociety , 0(0):19.\nMaldita. 2025. The Impact of Fact-Checkers in X\u2019s\nCommunity Notes.\nCameron Martel, Jennifer Allen, Gordon Pennycook,\nand David G. Rand. 2024. Crowds Can Effec-\ntively Identify Misinformation at Scale. Perspectives\non Psychological Science , 19(2):477\u2013488. PMID:\n37594056.\nMeta. 2025. More Speech and Fewer Mistakes.\nNicholas Micallef, Vivienne Armacost, Nasir Memon,\nand Sameer Patil. 2022. True or False: Studying the\nWork Practices of Professional Fact-Checkers. Proc.\nACM Hum.-Comput. Interact. , 6(CSCW1).\nGarrett Morrow, Briony Swire-Thompson, Jessica Mont-\ngomery Polny, Matthew Kopec, and John P Wihbey.\n2022. The Emerging Science of Content Labeling:\nContextualizing Social Media Content Moderation.\nJournal of the Association for Information Science\nand Technology , 73(10):1365\u20131386.\nMoritz Pilarski, Kirill Olegovich Solovev, and Nico-\nlas Pr\u00f6llochs. 2024. Community Notes vs. Snoping:\nHow the Crowd Selects Fact-Checking Targets on\nSocial Media. Proceedings of the International AAAI\nConference on Web and Social Media , 18:1262\u20131275.\nNicolas Pr\u00f6llochs. 2022. Community-Based Fact-\nChecking on Twitter\u2019s Birdwatch Platform. In Pro-\nceedings of the International AAAI Conference on\nWeb and Social Media , volume 16, pages 794\u2013805.\nMerten Reglitz. 2022. Fake News and Democracy. J.\nEthics & Soc. Phil. , 22:162.\nThomas Renault, David Restrepo-Amariles, and Au-\nrore Troussel. 2024. Collaboratively Adding Con-\ntext to Social Media Posts Reduces the Sharing of\nFalse News. HEC Research Papers Series 1519, HEC\nParis.\nMohammed Saeed, Nicolas Traub, Maelle Nicolas, Gi-\nanluca Demartini, and Paolo Papotti. 2022. Crowd-\nsourced Fact-Checking at Twitter: How Does the\nCrowd Compare With Experts? In Proceedings of\nthe 31st ACM International Conference on Informa-\ntion & Knowledge Management , CIKM \u201922, page\n1736\u20131746, New York, NY , USA. Association for\nComputing Machinery.\nMark Stencel, Erica Ryan, and Joel Luther. 2024. With\nHalf the Planet Going to the Polls in 2024, Fact-\nChecking Sputters. Technical report, Duke Re-\nporters\u2019 Lab.\nTikTok. 2025. Testing a New Feature to Enhance Con-\ntent on TikTok.\nTwitter/X. 2021. Introducing Birdwatch, a Community-\nBased Approach to Misinformation.\nTwitter/X. 2024a. Note Ranking Algorithm.\nTwitter/X. 2024b. Rating and Writing Impact.\nGreta Warren, Irina Shklovski, and Isabelle Augenstein.\n2025. Show Me the Work: Fact-Checkers\u2019 Require-\nments for Explainable Automated Fact-Checking. In\nProceedings of the CHI Conference on Human Fac-\ntors in Computing Systems , CHI \u201925, New York, NY ,\nUSA. Association for Computing Machinery.\nValerie Wirtschafter and Sharanya Majumder. 2023. Fu-\nture Challenges for Online, Crowdsourced Content\nModeration: Evidence from Twitter\u2019s Community\nNotes. Journal of Online Trust and Safety , 2(1).\nAmelie Wuehrl, Yarik Menchaca Resendiz, Lara Grim-\nminger, and Roman Klinger. 2024. What Makes\nMedical Claims (Un)Verifiable? Analyzing Entityand Relation Properties for Fact Verification. In Pro-\nceedings of the 18th Conference of the European\nChapter of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 2046\u20132058,\nSt. Julian\u2019s, Malta. Association for Computational\nLinguistics.\nTaha Yasseri and Filippo Menczer. 2023. Can Crowd-\nsourcing Rescue the Social Marketplace of Ideas?\nCommunications of the ACM , 66(9):42\u201345.\nAndy Zhao and Mor Naaman. 2023. Insights from a\nComparative Study on the Variety, Velocity, Verac-\nity, and Viability of Crowdsourced and Professional\nFact-Checking Services. Journal of Online Trust and\nSafety , 2(1).\nA Extended Background\nA.1 Impact of Community Notes on\nmisinformation spread\nPosts identified by community notes as mislead-\ning have been found to attain less virality (reposts,\nquote tweets and replies) than non-misleading posts\n(Drolsbach and Pr\u00f6llochs, 2023; Renault et al.,\n2024). Community notes have also been shown\nto increase the probability of tweet retractions and\ndeletions and speed up the retraction process (Gao\net al., 2024; Renault et al., 2024). However, other\nstudies have found less positive evidence; for ex-\nample, that users\u2019 followers, likes and engagement\nincrease after their post receives a community note\n(Wirtschafter and Majumder, 2023). Curiously,\none study claims that showing community notes\non posts reduced the spread of misleading posts\nby an average of 61% (Chuai et al., 2024a), while\na more recent analysis by the same authors found\nno effect of community notes on engagement with\nmisinformation (Chuai et al., 2024c).\nPeople shown community notes alongside mis-\nleading social media posts were more accurate\nin identifying misleading posts, and the notes\nwere judged to be more trustworthy than context-\nfree misinformation flags (e.g., \"Checked by fact-\ncheckers\" or \"Checked by other social media\nusers\"), regardless of (US-centric) political beliefs\n(Drolsbach et al., 2024). People shown either com-\nmunity notes or related news article suggestions\nwere both less likely to believe and report mis-\nleading information compared to a control group:\ncommunity notes were more effective in reducing\nbelief and sharing intention for positive rumours,\nwhile articles were more effective for negative ru-\nmours (Kankham and Hou, 2024). On the other\nhand, displaying community notes leads users to\npost more negative and angry replies to misleading\nposts (Chuai et al., 2024b), while crowd workers\nare also prone to cognitive biases, such as overes-\ntimating a statement\u2019s truthfulness the more they\nliked its claimant, and general overconfidence in\ntheir ability to ascertain truthful statements (Draws\net al., 2022).\nA.2 Professional fact-checking and\ncommunity note practices\nAlthough fact-checks and community notes share\nsimilarities in how they address misleading claims,\nthey also differ in key elements of practice and\ncommunication (Kankham and Hou, 2024). Fact-checking typically involves the analysis and veri-\nfication of public claims, and in addition to veri-\nfying claims, in recent years many fact-checking\norganisations have also assumed a wider role in\ncombating misinformation spread, e.g., long-term\ninvestigative journalism projects, media literacy\nprograms (Juneja and Mitra, 2022). Professional\nfact-checkers signatory to the International Fact-\nChecking Network follow a rigorous set of princi-\nples and transparency commitments11and a struc-\ntured workflow: (i) claim selection; (ii) collect-\ning evidence; (iii) deciding on a verdict; and (iv)\nwriting the fact-checking article (Graves, 2017;\nMicallef et al., 2022; Warren et al., 2025). In\ncontrast, any platform user can contribute to com-\nmunity notes under anonymity, and the rating ap-\nproach relies on the \u2018wisdom of crowds\u2019, with lit-\ntle oversight or transparency regarding biases of\nnote-writers. Community note writers and fact-\ncheckers tend to target similar topics (e.g., health\nand politics) (Saeed et al., 2022). Fact-checkers\nmust rely on credible sources and evidence to\nconvince the reader, while note writers often dis-\nagree with fact-checkers on what constitutes a re-\nliable source, particularly on political ideological\ngrounds (Saeed et al., 2022). The verdicts reached\nin notes tend to agree with those of fact-checkers \u2014\nhowever, due to political polarisation (Yasseri and\nMenczer, 2023), community notes on contentious\npolitical issues rarely reach a consensus (Saeed\net al., 2022). Fact-checking articles, which are sub-\nject to multiple rounds of editorial scrutiny, are\nmore formal and standardised in style than com-\nmunity notes, which vary considerably and can\nemploy a range of persuasion techniques, such\nas appeals to emotion or other logical fallacies\n(Kankham and Hou, 2024). Moreover, community\nnotes typically serve as direct rebuttals to mislead-\ning posts, while fact-checking articles may address\na more general claim than is expressed in a spe-\ncific post. Finally, fact-checking articles are a one-\nway exchange, while community notes represent a\nmore horizontal and interactive dialogue between\nwriter and recipient of the fact-check (Kankham\nand Hou, 2024). Prior work has found that collab-\norative fact-checking, a distinct approach to com-\nmunity notes for its Wikipedia-style approach that\nallows users to edit, as well as up and downvote\nuser-written posts (Haime, 2022), can produce fact-\n11https://www.ifcncodeofprinciples.poy\nnter.org/the-commitments\nchecks with comparable speed, reliability, objectiv-\nity, clarity and persuasiveness to those written by\nprofessional fact-checks (Zhao and Naaman, 2023).\nHowever, laypeople\u2019s work is expedited by existing\nfact-checking articles, and amateurs tend to defer\nto professional fact-checkers for topics requiring\nspecific expertise, such as medical claims (Zhao\nand Naaman, 2023). Our work builds on current\nunderstanding of the relationship between profes-\nsional fact-checking and community moderation\nby examining the extent to which community note\nwriters deploy the work of fact-checkers in their\nnotes.\nB Additional Material\nThis section details additional results or material\nreferenced from the paper\u2019s main body.\nFig. 6 A histogram of the number of community\nnotes written every month and their rating ( helpful ,\nnot helpful , orneeds more data ).\nFig. 7 Community ratings of notes with and without\nfact-checking source.\nTab. 2 List of top 100 most common domains\nfound in the community notes dataset, and their\ncategorisation.\nTab. 3 List of professional fact-checking organisa-\ntions and their URLs.\nTab. 4 A sample of tweets, notes, and their com-\nmunity annotations, as well as whether the note\ncontains a fact-checking link.\nTab. 5 Examples of community notes contain-\ning fact-checking sources that are rated as having\nnotHelpfulSourcesMissingOrUnreliable .\nC Reproducibility\nListing 1 The prompt used to classify URLs into\ncategories.\nListing 2 The prompt used to classify tweets and\nnotes into broader narratives and conspiracy theo-\nries.\nC.1 Manual Annotation Setup\nWe annotate 400 (tweet,note)pairs from Stextwith\n12 binary attributes. Each (tweet,note)pair was an-\nnotated in a multi-label fashion, i.e., more than one\nattribute can be selected at the same time. Fig. 8\ndepict our simple annotation setup, with the 12\nattributes being as follows.\nBroader narrative Whether the (tweet,note)pair\nis related to a broader narrative or a conspiracy\ntheory.Discredit source of claim If the community note\ndescribes the source shared by the original\npost as non-credible.\nAdd missing context If the community note pro-\nvides some missing context to refute a claim.\nHighlight AI generated If the community note\nclaims that the post shared AI-generated con-\ntent.\nHighlight edited media If the community note\nclaims that the post shared some media that\nwas edited (edited with Photoshop, the clip\nwas cut, etc.).\nLink to direct source If the community note\nshares a link to a source where an entity says\nthat a claim made about them is false.\nLink official source If the community note shares\na link to an official source such as a govern-\nment website.\nLink scientific source If the community note\nshares a link to some scientific article or web-\nsite.\nLink world knowledge If the community note\nshares a link to some reference resources such\nas Wikipedia.\nLink fact-checking If the community note shares\na link to a professional fact-checking organi-\nsation.\nIn-note fact-checking If the community note\nperforms an in-note fact-check by cross-\nreferencing several sources and constructing\na compelling argument.\nDomain Category Domain Category\nx.com social media thehill.com news\ntwitter.com social media amp.theguardian.com news\nyoutube.com social media whitehouse.gov government\nyoutu.be social media news.sky.com news\nun.org organisation merriam-webster.com reference\nu.today news techarp.com news\nt.co social media cbc.ca news\nsnopes.com fact checking politifact.com fact checking\nen.m.wikipedia.org reference pbs.org commercial\nen.wikipedia.org reference telegraph.co.uk news\ngoogle.com search engine businessinsider.com news\ninstagram.com social media time.com news\nbritannica.com reference justice.gov government\nreuters.com news cnbc.com news\nbbc.co.uk news wsj.com news\napnews.com news sciencedirect.com academic\nbbc.com news msn.com news\nnytimes.com news statista.com reference\ntheguardian.com news business.x.com commercial\nvice.com news amp.cnn.com news\nusatoday.com news congress.gov government\nfactcheck.org fact checking factcheck.afp.com fact checking\ncnn.com news yahoo.com search engine\nwashingtonpost.com news timesofindia.indiatimes.com news\nncbi.nlm.nih.gov academic thelancet.com academic\nnbcnews.com news hrw.org organisation\nhelp.twitter.com reference healthfeedback.org fact checking\ncdc.gov government fda.gov government\nnpr.org news m.youtube.com social media\nforbes.com news law.cornell.edu academic\nnewsweek.com news medium.com blog post\nfullfact.org fact checking healthfeedback.org fact checking\ndailymail.co.uk news who.int organisation\ncbsnews.com news haaretz.com news\nweb3antivirus.io database axios.com news\ntimesofisrael.com news mayoclinic.org commercial\nhelp.x.com reference nejm.org academic\nnypost.com news scienceexchange.caltech.edu academic\naljazeera.com news indiatoday.in news\nreddit.com social media bloomberg.com news\nindependent.co.uk news pewresearch.org academic\nusgs.gov academic jamanetwork.com academic\nabcnews.go.com news leadstories.com news\nnature.com academic dictionary.cambridge.org reference\ngov.uk government jpost.com news\nweb.archive.org database archive.ph database\nfoxnews.com news healthline.com commercial\ntiktok.com social media abc.net.au news\nedition.cnn.com news france24.com news\nTable 2: List of top 100 most common domains found in the community notes dataset, and their categorisation.\nName URL Language Region/domain\nLead stories leadstories.com English Global\nAFP Factuel factuel.afp.com French Global\nAAP FactCheck aap.com.au/factcheck English Australia\nFull Fact fullfact.org English Global\nScience Feedback science.feedback.org English Science\nPolitifact politifact.com English, Spanish USA\nHoaxEye hoaxeye.wordpress.com English Images\nLogically Facts logicallyfacts.com Multiple Europe/India\nFactCheckNI factcheckni.org English North Ireland\nDFRLab dfrlab.org English Global\nFactReview factreview.gr Greek Global\nLupa lupa.uol.com.br/jornalismo Portuguese Global\nCheck your fact checkyourfact.com English Global\nClimate feedback climatefeedback.org English Climate\nFactcheck factcheck.org English USA\nHealth feedback healthfeedback.org English Health\nSnopes snopes.com English US\naosfatos aosfatos.org Portuguese Global\nDemagog demagog.org.pl/fake_news Polish Poland\nFakeReporter fakereporter.net Hebrew Israel\nlitmus factcheck litmus-factcheck.jp Japanese Japan\nClimate Feedback climatefeedback.org English Global\nAFP factcheck.afp.com English Global\nUSA Today usatoday.com/story/news/factcheck English USA\nStatesman statesman.com English USA\nDallas News dallasnews.com/news/politifact English USA\nGoogle Fact Check toolbox.google.com/factcheck English Global\nMediaBias/FactCheck mediabiasfactcheck.com English Global\nMedDMO meddmo.eu English, Greek Greece, Cyprus, Malta\nPoynter poynter.org/fact-checking English USA\nNewsmeter newsmeter.in/fact-check English, Tamil India\nAfrica Check africacheck.org English Africa\nFact Crescendo India english.factcrescendo.com English India\nFactseeker factseeker.lk English Sri Lanka\nFact Crescendo Thailand thailand.factcrescendo.com Thai Thailand\nFact Crescendo Afghanistan afghanistan.factcrescendo.com Persian Afghanistan\nOnly Fact onlyfact.in English India\nFactly factly.in English India\nFact Crescendo Sri Lanka srilanka.factcrescendo.com Sinhala Sri Lanka\nFact Crescendo Cambodia cambodia.factcrescendo.com Cambodian Cambodia\nBecid becid.eu Baltic langs Baltic\nFact Hunt facthunt.in English India\nTec Arp techarp.com English Global (based in Malaysia)\n10 news 10news.com/news/fact-or-fiction English USA\nRMIT Fact Check rmit.edu.au English Australia\nGigafact gigafact.org English USA\nAyupp ayupp.com/fact-check English India\nThe Journal thejournal.ie English Ireland\nTable 3: List of professional fact-checking organisations and their URLs.\nTweet NotemisleadingUnverifiedClaimAsFactmisleadingOutdatedInformationmisleadingFactualErrormisleadingSatireFact Checking source\nThe NASA War Document is absolutely terri-\nfying https://t.co/...misrepresenting a presentation by NASA scientist Dennis Bush-\nnell, The lecture was not detailing plans by NASA to attack the\nworld it was a lecture for defense industry professionals, and\nhow defense tactics might rise to meet evolving threats in the\nfuture. https://leadstories.com/hoax-alert/2\n021/06/fact-check-the-future-is-now-is-n\not-a-nasa-war-document-plan-for-world-d\nomination-and-phasing-out-of-humans.html\u2713 \u2717 \u2717 \u2717 \u2713\nBREAKING NEWS: International Criminal\nInvestigation calls on every public citizen to\nrecommend indictments for Bill Gates, An-\nthony Fauci, Pfizer, BlackRock, Tedros and\nChristian Drosten for pushing everyone to re-\nceive the ineffective highly dangerous lethal\nexperimental vaccines...Video has been fact-checked by USA Today, was found to be\nmisleading, and promotes a conspiracy theory about COVID ...\nhttps://ca.movies.yahoo.com/movies/fact-c\nheck-viral-video-promotes-204414488.html\u2713 \u2717 \u2717 \u2717 \u2713\n1) California is RED. It is just because of the\nMASSIVE Election Fraud that stupid, brain-\nwashed people believe Calif. is blue. Joe\nBiden won only in the SFO Bay area ...The map shows the results of Reagan\u2019s reelection in 1984, not\nBiden\u2019s election in 2020. https://en.wikipedia.org\n/wiki/1984_United_States_presidential_el\nection_in_California\u2717 \u2713 \u2717 \u2717 \u2717\nDavis blows up $100,000 fireworks in Kai\nCenat setup During the Mr Beast Stream ...The second photo is from a house fire in Atlanta in 2019. http\ns://www.11alive.com/article/news/local/w\noodland-brook-drive-cause-of-house-fire/\n85-ecb7df9b-5f65-44e9-bf9d-8c162d36c334\u2717 \u2713 \u2717 \u2717 \u2717\n@cnviolations I swear community notes are\nthe only good thing Elon added since he\nbought Twitter.Community notes was first launched under former Twitter CEO\nJack Dorsey in 2021 under the name of \u2018Birdwatch\u2019. The\nonly thing Elon Musk did was that he renamed the feature to\ncommunity notes. https://blog.twitter.com/en_\nus/topics/product/2021/introducing-birdw\natch-a-community-based-approach-to-misin\nformation https://www.reuters.com/article/\nfactcheck-elon-birdwatch-idUSL1N31Z2VG/\u2717 \u2717 \u2713 \u2717 \u2713\nThailand will become the first country to\nmake the contract null and void, meaning that\nPfizer will become responsible for all vaccine\ninjuries ...Thailand has no plans to void its Pfizer COVID vaccine contract,\nan official with the country\u2019s National Vaccine Institute said.\nThailand\u2019s Department of Disease Control also rejected the\nclaims as \u2018fake news.\u2019 ... https://apnews.com/artic\nle/fact-check-covid-vaccine-pfizer-thail\nand-203948163859\u2717 \u2717 \u2713 \u2717 \u2713\nHilarious tweets by footballers, A thread: 1.\nVirgil Van Dijk [Current Liverpool Captain]\nhttps://t.co/...Virgil Van Dijk did not tweet this, the tweet was made by a fan\naccount in his name. https://www.pinkvilla.com/\nsports/fact-check-did-virgil-van-dijk-r\neally-root-for-man-u-because-no-one-lik\nes-liverpool-in-resurfaced-viral-tweet-1\n287250\u2717 \u2717 \u2717 \u2713 \u2713\nRob Reiner announces he\u2019s on the Epstein\nClient List and Epstein Flight logs. What a\nfool! When a lawyer tells me to STFU, I\nSTFU! https://t.co/...This is a digitally altered photo that might be misinterpreted\neven if used as a joke. The name Rob Reiner is misspelled, and\nthe text is not on Reiner\u2019s X timeline. https://twitter.\ncom/robreiner?t=iqu43-NszIW5oOM_KqRSpw\u2717 \u2717 \u2717 \u2713 \u2717\nTable 4: A sample of tweets, notes, and their community annotations, as well as whether the note contains a\nfact-checking link.\nID summary\n0 This claim ruled mostly false. https://www.politifact.com/factchecks/\n2020/may/07/facebook-posts/facebook-post-cites-doctors-widel\ny-disputed-calcul/\n1 The RedState article claims \u201cthe shots do not stop transmission of the virus. This is false.\n\u201d\u201cVaccines provide significant protection from \u2019getting it\u2019 \u2013 infection \u2013 and \u2019spreading it\u2019 \u2013\ntransmission \u2013 even against the delta variant.\u201d Source: https://www.usatoday.com\n/story/news/factcheck/2021/11/17/fact-check-covid-19-vaccine\ns-protect-against-infection-transmission/6403678001/\n2 There is no proof of this, the photo is real, it\u2019s not the last photo of the child. But snoops\nsay there is a tenuous link the parents used the same law firm to represent them as Maxwell\nhttps://www.snopes.com/fact-check/ghislaine-maxwell-jonbene\nt-ramsey/\n3 unfounded https://www.snopes.com/fact-check/ashley-biden-diary\n-afraid/\n4 The mRNA vaccine does not cause cancer: https://www.factcheck.org/2024/0\n5/still-no-evidence-covid-19-vaccination-increases-cancer-r\nisk-despite-posts/\n5 Many of the details in this popular essay are inaccurate and too numerous to list here. The\nessay was fact checked by Snopes in 2005: https://www.snopes.com/fact-che\nck/the-price-they-paid/\n6 POLITIFACT - rates False. The report analysed a small sample of 128 temp stations out of\nseveral thousand volunteer-run stations, then extrapolated results. NOAA uses 2 programs to\nrecord daily temps. The report did not look at the 900 more sophisticated automated stations.\nhttps://www.politifact.com/factchecks/2022/aug/19/facebook-p\nosts/fact-checking-talking-point-about-corrupted-climat/\n7 There is no verifiable evidence of campaign espionage in either the 2020 or the 2016\npresidential elections. https://www.snopes.com/fact-check/obama-spyin\ng-trump-campaign/ https://www.washingtonpost.com/politics/20\n19/05/06/whats-evidence-spying-trumps-campaign-heres-your-g\nuide/\n8 Ladapo did get caught altering COVID vaccine study findings. Ladapo replaced the language\nfrom an earlier study draft that found no significant risk from COVID vaccines, to then state\nthere was a high risk https://healthfeedback.org/claimreview/analysi\ns-florida-department-health-surgeon-general-joseph-ladopo-c\nontains-multiple-methodological-problems-covid-19-mrna-vacci\nnes/ https://healthexec.com/topics/clinical/COVID-19/florid\na-surgeon-general-altered-covid-19-study-findings\nTable 5: Examples of community notes containing fact-checking sources that are rated as having notHelpful-\nSourcesMissingOrUnreliable .\nFigure 6: A histogram of the number of community notes written every month and their rating ( helpful ,not helpful ,\norneeds more data . The grey vertical line (December 2022) indicates the date when the community notes became\nvisible worldwide.\nFigure 7: Community ratings of notes with and without fact-checking source.\nSYSTEM PROMPT\nYou are a professional IT system who has a vast knowledge of the internet and its\ncontent. Your goal is simple, but very important: Classify URLs into\ncategories. Choose only from the provided categories!\nUSER PROMPT\nRead the following URLs.\nYour goal is to categorize each url into one of the pre-defined categories.\nChose from the following list of categories:\nCategories =\n[\n\"social media\", # Social media sites like Facebook, Twitter, Youtube etc.\n\"news\", # Websites of news outlets or other organisations that report current\nevents, such as the nytimes, the guardian, etc.\n\"government\", # Government agencies and organisations, as well as websites\nrelated to policies and guidelines, such as the CDC, department of education,\nFDA, etc.\n\"academic\", # Academic sources, journals, and magazines, such as pubmed,\nnature, sciencedirect, etc.\n\"blog post\", # Independent blog posts about various topics, including cooking,\ntravel, home improvement, fandom, reviews, etc.\n\"fact checking\", # professional fact checking organisations\n\"database\", # Public databases such as google drive, archive.com, dropbox, etc.\n\"commercial\", # Webpages of commercial organisations such as BMW, Delta, Nike,\netc.\n\"reference\", # Public resources such as encyclopedias, dictionaries, advocacy\nsources, guides, DIYs, statistics, religious sources, travel information, usage\nguidelines, Q&As, terms of services, etc.\n\"organisation\", # non-commercial and non-government organisations such as WHO,\nthe UN, Greenpeace, LA-Lakers, etc.\n\"other\", # Any other website that does not fit into one of the previous\ncategories.\n\"unknown\", # if it is impossible to determine the category of the webpage.\n]\nOutput format example:\n[\n{\nid: <ID>,\nurl: <URL>,\ncategory: <CATEGORY>,\n}\n]\nURLs:\n<URLS>\nListing 1: The prompt used to classify URLs into categories.\nSYSTEM PROMPT\nYou are a professional fact-checker who specializes in analyzing misinformation\nspread on social media.\nYour goal is to analyse a tweet and a community note written about the tweet and\ndecide whether the tweet spread misinformation related to a known conspiracy\ntheory or a misleading wider narrative, and if so, which one is it.\nUSER PROMPT\nRead the following tweets and community notes written about them.\\nYour goal is to\nanalyse them and decide whether each tweet spread misinformation related to a\nknown conspiracy theory or a similar misleading wider narrative, and if so (and\nonly if so!), which one.\nInclude your reasoning. Output the results as a json file. If a tweet does not\nrelate to a conspiracy theory or a misleading wider narrative, output \"none\" in\nthe json.\n- Tweets *do not *discuss a wider narrative if the misleading information is tied\nto a specific singular event that is not connected to major topics on the\npublic discourse.\nThey do discuss a wider narrative if the misleading information is tied to a known\nconspiracy theory or to major topics on the public discorse.\nChose from the following list of theories and wider narrative:\nCONSPIRACY_THEORIES =\n[\nSeptember 11,\nOctober 7,\nthe great replacement,\nCOVID was intentionally spread,\nthe COVID outbreak is fake,\n2020 election fraud,\nvaccines cause autism,\n5G towers,\nRussian invasion of Ukraine,\nflat earth,\nchemtrails,\nQ-Anon and deep state,\nEpstein files,\nBarack Obama was not born in the USA,\nMichelle Obama is a man,\nLGBT grooming,\nfluorite in the water,\nclimate change,\nHolocaust denial,\nHunter Biden and Ukraine,\nother,\n]\nOutput format example:\n[\n{\nid: <ID>,\nis_related_to_conspiracy: <True/False>,\nconspiracy: <CONSOIRACY (or None)>,\nreasoning: <REASONING>\\\n}\n]\nTweets and notes:\n<TWEETS_AND_NOTED>\nListing 2: The prompt used to classify tweets and notes into broader narratives and conspiracy theories.\nFigure 8: Our annotation setup.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Can Community Notes Replace Professional Fact-Checkers?", "author": ["N Borenstein", "G Warren", "D Elliott"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "Two commonly-employed strategies to combat the rise of misinformation on social media are  (i) fact-checking by professional organisations and (ii) community moderation by platform"}, "filled": false, "gsrank": 124, "pub_url": "https://arxiv.org/abs/2502.14132", "author_id": ["uDM-PC0AAAAJ", "8HG2vY0AAAAJ", "OjYpMi4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:AI-rjMRqX_kJ:scholar.google.com/&output=cite&scirp=123&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D120%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=AI-rjMRqX_kJ&ei=GrWsaJ6pKcDZieoPqdqh8QU&json=", "num_citations": 3, "citedby_url": "/scholar?cites=17969198430637756160&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:AI-rjMRqX_kJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2502.14132?"}}, {"title": "Team kit kittredge at SemEval-2019 task 4: LSTM voting system", "year": "2019", "pdf_data": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019) , pages 1021\u20131025\nMinneapolis, Minnesota, USA, June 6\u20137, 2019. \u00a92019 Association for Computational Linguistics1021Team Kit Kittredge at SemEval-2019 Task 4: LSTM Voting System\nRebekah Cramerus\nDepartment of Linguistics\nUniversity of Potsdam\nPotsdam, Germany\nrebekah.cramerus@fulbrightmail.orgTatjana Schef\ufb02er\nDepartment of Linguistics\nUniversity of Potsdam\nPotsdam, Germany\ntatjana.scheffler@uni-potsdam.de\nAbstract\nThis paper describes the approach of team Kit\nKittredge to SemEval 2019 Task 4: Hyper-\npartisan News Detection. The goal was bi-\nnary classi\ufb01cation of news articles into the cat-\negories of \u201cbiased\u201d or \u201cunbiased\u201d. We had two\nsoftware submissions: one a simple bag-of-\nwords model, and the second an LSTM (Long\nShort Term Memory) neural network, which\nwas trained on a subset of the original dataset\nselected by a voting system of other LSTMs.\nThis method did not prove much more suc-\ncessful than the baseline, however, due to the\nmodels\u2019 tendency to learn publisher-speci\ufb01c\ntraits instead of general bias.\n1 Introduction\nWith the proliferation of online news agencies af-\nter the rise of the Internet, access to information\nabout what is going on in the world has never\nbeen more widespread. How that information is\npresented, however, can have a large in\ufb02uence on\nwhat conclusions the reader draws from it. Be-\ning able to automatically identify hyperpartisan-\nship (bias or adherence to one party or faction over\nothers) in a news article would help individuals in\ntheir news consumption and potentially result in a\nbetter-informed population.\nAs suggested, the challenge approached in this\npaper is that of hyperpartisan news detection: a\nbinary classi\ufb01cation problem (biased or unbiased)\nwith news articles as data. This task can be consid-\nered as related to stance detection and in general,\nsentiment analysis. The challenge was organized\nas Task 4 for SemEval 2019 (Potthast et al., 2018)\n(Kiesel et al., 2019). Final submissions were sub-\nmitted through TIRA, with the test datasets hidden\n(Potthast et al., 2019).\nFirst in this paper, Section 2 includes an in-\ntroduction of the provided dataset and a descrip-\ntion of preprocessing techniques used for our ap-\nproach. Section 3 describes the \ufb01rst submittedsoftware, a bag-of-words model. Section 4 contin-\nues with our second approach, an LSTM trained\non a subset of the original dataset, and a descrip-\ntion of how that subset was selected.\nSection 5 presents our results on the test set and\nSection 6 delves into analysis, presenting potential\nreasons why the models did not perform very well.\n2 Data\nDuring the course of the task participants were\ngranted access to different datasets with which to\nwork.\nA training dataset of 600,000 articles and a val-\nidation dataset of 150,000 articles were both re-\nleased to participants. Both sets contain 50% un-\nbiased and 50% biased articles, and of the latter,\nhalf are left-biased and the other half right-biased\n(in terms of their placement on the political spec-\ntrum). Importantly, these articles were all labeled\nwith the overall bias of their publisher, which was\nobtained by MediaBiasFactCheck.com and Buzz-\nFeed. The set of publishers whose articles appear\nin the training set has no overlap with the publish-\ners of the validation set, and neither has any over-\nlap with the publishers whose articles appear in the\ninaccessible test set.\nWe consider the labels of these datasets to be\nnoisy: though publishers may have an overall bias,\nit is likely that most biased news agencies do not\npublish only biased articles, just as most unbiased\nnews agencies may occasionally publish a biased\npiece.\nAlso relevant is a third released dataset referred\nto in this paper as the byarticle dataset. Unlike\nthe other datasets, this one contains articles which\nwere labeled individually through crowdsourcing.\nIt is small, at 645 articles, and unbalanced, at 63%\nunbiased and 37% hyperpartisan.\n10222.1 Preprocessing\nCertain preprocessing tasks were carried out on\nthe entire dataset pre-training, and also applied to\nthe test set during evaluation.\nSome cleaning tasks required segmentation of\ntexts into sentences or words using the Natural\nLanguage Toolkit (NLTK) (Bird et al., 2009).\nSpecial characters, double spaces, more than\nthree dots in a row, and any failures in charac-\nter translation (for example, \u201cgun control\u201d becom-\ning ?gun control?) were replaced or removed.\nRegular expressions were used for some of these\ntasks, as well as for removing img orhtml tags\nand URLs. Another list of phrases were summar-\nily removed from each text: those which were\nlikely byproducts of the articles\u2019 retrieval from\ntheir websites. These included \u201cContinue Reading\nBelow...\u201d, \u201cImage Source:\u201d, \u201cOpens a New Win-\ndow\u201d, and so on.\nAs will be discussed, a recurring problem en-\ncountered by our models was the tendency to learn\npublisher-speci\ufb01c traits and not hyperpartisanship\nitself. To combat this we included methods to re-\nmove potential publisher-speci\ufb01c text, especially\nnames and emails of the authors of the articles, in\nour preprocessing step.\n3 Software 1: Bag-Of-Words\nOur \ufb01rst approach was a bag-of-words baseline for\ninitial exploration of the dataset and comparison\nwith the more complex second approach.\n3.1 Tokenization / Lemmatization\nTexts were tokenized into words, and the words\nreduced to their lemmas, using spaCy (Honnibal\nand Johnson, 2015).\n3.2 Vectorization\nFirst we created a vocabulary of the most common\n4000 words in the overall corpus (all datasets), ex-\ncluding stopwords from a list compiled by scikit-\nlearn (Pedregosa et al., 2011).\nWe also excluded from the vocabulary words\nfrom an exceptions list, in an attempt to reduce\nthe problem of over\ufb01tting to the article publishers.\nThis exceptions list was formed by counting all\nwords in the training and validation datasets, and\ngathering those words which appeared \ufb01ve times\nmore often (relative to the size of the corpus) in\none set than in the other. Some of these terms were\nlocation-speci\ufb01c ( abq,lobos ,nmsu \u2014 likely apublisher based in New Mexico) and others hinted\nat coverage of a certain topic ( samsung ,boeing ,\nverizon \u2014 possibly a publisher which wrote of-\nten about the stock market). The intent behind this\nwas to help avoid the model picking up, for exam-\nple, that the presence of terms surrounding New\nMexico automatically meant a certain label.\nWith a \ufb01nal vocabulary, each text was then con-\nverted to a vector of length 4000, wherein each\ndimension is the count of the corresponding vo-\ncabulary word in that text.\n3.3 Model\nUsing scikit-learn, the training and validation\ndatasets were vectorized according to the previ-\nously described speci\ufb01cations and then \ufb01t to a lo-\ngistic regression model. This was then submitted\nto TIRA.\n4 Software 2: LSTM\nLong Short Term Memory networks (or LSTMs)\nare a form of Recurrent Neural Networks (or\nRNNs) which is capable of learning long-term de-\npendencies. Given the nature of the problem and\nthe data \u2014 a text being a sequence of words,\nthe relationship between them as important as the\nwords themselves \u2014 we chose to develop a model\nwith this architecture.\n4.1 Word Embeddings\nTo transform the article texts into vectors able to\nbe processed by the neural network, we chose to\ntrain our own skip-gram word embeddings on the\ntotal given corpus (training, validation and byarti-\ncle datasets). Embeddings of 50 dimensions (cho-\nsen mostly arbitrarily, but in part due to computa-\ntional limits) were trained using the Python pack-\nage gensim, for 10 epochs, including words in the\nvocabulary which appeared in the corpus over \ufb01ve\ntimes ( \u02c7Reh\u02dau\u02c7rek and Sojka, 2010). The total vocab-\nulary size was 457,197 words.\n4.2 Vectorization\nTexts were \ufb01rst transformed into arrays of the\nshape (100, 50), wherein 100 was the cutoff or\nmaximum text length and 50 was the dimension-\nality of the word embeddings. Texts shorter than\n100 words were padded with zero-vectors to keep\nthe shape consistent to feed into the network.\n1023Model Test Dataset Accuracy Precision Recall F1\nBag-of-Words byarticle 57.8 54.7 90.8 68.3\nLSTM byarticle 58.3 55.8 79.2 65.5\nBag-of-Words bypublisher 61.2 57.8 83.4 68.2\nLSTM bypublisher 65.2 64.7 67.1 65.9\nTable 1: Results on the test datasets.\n4.3 Architecture\nThe model consists of a single LSTM layer with\n50 units, followed by a dropout wrapper with a\nkeep probability of 0.75 to help prevent over\ufb01t-\nting. Next is a standard feedforward neural net-\nwork output layer. AdamOptimizer was used with\na 0.001 learning rate as well as softmax cross-\nentropy loss for optimization.\nAll LSTM models were trained using Tensor-\n\ufb02ow for approximately 2 epochs (Abadi et al.,\n2015).\n4.4 Voting System\nKnowing that the biggest obstacle faced so far was\nthe tendency of models trained on the datasets to\nover\ufb01t to the publishers and not bias itself, we\nchose to pare down the dataset for the \ufb01nal sub-\nmission. In theory the ideal dataset, in which there\nis no noise from the publisher-based labels, is con-\ntained within the original dataset. To \ufb01nd that sub-\nset \u2014 or at least to get closer \u2014 we implemented\na voting system.\nThree LSTMs of the previously described archi-\ntecture were trained: one each on the training, val-\nidation and byarticle datasets. We then collected\npredictions from each LSTM, on each article in\neach dataset. The articles which all three LSTM\nmodels correctly labeled were pulled into a new\ndataset labeled agree . This dataset, in total size\n162,046 articles with 37% biased and 63% unbi-\nased labels, was what we trained our \ufb01nal model\non.\n4.5 Retrained LSTM\nOnce the new datasets were compiled from the\nvoting system based on the originals, a new LSTM\nwith the same architecture was trained on the com-\nbined data. This model was submitted to TIRA as\nour second software.\n5 Results\nBoth approaches were scored on the hidden test\ndatasets using TIRA. One of the two test datasetswas labeled individually by article, referred to in\nthis paper as the byarticle-test dataset, including\n638 articles with no publisher overlap with any of\nthe given corpora. The other, like the training and\nvalidation sets, was labeled overall by publisher,\nhere referred to as the bypublisher-test dataset,\nwith a total of 4000 articles, also including no pub-\nlisher overlap with other datasets.\nResults can be seen in Table 1. The LSTM\ntended to outperform the Bag-of-Words model in\naccuracy, but had lower f1 scores. All results\nshowed higher recall than precision \u2014 and except\nfor the case of the LSTM with the bypublisher-test\nset, markedly higher. By accuracy, the best result\nwas the LSTM on the bypublisher-test set.\n6 Discussion\nIn the published leaderboard, most teams had\nhigher scores on the test dataset which was labeled\nby article rather than the one labeled by publisher;\noverall, the highest accuracy was over 10% higher\non the byarticle-test set than on the bypublisher-\ntest one. Our approaches, on the other hand, both\nperformed better on the bypublisher-test dataset.\nThis could be in part because we did not spend\ntoo much time optimizing over the small byarticle\ndataset which was released to us \u2014 trying addi-\ntional techniques to maximize performance over\nthis set could be a task for future work.\nWhy our results are better on the bypublisher-\ntest sets is an interesting question. Our efforts\nin both approaches were focused on enabling\nthe models into generalizing about bias, instead\nof on recognizing only which articles belong to\nwhich publishers. Better performance on the\nbypublisher-test run than on the byarticle-test run\nsuggests that our efforts may have paid off, but in\nthe sense that we are better able to identify biased\npublishers instead of biased articles. That is, the\nquestion that the \ufb01rst models were answering was,\n\u201cDoes this article belong to X set of publishers,\nor Y set of publishers?\u201d We attempted to instead\nanswer the question, \u201cIs this article biased?\u201d But\n1024higher accuracy on the bypublisher-test dataset in-\ndicates that we might instead answer the question,\n\u201cDoes this article belong to a biased publisher ?\u201d\n6.1 Precision/Recall\nAcross all models recall was consistently higher\nthan precision. Our approaches therefore were\ncorrectly picking out hyperpartisan articles, but\nalso misclassifying unbiased articles as biased.\nThere are a variety of reasons why this could hap-\npen: quotes by partisan speakers could affect a rat-\ning of an unbiased article which discusses it, or\ncertain topics could be more often reported in a\npartisan manner so that unbiased articles around\nthem are rare and misclassi\ufb01ed. A closer exami-\nnation of the test dataset results would be needed\nfor a more concrete discussion.\n6.2 Software 1 Exceptions List\nThe exceptions list was created with the intent of\nremoving words from the vocabulary which were\nextremely lopsided in their use between publish-\ners (as in, some publishers, or just one in partic-\nular, were much more likely to use the term than\nothers). While initial results looked promising, it\nis possible that the method was not robust enough,\nand some unigram indicators of a certain publisher\nstill ended up in the \ufb01nal model.\n6.3 Software 2 Dataset: Voting System\nThe idea behind the voting system was to pare\ndown the original dataset, reducing noise and\ntherefore focusing on the data points where bias\nwas most salient \u2014 and could as such be picked\nup by models trained on different publishers. The-\noretically these articles would all have character-\nistics common to biased articles of all publish-\ners. When put together, then, the hope was that\na model trained on this subset of the dataset would\nlearn those common characteristics and not just\nthe publisher-speci\ufb01c ones.\nThere are many things that could have gone\nwrong with this system, however. Our cutoff for\nthe news article length may have been too short,\nfor example. Secondly, Since the three models\nused for voting did not have very high accuracy\non each other\u2019s datasets in the \ufb01rst place, the level\nof noise may not have been reduced at all. Fur-\nthermore, the original training dataset was four\ntimes as large as the validation dataset, and the\nbyarticle dataset was far smaller than either. Their\nsubsets after the voting system was applied wereequally unbalanced. When combined and used for\ntraining the \ufb01nal LSTM, it could have been unbal-\nanced enough that the model learned mostly from\nthe data from the original dataset, and the features\nfrom those publishers.\n7 Conclusion\nIn approaching Task 4 (Hyperpartisan News De-\ntection) in SemEval 2019, we developed two mod-\nels for submission: a Bag-of-Words logistic re-\ngression model and an LSTM neural network\ntrained on a subset of the original training and val-\nidation sets. While neither model reached high ac-\ncuracy rates on the test datasets, their methods still\nprovoke some discussion on how to better avoid\n\ufb01tting to the publishers and not bias itself.\n8 Namesake\nMargaret Mildred \u201cKit\u201d Kittredge is a character\nfrom the American Girl doll and book series. She\nwas born in Ohio in the 1920s and wanted to be-\ncome a reporter when she grew up. In her room\nin the attic, she would write her news articles on a\ntypewriter to share with her family.\nReferences\nMart \u00b4\u0131n Abadi, Ashish Agarwal, Paul Barham, Eugene\nBrevdo, Zhifeng Chen, Craig Citro, Greg S. Cor-\nrado, Andy Davis, Jeffrey Dean, Matthieu Devin,\nSanjay Ghemawat, Ian Goodfellow, Andrew Harp,\nGeoffrey Irving, Michael Isard, Yangqing Jia, Rafal\nJozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh\nLevenberg, Dandelion Man \u00b4e, Rajat Monga, Sherry\nMoore, Derek Murray, Chris Olah, Mike Schus-\nter, Jonathon Shlens, Benoit Steiner, Ilya Sutskever,\nKunal Talwar, Paul Tucker, Vincent Vanhoucke,\nVijay Vasudevan, Fernanda Vi \u00b4egas, Oriol Vinyals,\nPete Warden, Martin Wattenberg, Martin Wicke,\nYuan Yu, and Xiaoqiang Zheng. 2015. TensorFlow:\nLarge-scale machine learning on heterogeneous sys-\ntems. Software available from tensor\ufb02ow.org.\nSteven Bird, Edward Loper, and Ewan Klein. 2009.\nNatural language processing with python. O\u2019Reilly\nMedia Inc.\nMatthew Honnibal and Mark Johnson. 2015. An im-\nproved non-monotonic transition system for depen-\ndency parsing. In Proceedings of the 2015 Con-\nference on Empirical Methods in Natural Language\nProcessing , pages 1373\u20131378, Lisbon, Portugal. As-\nsociation for Computational Linguistics.\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\n1025Benno Stein, and Martin Potthast. 2019. SemEval-\n2019 Task 4: Hyperpartisan News Detection. In\nProceedings of The 13th International Workshop on\nSemantic Evaluation (SemEval 2019) . Association\nfor Computational Linguistics.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Pretten-\nhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Pas-\nsos, D. Cournapeau, M. Brucher, M. Perrot, and\nE. Duchesnay. 2011. Scikit-learn: Machine learning\nin Python. Journal of Machine Learning Research ,\n12:2825\u20132830.\nMartin Potthast, Tim Gollub, Matti Wiegmann, and\nBenno Stein. 2019. TIRA Integrated Research Ar-\nchitecture. In Nicola Ferro and Carol Peters, edi-\ntors, Information Retrieval Evaluation in a Chang-\ning World - Lessons Learned from 20 Years of CLEF .\nSpringer.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz, Ja-\nnek Bevendorff, and Benno Stein. 2018. A Stylo-\nmetric Inquiry into Hyperpartisan and Fake News.\nIn56th Annual Meeting of the Association for Com-\nputational Linguistics (ACL 2018) , pages 231\u2013240.\nAssociation for Computational Linguistics.\nRadim \u02c7Reh\u02dau\u02c7rek and Petr Sojka. 2010. Software Frame-\nwork for Topic Modelling with Large Corpora. In\nProceedings of the LREC 2010 Workshop on New\nChallenges for NLP Frameworks , pages 45\u201350, Val-\nletta, Malta. ELRA. http://is.muni.cz/\npublication/884893/en .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Team kit kittredge at SemEval-2019 task 4: LSTM voting system", "author": ["R Cramerus", "T Scheffler"], "pub_year": "2019", "venue": "\u2026 of the 13th International Workshop on \u2026", "abstract": "This paper describes the approach of team Kit Kittredge to SemEval-2019 Task 4: Hyperpartisan  News Detection. The goal was binary classification of news articles into the categories"}, "filled": false, "gsrank": 126, "pub_url": "https://aclanthology.org/S19-2178/", "author_id": ["", "E-br2oUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:vzbtXsUTKEIJ:scholar.google.com/&output=cite&scirp=125&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D120%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=vzbtXsUTKEIJ&ei=GrWsaJ6pKcDZieoPqdqh8QU&json=", "num_citations": 3, "citedby_url": "/scholar?cites=4767081943993759423&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:vzbtXsUTKEIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/S19-2178.pdf"}}, {"title": "An analysis of people's reasoning for sharing real and fake news", "year": "2021", "pdf_data": "Boise State Univ ersity Boise State Univ ersity \nScholarW orks ScholarW orks \nComputer Science F aculty Publications and \nPresentations Depar tment of Computer Science \n2021 \nAn Analysis of P eople \u2019s Reasoning for Sharing Real and F ake An Analysis of P eople \u2019s Reasoning for Sharing Real and F ake \nNews News \nAnu Shr estha \nBoise State Univ ersity \nFrancesca Spezzano \nBoise State Univ ersity \nAn Analysis of People's Reasoning for Sharing\nReal and Fake News\nAnu Shrestha and Francesca Spezzano\nComputer Science Department\nBoise State University\nanushrestha@u.boisestate.edu\nfrancescaspezzano@boisestate.edu\nAbstract. The problem of the increase in the volume of fake news and\nits widespread over social media has gained massive attention as most of\nthe population seeks social media for daily news diet. Humans are equally\nresponsible for the surge of fake news spread. Thus, it is imperative to\nunderstand people's behavior when they decide to share real and fake\nnews items on social media. In an attempt to do so, we performed an\nanalysis on data collected through a survey where participants (n= 363\n) were asked whether they were willing to share the given news item on\ntheir social media and explain the reasoning for their decision. The re-\nsults show that the analysis presents several commonalities with previous\nstudies. Moreover, we also addressed the problem of predicting whether\na person will share a given news item or not. For this, we used intrin-\nsic features from participants' open-ended responses and demographics\nattributes. We found that the perceived emotions triggered by the news\nitem show a strong in\ruence on the user's decision to share news items\non social media.\nKeywords: Fake News \u00b7News Sharing \u00b7Emotion \u00b7Misinformation \u00b7\nSocial Media.\n1 Introduction\nSocial media has emerged as popular information source people rely on for events,\nbreaking news, and emergencies. Indeed, it has become a source of daily news\ndiet for the increasingly large population. Statistics show that majority of the\npopulation (71% of American adults) ever get news through social media in\n2020 [24] which was increased by 3% since 2018 [23]. The landscape of news\nconsumption and information \row has drastically changed with the popularity\nof social media. It has transformed how news content is created, how people en-\ngage with news items, and share information, blurring the journalists' boundary\nCopyright \u00a92021 for this paper by its authors. Use permitted under Creative Com-\nmons License Attribution 4.0 International (CC BY 4.0). Presented at the MISINFO\n2021 Workshop, held in conjunction with the 30th ACM The Web Conference, 2021,\nin Ljubljana, Slovenia.\n\n2 A. Shrestha and F. Spezzano\nin traditional media that is \frst verifying and then disseminating only the ac-\ncurate news items [25]. Moreover, users in social media (both organizations and\nindividuals) actively participate in creating and sharing news items with friends,\nfamilies, and other readers due to its ease of use, lower cost, and convenience\nof further sharing [2, 29]. This shift of news paradigm has led to an unprece-\ndented transformation in both news quality and quantity that users encounter\nin social media, increasing the probability of potential encounters and the spread\nof fake news, fostering social media as a fertile ground for the production and\npropagation of fake news.\nThe sheer volume of fake news being observed in social media has recently be-\ncome an obvious cause of concern. Many studies have highlighted the character-\nistics of fake news through linguistic and psychological attributes [11,20,21,27],\nwriting styles [3,11,13], network-based attributes [7] and hybrid attributes con-\nsidering both linguistic and network [29].\nDespite several studies illustrating cues to identify fake news and mitigate\nits spread, there is a worrisome amount of fake news widely spreading over so-\ncial media. Fake news has been identi\fed as more likely to go viral than real\nnews, spreading faster and wider [35]. Additionally, an analysis of news about\nthe 2016 election conducted by BuzzFeed, also found more engagement with fake\nnews than real news [32]. Earlier studies analyzed the potential reason behind\nthis rapid di\u000busion of news in social media, focusing on various factors, in-\ncluding polarized communities of users with common belief (echo-chambers) [4],\nepidemiological models [12]. Some studies highlighted the actors responsible for\nspreading fake news, including bots and cyborgs [6]. Although bots are equally\nresponsible for spreading real and fake news, the considerable spread of fake\nnews is caused by human activity [30, 35] as people are generally not able to\naccurately identify which news item is fake and which is real [34]. Thus, it is\ncrucial to understand the people's sharing behavior of fake and real news on\nsocial media to minimize fake news di\u000busion.\nIn this context, this study seeks to better understand how people reason\nwhen they decide to share real news and fake news. In particular, we surveyed\n363 undergraduate students where we asked participants to report and explain\ntheir willingness to share given news item (with headline and image) on their\nsocial media. We also leveraged the demographic attributes of participants like\ngender and political orientation in our study. We performed a comprehensive\ndata analysis to investigate the pattern of news sharing behavior, the role of\ndemographics in news sharing decisions, and why people share real and fake\nnews. Furthermore, we addressed the problem of predicting whether a person\nwill share a given news item or not according to emotion, psychological, and\ndemographics features as a binary classi\fcation task.\nOur experiments show several commonalities with previous \fndings regarding\nnews sharing behavior.\n{News sharing is rare as only a small percentage (19.2% to 28.2%) of users\nexpressed the willingness to share news in social media, regardless of news\nveracity.\nAn Analysis of People's Reasoning for Sharing Real and Fake News 3\n{Female participants are prone to share more news than male participants\nregardless of news veracity.\n{Left-leaning participants tend to share real news more than fake news, inde-\npendently of the news source's political orientation, and right-leaning par-\nticipants were instead more prone to share news items from sources with the\nsame political-leaning, independently of news veracity.\n{The prominent themes illustrated by the approaches used by participants to\nmake their sharing decisions falls under subjectivity and the focus on others\ninterest or disinterest in news topic.\n{Emotion features are more e\u000bective in predicting people's willingness to share\na given news item.\n2 Related Work\nSeveral studies have been conducted to understand the characteristics of users\nthat are likely to contribute to spreading fake news on social networks. Vosoughi\net al. [35] revealed that the fake news spreaders had, on average, signi\fcantly\nfewer followers, followed signi\fcantly fewer people, and were signi\fcantly less\nactive on Twitter. Moreover, bots tend to spread both real and fake news, and\nthe considerable spread of fake news on Twitter is caused by human activity.\nShrestha and Spezzano showed that social network properties help in identifying\nactive fake news spreaders [26]. Shu et al. [30] analyzed user pro\fles to under-\nstand the characteristics of users that are likely to trust/distrust fake news. They\nfound that, on average, users who share fake news tend to be registered for a\nshorter time than the ones who share real news and that bots are more likely\nto post a piece of fake news than a real one, even though users who spread\nfake news are still more likely to be humans than bots. They also show that\nreal news spreaders are more likely to be more popular and that older people\nand females are more likely to spread fake news. Guess et al. [9] also analyzed\nuser demographics as predictors of fake news sharing on Facebook and found\nout political-orientation, age, and social media usage to be the most relevant.\nSpeci\fcally, people are more likely to share articles they agree with (e.g., right-\nleaning people tended to share more fake news because the majority of the fake\nnews considered in the study were from 2016 and pro-Trump), seniors tend to\nshare more fake news probably because they lack digital media literacy skills\nthat are necessary to assess online news truthfulness, and the more people post\nin social media, the less they are likely to share fake news, most likely because\nthey are familiar with the platform and they know what they share.\nShrestha et al. [28] analyzed the linguistic patterns used by a user in their\ntweets and personality traits as a predictor for identifying users who tend to\nshare fake news on Twitter data [22, 28]. Likewise, Giachanou et al. [8] pro-\nposed an approach based on a convolutional neural network to process the user\nTwitter feed in combination with features representing user personality traits\nand linguistic patterns used in their tweets to address the problem of discrimi-\nnating between fake news spreaders and fact-checkers.\n4 A. Shrestha and F. Spezzano\nFig. 1: News items used in our survey instrument.\nMa et al. [15] went beyond the user and news characteristics and analyzed\nthe characteristics of di\u000busion networks to explain users' news sharing behavior.\nThey found opinion leadership, news preference, and tie strength to be the most\nimportant factors at predicting news sharing, while homophily hampered news\nsharing in users' local networks. Also, people driven by grati\fcations of infor-\nmation seeking, socializing, and status-seeking were more likely to share news\non social media platforms [14].\n3 Data Collection\nWe conducted an online survey delivered via Qualtrics. Through this online sur-\nvey, participants were given four news headlines and accompanying images. For\neach news item, participants were asked whether they were willing to share the\ngiven news item on their social media and write an explanation of the reasoning\nfor their decision. We considered the four news items shown in Figure 1 and\ngathered from politifact.com . In this news set, two are real news items, and\ntwo are fake news items, as fact-checked by politifact.com . Both real and fake\nnews items are one from a left-leaning source and one from a right-leaning source.\nNews source political-leaning has been gathered from mediabiasfactcheck.com .\nWe recruited undergraduate students ( n= 363 ) from a volunteer pool in\ngeneral education social science courses (Psychology 101) to participate in our\nsurvey (258 F, 101 M, 4 Other; mean age 19.7, SD = 4.25). The research was ap-\nproved by the university IRB. Participants were compensated with course credit\n(volunteering for studies being one option for a research experience requirement).\nParticipants received no training.\nAn Analysis of People's Reasoning for Sharing Real and Fake News 5\nPercentage of Sharing\nNews Item 1 (Fake) 19.2%\nNews Item 2 (Fake) 22.9%\nNews Item 3 (Real) 20.0%\nNews Item 4 (Real) 28.2%\nTable 1: News Sharing Behavior.\n4 Data Analysis\nNews sharing is rare. We start the analysis of our data by observing that only\na small percentage of users expressed the willingness to share news in social\nmedia, independently of the veracity of the news. As shown in Table 1, this\npercentage ranges between 19.2% and 28.2% among the news considered in our\nsurvey. Previous research [10] has shown that sharing news articles from fake\nnews domains on Facebook was a rare activity during the 2016 U.S. presidential\ncampaign. Our data on fake news sharing is aligned with this result, but our\nrespondents also showed some preliminary evidence that this pattern may be\ntrue for real news sharing as well.\nThe role of demographics in news sharing. We collected demographic data from\nour survey participants, including gender, political orientation, and age. As most\nparticipants are in the same age range (18-25), we did not consider age in our\nanalysis.\nWhen looking at di\u000berences in sharing behavior according to gender (see\nFigure 2), we observe that the female participants were more prone to share\nboth the fake news items considered than male participants who were more\nskeptical about the same news items. Shu et al. [31] in his studies have shown a\nsimilar result where female users tend to trust fake news more than male users.\nIn general, females were more prone to share more news items than males (three\nvs. one).\nRegarding participants political orientation, we see two interesting patterns\nas reported in Figure 3: (1) left-leaning participants were more prone to share\nreal news than fake news, independently of the political orientation of the news\nsource; (2) right-leaning participants were instead more prone to share news\nitems from sources with the same political-leaning (news items 1 and 3), in-\ndependently of news veracity. Similarly, Guess et al. [10] have shown that, in\n2016, conservatives were more likely to share articles from pro-Trump fake news\ndomains than liberals or moderates.\nWhy people share real and fake news? Yaqub et al. [36] analyzed open-ended\nresponses of participants in the study where they explained the reason behind\ntheir intention to share true, false, and satire headlines. In their study, the most\nfrequent rationales behind sharing/not sharing news were (1) the interest/non-\ninterest towards the news, (2) the potential of generating discussion among the\n6 A. Shrestha and F. Spezzano\n(a) News item 1 (fake)\n (b) News item 2 (fake)\n(c) News item 3 (real)\n (d) News item 4 (real)\nFig. 2: Distribution of participant's gender.\nfriends, (3) the fact that the news is not relevant to the user's life, and (4) the\nperceived news credibility, especially as a motivation for not sharing news.\nWe conducted a similar analysis on a sample of our data (n=25). Speci\fcally,\nwe conducted a thematic analysis to identify the prominent themes that illus-\ntrated the approaches used by participants to make their sharing decisions. We\nfollowed an inductive approach to generating codes [5]. We found out the prin-\ncipal codes to be focused on potential others (\"My friends would/would not be\ninterested in this\"), interest or disinterest in the news topic, and subjectivity/the\nself (\"I would/wouldn't share this because...\", \"I would call that fake/real\") and\nare mostly aligned with the \fnding by Yaqub et al. [36].\nRegarding performing credibility assessment before making the sharing de-\ncision, we also found in our sample data that this was performed more often for\nfake news (28% of the times for news item 1 and 56% for news item 2) than for\nreal news (24% of the times for news item 3 and 16% for news item 4). Moreover,\nwhen performed, the credibility assessment was much more correct in the case\nof fake news (100% of the times for news item 1 and 93% for news item 2) than\nreal news (67% of the times for news item 3 and 25% for news item 4).\nOverall, the data analysis performed in this section shows that our collected\ndata presents several commonalities with previous studies, ensuring we have qual-\nity data suitable for further investigations.\nAn Analysis of People's Reasoning for Sharing Real and Fake News 7\n(a) News item 1\n(fake, right-leaning source)\n(b) News item 2\n(fake, left-leaning source)\n(c) News item 3\n(real, right-leaning source)\n(d) News item 4\n(real, left-leaning source)\nFig. 3: Distribution of participant's self-identi\fed political orientation.\n5 Predicting News Sharing\nIn this section, we address the problem of predicting whether a person will share\nor not a news item according to emotion and psychological features generated\nwhen they consider a news item and demographics (gender and political orien-\ntation) as well. We modeled the problem as a binary classi\fcation task where\nwe computed emotion and psychological features from participants' open-ended\nresponses to the survey question asking for an explanation of their decision to\nshare or not the given news item.\n5.1 Textual Features Extraction\nEmotion Features (Emotion) In order to compute a vector of scores quan-\ntifying participants' emotions when deciding whether or not to share a news\nitem, we considered their open-ended survey responses and proceeded as fol-\nlows. We started by cleaning responses' text by expanding contraction words,\ncorrecting misspellings and grammatical mistakes using LanguageTool1and re-\nplacing negated words with their WordNet antonym. Next, we extracted emo-\n1https://pypi.org/project/language-tool-python/\n8 A. Shrestha and F. Spezzano\ntions from the text by using the Emotion Intensity Lexicon (NRC-EIL) [18]\nand EmoLex [33]. Emotion features computed via NRC-EIL include anger, joy,\nsadness, fear, disgust, anticipation, surprise, and trust, while Emolex2features\ninclude happy, sad, angry, don't care, inspired, afraid, amused, and annoyed. Fea-\nture vectors have been computed by using the approaches proposed in [16,17]. In\naddition, we also considered emotion-related features as computed by the 2015\nLinguistic Inquiry and Word Count (LIWC) [19] tool, which includes e\u000bective\nprocesses like anxiety, anger, positive and negative emotion.\nPsycho-linguistic Features (LIWC) To understand the relationship between\npsychological states and the participants' decision-making, we considered the set\nof psycho-linguistic features computed by the Linguistic Inquiry and Word Count\n(LIWC) tool [19]. LIWC is a transparent text analysis tool that counts words in\npsychologically meaningful categories. Speci\fcally, we considered psychological\nprocesses that include social processes (e.g., family, friends), cognitive processes\n(e.g., think, cause, perhaps), perceptual processes (e.g., see, heard, felt), biologi-\ncal processes (e.g., eat, pain, love), relativity (e.g., area, move, day) and personal\nconcerns (e.g., work, leisure, achieve, home, money, religion, death).\nDemographics (Demog) As explicit features, we used participants' self-identi\fed\ngender and political orientation to understand if the demographic attributes pro-\nvide potential cues in predicting users' sharing decisions.\n5.2 Experimental Setting and Results\nWe used each group of features described in the previous section as input to\na random forest classi\fer to compute the performance of these features in pre-\ndicting whether a reader of a news item (a participant of our survey) is willing\nto share or not the given news item on their social networks. We also tried\nother classi\fers such as Support Vector Machine (SVM) and logistic regression,\nbut random forest achieved the best results. Hence, in the paper, we report the\nresults of random forest only. We used class weighting to deal with the class\nimbalance and performed 5-fold cross-validation.\nThe results are reported in Table 2 according to the area under the ROC\ncurve (AUROC), average precision (AvgP), and F1-measure (F1). As can be\nseen, when each feature group is considered separately, emotion features are the\nbest performing features compared to LIWC features and demographics with\n72% vs. 61% and 52% AUROC and 40% vs. 25% and 20% average precision\nfor news item 1, 71% vs. 61% and 57% AUROC and 42% vs. 31% and 25%\naverage precision for news item 2, 77% vs. 59% and 62% AUROC and 58%\nvs. 31% and 26% average precision for news item 3 and 78% vs. 61% and 59%\nAUROC and 56% vs. 40% and 42% average precision for news item 4 (bold\nin Table 2). We further considered a combination of all feature groups to see\n2https://sites.google.com/site/emolexdata/\nAn Analysis of People's Reasoning for Sharing Real and Fake News 9\nFeatures AUROC AvgP F1\nNews Item 1 (Fake)LIWC 0.611 0.247 0.166\nDemog 0.518 0.207 0.228\nEmotion 0.720 0.403 0.228\nAll 0.722 0.382 0.129\nNews Item 2 (Fake)LIWC 0.608 0.307 0.175\nDemog 0.565 0.250 0.325\nEmotion 0.706 0.416 0.162\nAll 0.707 0.421 0.122\nNews Item 3 (Real)LIWC 0.586 0.310 0.257\nDemog 0.617 0.258 0.300\nEmotion 0.771 0.578 0.477\nAll 0.796 0.585 0.439\nNews Item 4 (Real)LIWC 0.611 0.397 0.302\nDemog 0.590 0.317 0.356\nEmotion 0.784 0.564 0.423\nAll 0.786 0.562 0.359\nTable 2: Comparison of emotion, psycho-linguistic, and demographic features to\npredict whether a news item will be shared or not. We used a random forest\nclassi\fer. Best results among feature groups considered separately are in bold.\nBest overall results are shaded.\nif combining demographics, psychological and emotional features can provide\ncomplementary information that can help improve the prediction. We observed\nthat when the combination of all feature groups is considered, the performance\nremained more or less the same if not improved according to AUROC (shaded\nin Table 2). This demonstrates that emotion features are more e\u000bective than\nother groups of features considered in our study for predicting people's sharing\nbehavior. Hence, one of the motivations for potential news-sharing behavior in\nsocial media could be emotional persuasion. It will not be inaccurate to say that\nbeing persuaded by strong emotions like anger, fear, surprise, joy, etc., triggered\nby news content, people tend to get involved and share more news on social\nmedia. This \fnding aligns with the previous research by Berger et al. [1] which\nalso states that emotional arousal tends to increases the likelihood of sharing\nnews on social media.\n6 Conclusion and Future Work\nTo sum up, this paper presents \fndings from studying people's reasoning when\nthey decide to share real and fake news items provided with headlines and im-\nages. This paper investigates the correlation between the user's sharing decision\nand explicit attributes provided by participants like demographics and politi-\ncal orientation. Furthermore, we addressed the problem of predicting whether\na person will share a given news item or not using intrinsic features like psy-\n10 A. Shrestha and F. Spezzano\nchological and emotion from participants' open-ended responses explaining their\nwillingness to share given news item along with demographics attributes.\nThe results show that news sharing is rare, and among the participants ex-\npressing willingness to share, females are prone to share more news in general.\nParticipants' political orientation exerts a signi\fcant pattern on news sharing\nbehavior that is left-leaning participants' news sharing behavior is motivated by\nnews veracity rather than political orientation. In contrast, it is the other way\naround for right-leaning participants. Likewise, it shows the possibility of users\nsharing news items depends on the perceived relevance of news interest among\nfriends and families. Moreover, this paper also highlights that the perceived emo-\ntions triggered by the news item show a strong in\ruence on user's news sharing\nbehavior in social media.\nOne potential limitation of our study is that we have considered only four\nnews of each political leaning (2 fake and 2 real). Considering a bigger set of\nnews items could have shown signi\fcant patterns and support to our \fndings.\nFurthermore, this work focuses on a younger sample of the limited range of age,\ndue to which we did not consider age in demographic attributes. It could have\nadded some more insights regarding news sharing behavior among di\u000berent age\ngroups if we could consider participants of a wide range of ages (from younger\nto older population). We will address these limitations in our future work.\nAcknowledgements\nThis work has been supported by the National Science Foundation under Award\nno. 1943370. We thank Brian Stone for facilitating the data collection and Ashlee\nMilton and Maria Soledad Pera for providing us with the code used in their\npapers [16,17] to compute emotional features.\nReferences\n1. Berger, J.: Arousal increases social transmission of information. Psychological\nscience 22(7), 891{893 (2011)\n2. Bruns, A., High\feld, T., Lind, R.A.: Blogs, twitter, and breaking news: The\nprodusage of citizen journalism. Produsing theory in a digital world: The\nintersection of audiences and production in contemporary theory 80(2012), 15{32\n(2012)\n3. Castillo, C., Mendoza, M., Poblete, B.: Information credibility on twitter. In:\nProceedings of the 20th international conference on World wide web. pp. 675{684\n(2011)\n4. Del Vicario, M., Bessi, A., Zollo, F., Petroni, F., Scala, A., Caldarelli, G.,\nStanley, H.E., Quattrociocchi, W.: The spreading of misinformation online.\nProceedings of the National Academy of Sciences 113(3), 554{559 (2016)\n5. DNSc, J., Strauss, A.: Basics of Qualitative Research: Techniques and Procedures\nfor Developing Grounded Theory. SAGE Publications, Inc, Los Angeles, fourth\nedition edn. (Dec 2014)\nAn Analysis of People's Reasoning for Sharing Real and Fake News 11\n6. Ferrara, E., Varol, O., Davis, C., Menczer, F., Flammini, A.: The rise of social\nbots. Communications of the ACM 59(7), 96{104 (2016)\n7. Gayo-Avello, D., Metaxas, P.T., Mustafaraj, E., Strohmaier, M., Schoen, H.,\nGloor, P., Castillo, C., Mendoza, M., Poblete, B.: Predicting information\ncredibility in time-sensitive social media. Internet Research (2013)\n8. Giachanou, A., Rissola, E.A., Ghanem, B., Crestani, F., Rosso, P.: The role of\npersonality and linguistic patterns in discriminating between fake news spreaders\nand fact checkers. In: Natural Language Processing and Information Systems:\n25th International Conference on Applications of Natural Language to\nInformation Systems, NLDB 2020. p. 181. Springer Nature\n9. Guess, A., Nagler, J., Tucker, J.: Less than you think: Prevalence and predictors\nof fake news dissemination on facebook. Science advances 5(1), eaau4586 (2019)\n10. Guess, A., Nagler, J., Tucker, J.: Less than you think: Prevalence and predictors\nof fake news dissemination on facebook. Science Advances 5(1) (2019)\n11. Horne, B.D., Adali, S.: This just in: Fake news packs a lot in title, uses simpler,\nrepetitive content in text body, more similar to satire than real news. In: The 2nd\nInternational Workshop on News and Public Opinion at ICWSM (2017)\n12. Jin, F., Dougherty, E., Saraf, P., Cao, Y., Ramakrishnan, N.: Epidemiological\nmodeling of news and rumors on twitter. In: Proceedings of the 7th workshop on\nsocial network mining and analysis. pp. 1{9 (2013)\n13. Jin, Z., Cao, J., Zhang, Y., Luo, J.: News veri\fcation by exploiting con\ricting\nsocial viewpoints in microblogs. In: Proceedings of the AAAI Conference on\nArti\fcial Intelligence. vol. 30 (2016)\n14. Lee, C.S., Ma, L.: News sharing in social media: The e\u000bect of grati\fcations and\nprior experience. Computers in human behavior 28(2), 331{339 (2012)\n15. Ma, L., Lee, C.S., Goh, D.H.: Understanding news sharing in social media from\nthe di\u000busion of innovations perspective. In: 2013 IEEE International Conference\non Green Computing and Communications and IEEE Internet of Things and\nIEEE Cyber, Physical and Social Computing. pp. 1013{1020. IEEE (2013)\n16. Milton, A., Batista, L., Allen, G., Gao, S., Ng, Y., Pera, M.S.: \"don't judge a\nbook by its cover\": Exploring book traits children favor. In: RecSys 2020:\nFourteenth ACM Conference on Recommender Systems, Virtual Event, Brazil,\nSeptember 22-26, 2020. pp. 669{674. ACM (2020)\n17. Milton, A., Pera, M.S.: What snippets feel: Depression, search, and snippets. In:\nCantador, I., Chevalier, M., Melucci, M., Mothe, J. (eds.) Proceedings of the\nJoint Conference of the Information Retrieval Communities in Europe (CIRCLE\n2020), Samatan, Gers, France, July 6-9, 2020. CEUR Workshop Proceedings,\nvol. 2621 (2020)\n18. Mohammad, S.: Word a\u000bect intensities. In: Proceedings of the Eleventh\nInternational Conference on Language Resources and Evaluation, LREC 2018,\nMiyazaki, Japan, May 7-12, 2018. European Language Resources Association\n(ELRA) (2018)\n19. Pennebaker, J.W., Boyd, R.L., Jordan, K., Blackburn, K.: The development and\npsychometric properties of liwc2015. Tech. rep. (2015)\n20. P\u0013 erez-Rosas, V., Kleinberg, B., Lefevre, A., Mihalcea, R.: Automatic detection of\nfake news. In: Proceedings of the 27th International Conference on\nComputational Linguistics. pp. 3391{3401 (2018)\n21. Potthast, M., Kiesel, J., Reinartz, K., Bevendor\u000b, J., Stein, B.: A stylometric\ninquiry into hyperpartisan and fake news. In: Proceedings of the 56th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long\nPapers). pp. 231{240 (2018)\n12 A. Shrestha and F. Spezzano\n22. Rangel, F., Giachanou, A., Ghanem, B., Rosso, P.: Overview of the 8th author\npro\fling task at pan 2020: Pro\fling fake news spreaders on twitter. In: CLEF\n(2020)\n23. Shearer, E., Matsa, K.E.: News use across social media platforms 2018. Pew\nResearch Center (2018)\n24. Shearer, E., Mitchell, A.: News use across social media platforms in 2020. Pew\nResearch Center (2020)\n25. Shoemaker, P.J., Vos, T.P., Reese, S.D.: Journalists as gatekeepers. The\nhandbook of journalism studies 73(2009)\n26. Shrestha, A., Spezzano, F.: Online misinformation: from the deceiver to the\nvictim. In: ASONAM '19: International Conference on Advances in Social\nNetworks Analysis and Mining. pp. 847{850. ACM (2019)\n27. Shrestha, A., Spezzano, F.: Textual characteristics of news title and body to\ndetect fake news: A reproducibility study. In: Advances in Information Retrieval -\n43rd European Conference on IR Research, ECIR 2021, Proceedings, Part II.\nLecture Notes in Computer Science, vol. 12657, pp. 120{133. Springer (2021)\n28. Shrestha, A., Spezzano, F., Joy, A.: Detecting fake news spreaders in social\nnetworks via linguistic and personality features. In: CLEF (2020)\n29. Shu, K., Sliva, A., Wang, S., Tang, J., Liu, H.: Fake news detection on social\nmedia: A data mining perspective. ACM SIGKDD explorations newsletter 19(1),\n22{36 (2017)\n30. Shu, K., Wang, S., Liu, H.: Understanding user pro\fles on social media for fake\nnews detection. In: 1st IEEE International Workshop on Fake MultiMedia\n(FakeMM 2018) (2018)\n31. Shu, K., Wang, S., Liu, H.: Understanding user pro\fles on social media for fake\nnews detection. In: 2018 IEEE Conference on Multimedia Information Processing\nand Retrieval (MIPR). pp. 430{435. IEEE (2018)\n32. Silverman, C.: This analysis shows how viral fake election news stories\noutperformed real news on facebook. BuzzFeed News 16(2016)\n33. Song, K., Gao, W., Chen, L., Feng, S., Wang, D., Zhang, C.: Build emotion\nlexicon from the mood of crowd via topic-assisted joint non-negative matrix\nfactorization. In: Proceedings of the 39th International ACM SIGIR conference\non Research and Development in Information Retrieval, SIGIR 2016. pp.\n773{776. ACM (2016)\n34. Spezzano, F., Shrestha, A., Fails, J.A., Stone, B.W.: That's fake news!\ninvestigating how readers identify the reliability of news when provided title,\nimage, source bias, and full articles. Proceedings of the ACM on Human\nComputer Interaction journal 5(CSCW1, Article 109) (2021)\n35. Vosoughi, S., Roy, D., Aral, S.: The spread of true and false news online. Science\n359(6380), 1146{1151 (2018)\n36. Yaqub, W., Kakhidze, O., Brockman, M.L., Memon, N., Patil, S.: E\u000bects of\ncredibility indicators on social media news sharing intent. In: Proceedings of the\n2020 CHI Conference on Human Factors in Computing Systems. p. 1{14. CHI '20\n(2020)", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "An analysis of people's reasoning for sharing real and fake news", "author": ["A Shrestha", "F Spezzano"], "pub_year": "2021", "venue": "NA", "abstract": "The problem of the increase in the volume of fake news and its widespread over social media  has gained massive attention as most of the population seeks social media for daily news"}, "filled": false, "gsrank": 129, "pub_url": "https://scholarworks.boisestate.edu/cs_facpubs/296/", "author_id": ["8lhmF9oAAAAJ", "u_5TCGoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:PTYXfwBUxVIJ:scholar.google.com/&output=cite&scirp=128&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D120%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PTYXfwBUxVIJ&ei=GrWsaJ6pKcDZieoPqdqh8QU&json=", "num_citations": 4, "citedby_url": "/scholar?cites=5964265642631050813&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:PTYXfwBUxVIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://scholarworks.boisestate.edu/cgi/viewcontent.cgi?article=1304&context=cs_facpubs"}}, {"title": "Multimodal Political Bias Identification and Neutralization", "year": "2025", "pdf_data": "arXiv:2506.17372v1  [cs.CY]  20 Jun 2025Multimodal Political Bias Identification and Neutralization\nCedric Bernard\ncedricb@vt.eduXavier Pleimling\nxavierp7@vt.eduAmun Kharel\nakharel@vt.eduChase Vickery\ncdvickery@vt.edu\nAbstract\nDue to the presence of political echo chambers, it be-\ncomes imperative to detect and remove subjective bias and\nemotionally charged language from both the text and im-\nages of political articles. However, prior work has focused\non solely the text portion of the bias rather than both the text\nand image portions. This is a problem because the images\nare just as powerful of a medium to communicate informa-\ntion as text is. To that end, we present a model that lever-\nages both text and image bias which consists of four dif-\nferent steps. Image Text Alignment focuses on semantically\naligning images based on their bias through CLIP models.\nImage Bias Scoring determines the appropriate bias score\nof images via a ViT classifier. Text De-Biasing focuses on\ndetecting biased words and phrases and neutralizing them\nthrough BERT models. These three steps all culminate to\nthe final step of debiasing, which replaces the text and the\nimage with neutralized or reduced counterparts, which for\nimages is done by comparing the bias scores. The results so\nfar indicate that this approach is promising, with the text de-\nbiasing strategy being able to identify many potential biased\nwords and phrases, and the ViT model showcasing effective\ntraining. The semantic alignment model also is efficient.\nHowever, more time, particularly in training, and resources\nare needed to obtain better results. A human evaluation\nportion was also proposed to ensure semantic consistency\nof the newly generated text and images.\n1. Problem Statement\nIn a study conducted in 2015, researchers analyzed ap-\nproximately 150 million tweets from 3.8 million Twitter\nUsers, each pertaining to political and nonpolitical issues.\nIn this study, researchers observed that people who share\nthe same ideologies when it comes to political topics ex-\nchange information with each other much more than those\nwho share different ideologies [2]. Through empirical ob-\nservation, the Internet and social media are the primary\nnews distributors today. Since we distribute news on a pub-\nlic platform, social media either acts as a public sphere that\ncan host a variety of opinions and information or an echochamber that strengthens views that it is built upon [7].\nWe postulate that the most significant contributor to the\npresence of political echo chambers in social media is the\npresence of subjective bias or emotionally charged lan-\nguage in the texts. In addition, propaganda is widespread\nin the news through cleverly crafted political images. For a\nhealthy exchange of ideas between people of different polit-\nical persuasions in social media, political images, and text\nshould adhere to Dahlberg\u2019s six essential qualities of the\nPublic Sphere. The six qualities are namely: Reasoned Ex-\nchange of Problematic Validity Claims, Reflexivity, Ideal\nRole Taking, Sincerity, Formal Inclusion and Discursive\nEquality, and Autonomy from State and Corporate Power\n[8, 23]. We need to cultivate these essential qualities in the\ndomain of news and news distribution by debiasing images\nand texts in the news to make them objective and neutral\nregardless of their political standing.\nIn previous work on text debiasing in the context of\nnews, researchers aimed to debias text by finding methods\nto make the text more neutral [20]. Text debiasing was\ndone by removing subjective bias using the method pro-\nvided by [22]: using Wikipedia\u2019s Neutral Point of View\n(NPOV) policy. However, for debiasing political images,\nthe work performed on it is very limited and not well ex-\nplored. We will perform cross-modal alignment of textual\nimages and news to solve the problem of debiasing political\nimages. Then we will select the image with the least bias\nusing the method in [26]. In summary, our work attempts to\nlearn an algorithm to minimize and neutralize political bias\nin news articles.\n2. Related Works\n2.1. Debiasing\nMachine learning and deep learning models are trained\non a large set of texts and images from the real world.\nThese images and texts may contain gender, cultural, re-\nligious, political, and other social biases [16]. Several\nworks have been proposed to address the problem of bi-\nases in real-world models. Some previous work was cen-\ntered around debiasing the sentence level representations,\nwhich removes the religious, gender, racial, and cultural bi-\nases [16,17]. [16] in particular analyzes the performance of\ndebiasing on sentence-level downstream tasks such as senti-\nment analysis, linguistic acceptability, and natural language\nunderstanding.\nFor political bias detection, [5] uses over 6900 news\narticles with labels derived from a website to develop a\nneural model for bias assessment, and [20] both analyzes\nsubjective bias in text and neutralizes the subjective bias.\nThere are two core problems with political news, which are\nnamely subjective or biased language and news, and selec-\ntive news reporting. [20] is used to address the first issue\nof modifying subjective bias in a paper, giving an exam-\nple where the paper converts the sentence \u201cJohn McCain\nexposed as an unprincipled politician\u201d to \u201cJohn McCain de-\nscribed as an unprincipled politician,\u201d which changes the\nsubjective tone to a more objective one.\nThese works are able to analyze biases in pre-trained\nlanguage models and vision models individually, however,\nonly a few works have been done on a multi-modal set-\nting [25]. In terms of these works, [25] does research to\ndemonstrate gender bias in VL-BERT, which works in a\nmulti-modal setting. Additionally, [26] collects a dataset\nof over one million unique images and associated news ar-\nticles from left- and right-leaning news sources to develop a\nmethod to predict the image\u2019s political leaning. [27] models\na real-world scenario where image-text pairs convey com-\nplementary information with little overlap. The approach\nused in [27] helps preserve the semantic relationships be-\ntween paired images and paired text. We can generate a\nseries of semantically aligned images from [27] given a text\nor news headline.\nThe objective of our project is to remove the subjectivity\nof the news and replace the news images with semantically\naligned images that are politically less biased. Using mulit-\nmodal information to reduce bias allows models to leverage\na wider amount of information and reduce bias more effec-\ntively than uni-modal models.\n2.2. Political Bias Identification (Images)\nRegarding work related to political image debiasing,\nsome existing papers focused on finding and predicting po-\nlitical bias within images. For example, [26] utilizes a two-\nstep process where a model first learns relevant visual con-\ncepts of an image to enable bias prediction. Then, a visual\nclassifier is trained upon that model. In terms of political\nimage debiasing, [14] aims to evaluate and proposes met-\nrics for measuring bias and bias augmentation in image text\npairs, as well as how current models and datasets perpet-\nuate and increase bias, but does not provide work on how\nto remove bias from image and text caption pairs. Addi-\ntionally, [3] studies non-verbal bias indicators in facial fea-\ntures of political images and statistical analysis of news arti-\ncles published around the 2016 election. Other works, such\nas [19], use facial feature extraction methods to identifyand correlate certain visual elements with various kinds of\nbias. This work shows that different political figures are dis-\nplayed quantifiably differently depending on political orien-\ntation and outlet. Finally, several approaches to other more\ngeneral image bias-related tasks could be extended to po-\nlitical bias identification. For identifying bias in images,\nsome work focuses on reducing bias to attribute/label data\nprovided with or extracted from the data [12]. Other com-\nmon approaches focus on learning from lower-dimensional\nrepresentations or determining bias by cross-analyzing mul-\ntiple datasets [12]. A more recent and uncommon approach\nutilizes an ensemble classification system by training a low-\ncapacity network and a high-capacity network to reduce\nbias [6, 12]. Overall, while several methods allow for iden-\ntifying bias in images, most of these methods are, to our\nknowledge, not applied or extended to the political domain.\nMoreover, some approaches are not viable to perform re-\ngardless since annotating and performing cross-analysis on\nmultiple datasets can be far too computationally expensive.\n2.3. Political Bias Identification (Text)\nMultiple techniques have been used in previous works\nto identify and reduce bias in the text. [20] and [24] use\npre-trained BERT transformers to locate and correct biased\nwords. [30] and [18] use adversarial training to create a\nclassifier to detect and correct hate speech. [13] uses an\nattention-based mechanism on the article headline network\nto detect bias in the article body to mirror the order in which\nhumans read articles. [4] uses a Gaussian mixture model to\nobserve probability distributions of the frequency, positions,\nand order of information to detect article-level bias. Re-\ngarding text dataset annotation, [10] proposes a framework\nto decompose gender biases across multiple dimensions, in-\ncluding the gender of the speaker, the person being spoken\nto, and the person being talked about.\nHowever, these previous approaches don\u2019t leverage or in-\nteract with available visual data or only focus on correcting\nspecific types of bias, i.e., gender, politics, and hate speech.\nBy also processing images available in the article, our ap-\nproach can use the images to inform the text bias and vice\nversa, as well as substitute the biased images with seman-\ntically similar ones but evaluated with a lower amount of\nbias.\n2.4. Evaluations/Metrics/Losses in Similar Ap-\nproaches\nDue to the varied approaches in bias detection and de-\nbiasing in related works, several different methods are\nalso used for evaluations. Frequently, individual datasets\nare scraped and developed by separate groups for specific\nprojects. This approach tends to result in datasets where\narticles, usually just represented through the text modal-\nity, have been manually labeled with one particular kind\nof bias [4, 13], lending the ability to use these labels in a\nsupervised classification task which identifies an article or\nsentence as biased. Bias detection here can vary between\na binary classification (biased vs. neutral) or multi-class\n(biased towards one of a set of groups). Other works use\nexisting corpora to identify and potentially correct biased\nlanguage [20, 28]. In most cases concerning bias detection\nwith these datasets, a popular evaluation metric is to check\nthe model\u2019s accuracy in classifying it as biased in binary or\nmulti-class settings.\nWhen evaluating text debiasing methods, basic natural\nlanguage metrics such as BLEU can be used [20]. Human\nevaluations are also crucial for understanding the effective-\nness of debiasing models, with graders manually deciding\non how fluent an original and corresponding debiased text\nare and whether they have the same meaning [20].\n2.5. Politics Dataset\nWe will use the dataset collected in [26]. This dataset\nis collected from biased news sources (from left/right) on\n20 politically contentious issues such as Abortion, Black\nLives Matter, LGBT, Welfare, etc. This dataset has around\n1.8 million images/articles in total. This paper uses crowd-\nsourced annotations to annotate over 14,000 sets that con-\ntain bias labels for images and image-text pairs alongside\nother metadata. Various curation mechanisms have been\nused to clean up the data from news sources. Also, the\ncrowdsourced annotations are curated with quality control.\nAlthough [26] identifies the bias as left/right-leaning, this\npaper does not have labels for neutral news sources.\nAnother dataset that we will use is the Wiki Neutral-\nity Corpus (WNC). WNC contains 180,000 sentence pairs\nwith biased and neutralized information, metadata, and ad-\nditional contextual sentences, which were all scraped from\nWikipedia edits that ensured texts were as unbiased as pos-\nsible [20]. This dataset will neutralize the biases in the text\nof political news articles.\n3. Proposed Approach\nFigure 1 illustrates our overall architecture. Images and\nTexts that are used to train this model will be retrieved from\nvarious left-leaning, and right-leaning websites from the\nPolitics Dataset [26]. Based on their political leaning, we\nlabeled the website from a score of -1 to 1 on a continuous\nscale. We scored -1 for far-left websites and 1 for right-\nleaning websites. We shared a score of 0 for neutral web-\nsites. For example, a score of -0.49 would be moderately\nleft-leaning. We got these websites\u2019 scores from mediabi-\nasfactcheck.com, from which the political dataset was used\nto determine left and right-leaning sources. For websites we\ndid not have a score, we looked at their wording, sourcing,\nstory choices, and political affiliation to give them a score\nfrom -1 to 1.\nFigure 1. Overall Architecture\nSection 3.1 will identify biased words in the articles us-\ning the BERT [20] Biased Word Predictor. Then, we will\ntrain a BERT model with image and text inputs. Specifi-\ncally, we will use Wikipedia images and text to generate an\nembedding space with unbiased images and text. During\ninference, we will mask the biased words and replace them\nwith objective alternatives.\nSection 3.2 will use the CLIP [21] model to generate\nCross-Modal Embedding Space with different biases. Dur-\ning inference, we will use the de-biased text from Section\n3.1 to generate a de-biased image for our news article.\nLastly, we will use the pre-trained Vision Transformer\n[11] used in Section 3.2 to predict the bias of each image in\nSection 3.3. We will fine-tune the Vision Transformer with\nmore images and its respective labels.\n3.1. Text Bias Identification and Neutralization\nOur architecture for Text Bias Identification and Neutral-\nization can be seen in Figure 2. First, we use the detection\nmodule from [20] to find biased words from news articles.\nGiven an input sentence, we will generate an output sen-\ntence that is semantically similar to the input, but the bias\nwill be neutralized. The source sentences will be passed\nthrough a BERT model [9] to determine the bias probabil-\nity of each word of the source sequence using the technique\npresented in [20]. The source sequence will be from the\nPolitics Dataset\u2019s news article.\nWe will fine-tune a visual BERT model with paired neu-\ntral image/text data (Wikipedia images and text) [15]. First,\nwe will use the biased words detected from the detection\nmodule and mask them. After that, we will encode the ar-\nticle images into a sequence of tokens. Finally, the BERT\nNeutral Word Predictor will take in the encoded image se-\nquence and the masked article text to predict the masked\nbiased words and create a new sentence that has reduced\nbias.\nFigure 2. Text Bias Neutralization\nFigure 3. Semantic Alignment Model\n3.2. Semantically Aligned Images\nThe second primary step of the approach is performing\nsemantic alignment based on the bias score introduced in\nthe description of the overall architecture. We would do this\nby creating semantic neighborhoods following the process\nof [27]. Angular loss, an alternative to triplet loss, is used\nwith a CLIP model to develop semantic alignment between\nimages using existing semantics in the text [27, 29]. The\nangular loss is:\nLang= [||xa\u2212xp||2\u22124 tan2\u03b1||xn\u2212xc||2](1)\nHere, xarepresents an anchor image, xpis a semantic near-\nest neighbor of xain the Doc2Vec space, xnis a randomnegative sample where that is not xa, andxc=xa+xp\n2[27].\nA semantic nearest neighbor is one that is one of the 200\nnearest neighbors to the anchor in Doc2Vec space. This\nloss can also be applied to the text representations of each\nsample to keep semantically related text close in the embed-\nding space. This loss enforces that the texts are semantically\nplaced close to each other and using them to create a link\nbetween their respective images so that visually distinct im-\nages with similar meanings will be nearby in the semantic\nspace. The ground-truth semantic similarity would be gen-\nerated using a pre-trained Doc2Vec model because an unsu-\npervised embedding learning was needed to gauge original\nsemantic similarity, and Doc2Vec can do this while provid-\ning relative semantic representations between samples.\nA new loss specific to this image debiasing task is also\ndeveloped to account for the bias of images in this shared\nspace. Aside from the angular loss that draws together dis-\ntinct images of the same topic, the images should also be\nseparated by bias. This process is done with another angu-\nlar loss objective in which we create positive pairs using an\nimage with similar bias of the anchor and negative pairs us-\ning an image with a different bias score. Again, this can be\nformulated as:\nLang= [||xa\u2212B(xa)||2\u22124 tan2\u03b1||xn\u2212xc||2](2)\nwhere Bb(xa)is a function that randomly samples an im-\nage from the bias neighborhood of xa. Images within a\nbias score range of 10% of an anchor image are consid-\nered as part of the anchor\u2019s bias neighborhood. The range\nof 10% can be changed, but 10% was the starting range be-\ncause our manual scoring typically varied by 5 or 10% of\nother scores. This way, the original angular loss will group\nsemantically-aligned images, and the images will be further\ngrouped based on bias scores (e.g., the semantic-alignment\nloss provides a group of images about the topic \u201cclimate\nchange\u201d and the new bias loss separates those images into\na spread of left, right, and neutrally biased scores). Fig-\nure 4 visualizes how this loss affects the embedding space.\nWith this, retrieval can be performed with debiased text,\nwhich will locate the nearest image that is both semanti-\ncally similar and neutrally biased. Here, the model would\ntake the debiased text as the input and feed it through a text-\nto-image cross-modal retrieval process to retrieve an image\nas the output. The nearest semantic image would be the\ndesignated debiased image allowing the model to perform\nimage debiasing by \u201creplacing\u201d the query image with a less\nbiased alternative with similar semantics. We will use the\nImage Bias Prediction in Section 3.3 to get the least biased\nimage if the manually-scored bias is not already available\nin the database. This score-based system was used in place\nof a classification-focused approach because we wanted to\ncapture a more precise granularity of bias which we can do\nusing a scale rather than classes.\n3.3. Image Bias Prediction\nThe ViT model in Figure 5 is trained in Section 3.2.\nWe will fine-tune this model further with more images and\nits respective bias score. Finally, we will pass an image\nthrough this model at inference, giving us a score from -1\nto 1.\n4. Results\n4.1. Bias Word Identification\nFor the bias word identification algorithm, quantitative\nevaluations were considered but the quantitative results\nFigure 4. Bias Loss. Text embeddings are represented as cir-\ncles and image embeddings by squares. Here, the red, gray, and\nblue, embeddings have already been pulled together by semantic\nalignment loss. The bias loss then aligns the image representa-\ntions in space based on their bias. Images that have a similar bias\nare pulled away from one another while being pushed away from\nimages with different bias, creating regions of bias scores in the\nembeddings space. Debiased text that is fed into the space for\nretrieval should be near images that are semantically similar and\nsimilar (neutral) in bias.\nFigure 5. Image Bias Prediction\nfrom [20] were generated in conjunction with the neutral-\nization portion of the algorithm, so there was no appropriate\nbaseline to consider. Furthermore, it is difficult to perform\nquantitative results on our own dataset because we do not\nhave a ground truth component unlike the Wikipedia Neu-\ntrality Corpus (WNC), which contains debiased forms of\nbiased text. For these reasons, a qualitative approach is con-\nsidered instead which can be seen in Figure 6, and Figure\n7. For implementation, the hidden size is 768, the number\nof layers is 12, and the learning rate for the results given is\n0.0001. Due to time constraints, the model was trained on\nat most one epoch of the dataset.\nFigure 6. Predicting the bias of BERT tokens with examples from\n[20] and WNC, respectively. The ground truth value is highlighted\nwith a blue border. The words with a higher probability for bias\n(>0.5) are shaded light red, with the most biased being shaded a\ndarker red.\nFigure 7. Predicting the bias of BERT tokens with examples from\nthe Politics Dataset. The color is: red for most biased, lighter red\nfor>0.9, pink for >0.75, light purple for >0.5, and no color\notherwise. The corresponding words in the text are highlighted\nwith this color scheme.\nThe results showcase that the detection model is often\nhelpful in identifying the most biased word. For the first\nexample of Figure 6, the exact word is identified, and for\nthe second example it is within the top 5 biased words. For\nFigure 7, since there is no ground truth, potential improve-\nments in regards to bias need to be visually identified. For\nthis example, \u201dthe [sic] capitalise\u201d is the best candidate for\nchange because the phrase implies that the author of the text\nbelieves that the leader in question is taking intentional ad-\nvantage which is subjective. All tokens associated with this\nphrase are within the top 5 and have a probability of >0.9.\nHowever, this model does appear to be sensitive to the\npresence of punctuation, rare words, and long sentences. In\nthe second example of Figure 6, there are several tokens\nplaced ahead of the ground truth token, being ., 2003, amer-\nican, and ali. It is possible that the model may require more\ntraining to generate more probable results, as 2003, ali, and\nmost punctuation do not imply any bias. The model also de-\ngrades as the statements get longer, which may be expectedbecause the training is performed on a dataset containing\nstatements that are shorter on average compared to the ones\non the Politics Dataset.\n4.2. Bias Word Neutralization\nTo evaluate the performance of the biased word neutral-\nization, we evaluate the cosine similarity between the orig-\ninal word and the newly generated word. This is done be-\ncause we want the new word to be semantically similar to\nthe original word, so they should have similar vectors in a\nword vector embedding space. For the evaluation, the word\nvectors are generated from a pre-trained word vector trained\non 16B tokens from Wikipedia, the UMBC web-base cor-\npus, and statmt.org news datasets. The word vector model\nis available here [1].\nOver 1000 test samples from the politics dataset were\nfirst passed through the biased word identification module\nthen used to evaluate the bias word neutralization module,\nThe bias word neutralization module achieved an average\ncosine similarity of 0.3960 between the original word and\nthe re-predicted word. We can compare this amount to the\ncosine similarity of a pair of synonyms, eg. the words \u201dva-\ncation\u201d and \u201dholiday\u201d produce a cosine similarity score of\n0.2400. The average of 0.3960 is substantially higher indi-\ncating that the model is not producing synonymous words\nin the majority of cases. Qualitatively we can see that in\nsome cases it makes sensible predictions, however it fails\nin cases where larger context is needed. For example in\na sentence talking about a military members discharge, the\nmodule replaced the masked word \u201ddischarged\u201d with \u201dgrad-\nuate\u201d, clearly missing the broader context that the person\nwas leaving the armed force rather than joining them.\n4.3. Image Alignment\nAdditionally, a pre-trained CLIP model is used and fine-\ntuned using a modified triplet loss to improve semantic\nalignment between text and images in a shared embedding\nspace [21, 27]. Performing this semantic alignment using\ntext to guide the images provides the backbone for finding\npotential replacement images of the same object and possi-\nble images of concepts that relate to the image in context,\ni.e., connect to the same topic as that of the image. Image\ndebiasing is a retrieval task, with heavily biased samples\nbeing processed and used to find images of similar objects\nand topics with less bias. To test its retrieval ability, the\nbias from the newly retrieved image will be measured and\ncompared against the bias of the original image. Equation 3\nmeasures the average bias of retrieved images in the test set,\nand Equation 4 measures the average divergence towards\nneutrality of the retrieved images as compared to the origi-\nnal images in the test set.\n1\n|Y|X\ny\u2208Y|b(N(y))| (3)\n1\n|Y|X\nx,y\u2208X,Y(|b(x)| \u2212 |b(N(y))|) (4)\nwhere X, Y is the set of test images and text, respectively,\nfrom the Politics dataset, bis the bias function of an im-\nage that returns the ground truth bias for known images in\nthe embedding space and estimated bias for newly scored\ninput images, and Nis a function that returns the nearest\nimage to the input text, y. A low average bias and high\naverage difference would indicate that retrieved images are\nboth neutral on an absolute scale and relative to the original\nimages.\nQualitative evaluations are also important for evaluating\nretrieval effectiveness. Figure 8 shows a pair of images re-\ntrieved from biased input text \u201dPolitician has been exposed\nas anti-science.\u201d and neutral text \u201dPolitician has been de-\nscribed as anti-science.\u201d These texts were not taken from\nthe dataset as time constraints prevented final merging of all\nmodules. The input text only deals with the topic of science,\nwhile the relation of each image has unclear implications in\nrelation to science as well as unclear bias considering the\ntopic. This could be due to the decreased training set size or\nthe relatively low training time for the alignment. It is also\npossible that some aspect of the bias loss interferes with the\nsemantic alignment in a negative way, which could indicate\nthat more ablations with the bias weighting could be done.\nFigure 8. This is an example of retrieved images from the test-\ning space of the last image debiasing checkpoint. a) More biased\ninput text \u201dPolitician has been exposed as anti-science.\u201d retrieved\na somewhat generic image from the right-leaning, climate change\ncategory. b) More neutral input text \u201dPolitician has been described\nas anti-science.\u201d retrieved a different image from the right-leaning,\nminimum wage topic.\n4.4. ViT model\nOur ViT model gives us a score of -1 to 1 during infer-\nence. Since our images are labeled from a score of -1 to 1,\nwe can test the model\u2019s accuracy using two metrics, namely\nRoot Mean Square Error (RMSE) and R2score.\nRMSE score gives us the standard deviation of the resid-\nuals or prediction errors. So, for example, if we have an\nRMSE score of 0.1, our model provides the results of a + or- 0.1 score close to the predicted output. A score of 0.1 is a\ngood RMSE score since our model is predicting closely to\nthe model\u2019s labeled value\u2014however, a score of 0.5 shows\nthat the model needs to predict the labeled score better.\nR2score, also known as the Regression Score Function,\nshows how well the model fits the data. We could have a\nnegative R2score, which indicates the model can be arbi-\ntrarily worse. A score of 0 shows that the model does not\nexplain the variability of the response data around its mean.\nA score of 1 corresponds to a model that explains the vari-\nability of the response variable around its mean.\nDue to lack of adequate resources, we were unable to get\ntheR2and RMSE score. While training the model, we got\nencouraging results for our training and validation loss.\n4.5. Human Evaluation\nWhile our report does not include any results from the\nhuman evaluation, a template form can be found here: ().\nThe goal of this form is to verify that randomly selected\nde-biased text and image pairs still make semantic sense\ntogether, reduce the intial bias, and maintain the same se-\nmantic meaning as the original text and image pair.\n5. Conclusion\nOur attempt to de-bias both the text and images of our\nnews succeeded as we devised an architecture that can de-\nbias emotionally charged language from the news. How-\never, our results could have been more impressive because\nwe needed more time and resources to train our model. Our\nmodel has four key components: Bias identification from\ntext, Bias neutralization, Image Alignment, and Image Bias\nScore Prediction. We were able to identify the biased text\nfor most of the cases correctly. However, the model is also\nsensitive to rare words and punctuation. Another model\nfor bias neutralization has issues with understanding con-\ntext since we only train one sentence at a time. For Image\nAlignment, the retrieval is computationally fast, but the re-\ntrieved results did not produce the desired results because\nof a lack of resources. Finally, we received good loss scores\nfor the Image Bias Prediction Score for training and valida-\ntion. Overall, our project was a step toward de-biasing text\nand images in the news.\n6. Ethical Considerations\nWhile the this approach is intended to reduce political\nbias in news that is supposed to cover objective truths, it is\nimportant to recognize that there are potential situations in\nwhich the technology could itself be biased or misused. Be-\ncause bias scores must be manually assigned to each source\nin the dataset, there is potential for human bias to affect the\ngrading of the data. In turn, this could negatively impact\nthe downstream debiaser, for example if scorers tended to\nprovide slightly more left-leaning scores, then a retrieved\nreplacement image may be slightly more left-leaning than\nnormal.\nThere are additional ethical considerations to examine as\nwell. When would debiasing an article\u2019s images or text be\nconsidered censorship? In other words, how does one deter-\nmine reasonable situations in which to use this debiaser or\naccept its results? This work also only considers bias as a\nvalue on a single spectrum. Additionally, this work takes an\nAmerica-centric view of political media which is likely dif-\nferent from the political climate of other countries. Issues\ncould arise both from this simplistic single-spectrum view\nas well as from the differing ranges of political opinions\nacross different regions. Depending on these political and\nsocietal differences between countries, certain media could\nseem more biased or neutral than it would somewhere else.\nAnother ethical question that arises is: if the negative or\npositive aspects being covered are truthful, is it appropriate\nto replace an image that reflects that emotional element with\none that does not? For example, in an article about human\nrights abuse, would it be appropriate to replace an image of\ndistressed people with one of people in a similar situation\nwho do not seem distressed? This is more difficult to sepa-\nrate because the truthful information being conveyed could\nbe inherently evocative. Addressing this with a debiasing\nmodel could help remove a political slant to an extent, but\nwould not help correct for other contextual information that\nwas left out that creates bias in the piece.\nAn additional consideration is one related to peoples\u2019\nperceptions of the model itself. If vulnerabilities or adver-\nsarial exploitations are found, we do not want the model to\nbe used as a veneer for neutrality even when the underly-\ning content is not unbiased nor objective. In a similar vein,\nthe model could be used to find more biased image replace-\nments, as there are not explicit restrictions placed on the\nbias of retrieved images.\n7. Acknowledgment and Future Work\nWe want to thank Dr. Thomas for providing this oppor-\ntunity to work on this research project and for the Multi-\nmodal Vision class, which has immensely increased our\nskills to critique papers, think critically, and come up with\nnovel ideas from the current literature on Multi-modal vi-\nsion, which is moving forward at a rapid pace. All authors\ncontributed equally to the project as we individually worked\non different parts of the architecture to get favorable re-\nsults and improvements. In addition, all authors contributed\nequally to the Project Proposal, Project Status Report, and\nProject Presentation and writing of the Final Report.\nWhile working on this project, we experienced several\nchallenges, such as a need for more training resources and\nexperience in research and knowledge of various tools. De-\nspite these challenges, our project is a novel project whichattempts to de-bias both images and texts. Since our image\nde-biasing is a retrieval task, it is fast. Also, successfully\nimplementing our paper would allow people to read factu-\nally accurate news. Despite these strengths, our project can\nreduce the bias of the text and images to make informa-\ntion less truthful. Since our models are interrelated, errors\nin one model may significantly compound mistakes in de-\nbiasing. Finally, people watch audio and video sources for\nnews these days, and we need to address this fundamental\nproblem.\nFor Future work, we want to examine the directional-\nity of bias in embedding space. Also, researching new\nloss functions will likely make regions for neutral repre-\nsentations. Finally, since we retrieve various images from\nour model, we need some metrics to measure the variety\nof images. Eventually, for audio and video news sources,\nwe could work on a project where these sources are times-\ntamped with their respective biases.\n8. Individual Contributions\nWe divided the work into four parts, one for each of the\nmodules. Amun completed the work relating to the ViT\nfor bias scoring. Chase completed the work with the CLIP\nmodel for building the multimodal space with our bias-\naware angular loss. Xavier completed the work relating to\nthe bias text identification and using the MODULAR de-\nsign, and Cedric created the module for masking and replac-\ning the biased words with neutral words. All of us worked\nin even parts to annotate the politics dataset with the bias\nscores from https://mediabiasfactcheck.com/.\n9. GITHUB LINK\nhttps://github.com/cedricb13579/NewsDebiasing\nReferences\n[1] English word vectors \u00b7 fastText. 6\n[2] Pablo Barber \u00b4a, John T. Jost, Jonathan Nagler, Joshua A.\nTucker, and Richard Bonneau. Tweeting From Left to\nRight: Is Online Political Communication More Than an\nEcho Chamber? Psychological Science , 26(10):1531\u20131542,\nOct. 2015. Publisher: SAGE Publications Inc. 1\n[3] Levi Boxell. Slanted Images: Measuring Nonverbal Media\nBias During the 2016 Election, Apr. 2021. 2\n[4] Wei-Fan Chen, Khalid Al-Khatib, Benno Stein, and Henning\nWachsmuth. Detecting Media Bias in News Articles using\nGaussian Bias Distributions, Oct. 2020. arXiv:2010.10649\n[cs]. 2, 3\n[5] Wei-Fan Chen, Khalid Al-Khatib, Henning Wachsmuth, and\nBenno Stein. Analyzing Political Bias and Unfairness in\nNews Articles at Different Levels of Granularity, Oct. 2020.\narXiv:2010.10652 [cs]. 2\n[6] Christopher Clark, Mark Yatskar, and Luke Zettlemoyer.\nLearning to Model and Ignore Dataset Bias with Mixed Ca-\npacity Ensembles, Nov. 2020. arXiv:2011.03856 [cs]. 2\n[7] Elanor Colleoni, Alessandro Rozza, and Adam Arvidsson.\nEcho Chamber or Public Sphere? Predicting Political Orien-\ntation and Measuring Political Homophily in Twitter Using\nBig Data. Journal of Communication , 64(2):317\u2013332, Apr.\n2014. 1\n[8] Lincoln Dahlberg. The Habermasian public sphere: A spec-\nification of the idealized conditions of democratic communi-\ncation. Studies in Social and Political Thought , Jan. 2004.\n1\n[9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina\nToutanova. BERT: Pre-training of Deep Bidirectional\nTransformers for Language Understanding, May 2019.\narXiv:1810.04805 [cs]. 3\n[10] Emily Dinan, Angela Fan, Ledell Wu, Jason Weston, Douwe\nKiela, and Adina Williams. Multi-Dimensional Gender Bias\nClassification, May 2020. arXiv:2005.00614 [cs]. 2\n[11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\nDirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\nMostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\nvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Image is\nWorth 16x16 Words: Transformers for Image Recognition at\nScale, June 2021. arXiv:2010.11929 [cs]. 3\n[12] Simone Fabbrizzi, Symeon Papadopoulos, Eirini Ntoutsi,\nand Ioannis Kompatsiaris. A Survey on Bias in Visual\nDatasets, June 2022. arXiv:2107.07919 [cs]. 2\n[13] Rama Rohit Reddy Gangula, Suma Reddy Duggenpudi, and\nRadhika Mamidi. Detecting Political Bias in News Articles\nUsing Headline Attention. In Proceedings of the 2019 ACL\nWorkshop BlackboxNLP: Analyzing and Interpreting Neural\nNetworks for NLP , pages 77\u201384, Florence, Italy, Aug. 2019.\nAssociation for Computational Linguistics. 2, 3\n[14] Yusuke Hirota, Yuta Nakashima, and Noa Garcia. Quanti-\nfying Societal Bias Amplification in Image Captioning. In\n2022 IEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition (CVPR) , pages 13440\u201313449, New Or-\nleans, LA, USA, June 2022. IEEE. 2\n[15] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh,\nand Kai-Wei Chang. VisualBERT: A Simple and Per-\nformant Baseline for Vision and Language, Aug. 2019.\narXiv:1908.03557 [cs]. 3\n[16] Paul Pu Liang, Irene Mengze Li, Emily Zheng, Yao Chong\nLim, Ruslan Salakhutdinov, and Louis-Philippe Morency.\nTowards Debiasing Sentence Representations, July 2020.\narXiv:2007.08100 [cs]. 1\n[17] Thomas Manzini, Yao Chong Lim, Yulia Tsvetkov, and\nAlan W. Black. Black is to Criminal as Caucasian is to Po-\nlice: Detecting and Removing Multiclass Bias in Word Em-\nbeddings, July 2019. arXiv:1904.04047 [cs, stat]. 1\n[18] Odbal, Guanhong Zhang, and Sophia Ananiadou. Examining\nand mitigating gender bias in text emotion detection task.\nNeurocomputing , 493:422\u2013434, July 2022. 2\n[19] Yilang Peng. Same Candidates, Different Faces: Uncov-\nering Media Bias in Visual Portrayals of Presidential Can-\ndidates with Computer Vision. Journal of Communication ,\n68(5):920\u2013941, Oct. 2018. 2[20] Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao\nKurohashi, Dan Jurafsky, and Diyi Yang. Automati-\ncally Neutralizing Subjective Bias in Text, Dec. 2019.\narXiv:1911.09709 [cs]. 1, 2, 3, 5, 6\n[21] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\nAmanda Askell, Pamela Mishkin, Jack Clark, Gretchen\nKrueger, and Ilya Sutskever. Learning Transferable Visual\nModels From Natural Language Supervision, Feb. 2021.\narXiv:2103.00020 [cs]. 3, 6\n[22] Marta Recasens, Cristian Danescu-Niculescu-Mizil, and\nDan Jurafsky. Linguistic Models for Analyzing and Detect-\ning Biased Language. In Proceedings of the 51st Annual\nMeeting of the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 1650\u20131659, Sofia, Bulgaria,\nAug. 2013. Association for Computational Linguistics. 1\n[23] Scott P. Robertson. Social Media and Civic Engagement:\nHistory, Theory, and Practice . Synthesis Lectures on\nHuman-Centered Informatics. Springer International Pub-\nlishing, Cham, 2018. 1\n[24] Manjira Sinha and Tirthankar Dasgupta. Determining Sub-\njective Bias in Text through Linguistically Informed Trans-\nformer based Multi-Task Network. In Proceedings of\nthe 30th ACM International Conference on Information &\nKnowledge Management , CIKM \u201921, pages 3418\u20133422,\nNew York, NY , USA, Oct. 2021. Association for Comput-\ning Machinery. 2\n[25] Tejas Srinivasan and Yonatan Bisk. Worst of Both Worlds:\nBiases Compound in Pre-trained Vision-and-Language Mod-\nels, May 2022. arXiv:2104.08666 [cs]. 2\n[26] Christopher Thomas and Adriana Kovashka. Predicting the\nPolitics of an Image Using Webly Supervised Data. 1, 2, 3\n[27] Christopher Thomas and Adriana Kovashka. Preserving Se-\nmantic Neighborhoods for Robust Cross-modal Retrieval,\nJuly 2020. arXiv:2007.08617 [cs]. 2, 4, 6\n[28] Jinglin Wang, Fang Ma, Yazhou Zhang, and Dawei Song.\nA Multibias-mitigated and Sentiment Knowledge Enriched\nTransformer for Debiasing in Multimodal Conversational\nEmotion Recognition, July 2022. arXiv:2207.08104 [cs]. 3\n[29] Jian Wang, Feng Zhou, Shilei Wen, Xiao Liu, and Yuanqing\nLin. Deep Metric Learning with Angular Loss, Aug. 2017.\narXiv:1708.01682 [cs]. 4\n[30] Mengzhou Xia, Anjalie Field, and Yulia Tsvetkov. De-\nmoting Racial Bias in Hate Speech Detection, May 2020.\narXiv:2005.12246 [cs]. 2", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Multimodal Political Bias Identification and Neutralization", "author": ["C Bernard", "X Pleimling", "A Kharel", "C Vickery"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "Due to the presence of political echo chambers, it becomes imperative to detect and remove  subjective bias and emotionally charged language from both the text and images of political"}, "filled": false, "gsrank": 130, "pub_url": "https://arxiv.org/abs/2506.17372", "author_id": ["", "", "A1tL2cAAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:DGAGM4BI4EAJ:scholar.google.com/&output=cite&scirp=129&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D120%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=DGAGM4BI4EAJ&ei=GrWsaJ6pKcDZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:DGAGM4BI4EAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2506.17372"}}, {"title": "Fake or Visual Trickery? Understanding the Quantitative Visual Rhetoric in the News.", "year": "2018", "pdf_data": "  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 104 Available online at www.jmle.org   The National Association for Media Literacy Education\u2019s Journal of Media Literacy Education 10 (2), 104 - 122  Fake or Visual Trickery?  Understanding the Quantitative Visual Rhetoric in the News    Rohit Mehta California State University, Fresno Lynette DeAun Guzm\u00e1n University of Arizona    ABSTRACT  In online and video/television spaces, news media discourses incorporate multimodal design as a discursive move capable of steering meaning toward desirable implications. Around the 2016 U.S. presidential elections, while polarized news outlets made their positionality on the candidates obvious, more neutral or central news outlets revealed their preferences through subtle multimodal design choices. One of these design choices is using a quantitative visual rhetoric: persuasive multimodal moves that draw on quantification through visual, spatial, and textual manipulation\u2014involving the choice of data representation, visual images, and illustrations, (im)balance between numeric and alphabetic texts, and general quantitative narrative. This quantitative visual rhetoric helps news outlets manipulate facts without lying with words, leaving the onus of misinterpretation on the readers/viewers. In this article, using examples from five types of media outlets\u2014far-left, left-leaning, central, right-leaning, and far-right\u2014we share examples of design choices we found through multimodal analysis of their quantitative visual rhetoric during the 2016 elections. We share implications for media literacy education and civic engagement.  Keywords: quantitative rhetoric, visual rhetoric, news, multimodality, design   Media discourses are rich in multimodal texts (Lemke, 2009). Modes like written and spoken words, images, videos, descriptive representations, statistical plots and graphs, share space and time in news media discourses (Kress, 2003). These modes are interwoven to create, represent, and share meaning with a wider audience (Lemke, 2006). Words, numbers, and images are composed together, often intentionally, to convey information (Tufte, 1983). In online news outlets, the written word often dominates the design and compositional decisions (Leu, Everett-Cacopardo, Zawilinski, McVerry, & O\u2019Byrne, 2012; Cleveland & McGill, 1984). In television and video-based news outlets, the spoken word of the presenters and experts often takes the onus of carrying the core of the meaning. Still, in both these spaces, visual modes play a critical role in shaping meaning (Kress, 2003; Tufte, 1983). Design choices for media websites, for instance, define how written words are displayed, the stylistic choices of font-face, colors, background, \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 105 menu options, ad placement, and screen space occupied by videos and images (Holsanova & Nord, 2010; Kress & van Leeuwen, 1996; Tufte, 1983). The choice and balance between words and numbers\u2014and the choice of images and video, their size and duration, nature of the content and frequency of advertisements, and multimodal rhetorical moves\u2014shape user experience, meaning-making, and perception of truth and distant reality (Foss, 2004; Kress, 2003; Kress & Van Leeuwen, 1996; Lemke, 2009). An expectation from journalistic media outlets, ideally, is of fairness (Peters & Broersma, 2013). The information shared on popular news outlets is often expected to be factual and accurate (at least before \u201cfake news\u201d became a popular term) (McNair, 2017). The multimodal rhetoric that shapes the user experience on these news outlets also carries the burden of veracity and accuracy of information. When this rhetoric is manipulated, the veracity can be brought into question as well. This rhetoric, however, is made of carefully chosen multimodal texts (Kress, 2003). Design is a part of the rhetoric of communication, may it be visual, verbal, or even mathematical (Kress, 2004). Therefore, when questioning the veracity of information, one needs to identify and tease apart the rhetoric of the journalistic media, which begins with the dissection of the design choices made with multimodal texts and discursive moves (Jewitt, 2014).  LITERATURE REVIEW  From Weaving Lies\u2026 In the realm of meaning-making in journalistic media, the onus of carrying the truth is placed on written and spoken words. Generally, people tend to believe that lies are told with words and, hence, focus on words to catch lies. In journalistic, political, and legal discourses, the choice of words and the subtle rhetorical moves to twist meaning are often seen as preferred conduits of lies without getting accused of lying. For instance, on his involvement with Monica Lewinsky, Bill Clinton rationalized to the grand jury that he was not lying to his top aides when he said, \u201cThere\u2019s nothing going on between us.\u201d He told the grand jury that:  It depends on what the meaning of the word \u2018is\u2019 is\u2026 if \u2018is\u2019 means is and never has been...that is one thing. If it means there is none, that was a completely true statement.... Now, if someone had asked me on that day, are you having any kind of sexual relations with Ms. Lewinsky, that is, asked me a question in the present tense, I would have said no. And it would have been completely true. (Starr, 1998)  Despite (or because of instances like) Clinton\u2019s rhetorical distortion, words and numbers are the ones that are closely surveyed and monitored. If a sequence of words does not align with what can be factually proven to be true, one can be prosecuted for lying. For example, in 2013, famous Fox News presenter, Bill O\u2019Reilly, was caught lying discussing the Falkland War when he said, \u201cMy photographer got run down and then hit his head and was bleeding from the ear on the concrete. And the army was chasing us ... I dragged him off.\u201d Shortly later, the aforementioned photographer countered his words (Arana, 2015):  \u201cI never fell nor was I bleeding out my ear at any time during my Buenos Aires assignment,\u201d Ignacio Medrano-Carbo said. \u201cI do not even recall Mr. O'Reilly being near me when I shot all that footage nor after I left the unrest at Plaza de Mayo that evening. But \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 106 it is not uncommon to be separated from your reporter during a disturbance such as that one.\u201d While the controversy petered off, what is interesting about this example is how the counter by the photographer attacked Bill O\u2019Reilly\u2019s specific words, such as \u201cgot run down,\u201d \u201cbleeding from the ear,\u201d and \u201cI dragged him off.\u201d The photographer could then provide stories that contradicted O\u2019Reilly\u2019s words, thereby accusing him of lying without using the word \u201clie.\u201d  Similarly, NBC presenter, Brian Williams was caught lying on a story he had been retelling for 12 years about being in a helicopter that was shot down in Iraq. But later, when refuted by a veteran who was actually in the helicopter, Williams admitted to being in a different helicopter 30 minutes behind the one that was shot down. Once again, he had exaggerated the sequencing of his word and manipulated them over a decade to reach a point where a co-experiencer could challenge them as blatant lies. A helicopter was shot down. Brian Williams was present during that time. He was in a helicopter. But, he was never in the helicopter that was shot down.   ...To Designing Lies Lying with words and numbers is difficult to get away with, especially when those are the only modes accessible to share a narrative. It is, however, comparatively easier to manipulate clarity, facts, and truth with quantitative visual texts and quantitative rhetoric that supports such visualization\u2014specifically, charts, graphs, visually represented quantitative concepts such as percentages, difference, change, probability, predictability, and chance (Kostelnick, 2007; Tufte, 1983)\u2014and even use of quantitative language that implies a spatial or visual arrangement of numbers without the use of numbers. For example, during his speeches and on social media, Donald Trump frequently uses quantitative words such as \u201ca lot of,\u201d \u201cmany,\u201d \u201cenough,\u201d etc. to create an impression of a numeric value without having to present a number (see Figure 1). While some choices (such as Figure 1) are more obvious as quantitative rhetoric, other choices can be subtle and may need better training to understand.     Figure 1. Donald Trump uses the word \u201cMany\u201d instead of providing data.   McNair (2017) argues that such quantitative manipulations are common among journalistic media outlets, too. Partial and carefully curated information is used to design a quantitative rhetoric that helps emphasize or exaggerate favorable points without having to lie with words. While others have explored quantitative rhetoric to understand how quantified information is used in argument and persuasion (e.g., Bookstein, 2009; Craig, 2017; Schmit, 2010), our focus on quantitative rhetoric specifically includes spatial information. In other words, we are interested in persuasive multimodal moves, as explained by Kress (2004) and Tufte (1983), that draw on quantification through visual, spatial, and textual manipulation. When using visual quantitative modes, such as scales, axes, chart and graph types, extracting information requires viewer to be able to perform mental-visual tasks that involve teasing apart complex modal affordances of the variables represented (Cleveland & McGill, 1984; Gibson, 2014). While graphical visualizations \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 107 are often considered signs for these mental-visual tasks, quantitative language (such as the one shown in Figure 1) can also demand mental visualization to process quantitative meaning. What does many mean? How many is many? Multimodal examples like these present complex challenges for media literacy education.     Quantitative Visual Rhetoric The complexity of manipulating multimodal texts, especially quantitative and visual texts, has become a common practice among journalistic media outlets\u2014perhaps more among some than others (McNair, 2017). Fox News, for instance, during Obama\u2019s presidency, frequently undermined his achievements and exaggerated his shortcomings by focusing on a rhetoric that served their political dispositions. But, what is more interesting to this paper is their manipulation of the quantitative visual rhetoric to corroborate their narrative. Figure 2 shows a television news graphic from 2014 by Fox News where the y-axis is skewed and labels are omitted on a chart that displayed number of enrollments for the Affordable Care Act (ACA), with the intent to visually exaggerate the gap between expected and actual enrollments.  \n  Figure 2. The original Fox News bar chart cropping y-axis and omitting labels.  Source: MediaMatters.org  There are several ways to dissect this graph and point to the problematic manipulation of quantitative concepts. Other arguments can be made regarding the violations made in this figure as it violates basic principles of graphical representation (Tufte, 1983), but instead of statistical literacy we focus on a specific aspect to underscore the importance of quantitative rhetoric. In MSNBC\u2019s reaction to Fox News, they called out this manipulation and questioned the relative size of the two bars, asking, \u201cSince when is six million less than half of seven million?\u201d Figure 3 shows a screenshot of this segment. Here, like our logical reaction, MSNBC is questioning the absence of data labels. But, they are (rightfully) assuming that the baseline, or x-axis, used by Fox News follows graphical standards and starts at where y equals zero (Tufte, 1983). With this assumption, MSNBC was pointing out a manipulated use of visual space to exaggerate difference. That is, the bars in this chart are unfairly scaled because it appears that the left bar of 6,000,000 people is less \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 108 than half of the right bar of 7,066,000 people, which is not true. MSNBC highlighted this unfair scaling\u2014with another flawed graph (Figure 3)\u2014by adjusting the left bar (\u2018factoring in reality\u2019) so that both quantities could at least be compared on the same scale where the increments between each line is around 875,000 people.  We argue, however, that Fox News instead disregarded agreed upon design norms and chose to begin the baseline at around 5.5 million and cropped out the rest of the graph as irrelevant. In other words, they chose to show us only the top portion of a bigger graph to exaggerate the gap between the two numbers because while the mathematical difference between two numbers is a fact, their perceived difference is relative. Although we could read the increments between each line as 200,000 people to give us the difference between these two bars, this image unfairly manipulates scale by not displaying most of the bars to compare overall relative size. Most importantly, Fox News circumnavigated lying by choosing to omit the legends and a label for the y-axis, which hides the careful design choice of zooming in to exaggerate the difference between 6 and 7 million.  \n  Figure 3. MSNBC questions the original chart from Fox News, factoring in the actual size of the bar assuming the baseline to be at zero. Source: MediaMatters.org  MSNBC accuses Fox News of lying with quantitative visuals because they assume Fox News is following the grammar of visual design and graphical representation (Tufte, 1983). Our explanation shows how Fox, instead, abused the modal affordances of a bar chart without, technically, lying. When it is easier to catch people lying with words and even with visual manipulation done using computer software such as Adobe Photoshop, it is frustrating for viewers to label fabrications created by dishonest design choices, especially those that are quantitative in nature. Quantitative rhetorical moves make it more difficult to label media outlets as fake. This Fox News example is one of the many reasons why it is important for media consumers and media literacy educators to look beyond traditional forms of literacy that center attention on words, and \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 109 instead give equal value to visual, spatial, and other types of modalities that shape user experience and meaning in the media. Before and during the 2016 U.S. presidential elections, polarized media outlets, like Fox News, made their positionality on the candidates obvious through rhetorical moves similar to the ones we have just described. More neutral or central media outlets, however, revealed their preferences in subtler ways through their multimodal design choices. These choices included visual and spatial design, data representation, content and positioning of images and illustrations, and other visual texts, especially those quantitative and statistical in nature. Irrespective of the political dispositions of the media sources, quantitative visual texts played a crucial role in creating a preferred narrative that allowed media outlets to manipulate facts without lying with words, leaving the onus of factual interpretation on the readers/viewers (McNair, 2017).  METHOD   In this article, we share our multimodal analysis of quantitative visual rhetoric in the news during the 2016 presidential elections. We use examples from five types of news outlets representing different positions on the political spectrum ranging from extreme left to extreme right. We studied the use of persuasive visuals and quantitative rhetoric that draw on quantification through spatial and statistical manipulation and what this means for media literacy in an era of alternative narratives and facts. Based on multimodal analysis, we present key design choices to discuss implications for media literacy education and civic engagement. We also offer a discussion for practice to detect quantitative manipulation in the news. These solutions involve multimodal analysis of quantitative visual rhetoric, including examinations of design choices such as spatial arrangement, type of charts, scale manipulation, distribution of visual information, which have implications for meaning-making (Kress & Van Leeuwen, 1996). To study examples of quantitative visual rhetoric across media, we begin by framing a researchable question:   RQ: In what ways do multimodal design choices affect quantitative rhetoric and meaning across popular online news outlets?  To answer this question, we started by delineating a replicable method of charting rich sources of online news items that show possibilities of manipulation with multimodal texts. Our goal was to find, across media outlets, examples of quantitative visual rhetoric that people engaged in during the 2016 presidential election. We could then conduct a multimodal analysis of each of these examples to understand how design choices affected the rhetoric and meaning. Finding examples that meet these criteria meant finalizing a short list of samples. In multimodal analysis, Kress (2003, 2004) and Jewitt (2014) have shown that identifying modal affordances of key examples are more important than the size of the sample.  We, too, focused on finding a handful of key examples from each news outlet that could offer us rich data to analyze their inherent design choices. First, we identified five types of media outlets that spanned the political spectrum\u2014left-bias, left-center, center, right-center, and right-bias\u2014to cover a range of possible examples of media bias, if any. Second, we used Amazon\u2019s popularity checker (https://www.alexa.com/siteinfo) to prepare a list of the most popular news outlets that have at least 50% readership/viewership in the USA to assure relevance to the United States. Third, we used Media Bias Fact Check\u2019s website (https://mediabiasfactcheck.com/)\u2014an \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 110 independent media outlet focused on educating public on media bias and \u201cdeceptive news practices\u201d\u2014to sort the popular media outlets based on their biases on the political spectrum. Media Bias Fact Check (https://mediabiasfactcheck.com/methodology/) uses a strict method to rate (on a Likert-type scale of 0 to 10 ranging from least bias to extreme bias) all media outlets for their biased wording and headlines, credibility of sources, story choices, political affiliation. Then, the aggregated scores determine where the respective outlet falls on the political spectrum between extreme left and extreme right bias with least bias placed in the middle.  The final five journalistic outlets that met all criteria and checks were: CNN (left-bias), New York Times (left-center), USA Today (center), Wall Street Journal (right-center), and Fox News (right-bias)\u2014the top outlets from each of the five categories on the political spectrum (where popularity was determined by alexa.com). All following data for rank and readership in the U.S. were recorded at the time of the analysis after the 2016 presidential election in the months of December and January. For left-bias, we also reviewed Huffington Post, which had a 71% of readership in the U.S., along with CNN, with 65.5% readership. Out of the two, we selected CNN for the final analysis because of its popularity over Huffington Post (CNN ranked at 15 versus HuffPo at 30 in the U.S.) and frequency of quantitative rhetoric that was often absent on Huffington Post, which relied more on lists and chunking information for readability. For left-center, we examined New York Times, which is open about its bias and keeps a record of its political positionality over the years. The New York Times was ranked at 21 with a 66% readership. For center, we examined USA Today, which was considered to be a leading media outlet under the least-biased category on Media Bias Fact Checker. They ranked at 76 and 76% readership. For right-center, we examined the Wall Street Journal, ranked at 101 with a 58% readership. Finally, for right-bias, we examined Fox News, ranked at 34 with 80% readership. Finally, having listed our top five media outlets, we needed to select their popular articles/pages that used quantitative visual rhetoric. We used BuzzSumo\u2019s advanced popularity and visit tracker (http://buzzsumo.com/) to gather the top visited news stories and pages for each outlet. This website allowed us to look at each article during the Presidential elections and sort them by \u201cmost popular\u201d and \u201cmost shared.\u201d We reviewed top articles from a six-month time period leading up to the election, from June 1, 2016 through November 30, 2016. Starting from the top of sorted lists, we read each article carefully for examples of quantitative visual rhetoric. Opinion pieces and special interest stories that received a lot of popularity were often heavy on written word and qualitative narratives than quantitative rhetoric.  Searching for popular news articles from each outlet on the political spectrum that fit under the criteria of 2016 election and quantitative rhetoric narrowed down search results to some key examples. Generating a large dataset for such niche topics is not only difficult, but also not appropriate given the importance of teasing apart the modal affordances of a smaller set of examples (Jewitt, 2014). We prepared a final list of sample articles after discussing whether each article fit the criteria of including a quantitative rhetoric. We finalized two articles per outlet, adding up to a total of ten articles that we further analyzed taking a multimodal approach to tease affordances of inherent design choices (Gibson, 2014; Kress, 2004; Jewitt, 2014).    Multimodal Analysis For each article, both the authors met and co-analyzed the multimodal affordances and how they influenced the overall rhetoric and meaning, taking detailed notes and identifying emerging patterns of design choices across the spectrum. Following Tufte\u2019s (1983) standards of graphical \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 111 design and Kress (2003, 2004) and Jewitt\u2019s (2014) method of multimodal analysis, we started to tease apart spatial modalities, such as height, width, axis, colors, size, position, supporting language, interactiveness, etc., for each example. We used these modalities to understand their affordances and how they could influence the overall rhetoric and meaning-making. For instance, as seen in the Fox News example in Figure 2, deleting the axis makes all the difference in the interpretation of the graph. If we label the baseline as 5.5 million, that too will transform the graph. Over several iterations of analyzing the samples, our goal was to find the nature of commonly occurring design choices that media outlets in our sample set used and how these choices shaped meaning. Upon analysis, we identified four key design choices made by the five outlets that have implications for media literacy education, which we share next.  FINDINGS  Through our investigations of the existing quantitative visual rhetoric across multiple news outlets, we focused on how these journalistic media represented, implied, and visualized numbers\u2014not simply that numbers were used. In process, we identified four key design choices, which are as follows: (a) spatial manipulation and biased design; (b) fantasizing with probability; (c) manipulation through data extrapolation; (d) avoiding numbers when inconvenient. In this section, we share each of the four design choices in further detail to explore the possibilities and affordances of lie, deception, and manipulation that may have contributed to the popular social experience of \u201cfake news.\u201d In each of the four design choices, we used examples from our final sample articles to explain the modal affordances of the choices themselves and how they contribute to the rhetoric of fake news. In each case, we attempted to dissect the nuances of the quantitative visual rhetoric and what it means for meaning-making. We must note that our focus is not centered on the veracity of the stories or descriptive data but rather the affordances of the design and rhetoric invoked.  Across the spectrum of our sample articles, we studied affordances for each of the four design choices. The extent of manipulation of these affordances, however, varied. For instance, we found Fox News\u2019 manipulation through data extrapolation to be more blatant and heavily right leaning than CNN. Fox News tweaked with the modal affordances for quantitative language, too, but in ways that can be considered unnoticeable or ineffective in showing bias.   Spatial Manipulation: Designing with Disposition The news media outlets on the left- and right-center in this study (i.e., New York Times and Wall Street Journal, respectively) both seemed to have used web design as a strategy to carefully create a quantitative visual rhetoric that favored their political dispositions. These dispositions become more obvious when compared with a relatively central outlet, such as USA Today. For example, in an analysis of Trump\u2019s involvement with lawsuits as a businessman, Penzenstadler and Page (2016) presented an investigative report that provided a breakdown of data, which is shown in Figure 4. In an effort to make fair comparisons, USA Today authors examined Trump\u2019s legal involvement compared to five top real-estate business executives. Without invoking sensationalist language to accompany visual representations, the authors allow readers to process the data for comparisons and meaning-making. The design choice shown in Figure 4 makes it difficult to infer their political dispositions as it does not contrast his data with other political figures. Additionally, the language accompanying the visuals was plain, transparent, preemptively addressing questions that may arise. The interactive feature took readers from one graph to another \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 112 that helped visualize the scope of Trump\u2019s lawsuits without implying whether that is normal or abnormal for a businessman or politician in his position. None of their rhetoric moves tried to appease readers with a preferable outcome or scenario, unlike the New York Times and the Wall Street Journal.  \n  Figure 4. Screenshot of visual display that presents a breakdown of Trump\u2019s 3,500 court cases.  Source: Penzenstadler & Page, 2016  In our analysis of the New York Times and Wall Street Journal, we found the most popular and widely shared articles to be their respective coverage on the contest between the democratic and republican nominees for the presidential election: Hillary Clinton and Donald Trump. Taking each in turn, we found that both outlets used similar subtle design-based approaches to create a visual rhetoric that used quantitative principles to imply preferences. For example, in one of the New York Times\u2019s most popular and widely-shared article/webpages during the 2016 presidential elections, they provided an interactive data-saturated space in which their readers could click and play multiple possibilities of win and loss combinations (Katz, 2016). Figure 5 shows an example from this series of infographics, with included various interactive graphs and charts, giving agency to the users, who could manipulate information to change the hypothetical outcome of the election and see possible paths to win for the candidate of their choice.  These charts included: (1) trend of winning chance for each candidate over the latter half of 2016, (2) change in winning chance in key states, (3) state-by-state comparisons, (4) news media and survey source comparisons, (5) state-by-state and survey source comparisons, (6) likelihood of each possible outcome including 500 odd combinations of the electoral votes, and (7) all possible paths to the White House for each candidate, starting with the choice of assigning a win to each of the following key states: Florida, Pennsylvania, Ohio, North Carolina, Virginia, Wisconsin, Colorado, Iowa, Nevada, and North Hampshire. On first glance, the idea of offering readers a chance to imagine multiple possibilities seemed fair and unbiased as it allowed all possible readers to play with data. However, on further \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 113 analysis, we deemed two foundational questions crucial. First, who is the intended audience? Second, if there is a subtext, what is it?    \n Figure 5. Screenshot of interactive diagram where readers can manipulate possible election outcomes from 1,024 pathways. Source: New York Times  The stance of convincing can be seen in particular design and rhetorical choices. Along with the interactive diagram, we found that the surrounding text shed light on the New York Times\u2019s position: \u201c[illustrating] Mr. Trump\u2019s challenging path to the presidency.\u201d Readers are encouraged to \u201ccontrol the outcome\u201d for ten key states, manipulating the 1,024 possible combinations for an imagined outcome based on collected data that supposedly reflect aspects of reality. While this interactive diagram seems to provide agency for readers to choose possibly pathways, it is still constrained (Rawlins & Wilson, 2014). Not only does the designer control the polling data used, but also the rhetorical message in the surrounding text that suggests a challenge for Trump\u2019s path to victory. Analyzing further into the quantitative rhetoric, we investigated the visual components that carried favorable meaning layered in the design and choice of charts and graphs. Each type of chart provides affordances for users to manipulate meaning that is convenient to them. A bar graph might allow the user to compare a variable across multiple instances. But the choice of those instances depends on the creator who can warp the message for the readers. Statistical and quantitative rhetoric, which deals with visual representation of numbers, might be viewed as an objective or unbiased stance. But when contextualized by the accompanying text and possible design choices, organizational and representational choices of data reveal a disposition as well. For example, the chart that displayed likelihood of each possible combination of electoral votes was labeled \u201cElectoral votes for Hillary Clinton,\u201d thereby making it a chart of number of ways Donald Trump can lose. Similar visual and statistical space was not given to his possibilities of winning.  \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 114 Similarly, at the Wall Street Journal, in an article that focused on linking corruption with Clinton in multiple possible ways, there was an embedded GIF of an interactive electoral college map (Barrett, 2016). Readers could click on the map and assign the states to the candidate of their choice. Interestingly, in the GIF, which was running in a continuous loop, showed Clinton\u2019s blue states turning to red by clicks of a moving mouse icon. Without any direct relation to the article itself (which was about possible charges of corruption), the newspaper offered an escape to its readers\u2014who might have felt direr than New York Times readers\u2014through the interactive map conveniently placed within the article like an advertisement.  Because both the New York Times and the Wall Street Journal are both open about their political dispositions, their respective narrative choices were not surprising, nor were they blatant manipulations of the standards of graphical representation and quantitative rhetoric like Fox News (as we explain later in this article). What is interesting, though, is the subtler use of visual design to appease anxious readers by offering them interactive data-driven charts to play with and fantasize possible futures. Using quantitative visual rhetoric, especially when combined with concepts of probability and predictability, offers outlets that may wish to be perceived as objective or least-biased an option to conceal dispositions in design.   Fantasy and Probability The difference between possible and probable is a crucial one, especially when speaking in the context of predictability. It was possible for Hillary Clinton to win the election. It was also possible for Donald Trump to win the election. But, these statements do not appease people of their anxieties for unpredictable social futures. People may want to know more than what they know themselves, so the news outlets seek statistical help and use probability to share the likelihood of every occurrence, which can be seen on data-driven websites like NY Times, FiveThirtyEight, and Fox News. Ultimately, the outcomes that fit the overall narrative and political dispositions are underscored as these statistics are created. Data-driven reporting is often conceived as being number-based and, therefore, objective and unbiased (Porter, 1995). Reporting the numbers, then, might be equated with reporting the facts. So, when the New York Times a news report shared 85% chance of winning for Hillary Clinton, it could be considered as a fact by some. Figure 6 shows a screenshot from an article where the probability of winning is calculated next to a face shot of each candidate. This is where design choices become important. How the numbers are shared online can shift the intended meaning (and subsequent sense-making). In the New York Times, for example, in a scenario where the current polls showed an 85% chance of winning for Hillary Clinton, users could have created a quantitative rhetoric around this number to favor a message that fits their agenda. They could have even varied from left-leaning to right-leaning storylines in many ways, such as:   a. \u201cHillary Clinton has an 85% chance of winning\u201d b. \u201cHillary Clinton has a fighting 85% chance of winning\u201d c. \u201cCrooked Hillary rigged polls to show an 85% chance of winning\u201d d. \u201cDonald Trump still in the race with a 15% chance of winning\u201d e. \u201cA victory by Mr. Trump remains possible: Mrs. Clinton\u2019s chance of losing is about the same as the probability that an N.F.L. kicker misses a 37-yard field goal.\u201d  \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 115   Figure 6. Screenshot from a New York Times article showing the chance of winning accompanied by the faces of the candidates. Source: Katz (2016)   The last sample (e) was an actual statement used in the New York Times article that we examined (Katz, 2016). The only instance in the article that included Trump in a possibility of winning was intertwined with the chance of Clinton losing explained with the help of a popular experience among Americans of missing a 37-yard field goal. Although both statistics were the same (85%), it was an interesting choice to reference professional sports\u2014an activity that can elicit strong affective reactions from fans. Particularly with professional sports like the National Football League (NFL), players perform at such a high caliber that might complicate how \u201885%\u2019 is made sense of in connection to the context of a presidential election. A victory by Trump might have been unlikely but was not impossible, just as a missed 37-yard field goal by a professional football kicker is unlikely but not impossible. In some ways, it raises the question: Is Trump politically as good as a professional football player? As discussed in the New York Times example, readers could play with statistical principles of probability and predictability to create a fantasyland with outcomes that they desired. The Wall Street Journal created a similar space in one of their most popular articles during the elections. In the article titled \u201cFBI in Internal Feud Over Hillary Clinton Probe,\u201d the Wall Street Journal used large numbers to create a narrative of a corrupt politician leading in the presidential race (Barrett, 2016). Starting with the subheader, \u201cLaptop may contain thousands of messages sent to or from Mrs. Clinton\u2019s private server,\u201d the Wall Street Journal used the word \u201cthousands\u201d as quantitative language to plant an image of an overwhelming number of emails. When we looked across news outlets, we found that \u201cthousands\u201d was the quantitative word of choice when raising allegations. \u201cThousands\u201d is a reasonable number to be possible, which makes it believable. If found untrue, this number can also be considered a reasonable error. For instance, if we replace the word \u201cthousands\u201d with \u201cmillions,\u201d the claim becomes absurd. \u201cMillions of emails\u201d is too large a quantity to grasp as reasonable for this context and raises doubts about the authenticity. \u201cHundreds,\u201d in contrast, feels too low to be problematic. \u201cThousands\u201d offers a decent range between 1001 to 999,999 and keeps the focus on the topic rather than shifting it to the news organization. Again, this quantitative language implies a spatial arrangement of numbers without the use of numbers or visuals\u2014creating a quantitative visual rhetoric that underscores particular narratives. \n\n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 116 Such narrative was common throughout the Wall Street Journal article (Barrett, 2016). What becomes more interesting is that, in the article, the use of quantities is more numeric than word-based. Embedded in the article, readers can spot larger numbers like \u201c650,000 emails,\u201d and \u201c$467,500 in campaign funds\u201d easily because they stand out from the rest of the article and are placed in the segments that specifically speak to possible corruption. We argue that such design choices are among the subtler forms are quantitative visual rhetoric because it does not even register as visual rhetoric with most readers.  Embedded in this same Wall Street Journal article was the interactive electoral college GIF mentioned in the previous section. Positioning these choices side-by-side, the authors produced a quantitative visual rhetoric that suggested Hillary Clinton\u2019s unfavorability. Consequently, readers are provided an opportunity to guess the electoral college outcome and fantasize about her losing the election. But, what was more interesting to us was the statistical and quantitative language that is used carefully to keep a claim at a safe distance from a lie. The choice to use probabilistic language such as \u201cmay,\u201d \u201clikely,\u201d and \u201cpossible\u201d\u2014that usually add nuance to statistical discussions\u2014have been used by some media outlets to make damaging claims more authentic, while saving the news outlet of responsibility. This puts the onus of meaning on the reader, who needs to be conscious of the quantitative rhetoric that is used to warp truths. The specious use of concepts of statistics and probability raise a bigger concern. While experimental probability estimates probability of occurrences based on existing data, theoretical probability attempts to mathematically calculate the chances for each occurrence. This is crucial to understand because what could mathematically happen may not actually happen. Even with a simple coin toss, just because head and tail have an equal probability of occurring, that does not mean that after a coin landing on \u201cheads,\u201d the next has to land on \u201ctails.\u201d In probability, fairness is a theoretical assumption. These arguments are important to understand because they influence our understanding of everyday predictability and probability in complex social scenarios. Just because Donald Trump has a 15% chance of winning, that does not mean he cannot win. Once he wins, all that matters is that he won. His chance of winning is a theoretical, mathematical calculation and an estimate. It does not influence the outcome of the future. It does not control what people will end up doing. Because unlikely is not impossible, people can always argue that it is still true that he had a low chance of winning and with his win a less likely event took place. But, for a shared reality, it is irrelevant what possible events could have happened. What matters is the one event that did happen. For readers then, probability and statistical models become fantastic escapes. So why produce these statistics at all? We argue that a part of the reason involves fantasizing, which can be an intentional design choice in produced media. In the next two sections, we explore how outlets drew on statistics and rhetorical moves to advance storylines.  Manipulation through Extrapolating Data As we have mentioned in the introduction, an important part of quantitative visual rhetoric is the quantitative language that helps manipulate a mental visualization. Word choices for numeric values are interesting design choices that create a visual rhetoric without visual manipulation. Media outlets might manipulate storylines by extrapolating data. In other words, reports might include carefully selected data points to imply an exaggerated scope of the phenomenon or issue. For example, a Fox News report on voter fraud reported single examples from four states to generalize a sense of voter fraud in the United States (Fox News Insider, 2016). \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 117 The online article was accompanied by a video interview segment that appeared on the television show, Fox & Friends. In the first state example, 20 deceased people and \u201cmore than 1,000 non-citizens in Virginia [were] registered to vote\u201d and the commentator in the video clip noted that this count did not include Fairfax County and Arlington County, which were two of the most populous areas in the state. She closed with comments suggesting that this \u201creally would have turned Virginia blue in recent months,\u201d despite not having any evidence to back up this claim. One notable observation from this example is the absence of how the count of 1,000 relates to the state population of Virginia (over 8 million) or the number of registered voters in the state (over 5 million). From those omissions, the commentator was able to extrapolate the specific example to suggest a massive problem, even though the relative percentage of the data given is about 0.02% for 1,000 out of 5 million registered voters. She does this by stating that these voter fraud counts do not even include areas with substantial population, and ultimately, implying that there must be more counts of voter fraud in these larger populated areas. The omission or lack of data from areas with substantial population is used as an advantage to make predictions about the areas without relevant evidence.  A second example from this report was that in Pennsylvania there may be more than 43,000 voters who are registered twice and \u201cmore than 700 Pennsylvania voters might have cast two ballots in recent elections.\u201d Similarly, this count is reported in isolation from the full context\u2014Pennsylvania is a state with over 12 million people of which 8 million are registered voters. Putting 43,000 in relation to the number of total registered voters (8 million) is around 0.53%. Furthermore, reporting statistics on voter registration alone is not the same as actual duplicate votes. There could be multiple legitimate reasons for duplicate voter registrations (e.g., recently moved to another state, delay in record updating), and that count does not represent fraudulent votes cast. Quite simply, voter registration is not the same as voting. Again, this example follows a similar extrapolation as the previous example in Virginia: the reporters imply that this is a problem of scale in the United States. Quantitative rhetoric in this stance was made more visible as the commentator verbally offered a visualization by stating, \u201cThere\u2019s a lot more. Tip of the iceberg.\u201d Not only does the quantitative language (\u201ca lot more\u201d) imply a spatial arrangement of numbers, but the subsequent idiom (\u201ctip of the iceberg\u201d) also creates the quantitative visual rhetoric to evoke imagery in this example. The last two state examples in this report were Texas and Colorado. In both cases, the reports avoid any numerical counts to continue the storyline of voter fraud as common. The focus in Texas was on mail-in ballots as problematic. In Colorado, the reporters invoke quantitative rhetoric by simply including the word \u201cmultiple,\u201d so that text on screen reads: \u201cMultiple cases of dead people voting.\u201d Closing out the narrative, the Fox & Friends interviewer stated, \u201cIt makes everyone who votes and votes earnestly feel like their vote might matter a little bit less,\u201d noting that Pennsylvania and Colorado are key swing states that will decide the presidential election. The commentator confidently made this assertion based on the extrapolation from these four examples, even though it is highly unlikely that these examples provide evidence of any impact of voter fraud on U.S. presidential elections (Goel, Meredith, Morse, Rothschild, & Shirani-Mehr, 2017).  Avoiding Numbers When Inconvenient In other instances, highlighting individual stories with powerful imagery was a design choice that created a visual rhetoric where quantification seemed less visible. Avoiding numbers could involve two practices: ignoring raw number counts or percentages, and invoking quantitative rhetoric. For example, a CNN article on post-election hate crimes reported a mixture of \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 118 percentages and raw numbers for a storyline that hate crimes are growing (Yan, Sgueglia, & Walker, 2016). The authors noted a raw number count of 867 cases from November 9 to November 18; however, this count did not provide contextual information to understand the quantity relative to previous counts of hate crimes in the United States. Invoking such quantitative rhetoric through words and raw numbers is still a mental-visual task (Cleveland & McGill, 1984) as the onus of visualizing the size and scale of these numbers is shifted on to the audience. In other words, is 867 a drastic increase? And in a country with over 300 million people, how might readers make sense of what 867 (over ten days) means? Quantitative rhetoric is also invoked by stating that these incidents have been \u201ceverywhere\u2014in schools, in places of business like Walmart, on the street,\u201d a widespread issue. Because of the omission of the relative nature of these numbers, a larger scope is absent from the report. Percentages might provide more context to make meaning of the scope of hate crimes during this time period. In another point of this article, the authors provided a percentage while omitting raw number counts, stating \u201cFBI statistics for 2015 showed a 67% increase in hate crimes against Muslim Americans.\u201d Without providing raw number counts to which the percentage is referencing, it is again difficult to determine the scope of hate crimes. Invoking quantitative rhetoric, the authors then go on to state, \u201cHate crimes against Jewish people, African Americans and LGBT individuals also increased,\u201d to imply a widespread issue increasingly affecting minoritized groups of people. Finally, the authors centered visual rhetoric by presenting 18 individual stories, back-to-back, that focus on cases of intimidation and violence after the 2016 election, followed by 3 stories about attacks on Trump supporters. These detailed individual cases serve as stories that might be extrapolated by the reader as disturbing interactions that are part of the larger body of cases occurring. This strategy to present a percentage with no connection to raw number count (and vice versa) commonly appears in news reports. There are many ways to create quantitative visual rhetoric\u2014this one involves supporting a narrative by omitting a larger scope of the data (i.e., raw number counts or percentages). Intentional inclusion or exclusion of numbers or quantitative words, all shape the meaning. That is, quantitative visual rhetoric is not just what you show, but also what you do not show (and could show).  DISCUSSION  After assessing the four key design choices, we argue that in a media ecology dominated by the dynamic and demanding digital change and capitalistic motivations, the expectations of sensational news cycles have led to fast and thrilling news generation (McNair, 2017). As digital tools and technologies enter everyday lived experiences, they start to blend with each other to a discernible degree. More adolescent and young adults, across the world, are exploring news through digital sources that blur the distance between media and lifeworld (Mitchell et al., 2018). Imagining life without it being intertwined with some form of informational media is becoming difficult. This underscores the importance of media literacy across K-12, higher education, and even lifelong learning. These changing trends highlight the increasing overlap between the goals of media literacy and democratic education. It is becoming unlikely to prepare people for a future immersed in digitality without equating media literacy with education (Mihailidis, 2006).  There is nothing new that we can say about the importance of focusing on media literacy throughout education that media literacy scholars and educators have not already said. (Baran, 2010; Hobbs, 2007; Mihailidis, 2006; Livingstone, 2004; Potter, 2013). The exigency of \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 119 incorporating media literacy education into disciplinary curriculum across K-12 and in higher education is manifesting itself in global effects of distrust in a media that established itself as an unbiased critic of political, judicial, and social power (Mitchell et al., 2014). Although from our analysis we found that media outlets across the political spectrum produced quantitative visual rhetoric to advance particular storylines, promoting an overall distrust of media sources is not productive for mitigating this issue. Perhaps, then, a goal for media literacy education is to make visible intricacies and subtleties in the content we constantly consume and produce, such as the four design choices we outline in this article. We view quantitative visual rhetoric as one small yet crucial piece of the bigger media literacy repertoire. Therefore, in this section we offer a few takeaways for media literacy education and civic engagement from a quantitative visual rhetoric perspective.  What accompanies numbers? The first takeaway from our analysis of the quantitative visual rhetoric in the media during the 2016 U.S. presidential elections is about the importance of non-quantitative language that accompanies a quantitative rhetoric. Whether it be a visual or predominantly verbal quantitative rhetoric, modifier words shape our meaning of numbers and other quantitative concepts. For this reason, teachers of language arts, science, mathematics, among other subject areas, all carry a responsibility of informing students about how rules and language\u2014the symbol systems\u2014in one subject area shape the symbol systems of others. As we showed in the New York Times and the Wall Street Journal examples, factual and statistically accurate graphs can be manipulated by the language in the labels and legends, the choice of colors, the type of the chart used, among other subtle design features.  Here, readers/viewers need to identify all possible modalities used in a given space and acknowledge what each of them bring to the meaning-making process. This can help identify the extent of variables involved in manipulating meaning and, therefore, becomes the first step in decoding the design choices. What do quantitative words mean? Our second takeaway is specifically about words that imply quantification. That is, words that represent some form of spatiotemporal countability, measurability, or comparability. For example, few, many, multiple, huge, and low (among other similar words) all offer some form of quantitative understanding to the overall meaning. In a quantitative rhetoric, such words leave a lot of room for manipulation of meaning. For instance, when the word multiple or many is used, technically, it could mean two, two million, or any number more than one, depending on the context. When we read a headline such as \u201cmultiple people were arrested,\u201d we form a quantitative image in our head that could anchor the actual number anywhere our understanding of the context places it. Similarly, words like more or decrease imply a scale or hierarchy; they do not tell us how we choose to count or create metrics, though. It is also important to note that proportions, ratios, percentages, and fractions do not mean much without reference to a whole\u2014as we showed with the Fox News and CNN examples that only produced percentages without a raw number count (and vice versa). What influences the meaning-making with such words are the social literacy practices in the media that shape how we process these words. As seen in the examples from Fox News, words like hundreds, thousands, and several are common when the actual number may not be as impactful for the purpose of the story.  How to read multimodality? Our third takeaway is to emphasize the relationship between visually-rich quantitative cognitive processes and the rhetoric that takes advantage of this fundamental human trait. Additionally, we want to draw attention to how emotion and feeling are part of an embodied sense-making of quantitative visual rhetoric.  \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 120 Visual modes help us comprehend and process numbers. But if someone dishonestly manipulates human psychology to persuade people, people have the right to be aware of such manipulations, be able to assess these practices, and take appropriate counter-action. Graphs, which can give the appearance of being scientific can increase persuasiveness; even trivial graphs and formulas increase public belief (Tal & Wansink, 2016). The impact of simple quantitative visual rhetoric on meaning-making has crucial repercussions for media literacy education. We found visual manipulations, such as use of space to imply gap and compare incommensurable items by size using charts, could imply non-existing meaning, thereby helping news outlets lie without getting caught with words.  What do statistics mean? Our fourth, and final, takeaway is to understand the use of statistical concepts of probability and predictability to feed fantasy. Starting from a young age and leading up to adulthood, people often find complex statistical concepts difficult to comprehend (Spiegelhalter, 2010). Concepts of probability and uncertainty can be seen as being misused and misunderstood by people, even in media. As seen in the examples shared from the New York Times and Wall Street Journal, news outlets can use probability and predictability as a fantastic escape for its readers.  Countering the challenge of rampant statistical models and rhetoric in the news media would mean educating people about the subtleties and complexities of the concepts of probability, uncertainty, and predictability. In addition to this, personal understanding of the world that involves theories about causality, influence of past on the future, fate, karma, and other spiritual, pseudoscientific, and even religious notions increase the messiness of statistical concepts. For example, for a person who chooses to believe in a supreme being controlling or determining future outcomes, probability can be irrelevant. Teaching statistical concepts to a world where everyone has folk theories about future and uncertainty raises deeper epistemological concerns that media literacy research needs to acknowledge and address as well.  CONCLUSION  Across the political spectrum for popular media outlets, we found examples of spatial manipulation, fantasizing with probability, manipulation through data extrapolation, and avoiding numbers when inconvenient. Given these, we argue that the goal through media literacy education is to make visible the intricacies and subtleties in the media that go beyond written or spoken word. This goal is bigger than a subject area or classroom curriculum and has repercussions that can be deeply personal to people. The process of meaning-making is rich with multimodal intertextuality (Kress, 2003). With a focus on words and images, we have only scratched the surface of manipulations. This dynamic and complex interplay of a barrage of sociocultural factors extend a daunting challenge for media literacy educators. It calls for a need to inject media literacy across disciplines and levels of education.    \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 121 REFERENCES  Arana, G. (2015, March 30). Bill O\u2019Reilly lied about rescuing me during Buenos Aires riot, says CBS cameraman. HuffPost. Retrieved from https://www.huffingtonpost.com/2015/03/30/bill-oreilly-lied-falklands_n_6970194.html  Baran, S. J. (2010). Introduction to mass communication: Media literacy and culture. New York, NY: McGraw Hill. Barrett, D. (2016, October 30). FBI in internal feud over Hillary Clinton probe. Wall Street Journal. Retrieved from https://www.wsj.com/articles/laptop-may-include-thousands-of-emails-linked-to-hillary-clintons-private-server-1477854957 Bookstein, F. L. (2009). How quantification persuades when it persuades. Biological Theory 4(2), 132-147. Cleveland, W. S., & McGill, R. (1984). Graphical perception: Theory, experimentation, and application to the development of graphical methods. Journal of the American Statistical Association, 79(387), 531\u2013554. Craig, J. C. (2017). Real fantasies in mathematics education: Numeracy, quantitative reasoners, and transdisciplinary wicked problems (Doctoral dissertation). Retrieved from ProQuest Dissertations and Theses database. (UMI No. 10621502). Foss, S. K. (2004). Framing the study of visual rhetoric: Toward a transformation of rhetorical theory. Defining Visual Rhetorics, 303-313. Fox News Insider. (2016, October 21). Dead people registering? Examples of voter fraud in key swing states. Fox News. Retrieved from http://insider.foxnews.com/2016/10/21/dead-people-registering-reporter-lays-out-examples-voter-fraud-swing-states Gibson, J. J. (2014). The ecological approach to visual perception: classic edition. Psychology Press. Goel, S., Meredith, M., Morse, M., Rothschild, D., & Shirani-Mehr, H. (2017, January 13). One Person, One Vote: Estimating the Prevalence of Double Voting in U.S. presidential Elections. Working Paper. Retrieved from https://polmeth.polisci.wisc.edu/Papers/2votes_v7.pdf Hobbs, R. (2007). Reading the media: Media literacy in high school English. Teachers College Press. New York, NY: Teachers College Press. Holsanova, J., & Nord, A. (2010). Multimodal design: Media structures, media principles and users\u2019 meaning-making in printed and digital media (pp. 81-103). Frankfurt/New York: Campus. Jewitt, C. (Ed.). (2014). The Routledge handbook of multimodal analysis. London: Routledge. Katz, J. (2016, November 8). Who will be president? New York Times. Retrieved from https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html Kostelnick, C. (2007). The visual rhetoric of data displays: The conundrum of clarity. IEEE Transactions on Professional Communication, 50(4), 280-294. Kress, G. R. (2003). Literacy in the new media age. Psychology Press. Kress, G. (2004). Reading images: Multimodality, representation and new media. Information Design Journal, 12(2), 110\u2013119. Kress, G. R., & Van Leeuwen, T. (1996). Reading images: The grammar of visual design. Psychology Press. \n  R. Mehta & L. Guzm\u00e1n  |  Journal of Media Literacy Education 2018 10(2), 104 - 122   \n 122 Lemke, J. (2013). Toward critical multimedia literacy: Technology, research, and politics. In M. McKenna, L. Labbo, R. Kieffer, & D Reinking (Eds), The  international handbook of literacy and technology: Volume two (pp. 3-14). New York: Routledge. Lemke, J. (2009). Multimodal genres and transmedia traversals: Social semiotics and the political economy of the sign. Semiotica, 2009(173), 283-297. Leu, D. J., Everett\u2010Cacopardo, H., Zawilinski, L., McVerry, G., & O\u2019Byrne, W. I. (2012). New Literacies of online reading comprehension. In C. Chapelle (Ed.), The encyclopedia of applied linguistics. New York: Wiley. Livingstone, S. (2004). Media literacy and the challenge of new information and communication technologies. The Communication Review, 7(1), 3-14. McNair, B. (2017). Fake news: Falsehood, fabrication and fantasy in journalism. New York: Routledge. Mihailidis, P. (2006). Media literacy in journalism/mass communication education: Can the United States learn from Sweden? Journalism & Mass Communication Educator, 60(4), 415 \u2013 428. Mitchell, A., Gottfried, J., Kiley, J., & Matsa, K. E. (2014, October 21). Political Polarization & Media Habits. Retrieved March 27, 2018, from http://www.journalism.org/2014/10/21/political-polarization-media-habits/ Mitchell, A., Simmons, K., Matsa, K. E., & Silver, L. (2018, January 11). Publics Globally Want Unbiased News Coverage, but Are Divided on Whether Their News Media Deliver. Retrieved March 27, 2018, from http://www.pewglobal.org/2018/01/11/publics-globally-want-unbiased-news-coverage-but-are-divided-on-whether-their-news-media-deliver/  Penzenstadler, N., & Page, S. (2016, June 1). Exclusive: Trump\u2019s 3,500 lawsuits unprecedented for a presidential nominee. USA Today. Retrieved from https://www.usatoday.com/story/news/politics/elections/2016/06/01/donald-trump-lawsuits-legal-battles/84995854/ Peters, C., & Broersma, M. J. (Eds.). (2013). Rethinking journalism: Trust and participation in a transformed news landscape. London/New York: Routledge. Porter, T. M. (1995). Trust in numbers: The pursuit of objectivity in science and public life. Princeton, NJ: Princeton University Press. Potter, W. J. (2013). Media literacy. Thousand Oaks, CA: Sage Publications. Rawlins, J. D., & Wilson, G. D. (2014). Agency and interactive data displays: Internet graphics as co-created rhetorical spaces, Technical Communication Quarterly, 23(4), 303\u2013322 Schmit, J. (2010). Teaching statistical literacy as a quantitative rhetoric course. Retrieved from http://www.statlit.org/pdf/2010SchmitASA.PDF Spiegelhalter, D. (2010, November).  Why do people find probability unintuitive and difficult? NRICH-University of Cambridge. Retrieved from https://nrich.maths.org/7326  Starr, K. (1998). The Starr Report: The findings of independent counsel Kenneth W. Starr on president Clinton and the Lewinsky affair. Washington, DC: Public Affairs. Tal, A., & Wansink, B. (2016). Blinded with science: Trivial graphs and formulas increase ad persuasiveness and belief in product efficacy, Public Understanding of Science, 25(1), 117\u2013125. Tufte, E. R. (1983). The visual display of quantitative information. Cheshire, CT: Graphic Press Yan, H., Sgueglia, K., & Walker, K. (2016, November 10). \u2018Make America White Again\u2019: Hate speech and crimes post-election. CNN. Retrieved from https://www.cnn.com/2016/11/10/us/post-election-hate-crimes-and-fears-trnd/index.html  ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fake or Visual Trickery? Understanding the Quantitative Visual Rhetoric in the News.", "author": ["R Mehta", "LDA Guzm\u00e1n"], "pub_year": "2018", "venue": "Journal of Media Literacy Education", "abstract": "In online and video/television spaces, news media discourses incorporate multimodal design  as a discursive move capable of steering meaning toward desirable implications. Around"}, "filled": false, "gsrank": 131, "pub_url": "https://eric.ed.gov/?id=EJ1198646", "author_id": ["H7v5stAAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:h0JgP2XINnsJ:scholar.google.com/&output=cite&scirp=130&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=h0JgP2XINnsJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 36, "citedby_url": "/scholar?cites=8878504052588036743&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:h0JgP2XINnsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.eric.ed.gov/fulltext/EJ1198646.pdf"}}]