[{"title": "Who falls for online political manipulation?", "year": "2019", "pdf_data": "Who Falls for Online Political Manipulation?\nThe case of the Russian Interference Campaign in the 2016 US Presidential Election\nADAM BADAWY, Information Sciences Institute, University of Southern California\nKRISTINA LERMAN, Information Sciences Institute, University of Southern California\nEMILIO FERRARA, Information Sciences Institute, University of Southern California\nSocial media, once hailed as a vehicle for democratization and the promotion of positive social change across\nthe globe, are under attack for becoming a tool of political manipulation and spread of disinformation. A\ncase in point is the alleged use of trolls by Russia to spread malicious content in Western elections. This\npaper examines the Russian interference campaign in the 2016 US presidential election on Twitter. Our aim is\ntwofold: first, we test whether predicting users who spread trolls\u2019 content is feasible in order to gain insight\non how to contain their influence in the future; second, we identify features that are most predictive of users\nwho either intentionally or unintentionally play a vital role in spreading this malicious content. We collected\na dataset with over 43 million elections-related posts shared on Twitter between September 16 and November\n9, 2016, by about 5.7 million users. This dataset includes accounts associated with the Russian trolls identified\nby the US Congress. Proposed models are able to very accurately identify users who spread the trolls\u2019 content\n(average AUC score of 96%, using 10-fold validation). We show that political ideology, bot likelihood scores,\nand some activity-related account meta data are the most predictive features of whether a user spreads trolls\u2019\ncontent or not.\nAdditional Key Words and Phrases: Political Manipulation, Russian Trolls, Bots, Social Media\nCite as:\nAdam Badawy, Kristina Lerman, and Emilio Ferrara. 2018. Who Falls for Online Political Manipulation? Arxiv\nPre-print v1, August 2018\n1 INTRODUCTION\nThe initial optimism about the role of social media as a driver of social change has been fading\naway, following the rise in concerns about the negative consequences of malicious behavior online.\nSuch negative outcomes have been particularly evident in the political domain. The spread of\nmisinformation [Shorey and Howard 2016; Tucker et al .2017] and the increasing role of bots [Bessi\nand Ferrara 2016] in the 2016 US presidential elections has increased the interest in automatic\ndetection and prediction of malicious actor activity.\nIn this study, we focus on the role of Russian trolls in the recent US presidential elections. Trolls\nare usually described as users who intentionally \u201cannoy\u201d or \u201cbother\u201d others in order to elicit an\nemotional response. They post inflammatory messages to spread discord and cause emotional\nreactions [Phillips 2015]. In the context of the 2016 US election, we define trolls as users who exhibit\na clear intent to deceive or create conflict . Their actions are directed to harm the political process and\ncause distrust in the political system. Our definition captures the new phenomenon of paid political\ntrolls who are employed by political actors for a specified goal. The most recent and important\nexample of such phenomenon is the Russian \u201ctroll farms\u201d\u2014trolls paid by the Russian government\nto influence conversations about political issues aimed at creating discord and hate among different\ngroups [Gerber and Zavisca 2016].\nAuthors\u2019 addresses: Adam Badawy, Information Sciences Institute, University of Southern California, abadawy@usc.\nedu; Kristina Lerman, Information Sciences Institute, University of Southern California, lerman@isi.edu; Emilio Ferrara,\nInformation Sciences Institute, University of Southern California, emiliofe@usc.edu.\n\u00a92018 The Authors\nThis is the author\u2019s version of the work. It is posted here for your personal use.arXiv:1808.03281v1  [cs.SI]  9 Aug 2018\n:2 Adam Badawy, Kristina Lerman, and Emilio Ferrara\nSurvey data from the Pew Research Center [Gottfried and Shearer 2016] show that two-thirds of\nAmericans get their news from Social Media. Moreover, they are being exposed to more political\ncontent written by ordinary people than ever before. Bakshy et al .[2015] report that 13% of posts by\nFacebook users\u2014who report their political ideology\u2014are political news. This raises the question of\nhow much influence the Russian trolls had on the national political conversation prior to the 2016\nUS election, and how much influence such trolls will have in the upcoming elections. Although we\ndo not discuss the effect that these trolls had on the political conservation prior to the election, we\nfocus our efforts in this paper on the following two questions:\nRQ1: Can we predict which users will become susceptible to the manipulation campaign by\nspreading content promoted by Russian trolls?\nRQ2: What features distinguish users who spread trolls\u2019 messages?\nThe goal of these questions is, first, to test whether it is possible to identify the users who will\nbe vulnerable to manipulation and participate in spreading the messages trolls post. We refer to\nsuch users as spreaders in this paper. Our second goal is to better understand what distinguishes\nspreaders form non-spreaders. If we can predict who will become a spreader, we can design a\ncounter-campaign, which might stop the manipulation before it achieves its goal.\nFor this study, we collected Twitter data over a period of seven weeks in the months leading\nup to the election. By continuously pulling the Twitter Search API for relevant, election-related\ncontent using hashtag- and keyword-based queries, we obtained a dataset of over 43 million tweets\ngenerated by about 5.7 million distinct users between September 16 and November 9, 2016. First,\nwe cross-referenced the list of Russian trolls published by the US Congress with our dataset and\nfound that 221 Russian trolls accounts exist in our dataset. Next, we identified the list of users who\nretweeted the trolls. We gather important features about the users and use a machine learning\nframework to address the questions posed earlier.\nWe used different machine learning classifiers on different models (each model includes a subset\nof the features, with the full model including all the features). We are able to achieve an average\nAUC score of 96% for a 10-fold validation in terms of distinguishing spreaders form non-spreaders\nusing Gradient Boosting for the full model on a subset of the dataset where the outcome variable\nhas roughly equal number of spreaders vs. non-spreaders. Moreover, we verified our results on\nthe full dataset as well as datasets where we increase the features but drop any rows with missing\nvalues. We are able to still achieve over 90% average AUC score in the full model using Gradient\nBoosting. In terms of feature importance, political ideology is the most prominent for the balanced\ndataset, as well as in the validation settings. Number of followers, statuses (no. tweets), and bot\nscores were also in the top most predictive features both in the balanced and other datasets.\n2 RELATED LITERATURE\nThe use of trolls and bots in political manipulation campaigns around the globe is well documented\nthrough an array of reports by mainstream media outlets and academics (see Tucker et al .[2018]\nfor a comprehensive review on the role of misinformation, bots, and trolls on social media). This\nphenomenon is not entirely new: researchers warned about the potential for online political\nmanipulation for over a decade [Howard 2006; Hwang et al .2012]. Reports tracking and studying\nthis phenomenon date back to the early 2010s [Metaxas and Mustafaraj 2012; Ratkiewicz et al .\n2011b,a]. Since then, an increasing account of such events has been recorded in the context of\nseveral elections, both in the United States [Bessi and Ferrara 2016; Kollanyi et al .2016; Marwick\nand Lewis 2017; Shorey and Howard 2016; Wang et al .2016; Woolley 2016; Woolley and Howard\n2016] and all over the world, including in South America [Forelle et al .2015; Su\u00e1rez-Serrato et al .\n2016], the U.K. [Howard and Kollanyi 2016], and Italy [Cresci et al. 2017].\nWho Falls for Online Political Manipulation? :3\nAlthough trolls do not necessarily need to be automated accounts, in many cases bots play\na substantial role in political manipulation. Bessi and Ferrara [2016] report that 400k bots were\nresponsible for posting 3.8 million tweets in the last month of the 2016 US presidential election,\nwhich is one-fifth of the total volume of online conversations they collected. Specifically, Russian\npolitical manipulation campaigns did not only target the US [Badawy et al .2018]: there is evidence\nof Russian interference in German electoral campaigns [Applebaum and Colliver. 2017], British\nelections [Gorodnichenko et al .2018], and the Catalonian referendum [Stella et al .2018]. Russian-\naffiliated accounts were also reported in the 2017 French presidential elections, where bots were\ndetected during the so-called MacronLeaks disinformation campaign [Ferrara 2017]. Moreover, a\nrecent NATO report claims that around 70% of accounts tweeting in Russian and directed at Baltic\ncountries and Poland are bots.\nRussian political manipulation online did not stop at Russia\u2019s borders. Domestically, there is\nstrong evidence that trolls and bots were present at multiple occasions. Ananyev and Sobolev\n[2017] provides evidence of Russian government-affiliated trolls being able to change the direction\nof conversations on the LiveJournal blog, a popular platform in Russia in the 2000s. Moreover, the\nsame entity that controlled many of the trolls studied in this paper, the Russian \"troll factory\", run\nby the Internet Research Agency , had its trolls contribute to Wikipedia in support of positions and\nhistorical narratives put forward by the current Russian government [Labzina 2017].\nOnline political manipulation is not only a Russian phenomenon. There is strong evidence of\nsimilar efforts by various governments to control political discussion online, particularly with the\nuse of bots. [King et al .2017] shows that the so-called \"50-centers\"\u2013low-paid government workers\nwho work online on behalf of the Chinese government\u2013 try to distract Chinese citizens online form\npolitically controversial topics. Even further, [Miller and Gallagher 2018] estimate that Chinese\nastroturfers produce about 15% of all comments made on the 19 popular Chinese news websites. In\nKorea, bots were utilized as a part of a secret intelligence operation in support of the incumbent\nparty\u2019s candidate reelection [Keller et al. 2017].\nThere is strong evidence that political manipulation campaigns are on the rise, but how effective\nare they? In the case of the recent US presidential elections, Allcott and Gentzkow [2017] find that,\neven though \u201cfake news\u201d stories were widely shared on social media during the 2016 election, an\naverage American saw only few of these stories. Despite this finding, we should not underestimate\nthe potential role misinformation might play in distorting the views of citizens. Misinformed\nindividuals hold consistently different opinions from those who are exposed to more factual\nknowledge. In some experimental studies, people who were exposed to accurate information about\npolitical issues often changed their views accordingly[Gilens 2001; Sides et al .2016]. Other studies\nshow that ignorance distorts collective opinion from what it would be if people were provided with\nmore information about politics [Althaus 1998; Bartels 1996; Gilens 2001] .\nThis distortion of individual opinion can lead to distortions at the aggregate level, as in the\ncollective public opinion. On many occasions, these distortions might be initiated, encouraged,\nand exploited by domestic political elites or foreign powers. Manipulating actors are attempting to\nconstruct their own \u201ctruth\u201d and push their version of the story in the public sphere to be adopted\nby their target audience. For example, some politicians might resort to distortion to win elections\nor avoid accountability for their performance in office [Flynn et al .2017; Fritz et al .2004]. Examples\nof misperceptions, whether caused by misinformation or not, that distort modern public policy\ndebates in the US are abound. For example, US citizens hold drastically exaggerated perceptions\nabout the amounts of the U.S. federal welfare, foreign aid, and the number of immigrants in the\ncountry. A recent Kaiser Family Foundation poll found that, on average, Americans estimated that\n31% of the federal budget goes to foreign aid, with very few people aware that the actual percentage\ndoes not exceed 1% [DiJulio and Brodie. 2016]. Similarly, another survey found that fewer than\n:4 Adam Badawy, Kristina Lerman, and Emilio Ferrara\none in ten respondents knew that welfare spending amounts to less than 1% of the federal budget\n[Kuklinski et al .2000]. Moreover, it has been found that Americans tend to overestimate the size of\nthe immigrant population [Hopkins et al .2018]. All these political misperceptions play a negative\nrole in American political life and strengthen the already polarized environment that the US finds\nitself in right now. In case of the recent presidential elections, we could see that trolls were spreading\nmisinformation about immigration, minority issues, and the government in general. The similarities\nwith the above-mentioned cases of misinformation are obvious: trolls adopt classical techniques\naimed at spreading misperceptions to push the agenda of the initiator of such campaigns.\nIn recent years, growing ideological and affective polarization was accompanied by the increase\nin conspiracy theories and partisan misinformation. Belief in false and unsupported claims is\nfrequently skewed by partisanship and ideology, suggesting that our vulnerability to them is\nincreased by directionally motivated reasoning. Directionally motivated reasoning is defined as\nthe tendency to selectively accept or reject information depending on its consistency with our\nprior beliefs and attitudes [Kunda 1990; Taber and Lodge 2006]. This tendency makes the recent\nUS presidential elections a good target for misinformation by internal and external actors: in\nan environment of severe polarization, both at the elite and mass level, false or misrepresented\ninformation that reinforces a person preexisting motivated perception/opinion can be quite effective.\nNyhan and Reifler [2010] and Flynn et al .[2017] show that motivated reasoning can even undermine\nthe effectiveness of corrective information, which sometimes fails to reduce misperceptions among\nvulnerable groups.\n3 DATA COLLECTION\n3.1 Twitter Dataset\nWe created a list of hashtags and keywords that relate to the 2016 U.S. Presidential election. The list\nwas crafted to contain a roughly equal number of hashtags and keywords associated with each major\nPresidential candidate: we selected 23 terms, including five terms referring to the Republican Party\nnominee Donald J. Trump (#donaldtrump, #trump2016, #neverhillary, #trumppence16, #trump), four\nterms for Democratic Party nominee Hillary Clinton (#hillaryclinton, #imwithher, #nevertrump,\n#hillary), and several terms related to debates. To make sure our query list was comprehensive,\nwe also added a few keywords for the two third-party candidates, including the Libertarian Party\nnominee Gary Johnson (one term), and Green Party nominee Jill Stein (two terms).\nBy querying the Twitter Search API continuously and without interruptions between September\n15 and November 9, 2016, we collected a large dataset containing 43.7 million unique tweets posted\nby nearly 5.7 million distinct users. Table 1 reports some aggregate statistics of the dataset. The data\ncollection infrastructure ran inside an Amazon Web Services (AWS) instance to ensure resilience\nand scalability. We chose to use the Twitter Search API to make sure that we obtained all tweets\nthat contain the search terms of interest posted during the data collection period, rather than a\nsample of unfiltered tweets. This precaution we took avoids known issues related to collecting\nsampled data using the Twitter Stream API that had been reported in the literature [Morstatter\net al. 2013].\n3.2 Russian Trolls\nWe used a list of 2,752 Twitter accounts identified as Russian trolls that was compiled and released\nby the U.S. Congress.1Table 2 offers some descriptive statistics of the Russian troll accounts. Out of\nthe accounts appearing on the list, 221 exist in our dataset, and 85 of them produced original tweets\n(861 tweets). Russian trolls in our dataset retweeted 2,354 other distinct users 6,457 times. Trolls\n1See https://www.recode.net/2017/11/2/16598312/russia-twitter-trump-twitter-deactivated-handle-list\nWho Falls for Online Political Manipulation? :5\nTable 1. Twitter Data Descriptive Statistics.\nStatistic Count\n# of Tweets 43,705,293\n# of Retweets 31,191,653\n# of Distinct Users 5,746,997\n# of Tweets/Retweets with a URL 22,647,507\nretweeted each other only 51 times. Twitter users can choose to report their location in their profile.\nMost of the self-reported locations of accounts associated with Russian trolls were within the U.S.\n(however, a few provided Russian locations in their profile), and most of the tweets were from users\nwhose location was self-reported as Tennessee and Texas (49,277 and 26,489 respectively). Russian\ntrolls were retweeted 83,719 times, but most of these retweets were for three troll accounts only:\n\u2018TEN_GOP\u2019, received 49,286 retweets; \u2018Pamela_Moore13\u2019, 16,532; and \u2018TheFoundingSon\u2019, 8,755.\nThese three accounts make up for over 89% of the times Russian trolls were retweeted. Overall,\nRussian trolls were retweeted by 40,224 distinct users.\nTable 2. Descriptive Statistics on Russian trolls.\nValue\n# of Russian trolls 2,735\n# of trolls in our data 221\n# of trolls wrote original tweets 85\n# of original trolls\u2019 tweets 861\n3.3 Spreaders\nUsers who rebroadcast content produced by Russian trolls, hereafter referred to as spreaders , may\ntell a fascinating story, thus will be the subject of our further investigation. Out of the forty thousand\ntotal spreaders, 28,274 of them produced original tweets (the rest only generated retweets). Overall,\nthese twenty-eight thousand spreaders produced over 1.5 Million original tweets and over 12\nMillion other tweets and retweets\u2014not counting the ones from Russian trolls (cf., Table 3).\nTable 3. Descriptive statistics of spreaders, i.e., users who retweeted Russian trolls.\nValue\n# of spreaders 40,224\n# of times retweeted trolls 83,719\n# of spreaders with original tweets 28,274\n# of original tweets >1.5 Million\n# of other tweets and retweets >12 Million\n4 DATA ANALYSIS & METHODS\nIn order to answer the questions posed in this paper, we gather a set of features about the users\nto(i)predict the spreaders with the highest accuracy possible and (ii)identify feature(s) which\n:6 Adam Badawy, Kristina Lerman, and Emilio Ferrara\nTable 4. List of features employed to characterize users in our dataset\nMetadata LIWC Engagement Activity Other\n# of followers Word Count Retweet variables # of characters Political Ideology\n# of favourites Postive Emotion Mention variables # of hashtags Bot Score\n# of friends Negative Emotion Reply variables # of mentions Tweet Count\nStatus count Anxiety Quote variables # of urls\nListed count Anger\nDefault Profile Sadness\nGeo-enabled Analytic\nBackground-image Clout\nVerified Affection\nAccount Age Tone\nbest distinguish spreaders from the rest. Table 4 shows all the features we evaluated in this paper,\ngrouped under the following categories: Metadata, Linguistic Inquiry and Word Count (LIWC),\nEngagement, Activity, and Other variables.\nTo understand what each variable in the Metadata and LIWC categories means, see the Twitter\ndocumentation page2and [Pennebaker et al .2015], respectively. The Activity variables convey the\nnumber of characters, hashtags, mentions, and URLs produced by users, normalized by the number\nof tweets they post. Tweet Count, under Other, is the number of user\u2019s tweets appearing in our\ndataset. The remaining variables are more involved and warrant a detailed explanation: we explain\nhow Political Ideology, Bot Scores, and Engagement variables were computed in the following\nsections. One may wonder how much the features evaluated here correlate with each other, and\nwhether they provide informative signals in terms of predictive power about the spreaders. Figure\n1 shows that, besides Engagement variables, most of the features are not highly correlated among\neach other (Pearson correlation is shown, results do not vary significantly for Spearman correlation).\nThere are however a few notable exceptions: Word Count and Tweet Count, LIWC Positive Emotion\nand Affection, Anxiety and Anger\u2014these pairs all show very high correlation. This is not surprising,\nconsidering that these constructs are conceptually close one another. As for the Engagement\nvariables, we can see a \"rich get richer\" effect here, where users who have higher scores in terms of\nsome of the sub-features in the Engagement category, are also higher in other sub-features. For\nexample, by construction the Retweet h-index will be proportional to the number of times a user\nis retweeted, and similarly for replies, quotes and mentions\u2014all these Engagement features are\nexplained in great detail in a section \u00a74.3.\n4.1 Political Ideology\n4.1.1 Classification of Media Outlets. We classify users by their ideology based on the political\nleaning of the media outlets they share. We use lists of partisan media outlets compiled by third-\nparty organizations, such as AllSides3and Media Bias/Fact Check.4The combined list includes 249\nliberal outlets and 212 conservative outlets. After cross-referencing with domains obtained in our\nTwitter dataset, we identified 190 liberal and 167 conservative outlets. We picked five media outlets\nfrom each partisan category that appeared most frequently in our Twitter dataset and compiled\n2https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object\n3https://www.allsides.com/media-bias/media-bias-ratings\n4https://mediabiasfactcheck.com/\nWho Falls for Online Political Manipulation? :7\nFig. 1. Feature correlation heat map for the all users in the dataset.\na list of users who tweeted from these outlets. The list of media outlets/domain names for each\npartisan category is reported in Table 5.\nTable 5. Liberal & Conservative Domain Names.\nLiberal Conservative\nwww.huffingtonpost.com www.breitbart.com\nthinkprogress.org www.thegatewaypundit.com\nwww.politicususa.com www.lifezette.com\nshareblue.com www.therebel.media\nwww.dailykos.com theblacksphere.net\nWe used a polarity rule to label Twitter users as liberal or conservative depending on the number\nof tweets they produced with links to liberal or conservative sources. In other words, if a user\nhad more tweets with links to liberal sources, he/she would be labeled as liberal and vice versa.\nAlthough the overwhelming majority of users include links that are either liberal or conservative,\n:8 Adam Badawy, Kristina Lerman, and Emilio Ferrara\nwe remove any users that had equal number of tweets from each side5\u2014this to avoid the conundrum\nof breaking ties with some arbitrary rule. Our final set of labeled users include 29,832 users.\n4.1.2 Label Propagation. We used label propagation6to classify Twitter accounts as liberal or\nconservative, similar to prior work [Conover et al .2011]. In a network-based label propagation\nalgorithm, each node is assigned a label, which is updated iteratively based on the labels of the node\u2019s\nnetwork neighbors. In label propagation, a node takes the most frequent label of its neighbors as\nits own new label. The algorithm proceeds updating labels iteratively and stops when the labels no\nlonger change (see [Raghavan et al .2007] for more information). The algorithm takes as parameters\n(i)weights, in-degree or how many times node iretweeted node j;(ii)seeds (the list of labeled\nnodes). We fix the seeds\u2019 labels so they do not change in the process, since this seed list also serves\nas our ground truth.\nWe construct a retweet network where each node corresponds to a Twitter account and a link\nexists between pairs of nodes when one of them retweets a message posted by the other. We use the\n29K users mentioned in the media outlets sections as seeds, those who mainly retweet messages\nfrom either the liberal or the conservative media outlets in Table 5, and label them accordingly. We\nthen run label propagation to label the remaining nodes in the retweet network.\nTable 6. Breakdown for overall users, trolls and spreader by political ideology\nLiberal Conservative\n# of users >3.4 M >1 M\n# of trolls 107 108\n# of spreaders 1,991 38,233\nTo validate results of the label propagation algorithm, we applied stratified 5-fold cross validation\nto the set of 29K seeds. We train the algorithm on four-fifths of the seed list and test how it performs\non the remaining one-fifth. The averge precision and recall scores are both over 91%.\nTo further validate the labeling algorithm, we notice that a group of Twitter accounts put media\noutlet URLs as their personal link/website. We compile a list of the hyper-partisan Twitter users\nwho have the domain names from Table 5 in their profiles and use the same approach explained\nin the previous paragraph (stratified 5-fold cross-validation). The average precision and recall\nscores for the test set for these users are above 93%. Table 7 shows the average precision and recall\nscores for the two validation methods we use: both labeled over 90% of the test set users correctly,\ncementing our confidence in the performance of the labeling algorithm.\nTable 7. Precision & Recall scores for the seed users and hyper-partisan users test sets.\nSeed Users Hyper-Partisan Users\nPrecision 91% 93%\nRecall 91% 93%\n5We use five categories, as in left, left center, center, right center, right, to make sure we have a final list of users who are\nunequivocally liberal or conservative and do not fall in the middle. The media outlet lists for the left/right center and center\nwere compiled from the same sources.\n6We used the algorithm in the Python implementation of the IGraph library [Csardi and Nepusz 2006]\nWho Falls for Online Political Manipulation? :9\n4.2 Bot Detection\nDetermining whether either a human or a bot controls a social media account has proven a very\nchallenging task [Ferrara et al .2016; Subrahmanian et al .2016]. We use an openly accessible\nsolution called Botometer (a.k.a. BotOrNot) [Davis et al .2016], consisting of both a public Web site\n(https://botometer.iuni.iu.edu/) and a Python API (https://github.com/IUNetSci/botometer-python),\nwhich allows for making this determination with high accuracy. Botometer is a machine-learning\nframework that extracts and analyses a set of over one thousand features, spanning six sub classes:\nUser : Meta-data features that include the number of friends and followers, the number of\ntweets produced by the users, profile description and settings.\nFriends : Four types of links are considered here: retweeting, mentioning, being retweeted,\nand being mentioned. For each group separately, botometer extracts features about language\nuse, local time, popularity, etc.\nNetwork : Botometer reconstructs three types of networks: retweet, mention, and hashtag co-\noccurrence networks. All networks are weighted according to the frequency of interactions\nor co-occurrences.\nTemporal : Features related to user activity, including average rates of tweet production over\nvarious time periods and distributions of time intervals between events.\nContent : Statistics about length and entropy of tweet text and Part-of-Speech (POS) tagging\ntechniques, which identifies different types of natural language components, or POS tags.\nSentiment : Features such as: arousal, valence and dominance scores [Warriner et al .2013],\nhappiness score [Kloumann et al .2012], polarization and strength [Wilson et al .2005], and\nemotion score [Agarwal et al. 2011].\nWe utilize Botometer to label all the spreaders, and we get bot scores for over 34K out of the total\n40K spreaders. Since using Botometer to get scores all non-spreaders (i.e., over 5.7M users) would\ntake an unfeasibly long time (due to Twitter\u2019s restrictions), we randomly sample the non-spreader\nuser list and use Botometer to get scores for a roughly equivalent-size list of non-spreader users.\nThe randomly-selected non-spreader list includes circa 37K users. To label accounts as bots, we\nuse the fifty-percent threshold which has proven effective in prior studies [Davis et al .2016]: an\naccount is considered to be a bot if the overall Botometer score is above 0.5. Figure 2 shows the\nprobability distribution for spreaders vs. non-spreaders. While most of the density is under the 0.5\nthreshold, the mean of spreaders (0.3) is higher than the mean of non-spreaders. Additionally, we\nused a t-test to verify that the difference is significant at the 0.001 level (p-value).\nAs for the plots in Figure 3, it is evident that the spreaders are different on almost all the Botometer\nsubclass scores, except for the temporal features. The differences in all plots are statistically\nsignificant (p <0.001). Besides, looking at the distributions, we can see that the difference in user\ncharacteristics (metadata), friends, and network distributions, are substantively different as well.\nMoreover, the mean of spreaders is higher in all the subclass features.\n4.3 Engagement\nWe plan to measure user engagement in four activities: retweets, mentions, replies, and quotes.\nEngagement of a user is measured through three components: the quantity, longevity, and stability\nin each activity. For instance, for a set of Nusers, this measure would calculate the engagement\nindex score of user i\u2208Nby including the following:\n1)number of retweets, replies, mentions, and quotes by N\u2212iusers for user i;\n2)time difference between the last and the first quote, reply, and retweet per tweet;\n3)consistency of mentioning, replying, retweeting, and quoting by N\u2212iusers for user iacross\ntime (per day);\n:10 Adam Badawy, Kristina Lerman, and Emilio Ferrara\nFig. 2. Probability density distributions of bot scores assigned to spreaders (red) and non-spreaders (blue).\n4)number of unique users who retweeted, commented, mentioned, and quoted user i\nItem three is measured using h-index [Hirsch 2005]. The measure captures two notions: how\nhighly referenced and how continuously highly referenced a user is by other members in the\nnetwork [Lietz et al .2014]. This measure was originally proposed to quantify an individual\u2019s\nscientific research output. In this context, a user has index hif for hdays, he/she is referenced at\nleast htimes and in all but hdays no more than htimes.\n5 RESULTS\nPredicting spreaders on the original dataset may be considered a daunting task: only a relatively\nsmall fraction of users engaged with Russian trolls\u2019 content (about 40K out of 5.7M users). However,\nfor the same reason, if a model were to trivially predict that no user will ever engage with Russian\ntrolls, the model would be accurate most of the time (i.e., most users won\u2019t be spreaders), even if its\nrecall would be zero (i.e., the model would never correctly predict any actual spreaders)\u2014provided\nthat we want to predict spreaders, this model would not be very useful in practice. In other words,\nour setting is a typical machine-learning example of a highly-unbalanced prediction task.\nTo initially simplify our prediction task, we created a balanced dataset that is limited to users\nwho have bot scores.7This balanced dataset has about 72K users, with 34K spreaders and 38K\nnon-spreaders. To test our ability to detect spreaders and to see which features are most important\nin distinguishing between the two groups, we leverage multiple classifiers and multiple models: the\nfirst model serves as a baseline with each model including more variables until we reach the full\nmodel. Since our goal was not that to devise new techniques, we used four off-the-shelf machine\nlearning algorithms: Extra Trees, Random Forest, Adaptive Boosting, and Gradient Boosting. We\ntrain our classifiers using Stratified 10-fold cross-validation with the following preprocessing steps\n(i)replace all categorical missing values with the most frequent value in the column (ii)replace\nmissing values with the mean of the column.\nTable 8 shows all the models we evaluate, from the simplest baseline model (Metadata) to the\nfull model that includes all the features we present in Table 4.\nFor Gradient Boosting, which is the best performing classifier among the four we evaluate, we\nobtained average AUC scores for the 10 folds that range from 85% to 96%. Figure 4 shows the ROC\n7Will get back to the original prediction task on the highly-unbalanced dataset later in this section.\nWho Falls for Online Political Manipulation? :11\n(a) Content\n (b) Friend\n(c) Network\n (d) Sentiment\n(e) Temporal\n (f) User\nFig. 3. Distribution of the probability density of Botometer subfeature scores for spreaders vs. nonspreaders.\ncurve plots for each model (using the fold/model with the highest AUC score among the trained\nones). The jump from 89% to 96% for the AUC scores from Model 4 to 5 shows that the addition of\nbot scores and political ideology are meaningful in distinguishing spreaders from non-spreaders\n(the legend in Figure 4 shows the average AUC score for each model). To better understand the\ncontribution of the features in predicting the target values (i.e., spreader vs. non-spreader), we\nlook at the variable importance plot of the Gradient Boosting results for Model 5. The Variable\nImportance plot (cf., Figure 5) provides a list of the most significant variables in descending order\nby a mean decrease in the Gini criterion. The top variables contribute more to the model than the\n:12 Adam Badawy, Kristina Lerman, and Emilio Ferrara\nTable 8. Machine Learning Models from the Baseline (Metadata) to Full Model.\nModel Features\n1 Metadata\n2 Metadata + LIWC\n3 Metadata + LIWC + Activity\n4 Metadata + LIWC +Activity + Engagement\n5 Metadata + LIWC +Activity + Engagement + Other\nFig. 4. Area under the ROC curve plot for the five models under evaluation using Gradient Boosting. We show\nfive models, in each we use the fold/model that yields the highest AUC among the trained ones. It is evident\nthat the addition of bot scores, political ideology, and tweet count variables are important in improving the\nperformance of the classifiers. The legend shows the average AUC scores for each model.\nbottom ones and can discriminate better between spreaders and non-spreaders. In other words,\nfeatures are ranked based on their predictive power according to the given model. Figure 5 shows\nthat, according to Model 5 and Gradient Boosting, political ideology is the most predictive feature,\nfollowed by number of followers, statuses/tweets count (obtained from the metadata), and bot score,\nin a descending order of importance. The plot does not show all the features, since the omitted\nfeatures contribute very little to the overall predictive power of the model.\nFeature importance plots reveal which features contribute most to classification performance, but\nthey do not tell us the nature of the relationship between the outcome variable and the predictors.\nAlthough predictive models are sometime used as black boxes, Partial Dependence plots (cf., Fig.\n6) can tell us a lot about the structure and direction of the relationship between the target and\nindependent variables. They show these relationships after the model is fitted, while marginalizing\nWho Falls for Online Political Manipulation? :13\nFig. 5. Relative importance of the features using Gradient Boosting for the full model (best performing fold) in\npredicting users as spreaders vs. non-spreaders. Political Ideology explains over 25% of the variance, followed\nby Followers Count, Statuses Counts, and Bot Scores, each explaining roughly 5% to 10% of the variance.\nover the values of all other features. The dependency along the x-axis captures the range of a given\nfeature, with that feature values normalized between 0 and 1.8\nUsing Partial Dependence, we illustrate that the target variable (spreader) has positive relation-\nships with the following features: political ideology, statuses count, bot scores, and friends count.\nFigure 6a visualizes these relationships (we put political ideology on a different y-axis in order to\nshow that its magnitude of influence on the target variable is significantly higher compared to all\nother features, including downward trend features in Figure 6b). This suggests that moving from\nleft to right political leaning increases the probability of being a spreader; larger number of posts,\nmore friends (a.k.a. followees), and higher bot scores are also associated with higher likelihood of\nbeing a spreader.\nOn the other hand, we can see that the outcome variable has a negative relationship with\nfollowers count, account age, characters count, and word count, as shown in Figure 6b. This means\nthat having fewer followers, having a recently-created account, posting shorter tweets with fewer\nwords, are all characteristics associated with higher probability of being a spreader.\nGoing back to the original highly-unbalanced dataset, we aim to validate the results above using\ntwo strategies: (i)we run Gradient Boosting (with the same preprocessing steps) on the whole\ndataset of 5.7M for the five models we outlined in table 8; (ii)we run Gradient Boosting classifier\non models without imputations and with all missing observations deleted. For the first approach,\nthe average AUC scores ranged form 83% for the baseline model to 98% for the full model. For\nthe second approach, due to the sparsity of some features, the overall number of observations\ndecreases significantly when these features are added. Putting the overall number of observations\naside, the average ROC scores for a 10-fold validation for the roughly same set of models specified\n8Political ideology should be considered in the range from 0 (to identify left leaning users), to 1 (for right-leaning ones).\n:14 Adam Badawy, Kristina Lerman, and Emilio Ferrara\n(a) Upward Trends\n(b) Downward Trends\nFig. 6. Partial Dependence plots for some of the features considered in the full model (best preforming fold).\nThese partial dependence plots are for the Gradient Boosting Classifier fitted to the balanced dataset. Each\nplot shows the dependence of feature (spreader) on the feature under consideration, marginalizing over the\nvalues of all other features (Note: x-axis values are CDF-normalized).\nearlier range from 84% to 91%. In terms of feature importance, political ideology is again the most\nimportant in the full model, with status count and bot scores following it in importance. In summary,\nthe results above remain consistent when validating on the highly-unbalanced prediction task.\n6 DISCUSSION AND LIMITATIONS\nThe results in previous section show that (i)with some insight on users who spread or produce\nmalicious content, we are able to predict the users that will spread their message to a broader\naudience; (ii)in the case we focus on, the 2016 US presidential elections, political ideology was\nhighly predictive of who is going to spread trolls\u2019 messages vs. not. Moreover, looking at the top\npredictive features in Figure 5, basic metadata features give a strong signal in terms of differentiating\nspreaders from non-spreaders, along with the bot score. Looking at the subclass features from\nBotometer, Figures 3b, 3c, and 3f show that spreaders and non-spreaders are significantly different\non the dimensions of friends, network, and user metadata, with spreaders having higher bot scores\non all three (thus, they have a higher likelihood of being a bot according to those subclasses).\nLooking at the partial dependence plots, we can deduce that spreaders write a lot of tweets\n(counting retweets as well), have higher bot scores, and tend to be more conservative (conservative\nis labeled as the highest numerical value in the political ideology feature). Also, since the range\nof the y-axis tells us about the range of influence a feature has on the target value, it is evident\nthat political ideology has by far the most influence on distinguishing between spreaders and\nnon-spreaders. On the other hand, we can also deduce that spreaders do not write much original\ncontent, tend not have that many followers, and have more recently established user accounts. In\nthe downward trends in Figure 6b, we can see that followers count and account age have more\ninfluence on the target value in comparison to the other features in this plot.\nAlthough our analysis shows that certain features might be predictive of spreaders, there are\ncertain limitations to how generalizable these findings can be. First and foremost, our data does\nnot capture all the trolls in the trolls\u2019 list. The rest of the trolls might not be present in our dataset\ndue to various reasons; perhaps, they were simply not that active during the period of our data\ncollection. In any case, it is virtually impossible to gauge the effect of such missingness on our\nresults and conclusions. Second, we lack sufficient information on how the troll list was compiled\nWho Falls for Online Political Manipulation? :15\nin the first place. This might be an issue, since the methodology taken to identify these trolls could\ninclude certain biases that might affect our conclusions. Third, while political ideology emerged as\nthe most predictive feature among the ones included in the paper, it is important to note that a large\nportion of the trolls\u2019 tweets were targeting conservatives in the first place. Thus, this finding gives\nus some insight into the conservatives\u2019 reaction to political manipulation; however, it does not tell\nus much about the respective reaction on the liberal side. Fourth, certain tools used in the paper\nmight work better on some types of data than others [Hoffman et al .2017]. For example, some of\nLIWC categories might work better on longer and more elaborate texts than tweets, particularly\non types of text that capture more sophisticated emotions beyond simply negative and positive\nvalence. Lastly, and this goes for any case study, our conclusions could be influenced by the special\ncircumstances of the 2016 US presidential elections, and the same phenomenon may or may not\nunfold in the similar manner in a different context.\nDespite the above-mentioned limitations of our approach and data, it is important to note\nthat understanding massive online political manipulation campaigns is, nevertheless, extremely\nimportant, and that the threat of such attacks on our democratic systems will not go away any\ntime soon. In this paper, we used a dataset collected through keywords that, in our view, fully\nencompass the political event under study. Using the list of trolls published by the Congress, we\nwere able to study a phenomenon we do not yet fully understand, to comprehend how it functions,\nand to start a conversation on whether it can be stopped or prevented in a duly manner. Overall,\nwe employed a variety of rigorous computational tools to analyze and predict trolls\u2019 activities in\nthe recent US presidential elections.\n7 CONCLUSION\nThis work focused on predicting spreaders who fall for online manipulation campaigns. We believe\nthat identifying likely victims of political manipulation campaigns is the first step in containing the\nspread of malicious content. Access to reliable and trustworthy information is a cornerstone of any\ndemocratic society. Declining trust of citizens of democratic societies in mainstream news and their\nincreased exposure to content produced by ill-intended sources poses a great danger to democratic\nlife. Social science literature shows a lot of evidence that mis-perceptions on the individual level\ncan aggregate into a distortion in the collective public opinion [Bartels 2002; Baum and Groeling\n2009], which can have severe policy implications [Flynn et al .2017; Fritz et al .2004]. Thus, we\nbelieve that studying how and who spreads political manipulation content is extremely important,\nand it is an issue that many social media platforms should attempt to contain.\nACKNOWLEDGMENTS\nThe authors gratefully acknowledge support by the Air Force Office of Scientific Research (award\n#FA9550-17-1-0327). The views and conclusions contained herein are those of the authors and\nshould not be interpreted as necessarily representing the official policies or endorsements, either\nexpressed or implied, of AFOSR or the U.S. Government.\nREFERENCES\nApoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data.\nInProceedings of the workshop on languages in social media . Association for Computational Linguistics, 30\u201338.\nHunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the 2016 election. Journal of Economic Perspectives\n31, 2 (2017), 211\u201336.\nScott L Althaus. 1998. Information effects in collective preferences. American Political Science Review 92, 3 (1998), 545\u2013558.\nMaxim Ananyev and Anton Sobolev. 2017. Fantastic Beasts and Whether They Matter: Do Internet Trolls Influence Political\nConversations in Russia? In preparation (2017).\n:16 Adam Badawy, Kristina Lerman, and Emilio Ferrara\nPeter Pomerantsev Melanie Smith Applebaum, Anne and Chloe Colliver. 2017. \"MAKE GERMANY GREAT AGAIN\u00e2\u0102\u0130\nKremlin, Alt-Right and International Influences in the 2017 German Elections. (2017).\nAdam Badawy, Emilio Ferrara, and Kristina Lerman. 2018. Analyzing the Digital Traces of Political Manipulation: The 2016\nRussian Interference Twitter Campaign. arXiv preprint arXiv:1802.04291 (2018).\nEytan Bakshy, Solomon Messing, and Lada A Adamic. 2015. Exposure to ideologically diverse news and opinion on Facebook.\nScience 348, 6239 (2015), 1130\u20131132.\nLarry M Bartels. 1996. Uninformed votes: Information effects in presidential elections. American Journal of Political Science\n(1996), 194\u2013230.\nLarry M Bartels. 2002. Beyond the running tally: Partisan bias in political perceptions. Political behavior 24, 2 (2002),\n117\u2013150.\nMatthew A Baum and Tim Groeling. 2009. Shot by the messenger: Partisan cues and public opinion regarding national\nsecurity and war. Political Behavior 31, 2 (2009), 157\u2013186.\nAlessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US Presidential election online discussion. First\nMonday 21, 11 (2016).\nM Conover, B Gon\u00e7alves, J Ratkiewicz, A Flammini, and F Menczer. 2011. Predicting the Political Alignment of Twitter\nUsers. In Proc. 3rd IEEE Conference on Social Computing . 192\u2013199.\nStefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. 2017. The paradigm-shift\nof social spambots: Evidence, theories, and tools for the arms race. In Proceedings of the 26th International Conference on\nWorld Wide Web Companion . International World Wide Web Conferences Steering Committee, 963\u2013972.\nGabor Csardi and Tamas Nepusz. 2006. The igraph software package for complex network research. InterJournal, Complex\nSystems 1695, 5 (2006), 1\u20139.\nClayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and Filippo Menczer. 2016. Botornot: A system to\nevaluate social bots. In Proc. 25th International Conference on World Wide Web . 273\u2013274.\nMira Norton DiJulio, Bianca and Mollyann Brodie. 2016. Americans\u00e2\u0102\u0179 Views on the U.S. Role in Global Health.\u00e2\u0102\u0130. (2016).\nEmilio Ferrara. 2017. Disinformation and social bot operations in the run up to the 2017 French presidential election. First\nMonday 22, 8 (2017).\nEmilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro Flammini. 2016. The rise of social bots. Comm.\nof the ACM 59, 7 (2016), 96\u2013104.\nDJ Flynn, Brendan Nyhan, and Jason Reifler. 2017. The nature and origins of misperceptions: Understanding false and\nunsupported beliefs about politics. Political Psychology 38, S1 (2017), 127\u2013150.\nMichelle Forelle, Phil Howard, Andr\u00e9s Monroy-Hern\u00e1ndez, and Saiph Savage. 2015. Political bots and the manipulation of\npublic opinion in Venezuela. arXiv preprint arXiv:1507.07109 (2015).\nBen Fritz, Bryan Keefer, and Brendan Nyhan. 2004. All the president\u2019s spin: George W. Bush, the media, and the truth . Simon\nand Schuster.\nTheodore P Gerber and Jane Zavisca. 2016. Does Russian propaganda work? The Washington Quarterly 39, 2 (2016), 79\u201398.\nMartin Gilens. 2001. Political ignorance and collective policy preferences. American Political Science Review 95, 2 (2001),\n379\u2013396.\nYuriy Gorodnichenko, Tho Pham, Oleksandr Talavera, et al .2018. Social media, sentiment and public opinions: Evidence\nfrom# Brexit and# USElection . Technical Report.\nJeffrey Gottfried and Elisa Shearer. 2016. News Use Across Social Medial Platforms 2016 . Pew Research Center.\nJorge E Hirsch. 2005. An index to quantify an individual\u2019s scientific research output. Proceedings of the National academy of\nSciences of the United States of America 102, 46 (2005), 16569.\nErin R. Hoffman, David W. McDonald, and Mark Zachry. 2017. Evaluating a Computational Approach to Labeling Politeness:\nChallenges for the Application of Machine Classification to Social Computing Data. Proc. ACM Hum.-Comput. Interact. 1,\nCSCW, Article 52 (Dec. 2017), 14 pages. https://doi.org/10.1145/3134687\nDaniel J Hopkins, John Sides, and Jack Citrin. 2018. The muted consequences of correct information about immigration.\n(2018).\nPhilip Howard. 2006. New media campaigns and the managed citizen .\nPhilip N Howard and Bence Kollanyi. 2016. Bots,# strongerin, and# brexit: Computational propaganda during the uk-eu\nreferendum. Browser Download This Paper (2016).\nTim Hwang, Ian Pearce, and Max Nanis. 2012. Socialbots: Voices from the fronts. Interactions 19, 2 (2012), 38\u201345.\nFranziska B Keller, David Schoch, Sebastian Stier, and JungHwan Yang. 2017. How to Manipulate Social Media: Analyzing\nPolitical Astroturfing Using Ground Truth Data from South Korea.. In ICWSM . 564\u2013567.\nGary King, Jennifer Pan, and Margaret E Roberts. 2017. How the Chinese government fabricates social media posts for\nstrategic distraction, not engaged argument. American Political Science Review 111, 3 (2017), 484\u2013501.\nIsabel M Kloumann, Christopher M Danforth, Kameron Decker Harris, Catherine A Bliss, and Peter Sheridan Dodds. 2012.\nPositivity of the English language. PloS one 7, 1 (2012), e29484.\nWho Falls for Online Political Manipulation? :17\nBence Kollanyi, Philip N Howard, and Samuel C Woolley. 2016. Bots and automation over Twitter during the first US\nPresidential debate. (2016).\nJames H Kuklinski, Paul J Quirk, Jennifer Jerit, David Schwieder, and Robert F Rich. 2000. Misinformation and the currency\nof democratic citizenship. Journal of Politics 62, 3 (2000), 790\u2013816.\nZiva Kunda. 1990. The case for motivated reasoning. Psychological bulletin 108, 3 (1990), 480.\nElena Labzina. 2017. Rewriting Knowledge: Russian Political Astroturfing as an Ideological Manifestation of the National\nRole Conceptions. In preparation (2017).\nHaiko Lietz, Claudia Wagner, Arnim Bleier, and Markus Strohmaier. 2014. When politicians talk: Assessing online conversa-\ntional practices of political parties on twitter. Proceedings of the Eighth International AAAI Conference on Weblogs and\nSocial Media (2014).\nAlice Marwick and Rebecca Lewis. 2017. Media manipulation and disinformation online. New York: Data & Society Research\nInstitute (2017).\nPanagiotis T Metaxas and Eni Mustafaraj. 2012. Social media and the elections. Science 338, 6106 (2012), 472\u2013473.\nBlake Miller and Mary Gallagher. 2018. The Progression of Repression: When does online censorship move toward real\nworld repression? (2018).\nFred Morstatter, J\u00fcrgen Pfeffer, Huan Liu, and Kathleen M Carley. 2013. Is the Sample Good Enough? Comparing Data from\nTwitter\u2019s Streaming API with Twitter\u2019s Firehose. In ICWSM . 400\u2013408.\nBrendan Nyhan and Jason Reifler. 2010. When corrections fail: The persistence of political misperceptions. Political Behavior\n32, 2 (2010), 303\u2013330.\nJames W Pennebaker, Ryan L Boyd, Kayla Jordan, and Kate Blackburn. 2015. The development and psychometric properties of\nLIWC2015 . Technical Report.\nWhitney Phillips. 2015. This is why we can\u2019t have nice things: Mapping the relationship between online trolling and mainstream\nculture . Mit Press.\nUsha Nandini Raghavan, R\u00e9ka Albert, and Soundar Kumara. 2007. Near linear time algorithm to detect community structures\nin large-scale networks. Physical review E 76, 3 (2007), 036106.\nJacob Ratkiewicz, Michael Conover, Mark Meiss, Bruno Gon\u00e7alves, Snehal Patil, Alessandro Flammini, and Filippo Menczer.\n2011b. Truthy: mapping the spread of astroturf in microblog streams. In Proceedings of the 20th international conference\ncompanion on World wide web . ACM, 249\u2013252.\nJacob Ratkiewicz, Michael Conover, Mark R Meiss, Bruno Gon\u00e7alves, Alessandro Flammini, and Filippo Menczer. 2011a.\nDetecting and tracking political abuse in social media. ICWSM 11 (2011), 297\u2013304.\nSamantha Shorey and Philip N Howard. 2016. Automation, Algorithms, and Politics: A Research Review. Int. J Comm. 10\n(2016).\nJohn Sides, Michael Tesler, and Lynn Vavreck. 2016. The electoral landscape of 2016. The ANNALS of the American Academy\nof Political and Social Science 667, 1 (2016), 50\u201371.\nMassimo Stella, Emilio Ferrara, and Manlio De Domenico. 2018. Bots sustain and inflate striking opposition in online social\nsystems. arXiv preprint arXiv:1802.07292 (2018).\nPablo Su\u00e1rez-Serrato, Margaret E Roberts, Clayton Davis, and Filippo Menczer. 2016. On the influence of social bots in\nonline protests. In International Conference on Social Informatics . Springer, 269\u2013278.\nVS Subrahmanian, Amos Azaria, Skylar Durst, Vadim Kagan, Aram Galstyan, Kristina Lerman, Linhong Zhu, Emilio Ferrara,\nAlessandro Flammini, and Filippo Menczer. 2016. The DARPA Twitter bot challenge. Computer 49, 6 (2016).\nCharles S Taber and Milton Lodge. 2006. Motivated skepticism in the evaluation of political beliefs. American Journal of\nPolitical Science 50, 3 (2006), 755\u2013769.\nJoshua Tucker, Andrew Guess, Pablo Barber\u00e1, Cristian Vaccari, Alexandra Siegel, Sergey Sanovich, Denis Stukal, and\nBrendan Nyhan. 2018. Social Media, Political Polarization, and Political Disinformation: A Review of the Scientific\nLiterature. (2018).\nJoshua A Tucker, Yannis Theocharis, Margaret E Roberts, and Pablo Barber\u00e1. 2017. From liberation to turmoil: social media\nand democracy. Journal of democracy 28, 4 (2017), 46\u201359.\nYu Wang, Yuncheng Li, and Jiebo Luo. 2016. Deciphering the 2016 US Presidential Campaign in the Twitter Sphere: A\nComparison of the Trumpists and Clintonists.. In ICWSM . 723\u2013726.\nAmy Beth Warriner, Victor Kuperman, and Marc Brysbaert. 2013. Norms of valence, arousal, and dominance for 13,915\nEnglish lemmas. Behavior research methods 45, 4 (2013), 1191\u20131207.\nTheresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis.\nInProceedings of the conference on human language technology and empirical methods in natural language processing .\nAssociation for Computational Linguistics, 347\u2013354.\nSamuel C Woolley. 2016. Automating power: Social bot interference in global politics. First Monday 21, 4 (2016).\nSamuel C Woolley and Philip N Howard. 2016. Automation, Algorithms, and Politics: Introduction. Int. Journal of Commun.\n10 (2016).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Who falls for online political manipulation?", "author": ["A Badawy", "K Lerman", "E Ferrara"], "pub_year": "2019", "venue": "\u2026 proceedings of the 2019 world wide \u2026", "abstract": "Social media, once hailed as a vehicle for democratization and the promotion of positive  social change across the globe, are under attack for becoming a tool of political manipulation"}, "filled": false, "gsrank": 93, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3308560.3316494", "author_id": ["", "PlAG11IAAAAJ", "0r7Syh0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:qSFuPARYC4MJ:scholar.google.com/&output=cite&scirp=92&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D90%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=qSFuPARYC4MJ&ei=FbWsaISmDuHUieoP9LKZ6AI&json=", "num_citations": 137, "citedby_url": "/scholar?cites=9442737818929340841&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:qSFuPARYC4MJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1808.03281"}}, {"title": "The Colorado Wolf Reintroduction Portrayal in News Media", "year": "2024", "pdf_data": "Student Publications Student Scholarship \nSummer 2024 \nThe Color ado W olf Reintr oduction P ortrayal in News Media The Color ado W olf Reintr oduction P ortrayal in News Media \nMegan K. McAr thur \nGettysbur g College \nMonica V . Ogr a \nGettysbur g College \nFollow this and additional works at: https:/ /cupola.gettysbur g.edu/student_scholarship \n Part of the Envir onmental P olicy Commons , Journalism Studies Commons , and the Natur al Resour ces \nand Conser vation Commons \nShar e feedback Shar e feedback   about the accessibility of this item. about the accessibility of this item. \nRecommended Citation Recommended Citation \nMcAr thur, Megan K. and Ogr a, Monica V ., \"The Color ado W olf Reintr oduction P ortrayal in News Media \" \n(2024). Student Publications . 1132. \nhttps:/ /cupola.gettysbur g.edu/student_scholarship/1132 \nThis open access poster is br ought t o you b y The Cupola: Scholarship at Gettysbur g College. It has been accepted \nfor inclusion b y an authoriz ed administr ator of The Cupola. F or mor e information, please contact \ncupola@gettysbur g.edu . \nThe Color ado W olf Reintr oduction P ortrayal in News Media The Color ado W olf Reintr oduction P ortrayal in News Media \nAbstr act Abstr act \nThe Color ado gr ay wolf (Canis lupus) r eintr oduction began in December 2023 in the hope of r estoring this \nonce nativ e population t o the ar ea, and it has r eceiv ed mix ed responses fr om the media. By answering the \nresear ch question of 'How has the wolf r eintr oduction in Color ado been fr amed in news media?', this \nresear ch poster looks at the por trayal of the r eintr oduction in news ar ticles fr om six months befor e and \nafter the first wolv es wer e released. Media is an influential fact or in people 's opinions and it is impor tant \nto be awar e of the information being shar ed and any bias within them. \nKeywor ds Keywor ds \nwolv es, Color ado, r eintr oduction, newsmedia, Compassionate conser vation \nDisciplines Disciplines \nEnvir onmental P olicy | Journalism Studies | Natur al Resour ces and Conser vation \nComments Comments \nFunded b y the K olbe Resear ch F ellowship \nCreativ e Commons License Creativ e Commons License \nThis work is licensed under a Creativ e Commons A ttribution 4.0 License . \nThis poster is a vailable at The Cupola: Scholarship at Gettysbur g College: https:/ /cupola.gettysbur g.edu/\nstudent_scholarship/1132 \nThe Colorado Wolf Reintroduction Portrayal in News Media\nMegan McArthur &  Monica Ogra\nEnvironmental Studies Department, Gettysburg College, Gettysburg PA 17325  \nIntroduction \nAs Euro -American settlers moved west across North America in the \n1800s, they came across natural predators on the land, including the \ngray wolf ( Canis lupus ). Largely in response to wolf predation on \nvaluable livestock, the species was hunted to extirpation in the west \nby the 1940s  (National Park Service n.d.). In light of the subsequent \ntrophic cascade, wolves were reintroduced to Yellowstone NP in \n1995 in an attempt to restore the ecological benefits lost with their \nresident wolves (National Park Service n.d.). To connect the historic \nhabitat area in the Rocky Mountains, Colorado was chosen as the \nnext focus. On December 18, 2023, five gray wolves were released in \nWestern Colorado, launching the first stage of a 2020 voter -\nmandated reintroduction of the nearly -extinct species of wildlife in \nthe US. Another five wolves were released later that same month on \nDecember 22. The program passed in a Colorado state vote with a \n51% to 49% result. \nFigure 1 -2. Photos from reintroduction -related news articles \n(Photos:  J. Neal/CO Parks and Wildlife (Left);  T. Schmidt (Right)\nResearch Questions \nHow has the wolf reintroduction in Colorado been framed in news \nmedia ? To address this question, w e employed 4 sub -questions: \n1.What  is the relationship between article framing and source?\n2.Is the headline type reflective of partisan media bias?\n3.To what extent are key story elements included in the reporting?\n4.Are the article content frames dependent on source geography? \nMethods \nWe located relevant articles using targeted keyword searches in \nthree databases: EBSCO Newspaper Source, MUSCAT +, and \nGoogleNews. Irrelevant articles and duplicates were removed. \nSources were compiled over a 12 -month period (6 months \nbefore/after the start  of the reintroduction period in Dec 2023). \nFollowing methods described in Crown and Doubleday (2017) and \nMajor (2024), we sorted the resulting articles into 5 geographic \nnews source categories (local, state, regional, national, and \ninternational). These were later re -combined into high (local, state, \nregional) and low (national, international) proximity categories. Each \narticle headline (article frame) type was subcategorized as positive, \nnegative, or neutral based on a coding scheme that evaluated how it \naddressed the reintroduction. Political media bias (left, center, right) \nfor each source publication was tracked and coded according to \nratings assigned by MediaBiasFactCheck.com. Articles (content \nframing) were evaluated and coded as containing (Y) or not \ncontaining (N) elements of each frame (Table 1).\nThe resulting qualitatively coded themes were analyzed in SPSS 28.0 \nto summarize frequencies and compared using a series of X2 tests.\nSelected Results\nContent Frames\nContent Frame Number \nof \u2018Yes\u2019 \narticlesPercent \n\u2018Yes\u2019 of total \narticles \nCost = Harm\nEcological Aspects\nBenefits\nDangers to Humans86 \n58 \n42\n2672.9%\n49.2%\n35.6%\n22.0%\nCoexistence\n- Tolerance\n- Compensation\nCompassionate  \n  conservation\n- Wolf as an \nIndividual\nRewilding43\n49\n55\n15\n11\n4336.4%\n41.5%\n46.6%\n12.7%\n9.3%\n36.4%\nFuture Plans\nLawsuit mentions\nOpinion Piece\nWyoming Incident54\n38 \n9\n045.8%\n32.2%\n7.6%\n0%\nTable 1. Frequency of \u201cyes\u201d (Y) coded articles \nper coding frame (n= 118). \u2018Costs\u2019 was the \nmost frequently reported frame, while \nelements of \u2018compassionate conservation\u2019 \nwere observed relatively infrequently.\nFigure 2. Low proximity (more distant) sources \nare more likely to report on future plans than \nhigh proximity (closer) sources (p=0.001)\nFigure 3. High proximity (closer) sources are \nmore likely to report on benefits than low \nproximity (more distant) sources (p=0.045)\n\u2018Future plans\u2019 (Figure 2) and  \u2018benefits\u2019 (Figure 3) were the only content coding \nframes that demonstrated a statistically significant relationship ( p\u2264 0.05) to article \nsource geography (low versus high proximity to the sites described in the articles):\nLow-proximity sources were more likely to discuss future plans and benefits of the \nreintroduction than high -proximity sources (i.e., those more closely situated). \nSimilarly, when the geographic source categories were evaluated for differences \nbetween article content and local, state, regional, and combined \nnational/international scales, \u2018Future plans\u2019 framing  was the only statistically \nsignificant relationship that we observed ( p=0.002).\nIn contrast to article body content results, headline framing \n(positive/neutral/negative) was not found to be significantly associated with \ngeographic proximity (origin location of the news source). In total, we found 47% \nof the headlines to be negatively framed, 36% neutral, and 18 % positive . \nMedia Bias\nFigure 4. Partisan bias in \u201cmainstream\u201d sources is reflected in the \nheadlines. Left-leaning sources published a larger percentage of \ntheir articles under positive headlines, politically \u201ccenter\u201d favored \nneutral headlines, and right -leaning sources were observed to \nmost frequently use negative headlines. ( p=0.029). No positive \nframings were observed in the headlines for sources coded \u201cRight\u201d \n(includes Right and Right -Center) in our sample, while Left (Left \nand Left -Center) and Neutral included all three frames.Compassionate Conservation?\n\u201cColorado officially launches a \ncontroversial experiment next month: \nState officials will release up to 10 gray \nwolves as mandated by a 2020 state law \nthat unleashed proverbial howls of protest \nfrom opponents. Wolves have long been a \ndivisive species, particularly in rural areas \nwhere many farmers and ranchers \nconsider them an unacceptable risk to \nboth humans and livestock\u201d\u201cWolves pose no studied \nthreat to human life, cannot \nbe demonstrated to reduce \nhunting opportunities for \nungulates, and while they \ndo sometimes prey on \nlivestock, total depredations \nin areas with large wolf \npopulations are so low they \nare statistically irrelevant.\u201d\n\u201cFor the animal conservationist, I wonder if they have overlooked \nthe effects on the wolves themselves. This is a completely unnatural \nprocess. They are scared, confused and wearing these unnatural \ntracking collars. The area is unfamiliar, climate is different, and they \nare still being moved around via helicopters because they are headed \nnorth out of the state of Colorado! This can also be a conversation \nabout their health and well being.\u201d\nFigure 5. Examples of differences in article framing and content of news \narticles published during the study period. We found relatively few \narticles that explicitly acknowledged the lives of individual relocated \nwolves or which recognized individual wolves as actors with an interest \nin the relocation process  or reintroduction project, itselfDiscussion \nHow human -wildlife interactions are framed in news media can \nglorify or demonize the wildlife species involved and can directly lead \nto dangerous or harmful human -carnivore interactions, specifically \n(Crown and Doubleday 2017). In our study, certain negative framings \n(especially \u2018costs\u2019), were heavily over -represented compared to more \npositive content frames such as ecological aspects, benefits, and \ncoexistence values. Other studies have shown that emphasizing \ninteraction narratives based on conflict is harmful not just for human -\nwildlife relations and can also undermine human -human relations \n(Major, 2024). \nWe were surprised by our geographic proximity findings. High -\nproximity sources in other studies often focus on immediate threats \nto residents (Niemiec et al., 2020), which suggests that specifics on \nhow to deal with the wolf reintroduction would be popular in these \nsources as well. However, our research found that high -proximity \nsources were less likely to discuss the benefits and future steps of the \nreintroduction plan. In context of observed patterns of partisan \nmedia bias, we note with caution that local news sources may be \npoorly preparing residents for the reintroduction and in the process. \nOur continued research will include coverage of related events that \noccurred after the study period ended (for example, the birth of wolf \npups, the deaths of two of the reintroduced wolves, the intentional \nretaliation killing of a yearling wolf in nearby Wyoming, and the \nrelocation of the reintroduced wolves). The intricacies of the news \nmedia companies and where their funding comes from could greatly \nimpact what types of stories are released, so looking further into \nthese owners and their publication rules could also provide insight \ninto related newsmedia  discourse. Additionally, looking at article \nimagery choice (Figures 1 -2) will provide another layer of analysis for \nboth content and potential messaging bias.\n \nConclusions\nMedia influences our thoughts without our notice all the time, and \nthe discourse about wolves remains a case in point (Lynn, 2010). The\nway something is written \u2013 and the impact of an editor\u2019s choices to \ninclude or exclude a specific element from any published story \u2013 can \nstrongly shape how readers will feel or act in response. This happens \ndaily in human conflict situations. In this case, and as wolves are \nunable to speak and advocate for themselves (Underwood, 1991), it \nbecomes even more important that to ensure that they get fair \nrepresentation in trusted media. As we all consume various media \ntypes daily, it is important to cultivate an awareness of what authors \nand media companies want to convey ( and why ) in their messaging. \nWorks Cited and Related References\nBekoff , M. (Ed.) 2013. Ignoring nature no more: The case for compassionate conservation . U Chicago Press .\nCrown, C.A., and Doubleday, K.F . 2017. \u2018Man -Eaters\u2019 in the Media: Representation of Human -Leopard \nInteractions in India Across Local, National, and International Media. Cons & Society, 15 (3).\nLynn, W. 2010. Discourse and Wolves: Science, Society, Ethics. Society & Animals; 18: 75 -92.\nMajor, E. 2024. Slayers, Rippers, and Blitzes: Dark Humor and the Justification of Cruelty to Possums in Online \nMedia in New Zealand . Frontiers in Communication, 9 . DOI 10.3389/fcomm.2024.1377559\nMediaBias/Fact Check. (n.d.). https://mediabiasfactcheck.com/\nNational Park Service. (n.d.). Wolf Restoration. https://www.nps.gov/yell/learn/nature/wolf -restoration.htm. \nNiemiec, R. et al. 2020. Public perspectives and media reporting of wolf reintroduction in Colorado. PeerJ \n8:e9074. https://doi.org/10.7717/peerj.9074. \nSchimdt , T . 2024. \u201cColorado, local leaders and stakeholders share thoughts on wolf reintroduction . \nhttps:// www.skyhinews.com /news/colorado -local -leaders -and-stakeholders -share -thoughts -on-wolf -reintroduction/\nUnderwood, P . 1991. Who Speaks for Wolf?  Learning Way Co: San Anselmo, Calif.\nWallach, A. et al. 2018. Summoning compassion to address the challenges of conservation. Cons Biology  32(6).\nAcknowledgements\nThis work was supported by the Gettysburg College 2024 Kolbe Research Fellowship. \nThanks to the Musselman Library staff for their research help. We extend our appreciation to PANWorks  \nmembers Dr. Bill Lynn, Dr. Julie Urbanik , Dr. Emily Major, and Dr. Stephen Vrla for providing encouragement \nand insight. Funding and logistical support from the ES Department is also gratefully acknowledged.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Colorado Wolf Reintroduction Portrayal in News Media", "author": ["MK McArthur", "MV Ogra"], "pub_year": "2024", "venue": "NA", "abstract": "The Colorado gray wolf (Canis lupus) reintroduction began in December 2023 in the hope of  restoring this once native population to the area, and it has received mixed responses from"}, "filled": false, "gsrank": 94, "pub_url": "https://cupola.gettysburg.edu/student_scholarship/1132/", "author_id": ["", ""], "url_scholarbib": "/scholar?hl=en&q=info:XAu7xuBnZMcJ:scholar.google.com/&output=cite&scirp=93&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D90%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=XAu7xuBnZMcJ&ei=FbWsaISmDuHUieoP9LKZ6AI&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:XAu7xuBnZMcJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://cupola.gettysburg.edu/cgi/viewcontent.cgi?article=2209&context=student_scholarship"}}, {"title": "Is ChatGPT the ultimate data augmentation algorithm?", "year": "2023", "pdf_data": "Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 15606\u201315615\nDecember 6-10, 2023 \u00a92023 Association for Computational Linguistics\nIs ChatGPT the ultimate Data Augmentation Algorithm?\nFr\u00e9d\u00e9ric Piedboeuf\nRALI, Diro\nUniversit\u00e9 de Montr\u00e9al\nfrederic.piedboeuf@umontreal.caPhilippe Langlais\nRALI, Diro\nUniversit\u00e9 de Montr\u00e9al\nfelipe@iro.umontreal.ca\nAbstract\nIn the aftermath of GPT-3.5, commonly known\nas ChatGPT, research has attempted to assess\nits capacity for lowering annotation cost, either\nby doing zero-shot learning, generating new\ndata, or replacing human annotators. Some\nstudies have also investigated its use for data\naugmentation (DA), but only in limited con-\ntexts, which still leaves the question of how\nChatGPT performs compared to state-of-the-\nart algorithms. In this paper, we use Chat-\nGPT to create new data both with paraphrasing\nand with zero-shot generation, and compare\nit to seven other algorithms. We show that\nwhile ChatGPT performs exceptionally well on\nsome datasets, it overall does not perform bet-\nter than the other algorithms, yet demands a\nmuch larger implication from the practitioner\ndue to ChatGPT often refusing to answer due\nto sensitive content in the datasets.\n1 Introduction\nTextual data augmentation (DA) is a rich and com-\nplicated field, with the goal of finding ways to gen-\nerate the most informative artificial examples to\nadd to a training set without additional labelling\ncost. Many techniques have been developed and\nthoroughly tested in order to create informative ar-\ntificial data. Recently, the new model ChatGPT\nhas put into question much of what was known for\ndataset construction, with researchers even won-\ndering if its capacities meant the end of human\nlabelling (Kuzman et al., 2023).\nWhile extensive studies have been done on the\nuse of ChatGPT for many Natural Language Under-\nstanding tasks, its use for DA has been surprisingly\nlittle investigated yet. To our knowledge, only two\npapers have looked into this, namely (M\u00f8ller et al.,\n2023) and (Dai et al., 2023). Both however ex-\nplore limited settings, which makes it still unclear\nwhether ChatGPT is a good tool for data augmenta-\ntion or not. In particular, M\u00f8ller et al. (2023) studythe performance of ChatGPT and GPT-4 on classi-\nfication tasks of medium size (500 examples), com-\nparing zero shot data generation and few-shot+data\naugmentation to crowdsourcing annotation, but not\nto other DA techniques. Dai et al. (2023) compare\nthe use of DA with ChatGPT for large datasets (sev-\neral thousand examples), focussing on bio-medical\ndata. Their algorithm however does not isolate\nChatGPT for data augmentation, but instead com-\nbines it with pre-training, preventing an objective\nevaluation of the capacities of ChatGPT for DA.\nIn this paper, we compare the use of ChatGPT\nfor paraphrasing as well as for zero-shot data gen-\neration, on five classification datasets (three binary\nand two multiclass ones), to seven algorithms that\nhave shown good performances in the past. We\nshow that the performance of ChatGPT is highly\ndependent on the dataset, due mainly to poorly\ndefined tasks, which makes prompting difficult.\nThese tasks were chosen because they are stan-\ndard on the textual DA literature, and as such these\nbiases are important to point out. With efficient\nprompting, generating new data with ChatGPT re-\nmains the best way to perform textual DA.\n2 Related Work\nThere are roughly three main types of DA tech-\nniques: word-level augmentation, paraphrase, and\ngenerative methods.1\nIn word-level DA, operations modify genuine\nsentences\u2019 words to create variations. Commonly,\nthe operation is word substitution, replacing it with\na synonym (Wei and Zou, 2019; Liesting et al.,\n2021), a neighboring word in pre-trained embed-\nding (Marivate and Sefara, 2020), or by masking\nand predicting with a neural network (Kobayashi,\n2018; Wu et al., 2019; Kumar et al., 2020).\n1For a full review of the literature surrounding textual data\naugmentation, we refer to (Shorten and Khoshgoftaar, 2019;\nFeng et al., 2021).15606\nParaphrasing techniques attempt to create para-\nphrases from the available sentences. The\nmost seminal technique of this family is Back-\nTranslation (BT), a technique in which a sentence\nis translated to a pivot language and then back\ninto English (Hayashi et al., 2018; Yu et al., 2018;\nEdunov et al., 2018; Corbeil and Ghadivel, 2020;\nAlAwawdeh and Abandah, 2021). Neural networks\nto directly generate paraphrases have also been\nused, with specialized decoding techniques for\nRNN (Kumar et al., 2019), or by using a BART\nmodel trained on a corpus of paraphrases generated\nfrom BT (Okur et al., 2022).\nGenerative methods learn the distribution of the\ntraining data and generate new data from it. While\nthe obvious advantage is that data should be more\ndiverse, generative models are often more compli-\ncated to train and fine-tune correctly. Examples\nof this family of methods includes using GPT-2\nfor generating new data (Kumar et al., 2020; Liu\net al., 2020; Queiroz Abonizio and Barbon Junior,\n2020), other generative models such as V AEs (Ma-\nlandrakis et al., 2019; Qiu et al., 2020; Piedboeuf\nand Langlais, 2022) or conditional V AEs to gen-\nerate examples conditionned on the class (Zhuang\net al., 2019; Malandrakis et al., 2019; Rizos et al.,\n2019; Wang et al., 2020).\nFinally, there have also been interest into the\nuse of proprietary models for DA. Both Yoo et al.\n(2021) and Sahu et al. (2022) show that GPT-3 is\nable to generate excellent new data, either by com-\npleting a list of sentences from one class, or by\nasking to generate both new sentences and their\nlabels. ChatGPT has also been studied to gen-\nerate new data, asking it to paraphrase existing\ndata (Dai et al., 2023) for few-shot learning, but\nthe authors first fine-tune the classifier with a large\ndataset from the same distribution, making it hard\nto isolate the impact of the generated sentences. Fi-\nnally, M\u00f8ller et al. (2023) look at the performance\nof ChatGPT and GPT-4 for data augmentation com-\npared to human annotation, and conclude that for\nsimple datasets (such as review analysis of prod-\nucts), ChatGPT is better, but otherwise human an-\nnotation outperforms data generated by ChatGPT.\nAs they do not compare to other DA techniques, it\nis also hard to know how ChatGPT performs.\n3 Algorithms\nIt is not clear from the literature which DA algo-\nrithms perform best, and so in order to thoroughlytest the capacities of ChatGPT we select a variety\nof techniques to compare DA objectively: EDA,\nAEDA, CBERT, CBART, CGPT, BT, T5-Tapaco,\nChatGPT-Par and ChatGPT-Desc. We briefly de-\nscribe each of those algorithms, and refer to the\ncode for the full details of the implementations and\nhyper-parameters.2\nEDA and AEDA are two simple word-level al-\ngorithms that achieved great performances in the\npast. In EDA, one of four operations is chosen (in-\nsertion of related words, swapping words, deleting\nwords, and replacing words by synonyms) and ap-\nplied to a percentage of the words in the sentence.3\nIn AEDA (Karimi et al., 2021), punctuations are\nrandomly inserted in the sentence (among \"?\", \".\",\n\";\", \":\", \"!\", and \",\"), the number of insertion being\nRANDINT(1, len(sentence)/3) .\nCBERT and CBART have very similar method-\nologies. We prepend the class of the example to all\ngenuine sentences, mask a fraction of the tokens,\nand fine-tune the model on the available training set\nto predict the masked words. For generation, we\nthen give the modified sentence (masked and with\nthe class prepended) and pass it through the trans-\nformers. The main difference between CBERT and\nCBART is that the latter can predict spans instead\nof tokens, which allows more flexibility.\nCGPT also works by prepending the class to\nthe sentence, which then allows GPT-2 to learn to\ngenerate conditionally to it. For generation, we\ngive the class as well as the separator token and let\nGPT-2 generate new sentences.4\nIn BT, we first translate the sentence to a pivot\nlanguage and retranslate it in English, creating para-\nphrases. We use the FSMT model from hugging\nface5, with the intermediary language being Ger-\nman, which has been shown to obtain good perfor-\nmances (Edunov et al., 2018).\nOkur et al. (2022) propose to fine-tune BART\non a corpus of in-domain paraphrases created with\nBT. We found in our experiments that we could get\nresults just as good by using T5-small-Tapaco6,\nwhich is the T5 model fine-tuned on the corpus of\n2Code available at https://github.com/smolPixel/\nDataAugmentationEMNLP2023 .\n3We affect 10% of the words, as recommended in the paper\nof Wei and Zou (2019)\n4We use GPT2-large with a top_p of 0.95 and a\nno_repeat_n_gram_size of three.\n5https://huggingface.co/docs/transformers/\nmodel_doc/fsmt\n6https://huggingface.co/hetpandya/\nt5-small-tapaco15607\nparaphrases TaPaCo (Scherrer, 2020).\nFinally, we test the use ChatGPT, either by ask-\ning for paraphrases of genuine sentences (ChatGPT-\nPar), or by giving a short description of the task and\nclasses and asking for novel sentences (ChatGPT-\nDesc). We give the exact prompts in Appendix A.\nBecause part of the experiments were done before\nthe API became publicly available, we use in this\npaper the Pro version of the Web interface of Chat-\nGPT and leave further fine-tuning for future work7.\n4 Datasets and Methodology\nWe test on five datasets with various complexity\nand characteristic to fully assess the performance of\nthe algorithms. We use SST-2 (Socher et al., 2013),\na binary dataset of movie reviews classification,\nFakeNews8, a dataset of news to classify into real\nnews or fake ones, Irony and IronyB (Van Hee et al.,\n2018), a binary and multiclass version of a task\nconsisting into classifying tweets as ironic or not,\nand which kind of irony for the multiclass version\n(polarity clash, situational irony, other irony), and\nTREC6 (Li and Roth, 2002), a multiclass dataset\nwhere the goal is to classify questions into six cate-\ngories (abbreviation, description, entities, human\nbeings, locations, and numeric values). More infor-\nmation is available in Appendix C.\nThese datasets were chosen to get a spread of\ntasks, and because they are commonly used in the\nliterature in data augmentation. SST-2 and TREC6\nare both fairly standard in DA research, being used\nfor example in (Kumar et al., 2020; Quteineh et al.,\n2020; Regina et al., 2021; Kobayashi, 2018). The\nIrony datasets are also used quite regularly, for ex-\nample in (Liu et al., 2020; Turban and Kruschwitz,\n2022; Yao and Yu, 2021). Finally, while FakeNews\nhas not been used in DA to our knowledge, it is\nstill commonly used for Fake News detection, for\nexample in (Verma et al., 2023; Chakraborty et al.,\n2023; Iceland, 2023).\nWe test data augmentation on two settings: few\nshot learning (10 or 20 starting examples), and\nclassification with dataset sizes of 500 and 1000 ex-\namples. While sampling the starting set, we make\nsure to balance the classes to be able to observe the\nperformance of data augmentation without the ad-\nditional factor of imbalanced data. We also tested\nthe process on the full dataset but, similarly to other\n7This most notably means that we couldn\u2019t play with pa-\nrameters such as the temperature, which affects the diversity\nof the sentences.\n8https://www.kaggle.com/c/fake-news/overviewpapers, we found DA to have little effect in this set-\nting. As such we do not discuss them in the paper,\nbut we include them in Appendix C.\nBased on results reported in the literature as\nwell as our experiments, we use a larger ratio of\ngenerated-to-genuine sentences for small datasets\nand a smaller one for larger datasets. Concretely,\nwe generate 10 new sentences per genuine sen-\ntences for the dataset sizes of 10 and 20, and one\nfor 500 and 1000.9As a classifier, we use BERT,\nand we fine-tune it using the development set, using\nearly-stopping. We run each experiment 15 times,\nreporting accuracy for binary tasks, and macro-f1\nfor multiclass tasks.\n5 Results\nTable 1 shows results for the dataset sizes of 10 and\n20 and Table 2, for the sizes of 500 and 1000.\nFor small dataset sizes, we observe that the per-\nformance of ChatGPT-Par is on par with the best\nalgorithms, but doesn\u2019t beat them by a significant\nmargin on average. While ChatGPT-Desc per-\nforms exceptionally well, its performance comes\nalmost exclusively from SST-2, for which it gener-\nates highly informative data. For other datasets, it\nmostly either brings no gain in the performance or\na very small one. Overall, all the algorithms pro-\nvide a reasonable augmentation of the performance,\nexcept maybe CGPT, which performs poorly. Ex-\ncluding ChatGPT-Desc, BART and T5-TaPaCo ob-\ntain some of the best performance, although not\nby much. Given the generative nature of ChatGPT-\nDesc and its performance, one could also wonder\nif it would perform better if we generated more\nsentences. In Appendix C we show that this is not\nthe case, and that the performance for all datasets\nplateau quickly.\nFor larger training sets, ChatGPT performs bet-\nter, while BART and T5-TaPaCo degrade the per-\nformance. We believe that this is due to these algo-\nrithms creating paraphrases which are closer to the\noriginal sentences, leading to less diversity overall.\nWhile on few-shot learning this is not a problem be-\ncause the goal is to give the neural network enough\nrelevant data to learn, on larger datasets diversity\nseems to become a prevalent factor. Nevertheless,\nthe overall effect of augmentation on moderately\n9While not a factor much studied in the DA literature,\nextensive experiments shows that at larger training set sizes, a\nlarger ratio is detrimental since it makes the neural network\nforget genuine examples.15608\nTable 1: Average metric over 15 runs for the training set sizes of 10 (left) and 20 (right) with a ratio of 10. We report\naccuracy for binary tasks and macro-f1 for multiclass ones. STDs are between 1.5 and 5, depending on the dataset.\nSST2 FakeNews Irony IronyB Trec6 Average\nBaseline 56.4/60.6 52.2/53.3 52.5/58.3 23.6/23.4 27.9/34.7 42.5/46.1\nEDA 59.4/63.2 55.0/56.6 53.7/57.3 25.3/27.8 30.8/43.7 44.9/49.7\nAEDA 59.3/64.6 53.4/55.3 54.1/56.0 25.4/27.1 26.5/44.2 43.7/49.5\nBT 59.0/64.6 55.1/56.2 54.3/56.5 25.4/26.7 32.9/ 46.3 45.4/50.1\nCBERT 57.6/63.1 54.5/55.5 55.1/57.4 25.3/29.5 29.0/40.6 44.3/49.2\nCGPT 55.6/61.2 52.4/54.7 51.9/53.1 22.9/25.1 23.3/38.1 41.2/46.4\nCBART 60.5/64.9 55.8/57.2 54.8/56.6 25.5/ 28.0 34.1 /46.1 46.2/50.6\nT5 60.4/64.6 54.5/56.6 53.2/56.7 23.5/27.1 34.0/ 46.3 45.1/50.3\nGPT3.5-Par 62.5/69.0 53.8/54.9 54.2/ 57.5 24.4/27.8 31.3/44.8 45.3/50.8\nGPT3.5-Desc 78.6/82.6 51.5/52.8 53.2/54.1 27.1/27.7 31.4/42.9 48.3/52.0\nTable 2: Average metric over 15 runs for the training set sizes of 500 (left) and 1000 (right) with a ratio of 1. We\nreport accuracy for binary tasks and macro-f1 for multiclass ones. STDs are between 0.6 and 3.0, depending on the\ndataset.\nSST2 FakeNews Irony IronyB Trec6 Average\nBaseline 87.7/88.8 73.3/77.0 65.6/68.1 42.4/45.2 81.0/85.4 70.0/72.9\nEDA 87.9/88.9 73.7/77.6 65.8/68.8 43.1/46.6 81.3/86.1 70.4/73.6\nAEDA 88.0/89.0 73.5/77.6 65.7/69.2 42.8/46.1 82.7/86.4 70.5/73.7\nBT 88.2/89.1 73.6/77.4 66.2/69.2 42.4/46.0 81.7/86.1 70.4/73.5\nCBERT 87.5/88.3 73.6/77.5 65.8/68.1 40.6/45.5 80.9/85.4 69.7/72.9\nCGPT 87.8/88.7 73.2/77.6 65.2/68.8 42.8/45.2 82.1/ 87.2 70.2/73.5\nCBART 87.7/88.6 73.9/77.9 65.9/68.8 42.7/45.0 78.6/83.4 69.8/72.7\nT5 87.9/88.7 73.8/73.3 65.3/68.2 43.1/45.3 79.9/85.0 70.0/72.1\nGPT3.5-Par 88.2/89.1 73.8/77.7 66.8/69.3 42.8/45.9 82.4/87.1 70.8/73.8\nGPT3.5-Desc 87.4/88.9 71.9/75.9 64.1/66.9 41.1/44.4 79.8/84.0 68.9/72.0\nsized datasets are very small, which brings the ques-\ntion of whether data augmentation is relevant at all\nin these cases.\n6 Discussion\nOf all the algorithms used here, T5 and ChatGPT\npresent the greatest novelty as well as show some\nof the best performances. As such, we center our\ndiscussion on these two algorithms. When we ob-\nserve T5 sentences (see Appendix B), we can see\nthat they are not as good as one would expect, of-\nten being ungrammatical or badly formed. Still, it\nhas been noted before that having correctly formed\nsentences is not an important criterion for the ef-\nficiency of a DA algorithm, which might explain\nwhy its performance is high (Karimi et al., 2021).\nChatGPT-Desc often has difficulty generating\nsentences of the desired class, accounting for its\noverall poor performance, while ChatGPT-Par cre-\nates excellent paraphrases, bringing diversity to the\ndataset while maintaining class coherence. Never-\ntheless, there is a hidden cost that we found was notdiscussed in other papers, namely the need for data\nreparation. ChatGPT-Par quite often refuses to cre-\nate paraphrases, especially for the FakeNews and\nIrony/IronyB datasets which contain occasional\nmentions of rape andsex. In these cases, we had to\nmanually find the \u201cbad\u201d element of the batch and\nrerun it without it, adding considerable complexity\nto the data augmentation algorithm. Another op-\ntion would be to simply not correct them, but our\npreliminary studies indicate that this degrades the\nperformance of DA significantly.10\n6.1 Poorly defined tasks and dataset biases.\nDespite the description strategy being able to\nadd something akin to external data, our experi-\nments show that ChatGPT underperforms with this\nmethod, the performance often being worse than\nwhen paraphrasing the existing data. This raises\nmany questions as adding more diverse data should\naugment performance.\n10As we see in Appendix C, running with a smaller ratio for\nfew shot learning reduces the performance by a large amount.15609\nWe found that for most part, the poor perfor-\nmance of ChatGPT was related to the poor health\nof the datasets. Except for SST-2, we found that\nFakeNews, Irony, IronyB, and TREC6 have poorly\ndefined labels in relation to the task, and that ex-\namples in the datasets were often ambiguous to\nhuman eyes. Under these conditions, it is difficult\nto expect ChatGPT to perform well. We underline\nthese problems here because poor dataset health is\nnot a rare phenomenon.\nIrony and IronyB are two datasets of the Se-\nmEV AL 2018 competition. Data was collected\nfrom Twitter by collecting tweets that contained\nsome specific hashtag such as #irony, #not, or #sar-\ncasm, which were then removed to form the data\nof the ironic class. The non-ironic class was then\nformed by collecting other tweets. This creates a\nheavy bias in the dataset which shift the task from\npredicting if the tweet is ironic to predicting if there\nwas a #irony hashtag coming with it. Without the\nclue that the hashtags give us, it is often impossible\nto know if the tweet is ironic or not, and we show in\nAppendix C some examples of ironic tweets which,\nfrom manual labelling, we found were ambiguous\nin their classes.\nTREC6 is a dataset of the Text REtrieval Con-\nference and consists in classifying the questions\ninto six categories. While all data was manually\nannotated, we found inconsistencies in the anno-\ntation. For example, \u201cWhat is narcolepsy?\u201d is la-\nbelled as description but \u201cWhat is a fear of motion?\u201d\nas an Entity . Other inconsistencies are \u201cWhat is\nthe oldest profession?\u201d and \u201cWhat team did base-\nball \u2019s St. Louis Browns become?\u201d labelled as\nHuman vs \u201cWhat do you call a professional map\ndrawer\u201d as Entity, or \u201cWhere did Indian Pudding\ncome from?\u201d being labelled as Description but\n\u201cWhere does chocolate come from?\u201d as Location.\nGiven that the same mislabelling remains in the test\nset (ex \u201cWhere does dew come from?\u201d being la-\nbelled as location), ChatGPT generating sentences\nof the correct class won\u2019t help the classifier much.\nIt is to note that these issues were already noted\nby Li and Roth (2002), who advise using multi-\nlabel classification to reduce biases introduced in\nthe classifier. In all of its usage for DA however,\nwe found it used as a regular classification problem,\nwith all the ambiguity problems it entails.\nFinally, FakeNews is a Kaggle dataset which has\nbeen thereafter used in many papers for fake news\ndetection. We decided to use this dataset becauseit seemed a difficult and interesting task, but while\nanalyzing it, we found it biased in a sense similar\nto Irony and IronyB. From what little information\nwe could find, news were gathered from various\nsources and split into real or fake news based on the\njournal they came from. This causes biases because\nwhile some journals may have a tendency to sprout\nfake news, it does not mean all of its news are fake.\nFurthermore, we found strange choices of labelling.\nFor example, all articles from Breitbart are labelled\nas real news even if it receives a mixed score of\nfactual reporting11and articles from consortium\nnews, which receives the overall same score, are\nlabelled as fake12.\nBy refining prompting, we can augment the\nTREC6 dataset to go to 68.6, which still underper-\nforms when compared to BERT13. We found Chat-\nGPT to have difficulty understanding the concept\nof \u201cEntity\u201d and \u201cHuman\u201d questions, often labelling\nthem instead as \u201cDescription\u201d.\n7 Conclusion\nData augmentation is a seminal technique to lower\nannotation cost and keep good performances, but\neven today it is difficult to figure out which tech-\nnique works best. In particular, the use of ChatGPT\nhas not been correctly assessed for data augmenta-\ntion, leading to the unknown factor for industries\nof whether it is worth the price.\nIn this paper, we study nine data augmentation\ntechniques, including a novel one using a pre-\ntrained T5 system for paraphrasing, and show that\nwhile ChatGPT achieves among the best results, it\ndoesn\u2019t outperform the other algorithm by a sig-\nnificant margin. This, coupled with the fact that\nusing ChatGPT costs both time and money when\ncompared to the other algorithms, brings us to a dif-\nferent conclusion than what previous studies using\nChatGPT for DA found, namely that it might not be\nworth it depending on the task. We further found\nthat while zero-shot generation of data could give\noutstanding results, it was often hindered by biased\ndatasets, which prevented efficient prompting of\nChatGPT.\n11https://mediabiasfactcheck.com/breitbart/\n12https://mediabiasfactcheck.com/\nconsortium-news/\n13Because FakeNews and the Irony datasets contains a lot\nof examples breaking ChatGPT term of services, we could not\nattempt to refine the prompting for those datasets15610\nLimitations\nThis paper explores the use of ChatGPT for DA,\ncomparing it to other algorithms from the literature.\nTechnical limitations of this paper include limited\nfine-tuning for some of the algorithms, including\nChatGPT for which we used the Web interface and\ntherefore could not finetune the hyperparameters.\nWhile the other algorithms have been fine-tuned on\nsome hyper-parameters, fine-tuning was built on\nsome supposition (such as the use of German as a\npivot language for BT), which may not be the best.\nThis paper also focuses on English language and\ntextual classification for short sentences, both as-\nsumptions which do not hold for many other tasks.\nAs such, we do not guarantee the results are appli-\ncable to other tasks, especially for languages which\nare low-resource (such as Inuktitut or Swahili) or\nfor longer texts, for which most of the algorithms\nused would most likely perform poorly due to lack\nof training data/limited context for input.\nEthics Statement\nUse of pre-trained language models, and espe-\ncially of \u201cvery large language models\u201d, come with\na plethora of ethical problems which have been\nwell discussed in the litterature, including the en-\nvironmental cost (Schwartz et al., 2019; Bender\net al., 2021) and environmental racism (Rillig et al.,\n2023), the repetition of learned biases against mi-\nnorities (Singh, 2023), and concerns over data pri-\nvacy (Li et al., 2023).\nA big concern with the most recent models is\nthe effect it will have on employement, but we\nbelieve this paper mitigates this effect by showing\nlimitation of ChatGPT, especially in the context of\ndata annotation and dataset creation.\nReferences\nShorouq M. AlAwawdeh and Gheith A. Abandah. 2021.\nImproving the Accuracy of Semantic Similarity Pre-\ndiction of Arabic Questions Using Data Augmen-\ntation and Ensemble. In 2021 IEEE Jordan Inter-\nnational Joint Conference on Electrical Engineer-\ning and Information Technology (JEEIT) , pages 272\u2013\n277.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\nDangers of Stochastic Parrots: Can Language Mod-\nels Be Too Big? . In Proceedings of the 2021\nACM Conference on Fairness, Accountability, and\nTransparency , pages 610\u2013623, Virtual Event Canada.\nACM.Souradip Chakraborty, Amrit Singh Bedi, Sicheng Zhu,\nBang An, Dinesh Manocha, and Furong Huang. 2023.\nOn the Possibilities of AI-Generated Text Detection.\nArXiv:2304.04736 [cs].\nJean-Philippe Corbeil and Hadi Abdi Ghadivel. 2020.\nBET: A Backtranslation Approach for Easy Data\nAugmentation in Transformer-based Paraphrase Iden-\ntification Context. ArXiv:2009.12452 [cs].\nHaixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke\nHuang, Zihao Wu, Lin Zhao, Wei Liu, Ninghao Liu,\nSheng Li, Dajiang Zhu, Hongmin Cai, Quanzheng\nLi, Dinggang Shen, Tianming Liu, and Xiang Li.\n2023. ChatAug: Leveraging ChatGPT for Text Data\nAugmentation. ArXiv:2302.13007 [cs].\nSergey Edunov, Myle Ott, Michael Auli, and David\nGrangier. 2018. Understanding Back-Translation at\nScale. ArXiv:1808.09381 [cs].\nSteven Y . Feng, Varun Gangal, Jason Wei, Sarath Chan-\ndar, Soroush V osoughi, Teruko Mitamura, and Ed-\nuard Hovy. 2021. A Survey of Data Augmentation\nApproaches for NLP. In Findings of the Association\nfor Computational Linguistics: ACL-IJCNLP 2021 ,\npages 968\u2013988, Online. Association for Computa-\ntional Linguistics.\nT. Hayashi, S. Watanabe, Y . Zhang, T. Toda, T. Hori,\nR. Astudillo, and K. Takeda. 2018. Back-Translation-\nStyle Data Augmentation for end-to-end ASR. In\n2018 IEEE Spoken Language Technology Workshop\n(SLT) , pages 426\u2013433.\nMatthew Iceland. 2023. How Good Are SOTA Fake\nNews Detectors. ArXiv:2308.02727 [cs].\nAkbar Karimi, Leonardo Rossi, and Andrea Prati. 2021.\nAEDA: An Easier Data Augmentation Technique for\nText Classification. In Findings of the Association\nfor Computational Linguistics: EMNLP 2021 , pages\n2748\u20132754, Punta Cana, Dominican Republic. Asso-\nciation for Computational Linguistics.\nSosuke Kobayashi. 2018. Contextual Augmentation:\nData Augmentation by Words with Paradigmatic Re-\nlations. In Proceedings of the 2018 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 2 (Short Papers) , pages 452\u2013457,\nNew Orleans, Louisiana. Association for Computa-\ntional Linguistics.\nAshutosh Kumar, Satwik Bhattamishra, Manik Bhan-\ndari, and Partha Talukdar. 2019. Submodular\nOptimization-based Diverse Paraphrasing and its Ef-\nfectiveness in Data Augmentation. In Proceedings\nof the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers) , pages 3609\u20133619, Minneapolis, Min-\nnesota. Association for Computational Linguistics.15611\nVarun Kumar, Ashutosh Choudhary, and Eunah Cho.\n2020. Data Augmentation using Pre-trained Trans-\nformer Models. In Proceedings of the 2nd Workshop\non Life-long Learning for Spoken Language Systems ,\npages 18\u201326, Suzhou, China. Association for Com-\nputational Linguistics.\nTaja Kuzman, Igor Mozeti \u02c7c, and Nikola Ljube\u0161i \u00b4c. 2023.\nChatGPT: Beginning of an End of Manual Linguistic\nData Annotation? Use Case of Automatic Genre\nIdentification. ArXiv:2303.03953 [cs].\nHaoran Li, Dadi Guo, Wei Fan, Mingshi Xu, Jie\nHuang, Fanpu Meng, and Yangqiu Song. 2023.\nMulti-step Jailbreaking Privacy Attacks on ChatGPT.\nArXiv:2304.05197 [cs].\nXin Li and Dan Roth. 2002. Learning question classi-\nfiers. In Proceedings of the 19th international confer-\nence on Computational linguistics - , volume 1, pages\n1\u20137, Taipei, Taiwan. Association for Computational\nLinguistics.\nTomas Liesting, Flavius Frasincar, and Maria Mihaela\nTru\u00b8 sc \u02d8a. 2021. Data augmentation in a hybrid ap-\nproach for aspect-based sentiment analysis. In Pro-\nceedings of the 36th Annual ACM Symposium on\nApplied Computing , SAC \u201921, pages 828\u2013835, New\nYork, NY , USA. Association for Computing Machin-\nery.\nRuibo Liu, Guangxuan Xu, Chenyan Jia, Weicheng\nMa, Lili Wang, and Soroush V osoughi. 2020. Data\nBoost: Text Data Augmentation Through Reinforce-\nment Learning Guided Conditional Generation. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) ,\npages 9031\u20139041, Online. Association for Computa-\ntional Linguistics.\nNikolaos Malandrakis, Minmin Shen, Anuj Goyal,\nShuyang Gao, Abhishek Sethi, and Angeliki Met-\nallinou. 2019. Controlled Text Generation for Data\nAugmentation in Intelligent Artificial Agents. In Pro-\nceedings of the 3rd Workshop on Neural Generation\nand Translation , pages 90\u201398, Hong Kong. Associa-\ntion for Computational Linguistics.\nVukosi Marivate and Tshephisho Sefara. 2020. Im-\nproving Short Text Classification Through Global\nAugmentation Methods. In Machine Learning and\nKnowledge Extraction , Lecture Notes in Computer\nScience, pages 385\u2013399, Cham. Springer Interna-\ntional Publishing.\nAnders Giovanni M\u00f8ller, Jacob Aarup Dalsgaard, Ari-\nanna Pera, and Luca Maria Aiello. 2023. Is a prompt\nand a few samples all you need? Using GPT-4\nfor data augmentation in low-resource classification\ntasks. ArXiv:2304.13861 [physics].\nEda Okur, Saurav Sahay, and Lama Nachman. 2022.\nData Augmentation with Paraphrase Generation and\nEntity Extraction for Multimodal Dialogue System.\nArXiv:2205.04006 [cs].Fr\u00e9d\u00e9ric Piedboeuf and Philippe Langlais. 2022. Effec-\ntive Data Augmentation for Sentence Classification\nUsing One V AE per Class. In Proceedings of the\n29th International Conference on Computational Lin-\nguistics , pages 3454\u20133464, Gyeongju, Republic of\nKorea. International Committee on Computational\nLinguistics.\nSiyuan Qiu, Binxia Xu, Jie Zhang, Yafang Wang, Xi-\naoyu Shen, Gerard de Melo, Chong Long, and Xi-\naolong Li. 2020. EasyAug: An Automatic Textual\nData Augmentation Platform for Classification Tasks.\nInCompanion Proceedings of the Web Conference\n2020 , pages 249\u2013252. Association for Computing\nMachinery, New York, NY , USA.\nHugo Queiroz Abonizio and Sylvio Barbon Junior. 2020.\nPre-trained Data Augmentation for Text Classifica-\ntion. In Intelligent Systems , Lecture Notes in Com-\nputer Science, pages 551\u2013565, Cham. Springer Inter-\nnational Publishing.\nHusam Quteineh, Spyridon Samothrakis, and Richard\nSutcliffe. 2020. Textual Data Augmentation for Effi-\ncient Active Learning on Tiny Datasets. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n7400\u20137410, Online. Association for Computational\nLinguistics.\nMehdi Regina, Maxime Meyer, and S\u00e9bastien Goutal.\n2021. Text Data Augmentation: Towards better de-\ntection of spear-phishing emails. ArXiv:2007.02033\n[cs].\nMatthias C. Rillig, Marlene \u00c5gerstrand, Mohan Bi,\nKenneth A. Gould, and Uli Sauerland. 2023. Risks\nand Benefits of Large Language Models for the En-\nvironment. Environmental Science & Technology ,\n57(9):3464\u20133466.\nGeorgios Rizos, Konstantin Hemker, and Bj\u00f6rn Schuller.\n2019. Augment to Prevent: Short-Text Data Augmen-\ntation in Deep Learning for Hate-Speech Classifica-\ntion. In Proceedings of the 28th ACM International\nConference on Information and Knowledge Manage-\nment , CIKM \u201919, pages 991\u20131000, New York, NY ,\nUSA. Association for Computing Machinery.\nGaurav Sahu, Pau Rodriguez, Issam H. Laradji, Parmida\nAtighehchian, David Vazquez, and Dzmitry Bah-\ndanau. 2022. Data Augmentation for Intent Clas-\nsification with Off-the-shelf Large Language Models.\nArXiv:2204.01959 [cs].\nYves Scherrer. 2020. TaPaCo: A Corpus of Sentential\nParaphrases for 73 Languages.\nRoy Schwartz, Jesse Dodge, Noah A. Smith, and Oren\nEtzioni. 2019. Green AI. ArXiv:1907.10597 [cs,\nstat].\nConnor Shorten and Taghi M. Khoshgoftaar. 2019. A\nsurvey on Image Data Augmentation for Deep Learn-\ning.Journal of Big Data , 6(1):60.15612\nSahib Singh. 2023. Is ChatGPT Biased? A Review.\nPublisher: OSF Preprints.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive Deep Models for\nSemantic Compositionality Over a Sentiment Tree-\nbank. In Proceedings of the 2013 Conference on\nEmpirical Methods in Natural Language Processing ,\npages 1631\u20131642, Seattle, Washington, USA. Asso-\nciation for Computational Linguistics.\nChristoph Turban and Udo Kruschwitz. 2022. Tackling\nirony detection using ensemble classifiers. In Pro-\nceedings of the Thirteenth Language Resources and\nEvaluation Conference , pages 6976\u20136984.\nCynthia Van Hee, Els Lefever, and Veronique Hoste.\n2018. SemEval-2018 Task 3: Irony Detection in\nEnglish Tweets. In Proceedings of The 12th Interna-\ntional Workshop on Semantic Evaluation , pages 39\u2013\n50, New Orleans, Louisiana. Association for Compu-\ntational Linguistics.\nPawan Kumar Verma, Prateek Agrawal, Vishu Madaan,\nand Radu Prodan. 2023. MCred: multi-modal mes-\nsage credibility for fake news detection using BERT\nand CNN. Journal of Ambient Intelligence and Hu-\nmanized Computing , 14(8):10617\u201310629.\nQian Wang, Fanlin Meng, and T. Breckon. 2020. Data\nAugmentation with norm-V AE for Unsupervised Do-\nmain Adaptation. ArXiv .\nJason Wei and Kai Zou. 2019. EDA: Easy Data Aug-\nmentation Techniques for Boosting Performance on\nText Classification Tasks. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP) , pages 6382\u20136388, Hong Kong,\nChina. Association for Computational Linguistics.\nXing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han,\nand Songlin Hu. 2019. Conditional BERT Contextual\nAugmentation. In Computational Science \u2013 ICCS\n2019 , Lecture Notes in Computer Science, pages 84\u2013\n95, Cham. Springer International Publishing.\nZonghai Yao and Hong Yu. 2021. Improving Formality\nStyle Transfer with Context-Aware Rule Injection.\nArXiv:2106.00210 [cs].\nKang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo\nLee, and Woomyoung Park. 2021. GPT3Mix: Lever-\naging Large-scale Language Models for Text Aug-\nmentation. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2021 , pages 2225\u2013\n2239, Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nAdams Wei Yu, David Dohan, Minh-Thang Luong, Rui\nZhao, Kai Chen, Mohammad Norouzi, and Quoc V .\nLe. 2018. QANet: Combining Local Convolution\nwith Global Self-Attention for Reading Comprehen-\nsion. arXiv:1804.09541 [cs] . ArXiv: 1804.09541.Peiye Zhuang, Alexander G. Schwing, and Oluwasanmi\nKoyejo. 2019. FMRI Data Augmentation Via Synthe-\nsis. In 2019 IEEE 16th International Symposium on\nBiomedical Imaging (ISBI 2019) , pages 1783\u20131787.\nISSN: 1945-8452.\nA Prompts used for ChatGPT\nWe use three types of prompts for querying Chat-\nGPT, two for the paraphrasing technique and one\nfor the description technique, in order to get the\nbest possible results while minimizing the num-\nber of queries. For the paraphrasing, if the ratio\nwas more than one, then the query is of the type:\n\u201cCreate X paraphrases of the following sentence : \u201d\nIf the ratio is one, then we process the examples\nin batch, with the query: \u201c Create a paraphrase for\neach of the following sentences: 1. [...], 2. [...]\u201d\nFinally, for the description strategy the tem-\nplate we use is : \u201cGenerate 10 new sentences\nthat you haven\u2019t generated before for a dataset\nof DATASET_DESCRIPTION which would be\nCLASS_DESCRIPTION\u201d. We found that speci-\nfying \u201cnew sentences that you haven\u2019t generated\nbefore\u201d helped ChatGPT generate more diverse sen-\ntences. The given dataset descriptions are \u201cmovie\nreview\u201d, \u201cheadline Fake/Real news classification\u201d,\n\u201cIronic tweet detection\u201d, and \u201cQuestion Classifica-\ntion\u201d.\nThe class values are \u201cnegative or somewhat neg-\native\u201d or \u201cpositive or somewhat positive\u201d for SST-\n2, \u201cReal\u201d and \u201cFake\u201d for FakeNews, \u201cNon Ironic\nTweets\u201d and \u201cIronic Tweets\u201d for Irony, \u201cTweets\nironic by polarity contrast, where the polarity is in-\nverted between the literal and intended evaluation\u201d,\n\u201cTweets ironic by Situational Irony, where a situa-\ntion fails to meet some expectation\u201d, \u201cTweets ironic\nby Other type of Irony, where the Irony is neither\nby Polarity Contrast or by Situational Irony\u201d, and\n\u201cTweets that are not ironic\u201d for IronyB, and finally\nfor TREC6 we use \u201cQuestion about an abbrevia-\ntion\u201d , \u201cQuestion about an entity (event, animal,\nlanguage, etc)\u201d, \u201cQuestion concerning a descrip-\ntion (of something, a definition, a reason, etc)\u201d,\n\u201cQuestion about a human (description of someone,\nan individual, etc)\u201d, \u201cQuestion about a location\u201d,\nand \u201cQuestion about something numerical (weight,\nprice, any other number)\u201d.\nWe referred to the description given in the orig-\ninal papers of each dataset to craft informative\nprompts.15613\nB Example of generated sentences\nWe give in Table 3 examples of generated sen-\ntences for the SST-2 dataset and the negative class,\nwith the starting sentence \u201cmakes a joke out of car\nchases for an hour and then gives us half an hour of\ncar chases.\u201d for the algorithms that takes a sentence\nas an input (all except CGPT and ChatGPT-Desc).\nWhen fine-tuning is needed, we use a training set\nsize of 20.\nAlgo Generated sentence\nEDA makes a joke out as of car chases\nfor an hour and then gives us half\nan hour of car chases .\nAEDA makes , a joke out of? car chases\nfor an ! hour and , then gives us !\nhalf an hour of : car , chases .\nBT turns car chases into a joke for\nan hour and then gives us half an\nhour of car chases.\nCBERT makes two breakfast out of car\nwash for a\u201e then gives us half an\ninch of car wash.\nCGPT \u2019makes a joke out of car chases\nfor an hour and then gives us half\nan\nCBART Stays out of car chases for\nan hour and then gives up on\nan hour\u2019s worth\u2019n\u2019a-bit-of-car-\nchases\nT5-Tapaco The car chases for half hour is a\njoke.\nChatGPT-Par It turns car chases into a comedic\nspectacle for an entire hour, fol-\nlowed by another 30 minutes of\nnon-stop car action.\nChatGPT-Desc The film was a major disappoint-\nment, lacking any coherent plot\nor engaging characters.\nTable 3: Examples of generated sentences for each al-\ngorithm for the SST-2 dataset and with a dataset size of\n20.\nC Supplementary Results\nIn this section we give supplementary results to\nthe paper. Table 4 gives some information about\nthe datasets, and Table 5, the results of data aug-\nmentation on the full training set, with a ratio of\ngenerated-to-genuine of one.Table 4: The tasks tackled in this study. The length of\nthe sentences is defined by the number of tokens when\ntokenized at white spaces.\nName SST2 Irony FakeNews IronyB TREC6\n|classes| 2 2 2 4 6\n|Dtrain|6920 2683 12799 2681 5452\nlen. sents. 19.3 13.7 12.5 13.7 10.2\nFigure 1: Average metric vs Ratio for a dataset size of\n10 and ChatGPT-Desc, AEDA, and T5.\nFigure 1 shows the performance as we increase\nthe ratio for the ChatGPT-Desc strategy, compared\nto AEDA and T5, and with a dataset size of 10. As\nwe can observe, the performance plateau quickly\nfor all algorithms. Given that Chat-GPTDesc per-\nforms much better on SST-2 than the other datasets,\nwe also give in Figure 2 the results while exclud-\ning SST-2. We leave for future work to investigate\nwhether the plateauing for ChatGPT-Desc is due to\nlack of fine-tuning or simply the limit of ChatGPT\nwhen it comes to generate diverse sentences.\nD Technical details\nAll final hyperparameters are detailed in the github,\nand we show a summary of which hyperparameters\nwe fine-tuned in Table 7. For fine-tuning the classi-\nfiers, we changed the number of epochs while leav-\ning the other parameters fixed. For fine-tuning the\nalgorithms, we played with the hyperparameters\ndetailed in Table 7, exploring random combinations\naround the hyperparameters recommended in the\noriginal papers. To correctly assess the capacities\nof the DA methods on the different datasets, we\nkeep the same hyperparameters for a given dataset\nsize across all datasets. Experiments were run on\nNVIDIA GeForce RTX 3090 with 24G of memory.15614\nTable 5: Average metric over 15 runs (accuracy and macro-F1) for the full training set and for all datasets. STDs are\nbetween 0.3 and 3.3, depending on the dataset.\nSST2 FakeNews Irony IronyB Trec6 Average\nBaseline 87.7 73.3 65.6 42.4 81.0 70.0\nEDA 87.9 73.7 65.8 43.1 81.3 70.4\nAEDA 88.0 73.5 65.7 42.8 82.7 70.5\nBT 88.2 73.6 66.2 42.4 81.7 70.4\nCBERT 87.5 73.6 65.8 40.6 80.9 69.7\nCGPT 87.8 73.2 65.2 42.8 82.1 70.2\nCBART 87.7 73.9 65.9 42.7 78.6 69.8\nT5 87.9 73.8 65.3 43.1 79.9 70.0\nGPT3.5-Par 88.2 73.8 66.8 42.8 82.4 70.8\nGPT3.5-Desc 87.4 71.9 64.1 41.1 79.8 68.9\nFigure 2: Average metric vs Ratio for a dataset size of\n10 and ChatGPT-Desc, AEDA, and T5, excluding the\nSST-2 datasets from the average.\nIronic Shoutout to my mom for being\nhella supportive of me\nIronic Luv this\nNon-Ironic @alyssaanicoleL this Friday lit\nNon-Ironic they don\u2019t sing live, but they sure\nare hella good looking #smh\nTable 6: Examples of the Irony datasets which our man-\nual examination found to be ambiguous.EDA ratios ins, del, swap, syn\nAEDA -\nBT num. beams (en \u2192de, de\u2192en),\nCBERT lr, epochs, bs, ratio mask\nCGPT lr, epochs, bs,\nCBART lr, epochs, bs, ratio mask\nT5 top_p\nChatGPT -\nTable 7: Hyperparameters fine-tuned during our experi-\nments. lr stands for learning rate, bs for batch size, and\nratio mask refers to the percentage of words that are\nmasked.\n10 20 500 1000\nEDA 0m1s 0m1s 0m4s 0m6s\nAEDA 0m0s 0m0s 0m0s 0m0s\nBT 0m7s 0m11s 0m27s 0m52s\nCBERT 0m1s 0m1s 0m8s 0m15s\nCGPT 0m15s 0m22s 2m11s 5m38s\nT5 0m6s 0m3s 0m18s 0m36s\nTable 8: Running time for the different DA algorithms\nand SST-2, excluding the time of the classifier.\nIn Table 8, we show the running time for aug-\nmentation part of the process, for SST-2 and the\ndifferent dataset sizes. We do not include the train-\ning time of the classifier.15615", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Is ChatGPT the ultimate data augmentation algorithm?", "author": ["F Piedboeuf", "P Langlais"], "pub_year": "2023", "venue": "Findings of the Association for \u2026", "abstract": "In the aftermath of GPT-3.5, commonly known as ChatGPT, research have attempted to  assess its capacity for lowering annotation cost, either by doing zero-shot learning, generating"}, "filled": false, "gsrank": 95, "pub_url": "https://aclanthology.org/2023.findings-emnlp.1044/", "author_id": ["TerngKQAAAAJ", "VHd-kDEAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:j48a1j-0QYkJ:scholar.google.com/&output=cite&scirp=94&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D90%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=j48a1j-0QYkJ&ei=FbWsaISmDuHUieoP9LKZ6AI&json=", "num_citations": 28, "citedby_url": "/scholar?cites=9890384442950324111&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:j48a1j-0QYkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2023.findings-emnlp.1044.pdf"}}, {"title": "A Hybrid Model to Detect Fake News", "year": "2019", "pdf_data": "Boi se St ate Universit y\nScholarWorks\nComput er Science Gr aduate Projects a nd The ses Departme nt of C omput er Science\n5-1-2019\nA H ybrid M odel t o D etect Fake N ews\nIndhumathi G urunathan\nBoise S tate University\nA HYBRID MODEL TO DETECT FAKE NEWS  \n \n \n \n  \nby \nIndhumathi Gurunathan \n     \nA project \nsubmitted in partial fulfillment \nof the requirements for the degree of \nMaster of Science in Computer Science \nBoise State University  \n \nMay 2019  \n \n            \n \n      \n\u00a9 2019 \nIndhumathi Gurunathan \nALL RIGHTS RESERVED   \nBOISE STATE UNIVERSITY GRADUATE COLLEGE  \n \n \nDEFENSE COMMITTEE AND FINAL READING APPROVALS  \n \n \nof the thesis submitted by \n  \nIndhumathi Gurunathan \n  \nThesis Title:  A hybrid Model to Detect Fake News \n Date of Final Oral Examination:  23 April 2019 \n The following individuals read and discussed the project submitted by student Indhumathi Gurunathan, and they evaluated her presentation and response to questions during the final oral examination.  They found that the student passed the final oral examination.  Francesca Spezzano, Ph.D.    Chair, Supervisory Committee \n Dianxiang Xu, Ph.D.     Member, Supervisory Committee  \n Bogdan Dit, Ph.D.    Member, Supervisory  Committee  \n \nThe final reading approval of the thesis was granted by Francesca Spezzano, Ph.D., Chair of the Supervisory Committee.  The thesis was approved for the Graduate College by John R. Pelton, Ph.D., Dean of the Graduate College. \niv DEDICATION  \nDedicated  to my husband Ashok, my two kids Akshaya Sri and Goutham Kirthik.  \nv ACKNOWLEDGEMENTS  \nI would like to address my heartfelt thanks to my advisor, Dr. Francesca Spezzano , \nfor her support and advice s he gave me during my graduate studies at Boise State \nUniversity. Her  guidance and knowledge have been a major factor throughout my project. \nI would also like to thank my committee members, Dr. Dianxiang Xu and Dr. Bogdan Dit  \nfor the guidance and support th rough this process.  \nI would also like to thank the Computer Science Administrative Department for \nhelping me whenever needed and for providing a welcoming environment for international \nstudents. And finally, I would like to thank my parents and my amazing  family for the \nnever -ending love, care and support given to me over the years and I undoubtedly could \nnot have done this without them.  \nvi ABSTRACT  \nThe wide availability of user -contributed content in the online social media \nfacilitates aggregation of people around common interests, worldviews, and narratives. But \nover the years, internet being the source of information also becomes the source of \nmisinformation. As people are generally awash in information, they can sometimes have \ndifficulty discerning misinformation propagated on web platforms from truthful \ninformation. They may also lean heavily on information providers or s ocial media \nplatforms to curate information even though such providers do not commonly validate \nsources.  In this project , we primaril y focus  was on political news and propose  a hybrid \nmodel to detect misleading news. We use different modalities including news content \n(headline, body, and associated image) , source bias and social network of users who spread \nthe news  to detect whether the news is misleading or factual .  \nWe study t he relation ship between the publisher bias and news stance and show \nthat hyperp artisan news sources are more likely to spread misleading stories than other \nsources. Also, we demonstrate that it is not necessary to analyze the news content to detect \nmisleading news, but using features such as publisher bias, user engagements, and imag es \nrelated to the news can achieve comparable  performances (AUROC of 0.90 vs. 0.88 and \naverage precision of 0.79 vs. 0.78) . \nvii TABLE OF CONTENTS  \nDEDICATION  ................................................................................................................... iv \nACKNOWLEDGEMENTS  .................................................................................................v \nABSTRACT  ....................................................................................................................... vi \nLIST OF TABLES  ............................................................................................................. ix \nLIST OF FIGURES  .............................................................................................................x \nLIST OF PI CTURES  ......................................................................................................... xi \nLIST OF ABBREVIATIONS  ........................................................................................... xii \nCHAPTER 1  ........................................................................................................................1 \nINTRODUCTION  ...................................................................................................1 \nCHAPTER 2  ........................................................................................................................4 \nRELATED WORK  ..................................................................................................4 \nCHAPTER 3  ........................................................................................................................9 \nDATASETS  .............................................................................................................9 \n3.1 Available Datasets and Limitations  .......................................................9 \n3.2 FakeNewsNet Dataset  ..........................................................................10 \n3.3 MediaBias/FactCheck Dataset  .............................................................11 \nCHAPTER 4  ......................................................................................................................13 \nMETHODS TO EXTRACT FEATURES  .............................................................13 \n4.1 Textual Features  ...................................................................................13 \n4.1.1 Term Frequency- Inverse Document Frequency (Tf -Idf) ..................13 \n4.1.2 Linguistic Inquiry and Word Count (LIWC)  ....................................14 \n4.1.3 Readability  ........................................................................................15 \nviii 4.2 Image Features .....................................................................................15 \n4.2.1 NeuralTalk2 ......................................................................................15 \n4.3 Source Bias  ..........................................................................................16 \n4.4 Social Network Features ......................................................................17 \nCHAPTER 5  ......................................................................................................................20 \nEXPERIMENTS  ....................................................................................................20 \n5.1 News Body Content .............................................................................20 \n5.2 News Headline .....................................................................................21 \n5.3 News Source Bias  ................................................................................21 \n5.4 News Image .........................................................................................21 \n5.5 News Social Network  ..........................................................................22 \n5.5 Do we need to \u201cRead\u201d? ........................................................................26 \nCHAPTER 6  ......................................................................................................................29 \nCONCLUSIONS AND FUTURE WORK  ............................................................29 \nREFERENCES ..................................................................................................................30 \nAPPENDIX A  ....................................................................................................................38 \nTitle of Appendix A ...............................................................................................38 \n \n \nix LIST OF TABLES  \nTable 3.1: Available datasets for misleading news detection. ............................................ 9 \nTable 4.1: Edge Potential functions between the node publisher and news ..................... 19 \nTable 4.2: Edge Potential functions between the node news and users ............................ 19 \nTable 4.3: Edge Potential func tions between the node users and users  ............................ 19 \nTable 5.1 Credibility Score for features with total news count spread by the user greater \nthan 6 and 7 (BuzzFeed). .......................................................................... 24 \nTable 5.2 Credibility Score for features with total news count spread by the user greater \nthan 6 and 7 (PolitiFa ct). ........................................................................... 25 \nTable 5.3: RandomForest Classification results with multi- modal features.  .................... 25 \nTable 5.4:  F1- measure, AUROC, and average precision results with combination of bias, \nheadline, image, and social features.  ........................................................ 27 \nTable A.1 Linear SVM Classifier results with multi -modal features  ........................ 38 \nTable A.2:  F1-measure, AUROC, and average precision results with the combination of \nbias, headline, image, and social features.  ................................................ 39 \n \n \nx LIST OF FIGURES  \nFigure 1: Number of publishers per category in the MediaBias/FactCheck dataset.  ........ 12 \nFigure 2: Publisher credibility per bias and bias distribution within questionable sources \nin the MediaBias/FactCheck dataset.  ........................................................ 12 \nFigure 3. In- degree & Out -degree and percentage of users\u2019 distribution  ......................... 23 \n \n \nxi LIST OF PICTURES  \nPicture 1: Examples of images associated with misleading (top) and factual (bottom) \nnews.  ......................................................................................................... 22 \n \n \nxii LIST OF ABBREVIATIONS  \nRNN    Recurrent Neural Network  \nLSTM    Long Short -Term Memory  \nGPU    Graphics Processing Unit  \nAMT    Amazon Mechanical Turk  \nTF-IDF   Term Frequency -Inverse Document Frequency  \nLIWC    Linguistic Inquiry and Word Count  \nSMOG   Simple Measure of Gobbledygook Index \nARI    Automatic Readability Index  \nLIX    Lycee International Xavier Index  \nCNN    Convolutional Neural Network \nVGG    Visual Geometry Group  \nSNAP    Stanford Network Analysis Platform  \nMBFC   Media Bias Fact Check  \nBP    Belief Propagation  \nROC    Receiver Operating Characteristic  \nAUROC   Area Under the ROC  \nMRF    Markov Random Field \nURL    Uniform Resource Locator  \nTTR    Text-Type Ratio  \nCSI    Capture, Score, and Integrate  \nxiii  \n \n1 \n CHAPTER 1  \nINTRODUCTION  \nAccording to the Oxford dictionary, misinformation is \u201cfalse or inaccurate \ninformation, especially that which is deliberately intended to deceive\u201d. These days, the \nmassive growth of the Web and social media has provided fertile ground to consume and quickly spread the misinformation without fact -checking. Misinformation can assume \nmany different forms such as vandalism  [6], spam  [50], rumors  [8], hoaxes  [51], clickba it, \ncounterfeit websites, fake product reviews  [7], fake news  [23] , etc.  \nFake news is low -quality news that is created to spread misinformation and mislead \nreaders. The consumption of news from social media is highly increased nowadays so as spreading of fake news. According to the Pew research center [ 9], 64% of Americans \nbelieve that fake news causes confusion about the basic facts of current events. A recent \nstudy conducted on Twitter [ 10] revealed that fake news spread significantly more than \nreal ones, in a deeper and faster manner and that the users responsible for their spread had, \non average, significantly fewer followers, followed significantly fewer people, were significantly less active on Twitter. Also, human behavior contributes more to the dif fusion \nof fake news than the real news especially when the news conforms to their preexisting attitudes and beliefs. Moreover, bots are equally responsible for spreading real and fake \nnews, and then the considerable spread of fake news on Twitter is caused  by human \nactivity.  \n2 \n The volume of misleading news in social media has grown in popularity in recent \nyears. In 2017, the Pew Research Center found that 67% of American adults (ages 18+) \nget news from social media, which was a 5% increase since 2016 [11]. An  analysis of news \nleading up to the 2016 election conducted by BuzzFeed, found that there was more engagement with the leading misleading news stories than real news stories [12]. Thus, news is becoming more accessible and widespread than ever before. However, the spread of information has also contributed to the spread of misleading news which has fostered the advancement of various methods to determine the validity of news. One such method is developed upon evaluating linguistic attributes such as features determining readability and lexical information [21, 16, 30]. These methods often mimic that of what would generally be considered the most effective of all: reading through news the purpose of evaluating their accuracy. However, with the spread of misleading news it is unlikely if not impossible for everyone to spend large quantities of time reading through multiple \nnewspapers and sources. Additionally, in a recent study, Gabielkov et al. [13] found \nevidence that the number of news shares is an inaccurate measure of actual readership. Thus, people are immersed in information across social media which is often shared without users reading and considering the validity of content thus leading to possible consequences of its diffusion. The impact of fake news  diffusion is huge, it affects news \nmedia ecosystem, cause political damage, influences social media marketing and also impairs individuals\u2019 opinions. According to the Pew research center [9], 64% of Americans believe that fake news cause confusion about the basic facts of current events. In the same Pew survey, 23% of respondents admitted to sharing fake news, while 14% said they shared an article knowing it was fake. Even Oxford dictionary selected \u201cpost -truth\u201d as its \n3 \n word of the year 2016. According to a  2016 Gallup poll [3], trust in mass media among \nAmericans has plummeted to 32 percent, an all-time low from 72 percent in 1976. \nThus, in this project, we use machine learning techniques to develop a hybrid model \nto detect fake news. To the best of our knowledge, we analyze all the news data available \nincluding headline, body content, associated image, social network of the users who spread the fake news and source bias, for misleading news detection. Interestingly, our analysis highlights a correlation between publisher political bias and its credibility. In fact, by analyzing information collected from mediabiasfactcheck.com, \u201cthe most comprehensive media bias resource on the Internet\u201d, we showed that hyperpartisan news sources are more likely to spread mi sleading stories than other sources. Moreover, we find out that we can \navoid to \u201cread\u201d the news to determine its veracity, as considering publisher bias, user engagements, and images related to the news can achieve comparable performances (AUROC of 0.90 vs. 0.88 and average precision of 0.79 vs. 0.78).  \nThe remainder of this document is organized as follows: Chapter 2 discusses about \nthe related work that was done previously for fake news detection. Chapter 3 provides a brief description on the dataset and discuss the techniques used in the data collection process from mediabiasfactcheck.com website. Chapters 4 and 5 describe the methods to extract features from various aspects of the news and the experiments for different combination of these features to detect misleading news. Chapter 6 concludes the report discussing the efficiency of the hybrid model and suggest directions for future work. \n4 \n CHAPTER 2  \nRELATED WORK  \nTo detect misleading news, many works have considered news content (headline, \nbody, image), the social network between the users and their social engagement (share, \ncomment, and discuss given news), or a hybrid approach that considers both (see [17, 23] for a survey). The survey Shu, et al. (2017) [23], precisely gave definitions about the fake news and provided the complete review of methods to detect fake news on social media. \nThe paper characterized the fake news by comparing different theories and properties in both traditional news media and social media. Existing algorithms to detect fake news  on \ntraditional media depends on only the news content. These methods are ineffective for the case of social media and therefore, leveraging this problem with extra social context auxiliary information helps to detect fake news more efficiently. \nNews content- based features include both linguistic features extracted from the text \nof the news, metadata- based features such as news source (author and/or publisher), \nheadlines, etc., and visual -based features extracted from images and videos associated with \nthe news. For instance, Seyedmehdi and Papalexakis [ 20] proposed a solution based on \nextracting latent features from news article text via tensor decomposition to categorize fake news as extreme bias, conspiracy theory, satire, junk science, hate group, or stat e news. \nPotthast et al. [ 24] used the writing style of the articles to identify extremely biased news \nfrom the neutral one by using the techniques called unmasking. This study used a dataset com- posed of 1,627 articles from a Buzzfeed dataset. Features such as n - grams,  stop \nwords, parts of speech and readability were considered in this study. Although there was higher accuracy in determining the mainstream articles vs. hyperpartisan (0.75 accuracy \n5 \n based on stylistic features and 0.71 for topic) the research was limited in deciphering \nbetween real and fake news (only a 0.55 accuracy for style and 0.52 for topic).  \nHorne and Adali [ 21] considered both news body and headline for determining the \nvalidity of news. They included three datasets: a dataset created  by Buzzfeed leading to the \n2016 US elections, one created by the researchers containing real, fake and satire sources, and a third dataset containing real and satire articles from a previous study. Based on textual features extracted from body and headline, they found out that the content of fake and real news is drastically different as they were able to obtain a 0.71 accuracy when considering number of nouns, lexical redundancy (TTR), word count, and number of quotes. Further, the study found that fake titles contain different sorts of words (stop words, extremely positive words, and slang among others) than titles of real news articles resulting in a 0.78 accuracy. P \u00e9rez-Rosas et al [1 6] collected two new datasets, the FakeNewsATM dataset \ncovering seven different news domains (education, business, sport, politics, etc.) and the \nCelebrity dataset regarding news on celebrities. They analyzed the news body content only and achieved an accuracy up to 0.76 in detecting misleading content. They also tested cross domain classification obtaining poor performances by training in one dataset and testing in the other one, but better accuracies (ranging from 0.51 to 0.91) in training on all but the test domain in the FakeNewsATM dataset.   \nImages in news articles also  play a role in misleading news detection [34, 18, 19 , \n25]. Fake images are used in news articles to provoke emotional responses from readers. Images are the most eye- catching type of content in news; a reader can be convinced of a \nclaim by just looking at the title of the news and the image itself. So, it\u2019s cru cial to include \nimage analysis in fake news detection techniques.  \n6 \n For instance, Jin et al. [ 33] used only visual and statistical features extracted from \nnews images for microblogs news verification and obtained an accuracy of 0.83 on an \nimage dataset coll ected from Sina Weibo on general news events. More recently, Wang \net al. [2 9] proposed a deep- learning based framework to extract features from both text \nand image of the news that are not related to specific events to detect misleading content. Their resu lts show an accuracy value ranging from 0.71 on a Twitter dataset to 0.82 on \nSina Weibo.  \nSocial context -based features consider (i) the profile and characteristics of users \ncreating and spreading the news (e.g., number of followers/followees, number of posts, credibility and the reliability of the user) also averaged among all the users related to particular news, (ii) users\u2019 opinion and reactions towards social media posts (post can potentially contain fake news), (iii) various type of networks such as friendship networks, co-occurrence networks (network formed based on the number of posts the user write \nrelated to the news), or diffusion network where edges between users represent information dissemination paths among them.  \nKim et al. [ 27] propose methods to not only detect the fake news but also to prevent \nthe spread of fake news by making the user flag fake news and used reliable third -parties \nto fact check the news content. They developed an online algorithm for this purpose, so it works at the time of  user spreading the fake news thus preventing it from spreading. Jin et \nal. [28] developed a method for detecting fake news by using the users\u2019 viewpoints to find \nrelationships such as support or oppose and by building a credibility propagation network \nby using these relationships. Users on social media inclined to network with like -minded \npeople and then they receive and share the news that promotes their interests/beliefs which \n7 \n will result in echo chamber effect. So, extracting these network -based features by creating \ndifferent kinds of network such as stance, co -occurrence, friendship, and diffusion \nnetworks help to infer network pattern to identify the fake news.  \nThe stance network has nodes and edges with nodes representing the posts related \nto the news and the edge indicating the weight of the similarity of the viewpoints. The co-\noccurrence network is built based on the user engagements by counting the number of posts \nthe user -authored related to the news. The friendship network represents the network \npattern of the followers and followees of the user who posts related to the news. The \ndiffusion network tracks the information diffusion path between the users. Network metrics \nsuch as degree and clustering coefficients are used to characterize the diffusi on and \nfriendship network. Wu and Liu [ 31] used the way news spread through the social network \nto find the fake news. They used graph mining method to analyze the social network and \nrecurrent neural networks to represent and classify propagation pathways of a message.  \nFinally, hybrid methods combine the two previous approaches. For instance, \nRuchansky et al. [ 32] used temporal behavior of users and their response and the text \ncontent of the news to detect the fake news. They proposed the CSI model (Capture, Score, and Integrate) to classify the news article. Fairbanks et al. [ 37] show that a content -based \nmodel can identify publisher political bias while a structural analysis of web links is enough to detect whether the news is credible or not. Shu et al. [ 36] exploited both fake news \ncontent and the relationship among publishers, news pieces, and users to detect fake news.  \nRegarding clickbait detection specifically, Chakraborty et al. [ 41] build \npersonalized automatic blocker for clickbait headlines by using a rich set of features that use sentence structure, word patterns, N -gram features, and clickbait language. Their \n8 \n browser extension \u2018Stop- Clickbait\u2019 warns users for potential click - baited headlines. \nPotthast et al. [ 39] used Twitter datasets to iden tify messages in social media that lead to \nclickbait. They gathered tweets from various publishers and constructed features based on \nteaser message, linked web page, and meta information. Anand et al. [ 38] used three \nvariants of bidirectional RNN models (LSTM, GPU, and standard RNNs) for detecting clickbait headlines They used two different word embedding techniques such as distributed word embeddings and character -level word embeddings. Chen et al. [ 42] examined a \nhybrid approach for clickbait detection by using text -based and non- text-based click baiting \ncues. While textual cues use text -based semantic and syntactical analysis, non -textual cues \nrelate to image and user behavior analysis.  \n9 \n CHAPTER 3  \nDATASETS  \nIn this chapter, we discuss the lack of a large- scale  misleading news dataset \n(especially in the political domain)  and present the datasets used in this project , namely the \nFakeNewsNet dataset and a new dataset containing publisher bias and credibility details  \ncrawled from the MediaBias/FactCheck website.   \n3.1 Available Datasets and Limitations  \nThere exist several datasets containing political news that have been used for fake \nnews detection, as shown in Table 1.  \nTable 3.1: Available datasets for misleading news detection.  \nDataset  Size Text Images  \nBuzzFeedNews [20]  1,627 \u2713  \nHorne and Adali DS1 [11] 71 \u2713  \nHorne and Adali DS2 [11] 225 \u2713  \nP\u00e9rez-Rosas et al [18]  480 \u2713  \nFakeNewsNet [24]  384 \u2713 \u2713 \n The BuzzFeedNews dataset contains news regarding the 2016 U.S. election \npublished on Facebook by 9 news agencies. This dataset labels 356 news articles as left -\nleaning and 545 as right -leaning articles, while 1264 are mostly true, 212 are a mixture of \ntrue and false, and 87 are false. Horne and Adali used two datasets in their paper [ 21]. The \nfirst dataset, DS1, contains 36 real news stories and 35 fake news stories, while the second \none, DS2, contains 75 real, misleading and satire news (75 for each category). The main drawback of these two datasets is that labels are assigned according to the credibility of  the \n10 \n news source, instead of via fact -checking. However, a news source can have mixed \ncredibility and publish both factual and misleading information. P \u00e9rez-Rosas et al [1 6] \ncollected a dataset of 480 news where 240 are fact -checked real news belonging to  six \ndifferent domains (sports, business, politics, etc.) and 240 are fake news collected via \ncrowdsourcing, i.e. they asked to AMT workers to write a fake news item based on one of their real news item and by mimic journalist style. FakeNewsNet [ 35], desc ribed in Section \n3.2, is the only state -of-the- art dataset containing information beyond the news content \nmodality and in the political domain. With the importance and relevance, this dataset was  \nused to conduct the analysis in this project. As Table 1 shows, there is generally limited \navailability of large -scale benchmarks for fake news detection as collecting labels requires \nfact-checking, which is a time -consuming activity. As reported in [23], other datasets have \nbeen used for related tasks, but they are not suitable for our analysis as they do not contain proper news articles. For instance, LIAR [ 40] contains human- labeled short statements, \nwhile CREDBANK [ 47] contains news events, where each event is a collection of tweets. \nFinally, the MediaEval Verifying Multimedia Use benchmark dataset [ 43] used in [29] \ncontains images and tweets instead of news articles.  \n3.2 FakeNewsNet Dataset  \nThe FakeNewsNet dataset consists of details about the news content, publisher \ninformation, and social engagement information [ 35]. The ground truth labels are collected \nfrom journalist experts such as Buzzfeed and the fact -checking website Politifact. The \ndataset is divided into two networks as Buzzfeed and Politifact and the news contents are collected from Facebook  web links. Dataset included  all the downloaded available images \nrelated to the news in this dataset. The publishers\u2019 bias is retrieved from the dataset \n11 \n described in the next section. In this work, the news from both Politifact and Buzzfeed \nwere merger to have a larger dataset to work with. After cleaning the dataset from missing \nnews bodies or headlines, there were  a total of 384 news, 175 misleading and 209 factual. \n3.3 MediaBias/FactCheck Dataset  \nIn order to exploit the partisan information of the news source, we crawled the \nwebsite mediabiasfactcheck.com, whose main goal is to educate the public on media bias \nand deceptive news practices. This website contains a comprehensive list of news sources, their bias and their credibility of factual reporting sc ore. Here, the publisher political bias \nis defined by using seven degrees of bias: extreme -right, right, right- centered, neutral, left-\ncentered, left, and extreme- left.  \nThe factual reporting score of all the news sources were collected under five \ncategori es: Left bias (moderately to strongly biased to - ward liberal causes), Left -center \n(slight to moderate liberal bias), Least (minimal bias), Right- Center (slightly to moderately \nconservative in bias), and Right bias (moderately to strongly biased toward conservative causes). The credibility score of these publishers falls into three categories: Very high (which means the source is always factual), High (which means the source is almost always factual) and Mixed (which means the source does not always use pro per sourcing or \nsources to other biased/mixed sources). The  publisher bias was also collected under the \ncategory Questionable Sources which contains extremely biased publishers mainly doing propaganda and/or writing misleading news. The number of publisher s in each category \nconsidered is reported in Figure 1 and there is  a total of 1,783 publishers. The relationship \nbetween the source bias and its credibility is analyzed in Section 4.3.  \n12 \n  \nFigure 1: Number of publishers per category in the MediaBias/FactCheck dataset.  \n  \n \n \nFi\ngure 2: Publisher credibility per bias and bias distribution within questionable \nsources in the MediaBias/FactCheck dataset.  \n\n13 \n CHAPTER 4  \nMETHODS TO EXTRACT FEATURES  \nIn this chapter, we describe in detail the set of features used in the experiments to \ndetect misleading political news. We consider five different  modalities, namely news \ncontent, headl ine, news description , images, source bias, and social.  \n4.1 Textual Features  \nTo analyze text content, we use the following groups of features, and these features \nare computed for both the news body content and news headline. \n4.1.1 Term Frequency -Inverse Do cument Frequency (Tf- Idf) \n In this work, a tf-idf is used  to represent text, where each word is \nrepresented by its score to express the importance of the word in a corpus based on how \nfrequently the word appears in the document and also how many other documents contain that word. We preprocessed the text by applying S temming  and punctuations and stop-\nword removal. A basic tf -idf scoring function is available in Eq. 4.1. \n \ntf-idf w,di,D = \ufffd\ud835\udc36\ud835\udc36\ud835\udc64\ud835\udc64\n|\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc56|\ufffd.log\ufffd|\ud835\udc37\ud835\udc37|\n1+|\ud835\udc51\ud835\udc51\u2208\ud835\udc37\ud835\udc37  \u2236  \ud835\udc64\ud835\udc64\u2208\ud835\udc51\ud835\udc51 |\ufffd      (4.1) \nThe first term represents the term frequency (tf) of the word w, which is the ratio \nof\n the number of occurrences of the word ( \ud835\udc36\ud835\udc36\ud835\udc64\ud835\udc64) to the total number of words in the document \n(|\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc56|). The second term is the inverse document frequency (idf) which boosts the more \ninformative words and  diminish the impact of frequently used words likes articles, \npronouns. The idf is computed by taking the logarithm of the total number of documents in the corpus (|D|) divided by the number of documents with the word offset by 1 to avoid \n0 denominators (1  + |d \u2208  D: w \u2208  d|). The words that appear in almost all the documents \n14 \n will have an idf close to 0 and the words that appear in only select documents will have \nlarger idf values, thereby increasing their tf -idf weights. \n4.1.2 Linguistic Inquiry and Word Count (LIWC) \nLIWC  is a transparent text analysis tool that counts words in psychologically \nmeaningful categories. LIWC 93 measures were used for analyzing the cognitive, affective, and grammatical processes in the text. To examine the difference between the factual and misleading news writing style, the LIWC features  are divided into four categories: \nLinguistic, Punctuation, Psychological, and Summary [44].  \nLinguistics features refer to features that represent functionality of text such as the \naverage numb er of words per sentence and the rate of misspelling. Thus, total function \nwords as well as negations under this category  were chosen .  \nPunctuation features  are used to dramatize or sensationalize a news story which \ncan be analyzed through types of punctuation used in the news such as Periods, Commas, \nColons, Semicolons, Question marks, Exclamation marks, Dashes, Quotation marks, \nApostrophes, Parentheses, and Other punctuation.  \nPsychological features  target emotional, social process and cognitive processes. \nThe affective processes (positive and negative emotions), social processes, cognitive processes, perceptual processes, biological processes, time orientations, relativity, personal concerns, and informal language (swear words, nonfluencies) can be used to scrutinize the emotional part of the news.  \nSummary features  define the frequency of words that reflect the thoughts, \nperspective, and honesty of the writer. It consists of Analytical thinking, Clout, \n15 \n Authenticity, Emotional tone, Words per sentence, Wor ds more than six letters, and \nDictionary words under this category. \n4.1.3 Readability \n  Readability measures how easily the reader can read and understand a text. \nText complexity is measured by using attributes such as word lengths, sentence lengths, \nand syllable counts. The  popular readability measures were used in the analysis: Flesh \nReading Ease, Flesh Kincaid Grade Level, Coleman Liau Index, Gunning Fog Index, Simple Measure of Gobbledygook Index (SMOG), Automatic Readability Index (ARI), Lycee Internat ional Xavier Index (LIX), and Dale -Chall Score. Higher scores of Flesch \nreading- ease indicate that the text is easier to read and lower scores indicate difficult to \nread. Coleman Liau Index depends on characters of the word to measure the understandability of the text. The Gunning Fog Index, Automatic Readability Index, \nSMOG Index, Flesh Kincaid Grade Level are algorithmic heuristics used for estimating \nreadability that is, how many years of education is needed to understand the text. Dale -\nChall readability  test use a list of words well- known for the fourth- grade students (easily \nreadable words) to determine the difficulty of the text.  \n4.2 Image Features  \nTo analyze the image associated with the news, the state -of-the- art deep -learning \nbased technique were used to extract features from the images.  \n \n \n4.2.1 NeuralTalk2  \n16 \n NeuralTalk2 is an efficient image captioning model, coded in Torch that runs on \nGPU. It is similar to the original NeuralTalk, but this model implementation is batched, \nuses Torch, runs on a GPU, and supports CNN finetuning. All of these together result in quite a large increase in training speed for the Language Model (~100x). NeuralTalk2 model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional R ecurrent Neural Networks over sentences, and a structured \nobjective that aligns the two modalities through a multimodal embedding. Then they designed a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. The models can be trained  using loadcaffe  using VGGNet. But in this project, the  pretrained model checkpoint \nwere used to extract a caption describing the image content from the images associated with the news by using NeuralTalk2 [ 45], a pre -trained recurrent neural network that \nsummarizes the content of an image in a one sentence description. After that  a tf-idf to \nrepresent the text  from these captions were computed and  considered as an additional set \nof features in the analysis.  \n4.3 Source Bias  \nSeveral studies in the field of journalism have theorized a correlation between the \npolitical bias of a publisher and the trustworthiness of the news content it distributes [6, 9]. To validate this assumption, the relationshi p between the political bias of a news source \nand its credibility were examined by analyzing the information about 1,785 publishers in the MediaBias/FactCheck dataset. Figure 2 shows the distribution of the credibility score per political bias category (from Left to Right) and the bias distribution in the questionable sources. The plots show that when the news source is moderately to strongly biased (either \n17 \n conservative or liberal), then the source is more likely to publish misleading news than \nother news sources that are more moderate and declared as left -centered, right -centered, or \nneutral. Also, the Extreme- right (or strongly conservative) is the predominant bias among \nthe questionable sources. Thus, the news source bias was  used as another feature in the \nexperiments.  \n4.4 Social Network Features \nSocial network  features give useful information about users' social network, how \nfast and deep the fake news propagate through these networks. Here we use the relationship between the publishers and news, news a nd users, users and users to derive the veracity of \neach of them. Then, the credibility score for a news is computing by modeling the problem \nas a Markov Random Field (MRF) where we use the loopy belief propagation  (BP)  \nalgorithm [ 49] to conduct the infere nce. In general, the MRF  approach treats each node as \na random variable and in our problem, we have  three types of node s publishers, news, and \nusers.  The random variable for each node is represented as p i \u2208 {0,1}, n j \u2208 {0,1}, and u k \u2208 \n{0,1} where  0 being not credible and 1 being credible and the output is a marginal \nprobability p(p i), p(n j), and p(u k) quantifying the belief that a node i belongs to class p i, \nnode j belongs to n j, and node k belongs to  uk. The prior probability of each node can be \nassigned and represented by the function \u2205(pi),  \u2205(nj), and \u2205(uk) that can be obtained from \nour dataset s. Given its bias, \u2205(pi) gives information about whether the publisher is credible \nor not. For example, for the Right bias, the prior probability that there is a higher chance \nthat the publisher is not credible as shown in Figure 2. For the left bias, even though the \nprobability of not credible is lower compared to right bias but the chance of being not \ncredible is higher compared to other biased publishers.  The questionable sources are \n18 \n mostly from non- credible sources and maximum percentage of publishers are extreme right \nbiased. \nWith the lack of prior knowledge and information regarding the news and based on \nthe ground truth , the assumption was made that the news can be 50% chance of being \ncredible and 50% not credible. A new study from MIT [ 46] [10] proposed that the human \nnature is responsible for  the rapid spread of fake news than the true credible news. The \nresearch work analyzed more than 100,000 news stories on Twitter as for how many total \ntweets were posted and re- posted, time to reach the magnitude of engagement, and \nverifying the account from where it is created. They have proved that the users who spread \nfake news had significantly fewer followers, followed fewer people and less active on Twitter. This study was used in this research work to infer the prior probability of the user s \nin the  network by computing the in- degree, out -degree. These  features representing number \nof followers/follow ings were extracted using the graph mining library , SNAP [4], based on \nthe network between the users. These individual level features are used to infer the \ncredibility and reliability for each user spreading news in the social network. \nThe function \ud835\udf13\ud835\udf13\nij is a hyper parameter that determines the conditional probability \nfor each node and the credibility score can be measured for the edges using edge potential \nfunction. The below tables show the choice of the affinity matrix \ud835\udf13\ud835\udf13 , for \ud835\udf00\ud835\udf00 > 0, this choice \nof \ud835\udf13\ud835\udf13 assumes the correlation between the nodes. Table 4.1. Shows that if the publisher is \nnot credible then there is higher probability to publish fake news and low probability to publish real news. Likewise, if the news is not credible then there is high probability that the user spread that news is also not credible and low probability to spread good news as shown in Table 4.2. Similarly, if the user is not credible then there is higher probability \n19 \n that the neighbor/friend users are also not credible and the same can be perceived from \nTable  4.3. \nTable 4.1: Edge Potential functions between the node  publisher and news  \n\ud835\udf13\ud835\udf13(pi, nj) 0 1 \n0 1\u2212\ud835\udf00\ud835\udf00 \ud835\udf00\ud835\udf00 \n1 \ud835\udf00\ud835\udf00 1\u2212\ud835\udf00\ud835\udf00 \n \nTable 4.2: Edge Potential functions between the node news and users  \n   \n \nTable 4.3: Edge Potential functions between the node users and users \n \n \n \n \ud835\udf13\ud835\udf13(nj, uk) 0 1 \n0 1\u2212\ud835\udf00\ud835\udf00 \ud835\udf00\ud835\udf00 \n1 \ud835\udf00\ud835\udf00 1\u2212\ud835\udf00\ud835\udf00 \n\ud835\udf13\ud835\udf13(uk, uk) 0 1 \n0 1\u2212\ud835\udf00\ud835\udf00 \ud835\udf00\ud835\udf00 \n1 \ud835\udf00\ud835\udf00 1\u2212\ud835\udf00\ud835\udf00 \n20 \n CHAPTER 5 \nEXPERIMENTS  \nIn this work, each group of features described in the previous section  was used  in \ninput to a RandomForest classifier with 5 -fold cross validation to compute the performance \nof these features in classifying factual vs. misleading stories.  Results are reported in Table \n5.3 according to Area Under the ROC curve (AUROC), F1 - measure, and Average \nPrecision (or area under the precision -recall curve) and discussed in the following. The  \nclass weighting was used to deal with class imbalance.  The exper iments also included \nclassification  using linear SVM classifier with L2 regularization (with 5 - fold cross \nvalidation) and the results are reported in Appendix. The  results from both the classifiers \nare compared and found that RandomForest classifier performed better with these features.  \n5.1 News Body Content \nThe first modality  analyze d is the news body content. Here, tf-idf features  achieves \nthe best results (0.8 88 AUROC, 0. 811 F1-measure and 0.781 average precision). Next, the \nLIWC features is  the second- best group of features. Among them, the psycho- linguistic \nfeatures are the most important groups of features, achieving comparable performances.  \nAfter LIWC, the readability features do not seem to separate well misleading news from \nfactual ones  in this dataset. The  misleading news have higher frequencies of psychology \nrelated words such as personal concerns (death), relativity (motion), social (family and affiliation), and biological processes. The language used has more tentative words evoking uncertainty, more informal and more swear words. In contrast, factual news is harder to understand (higher Flesh Kincaid and Gunning Fog values), have higher risk related words, \n21 \n less anger, and more sad words. There are more parentheses in factual news which were \nused to indicate additional content providing more evidence of the news.  \n5.2 News Headline \nAmong all the features considered to analyze the news headline, it is shown  that all \nthe LIWC features combined is  performing the best according to all the measures (e.g., \nAUROC of 0.7 91) and after that tf -idf with AUROC of 0.733 works better.  Regarding \npunctuations, misleading headlines have more occurrences of the dot, exclamation mark, and semi -column (which may indicate they are packing many sentences in  the news title). \nAccording to readability level, factual headlines are more complex to understand and show a higher Flesch -Kincaid score compared to misleading ones which have more tentative \nwords evoking uncertainty, more informal, and more swear words as seen in the news body content. Overall, the analysis shows that factual political news headlines are more \nprofessionally written compared to misleading one.  \n5.3 News Source Bias  \nThe news source bias is a strong predictor for news credibility as it achieves an \nAUROC of 0. 884, 0.917 of average precision  and F1 -measure of 0. 854. This result further \nconfirms the correlation between source bias and the credibility of the news it distributes. It is worth noting that the publisher information is independent on the news labels as the former is collected from MediaBias/FactCheck, while the latter from Buzzfeed and Politifact.  \n5.4 News Image \nThe image associated with the news were used  to determine the news validity and  \nfound that the tf -idf features of image capt ion from NeuralTalk2 performs better and is \n22 \n comparable to news headline (0.743 of F1- measure, AUROC of 0.600, and average \nprecision is 0.725) . Through a manual analysis of the images included in our datasets (see \nFigure 3 for examples), trends in the image s used in misleading news and real news became \napparent. One such trend was that real news articles included significantly more images \nfocused on a figure speaking whereas the misleading news articles contained more images of people with only expressions on their faces. Further, the images in real news portrayed more positive impressions than misleading news. A final note from the manual inspection of our datasets was that the misleading news images were more likely to have been photoshopped by placing two images together and such images were of lower quality than the images from the real news datasets.  \n \n \nPic\nture 1: Examples of images associated with misleading (top) and factual (bottom) \nnews.  \n \n5.5 News Social Network  \nThe social network features were used to compute a credibility score for each news \nbased on how users in the social network are sharing the news. In order to obtain the useful \n23 \n features from the social network, t he prior probability for the news was set as 50% credible \nand 50% not credible because of the lack of prior knowledge about the news. \n \n \nFi\ngure 3. In- degree & Out -degree and percentage of users\u2019 distribution  \n \nThe prior probability for each user was derived based on in- degree, out -degree, and \ncombining both degrees. The indegree and outdegree against the percentage of users in \neach category was plotted. We plotted with all the users and also with users who spread news more than 6, 7, 8, 9, and 10 and the threshold to get the prior probability for each user was set based on those histogram plots.  The Figure 3 shows the indegree, outdegree and percentage of users\u2019 distribution with the users who spread news greater or more than 8. We tried two different prior probabilities for publis hers in our experiments, one with \nderived from source bias and another with default prior as 50%  for both being credible and \nnot credible.  \nThe next step is  to use sparse- matrix belief propagation [ 48], a modified form of \nloopy belief propagation that encodes the structure of a graph with sparse matrices to infer \n24 \n the credibility score for each node. In this  case, the focus is on pairwise markov random \nfields that approximates the posterior marginals of each node. The  different possibilities \nwere tried and tested such as combining bias and in- degree, out -degree, both the degree, \netc., by changing their prior probabilities to compute the credibility score using loopy belief \npropagation. The experiments were also conducted with all the users and  also with users \nwho spread the total news count greater than 6,7,8,9, and 10, to observe whether the users simply creating noise by just spreading only one or two news. The metrics used to compute \nthe credibility score was  AUROC and average precision and t he results for the user who \nshared more than 6 and 7 news are shown in Table 5.1 and 5.2 for BuzzFeed and PolitiFact \ndataset . From this experiment, it is evident that the credibility score for users with different \nnews count was almost same with minor dif ference,  and both indegree and outdegree \nfeatures are working for BuzzFeed dataset and indegree feature gives better results for Politifact. The credibility score improves when we use publisher bias , but to combine with \nother modalities we used the credibi lity score with the combination of total news greater \nthan 8 and both the degree  for Buzzfeed  that gives better results (0. 722 average precision, \n0.636 AUROC) , and indegree for Politifact ( 0.513  average precision, 0. 560 AUROC)  to \navoid redundancy. O verall with all the modalities the results achieved are  0.880 AUROC, \n0.858 F1-measure, 0. 779 average -precision, that shows that exploiting social network  \nfeatures will definitely improves in detecting misleading news. T he credibility score is also \ncomputed with 50% default  prior probability for all the three nodes  as shown in the table. \n Table 5.1 Credibility Score for features with total news count spread by the user \ngreater than 6 and 7 (BuzzFeed).  \nFeatures  AUROC > 8 Avg.Precision > 8 AUROC > 9 \nAvg.Precision > 9 \n25 \n Indegree 0.584 0.604 0.603 0.638 \nOutdegree 0.415 0.503 0.397 0.493 \nBoth degree 0.636 0.722 0.648 0.738 \nAll Default  0.500 0.506 0.500 0.506 \n \nTable 5.2 Credibility Score for features with total news count spread by the user \ngreater than 6 and 7 (PolitiFact).  \nFeatures  AUROC > 8 Avg.Precision > 8 AUROC > 9 Avg.Precision > 9 \nIndegree 0.560 0.513 0.558 0.511 \nOutdegree 0.441 0.446 0.442 0.448 \nBoth degree 0.440 0.446 0.441 0.448 \nAll Default  0.500 0.500 0.500 0.500 \n \n \n      \nTable 5.3: RandomForest Classification results with multi- modal features.  \nFeatures  F1 AUROC  Avg.Precision \nNews Content     \nTF-IDF 0.811 0.888 0.781 \nReadability  0.642 0.682 0.629 \n26 \n Punctuation (LIWC)  0.704 0.766 0.636 \nLinguistic (LIWC)  0.719 0.787 0.650 \nPsychological (LIWC)  0.711 0.799 0.646 \nSummary (LIWC)  0.673 0.725 0.604 \nAll LIWC  0.761 0.836 0.691 \nAll News Content  0.848 0.874 0.771 \nNews Headline     \nTF-IDF 0.663 0.733 0.644 \nReadability  0.539 0.560 0.565 \nPunctuation (LIWC)  0.644 0.727 0.644 \nLinguistic (LIWC)  0.660 0.725 0.605 \nPsychological (LIWC)  0.635 0.676 0.574 \nSummary (LIWC)  0.657 0.705 0.600 \nAll LIWC  0.722 0.791 0.654 \nAll Headline  0.845 0.816 0.752 \nImage    \nNeuralTalk2  0.743 0.600 0.725 \nBias 0.854 0.884 0.917 \nSocial Network 0.738 0.627 0.731 \nAll 0.858 0.880 0.779 \n5.5 Do we need to \u201cRead\u201d? \nTo address this question, \u201cdo we need to look at the news body content?\u201d, we can \nrefer to Table 5.4. The headline, bias, image features,  and social features are combined to \nsee if it further improves misleading news detection. Results show that specific set of \nfeatures are effective for categorizing political news articles as factual or not. The feature \n27 \n bias plays a crucial part in detecting misleading news and the second most important \nfeature is news headlines. Conversely, Horne and Adali [11] showed that the news headline is more informative than the body content (78% vs. 71% of accuracy).  The results show \nthat instead of \u201creading\u201d the news article to figure out its validity, considering the metadata \nof news such as headline, bias, social network, and image can achieve comparable or even higher performances (0.90 AUROC vs. 0.88). Thus, looking at the news snippet by considering the headline characteristics, checking the publisher bias and headline keywords, and putting more attention on the associated images provides efficient tools for detecting misleading news. If these signals can be thought to humans, we can hopefully prevent people f rom massively spreading non-factual news through online social media.  \n    \n \n   \nTable 5.4:  F1 -measure, AUROC, and average precision results with  combination of \nbias, headline, image, and social features. \nFeatures  F1 AUROC  Avg.Precision \nHeadline + Content + Bias + Image + \nSocial  0.858 0.880 0.779 \nHeadline + Bias + Image + Social  0.865 0.901 0.786 \nHeadline + Content + Bias + Image 0.860 0.879 0.777 \n28 \n Headline + Content + Bias + Social  0.854 0.874 0.772 \nHeadline + Content + Image + Social  0.854 0.826 0.766 \nContent + Bias + Image + Social  0.864 0.898 0.785 \nHeadline + Bias + Image 0.858 0.895 0.778 \nHeadline + Image + Social  0.852 0.828 0.757 \nHeadline + Bias + Social  0.867 0.896 0.790 \nBias + Image + Social  0.871 0.879 0.846 \n \n \n29 \n CHAPTER 6  \nCONCLUSIONS  AND FUTURE WORK  \nIn this project,  the relative importance of different news modalities (body, headline, \nsource bias, visual content , social network) were analyzed in detecting misleading political \nnews. In particular, the source bias has never been analyzed before, and our findings \ndemonstrate a strong correlation between political bias and news credibility. Moreover, it is proved that it is not necessary to analyze the news body to assess its validity (which may \nbe time -consuming for the users), but comparable results can be achieved by looking at \nalternative modalities including headline features, source bias, and visual content.  \nOne of the main limitations is for sure the size of the dataset considered, but there \nare no other currently availab le datasets containing all the information about the four \nconsidered modalities. Thus, collect ing a bigger dataset will be helpful to  refine our \nanalysis as future work. Moreover, by extract ing the sentiment from the news images one \ncan achieve better perf ormance in analyzing misleading news, as the manual inspection of \nthe images in the dataset showed that images associated with misleading news are more emotional than the ones of factual news. Also, we would like to test the cross -domain \nefficiency of alternative news modalities as this has only been investigated for news body content so far [18].  From the social network, we analyzed by estimating the user credibility \nand network -based features such as diffusion network. It would be helpful to achieve better \nresults if we analyze user -based features such as user profiles, user opinions and also post -\nbased features represent users\u2019 social response in term of stance, topics, or credibility etc.  \nMoreover, it\u2019s worth to explore effective features and models for early fake news detection, \nas fake news usually evolves very fast on social media.  \n30 \n REFERENCES \n[1] [n.d.].MediaBias/Fa ctCheckApps/Extensions. https://mediabiasfactcheck.com/ \nappsextensions/  \n[2] Pen America. 2018. Faking News: Fraudulent News and the Fight for Truth. \nhttps://pen.org/faking-  news/  \n[3] 2016 Gallup poll - http://news.gallup.com/poll/195542/americans -trust-mass-media -\nsinks -new-low.aspx \n[4] http://snap.stanford.edu/index.html  \n[5] https://www.factcheck.org/2016/11/how -to-spot-fake-news/.  \n[6] Vandalism in Wikipedia. http://en.wikipedia.org/wiki/Wikipedia:Vandalism.  \n[7] Anu Shrestha, Francesca Spezzano, and Maria Soledad Pera. Who is really affected by \nfraudulent reviews? an analysis of shilling attacks on recommender systems in real -\nworld scenarios. In Late- Breaking Results track part of the Twelfth ACM \nConference on Recommender Systems (RecSys\u201918), 2018. \n[8] Arka itz Zubiaga, Elena Kochkina, Maria Liakata, Rob Procter, and Michal Lukasik. \nStance classification in rumours as a sequential task exploiting the tree structure of \nsocial media conversations. In COLING 2016, 26th Interna - tional Conference on \nComputational  Linguistics, Proceedings of the Conference: Technical Papers, \nDecember 11 -16, 2016, Osaka, Japan, pages 2438\u20132448, 2016. \n[9] Pew Research Survey -  http://www.journalism.org/2016/12/15/many- americans-\nbelieve- fake-news -is-sowing -confusion/  \n[10] Vosoughi, et  al. (2018). \"The spread of true and false news online.\" Science 359, no. \n6380 (2018): 1146- 1151.  \n[11] Shearer and Gottfried. 2017. News Use Across Social Media Platforms 2017.(2017). \n[12] Craig Silverman. 2016. This analysis shows how viral fake election news stories \noutperformed real news on Facebook. BuzzFeed News 16 (2016). \n31 \n [13] Maksym Gabielkov, Arthi Ramachandran, Augustin Chaintreau, and Arnaud Legout. \n2016. Social clicks: What and who gets read on Twitter? ACM SIGMET - RICS \nPerformance Evaluation Review 44, 1 (2016), 179\u2013192. \n[14] Joseph Kahne and Benjamin Bowyer.2017.Educating for democracy in a partisan age: \nConfronting the challenges of motivated reasoning and misinformation. American \nEducational Research Journal 54, 1 (2017), 3\u201334. \n \n[15] Paul Resnick,R Kelly Garrett,Travis Kriplean,Sean A Munson, and Natalie Jomini \nStroud. 2013. Bursting your (filter) bubble: strategies for promoting diverse \nexposure. In Proceedings of the 2013 conference on Computer supported cooperative work companion. ACM, 95\u2013100. \n \n[16] Ver \u00f3nica P \u00e9rez-Rosas,Bennett Kleinberg,Alexandra Lefevre,and Rada Mihalcea. \n2018. Automatic Detection of Fake News. In Proceedings of the 27th International \nConference on Computational Linguistics. 3391\u20133401. \n \n[17] Srijan Kumar and Neil Shah. 2018. False information on web and social media: A \nsurvey. arXiv preprint arXiv:1804.08559 (2018). \n  [18] Manish Gupta,Peixiang Zhao, and Jiawei Han.2012.Evaluating event credibility on \ntwitter. In Proceedings of the 2012 SIAM International Conference on Data \nMining. SIAM, 153\u2013164. \n \n[19] Zhiwei Jin, Juan Cao, Han Guo, Yongdong Zhang, and Jiebo Luo.2017.Multimodal \nfusion with recurrent neural networks for rumor detection on microblogs. In \nProceedings of the 2017 ACM on Multimedia Conference. ACM, 795\u2013816. \n \n32 \n [20] Seyedmehdi Hosseinimotlagh and Evangelos E. Papalexakis. Unsupervised content-\nbased identification of fake news articles with tensor decomposition en - sembles. \nIn MIS2: Misinformation and Misbehavior Mining on the Web Workshop held in \nconjunction with WSDM 2018 Feb 9, 2018 - Los Angeles, California, USA, 2018, 2018. \n \n[21] Benjamin D Horne and Sibel Adali. 2017. This just in: fake news packs a lot in title, \nuses simpler, repetitive content in text body, more similar to satire than real news. \narXiv preprint arXiv:1703.09398 (2017). \n \n[22] Hunt Allcott and Matthew Gentzkow. Social media and fake news in the 2016 \nelection. Journal of Economic Perspectives, 31(2):211\u201336, 2017. \n [23] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news \ndetection on social media: A data mining perspective. ACM SIGKDD \nExplorations Newsletter 19, 1 (2017), 22\u201336. \n \n[24] Potthast, et al. (2017). \"A Stylometric Inquiry into Hyperpartisan and Fake News.\" \narXiv preprint arXiv:1702.05638 (2017). \n [25] Dongping Ti an et al.2013. A review on image feature extraction and representation \ntechniques. International Journal of Multimedia and Ubiquitous Engineering 8, 4 \n(2013), 385\u2013396. \n \n[26] Sander Van der Linden, Anthony Leiserowitz, Seth Rosenthal, and Edward \nMaibach. 2017. Inoculating the public against misinformation about climate \nchange. Global Challenges 1, 2 (2017), 1600008. \n33 \n  \n[27] Jooyeon Kim, Behzad Tabibian, Alice Oh, Bernhard Scholkopf, and Manuel \nGomez -Rodriguez. Leveraging the crowd to detect and reduce the spre ad of fake \nnews and misinformation. In Proceedings of the Eleventh ACM International \nConference on Web Search and Data Mining, WSDM 2018, Marina Del Rey, CA, USA, February 5-9, 2018, pages 324\u2013332. \n \n[28] Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. News verification by \nexploiting conflicting social viewpoints in microblogs. In Proceedings of the Thir- \ntieth AAAI Conference on Artificial Intelligence, February 12 -17, 2016, Phoenix, \nArizona, USA., pages 2972\u20132978, 2016. \n \n[29] Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu \nSu, and Jing Gao. 2018. EANN: Event Adversarial Neural Networks for Multi- \nModal Fake News Detection. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 849\u2013857. \n \n[30] MartinPotthast,JohannesKiesel,KevinReinartz,JanekBevendorff,andBenno Stein. \n2018. A Stylometric Inquiry into Hyperpartisan and Fake News. In Proceed- ings \nof the 56th Annual Meeting of the Association for Computational Linguistics, ACL 20 18, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers. \n231\u2013240. \n \n[31] Liang Wu and Huan Liu. Tracing fake- news footprints: Characterizing social media \nmessages by how they propagate. In Proceedings of the Eleventh ACM \nInternational Conference o n Web Search and Data Mining, WSDM 2018, Marina \nDel Rey, CA, USA, February 5- 9, 2018, pages 637\u2013645, 2018. \n34 \n  \n[32] Natali Ruchansky, Sungyong Seo, and Yan Liu. CSI: A hybrid deep model for fake \nnews detection. In Proceedings of the 2017 ACM on Conference on Information \nand Knowledge Management, CIKM 2017, Singapore, November 06 - 10, 2017, pages 797\u2013806, 2017. \n \n[33] Jin, et al. (2017). \"Novel visual and statistical image features for microblogs news \nverification.\" IEEE transactions on multimedia 19, no. 3 (2017): 598-608. \n [34] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C \nLawrence Zitnick, and Devi Parikh. 2015. Vqa: Visual question answering. In \nProceedings of the IEEE international conference on computer vision. 2425\u20132433. \n \n[35] KaiShu, Suhang Wang, and Huan Liu.2017. Exploiting Tri-Relationship for Fake \nNews Detection. arXiv preprint arXiv:1712.07709 (2017). \n [36] Kai Shu, Suhang Wang, and Huan Liu. Beyond news contents: The role of social \ncontext for fake news detectio n. In Proceedings of the Twelfth ACM International \nConference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, \nAustralia, February 11-15, 2019, pages 312\u2013320, 2019. \n \n[37] Knauf Nathan Fairbanks James, Fitch Natalie and Briscoe Erica. Credibility \nassessment in the news: Do we need to read? In MIS2: Misinformation and \nMisbehavior Mining on the Web Workshop held in conjunction with WSDM \n2018 Feb 9, 2018 - Los Angeles, California, USA, 2018, 2018. \n \n35 \n [38] Ankesh Anand, Tanmoy Chakraborty, and Noseong Park. We used neural networks \nto detect clickbaits: You won\u2019t believe what happened next! In Advances in \nInformation Retrieval - 39th European Conference on IR Research, ECIR 2017, Aberdeen, UK, April 8-13, 2017, Proceedings, pages 541\u2013547, 2017. \n \n[39] Martin  Potthast, Sebastian Ko \u0308psel, Benno Stein, and Matthias Hagen. Clickbait \ndetection. In Advances in Information Retrieval - 38th European Conference on \nIR Research, ECIR 2016, Padua, Italy, March 20-23, 2016. Proceedings, pages 810\u2013817, 2016. \n   \n[40] William Yang Wang.2017. \"Liar, Liar Pants on Fire\": A New Benchmark Dataset \nfor Fake News Detection. In Proceedings of the 55th Annual Meeting of the \nAssociation for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 2: Short Papers. 422\u2013426. \n \n[41] Abhijnan Chakraborty, Bhargavi Paranjape, Sourya Kakarla, and Niloy Ganguly. \nStop clickbait: Detecting and preventing clickbaits in online news media. In 2016 \nIEEE/ACM International Conference on Advances in Social Networks Analysis \nand Mining, ASONAM 2016, San Francisco, CA, USA, August 18- 21, 2016, \npages 9 \u201316, 2016. \n \n[42] Yimin Chen, Niall J. Conroy, and Victoria L. Rubin. Misleading online content: \nRecognizing clickbait as \u201dfalse news\u201d. In Proceedings of the 2015 ACM \nWorkshop on Multimodal Deception Detection, WMDD@ICMI 2015, Seattle, Washington, USA, November 13, 2015, pages 15\u201319, 2015. \n \n36 \n [43] Symeon Papadopoulos Duc-Tien Dang- Nguyen Giulia Boato Michael Riegler \nYiannis Kompatsiaris et al. Christina Boididou, Katerina Andreadou. 2015. Veri - \nfying Multimedia Use at MediaEval 2015. In MediaEval. \n \n[44] James W Pennebaker, Ryan L Boyd, Kayla Jordan, and Kate Blackburn. 2015. The \ndevelopment and psychometric properties of LIWC2015. Technical Report. \n [45] Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. 2017. Show \nand Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge. \nIEEE Trans. Pattern Anal. Mach. Intell. 39, 4 (2017), 652\u2013663. \n \n[46] https://techcrunch.com/2018/03/08/false- news -spreads -faster -than-truth -online-\nthanks- to-human -nature/ \n [47] Tanushree Mitra and Eric Gilbert. 2015. CREDBANK: A Large- Scale Social Media \nCorpus With Associated Credibility Annotations. In Proceedings of the Ninth \nInternational Conference on Web and Social Media, ICWSM 2015, University of Oxford, Oxford, UK, May 26-29, 2015. 258\u2013267. \n \n[48] Bixler, Reid Morris. \"Sparse matrix belief propagation.\" PhD diss., Virginia Tech, \n2018. \n \n[49] Chau, et al. (2011). \"Poloni um: Tera -scale graph mining and inference for malware \ndetection.\" In Proceedings of the 2011 SIAM International Conference on Data Mining, pp. 131-142. Society for Industrial and Applied Mathematics, 2011.  \n37 \n [50] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. Detecting spammers \non social networks. In ACSAC, pages 1\u20139, 2010.  \n[51] Srijan Kumar, Robert West, and Jure Leskovec. Disinformation on the web: Impact, \ncharacteristics, and detection of wikipedia hoaxes. In Proceedings of the 25th \nIntern ational Conference on World Wide Web, WWW 2016, Montreal, Canada, \nApril 11 - 15, 2016, pages 591\u2013602, 2016.   \n \n38 \n APPENDIX A  \nTitle of Appendix A  \nTable A.1  Linear SVM Classifier results with multi -modal features  \nFeatures  F1 AUROC  Avg.Precision \nNews Content     \nTF-IDF 0.818 0.875 0.791 \nReadability  0.585 0.639 0.596 \nPunctuation (LIWC)  0.671 0.708 0.606 \nLinguistic (LIWC)  0.684 0.729 0.620 \nPsychological (LIWC)  0.695 0.735 0.632 \nSummary (LIWC)  0.637 0.678 0.581 \nAll LIWC  0.729 0.780 0.667 \nAll News Content  0.812 0.773 0.794 \nNews Headline     \nTF-IDF 0.672 0.730 0.654 \nReadability  0.573 0.593 0.591 \nPunctuation (LIWC)  0.640 0.742 0.653 \nLinguistic (LIWC)  0.608 0.640 0.568 \nPsychological (LIWC)  0.607 0.628 0.573 \nSummary (LIWC)  0.551 0.555 0.529 \nAll LIWC  0.675 0.720 0.626 \nAll Headline 0.785 0.704 0.772 \nImage     \nNeuralTalk2  0.721 0.670 0.761 \nBias 0.843 0.878 0.890 \n39 \n Social Network 0.444 0.538 0.690 \nAll 0.814 0.797 0.802 \n \nTable A.2:  F1- measure, AUROC, and average precision results with the \ncombination of bias, headline, image, and social features.   \nFeatures  F1 AUROC  Avg.Precision \nHeadline + Content + Bias + Image + \nSocial  0.814 0.797 0.802 \nHeadline + Bias + Image + Social  0.817 0.809 0.796 \nHeadline + Content + Bias + Image 0.824 0.803 0.805 \nHeadline + Content + Bias + Social  0.814 0.802 0.802 \nHeadline + Content + Image + Social  0.789 0.749 0.788 \nContent + Bias + Image + Social  0.833 0.826 0.821 \nHeadline + Bias + Image 0.846 0.825 0.827 \nHeadline + Image + Social  0.780 0.720 0.815 \nHeadline + Bias + Social  0.835 0.821 0.814 \nBias + Image + Social  0.835 0.873 0.876 \n40 \n  ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A Hybrid Model to Detect Fake News", "author": ["I Gurunathan"], "pub_year": "2019", "venue": "NA", "abstract": "The wide availability of user-contributed content in the online social media facilitates  aggregation of people around common interests, worldviews, and narratives. But over the years,"}, "filled": false, "gsrank": 96, "pub_url": "https://scholarworks.boisestate.edu/cs_gradproj/17/", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:kc4pOCE337MJ:scholar.google.com/&output=cite&scirp=95&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D90%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=kc4pOCE337MJ&ei=FbWsaISmDuHUieoP9LKZ6AI&json=", "num_citations": 2, "citedby_url": "/scholar?cites=12961138868411289233&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:kc4pOCE337MJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://scholarworks.boisestate.edu/cgi/viewcontent.cgi?article=1016&context=cs_gradproj"}}, {"title": "Protecting the Web from Misinformation", "year": "2020", "pdf_data": "Lecture Notes in Social Networks\nMohammad/uni00A0A./uni00A0Tayebi\nUwe/uni00A0Gl\u00e4sser\nDavid/uni00A0B./uni00A0Skillicorn/uni00A0   Editors\nOpen Source \nIntelligence \nand Cyber \nCrime\nSocial Media Analytics\nLecture Notes in Social Networks\nSeries editors\nReda Alhajj, University of Calgary, Calgary, AB, Canada\nUwe Gl\u00e4sser, Simon Fraser University, Burnaby, BC, CanadaHuan Liu, Arizona State University, Tempe, AZ, USA\nRafael Wittek, University of Groningen, Groningen, The Netherlands\nDaniel Zeng, University of Arizona, Tucson, AZ, USA\nAdvisory Board\nCharu C. Aggarwal, Yorktown Heights, NY , USA\nPatricia L. Brantingham, Simon Fraser University, Burnaby, BC, CanadaThilo Gross, University of Bristol, Bristol, UK\nJiawei Han, University of Illinois at Urbana-Champaign, Urbana, IL, USA\nRa\u00fal Man\u00e1sevich, University of Chile, Santiago, Chile\nAnthony J. Masys, University of Leicester, Ottawa, ON, Canada\nCarlo Morselli, School of Criminology, Montreal, QC, Canada\nLecture Notes in Social Networks (LNSN) comprises volumes covering the the-\nory, foundations and applications of the new emerging multidisciplinary \ufb01eld\nof social networks analysis and mining. LNSN publishes peer-reviewed works(including monographs, edited works) in the analytical, technical as well as the\norganizational side of social computing, social networks, network sciences, graph\ntheory, sociology, Semantics Web, Web applications and analytics, informationnetworks, theoretical physics, modeling, security, crisis and risk management, and\nother related disciplines. The volumes are guest-edited by experts in a speci\ufb01c\ndomain. This series is indexed by DBLP. Springer and the Series Editors wel-come book ideas from authors. Potential authors who wish to submit a book\nproposal should contact Christoph Baumann, Publishing Editor, Springer e-mail:\nChristoph.Baumann@springer.com\nMore information about this series at http://www.springer.com/series/8768\nMohammad A. Tayebi \u0081 Uwe Gl\u00e4sser\nDavid B. Skillicorn\nEditors\nOpen Source Intelligence\nand Cyber Crime\nSocial Media Analytics\nEditors\nMohammad A. Tayebi\nSchool of Computing ScienceSimon Fraser UniversityBurnaby, BC, CanadaUwe Gl\u00e4sser\nSchool of Computing ScienceSimon Fraser UniversityBurnaby, BC, Canada\nDavid B. Skillicorn\nSchool of ComputingQueen\u2019s University\nKingston, ON, Canada\nISSN 2190-5428 ISSN 2190-5436 (electronic)\nLecture Notes in Social NetworksISBN 978-3-030-41250-0 ISBN 978-3-030-41251-7 (eBook)https://doi.org/10.1007/978-3-030-41251-7\n\u00a9 Springer Nature Switzerland AG 2020\nChapter \u201cAutomated Text Analysis for Intelligence Purposes: A Psychological Operations Case Study\u201d\nis licensed under the terms of the Creative Commons Attribution 4.0 International License ( http://\ncreativecommons.org/licenses/by/4.0/ ). For further details see license information in the chapter.\nThis work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of\nthe material is concerned, speci\ufb01cally the rights of translation, reprinting, reuse of illustrations, recitation,\nbroadcasting, reproduction on micro\ufb01lms or in any other physical way, and transmission or informationstorage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodologynow known or hereafter developed.\nThe use of general descriptive names, registered names, trademarks, service marks, etc. in this publication\ndoes not imply, even in the absence of a speci\ufb01c statement, that such names are exempt from the relevantprotective laws and regulations and therefore free for general use.The publisher, the authors, and the editors are safe to assume that the advice and information in this book\nare believed to be true and accurate at the date of publication. Neither the publisher nor the authors or\nthe editors give a warranty, expressed or implied, with respect to the material contained herein or for anyerrors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional\nclaims in published maps and institutional af\ufb01liations.\nThis Springer imprint is published by the registered company Springer Nature Switzerland AG\nThe registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland\nContents\nProtecting the Web from Misinformation ..................................... 1\nFrancesca Spezzano and Indhumathi Gurunathan\nStudying the Weaponization of Social Media: Case Studies\nof Anti-NATO Disinformation Campaigns .................................... 29\nKatrin Galeano, Rick Galeano, Samer Al-Khateeb, and Nitin Agarwal\nYou Are Known by Your Friends: Leveraging Network Metrics for\nBot Detection in Twitter ......................................................... 53\nDavid M. Beskow and Kathleen M. Carley\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces\non the Public Web ................................................................ 89\nRichard Frank and Alexander Mikhaylov\nInferring Systemic Nets with Applications to Islamist Forums ............. 113\nDavid B. Skillicorn and N. Alsadhan\nTwitter Bots and the Swedish Election ......................................... 141\nJohan Fernquist, Lisa Kaati, Ralph Schroeder, Nazar Akrami,\nand Katie Cohen\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation ........... 165\nEric Nunes, Casey Buto, Paulo Shakarian, Christian Lebiere,\nStefano Bennati, and Robert Thomson\nSocial Media for Mental Health: Data, Methods, and Findings ............ 195\nNur Shazwani Kamarudin, Ghazaleh Beigi, Lydia Manikonda,\nand Huan Liu\nAutomated Text Analysis for Intelligence Purposes: A Psychological\nOperations Case Study .......................................................... 221\nStefan Varga, Joel Brynielsson, Andreas Horndahl, and Magnus Rosell\nv\nProtecting the Web from Misinformation\nFrancesca Spezzano and Indhumathi Gurunathan\nAbstract Nowadays, a huge part of the information present on the Web is delivered\nthrough Social Media and User-Generated Content (UGC) platforms, such as Quora,\nWikipedia, YouTube, Yelp, Slashdot.org, Stack Over\ufb02ow, Amazon product reviews,\nand much more. Here, many users create, manipulate, and consume content every\nday. Thanks to the mechanism by which anyone can edit these platforms, its content\ngrows and is kept constantly updated. However, malicious users can take advantage\nof this open editing mechanism to introduce misinformation on the Web.\nIn this chapter, we focus on Wikipedia, one of the main UCC platform and source\nof information for many, and study the problem of protecting Wikipedia articles\nfrom misinformation such as vandalism, libel, spam, etc. We address the problem\nfrom two perspectives: detecting malicious users to block such as spammers or\nvandals and detecting articles to protect, i.e., placing restrictions on the type of users\nthat can edit an article. Our solution does not look at the content of the edits but\nleverages the users\u2019 editing behavior so that it generally results applicable to many\nlanguages. Our experimental results show that we are able to classify (1) article\npages to protect with an accuracy greater than 92% across multiple languages and\n(2) spammers from benign users with 80.8% of accuracy and 0.88 mean average\nprecision.\nThe chapter also de\ufb01nes different types of misinformation that exist on the\nWeb and provides a survey of the methods proposed in the literature to prevent\nmisinformation on Wikipedia and other platforms.\n1 Introduction\nNowadays, a huge part of the information present on the Web is delivered through\nSocial Media such as Twitter, Facebook, Instagram, etc., and User-Generated\nContent (UGC) platforms, such as Quora, Wikipedia, YouTube, Yelp, Slashdot.org,\nF. Spezzano (/envelopeback) \u00b7 I. Gurunathan\nComputer Science Department, Boise State University, Boise, ID, USA\ne-mail: francescaspezzano@boisestate.edu ;indhumathigurunathan@u.boisestate.edu\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_11\n2 F. Spezzano and I. Gurunathan\nStack Over\ufb02ow, Amazon product reviews, and many others. Here, users create,\nmanipulate, and consume content every day. Thanks to the mechanism by which\nanyone can edit these platforms, its content grows and is kept constantly updated.\nUnfortunately, Web features that allow for such openness have also made\nit increasingly easy to abuse this trust, and as people are generally awash in\ninformation, they can sometimes have dif\ufb01culty discerning fake stories or imagesfrom truthful information. They may also lean too heavily on information providers\nor social media platforms such as Facebook to mediate even though such providers\ndo not commonly validate sources. For example, most high school teens usingFacebook do not validate news on this platform. The Web is open to anyone, and\nmalicious users shielded by their anonymity threaten the safety, trustworthiness,\nand usefulness of the Web; numerous malicious actors potentially put other usersat risk as they intentionally attempt to distort information, manipulate opinions and\npublic response. Even worse, people can get paid to create fake news and spam\nreviews, in\ufb02uential bots can easily create it, and misinformation spreads so fast thatis too hard to control. Impacts are already destabilizing the U.S. electoral system and\naffecting civil discourse, perception, and actions since what people read on the Web\nand events they think happened may be incorrect, and people may feel uncertainabout their ability to trust it.\nMisinformation can manifest in multiple forms such as vandalism, spam, rumors,\nhoaxes, fake news, clickbaits, fake product reviews, etc. In this chapter, we startby de\ufb01ning misinformation and describing different forms of misinformation that\nexist nowadays on the Web. Next, we focus on how to protect the Web from\nmisinformation and provide a survey of the methods proposed in the literature todetect misinformation on social media and user-generated contributed platforms.\nFinally, we focus on Wikipedia, one of the main UGC platform and source of\ninformation for many, and study the problem of protecting Wikipedia articles frommisinformation such as vandalism, libel, spam, etc. We address the problem from\ntwo perspectives: detecting malicious users to block such as spammers or vandals\nand detecting articles to protect, i.e., placing restrictions on the type of users that canedit an article. Our solution does not look at the content of the edits but leverages the\nusers\u2019 editing behavior so that it generally results applicable to many languages. Our\nexperimental results show that we are able to classify (1) article pages to protect withan accuracy greater than 92% across multiple languages and (2) spammers from\nbenign users with 80.8% of accuracy and 0.88 mean average precision. Moreover,\nwe discuss one of the main side effects of deploying anti-vandalism tools onWikipedia, i.e. a low rate of newcomers retention, and an algorithm we proposed\nto early detect whether or not a user will become inactive and leave the community\nso that recovery actions can be performed on time to try to keep them contributinglonger.\nThis chapter differs from the one by Wu et al. [ 1] because we focus more on the\nWikipedia case study and how to protect this platform from misinformation, whileWu et al. mainly deal with rumors and fake news identi\ufb01cation and intervention.\nOther related surveys are the one by Shu et al. [ 2] that focuses speci\ufb01cally on fake\nProtecting the Web from Misinformation 3\nnews, the work by Zubiaga [ 3] that deals with rumors, and the survey by Kumar and\nShah [ 4] on fake news, fraudulent reviews, and hoaxes.\n2 Misinformation on the Web\nAccording to the Oxford dictionary, misinformation is \u201cfalse or inaccurate infor-\nmation, especially that which is deliberately intended to deceive\u201d. These days, themassive growth of the Web and social media has provided fertile ground to consume\nand quickly spread the misinformation without fact-checking. Misinformation can\nassume many different forms such as vandalism, spam, rumors, hoaxes, counterfeit\nwebsites, fake product reviews, fake news, etc.\nSocial media and user-generated content platforms like Wikipedia and Q&A\nwebsites are more likely affected by vandalism, spam, and abuse of the content.Vandalism is the action involving deliberate damage to others property, and\nWikipedia de\ufb01nes vandalism on its platform as \u201cthe act of editing the project in\na malicious manner that is intentionally disruptive\u201d [ 5]. Beyond Wikipedia, other\nuser-generated content platforms on the Internet got affected by vandalism. For\nexample, editing/down-voting other users content in Q&A websites like Quora,\nStack Over\ufb02ow, Slashdot.org, etc. Vandalism can also happen on social media suchas Facebook. For instance, the Martin Luther King, Jr.\u2019s fan page was vandalized in\nJan 2011 with racist images and messages.\nSpam is, instead, a forced message or irrelevant content sent to a user who would\nnot choose to receive it. For example, sending email to a bulk of users, \ufb02ooding the\nwebsites with commercial ads, adding external link to the articles for promoting\npurposes, improper citations/references, spreading links created with the intentto harm, mislead or damage a user or stealing personal information, likejacking\n(tricking users to post a Facebook status update for a certain site without the user\u2019s\nprior knowledge or intent), etc.\nWikipedia, like most forms of online social media, receives continuous spam-\nming attempts every day. Since the majority of the pages are open for editing by any\nuser, it inevitably happens that malicious users have the opportunity to post spammessages into any open page. These messages remain on the page until they are\ndiscovered and removed by another user. Speci\ufb01cally, Wikipedia recognizes three\nmain types of spam, namely \u201cadvertisements masquerading as articles, external linkspamming, and adding references with the aim of promoting the author or the work\nbeing referenced\u201d [ 6].\nUser-generated content platforms de\ufb01ne policies and methods to report vandal-\nism, and spam and the moderation team took necessary steps like warning the\nuser, blocking the user from editing, collapse the content if it is misinformation,\nblock the question from visible to other users, or ban the user from writing/editinganswers, etc. These sites are organized and maintained by the users and built as\na community. So the users have responsibilities to avoid vandalism and make it\nas a knowledgeable resource to others. For example, the Wikipedia community\n4 F. Spezzano and I. Gurunathan\nadopts several mechanisms to prevent damage or disruption to the encyclopedia\nby malicious users and ensure content quality. These include administrators to ban\nor block users or IP addresses from editing any Wikipedia page either for a \ufb01niteamount of time or inde\ufb01nitely, protecting pages from editing, or detecting damaging\ncontent to be reverted through dedicated bots [ 7,8], monitoring recent changes, or\nhaving watch-lists.\nSlashdot gives moderator access to its users to do jury duty by reading comments\nand \ufb02ag it with appropriate tags like Offtopic, Flamebait, Troll, Redundant, etc.\nSlashdot editors also act as moderators to downvote abusive comments. In additionto that, there is an \u201cAnti\u201d symbol present for each comment to report spam, racist\nranting comments, etc. Malicious users can also act protected by anonymity. In\nQuora, if an anonymous user vandalizes the content, then a warning message issent to that user\u2019s inbox without revealing the identity. If the particular anonymous\nuser keeps on abusing the content, then Quora moderator revokes the anonymity\nprivileges of that user.\nOnline reviews are not free from misinformation either. For instance, on Amazon\nor Yelp, it is frequent to have spam paid reviewers writing fraudulent reviews\n(or opinion spam) to promote or demote products or businesses. Online reviewshelp customers to make decisions on buying the products or services, but when the\nreviews are manipulated, it will impact both customers and business [ 9]. Fraudulent\nreviewers post either positive review to promote the business and receive somethingas compensation, or they write negative reviews and get paid by the competitors to\ncreate damage to the business. There are some online tools like fakespot.com\nandreviewmeta.com that analyze the reviews and helps to make decisions. But\nin general, consumers have to use some common sense to not fall for fraudulent\nreviews and do some analysis to differentiate the fake and real reviews. Simple steps\nlike verifying the pro\ufb01le picture of the reviewer, how many other reviews they wrote,paying attention to the details, checking the timestamp, etc., will help to identify\nfraudulent reviews.\nCompanies also take some actions against fraudulent reviews. Amazon sued over\n1000 people who posted fraudulent reviews for cash. It is also suspending the sellers\nand shut-downing their accounts if they buy fraudulent reviews for their products.\nThey rank the reviews and access the buyer database to mark the review as \u201cVeri\ufb01edPurchase\u201d meaning that the customer who wrote the review also purchased the\nitem at Amazon.com. Yelp has an automated \ufb01ltering software that is continuously\nrunning to examine each review recommend only useful and reliable reviews to itsconsumers. Yelp also leverages the crowd (consumer community) to \ufb02ag suspicious\nreviews and takes legal action against the users who are buying or selling reviews.\nFake news is low-quality news that is created to spread misinformation and\nmisleading readers. The consumption of news from social media is highly increased\nnowadays so as spreading of fake news. According to the Pew research center [ 10],\n64% of Americans believe that fake news causes confusion about the basic factsof current events. A recent study conducted on Twitter [ 11] revealed that fake\nnews spread signi\ufb01cantly more than real ones, in a deeper and faster manner and\nthat the users responsible for their spread had, on average, signi\ufb01cantly fewer\nProtecting the Web from Misinformation 5\nfollowers, followed signi\ufb01cantly fewer people, were signi\ufb01cantly less active on\nTwitter. Moreover, bots are equally responsible for spreading real and fake news, and\nthen the considerable spread of fake news on Twitter is caused by human activity.\nFact-checking the news is important before spreading it on the Web. There are a\nnumber of news verifying websites that can help consumers to identify fake news\nby making more warranted conclusions in a fraction of the time. Some examplesof fact-checkers are FactCheck.org ,PolitiFact.com ,snopes.com ,o r\nmediabiasfactcheck.com .\nBeyond fact-checking, consumers should also be responsible for [ 12]:\n1.Read more than the headline \u2014Often fake news headlines are sensational to\nprovoke readers emotions that help the spread of fake news when readers shareor post without reading the full story.\n2.Check the author \u2014The author page of the news website provides details about\nthe authors who wrote the news articles. The credibility of the author helps tomeasure the credibility of the news.\n3.Consider the source \u2014Before sharing the news on social media, one has to ensure\nthe source of the articles, verify the quotes that the author used in the article. Also,a fake news site often has strange URL\u2019s.\n4.Check the date \u2014Fake news sometimes provides links to previously happened\nincidents to the current events. So, one needs to check the date of the claim.\n5.Check the bias \u2014If the reader has opinion or beliefs to one party, then they tend to\nbelieve biased articles. According to a study done by Allcott and Gentzkow [ 13],\nthe right-biased articles are more likely to be considered as fake news.\nMoreover, one of the most promising approaches to combat fake news is promoting\nnews literacy . Policymakers, educators, librarians, and educational institutions\ncan all help in educating the public\u2014especially younger generations\u2014across allplatforms and mediums [ 14].\nClickbait is a form of link-spam leading to fake content (either news or image).\nIt is a link with a catchy headline that tempts users to click on the link, but it leads tothe content entirely unrelated to the headline or less important information. Clickbait\nworks by increasing the curiosity of the user to click the link or image. The purpose\nof a clickbait is to increase the page views which in turn increase the revenue throughad sense. But when it is used correctly, the publisher can get the readers attention, if\nnot the user might leave the page immediately. Publishers employ various cognitive\ntricks to make the readers click the links. They write headlines to grab the attentionof the readers by provoking their emotions like anger, anxiety, humor, excitement,\ninspiration, surprise. Another way is by increasing the curiosity of the readers by\npresenting them with something they know a little bit but not many details about thetopic. For example, headlines like \u201cYou won\u2019t believe what happens next?\u201d provoke\nthe curiosity of the readers and make them click.\nRumors are pieces of information whose veracity is unveri\ufb01able and spreads\nvery easily. Their source is unknown, so most of the time the rumors are destructive\nand misleading. Rumors start as something true and get exaggerated to the point that\nit is hard to prove. They are often associated with breaking news stories [ 15]. Kwon\n6 F. Spezzano and I. Gurunathan\net al. [ 16] report on many interesting \ufb01ndings on rumor spreading dynamics such\nas (1) a rumor \ufb02ows from low-degree users to high-degree users, (2) a rumor rarely\ninitiate a conversation and people use speculative words to express doubts abouttheir validity when discussing rumors, and that rumors do not necessarily contain\ndifferent sentiments than non-rumors. Friggeri et al. [ 17] analyzed the propagation\nof known rumors from Snopes.com in Facebook and their evolution over time.\nThey found that rumors run deeper in the social network than reshare cascades in\ngeneral and that when a comment refers to a rumor and contains a link to a Snopes\narticle, then the likelihood that a reshare of a rumor will be deleted increases. Unlikerumors, hoaxes consist of false information pretending to be true information and\noften intended as a joke. Kumar et al. [ 18] show that 90% of hoaxes articles in\nWikipedia are identi\ufb01ed in 1 h after their approval, while 1% of hoaxes survive forover 1 year.\nMisinformation is also spread through counterfeit websites that disguise as\nlegitimate sites. For instance, ABCnews.com.co andBloomberg.ma are exam-\nples of fake websites. They create more impact and cause severe damage when these\nsites happen to be subject speci\ufb01c to medical, business, etc.\nAlso, online videos can contain misinformation. For instance, Youtube videos\ncan have clickbaiting titles, spam in the description, inappropriate or not relevant\ntags to the videos, etc. [ 19]. This metadata is used to search and retrieve the video\nand misinformation in the title or the tags lead to increase the video\u2019s views and,consequently, the user\u2019 monetization. Sometimes online videos are entirely fake and\ncan be automatically generated via machine learning techniques [ 20]. As compared\nto recorded videos, computer-generated ones lack the imperfections, a feature that ishard to incorporate in a machine-learning based algorithm to detect fake videos [ 21].\n3 Detecting Misinformation on the Web\nTo protect the Web from misinformation, researchers focused on detecting mis-\nbehavior, i.e., malicious users such as vandals, spammers, fraudulent reviewers,\nrumors and fake news spreaders that are responsible for creating and sharingmisinformation, or detecting whether or not a given piece of information is false.\nIn the following, we survey the main methods proposed in the literature to detect\neither the piece of misinformation or the user causing it. Table 1summarizes all the\nrelated work grouped by misinformation type.\n3.1 Vandalism\nPlenty of work has been done on detecting vandalism, especially on Wikipedia.\nOne of the \ufb01rst works is the one by Potthast et al. [ 22] that uses feature extraction\n(including some linguistic features) and machine learning and validate them on\nProtecting the Web from Misinformation 7\nTable 1 Related work in\ndetecting misinformation bytypeTypes of misinformation Related work\nVandalism [22\u201330]\nSpam [31\u201344]\nFraudulent reviews [45\u201356]\nFake news [2,4,57\u201367]\nClickbaits [68\u201371]\nRumors [3,72\u201380]\nHoaxes [18,81]\nthe PAN-WVC-10 corpus: a set of 32K edits annotated by humans on Amazon\nMechanical Turk [ 23]. Adler et al. [ 24] combined and tested a variety of proposed\napproaches for vandalism detection including natural language, metadata [ 25], and\nreputation features [ 26]. Kiesel et al. [ 27] performed a spatiotemporal analysis of\nWikipedia vandalism revealing that vandalism strongly depends on time, country,\nculture, and language. Beyond Wikipedia, vandalism detection has also been\naddressed in other platforms such as Wikidata [ 28] (the Wikimedia knowledge base)\nand OpenStreetMaps [ 29].\nCurrently, ClueBot NG [ 7] and STiki [ 8] are the state-of-the-art tools used\nby Wikipedia to detect vandalism. ClueBot NG is a bot based on an arti\ufb01cialneural network which scores edits and reverts the worst-scoring edits. STiki is an\nintelligent routing tool which suggests potential vandalism to humans for de\ufb01nitive\nclassi\ufb01cation. It works by scoring edits by metadata and reverts and computinga reputation score for each user. Recently, Wikimedia Foundation launched a\nnew machine learning-based service, called Objective Revision Evaluation Service\n(ORES) [ 82] which measures the level of general damage each edit causes. More\nspeci\ufb01cally, given an edit, ORES provides three probabilities predicting (1) whether\nor not it causes damage, (2) if it was saved in good-faith, and (3) if the edit\nwill eventually be reverted. These scores are available through the ORES publicAPI [ 83].\nIn our previous work [ 30], we addressed the problem of vandalism in Wikipedia\nfrom a different perspective. We studied for the \ufb01rsttime the problem of detecting\nvandal users and proposed VEWS, an early warning system to detect vandals before\nother Wikipedia bots.\n1Our system leverages differences in the editing behavior of\nvandals vs. benign users and detect vandals with an accuracy of over 85% andoutperforms both ClueBot NG and STiki. Moreover, as an early warning system,\nVEWS detects, on average, vandals 2.39 edits before ClueBot NG. The combination\nof VEWS and Cluebot NG results in a fully automated system that does not leverageany human input (e.g., edit reversion) and further increases the performances.\nAnother mechanism used by Wikipedia to protect against content damage is page\nprotection , i.e., placing restrictions on the type of user that can edit the page. To the\nbest of our knowledge, little research has been done on the topic of page protection\n1Dataset and code are available at http://www.cs.umd.edu/~vs/vews/ .\n8 F. Spezzano and I. Gurunathan\nin Wikipedia. Hill and Shaw [ 84] studied the impact of page protection on user\npatterns of editing. They also created a dataset (they admit it may not be complete) of\nprotected pages to perform their analysis. There are not currently bots on Wikipediathat can search for pages that may need to be protected. Wikimedia does have a\nscript [ 85] available in which administrative users can protect a set of pages all at\nonce. However, this program requires that the user supply the pages or the categoryof pages to be protected and is only intended for protecting a large group of pages at\nonce. There are some bots on Wikipedia that can help with some of the wiki-work\nthat goes along with protecting or removing page protection. This includes addingor removing a template to a page that is marked as protected or no longer marked\nas protected. These bots can automatically update templates if page protection has\nexpired.\n3.2 Spam\nRegarding spam detection, various efforts have been made to detect spam users onsocial networks, mainly by studying their behavior after collecting their pro\ufb01lesthrough deployed social honeypots [ 31,32]. Generally, social networks proper-\nties [ 33,34], posts content [ 35,36], and sentiment analysis [ 37] have been used\nto train classi\ufb01ers for spam users detection.\nRegarding spam detection in posted content speci\ufb01cally, researchers mainly\nconcentrated on the problem of predicting whether a link contained in an edit\nis spam or not. URLs have been analyzed by using blacklists, extracting lexicalfeatures and redirecting patterns from them, considering metadata or the content of\nthe landing page, or examining the behavior of who is posting the URL and who is\nclicking on it [ 38\u201341]. Another big challenge is to recognize a short URL as spam\nor not [ 42].\nLink-spamming has also been studied in the context of Wikipedia. West et al. [ 43]\ncreated the \ufb01rst Wikipedia link-spam corpus, identi\ufb01ed Wikipedia\u2019s link spamvulnerabilities, and proposed mitigation strategies based on explicit edit approval,\nre\ufb01nement of account privileges, and detecting potential spam edits through a\nmachine learning framework. The latter strategy, described by the same authorsin [44], relies on features based on (1) article metadata and link/URL properties,\n(2) HTML landing site analysis, and (3) third-party services used to discern spam\nlanding sites. This tool was implemented as part of STiki (a tool suggesting potentialvandalism) and has been used on Wikipedia since 2011. Nowadays, this STiki\ncomponent is inactive due to a monetary cost for third-party services.\n3.3 Rumors and Hoaxes\nThe majority of the work focused on studying rumors and hoaxes characteristics,and very little work has been done on automatic classi\ufb01cation [ 3,72,73]. Qazvinian\nProtecting the Web from Misinformation 9\net al. [ 74] addressed the problem of rumor detection in Twitter via temporal, content-\nbased and network-based features and additional features extracted from hashtags\nand URLs present in the tweet. These features are also effective in identifyingdisinformers, e.g., users who endorse a rumor and further help it to spread. Zubiaga\net al. [ 75] identify whether or not a tweet is a rumor by using the context of\nfrom earlier posts associated with a particular event. Wu et al. [ 76] focused on\nearly detection of emerging rumors by exploiting knowledge learned from historical\ndata. More work has been done for rumor or meme source identi\ufb01cation in social\nnetworks by de\ufb01ning ad-hoc centrality measures, e.g., rumor centrality, and studyrumor propagation via diffusion models, e.g., the SIR model [ 77\u201380].\nKumar et al. [ 18] proposed an approach to detect hoaxes according to article\nstructure and content, hyperlink network properties, and hoaxes\u2019 creator reputation.Tacchini et al. [ 81] proposed a technique to classify Facebook posts as hoaxes or\nnon-hoaxes on the basis of the users who \u201cliked\u201d them.\n3.4 Fraudulent Reviews\nA Fraudulent review (or deceptive opinion spam) is a review with \ufb01ctitious opinionswhich are deliberately written to sound authentic. There are many characteristics\nthat are often hallmarks of fraudulent reviews:\n1.There is no information about the reviewer. Users who only post a small number\nof reviews or have no pro\ufb01le information or social connections are more likelyto be \ufb01bbing.\n2.The opinions are all-or-nothing. Fabricated reviews tend to be more extreme (all\n5 stars or all one star).\n3.Several are posted at once. Suddenly a product or company with no reviews or\none every few months will have \ufb01ve in a row all mentioning something similar,\nfrom the same day which indicates that a company paid for a batch of reviews.\n4.They use smaller words. Scientists say it takes more brainpower to tell a lie\nthan a truth; when we\u2019re telling a lie, our vocabulary tends to suffer because\nwe\u2019re already expending mental energy on the fabrication. As a result, fraudulentreviews are characterized by shorter words according to research.\n5.They are very short. Since fraudulent review mills may only pay a few dollars (or\nless) per review, there\u2019s an incentive for a writer to dash them off quickly.\nJindal and Liu [ 45] \ufb01rst studied deceptive opinion spam problem and trained\nmachine learning-based models using features based on the opinion content, user,\nand the product itself. Ott et al. [ 46] created a benchmark dataset by collecting\nreal reviews from TripAdvisor and employing Amazon Mechanical Turk workers\nto write fraudulent reviews. They got 90% accuracy in detecting fraudulent reviews\non their dataset by using psycholinguistic-based features and text-based features(bigrams). However, Mukherjee et al. [ 47] found out that the method proposed by\nOtt et al. is not enough to have good performances on a larger and more realistic\n10 F. Spezzano and I. Gurunathan\ndataset extracted from Yelp, but behavioral features on the user who wrote the\nreview performed very well (86% accuracy). They also reported that the word\ndistribution between fake and real reviews is very different in the dataset by Ottet al., while this is not true in their more realistic Yelp dataset.\nSince then, researchers started focusing more on the problem of detecting opinion\nspammers (or fraudulent reviewers), rather than fraudulent reviews. Fei et al. [ 48]\ndiscovered that a large number of opinions made use of a sudden burst either\ncaused by the sudden popularity of the product or by a sudden invasion of a large\nnumber of fake opinions including some of the features of real users. They used this\ufb01nding to design an algorithm that applies loopy belief propagation on a network\nof reviewers appearing in different bursts to detect opinion spammers. Several other\nworks considered features extracted from reviewer behavior as well [ 49\u201351].\nRayana and Akoglu [ 52] also applied loopy belief propagation on a user\u2013\nproduct bipartite network with signed edges (positive or negative reviews) and\nconsidered metadata (text, timestamp, rating) to assign prior probabilities of usersbeing spammers, reviews being fake, and products being targeted by spammers.\nWang et al. [ 53] proposed three measures (the trustworthiness of the user, the\nhonesty of the review, and the reliability of the store) to be computed on the user-product-store network. Hooi et al. [ 54] proposed the BirdNest algorithm that detects\nopinion spammers according to the fact that (1) fraudulent reviews occur in short\nbursts of time and (2) fraudulent user accounts have skewed rating distributions.Kumar et al. [ 55] bridged network data and behavioral data to de\ufb01ne measures\nfor computing the fairness (or trustworthiness) of the reviewer, the goodness (or\nquality) of the product, and the reliability of the review. Several other works havebeen proposed to detect a group of opinion spammers. For instance, CopyCatch [ 56]\nleveraged the lockstep behavior, i.e., groups of users acting together, generally liking\nthe same pages at around the same time.\n3.5 Fake News\nTo identify fake news, the majority of the approaches proposed in the literature havefocused on machine learning-based approaches working with features extracted\nfrom news content and social context [ 2].\nNews content-based features include both linguistic features extracted from the\ntext of the news, metadata-based features such as news source (author and/or\npublisher), headlines, etc., and visual-based features extracted from images and\nvideos associated with the news. For instance, Seyedmehdi and Papalexakis [ 57]\nproposed a solution based on extracting latent features from news article text via\ntensor decomposition to categorize fake news as extreme bias, conspiracy theory,\nsatire, junk science, hate group, or state news. Potthast et al. [ 58] used the writing\nstyle of the articles to identify extremely biased news from the neutral one by\nusing the techniques called unmasking. This model used the news domain speci\ufb01c\nstyle features like ratios of quoted words, external links, the average length of the\nProtecting the Web from Misinformation 11\nparagraph, etc. Horne and Adali [ 59] considered both news body and headline for\ndetermining the validity of news. They found out that fake and real news have\ndrastically different headlines as they were able to obtain a 0.71 accuracy whenconsidering the number of nouns, lexical redundancy (TTR), word count, and the\nnumber of quotes. Further, the study found that fake titles contain different sorts of\nwords (stop words, extremely positive words, and slang among others) than titlesof real news articles. P\u00e9rez-Rosas et al. [ 60] analyzed the news body content only\nand achieved an accuracy up to 0.76 in detecting fake news. They also tested cross\ndomain classi\ufb01cation obtaining poor performances by training in one dataset andtesting in the other one. Jin et al. [ 61] used only visual and statistical features\nextracted from news images for microblogs news veri\ufb01cation.\nSocial context-based features consider (1) the pro\ufb01le and characteristics of users\ncreating and spreading the news (e.g., number of followers/followees, number of\nposts, credibility and the reliability of the user) also averaged among all the users\nrelated to particular news, (2) users\u2019 opinion and reactions towards social mediaposts (post can potentially contain fake news), (3) various type of networks such as\nfriendship networks, co-occurrence networks (network formed based on the number\nof posts the user write related to the news), or diffusion network where edgesbetween users represent information dissemination paths among them.\nKim et al. [ 62] propose methods to not only detect the fake news but also to\nprevent the spread of fake news by making the user \ufb02ag fake news and used reliablethird-parties to fact check the news content. They developed an online algorithm for\nthis purpose, so it works at the time of user spreading the fake news thus preventing\nit from spreading. Jin et al. [ 63] developed a method for detecting fake news by\nusing the users\u2019 viewpoints to \ufb01nd relationships such as support or oppose and by\nbuilding a credibility propagation network by using these relationships. Wu and\nLiu [ 64] used the way news spread through the social network to \ufb01nd the fake news.\nThey used graph mining method to analyze the social network and recurrent neural\nnetworks to represent and classify propagation pathways of a message.\nFinally, hybrid methods combine the two previous approaches. For instance,\nRuchansky et al. [ 65] used temporal behavior of users and their response and the\ntext content of the news to detect the fake news. They proposed the CSI model\n(Capture, Score, and Integrate) to classify the news article. Fairbanks et al. [ 66]s h o w\nthat a content-based model can identify publisher political bias while a structural\nanalysis of web links is enough to detect whether the news is credible or not. Shu\net al. [ 67] exploited both fake news content and the relationship among publishers,\nnews pieces, and users to detect fake news.\nRegarding clickbait detection speci\ufb01cally, Chakraborty et al. [ 68] build personal-\nized automatic blocker for clickbait headlines by using a rich set of features that usesentence structure, word patterns, N-gram features, and clickbait language. Their\nbrowser extension \u2018Stop-Clickbait\u2019 warns users for potential clickbaited headlines.\nPotthast et al. [ 69] used Twitter datasets to identify messages in social media that\nlead to clickbait. They gathered tweets from various publishers and constructed\nfeatures based on teaser message, linked web page, and meta information. Anand\net al. [ 70] used three variants of bidirectional RNN models (LSTM, GPU, and\n12 F. Spezzano and I. Gurunathan\nstandard RNNs) for detecting clickbait headlines They used two different word\nembedding techniques such as distributed word embeddings and character-level\nword embeddings. Chen et al. [ 71] examined a hybrid approach for clickbait\ndetection by using text-based and non-text based clickbaiting cues. While textual\ncues use text-based semantic and syntactical analysis, non-textual cues relate to\nimage and user behavior analysis.\n4 Case Study: Protecting Wikipedia Content Quality\nWikipedia is the world\u2019s biggest free encyclopedia read by many users every day.Thanks to the mechanism by which anyone can edit, its content is expanded andkept constantly updated. However, malicious users can take advantage of this open\nediting mechanism to seriously compromise the quality of Wikipedia articles. As we\nhave seen in Sect. 2, the main form of content damaging in Wikipedia is vandalism,\nbut other types of damaging edits are also common such as page spamming [ 6] and\ndissemination of false information, e.g., through hoax articles [ 86].\nIn this section, we discuss our research effort to ensure the content integrity of\nWikipedia. W start by introducing the DePP system, which is the state-of-the-art\ntool for detecting article pages to protect [ 87,88] in Wikipedia. Page protection is\na mechanism used by Wikipedia to place restrictions on the type of users that canmake edits to prevent vandalism, libel, or edit wars. Our DePP system achieves\nan accuracy of 92.1% across multiple languages and signi\ufb01cantly improves over\nbaselines.\nThen, we present our work on spam users identi\ufb01cation [ 89]. We formulate the\nproblem as a binary classi\ufb01cation task and propose a new system, called WiSDe ,\nbased on a set of features representing user editing behavior to separate spamusers from benign ones. Our results show that WiSDe reaches 80.8% classi\ufb01cation\naccuracy and 0.88 mean average precision and beat ORES, the most recent tool\ndeveloped by Wikimedia to assign damaging scores to edits.\nFinally, we discuss our related work [ 90,91] on detecting editors who will stop\ncontributing to the encyclopedia. In fact, one of the main problems of \ufb01ghting\nvandalism on Wikipedia is that newcomers are considered suspicious from veteranusers who often delete their contributions causing the non-integration of newcomers\nin the community. We think that the early prediction of inactive users is useful for\nWikipedia administrators or other users to perform recovering actions in time toavoid the loss of contributors. This section does not provide new results but collects\nthe ones presented in our prior publications.\n4.1 Detecting Pages to Protect\nThe \ufb01rst problem we address consists of deciding whether or not Wikipediaadministrators should protect a page. Page protection consists of placing restrictions\nProtecting the Web from Misinformation 13\non the type of users that can edit a Wikipedia page. Examples of protected pages on\nEnglish Wikipedia are Drug andBiology . Users can recognize this kind of pages by\nthe image of a lock in the upper right-hand corner of the page. Common motivationsthat an administrative user may have in protecting a page include (1) consistent\nvandalism or libel from one or more users, and (2) avoiding edit wars [ 92]. An\nedit war is when two users cannot agree on the content of an article and one userrepeatedly reverts the other\u2019s edits.\nThere are different levels of page protection for which different levels of users\ncan make edits (or, in general, perform actions on the page): fully protected pagescan be edited (or moved) only by administrators, semi-protected pages can be\nmodi\ufb01ed only by autocon\ufb01rmed users, while move protection does not allow pages\nto be moved to a new title, except by an administrator. Page protections can also beset for different amounts of time, including 24 or 36 h, or inde\ufb01nitely.\nCurrently, the English Wikipedia contains over \ufb01ve million pages. Only a small\npercentage of those pages are currently protected less than 0.2%. However, around17 pages become protected every day (according to the number of protected\npages from May 6 through Aug 6, 2016). This ratio shows how it is dif\ufb01cult for\nadministrative users to monitor overall Wikipedia pages to determine if any needto be protected. Users can request pages to be protected or unprotected, but an\nadministrative user would have to analyze the page to determine if it should be\nprotected, what level of protection to give, and for how long the protection shouldlast, if not inde\ufb01nitely. All this work is currently manually done by administrators.\nTo overcome this problem, we propose DePP ,t h e \ufb01rstautomated tool to detect\npages to protect in Wikipedia. DePP is a machine learning-based tool that works\nwith two novel set of features based on (1) users page revision behavior and (2)\npage categories . More speci\ufb01cally, the \ufb01rst group of features includes the following\nsix base features:\nE1 Total average time between revisions : pages that have very few edits over a\nlong period of time are less likely to become protected (as their content ismore stable) than pages with many edits that happen with little time between\nthem.\nE2 Total number of users making \ufb01ve or more revisions : this feature counts the\nnumber of users who make more than \ufb01ve edits to a page.\nE3 Total average number of revisions per user : if there are many users making a\nfew changes to a page, it is less likely to become protected than if a few usersare making a lot of changes to a page.\nE4 Total number of revisions by non-registered users : this feature measures the\nnumber of changes made to a page from non-registered users. If a user has notspent the time to set up an account, it is less likely that they are a pro\ufb01cient\nuser and more likely to be a spammer or vandal. Therefore, the more non-\nregistered users that are editing a page, the more likely it is that the page mayneed to be protected.\n14 F. Spezzano and I. Gurunathan\nE5 Total number of revisions made from mobile device : similar to feature E4, this\nfeature looks at the number of revisions that are tagged as coming from a\nmobile device. This is a useful feature because users making changes froma mobile device are not likely to be sitting down to spend time making\nrevisions to a page that would add a lot of value. It is possible that a\nuser making a change from a mobile device is only adding non-usefulinformation, vandalizing a page, or reverting vandalism that needs to be\nremoved immediately.\nE6 Total average size of revisions : it is possible that users vandalizing a page,\nor adding non-useful information would make an edit that is smaller in size.\nThis is opposed to a pro\ufb01cient user who may be adding a large amount of\nnew content to a page. For this reason, we measure the average size of an edit.Small edits to a page may lead to a page becoming protected more than large\nedits would.\nIn addition to the above base features, we also include an additional set of\nfeatures taking into account the page editing pattern over time. We de\ufb01ne these\nfeatures by leveraging the features E1\u2013E6 as follows. For each page, we considerthe edits made in the latest 10 weeks and we split this time interval into time frames\nof 2 weeks (last 2 weeks, second last 2 weeks, etc.). Then, we compute the base\nfeatures E1\u2013E6 within each time frame and compute the standard deviation of eachbase features in the 10 weeks time interval. This produces six new features whose\nidea is to measure how much features E1\u2013E6 are stable over time. For instance,\nfor normal pages with solid content, we may observe fewer edits of smaller sizerepresenting small changes in the page, corresponding to a low standard deviation\nfor features E1, E3, and E6. On the other hand, a higher standard deviation of the\nbase features can describe a situation where the content of the page was initiallystable, but suddenly we observe a lot of edits from many users, which may indicate\nthe page is under a vandalism attack and may need protection.\nThe second group of features use information about page categories and includes:\nNC Number of categories a page is marked under ;\nPC Probability of protecting the page given its categories : given all the pages\nin the training set Tand a page category c, we compute the probability\npr(c)that pages in category care protected as the percentage of pages in T\nhaving category cthat are protected. Then, given a page phaving categories\nc\n1,...,c n, we compute this feature as the probability that the page is in at\nleast one category whose pages have a high probability to be protected as\nPC(p) =1\u2212n/productdisplay\ni=1(1\u2212pr(ci)).\nWe also de\ufb01ne another group of features that shows how much features E1\u2013\nE6 vary for a page pw.r.t. the average of these values among all the pages in the\nsame categories as p. Speci\ufb01cally, given the set of pages in the training set T,w e\nProtecting the Web from Misinformation 15\ncomputed the set Cof the top- kmost frequent categories. Additionally, for each\ncategory c\u2208C, we averaged the features E1\u2013E6 among all the pages (denoted by\nTc) having the category cin the training set. Then, for each page pwe computed the\nfollowing set of features, one for each feature E i(1\u2264i\u22646) and for each category\nc\u2208Cas follows:\nC(Ei,c) =/braceleftBigg\nEi(p) \u2212avgp/prime\u2208Tc(Ei(p/prime))ifpis in category c\n0 otherwise\nwhere Ei(p) is the value of the feature E ifor the page p. The aim of this group\nof features is to understand if a page is anomalous w.r.t. other pages in the same\ncategory. All the features that we propose are language independent as they do notconsider page content. As a consequence, DePP is general and able to work on any\nversion of Wikipedia.\nTo test our DePP system, we built four balanced datasets, one for each of the\nfollowing Wikipedia versions: English, German, French, and Italian. Each dataset\ncontains all edit protected articles until to Oct. 12, 2016, an almost equal number of\nrandomly selected unprotected pages, and up to the last 500 most recent revisionsfor each selected page. The sizes of these datasets\n2are reported in Table 2.F o r\nprotected pages, we only gathered the revisions up until the most recent protection.\nIf there was more than one recent protection, we gathered the revision informationbetween the two protections. This allowed us to focus on the revisions leading up to\nthe most recent page protection. Revision information that we collected included the\nuser who made the revision, the timestamp of the revision, the size of the revision,the categories of the page, and any comments, tags or \ufb02ags associated with the\nrevision.\nTheDePP accuracy in the prediction task on 10-fold cross validation is reported\nfor random forest (the best performing algorithm as compared to Logistic Regres-\nsion, SVM, and K-Nearest Neighbor) in Table 3. As we can see, DePP can classify\npages to protect from pages that do not need protection with an accuracy greater\nTable 2 English, German,\nFrench, and Italian Wikipediadatasets used in to test ourDePP systemEnglish German French Italian\nProtected pages 7968 1722 524 171\nUnprotected pages 7889 1706 512 168\nNumber of edits 2.2M 311K 106K 29K\nTable 3DePP accuracy\nresults and comparison withbaselinesEnglish German French Italian\nB1+B2+B3 78% 48% 77% 43%\nDePP 95% 93% 93% 91%\nEverything is computed with random forest (best classi\ufb01er)Best scores are highlighted in bold\n2Datasets available at http://bit.ly/wiki_depp .\n16 F. Spezzano and I. Gurunathan\nthan 91% in all the four languages. As no automated tool detecting which page\nto protect exists in Wikipedia, we de\ufb01ned some baselines to compare our results.\nOne of the main reasons for protecting a page on Wikipedia is to stop edit wars,vandalism or libel from happening or continuing to happen on a page. Thus, we\nused the following baselines:\nB1 Number of revisions tagged as \u201cPossibl e libel or vandalism\u201d : These tags\nare added automatically without human interference by checking for certain\nwords that might be likely to be vandalism. If a match is found, the tag isadded.\nB2 Number of revisions that Wikipedia bots or tools reverted as possible vandal-\nism: number of reverted edits in the page made by each one of these tools.\nWe considered Cluebot NG and STiki for English Wikipedia and Salebot for\nFrench Wikipedia. We did not \ufb01nd any bot \ufb01ghting vandalism for German or\nItalian Wikipedia.\nB3 Number of edit wars between two users in the page : Edit warring occurs when\ntwo users do not agree on the content of a page or revision. Therefore, we\ncount the number of edit wars within the revision history of a page as anotherbaseline. In some Wikipedia languages, e.g., German and Italian, there is an\nexplicit tag denoting edit wars. For English and French Wikipedia, we de\ufb01ne\nan edit war as one user making a revision to a page, followed by another userreverting that revision, and this pattern happens 2 or 3 consecutive times.\nAs we can see in Table 3,DePP signi\ufb01cantly beats the combination of all the three\nbaselines across all the languages. By analyzing the most important features, wefound that features E1 (total average time between revisions) and PC (probability\nof protecting the page given its categories) consistently appear within the top-15\nfeatures in all the four languages considered. Wikipedia editors spend less time inrevising pages that end up being protected. For instance, in English Wikipedia the\nmean average time between revisions in 5.8 days for protected pages and 2.9 months\nfor unprotected ones. Also, a protected page is more likely to be in categoriesthat have other protected pages than an unprotected page (a probability of 0.84 on\naverage vs. 0.52 in English Wikipedia).\nIn the real-world scenario, we have more unprotected pages than unprotected\nones.\n3Thus, we performed an experiment where we created an unbalanced setting\nby randomly selecting pages at a ratio of 10% protected and 90% unprotected (due\nto the size of the data we have, we could not reduce this ratio further). Then, weperformed 10-fold cross-validation and measured the performance by using the\narea under the ROC curve (AUROC). We used class weighting to deal with class\nimbalance. Due to the randomness introduced, we repeated each experiment 10times and averaged the results. Results are reported in Table 4. We observe that\nAUROC values are pretty high across all the dataset considered and outperforms\n3Currently, there is a 0.16% of protected pages in English Wikipedia, 0,09% in German, 0.04% in\nFrench, and 0.015% in Italian.\nProtecting the Web from Misinformation 17\nTable 4DePP AUROC\nresults and comparison withbaselines in the unbalancedsetting (10% protected pages,90% unprotected)English German French Italian\nB1+B2+B3 0.77 0.50 0.80 0.50\nDePP 0.97 0.97 0.97 0.96\nEverything is computed with random forest (best clas-\nsi\ufb01er)Best scores are highlighted in bold\nthe baselines. In comparison, AUROC values for the balanced setting are 0.98\nfor English Wikipedia, 0.98 for German, 0.97 for French, and 0.93 for Italian.\nThus, performance does not drop when considering a more real-world unbalanced\nscenario. Moreover, as shown in [ 93], AUROC values do not change with changes\nin the test distribution, thus the above AUROC values for the balanced setting are\ngeneralizable to an unbalanced one. Random forest results the best classi\ufb01er in both\nthe balanced and unbalanced setting.\n4.2 Spam Users Identi\ufb01cation\nAnother problem that compromises the content quality of Wikipedia articles isspamming. Currently, no speci\ufb01c tool is available on Wikipedia to identify neitherspam edits or spam users. Tools like Cluebot NG and STiki are tailored toward\nvandalism detection, while ORES is designed to detect damaging edits in general.\nAs in the case of page protection, the majority of the work to protect Wikipediafrom spammers is done manually by Wikipedia users (patrollers, watchlisters, and\nreaders) who monitor recent changes in the encyclopedia and, eventually, report\nsuspicious spam users to administrators for de\ufb01nitive account blocking. To \ufb01ghtspammers on Wikipedia, we study the problem of identifying spam users from good\nones [ 89] .O u rw o r ki sc l o s e ri ns p i r i tt o[ 30] as the aim is to classify users by\nusing their editing behavior instead of classifying a single edit as vandalism [ 7,8],\nspam [ 44] or generally damaging [ 82].\nWe propose a system, called WiSDe (Wikipedia Spammer Detector), that uses\na machine learning-based framework with a set of features which are based onresearch that has been done regarding typical behaviors exhibited by spammers:\nsimilarity in edit size and links used in revisions, similar time-sensitive behavior\nin edits, social involvement of a user in the community through contribution toWikipedia\u2019s talk page system, and chosen username. We did not consider any\nfeature related to edit content so that our system would be language independent\nand capable of working for all Wikipedia versions. Also, the duration of a user\u2019sedit history, from the \ufb01rst edit to her most recent edit, is not taken into account as\nthis feature is biased towards spammers who are short-lived due to being blocked\nby administrators. Finally, we do not rely on third-party services, so there is nooverhead cost as in [ 44].\n18 F. Spezzano and I. Gurunathan\nThe list of features we considered to build WiSDe are as follows:\nUser\u2019s Edit Size Based Features\nS1 Average size of edits \u2014since spammers in Wikipedia are primarily trying to\npromote themselves (or some organization) and/or attract users to click on\nvarious links, the sizes of spammers\u2019 edits are likely to exhibit some similaritywhen compared to that of benign users.\nS2 Standard deviation of edit sizes \u2014since many spammers make revisions with\nsimilar content, the variation in a user\u2019s edit sizes is likely not to be very largewhen compared to benign users.\nS3 Variance signi\ufb01cance \u2014since variance in a spam user\u2019s edits can change based\non a user\u2019s average edit size, normalizing a user\u2019s standard deviation ofedit sizes by their average edit size may balance any difference found by\nconsidering the standard deviation alone.\nEditing Time Behavior Based Features\nS4 Average time between edits \u2014spammers across other social media tend to\nperform edits in batches and in relatively rapid succession, while benign\nWikipedia users dedicate more time in curating the article content and thenmake edits more slowly than spammers.\nS5 Standard deviation of time between edits \u2014the consistency in timing of\nspammers\u2019 edits tends to be somewhat mechanical, while benign users tendto edit more sporadically.\nLinks in Edit Based Features\nS6 Unique link ratio \u2014since spammers often post the same links in multiple edits,\na measure of how unique any links that a user posts may be very useful in\nhelping to determine which users are spammers. This measure is calculatedfor any user that has posted a minimum of two links in all of their edits, and it\nis the ratio of unique links posted by a user to the total number of links posted\nby the user (considering only the domain of the links)\nS7 Link ratio in edits \u2014since spammers on Wikipedia are known to post links in\nan effort to attract traf\ufb01c to other sites the number of edits that a user makes\nwhich contain links is likely a useful measure in determining spammers frombenign users.\nTalk Page Edit Ratio Since talk pages do not face the public and are only\npresented to a user that speci\ufb01cally clicks on one, spammers are less likely to getvery many views on these pages, and, therefore are much less likely to make edits to\ntalk pages. Because of this, the ratio of talk pages edited by a user that correspond\nwith the main article pages that a user edits is considered a possible good indicatorof whether a user is a spammer or not. We denote this feature by S8.\nUsername Based Features Zafarani and Liu [ 94] showed that aspects of users\u2019\nusernames themselves contain information that is useful in detecting malicious\nusers. Thus, in addition to the features based on users\u2019 edit behaviors, we also\nconsidered four additional features related to the user\u2019s username itself. These\nProtecting the Web from Misinformation 19\nfour features are: the number of digits in a username (S9), the ratio of digits in\na username (S10), the number of leading digits in a username (S11), and the unique\ncharacter ratio in a username (S12).\nTo test our WiSDe system, we built a new dataset4containing 4.2K (half\nspammer and half benign) users and 75.6K edits as follows. We collected allWikipedia users (up to Nov. 17, 2016) who were blocked for spamming from\ntwo lists maintained on Wikipedia: \u201cWikipedians who are inde\ufb01nitely blocked\nfor spamming\u201d [ 95] and \u201cWikipedians who are inde\ufb01nitely blocked for link\nspamming\u201d [ 96]. The \ufb01rst list contains all spam users blocked before Mar 12, 2009,\nwhile the second one includes all link-spammers after Mar 12, 2009, to today. We\ngathered a total of 2087 spam users (we only included users who did at least oneedit) between the two lists considered.\nIn order to create a balanced dataset of spam/benign users, we randomly select a\nsample of benign Wikipedia users of roughly the same size as the spammer user set(2119 users). To ensure these were genuine users, we cross-checked their usernames\nagainst the entire list of blocked users provided by Wikipedia [ 97]. This list contains\nall users in Wikipedia who have been blocked for any reason, spammers included.For each user in our dataset, we collected up to their 500 most recent edits. For each\nedit, we gathered the following information: edit content, time-stamp, whether or\nnot the edit is done on a Talk page, and the damaging score provided by ORES.\nWe run 10-fold cross-validation on several machine learning algorithms, namely\nSVM, Logistic Regression, K-Nearest Neighbor, Random Forest, and XGBoost, to\ntest the performances of our features. Experimental results are shown in Table 5\nfor the best performing algorithm (XGBoost). Here we can see that WiSDe is\nable to classify spammers from benign users with 80.8% of accuracy and it is\na valuable tool in suggesting potential spammers to Wikipedia administrators forfurther investigation as proved by a mean average precision of 0.88.\nFeature importance analysis revealed that the top three most important features\nfor spammers identi\ufb01cations are: Link ratio in edits ,Average size of edits , and\nStandard deviation of time between edits . As expected, spammers use more links\nin their edits. The average value of this feature is 0.49 for spammers and 0.251\nfor benign users. Also, benign users put more diverse links in their revisions thanspammers (0.64 vs. 0.44 on average). We also have that spammer\u2019s edit size is\nTable 5WiSDe spammers\nidenti\ufb01cation accuracy andMean Average Precision(MAP) results in comparisonwith ORESAccuracy MAP\nORES 69.7% 0.695\nWiSDe 80.8% 0.880\nWiSDe +ORES 82.1% 0.886\nEverything is computed with XGBoost\nBest scores are highlighted in bold\n4Dataset available at http://bit.ly/wiki_spammers .\n20 F. Spezzano and I. Gurunathan\nsmaller, and they edit faster than benign users. Regarding edits on talk pages, we\nhave that the majority of the users are not using talk pages (percentage for both\nbenign users and spammers is 69.7%). However, surprisingly, we have that, amongusers editing talk pages, the talk page edit ratio is higher for spammers (0.2) than\nfor benign users (0.081), and we observe a group of around 303 spammers trying\nto gain visibility by making numerous edits on talk pages. Finally, username basedfeatures contribute to an increase in accuracy prediction by 2.9% (from 77.9% to\n80.8%) and Mean Average Precision by 0.019 (from 0.861 to 0.880).\nWe compared WiSDe with ORES only, as the tool proposed in [ 44]i sn o\nlonger used, and Cluebot NG and STiki are explicitly designed for vandalism and\nnot spam. To compare our system with ORES, we considered the edit damaging\nscore. More speci\ufb01cally, given a user and all her edits, we computed both theaverage and maximum damaging score provided by ORES and used these as\nfeatures for classi\ufb01cation. Results on 10-fold cross-validation with XGBoost (the\nbest performing classi\ufb01er) are reported in Table 5, as well. As we can see, ORES\nperformances are poor for the task of spammer detection (69.7% of accuracy and\nmean average precision of 0.695). However, combining our features with ORES\nfurther increases the accuracy to 82.1%.\nIn reality, spam users are greatly outnumbered by benign users. Thus, similarly\nto what we did in the previous section, we also created an unbalanced dataset to\ntest our system WiSDe by randomly selecting users at a ratio of 10% spammers and\n90% of benign users. Then, we performed 10-fold cross-validation and measured\nthe performance by using the area under the ROC curve (AUROC). To deal with\nclass imbalance, we oversampled the minority class in each training set by usingSMOTE [ 98]. We also considered class weighting, but we found that SMOTE\nis performing the best. Due to the randomness introduced, we repeated each\nexperiment 10 times and averaged the results. Table 6reports the results for this\nexperiment. As we can see, even with class imbalance, WiSDe reaches a good\nAUROC of 0.842 (in comparison we have an AUROC of 0.891 for the balanced\nsetting) and signi\ufb01cantly improve over ORES (AUROC of 0.736). However, addingORES features to ours helps to increase the AUROC to 0.864.\nTable 6WiSDe vs. ORES\nperformance in theunbalanced settingAUROC\nORES 0.736\nWiSDe 0.842\nWiSDe +ORES 0.864\nEverything is computed by\nusing XGBoostBest scores are highlighted inbold\nProtecting the Web from Misinformation 21\n4.3 Content Quality Protection and User Retention\nAs we have seen in this chapter, a lot of research has been done with the aim\nof maintaining the trustworthiness, legitimacy, and integrity of Wikipedia content.\nHowever, one big drawback of deploying anti-vandalism and anti-spam tools is that\nveteran editors started to suspiciously look at newcomers as potential vandals andrapidly and unexpectedly deleted contributions even from good-faith editors. Many\nnewcomers, in fact, face social barriers [ 99] preventing them from the integration in\nthe editor community, with the consequence of stop editing after a certain period oftime [ 100,101]. As Halfaker et al. [ 102] have pointed out, Wikipedia is not anymore\nthe encyclopedia that anyone can edit but rather \u201cthe encyclopedia that anyone who\nunderstands the norms, socializes himself or herself, dodges the impersonal wall ofsemi-automated rejection, and still wants to voluntarily contribute his or her time\nand energy can edit. \u201d\nThe loss of active contributors from any user-generated content community\nmay affect the quantity and quality of content provision not only on the speci\ufb01c\ncommunity but also on the Web in general. Most importantly, UGC communities\nmainly survive thanks to the continued participation of their active users whocontribute with their content production.\nThus, being able to early predict whether or not a user will become inactive\nis very valuable for Wikipedia and any other user-generated content communityto perform engaging actions on time to keep these users contributing longer. In\nour related work [ 90,91], we addressed the problem of early predict whether or\nnot a Wikipedia editor will become inactive and stop contributing and proposeda predictive model based on users\u2019 editing behavior that achieves an AUROC of\n0.98 and a precision of 0.99 in predicting inactive users. By comparing the editing\nbehavior of active vs. inactive users, we discovered that active users are moreinvolved in edit wars and positively accept critiques, and edit much more different\ncategories of pages. On the other hand, inactive users have more edits reverted and\nedit more meta-pages (and in particular User pages).\nRegarding speci\ufb01c actions for engaging editors, the Wikipedia community\nconsiders several steps that can be taken to increase the retention rate such as (1)\nsurvey newly registered users to capture user\u2019s interests and use them for makingrelevant editing recommendations and (2) connect editors with similar interests\nto form meaningful contribution teams. They also developed and deployed a tool,\ncalled Snuggle [ 103], to support newcomers socialization.\n5 Conclusions\nIn this chapter, we discussed several types of misinformation that these days exist on\nthe Web such as vandalism, spam, fraudulent reviews, fake news, etc. and provided\na survey on how to detect them.\n22 F. Spezzano and I. Gurunathan\nThen, we focused on the speci\ufb01c case study of protecting Wikipedia from\nmisinformation and presented our research on detecting pages to protect and\nidentifying spam users. Our experimental results show that we are able to classify(1) article pages to protect with an accuracy of 92% across multiple languages\nand (2) spammers from benign users with 80.8% of accuracy and 0.88 mean\naverage precision. Both the methods proposed do not look at edit content and, asa consequence, they are generally applicable to all versions of Wikipedia, not only\nthe English one.\nFinally, we discussed a possible solution for newcomers retention, given that\nmany new users do not keep contributing to the encyclopedia because of the tools\ndeployed to \ufb01ght vandalism.\nReferences\n1. L. Wu, F. Morstatter, X. Hu, H. Liu, Mining misinformation in social media, in Big Data in\nComplex and Social Networks (2016), pp. 123\u2013152\n2. K. Shu, A. Sliva, S. Wang, J. Tang, H. Liu, Fake news detection on social media: a data mining\nperspective. ACM SIGKDD Explor. Newslett. 19(1), 22\u201336 (2017)\n3. A. Zubiaga, A. Aker, K. Bontcheva, M. Liakata, R. Procter, Detection and resolution of\nrumours in social media: a survey. ACM Comput. Surv. (CSUR) 51(2), 32 (2018)\n4. S. Kumar, N. Shah, False information on web and social media: a survey (2018). arXiv\npreprint:1804.08559\n5. Vandalism in Wikipedia. http://en.wikipedia.org/wiki/Wikipedia:Vandalism\n6. Spam in Wikipedia. http://en.wikipedia.org/wiki/Wikipedia:Spam\n7. Cluebot_NG. http://bit.ly/ClueBotNG\n8. STiki. http://bit.ly/STiki_tool\n9. A. Shrestha, F. Spezzano, M.S. Pera, Who is really affected by fraudulent reviews? an analysis\nof shilling attacks on recommender systems in real-world scenarios, in Late-Breaking Results\ntrack part of the Twelfth ACM Conference on Recommender Systems (RecSys\u201918) (2018)\n10. Pew Research Center. http://www.journalism.org/2016/12/15/many-americans-believe-fake-\nnews-is-sowing-confusion/\n11. S. V osoughi, D. Roy, S. Aral, The spread of true and false news online. Science ,359(6380),\n1146\u20131151 (2018)\n12.https://www.factcheck.org/2016/11/how-to-spot-fake-news/\n13. H. Allcott, M. Gentzkow, Social media and fake news in the 2016 election. J. Econ. Perspect.\n31(2), 211\u201336 (2017)\n14. P. America, Faking News: Fraudulent News and the Fight for Truth (2018). https://pen.org/\nfaking-news/\n15. A. Zubiaga, E. Kochkina, M. Liakata, R. Procter, M. Lukasik, Stance classi\ufb01cation in\nrumours as a sequential task exploiting the tree structure of social media conversations, inCOLING 2016, 26th International Conference on Computational Linguistics, Proceedings ofthe Conference: Technical Papers, December 11\u201316, 2016, Osaka, Japan (2016), pp. 2438\u2013\n2448\n16. S. Kwon, M. Cha, K. Jung, W. Chen, Y . Wang, Aspects of rumor spreading on a microblog\nnetwork, in Proceedings of Social Informatics\u20145th International Conference, SocInfo 2013,\nKyoto, Japan, November 25\u201327, 2013 (2013), pp. 299\u2013308\n17. A. Friggeri, L.A. Adamic, D. Eckles, J. Cheng, Rumor cascades, in Proceedings of the Eighth\nInternational Conference on Weblogs and Social Media, ICWSM 2014, Ann Arbor, Michigan,USA, June 1\u20134, 2014 (2014)\nProtecting the Web from Misinformation 23\n18. S. Kumar, R. West, J. Leskovec, Disinformation on the web: impact, characteristics, and\ndetection of wikipedia hoaxes, in Proceedings of the 25th International Conference on World\nWide Web, WWW 2016, Montreal, Canada, April 11\u201315, 2016 (2016), pp. 591\u2013602\n19. P. Bajaj, M. Kavidayal, P. Srivastava, M.N. Akhtar, P. Kumaraguru, Disinformation in\nmultimedia annotation: misleading metadata detection on youtube, in Proceedings of the\n2016 ACM Workshop on Vision and Language Integration Meets Multimedia Fusion, iVandL-MM@MM 2016, Amsterdam, Netherlands, October 16, 2016 (2016), pp. 53\u201361\n20. A. Nguyen, J. Clune, Y . Bengio, A. Dosovitskiy, J. Yosinski, Plug and play generative\nnetworks: conditional iterative generation of images in latent space, in 2017 IEEE Conference\non Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21\u201326,2017 (2017), pp. 3510\u20133520\n21. E. Gibney, The scientist who spots fake videos. Nature (2017)\n22. M. Potthast, B. Stein, R. Gerling, Automatic vandalism detection in wikipedia, in Proceedings\nof Advances in Information Retrieval, 30th European Conference on IR Research, ECIR 2008,Glasgow, UK, March 30-April 3, 2008 (2008), pp. 663\u2013668\n23. M. Potthast, B. Stein, T. Holfeld, Overview of the 1st international competition on wikipedia\nvandalism detection, in CLEF 2010 LABs and Workshops, Notebook Papers, 22\u201323 Septem-\nber 2010, Padua, Italy (2010)\n24. B.T. Adler, L. de Alfaro, S.M. Mola-Velasco, P. Rosso, A.G. West, Wikipedia vandalism\ndetection: combining natural language, metadata, and reputation features, in International\nConference on Intelligent Text Processing and Computational Linguistics (CICLing) (2011),\npp. 277\u2013288\n25. A.G. West, S. Kannan, I. Lee, Detecting wikipedia vandalism via spatio-temporal analysis\nof revision metadata? in Proceedings of the Third European Workshop on System Security,\nEUROSEC 2010, Paris, France, April 13, 2010 (2010), pp. 22\u201328\n26. B.T. Adler, L. de Alfaro, I. Pye, Detecting wikipedia vandalism using wikitrust\u2014lab report for\nPAN at CLEF 2010, in CLEF 2010 LABs and Workshops, Notebook Papers, 22\u201323 September\n2010, Padua, Italy (2010)\n27. J. Kiesel, M. Potthast, M. Hagen, B. Stein, Spatio-temporal analysis of reverted wikipedia\nedits, in Proceedings of the Eleventh International Conference on Web and Social Media,\nICWSM 2017, Montr\u00e9al, Qu\u00e9bec, Canada, May 15\u201318, 2017 (2017), pp. 122\u2013131\n28. S. Heindorf, M. Potthast, B. Stein, G. Engels, Vandalism detection in wikidata, in Proceedings\nof the 25th ACM International Conference on Information and Knowledge Management,CIKM 2016, Indianapolis, IN, USA, October 24\u201328, 2016 (2016), pp. 327\u2013336\n29. P. Neis, M. Goetz, A. Zipf, Towards automatic vandalism detection in openstreetmap. ISPRS\nInt. J. Geo Inf. 1(3), 315\u2013332 (2012)\n30. S. Kumar, F. Spezzano, V .S. Subrahmanian, VEWS: a wikipedia vandal early warning system,\ninProceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining, Sydney, NSW, Australia, August 10\u201313, 2015 (2015), pp. 607\u2013616\n31. G. Stringhini, C. Kruegel, G. Vigna, Detecting spammers on social networks, in Proceedings\nof the 26th Annual Computer Security Applications Conference (2010), pp. 1\u20139\n32. K. Lee, J. Caverlee, S. Webb, Uncovering social spammers: social honeypots + machine\nlearning, in Proceedings of the 33rd International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (2010), pp. 435\u2013442\n33. J. Song, S. Lee, J. Kim, Spam \ufb01ltering in twitter using sender-receiver relationship, in\nInternational Workshop on Recent Advances in Intrusion Detection (2011), pp. 301\u2013317\n34. C. Yang, R.C. Harkreader, G. Gu, Die free or live hard? empirical evaluation and new design\nfor \ufb01ghting evolving twitter spammers, in International Workshop on Recent Advances in\nIntrusion Detection , pp. 318\u2013337 (2011)\n35. C. Grier, K. Thomas, V . Paxson, M. Zhang, @ spam: the underground on 140 characters or\nless, in Proceedings of the 17th ACM Conference on Computer and Communications Security\n(CCS) (2010), pp. 27\u201337\n24 F. Spezzano and I. Gurunathan\n36. L. Wu, X. Hu, F. Morstatter, H. Liu, Detecting camou\ufb02aged content polluters, in Proceedings\nof the Eleventh International Conference on Web and Social Media, ICWSM 2017, Montr\u00e9al,Qu\u00e9bec, Canada, May 15\u201318, 2017 (2017), pp. 696\u2013699\n37. X. Hu, J. Tang, H. Gao, H. Liu, Social spammer detection with sentiment information, in\n2014 IEEE International Conference on Data Mining (ICDM) (2014), pp. 180\u2013189\n38. S. Lee, J. Kim, Warningbird: detecting suspicious urls in twitter stream. in 19th Annual\nNetwork and Distributed System Security Symposium, NDSS 2012, San Diego, California,USA, February 5\u20138, 2012 (2012)\n39. J. Ma, L.K. Saul, S. Savage, G.M. V oelker, Beyond blacklists: learning to detect malicious\nweb sites from suspicious urls, in Proceedings of the 15th ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining, Paris, France, June 28\u2013July 1, 2009(2009), pp. 1245\u20131254\n40. D.K. McGrath, M. Gupta, Behind phishing: an examination of phisher modi operandi, in\nProceedings of First USENIX Workshop on Large-Scale Exploits and Emergent Threats,LEET \u201908, San Francisco, CA, USA, April 15, 2008 (2008)\n41. C. Cao, J. Caverlee, Detecting spam urls in social media via behavioral analysis, in Proceed-\nings of Advances in Information Retrieval\u201437th European Conference on IR Research, ECIR2015, Vienna, Austria March 29\u2013April 2, 2015 (2015), pp. 703\u2013714\n42. D. Antoniades, I. Polakis, G. Kontaxis, E. Athanasopoulos, S. Ioannidis, E.P. Markatos,\nT. Karagiannis, we.b: the web of short URLs, in Proceedings of the 20th International\nConference on World Wide Web, WWW 2011, Hyderabad, India, March 28\u2013April 1, 2011(2011), pp. 715\u2013724\n43. A.G. West, J. Chang, K. Venkatasubramanian, O. Sokolsky, I. Lee, Link spamming wikipedia\nfor pro\ufb01t, in CEAS (2011), pp. 152\u2013161\n44. A.G. West, A. Agrawal, P. Baker, B. Exline, I. Lee, Autonomous link spam detection in purely\ncollaborative environments, in WikiSym (2011), pp. 91\u2013100\n45. N. Jindal, B. Liu, Opinion spam and analysis, in Proceedings of the International Conference\non Web Search and Web Data Mining, WSDM 2008, Palo Alto, California, USA, February11\u201312, 2008 (2008), pp. 219\u2013230\n46. M. Ott, Y . Choi, C. Cardie, J.T. Hancock, Finding deceptive opinion spam by any stretch of the\nimagination, in Proceedings of the 49th Annual Meeting of the Association for Computational\nLinguistics: Human Language Technologies, 19\u201324 June, 2011, Portland, Oregon, USA(2011), pp. 309\u2013319\n47. A. Mukherjee, V . Venkataraman, B. Liu, N.S. Glance, What yelp fake review \ufb01lter might be\ndoing? in Proceedings of the Seventh International Conference on Weblogs and Social Media,\nICWSM 2013, Cambridge, Massachusetts, USA, July 8\u201311, 2013 (2013)\n48. G. Fei, A. Mukherjee, B. Liu, M. Hsu, M. Castellanos, R. Ghosh, Exploiting burstiness\nin reviews for review spammer detection, in Proceedings of the Seventh International\nConference on Weblogs and Social Media, ICWSM 2013, Cambridge, Massachusetts, USA,July 8\u201311, 2013 (2013)\n49. E. Lim, V .A. Nguyen, N. Jindal, B. Liu, H.W. Lauw, Detecting product review spammers\nu s i n gr a t i n gb e h a v i o r s ,i n Proceedings of the 19th ACM Conference on Information and\nKnowledge Management, CIKM 2010, Toronto, Ontario, Canada, October 26\u201330, 2010(2010), pp. 939\u2013948\n50. A. Mukherjee, A. Kumar, B. Liu, J. Wang, M. Hsu, M. Castellanos, R. Ghosh, Spotting\nopinion spammers using behavioral footprints, in Proceedings of the 19th ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining, KDD 2013, Chicago,\nIL, USA, August 11\u201314, 2013 (2013), pp. 632\u2013640\n51. K.C. Santosh, A. Mukherjee, On the temporal dynamics of opinion spamming: case studies on\nyelp, in Proceedings of the 25th International Conference on World Wide Web, WWW 2016,\nMontreal, Canada, April 11\u201315, 2016 (2016), pp. 369\u2013379\nProtecting the Web from Misinformation 25\n52. S. Rayana, L. Akoglu, Collective opinion spam detection: Bridging review networks and\nmetadata, in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, Sydney, NSW, Australia, August 10\u201313, 2015 (2015), pp. 985\u2013\n994\n53. G. Wang, S. Xie, B. Liu, P.S. Yu, Review graph based online store review spammer detection,\ninProceedings of the 11th IEEE International Conference on Data Mining, ICDM 2011,\nVancouver, BC, Canada, December 11\u201314, 2011 (2011), pp. 1242\u20131247\n54. B. Hooi, N. Shah, A. Beutel, S. G\u00fcnnemann, L. Akoglu, M. Kumar, D. Makhija, C. Faloutsos,\nBIRDNEST: bayesian inference for ratings-fraud detection, in Proceedings of the 2016 SIAM\nInternational Conference on Data Mining, Miami, Florida, USA, May 5\u20137, 2016 (2016), pp.\n495\u2013503\n55. S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, V .S. Subrahmanian, REV2: fraudu-\nlent user prediction in rating platforms, in Proceedings of the Eleventh ACM International\nConference on Web Search and Data Mining, WSDM 2018, Marina Del Rey, CA, USA,February 5\u20139, 2018 (2018), pp. 333\u2013341\n56. A. Beutel, W. Xu, V . Guruswami, C. Palow, C. Faloutsos, Copycatch: stopping group attacks\nby spotting lockstep behavior in social networks, in Proceedings of the 22nd International\nWorld Wide Web Conference, WWW \u201913, Rio de Janeiro, Brazil, May 13\u201317, 2013 (2013), pp.\n19\u2013130\n57. S. Hosseinimotlagh, E.E. Papalexakis, Unsupervised content-based identi\ufb01cation of fake\nnews articles with tensor decomposition ensembles, in MIS2: Misinformation and Misbe-\nhavior Mining on the Web Workshop held in conjunction with WSDM 2018 Feb 9, 2018\u2014Los\nAngeles, California, USA, 2018 (2018)\n58. M. Potthast, J. Kiesel, K. Reinartz, J. Bevendorff, B. Stein, A stylometric inquiry into\nhyperpartisan and fake news. CoRR, abs/1702.05638 (2017)\n59. B.D. Horne, S. Adali, This just in: fake news packs a lot in title, uses simpler, repetitive\ncontent in text body, more similar to satire than real news (2017). arXiv preprint:1703.09398\n60. V . P\u00e9rez-Rosas, B. Kleinberg, A. Lefevre, R. Mihalcea, Automatic detection of fake news, in\nProceedings of the 27th International Conference on Computational Linguistics (2018), pp.\n3391\u20133401\n61. Z. Jin, J. Cao, Y . Zhang, J. Zhou, Q. Tian, Novel visual and statistical image features for\nmicroblogs news veri\ufb01cation. IEEE Trans. Multimedia 19(3), 598\u2013608 (2017)\n62. J. Kim, B. Tabibian, A. Oh, B. Sch\u00f6lkopf, M. Gomez-Rodriguez, Leveraging the crowd to\ndetect and reduce the spread of fake news and misinformation, in Proceedings of the Eleventh\nACM International Conference on Web Search and Data Mining, WSDM 2018, Marina DelRey, CA, USA, February 5\u20139, 2018 (2018), pp. 324\u2013332\n63. Z. Jin, J. Cao, Y . Zhang, J. Luo, News veri\ufb01cation by exploiting con\ufb02icting social viewpoints\nin microblogs, in Proceedings of the Thirtieth AAAI Conference on Arti\ufb01cial Intelligence,\nFebruary 12\u201317, 2016, Phoenix, Arizona, USA (2016), pp. 2972\u20132978\n64. L. Wu, H. Liu, Tracing fake-news footprints: characterizing social media messages by how\nthey propagate, in Proceedings of the Eleventh ACM International Conference on Web Search\nand Data Mining, WSDM 2018, Marina Del Rey, CA, USA, February 5\u20139, 2018 (2018), pp.\n637\u2013645\n65. N. Ruchansky, S. Seo, Y . Liu, CSI: a hybrid deep model for fake news detection. in\nProceedings of the 2017 ACM on Conference on Information and Knowledge Management,CIKM 2017, Singapore, November 06\u201310, 2017 (2017), pp. 797\u2013806\n66. N. Knauf, J. Fairbanks, N. Fitch, E. Briscoe, Credibility assessment in the news: do we need\nto read? in MIS2: Misinformation and Misbehavior Mining on the Web Workshop held in\nconjunction with WSDM 2018 Feb 9, 2018\u2014Los Angeles, California, USA, 2018 (2018)\n67. K. Shu, S. Wang, H. Liu, Beyond news contents: the role of social context for fake news\ndetection, in Proceedings of the Twelfth ACM International Conference on Web Search and\nData Mining, WSDM 2019, Melbourne, VIC, Australia, February 11\u201315, 2019 (2019), pp.\n312\u2013320\n26 F. Spezzano and I. Gurunathan\n68. A. Chakraborty, B. Paranjape, S. Kakarla, N. Ganguly, Stop clickbait: detecting and pre-\nventing clickbaits in online news media, in 2016 IEEE/ACM International Conference on\nAdvances in Social Networks Analysis and Mining, ASONAM 2016, San Francisco, CA, USA,August 18\u201321, 2016 (2016), pp. 9\u201316\n69. M. Potthast, S. K\u00f6psel, B. Stein, M. Hagen, Clickbait detection, in Proceedings of Advances\nin Information Retrieval\u201438th European Conference on IR Research, ECIR 2016, Padua,Italy, March 20\u201323, 2016 (2016), pp. 810\u2013817\n70. A. Anand, T. Chakraborty, N. Park, We used neural networks to detect clickbaits: you won\u2019t\nbelieve what happened next!, in Proceedings of Advances in Information Retrieval\u201439th\nEuropean Conference on IR Research, ECIR 2017, Aberdeen, UK, April 8\u201313, 2017 (2017)\npp. 541\u2013547\n71. Y . Chen, N.J. Conroy, V .L. Rubin, Misleading online content: recognizing clickbait as \u201cfalse\nnews\u201d, in Proceedings of the 2015 ACM Workshop on Multimodal Deception Detection,\nWMDD@ICMI 2015, Seattle, Washington, USA, November 13, 2015 (2015), pp. 15\u201319\n72. S. Hamidian, M. Diab, Rumor detection and classi\ufb01cation for twitter data, in Proceedings\nof the Fifth International Conference on Social Media Technologies, Communication, andInformatics (SOTICS) (2015), pp. 71\u201377\n73. S. Hamidian, M. Diab, Rumor identi\ufb01cation and belief investigation on twitter, in Proceedings\nof the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and SocialMedia Analysis (2016), pp. 3\u20138\n74. V . Qazvinian, E. Rosengren, D.R. Radev, Q. Mei, Rumor has it: identifying misinformation\nin microblogs, in Proceedings of the 2011 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2011, 27\u201331 July 2011, John McIntyre Conference Centre,\nEdinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL (2011), pp. 1589\u2013\n1599\n75. A. Zubiaga, M. Liakata, R. Procter, Exploiting context for rumour detection in social media,\ninInternational Conference on Social Informatics (Springer, Berlin, 2017), pp. 109\u2013123\n76. L. Wu, J. Li, X. Hu, H. Liu, Gleaning wisdom from the past: early detection of emerging\nrumors in social media, in Proceedings of the 2017 SIAM International Conference on Data\nMining, Houston, Texas, USA, April 27\u201329, 2017 (2017), pp. 99\u2013107\n77. D. Shah, T. Zaman, Rumors in a network: who\u2019s the culprit? IEEE Trans. Infor. Theory 57(8),\n5163\u20135181 (2011)\n78. W. Luo, W.-P. Tay, Finding an infection source under the SIS model, in IEEE International\nConference on Acoustics, Speech and Signal Processing, ICASSP 2013, Vancouver, BC,Canada, May 26\u201331, 2013 (2013), pp. 2930\u20132934\n79. W. Dong, W. Zhang, C.W. Tan, Rooting out the rumor culprit from suspects, in Proceedings of\nthe 2013 IEEE International Symposium on Information Theory, Istanbul, Turkey, July 7\u201312,2013 (2013), pp. 2671\u20132675\n80. C. Kang, S. Kraus, C. Molinaro, F. Spezzano, V .S. Subrahmanian, Diffusion centrality: a\nparadigm to maximize spread in social networks. Artif. Intell. 239, 70\u201396 (2016)\n81. E. Tacchini, G. Ballarin, M.L. Della Vedova, S. Moret, L. de Alfaro, Some like it hoax:\nautomated fake news detection in social networks. CoRR, abs/1704.07506 (2017)\n82. ORES. http://bit.ly/wikipedia_ores\n83. ORES API. http://ores.wikimedia.org\n84. B.M. Hill, A.D. Shaw, Page protection: another missing dimension of wikipedia research,\ninProceedings of the 11th International Symposium on Open Collaboration, San Francisco,\nCA, USA, August 19\u201321, 2015 (2015), pp. 15:1\u201315:4\n85. Pywikibot. https://www.mediawiki.org/wiki/Manual:Pywikibot/protect.py\n86. Hoaxes on Wikipedia. https://en.wikipedia.org/wiki/Wikipedia:List_of_hoaxes_on_\nWikipedia\n87. K. Suyehira, F. Spezzano, Depp: a system for detecting pages to protect in wikipedia, in\nProceedings of the 25th ACM International Conference on Information and KnowledgeManagement, CIKM 2016, Indianapolis, IN, USA, October 24\u201328, 2016 (2016), pp. 2081\u2013\n2084\nProtecting the Web from Misinformation 27\n88. F. Spezzano, K. Suyehira, L.A. Gundala, Detecting pages to protect in wikipedia across\nmultiple languages. Soc. Netw. Anal. Min. 9(1), 10 (2018)\n89. T. Green, F. Spezzano, Spam users identi\ufb01cation in wikipedia via editing behavior, in\nProceedings of the Eleventh International Conference on Web and Social Media, ICWSM2017, Montr\u00e9al, Qu\u00e9bec, Canada, May 15\u201318, 2017 (2017), pp. 532\u2013535\n90. H. Arelli, F. Spezzano, Who will stop contributing?: predicting inactive editors in wikipedia,\ninProceedings of the 2017 IEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining 2017, Sydney, Australia, July 31\u2013August 03, 2017 (2017),\npp. 355\u2013358\n91. H. Arelli, F. Spezzano, A. Shrestha, Editing behavior analysis for predicting active and\ninactive users in wikipedia, in In\ufb02uence and Behavior Analysis in Social Networks and Social\nMedia (2019), pp. 127\u2013147\n92. Edit War in Wikipedia. http://en.wikipedia.org/wiki/Wikipedia:Editwarring\n93. T. Fawcett, An introduction to ROC analysis. Pattern Recogn. Lett. 27(8), 861\u2013874 (2006)\n94. R. Zafarani, H. Liu, 10 bits of surprise: detecting malicious users with minimum information,\ninCIKM (2015), pp. 423\u2013431\n95.http://en.wikipedia.org/wiki/Category:Wikipedians_who_are_inde\ufb01nitely_blocked_for_\nspamming\n96.http://en.wikipedia.org/wiki/Category:Wikipedians_who_are_inde\ufb01nitely_blocked_for_\nlink-spamming\n97.http://en.wikipedia.org/wiki/Special:BlockList\n98. N.V . Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, Smote: synthetic minority over-\nsampling technique. J. Artif. Intell. Res. 16, 321\u2013357 (2002)\n99. I. Steinmacher, T. Conte, M.A. Gerosa, D.F. Redmiles, Social barriers faced by newcomers\nplacing their \ufb01rst contribution in open source software projects, in Proceedings of the 18th\nACM Conference on Computer Supported Cooperative Work and Social Computing, CSCW2015, Vancouver, BC, Canada, March 14\u201318, 2015 (2015), pp. 1379\u20131392\n100. L. Jian, J.K. MacKie-Mason, Why leave wikipedia? in iConference (2008)\n101. S. Asadi, S. Ghafghazi, H.R. Jamali, Motivating and discouraging factors for wikipedians:\nthe case study of persian wikipedia. Libr. Rev. 62(4/5), 237\u2013252 (2013)\n102. A. Halfaker, R.S. Geiger, J.T. Morgan, J. Riedl, The rise and decline of an open collaboration\nsystem: how wikipedia\u2019s reaction to popularity is causing its decline. Am. Behav. Sci. 57(5),\n664\u2013688 (2013)\n103. A. Halfaker, R.S. Geiger, L.G. Terveen, Snuggle: designing for ef\ufb01cient socialization and\nideological critique, in CHI Conference on Human Factors in Computing Systems, CHI\u201914,\nToronto, ON, Canada\u2014April 26\u2013May 01, 2014 (2014), pp. 311\u2013320\nStudying the Weaponization of Social\nMedia: Case Studies of Anti-NATO\nDisinformation Campaigns\nKatrin Galeano, Rick Galeano, Samer Al-Khateeb, and Nitin Agarwal\nAbstract Social media provides a fertile ground for any user to \ufb01nd or share\ninformation about various events with others. At the same time, social media is not\nalways used for benign purposes. With the availability of inexpensive and ubiquitous\nmass communication tools, disseminating false information and propaganda is\nboth convenient and effective. In this research, we studied Online Deviant Groups\n(ODGs) that conduct cyber propaganda campaigns in order to achieve strategic\nand political goals, in\ufb02uence mass thinking, and steer behaviors or perspectives\nabout an event. We provide case studies in which various disinformation and\npropaganda swamped social media during two NATO exercises in 2015. We\ndemonstrate ODGs\u2019 capability to spread anti-NATO propaganda using a highly\nsophisticated and well-coordinated social media campaign. In particular, blogs were\nused as virtual spaces where narratives are framed. And, to generate discourse, web\ntraf\ufb01c was driven to these virtual spaces via other social media platforms such as\nTwitter, Facebook, and VKontakte. By further examining the information \ufb02ows\nwithin the social media networks, we identify sources of mis/disinformation and\ntheir reach, i.e., how far and how quickly the mis/disinformation could travel and\nconsequently detect manipulation. The chapter presents an in-depth examination\nof the information networks using social network analysis (SNA) and social cyber\nforensics (SCF) based methodologies to identify prominent information brokers,\nleading coordinators, and information competitors who seek to further their own\nagenda. Through SCF tools, e.g., Maltego, we extract metadata associated with\ndisinformation-riddled websites. The extracted metadata helps in uncovering the\nimplicit relations among various ODGs. We further collected the social network of\nvarious ODGs (i.e., their friends and followers) and their communication network\n(i.e., network depicting the \ufb02ow of information such as tweets, retweets, mentions,\nK. Galeano \u00b7 R. Galeano \u00b7 N. Agarwal ( /envelopeback)\nDepartment of Information Science, University of Arkansas at Little Rock, Little Rock, AR, USA\ne-mail: kkaniagalea@ualr.edu ;ragaleano@ualr.edu ;nxagarwal@ualr.edu\nS. Al-Khateeb\nDepartment of Journalism, Media, and Computing, Creighton University, Omaha, NE, USA\ne-mail: sameral-khateeb1@creighton.edu\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_229\n30 K. Galeano et al.\nand hyperlinks). SNA helped us identify in\ufb02uential users and powerful groups\nresponsible for coordinating the various disinformation campaigns. One of the key\nresearch \ufb01ndings is the vitality of the link between blogs and other social mediaplatforms to examine disinformation campaigns.\nKeywords Social media \u00b7 Weaponization \u00b7 Cyber forensics \u00b7 Social network\nanalysis \u00b7 NATO \u00b7 Disinformation\n1 Introduction\nGlobal communication has accelerated through the use of social media platformsover the past decade and in turn, this social media craze has affected demographics\nacross the globe. An observation made in 2016 while living in The Netherlands,\nwas that of school-age children pedaling their bicycles through busy city streets andstaring at the screens of their phones. It even appeared that they were responding\nto messages while riding their bikes. Just a few years ago, this would have been\nunheard of, but it is ever present just driving down the street in any city now to seepeople driving vehicles and texting, posting updates, or even sur\ufb01ng the web.\nThe youth of yesteryear are the savvy technology operators of today. The\nkids that grew up playing the Atari 2600 or the Commodore 64 systems haverevolutionized the way people communicate in our general day to day lifestyles; can\nyou imagine how our communications cycle will look twenty-\ufb01ve years from now\nwith the millennials that text and ride their bikes at the same time! For example, priorto the home video game industry, electronic gaming was more of a social setting that\nhappened via coin-operated machines at an arcade or the pinball machine at the bar.\n\u201cAtari bridged the gap, they moved video games from these places to the home. Inso doing, they caused a market shift. [They realized] if you\u2019re only selling games per\nplay to people in bars, then you\u2019re missing out on a whole marketplace of families\nand kids,\u201d Bogost said [ 1].\nTransferring from the mindset of the \u2018home-based\u2019 video gaming world into the\nmodern age of social media communications, look at the CEO of Facebook, Mark\nZuckerberg. Facebook had its roots with Atari systems. At the age of twelve, Mr.Zuckerberg created \u201cZucknet\u201d that was used in his father\u2019s dental of\ufb01ce. Zucknet\nwas a social messaging network designed to share data on patients and inform\nhygienists that patients were in the waiting room; essentially \u201cZucknet\u201d was thegrandfather of Facebook [ 2]. Mindful that not all social media platforms have a\nkinship to the home video game industry, they do have the universal notion of\nproviding social conversations, sharing, and a gathering point for online businessand personal communications. All too often, social media is used as the medium for\nthe change agent. In this case, it does not necessarily represent an individual person\nbut rather a larger concept. The change agent seeks to control the narrative.\nControlling the narrative; irrelevant to the platform, dates back to the 3\nrdcentury\nB.C. at the Platonic Academy in Greece. Aristotle\u2019s approach with his three appeals\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 31\nabout the general means of persuasion: (1) Logos (logic/reason/proof) (2) Ethos\n(credibility/trust), and (3) Pathos (emotions/values) have morphed into modern day\ndisinformation campaigns via digital platforms. Controlling the narrative via massin\ufb02ux of messaging into the information environment or simply being the \ufb01rst to\ninput information\u2014EVEN IF IT IS FALSE\u2014has been able to gain momentum\nexpeditiously.\nThis has developed into controlling the narrative via social communications.\nSocial communication happens online, at a business meeting and even in class-\nrooms. In\ufb02uencing an audience through narrative is effective; for example, Ama-zon\u2019s founder and CEO has required executive meetings be switched to a story-\ntelling approach via the \u201cnarrative structure\u201d [ 3]. Jeff Bezos has banned PowerPoints\nduring executive meetings, rather, \u201c... he revealed that the \u201cnarrative structure\u201dis more effective than PowerPoint\u201d [ 3]. These examples of storytelling are even\nmore attentive on social media and are oftentimes told by networks of [initially]\norganized trolls\n1. The rhetoric of communications through storytelling often mimics\nmanipulative behaviors in order to in\ufb02uence the opinion of the audience by seeking\nto create an interest with the audience that keeps their attention. Otherwise, what\ngood is storytelling with no one to tell the story to?\nStudies have shown that public opinion is going to be more effective than bullets\nand bombs in the future war. Public opinion has become a tool to achieve a goal,\nmay it be favoritism or turmoil. Information warfare can be used to change andshape public opinion, as it was the case during the Ukraine con\ufb02ict during which the\nRussian public was in\ufb02uenced in believing that Russia was defending itself while\nthe West was to blame for the con\ufb02ict [ 4]. In\ufb02uence campaigns can also easily be\nused to create friction aimed at weakening an adversary as demonstrated by the\nforeign interference of the U.S. 2016 presidential election [ 5]. Countering ODG\nmentality is a must to win the new battle of ideas. Today, transnational terroristgroups know that opinions can be in\ufb02uenced and they are using sophisticated\ntechniques to overcome the time and space limitations of conventional in\ufb02uence\ncampaigns by using digital tactics that take advantage of the speed and reach ofthe Internet. A study conducted by the Defense Academy of the United Kingdom\n[6] examines the sharing of the beheading videos of hostages by Al-Qaeda as an\ninstance of strategic communication, de\ufb01ned as: \u201cA systematic series of sustainedand coherent activities, conducted across strategic, operational and tactical levels,\nthat enables understanding of target audiences, identi\ufb01es effective conduits, and\ndevelops and promotes ideas and opinions through those conduits to promote andsustain particular types of behaviour\u201d [ 6].\nTaking advantage of storytelling via blogs or social networking sites has quickly\nmoved into strategic narratives and the framework for communications. Studyingsocial media networks to identify false narratives or fake news has become easier\nbecause of the new digital information environment. Access to data reveals networks\n1A person who disseminates provocative posts on social media for the troll\u2019s amusement or because\n(s)he was paid to do so.\n32 K. Galeano et al.\noperating in their true nature, often the networks are extremely large, numbering\nhundreds of thousands of nodes and ties. Steve Borgatti, a renowned social scientist\nimplies that the importance of an organization in a given network is determined bythe institutional af\ufb01liations it has within the network [ 7]. The \ufb02ow of information\namongst the institutional af\ufb01liates illuminate areas that are not identi\ufb01ed without\nthe use of exploratory social network analysis. Illuminating these af\ufb01liations within\nnetworks was conducted through the combination of social network analysis and\nsocial cyber forensics. These two approaches allowed us to dissect the network,\nreview the narrative approaches, and study how the authors created disagreementamongst the audience and swayed opinions.\nIn this chapter, two different networks of online deviant groups (ODGs) are\nprovided as case studies. The \ufb01rst is the North Atlantic Treaty Organization (NATO)Trident Juncture 2015 exercise and the second is the U.S. Army Europe Operation\nDragoon Ride 2015. The focus of this chapter is to identify key actors and clusters\nwithin the overall networks and to be able to identify and illuminate these darknetworks using social network analysis (SNA) and social cyber forensics (SCF).\nMalcolm Sparrow, emphasized that intelligence agencies do not have the expertise\nto conduct SNA, \u201csocial network analysis has a lot to offer intelligence agenciesin this area through its ability to discover who is central within organizations,\nwhich individual\u2019s removal would most effectively disrupt the network, what role\nindividuals are playing, and which relationships are vital to monitor\u201d [ 8]. In general,\nthis study provides an academic research background to further develop SNA and\nSCF based methods and procedures for those seeking the truth. Remember, \u201cThe\nmain work of a trial attorney is to make a jury like his client.\u201d [ 9]. Our research\ndemonstrates in both studies that the main actor was the trial attorney and the\naudience was the jury, easily persuaded to follow, like, retweet, and support the\nsocial narrative.\n2 Literature Review\nFor this chapter we have reviewed literature of the work that has been previouslyconducted in the areas of bots, cyber forensics , and SNA. Speci\ufb01cally, we explain the\nbackground of bot research, data carving, and how cyber forensics is used with SNA.\nLastly, a review is conducted on the in\ufb02uence assessment in the blogosphere. One ofthe aforementioned references in the introduction refers to how modern approaches\nto developing the narrative are being explored. Corporations that fuse social science\ninto the business place are likely to have a competitive edge in their respectivemarkets. A simple search of Amazon\u2019s available job postings as of May 13, 2018,\nshowed multiple social science positions. Some of the preferred quali\ufb01cations for\na position as the Senior Research Psychologist identi\ufb01ed \u201c...research backgroundin social or cognitive psychology or affective science, particularly with ties to\nmotivation: deep knowledge of regressions, analysis of variance, multilevel models,\nstructural equation models\u201d [ 10]. Just this example alone provides a basis for\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 33\ncontinued research in this \ufb01eld as the job market dictates more and more positions\nto shape behavior change in the future. Reviewing even literature online in a non-\ntraditional sense such as \u201cjob postings\u201d allows us an alternative approach to identifythe relevance of this \ufb01eld.\nBots Automated social actors/agents or bots are not a new phenomenon. They have\nbeen studied previously in literature in a variety of domains, such as Internet Relay\nChat (IRC) [ 11], online gaming, e.g., World of Warcraft (WoW) [ 12], and more\nrecently behavioral steering through misinformation dissemination on social media[13]. One of the earliest bots emerged in 1993 in an internet protocol that allows\npeople to communicate with each other by text in real time called Eggdrop. This\nbot had very simple tasks to welcome new participants and warn them about theactions of other users [ 11]. Shortly thereafter, the use of bots in IRC became very\npopular due to the simplicity of the implementation in and their ability to scale IRCs\n[14]. Both evolved over time and the tasks these bots were assigned became more\ncomplicated and sophisticated.\nAbokhodair et al. studied the use of social bots regarding the con\ufb02ict in Syria\nin 2012 [ 15]. The study focused on one botnet (i.e., a set of bots working together)\nthat lived for six months before Twitter detected and suspended it [ 15]. The study\nanalyzed the life and the activities of the botnet. Focus was placed on the content\nof tweets, i.e., they classi\ufb01ed the content of the tweets into 12 categories: news,opinion, spam/phishing, testimonial, conversation, breaking news, mobilization of\nresistance/support, mobilization for assistance, solicitation of information, infor-\nmation provisioning, pop culture, and other. Through their research, the authorswere able to answer the question on how the content of the bot tweeting in\nArabic or English differ from the non-bot or legitimate users tweeting in Arabic or\nEnglish? For example, bots tend to share more news articles, less opinion tweets, notestimonial tweets, and less conversational tweets than any other legitimate Arabic\nor English Twitter user [ 16]. They also classi\ufb01ed bots based on the content posted,\ntime before the bot gets suspended, and type of activity the bot does (tweet orretweet) into the following categories:\n1. Core Bots: These bots are further divided into three sub-categories:\n(a) Generator Bots: bots that tweet a lot but seldom retweet anything.\n(b) Short Lived Bots: bots that retweet a lot but seldom tweet. These bot accounts\nlasted around 6 weeks before Twitter suspended them.\n(c) Long Lived Bots: bots that retweet a lot but seldom tweet. These bot accounts\nlasted more than 25 weeks before Twitter suspended them.\n2. Peripheral Bots: Twitter accounts that are being lured to participate in the\ndissemination process. Their task is retweeting one or more tweets generated\nby the core bots [ 15].\nResearch on detecting social bots has increased dramatically. In 2010, Chu et al.\n[17] proposed a classi\ufb01cation system to determine whether tweets on Twitter belong\nto a human, bot, or cyborg (human account use scripts or tools to post on their\n34 K. Galeano et al.\nbehalf, like a hybrid account). Over 500,000 accounts were studied to \ufb01nd the\ndifference between human, bots, and cyborg in tweeting content and behavior. Their\nclassi\ufb01er is comprised of the following four components: (1) Entropy Component:which is used to detect the regularity and periods of users\u2019 tweets, (2) Machine\nLearning Component: which is used to detect spam tweets, (3) Account Properties\nComponent: which help identify bots by checking external URLs ratio in the tweetsor checking the tweeting device (web, mobile, or API) to help detecting bots, and (4)\nDecision Maker Component: which uses the input of the previous three components\nto determine the type of the user [ 17].\nWang et al. [ 18] reviewed the possibility of human detection, suggesting the\ncrowdsourcing of social bot detection to legions of workers. To test this concept, the\nauthors created an Online Social Turing Test platform. The authors assumed thatbot detection is a simple task for humans because humans have a natural ability to\nevaluate conversational nuances like sarcasm or persuasive language and to observe\nemerging patterns or anomalies but this is yet unparalleled by machines. Using datafrom Facebook and Renren\u2014a popular Chinese online social network\u2014the authors\ntested the ef\ufb01cacy of humans\u2014both expert annotators and workers hired online\u2014\nat detecting social bot accounts simply from the information on their pro\ufb01les. Theauthors observed the detection rate for hired workers drops off over time, although it\nremains good enough to be used in a majority voting protocol. In their experiment,\nthe same pro\ufb01le was shown to multiple workers and the opinion of the majority wasused to determine the \ufb01nal verdict.\nThe derivative of this literature identi\ufb01es that bots are present in the current\ninformation environment. Sophisticated studies indicate that bots are dif\ufb01cultto monitor even as researchers develop advanced detection methods. Bots are\ncontinually growing more advanced demonstrating more human-like behavior [ 19]\nwhich makes them harder to detect, especially if they start to inject \u201cbot\u201d opinionsinto messaging. Findings from the DARPA \u201cTwitter Bot Detection Challenge\u201d show\nthat bots cannot be solely identi\ufb01ed using machine learning only, instead a vast\nenhancement of analytic tools that combine multiple approaches to help in botdetection is needed [ 20]. Hence in this chapter, we combine SNA and SCF to help\nin bot identi\ufb01cation, especially in dark networks.\nSocial Cyber Forensics (SCF) For the last three and half decades digital forensics\ntools have evolved from simple tools, which were used mainly by law enforcement\nagencies to import tools for detecting and solving corporate fraud [ 21]. Cyber\nforensics tools are not new but they are evolving over time to have more capabilities,\nmore exposure to the audience (investigators or public users), and more types and\namount of data that can be obtained using each tool. Cyber forensics tools can betraced back to the early 1980s when these tools were mainly used by government\nagencies, e.g., the Royal Canadian Mounted Police (RCMP) and the U.S Internal\nRevenue Service (IRS) and were written in Assembly or C language with limitedcapabilities and less popularity. With time these tools got more sophisticated and in\nthe mid of 1980s these tools were able to recognize \ufb01le types as well as retrieve\nlost or deleted \ufb01les, e.g., XtreeGold and DiskEdit by Norton. In 1990s these\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 35\ntools became more popular and also have more capabilities, e.g., they can recover\ndeleted \ufb01les and fragments of deleted \ufb01les such as Expert Witness and Encase [ 22].\nNowadays, many tools are available to the public that enable them to collect cyberforensics data and visualize it in an easy to understand way, e.g., Maltego tool\n(developed by Paterva Ltd. available at www.paterva.com ).\nSocial network forensics tools collect data in many different ways, e.g., crawling\nby using the social network APIs, extract artifacts from local web browsers cache, or\nsnif\ufb01ng on unencrypted Wi-Fi\u2019s (active attacks), or with ARP spoo\ufb01ng on LANs, or\nusing a third party extension for the social network in combination with a traditionalcrawler component (friend in the middle attack) [ 23].\nResearch by Noora et al. [ 24] obtains cyber forensics evidence from social\nmedia applications that are installed on smartphones. Their research was testingwhether the activities conducted through these applications were stored on the\ndevice\u2019s internal memory or not. They used three major social media apps, i.e.,\nFacebook, Twitter, and MySpace and three devices types, i.e., iPhone, Blackberry,and Android for their experiments. The results show that Blackberry devices do not\nstore any information that can be retrieved by digital forensics tools while iPhone\nand Android phones store a signi\ufb01cant amount of valuable data that can be retrieved[24]. Additional research focused on extracting forensics data of social media from\nthe computer hard disk such as carving artifacts left by the use of Facebook Chat on\na computer\u2019s hard disk [ 25].\nIn this work, we are not creating a tool to collect forensics data from social\nnetworks, instead we are using a social cyber forensic analysis tool called Maltego\nwhich collects open source information (OSINF) and forensics data. This toolprovides a library of transformations for discovery of data from open sources. It\nhelps analyze the real world connections between groups, websites, and af\ufb01liations\nwith online services such as Facebook, Flickr, LinkedIn, and Twitter. It also providesthe capability to visualize the results in a graph format that is suitable for link\nanalysis.\nSocial Network Analysis Borgatti implies that the importance of an organization\nin a given network is determined by the institutional af\ufb01liations it has within\nthe network [ 7]. The \ufb02ow of information amongst the institutional af\ufb01liates will\nilluminate areas that are not identi\ufb01ed without the use of exploratory social network\nanalysis. Often these networks are referred to as dark networks . SNA should aid in\nthe overall strategy to identify kinetic and non-kinetic operations, but should not bethe de\ufb01nitive component of a stratagem. Applying SNA combined with SCF allows\nfor network illumination of the dark networks.\nCommon centrality measures such as betweenness, eigenvector, and closeness\nare used throughout this research. Although these metrics are primary in this\nresearch, other areas of SNA are examined as well such as topography, cohesive\nsubgroups, components, and Focal Structure Analysis (FSA).\nNetworks that portray the shortest paths between the organizations inside of\nthe network, demonstrate betweenness centrality. Further de\ufb01ned, nodes with\nthe closest neighbors are measured by their betweenness centrality [ 26]. These\n36 K. Galeano et al.\nnetwork measurements are seen in several of the sociograms throughout the chapter.\nEigenvector centrality was used to illuminate hierarchy within the organizations.\nThis will display well-connected nodal connections to other well connected nodes[27]. Closeness centrality allows this research to identify the dissemination of\ninformation throughout the network. It is imperative to not use closeness as a\nstand alone metric \u201cThis could lead analysts to conclude that certain actors aremore important than they really are which of course could lead to using mistaken\nassumptions when crafting strategies \u201d [ 28]. It is not unusual that illumination of\nhigher level actors are already common knowledge to the public. Often, bots areused to amplify the messages. Because of the truly hidden ways that bots have been\ndisguised it was necessary to combine SNA and SCF to illuminate the bots.\nFocal Structure is an algorithm that was implemented by \u00b8 Sen et al. [ 29]t o\ndiscover an in\ufb02uential group of individuals in a large network. FSA is not a\ncommunity detection algorithm, i.e., in the context of networks, most community\ndetections algorithms try to \ufb01nd nodes that are more densely connected in one partof the network and not that much connected on the other part of the network. These\ncommunity detection algorithms would suggest that there is a community based on\nthe nodes connection strength (i.e., how closely they are connected). However, FSAis an algorithm that tries to \ufb01nd a key set of nodes that are in\ufb02uential if they are\nworking together (i.e., exist in the network whether they are directly connected or\nnot). These individuals need not to be strongly connected and may not be the mostin\ufb02uential actors on their own, but by acting together they form a compelling power.\nFSA is a recursive modularity-based algorithm. Modularity is a network struc-\ntural measure that evaluates the cohesiveness of a network [ 30]. FSA uses a network-\npartitioning approach to identify sub-structures or sub-graphs. FSA consists of\ntwo parts the \ufb01rst part is a top-down division, where the algorithm identi\ufb01es the\ncandidate focal structures in the complex network by applying the Louvain methodof computing modularity [ 31]. The second part is a bottom-up agglomeration, where\nthe algorithm stitches the candidate focal structures, i.e., the highly interconnected\nfocal structures, or the focal structures that have the highest similarity values, arestitched together and then the process iterates until the highest similarity of all\nsibling pairs is less than a given threshold value. Similarity between two structures\nis measured using Jaccard\u2019s Coef\ufb01cient [ 29,32] which results in a value between\n0 and 1, where 1 means the two networks are identical, while zero means the two\nnetworks are not similar at all. The stitching of the candidate focal structures was\ndone to extract the structures with low densities, i.e., structures contain nodes thatare not connected densely [ 29].\nIn\ufb02uence in Blogosphere Blogs provide rich medium for individuals to frame\nan agenda and develop discourse around it using half-truth or twisting facts to\nin\ufb02uence the masses. Twitter, however, due to the 280-character limit, is primarily\nused as a dissemination medium. Bloggers have used Twitter to build an audience(or, followership) and as a vehicle to carry their message to their audience. It\nis important to understand the disinformation dissemination network on Twitter\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 37\nbut it is equally, if not more, important to understand the blog environment and\nspeci\ufb01cally the blogger\u2019s in\ufb02uence, engagement with the audience, and motivations\nfor agenda setting.\nIdentifying in\ufb02uential individuals is a well-studied problem. Many studies have\nbeen conducted to identify the in\ufb02uence of a blogger in a community [ 33\u201337]. The\nbasic idea of computing the in\ufb02uence a blogger has is to aggregate the in\ufb02uence oftheir individual blog posts. A blog post having more in-links andcomments indicates\nthat the community is interested in it. In-links andcomments contribute positively\ntowards the in\ufb02uence of the posts whereas out-links of the blog posts contribute\nnegatively towards the in\ufb02uence. In\ufb02uence can be assessed using a stochastic model\nwith inbound links ,comments andoutbound links of a post as factors, as proposed in\n[33]. An alternate approach is to use a modi\ufb01cation of Google page rank to identify\nin\ufb02uential posts as well as bloggers [ 36].\n3 Methodology to Study Narratives and Propaganda\nIn this section, we provide a methodology to study narratives including propaganda\nthat is disseminated on various social media channels during various events. This\nmethodology has been tested on several case studies and provided consistent results.The overall methodology is depicted in Fig. 1. The methodology \ufb01rst starts by\ndomain experts identifying keywords relevant to an event. Second, searching various\nonline social media platforms is conducted to identify an initial seed of data,e.g., Twitter accounts tweeting propaganda about the event, or a YouTube video\ncontaining propaganda, or a blog site that contain narratives. Third, using various\ndata collection tools (NodeXL, Scraawl, Web Crawlers (e.g., WebContentExtracor),YouTube APIs, Twitter APIs, TAGs, and Maltego) we extracted the social and\ncommunication networks of Twitter users, crawled the blog\u2019s data, identi\ufb01ed bots,\nand extracted the metadata associated with the social media accounts of interest.Finally, we conducted a set of analyses on the collected data including:\n\u0081 Social Cyber Forensics (SCF) analysis to identify relations among various\ngroups, uncover their cross-media af\ufb01liation, and identify more groups.\n\u0081 Social Network Analysis (SNA) to identify leaders of the narrative and identify\nthe role of nodes in the network, e.g., the source of information, brokers, top\ndisseminators, and type of nodes (bot or human account).\n\u0081 We also conduct various blogs data analyses using our in-house developed Blog-\ntrackers tool (available at: http://blogtrackers.host.ualr.edu ) such as sentiment\nanalysis, keywords trends, in\ufb02uential blogs and bloggers, etc.\n38 K. Galeano et al.\nFig. 1 The overall research\nmethodology\n\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 39\n3.1 Case Study 1: Anti-NATO Propaganda During the 2015\nTrident Juncture Exercise\nWhat Was the Propaganda On 4 November 2015, the US soldiers along with\nsoldiers from more than thirty partner nations and Allies moved 36,000 personnelacross Europe during the 2015 Trident Juncture Exercise (TRJE). The exercise\ntook place in the Netherlands, Belgium, Norway, Germany, Spain, Portugal, Italy,\nthe Mediterranean Sea, the Atlantic Ocean, and also in Canada to prove thecapability and readiness of the Alliance on land, air, and maritime. The exercise\nalso demonstrated that the Alliance is equipped with the appropriate capabilities\nand capacities to face any present or future security issues. In addition to the PartnerNations and Allies, more than Twelve aid agencies, International Organizations,\nand non-governmental organizations participated in the exercise to demonstrate\n\u201cNATO\u2019s commitment and contribution to a comprehensive approach [ 38].\u201d\nThe buildup of the exercise saw a series of competing information maneuvers\ndesigned to counter NATO and Allies. Several of these maneuvers are highlighted\nas examples that were observed in Fig. 2below. Ranging from narrative hijacking\nin multiple languages across websites, to community counter NATO meetings, to\nprotests in the streets, and of note an Anti-NATO concert held in Zaragoza. All of\nwhich were pushed via social platforms months before the exercise and created ainformation de\ufb01cit that NATO had to \ufb01ll.\nMany opponent groups launched campaigns on Twitter, Blogs, Facebook, and\nother social media platforms that encouraged citizens to protest against the exercise\nFig. 2 Examples of Anti NATO activities that were observed in the information environment prior\nto the exercise [ 39\u201341]\n40 K. Galeano et al.\nor do violent acts. We identi\ufb01ed six groups by searching their names on various\nsocial media platforms to identify their Twitter and blogging pro\ufb01les (followed\nour proposed methodology). These six groups propagated their messages on socialmedia inviting people to act against NATO and TRJE 2015 exercise. Next, we\nprovide a description of the dataset along with our \ufb01ndings.\nData Collection An initial set of twelve blog sites were identi\ufb01ed that the groups\nuse to develop narratives against the TRJE 2015 exercise. We were also able to\nidentify Twitter handles used to steer the audience from Twitter to their blogs. Weidenti\ufb01ed an initial set of 9 Twitter accounts used by the six groups. We used Twitter\nAPI through a tool called NodeXL to collect a network of replies, mentions, tweets,\nfriends, and followers for all the nine Twitter accounts and whoever is connectedto them with any one of the aforementioned relationships for the period 8/3/2014\nto 9/12/2015. The dataset \ufb01le we obtained contains 10,805 friends/followers, 68\nreplies, 654 tweets, 1365 mentions, 9129 total nodes, and 10,824 total edges. Thetwitter handles, blogs, and names of the groups studied in this research are publicly\navailable. However, in order to ensure their privacy, we do not disclose them here.\nMetadata Extraction We used Maltego which is an open source information\ngathering and forensics application. Maltego can extract Google Analytics IDs from\nblog sites. Google Analytics is an online analytics service that allows a website\nowner to gather statistics about their website visitors such as their browser, operatingsystem, and country among other metadata. Multiple sites can be managed under\na single Google analytics account. The account has a unique identifying \u201cUA\u201d\nnumber, which is usually embedded in the website\u2019s HTML code [ 42]. Using\nthis identi\ufb01er other blog sites that are managed under the same UA number can\nbe identi\ufb01ed. This method was reported in Bazzell\u2019s Open Source Intelligence\nTechniques: Resources for searching and analyzing online information [ 43]. Using\nMaltego we inferred the connections among blog sites and identi\ufb01ed new sites that\nwere previously undiscovered.\nWe used a seed set of 12 blog sites to discover other blogs that are connected to\nthem using Maltego as explained earlier. We used the tool in a snowball manner\nto discover other blog sites. We were able to identify additional 9 blogs that\nwere connected to the initial seed blogs by the same Google analytics IDs. Thesenewly identi\ufb01ed websites have the same content published on different portals and\nsometimes in different languages. For example, a website written in English may\nalso have another identical version but written in another language that is nativeto the region. Such blogs are also known as bridge blogs [44]. Additional public\ninformation such as the IP addresses, website owner name, email address, phone\nnumbers, and locations of all the websites was reviewed. We obtained three clustersof websites based on their geolocation. These clusters are helpful to know the\noriginality of the blog sites, which would help an analyst understand the propaganda\nthat is being pushed by the speci\ufb01c blog site. Cluster 1 contains one website that islocated in Russia, Cluster 2 has 8 websites located in USA, and Cluster 3 has 12 blog\nsites located in Spain, Cayman Islands, UK, and Germany. From the initial 12 blog\nsites we grew to 21 blog sites, 6 locations, and 15 IP addresses. All the blog sites we\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 41\nidenti\ufb01ed during this study were crawled and their data is stored in a database that\nthe Blogtrackers tool can access and analyze.\nIdentifying In\ufb02uential Information Actors Using SNA In addition to extracting\nmetadata using Maltego to \ufb01nd other related blog sites used by the group to\ndisseminate their propaganda, we applied SNA such as indegree centrality (to assesspopular nodes) outdegree centrality (to assess information sources or gregarious\nnodes), betweenness centrality (to assess information brokers or bridges) to \ufb01nd\nthe most important nodes in the network by activity type we also applied variouscommunity detection measures such as modularity (to assess the quality of the\nclusters), etc. Using NodeXL we were able to \ufb01nd the most used hashtags during\nthe time of the exercise (i.e., the hashtags occurred the most in the collected tweets).This helps in targeting the same audience if counter narratives were necessary to\nbe pushed to the same audience. In addition to that, we found the most tweeted\nURLs in the graph. This gives an idea about the public opinion concerns. Finally,we found the most used domains, which helps to know where the focus of analysis\nshould be directed, or what other media platforms are used. For example, two of the\ntop 10 hashtags that were used during the TRJE 2015 exercise were #YoConvoco(that translates to \u201cI invite\u201d using Google translation service) and #SinMordazas\n(that translates to \u201cNo Gags\u201d). These two hashtags were referring to a campaign\nthat is asking people for protests and civil resistance or civil disobedience. Also,investigating the top 10 URLs that were shared the most in the dataset reveals that\nthese URLs were links to websites that are mobilizing people to raise objections on\nusing taxpayers\u2019 money to fund military spending on wars.\nIdentifying Powerful Groups of Individuals Affecting Cyber Propaganda Cam-\npaign using FSA We divided our network (9129 nodes and 10,824 unique edges)\ninto two type namely, the social network , derived from friends and follower\u2019s\nrelations and the communication network , derived from replies and mentions\nrelations. We ran the FSA algorithm on these two networks to discover the most\nin\ufb02uential group of nodes.\n\u0081 Running FSA on the social network resulted in 1 focal structure with 7 nodes.\nThese 7 nodes are in fact among the nine anti-NATO seed nodes we started withand are very tightly knit (i.e., they exert mutually reciprocative relationships).\nThis indicates a strong coordination structure among these 7 nodes, which is\ncritical for conducting information campaigns.\n\u0081 Running FSA on the communication network resulted in 3 focal structures\nwith a total of 22 nodes. The same 7 accounts (out of the 9 seed accounts)\nfound in the social network focal structures are distributed in these 3 focalstructures. This gives those 7 accounts more power/in\ufb02uence than other nodes in\nthe network because they are found in the focal structures of both networks, i.e.,\nthe communication and social network. The rest of the nodes (i.e., the additional15 accounts) found in these 3 focal structures of the communication network are\nnew nodes. These are important because they are either leaders or part of key\ngroups conducting propaganda campaigns.\n42 K. Galeano et al.\nAnalyzing Blogs Data Using Blogtrackers Using SCF analysis and SNA as\nexplained in the previous sections, we were able to identify a total of 21 blog sites\nof interest. We trained web crawlers to collect data from these blogs and store thedata in Blogtrackers database. Then we performed the following analysis:\n1. We explore the collected dataset by generating the traf\ufb01c pattern graph using\nBlogtrackers. We ran the analysis for the period of August 2014 to December\n2015. We observed a relatively higher activity in these blogs from September\n2015 to December 2015, the period around the TRJE 2015,\n2. We generated a keyword trends graph for the following keywords: \u2018anti nato\u2019,\n\u2018trident juncture\u2019, \u2018nato\u2019 (as shown in Fig. 3). The keyword trend for the \u2018anti\nnato\u2019 completely aligned with the traf\ufb01c pattern graph indicating the postsactually had \u2018anti nato\u2019 keyword in it. We also observed that trend for \u2018anti nato\u2019\nwas consistently higher than \u2018nato\u2019 for this time period indicating there was more\nnegative sentiment towards NATO in these blogs,\n3. We ran the sentiment analysis in Blogtrackers for the same period and observed\nmore negative sentiment than positive sentiment in the blogs,\n4. We ran the in\ufb02uential posts analysis in Blogtrackers to identify posts with\nhigh in\ufb02uence. In other words, we wanted to identify what resonates with\nthe community most, or which narratives are affecting the people most. The\nin\ufb02uence score was calculated using of a stochastic model [ 33] with inbound\nlinks ,comments andoutbound links of a post as factors. The most in\ufb02uential\nFig. 3 Keyword trends for \u201canti nato,\u201d \u201cnato,\u201d and \u201ctrident juncture\u201d generated by Blogtrackers\ndepicting the occurrence of these keywords over the time period\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 43\npost was an Italian blog post from the \u2018nobordersard\u2019 blog. Upon translation\nto English we found the post to be highly propaganda-riddled. The blogger\nused two of the conventional propaganda techniques [ 45] called \u201cName Calling\u201d\n(associating a negative word to damage the reputation) and \u201cPlain Folks\u201d\n(presenting themselves as ordinary people or general public to gather support\nfor their cause or ideology). The blog post used phrases like: \u201cNATO exercisewas contributing to pollution and exploiting resources\u201d. It also categorizes this\nexercise as an act of militarization of territories to train for war. Furthermore, the\nblog was asking people to protest against the exercise.\n3.2 Case Study 2: Anti-NATO Propaganda During the 2015\nDragoon Ride Exercise\nWhat Was the Propaganda On 21 March 2015, US soldiers assigned to the 3rd\nSquadron, 2nd Cavalry Regiment in Estonia, Latvia, Lithuania, and Poland as part of\nOperation Atlantic Resolve began Operation Dragoon Ride. US troops, nicknamed\u2018Dragoons\u2019, initiated a military movement which stretched from the Baltics to\nGermany, crossing \ufb01ve international borders and covering more than 1100 miles.\nThis mission exercised the unit\u2019s maintenance and leadership capabilities and alsodemonstrated the freedom of movement that exists within NATO [ 46].\nMany opponent groups launched campaigns to protest the exercise, e.g., \u2018Tanks\nNo Thanks\u2019 [ 47], which appeared on Facebook and other social media sites,\npromising large and numerous demonstrations against the US convoy [ 48]. Czech\nPresident Milos Zeman expressed sympathy with Russia; his statements were\nechoed in the pro- Russian English language media and the Kremlin \ufb01nanced media,i.e., Sputnik news [ 49]. The RT website also reported that the Czechs were not\nhappy with the procession of the \u201cU.S.Army hardware\u201d [ 47]. However, thousands\nof people from the Czech Republic welcomed the US convoy as it passed throughtheir towns, waving US and NATO \ufb02ags, while the protesters were not seen.\nDuring that time many bots were disseminating propaganda, asking people to\nprotest and conduct violent acts against the US convoy. A group of these bots wasidenti\ufb01ed using Scraawl (available at www.scraawl.com ), an online social media\nanalysis product developed for bot detection and discourse analysis. It\u2019s an easy-\nto-use discovery tool of Intelligent Automation, Inc. for open source information.The link will provide you a free test subscription, if you\u2019d like to try it out yourself.\nWe collected data on this network of bots and studied its structure in an attempt to\nunderstand how they operated. Next, we provide a description of the dataset and our\ufb01ndings.\nData Collection We collected data for the period between 8 May 2015 and 3\nJune 2015 of 90 Twitter accounts that were identi\ufb01ed by Scraawl as bots known\nto disseminate propaganda during the Dragoon Ride Exercise. Out of the 90 Twitter\naccounts we were able to collect data from 73 accounts. We were not able to collect\n44 K. Galeano et al.\nFig. 4 Two sub-networks, S1 and S2. S1 is un-collapsed while S2 is collapsed. Edges in blue\ndenote mutually reciprocal relations (bidirectional edges) while edges in red color denote non-reciprocal relations (unidirectional edges)\ndata for 17 Twitter accounts because the accounts had been either suspended, did\nnot exist ,o rw e r e set to private . Data was collected using NodeXL\u2014an excel plugin\nfor social media data collection and analysis\u2014 that included: friend and follower\nrelations, tweet, mention, and reply relations. This resulted in 24,446 unique nodesand 31,352 unique edges. An \u2018edge\u2019 is a \u2018relationship\u2019, which can be a tweet,\nretweet, mention, reply, or friendship between two nodes (Twitter accounts). We\nobtained 50,058 non-unique edges with 35,197 friends and followers edges, 14,428tweet edges, 358 mention edges, and 75 reply edges.\nAnalysis of Case Study 2 We analyzed the friend/follower networks (social\nnetwork) of the bot accounts. We applied the Girvan-Newman clustering algorithm[30] to this network and found that the network had two clusters, S1 and S2, as\nshown in Fig. 4.\nThe clusters are the same as the components in this graph. The smaller S2 cluster,\ncontaining only a triad of nodes, was rejected from further analysis, as it did not\ncontribute much to the information diffusion. Since the larger S1 cluster contained\nthe majority of nodes, we examined this sub-network further.\nZooming in for a closer examination of the S1 cluster revealed that the members\nof that network were more akin to a syndicate network, i.e., a network that has\ndense connections among their members and inter-group connections with the othernodes and do not have a most central node, i.e., no hierarchy. Further examination\nof the nodes in S1 revealed a mutually reciprocated relationship (the nodes followed\neach other), suggesting that the principles of \u2018 Follow Me and I Follow You\u2019\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 45\n(FMIFY) and \u2018I Follow You, Follow Me\u2019 (IFYFM) \u2014a well-known practice used\nby Twitter spammers for \u2018link farming\u2019, or quickly gaining followers [ 50,51]w e r e\nin practice\u2014a behavior that was also observed during other study we conducted onthe Crimean Water Crisis botnet [ 52,53].\nThis network had no central node or no start-shaped network. In other words,\nthere was no single node feeding information to the other bots, or seeder ofinformation (this was determined using indegree centrality measure). This indicated\nthe absence of a hierarchical organizational structure in the S1 network, in other\nwords no seeder was identi\ufb01ed/observed. In cases where the seeder is not easilyidenti\ufb01able, other, more sophisticated methods are warranted to verify if this\nbehaviour truly does not exist. Although there might not be a single most in\ufb02uential\nnode, a group of bots may be coordinating to make an in\ufb02uential group. To studythis behaviour further, we applied the Focal Structures Analysis (FSA) approach to\n\ufb01nd if any in\ufb02uential group of bots existed [ 54].\nFSA has been tested on many real world cases such as the Saudi Arabian\nWomen\u2019s Right to Drive campaign on Twitter [ 55] and the 2014 Ukraine Crisis\nwhen President Viktor Yanukovych rejected a deal for greater integration with the\nEuropean Union and three big events followed\u2014Yanukovych was run out of thecountry in February, Russia invaded and annexed Crimea in March, and pro-Russian\nseparatist rebels in eastern Ukraine brought the relationship between Russia and\nthe West to its lowest point since the Cold War. Applying focal structures duringthe two aforementioned examples revealed interesting \ufb01ndings. It was proven that\nduring the Saudi Arabian Women\u2019s Right to Drive Twitter campaign on 26 October\n2013 the focal structures were more interactive than average individuals in theevolution of a mass protest, i.e., the interaction rate of the focal structures was\nsigni\ufb01cantly higher than the average interaction rate of random sets of individuals.\nIt was also proven that focal structures were more interactive than communitiesin the evolution of a mass protest, i.e., the number of retweets, mentions, and\nreplies increases proportionally with respect to the followers of the individuals in\ncommunities [ 29]. Applying the FSA approach to the Ukraine-Russia con\ufb02ict also\nrevealed an interesting \ufb01nding. By applying FSA to a blog-to-blog network, Graham\nW. Phillips [ 56]\u2014a 39-year-old British journalist and blogger\u2014was found to be\ninvolved in the only focal structure of the entire network along with ITAR-TASS, theRussian News Agency, and V oice of Russia, the Russian government\u2019s international\nradio broadcasting service. Even though other central and well-known news sources,\nsuch as the Washington Post and The Guardian, were covering the events, Phillipswas actively involved in the crisis as a blogger and maintained a single-author blog\nwith huge in\ufb02uence that compared with some of the active mainstream media blogs.\nPhillips covered the 2014 Ukraine crisis and became a growing star on Kremlin-owned media. He set out to investigate in a way that made him a cult micro-celebrity\nduring the crisis\u2014by interviewing angry people on the street for 90 s at a time [ 57].\nWhile the bot detection methodology used in this study is not 100% accurate,\nwe used tools that are commonly used by government agencies. A manual check of\naccounts identi\ufb01ed as bots by the tools used served as an additional veri\ufb01cation.\n46 K. Galeano et al.\nFig. 5 The social network (friends/followers network) of the botnets. The focal structure analysis\napproach helped in identifying a highly sophisticated coordinating structure, which is markedinside the blue circle in the \ufb01gure on left. Upon zooming-in on this structure (displayed on theright), two bots were identi\ufb01ed as the seeders in this focal structure. The seeder bots are depictedin blue\nFig. 6 Communication network (tweets, mentions, and replies network) of the botnets. Ten nodes\nwere communicating the most with the two most in\ufb02uential bots in the network\nWe ran the FSA approach on the Dragoon Ride data to discover the most\nin\ufb02uential set of bots or the seeders of information in the S1 community. By\napplying FSA to the social network of these bots we obtained one focal structure\ncontaining two nodes (see Fig. 5). These two nodes form the most in\ufb02uential set of\nbots in the network, i.e., by working together those two bots had a profound impact\non the dissemination of propaganda.\nWe further applied FSA to the bots\u2019 communication network, i.e., tweets,\nmentions, and replies network to identify who are the most communicative nodes in\nthis network (see Fig. 6). We obtained one focal structure containing 12 nodes. Ten\nnodes were \u2018real people nodes\u2019, i.e., nodes that communicated the most with bots\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO ... 47\n(potential seeders of information), while the other two nodes were the bots identi\ufb01ed\nas the most in\ufb02uential nodes in the friends and followers network.\nIn this case study, deviant groups used a sophisticated tool to disseminate their\npropaganda and speed up the dissemination process by using botnets. These botnets\nwere very sophisticated compared to a study we previously conducted on the use of\nsocial bots during the Crimean water crisis in 2014 [ 52,53]. The network structure\nof the botnets in the latter case is much more complex than in the former. Botnets in\nthe Dragoon Ride exercise case required a more sophisticated approach to identify\nthe organizers or seeders of information, i.e., it required applying FSA to both thesocial network (friends/followers network) and the communication network (tweets,\nreplies, and mentions network). The evolution of complexity in the bots\u2019 network\nstructures con\ufb01rms the need for a systematic study of botnet behavior to developsophisticated approaches/techniques or tools that can deal with predictive modelling\nof botnets.\n4 Conclusion\nIn conclusion, the rapid advancement of technology has made people more con-\nnected than ever before. Internet, especially social media, has enabled the \ufb02owof information at unprecedented rates. This ampli\ufb01cation is observed more in the\nspread of misinformation, fake or inaccurate news, and propaganda. Conducting\ndeviant acts has become more convenient, effective, and rapid. Deviant groupscan coordinate cyber campaigns in order to achieve strategic goals, in\ufb02uence mass\nthinking, and steer behaviors or perspectives about an event in a highly coordinated\nand sophisticated manner that remains largely undetected.\nIn this chapter, we provided two important and detailed case studies, namely\nthe NATO\u2019s 2015 Trident Juncture Exercise (TRJE 2015) and 2015 Dragoon\nRide Exercise. We study the online deviant groups (ODGs) and their behavior inconducting deviant acts, especially disseminating propaganda against NATO during\nthe two exercises. We analyzed situational awareness of the real-world information\nenvironment in/around those events by employing computational social networkanalysis and social cyber forensics informed methodologies. These methodologies\nhelp identify information competitors who seek to take the initiative and the strategic\nmessage away from the main event in order to further their own agenda. We describeour methodology, analysis (node-level, group-level analysis, and content-level), and\nresults obtained in both case studies. We further study how ODGs use social media\nin coordinating cyber propaganda campaigns. The research offered many interesting\ufb01ndings and were of great bene\ufb01t to NATO and U.S. forces participating in both\nexercises on the ground.\n48 K. Galeano et al.\nAcknowledgment This research is funded in part by the U.S. National Science Foundation (IIS-\n1636933, ACI-1429160, and IIS-1110868), U.S. Of\ufb01ce of Naval Research (N00014-10-1-0091,N00014-14-1-0489, N00014-15-P-1187, N00014-16-1-2016, N00014-16-1-2412, N00014-17-1-2605, N00014-17-1-2675), U.S. Air Force Research Lab, U.S. Army Research Of\ufb01ce (W911NF-16-1-0189), U.S. Defense Advanced Research Projects Agency (W31P4Q-17-C-0059), the JerryL. Maulden/Entergy Fund at the University of Arkansas at Little Rock, the Arkansas ResearchAlliance, and Creighton University\u2019s College of Arts and Sciences. Any opinions, \ufb01ndings, andconclusions or recommendations expressed in this material are those of the authors and do notnecessarily re\ufb02ect the views of the funding organizations. The researchers gratefully acknowledgethe support.\nReferences\n1. Professor describes Atari\u2019s impact on gaming world. Technique, http://nique.net/life/2009/02/\n20/professor-describes-ataris-impact-on-gaming-world/ . Accessed 1 May 2018\n2. M. Zuckerberg, Biography.com, https://www.biography.com/people/mark-zuckerberg-507402 .\nAccessed 3 May 2018\n3. C. Gallo, Jeff Bezos banned powerpoint in meetings. His replacement is brilliant.\nInc.com (2018), https://www.inc.com/carmine-gallo/jeff-bezos-bans-powerpoint-in-meetings-\nhis-replacement-is-brilliant.html . Accessed 28 Apr 2018\n4. D. V olkov, Supporting a war that isn\u2019t: Russian public opinion and the Ukraine con\ufb02ict.\nCarnegie Moscow Center (2015), https://carnegie.ru/commentary/61236 . Accessed 9 Jan 2019\n5. D.V . Gioe, Cyber operations and useful fools: the approach of Russian hybrid intelligence.\nIntell. Natl. Secur. 33, 954\u2013973 (2018). https://doi.org/10.1080/02684527.2018.1479345\n6. S. Tatham, Strategic Communication: A Primer (Defence Academy of the United Kingdom,\nCon\ufb02ict Studies Research Centre, Camberley, 2008)\n7. S.P. Borgatti, Centrality and network \ufb02ow. Soc. Networks 27, 55\u201371 (2005). https://doi.org/\n10.1016/j.socnet.2004.11.008\n8. M.K. Sparrow, The application of network analysis to criminal intelligence: an assess-\nment of the prospects. Soc. Networks 13, 251\u2013274 (1991). https://doi.org/10.1016/0378-\n8733(91)90008-h\n9. R.B. Cialdini, In\ufb02uence: Psychology of Persuasion (Collins Business, New York, 1993)\n10. Senior Research Psychologist \u2013 Connections, amazon.jobs, https://www.amazon.jobs/en/jobs/\n655074/senior-research-psychologist-connections . Accessed 20 May 2018\n11. R.A. Rodr\u00edguez-G\u00f3mez, G. Maci\u00e1-Fern\u00e1ndez, P. Garc\u00eda-Teodoro, Survey and taxonomy of\nbotnet research through life-cycle. ACM Comput. Surv. 45, 1\u201333 (2013). https://doi.org/\n10.1145/2501654.2501659\n12. M.S. Ackerman, J. Muramatsu, D.W. Mcdonald, Social regulation in an online game, in\nProceedings of the 16th ACM International Conference on Supporting Group Work - GROUP10(2010). https://doi.org/10.1145/1880071.1880101\n13. S. Hegelich, D. Janetzko, Are social bots on Twitter political actors? Empirical evidence from\na Ukrainian social botnet, in Proceedings of the Tenth International AAAI Conference on Web\nand Social Media (International AAAI Conference on Web and Social Media (ICWSM-16)(2016)\n14. A. Karasaridis, B. Rexroad, D. Hoe\ufb02in, Wide-scale botnet detection and characterization, in\nProceedings of the First Conference on First Workshop on Hot Topics in Understanding Botnets(HotBots\u201907) (USENIX Association, Berkeley, CA, 2007), p. 7-7\n15. N. Abokhodair et al., Dissecting a social botnet: growth, content and in\ufb02uence in Twitter, in\nProceedings of the 18th ACM Conference on Computer Supported Cooperative Work & SocialComputing, CSCW \u201915 , ed. by D. Cosley et al. (ACM, New York, 2015), pp. 839\u2013851\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO. . . 49\n16. S. Al-khateeb, N. Agarwal, Examining botnet behaviors for propaganda dissemination: a case\nstudy of ISIL\u2019s beheading videos-based propaganda, in Proceedings of the Behavior Analysis,\nModeling, and Steering (BEAMS 2015) co-located with the IEEE International Conference onData Mining (ICDM 2015) (2015)\n17. Z. Chu et al., Who is tweeting on Twitter: human, bot, or cyborg? in Conference, 2010 Annual\nComputer Security Applications Conference (ACSAC 2010), Austin, TX, USA - December 06 -10, 2010 (ACM, New York, 2010), pp. 21\u201330\n18. G. Wang, M. Mohanlal, C. Wilson, X. Wang, M. Metzger, H. Zheng, B.Y . Zhao, Social\nturing tests: crowdsourcing sybil detection, in The Network and Distributed System Security\nSymposium (NDSS) (The Internet Society, 2013)\n19. E. Ferrara, O. Varol, C. Davis, et al., The rise of social bots. Commun. ACM 59, 96\u2013104 (2016).\nhttps://doi.org/10.1145/2818717\n20. V . Subrahmanian, A. Azaria, S. Durst, et al., The DARPA Twitter bot challenge. Computer 49,\n38\u201346 (2016). https://doi.org/10.1109/mc.2016.183\n21. N. Alherbawi, Z. Shukur, R. Sulaiman, Systematic literature review on data carving in digital\nforensic. Procedia Technol. 11, 86\u201392 (2013). https://doi.org/10.1016/j.protcy.2013.12.165\n22. K. Oyeusi, Computer Forensics (London Metropolitan University, London, 2009)\n23. M. Mulazzani, M. Huber, E. Weippl, Social network forensics: tapping the data pool of social\nnetworks, in Eighth Annual IFIP WG , vol. 11 (2012)\n24. N.A. Mutawa, I. Baggili, A. Marrington, Forensic analysis of social networking applications\non mobile devices. Digit. Investig. 9, S24 (2012). https://doi.org/10.1016/j.diin.2012.05.007\n25. N.A. Mutawa, I.A. Awadhi, I.M. Baggili, A. Marrington, Forensic artifacts of Facebook\u2019s\ninstant messaging service, in 2011 International Conference for Internet Technology and\nSecured Transactions (2011), pp. 771\u2013776\n26. K.M. Carley, J. Reminga, ORA: organization risk analyzer. Technical Report, Carnegie Mellon\nUniversity, School of Computer Science, Institute for Software Research International (2004),http://www.casos.cs.cmu.edu/publications/papers/carley_2004_oraorganizationrisk.pdf .\nAccessed 21 May 2018\n27. G. Cheliotis, Social network analysis. LinkedIn SlideShare (2010), https://www.slideshare.net/\ngcheliotis/social-network-analysis-3273045 . Accessed 25 May 2018\n28. S.F. Everton, Strategic options for disrupting dark networks, in Disrupting Dark Net-\nworks , (Cambridge University Press, New York, 2012), pp. 32\u201346. https://doi.org/10.1017/\ncbo9781139136877.004\n29. F. \u00b8 Sen, R. Wigand, N. Agarwal, et al., Focal structures analysis: identifying in\ufb02uential sets of\nindividuals in a social network. Soc. Netw. Anal. Min. 6, 17 (2016). https://doi.org/10.1007/\ns13278-016-0319-z\n30. M. Girvan, M.E.J. Newman, Community structure in social and biological networks. PNAS\n99(12), 7821\u20137826 (2002)\n31. V .D. Blondel, J.-L. Guillaume, R. Lambiotte, E. Lefebvre, Fast unfolding of communities in\nlarge networks. J. Stat. Mech: Theory Exp. 2008 , P10008 (2008). https://doi.org/10.1088/1742-\n5468/2008/10/p10008\n32. P. Jaccard, The distribution of the \ufb02ora in the alpine zone. New Phytol. 11(2), 37\u201350 (1912)\n33. N. Agarwal, H. Liu, L. Tang, P.S. Yu, Identifying the in\ufb02uential bloggers in a community, in\nProceedings of the International Conference on Web Search and Web Data Mining - WSDM08(2008). https://doi.org/10.1145/1341531.1341559\n34. N. Agarwal et al., Modeling blogger in\ufb02uence in a community. Soc. Netw. Anal. Min. 2(2),\n139\u2013162 (2012)\n35. S. Kumar et al., Convergence of in\ufb02uential bloggers for topic discovery in the blogosphere, in\nInternational Conference on Social Computing, Behavioral Modeling, and Prediction , ed. by\nS.-K. Chai et al. (Springer, Berlin 2010), pp. 406\u2013412\n36. A. Java, P. Kolari, T. Finin, T. Oates, Modeling the spread of in\ufb02uence on the blogosphere, in\nProceedings of the 15th International World Wide Web Conference (2006), pp. 22\u201326\n50 K. Galeano et al.\n37. K.E. Gill, How can we measure the in\ufb02uence of the blogosphere, in WWW 2004 Workshop on\nthe Weblogging Ecosystem: Aggregation, Analysis and Dynamics (2004)\n38. A.J. Girao, Tried and tested, in NATO Summit 2016 \u2013 Strengthening Peace and Security (2016),\npp. 105\u2013107\n39. Sputnik, Activistas espa\u00f1oles preparan movilizaciones contra la OTAN. Sputnik Mundo\n(2015), http://mundo.sputniknews.com/espana/20150819/1040501131.html . Accessed 20 Aug\n2015\n40. Sputnik, Nato-Soldaten trainieren Kampf in sozialen Netzwerken. Sputnik Deutschland (2015),\nhttp://de.sputniknews.com/militar/20150828/304057978.html . Accessed 2 Sep 2015\n41. Sputnik, NATO drills jeopardize Spanish residents\u2019 health, environment - politician. Sput-\nnik International (2015), http://sputniknews.com/military/20150902/1026475239/nato-drills-\nzaragoza.html . Accessed 2 Sep 2015\n42. L. Alexander, Open-source information reveals pro-kremlin web campaign. Global V oices\n(2015), https://globalvoices.org/2015/07/13/open-source-information-reveals-pro-kremlin-\nweb-campaign . Accessed 21 May 2018\n43. M. Bazzell, Open Source Intelligence Techniques: Resources for Searching and Analyzing\nOnline Information (Createspace Independent Publishing, Charleston, 2016)\n44. B. Etling, J. Kelly, R. Faris, J. Palfrey, Mapping the Arabic blogosphere: politics, culture, and\ndissent , vol 6 (Berkman Center for Internet & Society, Cambridge, 2009)\n45. R.B. Standler, Propaganda and how to recognize it (RBS0), www.rbs0.com/propaganda.pdf .\nAccessed 2 Sep 2005\n46. Operation Atlantic Resolve Exercises Begin in Eastern Europe. U.S. Department\nof Defense. https://www.defense.gov/News/Article/Article/604341/operation-atlantic-resolve-\nexercises-begin-in-eastern-europe/ . Accessed 21 May 2018\n47. \u2018Tanks? No thanks!\u2019: Czechs unhappy about US military convoy crossing country. RT Interna-\ntional. https://www.rt.com/news/243073-czech-protest-us-tanks/ . Accessed 21 May 2018\n48. D. Sindelar, U.S. Convoy, in Czech Republic, Real-Life Supporters Outnumber Virtual\nOpponents, Radio Free Europe/Radio Liberty (2015)\n49. Sputnik, Czechs plan multiple protests of US Army\u2019s \u2018operation dragoon ride\u2019. Sputnik Inter-\nnational (2015), https://sputniknews.com/europe/201503281020135278/ . Accessed 21 May\n2018\n50. S. Ghosh, B. Viswanath, F. Kooti, et al., Understanding and combating link farming in the\ntwitter social network, in Proceedings of the 21st international conference on World Wide Web\n- WWW 12 (2012). https://doi.org/10.1145/2187836.2187846\n51. V . Labatut, N. Dugue, A. Perez, Identifying the community roles of social capitalists in the\nTwitter network, in 2014 IEEE/ACM International Conference on Advances in Social Networks\nAnalysis and Mining (ASONAM 2014) (2014). https://doi.org/10.1109/asonam.2014.6921612\n52. S. Al-Khateeb, N. Agarwal, Understanding strategic information manoeuvres in network media\nto advance cyber operations: a case study analysing pro-Russian separatists\u2019 cyber informationoperations in Crimean water crisis. J. Balt. Secur. 2, 6 (2016). https://doi.org/10.1515/jobs-\n2016-0028\n53. N. Agarwal, S. Al-Khateeb, R. Galeano, R. Goolsby, Examining the use of botnets and their\nevolution in propaganda dissemination. Def. Strateg. Commun. 2, 87\u2013112 (2017). https://\ndoi.org/10.30966/2018.riga.2.4\n54. \u00b8Sen F, Wigand R, Agarwal N, et al., Focal Structure Analysis in Large Biological Networks, in\nIPCBEE (2014 3rd International Conference on Environment Energy and Biotechnology) ,v o l .\n70 (IACSIT Press, Singapore, 2014), p. 1\n55. S. Yuce et al., Studying the evolution of online collective action: Saudi Arabian Women\u2019s\n\u201cOct26Driving\u201d Twitter campaign, in International Conference on Social Computing,\nBehavioral-Cultural Modeling, and Prediction , ed. by W.G. Kennedy et al. (Springer, Cham,\n2014), pp. 413\u2013420\nStudying the Weaponization of Social Media: Case Studies of Anti-NATO. . . 51\n56. Graham Phillips is a British national contracted as a stringer by the Russian Times (RT). He\nhas produced numerous videos, blogs, and stories in and around eastern Ukraine. He speaksand writes in Russian and English in his reports. He recently spent time covering the WorldCup in Brazil for RT and has re-entered Eastern Ukraine as of July 2014. RT reported on thatPhillips was deported from Ukraine because he works for RT. He will not be allowed to re-enterUkraine for three years.\n57. M. Seddon, How a British blogger became an unlikely star of the Ukraine con\ufb02ict - and Russia\nToday. BuzzFeed, https://www.buzzfeed.com/maxseddon/how-a-british-blogger-became-an-\nunlikely-star-of-the-ukraine?utm_term=.poaNaBd7w#.ikzWz90Ny . Accessed 21 May 2018\nYou Are Known by Your Friends:\nLeveraging Network Metrics for Bot\nDetection in Twitter\nDavid M. Beskow and Kathleen M. Carley\nAbstract Automated social media bots have existed almost as long as the social\nmedia platforms they inhabit. Although efforts have long existed to detect and\ncharacterize these autonomous agents, these efforts have redoubled in the recent\nmonths following sophisticated deployment of bots by state and non-state actors.\nThis research will study the differences between human and bot social communica-\ntion networks by conducting an account snow ball data collection, and then evaluate\nnetwork, content, temporal, and user features derived from this communication\nnetwork in several bot detection machine learning models. We will compare this\nmodel to the other models of the bot-hunter toolbox as well as current state of the\nart models. In the evaluation, we will also explore and evaluate relevant training\ndata. Finally, we will demonstrate the application of the bot-hunter suite of tools in\nTwitter data collected around the Swedish National elections in 2018.\n1 Introduction\nAutomated and semi-automated social media accounts have been thrust into\nthe forefront of daily news as they became associated with several publicized\nnational and international events. These automated accounts, often simply called\nbots (though at times called sybils ), have become agents within the increasingly\nglobal marketplace of beliefs and ideas. While their communication is often less\nsophisticated and nuanced than human dialogue, their advantage is the ability to\nconduct timely informational transactions effortlessly at the speed of algorithms.\nThis advantage has led to a variety of creative automated agents deployed for\nbene\ufb01cial as well as harmful effects. While their purpose, characteristics, and\n\u201cpuppet masters\u201d vary widely, they are undeniably present and active. Their effect,\nwhile dif\ufb01cult if not impossible to measure, is tangible.\nD. M. Beskow (/envelopeback)\u00b7K .M .C a r l e y\nSchool of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA\ne-mail: dbeskow@andrew.cmu.edu ;kathleen.carley@cs.cmu.edu\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_353\n54 D. M. Beskow and K. M. Carley\nAutomated and semi-automated accounts are used for a wide variety of reasons,\ncreating effects that can be positive, nuisance, or malicious. Examples of positive\nbots include personal assistants andnatural disaster noti\ufb01cations . Nuisance bots are\ntypically involved in some type of \u2018spam\u2019 distribution or propagation. The spam\ncontent ranges from commercial advertising to the distribution of adult content.\nMalicious bots are involved in propaganda [ 52], suppression of dissent [ 64], and\nnetwork in\ufb01ltration/manipulation [ 8].\nMalicious bots have recently gained wide-spread notoriety due to their use in\nseveral major international events, including the British Referendum known as\u201cBrexit\u201d [ 43], the American 2016 Presidential Elections [ 13], the aftermath of\nthe 2017 Charlottesville protests [ 35], the German Presidential Elections [ 55], the\ncon\ufb02ict in Yemen [ 7], and recently in the Malaysian presidential elections [ 4]. These\naccounts attempt to propagate political and ideological messaging, and at times\naccomplish this through devious cyber maneuver.\nAs these bots are used as one line of effort in a larger operation to manipulate\nthe marketplace of information, beliefs, and ideas, their detection and neutralization\nbecome one facet of what is becoming known as social cyber security .C a r l e ye ta l .\nis the \ufb01rst to use this term, and de\ufb01nes it as:\nSocial Cyber-security is an emerging scienti\ufb01c area focused on the science to characterize,\nunderstand, and forecast cyber-mediated changes in human behavior, social, cultural andpolitical outcomes, and to build the cyber-infrastructure needed for society to persist in itsessential character in a cyber-mediated information environment under changing conditions,actual or imminent social cyber-threats. [ 18]\nWithin social cyber security , bot detection and neutralization are quickly becom-\ning a cat and mouse cycle where detection algorithms continuously evolve trying to\nkeep up with ever-evolving bots. Early detection algorithms exploited the automated\ntiming, arti\ufb01cial network structure, and unoriginal meta-data of automated accounts\nin order to identify them. These features are relatively easy for bot puppet-masters tomanipulate, and we are now seeing automated accounts that have meaningful screen\nnames, richer pro\ufb01le meta-data, and more reasonable content timing and network\ncharacteristics.\nWe are also seeing an increasing number of accounts that we call \u201cbot assisted\u201d\nor \u201chybrid\u201d accounts (also at times called \u201ccyborg\u201d accounts). Although researchers\noften attempt a binary classi\ufb01cation of botorhuman , the reality is that there is a\nspectrum of automated involvement with an account. Many accounts are no longer\nstrictly automated (all content and social transactions executed by a computer).\nThese accounts will have human intervention to contribute nuanced messaging totwo-way dialogue, but will have a computer executing a variety of tasks in the\nbackground. Grimme et al. [ 38] discusses this spectrum in detail, describing how\n\u2018social bots\u2019 are created, used, and how \u2018hybridization\u2019 can be used to bypassdetection algorithms (in their case successfully bypassing the \u2018Botornot\u2019 algorithm\ndiscussed later in this paper).\nWe hypothesize that bots are not involved in social networks and social commu-\nnication in the same way that humans are, and that this difference is measurable.\nLike other complex systems (natural ecosystems, weather systems, etc), social\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 55\ninteraction and relationships are the result of myriads of events and stimuli in both\nthe real and virtual worlds. Because bots lack real world engagement and social\nenvironments, they embed in different networks than humans.\nMany bots are programmed to interact with each other as a bot network, and\nattempt to interact with humans, but many features of these interactions will be\n\u2018robotic\u2019. Even \u2018hybrid\u2019 accounts will have some level of arti\ufb01cial and inorganicstructure and substance in their communications. This area of bot detection in\nTwitter is largely unexplored, primarily because the rich network data (both the\nfriends/followers network as well as their conversational network) are very timeconsuming to collect. We therefore set out to collect the data to characterize the\nsocial network(s) and social conversation(s) that a twitter account participates in,\ndescribe these networks with various network metrics, leverage these rich networkmetrics in traditional machine learning models, and evaluate whether the time\ninvolved creates substantial value.\n1.1 Research Questions\n1. Do bot Twitter accounts have fundamentally different conversational network\nstructures than human managed accounts?\n2. Do the conversations that surround bot accounts diverge from human conversa-\ntions in general substance and timing?\n3. Can the measured differences between bot and human conversation networks\nlead to increased accuracy in bot detection?\nThis paper will begin by discussing past bot detection techniques, as well as\nsummarize historical techniques for extracting features from network structures.Next we discuss our data collection, data annotation, and methodology for creating\nego-network metrics. We describe training and testing our bot-hunter machine\nlearning algorithms and present our results. We construct an evaluation to compareall bot-hunter models against the state of the art. Finally, we will demonstrate the\napplication of the bot-hunter suite of tools in the 2018 Swedish National elections,\nproviding a possible work\ufb02ow to open source intelligence practitioners.\nThis chapter is an extension of [ 10], with a focus of extending the feature space\nbeyond network metrics to include content and temporal metrics of the larger ego\nnetwork. Several of these features are novel, including a cascaded classi\ufb01er thatidenti\ufb01es portion of alters that are likely bots, portion of alters that don\u2019t have normal\ndaily rhythms, as well as portion of ego network that produces tweets that are more\npopular than the account itself. All of these have been documented as attributes ofbots, and we\u2019ve coded them into features in this algorithm. Additionally, we used\nthe larger models to explore several new bot data sets. Finally, this extension will\ncompare all of the bot-hunter suite of tools against state of the art models.\n56 D. M. Beskow and K. M. Carley\n2 Related Work\n2.1 Understanding Data Tiers\nIn earlier research our team proposed a tiered approach to bot detection [ 11] that\nmirrors the data tiers introduced below. This tiered approach creates a \ufb02exiblebot-detection \u201ctool-box\u201d with models designed for several scenarios and data\ngranularities. Tier 0 builds models on a single entity (usually a tweet text or user\nscreen name). Tier 1 builds models based on features extracted from the basicTweet object (and associated user object). Tier 2 extracts features from a users\u2019\ntimeline, and Tier 3 (explained in this paper) builds features from the conversation\nsurrounding a user. Higher tier models are generally more accurate, but consumemore data and are therefore computationally expensive. Some research requires bot\ndetection at such a scale, that models based on Tier 0 or Tier 1 are the only feasible\noption. At other times, highly accurate classi\ufb01cation of a few accounts is required. Inthese cases, models based on Tier 2 or Tier 3 data are preferred. This paper proposes\nan approach to Tier 2\u20133 bot detection that builds on the previous Tier 0 [ 12] and Tier\n1[11] research and relies heavily on network metrics collected through single seed\nsnowball sampling. We will view past research in bot detection through the lens of\nthese Tiers (Table 1).\nSince the early efforts to conduct bot/spam detection, numerous teams have\ndeveloped a variety of models to detect these. While similar, these models will differ\nbased on the underlying data they were built on (for example many community\ndetection and clickstream models were developed for Facebook, while the over-whelming majority of models built on Twitter data use Supervised and Unsupervised\nMachine learning [ 1]). Even in Twitter bot detection, these models can be grouped\nby either the models/methods or by the data that they use. We have provided Table 2\nto outline the connection between past models and the data that they use.\nAdewole et al. [ 1] reviewed 65 bot detection articles (articles from 2006\u20132016)\nand found that 68% involved machine learning, 28% involved graph techniques(note that these include some machine learning algorithms that rely heavily on\nTable 1 Four tiers of Twitter data collection to support account classi\ufb01cation (originally pre-\nsented in [ 11])\nTier Description FocusCollection\ntime per 250accounts#o fD a t aentities(i.e. tweets)\nTier 0 Tweet text only Semantics N/Aa1\nTier 1 Account +1 Tweet Account meta-data \u223c1.9s 2\nTier 2 Account +Timeline Temporal patterns \u223c3.7m i n 200+\nTier 3 Account +Timeline + Friends Timeline Network patterns \u223c20 h 50,000 +\naThis tier of data collection was presented by Kudugunta and Ferrara [ 47] and assumes the status\ntext is acquired outside of the Twitter API\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 57\nTable 2 Table of Twitter Bot detection models and the data that they use\nMachine learning\nData Community detection Supervised Unsupervised Crowd sourcing\nTier 0 Text [12,47] [48]\nTier 1 + Pro\ufb01le [22,49] [33]\nTier 2 + History [63] [20]\nTier 3 + Snowball [8] No known research [66]\nStream [3,14]\nnetwork metrics), and 4% involved crowd-sourcing. Below we will summarize the\nsalient works under each of these modeling techniques.\n2.2 Machine Learning Techniques\nAs noted above, Twitter bot detection has primarily used Machine Learning models.Thesupervised machine learning models used for bot detection include Na\u00efve Bayes\n[22], Meta-based [ 49], SVM [ 48], and Neural Network [ 47]. The unsupervised\nmachine learning models used include hierarchical [ 48], partitional [ 33], PCA-\nbased [ 65], Stream-based [ 53], and correlated pairwise similarity [ 20]. Most of these\nefforts leverage data collected from the basic tweet object or user object ( what we\nwould de\ufb01ne as a Tier 0 orTier 1 model).\nIn 2014, Indiana University launched one of the more prominent supervised\nmachine learning efforts with the Bot or Not online API service [ 25] (the service\nwas recently rebranded to Botometer ). This API uses 1150 features with a random\nforest model trained on a collage of labeled data sets to evaluate whether or not an\naccount is a bot. Botometer leverages network, user, friend, temporal, content, and\nsentiment features with Random Forest classi\ufb01cation [ 28].\nIn 2015 the Defense Advanced Research Projects Agency (DARPA) sponsored a\nTwitter bot detection competition that was titled \u201cThe Twitter Bot Challenge\u201d [ 59].\nThis 4 week competition pitted four teams against each other as they sought toidentify automated accounts that had in\ufb01ltrated the informal Anti-Vaccine network\non Twitter. Most teams in the competition tried to use previously collected data\n(mostly collected and tagged with honey pots ) to train detection algorithms, and\nthen leverage tweet semantics (sentiment, topic analysis, punctuation analysis, URL\nanalysis), temporal features, pro\ufb01le features, and some network features to create a\nfeature space for classi\ufb01cation. All teams used various techniques to identify initialbots, and then used traditional classi\ufb01cation models (SVM and others) to \ufb01nd the\nrest of the bots in the data set.\n58 D. M. Beskow and K. M. Carley\n2.3 Other Techniques\nSeveral other novel bot detection methods exist outside of machine learning and\nnetwork based approaches. Wang et al. [ 66] investigated the idea of Crowd Sourcing\nbot detection. While showing limited success, it was costly at scale, and usually\nrequired multiple workers to examine the same account. Another unique type ofunsupervised learning involves algorithms that \ufb01nd and label correlated accounts.\nMost bots are not deployed by themselves. Even if not deployed as a united bot-net,\nmany bot herders often task multiple bots to perform the same operations. Chavoshi\net al. [ 20] has leveraged the semantic and temporal similarity of accounts to identify\nbots in an unsupervised fashion, creating the Debot model which we will compare\nagainst in our results section.\n2.4 Network Based Techniques\nNetworks are an extremely important part of bots, bot behavior and bot detection.Aiello et al. [ 2] discusses the impact of bots on in\ufb02uence, popularity, and network\ndynamics. Adewole et al. [ 1] highlights that network features are robust to criminal\nmanipulation.\nOne approach to leveraging network structure involves community based\nbot/sybil detection. While community detection has been effectively implemented\non Facebook [ 67] and Seino Weibo [ 51], it has only recently been used on Twitter\nData due the strict friend/follower rate limiting discussed above. Only recently\nhas Benigni et al. [ 9] used dense subgraph detection to \ufb01nd extremists and their\nsupporting bots in Twitter.\nMost research that uses networks for bot detection with Twitter Data are in fact\ncreating network based metrics and introducing these features in traditional machine\nlearning models. As discussed below, the most challenging part of this type ofresearch is focused on how to build networks from limited data. The closest works\nto ours were performed by Bhat and Abulaish [ 14] in 2013 and [ 3] in 2016. Both\nresearch efforts used network features along with pro\ufb01le and temporal features froma Twitter Sample Stream without any snowball sampling enrichment. They created\nan egocentric network that involved ego, alters, with links between alters for both\nfollowing and mention ego centric networks. Having done this, they calculated con-tent, pro\ufb01le, and social interaction features. Their network features were restricted\nto centrality measures, density measures, and weak and strongly connected compo-\nnents. A similar earlier work by Bhat and Abulaish [ 14] attempts to use community\nfeatures (number of communities, core/periphery, foreign in/out degree, etc). This\nwas applied to both Facebook data and the Enron email data (not to Twitter).\nAdditionally, the Botometer algorithm leverages some network features extracted\nfrom the user timeline. This includes metrics on the retweet network, mention\nnetwork, and hashtag co-occurrence network. The metrics include density, degree\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 59\ndistributions, clustering coef\ufb01cient, and basic network characteristics. The Botome-\nteralgorithm does not conduct a snowball collection of friends orfollowers ,b u t\ndoes appear to collect user objects for accounts found in the timeline as a retweet or\nmention [28].\n2.5 Building Networks with Twitter Data\nAs noted above, however, it is dif\ufb01cult to quickly build comprehensive network\nstructure with Twitter data due the Twitter API rate limits, primarily associated with\ncollecting friend/follower ties. Researchers have generally used one of two methods\nto build limited networks.\nThe \ufb01rst method is used if the research team has a large sample or stream. These\nsamples may be random (collected from the 1% Twitter Sample) or they may be\nassociated with an event or theme (i.e. collecting all Tweets that have a givenhashtag like #hurricanesandy). These researcher then build ego-centric networks\nfrom this stream, without collecting any additional data from the Twitter API. This\nhas the advantage of speed, and doesn\u2019t suffer from issues getting data for suspendedaccounts. This method, however, will only model a small portion of an account\u2019s\nactivity and network. A 1% sample will arguably contain marginal activity for given\naccount, and even topical streams will only contain a small part of an account\u2019sactivity, given that they are involved in multiple topics and discussions. These small\nsamples may not be rich enough to serve as strong features for machine learning.\nThe second method that researchers use is to only collect the users timeline\n(history of tweets, up to last 3200). They then build an ego-centric network from\nthis data (variously using replies, retweets, hashtags, urls, and mentions to build\nnetworks). This is much richer than the \ufb01rst method, contain all of the users activity,but still lacks any information beyond that individual, providing the limited star\ngraph illustrated in Fig. 1. It doesn\u2019t contain the larger conversation(s) that they are\nparticipating in. Additionally, a bots\u2019s timeline is completely managed by the bot\npuppet master , and therefore can be manipulated to avoid detection.\nTo date our team has not found supervised learning bot detection research that\nleverages extensive snowball sampling to build ego networks.\n2.6 Extracting Features from Social Networks\nEvaluating network centrality measures, started by Bavelas in 1948 [ 6] and effec-\ntively clari\ufb01ed by Freeman in 1978 [ 31], has long been an important metric\nfor evaluating both nodes and networks. According to Freeman, network-level\ncentrality metrics measure the \u201ccompactness\u201d of the network. Our model includes\nseveral network centrality measures: degree centrality, k-betweenness [ 5], and\neigenvector centrality [ 45] are used to measure differing \u201ccompactness\u201d between\nhuman and bot conversation networks.\n60 D. M. Beskow and K. M. Carley\nSeveral seminal works describe the importance of triadic relationships in social\nnetworks [ 19,40] and as a foundation for measuring network clustering and groups\n[42]. The fact that the study of triadic relationship has almost exclusively been con-\ntained within the study of social interaction provides evidence that these observed\ntriadic relationships are unique to human behavior. We have therefore included\nseveral features based on these triadic relationships, including the full triadic census[41], number of Simmelian Ties [ 26,46], and clustering coef\ufb01cient. We also\nincluded reciprocity based on Mislove et al.\u2019s [ 54] examination of reciprocity in\nonline social networks.\nIn addition to \ufb01nding network centrality and triadic structures, network com-\nmunity detection has been an important aspect of network characterization, and\nis still an active research area. Current group detection techniques generally fallinto traditional methods, divisive methods, modularity based methods, statistical\ninference methods, and dynamic methods [ 29]. Our community detection features\nleverage Louvain Clustering [ 16], which is based on modularity optimization.\nOur approach uses network sampling in order to restrict the time of computation.\nWhile research in network sampling started in the 1970s with work from [ 30] and\nothers, the emergence of Online Social Networks (OSN\u2019s) increased the size ofnetworks and the need for sampling. Our approach to sampling ego networks was\ninformed by Gjoka [ 34]. Our sampling uses breadth-\ufb01rst-search (BFS) on the target\nnode. The known bias of BFS is eliminated because we are only conducting twohops from the target (only includes friends of alters).\nFinally, the study of ego networks is a special branch of social network analysis\nthat is relevant to our study. In 1972, [ 37] presented the classic concept of the\n\u201cStrength of Weak Ties\u201d in ego networks, which [ 17] clari\ufb01ed is more due to the\nstructural location of ties, and can be measured by effective size, ef\ufb01ciency, and\nconstraint. This informed our use of ego network effective size in our features space.Additionally, Centrality of ego-networks was explored by Freeman [ 32] in 1982\ninforming our use of betweenness in the feature space.\n2.7 Contributions of This Work\nWhile we discuss above several other research attempts to use network metrics ina bot detection feature space, these have largely relied on the mention network\nextracted from any Twitter query/stream. Ego-centric networks built on a singlestream/query arguably contain only a small subset of the overall account ego\nnetwork. Researchers have not attempted to build this ego network based on\nsnowball sampling [ 36] with a seed node since this requires signi\ufb01cant time given\nthe extent of the data and the strict API rate limits that Twitter imposes on\nfriend/follower data. Our research has taken the time to build this rich conversational\nnetwork in a novel way, and then evaluate whether the time and effort rendersuf\ufb01cient value.\nHaving built this extensive network for every account in question, this work\nattempts to fully exploit all available features, going above and beyond just\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 61\nstructural features. These additional features include content, temporal, and user\nsummary features. Adding the full range of additional features allows us to fully\nevaluate the increased accuracy against the additional computational cost.\nThis work additionally creates and explores bot detection metrics that require\ngreater effort and sophistication to circumvent. Currently, bot-herders can circum-\nvent current algorithms by changing their screen name, adding account meta-data,spending additional time selecting a unique pro\ufb01le picture, and creating a more\nrealistic tweet inter-arrival time. They can also deploy bots in bot networks,\ntherefore arti\ufb01cially manipulating friend/follower values to appear like they arepopular. However, it will arguably require signi\ufb01cantly more sophistication to\nchange the centrality, components, or triadic relationships in the conversations\nthat they participate in. By increasing the cost to deploy and operate bots, it mayeconomically force \u201cbot-herders\u201d out of their devious market.\nFinally, the bot-hunter framework builds on the multi-tiered bot detection\napproach that we introduced in [ 11]. This multi-tiered approach provides\nresearchers and government or non-governmental agencies with a \u201ctool-box\u201d of\nmodels designed for different classes of bots as well as different scales of data\n(designed for either high volume of high accuracy). This multi-tiered approachacknowledges that there is not a one-size \ufb01ts all model/approach that will work for\nall bot detection requirements. By merging and expanding on past bot detection\nresearch, we can create an easy to use \u201ctool box\u201d that can address several bot-detection requirements. The evaluation provided later in this paper will demonstrate\nthat key models in the bot-hunter suite of tools are equivalent or better than state of\nthe art models.\n3 Data\nOur team used the Twitter REST and Streaming API\u2019s to access the data used in thisresearch effort. Details of this process are provided below.\n3.1 Overview of Available Data\nResearch is loosely divided between account-focused data collection strategies and\ntopical or stream based collection strategies. Account based approaches will only\nuse data objects directly tied to the user (user JSON object, user time-line object,etc). Stream-based approaches extract features from a given topical stream or twitter\nstream sample. These stream based features are often network features, but represent\na small fraction of the ego-centered network of a given account. Our researchtherefore pursues an account based approach to build a fuller representation of the\naccount\u2019s ego network.\n62 D. M. Beskow and K. M. Carley\nResearchers must \ufb01nd a balance between speed and richness of data. Past account\nfocused research generally falls into four tiers. Table 1provides a description for\neach tierof data collection, the estimated time it would require to collect this data for\n250 accounts, and the amount of data that would be available for feature engineering\nper account.\n3.2 Data Required for Account Conversation Networks\nDetailed ego network modeling of a Twitter account\u2019s social interactions requires\nTier 3 data collection, but to date our team has not found any research that hasconducted that level of data collection to model the network structures and social\nconversations that an automated Twitter account interacts with. In fact, few teams\ngo beyond basic in-degree (follower count) and out-degree (friend count) networkmetrics found in Tier 1 meta-data. The closest effort to date is the Botometer model,\nwhich arguably operates at Tier 2 . By adding the user timeline, Tier 2 provides\nlimited network dynamics, to include being able to model hashtag and URL co-mentions in a meta-network (see Fig. 1). The resulting timeline based network,\nhowever, lacks comprehensive links between alters. While the time-line can provide\nrich temporal patterns, we found that it lacked suf\ufb01cient structure to model the egonetwork of an actor.\nAgent\nTweet\nHashtag\nUrl\npowered by ORA\nFig. 1 Leveraging only user timeline provides limited network features in a star graph\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 63\nWe set about to build the social network and social conversations that a twitter\naccount is interacting with. We also tried to do this in a way that would expedite\nthe time it takes to collect the data and measure network metrics. Our initial goalwas to collect data, build the feature space, and classify an account within 5 min.\nWe selected the 5 min limit in an attempt to process \u223c250 accounts per day with a\nsingle thread\nTo collect the necessary data, we executed the following steps sequentially:\n1. Collect user data object\n2. Collect user timeline (last 200 tweets)\n3. Collect user followers (if more than 250, return random sample of 250 followers)\n4. Collect follower timelines (last 200 tweets)\nWhen complete, this data collection process (illustrated in Fig. 2) creates up to\n50,000 events (tweets) that represent the conversation and virtual social interaction\nthat the user and their followers participate in.\nThe resulting network, while partially built on social network structure (the\ninitial following relationship), is primarily focused on the larger conversation they\nparticipate in. We initiated the single seed snowball by querying followers rather\nSeed Node 1H o pS n o w b a l l 2 Hop Snowball\nfollowing\nretweet\nmention\nreply1Get user data\nand time-line2Get followers\n(max 250)3Get alter\ntime-lines\n1Getuserdata\nandtime-line e2Getfollowers\n(max250)3Getalter\ntime- lines\nFig. 2 Illustration of 2-hop snowball sampling: conversation of target node and followers. First\nget followers of target node (if more than 250, sample followers). Then get timelines of alters. Usetimelines to draw connections to accounts that alters retweet ,reply ,a n d mention\n64 D. M. Beskow and K. M. Carley\nthan friends since followers are much less controlled by the bot-herder, and contain\nfewer news and celebrity accounts. We conducted a timeline rather than followers\nsearch for the 2nd hop of the snowball to overcome rate-limiting constraints and tomodel the conversation network rather than directly model the social network. This\nsingle seed snowball process conducts a limited breadth-\ufb01rst-search starting with a\nsingle seed and terminating at a depth of 2.\nArti\ufb01cially constraining the max number of alters at 250 was a modeling\ncompromise that facilitates the self-imposed 5 min collect/model time horizon. The\nchoice of 250 allows our process to stay under 5 min, and also represents the upperbound of Dunbar\u2019s number (the number of individuals that one person could follow\nbased on extrapolations of neocortex size) [ 27]. Additionally, in evaluating a sample\nof 22 million twitter accounts, we found that 46.6% had less than 250 followers.This means that approximately 50% of accounts will have their entire ego network\nmodeled. Bots tend to have fewer followers than human accounts and from the\n297,061 annotated bot accounts that we had available for this research, 72.5% ofthem had fewer than 250 followers. Given that this compromise will only affect\n25% of the bot accounts and 50% of all accounts, we felt that it was appropriate.\nWe used this data to create an agent to agent network where links represent one\nof the following relationships: mention, reply, retweet. These collectively represent\nthe paths of information and dialogue in the twitter \u201cconversation\u201d. We intentionally\ndid not add the follow/friend relationships in the network (collected in the \ufb01rst\nhop of the snowball) since follow/friend relationships are an easy metric for bot\nherders to simulate and manipulate with elaborate bot nets. Complex conversations,\nhowever, are much harder to simulate, even in a virtual world. Additionally, addingthefollowing links between the ego and alters would have created a single large\nconnected graph. By leaving them out, we were able to easily identify the natural\nfragmentation of the social interaction.\n3.3 Visualizing Conversations\nDuring our initial exploration, we visualized these conversations for both human\naccounts and bot accounts. A comparison of these conversations is provided in\nFig.3. Note that bots tend to get involved in isolated conversations, and the followers\nof the bot are very loosely connected. The network created from a human virtualinteraction on Twitter, is highly connected due to shared friendship, shared interests,\nand shared experiences in the real world.\n3.4 Annotated Data\nFor annotated bot data, we combined several legacy annotated bot data sets as well\nas some that our team has annotated during the development of the bot-hunter\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 65\nFig. 3 Differences between a human Twitter conversation(s) and a bot Twitter interactions\n(networks colored by Louvain group) [ 10]. (a)H u m a n conversation .(b)B o t conversation\ntoolbox. Note that Tier 3 model requires additional collection of friends, followers,\nand followers timeline, and therefore requires accounts that are not suspended.\nSeveral rich annotated bot data sets were used for our Tier 1 and Tier 2 models\nhave a high number of suspended accounts, and therefore were not used for thedevelopment of a Tier 3 model. These datasets will still be discussed in the results\nand evaluation sections since they were used in the development of Tier 1 and Tier\n2 models.\nThe \ufb01rst data set used for Tier 3 training data is a large diverse bot data set that\nwas annotated by detecting 15 digit random alpha-numeric strings as indicated in\n[12] (a data annotation method using a Tier 0 model). This method provided 1.7\nmillion annotated bot accounts. From this data we built network metrics on 6874\nof these accounts. The second data set is from the Debot bot detection system [ 21]\nwhich includes bots that were found due to correlated activity. Using the Debot API,our team extracted 6949 of these accounts, from which we built network metrics on\n5939 accounts. Additionally, we used the bot data manually annotated by Cresci et\nal. in 2015 [ 23] and again in 2017 [ 24].\nIn the results section we will discuss several other data sets that were used to train\nour Tier 1 and Tier 2 models. These include the annotated data our team captured\nin a bot attack on the NATO and the Digital Forensic Labs [ 11]. This data will\nbe referred to as NATO in the results. We also used the suspended Russian bot\ndata set that Twitter released in October 2018 [ 62]. This data set primarily contains\nbot/cyborg/troll activity generated by the Russian Internet Research Agency (IRA)during the 2016 US National Elections. In our results sections, this data set is\nreferred to as the IRA data. Finally, we used a large data set of suspended accounts.\nTo acquire this data, our team streamed the 1% Twitter Sample for 7 months, and\n66 D. M. Beskow and K. M. Carley\nTable 3 Data description\nTraining data Description Tier1 Tier2 Tier3\nCresci 2017 Manually annotated by Cresci et al. in 2017\n[24]X X X\nCresci 2015 Manually annotated by Cresci et al. in 2015\n[23]X X X\nDebot data Accounts labeled as bots by the Debot bot\ndetection system [ 21]X X X\nNATO Data our team captured in a bot attack on the\nDigital Forensic Labs and NATO [ 11]X X\nSuspended accounts These are accounts that were suspended by\nTwitterX\nRandom stringaccounts Accounts with 15 digit random alpha-numericstrings as screen names [ 12] X X X\nIRA data Suspended Russian bot dataset that Twitter\nreleased in October 2018X\nCombined data Combination of data listed above X\nthen went back to discover which of the accounts had been suspended. A similar\ndata collection technique was used by Thomas et al. in [ 61].\nThe IRA and suspended data sets were only used for Tier 1, since timeline and\nfollowers were not available for Tier 2 and Tier 3. For the NATO accounts, 96% ofthe accounts in this dataset have been suspended. We were able to collect suf\ufb01cient\ndata for Tier 2, but not Tier 3. A summary of each data set is provided in Table 3and\ncross walked with the models that it was used with. Note that the Varol data set isnot provided here and was not used in our latest bot-hunter models since it is dated\nand did not perform well.\nThese data sets contain a wide variety of bots. The Varol data set was founded\non the original 2011 Caverlee [ 50] Honey Pot data, but was supplemented with\nmanual annotations (we leveraged only the manually annotated data). The Cresci\ndata contains both traditional spambots (largely commercial spambots) as well associal spambots (both commercial and political). The random string data contains\na large variety of bots ranging from political bots focused on the Middle East to\nhobby bots focused on Japanese Anime. The Debot data is also fairly diverse,with the one unifying feature that they are all have content and timing correlated\nwith other accounts. The differences in these bots are demonstrated in the t-\nDistributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction thatwe conducted on 2000 randomly sampled accounts from the combined data set (see\nFig.4). Here we see that the Debot Data appears to be separate and different from\nthe Varol, Cresci, and Random String data, which appear to be more uniformlydistributed in this 2 dimensional representation of the data.\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 67\nFig. 4 t-SNE dimentsionality reduction of Tier 3 feature space (by bot dataset)\nIn order to train a model, we also needed accounts annotated as human .W eu s e d\nthe Twitter Streaming API to collect a sample of normal Twitter data, intentionally\ncollecting both weekend and weekday data. This provided 149,372 accounts to tagashuman Twitter accounts. Of these accounts, we were able to collect/measure\nnetwork metrics on 7614 accounts.\nPast research has estimated that 5\u20138% of twitter accounts are automated [ 63].\nIf this is true, then we mis-labeled a small amount of our accounts as human .\nWe believe this is acceptable noise in the data, but will limit the performance of\nsupervised machine learning models.\nMany other research efforts attempt to annotate human accounts. We chose not\nto do this because, in the process, these efforts create a biased sample of Twitter,\nheavily skewed toward average users and under sampling Celebrity, Organizational,Political, Commercial, and other accounts that make up a sizable portion of Twitter\ndiscourse. We want our \u2018human\u2019 annotated data to match all non-bot accounts,\nwithout biasing it towards any part of this space. Our classi\ufb01cation is binary, and themodel will be forced to classify all accounts, even those that are under-represented\nin training data. Our approach therefore attempts to create a truly random sample of\nTwitter, at the cost of having some bot accounts labeled as \u2018human\u2019.\n68 D. M. Beskow and K. M. Carley\n4 Feature Engineering\nIn this section we will introduce our feature engineering for user, content, temporal,\nand network features. We extracted features from Tier 0 through Tier 3, with afocus on measuring the importance of features extracted from Tier 3. The table of\nproposed features is provided in Table 4. All new features (beyond the features we\npresented in [ 10]) are in bold, and from our research most of these have not been\nused with an ego-network collected with snowball sampling.\nNote that our Tiered approach is cumulative, meaning Tier 3 feature space\nincludes features from Tier 0, Tier 1, and Tier 2. The Tier 3 model therefore includesthe Tier 2 network features created by building an entity (mention, hashtag, and\nURL) co-mention network based only on the user\u2019s time-line (last 200 tweets).\nThese Tier 2 network features are distinguished in our results section by the entity\npre\ufb01x.\nTable 4 Features by data collection tier (new features not presented in [ 10] highlighted in bold)\nSource User attributes Network attributes Content Timing\nUser object\n(Tier 1)Screen namelength Number offriends Is last statusretweet? Account age\nDefault pro\ufb01leimage? Number offollowers Same language? Avg tweetsper day\nDefault pro\ufb01leimage? Number offollowers Same language? Avg tweetsper day\nEntropy screenname Number offavorites Hashtags laststatus\nHas location? Mentions laststatus\nTotal tweets Last statussensitive?\nSource (binned) \u2018bot\u2019 reference?\nTimeline(Tier 2) Number nodesof E Mean/maxmentions Entropy ofinter-arrival\nNumber edges Mean/max hash Max tweets\nhour\nDensity Number oflanguages Max tweetsper day\nComponents Fraction retweets Max tweets\nper month\nLargest compo\nDegree/betweencentrality\n(continued)\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 69\nTable 4 (continued)\nSource User attributes Network attributes Content Timing\nSnowball\nsample(Tier 3)%w /d e f a u l timage # of bot friends # of languages Meantweets/min\nMedian # tweets Number ofnodes Mean emoji pertweet Meantweets/hour\nMean age Number of links Mean mentionper tweet Meantweets/day\n% w/ description Density Mean hash pertweet %d o n \u2019 tsleep\n%m a n yl i k e sand Fewfollowers Number ofisolates % retweets\nNumber of dyadisolates Mean jaccardsimilarity\nNumber of triadisolates Mean cosinesimilarity\nNumber ofcomponents >4\nClustering\ncoef\ufb01cient\nTransitivity\nReciprocity\nDegreecentrality\nK-betweennesscentrality\nMean eigencentrality\nNumber of\nsimmelian ties\nNumber of\nLouvain groups\nSize of largestLouvain group\nEgo effectivesize\nFull triadiccensus\nMedianfollowers\nMedian friends\n70 D. M. Beskow and K. M. Carley\nWe hypothesize that the network metrics for human conversations will have\ndifferent distributions than those made by bot accounts. We also believe that these\ndifferences would provide increased performance in traditional machine detectionalgorithms.\nWe have not found research that has built a snowball sampling network for bot\ndetection, and believe that all of the Snowball Sampling ego network features inour model are novel. To collect these at scale, our team built a Python package that\nwrapped around the networkx package [ 39]. We leveraged known network metrics,\nwhich are provided in Table 4with references.\n4.1 Network Features\nWe constructed an ego network from the data collected from snowball sampling,\nextracting metrics from this network in an effort to develop robust features for\nbot detection. As discussed earlier, this network consisted of the conversation\nof the account in question and up to 250 of their followers. All nodes wereTwitter accounts, and links were means of directed communication in the Twitter\necosystem (retweet, mention, reply). From this network we developed basic network\nmetrics, component level statistics, centrality metrics, triadic relationship metrics,and clustering related metrics. The basic network metrics are widely used and listed\nin Table 4. The other categories of metrics are described below.\nGiven that we did not include the following link in our network construction,\nthese networks were not fully connected. As seen in Fig. 5, information from these\ndisconnected components could be valuable in distinguishing real human networks\nfrom networks dominated by bots. Our features therefore contain multiple metricsmeasuring number and size of network components.\n(a)010203040\nHour of DayCountHistogram with Circadian Rhythm\n0 5 10 15 20010203040\n0 5 10 15 20\nHour of DayCountHistogram without Circadian Rhythm\n(b)\nFig. 5 Differences between a human and bot 24 h circadian rhythms. ( a)H u m a n circadian\nrhythms .(b)B o t without circadian rhythms\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 71\nWe included several network centrality metrics in our feature space, and found\nthat they were routinely strong bot predictors. These metrics included mean degree\ncentrality, mean eigenvector centrality, and mean K-betweenness centrality whereK=min(500,N\nnodes).\nIn addition to analyzing the components, we also computed Louvain grouping\nand developed metrics based on these groups. We chose the Louvain groupingalgorithm given its proven performance on larger data sets. Having computed the\nLouvain groups, we included metrics such as number of groups and size of largest\nLouvain group.\nGiven the importance of triadic relationships in social networks discussed above,\nwe have included several features based on these relationships. These include a full\ntriadic census, number of Simmelian ties, and the clustering coef\ufb01cient. Calculationof Simmelian ties [ 46] was not available in the networkX package. Our team\ntherefore created a Python implementation of Dekker\u2019s version [ 26] of the original\nalgorithm [ 46].\n4.2 Content Features\nWe felt we could leverage the large amount of content available from the snowball\nsample to develop predictive features. This was not done in [ 10], and was added in\nrecent version of the bot-hunter framework.\nThese features include the number of languages used in the network, as well\nas some key summary statistics on entities, including mean emojiis, mentions, andhashtags per tweet, as well as the percentage of retweets.\nWe also wanted to have several measures of similarity of text between the various\ncommunicators in the network. This search for similarity measures was motivatedby the fact that many bot networks post very similar or conversely very diverse\ncontent, and we felt that these measures of similarity may be distinguishing.\nTo compute similarity, tweet content in the network was aggregated by user. Once\naggregated, the content was cleaned and parsed (cleaning included conversion to\nlower case and removal of punctuation). We did not remove stopwords. The parsed\ndata was then converted to a document term matrix with raw counts (we chose notto normalize the data since the variance on tweet length is arti\ufb01cially constrained\nto 280 characters). The document term matrix was then used to compute both the\nJaccard and Cosine Similarity, which were used as features.\n4.3 User Features\nThe newest version of the Tier 3 classi\ufb01er also includes several aggregate userattributes that were not leveraged in earlier versions. While many of these are selfexplanatory, we did want to describe two novel metrics that have not been used\nbefore.\n72 D. M. Beskow and K. M. Carley\nRecently, several experts in online disinformation have highlighted how recent\nonline bots seem to produce tweets that are far more popular than the account\nitself [ 56]. This phenomena is the result of accounts in large bot-nets that create\nmessages that are then pushed by the entire network, resulting in reach that far\nexceeds expectations given its modest beginning.\nTo \ufb01nd this phenomena, we devised a simple heuristic that determines if any\noriginal (non-retweet) tweet is more popular than its account. This heuristic is\nde\ufb01ned as:\nPuser=retweets > 2\u00d7max(followers,friends)\nwhere the Boolean measure for a user is de\ufb01ned as Tru e if any tweet receives two\ntime more retweets than the highest value of its in-degree or out-degree. This metric\nis leveraged in two new features, one at the user level (Tier 2) and one at the Network\nLevel (Tier 3). The user level \ufb02ags the user if any tweet is \ufb02agged as True, and thenetwork metric measures the fraction of tweets produced by the network that are\n\ufb02agged by this heuristic.\n4.4 Timing Features\nLike user features, most of the temporal features listed in Table 4are self\nexplanatory. We did develop a heuristic method that measures whether or not an\naccount has daily rhythms. Most human users will have surges in activity based ontheir daily routines, and will have a measurable drop in activity that aligns with their\nsleep activity. Bots, on the other hand, do not require these circadian rhythms, and\nsome bots are programmed to produce content spread uniformly across the hours ofthe day. We developed the heuristic described below to \ufb02ag these accounts.\nTo measure whether an account has human circadian rhythms, we \ufb01rst aggregate\ntheir tweets by hour of day after ensuring that the account has produced enough data(at least 50 tweets). Given there is suf\ufb01cient data, we next determine whether this\nhourly distribution is uniformly distributed by normalizing it and conducting the\nKolmogorov-Smirnov non-parametric test for uniformity. A p-value greater than\n0.5 provides strong evidence of non-human circadian rhythms.\nIt is important to note that, while some bots exhibit this lack of circadian rhythm,\nit only takes a few lines of code for a bot manipulator to give a more realistictemporal pattern. Nonetheless, this remains a strong indicator of bot activity.\n5 Modeling\nAs indicated above, all feature engineering was conducted in Python using severalcustom Python packages that were developed for the bot-hunter framework. These\npackages build the feature space for Tier 1, Tier2, and Tier 3 models, which is then\ntrained using the steps outlined below.\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 73\nTable 5 Comparing algorithms for Tier 3 Bot detection\nModel Accuracy Precision Recall AUC F1\nNa\u00efve Bayes 0.562 0.541 0.864 0.563 0.665\nDecision tree 0.950 0.949 0.952 0.950 0.951\nSVM 0.952 0.969 0.933 0.952 0.952\nLogistic regression 0.951 0.940 0.965 0.983 0.952\nRandom forrest 0.955 0.955 0.956 0.986 0.956\nTable 6 Table of results for combined data (Tier 3)\nTier Accuracy F1 Precision Recall ROC AUC\nTier 1 0.7964 0.7729 0.8677 0.6969 0.8680\nTier 2 0.8335 0.8181 0.8970 0.7522 0.9179\nTier 3 0.8577 0.8478 0.9042 0.7983 0.9410\nFor training all data sets, human data was sampled so that the classes were bal-\nanced. The random forest algorithm was used because of its superior performance\non Tier 1 data [ 11] and its use in other bot detection algorithms [ 63]. In Table 5\nwe revisit model comparison in order to verify that the random forest model isstill appropriate for Tier 3 feature space. We see that random forest still provides\nsuperior performance, and in general is not as computationally expensive as some\nof the other models. Training, evaluation, and testing were conducted in the scikit-\nlearn Python package [ 57]. Tuning of the Random Forest algorithm was conducted\nthrough random search of parameter options while using three fold cross-validation.\nThe bot-hunter behavior returns both a binary classi\ufb01cation and an estimate\nof probability. The estimate of probability is provided by the Random Forest\nclassi\ufb01er by measuring the proportion of votes by trees in the ensemble. The binary\nclassi\ufb01cation result is evaluated by classifying accounts based on a probabilitythreshold of 0.5. The binary classi\ufb01cation feature of the results allows researchers\nto have a consistent threshold to compare results, while the probability allows users\nto tune a threshold for a given use case.\n6 Results\nAfter building the network metrics for all bot data sets as well as the annotatedhuman data, we built and evaluated Random Forest models for each of the data\nsets. Training, evaluating, and testing were conducted at Tier 1, Tier 2, and Tier 3\nwhere possible. We evaluated in-sample performance with 10 fold cross-validationmeasuring multiple evaluation metrics, which are provided in Table 6and Fig. 6.\nFrom the results presented in Table 6and Fig. 6, we see that Tier 1 models\ncontinue to provide solid performance, even with basic features extracted fromthe user pro\ufb01le and last status. We also observe improvement between Tier 1\n74 D. M. Beskow and K. M. Carley\nlll\nlll\nll\nll\nl\n0.70.80.91.0\ndebot random nato ira suspended\nTraining Data / TierAccuracytype tier1 tier2 tier3\nFig. 6 Results by training data and by Tier\nand Tier 2 and between Tier 2 and Tier 3 for all models. Using a combined data\nmodel we found that the Tier 2 improvement over Tier 1 is statistically signi\ufb01cant\n(p\u2212value =1.303e\u221210), as is the Tier 3 improvement over Tier 2 ( p\u2212value =\n1.101e\u221206). In Fig. 6we also see that the Random, NATO, and IRA data provide\nthe highest in sample cross validation performance, while models trained on Debot\nData and Suspended data offer lower in data cross validation performance. Thislikely indicates a wider variety of bot types in the Debot and Suspended data.\nFurther, in Fig. 7we see the top features for all Tier 1, Tier 2, and Tier 3 models\nin the bot-hunter suite of tools. These \ufb01gures represent the percentage that each\nfeature contributed to the model predictions. We see that network features provide\nstrong features in the model. This demonstrates that these values, while tedious to\ncollect, transform, and model, provide strong predictive features that are dif\ufb01cultfor bot puppet master to manipulate. In these data sets network centrality, network\nconnection, network timing, and network content all provide predictive value.\n7 Evaluating Against State of the Art\nGiven that this is the last Tier of the bot-hunter suite of tools, we wanted to evaluate\nthe models as well as various training data that is available. We also wanted to\ncompare the models in the bot-hunter suite of tools to existing models, namely the\nBotometer and Debot models. To do this, we set out to \ufb01nd a test that wasn\u2019t biased\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 75\n(a) (b)\n(c)\nFig. 7 Comparison of top features for all three Tiers of bot-hunter .(a)T i e r1T o pP r e d i c t i v e\nFeatures. ( b) Tier 2 Top Predictive Features. ( c) Tier 3 Top Predictive Features\ntoward any given model, meaning the test data could not be derived from the training\ndata of any of the models being compared.\nTo \ufb01nd an unbiased data set, we manually annotated 337 bot accounts. To do this,\nwe started by manually \ufb01nding several seed bots related to the Swedish elections,separate Russian propaganda bots, and bots found in Middle East conversations. We\nthen manually snowballed out on the followers and followers of followers, manually\nidentifying additional bots. In this evaluation we leveraged the visualizations andmetrics provided in the TruthNest tool to aid in making our determination. The\nTruthNest Tool originally was an EU-funded Reveal project developed to evaluate\nTwitter accounts for automated activity. While this tool was not evaluated in ourtest, it was used to assist in labeling bot accounts. TruthNest has instituted a paywall\nsince our use of it. Human users were sampled from the Twitter stream and manually\nveri\ufb01ed. The test data was balanced (337 bots, 337 users).\nIn evaluating our Tier1, Tier2, and Tier3 models, we also wanted to evaluate\nwhich training data and model combination generalizes to new data. Our models\nwere trained on the data and at the tiers described in Table 1.A l l bot-hunter and\nBotometer thresholds were set at 0.5. F1 performance for all models is provided in\nFig.8and detailed results are provided in Table 7.\n76 D. M. Beskow and K. M. Carley\nFig. 8 Results by training data and by Tier\nTable 7 Detailed results by Tier and training data\nTier Training data F1 Accuracy Precision Recall ROC-AUC TN FP FN TP\nBotometer model 0.524 0.657 0.858 0.377 0.587 256 55200 108\nDebot model 0.012 0.502 1.000 0.006 0.503 336 0335 2\nTier1 NATO 0.584 0.634 0.678 0.513 0.635 254 82164 173\nTier1 IRA 0.380 0.597 0.830 0.246 0.598 319 17254 83\nTier1 Combined 0.524 0.657 0.858 0.377 0.657 315 21210 127\nTier1 Cresci2015 0.559 0.404 0.444 0.754 0.404 18318 83254\nTier1 Cresci2017 0.576 0.419 0.454 0.789 0.418 16320 71266\nTier1 Debot 0.490 0.527 0.533 0.454 0.528 202 134 184 153\nTier1 Random 0.291 0.572 0.855 0.175 0.573 326 10278 59\nTier1 Suspended 0.656 0.713 0.821 0.546 0.713 296 40153 184\nTier2 IRA 0.315 0.567 0.903 0.191 0.584 305 7276 65\nTier2 Random 0.288 0.547 0.800 0.176 0.564 297 15281 60\nTier2 NATO 0.335 0.574 0.909 0.205 0.591 305 7271 70\nTier2 Cresci2015 0.426 0.596 0.824 0.287 0.610 291 21243 98\nTier2 Cresci2017 0.451 0.600 0.799 0.314 0.614 285 27234 107\nTier2 Debot 0.687 0.675 0.691 0.683 0.675 208 104 108 233\nTier2 Random 0.286 0.550 0.831 0.173 0.567 300 12282 59\nTier3 Debot 0.599 0.674 0.837 0.466 0.683 281 31182 159\nTier3 Random 0.236 0.533 0.810 0.138 0.551 301 11294 47\nTier3 Cresci2015 0.231 0.541 0.918 0.132 0.560 308 4296 45\nTier3 Cresci2017 0.120 0.507 0.880 0.065 0.527 309 3319 22\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 77\nIn these results we \ufb01rst see Botometer demonstrates consistent solid performance\nin predicting new bots across all metrics. The Debot algorithm provides high\nprecision but extremely low recall, resulting in a low F1 score overall. The valueof the Debot algorithm may indirectly lie in the data that it produces. Note that bot-\nhunter algorithms trained on Debot data performed well at all three Tiers, meaning\nthat the Debot algorithm for \ufb01nding correlated accounts produces great labeled datafor other supervised bot detection endeavors.\nFor the bot-hunter family of models, we see that Tier 1 consistently performs well\nand seems to generalize to new data better than Tier 2 and Tier 3. Tier 2 still hashigh performance, given its ability to identify anomalies in content and in temporal\nstatistics. Across the data sets, Tier 1 has a higher mean Accuracy and ROC AUC\nthan Tier 1. Tier 3 has very high precision but low recall. It therefore producespredictions that are more reliable, but fails to \ufb01nd a large portion of the bots in the\ndata. Additionally, this model may become increasingly important in identifying\nsophisticated emerging bots.\nAs we look at the various training data used for training these models, we see\nthat the models trained on suspended accounts or on data produced by the Debot\nmodel had the highest performance. As indicated earlier, this is likely due to thesedata sets containing a wide variety of bot \u201cgenres.\u201d We also see that the NATO\ndata captured in the deliberate attack against NATO and the DFR labs continues to\nprovide strong performance across all metrics. We found that few of the annotateddata sets released by other researchers provided strong performance, especially\nwhen considering accuracy and ROC-AUC metrics. The Cresci data (both 2015\nand 2017) appears to have high recall but low precision, with many false negatives.The models trained on the random string data also have low accuracy and ROC-\nAUC metrics, in this case caused by high precision but low recall. These random\nstring accounts probably represent a limited band in the spectrum of bot types, andtherefore do not generalize well to new data and different bot types.\nThe Venn Diagram of predicted bots is provided in Fig. 9a. This diagram shows\nthe overlap of the predicted bots, but does not provide any information on predictedhumans. We see signi\ufb01cant overlap for all three models. We also notice that the Tier\n2 model predicted the most accounts (330 accounts), while Tier 1 predicted 260\naccounts and Tier 3 predicted 183 bot accounts. The 95 accounts in the intersectioncontain 20 false positives (78.9% precision).\nThe Venn Diagram of predicted bots for Tier 1 and 2 compared to the reallabeled\nbots is provided in Fig. 9b. This shows that Tier 2 is adding something to Tier 1,\n\ufb01nding 94 additional accounts while only missing 21 of the accounts that Tier 1\nfound.\nFigure 9c provides an upset visualization to fully explore the intersection of sets.\nThis visualization demonstrates that our largest intersection is the intersection of\nall four sets. We also see in the upset graph the Tier 1 and in Particular Tier 2 is\nimportant to the prediction success, thought Tier 3 is also able to \ufb01nd 32 accountsthat neither Tier 1 or 2 could \ufb01nd. These visualizations illustrate the importance\nof having a tool-box of models that can be used for predicting bots in any given\nscenario.\n78 D. M. Beskow and K. M. Carley\n(c)\nTier_3\nTier_1\nTier_2\nReal_Bots\nSet Size8075\n575555\n4846\n39\n32 32\n20\n15\n764\n060\n40\n20Intersection Size\n300 200 100 00\nTier 1\n(a) (b)Tier 3 Real_Bots10568\n132\n94\n872136\n5487\n95\n436\n3939Tier 1 Tier 2Tier 2\nFig. 9 Understanding the overlap of predicted Bots with Tier 1, 2, and 3 models trained on Debot\ndata. ( a) Predicted Bots (Tier 1, 2, and 3) . ( b) Predicted Bots (Tier 1 and 2) with Real Labeled\nBots. ( c) Upset Plot with Predicted Bots (Tier 1, 2, and 3) and Real Labeled Bots\nWhile we believe this evaluation is informative, there are several limitations\nin our evaluation method. We aknowledge that we were not able to completely\nremove bias, given that the mental heuristics we used to manually annotate accountsmay have unintentionally mirrored the bot-hunter algorithms. Additionally, we\nacknowledge that the test set is still modest in size and, while somewhat diverse,\ndoes not represent the full spectrum of bot types. Finally, we acknowledge that any\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 79\ngiven model may perform better if the threshold is tuned for a given data set. Even\nwith these limitations, we believe this test and evaluation is informative for our team\nand for the greater community.\n7.1 Evaluating Bot Classi\ufb01cation Thresholds\nThe random forest model used in the bot-hunter suite of tools (and Botometer)provides a probability estimate rather than just a label. This allows researchers to\nestimate how strong a given prediction is. Every use case will require the analyst\nto determine the best threshold for establishing whether or not an account is likelya bot. To evaluate the best threshold for a given data set, a research team should\nexplore several thresholds, each time sampling 50\u2013100 accounts and manually\nlabeling them to estimate a rate of true/false positives, true/false negatives. Ifpossible they should attempt to construct a precision recall curve and/or ROC Curve,\nas demonstrated in Fig. 10using the Suspended, NATO, and Botometer models.\nNote that recall is always monotonically decreasing, but precision is not required tomonotonically increase.\nAs seen in Fig. 10, we generally recommend bot-hunter thresholds between 0.6\nand 0.8. The exact choice in this range will need to be made by the research team,and is dependent on the data as well as the team\u2019s prioritization of precision vs.\nrecall.\n8 Applying Bot Detection to Swedish Election\nHaving completed the bot-hunter suite of tools, we wanted to leverage this toolbox\nin analyzing a stream of data from the 2018 Swedish elections. This is done as acase study to illustrate that bot-detection is not a \u201cturn-key\u201d solution, and also to\nprovide practitioners with an example of an open source intelligence work\ufb02ow.\nSweden held national elections on 9 September 2018 for its equivalent of a\nParliament, known as the Riksdag. Swedish elections have historically lacked much\ndrama or suspense, with the center-left Social Democrat Party dominating politics\nsince 1914. In the 2018 election, however, their dominance was challenged byvarious nationalistic factions that capitalized on anti-immigrant sentiment.\nSome of the political discourse surrounding the election transpired on Twitter,\nas seen in many recent national elections across the world. As this discourse grew,multiple researchers and news agencies saw rising disinformation and associated\nbot activity [ 58]. Simultaneously, the Swedish Defence Research Agency reported\nincreased bot activity, primarily supporting right leaning, nationalistic, and anti-immigrant views [ 60].\nAs these bots grew in activity in this marketplace of beliefs and ideas, our\nteam began collecting and analyzing streams from this discourse. To collect Twitter\n80 D. M. Beskow and K. M. Carley\n1.0Suspended (Tier 1 Model) Precision Recall Curves Suspended (Tier 1 Model) ROC Curve\nNATO (Tier 1 Model) ROC Curve NATO (Tier 1 Model) Precision Recall Curves\nBotometer ROC Curve Botometer Precision Recall Curves1.00.8\n0.80.6\n0.60.4% % %0.40.2\n0.20.0\n1.0\n0.8\n0.60.4\n0.2\n0.01.0\n0.8\n0.60.4\n0.2\n0.0\n1.0\n0.8\n0.60.4\n0.2\n0.01.0\n0.8\n0.60.4\n0.2\n0.01.0\n0.80.60.40.20.0\n0.0 1.0 0.8 0.6 0.4 0.2 0.0\n1.0 0.8 0.6\nthresholdthreshold\nprecision\nauc=0.7819\nauc=0.7299\nauc=0.6645recall\nprecision\nrecall\nprecision\nrecall\nthreshold0.4 0.2 1.0 0.8 0.6 0.4 0.2 0.0\n1.0 0.8 0.6 0.4 0.2 0.0 1.0 0.8 0.6 0.4 0.2 0.0\nFig. 10 Using precision-recall curves and ROC curves to determine threshold\ndata around the Swedish National elections discourse, our team leveraged a spiral\ncollection methodology, starting with content and geographic streaming, and then\n\u2018spiraling\u2019 into more thorough data collection around the important parts of thediscussion. All collection was done through the Twitter Streaming and REST API\u2019s\nusing the Tweepy Python Package.\nWe started by identifying Swedish political hashtags through open source\nresearch, eventually identifying #svpol, #Val2018, #feministisktInitiativ, #migpol,\n#valet2018, #SD2018, #AfS2018, and #MEDval18. These hashtags were not\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 81\nselected because they cover the full spectrum of Swedish politics, but rather because\nthere was open source reporting of some bot campaigns using these hashtags. We\nstarted collecting on these hashtags using both the Streaming and REST API\u2019s (thestreaming API allows us to easily collect going forward while the REST API allows\nus to retroactively collect past data). Simultaneously we collected data that was\n\u2018geo-associated\u2019 with the Scandinavian peninsula, using a bounding box searchmethod.\nAs we began to collect content and geo-referenced data, we monitored other\ntrending hashtags and added them to the collection query. After launching theexploratory data analysis discussed below, we would also collect users friend and\nfollower relationships as well as user historical timelines for accounts of interest.\nThis continual return to the Twitter API creates the spiral nature of our collectionprocess.\nFor the Swedish Election Event we collected 661,317 tweets produced by 88,807\nunique users. This creates a political conversation that contains 104,216 nodes,\n404,244 links with a density of 0.000037.\nFor bot detection in the Swedish Election stream our team found that a 65%\nprobability was appropriate. Given that we were performing this evaluation on104,216 nodes, we used the Tier 1 model. This model is our best model for getting\nan accurate prediction on high volume of accounts.\nNote that we usually conduct other data enhancement as well, including sen-\ntiment analysis with NetMapper as well as geo-inference based on [ 44]. All\nenrichments are made available in easy formats that allow tools to merge them with\nexisting event data.\n8.1 Exploratory Data Analysis\nOur exploratory data analysis focuses on narratives, time, place, groups, and individ-uals. Our analysis typically starts with some type of temporal analysis. This allows\nus to see distributions over time. We try to look at overall temporal distribution, bot\nactivity over time, as well as changing narratives over time (Fig. 11).\nOur exploration of content and narratives starts with analysis of words and\nhashtags across the entire corpus, and then we explore narratives associated with\ntopic groups (these are groups that talk about the same thing but may not beconnected in the social network or conversational network) and social network\ngroup (these are groups that are connected, but may not talk about the same\nthing). We leverage latent dirichlet allocation [ 15] for topic group analysis, and\ncontent analysis by Louvain group [ 16] as a way to \u201ctriage\u201d network groups.\nTable 8provides the top 8 words by Louvain Group for the Swedish elections. In\nthis we already start to see groups that are focused on immigration, particularlyimmigration from Muslim countries. We also see at least one group that is mixing\nconversation about religious beliefs with political discourse. Finally and just as\n82 D. M. Beskow and K. M. Carley\nFig. 11 Bots as a proportion of total volume over time\nimportant, \u201ctriaging\u201d the data like this allows us to identify groups like Group 0\nthat don\u2019t appear to have any topics of interest.\nNetwork analysis of groups and individuals is done almost exclusively in\nthe ORA Network Analysis Tool. We typically start by visualizing a reducedconversational network. Nodes in this network represent Twitter accounts, and links\nrepresent a conversational action in the Twitter ecosystem (reply, retweet, mention).\nThese network are typically too large to visualize, so we reduce the network bytaking the K-core so that we have the core 15,000\u201320,000 nodes. Once this is done,\nwe color the network by botorhuman , by language, and by Louvain grouping (see\nFig.12). This coloration helps us better understand the groups and their relationship\nto each other. Finally, we reduce the network to only include reciprocal links. This\nusually reduces the network signi\ufb01cantly, and in Twitter provides the best proxy for\na true social network.\nWe then explore the in\ufb02uential accounts and in\ufb02uential bots in the network.\nThe ORA Network analysis tool provides several reports that analyze nodes by a\nvariety of centrality measures, and assists translating their role in the network. Forthe Swedish network, we found several bots with high betweenness , indicating that\nthese bots were in\ufb02uential in that they connect individuals and groups. With further\nexploration, it appeared that these bots, in connection with other accounts, weretrying to bridge several communities with nationalistic and anti-immigrant groups\nand narratives.\nWe leverage the bot-hunter Tier 2 and Tier 3 models during this phase of analysis.\nAs we identify in\ufb02uential accounts, we check them in a Tier 2/3 bot-hunter web\napplication that allows us to thoroughly explore the account and conduct a more\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot ... 83\nTable 8 Content analysis by Louvain group\nGroup # Tweets # Nodes Top 8 words by Louvain group\n0 15,708 4675 Video Gillade Lade Spellista\n2018 fortnite world part\n1 31,059 5688 Country Vo t e r s Refugees 82\nn number capita reported\n2 102,146 14,538 Sweden Election epp sd\nSwedish results left poll\n3 306,352 17,600 m6aubkudbg Jesus Kristus Varnar\nsverige gud namn fader\n4 8353 3137 Sweden Swedish Muslim Election\namp vote democrats gang\n5 40,585 9110 Sverige sd Svenska \u00e5kesson\nvalet jimmie \u00e5r svt\n7 82,708 12,300 sd Sverige R\u00f6sta \u00e5kesson\nvalet jimmie parti val\n8 17,675 4000 sd Friend American R\u00f6sta\npolitik claeson t\u00e5nkt fr\u00e5gar\n9 7144 5217 Sverige L\u00f6fven sd Moderaterna\nstefan kristersson amp r\u00f6sta\n10 7569 5214 Sverige Riks sd Alternativ\nafs Sweden svenska hahne\naccurate Tier 2 or Tier 3 bot prediction. These applications also allow us to explore\nin depth visualizations of the activity of the account.\nBot-detection is therefore a part of the overall open source intelligence work\ufb02ow,\ntrying to identify relevant information about how the world works to inform decisionmaker situational understanding and decisive action. In this case, our research\nvalidated research of large bot activity within the Swedish political discourse\non Twitter and provided identi\ufb01cation of narratives (primarily nationalistic andanti-immigrant, anti-Muslim, and some anti-Semitism). We were also able to\nidentify in\ufb02uential accounts that were attempting to connect individuals and online\ncommunities with extremist content. This type of information informs leaders ofcurrent dis-information strategies allowing them to better prepare their government\nand their populace for similar disinformation campaigns in their country.\n84 D. M. Beskow and K. M. Carley\nFig. 12 Exploring the Twitter conversational network surrounding online discourse on Swedish\npolitics. ( a) Bots (red) in conversation. ( b) Louvain Groups. ( c) Language Distribution in Network\n9 Conclusion and Future Work\nIn our pursuit of a multi-model bot detection toolbox, this paper builds on past\nresearch by adding a model that leverages a feature space extracted from 50 ,000+\nentities collected with single seed snowball sampling. This model is developed for\nhigh accuracy but low volume applications. Our research shows that supervisedmachine learning models are able to leverage these rich structural, content, and tem-\nporal features associated with the target ego-network to increase model precision.\nAdditionally, these network features offer an approach for modeling and detectingbot behavior that is dif\ufb01cult for bot puppet-masters to manipulate and evade.\nOur evaluation of the bot-hunter suite of tools demonstrates that these models\nprovide performance equivalent to or better than the state of the art. The Tier1 model in particular is valuable to the community because it is accurate and\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot. . . 85\ncan scale to large data (meaning researchers aren\u2019t required to sample their data).\nAdditionally, because the Tier 1 model was designed to predict existing data, there\nisn\u2019t a requirement to return to the Twitter API to re-collect account data. This alsomeans that it can be used to predict existing data sets that contain suspended or\notherwise missing accounts.\nOur analysis of Swedish political discourse on Twitter illustrates how bot-\ndetection tools can support a typical open source intelligence work\ufb02ow. The\nbot-hunter suite provides a way to enrich the data which can then be imported\ninto other analysis tools for visualization and further analysis. Bot detection isnot a \u201cturn-key\u201d solution, and does require some work to set the right parameters,\nparticularly the appropriate threshold level.\nFuture work will focus on creating a labeling methodology that will allow us\nto better characterize bot accounts and the various methods they employ. Binary\nprediction assists in understanding fake versus real, but does not help us in triaging\nthe hundreds of thousands of bot accounts that exist. Some spam content, othersintimidate users. Developing heuristics to label these methods and attributes is\nessential for characterizing these accounts and the disinformation campaigns they\npropagate.\nAcknowledgements This work was supported in part by the Of\ufb01ce of Naval Research\n(ONR) Multidisciplinary University Research Initiative Award N000140811186 and AwardN000141812108, the Army Research Laboratory Award W911NF1610049, Defense ThreatReductions Agency Award HDTRA11010102, and the Center for Computational Analysis ofSocial and Organization Systems (CASOS). The views and conclusions contained in this documentare those of the authors and should not be interpreted as representing the of\ufb01cial policies, eitherexpressed or implied, of the ONR, ARL, DTRA, or the U.S. government.\nReferences\n1. K.S. Adewole, N.B. Anuar, A. Kamsin, K.D. Varathan, S.A. Razak, Malicious accounts: dark\nof the social networks. J. Netw. Comput. Appl. 79, 41\u201367 (2017)\n2. L.M. Aiello, M. Deplano, R. Schifanella, G. Ruffo, People are strange when you\u2019re a stranger:\nImpact and in\ufb02uence of bots on social networks. Links 697(483,151), 1\u2013566 (2012)\n3. A. Almaatouq, E. Shmueli, M. Nouh, A. Alabdulkareem, V .K. Singh, M. Alsaleh, A. Alari\ufb01,\nA. Alfaris, et al., If it looks like a spammer and behaves like a spammer, it must be a spammer:analysis and detection of microblogging spam accounts. Int. J. Inf. Secur. 15(5), 475\u2013491\n(2016)\n4. A. Ananthalakshmi, Ahead of Malaysian Polls, Bots Flood Twitter with Pro-government ...\n(2018)\n5. D.A Bader, S. Kintali, K. Madduri, M. Mihail, Approximating betweenness centrality, in\nInternational Workshop on Algorithms and Models for the Web-Graph (Springer, Berlin, 2007),\npp. 124\u2013137\n6. A. Bavelas, A mathematical model for group structures. Hum. Organ. 7(3), 16\u201330 (1948)\n7. A.I. Bawaba, The Loop, in Thousands of Twitter Bots are Attempting to Silence Reporting on\nYemen (2017)\n86 D. M. Beskow and K. M. Carley\n8. M. Benigni, K.M. Carley, From tweets to intelligence: understanding the islamic jihad sup-\nporting community on twitter, in Proceedings of Social, Cultural, and Behavioral Modeling:\n9th International Conference, SBP-BRiMS 2016, Washington, DC, USA, June 28-July 1, 2016(Springer, Berlin, 2016), pp. 346\u2013355\n9. M.C. Benigni, K. Joseph, K.M. Carley, Online extremism and the communities that sustain it:\ndetecting the ISIS supporting community on twitter. PLoS One 12(12), e0181405 (2017)\n10. D. Beskow, K.M. Carley, Bot conversations are different: Leveraging network metrics for bot\ndetection in twitter, in 2018 International Conference on Advances in Social Networks Analysis\nand Mining (ASONAM) (IEEE, Piscataway, 2018), pp. 176\u2013183\n11. D. Beskow, K.M. Carley, Introducing bothunter: A tiered approach to detection and char-\nacterizing automated activity on twitter, in International Conference on Social Computing,\nBehavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling andSimulation , ed. by H. Bisgin, A. Hyder, C. Dancy, R. Thomson (Springer, Berlin, 2018)\n12. D. Beskow, K.M. Carley, Using random string classi\ufb01cation to \ufb01lter and annotate automated\naccounts, in International Conference on Social Computing, Behavioral-Cultural Modeling\nand Prediction and Behavior Representation in Modeling and Simulation , ed. by H. Bisgin, A.\nHyder, C. Dancy, R. Thomson (Springer, Berlin, 2018)\n13. A. Bessi, E. Ferrara, Social Bots Distort the 2016 US Presidential Election Online Discussion\n(2016)\n14. S.Y . Bhat, M. Abulaish, Community-based features for identifying spammers in online social\nnetworks, in 2013 IEEE/ACM International Conference on Advances in Social Networks\nAnalysis and Mining (ASONAM) (IEEE, Piscataway, 2013), pp. 100\u2013107\n15. D.M. Blei, A.Y . Ng, M.I. Jordan, Latent dirichlet allocation. J. Mach. Learn. Res. 3(Jan), 993\u2013\n1022 (2003)\n16. V .D. Blondel, J.-L. Guillaume, R. Lambiotte, E. Lefebvre, Fast unfolding of communities in\nlarge networks. J. Stat. Mech: Theory Exp. 2008 (10), P10008 (2008)\n17. R.S. Burt, Structural Holes: The Social Structure of Competition (Harvard University Press,\nCambridge, 2009)\n18. K.M. Carley, G. Cervone, N. Agarwal, H. Liu, Social cyber-security, in International Con-\nference on Social Computing, Behavioral-Cultural Modeling and Prediction and BehaviorRepresentation in Modeling and Simulation , ed. by H. Bisgin, A. Hyder, C. Dancy, R. Thomson\n(Springer, Berlin, 2018)\n19. D. Cartwright, F. Harary, Structural balance: a generalization of Heider\u2019s theory. Psychol. Rev.\n63(5), 277 (1956)\n20. N. Chavoshi, H. Hamooni, A. Mueen, Debot: Twitter bot detection via warped correlation, in\nIEEE International Conference on Data Mining (ICDM) (2016), pp. 817\u2013822\n21. N. Chavoshi, H. Hamooni, A. Mueen, On-demand bot detection and archival system, in Pro-\nceedings of the 26th International Conference on World Wide Web Companion . International\nWorld Wide Web Conferences Steering Committee (2017), pp. 183\u2013187\n22. C.-M. Chen, D.J. Guan, Q.-K. Su, Feature set identi\ufb01cation for detecting suspicious urls using\nbayesian classi\ufb01cation in social networks. Inform. Sci. 289, 133\u2013147 (2014)\n23. S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, M. Tesconi, Fame for sale: ef\ufb01cient\ndetection of fake twitter followers. Decis. Support. Syst. 80, 56\u201371 (2015)\n24. S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, M. Tesconi, Social \ufb01ngerprinting: detection\nof spambot groups through DNA-inspired behavioral modeling. IEEE Trans. DependableSecure Comput. 15(4), 561\u2013576 (2018)\n25. C.A. Davis, O. Varol, E. Ferrara, A. Flammini, F. Menczer, Botornot: a system to evaluate\nsocial bots, in Proceedings of the 25th International Conference Companion on World Wide\nWeb. International World Wide Web Conferences Steering Committee (2016), pp. 273\u2013274\n26. D.J. Dekker, Measures of Simmelian Tie Strength, Simmelian Brokerage, and, the Simmelianly\nBrokered (2006)\n27. R.I.M. Dunbar, Coevolution of neocortical size, group size and language in humans. Behav.\nBrain Sci. 16(4), 681\u2013694 (1993)\nYou Are Known by Your Friends: Leveraging Network Metrics for Bot. . . 87\n28. E. Ferrara, Measuring social spam and the effect of bots on information diffusion in social\nmedia (2017). arXiv preprint:1708.08134\n29. S. Fortunato, Community detection in graphs. Phys. Rep. 486(3\u20135), 75\u2013174 (2010)\n30. O. Frank, Sampling and estimation in large social networks. Soc. Networks 1(1), 91\u2013101\n(1978)\n31. L.C. Freeman, Centrality in social networks conceptual clari\ufb01cation. Soc. Networks 1(3), 215\u2013\n239 (1978)\n32. L.C. Freeman, Centered graphs and the structure of ego networks. Math. Soc. Sci. 3(3), 291\u2013\n304 (1982)\n33. K. Gani, H. Hacid, R. Skraba, Towards multiple identity detection in social networks, in\nProceedings of the 21st International Conference on World Wide Web (ACM, New York, 2012),\npp. 503\u2013504\n34. M. Gjoka, M. Kurant, C.T. Butts, A. Markopoulou, Practical recommendations on crawling\nonline social networks. IEEE J. Sel. Areas Commun. 29(9), 1872\u20131892 (2011)\n35. A. Glaser, Russian Bots are Trying to Sow Discord on Twitter After Charlottesville (2017)\n36. L.A. Goodman, Snowball sampling, in The Annals of Mathematical Statistics (1961), pp. 148\u2013\n170\n37. M.S. Granovetter, The strength of weak ties, in Social Networks (Elsevier, Amsterdam, 1977),\npp. 347\u2013367\n38. C. Grimme, M. Preuss, L. Adam, H. Trautmann, Social bots: human-like by means of human\ncontrol? Big Data 5(4), 279\u2013293 (2017)\n39. A. Hagberg, P. Swart, D.S. Chult, Exploring Network Structure, Dynamics, and Function Using\nNetworkx (Los Alamos National Lab.(LANL), Los Alamos, 2008). Technical report\n40. F. Heider, Attitudes and cognitive organization. J. Psychol. 21(1), 107\u2013112 (1946)\n41. P.W. Holland, S. Leinhardt, Transitivity in structural models of small groups. Compar. Group\nStud. 2(2), 107\u2013124 (1971)\n42. P.W. Holland, S. Leinhardt, A method for detecting structure in sociometric data, in Social\nNetworks (Elsevier, Amsterdam, 1977), pp. 411\u2013432\n43. P.N. Howard, B. Kollanyi, Bots,# strongerin, and# brexit: computational propaganda during\nthe uk-eu referendum, in Browser Download This Paper (2016)\n44. B. Huang, K.M. Carley, On predicting geolocation of tweets using convolutional neural\nnetworks, in International Conference on Social Computing, Behavioral-Cultural Modeling\nand Prediction and Behavior Representation in Modeling and Simulation (Springer, Berlin,\n2017), pp. 281\u2013291\n45. L. Katz, A new status index derived from sociometric analysis. Psychometrika 18(1), 39\u201343\n(1953)\n46. D. Krackhardt, The ties that torture: Simmelian tie analysis in organizations. Res. Sociol.\nOrgan. 16(1), 183\u2013210 (1999)\n47. S. Kudugunta, E. Ferrara, Deep neural networks for bot detection (2018). arXiv\npreprint:1802.04289\n48. S. Lee, J. Kim, Early \ufb01ltering of ephemeral malicious accounts on twitter. Comput. Commun.\n54, 48\u201357 (2014)\n49. K. Lee, J. Caverlee, S. Webb, Uncovering social spammers: social honeypots+ machine\nlearning, in Proceedings of the 33rd International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (ACM, New York, 2010), pp. 435\u2013442\n50. K. Lee, B.D. Eoff, J. Caverlee, Seven months with the devils: a long-term study of content\npolluters on twitter, in ICWSM (2011)\n51. D. Liu, B. Mei, J. Chen, Z. Lu, X. Du, Community based spammer detection in social networks,\ninInternational Conference on Web-Age Information Management (Springer, Berlin, 2015),\npp. 554\u2013558\n52. C. Lumezanu, N. Feamster, H. Klein, # bias: Measuring the tweeting behavior of propagandists,\ninSixth International AAAI Conference on Weblogs and Social Media (2012)\n53. Z. Miller, B. Dickinson, W. Deitrick, W. Hu, A.H. Wang, Twitter spammer detection using data\nstream clustering. Inf. Sci. 260, 64\u201373 (2014)\n88 D. M. Beskow and K. M. Carley\n54. A. Mislove, M. Marcon, K.P. Gummadi, P. Druschel, B. Bhattacharjee, Measurement and\nanalysis of online social networks, in Proceedings of the 7th ACM SIGCOMM conference on\nInternet measurement (ACM, New York, 2007), pp. 29\u201342\n55. L.M. Neudert, B. Kollanyi, P.N. Howard, Junk News and Bots During the German Federal\nPresidency Election: What Were German Voters Sharing Over Twitter? (2017)\n56. B. Nimmo, #botspot: Twelve Ways to Spot a Bot\u2014dfrlab\u2014medium (2017). https://medium.\ncom/dfrlab/botspot-twelve-ways-to-spot-a-bot-aedc7d9c110c (Accessed on 11/03/2018).\n57. F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel,\nP. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,M. Perrot, and E. Duchesnay, Scikit-learn: machine learning in Python. J. Mach. Learn. Res.12, 2825\u20132830 (2011)\n58. J. Stubbs, J. Ahlander, Exclusive: Right-Wing Sites Swamp Sweden with \u2018Junk News\u2019 in\nTight Election Race | Reuters (2018). https://www.reuters.com/article/us-sweden-election-\ndisinformation-exclus/exclusive-right-wing-sites-swamp-sweden-with-junk-news-in-tight-election-race-idUSKCN1LM0DN (Accessed on 11/20/2018).\n59. V .S. Subrahmanian, A. Azaria, S. Durst, V . Kagan, A. Galstyan, K. Lerman, L. Zhu, E. Ferrara,\nA. Flammini, F. Menczer, The darpa twitter bot challenge. Computer 49(6), 38\u201346 (2016)\n60. Swedish Defence Reserch Agency, Antalet botar p\u00e5 twitter \u00f6kar inf\u00f6r valet\u2014totalf\u00f6rsvarets\nforskningsinstitut (2018). https://www.foi.se/press--nyheter/nyheter/nyhetsarkiv/2018-08-29-\nantalet-botar-pa-twitter-okar-infor-valet.html (Accessed on 11/20/2018)\n61. K. Thomas, C. Grier, D. Song, V . Paxson, Suspended accounts in retrospect: an analysis of\ntwitter spam, in Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement\nconference (ACM, New York, 2011), pp. 243\u2013258\n62. Twitter. Elections Integrity Data Archive .https://about.twitter.com/en_us/values/elections-\nintegrity.html#us-elections (Accessed on 03/30/2019)\n63. O. Varol, E. Ferrara, C.A. Davis, F. Menczer, A. Flammini, Online human-bot interactions:\nDetection, estimation, and characterization (2017). arXiv preprint:1703.03107\n64. J.-P. Verkamp, M. Gupta, Five incidents, one theme: Twitter spam as a weapon to drown\nvoices of protest, in Presented as part of the 3rd USENIX Workshop on Free and Open\nCommunications on the Internet (2013).\n65. B. Viswanath, M.A. Bashir, M. Crovella, S. Guha, K.P. Gummadi, B. Krishnamurthy, A.\nMislove, Towards detecting anomalous user behavior in online social networks, in USENIX\nSecurity Symposium (2014), pp. 223\u2013238\n66. G. Wang, M. Mohanlal, C. Wilson, X. Wang, M. Metzger, H. Zheng, B.Y . Zhao, Social turing\ntests: crowdsourcing sybil detection (2012). arXiv preprint:1205.3856\n67. H. Yu, M. Kaminsky, P.B. Gibbons, A. Flaxman, Sybilguard: defending against sybil attacks\nvia social networks, in ACM SIGCOMM Computer Communication Review , vol. 36 (ACM,\nNew York, 2006), pp. 267\u2013278\nBeyond the \u2018Silk Road\u2019: Assessing Illicit\nDrug Marketplaces on the Public Web\nRichard Frank and Alexander Mikhaylov\nAbstract Criminals take advantage of internet communications to amplify the\nimpact of their actions and to form international criminal networks. At the same\ntime, vast amounts of information generated by their online activities have become\navailable for analysis. Open source web intelligence is a valuable methodology for\nunderstanding and responding to these new global criminal phenomena. Collecting\ndata from websites, social media platforms and online discussion forums enables\nresearchers, investigators and policy-makers to study and to develop appropriate\nresponses to emerging threats. Automated web intelligence tools such as web\ncrawlers can be used to extract relevant information from target websites and to map\nthe threat landscape of criminogenic environments online. For the study presented\nin this chapter, we used our web-crawling software to download contents of 28\nRussian online marketplaces for illicit drugs. Drug names, types, prices, quantities\nand geographical locations of sales were extracted and mapped to identify drug\ntraf\ufb01cking hotspots. Findings indicate such marketplaces can operate due to the\nability of their clients to pay anonymously with virtual currencies (speci\ufb01cally\nBitcoin and Qiwi) and to deliver the drugs through non-contact methods. This type\nof service is available in all large cities within Russia and provides to the seller with\na safer and more anonymous alternative to \u201cstreet-level\u201d purchases. The method\ndescribed in this study can be used to investigate and to prioritize online threats\naccording to their location and severity.\nKeywords Online drug traf\ufb01cking \u00b7 Anonymous payments \u00b7 Novel psychoactive\nsubstances\nR. Frank (/envelopeback) \u00b7 A. Mikhaylov\nSchool of Criminology, Simon Fraser University, Burnaby, BC, Canada\ne-mail: rfrank@sfu.ca ;amikhayl@sfu.ca\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_489\n90 R. Frank and A. Mikhaylov\n1 Introduction\nThe proliferation of internet connectivity throughout the world has facilitated the\ngrowth of legitimate and illegitimate economies alike. Globalization has made theinternational geographical borders, and the physical distance between buyers and\nsuppliers, largely irrelevant. The digital economy has allowed consumers to pay\nbills, make money transfers and purchase goods with unprecedented convenience,whether locally or internationally. Online payments \ufb01rst emerged in the late 1990s\nin the form e-gold services, owned by Gold & Silver Reserve Inc. (G&SR), which\nallowed users to open online accounts and purchase gold (and other precious metals)in grams, then transfer them to other accounts as payments [ 1]. Whether used for\nlegitimate business opportunities, or shady gambling websites and virtual Ponzi\nschemes, e-gold kickstarted the virtual currency industry [ 1]. Competitors quickly\nemerged, and the competition within the e-currency industry forced market actors to\ninnovate and to offer increasingly varied types of exchange services for converting\ntraditional \ufb01at currency into virtual currency for online transfers/payments. Thekey feature which came to de\ufb01ne the success or failure of a virtual currency is\nthe ease of depositing money into an online account [ 1]. Increased regulatory\nand law enforcement attention to e-gold and novel digital currencies in the mid-2000s has resulted in traditional banking systems, especially in the United States,\ndistancing themselves from e-currencies [ 1]. However, this merely meant e-currency\ncompanies would operate outside jurisdictions with strict regulations.\nE-currencies and mobile payments often avoid anti-money laundering (AML)\nlegislation as virtual currencies are not emitted or controlled by banks and as a\nresult these organizations are not subject to the same regulations [ 2]. With the\nadvent of e-commerce, the goods and services offered on underground markets have\nbecome increasingly diverse. While initially focused on trading in stolen credentials,\nstolen \ufb01nancial data and hacking, a new sector of the underground economy roseto prominence in 2011 with the creation of Silk Road\u2014the \ufb01rst crypto-market for\nillicit drugs, with many successors to follow [ 3]. While a European survey showed\nthat most illicit drug purchases among young people still relied on traditional retaildistribution models, the United Nations Of\ufb01ce on Drugs and Crime (UNODC)\nreported 90% of UNODC member states identi\ufb01ed the internet as a source of drug\ntraf\ufb01cking [ 4]. It is especially true in relation to \u201cnovel psychoactive substances\u201d\n(NPS), also known as \u201clegal highs\u201d, which are chemically distinct analogs of\ntraditionally used drugs not yet legally regulated.\nDespite the rapid rise of crypto-markets, internet-based drug traf\ufb01cking still\nrepresents only a small fraction of the world drug trade [ 5]. Traditional drugs remain\nthe dominant part of international drug traf\ufb01cking despite the rising popularity of\nNPS. Market diversi\ufb01cation, however, has encouraged polydrug abuse, which posesrisks to users as increasing numbers of different and previously unseen substances\nbecome available for purchase. Opioid users, for example, are at risk of consuming\nmuch stronger and deadlier fentanyl instead of traditional heroin, as syntheticopioids are more economically ef\ufb01cient to produce [ 4]. For instance, 260 substances\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 91\nclassi\ufb01ed as NPS were reported in 2012, and that number grew to 483 in 2015, with\napproximately 80 novel psychoactive substances securing a stable presence on the\nglobal drug market. Synthetic drug production is not tied to a particular locale, asthese substances do not rely on extracting chemicals from speci\ufb01c plants and can be\nproduced and distributed worldwide from anywhere [ 4].\nAlong with the emergence of NPS, \u201cnew payment methods\u201d (NPM) have gained\ntraction in legitimate and illegitimate economies alike. NPM include, but are not\nlimited to, prepaid cards, mobile payment services and internet-based payment\nservices which serve as an alternative to traditional payment methods, or offer aninnovative way of transferring value between individuals and organizations [ 6]. For\nthe study presented in this paper, we considered how NPM, speci\ufb01cally mobile\npayments and crypto-currencies, are used to enable the purchasing of illegal drugsonline in a safe and secure fashion. We used our automated web data collection\ntool, called The Dark Crawler (TDC), to analyze advertisements from illicit drug\nmarketplaces on the public web to assess business practices of this new emergingsector of the illicit drug market. TDC collects webpages from target websites, and\nthen, using customized rules, extracts user-speci\ufb01ed content from the pages [ 7\u20139].\nHowever, these marketplaces frequently implement strategies to prevent the typeof web-analysis we were trying to undertake. Speci\ufb01cally, they utilized Distributed\nDenial of Service (DDoS) attack protection and captchas. This required modifying\nour software to be able to satisfy these requirements and allow for (mostly-)automated data-capture. In this study, we used our modi\ufb01ed TDC to analyze 28\nonline drug markets in order to identify types of substances sold, prices, payment\nmethods used and geographic distribution of drug sales.\nFirst, we provide a brief literature review on international drug traf\ufb01cking and\nidentify conditions which lead to the emergence of markets for new psychoactive\nsubstances, and review research on data capture from the internet. Then we outlineour data collection methodology, considerations for data capture, followed by an\nanalysis of the data we captured from online drug marketplaces. Finally, the results\nand limitations are discussed as the paper is concluded.\n2 Literature Review\n2.1 Drug Prohibition and Drug Market Evolution\nThe United Nations (UN) played a major role in the internationalization of drug\nprohibition. The 1961 Single Convention on Narcotic Drugs represents a major\nmilestone of drug regulation which was widely adopted throughout the world\n[10]. The Single Convention was heavily in\ufb02uenced by the United States due\nto the American role in the creation of the UN. All 198 nations which signed\nthe Single Convention implemented generally similar drug laws, criminalizing\ncultivating and re\ufb01ning drugs such as opioids and cannabis. The Single Convention\n92 R. Frank and A. Mikhaylov\nwas supplemented by the addition of psychotropic substances (e.g. LSD) to the\nlist of prohibited drugs in the 1971 Convention on Psychotropic Substances [ 10].\nAdherence to the Single Convention differs throughout the world, from lenient drugpolicies (e.g. Netherlands and Portugal), to stricter hardline approaches (e.g. the UK\nand Russia) [ 10\u201312]. Cannabis, opiates and amphetamine-type stimulants (ATS) are\nthe three most traded and consumed types of drugs today [ 4].\nWorldwide criminalization of traditional drugs has eventually produced a partial\nmarket shift to novel designer drugs, also called \u201clegal highs\u201d. Producers of such\nsubstances can get ahead of legislators and distribute psychoactive substances whichare not yet criminalized. Some of the most known novel psychoactive substances\nare \u201cspice\u201d (synthetic cannabinoids) and \u201cbath salts\u201d (synthetic cathinones) [ 13\u2013\n15]. \u201cSpice\u201d refers to an herbal mixture with added synthetic cannabinoids typically\nmarketed as incense, which is sold online and in some countries in specialty stores\nsuch as tobacco shops. It \ufb01rst appeared in Europe and the United States in the\nearly 2000s, signaling the rise of the market for \u201cnew psychoactive substances\u201d(NPS) [ 16,17]. \u201cSpice\u201d is used as an alternative to marijuana, as users reported\neffects similar to those achieved by smoking cannabis [ 17]. Along with different\ndrug consumption patterns, emerging NPS markets have resulted in new distributionmodels. \u201cSpice\u201d and \u201cbath salts\u201d are available for purchase online on specialized\nwebsites that can be located through any search engine [ 15]. The internet has\nenabled easy access to outlets which sell prescription and non-designer illegal drugsdue to regulatory dif\ufb01culties inherent in controlling businesses which are dispersed\namong different jurisdictions [ 17]. Bath salts are typically advertised online as a\nlegal alternative to amphetamine-type stimulant drugs. In the early 2000s, thesesubstances were sold in retail stores owing to their legality at the time, but following\ntheir prohibition in 2010s in the US and Europe, the internet has become the primary\nsource of distribution for bath salts and similar new psychoactive substances (NPS)[15,18,19]. In the US, synthetic cannabinoids were not widely known before\n2009, but by 2010 the interest in \u201cherbal incense\u201d and other names for synthetic\ncannabinoids skyrocketed, based on internet searches [ 16].\n\u201cHot spots\u201d of illegal drug trade have emerged on the internet due to the\nanonymity, global reach, and availability of impersonal payment methods which\ndo not require client identi\ufb01cation [ 20]. Silk Road, the archetypal crypto-market\nfor illicit drugs, was structured similarly to eBay, providing a platform where any\nvendor can sell their product and any user can make purchases. This business model\nwas made possible due to the ability of clients to make anonymous payments withthe crypto-currency Bitcoin, while Silk Road itself was hosted in the encrypted Tor\nnetwork to maximize anonymity and to minimize risks to participants. The business\nmodel pioneered by the Silk Road was revolutionary because it allowed users toaccess vendor reviews and detailed information about the product, which served\nto mitigate distrust in an environment of uncertainty [ 21\u201325]. Customers of Silk\nRoad have listed a number of reasons for using the marketplace, such as access toa wider range of drugs, convenience, con\ufb01dence in highly rated sellers and lower\nprices [ 21]. Additionally, users found desirable the lack of necessity to turn to street\ndealers to acquire drugs [ 26]. User feedback for products they received typically\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 93\ndescribed quality (purity) of the product, delivery speed and packaging stealth [ 26,\n27]. Convenience, high variety and low risk were the key reasons why internet users\nmay purchase recreational drugs online.\nWhile crypto-markets have received extensive attention from journalists, aca-\ndemics and law enforcement alike, there is another form of internet-mediated\ndrug traf\ufb01cking that has emerged in post-Soviet states, termed \u201cnoncontact drugdealing\u201d. Like crypto-markets, this method relies on an online storefront where\nadvertisements for drugs are displayed, but the delivery method is different, as well\nas the fact these marketplaces are hosted openly in the public web and require noregistration to access. Instead of shipping, noncontact drug dealing marketplaces\nutilize pre-arranged drug stashes located throughout the market\u2019s area of operation.\nOnce the payment for drugs has been received, marketplace operators transferinstructions on how to locate the stash to clients as an instant message. The seller\nand the buyer never interact except online, and the buyer makes a money transfer\nusing one of the new digital payment methods with minimal identi\ufb01cation measures.This method is discussed in Russian-language literature on online drug traf\ufb01cking,\nas well as a Financial Action Task Force (FATF) report, which emphasize the abuse\nof virtual currencies such as Qiwi, WebMoney and YandexMoney for making theseillegal transactions [ 28\u201330]. The ability of these marketplaces to operate openly is\npossibly explained by bureaucratic and legislative obstacles encountered by Russian\nlaw enforcement in policing online drug dealing [ 31\u201333].\n2.2 Noncontact Drug Dealing\nThe \u201cnoncontact\u201d method of drug dealing has gained prominence due to the ability\nof individuals to use \u201cnew payment methods\u201d with minimal identi\ufb01cation measures.\nBy communicating with drug vendors over the internet through discussion forums,\nonline storefronts and marketplaces, drug users are able to procure prohibitedsubstances without ever meeting the seller. The buyer and the seller agree on a\nplace, which is used as a hiding spot for drugs, and a time for pickup. Once\nthe buyer has made the payment, they receive instructions on where to \ufb01nd thestashed drugs [ 34]. Noncontact drug dealing appears to be predominantly used\nin Russia and neighboring Commonwealth of Independent States (CIS) countries.\nThe Financial Action Task Force (FATF) report which included a description ofthe noncontact drug dealing method used an example that referred to Russia and\nTajikistan [ 34]. Noncontact drug dealing has been described extensively in Russian\nacademic journals. Drug market actors have started using mobile payment providers,such as Qiwi, WebMoney or YandexMoney, which enable money transfers between\nindividuals [ 29]. A source in Russian law enforcement claimed that hand-to-hand\ndrug dealing has become virtually non-existent and drug traf\ufb01ckers have largelymoved on to noncontact drug dealing [ 35].\nThe essence of the noncontact drug dealing method can be described as follows:\n(1) the buyer makes an order online (through a website or an instant messenger);\n94 R. Frank and A. Mikhaylov\n(2) the buyer then makes a payment with a virtual currency or as a mobile money\ntransfer; and (3) the buyer receives instructions as an SMS or an instant message\non where to \ufb01nd the stash with drugs [ 36]. This method of drug distribution became\ncommonplace because it signi\ufb01cantly reduces the risk of becoming the target of buy-\nand-bust operations [ 30]. The current study analyzed 28 online drug marketplaces\nall of which used the noncontact drug dealing method. The data pertaining togeographic distribution of online marketplaces, drug types, prices, amounts and\npayment methods were extracted to evaluate criminal risks posed by the noncontact\nmethod of drug dealing coupled with the ability to make anonymous payments.\n2.3 Data Capture from Web\nThe information age brought about persistent connectivity, and with it came theever-present digital cataloging of our activities\u2014whether legitimate or illegal. Tak-\ning advantage of these \u201cdigital traces\u201d allows researchers to study online activities\nof criminals in their natural environment\u2014so-called \u201cconvergence settings\u201d, ratherthan relying on potentially unreliable self-report data in surveys or interviews from\na subset of \u201cunsuccessful\u201d criminals who were apprehended [ 5,37]. Manual data\ncollection is a labor-intensive process as it may require researchers to analyzehundreds and thousands of webpages which need to be saved locally, coded, and\n\ufb01nally subjected to analysis. Despite this, manual data collection can provide\nlarge and rich datasets, which proved valuable for an in-depth analysis of onlinecriminal activities [ 5,37]. For example, Buskirk and colleagues sampled a crypto-\nmarket called Agora, at the time the largest \u201cdark net\u201d market, by manually saving\nwebpages and extracting the data with a Microsoft Excel VBA macro [ 38]. This\nmethod allowed authors to automatically categorize nearly 80% of listings, which\nshows that manual data collection is not necessarily an obstacle to ef\ufb01cient internet-\nbased research [ 38].\nAutomated data collection relies on software that creates local copies of the target\ncontent hosted online, a process called \u201cmirroring\u201d, and extracting the relevant data\nfrom saved webpage content in a process called \u201cscraping\u201d [ 39]. Also known as web\ncrawling, this process has typically been focused on online social networks such as\nblogs and forums, and also websites, often for consumer research and marketing\npurposes. In a review of research on web crawling most of studies were published inearly 2000s and were concerned with conventional content such as cooking recipes\nand movies in the surface web [ 40]. The context of these studies is signi\ufb01cantly\ndifferent from criminal content hosted on the public web or the \u201cdark web\u201d, wheresite administrators may take active steps to protect the website contents from access\nand indexing by automated means. The original Silk Road used cookies that allowed\nusers to stay logged in for a week before expiring, which enabled researchers tobypass captchas while crawling the website [ 41]. Unlike the \ufb01rst iteration of Silk\nRoad, Silk Road 2 did not use a captcha or require manipulating website cookies\nto perform data capture, enabling researchers to produce what the authors claims is\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 95\na complete crawl of the website [ 23]. This approach however was criticized due to\nthe instability of websites hosted in the Tor network undermining automated data\ncollection methods which possibly result in incomplete datasets [ 38].\nWeb crawling, or \u201cmirroring\u201d, is typically performed in the following fashion:\nstarting with a single webpage, the program indexes all hyperlinks within it then\nfollows those links, repeating the process for each subsequent webpage within limitsset by the user [ 39]. Ready-made solutions capable of mirroring webpages exist,\nsuch as HTTrack [ 23]. However, HTTrack and similar software will only mirror\nwebpages, without analysis, thereby requiring subsequent steps for data cleaningand conversion of the unstructured data into structured data. Scraping can also\nbe performed by separate programs, called scrapers, which can parse webpages to\nidentify relevant content, such as usernames attached to forum posts or drug names[39]. Custom-written web crawlers tend to have more functionality than freely\navailable solutions, such as the crawler DATACRYPTO which was speci\ufb01cally\ncreated for studying drug listings on the original Silk Road. This crawler bothmirrored and scraped the webpages, building a database of drug listings, vendor\ninformation and buyer feedback. Creating a custom web crawler from scratch\nrequires signi\ufb01cant investments and may not be feasible for all researchers [ 5,39].\nFor this study, the contents of target websites were downloaded using a custom-\nwritten web crawler and scraper called The Dark Crawler (TDC). TDC has\npreviously been used to study hacker forums and extremist websites and toidentify terrorist and child exploitation content on the dark web [ 9,42\u201344]. In\naddition to automated data collection, TDC allows integrating other analytical\ntools for studying the extracted content. For example, natural language processing(NLP) supplemented with parts of speech (POS) tagging were used to calculate\nsentiment scores for posts on hacking forums that reference attacks against critical\ninfrastructure such as government facilities, banks and hospitals [ 42]. Sentiment\nanalysis showed discussions of prominent topics, such as \ufb01nancially motivated\nattacks against banks, or exploitation of vulnerabilities in government systems,\ncorresponded to actual data on these incidents\u2014what forum members discussare types of attacks that are typically carried out [ 42]. Understanding the threat\nlandscape of such attacks can help potential targets prepare for them and mitigate\nthe damage. Another advantage of using an automated web crawler is the lack ofnecessity to manually review potentially disturbing media to establish their criminal\ncontent. For instance, identifying child exploitation and terrorism-related images is\npossible through image hashing, where each image is assigned a hash value that canbe compared against law enforcement databases of known illegal images [ 9].\n2.4 Studying Online Drug Traf\ufb01cking\nBeing the most notorious drug marketplace, the Silk Road attracted much attention\nfrom academics. This drug marketplace was one of the \ufb01rst to be studied in-depth\nbefore its shutdown by the authorities. The number of methods and approaches\n96 R. Frank and A. Mikhaylov\nused was quite varied, from qualitative analyses of attitudes towards online drug\npurchases, to analyzing trends among drug listings by saving snapshots of the\nwebsite for a given period [ 17,38]. By collecting vendor names and PGP keys\n(cryptographic sequences used to authenticate a user) through an automated web\ncrawler, researchers were able to describe organizational structure of online drug\ndistribution networks [ 22]. In order to evaluate the impact of Silk Road\u2019s closure\non the \u201cdarknet\u201d drug traf\ufb01cking economy, the number of vendors on competitor\nwebsites was analyzed through approximately one month period. Despite the\nshutdown of a major distribution hub, the drug market actors were able to quicklyadapt and to relocate to competing markets, as demonstrated by an explosive growth\nof the number of vendors on them [ 38]. Multiple studies categorized the illicit\ngoods offered on these marketplaces, ranging from drugs to pornography, stolendata and weapons [ 23,24]. We chose to focus on extracting and analyzing sales\ndata \u2013 speci\ufb01cally drug names, prices, quantities and regions where they were\navailable. This methodology allows to present an overview of the noncontact drugdealing problem and its extent, as well as to consider implications of this method\nfor combatting drug traf\ufb01cking internationally.\nFurthermore, as stated previously, noncontact drug dealing is a topic of extensive\ndiscussion among Russian-speaking academics and law enforcement profession-\nals [ 28\u201330,35,36,45\u201348]. However, the studies are primarily concerned with\norganizational aspects of noncontact drug dealing [ 28,29,36,46\u201348], as well as\ninvestigative methods and practices [ 29,46,48]. Few studies attempt to characterize\nthe drug market facilitated through these online marketplaces in terms of drug types,\nprices and volumes beyond general trends (e.g. a 9.5% increase in consumption ofsynthetic drugs between 2013 and 2015) [ 35,36,45]. By leveraging data collection\ncapabilities of the web crawler, we were able to provide an overview of the market\nbased on the publicly available drug listings data [ 23].\n3 Methods\nAs this is an exploratory study, the intention was to identify market prices, the\nscale of the problem (i.e. how widespread non-contact drug dealing is), and which\npayment methods were used to pay for the drugs. Speci\ufb01cally, the goal is to\nsystematically go through entire online websites and extract the required contentso the drug prices can be analyzed. To do this, 28 websites were selected (Sect.\n3.1). However, before data could be captured via our existing The Dark Crawler\n(TDC) infrastructure, several challenges had to be overcome as the target websiteshad implemented techniques to speci\ufb01cally prevent automated bots from entering\nthe site. After these changes were implemented (Sect. 3.2) we were able to capture\nthe required pages (Sect. 3.3), and de\ufb01ned rules (Sect. 3.4) which allowed us to\nextract the drug prices, locations and volumes into an analyzable dataset.\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 97\n3.1 Data Selection\nExploratory research led us to public Russian drug forums as a starting point, where\nadvertisements of drug markets in our sample were discovered. A clear pattern\nemerged among the websites found\u2014their designers relied on largely the same\nwebpage template with minor variations such as background images. Additionally,these websites were named similarly and hosted on the same top-level domain\n.biz(for example, narco24.biz, kumar24.biz , etc.). Although multiple domains were\nused, .bizappeared to be the most prevalent\u2014searches for \u201c24 biz\u201d proved to be the\nmost fruitful, while searches for \u201c 24 pw \u201do r\u201c 24 cc \u201d yielded less relevant results.\nOverall, over 47 open drug market websites were identi\ufb01ed by searching \u201c24 biz\u201d\nfrom 100 search hits spread out on 10 pages of the results from the Russian searchengine Yandex. Inclusion criteria were established, where an open drug market\nwebsite had to (1) be public (accessible without registration) and (2) display drug\nadvertisements. Between June 2016 and August 2016, only 28 out of 47 (59.5%)drug market websites remained available long enough to be captured, whereas 19\n(40.5%) had to be omitted as no advertisements were displayed.\n3.2 Data Collection Challenges\nTDC has been used to crawl webpages and extract structured data from them (for\nexamples, see [ 9,42\u201344]), however the websites that were picked for this study\ndiffered from previously studied websites in that these were protected by DDoS\nbrowser checks.\nThere are multiple commercial solutions available to defend against DDoS\nattacks, for example, by shielding the target website with proxy servers that\ndistribute the incoming traf\ufb01c between themselves and balance the load, or requiring\nthe browser to solve JavaScript calculations before the page is displayed. If thisability to solve JavaScript calculations is not present, then it is highly likely that\nthe requestor is an automated web crawler. The online marketplaces for illegal\ndrugs sampled for the current study utilized DDoS protection offered by a majorcommercial provider also relied on by legitimate businesses. By integrating the\nability to bypass DDoS browser checks into the TDC, we have signi\ufb01cantly\nexpanded the pool of websites the data can be collected from. TDC initially wasrelying on simple GET requests executed in parallel via multiple threads to retrieve\nmultiple HTML pages simultaneously (Fig. 1). However, while this method does\nretrieve the HTML served by the server, it does not interpret (i.e. execute) any ofthe content on it. Any JavaScript code that is required does not run (because it is\nnot even retrieved, unless it is embedded into the HTML), thus the checks that run\nagainst the browser would fail. To get around this problem, the GET method wasreplaced by the customizable web-browser engine Chromium. See Fig. 2for a high-\nlevel overview of the structure of TDC.\n98 R. Frank and A. Mikhaylov\nFig. 1 The Dark Crawler high-level overview (original)\nFig. 2 The Dark Crawler high-level overview (modi\ufb01ed)\nTo capture the data from these websites, the webpage-retrieval engine used\nby TDC was replaced with an actual browser capable of being automated. In\nthis fashion, the automated browser, called VisualChromium, could access andrender the webpages just like any other browser would, in the process solving\nany JavaScript required. When the browser-checks were done, and the webpage\nloaded, the automation kicked in and the HTML retrieved was analyzed. Some pagesrequired the solving of captchas to con\ufb01rm the user is human and the retrieval is not\nan automated request. As pages are being retrieved, TDC checks if each page meets\ncertain conditions, such as speci\ufb01c text (not) being present. If these conditions aremet, TDC moves onto the next page, and if not, the data capture stops and awaits\nuser action. A condition which was present on \u201cnormal\u201d pages but not captcha pages\nallowed the Crawler to recognize captcha pages and to wait for user action before\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 99\nFig. 3 A summary of the data capture process\ncontinuing. In the future, automated captcha solving will be investigated, but for the\nsites downloaded in this study, the websites did not use captchas, and thus this wasnot an issue.\nAfter the \u201cmirroring\u201d process was complete, the captured data was extracted\nbased on user-speci\ufb01ed data rules (see Fig. 3for an overview, and Sect. 3.4for more\ndetails). All rules were applied to all data, producing a .csv format \ufb01le compatible\nwith Microsoft Excel. Each column represents a data element (e.g. drug names)\nand rows represent single web-pages. Particularities of data collection and using theDark Crawler are discussed below.\n3.3 Final Data Collection\nThe Dark Crawler is an automated data collection tool which is able to download\nentire contents of webpages utilizing user-speci\ufb01ed rules. Given a list of webpages,\nthe Crawler will traverse them and parse them apart. The process is as follows:\n100 R. Frank and A. Mikhaylov\n<HTML>\n<DIV>\n<A href=\u201dindex.html\u201d>Home</A>\n</HTML><HTML>\n<DIV>\n<A href=\u201dindex.html\u201d>Home</A>\n</DIV>\n</HTML>\na) HTML tags are not closed properly in  a lot of websites b) Standard HTML\nFig. 4 Real-life HTML vs the standard. ( a) HTML tags are not closed properly in a lot of websites.\n(b) Standard HTML\n\u0081 For each webpage within the Queue, repeat until the Queue is empty\n\u2013 the Crawler gets a webpage from the queue of webpages to retrieve;\n\u2013 it retrieves the webpage, resulting in an HTML string;\n\u2013 the webpage HTML is cleaned up, with invalid (or unclosed) tags \ufb01xed\n(see Fig. 4for an example);\n\u2013 the HTML is parsed according to data capture rules and relevant\ninformation is identi\ufb01ed, such as links or images\n\u2013 each link within the HTML is added to the queue of future pages to be\nretrieved\n\u0081 Rules are applied to the cleaned HTML to extract user-de\ufb01ned pieces of\ndata (in this case, drug names, prices, amounts, etc.) into a spreadsheet\n(see Sect. 3.4for details).\nAs the captured data is stored in a structured database, the data extraction process\ncan be repeated after the data capture process, and the data extracted in multiple\nways, e.g. by searching for speci\ufb01c keywords or extracting certain types of dataelements (e.g. drug names). The resultant information is then saved in the form of a\nmatrix, with each webpage in a row, and each extracted data-element in a column.\nThis data can then be subjected for further analysis by, for example, geo-mappingthe distribution of drug sale locations.\n3.4 Data Extraction\nLanding pages of drug marketplaces in our sample were structured in a similar way.Each drug advertisement was placed inside a container that showed drug name,\nprice, quantity, whether the goods were in stock, and a \u201cBuy\u201d button which would\ntake the user to a page with transaction details. An example of such a webpage isshown in Fig. 5. Each webpage element can be targeted for capture by de\ufb01ning data\nrules. Some of the websites in the sample modi\ufb01ed the default webpage template\n(e.g. by restructuring and renaming elements of the webpage), however the overall\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 101\nstructure was consistent across all 28 sites studied. TDC downloaded each page,\ncleaning up unnecessary data, resulting in a structured table containing data from\nthese webpage elements. This enables the user to quickly extract all the requiredinformation from a webpage, signi\ufb01cantly reducing the amount of manual work\nrequired to preserve these data.\nThe Dark Crawler identi\ufb01es relevant information within the webpage by relying\non data rules speci\ufb01ed by the user. A data rule is a {path,pattern }combination,\nwhich uses the XPaths standard for path querying trees and the XQuery standard\nfor the pattern s, see Sects. 3.4.1 and 3.4.2 respectively for more details. This\nprocess allows selecting elements from a webpage to be downloaded and stored\nin a database.\nUsing Paths to Select Webpage Elements\nA hierarchy of branches from the root makes up a path, which follows the XPaths\nstandard, where a path results in zero or more nodes in a tree. To identify the drug\nname which is priced at \u201c900\u201d in Fig. 5, the Crawler identi\ufb01es distinct containers on\nthe webpage, traversing series of branches ( div, ul, li, anddiv), where the path would\nbe \u201c/html/body/div/section/ul/li/div \u201d. Figure 6shows how this process identi\ufb01es 4\ndrug names located on this webpage, one per container. To select a speci\ufb01c drugname from the list, the path is modi\ufb01ed to target one of the <div> tags under <li>.\nThe resultant rule then would be \u201c /html/body/div/section/ul/li/div[2] \u201d which directs\nthe Crawler to select the second divtag from the branch. By iterating through all the\ndivtags in this fashion, all prices can be extracted for all the drugs on the webpage.\nA similar strategy is used to extract all other required content.\nFig. 5 A typical drug marketplace landing page with advertisements displayed\n102 R. Frank and A. Mikhaylov\nFig. 6 HTML content as a tree on a similar drug market website. ( a) An illustration of how TDC\nnavigates through webpage elements. ( b) The HTML code of a webpage, shown as a tree-like\nstructure\nApplying Patterns to Filter Results of Paths\nTargeting the webpage element allows the Dark Crawler to download the desirable\ncontent, but not necessarily in the proper format. The rule selects the necessary\nelement, but cannot select any speci\ufb01c parts of it. This is problematic, for example,\nwhere the price would be extracted as \u201c900 \u00d3\u00d6\u00c4.\u201d, and not just \u201c900\u201d. To remove\nunnecessary text or to perform calculations with the result of operations with the\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 103\npath rule, patterns are used, which in turn follow the standard language of XQuery.\nFor an example, working with Fig. 5, the currency is speci\ufb01ed after the numeric\nvalue, which is in rubles for all the advertisements in the sample. Moving downthe HTML branches to /li/div class =\u201cprice \u201d would produce the result \u201c900 \u00d3\u00d6\u00c4.\u201d,\nwhere only \u201c900\u201d is necessary. Specifying a pattern in addition to the path will prune\nany unnecessary data. The pattern \u201c(?<RESULT1>.*) \u00d3\u00d6\u00c4.\u201d is created to remove the\ntext following the numeric value.\n4 Results\n4.1 eDrugs\nOnce the 28 websites were captured, and rules set up, 935 drug advertisements\nwere extracted. Most of the sample (N =839, 89.7%) was represented by small\nquantities intended for personal use ranging between 0.3 and 10 g per order.\nHowever, a fraction of the sample (N =97, 10.3%) contained larger quantities\nof drugs, advertisements for which were marked as \u201cwholesale\u201d or \u201cpre-order\u201d.\nDrug amounts in \u201cwholesale\u201d orders ranged between 3 and 1000 g, where smaller\nmarketplaces typically sold a few grams of substances per order, and largermarketplaces offered amounts upwards of tens and hundreds of grams per posting.\nEach website displayed between 1 and 250 drug postings, with 29 on average.\nAmong types of substances being sold, wholesale orders and consumer-sizedorders taken together, amphetamine-type stimulants made up 58.5% (n =547),\nsynthetic cannabinoids\u201422.4% (n =210) and natural cannabinoids, i.e. marijuana\nproducts\u201416.3% (n =153). The rest of the sample, 2.9% (n =25) was represented\nby hallucinogens, advertised by a single marketplace as \u201cacid\u201d. This is shown in\nFigs. 7and8. Regional differences between drugs offered for sale are visible in\nFig. 8. More variation in substance types can be observed in the Urals region, and\nnatural cannabinoids appear more frequently.\n4.2 Markets\nThree categories of drug marketplaces become immediately evident \u2013 large (sales\nrevenue over $4000), medium ($800\u2013$1600) and small (under $800). The distri-\nbution of total drug prices across marketplaces and average drug prices across theCentral region respectively are shown in Figs. 9and10. While large marketplaces\nconducted business in multiple cities and different geographical areas, medium mar-\nketplaces were limited to a more meager area of operation, and small marketplacesfocused exclusively on a single city and/or small suburban towns located closest to\nit. Drug prices across the country remained surprisingly consistent, which could be\nexplained by established equilibrium prices or price \ufb01xing.\n104 R. Frank and A. Mikhaylov\nFig. 7 Marketplaces by substance type\nFig. 8 Substance types spread across the region\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 105\nFig. 9 Marketplaces by total price\nFig. 10 Average prices across the region\n106 R. Frank and A. Mikhaylov\n4.3 Payment Methods\nNoncontact drug dealing literature implicates virtual currencies such as Qiwi,\nWebMoney, YandexMoney and Bitcoin in internet-mediated drug traf\ufb01cking, as\nthese virtual currencies offer convenient ways to pay without being subjected to\nthe same standards for identi\ufb01cation as bank payments would be. However, in oursample of open web drug markets only Qiwi and Bitcoin were used. Furthermore,\nQiwi, a mainstream virtual currency marketed as a vehicle for personal money\ntransfers and utility bill payments, was used more often\u2014on 28 marketplaces, asopposed to 20 for Bitcoin (see Figs. 11and12). This is perhaps due to the fact Qiwi\nis much more \u201cuser-friendly\u201d, where anyone can create an online wallet without\nany identi\ufb01cation. Anonymous Qiwi wallets are limited to $250 per transaction upto $665 per month, and personal money transfers (person-to-person transactions)\nare prohibited by federal legislation. Nevertheless, these personal money transfers\nplay a key role in facilitating online drug traf\ufb01cking, as open web drug markets\u2019business model relies on simple and straightforward payments available to any\ninternet user without a level of technical and \ufb01nancial competency required to use\ncrypto-currencies. Even without taking into account the illegal nature of goods beingsold on these marketplaces, payments for these goods themselves are against the\nlaw. A number of procedural and legislative obstacles exists which prevent ef\ufb01cient\npolicing of the internet environment by the Russian law enforcement, as mentionedabove.\nFig. 11 Marketplaces by payment methods\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 107\nFig. 12 Payment methods across the region\n5 Discussions and Conclusion\nThe digital economy has reshaped trade in both conventional and illicit goods.\nInternational drug prohibition regimes criminalizing traditional drugs throughoutmost of the world forced drug markets to adapt and to innovate, resulting in the\nrise of novel synthetic drugs acting as analogs of traditional substances capable\nof being produced anywhere. Although the majority of world drug traf\ufb01ckingis still made up of traditional drugs, the rising popularity of novel psychoactive\nsubstances and innovative methods of their distribution emerging online represent\na new worrisome trend. Taking advantage of opportunities afforded by the digitaleconomy and e-commerce, drug traf\ufb01ckers have capitalized on the ability to sell\nnovel, not yet regulated substances with the use of new payment technologies that\nenable their clients to pay with relative anonymity. We analyzed 28 online drugmarketplaces which sold both traditional and novel psychoactive substances. While\namphetamine-type stimulants and synthetic cannabinoids dominated the sample,\ntraditional marijuana products and some hallucinogens were also advertised. Thesemarketplaces primarily targeted the average consumer with drug amounts intended\nfor personal use, however larger marketplaces also offered business-sized amounts\nof drugs for purchase.\nDrug marketplaces which utilize noncontact drug dealing advertise and distribute\ndrug products through internet sites, similarly to crypto-markets, but rely on a\ndifferent delivery method, i.e. pre-arranged stashes. The ability of marketplaceclients to carry out anonymous transactions via Qiwi and Bitcoin enables this\n108 R. Frank and A. Mikhaylov\nbusiness model to exist. Relative to crypto-markets, these websites are even easier\nto access, and the ability to pay with a common virtual currency enables anyone\nwith a small amount of cash and a mobile phone to make a purchase. Operators ofdrug marketplaces in our sample took active steps to prevent automated access to\ntheir websites, which were circumvented by designing a separate application acting\nas web browser that can be used to solve the captcha and pass a DDoS protectionbrowser check so that the crawl may continue. Automated data collection enabled\nus to download and analyze 935 advertisements for drugs, identifying contours and\npractices of the market. Although some of the websites identi\ufb01ed as online drugmarketplaces became unavailable during the data collection period, the information\nfrom the remainder of the sample was suf\ufb01cient to chart and map the extent of\nthe problem. Online drug marketplaces appear to operate throughout major citiesand population clusters, where a higher variety of drugs is offered. Expanding the\nsample to include more drug marketplaces and/or locations would result in a more\ncomplete picture of the market. Such studies can be used to identify innovations indrug distribution, as well as to gauge consumption patterns among drug users.\nThe total number of noncontact drug-dealing marketplaces is unknown, therefore\nrepresentativeness of our sample cannot be stated with certainty (935 postingsacross 28 marketplaces). Nearly half of the drug marketplaces initially identi\ufb01ed\nfor data capture became unavailable or had no postings displayed during the\ndata collection period, pointing to instability of these websites perhaps due tomarket forces, business practices such as exit scams or law enforcement pressure.\nWhile these results may not paint a comprehensive picture, this study offers a\nglimpse into the noncontact drug dealing market which exists due to the abilityof marketplaces operators to exploit virtual currencies with low (or none, in case\nof Bitcoin) customer identi\ufb01cation standards. Since this study only considered\nRussian-language online drug marketplaces, external validity of these results maybe low due to differences in legislation, availability of payment providers or drug\ntraf\ufb01cking routes. Nevertheless, the delivery method, i.e. pre-arranged stashes,\nrepresents an innovation in drug distribution that drug traf\ufb01ckers in other countriesmay also utilize assuming there are easy payment methods in place for internet users\nto transfer value (digital currency in most cases) from one person to another.\nFrom a law enforcement perspective this type of non-contact drug purchase\nposes several challenges in identifying the dealer. While the delivery method would\nprevent the de-anonymization of the seller, the payment method, both Qiwi and\nbitcoin, could be traced. Although the money could be traced when the buyertransfers Qiwi to the dealer, as both the sender and recipient use mobile phones,\nthe dealer can add a layer of security to the transaction by immediately converting\nQiwi to physical currency through ATM withdrawals, and through the use ofburner-phones. This would provide only a small window of opportunity for law\nenforcement to identify the identity and location of the dealer, before the money\nis withdrawn and the burner phone disposed. In the event the buyer pays withbitcoins, the identi\ufb01cation of the dealer becomes much more challenging, as it takes\nsigni\ufb01cant effort to trace Bitcoin payments through tumblers, and eventually to a\nBitcoin exchange, where the money might not be withdrawn for years. Finally,\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 109\nlaw enforcement could try to identify and to apprehend the author/owner of the\nwebsite which peddles NPS, although, given the large number of cities where NPS is\navailable through online non-contact methods, it is very likely that the owner of thewebsite is acting as a middle-man between the buyer and the actual on-site dealer.\nLike crypto-markets, larger drug marketplaces in our study also offered business-to-\nbusiness purchases with drugs intended for resale, emphasizing the scalability of thisbusiness model which can serve both individuals and subsequent drug traf\ufb01ckers in\nthe chain of distribution.\nReferences\n1. P. Mullan, Who uses digital currency? in The Digital Currency Challenge: Shaping Online\nPayment Systems Through US Financial Regulations (Palgrave Pivot, New York, 2014), pp.\n13\u201315\n2. T. Tropina, Fighting money laundering in the age of online banking, virtual currencies and\ninternet gambling. ERA Forum 15(1), 69\u201384 (2014)\n3. D. D\u00e9cary-H\u00e9tu, L. Giommoni, Do police crackdowns disrupt drug cryptomarkets? A longi-\ntudinal analysis of the effects of Operation Onymous. Crime Law Soc. Chang. 67(1), 55\u201375\n(2017)\n4. United Nations Of\ufb01ce on Drugs and Crime, World Drug Report 2017 (2017), https://\nwww.unodc.org/wdr2017/index.html\n5. J. Aldridge, D. D\u00e9cary-H\u00e9tu, Hidden wholesale: the drug diffusing capacity of online drug\ncryptomarkets. Int. J. Drug Policy 35(C), 7\u201315 (2016)\n6. Financial Action Task Force, Guidance for a Risk-Based Approach to Prepaid Cards, Mobile\nPayments and Internet-Based Payment Services (FATF/GAFI, Paris, 2013), http://www.fatf-\nga\ufb01.org/publications/fatfrecommendations/documents/rba-npps-2013.html\n7. B. Monk, J. Mitchell, R. Frank, G. Davies, Uncovering Tor: an examination of the network\nstructure. Secur. Meas. Cyber Netw. 2018 , 4231326 (2018)\n8. B. Westlake, M. Bouchard, R. Frank, Assessing the validity of automated webcrawlers as data\ncollection tools to investigate online child sexual exploitation. Sex. Abus. 29, 685 (2015)\n9. A.T. Zulkarnine, R. Frank, B. Monk, J. Mitchell, G. Davies, Surfacing collaborated networks\nin dark web to \ufb01nd illicit and criminal content, in Intelligence and Security Informatics (ISI)\nConference , Arizona (2016)\n10. F. Mena, D. Hobbs, Narcophobia: drugs prohibition and the generation of human rights abuses.\nTrends Organised Crime 13(1), 60\u201374 (2010). https://doi.org/10.1007/s12117-009-9087-8\n11. D.R. Bewley-Taylor, The American crusade: the internationalization of drug prohibition.\nAddict. Res. Theory 11(2), 71\u201381 (2003). https://doi.org/10.1080/1606635021000021377\n12. E. Crick, Drugs as an existential threat: an analysis of the international securitization of drugs.\nInt. J. Drug Policy 23(5), 407\u2013414 (2012). https://doi.org/10.1016/j.drugpo.2012.03.004\n13. J. Buchanan, Ending drug prohibition with a hangover? Br. J. Community Justice 13(1), 55\u201374\n(2015)\n14. D. Perrone, R.D. Helgesen, R.G. Fischer, United States drug prohibition and legal highs: how\ndrug testing may lead cannabis users to spice. Drugs: Educ., Prev. Policy 20(3), 216\u2013224\n(2013). https://doi.org/10.3109/09687637.2012.749392\n15. K. Meyers, \u00d6. Kaynak, E. Bresani, B. Curtis, A. McNamara, K. Brown\ufb01eld, K.C. Kirby,\nThe availability and depiction of synthetic cathinones (bath salts) on the Internet: do onlinesuppliers employ features to maximize purchases? Int. J. Drug Policy 26(7), 670\u2013674 (2015).\nhttps://doi.org/10.1016/j.drugpo.2015.01.012.GLOBAL CRIME 25\n110 R. Frank and A. Mikhaylov\n16. B. Curtis, K. Alanis-Hirsch, \u00d6. Kaynak, J. Cacciola, K. Meyers, A.T. McLellan, Using Web\nsearches to track interest in synthetic cannabinoids (aka \u2018herbal incense\u2019). Drug Alcohol Rev.34(1), 105\u2013108 (2015). https://doi.org/10.1111/dar.12189\n17. P. Grif\ufb01ths, R. Sedefov, A. Gallegos, D. Lopez, How globalization and market innovation\nchallenge how we think about and respond to drug use: \u2018Spice\u2019 a case study. Addiction 105,\n951\u2013953 (2010). https://doi.org/10.1111/j.1360-0443.2009.02874.x\n18. J. Gershman, A. Fass, Synthetic cathinones (\u2018bath salts\u2019): legal and health care challenges. P T\n37(10), 571\u2013595 (2012)\n19. L. Karila, B. Megarbane, O. Cottencin, M. Lejoyeux, Synthetic cathinones: a new public health\nproblem. Curr. Neuropharmacol 13(1), 12\u201320 (2015)\n20. A. Lavorgna, Internet-mediated drug traf\ufb01cking: towards a better understanding of new\ncriminal dynamics. Trends Organised Crime 17(4), 250\u2013270 (2014). https://doi.org/10.1007/\ns12117-014-9226-8\n21. M.J. Barratt, J.A. Ferris, A.R. Winstock, Use of Silk Road, the online drug marketplace, in the\nUnited Kingdom, Australia and the United States. Addiction 109(5), 774\u2013783 (2014). https://\ndoi.org/10.1111/add.12470\n22. J. Bros\u00e9us, D. Rhumorbarbe, C. Mireault, V . Ouellette, F. Crispino, D. D\u00e9cary-H\u00e9tu, Studying\nillicit drug traf\ufb01cking on Darknet markets: structure and organisation from a Canadian per-spective. Forensic Sci. Int. 264, 7\u201314 (2016). https://doi.org/10.1016/j.forsciint.2016.02.045\n23. D.S. Dolliver, Evaluating drug traf\ufb01cking on the Tor Network: Silk Road 2, the sequel. Int. J.\nDrug Policy 26(11), 1113\u20131123 (2015). https://doi.org/10.1016/j. drugpo.2015.01.008\n24. A. Phelps, A. Watt, I shop online \u2013 recreationally! Internet anonymity and Silk Road\nenabling drug use in Australia. Digit. Investig. 11(4), 261\u2013272 (2014). https://doi.org/10.1016/\nj.diin.2014.08.001\n25. M.V . Hout, T. Bingham, \u2018Sur\ufb01ng the Silk Road\u2019: a study of users\u2019 experiences. Int. J. Drug\nPolicy 24(6), 524\u2013529 (2013). https://doi.org/10.1016/j.drugpo.2013.08.011\n26. M.C. Van Hout, T. Bingham, Responsible vendors, intelligent consumers: Silk Road, the online\nrevolution in drug trading. Int. J. Drug Policy 25(2), 183\u2013189 (2014). https://doi.org/10.1016/\nj.drugpo.2013.10.009\n27. J. Van Buskirk, A. Roxburgh, M. Farrell, L. Burns, The closure of the Silk Road: what has\nthis meant for online drug trading? Addiction 109, 517\u2013518 (2014). https://doi.org/10.1111/\nadd.12422\n28. A.L. Osipenko, P.V . Minenko, Investigative counteraction to illegal drug traf\ufb01cking by\ntelecommunication devices (in Russian). Bull. V oronezh Institute of MVD 1, 151\u2013155 (2014)\n29. A.V . Puptseva, Problematic issues of detecting crimes in the domain of illegal drug traf\ufb01cking\nwith the use of wireless communication devices (in Russian), in VIII International Scienti\ufb01c\nand Practice Conference , Tyumen, 15 Feb 2016\n30. A.V . Ryasov, The issues of illegal sale of drugs using information and telecommunication\nnetworks (in Russian). Vestnik SevKavGTI 16, 197\u2013199 (2014)\n31. A.N. Kolycheva, Certain aspects of preserving evidentiary information stored on Internet\nresources (in Russian). Bull. Udmurt University. Economics Law 2(27), 109\u2013113 (2017)\n32. L.M. Kryzhanovskaya, Interaction investigators and of\ufb01cers inquest in the production of\nselected investigative actions on cases of illegal traf\ufb01cking in narcotic drugs (in Russian).Theory Pract. Soc. Dev. 1, 1\u20134 (2008)\n33. F.P. Vasilyev, Modern features of interpretation of law enforcement interaction in Russia and\nthe need for improvement (in Russian). Innov. Sci 3(2), 102\u2013110 (2017)\n34. Financial Action Task Force, Financial Flows Linked to the Production and Traf\ufb01ck-\ning of Afghan Opiates (FATF/GAFI, Paris, 2014), http://www.fatf-ga\ufb01.org/documents/news/\n\ufb01nancial-\ufb02ows-afghan-opiates.html\n35. I.A. Sementsova, A. I. Fomenko, Internet environment as a method of traf\ufb01cking in illegal\ndrugs, psychoactive substances or their analogs (in Russian), in VIII International Scienti\ufb01c\nand Practice Conference , Tyumen, 10 Feb 2016\n36. D.A. Donika, Noncontact method of drug distribution (in Russian). Int. J. Exp. Educ. 6\n, 17\u201318\n(2014), http://cyberleninka.ru/article/n/sbyt-narkoticheskih-sredstv-beskontaktnym-sposobom\nBeyond the \u2018Silk Road\u2019: Assessing Illicit Drug Marketplaces on the Public Web 111\n37. M. Barratt, J. Aldridge, Everything you always wanted to know about drug cryptomarkets (but\nwere afraid to ask). Int. J. Drug Policy 35, 1\u20136 (2016)\n38. J. Van Buskirk, S. Naicker, A. Roxburgh, R. Bruno, L. Burns, Who sells what? Country speci\ufb01c\ndifferences in substance availability on the Agora cryptomarket. Int. J. Drug Policy 35, 16\u201323\n(2016)\n39. J. Aldridge, D. Decary-Hetu, Sifting through the net: monitoring of online offenders by\nresearchers. Eur. Rev. Organised Crime 2(2), 122\u2013141 (2015)\n40. H. Chen, Dark Web , Integrated Series in Information Systems, vol 30 (Springer, New York,\n2012)\n41. N. Christin, Traveling the Silk Road: a measurement analysis of a large anonymous online\nmarketplace (2012). https://doi.org/10.21236/ada579383\n42. M. Macdonald, R. Frank, J. Mei, B. Monk, Identifying digital threats in a hacker web forum,\nin2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and\nMining (ASONAM) (2015), pp. 926\u2013933\n43. M. Wong, R. Frank, R. Allsup, The supremacy of online white supremacists \u2013 an analysis of\nonline discussions by white supremacists. Inf. Commun. Technol. Law 24, 41\u201373 (2015)\n44. K. Joffres, Disruption Strategies for Online Child Pornography Networks (Library and\nArchives Canada, Ottawa, 2012)\n45. A.I. Anapolskaya, Characterizing typical methods and traces of crimes related to illegal drug\ntrade (in Russian). Eur. Union Sci.: Jurisprud. 8(17), 136\u2013138 (2015), http://cyberleninka.ru/\narticle/n/harakteristika-tipichnyh-sposobov-i-sledov-soversheniya-prestupleniy-svyazannyh-s-nezakonnym-oborotom-narkotikov\n46. M.V . Kondratiev, V .K. Znikin, Operational investigative characteristics of crimes related\nto the illegal sale of drugs (in Russian). Bull. Kemerovo State University 1(61), 248\u2013255\n(2015), http://cyberleninka.ru/article/n/operativno-rozysknaya-harakteristika-prestupleniy-\nsvyazannyh-s-nezakonnym-sbytom-narkoticheskih-sredstv\n47. O.N. Korchagin, D.K. Chirkov, A.C. Litvinenko, Synthetic drugs in Russia as a\nthreat to national security (in Russian). Actual Probl. Econ. Law 1(33), 245\u2013253\n(2015), http://cyberleninka.ru/article/n/sinteticheskie-narkotiki-v-rossii-kak-realnaya-ugroza-\nnatsionalnoy-bezopasnosti\n48. A.V . Shebalin, Speci\ufb01cs of conducting a preliminary inquiry into illegal sales\nof drugs via noncontact methods (in Russian). Curr. Issues Fighting Crim.Other Offenses. 1,https://xn%2D%2D90ao9d.xn%2D%2Db1aew.xn%2D%2Dp1ai/\nscience/Izdanija_BJUI_MVD_Rossii/Materiali_nauchno_prakticheskih_konferen/AKTUALNIE_PROBLEMI_BORBI_S_PRESTUPLENIJA\nInferring Systemic Nets with\nApplications to Islamist Forums\nDavid B. Skillicorn and N. Alsadhan\nAbstract Open-source intelligence often requires extracting content from doc-\numents, for example intent and timing. However, more interesting and subtle\nproperties can be extracted by directing attention to the thought patterns and framing\nthat is implicitly present in the writings of groups and individuals. Bag-of-words\nrepresentation of documents are useful for information retrieval, but they are weak\nfrom the perspective of intelligence analysis. We suggest that systemic functional\nlinguistics, with its focus on the purpose an author intends for a document, and its\nabstraction in terms of choices, is a better foundation for intelligence analysis. It\nhas been limited in practice because of the dif\ufb01culty of constructing the systemic\nnets that are its representation of these choices. We show that systemic nets can\nbe constructed inductively from corpora using non-negative matrix factorisation,\nand then apply this to infer systemic nets for language use in islamist magazines\npublished by three different groups: Al Qaeda, Daish (ISIS), and the Taliban. We\nshow that the structures captured are also present in posts in two large online forums:\nTurn to Islam and Islamic Awakening, suggesting a widely held mindset in the\nIslamic world.\n1 Motivation\nApplying intelligence collection and analysis strategies to open source data is an\nobvious strategy because of the availability of vast numbers of documents online:\nweb pages, but also social network status updates, tweets, forum posts, blogs, and\npodcasts. Leveraging this data requires solving two problems: (1) \ufb01nding documents\nrelevant to a subject of interest, and (2) extracting the intelligence content implicit\nin those documents.\nD. B. Skillicorn ( /envelopeback) \u00b7 N. Alsadhan\nSchool of Computing, Queen\u2019s University, Kingston, ON, Canada\ne-mail: skill@cs.queensu.ca\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_5113\n114 D. B. Skillicorn and N. Alsadhan\nThe \ufb01rst problem, information retrieval, has been solved using the bag-of-words\napproach to representing the content of each document, followed by large-scale\nindex search and careful ranking of the document set. Web search businesses dependon this as a crucial technology on which they build monetized services such as\nfocused advertisements.\nThe bag-of-words representation of text has proven extremely successful, even\nfor languages such as English where word order is crucial to meaning. However, it is\nless useful for extracting intelligence content: sentences such as \u201cthe criminal shot\nthe of\ufb01cer\u201d and \u201cthe of\ufb01cer shot the criminal\u201d are equally plausible responses toqueries about criminals and of\ufb01cers, but much less equivalent from the perspective\nof law enforcement and the media. Solving the second problem, intelligence\nextraction, depends on understanding what a document is \u2018about\u2019 in a semanticsense, as well as aspects of each document\u2019s meta-properties: who wrote it, what\ntheir intent was in doing so, how it might be understood by an audience, whether\nit was intentionally deceptive, what attitudes and emotional tone it conveys, anda long list of other possibilities. In other words, many useful properties require\nunderstanding what might be called the social, or even sociological, properties of\ndocuments.\nDetermining such properties is key to domains such as e-discovery (\ufb01nding\nsigni\ufb01cant emails in a corporate archive), intelligence (\ufb01nding meaningful threats\nin a set of forum posts), measuring the effectiveness of a marketing campaign (inonline social media posts), or predicting an uprising (using Twitter feed data).\nAlthough bag-of-words approaches have been moderately successful for such\nproblems, they tend to hit a performance wall (80% prediction accuracy is typical)because the representation fails to capture suf\ufb01cient subtleties [ 30]. There have\nbeen attempts to increase the quality of representations, for example by extracting\nparse trees (that is, context-free grammar representations) but this focuses entirelyon (somewhat arti\ufb01cial) language structure, and not at all on mental processes\n[14]. Other approaches leverage syntactically expressed semantic information, for\nexample by counting word bigrams, by using Wordnet [ 26], or using deep learning\n[29]. Recent developments in deep learning, particularly LSTMs and biLSTMs have\nincreased prediction accuracy; but these predictors are black boxes, so they bring\nlittle understanding of why and how a property is present in a document.\nOne approach that shows considerable promise is systemic functional linguistics\n[9,12,19], a model of language generation with sociological origins and an explicit\nfocus on the effect of the creator\u2019s mental state and social setting on a createddocument. In this model, the process of generating an utterance (a sentence, a\nparagraph, or an entire document) is conceived of as traversing a systemic net ,a\nset of structured choices. The totality of these choices de\ufb01nes the created document.At some nodes, the choice is disjunctive: continue by choosing thisoption or by\nchoosing that one. At others, the choice is conjunctive: choose a subset of these\noptions and continue in parallel down several paths.\nFigure 1shows a simple example of a systemic net. The decision to communicate\nrequires a parallel (independent) choice of the level of formality to be used and\nthe communication channel to be used. The level of formality could be formal or\nInferring Systemic Nets with Applications to Islamist Forums 115\nFig. 1 A simple example of a systemic net\ninformal; and the channel could be via physical letter or email. These choices at\nthe second level are disjunctive\u2014it has to be one or the other. Further choices exist\nbelow these ones, so the systemic net notionally continues to the right until it results\nin concrete language.\nProduction using a context-free grammar also requires a structured set of choices,\nbut the choices are top-down (so that the \ufb01rst choice is to instantiate, for example, a\ndeclarative sentence as a subject, an object, and a verb). In contrast, the order of the\nchoices in a systemic net has no necessary relationship to the concreteness of the\nimplications of those choices. For example, the choice to use formal or informal\nstyle is an early choice with broad consequences that limit the possibilities for\nsubsequent choices. The choice to write a letter or an email is also an early choice\nbut its immediate consequence is narrow and low level: typically whether the \ufb01rst\nword of the resulting document will be \u201cDear\u201d (for a letter) or not (for an email).\nAnother example of a well-used systemic net, called the Appraisal Net [ 1], is\nshown in Fig. 2. It describes the way in which choices of adjectives are made when\nevaluating some object. The choice process is not arbitrary; rather an individual\nchooses simultaneously from up to three parallel paths: appreciation, affect, and\njudgement. Within two of these choices, there are then subsequent parallel choices\nthat lead to particular adjectives\u2014one example adjective is shown at each leaf.\nThese choices are associated with different aspects of the situation: composition-\ncomplexity captures aspects of the object being appraised, while reaction-quality\ncaptures aspects of the person doing the appraising.\nThe power of systemic nets comes because these choices are made, not simply\nwith the goal of constructing a syntactically valid sentence, but because of the\nlimitations and exigencies of social purpose (certain things cannot be said in\ncertain circumstances although syntactically valid); mental state (because language\ngeneration is a largely subconscious process), and the properties of the language in\nuse. In other words, the choice of adjective in an appraisal certainly says something\n116 D. B. Skillicorn and N. Alsadhan\nFig. 2 The Appraisal systemic net, appropriate for representing judgements or reviews\nabout the object being assessed, but also reveals something about the person doing\nthe assessing; and the structure of the choices would be different in English from,\nsay, French or Japanese.\nA systemic net is explanatory at three different levels. First, the existence of a\nnet organizes constructions into categories and so explains some aspects of how the\npieces in a text \ufb01t together.\nSecond, the choices made by individuals traversing a net are not typically unique;\nrather, they cluster into common choice patterns that re\ufb02ect particular kinds of\ntextual targets. This is because there are social rules that govern acceptable end-\nproducts. Each individual can write with an individual style, but we can also say\nthat some set of documents by different authors are written in a down-to-earth style,\nand another set in a \ufb02owery style. This idea of a consistent set of choices in a net,\nleading to detectable consistencies in the resulting documents is called a register .\nThus the set of registers associated with a net are also explanatory.\nThird, for any particular document we can list the choices made in its construc-\ntion, and this becomes a record that describes that document at a higher level of\nabstraction than as a bag of words. This level of explanation is most directly useful\nfor analytics\u2014such choices can be used as attributes for clustering or for prediction.\nThe advantages of a systemic functional approach to textual analytics are:\nInferring Systemic Nets with Applications to Islamist Forums 117\n\u2013 The choices within the net are a smaller, more abstract, and more structured set\nthan the choice of individual words, and therefore provide a stronger foundation\nfor knowledge discovery\u2014a kind of structured attribute selection; and\n\u2013 These choices re\ufb02ect, and make accessible, the mental state of the author or\nspeaker and his/her perception of the social situation for which the text was\nconstructed. This enables a kind of reverse engineering of how the text cameto be, that is analytics about authors and settings.\nThe reason why systemic net approaches have not been more widely used in text\nanalytics is because they have, so far, been constructed by computational linguists,\noften requiring several person-years to build, even when of modest size. Some\nsubstantial systemic nets have been built, but usually within the context of projectswhere they have been kept con\ufb01dential; those that are public, like the Appraisal Net\nabove, are usually small.\nThe contributions of this chapter are:\n\u2013 We show that it is possible to infer systemic nets from corpora using Non-\nNegative Matrix Factorization (NNMF), and that these nets are plausible. Thus\nwe are able to construct systemic nets for any corpus, and for any set of relevantwords. This creates a new path to representing corpora at a deeper level, but\nwithout the need (and cost) for substantial human input.\n\u2013 We show that the resulting systemic nets organize corpora more strongly than the\ncorresponding bags of words, and that this organization improves both clustering\nand prediction tasks, using authorship prediction as a demonstration task.\n\u2013 We apply systemic functional nets to a real-world intelligence problem, learning\nsystemic nets from a set of Islamist magazines, and applying the resulting\nstructure to two large Islamist forums. We show that the top-level distinctions\nderived from the magazines can also be clearly seen in the forum posts,suggesting a widespread mindset shared by the audience for these ideas.\n2 Related Work\nThere have been several applications of prede\ufb01ned systemic nets to textual predic-tion problems. For example, Whitelaw et al. [ 32] show improvement in sentiment\nanalysis using the Appraisal Net mentioned above. Argamon et al. show how to\npredict personality type from authored text, again using systemic functional ideas\n[31]. Herke-Couchman and Patrick derive interpersonal distance from systemic\nnetwork attributes [ 13].\nThe most successful application of systemic functional techniques is the Scam-\nseek project. The goal of this project was to predict, with high reliability, webpages that represented \ufb01nancial scams and those that represented legitimate \ufb01nancial\nproducts. This is a challenging problem\u2014the differences between the two classes\nare small and subtle, and even humans perform poorly at the margins. The fractionof documents representing scams was less than 2% of the whole. This project\u2019s\n118 D. B. Skillicorn and N. Alsadhan\npredictive model was successfully deployed on behalf of the Australian Securities\nand Investments Commission [ 21]. However, the effort to construct the registers\ncorresponding to normal and (many varieties of) scam documents was substantial.\nKappagoda [ 15] shows that word-function tags can be added to words using\nconditional random \ufb01elds, in the same kind of general way that parsers add part-\nof-speech tags to words. These word-function tags provide hints of the systemic-functional role that words carry. This is limited because there is no hierarchy.\nNevertheless, he is able to show that the process of labelling can be partially\nautomated and that the resulting tags aid in understanding documents.\nEspecially since the World Trade Center attacks of 2001, there has been a\ngreat deal of academic work on open-source intelligence [ 4,17,24]. This includes\nleveraging text [ 16,25,33] and graph data, including social networks [ 5,6,10,22].\nA large number of commercial platforms have also been developed and are in\nwidespread use, for example i2 Analysts\u2019 Notebook and Palantir.\n3 Inductive Discovery of Systemic Nets\nThe set of choices in a systemic net lead eventually, at the leaves, to choices of\nparticular (sets of) words. One way to conceptualize a systemic net, therefore, isas a hierarchical clustering of words, with each choice representing selection of a\nsubset.\n1We use this intuition as a way to inductively construct a systemic net: words\nthat are used together in the same document (or smaller unit such as a sentenceor paragraph) are there because of a particular sequence of choices. An inductive,\nhierarchical clustering can approximate a hierarchical set of choices.\nOur overall strategy, then, is to build document-word matrices (where the\ndocument may be as small as a single sentence), and then cluster the columns (that\nis, the words) of such matrices using the similarity of the documents in which they\nappear. The question then is: which clustering algorithm(s) to use.\nIn this domain, similarity between a pair of documents depends much more\nstrongly on the presence of words than on their absence . Conventional clustering\nalgorithms, for example agglomerative hierarchical clustering and other algorithmsthat use distance as a surrogate for similarity, are therefore not appropriate, since\nmutual absence of a word in two different documents is uninformative, but still\nincreases their apparent similarity.\nSingular value decomposition is reasonably effective (J.L. Creasor, unpublished\nwork) but there are major issues raised by the need to normalize the document-\nword matrix so that the cloud of points it represents is centered around the\n1Complete systemic nets also include a downstream phase that de\ufb01nes the process for assembling\nthe parts of a constructed document into its actual linear sequence. We ignore this aspect. Indeclarative writing, assembly is usually straightforward, although this is not the case in, forexample, poetry.\nInferring Systemic Nets with Applications to Islamist Forums 119\norigin. Typical normalizations, such as z-scoring, con\ufb02ate median frequencies with\nzero frequencies and so introduce artifacts that are dif\ufb01cult to compensate for in\nsubsequent analysis.\nWe therefore choose to use Non-Negative Matrix Factorization, since a\ndocument-word matrix naturally has non-negative entries. An NNMF decomposes\na document-word matrix, A, as the product of two other matrices:\nA=WH\nIfAisn\u00d7m, thenWisn\u00d7rfor some chosen rusually much smaller than either\nmorn, andHisr\u00d7m. All of the entries of WandHare non-negative, and there is\na natural interpretation of the rows of Has \u2018parts\u2019 that are \u2018mixed\u2019 together by each\nrow of Wto give the observed rows of A[18].\nAlgorithms for computing an NNMF are iterative in nature, and the results may\nvary from execution to execution because of the random initialization of the valuesofWandH. In general, the results reported here are obtained by computing the\nNNMF 10 times and taking the majority con\ufb01guration. We use a conjugate gradient\nversion of NNMF, using Matlab code written by Pauca and Plemmons.\nThere are two alternative ways to use an NNMF, either directly from the given\ndata matrix, or starting from its transpose. If we compute the NNMF of the transpose\nof A, we obtain:\nA\n/prime=\u00afW\u00afH\nand, in general, it is not the case that \u00afH=W/primeand\u00afW=H/prime. Experiments showed\nthat results were consistently better if we applied the NNMF to A/prime, that is to the\nword-document matrix. The textual unit we use is the paragraph. A single sentencemight, in some contexts, be too small; a whole document is too large since it re\ufb02ects\nthousands of choices.\nWe extracted paragraph-word matrices in two ways. A parts-of-speech-aware\ntagger made it possible to extract the frequencies of, for example, all pronouns or\nall determiners [ 7]. For larger word classes, such as adjectives, it was also possible\nto provide the tagger with a given list and have it extract only frequencies of theprovided words. Frequency entries in each matrix were normalized by the total\nnumber of words occurring in each paragraph, turning word counts into word rates.\nThis compensates for the different lengths of different paragraphs.\nSuperior results were obtained by choosing only r=2 components. In the\n\ufb01rst step, the \u00afWmatrix has dimensionality number of words \u00d72, with non-\nnegative entries. Each word was allocated to the cluster with the largest entry inthe corresponding row of \u00afW, and the process repeated with the two submatrices\nobtained by splitting the rows of A\n/primebased on this cluster allocation. This process\ncontinued until the resulting clusters could not be cleanly separated further. Theseclusters therefore form a binary tree where each internal node contains the union of\nthe words of its two children.\n120 D. B. Skillicorn and N. Alsadhan\nEach NNMF was repeated 10 times to account for the heuristic property\nof the algorithm. We were able to leverage this to estimate the con\ufb01dence of\neach clustering. For example, there were occasionally particular words whosemembership oscillated between two otherwise stable clusters, and this provided a\nsignal that they didn\u2019t \ufb01t well with either. We were also able to use this to detect\nwhen to stop the recursive clustering: either clusters shrank until they containedonly a single word (usually a high-frequency one), or their subclusters began to\nshow no consistency between runs, which we interpreted to mean that the cluster\nwas being over-decomposed.\nThe result of applying this recursive NNMF algorithm to a word-paragraph\nmatrix is a hierarchical binary tree whose internal nodes are interpreted as choice\npoints, and whose leaves represent the \u2018outputs\u2019 that result from making the choicesthat result in reaching that leaf. A leaf consists of a set of words that are considered\nto be, in a sense, equivalent or interchangeable from the point of view of the total\nset of words being considered. However, this view of leaves contains a subtle point.Suppose that a leaf contains the words \u2018red\u2019 and \u2018green\u2019. These are clearly not\nequivalent in an obvious sense, and in any given paragraph it is likely that an author\nwill select only one of them. In what sense, then, are they equivalent? The answeris that, from the author\u2019s point of view, the choice between them is a trivial one:\neither could serve in the context of the document (fragment) being created. Thus\na leaf in the systemic net contains a set of words from which sometimes a singleword is chosen and sometimes a number of words are chosen\u2014but in both cases the\nchoice is unconstrained by the setting (or at least undetectably unconstrained in the\navailable example data).\nWe have remarked that choices at internal nodes in a systemic net can be\ndisjunctive or conjunctive. However, in our construction method each word in a\nparticular document is allocated to exactly one cluster or the other. We estimatethe extent to which a choice point is conjunctive or disjunctive by counting how\noften the choice goes either way across the entire set of documents, that is we\ntreat conjunction/disjunction as a global, rather than a local, property. (It wouldbe possible to allocate a word to both clusters if the entries in the corresponding\nrow of \u00afWhad similar magnitude, and therefore detect conjunctive choices directly.\nHowever, deciding what constitutes a similar magnitude is problematic because ofthe variation between runs deriving from the heuristic nature of the algorithm.)\n4 Inferred Systemic Nets\nThe data used for proof of concept of this approach is a set of 17 novels downloaded\nfrom gutenberg.org and lightly edited to remove site-speci\ufb01c content. These novels\ncovered a period of about a century from the 1830s to the 1920s and represent well-written, substantial documents. For processing they were divided into paragraphs;\nbecause of the prevalence of dialogue in novels, many of these paragraphs are\nactually single sentences of reported speech. The total number of paragraphs is\nInferring Systemic Nets with Applications to Islamist Forums 121\nTable 1 List of words used\nto create the systemicnetworksGroup type Words\nPersonal pronouns I, me, my, mine, myself, we, us,our, ours, ourselves, you, your,yours, yourself, yourselves, they,their, theirs, them, themselves, he,him, his, himself, she, her, hers,herself, it, its, itself, one, one\u2019s\nAdverbs Afterwards, already, always,immediately, last, now, soon, then,yesterday, above, below, here,outside, there, under, again, almost,ever, frequently, generally, hardly,nearly, never, occasionally, often,rarely\nAuxiliary verbs Was, wasn\u2019t, had, were, hadn\u2019t, did,didn\u2019t, been, weren\u2019t, are, is, does,\nam, has, don\u2019t, haven\u2019t, doesn\u2019t,\naren\u2019t, do, isn\u2019t, have, be, hasn\u2019t\nPositive auxiliary verbs Was, had, were, did, been, is, does,are, am, has, do, have, be\nAdjectives Good, old, little, own, great, young,long, such, dear, poor, new, whole,sure, black, small, full, certain,white, right, possible, large, fresh,sorry, easy, quite, blue, sweet, late,pale, pretty\nVerbs Said, know, see, think, say, go,came, make, come, went, seemed,made, take, looked, thought, saw,tell, took, let, going, get, felt, seen,give, knew, look, done, turned, like,asked\n48,511. The longest novel contained 13,617 paragraphs ( Les Miserables ) and the\nshortest 736 ( The 39 Steps ).\nWe selected six different categories of words for experiments as shown in Table 1.\nFigure 3shows the systemic net of pronouns. In all of these \ufb01gures, the thickness\nof each line indicates how often the corresponding path was taken as the result of achoice. Lines in blue represent the \u2018upper\u2019 choice, red the \u2018lower\u2019 choice, and black\nthe situation where both choices occurred with approximately equal frequency.\nThe top-level choice (1) in this net is between pronouns where the point of\nview is internal to the story, and where the point of view is of an external narrator.\nThis seems plausible, especially in the context of novels. Choice point 2 is largely\nbetween \ufb01rst-person and second-person pronouns, with apparently anomalousplacement of \u2018me\u2019 and \u2018we\u2019. Choice point 4 is between masculine pronouns and\nothers, again entirely plausible given the preponderance of masculine protagonists\nin novels of this period. The remaining choices in this branch separate feminine,impersonal, and third-person plural pronouns. All of these choices are strongly\n122 D. B. Skillicorn and N. Alsadhan\nFig. 3 Systemic net inferred for pronouns\ndisjunctive, weakening down the tree with choice point 7 the least disjunctive. It\nmight be expected that, after the choice at point 1, choices might become moreconjunctive as two or more people are mentioned. However, reported speech by one\nperson is the most common paragraph structure in these novels, and many of these\ndo not contain another pronoun reference (\u201cHe said \u2018What\u2019s for dinner?\u201d).\nFigure 4shows the systemic net for auxiliary verbs. These might have separated\nbased on their root verb (to be, to have, to do)\n2but in fact they separate based on\ntense. Choice point 1 is between past tense forms and present tense forms. Choicesbetween verb forms are visible at the subsequent levels. Of course, auxiliary verbs\nare dif\ufb01cult to categorize because they occur both as auxiliaries, and as stand-alone\nverbs.\nThe set of auxiliary verbs is also dif\ufb01cult because many of them encapsulate\na negative (\u2018hadn\u2019t\u2019), and negatives represent an orthogonal category of choices.\nFigure 5shows that systemic net when only the positive auxiliary verbs are\nconsidered. Again, tense is the dominant choice.\nFigure 6shows the systemic net for adverbs from a limited set of three different\nkinds: time, place, and frequency. This systemic net seems unclear, but note that atleast some branches agree with intuition, for example the lower branch from choice\nfour.\nThere are a very large number of adjectives used in the corpus, most of them only\nrarely. However, it is interesting to consider how adjectives might be empirically\n2And a computational linguist might have chosen this separation as the most \u2018natural\u2019.\nInferring Systemic Nets with Applications to Islamist Forums 123\nFig. 4 Systemic net inferred for auxiliary verbs\nFig. 5 Systemic net inferred\nfor positive auxiliary verbs\ndistinguished in \ufb01ction. (Note that this would not be the same net as the Appraisal\nNet described earlier, which might be inferrable from, say, a corpus of productreviews.) Figure 7shows the systemic net for a limited set of adjectives of three\nkinds: appearance, color, and time. This net shows the typical structure for an\nextremely common word, in this case \u2018good\u2019 which appears as one outcome ofthe \ufb01rst choice. The sets of adjectives at each leaf are not those that would\nbe conventionally grouped, but there are a number of interesting associations:\n\u2018great\u2019 and \u2018large\u2019 occur together, but co-occur with \u2018black\u2019 which is a plausiblepsychological association.\n124 D. B. Skillicorn and N. Alsadhan\nFig. 6 Systemic net inferred for adverbs\nFig. 7 Systemic net inferred for adjectives\nThese systemic nets look, from a human perspective, somewhere between\nplausible and peculiar. We now turn to more rigorous validation. Our goal is notso much that these nets should be explanatory from an intuitive perspective, but that\nthey should be useful for analytic tasks (Fig. 8).\nInferring Systemic Nets with Applications to Islamist Forums 125\nFig. 8 Systemic net inferred for verbs\n5 Validation\nTo validate our technique for inferring systemic nets, we use the following\nmethods:\n\u2013 Face validation. The systemic nets should involve choices that appear sensible\nand realistic. Note that this does not mean that they should match the hierarchycreated to explain English grammar\u2014such a grammar is an arti\ufb01cial construct\nintended to suggest consistent rules, and owing much to the grammar of Latin,\nrather than an accurate description of how English actually works.\n\u2013 Comparison of document clustering based on word choices and based on\nsystemic net choices. If choices re\ufb02ect deeper structure, then documents should\ncluster more strongly based on choice structure than on word structure.\n\u2013 Comparison of the performance of an example prediction task, authorship\nprediction, using word choices and systemic net choices. If choices re\ufb02ect deeper\nstructure, it should be easier to make predictions about documents based onchoice structure than on word structure.\n\u2013 Comparison with randomly created choice nets. Hierarchical clusterings with the\nsame macroscopic structure as induced systemic nets should perform worse thanthe induced systemic nets.\n126 D. B. Skillicorn and N. Alsadhan\n5.1 Face Validation\nThe systemic nets shown in the previous section are not necessarily what a linguist\nmight have expected, but it is clear that they capture regularities in the way words\nare used (especially in the domain of novels that was used, with their emphasis on\nindividuals and their high rates of reported speech).\n5.2 Clustering Using Word Choices Versus Net Choices\nThe difference between the systemic net approach and the bag-of-words approachis that they assume a different set of choices that led to the words that appear in each\nparagraph. The bag-of-words model implicitly assumes that each word was chosen\nindependently; the systemic net model assumes that each word was chosen basedon hierarchical choices driven by purpose, social setting, mental state, and language\npossibilities. Clustering paragraphs based on these two approaches should lead to\ndifferent clusters, but those derived from systemic net choices should be more clear-cut. In particular, choices are not independent both because of hierarchy and because\nof the extrinsic constraints of the setting (novels, in this case)\u2014so we expect to see\nclusters corresponding to registers.\nWe used two novels for testing purposes: Robinson Crusoe and Wuthering\nHeights , processed in the same way as our training data. Since these novels were\nnot used to infer the systemic nets, results obtained using them show that the netsare capturing some underlying reality of this document class.\nWe compute the singular value decomposition of the paragraph-word matrix and\nthe paragraph-choices matrix, both normalized by paragraph length. Plots showthe resulting clustering of the paragraphs, with one test novel\u2019s paragraphs in red\nand the other in blue. In all of Figs. 9,10,11, and 12the clustering derived from\nword frequencies is a single central cluster. In some of them, there appears to be\nFig. 9 SVD using pronouns, bag-of-words (left), choices (right)\nInferring Systemic Nets with Applications to Islamist Forums 127\nFig. 10 SVD using auxiliary verbs, bag-of-words (left), choices (right)\nFig. 11 SVD using adjectives, bag-of-words (left), choices (right)\nFig. 12 SVD using verbs, bag-of-words (left), choices (right)\na separation between the two test documents, but these are illusions caused by\noverlays of points. In contrast, the clustering using choices shows strong clusters.\nThese correspond to paragraphs that resulted from similar patterns of choices, that\nis to registers.\n128 D. B. Skillicorn and N. Alsadhan\n5.3 Authorship Prediction Using Word Choices Versus Net\nChoices\nWe argued that systemic nets are useful for applications where properties other than\nsimple content are signi\ufb01cant. To justify this claim we predict authorship at the level\nof each individual paragraph for our two test novels. This is a dif\ufb01cult task because\nparagraphs are so short; even humans would \ufb01nd it dif\ufb01cult to predict authorship at\nthis level, especially without access to the semantics of the words used. Our goal isto show that the choice structure of the nets improves performance over simple use\nof bags of words. There are, of course, other ways to predict authorship, for example\nword n-grams or deep learning using LSTMs, but these are not directly comparableto systemic net approaches.\nAgain we use paragraph-word and paragraph-choice matrices as our data, and\n5-fold cross-validated support vector machines with a radial basis kernel as thepredictors. Results are shown for each of the word sets in Tables 2,3,4,5,6and7.\nAcross all of these word classes, authorship prediction based on word use hovers\nclose to chance; in contrast, authorship prediction using systemic net choices rangefrom accuracies of around 65%\u201375%, that is performance lifts of between 15 and\n20 percentage points over prediction from word choices. And of these models is\nusing only small numbers of words as signals of authorship. Clearly, the structuralinformation coded in the systemic nets makes discrimination easier.\n5.4 Inferred Nets Versus Randomly Generated Nets\nTables 8and 9compare the authorship prediction performance of the inferred\nsystemic net and random networks constructed to have the same shape by dividingthe words hierarchically into nested subsets of the same sizes as in the systemic net,\nbut at random.\nTable 2 Confusion matrices for personal pronouns; accuracy using words: 69.7%, accuracy using\nchoices: 75.3%\nPredicted: words and choices\nActual RobCrusoe WutHeights RobCrusoe WutHeights\nRobCrusoe 694 (48%) 33 (2%) 584 (40%) 143 (10%)\nWutHeights 407 (28%) 320 (22%) 216 (15%) 511 (35%)\nTable 3 Confusion matrices for adverbs; accuracy using words: 51.3%, accuracy using choices:\n63.4%\nPredicted: words and choices\nActual RobCrusoe WutHeights RobCrusoe WutHeights\nRobCrusoe 171 (12%) 556 (38%) 387 (27%) 340 (23%)\nWutHeights 152 (10%) 575 (40%) 192 (13%) 535 (37%)\nInferring Systemic Nets with Applications to Islamist Forums 129\nTable 4 Confusion matrices for auxiliary verbs; accuracy using words: 50.6%, accuracy using\nchoices: 72.0%\nPredicted: words and choices\nActual RobCrusoe WutHeights RobCrusoe WutHeights\nRobCrusoe 435 (30%) 292 (20%) 553 (38%) 174 (12%)\nWutHeights 426 (29%) 301 (21%) 233 (16%) 494 (34%)\nTable 5 Confusion matrices for positive auxiliary verbs; accuracy using words: 51.4%, accuracy\nusing choices: 67.6%\nPredicted: words and choices\nActual RobCrusoe WutHeights RobCrusoe WutHeights\nRobCrusoe 453 (30%) 292 (20%) 623 (43%) 104 (7%)\nWutHeights 415 (29%) 312 (21%) 367 (25%) 360 (25%)\nTable 6 Confusion matrices for adjectives; accuracy using words: 50.1%, accuracy using choices:\n70.8%\nPredicted: words and choices\nActual RobCrusoe WutHeights RobCrusoe WutHeights\nRobCrusoe 295 (20%) 432 (30%) 490 (34%) 237 (16%)\nWutHeights 294 (20%) 433 (30%) 187 (13%) 540 (37%)\nTable 7 Confusion matrices for verbs; accuracy using words: 50.1%, accuracy using choices:\n67.5%\nPredicted: words and choices\nActual RobCrusoe WutHeights RobCrusoe WutHeights\nRobCrusoe 297 (20%) 430 (30%) 476 (33%) 251 (17%)\nWutHeights 296 (20%) 431 (30%) 221 (15%) 506 (35%)\nTable 8 Personal pronouns: systemic network versus random nets\nNumber of NNMF systemic network Random nets\nparagraphs Accuracy min mean max\n1 75.3% 69.3% 75.4% 82%\n3 84.1% 68.1% 72.1% 76.2%\n6 88.9% 66.3% 70% 71.5%\nTable 9 Adjectives systemic network versus random nets\nNumber of NNMF systemic network Random nets\nparagraphs Accuracy min mean max\n1 70.8% 70.2% 75.2% 79.4%\n3 72.3% 66.9% 71.5% 73%\n6 74.8% 64.5% 69.4% 72.3%\n130 D. B. Skillicorn and N. Alsadhan\nThe performance of the random network is approximately the same as the\ninferred network at the level of single paragraph prediction. This is clearly a small\nsample size effect: choices that differentiate authors well are also available in therandom network by chance. However, as the number of paragraphs available to make\nthe prediction increases, the predictive performance of the systemic net continues to\nimprove while that of the random network remains \ufb02at.\n5.5 Combining Systemic Nets\nWe have built our systemic nets starting from de\ufb01ned word sets. In principle, a\nsystemic net for all words could be inferred from a corpus. However, such a net\nwould represent, in a sense, the entire language generation mechanism for English,so it is unlikely that it could be reliably built, and would require an enormous corpus.\nHowever, it is plausible that the systemic nets we have built could be composed\ninto larger ones, joining them together with an implied conjunctive choice at the toplevel. We now investigate this possibility.\nOne way to tell if such a composition is meaningful is to attempt the authorship\nprediction task using combined systemic nets. The results are shown in Table 10.\nThe combined nets show a lift of a few percentage points over the best single net.\nThese results hint, at least, that complex systemic nets can be built by inferring\nnets from smaller sets of words, which can be done independently and perhapsrobustly; and then composing these nets together to form larger ones. Some care\nis clearly needed: if the choice created by composing two nets interacts with the\nchoices inside one or both of them, then the conjunctive composition may bemisleading. This property is known as selectional restriction, and is quite well\nunderstood, so that it should be obvious when extra care is needed. For example,\ncomposing a net for nouns and one for adjectives using a conjunctive choice isunlikely to perform well because the choice of a noun limits the choice of adjectives\nthat \u2018match\u2019 it.\nTable 10 Prediction accuracy using combined word sets, best single systemic network, and\ncombinations of systemic networks\nWords Best single Combined\nPronouns +adverbs 69% 75.3% 77.4%\nPronouns +adverbs +verbs 73.1% 75.3% 80.2%\nPronouns +adverbs +verbs+adjectives 80.37% 75.3% 80.44%\nInferring Systemic Nets with Applications to Islamist Forums 131\nTable 11 Sala\ufb01st-Jihadist words\nArabic\nEnglish America God Oppressors Prophet Enemy Jews\n6 Applying Systemic Nets for Intelligence Analysis\nWe now turn to applying the systemic net construction technique to text datasets\nthat have intelligence value, documents created with islamist purposes of varying\nintensity.\nA model of jihadist intensity developed by Koppel et al. [ 8] was designed to\ndistinguish different strands of Islamic thoughts. We use the model (or set of words)\ndescribing a Sala\ufb01st-jihadist orientation. The words were originally in Arabic, andwere translated into English by the second author, a native Arabic speaker. The\nresulting list consists of 144 words. Table 11shows some of words.\nWe show that a structure derived from three English-language islamist propa-\nganda magazines, Inspire ,Dabiq andAzan , generalizes elegantly to two islamist\nforums, showing that there is a widely held mindset (or set of distinctions) shared\nin this worldwide community.\n7 Measuring Islamist Language\nOne way to measure the jihadi intensity of a given document is simply to sum thefrequency with which relevant words occur. This approach has been widely used\nby, for example, Pennebaker to measure a number of properties [ 11] and the LIWC\npackage has made this technology available to many researchers. This approachhas been used to measure deception [ 20], informative language [ 23], imaginative\nlanguage [ 23], and propaganda [ 3,27,28].\nWe examine three different jihadist magazines, all with the same professed goals,\nbut originating from different countries, and from groups with different ideologies.\nInspire is produced by Al Qaeda in the Arabian Peninsula. The \ufb01rst nine issues\nwere edited by the American jihadist, Anwar al-Awlaki. Since his death, others, sofar unidenti\ufb01ed, have taken over. Dabiq is produced by ISIS (Daish) in Syria. Azan\nis produced by the Taliban in Pakistan. All three types of magazines are high in\nproduction values, use many visual images, and aim to imitate the look and feel ofmainstream Western magazines. All of these magazines appear as pdfs; more recent\nissues have become so complex that it is impossible to extract the textual content\nusing OCR but the text of 12 issues of Inspire, 5 issues of Azan, and 5 issues ofDabiq have been extracted. Skillicorn used the magazine data to do an empirical\nassessment of the intensity of propaganda across the three magazines [ 3].\nA document-word matrix for the magazines was constructed by counting the\nfrequencies of words from the jihadi language model, normalized as discussed\n132 D. B. Skillicorn and N. Alsadhan\nFig. 13 Similarity among magazines using SVD (IN: Inspire, AZ: Azan, DA: Dabiq. ( a)Ap l o to f\nthe magazines based on the jihadi language model. ( b) A plot of the magazines based on the jihadi\nlanguage model overlaid with the words, i.e. the UandVmatrices plotted together\nabove. The SVD plots of the document-word matrix based on the jihadi words are\nshown in Fig. 13. Both Azan and Dabiq cluster strongly. Inspire does not cluster as\nwell, suggesting that it does not have a consistent style or content focus. Figure 13b\nshows the magazines overlaid with the words they use\u2014words and magazines can\nbe considered to be pulled towards one another whenever a particular word isheavily used in a particular magazine issue. Some of the words most associated\nwith Dabiq, therefore, are: \u2018Iraq\u2019, \u2018Islamic\u2019, \u2018slave\u2019, and \u2018authority\u2019. This seems\nreasonable since ISIS is active in Syria and Iraq. ISIS also allows the practice ofslavery. Some of the words most associated with Azan are: \u2018Paradise\u2019, \u2018life\u2019, \u2018old\u2019,\nand \u2018system\u2019. These words suggest that Azan\u2019s message is more focused towards\nthe afterlife.\nInferring Systemic Nets with Applications to Islamist Forums 133\n8 A Systemic Net Based on Jihadi Language Model\nWe use the magazines to construct a systemic net derived from jihadi language.\nFigure 14shows the resulting systemic net labelled with the choice points for later\nreference. The tree has six choice points and six leaves, because the words at node\n7 do not split further.\nThe \ufb01rst choice in the tree re\ufb02ects a clear distinction between political and\nreligious words. A sample of the words associated with this choice is given in\nTable 12.\nFig. 14 A visualization of the systemic net\nTable 12 First choice wordsFirst choice\nReligious Political\nProphet Tyrants\nSheikh Enemy\nGod Fighting\nWorlds America\nParadise Brotherhood\nExalted Government\nEarth Palestinian\nMonotheism Oppressors\nGoodness Nation\nPlatform Categories\nIslamic Act\nFaith Movement\nOld Nation\nOwners War\nAllah Doubt\nAllowing Country\nPrayer Ruler\nCompanions Afghanistan\n134 D. B. Skillicorn and N. Alsadhan\nTable 13 Basic meaning behind each leaf node and the Google results obtained from using the\nwords in each node\nLeaf Meaning Google results\n8 Used by Verses of Quran on Jihad\u2013Islam\ninspire the most\n9 Used by Allah\u2019s Quran\u2014authenticity of the Quran\nDabiq the most Muhammad, Terrorist or Prophet?\u2014Bible Probe\nIslam and antisemitism\u2014Wikipedia, the free encyclopedia\nwhat every non-Muslim needs to know about Islam!\u2014Bible.ca\n10 Jihad focused Islamic State and the Others \u00b7Raqqa is Being Slaughtered\nHow Islam will dominate the world \u2014 - Duaat - WordPress.com\nChapter 1: Muhammad and the Quran\n11 Pure religion Prophet Muhammad, pbuh - Some selected verses\nDoes Islam regard non - Muslims with mercy and compassion\nThe Book of Faith - Sahih Muslim - Sunnah.com\n12 Al-qaeda and Islam in Afghanistan - Wikipedia, the free encyclopedia\nAfghanistan Afghan Arabs - Wikipedia, the free encyclopedia\nfocused Al-Qaeda - Infoplease\n13 Teachings about Contemporary Islamist ideology authorizing genocidal murder\nIslam Full text of \u201cIslamic Books by Ibn Taymiyyah Maqdisi\u201d\nDo the authentic teachings of Islam result in terrorism?\nWelcome to IONA masjid and learning center!\u2014IONA Masjid !\nThe word sets resulting from some of the choices make immediate intuitive sense,\nwhile others do not. As a way to understand what each choice is capturing, we takethe word sets from each leaf, and treat them as terms for a Google query. The top\nranked documents associated with each of them are shown in Table 13. Most sets\ncan be assigned a plausible meaning based on these results, the exception beingnode 8.\nWe can now compare how the magazines cluster based on bag of words versus\nbased on choice sets. An SVD plot of the variation between the magazines basedon choices is shown in Fig. 15. Compared to Fig. 13, Azan and Dabiq cluster more\ntightly based on choices than on words. There is no signi\ufb01cant difference between\nthe two approaches in how Inspire issues cluster. The color and shape coding ofthe magazines is based on which choices are made most often at choice points in\nthe systemic net. Inspire tends to prefers the political branch over the religious\nbranch, but does not cluster well. This re\ufb02ects the wide variation in focus thathas been previously noted, and perhaps the changes in editorship and authorship.\nBoth Azan and Dabiq have consistent choice patterns across all issues, suggesting\nclarity of purpose, and a consistent editorial framework. Choices 7 and 9 are stronglyassociated with Dabiq, while Inspire tends to favor the opposite choices (6 and 8).\nThis analysis allows us to associate particular sets of magazines with particular\npatterns of word choice, and therefore to take a \ufb01rst step towards judging group\nInferring Systemic Nets with Applications to Islamist Forums 135\nFig. 15 SVD plot of the document-choice matrix of the magazines (diamonds: prefer political\nchoice; asterisks: prefer religious choice; green and blue distinguish the outcome from choicepoint 2; black and red distinguish the outcome from choice point 3; numbers are the positionscorresponding to the choices, i.e. the columns of the matrix)\nintent. For example, it is possible to infer, in principle, whether a group\u2019s focus\nis internal or external, and if external what kind of target is likely to seem most\nattractive. This goes deeper than simply observing which words are frequent,because it associates words that are related in the sense that they occupy the same\nmental \u2018slot\u2019.\n9 Applying the Systemic Net to Islamist Forums\nWe apply the jihadi language systemic net that was inferred from the magazines totwo new corpora, two islamist forums:\n\u2013 Turn to Islam: which advertises itself as \u201ccorrecting the common misconceptions\nabout Islam\u201d.\n\u2013 Islamic Awakening: which identi\ufb01es itself as \u201cdedicated to the blessed global\nIslamic awakening\u201d.\nTurn to Islam (TTI) consists of 335,388 posts from 41,654 members collected\nbetween June 2006 and May 2013. Islamic Awakening (IA) consists of 201,287\nposts from 3964 members collected between April 2004 and May 2012. Both data\nsets were collected by the University of Arizona Arti\ufb01cial Intelligence Lab [ 2]. The\nposts are primarily in English, but with a mixture of transliterated Arabic, some\nFrench, and a small number of words from other European languages.\n136 D. B. Skillicorn and N. Alsadhan\nFigure 16a shows the variation among a 10% uniformly random sample of posts\nfrom the TTI forum, based on the Jihadi language systemic net choices. The color\nand shape coding is the same as in Fig. 15. We can see a clear separation between\nposts making political versus religious word choices (diamonds vs asterisks). The\nseparation also extends to the choice points in the second layer of the SFL net\n(blue/green and red/black). Figure 16b shows the cloud of points rotated so that the\nthird dimension is visible, showing that the variation between red and black points\nis orthogonal to the variation between blue and green points. The striking point\nis that the choices inferred from word usage in the islamist magazines stronglyand consistently cluster forum posts coming from a completely different context.\nFig. 16 SVD plot of the document-choice matrix of TTI posts (symbol and color coding as in\nFig.15). (a) First two dimensions. ( b) Rotated view to show the third dimension\nInferring Systemic Nets with Applications to Islamist Forums 137\nFig. 17 SVD plot of the document-choice matrix of IA posts with the same symbol and color\ncoding as Fig. 15.(a) First two dimensions. ( b) Rotated view to show the third dimension\nThis suggests that there is a widely shared mindset in this community, interpreted\nbroadly, that produces consistent language use across settings.\nFigure 17is the same analysis for the IA forums. Both TTI and IA cluster\nstrongly and consistently based on the choice structure of the systemic net inferredfrom the magazines.\nThe word sets that result from choice point 5 are particularly interesting; they\ndistinguish between two types of religious thinking, one that might be called purelyreligious and the other which is focused more on the jihad aspect of religion. The\nrelevant words are shown in Table 14.\nFigure 18shows an SVD plot of TTI posts color-coded by Jihadi intensity which\nwe obtain by adding two arti\ufb01cial documents that contain all of the words of the\n138 D. B. Skillicorn and N. Alsadhan\nTable 14 Choice point 5\nwordsFifth choice point\nPure religion Jihad focused\nOld Behalf\nCommand Hide\nExalted Islamic\nFolk Monotheism\nMohammed Authority\nAllah Owners\nPeace Jews\nBelievers Resistance\nGoodness Companions\nFaith Woman\nFamily\nWorlds\nEarth\nFig. 18 SVD plot of TTI document-choice matrix. The posts are color coded based on jihadi\nintensity from blue (least intense) to red (most intense)\nmodel at frequencies one standard deviation above, and one standard deviation\nbelow the mean, and using the line between them as a gradient of jihadi intensity.Blue points are the least jihadi and red are the most. Choice points from the systemic\nnet are also included, and it is clear that the word sets that distinguish jihadi intensity\nmost directly are those at nodes 10 and 11. Therefore, the choice made at choicepoint 5 could be also used, by itself, as a predictor of jihadi intensity.\n10 Discussion\nThe strength of the religious vs political choice at the \ufb01rst choice point of thesystemic net suggests that there is a fundamental differentiator among those who\nengage in islamist discussions or writings. It appears that islamist ideology can be\nInferring Systemic Nets with Applications to Islamist Forums 139\nplausibly separated into two threads, and this generalizes over different contexts\nand widely differing authors. It remains an open question whether the authors\nthemselves are consciously aware of this; and whether an understanding of thedichotomy could be leveraged to increased the effectiveness of propaganda vehicles\nsuch as the magazines (and, for some posters, the forums). There is also a strong\ndistinction in the religious domain between word choices that are, as it were, purelyreligious and those that are religious but with a jihadist subtext.\nWe have also demonstrated the effectiveness of systemic nets, and the choices\nthey capture. The structure inferred from large, well-written islamist magazinesgeneralizes very well to a completely different domain: short, informal posts in\nonline forums.\nMethodologically, we have shown that inferring systemic nets from data pro-\nduces structures that re\ufb02ect underlying language patterns, even though the word\nchoice sets do not necessarily have a direct interpretation. The ability to infer\nsystemic nets automatically, even if they are possibly not as accurate as thoseinferred by humans, opens up the SFL approach to many more application domains,\nof which intelligence analysis is just one.\nReferences\n1. S. Argamon, S. Dhawle, M. Koppel, J.W. Pennebaker, Lexical predictors of personality type,\ninProceedings of the Joint Annual Meeting of the Interface and Classi\ufb01cation Society of North\nAmerica (2005)\n2. Azure, Dark web forums. http://www.azsecure-data.org/dark-web-forums.html . AZSecure-\ndata.org version (Accessed May 4th, 2016)\n3. H. Borko, M. Bernick, Automatic document classi\ufb01cation. J. ACM 10(3), 151\u2013162 (1963)\n4. H. Chen, F.-Y . Wang, Arti\ufb01cial intelligence for homeland security. IEEE Intell. Syst. 20(5),\n12\u201316 (2005)\n5. T. Coffman, S. Greenblatt, S. Marcus, Graph-based technologies for intelligence analysis.\nCommun. ACM 47(3), 45\u201347 (2004)\n6. D. Cook, L.B. Holder, Graph-based data mining. IEEE Intell. Syst. 15(2), 32\u201341 (2000)\n7. J.L. Creasor, D.B. Skillicorn, QTagger: Extracting Word Usage from Large Corpora (Queen\u2019s\nUniversity, School of Computing, Kingston, 2012). Technical Report 2012-587\n8. G.S. Davidson, B. Hendrickson, D.K. Johnson, C.E. Meyers, B.N. Wylie, Knowledge mining\nwith VxInsight : discovery through interaction. J. Intell. Inf. Syst. 11(259-285) (1998)\n9. E.C. Davies, A retrospective view of Systemic Functional Linguistics, with notes from a\nparallel perspective. Funct. Linguistics 1(1), 4 (2014)\n10. J. Galloway, S. Simoff, Network data mining: discovering patterns of interaction between\nattributes, in Advances in Knowledge Discovery and Data Mining . Springer Lecture Notes\nin Computer Science, vol. 3918 (2006), pp. 410\u2013414\n11. Google WebAPI (2004). www.google.com/apis\n12. M.A.K. Halliday, J.J Webster, Bloomsbury Companion to Systemic Functional Linguistics .\nContinuum Companions (Bloomsbury Academic, London, 2009)\n13. M. Herke-Couchman, J. Patrick, Identifying interpersonal distance using systemic features,\ninProceedings of AAAI Workshop on Exploring Attitude and Affect in Text: Theories and\nApplications (Springer, Netherlands, 2004), pp. 199\u2013214\n140 D. B. Skillicorn and N. Alsadhan\n14. H. Kanayama, T. Nasukawa, H. Watanabe, Deeper sentiment analysis using machine trans-\nlation technology, in Proceedings of the 20th International Conference on Computational\nLinguistics (2004)\n15. A. Kappagoda, The use of systemic-functional linguistics in automated text mining, in DSTO\nDefence Science and Technology Organisation DSTO-RR-0339 (2009). Technical report\n16. C.E. Lamb, D.B. Skillicorn, Detecting deception in interrogation settings, in IEEE Interna-\ntional Conference on Intelligence and Security Informatics (2013), pp. 160\u2013162\n17. M. Lazaroff, D. Snowden, Anticipatory models for counter-terrorism, in Emergent Information\nTechnologies and Enabling Policies for Counter-terrorism , ed. by R.L. Popp, J. Yen, chapter 3,\nIEEE Press Series on Computational Intelligence (2006), pp. 51\u201373\n18. D.D. Lee, H.S. Seung, Learning the parts of objects by non-negative matrix factorization.\nNature 401, 788\u2013791 (1999)\n19. C. Matthiessen, M.A.K. Halliday, Systemic Functional Grammar: A First Step into the Theory\n(Macquarie University, Macquarie Park, 1997)\n20. M.L. Newman, J.W. Pennebaker, D.S. Berry, J.M. Richards, Lying words: predicting deception\nfrom linguistic styles. Personal. Soc. Psychol. Bull. 29(5), 665\u2013675 (2003)\n21. J. Patrick, The scamseek project\u2014text mining for \ufb01nancial scams on the internet, in Data\nMining: Proceedings of the 4th Australasian Workshop on Data Mining . Springer LNCS 3755\n(2006), pp. 295\u2013302\n22. J. Qin, J. Xu, D. Hu, M. Sageman, H. Chen, Analyzing terrorist networks: a case study of\nthe global Sala\ufb01 Jihad network, in Intelligence and Security Informatics, IEEE International\nConference on Intelligence and Security Informatics, ISI 2005, Atlanta, GA, USA, May 19-20 .\nLecture Notes in Computer Science LNCS 3495 (Springer, Berlin, 2005), pp. 287\u2013304\n23. P. Rayson, A. Wilson, G. Leech, Grammatical word class variation within the British National\nCorpus sampler. Lang. Comput. 36(1), 295\u2013306 (2001)\n24. M. Sageman, Understanding Terror Networks (University of Pennsylvania Press, Philadelphia,\n2004)\n25. A.P. San\ufb01lippo, A.J. Cowell, S.C. Tratz, A.M. Boek, A.K. Cowell, C. Posse, L.C. Pouchard,\nContent analysis for proactive intelligence: marshalling frame evidence, in Proceedings of the\nTwenty-Second AAAI Conference on Arti\ufb01cial Intelligence (2006), pp. 919\u2013924\n26. S. Scott, S. Matwin, Text classi\ufb01cation using WordNet hypernyms, in Natural Language\nProcessing Systems: Proceedings of the Conference. Association for Computational LinguisticsSomerset, New Jersey (1998), pp. 38\u201344\n27. D.B. Skillicorn, Lessons from a jihadi corpus, in 2012 IEEE/ACM International Conference\non Advances in Social Networks Analysis and Mining (ASONAM) (IEEE, Piscataway, 2012),\npp. 874\u2013878\n28. D.B. Skillicorn, E. Reid, Language use in the jihadist magazines Inspire and Azan. Secur.\nInform. 3(1), 9 (2014)\n29. R. Socher, A. Perelygin, J.Y . Wu, J. Chuang, C.D. Manning, A.Y . Ng, C. Potts, Recursive deep\nmodels for semantic compositionality over a sentiment treebank, in Proceedings of the 2013\nConference on Empirical Methods in Natural Language Processing (2013), pp. 1631\u20131642\n30. Y .R. Tausczik, J.W. Pennebaker, The psychological meaning of words: LIWC and computer-\nized text analysis methods. J. Lang. Soc. Psychol. 29, 24\u201354 (2010)\n31. C. Whitelaw, S. Argamon, Systemic functional features in stylistic text classi\ufb01cation, in\nProceedings of AAAI Fall Symposim on Style and Meaning in Language, Art, Music, andDesign, Washington, DC (2004)\n32. C. Whitelaw, N. Garg, S. Argamon, Using appraisal taxonomies for sentiment analysis, in\nSecond Midwest Computational Linguistic Colloquium (MCLC 2005) (2005)\n33. Y . Zhang, S. Zeng, L. Fan, Y . Dang, C.A. Larson, H. Chen, Dark web forums portal: Searching\nand analyzing jihadist forums, in IEEE International Conference on Intelligence and Security\nInformatics (2009), pp. 71\u201376\nTwitter Bots and the Swedish Election\nJohan Fernquist, Lisa Kaati, Ralph Schroeder, Nazar Akrami,\nand Katie Cohen\nAbstract In this chapter, we present a study of how political Twitter bots were\nused before the Swedish general election in 2018. We have not restricted our study\nto bots that are a software program instead, we are interested in any type of bot-\nlike automated behavior. This includes a human that manually copies or retweets\ncontent repeatedly in a robot-like way to in\ufb02uence the interaction between a user\nand content or with other users.\nOur results show that bots were more likely to express support towards the\nimmigration-critical party the Sweden Democrats, compared to genuine accounts.\nKeywords Bots \u00b7 Automated behavior \u00b7 Twitter \u00b7 Social media analysis \u00b7\nElection\n1 Introduction\nThe Swedish general election was held on September 9th 2018 and was surrounded\nby great concern regarding the role of disinformation disseminated via digital media.\nThe background to these concerns is broader debates about the role of digital media\nin politics that have intensi\ufb01ed since the Brexit referendum and the election of\nDonald Trump. The Internet and social media are powerful tools for in\ufb02uencing\npolitical campaigns and discussions. Since 2016, the Internet has been used more\nthan TV and newspapers as a source of political information in Sweden [ 17]. Ever\nJ. Fernquist \u00b7 L. Kaati ( /envelopeback) \u00b7 K. Cohen\nSwedish Defence Research Agency, Kista, Sweden\ne-mail: johan.fernquist@foi.se ;lisa.kaati@foi.se ;katie.cohen@foi.se\nR. Schroeder\nOxford University, Oxford, England\ne-mail: nazar.akrami@psyk.uu.se\nN. Akrami\nUppsala University, Uppsala, Sweden\ne-mail: nazar.akrami@psyk.uu.se\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_6141\n142 J. Fernquist et al.\nsince the Brexit Referendum and Donald Trump\u2019s presidential election campaign\nin 2016, there has been a discussion about the role that digital media play in\ndisinformation and in\ufb02uence operations in political campaigns. One preconditionfor effectively being able to counteract disinformation is a better understanding of\nhow disinformation and attempts to in\ufb02uence politics work. What are the messages?\nHow are they spread, and with what intentions?\nIn Sweden, the discussion about disinformation has focused on several areas: the\nuse of alternative or partisan websites, the possibility of the spread of messages\nby foreigners and speci\ufb01cally Russia, and the use of bots to spread messages.However, bots are not only used for spreading disinformation. Bots have been used\nfor a variety of purposes. While they were initially designed to automate otherwise\nunwieldy online processes which could not be done manually, they have come to bemost commonly used for commercial purposes such as directing Internet users to\nadvertisements and the like. Bots are also often used to further illegal activity such\nas collecting data from users for criminal gain.\nThere are many different de\ufb01nitions of \u2018bots\u2019. In [ 13] bots have been de\ufb01ned\nas \u201cexecutable software that automates the interaction between a user and content\nor other users\u201d. In the work by Gorwa and Guilbeault [ 11] a typology of bots is\npresented. The topology suggests six different types of bots:\n\u2013 web robots (crawlers and scrapers)\n\u2013 chatbots (human-computer dialog system which operates through natural lan-\nguage via text or speech)\n\u2013 spambots (bots that post on online comment sections and spread advertisements\nor malware on social media platforms)\n\u2013 social bots (various forms of automation that operate on social media platforms)\n\u2013 sock puppets and \u201ctrolls\u201d (fake identities used to interact with ordinary users on\nsocial networks)\n\u2013 cyborgs and hybrid accounts (a combination of automation and human curation)\nWeb robots do not interact with users on a social platform and are therefore\nconsidered to be different from automated social media accounts. Social bots are\nbots that generally act in ways that are similar to how a real human may act in an\nonline space. Social bots that are used for political purposes are called political bots.The term sock puppet refers to fake identities used to interact with ordinary users on\nsocial networks. Politically motivated sock puppets, especially when coordinated by\ngovernments or interrelated actors, are according to [ 11], called \u201ctrolls\u201d. According\nto the typology presented in [ 11], the bots we are studying in this work are both\nautomated social bots and sock puppets. The aim with the de\ufb01nition of bots that we\nuse is to capture an automated behavior. The automated behavior can be inducedby humans working at a state-owned agency to spread propaganda (sock puppets),\nby fully automated software bots (spambots, social bots), and by humans that are\nbehaving in an automated fashion (spambots). The effect of an automated behavioris the same independently of if it is a software or a human that is spreading the\nmessages.\nTwitter Bots and the Swedish Election 143\nPolitical bots are used in various ways when they aim at in\ufb02uencing public\nopinion. For example, bots can be used to spread disinformation to mislead about\nthe state-of-affairs. They can also be used to spread false news with the aim ofcreating uncertainty about established sources of information. Another aim of using\nbots is to lead users to think that speci\ufb01c content is more shared, more generally\naccepted or more mainstream than is the case. We will use botandautomated\naccount interchangeably. As mentioned before, we do not de\ufb01ne an automated\naccount based on whether there is a human or a piece of software that produces\nthe content but rather base this on the account\u2019s behavior.\nEven tough bots can exist on many different platforms, we only focus on studying\nbots on Twitter. One of the reasons for studying Twitter is because it is a widely used\npublic forum for political discussion in Sweden, especially among journalists [ 12].\nIn the rest of this chapter, we will present an analysis of how political bots were\nused on selected hashtags on Twitter before and after the Swedish general election\nin 2018. The data was collected between March 5th and September 30th.\nThe analysis of automated accounts presented in this chapter consist of three\ndifferent parts:\n\u0081 The number of automated accounts (bots)\n\u0081 An analysis of the domains bot links to and what kind of messages they distribute\n\u0081 How the bots communicate with other accounts on Twitter\n1.1 Swedish Politics\nIn Sweden, a party must receive at least 4% of the votes in an election to be assigneda seat in the Swedish parliament. In 2018 eight parties received more than 4% of thevotes. The largest party is the Social Democratic Party (S). S is a labor party at its\ncore with policies based on freedom, equality, and solidarity. The party prioritizes\nthe creation of more jobs and to provide a better education for all.\nThe Moderate Party (M) is the second largest party. M is a conservative party\nwith liberal ideas. The individual\u2019s freedom to choose is central to its policies, and\nthe party generally supports reduced taxes and economic liberalism.\nThe Sweden Democrats (SD) is a social conservative party based on nationalistic\nvalues. The party is associated with issues of migration, and the party\u2019s policies are\nbased on protecting the national identity as a way of sustaining the Swedish welfare\nstate.\nThe Centre Party (C) is a liberal and agriculture political party. The party believes\nthat society should be built on people\u2019s responsibility for each other and nature andfocus on the national economy, the environment, and integration.\nThe Left Party (V) de\ufb01nes itself as a socialist and feminist political party with\nan ecological basis. Focus areas are jobs, welfare services, and gender equality.The party was against Sweden joining the EU in 1995 and still advocates an exit.\nThe Christian Democratic Party (KD) believes that stable families should form the\n144 J. Fernquist et al.\nbasis of society. The four main issues that the Christian Democrats focuses on are:\nimproving elderly care, giving families with children the freedom to select desired\nchildcare, simplifying regulations for companies and lowering taxes as a means topromote growth and combat unemployment.\nThe Liberals (L) are a liberal and social\u2014liberal political party that holds a\nmiddle position in the Swedish political landscape. The Green Party (MP) has aclear focus on environmental issues. The party focuses on stopping climate change\nand protecting the environment, \ufb01ghting nuclear power and promoting European\nintegration.\nApart from the eight parties that are in the Swedish parliament, there are also\nseveral smaller parties. Two newly formed parties that appear in our analysis are\nAlternative for Sweden (AFS) and Citizens\u2019 Coalition (MED). AFS was foundedin 2017. The party\u2019s policies are based on immigration issues, democracy and\npoliticians, and law and order. MED considers itself liberal-conservative and green\nconservative. Both parties are anti-immigration.\n2 Method\nIn our analysis of the Swedish election, we use machine learning to detectaccounts with automatic behavior. In the rest of this section, we describe how\nthe classi\ufb01cation model is built, how it performs compared to other bot detection\nmodels, and what data we have used to train the model. Our work is also put intorelation to previous work in the domain.\n2.1 Classi\ufb01cation of Bots\nWe have trained a classi\ufb01cation model to identify accounts exhibiting automatic\nbehavior. The classi\ufb01cation problem is to determine if an account is genuine or a bot.\nHere, a genuine account is an account that is operated by a \u201cnormal\u201d human being.To build a model that is able to recognize automatic behavior, labeled training data\nis needed. The training data consists of accounts that are already known as bots or\ngenuine accounts. When training our model, we use a number of different features.Our model is language independent but we have used it to classifying tweets in\nSwedish. The classi\ufb01cation is described in more detail in [ 9].\nRelated Work\nThere have been several efforts dedicated to bot detection on Twitter. Random forest\nis the classi\ufb01cation algorithm that has been proven to give the best performance for\nbot detection for the supervised problem when several different classi\ufb01ers have been\nTwitter Bots and the Swedish Election 145\ntested [ 14,18,19]. In [ 10] user meta-features and tweet features were used when\ntraining a classi\ufb01cation algorithm. Their results indicated that bots have more URLs\nin their tweets and that they have a higher follower-friend ratio . The terminology\nused is from the Twitter API, where \u2018friend\u2019 indicates the number of users that the\nuser is following, as opposed that the number of followers he or she has. In [ 10]i t\nis also shown that genuine accounts get more likes on their tweets than bots.\nIn [2] bots and cyborgs are studied. The author states that follower-friend ratio\nmight be a bad feature since the bots might be able to unfollow accounts which\nnot are following them back automatically. Instead, they introduce text entropyas a feature to measure the similarity of the texts posted by an account with the\nhypothesis that bots have more uniform content in their tweets. Another feature that\nis considered is what kind of devices the different accounts are using when tweeting.Most of the genuine accounts are using the web or the mobile application while bots\nare using other applications such as the API. It was also noted that genuine accounts\nhave a more complex timing behavior compared to bots and cyborgs.\nIn [19] a total of 1150 different features are used to train a model that recognizes\nbots. One set of features that is used is time features, including the statistics of times\nbetween consecutive tweets, retweets, and mentions. The results show that the twomost informative feature types are user meta-data and content features. The content\nfeatures include frequency and proportion of part-of-speech-tags (POS), number of\nwords in a tweet and entropy of words in a tweet.\nTraining and Testing Data\nWe have used a number of different datasets to train our classi\ufb01cation model. The\n\ufb01rst dataset was originally crawled during October and November 2015 and isdescribed in [ 19]. The dataset contains labeled information about 647 bot accounts\nand 1367 genuine accounts. Each account has produced at least 200 tweets, of\nwhich at least 90 occurred during the crawling period. The accounts were manuallyannotated as bots or genuine. The annotation was based on characteristics such as\npro\ufb01le appearance, produced content, and the interaction with other pro\ufb01les.\nThe second dataset consists of 591 bots and 1680 genuine accounts [ 4]. The\ngenuine accounts are Italian users that through a survey accepted to be a part of the\nstudy or accounts that were regularly active for a long period. The bot accounts were\nbought from a bot-service provider.\nThe third dataset was manually annotated by four undergraduate students [ 10].\nThe users in the dataset were divided into four subsets depending on the number of\nfollowers. The subsets were divided into users with more than 10 million followers,users with between 900 thousand and 1, 1 million followers, users with 90 thousand\nto 110 thousand followers and users with 900 to 1100 followers. We only use the\ntwo sets with users with 90 thousand to 110 thousand followers and users with 900to 1100 followers since we believe that it is unlikely that a Swedish bot account has\nmore than 1 million followers. In total, the two sets consist of 519 human accounts\nand 355 bot accounts.\n146 J. Fernquist et al.\nThe datasets used in [ 4,10,19] are not available in the original form. Either data\nis missing, or only the annotated labels of the accounts are given. Since it is not\npossible to obtain these datasets in their original form, we cannot use the datasetsfor comparing performance. The datasets were only used for training our model.\nThe dataset used in [ 6] (referred to as test set one by the authors of the paper)\nis the only dataset available in its original form. The dataset consists of 991 socialspam bots and 991 genuine accounts. The genuine accounts are randomly selected\nfrom a set of more than 3000 accounts to get a 50/50 distribution of bots and genuine\naccounts. This means that we do not have the same set as the authors. The bots arecollected in conjunction with a mayoral election in Rome 2014 where one candidate\nbought 1000 automatic accounts. The purchased accounts all had (stolen) pro\ufb01le\npictures, (fake) pro\ufb01le description and a (fake) location. Genuine accounts wereidenti\ufb01ed by sending out a question to randomly selected Twitter users. The ones\nthat replied were considered genuine.\nFeatures\nIn our classi\ufb01cation model, we have used a total of 140 features. The features can\nbe divided into two different types. The \ufb01rst type is User Meta Data features where\ninformation about the characteristics of the pro\ufb01le, such as the number of followersand friends and a total number of tweets is gathered. The second feature type is the\ntweet features that holds information about the actual content and when and how the\ncontent is posted. Similar to what is done in [ 2,19] we use text entropy assuming\nthat bots might have a less complex and varied way of expressing themselves.\nSimilar to [ 19], we have included time features such as statistics of time between\nconsecutive tweets, retweets, and mentions as well as statistics for the time betweenposted tweets containing URLs. All features are listed in Table 1.\nClassi\ufb01cation Algorithm\nThere have been several approaches to build classi\ufb01cation models for bot detection.\nDifferent algorithms such as AdaBoost, logistic regression, support vector machines\nand naive Bayes have been tested. The best results (so far) are when using random\nforest which is the motivation for us to also use random forest in our classi\ufb01cation.\nModel Evaluation\nWe have used three datasets from [ 4,10,19] together with our 140 different features\nto train a model using random forest. The model was tested on the only dataset we\nhave access to in its original form. In [ 6], the same dataset was used to compare the\nperformance of other bot classi\ufb01cation models. We included a comparison from [ 6]\nand used the same dataset to test our model. The performance (Accuracy, Precision,\nTwitter Bots and the Swedish Election 147\nTable 1 List of the 140 features extracted from each Twitter user\nMeta features Content features\nAge of account # unique hashtags per tweet\n# tweets # unique mentions per tweet\n# tweets per day # unique Urls per tweet\nFriends-account age ratio Normalized distribution of sources\n# followers Time between tweetsa\n# friends Length of tweeta\nFollower-friends ratio # unique sources\nHas location retweet-tweet ratio\nHas default pro\ufb01le description # hashtags per tweets\nHas default pro\ufb01le image # urls per tweet\n#l i k e sg i v e n # mentions per tweet\n#l i k e sg i v e np e r#f o l l o w e r s # media per tweet\n#l i k e sg i v e np e r#f r i e n d s # symbols per tweet\n# likes per day # retweets achieved per # tweet\nL e n g t ho fu s e rn a m e Time between urlsa\nTime between mentionsa\nTime between retweetsa\n# wordsa\nHours of day tweeting\nWeekdays tweeting\nNormalized distribution hours tweeting\nNormalized distribution weekdays tweeting\nNormalized distribution of tweet endings\nString entropya\nTotal entropy of all tweets\u2019 strings concatenated\naStatistics of an array of values (mean, median, population standard deviation, standard deviation,\nmaximum value and minimum value)\nTable 2 Performance measures for different models, the model with the best performance is\nmarked with bold\nModel Type A P R F1\nOur model supervised 0.957 0.941 0.976 0.958\nDavis et al.[ 7] Supervised 0.734 0.471 0.208 0.288\nYang et al. [ 21] Supervised 0.506 0.563 0.170 0.261\nMiller et al. [ 16] Unsupervised 0.526 0.555 0.358 0.435\nAhmed et al. [ 1] Unsupervised 0.943 0.945 0.944 0.944\nCresci et al. [ 5] Unsupervised 0.976 0.982 0.972 0.977\nRecall, and F1-score) is shown in Table 2. The comparison includes both supervised\nand unsupervised models. As mentioned earlier, the 911 genuine accounts in [ 6]\nwere selected randomly from a set of more than 3000 genuine accounts. Since our\ngenuine accounts were selected randomly, we (most likely) ended up with a slightlydifferent testing set.\n148 J. Fernquist et al.\nThe supervised methods use cluster algorithms to identify clusters of bots. \u00cfn [ 16]\nfeature vectors with the majority of features as text features are clustered using\nDenStream and StremKM++ as clustering algorithms.\nIn [1] graph clustering on statistical features related to hashtags, URLs, mentions,\nand retweets are used. The feature vectors were compared to each other using\nEuclidean distance and then clustered using the Fast greedy community detection\nalgorithm. In [ 5] a bio-inspired technique for modelling behavior of users online\nwith so-called digital DNA sequences is presented. The sequences are string\nencodings of the behavior of a user, and the sequences are then compared between\nthe different users by measuring the longest common substring to \ufb01nd clusters ofusers.\nThe results in Table 2shows that the model from [ 5] performs best on all metrics\nexcept for recall where our model performs better. Our model performs best of thesupervised models included in the comparison. We are aware that one of our training\nsets has the same author as our test set which might be a reason for the high accuracy\nthat we obtain. However, we have veri\ufb01ed that none of the users are found in bothdatasets.\nFeature Importance\nTo get an understanding of what features that played an important role in the\nclassi\ufb01cation we have calculated the feature importance with forests of trees .T h e\nten most important features are shown in Table 3.\nThe most important feature when determining whether an account is a bot or\nnot is the number of given likes divided by the number of friends. The second\nmost important feature is the ratio between the number of followers and friends.\nAs mentioned earlier, this feature could however sometimes be misleading sincebots can be able to unfollow accounts that not are following back. Several of the\nmost important features are related to the time between retweets.\nTable 3 Most important features for our bot classi\ufb01cation\nTop 10 Feature\n1 # given likes per # friends\n2 Followers-friends ratio\n3 Maximum time between retweets\n4 # retweets achieved per tweet\n5 Standard deviation of time between retweets\n6 Median time between retweets\n7 Population standard deviation of time between retweets\n8 Mean time between retweets\n9 # given likes\n10 # given likes per # followers\nTwitter Bots and the Swedish Election 149\nTable 4 The different categories used to categorize the content of tweets\nCriticism om media Criticism of journalists, journalism or media\nCriticism of elites Criticism of the government, or persons or organizations that\nare regarded as in\ufb02uential political elite\nParty support Support of one or more parties\nCriticism of parties Criticism of one or more parties\nCriticism of immigration Criticism of immigration, asylum seekers and refugees\nElection fraud Discussions or observations of election fraud\nDeleted Tweets that have been deleted and can no longer be analyzed\nOther/Uncategorized Content that does not fall into any of the categories above\n2.2 Content Classi\ufb01cation\nTo understand the difference in communicated messages between bots and genuine\nTwitter accounts, a random sample of tweets was selected and then manually coded.This resulted in a number of different categories. The categories were identi\ufb01ed\nby \ufb01ve persons that independently analyzed a set of tweets. The categories were\nbased on the content of the tweet. The result of the \ufb01ve persons\u2019 classi\ufb01cations wascombined into eight generic categories that are described in Table 4.\nWhen the categories were de\ufb01ned, ten research assistants from Uppsala Univer-\nsity classi\ufb01ed a total of 1063 tweets, 547 tweets were published by bots and 516published by genuine account. Each tweet was classi\ufb01ed by at least two research\nassistants and each tweets category was determined by a majority decision. The\nresearch assistants did not know whether the tweet they were classifying waspublished by a bot or a genuine account. If the category for a tweet was selected\nas party support or criticism of party, the research assistant was able to enter which\none or which parties that the support or criticism was expressed for. If a tweetexpressed both support and criticism, the research assistants were advised to select\nparty support.\n2.3 Data\nThe data that is analysed was collected during the period March 5th\u2013September 30th2018. All tweets in Swedish that including at least one of the hashtags #valet2018,\n#val2018 or #valet, or one of the keywords valet2018 ,val2018 orvalet (all words\nare related to the election). The word valet isthe election in Swedish. A total of\n1,005,276 tweets published by 70,973 accounts were collected from the Twitter\nstreaming API.\n150 J. Fernquist et al.\nThe classi\ufb01cation of the accounts in the dataset was done after all the tweets had\nbeen downloaded. A number of tweets in the dataset belong to accounts that were\nsuspended by Twitter or deleted by the users themselves. The most common reasonfor an account to be suspended is that the account is spamming or using a fake\nidentity.\n1This indicates that a large part of the suspended accounts are automated,\nhowever, accounts can also be suspended by exhibiting offensive behavior.2\n3 The Amount of Bots\nDuring the period from March 5th to September 30th 2018, a total of 1,005,276tweets linked to the Swedish general election was published by 70,973 accounts.\nThese accounts were classi\ufb01ed into four different classes: genuine, automatic,\nsuspended, or deleted. The distribution between the different classes of accountsare shown in Table 5. Most of the accounts were classi\ufb01ed as genuine accounts.\nApproximately 6% of the accounts that tweet about Swedish election were\nclassi\ufb01ed as automated accounts, in total they were responsible for 8% of thecontent. If we make the somewhat extreme assumption that all suspended accounts\nare automated as well, then 12% of accounts are automated, and 9% of the content\nis automated. The real proportion of automatic accounts are most likely somewherein that interval.\nIn Fig. 1, the number of tweets per day is shown. From the beginning of August\nuntil the election day, there is an increase of tweets about the election. On theelection day September 9th, more than 45 thousand tweets were published. The\n\ufb01gure shows that the interest in discussing the election decreased right after the\nelection.\nIn Fig. 2, the number of active accounts per month from March to September\nare shown. More accounts were participating in discussing the election closer to the\nelection. The genuine accounts make up the biggest share of accounts for the wholeperiod. From July to August, the number of genuine accounts increased with 118%.\nFor the same period, July to August, the number of bots increased by 167%. From\nTable 5 Distribution\nbetween the differentcategories of accountsAccount category Number of accounts Number of tweets\nGenuine 60,384 876,792\nBots 4084 73,723\nSuspended 4052 14,902\nDeleted 2453 39,859\n1See Twitter\u2019s help page about suspended accounts https://help.twitter.com/en/managing-your-\naccount/suspended-twitter-accounts .\n2See Twitter\u2019s end-user licence agreement https://help.twitter.com/sv/rules-and-policies/twitter-\nrules .\nTwitter Bots and the Swedish Election 151\nFig. 1 The number of tweets per day for each category of accounts\nFig. 2 The number of accounts per month for each category of accounts\nAugust to September, the number of genuine accounts increased with 16%, and the\nnumer of bot accounts with 28%.\n4 Content\nTo get an understanding of what kind of content that were published we conducted\ntwo analyses. We explored the domains to which different accounts link to and what\nmessages that are spread by the different classes of accounts.\n152 J. Fernquist et al.\n4.1 Out Links\nA tweet can consist of a maximum of 280 characters, which sometimes restricts the\nuser from actually convey the message in the text. It is quite common to include\na link to an external website in the tweet. In the dataset being analyzed here, it is\ncommon to link to online versions of traditional media such as The Swedish publicservice television company (SVT) or the newspaper Expressen, it is also common to\nlink to digital platforms such as Youtube and Facebook. A third category of media\nthat is quite common to link to is immigration critical alternative media\n3such as\nSamh\u00e4llsnytt and Nyheter idag.\nTo get an understanding regarding the differences between the different classes\nof accounts, we have studied the most common domains that is linked to, for eachof the different classes of accounts. The ten most linked domains for each of the\ncategories of accounts are shown in Table 6. For each of the categories of accounts,\nexpressen.se and svt.se are the most common domains to link to. Youtube.com andaftonbladet.se are found in the list of most linked domains for each of the class of\naccounts. This is also true for the immigration critical alternative media samnytt.se,\nnyheteridag.se, and friatider.se. For the suspended accounts, half of the ten mostlinked domains are immigration critical. Here we can \ufb01nd the Nordic resistance\nmovement\u2019s news portal nordfront.se. One of the reasons for \ufb01nding nordfront.se in\nthe list for the suspended accounts is that Twitter are suspending accounts which arelinking to nordfront.se.\n4\nTable 7shows the difference between the bots and genuine accounts most\nshared domains 1 week before and after the election. Svt.se, expressen.se and\nTable 6 The ten most linked domains for the different categories of accounts\nGenuine Bots Suspended Deleted\nexpressen.se expressen.se expressen.se expressen.se\nsvt.se svt.se svt.se svt.se\naftonbladet.se aftonbladet.se nordfront.se samnytt.se\ndn.se omni.se youtube.com aftonbladet.se\nyoutube.com sverigesradio.se friatider.se friatider.se\nsamnytt.se youtube.com samnytt.se youtube.com\nnyheteridag.se samnytt.se nyheteridag.se nyheteridag.se\nomni.se friatider.se aftonbladet.se facebook.com\ngp.se dn.se katerinamagasin.se dn.se\nfriatider.se nyheteridag.se sverigesradio.se gp.se\n3In this chapter, we call these websites immigration critical alternative media since that is an\nestablished concept in Sweden when talking about media that are critical of what is considered tobe an overly generous immigration policy.\n4This article describes how Twitter removed accounts spreading links to nordfront.se (in Swedish)\nhttps://www.dn.se/nyheter/politik/\ufb02era-konton-kopplade-till-nazistiska-nmr-raderade-av-twitter/ .\nTwitter Bots and the Swedish Election 153\nTable 7 The ten most linked domains for bots and genuine accounts 1 week before and after the\nelection\nGenuine accounts Bots\nBefore election After election Before election After election\nsvt.se expressen.se expressen.se svt.se\nexpressen.se svt.se svt.se expressen.se\naftonbladet.se aftonbladet.se aftonbladet.se aftonbladet.se\nnyheteridag.se data.val.se samnytt.se youtube.com\nsamnytt.se metro.se sverigesradio.se omni.se\nyoutube.com dn.se youtube.com sverigesradio.se\ndn.se nyadagbladet.se omni.se dn.se\nomni.se omni.se nyheteridag.se samnytt.se\nsverigesradio.se youtube.com friatider.se metro.se\nfacebook.com samnytt.se dn.se data.val.se\naftonbladet.se, all traditional media, are dominating as most shared domains both\nbefore and after the election. Links to the immigration critical domains have\ndecreased after the election for both type of accounts. Data.val.se is a website withstatistics about the election, it is present for both account classes after the election.\n5 Messages\nTo understand the difference of content spread by bots and genuine accounts, we\nhave analyzed a sample of tweets published 1 week before and 1 week after the\nelection (see Sect. 2.2). The distribution between the different messages for bots\nand genuine accounts is shown in Fig. 3.\nThe most common message for both categories is party support followed by\ncriticism of parties. More than 20% of the tweets published by bots have beendeleted, compared to 10% for the genuine accounts. Overall, there are only minor\ndifferences between what bots and genuine accounts communicate.\nIn Figs. 4and5the distribution of party support and party criticism for bots\nand genuine accounts are shown. The \ufb01gures show the proportion of support and\ncriticism for the different parties.\nRegarding party support, it is clear that the Sweden democrats (SD) and\nAlternative for Sweden (AFS) are the most common parties to express support for\nin Twitter. It is also more common that a bot is showing support for SD compared\nto a genuine account. Also support for the Left Party (V) is more common from abot than a genuine account.\nRegarding the party criticism that is shown in Fig. 5, the criticism for the parties\nis relatively even between genuine accounts and bots. The Social Democratic Party(S) is the party receiving most of the criticism. The Center Party (C) and the Sweden\ndemocrats (SD) are the parties where the difference between criticism between\n154 J. Fernquist et al.\nFig. 3 The share of different messages spread by different categories of accounts\nFig. 4 The share of parties for which different categories of accounts express support\ngenuine and bot accounts are the largest. It is more common that a genuine account\nexpresses criticism for SD, while it is more common for a bot to express criticism\ntowards C.\nThere have been other studies on how bots were used in discussions about\nthe Swedish election. In [ 3], the authors found at least 55 accounts with bot-like\nTwitter Bots and the Swedish Election 155\nFig. 5 Distribution of the parties for which different accounts express criticism\nbehavior that expressed support for AFS. Those accounts were active especially the\nweeks prior the election. The study showed that bot-like behavior was particularly\nclear for accounts criticizing S and supporting SD, which is in line with the results\nof our study. In [ 3] it is concluded that the behavior of the identi\ufb01ed bot accounts\nwas more genuine-like than bots which had been identi\ufb01ed in previous elections in\nGermany and France.\nThe Swedish newspaper Dagens Nyheter published an article [ 15] about a Twitter\nanalysis regarding the support of AFS. All tweets with the hashtag #afs18 was\ndownloaded. The analysis showed that half of the 14,000 tweets with the hashtag\nwas published by 15 accounts.\n6 Spread\nHow messages spread and users communicate with each other can be understood bystudying the network of accounts retweeting each other. Retweeting is a powerful\ntool for in\ufb02uencing others on Twitter. When retweeting another account, you are\npublishing someone else\u2019s post in your own feed. This is a way to distribute someoneelse\u2019s message and commonly this also means that you agree and express support\nfor another account and the published post.\nA principle in marketing and propaganda is that increased visibility leads to\nincreased opportunity to in\ufb02uence. An article which because of several retweets\nappears in a user\u2019s feed several times will most likely in\ufb02uence the user more\nthen an article that appears only once. If the article also conveys a message which\n156 J. Fernquist et al.\nFig. 6 The network of accounts that have discussed the election\nthe user recognizes from previous discussions, the article is even more likely to\nassimilate [ 8].\nIn Fig. 6, the 70,973 accounts tweeting about the election from March 5th until\nSeptember 30th are shown. In the \ufb01gure, every account is indicated by a node\n(circle), and every line between two accounts shows that one account has retweetedthe material of another account in its own feed at least once during the time period.\nThe size of an account\u2019s circle indicates how much an account has been retweeted by\nother users. The larger the circle, the more popular account to retweet. Green nodesrepresent genuine, red nodes represent bots, yellow nodes represent suspended, and\nthe white nodes represent deleted accounts.\nIn Fig. 6, two big clusters of accounts which do not retweet anyone else in the\nnetworks are present. These two clusters appear in the top and bottom of the \ufb01gure.\nSince these accounts have not retweeted anyone else in the network, they are not a\npart of the bigger cluster in the middle but are instead found outside the big cluster.This does not exclude that these users might follow, like and comment other users\nin the network. These accounts may also have ended up in our dataset since they\nhave used the selected hashtags and keywords, but not in the context of discussionsabout the Swedish election.\nNotably, there are a number of smaller clusters of accounts on the edges of the\nbig cluster. These clusters consist of accounts that show the same behaviors asothers in the groups, and they retweet only larger and more popular accounts. These\nTwitter Bots and the Swedish Election 157\nFig. 7 The network of accounts that have discussed the election with the two clusters marked\nsmall clusters indicate that some accounts have a group of followers which by only\nretweeting one account make sure that the account gets increased distribution of\ncommunicated messages. By investigating what category of accounts that appears inthese smaller clusters, we can detect whether some accounts have used for example\nbots to get increased distribution of tweets.\nManual content analysis revealed that the main part of the network can be divided\ninto two clusters. One of the clusters are inside the solid circle marked in Fig. 7.\nIn this cluster, one can \ufb01nd the majority of the of\ufb01cial accounts of the political\nparties in the Swedish parliament. The discussions are politically general and manydifferent political issues are discussed. The second cluster can be found in the\ndashed circle. This cluster consists of accounts that discusses immigration policies\nand the negative consequences with immigration. The most popular accounts (interms of retweets) in the network appear in the middle of the dashed cluster. These\naccounts have many followers and are often retweeted by several other accounts.\nIn the middle between the two clusters (solid circled and dashed circled), we \ufb01ndaccounts that positions themselves as political independent. These accounts are\nretweeted by both the clusters. Accounts that appears between the clusters can for\nexample be news sites.\n158 J. Fernquist et al.\n6.1 The Impact of Bots and Suspended Accounts\nTo get an understanding of whether the bots was effective in spreading messages, we\ninvestigated how the different account categories appears in the network. Since the\nmost common reason that an account is being suspended by Twitter is that it shows\nwhat we call a bot-like behavior, we have also included the suspended accounts inthis analysis.\nThe network analysis can be used to give answers to the following questions:\n\u0081 Are the bots and the suspended accounts popular to retweet?\n\u0081 Are there clusters consisting of bots and suspended accounts?\nBy detecting clusters of bots and suspended accounts, we can \ufb01nd networks\nconnected to individual accounts that might have used bots to distribute their\nmessages. Seven of the ten most retweeted accounts in the cluster are part of the\nimmigration critical cluster. Nine of the accounts are genuine, and the tenth hasbeen suspended by Twitter.\nIn Fig. 8, we can see where in the network the bots appear. The majority of the\nbots can be found outside the big cluster and appears in the two clusters of accounts\nFig. 8 The network of accounts only showing the accounts that have been classi\ufb01ed as bots\nTwitter Bots and the Swedish Election 159\nFig. 9 The network of accounts only showing the accounts which have been suspended by Twitter\nwhich has not retweeted nor been retweeted. The density of bots are higher in the\nimmigration critical cluster but no large groups consisting of a large amount of botsretweeting only one account are identi\ufb01ed.\nIn Fig. 9, we can see where in the network the accounts that have been suspended\nby Twitter appear. It is clear that the majority of the suspended accounts appear inthe immigration critical cluster, and several smaller clusters of suspended accounts\nare found. Each of these clusters consist of accounts that have only retweeted one\nother account in the network and therefore acts as distributors of another account\u2019smessages. The occurrence of retweet accounts can serve as an indication that bots\nhave been used.\nOur analysis shows that it is more common for accounts discussing immigration\nto have other accounts distributing their messages. These accounts are more likely\nto be suspended by Twitter, one possible reason for the suspension is that they show\na bot-like behavior.\n160 J. Fernquist et al.\n7 Party Support on Twitter and the Election Results\nIn Sect. 5, we presented how bots and genuine accounts were expressing support for\nthe different parties. In Fig. 10, the expressed party support on Twitter and the actual\nelection results are shown. SD and AFS received the most support on Twitter while\nS and M got the largest share of votes in the election.\nWhen the result of the election was reported, discussions about election fraud\nstarted on Twitter. The discussions included claims that the election was rigged and\nthat the results were settled earlier and invalid. The term \u201cvalfusk\u201d (election fraud\nin Swedish) occurred almost 2500 times the day after the election, as can be seen in\nFig.11.\nThe hashtag #valfusk was used frequently during the election night. Note that\nthis hashtag was not a part of our searched hashtags or keywords and therefore all\nFig. 10 Distribution of the parties for which different accounts express support, and the actual\nelection results\nFig. 11 Occurrences of the term valfusk (election fraud)\nTwitter Bots and the Swedish Election 161\ntweets with the hashtag #valfusk are not included in this study. The \ufb01gure shows\nthe occurrences of the term valfusk in the data with the hashtags and keywords\nmentioned in Sect. 2.\nThere are several reasons for the increase of discussion about election fraud.\nOne reason might be many Twitter users were disappointed of the election results.\nAnother reason can be that the experienced support of certain parties in Twitter didnot agree with the results from the election.\n8 Discussion and Conclusions\nAmong the accounts that we analyzed, the proportion of bots was between 6 and\n12%, depending on whether we include accounts that were suspended among our\nbots or not. We can not say for sure how many of the suspended accounts that arebots, but since Twitter states that the most common reason for suspending an account\nis that the account shows bot-like behavior, we can assume that a high proportion\nof suspended accounts are bots. The number of bots that tweeted about the electionmore than doubled from July to August.\nOur analyses shows that it has been more common for a bot account to express\nsupport for the Sweden democrats (SD), compared to a genuine account. Themajority of the bots have not been a part of the cluster expressing immigration\ncriticism, but rather a part of the clusters with accounts not retweeting any other\naccounts.\nOur content analysis shows that criticism towards immigration and the negative\nconsequences with immigration is frequently discussed on Twitter in conjunction\nwith discussions about the election. However, it is important to point out that thehashtags we have used to gather our data might have been more popular to use\namong speci\ufb01c groups. This might have lead to skew in the result making the result\nin the study not a fully valid representation of the discussions about the electionoccurring on Twitter. The use of bots increased as the election date approached.\nThe party AFS, which was founded in March 2018, did succeed on Twitter where\nthey got around 25% of the party support from both bots and genuine accounts.This result is consistent with other studies that found that very active accounts with\nbot-like behavior has expressed support for the party.\nIt is important to add that it is not illegal to recruit bots to get an increased\nspread of a message. A thousand followers can be bought for around ten dollars\n5\nand retweets can be bought for twice as much.6\nThe analysis of supported parties showed that the immigration critical parties\nSD and AFS had more support on Twitter than in the actual election. After the\nelection, several discussions about election fraud occurred. The difference between\n5BuyTwitterFollowersReview\u2014 https://buytwitterfollowersreview.org/top-10/ .\n6BuySocialMediaMarketing\u2014 https://buysocialmediamarketing.com/twitter/retweets .\n162 J. Fernquist et al.\nthe election results and the expressed support on Twitter have likely contributed\nto the discussions about election fraud. Only a few days after the election, the\ndiscussions about election fraud subsided. One obvious conclusion of our study isthat in digital media certain parts of the Swedish population are more engaged. In\nthe case of Twitter, the most engaged are those who support the SD or who are\nstrong critics of S.\nOne of the questions raised by this study concerns how bots in\ufb02uence the\ndemocratic process and the political discussion before the election. This question\ncannot be answered without an understanding of how the automatic accountsanalyzed here \ufb01t into a larger picture of media use in Sweden. It would also be\nnecessary to analyze who is behind these bots and what the aims are of spreading\nmessages from bots. While answering these question is dif\ufb01cult, it is clear that theuse of bots for spreading various types of messages increased the closer we come\nto the election. This could be a sign of an attempt to in\ufb02uence public opinion or at\nleast a certain part of the political discussions.\nAn important question concerning all types of in\ufb02uence is to what extent the\nindividual who is the target of in\ufb02uence is aware of whether someone is attempting\nto exercise in\ufb02uence. The results of previous research indicate that attempts toin\ufb02uence are less effective if individuals are aware of them [ 20]. In other words,\nan awareness that someone is trying to in\ufb02uence us can, at least to some extent,\nmake us less susceptible to in\ufb02uence. Hopefully, studies like ours contributes tobetter awareness of attempts to exercise in\ufb02uence using bots.\nReferences\n1. F. Ahmed, M. Abulaish, A generic statistical approach for spam detection in online social\nnetworks. Comput. Commun. 36(10-11), 1120\u20131129 (2013)\n2. Z. Chu, S. Gianvecchio, H. Wang, S. Jajodia, Who is tweeting on twitter: human, bot, or\ncyborg? in Proceedings of the 26th annual computer security applications conference (ACM,\nNew York, 2010), pp. 21\u201330\n3. C. Colliver, P. Pmerantsev, A. Applebaum, J. Birdwell, Smearing Sweden, international\nin\ufb02uence campaigns in the 2018 Swedish election. Technical report (Institute of StrategicDialogue (ISD), London School of Economics, London, 2018)\n4. S. Cresci, R.D. Pietro, M. Petrocchi, A. Spognardi, M. Tesconi, Fame for sale: ef\ufb01cient\ndetection of fake twitter followers. CoRR, abs/1509.04098 (2015)\n5. S. Cresci, R.D. Pietro, M. Petrocchi, A. Spognardi, M. Tesconi, Dna-inspired online behavioral\nmodeling and its application to spambot detection. IEEE Intell. Syst. 31(5), 58\u201364 (2016)\n6. S. Cresci, R.D. Pietro, M. Petrocchi, A. Spognardi, M. Tesconi, The paradigm-shift of social\nspambots: evidence, theories, and tools for the arms race (2017). CoRR, abs/1701.03017\n7. C.A. Davis, O. Varol, E. Ferrara, A. Flammini, F. Menczer, Botornot: a system to evaluate\nsocial bots (2016). CoRR, abs/1602.00975\n8. P.M. DeMarzo, D. Vayanos, J. Zwiebel, Persuasion bias, social in\ufb02uence, and unidimensional\nopinions. Q. J. Econ. 118(3), 909\u2013968 (2003)\n9. R.S.J. Fernquist, L. Kaati, Political bots and the Swedish general election, in International\nConference of Security Informatics (ISI) (2018)\nTwitter Bots and the Swedish Election 163\n10. Z. Gilani, R. Farahbakhsh, G. Tyson, L. Wang, J. Crowcroft, Of bots and humans (on twitter), in\nProceedings of the 2017 IEEE/ACM International Conference on Advances in Social NetworksAnalysis and Mining 2017 , ASONAM \u201917 (ACM, New York, 2017), pp. 349\u2013354\n11. R. Gorwa, D. Guilbeault, Understanding bots for policy and research: challenges, methods, and\nsolutions (2018). CoRR, abs/1801.06863\n12. M. Grusell, Sociala medier i svenska medier\u00f6relser, in N\u00e4r makten st\u00e5r p\u00e5 spel\u2014journalistik i\nvalr\u00f6relser. Sthlm, Inst. f. mediestudier (2017)\n13. P.N. Howard, S. Woolley, R. Calo, Algorithms, bots, and political communication in the\nus 2016 election: the challenge of automated political communication for election law andadministration. J. Inform. Tech. Polit. 15(2), 81\u201393 (2018)\n14. K. Lee, B. David Eoff, J. Caverlee, Seven months with the devils: A long-term study of content\npolluters on twitter, in Fifth International AAAI Conference on Weblogs and Social Media ,v o l .\n01 (2011)\n15. E. Mannheimer, H. Ewald, S\u00e5 sprider falska konton h\u00f6gerextrema budskap inf\u00f6r eu-valet, in\nDagens nyheter (2018)\n16. Z. Miller, B. Dickinson, W. Deitrick, W. Hu, A.H. Wang, Twitter spammer detection using data\nstream clustering. Inf. Sci. 260, 64\u201373 (2014)\n17. N. Newman, R. Fletche, A. Kalogeropoulos, D.A.L. Levy, R.K. Nielsen, Reuters Institute\nDigital News Report 2018 (Reuters Institute for the Study of Journalism/University of Oxford,\nOxford, 2018)\n18. M. Singh, D. Bansal, S. Sofat, Who is who on twitter\u2013spammer, fake or compromised account?\na tool to reveal true identity in real-time. Cybern. Syst. 49(1), 1\u201325 (2018)\n19. O. Varol, E. Ferrara, C.A. Davis, F. Menczer, A. Flammini, Online human-bot interactions:\nDetection, estimation, and characterization (2017). CoRR, abs/1703.03107\n20. W. Wood, J.M. Quinn, Forewarned and forearmed? two meta-analysis syntheses of forewarn-\nings of in\ufb02uence appeals. Psychol. Bull. 1(129), 119\u2013138 (2003)\n21. C. Yang, R.C. Harkreader, G. Gu, Empirical evaluation and new design for \ufb01ghting evolving\ntwitter spammers. IEEE Trans. Inf. Forensics Secur. 8(8), 1280\u20131293 (2013)\nCognitively-Inspired Inference for\nMalware Task Identi\ufb01cation\nEric Nunes, Casey Buto, Paulo Shakarian, Christian Lebiere, Stefano Bennati,\nand Robert Thomson\nAbstract Malware reverse-engineering, speci\ufb01cally, identifying the tasks a given\npiece of malware was designed to perform (e.g., logging keystrokes, recording\nvideo, establishing remote access) is a largely human-driven process that is a\ndif\ufb01cult and time-consuming operation. In this chapter, we present an automated\nmethod to identify malware tasks using two different approaches based on the ACT-\nR cognitive architecture, a popular implementation of a uni\ufb01ed theory of cognition.\nUsing three different malware collections, we explore various evaluations for each\nof an instance-based and rule-based model\u2014including cases where the training data\ndiffers signi\ufb01cantly from test; where the malware being evaluated employs packing\nto thwart analytical techniques; and conditions with sparse training data. We \ufb01nd\nthat our approach based on cognitive inference consistently out-performs the current\nstate-of-the art software for malware task identi\ufb01cation as well as standard machine\nlearning approaches\u2014often achieving an unbiased F1 score of over 0.9.\n1 Introduction\nIdentifying the tasks a given piece of malware was designed to perform (e.g. logging\nkeystrokes, recording video, establishing remote access, etc.) is a dif\ufb01cult and time\nconsuming task that is largely human-driven in practice [ 1]. The complexity of this\ntask increases substantially when you consider that malware is constantly evolving,\nand that how each malware instance is classi\ufb01ed may be different based on each\nE. Nunes (/envelopeback) \u00b7 C. Buto \u00b7 P. Shakarian\nArizona State University, Tempe, AZ, USA\ne-mail: enunes1@asu.edu ;cbuto@asu.edu ;shak@asu.edu\nC. Lebiere \u00b7 S. Bennati\nCarnegie Mellon University, Pittsburgh, PA, USA\ne-mail: cl@cmu.edu\nR. Thomson\nUnited States Military Academy, West Point, NY, USA\ne-mail: robert.thomson@usma.edu\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_7165\n166 E. Nunes et al.\ncyber-security expert\u2019s own particular background. Automated solutions for this\nproblem are highly attractive as they can signi\ufb01cantly reduce the time it takes to\nconduct remediation in the aftermath of a cyber-attack.\nEarlier work has sought to classify malware by similar \u201cfamilies\u201d, something\nwhich has been explored as a supervised classi\ufb01cation problem [ 2\u20134]. However,\ndifferences over determining \u201cground truth\u201d for malware families (i.e. Symantec andMcAfee cluster malware into families differently) and the tendency for automated\napproaches to only succeed at \u201ceasy to classify\u201d samples [ 5,6] are two primary\ndrawbacks of malware family classi\ufb01cation. More recently, there has been work ondirectly inferring the tasks a malware was designed to perform [ 7]. This approach\nleverages static malware analysis (i.e. analysis of the malware sample conducted\nwithout execution, such as decompilation) and a comparison with a crowd-sourcedatabase of code snippets using a proprietary machine learning approach. However,\na key shortcoming of the static method is that it is of limited value when the malware\nauthors encrypt part of their code\u2014as we saw with the infamous Gauss malware [ 8].\nThis work builds upon recent developments in the application of cognitive models to\nintelligence analysis tasks [ 9] and our own preliminary studies on applying cognitive\nmodels to identify the tasks a piece of malware was designed to perform [ 10,11].\nSpeci\ufb01cally, in this chapter, we report\n\u2013 Experimental results illustrating consistent and signi\ufb01cant performance improve-\nments (in terms of precision, recall, and F1) of the instance-based cogni-\ntive model approach when compared with various standard machine learning\napproaches (including SVM, logistic regression and random forests) for twodifferent sandboxes and for three different datasets.\n\u2013 Experimental results showing a consistent and signi\ufb01cant performance improve-\nment of the instance-based cognitive model and several other machine learningapproaches when compared to the current state-of-the-art commercial technol-\nogy (based on static analysis).\n\u2013 Experiments where we study cases where the malware samples are mutated,\nencrypted, and use different carriers\u2014providing key insights into how our\napproach will cope with operational dif\ufb01culties.\n\u2013 Experimental results illustrating that a cognitively-inspired intermediate step\nof inferring probability distribution over malware families provides improved\nperformance over the machine learning and rule-based cognitive model (though\nno signi\ufb01cant change to the instance-based cognitive model).\nCognitive models have proved to signi\ufb01cantly outperform classical machine\nlearning approaches and state of the art products available in the market for\nmalware task prediction [ 10\u201312]. This chapter consolidates the results presented\nin previous research by including additional results for the GVDG dataset, run-\ntime comparisons of the experiments and discussing the cognitive models in\nterms of parameter selection and time complexity analyses. We also provide newexperimental results utilizing a dataset based on the MetaSploit framework [ 13]\u2014\ndemonstrating how our framework adapts to features based on malware that utilizes\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 167\nthe network protocol stack. We also explore the concept of predicting hacker\nintentions on a host machine.\nThis chapter is organized as follows. In Sect. 2we state the technical preliminar-\nies used in the chapter. In Sect. 3.1we introduce our cognitive-based approaches,\ndescribing the algorithms and explaining our selection of parameter settings. This\nis followed by a description of the baseline approaches that we studied in ourevaluation in Sect. 4.1and a description of the two different dynamic malware\nsandbox environments we used in Sect. 4.2. In Sect. 5we present our suite of\nexperimental results which include experiments involving samples discovered byMandiant, Inc. in their APT1 report [ 14], samples created using the GVDG [ 15]\ntool, and samples created using the MetaSploit framework. Finally, related work is\ndiscussed in Sect. 6.\n2 Technical Preliminaries\nThroughout this chapter, we shall assume that we have a set of malware samples\nthat comprise a historical corpus (which we shall denote M) and each sample\ni\u2208Mis associated with a set of tasks (denoted tasks(i)) and a set of attributes\n(denoted attribs (i)). Attributes are essentially binary features associated with a\npiece of malware that we can observe using dynamic and/or static analysis while the\ntasks\u2014which tell us the higher-level purpose of the malware\u2014must be determined\nby a human reviewing the results of such analysis. As Mcomprises our historical\nknowledge, we assume that for each i\u2208Mboth tasks(i)andattribs (i)are known.\nFor a new piece of malware, we assume that we only know the attributes. We also\nnote that throughout the chapter, we will use the notation |\u00b7|to denote the size of a\ngiven set. Tables 1and2provide examples of the attributes and tasks based on the\nmalware samples from the Mandiant APT1 dataset (created from samples available\nat [16], see also [ 14]). For instance, hasDynAttrib looks at the behavior section of\nthe analysis report and extracts all the activity of the malware on the host machine.\nThe attribute usesDll enumerates all the libraries that were used by the malware on\nthe host machine. The \ufb01le activity and the registry activity is captured by \ufb01leAct\nandregAct . Finally all the processes initiated and terminated by the malware are\ncaptured by proAct . There is not a \ufb01xed number of any of these attributes for a\nTable 1 Attributes extracted through automated malware analysis\nAttribute Intuition\nusesDll( X) Malware uses a library X\nregAct( K) Malware conducts an activity in the registry, modifying key K.\n\ufb01leAct( X) Malware conducts an activity on certain \ufb01le X\nproAct Malware initiates or terminates a process\n168 E. Nunes et al.\nTable 2 Sample of malware tasks\nTask Intuition\nbeacon Beacons back to the adversary\u2019s system\nenumFiles Designed to enumerate \ufb01les on the target\nserviceManip Manipulates services running on the target\ntakeScreenShots Takes screen shots\nupload Designed to upload \ufb01les from the target\ngiven malware. The number of attributes depends on the analysis report generated\nfrom the sandbox. A full description of this dataset is presented in Sect. 5.\nThroughout the chapter, we will also often consider malware families, using the\nsymbolFto denote the set of all families. Each malware sample will belong to\nexactly one malware family, and all malware samples belonging to a given family\nwill have the same set of tasks. Hence, we shall also treat each element of Fas a\nsubset of M.\n3 Cognitively-Inspired Inference\nWhile human inference has memory and attentional limitations, their cognitive pro-\ncesses are powerful, where adaptive heuristic strategies are adopted to accomplish\nthe tasks under strong time constraints using limited means. An advantage of using\na cognitive model to describe inferential processes is that the underling architectureprovides the bene\ufb01ts of human-inspired inference while allowing for more \ufb02exibility\nover constraints such as human working memory. We believe that there is a valid use\nof cognitive architectures for arti\ufb01cial intelligence that makes use of basic cognitivemechanisms while not necessarily making use of all constraints of the architecture.\nIn that case, it is arguably better to speci\ufb01cally state which aspects of the model\nare not constrained by data, and rather than mock up those aspects in plausiblebut impossible to validate manner, simply treat them as unmodeled processes. This\napproach results in simpler models with a clear link between mechanisms used\nand results accounted for, rather than being obscured by complex but irrelevantmachinery. For instance, while the models described in this chapter use activation\ndynamics well-justi\ufb01ed against human behavioral and neural data to account for\nfeatures such as temporal discounting, we do not directly model working memoryconstraints to allow for more features of malware and more instances to be present\nin memory.\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 169\n3.1 ACT-R Based Approaches\nWe propose two models built using the mechanisms of the ACT-R (Adaptive Control\nof Thought-Rational) cognitive architecture [ 17]. These models leverage the work\non applying this architecture to intelligence analysis problems [ 9]. In particular,\nwe look to leverage our recently-introduced instance-based (ACTR-IB) and rule-based (ACTR-R) models [ 10,11]. Previous research has argued the ability of\ninstance-based learning in complex dynamic situations making it appropriate for\nsensemaking [ 18]. On the other hand, the rule-based learning is a more compact\nrepresentation of associating samples in memory with their respective families. In\nthis section, we review some of the major concepts of the ACT-R framework that\nare relevant to these models and provide a description of both approaches.\nWe leveraged features of the declarative memory and production system of the\nACT-R architecture to complete malware task identi\ufb01cation. In ACT-R, recall from\ndeclarative memory (c.f., identi\ufb01cation, for our purposes) depends on three maincomponents: activation strengthening (i.e., the base-level activation of an element),\nassociative (i.e., spreading) activation, and inter-element similarity (i.e., partial\nmatching). These three values are summed together to represent an item\u2019s totalactivation. When a recall is requested from memory, the item with the highest total\nactivation is retrieved.\nDeclarative Knowledge Declarative knowledge is represented formally in terms\nofchunks . Chunks have an explicit type, and consist of an ordered list of slot-value\npairs of information. Chunks are retrieved from declarative memory by an activation\nprocess, and chunks are each associated with an activation strength which in turn\nis used to compute a retrieval probability . In this chapter, chunks will typically\ncorrespond to a malware family. In the version of ACTR-IB where we do not\nrepresent families explicitly, the chunks correspond with samples in the trainingdata.\nFor a given chunk i, the activation strength A\niis computed as,\nAi=Bi+Si+Pi (1)\nwhere, Biis the base-level activation, Siis the spreading activation, and Piis the\npartial matching score. We describe each of these in more detail as follows.\nBase-Level Activation ( Bi)Technically, base-level for chunk ire\ufb02ects both the\nfrequency and recency of samples in memory, even though we are not using recency\nhere but it could easily be applicable to weigh samples toward the more recent ones.More important, base-level is set to the logof the prior probability (i.e., the fraction\nof samples associated with the chunk) in ACTR-R; for instance-based (ACTR-IB),\nwe set it to a base level constant \u03b2\ni.\nSpreading Activation ( Si)Spreading activation is a measure of the uniqueness of\nthe attributes between a test sample iand a sample jin memory. The spread of\n170 E. Nunes et al.\nactivation to sample iis computed by the summing the strengths of association\nbetween sample jand the attributes of the current sample ibeing considered.\nTo compute the spreading activation we compute the fanof attribute a (i.e., the\nnumber of samples in memory with attribute a) for each attribute. The strength of\nassociation is computed differently in both approaches and, in some cognitive model\nimplementations, is weighted (as is done in ACTR-R of this chapter).\nPartial Matching ( Pi)A partial matching mechanism computes the similarity\nbetween two samples. In this work, it is only relevant to the instance-basedapproach. Given a test sample j, its similarity with a sample iin memory is\ncomputed as a product of the mismatch penalty ( mp, a parameter of the system)\nand the degree of mismatch M\nji. We de\ufb01ne the value of Mjito be between 0 and\n\u22121; 0 indicates complete match while \u22121 complete mismatch.\nAs common with models based on the ACT-R framework, we shall discard\nchunks whose activation strength is below a certain threshold (denoted \u03c4). Once\nthe activation strength, Ai, is computed for a given chunk, we can then calculate the\nactivation probability, pi. This is the probability that the cognitive model will recall\nthat chunk and is computed using the Boltzmann (softmax) equation [ 19], which we\nprovide below.\nPri=(eAi\ns)\n/summationtext\nj(eAj\ns)(2)\nHere, eis the base of the natural logarithm and sis momentary noise inducing\nstochasticity by simulating background neural activation (this is also a parameter of\nthe system).\n3.2 ACT-R Instance-Based Model\nThe instance based model is an iterative learning method that re\ufb02ects the cognitiveprocess of accumulating experiences (in this case the knowledge base of training\nsamples) and using them to predict the tasks for unseen test samples. Each malware\ninstance associates a set of attributes of that malware with its family. When a newmalware sample is encountered, the activation strength of that sample with each\nsample in memory is computed using Eq. 1. The spreading activation is a measure\nof the uniqueness of the attributes between a test sample iand a sample jin memory.\nTo compute the spreading activation we compute the fan for each attribute a\n(fan ( a) \ufb01nds all instances in memory with the attribute a) of the test sample i.\nThe Partial matching is computed as explained above. The degree of mismatch iscomputed as the intersection between the attribute vector of the given malware and\neach sample in memory normalized using the Euclidean distance between the two\nvectors. The retrieval probability of each sample jin memory with respect to the\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 171\ntest sample iis then computed using Eq. 2. This generates a probability distribution\nover families. The tasks are then determined by summing up the probability of the\nfamilies associated with that task with an appropriately set threshold (we set thatthreshold at 0 .5 (indicates that the model should be more than 50% con\ufb01dent before\na task is predicted for a test malware sample)). Algorithm 1shows the pseudo code\nfor the instance-based model.\nAlgorithm 1: ACT-R instance-based learning\nINPUT: New malware sample i, historical malware corpus M.\nOUTPUT: Set of tasks associated with sample i.\nforquery malware sample ido\nfor all jinMdo\nBj=\u03b2j\nPj=mp\u00d7|attribs (i)\u2229attribs (j)|\u221a|attribs (i)|\u00d7|attribs (j)|\nfora\u2208attribs (i)do\nifa\u2208attribs (j)then\nsij+=log(|M|\n|f an(a)|)\nelse\nsij+=log(1\n|M|)\nend if\nend forS\nj=/summationtext\njsij\n|attribs (i)|\nCalculate Ajas per Equation 1\nend for\nCalculate pjas per Equation 2\npf=/summationtext\nj\u2208fs.t.Aj\u2265\u03c4pj\ntp={t\u2208T|pf\u22650.5}\nend for\nTime Complexity of Instance-Based Model The Instance based model has no\nexplicit training phase, so there are no training costs associated with it. For a given\ntest sample the model computes the activation function for each sample in the\nknowledge base. Hence the time complexity increases linearly with the knowledgebase. Let nbe the number of the samples in the knowledge base and mis the number\nof attributes associated with the test sample, then the time complexity can be given\nasO(nm) for each test sample, as we expect mto be relative small ( n> >m ), the\nrelationship is linear in n.\n3.3 ACT-R Rule-Based Model\nIn this version of ACT-R model we classify the samples based on simple rules\ncomputed during the training phase. Given a malware training sample with its set\nof attributes a, along with the ground truth family value, we compute a pair of\n172 E. Nunes et al.\nconditional probabilities p(a|f)andp(a|\u00acf)for an attribute in a piece of malware\nbelonging (or not belonging) to family f. These probabilistic rules (conditional\nprobabilities) are used to set the strength of association of the attribute with a family(s\na,f). The strength of association is weighted by the source activation wto avoid\nretrieval failures for rule-based models. We use empirically determined Bayesian\npriors p(f) to set the base-level of each family as opposed to using a constant\nbase-level for instance based. Only two components of the activation Equation 1are\nused, namely the base-level and the spreading activation. Given the attributes for\ncurrent malware, we calculate the probability of the sample belonging to each familyaccording to Eq. 2, generating a probability distribution over families. The task are\nthen determined in a similar way to that of instance-based model. Algorithm 2shows\nthe pseudo code for the rule-based model.\nAlgorithm 2: ACT-R rule-based learning\nINPUT: New malware sample i, historical malware corpus M.\nOUTPUT: Set of tasks associated with new sample i.\nTRAINING:LetX=/uniontext\nj\u2208Mattrib(j)\nfor all ainXdo\nCompute the set of rules p(a|f)andp(a|\u00acf)\n(where p(a|f)=|{i\u2208M\u2229f|a\u2208attrib(i) }|\n|f|\nandp(a|\u00acf)=|{i\u2208M\u2212f|a\u2208attrib(i) }|\n|M|\u2212|f|)\nend for\nTESTING:for all f\u2208\nFdo\nBf=log(p(f)) (where p(f)=|f|\n|M|)\nfor all a\u2208attrib(i) do\nsa,f=log(p(a|f)\np(a|\u00acf));Sf=+w\u00d7sa,f\n|attribs (i)|\nend for\nAf=Bf+Sf\nend for\nCalculate pfas per Equation 2\ntp={t\u2208T|pf\u22650.5}\nTime Complexity of Rule-Based Model For Rule-based model computing the\nrules for each attribute in the knowledge base signi\ufb01cantly add to the com-\nputation time. Let nbe the number of samples in the training set, mbe the\nnumber of attributes in the new piece of malware, and m\u2217be the cardinality of/uniontext\nj\u2208Mattrib(j) . The resulting time complexity for training is then O(m\u2217n)for\ntraining, which is signi\ufb01cant as we observed m\u2217>> m in our study. While\nthis is expensive, we note that for testing an individual malware sample, the time\ncomplexity is less than the testing phase for the instance based O(|F|m)\u2014though\nthe instance based model requires no explicit training phase (which dominates thetime complexity of the training phase for the rule-based approach).\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 173\nTable 3 Parameters for the cognitive models\nModel Parameters\nInstance based learning \u03b2= 20 (base-level constant)\ns=0.1 (stochastic noise parameter)\n\u03c4=\u221210 (activation threshold)\nmp=20 (mismatch penalty)\nRule based learning s=0.1 (stochastic noise parameter)\nw=16 (source activation)\n3.4 Model Parameter Settings\nThe two proposed models leverage separate components of the activation function.\nTable 3provides a list of parameters used for both the ACT-R models\u2014we use\nstandard ACT-R parameters that have been estimated from a wide range of previousACT-R modeling studies from other domains [ 20] and which are also suggested in\nthe ACT-R reference manual [ 21].\nThe intuition behind these parameters is as follows. The parameter sinjects\nstochastic noise in the model. It is used to compute the variance of the noise\ndistribution and to compute the retrieval probability of each sample in memory.\nThe mismatch penalty parameter mpis an architectural parameter that is constant\nacross samples, but it multiplies the similarity between the test sample and the\nsamples in knowledge base. Thus, with a large value it penalizes the mismatch\nsamples more. It typically trades off against the value of the noise sin a signal-\nto-noise ratio manner: larger values of mplead to more consistent retrieval of the\nclosest matching sample whereas larger values of sleads to more common retrieval\nof poorer matching samples.The activation threshold \u03c4determines which samples\nwill be retrieved from memory to make task prediction decisions. The base level\nconstant \u03b2is used to avoid retrieval failures which might be caused due to high\nactivation threshold. The source activation wis assigned to each retrieval to avoid\nretrieval failures for rule-based models.\n4 Experimental Setup\n4.1 Baseline Approaches\nWe compare the proposed cognitive models against a variety of baseline\napproaches\u2014one commercial package and \ufb01ve standard machine learning\ntechniques. For the machine learning techniques, we generate a probabilitydistribution over families and return the set of tasks associated with a probability\nof 0.5 or greater while the commercial software was used as intended by the\n174 E. Nunes et al.\nmanufacturer. Parameters for all baseline approaches were set in a manner to\nprovide the best performance.\nCommercial Offering: Invencia Cynomix Cynomix is a malware analysis tool\nmade available to researchers by Invencia industries [ 7] originally developed under\nDARPA\u2019s Cyber Genome project. It represents the current state-of-the-art in the \ufb01eldof malware capability detection. Cynomix conducts static analysis of the malware\nsample and uses a proprietary algorithm to compare it to crowd-sourced identi\ufb01ed\nmalware components where the functionality is known.\nDecision Tree (DT) Decision tree is a hierarchical recursive partitioning algorithm.\nWe build the decision tree by \ufb01nding the best split attribute i.e. the attribute that\nmaximizes the information gain at each split of a node. In order to avoid over-\ufb01tting,the terminating criteria was set to less than 5% of total samples. Malware samples\nare tested by the presence and absence of the best split attribute at each level in\nthe tree till it reaches the leaf node. When it reaches the leaf node the probabilitydistribution at the leaf node is assigned to the malware sample.\nNaive Bayes Classi\ufb01er (NB) Naive Bayes is a probabilistic classi\ufb01er which uses\nBayes theorem with independent attribute assumption. During training we compute\nthe conditional probabilities of a given attribute belonging to a particular family. We\nalso compute the prior probabilities for each family; i.e., fraction of the training databelonging to each family. Naive Bayes assumes that the attributes are statistically\nindependent hence the likelihood for a sample Srepresented with a set of attributes\naassociated with a family fis given as, p(f|S)=P(f)\u00d7/producttext\nd\ni=1p(ai|f).\nRandom Forest (RF) Ensemble methods are popular classi\ufb01cation tools. They are\nbased on the idea of generating multiple predictors used in combination to classify\nnew unseen samples. We use a random forest which combines bagging for eachtree with random feature selection at each node to split the data, thus generating\nmultiple decision tree classi\ufb01ers [ 22]. Each decision tree gives its own opinion on\ntest sample classi\ufb01cation which is then merged to generate a probability distributionover families. For all the experiments we set the number of trees to be 100, which\ngives us the best performance.\nSupport Vector Machine (SVM) Support vector machines (SVM) are proposed\nby Vapnik [ 23]. SVMs work by \ufb01nding a separating margin that maximizes the\ngeometric distance between classes. The separating margin is termed as hyperplane.We use the popular LibSVM implementation [ 24] which is publicly available. The\nimplementation has the option of returning the probability distribution as opposed\nto the maximum probability prediction.\nLogistic Regression (LOG-REG) Logistic regression classi\ufb01es samples by com-\nputing the odds ratio. The odds ratio gives the strength of association between\nthe attributes and the family like simple rules used in the ACT-R rule basedlearning. We implement the multinomial logistic regression which handles multi-\nclass classi\ufb01cation.\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 175\n4.2 Dynamic Malware Analysis\nDynamic analysis studies a malicious program as it executes on the host machine. It\nuses tools like debuggers, function call tracers, machine emulators, logic analyzers,\nand network sniffers to capture the behavior of the program. We use two publicly\navailable malware analysis tools to generate attributes for each malware sample.These tools make use of a sandbox, which is a controlled environment to run\nmalicious software.\nAnubis Sandbox Anubis [ 25] is an online sandbox which generates an XML\nformatted report for a malware execution in a remote environment. It generates\ndetailed static analysis of the malware but provides less details regarding the\nbehavior of the malware on the host machine. Since it is hosted remotely we cannotmodify its settings.\nCuckoo Sandbox Cuckoo [ 26] is a standalone sandbox implemented using a\ndedicated virtual machine and more importantly can be customized to suit our\nneeds. It generates detailed reports for both static as well as behavior analyses by\nwatching and logging the malware while its running on the virtual machine. Thesebehavior analyses prove to be unique indicators (behavior patterns common to a\nsingle family) for a given malware for the experiments.\n4.3 Performance Evaluation\nIn our tests, we evaluate performance based primarily on four metrics: precision,\nrecall, unbiased F1, and family prediction accuracy. For a given malware samplebeing tested, precision is the fraction of tasks the algorithm associated with the\nmalware that were actual tasks in the ground truth. Recall, for a piece of malware,\nis the fraction of ground truth tasks identi\ufb01ed by the algorithm. The unbiased F1 isthe harmonic mean of precision and recall. In our results, we report the averages for\nprecision, recall, and unbiased F1 for the number of trials performed. Our measure\nof family accuracy\u2014the fraction of trials where the most probable family was theground truth family of the malware in question\u2014is meant to give some insight into\nhow the algorithm performs in the intermediate steps.\n5 Results\nAll experiments were run on Intel core-i7 operating at 3.2 GHz with 16 GB RAM.Only one core was used for experiments. Except where explicitly noted, the ACT-R\nparameters were \ufb01xed as per Table 3for all experiments (across all datasets and\nsandboxes).\n176 E. Nunes et al.\n5.1 Mandiant Dataset\nOur \ufb01rst set of experiments uses a dataset based on the T1 cyber espionage group as\nidenti\ufb01ed in the popular report by Mandiant Inc [ 14]. This dataset consisted of 132\nreal malware samples associated with the Mandiant report that were obtained from\nthe Contagio security professional website [ 16]. Each malware sample belonged to\none of 15 families including BISCUIT, NEWSREELS, GREENCAT and COOK-\nIEBAG. Based on the malware family description [ 14], we associated a set of\ntasks with each malware family (that each malware in that family was designed toperform). In total, 30 malware tasks were identi\ufb01ed for the given malware samples\n(Table 2). On average, each family performed nine tasks.\nWe compared the four machine learning approaches with the rule-based and\ninstance-based ACT-R models (ACTR-R and ACTR-IB respectively). We also\nsubmitted the samples to the Cynomix tool for automatic detection of capabilities.\nThese detected capabilities were then manually mapped to the tasks from theMandiant report. Precision and recall values were computed for the inferred\nadversarial tasks. On average the machine learning approaches predicted nine tasks\nper sample, ACTR-R predicted nine tasks per sample and ACTR-IB predicted tentasks. On the other hand, Cynomix was able to detect on average only four tasks.\nLeave One Out Cross-Validation (LOOCV)\nIn leave one out cross validation, for nmalware samples, train on n\u22121 samples\nand test on the remaining one. This procedure was repeated for all samples and\nthe results were averaged. We performed this experiment using both sandboxes and\ncompared the results (Table 4).\nThe average F1 increases by 0.03 when we use the attributes generated by the\nCuckoo sandbox instead of Anubis. The statistical signi\ufb01cance results are as fol-\nlows: for ACTR-IB (t (132) = 1.94, p= 0.05), ACTR-R (t (132) = 1.39, p= 0.16), RF\n(t (132) = 0.56, p= 0.57), SVM (t (132) = 1.95, p= 0.05), LOG-REG (t (132) = 1.82,\np= 0.07), NB (t (132) = 1.79, p= 0.08) and DT (t (132) = 0.83, p= 0.4). But the sig-\nni\ufb01cant improvement was in the family prediction values with ACTR-IB improvingby 0.12 from 0.81 to 0.93 (t (132) = 3.86, p<0.001) and ACTR-R by 0.15 from\nTable 4 Performance comparison of Anubis and Cuckoo Sandbox (Bold values indicates best\nperformance)\nMethod Anubis (F1) Cuckoo (F1) Anubis (Family) Cuckoo (Family)\nDT 0.80 0.80 0.59 0.63\nNB 0.71 0.74 0.30 0.40\nLOG-REG 0.82 0.85 0.65 0.84\nSVM 0.86 0.90 0.85 0.86\nRF 0.89 0.89 0.82 0.86\nACTR-R 0.85 0.88 0.73 0.89\nACTR-IB 0.93 0.96 0.81 0.93\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 177\n0.50.60.70.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB INVINCEA\nFig. 1 Average precision, recall, F1 and family prediction comparisons using cuckoo sandbox for\nLOG-REG, RF, SVM, ACTR-R, ACTR-IB and INVINCEA\n0.72 to 0.87 (t (132) = 3.78, p<0.001) outperforming all other methods. Since\nhaving behavior analysis helps in better task prediction as seen from the comparisonexperiment, we use cuckoo sandbox for rest of our experiments.\nFigure 1compares the performance of the \ufb01ve best performing methods from\nTable 1and compares it with the Cynomix tool of Invincea industries. ACTR-\nIB outperformed LOG-REG, SVM, RF and ACTR-R; average F1 = 0.97 vs 0.85\n(t (132) = 7.85, p<0.001), 0.9 (t (132) = 4.7, p<0.001), 0.89 (t (132) = 5.45,\np<0.001) and 0.88 (t (132) = 5.2, p<0.001) respectively. Both the proposed\ncognitive models and machine learning techniques signi\ufb01cantly outperformed the\nCynomix tool in detecting the capabilities (tasks).\nThese three approaches (LOG-REG, SVM, RF) were also evaluated with respect\nto predicting the correct family (before the tasks were determined). ACTR-IB out-\nperformed LOG-REG, SVM, RF and ACTR-R; average family prediction = 0.93 vs\n0.84 (t (132) = 3.22, p<0.001), 0.86 (t (132) = 3.13, p<0.001), 0.86 (t (132) = 3.13,\np<0.001) and 0.89 (t (132) = 2.13, p= 0.03) respectively. The Cynomix tool from\nInvincea does not have the capability to predict families.\nTask Prediction Without Inferring Families\nIn the proposed models we infer the malware family \ufb01rst and then predict the tasks\nassociated with that family. However, differences over \u201cground truth\u201d for malwarefamilies in the cyber-security community calls for a direct inference of tasks without\ndependence on family prediction. In this section we adapt the models to predict tasks\ndirectly without inferring the family.\nFigure 2shows the performance of the cognitive and machine learning models\nwithout inferring the families. There is no difference in the performance of ACTR-\nIB and ACTR-R approaches as compared to Fig. 2where we use families. On the\nother hand, direct task prediction reduces the F1 measure of machine learning\ntechniques on average by almost 0.1. This is due to the fact that, now instead\n178 E. Nunes et al.\n0.70.80.91\nPrecision Recall F1egarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 2 Average precision, recall, and F1 comparisons for LOG-REG, RF, SVM, ACTR-R and\nACTR-IB for Mandiant without inferring families\n050100150200\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9)ces(emitgniniarT\nLOG-REG SVM RF ACTR-R050100150200\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9)ces(emitgniniarT\nLOG-REG SVM RF ACTR-R\nFig. 3 Training time for LOG-REG, SVM, RF and ACTR-R with(left)/without(right) inferring\nfamilies\nof having a single classi\ufb01er for each family we have multiple classi\ufb01ers for each\ntask that a malware sample is designed to perform. This not only degrades the\nperformance but also adds to the training time for these methods (including the\nACT-R rule-based approach). We compare the training time with increase in trainingdata for task prediction with/without inferring families. Inferring families \ufb01rst\nreduces the training time (Fig. 3(left)). On the other hand, predicting tasks directly\nsigni\ufb01cantly increases the training time for the machine learning methods alongwith the rule-based ACT-R approach (Fig. 3(right)). Due to the issues with respect\nto performance and training time, we consider inferring families \ufb01rst for the rest of\nthe experiments. An important point to note is that this has no effect on the Instance-based model for both performance and computation time.\nParameter Exploration\nWe now discuss two system parameters that control the performance of the ACT-R\ninstance based model namely the stochastic noise parameter ( s) and the activation\nthreshold ( \u03c4). We use the mandiant dataset to perform this evaluation. The parameter\nstakes values between 0.1 and 1 (typical values range from 0.1 to 0.3). The value\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 179\n0.70.750.80.850.90.951\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1eulaV\nNoise Parameter (s)\nFamily Prediction F1\n(a)0.70.750.80.850.90.951\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1eulaV\nNoise Parameter (s)\nFamily Prediction F1\n(b)\n0.70.750.80.850.90.951\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1eulaV\nNoise Parameter (s)\nFamily Prediction F1\n(c)0.70.750.80.850.90.951\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1eulaV\nNoise Parameter (s)\nFamily Prediction F1\n(d)\n0.70.750.80.850.90.951\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1eulaV\nNoise Parameter (s)\nFamily Prediction F1\n(e)0.70.750.80.850.90.951\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1eulaV\nNoise Parameter (s)\nFamily Prediction F1\n(f)\nFig. 4 Family prediction and F1 value for different threshold and noise parameters values. ( a)\n\u03c4=\u221220. (b)\u03c4=\u221210. (c)\u03c4=0. (d)\u03c4=5. (e)\u03c4=10. (f)\u03c4=15\nof the activation threshold depends on the application. Figure 4shows the variation\nof family prediction accuracy and F1 score with respect to different noise parameter\nvalues and for different activation thresholds. The parameter sis used to compute\nthe variance of the noise distribution and retrieval probability of sample in memory.\nLarger value of striggers the retrieval of poor matching samples, which leads to\nlower family prediction and F1 scores. As seen in Fig. 4,a st h ev a l u eo f sincreases\nthe performance decreases. On the other hand, the activation threshold dictates how\nmany closely matched samples will be retrieved from memory. For high values of\n\u03c4the performance decreases as many fewer samples are retrieved. For lower values\nof\u03c4we end up retrieving almost all the samples in the training data, hence the\nperformance does not decrease as \u03c4decreases, but it adds to the computational\ncost of retrieving high number of samples which is not desirable. We get the best\n180 E. Nunes et al.\nperformance for \u03c4=\u2212 10 and s=0.1. Even s=0.2 is almost as good as 0.1\nproviding some advantages in terms of stochasticity ensuring robustness.\nWe keep the base-level constant ( \u03b2) and mismatch penalty ( mp) values constant.\nAs explained earlier the base-level constant trades off directly against the retrieval\nthreshold, and the mismatch penalty against the activation noise, respectively, so it\nmakes sense to vary only one of the pair.\n5.2 GVDG Dataset\nGVDG is a malware generation tool designed for the study of computer threats [ 15].\nIt is capable of generating the following malware threats:\n\u2013 File-virus\n\u2013 Key-Logger\u2013 Trojan-Extortionist\n\u2013 USB-Worm\n\u2013 Web Money-Trojan\nFigure 5shows the GVDG user interface used for the generation of malware\nsamples. We can select the carrier type and the tasks that we want the malwaresample to perform on the host machine. The tasks are represented as payloads, while\ncarrier is a functional template which can be modi\ufb01ed to execute the tasks desired\nby the user on the host system. In generating datasets with GVDG, we specify\nFig. 5 GVDG user interface\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 181\nfamilies based on sets of malware with the same tasks. Whether or not a family\nconsists of malware with the same carrier depends on the experiment. Further,\nGVDG also has an option to increase \u201cmutation\u201d or variance among the samples.We perform experiments analyzing the performance of the proposed methods when\nthe generated samples belong to different carrier and same carrier types, as well as\nwhen the samples are encrypted and mutated making task prediction dif\ufb01cult. In allthe experiments we consider 60% of the data for training and 40% for testing. The\nresults are averaged across ten trials. The Cynomix tool from Invencia was unable\nto detect any tasks for the GVDG dataset, primarily due to its inability to \ufb01nd publicsource documents referencing GVDG samples and also unable to generalize from\nsimilar samples.\nDifferent Carriers\nIn this experiment, we generated 1000 samples for each carrier type with low\nmutation. On average each carrier type performs seven tasks (payloads). Henceeach carrier represents one family for this experiment. Both random forest and\nACTR-IB model were able to predict the tasks and family with F1 measure of 1.0\noutperforming LOG-REG 1 vs 0.91, SVM 1 vs 0.95 and ACTR-R 1 vs 0.95. Allresults are statistical signi\ufb01cant with (t (1998) \u22658.93, p<0.001) (Fig. 6). Also for\nfamily prediction ACTR-IB and RF outperformed LOG-REG 1 vs 0.92, SVM 1 vs\n0.92 and ACTR-R 1 vs 0.95 (t (1998) \u22658.93, p<0.001).\nThese results are not surprising given that different carrier(family) types have\nhigh dissimilarity between them. Also, samples belonging to the same carrier have\non average 60% of similar attributes. Figure 7shows the similarity between the\ncarrier types. The similarity between families is calculated in the same way as\nACTR-IB partial matching with 0 indicating complete match while \u22121 complete\nmismatch.\n0.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 6 Average precision, recall, F1 and family prediction comparisons for LOG-REG, SVM, RF,\nACTR-R and ACTR-IB for different carrier samples\n182 E. Nunes et al.\nFig. 7 Similarity matrix for \ufb01ve different carriers\nDifferent Carriers-Mutation\nFor this case, we generate the same samples as in the previous experiment but with\nmaximum mutation between samples belonging to the same carrier. We generated\n1000 samples for each carrier with maximum mutation. In this case ACTR-IB had\nan average F1 of 1 outperforming LOG-REG 1 vs 0.83, SVM 1 vs 0.88, RF 1 vs 0.96\nand ACTR-R 1 vs 0.92 (t (1998) \u22657,p<0.001) (Fig. 8). Also for family prediction\nACTR-IB outperformed LOG-REG 1 vs 0.85, SVM 1 vs 0.88, RF 1 vs 0.95 and\nACTR-R 1 vs 0.92 (t (1998) \u22657,p<0.001).\nHigh mutation induces high variance between samples associated with the same\ncarrier making the classi\ufb01cation task dif\ufb01cult. High mutation samples belonging\nto same carrier have only 20% of common attributes as compared to 60% for low\nmutation.\nLess Training Data\nIn order to see how the cognitive models perform with less training data, we repeated\nthe different-carrier mutation experiment with 10% of the training data selected\nuniformly at random (300 samples). Even with less training data ACTR-IB had\nan average F1 of 0.93 outperforming LOG-REG 0.93 vs 0.71, SVM 0.93 vs 0.6, RF\n0.93 vs 0.83 and ACTR-R 0.93 vs 0.88 (t (1998) \u22652.89, p\u22640.001) (Fig. 9). Also for\nfamily prediction ACTR-IB outperformed LOG-REG 0.91 vs 0.73 (t (1998) = 19.3,\np<0.001), SVM 0.91 vs 0.58, RF 0.91 vs 0.79 and ACTR-R 0.91 vs 0.88 (t\n(1998) \u22652.05, p\u22640.04).\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 183\n0.70.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 8 Average precision, recall, F1 and family prediction comparisons for LOG-REG, SVM, RF,\nACTR-R and ACTR-IB for different carrier mutated samples\n0.40.60.81\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 9 Average precision, recall, F1 and family prediction comparisons for LOG-REG, SVM, RF,\nACTR-R and ACTR-IB for less training data\nDifferent Carriers: Low-High Mutation\nFor this case, we consider the low mutation samples as training data and the high\nmutation samples as testing. Figure 10shows the comparison results. ACTR-IB had\nan average F1 of 0.96 outperforming LOG-REG 0.96 vs 0.83, SVM 0.96 vs 0.92,\nRF 0.96 vs 0.93 and ACTR-R 0.96 vs 0.88 (t (2498) \u226515.7, p<0.001) (Fig. 10).\nAlso for family prediction ACTR-IB outperformed LOG-REG 0.96 vs 0.81, SVM0.96 vs 0.92, RF 0.96 vs 0.94 and ACTR-R 0.96 vs 0.88 (t (2498) \u22657,p<0.001).\nLeave One Carrier Out Cross-Validation\nTo see how the models generalize to unseen malware family(carrier), we performed\na leave-one-carrier-out comparison, where we test the models against one previously\nunseen malware carrier. ACTR-IB performs better or on par with all other baseline\n184 E. Nunes et al.\n0.70.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 10 Average precision, recall, F1 and family prediction comparisons for LOG-REG, SVM,\nRF, ACTR-R and ACTR-IB for low-high mutated samples\n0.10.20.30.40.5\nFile-virus Key-logger Trojan-E USB-worm Web-TF1\n0.10.20.30.40.5\nPrecision Recall F1egarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 11 Average F1 values for \ufb01ve malware carriers (above) and the average precision, recall and\nF1 across all carriers (below) for LOG-REG, SVM, RF, ACTR-R and ACTR-IB for leave-one-carrier-out\napproaches for all the carriers. It clearly outperforms all the approaches in recalling\nmost of the actual tasks (40%) (Fig. 11). ACTR-IB has shown to generalize for\nunseen malware families [ 10]. This case is dif\ufb01cult given the fact that the test family\nis not represented during training, hence task prediction depends on associating the\ntest family with the training families that perform similar tasks.\nSame Carrier\nAs seen in the previous experiments, different carrier types makes the task easier\nbecause of less similarity between them. We now test the performance, on samecarrier type performing exactly one task. Since there are 17 tasks in the GVDG\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 185\n0.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 12 Average precision, recall, F1 and family prediction comparisons for LOG-REG, SVM,\nRF, ACTR-R and ACTR-IB for unencrypted same carrier samples\ntool, we generate 100 samples for each task for carrier type File-virus. In this\nexperiment each task represents one family. Thus in total we have 1700 samples.\nWe do the 60\u201340 split experiment. From Fig. 12ACTR-IB had an average F1 of\n0.95 outperforming LOG-REG 0.95 vs 0.84, SVM 0.95 vs 0.87, RF 0.95 vs 0.90\nand ACTR-R 0.95 vs 0.92 (t (678) \u22651.52, p\u22640.13). Since each family performs\nexactly one task the family prediction is similar to F1. Using the same carrier foreach payload makes the task dif\ufb01cult as can be seen from the similarity matrix for\nthe 17 payloads (Fig. 13).\nSame Carrier-Encryption\nThe GVDG tool provides the option for encrypting the malware samples for the File-\nvirus carrier type. We use this option to generate 100 encrypted malware samples foreach task(payload) and use them as test data with the unencrypted versions from the\nsame carrier experiment as training samples. From Fig. 14ACTR-IB had an average\nF1 of 0.9 outperforming LOG-REG 0.9 vs 0.8, SVM 0.9 vs 0.8, RF 0.9 vs 0.74and ACTR-R 0.9 vs 0.88 (t (1698) \u22652.36, p\u22640.02). Encrypting malware samples\nmorphs the task during execution making it dif\ufb01cult to detect during analysis. Hence\nthe drop in performance as compared to non-encrypted samples. We note that SVMperforms better than RF likely because it looks to maximize generalization.\nRuntime Analysis\nTable 5shows the classi\ufb01er run times for the experiments. Machine learning\ntechniques are faster but have large training times, which increase almost linearly\nwith the size of the knowledge base. Hence updating the knowledge base iscomputationally expensive for these methods, as it has to re-estimate the parameters\nevery time. The same notion holds true for ACTR-R, since computing the rules\nduring training phase is expensive as can be seen from the large training times.ACTR-IB on the other hand, has no explicit training phase, so the only time cost\n186 E. Nunes et al.\nFig. 13 Similarity matrix for 17 versions of the same carrier\n0.60.70.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB\nFig. 14 Average precision, recall, F1 and family prediction comparisons for LOG-REG, SVM,\nRF, ACTR-R and ACTR-IB for encrypted same carrier samples\nis during testing. In fact ACTR-IB is faster than SVM and RF for same/encrypted\ncarrier experiments.\nScaling of Instance-Based Model\nFinally to conclude the GVDG experiments, we run ACTR-IB on a combination\nof all the above variations of dataset to highlight the space requirements for the\nlearning model. The dataset comprises of \ufb01ve different carriers with low/high muta-\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 187\nTable 5 Classi\ufb01er run timesExperiment Model Train (s) Test (s)\nDifferent carriers LOG-REG 202 7\nSVM 250 50\nRF 280 30\nACTR-R 6443 143\nACTR-IB \u2013 453\nMutated carriers LOG-REG 214 18\nSVM 260 63\nRF 303 85\nACTR-R 7223 185\nACTR-IB \u2013 465\nSame carriers LOG-REG 152 4.22\nSVM 270 38\nRF 290 55\nACTR-R 4339 120\nACTR-IB \u2013 205\nEncrypted carriers LOG-REG 180 15\nSVM 300 80\nRF 353 110\nACTR-R 6103 180\nACTR-IB \u2013 365\ntion (10,000 samples) and same carrier encrypted/non-encrypted (3400 samples).\nBased on the tasks they perform we have in total 22 families represented by 13,400samples. The analysis reports generated by cuckoo take up 4 GB of disk space for\nthe samples. We signi\ufb01cantly reduce the size to 600 MB by parsing the analysis\nreports and extracting attributes. We set aside 10% of the samples for testing(1340) and iteratively add 10% of the remaining data for training. Table 6gives\na summary of the average F1 measure and testing time for ACTR-IB. The results\nare averaged across ten trials. There is a steady increase in performance till wereach 40% of the training data, after that the F1 measure remains almost constant.\nThis experiment clearly indicates the ability of the ACTR-IB to learn from small\namount of representation from each family, signi\ufb01cantly reducing the size of theknowledge base required for training. We are also looking into techniques to reduce\nthe time requirements of instance-based learning algorithm (e.g., Andrew Moore\nexplored ef\ufb01cient tree-based storage). There are also techniques for reducing spacerequirements, [ 27] merged training instances in the ACT-R-Gammon model and\nobtained considerable space savings at little performance cost.\n188 E. Nunes et al.\nTable 6 Summary of\nACTR-IB resultsFraction of training data F1 measure Test time (s)\n0.1 0.77 418\n0.2 0.82 839\n0.3 0.90 1252\n0.4 0.97 1676\n0.5 0.97 2100\n0.6 0.97 2525\n0.7 0.97 2956\n0.8 0.98 3368\n0.9 0.98 3787\n1.0 0.98 4213\n5.3 MetaSploit\nMetaSploit is a popular penetration testing tool used by security professionals to\nidentify \ufb02aws in the security systems by creating attack vectors to exploit those\ufb02aws [ 28]. Penetration testing may also be de\ufb01ned as the methods an attacker would\nemploy to gain access to security systems. Hence identifying the tasks the exploit\nwas designed to perform is important to counter the exploit.\nFor this experiment we generate exploits that attacks windows operating systems.\nEach exploit has a set of tasks associated with it. The tasks include setting up tcp &\nudp back-door connections, adding unauthorized users to the system, modifying rootprivileges, download executables and execute them on the local machine, prevent\nwriting of data to disk, deleting system folders, copying sensitive information etc.\nWe generated 4 exploit families with 100 samples each performing on average 4tasks. We induced mutation between samples belonging to the same family making\nthe classi\ufb01cation task dif\ufb01cult. We perform a 60\u201340 split training-testing experiment\nand average the results across ten trials. From Fig. 15, ACTR-IB had an average F1\nof 0.86 outperforming LOG-REG 0.86 vs 0.62, SVM 0.86 vs 0.82, RF 0.86 vs 0.82,\nACTR-R 0.86 vs 0.81 and INVINCEA 0.86 vs 0.8 (t (158) \u22651.94, p\u22640.05). Also\nfor family prediction ACTR-IB outperformed LOG-REG 0.8 vs 0.7, SVM 0.8 vs0.72, RF 0.8 vs 0.72 and ACTR-R 0.8 vs 0.71 (t (158) \u22652.53, p\u22640.01).\n5.4 Discussion\nWe evaluated the two proposed cognitive models on three different datasets under\nvarious operational conditions (mutated and encrypted malware samples). The\ninstance based model performs on par or better than the rule-based model andstandard machine learning approaches. The performance improvement can be\nattributed to different ACT-R modules (partial matching and spreading activation)\nthat model different aspects of the malware sample. Partial matching computes the\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 189\n0.50.60.70.80.91\nPrecision Recall F1 Family\nPredictionegarevA\nLOG-REG SVM RF ACTR-R ACTR-IB INVINCEA\nFig. 15 Average precision, recall, F1 and family prediction comparisons for LOG-REG,SVM, RF,\nACTR-R and ACTR-IB for metasploit samples\nsimilarity between malware samples, while spreading activation identi\ufb01es attributes\nthat are indicative of a given malware family and the tasks that it is designed to\nperform. Hence, in cases where the training data is signi\ufb01cantly less (as in one of theGVDG experiments), the proposed model is able to identify attributes representative\nof a particular malware family making the goal of correct task prediction better as\ncompared to standard machine learning approaches which do require more trainingdata for better generalization.\nExperiments on the GVDG dataset under conditions of mutation and encryption\nprovide further insights in the working of the cognitive models. For mutation, themalware samples used for training differ signi\ufb01cantly from the ones used for testing.\nIn this case the partial matching module does not contribute much towards the\nactivation function but in turn the spreading activation is able to identify attributesthat represent tasks that the malware sample is designed to perform thus making the\ncorrect task prediction in majority of the test cases. A similar behavior is observed\nfor the encryption experiment as well. For the GVDG experiment with less trainingdata shows how well the cognitive models are able to generalize with less training\ndata which is dif\ufb01cult for standard machine learning approaches.\n5.5 Task Prediction from Hacker Activities\nIn all the experiments discussed so far, the tasks associated with a given piece of\nmalware are prede\ufb01ned and do not change with time. In this section, we try tomap the tasks that a hacker is trying to achieve from the activities it performs on\na compromised system. For the entire experiment only one malware is used whose\nsole purpose is to create a tcp backdoor connection to let the hacker have access tothe system. We evaluate the test samples only using ACTR-IB and not other machine\n190 E. Nunes et al.\nTable 7 Summary of\nACTR-IB resultsSubject Average precision Average recall Average F1\nHacker-1 0.8 0.85 0.83\nHacker-2 0.85 0.85 0.85\nlearning methods. The goal of this experiment is to demonstrate how the system can\ndeal with real time hacker activities on a compromised system.\nThe experimental setup is as follows. We keep the Cuckoo sandbox running on\nthe system by executing the malware. This will create a connection between the\nhacker and the system. Once the hacker gains control of the machine, he can perform\noperations in order to achieve his objectives. We treat these objectives as the tasksthat the hacker wants to complete on the system. Once these tasks are completed,\nCuckoo generates an analysis report detailing the behavioral analysis of the hacker.\nHowever, these analysis are too detailed and do not provide a clear picture of themain tasks of the hacker on the machine. Hence, traditionally, this will often require\nan expert security analyst to go through large analysis results to determine the task,\nwhich is often time consuming. But instead we can feed the analysis report to theACTR-IB model to get a prediction of the hacker tasks. For this experiment we use\nthe Metasploit dataset discussed in Sect. 5.3as the knowledge base for the instance\nbased approach. For the test set we generate samples in real time with hackerstrying to achieve their goals (tasks) on the compromised system. This test also\nillustrates how well our model generalizes, as we are identifying hacker behavior\nusing historical data that was not generated by the hacker\u2014or even a human inthis case. We consider two hackers, who are given a list of the payloads (tasks) to\ncomplete from the list mentioned in Sect. 5.3. They always perform a fraction of\nthe tasks assigned to them at a given time instance and then the model is tested onpredicting these tasks.\nWe generate ten such attacks, \ufb01ve from each hacker. Each attack consists of\nachieving \ufb01ve tasks on average. We note that for each of the test sample themalware used is the same. ACTR-IB results are presented in Table 7. The results are\naveraged for each hacker across test samples. Table 8shows the actual and predicted\ntasks for Hacker-1 for \ufb01ve different attack instances. The results for Hacker-2 wereanalogous.\n6 Related Work\nIdenti\ufb01cation of Malicious Software The identi\ufb01cation of whether or not binary is\nmalicious [ 29,30] is an important related, yet distinct problem from what we study\nin this chapter and can be regarded as a \u201c\ufb01rst step\u201d in the analysis of suspiciousbinaries in the aftermath of a cyber-attack. However, we note that as many pieces of\nmalware are designed to perform multiple tasks, that successful identi\ufb01cation of a\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 191\nTable 8 Actual and predicted Hacker-1 attacks\nAttack instance Actual tasks Predicted tasks\n1 Setup backdoor connection\nmodify root privileges uninstallprogram copy \ufb01lesSetup backdoor connection modifyroot privileges uninstall program deletesystem \ufb01les prevent access to drive\n2 Setup backdoor connectionmodify root privileges downloadexecutables execute \ufb01les copy\ufb01lesSetup backdoor connection modifyroot privileges download executablesexecute \ufb01les delete \ufb01les\n3 Setup backdoor connectionmodify root privileges addunauthorized users startkeylogging uninstall program\ndelete \ufb01les prevent access to\ndrivesSetup backdoor connection modifyroot privileges add unauthorized usersstart keylogging uninstall programdelete \ufb01les\n4 Setup backdoor connection addunauthorized users preventwriting data to disk delete \ufb01lescopy \ufb01lesSetup backdoor connection addunauthorized users prevent writing datato disk delete \ufb01les modifying rootprivileges prevent access to drives\n5 Setup backdoor connectiondownload executables execute\ufb01les start keylogging Setup backdoor connection downloadexecutables execute \ufb01les startkeylogging\nbinary as malicious does not mean that the identi\ufb01cation of its associated tasks will\nbe a byproduct of the result.\nMalware Family Classi\ufb01cation There is a wealth of existing work on malware\nfamily identi\ufb01cation [ 2\u20134,6,31\u201333]. The intuition here is that by identifying the\nfamily of a given piece of malware, an analyst can then more easily determine whatit was designed to do based on previously studied samples from the same family.\nHowever, malware family classi\ufb01cation has suffered from two primary drawbacks:\n(1) disagreement about malware family ground truth as different analysts (e.g.Symantec and McAfee) cluster malware into families differently; and (2) previous\nwork has shown that some of these approaches mainly succeed in \u201ceasy to classify\u201d\nsamples [ 5,6], where \u201ceasy to classify\u201d is a family that is agreed upon by multiple\nmalware \ufb01rms. In this chapter, we infer the speci\ufb01c tasks a piece of malware was\ndesigned to carry out. While we do assign malware to a family as a component\nof our approach, it is not the focus of our comparison (though we show familyprediction results as a side-result). Further, we also describe and evaluate a variant of\nour instance-based method that does not consider families and yields a comparable\nperformance.\nMalware Task Identi\ufb01cation With regard to direct inference of malware tasks,\nthe major related work includes the software created by the \ufb01rm Invincea [ 7]f o r\nwhich we have included a performance comparison. Additionally, some of the ideas\nin this chapter were \ufb01rst introduced in [ 10\u201312]. However, these work primarily\nfocused on describing the intuitions behind the cognitive modeling techniques and\n192 E. Nunes et al.\nonly included experimental evaluation on two datasets (the Mandiant APT1 and\nGVDG datasets). The experimental evaluation in this chapter includes additional\nexperiments for the GVDG dataset to consolidate the previous experiments. Alsoalgorithm analysis and parameter exploration are provided for the cognitive models.\nIn addition we introduce a popular penetration tool used by security analyst\nMetasploit and present new results on this tool.\n7 Conclusion\nIn this chapter, we introduced an automated method that combines dynamic malwareanalysis with cognitive modeling to identify malware tasks. This method obtains\nexcellent precision and recall\u2014often achieving an unbiased F1 score of over 0.9\u2014\nin a wide variety of conditions over three different malware sample collections andtwo different sandbox environments\u2014outperforming a variety of baseline methods.\nCurrently, our future work has three directions. First, we are looking to create a\ndeployed version of our approach to aide cyber-security analysts in the \ufb01eld. Second,we look to enhance our malware analysis to also include network traf\ufb01c resulting\nfrom the sample by extending the capabilities of the sandbox. Finally, we also look\nto address cases of highly-sophisticated malware that in addition to using encryptionand packing to limit static analysis and employ methods to \u201cshut down\u201d when run\nin a sandbox environment [ 34]. We are exploring multiple methods to address this\nsuch as the recently introduced technique of \u201cspatial analysis\u201d [ 35] that involves\ndirect analysis of a malware binary.\nReferences\n1. M. Sikorski, A. Honig, Practical Malware Analysis: The Hands-On Guide to Dissecting\nMalicious Software , 1st edn. (No Starch Press, San Francisco, 2012)\n2. U. Bayer, P.M. Comparetti, C. Hlauschek, C. Kruegel, E. Kirda, Scalable, behavior-based\nmalware clustering, in NDSS ,v o l . 9(Citeseer, 2009), pp. 8-11\n3. J. Kinable, O. Kostakis, Malware classi\ufb01cation based on call graph clustering. J. Comput.\nVirol. 7, 233\u2013245 (2011)\n4. D. Kong, G. Yan, Discriminant malware distance learning on structural information for\nautomated malware classi\ufb01cation, in Proceedings of the 19th ACM SIGKDD. KDD \u201913, New\nYork (ACM, New York, 2013), pp. 1357\u20131365\n5. P. Li, L. Liu, D. Gao, M.K. Reiter, On challenges in evaluating malware clustering, in\nInternational Workshop on Recent Advances in Intrusion Detection (Springer, Berlin, 2010),\npp. 238\u2013255\n6. R. Perdisci, ManChon, Vamo: towards a fully automated malware clustering validity analysis,\ninProceedings of the 28th Annual Computer Security Applications Conference (ACM, New\nYork, 2012), pp. 329\u2013338\n7. Invencia, Crowdsource: crowd trained machine learning model for malware capability\ndetection (2013). http://www.invincea.com/tag/cynomix/\nCognitively-Inspired Inference for Malware Task Identi\ufb01cation 193\n8. Kaspersky, Gauss: abnormal distribution (2012). https://media.kasperskycontenthub.com/wp-\ncontent/uploads/sites/43/2018/03/20134940/kaspersky-lab-gauss.pdf\n9. C. Lebiere, P. Pirolli, R. Thomson, J. Paik, M. Rutledge-Taylor, J. Staszewski, J.R. Anderson,\nA functional model of sensemaking in a neurocognitive architecture. Comput. Intell. Neurosci.5:5\u20135:5 (2013)\n10. C. Lebiere, S. Bennati, R. Thomson, P. Shakarian, E. Nunes, Functional cognitive models of\nmalware identi\ufb01cation, in Proceedings of ICCM, ICCM 2015, Groningen, April 9\u201311 (2015)\n11. R. Thomson, C. Lebiere, S. Bennati, P. Shakarian, E. Nunes, Malware identi\ufb01cation using\ncognitively-inspired inference, in Proceedings of BRIMS, BRIMS 2015, Washington DC,\nMarch 31\u2013April 3 (2015)\n12. E. Nunes, C. Buto, P. Shakarian, C. Lebiere, R. Thomson, S. Bennati, J. Holger, Malware\ntask identi\ufb01cation: a data driven approach, in Proceedings of International Symposium\non Foundation of Open Source Intelligence and Security Informatics (FOSINT-SI) (IEEE,\nPiscataway, 2015)\n13. Rapid7, Metasploit: penetration testing software (2003). http://www.metasploit.com/\n14. D. McWhorter, APT1: exposing one of China\u2019s cyber espionage units (2013). http://Mandiant.\ncom\n15. GVDG, Generator malware GVDG (2011)16. Mandiant, Mandiant APT1 samples categorized by malware families. Contagio Malware\nDump (2013)\n17. J.R. Anderson, D. Bothell, M.D. Byrne, S. Douglass, C. Lebiere, Y . Qin, An integrated theory\nof mind. Psychol. Rev. 111, 1036\u20131060 (2004)\n18. C. Gonzalez, J.F. Lerch, C. Lebiere, Instance-based learning in dynamic decision making.\nCogn. Sci. 27(4), 591\u2013635 (2003)\n19. R.S. Sutton, A.G. Barto, Introduction to Reinforcement Learning , 1st edn. (MIT Press,\nCambridge, 1998)\n20. T.J. Wong, E.T. Cokely, L.J. Schooler, An online database of ACT-R parameters: towards\na transparent community-based approach to model development, in Proceedings of the 10th\nInternational Conference on Cognitive Modeling (Citeseer, 2010), pp. 282\u2013286\n21. D. Bothell, Act-r 6.0 reference manual (2004). http://act-r.psy.cmu.edu/actr6/reference-\nmanual.pdf\n22. L. Breiman, Random forests. Mach. Learn. 45(1), 5\u201332 (2001)\n23. C. Cortes, V . Vapnik, Support-vector networks. Mach. Learn. 20, 273\u2013297 (1995)\n24. C.C. Chang, C.J. Lin, Libsvm: a library for support vector machines. ACM Trans. Intell. Syst.\nTechnol. 2(3), 27:1\u201327:27 (2011)\n25. ISEC-Lab, Anubis: analyzing unknown binaries (2007). http://anubis.iseclab.org/\n26. C. Guarnieri, A. Tanasi, J.B.M.S., Cuckoo sandbox (2012). http://www.cuckoosandbox.org/\n27. S. Sanner, J.R. Anderson, C. Lebiere, M. Lovett, Achieving Ef\ufb01cient and Cognitively Plausible\nLearning in Backgammon (Carnegie Mellon University, Pittsburgh, 2000)\n28. J. O\u2019Gorman, D. Kearns, M. Aharoni, Metasploit: The Penetration Tester\u2019s Guide (No Starch\nPress, San Francisco, 2011)\n29. I. Firdausi, C. Lim, A. Erwin, A.S. Nugroho, Analysis of machine learning techniques\nused in behavior-based malware detection, in Proceedings of the 2010 Second International\nConference on ACT. ACT \u201910, Washington, DC (IEEE Computer Society, Philadelphia, 2010),\npp. 201\u2013203\n30. A. Tamersoy, K. Roundy, D.H. Chau, Guilt by association: large scale malware detection by\nmining \ufb01le-relation graphs, in Proceedings of the 20th ACM SIGKDD. KDD \u201914 (ACM, New\nYork, 2014), pp. 1524\u20131533\n31. S.S. Hansen, T.M.T. Larsen, M. Stevanovic, J.M. Pedersen, An approach for detection\nand family classi\ufb01cation of malware based on behavioral analysis, in 2016 International\nConference on Computing, Networking and Communications (ICNC) (IEEE, Piscataway,\n2016), pp. 1\u20135\n32. K. Sanders, X. Wang, Malware family identi\ufb01cation using pro\ufb01le signatures. US Patent\n9,165,142, 20 Oct 2015\n194 E. Nunes et al.\n33. C. Annachhatre, T.H. Austin, M. Stamp, Hidden Markov models for malware classi\ufb01cation. J.\nComput. Virol. Hacking Tech. 11(2), 59\u201373 (2015)\n34. M. Lindorfer, C. Kolbitsch, P. Milani Comparetti, Detecting environment-sensitive malware, in\nProceedings of the 14th International Conference on RAID. RAID\u201911 (Springer, Berlin, 2011),\npp. 338\u2013357\n35. D. Giametta, A. Potter, There and back again: a critical analysis of spatial analysis (2014).\nhttps://archive.org/details/ShmooCon2014_A_Critical_Review_of_Spatial_Analysi\nSocial Media for Mental Health: Data,\nMethods, and Findings\nNur Shazwani Kamarudin, Ghazaleh Beigi, Lydia Manikonda, and Huan Liu\nAbstract There is an increasing number of virtual communities and forums\navailable on the web. With social media, people can freely communicate and share\ntheir thoughts, ask personal questions, and seek peer-support, especially those with\nconditions that are highly stigmatized, without revealing personal identity. We study\nthe state-of-the-art research methodologies and \ufb01ndings on mental health challenges\nlike depression, anxiety, suicidal thoughts, from the pervasive use of social media\ndata. We also discuss how these novel thinking and approaches can help to raise\nawareness of mental health issues in an unprecedented way. Speci\ufb01cally, this chapter\ndescribes linguistic, visual, and emotional indicators expressed in user disclosures.\nThe main goal of this chapter is to show how this new source of data can be tapped\nto improve medical practice, provide timely support, and in\ufb02uence government or\npolicymakers. In the context of social media for mental health issues, this chapter\ncategorizes social media data used, introduces different deployed machine learning,\nfeature engineering, natural language processing, and surveys methods and outlines\ndirections for future research.\nKeywords Social media \u00b7 Mental health \u00b7 Online social network \u00b7 Well-being\n1 Introduction\nSocial media is a popular channel to spread information online. There are hundreds\nof millions of users that communicate with each other to share their thoughts, ideas,\nand personal experiences which overloads these channels with information. There\nare remarkable challenges when it comes to mental health issues [ 14]. A growing\nbody of research have focused on understanding how social media activities can\nbe use to analyze and improve the well-being of people, including mental health\nN. S. Kamarudin ( /envelopeback) \u00b7 G. Beigi \u00b7 L. Manikonda \u00b7 H. Liu\nSchool of Computing, Informatics and Decision Systems Engineering, Arizona State University,\nTempe, AZ, USA\ne-mail: nurkamarudin@asu.edu ;gbeigi@asu.edu ;lmanikon@asu.edu ;huanliu@asu.edu\n\u00a9 Springer Nature Switzerland AG 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_8195\n196 N. S. Kamarudin et al.\nReview\nDatasetFeature\nSelectionData\nMining\nAnalysisEvaluationPre-\nProcessing\n\u0081Tokenizer\n\u0081Stopwords\n  Removal\nFig. 1 Steps of social media analysis\n[23,34,40]. With the presence of social media data, it is now easier to study\nthe trend of mental health problems and also to help researchers get information\nfrom social media to study mental health issues [ 14]. The easy access and use of\nsocial media allow users to update their social media pro\ufb01les without time or space\nrestriction [ 45]. This makes social media a preferable medium for researchers for\ntheir investigations. In addition, it is cost-effective for information seekers. Userscan easily get health-related information [ 32].\n1.1 Social Media and Its Analysis\nSocial media has become a good source for data collection. There are different types\nof data that can be used from social media such as text, image, video, and audio.\nThe amount of data on social media data increases rapidly. For example, on Twitter,350,000 tweets are generated per minute and 500 million tweets are generated per\nday. A major factor that might affect social media users is the way they use social\nmedia because it can be very bene\ufb01cial or toxic at the same time. For instance, activeuse of social media with two-way communication can be very bene\ufb01cial to the user\nbut it can also be destructive or toxic to the user [ 57].\nFigure 1shows the common steps in social media analysis. It starts with dataset\nreview in which the researchers need to choose the right dataset for their experiment.\nThe second step is data pre-processing, which means preparing the data for the\nexperiment such as removing stop words or word/sentence tokenizing. The nextstep is to select meaningful features from social media data such as an image or\ntextual features. After selecting the right features, it is data mining analysis which\nincludes deploying various techniques to develop the desired model. The \ufb01nal stepis an evaluation, employing different metrics such as accuracy, recall, precision, F1\nscores, for example.\n1.2 Mental Health Problem\nMental health has become a public concern nowadays. People have started to think\nabout the importance of mental health problems and their effects on our society.This is not a minor issue; on the contrary, it is a very serious issue that can contribute\nSocial Media for Mental Health: Data, Methods, and Findings 197\nto mental well-being. For example, graduate students nowadays may face anxiety,\ndepression, and stress because of the high competition in the academic world, long\nwork hours, and lack support from their advisor [ 12,29]. These studies show that\nnot just students [ 12,25,28,29,38], even employees [ 17,18,59] are all facing their\nown problems and authorities need to step up in order to help these groups of people.\nResearchers in the psychology \ufb01eld have studied this topic for decades. With theincreasing use of social media data, this speci\ufb01c problem also attracts the attention\nof many computer scientists. Users actively share and communicate with online\ncommunities and researchers have found that it is a smart idea to leverage socialmedia data to study this problem in order to help online communities and authorities\nat the same time. This can contribute to an immense change in overcoming this\nissue. Researchers have begun to investigate mental health problems such as post-traumatic stress disorder (PTSD) [ 15,33,46], depressive disorder [ 22,43,45,52],\nsuicidal ideation [ 16,21,37], schizophrenia [ 41], and anxiety [ 20,27,56] through\nsocial media data.\nThis chapter is organized into \ufb01ve sections. Section 2discusses the social media\ndata on mental health by categorizing the data into three categories, which are\nlinguistic-, visual- and combined-based. Section 3presents a set of approaches used\nby the researcher on mental health research. In addition, evaluation metrics and\n\ufb01ndings are discussed in Sect. 4. Lastly, the study is concluded and a list of possible\nfuture works is presented in Sect. 5.\n2 Social Media Data on Mental Health\nVarious types of social media data have been used by researchers to study mental\nhealth. Existing work could be categorized in to three groups based on the type of\nutilized social media data, (1) linguistic-based data, (2) visual-based data, and (3)\ncombination of linguistic and visual data. Next, we will discuss each separately.\n2.1 Linguistic-Based Data\nOver the past few years, research in crisis informatics have utilized language as amedium to understand how major crisis events unfold in affected populations, and\nhow they are covered on traditional media as well as online media such as blogs\nand social media sites [ 55]. Studies have shown that social media can provide a\ncomforting environment for support seekers especially when it comes to stigmatized\nissues that make them reluctant to share with individuals around them.\nSocial media has been accordingly used to understand users\u2019 mental health\nissues. Interesting work by Coppersmith et al. [ 16] studies suicide attempts or even\nideation among users using their posts in Twitter. The authors crawl tweets from 30\ngeolocations from all over the United States with at least 100 tweets per location.\n198 N. S. Kamarudin et al.\nThen, they use natural language processing techniques to compare behavior of\nusers who attempted suicide with those users who have previously stated that they\nwere diagnosed with depression and neurotypical controls. In another work, Parket al. [ 45] focus on studying the impact of online social networks (OSN) on the\ndepression issue. Accordingly, they collect two different kinds of data: (1) data\nfrom Internet-based screening test, which includes information of 69 participantswho were asked to complete a questionnaire including depression related questions,\nand (2) collected tweets from Twitter from June 2009 to July 2009 that include the\nkeyword \u2018depression\u2019. After qualitative and quantitative analysis of collected data,authors show that social media data could be used to understand users\u2019 mental health\nissues.\nNadeem [ 43] use social media data to study Major Depressive Disorder (MDD)\nissue in individuals. They use a publicly available dataset that was built from Shared\nTask organizers of Computational Linguistics and Clinical Psychology (CLPsych\n2015) [ 15]. This dataset includes information of Twitter users who were diagnosed\nwith depression. In another work, Amir et al. use Twitter to study depression and\npost-traumatic stress disorder (PTSD) [ 2]. They investigate the correlation between\nusers\u2019 posts and their mental state. In particular, they investigate if tweets couldbe used to predict whether a user is affected by depression and PTSD or not. De\nChoudhury et al. [ 22] also show that social media can be utilized for predicting\nanother mental health condition, i.e., major depressive disorder (MDD), usingTwitter data. In this work, authors employ crowd-sourcing technique to provide the\nground truth for their experiments. In another work [ 27], authors use Twitter data\nto study gender-based violence (GBV). The authors use Twitter\u2019s streaming API tosample a set of GBV related tweets based on a set of key phrases de\ufb01ned by the\nUnited Nations Population Fund (UNFPA) [ 50].\nAnother well-known social media platform is Reddit, which is a forum-based\nsocial media platform that captures communication between the original post and\nthe user who left a comment on the thread. Each thread discusses a speci\ufb01c topic,\nwhich is known as a \u201csubreddit\u201d. The work by De Choudhury and De [ 20]u s e s\nReddit to investigate how users seek mental health related information on online\nforums. They crawl mental health subreddits using Reddit\u2019s of\ufb01cial API\n1and\nPython wrapper PRAW.2In another work, De Choudhury and K\u0131c\u0131man [ 21]u s e\nReddit to study the language style of comments left by users on the discussion\nforum in terms of in\ufb02uences towards suicidal ideation. This work \ufb01lls the gap of how\nonline social support can contribute to this speci\ufb01c problem. Authors use strati\ufb01edpropensity score analysis to determine if the user was affected by comments or\nnot. They also estimate the likelihood that a user will receive a treatment based\non the user\u2019s covariates. There was a study by De Choudhury et al. [ 24] with\nwork speci\ufb01cally on mental health subreddits such as r/depression, r/mentalhealth,\nr/bipolarreddit, r/ptsd, r/psychoticreddit. Based on the time stamp, data were divided\n1http://www.reddit.com/dev/api .\n2https://praw.readthedocs.org/en/latest/index.html .\nSocial Media for Mental Health: Data, Methods, and Findings 199\ninto a treatment group and control group. These groups were further divided based\non the causal analysis in order to analyze the effect of comments on the content of\nearlier posts with comment shared and received by users in their dataset.\nAnother work by Saha and De Choudhury [ 55] uses Reddit data to study the\neffect of gun violence on college students and the way they express their experience\non social media. Authors collect related data from Reddit. Then they develop aninductive transfer learning approach [ 44] to see the pattern of stress expression by\ncomputing the mean accuracy value. In particular, they \ufb01rst build a classi\ufb01er which\nlabels the expressed stress in posts as High Stress andLow Stress . Then, they adopt\nthe trained classi\ufb01er to categorize collected posts from Reddit in order to identify\nposts that express higher stress level after the shooting incident. Another work from\nLin et al. [ 39] focuses on how online communities can affect the development of\ninteraction within social media. This work investigates if new members will bring\ninterruption in terms of perspectives towards social dynamic and lower content\nquality. The authors accordingly generate three questions related to user reception,discussion content and interaction patterns. They use Reddit data from Google\nBigQuery by choosing the top ten subreddits between years 2013 and 2014. They\nstudy user reception, post content, and commenting patterns among Reddit users.This work studies the role of online social support based on historical data in\nconjunction with its effect on future health. It also investigates linguistic changes\nin online communities over time using data from two peer reviewing communities.Cohan et al. [ 13] study mental health by analyzing the content of forum posts based\non the sign of self-harm thoughts. Their main goal was to study the impact of\nonline forums on self-harm ideation. They consider four level of severity for the postcontent. Author build a model that includes lexical, psycholinguistic, contextual and\ntopic modeling features. Their data were collected from a well-known mental health\nforum in Australia, namely, ReachOut.com.\n3\n2.2 Visual-Based Data\nThe popularity of visual-based social media has increased rapidly. Users tendto communicate on social media by posting their photographs. Photo sharing\nprovides a unique lens for understanding how people curate and express different\ndimensions of their personalities [ 3]. People use photos to de\ufb01ne and record their\nidentity, maintain relationships, curate and cultivate self-representation, and express\nthemselves [ 62].\nPosting pictures have become one way of communication among social media\nusers. The de\ufb01nition of \u201csel\ufb01e\u201d is a picture that users take of themselves. Kim et\nal. [36] study the behavior of sel\ufb01e-posting using Instagram data. This work uses\nsel\ufb01e-posting to predict the intention of users who post sel\ufb01es on social networking\n3https://au.reachout.com/ .\n200 N. S. Kamarudin et al.\nsites (SNSs). This work de\ufb01nes \ufb01ve hypotheses before they start designing the\nexperiment. Those hypotheses were: attitude toward the behavior of sel\ufb01e-posting,\nsubjective norm, perceived behavioral control, and narcissism, which were possiblyrelated to the intention to post sel\ufb01es on social network sites (SNSs). The last\nhypothesis was the intention to post sel\ufb01es on SNSs is positively related to the actual\nsel\ufb01e-posting behavior on SNSs. They begin with 89 Instagram users. They recruitthese users based on their agreement to be part of the study. Two coders analyze\neach user\u2019s account and the total sample size was ( n= 85). From the total number of\nparticipants, 9 were males and 76 were females. They also count the total numberof the pictures posted on each user\u2019s account in a 6-week timestamp. Each user\nwas required to answer a list of questions that were related to the standard Theory\nof Planned Behavior (TPB) variables such i.e., attitude, subjective norm, perceivedbehavioral control, and future intention based on [ 1].\nAnother work by Reece et al. [ 52] uses visual data for studying mental health in\nsocial media. The authors use Instagram data from 166 individuals with 43,950photographs. In order to study the markers of depression, they use machine\nlearning tools to categorize users to healthy and depressed groups. They began their\nexperiment by crawling all posts from each user\u2019s account upon their agreement.Participant users were also required to answer a depression related questionnaire\nthat contained speci\ufb01c questions based on inclusion criteria. In the last step of\nexperiments crawled Instagram photos are rated using a crowd-sourced serviceoffered by Amazon\u2019s Mechanical Turk (AMT) workers.\n2.3 Combined Data of Linguistic and Visual-Based\nApart from using only visual data or only linguistic data, researchers also combine\nthese two kinds of data to study social media in\ufb02uence on mental health. Sociol-\nogists also claim that it is not possible to communicate by using the only words;people also use pictures to communicate with each other [ 8] .Aw o r kb yB u r k e\net al. [ 10] used different features in Facebook data such as wall posts, comments,\n\u201clikes\u201d, and consumption of friends\u2019 content, including status updates, photos, andfriends\u2019 conversations with other friends in order to study the role of directed\ninteraction between pairs. This work distinguish between two types of activity:\ndirected communication and consumption. To do this, they recruited 1199 English-speaking adults from Facebook to be their research participants.\nAndalibi et al. [ 3] study depression-related images from Instagram. They use\nimage data and the matching captions to analyze if a user was having a depressionproblem or had faced this kind of problem in the past. They were keen on\ninvestigating if this group of users engage in a support network or not, and how\nsocial computing could be used to encourage this kind of support interaction amongusers. They gather 95,046 depression tagged photos posted by 24,920 unique users\nover 1 month (July 2014) using Instagram\u2019s API. All public details of each image\nwere stored from these photos, such as user ID, number of likes and comments,\nSocial Media for Mental Health: Data, Methods, and Findings 201\nTable 1 List of mental health related social media data and available datasets\nType of data Paper Name Availability\nLinguistic data [16,43] Computational Linguistic and\nClinical Psychology(CLPsych)Publicly available athttps://bit.ly/2T0hMGO\n[39,55] Google News dataset Publicly available at\nhttps://bit.ly/1LHe5gU\n[20,27,43,45]Reddit, Twitter, Facebook Crawled using provided\nAPI by social mediaplatform\nImage data [36] Instagram Publicly available at\nhttps://bit.ly/2SV5cbY\nCombination oftext and imagedata [3,40] Twitter, Facebook, Instagram Crawled using provided\nAPI by social mediaplatform\nLink data [22,35] Twitter, Facebook Crawled using provided\nAPI by social mediaplatform\ndate/time of creation, and tags. After conducting data collection, they begin the\nexperiment by analyzing images and their textual captions. They also develop\na codebook that includes 100 sample images and captions. Those coders thenmanually discuss the codebook in order to provide the best result for the experiment.\nThen, they add 100 more sample images and repeat the same steps.\nLikewise, Peng et al. [ 48] investigate the effect of pets, relationship status, and\nhaving children, towards user happiness using Instagram pictures and captions.\nThey use several hashtags such as #mydog, #mypuppy, #mydoggie, and #mycat,\n#mykitten, #mykitty to gather images of pet owner from Instagram. For non-petowners, hashtags such as #sel\ufb01es, #me, and #life were used to crawl the data. Before\nthey started with the experimental steps, they began by classifying their data. The\nauthors also provided the processed human face data called the face library for otherresearchers to use (see Table 1).\nManikonda and De Choudhury [ 40] use popular image-based media data in\norder to study mental health disclosure. This work extracts three main visualfeatures from each image that they have in the corpus. Those features include\nvisual features (e.g., color), themes, and emotions. Authors crawl the data from\nInstagram using Instagram\u2019s of\ufb01cial API.\n4The main focus of this work was to study\nmental health disclosure based on visual features, emotional expression and how\nvisual themes contrast with the language in a social media post. They speci\ufb01cally\nchoose ten mental health challenges from Instagram before they crawl two millionpublic images and textual data from that particular medium. Those categories\ncontain ten types of disorders, which were: anxiety disorder, bipolar disorder, eating\n4https://www.instagram.com/developer/ .\n202 N. S. Kamarudin et al.\ndisorder, non-suicidal self-injury, depressive disorder, panic disorder, OCD, PTSD,\nsuicide, and schizophrenia. Before they begin their experiment, they consult with the\nDiagnostic and Statistical Manual of Mental Health Disorders (DSM-V) in order tocon\ufb01rm that their \ufb01nal disorder categories could be reliable.\nTo sum-up, user-generated social media data is heterogeneous and consists of\ndifferent aspects such as text, image, and link data. Table 1summarizes different\ndatasets used by researchers to study mental health using social media.\n3 Studying Mental Health in Social Media\nAs social media data has recently emerged as the main medium to spread infor-\nmation among online communities, there are also various approaches used by\nresearchers to study related problems. This section discusses the approaches forstudying mental health on social media. In this section, we elaborate on types of\ntechniques or tools used in their research. Figure 2shows the categorization of social\nmedia analysis, namely machine learning methods, feature engineering and surveymethods. Next, we introduce how social media analysis are used for mental health\nanalysis in social media.\n3.1 Machine Learning Methods\nWe discuss machine learning methods in terms of classi\ufb01cation, clustering, and\nprediction with social media data for studying mental health problems.\nClassi\ufb01cation\nIn order to estimate the likelihood of having depression among users within a\ndataset, a work by Nadeem [ 43] employ four types of classi\ufb01ers (Decision Trees,\nLinear Support Vector Classi\ufb01er, Logistic Regression, and Naive Bayes). They\npresent a set of attributes to characterize the behavioral and linguistic differences\nof two classes. To do that, author utilize scikit-learn5which is a popular tool with\nmany supervised and unsupervised machine learning algorithms [ 47].\n5http://scikit-learn.org/stable/ .\nSocial Media for Mental Health: Data, Methods, and Findings 203\nSocial Media Analysis\nSurvey Methods\nN-gramsAmazon Mechanical\nTurk (AMT)\nQuestionnaire analysis\nmethodClassification\nClustering Bag-of-Words\nTopic Modeling\nStanford CoreNLP\nFace++Linguistic Inquiry and\nWord Count (LIWC)PredictionMachine Learning\nMethodsFeature\nEnineering/Natural\nLanguage Processing\n(NLP)\nFig. 2 Social media analysis approaches\n204 N. S. Kamarudin et al.\nClustering\nDe Choudhury et al. [ 22] cluster the ego-networks among users on social media.\nBy clustering the ego-network, they study the characteristics of the graphs based\non the egocentric measures, such as the number of followers, number of followees,\nreciprocity, prestige ratio, graph density, clustering coef\ufb01cient, 2-hop neighborhood,embeddedness and number of ego components. Another work by [ 35] studies the\ncorrelation of social ties and mental health and \ufb01nds that depressed individuals tend\nto cluster together.\nPrediction\nThe work by Reece et al. [ 52] predicts depression using photographic details, such\nas color analysis, metadata components and algorithmic face detection. In anotherapproach, the authors in [ 22] divide users into two categories based on differences\nin behavior. For each user, they utilize a set of behavioral measures, such as mean\nfrequency, variance, mean momentum, and entropy based on a user\u2019s 1-year Twitterhistory. In order to avoid over\ufb01tting, the authors employ principal component\nanalysis (PCA), then compared their method with several different parametric and\nnon-parametric classi\ufb01ers.\n3.2 Feature Engineering/Natural Language Processing (NLP)\nMethods\nNatural language processing plays a very important role in linguistic social media\nanalysis. This subsection discusses feature representation techniques used in study-ing social media for mental health.\nN-Grams\nThis text representational technique is widely adopted and is basically a set of co-\noccurring words within a given window. Features extracted using this technique\nare based on word frequency counts. In [ 20], authors calculate the most frequent\nunigrams from all Reddit posts and use negative binomial regression as theirprediction model.\nSaha et al. built a supervised machine learning model in order to classify\nstress expression in social media posts into binary labels of High Stress and\nLow Stress [55]. To develop the transfer learning framework for their experiment,\nthey measure the linguistic equivalence by borrowing a technique from domain\nadaptation literature [ 19]. By using top n-grams ( n= 3) as an additional feature, Saha\nSocial Media for Mental Health: Data, Methods, and Findings 205\net al. developed a binary Support Vector Machine (SVM) classi\ufb01er to detect High\nStress andLow Stress . To build their training set, the authors extract 500 n-grams\nfrom the Reddit posts that they crawled. They compute the cosine similarity andcompare their data with a Google News dataset in a 300-dimensional vector space.\nAuthors \ufb01nd that it is possible to use social media content to detect psychological\nstress. On the other hand, as Twitter data has a limited number of characters perpost, another work [ 9] designs a character n-gram language model (CLM) to get\nthe score for each short text. This speci\ufb01c method examines sequences of characters\nincluding spaces, punctuation, and emoticons. For example, if we have a set of datafrom two classes, the model is trained by recognizing the sequence of characters.\nSimilar character sequences will be classi\ufb01ed into the same class. Given a novel\ntext, the model can do estimations on which class can produce and generate all thetexts.\nFurthermore, the authors in [ 40] extract n-grams ( n= 3) to check the suitability\nand reliability of their corpus. Extracted n-grams have been further used to investi-\ngate if they are facing mental health disclosures. In order to extract visual features\nfrom the dataset, the authors pair OpenCV and Speeded Up Robust Features (SURF\n[6]). This approach is able to identify the meaningful themes from images. To study\nthe linguistic emotions based on the visual themes, this work uses psycholinguistic\nlexicon LIWC and TwitterLDA. These two approaches help authors to measure the\nestimation of how themes and images were coherent to each other.\nBag-of-Words (BOW)\nBag-of-Words (BOW) is a basic text representation for texts widely used by\nresearchers in this area. When implementing this approach, a histogram is createdto indicate how often a certain word is present in the text [ 63]. A previous work\nby [60] shows that the bag-of-words approach can be useful to identify depression.\nThe author in [ 43] utilizes word occurrence frequencies to quantify the content from\nTwitter data by assembling all words and measuring the frequency of each word.\nSimilarly, [ 13] uses BOW to extract features from their dataset. This work also uses\ncontent severity of the users in order to help forum moderators to identify the criticalusers that are keen on committing self-harm.\nTopic Modeling\nOne of the most mentioned topic modeling methods is Latent Dirichlet Allocation\n(LDA), which works by drawing distribution topics for each word in the document\n[7]. Then, words are grouped based on the distribution value. Similar words are in\nthe same topic category. Cohan et al. [ 13] use the LDA model to \ufb01nd a set of topics\nfrom their data collection. By training the LDA topic model on the entire forum\nposts from their dataset, they are able to use the topic model as additional features\nfor their experiment, which boosted the performance of their system and prove the\n206 N. S. Kamarudin et al.\neffectiveness of topic modeling. Additionally, Manikonda and De Choudhury [ 40]\nuse TwitterLDA to extract the linguistic themes from their dataset to see if visual\nand text are coherent to each other when it comes to mental health disclosure onInstagram.\nAmir et al. [ 2] adopt a model known as Non-Linear Subspace Embedding\n(NLSE) approach [ 4] that can quantify user embedding based on Twitter post\nhistories. The authors evaluate user embedding by using User2Vec (u2v), Para-\ngraph2vec\u2019s PV-dm and PV-dbow models. They also leverage Skip-Gram in order\nto build vectors. Another design based on bag-of-embedding was bag-of-topics byusing LDA to indicate topics presented in the user\u2019s posts [ 20]. They leverage LDA\nto identify types of social support on Reddit. They also consider information on\npractices that people share with the communities by characterizing self-disclosurein mental illness. The authors \ufb01nd that Reddit users discuss diverse topics. These\ndiscussions can be as simple as talking about daily routines but it can also turn into\na serious discussion that involves queries on diagnosis and treatments.\nAdditionally, a work by Lin et al. [ 39] studies linguistic changes and for their\ndata, the authors use several post-level measures including cross-entropy of posts\nand Jaccard self-similarity between adjacent posts. Then, the authors use the LDAmodel in order to compare the topic distribution among posts and general Reddit\npost samples. They also track the linguistic changes in sub-communities. In order to\nexamine the interaction network\u2019s structural change, they calculate the exponent \u03b1\nin the network\u2019s power-law degree distribution which gives the graph densi\ufb01cation\nof the network [ 11]. Reddit allow users to vote on each post and comments, and\nthe authors leverage this feature by computing the average score and complaintcomment percentage in order to investigate community reaction to the content\nproduced by newcomers.\nLinguistic Inquiry and Word Count (LIWC)\n6\nIt is a text analysis application that can be used to extract emotional attributes\non mental health. This tool will be able to extract psycholinguistic features [ 13].\nManikonda and De Choudhury [ 40] use LIWC on texts associated with mental\nhealth images spanning different visual themes. LIWC can also characterize\nlinguistic styles in posts from users [ 53]. Park et al. [ 45], use LIWC to quantify\nthe level of depressive moods from their Twitter data. They compare a normalgroup vs. depressed group by measuring the average sentiment score from categories\nprovided by the tools. LIWC contains a dictionary of several thousand words and\neach word fed to this tool will be scaled across six prede\ufb01ned categories: social ,\naffective ,cognitive ,perceptual ,biological processes , and relativity . Every criterion\n6http://www.liwc.net/ .\nSocial Media for Mental Health: Data, Methods, and Findings 207\nwill have its own categories and sub-categories. For each sub-category, LIWC will\nassign speci\ufb01c scores for each word. The authors in [ 22] use LIWC to study Twitter\nusers\u2019 emotional states. Then, they use point wise mutual information (PMI) andlog-likelihood ratio (LLR) to extract more features from their corpus. ElSherief et\nal. [27] leverage LIWC in order to measure interpersonal awareness among users by\ndifferentiating perceived user and actual user characteristics.\nA study by De Choudhury and De [ 20] captures the linguistic attributes of\ntheir data by measuring the unigram and then employ psycholinguistic lexicon\nLIWC. They choose LIWC because it can categorize Redditors\u2019 emotions. They alsoexamine the factors that drive social support on mental health Reddit communities,\nwhere the authors build a statistical model by measuring the top most frequent\nsemantic categories from LIWC. The authors in [ 21] adopt the LIWC lexicon to\nstudy the various sociolinguistic features from their dataset and then measure the\nt-tests in order to analyze the differences between subpopulations. Coppersmith\net al. [ 16] also use LIWC to study the pattern of language in conjunction with\npsychological categories generated from their dataset. This work uses LIWC to\ninterpret how language from a given psychological category will be scored by the\nclassi\ufb01ers that they built. Likewise, Saha and De Choudhury [ 55] investigate on\nquantifying the psycholinguistic characterization. They employ LIWC measures to\nunderstand the psychological attributes in social media.\nStanford CoreNLP\nA study by Peng et al. [ 48] classi\ufb01es the images and textual sentiments to see the\nsigni\ufb01cant role of those factors in reducing stress and loneliness among individuals.\nIn order to interpret a user\u2019s happiness from a caption, they also utilize a sentimentanalysis method, which is Valence Aware Dictionary and Sentiment Reasoner\n(V ADER). Saha and De Choudhury [ 55] use Stanford CoreNLP\u2019s sentiment analysis\nmodel to retrieve the sentiment class of posts.\nFace++\nA deep learning-based image analysis tool that is very useful for the facial recog-\nnition research \ufb01eld. It is an open-source face engine built with the convolutionalneural network (CNN). In the work by ElSherief et al. [ 27], the authors use Twitter\nuser\u2019s pro\ufb01le picture to predict the demographic information of the user by using\nFace++ API. Based on the GBV content, they investigate user involvement in GBVrelated post by leveraging the language nuances of those posts. Face++ is also used\nin [48] to do an experiment on face analysis by extracting user\u2019s information such\nas demographics inference, user relationship status, if a user has children, and thenanalyze user happiness.\n208 N. S. Kamarudin et al.\n3.3 Survey Methods\nThis subsection discusses works that use human intelligence tasks (HITs) for\ntheir analysis process, namely Amazon\u2019s Mechanical Turk and questionnaire based\nanalysis. We also discuss the tools used.\nAmazon Mechanical Turk (AMT)\nIt is one of the widely used crowdsourcing platforms. On AMT, chunks of work are\nreferred to as Human Intelligence Tasks (HIT) or micro-tasks [ 58]. This technique is\nleveraged in [ 20] to label words related to mental illness for their dataset. Moreover,\nAmazon\u2019s Mechanical Turk is used in [ 22] to take a standard clinical depression\nsurvey followed by several questions on depression history and demographics. The\ncrowdworkers have the option to either include their public Twitter pro\ufb01les or\nnot in the analyzing process. Reece et al. use AMT service to rate the Instagram\nphotographs collected for their experiment [ 52]. Raters are asked to judge how\ninteresting, likable, happy, and sad each photo seemed, on a 0\u20135 scale.\nQuestionnaire Analysis Method\nThe questionnaire can be very helpful for researchers to get more insight on the\ntopic they are studying. For example, authors in [ 36] use this technique to measure\nattitude towards sel\ufb01e-posting on semantically differential scales (e.g., bad/good,\npleasant/unpleasant). By using the Narcissism Personality Inventory (NPI) [ 30],\nthey measure Narcissism and participants\u2019 respond on a seven-point Likert scale(1 = \u201cstrongly disagree\u201d to 7 = \u201cstrongly agree\u201d). The authors uses AMOS 22 to\ntest their hypotheses and see the relationships between attitude, subjective norm,\nperceived behavioral control, and narcissism toward their main question, whichwas the user\u2019s intention and behavior toward posting sel\ufb01es on SNSs. In another\nwork [ 52], authors uses the Center for Epidemiologic Studies Depression Scale\n(CES-D) [ 51] to screen participants\u2019 depression level for the depressed user group.\nQuali\ufb01ed participants are asked to share their Instagram usernames and history. An\napp embedded in the survey allow participants to securely log into their Instagram\naccounts and share their data.\nBurke et al. [ 10] run a survey to analyze the relationship of social well-being\nand SNSs activity. Each user is required to answer survey questions using the\nformat from the UCLA loneliness scale [ 54], Likert scales, and Facebook intensity\nscales [ 26]. They analyze their data without analyzing the private data of users,\nsuch as friend networks or identi\ufb01able information. They measure the number of\nfriends and time spent on SNSs for each user so that they can get the answer totheir research questions. In another work[ 45], authors use the CES-D to measure\ndepressive symptoms and [ 22] also use CES-D to determine the depression levels\nSocial Media for Mental Health: Data, Methods, and Findings 209\nTable 2 The summary of methods and tools in the application of mental health studies\nApproach Paper\nLinguistic Inquiry and Word Count (LIWC) [20,22,27,40,45,55]\nLatent Dirichlet Allocation (LDA) [2,7,13,20,40]\nN-grams [9,16,20,40,55]\nAmazon Mechanical Turk (AMT) [20,22,52]\nCenter for Epidemiologic Studies Depression Scale (CES-D) [22,45,52]\nEvaluation\nmetric\nRegression\np-value precision recall accuracy F1 scoresnegative\npredictive\nvalue (NPV)Adjusted R-\nvalueClassification\nFig. 3 Categories of evaluation metrics used for mental health analysis in social media\nof crowdworkers by distributing a depression survey to Amazon Mechanical Turk.\nAs a summary, Table 2shows the methods and tools that we discuss in this section.\n4 Evaluation Methods and Findings\nIn this section we discuss the utilized evaluation metrics and \ufb01ndings from the\naforementioned papers. Figure 3represents the utilized evaluation metrics for\na mental health studies in social media. We begin this section by overviewing\nevaluation metrics. Then, we discuss the \ufb01ndings from previous works.\n4.1 Evaluation Metrics\nThere are various evaluation metrics in data mining analysis. We discuss theevaluation metrics used for studying mental health using social media data. The\nmost common prediction metrics include precision, recall, F1 scores, and recipient\noperating classi\ufb01cation (ROC) curves. Equation 1shows the calculation of precision\nde\ufb01ned as the number of true positives (TP) divided by the sum of all positive\npredictions, TP and false positive (FP). Equation 2is de\ufb01ned as the number of\nTP divided by the sum of all positives in the set, TP and false negative (FN).Equation 3measures F1 scores by considering both precision and recall. The F1\n210 N. S. Kamarudin et al.\nscore is the harmonic average of the precision and recall, and an F1 score reaches\nits best value at 1. Another metric known as adjusted R-squared is represented in\nEq.4. Adjusted R-squared is often used for explanatory purposes and explains how\nwell the selected independent variable(s) explain the variability in the dependent\nvariable(s). In adjusted R-squared, nis the total number of observations and kis the\nnumber of predictors. Adjusted R-squared is always less than or equal to R-squared.\nprecision =TP\nTP+FP(1)\nrecall =TP\nTP+FN(2)\nF1=2\u00b7precision \u00b7recall\nprecision +recall(3)\n(R2\nadj)=1\u2212[(1\u2212R2)(n\u22121)\nn\u2212k\u22121] (4)\nSeveral works implement these metrics for their experiments [ 13,22,43,55]. De\nChoudhury et al. [ 22] evaluate their proposed classi\ufb01cation approach by predicting\nindividual depression level from their posts. They use precision, recall, accu-\nracy, and receiver-operator characteristic (ROC) for evaluation. Their experimental\nresults show that their classi\ufb01er has a good performance in depression prediction.Another work from De Choudhury and K\u0131c\u0131man [ 21] measures the most positive\nor negative zscores in order to differentiate between mental health with in\ufb02uence\nrisks to suicidal ideation (SW) users and mental health users. On the contrary, astudy by [ 45] uses the coef\ufb01cients from regression models to predict the Center\nfor Epidemiologic Studies Depression Scale (CES-D) score. It then evaluates the\nproposed approach by measuring adjusted R-squared (Eq. 4) and p-value. Another\nwork [ 2] measures F1andbinary F1 with respect to a mental condition in order to\nmeasure the performance of different models for its experiment.\nFurthermore, authors in [ 27] measure the favorite rate and retweet rate for each\ntweet in order to count how many times a tweet was favorited and retweeted,\nrespectively. These metrics are used to explore the engagement of users with gender-\nbased violence (GBV) content on Twitter. Saha and De Choudhury [ 55] measure\naccuracy, precision, recall, F1-scores and ROC-AUC in order to see the performance\nlevel of their stress predictor classi\ufb01er. Likewise, Coppersmith et al. [ 16]p l o tR O C\ncurve of the performance for distinguishing people who attempted suicide from theirage- and gender-matched controls. In order to compare the accuracy of all data and\npre-diagnosis in their model prediction, [ 52] measure recall, speci\ufb01city, precision,\nnegative predictive value (NPV) and F1-scores.\nFurthermore, a study by Manikonda and De Choudhury [ 40] calculates the\nSpearman rank correlation coef\ufb01cients to compare the most frequent tags across\nall pairs of visual themes that belonged to six visual themes of mental health-related\nSocial Media for Mental Health: Data, Methods, and Findings 211\nposts. Burke et al. present the ordinary least square (OLS) regressions for bridging\nand bonding social capital and loneliness based on the overall SNS activities [ 10].\nAdditionally, [ 39] study the effect of newcomers to existing online forums such\nas Reddit. They leverage the regression analysis by calculating the adjusted R-\nsquared in order to measure the average score of post voting and complaint comment\npercentage on the content of the subreddit. In another work, Andalibi et al. calculateCohen\u2019s Kappa coef\ufb01cient to analyze depression related images along with the\ntextual captions [ 3].\n4.2 Output and Findings\nIn this section, we discuss the outputs and \ufb01ndings from previous works based on\nthe type of data used. As we discussed in Sect. 2, we categorize works based on\ndata that the authors used in their experiments. Here, we \ufb01rst discuss the \ufb01ndings of\nexisting works that used linguistic data. Then, we review \ufb01ndings from visual data.\nFinally, we discuss \ufb01ndings from using combined data.\nLinguistic-Based Findings\nBy focusing on linguistic-based experiments, [ 45] concludes that people disclose\nnot only depressed feelings, but also very private and detailed information aboutthemselves such as treatment history. For participants suffering from depression,\ntheir tweets were found to have high usage of words related to negative emotions and\nanger. In the end, users with depression tend to post more tweets about themselvesthan typical users. Likewise, the work by De Choudhury et al. [ 22] demonstrates\nthat Twitter can be used as a platform to measure major depression in individuals.\nTo develop the prediction framework, the authors calculate four statistical valuesfrom the corpus including mean, variance, momentum, and entropy of selected\nfeatures. Then, they compare these values between depression and non-depression\nclasses. They \ufb01nd that individuals with low social activity tend to have a greaternegative emotion, high self-attentional focus, increased relational and medicinal\nconcerns, and heightened expression of religious thoughts. We can conclude that\nsocial activity does play an important role in individual mental well being. Thisgroup of people with low social activity has close-knit networks, which are normally\nhighly embedded with their audience. The authors conclude that useful signals from\nsocial media can be used to characterize the onset of depression in persona bymeasuring their social activity and expression through their social networks. This\nkind of experiment shows how much social media can contribute to the body of\nknowledge in \ufb01nding the solution and helping individuals in need.\nSimilarly, a work by De Choudhury and K\u0131c\u0131man [ 21] reports that comments\nplay an important role in terms of giving support, especially among mental health\ncommunities. They observe that users who receive support from the online forums\n212 N. S. Kamarudin et al.\nare more socially active and engage with the communities. Moreover, Nadeem [ 43]\nshow that Twitter can be used as a tool to predict MDD among users. The novelty\nof this research is the proposed text classi\ufb01cation system which can classify if thetweets from users are depressive in nature or not. They conclude that social media\ncan capture the individual\u2019s present state of mind. The text classi\ufb01cation system\nis also effective because Twitter users are using this medium as a place to expresstheir feelings. In addition, this study shows that it is reliable to use social media\ndata for studying mental health related issues. Another study by Amir et al. [ 2]\npropose a novel model to extract users characteristics from their tweets knownas user embeddings and further investigate their mental health status with respect\nto depression and PTSD. Their results show the correlation between captured\nembeddings and users\u2019 mental health condition.\nIn addition, ElSherief et al. [ 27] show that people discuss GBV-related issues\non social medias. GBV-related hashtags help Twitter users to express their feelings,\nespecially to share experiences and seek support. It has been shown that the mostexpressed emotion was anger. Another work demonstrates that communication\nbetween users plays an important role in mental well-being [ 13]. Their results show\nthat when users are more active in communicating with other users, it helps todecrease the content severity. In another work, [ 39] compares the effects of growing\nonline communities to the current network and showed that users perception remains\npositive and growth has an impact on users\u2019 attention. Authors also \ufb01nd that highlevels of moderation helps to maintain the positive perception of community content\nafter getting defaulted and that the communities\u2019 language do not become more\ngeneric or more similar to the rest of Reddit after the massive growth.\nSaha and De Choudhury [ 55] show that posts published after gun-violence\nincident on college campuses include higher level of stress in comparison to those\nposted before incident. The authors also \ufb01nd that there is an increase in self-attention and social orientation when the campus population reduced. Also, more\nstudents were observed engaging in death-related conversations. In another work\n[16], researchers \ufb01nd that people who attempt suicide engage less in conversation,\nshowing that this group of users had a smaller proportion of their tweets directed\nto other users. This work demonstrates how social media data can be bene\ufb01cial for\nunderstanding mental health-related studies. De Choudhury et al. [ 20] also \ufb01nd that\nthere is a variation in each type of social support. They also observe that posts related\nto self-attention, relationship and health issues received more attention from Reddit\ncommunities. Moreover, they \ufb01nd that negative posts get more attention compared topositive posts. By studying user feedback from all posts, they conclude that certain\ntypes of disclosures receives more social support from the online communities.\nVisual-Based Findings\nKim et al. [ 36] use the theory of planned behavior (TPB) [ 1] for studying behavioral\nintention using social media data. They \ufb01nd that all of their outlined hypotheses\naffect sel\ufb01e-posting intention on social networks. Another work [ 52] extracts\nSocial Media for Mental Health: Data, Methods, and Findings 213\nfeatures from each images shared by users on social media platforms and shows that\nit is easy to distinguish between photos posted by healthy users and depressed ones.\nThe results of this work demonstrate that healthy people will share photographswith higher hue value in comparison to depressed users who tend to share grayer\nimages with lower brightness color. These results show that it is possible to detect\ndepression through visual social media data. These \ufb01ndings con\ufb01rm the fact thatsocial media data could be used for mental health-related research.\nCombined-Based Findings\nA study by Andalibi et al. [ 3] \ufb01nd that Instagram users are aware of their audience.\nThis is notable by observing how users address the audiences\u2019 concerns in captions\nof their posts. They \ufb01nd that images posted with a heavy amount of captions\nare related to support seeking and positive expression. Their results also showthat speci\ufb01c hashtags on Instagram are used not only as semantic markers, but\nalso as one way of categorizing content for the public. Similarly, Manikonda and\nDe Choudhury [ 40] found that users used images to express their feelings such as\nemotional distress, and helplessness. Users\u2019 posts can be further used to understand\nhow vulnerable and socially isolated they are. Results also show that images with\nvarious visual cues contribute to how users express themselves on Instagram. Theauthors \ufb01nally conclude that Instagram is one of the mediums for users with mental\nhealth problems to seek help and also receive psychosocial support that they need.\nAnother work by Burke et al. [ 10] demonstrates that direct communication affects\nusers positively by making the user to bond with other users. This can further help\nusers to feel less lonely. Their results also show that users with lower umber of\ninteractions with others, tend to become more observer of other peoples\u2019 lives.In another work, Peng et al. [ 48] study the effect of owning a pet on personnel\nhappiness by investigating posted images on social media. They compare users\u2019\nhappiness scores and \ufb01nd that pet owners were slightly happier than people whodo not own pets. These results show the effectiveness of social media data in\nunderstanding users\u2019 behaviors and mental health related issues. In the next section,\nwe summarize our \ufb01ndings and discuss potential future direction to expand researchin this \ufb01eld.\n5 Discussion and Future Directions\nThis chapter presents an overview of mental health related work that use social\nmedia data and machine learning in their studies. We discuss three key points\nfocusing on mental health studies using social media data, namely, data, approaches,and \ufb01ndings. In the rest of this chapter, we provide a brief discussion followed by\nfuture work.\n214 N. S. Kamarudin et al.\n5.1 Discussion\nSocial media can affect users in many different ways. The main concern is if\nsocial media is bene\ufb01cial to overcoming mental health problems among users. In\n[61], Facebook was rated as negative when it comes to cyber-bullying and bad\nsleeping patterns for users. But, when it comes to social support and building onlinecommunities, Facebook does help and was rated positively. Hence, it is important to\nmake sure that social media be used in a good manner that can bene\ufb01t users. Some\nsigni\ufb01cant effects of social media contributing to mental health well-being include:(1) social media can reduce stress in users through active communication with other\nusers [ 13] and also provide information in capturing individual\u2019s present state of\nmind [ 43]; (2) social media is a popular channel for users to seek help and share\ninformation on the stigmatized issue. The anonymity of social media gives freedom\nto the user to express their feeling and might also improve in the stigmatized topic\ndiscussion [ 20]. (3) The use of social media with active communication may lead to\nimprovement in the capability to share and understand others\u2019 feelings [ 10]. A study\nby Grieve et al. [ 31] indicates that Facebook connectedness may reduce depression\nand anxiety. Engaging with online communities can also give users the feeling ofsocial appreciation through being understood [ 5].\nOn the other hand, some earlier studies point out the negative effects of social\nmedia to users. One \ufb01nding is that users may have social isolation problems whenthey spend too much time on social media without having active communica-\ntion with the online communities [ 16,22]. Increasing social media use without\ninteraction with other users may cause depression, anxiety, sleep problems, eatingdisorder, and suicide risk. Primack et al. [ 49] report that in terms of subjective social\nisolation or perceived social isolation (PSI), increased time spent on social media\ncan result in decreased traditional social experience, thus, increased social isolation,and exacerbate the feeling of exclusion.\nFigure 4shows different types of mental illnesses and related work using social\nmedia data and analysis. Existing studies are summarized in categories of mentalhealth issues: (1) mood disorder [ 22,43,45,52], (2) post-traumatic stress disorder\n(PTSD) [ 15,33,46], (3) anxiety [ 20,27,56], (4) psychotic disorder [ 41], (5) eating\ndisorder [ 11], (6) sexual and gender disorder [ 27], (7) suicidal behavior [ 16,21,37],\nand (8) attention de\ufb01cit and hyperactivity disorder (ADHD) [ 14]. Mood disorder\nsuch as depression is studied in [ 15,23,60]. Depression is one of the mental\nhealth issues with high prevalence, receiving increasing attention lately. Limitedwork focuses on the psychotic disorder, eating disorder, and ADHD. These studies\ncan also leverage social media data as it provides data about individuals\u2019 language\nand behavior [ 33]. Researchers use social media data to predict types of mental\nissues [ 11,22,23,36\n]. In [ 43] the severity of users\u2019 mental issues is estimated\nusing social media data. A similar \ufb01nding is reported in [ 41]. Network information\navailable in social media data is leveraged for studying mental health issues [ 22,35].\nSocial Media for Mental Health: Data, Methods, and Findings 215\nFig. 4 An overview of different types of mental health issues and related work\n5.2 Future Directions\nStudying mental health issues using social media is challenging. Although a large\nbody of work has emerged in recent years for investigating mental health issues\nusing social media data, there are still open challenges for further investigation.\nSome potential research directions are suggested below:\n\u2013 The increasing popularity of social media allows users to participate in online\nactivities such as creating online pro\ufb01les, interacting with other people, express-\ning opinions and emotions, sharing posts and various personal information. User-\ngenerated data on these platforms is rich in content and could reveal information\nregarding users\u2019 mental health situation. However, little attention has been paid\non collecting the proper amount of user-information speci\ufb01cally on mental\n216 N. S. Kamarudin et al.\nhealth [ 16,43]. One future direction is to collect a proper amount of labeled\nuser-data as a benchmark which requires cooperation between psychologists\nand computer scientist [ 42]. This data can include users\u2019 behavioral information\ncollected from social media platforms as well as their mental health condition\ninformation provided by experts. Preparing such data gives opportunities to both\ncomputer scientists and psychologists to bene\ufb01t from a tremendous amount ofdata generated in social media platforms to better understand mental health issues\nand propose solutions to solve them.\n\u2013 User-generated social media data is heterogeneous and consists of different\naspects such as text, image, and link data. Most of the existing work investigates\nthe mental health problem issues by just incorporating one aspect of social media\ndata. For example, textual information is used in [ 2,15,16,20,22,27,43,45,55],\nimage information is exploited [ 3,36,52], and link data in [ 22,35] to understand\nhow user-generated information is correlated with people\u2019s mental health con-\ncerns. One potential research direction is to examine how different combinationsof heterogeneous social media data (e.g., a combination of image and link data,\ncombination of textual and link data, etc.) can be utilized to better understand\npeople\u2019s behavior and mental health issues concern. Another future direction isto explore how \ufb01ndings from each aspect of social media data are different from\neach other, e.g., results w.r.t. textual data in comparison the \ufb01ndings w.r.t. link\ndata.\n\u2013 Most existing work utilizes either human-computer interaction techniques or data\nmining related techniques. For example, interview and surveys are used to help\nfurther study mental health related issues in social media [ 10,20,22,36,45,52].\nStatistical and computational techniques are leveraged to understand users\u2019\nbehavior w.r.t. mental health issues [ 2,35,43,55]. However, research can\nbe furthered to exploit both techniques to understand mental health issues insocial media [ 22,45,52] and to develop both human-computer interaction and\ncomputational techniques specialized for understanding mental health issues for\nsocial media data.\n\u2013 This chapter shows how different mental health issues have been studied using\nsocial media data. Figure 4represents different categories of mental health\nrelated issues using social media data. More mental health issues can be studiedsuch as psychotic disorder, eating disorder, sexual and gender disorder.\nSocial media data can bene\ufb01t mental health studies. The existing work shows that\nit is possible to study mental health by leveraging the large-scale social media data\nin understanding and analyzing mental health problems and employing machine\nlearning algorithms to understand, measure, and predict mental health problems.More research on social media analysis using machine learning will help advance\nthis important emerging \ufb01eld via multidisciplinary collaboration, research and\ndevelopment.\nSocial Media for Mental Health: Data, Methods, and Findings 217\nAcknowledgements We would like to thank all members of Data Mining Machine Learning\nResearch Lab (DMML) at Arizona State University (ASU) for their constant support and feedbackfor this work. Special thanks to our lab members, Jundong Li, Matthew Davis, and Alex Nou fortheir detailed feedback on the earlier versions of this chapter. This work, in part, is supported bythe Ministry of Higher Education Malaysia and University Malaysia Pahang (UMP).\nReferences\n1. I. Ajzen, The theory of planned behavior. Organ. Behav. Hum. Decis. Process. 50(2), 179\u2013211\n(1991)\n2. S. Amir, G. Coppersmith, P. Carvalho, M.J. Silva, B.C. Wallace, Quantifying mental health\nfrom social media with neural user embeddings (2017). Preprint. arXiv:1705.00335\n3. N. Andalibi, P. Ozturk, A. Forte, Depression-related imagery on instagram, in Proceedings\nof the 18th ACM Conference Companion on Computer Supported Cooperative Work & SocialComputing (ACM, New York, 2015), pp. 231\u2013234\n4. R. Astudillo, S. Amir, W. Ling, M. Silva, I. Trancoso, Learning word representations from\nscarce and noisy data with embedding subspaces, in Proceedings of the 53rd Annual Meeting\nof the Association for Computational Linguistics and the 7th International Joint Conferenceon Natural Language Processing (Volume 1: Long Papers) , vol. 1 (2015), pp. 1074\u20131084\n5. D. Baker, S. Fortune, Understanding self-harm and suicide websites: a qualitative interview\nstudy of young adult website users. Crisis 29(3), 118\u2013122 (2008)\n6. H. Bay, T. Tuytelaars, L. Van Gool, Surf: Speeded up robust features, in European Conference\non Computer Vision (Springer, Berlin, 2006), pp. 404\u2013417\n7. D.M. Blei, A.Y . Ng, M.I. Jordan, Latent Dirichlet allocation. J. Mach. Learn. Res. 3(Jan),\n993\u20131022 (2003)\n8. I. Bourgeault, R. Dingwall, R. De Vries, The SAGE Handbook of Qualitative Methods in\nHealth Research (SAGE, London, 2010)\n9. S.R. Braithwaite, C. Giraud-Carrier, J. West, M.D. Barnes, C.L. Hanson, Validating machine\nlearning algorithms for twitter data against established measures of suicidality. JMIR MentalHealth 3(2), e21 (2016)\n10. M. Burke, C. Marlow, T. Lento, Social network activity and social well-being, in Proceedings\nof the SIGCHI Conference on Human Factors in Computing Systems (ACM, New York, 2010),\npp. 1909\u20131912\n11. S. Chancellor, Z. Lin, E.L. Goodman, S. Zerwas, M. De Choudhury, Quantifying and\npredicting mental illness severity in online pro-eating disorder communities, in Proceedings\nof the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing(ACM, New York, 2016), pp. 1171\u20131184\n12. W. Chris, Feeling overwhelmed by academia? You are not alone. Nature 557, 129 (2018)\n13. A. Cohan, S. Young, A. Yates, N. Goharian, Triaging content severity in online mental health\nforums. J. Assoc. Inf. Sci. Technol. 68(11), 2675\u20132689 (2017)\n14. G. Coppersmith, M. Dredze, C. Harman, K. Hollingshead, From ADHD to SAD: analyzing the\nlanguage of mental health on Twitter through self-reported diagnoses, in Proceedings of the\n2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signalto Clinical Reality (2015), pp. 1\u201310\n15. G. Coppersmith, M. Dredze, C. Harman, K. Hollingshead, M. Mitchell, Clpsych 2015 shared\ntask: depression and PTSD on twitter, in Proceedings of the 2nd Workshop on Computational\nLinguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality (2015), pp.\n31\u201339\n16. G. Coppersmith, R. Leary, E. Whyne, T. Wood, Quantifying suicidal ideation via language\nusage on social media, in Joint Statistics Meetings Proceedings, Statistical Computing Section,\nJSM (2015)\n218 N. S. Kamarudin et al.\n17. T. Cox, A. Grif\ufb01ths, E. Rial-Gonzalez, Research on work related stress. Of\ufb01ce for of\ufb01cial\npublications of the European communities, Luxembourg, 2000\n18. K. Danna, R.W. Grif\ufb01n, Health and well-being in the workplace: a review and synthesis of the\nliterature. J. Manag. 25(3), 357\u2013384 (1999)\n19. H. Daum\u00e9 III, Frustratingly easy domain adaptation (2009). Preprint. arXiv:0907.181520. M. De Choudhury, S. De, Mental health discourse on reddit: self-disclosure, social support,\nand anonymity, in ICWSM (2014)\n21. M. De Choudhury, E. K\u0131c\u0131man, The language of social support in social media and its effect\non suicidal ideation risk, in Proceedings of the International AAAI Conference on Weblogs and\nSocial Media , vol. 2017 (NIH Public Access, 2017), p. 32\n22. M. De Choudhury, M. Gamon, S. Counts, E. Horvitz, Predicting depression via social media,\ninICWSM , vol. 13 (2013), pp. 1\u201310\n23. M. De Choudhury, S. Counts, E.J. Horvitz, A. Hoff, Characterizing and predicting postpartum\ndepression from shared facebook data, in Proceedings of the 17th ACM Conference on\nComputer Supported Cooperative Work & Social Computing (ACM, New York, 2014), pp.\n626\u2013638\n24. M. De Choudhury, E. Kiciman, M. Dredze, G. Coppersmith, M. Kumar, Discovering shifts to\nsuicidal ideation from mental health content in social media, in Proceedings of the 2016 CHI\nConference on Human Factors in Computing Systems (ACM, New York, 2016), pp. 2098\u20132110\n25. N.H. El-Ghoroury, D.I. Galper, A. Sawaqdeh, L.F. Bufka, Stress, coping, and barriers to\nwellness among psychology graduate students. Train. Educ. Prof. Psychol. 6(2), 122 (2012)\n26. N.B. Ellison, C. Stein\ufb01eld, C. Lampe, The bene\ufb01ts of facebook \u201cfriends\u201d social capital and\ncollege students\u2019 use of online social network sites. J. Comput.-Mediat. Commun. 12(4), 1143\u2013\n1168 (2007)\n27. M. ElSherief, E.M. Belding, D. Nguyen, # notokay: Understanding gender-based violence in\nsocial media, in ICWSM (2017), pp. 52\u201361\n28. T.M. Evans, L. Bira, J. Beltran-Gastelum, L.T. Weiss, N. Vanderford, Mental health crisis in\ngraduate education: the data and intervention strategies. FASEB J. 31(1 Supplement), 750\u2013757\n(2017)\n29. T.M. Evans, L. Bira, J.B. Gastelum, L.T. Weiss, N.L. Vanderford, Evidence for a mental health\ncrisis in graduate education. Nat. Biotechnol. 36(3), 282 (2018)\n30. B. Gentile, J.D. Miller, B.J. Hoffman, D.E. Reidy, A. Zeichner, W.K. Campbell, A test of\ntwo brief measures of grandiose narcissism: the narcissistic personality inventory-13 and thenarcissistic personality inventory-16. Psychol. Assess. 25(4), 1120 (2013)\n31. R. Grieve, M. Indian, K. Witteveen, G.A. Tolan, J. Marrington, Face-to-face or facebook: can\nsocial connectedness be derived online? Comput. Hum. Behav. 29(3), 604\u2013609 (2013)\n32. E. Gunther, W. Jeremy, Using the internet for surveys and health research. J. Med. Internet\nRes. 4(2), E13 (2002)\n33. G. Harman, M.H. Dredze, Measuring post traumatic stress disorder in twitter, in ICWSM\n(2014)\n34. C.M. Homan, N. Lu, X. Tu, M.C. Lytle, V . Silenzio, Social structure and depression in\nTrevorSpace, in Proceedings of the 17th ACM Conference on Computer Supported Cooperative\nWork & Social Computing (ACM, New York, 2014), pp. 615\u2013625\n35. I. Kawachi, L.F. Berkman, Social ties and mental health. J. Urban Health 78(3), 458\u2013467\n(2001)\n36. E. Kim, J.-A. Lee, Y . Sung, S.M. Choi, Predicting sel\ufb01e-posting behavior on social networking\nsites: an extension of theory of planned behavior. Comput. Hum. Behav. 62, 116\u2013123 (2016)\n37. M. Kumar, M. Dredze, G. Coppersmith, M. De Choudhury, Detecting changes in suicide\ncontent manifested in social media following celebrity suicides, in Proceedings of the 26th\nACM Conference on Hypertext & Social Media (ACM, New York, 2015), pp. 85\u201394\n38. K. Levecque, F. Anseel, A. De Beuckelaer, J. Van der Heyden, L. Gisle, Work organization\nand mental health problems in phd students. Res. Pol. 46(4), 868\u2013879 (2017)\n39. Z. Lin, N. Salehi, B. Yao, Y . Chen, M.S. Bernstein, Better when it was smaller? Community\ncontent and behavior after massive growth, in ICWSM (2017), pp. 132\u2013141\nSocial Media for Mental Health: Data, Methods, and Findings 219\n40. L. Manikonda, M. De Choudhury, Modeling and understanding visual attributes of mental\nhealth disclosures in social media, in Proceedings of the 2017 CHI Conference on Human\nFactors in Computing Systems (ACM, New York, 2017), pp. 170\u2013181\n41. M. Mitchell, K. Hollingshead, G. Coppersmith, Quantifying the language of schizophrenia in\nsocial media, in Proceedings of the 2nd Workshop on Computational Linguistics and Clinical\nPsychology: From Linguistic Signal to Clinical Reality (2015), pp. 11\u201320\n42. F. Morstatter, J. Pfeffer, H. Liu, K.M. Carley, Is the sample good enough? Comparing data from\ntwitter\u2019s streaming API with twitter\u2019s \ufb01rehose, in Seventh International AAAI Conference on\nWeblogs and Social Media (2013)\n43. M. Nadeem, Identifying depression on twitter (2016). Preprint. arXiv:1607.0738444. S.J. Pan, Q. Yang, A survey on transfer learning. IEEE Trans. Knowl. Data Eng. 22(10),\n1345\u20131359 (2010)\n45. M. Park, C. Cha, M. Cha, Depressive moods of users portrayed in twitter, in Proceedings of the\nACM SIGKDD Workshop on Healthcare Informatics (HI-KDD) , vol. 2012 (ACM, New York,\n2012), pp. 1\u20138\n46. T. Pedersen. Screening twitter users for depression and ptsd with lexical decision lists, in\nProceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology:From Linguistic Signal to Clinical Reality (2015), pp. 46\u201353\n47. F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel, P.\nPrettenhofer, R. Weiss, V . Dubourg et al., Scikit-learn: machine learning in python. J. Mach.Learn. Res. 12(Oct), 2825\u20132830 (2011)\n48. X. Peng, L.-K. Chi, J. Luo, The effect of pets on happiness: a large-scale multi-factor analysis\nusing social multimedia. ACM Trans. Intell. Syst. Technol. (TIST) 9(5), 1\u201315 (2018)\n49. B.A Primack, A. Shensa, J.E. Sidani, E.O. Whaite, L. yi Lin, D. Rosen, J.B. Colditz, A.\nRadovic, E. Miller, Social media use and perceived social isolation among young adults inthe US. Am. J. Prev. Med. 53(1), 1\u20138 (2017)\n50. H. Purohit, T. Banerjee, A. Hampton, V .L. Shalin, N. Bhandutia, A.P. Sheth, Gender-based\nviolence in 140 characters or fewer: a# bigdata case study of twitter (2015). Preprint.arXiv:1503.02086\n51. L.S. Radloff, The CES-D scale: a self-report depression scale for research in the general\npopulation. Appl. Psychol. Meas. 1(3), 385\u2013401 (1977)\n52. A.G. Reece, C.M. Danforth, Instagram photos reveal predictive markers of depression. EPJ\nData Sci. 6(1), 15 (2017)\n53. S. Rude, E.-M. Gortner, J. Pennebaker, Language use of depressed and depression-vulnerable\ncollege students. Cognit. Emot. 18(8), 1121\u20131133 (2004)\n54. D.W. Russell, UCLA loneliness scale (version 3): reliability, validity, and factor structure. J.\nPers. Assess. 66(1), 20\u201340 (1996)\n55. K. Saha, M. De Choudhury, Modeling stress with social media around incidents of gun violence\non college campuses. Proc. ACM Hum. Comput. Interact. 1(CSCW), 1\u201327 (2017)\n56. B. Shickel, M. Heesacker, S. Benton, P. Rashidi, Hashtag healthcare: from tweets to mental\nhealth journals using deep transfer learning (2017). Preprint. arXiv:1708.01372\n57. Social media can be bad for youth mental health, but there are ways it can\nhelp. https://theconversation.com/social-media-can-be-bad-for-youth-mental-health-but-\nthere-are-ways-it-can-help-87613 . Accessed 15 Mar 2018\n58. K.-J. Stol, B. Fitzgerald, Two\u2019s company, three\u2019s a crowd: a case study of crowdsourcing\nsoftware development, in Proceedings of the 36th International Conference on Software\nEngineering (ACM, New York, 2014), pp. 187\u2013198\n59. A.H. De Lange, T.W. Taris, M.A.J. Kompier, I.L.D. Houtman, P.M. Bongers, Work characteris-\ntics and psychological well-being. Testing normal, reversed and reciprocal relationships withinthe 4-wave smash study. Work Stress 18(2), 149\u2013166 (2004)\n60. S. Tsugawa, Y . Kikuchi, F. Kishino, K. Nakajima, Y . Itoh, H. Ohsaki, Recognizing depression\nfrom twitter activity, in Proceedings of the 33rd Annual ACM Conference on Human Factors\nin Computing Systems (ACM, New York, 2015), pp. 3187\u20133196\n220 N. S. Kamarudin et al.\n61. UK News, Instagram rated worst social network for mental health (2017). http://www.theweek.\nco.uk/84799/instagram-rated-worst-social-network-for-mental-health . Accessed 28 Mar 2018\n62. N.A. Van House, M. Davis, The social life of cameraphone images, in Proceedings of the\nPervasive Image Capture and Sharing: New Social Practices and Implications for TechnologyWorkshop (PICS 2005) at the Seventh International Conference on Ubiquitous Computing(UbiComp 2005) . Citeseer (2005)\n63. M. Worring, Lecture notes: Multimedia information systems (2015). http://citeseerx.ist.psu.\nedu/viewdoc/download?doi=10.1.1.103.6399rep=rep1type=pdf\nAutomated Text Analysis for Intelligence\nPurposes: A Psychological Operations\nCase Study\nStefan Varga , Joel Brynielsson , Andreas Horndahl ,\nand Magnus Rosell\nAbstract With the availability of an abundance of data through the Internet, the\npremises to solve some intelligence analysis tasks have changed for the better. The\nstudy presented herein sets out to examine whether and how a data-driven approach\ncan contribute to solve intelligence tasks. During a full day observational study, an\nordinary military intelligence unit was divided into two uniform teams. Each team\nwas independently asked to solve the same realistic intelligence analysis task. Both\nteams were allowed to use their ordinary set of tools, but in addition one team was\nalso given access to a novel text analysis prototype tool speci\ufb01cally designed to\nsupport data-driven intelligence analysis of social media data. The results, obtained\nfrom the case study with a high ecological validity, suggest that the prototype tool\nprovided valuable insights by bringing forth information from a more diverse set of\nsources, speci\ufb01cally from private citizens that would not have been easily discovered\notherwise. Also, regardless of its objective contribution, the capabilities and the\nusage of the tool were embraced and subjectively perceived as useful by all involved\nanalysts.\nKeywords Data-driven analysis \u00b7 Text analysis \u00b7 Social media \u00b7 Intelligence \u00b7\nPsychological operations \u00b7 Ecological validity\nS. Varga\nKTH Royal Institute of Technology, Stockholm, Sweden\nSwedish Armed Forces Headquarters, Stockholm, Sweden\ne-mail: svarga@kth.se\nJ. Brynielsson (/envelopeback)\nKTH Royal Institute of Technology, Stockholm, Sweden\nFOI Swedish Defence Research Agency, Stockholm, Sweden\ne-mail: joel@kth.se\nA. Horndahl \u00b7 M. Rosell\nFOI Swedish Defence Research Agency, Stockholm, Sweden\ne-mail: andreas.horndahl@foi.se ;magnus.rosell@foi.se\n\u00a9 The Author(s) 2020\nM. A. Tayebi et al. (eds.), Open Source Intelligence and Cyber Crime , Lecture Notes\nin Social Networks, https://doi.org/10.1007/978-3-030-41251-7_9221\n222 S. Varga et al.\n1 Introduction\nVast amounts of easily accessible data on the Internet is generated every day by\nnews outlets, individuals, and other information sources. The traf\ufb01c volumes thatproduce this sea of data, too big for any human or group of humans to process\nwithout help, are predicted to increase even more in the future [ 13]. In other words,\ninformation overload , which simply put is about receiving too much information\n(to handle) [ 20], sometimes impairs the human ability to make use of available\ninformation. As the right pieces of information have the potential to be of value\nto some individuals or groups, it is desirable to possess a capability that takesadvantage of the possibilities of online data to the largest extent possible.\nA set of tools that enable users to sift through huge amounts of data in search\nof sought after information that is relevant to them, is software in the form of datamining and other analytical tools. It is generally thought that the end outcomes for\nvarious stakeholders will improve when such tools and techniques are employed in a\nsystematic fashion. Even if that assumption seems highly plausible, there appears tobe limited research that either con\ufb01rms or proves such a hypothesis wrong. On the\ncontrary, the (positive) value of text mining and similar techniques are often taken\nas a given fact in the literature.\nThis work seeks to examine the actual contribution of the use of a text mining\ntool for a real life intelligence task. In the literature much attention has been paid to\nthe investigation of matters related to the usability of software in terms of design and\nfunction [ 44]. When it comes to the actual usefulness of software in relation to some\ntask, considerably less scholarly articles are available. Furthermore, it is not always\nobvious that computer software contribute to the productivity of organizationsat all [ 35,45]. It is obviously of value to know if a piece of software actually\ncontributes to overall organizational goals or not. In this chapter the usefulness of a\npiece of text analysis software for the purpose of intelligence analysis is examined.\n1.1 The Intelligence Field\nBecause the context of this case study is set in an intelligence analysis setting, somewords about the intelligence \ufb01eld is given to enlighten the reader.\nIt seems that intelligence is not consistently de\ufb01ned in the literature, as many\narticles within the \ufb01eld begin with quite extensive discussions about basic def-initions [ 6]. In the national level context, however, Bimfort already in 1958 [ 7]\nsuggested that intelligence is about collecting and processing information about\nforeign countries and their agents, that is needed by a government for its foreignpolicy and national security goals. This de\ufb01nition will stand for the purpose of this\nchapter as well.\nAccording to U.S. doctrine Joint Publication 2-01 [ 51], which has similar\nde\ufb01nitions as other countries, the objective of joint intelligence operations in a\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 223\nmilitary context is to provide accurate and timely intelligence to commanders that\ngives them an understanding of the operational environment with, in particular,\nregard to adversary forces, capabilities, and intentions. The goal of intelligenceanalysis is therefore to produce accurate assessments of the current state of affairs,\nas well as suf\ufb01ciently good estimates about the future that can be of use to various\ndecision-makers [ 14].\nAlthough this mission is simple enough in theory, (good) analytical work is not\ntrivial. A number of uncertainties affect the quality of the \ufb01nal analysis, and the\nprocess itself is not straightforward as it typically involves a mixture of imaginativeand critical reasoning [ 8]. Sometimes analysts are in possession of a piece of\ninformation, and in search for missing pieces to \ufb01t into a hypothesis. At the same\ntime the analysts may also search for supportive evidence for multiple hypothe-ses [ 8]. In addition, most intelligence processes strive to collect information from\nseveral mutually independent sources in order to, hopefully, reduce uncertainty.\nOpen source information that is readily available and easily accessible is certainlyoften used in this respect.\nIn a military intelligence context the scope of the analytical interest for different\n\u201csituations\u201d as discussed above, varies with the hierarchical levels of war, e.g., thetactical, the operational, and the strategic level, which highlights diverse aspects\nof awareness. Although the exact meaning and classi\ufb01cation of the different levels\nvary between nations and organizations, the existence of multiple hierarchical levelsis uncontroversial. In the following, Swedish doctrine is used to exemplify. The\ndifferences and boundaries between the levels have diminished over time due to the\ndynamics and complexities of modern con\ufb02icts. The same pieces of informationcan sometimes answer to the intelligence requirements of multiple levels. The\ngreatest distinguishing factor between the levels is the time perspective [ 48]. The\ngoal of the tactical level intelligence function is to support the individual (military)unit in its planning and mission execution. The tactical level deals with a limited\ngeographical region on the battle\ufb01eld and the character of the questions that need\nanswers are concrete. The relevant timeframe for these activities is the immediate;it ranges from a day to a week, and sometimes from an hour to days [ 48]. The\ngoal of the operational level intelligence function, on the other hand, is to support\nongoing or planned (military) operations. Here the area of operation (theatre) is theregion of interest. The questions are diverse, both concrete and abstract [ 24], and\nthe timeframe is the intermediate; it typically ranges from a week to months [ 48].\nAt the strategic level the goal is to answer questions that may be abstract and covera diversity of different topics with unclear relations, and to produce intelligence\nin the form of estimates that can be used to, e.g., create policies and military\nplans, and to inform about security measures on a national level. The timeframe forstrategic intelligence ranges from months to several years [ 10]. The strategic level,\nthus, concerns and anticipates events of far-reaching political, diplomatic, social,\neconomic, and military signi\ufb01cance, that often revolve around the questions of war,peace, and stability [ 37].\nWith the wide variety of requirements as indicated above, a national level\nintelligence agency needs to have different types of intelligence sources at its\n224 S. Varga et al.\ndisposal. A commonly accepted taxonomy divide some of the source types into\nopen source intelligence (OSINT), human intelligence (HUMINT), measurements\nand signatures intelligence (MASINT), signals intelligence (SIGINT), and imageryintelligence (IMINT) [ 14, p. 104]. With the rapid growth of the Internet and the\navailability of data, OSINT has grown to become an important collection discipline\nfor intelligence purposes; not only for government intelligence functions, but alsofor civilian use [ 46]. OSINT, more speci\ufb01cally, is intelligence that ful\ufb01lls speci\ufb01c\nintelligence requirements and is produced from publicly available information from\nboth traditional media and web-based sources, that is, information that anyone canlawfully obtain by request, purchase, or observation [ 51]. Glassman and Kang [ 22]\ncharacterize the baseline work methods for OSINT work to be (1) the search\nfor relevant information, (2) the organization of the information, and (3) thedifferentiation of it, with the goal of transforming (converting, translating, and\nformatting) text, graphics, sound, and motion video in response to users\u2019 intelligence\nrequirements [ 51].\nHeuer [ 27] suggests that there are in general two fundamental but different meth-\nods to address intelligence analysis problems: the conceptually driven approach, and\nthe data-driven approach. The conceptually driven approach requires the presenceof an analytical schema, e.g., some model, and the results of the analysis are directly\ncorrelated to the availability and the quality of data that is fed into the model. For\ndata-driven analysis, on the other hand, there may not be a well-developed analyticalmodel available, but rather an abundance of available data. In this latter case the\nchallenges are not mainly about acquiring the data, but rather to \ufb01nd and select\nthe relevant pieces of information that can be used to form sensible hypothesesfor the intelligence problem at hand. A potential source of error when using the\nconceptual approach, is that research has shown that long-standing general beliefs\nand preconceptions by analysts affect the results of assessments even if there isavailable data that support other outcomes [ 33].\nTo this respect the availability of vast amounts of data that the Internet provides,\nhas changed the work for intelligence analysts [ 18], and is a good match for the\nrequirements of data-driven analysis. In particular, it has been found that social\nmedia posts provide relevant data that may be exploited for intelligence analysis.\nSeveral types of analyses can be made based on social media data, e.g., text analysis,social network analysis, and trend analysis [ 47].\n1.2 Research Questions and Outline\nThe overall purpose of the research presented in this chapter is to investigate how\nautomated text analysis can contribute to solve ordinary intelligence analysis tasks.\nTo do this, a case study that sought to answer the following two research questionswas performed:\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 225\n\u2013 Is PhraseBrowser, a speci\ufb01c instantiation of a text analysis tool, perceived as\nuseful for solving typical analytical tasks?\n\u2013 Does the use of the text analysis tool improve the quality of a typical analytical\ndeliverable?\nTo address the research questions, a research design that asked analysts to make\nan intelligence assessment of a psychological operations case was created. The\ncase of the poisoning of the former Russian intelligence of\ufb01cer Sergei Skripal and\nhis daughter Yulia in Great Britain was chosen. The rationale for choosing thisincident was that it was well covered by multiple media outlets of different types\nas well as other data producing sources. The topic was reasonably well within\nthe ordinary \ufb01eld of interest for the studied subjects, the scope of the intelligenceanalysis requirement was fairly realistic, and some amount of different narratives\nand counter-narratives, e.g., obfuscation, could be expected to be launched and\nspread to \ufb02ourish on the Internet.\nThe remainder of this chapter is structured as follows. Section 2provides an\noverview of the area of psychological operations, and related work. Then, in Sect. 3,\na description of the text analysis prototype tool PhraseBrowser follows. Next,Sect. 4describes the undertaken methodology covering the research design, the\nobservational study setup, and the execution of the study. In Sect. 5the results are\npresented. Then, the \ufb01ndings as well as issues of validity are discussed in Sect. 6.\nFinally, the conclusions are presented in Sect. 7.\n2 Background\nAfter having introduced the intelligence \ufb01eld above, this section describes the\nframework for intelligence analysis , psychological and in\ufb02uence operations, and\nlists some related work.\n2.1 Intelligence Analysis\nThe basic process for producing intelligence is about collecting information, makinganalyses, and then creating an intelligence product that can form the basis for\ndecision-making. It is primarily a cognitive process, an activity that takes placein the analyst\u2019s own head. It is not always clear exactly how the assessment goes\nand how it ought to be done in different situations, but on a methodological level\nthere are strong links between the intelligence profession and that of scienti\ufb01cwork: intelligence work is largely about formulating hypotheses, and examining and\nfalsifying these hypotheses if possible. But there are also large differences relative\nto scienti\ufb01c work in that intelligence work has a connection to operational work andthe need to deliver forecasts within a given timeframe based on currently available\ninformation, regardless of whether it is judged to be of suf\ufb01cient quality or not.\n226 S. Varga et al.\nRather than having the character of a \u201csecret science\u201d in itself , the characteristic\nfeatures of intelligence work can thus be said to be about the (indeed often secret)\napplication of scienti\ufb01c methods and approaches on information and intelligence\nquestions that are operational and strategic, rather than scienti\ufb01c, in nature. In an\nanalysis of the intelligence subject, and in an attempt to go from established practice\nto a more structural approach of it, Agrell and Treverton [ 1, p. 279] state this in the\nfollowing terms:\nIntelligence analysis has the potential to become an applied science. Its purpose would be\nmanaging the uncertainty in assessments of threats and possibilities based on incomplete,\nunreliable, or uncertain data in a context in which demand requires those assessmentsirrespective of the limitations. De\ufb01ned in these terms, intelligence analysis stands out asa genuine cross-disciplinary science in-being, with a theoretical basis and a set of methodsnot limited to any single subject matter or \ufb01eld of analysis but rather adapted to everyspeci\ufb01c application.\nAs noted, management of information and its related uncertainty play a central\nrole, and the means to measure precision, quality, and utility\u2014so-called informationawareness [ 5]\u2014is crucial.\n2.2 Psychological Operations\nTheroot causes for armed con\ufb02icts, or indeed any controversies between humans,\nmay be of different kinds, e.g., ideological differences, competition for scarce\nresources, etc., but the end goal in con\ufb02icts is always to impose the will of one party\non the other(s) in one way or the other, as expressed by, e.g., the ancient Chinese war\ntheorist Sun Tzu [ 49], as well as the highly in\ufb02uential Preussian war theorist Carl\nvon Clausewitz [ 54]. But there are other methods to affect the will of an opponent\nthan by using physical force: psychological and in\ufb02uence operations are ways to\nachieve this.\nPsychological operations, Psyops, within the context of military operations is a\npart of offensive information operations that aim to in\ufb02uence perceptions, attitudes\nand ultimately change the behavior of foreign approved target audiences [ 50].\nAnother name for Psyops that is sometimes used, is military information supportoperations, MISO [ 52]. Such activities are sometimes seen as a key enabler in a\nmilitary commander\u2019s campaign plan [ 4,50], and they can be conducted with both\nshort-term and long-term goals, according to doctrine. The overarching informationoperations \ufb01eld also involves other activities such as civil affairs, computer network\nattack, deception, destruction, electronic warfare, operations security, and public\naffairs [ 4]. Psyops and related activities, however, are not only part of U.S. and\nNato doctrine, but integral parts of Russian, Chinese, and other countries\u2019 national\nsecurity or military doctrines as well [ 4]. A related term is in\ufb02uence operations,\nwhich consists of similar types of activities, which are not necessarily conductedin conjunction with military operations. In\ufb02uence operations primarily consist\nof non-kinetic, communications-related, and informational activities that aim to\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 227\naffect cognitive, psychological, motivational, ideational, ideological, and moral\ncharacteristics of a target audience [ 36]. In\ufb02uence operations can be carried out by\ngovernment organizations other than the military, as well as by civilian informationoutlets. Furthermore, operations can be conducted openly (with a named source),\ncovertly, and clandestine.\nThe boundaries between roles, mandates, and who does what, as well as between\nmilitary and civilian organizations, with regard to in\ufb02uence operations is not always\nclear-cut [ 36]. For the sake of simplicity, only the term Psyops is used in this text.\nThe approved targets for operations can be individual persons, groups and networks,adversary leadership coalitions, and the (mass) public [ 36]. On the defensive side\nof Psyops, a possible task would be to determine if oneself, or some other target\naudience, is on the receiving end of adversarial operations. Such operations couldaim to change the perceptions/views, clog the perceptions, or delegitimize credible\nnews outlets [ 39]. To accomplish such an analysis, Nato doctrine [ 39], which is used\nto highlight Psyops principles here, prescribes that a detailed examination of source,content, audience, media, and effect (SCAME) is carried out. The SCAME template\ncan also be used in the planning process for offensive operations.\n2.3 Related Work\nThere seems to be a general consensus about the perceived usefulness of data mining\ntools, in that they can help \ufb01nd useful information in many instances. Examples ofprecisely how such tools contribute to the information gathering efforts, however,\nand more to the point, the quality improvement of the end products, are harder to\n\ufb01nd. A study commissioned by the British Government [ 38], however, concluded\nthat text mining contributes with several bene\ufb01ts in the context of academic\nresearch. The study found one improvement to be overall increased researcher\nef\ufb01ciency and research quality. Mining was further attributed to bring about theability to \u201cunlock hidden information\u201d, i.e., insights about underlying non-obvious\nconnections between texts, as well as the capacity to develop new knowledge and\nthe ability to explore \u201cnew horizons\u201d [ 38, p. 19]. The conclusions were based on\nresults from several case studies.\nPal [ 41] listed application areas where data mining tools were of great use both\nwithin the public and the commercial sector. For the public sector, \ufb01elds such as,for example, scienti\ufb01c enquiry and research analysis, criminal investigation and\nhomeland security, via health insurance and healthcare applications, were found\nto bene\ufb01t from text mining. Within the purely commercial sector, areas such ascustomer segmentation and targeted marketing, \ufb01nance, etc., were mentioned.\nSeveral scholars have noted that publicly available data on the Internet can be\nsystematically used for intelligence purposes [ 18,40]. It has been observed that\nsome of the automated data processing techniques used for systematic processing\nof corporate data, i.e., business intelligence, have migrated into security intelli-\ngence [ 10], and that the further development of these techniques has the potential to\n228 S. Varga et al.\nprovide a competitive edge [ 12,31,42]. There are, however, challenges as of how\nto \ufb01nd and extract relevant and meaningful pieces of information relative to the task\nat hand.\nAutomated text analysis using methods and tools from the \ufb01eld of natural\nlanguage processing has been proposed as a way to off-load some of the selective\nand interpretative work from human intelligence analysts. With regard to moreclosely related government and military intelligence tasks, Guo et al. [ 23]d i dw o r k\non entity extraction from human-generated tactical reports to support intelligence\nanalysis. They extracted entities such as organizations, locations, persons, etc., withpromising results. Razavi et al. [ 43] sought to extract information about risks in\nmaritime operations.\nOther examples with applications from the commercial sector include work by\nHe et al. [ 25] that explored how the use of text mining was useful for companies\nin the pizza industry. They concluded that text mining of social media adds useful\npieces of information, for example, in companies\u2019 quests to understand the pizzam a r k e t .A l e xe ta l .[ 2] were able to show an increase in ef\ufb01ciency, e.g., by the\nreduction of work time, in a biomedical data system scenario where natural language\nprocessing technology was used for curation.\n3 PhraseBrowser\nThis section serves to describe the scope and function of the prototype toolPhraseBrowser. PhraseBrowser is continuously developed at the Swedish Defence\nResearch Agency. It is one of several prototypes in a framework, aiming to highlight\nthe possibilities given by web and text analysis tools to analysts. The developmentprocess of PhraseBrowser, to this respect, provides opportunities for researchers and\npractitioners to engage in mutually bene\ufb01cial discussions.\n3.1 Overview\nPhraseBrowser is a text analysis prototype tool designed to support analytical\nwork by processing Twitter data. The idea is to provide the user/analyst withseveral perspectives of the collected data through prede\ufb01ned themes. The different\nperspectives provide an overview of the data that may guide an analyst to select\ninteresting subtopics and drill down further to \ufb01nd speci\ufb01c contents of interest.Hence, the prototype tool may be useful both for monitoring a subject or area\nof interest, and for conducting research to answer speci\ufb01c questions. Although\nthe prototype tool comes with prede\ufb01ned themes, it is a relatively easy andstraightforward process to quickly add simple \ufb01rst versions of new themes. This\nversatility makes the tool relevant for analytical work that concerns a wide variety\nof topical issues as well as for time-sensitive tasks.\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 229\n3.2 Phrases\nPhraseBrowser presents phrases to the user sorted by so-called phrase types. A\nphrase is de\ufb01ned as a sequence of one or more words, and each phrase has a type. A\nfew example phrases (and their phrase types) from the set of tweets used in the study\nare: \u201clab says\u201d (phrase type: \u201cGeneral Phrase\u201d), \u201cBoris Johnson lied about Skripal\u201d(\u201cExplicit Untruth\u201d), \u201cUK\u201d (\u201cLocation\u201d), \u201cYulia\u201d (\u201cPerson\u201d), and \u201c30 questions\u201d\n(\u201cCounted Thing\u201d). See Table 1for more examples of phrase types and phrases.\nAt the time of the study there were more than 50 different phrase types of varyingquality available to the analysts.\nIn the interface the user can choose a type, e.g., \u201cCounted Things\u201d, leading to that\na list of phrases of that type are presented along with statistics on how many tweetsthe phrases were used in. To read the texts containing any particular phrase, e.g.,\n\u201c30 questions\u201d, the user simply clicks on that phrase. Each piece of text works as a\nlink to the original tweet on Twitter, where more context may be found by studyingthe content of corresponding accounts, etc.\nThe phrases may be identi\ufb01ed using any automatic method. In the version of the\ntool used in the observational study presented herein, a third party library was usedto identify entities (see Sect. 3.5), and the rule language described in Sect. 3.6was\nused for all other phrase types.\n3.3 Prede\ufb01ned Phrase Types and Filtering\nIn the current study the analysts worked with a set of prede\ufb01ned phrase types, and\nwere not able to alter them or add new ones. Table 1displays some of these phrase\ntypes, and in the following they are described a bit further:\n\u201cGeneral Phrases\u201d tries to capture any kind of content based on part of speech tags.\nThis is an example of a phrase type that results in many phrases\u2014perhaps toomany. It would probably be useful to exchange or complement this phrase type\nwith a machine learning method. For now this is the most general phrase type,\nprimarily used to explore content without looking for any of the speci\ufb01c contentthat most of the other phrase types try to capture.\n\u201cCounted Things/Persons\u201d is de\ufb01ned using other phrase types capturing counts,\nand at the same time \u201cthings\u201d and/or \u201cpersons\u201d. One possible use of this phrasetype is to look for differing numbers being given in some context. Sources may\nexaggerate the number of protesters at an event, for instance.\n\u201cEntities\u201d such as \u201cPerson\u201d, \u201cLocation\u201d, and \u201cOrganization\u201d are found by an entity\ndetector (see Sect. 3.5). These entities are reused by several of the other phrase\ntypes, e.g., the \u201cCounted Persons\u201d phrase type mentioned above.\n\u201cExplicit Untruths\u201d captures phrases that use any word in a long list of words\nexplicitly related to deception, propaganda, misinformation, fake news, etc. The\nidea is that it is potentially interesting whenever someone writes that something is\nTable 1 Examples of themes/types available in the PhraseBrowser tool along with phrases\nextracted from the data set used in the study\nTheme/Type Phrase #\nGeneral Phrases All 2,806,084\nlab says 9297\nused in Skripal poisoning 8842\nproduced in Russia 5284\ndisinformation campaign in Britain 4326\nwas in US 4205\nPorton Down research laboratory 3401\nresearch laboratory has told Sky News 3373\nto Sergei Skripal 3122\nthat Christopher Steele 2803\nof Yulia Skripal 2563\nCounted Things/Persons All 105,931\n60 Russian diplomats 1406\n30 questions 927\ntwo weeks 861\n14 simple questions 823\nhundred narratives 383\ntwo BBC colleagues 294\n20 European countries 280\n2800 Russian bots 232\n23 British diplomats 212\ntwo people poisoned 203\nEntities All 5,601,461\nSkripal 373,735\nRussia 113,772\nUK 107,982\nYulia 97,560\nSalisbury 32,903\nPorton 25,029\nNovichok 22,236\nPutin 22,017\nOPCW 19,292\nTheresa May 14,136\nExplicit untruths All 62,579\npropaganda 4532\nBoris Johnson lied about Skripal 1641\nMoscow\u2019s lies 427\nKremlin propaganda 417\nUK lies 204\nTheresa May is lying 155\n\u201cRussia bot\u201d narrative 153\nthe Skripal narrative 142\nlying about the source of Novichok 111\nDowning Street spin-master 82\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 231\na lie, fake, misinformation, etc.: either the statement is true, or the person writing\nit has an agenda ...H ence, these phrases often contain suspicious/interesting\nstatements that can potentially be used as a starting point for further analysis.In Sect. 3.7some simpli\ufb01ed rule examples for \u201cExplicit Untruths\u201d are presented.\nTo drill down into the data, each phrase and phrase type may be used as a \ufb01lter\nthat narrows the search to only include tweets containing the chosen phrases. Theresulting smaller data set can then be studied using the other available types and\nphrases. For instance, \ufb01ltering the data using the phrase \u201cTheresa May\u201d and then\nlooking at the phrase type \u201cExplicit Untruths\u201d, one would only obtain the \u201cExplicitUntruths\u201d that co-occur with \u201cTheresa May\u201d.\n3.4 PhraseBrowser System Overview\nFigure 1shows an overview of the PhraseBrowser system. Data is downloaded in\nreal time using the Twitter Streaming API and/or RSS feeds. The data is contin-uously processed by several analysis components, and stored in an Elasticsearch\n1\ndatabase search engine. The system architecture and construction is scalable andadapted to parallelization, using Docker\n2for packaging of subsystems and Kafka3\nfor distributing data between the subsystems.\nThe analysis phase contains several subsystems that process the data and adds\ninformation to it. The original data (including metadata, if any) is stored by thestorage component along with the result of the analysis as (additional) metadata.\nWeb data Analysis StorageVisualization\nTwitter\nRSSText analysisMessage queue\nImage analysis\nFig. 1 PhraseBrowser system sketch. The prototype tool can handle Twitter and RSS data, and\nanalyzes both text and images\n1https://www.elastic.co/elasticsearch/ .\n2https://www.docker.com/ .\n3https://kafka.apache.org/ .\n232 S. Varga et al.\nBy \ufb01ltering on the metadata, different parts of the stored data can be retrieved and\nvisualized in the user interface.\nPhraseBrowser can be run in real time on a data stream. However, depending\non the hardware used, the analysis may not keep up with the stream. In such cases\nPhraseBrowser continuously processes the latest tweet or RSS update, meaning that\ncertain pieces of data may never be processed. In the present observational study\na single ordinary PC was used to run the search query \u201cSkripal,skripal\u201d using the\nTwitter Streaming API, leading to that 5% of the tweets were discarded.\n3.5 Text Processing\nFigure 2magni\ufb01es the part of the (text) analysis steps relevant to this study. For\ndetecting most phrases, a rule-based approach [ 30] is applied. Each piece of text\nis \ufb01rst run through a natural language processing (NLP) library to divide it into\nsentences and tokens, lemmatize tokens and determine part of speech, and detect\nentities. The output from the NLP library is transformed into a simple speci\ufb01c text\nformat representing each sentence in the input data. The formatted text is then sent\nto the rule language engine, resulting in a set of phrases for each sentence. The\nphrases are added to the metadata for the tweet/text as described in Sect. 3.4.\nThrough this construction, the rule language engine is separated from the NLP\nlibrary and the only thing that has to be done to try a new library is to specify\nthe transformation from the NLP library output format to the speci\ufb01c text format\nneeded by the rule language engine. Transformations have been speci\ufb01ed for a few\ndifferent libraries. For the current work TwitIE [ 9], a GATE [ 15] pipeline specialized\nfor microblog texts, was used.\nThe transformation into the previously mentioned speci\ufb01c text format includes\nturning the entities detected by the NLP library into phrases, with phrase types\ncorresponding to the entity type. Hence, these phrases are originally detected by\nwhatever method the library uses. For entities this is usually a combined method\nbased on both dictionaries and machine learning.\nThe rule language, described further in Sect. 3.6, is \ufb02exible and constructed to\nmake it possible to detect anything from single words using simple word lists to\nmore complex phrases. It is language dependent in the sense that for any new\nlanguage it is necessary to create a parallel text processing pipeline according to\nNLP library\n Rule languagesesarhP txetdettamroF Text\nFig. 2 PhraseBrowser text processing. Each piece of text is processed by the NLP library, followed\nby a transformation of the NLP library output into a speci\ufb01c text format. Based on the formatted\ntext, the rule language engine produces phrases for each sentence\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 233\nFig.2. However, after an initial learning period, it is easy to quickly create basic\nphrase types for a new language. So far processing pipelines and rules for English\nand Swedish have been implemented.\n3.6 PhraseBrowser Rule Language\nThe rule language can be compared to regular expressions, but on token (word)level rather than character level. The concept is inspired by many previous such\npattern detection methods, like for instance Hearst\u2019s patterns for \ufb01nding hyponymy\nrelations [ 26,32].\nEach phrase type is de\ufb01ned using several rules. The rule language allows for\nreferences to other phrase types, making it possible to reuse solutions and create\nmore sophisticated rules. The rule engine processes each sentence by applying therules in order of complexity, making sure that a rule referring to another rule is\napplied after the rule it is referencing has already been applied.\n4Every result is\ntemporarily kept in a data structure containing information about position in thesentence, so that results do not need to be found twice. This makes the rule engine\nef\ufb01cient, and less likely to become the bottleneck of the larger system. However,\nwith a huge set of rules and/or rules that are too generic and always \ufb01nd phrases, therule engine could still become a problem.\nDuring the text analysis the rule language is applied to a single sentence at a time.\nIf larger text blocks were to be considered, i.e., several sentences are used, too manyphrases would be selected. Hence, to capture information that is distributed over\nseveral sentences, other methods need to be used. Such methods were, however, not\nused in the study presented herein, and will therefore not be discussed further.\n3.7 PhraseBrowser Rule Language Examples\nTable 2shows a few simple examples of rules written with the rule language. The\nleft column contains rules for two different example phrase types called \u201cviolence\u201d\nand \u201cviolence_in_location\u201d. The \ufb01rst phrase type is a word list that simply detects\nwhenever the listed words appear, as in the example sentences in the right column.The rule language has several features that allow for creating more useful word lists,\nsuch as using the lemma instead of the actual token and using part of speech tags.\nThe phrase type \u201cviolence_in_location\u201d contains two rules that reference the\n\u201cviolence\u201d phrase type and the entity type \u201cLOCATION\u201d. The two rules also allow\n4Circular references are not allowed.\n234 S. Varga et al.\nTable 2 Simple examples of the PhraseBrowser rule language\n# Phrase type and rules Example text\nname:violence\n1 violence London has seen a lot of violence .\n2 \ufb01st \ufb01ght There is a \ufb01st \ufb01ght in London.\nname:violence_in_location\n3 !a(LOCATION) !any[*] !a(violence) London has seen a lot of violence .\n4 !a(violence) !any[*] !a(LOCATION) There is a \ufb01st \ufb01ght in London .\nThe left column shows simple rules, with rule numbers for convenience. The phrase type\n\u201cviolence_in_location\u201d reuses the phrase type \u201cviolence\u201d. The right column provides examplesof applying the rules. The boldface part of the example sentences is what would be found by therule in the same row\nfor any number (zero or more) of any kind of token in between.5The \ufb01rst rule in\n\u201cviolence_in_location\u201d (row 3 in Table 2) therefore could be read as:\na location entity, followed by zero or more appearances of any token, followed by either\n\u201cviolence\u201d or \u201c\ufb01st \ufb01ght\u201d.\nThe second rule (row 4 in Table 2) can be interpreted analogously. In practice\nthe \u201cviolence_in_location\u201d rules would detect too many uninteresting phrases, assentences may be long and the mentioning of a location does not necessarily relate\nto where the \u201cviolence\u201d is taking place. To overcome this problem, the rule language\nhas features for stopping phrases that contain certain tokens (or phrase types)between parts of the rules, and it also allows for requiring the presence or absence\nof certain tokens (or phrase types) within the current sentence.\nIn Table 3some simpli\ufb01ed examples of the rules for the \u201cExplicit Untruths\u201d\nphrase type are presented. The rules show the expressive power of the rule language:\nif the building blocks are well thought-out, the rules can become capable of\ndetecting many different kinds of relevant phrases. It is often easier to split morecomplex phenomena into parts. The \u201cExplicit Untruth\u201d rules used in the study,\nfor instance, are split into a few subtypes. The precise rule structure can be\naccomplished using linguistic insights, but more importantly it should be based onthe data at hand and be useful for the analyst.\nIt is imperative that either the analyst is actively involved in the creation of the\nrules or works in a team with an expert, since otherwise the analyst may interpret theresults erroneously. An analyst at the least needs to be made aware of the limitations\nof the rule language. Trial and error brings the analyst a long way in creating rules\nthat \ufb01nd many relevant examples, though. The precision can become high enough,while the recall obviously cannot be guaranteed.\n5It is possible to specify any number of repetitions, like for instance two to three tokens, as well as\nspecifying that only tokens from other phrase types are allowed in the repetition.\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 235\nTable 3 Simpli\ufb01ed examples of the \u201cExplicit Untruth\u201d rules\n# Phrase type and rules Example text\nname:u_basic\n1 lie Boris Johnson liedabout Skripal\n2 propaganda It\u2019s all Kremlin propaganda\n3 spread rumor John spreads rumors about Paul\n4 misinformation The \ufb01ght against misinformation\nname:u_obj\n5 !a(PERSON) Boris Johnson lied about Skripal\n6 !a(LOCATION) It\u2019s all Kremlin propaganda\nname:untruth\n7 !a(u_basic) That\u2019s just lies\n8 !a(u_obj) !a(u_basic) It\u2019s all Kremlin propaganda\nMany UK lies today\n9 !a(u_obj) \u2019s !a(u_basic) Have you heard Moscow\u2019s lies ?\nWe are used to John\u2019s misinformation\n10 !a(u_obj) !a(u_basic) about !a(u_obj) Boris Johnson lied about Skripal\nJohn spreads rumors about Paul\nThe left column shows simple rules along with rule numbers, and the right column shows examples\nof applying these rules. The boldface part of the text examples is what would be found by therule in the same row. Only the last phrase type, \u201cuntruth\u201d, is presented to the user. The othersprovide partial solutions. Note that rules 8\u201310 have been applied to two texts each, exemplifyingthe expressive power of the rule language\n3.8 New and Improved Rules\nAn advantage of the PhraseBrowser rule language as well as other similar rule\nlanguages, is that they allow a user to quickly add rules that capture new themes\nof interest. The ability to modify the rules is an important feature of the tool insituations when the prede\ufb01ned themes do not match a speci\ufb01c topic and there are\ntime constraints involved. Quickly adding a \ufb01rst version of a new theme is as easy\nas adding a word list containing some keywords. Although the obvious aim is tocapture precisely everything that is relevant to a speci\ufb01c investigation, it is better\nto be able to retrieve at least some amount of desirable information through the\ninclusion of new rules, than risk ending up with insuf\ufb01cient data or no data at all. Atthe same time it is important to minimize the retrieval of noise, e.g., irrelevant data,\nwhich risks to burden the analysts tasked with interpreting the results.\nIn the present observational study the analysts worked with a set of prede\ufb01ned\nphrase types, and could not alter them or add new ones. If they had had that\npossibility, after studying the data they would perhaps have added phrase types for\n\u201cpoisons\u201d and \u201clab results\u201d to capture more of what was written about those topics.They could then, for example, easily have gone on to study what was written about\npersons or untruths mentioned in connection to those topics using the prede\ufb01ned\nphrase types.\n236 S. Varga et al.\nWhile studying the results of using a \ufb01rst version of a rule, it is quite common to\nrealize ways to adapt and extend it. Interesting phrases that appear in the texts that\nwere captured can be added to the rule. Rules that capture irrelevant phrases canbe altered using different features of the rule language. To this end, a user interface\nfor interactive development of rules has been implemented for PhraseBrowser. This\ninterface allows the analyst to iteratively re\ufb01ne the phrase type to capture morerelevant data.\nIf a speci\ufb01c information requirement occurs in several investigations or over\ntime, more effort could be put into studying the resulting data to improve theinformation gathering. Any number of methods could be used, including creating\nmore sophisticated rules or training a machine learning model suited for the task.\nThe goal is always to assist the analysts, and the rule language helps to put a \ufb01rstattempt in place quickly. A more sophisticated method (based on rules, machine\nlearning, or any other method) can always be combined with the other phrase types\nto allow for varied ways to study the data. Also, whenever a new phrase type isadded, many new combinations become possible. These combinations as well as\nthe separate phrase types can be invaluable when a new subject needs to be studied.\n3.9 PhraseBrowser Interface\nFigure 3shows the PhraseBrowser interface. Here 1,140,608 tweets have been\ndownloaded using the Twitter search query \u201cSkripal,skripal\u201d, as can be seen in thetop gray area. In the left part (the blue area entitled \u201cPhrases\u201d) the phrase type\n\u201cPerson\u201d has been chosen and in the list of identi\ufb01ed persons \u201cBoris Johnson\u201d is\nselected (the line is shaded). The tweets in the right part consequently all contain\u201cBoris Johnson\u201d. Should any of the tweets seem interesting, it is possible to read\nthem in context on Twitter by clicking on them.\nBoth the list of phrases and the list of tweets are usually much longer than what\ncan be seen in the interface without scrolling through the lists. The count displayed\nnext to the phrases denotes the number of tweets the phrase appears in, and the\nnumber presented before each tweet denotes the number of retweets.\nTo the left of each phrase in the left part of the user interface there are two buttons.\nUsing the right button the user can plot the number of appearances of the phrases\nover time (not shown in this book chapter). When pressing the left button for aphrase a \ufb01lter temporarily removing all tweets not containing that particular phrase\nis applied, which also removes all phrases not co-occurring with that particular\nphrase. In the example in Fig. 3all phrases of type \u201cExplicit Untruth\u201d have been\napplied as \ufb01lter, meaning that all displayed tweets contain both \u201cBoris Johnson\u201d\nand a phrase of the type \u201cExplicit Untruth\u201d. This \ufb01lter is shown in the top gray area\nas \u201cAll Untruth\u201d.\nSeveral \ufb01lters can be used at the same time. For instance one could go on and\n\ufb01lter on \u201cBoris Johnson\u201d in addition to \u201cAll Untruth\u201d and then look at the phrase\ntype \u201cLocation\u201d to see which locations are mentioned in tweets containing both of\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 237\nFig. 3 The PhraseBrowser user interface. The gray area at the top is the \ufb01lter area, showing the\nTwitter search query, the number of downloaded tweets, as well as any \ufb01lters that are active. Inthe blue \u201cPhrases\u201d area to the left the user can choose a phrase type (\u201cPerson\u201d in the \ufb01gure), andthe corresponding phrases are displayed at the bottom. The \u201cTweets\u201d area to the right displays thetweets that contain the chosen phrases in the blue area (\ufb01ltered by the \ufb01lters in the gray area). Boththe \u201cPhrases\u201d and the \u201cTweets\u201d areas have \ufb01lter search boxes that allow the user to search amongthe phrases and tweets\nthese \ufb01lters. Each \ufb01lter can also be switched to its opposite, so that, for instance,\nonly tweets not containing \u201cBoris Johnson\u201d are shown.\nThe example in Fig. 3, as described in the previous paragraphs, shows one\nsnapshot of the work an analyst could use the tool for. By \ufb01ltering on \u201cAllUntruth\u201d he/she solely gets tweets containing explicit untruths. These tweets may\nbe interesting since they are likely to contain accusations regarding the truthfulness\nof statements centered around the Twitter search topic. To get more perspectives onthe accusations, the analyst could use several of the other phrase types. For instance\nhe/she would likely use the phrase type \u201cGeneral Phrases\u201d to obtain an overview\nof the content. In Fig. 3the phrase type \u201cPerson\u201d has been used, so that the list of\nphrases to the left shows person names that have been seen in tweets containing the\naccusations. For some reason the analyst takes particular interest in \u201cBoris Johnson\u201d\nhere, and reads the tweets containing both this name and explicit untruths. This mayprovide an insight that leads the analyst to follow up by other means or use other\nphrase types to browse the data.\n238 S. Varga et al.\n4 Method\nThis section describes research design, observational study setup and execution, as\nwell as contextual factors that were present at the time of the study.\n4.1 Research Design\nThe observational study participants ( N=8) were evenly split into two teams. One\nteam was equipped with their usual set of tools, and the other team also had theirordinary tools, but was in addition provided with the PhraseBrowser text analysis\ntool. Hence, the general methodological approach was to collect data and compare\nthe results of the two teams. The prototype tool had previously been used andevaluated at the unit by their personnel for some time.\nThe goal was to \ufb01nd a group of study participants that could be assumed to bene\ufb01t\na great deal from the use of text mining tools in their ordinary line of work. To thisrespect a military unit from the Swedish Armed Forces agreed to participate in the\nstudy. One of the normal tasks of the unit is to make intelligence assessments of\nthe information environment. The participants consisted of active duty and reserveof\ufb01cers, as well as permanent and part-time soldiers and civilians. The aim was\nto put together uniform teams with respect to their educational level, experience,\nand gender. The team compositions were suggested by a seasoned analyst from themilitary unit, who consequently had some knowledge about the research design,\nand therefore was not allowed to personally participate actively in the observational\nstudy. The teams were constituted as indicated in Tables 4and5.\nTable 4 Team without the PhraseBrowser tool\nAge Gender Military category Work role/title Months on job Educational level\n34 Male Civilian Section chief 30 B.Sc.\n35 Male Civilian Analyst 24 B.Sc.\n34 Female Civilian Analyst 12 M.Sc.\n27 Female Civilian Analyst 15 M.Sc.\nThe designated team leader in the observational study is enlisted as the topmost person in the table\nTable 5 Team with the PhraseBrowser tool\nAge Gender Military category Work role/title Months on job Educational level\n26 Female Civilian Analyst 18 B.Sc.\n29 Male Civilian Analyst 3 M.Sc.\n37 Female Reserve Analyst 24 University\n23 Male Soldier Analyst 48 High school\nThe designated team leader in the observational study is enlisted as the topmost person in the table\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 239\n4.2 Intelligence Assessment Task\nThe analytical questions for the teams concerned psychological operations. The case\nof the alleged poisoning of the former Russian intelligence of\ufb01cer Sergei Skripal\nand his daughter Yulia was used to provide a realistic backdrop for the intelligence\nassessment questions. This event occurred on March 4, 2018 in Salisbury, England.\nAs the observational study task evolved around a Psyops scenario it was assumed\nthat text analysis would be helpful mainly for source andcontent analysis (see\nSect. 2.2). For source analysis it was hypothesized that PhraseBrowser may be of\nuse in the search for actors and authors of information used in a Psyops campaign.\nForcontent analysis it was hypothesized that PhraseBrowser can help extract factual\ninformation related to a campaign. The following questions/tasks were phrased:\n1. Identify and document alternative explanations that contradict the British expla-\nnation.\n2. Identify possible explanations and messages that might be part of a Russian\nin\ufb02uence campaign.\n3. Identify and document possible sources and routes for dissemination of pro-\nRussian messages according to question/task 2 above.\nThe two teams were asked to produce an intelligence assessment consisting\nof a maximum of three sheets of A4 paper. They were instructed to collect datafrom Swedish or English language information resources only. Every information\nelement used in the \ufb01nal assessment, was to be adequately referenced and, if\npossible, easily retrievable.\n4.3 Study Setup\nThe observational study was conducted in situ at the military unit. The twoteams resided in rooms that are normally used for similar (intelligence) work.\nThe observational study was carried out during a single day, with additional data\ncollection being done the day after.\nThe Twitter data used was selected according to the principle of relevance\nsampling [ 34]. The search keywords \u201cSkripal,skripal\u201d were used, which were\njudged to be discriminatory enough to capture all relevant tweets concerning thepoisoning event. The search query resulted in a data set of 1,140,608 tweets that\nwas downloaded through the Twitter Streaming API between March 19 and April\n23, 2018, meaning that the data collection began some days after the event.\nTo answer the research questions, two main types of data collection were carried\nout: (1) the subjective views of the usefulness of the software [ 16] were collected\nfrom the personnel who participated in the observational study, and (2) the objectiveviews of their performance were judged by external observers, i.e., the rating of\nthe quality of the intelligence assessment deliverables. Observations of the work\n240 S. Varga et al.\nconducted by the teams were also made. Hence, the data was collected in four\ndifferent ways:\n1. The team members answered questions about the perceived usefulness of\nPhraseBrowser.\n2. Four (4) subject matter experts, SMEs, were asked to judge the overall quality\nof the deliverables. They were to highlight what they saw as interesting pieces\nof information. The experts came from two different departments within the\nSwedish Armed Forces Headquarters and an independent think tank. Theirexperience from working as Russia analysts were 8, 10, 10, and 23 years.\n3. All the tweets that were used by the teams were put in random order, and all\nparticipants were asked to judge the value of each individual tweet. They judgedeach tweet with regard to its perceived value (1\u20134), and its perceived area of\nuse, e.g., (1) whether it added new hitherto unknown information, and/or, (2) if\nit served as a pointer to other related information sources, and/or, (3) if it (theaccount) was judged to be a new source itself.\n4. One senior researcher per team was deployed to observe the work processes.\n4.4 Observational Study Execution\nThe teams received the intelligence task simultaneously, and at the same timethey were also given time for preparation. During this 1 h preparation, they had to\ndesignate a team leader, make an overall working plan, and make a time schedule.At least one person per team was required to read through the background material\non the Skripal case from Wikipedia.\n6\nBoth teams were allowed to use all available information sources. Both looked\ninto other sources than Twitter. Both teams used web browsers checking sites like\ngoogle.com ,hashtags.org ,tweetdeck.twitter.com , etc. They also read the of\ufb01cial\ngovernment sites of various countries and traditional news outlets.\n5 Results\nIn this section the data that was collected and the observations that were made duringand after the observational study are presented.\n6https://en.wikipedia.org/wiki/Sergei_Skripal [May 2, 2018].\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 241\n5.1 Perceived Usefulness\nThe analysts who used PhraseBrowser expressed that they liked to use the tool in\ngeneral. Among the perceived bene\ufb01ts they noted that it can be useful as events\nunfold in an area of interest. The tool was judged to speed up the whole data\ncollection phase of an intelligence task. Another recurring theme in the observationsabout its usefulness was the breadth of the collection that enables the analyst to\ndiscover a multitude of perspectives, and allows the analyst to get an overview of\nan issue quickly. One respondent speci\ufb01cally pointed out that one of the strengthsof the tool was that it steers analysts to look at data without the restraints of their\npreconceptions. Another useful feature of the text analysis tool that was voiced,\nwas that it added valuable perspectives from apparently private citizens (and theiraccounts) in addition to the more readily available and accessible information from\nmainstream news and information outlets.\n5.2 Subject Matter Expert Evaluation\nThe four SMEs, who normally read material in other formats that are not puttogether under time constraints, had some general remarks about the format of the\ndeliverables, namely that they were short and not very well laid out. The SMEs alsopointed out that they knew most of the information already, even though there were\npieces of information that they had no prior knowledge about. Three of the four\nexperts stated that the deliverable produced by the PhraseBrowser-team consistedof more alternate explanations and was \u201cmore detailed\u201d. Otherwise, the experts did\nnot \ufb01nd any signi\ufb01cant differences between the deliverables.\n5.3 Information Fragment Value\nThe two teams drew information from a total of 25 unique tweets that contributed\nto their assessments. The team with PhraseBrowser used 15 tweets, and the teamwithout the tool found ten relevant tweets that they used. The sample size of the\ndata that was collected was too small to draw any general conclusions. However,\nsome inferences can be made based on the collected data:\n1. The ratio of very valuable tweets (rated with a score of 4), was almost equal\nbetween the team with PhraseBrowser (50%) and the team without it (47%).\n2. At least one member of the team without PhraseBrowser stated that 90% of the\ntweets that they used brought hitherto unknown information. The corresponding\nnumber for the team with PhraseBrowser was 67%.\n3. The members of the team with PhraseBrowser reported that the tweets that they\nused pointed to other potential sources to a larger extent than the other team.\n242 S. Varga et al.\n5.4 General Observations of Work\nIt could be observed that the participants were well trained and had a common\nunderstanding of the work process, and worked according to a well-established staff\nmethodology, which meant that they could quickly start working together and act as\na team. Concerning working procedures, many similarities between the two groupscould be seen with regard to how they approached the task and planned their work.\nBoth groups planned the work according to roughly the same schedule with two\nmajor work shifts with an interim discussion in between, and then a \ufb01nal synthesisdiscussion before the preparation of the \ufb01nal intelligence report. At the planned\ninterim synthesis discussions, the analysts told what they had found as a basis for\nbeing able to draw common conclusions and align the further work. After the \ufb01nalwork shift, longer discussions were held focusing on the possible explanations for\nthe poisoning of Skripal, as a basis for writing the end intelligence report.\nA whiteboard was used to note the conditions for the task with regard to\navailable time and preconditions regarding limitations, intelligence/information,\nsuccess factors, and immediate actions to be taken. For sharing joint work and\nworking together, a large screen that everyone could easily see was used. Beforelunch, plans were made regarding who should monitor which sources, the cutoff\ntime for further information collection, and how the work was going to be logged.\nDuring the afternoon the team leaders led the work and moderated the discus-\nsions that needed to be conducted. Discussions included, for example, which sources\nand objects that ought to be prioritized and monitored, and information sharing\namong the analysts concerning, for example, different spellings and synonyms tobe used for the information collection (\u201cSkripal\u201d, \u201cJulia\u201d, and \u201cSergei\u201d are equally\ninteresting words to look for). During the work alternative explanations of the cause\nof the poisoning of Skripal were listed on the whiteboard along with preliminaryintelligence con\ufb01dence levels. These con\ufb01dence levels were successively updated\nduring the exercise based on which and how many sources that spoke for or against\nthe respective explanations.\nBoth teams were judged to work systematically and be led by competent team\nleaders. They followed their work plans very well. Due to the severe time constraints\nthere was some amount of stress in both teams, but the atmosphere was calm andprofessional. Both teams planned for and had a short 15-min break during the\nobservational study, meaning that they invested an equal amount of time in solving\nthe task.\n5.5 Observations of Work Related to the Use of PhraseBrowser\nThe team with PhraseBrowser chose to designate one of the most pro\ufb01cient users ofPhraseBrowser as team leader, which resulted in that two individuals with limited\nexperience to operate the tool were tasked to do so. It was noted that they did\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 243\nnot take advantage of all of the useable features of the software, and that they\ncould not operate the software in an optimal manner. Otherwise, no signi\ufb01cant\ndifferences in the working conditions between the teams were observed. Membersof both teams explicitly strived to only take information that was collected during\nthe observational study into account, effectively suppressing their prior knowledge\nof the case.\nThe team with PhraseBrowser used the tool to \ufb01nd different explanations of the\nSkripal incident that were proposed in the Twitter data, and to some extent to also\nunderstand whether these explanations were used in some information operation.The latter is obviously very dif\ufb01cult, and proved too hard to achieve during the\nshort time allotted. The team used the tool similarly to the description in Sect. 3.9,\ntrying several different phrase types and the \ufb01lter functionality. Some of the phrasetypes proved useful, such as \u201cGeneral Phrases\u201d, \u201cEntities\u201d, and \u201cExplicit Untruths\u201d,\nas described in Sect. 3.3. Among other phrase types that were experienced as useful\nwas one that tries to capture citations and statements, one trying to \ufb01nd accusations,and a few more speci\ufb01c phrase types for \ufb01nding expressions of aggressions and\ntensions between different actors.\nFor each phrase type the team looked at phrases in order of how many times\nthey had been used. When \ufb01nding an interesting phrase, they sometimes looked at\na graph of how often it had been used over time. For each interesting phrase the\nteam always read one or more tweets these phrases appeared in. They collected thetweets that were interesting enough, taking the number of retweets into account. If\nthese tweets had a link in them they followed that link, sometimes resulting in useful\nlonger media articles.\n6 Discussion\nIn this section the theory for measuring perceived usefulness as well as some validityaspects of the study are discussed. A few notes about OSINT as a data source for\ntext mining are also provided, and the section concludes with some proposals and\nideas for improvement of the PhraseBrowser tool.\n6.1 Theory\nThis case study has aimed to examine usefulness , a subset of the overarching\nproblem of user acceptance\u2014why people embrace or reject computers and com-\nputer software. It has been shown that there are numerous variables that affect this\nacceptance. The widely cited technology acceptance model, TAM, conceived byDavis et al. [ 17], is used to model user acceptance. Davis [ 16] divides the variables\nthat affect acceptance into two main categories, the perceived ease of use and the\nperceived usefulness . The perceived ease of use is de\ufb01ned by Davis [ 16, p. 320]\n244 S. Varga et al.\nas the \u201cdegree to which a person believes that using a particular system would be\nfree of effort\u201d, or in other words: how easy it is to use a particular system. By\ncontrast, perceived usefulness is de\ufb01ned as \u201cthe degree to which a person believesthat using a particular system would enhance his or her job performance\u201d [ 16,\np. 320]. Later Venkatesh and Davis [ 53] presented an extended model, that they\ncalled TAM2, that among other developments, e.g., the introduction of socialin\ufb02uence processes, divided the concept of perceived usefulness into four factors:\njob relevance (to what extent the proposed system is able to support one\u2019s job),\noutput quality (how well the system performs), result demonstrability (to whatextent performance can be attributed to the system), and the perceived ease of\nuse, which in TAM2 is a direct determinant for perceived usefulness as well as\nfor the intention to use, and ultimately\u2014user behavior. With the extended model theperformance dimension was emphasized. In this study the aim has primarily been to\ninvestigate the job relevance and the output quality aspects in terms of this model.\nThe result demonstrability aspect was not emphasized, and ease of use questionswere not considered at all.\n6.2 Validity of the Study\nThe usefulness, or functional validity of some solution, is hard to measure because it\nis highly context dependent. A viable option is to compare the solution with another\ncompeting solution [ 34], which is what was intended here. A case study is by\ndesign a \u201csmall- N\u201d study [ 21] that cannot be expected to provide conclusions with\nstatistically signi\ufb01cant results. On the other hand, case studies have other strengths,\nsuch as that they can provide valuable insights that may be used as a basis for furtherresearch.\nThe participants were operational personnel who ranked the observational study\ntask to be on average realistic (scale: completely unrealistic/somewhat realis-tic/realistic/very realistic) compared to their normal tasks, and its relevance to\nbe high to very high (scale: limited/some/high/very high). In this respect, i.e.,\noperational personnel solving realistic tasks in a realistic setting, the results oughtto be judged to have a high ecological validity [ 11].\nA threat to the validity of the results, however, is the prior knowledge of the case\nby the observational study participants which could have affected the results. It wasinevitable that the teams used their background knowledge of the case, even though\nthey actively tried to avoid doing so. Therefore an effort was made to establish the\nlevel of participant background knowledge of the Skripal case. Some familiarity ofthe case was expected, but the main intention was to make sure that the two teams\noverall had a reasonably equal level of experience. Five of the eight participants\nstated that they had followed the events of the case brie\ufb02y, while three stated thatthey had followed them closely (scale: not at all/brie\ufb02y/closely/very thoroughly).\nThree of the participants answered that they had followed the case in other languages\nthan English (e.g., in Russian and German).\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 245\nThere are numerous factors that affect team performance. To reach reliable\nconclusions in the observational study it was important to account for such\ncontextual factors, and isolate the variables of interest, i.e., to the extent possible thevariables related to the contribution of the text analysis tool only. Among several\nmodels that seek to analyze performance shaping factors to minimize human errors\nand optimize performance [ 3], the cognitive reliability and error analysis method\n(CREAM) of Hollnagel [ 28] lists such factors. The CREAM model lists \u201ccommon\nperformance conditions\u201d, in three categories: human, technological and organi-\nzational. Here we extract the identi\ufb01ed factors of importance from the CREAMframework. CREAM suggests that eleven factors are of importance: (1) availability\nof resources, (2) training and experience, (3) quality of communication, (4) human-\nmachine interface and operational support, (5) access to procedures and methods,(6) conditions of work, (7) number of goals and con\ufb02ict resolution, (8) available\ntime (time pressure), (9) circadian rhythm, (10) crew collaboration quality, and\n(11) quality and support of organization.\nEqualization of the CREAM factors for the teams to the widest possible extent\nwas made. The teams were given the same conditions except for factors 1 (available\nresources), and 4 (human-machine interface and operational support), where oneteam was given PhraseBrowser, and the other one was not. Here it can be noted that\nit was both unexpected and unfortunate that the team equipped with PhraseBrowser\ndid not chose to assign the most pro\ufb01cient PhraseBrowser user(s) to operate thesoftware. If the software would have been used more to the full extent of its\ncapabilities, perhaps a bigger difference between the teams would have been the\nresult. However, the research team decided not to interfere with the internal workprocesses, i.e., the division of labor, of either team. It was not possible to make\nfactor 2 (training and experience) identical for the two teams, but a justi\ufb01cation for\nthe team composition has been presented in this chapter. Factor 8 (available time)was the same for both teams, but the participants stated that (on average) at least four\ntimes as much time would be needed to solve the given task suf\ufb01ciently well. Thus,\nit is reasonable to assume that the limited time affected the quality of the outputs forboth teams negatively but equally. Another aspect with regard to time that may have\naffected the results, is that the data collection of tweets started only some time, i.e.,\naround 2 weeks, after the incident took place.\n6.3 Open Source Intelligence as a Data Source for Text Mining\nSince the main information source for the intelligence assessments was OSINT, afew words on OSINT as a source is in place. One of the drawbacks that was found\nsome time ago and that has already been mentioned, is that the sheer amount of data\ncan be overwhelming for individuals or even organizations [ 29]. Moreover, even\nif a huge amount of data is easily accessible, much data still remain out of reach\nfor practitioners due to various constraints, e.g., lack of access to closed forums,\npay-for services, and password-protected sites that are prohibited, and there are\n246 S. Varga et al.\nalso other legal constraints such as copy restrictions that may hinder access [ 29].\nAnother drawback of publicly available information is that the quality of it can be\nquestionable\u2014after all, anyone can post just about anything on the Internet withoutdiscrimination.\nA signi\ufb01cant part of the OSINT problem is how to handle unstructured, soft\ndata, and Dragos [ 19] noted that there are multiple other uncertainties beside the\ncredibility of sources in such data, for example, intrinsic properties such as the\nambiguity of natural language and the presence of possible inconsistencies in the\nprovided information. On a smaller scale, practical obstacles such as the handlingof several obscure languages and the prevalence of \u201cslang\u201d language pose problems\nin the information organization work phase when it comes to unifying and cleaning\nthe data for further processing [ 29].\n6.4 Potential Improvements of PhraseBrowser\nDuring and after the observational study, the participating analysts provided several\nsuggestions on how PhraseBrowser could be improved. Some of these thoughts arerelated to and discussed here, along with a discussion on the improvements that have\nbeen made since the observational study, as well as some plans for future work.\nThe analysts found the phrase types and phrases useful. However, as there are\nalready many phrase types to choose from, it is not always easy to understand\nwhat all of them were created to support. The analysts would have liked to have\nshort explanations of the phrase types, and also some indication about how well-developed they are. The latter could partially be answered by displaying the number\nof rule lines in the phrase types.\nThe participants also realized the potential bene\ufb01ts of being able to create their\nown phrase types, and asked for this functionality. Since then a \ufb01rst version of a\nuser interface for rule development has been implemented. To be expressive, the rule\nlanguage is still, however, somewhat complex, so only dedicated analysts, perhapswith some computer science knowledge, can be expected to use it to its full potential.\nPhraseBrowser is focused on providing an overview of the textual content in\ntweets. The analysts would have liked to have access to more sources within theinterface, such as other social media platforms, news media, etc. Since then partial\nsupport for RSS feeds has been implemented.\nDuring the study the analysts found interesting tweets that led them to interesting\nTwitter accounts. They would have liked to get more information about these\naccounts within the prototype, and be able to search for speci\ufb01c accounts in the\ndata. This functionality will possibly be implemented in a separate, complementaryprototype.\nThere are many ways to \ufb01lter data that are implemented in the PhraseBrowser\nprototype, some of which were also mentioned by the analysts, such as URLs andlocation information derived from accounts. It is also possible to look at data during\nAutomated Text Analysis for Intelligence Purposes: A Psychological ... 247\nsmaller or larger time intervals and for chosen phrases, but the analysts would have\nliked this functionality to be more developed.\nAs described in Sect. 3.4, PhraseBrowser does not necessarily analyze every\ntweet when the data stream is too large compared to the computing power. Also,\nusing phrases as \ufb01lters, as described in Sect. 3.3, reduces the set of tweets under\ninvestigation. These facts are currently re\ufb02ected to some extent in the user interface,but the analysts would have liked them to be more prominent.\nPhraseBrowser, and the set of prototype tools it is part of, allows for a great deal\nof \ufb02exibility. After using the possibilities for a while, certain usage patterns mightemerge. For instance, it could under certain circumstances prove bene\ufb01cial to \ufb01lter\ndata by \u201cExplicit Untruths\u201d and a particular list of persons, before trying to explore\nwhat is written. If further methods for \ufb01ltering data, such as by image content oruser account meta data, are available, even more complex usage patterns may prove\nuseful. Such usage patterns could potentially be executed in advance, with the results\npresented using a digital dashboard.\n7 Conclusions\nThis chapter presents the results of a case study that seeks to investigate theperceived usefulness of a text mining tool and how it affects the quality of the end\nresult (output) of a realistic intelligence assessment task. Conclusions from a case\nstudy like this, however, should be interpreted in light of the limited scope of thestudy, e.g., the number of participants and the study design at large, and be regarded\nas preliminary. As outlined in Sect. 1, two research questions have governed the\npresent study:\n\u2013 Is PhraseBrowser, a speci\ufb01c instantiation of a text analysis tool, perceived as\nuseful for solving typical analytical tasks?\nIt was found that all analysts that used or had used the PhraseBrowser tool\npreviously, liked the tool and subjectively perceived it as useful. The main bene\ufb01t\nwas that it was thought to provide analysts with an opportunity to get an overviewof an issue quickly. The results indicate that its main contribution is to highlight\npointers to other sources making it possible to conduct further searches, and to a\nlesser extent also to \ufb01nd unique information and new Twitter sources.\n\u2013 Does the use of the text analysis tool improve the quality of a typical analytical\ndeliverable?\nBased on the inputs from the study participants and the SMEs, it was not possible\nto discern any major quality differences in the intelligence assessment deliverables.\nThe assessment of the deliverable from the team that operated the tool reportedthat it contained more diverse and \u201cmore detailed\u201d pieces of information than the\ndeliverable from the team that did not have the tool.\n248 S. Varga et al.\nIn the future the research methodology ought to be developed further, and more\nobservational studies with other groups of analysts should be undertaken. A speci\ufb01c\nobservational study could be to examine the usefulness of the PhraseBrowser toolfor intelligence analysis of ongoing events. It should also be noted that the value\nof PhraseBrowser was examined relative to the use of a range of other pieces of\nsoftware, e.g., the ones that the team that did not use the tool had at its disposal.To further strengthen the results of this study, future research should strive to also\nestablish the function of the additional software used, in some detail.\nAcknowledgements The authors would like to express their gratitude to the commander of the\nmilitary unit that took part in the observational study, and especially to the enthusiastic and highlyprofessional personnel involved in the preparation and execution of the study. This work wassupported by the Swedish Armed Forces, and by the European Union Horizon 2020 program (grantagreement no. 832921).\nReferences\n1. W. Agrell, G.F. Treverton, The science of intelligence: re\ufb02ections on a \ufb01eld that never was, in\nNational Intelligence Systems: Current Research and Future Prospects , ed. by G.F. Treverton,\nW. Agrell, Chap. 11 (Cambridge University Press, New York, 2009), pp. 265\u2013280\n2. B. Alex, C. Grover, B. Haddow, M. Kabadjov, E. Klein, M. Matthews, S. Roebuck, R. Tobin,\nX. Wang, Assisted curation: does text mining really help?, in Proceedings of the Paci\ufb01c\nSymposium on Biocomputing (PSB 2008) (World Scienti\ufb01c, Singapore, 2008), pp. 556\u2013567.\nhttps://doi.org/10.1142/9789812776136_0054\n3. M.A.B. Alvarenga, P.F.F. Frutuoso e Melo, R.A. da Fonseca, A review of the models for\nevaluating organizational factors in human reliability analysis, in Proceedings of the 2009\nInternational Nuclear Atlantic Conference (INAC 2009) (Brazilian Nuclear Energy Association\n(ABEN), Rio de Janeiro, 2009)\n4. L. Armistead (ed.), Information Operations: Warfare and the Hard Reality of Soft Power , Issues\nin Twenty-First Century Warfare (Brassey\u2019s, Washington, 2004)\n5. S. Arnborg, J. Brynielsson, H. Artman, K. Wallenius, Information awareness in command and\ncontrol: precision, quality, utility, in Proceedings of the Third International Conference on\nInformation Fusion (FUSION 2000) , vol. 2 (IEEE, Piscataway, 2000), pp. ThB1/25\u201332. https://\ndoi.org/10.1109/IFIC.2000.859871\n6. M. Bang, Military intelligence analysis: institutional in\ufb02uence. Ph.D. thesis, National Defence\nUniversity, Helsinki, October 2017. http://urn.\ufb01/URN:ISBN:978-951-25-2930-80\n7. M.T. Bimfort, A de\ufb01nition of intelligence. Stud. Intell. 2(4), 75\u201378 (1958)\n8. M. Boicu, G. Tecuci, D.A. Schum, Intelligence analysis ontology for cognitive assistants, in\nProceedings of the Third International Ontology for the Intelligence Community Conference(OIC-2008) (George Mason University, Fairfax, 2008), pp. 31\u201335\n9. K. Bontcheva, L. Derczynski, A. Funk, M.A. Greenwood, D. Maynard, N. Aswani, TwitIE:\nan open-source information extraction pipeline for microblog text, in Proceedings of the Ninth\nInternational Conference on Recent Advances in Natural Language Processing (RANLP 2013)(Association for Computational Linguistics, Stroudsburg, 2013), pp. 83\u201390\n10. A. Breakspear, A new de\ufb01nition of intelligence. Intell. Natl. Secur. 28(5), 678\u2013693 (2013).\nhttps://doi.org/10.1080/02684527.2012.699285\n11. U. Bronfenbrenner, Toward an experimental ecology of human development. Am. Psychol.\n32(7), 513\u2013531 (1977). https://doi.org/10.1037/0003-066X.32.7.513\nAutomated Text Analysis for Intelligence Purposes: A Psychological Operations. . . 249\n12. J. Brynielsson, A. Horndahl, L. Kaati, C. M\u00e5rtenson, P. Svenson, Development of computerized\nsupport tools for intelligence work, in Proceedings of the 14th International Command and\nControl Research and Technology Symposium (14th ICCRTS) (U.S. Department of Defense\nCCRP, Washington, 2009). Paper no. 48\n13. Cisco, Cisco visual networking index: forecast and trends, 2017\u20132022. White paper C11-\n741490-00, February 2019\n14. R.M. Clark, Intelligence Analysis: A Target-Centric Approach , 5th edn. (CQ Press, Washing-\nton, 2016)\n15. H. Cunningham, V . Tablan, A. Roberts, K. Bontcheva, Getting more out of biomedical\ndocuments with GATE\u2019s full lifecycle open source text analytics. PLOS Comput. Biol. 9(2),\ne1002854 (2013). https://doi.org/10.1371/journal.pcbi.1002854\n16. F.D. Davis, Perceived usefulness, perceived ease of use, and user acceptance of information\ntechnology. MIS Q. 13(3), 319\u2013340 (1989). https://doi.org/10.2307/249008\n17. F.D. Davis, R.P. Bagozzi, P.R. Warshaw, User acceptance of computer technology: a compar-\nison of two theoretical models. Manag. Sci. 35(8), 982\u20131003 (1989). https://doi.org/10.1287/\nmnsc.35.8.982\n18. M. Degaut, Spies and policymakers: intelligence in the information age. Intell. Natl. Secur.\n31(4), 509\u2013531 (2016). https://doi.org/10.1080/02684527.2015.1017931\n19. V . Dragos, An ontological analysis of uncertainty in soft data, in Proceedings of the 16th\nInternational Conference on Information Fusion (FUSION 2013) (IEEE, Piscataway, 2013),\npp. 1566\u20131573\n20. M.J. Eppler, J. Mengis, The concept of information overload: a review of literature from\norganization science, accounting, marketing, MIS, and related disciplines. Inf. Soc. 20(5), 325\u2013\n344 (2004). https://doi.org/10.1080/01972240490507974\n21. A.L. George, A. Bennett, Case Studies and Theory Development in the Social Sciences (MIT\nPress, Cambridge, 2005)\n22. M. Glassman, M.J. Kang, Intelligence in the internet age: the emergence and evolution of open\nsource intelligence (OSINT). Comput. Hum. Behav. 28(2), 673\u2013682 (2012). https://doi.org/10.\n1016/j.chb.2011.11.014\n23. J.K. Guo, D. Van Brackle, N. LoFaso, M.O. Hofmann, Extracting meaningful entities from\nhuman-generated tactical reports. Procedia Comput. Sci. 61, 72\u201379 (2015). https://doi.org/10.\n1016/j.procs.2015.09.153\n24. W.M. Hall, G. Citrenbaum, Intelligence Analysis: How to Think in Complex Environments\n(Praeger, Santa Barbara, 2009)\n25. W. He, S. Zha, L. Li, Social media competitive analysis and text mining: a case study in the\npizza industry. Int. J. Inf. Manag. 33(3), 464\u2013472 (2013). https://doi.org/10.1016/j.ijinfomgt.\n2013.01.001\n26. M.A. Hearst, Automatic acquisition of hyponyms from large text corpora, in Proceedings\nof the 15th International Conference on Computational Linguistics (COLING-92) ,v o l .2\n(Association for Computational Linguistics, Stroudsburg, 1992), pp. 539\u2013545\n27. R.J. Heuer, Jr., Psychology of Intelligence Analysis (Center for the Study of Intelligence,\nCentral Intelligence Agency, Washington, 1999)\n28. E. Hollnagel, Cognitive Reliability and Error Analysis Method (CREAM) (Elsevier, Oxford,\n1998). https://doi.org/10.1016/B978-0-08-042848-2.X5000-3\n29. A.S. Hulnick, The downside of open source intelligence. Int. J. Intell. CounterIntell. 15(4),\n565\u2013579 (2002). https://doi.org/10.1080/08850600290101767\n30. J. Jiang, Information extraction from text, in Mining Text Data , ed. by C.C. Aggarwal, C. Zhai,\nChap. 2 (Springer, Boston, 2012), pp. 11\u201341. https://doi.org/10.1007/978-1-4614-3223-4_2\n31. F. Johansson, J. Brynielsson, P. H\u00f6rling, M. Malm, C. M\u00e5rtenson, S. Truv\u00e9, M. Rosell,\nDetecting emergent con\ufb02icts through web mining and visualization, in Proceedings of the 2011\nEuropean Intelligence and Security Informatics Conference (EISIC 2011) (IEEE, Piscataway,\n2011), pp. 346\u2013353. https://doi.org/10.1109/EISIC.2011.21\n250 S. Varga et al.\n32. D. Jurafsky, J.H. Martin, Speech and Language Processing: An Introduction to Natural\nLanguage Processing, Computational Linguistics, and Speech Recognition , 2nd edn. (Prentice\nHall, Upper Saddle River, 2009)\n33. C. Koopman, J. Snyder, R. Jervis, Theory-driven versus data-driven assessment in a crisis: a\nsurvey of international security readers. J. Con\ufb02. Resolut. 34(4), 694\u2013722 (1990). https://doi.\norg/10.1177/0022002790034004006\n34. K. Krippendorff, Content Analysis: An Introduction to Its Methodology , 2nd edn. (SAGE,\nThousand Oaks, 2004)\n35. T.K. Landauer, The Trouble with Computers: Usefulness, Usability, and Productivity ,A\nBradford Book (MIT Press, Cambridge, 1995)\n36. E.V . Larson, R.E. Darilek, D. Gibran, B. Nichiporuk, A. Richardson, L.H. Schwartz, C.Q.\nThurston, Foundations of Effective In\ufb02uence Operations: A Framework for Enhancing\nArmy Capabilities (RAND Corporation, Santa Monica, 2009). https://www.rand.org/pubs/\nmonographs/MG654.html\n37. K. Lim, Big data and strategic intelligence. Intell. Natl. Secur. 31(4), 619\u2013635 (2016). https://\ndoi.org/10.1080/02684527.2015.1062321\n38. D. McDonald, U. Kelly, The value and bene\ufb01t of text mining to UK further and higher\neducation. Digital Infrastructure Directions Report, Doc# 811, Version 1.1, JISC, March 2012.https://www.jisc.ac.uk/reports/value-and-bene\ufb01ts-of-text-mining\n39. NATO, Allied joint doctrine for psychological operations. Publication AJP-3.10.1(A), NATO\nStandardization Agency, Brussels, October 2007\n40. D. Omand, J. Bartlett, C. Miller, Introducing social media intelligence (SOCMINT). Intell.\nNatl. Secur. 27(6), 801\u2013823 (2012). https://doi.org/10.1080/02684527.2012.716965\n41. J.K. Pal, Usefulness and applications of data mining in extracting information from different\nperspectives. Ann. Libr. Inf. Stud. 58(1), 7\u201316 (2011)\n42. N.A. Pollard, On counterterrorism and intelligence, in National Intelligence Systems: Current\nResearch and Future Prospects , ed. by G.F. Treverton, W. Agrell, Chap. 6 (Cambridge\nUniversity Press, New York, 2009), pp. 117\u2013146\n43. A.H. Razavi, D. Inkpen, R. Falcon, R. Abielmona, Textual risk mining for maritime situational\nawareness, in Proceedings of the 2014 IEEE International Inter-Disciplinary Conference\non Cognitive Methods in Situation Awareness and Decision Support (CogSIMA) (IEEE,\nPiscataway, 2014), pp. 167\u2013173. https://doi.org/10.1109/CogSIMA.2014.6816558\n44. F.E. Ritter, G.D. Baxter, E.F. Churchill, Foundations for Designing User-Centered Systems:\nWhat System Designers Need to Know about People (Springer, London, 2014). https://doi.org/\n10.1007/978-1-4471-5134-0\n45. D.E. Sichel, The Computer Revolution: An Economic Perspective (Brookings Institution Press,\nWashington, 1997)\n46. R.D. Steele, On Intelligence: Spies and Secrecy in an Open World (AFCEA International Press,\nFairfax, 2000)\n47. S. Stieglitz, L. Dang-Xuan, A. Bruns, C. Neuberger, Social media analytics: an interdisci-\nplinary approach and its implications for information systems. Bus. Inf. Syst. Eng. 6(2), 89\u201396\n(2014). https://doi.org/10.1007/s12599-014-0315-7\n48. Swedish Armed Forces, F\u00f6rsvarsmaktens underr\u00e4ttelsereglemente [The armed forces\u2019 intelli-\ngence manual]. Publication M7739-353025, Headquarters, Stockholm, December 2010\n49. S. Tzu, The Art of War , trans. by S.B. Grif\ufb01th (Clarendon Press, Oxford, 1963)\n50. U.S. Department of Defense, Joint doctrine for information operations. Joint Publication 3.13,\nJoint Chiefs of Staff, Washington, October 1998\n51. U.S. Department of Defense, Joint and national intelligence support to military operations.\nJoint Publication 2-01, Joint Chiefs of Staff, Washington, July 2007\n52. U.S. Department of Defense, Information operations. Joint Publication 3.13, Joint Chiefs of\nStaff, Washington, November 2012\nAutomated Text Analysis for Intelligence Purposes: A Psychological Operations. . . 251\n53. V . Venkatesh, F.D. Davis, A theoretical extension of the technology acceptance model: four\nlongitudinal \ufb01eld studies. Manag. Sci. 46(2), 186\u2013204 (2000). https://doi.org/10.1287/mnsc.\n46.2.186.11926\n54. C. von Clausewitz, On War , trans. by M. Howard, P. Paret (Princeton University Press,\nPrinceton, 1976). Originally published 1832\nOpen Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriatecredit to the original author(s) and the source, provide a link to the Creative Commons license andindicate if changes were made.\nThe images or other third party material in this chapter are included in the chapter\u2019s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is notincluded in the chapter\u2019s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Protecting the Web from Misinformation", "author": ["F Spezzano", "I Gurunathan"], "pub_year": "2020", "venue": "Open Source Intelligence and Cyber Crime \u2026", "abstract": "Nowadays, a huge part of the information present on the Web is delivered through Social  Media and User-Generated Content (UGC) platforms, such as Quora, Wikipedia, YouTube,"}, "filled": false, "gsrank": 101, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-030-41251-7_1", "author_id": ["u_5TCGoAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:IL9RAH1hI-sJ:scholar.google.com/&output=cite&scirp=100&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D100%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=IL9RAH1hI-sJ&ei=FrWsaM7kLPnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:IL9RAH1hI-sJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://gerdab.ir/files/fa/news/1400/12/24/56880_758.pdf#page=7"}}, {"title": "Ideological variation in preferred content and source credibility on Reddit during the COVID-19 pandemic", "year": "2022", "pdf_data": "Florida International Univ ersity Florida International Univ ersity \nFIU Digital Commons FIU Digital Commons \nCoronavirus Resear ch at FIU \n3-9-2022 \nIdeological v ariation in pr eferred content and sour ce cr edibility on Ideological v ariation in pr eferred content and sour ce cr edibility on \nReddit during the CO VID-19 pandemic Reddit during the CO VID-19 pandemic \nTendai Gwanzur a \nDepar tment of Epidemiology , Florida International Univ ersity \nWallace Chipidza \nCenter for Information Systems and T echnology , Clar emont Gr aduate Univ ersity \nChrist opher Kr ewson \nPolitical Science Depar tment, Brigham Y oung Univ ersity \nNicole Gatt o \nSchool of Community and Global Health, Clar emont Gr aduate Univ ersity \nFollow this and additional works at: https:/ /digitalcommons.fiu.edu/co vid-19_r esear ch \nRecommended Citation Recommended Citation \nGwanzur a, Tendai; Chipidza, W allace; Kr ewson, Christ opher; and Gatt o, Nicole, \"Ideological v ariation in \npreferred content and sour ce cr edibility on Reddit during the CO VID-19 pandemic \" (2022). Coronavirus \nResear ch at FIU . 96. \nhttps:/ /digitalcommons.fiu.edu/co vid-19_r esear ch/96 \nThis work is br ought t o you for fr ee and open access b y FIU Digital Commons. It has been accepted for inclusion in \nCoronavirus Resear ch at FIU b y an authoriz ed administr ator of FIU Digital Commons. F or mor e information, please \ncontact dcc@fiu.edu . \nIdeological variation in preferred content\nand source credibility on Reddit during\nthe COVID-19 pandemic\nWallace Chipidza1, Christopher Krewson2, Nicole Gatto3,\nElmira Akbaripourdibazar1and T endai Gwanzura4\nAbstract\nIn this exploratory study, we examine political polarization regarding the online discussion of the COVID-19 pandemic.We use data from Reddit to explore the differences in the topics emphasized by different subreddits according to political\nideology. We also examine whether there are systematic differences in the credibility of sources shared by the subscribers\nof subreddits that vary by ideology, and in the tendency to share information from sources implicated in spreadingCOVID-19 misinformation. Our results show polarization in topics of discussion: the Trump, White House, and eco-\nnomic relief topics are statistically more prominent in liberal subreddits, and China and deaths topics are more prominent\nin conservative subreddits. There are also signi \ufb01cant differences between liberal and conservative subreddits in their pre-\nferences for news sources. Liberal subreddits share and discuss articles from more credible news sources than conser-\nvative subreddits, and conservative subreddits are more likely than liberal subreddits to share articles from sites \ufb02agged\nfor publishing COVID-19 misinformation.\nKeywords\nCOVID-19, Reddit, misinformation, topic analysis, ideology, health, politics\nIntroduction\nBackground\nIncreasingly, Americans get their news from new media\nsuch as Reddit, Facebook, and Twitter, which have been\nimplicated in intensifying political polarization (PewResearch Center, 2019). While it is well-understood thatsuch new media democratize access to information thusmollifying the gatekeeping effect of legacy media(Andersen et al., 2016), these media make it easy forusers to customize their media diets, potentially increasingpolitical polarization (Young and Anderson, 2017). Redditis the \ufb01fth most visited website in the USA with over 400\nmillion unique monthly visitors\n1. Underscoring Reddit \u2019s\nimportance in academic research, a recent review foundmore than 700 studies leveraging data sets from Redditover the 2010 \u20132020 period (i.e. Proferes et al., 2021).\nThe website is a collection of independently moderated sub-communities \u2014known as subreddits \u2014organized around\nshared interests by subscribers. There are political subred-dits devoted to ideologies such as conservatism, libertarian-ism, liberalism, and socialism (Centivany and Glushko,2016). Given that there is no editorial process and indivi-\nduals are free to post news articles that conform to their\nideological biases on Reddit, it is worthwhile to explore\nwhether information sharing regarding COVID-19 onReddit re \ufb02ects political polarization (i.e. are conservatives\nand liberals getting their COVID-19-related news from\nthe same sources?).\nConcerns with spread of misinformation, especially\nthrough social media platforms, have accompanied the\nCOVID-19 pandemic. The problem of misinformation is\n1Center for Information Systems and T echnology, Claremont Graduate\nUniversity, California, USA\n2Political Science Department, Brigham Y oung University, Provo, Utah,\nUSA\n3School of Community and Global Health, Claremont Graduate\nUniversity, California, USA\n4Department of Epidemiology, Florida International University, Miami,\nUSA\nCorresponding author:\nWallace Chipidza, Center for Information Systems and T echnology,\nClaremont Graduate University, Claremont, CA 91711, USA.\nEmail: wallace.chipidza@cgu.edu\nCreative Commons Non Commercial CC BY -NC: This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 License (https://creativecommons.org/licenses/by-nc/4.0/) which permits non-commercial use, reproduction and\ndistribution of the work without further permission provided the original work is attributed as speci \ufb01ed on the SAGE and Open Access page (https://us.\nsagepub.com/en-us/nam/open-access-at-sage).Original Research Article\nBig Data & Society\nJanuary \u2013June: 1 \u201314\n\u00a9 The Author(s) 2022\nArticle reuse guidelines:sagepub.com/journals-permissionsDOI: 10.1177/20539517221076486\njournals.sagepub.com/home/bds\n\nserious enough to in \ufb02uence the outcomes of national elec-\ntions (Allcott and Gentzkow, 2017), but when it affectspublic health, misinformation can have life and death impli-\ncations (Baum, 2011). Thus, the value of credible informa-\ntion concerning public health measures for COVID-19prevention cannot be emphasized enough. Reddit has\nbeen implicated in spreading misinformation in the past\n(Au et al., 2020; Tasnim et al., 2020). The phenomenonof health misinformation has been dubbed the infodemic\nand has been highlighted by the World Health\nOrganization as posing serious threats to public health(Zarocostas, 2020). Given the amplifying effect of social\nmedia on infodemics, it is important to examine the cred-\nibility of information shared on Reddit when usersdiscuss COVID-19.\nOur study is based on Reddit data; thus, it is useful to\npoint out some attendant limitations of Reddit that have abearing on the interpretation of our \ufb01ndings. The Reddit\nuser base is mostly young (58% in the 18 \u201334 years\nrange), male (57%), and resides in the USA (plurality of49%) (Proferes et al., 2021; Statista, 2021). Our \ufb01ndings\nshould be understood incorporating that context. As we\nnote earlier, because of its popularity \u2014that is, 52 million\ndaily active users (Proferes et al., 2021) \u2014and impact on\nreal world events, Reddit is worth studying in its own\nright. Reddit \u2019s affordances make it possible to answer ques-\ntions on whether aspects of the COVID-19 pandemic are\nideologically politicized in ways that might not be possible\notherwise. The demographic limitations notwithstanding,our\ufb01ndings are still revelatory given how many people\nvisit Reddit daily and the platform \u2019s affordances that\nallow people to subscribe to subreddits based on sharedinterests.\nTo get a complete picture of the COVID-19 pandemic as\nit unfolds on Reddit, it is imperative to understand (a) the\ntopics that comprise its discussion, (b) whether ideology\nin\ufb02uences the topics that are emphasized in political subred-\ndits, (c) whether ideology in \ufb02uences preferred information\nsources, and (d) whether ideology in \ufb02uences preference\nfor sharing COVID-19-related misinformation. Thestudy \u2019s research questions are summarized as follows:\n1. What are the topics that comprise the discussion of the\nCOVID-19 pandemic on Reddit?\n2. How does a subreddit \u2019s expressed or implied political\nideology/bias in \ufb02uence the topics preferred for discus-\nsion by its subscribers?\n3. How does a subreddit \u2019s expressed or implied political\nideology/bias in \ufb02uence the COVID-19-related informa-\ntion sources preferred by its subscribers?\n4. How does a subreddit \u2019s expressed or implied political\nideology/bias in \ufb02uence the COVID-19-related misin-\nformation shared by its subscribers?Social media platforms like Reddit play an increasingly\nimportant role in disseminating information on health andpandemics (Baum, 2011). Examining these questions on\nReddit potentially explains how COVID-19 is being dis-\ncussed online, while also highlighting how political polari-zation affects public receptiveness to pandemic mitigation\nmessaging. We use structural topic modeling (STM) \u2014a\nmachine learning technique to automate topic discoverywithin large corpora of data (Roberts et al., 2014) \u2014to\nuncover the topics (clusters of co-occurring words) asso-\nciated with COVID-19 on Reddit. We then assign qualita-tive labels to the topics based on the most prevalent\nwords in each topic and the most representative text\nloading on each topic. In addition to topic discovery,STM allows for examining the effect of covariates (in our\ncase political ideology) on preferred topics (i.e. which\ntopics do conservative subreddits tend to prefer relative toliberal subreddits?). The r/coronavirus and r/science subred-\ndits provide useful comparisons for how non-political sub-\nreddits discuss COVID-19 relative to their politicalcounterparts.\nWhy Reddit?\nAnswering our research questions helps inform the degreeto which Reddit and other social media platforms fosterideological polarization regarding COVID-19. Our study\nalso builds knowledge on the effect of ideology on tendency\nto share COVID-19 misinformation potentially helpingbroader efforts to mitigate the pandemic. Our \ufb01ndings\nregarding ideological polarization on Reddit may re \ufb02ect\nunderlying political polarization in the USA in the contextof COVID-19.\nReddit has multiple affordances that make it amenable to\nanswering our research questions. First, it has an API thatallows for all sorts of queries regarding content submitted\nand discussed, the timing of that content, as well as other\nimportant metadata (e.g. number of upvotes and downvotes,upvote ratio, number of comments, etc.). The Reddit API is\nuniquely generous among social media platforms in the\nlevel of transparency that it offers to researchers, possiblybecause Reddit users are typically anonymous and the\nprivacy concerns that matter for Facebook for example\nmay not be as salient.\nEven more important, the organization of Reddit by sub-\nreddits makes it possible to examine how users subscribing\nto certain interests come to view certain phenomena. Ourcase of COVID-19 is telling; the numerous ideological sub-\nreddits surely weigh in on contentious issues such as possi-\nble cures for the disease, vaccine safety and ef \ufb01cacy, as well\nas the effectiveness of mitigation measures such as masks\nand lockdowns.\nIn the next section, we describe related theory and\nresearch. We proceed to describe our data collection and\nanalyses processes. After, we describe the results of our2 Big Data & Society\nstudy, discuss them as they relate to existing research, and\nconclude.\nRelated research and theory\nReddit features and political polarization\nExisting communication theories regarding health informa-\ntion sharing largely draw from studies on traditional media,\nsuch as newspapers, television, or other broadcasting ser-\nvices (Dalmer, 2017). However, social media platformslike Reddit are emerging as new media from which the\nincreasing majorities of the population obtain their news\n(Shearer and Matsa, 2018).\nAs Reddit is organized as a collection of common inter-\nest subreddits, with individuals free to subscribe to subred-\ndits of their choice, it enables \u201cindividuals to select outlets\nthat conform to their prior ideologies as in an \u2018echo\nchamber \u2019\u201d(Campante and Hojman, 2013: 80). In the\ncontext of Reddit, extant research suggests that individualsmay become dependent on speci \ufb01c subreddits for their poli-\ntical news. In fact, Reddit \u2019s subscription feature reinforces\nthis dependency effect to the extent that it facilitatesdefault exposure to content from subreddits to which a\ngiven user has subscribed (Massanari, 2017). Thus, we\nare likely to \ufb01nd political polarization in the discussion of\nCOVID-19 wherein subscribers to political subreddits\ndiscuss those issues which are helpful in justifying their\nideological projects. Furthermore, we expect political sub-reddits to select those information sources that are congru-\nent with their worldviews, such that subscribers to\nconservative subreddits may prefer right-leaning informa-tion sources and subscribers to liberal subreddits may\nprefer left-leaning information sources. Consequently, we\nexpect limited overlap in the information sources preferredacross conservative and liberal subreddits.\nThe concept of a \u201cgatekeeper \u201d(a person who determines\nwhat makes the news and what does not) is less relevanttoday as nearly anyone with modest resources can report\nnews via the internet (Young and Anderson, 2017). On\nReddit, users organize themselves into subcommunitiesknown as subreddits structured along shared interests.\nPolitics form a dominant means of organizing these subred-\ndits, bringing together users subscribing to similar ideolo-gies. Each user may then subscribe to a set of subreddits\nof their choice, the most popular and current content of\nwhich subreddits constitutes the user \u2019s default front page\nwhen logged in. One of the most common activities on\nReddit is the sharing of links to external news sources\n(Gaudette et al., 2021). These links are important sourcesof news which may unintentionally reveal important\nbiases in news exposure and consumption.\nFor our study, we expect political subreddits to cover\nCOVID-19 because of the magnitude of the importance\nof the event globally. While we expect liberal, conservative,and neutral subreddits to focus on a similar agenda\n(COVID-19) during our period of study, we also expectthat the various subreddit communities will frame this\nevent differently. Furthermore, we also expect that commu-\nnity members will be more likely to share news sources thatare biased toward their community \u2019s preferences.\nMetzger et al. (2020) show that people perceive attitude-\nconsistent news sources as more credible than attitude-challenging news sources, all else equal. Accordingly, we\nmight expect individual evaluations of a news source \u2019s\ncredibility to be correlated with the ideological leaningsof its content rather than on the actual quality or factuality\nof the news being reported. This may lead to the selective\nsharing of information to Reddit based on partisanship.On political subreddits, selective sharing is likely ampli \ufb01ed\nbecause moderation rules, norms, and groupthink are likely\nto shape media diets to re \ufb02ect their organizing ideologies,\nleading to variations in information source credibility and\npropensity to share COVID-19 misinformation according\nto ideology.\nEarlier research on Reddit suggests various mechanisms\nby which polarization emerges on the platform. For\nexample, Mills (2018) found that the subreddits supportingDonald Trump (i.e. r/the_donald) and Bernie Sanders (i.e. r/\nSFP) during the 2016 US presidential elections sourced\ntheir news from different outlets and that it was relativelyeasy for these communities to obtain news conforming to\ntheir preferred narratives. Content that conforms to a sub-\nreddit \u2019s dominant narrative is more likely to be upvoted\nthan content that challenges the narrative (Mills, 2018;\nSoliman et al., 2019). Rules in political subreddits that pro-\nhibit certain content and limit participation to supporters ofa political cause also encourage polarization (Mills, 2018;\nRobards, 2018). Thus, multiple features on Reddit includ-\ning organization by subreddits, default page, moderation\npolicies, link sharing, and upvoting (or downvoting) may\ncontribute toward polarization.\nData and methods\nWe used PRAW \u2014Reddit \u2019s Python API \u2014to collect titles of\nall posts containing the terms \u201ccoronavirus \u201dor\u201cCovid \u201d\nfrom 21 January 2020 to 9 July 2020. A variety of subred-\ndits dedicated to politics exist. On these subreddits, subscri-bers share information/news through posts of their own\ncontent or links to news articles which other users can\nalso comment and vote on. (Votes signaling approval arecalled upvotes, and those signaling disapproval are called\ndownvotes.) We followed the IRB guidelines at our institu-\ntion that determine that publicly available data is exemptfrom review. Furthermore, data is reported only in the\naggregate, with no means to link it to the real identities of\nReddit users.\nWe collected posts linking to external information\nsources from 12 subreddits with noted political biasesChipidza et al. 3\n(conservative and liberal), and from 2 that are politically\nneutral but with relevant coverage of the COVID-19 pan-demic (r/coronavirus and r/science)\n2. The number of posts\nwas 6268 but ultimately 5188 posts were used in the ana-\nlysis after \ufb01ltering out self-posts (i.e. those not linking to\nexternal news sources). For our purposes, the r/science\nand r/coronavirus subreddits are neutral based on their\nstated missions, that is, \u201cIncrease Knowledge \u201d(sic) and\n\u201c\u2026 monitor the spread of the disease COVID-19 \u2026,\u201d\nrespectively. In fact, one of the rules for participating in r/\ncoronavirus is to \u201c(a)void politics. \u201dThus, the stated foci\nof these subreddits are not to promote ideological goals\nand are thus considered politically neutral. We relied on\nthe descriptions displayed on the subreddits \u2019front pages\nto determine their ideological biases, and in the case of r/\npolitics and r/esist, we con \ufb01rmed the ideological bias to\nbe liberal as noted in recent literature (Soliman et al.,2019). The data for each post title included the source sub-\nreddit, the source URL for the post, and the time of posting.\nAlthough Reddit allows posting of original content(referred to as self-posts) by users, we only considered\nposts that linked to other information sources. Table 1\nshows the details of these subreddits and counts of titles ful-\ufb01lling our search criteria.\nWe employ STM to discover hidden topics within the\ntitles of COVID-19-related news articles posted in the 12political subreddits (six left-leaning and six right-leaning)\nand the two neutral subreddits (r/science focused on\nscience in general and r/coronavirus on COVID-19 inparticular).\nSTM is a generative algorithm wherein data are gener-\nated until parameters are found that maximize the probabil-ity of the observed input corpus (Roberts et al., 2014).\nMuch like other topic modeling algorithms (e.g. Latent\nDirichlet Allocation (LDA)), the goal of STM is to \ufb01nd dis-\ntributions of words over topics, and of topics over docu-\nments, that is, each topic is a mixture of words, and eachdocument is a mixture of topics (Roberts et al., 2014).\nThus, STM is similar to a soft clustering scheme in that a\nword can belong to multiple topics but with varying prob-abilities. Topics can be understood as sets of words occur-\nring together with greater than expected chance (Chandelier\net al., 2018). Unlike LDA, however, in STM topics can becorrelated, the topic proportion for a given document can be\nin\ufb02uenced by a set of covariates (i.e. using ideological bias\nas an example covariate, certain topics become much moreprevalent in a document for liberals compared to conserva-\ntives). The use of a given word in a topic can also be in \ufb02u-\nenced by a set of covariates that is, conservatives mayemphasize certain words within a given topic much more\nthan their liberal counterparts.\nThe incorporation of covariates in topic modeling thus\ninjects useful information into the inference process. As\nwith all topic modeling approaches, it is still up to the\nresearcher to interpret discovered topics within a corpusof data. The major advantage of using an automated\napproach lies in uncovering the dominant themes withinlarge corpora of text, which would require orders of magni-\ntude more effort if left to human labor.\nHere we make no a priori hypotheses as to the topics we\nmight \ufb01nd; rather, we adopt an inductive approach to topic\ndiscovery. We employed STM to understand (a) the topics\nof COVID-19-related discussions on Reddit (RQ1) and (b)how those topics varied by ideology (RQ2) in the corpus\nsince 21 January 2020. We use the stm package in R to\ncarry out our analyses (R Development Core Team, 2010;Roberts et al., 2014). After varying K\u2014the number of\ntopics contained within the corpus \u2014we settled on K=9\nbecause that is the number of topics that maximizes topiccoherence and held-out log-likelihood of generating the\nobserved corpus (Mimno et al., 2011). We ran the STM\nalgorithm over the Reddit corpus with spectral initializationto ensure that results were consistent across different runs of\nthe algorithm (Roberts et al., 2014), with maximum number\nof iterations equaling 1000. We used the function\ufb01ndThoughts in the stm package to help derive the qualita-\ntive labels of the generated topics. The function retrieves the\nmost representative posts loading on a given topic.\nFigure 1 summarizes the process of data collection and\nanalysis for the topics that comprise discussion of the\nCOVID-19 pandemic on Reddit.\nWe use source credibility ratings from\nMediaBiasFactCheck.com to examine differences in cred-\nibility of information sources shared by Reddit users\nacross ideological lines with linear regression (RQ3). The\nsite MediaBiasFactCheck classi \ufb01es over 3300 media\nsources according to factual rating and ideological biasand has been cited in academic research for the same\npurpose as our study (e.g. Mensio and Alani, 2019; Yu\net al., 2019). We assigned values between 1 and 6 corres-\nponding to the following factual accuracy ratings by\nMediaBiasFactCheck: very low (1), low (2), mixed (3),mostly factual (4), high (5), and very high (6). For robust-\nness checks, we tested whether the credibility differences\nacross conservative versus liberal subreddits would stillbe observed using another media credibility rating\nservice. We employed NewsGuard\n3, a service that \u201ctell(s)\nyou if a site is reliable as you browse online news. \u201d\nTo understand how a subreddit \u2019s expressed or implied\npolitical ideology/bias in \ufb02uence the COVID-19-related\nmisinformation shared by its subscribers (RQ4), we usedthe NewsGuardTech \u2019s database of sites \ufb02agged for\nCOVID-19 misinformation\n4. To date, 336 sites have been\n\ufb02agged as sources of COVID-19 misinformation, with the\n\ufb02agged content including myths such as that Sars-Cov-2\nwas stolen by Chinese spies from a Canadian lab, that 5G\ntechnology is linked to the spread of COVID-19, and thatthe National Institute of Allergy and Infectious Diseases\nDirector Dr Anthony Fauci would personally pro \ufb01t from\na COVID-19 vaccine\n5. We assigned a \ufb02ag of 1 to sites4 Big Data & Society\n\ufb02agged for misinformation, and 0 otherwise. We regressed\nthe\ufb02ag variable on subreddit ideology to determine the\neffect of subreddit ideology on sharing COVID-19 news\nfrom sites that spread misinformation.\nResults\nGenerated topics\nSetting K=9 as suggested by the topic coherence measure\nresulted in topics ordered by proportion in the corpus which\nwe labeled as follows: deaths (14.3%), Trump (13.5%),scienti \ufb01c research (12.9%), economic relief (11.6%),\nChina (9.8%), \ufb01ghting the pandemic (9.7%), protests\n(9.7%), White House (9.6%), and reopening debate(8.9%). It is worth noting that the scienti \ufb01c research topic\nreferences many ideas that have been deemed misinforma-\ntion by the WHO, for example, the idea that hydroxychlor-oquine is an effective treatment for COVID-19 (World\nHealth Organization, 2021). Table 2 summarizes thegenerated topics; it includes the labels we assigned to\neach topic, the most frequent words appearing in each\ntopic, its description, and example posts loading highly\non each topic \u2014one each from neutral, conservative, and\nliberal subreddits.\nEffect of ideological bias on topic distribution\nThe analysis of the Reddit corpus using STM shows that\nthere were statistically signi \ufb01cant differences in preferences\nfor seven of the nine topics. Conservative subreddits weremore likely than liberal subreddits to post about scienti \ufb01c\nresearch ( \u03b2=0.06, p=.00) (the beta corresponds to a prob-\nability, meaning that the probability of a post loading on thescienti \ufb01c research topic was 6% higher if posted in a con-\nservative subreddit relative to a liberal subreddit), deaths\n(\u03b2=0.05, p=.00), and China ( \u03b2=0.01, p=.04)\ntopics. On the other hand, liberal subreddits were more\nlikely than conservative subreddits to post about theTable 1. Subreddits, self-descriptions, biases, and COVID-19 post counts.\nSubreddit Subreddit self-descriptionSubreddit\nbiasNumber of\nCOVID-19 posts\nAskThe_Donald We are a PRO T rump, PRO Administration, and MAGA zone. This sub is\nfor people to learn and talk about Trump and Conservative subjectsConservative 372\nConservative The place for Conservatives on Reddit Conservative 561\nCoronavirus In December 2019, a novel coronavirus strain (SARS-CoV-2) emerged in\nthe city of Wuhan, China. This subreddit seeks to monitor the spread ofCOVID-19, declared a pandemic by the WHONeutral 738\nDrainTheSwamp Our country is now taking so steady a course as to show by what road it\nwill pass to destruction, to wit: by consolidation of power \ufb01rst, and then\ncorruption, its necessary consequence \u2014Thomas JeffersonConservative 548\nEnoughTrumpSpam Because the amount of T rump spam is *too damn high!* Enough \u0422\u0440\u0430\u043c\u043f\nSpamLiberal 430\nEsist Welcome to esist Liberal 362\nLibertarian A place to discuss libertarianism, politics, related topics, and to share\nthings that would be of interest to libertariansConservative 575\nPolitical_Revolution This subreddit is a part of the political revolution as envisioned by Senator\nBernie Sanders. We represent a movement promoting activism, raising\nsupport for progressive candidates, and spreading awareness for the\nissues focused on by the progressive causeLiberal 495\npolitics /r/Politics is for news and discussion about US politics Liberal 525\nredacted Welcome to redacted Conservative 154SandersForPresident Bernie Sanders 2020! Liberal 396\nScience This community is a place to share and discuss new scienti \ufb01c research.\nRead about the latest advances in astronomy, biology, medicine, physics,social science, and more. Find and submit new publications and popularscience coverage of current researchNeutral 441\nSocialism Welcome to r/socialism! This is a community for socialists to discuss\ncurrent events in our world from an anti-capitalist perspectivesLiberal 518\ntucker_carlson T ucker Carlson is the sworn enemy of lying, pomposity, smugness and\ngroupthink. His goal is to pierce pomposity, translate double-speak,mock smugness and barbecue nonsense as he debates people from allacross the political spectrum every weeknight on T ucker Carlson\nT onight!Conservative 153\nT otal 6268Chipidza et al. 5\nTrump topic ( \u03b2=0.05, p=.00), economic relief ( \u03b2=\n0.03, p=.00), White House ( \u03b2=0.02, p=.00), and\nreopening debate ( \u03b2=0.02, p=.00). There were no sig-\nni\ufb01cant differences in preference for the Black Lives\nMatter protests and \ufb01ghting the pandemic topics. Figure 2\ngraphically summarizes these differences.\nIt is also worth noting that the neutral subreddits (r/cor-\nonavirus and r/science) were more likely than biased Reddit\nsubreddits to post about scienti \ufb01c research ( \u03b2=0.15, p=\n.00), deaths ( \u03b2=0.11, p=.00), and \ufb01ghting the pandemic\n(\u03b2=0.08, p=.00) topics. They were less likely to post\nabout Trump ( \u03b2=\u20130.16, p=.00), economic relief ( \u03b2=\n\u20130.09, p=.00), White House ( \u03b2=\u20130.06, p=.00),\nChina ( \u03b2=\u20130.02, p=.00) and Black Lives Matter protests\n(\u03b2=\u20130.02, p=.00) topics. The neutral subreddits were\njust as likely as biased subreddits to post about the reopen-\ning debate. Figure 3 summarizes this information.\nEffect of subreddit moderation on topic distribution\nWe considered two kinds of moderation as covariatespotentially in \ufb02uencing topic distribution in discussing\nCOVID-19 news on Reddit. The \ufb01rst kind \u2014editing restric-\ntion\u2014relates to permission to submit edited titles; this kind\nof moderation was not signi \ufb01cant in all topics. The second\nkind\u2014domain restriction \u2014which relates to allowing sub-\nmissions from all domains, was not signi \ufb01cant save for\ntwo topics, that is, the White House topic, which was\nmore popular in subreddits enforcing this moderation, andthe\ufb01ghting the pandemic topic which was less popular.\nThe effect of moderation on topic distribution is thus\nlimited to only two topics, and is dwarfed by the effect ofideology.\nEffect of ideology on COVID-19 news source\naccuracy\nOf the 312 news sources shared by Reddit users with a\nrating from MediaBiasFactCheck, 10% had a very low\nfactual rating (e.g. Breitbart News and Gateway Pundit),\n1% low (e.g. Children \u2019s Health Defense and Global\nResearch Canada), 19% mixed (e.g. CNN and Fox\nNews), 11% mostly factual (e.g. Bloomberg News andNational Review), 55% high (e.g. ABC News and\nChicago Tribune), and 3% very high factual rating (e.g.\nAssociated Press and Reuters). Figure 4 shows the top 20news sources shared by subscribers of conservative and\nliberal subreddits, respectively. We assign low credibility\nto news sources with very low, low, and mixed factualratings from MediaBiasFactCheck, and high credibility to\nsources with mostly factual, high, and very high factual\nratings. Of the top 20 news sites posted in conservative sub-reddits, 60% had mixed or lower factual ratings. In contrast,\nthe equivalent number for liberal subreddits is 20%.\nOn average, liberal subreddit subscribers shared news\nfrom sources with higher factual ratings (mean =4.46/6)\nthan their conservative counterparts (mean =3.07), a dif-\nference that is statistically signi \ufb01cant ( \u03b2=1.00, p=.00).\nFurthermore, the neutral subreddits shared from sources\nwith higher credibility (mean =4.61) than the ideologically\nbiased subreddits (mean =4.07) and the difference was\nalso signi \ufb01cant ( \u03b2=0.55, p=.00).\nUsing NewsGuard, \ufb01ve (25%) of the top 20 sites shared\nby conservatives \u201cseverely violate basic journalistic stan-\ndards. \u201dThe equivalent number for liberal subreddits is\nzero. On average, using the NewsGuard trustscore, neutral\nand liberal sources had average credibility ratings of93.3% and 91.5%, respectively, which were higher than\nthe conservative average of 75.2%. The difference\nbetween the liberal and conservative means was signi \ufb01cant\n(\u03b2=16.4, p=.00), as was the difference between neutral\nand biased sources ( \u03b2=7.88, p=.00). Thus, we can be\nreasonably con \ufb01dent that conservative subreddits on\nReddit consume COVID-19 news from sites with lower\ncredibility than their liberal and neutral counterparts and\nthat the biased subreddits consume news from less crediblesites than their neutral counterparts.\nEffect of ideology on preference for COVID-19\nmisinformation\nOf the 5258 posts from news sources, 260 (5%) were from\nsites\ufb02agged for COVID-19 misinformation. We found that\nconservative subreddits share COVID-19 news from sites\ufb02agged for COVID-19-related misinformation at higher\nrates than liberal subreddits ( \u03b2=\u20130.20, p=.00) and\nFigure 1. Structural topic modeling process.6 Big Data & Society\nTable 2. Structural topic modeling (STM)-generated topics from Reddit corpus.\nT opic Keywords DescriptionRepresentative text from\nneutral subredditsRepresentative text from\nconservative subredditsRepresentative text from liberal\nsubreddits\nDeaths T est, death, case, die,\npositive, hospital, report,\ufb01rst, mask, protest, home,\nweek, nurse, cdc, number,\ngovern, patient, Florida,Y ork, evenLamenting the deaths\ncaused by COVID-19New Y ork, New Jersey, and\nMichigan saw 20,000 moredeaths than average in March\nand April. These were on top\nof the deaths alreadyaccounted for by Covid deathcounts. This leads researchersto believe the Covid death\ncount is actually much higher\nthan is being reported.The USA Is Dramatically\nOvercounting Covid Deaths. If youwere in hospice and had already\nbeen given a few weeks to live, and\nthen you also were found to haveCOVID that would be counted as aCOVID death. Even if you died ofclear alternative cause it still listed\nas a COVID death.Corona death toll: Americans are\nalmost certainly dying of Covid butbeing left out of the of \ufb01cial count\nT rump T rump, response, crisis,\nclaim, use, America, brief,\nadministration, blame,\ntreatment, govern, rally,show, campaign, global, fail,press, video, danger, mediaCriticism and defense\nof President Trump \u2019s\nresponse to the\npandemicT rump suggests \u201cinjection \u201dof\ndisinfectant to beat corona and\n\u201cclean\u201dthe lungsTrump is Right: WHO Failed the\nWorld With the corona PandemicT rump T outs \u201cGame-Changing \u201d\nDrug Cocktail For corona Linked\nT o Fatal Arrhythmia \u2014The\npresident, who is not a doctor,recommends a potentiallydangerous drug combo to his 74million T witter followers. \u201cWhat\ndo we have to lose? \u201dhe asked.\nScienti \ufb01c\nresearchInfect, patient, study,\nresearch, rate, \ufb01nd,\ndisease, show, use, virus,symptom, severe, drug,\nsuggest, can, sars-cov-2,\nhuman, may, spread, foundResults of scienti \ufb01c\nstudies thatcharacterize thenature of the virus\nand possible\ntreatmentsResearchers Identify Multiple\nMolecules that Shut DownSARS-Cov-2 PolymeraseReaction: A library of\nmolecules with unique\nstructural and chemicalfeatures inhibit the novelcorona polymerase, a key drugtarget for CovidHydroxychloroquine rated \u201cmost\neffective therapy \u201dby doctors for\ncorona: Global surveyThe US government gave\nhydroxychloroquine to 1300veterans infected with Covid,despite evidence that the drug is\nineffective and could increase the\nrisk of death\nEconomic\nrelief\nSander, bill, amid, relief,\nmillion, senate, help, need,fund, vote, stock, support,month, economic, Pelosi,\nreport, can, stimulus, gop,\naidLegislative efforts to\nmitigate against theeconomic damagewrought by the\npandemicMitt Romney: Every American\nadult should immediatelyreceive $1000 to help ensurefamilies and workers can meet\ntheir short-term obligations\nand increase spending in theeconomy.Speaker Nancy Pelosi Caught T rying\nto Include Abortion Funding in Billto Combat coronaAOC T akes Brave, Lonely Stand\nAgainst \u201cUnconscionable \u201dCovid\nRelief Package That Doesn \u2019t\nSuf\ufb01ciently Help Those Hurt the\nMost\nChina Health, China, spread, just,\nstop, news, work, order,\npublic, Chinese, doctor,\ncon\ufb01rm, nation, south,\npolit, see, Korea, issue,Wuhan, foxCriticisms of China \u2019s\nrole in the spread of\nthe virusThe Chinese doctors squad just\narrived in Italy to help to \ufb01ght\nthe Covid with their\nexperienceChina \u201cintentionally concealed the\nseverity \u201dof corona outbreak to\nhoard supplies: DHS reportReferring to the corona, Trump says\nhe was told by China \u2019s President\nXi. By April, during the month of\nApril, the heat generally kills thiskind of virus, so that would be agood thing.\n(continued)Chipidza et al. 7\nTable 2. Continued\nT opic Keywords DescriptionRepresentative text from\nneutral subredditsRepresentative text from\nconservative subredditsRepresentative text from liberal\nsubreddits\nFighting the\npandemicVirus, worker, time, social,\ncountry, \ufb01ght, lockdown,\nmedia, organ, black, know,\nway, emergency, lead,attack, still, last, better,near, nationEfforts to \ufb01ght against\nthe spread of\nCOVID-19, including\nlockdowns, socialdistancing, anddeclared states ofemergency.Rihanna Donates $4.2 Million to\nDomestic Violence Victims\nImpacted by Covid\nLockdowns. The pop starteams up with T witter CEOJack Dorsey to make thesizable donationPresident T rump made a\ncommitment to donate his salary\nwhile in of \ufb01ce. Honoring that\npromise and to further protect theAmerican people, he is donating his2019 Q4 salary to HHS to supportthe efforts being undertaken to\nconfront, contain, and combat\ncorona.Still No Widespread Covid T esting,\nBut the Fed Has a $500 Billion\nBank Stimulus \u2014The government\nis forking over a grand total of $1.5trillion to \u2026nudge the stock\nmarket\nBlack Lives\nMatterprotestsAmerican, world, democrat,\nright, lie, try, live, face, man,want, kill, force, threat,\nsave, capital, keep, give, get,\nthink, tellLink of Black Lives\nMatter protests tospread of COVID-19.Police Tactics Could T urn\nProtests Into Covid Hot Spots\u2014Sure, large crowds already\ncarry a risk of transmission. It \u2019s\njust worse when you teargaspeople, make them cough oneach other, and bus them tojail.Democrats cheering \u201cBlack Lives\nMatter \u201dprotests now say Trump\nrallies pose corona riskDOJ Wants to Suspend\nConstitutional Rights DuringCorona Emergency\nWhite\nHouseHouse, call, white,\nrepublican, take, make,Biden, warn, plan,governor, expert, push,\nconcern, don \u2019t, sick, top,\nhold, leave, joe, hoaxCriticism and defense\nof White Houseresponse to thepandemic.Bipartisan group pitches the\nWhite House on a $46.5billion Covid plan: to hire anarmy of 180,000\ncontact-tracers, book blocks\nof vacant hotel rooms soAmericans sick with Covid canself-isolate, and pay sickindividuals to stay away from\nwork until they recoverOnly 632 People Watch Sleepy Joe\nBiden \u2019s corona T own Hall on\nY ouT ubeThe Trump Administration Paid\nMillions for T est T ubes \u2014and Got\nUnusable Mini Soda Bottles; Theplastic tubes supplied for Corona\ntesting by Fillakit, a \ufb01rst-time\nfederal contractor with a sketchyowner, don \u2019te v e n \ufb01t the racks\nused to analyze samples.\nReopening\ndebatePandemic, state, outbreak,\nof\ufb01ce, care, due, vaccine,\nmedic, demand, year,medicare, company,\nsystem, expose, data, poll,\nhealthcare, refuse, T exas,reopenDebates on whether\nstates should reopenor not.T exas Has Over 1700 New\nCovid Cases Since AbbottAnnounced State \u2019s ReopeningElon Musk says he plans to move\nT esla out of California and suecounty after corona restrictionsT exas Began Opening Businesses\nMay 1. Now, They \u2019re Averaging\n1000 New Cases of Covid a Day8 Big Data & Society\nneutral subreddits ( \u03b2=\u20130.21, p=.00). In fact, 15% of all\nposts in conservative subreddits originated from sites\n\ufb02agged for misinformation; the equivalent number for\nboth liberal and neutral subreddits was 0%. There was nosigni\ufb01cant difference in sharing COVID-19 articles from\nsites \ufb02agged for misinformation between liberal and\nneutral sources. Subreddit moderation policies \u2014that is,\ndomain and title editing restrictions \u2014had no signi \ufb01cant\neffect on the tendency to share news sources from sites\n\ufb02agged for misinformation.\nDiscussion\nWe include in our sample some of the most in \ufb02uential sub-\nreddits on Reddit; r/science, r/coronavirus, r/politics, and r/\nConservative for example, boast 27 million, 2.4 million, 7.6million, and 800,000 subscribers\n6, respectively. The\nmedian subscriber count across all the subreddits is\n385,000. Submissions had 44 comments on average andwere upvoted 238 times, with an upvote ratio of 83%\n(meaning that 17% of votes were downvotes). These\nmetrics show signi \ufb01cant engagement of\nCOVID-19-related content in political subreddits as well\nas in r/science and r/coronavirus.\nOur study \ufb01nds that discussion of the COVID-19 pan-\ndemic is polarized across political ideology on Reddit.\nReddit affords adherents to political ideologies the abilityto coalesce around common interests, further bolstering\nthe echo chamber effect whereby people primarily expose\nthemselves to those beliefs that reinforce their world\nviews. Thus, whereas discussion in liberal subredditsframed the COVID-19 phenomenon as an indictment of\nTrump \u2019s perceived mishandling of the crisis than did con-\nservative subreddits, the latter were much more likely toframe the resulting fallout as the fault of China. These \ufb01nd-\nings suggest that conservatives and liberals on Reddit\nconsume COVID-19 information from different sources,and they emphasize those aspects of the pandemic that\nmight be politically helpful for their ideological projects.\nAt the same time, information that helps with COVID-19prevention was little discussed relative to other topics, sug-\ngesting that political polarization might be undercutting the\npublic health message.\nWhy do we observe political polarization on the health-\ncare phenomenon that is COVID-19 as discussed on\nReddit? Part of the answer might lie in certain Reddit fea-tures, which inadvertently foster political polarization.\nFeatures such as upvoting, default sorting \ufb01lter, post aggre-\ngation across subreddits, and limited tool support for mod-erators have been implicated in fostering \u201ctoxic\ntechnocultures \u201dand ideological extremism on Reddit\n(Gaudette et al., 2021; Massanari, 2017). Our study impli-cates Reddit \u2019s subreddit subscription feature in making\nCOVID-19 a politically polarizing phenomenon. Reddit\nFigure 2. T opic preferences by ideological bias.Chipidza et al. 9\nusers subscribe to those subreddits which interest them, and\nthese form the default front page for the user when acces-sing reddit.com (Massanari, 2017). If a user is subscribed\nto subreddits that align only with their ideology, they will\nprimarily see content conforming to the same. Users arealso likely to share information from sources that reinforce\ntheir existing viewpoints, making it much harder to change\nminds in ways that are bene \ufb01cial for public health. Thus,\nusers may only be exposed to the narrative of COVID-19\nas\u201cnot as deadly as the \ufb02u\u201dthus downplaying its risk.\nFurthermore, users may decide to spend most of theirtime on Reddit interacting with others within select subred-\ndits, where narratives may crystallize into echo chambers\n(Gaudette et al., 2021). People upvote content and byvoting for certain topics, it might appear that certain\nCOVID-19 viewpoints are valid and mainstream when\nthey are not. For example, a post titled \u201cThe US Is\nDramatically Overcounting COVID-19 Deaths \u2026\u201d was\nupvoted about 1000 times, even if the scienti \ufb01c consensus\nis clear that these ideas are wrong. Reddit \u2019s voting algo-\nrithm thus facilitates mistrust in scienti \ufb01c reporting and\nskepticism of COVID-19 mitigation measures.\nOur\ufb01ndings demonstrate a link between political polar-\nization and misinformation. On a platform like Reddit with\nrelatively few editorial guardrails, one may submit informa-\ntion from other sources whether vetted or not; here the argu-ment is that Reddit is a content aggregator rather than\ncontent host and thus should not be responsible for the\ncontent submitted and discussed by users (see Massanari,2017). Given that the goal of political subreddits is to advo-\ncate for viewpoints that are bene \ufb01cial for their particular\nideological projects, it follows that misinformation will\nlikely be prevalent in political subreddits. We do \ufb01nd that\nconservative subreddits share articles from sites \ufb02agged\nfor COVID-19 misinformation at much higher rates than\nliberal and neutral subreddits.\nThe content of the misinformation is instructive in\nterms of its perceived political bene \ufb01ts for proponents of\nconservative ideology. The ideas that COVID-19 death\ntolls in the USA are in \ufb02ated and that hydroxychloroquine\nis effective at curing the disease are meant to suggest that\nthe USA is overreacting to the pandemic and that lock-\ndowns which are seen as economically and politicallycostly to the Republican party are therefore unnecessary.\nOur\ufb01ndings are interesting in light of recent research\nthat examines the spread of misinformation promotinghydroxychloroquine as a \u201ccure\u201dof COVID-19 on\nTwitter, especially given former US President Trump \u2019s\npromotion of the drug. (Haupt et al., 2021). Similar toour\ufb01ndings, claims of hydroxychloroquine \u2019se f\ufb01cacy in\ntreating COVID-19 leverage scienti \ufb01c authority (i.e. the\nfringe group of physicians \u201cAmerica \u2019s Frontline\nDoctors \u201d), but in truth most healthcare experts and\nextant scienti \ufb01c studies \ufb01\nnd hydroxychloroquine an inef-\nfective, even damaging, as a cure for COVID-19. Thefeature of Reddit as a content aggregator even from sites\n\ufb02agged for COVID-19 misinformation facilitates the dis-\nsemination of unveri \ufb01ed information.\nFigure 3. T opic preferences: biased versus neutral.10 Big Data & Society\nPublic health and health care interventions that are\ndesigned with an understanding of the political systems\nand institutions in which they are to be implemented may\nbe more successful in generating a sustainable healthimpact (Greer et al., 2017; Trachtman, 2019). We recom-\nmend that public health professionals become active on\nReddit to help with messaging on COVID-19 preventionand mitigation. Although Reddit aims to be laissez-faire\nas possible in terms of moderating content, the problem\nof misinformation could be par tially alleviated if infec-\ntious disease specialists, e pidemiologists, medical\ndoctors, lab scientists, and other public health profes-\nsionals were to contribute to subreddits to push factualinformation about COVID-19. Organizations represent-\ning these health professionals such as the American\nMedical Association or the American Public HealthAssociation may also consider adjusting their advocacy\nactivities to combat misinformation. This could be\naccomplished, for example, by dedicating efforts to mon-itoring news sites for health-related misinformation and\nuse Reddit features such as \ufb02airs to display the \ufb02ag onposts linking to \ufb02agged sites. Over time, the \ufb02ags\nwould likely nudge users away from posting information\nfrom sites with low credibility. In fact, the WHO advo-\ncates that trusted sources such as the WHO and nationalhealth authorities are used for accurate COVID-19 infor-\nmation through their \u201cStop the Spread \u201dcampaign and\nencourages everyone to help stop the spread of misinfor-mation. See https://www.who.int/campaigns/connectin\ng-the-world-to-combat-coronavirus/how-to-report-misin\nformation-online\nWe also \ufb01nd that the neutral subreddits shared articles\nfrom more credible sites compared to the ideological sub-\nreddits. Subreddit moderation potentially explains whythe neutral subreddits share more credible information; by\nallowing submissions only from peer reviewed research,\nr/science prevents the spread of unveri \ufb01ed COVID-19\ninformation and likely limits the politicization of the pan-\ndemic as well in that subreddit. Disseminating accurate\ninformation about infection is a key component of mana-ging a pandemic. Reddit may help push credible informa-\ntion to their users by algorithmically promoting\nFigure 4. T op 20 news sources posted by subscribers of conservative and liberal subreddits.Chipidza et al. 11\ninformation from science-focused subreddits. Such promo-\ntion would educate users on how to avoid infection basedon best available peer-reviewed material, while also limit-\ning user exposure to potentially harmful misinformation.\nIn essence, for users of Reddit, credible information aboutthe pandemic is best found in the neutral subreddits, and\nconservative subreddits are much less credible than liberal\nsubreddits.\nModeration of content also has a role to play. If users are\nfound to repeatedly post unveri \ufb01ed health-related informa-\ntion to a given subreddit, moderators may impose Redditpenalties such as suspensions or bans on offenders.\nAwarding \ufb02airs of expertise to veri \ufb01ed users is another\nmechanism that may help promote credible informationon Reddit. These veri \ufb01ed users would have \ufb02air indicating\nexpertise in epidemiology, medicine, and/or public health,\nfor example. The \ufb02air would nudge other users to trust\ntheir responses more than from unveri \ufb01ed users.\nStudy limitations and future research\nOur study has several limitations. First, our \ufb01ndings show\nthat conservative and liberal subreddits consumeCOVID-19 information from disparate sources, but it\ndoes not show whether Reddit causes this polarization as\nopposed to just re \ufb02ecting it. Future research could inves-\ntigate the extent to which Re ddit itself serves as a polar-\nizing or misinformation source. Furthermore, the\ndemographics of Reddit users skew young, white, andmale (Massanari, 2017), meaning that the platform is\nnot representative of the US or global population.\nMethodologically, there are limitations with Reddit \u2019s\nPRAW API, which is not guaranteed to return all the\nitems requested from a speci \ufb01ed search\n7. Another limita-\ntion is that we relied on MediaBiasFactCheck.comratings of media credibility to understand the effect of\nideology on information source credibility. Although\nwe con \ufb01rmed the robustness of our \ufb01ndings using\nratings from NewsGuard, there is an opportunity for\nfuture research to make use of alternative rating\nsystems, for example, crowdsourced ratings.\nThere are other political and COVID-19 themed subred-\ndits that we did not include in our study at this exploratory\nphase, because they did not meet our inclusion criteria. Wedid not include COVID-19 themed subreddits such as r/\nCOVID-19, r/China_Flu, and r/COVID19_support\nbecause they were created much later than the beginningof the phenomenon. We consider two politically neutral\nsubreddits \u2014r/science and r/coronavirus \u2014in our analyses\nbecause they offer relevant coverage of COVID-19related issues. Future research might examine COVID-19\ntopics on Reddit as a whole, to understand how other non-\npolitical but highly subscribed subreddits like r/sports, r/news, and r/videos discuss the pandemic. Results from\nsuch studies may demonstrate how issues becomepoliticized over time. Last, subreddit moderation policies\nbeyond the domain and editing restrictions that we identi-\ufb01ed in this study may also in \ufb02uence discussion of\nCOVID-19 on Reddit. Notably, we examined the effect of\nthese moderation policies, not their actual enforcement.Future research may examine the effect of active modera-\ntion activities, for example, the extent to which the\nmanual \ufb02agging of posts impacts the popularity of sub-\nmitted posts and the extent to which deletion of posts that\nviolate subreddit policies impacts topic discussion and\nspread of misinformation.\nConclusions\nSocial media has previously been implicated in fueling poli-tical polarization. In this paper, we investigated whether thediscussion of COVID-19-related news re \ufb02ects political\npolarization on Reddit, a popular online discussion plat-\nform. The topics of discussion in political subreddits arepolarized on ideological lines: Trump, White House, and\neconomic relief topics are statistically more prominent in\nliberal subreddits, and China and deaths topics are moreprominent in conservative subreddits. We found signi \ufb01cant\ndifferences between liberal and conservative subreddits in\ntheir preferences for news sources. Liberal subredditsshare and discuss more credible news sources than conser-\nvative subreddits. Conservative subreddits are more likely\nthan liberal subreddits to share articles from sites \ufb02agged\nfor publishing COVID-19 misinformation.\nCOVID-19 misinformation has been proliferating at\nalarming rates on social media (Allington et al., 2021).Our study shows that the misinformation is largely shared\nin conservative subreddits on Reddit. Social media sites\nshould intervene to algorithmically promote credible newssources in relation to health information.\nDeclaration of con \ufb02icting interests\nThe author(s) declared no potential con \ufb02icts of interest with\nrespect to the research, authorship, and/or publication of thisarticle.\nFunding\nThe author(s) received no \ufb01nancial support for the research,\nauthorship, and/or publication of this article.\nORCID iDs\nWallace Chipidza https://orcid.org/0000-0002-3980-4861\nChristopher Krewson https://orcid.org/0000-0002-1286-1778\nTendai Gwanzura https://orcid.org/0000-0002-2110-3530\nNotes\n1. https://www.redditinc.com/2. The list of political and neutral subreddits chosen in this study\nis not exhaustive. Political subreddits were included by the12 Big Data & Society\nfollowing criteria: if they were in the top six by both number of\nsubscribers and number of coronavirus or COVID-19 posts.We applied these criteria so as to equalize the conservativeand liberal subreddits and to exclude subreddits with low\ncounts of COVID-19 related posts. Although other coronavirus\nthemed subreddits exist (e.g., r/COVID19 and r/COVID19_support), we included r/coronavirus as representa-tive as it is the oldest (created in May 2013) and the largest sub-scribed of subreddits dedicated to coronaviruses and theCOVID-19 pandemic.\n3. https://www.newsguardtech.com/4. https://www.newsguardtech.com/coronavirus-misinformation-\ntracking-center/, retrieved 10/4/20. (accessed 4 October 2020)>\n5. https://www.newsguardtech.com/covid-19-myths/, retrieved\n10/4/20. (accessed 4 October 2020)\n6. http://redditlist.com/7. https://praw.readthedocs.io/en/v3.6.2/pages/getting_started.html\nReferences\nAllcott H and Gentzkow M (2017) Social media and fake news in\nthe 2016 election. Journal of Economic Perspectives 31(2):\n211\u2013236.\nAllington D, Duffy B, Wessely S, et al. (2021)\nHealth-protective behaviour, social media usage and con-spiracy belief during the COVID-19 public health emer-gency. Psychological Medicine 51(10): 1763 \u20131769. DOI:\n10.1017/S003329172000224X.\nAndersen K, de Vreese CH and Alb\u00e6k E (2016) Measuring media\ndiet in a high-choice environment-testing the list-frequency\ntechnique. Communication Methods and Measures 10(2\u20133):\n81\u201398.\nAu H, Bright J and Howard PN (2020) Social media misinforma-\ntion about the WHO .\nBaum MA (2011) Red state, blue state, \ufb02u state: Media self-\nselection and partisan gaps in swine \ufb02u vaccinations. Journal\nof Health Politics, Policy and Law 36(6): 1021 \u20131059.\nCampante FR and Hojman DA (2013) Media and polarization.\nJournal of Public Economics 100: 79 \u201392.\nCentivany A and Glushko B (2016) \u2018Popcorn tastes good \u2019:\nParticipatory policymaking and Reddit \u2019s Amageddon. In:\nProceedings of the SIGCHI conference on human factors incomputing systems New York, NY, USA, 7 May 2016,\npp. 1126 \u20131137. CHI \u201916. Association for Computing\nMachinery. DOI: .\nChandelier M, Steuckardt A, Mathevet R, et al. (2018) Content\nanalysis of newspaper coverage of wolf recolonization inFrance using structural topic modeling. Biological\nConservation 220: 254 \u2013261.\nDalmer NK (2017) Questioning reliability assessments of health\ninformation on social media. Journal of the Medical Library\nAssociation 105(1): 61 \u201368.\nGaudette T, Scrivens R, Davies G, et al. (2021) Upvoting extrem-\nism: Collective identity formation and the extreme right onReddit. New Media and Society 23(12): 3491 \u20133508. DOI:\n10.1177/1461444820958123\nGreer SL, Bekker M, De Leeuw E, et al. (2017) Policy, politics\nand public health. European Journal of Public Health 27-\n(suppl_4): 40 \u201343.Haupt MR, Li J and Mackey TK (2021) Identifying and character-\nizing scienti \ufb01c authority-related misinformation discourse\nabout hydroxychloroquine on twitter using unsupervisedmachine learning. Big Data and Society 8(1):\n20539517211013844.\nMassanari A (2017) #Gamergate and The Fappening: How\nReddit \u2019s algorithm, governance, and culture support toxic tech-\nnocultures.\nNew Media and Society 19(3): 329 \u2013346.\nMensio M and Alani H (2019) News source credibility in the eyes\nof different assessors.\nMetzger MJ, Hartsell EH and Flanagin AJ (2020) Cognitive dis-\nsonance or credibility? A comparison of two theoretical expla-\nnations for selective exposure to partisan news.\nCommunication Research 47(1): 3 \u201328.\nMills RA (2018) Pop-up political advo cacy communities on reddit.com:\nSandersForPresident and The Donald. AI & Society 33(1): 39 \u201354.\nMimno D, Wallach HM, Talley E, et al. (2011) Optimizing\nsemantic coherence in topic models. In: Proceedings of\nthe conference on empirical methods in natural languageprocessing , USA, 27 July 2011, pp. 262 \u2013272. EMNLP \u201911.\nAssociation for Computational Linguistics.\nPew Research Center (2019) Key \ufb01ndings about the online news\nlandscape in America. Available at: https://www.pewresearch.org/fact-tank/2019/09/11/key- \ufb01ndings-about-the-online-news-\nlandscape-in-america/ (accessed 27 February 2020).\nProferes N, Jones N, Gilbert S, et al. (2021) Studying reddit: A\nsystematic overview of disciplines, approaches, methods, andethics. Social Media +Society 7(2): 205630512110190.\nR Development Core Team RC (2010) R: A language and envir-\nonment for statistical computing.\nRobards B (2018) Belonging and Neo-Tribalism on Social Media\nSite Reddit. In: Hardy A, Bennett A, and Robards B (eds) Neo-\nTribes: Consumption, Leisure and Tourism . Cham: Springer\nInternational Publishing, pp. 187 \u2013206. DOI: 10.1007/978-3-\n319-68207-5_12\nRoberts ME, Stewart BM and Tingley D (2014) Stm: R package\nfor structural topic models. Journal of Statistical Software\n10(2): 1 \u201340.\nShearer E and Matsa KE (2018) News use across social media\nplatforms 2018. Available at: https://www.journalism.org/2018/09/10/news-use-across-social-media-platforms-2 018/\n(accessed 19 October 2020).\nSoliman A, Hafer J and Lemmerich F (2019) A characterization\nof political communities on Reddit. In: Proceedings of\nthe 30th ACM Conference on Hypertext and SocialMedia , New York, NY, USA, 12 September 2019, pp. 259 \u2013\n263. HT \u201919. Association for Computing Machinery. DOI:\n10.1145/3342220.3343662.\nStatista (2021) Reddit: traf \ufb01c by country. Available at: https://\nwww.statista.com/statistics/ 325144/reddit-global-active-user\n-distribution/ (accessed 24 August 2021).\nTasnim S, Hossain MM and Mazumder H (2020) Impact of rumors\nand misinformation on COVID-19 in social media. Journal of\nPreventive Medicine and Public Health 53(3): 171 \u2013174.\nTrachtman S (2019) Polarization, participation, and premiums:\nHow political behavior helps explain where the ACA works,and where It doesn \u2019t.Journal of Health Politics, Policy and\nLaw 44(6): 855 \u2013884.\nWorld Health Organization (2021) Drugs to prevent COVID-19:\nA WHO living guideline. Available at: https://app.Chipidza et al. 13\nmagicapp.org/#/guidelin e/L6RxYL/section/jM1N5j\n(accessed 21 July 2021).\nYoung DG and Anderson K (2017) Media diet homogeneity in a\nfragmented media landscape. Atlantic Journal of\nCommunication 25(1): 33 \u201347.Yu S, Martino GDS and Nakov P (2019) Experiments in detecting\npersuasion techniques in the news. arXiv preprint\narXiv:1911.06815 .\nZarocostas J (2020) How to \ufb01ght an infodemic. The Lancet 395-\n(10225): 676.14 Big Data & Society", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Ideological variation in preferred content and source credibility on Reddit during the COVID-19 pandemic", "author": ["T Gwanzura", "W Chipidza", "C Krewson", "N Gatto"], "pub_year": "2022", "venue": "NA", "abstract": "In this exploratory study, we examine political polarization regarding the online discussion  of the COVID-19 pandemic. We use data from Reddit to explore the differences in the topics"}, "filled": false, "gsrank": 102, "pub_url": "https://digitalcommons.fiu.edu/covid-19_research/96/", "author_id": ["zDCvIt8AAAAJ", "Cr3omicAAAAJ", "", "ntru8nEAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:-E0NmQuaCj4J:scholar.google.com/&output=cite&scirp=101&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D100%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=-E0NmQuaCj4J&ei=FrWsaM7kLPnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:-E0NmQuaCj4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://digitalcommons.fiu.edu/cgi/viewcontent.cgi?article=1095&context=covid-19_research"}}, {"title": "Politikweli: A swahili-english code-switched twitter political misinformation classification dataset", "year": "2023", "pdf_data": "  \nPolitiKweli: A Swahili -English Code -switched Twitter \nPolitical Misinformation Classification Dataset\n \nCynthia Amol1 Lilian Wanzare2 and James Obuhuma3 \n1 Maseno University, Kenya  \ncynthia@maseno.ac.ke  \n2 Maseno University, Kenya  \n3 Maseno University, Kenya  \n \n \n1. Abstract  \nIn the age of freedom of speech, users of the social media platform Twitter post \nmil-lions of messages per day. These messages are not always fact -checked \nresulting in misinformation which is false or misleading news. M isinformation \nclassification involves identifying and classifying text as either false or fact by \ncomparing the text against fact -checked news. On political matters, \nmisinformation online can result in mistrust of political figures, polarization of \ncommuni ties and violence offline. Existing studies mostly address misinformation \ndetection for messages written in a single language such as English. Among most \nbilingual or multilingual user groups in countries like Kenya, the use of Swahili -\nEnglish code -switchi ng and code -mixing is a common practice in informal text -\nbased communication such as messaging on social media platforms like Twitter. \nThere is therefore need for more research in low -resource languages such as \nSwahili. The PolitiKweli1 dataset introduced by this study, which a novel Swahili -\nEnglish misinformation classification dataset, contains 6,345 Swahili -English \ntexts, 22,954 English texts and 211 Swahili texts. The texts are labelled as true, \nfalse or neutral as compared to a fact -checked dataset als o created for this study. \nThe dataset curation process including data collection, processing and \nannotation are explained. Challenges during annotation are also discussed. The \nresults of experiments conducted using pretrained language models prove the \ndata set\u2019s usefulness in training Swahili -English code -switched misinformation \nclassification models.  \n1 Introduction  \nThe increasing popularity of social media has shifted the preference of news dissemination \nchannels from mainstream newsrooms on cable television to digital platforms such as the social \nmedia platform Twitter  (now X)  which offer real -time, more interactive and uncensored avenues \nto share news and comment on current topics (Ombui, Muchemi & Wagacha , 2019). Twitter users \noften take advantage of the anonymity that comes with an online persona to spread \n                                                                    \n1 dataset: https://github.com/jayneamol/kweli  \n\n2 misinformation. By posting false texts, links or re -posting other users\u2019 misleading news, Twitter \nusers can easily amplify one false post causing it to  trend and sometimes be picked up by \nmainstream news channels. Twitter defines misleading content ('misinformation') as claims that \nhave been confirmed to be false by external, subject -matter experts or include information that is \nshared in a deceptive or confusing manner (Twitter, 2023).  \nIn Africa, Kenya is among the leading countries in terms of blogging, and Twitter is an increasing \nplatform for social commentary and political engagement (Mukhongo, 2020). Political events like \nthe recently concluded 2022 General Elections in Kenya were widely tweeted about. Despite \nTwitter\u2019s set policies against misinformation amplification, multiple posts relating to misleading \nnews like fake polls, unverified electoral results, and unsubstantiated statements from po litical \nparties and individuals were flagged (Mozilla, 2022). Misinformation on political issues often \npolarises the country and may result to violence in extreme cases. Twitter serves as a mobilization \nplatform for Kenyan internet users to go to the stree ts and stage protests after con -tested elections \n(Mukhongo, 2020).  \nThe Swahili language  is an African language of the Bantu family with a constant changing \nvocabulary (Kresse & Vierke, 2022) and is spoken by over 100 million people in East and Central \nAfrica. Despite this high number of speakers, Swahili is still classified as a low -resource language \n(Wanjawa et. al., 2022) because of the inadequate data for Natural Language Processing (Shikali & \nMokhosi, 2020). Aside from the use of standard Swahili or Eng lish and other native languages, an \never -evolving slang (sheng\u2019) is often developed among Twitter users. So far, there is hardly any \nwork involving East African languages in detecting misinformation from social media (Nabende et. \nal., 2021).  \nIn a multicult ural country like Kenya with 42(+) tribes (Balaton -Chrimes, 2021) each speaking an \nalmost distinct language and two national languages, messages on Twitter are often code -\nswitched. Code -switching, which denotes a shift from one language to another within a  single \nutterance, is common in casual text found in social media (Sitaram et. al, 2019) among bilingual or \nmultilingual communities. The shift in languages vary and can occur in the form of a whole phrase \nor word in a different language in one sentence. T able 1  shows some of the variations in code -\nswitched  Swahili -English texts.  \nTable 1 : Variations in code -switched texts  \nLanguage  Text  \n|eng| swa| eng| swa| eng| \nswa |propaganda| imeganda| proper| kama hauna| facts don't \nengage| watu haujui  \n|swa| eng  |kwa hivo kuibiwa pia ni makosa| why victimise him  \n|swa| eng  |mheshimiwa| voting is through secret ballot  \n \nThe semantic complexities of code -mixing in social media texts (Ombui, Muchemi & Wagacha , \n2019) makes models that are trained with single language datasets less accurate when classifying \na code -mixed dataset. This necessitates building of code -switched datasets to train models that \ncan perform classification tasks for code -switched data.  \nThis study introduces a novel dataset: PolitiKweli, a Swahili -English misinformation classification \ndataset built from tweets relating to the highly contested 2022 General Elections in Kenya. The \ndataset containing tweets posted by Kenya\u2019s electoral commissio n, Independent Electoral and \nBoundaries Commission, IEBC was also created for fact -checking the text.  \n3 This dataset can be used to train and test text classification models which can be applied to Twitter \nand other social media platforms to flag cases of m isinformation on political issues in Swahili -\nEnglish code -switched texts. Misinformation classification helps preserve the integrity of news \nposted on social media and curb any adverse effects that may result from misinformation.  \n2 Related Work  \nPrevious stud ies have built datasets that are used in training and testing classification models in \nmachine learning. Some of the common classification tasks are misinformation classification, fake \nnews detection and hate speech detection. Nabende et. al. (2021) curate d a Luganda -English code -\nmixed COVID -19 misinformation classification dataset by comparing tweets and Facebook posts \nabout COVID -19 against credible information posted by the Ugandan Ministry of Health. The posts \nwere annotated as \u2018misinformation\u2019 or \u2018no -misinformation\u2019. \u2018FACTOID\u2019 (Sakketou et. al., 2022) is \nan English language dataset designed for misinformation detection on Reddit  built by  classifying \nReddit users as \u2018misinformation spreaders\u2019 versus \u2018real news spreaders\u2019 and assigning credibility \nscores to each user based on the factuality of the news sources.   \nThe datasets \u2018FakeNewsNet\u2019 by Shu et. al. (2020) and \u2018ISOT\u2019 used by Amer, Kwak, & El -Sappagh \n(2022) are built for fake news detection tasks. It is in English and contains instances of fake news \ncampaigns by Twitter users and who they follow which can be used to create a social network of \nfake news spreaders (Michail, Kanakaris & Varlamis, 2022). \u2018ISOT\u2019 used by the study Amer, Kwak, \n& El -Sappagh (2022) on the other hand, contains English language ne ws stories sourced from \nReuters, Wikipedia, Politifact. The real articles were gathered from the Reuters website, while the \nfake or false ones were from different sites identified as fictitious by Wikipedia and Politifact. In \nthe study by Ombui, Muchemi an d Wagacha (2019), a Swahili -English code -mixed dataset for hate \nspeech detection  was created from tweets from the 2017 and 2012 general election in Kenya.  \nSome of the publicly available datasets that focus on low -resource languages in -cluding Swahili are \n\u2018Afrisenti\u2019 (Muhammad, et. al., 2023), \u2018Kencorpus\u2019 (Wanjawa et. al., 2022), \u2018MasakhaNER\u2019 (Adelani \net. al., 2021) and  \u2018NER\u2019 (David, 2020). The pro -cess of creation of these datasets include data \ncollection, data pre -processing and annotation. During the cre ation of PolitiKweli , we took \ninspiration from the studies by (Muhammad, et. al., 2023), Wanjawa et. al. (2022), Nabende et. al. \n(2021) and Ombui, Muchemi & Wagacha (2019) in dataset creation for code -switched texts and \nexploration of the low -resource lang uage, Swahili.  \n3 Methodology  \nAn exploratory research design was applied in data collection from Twitter, data pre -processing \nand processing to generate viable data to train the model and data annotation as either \u2018fake\u2019, \n\u2018false\u2019 or \u2018neutral\u2019.  \n3.1  Data Collection  \nData on Twitter was collected using Twitter Academic API which offers access to both historical \nand real -time data as in Muhammad et al. (2023). The study collected 50,000 tweets posted from \n4th October, 2021 which was the first day of voter reg istration in preparation for 2022 elections in \nKenya to the 5th September, 2022 when the Supreme Court of Kenya issued the ruling on the \ncontested presidential election results.  \nThe collection process involved selection of tweets with hashtags relating to elections that trended \nduring the election period such as #KURA 2022, #Uamuzi2022 #KenyaElections2022, #Kenya  and \n4 #GE2022. In addition to hashtags, the most used key words such as elections, vote, voters, general \nelections, tallying, election results and k ey mentions such as @RailaOdinga, @WilliamsRuto and \n@IEBCKenya \u2013 the electoral body were used in the search. There were two sets of tweets: the \ngeneral tweets posted by Twitter users about the 2022 General Elections and tweets posted by the \nelectoral body (@IEBCKenya) which were regarded as fact -checked news.  \n3.2  Data Processing  \nThe data processing stage included language identification, data cleaning, anonymization and \nlowercasing.  Manual language detection was done due to semantic complexities of code -switched \ntexts and the several other languages that may be present in one tweet. A team of ten annotators \nlabeled the data in four categories: \u2018Swahili -English\u2019, \u2018Swahili\u2019, \u2018English\u2019 or \u2018Other\u2019. This resulted in \nfour sets data grouped data according to langu age. The data anonymization process involved \nchanging of any mentions to @user to protect identities of Twitter users mentioned in tweets.  \n3.3  Data Annotation  \nA team of ten annotators labeled the clean  data as fake, false or neutral . The grammatical \ncomplexity of code -switched texts necessitates that the human annotators be conversant with \nboth languages used.  Both inter -annotator agreement and measure of code -switching w ere \ncomputed . An average Free -Marginal Multirater Kappa  score of 0.47 was achieve d. The code -\nswitched texts had an average M -index of 0.67 which indicated good code -switching.  \nSome of the challenges faced during annotation were the high cost of annotation given that the \nstudy did not have any external funding and decoding of satirical text.  \n4 Results  \nA summary of the respective labels per language is shown in Table 2. The text s are classified as \nSwahili -English (swa -eng), English (eng) and Swahili (swa).  \nTable 2: Summary of the respective labels per language  \nData  swa-eng eng swa \nFactual Data      1221     6065     8                    \nNeutral Data      4094    13380    19                  \nFake Data      1030     3512             184 \n \nThe Swahili -English texts which were the main focus of this study, were tested using BERT pre -\ntraining language model . An accuracy of 53.9% was achieved.  \nThe English and Swahili texts are also this study\u2019s contribution and can be used for other machine \nlearning tasks such as text classification and sentimental analysis in Swahili or English only tasks in \nthe future.  \n5 Conclusion and Future Work  \nThe contribution of this study is a dataset with three sets of texts: 6,345 Swahili -English texts, \n22,954 English texts and 211 Swahili texts . The dataset can be used in training models that perform \nclassification tasks for both  Swahili -English code -mixed texts and Swahili only texts. With constant \nadvancements in technology and increased use of code -switching in the new generations of \nlanguage speakers, there is need for more research in low -resource languages such as Swahili. This \nstudy paves way for more research in code -mixing and how machine learning can be leveraged to \nprovide solutions for constantly evolving problems such as misinformation detection on social \nmedia.  We al so hope to achieve better accuracy with pretrained m ultilingual models such a mBERT.  \n5 6 Acknowledgements  \nWe acknowledge the contributions of Shamsuddeen Hassan, Martin Okech, Edwin Onkoba, Mary \nGitaari, Elphas Otieno, Bowa Marita, Peter Gathuita and the Maseno  University School of \nComputing and Informatics staff and students. We thank Eze -kiel Maina, Nelson Odhiambo, \nStephen Otieno, Monicah Odipo, Harrison Kioko and Samwel Okonda for their contribution in data \nannotation.  \nReferences  \n1. Adelani, D. I., Abbott, J., Neubig, G., D\u2019souza, D., Kreutzer, J., Lignos, C., ... & Osei, S. \n(2021). MasakhaNER: Named entity recognition for African languages. Transactions of \nthe Association for Computational Linguistics, 9, 1116 -1131  \n2. Amer, E., Kwak, K. S., & El -Sappagh, S. (2022) . Context -Based Fake News Detection \nModel Relying on Deep Learning Models. Electronics, 11(8), 1255.  \n3. Balaton -Chrimes, S. (2021). Who are Kenya\u2019s 42 (+) tribes? The census and the political \nutility of magical uncertainty. Journal of Eastern African Studies,  15(1), 43 -62. \n4. Barnett, R., Cod\u00f3, E., Eppler, E., Forcadell, M., Gardner -Chloros, P., Van Hout, R., ... & \nWensing, S. (2000). The LIDES Coding Manual: A Document for Preparing and Analyz -ing \nLanguage Interaction Data Version 1.1 --July 1999. International J ournal of Bilingual -ism, \n4(2), 131 -271.  \n5. Davis David. 2020. Swahili: News classification dataset.  \n6. Githiora, 2018 \u2014 Githiora, C. J. (2018). Sheng: rise of a Kenyan Swahili vernacular. \nBoydell & Brewer.  \n7. Kresse, K., & Vierke, C. (2022). Swahili language and li terature as resources for Indian \nOcean studies. History Compass, e12725.  \n8. Landis, J. R., & Koch, G. G. (1977). An application of hierarchical kappa -type statistics in \nthe assessment of majority agreement among multiple observers. Biometrics, 363 -374.  \n9. Martin , G., Mswahili, M. E., Jeong, Y. S., & Young -Seob, J. (2022, July). SwahBERT: \nLanguage Model of Swahili. In Proceedings of the 2022 Conference of the North \nAmerican Chapter of the Association for Computational Linguistics: Human Language \nTechnologies (pp. 303-313).  \n10. Michail, D., Kanakaris, N., & Varlamis, I. (2022). Detection of fake news campaigns using \ngraph convolutional networks. International Journal of Information Management Data \nIn-sights, 2(2), 100104.  \n11. Mozilla. https://foundation.mozilla.org/en/blog/ new -research -in-kenya -disinformation -\ncampaigns -seek -to-discredit -pandora -papers/ last accessed 2022/12/15  \n12. Muhammad, S. H., Abdulmumin, I., Ayele, A. A., Ousidhoum, N., Adelani, D. I., Yimam, S. \nM., ... & Arthur, S. (2023). Afrisenti: A twitter sentiment an alysis benchmark for african \nlanguages. arXiv preprint arXiv:2302.08956.  \n13. Mukhongo, L. L. (2020). Participatory Media Cultures: Virality, Humour, and Online Polit -\nical Contestations in Kenya. Africa Spectrum, 55(2), 148 -169.  \n14. Nabende, P., Kabiito, D., Babiry e, C., Tusiime, H., & Nakatumba -Nabende, J. (2021). Mis -\ninformation detection in Luganda -English code -mixed social media text. arXiv preprint \narXiv:2104.00124.  \n15. Okoth, G. B. W. (2020). How Kenyans on Twitter use visuals as a form of political protest. \nJourn al Kommunikation. Medien, 1 -27. \n16. Ombui, E., Muchemi, L., & Wagacha, P. (2019, October). Hate speech detection in code -\nswitched text messages. In 2019 3rd International Symposium on Multidisciplinary \nStudies and Innovative Technologies (ISMSIT) (pp. 1 -6).  \n6 17. Sakketou, F., Plepi, J., Cervero, R., Geiss, H. J., Rosso, P., & Flek, L. (2022). FACTOID: A \nNew Dataset for Identifying Misinformation Spreaders and Political Bias. arXiv preprint \narXiv:2205.06181.  \n18. Shu, K., Mahudeswaran, D., Wang, S., Lee, D., & Liu, H. (2 020). Fakenewsnet: A data re -\npository with news content, social context, and spatiotemporal information for studying \nfake news on social media. Big data, 8(3), 171 -188., 8(3), 171 \u2013188.  \n19. Shikali, C. S., & Mokhosi, R. (2020). Enhancing African low -resource la nguages: Swahili \ndata for language modelling. Data in brief, 31, 105951.  \n20. Sitaram, S., Chandu, K. R., Rallabandi, S. K., & Black, A. W. (2019). A survey of code -\nswitched speech and language processing. arXiv preprint arXiv:1904.00784.  \n21. Twitter, https://help. twitter.com/en/resources/addressing -misleading -info, last \naccessed 2023/06/10.  \n22. Wanjawa, B., Wanzare, L., Indede, F., McOnyango, O., Ombui, E., & Muchemi, L. (2022). \nKencorpus: A Kenyan Language Corpus of Swahili, Dholuo and Luhya for Natural Lan -guage  \nProcessing Tasks. arXiv preprint arXiv:2208.12081.  ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Politikweli: A swahili-english code-switched twitter political misinformation classification dataset", "author": ["C Amol", "L Wanzare", "J Obuhuma"], "pub_year": "2023", "venue": "International Conference on Speech \u2026", "abstract": "In the age of freedom of speech, users of the various social media platforms post millions of  unverified messages, resulting in misinformation. Despite these platforms\u2019 set policies"}, "filled": false, "gsrank": 103, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-031-58495-4_1", "author_id": ["SVeANIQAAAAJ", "C7JxmXUAAAAJ", "0KffpQ0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:9EgVABqZSkYJ:scholar.google.com/&output=cite&scirp=102&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D100%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=9EgVABqZSkYJ&ei=FrWsaM7kLPnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:9EgVABqZSkYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://openreview.net/pdf?id=gwy20bFNsX"}}, {"title": "Analyzing the digital traces of political manipulation: The 2016 Russian interference Twitter campaign", "year": "2018", "pdf_data": "Analyzing the Digital Traces of Political Manipulation:\nThe 2016 Russian Interference Twitter Campaign\nAdam Badawy\nUSC Dept. of Political Science & USC\nInformation Sciences Institute\nabadawy@usc.eduEmilio Ferrara\nUSC Information Sciences Institute\nemiliofe@usc.eduKristina Lerman\nUSC Information Sciences Institute\nlerman@isi.edu\nABSTRACT\nUntil recently, social media was seen to promote democratic dis-\ncourse on social and political issues. However, this powerful com-\nmunication platform has come under scrutiny for allowing hostile\nactors to exploit online discussions in an attempt to manipulate\npublic opinion. A case in point is the ongoing U.S. Congress inves-\ntigation of Russian interference in the 2016 U.S. election campaign,\nwith Russia accused of, among other things, using trolls (malicious\naccounts created for the purpose of manipulation) and bots (auto-\nmated accounts) to spread misinformation and politically biased\ninformation. In this study, we explore the effects of this manipu-\nlation campaign, taking a closer look at users who re-shared the\nposts produced on Twitter by the Russian troll accounts publicly dis-\nclosed by U.S. Congress investigation. We collected a dataset with\nover 43 million elections-related posts shared on Twitter between\nSeptember 16 and October 21, 2016 by about 5.7 million distinct\nusers. This dataset included accounts associated with the identified\nRussian trolls. We use label propagation to infer the ideology of all\nusers based on the news sources they shared. This method enables\nus to classify a large number of users as liberal or conservative\nwith precision and recall above 90%. Conservatives retweeted Rus-\nsian trolls about 31 times more often than liberals and produced\n36 times more tweets. Additionally, most retweets of troll content\noriginated from two Southern states: Tennessee and Texas. Using\nstate-of-the-art bot detection techniques, we estimated that about\n4.9% and 6.2% of liberal and conservative users respectively were\nbots. Text analysis on the content shared by trolls reveals that they\nhad a mostly conservative, pro-Trump agenda. Although an ide-\nologically broad swath of Twitter users were exposed to Russian\nTrolls in the period leading up to the 2016 U.S. Presidential election,\nit was mainly conservatives who helped amplify their message.\nKEYWORDS\nSocial media manipulation, Russian trolls, Bots, Misinformation\nACM Reference Format:\nAdam Badawy, Emilio Ferrara, and Kristina Lerman. 2018. Analyzing the\nDigital Traces of Political Manipulation: The 2016 Russian Interference\nTwitter Campaign. In Proceedings of The Web Conference (WWW\u201918). ACM,\nNew York, NY, USA, 8 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn\n1 INTRODUCTION\nSocial media have helped foster democratic conversation about\nsocial and political issues: from the Arab Spring [ 31], to Occupy Wall\nStreet movements [ 16,17] and other civil protests [ 30,55], Twitter\nWWW\u201918, April 2018, Lyon, FR\n2018. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnnand other social media platforms appeared to play an instrumental\nrole in involving the public in policy and political conversations by\ncollectively framing the narratives related to particular social issues,\nand coordinating online and off-line activities. The use of digital\nmedia for political discussions during presidential elections was\nexamined by many studies, including the past four U.S. Presidential\nelections [ 1,8,12,20,21], and other countries like Australia [ 11,29],\nand Norway [ 24]. Findings that focused on the positive effects of\nsocial media, such as increasing voter turnout [ 10] or exposure to\ndiverse political views [ 7] contributed to the general praise of these\nplatforms as a tool for promoting democracy and civic engagement\n[22, 36, 49, 52, 53].\nHowever, concerns regarding the possibility of manipulating\npublic opinion and spreading political misinformation or fake news\nthrough social media were also raised early on [ 33]. These effects\nwere later documented by several studies [ 9,15,23,25,27,46,50,56].\nSocial media have been proven as effective tools to influence in-\ndividuals\u2019 opinions and behaviors [ 4\u20136,13,14] and some studies\neven evaluated the current tools to combat misinformation [ 42].\nComputational tools, like troll accounts and social bots, have been\ndesigned to perform such type of influence operations at scale, by\ncloning or emulating the activity of human users while operating\nat much higher pace (e.g., automatically producing content fol-\nlowing a scripted agenda) [ 26,34,38,54] \u2013 however, it should be\nnoted that bots have been also used, in some instances, for positive\ninterventions [40, 47].\nEarly accounts of the adoption of bots to attempt manipulate\npolitical communication with misinformation started in 2010, dur-\ning the U.S. midterm elections, when social bots were employed to\nsupport some candidates and smear others; in that instance, bots\ninjected thousands of tweets pointing to Web sites with fake news\n[45]. Similar cases were reported during the 2010 Massachusetts\nspecial election [ 39] \u2013 these campaigns are often referred as to\nTwitter bombs, or political astroturf. Unfortunately, oftentimes\ndetermining the actors behind these operations was impossible\n[26,35]. Prior to this work, only a handful of other operations\nwere linked to some specific actors [ 56], e.g., the alt-right attempt\nto smear a presidential candidate before the 2017 French election\n[25]. This is because governments, organizations, and other entities\nwith sufficient resources, can obtain the technological capabilities\nnecessary to covertly deploy hundreds or thousands of accounts\nand use them to either support or attack a given political target.\nReverse-engineering these strategies has proven a challenging re-\nsearch venue [ 2,19,28,51], but it can ultimately lead to techniques\nto identify the actors behind these operations.arXiv:1802.04291v1  [cs.SI]  12 Feb 2018\nWWW\u201918, April 2018, Lyon, FR Adam Badawy, Emilio Ferrara, and Kristina Lerman\nManipulation through misinformation, or \u201cfake news,\u201d has in\nthe past year gain notoriety, as a result of the 2016 U.S. presiden-\ntial election [ 3,32,37,43,48,57]. Data from Facebook and Twitter\nshow that deceptive, made-up content, marketed as political news,\nwas shared with millions of Americans before the 2016 election,1,2\nalthough only a handful of studies have examined this phenome-\nnon in detail [ 32]. One difficulty facing such studies is objectively\ndetermining what is fake news, as there is a range of untruthful-\nness from simple exaggeration to outright lies. Beyond factually\nwrong information, it is difficult to classify information as fake. We\nargue that the key element in the definition of fake news is intent.\nIn order to label some accounts or sources of information as fake,\nanintent to deceive has to be present. A malicious intent to harm\nthe political process and cause distrust in the political system was\nevident in 2,752 now-deactivated Twitter accounts that were later\nidentified as being tied to Russia\u2019s \u201cInternet Research Agency\" troll\nfarm. The U.S. Congress released a list of these accounts as part of\nthe Congress\u2019 investigation of Russian efforts to interfere in the\n2016 presidential election. Since their intent was clearly malicious,\nwe use messages posted by these Russian Troll accounts as a proxy\nfor fake news, and study their spread on Twitter to understand\nthe phenomenon of misinformation and its effects on the modern\npolitical life.\nIn this paper, we aim to answer three crucial questions regarding\nthe spread of misinformation. The first question is: Does political\nideology affect who engages with the producers of fake news and\nhelps propagate it? Is the fake news phenomenon more pronounced\namong liberals or conservatives, or is it evenly spread across the\npolitical spectrum? Second, how active were bots in spreading\nfake news, and where on the political spectrum was this phenom-\nenon more prevalent? Last, did the fake news phenomenon have\ngeographical component, with users located within some states par-\nticipating in the consumption and propagation of misinformation\nmore than others?\nWe collected Twitter data over a period of few weeks in the\nmonths leading up to the election. By continuously polling the Twit-\nter Search API for relevant, election-related content using hashtag-\nand keyword-based queries, we obtained a dataset of over 43 mil-\nlion tweets generated by about 5.7 million distinct users between\nSeptember 16 and October 21, 2016. We were able to successfully\ndetermine the political ideology of most of the users using label\npropagation on the retweet network with precision and recall ex-\nceeding 90%. Next, using advanced machine learning techniques\ndeveloped to discover social bots [ 19,26,51] on users who engaged\nwith Russian trolls, we found that bots existed among both liberal\nand conservative users (although it is worthy to note that most of\nthese users are conservative and pro-Trump). We performed text\nanalysis on the content Russian trolls disseminated, and found that\nthey were mostly concerned with conservative causes and were\nspreading pro-Trump material. Additionally, we offer an extensive\ngeospatial analysis of tweets across the United States, showing that\nit is, as expected, proportionate to the states\u2019 population size.\n1https://blog.twitter.com/official/en_us/topics/company/2017/\nUpdate-Russian-Interference-in-2016--Election-Bots-and-Misinformation.html\n2https://www.theguardian.com/technology/2017/oct/30/\nfacebook-russia-fake-accounts-126-million1.1 Research Questions\nOur work attempts to characterize users who engaged with Russian\ntrolls by resharing their messages in the period leading to the 2016\nUS Presidential election. These interactions serve as a proxy for\nfake news consumption. Specifically, we examine the following\nquestions:\n\u2022What was the role of the users\u2019 political ideology?\n\u2022How many of these accounts were bots, and how was bot\nactivity distributed among liberal and conservative sides?\n\u2022What was the geographic location of the users who engaged\nwith Russian Trolls? Did trolls especially succeed in specific\nareas of the US?\n1.2 Summary of Contributions\nOur findings can be summarized as follows:\n\u2022We proposed a novel way of measuring the production and\nconsumption of fake news through the analysis of activities\nof manipulative accounts (Russian Trolls) on Twitter in the\nrun-up period to the election.\n\u2022Using a network-based machine learning method, we were\nable to successfully determine the political ideology of most\nof the users in our dataset, with precision and recall above\n90%.\n\u2022We ran state-of-the-art bot detection analysis on users who\nengaged with Russian Trolls and determined that bots were\nengaged in both liberal and conservative domains (with the\ncaveat that the majority of the users in our dataset are con-\nservative; thus, most bots were on the conservative side as\nwell).\n\u2022Text analysis shows that Russian trolls were mostly promot-\ning conservative causes and were, specifically, spreading\npro-Trump material.\n\u2022We offered a comprehensive geo-spatial analysis of the tweets.\nOur comprehensive analysis indicates that although the consump-\ntion and dissemination of content produced by Russian Trolls was\ndistributed broadly over the political spectrum, it was especially\nconcentrated among the conservative Twitter accounts. These ac-\ncounts helped amplify the misinformation produced by trolls to\nmanipulate public opinion during the period leading up to the 2016\nU.S. Presidential election.\n2 DATA COLLECTION\n2.1 Twitter Dataset\nWe created a list of hashtags and keywords that relate to the 2016\nU.S. Presidential election. The list was crafted to contain a roughly\nequal number of hashtags and keywords associated with each major\nPresidential candidate: we selected 23 terms, including five terms\nreferring to the Republican Party nominee Donald J. Trump (#don-\naldtrump, #trump2016, #neverhillary, #trumppence16, #trump), four\nterms for Democratic Party nominee Hillary Clinton (#hillaryclin-\nton, #imwithher, #nevertrump, #hillary), and several terms related\nto debates. To make sure our query list was comprehensive, we also\nadded a few keywords for the two third party candidates, including\nthe Libertarian Party nominee Gary Johnson (one term), and Green\nParty nominee Jill Stein (two terms).\nAnalyzing the Digital Traces of Political Manipulation:\nThe 2016 Russian Interference Twitter Campaign WWW\u201918, April 2018, Lyon, FR\nFigure 1: Timeline of the volume of tweets (in blue) and\nusers (in red) generated during our observation period.\nTable 1: Twitter Data Descriptive Statistics.\nStatstic Count\n# of Tweets 43,705,293\n# of Retweets 31,191,653\n# of Distinct Users 5,746,997\n# of Tweets/Retweets with a Url 22,647,507\nBy querying the Twitter Search API at an interval of 10 seconds,\ncontinuously and without interruptions between 15thof September\nand 9thof November 2016, we collected a large dataset containing\n43.7 million unique tweets posted by nearly 5.7 million distinct users.\nTable 1 reports some aggregate statistics of the dataset while Figure\n1 shows the timeline of the volume of the tweets and users during\nthe aforementioned period. The data collection infrastructure ran\ninside an Amazon Web Services (AWS) instance to ensure resilience\nand scalability. We chose to use the Twitter Search API to make sure\nthat we obtained all tweets that contain the search terms of interest\nposted during the data collection period, rather than a sample of\nunfiltered tweets. This precaution we took avoids certain issues\nrelated to collecting sampled data using the Twitter Stream API\nthat had been reported in literature [41].\n2.2 Classification of Media Outlets\nWe classify users by their ideology based on the political leaning\nof the media outlets they shared. The classification algorithm is\ndescribed later in the paper; here, we describe the methodology of\nobtaining ground truth labels for these outlets.\nWe use lists of partisan media outlets compiled by third-party\norganizations, such as AllSides3and Media Bias/Fact Check.4The\ncombined list includes 249 liberal outlets and 212 conservative out-\nlets. After cross-referencing with domains obtained in our Twitter\n3https://www.allsides.com/media-bias/media-bias-ratings\n4https://mediabiasfactcheck.com/\n(a)\n(b)\nFigure 2: Distribution of tweets with links to the top five (a)\nliberal and (b) conservative media outlets.\ndataset, we identified 190 liberal and 167 conservative outlets. We\npicked five media outlets from each partisan category that appeared\nmost frequently in our Twitter dataset and compiled a list of users\nwho tweeted from these outlets. The list of media outlets/domain\nnames for each partisan category is reported in Table 2.\nOverall, 161,907 tweets in the dataset contained a url that pointed\nto one of the top-five liberal media outlets, which were tweeted by\n10,636 users. For the conservative outlets, the numbers are 184,720\ntweets and 7,082 users. Figures 2a and 2b show the distribution of\ntweets with urls from liberal and conservative outlets respectively.\nAs we can see in the figures, Huffington Post and Breitbart make\nup more than 60% of the total volume.\nWe used a polarity rule to label Twitter users as liberal or con-\nservative depending on the number of tweets they produced with\nlinks to liberal or conservative sources. In other words, if a user had\nmore tweets with urls to liberal sources, he/she would be labeled\nliberal and vice versa. Although the overwhelming majority of users\ninclude urls that are either liberal or conservative, we removed any\nusers that had equal number of tweets from each side5. Our final\nset of labeled users include 29,832 users.\n2.3 Russian Trolls\nWe used a list of 2,752 Twitter accounts identified as Russian trolls\nthat was compiled and released by the U.S. Congress6, see Table\n3 for descriptive statistics. Out of the accounts appearing on the\n5We used five categories, as in left, left center, center, right center, right, to make sure\nwe have a final list of users who are unequivocally liberal or conservative and do\nnot fall in the middle. The media outlet lists for the left/right center and center were\ncompiled from the same sources.\n6See https://www.recode.net/2017/11/2/16598312/russia-twitter-trump-twitter-\ndeactivated-handle-list\nWWW\u201918, April 2018, Lyon, FR Adam Badawy, Emilio Ferrara, and Kristina Lerman\nTable 2: Liberal & Conservative Domain Names.\nLiberal Conservative\nwww.huffingtonpost.com www.breitbart.com\nthinkprogress.org www.thegatewaypundit.com\nwww.politicususa.com www.lifezette.com\nshareblue.com www.therebel.media\nwww.dailykos.com theblacksphere.net\nTable 3: Descriptive Statistics on Russian Trolls.\nValue\n# of Russian Trolls 2,735\n# of trolls in our data 221\n# of trolls wrote original tweets 85\n# of original tweets 861\nTable 4: Descriptive statistics of the Retweet Network.\nStatstic Count\n# of nodes 4,678,265\n# of edges 19,240,265\nMax in-degree 278,837\nMax out-degree 12,780\nDensity 8.79E-07\nlist, 221 exist in our Twitter dataset, and 85 of them wrote original\ntweets (861 tweets). Russian trolls in our dataset retweeted 2,354\nother distinct users 6,457 times. Trolls retweeted each other only\n51 times.\nTwitter users can choose to report their location in their profile.\nMost of the self-reported locations of accounts associated with\nRussian trolls were within the U.S. (some provided Russian locations\nin their profile), and most of the tweets were from users who are\nbased in Tennessee and Texas, 49,277 and 26,489 respectively.\nRussian trolls were retweeted 83,719 times, but most of these\nretweets were for three troll accounts only: \u2018TEN_GOP\u2019, 49,286;\n\u2018Pamela_Moore13\u2019, 16,532; and \u2018TheFoundingSon\u2019, 8,755, in total\nmaking over 89% of the times Russian trolls were retweeted. Russian\ntrolls were retweeted by 40,224 distinct users.\n3 DATA ANALYSIS & METHODS\n3.1 Retweet Network\nWe construct a retweet network, containing nodes (Twitter users)\nwith a directed link between them if one user retweeted a post\nof another. Table 4 shows the descriptive statistics of the retweet\nnetwork. It is a sparse network with a giant component that includes\n4,474,044 nodes.Table 5: Precision & Recall scores for the seed users and\nhyper-partisan users test sets.\nSeed Users Hyper-Partisan Users\nPrecision 0.91 0.93\nRecall 0.91 0.93\n3.2 Label Propagation\nWe used label propagation7to classify Twitter accounts as liberal\nor conservative. In a network-based label propagation algorithm\neach node is assigned a label, which is updated iteratively based on\nthe labels of node\u2019s network neighbors. In label propagation, a node\ntakes the most frequent label of its neighbors as its own new label.\nThe algorithm proceeds updating labels iteratively and stops when\nthe labels no longer change (see [ 44] for more information). The\nalgorithm takes as parameters (i) weights, in-degree or how many\ntimes node iretweeted node j; (ii) seeds (the list of labeled nodes).\nWe fix the seeds\u2019 labels so they do not change in the process, since\nthis seed list also serves as our ground truth.\nWe constructed a retweet network where each node corresponds\nto a Twitter account and a link exists between pairs of nodes when\none of them retweets a message posted by the other. We used\nthe 29k users mentioned in the media outlets sections as seeds,\nthose who mainly retweet messages from either the liberal or the\nconservative media outlets in table 2, and label them accordingly.\nWe then run label propagation to label the remaining nodes in the\nretweet network.\nTo validate results of the label propagation algorithm, we applied\nstratified cross (5-fold) validation to the set of 29k seeds. We train\nthe algorithm on 4/5 of the seed list and see how it performs on the\nremaining 1/5. The precision and recall scores are around 0.91.\nTo further validate the labeling algorithm, we noticed that a\ngroup of twitter accounts puts media outlet urls as their personal\nlink/website. We compiled a list of these hyper-partisan twitter\nusers who has the domain names from table 2 in the profiles and\nused the same approach explained in the previous paragraph (strat-\nified 5-fold cross-validation). The precision and recall scores for the\ntest set for these users were around 0.93. Table 5 show the precision\nand recall scores for the two validation methods we used, both\nlabeled more than 90% of the test set users correctly, cementing our\nconfidence in the performance of the labeling algorithm.\n3.3 Bot Detection\nDetermining whether either human or a bot controls a social media\naccount has proven a very challenging task [ 26,51]. We used an\nopenly accessible solution called Botometer (a.k.a. BotOrNot) [ 19],\nconsisting of both a public Web site (https://botometer.iuni.iu.edu/)\nand a Python API (https://github.com/IUNetSci/botometer-python),\nwhich allow for making this determination. Botometer is a machine-\nlearning framework that extracts and analyses a set of over one\nthousand features, spanning content and network structure, tem-\nporal activity, user profile data, and sentiment analysis to produce\na score that suggests the likelihood that the inspected account\n7We used the algorithm in the Python version of the Igraph library [18]\nAnalyzing the Digital Traces of Political Manipulation:\nThe 2016 Russian Interference Twitter Campaign WWW\u201918, April 2018, Lyon, FR\nis indeed a social bot. Extensive analysis revealed that the two\nmost important classes of features to detect bots are, maybe un-\nsurprisingly, the metadata and usage statistics associated with the\nuser accounts. The following indicators provide the strongest sig-\nnals to separate bots from humans: (i) whether the public Twitter\nprofile looks like the default one or it is customized (it requires\nsome human efforts to customize the profile, therefore bots are\nmore likely to exhibit the default profile setting); (ii) absence of\ngeographical metadata (humans often use smartphones and the\nTwitter iPhone/Android App, which records as digital footprint\nthe physical location of the mobile device); and, (iii) activity sta-\ntistics such as total number of tweets and frequency of posting\n(bots exhibit incessant activity and excessive amounts of tweets),\nproportion of retweets over original tweets (bots retweet contents\nmuch more frequently than generating new tweets), proportion\nof followers over followees (bots usually have less followers and\nmore followees), account creation date (bots are more likely to have\nrecently-created accounts), randomness of the username (bots are\nlikely to have randomly-generated usernames).\nBotometer was trained with thousands of instances of social\nbots, from simple to sophisticated, with an accuracy above 95 per-\ncent [ 19]. Typically, Botometer yields likelihood scores above 50\npercent only for accounts that look suspicious to a scrupulous analy-\nsis. We adopted the Python Botometer API to systematically inspect\nthe most active users in our dataset. The Python Botometer API\nqueries the Twitter API to extract 300 recent tweets and publicly\navailable account metadata, and feeds these features to an ensemble\nof machine learning classifiers, which produce a bot score.\nTo label accounts as bots, we use the fifty-percent threshold \u2013\nwhich has proven effective in prior studies [ 19] \u2013 an account is\nconsidered to be a bot if the bot score is above 0.5.\n3.4 Geo-location\nThere are two ways to identity the location of tweets produced\nby users. One way is to collect the coordinates of the location the\ntweets were sent from; however, this is only possible if users enable\nthe geolocation option on their Twitter accounts. The second way\nis to analyze the self-reported home locations in users\u2019 profiles. The\nlatter includes substantially more noise, since many people write\nfictitious or imprecise locations, for example, they may identify the\nstate and the country they reside in, but not the city.\nThere were 36,351 tweets with exact coordinates in our dataset.\nThe distribution of tweets across the fifty states tended to be con-\ncentrated in the South, with Kentucky being the state with the\nhighest number of geolocated tweets. It is hard to know why that\nis the case; besides, geo-tagged tweets in this dataset comprise less\nthan 0.001% of the whole dataset.\nTweets and users\u2019 self-reported locations make up substantially\nmore of our dataset than geo-tagged tweets. More than 3.8 million\nTwitter users provided a location in their profile, and out of those\nthat are intelligible and located within the US, 1.6 Million remained.\nFrom users\u2019 locations, we mapped over 10.5 Million tweets to some\nU.S, States, as shown in Figure 3. The distribution of the tweets\nand users seems to be as expected population-wise, although it is\nslightly less than expected for the state of California, provided that\nit is the most populous state in the nation.\nFigure 3: Self-reported sources for tweets; white/non-\nexisting states mean no tweets/users are located within\nthese states.\nTable 6: Breakdown of the Russian Trolls by political ideol-\nogy, with the ratio of conservative to liberal trolls.\nLiberal Conservative Ratio\n# of trolls 107 108 1\n# of trolls w orginial tweets 15 64 4.3\n# of original tweets 44 844 19\n4 RESULTS\n4.1 Activity of Russian Trolls\nAlthough the predicted labels for the 215 Russian troll accounts\nin our dataset is almost equally divided between liberal and con-\nservative, with 107 accounts labeled as liberal and 108 labeled as\nconservative, the two groups are extremely different in terms of\ntheir activity (see table 6). While there are only 15 liberal Russian\ntrolls who wrote original tweets, there are 64 conservative trolls\nwho produced original content. Left leaning trolls wrote 44 origi-\nnal tweets, while conservatives wrote 844 original tweets. Table 7\nshows the top 20 stem words from tweets of liberal and conservative\ntrolls respectively.\n4.2 Users Engaged with Russian Trolls\nConcerning the users who retweeted Russian trolls, which we call\nspreaders, three key questions emerge: What is their political ideol-\nogy (liberal vs conservative)? Where are they located? How many\nof them are bots?\n4.2.1 Political Ideology. Spreaders tell a fascinating story (see\ntables 8 & 9). There are 28,274 spreaders in our dataset that wrote\noriginal tweets. They produced over 1.5 Million original tweets\nand over 12 Million tweets and retweets, not counting the ones\nfrom Russian trolls. Looking at the content of the top 10 users, we\ncan easily identify them as conservative; besides, they produced an\nWWW\u201918, April 2018, Lyon, FR Adam Badawy, Emilio Ferrara, and Kristina Lerman\nTable 7: Top 20 stemmed words from the tweets of Russian\nTrolls classified as liberal and conservative.\nLiberal count Conservative count\ntrump 14 trumpforpresid 486\ndebat 10 trump 241\nnevertrump 6 trumppence16 227\nlike 5 hillaryforprison2016 168\n2016electionin3word 5 vote 127\nelections2016 4 maga 113\nimwithh 4 neverhillari 106\nobama 3 election2016 102\nneed 3 hillari 100\nbetteralternativetodeb 3 hillaryclinton 85\nwomen 3 trump2016 80\nwould 3 draintheswamp 50\nvote 3 trumptrain 48\nmondaymotiv 2 debat 48\nlast 2 realdonaldtrump 45\noh 2 electionday 43\nthing 2 clinton 41\ndamn 2 makeamericagreatagain 34\nsee 2 votetrump 32\ndefeat 2 america 31\nTable 8: Descriptive statistics of spreaders, i.e., users who\nretweeted Russian Trolls.\nValue\n# of spreaders 40,224\n# of times retweeted trolls 83,719\n# of spreaders with original tweets 28,274\n# of original tweets >1.5 Million\n# of original tweets and retweets >12 Million\nunreasonable amount of tweets in such a short period. In the next\nparagraph we will look systematically at these users\u2019 activities by\npolitical leaning.\nThere are more than 42 thousand tweets by the liberal spreaders\nand more than 1.5 million tweets by conservative ones. There are\n892 liberal and 27,382 conservative spreaders. The top stemmed\nwords in the liberals\u2019 tweets indicate support for Clinton, while\nthe conservatives\u2019 postings openly support Trump. The top urls\nfor the liberals include media outlets, such as: Huffington Post and\nNBC News, while conservatives tweeted from Breitbart, The Gate-\nway Pundit, and Info Wars. For the profile url, liberals mostly had\nsocial network accounts, while conservatives, besides social net-\nwork accounts, put \u201cwww.donaldjtrump.com\u201d and \u201clyingcrooked-\nhillary.com\u201d.\n4.2.2 Geospaitial Analysis. we can see in Figures 4a and 4b,\nliberals\u2019 tweets come from fewer states and some Democratic states\nstand out as a major source of the tweets, such as the state of\nNew York. For the conservative users, the tweets come from higher\nnumber of states (which can be just an artifact of the conservatives\u2019Table 9: Breakdown by political ideology of users who\nspread Russian Troll content and wrote original tweets.\nLiberal Conservative Ratio\n# of spreaders 892 27,382 31\n# of tweets >42,000 >1.5 Million 36\n(a)\n(b)\nFigure 4: Self-reported sources for tweets for liberal users\nwho retweeted Russian trolls (a), and for conservatives (b);\nwhite/non-existing states mean no tweets/users are located\nwithin these states.\ntweet volume) and prominent Republican states, such as Texas\nand Florida stand out as the biggest geographic sources of the\nconservatives\u2019 tweets.\n4.2.3 Bots. Using the approach explained in the Bot detection\nsection, we were able to obtain bot scores for 34,160 out of the 40,224\nspreaders. The number of accounts that has a bot score above 0.5\nand can be considered bots are 2,126 accounts.\nAnalyzing the Digital Traces of Political Manipulation:\nThe 2016 Russian Interference Twitter Campaign WWW\u201918, April 2018, Lyon, FR\nTable 10: Bot Analysis on Spreaders (those with bot scores).\nLiberal Conservative Ratio\n# of spreaders 1,506 32,513 22\n# of tweets 224,943 11,928,886 53\n# of bots 75 2,018 27\n# of tweets by bots 18,749 955,583 51\nAnswering the third question is trickier, since most of the spread-\ners are conservative (see table 10 for spreaders\u2019 bot analysis by po-\nlitical ideology). But putting that aside, out of the 34,160 spreaders\nwith bot scores, 1,506 are liberal and 75 of them have bot scores\nabove 0.5, about 4.9% of the total. As for the conservatives, there\nare 32,513 spreaders, with 2,018 who have bot scores more than 0.5,\nrepresenting around 6.2% of the total. In terms of tweet/retweet pro-\nduction, liberal spreaders produced 224,943 tweets/retweets with\n18,749 tweets/retweets by users who have a bot score above 0.5, rep-\nresenting around 8.3%. For conservative spreaders, they produced\n11,928,886 tweets/retweets, with 955,583 from users with bot score\nmore than 0.5, around 8% of the total.\nFigure 5 shows the probability density of bot scores of liberal (top)\nand conservative (bottom) spreaders respectively. Again, putting\nthe disproportionate number of liberals to conservatives aside, the\ndensity of bot scores seem to be similar to each other, with the\nmajority of the users ranging from 0 to 0.6.\n5 CONCLUSIONS\nThe dissemination of information and the mechanisms for demo-\ncratic discussion have radically changed since the advent of digital\nmedia, especially social media. Platforms like Twitter have been ex-\ntensively praised for their contribution to democratization of public\ndiscourse on civic and political issues. However, many studies have\nalso highlighted the perils associated with the abuse of these plat-\nforms. The spread of deceptive, false and misleading information\naimed at manipulating public opinion are among those risks.\nIn this work, we investigated the role and effects of misinfor-\nmation, using the content produced by Russian Trolls on Twitter\nas a proxy for misinformation. We collected tweets posted during\nthe period between 16 September and 21 October 2016 related to\nthe U.S. presidential election using the Twitter Search API and a\nmanually compiled list of keywords and hashtags. We showed that\nthat misinformation (produced by Russian Trolls) was shared more\nwidely by conservatives than liberals on Twitter. Although there\nwere about 4 times as many Russian Trolls posting conservative\nviews as liberal ones, the former produced almost 20 times more\ncontent. In terms of users who retweeted these trolls, there were\nabout 30 times more conservatives than liberals. Conservatives also\noutproduced liberals in terms on content, at a rate of 35:1. Using\nstate-of-the-art bot detection method, we estimated that about 4.9%\nand 6.2% of the liberal and conservative users are bots.\nThe spread of misinformation by malicious actors can have se-\nvere negative consequences. It can enhance malicious information\nand polarize political conversations, causing confusion and social\nFigure 5: Distribution of the probability density of bot scores\nassigned to liberal users who retweet Russian Trolls (top)\nand for conservative users (bottom).\ninstability. Political scientists are currently investigating the conse-\nquences of such phenomena [ 50,56]. We plan to explore in partic-\nular the issue of how malicious information spread via exposure\nand the role of peer effect. Concluding, it is important to stress\nthat, although our analysis unveiled the current state of the polit-\nical debate and agenda pushed by the Russian Trolls who spread\nmalicious information, it is impossible to account of all the ma-\nlicious efforts aimed at manipulation during the last presidential\nelection. State- and non-state actors, local and foreign governments,\npolitical parties, private organizations, and even individuals with\nadequate resources [ 35], could obtain operational capabilities and\ntechnical tools to construct misinformation campaigns and deploy\narmies of social bots to affect the directions of online conversations.\nTherefore, future efforts will be required by the machine learning\nresearch and social sciences communities to study this issue in\ndepth and develop more sophisticated detection techniques capable\nof unmasking and fighting these malicious efforts.\nACKNOWLEDGMENTS\nThe authors gratefully acknowledge support by the Air Force Office of\nScientific Research (AFOSR, award number FA9550-17-1-0327). The views\nand conclusions contained herein are those of the authors and should not be\ninterpreted as necessarily representing the official policies or endorsements,\neither expressed or implied, of AFOSR or the U.S. Government.\nWWW\u201918, April 2018, Lyon, FR Adam Badawy, Emilio Ferrara, and Kristina Lerman\nREFERENCES\n[1]Lada A Adamic and Natalie Glance. 2005. The political blogosphere and the 2004\nUS election: divided they blog. In Proceedings of the 3rd international workshop\non Link discovery . ACM, 36\u201343.\n[2]Abdulrahman Alarifi, Mansour Alsaleh, and AbdulMalik Al-Salman. 2016. Twitter\nturing test: Identifying social machines. Information Sciences 372 (2016), 332\u2013346.\n[3]Hunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the\n2016 election. Journal of Economic Perspectives 31, 2 (2017), 211\u201336.\n[4]Sinan Aral, Lev Muchnik, and Arun Sundararajan. 2009. Distinguishing influence-\nbased contagion from homophily-driven diffusion in dynamic networks. Proceed-\nings of the National Academy of Sciences 106, 51 (2009), 21544\u201321549.\n[5]Sinan Aral and Dylan Walker. 2012. Identifying influential and susceptible\nmembers of social networks. Science 337, 6092 (2012), 337\u2013341.\n[6]Eytan Bakshy, Jake M Hofman, Winter A Mason, and Duncan J Watts. 2011.\nEveryone\u2019s an influencer: quantifying influence on twitter. In Proceedings of the\nfourth ACM international conference on Web search and data mining . ACM, 65\u201374.\n[7]Eytan Bakshy, Solomon Messing, and Lada A Adamic. 2015. Exposure to ideologi-\ncally diverse news and opinion on Facebook. Science 348, 6239 (2015), 1130\u20131132.\n[8]Marija Anna Bekafigo and Allan McBride. 2013. Who tweets about politics?\nPolitical participation of Twitter users during the 2011gubernatorial elections.\nSocial Science Computer Review 31, 5 (2013), 625\u2013643.\n[9]Alessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US\nPresidential election online discussion. First Monday 21, 11 (2016).\n[10] Robert M Bond, Christopher J Fariss, Jason J Jones, Adam DI Kramer, Cameron\nMarlow, Jaime E Settle, and James H Fowler. 2012. A 61-million-person experi-\nment in social influence and political mobilization. Nature 489, 7415 (2012).\n[11] Axel Bruns and Jean E Burgess. 2011. The use of Twitter hashtags in the formation\nof ad hoc publics. In Proceedings of the 6th European Consortium for Political\nResearch (ECPR) General Conference 2011 .\n[12] Juliet E Carlisle and Robert C Patton. 2013. Is social media changing how we un-\nderstand political engagement? An analysis of Facebook and the 2008 presidential\nelection. Political Research Quarterly 66, 4 (2013), 883\u2013895.\n[13] Damon Centola. 2010. The spread of behavior in an online social network\nexperiment. Science 329, 5996 (2010), 1194\u20131197.\n[14] Damon Centola. 2011. An experimental study of homophily in the adoption of\nhealth behavior. Science 334, 6060 (2011), 1269\u20131272.\n[15] Michael Conover, Jacob Ratkiewicz, Matthew R Francisco, Bruno Gon\u00e7alves,\nFilippo Menczer, and Alessandro Flammini. 2011. Political polarization on twitter.\nICWSM 133 (2011), 89\u201396.\n[16] Michael D Conover, Clayton Davis, Emilio Ferrara, Karissa McKelvey, Filippo\nMenczer, and Alessandro Flammini. 2013. The geospatial characteristics of a\nsocial movement communication network. PloS one 8, 3 (2013), e55957.\n[17] Michael D Conover, Emilio Ferrara, Filippo Menczer, and Alessandro Flammini.\n2013. The digital evolution of occupy wall street. PloS one 8, 5 (2013), e64679.\n[18] Gabor Csardi and Tamas Nepusz. 2006. The igraph software package for complex\nnetwork research. InterJournal, Complex Systems 1695, 5 (2006), 1\u20139.\n[19] Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and\nFilippo Menczer. 2016. Botornot: A system to evaluate social bots. In Proceedings\nof the 25th International Conference Companion on World Wide Web . International\nWorld Wide Web Conferences Steering Committee, 273\u2013274.\n[20] Nicholas A Diakopoulos and David A Shamma. 2010. Characterizing debate\nperformance via aggregated twitter sentiment. In Proceedings of the SIGCHI\nConference on Human Factors in Computing Systems . ACM, 1195\u20131198.\n[21] Joseph DiGrazia, Karissa McKelvey, Johan Bollen, and Fabio Rojas. 2013. More\ntweets, more votes: Social media as a quantitative indicator of political behavior.\nPloS one 8, 11 (2013), e79449.\n[22] Robin Effing, Jos Van Hillegersberg, and Theo Huibers. 2011. Social media and\npolitical participation: are Facebook, Twitter and YouTube democratizing our\npolitical systems? Electronic participation (2011), 25\u201335.\n[23] Sara El-Khalili. 2013. Social media as a government propaganda tool in post-\nrevolutionary Egypt. First Monday 18, 3 (2013).\n[24] Gunn Sara Enli and Eli Skogerb\u00f8. 2013. Personalized campaigns in party-centred\npolitics: Twitter and Facebook as arenas for political communication. Information,\nCommunication & Society 16, 5 (2013), 757\u2013774.\n[25] Emilio Ferrara. 2017. Disinformation and social bot operations in the run up to\nthe 2017 French presidential election. First Monday 22, 8 (2017).\n[26] Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro\nFlammini. 2016. The rise of social bots. Comm. of the ACM 59, 7 (2016), 96\u2013104.\n[27] Adam Fourney, Miklos Z Racz, Gireeja Ranade, Markus Mobius, and Eric Horvitz.\n2017. Geographic and Temporal Trends in Fake News Consumption During the\n2016 US Presidential Election. In CIKM , Vol. 17. 6\u201310.\n[28] Carlos Freitas, Fabricio Benevenuto, Saptarshi Ghosh, and Adriano Veloso. 2015.\nReverse engineering socialbot infiltration strategies in twitter. In Proceedings of\nthe 2015 IEEE/ACM ASONAM . ACM, 25\u201332.\n[29] Rachel K Gibson and Ian McAllister. 2006. Does cyber-campaigning win votes?\nOnline communication in the 2004 Australian election. Journal of Elections, Public\nOpinion and Parties 16, 3 (2006), 243\u2013263.[30] Sandra Gonz\u00e1lez-Bail\u00f3n, Javier Borge-Holthoefer, and Yamir Moreno. 2013. Broad-\ncasters and hidden influentials in online protest diffusion. American Behavioral\nScientist 57, 7 (2013), 943\u2013965.\n[31] Sandra Gonz\u00e1lez-Bail\u00f3n, Javier Borge-Holthoefer, Alejandro Rivero, and Yamir\nMoreno. 2011. The dynamics of protest recruitment through an online network.\nScientific reports 1 (2011), 197.\n[32] Andrew Guess, Brendan Nyhan, and Jason Reifler. 2018. Selective Exposure to\nMisinformation: Evidence from the consumption of fake news during the 2016 U.S.\npresidential campaign . Technical Report.\n[33] Philip Howard. 2006. New media campaigns and the managed citizen . Cambridge.\n[34] Tim Hwang, Ian Pearce, and Max Nanis. 2012. Socialbots: Voices from the fronts.\ninteractions 19, 2 (2012), 38\u201345.\n[35] Bence Kollanyi, Philip N Howard, and Samuel C Woolley. 2016. Bots and automa-\ntion over Twitter during the first US Presidential debate. Data Memo (2016).\n[36] Brian D Loader and Dan Mercea. 2011. Networking democracy? Social media\ninnovations and participatory politics. Information, Communication & Society 14,\n6 (2011), 757\u2013769.\n[37] Nicco Mele, David Lazer, Matthew Baum, Nir Grinberg, Lisa Friedland, Kenneth\nJoseph, Will Hobbs, and Carolina Mattsson. 2017. Combating Fake News: An\nAgenda for Research and Action. (2017).\n[38] Johnnatan Messias, Lucas Schmidt, Ricardo Oliveira, and Fabr\u00edcio Benevenuto.\n2013. You followed my bot! Transforming robots into influential users in Twitter.\nFirst Monday 18, 7 (2013).\n[39] Panagiotis T Metaxas and Eni Mustafaraj. 2012. Social media and the elections.\nScience 338, 6106 (2012), 472\u2013473.\n[40] Bjarke Monsted, Piotr Sapiezynski, Emilio Ferrara, and Sune Lehmann. 2017.\nEvidence of complex contagion of information in social media: An experiment\nusing Twitter bots. PLOS ONE 12, 9 (09 2017), 1\u201312.\n[41] Fred Morstatter, J\u00fcrgen Pfeffer, Huan Liu, and Kathleen M Carley. [n. d.]. Is\nthe Sample Good Enough? Comparing Data from Twitter\u2019s Streaming API with\nTwitter\u2019s Firehose. In ICWSM . 400\u2013408.\n[42] Gordon Pennycook and David G. Rand. 2017. Assessing the Effect of \u201cDisputed\u201d\nWarnings and Source Salience on Perceptions of Fake News Accuracy. (2017).\n[43] Gordon Pennycook and David G Rand. 2017. Who falls for fake news? The\nroles of analytic thinking, motivated reasoning, political ideology, and bullshit\nreceptivity. (2017).\n[44] Usha Nandini Raghavan, R\u00e9ka Albert, and Soundar Kumara. 2007. Near linear\ntime algorithm to detect community structures in large-scale networks. Physical\nreview E 76, 3 (2007), 036106.\n[45] Jacob Ratkiewicz, Michael Conover, Mark Meiss, Bruno Gon\u00e7alves, Snehal Patil,\nAlessandro Flammini, and Filippo Menczer. 2011. Truthy: mapping the spread of\nastroturf in microblog streams. In Proceedings of the 20th international conference\ncompanion on World wide web . ACM, 249\u2013252.\n[46] Jacob Ratkiewicz, Michael Conover, Mark R Meiss, Bruno Gon\u00e7alves, Alessandro\nFlammini, and Filippo Menczer. 2011. Detecting and Tracking Political Abuse in\nSocial Media. ICWSM 11 (2011), 297\u2013304.\n[47] Saiph Savage, Andres Monroy-Hernandez, and Tobias H\u00f6llerer. 2016. Botivist:\nCalling volunteers to action using online bots. In 19th ACM Conference on\nComputer-Supported Cooperative Work & Social Computing . ACM, 813\u2013822.\n[48] Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol, Alessandro Flammini,\nand Filippo Menczer. 2017. The spread of fake news by social bots. arXiv preprint\narXiv:1707.07592 (2017).\n[49] Clay Shirky. 2011. The political power of social media: Technology, the public\nsphere, and political change. Foreign affairs (2011), 28\u201341.\n[50] Samantha Shorey and Philip N Howard. 2016. Automation, Algorithms, and\nPolitics / Automation, Big Data and Politics: A Research Review. International\nJournal of Communication 10 (2016), 24.\n[51] VS Subrahmanian, Amos Azaria, Skylar Durst, Vadim Kagan, Aram Galstyan,\nKristina Lerman, Linhong Zhu, Emilio Ferrara, Alessandro Flammini, and Filippo\nMenczer. 2016. The DARPA Twitter bot challenge. Computer 49, 6 (2016), 38\u201346.\n[52] Zeynep Tufekci. 2014. Big Questions for Social Media Big Data: Representative-\nness, Validity and Other Methodological Pitfalls. ICWSM 14 (2014), 505\u2013514.\n[53] Zeynep Tufekci and Christopher Wilson. 2012. Social media and the decision\nto participate in political protest: Observations from Tahrir Square. Journal of\nCommunication 62, 2 (2012), 363\u2013379.\n[54] Onur Varol, Emilio Ferrara, Clayton Davis, Filippo Menczer, and Alessandro\nFlammini. 2017. Online Human-Bot Interactions: Detection, Estimation, and\nCharacterization. In ICWSM . 280\u2013289.\n[55] Onur Varol, Emilio Ferrara, Christine L Ogan, Filippo Menczer, and Alessandro\nFlammini. 2014. Evolution of online user behavior during a social upheaval. In\nProceedings of the 2014 ACM conference on Web science . ACM, 81\u201390.\n[56] Samuel C Woolley and Philip N Howard. 2016. Automation, Algorithms, and\nPolitics / Political Communication, Computational Propaganda, and Autonomous\nAgents \u2013 Introduction. International Journal of Communication 10 (2016), 9.\n[57] Savvas Zannettou, Tristan Caulfield, Emiliano De Cristofaro, Michael Sirivianos,\nGianluca Stringhini, and Jeremy Blackburn. 2018. Disinformation Warfare: Un-\nderstanding State-Sponsored Trolls on Twitter and Their Influence on the Web.\narXiv:1801.09288 (2018).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Analyzing the digital traces of political manipulation: The 2016 Russian interference Twitter campaign", "author": ["A Badawy", "E Ferrara", "K Lerman"], "pub_year": "2018", "venue": "2018 IEEE/ACM international \u2026", "abstract": "Until recently, social media was seen to promote democratic discourse on social and  political issues. However, this powerful communication platform has come under scrutiny for"}, "filled": false, "gsrank": 107, "pub_url": "https://ieeexplore.ieee.org/abstract/document/8508646/", "author_id": ["", "0r7Syh0AAAAJ", "PlAG11IAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:J6fDGjFOfUAJ:scholar.google.com/&output=cite&scirp=106&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D100%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=J6fDGjFOfUAJ&ei=FrWsaM7kLPnSieoPxKLpgQ0&json=", "num_citations": 530, "citedby_url": "/scholar?cites=4646956363325613863&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:J6fDGjFOfUAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1802.04291"}}, {"title": "The Role of Media in the Acceptance of Real News or Fake News", "year": "NA", "pdf_data": "\u00a9THOMAS J FROEHLICH, PH.D.\nPROFESSOR EMERITUS \nSCHOOL OF INFORMATION\nKENT STATE UNIVERSITY\nKENT OH 44240 \nTFROEHLI@KENT.EDU\nHTTP://PERSONAL.KENT.EDU/~TFROEHLI/The Role of Media in the Acceptance of \nReal News orFake News\nOverview\n\uf097My current research has been interested in authoritative \ninformation and disinformation \n\uf0a1How genuine information is created, authorized and disseminated\n\uf0a1How disinformation is created, authorized and disseminated and how \ndisinformation succeeds in light of or despite the content of the message\n\uf097I will compare and contrast specific examples of cognitive \nauthorities of the New York Times and Fox News\n\uf097You may not agree with everything that I detail here, but it is a \nsynthesis of my research from a variety of fields, psychology, \nphilosophy, communication studies, information studies, \njournalism, etc.\n\uf097I back my claims by extensive research, based on evidence, facts, logic and reasoning.  You can dispute my findings, but \nthey can only be challenged with evidence, facts, logic and \nreasoning.  Sometimes one may be able to develop an alternative interpretation of data, facts or evidence.  If so, I \nwould encourage your sharing such interpretations with me.2\nOutline\n\uf097Cognitive Authorities\n\uf097Knowledge, beliefs, second- hand knowledge\n\uf097Mass Media as Cognitive Authorities\n\uf097New York Times versus Fox News\n\uf097Persistence of Fox News\n\uf097Psychological Factors, Cognitive Bias, Trump Supporters\n\uf097Nature of Fox\u2019s Cognitive Authority\n\uf097Unbalanced Analysis?\n\uf097Social Media as Cognitive Authorities\n\uf097Unregulated Platforms and Fairness Doctrine\n\uf097Conclusion:  The Age of Inflamed Grievances3\nCognitive Authorities\n\uf097What is a cognitive authority? \n\uf097When one lacks experience, education, or knowledge, or does \nnot have the time or inclination to acquire such, a cognitive \nauthority is a person, organization, media source, group, or \nleader whose information one takes as second- hand \nknowledge based on that entity\u2019s credibility, trustworthiness, \nand reliability. One can be mistaken about whether the \nauthority is sound or not.\n\uf097As we grow up and as we live, we cannot experience everything and so some of what we know is taken from \nindividuals (e.g. father, mother, friends, leader), groups (e.g., \nclassmates), or institutions (e.g., schools, books).  \n\uf097For this paper, the focus is on news sources including social media, political leaders, political parties, and religious \nleaders). 4\nPatrick Wilson and Cognitive Authority\n\uf097Patrick Wilson wrote a work called Second- hand knowledge -an inquiry \ninto cognitive authority in 1983 which promoted a variety of notions.\n\uf097He argues that we can construct knowledge in one of two ways:  \n(1) We can construct first -hand knowledge based on our experience.  Unfortunately, our \nexperience is limited.\n(2) We can construct knowledge from or through others, second- hand knowledge, something \nthat we do not know for sure but take at the word of others\n\uf097Question:  taking an inventory of the information in your mind, how much do \nyou really know?  How much is derived from the knowledge of others?\n\uf097Second- hand knowledge comes in various degrees \u2013some people know \nwhat they are talking about, and others can be self -inflated liars\n\uf097If we have questions about political issues and are not well versed in the area, we are inclined to ask a friend, associate, or other person who is knowledgeable in that area \u2013they become our cognitive authority on that \ntopic, assuming that they are trustworthy, credible and have a level of \nexpertise.\n\uf097We can have many cognitive authorities based on various topics of concern\n\uf097My use of cognitive authority expands Patrick Wilson\u2019s original description.5\nCognitive Authorities\n\uf097Cognitive authority is related to credibility, competence, and \ntrustworthiness.\n\uf097Cognitive authority exists on a continuum, exists in relation to a sphere of interest, and involves at least two people.  \n\uf097Cognitive authorities can be friends, colleagues, peers, news media, Internet blogs, Twitter feeds, news channels, social media sites, etc. \n\uf097Examples of cognitive authorities are news sites representing different points of a political spectrum: e.g., Fox News or MSNBC.\n\uf097For news sites, the measure of their credibility or trustworthiness is related to consumer loyalty. This observation is true for both authentic \nand pseudo- cognitive authorities.6\nCredibility\nCredibility is not a simple judgment, though it is  claimed to be \u201cintuitive.\u201d  \nAccording to Rieh (2010) \n\uf097\u201cMost credibility researchers agree that credibility assessment results \nfrom simultaneously evaluating multiple dimensions. \n\uf097\u201cAmong these, two key dimensions are identified: trustworthiness and \nexpertise.\n\uf097\u201cTrustworthiness is a core dimension in credibility assessment that captures the perceived goodness and morality of the source.\n\uf097\u201cThe perception that a source is fair, unbiased, and truthful contributes \nto the trustworthiness of information. Trustworthiness is, however, not a \nsynonym for credibility because people also must recognize expertise \nin order to deem information credible.\u201d (Rieh, 2010, 1337).\n\uf097It is a key point that trustworthiness is not equivalent to credibility because expertise is also required.7\nCredibility\n\uf097\u201cExpertise reflects perceived knowledge, skill, and experience of the \nsource.\n\uf097\u201cExpertise is likewise an important factor given its close relationship to \npeople\u2019s perceptions of a source\u2019s ability to provide information that is \nboth accurate and valid.\u201d(Rieh, 2010, 1337- 1138).\n\uf097Before the era of fake news, trustworthiness and expertise had clear \npositive conceptualizations.\n\uf097But we see that instances of doxing and fake news pose interesting \ndistortions of these words.  \n\uf097Many listeners of Fox News believe that it is trustworthy and even that \nexpertise resides in the assertions of its political commentators, which \nare often inconsistent over time and which are often lies or reflect \npartisan beliefs, without evidence.  8\nKnowledge, Belief and Second- Hand Knowledge\n\uf097Two questions that are of interest is:\n\uf097(1) What is the cognitive state of the creators or \ntransmitters of information on news media\n\uf097(2) What is the cognitive state of the receivers of such information?\n\uf097Is it knowledge, belief (true belief, false belief, and beliefs that are neither true or false)?  How do they differ among senders and receivers?\n\uf097Senders and receivers have related and different motivations: \n\uf0a1Senders:  power, money, advancing a political agenda\n\uf0a1Receivers:  information, confirmation bias, supporting a political \nagenda9\nKnowledge, Belief and Second- Hand Knowledge\n\uf097I expand on the notion of belief by arguing that beliefs come in three \ngeneral types: (1) true beliefs; (2) beliefs that are preferences, being \nneither true or false; and (3) false beliefs.  \n\uf097\u201cTrue belief\u201d is a belief that could be turned into knowledge (or which can be justified) through experience, education or research, such as seeking \nevidence from reliable sources. If one did not know that the hypotenuse of \na right triangle is the square root of the sum of its sides squared, I could \ntake a course in geometry to learn it. If one believes that Pizzagate is a \nfake news story, one can do the research using reliable sources for \nconfirming that assessment.  \n\uf097If I think that Adele is a better singer than Lady Gaga, that may be true for one person and not another.  Matters of taste, for which one can make \narguments, are never true per se. They are matters of preferential beliefs that will vary among individuals or groups, even though one can advance \narguments for why one would prefer one over the other. \n\uf097There are \u201cfalse beliefs,\u201d e.g., climate change denial, which cannot be \nconverted into truth.  Some false beliefs are often tried to be portrayed as \ntrue through appeals to false or selective expertise, faulty data collection or \nmanipulation, or false evidence.  10\nKnowledge, Belief and Second- Hand Knowledge\n\uf097During the current coronavirus pandemic, Trump has made claims for his \nmanaging the pandemic in the best possible way, that he had anticipated \nthe pandemic, that there were enough tests and ventilators\n\uf097All of these claims are verifiably false (by citing scientific evidence, referring to bona fide experts or showing audiovisual recordings about his \nclaims), but that does not seem to deter Fox viewers either to endorse his \nleadership or to ignore, dismiss or rationalize (e.g., he really did not mean \nwhat he said) some of his claims (e.g., to internally use bleach or \ndisinfectant to cure the coronavirus, that he was cured with regeneron). \n\uf097A somewhat confusing scenario needs to be sorted out:  consumers receive information that pretends to be knowledge and that may be \nclaimed to be knowledge by the consumer, based on their belief in a \ncognitive authority (such as a political leader, religious leader or news \norganization) and yet which is at best in the consumer\u2019s mind second- hand \nknowledge that may be in actuality belief and even false belief. \n\uf097Various psychological factors predispose or motivate both creators/senders \nof disinformation as well as receivers and we will look at some of these \nlater.11\nMedia as Cognitive Authorities\n\uf097Various media for different age groups may act as \ncognitive authorities, measured in terms of using particular sources and the level of loyalty to those sources.  \n\uf097One can argue that loyalty is a measure of expertise, credibility and trustworthiness for a cognitive authority, whether positively or ill- placed. \n\uf097We will next look at the result of a Pew Research Center study on sources of information and loyalty to them based on a variety of factors.\n\uf097The study took place in 2016/2017, but it still represents trends.12\nPew Research:  Loyalty and Source Attention \n(2016, updated 2017)\n\uf097About half (51%) of Americans say that they are loyal to their news \nsources, while 48% say they are not particularly loyal.\n\uf097At the same time though, 76% of Americans say they usually turn to the same sources for news.\n\uf097Taken together, nearly half (46%) of Americans both describe themselves as loyal and also go to the same sources repeatedly (the \u201cvery loyal\u201d). Just 18% are neither attitudinally nor behaviorally loyal (the \u201cnon- loyal\u201d).\n\uf097Older adults are more likely to be in this group: 58% of those ages 65+ are \u201cvery loyal,\u201d whereas only 28% of those ages 18- 29 are. \nAnd women are more likely to be very loyal (49%) than men (43%).\n\uf097Very loyal news consumers follow news at a much higher rate. They are also more likely to think media organizations do a good job informing people and to trust the info they provide\nhttp://www.journalism.org/2016/07/07/loyalty -and-source- attention/13\nPew Research:  Loyalty and Source Attention \n(2016, updated 2017)\n\uf097TV dominates as preferred news platform among very loyal news \nconsumers; wider mix among the non- loyal\n\uf097Despite digital advances, most still share news by word of mouth\n\uf097In a real time analysis, speaking with others is the most common way to \nrespond to getting news online\n\uf097Those who prefer to get news online have more negative attitudes toward \nthe news media. Online, however, they\u2019re much more likely to intentionally \nseek news out\n\uf097Young adults no more likely to engage with news on social media\n\uf097Democrats are more trusting of information from the national news media, \nbut liberal Democrats are about as likely to see bias as moderate/liberal \nRepublicans\n\uf097Liberal Dems, conservative Reps more likely to get one- sided news from \nfamily and friends online, but conservative Republicans are most likely to think that\u2019s OK\n\uf097http://www.journalism.org/2016/07/07/loyalty -and-source -attention/14\nSource Loyalty, Cognitive Authority\nSo far we have made 3 key points:\n1.We all have cognitive authorities\n2.News media in whatever format can be considered \ncognitive authorities based on the degree of source loyalty of the consumer.\n3.Both right and left news sources believe that their sources are credible, trustworthy and have expertise.\nTo provide a focus we will compare Fox News and New York Times.  Although they are different in the way the news is presented, they are good examples of different political views and exercise a great deal of influence on their constituencies.15\nWhat Readers/Viewers Believe\nNew York Times Fox News\nCenter -left bias (mediabiasfactcheck.com) \nBecause they have a bias does not mean \nthat their reporting is not grounded in facts.Strongly right bias (mediabiasfactcheck.com) Because they have a bias does not mean that their reporting is not grounded in facts.\nTrustworthy \u201ccaptures the perceived goodness and morality of the source (Rieh, 2010, p. 1337).Trustworthy \u201ccaptures the perceived goodness and morality of the source (Rieh, 2010, p. 1337).\nPossesses expertise:  they provide information that is accurate and validPossesses expertise; they provide information that is accurate and valid\nReal News Real News (others are Fake News)16\nNew York Times:  Actuality\nNew York Times Basis for their Authority\nCenter -left bias (mediabiasfactcheck.com) Having a political leaning does not invalidate \nthe content, particularly because  opinion pieces are published as opinion\nTrustworthy \u201ccaptures the perceived goodness \nand morality of the source (Rieh, 2010, p. \n1337).Long history (1851) as a respected publication.  Articles are well -researched and \nverified. Opinion is identified as opinion (editorials).\nPossesses expertise:  they provide information that is accurate and validProduces (1) second -hand knowledge, (2) \nwell-informed opinion (with which other may \ndisagree:  e.g., Trickle -down economics is \nnot successful), and (3) preferences (best movies to watch)\nHas a cadre of respected and experienced \nexperts.  When they become aware of  false or problematic statements or reporting, they issue retractions\nBelieve in fact -finding and verification by \n 17\nNew York Times:  Actuality\nNew York Times Basis for their Authority\nAdhere to the Principles of Good Journalism \n(https://americanpressassociation.com/principles -of-\njournalism/ )The obligation to present the truth (or the best representation thereof, by providing evidence and upgrading narrative as facts and errors emerge)\nNY Times follow these principles Its first loyalty is to citizens, not to partisan politics\nFor a measured assessment, see:  \nhttps://mediabiasfactcheck.com/new -york-times/Practitioners must maintain an independence of those they cover \u2013when covering anything connected to the \nNY Times, they note it\nServe as an independent monitor of power\nMust provide a forum for public criticism and \ncompromise\nMust strive to make the significant interesting and \nrelevant\nMust keep the news interesting and proportional.  This \nmeans that one does not sensationalize certain events and ignoring others, stereotyping or being overly negative \u2013all affected communities and perspectives \nmust be taken in account.\nIts practitioners must be allowed to exercise their \npersonal conscience.18\nFox News:  Actuality\nFox News Basis for their Authority\nStrong right bias (mediabiasfactcheck.com). For a \nmeasured assessment see: \nhttps://mediabiasfactcheck.com/fox -news/Having a political leaning does not invalidate the content, particularly because  opinion pieces are published as opinion\nThey claim that they are trustworthy implying that they stand for \u201cthe perceived goodness and \nmorality of the source (Rieh, 2010, p. 1337).It has a long history associated with right and \nconservative causes, a history which has been often shaky and scandalous, with commentators leaving (e.g., Bill O\u2019Reilly) for various reasons, often sexual harassment.  (Stelter, 2020; Smith, 2019).  Many of their sources are conspiracy theories from alt -right web sites.    \nPossesses expertise:  they purport to provide information that is accurate and validThey have various pundits, Sean Hannity, Tucker Carlson, Jeanine Pirro, Neil Cavuto, et al., who claim to be experts, but they are mostly apologists for ring- wing viewpoints. Its second-\nhand knowledge, on political matters, is often at best opinion or opinion based on alternative \u201cfacts\u201d or misconstrued data. Example of Lou Dobbs and \u201cNoble\u201d Prize19\nFox News:  Actuality\nPrinciples of Good Journalism Basis for their Authority\nThe obligation to present the truth (or the best \nrepresentation thereof, by providing evidence and upgrading narrative as facts and errors emerge)For four straight months, they pushed misinformation \nevery single day (Sulivan, 2019). Trump\u2019s failure or incompetence in dealing with the coronavirus epidemic is never mentioned, and in fact he is praised for his superior leadership.\nIts first loyalty is to citizens Their loyalty is toward its partisan viewers, not to all \ncitizens, though they hope to convert them\nPractitioners must maintain an independence of those \nthey coverThe most obvious case is that of Donald Trump.  They never criticize his speech or behavior and claim the he is the best president that the US has ever had.  He frequently is invited or invites himself for interviews.  Their relationship is so close that Fox News is often referred to as \u201cTrump TV.\u201d\nServe as an independent monitor of power See the above; most commentary and \ncommentators support right -wing causes:  unfettered \ncapitalism, oligarchy, pro-business, anti -labor \nagenda, etc.  They endorse the Republican party \nand the Trump agenda, often ignoring previous principles of conservatism (e.g., anti -communism, \nfiscal responsibility).20\nFox News:  Actuality\nPrinciples of Good Journalism Basis for their Authority\nMust provide a forum for public criticism and compromise They rarely invite speakers, politicians or commentators \nfrom the Democrats or the left.  They also refuse to run advertisements that are critical of the president or right-\nwing agenda\nMust strive to make the significant interesting and relevant They are committed to reporting or making narratives that support the biases of their viewers, a right -wing or \nconservative viewpoint (which has been muddled). \nMust keep the news interesting and proportional.  This means that one does not sensationalize certain events \nand ignoring others, stereotyping or being overly negative \u2013all affected communities and perspectives must be taken \nin account.They are often committed to sensationalism, such as fear of migrants, fear of communism and socialism, turning peaceful protests into riots against law and order, \netc.  For an overview of a variety of issues see:  \nhttps://en.wikipedia.org/wiki/Fox_News_controversies\nIts practitioners must be allowed to exercise their personal \nconscience.When reporting, one should include their viewpoint reflecting their own moral conscience.  Certainly, many of Fox News pundits do so:  Sean Hannity, Tucker \nCarlson, Jeanine Pirro, Neil Cavuto, et al. take that view, \nbut there are serious questions about a moral compass \nthat approves of children in cages, that support a \ncontinuous liar (20,000+ lies or misleading information \nuntil July 13, 2020  (\nhttps://www.washingtonpost.com/politics/2020/07/13/pr\nesident -trump-has -made -more -than -20000 -false- or-\nmisleading-claims/ ) or ignore, hide or manipulate \nrelevant information.21\nThe Persistence of Fox News\nA study Pew undertook in the fall of 2019 gives a more up- to-date \nunderstanding of Fox News viewers. It concluded: \n1.Around four -in-ten Americans trust Fox News. Nearly the same share \ndistrust it.\n2.Republicans [(2/3) and Republican- leaning independents (65%)] trust \nFox News more than any other outlet. Democrats distrust it more than \nany other outlet. \n3.On an ideological scale, the average Fox News consumer is to the \nright of the average U.S. adult, but not as far to the right as the \naudiences of some other outlets [Such as Rush Limbaugh and Alex \nJones.]\n4.People who cite Fox News as their main source of political news are \nolder and more likely to be white than U.S. adults overall. \n1.Americans ages 65 and older account for around four -in-ten of \nthose who say their main source is Fox News (37%), compared \nwith 21% of all adults. \n2.Around nine- in-ten who turn to Fox News (87%) identify their race \nand ethnicity as non- Hispanic white, compared with 65% of all \nadults. (Gramlich, 2020)22\nThe Persistence of Fox News\n5.   Those who name Fox News as their main source of political news stand out from the \ngeneral public in their views on key issues and people, including President Donald Trump. \n(Gramlich, 2020)\n\uf097People who get their news from outlets other than Fox generally said, even as early as \nMarch 2020, that Trump was not responding to the COVID -19 pandemic well, but 63% of Fox \nNews viewers said that Trump was doing an \u201cexcellent job\u201d responding to the outbreak \n(Gramlich, 2020).  \n\uf097Fox News viewership was more predictive than party affiliation; as Pew noted, \u201cFox News \nregulars were considerably more likely than Republicans overall to describe Trump\u2019s handling of the outbreak as excellent (63% vs. 47%) (Gramlich, 2020). \n\uf097These observations serve to show the extent of the power of Fox News to influence its \nconsumers.\n\uf097According to Eric Wemple, the influence of Fox News cannot be underestimated:\nThere\u2019s simply no outlet that dominates any other part of the political spectrum in the \nway Fox News dominates the right. With that dominance, Fox News has done great \ndamage. It\u2019s not as if Fox News\u2019s influence extends to only however many millions \nmay be viewing in prime time. There\u2019s what experts call a \u201cmedia ecosystem\u201d out \nthere, where people take nonsense uttered on Fox News, then share it on Twitter, on \nFacebook, with their neighbor. Nonsense has a high pass around rate (Wemple, \n2019).\nThese observations serve to show the extent of the power of Fox News to influence its \nconsumers.\n\uf097How can they be a cognitive authority while extensively misinforming their viewers?  We \nhave to look at psychology for a clue.23\nA Sample of Psychological Factors\n\uf097Information avoidance is information is actively avoided for fear \nthat it would complicate or nullify currently held strong beliefs.  \n\uf097Gullibility is \u201ca failure of social intelligence in which a person is easily tricked or manipulated into an ill -advised course of action\u201d \n(Forgas & Baumeister, 2019, p. 2). \n\uf097Gullibility can occur in one of two situations: \u201cEither an individual\u2019s beliefs are manifestly inconsistent with facts and reality, or an individual\u2019s beliefs are at variance with social norms about reality\u201d (p. 2).  \n\uf097The psychological foundation of gullibility \u201cappears to be the universal human capacity for trust \u2013 to accept second-hand \ninformation we receive from others as a proxy for reality\u201d (p. 5).  \n\uf097For more detail on psychological issues and other psychological factors, see my recent publication on \u201cTen Lessons for the Age  of Disinformation\u201d at my website:  \nhttp://personal.kent.edu/~tfroehli/24\nCognitive Bias\n\uf097Cherry (2020) defines cognitive bias as \u201ca systematic error in thinking that occurs \nwhen people are processing and interpreting information in the world around them.\u201d  \n\uf097The vast research on cognitive bias has identified several aspects that foster disinformation campaigns, some of which are particularly salient in the political \ndomain.  \n\uf097When people exhibit cognitive bias, they take particular, flawed mental shortcuts regularly. \n\uf097In the face of too much information, people typically allow their cognitive biases to dictate their thinking, opinions, and actions when they must make quick \nassessments.\n\uf097Other factors that invoke cognitive biases include a person\u2019s emotions or \nmotivations, the limits on the mind\u2019s ability to process information, and social pressures (Cherry, 2020).  \n\uf097All of these causes seem to be relevant to such groups as Trump supporters, who \nmake errors in judgment about actual facts, who often are engaged in anger and \nresentment about current events, who are seduced by the social pressures coming \nfrom their ingroup (social self -deception and collective self -deception), and who \nhave less flexibility in processing information than non- Trump supporters.  25\nCognitive Bias\n\uf097There are hundreds of cognitive biases that have particular relevance for \ndisinformation adherents\n\uf097There is an obvious example:  confirmation bias .\n\uf097Confirmation bias involves interpreting information that supports our existing beliefs, even when presented with conflicting evidence.  Trump supporters hold all sorts of improbable beliefs because they concord with their pre-existing beliefs: e.g., that Trump is a great president, was successful in curbing the coronavirus and its infection and death rate, cares about poor people, is draining the Washington swamp, is a great businessman, that his tax cuts helped all Americans, and that he has a great plan for healthcare, all of which are false (at this point).\n\uf097For an extended treatment of 13 of them relevant to disinformation campaigns, \nsee my paper: http://personal.kent.edu/~tfroehli/fox.pdf26\nPsychological Factors: Pettigrew\nThomas Pettigrew (2017) in, \"Social Psychological Perspectives on Trump Supporters,\" identifies \nfactors reflecting five major social psychological phenomena that account for the bulk of Trump supporters' devotion: \n(1) Tolerance for authoritarianism . Trump supporters are attracted to authoritarian figures. \nAuthoritarians see the world as dangerous, and fear guides their response to it. (2) A preference for associating with socially dominant groups (social dominance orientation, \nSDO).It is an individual's preference for the societal hierarchy of groups and domination over lower -status groups\" (p. 108). People who want to maintain the current social hierarchy have an \nSDO. They believe members of other groups are inferior to members of their own. \n(3) Prejudiced. Trump supporters are prejudiced, which is manifest in their support for anti -\nimmigrant rhetoric and policy. In the 2016 election, Trump launched rhetorical attacks on \nimmigrants, Mexicans, and Muslims.  His actions in office have reinforced that stance: \n(4) Low intergroup contact (i.e., little familiarity with groups other than themselves). They have less \nexperience with minorities such as Muslims, Mexicans, or even Black Americans, than other Americans. Low intergroup contact makes it easier to dismiss members of other groups as foreign, un-American, and/or inferior. \n(5) Relative deprivation (i.e., feeling that others are much better off than they are). R elative \ndeprivation may be the most powerful and troubling problem to enable Trump\u2019s rise. While Trump\u2019s supporters are not disproportionately economically disadvantaged\u2014they are disproportionately employed full time and unlikely to live in districts that depend on manufacturing\u2014they perceive\nthemselves as deprived. 27\nPsychological Factors\n\uf097Hours of Fox News and right -wing social media sites denigrating \"welfare \nqueens,\" welfare programs, the more frequent appearance of minorities, mixed \nand gay marriages, on media, and the media's and advertising's version of what an ordinary American home is supposed to be like strengthen the sense of deprivation. Trump offered supporters an opportunity to reverse the trend.  They feel that they are victims of the forces of politics, corporations, education, and demographic shifts, and the president's focus on those themes makes them feel empowered. \n\uf097Emotion, not critical thought, drives the behavior of Trump supporters and Fox viewers. The disinformation campaigns that support Trump appear to be based on cognitive biases, as is evidenced by many Trump supporters screaming at any opposition to him as \u201cfake news,\u201d or calling police for imagined intrusions on their rights by Black people.28\nThe Nature of Fox\u2019s Cognitive Authority\n\uf097It starts with or instills a maelstrom of grievances, resentments, a sense of \ninvisibility or a lack of importance ofits viewers, where the wider culture often \nchallenges many of their core values (e.g., white dominance)\n\uf097Fox News then tells those viewers what they want to hear, consciously or unconsciously, with claims that support and fulfill their cognitive biases and real, instilled or professed ideology.  For example, they may think of themselves as conservatives, without having much depth about its meaning, except maintaining things as they were (e.g., male white dominance in society).  Fox News will then shape and enlarge that image with anti -liberal, anti -labor, pro-\nbusiness, pro-average-joe narratives.\n\uf097These messages are myths, tropes, and narratives, often detailed through the shows of their various pundits. They include persistent myths about antifa conspiracies, fast fixes or lies about the coronavirus epidemic or the extraordinary leadership of Trump.  They echo the view that God rewards those who work hard and other variations of the Protestant work ethic, implying that those are poor or disadvantaged have not worked hard enough and are \ndeserving of their circumstances.29\nThe Nature of Fox\u2019s Cognitive Authority\n\uf097It presents white privilege as the natural way of things and racism as a thing of \nthe past. Kneeling during the national anthem is an insult to the flag or the country. It satirizes the mass media as pushing values that are un-American. It claims that restrictions on gun ownership are an assault on basic human rights and the Constitution. It mirrors and accentuates the lies on radical right -wing \nwebsites, such as Breitbart (Benkler, et al., 2018, p. 14). The emotional triggers that it fosters are legion, not to say they are true, only that they work.\n\uf097They engage in \u201cmotivated reasoning,\u201d especially when the topic at hand is \nsomething that we promotes or inflames their cause.  It is the effect of emotions \nthat we associate with a given topic at a primal level.  It is not really reasoning but rationalization, making our arguments fit a pre-determined end.  Not only does it involve a confirmation bias but also a \u201cdisconfirmation bias\u201d \u201cin which we expend disproportionate energy trying to debunk or refute views and arguments that we find uncongenial.\u201d (Mooney, 2011).  When they grab onto what appears to be scientific evidence that supports their bias, they pounce on it.   When one \u201cscientist\u201d proclaims that climate change is a hoax, they are featured on Fox News and the overwhelming majority of scientists are ignored, if not mocked.30\nThe Nature of Fox\u2019s Cognitive Authority\n\uf097These arguments from motivated reasoning or memes, myth, tropes and \nnarratives are reinforced and repeated throughout the disinformation-\nmisinformation ecosystem to the point of addiction where viewers\u2019 self -\ndeception dialectically reinforces and is reinforced by the social and collective self -deception of others and selective events in the \ndisinformation- misinformation ecosystem.  This disinformation-\nmisinformation ecosystem is a filter bubble or \u201cpropaganda feedback loop.\u201d (Benkler, et al., 2018, p. 33).  Morrison (2018) suggests that right -wing \nmedia keep over a quarter of Americans siloed in this \u201cpropaganda feedback loop.\u201d\n\uf097Because Fox News promotes relentless moral outrage, viewers are prone \nto believe irrational or unfounded claims or assertions, and to regard all \nother venues as fake news.  This moral outrage is reflected in the actions of the viewers taken into the market place, such as the refusal to wear \nmasks for the coronavirus pandemic or to call the police on any Black \nperson they imagine is threatening them.\n\uf097It is not that Fox News alone does this \u2013so do some social media sites \u2013\nbut it is a major factor given its degree of influence.31\nThe Nature of Fox\u2019s Cognitive Authority\nRegardless of topic, Fox News commentators are supposed to stoke rage and \npush the emotional buttons of their viewers.  Tobin Smith, a former Fox News \ncommentator, suggests that their programming fosters an addictive and \nresentment -based process to:\n[1] Understand the elderly white conservative viewer\u2019s pre- tribal mindset, \nwhich is a compilation of their resentments, indignations, cultural values, \nreligious values, political values, racial perspectives, regional outlooks, and worldviews.\n[2] Scare or outrage the crap out of viewers by boring down on a recently \nexposed tribal nerve like a psychic dentist with a drill, presenting a heresy or an innately scary image of non- white/non- Christian foreigners, \nimmigrants, or terrorists doing horrible things.\n[3] Produce each seven- minute rigged outcome opinion- debate segment \naround the carefully selected partisan heresy such that the \u201cfair and \nbalanced\u201d debate is massively rigged for the conservative pundits on the \nprogram to . . .                                                                                                             \n[4] Deliver the climactic and righteous rhetorical victory for the partisan \nright-wing viewer to trigger the jolt of dopamine and serotonin that the \naddict anticipated and knew was coming. (Smith, 2019, pp. 485- 486).32\nThe Nature of Fox\u2019s Cognitive Authority\n\uf097Fox News claims to base its stories on evidence and facts.  At best, when they actually \nuse facts, their interpretation of these facts is often distorted, manipulated, misleading or missing.  \n\uf097It claims to the trustworthy \u2013 it is only trustworthy in that it reinforces and stokes bias.  \n\uf097It claims to have journalistic integrity.  It is not journalistic integrity when you make the narrative about the facts or the omission of facts fit your political bias or when you originate a narrative based on a conspiracy theory of a radical right -wing social media \nsite. (Benkler, et al., 2018, p. 14).  \n\uf097It claims to have expertise, but its expertise is sophistry, because they are interested in political power and influence and economic rewards.  The repetition of Fox\u2019s messages through social media and other personal interactions reinforces and socializes the self -\ndeception. \n\uf097Fox News exists as a significant component of a disinformation- misinformation ecology \ncomposed of like-minded peers, friends, associates, religious leaders, politicians, and \npundits which foster, nurture and reinforce one\u2019s grievances through memes, narratives, tropes and stories.  It is a major component of a \u201cpropaganda feedback loop,\u201d where each part reinforces (and often inflames) the others, through multiple channels (Cable news, social media, group associations, party rallies, word- of-mouth, etc.) are echoing each \nother.\n\uf097Fox relies for its authority on a self -reinforcing dialectical process where each part \nreinforces the other and rejects discordant information.  The result is Fox\u2019s robust approval rating at 43% and a steady 63% among Republicans and Republican leaning independents (Gramlich, 2020).\n\uf097The conclusion is Fox News is a pseudo- cognitive authority, one that pretends, fosters \nand succeeds in being an faux authority, but one that lacks a legitimate  foundation.33\nUnbalanced Analysis?\nIs this fair?  Are there not cases on the left that replicate what is going \non in the right wing media?\nThere are two responses:  this assumes the notion of the false \nequivalences and ignores the obsessiveness of right wing media\n\uf097The notion of false equivalences asserts that for any issue there are two equally valid opinions. \n\uf097Everyone is entitled to an opinion but not all opinions are founded, justified or justifiable.  \n\uf097Some opinions are formed from false information or selective information (that distorts the context and meaning), and such opinions do not have the same standing as ones that are well -\nformed:  that is, ones based on rational arguments, evidence, and logic.  \n\uf097To insist that they are equivalent is a mistake in reasoning. In the current environment, we have wars where your opinions or moral indignation trump facts or your civil liberties trump science.34\nNo Symmetry Between Right and Left\nYochai Benkler, Robert Faris, and Hal Roberts published Network Propaganda: \nManipulation, Disinformation, and Radicalization in American Politics, which shows that right \nand other media differ significantly in dealing with network information.  By doing a rigorous \nanalysis of online stories, tweets, and Facebook -shares data points, the authors conclude \nthat \u201csomething very different was happening in right- wing media than in centrist, center -left \nand left- wing media.\u201d (Benkler, et al., 2018, p. 14). They observe that\nthe behavior of the right -wing media ecosystem represents a radicalization of roughly a third of the \nAmerican media system. We use the term \u201cradicalization\u201d advisedly in two senses. First, to speak of \n\u201cpolarization\u201d is to assume symmetry. No fact emerges more clearly from our analysis of how four million \npolitical stories were linked, tweeted, and shared over a three -year period than that there is no symmetry \nin the architecture and dynamics of communications within the right-wing media ecosystem and outside of it. Second, throughout this period we have observed repeated public humiliation and vicious disinformation campaigns mounted by the leading sites in this sphere against individuals who were the \ncore pillars of Republican identity a mere decade earlier. (Benkler, et al., 2018, p. 14). \nBenkler et al. believe that the research they performed generally indicated that the \nleft were less susceptible to their biases and that the right sought confirmation bias to \ntheir preexisting beliefs.  They conclude that \u201cthe right- wing media ecosystem differs \ncategorically from the rest of the media environment,\u201d and has been much more \nsusceptible to \u201cdisinformation, lies and half- truths.\u201d   As for Fox News\u2019 role in this, \u201cwe \nfound Fox News accrediting and amplifying the excesses of the radical sites.\u201d \n(Benkler, et al., 2018, p. 14).35\nSocial Media\n\uf097Social media sites can also act as cognitive authorities or pseudo-cognitive \nauthorities\n\uf097The problem with the internet is that is a self -serve \u201cinformation\u201d bank.  Using \nGoogle or some social media sites like mediabiasfactcheck.com, one can often find legitimate information. \n\uf097For many on the right, right -wing social media (e.g., Breitbart, Truthfeed, \nInfowars, Gateway Pundit, Zero Hedge) is a self -serve disinformation or \nmisinformation bank. Right -wing ideologues, foreign agents and click -bait \nentrepreneurs produce a deluge of disinformation of memes and narratives to solicit (at a minimum) and inflame (at a maximum) the disinformation seeker at these sites.  \n\uf097Self-serve engagement is mediated by cognitive bias, confirmation bias, and \nsteerage to selective sources.  Generally, there are little restrictions on the kind of content that is made available.  \n\uf097Conservatives are more susceptible to clickbait than liberals, more likely to fall \nfor fake news. (Ingraham, 2019).  36\nSocial Media\nBeyond specific right -wing media sources, as political commentator and professor \nRobert Reich argued in the Guardian, Facebook and Twitter are alarmingly \ninfluential. As he wrote:\n\uf097The reason 45% of Americans rely on Facebook for news and Trump\u2019s \ntweets reach 66 million is because these platforms are near monopolies, dominating the information marketplace. No TV network, cable giant or newspaper even comes close. Fox News\u2019 viewership rarely exceeds 3 \nmillion. The New York Times has 4.7 million subscribers.\n\uf097Facebook and Twitter aren\u2019t just participants in the information \nmarketplace. They\u2019re quickly becoming the information marketplace.\n(Reich, 2019).\nOne of the most problematic aspects of social media are the number of hate \ngroups and the far -right partisans that use it to attract followers and disseminate \ntheir propaganda. 37\nSocial Media\n\uf097A report of \u201cHate in America,\u201d a project produced by the Carnegie-\nKnight News21 initiative, did a study of far- right users of Facebook, \nTwitter, Gab, VK, and others during a two- week period in June \n2018.  They tracked more than 3 million followers and compiled more than 2,500 posts from these platforms that threatened harm against Black Americans, Latinos, Jews, and LGBTQ+ people.  These posts got over a half -million likes and were shared 200,000 \ntimes.  This evidence shows the strength and breadth of these groups, who gain power by assembling a collective voice, despite some restrictions by some platforms (Gardner, 2018).\n\uf097What poses additional threat is the spread and speed of disinformation, and in the inflammation of emotional triggers (memes, tropes).  MIT researchers Soroush Vosoughi, Deb Roy, and Sinan Aral (2018) find in a study of rumor cascades from 2006 to 2017 that false information spreads more quickly and broadly than truthful information and that those on the right are more susceptible and more prone to disseminate false information than those on the left.  38\nSocial Media\n\uf097YouTube in particular engages a rabbit hole phenomenon that \nincreases right -wing radical viewership.  \n\uf097When perusing YouTube videos for particular content, such as a specific conspiracy theory, the site\u2019s algorithm suggests more \nprovocative videos to view, which in turn suggest more provocative \nvideos to view. \n\uf097The impact is to advance Google\u2019s profits, with dire political consequences. Sociologist and information and library science \nprofessor Zeynep Tufekci declared YouTube to be \u201cone of the most \nradicalizing instruments of the 21st century\u201d because of these \nmechanisms (Tufekci, 2018).  According to the analysis of New York \nTimes columnists Max Fisher and Amanda Taum, Brazil\u2019s ultra- right \npresident Jair Bolsonaro owes his electoral success primarily to \nYouTube videos (Fisher & Taub, 2019).  39\nSocial Media and Free Speech\n\uf097While there are concerns for groups like 8chan and other alt -right sites, \nFacebook illustrates a broader problem of regulating speech on the internet, \nparticularly hate speech or conspiracy theories.   \n\uf097Perhaps the major problem with social media is the fact that anyone can use or create or propagate social media to disseminate clear lies and falsehoods on the internet in the name of intellectual freedom or freedom of expression.  \n\uf097Mark Zuckerberg perhaps best exemplified this in a speech at Georgetown University where he argued that Facebook should be unfettered in intellectual freedom, including political advertisements of outright lies (e.g., pro-Trump reelection campaign advertisements that include lies about his opponents).  \n\uf097He takes the view that the marketplace will work it out \u2013 the lies will be \ndiscovered, eventually rejected or ignored.  He bases his argument, as do other \nfree speech advocates, on the First Amendment. 40\nUnregulated Platforms\n\uf097Harvard legal expert Yochai Benkler argues that Zuckerburg\u2019s \ninterpretation of the First Amendment as preventing his company from \nsuppressing false or dangerous speech is erroneous.  He argues that \nthe First Amendment is only about government involvement in speech; \nit does not apply to private speech or private parties, of which Twitter \nand Facebook are examples (Morrison, 2018). \n\uf097Evidence shows that untruths are not sorting themselves out in the disinformation- misinformation marketplace.  Disinformation spreads \nunchecked by any retractions (and if even they occur, the first \nimpression is what is originally remembered) across the internet.  Fox \nNews, for example, echoes Trump\u2019s and his supporters\u2019 talking points, which are often patently false, but that is what is remembered (Affect \nCognitive Bias)41\nUnregulated Platforms\nIt is simply wrong to believe that Facebook as a whole is balanced or neutral and \nhas no particular bias.  The Economist did a study on Facebook using \nCrowdTangle, a Facebook tool that tracks how web material is shared across \nsocial media.  They discovered that in August, 2020, the two most popular sites \nwere Fox News and Breitbart measured by user engagements \u2013shares, views, \ncomments and other activities.    They concluded that\nwhatever Facebook\u2019s intentions, the social -networking site has more of a \npolitical slant than Mr. Zuckerberg lets on. Using CrowdTangle, we compiled a list of the media outlets that received the most Facebook engagement in \nAugust. We then examined the top 35 for which data on their political biases \nwere available from Ad Fontes Media, a media-watchdog organisation. All \ntold, these sites received an average of 8.7m engagements in August. Fox \nNews topped the list with 56.4m interactions in the month; MSNBC, a rival \ncable-news network, received just 9.7m  (Facebook. . ., 2020).  42\nFairness Doctrine and Unregulated Platforms\n\uf097The belief that individuals are capable of sorting out the truth for themselves in such an \nenvironment is problematic to say the least. For example, in 1987 the Reagan administration \nrevoked the fairness doctrine of the Federal Communications Commission (FCC), which since \n1949 had required broadcast license holders to present both sides of issues of public \nimportance in a manner that was honest, equitable, and balanced.  In eliminating it, FCC \ndecision makers claimed that it \u201crestricts the journalistic freedom of broadcasters ...\u201d (FCC \nFairness Doctrine).  NBCUniversal lauded the decision, saying, \u201cToday we reaffirm our faith in \nthe American people.  Our faith in their ability to distinguish between fact and fiction without any \nhelp from government\u201d (FCC Fairness Doctrine, footnote 18 of Wikipedia entry).  \n\uf097The emergence of right -wing media closely followed on the decision; the Rush Limbaugh Show \npremiered in 1988.\n\uf097Obviously, it is nice to think that the truth will always win out. But in the Age of Disinformation, this approach seems too simplistic. Thus, we must ask, is there a limit to free expression when \nthat expression leads to harmful acts to demonized populations, the destruction of trust in \npolitical, governmental and media institutions, the loss of expertise, and the denigration of \nscience and evidence?  \n\uf097Robert Reich (Reich, 2019) argues that two actions need to occur to bring rational control back to the internet.  First, there should be some anti -trust action that would break up the large \nproviders, such as Facebook and Twitter.   He argues that they have a too broad and monolithic influence. Second, we must prevent such providers from pretending to be neutral \nproviders of information for which they have no responsibility. 43\nSocial Media\n\uf097In sum, we have a diversity of sites on the internet and there are places where one \ncan obtain reliable information.  \n\uf097There are many sites where the opposite is true.  Fox News and alt -right social \nmedia sites are two of the major factors that have contributed to the uncivil \ndiscourse in American society, the undermining of American democracy and \ndemocratic institutions, the decline in law and order, an anti -science, anti -\nhumanistic agenda, and the hypersensitivity to presumed threats to one\u2019s rights and ideology.  \n\uf097It is naive to think that users can sort out misinformation/disinformation by \nthemselves: they lack the skills to critically evaluate information or to assess who \nare proper cognitive authorities.  Heavy doses of information, media and digital \nliteracies are required.\n\uf097While we are engaged in disinformation wars in the Age of Disinformation (wars \nwhich have attacked democracies in vulnerable ways), we also have entered the \nAge of Inflamed Grievances, given the in- your-face stoked grievances by the alt -\nright in cable news and social media and the Trump administration. Not that there is not some of that behavior on the left, e.g., attacking those who support racial \ndivision or police brutality.44\nSumming Up\n\uf097We have entered a brave new world, where, as Alice in Through the \nLooking Glass (Carroll, 2019) said, \"Why, sometimes I've believed as \nmany as six impossible things before breakfast.\" \n\uf097The more one leans to the right, the more true this seems to be.  If \none\u2019s sources of information are Fox News or like- minded news sites \nand alt -right social media sites, not only are you asked to perpetuate \nthese impossible things, but also you are asked to promote these \nthings with a sense of self -entitled moral outrage throughout your \ndisinformation ecology.  \n\uf097In the age of distraction, truth is \u201cwhatever makes you click\u201d (Wijnberg, \n2020).\n\uf097In the age of inflamed grievances, truth is whatever you are predisposed and inflamed to click.45\nResources\nPlease reference my home page for more details about my work\nhttp://personal.kent.edu/~tfroehli/\nSee especially the most recent papers:\n\"A disinformation -misinformation ecology: the case of Trump.\" October 1, \n2020. Book chapter out for review for Fake News Is Bad News - Hoaxes, \nHalf-truths and the Nature of Today's Journalism.  Draft at:  \nhttp://personal.kent.edu/~tfroehli/fox.pdf\n\"10 Lessons for the Age of Disinformation,\" Navigating Fake News, \nAlternative Facts and Misinformation in a Post- Truth World, edited by \nProfessor Kamiz Dalkir, University of Montreal, February, \n2020. https://www.igi- global.com/gateway/chapter/full- text-pdf/249503 .46\nReferences\nBenkler, Y ., Faris, R. & Roberts, H. (2018). Network propaganda: manipulation, disinformation, \nand radicalization in American politics . Oxford, UK: Oxford University Press.\nCarroll, L. (2019). Through the Looking Glass . Newbury, Berkshire, NY: CCS Books.\nCherry, K. (2020, July 19). How Cognitive Biases Influence How You Think and Act. Very Well \nMind .  Retrieved August 27, 2020, from https://www.verywellmind.com/what -is-a-\ncognitive- bias-2794963\nDavis, J. H. & Chokshi, N.  (2018, May 17).  Trump defends \u2018animals\u2019 remark, \nsaying it referred to MS -13 gang members. New York Times. Retrieved \nSeptember 13, 2018, from  https://www.nytimes.com/2018/05/17/us/trump -\nanimals -ms-13-gangs.html .\nFacebook offers a distorted view of American news. (2020, September 10). Economist.\nRetrieved September 14, 2020, from https://www.economist.com/graphic -\ndetail/2020/09/10/facebook -offers -a-distorted- view-of-american-\nnews?utm_campaign=the- economist- today . \nFCC fairness doctrine. (2019). In: Wikipedia. Retrieved September 15, 2018, from \nhttps://en.wikipedia.org/wiki/FCC_fairness_doctrine .\nFisher, M. & Taub, A. (2019, August 11).  How YouTube radicalized Brazil , New York Times.\nRetrieved August 29, 2019, from \nhttps://www.nytimes.com/2019/08/11/world/americas/youtube -brazil.html\n47\nForgas, J. P. & Baumeister, R. F. (2019).  Homo credulous:  On the social psychology of gullibility.   \nIn: Forgas, J.P. & Baumeister, R.F. (Eds)., The Social Psychology of Gullibility: Conspiracy \nTheories, Fake News and Irrational Beliefs.  Routledge.  Retrieved from \nhttps://ebookcentral.proquest.com .\nGardner, K. (2018, August 30). Social media: Where voices of hate find a place to preach. The \nCenter for Public Integrity. Retrieved September 03, 2020, from \nhttps://publicintegrity.org/politics/social -media -where- voices- of-hate- find-a-place- to-preach/\nGramlich, J. (2020, April 8). 5 facts about Fox News. Pew Research Center . Retrieved August 25, \n2020, from https://www.pewresearch.org/fact -tank/2020/04/08/five- facts -about -fox-news/ .\nIngraham, C. (2019, April 29). Why conservatives might be more likely to fall for fake news. \nWashington Post. Retrieved October 26, 2019, from \nhttps://www.washingtonpost.com/news/wonk/wp/2016/12/07/why -conservativesmight -be-more -\nlikely -to-fall-for-fake-news/ . \nMooney, C. (2011, April 18). The science of why we don't believe science. Retrieved August 22, \n2020, from https://www.motherjones.com/politics/2011/04/denial -science -chris -\nmooney/?fbclid=IwAR0joSt0kxWLUlWut1AMYwn0xT3d_wEp9l79mhVySrs26pi3WvtbW3pyptk\n(Mooney, 2011)\nMorrison, P. (2018, November 7). How the 'propaganda feedback loop' of right -wing media keeps \nmore than a quarter of Americans siloed. Los Angeles Times.  Retrieved October 26, 2019, \nfrom https://www.latimes.com/opinion/op- ed/la -ol-patt-morrison- yochai -benkler -20181107-\nhtmlstory.html . \n48\nMutz, D. C. (2018, May 8).   Status threat, not economic hardship, explains the 2016 \npresidential vote, Proceedings of the National Academy of Sciences (PNAS) .  Retrieved \nJune 30, 2019, from https://www.pnas.org/content/115/19/E4330 .\nPettigrew, T. F. (2017). Social psychological perspectives on Trump supporters, Journal of \nSocial and Political Psychology (5). Retrieved August 18, 2017, from \nhttps://jspp.psychopen.eu/index.php/jspp/article/view/750/html .\nReich, R. (2019, November 03). Facebook and Twitter spread Trump's lies \u2013they must be \nbroken up. The Guardian. Retrieved September 02, 2020, from \nhttps://www.theguardian.com/commentisfree/2019/nov/02/facebook -twitter -donald- trump -\nlies\nRieh, Soo Young (2010). Credibility and cognitive authority of information. In: M. Bates & M. N. \nMaack (Eds.) Encyclopedia of Library and Information Sciences, 3rd Ed. (pp. 1337\u2013\n1344), New York: Taylor and Francis Group, LLC. Retrieved August 18, 2017, from \nhttp://hdl.handle.net/2027.42/106416 . \nSmith, T. (2019). Foxocracy: Inside the Network\u2019s Playbook of Tribal Warfare. New York, NY: \nDiversion Books.\nStelter, B. (2020). Hoax: Donald Trump, Fox News and The Dangerous Distortion of Truth. \nAtria Books.\nSullivan, K. (2019, May 13). The Fox \"News\" lie: Fox's \"news\" side pushed misinformation \nevery day for four months straight. Media Matters .  Retrieved August 26, 2020, from \nhttps://www.mediamatters.org/fox -news/fox -news -lie\n49\nTufekci, Z.  (2018, March 10).    YouTube, the great radicalizer. New York Times.\nRetrieved August 29, 2019, from \nhttps://www.nytimes.com/2018/03/10/opinion/sunday/youtube- politics- radical.html\nVosoughi, S., Roy, D., & Aral, S. (2018, March 9). The spread of true and false news \nonline.  Science, 359 (6380), 1146- 1151.\nWemple, E. (2019, April 11). Yes, Fox News matters. A lot. Washington Post. Retrieved \nApril 14, 2019, from https://www.washingtonpost.com/opinions/2019/04/11/yes- fox-\nnews- matters -lot/?noredirect&utm_term=.8ad57d66b52f . \nWijnberg, R. (2020, April 16). How the truth became whatever makes you click. The \nCorrespondent. Retrieved August 29, 2020, from \nhttps://thecorrespondent.com/410/how -the-truth-became- whatever -makes- you-\nclick/9567807150- 326405ae . \nWilson, P.  (1983).  Second- hand Knowledge: an Inquiry into Cognitive Authority.\nWestport, CT: Greenwood Press.  \nZorn, E. (2019, May 31). The foolish inconsistency of the Fox News propaganda \nmachine. Chicago Tribune. Retrieved August 25, 2020, from \nhttps://www.chicagotribune.com/columns/eric- zorn/ct -perspec- zorn- fox-trump -\nobama- korea- 20180320- story.html . \n50", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Role of Media in the Acceptance of Real News or Fake News", "author": ["TJ FROEHLICH"], "venue": "NA", "pub_year": "NA", "abstract": "\uf097 I back my claims by extensive research, based on evidence, facts, logic and reasoning.  You can dispute my findings, but they can only be challenged with evidence, facts, logic and"}, "filled": false, "gsrank": 109, "pub_url": "http://personal.kent.edu/~tfroehli/role.of.media.cut.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:XkMkGB3yevAJ:scholar.google.com/&output=cite&scirp=108&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D100%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=XkMkGB3yevAJ&ei=FrWsaM7kLPnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:XkMkGB3yevAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://personal.kent.edu/~tfroehli/role.of.media.cut.pdf"}}, {"title": "zagrut\u200b.", "year": "2018", "pdf_data": "\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\nzagrut\n\u200b\n.\n\u00a0\n\u00a0\nA news reader app that critiques the existing system of online news and\n\u00a0\n\u00a0\ngently guides the user against prevalent media bias.\n\u00a0\n\u00a0\n\u00a0\nv1.5 June 2018\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\nMario Dcunha\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\nCopyright \u00a9  2018-2019, All Rights Reserved\n\u00a0\nTable of Contents\n\u00a0\n\u00a0\nPreface\n3\n \nIntroduction\n3\n \nContext\n3\n \nIdea\n4\n \nUnderstanding the Problem\n6\n \nImportance of Smartphones\n6\n \nEcho Chambers\n8\n \nUnderstanding the Solutions\n11\n \nUser Research\n12\n \nThe Mobile App - Zagrut\n12\n \nDomains\n14\n \nProcess\n16\n \nPrototypes\n18\n \nThe Algorithm\n22\n \nEvaluation and Next Steps\n22\n \nConclusion\n22\n \nAppendix\n24\n \n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\nPreface\n\u00a0\n\u201cOrder is Heaven\u2019s first law\u201d, a quote from Alexander Pope that I hold dear. Design to me, is about\n\u00a0\ncreating specific order and organizing elements within it, which best accomplishes a task and\n\u00a0\nestablishes a framework for future improvements. Incidentally, this also almost coincides with\n\u00a0\nCharles Eames definition of design\n - \u201cPlan for arranging elements to accomplish a particular\n\u00a0\n1\npurpose.\u201d Having said that a true designer must be reflective - this factor adds the disruption and\n\u00a0\nthe fluidity to the concept and art of design.\n\u00a0\n\u00a0\nIntroduction\n\u00a0\n\u00a0\nAs an aspiring interaction and UX designer, I wanted to formally explore the design discipline of\n\u00a0\nUI/UX design. My intent was to explore and experiment with the UI/UX design process,\n\u00a0\nunderstand the intricacies of the interface and be able to express a suitable design solution that\n\u00a0\ncomplements the problems from the field of digital interfaces. I also wanted to build a product - a\n\u00a0\ndigital product that originated from my interest and my causes that I am passionate about and also\n\u00a0\nstands to be a solution that others can make use of or find beneficial in some way. Hence,\n\u00a0\ndesigning a mobile app was my most preferred exploration and it also complemented the problem\n\u00a0\nof bias in media and news consumption. Further context to the problem is shared below.\n\u00a0\nContext\n\u00a0\n\u00a0\nIn the month of March and April 2018, there was a spike of news stories that troubled me. The\n\u00a0\nexcessive and unnecessary media coverage of the death of Sri Devi, a legendary Indian film actress\n while thousands of farmers marching on barefoot against the Indian Government\n was ignored.\n\u00a0\n2\n3\n1\n Eames, Charles. \"Design Q&A Text\". Palais de louvre, 1972.\n \n<http://www.eamesoffice.com/the-work/design-q-a-text/>\n \n \n2\n Upadhyay, Karishma. \"Sridevi\u2019s death has brought out the worst in Indian media, crossing the line between\n \njournalism and exploitation\". Feb, 27 2018.\n \n<https://www.firstpost.com/entertainment/sridevis-death-has-brought-out-the-worst-in-indian-media-crossing-the-line-\nbetween-journalism-and-exploitation-4368811.html>\n \n \nAlso, the Facebook data scandal\n\u200b\n4\n\u200b\n that erupted data privacy issues and concerns against not just\n\u00a0\nFacebook but effectively questioning most companies working from the Silicon Valley. What was\n\u00a0\ninteresting to me was how this all circles back to politics, media coverage and reporting of such\n\u00a0\nnews, and how it was a global problem, where one scandal had immediate repercussions and\n\u00a0\ndebates in not just US, but India\n, Europe and several other countries too. Hence I decided to focus\n\u00a0\n4\nmy attention on one of this problem - the bias in media and the bias in ourselves thereby.\n\u00a0\n\u00a0\n\u00a0\nIdea\n\u00a0\n\u00a0\nThe idea for this design solution emanated from a personal place, with our biases and an\n\u00a0\nirresponsible system of media and news propagation that was heavily influencing political biases,\n\u00a0\nvotes, government formations and understanding what is truly best for the country. My ideation\n\u00a0\nprocess started off by putting my thoughts and feeling into writing for what I call - \u2018free writing\u2019,\n\u00a0\nwhere you just stick your pen to paper and write a marathon of thoughts and questions. Then I\n\u00a0\nfiltered these into key points and issues because the problem at hand is a large and messy one, that\n\u00a0\nwill go around in circles. So it was important at the start to keep this filtered and focussed.\n\u00a0\n\u00a0\nThis was followed by a mind map where the filtered thoughts are now arranged so that you\n\u00a0\nunderstand the connections laterally and not just linearly. This was very helpful for my process\n\u00a0\nbefore you begin research and also, its a good anchor point to keep your research focussed and\n\u00a0\nwander into the never-ending space of information.\n\u00a0\n\u00a0\n3\n Jadhav, Rajendra. \"Thousands of farmers march to Mumbai to demand help\". March 12, 2018.\n \n<https://in.reuters.com/article/india-farmers-march/thousands-of-farmers-march-to-mumbai-to-demand-help-idINKCN\n1GO09T>\n \n \n4\n Abraham, Sunil. \"Cambridge Analytica scandal: How India can save democracy from Facebook\". March 29, 2018.\n \n<http://www.business-standard.com/article/economy-policy/cambridge-analytica-scandal-how-india-can-save-democr\nacy-from-facebook-118032800146_1.html>\n \n \n \n\u00a0\nImage 1\n\u00a0\n\u00a0\n\u00a0\nImage 2\n\u00a0\n\u00a0\nUnderstanding the Problem\n\u00a0\n\u00a0\nThe internet and social media may have exacerbated low trust and \u2018fake news\u2019, but we find that in\n\u00a0\nmany countries the underlying drivers of mistrust are as much to do with deep-rooted political\n\u00a0\npolarisation and perceived mainstream media bias.\n\u00a0\nEcho chambers and filter bubbles are undoubtedly real for some, but we also find that \u2013 on\n\u00a0\naverage \u2013 users of social media, aggregators, and search engines experience more diversity than\n\u00a0\nnon-users.\n\u00a0\n5\nWith data covering more than 30 countries and five continents, the Reuter\u2019s Digital News\n\u00a0\nresearch of 2017\n\u200b\n5\n\u200b\n is a reminder that the digital revolution is full of contradictions and exceptions.\n\u00a0\nSome of the key findings from the research are:\n\u00a0\n\u00a0\nGrowth in social media for news is flattening out in some markets, as messaging apps that are (a) more\n\u00a0\nprivate and (b) tend not to filter content algorithmically are becoming more popular. Only a quarter (24%)\n\u00a0\nof the respondents think social media do a good job in separating fact from fiction, compared to 40% for\n\u00a0\nthe news media. Our qualitative data suggest that users feel the combination of a lack of rules and viral\n\u00a0\nalgorithms are encouraging low quality and \u2018fake news\u2019 to spread quickly\n\u200b\n.\n\u200b\n5\n\u00a0\nIn most countries, we find a strong connection between distrust in the media and perceived political bias.\n\u00a0\nThis is particularly true in countries with high levels of political polarisation like the United States, Italy,\n\u00a0\nand Hungary. Almost a third of our sample (29%) say they often or sometimes avoid the news. For many,\n\u00a0\nthis is because it can have a negative effect on mood. For others, it is because they can\u2019t rely on news to be\n\u00a0\ntrue.\n\u200b\n5\n\u00a0\nImportance of Smartphones\n\u00a0\n\u00a0\nMobile marches on, outstripping computer access for news in an increasing number of countries. Mobile\n\u00a0\nnews notifications have grown significantly in the last year. In a related development there has been a\n\u00a0\nsignificant growth in mobile news aggregators, notably Apple News, but also Snapchat Discover for\n\u00a0\nyounger audiences. Both have doubled usage with their target groups in the last year.\n\u200b\n5\n\u00a0\n5\n \n\u200b\nReuters. \"Digital News Repor t\". 2017\n \n<https://reutersinstitute.politics.ox.ac.uk/sites/default/files/Digital%20News%20Report%202017%20web_0.pdf>\n \nSmartphones are now as important for news inside the home as outside. More smartphone users now\n\u00a0\naccess news in bed (46%) than use the device when commuting to work.\n\u200b\n5\n\u00a0\n\u00a0\nIn terms of online news subscriptions, we have seen a very substantial \u2018Trump bump\u2019 in the US (from 9 to\n\u00a0\n16%) along with a tripling of news donations. Most of those new payments have come from the young \u2013 a\n\u00a0\npowerful corrective to the idea that young people are not prepared to pay for online media, let alone\n\u00a0\nnews. We have new evidence that news brands may be struggling to cut through on distributed platforms.\n\u00a0\nIn a study tracking more than 1,500 respondents in the UK, we found that while most could remember\n\u00a0\nthe path through which they found a news story (Facebook, Google, etc.), less than half could recall the\n\u00a0\nname of the news brand itself when coming from search (37%) and social (47%).\n\u200b\n5\n\u00a0\n\u00a0\n\u00a0\nImage 3\n\u00a0\n\u00a0\nImage 4\n\u00a0\n\u00a0\nThe biggest change has been the growth of news accessed via social media sites like Facebook and\n\u00a0\nTwitter. In the United States, social media became a key player in the story of the election not\n\u00a0\nleast because of its well-documented role in spreading made-up news stories, such as that Pope\n\u00a0\nFrancis endorsed Donald Trump or that Hillary Clinton sold weapons to ISIS. Over half (51%) of\n\u00a0\nour US sample now get news via social media \u2013 up five percentage points on last year and twice as\n\u00a0\nmany as accessed in 2013.\n\u00a0\n\u00a0\nWe should also remember that there are significant generational splits in the sources used for\n\u00a0\nnews. Across all countries, younger groups are much more likely to use social media and digital\n\u00a0\nmedia as their main source of news, while older groups cling to the habits they grew up with (TV,\n\u00a0\nradio, and print).\n\u200b\n5\n\u00a0\n\u00a0\n\u00a0\nEcho Chambers\n\u00a0\n\u00a0\nFlipboard curates the news you want by watching what you read and offering similar stories.\n\u00a0\nApple News app is a decent offering if you take the time to curate what you want to see.\n\u00a0\n\u00a0\nYou can select the sources you want to accept stories from and then they will filter through to\n\u00a0\nyour notification centre.\n\u00a0\n6\n\u00a0\nWe show, via a massive (\n\u200b\na sample of \n\u200b\n689,003) experiment on Facebook, that emotional states can\n\u00a0\nbe transferred to others via emotional contagion, leading people to experience the same emotions\n\u00a0\nwithout their awareness. We provide experimental evidence that emotional contagion occurs\n\u00a0\nwithout direct interaction between people (exposure to a friend expressing an emotion is\n\u00a0\nsufficient), and in the complete absence of nonverbal cues.\n\u00a0\n7\nWe tend to follow politicians we agree with; respondents on the left are five times more likely to\n\u00a0\nfollow left-leaning politicians in social media than politicians from the right. The same is true in\n\u00a0\nreverse in equal proportion.\n\u00a0\n\u00a0\n\u00a0\nImage 5\n\u00a0\n\u00a0\n6\n \n\u200b\nHayes, Jimmy. \"10 best news  apps: keep up to date with the real stories\". Tech Radar, August 27, 2017\n \n<https://www.techradar.com/news/forget-fake-news-10-great-apps-to-keep-up-to-date-with-the-real-news>\n \n \n7\n Kramer, Adam. Guillory, Jamie. Hancock, Jeffrey. \"Experimental evidence of massive-scale emotional contagion\n \nthrough social networks\". June 17, 2014. <http://www.pnas.org/content/111/24/8788>\n \nThis suggests that following politicians in social media may be contributing to greater polarisation.\n\u00a0\nOn the other hand, we should remember that in a pre-digital age political activists would have\n\u00a0\nspent a considerable amount of time with people who held similar views as well. What is different\n\u00a0\nis the scale of this activity. Over half of social media users (54%) in the United States following\n\u00a0\npoliticians equates to around a third of the entire US online population.\n\u200b\n5\n\u00a0\n\u00a0\nFrom the above reports\n\u200b\n5\n\u200b\n \n\u200b\nwe can also find that:\n\u00a0\n\u00a0\n\u25cf\nThe biggest change has been the growth of news accessed via social media sites like\n\u00a0\nFacebook and Twitter. It is striking that, outside the United States and United Kingdom,\n\u00a0\ngrowth in the use of social media for news seems to be flattening out.\n\u00a0\n\u25cf\nOverall around a quarter (23%) of our respondents now find, share, or discuss news using\n\u00a0\none or more messaging applications. We\u2019ve been tracking the growth of WhatsApp for\n\u00a0\nsome time but its use for news has jumped significantly in the last year to 15%, with\n\u00a0\nconsiderable country-based variation.\n\u00a0\n\u25cf\nOn a mobile phone in particular, where it can be difficult to move quickly between multiple\n\u00a0\napps and websites, the convenience of a one-stop-shop can be compelling. Sometimes\n\u00a0\nthese news aggregations are stand-alone products (Flipboard, SmartNews), at other times\n\u00a0\nthey are part of a wider service (Apple News, Google News, Snapchat Discover, Kakao\n\u00a0\nChannel, and Line News). This second group \u2013 that are both destinations in their own right\n\u00a0\nand allow content to hook into established ecosystems \u2013 are currently showing the\n\u00a0\nstrongest growth in our data. Despite the rise of aggregators, social media and search\n\u00a0\nremain the most important gateways to online content, alongside traffic coming to their\n\u00a0\nown websites and apps.\n\u00a0\n\u25cf\nWe can also add up preferences for content that is selected by an algorithm (search, social,\n\u00a0\nand many aggregators) and compare with that selected by an editor (direct, email, and\n\u00a0\nmobile notifications). More than half of us (54%) prefer paths that use algorithms to select\n\u00a0\nstories rather than editors or journalists (44%). This effect is even more apparent for those\n\u00a0\nwho mainly use smartphones (58%) and for younger users (64%).\n\u00a0\n\u00a0\n\u25cf\nAs the smartphone extends its grip in the home, and becomes the central organising device\n\u00a0\nof the digital age, it is worth reflecting on the implications for publishers. Two key factors\n\u00a0\nare likely to be at play: (a) more publishers have enabled deep linking to apps from search,\n\u00a0\nsocial, and email; (b) the substantial increase in mobile notifications noted earlier, as\n\u00a0\npublishers pursue loyalty strategies and take advantage of new platform capabilities.\n\u00a0\n\u25cf\nReading news in Text is a more preferred choice of news consumption, than video.\n\u00a0\n\u25cf\nThe widespread public debate over fake news and media bias has prompted us to look in\n\u00a0\ndetail at the issue of trust in the news media and in social media. Part of that has been to\n\u00a0\ninvestigate a link with political polarisation and perceived media bias in a number of\n\u00a0\ncountries. We have explored these issues though our core survey, through analysing\n\u00a0\nopen-ended answers on trust from 10 countries and from our focus group activity in a\n\u00a0\nsmaller group of countries including the United States.\n\u00a0\nUnderstanding the Solutions\n\u00a0\n\u00a0\nOn any platform of social media, when we point out with fact and reliable documentation that\n\u00a0\neither the news is fake, or the news post or source is biased, irrespective of the truth, there tends\n\u00a0\nto be a knee-jerk reaction to oppose fingers are pointed at someone. It needs to be determined if\n\u00a0\nthis is a platform effect, where we don\u2019t want to be corrected in public, or some other factor or just\n\u00a0\nour humane approach to things that we identify with.\n\u00a0\n\u00a0\nThough partisanship and selective exposure are strong determinants of attitudes and behavior,\n\u00a0\nintense media concentration on an issue may alter partisans\u2019 evaluations of politicians by changing\n\u00a0\nthe balance of headlines.\n Contrary to conventional wisdom, robots accelerated the spread of both\n\u00a0\n8\ntrue and false news at the same rate. This implies that false news spreads more than the truth\n\u00a0\nbecause humans\u2013not robots\u2013are more likely to spread it.\n\u00a0\n9\n\u00a0\nThe solution here is to take the problem and try to draw it in another way - for example, if echo\n\u00a0\nchamber means reading the same source, create a solution that will force you to read multiple\n\u00a0\nsource. If forcing is close to poking fingers at a person\u2019s biases or beliefs, then do this in a bland\n\u00a0\nway or with no labels attached - either to the source or to the user\u2019s bias.\n\u00a0\n\u00a0\n8\n Darr, Joshua. \"Collision with Collusion: Republican Reaction to the Trump-Russia Scandal\". SPSA 2018, New\n \nOrleans, LA. <http://joshuadarr.weebly.com/uploads/5/1/8/1/51819147/darr_et_al_trump_russia_spsa.pdf>\n \n \n9\n Vosoughi, Soroush. Roy, Deb. \"The Spread of True and False Information Online\". Social Machines, MIT Media\n \nLab. <https://www.media.mit.edu/projects/the-spread-of-false-and-true-info-online/overview/>\n \nWe can deduce the following from the above reflections:\n\u00a0\n\u00a0\n\u25cf\nIt\u2019s easy to identify and study the very biased to least biased sources\n\u00a0\n\u25cf\nWe can mention who is the owner of media, funded by, and other details of the source\n\u00a0\n\u25cf\nSearching the same topic on left, centre, right view sources present articles / views\n\u00a0\n\u25cf\nFollowing a story, leads to accountability\n\u00a0\n\u25cf\nAI can be used to summarise articles for TLDR (Too Long, Didn\u2019t Read) versions.\n\u00a0\n\u00a0\nUser Research\n\u00a0\n\u00a0\nMy user research included a quantitative approach of sending surveys out to users and getting\n\u00a0\ntheir opinions on how they chose a news app to read or use daily. I also wanted a user poll on\n\u00a0\nunderstanding a few icons to be used in the visual design of my app. I wanted to force myself to\n\u00a0\ntake a risk and pick out one icon that is generally not used in the context of this app, and wanted to\n\u00a0\ntry to test that on user\u2019 perception.\n\u00a0\nThe qualitative research included narration sessions with users that was required for my sense\n\u00a0\nand flow process. This process is to ask users to narrate out loud whatever they are seeing,\n\u00a0\nthinking or understanding about the paper prototype of the app. This helps me understand if the\n\u00a0\nusers are understanding the solution and the essence of the app\u2019s intended solution.\n\u00a0\n\u00a0\nThe Mobile App - Zagrut\n\u00a0\n\u00a0\nToday, most news is biased. We are unaware of our own biases. Bias, is as per, rating a single\n\u00a0\nsource by people from multiple perspectives. Our apps and news readers have bias built in. The\n\u00a0\n\u2018My Feed\u2019 or \u2018News for you\u2019 is a biased feed, that only feeds into news you like.\n\u00a0\n\u00a0\nI named the app \u2018zagrut\u2019, pronounced za-groot, which means \u2018beware\u2019 in my mother tongue,\n\u00a0\nKonkani, from South India. \n\u200b\nZagrut\n\u200b\n is a mobile app to critique the existing system of news\n\u00a0\npropagation and consumption and makes the user aware of the bias in this environment.\n\u00a0\n\u00a0\nZagrut focuses on the following solutions:\n\u00a0\n\u00a0\n\u25cf\nHome Page presents a \u2018latest feed\u2019 with option of choosing topics but not sources. \u2018My\n\u00a0\nfeed\u2019 or \u2018news for you\u2019 is absent.\n\u00a0\n\u00a0\n\u25cf\nMeta Article (data about the article) is shown in focus before the content itself.\n\u00a0\n\u25cf\nUsers are propelled to judge the headline.\n\u00a0\n\u25cf\nEcho Chambers - users are seamlessly shown multiple perspectives and feed changes to\n\u00a0\nthe other biased side that is not read as often.\n\u00a0\n\u25cf\nThe app has a dedicated onboarding for new users\n\u00a0\n\u25cf\nUsers can follow a particular news story\n\u00a0\n\u25cf\nSharing a news particle will always share three multiple perspectives.\n\u00a0\n\u00a0\nWhy will people trust this app?\n\u00a0\n\u00a0\n\u25cf\nWhy do people trust bottled water, when they can actually drink safe tap water?\n\u00a0\n10\n\u25cf\nWhy did people trust facebook so far, but after the data scandal broke out, their trust is\n\u00a0\nshaken from facebook?\n\u00a0\n11\n\u25cf\nAre reasons more than the obvious?\n\u00a0\n\u25cb\nManufactured demand: Research shows no trust in \u2018media\u2019 irrespective of side\n\u200b\n5\n\u00a0\n\u25cb\nPerception and perceived control: My app keeps the reader in the judging seat\n\u00a0\n\u25cb\nScaring and Misleading: Leaders like Trump/Modi openly shunning media\n\u00a0\n\u25cb\nTransparency: App states everything as is with no labels.\n\u00a0\n\u25cf\nWhy do people trust Wikipedia or why is it seen as trustworthy?\n\u00a0\n12\n\u25cb\nMachine learning mammoths and Tech Giants, like Facebook, Google Search and\n\u00a0\nYoutube  are already quoting Wikipedia.\n\u00a0\n\u25cf\nBias Pointers are propping up by demand: AllSides.com, MediaBiasFactCheck.com\n\u00a0\n10\n \u201cThe Story of Bottled Water\u201d <https://www.youtube.com/watch?v=Se12y9hSOM0>\n \n \n11\n Reuters Staff. \"Americans less likely to trust Facebook than rivals on personal data\". March 25, 2018.\n \n<https://www.reuters.com/article/us-facebook-cambridge-analytica-apology/americans-less-likely-to-trust-facebook-th\nan-rivals-on-personal-data-idUSKBN1H10AF>\n \n \n12\n Cox, Joseph. \"Why People Trust Wikipedia More Than the News\". Motherboard, August 11, 2014.\n \n<https://motherboard.vice.com/en_us/article/ae37ee/in-defense-of-wikipedia>\n \n \n \nDomains\n\u00a0\n\u00a0\nThe domains that I am exploring with this project are user experience design, interaction design,\n\u00a0\nUI design, mobile app screen design that delve into media bias, news reader bias, political biases\n\u00a0\nand the human psychology that encircles all of this.\n\u00a0\n\u00a0\nGoal and Design Statement\n\u00a0\n\u00a0\nHow can I make an app for smartphones that will\n\u00a0\n\u25cf\nengage users from all sides\n\u00a0\n\u25cf\nmake them read both sides of a story\n\u00a0\n\u25cf\nmake them aware of media sources, authors, known biases\n\u00a0\n\u25cf\ngetting them to follow a particular story\n\u00a0\n\u25cf\nrestrict their curation and \u201ctrends\u201d\n\u00a0\n\u25cf\nGenerate TLDR versions as optional reading\n\u00a0\n\u00a0\nPrecedents\n\u00a0\n\u00a0\n1.\nVox: is an American news and opinion website owned by Vox Media. The website was\n\u00a0\nfounded in 2014 by Melissa Bell, Matthew Yglesias, and Ezra Klein. Vox is noted for its\n\u00a0\nconcept of explanatory journalism.\n\u00a0\n\u00a0\n2.\nSnopes and PolitiFact:\n\u00a0\n\u00a0\nSnopes.com is one of the first online fact-checking websites. It is a widely known resource\n\u00a0\nfor validating and debunking urban legends and similar stories in American popular\n\u00a0\nculture, receiving 300,000 visits a day in 2010.\n\u00a0\n\u00a0\nPolitiFact.com is a project operated by the Tampa Bay Times, in which reporters and\n\u00a0\neditors from the Times and affiliated media fact-check statements by members of\n\u00a0\nCongress, the White House, lobbyists, and interest groups. They publish original\n\u00a0\nstatements and their evaluations on the PolitiFact.com website, and assign each a\n\u00a0\n\"Truth-O-Meter\" rating.\n\u00a0\n\u00a0\n3.\n\u2018Fake News\u2019 Games:\n\u00a0\n\u00a0\nPolitiTruth is a game about \u201cdistinguishing political fact from fiction.\u201d In our current\n\u00a0\npolitical nightmare climate, full of fake news and lying fascists co-opting the term fake\n\u00a0\nnews, anything that gets the truth out to as many people as possible as easily and as fun as\n\u00a0\npossible is more than just a Game of the Year.\n\u00a0\n13\nFactitious is a game to test users' ability to detect fake news from real.\n\u00a0\n\u00a0\n14\n\u00a0\n4.\nThe Wall Street Journal - Red Feed, Blue Feed\n: To demonstrate how reality may differ for\n\u00a0\n15\ndifferent Facebook users, The Wall Street Journal created two feeds, one \u201cblue\u201d and the\n\u00a0\nother \u201cred.\u201d If a source appears in the red feed, a majority of the articles shared from the\n\u00a0\nsource were classified as \u201cvery conservatively aligned\u201d in a large 2015 Facebook study. For\n\u00a0\nthe blue feed, a majority of each source\u2019s articles aligned \u201cvery liberal.\u201d These aren't\n\u00a0\nintended to resemble actual individual news feeds. Instead, they are rare side-by-side\n\u00a0\nlooks at real conversations from different perspectives.\n\u00a0\n\u00a0\n5.\nAllSides.com is a multi-partisan revolution and set of technologies fueled by data and\n\u00a0\npeople like you. The AllSides Bias Rating is based on a crowd-driven, patented technology.\n\u00a0\nFrom bias ratings to AllSides for Schools and civil dialogue across divides, it's\n\u00a0\npeople-powered tech.\n\u00a0\n\u00a0\n6.\nMediaBiasFactCheck.com founded in 2015, is an independent online media outlet. MBFC\n\u00a0\nNews is dedicated to educating the public on media bias and deceptive news practices.\n\u00a0\nMBFC News\u2019 aim is to inspire action and a rejection of overtly biased media. We want to\n\u00a0\nreturn to an era of straight forward news reporting. Funding for MBFC News comes from\n\u00a0\nsite advertising, individual donors, and the pockets of bias checkers.\n\u00a0\n13\n Minor, Jordan. \"PolitiTruth is Fake News: The Game\". June 20th, 2017.\n \n<https://www.geek.com/games/game-of-the-year-polititruth-1704116/>\n \n \n14\n Watson, Tennessee. \"To Test Your Fake News Judgment, Play This Game\". July 3, 2017.\n \n<https://www.npr.org/sections/ed/2017/07/03/533676536/test-your-fake-news-judgement-play-this-game>\n \n \n15\n Keegan, Jon. \"Blue Feed, Red Feed\". May 18, 2016.\n \n<http://graphics.wsj.com/blue-feed-red-feed/#/president-trump>\n \n\u00a0\n7.\nInShorts is a news app that selects latest and best news from multiple national and\n\u00a0\ninternational sources and summarises them to present in a short and crisp 60 words or less\n\u00a0\nformat, personalized for you, in both, English or Hindi. All summarised stories contain only\n\u00a0\nheadlines and facts, no opinions, to help you stay informed of the current affairs.\n\u00a0\n\u00a0\nConstraints\n\u00a0\n\u00a0\n\u25cf\nCheck for truly Partisan Agnostic - your own presumptions\n\u00a0\n\u25cf\nEvaluating sentiment not poke at belief or identity\n\u00a0\n\u25cf\nFinding the right proxy\n\u00a0\n\u25cf\nMeasure the \u2018do\u2019 than \u2018say\u2019\n\u00a0\n\u25cf\nGet people thinking - that should be good enough of a solution?\n\u00a0\n\u25cf\nExtreme people are not the intended focus\n\u00a0\n\u00a0\nProcess\n\u00a0\n\u00a0\n\u00a0\nImage 6\n\u00a0\n\u00a0\nI imagined amy process to be in stages - in a linear flowchart, but through my design thought\n\u00a0\nprocess and practice, it evolved into a circular method. I first started with sketches, from writing to\n\u00a0\nmind maps, to rough drawings, and then charting out the user flow. This was then made into a\n\u00a0\npaper prototype to be presented in front of a few users - not for the user interface, but to\n\u00a0\nunderstand the essence of the app, its meaning, the flow of thoughts and actions and to spot\n\u00a0\nanything abrupt or unusual.\n\u00a0\n\u00a0\n\u00a0\nWhile presenting the paper prototypes to the users, I asked them to narrate it out loud, so that\n\u00a0\ntheir thoughts, expectations and understanding of the app and their actions are clear to\n\u00a0\nthemselves and to me, and I can record their reactions perfectly. This went back to the drawing\n\u00a0\nboard for a better fidelity prototype.  All this comprised the stage of what I term as \u201csense and\n\u00a0\nflow\u201d. After sense and flow, the process was linear, but of course had many iterations and requires\n\u00a0\nmore too.\n\u00a0\n\u00a0\n\u25cf\nSense and Flow: the above described circular process. Prototypes 1 and 2 below belong to\n\u00a0\nthis section of the process. (Images 7 and 8)\n\u00a0\n\u25cf\nPrimary high fidelity: This is the most understandable prototype you can quickly make -\n\u00a0\nthat would seem like a well developed wireframe. Prototypes 3 and above were built here\n\u00a0\nat this stage. (Images 9, 10, 11)\n\u00a0\n\u25cf\nWord Design and Visual Design: Choosing the right wording, expressions and phrases.\n\u00a0\n\u25cf\nUser Reactions: Showing high fidelity interactive prototypes and recording reactions - this\n\u00a0\nwas done during the \u2018Major Major DIMENSIONS\u2019 Studio Exhibition show, May 5th, 2018.\n\u00a0\n\u25cf\nIterations - for refining the app, minor details, added features - based on more elaborate\n\u00a0\nuser feedback and reactions recorded.\n\u00a0\n\u00a0\nPrototypes\n\u00a0\n\u00a0\nImage 7\n\u00a0\n16\n\u00a0\n\u00a0\nImage 8\n\u00a0\n16\n \"What do Prototypes Prototype? - Semantic Scholar.\" Accessed February May 8, 2018.\n \nhttps://pdfs.semanticscholar.org/30bc/6125fab9d9b2d5854223aeea7900a218f149.pdf\n\u200b\n.\n \n \n\u00a0\nImage 9\n\u00a0\n\u00a0\n\u00a0\nImage 10\n\u00a0\n\u00a0\nImage 11\n\u00a0\n\u00a0\nImage 12\n\u00a0\nVisual Design\n\u00a0\n\u00a0\nFor a news app that speaks against bias, I decided that it should be \u2018colorless\u2019 and stick to greys\n\u00a0\nand whites. But to add to the aesthetic, I chose the Pantone Color of the Year, Ultra Violet\n, that\n\u00a0\n17\nalso well represents the \u2018centre\u2019 that is neither left or right biased, and is only used as an accent\n\u00a0\ncolor.\n\u00a0\n\u00a0\nThe rest of the visual design was simple, not too far away from the regular news apps, and I based\n\u00a0\nthis on Google\u2019s Material Design basics. The app will need a few more iterations on the visual\n\u00a0\ndesign.\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n17\n Pantone.com <https://www.pantone.com/color-of-the-year-2018>\n \nThe Algorithm\n\u00a0\n\u00a0\n\u25cf\nYou are only fed with news from \u2018center\u2019 sources.\n\u00a0\n\u25cf\nIf you read one biased news source, you will be shown another biased news source from\n\u00a0\nthe opposite end - same translated on to the news feed.\n\u00a0\n\u25cf\nYou will have one news story from each side, left, right and center to read and without\n\u00a0\nwhich you will have to reset back home and pick your next story.\n\u00a0\n\u00a0\n\u25cf\nGenerating unique key for every page combination, so that when shared outside the app,\n\u00a0\nclicks to this will take you back to the screen showing multiple sources of the same story.\n\u00a0\n\u25cf\nFiltering and judging would not change the general news feed, but reading them will.\n\u00a0\n\u25cf\nTLDR versions of articles will be shown by machine learning and a summary will be\n\u00a0\ncreated. This can be turned off in settings and users will get direct access to the full\n\u00a0\nversions out of the article.\n\u00a0\n\u00a0\nEvaluation and Next Steps\n\u00a0\n\u00a0\n\u25cf\nNext steps is to frame and refine all the features perfectly\n\u00a0\n\u25cf\nGive multiple iterations to the visual design\n\u00a0\n\u25cf\nFrame this in two contexts of people - USA and India and record more user reactions.\n\u00a0\n\u00a0\nConclusion\n\u00a0\n\u00a0\nJournalism is being hit by forces that have been building for some time but the past year has seen\n\u00a0\nthis story break out from its media bubble to attract the attention of policy makers, politicians, and\n\u00a0\neven the wider public. The news itself has become the news.\n\u00a0\n\u00a0\nFrom the platform perspective, there is an increased recognition that algorithms are rarely\n\u00a0\nneutral, nor can they deal with the nuances and complexities of our modern world. As regulators\n\u00a0\nand legislators circle in the wings, Google and Facebook are responding in various ways including \u2013\n\u00a0\nin the news area \u2013 through partnerships with independent fact-checkers and the testing of new\n\u00a0\nalgorithms that attempt to break people out of their bubbles.10 They know too that their\n\u00a0\nlong-term business depends on building far higher levels of trust than our survey demonstrates\n\u00a0\npeople currently have in social media in particular.\n\u200b\n5\n\u00a0\n\u00a0\nThe crisis over fake news could be the best thing that has happened to journalism \u2013 or the worst.\n\u200b\n2\n\u00a0\n\u00a0\nZagrut is not a magic wand that is aimed to solve all these problems. However, it's a step in that\n\u00a0\ndirection - to critique the existing system of news propagation and consumption and makes the\n\u00a0\nuser aware of the bias in this environment.\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n \n \n\u00a0\n \nAppendix\n\u00a0\n\u00a0\nImages Index\n\u00a0\n\u00a0\n1.\nFree Writing Screenshot\n\u00a0\n2.\nMind Map Sketch\n\u00a0\n3.\nChanging Device Use for News - Reuters Digital News Report, 2017\n\u00a0\n4.\nSmartphone News Use - Reuters Digital News Report, 2017\n\u00a0\n5.\nBias in following politicians on social media - Reuters Digital News Report, 2017\n\u00a0\n6.\nProcess Diagram\n\u00a0\n7.\nPrototype Purpose Diagram\n\u00a0\n8.\nPrototype 1 - Sense and Flow\n\u00a0\n9.\nPrototype 2 - Sense and Flow\n\u00a0\n10.\nPrototype 3\n\u00a0\n11.\nPrototype 4\n\u00a0\n12.\nPrototype Final\n\u00a0\n\u00a0\nReferences\n\u00a0\n\u00a0\n1.\nEames, Charles. \"Design Q&A Text\". Palais de louvre, 1972.\n\u00a0\n<http://www.eamesoffice.com/the-work/design-q-a-text/>\n\u00a0\n\u00a0\n2.\n Upadhyay, Karishma. \"Sridevi\u2019s death has brought out the worst in Indian media, crossing\n\u00a0\nthe line between journalism and exploitation\". Feb, 27 2018.\n\u00a0\n<https://www.firstpost.com/entertainment/sridevis-death-has-brought-out-the-worst-in-\nindian-media-crossing-the-line-between-journalism-and-exploitation-4368811.html>\n\u00a0\n\u00a0\n3.\n Jadhav, Rajendra. \"Thousands of farmers march to Mumbai to demand help\". March 12,\n\u00a0\n2018.\n\u00a0\n<https://in.reuters.com/article/india-farmers-march/thousands-of-farmers-march-to-mu\nmbai-to-demand-help-idINKCN1GO09T>\n\u00a0\n\u00a0\n4.\nAbraham, Sunil. \"Cambridge Analytica scandal: How India can save democracy from\n\u00a0\nFacebook\". March 29, 2018.\n\u00a0\n<http://www.business-standard.com/article/economy-policy/cambridge-analytica-scanda\nl-how-india-can-save-democracy-from-facebook-118032800146_1.html>\n\u00a0\n\u00a0\n5.\nReuters. \"Digital News Report\". 2017\n\u00a0\n<https://reutersinstitute.politics.ox.ac.uk/sites/default/files/Digital%20News%20Report\n%202017%20web_0.pdf>\n\u00a0\n\u00a0\n6.\n Hayes, Jimmy. \"10 best news apps: keep up to date with the real stories\". Tech Radar,\n\u00a0\nAugust 27, 2017\n\u00a0\n<https://www.techradar.com/news/forget-fake-news-10-great-apps-to-keep-up-to-date-\nwith-the-real-news>\n\u00a0\n\u00a0\n7.\nKramer, Adam. Guillory, Jamie. Hancock, Jeffrey. \"Experimental evidence of massive-scale\n\u00a0\nemotional contagion through social networks\". June 17, 2014.\n\u00a0\n<http://www.pnas.org/content/111/24/8788>\n\u00a0\n\u00a0\n8.\nDarr, Joshua. \"Collision with Collusion: Republican Reaction to the Trump-Russia Scandal\".\n\u00a0\nSPSA 2018, New Orleans, LA.\n\u00a0\n<http://joshuadarr.weebly.com/uploads/5/1/8/1/51819147/darr_et_al_trump_russia_spsa\n.pdf>\n\u00a0\n\u00a0\n9.\nVosoughi, Soroush. Roy, Deb. \"The Spread of True and False Information Online\". Social\n\u00a0\nMachines, MIT Media Lab.\n\u00a0\n<https://www.media.mit.edu/projects/the-spread-of-false-and-true-info-online/overview\n/>\n\u00a0\n\u00a0\n10.\n\u201cThe Story of Bottled Water\u201d <https://www.youtube.com/watch?v=Se12y9hSOM0>\n\u00a0\n\u00a0\n11.\n Reuters Staff. \"Americans less likely to trust Facebook than rivals on personal data\".\n\u00a0\nMarch 25, 2018.\n\u00a0\n<https://www.reuters.com/article/us-facebook-cambridge-analytica-apology/americans-l\ness-likely-to-trust-facebook-than-rivals-on-personal-data-idUSKBN1H10AF>\n\u00a0\n\u00a0\n12.\n Cox, Joseph. \"Why People Trust Wikipedia More Than the News\". Motherboard, August\n\u00a0\n11, 2014. <https://motherboard.vice.com/en_us/article/ae37ee/in-defense-of-wikipedia>\n\u00a0\n\u00a0\n13.\n Minor, Jordan. \"PolitiTruth is Fake News: The Game\". June 20th, 2017.\n\u00a0\n<https://www.geek.com/games/game-of-the-year-polititruth-1704116/>\n\u00a0\n\u00a0\n14.\n Watson, Tennessee. \"To Test Your Fake News Judgment, Play This Game\". July 3, 2017.\n\u00a0\n<https://www.npr.org/sections/ed/2017/07/03/533676536/test-your-fake-news-judgem\nent-play-this-game>\n\u00a0\n\u00a0\n15.\n Keegan, Jon. \"Blue Feed, Red Feed\". May 18, 2016.\n\u00a0\n<http://graphics.wsj.com/blue-feed-red-feed/#/president-trump>\n\u00a0\n\u00a0\n16.\n Pantone.com <https://www.pantone.com/color-of-the-year-2018>\n\u00a0\n\u00a0\n\u00a0\nCredits\n\u00a0\n\u00a0\n\u25cf\nProf. David Carroll, Parsons School of Design, New York\n\u00a0\n\u25cf\nMichael Lee, Google, New York and Parsons School of Design\n\u00a0\n\u25cf\nShayla, Google, New York\n\u00a0\n\u25cf\nKenneth Dsouza, GoJek, Bangalore, India\n\u00a0\n\u25cf\nAllSides.com and MediaBiasFactCheck.com\n\u00a0\n\u25cf\nSummaries from smmry.com\n\u00a0\n\u25cf\nThe Noun Project thenounproject.com\n \n\u25cf\nInvision Studio, Sketch\n\u00a0\n\u00a0", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "zagrut\u200b.", "author": ["M Dcunha"], "pub_year": "2018", "venue": "NA", "abstract": "\u201cOrder is Heaven\u2019s first law\u201d, a quote from Alexander Pope that I hold dear. Design to me, is  about creating specific order and organizing elements within it, which best accomplishes a"}, "filled": false, "gsrank": 112, "pub_url": "https://mariodcunha.github.io/papers/zagrut_mariodcunha_draft.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:skvsZ4g-VqIJ:scholar.google.com/&output=cite&scirp=111&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D110%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=skvsZ4g-VqIJ&ei=GLWsaJ-LII6IieoP0sKRuAk&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:skvsZ4g-VqIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://mariodcunha.github.io/papers/zagrut_mariodcunha_draft.pdf"}}]