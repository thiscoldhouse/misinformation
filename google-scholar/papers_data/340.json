[{"title": "Gamified inoculation interventions do not improve discrimination between true and fake news: Reanalyzing existing research with receiver operating characteristic \u2026", "year": "2023", "pdf_data": "HOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  1 \n \n \n \nGamified Inoculation Interventions Do Not Improve Discrimination Between True and \nFake News:  Reanalyzing Existing Research With Receiver Operating Characteristic \nAnalysis  \n \nAriana Modirrousta -Galian  & Philip A. Higham  \nUniversity of Southampton  \n \n \nWord Count: 18 ,646 \n \n \n\u00a9 2023, American Psychological Association. This paper is not the copy of record and \nmay not exactly replicate the final, authoritative version of the article. Please do not \ncopy or cite without authors' permission. The final article is available at : \nhttps://doi.org/10.1037/xge0001395  \n \n \n \n \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  2 \nAuthor Note  \n Ariana Modirrousta -Galian  https://orcid.org/0000 -0003 -2925 -2976   \n Philip A. Higham  https://orcid.org/0000 -0001 -6087 -7224    \n The data and analytic code needed to replicate the analyses reported in this paper  \nand the supplemental materials  are available on the Open Science Framework:  \nhttps://osf.io/85be7/ . This study was not preregistered. We have no conflicts of interest to \ndisclose. Our work was funded by the Economic and Social Research Council South Coast \nDoctoral Training Partnership.  \n This manuscript was uploaded as a preprint to PsyAr Xiv \n(https://psyarxiv.com/4bgkd/ ), and portions of its findings were presented at the 63rd Annual \nMeeting of the Psychonomic  Society , Boston, M A, United States,  November 17 \u201320, 2022 . \n Ariana Modirrousta -Galian played lead role in data curation, formal analysis, funding \nacquisition, investigation, methodology, project administration, resources, software, \nvalidation, visualization and writing of original draft, equal role in writing of r eview and \nediting, and supporting role in conceptualization. Philip A. Higham played lead role in \nconceptualization and supervision, supporting role in data curation, formal analysis, \ninvestigation, methodology, project administration, validation, visualiz ation and writing of \noriginal draft and equal role in writing of review and editing.  \n We would like to thank Tina Seabrooke for her proofreading of the manuscript  and \nvaluable suggestions . \n Correspondence concerning this article should be addressed to Ariana Modirrousta -\nGalian, Centre for Perception and Cognition, School of Psychology, University of \nSouthampton, Highfield, Southampton, UK, SO17 1BJ. Email: amg1g17@soton.ac.uk   \n  \n\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  3 \nAbstract  \nGamified inoculation  interventions designed to improv e detect ion of online misinformation \nare becoming increasingly prevalent . Two of the most notable interventions of this kind are \nBad News and Go Viral!. To assess their efficacy, prior research has typically used pre -post \ndesigns in which participants rated the reliability or manipulativeness of true and fake news \nitems before and after playing  these games , while most of the time  also including a control \ngroup who played an irrelevant game (Tetris)  or did nothing at all . Mean ratings  were then \ncompared between pre -tests and post -tests  and/or between the control and experimental \ncondition s. Critically, these prior studies have not separated response bias effects (overall \ntendency to respond \u201ctrue\u201d or \u201cfake\u201d) from discrimination ( ability to distinguish between true \nand fake news , commonly dubbed discernment ). We reanalyzed the results from five prior \nstudies using receiver operating characteristic (ROC) curves , a method common to  signal \ndetection theory  (SDT)  that allows for discrimination to be measured free from response \nbias. Across the studies , when comparable true and fake news items were used , Bad News \nand Go Viral! d id not improve discrimination, but rather elicit ed more \u201cfalse\u201d responses to all \nnews items  (more conservative responding ). These novel findings suggest that the current \ngamified inoculation  interventions designed to improve fake news detection are not as \neffective as previously thought  and may even be counterproductive . They also  demonstrate  \nthe usefulness of ROC analysis, a largely  unexploited method in this setting, for assessing \nthe effectiveness of any intervention designed to improve fake news detection.   \n Keywords : Online misinformation, gamification, fake news games, receiver operating \ncharacteristic s, signal detection theory  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  4 \nPublic Significance Statement  \nThis study suggests that Bad News and Go Viral!, two popular online browser games, do not \nimprove people\u2019s ability to discriminate between true and fake news. Instead, they cause \npeople to respond more  conservative ly (i.e., a general tendency to rate all news items as \nmore  \u201cfalse \u201d). This finding highlights the possibility that certain games designed to improve \npeople\u2019s ability to spot online misinformation may be counterproductive, as they could be \nincreasing distrust in legitimate information. We offer a key recommendation to avoid this \npotential risk: Researchers should assess how these gamified psychological interventions \naffect belief in both true and fake news with a method that can measure discrimination free \nfrom response bias, such as receiver operating characteristic analysis.  \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  5 \nGamified Inoculation Interventions Do Not Improve Discrimination Between True and \nFake News:  Reanalyzing Existing Research With Receiver Operating Characteristic \nAnalysis  \n \n\"Falsehood flies, and truth comes limping after it, so that when men come to be  undeceived, \nit is too late; the jest is over, and the tale hath had its effect\u201d (Jonathan Swift, 1710/2012, \npara. 9).  \n \nSwift\u2019s insight appeared in The Art of Political Lying , which was published over 300 year s \nago. It suggests  that attempts to manipulate people with f alse or misleading information, also \nknown as misinformation, are not novel (Allen et al., 2020). However, recent advances in \ntechnology have only served to facilitate the distribution of misinformation. The creation of \nthe internet in 1983 eventually gave rise to online  misinformation, particularly after the \npopularization of social media, and provided a global medium for falsehoods as well as the \ntools necessary to promote their spread ( Allen  et al., 2020 ). Seeing  as 63% of the total world \npopulation uses the internet as of April 2022 (Johnson, 2022 ), a vast number  of people can  \ngenerate online misinformation that has the potential to reach a huge  audience.   \nOnline misinformation , commonly referred to as  fake news ,1 originate s from a variety \nof sources , including individual social media users, websites, social media influencers, \ncelebrities, and governments  (Mukhtar, 2021) . The prevalence of misinformation, coupled \nwith people\u2019s inability to identify and disregard it, has created a major problem in modern \nsociety (Kanozia et al., 2021). As highlighted  in Swift\u2019s comment, t his issue is further \nexacerbated by the fact that once people have accepted misinformation as true, they often \ncontinue to believe in it even after it has been corrected, which is terme d the continued \ninfluence effect  (Johnson & Seifert, 1994; Lewandowsky et al., 2012).  \n \n1 Throughout this paper, we use the terms \u201cfake news \u201d and \u201cmisinformation \u201d interchangeably for ease  of \nexposition . However, it is important to note that the two terms are not always regarded as synonymous. For \nexample, Lazer et al. (2018) defined fake news as a specific type of misinformation that \"mimics news media \ncontent in form but \u2026 lack[s] the news media's edit orial norms and processes for ensuring the accuracy and \ncredibility of information\" (p. 1094).  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  6 \nRegardless of its origin, online misinformation can have devastating consequences, \nsuch as inciting violence and even threatening  democracy . This is exemplified by the deadly \ninsurrection at the  US Capitol  on January 6, 2021 , which was fueled by false election fraud \nclaims  that proliferated on social media  at the time  (Calvillo et al., 2021). Considering the \nalarming effects  of online misinformation, finding ways to combat this issue is imperative. \nFor psychologists, an important  avenue of investigat ion involves  finding ways to  improv e \npeople\u2019s ability to identify and thus discount online misinformation  before it is accepted as \ntrue, thereby avoiding the problem of continued influence . Early misinformation discounting \nlimits the unintentional spread of online misinformation by social media users (Adjin -Tettey, \n2022), reduces the incentive to create false or misleading content due to a lack of public \nconfidence and support (Van Bavel et al., 2021), and prevent s the harmful consequences \nthat stem from mistaken ly belie ving online misinformation (Ecker et al., 2022).  \nInoculation Theory and Gamified Interventions  \nGamified psychological interventions designed to protect people from online \nmisinformation before it is encountered are becoming increasingly prevalent. Gamification \nrefers to using game design elements in non -game settings (Huotari & Hamari, 2016), and \nits popularity in the context of online misinformation can be attributed to its ability to increase \npublic participati on and stimulate user engagement (Morschheuser et al., 2016). The best -\nknown gamified fake news interventions are typically  informed by inoc ulation theory \n(McGuire, 1964). Inoculation theory  draws upon a medical analogy; vaccines containing a \nweakened dose of a virus can trigger the production of antibodies in the immune system that \nconfer resistance against future infection by a stronger version of the same virus. \nAnalogously , inoculation theory suggests that by exposing people to weakened arguments \nagainst an attitude they hold, resistance can be conferred against future attacks on that \nparticular attitude (Banas & Rains, 2010). In recent years, inoculation theory has been \napplied to the topic of o nline misinformation, with researchers investigating the possibility of \ncreating a \u201cbroad -spectrum vaccine\u201d that generates \u201cmental antibodies\u201d against false or \nmisleading content spread on the internet (Roozenbeek & van der Linden, 2019, p. 2). To \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  7 \nachieve psychological inoculat ion, gamified interventions have  expos ed people to some \ncommon techniques used to produc e online misinformation . The hope is that such exposure \nwill confer resistance against actual online misinformation they encounter in the future \n(Roozenbeek & van der Linden, 2019).  \n Gamified interventions  that aim to pre -emptively protect people against online \nmisinformation  utilize  \u201cprebunking\u201d , namely , preventing people from believing online \nmisinformation they encounter in the future  (Tay et al., 2021) . Prebunking  differ s from the \nmore traditional \u201c debunking \u201d, which aims to retrospectively correct people\u2019s belief in online \nmisinformation. Although the comparative effectiveness of prebunking and debunking falls \noutside the scope of this paper, it is worth noting that the research comparing the efficacy of \nthese approaches is mixed; some studies show that debunking is more effective at \nimproving news veracity discernment than prebunking (Brashier et al., 2021), while others \nindicate the opposite (Grady et al., 2021). Nevertheless, interventions derived from \ninoculation theor y automatically inco rporate prebunking due to their preventative nature.  \nIntervention Specificity  \nThe overarching aim of any psychological intervention is to change people\u2019s behavior \nfor the better (Jhangiani et al., 20 19). However, some  interventions can be over-general and \nunintentionally influence  other  behaviors . Depending on the behaviors, overly general \ninterventions can be  devastating.  For example,  in the last few decades, interventions have \nbeen developed to reduce the blame associated with  mental illness . This blame reduction \nhas been achieved  by developing interventions that place more emphasis on the biological \ncauses of mental illness (Corrigan, 2016). Phelan et al. (2011) found that these interventions \nhelped people understand that mental illness is not a choice , but more akin to a disease . \nWhen only taking this outcome into account, this type of intervention may seem successful, \nbut it is only half the story . Unfortunately,  these interventions also promoted the belief that \nmental illness is hard wired and un treatable , which  can influence whether an employer will \nhire people with mental illness, or whether a landlord will rent to them.  Thus , despite the \nintervention s having the desirable intended effect, the unfortunate  unintended effects have \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  8 \nmeant that the success of these interventions have been called into question (Corrigan, \n2016; Phelan et al., 2011; Read & Harr \u00e9, 2009; Read, 2011).  \n  In our view, the issue of online misinformation is similar to this example from clinical \npsychology. If an intervention has the desired effect of decreas ing belief in fake news but \nalso has the undesired effect of decreas ing belief in true news, then we should  question its \nefficacy. As a case in point , Clayton et al. (2020) found that when people received a general \nwarning about misleading information on social media, their belief in both true and false \nheadlines decreased. Accordingly, they concluded tha t these general warnings \"pose a \npotential hazard\" as they could \"increase distrust in legitimate information\" (p. 1091 ). In fact, \nfailure to believe the truth can potentially be more damaging than believing falsehoods. For \nexample, rejecting  the valid scientific evidence supporting the efficacy of COVID -19 vaccine s \nis arguably more harmful than believing the falsehood that 5G towers cause COVID -19. The \nformer leads to  vaccine refusal , which threaten s personal and global health, while the latter \nleads to vandalization of 5G towers , which is comparably innocuous (Afolabi & Ilesanmi, \n2021; Pertwee et al., 2022). Therefore, in our view , any intervention designed to tackle the \nissue of online misinformation must be assessed both with respect to belief in fake news and \nbelief in true news  (see also Guay et al., 2022) . However, as will be demonstrated in \nsubsequent sections, this is not a universal opinion in the field of online misinformation \nresearch.   \nSignal Detection Theory  and Receiver Operating Characteristic Analysis  \nBatailler et al. (2022) were the first to apply signal detection theory (SDT) to research \non the identification of fake news. They used SDT to reanalyze data from two previous \nstudies : Pennycook et al. (2018) and Pennycook and Rand (2019) . The reanalys es provided \nmore nuanced insights into the results of these studies by distinguishing between \ndiscrimination and response bias. In the context of online misinformation, discrimination \nrefers to the ability to distinguish between true and fake news, which is al so referred to as \nnews veracity discernment , while response bias refers to the general tendency to rate news \nitems as true or fake regardless of their objective veracity. If an intervention affects only the \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  9 \ntarget behavior, this will result in an increase in discrimination. For example, discrimination \nwould improve if belief in fake news decreases while belief in true news remains relatively \nintact. Conversely, if the intervention has more general effects on both true and fake news \nby, for example, reducing belief in all news regardless of objective veracity, this will affect \nresponse bias.2  \nBatailler et al. (2022) used single -point indices of discrimination ( d\u2032) and  response  \nbias ( c), which carry the strong assumption of equal -variance Gaussian underlying evidence \ndistributions. Receiver operating characteristic (ROC) analysis, a  more powerful  \nmethod ology  common to SDT, allows researchers to measure discrimination free from \nresponse bias  without making the same strong assumptions  (Higham & Higham, 2018).  \nIndeed, Batailler et al. recommended using ROC analysis in future research.  To the best of \nour knowledge, ROC analysis has only been used once before with research on fake news \n(Modir rousta -Galian et al., in press ). Instead, most studies have analyzed mean belief \nratings  in true and fake news , which are not ideally suited for separating discrimination and \nresponse bias.  \nSDT assumes that people have an internal dimension, also referred to as a decision \naxis, that represents the amount of subjective evidence for the presence of one type of \nstimul us over another type of stimul us (Aleci, 2021). Commonly, one type of stimulus \ncontains sought -after information (e.g., truth) and is called a signal  trial, whereas this \ninformation is absent in the other type of stimulus and is called a noise  trial.3 To understand \nthis, consider the discernment of true and fake news items. When the task is defined as \ndetecting truth in news items, the internal dimension will represent a continuum ranging from \n \n2 A change in  response bias is often  interpreted to mean that the placement of the response criterion (the \ndecision cut-off, as explained later)  has been altered . However, a lthough a change to the placement of the \nresponse criterion will affect measures of response bias, so will changes to the placement of the evidence \ndistributions  on the subjective evidence dimension . We elaborate on these different interpretation s of response \nbias effects  in the General Discussion . For now, readers should not assume that if we describe an intervention as \naffecting response bias , we do not necessarily mean that the response criterion has moved.  \n \n3 SDT applications are  commonly concerned with modelling discrimination when there is one type of evidence  \nassociated with  the signal  stimulus (e.g., evidence for truth)  which is lacking from the noise stimulus . However, it \nis possible that noise trial s could contain evidence aiding discrimination as well. For example, a fake news item \n(noise) might not just lack evidence for truth, it might also contain  evidence for falsity.   \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  10 \nlow perceived truth to high perceived truth (see Figure 1). The subjective mapping of true \nand fake news items on this internal dimension can be represented by equal -variance \nGaussian distributions as shown in Figure 1, although other possibilities can also  be \nconsidered (e.g., unequal -variance Gaussian  distributions ). Gaussian distributions are \ncommonly assumed because of noise; that is, the perceived truth of a news item, regardless \nof whether it is true or fake, will vary across items and be influenced b y other random factors \nsuch as memory and current context (Heeger, 1997; Higham et al., 2016). Notably, since the \ntask is to detect truth in news items, the true news (signal) distribution will be higher on the \ninternal dimension (i.e., further to the right) than the fake news (noise) distribution, as long \nas discernment is above chance.  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  11 \nFigure 1  \nEqual -Variance Gaussian Distributions of True and Fake News Items Distributed Over a Dimension of \nSubjective Truth as Conceptualized by Signal Detection Theory  \n \nNote . Lib. = Liberal; Cons. = Conservative; Discr. = Discrimination. The vertical dotted lines represent \nliberal (left) and conservative (right) decision criteria. The red and blue circles represent individual \nfake and true news items, respectively.  \n \nFigure 1 shows the simplest SDT case with two types of stimuli (true and fake news) \nand two available responses (\u201ctrue\u201d and \u201cfake\u201d). The response elicited for a given item is \ndetermined by the item\u2019s position relative to a cut -off, also known as a response  criterion.  \nThe placement of the criterion on the decision axis is malleable and assumed to be under \nthe control of  the observer (Aleci, 2021). We  have represented this malleability by including \ntwo criteria (vertical dotted lines) in two different positi ons in Figure 1. If the subjective \nevidence of an item is equal to or higher than the criterion, the observer gives a response \nindicating the presence of a signal, which in this case would be a \u201ctrue\u201d response. If the \n\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  12 \nsubjective evidence associated with an item does not reach the criterion, then the observer \nresponds that the signal is absent (i.e., \u201cfake\u201d). If the criterion is placed low on the internal \ndimension (e.g., the vertical line  further  to the left in Figure 1), then little subjective evidence \nis needed for a \u201ctrue\u201d response,  so the observer  respond s \u201ctrue\u201d frequently . In this case, the  \nobserver  is said to have a liberal response bias. In contrast, if the criterion is placed high on \nthe internal dimension (e.g., the vertical line further to the right in Figure 1), then a \nconsiderable amount  of subjective evidence is needed for a \u201ctrue\u201d respon se, so the observer \nresponds \u201ctrue\u201d  relatively infrequently . In this case, the observer is said to have a \nconservative response bias. Finally, the ability for the observer to accurately discriminate \nbetween true and fake news items is represented by the overlap of the distributions  (i.e., \ncomplete overlap  = no discrimination ; no overlap = excellent discrimination) . A common \nmeasure of discrimination is the standardized distance between the means of the respective \ndistributions, which is known as d\u2032 (de Gardelle & Kouider, 2009). Note that discrimination is \nthe same regardless of whether the response criterion is liberal or conservative in Figure 1, \nreflecting the independence of discrimination and response bias.  \nAlso shown in Figure 1 are two specific news items represented as circles, one fake \n(red) and the other true (blue). For the liberal criterion case, the evidence associated with \nboth items exceeds the criterion, so the observer would respond \u201ctrue\u201d for bot h. This is a \ncorrect response for the true (blue) news item and is called a hit. The proportion of all true \nnews items falling above the criterion is called the hit rate (HR), which for the liberal case in \nFigure 1  is approaching 1.0. The \u201ctrue\u201d response t o the fake (red)  news  item, however, is a \ntype of error called a false alarm . The proportion of fake news items falling above the \ncriterion (which in this case is liberal) is called the false alarm rate  (FAR), which in the \nexample in Figure 1 is about 0.7.  \nThe situation is somewhat different for the conservative criterion case. Now, neither \nitem exceeds the criterion, and so the observer responds \u201cfake\u201d to both. This response is \ncorrect for the fake news item and is called a correct rejection . The correct rejection rate  \n(i.e., the proportion of correct rejections) is equal to one minus the FAR. The \u201cfake\u201d response \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  13 \nto the true news item is incorrect and is called a miss. The miss rate  (i.e., the proportion of \nmisses) is equal to one minus the HR.  \nFigure 1 depicts the SDT model for binary tasks , where participants can only choose \nbetween two answers (e.g., \u201ctrue\u201d or \u201cfake\u201d) . If participants answer using an ordinal  rating \nscale , however , a more powerful ROC analys is can be conducted  instead . Two example \nROC curves are shown in Figure 2. In short, ROC curves plot multiple HRs as a function of \nmultiple FARs , which are each derived from the individual points on the rating scale . ROC \ncurves  provide a useful graphical tool for visualizing discrimination and response bias \n(Tasche, 2008). The ordinal rating scale is dichotomized at each point on the scale by \ntreating each level ( e.g., 1, 2, 3, 4, 5, 6, and 7) as a single cut -off point, specifically a point \non the scale that corresponds to hypothetical yes/no (or in this case true/ fake) criteria \n(Mandrekar, 2010). A HR and a FAR is computed for each scale value, with higher scale \nvalues corresponding to more conservative criteria. So, if 4 was the cut -off point, the \nproportion of true and fake news items assigned 4 or higher would const itute the HR and \nFAR, r espectively. This process is completed for all the points on a scale.  Chance -level \ndiscrimination, where the HR equals the FAR for all points (i.e., complete overlap of the \nevidence distributions), corresponds to a straight line drawn from the bottom -left to the top -\nright in the ROC space. It is commonly included as a point  of reference when plotting ROC \ncurves (see Figures 2 & 3).  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  14 \nFigure 2  \nROC Curves Showing Lower Discriminatory Power and Higher Discriminatory Power  \n \nNote . ROC = Receiver operating characteristic. These ROC curves are obtained from equal -variance \nGaussian distributions.  \n \n  \n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Lower Discriminator y Power\nFalse Alar m RateHit Rate\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Higher Discriminator y Power\nFalse Alar m RateHit Rate\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  15 \nFigure 3  \nROC Curves Showing a Liberal Response Bias, no Response Bias, and a Conservative Response \nBias \n \nNote . ROC = Receiver operating characteristic. These ROC curves are obtained from equal -variance \nGaussian distributions, and discrimination was kept constant across all three scenarios. Although it \nappears as though the liberal figure has five points and the unbiased figure ha s six points, in fact all \nfigures have seven points; three points in the upper -right portion of the liberal figure are overlapping, \nand two points in the upper -right portion of the unbiased figure are overlapping.  \n \nROC curves can be created for individual participants by plotting their HRs and FARs \nat each scale point . Alternatively,  ROC curves can be generated for different tests (e.g., pre -\ntests and post -tests) or for different experimental conditions (e.g., treatment conditions and \ncontrol conditions) by plotting HRs and FARs at each scale point aggregated across \nparticipants. The shape of  the ROC curve  and where the points lie on it provide a \nstraigh tforward  means to examine  discrimination and response bias. Changes in \ndiscrimination are indicated by the extent to which the ROC curve bows from the diagonal; if \ndiscrimination decreases , the ROC curve bows less from the diagonal, whereas if \ndiscrimination increases , the ROC curve bows further  from the diagonal (see Figure 2). In \ncontrast, changes in response bias are indicated by the placement of the points on the ROC \ncurve; a conservative response bias is indicated by ROC points that are more offset towards \n0.0 0.2 0.4 0.6 0.8 1.00.0 0.2 0.4 0.6 0.8 1.0Liberal\nFalse Alar m RateHit Rate\n0.0 0.2 0.4 0.6 0.8 1.00.0 0.2 0.4 0.6 0.8 1.0Unbiased\nFalse Alar m RateHit Rate\n0.0 0.2 0.4 0.6 0.8 1.00.0 0.2 0.4 0.6 0.8 1.0Conser vative\nFalse Alar m RateHit Rate\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  16 \nthe lower -left portion of the curve, whereas a liberal response bias is indicated by ROC \npoints that are more offset towards the upper -right portion of the curve (see Figure 3).  \nStatistical measures of discrimination and response bias can also be obtained from \nROC curves. One of the most widely used non -parametric measures of discrimination is the \narea under the curve (AUC) . As discrimination increases from chance -level responding to \nperfect discrimination, AUC increases from .5 to 1.0. It can be estimated by using the \ntrapezoidal rule formula from Pollack and Hsieh (1969) : \n\ud835\udc34\ud835\udc48\ud835\udc36 =0.5 \u2211(\ud835\udc3b\ud835\udc45 \ud835\udc58+1+\ud835\udc3b\ud835\udc45 \ud835\udc58)(\ud835\udc39\ud835\udc34\ud835\udc45 \ud835\udc58+1\u2212\ud835\udc39\ud835\udc34\ud835\udc45 \ud835\udc58)\ud835\udc5b\n\ud835\udc58=0 (1) \nIn this equation, k denotes the different criteria plotted on the ROC curve and n represents \nthe total number of criteria. The trapezoidal rule estimates the AUC by drawing straight lines \nbetween the points on the ROC curve to create trapezoids. Therefore, if the ROC curve is \ncurvilinear, the trapezoidal rule underestimates the AUC (De Long et al., 1988). Corrections \nhave been offered to compensate for this underestimation (see Donaldson & Good, 1996), \nbut they are mathematically complex and limited to certain types of data (Higham & Higham, \n2018). Therefore, we used  the trapezoidal rule  in the current paper as it has the advantage \nof broad applicability , few assumptions,  and mathematical simplicity (Messori et al., 2019).  \nA useful non -parametric index of response bias is B\"D, which can be calculated at \neach scale point using the following formula from  Donaldson (1992 ): \n\ud835\udc35\"\ud835\udc37=(1\u2212\ud835\udc3b\ud835\udc45)(1\u2212\ud835\udc39\ud835\udc34)\u2212(\ud835\udc3b\ud835\udc45)(\ud835\udc39\ud835\udc34)\n(1\u2212\ud835\udc3b\ud835\udc45)(1\u2212\ud835\udc39\ud835\udc34)+(\ud835\udc3b\ud835\udc45)(\ud835\udc39\ud835\udc34) (2) \nCrucially, its usefulness stems from its ability to provide accurate estimates of response bias \neven when it is calculated from collapsed or grouped data, and also over the full range of \ndiscrimination performance, namely from chance to perfect performance  (Donaldson, 1992; \nSee et al., 1997; Snodgrass & Corwin, 1988). Positive  versus negative  values of B\"D \ncorrespond to conservative versus  liberal responding, respectively, with B\"D = 0 indicating \nno response bias  and the maximum absolute value being 1.0 . B\"D differs from AUC in that it \nis computed for a single HR and FAR rather than being based on the whole ROC curve  with \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  17 \nmultiple points . However, as will become clear, it is possible to compute B\"D separately for \neach point on the ROC curve to assess response bias. It should be noted that non -\nparametric measures of discrimination and response bias, such as the AUC using the \ntrapezoidal rule and B\"D, have the clear advantage of not making strong assumption s about \nthe nature of the underlying evidence distributions , which may not be met. For example , d\u2032, \nwhich assumes  equal -variance Gaussian distributions , is not independent o f response bias if \nthe variances of the Gaussian evidence distributions  are not equal .  \nAims of the Present Paper  \nAs noted earlier, despite its usefulness for assessing the specificity of an \nintervention \u2019s effect , we are aware of only one paper that has analyzed data from gamified \nfake news interventions using ROC analysis ( Modirrousta -Galian et al., in press ). Indeed, in \nsome  prior research , there is seeming ly a lack of concern over the generality of the \nintervention\u2019s effect. For example, some researchers have reported that they collected \nparticipants\u2019 ratings  of true news items , but either excluded them from the main analysis \n(Maertens et al., 2021 ) or failed to  report them in their manuscripts at all  (Basol et al., 2020 ). \nConsequently , the aim of the current paper was to reanalyze data from published \npapers on gamified fake news interventions using  ROC analysis  to determine the specificity  \nof the effects . This paper is not intended to be a critique  of prior studies , and thus does not \ndiscuss  their potential  methodological problems  unless they are directly relevant to the \nreanalysis. The following  criteria had to be met for a study to be included in our reanalysis : \n(a) the study examined the effectiveness of a gamified fake news intervention;  (b) a scale \npertaining to new s veracity was included as a  dependent variable ; (c) rating s were collected \nfor both true and fake news items ; and ( d) the raw data from the study were  either  publicly \navailable  or made available by the authors .  \nWe conducted our literature search in March  2022. First, we searched Google \nScholar and ProQuest with the following search query: (\"fake news game\" OR \"fake news \nintervention\" OR \"misinformation game\" OR \"misinformation intervention\") AND (\"true news \nitems\" OR \"real news items\" OR \"fake news items\" OR \"false news items\") , which  revealed \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  18 \n37 potentially eligible studies . We examined the titles , abstracts , and results of these 3 7 \npapers and found that five met our inclusion criteria (Basol et al., 2020; Basol et al., 2021; \nMaertens et al., 2021; Roozenbeek et al., 2020; Roozenbeek & van der Linden, 2019). We \nthen manually searched the reference  lists in  these five studies and found another  \npotentially eligible paper (Saleh et al., 2021). Finally , we searched Google with the following \nsearch quer y: \"fake news game\"  and found  three more  potenti ally eligible studies (Grace & \nHone, 2019; Micallef et al., 2021; Urban et al., 2019). However, after examining  the titles, \nabstracts, and results of these four additional papers , we found  that they did not meet our \ninclusion criteria. Therefore, out of 41 potential papers , five were selected .  \nSome of t hese five papers reported  several experiments , and in some cases, it was \nnot possible to reanalyze  data from every experiment. Details about which experiments  were \nincluded or excluded from each of the five studies are provided  in more detail later  when  we \ndescribe the specifics  of each reanalysis.  The five suitable papers all used the games Bad \nNews or Go Viral! . Both fake news games are considered prebunking interventions as they \naim to pre -emptively protect people against online misinformation by exposing them to the \ncommon techniques used in its production.  These interventions have received much  \nattention both in the academic literat ure and beyon d. Bad News alone has been played over \na million times and  Go Viral! is supported by the UK Cabinet Office, the World Health \nOrganization, and the United Nations. Furthermore, both interventions have been reported \non by various mainstream media outlets, such as the BBC and CNN, and their popularity \nhas led to the current (as of December  2022) versions of Bad News and Go Viral! being \nplayable in 19 and 13 different languages, respectively. Considering the impact of these \ngames and the fact that all our reanalyses  are based on  them,  we will now describe them in \nsome detail.  \nBad News and Go Viral!  \nBad News  has players adopt the role of a fake news creator whose aim is to gather \nas many followers as possible whilst also maintaining credibility. To do this, players use six \ndifferent strategies to create online misinformation, namely , impersonating people, emotional \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  19 \nlanguage, group polari zation, conspiracy theories, discrediting opponents, and trolling. After \nusing each strategy, players receive a fake news badge, which essentially serves as a \nprogression milestone. Players can choose between different options in the game. Most \nimportantly,  they can choose from several  different fake news stories to share. Players must  \npay attention to their follower and credibility meters, which are contingent on their choices. If \nthe credibility meter drops to zero, the game ends and  the player loses. However, if the \ncredibility meter remains above zero and players use all six strategies to create online \nmisinformation, the game ends and the player wins, and the total number of followers they \ngathered counts as their final score.  \nThe gameplay of Go Viral!  is almost identical to that of Bad News . The main \ngameplay differences between them are the following: (a) the follower meter in Bad News  is \nreplaced with a \u201clikes\u201d meter in Go Viral! ; (b) three different strategies are used to create \nonline misinformation in Go Viral! , namely fearmongering, using fake experts, and \nconspiracy theories, instead of the six used in Bad News ; (c) unlike Bad News , players do \nnot receive fake news badges in Go Viral! ; and (d) Bad News  presents players wi th general \nonline misinformation, whereas Go Viral!  only presents players with COVID -19-related online \nmisinformation. Due to these gameplay differences, particularly the disparity in the number \nof strategies and the inclusion versus exclusion of fake news badges, Bad News  takes about \n15 minutes to complete, while Go Viral!  takes about 5 minutes.  \nTo determine the effectiveness of Bad News  and Go Viral! , prior research has used \npre-post designs in which participants rated true and fake news items before and after \nplaying either Bad News  (Basol et al., 2020; Maertens et al., 2021; Roozenbeek et al., 2020; \nRoozenbeek & van der Linden, 2019) or Go Viral!  (Basol et al., 2021). All but one  of these \nstudies also included a control group that completed ratings before and after either playing \nTetris , which is  not designed  to improve detection of fake news , or not playing anything at \nall. Studies investigating the effectiveness of Bad News  used a 7 -point scale ranging from 1 \n(not at all reliable ) to 7 ( very reliable ), while the study investigating the effectiveness of Go \nViral!  used a 7 -point scale ranging from 1 ( not at all manipulative ) to 7 ( very manipulative ). \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  20 \nNotably, we will use mean ratings as an umbrella term to refer to both mean reliability ratings \nand mean manipulativeness ratings throughout this paper.  \nMean ratings for fake news items were compared between pre -tests and post -tests, \nas were mean ratings for true news items in most studies. The results from most of this prior \nwork showed that Bad News  and Go Viral!  reduced people\u2019s belief in fake news, but also \nsometimes in true news, albeit to a lesser degree. This raises the concern that the effects of \nBad News  and Go Viral!  might be  overly general, affecting responding to all news items \nregardless of their objective veracity. However, Basol et al. (2021)  concluded that these  \ntypes of gamified psychological interventions are effective in helping people detect and \ndiscount fake news, and although they also sometimes reduce belief in true news, the \nvariability and small size of this effect suggests that this may be due to item ef fects rather \nthan general skepticism.  \nOverview of the Reanalyses  \nAs noted earlier, w e reanalyzed the results from five different studies, four of which \ninvestigated the effectiveness of Bad News  (Basol et al., 2020; Maertens et al., 202 1; \nRoozenbeek et al., 2020; Roozenbeek & van der Linden, 2019) and one of which \ninvestigated the effectiveness of Go Viral!  (Basol et al. , 2021). To do this, we used ROC \nanalysis to assess discrimination free from response bias and thus determine whether the \nfindings from these previous experiments were due to improvements in the ability to \ndiscriminate betw een true and fake news (i.e., the intervention had an effect specific to belief \nin fake news) , shifts in response bias (i.e., the intervention had a general effect on belief in \nall types of news) , or both .  \nIn each reanalysis , we created ROC curves for different tests (i.e., pre -tests and \npost-tests) and experimental conditions (i.e., treatment conditions and control conditions)  \naggregated  over participants . For stat istical analysis, t he trapezoidal rule was used to \ncalculate the AUC for each participant, and the B\"D was calculated at each scale point \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  21 \n(except for 1)4 for each participant, resulting in six B\"D values per participant.5 The B\"D \nvalues were then collapsed across all scale points for each participant to result in one \naverage B\"D value per participant. ANOVAs and t-tests were carried out to compare \nparticipants\u2019 AUC and B\"D values between tests (i.e., pre -tests and post -tests). Furthermore, \nthe Bayes factor was calculated for these analyses and interpreted through the discrete \nevidence categories proposed by Jeffreys (1961) and their corresponding interpretations \nadapted by Lee and Wagenmakers (2013; see Table 1). \n \nTable 1 \nBayes Factor Evidence Categories According to Jeffreys (1961) and Their Corresponding \nInterpretations Adapted by Lee and Wagenmakers (2013)  \nBF10 Interpretation  \n>100  Extreme evidence for H1  \n30\u2013100 Very strong evidence for H1  \n10\u201330 Strong evidence for H1  \n3\u201310 Moderate evidence for H1  \n1\u20133 Anecdotal evidence for H1  \n1 No evidence  \n1/3\u20131 Anecdotal evidence for H0  \n1/10\u20131/3 Moderate evidence for H0  \n1/30\u20131/10 Strong evidence for H0  \n1/100 \u20131/30 Very strong evidence for H0  \n<1/100  Extreme evidence for H0  \nNote . BF10 quantifies the empirical evidence in favor of the alternative hypothesis . \n \n \n4 The B\"D was not calculated at scale point 1 because both the HR and FAR are necessarily equal to 1.0 due to \nthe nature of the task (i.e., all items are assigned 1 or higher). Hence, it provides no meaningful information.  \n \n5 When participants have a HR of 1 and a FAR of 0, the formula for B\"D results in 0/0, which is undefined. \nTherefore, we applied a loglinear correction when calculating the HRs and FARs (only for calculating B\"D) by \nadding 0.5 to both the number of hits and false alarms and adding 1 to both the number of signal (true news) and \nnoise (fake news) trials  (Stanislaw & Todorov, 1999) . \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  22 \nOverview  of the Results  \n A summary of the results are shown  in Table 2.  \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  23 \nTable 2  \nSummary of the Results  \nStudy  n AUC analysis  B\"D analysis  \nMpretest Mposttest  p d BF10 Mpretest Mposttest  p d BF10 \nRoozenbeek and van der \nLinden (2019)  13,564  .88 .91 < .001  0.17 1.73\u00d710122 -.09 .04 < .001  0.40 1.34\u00d710486 \nBasol et al. (2020), Treatment \nCondition  96 .73 .75 .359 0.09 0.17 .07 .24 < .001  0.47 48,915.96  \nBasol et al. (2020), Control \nCondition  102 .70 .71 .543 0.05 0.13 .03 .07 .090 0.12 0.45 \nRoozenbeek et al. (2020), Set \nA\u2013A, Experiment 1  480 .75 .78 .074 0.16 0.48 .21 .36 < .001  0.39 764.51  \nRoozenbeek et al. (2020), Set \nB\u2013B, Experiment 1  480 .83 .84 .452 0.07 0.13 .14 .17 .426 0.07 0.14 \nRoozenbeek et al. (2020), \nControl Condition, Experiment 2  760 .80 .79 .037 -0.07 0.36 .06 .08 .094 0.05 0.16 \nMaertens et al. (2021), \nTreatment Condition, \nExperiment 1  58 .88 .88 .943 0.12 0.01 -.16 .14 < .001  1.40 5.32\u00d71015 \nMaertens et al. (2021), Control \nCondition, Experiment 1  60 .87 .86 .534 -0.20 0.03 -.21 -.14 .002 0.55 7.81 \nMaertens et al. (2021), \nTreatment Condition, \nExperiment 2  54 .74 .77 .482 0.20 0.12 .05 .20 < .001  0.87 289.85  \nMaertens et al. (2021), Control \nCondition, Experiment 2  56 .71 .71 .909 0.08 0.06 -.01 .03 .541 0.20 0.10 \nBasol et al. (2021), Study 1  1,771  .89 .90 .003 0.06 2.48 .03 .13 < .001  0.27 3.07\u00d71037 \nBasol et al. (2021), Active \nCondition, Study 2  151 .86 .89 < .001  0.59 4982.90  .05 .21 < .001  0.84 213,083,135  \nBasol et al. (2021), Control \nCondition, Study 2  235 .84 .86 < .001  0.46 865.87  .08 .11 .111 0.19 0.13 \nNote . For Maertens et al. (2021) and Basol et al.\u2019s (2021) Study 2, d was converted from \u03b72 on https://www.psychometrica.de/effect_size.html . Mposttest  is the \naverage AUC and B\"D across all post -tests.\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  24 \nReanalysis of Bad News  \nTransparency and Openness  \n The data and  analytic code needed to replicate th ese reanalys es are available on the \nOpen Science Framework:  https://osf.io/85be7/ . We obtained ethical approval  to conduct \nthis research  from the  University of Southampton Faculty of Environmental and Life \nSciences  Ethics Committee  (77386). This study was not preregistered.  \nRoozenbeek and van der Linden (2019)  \n The aim of Roozenbeek and van der Linden\u2019s (2019) study was to investigate the \neffect of Bad News  on people\u2019s ability to identify misinformation. To test this, they embedded \na voluntary pre -post survey in the game that asked players who opted in to rate the reliability \nof the same five news items before and after playing Bad News . Reliability ratings were \nmade on a scale that ranged from 1 ( not at all reliable ) to 7 ( very reliable ), and the five news \nitems were presented in the form of Twitter posts and new s headlines. Three of these news \nitems were created by the researchers and contained false information, and two were \nobtained from global news events and contained true information. The three fake news items \nreflected three out of the six misinformation te chniques presented in Bad News  (one \ntechnique per item), namely impersonating people, floating conspiracy theories, and \ndiscrediting opponents.  \n Roozenbeek and van der Linden (2019) hypothesized  that participants would rate the \nfake news items, but not the real news items, as less reliable after playing Bad News  \ncompared to before. To test this hypothesis, differences in mean reliability ratings between \nthe pre -test and the post -test were analyzed for each of the five news items. The results \nshowed that although the pre -post differences were statistically signifi cant for all items, the \neffect sizes for the true news items were almost negligible (i.e., d \u2264 0.04), whereas the effect \nsizes for the fa ke news items were much greater (i.e., d \u2265 0.30). Given the large sample size \n(14,163 \u201314,266 depending on the news item), Roozenbeek and van der Linden concluded \nthat there were meaningful pre -post differences for the fake news items but not for the real \nnews items, which supported their hypothe sis.  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  25 \n It should be noted that Roozenbeek and van der Linden\u2019s (2019) study involved two \nseparate data collection stages: The first is described above, and the second gathered and \nanalyzed pre -post data for an additional fake news item. This item was also create d by the \nresearchers and presented in the form of a news headline, but it reflected a different \nmisinformation technique, namely , polarizing opponents. A different, much smaller set of \nparticipants took part in the second data collection stage (8 85) compar ed to the first data \ncollection stage (14,163 \u201314,266). The second data collection stage only gathered pre -post \ndata for one fake news item  and no true news items. Omitting the true news items made it \nimpossible to compute  HRs, and consequently AUC and B\"D values . Therefore,  we limited \nour reanalysis to the initial data collection stage and to participants who had completed the \npre-test and the post -test for all five news items. This resulted in a sample of 13,564 \nparticipants for our reanalysis.  \nResults  \nThe ROC curves for the pre -test and the post -test are shown in Figure 4. A paired \nsamples t-test revealed that although the AUC  values  for the pre -test ( M = .88, SD = .19) \nwere significantly smaller than the AUC values for the post -test ( M = .91, SD = .17), the \neffect size was almost negligible, t(13,563) = 24.18, p < .001, d = 0.17 , 95% CI [0.16 , 0.18 ]. \nHowever, the Bayes factor indicated extreme evidence in favor of the alternative hypothesis, \nBF10 = 1.73 \u00d710122. Although the HRs remained mostly equal across the pre -test and the \npost-test, the FARs decreased (see Table S1). A paired samples t-test revealed that the B\"D \nvalues for the pre -test ( M = -.09, SD = .55) were significantly smaller than the B\"D values for \nthe post -test ( M = .04, SD = .51), t(13,563) = 49.45, p < .001, d = 0.40 , 95% CI [0.38 , 0.41 ] \n(see Table S2), and the Bayes factor indicated extreme evidence in favor of the alternative \nhypothesis, BF10 = 1.34 \u00d710486. \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  26 \nFigure 4  \nROC Curves for the Pre -Test and Post -Test in Roozenbeek and van der Linden (2019)  \n \nNote . ROC = Receiver operating characteristic.  \n \nDiscussion  \n In summary, Bad News improved participants\u2019 news veracity discernment, although \nthe effect size was almost negligible. Specifically, the FAR for fake news decreased, \nwhereas the HR for true news was unaffected, a result that is consistent with larger pre -post \ndifferences in reliability ratings for the fake news items compared to the true news items \nreported  in Roozenbeek and van der Linden (2019). This pattern of responding resulted in \n0.0 0.2 0.4 0.6 0.8 1.00.0 0.2 0.4 0.6 0.8 1.0\nFalse Alar m RateHit Rate\nPretest\nPosttest\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  27 \nhigher B\"D values because the overall proportion of responses exceeding the upper criteria \n(i.e., those associated with scale values greater than 1) decreased (cf. Tables S1 and S2).  \nOn the surface, this outcome suggests that Bad News is a mildly effective \nintervention that targets belief in fake news while having no effect on true news. However, \nbefore accepting this interpretation out of hand, it is worth taking a closer look at the items \nthat were used in this study. Specifically, the two true news items were evidently reliable, \nhaving been reported extensively in t he mainstream media ( i.e., \u201cPresident Trump wants to \nbuild a wall between the United States and Mexico\u201d  and \u201c #Brexit, the United Kingdom\u2019s exit \nfrom the European Union, will officially happen in 2019 \u201d). This obvious reliability explains \nwhy the mean pre-test reliability rating across the two true news items was 6.10, which is \nalmost at the upper limit of the scale (i.e., 7). In contrast, the fake news items were \nambiguous, having been created by the researchers (e.g., \u201cThe 8th season of \n#GameOfThrones will be postponed due to a salary dispute\u201d). This ambiguity resulted in an \naverage pre -test reliability rating across the three fake news items of 2.61, which is \ncomparatively closer to the mid -point of the scale (i.e., 4).  \n It is unlikely that any psychological intervention would impact belief in true news \nitems that are near the ceiling of the reliability scale because they have been reported \nextensively in the mainstream media. Participants\u2019 memories of those reports would  likely \nimmunize their ratings to any sort of change. Hence, it may be premature to conclude that \nBad News  is inherently an intervention that targets only fake news. It is equally plausible that \nits effects are general, but the particular true news items u sed in this study masked this \ngenerality. Fortunately, other research investigating the efficacy of Bad News  has used true \nnews items that are less obviously true and more comparable to the fake news items , \nallow ing for some level of uncertainty. This research provides a better test of the specificity  \nof Bad News \u2019 effects , and we turn to that research next.   \nBasol et al. (2020)  \n The purpose of Basol et al.\u2019s (2020) study was to replicate the findings reported in \nRoozenbeek and van der Linden (2019) with a more robust experimental design. \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  28 \nSpecifically, they added a randomized control condition in which participants played Tetris \ninstead of Bad News. Additionally, they used a larger set of news items to test participants\u2019 \nability to spot misinformation. Both conditions included a pre -test an d a post -test that asked \nparticipants to rate the reliability of the same 21 news items before and after playing either \nTetris or Bad News. Reliability ratings were made on a scale that ranged from 1 ( not at all \nreliable ) to 7 ( very reliable ), and all news items were presented in the form of Twitter posts. \nEighteen of these news items were created by the researchers and contained false \ninformation, and three were obtained from global news events and contained true \ninformation. There were three fake new s items corresponding to each of the six \nmisinformation techniques presented in Bad News.  \n To assess the effectiveness of Bad News, differences in mean reliability ratings \nbetween the pre -test and the post -test were analyzed for the 18 fake news items and \ncompared between conditions. For reasons that are not entirely clear, the three true news \nitems were not mentioned nor analyzed in the ir paper. The results showed that, compared to \nparticipants in the control condition, those in the treatment condition demonstrated a greater \ndecrease in reliability ratings to fake news items from the pre -test t o the post -test. \nConsequently, Basol et al. (2020) concluded that Bad News improved participants\u2019 ability to \nspot misinformation  and that their data \u201cdemonstrated the efficacy of a \u2018broad -spectrum\u2019 \ninoculation against misinformation \u201d (p. 5) .  \nBasol et al. (2020) also collected data on how confident participants were in their \nreliability ratings. We did not reanalyze those data  because o ur aim was to determine the \neffectiveness of gamified inoculation  interventions for improving news veracity discernment, \nand reliability ratings on their own serve this purpose. Furthermore,  although Basol et al. \nexcluded the true news items from their analysis of mean ratings, it was necessary for us to \ninclude both true and fake news items in our reanalysis to a ssess discernment  and response \nbias. Overall, Basol et al.\u2019s full sample of 19 8 participants (102 from the control condition \nand 96 from the treatment condition) was used for our reanalysis.  \nResults  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  29 \n Treatment Condition.  The ROC curves for the pre -test and the post -test in the \ntreatment condition are shown in Figure 5. A paired samples t-test revealed that the AUC \nvalues for the pre -test ( M = .73, SD = .18) were not significantly different from the AUC \nvalues for the post -test ( M = .75, SD = .20), t(95) = 0.92, p = .359,  d = 0.09, 95% CI [ -0.11, \n0.29], and the Bayes factor indicated moderate evidence for the null hypothesis, BF10 = 0.17. \nBoth the HRs and the FARs decreased between the pre -test and the post -test (see Table \nS3). A paired samples t-test revealed that the B\"D values for the pre -test ( M = .07, SD = .78) \nwere significantly smaller than the B\"D values for the post -test ( M = .24, SD = .78), t(95) = \n5.54, p < .001, d = 0.47 , 95% CI [ 0.29, 0.64]  (see Table S4), and the Bayes factor indicated \nextreme evidence in favor of the alternative hypothesis, BF10 = 48,915.96.  \n \nFigure 5  \nROC Curves for the Pre -Test and Post -Test in Basol et al.\u2019s (2020) Treatment Condition and Control \nCondition  \n \nNote . ROC =  Receiver operating characteristic.  \n  \n Control Condition. The ROC curves for the pre -test and the post -test in the control \ncondition are shown in Figure 5. A paired samples t-test revealed that the AUC values for \nthe pre -test ( M = .70, SD = .18) were not significantly different from the AUC values for the \n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Treatment Condition\nFalse Alar m RateHit Rate\nPretest\nPosttest\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Contr ol Condition\nFalse Alar m RateHit Rate\nPretest\nPosttest\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  30 \npost-test ( M = .71, SD = .19), t(101) = 0.61, p = .543, d = 0.05, 95% CI [ -0.11, 0.21], and the \nBayes factor indicated moderate evidence for the null hypothesis, BF10 = 0.13. Both the HRs \nand the FARs only slightly decreased between the pre -test and the post -test (see Table S5). \nA paired samples t-test revealed that the B\"D values for the pre -test ( M = .03, SD = .77) \nwere not significantly different from the B\"D values for the post -test ( M = .07, SD = .79), \nt(101) = 1.71, p = .090 , d = 0.12, 95% CI [ -0.02, 0.27] (see Table S6). The Bayes factor \nindicated anecdotal evidence for the null hypothe sis, BF10 = 0.45.  \nDiscussion  \n In summary, neither Bad News nor Tetris improved participants\u2019 news veracity \ndiscernment. These results stand in contrast to those of our previous reanalysis of \nRoozenbeek and van der Linden \u2019s (2019)  data in which discernment was better after playing \nBad News  compared to before. We hypothesized that the improved discernment in the \nprevious reanalysis may have been an artifact of using true news items that were obviously \ntrue. Indeed, several factors point to this factor being critical. First ly, compared to \nRoozenbeek and van der Linden (2019), the shape of the ROC curve was notably less \nbowed in Basol et al. (2020), and the AUC values were considerably smaller (AUC in \nRoozenbeek and van der Linden\u2019s data: . 88\u2013.90; AUC in Basol et al.\u2019s data: .70 \u2013.75). \nMoreover, this difference in AUC was primarily due to much lower HRs to true news items in \nBasol et al.\u2019s data. Most notably, the HR associated with scale value 7 in Roozenbeek and \nvan der Linden\u2019s data was .60, whereas it was only .09 \u2013.12 in Basol et al.\u2019s  study . In other \nwords, participants assigned the most extreme reliability rating to the true news items 60% \nof the time in Roozenbeek and van der Linden\u2019s study, whereas this type of responding only \noccurred about 10% of the time in Basol et al.\u2019s study \u2013 a sixfold difference. A closer look at \nthe items used in Basol et al.\u2019s study reveals why this occurred: Unlike the items used in \nRoozenbeek and van der Linden\u2019s study, the true and fake items were similarly obscure \n(e.g., \u201cSuper Bowl overnight TV ratings hit 10 -year low\u201d [true], \u201cThe 8th season of \n#GameOfThrones will be postponed due to a salary dispute\u201d [fake]). Consistent with this \nobservation, the overall average pre -test reliability rating collapsed acros s the two conditions \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  31 \nwas 4.5 7 for the three true news items and 3.23 across the 18 fake news items, neither of \nwhich are close to the lower or upper limit of the scale (i.e., 1 or 7).  \nWhile  this reanalysis showed that Bad News  did not improve discernment, it did \ninfluence response bias. That is, the B\"D analysis showed that after playing Bad News  (but \nnot Tetris) , participants rated both true and fake news items as less reliable . Basol et al. , by \ncontrast,  did not report any analyses of the true news items , and only reported that playing \nBad News  resulted in  a greater decrease in reliability ratings to fake news items than playing \nTetris . These findings are consistent with the response bias effect we report here. However, \nbecause true news items were omitted from their analyses, this difference in response bias \nwas misinterpreted to be \u201cclear evidence in support of the intervention\u201d (Baso l et al., 2020, p. \n5), a conclusion that we do not believe is supported  by their data.  \nRoozenbeek et al. (2020)  \n The goal of Roozenbeek et al.\u2019s (2020) study was to address two methodological \nissues associated with using pre -post designs to assess the effectiveness of Bad News. The \nfirst issue pertains to item effects, which can result from presenting the same items  in the \npre-test and the post -test, as this raises the concern that any observed effects are specific to \nthose particular items. The second issue pertains to testing effects, which can result from the \nimplementation of a pre -test, as prior experience with the testing procedure could be a \ncause of any observed effects . Roozenbeek et al. conducted Experiment 1 to examine item \neffects and Experiment 2 to examine testing effects. For both experiments, a voluntary pre -\npost survey was embedded in Bad News that asked players who opted in to rate the \nreliability of news items on a scale that ranged from 1 ( not at all reliable ) to 7 ( very reliable ).  \n In Experiment 1, two different sets of news items labelled Set A and Set B were \nused. Both sets contained a total of eight news items that were presented in the form of \nTwitter posts. Six of these news items were created by the researchers and contained f alse \ninformation, and two were obtained from global news events and contained true information. \nThere was one fake news item for each misinformation technique presented in Bad News. \nParticipants were randomly assigned to one of two conditions: A \u2013B, where p articipants were \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  32 \npresented with Set A in the pre -test and Set B in the post -test, and B \u2013A, where participants \nwere presented with Set B in the pre -test and Set A in the post -test. To test for item effects, \nthe four different sets of pre-post differences shown in Figure 6 were analyzed .  \n \nFigure 6 \nDesign of Roozenbeek et al.\u2019s (2020) Experiment 1 and the Pre-Post Differences  of Interest   \n \nNote . The pre-post differences  of interest are indicated by the red arrows. Adapted from \n\u201cDisentangling Item and Testing Effects in Inoculation Research on Online Misinformation: Solomon \nRevisited\u201d, by J. Roozenbeek, R. Maertens, W. McClanahan, S. van der Linden, 2020, Educational \nand Psychological Measurement , 81(2), pp. 340 \u2013362 \n(https://doi.org/10.1177%2F0013164420940378 ).  \n \n \n Roozenbeek et al.  (2020)  argued that item effects would be indicated through \nsignificant disparities in pre -post differences between either  Set A \u2013A and Set B \u2013B, or Set A \u2013\nB and Set B \u2013A. The results showed that  pre-post differences were significant for Set A \u2013A \nbut not Set B \u2013B. Furthermore, although pre -post differences were  significant for both Set A\u2013\nB and Set B\u2013A, after using standardized tests (i.e., the same tests but on z -scores based on \nthe means and standard deviations of the pre -test scores for each item set ) to account for \nPre-test \n(Set A ) \nInoculation  \n(Bad News)  \nPost-test \n(Set B ) \nPre-test \n(Set B ) \nInoculation  \n(Bad News)  \nPost-test \n(Set A ) \nGroup 1  \nCondition: A \u2013B \nGroup 2 \nCondition: B\u2013A \nSet A \u2013B \nSet B \u2013A \n\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  33 \nthe different items being used in the pre -test and the post -test, the pre -post differences for \nSet A \u2013B were no longer significant, whereas the pre -post differences for Set B \u2013A remained \nsignificant.  Overall, these findings suggested that there were indeed item effects.  \n In Experiment 2, participants were randomly assigned to one of three conditions: (a) \npre-post, where participants first completed a pre -test, then played Bad News, and then \ncompleted a post -test; (b) control, where participants first completed  a pre -test, then did a \nfiller task ( demographic questions ), and then completed  a post -test; and (c) post only, where \nparticipants first played Bad News and then completed  a post -test. Although Set B was used \nfor the control condition, a combination of Set A and Set B  items was used for the post only \nand pre -post conditions. This combination still amounted to two real news items and six fake \nnews items that reflected the six misinformation techniques presented in Bad News  (one \ntechnique per item).  Roozenbeek et al. (2020) argued that testing effects would be indicated \nby significant pre -post differences in the control condition, and a significant difference \nbetween post -test scores in the pre -post and post only conditions  (see Figure 7). The results \nsuggested that there  were no testing effects since these differences were not significant.  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  34 \nFigure 7 \nDesign of Roozenbeek et al.\u2019s (2020) Experiment 2 and the Differences  of Interest   \n \nNote . The differences of interest are indicated by the red arrows. Adapted from \u201c Disentangling Item \nand Testing Effects in Inoculation Research on Online Misinformation: Solomon Revisited\u201d, by J. \nRoozenbeek, R. Maertens, W. McClanahan, S. van der Linden, 2020, Educational and Psychological \nMeasurement , 81(2), pp. 340 \u2013362 (https://doi.org/10.1177%2F0013164420940378 ).  \n \n Due to the item effects demonstrated in Roozenbeek et al.\u2019s (2020) study, we limited \nour reanalysis to pre -post differences between equivalent item sets. Therefore, we \nreanalyzed : (a) Set A \u2013A in Experiment 1 ; (b) Set B \u2013B in Experiment 1; and (c) the control \ncondition in Experiment 2. Overall, data from 1240 participants (480 from both Set A \u2013A and \nSet B \u2013B, and 760 from the control condition) w ere used for our reanalysis.  \nResults  \n Experiment 1: Set A \u2013A. The ROC curves for the pre -test and the post -test from Set \nA\u2013A in Experiment 1 are shown in Figure 8. Despite the apparent separation of the ROC \ncurves, a Welch\u2019s  independent samples t-test revealed that the AUC values for the pre -test \n(M = .75, SD = .22) were not significantly different from the AUC values for the post -test ( M = \n.78, SD = .18), t(462.62) = 1.79, p = .074 , d = 0.16, 95% CI [ -0.02, 0.34]. The Bayes factor \nindicated anecdotal evidence for the null hypothesis, BF10 = 0.48. The FARs decreased \nbetween the pre -test and the post -test, and so did the HRs, albeit to a lesser degree (see \nPre-test \n(Combination of \nSet A & B)  \nInoculation  \n(Bad News)  \nPost-test \n(Combination of \nSet A & B)  \n \nPre-test \n(Set B ) \nFiller task \n(Demographic \nquestions)  \nGroup 1  \nPre-post condition  \nPost-test \n(Set B) \nGroup 2 \nControl condition  \nPost-test \n(Combination of \nSet A & B)  \n \nInoculation  \n(Bad News)  \n \nGroup 3 \nPost only condition  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  35 \nTable S7). A Welch\u2019s  independent samples t-test revealed that the B\"D values for the pre -\ntest ( M = .21, SD = .69) were significantly smaller than the B\"D values for the post -test ( M = \n.36, SD = .64), t(476.32) = 4.32, p < .001, d = 0.39 , 95% CI [ 0.21, 0.58]  (see Table S8), and \nthe Bayes factor indicated extreme evidence in favor of the alternative hypothesis, BF10 = \n764.51.  \n \nFigure 8 \nROC Curves for the Pre -Test and Post -Test in Roozenbeek et al.\u2019s (2020) Set A \u2013A and Set B \u2013B \nFrom Experiment 1  and Control Condition From Experiment 2  \n \nNote . ROC = Receiver operating characteristic.  \n \n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Set A\u2212A, Experiment 1\nFalse Alar m RateHit Rate\nPretest\nPosttest\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Set B\u2212B, Experiment 1\nFalse Alar m RateHit Rate\nPretest\nPosttest\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Contr ol Condition, Experiment 2\nFalse Alar m RateHit Rate\nPretest\nPosttest\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  36 \n Experiment 1: Set B \u2013B. The ROC curves for the pre -test and the post -test from Set \nB\u2013B in Experiment 1 are shown in Figure 8. A Welch\u2019s  independent samples t-test revealed \nthat the AUC values for the pre -test ( M = .83, SD = .18) were not significantly different from \nthe AUC values for the post -test ( M = .84, SD = .19), t(476.10) = 0.75, p = .452,  d = 0.07, \n95% CI [ -0.11, 0.25], and the Bayes factor indicated moderate evidence for the null \nhypothesis, BF10 = 0.13. The HRs remained mostly equal across the pre -test and the post -\ntest, while the FARs only slightly decreased (see Table S9). A Welch\u2019s  independent samples \nt-test revealed that the B\"D values for the pre -test ( M = .14, SD = .67) were not significantly \ndifferent from the B\"D values for the post -test ( M = .17, SD = .69), t(456.95) = 0.80, p = .426 , \nd = 0.07, 95% CI [ -0.11, 0.25] (see Table S10). The Bayes factor indicated moderate \nevidence in favor of the null hypothesis, BF10 = 0.14.  \n Experiment 2: Control Condition.  The ROC curves for the pre -test and the post -\ntest from the control condition in Experiment 2 are shown in Figure 8. A paired samples t-\ntest revealed that although the AUC values for the pre -test ( M = .80, SD = .20) were \nsignificantly greater than the AUC values for the post -test ( M = .79, SD = .21), the effect size \nwas almost negligible, t(759) = -2.09, p = .037, d = -0.07, 95% CI [ -0.13, -0.00] . The Bayes \nfactor indicated  anecdotal evidence for the null hypothesis, BF10 = 0.36. The HRs only \nslightly decreased across the pre -test and the post -test, while the FARs only slightly \nincreased (see Table S11). A paired samples t-test revealed that the B\"D values for the pre -\ntest ( M = .06, SD = .68) were not significantly different from the B\"D values for the post -test \n(M = .08, SD = .71), t(759) = 1.68, p = .094 , d = 0.0 5, 95% CI [ -0.01, 0.11] (see Table S12), \nand the Bayes factor indicated moderate evidence for the null hypothesis, BF10 = 0.16.  \nDiscussion  \n Overall, participants in the control condition in Experiment 2 , where the Bad News \nintervention was absent,  did not demonstrate a change in news veracity discernment or \nresponse bias from the pre -test to the post -test. When Bad News intervened between the \npre-test and post -test in Experiment 1, it did not improve participants\u2019 news veracity \ndiscernment in either Set A \u2013A or Set B \u2013B, but it did elicit a more conservative response bias \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  37 \nin Set A \u2013A. This is noteworthy since Set B \u2013B and the control condition used the same set of \nnews items to assess participants\u2019 reliability ratings (i.e., Set B), whereas Set A \u2013A used a \ndifferent set of news items (i.e., Set A). These results could potentially  be attributed to \ndifferences in ambiguity between the true versus fake news items used in each set, as those \nin Set A (AUC = .75 \u2013.78) were more ambiguous than those in Set B (AUC = .79 \u2013.84). \nIndeed, the mean reliability ratings support this conclusion.  Specifically, the mean pre -test \nreliability rating was 4.50 for the true news items and 2.73 for the fake news items in Set A \u2013\nA (difference = 1.77), whereas the respective mean pre -test ratings were 5.08 and 2.60 for \ntrue and fake news items in Set B \u2013B (difference = 2.48).  \n Thus, a nalogous to the reanalys is of Basol et al.\u2019s (2020) data,  when ambiguous \nnews items were used (i.e., Set A ), Bad News prompted more conservative responding  on \nthe post -test compared to the pre -test. Conversely, when the items were less ambiguous \nsuch that participants had strong opinions about  their objective veracity on the pre -test (i.e., \nSet B ), Bad News had little effect on response bias. More specifically , the B\"D analysis \nshowed that playing Bad News caused participants to become more conservative in their \nresponses to  news items in Set A \u2013A, but not in Set B \u2013B. Although both the HRs (true news) \nand FAR s (fake news)  were lower in the post -test than the pre -test for Set A , the decrease \nwas greater  for the FARs. This finding explains the significant pre -post differences in \nreliability ratings for the fake news items but not the true news items in Set A \u2013A reported by \nRoozenbeek et al. (2020). Furthermore, the fact that both playing Bad News  and doing \nnothing (control) had null effects on both news veracity discernment and response bias for \nSet B items is consistent with the non -significant pre -post differences in reliability ratings  in \nSet B \u2013B reported by Roozenbeek et al . Ultimately, our findings suggest that Bad News can \ncause  participants to respond more  conservative ly but does not improve discernment, and \nthat this shift to more conservative responding is more likely to occur when the news items \nused to assess reliability ratings are more ambiguous.  \nMaertens et al. (202 1) \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  38 \n Maertens et al. (202 1) conducted three experiments to investigate the long -term \neffectiveness of Bad News. In Experiments 1 and 2, participants were randomly allocated to \neither a control condition that play ed Tetris or a treatment condition that play ed Bad News. \nIn Experiment 3, all participants played Bad News. All three experiments included a pre -test \nand several post -tests that required participants to rate the reliability of news items on a \nscale ranging from 1 ( not at all reliable ) to 7 ( very reliable ). In Experiment 1, the pre -test \noccurred just before playing either Tetris or Bad News, and the post -tests were administered \nimmediately, 1 week, 5 weeks, and 13 weeks after the pre -test. In Experiments 2 and  3, the \npre-test and the first post -test followed the same scheduling as in Experiment 1, but there \nwas only one follow -up post -test. This follow -up post -test occurred 9 weeks after the pre -test \nin Experiment 2 and 1 week after the pre -test in Experiment 3 .  \n In Experiments 1 and 2, the news items did not vary between the pre -test and the \npost-tests. In both experiments, participants were presented with 21 news items in each test, \n18 of which were created by the researchers and contained false information, and  three of \nwhich were obtained from global news events and contained true information. The same 18 \nfake news items were used in Experiments 1 and 2, but two out of the three true news items \nwere different. There were three fake news items corresponding to e ach of the six \nmisinformation techniques presented in Bad News. In Experiment 3, the ratio of true to fake \nnews items was changed to 1:6 in the pre -test and the first post -test, and to 6:6 in the \nsecond post -test. The news items in the pre -test and the fir st post -test differed from the \nnews items in the second post -test. Nevertheless, every pre -test and post -test had one fake \nnews item for every misinformation technique . Furthermore,  the fake news items were \ncreated  by the researchers  while the true news it ems were obtained from global news \nevents  in the same way as in Experiments 1 and 2. In all three experiments, the news items \nwere presented in the form of news headlines. Critically, the true news items were excluded \nfrom the main analysis for all three experiments.  \n In Experiment 1, participants in the treatment condition demonstrated a significantly \ngreater decrease in mean fake news reliability ratings from the pre -test to all four post -tests \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  39 \nthan participants in the control condition. In Experiment 2, participants in the treatment \ncondition demonstrated a significantly greater decrease in fake news reliability ratings from \nthe pre -test to the first post -test, but not the second post -test, than participants in the control \ncondition. In Experiment 3, participants demonstrated a significant decrease in fake news \nreliability ratings from the pre -test to the two post -tests. The results of Experiment 1 \nindicated that Bad News improved people\u2019s abilit y to identify misinformation for up to 13 \nweeks after playing the game. However, the results of Experiment 2 revealed that this was \nmost likely due to repeat ed testing, and that the effect of Bad News decays and becomes \nnegligible after 9 weeks. Finally, the results of Experiment 3 ruled out the possibility that the \nfindings from Experiments 1 and 2 were due to the unbalanced ratio of true to fake news \nheadlines  and/or the presentation of the same news headlines in the pre -test and the post -\ntests.  \n In Experiment 3, only one true news item was used in the pre -test and the first post -\ntest compared to six in the follow -up post -test. In our view,  a single  true news item in the \npre-test and the first post -test would not allow for a representative  account of participants\u2019 \nbelief in true news. As a result, we limited our reanalysis to Experiments 1 and 2. \nFurthermore, although Maertens et al. (202 1) excluded the true news items from their main \nanalysis and only included the fake news items, it was necessary for us to include both types \nof news items in our reanalysis so that ROC curves could be constructed. Finally, we limited \nour reanalysis to part icipants who had completed the entire experiment. This resulted in a \nsample of 118 participants for Exp eriment 1 (58 from the treatment condition and 60 from \nthe control condition), and 110 for Experiment 2 (54 from the treatment condition and 56 \nfrom the control condition).  \nResults  \n Experiment 1: Treatment Condition.  The ROC curves for the pre -test and the  four \npost-tests from the treatment condition in Experiment 1 are shown in Figure 9. A one -way \nrepeated -measures ANOVA revealed that the main effect of test on AUC values was not \nsignificant, F(4, 228) = 0.19, p = .943, \u03b72 = .00, 95% CI [. 00, .01], and the Bayes factor \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  40 \nindicated very strong evidence for the null hypothesis, BF10 = 0.01. The means and standard \ndeviations of  the AUC values  are shown in Table S13. Both the HRs and the FARs \ndecreased between the pre -test and the four post -tests but varied only slightly between the \nfour post -tests (see Table S14). A one -way repeated -measures ANOVA revealed that the \nmain effect of test on B\"D values was significant, F(4, 228) = 27.70, p < .001, \u03b72 = .33 , 95% \nCI [.2 3, .41], and the Bayes factor indicated extreme evidence in favor of the alternative \nhypothesis, BF10 = 5.32 \u00d71015 (see Table S15). A post -hoc Tukey test showed that the pre -\ntest was significantly different from each of the four post -tests at p < .001, but none of the \nfour post -tests were significantly different from each other , smallest p = .059 . \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  41 \nFigure 9 \nROC Curves for the Pre -Test and Post -Tests in Maertens et al.\u2019s (202 1) Treatment  Condition  and \nControl Condition From Experiment 1 and Treatment  Condition  and Control Condition From \nExperiment 2  \n \nNote . ROC = Receiver operating characteristic. T = time. T1 = just before playing Bad News  or Tetris  \nin Experiments 1 and 2 . T2 = just after playing Bad News  or Tetris  in Experiments 1 and 2 . T3 = 1 \nweek after playing Bad News  or Tetris  in Experiment 1 and 9 weeks after playing Bad News or Tetris \nin Experiment 2 . T4 = 5 weeks after playing Bad News  or Tetris  in Experiment 1 . T5 = 13 weeks after \nplaying Bad News  or Tetris  in Experiment 1 . \n \nExperiment 1: Control Condition.  The ROC curves for the pre -test and the  four \npost-tests from the control condition in Experiment 1 are shown in Figure 9. A one -way \n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Treatment Condition, Experiment 1\nFalse Alar m RateHit Rate\nPretestT1\nPosttestT2\nPosttestT3\nPosttestT4\nPosttestT5\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Contr ol Condition, Experiment 1\nFalse Alar m RateHit Rate\nPretestT1\nPosttestT2\nPosttestT3\nPosttestT4\nPosttestT5\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Treatment Condition, Experiment 2\nFalse Alar m RateHit Rate\nPretestT1\nPosttestT2\nPosttestT3\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Contr ol Condition, Experiment 2\nFalse Alar m RateHit Rate\nPretestT1\nPosttestT2\nPosttestT3\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  42 \nrepeated measures ANOVA revealed that the main effect of test on AUC values was not \nsignificant, F(4, 236) = 0. 79, p = .534 , \u03b72 = .01, 95% CI [. 00, .04], and the Bayes factor \nindicated very strong evidence for the null hypothesis, BF10 = 0.03. The means and standard \ndeviations of the AUC values are shown in Table S16. Both the HRs and the FARs \ndecreased between the pre -test and the final post -test but varied only slightly between the \npre-test and the first three post -tests (see Table S17). A one -way repeated measures \nANOVA revealed that the main effect of test on B\"D values was significant, F(4, 236) = 4.25, \np = .002, \u03b72 = .07 , 95% CI [.0 1, .13], and the Bayes factor indicated moderate evidence in \nfavor of the alternative hypothesis, BF10 = 7.81  (see Table S18). A post -hoc Tukey test \nshowed that the pre -test was significantly different from the final post -test at p = .037, but \nnone of the other comparisons was significant , smallest p = .080. \nExperiment 2: Treatment Condition.  The ROC curves for the pre -test and the two \npost-tests from the treatment condition in Experiment 2 are shown in Figure 9. A one -way \nrepeated measures ANOVA revealed that the main effect of test on AUC values was not \nsignificant , F(2, 106) = 0.7 4, p = .482, \u03b72 = .01, 95% CI [.00, .0 7], and the Bayes factor \nindicated moderate evidence for the null hypothesis, BF10 = 0.1 2. The means and standard \ndeviations of the AUC values are shown in Table S19. Both the HRs and the FARs \ndecreased between the pre -test and the first post -test. The FARs also decreased between \nthe pre -test and the second post -test, but to a lesser degree than with the first post -test, \nwhereas the HRs remained static (see Table S20). A one -way repeated measures ANOVA \nrevealed that the mai n effect of test on B\"D values was significant, F(2, 106) = 10.45, p < \n.001, \u03b72 = .16 , 95% CI [ .05, .29], and the Bayes factor indicated extreme evidence in favor of \nthe alternative hypothesis, BF10 = 289.85  (see Table S21). A post -hoc Tukey test showed \nthat the pre -test was significantly different from the first post -test at p < .001, but none of the \nother comparisons was significant , smallest p = .060. \nExperiment 2: Control Condition.  The ROC curves for the pre -test and the  two \npost-tests from the control condition in Experiment 2 are shown in Figure 9. A one -way \nrepeated measures ANOVA revealed that the main effect of test on AUC values was not \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  43 \nsignificant , F(2, 110) = 0. 10, p = .909, \u03b72 = .00, 95% CI [.00, .0 2], and the Bayes factor \nindicated very strong evidence for the null hypothesis,  BF10 = 0.06. The means and standard \ndeviations of the AUC values are shown in Table S22. Both the HRs and the FARs only \nslightly decreased between the pre -test and the two post -tests (see Table S23). A one -way \nrepeated measures ANOVA revealed that the main effect of test on B\"D values was not \nsignificant, F(2, 110) = 0. 62, p = .541, \u03b72 = .01, 95% CI [.00, .0 7] (see Table S24), and the \nBayes factor indicated moderate evidence in favor of the null hypothesis, BF10 = 0.10.  \nDiscussion  \n In summary, neither Bad News nor Tetris improved participants\u2019 news veracity \ndiscernment in either Experiment 1 or 2. In Experiment 1, Bad News elicited more \nconservative respon ding immediately after playing, as well as 1, 5, and 13 weeks later, and \nTetris elicited more conservative responding  13 weeks after playing. In Experiment 2, Bad \nNews elicited more conservative respon ding immediately after playing but not 9 weeks later, \nwhereas Tetris  did not elicit more conservative responding  at all. Although the  results from \nExperiment 1 showed that both Bad News and Tetris  caused participants to respond more \nconservatively , they were confounded by the effects of repeat ed testing. However, this \nconfound had equal influence on the treatment condition and the control condition, and Bad \nNews caused an increase in conservative responding  at each post -test, while Tetris only \ncaused an increase in conservative responding  at one post -test. Therefore, even if both \ngames caused more conservative responding , the one produced by Bad News was more \nconsistent in Experiment 1. Moreover, Experiment 2 was not confounded by the effects of \nrepeat ed testing, and it showed that Bad News increased conservative responding , whereas \nTetris  did not.  \n Although Maertens et al. (2021) excluded the true news items from the main \nanalysis, our reanalysis allows us to add nuance to their results . In Experiment 1, Bad News \nincreased conservative responding at all four post -tests, while Tetris  only did so at the final \npost-test. This explains the significantly greater decrease in reliability ratings from the pre -\ntest to all four post -tests in the treatment condition compared to the control condition. In \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  44 \nExperiment 2, Bad News increased conservative responding at the first post -test but not the \nsecond, while Tetris did not do so at all. This explains the significantly greater decrease in \nmean reliability ratings from the pre -test to the first post -test in the treatment condition \ncompared to the control condition, as well as the non -significant difference in reliability \nratings from the pre -test to the second post -test in both conditions. Ultima tely, our findings \nsuggest that Bad News can cause more conserva tive responding  but not an improvement in \ndiscernment, and that this change to response bias disappears over time unless participants \nundergo repeat ed testing.   \nReanalysis of Go Viral!  \nBasol et al. (2021)  \n The aim of Basol et al.\u2019s (2021) paper was to investigate the effectiveness of Go \nViral! and a series of infographics on people\u2019s ability to identify COVID -19 misinformation. \nFor this purpose, they conducted two different studies. In Study 1, a voluntary pre -post \nsurvey was embedded in Go Viral! that asked players who opted in to rate the \nmanipulativeness of the same six news items before and after playing the game. \nManipulativeness ratings were made on a scale th at ranged from 1 ( not at all manipulative ) \nto 7 ( very manipulative ), and the six news items were presented in the form of Twitter posts. \nHalf of these news items were obtained from fact -checking websites and contained false \ninformation, and the other half were obtained from the Twitter accounts of reputable news \nsources and contained true information. The three fake news items reflected the three \nmisinformation techniques presented in Go Viral!  (one technique per item) . Source \ninformation was omitted from each news item to prevent participants from only using this \nfeature to spot misinformation.  \n To test whether Go Viral! improved participants\u2019 ability to spot misinformation, \ndifferences in mean manipulativeness ratings between the pre -test and the post -test were \nanalyzed for the six news items. The results showed that participants rated the fake news \nitems as significantly more manipulative in the post -test compared to the pre -test, but there \nwere no significant pre -post differences for the true news items. To test whether Go Viral! \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  45 \nimproved participants\u2019 news veracity discernment, differences in mean manipulativeness \nratings between the true and fake news items were compared in the pre -test and the post -\ntest. The results showed that this difference was significantly larger in the post -test \ncompared to the pre -test. Overall, Basol et al. (2021) conclude d that Go Viral! improved \npeople\u2019s ability to spot misinformation as well as their ability to distinguish between true and \nfake news.  \n In Study 2, participants were randomly assigned to one of three conditions: (a) \ncontrol, where participants played Tetris; (b) passive, where participants were shown a \nseries of infographics; and (c) active, where participants played Go Viral!. All condit ions \nincluded a pre -test and a post -test that asked participants to rate the manipulativeness of the \nsame 18 news items before and after experiencing either Tetris, Go Viral! , or infographics. \nManipulativeness ratings were made on the same scale as in Stud y 1. Furthermore, the 18 \nnews items were collected and presented in the same way, had the same 1:1 ratio of true to \nfake news items, and incorporated the same misinformation techniques as in Study 1. Study \n2 was conducted in English, German, and French, an d participants who completed the study \nin English were asked to take part in a follow -up test 1 week after the initial test date. This \nfollow -up test required participants to rate the manipulativeness of 12 different news items , \nhalf of which were true and  half of which were fake .  \n To test whether Go Viral! or the infographics improved participants\u2019 ability to spot \nmisinformation, differences in mean manipulativeness ratings between the pre -test and the \npost-test were analyzed for the 18 news items and compared between conditions. T he \nresults showed that participants in the active and passive conditions rated the fake news \nitems as more manipulative than participants in the control condition. However, participants \nin the active condition also rated the true news items as more manipul ative than participants \nin the passive and control conditions. To test whether the effects of Go Viral! or the \ninfographics decayed over time, the mean manipulativeness ratings for the 12 news items in \nthe 1 -week follow -up test were compared between condit ions. The results showed that \nparticipants in the active condition rated the fake news items as more manipulative than \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  46 \nparticipants in the passive and control conditions, but there were no significant differences \nbetween conditions for the true news items.  \n Overall, Basol et al. (2021) concluded that Go Viral! and the infographics improved \nparticipants\u2019 ability to spot misinformation, and that this effect lasted a week for Go Viral!, but \nnot for the infographics. Critically, Go Viral! worsened participants\u2019 ability to spot true \ninformation, but this effect disappeared after a week.  \nBasol et al. also collected data on how confident participants were in their \nmanipulativeness ratings as well as how willing they were to share the news items online. \nHere, we focus ed on the manipulativeness ratings as these are suitable for  ROC analysis. \nFurthermore, although we reanalyzed both Study 1 and Study 2, we limited our reanalysis to \nthe active and control conditions from Study 2 as the effectiveness of infographics was not \nour primary interest. Finally, we limited our reanalysis to participants who had completed the \nentire experiment . To keep the reanalyses consistent, we reverse -coded the \nmanipulativeness scores so that 1 = \u201cvery manipulative\u201d and 7 = \u201cnot at all manipulative\u201d. \nThus, the direction of the manipulativeness scale matched that of th e reliability scales used \nin previous studies (i.e., higher values are associated with greater perceived truth). Overall, \nwe used a sample of 1 ,771 participants for Study 1 and 386 participants for Study 2 ( 151 \nfrom the active condition and 235 from the control condition).  \nResults  \n Study 1. The ROC curves for the pre -test and the post -test in Study 1 are shown in \nFigure 1 0. A paired samples t-test revealed that although the AUC values for the pre -test ( M \n= .89, SD = .18) were significantly smaller than the AUC values for the post -test ( M = .90, \nSD = .18), the effect size was almost negligible, t(1770) = 3.02, p = .003, d = 0.06, 95% CI \n[0.02, .09], and the Bayes factor only indicated anecdotal evidence for the alternative \nhypothesis, BF10 = 2.48. The FARs decreased between the pre -test and the post -test, and \nso did the HRs, albeit to a lesser degree (see Table S25). A paired samples t-test revealed \nthat the B\"D values for the pre -test ( M = .03, SD = .66) were significantly smaller than the \nB\"D values for the post -test ( M = .13, SD = .61), t(1770) = 13.77, p < .001, d = 0.27 , 95% CI \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  47 \n[0.23, 0.31]  (see Table S26), and the Bayes factor indicated extreme evidence in favor of the \nalternative hypothesis, BF10 = 3.07 \u00d71037. \n \nFigure 1 0 \nROC Curves for the Pre -Test and Post -Test in Basol et al.\u2019s (2021) Study 1  and Active  Condition  and \nControl Condition From Study 2  \n \nNote . ROC = Receiver operating characteristic.  The follow -up test took place  1 week after playing Go \nViral! or Tetris  in Study 2 . \n \n Study 2: Active Condition.  The ROC curves for the pre -test, post-test, and follow -\nup test  from the active condition in Study 2 are shown in Figure 1 0. A one -way repeated \n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Stud y 1\nFalse Alar m RateHit Rate\nPretest\nPosttest\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Active Condition, Stud y 2\nFalse Alar m RateHit Rate\nPretest\nPosttest\nFollow\u2212Up T est\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Contr ol Condition, Stud y 2\nFalse Alar m RateHit Rate\nPretest\nPosttest\nFollow\u2212Up T est\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  48 \nmeasures ANOVA revealed that the main effect of test on AUC was significant, F(2, 300) = \n13.50, p < .001, \u03b72 = .08, 95 % CI [.03, .14], and the Bayes factor indicated extreme \nevidence for the alternative hypothesis, BF10 = 5045.25. A post -hoc Tukey test showed that \nboth the pre -test and the post -test were significantly different from the follow -up test at p < \n.001, but the pre -test was not significantly different from the post -test, p = .973. The means \nand standard deviations of the AUC values are shown in Table S27. Both the HRs and the \nFARs decreased between the pre -test and the post -test, whereas the HRs remained the \nsame while the FARs decreased between the pre -test and the follow -up test (see Table \nS28). A one -way repeated measures ANOVA revealed that the main effect of test on B\"D \nvalues was significant, F(2, 300) = 26.01, p < .001, \u03b72 = .15, 95% CI [.08, .22], and the Bayes \nfactor indicated extreme evidence for the alternative hypothesis, BF10 = 212,975,465 (see \nTable S2 9). A post -hoc Tukey test showed that  the pre -test was significantly different from \nboth the post -test and the follow -up test at p < .001, and the post -test was significantly \ndifferent from the follow -up test, p = .004 . \nStudy 2: Control Condition.  The ROC curves for the pre -test, post-test, and follow -\nup test  from the control condition in Study 2 are shown in Figure 1 0. A one -way repeated \nmeasures ANOVA revealed that the main effect of test on AUC values was significant, F(2, \n468) = 11.60, p < .001, \u03b72 = .05, 95 % CI [.02, .09], and the Bayes factor indicated extreme \nevidence for the alternative hypothesis, BF10 = 860.03. A post -hoc Tukey test showed that \nboth the pre -test and the post -test were significantly different from the follow -up test , p = \n.003 and p < .001,  respectively,  but the pre -test was not significantly different from the post -\ntest, p = .361. The means and standard deviations of the AUC values are shown in Table \nS30. Both the HRs and the FARs only slightly decreased between the pre -test and the post -\ntest, whereas the HRs increased while the FARs decreased between the pre -test and the \nfollow -up test (se e Table S 31). A one -way repeated measures ANOVA revealed that the \nmain effect of test on B\"D values was not significant, F(2, 468) = 2.21, p = .111, \u03b72 = .00, \n95% CI [.00, .03], and the Bayes factor indicated moderate evidence for the null hypothesis, \nBF10 = 0.13 (see Table S 32).  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  49 \nDiscussion  \n Overall, in Study 1, Go Viral! elicited more conservative responding in the post -test \ncompared to the pre -test, but its effect on participants' news veracity discernment was \nambiguous. In Study 2, Go Viral! elicited more conservative responding but had no effect on \nnews veracity discernment in the post -test compared to the pre -test. Although Tetris also did \nnot have an effect on news veracity discernment, it did not elicit more conservative \nresponding in the post -test compared to the pre -test. Finally, bot h Go Viral! and Tetris \nimproved news veracity discernment in the follow -up test compared to the pre -test and the \npost-test. Specifically, Tetris decreased  the FAR and increas ed the HR (cf. Tables S25 and \nS26) , whereas  Go Viral! decreased  the FAR  but barely affected  the HR , which  resulted in \nhigher B\"D values because the overall proportion of responses exceeding the upper criteria \n(i.e., those associated with scale values greater than 1) decreased (cf. Tables S23 and S24).  \nConsidering that the delayed improvement in news veracity discernment was found \nin both the active condition and the control condition, coupled with the fact that different \nitems were used in the follow -up test than in the pre -test and the post -test, this effect can be \nattrib uted to item differences. Specifically, the items used in the follow -up test appear to \nhave been easier to discern than the items used in the pre -test and the post -test. This is \nsupported by the average reliability ratings for the true and fake news items, respectively, \ncollapsed across the two conditions ; these were 4.9 7 and 2. 60 in the pre -test, and 5.18 and \n2.20 in the follow -up test, the latter of which are considerably closer to the lower and upper \nlimits of the scale (i.e., 1 and 7).   \n These findings  can be used to explain Basol et al.\u2019s (2021) results. The B\"D analysis \nshowed that playing Go Viral! caused participants to respond more conservatively  in Study \n1. Although both the HRs (true news) and FARs (fake news) were lower in the post -test than \nthe pre -test after playing Go Viral! , the decrease was greater for the FARs . This explains the \nsignificant pre -post differences in manipulativeness ratings for the fake news items but not \nthe true news items in Study 1 of Basol et al. Similarly , Go Viral! caused participants to \nrespond more conservatively  in Study 2 , while Tetris did not . This explains the larger pre -\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  50 \npost differences in mean manipulativeness ratings for both the true and the fake news items \nin the active condition compared to the control condition shown in Basol et al.\u2019s paper. \nFinally, the HRs for the follow -up test were almost identical between the active condition and \nthe control condition, whereas the FARs were slightly lower in the active condition compared \nto the control condition. This explains Basol et al.\u2019s conclusion th at participants who played \nGo Viral! rated fake news items as more manipula tive than participants who played Tetris in \nthe follow -up test.  \nUltimately, our findings suggest that Go Viral! causes a shift to more conservative \nresponding that can impact responses to both true and fake news items  immediately  after \nplaying . However, its impact on news veracity discernment is unclear ; it was ambiguous in \nStudy 1, whereas in Study 2 , it improved after 1 week, but this also occurred for participants \nthat played  Tetris . Therefore, considering Basol et al. (2021) is the only published paper that \nhas examined the effectiveness of Go Viral!, further research on this topic is necessary to \nestablish the relationship between playing Go Viral! and news veracity discernment.  \nMeta -Analysis  \n To examine the overall evidence for intervention -based effects on discernment and \nresponse bias across the five reanalyzed studies with k = 13 experiments, we conducted a \nmeta -analysis on their pre -post AUC and B\"D effect sizes, separately. For each set of pre -\npost effect sizes, we first fit two random -effects models, one on the k = 8 experiments that \ninvolved a treatment (i.e., Bad News or Go Viral!) and one on the k = 5 experiments that \ninvolved a control (i.e., Tetris or nothing). These two models compa red the overall meta -\nanalytic effect size estimate to the null effect size (i.e., d = 0). We then fitted a fixed -effects \nmeta -regression model with a binary moderator variable (treatment/control) on the results \nfrom the two random -effects models.6 This model compared the overall meta -analytic effect \n \n6 According to Borenstein et al. (2010), fixed -effects models assume that a common effect size underlies all the \nstudies in the analysis, and that any observed effect size differences between them are due to sampling error. In \ncontrast, random -effects model s assume that a different effect size can underly each study due to heterogeneity \nbetween them. Considering the heterogeneity between the studies we analyzed (e.g., different participant pools, \nitems, and treatment versions), we fitted random -effects model s on the pre -post effect sizes. We then compared \nthese two random -effects models with a fixed -effects model since the heterogeneity between studies had already \nbeen accounted for by the two prior random -effects models.  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  51 \nsize estimate for the treatment conditions to the overall meta -analytic effect size estimate for \nthe control conditions.  This analysis was informed by the metafor R package ( Viechtbauer, \n2010 ) website ( https://www.metafor -\nproject.org/doku.php/tips:comp_two_independent_estimates ). \n The results of our meta -analysis on the pre -post AUC effect sizes are shown in Table \n3 and Figure 11. The random -effects model on the treatment conditions showed a significant \nincrease in AUC values from the pre -test to the post -test, while the random -effects model on \nthe control conditions did not. However, the fixed -effects model comparing the two random -\neffects models showed no significant diff erence in pre -post AUC effect sizes between the \ntreatment conditions and the control conditions. In other words, there was no overall \nevidence for intervention -based effects on discernment  once the control data were taken into \nconsideration .  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  52 \nTable 3 \nResults from the Meta -Analys es on the AUC and B\"D Pre-Post Effect Sizes  \nMeta -analytic model  d z p \nAUC pre -post effect sizes  \nRandom -effects model (treatment \nconditions)  0.17 2.73 .006 \nRandom -effects model (control \nconditions)  0.09 0.72 .473 \nFixed -effects model (comparing the two \nrandom -effects models)  0.08 0.52 .606 \nB\"D pre-post effect sizes  \nRandom -effects model (treatment \nconditions)  0.57 3.92 < .001  \nRandom -effects model (control \nconditions)  0.16 2.24 .025 \nFixed -effects model (comparing the two \nrandom -effects models)  0.41 2.51 .012 \nNote . AUC = area under the curve.  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  53 \nFigure 11 \nThe Two Random -Effects Models and the Fixed -Effects Model Fitted on the AUC Pre -Post Effect \nSizes  \n \nNote . RE = random effects. The error bars represent the standard errors. The size of the points \nrepresent s the weight given to each study.   \n \nThe results of our meta -analysis on the pre -post B\"D effect sizes are shown in Table \n3 and Figure 12. The random -effects model on the treatment conditions showed a significant \nincrease in B\"D values from the pre -test to the post -test, as did the random -effects model on \nthe control conditions. However, the fixed -effects model comparing the two random -effects \nmodels showed a significant difference in pre -post B\"D effect sizes between the treatment \n\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  54 \nconditions and the control conditions. Specifically, the increase in B\"D values from the pre -\ntest to the post -test was significantly greater in the treatment conditions compared to the \ncontrol conditions. In other words, there was overall evidence for intervention -based effects \non response bias, where by the interventions made participants respond significantly more \nconservatively.  \n \n  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  55 \nFigure 12 \nThe Two Random -Effects Models and the Fixed -Effects Model We Fitted on the B\"D Pre-Post Effect \nSizes  \n \nNote . RE = random effects. The error bars represent the standard errors. The size of the points \nrepresent s the weight given to each study.   \n \nGeneral Discussion  \nThe main goal of this paper was to explore whether gamified fake news interventions \nspecific ally affect only the targeted  behavior (i.e., belie f in fake news) or have more general \neffects that include  the targeted behavior as well as other behaviors (e.g., belief in  true \n\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  56 \nnews). We achieved this goal  using ROC analysis, a method common ly used with SDT that \nis ideally suited for determining the generality of interventions. Specifically, ROC analysis \nallows researchers  to separate discrimination (i.e., the ability to distinguish between true and \nfake news), which is also referred to as news veracity discernment, from response bias (i.e., \nthe tendency to rate news items as true or fake regardless of their objective veracity; \nBatailler et al., 202 2). If the gamified  intervention  affects only the target behavior, this will \nresult in a n increase in discrimination because the FARs  (derived from  fake news ratings) \nwould decrease whereas the HRs (derived from true news ratings) would remain static (or \npossibly increase). If the gamified  intervention has more general effects, this will result in an \neffect on response bias because both the FARs and HRs would decrease.  Despite this, to \nthe best of our knowledge, ROC analysis has only been used once before with research on \nfake news  (Modirrousta -Galian et al., in press ). Instead,  most studies have analyzed  mean \nratings , which are not ideally suited for separating discrimination and response bias (more \non this later) .  \nConsequently, we used ROC analysis to reanalyze the results from five different \nstudies that used mean reliability or manipulativeness ratings  to assess the effectiveness of \nBad News  and Go Viral! , respectively, two notable gamified inoculation  interventions (Basol \net al., 2020; Basol et al., 2021; Maertens et al., 202 1; Roozenbeek et al., 2020; Roozenbeek \n& van der Linden, 2019). Table 4 shows a summary of the conclusions the authors drew \nfrom their data in those papers along with the conclusions we drew f rom reanalyzing the \nsame data using ROC analysis. Overall, the  authors of these  prior studies concluded that \nBad News  and Go Viral!  are effective in improving people\u2019s ability to detect false or \nmisleading online content. Conversely, our reanalysis suggested  that the interventions  \nmerely make  people respond more conservative ly, with little or no effect on discernment  per \nse.  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  57 \nTable 4 \nA Summary of the Conclusions Drawn from the Reanalyzed Papers That Used Mean Ratings and Our \nReanalysis That Used ROC Analysis  \nIntervention and \nStudy  Conclusions from analyzing mean \nratings  Conclusions from ROC analysis  \nBad News    \nRoozenbeek \nand van der \nLinden (2019)  Bad News  improves people\u2019s ability \nto spot online misinformation.  \n  \n Bad News caused a slight \nimprovement in news veracity \ndiscernment, but this result can be \nattributed to differences in \nambiguity between the true and \nfake news items.  \nBasol et al. \n(2020)  Bad News  improves people\u2019s ability \nto spot online misinformation.  \n Bad News  causes more  \nconservative responding but not an \nimprovement in news veracity \ndiscernment.  \nRoozenbeek et \nal. (2020)  Bad News  improves people\u2019s ability \nto spot online misinformation, but \nitem effects are present when using \nthe same items in the pre -test and \nthe post -test.  Bad News  causes more \nconservative responding but not an \nimprovement in news veracity \ndiscernment, and more \nconservative responding  is more \nlikely to occur when the news items \nused to assess mean ratings are \nambiguous.  \nMaertens et al. \n(2021) Bad News  improves people\u2019s ability \nto spot online misinformation \nimmediately after playing, but this \neffect decays and becomes \nnegligible after 9 weeks unless \nparticipants undergo repeat ed \ntesting.  Bad News causes more \nconservative responding but not an \nimprovement in news veracity \ndiscernment . The increased \nconservative responding disappears \nafter 9 weeks unless participants \nundergo repeat ed testing.   \nGo Viral!    \nBasol et al. \n(2021)  Go Viral!  improves people\u2019s ability \nto spot online misinformation but \nworsens their ability to spot true \ninformation immediately after \nplaying . The effect on  true news \ndissipate s after 1 week, whereas \nthe effect on fake news d oes not. Go Viral! causes more conservative \nresponding immediately after \nplaying, but its impact on news \nveracity discernment is unclear ; it \nwas either ambiguous or improved \nafter 1 week, but this latter result \ncan be attributed to item differences \nas it also occurred to participants \nwho played Tetris.  Therefore,  \nfurther research is needed to clarify \nthis effect.  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  58 \nNote . ROC = Receiver operating characteristic. The list of conclusions drawn from analyzing mean \nratings reported in the table are not exhaustive. That is, not all the original conclusions were reported, \nbut rather just the ones that can be compared to those from our reanalysis.  \n \n The only stud ies that produced evidence of an intervention -based improvement in \nnews veracity discernment when reanalyzed w ere Roozenbeek and van der Linden (2019)  \nand Basol et al.\u2019s (2021)  Study 2  in the 1 -week follow -up test . The result from Roozenbeek \nand van der Linden  can be attributed to differences in ambiguity between the true and fake \nnews items used to obtain mean reliability ratings. Specifically, the true news items were \nevidently reliable, whereas the fake news items were, by contrast, ambiguo us (see \nreanalysis of Roozenbeek & van der Linden, 2019 presented earlier for more information ). \nClearly,  it is much less likely for a psychological intervention to impact participants\u2019 beliefs in \nnews items that they are certain about compared to news items that they are uncertain \nabout. Indeed, when the differences in ambiguity between true and fake news ite ms are less \npronounced, as was the case for all the other reanalyzed studies on Bad News, no \nintervention -based improvements to news veracity discernment were found.  \nThe result from Basol et al.\u2019s (2021) Study 2 can also be attributed to item effects. \nSpecifically, the items used in the 1-week follow -up test were easier than the items used in \nthe pre -test and the post -test (see reanalysis of Basol et al., 2021 presented earlier for more \ninformation) . This explains why the same delayed improvement in news veracity \ndiscernment was found in control participants who played Tetris.  \nOther Cases of Response Bias and Data Analysis Problems in Psychology  \nIn our view, our research is one of many examples in the history of psychology where \nan initial interpretation of some data has been undermined by concerns about response \nbias. An early example occurred with the \u201cdirty word\u201d studies on perceptual defense \nconducted in the 1940s and 50s (see Eriksen, 1954 for a review) . The idea under \nconsideration at the time was that the ego protects consciousness from perceiving anxiety \nprovoking stimuli such as taboo words. For example, McGinnies (1949)  found that, \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  59 \ncompared to neutral words, a longer exposure duration was needed before participants \nreported seeing briefly presented taboo words. Simultaneously, however, participants\u2019 \nGalvanic Skin Response ( GSR ) was raised even for the unreported subliminal taboo words, \nsuggesting that participants unconsciously perceived the word, but the content of that \nperception was denied entry into consciousness. However, Howes and Solomon (1950)  \noffered an amusing alternative explanation to these findings from a male participant\u2019s \nperspective:  \nBut, Heavens, NO! The word is \u2013 penis ! And there is that girl (not to mention your \nprofessor) hanging on every word! Suppose it really isn't penis , after all (one can't be \nsure about tenth -of-a-second flashes) \u2014what wouldn't  they think about you if, out of \nthe clear blue sky, you should volunteer that word! (p. 233)  \nThus, failure to report the taboo words might have been due to conservative reporting, not \nfailure to consciously perceive the taboo words. At the same time, the elevated GSR might \nhave been due to participants feeling pressured by the context to say taboo  words aloud.  \nSimilar concerns about report bias have been raised \u2013 but in reverse \u2013 with hypnosis \nand the cognitive interview (Fisher & Geiselman, 1992)  in memory research. Both \nprocedures have been promoted as providing victims and witnesses of crime access to \nmemories that would otherwise be unrecallable. However, some have noted that hypnotized \nparticipant s tends to report more information than control participants (e.g., Klatzky & \nErdelyi, 1985) . Similarly, because one of the four main techniques incorporated into the \ncognitive interview is to \u201creport everything,\u201d the cognitive interview is also likely to liberalize \ninterviewees\u2019 report criterion (see Memon & Higham, 1999) . If the report criterion is made \nmore liberal, it is likely that there will be increased reporting of both true and false memories. \nHowever, if only the true memories are counted, a procedure that merely causes more \nliberal reporting may seem like a memory enhancement technique.  \nROC analysis like that we have recommended here has the potential to identify more \nnuanced response bias problems. Indeed, some theorists have gone so far as to suggest \nthat unless ROC curves are used, it is impossible to measure memory efficacy in such \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  60 \ncommon paradigms as old/new recognition (see Brady et al., 2022) . In the context of \neyewitness memory, Mickes et al. (2012)  introduced ROC analysis to examine the relative \nefficacy of sequential versus simultaneous lineup procedures. The received wisdom at the \ntime was that sequential lineups were superior. However, these conclusions were partly due \nto reliance on a measure kn own as the diagnosticity ratio , the ratio of the HR (proportion of \ncorrect identifications when culprit present) and FAR (proportion of incorrect identifications \nwhen culprit absent; diagnosticity ratio = HR/FAR).  \n Steblay et al. (2011)  conducted a meta -analysis on studies that mainly used this \nmeasure. They noted that although both the HR and FAR were less in the sequential (vs. \nsimultaneous) lineups, the FAR reduction was greater, which produced a higher \ndiagnosticity ratio. However, t he diagnosticity ratio is not independent of response bias  \nunder most circumstances , so these differences might be due to more conservative \nresponding with the sequential lineup procedure rather than a sequential -superiority effect . \nIndeed, when Mickes et al. (2012) analyzed lineup data with ROC analysis, the opposite \nconclusion was reached (i.e., simultaneous > sequential), a finding that has had a dramatic \neffect on how the police use and interpret lineups.  \nIn addition to the effect that ROC analysis has had on memory research, Heit and \nRotello (2014)  used ROC analysis to demonstrate that belief bias from the reasoning \nliterature (the tendency to find fallacious reasoning to be valid when the content of the \nexample is believable) was a response bias effect rather than a demonstration of flawed \nreasonin g. Also, Rotello et al. (2015)  argued that ROC analysis is needed in other domains \nsuch as shooter bias research in social psychology (the tendency for white participants to \nshoot unarmed black suspects more than unarmed white suspects) and referrals for child \nmaltreatment. Although signal detection theorizing has been applied to both of these \ndomains (e.g., see Correll et al., 2002 , and Mumpower & McClelland, 2014 , respectively), \nneither have used ROC analysis.  \nThe longstanding illusion of a sequential -superiority effect is not just attributable to \nuse of the diagnosticity ratio. A problem that is coupled with use of this statistic is analyzing \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  61 \narithmetic differences in mean HR and FAR scores between the conditions of interest to \nassess discrimination. This problem is present in research on fake news as well. For \nexample, Roozenbeek and van der Linden (2019) noted that:  \nAlthough statistically significant, there were no meaningful differences in the pre -\nscores and post -scores of the \u201creal\u201d control headlines\u2026 In contrast, there were both \nstatistically significant and much larger differences in the pre -scores and post -scores  \nfor the fake tweets (pp. 5 -7).  \nAn obvious interpretation of these statements is that the authors are assuming that the \nbigger pre/post difference scores for FARs (vs. HRs) is evidence that Bad News is improving \ndiscernment. This conclusion is reminiscent of Steblay et al.\u2019s (2011) assum ption that the \nbigger FAR (vs HR) difference between sequential versus simultaneous lineups was \nevidence for the sequential superiority effect. The problem with interpreting data in this way \nis that it assumes a linear relationship between the HRs and FARs . However, this \nassumption is not met in the vast majority of empirical psychological research, including fake \nnews research (see Figures 4, 5, 8, 9, and 10 ). If, instead, the relationship is nonlinear, \nproducing bowed  ROC curves rather than straight lines, then shifts in response bias on their \nown can also produce a pattern of data where FARs change more than the HRs in response \nto an intervention.   \nWhat Does \u201cMore Conservative Responding\u201d  Mean?  \nIn most of the reanalyses we conducted, there was evidence of both a lower FAR \n(fake news) and a lower HR (true news) in the post -test following the gamified intervention \ncompared to the pre -test. This lowering of both the HR and FAR could be seen on the R OC \ncurves as the points shifting toward s the lower -left portion of the curve. It was also reflected \nin the SDT measure B\"D, which indicated more conservative responding (i.e., increased B\"D \nvalues associated with several of the ROC points in the post -test compared to the pre -test). \nHow should we interpret these changes to response bias?  \n There are two SDT models that can account for more conservative responding in the \npost-test, which are shown in Figure 1 3 (Witt et al., 2015) . The criteria -shift account shown \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  62 \nin the top panel of Figure 1 3 assumes that participants adopt more conservative criteria in \nthe post -test compared to the pre -test. For convenience, Figure 1 3 shows a similar  shift for \neach criterion. However, some criteria may shift more than others , while some may not shift \nat all, which is consistent with the B\"D results from the reanalyses. For participants to adopt \nmore conservative criteria in the post -test compared to the pre -test, it means that they need \nmore subjective evidence of truth before assi gning any scale value higher than 1.7 This shift \nwould have the effect of lowering both the HR and FAR at each of the scale points greater \nthan 1, but not have any effect on discrimination.8 In Figure 1 3, this decrease in both the HR \nand FAR is shown most clearly with scale point 4. For the pre -test, the 4 criterion is located \nat the intersection point of the fake and true news item distributions. However, at the post -\ntest, assigning a 4 requires more sub jective evidence, represented by the criterion for scale \nvalue 4 moving to the right of the intersection point. This shift means that fewer items are \nassigned 4 or higher , thereby lowering both the HR and FAR.   \n \n \n7 As noted earlier, the criterion for \u201c1\u201d on the scale is maximally liberal and has a HR and FAR fixed at 1.0 \nbecause all items are assigned 1 or higher due to the nature of the task. Indeed, some may argue that 1 on the \nscale does not have a criterion asso ciated with it at all, but we include it in Figure  13 to facilitate exposition.  \n \n8 In principle, it is possible for the criteria to shift and for there also to be a change in discrimination. However, \nbecause our reanalyses did not reveal any clear evidence for cases where discrimination changed between the \npre-test and the post -test (except for cases where there were item effects ), neither model depicted in Figure 1 3 \nincorporates th is feature.   \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  63 \nFigure 1 3 \nTwo Signal -Detection Models that Account for More Conservative Responding Following a Gamified \nIntervention.  \n \n \n\nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  64 \n The second potential account of more conservative responding in the post -test \ncompared to the pre -test is shown in the bottom panel of Figure 1 3. The placement of the \ncriteria and distributions for the pre -test in this model are the same as in the first model. \nHowever, to account for the more conservative responding in the post -test, this model does \nnot assume that the criteria move up the decision axis, but rather that both the true and fake \nnews item distributions shift down the decision axis, toward s the left. In this model, which we \nhave dubbed the dual distribution shift , the criteria are static; that is, there is no change in \nthe amount of evidence needed to assign particular scale values. Instead, the intervention \nhas led participants to perceive less evidence of truth in both true and fake  news items.  \nNote that the HRs and FARs in the pre -test and post -test are identical between the \ntwo models. This equality is seen most readily by focusing on scale value 4  in Figure 13 . \nMoreover, because the HRs and FARs are identical between the two models, so is the \nmeasure of bias, B\"D. B\"D is a function of the HR and FAR, and so it is only responsive to \nthe magnitude of those values; it cannot \u201cknow\u201d whether a change in the HR, FAR, or both, \nis due to criteria shifts or dual distribution shifts. Finally, it is worth  noting that these two \nmodels represent the extreme cases. In reality, the data from the reanalyses could also have \nbeen produced by the intervention s causing some combination of criteria and distribution \nshifts.  \n Without further research, it is difficult to distinguish between these two models. \nNonetheless, it is worth considering the potential psychological mechanisms underpin ning \neach model. The criteria  shift model suggests that participants\u2019 assessment of the evidence \nfor truth of the items does not change as a result of the intervention. A participant that \nassesses an item with x amount of evidence in the pre -test still assesses it as having x \namount of evidence in the post -test. In other words, the intervention has not taught  \nparticipants anything specific. Instead, participants have lowered the scale value they are \nwilling to assi gn to an item with x amount of evidence.  \nThere are at least two reasons why this type of scale recalibration might occur. First, \nthe intervention may simply highlight the problem of fake news and cause a general increase \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  65 \nin participants\u2019 skepticism . For example, the intervention might activate a schema about \nmost people being untrustworthy . In this scenario, the intervention has not made participants \nany better at identifying manipulative techniques in fake news. Rather, participants become \nskeptical of all news and are less willing to assign high reliability ratings or low \nmanipulativeness ratings to any given news item.  \nA second possible reason for scale recalibration could result from methodological \nconcerns. In most of the studies that we reanalyzed, the number of true news items in the \npre-test was much lower than the number of fake news items.9 Along with manipulating \npayoff matrices  (i.e., the relative benefit vs. cost of hits vs. false alarms , respectively ), \nvarying the base  rate probability of the signal trials (which are true news items in the current \nscenario) is a classical method of varying criterion placement in signal detection experiments \n(e.g., see Ratcliff et al., 1992; Rhodes & Jacoby, 2007). If there are very few s ignal trials, \npeople are less willing to give high confidence \u201csignal\u201d responses, exactly the outcome we \nobserved across multiple datasets. However, unless participants are explicitly told about the \nsignal base rates a priori, it takes several trials for p articipants to learn that the correct \nresponse is nearly always \u201cnoise\u201d (\u201cfake\u201d). Consequently, the likely result of a low proportion \nof signal (true news) trials in the pre -post design would be relatively unbiased responding on \nthe pre -test as base rate l earning is taking place, followed by higher criteria in the post -test. \nRegarding the dual distribution shift account, there are also at least two different \npsychological mechanisms that might produce this outcome. The main difference between \nthis account and the criteria shift account is that participants are assessing the ev idence \ndifferently rather than merely recalibrating their use of the rating scale. Specifically, they are \nsubjectively perceiving less evidence of truth, but this is occurring for both true and fake \nnews items. Such an outcome could occur if the gamified i ntervention promoted correct \nidentification of manipulative techniques in fake news, but participants were also incorrectly \n \n9 Note, however, that this explanation cannot account for the more conservative responding caused by  playing \nGoViral! since the study examining its effectiveness (Basol et al. , 2021) used  an equal number of true and fake  \nnews  items.  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  66 \nidentifying these techniques in true news when they were not there. Again, the intervention \ncausing activation of schemas such as \u201c most people are untrustworthy\u201d might play a role \nhere. However, in this case, activation of this schema has changed the perception of the \navailable evidence rather  than how the rating scale is calibrated with respect to the \nsubjective evidence.  \nAn alternative psychological account of the dual distribution shift model is that some \nof the manipulative techniques the games seek  to teach participants about are present in \nboth fake news and true news. Consequently, if the intervention facilitates identification of \nthese techniques, then it stands to reason that participants would perceive less evidence of \ntruth (or more evidence of falsity) in both true and fake news items. Such a possibilit y is not \nwithout merit. Mainstream news outlets are under pres sure to capture their audience\u2019s \ninterest and attention in the same way that generators of fake news are. In this vein, Hart et \nal. (2020) found that six reputable newspapers (i.e.,  USA Today , The Washington Post , The \nPhiladelphia Inquirer , The New York Times , The Los Angeles Times , The Minneapolis Star -\nTribune , and The Atlanta Journal -Constitution ), five of which are rated as high and one of \nwhich is rated as moderate on factual reporting by the fact -checking website Media \nBias/Fact Check ( https://mediabiasfactcheck.com/ ), provided highly polarized news \ncoverage on COVID -19. Furthermore, it is well established that news headlines, regardless \nof source, often use loaded words to fearmonger (Glassner, 2004) and evoke other \nemotions in readers (Clark, 2006). Polarization and  provocative emotional content are two of \nthe manipulative techniques taught by Bad News , and fearmongering is one of the \nmanipulative techniques taught by Go Viral!  (Basol et al., 2021; Roozenbeek & van der \nLinden, 2019). Therefore, Bad News  and Go Viral!  may effectively teach people how to \ndetect manipulative strategies, but if they are  present in both true and fake news, these \ninterventions could cause people to consider all news as less reliable or more manipulative.  \nNew Studies and the Up -to-Dateness of This Paper  \nWe acknowledge that this reanalysis has the potential to be out of date the moment it \nis accepted for publication, especially due to the current popularity of gamified fake news \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  67 \ninterventions. Indeed, after the conclusion of our literature review, two new papers on the \neffectiveness of Bad News were published that met all of our inclusion criteria, namely \nRoozenbeek et al. (2022) and Iyengar et al. (2022). Although we cannot conti nue amending \nthis paper to include all of the newest experiments as they get published, we reanalyzed \nthese two particular studies in an attempt to make our reanalysis as up to date as possible \nbefore it is published. We will not reanalyze any more papers henceforth. Overall, \nRoozenbeek et al. showed no meaningful improvement in discernment but a meaningful \nincrease in conservative responding after playing Bad News (see Table S 33 and Figure S1). \nIn contrast, Iyengar et al. showed a meaningful increase in discernment after playing Bad \nNews (see Table S 33 and Figure S2).  \nWe offer three different explanations for Iyengar et al.\u2019s (2022) uncharacteristic \nresult: (a) sample differences; Iyengar et al. recruited an Indian sample, whereas all the \nother reanalyzed studies recruited Western samples. Perhaps Bad News is only effec tive for \nnon-WEIRD (western, educated, industrialized, rich, and democratic) samples; (b) design \nflaws; although the pre -test items were different from the post -test items, they were not \ncounterbalanced, and the experiment lacked a control condition. These  methodological \nissues introduce the potential confounds of sequence effects, order effects, and item effects; \nand (c) Iyengar et al. may simply be an outlier; out of the 12 reanalyzed treatment \nconditions, only one has shown such considerable improvements  in discernment. \nNevertheless, although including Roozenbeek et al. (2022) and Iyengar et al. in the meta -\nanalysis changed the magnitude of effects, it did not change their statistical significance (see \nTable S28 and Figures S3 and S4). Therefore, the conc lusions we made from our reanalysis \nremain the same.  \nConclusion  \nThe difference in the conclusions drawn from analyzing mean ratings and ROC \nanalysis is arguably the most important finding from this paper. It demonstrates that by \nconflating discrimination and response bias, and thus providing a rather coarse and \nimpreci se overview of the decision -making process, an intervention can misguidedly appear \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  68 \neffective in producing its intended effects. However, after separating these diverse \ninfluences, and thus providing a more detailed and accurate breakdown of the different \nmechanisms at play, the same intervention can be revealed to be not so effective in \nproducing its intended effects. Consequently, using a statistical method that offers such \nnuanced insights is of vital importance. ROC analysis is perfectly suited for this purpose, and \nwe therefore recommend its use for assessing the generality and hence efficacy of  \ninterventions that aim to improve fake news detection . \nConstraints on Generality  \nOur findings suggest that Bad News and Go Viral! do not improve news veracity \ndiscernment. Instead, they both elicit more conservative responding. Given that this result \nhas been observed across five papers amounting to a total of 13 experiments (eight \ntreatment conditions and five control conditions) and 17,867 participants, we believe that it \nwill be reproducible with participants from similar subject pools, specifically WEIRD samples. \nHowever, we do not have evidence that our findings will occur for non -WEIRD samples (see \nIyengar  et al., 2022). In most of the reanalyzed studies, the stimuli consisted of a limited \nnumber of true and fake news items, the latter of which were often created by the \nresearchers. Therefore, we expect our results to generalize to situations in which \nparticipants rate similar item sets. Indeed, when participants were tested on a larger set of \ntrue and fake news items that had been posted on the internet in the past, Bad News had no \neffect at all; it did not improve news veracity discernment nor elicit more conservative \nresponding (Modirrousta -Galian et al., in press). Finally, we do not have evidence that our \nfindings will generalize to gamified fake news interventions other than Bad News and Go \nViral!. We have no reason to believe that the re sults depend on  other characteristics of the \nparticipants, materials, or context.   \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  69 \nContext  \nGamified psychological interventions designed for improving people\u2019s ability to spot \nonline misinformation have become popular. To determine their efficacy, we believe it is vital \nto assess their generality  (their effect on both true and fake news ) because some \ninterventions may affect the intended behavior as well as unintended behaviors (reduced \nbelief in true news). Considering that reduced belief in true news can potentially have \ndevastating consequences (e.g., rejecting the scientific truth that vaccin es are important for \npersonal and global health) , this distinction is critical. Receiver operating characteristic \n(ROC) analysis  is ideally suited for determining the generality of interventions , as it allows \nfor discrimination  (ability to distinguish between true and fake news) and response bias  \n(tendency to rate news items as true or fake regardless of their objective veracity) to be \nmeasured separately.  Despite its usefulness, ROC analysis has scarcely been used in \nonline misinformation research  (althoug h see Modirrousta -Galian et al., in press ). \nConsequently, we filled this gap in the literature by using ROC analysis to reanalyze data \nfrom published papers on gamified inoculation  interventions, which allowed us to determine \ntheir generality and thus effectiveness.  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  70 \nReferences  \nAdjin -Tettey, T. D. (2022). Combating fake news, disinformation, and misinformation: \nExperimental evidence for media literacy education. Cogent Arts & Humanities , 9(1), \nArticle 2037229. https://doi.org/10.1080/23311983.2022.2037229   \nAfolabi, A. A., & Ilesanmi, O. S. (2021). Dealing with vaccine hesitancy in Africa: The \nprospective COVID -19 vaccine context. The Pan African Medical Journal , 38, Article \n3. https://doi.org/10.11604%2Fpamj.2021.38.3.27401   \nAleci, C. (2021). Measuring the soul . EDP Sciences. https://doi.org/10.1051/978 -2-7598 -\n2518 -9  \nAllen, J., Howland, B., Mobius, M., Rothschild, D., & Watts, D. J. (2020). Evaluating the fake \nnews problem at the scale of the information ecosystem. Science Advances , 6(14), \nArticle eaay3539. https://doi.org/10.1126/sciadv.aay3539  \nBanas, J. A., & Rains, S. A. (2010). A meta -analysis of research on inoculation theory. \nCommunication Monographs , 77(3), 281 \u2013311. \nhttp://dx.doi.org/10.1080/03637751003758193   \nBasol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & van der Linden, \nS. (2021). Towards psychological herd immunity: Cross -cultural evidence for two \nprebunking interventions against COVID -19 misinformation. Big Data & Society , 8(1), \n1\u201318. https://doi.org/10.1177%2F20539517211013868  \nBasol, M., Roozenbeek, J., & van der Linden, S. (2020). Good news about bad news: \nGamified inoculation boosts confidence and cognitive immunity against fake news. \nJournal of Cognition , 3(1), Article 2. https://doi.org/10.5334/joc.91  \nBatailler, C., Brannon, S. M., Teas, P. E., & Gawronski, B. (202 2). A signal detection \napproach to understanding the identification of fake news. Perspectives on \nPsychological Science , 17(1), 79 \u201398. https://doi.org/10.1177/1745691620986135  \nBorenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2010). A basic \nintroduction to fixed -effect and random -effects models for meta -analysis. Research \nSynthesis Methods , 1(2), 97 \u2013111. https://doi.org/10.1002/jrsm.12   \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  71 \nBrady, T. F., Robinson, M. M., Williams, J. R., & Wixted, J. T. (2022). Measuring memory is \nharder than you think: How to avoid problematic measurement practices in memory \nresearch. Psychonomic Bulletin & Review . https://doi.org/10.3758/s13423 -022-\n02179 -w  \nBrashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when \ncorrecting fake news. Proceedings of the National Academy of Sciences , 118(5), \nArticle e2020043118. https://doi.org/10.1073/pnas.2020043118  \nCalvillo, D. P., Rutchick, A. M., & Garcia, R. J. B. (2021). Individual differences in belief in \nfake news about election fraud after the 2020 U.S. election. Behavioral Sciences , \n11(12), 175. https://doi.org/10.3390/bs11120175   \nClark, C. M. B. (2006). Views in the news . LED Edizioni Universitarie.  \nClayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, \nA., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz -Bright, R., Welch, A. T., \nWolff, A. G., Zhou, A., & Nyhan, B. (2020). Real solutions for fake news? Mea suring \nthe effectiveness of general warnings and fact -check tags in reducing belief in false \nstories on social media. Political Behavior, 42 (4), 1073 \u20131095. \nhttps://doi.org/10.1007/s11109 -019-09533 -0  \nCorrell, J., Park, B., Judd, C. M., & Wittenbrink, B. (2002). The police officer\u2019s dilemma: \nUsing ethnicity to disambiguate potentially threatening individuals. Journal of \nPersonality and Social Psychology , 83(6), 1314 \u20131329. https://doi.org/10.1037/0022 -\n3514.83.6.1314   \nCorrigan, P. W. (2016). Lessons learned from unintended consequences about erasing the \nstigma of mental illness. World Psychiatry , 15(1), 67 \u201373. \nhttps://doi.org/10.1002%2Fwps.20295   \nde Gardelle, V., & Kouider, S. (2009). Cognitive theories of consciousness. In W. P. Banks \n(Ed.), Encyclopedia of consciousness  (pp. 135 \u2013146). Elsevier. \nhttps://doi.org/10.1016/B978 -012373873 -8.00077 -3  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  72 \nDeLong, E. R., DeLong, D. M., & Clarke -Pearson, D. L. (1988). Comparing the areas under \ntwo or more correlated receiver operating characteristic curves: a nonparametric \napproach. Biometrics , 44(3), 837 \u2013845. https://doi.org/10.2307/2531595   \nDonaldson, W. (1992). Measuring recognition memory. Journal of Experimental Psychology: \nGeneral, 121 (3), 275 \u2013277. https://doi.org/10.1037/0096 -3445.121.3.275  \nDonaldson, W., & Good, C. (1996). A\u2032r: An estimate of area under isosensitivity curves. \nBehavior Research Methods, Instruments & Computers, 28 (4), 590 \u2013597. \nhttps://doi.org/10.3758/BF03200547  \nEcker, U. K. H., Lewandowsky, S., Cook, J., Schmid, P., Fazio, L. K., Brashier, N., Kendeou, \nP., Vraga, E. K., & Amazeen, M. A. (2022). The psychological drivers of \nmisinformation belief and its resistance to correction. Nature Reviews Psychology , \n1(1), 13 \u201329. https://www.nature.com/articles/s44159 -021-00006 -y  \nEriksen, C. W. (1954). The case for perceptual defense. Psychological Review , 61(3), 175 \u2013\n182. https://doi.org/10.1037/h0058094   \nFisher, R. P., & Geiselman, R. E. (1992). Memory -enhancing techniques for investigative \ninterviewing: The cognitive interview.  (pp. xi, 220). Charles C Thomas, Publisher.  \nGlassner, B. (2004). Narrative techniques of fear mongering. Social Research: An \nInternational Quarterly , 71(4), 819 \u2013826. https://doi.org/10.1353/sor.2004.0001   \nGrace, L., & Hone, B. (2019). Factitious: large scale computer game to fight fake news and \nimprove news literacy. Extended Abstracts of the 2019 CHI Conference on Human \nFactors in Computing Systems , 1\u20138. https://doi.org/10.1145/3290607.3299046   \nGrady, R. H., Ditto, P. H., & Loftus, E. F. (2021). Nevertheless, partisanship persisted: Fake \nnews warnings help briefly, but bias returns with time. Cognitive Research: Principles \nand Implications , 6(1), Article 52. https://doi.org/10.1186/s41235 -021-00315 -z  \nGuay, B., Berinsky, A. J., Pennycook, G., & Rand, D. (2022). How to think about whether \nmisinformation interventions work . PsyArxiv. https://doi.org/10.31234/osf.io/gv8qx   \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  73 \nHart, P. S., Chinn, S., & Soroka, S. (2020). Politicization and polarization in COVID -19 news \ncoverage. Science Communication , 42(5), 679 \u2013697. \nhttps://doi.org/10.1177%2F1075547020950735  \nHeeger, D. (1997, November 12). Signal Detection Theory  [Teaching handout]. Department \nof Psychology, Stanford University. http://www.cns.nyu.edu/~david/handouts/sdt -\nadvanced.pdf    \nHeit, E., & Rotello, C. M. (2014). Traditional difference -score analyses of reasoning are \nflawed. Cognition , 131(1), 75 \u201391. https://doi.org/10.1016/j.cognition.2013.12.003   \nHigham, P. A., & Higham, D. P. (2018). New improved gamma: Enhancing the accuracy of \nGoodman \u2013Kruskal\u2019s gamma using ROC curves. Behavior Research Methods , 51(1), \n108\u2013125. https://doi.org/10.3758/s13428 -018-1125 -5  \nHigham, P. A., Zawadzka, K., & Hanczakowski, M. (2016). Internal mapping and its impact \non measures of absolute and relative metacognitive accuracy. In J. Dunlosky & S. K. \nTauber (Eds.), The Oxford handbook of metamemory  (pp. 39 \u201361). Oxford University \nPress. http://dx.doi.org/10.1093/oxfordhb/9780199336746.013.15   \nHowes, D. H., & Solomon, R. L. (1950). A note on McGinnies\u2019 \u2018Emotionality and perceptual \ndefense.\u2019 Psychological Review , 57(4), 229 \u2013234. https://doi.org/10.1037/h0060881   \nHuotari, K., & Hamari, J. (2016). A definition for gamification: Anchoring gamification in the \nservice marketing literature. Electronic Markets , 27(1), 21 \u201331. \nhttps://doi.org/10.1007/s12525 -015-0212 -z  \nIyengar, A., Gupta, P., & Priya, N. (2022). Inoculation against conspiracy theories: A \nconsumer side approach to India\u2019s fake news problem. Applied Cognitive \nPsychology . Advance online publication. https://doi.org/10.1002/acp.3995   \nJeffreys, H. (1961). Theory of probability  (3rd ed.). Oxford University Press.  \nJhangiani, R. S., Chiang, I. -C. A., Cuttler, C., & Leighton, D. C. (2019). Research methods in \npsychology  (4th ed.). Kwantlen Polytechnic University. \nhttps://doi.org/10.17605/OSF.IO/HF7DQ    \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  74 \nJohnson, J. (2022). Worldwide digital population as of April 2022 . Statista. \nhttps://www.statista.com/statistics/617136/digital -population -worldwide/    \nJohnson, H. M., & Seifert, C. M. (1994). Sources of the continued influence effect: When \nmisinformation in memory affects later inferences. Journal of Experimental \nPsychology: Learning, Memory, and Cognition , 20(6), 1420 \u20131436. \nhttps://doi.org/10.1037/0278 -7393.20.6.1420  \nKanozia, R., Kaur, S., & Arya, R. (2021). Infodemic during the COVID -19 lockdown in India. \nMedia Asia , 48(1), 58 \u201366. https://doi.org/10.1080/01296612.2021.1881286   \nKlatzky, R. L., & Erdelyi, M. H. (1985). The response criterion problem in tests of hypnosis \nand memory. International Journal of Clinical and Experimental Hypnosis , 33(3), \n246\u2013257. https://doi.org/10.1080/00207148508406653   \nLazer, D. M. J., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, F., \nMetzger, M. J., Nyhan, B., Pennycook, G., Rothschild, D., Schudson, M., Sloman, S. \nA., Sunstein, C. R., Thorson, E. A., Watts, D. J., & Zittrain, J. L. (2018). The s cience \nof fake news. Science , 359(6380), 1094 \u20131096. \nhttps://doi.org/10.1126/science.aao2998   \nLee, M. D., & Wagenmakers, E. -J. (2013). Bayesian cognitive modelling: A practical course . \nCambridge University Press. \nhttps://psycnet.apa.org/doi/10.1017/CBO9781139087759   \nLewandowsky, S., Ecker, U. K. H., Seifert, C. M., Schwarz, N., & Cook, J. (2012). \nMisinformation and its correction: continued influence and successful debiasing. \nPsychological Science in the Public Interest , 13(3), 106 \u2013131. \nhttps://doi.org/10.1177%2F1529100612451018   \nMaertens, R., Roozenbeek, J., Basol, M., & van der Linden, S. (2021). Long -term \neffectiveness of inoculation against misinformation: three longitudinal experiments. \nJournal of Experimental Psychology: Applied , 27(1), 1 \u201316. \nhttps://psycnet.apa.org/doi/10.1037/xap0000315  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  75 \nMandrekar, J. N. (2010). Receiver operating characteristic curve in diagnostic test \nassessment. Journal of Thoracic Oncology , 5(9), 1315 \u20131316. \nhttps://doi.org/10.1097/jto.0b013e3181ec173d  \nMcGinnies, E. (1949). Emotionality and perceptual defense. Psychological Review , 56(5), \n244\u2013251. https://doi.org/10.1037/h0056508  \nMcGuire, W. J. (1964). Some contemporary approaches. In L. Berkowitz (Ed.), Advances in \nExperimental Social Psychology  (Vol. 1, pp. 191 \u2013229). Academic Press. \nhttps://doi.org/10.1016/S0065 -2601(08)60052 -0 \nMemon, A., & Higham, P. A. (1999). A review of the cognitive interview. Psychology, Crime \nand Law , 5(1\u20132), 177 \u2013196. http://dx.doi.org/10.1080/10683169908415000   \nMessori, A., Damuzzo, V., Agnoletto, L., Leonardi, L., Chiumente, M., & Mengato, D. (2019). \nA model -independent method to determine restricted mean survival time in the \nanalysis of survival curves. SN Comprehensive Clinical Medicine , 2(1), 66 \u201368. \nhttps://doi.org/10.1007/s42399 -019-00199 -7  \nMicallef, N., Avram, M., Menczer, F., & Patil, S.  (2021). Fakey: a game intervention to \nimprove news literacy on social media. Proceedings of the ACM on Human -\nComputer Interaction , 5(CSCW1), Article 6. https://doi.org/10.1145/3449080   \nMickes, L., Flowe, H. D., & Wixted, J. T. (2012). Receiver operating characteristic analysis of \neyewitness memory: Comparing the diagnostic accuracy of simultaneous versus \nsequential lineups. Journal of Experimental Psychology: Applied , 18(4), 361 \u2013376. \nhttps://doi.org/10.1037/a0030609   \nModirrousta -Galian, A., & Higham, P. A. (2022, December 21). Gamified Inoculation \nInterventions Do Not Improve Discrimination Between True and Fake News:  \nReanalyzing Existing Research With Receiver Operating Characteristic Analysis. \nhttps://doi.org/10.17605/OSF.IO/85BE7   \nModirrousta -Galian, A., Higham, P. A., & Seabrooke, T. ( in press ). Effects of inductive \nlearning and gamification on news veracity discernment . Journal of Experimental \nPsychology : Applied . \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  76 \nMorschheuser, B., Hamari, J., & Koivisto, J. (2016). Gamification in crowdsourcing: a review. \nProceedings of the 49th Annual Hawaii International Conference on System \nSciences , 4375 \u20134384. https://doi.org/10.1109/HICSS.2016.543   \nMukhtar, S. (2021). Psychology and politics of COVID -19 misinfodemics: Why and how do \npeople believe in misinfodemics? International Sociology , 36(1), 111 \u2013123. \nhttps://doi.org/10.1177/0268580920948807  \nMumpower, J. L., & McClelland, G. H. (2014). A signal detection theory analysis of racial \nand ethnic disproportionality in the referral and substantiation processes of the U.S. \nchild welfare services system. Judgment and Decision Making , 9(2), 114 \u2013128. \nhttps://journal.sjdm.org/13/13422/jdm13422.html   \nPennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived \naccuracy of fake news. Journal of Experimental Psychology: General , 147(12), \n1865 \u20131880. https://doi.org/10.1037/xge0000465   \nPennycook, G., & Rand, D. G. (2019). Cognitive reflection and the 2016 U.S. presidential \nelection. Personality and Social Psychology Bulletin , 45(2), 224 \u2013239. \nhttps://doi.org/10.1177/0146167218783192   \nPertwee, E., Simas, C., & Larson, H. J. (2022). An epidemic of uncertainty: rumors, \nconspiracy theories and vaccine hesitancy. Nature Medicine , 28(3), 456 \u2013459. \nhttps://doi.org/10.1038/s41591 -022-01728 -z  \nPhelan, J. C., Cruz -Rojas, R., & Reiff, M. (2011). Genes and stigma: The connection \nbetween perceived genetic etiology and attitudes and beliefs about mental illness. \nPsychiatric Rehabilitation Skills , 6(2), 159 \u2013185. \nhttps://doi.org/10.1080/10973430208408431   \nPollack, I., & Hsieh, R. (1969). Sampling variability of the area under the ROC -curve of d \u2032e. \nPsychological Bulletin , 71(3), 161 \u2013173. \nhttps://psycnet.apa.org/doi/10.1037/h0026862  \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  77 \nRatcliff, R., Sheu, C. -F., & Gronlund, S. D. (1992). Testing global memory models using \nROC curves. Psychological Review, 99 (3), 518 \u2013535. https://doi.org/10.1037/0033 -\n295X.99.3.518  \nRead, J., & Harr\u00e9, N. (2009). The role of biological and genetic causal beliefs in the \nstigmatisation of \u2018mental patients\u2019. Journal of Mental Health , 10(2), 223 \u2013235. \nhttps://doi.org/10.1080/09638230123129   \nRead, J. (2011). Why promoting biological ideology increases prejudice against people \nlabelled \u201cschizophrenic\u201d. Australian Psychologist , 42(2), 118 \u2013128. \nhttps://doi.org/10.1080/00050060701280607   \nRhodes, M. G., & Jacoby, L. L. (2007). On the dynamic nature of response criterion in \nrecognition memory: Effects of base rate, awareness, and feedback. Journal of \nExperimental Psychology: Learning, Memory, and Cognition , 33(2), 305 \u2013320. \nhttps://doi.org/10.1037/0278 -7393.33.2.305  \nRoozenbeek, J., Maertens, R., McClanahan, W., & van der Linden, S. (2020). Disentangling \nitem and testing effects in inoculation research on online misinformation: Solomon \nrevisited. Educational and Psychological Measurement , 81(2), 340 \u2013362. \nhttps://doi.org/10.1177/0013164420940378  \nRoozenbeek, J.,  Traberg, C. S., & van der Linden, S. (2022) Technique -based inoculation \nagainst real -world misinformation. Royal Society Open Science , 9(5), Article 211719. \nhttps://doi.org/10.1098/rsos.211719   \nRoozenbeek, J., & van der Linden, S. (2019). Fake news game confers psychological \nresistance against online misinformation. Palgrave Communications , 5, Article 65. \nhttps://doi.org/10.1057/s41599 -019-0279 -9 \nRotello, C. M., Heit, E., & Dub\u00e9, C. (2015). When more data steer us wrong: Replications \nwith the wrong dependent measure perpetuate erroneous conclusions. Psychonomic \nBulletin & Review , 22(4), 944 \u2013954. https://doi.org/10.3758/s13423 -014-0759 -2  \nSaleh, N. F., Roozenbeek, J., Makki, F. A., McClanahan, W. P., & van der Linden, S. (2021).  \nActive inoculation boosts attitudinal resistance against extremist persuasion \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  78 \ntechniques: A novel approach towards the prevention of violent extremism. \nBehavioural Public Policy , 1\u201324. https://doi.org/10.1017/bpp.2020.60    \nSee, J. E., Warm, J. S., Dember, W. N., & Howe, S. R. (1997). Vigilance and signal \ndetection theory: An empirical evaluation of five measures of response bias. Human \nFactors: The Journal of the Human Factors and Ergonomics Society , 39(1), 14 \u201319. \nhttps://doi.org/10.1518/001872097778940704   \nSnodgrass, J. G., & Corwin, J. (1988). Pragmatics of measuring recognition memory: \napplications to dementia and amnesia. Journal of Experimental Psychology: General , \n117(1), 34 \u201350. https://doi.org/10.1037/0096 -3445.117.1.34   \nStanislaw, H., & Todorov, N. (1999). Calculation of signal detection theory measures. \nBehavior Research Methods, Instruments, & Computers , 31(1), 137 \u2013149. \nhttps://doi.org/10.3758/bf03207704   \nSteblay, N. K., Dysart, J. E., & Wells, G. L. (2011). Seventy -two tests of the sequential lineup \nsuperiority effect: A meta -analysis and policy discussion. Psychology, Public Policy, \nand Law , 17(1), 99 \u2013139. https://doi.org/10.1037/a0021650   \nSwift, J. (2012). Political lying . Bartleby. https://www.bartleby.com/209/633.html  (Original \nwork published 1710)  \nTasche, D. (2008). Validation of internal rating systems and PD estimates. In G. \nChristodoulakis & S. Satchell (Eds.), The analytics of risk model validation  (pp. 169 \u2013\n196). Elsevier. https://doi.org/10.1016/B978 -075068158 -2.50014 -7  \nTay, L. Q., Hurlstone, M. J., Kurz, T., & Ecker, U. K. H. (2021). A comparison of prebunking \nand debunking interventions for implied versus explicit misinformation. British Journal \nof Psychology , 113(3), 591 \u2013607. https://doi.org/10.1111/bjop.12551   \nUrban, A., Moore, J., & Hewitt, C. (20 19). Fake it to make it, media literacy, and persuasive \ndesign: Using the functional triad as a tool for investigating persuasive elements in a \nfake news simulator. Proceedings of the Association for Information Science and \nTechnology , 55(1), 915 \u2013916. https://doi.org/10.1002/pra2.2018.14505501174   \nHOW EFFECTIVE ARE GAMIFIED INOCULATION  INTERVENTIONS?  79 \nViechtbauer, W. (2010). Conducting meta -analyses in R with the metafor package. Journal \nof Statistical Software , 36(3), 1 \u201348. https://doi.org/10.18637/jss.v036.i03   \nVan Bavel, J. J., Harris, E. A., P\u00e4rnamets, P., Rathje, S., Doell, K. C., & Tucker, J. A. (2021). \nPolitical psychology in the digital (mis)information age: A model of news belief and \nsharing. Social Issues and Policy Review , 15(1), 84 \u2013113. \nhttps://doi.org/10.1111/sipr.12077   \nWitt, J. K., Taylor, J. E. T., Sugovic, M., & Wixted, J. T. (2015). Signal Detection Measures \nCannot Distinguish Perceptual Biases from Response Biases. Perception , 44(3), \n289\u2013300. https://doi.org/10.1068/p7908   \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Gamified inoculation interventions do not improve discrimination between true and fake news: Reanalyzing existing research with receiver operating characteristic \u2026", "author": ["A Modirrousta-Galian", "PA Higham"], "pub_year": "2023", "venue": "Journal of Experimental \u2026", "abstract": "Gamified inoculation interventions designed to improve the detection of online misinformation  are becoming increasingly prevalent. Two of the most notable interventions of this kind are"}, "filled": false, "gsrank": 529, "pub_url": "https://psycnet.apa.org/fulltext/2023-58664-001.html", "author_id": ["kJz88mAAAAAJ", "QBHtdB0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:v0CujFeokTEJ:scholar.google.com/&output=cite&scirp=528&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D520%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=v0CujFeokTEJ&ei=ZbWsaNbECb_SieoPzJnloAQ&json=", "num_citations": 125, "citedby_url": "/scholar?cites=3571821073457365183&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:v0CujFeokTEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://eprints.soton.ac.uk/475360/2/2023_JEPG_Accepted_Manuscript.pdf"}}, {"title": "The Inventory is Dark and Full of Misinformation: Understanding Ad Inventory Pooling in the Ad-Tech Supply Chain", "year": "2024", "pdf_data": "The Inventory is Dark and Full of Misinformation:\nUnderstanding Ad Inventory Pooling in the Ad-Tech Supply Chain\nYash Vekaria\nUniversity of California, DavisRishab Nithyanand\nUniversity of IowaZubair Sha\ufb01q\nUniversity of California, Davis\nAbstract \u2014Ad-tech enables publishers to programmatically sell\ntheir ad inventory to millions of demand partners through a\ncomplex supply chain. The complexity and opacity of the ad-\ntech supply chain can be exploited by low-quality publishers\n(e.g., misinformation websites) to deceptively monetize their ad\ninventory. To combat such deception, the ad-tech industry has\ndeveloped transparency standards and brand safety products.\nIn this paper, we show that these developments still fall short\nof preventing deceptive monetization. Speci\ufb01cally, we focus on\nhow publishers can exploit the ad-tech supply chain, subvert\nad-tech transparency standards, and undermine brand safety\nprotections by pooling their ad inventory with unrelated sites.\nThis type of deception is referred to as \u201cdark pooling.\u201d Our\nstudy shows that dark pooling is commonly employed by\nmisinformation publishers on various major ad exchanges, and\nallows misinformation publishers to deceptively sell their ad\ninventory to reputable brands. Our work suggests the need for\nimproved vetting of ad exchange supply partners, the adoption\nof new ad-tech transparency standards that enable end-to-end\nvalidation of the ad-tech supply chain, and the widespread\ndeployment of independent audits like ours.\n1. Introduction\nThe complexity of online advertising lends itself to fraud.\nA key to the success of online advertising is the ability\nof advertisers and publishers to programmatically buy and\nsell ad inventory across hundreds of millions of websites\nin real-time [1]. Notably, Real-Time Bidding (RTB) allows\npublishers to list their ad inventory for auction at an ad\nexchange [2]. The ad exchange then asks its demand partners\nto bid on the ad inventory listed by its supply partners, based\non the associated contextual and behavioral information.\nThe ad-tech supply chain is complex because it relies on\nhundreds of specialized entities to effectively buy and sell\nthe ad inventory in real-time and at scale [3]. Adding to this\ncomplexity, each ad impression often gets sold and resold\nthrough multiple parallel or waterfall auctions [4]. Such\nscale and complexity, combined with the opaque nature of\nthe ad-tech supply chain, makes it a ripe target for fraud and\nabuse [5]\u2013[13]. One of the most common types of ad fraud\ninvolves creating low-quality websites and monetizing their\nad inventory. Fraudsters attempt to drive large volumes of\ntraf\ufb01c to their website through various illicit means such as\nbots, underground marketplaces, traf\ufb01c exchanges, or evendriving legitimate traf\ufb01c through click-bait and viral propa-\nganda [14]\u2013[16]. A notable example that motivated our work\nis that of the \u201cMacedonian fake news complex\u201d [17]\u2013[19].\nIn this scheme, fraudsters created misinformation websites\nwith misleading and clickbait headlines, aiming to go viral\non social media, which led to tens of millions of monetized\nad impressions.\nAdvertisers are invested in preventing fraud. Ad-tech has\nsafeguards to protect against this type of ad fraud by block-\ning the ad inventory of low-quality websites even when the\nad impressions might be from legitimate users. Speci\ufb01cally,\nbrand safety features supported by demand-side platforms\naim to allow advertisers to block ad inventory of web pages\nthat contain hardcore violence, hate speech, pornography,\nor other types of potentially objectionable content [20].\nAll the effort of fraudsters would be wasted if they are\nunable to monetize their ad inventory through programmatic\nadvertising due to these brand safety features. Fraudsters\nare known to exploit the opaque nature of the complex ad-\ntech supply chain to undermine brand safety protections\nby misrepresenting their ad inventory [21]. For example,\nin domain spoo\ufb01ng [22], low-quality publishers mimic the\nURLs of reputable publishers in their ad inventory, thus\ndeceiving reputable brands into purchasing their ad space\neven when their original domain is blocked due to brand\nsafety concerns [23]\u2013[25]. To combat ad fraud resulting\nfrom misrepresented ad inventory, the Interactive Advertis-\ning Bureau (IAB) introduced two transparency standards.\nads.txt [26] requires publishers to disclose all authorized\nsellers of their ad inventory. sellers.json [27] requires\nad exchanges to disclose all publishers and intermediate\nsellers involved in selling the ad inventory. Together, when\ncorrectly implemented, these standards can reduce ad fraud\nby enabling buyers to verify the sources of the inventory\nthey are purchasing.\nTransparency mechanisms to prevent fraud are falling\nshort. There is increasing concern that the ads.txt and\nsellers.json standards are either not widely adopted,\nimplemented in ways that do not facilitate effective supply-\nchain validation, or intentionally subverted by malicious\nactors in a variety of ways. In this paper, we empirically\ninvestigate these concerns. We \ufb01nd that the ads.txt and\nsellers.json disclosures are plagued by a large number\nof compliance issues and misrepresentations. Most notably,\nwe \ufb01nd extensive evidence of \u201cpooling\u201d of ad inventoryarXiv:2210.06654v3  [cs.CR]  14 Oct 2023\nfrom unrelated websites \u2014 a practice known in the industry\nas \u201cdark pooling.\u201d This makes it impossible for a buyer\nto reliably identify the sources of the ad inventory (i.e.,\nwhere their ad will ultimately be placed). Dark pooling\neffectively enables low-quality publishers to \u201claunder\u201d their\nad inventory, making it indistinguishable from that of well-\nreputed publishers. To gain insight into how low-quality\npublishers might circumvent the transparency required by\ntheads.txt andsellers.json standards, we selected\na set of well-known misinformation websites as a case\nstudy. This choice is motivated by the known instances\nwhere ads from reputable brands have inadvertently ended\nup on such websites in the past [28]\u2013[33]. Focusing on these\nmisinformation websites, we con\ufb01rm: (1) their widespread\nfailure to comply with the ads.txt andsellers.json\nstandards; and (2) widespread prevalence of ad inventory\npooling. We also \ufb01nd instances of reputable brands buying\nad impressions on these misinformation websites, perhaps\nunintentionally. Taken together, we make three key contri-\nbutions.\nMeasuring compliance with the transparency standards of\nads.txt andsellers.json .We study a set of control\nand well-known misinformation websites to compare their\ncompliance with ads.txt andsellers.json . We \ufb01nd\nthat although compliance issues are widespread even in the\ncontrol set of websites, they are signi\ufb01cantly more prevalent\non misinformation websites.\nMeasuring the prevalence of (dark) pooling. We measure\nthe high prevalence of ad inventory pooling by our control\nand misinformation websites. By analyzing the ads.txt\nandsellers.json \ufb01les, we identi\ufb01ed nearly 80 thousand\ninstances of pooling. We \ufb01nd that the misinformation pools\nare signi\ufb01cantly more than twice as likely to pool ad inven-\ntory from unrelated websites than those that do not contain a\nmisinformation website. Upon further analysis of ad-related\nmetadata in network traf\ufb01c, we con\ufb01rmed the use of 297\npools across 38 ad exchanges by misinformation websites.\nMeasuring the (in)effectiveness of brand safety tools. We\n\ufb01nd ads from 55 reputable brands, including Forbes, Go-\nDaddy, Harvard, Intel, Microsoft, Nike, Samsung, Tumblr,\nYahoo!, Verizon, and Wayfair, on misinformation websites.\nWe investigate the correlation between the prevalence of\npooling and ads from reputable brands on misinformation\nwebsites. We \ufb01nd that misinformation websites that are part\nof at least one dark pool are nearly 20% more likely to\nattract ads from reputable brands than those that are not part\nof a dark pool. The responses to our disclosures indicate\nthat reputable brands are generally unaware of their ads\nappearing on misinformation websites despite several using\na brand safety service.\nWhile there is some anecdotal evidence of a general\nlack of compliance with the ad-tech transparency standards\nand dark pooling [34], [35], it does not systematically study\nthese issues at scale. To the best of our knowledge, our\nwork is the \ufb01rst to systematically study compliance with ad\ntransparency standards and (dark) pooling at scale.\nAd\nAdvertisersDSPSSPAd exchangePublisherUsersellers.jsonads.txt1234\nFigure 1: Programmatic advertising ecosystem: When a user\nvisits a publisher website (Step \u2202), the publisher puts its\nad-inventory for sale on ad exchanges via SSPs in real-\ntime (Step \u2211). Advertisers bid for these slots via DSPs\n(Step \u220f). Advertisement of the winning bid is displayed\nto the user on the publisher website (Step \u03c0). To mitigate\nfraud, advertisers use sellers.json of ad exchanges and\nads.txt of publishers to verify who is and who is not an\nauthorized seller of a given inventory.\n2. Background\nIn this section, we provide a high-level overview of the\nmechanisms behind the supply of programmatic ads (\u00a72.1)\nand the vulnerabilities in the ad supply chain (\u00a72.2).\n2.1. Programmatic advertising\nAlthough there are a variety of mechanisms for program-\nmatic advertising (e.g., real-time bidding, header bidding,\nexchange bidding) and the participating organizations might\ndiffer, the types of entities involved in the supply chain\nremain the same for each mechanism.\nThe programmatic advertising supply chain. Program-\nmatic advertising is made possible by the following entities\nillustrated in Figure 1: supply-side platforms (SSPs) for pub-\nlishers to list their ad inventory in real-time, ad exchanges\n(AdX) which aggregate the inventory of multiple SSPs and\nfacilitate bidding on individual ad slots, and demand-side\nplatforms (DSPs) which allow advertisers and brands to\nidentify targets for their ad creatives by suitably bidding\non the inventory listed at ad exchanges. These entities work\ntogether to create a supply chain for ads as follows: When\na user visits a publisher, the ad inventory associated with\nthat visit is put up for auction at an AdX by the SSP. DSPs,\noperating on behalf of advertisers and brands, then make\nbids on the ad inventory available at the AdX. These bids\nare informed by what is known (to the DSP) about the user\nand the publisher. The winner of the auction is then noti\ufb01ed\nby the AdX and the associated ad creative is used to \ufb01ll the\nad slot on the publisher\u2019s website.\nTransparency in the supply chain. Crucial to the operation\nof the ad supply chain is that the participating organizations\ncan trust that publishers and AdXs are not misrepresenting\ntheir inventories or their relationships with other entities. For\nexample, DSPs need to con\ufb01rm that the ad inventory that\nthey are bidding on is actually associated with a particular\npublisher. Similarly, DSPs also need to con\ufb01rm that the\nAdXs that they are purchasing ad inventory from are actually\nauthorized to (re)sell that inventory. The absence of trust in\n2\nthis supply chain can lead to situations where DSPs place\npremium bids for ad slots that are actually associated with\nnon-premium publishers \u2014 ultimately leading to a brand\u2019s\nad creative appearing on websites that they may not want\nto be associated with. To foster trust and enable DSPs\n(Demand-Side Platforms) to perform basic veri\ufb01cation of\nthe ad inventory, the Interactive Advertising Bureau (IAB)\nintroduced two standards: ads.txt andsellers.json .\nThe ads.txt standard. The ads.txt1standard\n(introduced in 2017) aims to address ad inventory\nfraud by requiring each publisher domain to main-\ntain an ads.txt \ufb01le at the root level directory (e.g.,\npublisher.example/ads.txt ). The ads.txt \ufb01le is\nsupposed to contain entries for all AdXs that are authorized\nto sell or resell the ad inventory of the publisher. Each entry\nin the ads.txt \ufb01le contains the following \ufb01elds:\n\u2022the authorized AdX,\n\u2022the publisher ID assigned to the publisher domain within\nthe AdX network, and\n\u2022the authorized relationship between the publisher and\nauthorized AdX \u2014 i.e., whether the AdX is authorized\nas a DIRECT seller or RESELLER of inventory for the\ndomain.\nHow ads.txt helps prevent fraud. When an ad request is\nsent by a publisher to an AdX (which issues bid requests\nto DSPs), the request contains the publisher ID and the\ndomain associated with the inventory being listed. Impor-\ntantly, because publisher IDs are typically associated with\nan organization and not a domain, it is possible for multiple\ndomains to share the same publisher ID. ads.txt enables\nveri\ufb01cation that a website is not spoo\ufb01ng the domain in their\nad requests. More speci\ufb01cally, ads.txt allows:\n\u2022AdXs to verify that the publisher ID in the ad request\nmatches the publisher ID associated with the domain in\nthe ad request and\n\u2022DSPs to verify that the AdX claiming to (re)sell the\ninventory of a domain is authorized by the domain to\ndo so.\nBefore the ads.txt standard, there were no mechanisms\nto facilitate such checks and the sale of fraudulent inventory\nwas widespread [21].\nThe sellers.json standard. Similar to the\nads.txt standard, sellers.json aims to miti-\ngate ad inventory fraud and misrepresentation. The\nsellers.json standard2requires each AdX and SSP\nto maintain a sellers.json \ufb01le at the root level\ndirectory (e.g., adx.example/sellers.json ).3This\nsellers.json \ufb01lemust contain an entry for each entity\nthat may be paid for inventory purchased through the AdX\n1. \u201cads\u201d in ads.txt stands for Authorized Digital Sellers. Full spec-\ni\ufb01cation of the ads.txt standard is available at: https://iabtechlab .com/\nwp-content/uploads/2021/03/ads .txt-1 .0.3.pdf\n2. Full speci\ufb01cation of the sellers.json standard is available at:\nhttps://iabtechlab .com/wp-content/uploads/2019/07/Sellers .json Final .pdf\n3. We observed that several AdXs, including Google, use non-\nstandard paths \u2014 e.g., Google\u2019s sellers.json is located at https:\n//storage .googleapis .com/adx-rtb-dictionaries/sellers .json\u2014 i.e., one entry for each partner that is an inventory\nsource for the AdX. Each entry in the sellers.json\n\ufb01le contains the following \ufb01elds:\n\u2022the seller type which indicates whether the entry is as-\nsociated with a PUBLISHER , anINTERMEDIARY (i.e.,\ninventory reseller AdX), or BOTH (i.e., this entity has\ntheir own inventory and also resells other inventory);\n\u2022the seller ID associated with the inventory source (same\nas the publisher ID in ads.txt if this entry is associated\nwith a publisher. From this point onwards we will refer\nto seller ID or publisher ID as seller ID); and\n\u2022the name and domain associated with the seller ID (these\n\ufb01elds may be marked as \u201ccon\ufb01dential\u201d by AdXs to\nprotect the privacy of publishers).\nHow sellers.json helps prevent fraud. When a bid\nrequest is received by a DSP from an AdX that is compliant\nwith the sellers.json standard, it must contain infor-\nmation about the provenance of the inventory in a Supply\nChain Object (SCO).4At a high level, the sellers.json\n\ufb01le provides a mechanism for DSPs to identify and verify\nall the entities listed in this SCO. This is done as follows:\n\u2022When a bid request is received by the DSP, it should use\nthe AdX\u2019s sellers.json \ufb01le to verify that the \ufb01nal\nAdX has an authorized relationship with the prior holder\n(an SSP or another AdX) of the inventory.\n\u2022The previous step is applied recursively (on all inter-\nmediate neighbors in the SCO) to verify the end-to-end\nauthenticity of the inventory.\n\u2022The DSP then uses the sellers.json \ufb01les of all\nintermediaries and the ads.txt \ufb01le of the publisher to\nverify that the publisher is legitimate and (re)sellers who\nhandle the publisher\u2019s inventory are authorized to do so.\nThis capability for end-to-end validation of the SCO (Supply\nChain Object) allows DSPs to identify instances where the\nad inventory originates from low-quality publishers using\nfraudulent ads.txt \ufb01les or is being sold by malicious\nintermediaries.\n2.2. Supply chain vulnerabilities\nDespite the introduction of the ads.txt and\nsellers.json standards, there remain various vulner-\nabilities in the ad inventory supply chain. Our investiga-\ntion focuses on the vulnerabilities that enable low-quality\npublishers to monetize their ad inventory by misrepresent-\ning or obscuring its source. Some of these vulnerabili-\nties arise from misrepresentations in the ads.txt and\nsellers.json \ufb01les, while others arise from pooling their\nlow-quality inventory with the inventory of unrelated high-\nquality publishers. We refer to the former as inventory\nmisrepresentation and the latter as dark pooling .\nInventory misrepresentation. Inventory misrepresentation\narises from misrepresentations of ad inventory by publishers.\nIt can be identi\ufb01ed by discrepancies in the publisher\u2019s\n4. Supply Chain Object (SCO) contains an ordered list of all the entities\ninvolved in the ad transaction (e.g., publisher !SSP !reseller !AdX).\n3\nads.txt \ufb01le and is possible when DSPs and AdXs do\nnot follow the ads.txt andsellers.json standards.\nSome examples of these misrepresentations include:\n\u2022a publisher\u2019s ads.txt \ufb01le might incorrectly use seller\nIDs of other publishers to suggest an authorized relation-\nship with an AdX to boost the perception of its inventory.\n(Misrepresentations #1 and #2)\n\u2022a publisher\u2019s ads.txt \ufb01le might incorrectly indicate\nthat a popular AdX is an authorized (re)seller of its\ninventory to boost its reputation with other AdXs. (Mis-\nrepresentation #3)\n\u2022a publisher\u2019s ads.txt \ufb01le might have more than\none entry of the same seller type for an AdX or\nsellers.json \ufb01les might associate a seller ID with\nmultiple publishers or sellers making ads.txt and\nsellers.json veri\ufb01cation unreliable. (Misrepresenta-\ntions #4 and #9)\n\u2022a publisher\u2019s ads.txt \ufb01le might list authorized relation-\nships with (re)sellers that do not have sellers.json\n\ufb01les, making end-to-end veri\ufb01cation impossible. (Misrep-\nresentation #8)\nDark pooling. Pooling is a common strategy to share\nresources in online advertising. Consider, for example, the\ncase where two or more publishers are owned by the same\nparent organization. In such scenarios, the ability to share\nadvertising infrastructure and AdX accounts allows for more\nef\ufb01cient operation and management. One way to identify\nthe occurrence of pooling is by noting a single AdX-\nissued \u2018seller ID\u2019 shared by multiple publisher websites.\nDark pools are pools in which seller IDs are shared by\norganizationally-unrelated publishers (possibly of differing\nreputation). Note that \u201cdark pooling\u201d is a term of art that\nis commonly used in industry. While pooling is not itself a\n\u201cdark\u201d practice, pooling seller IDs of unrelated publishers\nis considered a \u201cdark\u201d practice because it deceives potential\nbuyers about the actual source of the ad inventory [34], [35].\nThe seller ID de\ufb01ned in ads.txt and\nsellers.json standards is also de\ufb01ned in the RTB\nprotocol [36], [37]. Note that the payment after successful\ncompletion of an RTB auction is made to the publisher\n(i.e., the seller) associated with the seller ID [38]. Hence,\nit should be noted that simply using another domain\u2019s\nseller ID in ad requests from a website will result in any\nad-related payments being made to the owner of the seller\nID. Therefore, for revenue sharing, the creation of these\npools needs to be facilitated either through intermediaries\n(e.g., SSPs) or by collaboration between publishers.\nEnd-to-end validation of pooled supply chains. Pooling\nleads to a break down of any brand or DSP\u2019s ability to\nperform end-to-end veri\ufb01cation of the ad inventory supply\nchain. Speci\ufb01cally, the \ufb01nal step of veri\ufb01cation highlighted\nin \u00a72.1 cannot be meaningfully completed unless alldo-\nmains associated with a publisher\u2019s account are publicly\nknown (and unfortunately, this is not the case). This is\nbecause the end-to-end veri\ufb01cation of the ad inventory\nsupply chain, as speci\ufb01ed by the IAB, implicitly relies on\ntrust that seller IDs are actually associated with speci\ufb01corganizations and that these associations are veri\ufb01ed by\nAdXs. We illustrate this with an example.\n\u2022Consider a publisher website sportsnews.example\nwhich has a legitimate subsidiary: nbanews.example .\nThe publisher registers for an account with a popular\nAdX ( adx) and is issued the seller ID sellerid after\nbeing vetted by adx. It is expected that this website\ncan now share this seller ID with its subsidiaries. Both\nwebsites will now list adxas a DIRECT seller through\nthesellerid account in their ads.txt \ufb01les.\n\u2022The publisher now decides to share adx-issued\nseller ID with fakesportsnews.example , an-\nother sports news website but of low quality, for\na cut of the revenue generated from ads shown on\nfakesportsnews.example . In its ads.txt \ufb01le,\nfakesportsnews.example now adds adx as a\nDIRECT seller and also lists sellerid as its seller ID.\nNote that fakesportsnews.example would other-\nwise be unable to get directly listed on adxand monetize\nits ad inventory due to its low quality.\n\u2022When an ad request for some inventory is sent from\nfakesportsnews.example , all basic supply chain\nvalidation checks are successful because the seller ID\nsellerid is in fact registered by adx in their\nsellers.json \ufb01le. Any bidding DSP will therefore\noperate under the assumption that the website receiving\ntheir ads has been vetted by adxand is associated with\nsportsnews.example .\n\u2022Complications only arise if the veri\ufb01er notices that\nsellerid was only registered to the owner of\nsportsnews.example and the bid request actu-\nally originated at fakesportsnews.example . How-\never, invalidating the bid request simply because of\nthis inconsistency will mean that even legitimate sub-\nsidiaries such as nbanews.example cannot pool their\ninventory. Instead, additional checks are required to\nascertain whether fakesportsnews.example and\nsportsnews.example are related or whether adx\nvetted fakesportsnews.example as well. This is-\nsue remains unaddressed by current validation mecha-\nnisms.\nCaveat. The example described assumes collaboration\nbetween publishers \u2014 sportsnews.example and\nfakesportsnews.example . This might be inadvertent\nin some cases \u2014 e.g., if sportsnews.example and\nfakesportsnews.example are both assigned the same\nseller ID through a common intermediary (an SSP, for\nexample as shown in Figure 2).\nIn sum, by pooling various unrelated websites under a\nsingle seller ID, low-quality publishers can \u201claunder\u201d their\nad inventory, rendering it indistinguishable from the inven-\ntory of high-quality publishers. Moreover, this can occur\nwhen an AdX provides the seller ID to a trusted publisher\n(or an SSP), which then inadequately vets the low-quality\npublishers whose inventory it pools. Figure 2 illustrates this\nscenario of syndication-based pooling by some intermediary\nSSP. As we show later, such pooling is common. In fact, we\n4\nAdvertisersPublishers\nokay.examplegood.examplessp.exampleAd exchange\nSample ad inventoryA1A2\nDomain:okay.examplesellerID:A2\nbad.example\nFigure 2: Illustration of pooling by an SSP \u2014 A premium\npublisher ( good.example ) or an AdX-trusted intermedi-\nary SSP ( ssp.example ) can list on the AdX to obtain\nseller IDs A1andA2respectively. Whereas, a low-quality\npublisher ( bad.example ) or legitimate but unrecognized\npublisher ( okay.example ) are unable to directly list on\nthe AdX. A legitimate publisher may not get listed on the\nAdX because, for instance, traf\ufb01c requirements are not met.\nHowever, bad.example andokay.example are able\nto list on SSP, which essentially pools multiple publish-\ners together. Bid request may misrepresent the inventory\nonbad.example as that of okay.example using the\nseller ID of the SSP (i.e., A2). Reputable advertisers may\nbid on the inventory assuming that they are bidding on\nokay.example , when in fact their ad actually would end\nup on bad.example .\n\ufb01nd some AdXs even providing services, via intermediaries,\nthat facilitate pooling of unrelated entities.\n3. Data\nIn this section, we describe the selection of publishers\nthat we study (\u00a73.1) and our methodology for collection\nofads.txt ,sellers.json , and ad-related metadata\nassociated with these websites (\u00a73.2).\n3.1. Publisher website selection\nOur goal is to identify practices that hinder the end-to-\nend validation of the ad inventory supply chain, both among\nhigh-quality and low-quality websites. We use misinforma-\ntion websites as a case study for low-quality websites and\nuse comparably ranked websites from the Tranco list [39]\nthat have ads.txt as a stand-in for high-quality websites\n(referred to as a control).\nSelection of misinformation websites. Since identifying\nmisinformation websites is itself not the focus of our work,\nwe leverage lists of misinformation websites curated in\nprior research by media scholars [40], [41] and computer\nscientists [42], [43].5To construct our list of misinformation\nwebsites, we began by aggregating all websites from these\n5. For websites obtained from [41], we discard those labeled as \u2018state\u2019,\n\u2018political\u2019, \u2018credible\u2019, and \u2018unknown\u2019.Notation Description Size\nMfull Complete set of misinformation domains studied 669\nMranked Sites in Mfullwith ads.txt & part of Tranco-1M 251\nCranked Similar-ranked NM with ads.txt for each Mranked 251\nC100K Tranco Top-100K domains with ads.txt presence 20K\nDstaticads.txt andsellers.json crawled on 02/22 1.4K\nDcrawls(PD, AdX, OD) tuples from dynamic crawl of Mfull 2.8K\nDbrands(PD, Brand) pairs from dynamic crawl of Mfull 4.2K\nTABLE 1: Description of dataset notations and sizes. NM\nrepresents non-misinformation websites. PD and OD repre-\nsent publisher domain and owner domain respectively.\nlists and removing duplicates. This left us with 1276 web-\nsites. Next, we discarded 434 websites that were no longer\nfunctional. Finally, we additionally classi\ufb01ed each misinfor-\nmation website using multiple independent sources includ-\ning Politifact, Snopes, MBFC, OpenSources, PropOrNot,\nand FakeNewsCodex to ensure that each remaining web-\nsites contained content that was undeniably misinformation.\nWe excluded the websites that were now parked domains,\nseemed to have been repurposed, or had con\ufb02icting labels\nacross different sources. This left us with a set of 669 mis-\ninformation websites (Mfull). Of these 669 websites, we cre-\nated a subset of all the 251 websites that had an ads.txt\n\ufb01le and were also present in the Tranco top-million list\n[39] ( Mranked). We use Mranked to compare the prevalence\nofads.txt andsellers.json discrepancies between\nmisinformation and non-misinformation websites.\nSelection of benign (control) websites. To facilitate com-\nparisons of the prevalence of compliance issues between\nmisinformation and benign websites, we created a control\nset of non-misinformation websites ( Cranked). For each web-\nsite in Mranked, we included the most similarly ranked non-\nmisinformation website that also had an ads.txt \ufb01le.\nWe performed matching based on website domain ranks\nto avoid confounds related to website popularity. We also\ncreated a control set of the Tranco top-100K domains which\ncontained an ads.txt \ufb01le ( C100K). This dataset was used\nto investigate the broad prevalence of pooling. These four\nsets of websites ( Mfull,Mranked,Cranked, and C100K) are the\nsubject of our study.\n3.2. Data collection\nOur analysis relies on three sources of data: (1)\nads.txt andsellers.json \ufb01les related to publishers,\nAdXs, and other intermediaries; (2) bid/ad requests and\nresponses during visits to a publisher domain; and (3) brands\nplacing advertisements on a publisher domain. An overview\nof our data collection is illustrated in Figure 3. Table 1\nlists the notations for different datasets used throughout the\npaper.\nads.txt and sellers.json \ufb01les. To build evi-\ndence for the occurrence of pooling and other misrepre-\nsentations, we need to analyze published ads.txt and\nsellers.json \ufb01les associated with publishers and ad-\ntech entities.\n5\nads.txtcrawler sellers.jsoncrawlerExtract distinctseller domains\nVisit the siteHAR file dumpDstatic\nDbrands\nExtract URLs<iframe><a>browser req. tracesRetain ad URLsClick ad URLExtract landing domainDcrawls{Publisher, AdX, Owner}\nads.txt\nsellers.jsonMfull\n     https://brand.exampleExtract domain triplets\nC100KCrankedFigure 3: Overview of data collection methodology.\nProcessing ads.txt \ufb01les. We searched for an ads.txt\n\ufb01le at the root of each website in Mfull,Mranked,Cranked, and\nC100K. From these ads.txt \ufb01les, we extracted the domains\nof all the entities that were listed as DIRECT sellers or\nRESELLERS of the publisher\u2019s inventory.\nProcessing sellers.json \ufb01les. For each seller identi\ufb01ed\nin our ads.txt \ufb01les, we crawled the sellers.json\n\ufb01le at the domain\u2019s root. When the sellers.json \ufb01le\nwas unavailable at this path, a best-effort attempt was\nmade to manually identify any non-standard location of\nthis \ufb01le. We manually searched for the sellers.json\nfor the top-1K ranked seller domains that were detected\nasINTERMEDIARY orBOTH and no sellers.json\nwas extracted by the crawler for that domain. We per-\nformed a web search using \u201c <domain >\u2013 sellers.json\u201d\nquery and looked for the JSON \ufb01le on the of\ufb01cial web-\npage of the seller. Two sellers.json were detected\nin this manner \u2013 google.com and pubmatic.com. We then\nparsed each sellers.json \ufb01le to identify entities (and\ntheir domains) that were associated with PUBLISHER ,\nINTERMEDIARY , or BOTH entries. Finally, until no new\nentities were discovered, we recursively fetched and parsed\nthesellers.json \ufb01le associated with the entities labeled\nas either INTERMEDIARY orBOTH . This recursive fetching\nensures that we have complete coverage of all the supply\nchain entities that may sell the inventory of all publishers\nin our datasets.\nTheDstaticdatasets. We crawled and processed ads.txt\nandsellers.json \ufb01les in February 2022. We refer to\nthe dataset as Dstatic. In total, Dstaticincluded over 98K\nrelationships from ads.txt \ufb01les and 2.4M relationships\nfrom sellers.json \ufb01les.\nLimitations of this dataset. It should be noted that, by itself,\nthis dataset cannot present evidence that pooling is actually\noccurring. This is because each publisher is responsible only\nfor the content of their own ads.txt \ufb01le, misrepresenta-\ntion in other publishers\u2019 ads.txt \ufb01les is not suf\ufb01cient to\nimply pooling.\nObtaining real-time bidding metadata. To identify con-\ncrete evidence of pooling, we constructed a dataset of\nreal-time bidding metadata. These include bid requests, re-\nsponses, redirects, and payloads associated with ad requests\nand responses. Seller ID is communicated in requests and\nresponses to different entities in the advertising ecosystem.\nTherefore, during a crawl of a given publisher\u2019s website,\"seller_id\": \"pub-3740653521982427\",\"seller_type\": \"PUBLISHER\", \"domain\": \"volcanodiscovery.com\"https://googleads.g.doubleclick.net/pagead/ads?client=ca-pub-3740653521982427&output=html&h=0&adk=4200137118&adf=4165721491&w=0&rafmt=12&psa=0&url=https%3A%2F%2Fgalacticconnection.com%2F&format=0x0&ea=0&flash=0&...AdXsellerIDseller domain Ad-request captured on publisher domain: galacticconnection.com (no ads.txt):owner domaingoogle.com, pub-3740653521982427, DIRECThttps://realtimebidding.google.com/sellers.jsonhttps://volcanodiscovery.com/ads.txt\n(a) True positive case of ID matching an ad request\"seller_id\": \"57734\",\"seller_type\": \"INTERMEDIARY\", \"domain\": \"google.com\"https://medianet-match.dotomi.com/match/bounce/current?DotomiTest=47eb4cc43fa7123c&is_secure=true&version=1&networkId=57734&redir=https%3A%2F%2Fcontextual.media.net%2Fcksync.php%3Fcs%3D8%26vsid%3D2907665791192295...AdXsellerIDseller domain Ad-request captured on publisher domain: ufoholic.com:owner domainNo matching entry forsellerID: 57734https://yahoo.com/sellers.jsonhttps://ufoholic.com/ads.txt\n(b) False positive case of ID matching in an ad request\nFigure 4: Illustration of seller ID matching in ad requests\nfor (a) true positive on the misinformation website: galactic-\nconnection.com and (b) false positive on the misinformation\nwebsite: ufoholic.com.\nobserving an unrelated entity\u2019s seller ID in these metadata\nconstitutes a more concrete evidence of pooling between\nthem.\nCrawling con\ufb01guration. Following the best practices for\ncrawling-based data collection [44], [45], we collected this\ndataset using a web crawler driven by Selenium (v4.1.0) and\nthe Chrome browser (v91.0) with bot mitigation strategies\n(multiple randomly timed full page scrolls and randomized\nmouse movements), Xvfb from a non-cloud vantage point,\nand a 30-second waiting time after the completion of each\npage load. Prior work has shown that the bidders and content\nof ad slots are impacted by previous browsing history [46],\n[47]. Therefore, each page load was conducted with a new\nbrowser pro\ufb01le to avoid biases in our measurements of\nad responses and content. With these settings, we loaded\neach website twice in Mfulland saved the associated HTTP\nArchive (HAR) \ufb01les and full-page screenshots.\nExtracting real-time bidding metadata from ad-related re-\nquests and responses. From each HAR \ufb01le, we \ufb01rst identi-\n\ufb01ed ad-related requests and responses by matching request\nURLs against well-known advertising \ufb01lter lists used in\n6\nprior research [48]. We extracted the URLs, content, and\nHTTP POST-encoded data from each ad-related request and\nresponse. We then identi\ufb01ed all (key, value) pairs using\nstandard delimiters (e.g., & in query parameters). Finally, we\nmatched the identi\ufb01ed values with the seller IDs in from the\nDstaticdataset. To mitigate false positives, we only matched\nID strings with length greater than \ufb01ve characters.\nFigure 4a shows a sample ad request for doubleclick.net\nthat is matched for the highlighted seller ID. Since vol-\ncanodiscovery.com listed in Google\u2019s sellers.json and\nthe misinformation website galacticconnection.com are un-\nrelated, this represents a true positive instance of dark\npooling. For each ad-related request and response, we iden-\nti\ufb01ed the domain from which the request originated as the\npublisher domain (i.e., observed inventory source) and the\nAdX domain owning the detected seller ID as the AdX\n(i.e., inventory seller). We then used the sellers.json\nof the AdX/inventory seller to identify the domain that\nowned the seller ID found in the ad request. This domain\nis labeled as the owner domain (i.e., expected inventory\nsource). The ( publisher domain ,AdX,owner domain ) triples\nare used in later analysis. Figure 4b also shows a sample ad\nrequest on ufoholic.com, where one of the values matches\nwith a Yahoo-issued seller ID that is owned by Google.\nHowever, Google-associated domains are absent from the ad\nrequest. The seller ID also does not exist in ufoholic.com\u2019s\nads.txt . This match is deemed a false positive match and\ndiscarded from further analysis.\nMethodology validation. We manually evaluated the ac-\ncuracy of our method to extract metadata from ad-related\nrequests. Speci\ufb01cally, we manually examined the requests\nand responses to verify that they did in fact include a key\nthat suggested that the value was associated with a seller\nID. Our manual evaluation gave a false positive rate of 1.5%.\nThe Dcrawlsdataset. We label this dataset of ( publisher\ndomain ,AdX,owner domain ) triples as Dcrawls. In total, the\nDcrawlsdataset consisted of 3.1K distinct triples observed\nacross two crawls of 669 Mfullwebsites. In \u00a74, we use\nthese triples to determine (dark) pooling on misinformation\nwebsites.\nLimitations of this dataset. The programmatic advertising\nis auction-driven and participation from entities is non-\ndeterministic. Therefore, any observations of entities and the\nIDs in requests and responses related to ads will vary from\none crawl to the next, even when all other client-related\nfactors are identical. Further, the browser provides a vantage\npoint that typically only affords observations of the winners\nof real-time bidding auctions. Finally, it is possible that some\ncommunications regarding the involved seller ID are not\nvisible to us due to hashing or other forms of obfuscation\n[49]. These limitations are unavoidable. It should be noted,\nhowever, that these limitations only impact the completeness\nof our \ufb01ndings and not the correctness. In other words, the\nprevalence of pooling and other discrepancies, as measured\nby our crawls, are only a lower-bound for their actual\nprevalence.Identifying brands in advertisements. We also analyzed\nthe brands whose ads appear on misinformation websites.\nTo identify brands advertising on misinformation websites,\nwe performed 10 separate crawls. This repetition was to\naccount for the non-deterministic nature of programmatic\nadvertising that results in a user receiving different ads on\nrepeat visits to the same website. In each of the 10 crawls,\nafter each page load was complete and the 30-second wait\nperiod ended, we clicked the DOM elements associated with\neach ad-related URL on the page. These clicks typically\nresulted in navigation to the brand\u2019s website. We used this\nwebsite\u2019s domain to label the brand associated with the ad.\nMethodology validation. To test the effectiveness of this\nmethodology, we conducted a pilot test on one crawl where\nwe compared the brand names identi\ufb01ed through manual\nanalysis and the automated approach. We found that in 30%\nof the displayed ads, the automated approach failed to iden-\ntify the brand associated with an ad. In these cases, failure\nwas largely because some ad-related request URLs were\nassociated with\u201cunclickable\u201d elements of the ad. As a result,\nour automated approach could not trigger navigation to the\nbrand\u2019s website. To mitigate this issue, we supplemented\nour automated approach by manually annotating the ads on\nall crawls that could not be associated with a brand. This\nprocess was relatively quick since most of the ads had been\nalready automatically annotated with associated brands.\nThe Dbrandsdataset. We recorded all ( publisher, brand )\npairs identi\ufb01ed with this methodology in Dbrandsdataset. In\ntotal, the Dbrandsdataset consisted of 4.2K distinct (publisher,\nbrand) pairs and 2.1K unique brands.\nCrawl success rate. Our crawling infrastructure for\nads.txt andsellers.json had a 100% success rate\n(i.e., if a website had a \ufb01le, we were able to crawl it without\nany failures). Dynamic web crawls did fail for a small\npercentage of websites ( <5%) due to timeouts. However,\nwe were able to crawl all websites at least once since we\nperformed multiple crawls for each website.\nLimitations. We performed all crawls from one IP address,\nwhich could impact our analysis of brands. In other words,\nwe might have observed more or less brands had we per-\nformed crawling from multiple IP addresses.\nEthical considerations. We discuss the ethics of our\nweb crawling along three dimensions: infrastructure costs,\nprivacy risks, and advertising costs caused by this study.\nOverall, our study respects the principle of bene\ufb01cence as\noutlined in the Menlo Report [50] and Belmont Report [51]\nby maximizing the possible bene\ufb01ts and minimizing the\nharms.\nInfrastructure costs. Our crawls were used to measure the\nprevalence of compliance issues and misrepresentations. Our\ntwo dynamic crawls were not conducted concurrently to\navoid stressing the web servers. Similarly, our additional\nstatic crawls for ads.txt andsellers.json were per-\nformed six months apart. While our crawlers did not follow\ntherobots.txt directives (if present) on misinformation\npublishers, our crawling methodology is in line with ethical\n7\nand legal considerations of such crawling-based auditing\nsystems [52]\u2013[54]. Also note that our study did not involve\nhuman subjects or gather any personal information.\nAdvertising costs. To actually understand what brands\nare advertising on misinformation websites and what ad-\nexchange is responsible for showing that ad, we clicked on\nthe ads shown during the page loads. The costs associated\nwith our ad clicks are negligible (CPMs are in the order\nof fractions of cents and we clicked a total of 4247 ads).\nWe believe these costs are justi\ufb01able given the bene\ufb01t of\nunderstanding vulnerabilities in the ad-tech ecosystem.\n4. Measuring Problematic Representations\nIn this section, we answer the question: what is the\nprevalence of pooling and other problematic representations\non misinformation websites? Speci\ufb01cally, we focus on mea-\nsuring the prevalence of misrepresentations that hinder end-\nto-end supply chain validation. In \u00a74.1, we provide a broad\noverview of the types of misrepresentations commonly seen\ninsellers.json andads.txt \ufb01les. We compare the\nprevalence of these misrepresentations on control and mis-\ninformation websites. In \u00a74.2, we present evidence of ad\ninventory pooling and highlight cases of dark pooling by\nmisinformation websites.\n4.1. Prevalence of misrepresentations\nCertain types of misrepresentations in a publisher\u2019s\nads.txt \ufb01le or an AdX\u2019s sellers.json \ufb01le may pro-\nhibit automated end-to-end veri\ufb01cation of the ad inventory\nsupply chain. We identify eight such problematic represen-\ntations:\n1)Misrepresented direct relationships: The Publisher claims\nthat an AdX is a DIRECT seller of its inventory, but the\nAdX\u2019s sellers.json lists it as an INTERMEDIARY\n(reseller) relationship;\n2)Misrepresented reseller relationships: The Publisher\nclaims that an AdX account is a RESELLER of its\ninventory, but the AdX\u2019s sellers.json associates the\ncorresponding account as a PUBLISHER (direct) entry;\n3)Fabricated seller IDs: A publisher\u2019s ads.txt claims\nthat an AdX is authorized to sell its inventory via some\nseller ID, but the AdX\u2019s sellers.json does not have\nanyaccount associated with that speci\ufb01c ID;\n4)Con\ufb02icting relationships: A publisher claims the same\ntype of relationship(s) with more than one seller ID on\na given AdX in their ads.txt , but the AdX only lists\none of these relationships in their sellers.json ;\n5)Invalid seller type: The sellers.json does not\nuse any of the three acceptable types ( PUBLISHER ,\nINTERMEDIARY , or BOTH ) to describe the source of\nthe inventory associated with a speci\ufb01c seller ID;Index Type C ranked Mranked\n1 Misrepresented direct relationships 51% 64%\n2 Misrepresented reseller relationships 47% 65%\n3 Fabricated seller IDs 65% 83%\n4 Con\ufb02icting relationships 33% 49%\nTABLE 2: Prevalence of problematic representations in\nads.txt from websites in Cranked andMranked.\nIndex Type No M full \u00001M full\n5 Invalid seller type 0.7% 0%\n6 Invalid domain names 0.8% 54.8%\n7 Con\ufb01dential sellers 0.1% 46.1%\n8 Intermediaries w/o sellers.json 13.3% 49.8%\n9 Non-unique seller IDs 62.6% 95.3%\nTABLE 3: Fraction of sellers.json entries that contain\ndifferent problematic representations from AdXs serving no\nMfullwebsites and at least one Mfullwebsite.\n6)Invalid domain names: The sellers.json does not\npresent a valid domain name6in the \u2018domain\u2019 \ufb01eld;\n7)Con\ufb01dential sellers: The sellers.json lists the do-\nmain associated with the seller ID as \u2018con\ufb01dential\u2019.\nIt should be noted that this is not a violation of the\nsellers.json standard, but does prevent end-to-end\nsupply chain veri\ufb01cation because both the \u2018domain\u2019 and\n\u2018name\u2019 \ufb01elds are redacted;\n8)Intermediaries without sellers.json :An AdX\u2019s\nsellers.json lists intermediaries that do not have a\nsellers.json ; and\n9)Non-unique seller IDs: Thesellers.json associates\nmultiple publisher or seller domains with the same seller\nID confounding the buyer\u2019s veri\ufb01cation.\nTable 2 compares the prevalence of misrepresentations\ninads.txt \ufb01les of Cranked andMranked websites. We \ufb01nd\na statistically signi\ufb01cant difference in the number of errors\npresent in ads.txt \ufb01les from Cranked andMranked websites\n(\u00002-test; p<. 05). We \ufb01nd that misinformation websites\nare more likely to contain higher rates of ads.txt mis-\nrepresentations that result in failed supply chain validation,\neven when controlling for website rank. Table 3 compares\nthe prevalence of misrepresentations in sellers.json\nof AdXs that serve Mfull(344 AdXs) websites with the\nsellers.json from AdXs that do not serve any of our\nMfullwebsites (483 AdXs). Again, we see that the AdXs that\nengage with misinformation websites are signi\ufb01cantly more\nlikely to have misrepresentations in their sellers.json\nthat result in the inability to perform supply chain validation.\nTaken together, our results highlight the lack of compliance\nwith ads.txt andsellers.json standards and their\ncurrent inability to allow end-to-end supply chain validation.\nThis problem is especially pronounced for the ad inventory\nof misinformation publishers.\n6. While a buyer may still rely on the \u2018name\u2019 \ufb01eld, it is not suitable for\nautomated analysis because \u2018name\u2019 is a free text \ufb01eld. Automated analysis\nis crucial as bid requests need to be programmatically validated in real-time\nand at scale.\n8\n4.2. Prevalence of pooling\nAs described in \u00a72.2, pooling is the practice of using\na single AdX account to manage the inventory of multiple\nwebsites. This results in a single AdX-issued seller ID being\nassociated with multiple websites. Although this practice\nenables more ef\ufb01cient management of advertising resources\nfor publishers, it comes at the cost of increased opacity in\nthe advertising ecosystem and reduces the effectiveness of\nthe end-to-end supply chain validation mechanisms.\nGathering evidence of pooling with the Dstaticdataset.\nWe begin by identifying evidence of pooling in the C100K\nand Mfullwebsites from our Dstaticdataset. We use this\ndataset of ads.txt \ufb01les associated with the Tranco top-\n100K domains to identify all cases where multiple domains\nlisted the same seller ID and AdX as a seller of their inven-\ntory. In total, we observed 79K unique pools \u2014 i.e., 79K\nunique (seller ID, AdX) pairs were observed to have been\nshared by multiple publisher domains. Of these 79K pools,\n11% (8.7K) also included at least one of the misinformation\nwebsites in Mfull. We refer to these 79K pools identi\ufb01ed\nthrough the Dstaticdataset as static pools . The size of these\npools ranged from 2 to nearly 9K domains, with an average\nof 70 domains per pool.\nCharacteristics of pools identi\ufb01ed in the Dstaticdataset.\nThese above-reported pool sizes were certainly larger than\nwhat we anticipated and necessitated additional inspection\nfor a better understanding of our \ufb01ndings. Speci\ufb01cally, we\npaid attention to the organizational relationships between\npooled entities and whether pooling was occurring due to\nsome ad-tech related mechanism.\nOrganizational homogeneity of pools. From a cursory\nmanual inspection of our pools, we observed (rather un-\nsurprisingly) that larger pools appeared to contain many\norganizationally unrelated domains \u2014 i.e., they were het-\nerogeneous . To measure the prevalence of such types of\npools at scale, we mapped each domain in a pool to their\nparent organization using the DuckDuckGo entity list [55]\nand labeled each pool as follows:\n1)Homogeneous: Pools whose member domains could all\nbe mapped to a single parent organization;\n2)Potentially homogeneous: Pools for which the parent\norganizations of all domains could not be identi\ufb01ed.\nHowever, all domains that could be mapped were found\nto have the same parent organization;\n3)Heterogeneous: Pools whose member domains were\nowned by more than one parent organization; and\n4)Unknown: Pools for which no domain could be mapped\nto a single parent organization.\nFigure 5 illustrates how pools are categorized into homo-\ngeneous and heterogeneous. Table 4 provides a breakdown\nof the prevalence of different types of pools. We make three\nkey observations. First, we notice that heterogeneous pools\ncomprise a large fraction of all pools \u2014 a deviation from\nthe expectation that pools are allowed in order to facilitate\nresource sharing between sibling domains. The high inci-\ndence rates of heterogeneous pools in non-misinformation        adexchange.example, 12345, DIRECT             \"seller_id\": \"12345\",             \"seller_type\": \"PUBLISHER\",             \"domain\": \"publisherA.example\",             \"name\": \"PublisherA\"       OR             \"seller_id\": \"12345\",             \"seller_type\": \"PUBLISHER\",             \"domain\": \"ABgroup.example\",             \"name\": \"AB Group\"publisherA.example/ads.txtadexchange.example/sellers.json\n1. Homogenous Pools\n        adexchange.example, 12345, DIRECTpublisherB.example/ads.txt\n        adexchange.example, 12345, DIRECT             \"seller_id\": \"12345\",             \"seller_type\": \"PUBLISHER\",             \"domain\": \"publisherC.example\",             \"name\": \"PublisherC\"publisherA.example/ads.txtadexchange.example/sellers.json\n2. Heterogenous Pools\n        adexchange.example, 12345, DIRECTpublisherB.example/ads.txt\nFigure 5: Categorization of pools based on the relation of\nthe publishers with the domain owner organization. In the\nhomogeneous pool, PublisherA and PublisherB authorize\nseller account 12345 on adexchange.example as their direct\nseller. The sellers.json ofadexchange.example recog-\nnizing 12345 as an account owned by either PublisherA ,\nPublisherB , orAB Group represent all valid cases of pooling\nassuming PublisherA andPublisherB are related (in this case\nowned or operated by AB Group ). If the sellers.json\nofadexchange.example shows that the seller account 12345\nis owned by PublisherC and PublisherA orPublisherB\nare unrelated to PublisherC , then this represents a case of\nheterogeneous pool, which we consider a dark pool.\nwebsites also suggests that there may be legitimate (i.e., not\nill-intentioned) mechanisms that facilitate seller ID sharing\nbetween organizations. Second, pools containing misinfor-\nmation websites are statistically signi\ufb01cantly more likely to\nbe heterogeneous (85%) than pools without misinformation\nwebsites (41%) [ \u00002-test; p<. 05]. Finally, we see that\npools containing misinformation websites are statistically\nsigni\ufb01cantly larger (412.1 websites/pool) than pools without\nmisinformation websites (20.3 websites/pool) [2-sample t-\ntest: p<. 05;u-test: p<. 05]. Taken together, the latter\ntwo \ufb01ndings lend credence to the thesis that misinformation\nwebsites are effectively \u201claundering\u201d their ad inventory by\nparticipating in mechanisms that facilitate large heteroge-\nneous pools.\nPools facilitated by authorized ad-tech mechanisms. Our\n\ufb01ndings about the high rate of heterogeneous pools of large\nsizes, even among non-misinformation websites, suggest\nthat there are ad-tech mechanisms that organically facilitate\npooling. After further investigation we found that many of\nthe heavily pooled (seller ID, AdX) pairs appeared to be\nissued by a small number of AdXs whose sellers.json\n\ufb01le indicated that the issued seller IDs were not associ-\nated with speci\ufb01c publishers but instead other ad platforms\n(AdXs or SSPs). In other words, the seller ID issuing AdX\u2019s\nsellers.json \ufb01le indicated that the \u2018owner domain\u2019 of\n9\nPools w/ M full Pools w/o M full\nPool Type # Pools \u00b5size # Pools \u00b5size\nHomogeneous 40 (0.4%) 2.6 6.7K (9.6%) 2.6\nPo. Homogeneous 913 (9.1%) 18.8 18.4K (26.6%) 7.0\nHeterogeneous 8.6K (85.0%) 482.5 28.4K (41.0%) 42.2\nUnknown 563 (5.6%) 4.3 15.7K (22.7%) 3.9\nAll pools 8.7K 412.1 70.5K 20.3\nTABLE 4: Prevalence of pools from Dstaticin C 100K.\nPools are broken down by organization homogeneity and\nwhether they contained a misinformation website from the\nMfulldataset. \u00b5sizedenotes the average (mean) number of\nwebsites in a pool.\nthe pooled seller ID was another AdX/SSP \u2014 suggesting\nthat these pooling mechanisms might be authorized by the\nAdX platforms themselves for aggregating and reselling ad\ninventory of different publishers. Table 5 shows that three\nof the most commonly pooled owner domains belong to\nlarge AdXs ( google.com ,justpremium.com owned\nby GumGum, and townnews.com ). Most notably, nearly\n25% and 12% of the pools that used GumGum- and Google-\nowned seller IDs also contained known misinformation web-\nsites. For example, 100percentfedup.com , a website\nthat promoted anti-vax and stolen-election theories, received\nads through pools using Google-owned seller IDs issued by\nthe AdX \u2018Index Exchange\u2019. In contrast, TownNews, an ad-\nvertising \ufb01rm focused on serving local media organizations\ndid not have a single pool containing known misinformation\nwebsites.\nTo investigate the prevalence of pooling, we looked for\nAdX-sanctioned programs that might require pooling \u2014 i.e.,\nis there public documentation of authorized programs to\nallow unrelated publishers to pool their inventory through\nintermediaries. Notably, we found public documentation of\nGoogle\u2019s Multiple Customer Management (MCM) program\nthat allows \u2018Google MCM-partner\u2019 organizations to manage\nthe inventory of multiple client publishers through a single\naccount [56]. As a result, all the publishers that are managed\nby an MCM partner are served ads via the same seller ID\nof the intermediary MCM organization. Our results show\nthat misinformation websites are able to monetize their\nad inventory by being part of these MCM networks. Our\nresults highlight a violation of Google\u2019s own policies re-\ngarding advertising on websites \u2018making unreliable claims\u2019\nor \u2018distributing manipulated media\u2019 [57]. However, public\ndocumentation does not clearly state whether Google dele-\ngates all website and content veri\ufb01cation responsibilities to\ntheir MCM partners and therefore it remains unclear if the\nviolation is a failure of Google\u2019s own veri\ufb01cation practices\nor those of their MCM partners. Similarly, the pooled misin-\nformation websites using GumGum-owned seller IDs were\nalso in violation of GumGum\u2019s content policy [58].\nPools using seller IDs with hidden or unknown owner\ndomains. During our investigation, we also discovered that\nmany AdX\u2019s sellers.json \ufb01les did not allow identi\ufb01ca-\ntion of the owner domain of the seller ID that was used. This\ncomprised nearly half of all identi\ufb01ed pools. The breakdownType Domain Pools Pools w/ M full\nOwner of sellerIDgoogle.com 5.1K 598\ngannett.com 370 5\njustpremium.com 337 84\ntownnews.com 313 0\nhearst.com 219 1\nAdX issuer of sellerIDgoogle.com 10.3K 461\ntaboola.com 6.6K 132\nfreewheel.com 3.9K 625\npubmine.com 3.6K 2\nopenx.com 2.4K 524\nTABLE 5: Most pooled domains and AdXs from Dstatic.\nThe top \ufb01ve rows represent the most frequently observed\ndomains whose seller IDs were used in pools. The bottom\n\ufb01ve rows represent the most frequently observed AdXs who\nissued the seller IDs that were used for pooling.\nof reasons for this is provided in Table 6. Here, we see that\nthe most common reasons for failed identi\ufb01cation of the\nowners of seller IDs being used in pooling are: (1) the seller\nID is itself unlisted in the issuing AdX\u2019s sellers.json\n\ufb01le and (2) the unavailability of a public sellers.json\nfrom the owner domain that owned the AdX-issued seller\nID (when owner domain is not a PUBLISHER type entry).\nIt is important to note that any of the reasons shown in\nTable 6 would result in the impossibility of any end-to-end\nsupply chain veri\ufb01cation. Interestingly, we \ufb01nd no statis-\ntical differences ( \u00002-test; p<. 05) between the reasons\nfor failed identi\ufb01cation of owners of non-misinformation\nand misinformation pools. This suggests that the issues of\npoor compliance with end-to-end supply chain veri\ufb01cation\nprocedures are industry-wide and no speci\ufb01c cause for these\nfailures is exploited by misinformation websites.\nReason All pools Pools w/ M full\nTotal pools 79K 8.7K\nseller ID unlisted 20.9K 2.5K\nsellers.json not public 16.5K 2.0K\nOwner not listed 2.6K 135\nOwner is con\ufb01dential 3.4K 86\nTABLE 6: Pools from Dstaticusing IDs of unknown\nowners. Reasons for failed identi\ufb01cation of the owners of\nseller IDs used in pools.\nFinding occurrences of pooling with the Dcrawlsdataset.\nBecause of the high rates of misrepresentations, unreliability\nof publisher-sourced ads.txt \ufb01les, and the incomplete-\nness of AdX-sourced sellers.json \ufb01les, it is important\nto note that our analysis of the Dstaticcan only be used as\nevidence that suggests the widespread practice of potential\ndark pooling. In order to con\ufb01rm a dark pool\u2019s existence\nwith certainty we need to observe it in a live page load.\nTo this end, we leverage the set of all (publisher domain,\nAdX, owner domain) triples recorded in our Dcrawlsdataset\n(cf. \u00a73.2). Since these were obtained from actual ad-related\nmetadata from crawls of the Mfulldataset, they provide\nconcrete evidence of pooling actually being leveraged by\nknown misinformation websites (i.e., dark pooling). In total,\n10\nwe gathered 2.8K (publisher domain, AdX, owner domain)\ntriplets through two crawls of Mfullwebsites from which\nwe identi\ufb01ed 297 pools across 38 ad exchanges. These 297\npools are depicted in Figure 6 Of these, 218 pools (73.4%)\noverlapped with those identi\ufb01ed in our analysis of the Dstatic\ndataset and 79 were new. The non-existence of 79 pools in\ntheDstaticdataset prevented us from classifying them and\nthis once again highlights the ad industry\u2019s poor compliance\nwith ads.txt andsellers.json standards.\nGoogle and PubMatic were found to be the issuers of\nthe seller IDs associated with 120 and 48 pools, respec-\ntively. These pools enabled advertising supply chains for\n127 (Google) and 67 (PubMatic) misinformation websites.\n33Across and Gourmet Ads were found to be the owners of\nseller IDs that were shared by the most number of misin-\nformation websites (28 and 23 websites, respectively). Both\nseller IDs were issued by PubMatic. Other notable AdXs\n(and count of the number of seller IDs issued by them which\nwere pooled by misinformation websites) include Rubicon\nProject (now Magnite) (34), ContextWeb (now PulsePoint)\n(30), Amazon (28), and media.net (25).\nHomogeneity of Dcrawlspools. From 297 distinct pools,\nwe were able to identify the presence of 15 homoge-\nneous and 203 heterogeneous pools. The homogeneity\nof the remaining pools could not be determined. The\nlargest homogeneous pool shared a seller ID issued to\nfunkedigital.de by PubMatic. This pool included\nnine websites such as principia-scientific.org ,\nallnewspipeline.com ,russia-insider.com \u2014\nMedia Bias/Fact Check identi\ufb01ed all the nine websites as\n\u2018Conspiracy Theory\u2019 or \u2018Propaganda\u2019 related with \u2018Low\u2019\nfactual reporting and having \u2018Right\u2019 to \u2018Extreme-Right\u2019\nbias. We identi\ufb01ed stories related to climate change de-\nnial, vaccination misinformation, and pro-insurrection views\n\u2014 all in violation of PubMatic\u2019s own content guide-\nlines for publishers [59]. Incidentally, a seller ID on Pub-\nmatic was also associated with the largest heterogeneous\npool with 47 unique misinformation websites, including\ndrudgereport.com and worldtruth.tv . Unfortu-\nnately, PubMatic\u2019s sellers.json \ufb01le did not list the\nseller ID associated with this heterogeneous pool, suggesting\nthat it was employing fabricated or unlisted ID for pooling.\nDcrawlspools and the Google MCM program. In order\nto identify occurrences of pooling in Google\u2019s MCM pro-\ngram, we identi\ufb01ed pools associated with the seller IDs\nissued by Google to MCM partners. Of the 203 unique\nheterogeneous pools identi\ufb01ed, a vast majority were labeled\nas con\ufb01dential in Google\u2019s sellers.json [60] but we\nwere able to link 15 to Google\u2019s MCM program based\non public documentation. In total, Google\u2019s MCM partners\nwere associated with 27 misinformation websites. Some of\nthese MCM partners whose Google-issued seller IDs were\npooled by misinformation websites include Adnimation,\nEzoic, etc. Misinformation websites supported by Google\u2019s\nMCM program included 369news.net (pseudoscience or\nanti-vaxx theories) and truthandaction.org (extreme-\nright propaganda and/or misinformation), amongst other\nFigure 6: Dark pooling relationships between AdXs (left)\nand owner domains of AdX-issued pooled IDs (right) for\n297 unique pools observed during the crawls of Mfullweb-\nsites. The counts represent the number of distinct misinfor-\nmation websites pooled.\n11\n0255075100125Brand Counts0.00.20.40.60.81.0Fraction of SitesFigure 7: Cumulative distribution of the number of distinct\nbrands across different misinformation websites\nsimilar websites. The MCM partners most frequently found\nto be using their Google-issued seller ID for pools contain-\ning misinformation websites were Monumetric (5 pools) and\nFreestar (4 pools).\nTakeaways. Our analysis shows a widespread failure to\nadhere to the ads.txt andsellers.json standards\nand the compliance is even more weaker amongst misinfor-\nmation websites (\u00a74.1). This poor adherence has one major\nconsequence: end-to-end validation of the ad-inventory sup-\nply chain is not always possible, particularly in the case of\nmisinformation websites. Further compounding supply chain\nvalidation challenges, we \ufb01nd that the pooling of seller IDs\nby unrelated publishers is also widespread (\u00a74.2). Misinfor-\nmation websites, which violate the publisher content policies\nof many AdXs, are able to monetize their ad inventory\nthrough these pools. In fact, we \ufb01nd that in many cases\nthey are able to leverage the authorized programs of the\nsame AdXs whose policies they violate.\n5. Brand Analysis\nIn this section, we analyze the display ads loaded on\nmisinformation websites to identify the advertisers/brands\nthat end up buying their ad inventory.\nData collection. We curate Dbrandsby crawling each of the\n669 misinformation websites ten times as discussed in \u00a73.2.\nWe are able to collect a total of 4,246 ads belonging to 2,068\ndistinct brands. Figure 7 plots the distribution of the number\nof distinct brands across misinformation websites. We \ufb01nd\nthat a non-trivial fraction of misinformation websites are\nable to get ads from tens of distinct brands. Speci\ufb01cally, 23\nmisinformation websites have ads from at least 41 distinct\nbrands each while 142 misinformation websites have ads\nfrom at most 10 distinct brands each.\nReputable brand classi\ufb01cation and prevalence. To as-\nsess whether these ads are from reputable brands, we use\ntheir Tranco ranks as a rough proxy for their reputation.\nSpeci\ufb01cally, we classify brands with top-1K Tranco rank-\ning as \u201creputable\u201d. Figure 8 shows the number of distinct\nreputable and non-reputable brands across top-20 misinfor-\nmation websites that contain ads from the highest distinct\nbrands. Perhaps surprisingly, we \ufb01nd that Breitbart \u2013 a well-\nknown misinformation website \u2013 is able to attract ads from\nthe highest number of distinct brands. The two reputable\nbrands with ads on Breitbart include Forbes and GoDaddy.050100Brand Countsactualidadpanamericana.comnewsrescue.comusamagazinestudio.comendtimeheadlines.orgisraelislamandendtimes.compaci\ufb01cpundit.comworldtruth.tvendoftheamericandream.comnewsammo.comimmediatesafety.orgburrardstreetjournal.comin5d.comamericanpatriotdaily.comtheeconomiccollapseblog.comusanetwork.infothedailycheck.netusasupreme.comlibertyunyielding.comreturntonow.netbreitbart.com\nNon-Reputed BrandsReputed BrandsFigure 8: Distribution of reputable and non-reputable brands\namong the top-20 misinformation websites with the highest\nnumber of distinct brands advertising on their website.\nIn total, we observe ads from 55 reputable brands including\nForbes, GoDaddy, Harvard, Intel, Microsoft, Nike, Samsung,\nTumblr, Yahoo!, Verizon, and Wayfair. We note that these\ntop-20 misinformation websites tend to have more ads from\nreputable brands on average as compared to the remaining\nmisinformation websites. Speci\ufb01cally, the average number\nof reputable brands is 2.05 for the top-20 misinformation\nwebsites in Figure 8 and 0.78 for the remaining misinfor-\nmation websites.\nCorrelation between ad inventory misrepresentation and\nnumber of brands. Next, we investigate whether the mis-\nrepresentation of ad inventory by misinformation websites\nimpacts their ability to sell their ad inventory.\nFigure 9 plots the distribution of the distinct brand\ncounts of all the brands advertising on misinformation web-\nsites with/without ads.txt . Note that we are looking for\nthe existence of ads.txt .7We \ufb01nd that misinformation\nwebsites with ads.txt are able to attract ads from twice\nas many brands on an average as compared to the websites\nwithout ads.txt . We conclude that some brands do avoid\nadvertising on misinformation websites without ads.txt .\nFigure 10 plots the conditional probabilities of ob-\nserving reputable brands across misinformation websites\nwith/without dark pools. We \ufb01nd that more than half of the\nmisinformation websites part of one or more dark pools get\nads from reputable brands. In contrast, less than one-third of\nthe misinformation websites part of no dark pools get ads\nfrom reputable brands. This nearly 20% difference in the\nconditional probability shows that dark pooling signi\ufb01cantly\nincreases the chances of ads from reputable brands ending\nup on misinformation websites.\nBrand disclosures. It is reasonable to assume that reputable\nbrands generally do not want to advertise on misinformation\nwebsites [29], [30], [32]. Taking the example of Breitbart,\nthere is ample evidence that reputable brands did not want\n7. The mere existence of ads.txt does not guarantee the veracity of its\ncontent. A misinformative publisher could have misrepresented ads.txt\nentries to bypass brand checks. Advertisers are recommended by IAB to\nperform ads.txt checks against the data observed in the bid requests\nbefore making a bid.\n12\n0255075100125Brand Counts0.00.20.40.60.81.0Fraction of SitesWebsites without ads.txtWebsites with ads.txtFigure 9: Cumulative distribution of the number of dis-\ntinct brands on misinformation websites with or without\nads.txt\ntheir ads shown on Breitbart [32], [61], [62]. DSPs and\nAdXs typically provide brand safety features [63] to help\nbrands avoid buying the ad inventory of low-quality web-\nsites. Brand safety features allow brands to block unwanted\nad inventory through a block list of domains or seller IDs\n[60]. One would expect that reputable brands would attempt\nto avoid buying the ad inventory of misinformation websites\nthrough these brand safety features. Since brand safety is\nnot externally measurable, we conduct individualized dis-\nclosures to these 55 reputable brands and speci\ufb01cally ask\nthem (a) whether they want their ads on misinformation\nwebsites or not and (b) whether they employ brand safety\nfeatures to this end.\nTo perform disclosures, we \ufb01rst attempted to \ufb01nd\nadvertising-related email addresses for each reputable brand\nfrom their website. If we were unsuccessful, we included\ngeneric email addresses from their \u201cAbout Us\u201d and \u201cContact\nUs\u201d pages. In our disclosures, we listed the misinforma-\ntion websites where the ads of the reputable brand were\nobserved. We included full-page screenshots showing the\nbrand\u2019s ad creative on the misinformation website as well\nas the full HTTP Archive (HAR) recording of the network\ntraf\ufb01c. We also asked them whether they were aware of or\nintended to have their ads on the misinformation websites\nand whether/which brand safety service they used.\nWe received responses from 11 reputable brands. 8\nbrands con\ufb01rmed that they were unaware and did not intend\nto advertise on these misinformation websites. For example,\none brand responded that \u201c We don\u2019t advertise on the site. It\nwas an unintentional oversight related to automated adver-\ntising and the ad was immediately pulled when discovered.\nWe always aim to advertise on sites that are aligned with\nour mission and values and we apologize if this upset any of\nour customers. \u201d Another brand mentioned that \u201c We will not\nwant to see our ads on misinformation websites. \u201d Regard-\ning the deployment of brand safety features, we received\ncon\ufb01rmation from 4 brands that they indeed used a brand\nsafety service but it did not adequately detect or prevent\ntheir ad from appearing on the misinformation website. One\nbrand told us that it used Google Display Network\u2019s built-in\nbrand-safety measure while two brands employed the brand\nsafety service provided by Integral Ad Science (IAS). One\nbrand told us that \u201c the misinformation website disclosed by\nyou [...] is neither present in the logs provided to us by\nour DSP partner nor is \ufb02agged by IAS. We think that it is0.00.20.40.60.81.0Conditional ProbabilityNo reputable brand adsReputable brandsMfullwith 0 dark poolsMfullwith 1+ dark pools\nFigure 10: Conditional probabilities of ads from reputable\nbrands in presence or absence of dark pooling\nbeing misplaced on the misinformation website due to dark\npooling. \u201d Another brand told us that \u201c About the brand-safety\nservice, please understand we are not able to tell any detail \u201d\npresumably due to a con\ufb01dentiality agreement.\nTakeaways. In summary, our results show that the mis-\nrepresentation of ad inventory by misinformation websites\nseems to be correlated with their ability to monetize their\nad inventory through reputable brands. We found that the ad\ninventory of misinformation websites that use dark pooling\nis more likely to be bought by reputable brands. The limited\nresponses from reputable brands suggest that they do not\nwant to advertise on misinformation websites and employ\nbrand safety features to this end.\n6. Related Work\nExamining the online advertising ecosystem. In recent\nyears, there have been many research efforts to bring trans-\nparency to the mechanisms of online advertising. A large\nnumber of these have focused on studying personal data\ncollection and sharing to deliver personalized ads [64]\u2013[69].\nOur work instead focuses on the prevalence of inventory\nfraud, pooling, and its impact on brands.\nInventory fraud. There have been a few measurements\nrelated to ads.txt standard and related inventory fraud\nsince its introduction. However, no work has focused on\nsellers.json or the ad-fraud that emerges by the com-\nbined failure of ads.txt andsellers.json . In 2019,\nBashir et al. [21] gathered and conducted a longitudinal\nanalysis of ads.txt \ufb01les. They found that these \ufb01les\nwere riddled with syntactic errors and inconsistencies that\nmade them dif\ufb01cult to process in an automated fashion.\nTingleff [70] and Pastor et al. [71] highlighted \ufb02aws of\ntheads.txt standard that undermines its effectiveness in\npreventing ad fraud, albeit without measurements to sup-\nport their hypotheses. Some of these identi\ufb01ed \ufb02aws are,\nhowever, supported by measurements from Papadogiannakis\net al. [72]. These \ufb01ndings, suggesting that the ads.txt\nstandard is not effectively enforced, are corroborated by our\nstudy. Our work complements these efforts by undertaking a\nmeasurement study of both the standards of ads.txt and\nsellers.json for the \ufb01rst time to measure inventory\nfraud as well as prevalence of pooling, which allows low-\nquality publishers to launder their ad inventory.\n13\nBrand safety. There have been many studies that have\nhighlighted the impact of ads (and the websites on which\nthey appear) on the reputation of a brand [28], [63], [73],\n[74]. In fact, several activist efforts have successfully lever-\naged brand safety concerns to demonetize misinformation.\nNotable among these are the efforts of Check My Ads\nand Sleeping Giants [75], who successfully used public\ncampaigns to pressurize 820 brands to add Breitbart News\u2019\ndomain to their advertising block lists. Our cataloging of\nbrands found on known misinformation websites can supple-\nment these ad-hoc efforts and increase pressure on ad-tech to\nenforce its own ads.txt andsellers.json standards\nmore effectively. Other work has focused on measuring or\nimproving the effectiveness of mechanisms for identifying\n\u2018brand safe\u2019 web content. Most recently, Vo et al. [76]\nbuilt an image-based brand-safety classi\ufb01er to prevent ad\nplacement on inappropriate pages. Numerous products from\nmajor ad-tech \ufb01rms such as DoubleVerify [77], Integral Ad\nScience [78], and Oracle [79] have also recently started\npromoting their \u2018brand safety\u2019 features.\nFunding infrastructure of misinformation. Ours is not\nthe \ufb01rst work to consider the role of the online advertising\necosystem in funding misinformation. In fact, it has been\nknown for several years that online advertising provides the\nprimary revenue stream for misinformation websites [80]\u2013\n[84]. Han et al. [85], in their study, focused on network\ninfrastructure, also explored the revenue streams on mis-\ninformation websites and identi\ufb01ed disproportionately high\nreliance on advertising and consumer donations.\nBozarth et al. [86] showed that although there is a\nunique ecosystem of \u2018risky\u2019 AdXs that partner with pub-\nlishers of misinformation, there is also a heavy presence\nof mainstream AdXs (e.g., Google) in the misinformation\necosystem.\nBraun & Eklund [87] take a qualitative approach to\nunderstand the role of the advertising ecosystem in in-\ncreasing revenues of misinformation and the dismantling\nof traditional journalism. Their work, along with numerous\nothers [88]\u2013[90], has highlighted the need for additional\ntransparency to realize the promise of market-based strate-\ngies to curb funding of misinformation.\nConsidering another angle, several studies have also\nexamined how deceptive ads are used to promote and fund\nharmful products [91]\u2013[93] and ideologies [43], [94], [95].\nAt a high-level, our work complements all these efforts\nto better understand how the misinformation ecosystem is\nfunded by online advertising by uncovering and analyzing\nthe exploitation of speci\ufb01c advertising-related vulnerabilities\nsuch as pooling and relationship misrepresentations by the\nmisinformation ecosystem.\n7. Concluding Remarks\nOur work shows how the opacity of the ad-tech supply\nchain is exploited by misinformation publishers to mon-\netize their ad inventory. Through our measurements, we\ndemonstrate a widespread lack of compliance with the IAB\u2019sads.txt and sellers.json standards, ad inventory\npooling by misinformation publishers, and reputed brands\nwho end up buying this ad inventory of misinformation\npublishers. Taken all together, our results point to speci\ufb01c\ngaps that need to be further explored by the ad-tech and\nsecurity research communities.\nTrust delegation in advertising partner programs. One\nof our key \ufb01ndings is that a small number of ad exchanges\nare responsible for a majority of dark pooling. In many\ncases, we see evidence that this dark pooling is achieved\nthrough the use of legitimate partner programs made avail-\nable by ad exchanges (e.g., Google\u2019s MCM partner program\n[56]). These programs serve an important purpose \u2014 to\nhelp reduce the management burdens on small publishers.\nHowever, as we see in our study, this expanded access\nfacilitated via advertising partners results in new vulnera-\nbilities. Speci\ufb01cally, publishers who are in clear violation\nof the policies set by an ad exchange are still able to obtain\nseller IDs issued by the exchange through their partners.\nOne perspective of this problem is that there is a funda-\nmental breakdown of trust delegation \u2014 i.e., partners are\ndelegated the rights to assign and manage seller IDs on\nbehalf of exchanges, but without being properly delegated\nthe responsibilities for vetting publishers and verifying their\ncompliance with ad exchange policies. While this work is\nthe \ufb01rst to uncover this delegation of trust in the form of\nveri\ufb01cation responsibilities in the ad-tech ecosystem, it is\nnot new to the security community. Indeed, this type of trust\ndelegation is a central theme in the public key infrastructure\n[96], app stores [97], and other domains. From these prior\nefforts to delegate veri\ufb01cation responsibilities, it is clear that\nsuccess is only possible with effective mechanisms to moni-\ntor compliance and revoke delegated trust. A key difference\nfrom prior efforts, however, is that it is not publicly known\nhow these trust delegation processes work within speci\ufb01c ad\nexchanges. Without public documentation of these processes\nor research studies that uncover them, we anticipate that\nidentifying weaknesses and causes for failure will remain\nan open challenge.\nSupply chain transparency and compliance with in-\ndustry standards. The programmatic advertising supply\nchain is complex because of the large number of enti-\nties involved between publishers and advertisers. Further\ncomplicating matters, our study shows that these entities\nare frequently out of compliance with even basic standards\nsuch as ads.txt andsellers.json . In fact, many of\nthe concerning \ufb01ndings of our work could be addressed if\nadvertisers were able to trace the provenance of ad inventory\nusing the existing \u2018Supply Chain Object\u2019 (SCO) ad-tech\nstandard. Unfortunately, our analysis of SCOs in \u00a7B shows\nthat less than a quarter of bid requests actually include\nthe SCO. Further, even when the SCO is included in bid\nrequests, they are often incomplete and missing information\nwould make end-to-end veri\ufb01cation of the supply chain\ndif\ufb01cult. We further \ufb01nd that even major ad exchanges\nimplement digital advertising standards in a way that hinders\nexternal independent audits. Notably, Google\u2019s widespread\n14\nuse of con\ufb01dential sellers.json entries [60] makes it\nchallenging to identify Google AdX\u2019s partners who are not\ndoing adequate compliance veri\ufb01cation for the publishers\nwhose inventory they list. IAB has recently released new and\nupdated digital advertising standards [98], [99] to improve\nend-to-end validation of the ad-tech supply chain. However,\nthese are not widely adopted yet. Therefore, in its current\nstate, to mitigate ad fraud and reduce ad-tech\u2019s inadver-\ntent funding of misinformation, it is crucial that adoption\nand compliance with new and existing digital advertising\nstandards such as SCO, ads.txt , and sellers.json\nimprove. However, a key challenge is the absence of in-\ncentives for achieving compliance with these standards. It\nremains to be seen if recent US regulatory efforts will\nimprove compliance. Notably, the Digital Services Oversight\nand Safety Act (DSOSA) [100] and Advertising Middle-\nmen Endangering Rigorous Internet Competition Account-\nability Act (AMERICA) [101] introduce new requirements\nrelated to online advertising transparency. In addition, we\nare currently engaged in conversations with members of US\nCongress seeking to draft additional legislation speci\ufb01cally\nto strengthen compliance with ad-tech industry standards,\nimprove transparency around the ad-tech supply chain, and\nmitigate ad fraud.\nEffective noti\ufb01cation and vulnerability reporting mech-\nanisms. The ad-tech industry is currently lacking mech-\nanisms through which supply chain vulnerabilities may be\nreported. This absence has resulted in several community-\norganized efforts such as the Check My Ads Institute [31]\nthat monitor ads on misinformation websites and use social\nmedia to report on the brands or ad-tech loopholes that fund\nthese publishers. While these efforts have been successful\nat mitigating some of the harms from the opacity of the\nsupply chain, they are not systematic reports and rely on\nampli\ufb01cation via social media in order to reach their in-\ntended targets. Further, like our study, they generally focus\non speci\ufb01c harms caused by the opacity of ad-tech (e.g.,\nfunding of misinformation). There is a need to develop more\ngeneralized and systematic mechanisms for reporting sup-\nply chain vulnerabilities and non-compliance with existing\nindustry standards.\nFor reproducibility and to foster follow-up research,\nour dataset is available at https://osf .io/hxfkw/?view only=\nbda006ebbd7d4ec2be869cbb198c6bd5\nAcknowledgment\nThis work is supported in part by the National Science\nFoundation under grant numbers 2103439, 2103038, and\n2138139. We want to thank the anonymous shepherd and re-\nviewers for their constructive feedback that helped improve\nthe work.\nReferences\n[1] Shuai Yuan, Jun Wang, and Xiaoxue Zhao. Real-time bidding\nfor online advertising: measurement and analysis. In Proceedings\nof the seventh international workshop on data mining for online\nadvertising , 2013.[2] OpenRTB Guidelines. IAB: https://www .iab.com/guidelines/\nopenrtb/, 2022.\n[3] Display ad-tech Lumascape. https://lumapartners .com/content/\nlumascapes/display-ad-tech-lumascape/.\n[4] What\u2019s the Difference Between Waterfall Auctions & Header\nBidding? https://clearcode .cc/blog/difference-waterfall-header-\nbidding/, 2022.\n[5] Sumayah A. Alrwais, Alexandre Gerber, Christopher W. Dunn,\nOliver Spatscheck, Minaxi Gupta, and Eric Osterweil. Dissecting\nghost clicks: Ad fraud via misdirected human clicks. In Proceedings\nof the 28th Annual Computer Security Applications Conference\n(ACSAC) , 2012.\n[6] Brett Stone-Gross, Ryan Stevens, Apostolis Zarras, Richard Kem-\nmerer, Chris Kruegel, and Giovanni Vigna. Understanding fraudulent\nactivities in online ad exchanges. In Proceedings of the ACM Internet\nMeasurement Conference , 2011.\n[7] Jonathan Crussell, Ryan Stevens, and Hao Chen. Madfraud: Inves-\ntigating ad fraud in android applications. In Proceedings of the 12th\nAnnual International Conference on Mobile Systems, Applications,\nand Services , 2014.\n[8] Vacha Dave, Saikat Guha, and Yin Zhang. Measuring and \ufb01nger-\nprinting click-spam in ad networks. In Proceedings of the ACM\nSIGCOMM Conference , 2012.\n[9] Apostolis Zarras, Alexandros Kapravelos, Gianluca Stringhini,\nThorsten Holz, Christopher Kruegel, and Giovanni Vigna. The dark\nalleys of madison avenue: Understanding malicious advertisements.\nInProceedings of the ACM Conference on Internet Measurement\nConference , 2014.\n[10] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna.\nShady paths: Leveraging sur\ufb01ng crowds to detect malicious web\npages. In Proceedings of the ACM SIGSAC Conference on Computer\n& Communications Security , 2013.\n[11] Kurt Thomas, Elie Bursztein, Chris Grier, Grant Ho, Nav Jagpal,\nAlexandros Kapravelos, Damon Mccoy, Antonio Nappa, Vern Pax-\nson, Paul Pearce, Niels Provos, and Moheeb Abu Rajab. Ad injection\nat scale: Assessing deceptive advertisement modi\ufb01cations. In IEEE\nSymposium on Security and Privacy , 2015.\n[12] Shishir Nagaraja and Ryan Shah. Clicktok: Click fraud detection\nusing traf\ufb01c analysis. In Proceedings of the Conference on Security\nand Privacy in Wireless and Mobile Networks , 2019.\n[13] Suibin Sun, Le Yu, Xiaokuan Zhang, Minhui Xue, Ren Zhou,\nHaojin Zhu, Shuang Hao, and Xiaodong Lin. Understanding and\ndetecting mobile ad fraud through the lens of invalid traf\ufb01c. In\nProceedings of the 2021 ACM SIGSAC Conference on Computer\nand Communications Security (CCS) , 2021.\n[14] Mobin Javed, Cormac Herley, Marcus Peinado, and Vern Paxson.\nMeasurement and analysis of traf\ufb01c exchange services. In Proceed-\nings of the ACM Internet Measurement Conference , 2015.\n[15] Shehroze Farooqi, Guillaume Jourjon, Muhammad Ikram, Mo-\nhamed Ali Kaafar, Emiliano De Cristofaro, Zubair Sha\ufb01q, Arik\nFriedman, and Fareed Zaffar. Characterizing key stakeholders in an\nonline black-hat marketplace. In APWG Symposium on Electronic\nCrime Research (eCrime) , 2017.\n[16] Manolis Chalkiadakis, Alexandros Kornilakis, Panagiotis Pa-\npadopoulos, Evangelos Markatos, and Nicolas Kourtellis. The rise\nand fall of fake news sites: A traf\ufb01c analysis. In ACM Web Science\nConference , 2021.\n[17] Inside the Macedonian Fake News Complex. https:\n//www .wired .com/2017/02/veles-macedonia-fake-news/, 2022.\n[18] How teens in the balkans are duping trump supporters\nwith fake news. https://www .buzzfeednews .com/article/\ncraigsilverman/how-macedonia-became-a-global-hub-for-pro-\ntrump-misinfo# .fu2okXaeKo.\n15\n[19] How Facebook powers money machines for obscure political\nnews sites. https://www .theguardian .com/technology/2016/aug/24/\nfacebook-clickbait-political-news-sites-us-election-trump, 2016.\n[20] IAB Brand-safety. https://www .iab.com/topics/brand-safety/, 2022.\n[21] Muhammad Ahmad Bashir, Sajjad Arshad, Engin Kirda, William\nRobertson, and Christo Wilson. A longitudinal analysis of the ads.\ntxt standard. In ACM Internet Measurement Conference , 2019.\n[22] What is domain spoo\ufb01ng? https://www .adpushup .com/blog/what-\nis-domain-spoo\ufb01ng/, 2017.\n[23] Domain spoo\ufb01ng remains a huge threat to programmatic.\nhttps://digiday .com/marketing/domain-spoo\ufb01ng-remains-an-ad-\nfraud-problem/, 2017.\n[24] The Sentencing of The King Of Fraud and the Birth of Collective\nProtection. https://www .humansecurity .com/learn/blog/the-\nsentencing-of-the-king-of-fraud-and-the-birth-of-collective-\nprotection, 2021.\n[25] The four types of domain spoo\ufb01ng. https://integralads .com/insider/\nthe-four-types-of-domain-spoo\ufb01ng/, 2018.\n[26] IAB ads.txt Speci\ufb01cations. https://iabtechlab .com/ads-txt/, 2017.\n[27] IAB sellers.json Speci\ufb01cations. https://iabtechlab .com/sellers-json/,\n2019.\n[28] Chunsik Lee, Junga Kim, and Joon Soo Lim. Spillover effects of\nbrand safety violations in social media. Journal of Current Issues\n& Research in Advertising , 2021.\n[29] New ias report uncovers how consumer perception of misleading\ncontent impacts brand favorability. https://integralads .com/news/\nmisinformation-consumer-research/, 2022.\n[30] New ias report uncovers how misleading content impacts digital\nadvertising. https://integralads .com/news/new-ias-report-uncovers-\nhow-misleading-content-impacts-digital-advertising/, 2022.\n[31] Check My Ads Institute. https://checkmyads .org/, 2022.\n[32] List of advertisers that demonetized breitbart. https://twitter .com/\nslpng giants/status/1200473586886205440, 2020.\n[33] Cvs blocks breitbart. https://mobile .twitter .com/slpng giants/status/\n808381433173577730, 2016.\n[34] Further investigation into the \u201cdark pool sales house\u201d phenomenon.\nhttps://deepsee .io/blog/non-unique-pub-ids, 2021.\n[35] Murky ad-tech tactics: What you should know about dark pool sales\nhouses. https://www .adweek .com/media/dark-pool-sales-houses-\nwhat-you-need-to-know/, 2021.\n[36] Google openrtb integration. https://developers .google .com/\nauthorized-buyers/rtb/openrtb-guide.\n[37] Vungle openrtb integration. https://support .vungle .com/hc/\nen-us/articles/360045953431-Vungle-Exchange-OpenRTB-2-5-\nIntegration-Guide#3-2-2-source-ext-schain-nodes-object-0-12,\n2022.\n[38] Doubleclick for publishers. https://www .adpushup .com/blog/\ngoogle-dfp-doubleclick-for-publishers/, 2021.\n[39] Victor Le Pochat, Tom Van Goethem, Samaneh Tajalizadehkhoob,\nMaciej Korczy \u00b4nski, and Wouter Joosen. Tranco list. https://tranco-\nlist.eu. Accessed on 27th Oct, 2021.\n[40] Maciej Szpakowski and Renato. Fake news corpus. https://\ngithub .com/several27/FakeNewsCorpus, Feb 2018.\n[41] Media Bias/Fact Check Team. Media bias/fact check: The most com-\nprehensive media bias resource. https://mediabiasfactcheck .com.\n[42] Austin Hounsel, Jordan Holland, Ben Kaiser, Kevin Borgolte, Nick\nFeamster, and Jonathan Mayer. Identifying disinformation websites\nusing infrastructure features. In 10th USENIX Workshop on Free\nand Open Communications on the Internet (FOCI) , 2020.[43] Eric Zeng, Tadayoshi Kohno, and Franziska Roesner. Bad news:\nClickbait and deceptive ads on news and misinformation websites.\nInWorkshop on Technology and Consumer Protection (ConPro) ,\n2020.\n[44] Syed Suleman Ahmad, Muhammad Daniyal Dar, Zareed Zaffar,\nNarseo Vallina-Rodriguez, Rishab Nithyanand, et al. Apophanies\nor epiphanies: How crawlers can impact our understanding of the\nweb. In The Web Conference , 2020.\n[45] Jordan Jueckstock, Shaown Sarker, Peter Snyder, Aidan Beggs,\nPanagiotis Papadopoulos, Matteo Varvello, Benjamin Livshits, and\nAlexandros Kapravelos. Towards realistic and reproducibleweb\ncrawl measurements. In Proceedings of the Web Conference , 2021.\n[46] John Cook, Rishab Nithyanand, and Zubair Sha\ufb01q. Inferring tracker-\nadvertiser relationships in the online advertising ecosystem using\nheader bidding. Proceedings on Privacy Enhancing Technologies ,\n1, 2020.\n[47] Maaz Bin Musa and Rishab Nithyanand. Atom: Ad-network tomog-\nraphy. a generalizable technique for inferring tracker-advertiser data\nsharing in the online behavioral advertising ecosystem. Proceedings\non Privacy Enhancing Technologies , 2022.\n[48] Umar Iqbal, Peter Snyder, Shitong Zhu, Benjamin Livshits, Zhiyun\nQian, and Zubair Sha\ufb01q. Adgraph: A graph-based approach to ad\nand tracker blocking. In IEEE Symposium on Security and Privacy ,\n2020.\n[49] Panagiotis Papadopoulos, Nicolas Kourtellis, Pablo Rodriguez Ro-\ndriguez, and Nikolaos Laoutaris. If you are not paying for it, you\nare the product: How much do advertisers pay to reach you? In\nProceedings of the 2017 Internet Measurement Conference , 2017.\n[50] Menlo report. https://www .dhs.gov/sites/default/\ufb01les/publications/\nCSD-MenloPrinciplesCORE-20120803 1.pdf, 2012.\n[51] Belmont report. https://www .hhs.gov/ohrp/regulations-and-policy/\nbelmont-report/read-the-belmont-report/index .html, 1979.\n[52] Robots.txt meant for search engines don\u2019t work well for web\narchives. https://blog .archive .org/2017/04/17/robots-txt-meant-for-\nsearch-engines-dont-work-well-for-web-archives, 2017.\n[53] Christian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric\nLangbort. Auditing algorithms: Research methods for detecting\ndiscrimination on internet platforms. Data and discrimination:\nconverting critical concerns into productive inquiry , 22(2014), 2014.\n[54] Madison Addicks. Van buren v. united states: The supreme court\u2019s\nruling on the fate of web scraping-\u201d access\u201d to discovery or deten-\ntion? Tul. J. Tech. & Intell. Prop. , 24, 2022.\n[55] Github \u2014 duckduckgo tracker-radar/entities. https://github .com/\nduckduckgo/tracker-radar/tree/main/entities.\n[56] Overview of MCM - Google AdMob Help. https:\n//support .google .com/admob/answer/9142605?hl=en.\n[57] Misrepresentation - Advertising Policies Help. Google Advertising\nPolicies, https://support .google .com/adspolicy/answer/6020955?hl=\nen&ref topic=1626336, 2022.\n[58] GumGum \u2014 Prohibited Content Policy for Buyers and Sellers.\nhttps://gumgum .com/terms-and-policies/buyer-policy, 2022.\n[59] Supply policy. Pubmatic, 2022.\n[60] Porn, piracy, fraud: What lurks inside google\u2019s black box ad em-\npire. https://www .propublica .org/article/google-display-ads-piracy-\nporn-fraud, 2022.\n[61] Sunrun blocks breitbart. https://twitter .com/slpng giants/status/\n1024019694523695111, 2018.\n[62] Sagenamerica blocks breitbart. https://twitter .com/slpng giants/\nstatus/913821166304763904, 2017.\n[63] Steven Bellman, Ziad HS Abdelmoety, Jamie Murphy, Shruthi Aris-\nmendez, and Duane Varan. Brand safety: the effects of controversial\nvideo content on pre-roll advertising. Heliyon , 4(12), 2018.\n16\n[64] Steven Englehardt and Arvind Narayanan. Online tracking: A\n1-million-site measurement and analysis. In Proceedings of the\n2016 ACM SIGSAC conference on computer and communications\nsecurity , 2016.\n[65] Abbas Razaghpanah, Rishab Nithyanand, Narseo Vallina-Rodriguez,\nSrikanth Sundaresan, Mark Allman, Christian Kreibich, Phillipa\nGill, et al. Apps, trackers, privacy, and regulators: A global study\nof the mobile tracking ecosystem. In The 25th Annual Network and\nDistributed System Security Symposium (NDSS 2018) , 2018.\n[66] Muhammad Ahmad Bashir, Sajjad Arshad, William Robertson, and\nChristo Wilson. Tracing information \ufb02ows between ad exchanges\nusing retargeted ads. In USENIX Security Symposium , 2016.\n[67] Aaron Cahn, Scott Alfeld, Paul Barford, and Shanmugavelayutham\nMuthukrishnan. An empirical study of web cookies. In Proceedings\nof the 25th international conference on world wide web , 2016.\n[68] Yash Vekaria, Vibhor Agarwal, Pushkal Agarwal, Sangeeta Mahap-\natra, Sakthi Balan Muthiah, Nishanth Sastry, and Nicolas Kourtellis.\nDifferential tracking across topical webpages of indian news media.\nInACM Web Science Conference , 2021.\n[69] Marjan Falahrastegar, Hamed Haddadi, Steve Uhlig, and Richard\nMortier. The rise of panopticons: Examining region-speci\ufb01c third-\nparty web tracking. In International Workshop on Traf\ufb01c Monitoring\nand Analysis . Springer, 2014.\n[70] S Tingleff. The Three Deadly Sins of Ads. Txt and How Publish-\ners Can Avoid Them. https://iabtechlab .com/blog/the-three-deadly-\nsins-of-ads-txt-and-how-publishers-can-avoid-them, 2019.\n[71] Antonio Pastor, Rub \u00b4en Cuevas, \u00b4Angel Cuevas, and Arturo Azcorra.\nEstablishing trust in online advertising with signed transactions.\nIEEE Access , 9, 2020.\n[72] Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos\nP. Markatos, and Nicolas Kourtellis. Who funds misinformation?\na systematic analysis of the ad-related pro\ufb01t routines of fake news\nsites. In Proceedings of the ACM Web Conference 2023 , pages\n2765\u20132776, 2023.\n[73] Edlira Shehu, Nadia Abou Nabout, and Michel Clement. The risk of\nprogrammatic advertising: Effects of website quality on advertising\neffectiveness. International Journal of Research in Marketing , 38(3),\n2021.\n[74] Sophie Bishop. In\ufb02uencer management tools: Algorithmic cultures,\nbrand safety, and bias. Social Media+ Society , 7(1), 2021.\n[75] Claudia Pereira Ferraz. Sleeping giants and indirect boycotts against\nthe far right in united states of america. Aurora. , 14(40), 2021.\n[76] Quan Minh Vo, Nhan Thi Cao, and An Hoa Ton-That. Unsafe image\nclassi\ufb01cation using convolutional neural network for brand safety.\nInIEEE Asia-Paci\ufb01c Conference on Computer Science and Data\nEngineering (CSDE) , 2020.\n[77] Doubleverify unveils expanded brand safety & brand\nsuitability integration with facebook - doubleverify.\nhttps://doubleverify .com/newsroom/doubleverify-unveils-expanded-\nbrand-safety-brand-suitability-integration-with-facebook/.\n[78] Integral ad science \u2014 brand safety & suitability solutions. https:\n//integralads .com/solutions/brand-safety-suitability/.\n[79] Oracle moat measurement \u2014 oracle advertising. https://\nwww .oracle .com/cx/advertising/measurement/.\n[80] Nir Kshetri and Jeffrey Voas. The economics of \u201cfake news\u201d. IT\nProfessional , 19(6), 2017.\n[81] Arvind Hickman. Advertisers spend $2.6bn on misinformation web-\nsites, study \ufb01nds. https://www .campaignlive .com/article/advertisers-\nspend-26bn-misinformation-websites-study-\ufb01nds/1725293, Aug\n2021.\n[82] Global Disinformation Index. Cutting the funding of disinformation:\nThe ad-tech solution. https://disinformationindex .org/wp-content/\nuploads/2019/05/GDI Report Screen AW2 .pdf, May 2019.[83] Global Disinformation Index. The quarter billion\ndollar question: How is disinformation gaming ad tech?\nhttps://disinformationindex .org/wp-content/uploads/2019/09/GDI\nAd-tech Report Screen AW16 .pdf, Sep 2019.\n[84] Augustine Fou. Big advertisers still fund hate and disinformation\noutside of facebook. https://www .forbes .com/sites/augustinefou/\n2020/07/06/big-advertisers-still-fund-hate-and-disinformation-\noutside-of-facebook/?sh=383aa3376f78, July 2020.\n[85] Catherine Han, Deepak Kumar, and Zakir Durumeric. On the\ninfrastructure providers that support misinformation websites. In\nProceedings of the International AAAI Conference on Web and\nSocial Media , 2022.\n[86] Lia Bozarth and Ceren Budak. Market forces: Quantifying the role\nof top credible ad servers in the fake news ecosystem. In The\nInternational AAAI Conference on Web and Social Media , 2020.\n[87] Joshua A Braun and Jessica L Eklund. Fake news, real money: Ad\ntech platforms, pro\ufb01t-driven hoaxes, and the business of journalism.\nDigital Journalism , 7(1), 2019.\n[88] Joel Timmer. Fighting falsity: Fake news, Facebook, and the \ufb01rst\namendment. Cardozo Arts & Ent. LJ , 35, 2016.\n[89] Damian Tambini. Fake news: public policy responses. 2017.\n[90] Norman Vasu, Benjamin Ang, Terri-Anne Teo, Shashi Jayakumar,\nMuhammad Raizal, and Juhi Ahuja. Fake news: National security\nin the post-truth era . S. Rajaratnam School of International Studies.,\n2018.\n[91] Yelena Mejova and Kyriaki Kalimeri. Advertisers jump on coro-\nnavirus bandwagon: Politics, news, and business. arXiv preprint\narXiv:2003.00923 , 2020.\n[92] Amelia M Jamison, David A Broniatowski, Mark Dredze, Zach\nWood-Doughty, DureAden Khan, and Sandra Crouse Quinn.\nVaccine-related advertising in the facebook ad archive. Vaccine ,\n38(3), 2020.\n[93] Vanessa Boudewyns, Brian G Southwell, Kevin R Betts, Cather-\nine Slota Gupta, Ryan S Paquin, Amie C O\u2019Donoghue, and Natasha\nVazquez. Two awareness of misinformation in health-related adver-\ntising: A narrative review of the literature. Misinformation and mass\naudiences , 2021.\n[94] Eric Zeng, Miranda Wei, Theo Gregersen, Tadayoshi Kohno, and\nFranziska Roesner. Polls, clickbait, and commemorative $2 bills:\nproblematic political advertising on news and media websites around\nthe 2020 US elections. In Proceedings of the 21st ACM Internet\nMeasurement Conference , 2021.\n[95] Yingying Chen and Luping Wang. Misleading political advertising\nfuels incivility online: A social network analysis of 2020 US presi-\ndential election campaign video comments on YouTube. Computers\nin Human Behavior , 2022.\n[96] Laurent Chuat, AbdelRahman Abdou, Ralf Sasse, Christoph\nSprenger, David Basin, and Adrian Perrig. Sok: Delegation and\nrevocation, the missing links in the web\u2019s chain of trust. In IEEE\nEuropean Symposium on Security and Privacy (EuroS&P) , 2020.\n[97] Fuqi Lin, Haoyu Wang, Liu Wang, and Xuanzhe Liu. A longitudinal\nstudy of removed apps in iOS app store. In Proceedings of the Web\nConference , 2021.\n[98] Ads.cert 2.0. https://iabtechlab .com/ads-cert/, 2022.\n[99] ads.txt Version 1.1. https://iabtechlab .com/wp-content/uploads/\n2022/04/Ads .txt-1 .1.pdf, 2022.\n[100] H.R.6796 - Digital Services Oversight and Safety Act of 2022. https:\n//www .congress .gov/bill/117th-congress/house-bill/6796/text, 2022.\n[101] S.1073 - Advertising Middlemen Endangering Rigorous Internet\nCompetition Accountability Act or the AMERICA Act. https://\nwww .congress .gov/bill/118th-congress/senate-bill/1073/text, 2023.\n17\nAppendix A.\nLongitudinal Analysis of sellers.json\nVarious campaigns have highlighted the role of AdXs in\nmonetizing the misinformation ecosystem, pressuring them\nto remove their support for these domains [31]. To under-\nstand the effectiveness of these campaigns, we monitored\nchanges to the sellers.json \ufb01les present in our Dstatic\n.\ndataset for a three-month period (from Oct\u201921 to Feb\u201922).\nOf the 470 AdXs found to support misinformation web-\nsites (by listing them as publishers) on October 2021, 39\n(8.3%) AdXs delisted at least one misinformation website\nby February 2022.\nBashir et. al. [21] performed this analysis on ads.txt\nof Alexa Top-100K websites in their work. However, our\nstudy is on misinformation websites, whose ads.txt\nshould not be trusted. Hence, we perform this analysis on\nsellers.json \ufb01les of trusted AdXs.\nWe observed 470 sellers.json supporting at least\none misinformation website as per October\u2019s crawl \u2013 46 of\nwhich support 10 or more misinformation outlets. The ones\nthat support the highest misinformation websites are revcon-\ntent.com (204), liveintent.com (56), outbrain.com (56), pix-\nfuture.com (39), and lijit.com (now part of Sovrn ) (30).\nFrom Oct\u201921 to Feb\u201922, only 39 AdXs de-list at least 1\nmisinformation website, while 53 sellers.json include\nat least 1 misinformation website in their \ufb01les. Table 7\nshows the top AdXs and their longitudinal support for the\nmisinformation websites in their sellers.json .\nAd exchangeMisinformation Website Counts\nOct\u201921 Feb\u201922 Added Dropped\nrevcontent.com 204 73 2 133\noutbrain.com 56 35 0 21\n9mediaonline.com 20 1 0 20\nstitchvideo.tv 14 1 0 13\nadtelligent.com 26 28 13 11\ninfolinks.com 23 14 2 11\npublisherdesk.com 14 3 0 11\nmgid.com 20 32 13 1\nnextmillennium.io 7 9 3 1\nvidazoo.com 5 8 3 0\npixfuture.com 39 41 2 0\nlijit.com 30 30 0 0\nTABLE 7: AdXs that add and drop the most misinformation\nwebsites from their sellers.json between Oct\u201921 and\nFeb\u201922. The table is arranged in descending order of the\ndropped counts.\nUpon further investigation of RevContent, we observed\nthat it dropped \u21e087% of the total publisher domains from\ntheir sellers.json in mid-December 2021 (Oct\u201921:\n4727 domains to Feb\u201922: 621 domains) and we speculate\nthat their primary aim might not have been to drop mis-\ninformation websites, but they ended up de-listing a few\nof misinformation websites too as a result of their bulk\ndrop. There has always been a constant peer-pressure and\ncriticism from activists (e.g., [31]) forcing RevContent to re-\nmove their support for misinformation websites. There wereactive discussions on social media speculating RevContent\u2019s\nintent behind this massive drop. However, RevContent did\nthis silently and never publicly addressed this action. Even\nafter the drop, RevContent still potentially funds the most\nmisinformation websites in our data. Other than RevContent,\nother AdXs that continued their support for the highest mis-\ninformation websites in Feb\u201922 are LiveIntent (56), Pixfuture\n(41), Outbrain (35), and MGID (32).\nAdditionally, the misinformation outlets which were\nadded by the most AdXs are rearfront.com ,vidmax.com ,\nandthetruereporter.com . The former 2 outlets are agents\nof spreading viral and misleading content, while the latter\npublishes politicized news, commentary and analysis. These\nwere added by 6 different AdXs. Similarly, lifezette.com ,\nwaynedupree.com , and news18.co were dropped by 6, 6, and\n5 AdXs respectively.\nAppendix B.\nSupply Chain Object Analysis\nIf adopted and implemented correctly, Supply Chain\nObjects (SCOs) can aid overall validation and provide trans-\nparency into all the entities involved in (re-)selling of a\nparticular ad-inventory. In absence of SCOs, a buyer has\nvisibility into only the immediate upstream seller but not\nthe entire path of (re-)sellers that were involved before the\nupstream seller. It is the job of each seller to append its\nseller object in the existing SCO and forward the bid request\nfurther. A buyer extracts the SCO object from the bid request\nand parses the list of all seller nodes represented by key\nnodes . Higher the index of a node in this list, the more\nrecent the seller. When an AdX forwards the bid request\nfor a publisher, it associates the publisher with dictionary\nkeyasiand the account identi\ufb01er for that publisher in its\nnetwork with the key sid.\nIn order to analyze the adoption and correctness of SCOs\nin our data, we use our custom SCO parser (based on the\nIAB guidelines) on all the bid requests captured in the\nDcrawlsdataset. Despite SCOs being introduced by IAB since\nJuly 2019, only 20.5% (3796) bid requests have included\nSCOs, all of which comprised only a single seller node. To\nverify the correctness of SCOs, we extracted sidandasi\nassociated with the seller node and performed sidlookup in\nthesellers.json \ufb01le of the asito obtain the upstream\nseller domain with which the ad-inventory is associated as\nper the SCO. Next, we checked if this website domain\nmatched the actual website\u2019s domain on which the current\nbid request was captured during the dynamic crawl. Let\u2019s\ncall this boolean result \u2013 A. We also validated all 3796 SCO-\nbased paths (upstream website !asiseller !ad-request\ndomain) against 3-hop static paths involving each misinfor-\nmation website generated from the sellers.json \ufb01les.\nLet\u2019s call this boolean result \u2013 B. The cases where A and B\nwere True are cases where we could verify the correctness\nof the SCOs. The rest cases were SCO misrepresentations.\nWe observed only 18.94% (719) of 3796 bid requests with\ncorrect implementation of SCOs.\n18", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Inventory is Dark and Full of Misinformation: Understanding Ad Inventory Pooling in the Ad-Tech Supply Chain", "author": ["V Yash", "N Rishab", "S Zubair"], "pub_year": "2024", "venue": "NA", "abstract": "The rise of ad-blockers is viewed as an economic threat by online publishers who primarily  rely on online advertising to monetize their services. To address this threat, publishers have"}, "filled": false, "gsrank": 533, "pub_url": "https://par.nsf.gov/biblio/10535677", "author_id": ["zoft_JcAAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:i5StoyN6agMJ:scholar.google.com/&output=cite&scirp=532&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D530%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=i5StoyN6agMJ&ei=ZrWsaNvsJbXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:i5StoyN6agMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://par.nsf.gov/servlets/purl/10535677"}}, {"title": "Using LLM for improving key event discovery: Temporal-guided news stream clustering with event summaries", "year": "2023", "pdf_data": "Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 4162\u20134173\nDecember 6-10, 2023 \u00a92023 Association for Computational Linguistics\nUsing LLM for Improving Key Event Discovery:\nTemporal-Guided News Stream Clustering with Event Summaries\nNishanth Nakshatri\u2663Siyi Liu\u2662Sihao Chen\u2662\nDaniel J. Hopkins\u2662Dan Roth\u2662Dan Goldwasser\u2663\n\u2663Purdue University\u2662University of Pennsylvania\n{nnakshat,dgoldwas}@purdue.edu\n{siyiliu, sihaoc, danhop, danroth}@upenn.edu\nAbstract\nUnderstanding and characterizing the discus-\nsions around key events in news streams is im-\nportant for analyzing political discourse. In this\nwork, we study the problem of identification of\nsuch key events and the news articles associated\nwith those events from news streams. We pro-\npose a generic framework for news stream clus-\ntering that analyzes the temporal trend of news\narticles to automatically extract the underlying\nkey news events that draw significant media\nattention. We characterize such key events by\ngenerating event summaries, based on which\nwe form document clusters in an unsupervised\nfashion. We evaluate our simple yet effective\nframework, and show that it produces more co-\nherent event-focused clusters. To demonstrate\nthe utility of our approach, and facilitate future\nresearch along the line, we use our framework\nto construct KEYEVENTS1, a dataset of 40k\narticles with 611key events from 11topics.\n1 Introduction\nAnalyzing the dynamics of discussions within the\nstream of news coverage has been an important\ntool for researchers to visualize and characterize\nmedia discourse around a topic (Field et al., 2018;\nLiu et al., 2019; Li and Goldwasser, 2019; Roy\nand Goldwasser, 2020; Luo et al., 2020; Liu et al.,\n2021; Lei et al., 2022; Dutta et al., 2022). News\nmedia discourse is typically centered around\nreal-world events that catch media attention and\ngives rise to news reports streams. With the\nvast, ever-growing amount of news information\navailable, we need automatic ways for identifying\nsuch key events.\nIn this paper, we study the problem of identi-\nfying and characterizing key events from a large\ncollection of news articles. Since the number of\n1https://github.com/nnakshat/KeyEventsnews events is usually not known in advance, past\nworks have typically formulated the problem as\na form of non-parametric clustering of news arti-\ncles, using Hierarchical Dirichlet Processes (Zhou\net al., 2015; Beykikhoshk et al., 2018) or Stream\nClustering (Laban and Hearst, 2017; Miranda et al.,\n2018; Staykovski et al., 2019; Saravanakumar et al.,\n2021). Rather than relying on the output of such\nclustering algorithms directly, we view the dis-\ncovered clusters as event candidates , and lever-\nage recent advances in Large Language Modeling\n(LLM) (Brown et al., 2020) to characterize these\ncandidates and reason about their validity. From a\nbird\u2019s eye view, the process is related to past work\non interactive clustering (Hu et al., 2014; Pacheco\net al., 2022, 2023), but instead of using human\nfeedback to shape the emergent clusters, we rely\non LLM inference.\nWe propose a framework for clustering an\narchive of news articles into temporally motivated\nnews events. A high-level overview of our ap-\nproach is shown in Figure 1. We first retrieve rele-\nvant issue-specific articles (details about the docu-\nment retrieval module are in App A) and perform\ntemporal analysis to identify \u201cpeaks\u201d, in which\nthe number of articles is significantly higher. We\nthen use HDBSCAN (Campello et al., 2013) a non-\nparametric clustering algorithm to generate can-\ndidate event clusters. We then characterize the\ncandidate clusters by performing few-shot multi-\ndocument summarization of the top-K articles as-\nsigned to each cluster, identify inconsistent clusters\nby assessing the (dis)agreement between the sum-\nmary and each article individually, and redundant\nclusters by assessing the similarity between cluster\npairs\u2019 summaries (details in Sec. 2.1). These low-\nquality candidates are removed, resulting in higher\nquality event clusters. We demonstrate this prop-\nerty over the NELA dataset (Horne et al., 2022)\nand show the improvement both in terms of event\ncoherence and document mapping quality.4162\nList of Issues\nIssue 1\nIssue nGPT-3.5\nKeywords\nIssue 1 keywords\nIssue n keywords\nNELA  Data Data RetrieverPeak\nDetectionPeak 1 Peak nPeak Specific\nClusteringPeak Specific\nEventsGPT-3.5Event\nCharacterizationMerge / Remove\nEventsCluster\nMembership\nDocument Retrieval ModuleUser\nTemporal Filtering ModuleEvent Discovery Inference\nIssue\nSpecific\nArticlesFigure 1: High-level overview of our framework for K EYEVENTS identification.\n2 Event Discovery and Article Inference\n2.1 Event Discovery\nTemporal Filtering. The first step towards gener-\nating event candidates is to identify temporal land-\nmarks orpeaks , where the media coverage surges\nwith respect to one or more real-world events.\nWe represent the news articles as a time-series\ndata, where T={t1, t2,\u00b7\u00b7\u00b7, tn}denote time, and\nC={ct1, ct2,\u00b7\u00b7\u00b7, ctn}denote the number of ar-\nticles published at each time step. The task is to\nidentify a set of peaks, P={p1, p2,\u00b7\u00b7\u00b7, pm}at\ndifferent points in time. With this formulation, we\nhypothesize that the resulting clusters from our\nframework would be able to segregate discussions\nat various time steps and form coherent events com-\npared to other approaches. We use an existing\noutlier detection algorithm (Palshikar et al., 2009)\ntowards this task. More details in Appendix B.\nPeak-Specific Clustering. Within each peak, the\nincreased media coverage can be attributed to mul-\ntiple relevant events. We categorize the docu-\nments in each peak piinto a set of events, Ei=\n{e1, e2,\u00b7\u00b7\u00b7, eq}, and form an overall event set,\nE={E1,E2,\u00b7\u00b7\u00b7,Em}, pertaining to the issue. We\nembed the titleandfirst 4 lines of a news article\ninstance using a dense retriever (Ni et al., 2021)\nmodel. The embedded documents are clustered us-\ning HDBSCAN to identify key news events. Prior\nto clustering, we reduce the dimensions of doc-\nument embedding using UMAP (McInnes et al.,\n2018). Details are in Appendix C.\nEvent Characterization. The event set obtained\nat each peak ( Ei), is still prone to noise and is not\neasily interpretable without significant effort. Char-\nacterizing the news events makes the clusters in-\nterpretable and helps remove inconsistencies. The\ncandidate events are characterized by generatingIncoherent Cluster (Top-3 documents shown)\nEvent Title : Climate Justice and African Activists\nEvent Description : This is about the challenges faced\nby African climate activists in bringing attention to the\nclimate crisis and the need for climate justice.\nDoc. 1: There Will Never Be Climate Justice If African\nActivists Keep Being Ignored\nWe go to Kampala, Uganda, to speak to climate activist\nVanessa Nakate on the occasion of her first book being\npublished, A Bigger Picture. ...\nDoc. 2: The Looking Glass World Of \u2019Climate Injustice\u2019\nIn our wacky world where almost nothing makes sense\nanymore, there is no shortage of examples of politicians,\nlet alone self-important academics, journalists, and\nwealthy elites, looking foolish with self-contradictory\npolicy demands. ...\nDoc. 3: New Miss Universe Urges Action on Climate\nChange: Choice to Kill or Save Nature\nA new Miss Universe has been crowned and she is a\nclimate alarmist. ...\nTable 1: Incoherent cluster removal. The cluster sum-\nmary aligns with the 1stand the 2ndarticle, while the\n3rdarticle is off-topic compared to the other two.\na multi-document summary using GPT-3.5. The\nprompts are engineered to generate short event-\nspecific summaries in a two-shot setting. The two\nclosest documents to each centroid are used in the\nprompt to generate event summaries.\nPost summary generation, we perform a cluster\ninconsistency check . A cluster is deemed to be\nincoherent if the top-K closest documents to the\ncentroid do not align with the summary embedding.\nWe embed the event summaries using the same\ndense retriever model, and compute the cosine sim-\nilarity score between the summary embedding and\nthe top-K documents for the cluster ( k= 5). Based\non a threshold value, we treat the incoherent clus-\nters as noise and discard them. Note that we only\ndiscard clusters but not documents associated with\nthem. They are still used for cluster membership as-\nsignment in the next stage of our framework. Tab. 14163\nSummary of Article 1 Summary of Article 2\nEvent Title : President Biden\u2019s Climate Plan Event Title : Biden\u2019s Climate Change Actions\nEvent Description : This is about President Joe Biden\u2019s ex-\necutive orders aimed at tackling climate change by reducing\nthe U.S. carbon footprint and emissions, stopping oil and gas\nleases on public lands, and prioritizing climate change as a\nnational security concern.Event Description: This is about President Joe Biden\u2019s exec-\nutive actions to combat climate change by prioritizing science\nand evidence-based policy across federal agencies, pausing\noil drilling on public lands, and aiming to cut oil, gas, and\ncoal emissions.\nEvent Title : Texas Abortion Ban Event Title : Texas Abortion Law\nEvent Description : This is about a new Texas law that bans\nabortions after 6 weeks and empowers regular citizens to bring\ncivil lawsuits against anyone who aids a woman looking to\nterminate a pregnancy.Event Description : This is about the controversial Texas\nabortion law that bans abortions after six weeks and has been\ncondemned by President Joe Biden as an unprecedented as-\nsault on women\u2019s rights.\nTable 2: Illustrates two cases of cluster merge from issue Climate Change , and Abortion respectively.\nshows an example of the discarded cluster.\nWe do an additional cleaning step by merging\nthe clusters that share a similar event summary .\nWe devise a simple greedy algorithm which uti-\nlizes GPT-3.5 for inference. In the first iteration\nof the algorithm, we start by constructing a set,\nS={(s1, s2),\u00b7\u00b7\u00b7,(sn\u22121, sn)}, that contains ev-\nery pairwise combination of event summaries. For\neach element in S, we prompt LLM to infer if the\npair of summaries are discussing about the same\nevent. If the event summaries, say (s1, s2), are\nequivalent, then we merge these summaries, and\nupdate the set Sby removing every element in the\nset that contains s1ors2. In the second iteration,\nwe construct a new set, S\u2032, that holds every com-\nbination of updated event summaries, and repeat\nthe previous step. We run the algorithm for two\niterations or halt if there are no merges after the\nfirst iteration. Tab. 2 shows an example where the\nevent summaries clearly indicate that the clusters\nneed to merged. Details about the hyperparameter\nselections, and prompts are in Appendix C, B.\n2.2 Inference: Map Articles to Events\nIn this stage of our framework, we decide the clus-\nter membership using a similarity module. We em-\nbed the updated event summaries using the same\nencoder, and compute the cosine similarity score\nbetween the summary and the document of interest.\nBy thresholding, we determine if the article can\nbe mapped to an event. For cluster membership,\nwe extend the temporal window by ddays before\nand after the peak ( d= 1), and consider all the\ndocuments published in that timeframe.\n3 Experiments and Results\nWe conduct experiments on the NELA-dataset,\nwhich is a large collection of news articles (see Ap-pendix A). Using our document retrieval module,\nwe collect a total of 335krelevant news articles on\n11contemporary issues2. The application of tem-\nporal filters reduces the article count to 90k, which\nis the basis for our analysis. The retrieved articles\nare mapped to a four-way { left,right ,center , and\nconspiracy-pseudoscience } political rating. Details\nabout the dataset, document retrieval module, and\nfour-way political rating can found in Appendix A.\nEvaluation Metrics. We evaluate our frame-\nwork\u2019s ability to create coherent event clusters at\nthe desired granularity with three automatic metrics\ninspired by Mimno et al. (2011). Given an event ei\nand the top-10 relevant entities Vei={vei\nl}l\u2208[1..10]\ntoeiby TF-IDF, entity purity measures the percent-\nage of the documents that mention at least one of\nthe top-10 entities; coverage counts the percentage\nof documents accounted for in the cluster assign-\nments. In addition, entity coherence considers co-\noccurrences of central entity pairs in the clustered\ndocuments to measure coherency for an event.\nC(ei, Vei) =M/summationdisplay\nm=2m\u22121/summationdisplay\nl=1logF(veim, vei\nl) +\u03f5\nF(vei\nl)\nwhere F(veim, vei\nl)indicates the co-occurrence fre-\nquency of two entities in documents. An entity\ncoherence value closer to zero indicates a highly\ncoherent news event cluster. We offer a more de-\ntailed explanation of the metrics in Appendix D.\nBaselines. We compare our method\u2019s perfor-\nmance against various competitive topic model as\nbaselines. We consider LDA (Blei et al., 2003;\nHoffman et al., 2010) in two different settings -\nLDA, and LDA (Temporal) . The topics are esti-\nmated individually at each temporal peak for LDA\n(Temporal) , whereas the topics are estimated across\n2https://www.allsides.com/topics-issues4164\nModel Coverage \u2193Entity Purity \u2191Entity Coherence \u2191Event Count\nLDA (baseline) 99.69 31.52 -1008.42 60.0\nTemporal filtering - 28.15 -1061.60 18.7\nLDA (Temporal) 89.02 38.62 -1005.37 65.7\nHDBSCAN 81.78 62.55 -776.80 58.4\nBERTopic 84.04 66.00 -726.11 62.3\nOur Method 44.29 82.69 -477.89 55.5\nOur Method (iter 2) 56.83 77.49 -579.48 55.5\nTable 3: Evaluation results averaged for all issues. Last column shows the average of the total event count from each\npeak and for each issue. For LDA(Temporal), we assigned the document to its most probable topic if the probability\nwas\u22650.5.\nall peaks at once for LDA. We include three addi-\ntional baselines - Temporal Filtering ,HDBSCAN ,\nandBERTopic (Grootendorst, 2022). Note that\nBERTopic3is an off-the-shelf neural baseline for\nclustering documents. For methods other than ours,\nwe do not incorporate a cluster membership module\nas we directly estimate the topics for all the docu-\nments in an extended temporal window of ddays\nbefore and after the peak ( d= 1). Preprocessing\nand hyperparameter details are in Appendix C.\nResults. Tab. 3 shows the aggregated results ob-\ntained for various methods across all the issues.\nFor LDA (baseline), the events are estimated over a\nunion of all the documents from every peak for an\nissue. We study the impact of event estimation with\nthe temporal component by comparing LDA (base-\nline) and Temporal Filtering methods. We observe\nonly a slight drop in average purity ( \u22123points)\nfor the Temporal Filtering method. Further, Tab. 8\nshows that in case of Free Speech, Abortion, Im-\nmigration issues, the purity scores are higher than\nLDA (baseline), which validates our hypothesis\nthat adding a temporal dimension to event identifi-\ncation can help form coherent events.\n4 Analysis and Discussion\n4.1 Coverage vs Purity Trade off\nWe evaluate the trade-off between coverage and en-\ntity purity among the methods that take event tem-\nporality into account. We observe that LDA (Tem-\nporal) has a very high coverage with the least purity,\nwhich can be attributed to noise associated with\nthe topic distributions. BERTopic improves over\nthis method in both coverage, and purity measures\nacross 11issues. It even outperforms HDBSCAN\nin both the metrics. However, while BERTopic has\nincreased coverage, it still fails to outperform our\n3https://maartengr.github.io/BERTopicmethod in terms of purity, and this can be primarily\nattributed to our inference mechanism that is based\non generated event summaries.\nTo address low coverage issue from our method,\nwe propose to run our framework for the second\niteration by updating event summary embedding\nwith the mean value of top-10 most representative\ndocument embeddings in the cluster (from the first\niteration). In doing so, average coverage increased\nby +12.5 points across all issues, with minimal\ndecrease of <5points in purity. Tab. 6 shows the\nresults for each issue after the second iteration.\n4.2 Impact of Merge/Remove Operations\nWe investigate the impact of removing cluster in-\nconsistencies over the generated candidate events.\nFor this analysis, we compare HDBSCAN with\nthe same hyperparameters and input data as our\nmethod. We observe that average of the inter-event\ncosine similarity score between event-pairs, and\nacross all issues is lesser by 0.14for our method.\nThis indicates that our method achieves improved\ncluster separability after eliminating inconsisten-\ncies. Tab. 5 shows the report for each issue. Over-\nall, the score is reduced, with one exception for the\nissue of Corruption . Manual inspection suggest\nthat the increase can be due to removal of \"good\"\nclusters. An example is shown in Fig. 7.\n4.3 K EYEVENTS \u21d2More Event Coherence\nTo better understand the advantages and disadvan-\ntages of our method, the authors manually annotate\na small set of data samples for Climate Change .\nWe test for event coherence , and mapping quality\nover this dataset. We define an event to be coherent\nif the top-K most representative documents of that\nevent are in agreement with each other ( k= 3).\nWe also annotate to verify the validity of document-\nto-event assignments ( mapping quality ), where we\ncheck for agreement between the document and its4165\nModel Event Coherence \u2191Mapping Quality\n(Precision) \u2191\nHDBSCAN 84.90 62.27\nBERTopic 85.48 69.87\nOur Method 91.07 72.19\nTable 4: Human evaluation results of our method.\nrespective event summary. The details about the\nexperimental setup can be found in Appendix E.\nThe test is conducted across all events for our\nmethod, HDBSCAN, and BERTopic. To mea-\nsure coherence, we first identify the top-K doc-\numents for an event based on their cosine similarity\nscores with the event centroid. In addition, we esti-\nmate mapping quality by judging if document pairs\nshould be clustered together or not.\nResults. The results of the human evaluation are\nshown in Tab. 4. Our method failed to generate\ncoherent events for 5out of the 56cases for Cli-\nmate Change , while BERTopic failed in 9out of\n62cases (ignoring 3cases where the annotator pro-\nvided a label of \u22121). HDBSCAN failed in 8out\nof53cases. Overall, the event coherence scores\nfrom BERTopic and HDBSCAN closely trail our\nmethod by a margin of approximately \u22126points,\nimplying that the generated events from these meth-\nods are coherent. However, considering the event\npurity scores, we conclude that these two methods\nare more noisy. In terms of mapping quality, our\nmethod outperforms HDBSCAN by a large mar-\ngin. The precision score from BERTopic is better\nthan HDBSCAN, indicating the effectiveness of\nBERTopic in grouping \u2019good\u2019 item pairs together\nover a small sample of randomly selected data-\npoints for the issue - Climate Change . More details\nin Appendix E.\n4.4 LLM Usage and Efficiency\nAs temporal filtering results in an average of 55\nevent clusters per issue, we observe that using LLM\nfor event summarization and cluster-merging incurs\nreasonable cost, as we discuss in Limitations.\n5 Broader Impact\nOur method and the resulting KEYEVENTS dataset\ncould be useful for analyzing political discourse\nacross different ideologies. As a simple case study,\nwe illustrate how the portrayal of events varies for\ndifferent political ideologies. We take an entity-\nbased approach (Rashkin et al., 2016; Field and\nFigure 2: Frequency of the entity Joe Manchin (y-axis:\n#entity mentions per article within each event) in Cli-\nmate Change events (x-axis: event indices across time).\nTsvetkov, 2019; Roy et al., 2021) and analyze men-\ntions of Joe Manchin , a democratic senator and\nthe chair of Senate Energy Committee, in Climate\nChange articles. Fig. 2 shows that left-leaning arti-\ncles mention him significantly more than the other\ntwo ideologies in some of the events (e.g. the 5th,\n9th, and 14th). Analyzing these events\u2019 articles\nshow that left leaning articles criticize his ties to\nthe coal industry and opposition to climate change\nlegislation, while fewer (or no) mentions in articles\nwith other ideology leanings under the same events.\nDifferent ideologies also persist different senti-\nments when mentioning the same entity. In Biden\u2019s\nExecutive Actions on Climate Change (16thevent\nin Fig. 2), articles from different ideologies have\ncomparable mention frequencies of Joe Manchin .\nWe prompt GPT-3.5 to classify the sentiment ex-\npressed towards him (positive, neutral, negative).\nInterestingly, none of the articles from any ideology\nexpresses a positive sentiment; 86% of the articles\nfrom the left endure a negative attitude towards\nhim, whereas only 38% and 0% of the articles from\nthe center and the right have negative sentiments.\nThis distinction shows that even the same entities\ncould be portrayed differently within each event to\nstrengthen the beliefs along their political lines.\n6 Conclusion\nWe present a framework for key events identifica-\ntion and showed that events generated from our\napproach were coherent through quantitative mea-\nsures, and human evaluation. We also presented a\nsimple qualitative study to showcase the potential\nofKEYEVENTS , for investigating various political\nperspectives under nuanced settings.4166\nLimitations\nAs the temporal filtering step of our framework\nrelies on the publicaiton date of documents as in-\nput, we work with the assumption that the docu-\nments have a timestamp attached to them. How-\never, the main idea of event characterization using\nLLM, and associating the documents to their clos-\nest event summary is applicable to other cases with\nno changes.\nOur approach relies on GPT-3.5 for generat-\ning a multi-document event summary and cluster-\nmerging. We choose to use GPT-3.5 instead of the\nopen-source counterparts mostly due to computa-\ntional resource constraints. Since all GPT calls are\nmade on the cluster-level, we are able to maintain\nthe total experimental cost of the paper under $5\nwith respect to the OpenAI API. To minimize the\nreliance and cost associated with LLM usage, we\nare using only pairs of documents with most similar\nvector representation to generate event summary.\nWe opt for more an efficient approach here, and\nleave the exploration of efficiency vs. performance\ntrade-off for future work.\nAcknowledgements\nWe thank the anonymous reviewers of this paper\nfor all of their vital feedback. The project was par-\ntially funded by NSF award IIS-2135573, and in\npart by the Office of the Director of National Intel-\nligence (ODNI), Intelligence Advanced Research\nProjects Activity (IARPA), via 2022-22072200003.\nThe views and conclusions contained herein are\nthose of the authors and should not be interpreted\nas necessarily representing the official policies, ei-\nther expressed or implied, of ODNI, IARPA, or\nthe U.S. Government. The U.S. Government is\nauthorized to reproduce and distribute reprints for\ngovernmental purposes notwithstanding any copy-\nright annotation therein.\nEthics Statement\nTo the best of our knowledge, we did not violate any\nethical code while conducting the research work\ndescribed in this paper. We report the technical\ndetails needed for reproducing the results and will\nrelease the code and data collected. We make it\nclear that the KEYEVENTS dataset is the result\nof an automated algorithm not human annotation\n(though human evaluation was used in assessing its\nperformance over a subset of the data).References\nAdham Beykikhoshk, Ognjen Arandjelovi \u00b4c, Dinh\nPhung, and Svetha Venkatesh. 2018. Discovering\ntopic structures of a temporally evolving document\ncorpus. Knowledge and Information Systems , 55:599\u2013\n632.\nDavid M Blei, Andrew Y Ng, and Michael I Jordan.\n2003. Latent dirichlet allocation. Journal of machine\nLearning research , 3(Jan):993\u20131022.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems , 33:1877\u20131901.\nRicardo JGB Campello, Davoud Moulavi, and J\u00f6rg\nSander. 2013. Density-based clustering based on\nhierarchical density estimates. In Advances in Knowl-\nedge Discovery and Data Mining: 17th Pacific-Asia\nConference, PAKDD 2013, Gold Coast, Australia,\nApril 14-17, 2013, Proceedings, Part II 17 , pages\n160\u2013172. Springer.\nSihao Chen, William Bruno, and Dan Roth. 2023. To-\nwards corpus-scale discovery of selection biases in\nnews coverage: Comparing what sources say about\nentities as a start. arXiv preprint arXiv:2304.03414 .\nSujan Dutta, Beibei Li, Daniel S Nagin, and Ashiqur R\nKhudaBukhsh. 2022. A murder and protests, the\ncapitol riot, and the chauvin trial: Estimating dis-\nparate news media stance. In Proceedings of the\nThirty-First International Joint Conference on Artifi-\ncial Intelligence , pages 5059\u20135065.\nAnjalie Field, Doron Kliger, Shuly Wintner, Jennifer\nPan, Dan Jurafsky, and Yulia Tsvetkov. 2018. Fram-\ning and agenda-setting in russian news: a computa-\ntional analysis of intricate political strategies. In Pro-\nceedings of the 2018 Conference on Empirical Meth-\nods in Natural Language Processing , pages 3570\u2013\n3580.\nAnjalie Field and Yulia Tsvetkov. 2019. Entity-centric\ncontextual affective analysis. In Proceedings of the\n57th Annual Meeting of the Association for Computa-\ntional Linguistics , pages 2550\u20132560, Florence, Italy.\nAssociation for Computational Linguistics.\nMaarten Grootendorst. 2022. Bertopic: Neural topic\nmodeling with a class-based tf-idf procedure. arXiv\npreprint arXiv:2203.05794 .\nMatthew Hoffman, Francis Bach, and David Blei. 2010.\nOnline learning for latent dirichlet allocation. ad-\nvances in neural information processing systems , 23.\nBenjamin Horne, Mauricio Gruppi, and Sibel Adali.\n2022. NELA-GT-2021.\nAlexander Hoyle, Pranav Goel, Andrew Hian-Cheong,\nDenis Peskov, Jordan Boyd-Graber, and Philip4167\nResnik. 2021. Is automated topic model evaluation\nbroken? the incoherence of coherence. Advances\nin Neural Information Processing Systems , 34:2018\u2013\n2033.\nYuening Hu, Jordan Boyd-Graber, Brianna Satinoff, and\nAlison Smith. 2014. Interactive topic modeling. Ma-\nchine learning , 95:423\u2013469.\nPhilippe Laban and Marti A Hearst. 2017. newslens:\nbuilding and visualizing long-ranging news stories.\nInProceedings of the Events and Stories in the News\nWorkshop , pages 1\u20139.\nYuanyuan Lei, Ruihong Huang, Lu Wang, and Nick\nBeauchamp. 2022. Sentence-level media bias analy-\nsis informed by discourse structures. In Proceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing , pages 10040\u201310050,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nChang Li and Dan Goldwasser. 2019. Encoding so-\ncial information with graph convolutional networks\nforpolitical perspective detection in news media. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 2594\u2013\n2604.\nSiyi Liu, Sihao Chen, Xander Uyttendaele, and Dan\nRoth. 2021. MultiOpEd: A corpus of multi-\nperspective news editorials. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies , pages 4345\u20134361, On-\nline. Association for Computational Linguistics.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and\nDerry Tanti Wijaya. 2019. Detecting frames in news\nheadlines and its application to analyzing news fram-\ning trends surrounding us gun violence. In Proceed-\nings of the 23rd conference on computational natural\nlanguage learning (CoNLL) , pages 504\u2013514.\nYiwei Luo, Dallas Card, and Dan Jurafsky. 2020. De-\ntecting stance in media on global warming. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020 , pages 3296\u20133315.\nLeland McInnes, John Healy, and James Melville. 2018.\nUmap: Uniform manifold approximation and pro-\njection for dimension reduction. arXiv preprint\narXiv:1802.03426 .\nDavid Mimno, Hanna Wallach, Edmund Talley, Miriam\nLeenders, and Andrew McCallum. 2011. Optimizing\nsemantic coherence in topic models. In Proceed-\nings of the 2011 conference on empirical methods in\nnatural language processing , pages 262\u2013272.\nSebasti\u00e3o Miranda, Arturs Znotins, Shay B Cohen, and\nGuntis Barzdins. 2018. Multilingual clustering of\nstreaming news. In Proceedings of the 2018 Con-\nference on Empirical Methods in Natural Language\nProcessing , pages 4535\u20134544.Davoud Moulavi, Pablo A Jaskowiak, Ricardo JGB\nCampello, Arthur Zimek, and J\u00f6rg Sander. 2014.\nDensity-based clustering validation. In Proceedings\nof the 2014 SIAM international conference on data\nmining , pages 839\u2013847. SIAM.\nFederico Nanni, Simone Paolo Ponzetto, and Laura Di-\netz. 2017. Building entity-centric event collections.\nIn2017 ACM/IEEE Joint Conference on Digital Li-\nbraries (JCDL) , pages 1\u201310. IEEE.\nJianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gus-\ntavo Hern\u00e1ndez \u00c1brego, Ji Ma, Vincent Y Zhao,\nYi Luan, Keith B Hall, Ming-Wei Chang, et al.\n2021. Large dual encoders are generalizable retriev-\ners.arXiv preprint arXiv:2112.07899 .\nMaria Leonor Pacheco, Tunazzina Islam, Monal Maha-\njan, Andrey Shor, Ming Yin, Lyle Ungar, and Dan\nGoldwasser. 2022. A holistic framework for analyz-\ning the COVID-19 vaccine debate. In Proceedings\nof the 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 5821\u20135839,\nSeattle, United States. Association for Computational\nLinguistics.\nMaria Leonor Pacheco, Tunazzina Islam, Lyle Ungar,\nMing Yin, and Dan Goldwasser. 2023. Interactive\nconcept learning for uncovering latent themes in large\ntext collections. In Findings of the Association for\nComputational Linguistics: ACL 2023 , pages 5059\u2013\n5080, Toronto, Canada. Association for Computa-\ntional Linguistics.\nGirish Palshikar et al. 2009. Simple algorithms for\npeak detection in time-series. In Proc. 1st Int. Conf.\nAdvanced Data Analysis, Business Analytics and In-\ntelligence , volume 122.\nHannah Rashkin, Sameer Singh, and Yejin Choi. 2016.\nConnotation frames: A data-driven investigation. In\nProceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) , pages 311\u2013321, Berlin, Germany. As-\nsociation for Computational Linguistics.\nLev Ratinov, Dan Roth, Doug Downey, and Mike An-\nderson. 2011. Local and global algorithms for disam-\nbiguation to wikipedia. In Proceedings of the 49th\nannual meeting of the association for computational\nlinguistics: Human language technologies , pages\n1375\u20131384.\nRadim Rehurek and Petr Sojka. 2011. Gensim\u2013python\nframework for vector space modelling. NLP Centre,\nFaculty of Informatics, Masaryk University, Brno,\nCzech Republic , 3(2):2.\nShamik Roy and Dan Goldwasser. 2020. Weakly su-\npervised learning of nuanced frames for analyzing\npolarization in news media. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP) , pages 7698\u20137716.4168\nShamik Roy, Mar\u00eda Leonor Pacheco, and Dan Gold-\nwasser. 2021. Identifying morality frames in political\ntweets using relational learning. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing , pages 9939\u20139958.\nKailash Karthik Saravanakumar, Miguel Ballesteros,\nMuthu Kumar Chandrasekaran, and Kathleen Mck-\neown. 2021. Event-driven news stream clustering\nusing entity-aware contextual embeddings. In Pro-\nceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume , pages 2330\u20132340.\nAndreas Spitz and Michael Gertz. 2018. Exploring\nentity-centric networks in entangled news streams. In\nCompanion Proceedings of the The Web Conference\n2018 , pages 555\u2013563.\nTodor Staykovski, Alberto Barr\u00f3n-Cedeno, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Dense vs.\nsparse representations for news stream clustering.\nDeyu Zhou, Haiyang Xu, and Yulan He. 2015. An unsu-\npervised bayesian modelling approach for storyline\ndetection on news articles. In Proceedings of the\n2015 Conference on Empirical Methods in Natural\nLanguage Processing , pages 1943\u20131948.\nA Document Retrieval Module\nThis module retrieves news articles relevant to an\nissue of interest. User is expected to provide an\nissue name or a set of issue names around which\nthe documents are to be retrieved. Using this input,\nwe generate a set of relevant keywords associated\nwith each issue by prompting GPT-3.5. We craft\nthe prompt in such a way that GPT-3.5 generates a\nlist of keywords that appear in the context of the\nissue specified by the user. We then use BM25\nalgorithm on the indexed NELA data to retrieve\ndocuments associated with each keyword for the\nissue. We use BM25 with the default settings for\nb, and only vary the term frequency saturation\nk1 = 1 .3as we are dealing with longer news\ndocuments.\nNELA Dataset It is a collection of \u22481.8Mnews\ndocuments from 367 news outlets between January\n1st 2021, and December 31st, 2021. NELA is\nsuccessful in organizing the news articles based\non their ideological bias. However, this structure\nis not well-suited to characterize the differences\nin discourse between the political ideologies in\nonline news media.\nIn this work, we primarily focus on 207news\nsources that are based out of USA. The political\nrating corresponding to these sources are mappedto a four-way { left,right ,center ,conspiracy-\npseudoscience }. The ratings are decided based\non MBFC4. Using the scores provided by MBFC,\nwe categorize left-center andright-center political\nratings to one of the { center ,left,right } ratings.\nB Event Candidate Generation\nTemporal Filtering We implement an outlier de-\ntection algorithm (Palshikar et al., 2009) which\nconsiders a temporal window of 2kpoints around\neach data point, x. These are kpoints before x, and\nkpoints after x. Using these 2kdata points, we\ncompute the mean and standard deviation. The data\npoint is considered as a local peak if it is at least\na standard deviation away from the mean value.\nAmong the detected local peaks, we further apply\na filter to retrieve global peaks. We do this by com-\nputing the mean and standard deviation values for\nthe detected local peaks. If the value at the local\npeak is above the mean value, we mark that as a\nglobal peak. In the case of multiple peaks within\na temporal window of kdays, we merge them to\nform a single peak. We set the value of k= 3for\nour experiments. Figure 3 shows the result of this\nalgorithm for the issue - Abortion .\nFigure 3: Dynamic Analysis of documents from Jan 1 to\nDec 31, 2021, for the issue Abortion .X-axis represents\ntime (one day interval). Red dots indicate detected\npeaks.\nC Models and Hyperparameters\nTo obtain topics from LDA with Variational Bayes\nsampling (under both settings), we use Gensim (Re-\nhurek and Sojka, 2011) implementation. We follow\nthe preprocessing steps shown in (Hoyle et al.,\n2021), and estimate the number of topics in a data-\ndriven manner by maximizing . We do a grid-\nsearch over a set of {2,3,4,5}for LDA (Temporal)\nmethod. The set of topics for LDA (baseline) is\n{10,20,\u00b7\u00b7\u00b7,60}.\n4https://mediabiasfactcheck.com/4169\nIn the case of HDBSCAN, when used for our\nmethod, and as a standalone clustering model,\nwe use a data-driven approach to estimate the\nbest number of topics by maximizing the DBCV\nscore (Moulavi et al., 2014). We retain the default\nsettings for cluster_selection_method , and metric\nparameters, while we change the min_cluster_size\nto get more sensible topics. This number is selected\nbased on a grid search whose values are sensitive\nto the number of input data points. Suppose |X|\ndenote the number of data points, then the grid\nparameters for HDBSCAN used in our method in-\nclude{0.05\u00d7|X|,0.06\u00d7|X|,\u00b7\u00b7\u00b70.1\u00d7|X|}. This\nis updated to consider only the last three elements\nfor HDBSCAN (standalone). If not, we see un-\nusually high number of topics per peak. We set\nthen_neighbors parameter in UMAP embedding\nmodel to min_cluster_size .\nFor cluster incoherency check, we choose a\nthreshold of 0.6. If the cosine similarity score\nbetween the event summary embedding and the\ndocument embedding is lower than this threshold,\nwe discard those documents as noise.\nFor our method\u2019s similarity module, we choose a\nthreshold of 0.69based on evaluating the trade-off\nbetween purity, coherence and coverage values.\nPrior to computing the TF-IDF scores to retrieve\nthe top-K entities, we use a simple yet effective\nmethod for entity linking (Ratinov et al., 2011) that\nis based on Wikipedia mentions.\nD Evaluation Metrics\nIn this section, we describe the evaluation metrics\nproposed in our work.\nSeveral studies (Nanni et al., 2017; Spitz and\nGertz, 2018; Chen et al., 2023) in the past have\nshown that entities and the context associated with\nthem can potentially represent a topic or an event.\nWith this as the premise, we have devised entity-\nbased evaluation metrics that helps us quantify the\nquality of the resulting clusters. We further vali-\ndate our results through a simple human evaluation\nprocess on partially annotated data for the issue -\nClimate Change .\nWe define entity purity for an event to be the\nproportion of the documents that are mapped to\nthat event, where the document has at least one\nentity that overlaps with the top-K TF-IDF based\nentities for that event (k = 10). The idea is that\ncentral entities associated with a news event must\nbe reflected in the documents clustered for thatevent. Note that in order to remove commonly\nrepeated entities in news such as Biden, Trump etc.,\nwe consider top-K TF-IDF based entities for an\nevent as central entities. A purity score of 100%\nfor an event indicates that every document in the\ncluster has atleast a mention of one of the top-K\ncentral entities, suggesting that each document is\npotentially discussing about that event.\nWe also define entity coherence metric as an\nadditional measure to validate the cluster quality.\nWe adapt the topic coherence metric from (Mimno\net al., 2011) to define entity coherence C, for an\nevent, eias\nC(ei, Vei) =M/summationdisplay\nm=2m\u22121/summationdisplay\nl=1logF(veim, vei\nl) +\u03f5\nF(vei\nl)\nwhere, eidenotes an event, Vei =\n{vei\n1, vei\n1,\u00b7\u00b7\u00b7, vei\n10}denotes the top-10 TF-\nIDF based entities for ei,F(veim, vei\nl)indicates the\nco-document frequency (counts the joint document\nfrequency for entity types vm,vl),F(vl)indicates\ndocument frequency for entity type vl, and \u03f5\nis a smoothing factor. Informally, it considers\nco-occurrences of central entity pairs (as opposed\nto topic words) in the clustered documents to\nmeasure coherency for an event. Note that a higher\nvalue indicates a highly coherent news event. By\nvirtue of using login formula, a value closer to\nzero is more desirable than a largely negative\nvalue. We further observe that this measure is\npositively correlated with entity purity, indicating\nthat purity can be a good measure to represent\ncluster coherence.\nIn addition to these, we have an additional metric\ncoverage , which essentially counts the number of\ndocuments accounted for in the clustering process.\nIdeally, we want any clustering algorithm to reject\nnoise and cluster every document in the corpus. We\ndo not want to exclude any document. Post noise\nremoval, a good clustering algorithm is expected\nto have a coverage of 100% in an ideal scenario.\nE Human Evaluation\nFor the event coherence case, the annotators are\nasked to verify if the top-3 documents for the event\nare in agreement with each other. They are asked\nto provide a score of 1if the documents are in\nagreement, a score 0if they are not, or a score of\n\u22121if they are not sure about the label. We show\nonly the titleandfirst four lines of the news article.\nWe did not receive any \u22121for this case.4170\nTo evaluate the mapping quality of our model,\nwe randomly sample a set of peaks, and within\neach peak, we randomly sample 50documents to\nform an overall set of 430documents mapped to\nvarious events for the issue Climate Change . We\nshow the title andfirst four lines of news article,\nand the event summary to the annotators. Similar to\ncoherence case, we ask the annotators to provide a\nscore of 1if the document aligns with the summary,\n0for no alignment, or \u22121if they are not sure. There\nis no clear definition of alignment, and we let the\nannotators make this judgement. We received a\ntotal of 6not sure labels. On eliminating unsure\ninstances, our method got 352out of 424instances\ncorrect, which translates to a precision value of\n\u22480.83.\nHowever, in order to compare the performance\nof our method with other model, we devise a strat-\negy to derive \u2019good\u2019 and \u2019bad\u2019 example-pairs by\ntreating human-labeled data as the gold standard.\nWe assume that if the two documents receive a\nscore of 1within the same event, then they must be\n\u2019equivalent\u2019.\nWith this assumption, for a given tempo-\nral peak and within every event, we construct\n\u2019good/positive\u2019 example set by considering every\npossible document-pairs from valid cluster assign-\nments. To construct \u2019bad/negative\u2019 example set, we\nconsider a union of the following - (a) Document-\npairs from valid cluster assignments between dif-\nferent events; (b) Document-pairs from an invalid,\nand a valid cluster assignment within each event.\nThe task is to evaluate how well each method per-\nforms in retaining the good example-pairs within\nthe same cluster. We ensure to remove all the doc-\numents that are not mapped to any event by each\nmethod. Owing to the nature of data collection, we\nreport only the precision values for all the three\nmethods under consideration.\nF Results\nG Prompt Templates\nThis section shows the prompt templates used to\ngenerate multi-document summary (Fig. 9), and to\nverify if a pair of cluster characterization is equiva-\nlent (Fig. 10).Issue ModelAvg. Inter-Event\nCosine Similarity# Events# Merge\nOperations# Remove\nOperations\nCapitol InsurrectionHDBSCAN 0.864877655 64 - -\nOur Method 0.641329667 40 21 3\nCoronavirusHDBSCAN 0.860832152 122 - -\nOur Method 0.857558543 112 10 2\nClimate ChangeHDBSCAN 0.833522985 74 - -\nOur Method 0.772742185 56 11 7\nFree SpeechHDBSCAN 0.847346069 72 - -\nOur Method 0.668949583 56 7 13\nAbortionHDBSCAN 0.877382542 48 - -\nOur Method 0.410449078 24 20 4\nImmigrationHDBSCAN 0.852341823 64 - -\nOur Method 0.75051009 48 15 1\nGun ControlHDBSCAN 0.829052923 60 - -\nOur Method 0.663993032 40 9 9\nCriminal Injustice & Law EnforcementHDBSCAN 0.824876478 70 - -\nOur Method 0.581169596 48 7 13\nRacial EquityHDBSCAN 0.839611843 98 - -\nOur Method 0.730141103 68 13 17\nDefense and National SecurityHDBSCAN 0.837432569 106 - -\nOur Method 0.835570683 89 11 6\nCorruptionHDBSCAN 0.818098607 46 - -\nOur Method 0.821913246 30 5 31\nTable 5: Shows the impact of cluster merge and remove\noperations for each issue. Note that input data and hyper-\nparameters used by HDBSCAN in this setting are the\nsame as our method. Lower the similarity score the\nbetter.\nIssue Coverage Avg. Entity Purity Avg. Entity Coherence\nCapitol Insurrection 65.164 72.253 -619.226\nCoronavirus 54.562 56.159 -762.147\nClimate Change 56.263 84.509 -519.816\nFree Speech 47.378 78.124 -589.486\nAbortion 87.946 66.658 -739.842\nImmigration 67.398 76.275 -618.273\nGun Control 46.797 88.781 -427.161\nCriminal Injustice & Law Enforcement 38.701 87.209 -561.958\nRacial Equity 41.966 82.548 -549.100\nDefense and National Security 55.264 84.907 -451.647\nCorruption 63.702 79.943 -535.650\nAverage Stats 56.831 77.942 -579.482\nTable 6: Statistics for our proposed method after in-\ncreased coverage with acceptable reduction in entity\npurity ( \u2248 \u22125points on an average for all issues).\nSummary Document\nNews Event Title: Election Fraud Claims in the US.\nNews Event Description: This is about the claims of\nelection fraud in the US and the upcoming congressional\nmeeting to certify the Electoral College votes.Vice President Pence supports Congress members who will\nobject to Biden\u2019s designation Jan. 6.\nVice President Mike Pence welcomed the decision by a group of\nsenators, led by Sen. Ted Cruz ( R-Texas ), to challenge the\nscheduled nomination of Democratic presidential candidate\nJoe Biden as the winner of the election held on Nov. 3.\nThe vice president welcomes the efforts of members of the House and\nSenate to use the authority they have under the law to raise objections\nand bring forward evidence before the Congress and the American\npeople, Pence\u2019s chief of staff Marc Short said, according to Axios\non Jan. 3.@ @ @ @ @ @ @ of millions of Americans\nabout voter fraud and irregularities.\nTable 7: Illustrates an example where the cluster was\nremoved due to the document being present in the top-5\nlist for this event. We see that the document is talking\nabout the same issue from a different frame and merely,\nusing a similarity module to identify cluster incoherency\nis not sufficient in this case.4171\nIssue Model Coverage Avg. Entity Purity Avg. Entity Coherence Agg. Event Count\nCapitol InsurrectionLDA (baseline) 99.781 36.058 -1027.214 60\nTemporal Filtering - 27.867 -1092.882 17\nLDA (Temporal) 85.491 37.129 -1025.687 64\nHDBSCAN (standalone) 77.964 54.155 -888.38 50\nBERTopic 83.351 64.819 -791.722 54\nOur Method 47.349 76.821 -547.06 40\nCoronavirusLDA (baseline) 99.774 17.885 -1003.54 60\nTemporal Filtering - 8.79 -1184.476 21\nLDA (Temporal) 62.784 14.487 -1110.409 83\nHDBSCAN (standalone) 65.586 34.458 -1004.468 64\nBERTopic 61.731 35.915 -941.667 54\nOur Method 41.965 56.299 -749.045 112\nClimate ChangeLDA (baseline) 99.767 42.439 -883.566 60\nTemporal Filtering - 28.02 -1040.555 18\nLDA (Temporal) 90.89 39.806 -957.687 64\nHDBSCAN (standalone) 84.011 64.148 -763.608 53\nBERTopic 83.595 67.635 -689.429 65\nOur Method 45.015 81.528 -453.923 56\nFree SpeechLDA (baseline) 99.684 21.785 -1090.102 60\nTemporal Filtering - 30.039 -1105.5 20\nLDA (Temporal) 93.135 41.441 -1032.338 68\nHDBSCAN (standalone) 83.175 65.337 -772.847 72\nBERTopic 83.649 70.303 -704.514 75\nOur Method 35.46 87.964 -439.135 56\nAbortionLDA (baseline) 99.078 33.739 -917.643 60\nTemporal Filtering - 36.691 -1045.857 14\nLDA (Temporal) 93.436 48.161 -914.619 48\nHDBSCAN (standalone) 79.04 70.162 -732.593 37\nBERTopic 85.655 71.765 -733.281 42\nOur Method 77.198 70.332 -594.95 24\nImmigrationLDA (baseline) 99.746 24.253 -1033.2 60\nTemporal Filtering - 24.781 -1060.21 19\nLDA (Temporal) 87.848 34.72 -993.803 66\nHDBSCAN (standalone) 79.944 61.818 -776.407 54\nBERTopic 86.339 67.634 -713.125 56\nOur Method 53.964 80.107 -535.755 48\nGun ControlLDA (baseline) 99.606 26.002 -1049.5 60\nTemporal Filtering - 35.109 -903.333 18\nLDA (Temporal) 90.146 42.534 -955.083 61\nHDBSCAN (standalone) 91.494 67.047 -649.708 48\nBERTopic 94.906 66.774 -675.880 50\nOur Method 36.306 95.124 -323 40\nCriminal Injustice &\nLaw EnforcementLDA (baseline) 99.85 40.432 -996.468 60\nTemporal Filtering - 31.152 -1075.809 20\nLDA (Temporal) 96.648 45.199 -1027.712 66\nHDBSCAN (standalone) 87.968 67.118 -796.317 68\nBERTopic 88.725 67.105 -756.769 78\nOur Method 31.368 94.194 -463.652 48\nRacial EquityLDA (baseline) 99.79 31.377 -1073 60\nTemporal Filtering - 30.931 -1109.25 24\nLDA (Temporal) 93.893 40.448 -1040.695 82\nHDBSCAN (standalone) 80.344 63.346 -811.065 76\nBERTopic 85.374 66.614 -747.699 75\nOur Method 33.206 89.082 -369.184 68\nDefense &\nNational SecurityLDA (baseline) 99.951 38.158 -940.564 60\nTemporal Filtering - 25.312 -1098.041 24\nLDA (Temporal) 91.609 40.008 -1008.138 87\nHDBSCAN (standalone) 84.319 71.648 -686.023 84\nBERTopic 89.004 74.519 -617.425 87\nOur Method 40.083 90.61 -353.291 89\nCorruptionLDA (baseline) 99.572 34.557 -1023.875 60\nTemporal Filtering - 30.965 -961.727 11\nLDA (Temporal) 93.33 40.925 -992.941 34\nHDBSCAN (standalone) 85.763 68.762 -663.4 36\nBERTopic 82.115 73.368 -615.773 50\nOur Method 45.233 87.577 -427.75 30\nTable 8: Compares the results obtained for each method and issue. Last column shows summation of all event\ncounts (from each detected temporal peak). For LDA(Temporal), we assigned the document to its most probable\ntopic if the probability was \u22650.5.4172\nYou need to provide a title and a sentence long description for the news event based on\nnews article snippets shown below. The title and description should not be too specific to the\narticles shown below but rather, they need to focus on the main event.\nNews Article1: **Title**\n*Description**\nNews Article2: **Title**\n*Description**\nNews Event Title: **Response**\nNews Event Description: **Response**\nNews Article1: **Title**\n*Description**\nNews Article2: **Title**\n*Description**\nTable 9: Prompt template for multi-document event summary generation (shown as one-shot).\nYou need to tell if the following two news event descriptions belong to the same news event.\nYou need to say yes or no and nothing more.\nNews Event Title1: **Title**\n*Description**\nNews Event Title2: **Title**\n*Description**\nAnswer:\nTable 10: Prompt template to check for entailment (shown as zero-shot).4173", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Using LLM for improving key event discovery: Temporal-guided news stream clustering with event summaries", "author": ["N Nakshatri", "S Liu", "S Chen", "D Roth"], "pub_year": "2023", "venue": "Findings of the \u2026", "abstract": "Understanding and characterizing the discus-sions around key events in news streams is  important for analyzing political discourse. In this work, we study the problem of identification of"}, "filled": false, "gsrank": 534, "pub_url": "https://aclanthology.org/2023.findings-emnlp.274/", "author_id": ["z0tNU24AAAAJ", "Z4vfzqkAAAAJ", "PQ9dRCgAAAAJ", "E-bpPWgAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:2h9iVf8PMsAJ:scholar.google.com/&output=cite&scirp=533&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D530%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=2h9iVf8PMsAJ&ei=ZrWsaNvsJbXCieoP4PfQ0A8&json=", "num_citations": 24, "citedby_url": "/scholar?cites=13849149393441267674&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:2h9iVf8PMsAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2023.findings-emnlp.274.pdf"}}, {"title": "Chinese narrative about Africa", "year": "2026", "pdf_data": "Vol. 30 \u2022 No. 1 \u2022 2026 \u2022 ISSN: 2084-6118 \u2022 DOI: 10.2478/mgrsd-2025-0012MISCELLANEA GEOGRAPHICA \u2013 REGIONAL STUDIES ON DEVELOPMENT 1\nIntroduction\nChina seeks to expand its economic presence in Africa as a \nstrategic move to secure the resources and markets necessary \nto sustain its rapid economic growth. Even though Africa is not a \nprimary region for the export1 or import2 of Chinese goods, China \nis heavily investing in relationships with the continent, aiming \nto fill the niche created by the gradual deterioration (or even \nseverance) of relationships with former European colonial powers \n(Ajakaiye 2006 ). China is also positioning itself as the new donor for \nthe continent. According to Paul Zeleza\u2019s work, China enabled \nAfrica to reach for \u201cnew economic opportunities and diplomatic \nbreathing room\u201d ( Zeleza 2014, p.165 ). However, according to many \nresearchers, this generosity should be approached with caution \nas it may reflect neocolonial and neo-imperialist ambitions ( ed. \nvan Dijk 2009 ). \nThe flagship project of Sino-African cooperation is the \ncontroversial Belt and Road Initiative (BRI) \u2013 a large-scale \ninfrastructure development programme aimed at connecting Asia \nwith Africa and Europe. Recently, the African continent has also \nexperienced a significant influx of economic migrants from China, \nwhich has been relatively well received by the local communities. \nHowever, research on this topic remains scarce ( Mohan & Tan-\nMullins 2009 ).\nThe Chinese initiative in Africa is also characterized by a \nstrong focus on maintaining soft power. One of the main tools \nfor shaping a positive image of China in the eyes of Africans, as \n1World Integrated Trade Solution 2024, China Product Exports by Country and \nRegion in US$ Thousand 2017\u20132022. Available from: <https://wits.worldbank.org/\nCountryProfile/en/country/CHN/startyear/2017/endyear/2023/trade Flow/Export/\nindicator/XPRT-TRD-VL/partner/All/product/Total>. [27 November 2024].\n2World Integrated Trade Solution 2024, China Product Imports by Country and \nRegion in US$ Thousand 2017\u20132022. Available from: <https://wits.worldbank.org/\nCountryProfile/en/Country/CHN/StartYear/2017/EndYear/2022/TradeFlow/Import/\nIndicator/MPRT-TRD-VL/Partner/ALL/Product/Total>. [27 November 2024].well as promoting cooperation between them, is Chinese media \n(Memon & Sandano 2023 ). One of the most recognizable of these \nnews outlets is China Global Television Network ( Memon & Sandano \n2023). Rebranded from CCTV International in December 2016, \nCGTN aimed to compete with popular media outlets, such as \nBBC or CNN, attracting international audiences worldwide ( Varrall \n2020; Yan et al. 2022 ).\nAs research has previously shown, mass media can reflect \nstate policies ( Wlezien & Soroka 2024 ), especially when dealing with \nhighly biased journalism3 and an editorial board that is frequently \naccused of close ties with Xi Jinping\u2019s government ( Varrall 2020 ). \nFor this reason, the study on Chinese media content is important \nin the context of international relations.\nThe use of media in geographical research is also \nworth explaining. According to Paul C. Adams ( Adams 2018 ), \ncommunication permeates human surroundings in the \ncontemporary world, integrating into the environment. Information \nhas become a permanent part of the anthropogenic landscape. \nFor a field as interdisciplinary and broad in scope as geography, it \nis crucial to remain flexible, and to adapt to the ways in which the \nworld around us, and its principles, evolve. Moreover, media can \nprovide various information that is valuable from a geographers\u2019 \npoint of view, such as spatial data. Research on Chinese media \ndid attract the interest of researchers exceptionally quickly; \nhowever, in general, geographical media research remains niche. \nThe purpose of this article is to examine the image of \nAfrican countries portrayed by CGTN through its content. The \nauthor anticipated that CGTN would promote a positive narrative \nregarding African countries. Emphasis would be placed on the \naid provided for Africa. Additionally, the news would focus on the \ncountries that are China\u2019s most important economic partners.\n3Media Bias Fact Check 2024, China Global Television Network (CGTN) \u2013 Bias and \nCredibility. Available from: <https://mediabiasfactcheck.com/china-global-television-\nnetwork-cgtn/>. [28 November 2024].Chinese narrative about Africa: \nQuantitative analysis of CGTN\u2019s online publications\nFaculty of Geography and Regional Studies, University \nof Warsaw, Warsaw, Poland  \ne-mail: w.jackowska2@student.uw.edu.plWiktoria Jackowska\nReceived: 17 January 2025 \nAccepted: 13 February 2025Abstract\nThis article aims to study the portrayal of African countries in online \npublications of one of the leading internationally focused Chinese \nmedia platforms \u2013 China Global Television Network (widely known as \nCGTN). China\u2019s increasing economic engagement in Africa, including in \ninvestments, infrastructure projects under the Belt and Road Initiative, and \nthe influx of Chinese migrants reflects its strategic pursuit of tightening \nSino-African relations and gaining influence on the continent. Using a \nquantitative content analysis of CGTN\u2019s online news, the study reveals \na dual narrative. African countries are depicted in an overall positive \nmanner. However, their need for external aid is emphasized. The author \nalso highlights the need for geographers to pay greater attention to media \nissues, which could help to better understand and study the anthropogenic \nlandscape in the contemporary world.\nKeywords\nAfrica \u2022 China \u2022 media geography \u2022 media coverage \u2022 news sentiment\n\u00a9 2025 Author, published by Sciendo.  This work is licensed under the Creative Commons Attribution 4.0 License.\nVol. 30 \u2022 No. 1 \u2022 2026 \u2022 ISSN: 2084-6118 \u2022 DOI: 10.2478/mgrsd-2025-0012MISCELLANEA GEOGRAPHICA \u2013 REGIONAL STUDIES ON DEVELOPMENT2\nMethod\nThe research took the form of quantitative content analysis. \nData collection was carried out by reviewing the content of \nonline news published on CGTN\u2019s website. Data was gathered \nfrom news articles published between 7 December 2023 and 16 \nMarch 2024, covering a period of 100 days. \nThe content analysis was carried out through three research \nquestions: (1) Which African countries are mentioned?; (2) \nWhat is the overall sentiment of the publication?; (3) Does \nthe publication mention intervention by non-African countries/\norganizations?\nIn the course of the sentiment analysis, the author measured \nthe proportion of positive content relative to the total number \nof mentions analyzed (Figure 1). The indicator, created for the \npurpose of this study, will be referred to as Positive Sentiment \nIndex (PSI).\nThe obtained results were compared with several statistics, \nselected by the author, concerning the engagement of African \nstates in economic and diplomatic cooperation with China.\nResults\nDuring the research period, CGTN published 116 news \narticles related to Africa. Some publications covered more than \none country, which was described in the number of mentions \u2013 \n126 (Figure 2).\nFor the purpose of the study, the author created four \nsubjective categories of the text\u2019s sentiment: negative, positive, \nneutral, difficult to define (Table 1). Positive sentiment accounted \nfor half of all the mentions, while negative was 25%.\nThe results for the PSI index can be observed on the map \n(Figure 2). Thirteen countries achieved 100%, which indicates \nthat all analyzed mentions were positive. On the other hand, nine \ncountries received a score of 0%. The results of six countries \nwere in 60\u201399% range. The results of seven countries were in \nthe 30\u201359% range. Finally, three countries achieved a result \nranging from 1% to 29%. Countries frequently mentioned tended \nto achieve moderate PSI values. Exceptions included Angola, \nNigeria, and South Sudan. Angola was mentioned three times, \nand each instance conveyed positive content, resulting in a \nPSI value of 100%. The opposite situation occurred for Nigeria \nand South Sudan, which were mentioned four and three times, \nrespectively, with all mentions being negative.\nWhile the PSI index reflects CGTN\u2019s general narrative about \nAfrican countries, the author is aware of its limitations. Countries \nwith fewer mentions achieved very high or very low scores due to \na lack of diverse media narratives. Therefore, the interpretation \nof results derived from the index should always be considered in \nthe context of the total number of mentions.\nThe last research question concerned whether the texts \ncontained any mentions of an intervention or aid by non-\nAfrican subjects. Such information was included in 54% of the \npublications.\nDiscussion\nThe most frequently mentioned countries in CGTN\u2019s \npublications were the Democratic Republic of the Congo (12), \nEgypt (9), South Africa (8), Sudan (7), Kenya (6), and Somalia \n(6). It is not possible to identify a single region of Africa that stood \nout with a significantly greater interest from the studied media \noutlet \u2013 the data is scattered throughout the whole continent. \nOnly West Africa received very little interest from CGTN.\nA clear dominance of positive over negative news was \nobserved. Southern Africa was portrayed in a slightly more \npositive manner than the rest of the regions. However, once \nagain, the obtained data is heterogeneous. The PSI results \nfor the most frequently mentioned countries were as follows: Democratic Republic of the Congo \u2013 33%, Egypt \u2013 44%, South \nAfrica \u2013 38%, Sudan \u2013 29%, Kenya \u2013 83%, and Somalia \u2013 50%. \nWith the exception of Kenya, these countries had a moderate or \nlow share of positive news. \nMentions of aid or interventions by non-African subjects \nappeared in more than half of the publications, which supports \nthe thesis that African countries are portrayed as dependent \nentities in need of assistance. It should be noted that the \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\n\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e+\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f+\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50+\ud835\udc51\ud835\udc51\ud835\udc51\ud835\udc51\u00d7100%  \na \u2013 number  of positive mentions  \nb \u2013 number  of negative mentions  \nc \u2013 number  of neutral mentions  \nd \u2013 number  of difficult to define mentions  \nFigure 1. Positive Sentiment Index formula\nSource: own elaboration\nFigure 2. Number of mentions and Positive Sentiment Index \nvalue for each country in CGTN during the research period \n(n=126)\nSource: own elaboration\nTable 1. Sentiment of the content that appeared on CGTN dur -\ning the research period (n=126)\nsentiment N %\nnegative 31 25\npositive 63 50\nneutral 18 14\ndifficult to define 14 11\nSource: own elaboration\nVol. 30 \u2022 No. 1 \u2022 2026 \u2022 ISSN: 2084-6118 \u2022 DOI: 10.2478/mgrsd-2025-0012MISCELLANEA GEOGRAPHICA \u2013 REGIONAL STUDIES ON DEVELOPMENT3\nmentioned support largely referred to the Chinese influence on \nthe continent.\nEconomic issues play a noticeable role in the selection \nof content for publication. When looking at the most lucrative \npartners in Chinese exports \u2013 South Africa, Nigeria, and Egypt, \nthese countries were mentioned frequently or moderately, and \nhad a low or very low PSI index value. Regarding the countries \nreceiving the highest Chinese FDI4 \u2013 Democratic Republic of the \nCongo, South Africa, and Ethiopia, the Democratic Republic of \nthe Congo and South Africa were mentioned frequently but had a \nlow PSI value, while Ethiopia appeared very rarely in publications \nbut had a higher PSI. Participation in the BRI programme was \nnot taken into account as nearly all countries on the continent \nare involved in it.\nA certain trend can be observed \u2013 the largest economic \npartners were mentioned more frequently but presented in a less \npositive manner. This is likely an attempt to justify the expansion of \nChinese influence and governance in relation to these countries. \n4SAIS China Africa Research Initiative 2024, Chinese FDI in Africa Data Overview. \nAvailable from: <https://www.sais-cari.org/chinese-investment-in-africa>. [29 November \n2024].If we consider the foreign diplomatic trips made by President Xi \nJinping ( Turcs\u00e1nyi et al. 2021 ), the most frequently visited countries \nin Africa were (previously outlined) South Africa and Egypt, which \nfurther confirms the trend described above.\nConclusions\nThe author\u2019s assumptions were fully confirmed \u2013 Africa is \nportrayed in an overall positive manner but, at the same time, \nas a subject with a strong need for external aid. Economic and \ndiplomatic issues exhibit the same trend \u2013 countries that are \nmore profitable for China are mentioned more frequently in \nCGTN but they have a lower PSI value, which means they are \nbeing presented less positively. Finally, the author expresses \nthe hope that media will be more frequently considered in future \ngeographical research.\nORCID\nWiktoria Jackowska  https://orcid.org/0009-0000-0231-5717\nReferences\nAdams, PC 2018, \u2018Geographies of media and communication \nII: Arcs of communication\u2019, Progress in Human Geography , \nvol. 42, no. 4, pp. 590\u2013599.\nAjakaiye, O 2006, \u2018China and Africa: Opportunities and \nchallenges\u2019, AERC Scoping Studies on China-Africa \nEconomic Relations, African Economic Research \nConsortium (AERC), Nairobi.\nvan Dijk, MP (ed.) 2009, The new presence of China in Africa , \nAmsterdam University Press, Amsterdam. \nMemon, NS & Sandano, IA 2023, \u2018China in Africa: The soft power \nof media development\u2019, Africa Development , vol. 48, no. 4, \npp. 81\u2013102.\nMedia Bias Fact Check 2024, China Global Television Network \n(CGTN) \u2013 Bias and Credibility . Available from: <https://\nmediabiasfactcheck.com/china-global-television-network-\ncgtn/> [28 November 2024].\nMohan, G & Tan-Mullins, M 2009, \u2018Chinese migrants in Africa as \nnew agents of development? An analytical framework\u2019, The \nEuropean Journal of Development Research , vol. 21, pp. \n588\u2013605.\nSAIS China Africa Research Initiative 2024, Chinese FDI in Africa \nData Overview . Available from: <https://www.sais-cari.org/\nchinese-investment-in-africa>. [29 November 2024].\nTurcs\u00e1nyi, R, \u0160imila\u010dik , M, Eckert, M & Majsniarov\u00e1, N 2021, \nWHO | WHERE | WHEN - International travel of the PRC \nleaders (1949\u20132020) , Central European Institute of Asian \nStudies (CEIAS). Available from: <https://who-where-when.\nceias.eu/>. [29 November 2024].\nVarrall, M 2020, Behind the news: inside China Global Television \nNetwork , Lowy Institute,  Sydney.\nWlezien, C & Soroka, S 2024, Media reflect! Policy, the public, \nand the news , American Political Science Review , vol. 118, \nno. 3, pp. 1563-1569.\nWorld Integrated Trade Solution 2024, China Product Imports by \nCountry and Region in US$ Thousand 2017\u20132022 . Avail -\nable from: <https://wits.worldbank.org/CountryProfile/en/\nCountry/CHN/StartYear/2017/EndYear/2022/TradeFlow/Im -\nport/Indicator/MPRT-TRD-VL/Partner/ALL/Product/Total>. \n[27 November 2024].World Integrated Trade Solution 2024, China Product Exports \nby Country and Region in US$ Thousand 2017\u20132022 . \nAvailable from: <https://wits.worldbank.org/CountryProfile/\nen/country/CHN/startyear/2017/endyear/2023/trade Flow/\nExport/indicator/XPRT-TRD-VL/partner/All/product/Total>. \n[27 November 2024].\nYan, Z, Jiaru, T & Xinlong, L 2022, \u2018A critical analysis of the \nchallenges posed by China Global Television Network \n(CGTN) to the traditional dominance of global media by \nWestern outlets\u2019, International Journal of Social Science and \nEducation Research , vol. 5, no. 11, pp. 102\u2013107.\nZeleza, PT 2014, \u2018The Africa-China relationship: challenges and \nopportunities\u2019, Canadian Journal of African Studies , vol. 48, \nno. 1, pp. 145\u2013169.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Chinese narrative about Africa", "author": ["W Jackowska"], "pub_year": "2026", "venue": "MISCELLANEA GEOGRAPHICA", "abstract": "This article aims to study the portrayal of African countries in online publications of one of the  leading internationally focused Chinese media platforms\u2013China Global Television Network"}, "filled": false, "gsrank": 536, "pub_url": "https://sciendo.com/pdf/10.2478/mgrsd-2025-0012", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:xuI82yAJjfQJ:scholar.google.com/&output=cite&scirp=535&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D530%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=xuI82yAJjfQJ&ei=ZrWsaNvsJbXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:xuI82yAJjfQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://sciendo.com/pdf/10.2478/mgrsd-2025-0012"}}, {"title": "Fine-grained analysis of propaganda in news articles", "year": "2019", "pdf_data": "Fine-Grained Analysis of Propaganda in News Articles\nGiovanni Da San Martino1Seunghak Yu2Alberto Barr \u00b4on-Cede \u02dcno3\nRostislav Petrov4Preslav Nakov1\n1Qatar Computing Research Institute, HBKU, Qatar\n2MIT Computer Science and Arti\ufb01cial Intelligence Laboratory, Cambridge, MA, USA\n3Universit `a di Bologna, Forl `\u0131, Italy,4A Data Pro, So\ufb01a, Bulgaria\nfgmartino, pnakov g@hbku.edu.qa\nseunghak@csail.mit.edu ,a.barron@unibo.it\nrostislav.petrov@adata.pro\nAbstract\nPropaganda aims at in\ufb02uencing people\u2019s\nmindset with the purpose of advancing a spe-\nci\ufb01c agenda. Previous work has addressed\npropaganda detection at the document level,\ntypically labelling allarticles from a propa-\ngandistic news outlet as propaganda. Such\nnoisy gold labels inevitably affect the quality\nof any learning system trained on them. A\nfurther issue with most existing systems is the\nlack of explainability. To overcome these lim-\nitations, we propose a novel task: performing\n\ufb01ne-grained analysis of texts by detecting all\nfragments that contain propaganda techniques\nas well as their type. In particular, we cre-\nate a corpus of news articles manually anno-\ntated at the fragment level with eighteen pro-\npaganda techniques and we propose a suit-\nable evaluation measure. We further design\na novel multi-granularity neural network, and\nwe show that it outperforms several strong\nBERT-based baselines.\n1 Introduction\nResearch on detecting propaganda has focused\nprimarily on articles (Barr \u00b4on-Cedeno et al., 2019;\nRashkin et al., 2017). In many cases, there are no\nlabeled data for individual articles, but there are\nsuch labels for entire news outlets. Thus, often all\narticles from the same news outlet get labeled the\nway that this outlet is labeled. Yet, it has been\nobserved that propagandistic sources could post\nobjective non-propagandistic articles periodically\nto increase their credibility (Horne et al., 2018).\nSimilarly, media generally recognized as objec-\ntive might occasionally post articles that promote a\nparticular editorial agenda and are thus propagan-\ndistic. Thus, it is clear that transferring the label\nof the news outlet to each of its articles, could in-\ntroduce noise. Such labels can still be useful for\ntraining robust systems, but they cannot be used to\nget a fair assessment of a system at testing time.One option to deal with the lack of labels for arti-\ncles is to crowdsource the annotation. However, in\npreliminary experiments we observed that the av-\nerage annotator cannot detach her personal mind-\nset from the judgment of propaganda and bias,\ni.e., if a clearly propagandistic text expresses ideas\naligned with the annotator\u2019s beliefs, it is unlikely\nthat she would judge it as such.\nWe argue that in order to study propaganda in a\nsound and reliable way, we need to rely on high-\nquality trusted professional annotations and it is\nbest to do so at the fragment level, targeting spe-\nci\ufb01c techniques rather than using a label for an en-\ntire document or an entire news outlet.\nOurs is the \ufb01rst work that goes at a \ufb01ne-grained\nlevel: identifying speci\ufb01c instances of propaganda\ntechniques used within an article. In particular, we\ncreate a corresponding corpus. For this purpose,\nwe asked six experts to annotate articles from\nnews outlets recognized as propagandistic and\nnon-propagandistic, marking speci\ufb01c text spans\nwith eighteen propaganda techniques. We also\ndesigned appropriate evaluation measures. Taken\ntogether, the annotated corpus and the evalua-\ntion measures represent the \ufb01rst manually-curated\nevaluation framework for the analysis of \ufb01ne-\ngrained propaganda. We release the corpus (350K\ntokens) as well as our code in order to enable fu-\nture research.1Our contributions are as follows:\n\u000fWe formulate a new problem: detect the use\nof speci\ufb01c propaganda techniques in text.\n\u000fWe build a new large corpus for this problem.\n\u000fWe propose a suitable evaluation measure.\n\u000fWe design a novel multi-granularity neural\nnetwork, and we show that it outperforms\nseveral strong BERT-based baselines.\n1The corpus, the evaluation measures, and the models are\navailable at http://propaganda.qcri.org/arXiv:1910.02517v1  [cs.CL]  6 Oct 2019\nOur corpus could enable research in propagandis-\ntic and non-objective news, including the devel-\nopment of explainable AI systems. A system that\ncan detect instances of use of speci\ufb01c propagan-\ndistic techniques would be able to make it explicit\nto the users why a given article was predicted to be\npropagandistic. It could also help train the users to\nspot the use of such techniques in the news.\nThe remainder of this paper is organized as\nfollows: Section 2 presents the propagandistic\ntechniques we focus on. Section 3 describes\nour corpus. Section 4 discusses an evaluation\nmeasures for comparing labeled fragments. Sec-\ntion 5 presents the formulation of the task and\nour proposed models. Section 6 describes our ex-\nperiments and the evaluation results. Section 7\npresents some relevant related work. Finally, Sec-\ntion 8 concludes and discusses future work.\n2 Propaganda and its Techniques\nPropaganda comes in many forms, but it can\nbe recognized by its persuasive function, sizable\ntarget audience, the representation of a speci\ufb01c\ngroup\u2019s agenda, and the use of faulty reasoning\nand/or emotional appeals (Miller, 1939). Since\npropaganda is conveyed through the use of a num-\nber of techniques, their detection allows for a\ndeeper analysis at the paragraph and the sentence\nlevel that goes beyond a single document-level\njudgment on whether a text is propagandistic.\nWhereas the de\ufb01nition of propaganda is widely\naccepted in the literature, the set of propaganda\ntechniques differs between scholars (Torok, 2015).\nFor instance, Miller (1939) considers seven tech-\nniques, whereas Weston (2018) lists at least 24,\nand Wikipedia discusses 69.2The differences are\nmainly due to some authors ignoring some tech-\nniques, or using de\ufb01nitions that subsume the def-\ninition used by other authors. Below, we describe\nthe propaganda techniques we consider: a curated\nlist of eighteen items derived from the aforemen-\ntioned studies. The list only includes techniques\nthat can be found in journalistic articles and can\nbe judged intrinsically, without the need to retrieve\nsupporting information from external resources.\nFor example, we do not include techniques such as\ncard stacking (Jowett and O\u2019Donnell, 2012, page\n237), since it would require comparing against ex-\nternal sources of information.\n2http://en.wikipedia.org/wiki/\nPropaganda_techniques ; last visit May 2019.The eighteen techniques we consider are as fol-\nlows (cf. Table 1 for examples):\n1. Loaded language. Using words/phrases with\nstrong emotional implications (positive or nega-\ntive) to in\ufb02uence an audience (Weston, 2018, p. 6).\nEx.: \u201c[. . . ] a lone lawmaker\u2019s childish shouting.\u201d\n2. Name calling or labeling. Labeling the ob-\nject of the propaganda campaign as either some-\nthing the target audience fears, hates, \ufb01nds un-\ndesirable or otherwise loves or praises (Miller,\n1939). Ex.: \u201cRepublican congressweasels\u201d, \u201cBush\nthe Lesser.\u201d\n3. Repetition. Repeating the same message over\nand over again, so that the audience will eventually\naccept it (Torok, 2015; Miller, 1939).\n4. Exaggeration or minimization. Either rep-\nresenting something in an excessive manner: mak-\ning things larger, better, worse (e.g., \u201cthe best of\nthe best\u201d, \u201cquality guaranteed\u201d) or making some-\nthing seem less important or smaller than it ac-\ntually is (Jowett and O\u2019Donnell, 2012, p. 303),\ne.g., saying that an insult was just a joke. Ex.:\n\u201cDemocrats bolted as soon as Trumps speech\nended in an apparent effort to signal they can\u2019t\neven stomach being in the same room as the pres-\nident\u201d; \u201cI was not \ufb01ghting with her; we were just\nplaying.\u201d\n5. Doubt. Questioning the credibility of some-\none or something. Ex.: A candidate says about his\nopponent: \u201cIs he ready to be the Mayor?\u201d\n6. Appeal to fear/prejudice. Seeking to build\nsupport for an idea by instilling anxiety and/or\npanic in the population towards an alternative,\npossibly based on preconceived judgments. Ex.:\n\u201cstop those refugees; they are terrorists.\u201d\n7. Flag-waving. Playing on strong national feel-\ning (or with respect to a group, e.g., race, gender,\npolitical preference) to justify or promote an ac-\ntion or idea (Hobbs and Mcgee, 2008). Ex.: \u201cen-\ntering this war will make us have a better future in\nour country.\u201d\n8. Causal oversimpli\ufb01cation. Assuming one\ncause when there are multiple causes behind an\nissue. We include scapegoating as well: the trans-\nfer of the blame to one person or group of people\nwithout investigating the complexities of an issue.\nEx.: \u201cIf France had not declared war on Germany,\nWorld War II would have never happened.\u201d\nDoc ID Technique \u000fSnippet\n783702663 loaded language \u000funtil forced to act by a worldwide storm of outrage .\n732708002 name calling, labeling \u000fdismissing the protesters as lefties and hugging Barros publicly\n701225819 repetition\u000fFarrakhan repeatedly refers to Jews as Satan . He states to his audience [. . . ] call them by\ntheir real name, \u2018 Satan .\u2019\n782086447 exaggeration, minimization \u000fheal the situation of extremely grave immoral behavior\n761969038 doubt\u000fCan the same be said for the Obama Administration ?\n696694316 appeal to fear/prejudice \u000fA dark, impenetrable and irreversible winter of persecution of the\nfaithful by their own shepherds will fall .\n776368676 flag-waving\u000fcon\ufb02icted, and his 17 Angry Democrats that are doing his dirty work are a disgrace to\nUSA ! \u2014Donald J. Trump\n776368676 flag-waving\u000fattempt (Mueller) to stop the will of We the People !!! It\u2019s time to jail Mueller\n735815173 causal oversimplification \u000fhe said The people who talk about the \u201dJewish question\u201d are gen-\nerally anti-Semites . Somehow I don\u2019t think\n781768042 causal oversimplification \u000fwill not be reversed, which leaves no alternative as to why God\njudges and is judging America today\n111111113 slogans\u000fBUILD THE WALL!\u201d Trump tweeted.\n783702663 appeal to authority \u000fMonsignor Jean-Franois Lantheaume, who served as \ufb01rst Counsellor of\nthe Nunciature in Washington, con\ufb01rmed that \u201cVigan said the truth. Thats all\u201d\n783702663 black-and-white fallacy \u000fFrancis said these words: Everyone is guilty for the good he could have\ndone and did not do . . . If we do not oppose evil, we tacitly feed it .\n729410793 thought-terminating cliches \u000fI do not really see any problems there. Marx is the President\n770156173 whataboutism\u000fPresident Trump \u2014 who himself avoided national military service in the 1960\u2019s\u2014 keeps\nbeating the war drums over North Korea\n778139122 reductio ad hitlerum \u000f\u201cVichy journalism,\u201d a term which now \ufb01ts so much of the mainstream media.\nIt collaborates in the same way that the Vichy government in France collaborated with the Nazis.\n778139122 red herring\u000fIt describes the tsunami of vindictive personal abuse that has been heaped upon Julian from\nwell-known journalists, many claiming liberal credentials. The Guardian, which used to consider itself the\nmost enlightened newspaper in the country , has probably been the worst.\n698018235 bandwagon\u000fHe tweeted, \u201c EU no longer considers #Hamas a terrorist group. Time for US to do same.\u201d\n729410793 obfusc., int. vagueness, confusion \u000fThe cardinal\u2019s of\ufb01ce maintains that rather than saying \u201cyes,\u201d there is\na possibility of liturgical \u201cblessing\u201d of gay unions, he answered the question in a more subtle way without\ngiving an explicit \u201cyes.\u201d\n783702663 straw man\u000f\u201cTake it seriously, but with a large grain of salt.\u201d Which is just Allen\u2019s more nuanced way of\nsaying: \u201cDon\u2019t believe it .\u201d\nTable 1: Instances of the different propaganda techniques from our corpus. We show the document ID, the tech-\nnique, and the text snippet, in bold. When necessary, some context is provided to better understand the example.\n9. Slogans. A brief and striking phrase that may\ninclude labeling and stereotyping. Slogans tend to\nact as emotional appeals (Dan, 2015). Ex.: \u201cMake\nAmerica great again!\u201d\n10. Appeal to authority. Stating that a claim is\ntrue simply because a valid authority/expert on the\nissue supports it, without any other supporting ev-\nidence (Goodwin, 2011). We include the special\ncase where the reference is not an authority/expert,\nalthough it is referred to as testimonial in the liter-\nature (Jowett and O\u2019Donnell, 2012, p. 237).\n11. Black-and-white fallacy, dictatorship. Pre-\nsenting two alternative options as the only pos-\nsibilities, when in fact more possibilities exist\n(Torok, 2015). As an extreme case, telling the\naudience exactly what actions to take, eliminat-\ning any other possible choice ( dictatorship ).Ex.:\n\u201cYou must be a Republican or Democrat; you are\nnot a Democrat. Therefore, you must be a Repub-\nlican\u201d; \u201cThere is no alternative to war.\u201d12. Thought-terminating clich \u00b4e.Words or\nphrases that discourage critical thought and mean-\ningful discussion about a given topic. They are\ntypically short, generic sentences that offer seem-\ningly simple answers to complex questions or\nthat distract attention away from other lines of\nthought (Hunter, 2015, p. 78). Ex.: \u201cit is what it\nis\u201d; \u201cyou cannot judge it without experiencing it\u201d;\n\u201cit\u2019s common sense\u201d, \u201cnothing is permanent ex-\ncept change\u201d, \u201cbetter late than never\u201d; \u201cmind your\nown business\u201d; \u201cnobody\u2019s perfect\u201d; \u201cit doesn\u2019t\nmatter\u201d; \u201cyou can\u2019t change human nature.\u201d\n13. Whataboutism. Discredit an opponent\u2019s posi-\ntion by charging them with hypocrisy without di-\nrectly disproving their argument (Richter, 2017).\nFor example, mentioning an event that discred-\nits the opponent: \u201cWhat about . . . ?\u201d (Richter,\n2017). Ex.: Russia Today had a proclivity for\nwhataboutism in its coverage of the 2015 Balti-\nmore and Ferguson protests in the US, which re-\nvealed a consistent refrain: \u201cthe oppression of\nblacks in the US has become so unbearable that\nthe eruption of violence was inevitable\u201d, and that\nthe US therefore lacks \u201cthe moral high ground to\ndiscuss human rights issues in countries like Rus-\nsia and China.\u201d\n14. Reductio ad Hitlerum. Persuading an audi-\nence to disapprove an action or idea by suggest-\ning that the idea is popular with groups hated in\ncontempt by the target audience. It can refer to\nany person or concept with a negative connota-\ntion (Teninbaum, 2009). Ex.: \u201cOnly one kind of\nperson can think this way: a communist.\u201d\n15. Red herring. Introducing irrelevant mate-\nrial to the issue being discussed, so that every-\none\u2019s attention is diverted away from the points\nmade (Weston, 2018, p. 78). Those subjected to\na red herring argument are led away from the is-\nsue that had been the focus of the discussion and\nurged to follow an observation or claim that may\nbe associated with the original claim, but is not\nhighly relevant to the issue in dispute (Teninbaum,\n2009). Ex.: \u201cYou may claim that the death penalty\nis an ineffective deterrent against crime \u2013 but what\nabout the victims of crime? How do you think sur-\nviving family members feel when they see the man\nwho murdered their son kept in prison at their ex-\npense? Is it right that they should pay for their\nson\u2019s murderer to be fed and housed?\u201d\n16. Bandwagon. Attempting to persuade the tar-\nget audience to join in and take the course of ac-\ntion because \u201ceveryone else is taking the same ac-\ntion\u201d (Hobbs and Mcgee, 2008). Ex.: \u201cWould you\nvote for Clinton as president? 57% say yes.\u201d\n17. Obfuscation, intentional vagueness, confu-\nsion. Using deliberately unclear words, so that the\naudience may have its own interpretation (Supra-\nbandari, 2007; Weston, 2018, p. 8). For instance,\nwhen an unclear phrase with multiple possible\nmeanings is used within the argument, and, there-\nfore, it does not really support the conclusion. Ex.:\n\u201cIt is a good idea to listen to victims of theft.\nTherefore, if the victims say to have the thief shot,\nthen you should do it.\u201d\n18. Straw man. When an opponent\u2019s proposition\nis substituted with a similar one which is then re-\nfuted in place of the original (Walton, 1996). We-\nston (2018, p. 78) speci\ufb01es the characteristics of\nthe substituted proposition: \u201ccaricaturing an op-\nposing view so that it is easy to refute.\u201dProp Non-prop All\narticles 372 79 451\navg length (lines) 49.8 34.4 47.1\navg length (words) 973.2 635.4 914.0\navg length (chars) 5,942 3,916 5,587\nTable 2: Statistics about the articles retrieved\nwith respect to the category of the media source:\nprop agandistic, non-prop agandistic, and all together.\nNews Outlet # News Outlet #\nFreedom Outpost 133 The Remnant Magazine 14\nFrontpage Magazine 56 Breaking911 11\nshtfplan.com 55 truthuncensored.net 8\nLew Rockwell 26 The Washington Standard 6\nvdare.com 20 www.unz.com 5\nremnantnewspaper.com 19 www.clashdaily.com 1\nPersonal Liberty 18\nTable 3: Number of articles retrieved from news outlets\ndeemed propagandistic by Media Bias/Fact Check.\nWe provided the above de\ufb01nitions, together\nwith some examples and an annotation schema, to\nour professional annotators, so that they can man-\nually annotate news articles. The details are pro-\nvided in the next section.\n3 Data Creation\nWe retrieved 451 news articles from 48 news out-\nlets, both propagandistic and non-propagandistic,\nwhich we annotated as described below.\n3.1 Article Retrieval\nFirst, we selected 13 propagandistic and 36 non-\npropagandistic news media outlets, as labeled by\nMedia Bias/Fact Check.3Then, we retrieved arti-\ncles from these sources, as shown in Table 2. Note\nthat 82.5% of the articles are from propagandistic\nsources, and these articles tend to be longer.\nTable 3 shows the number of articles re-\ntrieved from each propagandistic outlet. Over-\nall, we have 350k word tokens, which is compa-\nrable to standard datasets for other \ufb01ne-grained\ntext analysis tasks, such as named entity recog-\nnition, e.g., CoNLL\u201902 and CoNLL\u201903 covered\n381K, 333K, 310K, and 301K tokens for Spanish,\nDutch, German, and English, respectively (Tjong\nKim Sang, 2002; Tjong Kim Sang and De Meul-\nder, 2003).\n3http://mediabiasfactcheck.com/\n3.2 Manual Annotation\nWe aim at obtaining text fragments annotated with\nany of the 18 techniques described in Section 2\n(see Figure 1 for an example). Since the time re-\nquired to understand and memorize all the pro-\npaganda techniques is signi\ufb01cant, this annotation\ntask is not well-suited for crowdsourcing. We part-\nnered instead with a company that performs pro-\nfessional annotations, A Data Pro.4Appendix A\nshows details about the instructions and the tools\nprovided to the annotators.\nWe computed the \rinter-annotator agree-\nment (Mathet et al., 2015). We chose \rbecause\n(i) it is designed for tasks where both the span and\nits label are to be found and ( ii) it can deal with\noverlaps in the annotations by the same annotator5\n(e.g., instances of doubt often use name calling or\nloaded language to reinforce their message). We\ncomputed\rs, where we only consider the iden-\nti\ufb01ed spans, regardless of the technique, and \rsl,\nwhere we consider both the spans and their labels.\nLetabe an annotator. In a preliminary exer-\ncise, four annotators a[1;::;4]annotated six articles\nindependently, and the agreement was \rs= 0:34\nand\rsl= 0:31. Even taking into account that\n\ris a pessimistic measure (Mathet et al., 2015),\nthese values are low. Thus, we designed an an-\nnotation schema composed of two stages and in-\nvolving two annotator teams, each of which cov-\nered about 220documents. In stage 1, both a1and\na2annotated the same documents independently.\nIn stage 2, they gathered with a consolidator c1to\ndiscuss all instances and to come up with a \ufb01nal\nannotation. Annotators a3anda4and consolida-\ntorc2followed the same procedure. Annotating\nthe full corpus took 395 man hours.\nTable 4 shows the \ragreements on the full cor-\npus. As in the preliminary annotation, the agree-\nments for both teams are relatively low: 0.30 and\n0.34 for span selection, and slightly lower when la-\nbeling is considered as well. After the annotators\ndiscussed with the consolidator on the disagreed\ncases, the\rvalues got much higher: up to 0.74\nand 0.76 for each team. We further analyzed the\nannotations to determine the main cause for the\ndisagreement by computing the percentage of in-\nstances spotted by one annotator only in the \ufb01rst\nstage that are retained as gold annotations.\n4http://www.aiidatapro.com\n5See (Meyer et al., 2014; Mathet et al., 2015) for other\nalternatives, which lack some properties; ( ii) in particular.Annotations spans ( \rs) +labels ( \rsl)\na1a2 0.30 0.24\na3a4 0.34 0.28\na1c1 0.58 0.54\na2c1 0.74 0.72\na3c2 0.76 0.74\na4c2 0.42 0.39\nTable 4:\rinter-annotator agreement between an-\nnotators spotting spans alone ( spans ) and spotting\nspans+labeling ( +labels ). The top-2 rows refer to the\n\ufb01rst stage: agreement between annotators. The bottom\n4 rows refer to the consolidation stage: agreement be-\ntween each annotator and the \ufb01nal gold annotation.\nFigure 1: Example given to the annotators.\nOverall the percentage is 53% (5;921 out of\n11;122), and for each annotator is a1= 70% ,\na2= 48% ,a3= 57% ,a4= 31% . Observ-\ning such percentages together with the relatively\nlow differences in Table 4 between \rsand\rslfor\nthe same pairs (ai;aj)and(ai;cj), we can con-\nclude that disagreements are in general not due to\nthe two annotators assigning different labels to the\nsame or mostly overlapping spans, but rather be-\ncause one has missed an instance in the \ufb01rst stage.\n3.3 Statistics about the Dataset\nThe total number of technique instances found\nin the articles, after the consolidation phase, is\n7;485, with respect to a total number of 21;230\nsentences (35.2%). Table 5 reports some statistics\nabout the annotations. The average propagandis-\ntic fragment has a length of 47characters and the\naverage length of a sentence is 112.5 characters.\nOn average, the propagandistic techniques are\nhalf a sentence long. The most common ones are\nloaded language andname calling, labeling with\n2;547and1;294occurrences, respectively. They\nappear 6.7 and 4.7 times per article, while no other\ntechnique appears more than twice. Note that rep-\netition are in\ufb02ated as we asked the annotators to\nmark both the original and the repeated instances.\nPropaganda Technique inst avg. length\nloaded language 2,547 23:70\u000625:30\nname calling, labeling 1,294 26:10\u000619:88\nrepetition 767 16:90\u000618:92\nexaggeration, minimization 571 45:36\u000635:55\ndoubt 562 123:21\u000697:65\nappeal to fear/prejudice 367 93:56\u000674:59\n\ufb02ag-waving 330 61:88\u000668:61\ncausal oversimpli\ufb01cation 233 121:03\u000671:66\nslogans 172 25:30\u000613:49\nappeal to authority 169 131:23\u0006123:2\nblack-and-white fallacy 134 98:42\u000673:66\nthought-terminating cliches 95 34:85\u000629:28\nwhataboutism 76 120:93\u000669:62\nreductio ad hitlerum 66 94:58\u000664:16\nred herring 48 63:79\u000661:63\nbandwagon 17 100:29\u000697:05\nobfusc., int. vagueness, confusion 17 107:88\u000686:74\nstraw man 15 79:13\u000650:72\nall 7,485 46:99\u000661:45\nTable 5: Corpus statistics including instances per tech-\nnique and their avg. length in terms of characters.\n4 Evaluation Measures\nOur task is a sequence labeling one, with the fol-\nlowing key characteristics: ( i) a large number of\ntechniques whose spans might overlap in the text,\nand ( ii) large lengths of these spans. This requires\nan evaluation measure that gives credit for par-\ntial overlaps.6We derive an ad hoc measure fol-\nlowing related work on named entity recognition\n(NER) (Nadeau and Sekine, 2007) and (intrinsic)\nplagiarism detection (PD) (Potthast et al., 2010).\nWhile in NER, the relevant fragments tend to be\nshort multi-word strings, in PD \u2014and in our pro-\npaganda technique identi\ufb01cation task\u2014 the length\nvaries widely (cf. Table 5), and instances span\nfrom single tokens to full sentences or even longer\npieces of text. Thus, in our precision and re-\ncall versions, we give partial credit to imperfect\nmatches at the character level, as in PD.\nLet document dbe represented as a sequence of\ncharacters. A propagandistic text fragment is then\nrepresented as t= [ti;:::;t j]\u0012d. A document\nincludes a set of (possibly overlapping) fragments\nT. Similarly, a learning algorithm produces a set S\nwith fragments s= [sm;:::;s n], predicted on d.\nA labeling function l(x)2f1;:::; 18gassociates\ns2Sto one of the eighteen techniques. Figure 2\ngives examples of gold and predicted fragments.\n6The evaluation measures for the CoNLL\u201902 and\nCoNLL\u201903 NER tasks, where an instance is considered prop-\nerly identi\ufb01ed if and only if both the boundaries and the label\nare correct (Tsai et al., 2006), are not suitable in our context.\nt1 (c=1)                     t2 (c=2)             t3 (c=3) T\ns1 (c=1)              s2 (c=2) s3(c=2)       s4 (c=4)\nSFigure 2: Example of gold annotation (top) and the pre-\ndictions of a supervised model (bottom) in a document\nrepresented as a sequence of characters. The class of\neach fragment is shown in parentheses. s1goes beyond\nt1\u2019s proper boundaries; s2ands3partially spot t2, but\nfail to identify it entirely; s4spots the exact boundaries\noft3, but fails to assign it the right label.\nWe de\ufb01ne the following function to handle par-\ntial overlaps between fragments with same labels:\nC(s;t;h ) =j(s\\t)j\nh\u000e(l(s);l(t)); (1)\nwherehis a normalizing factor and \u000e(a;b) = 1 if\na=b, and 0otherwise. In the future, \u000ecould be\nre\ufb01ned to account for custom distance functions\nbetween classes, e.g., we might consider mistak-\ningloaded language forname calling or labeling\nless problematic than confusing it with Reduction\nad Hitlerum . Given Eq. (1), we now de\ufb01ne vari-\nants of precision and recall able to account for the\nimbalance in the corpus:\nP(S;T) =1\njSjX\ns2S;\nt2TC(s;t;jsj); (2)\nR(S;T) =1\njTjX\ns2S;\nt2TC(s;t;jtj); (3)\nWe de\ufb01ne Eq. (2) to be zero if jSj= 0 and\nEq. (3) to be zero if jTj= 0. Following Potthast\net al. (2010), in Eqs. (2) and (3) we penalize sys-\ntems predicting too many or too few instances by\ndividing byjSjandjTj, respectively, e.g., in Fig-\nure 2P(fs2;s3g;T)< P(fs3g;T). Finally, we\ncombine Eqs. (2) and (3) into an F 1-measure, the\nharmonic mean of precision and recall.\nHaving a separate function Cto be responsible\nfor comparing two annotations gives us some ad-\nditional \ufb02exibility that is missing in standard NER\nmeasures that operate at the token/character level.\nFor example, in Eq. (1) we could easily change the\nfactor that gives credit for partial overlaps by be-\ning more forgiving when only few characters are\nwrong.\n5 Tasks and Proposed Models\nWe de\ufb01ne two tasks based on the corpus described\nin Section 3: ( i)SLC (Sentence-level Classi\ufb01ca-\ntion) , which asks to predict whether a sentence\ncontains at least one propaganda technique, and\n(ii)FLC (Fragment-level classi\ufb01cation) , which\nasks to identify both the spans and the type of pro-\npaganda technique. Note that these two tasks are\nof different granularities, g1andg2, i.e., tokens for\nFLC and sentences for SLC. We split the corpus\ninto training, development and test, each contain-\ning 293, 57, 101 articles and 14,857, 2,108, 4,265\nsentences.\n5.1 Baselines\nWe depart from BERT (Devlin et al., 2019), as it\nhas achieved state-of-the-art performance on mul-\ntiple NLP benchmarks, and we design three base-\nlines based on it.\nBERT. We add a linear layer on top of BERT\nand we \ufb01ne-tune it, as suggested in (Devlin et al.,\n2019). For the FLC task, we feed the \ufb01nal hid-\nden representation for each token to a layer Lg2\nthat makes a 19-way classi\ufb01cation: does this to-\nken belong to one of the eighteen propaganda tech-\nniques or to none of them (cf. Figure 3-a). For the\nSLC task, we feed the \ufb01nal hidden representation\nfor the special [CLS] token, which BERT uses to\nrepresent the full sentence, to a two-dimensional\nlayerLg1to make a binary classi\ufb01cation.\nBERT-Joint. We use the layers for both tasks\nin the BERT baseline, Lg1andLg2, and we train\nfor both FLC and SLC jointly (cf. Figure 3-b).\nBERT-Granularity. We modify BERT-Joint to\ntransfer information from SLC directly to FLC.\nInstead of using only the Lg2layer for FLC, we\nconcatenate Lg1andLg2, and we add an extra\n19-dimensional classi\ufb01cation layer Lg1;2on top of\nthat concatenation to perform the prediction for\nFLC (cf. Figure 3-c).\n5.2 Multi-Granularity Network\nWe propose a model that can drive the higher-\ngranularity task (FLC) on the basis of the lower-\ngranularity information (SLC), rather than simply\nusing low-granularity information directly. Fig-\nure 3-d shows the architecture of this model. More\ngenerally, suppose there are ktasks of increas-\ning granularity, e.g., document-level, paragraph-\nlevel, sentence-level, word-level, subword-level,\ncharacter-level.\n...\nBERTToken\nLabel 1Token\nLabel 2Token\nLabel N \nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n... ...\nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n......\n......\nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n(c) BERT-Granu (d) Multi-Granularity Network(a) BERT (b) BERT-Joint... ... ... ... ...\n... ...\n... ...CLS T 1 T2 TN CLS T 1 T2 TN\nCLS T 1 T2 TNCLS T 1 T2 TNg1o\ng2o g2og1w g1wg1L g2L \ng1,2L \nf fFigure 3: The architecture of the baseline models (a-c),\nand of our proposed multi-granularity network (d).\nEach task has a separated classi\ufb01cation layer Lgk\nthat receives the feature representation of the spe-\nci\ufb01c level of granularity gkand outputs ogk. The\ndimension of the representation depends on the\nembedding layer, while the dimension of the out-\nput depends on the number of classes in the task.\nThe output ogkgenerates a weight for the next\ngranularity task gk+1through a trainable gate f:\nwgk=f(ogk) (4)\nThe gatefconsists of a projection layer to one\ndimension and an activation function. The result-\ning weight is multiplied by each element of the\noutput of layer Lgk+1to produce the output for\ntaskgk+1:\nogk+1=wgk\u0003ogk+1 (5)\nIfwgk= 0 for a given example, the output of\nthe next granularity task ogk+1would be 0 as well.\nIn our setting this means that, if the sentence-level\nclassi\ufb01er is con\ufb01dent the sentence does not con-\ntain propaganda, i.e., wgk= 0, then ogk+1= 0\nand there would be no propagandistic technique\npredicted for any span within that sentence. Simi-\nlarly, when back-propagating the error, if wgk= 0\nfor a given example, the \ufb01nal entropy loss would\nbecome zero; i.e. the model would not get any in-\nformation from that example. As a result, only ex-\namples strongly classi\ufb01ed as negative in a lower-\ngranularity task would be ignored in the high-\ngranularity task. Having the lower-granularity as\nthe main task means that higher-granularity infor-\nmation can be selectively used as additional infor-\nmation to improve the performance, but only if the\nexample is not considered as highly negative. We\nshow this in Section 6.3.\nFor the loss function, we use a cross-entropy loss\nwith sigmoid activation for every layer, except for\nthe highest-granularity layer LgK, which uses a\ncross-entropy loss with softmax activation. Un-\nlike softmax, which normalizes over all dimen-\nsions, the sigmoid allows each output component\nof layerLgkto be independent from the rest. Thus,\nthe output of the sigmoid for the positive class\nincreases the degree of freedom by not affecting\nthe negative class, and vice versa. As we have\ntwo tasks, we use sigmoid activation for Lg1and\nsoftmax activation for Lg2. Moreover, we use a\nweighted sum of losses with a hyper-parameter \u000b:\nLJ=Lg1\u0003\u000b+Lg2\u0003(1\u0000\u000b) (6)\nAgain, we use BERT (Devlin et al., 2019) for\nthe contextualized embedding layer and we place\nthe multi-granularity network on top of it.\n6 Experiments and Evaluation\n6.1 Experimental Setup\nWe used the PyTorch framework and the pre-\ntrained BERT model, which we \ufb01ne-tuned for our\ntasks. We trained all models using the follow-\ning hyper-parameters: batch size of 16, sequence\nlength of 210, weight decay of 0.01, and early\nstopping on validation F 1with patience of 7. For\noptimization, we used Adam with a learning rate\nof 3e-5 and a warmup proportion of 0.1. To deal\nwith class imbalance, we give weight to the binary\ncross-entropy according to the proportion of posi-\ntive samples. For the \u000bin the joint loss function,\nwe use 0.9 for sentence classi\ufb01cation, and 0.1 for\nword-level classi\ufb01cation. In order to reduce the\neffect of random \ufb02uctuations for BERT, all the re-\nported numbers are the average of three experi-\nmental runs with different random seeds. As it is\nstandard, we tune our models on the dev partition\nand we report results on the test partition.\n6.2 Fragment-Level Propaganda Detection\nTable 6 shows the performance for the three base-\nlines and for our multi-granularity network on the\nFLC task. For the latter, we vary the degree to\nwhich the gate function is applied: using ReLU is\nmore aggressive compared to using the Sigmoid,\nas the ReLU outputs zero for a negative input.\nNote that, even though we train the model to pre-\ndict both the spans and the labels, we also evalu-\nated it with respect to the spans only.ModelSpans Full Task\nP R F 1 P R F 1\nBERT 39.57 36.42 37.90 21.48 21.39 21.39\nJoint 39.26 35.48 37.25 20.11 19.74 19.92\nGranu 43.08 33.98 37.93 23.85 20.14 21.80\nMulti-Granularity\nReLU 43.29 34.74 38.28 23.98 20.33 21.82\nSigmoid 44.12 35.01 38.98 24.42 21.05 22.58\nTable 6: Fragment-level experiments (FLC task).\nShown are two evaluations: ( i)Spans checks only\nwhether the model has identi\ufb01ed the fragment spans\ncorrectly, while ( ii)Full task is evaluation wrt the ac-\ntual task of identifying the spans and also assigning the\ncorrect propaganda technique for each span.\nTable 6 shows that joint learning (BERT-Joint)\nhurts the performance compared to single-task\nBERT. However, using additional information\nfrom the sentence-level for the token-level classi-\n\ufb01cation (BERT-Granularity) yields small improve-\nments. The multi-granularity models outperform\nall baselines thanks to their higher precision. This\nshows the effect of the model excluding sen-\ntences that it determined to be non-propagandistic\nfrom being considered for token-level classi\ufb01ca-\ntion. Nevertheless, the performance of sentence-\nlevel classi\ufb01cation is far from perfect, achieving\nan F1of up to 60.98 (cf. Table 7). The information\nit contributes to the \ufb01nal classi\ufb01cation is noisy and\nthe more conservative removal of instances per-\nformed by the Sigmoid function yields better per-\nformance than the more aggressive ReLU.\n6.3 Sentence-Level Propaganda Detection\nTable 7 shows the results for the SLC task. We\napply our multi-granularity network model to the\nsentence-level classi\ufb01cation task to see its effect\non low granularity when we train the model with a\nhigh granularity task. Interestingly, it yields huge\nperformance improvements on the sentence-level\nclassi\ufb01cation result. Compared to the BERT base-\nline, it increases the recall by 8.42%, resulting in\na 3.24% increase of the F 1score. In this case, the\nresult of token-level classi\ufb01cation is used as addi-\ntional information for the sentence-level task, and\nit helps to \ufb01nd more positive samples. This shows\nthe opposite effect of our model compared to the\nFLC task. Note also that using ReLU is more ef-\nfective than using the Sigmoid, unlike in token-\nlevel classi\ufb01cation.\nModel Precision Recall F1\nAll-Propaganda 23.92 100.0 38.61\nBERT 63.20 53.16 57.74\nBERT-Granu 62.80 55.24 58.76\nBERT-Joint 62.84 55.46 58.91\nMGN Sigmoid 62.27 59.56 60.71\nMGN ReLU 60.41 61.58 60.98\nTable 7: Sentence-level (SLC) results. All-propaganda\nis a baseline which always output the propaganda class.\nThus, since the performance range of the token-\nlevel classi\ufb01cation is low, we think it is more ef-\nfective to get additional information after aggres-\nsively removing negative samples by using ReLU\nas a gate in the model.\n7 Related Work\nPropaganda identi\ufb01cation has been tackled mostly\nat the article level. Rashkin et al. (2017) created\na corpus of news articles labelled as belonging\nto four categories: propaganda, trusted, hoax, or\nsatire. They included articles from eight sources,\ntwo of which are propagandistic. Barr \u00b4on-Cede \u02dcno\net al. (2019) experimented with a binarized version\nof the corpus from (Rashkin et al., 2017): propa-\nganda vs. the other three categories. The corpus\nlabels were obtained with distant supervision, as-\nsuming that all articles from a given news outlet\nshare the label of that outlet, which inevitably in-\ntroduces noise (Horne et al., 2018).\nA related \ufb01eld is that of computational argu-\nmentation which, among others, deals with some\nlogical fallacies related to propaganda. Haber-\nnal et al. (2018b) presented a corpus of Web fo-\nrum discussions with cases of ad hominem fal-\nlacy identi\ufb01ed. Habernal et al. (2017, 2018a) in-\ntroduced Argotario , a game to educate people to\nrecognize and create fallacies. A byproduct of Ar-\ngotario is a corpus with 1:3karguments annotated\nwith \ufb01ve fallacies, including ad hominem ,red her-\nring andirrelevant authority , which directly relate\nto propaganda techniques (cf. Section 2). Differ-\nently from (Habernal et al., 2017, 2018a,b), our\ncorpus has 18 techniques annotated on the same\nset of news articles. Moreover, our annotations\naim at identifying the minimal fragments related to\na technique instead of \ufb02agging entire arguments.8 Conclusion and Future Work\nWe have argued for a new way to study propa-\nganda in news media: by focusing on identifying\nthe instances of use of speci\ufb01c propaganda tech-\nniques. Going at this \ufb01ne-grained level can yield\nmore reliable systems and it also makes it possible\nto explain to the user why an article was judged as\npropagandistic by an automatic system.\nIn particular, we designed an annotation schema\nof 18 propaganda techniques, and we annotated\na sizable dataset of documents with instances of\nthese techniques in use. We further designed an\nevaluation measure speci\ufb01cally tailored for this\ntask. We made the schema and the dataset publicly\navailable, thus facilitating further research. We\nhope that the corpus would raise interest outside\nof the community of researchers studying propa-\nganda: the techniques related to fallacies and the\nones relying on emotions might provide a novel\nsetting for the researchers interested in Argumen-\ntation and Sentiment Analysis.\nWe experimented with a number of BERT-based\nmodels and devised a novel architecture which\noutperforms standard BERT-based baselines. Our\n\ufb01ne-grained task can complement document-level\njudgments, both to come out with an aggregated\ndecision and to explain why a document \u2014or an\nentire news outlet\u2014 has been \ufb02agged as poten-\ntially propagandistic by an automatic system.\nWe are collaborating with A Data Pro to expand\nthe corpus. In the mid-term, we plan to build an\nonline platform where professors in relevant \ufb01elds\n(e.g., journalism, mass communication) can train\ntheir students to recognize and annotate propa-\nganda techniques. The hope is to be able to ac-\ncumulate annotations as a by-product of using the\nplatform for training purposes.\nAcknowledgments\nThis research is part of the Tanbih project,7which\naims to limit the effect of \u201cfake news\u201d, propa-\nganda and media bias by making users aware\nof what they are reading. The project is de-\nveloped in collaboration between the MIT Com-\nputer Science and Arti\ufb01cial Intelligence Labora-\ntory (CSAIL) and the Qatar Computing Research\nInstitute (QCRI), HBKU.\n7http://tanbih.qcri.org/\nReferences\nAlberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the 33rd AAAI Conference on Arti\ufb01-\ncial Intelligence , AAAI \u201919, pages 9847\u20139848, Hon-\nolulu, HI, USA.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nLavinia Dan. 2015. Techniques for the Translation of\nAdvertising Slogans. In Proceedings of the Interna-\ntional Conference Literature, Discourse and Multi-\ncultural Dialogue , LDMD \u201915, pages 13\u201323, Mures,\nRomania.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, MN, USA.\nJean Goodwin. 2011. Accounting for the force of the\nappeal to authority. In Proceedings of the 9th Inter-\nnational Conference of the Ontario Society for the\nStudy of Argumentation , OSSA \u201911, pages 1\u20139, On-\ntario, Canada.\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings\nof the Conference on Empirical Methods in Natu-\nral Language Processing , EMNLP \u201917, pages 7\u201312,\nCopenhagen, Denmark.\nIvan Habernal, Patrick Pauli, and Iryna Gurevych.\n2018a. Adapting serious game for fallacious argu-\nmentation to German: pitfalls, insights, and best\npractices. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation , LREC \u201918, Miyazaki, Japan.\nIvan Habernal, Henning Wachsmuth, Iryna Gurevych,\nand Benno Stein. 2018b. Before name-calling: Dy-\nnamics and triggers of ad hominem fallacies in web\nargumentation. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201918, pages 386\u2013\n396, New Orleans, LA, USA.\nRenee Hobbs and Sandra Mcgee. 2008. Teaching\nabout propaganda: An examination of the historical\nroots of media literacy. Journal of Media Literacy\nEducation , 6(62):56\u201367.Benjamin D Horne, Sara Khedr, and Sibel Adali. 2018.\nSampling the news producers: A large news and fea-\nture data set for the study of the complex media land-\nscape. In International AAAI Conference on Web\nand Social Media , ICWSM \u201918, Stanford, CA, USA.\nJohn Hunter. 2015. Brainwashing in a large group\nawareness training? The classical conditioning hy-\npothesis of brainwashing. Master\u2019s thesis, Uni-\nversity of Kwazulu-Natal, Pietermaritzburg, South\nAfrica.\nGarth S. Jowett and Victoria O\u2019Donnell. 2012. What is\npropaganda, and how does it differ from persuasion?\nInPropaganda & Persuasion , chapter 1, pages 1\u201348.\nSage Publishing.\nYann Mathet, Antoine Widl \u00a8ocher, and Jean-Philippe\nM\u00b4etivier. 2015. The uni\ufb01ed and holistic method\ngamma (\r) for inter-annotator agreement mea-\nsure and alignment. Computational Linguistics ,\n41(3):437\u2013479.\nChristian M. Meyer, Margot Mieskes, Christian Stab,\nand Iryna Gurevych. 2014. DKPro agreement: An\nopen-source Java library for measuring inter-rater\nagreement. In Proceedings of the International\nConference on Computational Linguistics , COL-\nING \u201914, pages 105\u2013109, Dublin, Ireland.\nClyde R. Miller. 1939. The Techniques of Propaganda.\nFrom \u201cHow to Detect and Analyze Propaganda,\u201d an\naddress given at Town Hall. The Center for learning.\nDavid Nadeau and Satoshi Sekine. 2007. A sur-\nvey of named entity recognition and classi\ufb01cation.\nLingvisticae Investigationes , 30(1):3\u201326.\nMartin Potthast, Benno Stein, Alberto Barr \u00b4on-Cede \u02dcno,\nand Paolo Rosso. 2010. An evaluation framework\nfor plagiarism detection. In Proceedings of the In-\nternational Conference on Computational Linguis-\ntics, COLING \u201910, pages 997\u20131005, Beijing, China.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing , EMNLP \u201917, pages 2931\u20132937, Copen-\nhagen, Denmark.\nMonika L Richter. 2017. The Kremlin\u2019s platform for\n\u2018useful idiots\u2019 in the West: An overview of RT\u2019s ed-\nitorial strategy and evidence of impact. Technical\nreport, Kremlin Watch.\nFrancisca Niken Vitri Suprabandari. 2007. Ameri-\ncan propaganda in John Steinbeck\u2019s The Moon is\nDown. Master\u2019s thesis, Sanata Dharma University,\nYogyakarta, Indonesia.\nGabriel H Teninbaum. 2009. Reductio ad Hitlerum:\nTrumping the judicial Nazi card. Michigan State\nLaw Review , page 541.\nErik F. Tjong Kim Sang. 2002. Introduction to the\nCoNLL-2002 shared task: Language-independent\nnamed entity recognition. In Proceedings of the\n6th Conference on Natural Language Learning ,\nCoNLL \u201902, pages 155\u2013158, Taipei, Taiwan.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the 7th Conference on Natural Lan-\nguage Learning , CoNLL \u201903, pages 142\u2013147, Ed-\nmonton, Canada.\nRobyn Torok. 2015. Symbiotic radicalisation strate-\ngies: Propaganda tools and neuro linguistic pro-\ngramming. In Proceedings of the Australian Se-\ncurity and Intelligence Conference , pages 58\u201365,\nPerth, Australia.\nRichard Tzong-Han Tsai, Shih-Hung Wu, Wen-Chi\nChou, Yu-Chun Lin, Ding He, Jieh Hsiang, Ting-\nYi Sung, and Wen-Lian Hsu. 2006. Various criteria\nin the evaluation of biomedical named entity recog-\nnition. BMC bioinformatics , 7:92.\nDouglas Walton. 1996. The straw man fallacy . Royal\nNetherlands Academy of Arts and Sciences.\nAnthony Weston. 2018. A rulebook for arguments .\nHackett Publishing.\nA Annotation Guidelines\nWe provided the de\ufb01nitions in Section 2 together\nwith some examples and an annotation schema,\nto our professional annotators, so that they could\nmanually annotate news articles. The annotators\nperformed their task following the instructions dis-\nplayed in Figure A.1. In order to help them, we\nbuilt the \ufb02owchart displayed in the same \ufb01gure. It\npartitions the set of techniques hierarchically and\ncan be traversed by answering a series of ques-\ntions. These instructions and the \ufb02owchart were\nalways available to the annotators, next to the an-\nnotation interface (cf. Figure 1). As an example of\nthe process for generating the questions, the \ufb01rst\nsubdivision is inspired by the following descrip-\ntion of propaganda: \u201cPropaganda comes in many\nforms, but you can recognize it by [. . . ] the use of\nfaulty reasoning and/or emotional appeals\u201d. The\ndescription distinguishes between logical fallacies\nand techniques appealing to emotions.\nWe aim at identifying propagandistic techniques in news ar-\nticles. We provide you with a news article and a \ufb02owchart\nto guide you through the identi\ufb01cation of propaganda tech-\nniques. The de\ufb01nition of each technique is shown when set-\nting the mouse pointer on the name of the technique in the\n\ufb02owchart. You are free to annotate single words, phrases,\nor sentences, but we encourage you to select the minimal\namount of text in which the propaganda technique appears.\n1. Let us look at the \ufb02owchart [below]\n2. Let us look at an example which includes four propa-\nganda techniques [cf. Figure 1]\n\u000fName calling : the democrats are being called \u201dbabies\u201d\n\u000fBlack-and-white fallacy : obstruction vs progress\n\u000fLoaded language : stupid, petty, killing\u000fExaggeration : killing a grandma, stomaching the\npresence of a person\nUse the \ufb02owchart as your guide to spot propaganda. If you\nare not sure about a propaganda technique (any rounded box\nin the \ufb02owchart), just click on it and a new page will open\nwith explanations and examples when necessary. [cf. Sec-\ntion 2]\nTIPS\n\u000fSome sentences might be tricky. Please try to select the\nright technique(s)\n\u000fYour emotions have nothing to do with the articles, as\nyou are requested to spot propagandistic techniques,\nnot their message: try to distance yourself from the\ncontents and avoid being biased.\n\u000fOne text fragment may include more than one tech-\nnique at the same time\nFigure A.1: Instructions as provided to the professional annotators in the Anafora-based annotation process (top).\nFlowchart to drive the identi\ufb01cation of propaganda techniques (bottom).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fine-grained analysis of propaganda in news articles", "author": ["GDS Martino", "S Yu", "A Barr\u00f3n-Cede\u00f1o", "R Petrov"], "pub_year": "2019", "venue": "arXiv preprint arXiv \u2026", "abstract": "Propaganda aims at influencing people's mindset with the purpose of advancing a specific  agenda. Previous work has addressed propaganda detection at the document level, typically"}, "filled": false, "gsrank": 537, "pub_url": "https://arxiv.org/abs/1910.02517", "author_id": ["URABLy0AAAAJ", "ayy2eo0AAAAJ", "0q0QVG4AAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:PmI5M_FzwNkJ:scholar.google.com/&output=cite&scirp=536&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D530%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PmI5M_FzwNkJ&ei=ZrWsaNvsJbXCieoP4PfQ0A8&json=", "num_citations": 30, "citedby_url": "/scholar?cites=15690668581542519358&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:PmI5M_FzwNkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1910.02517"}}, {"title": "Interactive Visualization of the Polarity-based Stance of News Websites using News Genres", "year": "2021", "pdf_data": "Interactive Visualization of the Polarity-based Stance\nof News Websites using News Genres\nMasaharu Yoshioka1,Norihiko Tatsunami2,Masahiko Itoh3,NorikoKando4and\nJamesAllan5\n1Hokkaido University, N14 W9, Kita-ku, Sapporo-shi, Hokkaido, Japan\n2FujitsuJapanLtd.,ShiodomeCityCenter: HigashiShimbashi1-5-2,Minato-ku,Tokyo,Japan; Thisworkwasconducted\nduring his study at Hokkaido University.\n3Hokkaido Information University, Nishi Nopporo 59-2, Ebetsu, Hokkaido, Japan\n4National Institute of Informatics, Hitotsubashi 2-1-2, Chiyoda-ku, Tokyo Japan\n5University of Massachusetts, Amherst, 140 Governors Drive, Amherst, Massachusetts, United States of America\nAbstract\nWe have been working on a project that aims to characterize the stance of news websites. We are\nproposingaframeworkthatcanclassifywebsitesintermsoftherelativeproportionsofpositiveand\nnegativearticlesaboutparticulartopics. Thissystemcanrepresentthewebsite\u2019sgeneralstanceforeasily\ncomparable topics such as presidential election but it is more difficult to analyze the news website from\ntheviewpointofitsusers\u2019underlyinginterests. Inthispaper,weproposeasystemfortheinteractive\nvisualizationofawebsite\u2019spolarity-basedstancebyrepresentingtheusers\u2019interestsintermsofnews\ngenres and demonstrate the system using articles refereed to Donald Trump in 2016 US presidential\nelection periods.\nKeywords\nnews, polarity, stance, interactive visualization, visualization of multidimensional data, news genre\n1. Introduction\nNowadays, we can access a wide variety of opinions from Internet-based sources, including\nnews articles, messages on blog websites, and other review websites. To be able to comprehend\nthespectrumofsuchopinions,itishelpfultounderstandthe stanceofsuchopinionsources[ 1].\nRecently,thereareseveralwebsitesthatdiscussthemediabiasofnewswebsites,suchasMedia\nBias Chart1and Media Bias/Fact Check (MBFC)2. Since those pages are maintained by the\nhuman experts, it is good to have a system to analyze such bias for analyzing wide varieties of\nnews websites. In previouswork [ 2], we considered the polarity-based stance of articles from\nnews websites about a particular topic. This approach could handle substantial amounts of\nINRA\u201921: 9th International Workshopon NewsRecommendation and Analytics,September 25, 2021, Amsterdam,\nNetherlands\nEnvelope-Openyoshioka@ist.hokudai.ac.jp (M. Yoshioka); tatsunami.norih@fujitsu.com (N. Tatsunami);\nimash@do-johodai.ac.jp (M. Itoh); kando@nii.ac.jp (N. Kando); allan@cs.umass.edu (J. Allan)\nOrcid0000-0002-2096-1218 (M. Yoshioka); 0000-0002-7759-392X (M. Itoh); 0000-0002-2133-0215 (N. Kando)\n\u00a9 2021 Copyright for this paper by its authors. Use permitted under CreativeCommons License Attribution 4.0 International (CCBY 4.0).\nCEUR\nWorkshop\nProceedingshttp://ceur-ws.org\nISSN 1613-0073\nCEUR Workshop Proceedings ( CEUR-WS.org )\n1https://www.adfontesmedia.com\n2https://mediabiasfactcheck.com/\n\nrelevant textual material and was therefore well suited to obtaining a macroscopic view of the\nstance for a particular topic in terms of a polarity-based score (the ratio of positive to negative\narticles for a particular topic). However, this framework was not able to discriminate between\nnews websites that had different underlying interests.\nTovisualizethestancewithrespecttounderlyinginterests,weproposeasystemforrepresent-\ning news websites using a stance matrix that combines polarity(positive, neutral, and negative)\nandnews genre (e.g., politics or economy) for these multidimensional data. To represent users\u2019\ninterests interactively, several methods havebeen proposed that arebased on modifications to\na distance metric [ 3,4,5]. In this paper, we report on an application of a recently developed\ninteractive visualization tool called \u201csymmetric interactive representations in a unified system\u201d\n(SIRIUS) [ 5]. This application addresses real-world problems, including the visualization of the\npolarity-based stance of various news websites [ 2].\nIn the remainder of this paper, Section 2 introduces our method for assessing polarity-based\nnews stances and the interactiveinformation visualization tool SIRIUS [ 5]. Section 3 describes\nourapproachtothepolarity-basedstanceofanewswebsiteandproposesanextensionthatuses\nnews genres to represent the news-website stance in terms of multidimensional data. Section 4\npresentsa method for constructing news-website-stance data and demonstrates news-website\nvisualization using SIRIUS. Section 5 concludes the paper.\n2. Polarity-based Stance of News Websites and SIRIUS\n2.1. Polarity-based Stance of News Websites\nCurrently, many users use news aggregation websites that show compiled lists of news articles\nfromvarioussources. Ifthesuggestionsarebasedontopicsrelatedtotheuser\u2019sinterests,those\nuserswillbeexposedtonewsfrommorediversesources,whichwillinvolveawiderarrayof\npolitical stances. Users must, therefore, use their judgment selectively to digest what they read,\nespecially for controversial topics, often by assessing the source\u2019s stance.\nTo characterize the stance of news websites, we have already proposed a framework [ 2]\nthatrepresentsthebiasofnewswebsitestowardaparticulartopicintermsofavector. This\nPolarity-based Stance vector expresses the proportions of positive, neutral, and negative articles\nfor a particular topic. Comparing the Polarity-based Stance for various topics is useful for\ncharacterizingthestanceofanewswebsite(e.g.,beingfororagainstaparticularpresidential\ncandidate).\n2.2. SIRIUS: Interactive Visualization Tool for Multidimensional Data\nSIRIUS [5] is a recently developed interactive visualization tool for multidimensional data.\nSIRIUS usesmultidimensionalscaling (MDS)as thebasictoolforvisualization andproposes a\nframework for visualizing data using symmetric duality in the multidimensional data. MDS\ncharacterizes the data by calculating the distances between data items. In addition to giving the\nMDSresultsforthedata,SIRIUScanvisualizetheattributes(conceptualnamesforthevaluesin\neach dimension) used by MDS and the transposed matrix used to calculate distances among the\ndataitems. SIRIUS implements interactivevisualizationin termsof weighted MDS(WMDS) [ 6].\nWMDS uses the weighted Euclidean distance between the \ud835\udc56-th and\ud835\udc57-th data item ( \ud835\udc64\ud835\udc51\ud835\udc56\ud835\udc57) instead\nof the standard Euclidean distance. The weighted Euclidean distance is calculated as\n\ud835\udc64\ud835\udc51\ud835\udc56\ud835\udc57=\ud835\udc5b\n\u2211\n\ud835\udc58=1\ud835\udc64\ud835\udc58(\ud835\udc51\ud835\udc56\ud835\udc58\u2212\ud835\udc51\ud835\udc57\ud835\udc58), (1)\nwhere\ud835\udc5b,\ud835\udc64\ud835\udc58,and\ud835\udc51\ud835\udc56\ud835\udc58denotethedimensionality,theweightvalueforthe \ud835\udc58-thdimensionofweight\nvector\ud835\udc64, and the \ud835\udc58-th attribute value of the \ud835\udc56-th data item, respectively.\nWMDScanrepresentthemultidimensionaldatabasedonusers\u2019interests( \ud835\udc64)byusingthe\nweighted Euclidean distance instead of the standard Euclidean distance.\nSIRIUSoffersaframeworkforestimatingthevalueoftheweightvector \ud835\udc64basedoninteraction\nwiththevisualizationresults. Theusercanreorganizethedatatorepresentbettertheuser\u2019s\ninterests. SIRIUS updates the weight vectors using WMDS, aiming to minimize the sum of the\ndifferences between distances in the reorganized data and those in the new visualization data.\nFeedbackfromthesystemisgivenviavisualizationoftheattributes. Userscanunderstand\ntheirintereststhroughtheweightvaluesassignedforeachdimensionandthescatterplotsof\nthe data given by WMDS.\n3. Visualization of the Polarity-based Stance Matrix using News\nGenres\n3.1. News-genre Polarity-based Stance Matrix\nTo understand better the characteristics of a news website, it is useful to know its degree\nof interest in various topics. We assume that its interests can be characterized in terms of\nnewsgenres. Forexample,anewswebsitecouldbepositivetowardatopicwithrespecttoits\neconomicsaspects,butnegativewithrespecttoitspoliticalaspects. Therefore,weproposea\nnovelrepresentationforthestanceofnewswebsitesusingbothpolarity-basedscoresandnews\ngenres in terms of a news-genre polarity-based stance matrix (NPSM):\nNPSM=(\ud835\udc5d1\ud835\udc5d2\u22ef \ud835\udc5d\ud835\udc5a\nneu1neu2\u22efneu\ud835\udc5a\n\ud835\udc5b1\ud835\udc5b2\u22ef \ud835\udc5b\ud835\udc5a)\n.\nHere,\ud835\udc5ais the number of news genres considered, and \ud835\udc5d\ud835\udc56, neu\ud835\udc56, and\ud835\udc5b\ud835\udc56correspond to the\nproportions of positive,neutral, and negative articles, respectively, for newsgenre \ud835\udc56among all\navailablearticlesonthetopic. Thereasonforincludingtheproportionofneutralarticles,which\nwasnotusedinthepreviousdefinition,isthatthisvalueisusefulincharacterizingthenews\nwebsites\u2019degreeofinterestinthetopic. Thismatrixforeachnewswebsiteisconvertedto 3\u00d7\ud835\udc5a\ndimension vector for calculating distance between other news website.\n3.2. Data Construction\n3.2.1. Assigning a news genre to each article\nToanalyzenewswebsitesusing \ud835\udc41\ud835\udc43\ud835\udc46\ud835\udc40,itisnecessarytoselectalistofnewsgenres. Forthis\npurpose,weanalyzedseveralwell-knownnewswebsites,namely Los Angeles Times ,Washington\nPost,Business Insider , andYahoo!News , that have news genres. Based on this analysis, we\nselected the following seven top-level genres as a candidate list of news genres for this analysis\n(i.e.,\ud835\udc5a = 7): politics (pol), domestic (dom), international (int), economy (eco), science (sci),\nlifestyle (lif), and entertainment and sports (e/s) for analyzing the political stance of a news\nwebsite. Intherealdata,therearearticlesthatareassignedtwoormorenewsgenres. However,\nin this research, we assign one news genre for all articles to make this assignment task simpler.\nIt is necessary to analyze the effect of this setting for the future works of our system.\nApossibleproblemincollectingdataforeachnewswebsiteisthatinsufficientinformation\nmay be available to estimate the genres for its news articles. If a news website organizes its\narticles using the genres proposed in this paper, there is no problem. However, there are news\nwebsites that use different names for news genres and others that omit genre information.\nFortheformercase,wemanuallyconstructrulesthatmapthenewsgenresusedbythenews\nwebsite into our seven newsgenres. For the latter case, it is necessary to develop a system for\nassigning news genre information about the news articles.\nIn this work, we planned to use the GDELT3database, which contains information about\nthe list of named entities mentioned in the paper, polarity information, and universal resource\nlocators (URLs). We use the URLs to estimate the news genre because they often contain infor-\nmation related to the news genre or title of the article and propose a news genreclassification\ntool that uses the deep-learning-based natural-language-processing tool BERT [ 7]. BERT is an\ninfrastructure for creating contextual text-analysis tools via training with a big-data corpus for\ngeneralcontextualtasks. For thetraining data,weused URLsfor thenewswebsitesthatwere\nproperly categorized in terms of our seven news genres and URLs for news websites whose\nnews genre was assigned manually (\u201cgold standard\u201d news genre data).\n3.2.2. Construction of news genre polarity-based stance data\nFor each news article, a polarity type (positive, neutral, or negative) is assigned via the method\nproposedin[ 2]. Inthismethod,the\u201ctonescore\u201d \ud835\udc61,whichisascoreforrepresentingthepositive\ncontentsminusthe negativecontentsand providedby GDELT,isused forthisclassification.\nThat is, positive is represented by \ud835\udc61 > 1, negative by \ud835\udc61 < \u22121, and neutral otherwise).\nAsaresult,allnewsarticlescanbeclassifiedintermsofnewsgenreandpolarity. Thesystem\nthen constructs \ud835\udc41\ud835\udc43\ud835\udc46\ud835\udc40by calculating the ratios (seven news genres \u00d7three polarities) for each\nnewswebsite. Afterconstructingthe 7\u00d73matrix,wetranslatethismatrixto21-dimensional\nvectors for input to SIRIUS.\n3https://www.gdeltproject.org/\n4. Experiments\n4.1. Data Construction using GDELT\nFollowing [ 2], we collected article data from GDELT for news websites listed in the Media Bias\nChart5.14, whichprovided information about bias and quality aspects of news,mainly for US\nnews websites. Examples of the type of information about an article included whether the\ncontentofthearticlerelatedtopresidentialcandidatesDonaldTrumporHillaryClinton,the\ndateofdistributionofthearticle,itsURL,andthevalueofitspolarity(calculatedbyGDELT\nfromwordsusedinthebodyofthearticle). Thedatacollectedwerefor77newswebsitesduring\nthe period from September 1, 2016 to November 31, 2016.\n4.2. News Genre prediction using BERT\nWe constructed a news genre classification system, as discussed in Section 3.2.1, us-\ning the collected data. For URL data, we used their final element (e.g., aaa.html in\nhttps://www.aa.com/bb/aaa.html )forinputintothesystem. ThepretrainedmodelforBERTwas\nthe12-headuncasedmodelreleasedbyGooglein20185andweuseda12-layer,768-dimensional\nhiddenlayerforfinetuning. Wesplitthedatacollectedas\u201cgoldstandard\u201dnewsgenredatainto\na training set, a development set, and a test set at ratios of 6:2:2, respectively, and the task was\nto estimate the news genre based on the probabilities predicted for each news genre. In this\nsystem, the highest-probabilitynewsgenrewas assigned as the newsgenreof the article. The\nresults of the predictions for the test data are shown in Table 1.\nTable 1\nPerformance in Predicting Article News Genre for Test Data\nNews Genre Precision Recall F1-score Support\npol 0.96 0.86 0.91 8,304\ndom 0.74 0.79 0.76 2,970\nint 0.90 0.87 0.88 3,286\neco 0.76 0.86 0.81 2,833\nsci 0.86 0.87 0.87 3,147\nlif 0.84 0.93 0.88 2,882\ne/s 0.88 0.89 0.88 3,169\nAccuracy 0.87 26,591\nThissystemwasusedtoassignanewsgenretonewsarticleswhoseURLsdidnotcontain\nnewsgenreinformation. Table 2givesthenumbersofarticlesrelatedtoDonaldTrumpused\nfor the data analysis.\nTable 2\nNumber of Articles by Classification Method\nClassified manually 24,564\nClassified by BERT 120,440\nTotal 145,004\n4https://www.adfontesmedia.com\n5https://github.com/google-research/bert\n4.3. Data Analysis using SIRIUS\nUsingourcollectednews-websiteinformation,weaimedtoanalyzethepolarity-basedstance\nof news websites toward Donald Trump during the presidential election period, September\n1, 2016 to November 31, 2016. Right-upper side of Figure 1shows an initial plot of the news\nwebsites(graybackground)andattributes(bluebackground)usingSIRIUS.Forthenewswebsites\nplot,initialplotiscalculatedbyordinalMDS(weightsforalldimensionsaresame). Redand\nblue colored nodes shows the right-wing and the left-wing news websites defined by the\ninformationinMediaBiasChart5.1respectively. Attributesplotshowstheresultssimilarity\namong parameters. The radius of the node shows weight of the attribute. Since distance\nbetweentwoattributesarecalculatedbyusingattribute-newswebsitematrixbytransposing\nnews website-attributes matrix, attributes whose distribution are different from others are\nplotted far from the middle.\nRight-wingtheamericancoservative.com,infowars.com, newsmax.com, theblaze.com, politico.com. washingtontimes.com, thehill.comLeft-wingcnn.com, nytimes.com,washingtonpost.com,counterpunch.org,alternet.orgChange location of left-wing and right-wing sitefor representing similarity and dissimilarity\nNeg-domNeg-lifeNeg-sciNeg-eco\nNeg-intNeg-polNeg-ent\nforbes.com,fortune.com,thefiscaltimes.com, wsj.com, marketwatch.combloomberg.com\nFigure 1: Interactive updating by moving news-website nodes\nFrom this initial plots, the user change the position of some right-wing news websites\n(theamericanconservative ,newsmax,theblaze,washingtontimes ,infowars,politico,thehill)\nandleft-wingnewswebsites( cnn,nytimes,washingtonpost ,alternet,counterpunch )tothe cor-\nner for reprsenting similarity and dissimilarity (left side of Figure 1). SIRIUS update the weight\nof attribute based on this node location and update the results (right bottom of Figure 1). In\nthis case, most of the negative attributes are plotted far from the middle. The interpretation is\nFigure 2: Result of replotting with the weight of the international (int) topic increased\nthat ratio of negative articles of various news genres can be used to characterize the differences\namongnewswebsitesusingwingspecificinformation. Notethatneutralfinancialnewswebsites\nsuch as ForbesandFortuneare gathered together at the bottom.\nAnotherpossibleoperationistocontroltheweight. Figure 2illustratestheresultofupdating\nthe plot by putting an emphasis on \u201cinternational\u201d (int) (the positive, negative, and neutral\nweights for int were 0.2133and were 0.02for others). In this figure, note that the node for\nforeignpolicy.com is large and plotted at a position distant from other objects. This is because\nthis news website focuses on issues related to foreign policy (i.e., related to \u201cinternational\u201d),\nwhereasnewswebsitesthatarelessinterestedininternationalissuesaregatheredinthemiddle.\n4.4. Discussion\nBasedontheseexamples,wecanconfirmthattheinteractivevisualizationofnewswebsites\nusing SIRIUS promises to represent the characteristics of news-stance differences based on the\nnews genres. This reflects those news websites may have different interests on issues classified\nby news genre. Interactive operation to such multiple dimension data may be useful to analyze\nsimilaritywithmultipleaspects. Forexample,feedbackfromthesystemasattributeinformation\nis helpful in understanding better the replotted results (Figure 1) and direct operation to the\nweight change can generate a visualization result that focused on particular news genre (Figure\n2). However,it is not always easy to interpretthe final resultsin depth.\n5. Conclusions and Future Work\nInthispaper, weproposea systemtoevaluatethestanceof newswebsitesusinginteractive\nmultidimensionaldata-visualizationtools. Inparticular,wediscussthecharacteristicsofthe\ninteractive visualization tool SIRIUS. Because this is the first attempt at visualizing political\nstances using news genres, it will be necessary to apply this system to other examples and\nobtain feedback from real users in its evaluation.\nAcknowledgments\nThis work was partially supported by JSPS KAKENHI Grant Number 18H0333808.\nReferences\n[1]D. K\u00fc\u00e7\u00fck, F. Can, Stance detection: Concepts, approaches, resources, and outstanding\nissues, in: Proceedingsof the 44thInternational ACMSIGIR Conferenceon Researchand\nDevelopmentinInformationRetrieval,SIGIR\u201921,AssociationforComputingMachinery,\nNew York, NY, USA, 2021, p. 2673\u20132676. URL: https://doi.org/10.1145/3404835.3462815 .\ndoi:10.1145/3404835.3462815 .\n[2]M. Yoshioka, M. Jang, J. Allan, N. Kando, Visualizing polarity-based stances of news\nwebsites, in: Proceedings of the Second International Workshop on Recent Trends in News\nInformation Retrieval co-located with 40th European Conference on Information Retrieval\n(ECIR 2018), Grenoble, France, March 26, 2018., 2018, pp. 6\u20138. URL: http://ceur-ws.org/\nVol-2079/paper2.pdf .\n[3]E. T. Brown, J. Liu, C. E. Brodley, R. Chang, Dis-function: Learning distance functions\ninteractively, in: VisualAnalytics Science andTechnology (VAST),2012 IEEEConference\non, IEEE, 2012, pp. 83\u201392.\n[4]M.Yoshioka,M.Itoh,M.Sebag, Interactivemetriclearning-basedvisualdataexploration:\nApplication to the visualization of a scientific social network, in: E. Grant, D. Kotzinos,\nD. Laurent, N. Spyratos, Y. Tanaka (Eds.), Information Search, Integration, and Personaliza-\ntion, Springer International Publishing, Cham, 2016, pp. 142\u2013156.\n[5]M. Dowling, J. Wenskovitch, J. T. Fry, S. Leman, L. House, C. North, Sirius: Dual, symmet-\nric,interactivedimensionreductions, IEEETransactionsonVisualizationandComputer\nGraphics 25 (2019) 172\u2013182. doi: 10.1109/TVCG.2018.2865047 .\n[6]A.Endert, C.Han, D.Maiti, L.House, S. Leman, C. North, Observation-levelinteraction\nwithstatisticalmodelsforvisualanalytics, in: 2011IEEEConferenceonVisualAnalytics\nScience and Technology (VAST), 2011, pp. 121\u2013130.\n[7]J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep bidirectional\ntransformersforlanguageunderstanding,2018.URL: http://arxiv.org/abs/1810.04805 ,cite\narxiv:1810.04805Comment: 13 pages.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Interactive Visualization of the Polarity-based Stance of News Websites using News Genres", "author": ["M Yoshioka", "N Tatsunami", "M Itoh", "N Kando", "J Allan"], "pub_year": "2021", "venue": "NA", "abstract": "We have been working on a project that aims to characterize the stance of news websites. We  are proposing a framework that can classify websites in terms of the relative proportions of"}, "filled": false, "gsrank": 539, "pub_url": "https://ceur-ws.org/Vol-3143/paper6.pdf", "author_id": ["rZZY-X4AAAAJ", "", "DKWtO7MAAAAJ", "IKVCQG8AAAAJ", "-bLGeg0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:KunMRE0fStIJ:scholar.google.com/&output=cite&scirp=538&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D530%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=KunMRE0fStIJ&ei=ZrWsaNvsJbXCieoP4PfQ0A8&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:KunMRE0fStIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ceur-ws.org/Vol-3143/paper6.pdf"}}, {"title": "The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment", "year": "2024", "pdf_data": "Vol.:(0123456789)1 3Behavior Research Methods (2024) 56:1863\u20131899 \nhttps://doi.org/10.3758/s13428-023-02124-2\nThe Misinformation Susceptibility Test (MIST): A\u00a0psychometrically \nvalidated measure of\u00a0news veracity discernment\nRakoen\u00a0Maertens1 \u00a0\u00b7 Friedrich\u00a0M.\u00a0G\u00f6tz2 \u00a0\u00b7 Hudson\u00a0F.\u00a0Golino3 \u00a0\u00b7 Jon\u00a0Roozenbeek1 \u00a0\u00b7 Claudia\u00a0R.\u00a0Schneider1 \u00a0\u00b7 \nYara\u00a0Kyrychenko1 \u00a0\u00b7 John\u00a0R.\u00a0Kerr1 \u00a0\u00b7 Stefan\u00a0Stieger4 \u00a0\u00b7 William\u00a0P .\u00a0McClanahan1,5 \u00a0\u00b7 Karly\u00a0Drabot1 \u00a0\u00b7 James\u00a0He1 \u00a0\u00b7 \nSander\u00a0van\u00a0der\u00a0Linden1 \nAccepted: 5 April 2023 / Published online: 29 June 2023 \n\u00a9 The Author(s) 2023\nAbstract\nInterest in the psychology of misinformation has exploded in recent years. Despite ample research, to date there is no validated \nframework to measure misinformation susceptibility. Therefore, we introduce V erification done, a nuanced interpretation schema \nand assessment tool that simultaneously considers V eracity discernment, and its distinct, measurable abilities (r eal/fake news \ndetection), and biases (d istrust/ na\u00efvit\u00e9\u2014negative/positive judgment bias). We then conduct three studies with seven independent \nsamples (Ntotal = 8504) to show how to develop, validate, and apply the Misinformation Susceptibility Test (MIST). In Study 1 \n(N = 409) we use a neural network language model to generate items, and use three psychometric methods\u2014factor analysis, item \nresponse theory, and exploratory graph analysis\u2014to create the MIST-20 (20 items; completion time < 2 minutes), the MIST-16 \n(16 items; < 2 minutes), and the MIST-8 (8 items; < 1 minute). In Study 2 (N = 7674) we confirm the internal and predictive \nvalidity of the MIST in five national quota samples (US, UK), across 2 years, from three different sampling platforms\u2014Respondi, \nCloudResearch, and Prolific. We also explore the MIST\u2019s nomological net and generate age-, region-, and country-specific norm \ntables. In Study 3 (N = 421) we demonstrate how the MIST\u2014in conjunction with Verification done\u2014can provide novel insights \non existing psychological interventions, thereby advancing theory development. Finally, we outline the versatile implementations \nof the MIST as a screening tool, covariate, and intervention evaluation framework. As all methods are transparently reported and \ndetailed, this work will allow other researchers to create similar scales or adapt them for any population of interest.\nKeywords Misinformation susceptibility\u00a0\u00b7 Automated item generation\u00a0\u00b7 Fake news\u00a0\u00b7 Neural networks\u00a0\u00b7 Psychometrics\nThe global spread of misinformation has had a palpable \nnegative impact on society. For instance, conspiracy theories about the coronavirus disease 2019 (COVID-19) vaccines \nhave been linked to increased vaccine hesitancy and a decline \nin vaccination intentions (Hotez et\u00a0al., 2021; Loomba et\u00a0al., \n2021; Roozenbeek et\u00a0al., 2020). Misinformation about the \nimpact of 5G has led to the vandalization of cell phone masts \n(Jolley & Paterson, 2020 ), and misinformation about climate \nchange has been associated with a reduction in perceptions of \nscientific consensus (Maertens et\u00a0al., 2020; van der Linden \net\u00a0al., 2017). With false and moral-emotional media spread-\ning faster and deeper than more accurate and nuanced content \n(Brady et\u00a0al., 2017; Vosoughi et\u00a0al., 2018), the importance of \ninformation veracity has become a central debate for scholars \nand policymakers (Lewandowsky et\u00a0al., 2017, 2020).1Rakoen Maertens and Friedrich M. G\u00f6tz contributed equally to this work.\n * Rakoen Maertens \n rm938@cam.ac.uk\n Friedrich M. G\u00f6tz \n friedrich.goetz@ubc.ca\n1 Department of\u00a0Psychology, University of\u00a0Cambridge, \nDowning Street, CB2\u00a03EB\u00a0Cambridge, Cambridgeshire, UK\n2 Department of\u00a0Psychology, University of\u00a0British Columbia, \n2136 West Mall, Vancouver, BC\u00a0V6T\u00a01Z4, Canada\n3 University of\u00a0Virginia, Charlottesville, VA, USA\n4 Karl Landsteiner University of\u00a0Health Sciences, \nKrems\u00a0an\u00a0der\u00a0Donau, Austria\n5 Max Planck Institute for\u00a0the\u00a0Study of\u00a0Crime, Security \nand\u00a0Law, Freiburg\u00a0im\u00a0Breisgau, Germany1 It should be noted that recent research also provides evidence for \nan alternative perspective, namely that the spread of misinforma-\ntion could be driven more by an emotional dimension than a veracity \ndimension (Cinelli et\u00a0al., 2020).\n1864 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nAccordingly, across disciplines, research on the pro -\ncesses behind, impact of, and interventions against misin-\nformation has surged over the past years (for recent reviews, \nsee Pennycook & Rand, 2021; Roozenbeek et\u00a0al., 2023; Van \nBavel, Harris, et\u00a0al., 2020; van der Linden et\u00a0al., 2021). \nResearchers have made progress in designing media and \ninformation literacy interventions in the form of educational \ngames (Basol et\u00a0al., 2021; Roozenbeek & van der Linden, \n2019, 2020), \u201caccuracy\u201d primes (Pennycook et\u00a0al., 2021b; \nPennycook et\u00a0al., 2020 ), introducing friction (Fazio, 2020 ), \nand inoculation messages (Lewandowsky & van der Linden, \n2021). Crucially, however, no theoretical framework exists \nfor a nuanced evaluation of misinformation susceptibility, \nnor a psychometrically validated measurement that provides \na reliable measure across studies.\nInconsistent interpretation and\u00a0the\u00a0need \nfor\u00a0a\u00a0new measurement instrument\nDespite the plethora of research papers on the psychology of \nmisinformation, the field has not converged on a standard-\nized way of defining or measuring people\u2019s susceptibility to \nmisinformation. In the absence of such a commonly agreed-\nupon standard, scholars have been inventive in the way that \nthey employ individually constructed misinformation tests, \noften with the best intentions to create a good scale, but typi-\ncally without formal validation (e.g., Pennycook, Epstein, \net\u00a0al., 2021b; Roozenbeek et\u00a0al., 2021b).\nThe extent of the problem becomes evident when exam-\nining how researchers develop their test items and report \nthe success of their models or interventions. Typically, \nresearchers create (based on commonly used misinforma-\ntion techniques; e.g., Maertens et\u00a0al., 2021; Roozenbeek \n& van der Linden, 2019) or select (from a reliable fact-\ncheck database; e.g., Cook et\u00a0al., 2017; Guess et\u00a0al., 2020; \nPennycook et\u00a0al., 2020; Pennycook & Rand, 2019; Swire \net\u00a0al., 2017; van der Linden et\u00a0al., 2017) news headlines \nor social media posts, where participants rate the relia -\nbility, intentions to share, accuracy, or manipulativeness \nof these items on a Likert or binary (e.g., true vs. false) \nscale; for an extensive discussion, see Roozenbeek et\u00a0al. \n(2022). Sometimes the news items are presented as plain-\ntext statements (e.g., Roozenbeek et\u00a0al., 2020), while in \nother studies researchers present headlines together with an \nimage, source, and lede sentence (e.g., Pennycook & Rand, \n2019). The true-to-false ratio often differs, where in some \nstudies only false news items are presented (e.g., Roozen-\nbeek et\u00a0al., 2020), and in others this is an unbalanced (e.g., \nRoozenbeek et\u00a0al., 2021b ) or balanced (e.g., Pennycook & \nRand, 2019) ratio of true and false items. Often an index \nscore is created by taking the average of all item ratings \n(an index score reflecting general belief in false or true news items; e.g., Maertens et\u00a0al., 2021), or by calculating \nthe difference between ratings of true items and false items \n(veracity discernment; e.g., Pennycook, McPhetres, et\u00a0al., \n2020). Finally, an effect size is calculated, and a claim is \nmade with respect to the effectiveness of the intervention, \nbased on a change in false news ratings (e.g., Roozenbeek \n& van der Linden, 2019), a combined change in true news \nratings and false news ratings (e.g., Guess et\u00a0al., 2020 ), \nor even a change in true news ratings only (Pennycook, \nMcPhetres et\u00a0al., 2020).\nIt becomes clear that the wide variation in methodolo-\ngies makes it hard to compare studies or generalize con -\nclusions beyond the studies themselves. Little is known \nabout the psychometric properties of these ad hoc scales \nand whether or not they measure a latent trait. As a wide-\nspread practice in misinformation research, scholars often \nassume\u2014rather than know\u2014that they are measuring the \nsame construct. As a result, if this bold assumption turned \nout to be untrue, we would be at risk of obscuring underly -\ning phenomena by incorrectly labeling them as the same \nmechanism, thereby engaging in an illusory essence bias \n(Brick et\u00a0al., 2022) and/or falling prey to jingle fallacies \n(Block, 1995; Condon et\u00a0al., 2020). As misinformation is a \ncomplex issue, the responses on one item set may be a result \nof motivational factors, while responses on another scale \nmay be more reflective of critical thinking skills, instead \nof both measuring the same \u201cdiscernment skill.\u201d We cur -\nrently do not know how different misinformation suscep -\ntibility scales are related, or how the true-to-false ratios \ninfluence their outcome (Aird et\u00a0al., 2018) and how much \nof the effects found are due to response biases rather than \nchanges in skill (Batailler et\u00a0al., 2022). The limited stud-\nies that do look at the issue of scale-specific effects show \nsignificant item effects, indicating a risk of skewed con-\nclusions about intervention effect sizes (e.g., Roozenbeek, \nMaertens et\u00a0al., 2021b).2 Relatedly, whether the sampling \nof test items, their presentation, and response modes have a \nhigh ecological validity is often not discussed (Dhami et\u00a0al., \n2004 ; Roozenbeek et\u00a0al., 2022 ), and little is known about \nthe nomological net and reliability of the indices used. In \nother words, it is difficult to disentangle whether differences \nbetween studies are due to differences in the interpretation \nschema, the measurement instrument, or actual differences \nin misinformation susceptibility. This indicates a clear need \nfor a unified theoretical framework in conjunction with a \nstandardized instrument with strong internal and external \nvalidity.\n2 While there are models that take into account the baseline plausi-\nbility of each item, they still do not reveal what construct each item \nis measuring. In other words, there may still be unexplained variabil-\nity even when controlling for baseline plausibility, such as issues with \nitem stability, and different effect sizes between item sets in interven-\ntion studies.\n1865 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nThe present research\nTowards a\u00a0universal conceptualization \nand\u00a0measurement: The Verification done framework\nHere, we set out to create a theoretical interpretation schema \nas well as a first psychometrically validated measurement \ninstrument that, in conjunction, resolve the issues mentioned \nabove and offer utility for a wide range of scholars. We \nextend the current literature by providing the first psycho-\nmetrically integrated conceptualization of misinformation \nsusceptibility that allows for a reliable holistic measurement \nthrough the Verification done framework: we can only fully \ninterpret misinformation susceptibility\u2014or the impact of an \nintervention\u2014by capturing news veracity discernment ( V, \nability to accurately distinguish real news from fake news) as \na general factor, the specific facets real news detection abil -\nity (r, ability to correctly identify real news) and fake news \ndetection ability ( f, ability to correctly identify fake news), \ndistrust ( d; negative judgment bias, being overly skeptical), \nand na\u00efvit\u00e9 ( n; positive judgment bias, being overly gulli-\nble), and comparing V , r, f, d, and n alongside each other. A \nvisualization of the V erification done model can be found in \nFig.\u00a01. For example, two different interventions may increase \ndiscernment ability V  to a similar extent, but intervention \nA might do so by increasing detection ability r , while inter -\nvention B may accomplish the same by increasing detection \nability f. Similarly, two people with the same discernment \nability V may have opposite r  and f  abilities. Changes in \ndetection abilities r  or f  after an intervention have to be interpreted together with changes in judgment biases d \nand n to determine whether the intervention has done more \nthan just increase a judgment bias. Existing interventions \noften look at a limited subset of these five dimensions; for \nexample, the creators of the Bad News Game intervention \n(Roozenbeek & van der Linden, 2019) originally focused on \nfake news detection, including only a few real news items. \nMeanwhile, the accuracy nudge intervention seems to work \nmainly by addressing real news detection (Pennycook, \nMcPhetres, et\u00a0al. 2020), although we are not sure about the \njudgment biases. Another media literacy intervention was \nfound to increase general distrust, but showed improvement \non veracity discernment nevertheless (Guess et\u00a0al., 2020).\nIn order to be able to compare these scores and gain \ninsights into the complete picture, we need to employ the \nVerification done framework, but also make sure that each \nscale has high validity and comparability. To accomplish \nthis, through a series of three studies and using a novel neu-\nral-network-based item generation approach, we develop \nthe Misinformation Susceptibility Test (MIST): a psycho-\nmetrically validated (based on classical test theory and \nitem response theory, as well as exploratory graph analysis) \nmeasurement instrument. The MIST was developed to be the \nfirst truly balanced misinformation susceptibility measure \nwith an equal emphasis on discernment, real news detec-\ntion, fake news detection, and judgment bias. In addition, to \nput the results into perspectives, all scores should be inter -\npreted along with national norm tables. In the present study, \nwe describe how we developed and validated the MIST to \naccomplish these goals, evaluate each of these dimensions, \nFig. 1  Visualization of the Verification done model\n1866 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nand investigate the practical utility of the MIST for research-\ners and practitioners in the field.\nThe Misinformation Susceptibility Test\nWe conduct three studies to develop, validate, and apply the \nMIST. In Study 1 (N  = 409), we employ a multitude of explor -\natory factor analysis (EFA)- and item response theory (IRT)-\nbased selection criteria to create a 20-item MIST full-scale \nand an 8-item MIST short-scale from a larger item pool that \nwas built using a combination of advanced language-based \nneural network algorithms and real news headline extraction \nfrom reliable and unbiased media outlets, and then pre-filtered \nthrough multiple iterations of expert review. The resultant \nMIST scales are balanced (50% real, 50% fake), binary (real/\nfake), cumulatively scored instruments that ask participants \nto rate presented news headlines as either true or false, with \nhigher MIST scores indicating greater discernment ability.3 \nWe also present a new, alternative method to EFA and IRT, \nnamely exploratory graph analysis (EGA; Golino & Epskamp, \n2017; Golino et\u00a0al., 2021), to show how modern psychomet-\nrics may lead to other robust item selections.\nWe acknowledge that the typical news consumption diet \nin real life includes more real news than fake news (e.g., \nGuess et\u00a0al., 2020). However, as misinformation has the \npotential to spread faster (Brady et\u00a0al., 2017; Vosoughi et\u00a0al., \n2018), and we aim to accurately measure a general discern-\nment ability as well as both real news detection and fake \nnews detection, in creating the MIST we have given equal \nrepresentation on both facets. This allows us to generalize \nacross the board\u2014independent of an individual\u2019s news con-\nsumption ratio. Meanwhile, to capture any biases related to \noverly positive or negative responses (to news in general), \nwe have later added a method to calculate response biases d \nand n (these were not part of the original scale development \nprotocol). As such, the MIST exhibits a psychometrically \nvalidated higher-order structure, with two validated first-\norder factors r and f (i.e., real news detection, fake news \ndetection) and one general ability second-order factor V \n(i.e., veracity discernment), as well as a method to calculate \nresponse biases d (i.e., distrust) and n (i.e., na\u00efvit\u00e9).4In Study 2 (N  = 7674), we employ confirmatory factor \nanalyses (CFA), as well as EGA, to replicate the MIST\u2019s \nstructure across four national quota samples from the UK \nand the US, establish construct validity via a large, prereg -\nistered nomological network, and derive norm tables for the \ngeneral populations of the UK and US and demographic and \ngeographical subgroups.\nIn Study 3 (N  = 421), we provide an example of how to \nimplement Verification  done and the MIST in the field by \napplying it in the naturalistic setting of a well-replicated media \nliteracy intervention, the Bad News Game ( https:// www. getba  \ndnews. com/). Whereas ample prior studies have attested to the \ntheoretical mechanisms and effects that contribute to the Bad \nNews Game\u2019s effectiveness in reducing misinformation sus-\nceptibility (see, e.g., Maertens et\u00a0al., 2021 ; Roozenbeek & van \nder Linden, 2019), within-subject repeated-measures analy -\nses of the MIST-8 for pre-and post-game tests in conjunction \nwith the V erification done framework reveal important new \ninsights about how the intervention affects people across dif-\nferent evaluative dimensions. This paper demonstrates the ben -\nefits of integrated theory and assessment development, result-\ning in a framework providing nuanced, multifaceted insights \nthat can be gained from a short, versatile, psychometrically \nsound, and easy-to-administer new measure. Table\u00a0 1 offers a \ncomprehensive summary of all samples used, detailing their \nsize, demographic breakdowns, included measures, country of \norigin, recruitment platform, and whether or not they (a) used \nnationally representative quota and (b) were preregistered.\nStudy 1: Development\u2014Scale construction, \nexploratory analyses, and\u00a0psychometric \nproperties\nFollowing classic (Clark & Watson, 1995; Loevinger, 1957) \nand recent (Boateng et\u00a0al., 2018; Rosellini & Brown, 2021; \nZickar, 2020) psychometrics guidelines, and taking into \naccount insights from misinformation scholars (Pennycook \net\u00a0al., 2021a; Roozenbeek et\u00a0al., 2021b), we devised a four-\nstage, preregistered scale development protocol (i.e., 1\u2014\nitem generation, 2\u2014expert filtering, 3\u2014quality control, and \n4\u2014data-driven selection), shown in Fig.\u00a0 2.\nMethod\nPreparatory steps\nPhase 1: Item generation\nFake news There is a debate in the literature on whether the \nmisinformation items administered in misinformation stud-\nies should be actual news items circulating in society, or news 3 We chose the binary coding approach (i.e., true versus false head-\nline) because it allows us to create a straightforward and easy-to-inter -\npret structure with either a correct or an incorrect response for each \nitem, which is also easy to implement and analyze in a performance-\nbased IRT model, without compromising on quality (e.g., in Studies \n1\u20132 we validated the MIST with items that are administered with Lik -\nert scales, providing evidence for its broader predictive validity).\n4 Note that distrust and na\u00efvit\u00e9 were not included in the psychomet-\nric scale development protocol, but only added later on as a post hoc \ncalculation. The factor structure used for the scale development using \nEFA/IRT analyses can be found in Fig.\u00a0 9, and the structure used for \nthe EGA-based scale can be found in Fig.\u00a07.\n1867 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nTable 1  Summary of samples\nStudy 1: Devel-\nopmentStudy 2: Validation Study 3:  \nApplication\nSample 1A 2A 2B 2C 2D 2E 3\nN 409 3479 510 1227 1245 1213 421\nCountry of \noriginUSA USA USA UK UK USA USA\nNationally \nrepresenta-\ntive quotaNo Yes Yes Yes Yes Yes No\nRecruitment \nplatformProlific Respondi CloudResearch Respondi Prolific Respondi Bad News  \nGame\nPreregistration Yes No Yes No No No No\nDemographic \ncompositionAge\nMage = 33.20\nSDage = 11.85Age\nMage = 45.10\nSDage = 16.16Age\nMage = 49.25\nSDage = 16.96Age\nMage = 45.34\nSDage = 16.52Age\nMage = 44.66\nSDage = 15.65Age\nMage = 45.21\nSDage = 17.35Age\n55.58% [18,  \n29]\n32.30% [30,  \n49]\n12.11% [50,  \n99]\nGender\n55.50% female\n42.30% male\n2.20% other/non-\nbinaryGender\n51.11% female\n48.84% male\n0.06% other/nonbinaryGender\n55.88% female\n43.53% male\n0.59% other/nonbinaryGender\n51.67% female\n48.33% male\n0.00% other/non-\nbinaryGender\n52.53% female\n47.07% male\n0.40% other/non-\nbinaryGender\n54.00% female\n44.19% male\n1.81% nonbinaryGender\n52.02% female\n41.09% male\n6.89% other/\nnonbinary\nEthnicity\n\u2013Ethnicity\n76.89% White, Caucasian, \nAnglo, or European \nAmerican\n8.39% Asian or Asian Ameri-\ncan\n6.00% Hispanic or Latino\n5.98% Black or African \nAmerican\n1.12% Native American or \nAlaskan Native\n0.54% Middle Eastern\n0.30% Hawaiian or Pacific \nIslander\n0.77% Other/Prefer not to \nanswerEthnicity\n68.81% White, Caucasian, Anglo, or \nEuropean American\n4.28% Asian or Asian American\n11.05% Hispanic or Latino\n12.12% Black or African American\n2.50% Native American or Alaskan \nNative\n0.18% Middle Eastern\n1.07% Other/Prefer not to answerEthnicity\n87.33% White\n6.95% Asian\n2.45% Black\n0.08% Arab\n2.13% Mixed\n1.06% OtherEthnicity\n86.10% White\n7.47% Asian\n3.53% Black\n0.16% Arab\n1.61% Mixed\n1.12% OtherEthnicity\n\u2013Ethnicity\n\u2013\n1868 Behavior Research Methods (2024) 56:1863\u20131899\n1 3Table 1  (continued)\nStudy 1: Devel-\nopmentStudy 2: Validation Study 3:  \nApplication\nEducation\n1.47% Less than \nhigh school \ndegree\n9.29% High \nschool graduate\n31.30% Some \ncollege but no \ndegree\n38.88% Bach-\nelor's degree in \ncollege\n1.96% Profes-\nsional degree\n13.45% Master's \ndegree\n3.67% Doctoral \ndegreeEducation\n1.74% Did not complete high \nschool\n34.98% High school degree \nor equivalent\n15.08% Associate degree\n31.84% Degree (bachelor\u2019s) \nor equivalent\n15.11% Degree (master\u2019s) or \nother postgraduate quali-\nfication\n1.25% Doctorate\n0.97% Other/Prefer not to sayEducation\n2.55% Less than high school degree\n25.10% High school graduate\n27.45% Some college but no degree\n26.08% Bachelor's degree in college\n1.57% Professional degree\n13.92% Master's degree\n3.33% Doctoral degreeEducation\n11.03% No formal \neducation above \nage 16\n16.18% Profes-\nsional or technical \nqualifications \nabove age 16\n27.12% School \neducation up to \nage 18\n31.94% Degree \n(bachelor\u2019s) or \nequivalent\n12.09% Degree \n(master\u2019s) or \nother postgradu-\nate qualification\n1.63% DoctorateEducation\n6.27% No formal \neducation above \nage 16\n10.68% Profes-\nsional or techni-\ncal qualifications \nabove age 16\n25.22% School \neducation up to \nage 18\n38.63% Degree \n(bachelor\u2019s) or \nequivalent\n16.87% Degree \n(master\u2019s) or \nother postgradu-\nate qualification\n2.33% DoctorateEducation\n2.72%  Less than high \nschool degree\n24.73% High school \ngraduate or equivalent\n19.79% Some college, \nbut no degree\n11.54% Associate \ndegree in college, \n2-year\n25.72%  Bachelor\u2019s \ndegree in college, \n4-year\n12.45% Master\u2019s degree\n2.14% Professional \ndegree, JD, MD\n0.91% Doctoral degreeEducation\n14.49% High \nschool or less\n36.10% Some \ncollege\n49.41% Higher \ndegree\nMeasured \nconstructs- MIST-100\n- BSR\n- CMQ\n- COVID-19 com-\npliance\n- CRT \n- DEPICT\n- CV19 fact-check- MIST-20 (incl. MIST-8)\n- AOT\n- Anti-vaccination attitudes\n- COVID-19 misinformation \nbeliefs\n-CRT \n- Numeracy\n- Political ideology\n- Trust (in scientists, journal-\nists, politicians, the govern-\nment)- MIST-20 (incl. MIST-8)\n- BSR\n- BFI2-S\n- CMQ\n- EDO\n- DEPICT SF\n- Go Viral!\n- MFQ20\n- SD4\n- SDO\n- SINS\n- SISES\n- SIRIS\n- SSPC\n- Trust (in medical personnel, scien-\ntists, politicians, journalists, the \ngovernment, scientific knowledge, \ncivil servants, mainstream media)- MIST-20 (incl. \nMIST-8)\n- Numeracy\n- Political ideology\n- Trust (in medical \npersonnel, scien-\ntists, politicians, \njournalists, the \ngovernment, sci-\nentific knowledge, \ncivil servants, \nmainstream \nmedia)- MIST-20 (incl. \nMIST-8)\n- Numeracy\n- Political ideology\n- Trust (in medical \npersonnel, scien-\ntists, politicians, \njournalists, the \ngovernment, sci-\nentific knowledge, \ncivil servants, \nmainstream \nmedia)- MIST-16 - MIST-8\n- BN\nAOT = Actively Open-minded Thinking (Baron, 2019); BFI-2-S = Big-Five Inventory 2 Short-Form (Soto & John, 2017); BN = Bad News Game (Roozenbeek & van der Linden, 2019); BSR = \nBullshit Receptivity scale (Pennycook et\u00a0al., 2015); CMQ = Conspiracy Mentality Questionnaire (Bruder et\u00a0al., 2013); CRT = Cognitive Reflection Test (Frederick, 2005); DEPICT = Discrediting-\nEmotion-Polarization-Impersonation-Conspiracy-Trolling deceptive headlines inventory (Maertens et\u00a0al., 2021); DEPICT SF = DEPICT Balanced Short Form (Maertens et\u00a0al., 2021); EDO = Ecological \nDominance Orientation (Uenal et\u00a0al., 2022); CV19 fact-check = COVID-19 fact-check task (Pennycook, McPhetres, et\u00a0al., 2020); Go Viral! = Go Viral! Balanced Item Set (Basol et\u00a0al., 2021); MFQ20 \n= Moral Foundations Questionnaire 20-Item Short Form (Graham et\u00a0al., 2011 ); Numeracy = combination of Schwartz Numeracy Test (Schwartz et\u00a0al., 1997 ) and Berlin Numeracy Test (Cokely et\u00a0al., \n2012), SD4 = Short Dark Tetrad (Paulhus et\u00a0al., 2020); SDO = Social Dominance Orientation (Ho et\u00a0al., 2015); SINS = the Single-Item Narcissism Scale (Konrath et\u00a0al., 2014); SISES = Single-Item \nSelf-Esteem Scale (Robins et\u00a0al., 2001) SIRIS = Single-Item Religious Identification Scale (Norenzayan & Hansen, 2006); SSPC = Short Scale of Political Cynicism (Aichholzer & Kritzinger, 2016)\n1869 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nFig. 2  Development protocol of the \nMisinformation Susceptibility Test\n1870 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nitems created by experts that are fictional but feature common \nmisinformation techniques. The former approach arguably \nprovides better ecological validity (Pennycook, Binnendyk, \net\u00a0al., 2021), while the latter provides a cleaner and less con-\nfounded measure since it is less influenced by memory and \nidentity effects (van der Linden & Roozenbeek, 2020). Con-\nsidering these two approaches and reflecting on representative \nstimulus sampling (Dhami et\u00a0al., 2004 ), we opted for a novel \napproach that combines the best of both worlds. We employed \nthe generative pretrained transformer 2 (GPT-2)\u2014a neutral-\nnetwork-based artificial intelligence developed by OpenAI \n(Radford et\u00a0al., 2019)\u2014to generate fake news items (cf., G\u00f6tz \net\u00a0al., 2022; Hommel et\u00a0al., 2022). The GPT-2 is one of the \nmost powerful open-source text generation tools currently avail-\nable for free use by researchers. It was trained on eight mil-\nlion text pages, combines 1.5 billion parameters, and is able to \nwrite coherent and credible articles based on just one or a few \nwords of input.5 We did this by asking the GPT-2 to generate a \nlist of fake news items inspired by a smaller set of items. This \nsmaller set contained items from any of five different scales \nthat encompass a wide range of misinformation properties: the \nBelief in Conspiracy Theories Inventory (BCTI; Swami et\u00a0al., \n2010), the Generic Conspiracist Beliefs scale (GCB; Brotherton \net\u00a0al., 2013), specific Conspiracy Beliefs scales (van Prooijen \net\u00a0al., 2015), the Bullshit Receptivity scale (BSR; Pennycook \net\u00a0al., 2015), and the Discrediting-Emotion-Polarization-Imper -\nsonation-Conspiracy-Trolling deceptive headlines inventory \n(DEPICT; Maertens et\u00a0al., 2021; Roozenbeek & van der Lin-\nden, 2019 ). We set out to generate 100 items of good quality, \nbut as this is a new approach, we opted for the generation of at \nleast 300 items. More specifically, we let GPT-2 generate thou-\nsands of fake news headlines, and tossed out any duplicates and \nclearly irrelevant items (see Supplement S1 for a full overview \nof all items generated and those that have been removed).\nReal news For the real news items, we decided to include \nitems that met each of the following three selection cri-\nteria: (1) the news items are actual news items (i.e., they \ncirculated as real news), (2) the news source is the most \nfactually correct (i.e., accurate), and (3) is the least biased \n(i.e., nonpartisan or politically centrist). To do this, we used \nthe Media Bias/Fact Check database (MBFC; https:// media  \nbiasf  actch eck. com/) to select news sources marked as least \nbiased and scoring very high on factual reporting.6 The news sources we chose were Pew Research (https:// www. pewre  \nsearch. org/), Gallup (https:// www. gallup. com/), MapLight \n(https:// mapli ght. org/), Associated Press (https:// www. ap.  \norg/), and World Press Review (http:// world press. org/). We \nalso diversified the selection by including the non-US outlets \nReuters ( https:// www. reute  rs. com/), Africa Check (https://  \nafric  acheck. org/), and JStor Daily ( https://  daily. jstor.  org/). \nAll outlets received the maximum MBFC score at the time \nof item selection.7 A full list of the real news items selected \ncan be found in Supplement S1.\nOverall, this item-generation process resulted in an initial \npool of 413 items. The full list of items we produced and \nmethods through which each of them was obtained can be \nfound in Supplement S1.\nPhase 2: Item condensation To reduce the number of head-\nlines generated in Phase 1, we followed previous scale devel-\nopment research and practices (Carpenter, 2018 ; Haynes \net\u00a0al., 1995; Simms, 2008) and established an expert com-\nmittee with misinformation researchers from four different \ncultural backgrounds: Canada, Germany, the Netherlands, \nand the United States. Each expert conducted an independ-\nent review and classified each of the 413 items generated \nin Phase 1 as either fake news or real news. All items with \na three-fourths expert consensus and matching the correct \nanswer key (i.e., the source veracity category)\u2014a total of \n289 items\u2014were selected for the next phase.8 A full list of \nthe expert judgments and inter-rater agreement can be found \nin Supplement S1.\nPhase 3: Quality control  As a final quality control before \ncontinuing to the psychometrics study, the two-person item \ngeneration committee in combination with an extra third \nexpert\u2014who had not been previously exposed to any of the \nitems\u2014made a final selection of items from Phase 2. Apply -\ning a two-thirds expert consensus as cutoff, we selected 100 \nitems (44 fake news, 56 real news) out of the 289 from the \nprevious stage (i.e., we cut 189 items), thus creating a fairly \nbalanced item pool for empirical probing that hosted five \ntimes as many items as the final scale that we aimed to con-\nstruct\u2014in keeping with conservative guidelines (Boateng \net\u00a0al., 2018; Weiner et\u00a0al., 2012). A full list of the item sets \n6 MBFC is an independent fact-checking platform that rates media \nsources on factual reliability as well as ideological bias. At the time \nof writing, the MBFC database lists over 3700 media outlets and its \nclassifications are frequently used in scientific research (e.g., Bovet & \nMakse, 2019; Cho\u0142oniewski et\u00a0al., 2020; Cinelli et\u00a0al., 2021).7 Three out of six no longer receive the maximum score, and are now \nconsidered to have a center-left bias, and score between mostly fac-\ntual and highly factual reporting: World Press Review (mostly factual, \ncenter-left), MapLight (highly factual, center-left), and JStor Daily \n(highly factual, center-left). This reflects both the dynamic nature of \nnews media and the limits of the classification methodology used.\n8 We used three-fourths as a criterion instead of 100% consensus \nbecause, as experts, we may be biased ourselves, and therefore we \nalso accepted items where only one expert did not agree. If less than \n120 items would remain, then the Phase 1 item generation process \nwould be restarted.5 For a step-by-step guide on how to set up the GPT-2 to use as a \npsychometric item generator, see the tutorial paper by G\u00f6tz et\u00a0 al. \n(2023), as well as the useful blog posts by Woolf (2019), Nasser \n(2020), and Curley (2020).\n1871 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nselected per expert and expert agreement can be found in \nSupplement S1.\nImplementation\nParticipants In line with widespread recommendations to \nassess at least 300 respondents during initial scale implementa-\ntion (Boateng et\u00a0al., 2018; Clark & Watson, 1995, 2019; Com-\nrey & Lee, 1992; Guadagnoli & Velicer, 1988), we recruited a \ncommunity sample of 452 US residents (for a comprehensive \nsample description see Table\u00a0 1). The study was carried out on \nProlific Academic (https:// www. proli fic. co/), an established \ncrowd-working platform which provides competitive data \nquality (Palan & Schitter, 2018; Peer et\u00a0al., 2017). Based on the \nexclusion criteria laid out in the preregistration, we removed \nincomplete cases, participants who took either an unreasonably \nshort or long time to complete the study (less than 8 minutes or \nmore than 2 hours), participants who failed an attention check, \nunderage participants, and participants who did not live in the \nUnited States, retaining 409 cases for data analysis.9 Of these, \n225 participants (i.e., 55.01%) participated in the follow-up \ndata collection eight months later (T2).10\nParticipants received a set remuneration of 1.67 GBP \n(equivalent to US$ 2.32) for participating in the T1 ques-\ntionnaire and 1.10 GBP (equivalent to US$ 1.53) for T2.\nProcedure, measures, transparency, and\u00a0openness\nThe preregistrations for T1 and T2 are available on AsPre-\ndicted https:// aspre dicted. org/ m7vb3. pdf; https:// aspre  \ndicted. org/ js2jz. pdf; any deviations can be found in Sup-\nplement S2). The supplement, raw and clean datasets, and \nall analysis scripts in R can be found in the OSF repository \n(https:// osf. io/ r7phc/).\nParticipants took part in a preregistered online survey. \nAfter providing informed consent, participants had to cat-\negorize the 100 news headlines from Phase 3 (i.e., the items \nthat were retained after the previous three phases) in two \ncategories: Fake/Deceptive and Real/Factual.11 Participants were told that each headline had only one correct answer. See \nthe preregistration or the Qualtrics files on the OSF reposi-\ntory for the exact survey framing (https:// osf. io/ r7phc/).\nAfter completing the 100-item categorization task, par -\nticipants completed the 21 items from the DEPICT inven-\ntory (a misleading social media post reliability judgment \ntask; Maertens et\u00a0al., 2021), a 30-item COVID-19 fact-check \ntask (a classical true/false headline evaluation task; Penny -\ncook, McPhetres, et\u00a0al., 2020), the Bullshit Receptivity scale \n(BSR; Pennycook et\u00a0al., 2015), the Conspiracy Mentality \nQuestionnaire (CMQ; Bruder et\u00a0al., 2013), the Cognitive \nReflection Test (CRT; Frederick, 2005), a COVID-19 com-\npliance index (sample item: \u201cI kept a distance of at least two \nmeters to other people\u201d: 1 \u2013 does not apply at all, 4 \u2013 applies \nvery much), and a demographics questionnaire (see Table\u00a0 1 \nfor an overview). Finally, participants were debriefed. Eight \nmonths later, the participants were recruited again for a \ntest-retest follow-up survey.12 In the follow-up survey, after \nparticipants provided informed consent to participate, the \nfinal 20-item MIST was administered, the same COVID-19 \nfact-check task (Pennycook, McPhetres, et\u00a0al., 2020 ) and \nCMQ (Bruder et\u00a0al., 2013) were repeated, a new COVID-19 \ncompliance index was administered, and finally a full debrief \nwas presented. The complete surveys are available in the \nOSF repository: https:// osf. io/ r7phc/.\nThe full study received institutional review board (IRB) \napproval from the Psychology Research Ethics Committee \nof the University of Cambridge (PRE.2019.108).\nAnalytical strategy 1: Exploratory factor analysis (EFA) \nand\u00a0item response theory (IRT)\nTo extract the final MIST-20 and MIST-8 scales from the \npre-filtered MIST-100 item pool, we followed an item selec-\ntion decision tree, which can be found in Supplement S3. \nSpecifically\u2014after ascertaining the general suitability of \nthe data for such procedures\u2014the following EFA- and IRT-\nbased exclusion criteria were employed: (1) factor loadings \nbelow .40 (Clark & Watson, 2019; Ford et\u00a0al., 1986; Hair \net\u00a0al., 2010 ; Rosellini & Brown, 2021 ); (2) cross-loadings \nabove .30 (Boateng et\u00a0al., 2018; Costello & Osborne, 2005); \n(3) communalities below .4 (Carpenter, 2018; Fabrigar et\u00a0al., \n1999; Worthington & Whittaker, 2006); (4) Cronbach\u2019s \u03b1 \nreliability analysis; (5) differential item functioning (DIF) \nanalysis (Holland & Wainer, 1993; Nguyen et\u00a0al., 2014; \nReise et\u00a0al., 1993); (6) item information function (IIF) \nanalysis. Finally, we sought to establish initial evidence for \nconstruct validity (Cronbach & Meehl, 1955). To do this, we \ninvestigated the associations between the MIST scales and \n11 All headlines can be found in Supplement S1.12 We chose to have a follow-up to be able to measure changes in the \nMIST score over the medium long term. We found a period of eight \nmonths fitting for this purpose.9 We preregistered that we would split the sample in half for explora-\ntory analyses and confirmatory analyses. However, we used the full \nStudy 1 sample for exploratory analyses instead and conducted a new \nstudy with a fresh sample (Study 2) for the confirmatory analyses. \nThis more rigorous and more conservative approach was chosen to \nboost power and increase the quality of the initial item selection.\n10 We looked at the difference in demographics between T1 and T2 \nProlific users. While we found no noteworthy differences in age (MT1 \n= 33.20, MT2 = 35.76) or educational attainment rates, (T1: 38.88% \nwith bachelor\u2019s degree, T2: 41.52% with bachelor\u2019s degree), the per -\ncentage of female participants rose somewhat during the follow-up \n(T1: 55.50% male, T2: 39.72% male).\n1872 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nthe DEPICT deceptive headline recognition task (Maertens \net\u00a0al., 2021) and COVID-19 fact-check (Pennycook et\u00a0al., \n2020; concurrent validity). We further examined additional \npredictive accuracy of the MIST in accounting for variance \nin DEPICT and fact-check scores above and beyond the \nCMQ (Bruder et\u00a0al., 2013), BSR (Pennycook et\u00a0al., 2015), \nand CRT (Frederick, 2005; incremental validity).\nAnalytical strategy 2: Exploratory graph analysis (EGA)\nIn this section we explore an alternative method of scale \ndevelopment, based on the new field of exploratory graph \nanalysis (Golino & Epskamp, 2017), rooted in network \nmethods. Network methods in psychology gained momen-\ntum with the publication of the mutualism model of intel-\nligence (Van Der Maas et\u00a0al., 2006) and network perspec-\ntive on psychopathology (Borsboom, 2008; Borsboom et\u00a0al., \n2011 ; Cramer et\u00a0al., 2010 ), giving rise to a new subfield \nof quantitative psychology called network psychometrics  \n(Epskamp et\u00a0al., 2017 ; Epskamp et\u00a0al., 2018 ). Network \nmodels are used to estimate the relationship between mul-\ntiple variables\u2014typically using the Gaussian graphical \nmodel (GGM; Lauritzen, 1996), where nodes (e.g., test \nitems) are connected by edges (or links) that indicate the \nstrength of the association between the variables (Epskamp \n& Fried, 2018 ), forming a system of mutually reinforcing \nelements (Christensen et\u00a0al., 2020b; Cramer, 2012). Network \nand latent variable models have been shown to be closely \nrelated, and can produce model parameters that are consist-\nent with one another (Boker, 2018 ; Christensen & Golino, \n2021c; Epskamp et\u00a0al., 2017; Golino et\u00a0al., 2021; Golino \n& Epskamp, 2017; Marsman et\u00a0al., 2018). These statistical \nsimilarities can be used as a way to explore the dimension-\nality structure of measurement instruments in a new frame-\nwork termed exploratory graph analysis (Christensen et\u00a0al., \n2019; Golino & Demetriou, 2017; Golino & Epskamp, 2017; \nGolino et\u00a0al., 2020a,\u00a0 2020b).\nIn network psychometrics (Christensen et\u00a0al., 2019; \nEpskamp et\u00a0al., 2018; Epskamp et\u00a0al., 2017; Golino & \nDemetriou, 2017; Golino & Epskamp, 2017; Golino et\u00a0al., \n2020a,\u00a0 2020b), networks are typically estimated using the \nGaussian graphical model (Lauritzen, 1996) using the EBIC-\nglasso  approach (Epskamp & Fried, 2018). The EBICglasso \napproach operates by minimizing a penalized log-likelihood \nfunction and selecting the best model fit (i.e., the optimum \nlevel of sparsity in a network) using the extended Bayes-\nian information criterion (EBIC; Chen & Chen, 2008). As \nGolino et\u00a0al. (2022) argue, the use of weighted network \nmodels in psychology opened the doors for network science \nmethods developed in other areas of science to psychologi-\ncal problems such as dimensionality (e.g., factor analysis).\nExploratory graph analysis was originally proposed \nby Golino and Epskamp et\u00a0al. (2017 ), which showed that the GGM model combined with a clustering algorithm for \nweighted networks (Walktrap; Pons & Latapy, 2005) could \naccurately recover the number of simulated factors, present-\ning higher accuracy than traditional factor analytic-based \nmethods. Later, Golino, Shi, et\u00a0al. (2020b) compared EGA \nwith different types of factor analytic methods (including \ntwo types of parallel analysis), finding that EGA achieves \nthe highest overall accuracy (87.91%) in estimating the num-\nber of simulated factors, followed by the traditional parallel \nanalysis with principal components of Horn (1965; 83.01%), \nand parallel analysis using principal axis factoring proposed \nby Humphreys and Ilgen (1969; 81.88%).\nGolino et\u00a0al. (2022) summarized the advantages of the \nEGA framework over more traditional methods (Golino, \nShi, et\u00a0al., 2020b): (1) unlike exploratory factor analysis \n(EFA) methods, EGA does not require a rotation method to \ninterpret the estimated first-order factors (although rotations \nare rarely discussed in the validation literature, they have \nsignificant consequences for validation, e.g., estimation of \nfactor loadings; Sass & Schmitt, 2010); (2) EGA automati-\ncally places items into factors without the researcher\u2019s direc-\ntion, which contrasts with exploratory factor analysis, where \nresearchers must decipher a factor loading matrix (such a \nplacement opens the door for dimension and item stabil-\nity methods, which is presented next); and (3) the network \nrepresentation depicts how items relate within and between \ndimensions.\nOver the past couple of years, the EGA framework has \nexpanded into several important areas of psychometrics. \nChristensen and Christensen and Golino (2021c) devel-\noped a new metric termed network loadings computed by \nstandardizing node strength\u2014the sum of the edges a node is \nconnected to\u2014split between dimensions identified by EGA. \nChristensen and Christensen and Golino (2021c) showed \nin their simulation study that network loadings are akin to \nfactor loadings, but with different reference values. Network \nloadings of .15, .25, and .35 are equivalent to low (.40), \nmoderate (.55), and high (.70) network loadings, respec-\ntively (Christensen & Golino, 2021c). The development of \nnetwork loadings opened new lines of research, such as the \ndevelopment of metric invariance using EGA and permuta-\ntion tests in a network perspective (Jamison et\u00a0al., 2022), \nand determining whether data are generated from a factor or \nnetwork model (Christensen & Golino, 2021b).\nBased on the automated item placement of EGA, Chris-\ntensen and Golino (2021a) developed a bootstrap approach \nto investigate the stability of items and dimensions estimated \nby EGA, termed bootstrap exploratory graph analysis, and \nproposed two new metrics of psychometric quality: item sta-\nbility  and structural consistency . Item stability indicates how \noften an item replicates in their designated EGA dimension, \nwith values lower than .75 (i.e., that are estimated in their \noriginal dimensions in 75% of the bootstrapped samples) \n1873 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nindicating problematic (or unstable) items. Structural con-\nsistency, by its turn, indicates how often an EGA dimension \nexactly replicates and can be used to verify configural (or \nstructural) invariance and determine poor-functioning items \n(Golino et\u00a0al., 2022). A complementary approach, called \nunique variable analysis, was developed to identify redun-\ndant items and can be used to identify the reason why some \nitems function poorly (Christensen, Garrido, & Golino, \n2020a).\nThe fit of a dimensionality structure estimated using \nEGA to the data can be verified using an innovative fit index \ntermed total entropy fit index ( TEFI; Golino, Moulder, et\u00a0al., \n2020a), developed as an alternative to traditional fit meas-\nures used in factor analysis and structural equation modeling \n(SEM). In a comprehensive simulation study, the TEFI dem-\nonstrated higher accuracy in correctly identifying the num-\nber of simulated factors than the comparative fit index (CFI), \nthe root mean square error of approximation (RMSEA), \nand other indices used in SEM (Golino, Moulder, et\u00a0al., \n2020a). The TEFI is based on the Von Neumann entropy \n(Von Neumann, 1927 )\u2014a measure developed to quantify \nboth the amount of disorder in a system and the entangle-\nment between two subsystems (Preskill, 2018). The TEFI  \nindex is a relative measure of fit that can be used to compare \ntwo or more dimensionality structures. The dimensionality \nstructure with the lowest TEFI value indicates the best fit \nfor the data.\nAnother recent development within the EGA framework \nis the hierarchical EGA (hierEGA) technique by Jimenez \net\u00a0al. (2022). In their work, Jimenez et\u00a0al. (2022) proposed \nan alternative variation to a popular clustering algorithm \ncalled Louvain (Blondel et\u00a0al., 2008) to detect lower- and \nhigher-order factors in data, and showed that this new tech-\nnique is more effective than traditional factor analytic tech-\nniques to estimate the structure of first- and second-order \nfactors in generalized bifactor structures.\nAll the EGA-based techniques/metrics mentioned above \nuse the free and open-source R package EGAnet (Golino \n& Christensen, 2019), which has become one of the main \nsoftware programs in network psychometrics. In the cur -\nrent paper, version 1.2.4 of the EGAnet  package (Golino \n& Christensen, 2019) was used, and several strategies \nwere implemented. The first strategy aimed at estimating \nthe dimensionality structure of the 100 MIST items. Then, \nredundant items were identified using unique variable analy -\nsis (Christensen et\u00a0al., 2020a), and for every group or pair of \nredundant items the one with the higher ratio of main net-\nwork loadings to cross-loadings was kept in the analysis. The \nstability of the items and the structural consistency of the \ndimensions were obtained via bootstrap exploratory graph \nanalysis (Christensen & Golino, 2021a) with 500 iterations \n(using parametric bootstrapping), and items with stability \nlower than 75% and network loadings lower than .15 were removed from subsequent steps. Once a subset of stable \nitems with at least low to moderate network loadings were \nfound, a subset of the best items per dimension (i.e., with \nmoderate to high network loadings\u2014with a network load-\ning of at least .23) were identified, and further item stability \nand structural consistency metrics were computed until all \nitems were highly stable (with item stability greater than \n90%). The metric invariance of the final pool of best items \nper dimension (moderate to high network loadings and high \nitem stability) was investigated using the EGA permutation \ntest developed by Jamison et\u00a0al. (2022), having as reference \ngroups sex, age (above or below the median birth year), and \neducation (above or below the median level of formal edu-\ncation received). The fit of the EGA-estimated dimensions \nto the data was computed using the total entropy fit index \n(Golino, Moulder, et\u00a0al., 2020a) and compared to the two-\nfactor structure of real and fake news items identified using \nEFA. CFI and RMSEA  computed after fitting a confirmatory \nfactor model to the EGA-estimated dimensions were also \nobtained, and compared to the CFI and RMSEA of the two-\nfactor structure. Additionally, the Satorra (Satorra, 2000) \nscaled difference test was implemented to verify the struc -\nture with the best fit to the data.\nResults\nEFA/IRT results\nItem selection Using parallel analysis with the psych pack -\nage (Revelle, 2021), we aimed to select a parsimonious fac-\ntor structure, with each factor reflecting eigenvalues above \nthe 95th percentile of corresponding eigenvalues from 500 \nsimulated random datasets.13 Parallel analysis (with 500 iter -\nations) suggested a total of six factors, but only five factors \n(eigenvalues:  F1 = 10.89,  F2 = 7.82,  F3 = 1.89,  F4 = 1.42, \n F5 = 1.23,  F6 = 0.98) matched our criteria and were above \nthe 95th percentile of corresponding eigenvalues from the \n500 simulated random datasets (eigenvalue 95th percentile = \n0.99).14 Two factors explained most of the variance, which is \nin line with our theoretical model of two main factors (fake \nnews detection and real news detection). An EFA using the \ntetrachoric correlation matrix with unweighted least squares  \n13 The factorability of the data was tested via the Kaiser\u2013Meyer\u2013\nOlkin (KMO) measure of sampling adequacy and Bartlett\u2019s test of \nsphericity using R and the EFAtools package (Steiner & Grieder, \n2020). Both tests indicated excellent data suitability (Bartlett\u2019s \u03c72 \n= 12,896.84, df = 4950, p < .001; KMO = .831) according to estab-\nlished guidelines (Carpenter, 2018; Tabachnick & Fidell, 2007).\n14 These five factors are in line with the criteria set out in the pre-\nregistration, as they have both (i) an eigenvalue > 1 and (ii) an eigen-\nvalue larger than the simulated value (above the line of randomly \ngenerated data).\n1874 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\n(ULS) estimation without rotation using the EFAtools pack -\nage (Steiner & Grieder, 2020) indicated that for both the \ntwo-factor structure and the five-factor structure, the first \ntwo factors were specifically linked to the real news items \nand the fake news items, respectively, while the other three \nfactors did not show a pattern easy to interpret and in general \nshowed low factor loadings (< .30).15 See Supplement S4 \nfor a pattern matrix.\nAs we set out to create a measurement instrument for \ntwo distinct abilities, real news detection and fake news \ndetection, we continued with a two-factor EFA, employ -\ning principal axis factoring and varimax rotation using \nthe psych package (Revelle, 2021).16 Theoretically we \nwould expect a balancing out of positive and negative \ncorrelations between the two factors: positive because of \nthe underlying veracity discernment ability, and negative \nbecause of the response biases. In line with this, we chose \nan orthogonal rotation instead of an oblique rotation to \nseparate out fake news detection and real news detection \nas cleanly as possible.\nThree iterations were needed to remove all items with \na factor loading under .40 (43 items were removed). After \nthis pruning, no items showed cross-loadings larger than \n.30. Communality analysis using the three-parameter logistic \nmodel function in the mirt package (Chalmers, 2012) with \n50% guessing chance (c  = .50) indicated two items with \ncommunality lower than .40 after one iteration. These items \nwere removed. No further iterations yielded any additional \nremovals. A final list of the communalities can be found in \nSupplement S5. Cronbach\u2019s \u03b1 reliability analysis with the \npsych package was used to remove all items that had nega-\ntive effects (\u2206\u03b1 > .001) on the overall reliability of the test \n(Revelle, 2021). No items had to be removed based on this \nanalysis.17 Differential item functioning using the mirt pack -\nage was used to explore whether differences in gender or \nideology would alter the functioning of the items (Chalmers, \n2012). None of the items showed differential functioning for \ngender or ideology.Finally, using the three-parameter logistic model \nIRT functions in the mirt package (Chalmers, 2012), we \nselected the 20 best items (10 fake, 10 real) and the 8 best \nitems (4 fake, 4 real), resulting in the MIST-20 and the \nMIST-8, respectively. These items were selected based on \ntheir discrimination and difficulty values, where we aimed \nto select a diverse set of items that have high discrimina-\ntion (a  \u2265 2.00 for the MIST-20, a  \u2265 3.00 for the MIST-8) \nyet have a wide range of difficulties (b  = [\u22120.50, 0.50], for \neach ability), while keeping the guessing parameter at 50% \nchance (c  =.50). We also took into account the topics to \nensure both that we covered a wide range of news areas \nand that there was no repetition of content (Flake et\u00a0al., \n2017 ). A list of the IRT coefficients and plots can be found \nin Supplement S1 and Supplement S6, respectively. See \nFig.\u00a0 3 for a MIST-20 item trace line plot, and Fig.\u00a0 4 for \na multidimensional plot of the MIST-20 IRT model pre-\ndictions. The final items that make up the MIST-20 and \nMIST-8 are shown in Table\u00a0 2.18 An overview of different \ncandidate sets and how they performed, as well as the full \nanalysis scripts and the supplement, can be found in the \nOSF repository: https:// osf. io/ r7phc/.\nReliability Inter-item correlations show good internal con-\nsistency for both the MIST-8 (IICmin = .20, IICmax = .27) \nand the MIST-20 (IICmin = .22, IICmax = .29). Item-total \ncorrelations also show good reliability for both the MIST-8 \n(ITCmin = .44, ITCmax = .53) and the MIST-20 (ITCmin = .31, \nITCmax = .54).\nLooking further into the MIST-20, we analyze the reli-\nability of veracity discernment (V ; M = 15.71, SD = 3.35), \nreal news detection (r ; M = 7.62, SD = 2.43), and fake news \ndetection (f ; M = 8.09, SD = 2.10). In line with the guidelines \nby Revelle and Condon (2019), we calculate a two-factor \nMcDonald\u2019s \u03c9 (McDonald, 1999) as a measure of internal \nconsistency using the psych package (Revelle, 2021), and \nfind good reliability for the general scale and the two facet \nscales (\u03c9g = 0.79, \u03c9F1 = 0.78, \u03c9F2 = 0.75). Also using the \npsych package (Revelle, 2021), we calculate the variance \ndecomposition metrics as a measure of stability, finding that \nF1 explains 14% of the total variance and F2 explains 12% \nof the total variance. Of all variance explained, 53% comes \nfrom F1 (r) and 47% comes from F2 (f ), demonstrating a \ngood balance between the two factors.15 When using EFA with a promax rotation, there is some evidence \nfor two factors for the fake news items and two factors for the real \nnews items, bringing up a total of four factors, but its pattern and \nmeaning is unclear. This alternative structure will be further explored \nin the EGA section.\n16 While we chose to adhere to the more traditional methods for \nestimating and rotating factors in EFA, we acknowledge that recent \nresearch provides arguments for the use of ML estimation and oblique \nrotations (Goretzko et\u00a0 al., 2021), and specifically ULS estimation \n(using the tetrachoric correlation matrix) for dichotomous variables \n(see Shi et\u00a0al., 2018). We provide an alternative, modern approach to \nitem selection based on EGA in the section below.\n17 We note that some researchers argue that the focus on reliability \ncan reduce the content validity of the scale, as there may be relevant \nitems with weaker loadings (e.g., Flake et\u00a0al., 2017). However, as no \nitems were removed, this is not a concern for this study.18 As can be glimpsed from the final set, the misinformation items \ncontain certain words and topics that are more often linked to manip-\nulative content, such as \u201ccontrol/manipulate/cause,\u201d \u201cvaccine/virus,\u201d \nand \u201cgovernment.\u201d These topics were already present in the sample \nitems given to the GPT-2\u2014which led to more of these topics being \npresent in the original fake news item pool than in the real news \nitem pool. This thus represents a feature that was present since the \nfirst phase of the development and is not just a consequence of a later \nselection by the experts or elimination based on factor loadings.\n1875 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nFinally, test\u2013retest reliability analysis indicates that MIST \nscores are moderately positively correlated over a period of \neight to nine months (rT1,T2 = 0.58).19\nValidity To assess initial validity, we examined the asso-\nciations between the MIST scales and two scales that have \nbeen used regularly in previous misinformation research\u2014\nthe COVID-19 fact-check by Pennycook, McPhetres, et\u00a0al. \n(2020) and the DEPICT task by Maertens et\u00a0al. (2021)\u2014\nexpecting high correlations (r  > .50; concurrent valid-\nity) and additional variance explained as compared to the \nexisting CMQ, BSR, and CRT scales (incremental valid-\nity; Clark & Watson, 2019 ; Meehl, 1978 ). As can be seen \nin Table\u00a0 3, we found that the MIST-8 displays a medium \nto high correlation with the fact-check (rfact-check,MIST-8  = .49) \nand DEPICT task (rDEPICT,MIST-8  = .45), while the MIST-\n20 shows a large positive correlation with both the fact-\ncheck (rfact-check,MIST-20  = .58) and the DEPICT task \n(rDEPICT,MIST-20  = .50). Using a linear model, we found that the \nexplained variance in the fact-check indicates that the MIST-\n20 can explain 33% (adjusted R2) of variance by itself. The \nCMQ, BSR, and CRT combined account for 19%. Adding the \nMIST-20 on top provides an incremental 18% of explained \nvariance (adjusted R2 = 0.37). The MIST-20 is the strongest \npredictor in the combined model (t (404) = 10.82, p < .001, \n\u03b2 = 0.49, 95% CI [0.40, 0.57]). For the DEPICT task we \nfound that the CMQ, BSR, and CRT combined explain 12% of variance in deceptive headline recognition and 26% when \nthe MIST-20 is added (\u2206R2 = 0.14), while the MIST-20 alone \nexplains 25%. For the DEPICT task we found the MIST-20 \nto be the only significant predictor in the combined model \n(t(404) = 8.94, p < .001, \u03b2 = 0.43, 95% CI [0.34, 0.53]).20\nEGA results\nIn this section we re-analyze the pool of 100 MIST items using \nEGA. EGA estimated four dimensions (see Fig.\u00a0 5), which can \nbe identified as two dimensions of real news headlines and two \nof fake news headlines. Dimension 1 (red nodes on Fig.\u00a0 5) is \na combination of US and international real news headlines, \nwith items such as MIST 96 ( US Hispanic Population Reached \nNew High in 2018, But Growth Has Slowed), MIST 92 ( Taiwan \nSeeks to Join Fight Against Global Warming), and MIST 60  \n(Hyatt Will Remove Small Bottles from Hotel Bathrooms by \n2021). Dimension 2 (blue nodes on Fig.\u00a0 5) has fake news items \nabout science, such as item MIST 8 ( Climate Scientists\u2019 Work \nIs \u201cUnreliable\u201d, a \u201cDeceptive Method of Communication\u201d), \nand false statements against people with a liberal world view, \nsuch as items MIST 16 ( Left-Wingers Are More Likely to Lie \nto Get a Good Grade ) and MIST 20 ( New Study: Left-Wingers \nAre More Likely to Lie to Get a Higher Salary). The third \ndimension (green nodes on Fig.\u00a0 5) has real news items related \nto politically charged topics in the US, such as items MIST 70 \n(Majority in US Still Want Abortion Legal, with Limits), MIST \n74 (Most Americans Say It\u2019s OK for Professional Athletes \n19 It must be noted that at T2, participants only completed the \n20-item MIST, while at T1 participants had to categorize 100 items, \nwith slightly different question and response framings (see full Qual-\ntrics layouts and question framings in the OSF repository: https:// osf. \nio/ r7phc/). We expect the actual test\u2013retest correlation to be higher.20 Full model output for the MIST-8 and MIST-20 linear models can \nbe found in Supplement S8. Full analysis scripts can be found in the \nOSF repository: https:// osf. io/ r7phc/.\nFig. 3  Item trace lines for MIST-20 items, for the fake news items in Panel A and real news items in Panel B. The items in the legend are ordered \naccording to their difficulty level\n1876 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nto Speak out Publicly about Politics), and MIST 94 ( United \nNations Gets Mostly Positive Marks from People Around the \nWorld). Dimension 4 (orange nodes on Fig.\u00a0 5) has fake news \nitems related to general conspiracy beliefs, such as item MIST \n1 (A Small Group of People Control the World Economy by \nManipulating the Price of Gold and Oil),  and conspiracies \nrelated to the government, such as items MIST 31 ( The Gov -\nernment Is Actively Destroying Evidence Related to the JFK \nAssassination) and MIST 32 ( The Government Is Conducting \na Massive Cover-Up of Their Involvement in 9/11).\nThe unique variable analysis technique (Christensen \net\u00a0al., 2020a) identified two redundant items: MIST 43 ( UN: \nNew Report Shows Shark Fin Soup as \u2018the Most Important \nSource of Protein\u2019 for World\u2019s Poor) and MIST 17 ( New \nData Show Shark Fins Are the \u2018Most Important Source of \nProtein\u2019 for the World\u2019s Poor ). The ratio of network loadings \n(main/cross-loadings) for these items (8.47 and 6.9, respec-\ntively) suggested that item MIST 43 should be kept in the \nsubsequent analyses. A bootstrap exploratory graph analysis \nwith 500 iterations (parametric bootstrapping) identified four \nmedian dimensions (95% CI: 2.11, 5.89) but with very low structural consistency for each dimension (0.09, 0.14, 0.07, \nand 0.43 for dimensions 1, 2, 3, and 4, respectively). The \nitem stability metric (Christensen & Golino, 2021a) varied \nfrom 23% to 98%, with 40% of items presenting inadequate \nor moderate stability (i.e., lower than 75%, see Fig.\u00a0 6).\nRemoving the items with item stability lower than 75% \nand repeating the parametric bootstrap EGA technique with \n500 iterations showed that the stability improved consider -\nably, leading to structural consistency between 0.61 (dimen-\nsion 2) and 0.96 (dimension 4), and mean item stability of \n93%. From the 59 items selected in the steps above, a subset \nwith network loadings equal to or higher than .155 were \nselected from each dimension estimated via EGA, resulting \nin 34 items. A parametric bootstrap EGA with 500 itera-\ntions followed by item stability analysis was implemented \nonce again, and items with stability lower than 75% were \nremoved, resulting in 32 items.\nThe final selection of items was implemented using the \nfollowing strategy. Out of the 32 items selected in the previ-\nous steps, only those with relatively high network loadings \n(\u2265 .23 or \u2265 . 235) were used in the subsequent bootEGA and \nFig. 4  Multidimensional IRT plot representing the final MIST-20 test\n1877 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nitem stability analysis, which identified 16 highly stable \nitems (see Fig.\u00a0 7). Exploratory graph analysis identified the \nsame four dimensions described in the first paragraph of this \nsection, but now they presented very high structural consist-\nency ranging from .982 to 1, and very high item stability \n(ranging from 98 to 100%). The network loadings of the final \nMIST-16 EGA items are presented in Table\u00a0 4.\nA metric invariance analysis for EGA using permutation \ntests (Jamison et\u00a0al., 2022) was conducted using sex, mean age, \nand mean education as grouping variables. None of the items \nexhibited a significant ( p < .05) difference in network loadings \nacross the tested groups, suggesting that the 16 items selected \nusing the EGA framework work similarly irrespective of sex, \nage, and education (see Supplement S19 for an overview).\nThe fit of the four-dimensional structure estimated via \nEGA was compared to the fit of the two-factor structure of real \nand fake news items using the total entropy fit index (Golino, \nMoulder, et\u00a0al., 2020a), and two traditional factor-analytic \nfit measures (CFI and RMSEA). To compute the traditional \nfactor-analytic fit indices, a confirmatory factor analysis was \nimplemented using the WLSMV estimator for each structure \n(see Fig.\u00a0 8). Table\u00a0 5 shows that the EGA four-factor struc-\nture presented the lowest TEFI and RMSEA, and the highest CFI, suggesting that the four-factor first-order dimensions \nestimated via EGA fit the data better than the theoretical two-\nfactor structure, although the two-factor structure also has an \nacceptable fit. The Satorra (Satorra, 2000; Table\u00a0 6) scaled \ndifference test also showed that the EGA four-factor structure \nis preferable to the theoretical two first-order factor structure.\nTwo different traditions were used to select a subset of \nitems, one relying on traditional techniques (EFA and IRT) \nand another relying on modern network psychometric methods \n(EGA). Looking at the item stability and structural consistency \nof the dimensions between the two, we found that the MIST-\n16 EGA items are stable and consistent, indicating that the \nfour dimensions estimated using exploratory graph analysis are \nrobust and likely to be identified in independent samples. The \n20 items selected using EFA/IRT were less robust in terms of \nstability (see Supplement S19: EGA Metric Invariance Tests). \nThe low stability for some of the items of MIST-20 might \nindicate that there are a higher or lower number of dimensions \nunderlying the data. The parametric bootstrap EGA analysis \n(with 500 iterations) of the MIST-20 items indicates that \ntwo dimensions are estimated in 21.0% of the bootstrapped \nsamples, three dimensions in 68.2%, and four dimensions in \n10.0%. The item stability of the most common structure (three Table 2  Final items selected for MIST-20 and MIST-8\nItems in bold are items included in the short version of the test (MIST-8). a = discrimination parameter. b = difficulty parameterItem no. a b Content\nFake news\nMIST_14 3.50 0.53 Government Officials Have Manipulated Stock Prices to Hide Scandals\nMIST_28 2.69 0.06 The Corporate Media Is Controlled by the Military-industrial Complex: The Major Oil Compa-\nnies Own the Media and Control Their Agenda\nMIST_20 3.26 \u22120.20 New Study: Left-Wingers Are More Likely to Lie to Get a Higher Salary\nMIST_34 3.42 \u22120.25 The Government Is Manipulating the Public's Perception of Genetic Engineering in Order to \nMake People More Accepting of Such Techniques\nMIST_15 2.34 \u22120.40 Left-Wing Extremism Causes 'More Damage' to World Than Terrorism, Says UN Report\nMIST_7 2.57 \u22120.45 Certain Vaccines Are Loaded with Dangerous Chemicals and Toxins\nMIST_19 2.00 \u22120.55 New Study: Clear Relationship Between Eye Color and Intelligence\nMIST_33 5.60 \u22120.76 The Government Is Knowingly Spreading Disease Through the Airwaves and Food Supply\nMIST_10 2.64 \u22121.02 Ebola Virus 'Caused by US Nuclear Weapons Testing', New Study Says\nMIST_13 2.86 \u22121.30 Government Officials Have Illegally Manipulated the Weather to Cause Devastating Storms\nReal news\nMIST_50 3.12 0.38 Attitudes Toward EU Are Largely Positive, Both Within Europe and Outside It\nMIST_82 2.22 0.31 One-in-Three Worldwide Lack Confidence in NGOs\nMIST_87 2.25 0.14 Reflecting a Demographic Shift, 109 US Counties Have Become Majority Nonwhite Since 2000\nMIST_65 2.36 \u22120.03 International Relations Experts and US Public Agree: America Is Less Respected Globally\nMIST_60 3.39 \u22120.09 Hyatt Will Remove Small Bottles from Hotel Bathrooms by 2021\nMIST_73 2.43 \u22120.14 Morocco\u2019s King Appoints Committee Chief to Fight Poverty and Inequality\nMIST_88 2.79 \u22120.31 Republicans Divided in Views of Trump\u2019s Conduct, Democrats Are Broadly Critical\nMIST_53 2.12 \u22120.37 Democrats More Supportive than Republicans of Federal Spending for Scientific Research\nMIST_58 8.59 \u22120.60 Global Warming Age Gap: Younger Americans Most Worried\nMIST_99 2.26 \u22120.83 US Support for Legal Marijuana Steady in Past Year\n1878 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\ndimensions, see Supplement S20) reveals that the items are \nrelatively stable, but still not as stable as the MIST-16 EGA \nitems. A comparison of the three-dimensional structure esti-\nmated using EGA in the MIST-20 items with the theoretical \ntwo-factor structure (see Table\u00a0 7) shows that the three-factor \nsolution performs slightly better, since it presents lower TEFI \nand RMSEA, and higher CFI.\nDiscussion\nIn Study 1, we generated 413 news items using GPT-2 auto-\nmated item generation for fake news, and trusted sources for real \nnews. Through two independent expert committees, we reduced \nthe item pool to 100 items (44 fake and 56 real). We then com-\nbined item response theory with factor analysis to reduce the \nitem set to the 20 best items for the MIST-20 and the 8 best \nitems for the MIST-8. We found that the final items demonstrate \ngood reliability. In an initial test of validity, we found strong \nconcurrent validity for both the MIST-8 and the MIST-20 as \nevidenced by their strong associations with the COVID-19 fact-\ncheck (a headline evaluation task) and the DEPICT deceptive \nheadline recognition task (a social media post reliability judg-\nment task). Moreover, we found that both the MIST-20 and the \nMIST-8 outperformed the combined model of the CMQ, BSR, \nand CRT, when explaining variance in fact-check and DEPICT \nscores, evidencing incremental validity. This study provides the \nfirst indication that both the MIST-20 and MIST-8 are psycho-\nmetrically sound, and can explain and test misinformation sus-\nceptibility above and beyond the existing scales. Finally, we also presented an alternative approach to item selection, namely one \nbased on EGA that uses network psychometrics to identify the \nbest partition of the multidimensional space, combined with a \nbootstrap analysis of item and dimensional stability (structural \nconsistency), to identify a set of highly stable items with moder -\nate or high network loadings, leading to the selection of 16 items \nmeasuring four dimensions of misinformation susceptibility.\nStudy 2: Validation\u2014Confirmatory analyses, \nnomological net, and\u00a0national norms\nStudy 2 sought to consolidate and extensively test the psycho-\nmetric soundness of the newly developed MIST-20, MIST-16, \nand MIST-8 scales. Across five large samples with nationally \nrepresentative quotas from two countries (US, UK) and three \ndifferent recruitment platforms (CloudResearch, Prolific, and \nRespondi) we pursued three goals. First, we used structural \nequation modeling and reliability analyses to probe the struc-\ntural stability, model fit, and internal consistency of the MIST \nacross different empirical settings. Second, we built an exten-\nsive nomological network and examined both the correlation \npatterns and the predictive power of the MIST to demonstrate \nconvergent, discriminant, and incremental validity. Third, we \ncapitalized on the representativeness of our samples to derive \nnational norms for the general population (UK, US) and spe-\ncific demographic (UK, US) and geographical subgroups (US).\nMethod: MIST\u201120/MIST\u20118\nParticipants\nAs part of our EFA/IRT validation study, we collected data from \nfour samples with nationally representative quota ( Ntotal = 8310, \nNclean = 6461).21 Sample 2A was a US sample (N  = 3692) with \ninterlocking age and gender quota (i.e., each category contains a \nrepresentative relative proportion of the other category) accessed \nthrough Respondi, an International Organization for Standardi-\nzation (ISO)-certified international organization for market and \nsocial science research (for previous applications see, e.g., D\u00fcr \n& Schlipphak, 2021; Heinsohn et\u00a0al., 2019; Roozenbeek, Free-\nman, et\u00a0al., 2021a). After excluding incomplete cases and par -\nticipants outside of the quota, 3479 participants were considered \nfor analysis. Sample 2B was a US sample with nationally rep-\nresentative age, ethnicity, and gender quota (N  = 856) recruited \nthrough CloudResearch (formerly TurkPrime), an online \nresearch platform similar to MTurk but with additional validity \nchecks and more intense participant pool controls (Buhrmester \net\u00a0al., 2018; Litman et\u00a0al., 2017). After excluding all participants \n21 Surveys 2A, 2C, and 2D were designed as part of a separate \nresearch project which featured the MIST-20 as an add-on. Survey 2B \nwas designed specifically for this project.Table 3  Incremental validity of MIST-8 and MIST-20 with existing \nmeasures\n* p < .05, ** p < .01, *** p < .001r Adjusted R2\u2206R2\nCV19 fact-check ~\n\u00a0 MIST-8 .49 .24\n\u00a0 MIST-20 .58 .33\n-\n\u00a0 CMQ + BSR + CRT .19\n\u00a0 CMQ + BSR + CRT + MIST-8 .30 .11***\n-\n\u00a0 CMQ + BSR + CRT .19\n\u00a0 CMQ + BSR + CRT + MIST-20 .37 .18***\nDEPICT ~\n\u00a0 MIST-8 .45 .20\n\u00a0 MIST-20 .50 .25\n-\n\u00a0 CMQ + BSR + CRT .12\n\u00a0 CMQ + BSR + CRT + MIST-8 .22 .11***\n-\n\u00a0 CMQ + BSR + CRT .12\n\u00a0 CMQ + BSR + CRT + MIST-20 .26 .14***\n1879 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nwho failed an attention check, were underage, did not reside in \nthe United States, did not complete the entire study, completed \nthe study in \u2264 10 minutes, or were a second-time participant, \n510 participants remained.22 Sample 2C was a UK sample \n(N = 2517) based on nationally representative interlocking age \nand gender quota recruited through Respondi. After excluding \nincomplete cases and participants outside of our quota criteria, \n1227 participants were retained. Lastly, sample 2D was a UK \nsample (N  = 1396) with nationally representative age and gender \nquota recruited through Prolific. Excluding all entries that fell \noutside of our quota criteria and all incomplete entries resulted \nin an analysis sample of 1245 participants.In line with the best practices for scale development to \nrecruit at least 300 participants per sample (Boateng et\u00a0al., \n2018; Clark & Watson, 1995, 2019; Comrey & Lee, 1992; \nGuadagnoli & Velicer, 1988) and for being highly powered \n(power = .90, \u03b1 = .05) to detect the smallest effect size of \ninterest (r  = .10, needed N = 1046; Anvari & Lakens, 2021; \nFunder & Ozer, 2019; G\u00f6tz, Gosling, et\u00a0al., 2022), Samples \n2A, 2C, and 2D exceed the size requirements. Sample 2B \nwas highly powered (power = .90, \u03b1 = .05) to detect effect \nsizes r of .15 (needed N  = 463). Power analyses were com-\npleted using the pwr package in R (Champely et\u00a0al., 2021).\nDetailed demographic breakdowns of all samples are \nshown in Table\u00a0 1.\nProcedure and\u00a0measures\nAll participants were invited to take part in an online sur -\nvey through the respective research platforms. After pro-\nviding informed consent, all participants provided basic 22 This is a slight deviation from the preregistration, as we added \nincomplete entries, second entries, participants that completed the \nsurvey in \u2264 10 minutes, and participants who failed any  attention \ncheck (instead of both) to the exclusion criteria, thus adopting a more \nrigorous and conservative exclusion approach than we had preregis-\ntered. These additional exclusions were to ensure high-quality data.\nFig. 5  Structure of the 100 MIST items estimated using exploratory graph analysis\n1880 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nFig. 6  Item stability metric of the MIST-100 items in Study 1\n1881 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\ndemographic information and completed the MIST-20 \nand\u2014depending on their sample group\u2014a select set of \nadditional psychological measures (for a detailed descrip -\ntion of all constructs assessed in each sample group, see \nTable\u00a0 1). All participants received financial compensation \nin accordance with platform-specific remuneration stand -\nards and guidelines on ethical payment at the University of Cambridge. Participants in Samples 2A, 2B, and 2C were \npaid by the sampling platform directly, while participants in \nSample 2D received 2.79 GBP for a 25-minute survey (6.70 \nGBP per hour). All data collections were approved by the \nPsychology Research Ethics Committee of the University of \nCambridge (PRE.2019.108, PRE.2020.034, PRE.2020.086, \nPRE.2020.120).\nTable 4  Network loadings per item and dimension estimated via EGA. Network loadings of .15, .25, and .35 are equivalent to low (.40), moder -\nate (.55), and high (.70) network loadings, respectively (Christensen & Golino, 2021c)\nItem Dim1Dim2Dim3Dim 4Dim Headline\nMIST_73 0.35 0.04 \u22120.01 0.11 1 Morocco\u2019s King Appoints Committee Chief to Fight Poverty and Inequality\nMIST_96 0.33 \u22120.12 \u22120.06 0.10 1 US Hispanic Population Reached New High in 2018, But Growth Has Slowed\nMIST_60 0.28 0.03 0.07 0.10 1 Hyatt Will Remove Small Bottles from Hotel Bathrooms by 2021\nMIST_92 0.24 0.11 0.08 0.09 1 Taiwan Seeks to Join Fight Against Global Warming\nMIST_47 0.24 0.06 \u22120.03 0.00 1 About a Quarter of Large US Newspapers Laid off Staff in 2018\nMIST_33 0.16 0.40 0.06 0.00 2 The Government Is Knowingly Spreading Disease Through the Airwaves and Food Supply\nMIST_31 0.00 0.40 0.00 0.01 2 The Government Is Actively Destroying Evidence Related to the JFK Assassination\nMIST_14 \u22120.05 0.26 0.06 \u22120.04 2 Government Officials Have Manipulated Stock Prices to Hide Scandals\nMIST_1 \u22120.06 0.22 0.05 \u22120.02 2 A Small Group of People Control the World Economy by Manipulating the Price of Gold and \nOil\nMIST_32 \u22120.10 0.31 0.13 0.00 2 The Government Is Conducting a Massive Cover-Up of Their Involvement in 9/11\nMIST_20 0.09 0.05 0.44 0.01 3 New Study: Left-Wingers Are More Likely to Lie to Get a Higher Salary\nMIST_8 0.08 0.09 0.26 0.00 3 Climate Scientists' Work Is 'Unreliable', a 'Deceptive Method of Communication'\nMIST_16 0.01 0.10 0.39 0.05 3 Left-Wingers Are More Likely to Lie to Get a Good Grade\nMIST_70 0.14 \u22120.04 0.00 0.38 4 Majority in US Still Want Abortion Legal, with Limits\nMIST_74 0.08 0.00 0.04 0.32 4 Most Americans Say It\u2019s OK for Professional Athletes to Speak out Publicly about Politics\nMIST_94 0.06 0.02 0.02 0.30 4 United Nations Gets Mostly Positive Marks from People Around the World\nFig. 7  Final structure of the MIST-16 EGA items (left) and their stability indices (right) estimated using parametric bootstrap EGA with 500 \niterations\n1882 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nAnalytical strategy\nWe adopted a three-pronged analytical strategy. First, we com-\nputed reliability estimates and conducted confirmatory factor \nanalyses for each subsample, seeking to reproduce, consoli-\ndate, and evaluate the higher-order model derived in Study 1. \nSecond, in an effort to establish construct validity (Cronbach \n& Meehl, 1955; Strauss & Smith, 2009), we pooled the con-\nstructs assessed across our four validation samples to build \na comprehensive, theory-driven, and preregistered (Sample \n2B) nomological network. To this end, we cast a wide net \nand included (1) concepts that should be meaningfully posi-\ntively correlated with MIST scores (convergent validity; i.e., \nDEPICT Balanced Short Form; Maertens et\u00a0al., 2021; Go \nViral! Balanced Item Set; Basol et\u00a0al., 2021), expecting a high \npositive Pearson r correlation ([0.50, 0.80]), (2) concepts that \nshould be clearly distinct from the MIST (discriminant valid-\nity; i.e., Bullshit Receptivity Scale; BSR; Pennycook et\u00a0al., \n2015; Conspiracy Mentality Questionnaire; CMQ; Bruder \net\u00a0al., 2013), expecting a low to medium negative correlation \nwith the MIST (Pearson r = [\u22120.50, \u22120.20]), and (3) an array \nof prominent psychological constructs of general interest (i.e., \npersonality traits, attitudes, and cognitions including the Big Five, Dark Tetrad, Moral Foundations, Social Dominance \nOrientation, Ecological Dominance Orientation, religiosity, \nself-esteem, political cynicism, numeracy, and trust in vari -\nous public institutions and social agents) for which no a priori \nexpectations were formulated. Third, we leveraged the size \nand representativeness of our samples to establish norm tables \nfor the US and UK general populations as well as specific \ndemographic and geographical subgroups.\nMethod: MIST\u201116\nParticipants\nWe also collected a new dataset (Sample 2E; November 2022) \nwith the best items per dimension that were identified using \nthe EGA approach (the MIST-16). The dataset was collected \nusing Respondi/Bilendi, in a nationally representative quota \nsample (N  = 1213) of adults from the US. The sample compo-\nsition was as follows: 54% identifying as female (44% male, \n2% nonbinary), 33% between 18 and 34 years, 31% between \n35 and 54 years, and 36% between 55 and 75 years; 24% of \nthe participants reported coming from the Midwest (Illinois, \nFig. 8  Plot of the confirmatory factor model estimated using the EGA four-factor structure (left) and the theoretical two-factor structure (right)\nTable 5  Comparison of fit indices of the EGA four-factor model and \nthe theoretical two-factor model\nStructure TEFI CFI RMSEA\nEGA four-factor \u221214.27 0.97 0.03\nTheoretical two-factor \u221211.77 0.91 0.05Table 6  The Satorra scaled difference test comparing the EGA four-\nfactor structure to the theoretical two first-order factor\u00a0structure\nStructure Df Chisq ChisqDiff DfDiff p\nEGA four-factor 98 112.32\nTheoretical two-factor 103 203.49 29.73 5 < .001\n1883 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nIndiana, Iowa, Kansas, Michigan, Minnesota, Missouri, \nNebraska, North Dakota, Ohio, South Dakota, and Wiscon-\nsin), 17% from the Northeast (Connecticut, Maine, Massachu-\nsetts, New Hampshire, Rhode Island , Vermont, New Jersey, \nNew York, and Pennsylvania), 40% from the South (Florida, \nGeorgia, Maryland, North Carolina, South Carolina, Virginia, \nWest Virginia, Delaware, Alabama, Kentucky, Mississippi, \nTennessee, Arkansas, Louisiana, Oklahoma, and Texas), and \n20% from the West (Montana, Wyoming, Colorado, New \nMexico, Idaho, Utah, Arizona, Nevada, Washington, Oregon, \nCalifornia, Alaska, and Hawaii) of the country.\nAnalytical strategy\nExploratory graph analysis\u2014as well as hierarchical EGA \n(Jimenez et\u00a0al., 2022)\u2014was applied to the MIST items. The \nadvantage of using hierarchical EGA (Jimenez et\u00a0al., 2022) \non the US representative quota sample collected (using the \nbest MIST items identified in the first stage of EGA analy -\nsis) is that as the sample size increases, there is a realistic \nchance of EGA estimating a structure reflecting general fac-\ntors instead of first-order factors, if the dimensions are hier -\narchical or form a generalized bifactor structure. Therefore, \nthe item stability and structural consistency of the first-order \nfactors were computed using a hierarchical EGA (Jimenez \net\u00a0al., 2022) version of bootstrap exploratory graph analysis \n(Christensen & Golino, 2021a).\nWe would like to note that the MIST-16 was developed \nand validated after the samples from the other validation \n(Studies 2A\u20132D) and application (Study 3) studies were col-\nlected, due to the emergence of new psychometric methods. \nAs the MIST-16 is not a subset of the MIST-20, we do not \nhave the same nomological net and intervention evaluation \ndata available for the MIST-16. However, as the correlation \n(in Study 1) between the MIST-20 and MIST-16 item sets is \nlarge, r = .81, 95% CI [.77, .84], p  < .001, we can expect the \nMIST-20 results to be a close approximation.\nResults: MIST\u201120/MIST\u20118\nInternal consistency\nFor each sample, we employed SEM to assess model fit\u2014\nexamining both a basic first-order model with two distinct \nfactors (i.e., real news detection, fake news detection; without allowing the factors to correlate) and a theoreti-\ncally derived higher-order model (Markon, 2019; Thurs-\ntone, 1944; which establishes a relationship between the \ntwo factors) in which both first-order factors load onto a \ngeneral second-order veracity discernment factor. We then \ncalculated reliability estimates using internal consistency \nmeasures (inter-item correlations, item-total correlations, \nand McDonald\u2019s \u03c9). We used the lavaan  package for SEM \nin R (Rosseel, 2012).\nIn keeping with our theoretical conceptualization of \nthe MIST\u2014with a general ability factor of veracity dis-\ncernment, and two subordinate factors capturing real \nnews and fake news detection, respectively\u2014we fitted \na higher-order model (Markon, 2019; Thurstone, 1944) \nin which both first-order factors load onto a general \nsecond-order veracity discernment factor (see Fig.\u00a0 9). \nWe first did this with Sample 2A (US quota sample \nfrom Respondi). Consistent with conventional guide-\nlines (RMSEA/ SRMR < .10 = acceptable; < .06 = excel-\nlent; CFI/ TLI > .90 = acceptable; > .95 = excellent; Clark \n& Watson, 2019; Finch & West, 1997; Hu & Bentler, \n1999; Pituch & Stevens, 2015; Schumacker et\u00a0al., 2015), \nthe model fits the data adequately (MIST-20: CFI = .90, \nTLI = .89, RMSEA  = .041, SRMR  = .040; MIST-8: \nCFI = .97, TLI = .95, RMSEA = .030, SRMR = .025).23 \nWe note that the \u03c72 goodness-of-fit test was significant\u2014\nsignaling lack of fit (MIST-20: \u03c72 = 1021.86, p < .001; \nMIST-8: ; \u03c72 = 72.74, p < .001). However, this should be \ninterpreted with caution, as the \u03c72 is a test of perfect fit \nand very sensitive to sample size. As such, as sample sizes \napproach 500, \u03c72 is usually significant even if the differ -\nences between the observed and model-implied covariance \nmatrices are trivial (Bentler & Bonett, 1980; Curran et\u00a0al., \n2003; Rosellini & Brown, 2021). Taken together, the find-\nings thus suggest an adequate model fit for the theoreti-\ncally derived higher-order model.\nImportantly, this model also yielded better fit than a tra-\nditional basic first-order model (with two distinct fake news \nand real news factors; MIST-20: \u03c72 = 1027.17, p < .001, \nCFI = 0.90, TLI = 0.89, RMSEA = 0.041, SRMR = 0.041; \nMIST-8: \u03c72 = 99.46, p < .001, CFI = 0.95, TLI = 0.93, \nRMSEA = 0.035, SRMR = 0.035). A likelihood-ratio test of \nthe higher-order model versus the first-order model (which \n23 We acknowledge that there is a discussion in the literature on \ndefining new (dynamic) fit values depending on the specific model \ntested (see McNeish & Wolf, 2021). For example, simulations using \nthe ezCutoffs (Schmalbach et\u00a0 al., 2019) package indicate we would \nneed a CFI and a TLI of larger than 0.99 for excellent fit, in conjunc-\ntion with an RMSEA of smaller than 0.04/0.03 (MIST-8/MIST-20) \nand an SRMR smaller than 0.03. However, as the new cutoff values \nare still under consideration and not well established, we focused on \nthe conventional and\u2014in this case also\u2014preregistered cutoff values \nfor our evaluation.Table 7  Fit of the three- and two-dimensional structures of the MIST-\n20 items\nStructure TEFI CFI RMSEA\nMIST-20 EGA three-factor \u221220.70 0.963 0.029\nMIST-20 Theoretical two-factor \u221216.93 0.955 0.032\n1884 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\ndid not include a correlation between the two factors) was \nsignificant for both the MIST-20 and the MIST-8 (MIST-\n20: \u2206\u03c72 = 5.35, p = .021, MIST-8: \u2206 \u03c72 = 26.29, p < .001), \nindicating a better fit for the higher-order model.\nSample comparison Across all four samples, we success-\nfully reproduced the original higher-order model, with \nparameters indicating good fit, as well as good internal \nconsistency in all four samples (see Table\u00a0 8 for a com-\nplete overview).24 A similar fit is found between the US \nRespondi and UK Respondi samples, indicating that the \nMIST works similarly in the UK as it does in the US.25 \nMeanwhile, larger differences are found between the US \nRespondi and the US CloudResearch samples, and between \nthe UK Respondi and the UK Prolific samples, indicating \nthat sampling platform plays a larger role than nationality \nwhen administering the MIST even when using representa-\ntive quota sampling.Nomological network26\nConvergent validity  As preregistered, in Sample 2B27\u2014\nwhich was the sample we primarily relied on in constructing \nthe nomological network, as it offered the widest coverage \nof psychological constructs among our validation samples\u2014\nthe correlation between the general MIST-20 score and the \nDEPICT Balanced Short Form measure (Maertens et\u00a0al., \n2021) was found to be positive and medium to large, with \na significant Pearson correlation of .54 (95% CI [.48, .60], \np < .001).28 The MIST-20 correlation with the Go Viral!  \ninventory (Basol et\u00a0al., 2021) was lower than the estimated \nvalue but was significantly correlated, with a Pearson corre-\nlation of .26 (95% CI [.18, .34], p  < .001). Similarly, regard-\ning incremental validity, the additional explained variance \nin the DEPICT Balanced Short Form measure above and \nbeyond the CMQ and the BSR is at the upper side of our \nprediction, with an additional 20% of variance explained, \n25 We would like to stress that this does not imply measurement invar -\niance and would like to caution researchers to compare results directly \nbetween countries. The current data indicate that the MIST works in \nthe US and the UK and likely measures the same latent construct, but \nit does not mean that the results are directly comparable. We recom-\nmend researchers and practitioners keep the focus on comparisons \nwithin instead of between countries. For a detailed discussion about \ncross-cultural generalizability please see Deffner et\u00a0al. (2022).24 Supplement S9 includes model plots for both the MIST-20 and \nMIST-8 for all samples.26 This section focuses on the nomological network of the general \nability factor (veracity discernment) of the MIST -20. However, we \nhave also constructed nomological networks for the subcomponents \nof the MIST as well as the MIST -8. For parsimony\u2019s sake, these are \nreported in Supplements S10-S12.\n27 Some variables were only analyzed in specific samples, as not all \nvariables were present in all datasets.\n28 See https:// aspre dicted. org/ nx7xu. pdf for the preregistration \n(Sample 2B).\nFig. 9  Plot of higher order MIST-8 SEM model in Sample 2A (N = 3479)\n1885 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nwhereas with 3% it is under the predicted value for the Go \nViral! inventory.29 For a more detailed account, see Supple-\nment S13. In addition, in Sample 2A, we measured belief in \nCOVID-19 myths, which was significantly positively cor -\nrelated and within the preregistered strength of convergent \nvalidity measures (r  = \u2212.51, 95% CI [\u2212.55, \u2212.47], p  < .001).\nDiscriminant validity As preregistered for Sample 2B, the \nMIST-20 was moderately negatively correlated with the BSR \n(r = \u2212.21, [\u2212.29, \u2212.13], p < .001) and the CMQ ( r = \u2212.38 \n[\u2212.45, \u2212.30], p < .001). Overall, the correlational pattern of \nour nomological network supports the construct validity of \nthe MIST, with the MIST being more strongly correlated with \nthe convergent measures than with the discriminant measures \n(Campbell & Fiske, 1959; Rosellini & Brown, 2021).\nCRT (Sample 2A) In line with other studies finding a role for \nthe CRT in misinformation detection (e.g., Pennycook & \nRand, 2019), we found a significant correlation between the \nMIST score and the cognitive reflection test, or CRT (r  = .29, \n95% CI [.26, .32], p < .001).\nAOT (Sample 2A) We found an even larger significant cor -\nrelation between the MIST score and actively open-minded \nthinking or AOT (r  = .49, 95% CI [.46, .51], p < .001).\nBFI (Sample 2B) Contrary to our preregistered exploratory \nhypotheses, in Sample 2B the MIST-20 score was not  sig-\nnificantly correlated with openness, r = .02, 95% CI [\u2212.06, .11], p = .594, and agreeableness was not  negatively corre-\nlated with distrust d , r = .05, 95% CI [\u2212.04, .14], p  = .255.30 \nThe MIST-20 score was also not significantly correlated \nwith agreeableness (r  = .05, 95% CI [\u2212.04, .14], p  = .271) \nor extraversion (r  = \u2212.07, 95% CI [\u2212.15, .02], p  = .141), but \ndid significantly correlate with conscientiousness (r  = .10, \n95% CI [.02, .19], p  = .020) and neuroticism (r  = \u2212.14, 95% \nCI [\u2212.23, \u2212.06], p = .001).\nDT (Sample 2B) The MIST-20 score was negatively correlated \nwith each of the four Dark Tetrad traits: Machiavellianism  \n(r = \u2212.09, 95% CI [\u2212.17, \u2212.00], p  = .047), narcissism ( r = \u2212.26, \n95% CI [\u2212.34, \u2212.18], p  < .001), psychopathy ( r = \u2212.30, 95% \nCI [\u2212.37, \u2212.22], p  < .001), and sadism (\u2212.22, 95% CI [\u2212.30, \n\u2212.12], p < .001). However, contrary to our preregistered \nexploratory hypothesis, Machiavellianism was not  negatively \ncorrelated with na\u00efvit\u00e9 n, r = .16, 95% CI [.07, .24], p < .001.\nTrust measures (Sample 2B)  In line with our preregistered \nexploratory hypotheses, we found that the MIST score was \ncorrelated with trust in science, r  = .33, 95% CI [.25, .41], \np < .001, scientists, r = .36, 95% CI [.28, .43], p  < .001, and \nmainstream media, r  = .18, 95% CI [.09, .26], p  < .001. In addi-\ntion, we found that trust in doctors, r  = .36, 95% CI [.28, .43], \np < .001, journalists, r = .19, 95% CI [.11, .27], p  < .001, and \nofficials, r = .09, 95% CI [.00, .17], p  = .049, was significantly \n29 It must be noted that the Go Viral inventory is not a validated meas-\nurement instrument. Results should be interpreted in light of this.30 The lack of a significant correlation between the MIST score and \nopenness is somewhat surprising given the strong correlation between \nthe MIST and the AOT score, indicating that openness as measured \nin the Big Five is not the same as open-minded thinking as measured \nby the AOT.Table 8  Model fit overview\nTotal N = 6461. Samp = sample. Plat = sampling platform. Pop = sample population. CI = confidence interval; LL = lower limit; UL = upper \nlimit. R = Respondi. C = CloudResearch. P = Prolific. \u03c9tot = McDonald\u2019s Omega. 3F reflects whether the three-factor (higher-order) model pro-\nvided better fit than the two-factor (two-order) model. \u26ac = descriptively better fit but not significant; * p < .05, ** p < .01, *** p < .001MIST-20\nSamp. Plat. Pop. \u03c7\u00b2 p CFI TLI RMSEA 95% CI SRMR \u03c9tot 3F\nLL UL\n2A R US 1021.86 < .001 0.90 0.89 0.041 0.039 0.044 0.040 0.76 *\n2B C US 264.66 < .001 0.92 0.91 0.035 0.027 0.043 0.051 0.75 \u26ac\n2C R UK 473.56 < .001 0.91 0.90 0.041 0.037 0.046 0.049 0.81 ***\n2D P UK 432.12 < .001 0.86 0.85 0.038 0.034 0.042 0.045 0.70 ***\nMIST-8\nSamp. Plat. Pop. \u03c7\u00b2 p CFI TLI RMSEA 95% CI SRMR \u03c9tot 3F\nLL UL\n2A R US 72.74 < .001 0.97 0.95 0.030 0.023 0.037 0.025 0.57 ***\n2B C US 30.32 .048 0.96 0.94 0.036 0.003 0.058 0.040 0.58 *\n2C R UK 64.13 < .001 0.94 0.91 0.045 0.033 0.058 0.040 0.62 ***\n2D P UK 46.91 < .001 0.93 0.90 0.037 0.023 0.050 0.035 0.55 ***\n1886 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\npositively correlated, while trust in the government, r  = \u2212.11, \n95% CI [\u2212.20, \u2212.02], p  = .012, was significantly negatively cor -\nrelated with the MIST-20. We found no significant correlation \nfor either of the two trust-in-politicians scales, ra = \u2212.06, 95% \nCI [\u2212.14, .03], p = .210, rb = .07, 95% CI [\u2212.02, .15], p = .131.\nAdditional associations For a summary and discussion of \nthe exploratory analyses of MFQ, SDO, EDO, numeracy, \nanti-vaccination attitudes, self-esteem, religiosity, trust, ide-\nology, and demographics, please see Supplement S14.\nDetailed summary figures separated by outcome category \nare available in Supplements S10-S12.\nNational norms\nWe used the Respondi samples for each country (i.e., Sam-\nple 2A for the US and Sample 2C for the UK) to generate \nnorm tables for general veracity discernment as well as fake \nnews and real news detection.31 As can be gleaned from \nTable\u00a0 9, the norms for the two countries were very similar, \nwith minor deviations of single score points, further corrob-\norating evidence for the cross-cultural validity of the MIST. \nTable\u00a0 10 exhibits norms for the general US population.\nFull norm tables for the US and the UK, including spe-\ncific norms based on age (US, UK) and geography (US; i.e., \n9 census divisions, 4 census regions), as well as means and \nstandard deviations per item, including a per-item compari-\nson between Democrats (US)/liberals (UK) and Republicans \n(US)/conservatives (UK), are available in Supplement S15.\nResults: MIST\u201116\nExploratory graph analysis was applied to the MIST-16 \nitems, as well as hierarchical EGA (Jimenez et\u00a0al., 2022).32 The item stability and structural consistency of the first-\norder factors were computed using a hierarchical EGA \n(Jimenez et\u00a0al., 2022) version of bootstrap exploratory graph \nanalysis (Christensen & Golino, 2021a).33 The traditional \nEGA technique indeed identified only two dimensions (real \nand fake news items, see Fig.\u00a0 10). The hierarchical EGA \ntechnique, on the other hand, identified the original four-\ndimensional (first-order) structure and two general factors \n(real and fake news items, see Fig.\u00a0 11).\nA parametric bootstrap EGA using the hierarchical EGA \nmethod (Jimenez et\u00a0al., 2022) showed that the four dimen -\nsions are very stable, being estimated in 90.8% of the 500 \nbootstrapped samples. In terms of item stability, the MIST-\n16 EGA items presented very high stability, except for item \nMIST 73, which was estimated on their empirical hierarchi-\ncal EGA first-order dimension in 73% of the bootstrapped \nsamples (see Fig.\u00a0 12).\nDiscussion\nIn Study 2, we consolidated and expanded the psychomet-\nric properties of the MIST. First, we conducted confirma-\ntory factor analyses across four samples with representative \nquota from the US and the UK, consistently replicating the \nhigher-order structure yielding good model fit and internal \nconsistency for both the MIST-8 and the MIST-20. Next, we \nconstructed an extensive nomological network of the MIST \nto assess construct validity (Cronbach & Meehl, 1955). As \npreregistered, and similar to Study 1, in Sample 2B we found \na high correlation between the MIST score and the DEPICT \nmisinformation inventory, supporting convergent validity. \nSimilarly, in Sample 2A we found a medium to high negative \ncorrelation between the MIST-20 and a COVID-19 misinfor -\nmation beliefs inventory, further attesting to the measure\u2019s \nconvergent validity. In addition, we demonstrated that both \n31 We chose to create the norm tables based on the Respondi samples \ninstead of pooling all samples, as through recent projects we found \nsome evidence indicating that Respondi samples provide more rep-\nresentative levels of numeracy, education, and ideology than Prolific, \nand our experience with CloudResearch is limited.\n32 Due to an error in the Qualtrics system, only 15 items were pre-\nsented to the participants. Item MIST 16 (Left-Wingers Are More Likely \nto Lie to Get a Good Grade) was left out of the data collection system.33 As pointed out earlier, the advantage of using hierarchical EGA \n(Jimenez et\u00a0 al., 2022) on the US representative quota sample (col-\nlected using the MIST-16 EGA items) is that as the sample size \nincreases, there is a meaningful chance that the EGA estimates a \nstructure reflecting general factors instead of first-order factors, if the \ndimensions are hierarchical or form a generalized bifactor structure.Table 9  MIST norm score comparison between US and UK samples\nScale Sample Minimum 1st Quartile Median Mean 3rd Quartile Maximum\nMIST-8\nUS 0 4 6 6 7 8\nUK 0 4 5 5 7 8\nMIST-20\nUS 4 11 14 14 17 20\nUK 4 11 13 13 16 20\n1887 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nthe MIST-8 and the MIST-20 explain considerable extra \nvariance above the existing CMQ and BSR scales (MIST-\n20: \u2206R2 = 20%, MIST-8: \u2206R2 = 14%), indicating substantial \nincremental validity (Clark & Watson, 2019). Surprisingly, \nhowever, the correlations of each of the MIST, CMQ, and \nthe BSR with the Go Viral! items were all low (r  < .30). Nev -\nertheless, the MIST-20 remained the single best predictor \nfor the Go Viral! items, significantly improving the variance \nexplained in a combined model on top of the CMQ and BSR \nmeasures (\u2206R2 = .03). In terms of discriminant validity, as \npreregistered, in Sample 2B we observed moderate negative \nassociations between the MIST-20 and the BSR as well as the \nCMQ. In Sample 2A, we also found preliminary evidence for \nthe role of actively open-minded thinking (AOT) as a potential \nvehicle for better distinction between fake and real news. This \naligns with previous research showing that AOT is related to \nmore critical information source evaluation (Baron, 2019) and \ndecreased susceptibility to fake news (Pennycook & Rand, \n2020, Pennycook & Rand, 2021).\nWithin the realm of trait measures we found relatively small \ncorrelations with the core personality traits. Contrary to our \nexpectations, openness, extraversion, and agreeableness were \nnot significantly related to the MIST-20. Meanwhile, conscien-\ntiousness exhibited a small positive association. This dovetails well with previous research finding that individuals high in \nconscientiousness are more likely to read news offline (rather \nthan relying solely on social media; Sindermann et\u00a0al., 2020) \nand less likely to share fake news (Lawson & Kakkar, 2021 ) \nand engage in conspiracist ideation (Brotherton et\u00a0al., 2013). \nWe also found a small negative association with neuroticism. \nAs neuroticism is widely understood as a stable predisposition \nto experience anxiety and fear (Eysenck, 1967; Hofstee et\u00a0al., \n1992; Soto & John, 2017), this is consistent with previous \nwork identifying fear and trait anxiety as positive predictors \nof conspiracy beliefs (Grzesiak-Feldman, 2013; Swami et\u00a0al., \n2016) as well as other studies finding that those high in neu-\nroticism tend to rely on social media news feeds and are thus \nmore likely to get caught in filter bubbles and echo chambers \n(Sindermann et\u00a0al., 2020). Larger correlations were found with \nthe Dark Tetrad personality traits, which were all negatively \nrelated to the MIST-20 score. While the links with Machi-\navellianism, psychopathy, and sadism are novel, the positive \nassociation with narcissism dovetails well with previous work \ndemonstrating narcissists\u2019 greater susceptibility to conspiracies \n(Cichocka et\u00a0al., 2016; Kumareswaran, 2014).\nMeanwhile, in Sample 2E, we successfully validated the \npsychometric strength of the EGA-based MIST-16, which also \nshowed evidence for two general factors, fake news detection \nand real news detection, as well as two facets for each. While \nEGA uses an entirely different approach for item analysis and \nselection, the convergent outcome of two general factors and \nthe overlap in the item sets between the two methods show that \nit is possible\u2014using a variety of methodologies\u2014to develop a \npsychometrically validated misinformation susceptibility test Table 10  MIST-20 general population norms for the United States \n(N = 3479)\nV (Veracity discern-\nment)f (Fake news detec-\ntion)r (Real news detec-\ntion)\nPercentile Score Percentile Score Percentile Score\n0% 4 0% 0 0% 0\n5% 8 5% 3 5% 2\n10% 9 10% 4 10% 3\n15% 10 15% 5 15% 4\n20% 10 20% 5 20% 4\n25% 11 25% 6 25% 5\n30% 12 30% 7 30% 5\n35% 12 35% 7 35% 6\n40% 13 40% 7 40% 6\n45% 14 45% 8 45% 7\n50% 14 50% 8 50% 7\n55% 15 55% 8 55% 7\n60% 15 60% 9 60% 7\n65% 16 65% 9 65% 8\n70% 16 70% 9 70% 8\n75% 17 75% 9 75% 8\n80% 17 80% 10 80% 9\n85% 18 85% 10 85% 9\n90% 19 90% 10 90% 10\n95% 19 95% 10 95% 10\n100% 20 100% 10 100% 10\nFig. 10  Structure estimated via EGA using the validation sample\n1888 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nwith congruent results. Meanwhile, the EGA data show that \nEGA is a useful new method psychologists can use to design \nmisinformation detection scales (or indeed, any scale), enlarg-\ning the toolkit available for scale development.\nAll in all, the nomological network largely confirmed the \npreregistered relationship patterns\u2014thus corroborating the \nMIST\u2019s construct validity\u2014while at the same time demon-\nstrating new insights that can be gained by using the MIST-\n20 measure, which may stimulate further research. Finally, \nwe leveraged the large size and national representativeness \nof our validation samples to produce norm tables for the \nUK and US general populations as well as distinct demo-\ngraphic subgroups in the UK and the US and geographical \nsubgroups in the US.\nStudy 3: Application\u2014A nuanced \neffectiveness evaluation of\u00a0a\u00a0popular media \nliteracy intervention\nIn Study 3, we demonstrate how the MIST can be used in \nconjunction with the V erification done framework and norm \ntables.34 We employ the MIST-8 in a simple within-groups \npretest /post-test design with the Bad News Game, a major \nmedia literacy intervention played by over a million people \n(Roozenbeek & van der Linden, 2019). The Bad News Game  is based on inoculation theory (van der Linden & Roozenbeek, \n2020 ), and both its theoretical mechanisms and its effects \nhave been replicated multiple times (see, e.g., Maertens et\u00a0al., \n2021; Roozenbeek, Maertens et\u00a0al., 2021), making it a well-\nestablished intervention in the literature as a tool to reduce \nmisinformation susceptibility. We therefore hypothesized that \nthe intervention would improve v eracity discernment (ability \nto accurately distinguish real news from fake news), r eal news \ndetection  (ability to correctly flag real news), and fake news \ndetection (ability to correctly tag fake news). In addition, we \nhypothesized that the Bad News Game would decreases both \ndistrust (negative judgment bias or being hyper-skeptical) and \nna\u00efvit\u00e9 (positive judgment bias or believing everything). We \nused norm tables to establish where the baseline MIST scores \nof our convenience sample lay.\nMethod\nParticipants\nWe collected data from an online community sample of 4024 \nparticipants who played the Bad News Game (www.getbad-\nnews.com) between 7 May 2020 and 29 July 2020 and who \nagreed to participate in the in-game survey. After filtering \nout participants who did not complete the full study, did \nnot have prior experience with the game, were underage, \nor entered the study multiple times, and lived outside of the \nUnited States, 421 participants remained.35 Based on earlier \n34 A MIST implementation guide explaining how researchers and \npractitioners can set up the MIST in their studies as well as how to \ncalculate the Verification done (Vrf dn) scores can be found in Sup-\nplement S17. An example Qualtrics survey and a score calculation R \nscript are available in the OSF repository: https:// osf. io/ r7phc/.35 We restricted our sample to US residents, as we did not have a UK \nfilter and have not yet validated the MIST in any other country.\nFig. 11  Structure estimated via hierarchical EGA using the validation sample\n1889 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nstudies evaluating the Bad News Game (Maertens et\u00a0al., \n2021; Roozenbeek, Maertens et\u00a0al., 2021), we aimed to be \nhighly powered (power = .90, \u03b1 = .05) to detect a Cohen\u2019s \nd effect size of 0.250, which required a sample size of 338, \nwhich we exceed in this sample. The power was calculated \nusing the R pwr package (Champely et\u00a0al., 2021).\nOn average, participants were young (55.58% 18\u201329 \nyears, 32.30% 30\u201349, 12.11% over 50), 52.02% identified \nas female (41.09% male, 6.89% other), and 86% had either \na higher education degree or some college experience (see \nTable\u00a0 1 for a complete demographics overview). The median \nideology on a scale from 1 (liberal) to 7 (conservative) was \n3 (M  = 2.88, SD = 1.39), indicating a slightly left-leaning \naudience.\nProcedure and\u00a0measures\nIndividuals who played the Bad News Game  (Roozenbeek \n& van der Linden, 2019) were invited to participate in the \nstudy. The Bad News Game (www.getbadnews.com) is a free \nonline browser game in which players learn about six com-\nmon misinformation techniques over the course of 15 min-\nutes in a simulated social media environment (see Roozen-\nbeek & van der Linden, 2019, for a detailed discussion). In \nthe current study, after providing informed consent, indi -\nviduals completed the MIST-8 both before and after playing \nthe Bad News Game. Participation was completely volun-\ntary, and no rewards, monetary or otherwise, were offered. This study was approved by the Psychology Research Ethics \nCommittee of the University of Cambridge (PRE.2020.120, \nPRE.2020.136).\nAnalytical strategy\nAfter contextualizing our findings by juxtaposing the sam-\nple\u2019s baseline findings to the US general national norms \nderived in Study 2, we conducted repeated-measures t -tests \nfor veracity discernment (M  = 6.23, SD = 1.53) and for \nthe four subcomponents of the MIST\u2014f ake news detec-\ntion (M  = 3.19, SD = 0.92), real news detection (M  = 3.04, \nSD = 0.95), distrust (M  = 0.31, SD = 0.63), and na\u00efvit\u00e9 \n(M = 0.46, SD = 0.69).\nResults\nBaseline\nWe found that our US convenience sample scored higher \non the MIST than the US population average for v erac-\nity discernment (see Study 2;  1st QuartilePopulation  = 4,  1st \nQuartileSample  = 6).36\n36 We found similar results when looking at fake news detection  (1st \nQuartilePopulation  = 2,  1st QuartileSample  = 3) and real news detection \n (1st QuartilePopulation  = 2,  1st QuartileSample  = 3).\nFig. 12  Item stability of the hierarchical EGA first-order structure in the validation sample\n1890 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nHypothesis tests\nV\u2014Veracity discernment Contrary to our expectations, we \ndid not find a significant effect of veracity discernment \npost-intervention relative to pre-intervention (Mdiff = 0.11, \n95% CI [\u22120.01, 0.23], t (420)  = 1.80, p = .072, d = 0.088, \n95% CI [\u22120.103, 0.279]). See Fig.\u00a0 13, Panel A for a bar \nplot.\nr\u2014Real news detection While we found an effect of the \nintervention on real news detection, the effect was in the \nopposite direction of our prediction (Mdiff = \u22120.17, 95% CI \n[\u22120.26, \u22120.08], t (420) = \u22123.72, p < .001, d = \u22120.181, 95% \nCI [\u22120.373, 0.011]). See Fig.\u00a0 13, Panel B, for a bar plot.\nf\u2014Fake news detection In line with our expectations, we did \nfind a positive effect of the intervention on fake news detec-\ntion (Mdiff = 0.28, 95% CI [0.20, 0.36], t (420) = 6.81, p < .001, \nd = 0.332, 95% CI [0.138, 0.525]). See Fig.\u00a0 13, Panel C for \na bar plot.\nd\u2014Distrust Contrary to our hypothesis, we observed \nan increase in distrust ( Mdiff = 0.31, 95% CI [0.22, 0.40], \nt(420) = 6.94, p < .001, d = 0.338, 95% CI [0.144, 0.532]). \nSee Fig.\u00a0 13, Panel D for a bar plot.\nn\u2014Na\u00efvit\u00e9 As hypothesized, we did find a significant reduc-\ntion in na\u00efvit\u00e9 after intervention ( Mdiff = \u22120.14, 95% CI \n[\u22120.20, \u22120.07], t (420) = \u22124.12, p < .001, d = \u22120.201, 95% \nCI [\u22120.392, \u22120.008]). See Fig.\u00a0 13, Panel E for a bar plot.See Supplement S16 for a detailed summary table with \nvariable descriptive statistics and difference scores.\nDiscussion\nTraditionally, evaluators of Bad News Game (e.g., Roozen-\nbeek & van der Linden, 2019) only looked at a small \namount of (ad hoc-created) real news items and focused \non participants\u2019 reliability ratings of a large set of fake \nnews items. Study 3 showed that using the MIST in con-\njunction with the V erification done framework provided \nnovel insights contrary to our expectations. Although \ntrending towards an effect in the expected direction, par -\nticipants did not become significantly better at general \nnews veracity discernment after playing the Bad News \nGame ( p = .072). Looking at the MIST facet scales, we did \nfind significant differences in both fake news detection and \nreal news detection. More specifically, we observed that \nwhile people improved in the detection of fake news, they \nalso became worse at the detection of real news. Looking \nfurther at response biases, we can also see that the Bad \nNews Game might increase general distrust in news head-\nlines while also diminishing na\u00efvit\u00e9. At first sight, these \nresults seem to indicate that the intervention does decrease \npeople\u2019s susceptibility to fake news and reduces general \nna\u00efvit\u00e9, but at a potential cost of increased general distrust \n(hyper-skepticism). Whether this means the intervention \nworks depends on the aim: to decrease susceptibility to \nmisinformation, or to increase the ability to accurately \nFig. 13  Plot of Verification done variables applied to the Bad News Game (N = 421). T1 = pretest. T2 = post-test\n1891 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\ndiscern real news from fake news. The V erification done \nframework allows interventionists to start differentiating \nthese important questions both theoretically and empiri-\ncally, and we encourage researchers and practitioners to \nuse the framework independently of the misinformation \nsusceptibility measure used.\nOne reason why the pattern for the subordinate factors \nmay be found is that the Bad News Game focuses mainly \non detecting misinformation and warning people about the \nthreats of misinformation, and is less focused on recogniz-\ning real news (Roozenbeek & van der Linden, 2019). In \naddition, as the evidence shows there may be counteract-\ning effects (increased distrust but also improved fake news \ndetection), the lack of significant effects for the general fac-\ntor (the discernment variable) may therefore also be due to \nthese counteracting effects, resulting in an effect that is too \nsmall to measure with our sample (N  = 421), especially in \nthe context of a short 15-minute intervention in combina-\ntion with an 8-item scale. Finally, it is also possible that the \nintervention may simply not be sufficient to make a large \nenough impact on a general susceptibility factor.\nIn addition, as recommended by our framework, these \nresults need to be interpreted in conjunction with the norm \ntables. The general sample that was recruited was already \nhighly media-literate. The first quartile of the pretest MIST \nscores was higher than the population average (verac-\nity discernment:  1st  QuartilePopulation  = 50% accuracy,  1st \n QuartileSample  = 75% accuracy). Effects of the intervention \nmight therefore be different with a more representative sam-\nple, or for people performing worse during the pretest phase.\nThe results of this study come with two caveats. First, the \nMIST-8 was used instead of the MIST-20. As is common \nfor short scales (Rammstedt et\u00a0al., 2021; Thalmayer et\u00a0al., \n2011)\u2014while maintaining high psychometric quality\u2014the \nparsimonious MIST-8 is less precise and less reliable than \nthe MIST-20. Since the MIST-20 only takes about 2 minutes \nto complete, we recommend researchers use the MIST-20 \nwhenever possible. Second, while we were sufficiently pow -\nered to detect effect sizes similar to the original evaluation \nof the intervention (Roozenbeek & van der Linden, 2019), \nwith a sample of 421 participants\u2014as is also reflected in the \nrather large confidence intervals\u2014we did not have sufficient \nstatistical power to detect smaller nuances (Anvari & Lakens, \n2021; Funder & Ozer, 2019; G\u00f6tz, Gosling, et\u00a0al., 2022).\nThe results of this study indicate the importance of look -\ning at misinformation susceptibility in a more holistic way. \nApplying the V erification done framework, we discovered \nkey new theoretical dimensions that previous research had \noverlooked. Evaluators of this intervention, and other inter -\nventions, can now disentangle and accurately measure the \nfive dimensions of misinformation susceptibility, thereby \nexpanding our understanding of both the underlying mecha-\nnisms and the intervention\u2019s practical impact.General discussion\nWe explained the necessity of having a multifaceted measure-\nment of misinformation susceptibility, and based on theoreti-\ncal insights from previous research, developed the Verifica-\ntion done framework. Then, in three studies and six samples \nfrom two countries, we developed, validated, and applied the \nMisinformation Susceptibility Test (MIST): a holistic test \nwhich allows the assessment of veracity discernment ability , \nits facets fake news detection ability and real news detection \nability, and judgment biases distrust and na\u00efvit\u00e9.\nIn Study 1, we derived a development protocol, gener -\nated a set of fake news headlines using the GPT-2 neural \nnetwork\u2014an advanced language-based machine learning \nalgorithm\u2014and extracted a list of real news headlines from \nneutral and well-trusted sources. Through psychometric \nanalysis using factor analysis and item response theory, we \ndeveloped the MIST-8, MIST-16, and the MIST-20 tests.\nIn Study 2, we recruited five samples with nationally rep-\nresentative quota, two each for the US and the UK, from three \ndifferent recruitment platforms, and followed a multifaceted \nvalidation strategy with the aim of gaining insights into the \nmeasure\u2019s validity and replicability. First, confirmatory factor \nanalyses consistently favored the higher-order structure and \nyielded satisfactory properties that suggest high validity and \ngood reliability of both the MIST-8 and the MIST-20. Second, \nadopting a wide-net approach, we constructed an extensive \nnomological network. We found the MIST-8 and MIST-20 to \nbe consistently highly correlated with various fact-check tests\u2014\nthe \u201cCOVID-19 fact-check\u201d headline evaluation task (Penny -\ncook, McPhetres, et\u00a0al., 2020) and the and \u201cDEPICT\u201d social \nmedia post reliability judgment task (Maertens et\u00a0al., 2021)\u2014\nthus signaling convergent validity\u2014while being clearly distinct \nfrom the existing Conspiracy Mentality Questionnaire (CMQ) \nand the Bullshit Receptivity Scale (BSR), hence providing evi -\ndence for discriminant validity. The correlation with ad hoc \nheadline evaluation tasks is strong enough to show that they are \nmeasures of a similar construct, but it is also weak enough to \ndemonstrate that they are sufficiently distinct. The MIST offers \na reliable, standardized, and validated alternative to these ad \nhoc tests, with high predictive validity for a wide set of scales, \nas well as norm tables. However, due to the high stability of the \nMIST, it is possible that the MIST may turn out to be particu-\nlarly useful for subgroup analyses, and may be less sensitive for \nthe measurement of (small) intervention effects. In addition, \nthe MIST aims to measure generalized susceptibility to misin-\nformation, which is not tailored to the skills trained in specific \ninterventions. Therefore, the MIST is not meant to replace ad \nhoc measures, but can exist in conjunction with them, depend-\ning on the outcome variable of interest. Moreover, we presented \nMIST-20 and MIST-8 norm tables for both the UK and the US \nbased on our large samples with nationally representative quota, \nwhich can be used to contextualize effects.\n1892 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nUsing a new, modern, psychometric method, namely \nexploratory graph analysis (EGA; Golino & Epskamp, 2017), \nwe showed a proof of concept of how EGA can be used to \nhelp with establishing the factor structure, the item selection, \nand the validation of scales such as the MIST. In both Study \n1 and Study 2 we show how EGA can lead to potentially \nmore stable item selection than when using the traditional \nEFA and IRT methods, and present an alternative version of \nthe MIST: the MIST-16. Meanwhile, further analyses reveal \nthat EGA can help to detect extra dimensions as facets of \nthe general factors. Interestingly, the validation sample (Sam-\nple 2E) showed that a structure with two generalized factors \nand four facets had the best fit, potentially informing misin-\nformation theorists on further dimensions to explore when \nresearching the nature of misinformation. Meanwhile, it also \ncorroborated more evidence that misinformation susceptibil-\nity can be viewed through the lens of two general factors (real \nnews detection, fake news detection), and robustly measured \nas such. This congruence between these two very different \npsychometric methods shows the robustness of our psycho-\nmetric toolkit and the ability for it to produce reliable scales \nto measure psychological constructs.\nIn the third and last study, we demonstrated how V eri-\nfication done and the MIST can be employed in naturalis-\ntic settings, in this case to evaluate the general effects of a \nhighly popular inoculation intervention. Employing a vali -\ndated measure to evaluate interventions in combination with \nthe norm tables\u2014which have not been used in this field \nbefore\u2014we were able to uncover new mechanisms behind \na well-known media literacy intervention, the Bad News \nGame (Maertens et\u00a0al., 2021; Roozenbeek & van der Lin-\nden, 2019), and highlighted both weaknesses and strengths \nof this intervention that had not been detected before using \nthe classical methods. For example, while the intervention \nis typically evaluated by looking at fake news reliability rat-\nings (e.g., Roozenbeek & van der Linden, 2019) without an \nevaluation framework or norm tables, we were now able to \nunveil important dynamics between fake news, distrust, and \nreal news detection. Moreover, our approach allowed us to \nestablish that the average participant who chose to partici-\npate in the intervention already scored above the norm when \ncompleting the pretest. Moreover, for the first time, we were \nable to disentangle the five dimensions of misinformation \nsusceptibility using a validated and standardized item set, \nfinding unexpected changes in judgment biases as well as in \nreal news detection (which other research does not necessar -\nily find; see Roozenbeek & van der Linden, 2019), which can \ninspire further research and theoretical development. Never -\ntheless, we must emphasize that the MIST is a generalized  \nmeasure of susceptibility, relevant for measuring an overarch-\ning skill, which is not the sole focus of the Bad News Game \nintervention. For example, there is a wide range of evidence \nthat shows that the Bad News Game is effective at improving the detection of specific manipulation techniques that typi-\ncally underlie misinformation that the participant was trained \non (e.g., appeal to emotion, polarizing language; Roozenbeek \n& van der Linden, 2019; Lewandowsky & van der Linden, \n2021). Improvements in those specific skills can be best iden-\ntified with a tailored measurement instrument rather than a \n\u201cgeneral\u201d measure such as the MIST.\nOverall, these studies show that it is feasible to develop a \npsychometrically validated measurement instrument for mis-\ninformation susceptibility. Moreover, the evidence discussed \nin the studies, and in particular the analyses of Table\u00a0 3, Sup-\nplement S13, and Supplement S18, show clear evidence for \nthe utility\u2014or indeed superiority\u2014of the new measure com-\npared to other measures in terms of predicting outcomes.\nImplementation\nAn overview of the MIST-20, MIST-16, and MIST-8 item \nsets can be found in Supplement S21. For an implementation \nand scoring guide, please see Supplement S17. The supple-\nments can be found on the OSF repository at https:// osf. io/  \nr7phc/.\nOpen\u2011Source web application\nTo facilitate the implementation of the MIST, we pro-\ngrammed an open-source, user-friendly, online version of \nthe MIST-20, called YourMIST: an interactive self-assess-\nment tool designed for easy accessibility and repurposing by \nindividuals, researchers, and practitioners. Our implementa-\ntion of the MIST-20 utilizes the Python programming lan-\nguage and the Streamlit web development module to enable \na web-based quiz that provides personalized feedback to \nusers. The tool reports scores for each of the components of \nthe Verification done framework, accompanied by detailed \nexplanations and a comparison with the US and UK popula-\ntion scores. Our web app and the source code are publicly \naccessible for individual use and adaptation on the OSF \nrepository at https:// osf. io/ r7phc/.\nLimitations and\u00a0future research\nWhile we firmly believe that the MIST and V erification done \nmark a substantial methodological advance in the field of \nmisinformation research (Bago et\u00a0al., 2020; Batailler et\u00a0al., \n2022; Roozenbeek, Maertens et\u00a0al., 2021; Rosellini & Brown, \n2021; Zickar, 2020), it is of course not without limitations. \nAn inevitable challenge of doing any type of systematic and \nmethodologically rigorous news headline research lies in the \nfact that what might be real news at one point in time might \nbe outdated at a later point in time, while\u2014albeit admittedly \nmuch less likely\u2014what is fake news at one point in time \nmight become true or more credible at a later point in time. \n1893 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nTherefore, similar to an IQ test, it may be necessary to update \nthe MIST over time. Nevertheless, in recent studies, the MIST \nstill shows similar validity as it did 2 years ago. To illustrate, \nin a recent research project by Said et\u00a0al. (2023, in prep), a \nnew US quota sample was collected through Respondi with \n547 respondents, and both the MIST-8 and MIST-20 showed \ngood internal and predictive validity similar to the original \nsample (see Supplement S7). For example, the fit indices of the \nMIST sample collected in August 2022 (MIST-20: CFI = 0.92, \nTLI = 0.91, RMSEA = 0.039, SRMR = 0.052) showed similar\u2014\nand for some indices better\u2014fit relative to the sample col-\nlected in September 2020 (MIST-20: CFI = 0.90, TLI = 0.89, \nRMSEA = 0.041, SRMR = 0.040). Similarly, the MIST-20 was \nan even better predictor of performance on the DEPICT decep-\ntive headlines recognition task (Maertens, Roozenbeek, et\u00a0al., \n2021) in the August 2022 (r  = .64, p < .001) sample than it was \nin the April 2020 sample (r  = .50, p < .001).\nAnother related limitation concerns the inherent difficulty \nin the MIST\u2019s cross-cultural application. While we are greatly \nencouraged by our finding that the MIST appears to be an \nequally effective measure in the UK as in the US-American \ncultural context in which it was originally developed, cross-\ncultural translation poses a challenge. For obvious reasons, \na simple and direct translation may not be sufficient. At the \nsame time, while trustworthy news sources from which real \nnews items could be extracted can doubtlessly be identified \nin any language, at the time the MIST-20 was developed, \nthe GPT-2 (Radford et\u00a0al., 2019)\u2014the advanced language-\nbased neural network algorithm that we employed to generate \nfake news items\u2014was mainly trained on English language \ncorpora. Meanwhile, however, an increasing amount of new \nresearch and applications has managed to make the GPT-2 \nwork in the context of other languages (see, e.g., de Vries & \nNissim, 2020 ; Guillou, 2020 ; for promising initial applica -\ntions in Dutch, Italian, and Portuguese). Moreover, the recent \narrival of GPT-3 and GPT-4, which have support for an \nincreasingly wide range of languages, now enables the field \nto develop non-English adaptations of the MIST that will \nempower researchers around the globe to capture the com-\nplex and multifaceted reality of misinformation spread\u2014and \nresistance. Even without the GPT-2, researchers can create a \ndatabase of their own misinformation items and use the same \npsychometric techniques as outlined in this paper to come \nto a valid misinformation susceptibility test in any culture. \nTherefore, we see this paper as a proof of concept on the fea -\nsibility of using psychometrics to develop a comprehensive \nmisinformation susceptibility test in any culture.\nOne other concern that may be raised is that the MIST \nmay be confounded with general news consumption, mean-\ning that those who are more aware of the news may be more \nlikely to score high on the MIST and controlling for this \nmay reduce the MIST\u2019s predictive validity, and that mis-\ninformation news engagement is often driven by partisan polarization and outgroup derogation (Osmundsen et\u00a0al., \n2021). To investigate these concerns, we looked at data \nfrom a separate study that is currently being prepared, which \ncontains the MIST, the CMQ, and a social media misinfor -\nmation and manipulative posts discernment test (Maertens \net\u00a0al., 2022, in prep). Looking at these data (N  = 2220, US \nquota sample, Respondi), we found that the MIST was the \nsingle best predictor for manipulative headline discernment \nabove the CMQ and news consumption (not controlling \nfor news consumption: \u03b2 = 0.366, p  < .001, controlling for \nnews consumption: \u03b2 = 0.362, p < .001), that general news \nconsumption was only weakly correlated with MIST perfor -\nmance (r  = 0.218, p < .001), and that news consumption did \nnot have an impact on the MIST\u2019s predictive validity (see \nSupplement S18). In other words, the MIST discernment \nscore does reflect ecologically valid discernment, and is not \nconfounded by news consumption.\nFinally\u2014although based on the consistent results across \nsamples and time points it is unlikely that this has confounded \nthe results\u2014it should be noted that in all studies and with all \nsamples, we have excluded participants who did not com-\nplete the entire study up to the analysis of interest. This means \nthat in Study 1, the test\u2013retest reliability may be influenced \nby the type of participants who participated in the follow-up \n(i.e., long-term Prolific users), in Study 2 it is possible that \nthe construct validity findings were influenced by excluding \nparticipants who dropped out during the study, and in Study \n3 it is possible that the evaluation was influenced by some \nparticipants dropping out between the pretest and post-test.\nWe can see many more avenues for future studies using \nVerification done and the MIST. One example is the imple-\nmentation of the MIST in geo-psychological studies (Ebert \net\u00a0al., 2021; Rentfrow et\u00a0al., 2013, 2015) to identify misinfor -\nmation hotspots and covariates with national, regional, and \nlocal levels of misinformation susceptibility. Another strand \nof research may further deepen our conceptual understand-\ning of media literacy. For example, in light of the current \nfindings, it appears that veracity discernment may encom-\npass both a comparatively stable, trait-like component, and \na more malleable skill component. Future studies may more \nclearly identify this distinction and find ways to best use these \ninsights to devise effective interventions that foster better \ndetection of both fake news and real news, and in turn ulti-\nmately lead to greater genuine veracity discernment.\nFinally, we identify six immediate use cases for the MIST: \n(1) to prescreen participants for studies, (2) as a covariate to \ninvestigate subgroups (e.g., that are highly susceptible to mis-\ninformation), (3) as a control variable in a model, (4) to map \ngeographical regions to identify misinformation susceptibility \nhotspots, (5) to identify brain regions linked to misinformation \nsusceptibility, and (6) to evaluate interventions. In addition, \nwe would like to encourage the use of the V erification done \nframework as a general method to look at misinformation \n1894 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nsusceptibility and intervention effects more holistically, inde-\npendent of the measure used: indeed, we would encourage \npractitioners to use the framework with any tests.\nConclusion\nResearchers lack a unifying conceptualization of misinfor -\nmation susceptibility and too often use unvalidated measures \nof misinformation susceptibility. We therefore developed a \nnew overarching, unifying and multifaceted interpretation \nframework (i.e., Verification  done) and a new, thoroughly \nvalidated measurement instrument based on this framework \n(i.e., the Misinformation Susceptibility Test; MIST). The \ncurrent paper acts as a blueprint of integrated theory and \nassessment development, and opens the door to standard-\nized and comparative misinformation susceptibility research. \nBoth researchers and practitioners can now make a thor -\nough evaluation of media literacy interventions by compar -\ning MIST scores using the norm tables and the V erification  \ndone framework. The use of our standardized and psycho-\nmetrically validated instrument allows for a comprehensive \nevaluation, and also permits holistic comparison studies and \ntables to be compiled reporting all five V erification done \nscores. Practitioners in turn can use these scores and com-\nparisons to choose interventions that best fit their needs. \nVerification done and the MIST can be employed across a \nrange of psychological disciplines, ranging from cognitive \nneuroscience to social and personality psychology, to reveal \nthe psychological mechanisms behind susceptibility to mis-\ninformation or to test the outcome of interventions.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 3758/ s13428- 023- 02124-2.\nAuthor note Parts of the current article were presented at a conference \ntalk given by the first author at the 2021 Annual Convention of the Society \nfor Personality and Social Psychology (SPSP). A preprint of the article \nwas published on PsyArXiv at https:// doi. org/ 10. 31234/ osf. io/ gk68h.\nThe supplements, data, and analysis scripts that support this paper\u2019s \nfindings, including Qualtrics files, analysis code, raw and clean data-\nsets, and all research materials, are openly available on the Open Sci-\nence Framework (OSF) at https:// osf. io/ r7phc/. Preregistrations are \navailable on AsPredicted at https:// aspre dicted. org/ m7vb3. pdf (Study \n1, T1), https:// aspre dicted. org/ js2jz. pdf (Study 1, T2), and https:// aspre  \ndicted. org/ nx7xu. pdf (Study 2B).\nFunding This work was financially supported by the United King -\ndom Economic and Social Research Council (ESRC), the Cambridge \nTrust  (CT), the Winton Centre for Risk and Evidence Communication  \n(University of Cambridge), the German Academic Exchange Service  \n(DAAD), and the University of Virginia\u2019s 3 Cavaliers Fund and the \nCenter for Global Inquiry and Innovation.\nDeclarations  \nConflicts of interest/Competing interests The authors have no con-\nflicts of interest to declare.Ethics approval All procedures performed in studies involving human \nparticipants were in accordance with the ethical standards of the \ninstitutional and/or national research committee and with the 1964 \nHelsinki Declaration and its later amendments or comparable ethical \nstandards. The study was reviewed and approved by the Psychology \nResearch Ethics Committee of the University of Cambridge (Study 1: \nPRE.2019.108; Study 2: PRE.2019.108, PRE.2020.034, PRE.2020.086, \nPRE.2020.120; Study 3: PRE.2020.120, PRE.2020.136).\nConsent to participate Informed consent was obtained from all indi-\nvidual participants included in Study 1, Study 2, and Study 3.\nConsent for publication The authors affirm that all research participants \nprovided informed consent for the publication of the anonymized data-\nsets in Study 1 and Study 2. In Study 3, no personal data was collected.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\nAichholzer, J., & Kritzinger, S. (2016). Kurzskala politischer Zynismus \n(KPZ). [Short scale of political cynicism]. Zusammenstellung \nSozialwissenschaftlicher Items und Skalen. https:// doi. org/ 10.  \n6102/ zis245\nAird, M. J., Ecker, U. K. H., Swire, B., Berinsky, A. J., & Lewan-\ndowsky, S. (2018). Does truth matter to voters? The effects of \ncorrecting political misinformation in an Australian sample. \nRoyal Society Open Science, 5(12), Article 180593. https:// doi.  \norg/ 10. 1098/ rsos. 180593\nAnvari, F., & Lakens, D. (2021). Using anchor-based methods to deter -\nmine the smallest effect size of interest. Journal of Experimental \nSocial Psychology. Advance online publication. https:// doi. org/  \n10. 1016/j. jesp. 2021. 104159\nBago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and \nslow: Deliberation reduces belief in false (but not true) news \nheadlines. Journal of Experimental Psychology: General, 149(8), \n1608\u20131613. https:// doi. org/ 10. 1037/ xge00 00729\nBaron, J. (2019). Actively open-minded thinking in politics. Cogni -\ntion, 188 , 8\u201318. https://  doi. org/ 10. 1016/j.  cogni  tion. 2018.  10. 004\nBasol, M., Roozenbeek, J., McClanahan, P., Berriche, M., Uenal, F., \n& van der Linden, S. (2021). Towards psychological herd immu-\nnity: Cross-cultural evidence for two prebunking interventions \nagainst COVID-19 misinformation. Big Data & Society, 8 (1), \n1\u201318. https:// doi. org/ 10. 1177/ 20539 51721 10138 68\nBatailler, C., Brannon, S. M., Teas, P. E., & Gawronski, B. (2022). A \nsignal detection approach to understanding the identification of \nfake news. Perspectives on Psychological Science, 17(1), 78\u201398. \nhttps:// doi. org/ 10. 1177/ 17456 91620 986135\nBentler, P. M., & Bonett, D. G. (1980). Significance tests and good-\nness of fit in the analysis of covariance structures. Psycho-\nlogical Bulletin, 88(3), 588\u2013606. https:// doi. org/ 10. 1037/ 0033-  \n2909. 88.3. 588\n1895 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nBlock, J. (1995). A contrarian view of the five-factor approach to per -\nsonality description. Psychological Bulletin, 117(2), 187\u2013215. \nhttps:// doi. org/ 10. 1037/ 0033- 2909. 117.2. 187\nBlondel, V. D., Guillaume, J.-L., Lambiotte, R., & Lefebvre, E. \n(2008). Fast unfolding of communities in large networks. Jour -\nnal of Statistical Mechanics: Theory and Experiment, 2008(10), \nP10008. https:// doi. org/ 10. 1088/ 1742- 5468/ 2008/ 10/ P10008\nBoateng, G. O., Neilands, T. B., Frongillo, E. A., Melgar-Qui\u00f1onez, \nH. R., & Young, S. L. (2018). Best practices for developing and \nvalidating scales for health, social, and behavioral research: A \nprimer. Frontiers in Public Health, 6, 149. https:// doi. org/ 10.  \n3389/ fpubh. 2018. 00149\nBoker, S. M. (2018). Longitudinal multivariate psychology (E. Ferrer, \nS. M. Boker, & K. J. Grimm, Eds.). Routledge. https:// doi. org/  \n10. 4324/ 97813 15160 542\nBorsboom, D. (2008). Psychometric perspectives on diagnostic sys -\ntems. Journal of Clinical Psychology, 64(9), 1089\u20131108. https:// \ndoi. org/ 10. 1002/ jclp. 20503\nBorsboom, D., Cramer, A. O., Schmittmann, V. D., Epskamp, S., & \nWaldorp, L. J. (2011). The small world of psychopathology. PloS \nOne, 6(11), e27407. https:// doi. org/ 10. 1371/ journ al. pone. 00274 07\nBovet, A., & Makse, H. A. (2019). Influence of fake news in Twitter \nduring the 2016 US presidential election. Nature Communica -\ntions, 10(1), 7. https:// doi. org/ 10. 1038/ s41467- 018- 07761-2\nBrady, W. J., Wills, J. A., Jost, J. T., Tucker, J. A., & Van Bavel, J. J. \n(2017). Emotion shapes the diffusion of moralized content in \nsocial networks. Proceedings of the National Academy of Sci-\nences of the United States of America, 114(28), 7313\u20137318. \nhttps:// doi. org/ 10. 1073/ pnas. 16189 23114\nBrick, C., Hood, B., Ekroll, V., & de-Wit, L. (2022). Illusory essences: \nA bias holding back theorizing in psychological science. Per -\nspectives on Psychological Science, 17(2), 491\u2013506. https:// doi.  \norg/ 10. 1177/ 17456 91621 991838\nBrotherton, R., French, C. C., & Pickering, A. D. (2013). Measuring \nbelief in conspiracy theories: The generic conspiracist beliefs \nscale. Frontiers in Psychology, 4 , 1\u201315. https://  doi. org/ 10. 3389/  \nfpsyg. 2013. 00279\nBruder, M., Haffke, P., Neave, N., Nouripanah, N., & Imhoff, R. (2013). \nMeasuring individual differences in generic beliefs in conspiracy \ntheories across cultures: Conspiracy mentality questionnaire. \nFrontiers in Psychology, 4 (279), 1\u201315. https://  doi. org/ 10. 3389/  \nfpsyg. 2013. 00225\nBuhrmester, M. D., Talaifar, S., & Gosling, S. D. (2018). An evaluation \nof Amazon\u2019s Mechanical Turk, its rapid rise, and its effective use. \nPerspectives on Psychological Science, 13(2), 149\u2013154. https://  \ndoi. org/ 10. 1177/ 17456 91617 706516\nCampbell, D. T., & Fiske, D. W. (1959). Convergent and discriminant \nvalidation by the multitrait-multimethod matrix. Psychological \nBulletin, 56(2), 81\u2013105. https:// www. ncbi. nlm. nih. gov/ pubmed/  \n13634 291.\nCarpenter, S. (2018). Ten steps in scale development and reporting: A \nguide for researchers. Communication Methods and Measures, \n12(1), 25\u201344. https:// doi. org/ 10. 1080/ 19312 458. 2017. 13965 83\nChalmers, R. P. (2012). mirt: A multidimensional item response theory \npackage for the Renvironment. Journal of Statistical Software, \n48(6), 1\u201329. https:// doi. org/ 10. 18637/ jss. v048. i06\nChampely, S., Ekstrom, C., Dalgaard, P., Gill, J., Weibelzahl, S., \nAnandkumar, A., ... & De Rosario, M. H. (2021). pwr: Basic \nfunctions for power analysis. The Comprehensive R Archive Net -\nwork . https:// cran.r- proje ct. org/ packa ge= pwr\nChen, J., & Chen, Z. (2008). Extended Bayesian information crite-\nria for model selection with large model spaces. Biometrika, \n95(3), 759\u2013771. https:// doi. org/ 10. 1093/ biomet/ asn034\nCho\u0142oniewski, J., Sienkiewicz, J., Dretnik, N., Leban, G., Thel-\nwall, M., & Ho\u0142yst, J. A. (2020). A calibrated measure to \ncompare fluctuations of different entities across timescales. Scientific Reports, 10(1), Article 20673. https:// doi. org/ 10.  \n1038/ s41598- 020- 77660-4\nChristensen, A. P., Cotter, K. N., & Silvia, P. J. (2019). Reopening open -\nness to experience: A network analysis of four openness to expe-\nrience inventories. Journal of Personality Assessment, 101(6), \n574\u2013588. https:// doi. org/ 10. 1080/ 00223 891. 2018. 14674 28\nChristensen, A. P., Garrido, L. E., & Golino, H. (2020a). Unique \nvariable analysis: A novel approach for detecting redundant \nvariables in multivariate data. PsyArXiv. https:// doi. org/ 10.  \n31234/ osf. io/ 4kra2\nChristensen, A. P., Golino, H., & Silvia, P. J. (2020b). A psychomet-\nric network perspective on the validity and validation of per -\nsonality trait questionnaires. European Journal of Personality, \n34(6), 1095\u20131108. https:// doi. org/ 10. 1002/ per. 2265\nChristensen, A. P., & Golino, H. (2021a). Estimating the stability \nof psychological dimensions via bootstrap exploratory graph \nanalysis: A Monte Carlo simulation and tutorial. Psych, 3(3), \n479\u2013500. https:// doi. org/ 10. 3390/ psych 30300 32\nChristensen, A. P., & Golino, H. (2021b). Factor or network model? \nPredictions from neural networks. Journal of Behavioral Data \nScience, 1(1), 85\u2013126. https:// doi. org/ 10. 35566/ jbds/ v1n1/ p5\nChristensen, A. P., & Golino, H. (2021c). On the equivalency of \nfactor and network loadings. Behavior Research Methods, 53, \n1563\u20131580. https:// doi. org/ 10. 3758/ s13428- 020- 01500-6\nCichocka, A., Marchlewska, M., & de Zavala, A. G. (2016). Does \nself-love or self-hate predict conspiracy beliefs? Narcissism, \nself-esteem, and the endorsement of conspiracy theories. \nSocial Psychological and Personality Science, 7(2), 157\u2013166. \nhttps:// doi. org/ 10. 1177/ 19485 50615 616170\nCinelli, M., Quattrociocchi, W., Galeazzi, A., Valensise, C. M., \nBrugnoli, E., Schmidt, A. L., et\u00a0al. (2020). The COVID-19 \nsocial media infodemic. Scientific Reports, 10(1), 1\u201310. https://  \ndoi. org/ 10. 1038/ s41598- 020- 73510-5\nCinelli, M., De Francisci Morales, G., Galeazzi, A., Quattrociocchi, \nW., & Starnini, M. (2021). The echo chamber effect on social \nmedia. Proceedings of the National Academy of Sciences of \nthe United States of America, 118(9), e2023301118. https://  \ndoi. org/ 10. 1073/ pnas. 20233 01118\nClark, L. A., & Watson, D. (1995). Constructing validity: Basic issues \nin objective scale development. Psychological Assessment, 7(3), \n309\u2013319. https:// doi. org/ 10. 1037// 1040- 3590.7. 3. 309\nClark, L. A., & Watson, D. (2019). Constructing validity: New develop-\nments in creating objective measuring instruments. Psychological \nAssessment, 31 (12), 1412\u20131427. https://  doi. org/ 10. 1037/  pas00  00626\nCokely, E. T., Galesic, M., Schulz, E., Ghazal, S., & Garcia-Retamero, \nR. (2012). Measuring risk literacy: The Berlin numeracy test. \nJudgment and Decision Making, 7(1), 25\u201347. http:// journ al. sjdm.  \norg/ 11/ 11808/ jdm11 808. pdf\nComrey, A. L., & Lee, H. B. (1992). A first course in factor analysis  \n(2nd ed.). Erlbaum Associates\nCondon, D. M., Wood, D., M\u00f5ttus, R., Booth, T., Costantini, G., Greiff, \nS., ..., Zimmermann, J. (2020). Bottom up construction of a per -\nsonality taxonomy. European Journal of Psychological Assess -\nment, 36(6), 923\u2013934. https:// doi. org/ 10. 1027/ 1015- 5759/ a0006 26\nCook, J., Lewandowsky, S., & Ecker, U. K. H. (2017). Neutralizing \nmisinformation through inoculation: Exposing misleading argu-\nmentation techniques reduces their influence. PloS One, 12(5), \ne0175799. https:// doi. org/ 10. 1371/ journ al. pone. 01757 99\nCostello, A. B., & Osborne, J. (2005). Best practices in exploratory \nfactor analysis: Four recommendations for getting the most \nfrom your analysis, Practical Assessment, Research, and Eval-\nuation, 10(1), 7. https:// doi. org/ 10. 7275/ jyj1- 4868\nCramer, A. O. (2012). Why the item \u201c23+ 1\u201d is not in a depression \nquestionnaire: Validity from a network perspective. Meas-\nurement: Interdisciplinary Research & Perspective, 10 (1-2), \n50\u201354. https:// doi. org/ 10. 1080/ 15366 367. 2012. 681973\n1896 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nCramer, A., Waldorp, L. J., Van Der Maas, H. L., & Borsboom, D. \n(2010). Comorbidity: A network perspective. Behavioral and \nBrain Sciences, 33(2-3), 137\u2013150. https:// doi. org/ 10. 1017/  \nS0140 525X0 99915 67\nCronbach, L. J., & Meehl, P. E. (1955). Construct validity in psycho-\nlogical tests. Psychological Bulletin, 52(4), 281\u2013302. https://  \ndoi. org/ 10. 1037/ h0040 957\nCurley, A. (2020). How to use GPT-2 in Google Colab. The Startup. \nhttps:// medium. com/ swlh/ how- to- use- gpt-2- in- google- colab-  \nde44f 59199 c1\nCurran, P. J., Bollen, K. A., Chen, F., Paxton, P., & Kirby, J. B. (2003). \nFinite sampling properties of the point estimates and confidence \nintervals of the RMSEA. Sociological Methods & Research, \n32(2), 208\u2013252. https:// doi. org/ 10. 1177/ 00491 24103 256130\nde Vries, W., & Nissim, M. (2020). As good as new: How to success-\nfully recycle English GPT-2 to make models for other languages. \nArXiv. https:// arxiv. org/ abs/ 2012. 05628. Accessed\u00a010 Dec 2020.\nDeffner, D., Rohrer, J. M., & McElreath, R. (2022). A causal frame-\nwork for cross-cultural generalizability. Advances in Methods \nand Practices in Psychological Science, 5(3), 1\u201318. https:// doi.  \norg/ 10. 1177/ 25152 45922 11063 66\nDhami, M. K., Hertwig, R., & Hoffrage, U. (2004). The role of rep-\nresentative design in an ecological approach to cognition. Psy-\nchological Bulletin, 130(6), 959\u2013988. https:// doi. org/ 10. 1037/  \n0033- 2909. 130.6. 959\nD\u00fcr, A., & Schlipphak, B. (2021). Elite cueing and attitudes towards trade \nagreements: The case of TTIP. European Political Science Review, \n13(1), 41\u201357. https:// doi. org/ 10. 1017/ S1755 77392 00003 4X\nEbert, T., G\u00f6tz, F. M., Gladstone, J. J., M\u00fcller, S. R., & Matz, S. C. \n(2021). Spending reflects not only who we are but also who we \nare around: The joint effects of individual and geographic per -\nsonality on consumption. Journal of Personality and Social Psy -\nchology, 121(2), 378\u2013393. https:// doi. org/ 10. 1037/ pspp0 000344\nEpskamp, S., & Fried, E. (2018). A tutorial on regularized partial \ncorrelation networks. Psychological Methods, 23(4), 617\u2013634. \nhttps:// doi. org/ 10. 1037/ met00 00167\nEpskamp, S., Maris, G., Waldorp, L. J., & Borsboom, D. (2018). Net-\nwork psychometrics. In B. Irwing Paul (Ed.), The Wiley hand-\nbook of psychometric testing: A multidisciplinary reference on \nsurvey, scale and test development (pp. 953\u2013986). John Wiley & \nSons Ltd.. https:// doi. org/ 10. 1002/ 97811 18489 772. ch30\nEpskamp, S., Rhemtulla, M., & Borsboom, D. (2017). Generalized \nnetwork psychometrics: Combining network and latent variable \nmodels. Psychometrika, 82(4), 904\u2013927. https:// doi. org/ 10. 1007/  \ns11336- 017- 9557-x\nEysenck, H. J. (1967). The biological basis of personality. Thomas\nFabrigar, L. R., Wegener, D. T., MacCallum, R. C., & Strahan, E. \nJ. (1999). Evaluating the use of exploratory factor analysis in \npsychological research. Psychological Methods, 4(3), 272\u2013299. \nhttps:// doi. org/ 10. 1037/ 1082- 989X.4. 3. 272\nFazio, L. K. (2020). Pausing to consider why a headline is true or false can \nhelp reduce the sharing of false news. Harvard Kennedy School Mis-\ninformation Review, 1(2), 1\u20138. https:// doi. org/ 10. 37016/ mr- 2020- 009\nFinch, J. F., & West, S. G. (1997). The investigation of personality \nstructure: Statistical models. Journal of Research in Personality, \n31(4), 439\u2013485. https:// doi. org/ 10. 1006/ jrpe. 1997. 2194\nFlake, J. K., Pek, J., & Hehman, E. (2017). Construct validation in \nsocial and personality research: Current practice and recom-\nmendations. Social Psychological and Personality Science, 8(4), \n370\u2013378. https:// doi. org/ 10. 1177/ 19485 50617 693063\nFord, J. K., MacCallum, R. C., & Tait, M. (1986). The application \nof exploratory factor analysis in applied psychology: A criti-\ncal review and analysis. Personnel Psychology, 39(2), 291\u2013314. \nhttps:// doi. org/ 10. 1111/j. 1744- 6570. 1986. tb005 83.x\nFrederick, S. (2005). Cognitive reflection and decision making. The \nJournal of Economic Perspectives: A Journal of the American Economic Association, 19(4), 25\u201342. https:// doi. org/ 10. 1257/  \n08953 30057 75196 732\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psycho-\nlogical research: Sense and nonsense. Advances in Methods and \nPractices in Psychological Science, 2(2), 156\u2013168. https:// doi.  \norg/ 10. 1177/ 25152 45919 847202\nGolino, H. F., & Demetriou, A. (2017). Estimating the dimensionality \nof intelligence like data using exploratory graph analysis. Intel-\nligence, 62, 54\u201370. https:// doi. org/ 10. 1016/j. intell. 2017. 02. 007\nGolino, H. F., & Epskamp, S. (2017). Exploratory graph analysis: A \nnew approach for estimating the number of dimensions in psy -\nchological research. PloS One, 12(6), e0174035. https://  doi. org/  \n10. 1371/ journ al. pone. 01740 35\nGolino, H. F., & Christensen, A. P. (2019). EGAnet: Exploratory graph \nanalysis: A framework for estimating the number of dimensions in \nmultivariate data using network psychometrics. The Comprehensive \nR Archive Network. https:// cran.r- proje ct. org/ packa ge= EGAnet\nGolino, H. F., Christensen, A. P., & Garrido, L. E. (2022). Exploratory \ngraph analysis in context. Revista Psicologia: Teoria e Pr\u00e1tica, 24(3), \nePTPPA14197. https:// doi. org/ 10. 5935/ 1980- 6906/ ePTPI C15531. en\nGolino, H. F., Lillard, A. S., Becker, I., & Christensen, A. P. (2021). \nInvestigating the structure of the children\u2019s concentration and \nempathy scale using exploratory graph analysis. Psychological \nTest Adaptation and Development, 2(1), 35\u201349. https:// doi. org/  \n10. 1027/ 2698- 1866/ a0000 08\nGolino, H. F., Moulder, R., Shi, D., Christensen, A., Garrido, L., Neto, \nM., et\u00a0al. (2020a). Entropy fit indices: New fit measures for assess-\ning the structure and dimensionality of multiple latent variables. \nMultivariate Behavioral Research, 56(6), 874\u2013902. https:// doi. org/  \n10. 1080/ 00273 171. 2020. 17796 42\nGolino, H. F., Shi, D., Garrido, L. E., Christensen, A. P., Nieto, M. \nD., Sadana, R., et\u00a0al. (2020b). Investigating the performance of \nexploratory graph analysis and traditional techniques to identify \nthe number of latent factors: A simulation and tutorial. Psychologi-\ncal Methods, 25(3), 292\u2013230. https:// doi. org/ 10. 1037/ met00 00255\nGoretzko, D., Pham, T. T. H., & B\u00fchner, M. (2021). Exploratory fac-\ntor analysis: Current use, methodological developments and \nrecommendations for good practice. Current Psychology, 40(7), \n3510\u20133521. https:// doi. org/ 10. 1007/ s12144- 019- 00300-2\nG\u00f6tz, F. M., Maertens, R., Loomba, S., & van der Linden, S. (2023). \nLet the algorithm speak: How to use neural networks for auto-\nmatic item generation in psychological scale development. Psy-\nchological Methods. Advance online publication. https:// doi. org/  \n10. 1037/ met00 00540\nG\u00f6tz, F. M., Gosling, S. D., & Rentfrow, P. J. (2022). Small effects: \nThe indispensable foundation for a cumulative psychological \nscience. Perspectives on Psychological Science, 17(1), 205\u2013\n215. https:// doi. org/ 10. 1177/ 17456 91620 9844\nGraham, J., Nosek, B. A., Haidt, J., Iyer, R., Koleva, S., & Ditto, P. \nH. (2011). Mapping the moral domain. Journal of Personality \nand Social Psychology, 101(2), 366\u2013385. https:// doi. org/ 10.  \n1037/ a0021 847\nGuadagnoli, E., & Velicer, W. F. (1988). Relation of sample size to \nthe stability of component patterns. Psychological Bulletin, \n103(2), 265\u2013275. https:// doi. org/ 10. 1037/ 0033- 2909. 103.2. 265\nGuess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., \nReifler, J., & Sircar, N. (2020). A digital media literacy inter -\nvention increases discernment between mainstream and false \nnews in the United States and India. Proceedings of the National \nAcademy of Sciences of the United States of America, 117(27), \n15536\u201315545. https:// doi. org/ 10. 1073/ pnas. 19204 98117\nGrzesiak-Feldman, M. (2013). The effect of high-anxiety situations \non conspiracy thinking. Current Psychology, 32(1), 100\u2013118. \nhttps:// doi. org/ 10. 1007/ s12144- 013- 9165-6\nGuillou, P. (2020). Faster than training from scratch \u2014 Fine-tuning the \nEnglish GPT-2 in any language with Hugging Face and fastai v2 \n1897 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\n(practical case with Portuguese) . Medium. https://  medium.  com/@  \npierre_ guill ou/ faster- than- train ing- from- scrat ch- fine- tuning- the-  \nengli sh- gpt-2- in- any- langu age- with- huggi ng- f2ec0 5c987 87\nHair, J. F., Anderson, R. E., Babin, B. J., & Black, W. C. (2010). Mul-\ntivariate data analysis: A global perspective (7th ed.). Pearson\nHaynes, S. N., Richard, D. C. S., & Kubany, E. S. (1995). Content \nvalidity in psychological assessment: A functional approach to \nconcepts and methods. Psychological Assessment, 7(3), 238\u2013247. \nhttps:// doi. org/ 10. 1037/ 1040- 3590.7. 3. 238\nHeinsohn, T., Fatke, M., Israel, J., Marschall, S., & Schultze, M. \n(2019). Effects of voting advice applications during election \ncampaigns: Evidence from a panel study at the 2014 European \nelections. Journal of Information Technology & Politics, 16(3), \n250\u2013264. https:// doi. org/ 10. 1080/ 19331 681. 2019. 16442 65\nHo, A. K., Sidanius, J., Kteily, N., Sheehy-Skeffington, J., Pratto, F., \nHenkel, K. E., Foels, R., & Stewart, A. L. (2015). The nature of \nsocial dominance orientation: Theorizing and measuring prefer -\nences for intergroup inequality using the new  SDO7 scale. Jour -\nnal of Personality and Social Psychology, 109(6), 1003\u20131028. \nhttps:// doi. org/ 10. 1037/ pspi0 000033\nHofstee, W. K., de Raad, B., & Goldberg, L. R. (1992). Integration of \nthe big five and circumplex approaches to trait structure. Journal \nof Personality and Social Psychology, 63(1), 146\u2013163. https://  \ndoi. org/ 10. 1037// 0022- 3514. 63.1. 146\nHolland, P. W., & Wainer, H. (Eds.). (1993). Differential item func-\ntioning. Lawrence Erlbaum. https:// psycn et. apa. org/ record/  \n1993- 97193- 000\nHommel, B. E., Wollang, F. J. M., Kotova, V., Zacher, H., & Schmukle, \nS. C. (2022). Transformer-based deep neural language modeling \nfor construct-specific automatic item generation. Psychometrika, \n87(2), 749\u2013772. https:// doi. org/ 10. 1007/ s11336- 021- 09823-9\nHorn, J. L. (1965). A rationale and test for the number of factors in \nfactor analysis. Psychometrika, 30(2), 179\u2013185. https:// doi. org/  \n10. 1007/ BF022 89447\nHotez, P., Batista, C., Ergonul, O., Figueroa, J. P., Gilbert, S., Gursel, \nM., Hassanain, M., Kang, G., Kim, J. H., Lall, B., Larson, H., \nNaniche, D., Sheahan, T., Shoham, S., Wilder-Smith, A., Strub-\nWourgaft, N., Yadav, P., & Bottazzi, M. E. (2021). Correcting \nCOVID-19 vaccine misinformation. EClinicalMedicine, 33, \nArticle 100780. https:// doi. org/ 10. 1016/j. eclinm. 2021. 100780\nHu, L., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covari-\nance structure analysis: Conventional criteria versus new alterna-\ntives. Structural Equation Modeling: A Multidisciplinary Jour -\nnal, 6(1), 1\u201355. https:// doi. org/ 10. 1080/ 10705 51990 95401 18\nHumphreys, L. G., & Ilgen, D. R. (1969). Note on a criterion for the \nnumber of common factors. Educational and Psychological \nMeasurement, 29(3), 571\u2013578. https:// doi. org/ 10. 1177/ 00131  \n64469 02900 303\nJamison, L., Golino, H., & Christensen, A. P. (2022). Metric invariance \nin exploratory graph analysis via permutation testing. PsycArxiv.  \nhttps:// doi. org/ 10. 31234/ osf. io/ j4rx9\nJimenez, M., Abad, F. J., Garcia-Garzon, E., Golino, H., Christensen, \nA. P., & Garrido, L. E. (2022). Dimensionality assessment in \ngeneralized bi-factor structures: A network psychometrics \napproach. PsyArXiv. https:// doi. org/ 10. 31234/ osf. io/ 2ujdk\nJolley, D., & Paterson, J. L. (2020). Pylons ablaze: Examining the role \nof 5G COVID-19 conspiracy beliefs and support for violence. \nBritish Journal of Social Psychology, 59(3), 628\u2013640. https://  \ndoi. org/ 10. 1111/ bjso. 12394\nKonrath, S., Meier, B. P., & Bushman, B. J. (2014). Development and val-\nidation of the Single Item Narcissism Scale (SINS). PloS One, 9(8), \nArticle e103469. https:// doi. org/ 10. 1371/ journ al. pone. 01034 69\nKumareswaran, D. J. (2014). The psychopathological foundations of \nconspiracy theorists. Victoria University of Wellington.\u00a0 http://  \nhdl. handle. net/ 10063/ 3603\nLauritzen, S. L. (1996). Graphical models (Vol. 17). Clarendon Press.Lawson, A., & Kakkar, H. (2021). Of pandemics, politics, and personal-\nity: The role of conscientiousness and political ideology in shar -\ning of fake news. PsyArXiv. https:// doi. org/ 10. 31234/ osf. io/ ves5m\nLewandowsky, S., Ecker, U. K. H., & Cook, J. (2017). Beyond misin-\nformation: Understanding and coping with the \u201cpost-truth\u201d era. \nJournal of Applied Research in Memory and Cognition, 6 (4), \n353\u2013369. https:// doi. org/ 10. 1016/j. jarmac. 2017. 07. 008\nLewandowsky, S., Smillie, L., Garcia, D., Hertwig, R., Weatherall, J., \nEgidy, S., Robertson, R. E., O\u2019Connor, C., Kozyreva, A., Lorenz-\nSpreen, P., Blaschke, Y., & Leiser, M. R. (2020). Technology and \ndemocracy: Understanding the influence of online technologies \non political behaviour and decision-making. Publications Office \nof the European Union. https:// doi. org/ 10. 2760/ 709177\nLewandowsky, S., & van der Linden, S. (2021). Countering misin-\nformation and fake news through inoculation and prebunking. \nEuropean Review of Social Psychology, 32(2), 348\u2013384. https://  \ndoi. org/ 10. 1080/ 10463 283. 2021. 18769 83\nLitman, L., Robinson, J., & Abberbock, T. (2017). TurkPrime.com: A \nversatile crowdsourcing data acquisition platform for the behav -\nioral sciences. Behavior Research Methods, 49(2), 433\u2013442. \nhttps:// doi. org/ 10. 3758/ s13428- 016- 0727-z\nLoevinger, J. (1957). Objective tests as instruments of psychological \ntheory. Psychological Reports, 3(3), 635\u2013694. https:// doi. org/ 10.  \n2466/ pr0. 1957.3. 3. 635\nLoomba, S., de Figueiredo, A., Piatek, S. J., de Graaf, K., & Larson, \nH. J. (2021). Measuring the impact of COVID-19 vaccine mis-\ninformation on vaccination intent in the UK and USA. Nature \nHuman Behaviour, 5(3), 337\u2013348. https:// doi. org/ 10. 1038/  \ns41562- 021- 01056-1\nMarsman, M., Borsboom, D., Kruis, J., Epskamp, S., van Bork, R., \nWaldorp, L., et\u00a0al. (2018). An introduction to network psycho-\nmetrics: Relating Ising network models to item response theory \nmodels. Multivariate Behavioral Research, 53(1), 15\u201335.\nMcNeish, D., & Wolf, M. G. (2021). Dynamic fit index cutoffs for \nconfirmatory factor analysis models. Psychological Methods. \nAdvance online publication. https:// doi. org/ 10. 1037/  met00  00425\nMaertens, R., Anseel, F., & van der Linden, S. (2020). Combatting \nclimate change misinformation: Evidence for longevity of inocu-\nlation and consensus messaging effects. Journal of Environmen-\ntal Psychology, 70, 101455. https:// doi. org/ 10. 1016/j. jenvp. 2020.  \n101455\nMaertens, R., Roozenbeek, J., Basol, M., & van der Linden, S. (2021). \nLong-term effectiveness of inoculation against misinformation: \nThree longitudinal experiments. Journal of Experimental Psy -\nchology: Applied, 27(1), 1\u201316. https:// doi. org/ 10. 1037/ xap00  \n00315\nMaertens, R., Roozenbeek, J., Simons, J., Lewandowsky, S., Maturo, \nV., Goldberg, B., ...,, van der Linden, S. (2022). Psychological \nbooster shots targeting memory increase long-term resistance \nagainst misinformation. [Manuscript in preparation]\nMarkon, K. E. (2019). Bifactor and hierarchical models: Specifica -\ntion, inference, and interpretation. Annual Review of Clinical \nPsychology, 15, 51\u201369. https:// doi. org/ 10. 1146/ annur  ev- clinp  \nsy- 050718- 095522\nMcDonald, R. P. (1999). Test theory: A unified treatment. Psychology \nPress. https:// doi. org/ 10. 4324/ 97814 10601 087\nMeehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir Karl, \nSir Ronald, and the slow progress of soft psychology. Journal \nof Consulting and Clinical Psychology, 46(4), 806\u2013834. https://  \ndoi. org/ 10. 1037/ 0022- 006X. 46.4. 806\nNasser, M. A. (2020) Step-by-step guide on how to train GPT-2 on \nbooks using Google Colab. Towards Data Science. https://\ntowardsdatascience.com/step-by-step-guide-on-how-to-train-\ngpt-2-on-books-using-google-colab-b3c6fa15fef0\nNguyen, T. H., Han, H.-R., Kim, M. T., & Chan, K. S. (2014). An intro-\nduction to item response theory for patient-reported outcome \n1898 Behavior Research Methods (2024) 56:1863\u20131899\n1 3\nmeasurement. The Patient, 7(1), 23\u201335. https://  doi. org/ 10. 1007/  \ns40271- 013- 0041-0\nNorenzayan, A., & Hansen, I. G. (2006). Belief in supernatural agents \nin the face of death. Personality & Social Psychology Bulletin, \n32(2), 174\u2013187. https:// doi. org/ 10. 1177/ 01461 67205 280251\nOsmundsen, M., Bor, A., Vahlstrup, P. B., Bechmann, A., & Petersen, \nM. B. (2021). Partisan polarization is the primary psychological \nmotivation behind political fake news sharing on Twitter. Ameri-\ncan Political Science Review, 115(3), 999\u20131015. https:// doi. org/  \n10. 1017/ S0003 05542 10002 90\nPalan, S., & Schitter, C. (2018). Prolific.ac\u2014A subject pool for online \nexperiments. Journal of Behavioral and Experimental Finance, \n17, 22\u201327. https:// doi. org/ 10. 1016/j. jbef. 2017. 12. 004\nPaulhus, D. L., Buckels, E. E., Trapnell, P. D., & Jones, D. N. (2020). \nScreening for dark personalities. European Journal of Psycho -\nlogical Assessment, 37(3), 208\u2013222. https:// doi. org/ 10. 1027/  \n1015- 5759/ a0006 02\nPeer, E., Brandimarte, L., Samat, S., & Acquisti, A. (2017). Beyond \nthe Turk: Alternative platforms for crowdsourcing behavioral \nresearch. Journal of Experimental Social Psychology, 70, 153\u2013\n163. https:// doi. org/ 10. 1016/j. jesp. 2017. 01. 006\nPennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021a). A \npractical guide to doing behavioral research on fake news and \nmisinformation. Collabra: Psychology, 7(1), 25293. https:// doi.  \norg/ 10. 1525/ colla bra. 25293\nPennycook, G., Cheyne, J. A., Barr, N., Koehler, D. J., & Fugelsang, \nJ. A. (2015). On the reception and detection of pseudo-profound \nbullshit. Judgment and Decision Making,  10(6), 549\u2013563. http:// \njourn al. sjdm. org/ 15/ 15923a/ jdm15 923a. pdf\nPennycook, G., Epstein, Z., Mosleh, M., Arechar, A. A., Eckles, D., & \nRand, D. G. (2021b). Shifting attention to accuracy can reduce \nmisinformation online. Nature, 592, 590\u2013595. https:// doi. org/ 10.  \n1038/ s41586- 021- 03344-2\nPennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., & Rand, D. G. \n(2020). Fighting COVID-19 misinformation on social media: \nExperimental evidence for a scalable accuracy-nudge interven-\ntion. Psychological Science, 31(7), 770\u2013780. https:// doi. org/ 10.  \n1177/ 09567 97620 939054\nPennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility \nto partisan fake news is better explained by lack of reasoning than \nby motivated reasoning. Cognition, 188, 39\u201350. https:// doi. org/  \n10. 1016/j. cogni tion. 2018. 06. 011\nPennycook, G., & Rand, D. G. (2020). Who falls for fake news? The \nroles of bullshit receptivity, overclaiming, familiarity, and ana-\nlytic thinking. Journal of Personality, 88(2), 185\u2013200. https://  \ndoi. org/ 10. 1111/ jopy. 12476\nPennycook, G., & Rand, D. G. (2021). The psychology of fake news. \nTrends in Cognitive Sciences, 25(5), 388\u2013402. https:// doi. org/ 10.  \n1016/j. tics. 2021. 02. 007\nPituch, K. A., & Stevens, J. P. (2015). Applied multivariate statistics \nfor the social sciences: Analyses with SAS and IBM\u2019s SPSS. Rout-\nledge. https:// doi. org/ 10. 4324/ 97813 15814 919\nPons, P., & Latapy, M. (2005). Computing communities in large net-\nworks using random walks. In Pi. Yolum, T. G\u00fcng\u00f6r, F. G\u00fcrgen, \n& C. \u00d6zturan (Eds.), Computer and information sciences - ISCIS \n2005 (pp. 284\u2013293). Berlin, Heidelberg: Springer. https:// doi. org/  \n10. 1007/ 11569 596_ 31\nPreskill, J. (2018). Quantum Shannon entropy. In J. Preskill (Ed.), \nQuantum information (p. 94). Cambridge University Press. \nhttps:// arxiv. org/ pdf/ 1604. 07450. pdf\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. \n(2019). Language models are unsupervised multitask learners. \nhttps:// d4muc fpksy wv. cloud front. net/ better- langu age- models/  \nlangu age- models. pdf\nRammstedt, B., Lechner, C. M., & Danner, D. (2021). Short forms do \nnot fall short: A comparison of three (extra-)short forms of the Big Five. European Journal of Psychological Assessment, 37(1), \n23\u201332. https:// doi. org/ 10. 1027/ 1015- 5759/ a0005 74\nReise, S. P., Widaman, K. F., & Pugh, R. H. (1993). Confirmatory \nfactor analysis and item response theory: Two approaches for \nexploring measurement invariance. Psychological Bulletin, \n114(3), 552\u2013566. https:// doi. org/ 10. 1037/ 0033- 2909. 114.3. 552\nRentfrow, P. J., Gosling, S. D., Jokela, M., Stillwell, D. J., Kosinski, \nM., & Potter, J. (2013). Divided we stand: Three psychological \nregions of the United States and their political, economic, social, \nand health correlates. Journal of Personality and Social Psychol-\nogy, 105(6), 996\u20131012. https:// doi. org/ 10. 1037/ a0034 434\nRentfrow, P. J., Jokela, M., & Lamb, M. E. (2015). Regional personality \ndifferences in Great Britain. PloS One, 10(3), e0122245. https://  \ndoi. org/ 10. 1371/ journ al. pone. 01222 45\nRevelle, W. (2021). psych: Procedures for psychological, psychometric, \nand personality research. The Comprehensive R Archive Network.  \nhttps:// cran.r- proje ct. org/ packa ge= psych\nRevelle, W., & Condon, D. M. (2019). Reliability from \u03b1 to \u03c9: A tuto-\nrial. Psychological Assessment, 31(12), 1395\u20131411. https:// doi.  \norg/ 10. 1037/ pas00 00754\nRobins, R. W., Hendin, H. M., & Trzesniewski, K. H. (2001). Measuring \nglobal self-esteem: Construct validation of a single-item measure and \nthe Rosenberg self-esteem scale. Personality & Social Psychology \nBulletin, 27(2), 151\u2013161. https:// doi. org/ 10. 1177/ 01461 67201 272002\nRoozenbeek, J., Culloty, E., & Suiter, J. (2023). Countering misinfor -\nmation: Evidence, knowledge gaps, and implications of current \ninterventions. European Psychologist. In press. https:// doi. org/  \n10. 31234/ osf. io/ b52um\nRoozenbeek, J., Freeman, A. L. J., & van der Linden, S. (2021a). How \naccurate are accuracy nudges? A pre-registered direct replica-\ntion of Pennycook et\u00a0al. (2020). Psychological Science, 32(7), \n1169\u20131178. https:// doi. org/ 10. 1177/ 09567 97621 10245 35\nRoozenbeek, J., Maertens, R., Herzog, S., Geers, M., Kurvers, R., \nSultan, M., & van der Linden, S. (2022). Susceptibility to mis-\ninformation is consistent across question framings and response \nmodes and better explained by myside bias and partisanship than \nanalytical thinking. Judgment and Decision Making, 17(3), 547\u2013\n573. http:// journ al. sjdm. org/ 22/ 220228/ jdm22 0228. pdf\nRoozenbeek, J., Maertens, R., McClanahan, W., & van der Linden, S. \n(2021b). Disentangling item and testing effects in inoculation \nresearch on online misinformation: Solomon revisited. Educa-\ntional and Psychological Measurement, 81(2), 340\u2013362. https://  \ndoi. org/ 10. 1177/ 00131 64420 940378\nRoozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. \nJ., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). \nSusceptibility to misinformation about COVID-19 around the \nworld. Royal Society Open Science, 7(10), 201199. https:// doi.  \norg/ 10. 1098/ rsos. 201199\nRoozenbeek, J., & van der Linden, S. (2019). Fake news game con -\nfers psychological resistance against online misinformation. \nPalgrave Communications, 5 (1), 65. https://  doi. org/ 10. 1057/  \ns41599- 019- 0279-9\nRoozenbeek, J., & van der Linden, S. (2020). Breaking Harmony \nSquare: A game that \u201cinoculates\u201d against political misinforma-\ntion. Harvard Kennedy School Misinformation Review, 1 (8), \n1\u201326. https:// doi. org/ 10. 37016/ mr- 2020- 47\nRosellini, A. J., & Brown, T. A. (2021). Developing and validating clin-\nical questionnaires. Annual Review of Clinical Psychology, 17, \n55\u201381. https:// doi. org/ 10. 1146/ annur  ev- clinp sy- 081219- 115343\nRosseel, Y. (2012). lavaan: An R package for structural equation mod-\neling and more. Journal of Statistical Software, 48(2), 1\u201336. \nhttps:// doi. org/ 10. 18637/ jss. v048. i02\nSaid, N., Maertens, R., J\u00fcrgen, B., & Roozenbeek, J. (2023). The \nManipulative Online Content Recognition Inventory (MOCRI). \n[Manuscript in preparation]\n1899 Behavior Research Methods (2024) 56:1863\u20131899 \n1 3\nSass, D. A., & Schmitt, T. A. (2010). A comparative investigation of \nrotation criteria within exploratory factor analysis. Multivariate \nBehavioral Research, 45(1), 73\u2013103. https:// doi. org/ 10. 1080/  \n00273 17090 35048 10\nSatorra, A. (2000). Scaled and adjusted restricted tests in multi-sample \nanalysis of moment structures. In Innovations in multivariate \nstatistical analysis  (pp. 233\u2013247). Springer. https:// doi. org/ 10. \n1007/ 978-1- 4615- 4603-0_ 17\nSchmalbach, B., Irmer, J. P., & Schultze, M. (2019). ezCutoffs: Fit \nmeasure cutoffs in SEM. The Comprehensive R Archive Network. \nhttps:// cran.r- proje ct. org/ packa ge= ezCut  offs\nSchumacker, R. E., Lomax, R. G., & Schumacker, R. (2015). A begin-\nner\u2019s guide to structural equation modeling (4th ed.). Routledge. \nhttps:// www. routl edge. com/A- Begin ners- Guide- to- Struc tural-  \nEquat ion- Model ing- Fourth- Editi on/ Schum acker- Lomax- Schum  \nacker- Lomax/p/ book/ 97811 38811 935. Accessed 10 Dec 2020.\nSchwartz, L. M., Woloshin, S., Black, W. C., & Welch, H. G. (1997). \nThe role of numeracy in understanding the benefit of screening \nmammography. Annals of Internal Medicine, 127(11), 966\u2013972. \nhttps:// doi. org/ 10. 7326/ 0003- 4819- 127- 11- 19971 2010- 00003\nShi, D., DiStefano, C., McDaniel, H. L., & Jiang, Z. (2018). Examining chi-\nsquare test statistics under conditions of large model size and ordinal \ndata. Structural Equation Modeling: A Multidisciplinary Journal, \n25(6), 924\u2013945. https:// doi. org/ 10. 1080/ 10705 511. 2018. 14496 53\nSimms, L. J. (2008). Classical and modern methods of psychological \nscale construction. Social and Personality Psychology Compass, \n2(1), 414\u2013433. https:// doi. org/ 10. 1111/j. 1751- 9004. 2007. 00044.x\nSindermann, C., Elhai, J. D., Moshagen, M., & Montag, C. (2020). Age, \ngender, personality, ideological attitudes and individual differences \nin a person\u2019s news spectrum: How many and who might be prone \nto \u201cfilter bubbles\u201d and \u201cecho chambers\u201d online? Heliyon, 6(1), \nArticle e03214. https:// doi. org/ 10. 1016/j. heliy  on. 2020. e03214\nSoto, C. J., & John, O. P. (2017). Short and extra-short forms of the Big \nFive Inventory\u20132: The BFI-2-S and BFI-2-XS. Journal of Research \nin Personality, 68, 69\u201381. https:// doi. org/ 10. 1016/j. jrp. 2017. 02. 004\nSteiner, M., & Grieder, S. (2020). EFAtools: An R package with fast \nand flexible implementations of exploratory factor analysis tools. \nJournal of Open Source Software, 5(53), 2521. https:// doi. org/  \n10. 21105/ joss. 02521\nStrauss, M. E., & Smith, G. T. (2009). Construct validity: Advances in \ntheory and methodology. Annual Review of Clinical Psychology, \n5, 1\u201325. https:// doi. org/ 10. 1146/ annur  ev. clinp sy. 032408. 153639\nSwami, V., Chamorro-Premuzic, T., & Furnham, A. (2010). Unanswered \nquestions: A preliminary investigation of personality and individual \ndifference predictors of 9/11 conspiracist beliefs. Applied Cogni-\ntive Psychology, 24(6), 749\u2013761. https:// doi. org/ 10. 1002/ acp. 1583\nSwami, V., Furnham, A., Smyth, N., Weis, L., Lay, A., & Clow, A. \n(2016). Putting the stress on conspiracy theories: Examining \nassociations between psychological stress, anxiety, and belief in \nconspiracy theories. Personality and Individual Differences, 99, \n72\u201376. https:// doi. org/ 10. 1016/j. paid. 2016. 04. 084\nSwire, B., Berinsky, A. J., Lewandowsky, S., & Ecker, U. K. H. (2017). \nProcessing political misinformation: Comprehending the Trump \nphenomenon. Royal Society Open Science, 4(3), 160802. https:// \ndoi. org/ 10. 1098/ rsos. 160802\nTabachnick, B. G., & Fidell, L. S. (2007). Using multivariate sta-\ntistics (5th ed.). Pearson. https://  psycn  et. apa. org/ record/  \n2006- 03883- 000\nThalmayer, A. G., Saucier, G., & Eigenhuis, A. (2011). Compara-\ntive validity of brief to medium-length Big Five and Big Six \nPersonality Questionnaires. Psychological Assessment, 23(4), \n995\u20131009. https:// doi. org/ 10. 1037/ a0024 165\nThurstone, L. L. (1944). Second-order factors. Psychometrika, 9(2), \n71\u2013100. https:// doi. org/ 10. 1007/ BF022 88715Uenal, F., Sidanius, J., Maertens, R., Hudson, S. K. T., Davis, G., & \nGhani, A. (2022). The roots of ecological dominance orientation: \nAssessing individual preferences for an anthropocentric and hier -\narchically organized world. Journal of Environmental Psychol-\nogy, 81, 101783. https:// doi. org/ 10. 1016/j. jenvp. 2022. 101783\nVan Bavel, J. J., Harris, E. A., P\u00e4rnamets, P., Rathje, S., Doell, K., & \nTucker, J. A. (2020). Political psychology in the digital (mis)\ninformation age: A model of news belief and sharing. PsyArXiv.  \nhttps:// doi. org/ 10. 31234/ osf. io/ u5yts\nvan der Linden, S., Leiserowitz, A., Rosenthal, S., & Maibach, E. \n(2017). Inoculating the public against misinformation about cli-\nmate change. Global Challenges, 1(2), 1600008. https:// doi. org/  \n10. 1002/ gch2. 20160 0008\nvan der Linden, S., & Roozenbeek, J. (2020). Psychological inoculation \nagainst fake news. In R. Greifeneder, M. Jaff\u00e9, E. J. Newman, \n& N. Schwarz (Eds.), The psychology of fake news: Accepting, \nsharing, and correcting misinformation. Routledge https:// www.  \nroutl edge. com/p/ book/ 97803 67271 831\nvan der Linden, S., Roozenbeek, J., Maertens, R., Basol, M., K\u00e1cha, \nO., Rathje, S., & Traberg, C. S. (2021). How can psychological \nscience help counter the spread of fake news? The Spanish Jour -\nnal of Psychology, 24, e25. https:// doi. org/ 10. 1017/ SJP. 2021. 23\nVan Der Maas, H. L., Dolan, C. V., Grasman, R. P., Wicherts, J. M., \nHuizenga, H. M., & Raijmakers, M. E. (2006). A dynamical \nmodel of general intelligence: The positive manifold of intel-\nligence by mutualism. Psychological Review, 113(4), 842\u2013861. \nhttps:// doi. org/ 10. 1037/ 0033- 295X. 113.4. 842\nvan Prooijen, J.-W., Krouwel, A. P. M., & Pollet, T. V. (2015). Political \nextremism predicts belief in conspiracy theories. Social Psycho-\nlogical and Personality Science, 6(5), 570\u2013578. https:// doi. org/  \n10. 1177/ 19485 50614 567356\nVon Neumann, J. (1927). Wahrscheinlichkeitstheoretischer Aufbau der \nQuantenmechanik. Nachrichten von Der Gesellschaft Der Wis-\nsenschaften Zu G\u00f6ttingen, Mathematisch-Physikalische Klasse,  \n1927, 245\u2013272. http:// eudml. org/ doc/ 59230\nVosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false \nnews online. Science, 359(6380), 1146\u20131151. https:// doi. org/ 10.  \n1126/ scien ce. aap95 59\nWeiner, I. B., Schinka, J. A., & Velicer, W. F. (2012). Handbook of \npsychology: Research methods in psychology (2nd ed., Vol. 2). \nJohn Wiley & Sons\nWoolf, M. (2019) How to make custom AI-generated text with GPT-2. \nMax Woolf\u2019s Blog. https:// minim axir. com/ 2019/ 09/ howto- gpt2/\nWorthington, R. L., & Whittaker, T. A. (2006). Scale development \nresearch: A content analysis and recommendations for best prac-\ntices. The Counseling Psychologist, 34(6), 806\u2013838. https:// doi.  \norg/ 10. 1177/ 00110 00006 288127\nZickar, M. J. (2020). Measurement development and evaluation. \nAnnual Review of Organizational Psychology and Organiza-\ntional Behavior, 7, 213\u2013232. https:// doi. org/ 10. 1146/ annur  ev- \norgps ych- 012119- 044957\nOpen Practices Statement: Availability of data, code materials (data \ntransparency) The supplements, data, and analysis scripts that \nsupport this paper\u2019s findings, including Qualtrics files, analysis code, \nraw and clean datasets, and all research materials, are openly available \non the Open Science Framework (OSF) at https:// osf. io/ r7phc/. \nPreregistrations are available on AsPredicted at https:// aspre dicted. \norg/ m7vb3. pdf (Study 1, T1), https:// aspre dicted. org/ js2jz. pdf (Study \n1, T2), and https:// aspre dicted. org/ nx7xu. pdf (Study 2B).\nPublisher\u2019s note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment", "author": ["R Maertens", "FM G\u00f6tz", "HF Golino", "J Roozenbeek"], "pub_year": "2024", "venue": "Behavior Research \u2026", "abstract": "Interest in the psychology of misinformation has exploded in recent years. Despite ample  research, to date there is no validated framework to measure misinformation susceptibility."}, "filled": false, "gsrank": 540, "pub_url": "https://link.springer.com/article/10.3758/s13428-023-02124-2", "author_id": ["wnPfW9wAAAAJ", "lPknh6YAAAAJ", "Ris_otUAAAAJ", "MD5IiCsAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:nEE30LXNOx8J:scholar.google.com/&output=cite&scirp=539&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D530%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=nEE30LXNOx8J&ei=ZrWsaNvsJbXCieoP4PfQ0A8&json=", "num_citations": 121, "citedby_url": "/scholar?cites=2250618619567751580&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:nEE30LXNOx8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.3758/s13428-023-02124-2.pdf"}}, {"title": "Assessing Italian News Reliability in the Health Domain through Text Analysis of Headlines", "year": "2023", "pdf_data": "Assessing Italian News Reliability in the Health Domain through Text\nAnalysis of Headlines\nLuca Giordano\nUNIOR NLP Research Group\nUniversity of Naples \u201dL\u2019Orientale\u201d\ngiordanoluca.uni@gmail.comMaria Pia di Buono\nUNIOR NLP Research Group\nUniversity of Naples \u201dL\u2019Orientale\u201d\nmpdibuono@unior.it\nAbstract\nFake news detection and fact checking rep-\nresent challenging research areas in Natural\nLanguage Processing (NLP), especially in the\nhealth domain, which presents specific char-\nacteristics to be dealt with. On the one hand,\nonline sources have become one of the main\nchannels to retrieve health-related information.\nOn the other hand, most of the time such on-\nline information suffers from lack of quality\nand requires domain-specific knowledge to be\nassessed. Therefore, the spread of untrustwor-\nthy health-related content urges to be mitigated\nsince it may represent a threat for lives.\nTo this aim, we develop a domain-specific an-\nnotated dataset suitable for training automatic\nsystems to assess Italian news reliability. Our\nproposal tries to overcome some of the limi-\ntations of the available datasets by applying\nan in-depth text analysis to obtain a more fine-\ngrained reliability assessment in the health do-\nmain.\n1 Introduction\nLately, the use of online sources for retrieving\nhealth information has become widespread, and\nthus an important source of medical advice (Dai\net al., 2020). Particularly, social media platforms\n(SMPs) seem to be one of the most preferred chan-\nnels to search and share information, especially in\nthe health domain (Chen et al., 2018). As proved by\nseveral scholars (e.g., Finney Rutten et al. (2019);\nBasch et al. (2017)), the Internet and SMPs repre-\nsent the main source of information for adults and\nalso adolescents that are active users and searchers\nfor online health information (Gre \u02c7skovi \u02c7cov\u00b4a et al.,\n2022).\nNevertheless, online health information is affected\nby several limitations with reference to its quality\n(Melchior and Oliveira, 2022). The lack of qual-\nity in information may generate two main types of\nuntrustworthy content, namely disinformation and\nmisinformation (Lazer et al., 2018).Nowadays, fighting the spread of untrustworthy\nand low-quality content through fake news detec-\ntion and/or fact checking represents one of the main\nchallenges to be faced. This is particularly true in\nthe medical domain because such untrustworthy\nhealth-related content threaten lives (Anoop et al.,\n2020).\nThe Covid-19 pandemic has exacerbated the prob-\nlem and brought out the need for gold standard\ndatasets and predefined benchmarks for automated\napproaches, which have been neglected before that,\nas revealed by Viviani and Pasi (2017).\nIn fact, the scarcity of comprehensive resources,\nmainly datasets, for fake health news detection\nslows down the development of novel approaches\ndevoted to detect misinformation and disinforma-\ntion within this domain (Dai et al., 2020).\nStill, the development of resources suitable for as-\nsessing information and news in the health domain\nis far to be fully satisfied, mainly with reference to\nsome domain-specific aspects and languages.\nFor this reason, in this paper we present a domain-\nspecific annotated dataset suitable for training au-\ntomatic systems to assess Italian news reliability.\nOur proposal tries to overcome some of the lim-\nitations of the available datasets and to propose\na more fine-grained assessment of health-related\nnews, achieved through an in-depth text analysis.\nOur main contributions are three: (i) proposing a\nset of stylometric, lexical, and sentiment features\nto assess news reliability; (ii) developing a domain-\nspecific dataset for the Italian language1; (iii) pro-\nviding a first baseline for the developed dataset.\nThe rest of the paper is organized as follows. In the\nnext section, we present studies which are relevant\nto our analysis, referring mainly to the development\nof datasets for fake news detection. In Section 3,\nwe introduce our methodology, our dataset and the\nfeature set. In Section 4 we explain the experimen-\n1The dataset is publicly available at https://github.\ncom/unior-nlp-research-group/TRADISAN.\n538\ntal setup and present the results. Finally in Section\n5 conclusion and future work are discussed.\n2 Related Work\nThe majority of studies published and resources\nmade available focus on a binary classification of\nthe veracity of English news at document-level\n(that is, an overall veracity rating either True or\nFalse for the whole news), although tested by\nmeans of different kinds of analysis (such as a\nrange of linguistic features, e.g., Choudhary and\nArora (2021); Kasseropoulos and Tjortjis (2021),\nsentiment analysis, e.g., Alonso et al. (2021) and\nothers). As shown in D\u2019Ulizia et al. (2021), out of\nthe 27 datasets surveyed in the paper, 14 present\na binary veracity classification (such as Shu et al.\n(2020); Tacchini et al. (2017)), while only 4 of\nthem a three-way rating scale (such as Thorne et al.\n(2018)) and 6 a four-way one (such as Santia and\nWilliams (2018)). Furthermore, 22 out of 27 are\nmonolingual English datasets, only 2 are focused\non the Health domain (Posadas-Dur \u00b4an et al., 2019;\nJwa et al., 2019) and all of them are annotated at\ndocument-level.\nAlthough in Bonet-Jover (2022) the classification\nproposed is still binary (Reliable/Unreliable), it is\nnoteworthy that the author works on Spanish and\nthat the annotation proposal is focused on the indi-\nvidual annotation of different structural and content\nelements of the news, therefore going beyond the\ndocument-level of analysis.\nRegarding the Italian language, to the best of our\nknowledge, there seems to exist only one publicly\naccessible dataset of Italian news annotated accord-\ning to their veracity value, namely HoaxItaly (Pierri\net al., 2020): it is a dataset composed of 1.2M\ntweets referring to 37k Italian news in total, di-\nvided into 3566 fact-checked true news and 32,686\nfake news. However, the news domain is generic,\nthe assessment is binary and at document-level.\nWith reference to the set of features typical of trust-\nworthy and untrustworthy news respectively, sev-\neral studies highlight different kinds of linguistic\npatterns.\nInBiyani et al. (2016) the authors show that the\ndegree of informality of a webpage, as measured\nby different metrics, is a strong indicator of it being\na clickbait, that is an article with a misleading head-\nline, exaggerating the content on the landing page.\nThe amount of superlatives, quotes, exclamations,\nupper case letters, question marks and other indi-cators are used as features for a machine-learning\nmodel which achieves a 74.9% F1 score in predict-\ning clickbaits.\nHorne and Adali (2017) apply a set of linguistic\nfeatures to three datasets in order to analyze the\nlanguage of news articles in the political domain.\nThey show that stylistic features such as the length\nof the article, the use of punctuation, the amount of\npersonal pronouns, nouns and adverbs, the lexical\nredundancy of the text and others, applied both to\nthe headline and to the body of the news, can help\ndistinguish between real and fake news. Their find-\nings are mostly confirmed by Shrestha and Spez-\nzano (2021), who conduct a reproducibility study,\nand in addition show that also other factors, such\nas emotion and readability features are helpful in\nthe fake news detection task.\nInRashkin et al. (2017) the authors show that fea-\ntures such as the amount of swear words, hedge\nwords, sexual-related words, negations, superla-\ntives and others appear to be typical of fake politi-\ncal news, while a frequent use of numbers, money-\nrelated words, assertive expressions and compara-\ntives appear to be typical of true political news.\nGre\u02c7skovi \u02c7cov\u00b4a et al. (2022) show that seemingly\nminor editorial elements, such as poor grammar or\nboldface, in addition to the presence of superlatives,\nclickbaits and appeal to authority in health-related\nmessages, which are all typical elements of untrust-\nworthy news, influence and distort the perception\nof the credibility of news among secondary school\nstudents.\n3 Methodology\nDai et al. (2020) identified several challenges that\nhave to be addressed in fake health news detection,\nas they are specific of this domain. In fact, fake\nhealth news may require specialized knowledge to\nbe recognized more than fake news in other do-\nmains.\nFurthermore, health news are also easier to be ma-\nnipulated, in that they can be easily transformed\ninto misinformation or disinformation just by stat-\ning the association as causation or mixing up the\nabsolute risk and relative risk, which, as Dai et al.\n(2020) point out, require just minor modifications\nof the true information.\nThus, the proposed methodology tries to combine\nthe identification of trustworthy sources together\nwith the integration of linguistic and sentiment fea-\ntures selected by means of an in-depth analysis. To\n539\nour aims, we adopt the criterion of reliability in-\nstead of veracity, to distinguish untrustworthy news\nfrom trustworthy ones and assume that stylometric,\nlexical and sentiment-based characteristics can be\nrepresentative of the degree of news reliability.\nAs first step, we collect a list of news sources\n(i.e., online newspapers) which have been classi-\nfied as trustable or untrustable by Newsguard2, Me-\ndia Bias/Fact Check3, Bufale.net4and Butac5, two\ninternational and two italian fact checking orga-\nnizations which, among other activities, publish\nanalyses and reports on news sources\u2019 trustworthi-\nness. Furthermore, we take into account the data\nand analysis provided in the Digital News Report\n2022 for Italy published by the Reuters Institute\nfor the Study of Journalism6. Therefore, we create\ntwo lists of sources, respectively a trustworthy list\nand an untrustworthy list (Table 1).\nWe use these sources to extract a set of health-\nrelated news, using the classification by categories\nprovided by the newspapers themselves together\nwith a topic-label based extraction. This allows\nus to come up with a list of both trustworthy and\nuntrustworthy news. Then, we perform a linguistic\nanalysis to select a set of features that are represen-\ntative of news reliability.\n3.1 Data Collection\nThe list of trustworthy sources is made up of 12\nItalian news outlets (e.g., Il Sole 24 Ore7, la Repub-\nblica8, ANSA9), while the list of unstrustworthy\nsources is made up of 26 Italian news outlets (e.g.,\nV oxnews10, Dionidream11, Byoblu12) for a total\namount of 38 news sources (Table 1).\nIn order to collect the data from our sources,\nwe write Python scripts tailored to each news\noutlet in order to scrape the news content. We\nexploit the Python libraries pandas13,requests14,\n2https://www.newsguardtech.com/it/\n3https://mediabiasfactcheck.com/\n4https://www.bufale.net/\n5https://www.butac.it/\n6https://reutersinstitute.politics.ox.\nac.uk/digital-news-report/2022/italy\n7https://www.ilsole24ore.com/\n8https://www.repubblica.it/\n9https://www.ansa.it/\n10https://voxnews.info/\n11https://dionidream.com/\n12https://www.byoblu.com/\n13https://pandas.pydata.org/\n14https://requests.readthedocs.io/en/\nlatest/beautifulsoup15andnewspaper3k16, which stem\nfrom machine-learning and data science. We\naim at extracting the URLs of each article in the\nhealth-related categories of the news outlets and\nthrough those we extract the news content, that is\nthe article\u2019s source, date of publication, headline,\nbody of text and links to its images, if any (Table\n2).\nThen, we remove broken links and articles with\nmissing information, as well as duplicate articles\nfrom the same source. We also remark a potentially\ninteresting phenomenon: 28 articles among the\nones extracted from the trustworthy sources\nand 17 among the ones from the untrustworthy\nsources present an identical headline, despite\nbeing published by different sources. This might\nsuggest plagiarism among news outlets. We keep\nthese articles in our dataset since they might be\nsignificant, although we are aware that the pres-\nence of duplicates might affect the training data.\nNevertheless, they represent a small part within the\ntotal amount of data. From the trustworthy list\nwe keep a total of 9.973 news, which amount to\n156.372 sentences and 4.925.379 tokens (we adopt\nthe default AntConc token definition \u201dCharacter\nClasses\u201d17); from the untrustworthy list we keep\na total of 22.128 news, which amount to 611.433\nsentences and 17.648.641 tokens. Therefore,\nthe corpus is made up of a total of 32.101 news\npublished between November 1999 and February\n2023, and it amounts to 767.805 sentences and\n22.574.020 tokens (Table 3). To the aim of the\npresent analysis we consider just news headlines,\nwhich amount to a total of 351.104 tokens.\n3.2 Linguistic Analysis\nIn order to select the features suitable for our news\nassessment, we perform an initial analysis of our\ncorpus to identify a first set of linguistic aspects de-\nnoting (un)reliability. We adopt a method which in-\ncludes a top-down approach, namely applying fea-\ntures already used by other scholars for other lan-\nguages and domains (see Section 2), and a bottom-\nup approach, that is we analyse the dataset and\ncollect features that arise from our set of news.\n15https://beautiful-soup-4.readthedocs.\nio/en/latest/\n16https://newspaper.readthedocs.io/en/\nlatest/\n17https://laurenceanthony.net/software/\nantconc/releases/AntConc4011/help.pdf ,\np.13\n540\nTrustworthy Untrustworthy\nSalute.gov Eticamente.net Vacciniinforma\nISS Raffaele Palermo News eVenti Avversi\nla Repubblica Nexus Edizioni ByoBlu\nil Post Scienza e Conoscenza Come Don Chisciotte\nVaccinarsi.org COMILV A V oxNews\nil Fatto Quotidiano Vivo in Salute Mag24\nTPI The Living Spirits Dagospia\nAGI Il Paragone Filosofia e Scienza\nANSA Database Italia controinformazione.info\nFocus Ingannati Disquisendo\nIl Sole 24 Ore CheSuccede Essere Informati\nCorriere della Sera SocialBuzz! Eurosalus\nSilenzi e Falsit `a Dionidream\nTable 1: Data Sources\nID Source Date Headline Text Image URL\n3762 la Repubblica 2019/04/12Fagioli e spinaci tengono\nlontano il tumore della vescica... Image1.jpg ...\n9626 Il Sole 24 Ore 2023/01/12Pi`u contagi, non casi pi `u gravi e lo scudo\ndei vaccini: ecco perch \u00b4e\nla variante Kraken non deve fare paura... Image1.jpg ...\n15526 ByoBlu 2022/09/21\u201cBILL GATES HA GESTITO IL COVID\nPER ARRICCHIRSI\u201d: ORA SE\nNE ACCORGE ANCHE IL MAINSTREAM... Image1.jpg ...\n18104 V oxNews 2021/04/09RECORD DI MORTI SPALMATI: 718\nIN 24 ORE, 9 APRILE SCORSO ANNO\nERANO STATI 612... Image1.jpg ...\nTable 2: Examples of Trustworthy (IDs 3762 and 9626) and Untrustworthy (IDs 15526 and 18104) Entries from our\nCorpus\n.\nList # News # Sentences # Tokens\nTrust. 9.973 156.372 4.925.379\nUntrust. 22.128 611.433 17.648.641\nTOTAL 32.101 767.805 22.574.020\nTable 3: Corpus Description\nWe obtain a total number of 31 features (Table 4)\naccounting for three different levels of analysis,\nnamely stylometry, lexicon, and sentiment.\nStylometric Features The stylometric features\nwe take into account refer to sentence and word\nlength (by characters), the use of uppercase style,\nthe frequency of consecutive question and exclama-\ntion marks, frequency of quotes, double quotes and\nsingle quotes, ellipses and direct discourse. We also\ncompute the amount of typos through a customized\nContextual Spell Checker18, a deep-learning based\nNoisy Channel Model Spell Algorithm trained on\nthe PAIS `A Corpus19, one of the largest publicly\navailable corpora of Italian Web texts, licensed un-\nder Creative Commons.\n18Towards Data Science - Training a Contextual Spell\nChecker for Italian Language\n19https://www.corpusitaliano.it/The number of words written in uppercase, the\nnumber of long words (understood as being longer\nthan 6 characters) and the number of typos are all\nweighted values accounting for the length of the\nsentence.\nLexical Features The lexical features we com-\npute are the number of adverbs, comparatives, su-\nperlatives, currency-related words (such as dollar ),\nnegative adverbs, nouns, proper nouns, adjectives,\npossessive adjectives other than the 1st and 2nd\nsingular and digits. Additionally, we exploit the\nRevised HurtLex (Tontodimamma et al., 2022), a\nlexicon of offensive, aggressive, and hateful words\ndivided into 17 categories in over 50 languages\nin order to compute the number of occurrences of\nsuch words in the corpus. In the revised version,\nevery Italian headword is annotated with an offen-\nsiveness level score, derived by applying an Item\nResponse Theory model to the ratings provided\nby a large number of annotators (Tontodimamma\net al., 2022). Therefore, we also compute the total\noffensiveness score of the sentence based on the\nscores of the words contained in it.\nFurthermore, we also count the occurrences of\n541\ndomain-specific buzzwords, understood by the defi-\nnition provided by the Cambridge Dictionary: \u201da\nword or expression from a particular subject area\nthat has become fashionable by being used a lot,\nespecially on television and in the newspapers\u201d20.\nFor this purpose, we compile a gazetteer of 73\nwords and phrases extracted from the top 300 key-\nwords in the corpus sorted by likelihood and from\nthe top ranking bigrams and trigrams sorted by\nfrequency. Some examples of buzzwords in our\ngazetteer are vaccino (vaccine), covid, coronavirus,\nsintomi (symptoms), immunit `a di gregge (herd im-\nmunity), lockdown, AIDS, green pass, vaiolo delle\nscimmie (monkeypox) and no vax. We assume that\nCovid-19 global impact, urgency, and relevance\nas a major health crisis have led to a significant\nconcentration of Covid-19-related keywords in the\ncorpus, despite the pandemic started only in 2020,\nwhile the corpus contains news up to 1999. This\nmight be evidence of the impact of the pandemic on\nnews production in Italy. Therefore, we choose to\nkeep this statistical bias in our buzzwords gazetteer\nas well.\nAll lexical features, except for the offensiveness\nscore, are weighted values accounting for the\nlength of the sentence.\nSentiment Features Additionally, we exploit\nthe adoption of sentiment-related features. This\ncomes from the fact that several scholars (Alonso\net al., 2021; Bhutani et al., 2019; Ajao et al., 2019)\nhave recognized that the polarity and strength\nof sentiments expressed in text can improve the\nresults in fake news and rumor detection tasks.\nThus, we apply NRC Emotion Intensity Lexicon\n(Mohammad and Turney, 2013) to detect and\nevaluate the presence of emotions-related words\nwithin the texts, such as anger, joy, and trust. In\nfact, we notice that news from the untrustworthy\nsources are characterized by a more frequent use of\nwords associated with negative emotions, such as\nanger, e.g., Example (1), while trustworthy news\ntend to express more positive emotions, such as\njoy or trust, e.g., Example (2).\nSource: Disquisendo - ID: 26847\nIl governo italiano ha dichiarato GUERRA agli\nitaliani. OBBLIGO VACCINALE che passa da 4 a\n12 e fino a 16 anni!! SVEGLIAAAAA!! (The Italian\ngovernment has declared WAR on the Italians.\n20https://dictionary.cambridge.org/it/\ndizionario/inglese/buzzwordCOMPULSORY V ACCINATION goes from 4\nto 12 and up to 16 years!! WAKE UUUUUP!!)\nSource: La Repubblica - ID: 4148\nLo smartwatch? Pu `o salvare la vita (letteralmente)\n(The smartwatch? It can (literally) save lives)\nFurthermore, through SentITA (Nicola, 2018)\nwe also consider the sentiment polarity of the\nheadlines, as untrustworthy news tend to present a\nmostly negative polarity while trustworthy news\na mostly positive one (Shrestha and Spezzano,\n2021).\n3.3 Reliability Assessment\nWe perform an analysis of news headlines from\nboth trustworthy and untrustworthy sets, according\nto the aforementioned features and use these results\nto define a textual model. The textual model char-\nacterizes the set of untrustworthy news headlines\nand presents the following linguistic aspects:\n\u2022 Longer headlines (by characters);\n\u2022 Frequent use of uppercase style;\n\u2022Presence of consecutive question and excla-\nmation marks;\n\u2022Higher frequency of ellipses, typos, double\nand single quotes (but less direct discourse);\n\u2022Higher frequency of adverbs, superlatives,\nfirst person singular pronouns and negative\nadverbs;\n\u2022Limited use of comparatives, currency-related\nwords, nouns, adjectives, second person sin-\ngular pronouns and digits;\n\u2022Higher frequency of words and phrases from\nthe HurtLex lexicon and a higher offensive-\nness score;\n\u2022 Higher frequency of proper nouns;\n\u2022 Slightly higher frequency of buzzwords;\n\u2022Lower frequency of lexical items related to\ntrust and joy.\nThen, the textual model is employed to assess the\nheadline reliability.\n3.4 Dataset Creation\nOn the basis of such methodology, we create a\ndataset which contains the information related to\nthe textual model for assessing reliability (Figure\n1). The selected features are annotated according\nto their pertaining level, that is stylometric ( styl ),\nlexical (lex), and sentiment (sent).\n542\nStylometric Lexical Sentiment\nchar count adverb count w nrc anger w\nuppercase word w comp w nrc trust w\nlong ww superl count w nrc joyw\nconsecutive question count currency w opos\nconsecutive excla count rev hurtlex count w oneg\nquotes count hurtlex score\ndouquotes count neg adverbs count w\nsingle quote count noun count w\nellipses count prop noun count w\ndirect discourse adj count w\ntypo count w adj poss others w\n1stpers sing w\n2ndpers sing w\ndigits w\nbuzzwords count w\nTable 4: List of the 31 Reliability Features\nFigure 1: Annotation example for the headline ID: 16733 La FARSA dei Tamponi e degli Asintomatici (The FRAUD\nof Swabs and Asymptomatic patients), source: Come Don Chisciotte\nIn addition to this annotation at title-level, we\nalso provide the dataset with additional annota-\ntions (Table 5), such as lemmatization (L), Part-of-\nspeech tagging (PoS), Inside\u2013Outside\u2013Beginning\nchunk-tagging and (IOB) Named Entity Recogni-\ntion tagging (NER). We test the annotated dataset\nperforming an experiment to evaluate the results\nfrom some of the most common classifiers.\n4 Experiment\nWe conduct a series of experiments to test our hy-\npothesis, i.e. the assumption that stylometric, lex-\nical and sentiment-based features can be suitable\nfor assessing news reliability. Therefore, the main\naim of these experiments is to test how fit our fea-\nture set is for an automatic assessment of newsreliability. Although the final goal is a fine-grained\n(multi-class) automatic reliability annotation of the\nwhole dataset, for the sake of these experiments\nand its contextual aim (i.e., testing the feature set\nand the generalizability of the results for the dataset\nannotation, rather than the classification granular-\nity and performance per se), we assume that every\narticle from the untrustworthy and trustworthy lists\nmake up only two separate classes, therefore con-\nfiguring it as a binary classification problem.\nSince the dataset is imbalanced, we perform an un-\ndersampling process, i.e. we extract a sample of\nrandom unstrustworthy news equal to the (smaller)\nsubset of trustworthy news (9973 samples). We end\nup with two equally sized subsets which amount\nto a total of 19946 samples. We justify the under-\n543\nH ID Token L PoS IOB NER\n18192 1 AstraZeneca AstraZeneca PROPN B ORG\n18192 2 vietato vietare VERB O \u2013\n18192 3 in in ADP O \u2013\n18192 4 ... ... ... ... ...\nTable 5: Annotation example extracted from the headline ID: 18192 AstraZeneca vietato in Germania sotto ai 60\nanni, Merkel: \u201cImpossibile nascondere l\u2019insicurezza\u201d (AstraZeneca banned in Germany under 60 years old, Merkel:\n\u201dImpossible to hide uncertainty\u201d), source: V oxNews\nsampling since the final number of samples is still\na considerable amount. Finally, we do not stratify\nthe sampling process neither on date of publication,\nnor source of provenance nor any other factor since\nwe aim at a subset as randomized as possible. After\nthe random undersampling, the subset of untrust-\nworthy news contains 2 of the 17 duplicates, while\nthe subset of trustworthy news keeps all its original\n28 duplicates.\nEnvironmental Setup All code was written and\ncompiled in Python 3.10 on Linux Ubuntu 23.04\nand several packages and libraries were exploited,\nsuch as pandas, NumPy21,SpaCy22,NLTK23,\nTransformers24,scikit-learn25,fastText26andPy-\nTorch27.\nThe Neural Network runs on an NVIDIA GeForce\nRTX\u2122 3060 Laptop GPU with CUDA v12.0.\nFeature Selection In order to reduce computa-\ntional cost, avoid overfitting, increase generaliz-\nability, and contribute to the explainability of the\nmodels, we apply statistical-based feature selection\ntechniques, aiming at reducing the number of in-\nput variables to only those that have the strongest\nrelationship with the target variable (Butcher and\nSmith, 2020). We adopt a filter-based univariate\nfeature selection method. In detail, since we are\ndealing with numerical input variables and categori-\ncal output variables, we perform an analysis of vari-\nance (ANOV A) to compute the ANOV A correlation\ncoefficient (F-value). ANOV A test is used to com-\npare the means of different groups on a dependent\nvariable and to determine whether the difference in\ngroup means is due to random variation or if they\n21https://numpy.org/\n22https://spacy.io/\n23https://www.nltk.org/index.html\n24https://huggingface.co/docs/\ntransformers/index\n25https://scikit-learn.org/stable/\n26https://fasttext.cc/\n27https://pytorch.org/represent true population differences. Its assump-\ntions are independence, homogeneity of variances\nof the residuals and a normal distribution (Butcher\nand Smith, 2020). We assume that each feature is\nindependent from the other, and, since we conduct\nthe analysis on two equally big subsets built ad-hoc,\nwe can also assume feature homogeneity (Sawyer,\n2009).\nRegarding normality of distribution, several schol-\nars, e.g., Lumley et al. (2002); Ghasemi and Za-\nhediasl (2012), show that with large sample sizes\nthe distribution of data can be ignored, as the po-\ntential violation of the normality assumption does\nnot cause problems. Moreover, the adoption of the\nANOV A test is justified due to its robustness un-\nder conditions of non-normally distributed data, as\nproved by Schmider et al. (2010) and Blanca Mena\net al. (2017). Since ANOV A test can be suitable\nfor both normal and non-normal distributions, espe-\ncially with large sample sizes and our sample size\namounts to 19946 samples, we choose not to test\nnormality and to perform directly the ANOV A test.\nFeatures are then sorted in descending order by the\nF-value computed with the ANOV A test to deter-\nmine the importance. We choose to consider the\ntopK features that have an F-value of more than\n100. We therefore keep the top 13 features (Table\n6).\nClassification We conduct a series of experi-\nments, testing five different machine-learning clas-\nsifiers (namely, Logistic Regression, Decision Tree,\nMultinomial Naive-Bayes, Random Forest and Lin-\nearSVC) and, for BERT, a Multi-Layer Perceptron\n(MLP) with different input combinations and dif-\nferent word embedding techniques (namely, GloVe,\nfastText, and pre-trained BERT Base). We split the\ndata in 90:10 training and testing ratio and make\nsure that all the duplicates are always only in the\ntraining set, since, as stated in Section 3.1, they\nmight have been generated through a process we\nwant to take into account. We then perform a cross-\n544\n# Top Features F-value\n1 prop noun count w 1068.08\n2 uppercase word w 832.12\n3 char count 630.26\n4 dou quotes count 393.81\n5 ellipses count 387.03\n6 single quote count 367.05\n7 quotes count 338.06\n8 direct discourse 223.11\n9 noun count w 193.67\n10 typo count w 172.22\n11 long ww 170.29\n12 oneg 159.22\n13 hurtlex score 128.98\nTable 6: Top features calculated using ANOV A\nvalidation on the training set, i.e. we split it into\n10 train/validation subsets, while the test set re-\nmains unaltered. In each iteration, the training set\nis used for training while the validation set for vali-\ndation. The performance measure reported is then\nthe average of the values computed in the loop. For\nthe MLP, the cross-validation is performed directly\nin the training loop, while, for the ML classifiers,\nthrough a GridSearchCV28technique implemented\nvia scikit-learn, which also allows us to perform\na hyperparameter optimization for every ML clas-\nsifier. The cross-validation parameter is set to 10\nfolds. We then use the best estimator obtained for\nthe classification task on the test set.\nFirst, we try a classification taking only the whole\n31 numerical features as input, without any word\nvector representation.\nThen we ignore the features and classify the data\nonly with three different word embedding tech-\nniques; we first try GloVe, then fastText and finally\nan italian XXL Bert Base transformer cased model\npre-trained on the whole italian Wikipedia, OPUS\ncorpus and the italian subset of OSCAR corpus, for\na total amount of 13,138,379,147 tokens29. Being\na Base model, it is made up of 12 layers of trans-\nformers block with a hidden size of 768 and 12\nself-attention heads and has around 110M trainable\nparameters.\nThen, we combine the different word embeddings\nwith all 31 features.\n28https://scikit-learn.org/stable/\nmodules/generated/sklearn.model_\nselection.GridSearchCV.html\n29https://huggingface.co/dbmdz/\nbert-base-italian-casedFinally, we classify the data with a combination\nof the different word embeddings and only the top\n13 features we obtained from the feature selection\nprocess. We implement the MLP with PyTorch: the\npooled output of the BERT encoder is used as input,\nthe dropout rate is set at 0.5, the activation func-\ntion is ReLu, the optimizer Adam, the loss function\nCrossEntropy, and we found that the optimal num-\nber of epochs is 6. When combining BERT with\nthe features, the linear layer takes as input a tensor\nof length equal to the pooled output of BERT + the\nnumber of features.\nResults The results (Table 7) show that, as ex-\npected, state-of-the-art BERT is the best model,\nachieving an F1 score of 0.855 alone, 0.884 when\ncombined with the top 13 features. A classification\nbased exclusively on our entire feature set achieves\nan F1 score of 0.70, while with only the top 13 it\ndecreases to 0.68. Although the score is slightly\nlower, it is noteworthy that less than half of the\noriginal feature set were used. This emphasizes\nthe importance of the feature selection process, and\nthis must be taken into account for the dataset anno-\ntation, for example by assigning different weights\nto different features. The use of our features in\nall settings (alone, in combination with word em-\nbeddings and with BERT) improves the results,\nalthough slightly. The improvement is more consid-\nerable for fastText word embeddings than GloVe.\nThese results show that this feature set can be a\nstarting point for assessing Italian news reliability\nin the health domain.\n5 Conclusion and Future Work\nIn this paper, we present our preliminary work on\nthe automatic reliability assessment of Italian news\nin the health domain. Our methodology is based on\nthe use of trustworthy and untrustworthy sources\nand the definition and selection of a set of sty-\nlometric, lexical and sentiment features suitable\nfor detecting misinformation and disinformation\nwithin health-related content. We believe that our\napproach can help improving the explainability of\nclassification models thanks to our in-depth linguis-\ntic analysis. In addition, we also believe that the\nresearch community will be able to further exploit\nour annotated dataset to build upon this resource.\nAs future work, we intend to investigate further\nthe linguistic features as well as the integration of\ninformation from external knowledge bases in or-\nder to check content manipulation. We also plan\n545\nModel Classifier P MacroA VG RMacroA VG F1\nAll Features RandomForest 0.70 0.70 0.70\nTop13 Features RandomForest 0.68 0.68 0.68\nfastText LinearSVC 0.76 0.76 0.76\nfastText + All Features LinearSVC 0.78 0.78 0.78\nfastText + Top13 Features LinearSVC 0.79 0.79 0.79\nGloVe LogisticRegression 0.78 0.78 0.78\nGloVe + All Features LogisticRegression 0.79 0.79 0.79\nGloVe + Top13 Features LogisticRegression 0.79 0.78 0.79\nBERT BASE Multi-Layer Perceptron 0.855 0.855 0.855\nBERT BASE + All Features Multi-Layer Perceptron 0.871 0.871 0.871\nBERT BASE + Top13 Features Multi-Layer Perceptron 0.887 0.884 0.884\nTable 7: Experiment Results\nto extend our analysis to the whole news content\nand assign different weights to the features on the\nbasis of their relevance and other linguistic and\nstylistic considerations related to this specific do-\nmain. Finally, we will investigate the integration of\nsocial media-related aspects, such as news network\npropagation, reach and engagement.\nAcknowledgements\nLuca Giordano has been supported by Borsa di Stu-\ndio GARR \u201dOrio Carlini\u201d 2022/23 - Consortium\nGARR, the National Research and Education Net-\nwork.\nMaria Pia di Buono has been supported by\nFondo FSE/REACT-EU - Progetti DM 1062\ndel 10/08/2021 \u201dRicercatori a Tempo Deter-\nminato di tipo A) (RTDA)\u201d. Azione IV .4 -\nDottorati e contratti di ricerca su tematiche\ndell\u2019innovazione/Azione IV .6 - Contratti di ricerca\nsu tematiche Green.\nThe authors would like to thank Raffaele Manna\nfor his support.\nReferences\nOluwaseun Ajao, Deepayan Bhowmik, and Shahrzad\nZargari. 2019. Sentiment aware fake news detection\non online social networks. In ICASSP 2019-2019\nIEEE International Conference on Acoustics, Speech\nand Signal Processing (ICASSP), pages 2507\u20132511.\nIEEE.\nMiguel A Alonso, David Vilares, Carlos G \u00b4omez-\nRodr \u00b4\u0131guez, and Jes \u00b4us Vilares. 2021. Sentiment analy-\nsis for fake news detection. Electronics, 10(11):1348.\nK Anoop, P Deepak, and VL Lajish. 2020. Emotion\ncognizance improves health fake news identification.\nInIDEAS, volume 2020, page 24th.CH Basch, Patricia Zybert, Rachel Reeves, and\nCE Basch. 2017. What do popular youtubetm videos\nsay about vaccines? Child: care, health and develop-\nment, 43(4):499\u2013503.\nBhavika Bhutani, Neha Rastogi, Priyanshu Sehgal, and\nArchana Purwar. 2019. Fake news detection using\nsentiment analysis. In 2019 twelfth international\nconference on contemporary computing (IC3), pages\n1\u20135. IEEE.\nPrakhar Biyani, Kostas Tsioutsiouliklis, and John Black-\nmer. 2016. \u201d8 amazing secrets for getting more\nclicks\u201d: Detecting clickbaits in news streams using\narticle informality. In Proceedings of the AAAI Con-\nference on Artificial Intelligence, volume 30.\nM Jos \u00b4e Blanca Mena, Rafael Alarc \u00b4on Postigo, Jaume Ar-\nnau Gras, Roser Bono Cabr \u00b4e, and Rebecca Bendayan.\n2017. Non-normal data: Is anova still a valid option?\nPsicothema, 2017, vol. 29, num. 4, p. 552-557.\nAlba Bonet-Jover. 2022. Veracity vs. reliability: Chang-\ning the approach of our annotation guideline.\nBrandon Butcher and Brian J Smith. 2020. Feature\nengineering and selection: A practical approach for\npredictive models: by max kuhn and kjell johnson.\nboca raton, fl: Chapman & hall/crc press, 2019, xv+\n297 pp., $79.95 (h), isbn: 978-1-13-807922-9.\nLiang Chen, Xiaohui Wang, and Tai-Quan Peng.\n2018. Nature and diffusion of gynecologic cancer\u2013\nrelated misinformation on social media: analysis\nof tweets. Journal of Medical Internet Research,\n20(10):e11515.\nAnshika Choudhary and Anuja Arora. 2021. Linguistic\nfeature based learning model for fake news detection\nand classification. Expert Systems with Applications,\n169:114171.\nEnyan Dai, Yiwei Sun, and Suhang Wang. 2020. Ginger\ncannot cure cancer: Battling fake health news with a\ncomprehensive data repository. In Proceedings of the\nInternational AAAI Conference on Web and Social\nMedia, volume 14, pages 853\u2013862.\n546\nArianna D\u2019Ulizia, Maria Chiara Caschera, Fernando\nFerri, and Patrizia Grifoni. 2021. Fake news detec-\ntion: a survey of evaluation datasets. PeerJ Computer\nScience, 7:e518.\nLila J Finney Rutten, Kelly D Blake, Alexandra J\nGreenberg-Worisek, Summer V Allen, Richard P\nMoser, and Bradford W Hesse. 2019. Online health\ninformation seeking among us adults: measuring\nprogress toward a healthy people 2020 objective.\nPublic Health Reports, 134(6):617\u2013625.\nAsghar Ghasemi and Saleh Zahediasl. 2012. Normal-\nity tests for statistical analysis: a guide for non-\nstatisticians. International journal of endocrinology\nand metabolism, 10(2):486.\nKatar \u00b4\u0131na Gre \u02c7skovi \u02c7cov\u00b4a, Radom \u00b4\u0131r Masaryk, Nikola\nSynak, and Vladim \u00b4\u0131ra\u02c7Cavojov \u00b4a. 2022. Superlatives,\nclickbaits, appeals to authority, poor grammar, or\nboldface: Is editorial style related to the credibility\nof online health messages? Frontiers in Psychology,\npage 5056.\nBenjamin Horne and Sibel Adali. 2017. This just in:\nFake news packs a lot in title, uses simpler, repetitive\ncontent in text body, more similar to satire than real\nnews. In Proceedings of the international AAAI con-\nference on web and social media, volume 11, pages\n759\u2013766.\nHeejung Jwa, Dongsuk Oh, Kinam Park, Jang Mook\nKang, and Heuiseok Lim. 2019. exbake: Automatic\nfake news detection model based on bidirectional\nencoder representations from transformers (bert). Ap-\nplied Sciences, 9(19):4062.\nDimitrios Panagiotis Kasseropoulos and Christos\nTjortjis. 2021. An approach utilizing linguistic fea-\ntures for fake news detection. In Artificial Intelli-\ngence Applications and Innovations: 17th IFIP WG\n12.5 International Conference, AIAI 2021, Hersonis-\nsos, Crete, Greece, June 25\u201327, 2021, Proceedings\n17, pages 646\u2013658. Springer.\nDavid MJ Lazer, Matthew A Baum, Yochai Ben-\nkler, Adam J Berinsky, Kelly M Greenhill, Filippo\nMenczer, Miriam J Metzger, Brendan Nyhan, Gordon\nPennycook, David Rothschild, et al. 2018. The sci-\nence of fake news. Science, 359(6380):1094\u20131096.\nThomas Lumley, Paula Diehr, Scott Emerson, and\nLu Chen. 2002. The importance of the normality\nassumption in large public health data sets. Annual\nreview of public health, 23(1):151\u2013169.\nCristiane Melchior and Mirian Oliveira. 2022. Health-\nrelated fake news on social media platforms: A\nsystematic literature review. new media & society,\n24(6):1500\u20131522.\nSaif M Mohammad and Peter D Turney. 2013. Nrc emo-\ntion lexicon. National Research Council, Canada,\n2:234.Giancarlo Nicola. 2018. Bidirectional attentional\nlstm for aspect based sentiment analysis on italian.\nEVALITA Evaluation of NLP and Speech Tools for\nItalian, 12(108).\nFrancesco Pierri, Alessandro Artoni, and Stefano Ceri.\n2020. Hoaxitaly: a collection of italian disinforma-\ntion and fact-checking stories shared on twitter in\n2019. arXiv preprint arXiv:2001.10926.\nJuan-Pablo Posadas-Dur \u00b4an, Helena G \u00b4omez-Adorno,\nGrigori Sidorov, and Jes \u00b4us Jaime Moreno Escobar.\n2019. Detection of fake news in a new corpus for\nthe spanish language. Journal of Intelligent & Fuzzy\nSystems, 36(5):4869\u20134876.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 con-\nference on empirical methods in natural language\nprocessing, pages 2931\u20132937.\nGiovanni Santia and Jake Williams. 2018. Buzzface: A\nnews veracity dataset with facebook user commentary\nand egos. In Proceedings of the international AAAI\nconference on web and social media, volume 12,\npages 531\u2013540.\nSteven F Sawyer. 2009. Analysis of variance: the funda-\nmental concepts. Journal of Manual & Manipulative\nTherapy, 17(2):27E\u201338E.\nEmanuel Schmider, Matthias Ziegler, Erik Danay, Luzi\nBeyer, and Markus B \u00a8uhner. 2010. Is it really robust?\nMethodology.\nAnu Shrestha and Francesca Spezzano. 2021. Textual\ncharacteristics of news title and body to detect fake\nnews: a reproducibility study. In Advances in Infor-\nmation Retrieval: 43rd European Conference on IR\nResearch, ECIR 2021, Virtual Event, March 28\u2013April\n1, 2021, Proceedings, Part II 43, pages 120\u2013133.\nSpringer.\nKai Shu, Deepak Mahudeswaran, Suhang Wang, Dong-\nwon Lee, and Huan Liu. 2020. Fakenewsnet: A data\nrepository with news content, social context, and spa-\ntiotemporal information for studying fake news on\nsocial media. Big data, 8(3):171\u2013188.\nEugenio Tacchini, Gabriele Ballarin, Marco L Della Ve-\ndova, Stefano Moret, and Luca De Alfaro. 2017.\nSome like it hoax: Automated fake news detection in\nsocial networks. arXiv preprint arXiv:1704.07506.\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFever: a large-scale dataset for fact extraction and\nverification. arXiv preprint arXiv:1803.05355.\nAlice Tontodimamma, Lara Fontanella, Stefano Anzani,\nand Valerio Basile. 2022. An italian lexical resource\nfor incivility detection in online discourses. Quality\n& Quantity, pages 1\u201319.\n547\nMarco Viviani and Gabriella Pasi. 2017. Credibility\nin social media: opinions, news, and health infor-\nmation\u2014a survey. Wiley interdisciplinary reviews:\nData mining and knowledge discovery, 7(5):e1209.\n548", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Assessing Italian News Reliability in the Health Domain through Text Analysis of Headlines", "author": ["L Giordano", "MP Di Buono"], "pub_year": "2023", "venue": "Proceedings of the 4th Conference on \u2026", "abstract": "Fake news detection and fact checking represent challenging research areas in Natural  Language Processing (NLP), especially in the health domain, which presents specific"}, "filled": false, "gsrank": 541, "pub_url": "https://aclanthology.org/2023.ldk-1.58.pdf", "author_id": ["H4aNFeAAAAAJ", "PGR1GuoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:mltvvI2GTvQJ:scholar.google.com/&output=cite&scirp=540&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=mltvvI2GTvQJ&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:mltvvI2GTvQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/2023.ldk-1.58.pdf"}}, {"title": "JCSP 44 PCEMI 44", "year": "NA", "pdf_data": "   \nThe Kremlin\u2019s Handmaiden: Public Diplomacy Po Russki  \n \nMaj Natasha Bolduc  \nJCSP 44 \n PCEMI 4 4 \nExercise Solo Flight  Exercice Solo Flight  \n \n \n \n \nDisclaimer   \n \n \n \nAvertissement  \n \nOpinions expressed remain those of the author and \ndo not represent Department of National Defence or \nCanadian Forces policy.  This paper may not be used \nwithout written permission.   \nLes opinons exprim\u00e9es n\u2019engagent que l eurs auteurs \net ne refl\u00e8tent aucunement des politiques du \nMinist\u00e8re de la D\u00e9fense nationale ou des Forces \ncanadiennes. Ce papier ne peut \u00eatre reproduit sans \nautorisation \u00e9crite.  \n \n \n\u00a9 Her Majesty the Queen in Right of Canada, as \nrepresented by the Minister of National Defence, 201 8.  \n \n\u00a9 Sa Majest\u00e9 la Reine du Chef du Canada, repr\u00e9sent\u00e9e par \nle ministre de la D\u00e9fense nationale, 201 8. \n \n \n \n \n\nCANADIAN FORCES COLLEGE \u2013 COLL\u00c8GE DES FORCES CANADIENNES  \nJCSP 44 \u2013 PCEMI 44  \n2017 \u2013 2018 \n \nDS 568 \u2013 ADVANCED  TOPICS IN INTERNATIONAL SECURITY STUDIES  \nThe Kremlin\u2019s Handmaid en: Public Diplomacy Po Russki \nBy Major M.T.N. Bolduc  \n \n\u201cThis paper was written by a student \nattending the Canadian Forces College \nin fulfilment  of one of the requirements \nof the Course of Studies.  The paper is \na scholastic document, and thus \ncontains facts and opinions, which the \nauthor alone considered appropriate \nand correct for the subject.  It does not \nnecessarily reflect the policy or the \nopinion of any agency, including the \nGovernment of Canada and the \nCanadian Department of National \nDefence.  This paper may not be \nreleased, quoted or copied, except with \nthe express permission of the Canadian \nDepartment of National Defence.\u201d   \u00ab La pr\u00e9sente \u00e9tude a \u00e9t\u00e9 r\u00e9dig\u00e9e par \nun stagiaire du Coll\u00e8ge des Forces \ncanadiennes pour satisfaire \u00e0 l'une des \nexigences du cours.  L'\u00e9tude est un \ndocument qui se rapporte au cours et \ncontient donc des faits et des opinions \nque seul l'auteur consid\u00e8re appropri\u00e9s \net convenables au sujet.  Elle ne refl\u00e8te \npas n\u00e9cessairement la politique ou \nl'opinion d'un organisme quelconque, y \ncompris le gouvernement du Canada et \nle minist\u00e8re de la D\u00e9fense nationale du \nCanada.  Il est d\u00e9fendu de diffuser, de \nciter ou de reproduire cette  \u00e9tude sans \nla permission expresse du minist\u00e8re de \nla D\u00e9fense nationale.  \u00bb \nWord Count: 5452  Compte de mots  : 5452 \n \n \n \n \n \n \n \n \n \n1 \n Public diplomacy can no longer be seen as an add -on to the rest of diplomacy. It must be seen \nas a central activity that is played out across many dimensions and with many partners. \nAbove all, Western governments need a much broader and more creative idea of what public \ndiplomacy is and what it can do.  \n\u2013 Mark Leonard  \nINTRODUCTION  \nThe end of the Cold War brought about a hiatus and marginalization of public diplomacy \nstrategies because of the view that former enemies would become partners and stakeholders in a \nnew democratic world order based on mutual truth and shared security.1 Yet, the emergence  of \nthe hypermedia environment and global information social network s stimulated a growth in \npublic opinion and multiplicity of international non -state actors, further changing the \ninternational geopolitical landscape . The new pace and reach of the information age led  \ncontemporary states to rethink th eir public diplomacy st rategies as alternate means of influence \nin state-to-foreign population diplomacy.  For the Russian Federation , the colour revolutions were \nregarded as strategies of influence by t he EU and NATO to promote democracy and liberalism . \nThe Arab Spring was  further seen as turning point in  the use of media as an enabler to accelerate \nrevolutions , changing the nature of warfare in the 21st century. Feeling threatened by their \nshrinking influence in  the post-Soviet space, the Russian Federation  invested millions in to public \ndiplomacy to  counter the Western democratic narrative, extend its influence in the region, and \nimprove its image.  But their initiatives  fell short of their expectations , attributable the Kremlin\u2019s \ninconsistent rhetoric and its military intervention s. \nThe Russian Federation \u2019s international image continued to decline after the Georgian-\nRussian war, the 2011 -2012 anti -Putin protests, the Annexation of Crimea, and today\u2019s \n                                                           \n1 Marcel van Herpen, Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy  (London: \nLandham, Md: Rowman & Littlefield, 2016), 6 -7. \n2 \n aggression in Ukraine and intervention in Syria . Significant debate was generated on the \nemergence of a new Russian form of hybrid warfare  and their use of mass media technology as \nthe latest weapon in grey -zone strategies.  If Western states dismiss Russian public diplomacy \nefforts as mere propaganda , they risk misunderstandi ng the Russian narrative which could result \nin a superfluous escalation of conflict. Public diplomacy, a component of hybrid strategies, \nbecomes an attractive option for countries like Russia against the supremacy of Western state s\u2019 \ntraditional instruments  of national power  to restore influence in their region and gain \ninternational recognition.  \nThis persuasive essay will explore Russian public diplomacy and its place in Moscow\u2019s  \nhybrid strategy . It will examine how it is practically implemented and why th eir efforts have  only \nbeen partially successful  thus far. This essay will be divided into four sections: basic public \ndiplomacy theories and Soviet Union\u2019s interpretation  of public diplomacy ; the objectives and \nmeans of Russian public diplomacy and its place in the Kremlin\u2019s hybrid strategy; media and \ncultural diplomacy initiatives  targeting its diasporas ; and assessment of their effectiveness .  \nFUNDAMENTALS OF PUBLIC DIPLOMACY  \nWhile traditional  diplomacy refers to the interaction between state governments, public \ndiplomacy  refers to the foreign policy strategy of influencing foreign public opinion to obtain \ninternational support and turn their policies into advantageous ones. The Russian Federation , like \nmany states, takes public diplomacy seriously; however, it has also been accused of engaging in \ncovert activities of influence , historically referred to as active measures .2 This section will \n                                                           \n2 Martin Kragh and Sebastian Asberg, \u201cRussia\u2019s Strategy for Influence Through Public Diplomacy and \nActive Measures: the Swedish Case,\u201d 777 -778. \n3 \n review some basic theories on public diplomacy and the Soviet  Union\u2019s interpretation  of public \ndiplomacy to provide a context in understanding Russian public diplomacy in the 21st century. \nWhat is public diplomacy?   \nThe practice of \u201cpublic diplomacy \u201d is not new; however, the concept was  officially defined \nin the 20th century. First  introduced as \u201copen diplomacy \u201d by U.S. President Woodrow Wilson , its \nmeaning denoted  diplomacy open to the public, where negotiations, alliances and partnerships \nbetween states needed to be transparent . This was a response to the secret diplomacy of World \nWar I.3 The practice  was later coined as \u201cpublic diplomacy \u201d in 1965 by former U.S. diplomat \nand scholar Edmund  Gullion. One of the earliest pamphlets of the Edward R. Murr ow Center \ndescribed public diplomacy as dea ling with  \n\u2026the influence of public attitudes on the formation and execution of foreign \npolicies. It encompasses dimensions of international relations beyond traditional \ndiplomacy; the cultivation by governments of public opinion in other countries; the \ninteraction of private groups and interest on one country with another; the \nreporting of foreign affairs and its impact on policy; communication between those \nwhose job is communication, as diplomats and foreign correspondents; and the \nprocess of intercult ural communications.4   \nPublic diplomacy , as defined by Nicholas Cull, is \u201can international actor\u2019s attempt to manage the \ninternational environment through e ngagement with a foreign public,\u201d5 widely seen as linked to \nJoseph Nye\u2019s Soft Power.6 Some scho lars contend public diplomacy  is nothing more than a \n                                                           \n3 Yale Law School Lillian Goldman Law Library, \u201c8 January, 1918: President Woodrow Wilson\u2019s Fourteen \nPoints,\u201d The Avalon Project , accessed 13 April 2018. http://avalon.law.yale.edu/20th_century/wilson14.asp   \n4  Public Diplomacy Alumni Association, \u201cAbout U.S. Public Diplomacy,\u201d PublicDiplomacy.org  (2018). \nAccessed 23 April 2018. http://pdaa.publicdi plomacy.org/?page_id=6  \n5 Nicholas J. Cull, Public Diplomacy: Lessons from the Past (Los Angeles, CA: Figueroa Press, 2009), 12. \nhttp://kamudiplomasisi.org/pdf/kitaplar/PDPers pectivesLessons.pdf .  \n6 Soft power is about mobilizing cooperation from other without threats or payments\u2026policies based on \nbroadly inclusive and far -sighted definitions of the national interest are easier to make attractive to others than \npolicies that ta ke a narrow or myopic perspective.\u201d;  Joseph S. Nye,  Soft Power: The Means to Success in World \nPolitics. 1st ed. (New York: Public Affairs, 2004), 61  \n4 \n euphemism and refinement for propaganda.7 Etymologically speaking , the term \u201cpropaganda \u201d \nmeans propagating a message with the intent of swaying targeting audiences . If based on facts, \npublic diplomacy can be  equated to propaganda ; however, propaganda based on fa lsehoods and \nlies is more so considered  disinformation .8 Murrow summed it up best by saying \u201c truth is the \nbest propaganda and lies are the worst.\u201d9 Though the distinction between public diplomacy and \npropaganda may be subtle, any influence lacking credibility would be counterproductive  to \npromoting a state\u2019s image.10  \nThe end of the Cold War brought about a relegation of public diplomacy efforts based on  \nthe view that globalization and  democracy would  turn former enemies into partners and \nstakeholders .11 Conversely , the emergence of the hypermedia environment and global \ninformation networks fostered a rise public opinion and array of new international non -state \nactors, reinvigorating interest in public diplomacy strategies . The term \u201cmass diplomacy\u201d is often \nused in the context of the global information age to \u201cnew diplomacy that attempts to cultivate the \nsupports of the masses, and for the mean of communication and information transmission that \ncan be rightly dubbed mass communication .\u201d12 While the term still accounts for traditional \nmeans of public diplomacy, \u201cmass diplomacy\u201d  more accurately accounts for cultural, diaspora, \ncyber and mass media diplomacy lacking from its  original definition. It can be argued that mass \ndiplomacy is an evolution of public diplomacy due to the global information revolution. For the \n                                                           \n7 Pierre Pahlavi, Mass Diplomacy: Foreign Policy in the Global Information Age  (Montreal: McGill \nUniversity , 2004), 20; Geoff Berridge, Diplomacy: Theory and Practice , 4th ed. (New York; Houndmills, \nBasingstoke, Hamphire: Palgrave MacMillan, 2010), 182.  \n8 \u201cPropaganda,\u201d Online Etymology Dictionary . Accessed 12 April 2018. \nhttps://www.etymonline.com/word/propaganda ; \u201cAbout U.S. Public Diplomacy.\u201d  \n9 Edward R. Murrow was the Director of the USIA in 1963 ; \u201cAbout U.S. Public Diplomacy.\u201d  \n10 Mark Leonard, \"Diplomacy by Ot her Means,\"  Foreign Policy  no. 132 (Sept 2002)50. https://search -\nproquest-com.cfc.idm.oclc.org/docview/224048517?accountid=9867.  \n11 Marcel van Herpen, Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy  (London: \nLandham, Md: Rowman & Littlefield, 2016), 6 -7. \n12 Pahlavi, Mass Diplomacy: Foreign Policy in the Global Information Age, 20. \n5 \n purposes of this paper,  the terms mass diplomacy and public diplomacy will be considered \nsynonymous .  \nSoviet Public Diplomacy   \nTo understand  Russian public diplomacy, it is important to understand its Soviet history  \nbecause the Russian government took some cues from its past to develop their current public \ndiplomacy st rategies. For the Soviets, public diplomacy was interpreted as \u201chighly competitive \nand ideological\u2026 [consisting ] of propaganda, cultural diplomacy and special \u2018political influence \ntechniques \u2019\u201d that were both covert and overt.13 While Western states typically assess former \nSoviet public diplomacy as sheer propaganda, the Soviet Union once possessed a great  deal of \nsoft power. After World War II, the Soviet Union attracted many Europeans due to its victory \nagainst Hilter and as an alternative option to European imperialism, especially in colonized areas \nof Africa and Asia. The Soviet Union invested billions on public diplomacy  programs  to promote \nthe communist ideology,  a Soviet high culture and a positive image of the Soviet Union abroad .14  \nThese programs included international publishing and broadcasting, cultural exchange and youth \nprograms, and sponsoring antinuclear protests and peace movements.15 Their use of overt \ntechniques , however,  was more of a window dressing  that showcased the best features the Soviet \nUnion had to offer .  \n                                                           \n13 Sinikukka Saari, \u201cRussia\u2019s Post -Orange Revolution Strategies to Increase its Influence in Former Soviet \nRepublics: Public Diplomacy Po Russkii,\u201d Europe-Asia Studies  66, no. 1 (2014), 53.  \n14 The institutions responsible for these forms of Soviet public diplomacy were the Central Committee\u2019s \nInternational Department and the Internationa l Information Department as well  as the Soviet Foreign Ministry and \nthe national security agency KGB. Philip Taylor estimates the equivalent of $2 billion dollars was spent by 1960 on \ncommunist propaganda worldwide . This is worth noting President Vladimir Putin\u2019s experience as a former KGB \nIntelligence Officer provides some con text into a seeming resurgence of Soviet like covert strategies in the 21st \ncentury; Philip M. Taylor, Munitions of the Mind: A History of Propaganda from the Ancient World to the Present \nDay 3rd ed. (Manchester; New York: Manchester University Press, 2003), 256.  \n15 Nye, Soft Power: The Means to Success in World Politics , 73-74; Saari, \u201cRussia\u2019s Post -Orange Revolution \nStrategies to Increase its Influence in Former Soviet Republics: Public Diplomacy Po Russkii,\u201d, 53.  \n6 \n Despite the ir efforts, the Soviet Union could not compete with the rise in popularity of the \n\u2018America Dream\u2019 and  Western popular culture . The disparity between what the Soviet Union \npresented to the international community through its \u201csofter\u201d means and what it achieved \nthrough \u201charder\u201d methods received the most criticism . Much of the Soviet  soft power  was lost \nafter the invasions of Hungary and Czechoslovakia, despite growth in the ir economic and \nmilitary. 16 The Soviet War in Afghanistan  and the Chechen wars  leveraged the use of proxy \nforces, disseminating a messaging campaign to justify their actions as counterinsurgency. The \nterm active measures became central in their glossary as a \u201ccontinua tion of war through other \nmeans\u201d or political warfare.17 These measures aimed at  \n\u2026influencing another government, undermining confidence in its leaders and \ninstitution, disrupting relations between other nations, strengthening the allies of \nthe Soviet Union and discrediting and weakening governmental and non-\ngovernmental  opponents of t he Soviet Union. 18 \nAlthough these methods are not open and transparent, disseminating disinformation in Western \nmedia, deploying agents of influence and leveraging front organization s were facets of Soviet \npublic diplomacy to influence foreign populations and advance Soviet foreign policy goals.  \nPUBLIC DIPLOMACY: A COMPONENT OF HYBRID STRATEGY?  \nThough the Soviet Union used overt and covert strategies of influence to maintain power in \nthe region, the balance of power and stability during the Cold War  can be attributed  to bipolarity \nand nuclear deterrence, rather than  public diplomacy efforts. According to the Stability-\nInstability Paradox theory, the collapse of the Soviet Union end ed of bipolarity  and transformed \n                                                           \n16 Soft Power: The Means to Success in World Politics , 9. \n17 Also known as aktivnye meropriyatiya; Saari, \u201cRussia\u2019s Post -Orange Revolution Strategies to Increase its \nInfluence in Former Soviet Republics: Public Diplomacy Po Russkii,\u201d 53.  \n18 Ibid. \n7 \n threats, violence and terror into asy mmetric forms.19 These events indirectly influenced the \nevolution of public diplomac y by creating the illusion of the \u201cend of history\u201d and the impression \nthat ideological struggles have been overcome.20 When this illusion was blurred with the realities \nof the 21st century, public diplomacy was reborn but  it needed to adapt to a  privatized and \nderegulated environment. These changes in the world order fundamentally changed how the \nRussians viewed themselves, their perceived role internationally and their overall goals. This \nsection will define Russian public diplomacy in the 21st century and its place in Russia\u2019s hybrid \nstrategy \nRussian Public Diplomacy   \nWith the fall of the Soviet Union, the communist ideology giving the state its identity also \nfell apart, forcing Russia to redefine itself. Unfortunately, t he discourse of Cold War defeat, \nfollowed b y the dark decade  of the 1990s, 21 left the new Russia searching for a new identity, \neconomic prospe rity and most importantly securitizing its position as a great power. 22 President \nVladimir Putin promised reform focusing on strengthening sovereignty, growing of the \neconomy, protecti ng of Russian interests, and promoting regional influence.23 The common \n                                                           \n19 The Stability -Instability Paradox is an international relations theory which defines the probability of a \ndirect war between states as directly proportional with the concept of mutual assured destruction and the use of \nnuclear deterrence. See: Robert, Rauchhaus, \"Evaluating the Nuclear Peace Hypothesis: A Quantitative Approach,\" \nThe Journal of Conflict Resolution  53, no. 2 (2009): 258 -277. \n20 See: Francis Fukuyama,\u201d The End of History?\u201d The National Interest (Summer 1989), 1 -18. \nhttps://www.embl.de/aboutus/science_society/discussion/discussion_2006/ref1 -22june06.pdf   \n21 During the 1990s, the new Russian Federation failed to thrive , politically and economically; however, \nthese failures are not solely attributable to Yeltin\u2019s administration. The Russians also blamed the United States and \nEurope for failing to recognize Russia as an equal international partner. See: Roger E. Kanet and  R\u00e9mi Piet, Shifting \nPriorities in Russia\u2019s Foreign and Security Policy (Burlington, VT: Farnham, Surrey, UK: Ashgate, 2013), 2.  \n22 Team of the Official Website of the President of Russia, \u201cThe Foreign Policy Concept of the Russian \nFederation,\u201d (Moscow: 12 January 2008), accessed 24 April 2018. http://en.kremlin.ru/supplement/4116 ; President \nVladimir Putin, \u201cAnnual Address to the Federal Assembly of the Russian Federation,\u201d (Moscow: 8 July 2000), \naccessed 25 April 2018. http://en.kremlin.ru/events/president/transcripts/21480 .  \n23 These are the four overarching objectives within  the 2000, 2008 and 2013 Russian Foreign Policy Concept, \naimed at restoring Russia to a power status. See:  Federation of American Scientists, \u201cThe Foreign Policy Concept \nof the Russian Federation,\u201d (Moscow: 28 June 2000), htssiatps://fas.org/nu ke/guide/russia/doctrine/econcept.htm ; \n8 \n assumption within the Kremlin , however , was that the negative sentiments  towards Russia were \na direct result of the Western states\u2019 global dominance of the media, which favoured \u2018anti-\nKremlin\u2019 narratives . Russian public diplomacy, therefore, became an important  offensive tool in \nthe attempt to convey alternate narratives and engage with target audiences abroad.24 \nThe Kremlin believed it could shed its former pre -conception s of Soviet Russia  by \nfocusing on a narrative of economic cooperation  partnership . It attempted to project an image of \nRussia as an integrated and reliable business partner , predominantly in the gas and oil industry \nand in foreign investment.25 These were  not without its challenges . Russia\u2019s economic influence \nwas undermined, not only from the 2008 economic crisis, but from its non-transparent business \npractices and  its desire to maintain an economic monopoly in the post -Soviet space.  Although \nthe Russian government needed to rebuild relations with the states in its Near-Abroad, Russian \npolitical elites struggled to accept  the former interdependent Soviet republics as i ndependent \nsovereign states, upholding  a greater interest in this region compared to other foreign states. This \ndesire to maintain influence in the post -Soviet space was deeply engrained in Russian Foreign \npolicy and evident in their practice of public diplomacy. When Russian economic influence \nbegan to decline, the Kre mlin shifted focus to compatriot policies and the promotion a collective \nRussian identity.  \nTo understand Russian public diplomacy, it is important to understand Russian Foreign \nPolicy goals towards its neighbouring states. Viewing the region as a zero -sum game , its \napproaches to influence foreign public opinion changed due to NATO\u2019s expansion. The Kremlin \n                                                                                                                                                                                           \n\u201cThe Foreign Policy Concept of the Russian Federation\u201d (2008); Ministry of Foreign Affairs of the Russian \nFederation, \u201cConcept of the Foreign Policy of the Russian Federation,\u201d (Moscow: 12 February 2013), \nhttp://www.mid.ru/foreign_policy/official_documents/ -/asset_publisher/CptICkB6BZ29/content/id/122186 . \n24 Russia\u2019s Strategy for Influence Through Public Diplomacy and Active Measures: The Swedish Case,\u201d 5.  \n25 Valentina Feklyunina, \u201cSoft Power and Identity: Russia, Ukraine and the \u2018Russian World(s)\u2019,\u201d European \nJournal of International Relations 22, no.4 (December 1, 2016), 783.  \n9 \n consistently drew the hard line against  the expansion, considering  it a manifestation of United \nStates influence by proxy.26 The use of Russian public diplomacy was , therefore,  used not solely \nto promote Russian language and culture but also as a force multiplier to degrade the unity of \nNATO and European Union and to quell American exceptionalism. Straying away from Nye\u2019s \noriginal definition of Soft Power , the Kremlin use d a consequentialist approach with in using its \ninstruments of influence, combining the power of attraction and the art of manipulation.  \nThe colour revolutions were the catalyst in the Russian Federation \u2019s shift in foreign policy \npolicies, and subsequently evident in its practice of public diplomacy. The Kremlin viewed these \nevents as a deliberate  use of soft power  and public diplomacy  by Western states to create a pro-\nWest and a Pro -Russian cleavage  in Eastern Europe.27 Feeling threatened, the Kremlin  shifted its \nforeign policy philosophy from a relatively pragmatic approach, focusing  on economic growth \nand international cooperation, to a nationalist approach,  emphasizing the need for a collective \nRussian identity. 28 Regardless , Russia still maintained its desire to reaffirm its position as a great \npower.  \nSinikukka defines Russian public diplomacy as divided into two categori es: the Western \nStrand and the Post-Soviet Strand. Russia invest ed heavily to develop their public diplomacy , \npredominantly in their media, to invoke soft power  aiming to attract and persuade Western \n                                                           \n26 Russian Foreign policy concepts  \n27 Team of the Official Website of the President of Russia, \u201cInterview with Time Magazine,\u201d (19 December \n2007). http://en.kremlin.ru/events/president/t ranscripts/24735 ;  \n28 Russia has yet to fully define its identity. Some refer to it as Soviet-like, but without the communist \nideology, while other scholars the Kremlin is attempting to restore a sense of Russian imperialism. There is \nsignificant debate abo ut what characterizes Russian nationalism, on whether geopolitics play a central role, or \nwhether it is culture and spiritual factors, such as the Russian Orthodox Church. Others like Limonov and Dugin \nspeak of neo -eurasianism and of the idea of being cult ural closer to Asia than Europe while lending their hand to \nRussian minorities living in its Near Abroad. Yet President Putin understood Russian sense of collectivism best in \nhis \u201cRussia at the Turn of the Millennium,\u201d as deeply rooted and paternalistic. a rticle; See: Vladimir Putin, \n\u201cVladimir Putin\u2019s First Paper as President: \u2018Russia at the Turn of the Millennium\u2019 \u2013 A Strategy for Russia\u2019s \nRevival,\u201d Signs of the Times  (31 December 1999). Accessed 03 May 2018. https://www.sott.net/article/310072 -\nVladimir-Putins-first-paper-as-president-Russia-at-the-turn-of-the-Millenium -A-Strategy-for-Russias-Revival.  \n10 \n audiences, and to counter Western monopoly and narrati ve; however, it  \u201cstill suffer [ed] from the \nsame clumsiness that the Soviet propaganda once it .\u201d 29 The Post-Soviet Strand , conversely , \n\u201creli[ed] on the manipulative logic that was inherited from Soviet practices,\u201d targeting Russian \nspeaking communities, predominantly in the Slavic, Baltic and the Eastern European States.30 \nThe Kremlin leveraged  its compatriot and humanitarian policies to reach out to its compatriots \nliving abroad, or diasporas. The Russian Orthodox Church and cultural organizations, as the \nRusskiv Mir, are also leveraged to build sympathetic communities  and encourage public \ndiplomacy by proxy in targeted regions in the post -Soviet space. \nPublic Diplomacy and Hybrid Strategy   \nIn the 21st century, the term Hybrid War  became widely used  to define a strategy \ncombining  the use of conventional warfare with irregular, cyber and other influencing methods. \nBy definition, hybrid warfare  fundamental principles resemble Nye\u2019s cohesive use of soft and \nhard power, known as  Smart Power ; but the difference between Smart Power  and hybrid warfare \nlies in the eye of the beholder. Hybrid warfare became pejoratively associated to Russian \nmethods of  a concealed character, notoriously in Ukraine and Crimea, with the use of \ndisinformation, agents of influence and special operations ; all which  ultimately undermin ed their \ncredibility . Smart Power , however, became typically associated with transparent methods \nendorsed by Western states. 31 Conversely,  the Russian narrative likewise accused Western states \n                                                           \n29 Saari, \u201cRussia\u2019s Post -Orange Revolution Strategies to Increase its Influence in Former Soviet Republics: \nPublic Diplomacy Po Russkii,\u201d 62 . \n30 Ibid., 62-63. \n31 Mark Galeotti, \u201cHybrid, Ambiguous, and Non -Linear? How New is Russia\u2019s \u2018New Way of War\u2019?\u201d Small \nWars and Insurgencies 27:2 (2016), 287; IISS Military Balance 2015 (London: International Institute for Strategic \nStudies, 2015), 5.  \n11 \n of using concealed and non -transparent forces under the guise of peacekeeping and crisis \nmissions.32   \nRussia elevated the logic of hybridity to an unpre cedented level of complexity  \n\u2026[adopting] a multifaceted  policy which has been described as \u201cgrey zone\u201d, \n\u201casymmetrical \u201d, \u201chybrid\u201d or \u201cshort of war\u201d strategy. The world is witnessing the \nemergence of this stealthy 360o influence strategy for some time, which adopts a \nmultifaceted non -conventional approach to international affairs while minimizing \nthe use of direct violence .33 \nWhile this strategy may seem new in the West, the concept is arguably not  new for Russia , \nsharing a resemblance  to the Soviet integrated use of former public diplomacy and active \nmeasures.  Galeotti argued  a corollary with the Clausewitz doctrine,  that if \u201cwar is politics by \nother means [than] politics can also be war by other means.\u201d34 Even Sun Tzu interred that \n\u201c[subduing the enemy without fighting is extreme excellence ,\u201d and Machiavelli that \u201cno \nproposition ought not to be rejected.\u201d35 But grey-zone strategies differ  from early theorist \nbecause of  globalization and the information revolution . The growing influence of public \nopinion, the increased speed of information, the vastly expanding social networks  and the global \neconomic interdependence have increased constrain ts on the use of brute force. Public \ndiplomacy, cyber and sp ecial operations ha ve become another dimension of diplomacy  to \npromote national interests and achieve foreign policy objectives.  \n                                                           \n32 Mark Galeotti, \u201cThe \u2018Gerasimov Doctrine\u2019 and Russian Non -Linear War,\u201d In Moscow\u2019s Shadows  (2013). \nAccessed 02 April 20 18. https://inmoscowsshadows.wordpress.com/2014/07/06/the -gerasimov -doctrine-and-\nrussian-non-linear-war/ \n33 Pierre Pahlavi, \u201cGrey Zone Strategies,\u201d Canadian Defence at 150 and Beyond  (NATO Association of \nCanada, 2017),  41. \n34 Galeotti, \u201cHybrid, Ambiguous, and Non -Linear? How New is Russia\u2019s \u2018New Way of War\u2019?\u201d, 287.  \n35  Tao, Hanzhang, Shibing, Yuan and Sunzi, Sun Tzu\u2019s Art of War: The Modern Chinese Interpretation  \n(New York: Sterling Pub. Co, 2000), 15; Niccol \u00f2 Machiavelli, Machiavelli on International Relations , First Ed. \n(New York: Oxford: Oxford University Press, 2014), 62.  \n12 \n Many claim the events of the Arab Spring  as defining a moment in the evolution of 21st \ncentury warfare because it  uses the media as a n enabling platform to \u201caccelerate the pace of a \nrevolution and help build its constituency.\u201d36 General Valery Gerasimov, in his infamous  2013 \narticle, shared this view , arguing the Arab Spring  was an example where  \n \u2026the role of non -military means of achieving political and strategic goals has \ngrown, and in many cases, they have exceeded the power of force weapons in their \neffectiveness \u2026The focus of applied methods of conflict has altered in the \ndirection of the broad use of political, economic, informational, h umanitarian and \nother non -military measures \u2013 applied in coordination with the protest potential of \nthe population.37  \nHe recapitulate d how the Russian Federation  viewed the conduct warfare in the 21st century and \nelaborated how \u201cnew tactics [were] needed which focus on the enemy\u2019s weaknesses and avoid \ndirect and overt confrontations.\u201d 38 Over the past decade , the Russian Federation use d the Arab \nSpring, the colour revolution and the NATO expansion, in their narrative to re -invigorate  public \ndiplomacy efforts as an essential element of non-linear political focused operations . Russian \npublic diplomacy simultaneously mimicked  some Western practices while incorporat ing former \nSoviet active measures  as a means to counter  Western supremacy , restore influence in the region \nand seek international recognition.  \nRUSSIAN PUBLIC DIPLOMACY INITIATIVES  \nApproximately  30 million ethnic Russians reside in the post -Soviet space, with its largest \npopulations in Ukraine, Belarus and Kazakhstan .39 The Kremlin viewed this  diaspora population \nas a distinctly separate audience from other foreign population s. Even before the colour \n                                                           \n36 Philip M. Seib, Real-Time Diplomacy:  Politics and Power in the Social Media Era , 1st Ed. (New York: \nPalgrave MacMillian, 2012) , 41; \n37 Galeotti, \u201cThe \u2018Gerasimov Doctrine\u2019 and Russian Non -Linear War.\u201d  \n38 Ibid. \n39 \u201cMoscow Says 30 Million Russian Live Abroad\u201d (Radio Free Europe Radio Liberty:08  March 2006). \nAccessed 01 May 2018. https://www.rferl.org/a/1066475.html .  \n13 \n revolutions, the Kremlin was taking measures to strengthen its ties with compatriots abroad, a \ntheme highlighted  in Russian Foreign Policy from 2000 to 2016. These policies focused on \nconsolidating the Russian diaspora, not only for the promotion of Russian language and culture \nbut for strengthening Russia\u2019s position in the world. This section will explore Russia\u2019s use of \nmedia diplomacy  and cultural diplomacy  as elements of a public diplomacy strategy to attempt to \nincrease its influence in its diaspora population .40 \nRussia\u2019s Media Diplomacy  \nThe global information age revolutioni zed the media industry , providing a broader array of \ninstruments at Russia\u2019s disposal for its public diplomacy efforts. Television and the internet \nbecame primary means of mass influence . In 2005, the Russian Federation  launched a new \ngovernment sponsored international news channel, Russia Today (now simply known as RT).  \nBetween 2005 and 2007, the Kremlin invested over $150 million into this project and their \nbudget continued to increase, with $120 million 2008 and $380  million in 2011  from the Russian \nFederation federal budget.41 The Kremlin envisioned this 24 -hour English news channel  as \nbecoming a global competitor to western broadcasters such as BBC World, CNN and Al -\nJazeera.42 Although d iffusing in over 100 states, its largest audience  resides across Europe, with \n43 million weekly viewers in 15 countries.43 In RT\u2019s early years, the Kremlin\u2019s rhetoric \nprimarily focused on improving the Russian Federation \u2019s image by disseminating  cultural \n                                                           \n40 Ho and McConnell, using assemblage theory, conceptualize \u201cdiaspora diplomacy as diaspora assemblages  \ncomposed of states, non -state and other international actors that function as constituent components of assemblages, \nconnected through networks and flows of people, information and resources.\u201d This dimension of diplomacy \nconsiders how states engages in di plomacy through diasporas to promote their national interests, and how diasporas \nconduct diplomacy for their own agenda;  Elaine L.E. Ho and Fiona McConnell, \u201cConceptualizing \u2018Diaspora \nDiplomacy\u2019: Territory and Populations Betwixt the Domestic and Foreign, \u201d Progress in Human Geography (SAGE \nPublication Ltd., 2017) http://journals.sagepub.com/doi/pdf/10.1177/0309132517740217 , 16. \n41 Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy , 70-71; About RT.\u201d RT News. \nAccessed 02 May 2018. https://www.rt.com/about -us/ \n42 Ibid. \n43 \u201cAbout RT\u201d (RT News). Accessed 02 May 2018. https://www.rt.com/about -us/ \n14 \n programming highlighting Russian culture, ethnicity and also modernization efforts. Regardless \nof success es, it has been continuously criticized by Western states for the Soviet-like, top-down \ncentralization management of its media outlets; this is a sharp contrast to the bureaucratic -\nentrepreneurial model of most Western states.44 Regardless of its attempts to project a positive \nimage, the credibility of Russian media, even in its early years, was question ed for the  absence of \nreliable, consis tent and objective information  on critical subjects regarding government \ncorruption, atrocities of the Second Chechen War, murders of journalists, amongst others.  \nIn 2006, Russia\u2019s international reputation was at all time low  because of Russia\u2019s \ninterference in the Orange Revolution , its role in the Ukrainian gas disputes  and subsequent lack \nof comprehensive media strategy. Avgerinos argued  that \n\u2026Russia\u2019s failure to promptly form a coherent public relations strategy and \nconvey its points of view to foreign media delivered a major blo w to Russia\u2019s \nbrand image, as the Ukrainian version of the story dominated the press and was \naccepted by Western publics as the truth\u2026 During the August 2008 Russia -Georgia \nconflict in South Ossetia, Russia repeated many of the same public relation \nmistakes.45 \nDuring the Ukrainian and Russia-Georgia conflict s, Russian media diplomacy , including RT, \nshifted towards offensive soft power  strategies, focus ing on Russian nationalism and the negative \naspects of the West.  Sputnik News  and the increase of internet troll factories  grew from this shift \nin public diplomacy strateg y. In 2014, the Kremlin launched this new website and radio service, \nas a replacement of its international broadcasting service Voice of Russia.46 The Kremlin \n                                                           \n44 According to Pahlavi, the \u201cbureaucratic -entrepreneurial\u201d mass diplomacy [that combines] a minimum of \ndecision-making centralisation and a maximum of managerial decentralisation replacing the obsolete hierarchical \nsystem inher ited from the Cold War period; see: Pierre Pahlavi, \u201cBureaucratic -Entrepreneurial\u201d Mass Diplomacy: \nForeign Policy in the Global Information Age, 191-245. \n45 Katherine P. Avgerinos, \u201cRussia\u2019s Public Diplomacy Effort: What the Kremlin is Doing and Why it is Not \nWorking,\u201d Journal of Public & International Affairs Vol. 20 (Spring 2009). 119 -120. \n46 The Voice of Russia was seen at the time as a revival of the Soviet  Moscow Radio; Alec Luhn, \u201cEx -Soviet \nCountries on Front Line of Russia\u2019s Media War with the West\u201d (The Guardian: 6 January 2015). \n15 \n invested $103 million in Rossiya Segodnya, the state-run news agency which includes Sputnik. \nHeadquartered in Moscow with regional offices around the world , Sputnik broadcast s in 130 \ncities in 24 countries ; yet, its focus resides in its  Near Abroad and  on countering the western bias \ntowards Russia. Focusing on its neighbouring states, Sputnik runs versions of their website in \nlocal languages targeting Abkhazia, Belarus, Kyrgyzstan, China, Spain and Turkey.47 Russian \npublic diplomacy through social media platforms, like Facebook  and YouTube, are more \ndifficult to categorize  because it falls into the nebulous grey-zone.  Renowned  for its use of \ninternet trolls, this use of media and information technology saturate s social media and internet \nplatforms with large scale disinformation, with articles like the MH17 airplane crash  and others \non the Ukraine conflict to create confusion and disunity amongst target audiences.  \nRussia\u2019s Cultural Diplomacy  \nRussian media is a noticeable  tool in socializing foreign compatriots  to Russian cultural , \nbut cultural diplomacy has always been an equally fundamental element of Russian public \ndiplomacy.  Russia\u2019s cultural and diaspora diplomacy is about redefining the collective Russian \nidentity and wel ding some soft power through similarities on language, religious and cultural \nviews. The Kremlin defined Russian ethnicity as Russian born, descendants of Russians and any \nRussian speaker living abroad to reach into its diasporas  and play onto this sense o f collectivism  \nand nationalism . Mimicking the Confucius  Institutes and the British Council & Goethe Institute, \nthe Russian government invested  into a variety of government -organized nongovernment \norganizations (GONGOs) to export its academic, religious and humanitarian views into its \n                                                                                                                                                                                           \nhttps://www.theguardian.com/world/2015/jan/06/ -sp-ex-soviet-countries-front-line-russia-media-propaganda -war-\nwest.  \n47 Luhn, \u201cEx -Soviet Countries on Front Line of Russia\u2019s Media War with the West\u201d;  van Herpen, Putin\u2019s \nPropaganda Machine, Soft Power and Russian Foreign Policy,  70-71. \n16 \n periphery and beyond. 48 The Russian Orthodox Church (ROC) and GONGOs, like the Russkiv \nMir Foundation and Rossotrudnichestvo  explored further in this  section.  \nThe Russian Orthodox Church was always  an agent of the Russian state, dating back from \nthe tsars. Even under the Soviet Union, i t remained tutelage of the Kremlin but  was repressed \nunder the communist atheist ideology. The re -emergence the R OC as a soft power  and Foreign \nPolicy instrument was emphasized during President Putin\u2019s first presidency . He not only praised \nthe positive role and virtues of the religion  but also affirmed  a need for \u201cspiritual security\u201d of the \nRussian diaspora.49 The newly constructed Kremlin -funded Russian Orthodox cathedral in Paris \nserves as a prime example of Russia\u2019s attempt to boost its soft power.50 The ROC formalized its \nties with the Russian Foreign Ministry , subsequent the reunification of the Russian Orthodox \nChurch Outside Russia  (ROCOC)  and the Moscow Patriarchate under the Act of Canonical \nCommunion . As a united entity, the Russian Orthodox Church could on providing spiritual \noversight of the Orthodox people from Rus sian and its diasporas, advocating  for international \nhuman rights, facilitating dialogue with the United Nations, UNESCO, OSCE and the Council of \nEurope.51 \n                                                           \n48 Rutland, Peter and Andrei Kazantsev, \u201cThe Limits of Russia\u2019s \u2018Soft Power\u2019,\u201d Journal of Political Power \nvol. 9, no. 3 (2016), 402.  \n49 van Herpen, Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy , 131-133; Daniel P. \nPayne, \"Spiritual Security, the Russian Orthodox Church, and the Russian Foreign Ministry: Collaboration or \nCooptation?\"  Journal of Church and State  52, no. 4 (Autumn, 2010): 712 -727.  \n50 \"A New Orthodox Church Next to the Eiffel Tower Boosts Russ ian Soft Power.\"  The Economist  (5 \nDecember 2016).  https://www.economist.com/blogs/erasmus/2016/12/ecclesiastical -diplomacy ; John Lichfield , \n\u201cParis Welcomes Kremlin -funded Russian Orthodox Cathedral \u2013 As French Court Tries to Seize its Assets,\u201d \nIndependent (Paris, 18 March 2016). https://www.independent.co.uk/news/world/europe/sainte -trinite-paris-\nwelcomes -kremlin-funded-russian-orthodox-cathedral-as-french-court-tries-to-a6939601.html  \n51 van Herpen, Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy , 131-133; Daniel P. \nPayne, \"Spiritual Security, the Russian Orthodox Church, and the Russian Foreign Ministry: Collaboration or \nCooptation?\" Journal of Church and State  52, no. 4 (Autumn, 2010): 712 -727.  \n17 \n The Russkiy Mir  Foundation was created in 2007 by presidential decree with the purpose \nof \u201cpromoting the Russian language [and] support Russian teaching programs abroad.\u201d52 A joint \nproject between the Ministry of Foreign Affairs and the Ministry of Education and Science, its \noriginal importance was on the promotion of Russian cultural, rather than the spiritual one of the \nRussian Orthodox Church. However, over the course of the decade, the emphasis gradually \nshifted to the promotion of \u201cspiritual heritage.\u201d  Russkiy Mir \u201creflects a softer overt side of \nRussian public diplomacy in the post -Soviet regio n,\u201d having established centers in 39 countries, \n17 centers in Ukraine alone, and receiving more than $20 million annually from the federal \nbudget.53 In 2008, Rossotrudnichestv o was established under the Foreign Ministry with almost \nthe same vision as the Russkiy Mir.54 Agencies like these have propelled  throughout the world \nwith representative offices in most European states, the United States, Canada and in many major \nstates in Asia, Africa and Latin America. Institutions like Russkiy Mir are excellent platforms for \ndiplomacy by proxy, further providing  grants for individuals and NGOs. 55  \nEFFECTIVE OF RUSSIAN PUBLIC DIPLOMAC Y \nThe long-term effects of public diplomacy are difficult to assess in the privatized, \nderegulated and information age of the 21st century. Pahlavi argued  that effects of political, \neconomic and strategic payoff  cannot be fully evaluated  because governments have yet to  \n                                                           \n52 \u201cAbout Russkiy Mir Foundation.\u201d Russkiy Mir Foundation. Accessed 03 May 2018. \nhttps://russkiymir.ru/en/fund  \n53 Sinikukka.  \"Russia's Post -Orange Revolution Strategies to Increase its Influence in Former Soviet \nRepublics: Public Diplomacy Po Russkii  Diplomacy Po Russkii,\u201d  60. \n54 Also known as the Federal Agency for the Commonwealth of Independent States Affairs, Compatriots \nLiving Abroad, and International Humanitarian Cooperation, the Russotrudichestvo , operates under the jurisdiction \nof the Ministry of Foreign Affairs and guided by the constitution of the Russian Federation; \u201cAbout \nRossotrudnichestvo.\u201d Rossotrudnichestvo. Acce ssed 05 May 2018. http://rs.gov.ru/en/about .  \n55 Ibid. \n18 \n develop a measurable system of evaluation  of the real effectiveness of public diplomacy policy.56 \nAt the moment, public diplomacy is critiqued through audience analysis, perceived credibility, \nand popular public opinion. Since public diplomacy and strategies of influence, in general, are \ndifficult to quantify , Western states often dismiss their relevan cy. States like Russia, China and \nIran, on the other hand, profoundly believe in its soft power  albeit the lack of metric s. This \nsection will explore the  immediate outcomes of R ussian media and cultural  diplomacy \ninitiatives.   \nThe Media Wars  \nAlthough investing heavily into international  TV channe ls and web -based media , Russian \nmedia outlets,  by industry standard, are still considered relatively small compared to the world\u2019s \nleading stations like BBC, Deutsche Welle and Al Jazeera. RT, for example, has amassed  70 \nmillion weekly viewers worldwide compared to 372 million weekly viewers watching BBC.57 \nRegardless , it has gained international recognition;  successfully adopt new media technology, \nincluding Facebook, Twitter and YouTube  to increase its sphere of influence.58  However, the \nRussian media enterprise only superficially appears as an instrument of public diplomacy and \nsoft power . From the Western perspective, credibility relies on impartiality , the reliability  of \nsources and  a perceived distance from governments . For Russia, objectivity and credibility are \ncompromised because their \u201ceditorial accountability for authoritarian media outlets ultimately \nrest with the political leadership [and]  the content that they produce is compr omised through \n                                                           \n56 Pierre Pahlavi,\u201d Evaluating Public Diplomacy Programmes,\u201d The Hague Journal of Diplomacy 2, no. 3 \n(2007), 256.  \n57 Rutenberg, Jim. \"RT, Sputnik and Russia\u2019s New  Theory of War.\"  The New York Times.  (13 September \n2017). Accessed 02 May 2018.  https://www.nytimes.com/2017/09/13/magazine/rt -sputnik-and-russias-new-theory-\nof-war.html. \n58 Ibid. \n19 \n either editorial omission or commission.59 Some criticize Russian media diplomacy as  a mere re-\nemergence of Soviet style propaganda and disinformation, while other s characterize its efforts  as \na \u201cfirehose of falsehoods\u201d leveraged by the techn ologies of the information era. 60 \nMediaBiasFactChecks.com  concurs with some of these allegations,  labelling Sputnik for \npublishing a mix of truthful, misleading and false stories; but, RT News is considered mostly \nfactual but categorized as using loaded language to entice strong public emotions over events.61 \nRutland argues  that RT viewers   \n\u2026experience cognitive dissonance. Domestically, the Russia regime legitimizes \nitself as a defender of traditional conservative values\u2026But Russian Today presents \nitself as a radical, free thinking critic of establishment thinking. Its broadcasts \noscillate between ridic uling Western political correctness, multiculturalism, and \ngay rights on one.62 \nSimilarly, Russia criticizes the West\u2019s deontological perspective towards media reporting, \narguing \u201cthere is no such thing as objective reporting\u201d and justifying  the deployment of the \nnecessary  means to sway foreign publics.63  \nThere appears to be  no effort made by Russian officials and media outlets to reconcile \nthese widely divergent ideologies ; instead, Russian public diplomacy is entrenched with deep \ncontradictions.  Walter suggests the West misinterprets  Russia\u2019s significant investment  into its \nmedia, was not \u201cto build prestige and gain respect from the outside world,\u201d but to \u201ccontain the \nspread of democracy and reshape the norms of the international order.\u201d64 Russia is not t he only \n                                                           \n59 Christopher Walker, \u201cThe Hijacking of \u2018Soft -Power\u2019,\u201d Journal of Democracy  Vol 27, No 1 (January \n2016), 51  \n60 Christopher Paul and Miriam Matthews, \u201cThe Russian \u2018Firehose of Falsehood\u2019 Propaganda Model: Why it \nMay Work and Options to Counter it\u201d RAND Corporation  (2016). \n61 \"Media Bias/Fact Check - Search and Learn the Bias of News Media.\u201d Media Bias Fact Check. Acc essed \nMay 4, 2018.  https://mediabiasfactcheck.com/ . \n62 Rutland, \u201cThe Limits of Russia\u2019s \u2018Soft Power\u2019,\u201d 403.  \n63 Peter Pomerantsev, \u201cInside Putin\u2019s Information War,\u201d PoliticoMagazine (04 January 2015). Accessed 03 \nMay 2018. https://www.politico.com/magazine/story/2015/01/putin -russia-tv-113960.  \n64 Christopher Walker, \u201cThe Hijacking of \u2018Soft -Power\u2019.\u201d \n20 \n regime to adopt these strategies,  with Iran\u2019s Press TV and CCTV shar ing similar philosophies.65 \nTools like Spu tnik and social media troll factories serve to spread confusion and encourage \ndisunity within their target audiences. Europe, for example, is portrayed as weak, focusing on \nissues like the Greek economic  crisis and the influx of migrants; simultaneously, it consider s the \nNATO expansion  an existential threat , accusing political leaders a meagre vassal of the US \ngovernment. 66   \nThe Russian Fede ration\u2019s international reputation was hurt most by the duality between its \nmessaging and actions, notably during the Ukrainian and Geor gian conflicts. Avgerinos argued  \nthat Russia\u2019s image  was severe ly affected by the Kremlin\u2019s \u201cfailure to promptly form a coherent \npublic relations strategy and convey its point of view to foreign media \u2026 as the Ukrainian \nversion of the story dominated in the press and was accepted by Western publics as the truth.\u201d67 \nThe Orange Revolution, th e Gazprom dispute, the Russian-Georgian war, the Annexation of \nCrimea, and the conflict in the Donetsk region demonstrate d some of Russia\u2019s use of hard power \nto exert influence into a neighbouring state . The Kremlin felt completely justi fied in their \nactions, advocating for the rights of its compatriots  and interdicting perceived hostile forces near \ntheir borders. However,  Nye and Leonard  argued that explaining domestic decisions to foreign \npress is a crucial element of public diplomacy,  but many government s pay more attention of \nexplaining political decisions only to their domestic audiences, consequently overlooking how \ntheir actions may be perceived by the international community.68 The Russian Federation  made \n                                                           \n65 Christopher Walker, \u201cThe Hijacking of \u2018Soft -Power\u2019,\u201d 61. \n66 \u201cPutin: US needs vassals, not allies, it doesn\u2019t suite Russia,\u201d YouTube video, 4:40. Posted by \u201cRT,\u201d 16 \nApril 2015. www.youtube.com/watch? v-MDyCWKcONHk ; Kragh, \u201cRussia\u2019s Strategy for Influence Through \nPublic Diplomacy and Active Measures: The Swedish Case,\u201d 788 \n67 Avgerinos, \u201c Russia\u2019s Public Diplomacy Effort: What the Kremlin is Doing and Why it is Not Working,\u201d \n119-120. \n68 Nye, Soft Power: Th e Means to Success in World Politics . 1st ed. (New York: Public Affairs, 2004), 107 -\n108; Mark Leonard, \"Diplomacy by Other Means,\"  Foreign Policy  no. 132 (Sept 2002): 50. https://search -proquest-\ncom.cfc.idm.oclc.org/docview/224048517?accountid=9867.  \n21 \n precisely this mistake  even though  it claimed a military victory in Georgian . Essentially,  they \nlost the media war  because th e Kremlin  \u201cfailed to put together a sophisticated communications \nstrategy to relay Russia\u2019s version of the conflict to international audiences,\u201d whereby the Russian \nFederation  was demonized for its actions.69 This duality and inconsistency have frustrated \nWestern media and policy makers , further agitat ing the anti-Russian bias. Consequently , the \nRussian Federation  makes use of media outlets , as a part of their grey-zone strategies , to \noverwhelm foreign publics  and sow confusion , making not only difficult to discern facts from \nfiction but exasperating underlying societal divides and casting doubt on the legitimacy of \ndemocratic leaders. 70 Western actors, accustomed to linear, legal and overt approaches, \nunderestimated the magnitude of Russia\u2019s public diplomacy efforts but also failed to understand \nits function within Russia\u2019s new hybrid strategy, especially pertaining to its Near Abroad.  \nThe Russian World  \nThe Russian Orthodox Church and Russian GONGOs  more closely resemble  the original \nprinciples of public diplomacy and Nye\u2019s soft power, yet they remain divergent from Western \npractices. The Kremlin views these institutions as agents of the state reaching into the Russian \ndiasporas to project their soft power and the notion s of Russkiy Mir  and Novorossiya .71 Sharing \nsimilar primary convictions  with Russian Foreign Policy , they focus on shaping the search for \n                                                           \n69 Avgerinos, \u201c Russia\u2019s Public Diplomacy Effort: What the Kremlin is Doing and Why it is Not Working,\u201d \n120. \n70 Mike Wendling and Will Yates. \"NATO Says Viral News Outlet is Part of \"Kremlin Misinformation \nMachine\",\"  BBC News (11 February 2017) . http://www.bbc.com/news/blogs -trending-38936812 . \n71 Based on Shedrovitsky, Russkiy Mir  or \u201cRussian World\u201d is defined as a as a network of communities \nthinking and speaking in Russian.  The term Novorossiya  was reinvigorated by President Putin in 2014 to emphasise \nthat the regions of Kharkov, Lunansk, Donetsk, Kherson, Nikolayev and Odessa were part not part of Ukraine \nduring the tsarist era, but part of Russia. This plays into the minds et that Russia wants to reclaim their lost territories \nand re-unite its Russian communities with the Russian Federation; Alexander Sergunin and Leonid Karabeshkin. \n\u201cUnderstanding Russia\u2019s Soft Power Strategy.\u201d Politics Vol. 35 (3 -4) (2015), 355;  \"Transcrip t: Vladimir Putin\u2019s \nApril 17 Q&A.\"  Washington Post ( 04 April 2014). Accessed 06 May \n2018. https://www.washingtonpost.com/world/transcript -vladimir-putins-april-17-qanda/2014/04/17/ff77b4a2 -c635-\n11e3-8b9a-8e0977a24aeb_story.html . \n22 \n Russia\u2019s national identity , including  a sense of Russian national ism, deep-rooted sense of \nconservatism, advocacy of anti -liberalism, profound disli ke for Western democracy, and \ncontinuation of the former Russian \u201cfreedom of fear.\u201d 72 Russian GONGOs, like the Russkiy Mir \nFoundation and Rossotrudnichestvo , experience d some modest success  but they may pale in \ncomparison compared to larger institutions; as smaller institutions, they have concentrated most \nof their offices in regions of national interest , Europe and South East Asia , attempting to \nmaximize their influence .73 Russotrudnichestvo , however, despite its best efforts, has not lived \nup to expectations,  has provided a  low number of scholarships available f or post-soviet states \nand acquired a reputation  for incompeten cy.74 The Kremlin\u2019s restrictions on foreign NGOs \noperating within the state has further impeded relationships betw een Russian and foreign states.75  \nSince the colour revolutions, the rhetoric of the Russian Orthodox Church prominently  \nfocused the \u2018sacred\u2019 East Slavic orthodox community , eliciting the old idea of a \u2018Holy Russia\u2019 to \nreunite Russia, Belarus and Ukraine as an informal  (religious)  empire.76 The ROC is considered \nby some as \u201cthe Kremlin\u2019s soft -power instrument par excellence\u201d  and an effective mean  of \nstrengthen ing the linkages with post -Soviet states; however, others scrutinize its credibility for \nits close collaboration with the Russian gover nment.77 With Putin\u2019s help, the Moscow \nPatriarchate brought the Russian Orthodox Church Outside Russia  under its fold , meaning the \n                                                           \n72 van Herpen, Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy , 148-149. \n73 \u201cRussian Centers of the Russkiy Mir Foundation.\u201d Russkiy Mir Foundation. Accessed 0 May 2018. \nhttps://russkiymir.ru/en/rucenter/ .  \n74 Rutland, \u201cThe Limits of Russia\u2019s \u2018Soft Power\u2019,\u201d 406.  \n75 Chloe Arnold, \u201cRussia: NGOs Uneasy as Dea dline Passes,\u201d RadioFreeEurope Radio Liberty  19 April \n2007). Accessed 06 May 2018. https://www.rferl.org/a/1075954.html ; \u201cRussia Closer to Controlling NGOs,\u201d BBC \nNews (27 December 2005). Accessed 06 May 2018. http://news.bbc.co.uk/2/hi/europe/4562278.stm .  \n76 This notion mirrors with Shedrovitsky\u2019s concept Russkiy Mir previously mentioned, but with a theological \nidentity. \n77 Van Herpen,  Putin\u2019s P ropaganda Machine, Soft Power and Russian Foreign Policy,  268; According to \nCull, the credibility of public diplomacy via cultural diplomacy and international broadcasting is contingent on its \nperceived distance from the government; see: Nicolas J. Cull, \u201c Public Diplomacy: Taxonomies and Histories,\u201d The \nAnnals of the American Academy of Political and Social Science 616, no. 1 (2008), 33 -36. \n23 \n Kremlin could maintain a closer grip of the priest appointments in foreign states  and expecting \npriests to support the \u201cconservative and often openly reactionary version of the Orthodoxy \npropagated by the Moscow Patriarchate.\u201d78 The ROC also acts as Kremlin\u2019s unofficial \nmouthpiece in international organizations , \u201cwhere [it attacks]  universal human rights in the  name \nof \u2018traditional values\u2019.\u201d79 But the Western States are not the only  to criticize the centralization of \nthe Church. Belarus, shar ing good diplomatic, economic and military tie s with Russia , seeks \nmore independence and self-governance status for the Belarusian Orthodox Church , especially \nsince the intensified conflict in Ukraine.80 Regardless, the Moscow Patriarchate  will continue its \nefforts to promote unity and a collective identity amongst all its self -governing branches of the \nROC, especially those  in Eastern Europe .81  \nCONCLUSION  \nPublic diplomacy aims to influence  foreign publics\u2019 perceptio n, promote greater mutual \nunderstanding and indirectly impact official relations  with foreig n governments to serve their \nnational interests. It is quintessentially a soft policy aimed at achieving hard goals.  Although  \nadopting a similar public diplomacy framework  to the West, Russian understanding  of public \ndiplomacy  is vastly dif ferent and divergent from Nye\u2019s soft power . Believing it  could never truly \nrely on other states for its survival, the Kremlin\u2019s  motives are best understood through a realist, \nWestphalian and low context societ al lens, where  it aims to regain control of Russia\u2019s destiny \nand sovereignty. This perspective explain s the dichotomy between the search for a defined \n                                                           \n78 Van Herpen,  Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy,  268 \n79 International organization such  as the UN, UNESCO, the OSCE and the Council of Europe; Van Herpen,  \nPutin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy,  268; \"Russkiy Mir: \"Russian World\".\" \nGerman Council on Foreign Relations. Accessed May 5, 2018.  https://dgap.org/en/node/28188 . \n80 \u201cBelarusian Orthodox Church Seeks More Independence from Russia,\u201d BelarusDigest . Accessed 05 May \n2018. https://belarusdigest.com/story/belarusian -orthodox-church-seeks-more-independence -from-russia/. \n81  Self-governing branches of the ROC in Eastern Europe are Ukraine, Estonia, Latvia, Moldova and \nBelarus. \n24 \n Russian identity and the desire to reaffirm its position as a great power. It also explain s the vast \ninconsistencies and duality between the Kremlin\u2019s rhetoric and its  actions; that in one breath, the \ndiscourse speaks to non-intervention and sovereignty while defending Assad and Russian  actions \nin Georgia and Ukraine. The global information age  further changed the conduct of warfare of \nthe 21st century, necessitating the need for new tactics and strategies to contain the West\u2019s liberal \nand democratic narrative. The Kremlin re -invigorated  its own version of  public diplomacy , \nintegrating  overt and covert strategies drawn its former Soviet strategies  and leveraged by the \nlatest information technologi es. This form of Russian public diplomacy became an attractive \noption for grey-zone or hybrid strategy, subservient to the achievement of Russian economic and \nmilitary objectives, especially pertaining to the Near Abroad.  \nWhile it may be too soon to evaluate the long -term outcomes of Russian public  diplomacy \nand its impact on  foreign policy,  the efforts to project a positive image of Russia were  \novershadowed by the deployment  of hard military and information power, particularly in \nGeorgia and Ukraine.  Although Russia justified its actions as legitimate in the face of \nhumanitarian aid and self -defence, the West considers Russian military intervention as flagrant \nbreaches of international law.  This use of force, along with  its current interference in Syria, has \nreinforced negative stereotypes of Russia as a hard power, undermining any soft power and \npublic diplomacy initiatives. \u201cLooking like the evil wrongdoer,\u201d Russian officials failed \nrepeatedly  to develop an adequate media strategy  to explain decisions to foreign publics. 82 \nRussia, however, ma de use its media to overwhelm foreign audiences,  spread confusion, sow \nseeds of doubt and encourage disunity ; this is becoming  more evident in the region of Western \nEurope and the United States . With Putin\u2019s help, the Russian Orthodox Church was re-\n                                                           \n82 Avgerinos, \u201cRussia\u2019s Public Diplomacy Effort: What the Kremlin is Doing and Why it is Not Working,\u201d \n121. \n25 \n invigorated as an effective mean of strengthening the linkages between Moscow and foreign \ndiasporas, promoting a Russian nationalism and conservatism. The use of NGOs and diaspora \ndiplomacy , also atte mpting to create  a level of separation between foreign p ublic and the \nKremlin, has been met with mixed results  with Kremlin calling for tighter control over NGO \nactivities and finances.   \nEven though the Russian Federation continues to  be criticized for its deceitfulness and \nnepotism, they do understand public diplomacy more than the West\u2019s give them credit for.  From \nthe Russian perspective, the Kremlin does not feel the need to differentiate between overt and \ncovert or truth and lie, so long as they  meet their foreign policy objectives  and avoid military \nconfrontation . Public diplomacy should also concentrate on \u201cbuilding relationships, starting from \nunderstanding other countries' needs, cultures, and peoples and then looking for areas to make \ncommon cause.\u201d83 As ideologies continue to diverge between Russia and liberal democratic \nstates, the Russian Federation\u2019s focus  will be towards only those most loyal and willing to \nsupport Russian foreign policy, on a rapprochement with regions formerly under Russian \nimperial control, such as Crimea and the Donetsk region, and states with similar anti -liberal \nphilosophies, such as Iran, Belarus, China and Syria.   \n \n \ns \n \n \n                                                           \n83 Mark Leonard, \"Diplomacy by Other Means,\" 50.  \n26 \n BIBLIOGRAPHY  \nBooks: \n \nBerridge, Geoff.  Diplomacy: Theory and Practice . 4th ed. New York ; Houndmills , Basingstoke, \nHampshire ; Palgrave Macmillan, 2010.  \nHerpen, Marcel van.  Putin's Propaganda Machine: Soft Power and Russian Foreign Policy . \nLondon; Lanham,Md: Rowman & Littlefield, 2016.  \nKanet, Roger E. and R\u00e9mi Piet.  Shifting Priorities in Russia's Foreign and Security Policy . \nBurlington, VT; Farnham, Surrey, UK: Ashgate, 2013a.  \nMachiavelli, Niccol\u00f2. Machiavelli on International Relations . First ed. New York; Oxford: \nOxford University Press, 2014.  \nNye, Joseph S. Nye,  Soft Power: The Means to Success in World Politics , 1st ed. New York: \nPublic Affairs, 2004.  \nSeib, Philip M.  Real-Time Diplomacy: Politics and Power in the Social Media Era . 1st ed. New \nYork: Palgrave Macmillan, 2012.  \nTao, Hanzhang, Shibing Yuan, and Sunzi . Sun Tzu's Art of War: The Modern Chinese \nInterpretation . New York: Sterling Pub. Co, 2000.  \nTaylor, Philip M.  Munitions of the Mind: A History of Propaganda from the Ancient World to the \nPresent Era . 3rd ed. Manchester;New  York;: Manchester University Press, 2003  \nvan Herpen, Marcel. Putin\u2019s Propaganda Machine, Soft Power and Russian Foreign Policy . \nLondon: Landham, Md: Rowman & Littlefield, 2016.  \n \nArticles in a Periodical : \n \nAvgerinos, Katherine P \u201cRussia\u2019s Public Diplomacy Effort: What the Kremlin is Doing and Why \nit is Not Working.\u201d Journal of Public & International Affairs Vol. 20 (Spring 2009): 115 -\n132. \n \nCull, Nicholas J. Public Diplomacy: Lessons from the Past. Los Angele s, CA: Figueroa Press, \n2009. http://kamudiplomasisi.org/pdf/kitaplar/PDPerspectivesLessons.pdf .  \n \nCull, Nicholas J. \"Public Diplomacy: Taxonomies and Histories.\"  The Annals o f the American \nAcademy of Political and Social Science  616, no. 1(2008): 31 -54. \nFeklyunina, Valentina. \"Soft Power and Identity: Russia, Ukraine and the \u2018Russian \nWorld(s)\u2019.\"  European Journal of International Relations 22, no. 4 (December 1, 2016a): \n773-796. doi:10.1177/1354066115601200.  https://doi.org/10.1177/1354066115601200 . \n \n27 \n Fukuyama, Francis. \u201cThe End of History?\u201d The National Interest (Summer 198 9). \nhttps://www.embl.de/aboutus/science_society/discussion/discussion_2006/ref1 -\n22june06.pdf  \nGaleotti, Mark. \u201cHybrid, Ambiguous, And Non -Linear? How Ne w is Russia\u2019s \u2018New War of \nWar?\u2019\u201d Small Wars & Insurgencies  Vol. 27 No. 2 (2016): 282 -301. \nHo, Elaine L.E. and Fiona McConnell. \u201cConceptualizing \u2018Diaspora Diplomacy\u2019: Territory and \nPopulations Betwixt the Domestic and Foreign.\u201d Progress in Human Geography. SAGE \nPublication Lt d, 2017: http://journals.sagepub.com/doi/pdf/10.1177/0309132517740217 , \n16. \nKragh, Martin and Sebastian Asberg. \u201cRussia\u2019s Strategy for Influence Through Public \nDiplomacy and Active Measures: The Swedish Case,\u201d Journal of Strategic Studies 40:6, \n2017: 773 -816 \nLeonard, Mark. \"Diplomacy by Other Means.\"  Foreign Policy  no. 132 (Sept 2002): 48 -56. \nhttps://search -proquest-com.cfc.idm.oclc.org/docview/224048517?accountid=9867.  \nPahlavi, Pierre. \"Evaluating Public Diplomacy Programmes.\"  The Hague Journal of \nDiplomacy  2, no. 3 (2007): 255 -281 \nPahlavi, Pierre. \u201cGrey Zone Strategies.\u201d Canadian Defence at 1 50 and Beyond . NATO \nAssociation of Canada, 2017: 40 -42. \nPayne, Daniel P. \"Spiritual Security, the Russian Orthodox Church, and the Russian Foreign \nMinistry: Collaboration or Cooptation?\"  Journal of Church and State  52, no. 4 (Autumn, \n2010): 712 -727. https://search -proquest-\ncom.cfc.idm.oclc.org/docview/853756326?accountid=9867.  \nRauchhaus, Robert. \"Evaluating the Nuclear Peace Hypothesis: A Quantitative Approach,\" The \nJournal of Conflict Resolution  53, no. 2 (2009): 258 -277. \nRutland, Peter and Andrei Kazantsev. \u201cThe Limits of Russia\u2019s \u2018Soft Power\u2019.\u201d Journal of \nPolitical Power  9, no. 3 (2016): 395 -412. \nSergunin, Alexander and Leonid Karabeshkin. \u201cUnderstanding Russia\u2019s Soft Power Strategy.\u201d \nPolitics Vol. 35 (3 -4) (2015), 347 -363 \nSaari, Sinikukka . \"Russia's Post -Orange Revolution Strategies to Increase its Influence in Former \nSoviet Republics: Public Diplomacy Po Russkii.\"  Europe-Asia Studies  66, no. 1 (2014): \n50-65. \nWalker, Christopher. \u201cThe Hijacking of \u2018Soft -Power\u2019,\u201d Journal of Democracy  Vol 27, No 1 \n(January 2016): 49 -63. \n \n \n \n28 \n Other Academic Publications:  \nIISS Military Balance 2015. London: International Institute for Strategic Studies, 2015.  \nPahlavi, Pierre. Mass Diplomacy: Foreign Policy in the Global Information Age . Montreal: \nMcGill University, 2004.  \nPaul, Christopher and Miriam Matthews. The Russian \u201cFirehose of Falsehood\u201d Propaganda \nModel: Why it Might Work and Options to Count it. RAND Corporation, 2016.  \n \n \nElectronic Newspaper and Magazine Articles:  \n \n\"A New Orthodox Church Next to the Eiffel Tower Boosts Russian Soft Power.\"  The \nEconomist , 5 December 2016.  Accessed 11 May 2018.  \nhttps://www.economist.com/blogs/erasmus/2016/12/ecclesiastical -diplomacy ;  \n \n \n\u201cRussia Closer to Controlling NGOs.\u201d BBC News , 27 December 2005. Accessed 06 May 2018. \nhttp://news.bbc.co.uk/2/hi/europe/4562278.stm .  \n \nArnold, Chloe \u201cRussia: NGOs Uneasy as Deadline Passes.\u201d RadioFreeEurope Radio Liberty,  19 \nApril 2007. Accessed 06 May 2018. https://www.rferl.org/a/1075954.html  \n \nJust, Thomas. \u201cPromoting Russia Abroad: Russia\u2019s Post -Cold War National Identity and Public \nDiplomacy.\u201d The Journal of International Communication  Vol. 22 No. 1 (2016): 82 -95. \n \nKolerov, Modest. \u201cWhat We Know About Post -Soviet Countries\u201d Russia In Global Affairs . 13 \nOctober 2016. Accessed 02 May 2018. http://eng.globalaffairs.ru/number/n_7337  \n \n \nLichfield, John. \u201cParis Welcomes Kremlin -funded Russian Orthodox Cathedral \u2013 As French \nCourt Tries to Seize its Assets .\u201d Independent , Paris, 18 March 2016.  Accessed 11 May \n2018. https://www.independent.co.uk/news/world/europe/sainte -trinite-paris-welcomes -\nkremlin-funded-russian-orthodox-cathedral-as-french-court-tries-to-a6939601.html  \n \nLuhn, Alec. \"Ex -Soviet Countries on Front Line of Russia's Media War with the West.\" The \nGuardian, 6 January 2015. Accessed May 2, 2018.   \nhttp://www.theguardian.com/world/2015/jan/06/ -sp-ex-soviet-countries-front-line-russia-\nmedia-propaganda -war-west. \n \nPomerantsev, Peter. \u201cInside Putin\u2019s Information War,\u201d PoliticoMagazine (04 January 2015). \nAccessed 03 May 2018. https://www.politico.com/magazine/story/2015/01/putin -russia-tv-\n113960. \n \n29 \n Rutenberg, Jim. \"RT, Sputnik and Russia\u2019s New Theory of War.\"  The New York Times,  -09-13, \n2017. Accessed 02 May 2018. https://www.nytimes.com/2017/09/13/magazine/rt -sputnik-\nand-russias-new-theory-of-war.html. \n \nWendling, Mike and Will Yates. \"NATO Says Viral News Outlet is Part of \"Kremlin \nMisinformation Machine\".\"  BBC News,  11 February 2017.  \n http://www.bbc.com/news/blogs -trending-38936812 . \n \nVera Zakem, Paul J Saunders. \"How Russia Views its 'Compatriots' in the Near Abroad.\" The \nCenter for the National Interest. Accessed May 2, \n2018. http://nationalinterest.org/feature/how -russia-views-its-compatriots -the-near-abroad-\n15516. \n \n \nProfessional Websites:  \n \n\u201cAbout Rossotrudnichestvo.\u201d Rossotrudnichestvo. Accessed 05 May 2018. \nhttp://rs.gov.ru/en/about .  \n \n\u201cAbout RT .\u201d RT News. Accessed 02 May 2018. https://www.rt.com/about -us/ \n \n\u201cAbout Russkiv Mir Foundation.\u201d Russkiy Mir Foundation. Accessed on 03 May 2018. \nhttps://russkiymir.ru/en/fund/  \n \n\"Moscow Says 30 Million Russians Live Abroad,\" Radio Free Europe R adio Liberty. Accessed \nMay 2, 2018.  https://www.rferl.org/a/1066475.html . \n \n\u201cRussian Centers of the Russkiy Mir Foundation.\u201d Russkiy Mir Foundation. Accessed 0 May \n2018. https://russkiymir.ru/en/rucenter/ . \n \n\"Russkiy Mir: \"Russian World\".\" German Council on Foreign Relations. Accessed May 5, \n2018. https://dgap.org/en/node/28188 . \n \n\"Transcript: Vladimir Putin\u2019s April 17 Q&A.\"  Washington Post, 04 April 2014. Accessed 06 \nMay 2018.  https://www.washingtonpost.com/world/transcript -vladimir-putins-april-17-\nqanda/2014/04/17/ff77b4a2 -c635-11e3-8b9a-8e0977a24aeb_story.html . \nFederation of American Scientists.  \u201cThe Foreign Policy Concept of the Russian Federation,\u201d \n(Moscow: 28 June 2000). Accessed 28 October 2017. \nhttps://fas.org/nuke/guide/russia/doctrine/econcept.htm  \n \nMinistry of Foreign Affairs of the Russian Federation. \u201cConcept of the Foreign Policy of the \nRussian Federation,\u201d (Moscow: 12 February 2013). Accessed on 28 October 2017. \nhttp://www.mid.ru/foreign_policy/official_documents/ -\n/asset_publisher/CptICkB6BZ29/content/id/122186  \n30 \n Public Diplomacy Alumni Association. \u201cAbout U.S. Public Diplomacy,\u201d PublicDiplomacy.org , \n2018. Accessed 23 April 2018. http://pdaa.publicdiplomacy.org/?page_id=6  \nPutin, President Vladimir. \"Annual Address to the Federal Assembly of the Russian Federation,\" \n(Moscow: 8 July 2000). Accessed 28 October 2017 . \nhttp://en.kremlin.ru/events/president/transcripts/21480  \nPutin, Vladimir. \"Vladimir Putin's First Paper as President: 'Russia at the Turn of the \nMillennium' - A Strategy for Russia's Revi val.\" Signs of the Times , 31 December  1999, \nAccessed 28 October 2017. https://www.sott.net/article/310072 -Vladimir-Putins-first-\npaper-as-president-Russia-at-the-Turn-of-the-Millennium -A-Strategy-for-Russias-Revival \nTeam of the Official Website of the President of Russia. \"Interview with Time Magazine,\" 19 \nDecember 2007. Accessed 28 April 2018.    \nhttp://en.kremlin.ru/events/president/transcripts/24735  \n \nTeam of the Official Website of the President of Russia . \"The Foreign Policy Concept of the \nRussian Feder ation,\" (Moscow: 12 January 2008). Accessed 28 April 2018. \nhttp://en.kremlin.ru/supplement/4116 .  \n \nYale Law School Lillian Goldman Law Library. \u201c8 January, 1918: President Woodrow Wilson\u2019s \nFourteen Points,\u201d The Avalon Project . Accessed 13 April 2018. \nhttp://avalon.law.yale.edu/20th_century/wilson14.asp  \nOnline Blogs:  \n \n\u201cBelarusian Orthodox Church Seeks More Independence from Russia,\u201d BelarusDigest . Accessed \n05 May 2018. https://belarusdigest.com/story/belarusian -orthodox-church-seeks-more-\nindependence -from-russia/. \n\"A Former Russian Troll Explains how to Spread Fake News.\"  Accessed May 3, \n2018. http://time.com/5168202/russia -troll-internet-research-agency/. \n \nCull, Nicholas J. Cull. \u201cPublic Diplomacy Before Gullion: The Evolution of a Phrase.\u201d 18 April \n2006. Accessed 08 April 2018. http://uscpublicdiplomacy.org/blog/public -diplomacy -\ngullion-evolution -phrase \nMark Galeotti, \u201cThe \u2018Gerasimov Doctrine\u2019 and Russian Non -Linear War,\u201d In Moscow\u2019s \nShadows, 2013. Accessed 02 April 2018. \nhttps://inmoscowsshadows.wordpress.com/2014/07/06/the -gerasimov -doctrine-and-\nrussian-non-linear-war/ \n \n \n \n \n \n \n31 \n YouTube Videos  \n \n\u201cPutin: US needs vassals, not allies, it doesn\u2019t suit Russia,\u201d YouTube video, 4:40. Posted by \n\u201cRT,\u201d 16 April 2015, www.youtube.com/watch?v=MDyCWKcONHk  \n \nOnline Database:  \n \n\"Media Bias/Fact Check - Search and Learn the Bias of News Media.\u201d Media Bias Fact Check. \nAccessed May 4, 2018.  https://mediabiasfactcheck.com/ . \n \n\u201cPropaganda,\u201d Online Etymology Dictionary. Accesse d 12 April 2018. \nhttps://www.etymonline.com/word/propaganda . \n \n Yale Law School Lillian Goldman Law Library. \u201c8 January, 1918: President Woodrow Wilson\u2019s \nFourteen Points,\u201d The Avalon Project . Accessed 13 April 2018. \nhttp://avalon.law.yale.edu/20th_century/wilson14.asp \n \nOnline Blogs: \n \n\u201cBelarusian Orthodox Church Seeks More Independence from Russia,\u201d BelarusDigest . Accessed \n05 May 2018. https://belarusdigest.com/story/belarusian -orthodox-church-seeks-more-\nindependence -from-russia/. \n\"A Former Russian Troll Explains how to Spread Fa ke News.\"  Accessed May 3, \n2018. http://time.com/5168202/russia -troll-internet-research-agency/. \n \nCull, Nicholas J. Cull. \u201cPublic Diplomacy Before Gullion: The Evolution of a Phrase.\u201d 18 April \n2006. Accessed 08 April 2018. http://uscpublicdiplomacy.org/blog/pub lic-diplomacy-\ngullion-evolution-phrase \nMark Galeotti, \u201cThe \u2018Gerasimov Doctrine\u2019 and Russian Non-Linear War,\u201d In Moscow\u2019s \nShadows, 2013. Accessed 02 April 2018. \nhttps://inmoscowsshadows.wordpress.com/2014/07/06/the-gerasimov-doctrine-and-\nrussian-non-linear-war/ \n \nYouTube Videos \n \n\u201cPutin: US needs vassals, not allies, it doesn\u2019t suit Russia,\u201d YouTube video, 4:40. Posted by \n\u201cRT,\u201d 16 April 2015, www.youtube.com/watch?v=MDyCWKcONHk  \n \nOnline Database: \n \n\"Media Bias/Fact Check - Search and Learn the Bias of News Media.\u201d Media Bias Fact Check. \nAccessed May 4, 2018.  https://mediabiasfactcheck.com/ . \n \n\u201cPropaganda,\u201d Online Etymology Dictionary. Accessed 12 April 2018. \nhttps://www.etymonline.com/word/propaganda \n \n \n \n \n32", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "JCSP 44 PCEMI 44", "author": ["MMTN Bolduc"], "venue": "NA", "pub_year": "NA", "abstract": "The end of the Cold War brought about a hiatus and marginalization of public diplomacy  strategies because of the view that former enemies would become partners and stakeholders in"}, "filled": false, "gsrank": 544, "pub_url": "https://www.cfc.forces.gc.ca/papers/csc/csc44/solo/bolduc.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:fAJZktm6oGoJ:scholar.google.com/&output=cite&scirp=543&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=fAJZktm6oGoJ&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:fAJZktm6oGoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.cfc.forces.gc.ca/papers/csc/csc44/solo/bolduc.pdf"}}, {"title": "Proceedings of the Joint Computation and Journalism European Data & Computational Journalism Conference", "year": "2023", "pdf_data": "Joint\nComputation + Journalism\nEuropean Data & Computational JournalismConference\n22-24 June 2023SwitzerlandProceedings\nof the\nEditors :\nBahareh Heravi\nTitus Plattner\nFlorian Stalph ISBN: 978-1-84469-038-1  \nISBN: 978-1-84469-038-1\nCopyright : The Authors of \nthe papers in the collection\n3The Joint Computation\n+Journalism and European\nData & Computational\nJournalism Conference, was\nheld from June 22nd to June\n24th, 2023, at ETH Zurich,\nSwitzerland. Th e event, marking\nthe 10th edition of the\nComputation+Journalism\nSymposium (C+J) and the 4th\nedition of the European Data\nand Computational Journalism\nConference (datajconf), was\njointly hosted for the first time\nin Zurich. It was also a notable\noccasion as the C+J\nSymposium was held outside of\nthe United States for the first\ntime.\nThe conference brought \ntogether professionals from \nindustry, academia, and \njournalism to foster a \nmultifaceted dialogue on \ninformation, data, social, and \ncomputer sciences. The \nobjective was to propel \nresearch and practice in the \nextensive field of Data and \nComputational Journalism. This \nevent served as a platform for \njournalists and researchers  to interact, allowing news \norganizations to engage \nwith computational and \nsocial scientists, and \nexplore innovative practices \nthat benefit the public. The \nfirst day of the conference, \ndedicated to workshops, \ntook place at the Tamedia \nHQ (TX Group), in Zurich.\nA key focus of the \nconference's program was \nthe impact of Artificial \nIntelligence in the media \nsector. The agenda included \na diverse array of talks, \nworkshops, and panel \ndiscussions. Topics covered \nwere the future of AI in \nnews, deepfake ethics, \nnatural language processing \n(NLP), algorithmic \naccountability, data \njournalism, newsroom \nautomation, and many other  \nissues.\nThe conference provided a \nblend of academic \npresentations and keynotes \nfrom industry leaders,\n4encapsulating a comprehensive \nperspective on the current and \nfuture trends in the realm of \njournalism and technology.\nBahareh Heravi,\nTitus Plattner  & Fabio Z\u00fcnd\nC+J DataJConf 2019\nProgram Chair\n& General Co-Chairs\nThe Ethical Dimensions of Data Quality for Automated\nFact-Checking\nLaurence Dierickx\nUniversity of Bergen\nBergen, Norway\nl.dierickx@uib.noCarl-Gustav Lind\u00e9n\nUniversity of Bergen\nBergen, Norway\ncarl-gustav.linden@uib.noAndreas Lothe Opdahl\nUniversity of Bergen\nBergen, Norway\nandreas.opdahl@uib.no\nABSTRACT\nAutomated fact-checking (AFC) has grown in popularity to address\nthe online spread of misinformation, propaganda, and misinforma-\ntion about critical contemporary issues. Various natural language\nprocessing, machine learning, knowledge representation and data-\nbase techniques have been used in AFC, whereas, from an end-user\nperspective, little attention was paid to the quality of the datasets\nfeeding these information systems. Considering the recognised\nneed to blend AI-based tools with journalistic values, this research\nproposes a practical framework for assessing and improving data\nquality when developing or implementing AFC systems. Drawing\non an interdisciplinary approach, it contributes to understanding\nhow to better align AI-based solutions with ethical standards in\njournalism and fact-checking.\nKEYWORDS\nautomated fact-checking, datasets, data quality, ethics\n1 INTRODUCTION\nAutomated fact-checking (AFC) attracted growing interest in the\nwake of the online spreading of misinformation, disinformation, and\npropaganda on significant issues of our contemporary world, such\nas the presidential US elections, the COVID-19 pandemic, the global\nwarming crisis, or the Russian-Ukraine war. Since online lies spread\nfaster than the truth [ 50], automated fact-checking aims to provide\npractical answers to speed up a time-consuming process when\nperformed manually [ 38]. AFC can be used for claim identification,\nevidence retrieval, which consists of finding information beyond\nthe claim, and claim classification [48] [29] [38].\nResearch explored several tools and techniques based on natural\nlanguage processing, machine learning, knowledge representation\nand databases, which play a pivotal role in claim detection and\nverification [ 21]. However, the journalistic field or the journalist as\nend-users were less considered. In a systematic literature review\nof papers devoted to AFC and published over the last five years,\nwe only found 21 papers out of 267 that considered them. In these\nworks, the focus was mainly on the complementarity between the\njournalist and the tool. Less attention was paid to the quality of\nthe datasets that feed these systems, especially from an end-user\nperspective according to the fitness-for-use principle, which relates\nto data that adapt to the use of their final users. Therefore, this\nprinciple goes beyond the sole concerns of accuracy in data [44].\nAt the same time, there is a recognised need for embedding jour-\nnalistic values within AI systems to integrate them into journalism\nworkflows better [ 7][34][28]. AFC systems work well when the\ndomains of facts are restricted and on English corpus, but they are\nnot often scalable to real-time content spread on social media andpre-existing fact datasets appear as insufficient [ 31]. However, they\nare a means to feed helpfully the systems, insofar as information\ndisorders are not solely agenda-related: for instance, conspiracy\ntheories do not go away once they are debunked [19].\nThis research aims to question the quality of the data used in AFC\nsystems and to define how to blend datasets with the professional\nvalues of their potential end-users. Hence, we have developed a\ndata quality assessment to provide a method to evaluate issues and\ndefine the levels to improve when building (or using) datasets in au-\ntomated fact-checking. This framework is grounded in data science\nand previous works on data quality in data-driven journalism [ 13].\nFrom an end-user perspective, it is built on the ethical standards of\njournalism and fact-checking, to contribute to align AFC system\nwith professional values. Therefore, it can be considered a practical\ntool to infuse end-users\u2019 values in AFC systems.\n2DATA QUALITY AND THE FITNESS-FOR-USE\nPRINCIPLE\nThe definition of data quality is protean insofar as it encompasses a\nset of complementary dimensions which were extended and refined\nover time. Accuracy was approached as a measure of agreement\nwith an identified source [ 25], the level of precision and reliability of\nthe data [ 18], or as the representation of a different real-world state\nfrom the one that should have been represented [ 52]. Scientific\nliterature also refers to the completeness of a given dataset, its\nconsistency (in terms of meeting formal requirements), timeliness\nand reliability. Considering that defining data quality remains a\ncomplex task due to the multidimensionality of the concept, an\nagreement was found on the fitness-for-use principle, according to\nwhich quality data meet explicit or implicit user needs [ 5]. In other\nwords, data quality refers to data that adapt to their final use, also\nin terms of relevance and comprehensibility [53].\nThe rise of big data added extra layers to these concerns, as they\nchallenge the quality dimensions of believability, verifiability and\nthe reputation of the data in the context of data collected online\nor through sensors [ 4]. Beyond the correctness of the data, it is\nalso a matter of trusting them [ 8][33]. Considering that building\ntrust is essential for adopting a machine learning application [42],\nall of these considerations are far from trivial in the wake of the\ngrowing development of artificial intelligence systems because of\ntheir strong dependence on data. Nonetheless, the system\u2019s perfor-\nmances also depend on the algorithm at work, which behaviour\nmay also depend on the intrinsic characteristic of the data \u2013 espe-\ncially in terms of volume and completeness [ 16][22][41]. These\nconcerns often remain confined to specialised research areas, and\njournalistic aspects were little considered. In journalism studies,\nresearch on data-driven journalism recognised the structuring role\n5\nLaurence Dierickx, Carl-Gustav Lind\u00e9n, and Andreas Lothe Opdahl\nplayed by computerised databases, which is probably exacerbated\nby introducing AI technologies in newsrooms. In these fields, the\nneed for high quality data is a prerequisite because if the data are\nbad or biased, the information will be bad or biased too [ 1][6]\n[15]. Nonetheless, aspects related to data quality have been little\naddressed, although it was also considered a critical issue [ 12][35].\nFurthermore, it was also suggested that data selection and evalua-\ntion should be journalistic, considering that these tasks are related\nto a journalistic human expertise, while validation, standardisation\nand normalisation should be programmers\u2019 domain [32].\n2.1 Building the Assessment Framework\nAccording to the fitness-for-use principle, data quality assessment\nis use and context-dependent. It encompasses various strategies,\nmethods and techniques to identify erroneous data and measure\ntheir impact on the processes. Its objective is to improve the overall\nquality of the data [ 3][9]. In this research, we defined data qual-\nity indicators that fit journalistic and fact-checking ethical values,\nconsidering that automated fact-checking systems are likely to be\nused by journalists and fact-checkers to support or augment their\nprofessional practices. Also, we considered that fact-checking ac-\ntivities relate to journalism practices as a distinct sub-genre and a\nform of accountable journalism [20] [36] [43].\nThe core ethical standards of journalism are grounded in the\nsocial responsibility of journalism, which indistinctly refers to the\ncontent of the news, the function of news media in society and the\nresponsibility of news media towards society [ 2]. Although ethical\njournalism is first and foremost a matter of practice, it is framed by\nprinciples commonly acknowledged: the respect of the truth, which\nmeans providing verified facts based on reliable sources; reporting\nwith accuracy; providing well-balanced information with fairness,\nindependence and non-partisanship [ 23]. Objectivity is another\nstandard promoted in journalism as a constitutive of professional\nself-perception and identity [ 11]. However, this concept is regularly\ncriticised as it appears as an ideal, or even a myth, because it relies\non the individual subjectivity of the journalist [ 37][54]. Choosing a\ntopic, an angle, sources, and the narrative also illustrate the impos-\nsibility of objectivity insofar as it implies human and organisational\nchoices [45] [51] [55].\nConsidering that explaining these choices contributes to increas-\ning the credibility of the news and to (re) building trust with audi-\nences, transparency was presented as an alternative to the disputed\nconcept of objectivity [ 10][26][27]. Transparency means that jour-\nnalists remain \"open and explicit about their processes, methods,\nlimitations and assumptions\" [ 49]: 1507. This concept gained in-\nterest in the context of digital environments, seen as a means to\nopen the \"black box\" of professional practices. In data journalism,\nfor instance, transparency is considered a normative value that\ncontributes to open journalism [ 40]. Transparency is also at the\nheart of the guidelines promoted by the international fact-checking\norganisations \u2013 International Fact-Checking Network (IFCN) and\nEuropean Fact-Checking Standard Network (EFCSN). Practically,\ntheir members must be transparent about their organisational struc-\nture, funding, partnerships and agreements. They must also be\ncommitted to non-partisanship and fairness. Last but not least, fact-\ncheckers must provide their narratives with all the details, methodsand sources to allow readers to replicate their work. Much more\nthan a discursive stance, transparency rhymes with professional\npractices in fact-checking as it is a practical requirement.\nTable 1: Assessment of the data quality dimensions\nDimension Verification\nTRUTH\nAccuracy Level of interoperability, standardisation\nRatio accurate values/total values (mea-\nsure of erroneous data)\nUniqueness (measurement of duplicate\nentries and redundancies)\nNo encoding problems, no information\noverload\nConsistency Well defined data structure (percentage of\ndata with consistent format and values)\nHomogeneity in the format, structure,\nand values\nUnambiguous and explicit labelling\nCorrectness Identifying abnormal values\nIdentifying the causes of NULL values\nSpelling coherence\nData documented with metadata\nCompliance with metadata\nComprehensibility The extent to which data are understand-\nable by the end-user\nFAIRNESS\nTimeliness Currentness (percentage of updated data)\nCompleteness Appropriate amount of data (ratio miss-\ning values/total values - ratio NULL val-\nues/total values)\nAccessibility Right to use the data\nLevel of retrievability of the data\nObjectivity Unbiased data (size and representativity\nof the sample)\nIdentification of human bias (data and/or\nannotations)\nRelevance The extent to which the data are relevant\nfor the purpose\nNewsworthiness\nData scarcity (fraction of data containing\nrelevant information)\nUsability Making sense in a journalistic context\nTRANSPARENCY\nReliability Authenticity (source)\nAuthority and reputation (source, anno-\ntators)\nCredibility Degree of believability and expertise\n(data source, annotated data and anno-\ntation process - annotators)\nVerifiability Fact-checking the source, the data, the an-\nnotation process, and the annotated data\n6\nThe Ethical Dimensions of Data Quality for Automated Fact-Checking\nTable 2: Sample of Fact-Checking Datasets\nAuthors Description/URL\nAlhindi et al.,\n2021Multidomain dataset based on 4K+ claim\u2013article pairs from diverse sources.\nhttps://github.com/Tariq60/arastance\nArslan et al.,\n2020Dataset of 23K+ statements extracted from U.S. general election presidential debates, annotated by human\ncoders.\nhttps://zenodo.org/record/3609356\nDrchal et al.,\n2022Derived from the FEVER dataset, CsFEVER contains 127K+ claims. CTKFacts contains 3K+ claims from a\ncorpus of more than two million Czech News Agency news reports.\nhttps://huggingface.co/ctu-aic/\nSep\u00falveda-Torres et al.,\n2021Content 7K+ news items classified as Compatible, Contradiction, or Unrelated.\nhttps://zenodo.org/record/4596394\nSamarinas et al.,\n2020Large-scale dataset based on the FEVER dataset, used for evidence-retrieval, and MSMARCO, a collection\nof large-scale datasets for deep learning.\nhttps://github.com/algoprog/Quin\nShahi and Nandini,\n2020Multilingual cross-domain dataset of 5K+ fact-checked news articles on COVID-19, collected from\n04/01/2020 to 01/07/2020.\nhttps://gautamshahi.github.io/FakeCovid/\nKotonya and Toni,\n2020Dataset based on 11,8K claims collected from 5 fact-checking websites.\nhttps://github.com/neemakot/Health-Fact-Checking\nSathe et al.,\n2020Dataset of 124k+ triples consisting of a claim, context and evidence document extracted from English\nWikipedia articles and citations, and 34k+ manually written claims refuted by evidence documents.\nhttps://github.com/wikifactcheck-english/wikifactcheck-english/\nGupta and Srikumar,\n2021Multilingual dataset for factual verification of naturally existing real-world claims composed of 38K+ short\nstatements.\nhttps://github.com/utahnlp/x-fact/\n2.2 Method\nData quality assessments usually consists of defining data quality\nindicators and providing tools for measurement [ 18]. However,\ndata quality also depends on the design and production processes\nat work to generate the data [ 52]. Also, in a data quality assessment,\nsubjective considerations intertwine with objective ones, insofar as\nit reflects human needs, experiences and contexts of [39].\nThe framework to assess data quality for automated fact-checking\nis built upon three core ethical principles in journalism and fact-\nchecking (Table 1): the principle of \"truth\" relates to the data quality\ndimensions of accuracy, consistency, correctness and comprehen-\nsibility; the principle of \"fairness\" encompasses the dimensions of\ntimeliness, completeness, accessibility, objectivity, relevance and\nusability; the principle of \"transparency\", as a lever for trust, is re-\nlated to the reliability, credibility and verifiability of the data. This\nthree-level segmentation assumes that telling the truth involves\nthe knowledge of the application domain the data refers to, that\nbeing fair refers to unbiased and well-balanced information, and\nthat transparency gathers the means for remaining trustworthy.\nAn extensive literature review of papers, pre-prints and pro-\nceedings published between 2020 and 2022 allowed us to identify\na sample of nine datasets developed for automated fact-checking,\nwhich are publicly available (Table 2). This sample only included\ntextual data because a corpus of images involves other types of con-\nsiderations related to the intrinsic characteristics of images in terms\nof blur, noise, contrast, format and compression [ 14]. Nonetheless,\ndata quality challenges also encompass the diversity of datasets,and the quality of annotations [ 57]. Google Refine was used as a\ndata quality tool for data profiling to identify the overall data qual-\nity challenges from formal and empirical perspectives [ 30]. Due to\nthe vast amount of data to assess, we considered the Pareto prin-\nciple relevant, as \"most of the errors are attributable to just a few\nvariables\" [47]: 237.\n3 MAIN FINDINGS\nThe analysis aimed to identify the limitations or issues regarding\nthe ethical principles of truth, fairness and transparency. As the\npurpose is not to attribute good and bad points to each examined\ndataset, this analysis adopted a transversal approach.\n3.1 Truth\nThe nine datasets of our corpus have different characteristics in\nterms of size, domains, languages and format (JSON, CSV, TXT,\nTSV), which do not seem an obstacle to reusing them. However,\ncross-domain approaches (e.g., politics, sports, health) appear as the\nmost challenging to deal with, considering the knowledge required\nto handle each domain well. Four datasets were not documented by\nmetadata or lacked explicit labelling. The use of a sentiment score\nin one dataset was unclear, as well as the labelling used to assess the\nvalidity of a claim. Three datasets contained NULL values, which\nmay have various causes and require human knowledge (e.g. the\nNULL values are equal to zero, the information exists but is not\nknown or irrelevant to the variable). The overall understandability\n7\nLaurence Dierickx, Carl-Gustav Lind\u00e9n, and Andreas Lothe Opdahl\nof the datasets was not always granted because of a lack of docu-\nmentation, although academic papers documented processes. As\nthey relied on textual data, the question of the standardisation and\nharmonisation of the language arose, also in multilingual datasets.\n3.2 Fairness\nIn terms of relevancy, the language and context-dependency of\nthe datasets raised the issue of using them in other languages or\nnational contexts. The datasets\u2019 usability (and reusability) is also\nchallenged by the dimension of accessibility, as most of the datasets\ndid not have an attached licence. The dimension of timeliness is\nalso problematic for several reasons: missing dates (1 dataset), no\nmention of the last update (1 dataset), and corpus collected over a\nlimited period (3 datasets). Hence, the currentness of the datasets\nwas not always guaranteed and raised questions about the rele-\nvance of their reusability, despite they can be useful to fact-check\nold propaganda discourses or conspiracy theories. However, the\nlack of maintenance of the datasets remains an obstacle to meeting\nthe two ethical principles of truth and fairness since information\ndisorders are also a dynamic phenomenon that can vary or change\nover time, and this also applies to concepts and definitions, consid-\nering that the construction of knowledge is an ongoing process. In\naddition, a cross-domain approach made it difficult to assess the\ncompleteness dimension. We also found two datasets with missing\nvalues, with a respective proportion of 11.37% and 24.53%. Nev-\nertheless, the completeness of the datasets remained difficult to\nevaluate, whether for recent or older phenomena, because there is\nno absolute referral to assess it. As a corollary, the dimension of\nobjectivity appeared problematic when looking at the annotations\nused for classification purposes: from \"True\" to \"False\", \"Half-true\",\n\"Unproven\", \"Contradiction\", \"Compatible\" or \"Unrelated\", there\nwas no consensus among researchers.\n3.3 Transparency\nThe majority of the datasets had no issues related to the source\ntrustworthiness, as they mostly relied on specialised fact-checking\nand news websites. The pitfalls underlined in previous research\nwere globally avoided, considering that several potential data qual-\nity issues will likely appear with open data, user-generated data\nand data from multiple sources [ 24]. However, three datasets used\nWikipedia as a primary source and raised questions related to their\nreliability, credibility and verifiability but they also questioned\nthe fairness principle, in terms of objectivity and relevance. In\njournalism, Wikipedia is taken with caution as the content comes\nfrom users of whom nothing is known about their expertise [ 46].\nAlso, the Wikipedan - or encyclopaedic - writing style differs from\njournalistic writing, making it less useful for training. The same\napplies to social media content used in one dataset, and it is per-\nhaps exacerbated by the unknown and volatile nature of the users.\nThe annotation processes did not appear particularly problematic.\nDatasets were mostly well documented, except one with no indi-\ncation on the level of the human expertise for annotations. In this\nregard, research emphasised that, whether manual or automated,\nannotations are inherently error-prone and that, when performed\nmanually, human subjective factors should also be considered [ 17]\n[22] [41].4 DISCUSSION AND CONCLUSION\nResults showed that adapting data to the ethical values of journalists\nand fact-checkers does not only mean ensuring the reliability and\ncredibility of the data source as well as the accuracy of the data. One\nof the main challenges is related to the maintenance over time in re-\ngard to the dimension of actuality insofar as information disorders\nare an ongoing process. However, several examined datasets might\nbe useful for older cases, considering that history might be repeat-\ning. Still, the question of maintenance remains critical as domains\nand concepts evolve over time. Further, fact-checking requires a\ncritical approach toward the source of the data, including anno-\ntated data. Datasets based on Wikipedia and on social media raised\nquestions about their fairness and trustworthiness. Acknowledging\nthat the relationship between journalists and AI-driven systems\nis built on trust, the data that feed these systems should also be\ntrusted.\nDespite limitations due to its normative lenses and the sample\nsize, the data quality assessment framework developed in this re-\nsearch aimed to provide clues to improve the overall data quality\nwhen using technologies that rely so heavily on large volumes of\ndata. In many ways, the developed approach shares common con-\ncerns with computer and data science, such as it is set in the FAIR\nprinciples, which propose guidelines for improving the findability,\naccessibility, interoperability and reuse of digital assets [ 56]. As\nend-users of AI-based systems, journalists and fact-checkers are\nnot always aware or informed about the data that feed the systems\nthey use. At the same time, their expertise in the data source\u2019s\nreliability and credibility and their knowledge of the context should\nnot be overlooked. Therefore, better fine-tuning AI-based systems\nwith their end users would strengthen collaborations and favour\ncross-discipline approaches.\n5 FUNDING\nThe research was funded by EU CEF grant number 2394203.\nREFERENCES\n[1] C.W. Anderson. 2018. Apostles of Certainty: Data Journalism and the Politics of\nDoubt. Oxford University Press. https://doi.org/10.1093/oso/9780190492335.001.\n0001\n[2] Jo Bardoel and Leen dHaenens. 2004. Media Responsibility and Accountability.\nNew Conceptualizations and Practices. Communications 29, 1 (2004). https:\n//doi.org/10.1515/comm.2004.007\n[3] Carlo Batini. 2009. Data Quality Assessment. In Encyclopedia of Database Systems.\nSpringer US, 608\u2013612. https://doi.org/10.1007/978-0-387-39940-9_107\n[4] Carlo Batini, Anisa Rula, Monica Scannapieco, and Gianluigi Viscusi. 2015. From\nData Quality to Big Data Quality. Journal of Database Management 26, 1 (2015),\n60\u201382. https://doi.org/10.4018/jdm.2015010103\n[5]Isabelle Boydens and Seth van Hooland. 2011. Hermeneutics Applied to the\nQuality of Empirical Databases. Journal of Documentation 67, 2 (2011), 279\u2013289.\nhttps://doi.org/10.1108/00220411111109476\n[6]Paul Bradshaw. 2017. Data journalism. In The Online Journalism Handbook.\nRoutledge, 250\u2013280. https://doi.org/10.4324/9781315761428-10\n[7] Meredith Broussard, Nicholas Diakopoulos, Andrea L. Guzman, Rediet Abebe,\nMichel Dupagne, and Ching-Hua Chuan. 2019. Artificial Intelligence and Jour-\nnalism. Journalism & Mass Communication Quarterly 96, 3 (2019), 673\u2013695.\nhttps://doi.org/10.1177/1077699019859901\n[8]Li Cai and Yangyong Zhu. 2015. The Challenges of Data Quality and Data\nQuality Assessment in the Big Data Era. Data Science Journal 14, 0 (2015), 2.\nhttps://doi.org/10.5334/dsj-2015-002\n[9] Corinna Cichy and Stefan Rass. 2019. An Overview of Data Quality Frameworks.\nIEEE Access 7 (2019), 24634\u201324648. https://doi.org/10.1109/access.2019.2899751\n[10] Stephanie Craft and Tim P. Vos. 2021. The Ethics of Transparency. In The\nRoutledge Companion to Journalism Ethics. Routledge, 175\u2013183. https://doi.org/\n10.4324/9780429262708-24\n8\nThe Ethical Dimensions of Data Quality for Automated Fact-Checking\n[11] Mark Deuze. 2005. What Is Journalism?: Professional Identity and Ideology of\nJournalists Reconsidered. Journalism 6, 4 (2005), 442\u2013464. https://doi.org/10.\n1177/1464884905056815\n[12] Nicholas Diakopoulos. 2019. Automating the News. Harvard University Press.\nhttps://doi.org/10.4159/9780674239302\n[13] Laurence Dierickx. 2017. News Bot for the Newsroom: How Building Data\nQuality Indicators Can Support Journalistic Projects Relying on Real-TimeOpen Data. In Global Investigative Journalism Conference 2017 Academic\nTrack. https://ijec.org/2018/02/02/research-news-bot-for-the-newsroom-how-\nbuilding-data-quality-indicators-can-support-journalistic-projects-relying-\non-real-time-open-data/\n[14] Samuel Dodge and Lina Karam. 2016. Understanding How Image Quality Affects\nDeep Neural Networks. In 8th International Conference on Quality of Multimedia\nExperience (QoMEX). IEEE. https://doi.org/10.1109/qomex.2016.7498955\n[15] Konstantin Nicholas D\u00f6rr and Katharina Hollnbuchner. 2016. Ethical Challenges\nof Algorithmic Journalism. Digital Journalism 5, 4 (2016), 404\u2013419. https:\n//doi.org/10.1080/21670811.2016.1167612\n[16] Lisa Ehrlinger, Verena Haunschmid, Davide Palazzini, and Christian Lettner.2019. A DaQL to Monitor Data Quality in Machine Learning Applications. In\nLecture Notes in Computer Science. Springer International Publishing, 227\u2013237.\nhttps://doi.org/10.1007/978-3-030-27615-7_17\n[17] Harald Foidl and Michael Felderer. 2019. Risk-Based Data Validation in Ma-\nchine Learning-Based Software Systems. In Proceedings of the 3rd ACM SIGSOFT\nInternational Workshop on Machine Learning Techniques for Software Quality\nEvaluation. ACM. https://doi.org/10.1145/3340482.3342743\n[18] Christopher Fox, Anany Levitin, and Thomas Redman. 1994. The Notion of Data\nand its Quality Dimensions. Information Processing & Management 30, 1 (1994),\n9\u201319. https://doi.org/10.1016/0306-4573(94)90020-5\n[19] Ted Goertzel. 1994. Belief in Conspiracy Theories. Political Psychology 15, 4\n(1994), 731. https://doi.org/10.2307/3791630\n[20] Lucas Graves and CW Anderson. 2020. Discipline and Promote: Building In-\nfrastructure and Managing Algorithms in a \u201cStructured Journalism\u201d Project by\nProfessional Fact-Checking Groups. New Media & Society 22, 2 (2020), 342\u2013360.\nhttps://doi.org/10.1177/1461444819856916\n[21] Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos. 2022. A Survey on\nAutomated Fact-Checking. Transactions of the Association for Computational\nLinguistics 10 (2022), 178\u2013206. https://doi.org/10.1162/tacl_a_00454\n[22] Nitin Gupta, Shashank Mujumdar, Hima Patel, Satoshi Masuda, Naveen Panwar,\nSambaran Bandyopadhyay, Sameep Mehta, Shanmukha Guttula, Shazia Afzal,\nRuhi Sharma Mittal, and Vitobha Munigala. 2021. Data Quality for Machine\nLearning Tasks. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge\nDiscovery & Data Mining. ACM. https://doi.org/10.1145/3447548.3470817\n[23] Kai Hafez. 2002. Journalism Ethics Revisited: A Comparison of Ethics Codes in\nEurope, North Africa, the Middle East, and Muslim Asia. Political Communication\n19, 2 (2002), 225\u2013250. https://doi.org/10.1080/10584600252907461\n[24] Joseph F. Hair and Marko Sarstedt. 2021. Data, Measurement, and CausalInferences in Machine Learning: Opportunities and Challenges for Market-ing. Journal of Marketing Theory and Practice 29, 1 (2021), 65\u201377. https:\n//doi.org/10.1080/10696679.2020.1860683\n[25] YU Huh, FR Keller, TC Redman, and AR Watkins. 1990. Data Quality. Information\nand Software Technology 32, 8 (1990), 559\u2013565. https://doi.org/10.1016/0950-\n5849(90)90146-i\n[26] Michael Karlsson. 2020. Dispersing the Opacity of Transparency in Journalism onthe Appeal of Different Forms of Transparency to the General Public. Journalism\nStudies 21, 13 (2020), 1795\u20131814. https://doi.org/10.1080/1461670x.2020.1790028\n[27] Michael Koliska. 2022. Trust and Journalistic Transparency Online. Journalism\nStudies 23, 12 (2022), 1488\u20131509. https://doi.org/10.1080/1461670x.2022.2102532\n[28] Tomoko Komatsu, Marisela Gutierrez Lopez, Stephann Makri, Colin Porlezza,Glenda Cooper, Andrew MacFarlane, and Sondess Missaoui. 2020. AI Should\nEmbody Our Values: Investigating Journalistic Values to Inform AI Technology\nDesign. In Proceedings of the 11th Nordic Conference on Human-Computer In-\nteraction: Shaping Experiences, Shaping Society. ACM. https://doi.org/10.1145/\n3419249.3420105\n[29] Lev Konstantinovskiy, Oliver Price, Mevan Babakar, and Arkaitz Zubiaga. 2021.\nToward Automated Factchecking: Developing an Annotation Schema and Bench-\nmark for Consistent Automated Claim Detection. Digital Threats: Research and\nPractice 2, 2 (2021), 1\u201316. https://doi.org/10.1145/3412869\n[30] Tien Fabrianti Kusumasari and Fitria. 2016. Data Profiling for Data Quality\nImprovement With Openrefine. In 2016 International Conference on Information\nTechnology Systems and Innovation (ICITSI) . IEEE. https://doi.org/10.1109/icitsi.\n2016.7858197\n[31] Eric Lazarski, Mahmood Al-Khassaweneh, and Cynthia Howard. 2021. UsingNLP for Fact Checking: A Survey. Designs 5, 3 (2021), 42. https://doi.org/10.\n3390/designs5030042\n[32] Carl-Gustav Lind\u00e9n. 2016. Decades of Automation in the Newsroom. Digital\nJournalism 5, 2 (2016), 123\u2013140. https://doi.org/10.1080/21670811.2016.1160791\n[33] Jianzheng Liu, Jie Li, Weifeng Li, and Jiansheng Wu. 2016. Rethinking Big Data: A\nReview on the Data Quality and Usage Issues. ISPRS Journal of Photogrammetryand Remote Sensing 115 (2016), 134\u2013142. https://doi.org/10.1016/j.isprsjprs.2015.\n11.006\n[34] Marisela Gutierrez Lopez, Colin Porlezza, Glenda Cooper, Stephann Makri, An-\ndrew MacFarlane, and Sondess Missaoui. 2022. A Question of Design: Strategies\nfor Embedding AI-Driven Tools into Journalistic Work Routines. Digital Jour-\nnalism (2022), 1\u201320. https://doi.org/10.1080/21670811.2022.2043759\n[35] Wilson Lowrey, Ryan Broussard, and Lindsey A. Sherrill. 2019. Data Journalism\nand Black-Boxed Data Sets. Newspaper Research Journal 40, 1 (2019), 69\u201382.\nhttps://doi.org/10.1177/0739532918814451\n[36] Paul Mena. 2018. Principles and Boundaries of Fact-checking: Journalists\u2019 Per-\nceptions. Journalism Practice 13, 6 (2018), 657\u2013672. https://doi.org/10.1080/\n17512786.2018.1547655\n[37] Juan Ram\u00f3n Mu\u00f1oz-Torres. 2012. Truth and Objectivity in Journalism. Journalism\nStudies 13, 4 (2012), 566\u2013582. https://doi.org/10.1080/1461670x.2012.662401\n[38] Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer Elsayed,\nAlberto Barr\u00f3n-Cede\u00f1o, Paolo Papotti, Shaden Shaar, and Giovanni Da San\nMartino. 2021. Automated Fact-Checking for Assisting Human Fact-Checkers. InProceedings of the Thirtieth International Joint Conference on Artificial Intelligence.\nInternational Joint Conferences on Artificial Intelligence Organization. https:\n//doi.org/10.24963/ijcai.2021/619\n[39] Leo L. Pipino, Yang W. Lee, and Richard Y. Wang. 2002. Data Quality Assessment.\nCommun. ACM 45, 4 (2002), 211\u2013218. https://doi.org/10.1145/505248.506010\n[40] Colin Porlezza and Sergio Splendore. 2019. From Open Journalism to Closed\nData: Data Journalism in Italy. Digital Journalism 7, 9 (2019), 1230\u20131252. https:\n//doi.org/10.1080/21670811.2019.1657778\n[41] Fakhitah Ridzuan, Wan Mohd Nazmee Wan Zainon, and Mohd Zairul. 2021. A\nThematic Review on Data Quality Challenges and Dimension in the Era of Big\nData. In Lecture Notes in Electrical Engineering. Springer Singapore, 725\u2013737.\nhttps://doi.org/10.1007/978-981-16-2406-3_56\n[42] Keng Siau and Weiyu Wang. 2018. Building Trust in Artificial Intelligence,\nMachine Learning, and Robotics. Cutter Business Technology Journal 31, 2 (2018),\n47\u201353. https://www.cutter.com/article/building-trust-artificial-intelligence-\nmachine-learning-and-robotics-498981\n[43] Jane B Singer. 2020. Border Patrol: The Rise and Role of Fact-Checkers and\nTheir Challenge to Journalists\u2019 Normative Boundaries. Journalism 22, 8 (2020),\n1929\u20131946. https://doi.org/10.1177/1464884920933137\n[44] Giri Kumar Tayi and Donald P. Ballou. 1998. Examining Data Quality. Commun.\nACM 41, 2 (1998), 54\u201357. https://doi.org/10.1145/269012.269021\n[45] Jingrong Tong and Landong Zuo. 2019. The Inapplicability of Objectivity: Under-\nstanding the Work of Data Journalism. Journalism Practice 15, 2 (2019), 153\u2013169.\nhttps://doi.org/10.1080/17512786.2019.1698974\n[46] Khonzodakhon Umarova and Eni Mustafaraj. 2019. How Partisanship andPerceived Political Bias Affect Wikipedia Entries of News Sources. In Com-\npanion Proceedings of The 2019 World Wide Web Conference. ACM. https:\n//doi.org/10.1145/3308560.3316760\n[47] Richard D. De Veaux and David J. Hand. 2005. How to Lie with Bad Data. Statist.\nSci.20, 3 (2005). https://doi.org/10.1214/088342305000000269\n[48] Andreas Vlachos and Sebastian Riedel. 2014. Fact Checking: Task definition\nand dataset construction. In Proceedings of the ACL 2014 Workshop on Language\nTechnologies and Computational Social Science. Association for Computational\nLinguistics. https://doi.org/10.3115/v1/w14-2508\n[49] Tim P. Vos and Stephanie Craft. 2016. The Discursive Construction of Journalistic\nTransparency. Journalism Studies 18, 12 (2016), 1505\u20131522. https://doi.org/10.\n1080/1461670x.2015.1135754\n[50] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The Spread of True and\nFalse News Online. Science 359, 6380 (2018), 1146\u20131151. https://doi.org/10.1126/\nscience.aap9559\n[51] Karin Wahl-Jorgensen. 2013. Subjectivity and Story-telling in Journalism. Jour-\nnalism Studies 14, 3 (2013), 305\u2013320. https://doi.org/10.1080/1461670x.2012.\n713738\n[52] Yair Wand and Richard Y. Wang. 1996. Anchoring Data Quality Dimensions in\nOntological Foundations. Commun. ACM 39, 11 (1996), 86\u201395. https://doi.org/\n10.1145/240455.240479\n[53] Richard Y. Wang and Diane M. Strong. 1996. Beyond Accuracy: What Data\nQuality Means to Data Consumers. Journal of Management Information Systems\n12, 4 (1996), 5\u201333. https://doi.org/10.1080/07421222.1996.11518099\n[54] Stephen J. A. Ward. 2019. Journalism Ethics. In The Handbook of Journalism\nStudies. Routledge, 307\u2013323. https://doi.org/10.4324/9781315167497-20\n[55] Charlotte Wien. 2005. Defining Objectivity within Journalism. Nordicom Review\n26, 2 (2005), 3\u201315. https://doi.org/10.1515/nor-2017-0255\n[56] Mark D. Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Ap-\npleton, Myles Axton, Arie Baak ..., and Barend Mons. 2016. The FAIR Guiding\nPrinciples for scientific data management and stewardship. Scientific Data 3, 1\n(2016). https://doi.org/10.1038/sdata.2016.18\n[57] Yazhou Yao, Jian Zhang, Fumin Shen, Li Liu, Fan Zhu, Dongxiang Zhang, and\nHeng Tao Shen. 2020. Towards Automatic Construction of Diverse, High-Quality\nImage Datasets. IEEE Transactions on Knowledge and Data Engineering 32, 6\n(2020), 1199\u20131211. https://doi.org/10.1109/tkde.2019.2903036\n9\nAudience reception of news articles made with various levels of \nautomation \u2014and none : Comparing cognitive & emotional impacts  \nFlorian Stalp h \n Department of Media and \nCommunication  \n LMU Munich  \n Germany  \n florian.stalph@ifkw.lmu.de  Sina Th\u00e4sler -Kordonouri  \n Department of Media and \nCommunication  \n LMU Munich  \n Germany  \n sina.thaesler -\nkordonouri@ifkw.lmu.de  Neil Thurman  \n Department of Media and \nCommunication  \n LMU Munich  \n Germany  \n neil.thurman@ifkw.lmu.de  \nABSTRACT  \nOur knowledge about audience perceptions of manually  authored \nnews articles and automated news articles is limited. Although over \na dozen studies have been carried out, findings are inconsistent and \nlimited by methodological shortcomings. For example, the \nexperimental stimuli used in some have made isolation of the \neffects of the actual authorship (automated or manual ) difficult. Our \nstudy attempts to overcome previous studies\u2019 shortcomings to \nbetter evaluate audiences\u2019 relative evaluations of news articles \nproduced with varying degrees of automation \u2014and none.  We \nconducted a 3 (art icle source: manually  written, automated, post -\nedited) \u00d7 12 (story topics) between -subjects online survey \nexperiment using a sample ( N = 4,734 ) representative of UK online \nnews consumers by age and gender. Each of the 36 treatment \ngroups read a data -driven news article that was either: (1) manually  \nwritten by a journalist, (2) automated using a data -driven template, \nor (3) automated then subsequently post -edited by a journalist. The \narticles\u2019 authorship was  not declared. To minimise confounding \nvariables, t he articles in each of the 12 story sets shared the same \ndata source, story angle, and geographical focus. Respondents\u2019 \nperceptions were measured using criteria developed in a qualitative \ngroup interview study with news consumers.  The results show that  \nrespondents found manually  written articles to be significantly \nmore comprehensible \u2014both overall and in relation to the numbers \nthey contained \u2014than automated and post -edited articles. \nAuthorship did not have any statistically significant  effect on \noverall lik ing of the articles, or on the positive or negative feelings \n(valence) articles provoked in respondents, or the strength of those \nfeelings (arousal).  CCS CONCEPTS  \n\u2022Human -centered computing  \u2022 Human computer interaction\n(HCI)  \u2022 Empirical studies in HCI\nKEYWORDS  \nAutomated journalism , Data journalism , Survey , Audience  \nperception study  \nACM Reference format:  \nFlorian Stalph , Sina Th\u00e4sler -Kordonouri  and Neil Thurman . 2023 . \nAudience Reception of News Articles Made with Various Levels \nof Automation \u2014and None: Comparing Cognitive & Emotional \nImpacts . Paper presented at The Joint Computation + Journalism \nEuropean Data & Computational Journalism Conference 2023. \nETH Zurich, Switzerland, 22 -24 June 2023.  \n1 Introduction  \nNews organisations are increasingly deploying automation \ntechnologies in news production (e.g. [11, 5]). For example, data \nmining can augment news discovery, automatically calibrated \ncontent can boost personalised experiences, and the automated \nproduction of news articles via text generation software can make \njournalistic content production scalable. This  last practice \u2014so-\ncalled \u201cautomated journalism \u201d\u2014relies primarily on rule -based \nnatural language generation (NLG) systems that use manually \ncreated story templates [6] to transform data so that it possesses the \nsemantic structure of a readable text. Influenced  by computational \nthinking and the technica l constraints of these story templates, \njournalists who automate journalism this way are not writing a \nstory \u2014they are \u201cwriting the potential for every eventuality of the \nstory\u201d (Rogers in [4]) to allow templates to react to variations in \ndatasets. As pointed out by previous studies, the use of such NLG \nsystems could affect the composition of data -driven news articles, \nincluding the presence of what Caswell [2019 ] considers the \n\u201cessential components of the human craft of journalism\u201d, such as \ndescription, bac kground, and anecdotes . Consequently, the \nincreasing use of automated journalism may affect how news \nconsumers perceive news content and necessitates research into the \njournalistic performance of stories produced this way. Therefore, Permission to make digital or hard copies of part or all of this work for personal or \nclassroom use is granted without fee provided that copies are not made or \ndistributed for profit or commercial advantage and that copies bear this notice \nand the full cit ation on the first page. Copyrights for third -party components of \nthis work must be honored. For all other uses, contact the owner/author(s).  \nThe Joint Computation + Journalism European Data & Computational Journalism \nConference 2023  \n\u00a9 2023  Copyright held by the author(s).  \n9\n10\nThe Joint C + J European DataJ Conference , June \n2023 , Zurich, Switzerland  F.Stalph  et al.\nthis study seeks to gather and compare audience perceptions of \narticles produced using varying degrees of automation and none \nand to do so in a way that produces results of unprecedented \ninternal and external validity.  \n2 Literature Review  \nOur knowledge  about the  perceptions of data -driven, automated \nnews articles is limited as few studies have compared  the \nperceptions of news articles written with the full range of \nautomation variants, including automated, post -edited , and \nmanually  written articles (to our knowledge, only [22]). Most \ncommonly, studies comparing audience evaluations focus on two \nvariants: automated and manually  written. However, the third \nvariant, where automated articles are post -edited by journalists \nprior to publication, is increasingly commonly  used (see, e.g., [19]). \nAlthough over a dozen studies have been conducted  on the \nperception of automated journalism , their findings are inconsistent \nand often limited by methodological shortcomings.  \nAutomation technologies explored in perception studies range from \nmore human -dependent, template -based applications (e.g. [10, 7] ) \nto less human -dependent \u201cmodular \u201d NLG systems [14] and \nmachine -learning -based applications [18]. In several studies, \nscholars omit to describe how the analysed automation systems \noperate and refer to their output simply as \u201csoftware -generated\u201d [3] \nor as \u201cgenerated by algorithms\u201d [23].  \nScholars  have followed different strategies to find and pair \nautomated and manually  written news articles to be used as \nexperimental stimulus material . In several studies, automatically \ngenerated articles were paired with published, manually  written \narticles based on the same data, or about the same topic or event , as \nthe automated articles  (e.g. [10, 22, 21, 7] ). Some studies \ncommissioned professional journalists [9, 14]  or journalism \nstuden ts [20] to write articles to pair with  automated stories. In a \nfew cases, articles were paired even though they were written in \ndifferent journalistic styles . One study, for example, paired  an \nautomatically generated factual sports report with a manually  \nwritten opinion piece [3]. \nIn several cases, scholars edited the articles before showing them \nto readers, for instance by shortening the manually  written articles \nto \u201cmatch the length of the one written by the algorithm\u201d [9] or by \nonly using the first \u201c400 words\u201d of articles generated by a machine -\nlearning based application [18]. Such artificial interventions might \nimpact the validity of the studies \u2019 findings.  \nOnly one study has compared perceptions of fully automated, \nmanually  written , and post -edited articles , doing so with regard to  readers\u2019 evaluations of source and message credibility [22]. \nHowever, this study also has methodological limitations , as one of \nthe post -edited stories was created by the study\u2019s authors, which \nmight have reduce d the external validity of the \nstimulus.  Furthermore, similar to other studies, the authors  only \ninvestigated two sets of stimuli. As Jackson and Jacobs [1983 ] \npoint out, \u201cgeneralization about a whole category of messages \n[such as automated or post -edited journalism] requires careful \nanalysis of multiple members of the category\u201d , because \u201cany \nparticular message chosen to represent any message category must \nbe assumed to differ from other members of the category in \nunknown and indefinitely numerous ways\u201d. Therefore, we do not \nbelieve that the resul ts of a study, such as W\u00f6lker and Powell\u2019s  \n[2018 ], that uses just two messages for each message category \nstudied can be generalised to that whole message category.   \nOur study attempts to overcome previous shortcomings to better \nevaluate audiences\u2019 relative evaluations of news articles produced \nwith varying degrees of automation (and none). Given the apparent \nabsence of literature on how the perception of automated new s \nstories compares with their post -edited offspring, we do not test any \nhypotheses but rather ask the following research question : \nRQ1: How does the perception of automated articles that have been \npost-edited by human journalists compare with the perception of \ntheir automated progenitors and of equivalent, manually  written \narticles that are on the same stories and based on the same \nquantitative data?  \n3 Methodology  \nA large -scale 3 (article source: manually  written, automated, post -\nedited) \u00d7 12 (story topics) between -subjects online survey \nexperiment was conducted using a sample ( N = 4, 734) \nrepresentative of UK online news consumers by age and gender. \nThe sample of respondents was drawn from various local regions \nand divided into 36 treatment groups. Each treatment group was \nexposed to a data -driven news article that had been produced either: \n(1) manuall y by a human journalist  (n = 1,542), (2) using template -\nbased automation  (n = 1,599), or (3) in a post -edited manner, where\na human journalist ha d further developed the automated article  (n\n= 1,593).\nRespondents\u2019 perceptions were measured using news perception \ncriteria developed in a qualitative pre -study [16] based on group \ninterviews with UK news consumers ( N = 31). The 13 criteria cover \nfour domains: antecedents of perception , emotional and cognitive \nimpacts , article composition , and news and editorial values . \nSeveral of the criteria have not been used in prior research on the \nperception of data -driven journalism, including that produced with \nthe help of automation.  In this paper we focus on one of these \n11\nF. Stalph et al.The Joint C + J European DataJ Conference , June \n2023 , Zurich, Switzerland  \ndomains: the emotional and cognitive impacts that the articles have \non readers.  \n3.1 Survey Instrument  \n3.1.1 Stimulus News Stories. The stimulus material comprise d \nstories sourced from PA Media\u2019s Reporters And Data And Robots \n(RADAR) automated news service and from local, regional, and \nnational British online news websites. The sources were chosen \npurposefully to include a wide range of news outlets and publishers \nwith different geographical foci, backgrounds, funding models, \ntarget audiences, and ownership structure s. The stimuli cover a \nrange of topics including public health, crime, sport, transport, and \nsocial affairs. To eliminate potentially confounding variables, we \nstripped the articles of bylines and the publishers\u2019 logos and \nbranding, showing respondents  only the text in basic HTML \nformatting to ensure readability.  \nThe automated articles ( N = 12) were produced by data -driven \ntemplates created by data journalists at PA Media\u2019s RADAR. The \npost-edited articles ( N = 12) were developed directly from the \nparticular aforementioned automated stories by journalists, who, \nfor example, added quotes from local spokespeople or deleted  \ncontent that was not deemed relevant to the target audience. We \nclassified articles as post -edited by identifying editorial changes \nthat had been made to the body text of the automated stories. \nArticles in which only the headline had been changed were not \nincluded in the sample of post -edited stories. The final set of \narticles ( N = 12) were pure ly manually  written  (which  was \nconfirmed in personal correspondence with the articles\u2019 authors) \nand drew on the same data used in the automated  and post -edited \nversions. The article sets were found via extensive online \nresearch.    \nTo minimise confounding variables, the three articles in each of the \n12 story sets are based on the same data source(s), feature the same \nstory angle, and cover the same locality . \n3.1.2 Perception Criteria and Measures . As we knew from the \nqualitative interview -based pre -study [16] that the articles could \nhave an emotional impact on respondents, we measured valence  \nand levels of arousal and liking . Respondents indicated the \nintensity and direction of emotional arousal they experienced when \nreading an article (see [12]). Additionally, respondents reported \ntheir overall \u201cliking \u201d of the news article (see [17]). These variables \nwere measured on a continuous scale from \u221230 to +30, modelled \nafter the affective slider, a self -reporting tool for the quick \nassessment of pleasure and arousal [1]. \nIn addition to emotional impact , our qualitative interview -based \npre-study [16] showed that articles can also have a cognitive impact \non readers. Therefore, we asked respondents about the overall \ncomprehensibility of the article they read. In addition, we asked about respondents\u2019 comprehension of numbers  in the article . Before \ndata analysis, all variables were recoded to a 1 to 60 metric scale.  \n3.1.3 Instrument Pre -Test. The questionnaire was pre -tested in \nOctober 2022 after its initial development but before its full -scale \nfield administration. We used developmental expert reviewing and \ncognitive interviews ( N = 10) with respondents , involving think -\naloud complemented with verbal probing procedures [21]. Our  goal \nwas to identify and repair problematic measures, questions , and \nconcepts ; and issues with the usability of the survey. To generate \nfeedback, we administered a prototype of the survey tha t contained \nnine different articles. Three of these articles were manually  \nwritten, three automated, and three post -edited to ensure that the \npre-test covered articles produced with all potential degrees of \nautomation, including none. To test variations in the responses \nrelated to individual reactions to story topics, the article s covered \nnine different topics, including energy costs, e -scooter casualties, \nand drug deaths. Each article was sourced from Birmingham news \noutlets and we only recruited pre -test candidates who lived in the \nBirmingham area. By doing so, we took special care to ensure that \nour respondents were exposed only to sets of stories that were \nrelevant to their geographic interest. Based on the feedback \ncollected from the pre -test interviews, we modified questions and \nrepaired survey defects [21]. \nBefore the survey\u2019s broader distribution , we deployed a soft launch . \nApproximately 100 respondents complet ed the survey allowing us \nto test its technical functionality and measures, check output data \nstructure and validity, and gather additional feedback via a free -text \nquestion.  \n3.1.4 Survey Administration and Data Collection . The survey was \nfielded by YouGov to their own proprietary  online  panel between \n26 January and 1 March 2023. To be eligible for participation in \nthe survey, respondents were pre-screened to ensure that they were \naged 18 or older, used online news at least once a month, and were \nresident in one of the selected news organisations\u2019 catchment areas \nto ensure that the article was relevant to where they lived. Each \nexperimental treatment group (automated, manual ly written , and \npost-edited ) comprised at least 100 participants, with quotas set on \nage and gender.  \nTo make sure that the recruited participants read the stimulus \narticle, only respondents who passed an attention check were \nincluded in the final sample [15]. \n3.1.5 Sample Description . The overall target population for this \nsurvey was monthly UK news consumers age d 18 and older, who \nwere resident in regions and cities covered by the catchment areas \nof those news organisations we drew our stimulus news articles \nfrom.  \n12\nThe Joint C + J European DataJ Conference , June \n2023 , Zurich, Switzerland  F.Stalph  et al.\nThe sample comprise d N = 4,734 respondents with a mean age of \nM = 50.66 years ( SD = 15.77) and a gender split of 55 % women ( N \n= 2,602) and 45 % men ( N = 2,132).  Each experiment within each \narea required at least 100 respondents per treatment (automated, \nmanually written, and post -edited), and there were at least 300 \nrespondents per experiment due to oversampling . \n4 Results  \nTo compare the mean  scores  of the variables overall liking , \nemotional  impact , and cognitive impact  across manually  written, \nautomated, and post -edited articles, we ran multiple ANOVAs. \nVariance distribution  of the three treatment groups  was mostly \nheteroscedastic, i.e. having unequal variances. Therefore, we opted \nfor the Games -Howell test  to compare multiple means , which \nprovides a method for dealing with a situation where either or both \nof the assumptions are violated , while still controlling for Type 1 \nerrors (see [13]). \n4.1 Differences in Levels of Liking Between  \nAutomated, Manually  Written , and Post-\nedited Articles  \nThe level of liking did not differ  significant ly for the different levels \nof automation, Welch\u2019s F(2, 3144.24 ) = 2.479, p = .084, \u03b7\u00b2 = .001. \nAn inspection  of the mean values reveals that manually  written \narticles were the most liked  (M = 33.73 , SD =12.93), followed by \npost-edited articles ( M = 33.41 , SD = 12.36 ), followed by \nautomated articles  (M = 32.76 , SD = 12.08 ). \n4.2 Differences in Emotional Impact Between  \nAutomated, Manually Written , and Post-\nedited Articles  \nThe highest levels of arousal \u2014i.e. the strength of an associated \nemotional state \u2014across the respondents could be found after they \nhad read one of the manually written  articles ( M = 35.16 , SD = \n14.43 ). Arousal was weaker after respondents had read a post-\nedited  article  (M = 35.06 , SD = 14.07 ) or an automated article ( M \n= 34.76 , SD = 13.92 ). However, ar ousal did not differ \nsignificant ly for the different levels of automation, Welch\u2019s F(2, \n3149.19 ) = .345, p > .05.  \nWe then assess ed the effects of level of automation on valence , \ni.e. the extent to which an emotion is negative  or positive . After \nrecoding, r espondents perceptions of valence w ere measured \nusing a scale from 0 very negative to 60 very positive  with 30 as \nthe neutral middle point . All article types were evaluated on the \nslightly more negative side of the scale. The automated articles \ntriggered the highest negative valence ( M = 23.48 , SD = 12.34), \nfollowed by post-edited articles ( M = 24.14 , SD = 12. 78), and \nmanually  written articles ( M = 24.60 , SD = 14.34). However, \nvalence did not differ significantly for the different levels of \nautomation, Welch\u2019s F(2, 3131.17 ) = 2. 83, p > .05 .4.3 Differences in Cognitive Impact Between  \nAutomated, Manually  Written , and Post-\nedited Articles  \nThe overall comprehensibility of the articles differed significant ly \nfor the different levels of automation, Welch\u2019s F(2, 3153.97 ) = \n23.56 , p < .001, \u03b7\u00b2 = .010. \nGames -Howell post  hoc analysis revealed a significant difference \n(p < .001) in overall comprehensibility between  manually  written  \nand automated articles as well as between manually  written  and \npost-edited articles. There were no significant differences between \nautomated and post -edited articles. The manually  written article s \nwere considered the most comprehensible (M =46.07 , SD = 12.90), \nand significantly more comprehensible than both automated \narticles (M = 42.92, SD = 13.06 , 95% -CI[2.04, 4.26]) and post -\nedited articles ( M = 43.86, SD = 13.63 , 95% -CI[1.10, 3.32]). \nRespondents\u2019 comprehension of numbers in the articles also \ndiffered significant ly for the different levels of automation, \nWelch\u2019s F(2, 3153.97 ) = 39.944 , p < .001, \u03b7\u00b2 = .016. \nA pair -wise comparison of the mean values  revealed a significant \ndifference ( p < .001) in the comprehension of numbers between \nmanually  written  and automated articles and between manually  \nwritten  and post-edited articles. There were no significant \ndifferences between automated and post -edited articles. The mean \nvalue for how comprehensible respondents thought numbers in the \narticles was highest  for manually  written articles  (M = 44.44 , SD = \n13.127). Our data showed a significant drop -off for automated \narticles ( M = 40.17, SD = 14.06 , 95% -CI[3.13, 5.42]), as well as for \npost-edited articles ( M = 41.63 , SD = 14.03, 95%-CI[1.67, 3.96]). \n5 Discussion  \nThis study investigated the differences in news consumers\u2019 liking  \nof automated, manually  written, and post -edited news articles , and \nthe emotional and cognitive impacts those different article types \nhad on them . The results show no significant differences in the level \nof liking for the three types of articles . Regarding emotional impact, \nalthough manually written articles triggered the highest level of \narousal, followed by post-edited  and automated articles , the  \ndifferences were  small  and not statistically s ignificant. In terms of \nvalence,  although automated articles triggered the highest level of \nnegative valence, followed by post-edited and manually  written \narticles, again these differences were not statistically significant. In \nterms of cognitive impact, there were significant differences  \nbetween the article types.  Manually  written articles were perceived \nas significantly  more comprehensible than post-edited and \nautomated articles. The comprehension of numbers in articles was \nalso significantly higher for manually  written  articles than for \nautomated and post -edited articles.  \n13\nF. Stalph et al.  The Joint C + J European DataJ Conference , June \n2023 , Zurich, Switzerland  \n \n The findings of this study have implications for the design and \nproduction of news articles. The results suggest that manually  \nwritten  articles are perceived as more comprehensible  overall and \nin their presentation of numbers  than fully automated articles, \nindicating the importance of maintaining human involvement in the \nproduction of news content. However, the study also showed that \npost-edited and automated articles were not significantly less liked \nthan manually  written articles, suggesting that automate d content \nhas reached a level of acceptance amongst news consumers . \nOverall, the study highlights the importance of finding the right \nbalance between human involvement and automation to ensure that \nnews content is comprehensible to the audience . \nACKNOWLEDGMENTS  \nThis work was supported by Volkswagen Foundation:  \n[Grant Number A110823/88171] . \n \nREFERENCES  \n[1] Alberto Betella and Paul F. M. J. Verschure . 2016. The \naffective slider: A digital self-assessment scale for the \nmeasurement of human emotions. PLoS ONE  11, 2 (Feb. 2016) , \ne0148037. DOI:  https://doi.org/10.1371/journal.pone.0148037    \n[2] David Caswell. 2019. Structured Journalism and the Semantic \nUnits of News. Digital Journalism , 7, 8, 1134 -1156. DOI: \nhttps://doi.org/10.1080/21670811.2019.1651665   \n[3] Christer Clerwall . 2014. Enter the robot journalist : Users' \nperceptions of automated content . Journalism Practice  8, 5, 519 -\n531. DOI:  http://dx.doi.org/10.1080/17512786.2014.883116    \n[4] Nicholas Diakopoulos. 2019. Automating the News: How \nAlgorithms are Rewriting the Media . Cambridge: Harvard \nUniversity Press.  \n[5] Konstantin Nicholas D\u00f6rr. 2016. Mapping the Field of \nAlgorithmic Journalism. Digital Journalism  4, 6, 700 \u2013722. DOI: \nhttps://doi.org/10.1080/21670811.2015.1096748   \n[6] Andreas Graefe  and Nina Bohlken . 2020. Automated \njournalism: A meta-analysis of readers\u2019 perceptions of human -\nwritten in comparison to automated news. Media and \nCommunication 8, 3 (Jul. 2020) , 50-59. DOI:  \nhttps://doi.org/10.17645/mac.v8i3.3019   \n[7] Mario Haim  and Andreas Graefe . 2017. Automated news: \nBetter than expected?  Digital Journalism , 5, 8, 1044 -1059 . DOI:  \nhttp://dx.doi.org/10.1080/21670811.2017.1345643    \n[8] Sally Jackson and Scott Jacobs . 1983. Generalizing about \nmessages: Suggestions for design and analysis of experiments . \nHuman Communication Research 9, 2 (Dec. 1983) , 169 -181. \nDOI: https://doi.org/10.1111/j.1468 -2958.1983.tb00691.x  \n[9] Jaemin Jung, Haeyeop Song, Youngju Kim, Hyunsuk  Im, and \nSewook Oh. 2017. Intrusion of software robots into journalism: \nThe public's and journalists' perceptions of news written by \nalgorithms and human journalists. Computers in Human Behavior \n71 (Jun. 2017) , 291 -298. DOI:  \nhttps://doi.org/10.1016/j.chb.2017.02.022    \n[10] Castulus Kolo,  Joschka  M\u00fctterlein , and Sarah Anna Schmid . \n2022. Believing journalists, AI, or fake news: The role of trust in media. 55th Hawaii International Conference on System Sciences , \n3202 -3211.  DOI:  https://doi.org/10.24251/HICSS.2022.393    \n[11] Efthimis Koten idis and Andreas Veglis. 2021.  Algorithmic \nJournalism \u2014Current Applications and Future Perspectives. \nJournalism and Media , 2, 2, 244 -257. DOI: \nhttps://doi.org/10.3390/journalmedia2020014   \n[12] Peter Kuppens, Francis Tuerlinckx, James A. Russell , and \nLisa Feldman Barrett . 2013. The relation between valence and \narousal in subjective experience. Psychological Bulletin 139, 4, \n917\u2013940. DOI:  https://doi.org/10.1037/a0030811   \n[13] Sangseok Lee and Dong Kyu Lee. 2018. What is the proper \nway to apply the multiple comparison test? Korean J Anesthesiol  \n71, 5, 353 -360. DOI: https://doi.org/10.4097/kja.d.18.00242 . \nErratum in: Korean J Anesthesiol . 2020. 73, 6, 572.  \n[14] Magnus Melin , Asta  B\u00e4ck,  Caj S\u00f6derg\u00e5rd, Myriam D.  \nMunezero, Leo J. Lepp\u00e4nen , and  Hannu Toivonen . 2018. No \nlandslide for the human journalist - An empirical study of \ncomputer -generated election news in Finland. IEEE Access 6 \n(Aug. 2018) , 43356 -43367. DOI:  \nhttps://doi.org/10.1109/ACCESS.2018.2861987    \n[15] Rachel A. Ruble. 2017.  Experimental Manipulation. The \nSAGE Encyclopedia of Communication Research Methods . SAGE \nPublications Ltd. DOI: https://dx.doi.org/10.4135/9781483381411   \n[16] Florian Stalph, Neil Thurman, and Sina Th\u00e4sler -Kordonouri . \n2023. Exploring audience perceptions of, and preferences for, \ndata-driven \u201cquantitative\u201d journalism . 2023. Journalism: Theory, \nPractice and Criticism . DOI: \nhttps://doi.org/ 10.1177/14648849231179606  \n[17] S. Shyam Sundar. 1999.  Exploring Receivers\u2019 Criteria for \nPerception of Print and Online News. Journalism & Mass \nCommunication Quarterly , 76, 2, 373 -386. \n[18] Shubhra Tewari, Renos Zabounidis, Ammina Kothari, \nReynold Bailey , and Cecilia Ovesdotter Alm. 2021. Perceptions \nof human and machine -generated articles. Digital Threats: \nResearch and Practice  2, 2 (Apr. 2021) , 1-16. DOI:  \nhttps://doi.org/10.1145/3428158    \n[19] Sina Th\u00e4sler -Kordonouri and Kurt Barling. 2023. Automated \njournalism in UK local newsrooms: Attitudes, integration, impact. \nJournalism Practice , 1-18. DOI: \nhttps://doi.org/10.1080/17512786.2023.2184413   \n[20] Chris van der Lee,  Bart Verduijn, Emiel  Krahmer , and \nSander Wubben . 2018. Evaluating the text quality, human \nlikeness and tailoring component of PASS: A Dutch data -to-text \nsystem for soccer. In Proceedings of the 27th International \nConference on Computational Linguistics , Santa Fe, New Mexico, \nUSA, 20-26 August 2018, 962 \u2013972. \n[21] Gordon B. Willis. 2016. Questionnaire Pretesting. The SAGE \nHandbook of Survey Methodology.  SAGE Publications Ltd. DOI: \nhttps://doi.org/10.4135/9781473957893   \n[22] Anja W\u00f6lker  and Thomas E.  Powell . 2018. Algorithms in the \nnewsroom? News readers\u2019 perceived credibility and selection of \nautomated journalism. Journalism  22, 1 , 86-103. DOI:  \nhttps://doi.org/10.1177/1464884918757072    \n[23] Yanfang Wu. 2020. Is automated journalistic writing less \nbiased? An experimental test of auto-written and human -written \nnews stories. Journalism Practice  14, 8, 1008 -1028 . DOI: \n \n14\nAdding Quotable Signatures to the\nTransparency Repertoire in Data Journalism\nMar\u00edlia Gehrke\nUniversity of Southern Denmark\nOdense, Denmark\nmage@sdu.dkSimon Erfurth\nUniversity of Southern Denmark\nOdense, Denmark\nsimon@serfurth.dk\nABSTRACT\nFabricated content falsely attributed to reputable news sources is\none of the significant challenges for journalism today. One of the\nmanipulation methods is to copy the layout of news websites and\nsubstitute the original text. The manipulated version is then re-\ncirculated, making it hard to assess the reliability and trace the\norigin of such \u201cinformation.\u201d Offering an exploratory, descriptive,\nand solution-oriented approach, we present examples of how this\nmanipulation threatens news outlets and can escalate to data jour-\nnalism and other specialized forms of news reporting. One reason\nfor that is people\u2019s overreliance on numbers and data visualiza-\ntions as cues to assess the trustworthiness of the content. Then, we\nsuggest that news organizations and social media platforms incor-\nporate a tool to make the digital information environment safer\nfor users and readers. By presenting quotable signature schemes,\na cryptography-based solution, we claim that the transparency\nrepertoire in journalism can be improved and extended.\nKEYWORDS\ndata journalism, transparency, disinformation, cryptography, digital\nsignatures, quotable signatures\nACM Reference Format:\nMar\u00edlia Gehrke and Simon Erfurth. 2023. Adding Quotable Signatures to\nthe Transparency Repertoire in Data Journalism. In Proceedings of Joint\nComputation+Journalism and European Data & Computational Journalism\nConference (C+J & DataJ, 2023). ACM, New York, NY, USA, 5 pages. https://\ndoi.org/10.1145/nnnnnnn.nnnnnnn\n1 INTRODUCTION\nIn this paper, we argue that using quotable signature schemes can\nenhance and extend the repertoire of transparency strategies in data\njournalism to prevent or combat mis- and disinformation spread.\nOur approach here is descriptive, exploratory, and solution-based.\nWe start the study with a theoretical background, present examples\nof how manipulation impersonates reputable news brands, and\noffer a solution based on a cryptographic primitive called quotable\nsignature schemes. Lastly, we offer a prototype to trace a publi-\ncation\u2019s provenance when excerpts from it are shared on social\nmedia.\nOur research is in line with literature that debates fabricated\ninformation that often mimics the format of news (Lazer et al., 2018),\nrelies on numbers as cues to manipulate readers (Gehrke & Benetti,\n2021; Peng, Lu, & Shen, 2023), and even recirculates journalistic\nproducts by taking them out of their original context (Soares &\nC+J & DataJ, 2023, June 23\u201324, 2023, ETH Zurich, Switzerland\n2023. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnnRecuero, 2021). Thus, our goal is to describe how disinformation\nspread is currently problematic to news organizations and has the\npotential to escalate to data journalism websites in the future, taking\ninto account that numbers and data visualizations are potent cues\nto perceived credibility (Peng et al., 2023).\nThis study is part of the Trust and News Authenticity interdis-\nciplinary project, connected with the Digital Democracy Centre\n(DDC) at the University of Southern Denmark (SDU). All in all,\nwe suggest that data journalists use computational tools to make\nthe information environment safer and more transparent for users\nand readers. As part of transparency strategies, quotable signature\nschemes can be extended to news sources inside the journalistic ar-\nticles, which allows one to authenticate information\u2019s provenance.\nIn the future, the mechanism can even be extended to multimedia\nforms, such as pictures and videos.\n2 THEORETICAL BACKGROUND\n2.1 Transparency in data journalism practices\nData journalism has ascended since the late 2000s in Europe and\nthe United States, mainly due to the advance of Freedom of Infor-\nmation Access legislation (Coddington, 2015; Rogers, 2013). This\ndata-driven journalism practice encompasses investigations that\nprimarily rely on public databases, even though leaked documents\ncan also be used as sources.\nSince its theoretical roots trace back to Precision Journalism\n(Meyer, 2002), which aimed to posit journalism closer to the sci-\nentific method, data journalism investigations might start with a\nhypothesis to be tested, followed by data analysis, visualization, and\ncommunication of the reporting method \u2013 that is, methodological\ntransparency. One of the most common requirements of openness\nis focused on the replicability and/or reproducibility of the analy-\nsis, allowing the audience to verify information and find the same\nresults as the journalists (Gehrke, 2022; Gehrke & Mielniczuk, 2017;\nMeyer, 2002).\nIn summary, transparency means disclosing reporting practices\nand being clear about the origin of news sources and the methodol-\nogy adopted. Almost a decade ago, transparency in digital journal-\nism, which includes data-driven approaches, was seen by scholars\nas a way to establish credibility and reduce mistrust among audi-\nences (Coddington, 2015; Karlsson, 2010). The optimism was mainly\nconnected with the Web allowing the use of hypertext and, there-\nfore, new layers of information. Recently, though, only a couple of\ninvestigations presented evidence that transparency could increase\nperceived credibility (Johnson & St. John III, 2021), and some scho-\nlars argue that trust is a prerequisite for openness to be effective\n(Karlsson, 2022).\n15\nC+J & DataJ, 2023, June 23\u201324, 2023, ETH Zurich, Switzerland Mar\u00edlia Gehrke and Simon Erfurth\nDespite the limitation of not being data producers, which makes\nthem use sometimes opaque second-hand government data (Tong,\n2023), data journalists believe that sharing their choices, work\nmethodology, and even uncertainty with the audience improve\ninformation clarity. According to the perception of 36 Brazilian\ndata journalists, transparency is not only a way for them to commu-\nnicate their work method but also a path to establish a relationship\nbased on honesty with the readership and combat misinformation\n(Gehrke, 2020).\n2.2 Data as a cue to perceived credibility in the\n(dis)information landscape\nNumbers, statistics, and data visualizations are potent cues in jour-\nnalism and are often connected with straightforward communica-\ntion of the facts. Fact-checkers also use data when verifying public\nclaims, which implies that numbers are more accurate than dis-\ncourse. Activating the same perception, mis- and disinformation\nnarratives often use numbers and statistics to claim reliability.\nFabricated content related to the Covid-19 pandemic is an exam-\nple of number manipulation as part of a misleading narrative. In\na content analysis to explore 407 texts of false content that circu-\nlated during the first months of the pandemic in Brazil, Gehrke and\nBenetti (2021) identified that \u201cdata\u201d was the third most recurrent\ncategory of the corpus analyzed, making up 19.66% of the cases.\nWith the intent of minimizing the impact of the pandemic and argu-\ning that the news media was creating terror, numbers and statistics\nwere employed to construct a narrative that aimed to \u201cdemonstrate\u201d\nthat figures reported by the media were exaggerated. The examples\nincluded over-reported cases and deaths to the disease and allegedly\nempty hospitals.\nWhereas pictures and videos are primarily adopted as evidence\nin disinformation narratives (Dan et al., 2021), numbers contained\nin data visualizations are part of what Peng et al. (2023, p. 228)\ncalls \u201cvisual features as arguments\u201d when discussing visual features\nof misinformation posts that might influence people\u2019s credibility\nperception.\nGiven that visual mis- and disinformation has been studied less\nthan general forms of manipulation, it is hard to estimate the fre-\nquency with which the layout of a news website is copied and\nconverted into false content. Nevertheless, Peng et al. (2023) list\nthat aesthetics usually work as a heuristic by providing people with\nhints that suggest (or not) the message come from a professional\nand credible source. Moreover, a previous study developed in our\nproject found that news brands/logos are a powerful cue for peo-\nple to assess the news\u2019 reliability (Gehrke, Eggers, De Vreese, &\nHopmann, 2023).\nTo exemplify this problem, we present fact-checked publications\nclassified as \u201cfalse\u201d text and images that circulated online in 2022\nmainly by mimicking the layout of news websites and logos of jour-\nnalistic brands (see Figures 1 and 2). The content we use here was\nverified by fact-checking agencies that are signatories of the Inter-\nnational Fact-checking Network (IFCN), which provides rigorous\nmethodological and transparency premises that must be followed\nand shared with the audience.\nRegarding Figure 1, the logo employed in the fabricated message\n(A) aims to attribute credibility to the content, by using the sameshape and color as (B), which is the verified CNN Instagram account.\nDue to changes on Twitter (C), CNN\u2019s logo shape and verification\nbatch are slightly different one year later. Still, a quick comparison\nbetween logos in different social media can easily generate confu-\nsion and mislead readers. The image and text (A) were verified and\nclassified as false by the American fact-checking agency PolitiFact\n(Curet, 2022).\nFigure 2 presents news falsely attributed to Deutsche Welle (DW)\nBrasil (A) in November 2022. Comparison it with the actual DW\nBrasil website (B), shows that a screenshot of the mobile website\nversion was manipulated. The false text (A) claimed fraud in the\nBrazilian presidential elections and presented made-up statistics\nabout the results. Besides the numbers, a fabricated news source\nwith a \u201cPh.D. in Cybersecurity\u201d was attributed within the text\nto contest the election results and mimic reporting procedures\nused in journalism, such as gathering information through sources.\nBrazilian fact-checking organization Ag\u00eancia Lupa classified the\ncontent as false (Schiochet, 2022).\n2.3 Quotable signatures\nThis section first introduces the technical aspects of quotable signa-\ntures, and then gives a practical description of the prototype, and\nsome related considerations.\nDigital signature schemes are a classical and widely used tool\nin modern cryptography (Diffie & Hellman, 1976; Moody, 2023). In\ngeneral, a digital signature scheme is a triple of algorithms KeyGen ,\nSign, and Verify . The algorithm KeyGen generates related pairs\nof a private and a public keys (sk,pk). The algorithm Sign signs\nany message \ud835\udc5a\ud835\udc5ausing a private key sk. This procedure produces\na signature \ud835\udc60\ud835\udc60=Signsk(\ud835\udc5a\ud835\udc5a)for\ud835\udc5a\ud835\udc5a. The algorithm Verify verifies a\nmessage \ud835\udc5a\ud835\udc5aand a signature \ud835\udc60\ud835\udc60using the public key pk. Ignoring\ntechnicalities, the verification is successful only if the signature\nwas generated using \ud835\udc5a\ud835\udc5aand the private key corresponding to pk, and\nneither the message \ud835\udc5a\ud835\udc5anor the signature \ud835\udc60\ud835\udc60was altered. We say that \ud835\udc60\ud835\udc60\nis a signature for \ud835\udc5a\ud835\udc5asigned with the private key sk. In other words,\na secure signature scheme essentially ensures that only an entity\nin possession of the private key skcan produce a signature \ud835\udc60\ud835\udc60for\na message \ud835\udc5a\ud835\udc5a, while the signature can be verified by anyone in\npossession of the public key pk.\nThis construction means that digital signatures ensure that (1)\nthe message comes from a party that has a specific private key\n(identity), (2) the message has not been altered (integrity), and (3) a\nsigner cannot lie about not signing a message, while also claiming\nthat their private key remains private.\nA newer concept is quotable signature schemes (Kreutzer, Nieder-\nhagen, Shrishak, & Fhom, 2019), which has been expanded upon by\nthe authors (Boyar, Erfurth, Larsen, & Niederhagen, 2023). Summa-\nrizing, the main parts are as follows. A quotable signature scheme\ncan be defined as digital signature schemes with an additional algo-\nrithm Quote. Given a message \ud835\udc5a\ud835\udc5aand a quotable signature \ud835\udc60\ud835\udc60, any\nthird party can use Quote to extract a second quotable signature\n\ud835\udc60\ud835\udc60\u2032for a quote \ud835\udc5e\ud835\udc5efrom \ud835\udc5a\ud835\udc5a, without knowing the secret key used to\nsign \ud835\udc5a\ud835\udc5aor interacting with the party that signed \ud835\udc5a\ud835\udc5a. This quotable\nsignature \ud835\udc60\ud835\udc60\u2032is still signed with the private key used to sign \ud835\udc5a\ud835\udc5a, and\nhence authenticates the original signing party as the author of the\nquote. In addition to having all the properties of standard digital\n16\nAdding Quotable Signatures to the Transparency Repertoire in Data Journalism C+J & DataJ, 2023, June 23\u201324, 2023, ETH Zurich, Switzerland\nFigure 1: An Instagram post (A) with a screenshot of a manipulated tweet that was allegedly published by the American news\norganization CNN (B/C) on April 2022 concerning children\u2019s support of the Ukraine War.\nFigure 2: Another type of manipulation consists of the complete copy (A) of a news website\u2019s original layout (B). In this example,\nthe mobile version was adopted.17\nC+J & DataJ, 2023, June 23\u201324, 2023, ETH Zurich, Switzerland Mar\u00edlia Gehrke and Simon Erfurth\nFigure 3: The user\u2019s journey when (A) reading and copying\npart of the news and (B) sharing the content on social media.\nsignatures, quotable signatures also allow deriving where parts of\nthe message have been removed relative to the quote. A signature\nfor a quote is again a quotable signature with respect to sub-quotes\nof the quote.\nIn the Trust and News Authenticity project, we have developed\na prototype of a tool which aims to mitigate the effect of disin-\nformation by authenticating quotes from articles using quotable\nsignatures. This authentication is intended to complement the al-\nready existing flagging of problematic content. Since quotable sig-\nnatures do not verify the truthfulness of the content, but rather\nauthenticate its origin and inte)grity, this approach is different from\nfact-checking. Essentially, rather than aiming to prove that the\nstatement is correct, it validates that a statement is extracted ipsis\nlitteris from its provenance without falsification. Figure 3 illustrates\nthe user journeys when using the prototype.\nFigure 3 also shows that only the exact part copied and pasted\nis turned green (B), indicating that the quote, and only the quote,\nwas authenticated, and that the excerpt comes from the original\nnews media from which it was retrieved. The text added by the\nuser is not highlighted. For our prototype, we used Facebook as\nsocial media since our project development occurred in Denmark,\nwhere 72% of the population use this platform for general purposes\nand 35% for news (Newman, Fletcher, Robertson, Eddy, & Nielsen,\n2022). In addition, Facebook is browser-friendly, compared to other\nsocial media that prioritize app use.\nThe logo before the highlighted text (B) refers to DR, a public\nbroadcaster highly trusted by the population (Newman et al., 2022),\nfrom which the quote originates. We decided to incorporate logos\nafter our first project study with young Danes which indicated that\nnews brands are, as a whole, a powerful cue for people to assess if\na piece of news is trustworthy (Gehrke et al., 2023).\nBy clicking on authenticated content, a reader can summon a\npopup with more information, such as who signed it, when it was\nsigned, an indication of where text was removed, and a link to theoriginal article. Additionally, information about what (quotable)\nsignatures are and what being authenticated means can also be\nprovided bythis popup.\nRelating the prototype to the general terms of quotable signa-\ntures, the original source of the quote (for example an article) is the\nmessage, and the author or distributor of the article (a news outlet,\nfor instance) is the signing party. The party sharing the quote is\nthe one extracting the signature for the quote, and the one reading\nthe verified quote performs the verification. In practice, the act of\nextracting and including the signature for the quote, and of verify-\ning the signature, would be completely automated, and happen in\nthe background, requiring no additional user interaction.\nOur prototype is separated into two parts: a library that can\nbe used by media companies to sign their articles and a browser\nextension that allows users to quote with signatures and to verify\nsignatures for quotes. The library contains implementations of the\nrelevant algorithms, and it is intended that media companies can\nintegrate it in their publishing workflow. The browser extension\nmodifies websites such that both full articles and quotes with ver-\nified signatures are shown to be signed. It also allows the user to\nmake quotes that include a signature when quoting from signed\ntext. In addition, the browser extension provides more information\nfor a quote to the user.\nFor our proposed approach to be effective, it would need to be\nwidely adopted by news media, social media, and by users sharing\nand reading quotes from articles. Notably, if news media and social\nmedia integrate this solution into their websites, our approach\ncan be employed without any explicit user awareness. With such\nintegration, when a user copies a quote from a signed article, a\nsignature for the quote is automatically generated, and an element\nincluding both quote and text is put into the clipboard, together\nwith the plain text quote (in practice, this would be a text/html\nelement and a text/plain element). When the user then pastes\nthe quote, a website supporting signatures will use the clipboard\nelement with a signature (W3C, 2021).\n3 DISCUSSION AND CONCLUSION\nAdding quotable signature schemes to the data journalism trans-\nparency repertoire might help to reduce mis- and disinformation\nspread. In this exploratory and descriptive study, we argue that\nfabricating content and falsely attributing it to news websites is a\ncurrent problem that can mislead readers and, in the end, undermine\njournalism the perceived credibility .\nEven though we have mapped cases in which legacy news media\nare mainly the object of manipulation, we argue that the disinfor-\nmation impact can quickly be extended to highly specialized news\ncoverage websites, such as data journalism. Since this data-driven\npractice deals with massive amounts of data, analysis, and visual-\nization, it can quickly become a target of mis- and disinformation\nnarratives once it provides cues people usually trust, such as statis-\ntics. Thus, quotable signature schemes are particularly promising\nto data journalism initiatives. Furthermore, emerging forms such as\npredictive journalism (Diakopoulos, 2022) could go in the same di-\nrection and suffer the consequences of a manipulative information\nenvironment.18\nAdding Quotable Signatures to the Transparency Repertoire in Data Journalism C+J & DataJ, 2023, June 23\u201324, 2023, ETH Zurich, Switzerland\nBesides working as a resource to trace the origin of a text excerpt,\nquotable signatures schemes could be extended to validate pictures,\nvideos, databases, and combinations of different formats. It would\nmean that data journalism, and other forms of journalism, could\nvalidate the provenance of different sources (including multime-\ndia content) within news articles. Available to the readership, it\nimproves and extends the transparency repertoires. Fact-checking\nagencies can also benefit from the same authentication structure\nby providing quotable signatures in pieces of verification to their\nreaders. When analyzing claims, these agencies provide evidence\nof how they have checked them by providing the original sources\nused in the verification process. The method performed is crucial\nfor fact-checking agencies to classify a claim as \u201cfalse.\u201d\nTo make a difference in the future, media companies and users on\nsocial media need to adopt these quotable signatures. To have the\nbest effect, social media platforms and news outlets should directly\nsupport quotable signatures, and the required extension should be\nnatively integrated into browsers. Ultimately, this is also a way for\nplatforms to engage in efforts to combat disinformation and protect\ndemocracy actively.\n4 ACKNOWLEDGMENTS\nWe thank our colleague and project member Johanna Eggers for\nvisualizing the user journey in Figure 3.\n5 FUNDING\nThe research project Trust and News Authenticity develops a digital\nsignature attached to journalistic content and a recognizable label\nfor users to see if the content is authentic and verified. The project\nand, therefore, the present study received financial support from\nTrygFonden and the Digital Democracy Centre at the University of\nSouthern Denmark.\nREFERENCES\nBoyar, J., Erfurth, S., Larsen, K. S., & Niederhagen, R. (2023). Quotable\nsignatures for authenticating shared quotes. arXiv. Retrieved from\nhttps://arxiv.org/abs/2212.10963v2\nCoddington, M. (2015). Clarifying journalism\u2019s quantitative turn: A typol-\nogy for evaluating data journalism, computational journalism, and\ncomputer-assisted reporting. Digital Journalism ,3(3), 331\u2013348. doi:\n10.1080/21670811.2014.976400\nCuret, M. (2022). CNN tweeted about \u201cbrave children\u201d in Ukraine signing up\nto fight Russia. PolitiFact. Retrieved 2023-03-15, from https://\nwww .politifact .com/factchecks/2022/apr/19/instagram\n-posts/cnn-did-not-tweet-about-children-ukraine-signing\n-f/\nDan, V., Paris, B., Donovan, J., Hameleers, M., Roozenbeek, J., van der Linden,\nS., & von Sikorski, C. (2021). Visual mis- and disinformation, social\nmedia, and democracy. Journalism & Mass Communication Quarterly ,\n98(3), 641-664. (See Introduction) doi: 10.1177/10776990211035395\nDiakopoulos, N. (2022). Predictive journalism: On the role of com-\nputational prospection in news media. Columbia Journalism Re-\nview. Retrieved 2023-03-15, from https://www .cjr .org/tow\n_center _reports/predictive -journalism -on -the -role -of\n-computational-prospection-in-news-media.php/\nDiffie, W., & Hellman, M. (1976). New directions in cryptography. IEEE\nTransactions on Information Theory ,22(6), 644\u2013654. doi: 10.1109/\nTIT.1976.1055638Gehrke, M. (2020). Transparency as a key element of data journalism:\nPerceptions of brazilian professionals. In Computation + Journalism\nSymposium conference proceedings.\nGehrke, M. (2022). Os elementos de transpar\u00eancia no jornalismo guiado por\ndados. Insular.\nGehrke, M., & Benetti, M. (2021). Disinformation in brazil during the\ncovid-19 pandemic: topics, platforms, and actors. Fronteiras-Estudos\nMidi\u00e1ticos ,23(2), 14\u201328.\nGehrke, M., Eggers, J., De Vreese, C., & Hopmann, D. (2023). What makes\nnews (seem) authentic? indicators from a qualitative study of young\nadults. Manuscript submitted to Digital Journalism .\nGehrke, M., & Mielniczuk, L. (2017). Philip Meyer, the outsider who created\nPrecision Journalism. Intexto (39), 4. doi: 10.19132/1807-8583201739.4\n-13\nJohnson, K. A., & St. John III, B. (2021). Transparency in the news: the impact\nof self-disclosure and process disclosure on the perceived credibility\nof the journalist, the story, and the organization. Journalism Studies ,\n22(7), 953\u2013970. doi: 10.1080/1461670X.2021.1910542\nKarlsson, M. (2010). Rituals of transparency: evaluating online news\noutlets\u2019 uses of transparency rituals in the united states, united\nkingdom and sweden. Journalism Studies ,11(4), 535\u2013545. doi:\n10.1080/14616701003638400\nKarlsson, M. (2022). Transparency and journalism: a critical appraisal of a\ndisruptive norm. Routledge.\nKreutzer, M., Niederhagen, R., Shrishak, K., & Fhom, H. S. (2019). Quotable\nsignatures using Merkle trees. In Informatik 2019: 50 jahre gesellschaft\nf\u00fcr informatik (Vol. P-294, pp. 473\u2013477).\nLazer, D. M. J., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M.,\nMenczer, F., . . . Zittrain, J. L. (2018). The science of fake news. Science ,\n359(6380), 1094\u20131096. doi: 10.1126/science.aao2998\nMeyer, P. (2002). Precision journalism: a reporter\u2019s introduction to social\nscience methods (4th ed.). Rowman & Littlefield Publishers.\nMoody, D. (2023). Digital signature standard (DSS) (Tech. Rep. No. NIST\nFIPS 186-5). National Institute of Standards and Technology (NIST).\ndoi: 10.6028/NIST.FIPS.186-5\nNewman, N., Fletcher, R., Robertson, C. T., Eddy, K., & Nielsen, R. K. (2022).\nReuters institute digital news report 2022 (Tech. Rep.). Reuters Institute\nfor the Study of Journalism.\nPeng, Y., Lu, Y., & Shen, C. (2023). An agenda for studying credibility\nperceptions of visual misinformation. Political Communication ,40(2),\n225\u2013237. doi: 10.1080/10584609.2023.2175398\nRogers, S. (2013). Facts are sacred: the power of data. Faber and Faber,\nGuardian Books.\nSchiochet, A. (2022). \u00c9 falso que instituto alem\u00e3o apontou fraude nas elei\u00e7\u00f5es\ndo Brasil. Retrieved 2023-03-15, from https://lupa .uol .com\n.br/jornalismo/2022/11/17/e-falso-que-instituto-alemao\n-apontou-fraude-nas-eleicoes-do-brasil\nSoares, F., & Recuero, R. (2021). How the mainstream media help to spread\ndisinformation about covid-19. M/C Journal ,24(1). doi: 10.5204/\nmcj.2735\nTong, J. (2023). Data for journalism: between transparency and accountability.\nRoutledge, Taylor & Francis Group.\nW3C. (2021). Clipboard api and events, W3C working draft, 6 august 2021.\nhttps://www.w3.org/TR/2021/WD-clipboard-apis-20210806/ .\n(See also https://w3c.github.io/clipboard-apis/)\n19\nData Journalism Roadmapping  \nA Conceptual Approach to Embrace Data Storytelling Formats in the Journalism Business Model  \nMathias-Felipe de-Lima-Santos\u2020 \n Faculty of Humanities  \n University of Amsterdam  \n Amsterdam, Netherlands  \n m.f.delimasantos@uva.nl  \nDigital Media and Society Observatory (DMSO)  \n Federal University of S\u00e3o Paulo (Unifesp)   \nS\u00e3o Jos\u00e9 dos Campos, SP, Brazil  \n mathias.felipe@unifesp.br \n \nABSTRACT \nIt has been almost a decade since the term data j ournalism was \ncoined. Since then, much has changed and often in unexpected \nways. Data journalism has become a global phenomenon. \nHowever, much of the ongoing and fast -paced evolution of the \npractice still occurs in well - resourced news outlets. Smaller \norganizations continue to struggle to understand how to deploy \ndata skills in their newsrooms. This study draws on extensive \nresearch involving over 60 interviews with experts on four \ncontinents (Americas, Europe, Asia, and Oceania) and participant \nobservatio ns in four well -known data -driven news outlets\u2014 La \nNaci\u00f3n  (Argentina), ProPublica (US), Al Jazeera (Qatar), and \nBBC (UK) \u2014to illuminate best practices that transcend \norganizational differences and contribute to calibrating the \nexecution of journalistic data -driven projects. By examining the \ninfrastructure levels of these organizations, that is, key activities, \nkey resources, and partner networks, I propose a roadmap that \nconceptually describes the key factors in the business model \ndecisions of news organizati ons to enable the emergence of data -\ndriven storytelling in newsrooms. Ultimately, this study notes that \nthis roadmap is not a solution but a way to provide guidelines for \nnews outlets that are willing to adopt data journalism practices.  \nCCS CONCEPTS \n\u2022 data analysis  \u2022 data visualization  \u2022 computing  \nKEYWORDS  \ndata journalism , business model , collaboration , roadmap \nACM Reference format:  \nMathias -Felipe de -Lima -Santos. 2023. Data Journalism Roadmapping : A Conceptual Approach to Embrace Data Storytelling Formats in the \nJournalism Business . In Proceedings of The Joint  Computation + \nJournalism  European Data & Computational Journalism  Conference \n2023, Zurich, Switzerland , 4 pages.   \n1 Introduction  \nDuring these more than ten years, data journalism has had to adapt \nand change to embrace technological trends and evolutions in \nrecent years. Thus, data journalism has drawn significant attention \nin academic literature and industry practices. Furthermore, the \npandemic brought a whole new set of  challenges and \nopportunities for data journalism. Some media outlets had to \nleverage the use of data and technology in time to produce stories \nabout global death toll and infection rates.   \nThe practice helped the news industry reach new developments \nin di gital news production, reshaping how the public consumes \ninformation. The practice can be a source to regain readers\u2019 trust, \nas evidence -based reporting is primarily trusted by the public \n(Heravi and Harrower 2015). Living in a post -truth world, fact -\nbased  journalism combined with excellent storytelling skills \nbacked by data is more in demand than ever before. Even with a \ncertain skepticism about the objectivity that data could bring to \njournalism (Tong and Zuo 2021), fact -based journalism allows \nproducing quality journalism that engages the public and \nmaintains a healthy democracy. However, it is essential to \nelucidate best practices that transcend organizational differences \nand calibrate the execution of journalistic data -driven projects \nbeyond award- winni ng, cross -border projects (Heft, Alfter, and \nPfetsch 2019; Konow -Lund 2019; Alfter 2016).  \n \n2  Picturing Data Journalism as a Strategic \nDifferentiator  \nSince 2019, I have been working on understanding how data \njournalism is intertwined with the business model of media \norganizations. This research project draws on extensive research \ninvolving over 60 interviews with experts on four continents Permission to make digital or hard copies of part or all of  this work for personal or \nclassroom use is granted without fee provided that copies are not made or \ndistributed for profit or commercial advantage and that copies bear this notice and \nthe full citation on the first page. Copyrights for third -party compone nts of this \nwork must be honored. For all other uses, contact the owner/author(s).  \nWOODSTOCK\u201918, June, 2018, El Paso, Texas USA  \n\u00a9 2018 Copyright held by the owner/author(s). 978- 1-4503- 0000- 0/18/06...$15.00  \n20\nThe Joint Computation + Journalism European Data & \nComputational Journalism Conference 2023, Zurich, Switzerland  M.-F. de-Lima -Santos  \n \n \n (Americas, Eu rope, Asia, and Oceania) and participant \nobservations in four well -known data -driven news outlets\u2014 La \nNaci\u00f3n (Argentina), ProPublica (US), Al Jazeera (Qatar), and \nBBC (UK) \u2014to illuminate best practices that transcend \norganizational differences and contribute  to calibrating the \nexecution of journalistic data -driven projects in newsrooms. \n \n \nFigure 1:  Steps  of the Data Journalism Roadmapping  \nThe guidelines are structured following the categorization of \ninfrastructure proposed in the Business Model Canvas (BMC) by \nOsterwalder and Pigneur (2010). The authors define infrastructure \nas one of the four areas that comprise the nine building blocks \nutilized to describe how an organization creates, delivers, and \ncaptures value, as well as the interconnections among them. This \nreport considers the three building blocks of infrastructure as part \nof the discussion of dat a journalism as a strategy for news \norganizations. Specifically, it aimed to understand the \ninfrastructure levels of these organizations, that is, key activities, \nkey resources, and partner networks.  \n \nThe key activities differ from business to business de pending \non the product or service offered. They are performed to support a \ncompany\u2019s value proposition, which requires the key resources. \nThese resources are the main assets needed in a successful \nbusiness model (Osterwalder and Pigneur 2010; Zolnowski and  \nB\u00f6hmann 2014). They are also the core enabler for a company\u2019s \nsuccessful implementation of operational strategies, which can be \nphysical assets, intellectual property, human resources, or \nfinancial resources. Finally, the partner network is an essential \nchain of associates and suppliers that enable an organization to \nachieve its value proposition by providing critical resources and \nperforming main activities. Forming alliances with other \ncompanies can strengthen organizations\u2019 business models by \nlimiting risks and providing new resources (Osterwalder and \nPigneur 2010; Zolnowski and B\u00f6hmann 2014). This does not mean that companies can no longer compete. Instead, \norganizations form strategic partnerships to achieve a common \ngoal (De Reuver, Bouwman, and Haake r 2013). In the news \nindustry, this is commonly seen in collaborative journalistic \nprojects (Carson and Farhall 2018; Heft, Alfter, and Pfetsch 2019; \nHeft and Baack 2021).  \n3  The Infrastructure of Data Journalism  \nIn this research, I sought to understand ho w specific elements \nfunctioned inside these organizations and identified common \nfactors that enabled these practitioners to produce data stories. \nRespondents mentioned that adopting data journalism requires \nstrong leadership to drive the transformation and  embrace the \npace of change. Thus, a congruent and sustainable action that \ndrives organizational leaders\u2019 decision -making toward data \njournalism is essential to ensure a long- term investment strategy \nand sufficient incentives to deploy data skills in the n ewsroom \n(Kosterich 2020; Lewis and Usher 2014; De Maeyer et al. 2015).  \nPractitioners mentioned the importance of establishing \nworking structures at the outset and agreeing on the \nresponsibilities and activities of data journalists. This can be done \nfollowi ng the infrastructure of BMC, as shown in the figure \nbelow.  \n \n \nFigure 1:  The Infrastructure Component of a Business Model \n1.3  Analyzing Key Activities and Exec ution \nPossibilities \nCompiling, cleaning, combining, and giving context for data \nare the central working units to produce data stories. Furthermore, \nthese professionals are expanding their knowledge boundaries to \nperform activities that were not previously habitual in the fiel d \nand interact with other actors, thereby expanding their network. \nMedia managers must guarantee that data teams are not seen as \nservice desks but as a unit dedicated to scrutinizing data to \ninterpret trends, events, and areas of concern. Similarly, \ntechnology\u2019s normative values of transparency, iteration, \ntinkering, and participation became important activities that data \njournalism practitioners bring to newsrooms and incorporate into \n21\nInsert Your Title Here  WOODSTOCK\u201918, June, 2018, El Paso, Texas USA  \n \n their daily work. This includes the open data culture, the \npromotion of the Freedom of Information Act (FOIA), and open -\nsource codes.  \n4  Implementing Key Resources and Capabilities  \nData journalism is often perceived as a time -consuming, labor -\nintensive, and expensive practice (Jamil 2021). Still, identifying \ntools and capabili ties that support the sustainability and longevity \nof the production of data stories in newsrooms can buffer these \nissues. As coding requires time and practice, most journalists do \nnot have significant spare time to do it. Newsrooms have resorted \nto third -party solutions to build interactive and visual stories \nwithout the necessary expertise and knowledge of coding. This is \nparticularly important in newsrooms that feature a one -man-band \natmosphere, that is, a single data journalist responsible for the \nentire production pipeline. These tools allow one person to \nproduce a story without data- specific knowledge (de -Lima -Santos \nand Mesquita 2021a). Third -party solutions impose some \nlimitations, such as a lack of \u201cfeatures, premium subscription \ncosts and the poten tial for changes to these services\u201d (de -Lima -\nSantos, Schapals, and Bruns 2021, 164). To overcome this, news \noutlets hire multidisciplinary teams that cooperate across different \ndisciplines toward a common goal of producing scalable products \nfor their newsr ooms instead of relying on out -of-the-box \nsolutions. These in -house tools are customized to company -\nprescribed guidelines and deliver visualizations and interactive \nfeatures that align with the visual identities of the organizations. \nIn fact, these differe nt approaches create a dichotomy in the news \nindustry. While well -resourced news outlets are developing in -\nhouse solutions, small and medium -sized news organizations, \nwhich do not enjoy the same financial resources as large \nnewsrooms, adopted third -party s olutions. Another essential \nresource for data journalists is access to open data and Freedom of \nInformation (FOI) laws. Without them, this becomes an activity \nfor these professionals who have to build datasets from documents \nor studies or collect their own  data.  \n5  Creating Partner Networks to Leverage the \nCapabilities of Data Journalism  \nThe scholarly literature recognizes the collaborative nature of \ndata journalism. However, this cooperative endeavor emerges at \ndifferent levels and amplitudes in various or ganizations, from \nmicro and meso to macro levels. Data journalists work at data \ndesks and collaborate with other newsrooms\u2019 departments (micro \nlevel). By cooperating, journalists and non -journalist actors have \nthe opportunity to create innovative practices  that positively \nimpact the implementation of data journalism (meso level). \nSimilarly, the partner network can be built through external \ncollaborations (macro level). Intending to maximize the impact of \nits stories, ProPublica had 228 publishing partners a t local and \ninternational levels in 2019. These collaborative alliances are an \nimportant strategy for reaching this goal, particularly at the local \nlevel. Consequently, ProPublica developed the Local Reporting \nNetwork with over 20 newsrooms across the Unit ed States. Each \nnewsroom pays its salary and gets access to our research team, news app data, and engagement. These alliance members also \nrepublish ProPublica\u2019s content and are also supply and knowledge \nsources from local stories (de -Lima -Santos 2022). Sim ilarly, \ngrassroots communities have been essential in establishing data \njournalism as a trend in Latin America (de -Lima -Santos and \nMesquita 2021b). Ancillary organizations, such as the Mexican \nnon-profit organization SocialTIC, which is responsible for the  \nEscuela de Datos(School of Data, in Spanish), Internews, the \nInternational Center for Journalists (ICFJ), and Abraji (the \nBrazilian Association of Investigative Journalism), promoted \ncourses and seminars and published numerous works for the data \njournalis m community in Latin America.  \n6  Conclusion  \nThis roadmap has sequentially discussed the core elements of \nimplementing data journalism practices in newsrooms. A central \nfinding of this roadmap is that many key activities, resources, and \nalliances collaborat e to produce data stories. Importantly, these \npoints are not collinear, as each news organization has its own \noperating culture, processes, and financial situation. However, \nadopting some of these best practices may allow organizations to \nremain focused and foster a long -term strategy to develop data \njournalism in small and medium -sized news outlets. Generally, \nlong-term plans have been hijacked by shorter -term projects \n(K\u00fcng 2017), which places news organizations at a strategic \ndisadvantage vis -\u00e0-vis their  early adopters and disrupts \ncompetitors. This conceptual roadmap is essential because it \nidentifies a potential infrastructure area that describes the rationale \nof how an organization creates, delivers, and captures value \n(Osterwalder and Pigneur 2010). T herefore, this roadmap is not a \nsolution but a way to offer guidelines for news outlets willing to \nadopt data journalism practices. It notes that transforming news \norganizations is difficult and often risky work that depends on \nhow processes are articulate d and calibrated for this \ntransformation. I profoundly hope that this work simplifies the \ntask for practitioners by identifying change levers and sharing best \npractices so that more newsrooms can adopt data -driven practices \nin their storytelling.  \n \nREFERENC ES \nAlfter, Brigitte. 2016. \u201cCross- Border Collaborative Journalism: Why Journalists and \nScholars Should Talk about an Emerging Method.\u201d  Journal of Applied \nJournalism & Media Studies  5 (2): 297\u2013 311. \nhttps://doi.org/10.1386/ajms.5.2.297_1.  \nCarson, Andrea, and Kate Farhall. 2018. \u201cUnderstanding Collaborative Investigative \nJournalism in a \u2018Post -Truth\u2019 Age.\u201d  Journalism Studies  19 (13): 1899\u2013 1911. \nhttps://doi.org/10.1080/1461670X.2018.1494515.  \nde-Lima- Santos, Mathias- Felipe. 2022. \u201cProPublica\u2019s Data Journalism: How \nMultidisciplinary Teams and Hybrid Profiles Create Impactful Data \nStories.\u201d Media and Communication  10 (1): 5\u2013 15. \nhttps://doi.org/10.176 45/mac.v10i1.4433.  \nde-Lima- Santos, Mathias- Felipe, and Lucia Mesquita. 2021. \u201cThe Strategic Value of \nData Journalism.\u201d In Journalism, Data and Technology in Latin America , \nedited by Ram\u00f3n Salaverr\u00eda and Mathias -Felipe De -Lima- Santos, 1st ed., 97 \u2013\n136. Cham:  Palgrave Macmillan Ltd. https://doi.org/10.1007/978 -3-030-65860-\n1_4. \nde-Lima- Santos, Mathias- Felipe, Aljosha Karim Schapals, and Axel Bruns. 2021. \n\u201cOut -of-the-Box versus in -House Tools: How Are They Affecting Data \nJournalism in Australia?\u201d  Media Internati onal Australia  181 (1): 152 \u201366. \nhttps://doi.org/10.1177/1329878X20961569.  \n22\nThe Joint Computation + Journalism European Data & \nComputational Journalism Conference 2023, Zurich, Switzerland  M.-F. de-Lima -Santos  \n \n \n Heft, Annett, Brigitte Alfter, and Barbara Pfetsch. 2019. \u201cTransnational Journalism \nNetworks as Drivers of Europeanisation.\u201d  Journalism  20 (9): 1183\u2013 1202. \nhttps://doi.org/10.1177/146 4884917707675.  \nHeft, Annett, and Stefan Baack. 2021. \u201cCross -Bordering Journalism: How \nIntermediaries of Change Drive the Adoption of New Practices.\u201d  Journalism , \nMarch, 146488492199954. https://doi.org/10.1177/1464884921999540.  \nHeravi, Bahareh Rahmanzadeh, and Natalie Harrower. 2015. \u201cSourcing and Trust.\u201d \nIn Proceedings of the 2015 International Conference on Social Media & \nSociety \u2013 SMSociety \u201915 , 1\u20135. New York, New York, USA: ACM Press. \nhttps://doi.org/10.1145/2789187.2789194.  \nJamil, Sadia. 2021. \u201cIncreasi ng Accountability Using Data Journalism: Challenges \nfor the Pakistani Journalists.\u201d Journalism Practice  15 (1): 19 \u201340. \nhttps://doi.org/10.1080/17512786.2019.1697956.  \nKonow- Lund, Maria. 2019. \u201cNegotiating Roles and Routines in Collaborative \nInvestigative Jo urnalism.\u201d  Media and Communication  7 (4): 103\u2013 11. \nhttps://doi.org/10.17645/mac.v7i4.2401.  \nK\u00fcng, Lucy. 2017. \u201cGoing Digital: A Roadmap for Organisational \nTransformation.\u201d  Twist . Oxford, UK.  \nOsterwalder, Alexander, and Yves Pigneur. 2010.  Business Model Gene ration: A \nHandbook for Visionaries, Game Changers, and Challengers . 1st ed. Hoboken: \nWiley.  \nReuver, Mark De, Harry Bouwman, and Timber Haaker. 2013. \u201cBusiness Model \nRoadmapping: A Practical Approach to Come from an Existing to a Desired \nBusiness Model.\u201d  International Journal of Innovation Management  17 (1): 1\u2013\n18. https://doi.org/10.1142/S1363919613400069.  \nTong, Jingrong, and Landong Zuo. 2021. \u201cThe Inapplicability of Objectivity: \nUnderstanding the Work of Data Journalism.\u201d  Journalism Practice  15 (2): 153\u2013\n69. https://doi.org/10.1080/17512786.2019.1698974.  \nZolnowski, Andreas, and Tilo B\u00f6hmann. 2014. \u201cFormative Evaluation of Business \nModel Representations \u2013 The Service Business Model Canvas.\u201d  ECIS 2014 \nProceedings \u2013 22nd European Conference on Information Syste ms, no. July: 1 \u2013\n15. \n \n23\nThe Joint Computation + Journalism European Data & \nComputational Journalism Conference 2023, Zurich, Switzerland  M.-F. de-Lima -Santos  \n \n \n (Americas, Eu rope, Asia, and Oceania) and participant \nobservations in four well -known data -driven news outlets\u2014 La \nNaci\u00f3n (Argentina), ProPublica (US), Al Jazeera (Qatar), and \nBBC (UK) \u2014to illuminate best practices that transcend \norganizational differences and contribute  to calibrating the \nexecution of journalistic data -driven projects in newsrooms. \n \n \nFigure 1:  Steps  of the Data Journalism Roadmapping  \nThe guidelines are structured following the categorization of \ninfrastructure proposed in the Business Model Canvas (BMC) by \nOsterwalder and Pigneur (2010). The authors define infrastructure \nas one of the four areas that comprise the nine building blocks \nutilized to describe how an organization creates, delivers, and \ncaptures value, as well as the interconnections among them. This \nreport considers the three building blocks of infrastructure as part \nof the discussion of dat a journalism as a strategy for news \norganizations. Specifically, it aimed to understand the \ninfrastructure levels of these organizations, that is, key activities, \nkey resources, and partner networks.  \n \nThe key activities differ from business to business de pending \non the product or service offered. They are performed to support a \ncompany\u2019s value proposition, which requires the key resources. \nThese resources are the main assets needed in a successful \nbusiness model (Osterwalder and Pigneur 2010; Zolnowski and  \nB\u00f6hmann 2014). They are also the core enabler for a company\u2019s \nsuccessful implementation of operational strategies, which can be \nphysical assets, intellectual property, human resources, or \nfinancial resources. Finally, the partner network is an essential \nchain of associates and suppliers that enable an organization to \nachieve its value proposition by providing critical resources and \nperforming main activities. Forming alliances with other \ncompanies can strengthen organizations\u2019 business models by \nlimiting risks and providing new resources (Osterwalder and \nPigneur 2010; Zolnowski and B\u00f6hmann 2014). This does not mean that companies can no longer compete. Instead, \norganizations form strategic partnerships to achieve a common \ngoal (De Reuver, Bouwman, and Haake r 2013). In the news \nindustry, this is commonly seen in collaborative journalistic \nprojects (Carson and Farhall 2018; Heft, Alfter, and Pfetsch 2019; \nHeft and Baack 2021).  \n3  The Infrastructure of Data Journalism  \nIn this research, I sought to understand ho w specific elements \nfunctioned inside these organizations and identified common \nfactors that enabled these practitioners to produce data stories. \nRespondents mentioned that adopting data journalism requires \nstrong leadership to drive the transformation and  embrace the \npace of change. Thus, a congruent and sustainable action that \ndrives organizational leaders\u2019 decision -making toward data \njournalism is essential to ensure a long- term investment strategy \nand sufficient incentives to deploy data skills in the n ewsroom \n(Kosterich 2020; Lewis and Usher 2014; De Maeyer et al. 2015).  \nPractitioners mentioned the importance of establishing \nworking structures at the outset and agreeing on the \nresponsibilities and activities of data journalists. This can be done \nfollowi ng the infrastructure of BMC, as shown in the figure \nbelow.  \n \n \nFigure 1:  The Infrastructure Component of a Business Model \n1.3  Analyzing Key Activities and Exec ution \nPossibilities \nCompiling, cleaning, combining, and giving context for data \nare the central working units to produce data stories. Furthermore, \nthese professionals are expanding their knowledge boundaries to \nperform activities that were not previously habitual in the fiel d \nand interact with other actors, thereby expanding their network. \nMedia managers must guarantee that data teams are not seen as \nservice desks but as a unit dedicated to scrutinizing data to \ninterpret trends, events, and areas of concern. Similarly, \ntechnology\u2019s normative values of transparency, iteration, \ntinkering, and participation became important activities that data \njournalism practitioners bring to newsrooms and incorporate into \n24\nTiancheng Hu, Manoel Horta Ribeiro, Robert West, and Andreas Spitz\nleanings of different U.S. outlets. By counting the usage of nonobjec-\ntive quotatives like \u201cshout\u201d or \u201cassert\u201d, we analyze how U.S. news\noutlets of different political inclinations adhere to basic journalistic\nobjectivity principles and how this adherence evolves. Further, ana-\nlyzing how outlets of different political inclinations use quotatives\nto talk about politicians of different parties, we study the evolution\nof quotative bias in news outlets.\n1.0.2 Summary of Findings. We find that the usage of nonob-\njective quotatives varies across different outlet categories. Overall,\nthe more ideologically extreme an outlet is, the more nonobjective\nquotatives it uses. However, we also find that centrist outlets are\nexperiencing a significant increase in the usage of nonobjective quo-\ntatives over the last years (about 0.6 percentage points, or 20% in\nrelative percentage), suggesting that they may be \u201ccatching up\u201d to\nthe more biased outlets, which are not experiencing such significant\nincreases (RQ1). We also find evidence of \u201cquotative bias\u201d, i.e., out-\nlets tend to use nonobjective quotatives, especially when referring to\npoliticians of opposing ideology. For instance, left and right-leaning\noutlets use nonobjective quotatives up to 2% more often when refer-\nring to republicans and democratic politicians, respectively (RQ2).\nLast, we find that this quotative bias is increasing at a swift pace,\nincreasing as much as 0.5 percentage points per year in absolute\npercentage, or 25% in relative percentage, for left-leaning outlets,\nsuggesting a rapid increase in polarization (RQ1 andRQ2).\n1.0.3 Implications. Our findings indicate a decline in journalistic\nobjectivity in U.S. political news, particularly from centrist outlets.\nThis suggests that centrist outlets may play a role in the increasingly\nless respectful and fact-based debate around politics [ 16]. Further,\nwe also find evidence of an increasing quotative bias, which could\nfurther erode trust in media [7].\n2 MATERIALS AND METHODS\n2.1 Data and Data Processing\nTo study quotative usage across various news outlets, we use the\nQuotebank [ 38] dataset, a web-scale corpus of quotes. Quotebank\ncontains over 235 million unique quotes, extracted from 196 million\nEnglish news articles from 377 thousand web domains between\nSeptember 2008 and April 2020. We additionally obtain a list of\ncurrent and former U.S. politicians with their party affiliations from\nWikidata, in the same fashion as K\u00fclz et al . [23] , We filter QuoteBank\nto consider the period containing the best-quality speaker attributions\n(May 2013 to 2020) and retain only quotes from politicians on this\nlist.\nTo ensure the validity of our findings, we preprocess Quotebank\nas depicted in Figure 1. We 1) use heuristics to retain only direct\nquotes; 2) extract quotatives and remove quotes without quotatives\nin the verb form; 3) filter quotes, keeping only those from U.S-based\noutlets with human-verified bias ratings; and 4) create dictionaries\nof common quotatives, removing quotes with rare quotative verbs\nfor which quotative extraction performs poorly. We detail each of\nthese steps in the following paragraphs.\nStep 1: Removing Titles and Mixed Quotes. To remove titles from\nthe dataset that are erroneously recognized as quotes (e.g., movies,\nbooks, etc.), we apply a filter using the percentage of words in a\nquote whose first letter is capitalized (using a threshold of 50%14.6M quotes\n(76.2%)19.2M quotes\nby U.S. politicians\n14.4M quotes\n(75.4%)\n7.3M quotes\n(38.0%)\n6.7M quotes\n(35.1%)Quotebank@!#?@!\n1: Removing titles and mixed quotes\n2: Extracting quotatives and removing non-verb quotatives\n3: Removing unsuitable news outlets\n4: Creating & applying dictionaries of common quotativesSelecting quotes attributed to U.S. politicians\nFigure 1: Data processing pipeline. We outline the key steps in\nour data processing pipeline and the percentage of retained data\nafter filtering.\ncapitalization). Afterward, to remove mixed quotes, we employ a\nsentence recognition filter that combines constituency parsing1and\ndependency parsing2. We retain only quotes that can be parsed\nas a full sentence at the root level by constituency parsing and\ncontain a subject and a predicate (root) in dependency parsing. These\nheuristics greatly improve data quality (e.g., extracted quotatives in\nStep 2 are much more accurate) while retaining 76.2% of the dataset.\nStep 2: Extracting Quotatives and Removing Non-verb Quota-\ntives. In the next step, we adopt a three-stage approach to extract the\nquotative from each quote using dependency parsing. First, we run\ndependency parsing and acquire a distribution of quotatives from\nthe root node of each parsed quote. Second, we add a condition\nto ensure that in cases where one verb is identified as the root and\nanother verb exists in a parallel node3, we choose the verb with the\nhigher probability as the quotative (according to the distribution of\nverbs extracted in the first stage). Finally, we take the lemma of each\nextracted quotative and remove quotatives that are not in verb form.\nAfter this step, we retain around 75.4% of the original data.\nStep 3: Removing Unsuitable Outlets. We obtain a list of media\nbias ratings from mediabiasfactcheck.com (hereinafter MB/FC) and\nclassify outlets into five categories based on the bias rating: left,\nleft-center, least-biased, right-center, and right. We refer to left-\ncenter, least-biased, and right-center outlets as centrist outlets in the\nfollowing. We remove quotes from outlets without a bias rating, from\noutlets that are not from the U.S. (also according to MB/FC data),\nand from outlets that have very few quotes (which may suggest data\nquality issues), only keeping outlets with more than 20 quotes over\n1Constituency parsing breaks down sentences into phrases and identifies their grammat-\nical roles, e.g., in \u201cI eat a big apple\u201d, \u201ca big apple\u201d is a noun phrase. See Jurafsky and\nMartin [20] for details.\n2Dependency parsing extracts dependency relationships between words, with verbs\ntypically being in the structural center, e.g., in \u201cI eat a big apple\u201d, \u201cbig\u201d is an adjectival\nmodifier of \u201capple.\u201d See K\u00fcbler et al. [22] for details.\n3csubj ,ccomp ,xcomp ,advcl ,acl,parataxis ,conj ,cc,relcl , see https:\n//universaldependencies.org/en/dep/\n25\nQuotatives Indicate Decline in Objectivity in U.S. Political News\n10%7%5%3%2%1%\nUsage of Nonobjective QuotativeLeft\nLeft-Center\nLeast-Biased\nRight-Center\nRight\nQuote-level average\nFigure 2: Usage of nonobjective quotatives across outlets of\ndifferent political leaning. For each media bias category (on the\n\ud835\udc66\ud835\udc66-axis), we depict the usage of nonobjective quotatives per outlet\n(each represented by a circle \u25e6) and the overall average usage\npooled across outlets ( \u00d7). Note that the \ud835\udc65\ud835\udc65-axis is on a logarithmic\nscale. Pairwise differences between averages are statistically\nsignificant under the Wilcoxon Rank-Sum Test with Bonferroni\ncorrection.\na period of 12 months. After this step, around 38.0% of the original\ndata remains, all from relevant U.S. media outlets with human-\nverified bias ratings. Manual inspection of the removed data confirms\nthat the removed outlets are predominantly non-news websites, small\nlocal newspapers, radio stations, and non-U.S news outlets.\nStep 4: Creating Dictionaries of Common Quotatives. Inspired\nby Lee [24] as well as the recommendations laid out in Reuters [29]\nand The Associated Press [35], we define quotatives as objective\nif they refer to the direct speech action and do not involve any\nsubjective judgment of the action (e.g., like \u201csay\u201d and \u201ctell\u201d); and as\nnonobjective if they refer to some additional action or conduct and\nwith subjective judgments (such as \u201cboasted\u201d, \u201crasped\u201d, \u201ctaunted\u201d, or\n\u201chailed\u201d). To optimize for precision, we exclude common verbs with\nmany non-quotative senses, such as \u201cgo.\u201d Using this definition, we\nmanually annotate the most frequent 99.5% of quotatives overall and\nthe 98.0% of the most frequent quotatives per month. We consulted\na professional journalist throughout this process, who suggested\nthat the verbs \u201copine\u201d, \u201cpen\u201d, and \u201cutter\u201d are only sometimes used\nnonobjectively. Since it would be infeasible to create a separate\ncategory just for these verbs, we excluded them. In the end, we\ncurated a list of 32 objective and 152 nonobjective verbs. We use\nthis list to remove rare verbs (i.e., those not on the list), obtaining\na final dataset with 6.7M quotes (35.1% of the original data) from\n14,031 politicians in 989 outlets.\n3 RESULTS\n3.1 RQ1: How Has the Usage of Nonobjective\nQuotatives Evolved?\nAcross the study period, we find that the usage of nonobjective quo-\ntatives produces a sensible ordering of the media bias categories\nconsidered, with the more partisan outlets using the most nonobjec-\ntive quotatives and the less partisan outlets using the least. We depict\nthis order in Fig. 2, where each circle ( \u25e6) represents the average\nusage of nonobjective quotatives in one of the outlets considered,\nand crosses ( \u00d7) indicate the average usage pooled across each media\nbias category. When quoting politicians, U.S. least-biased outlets use\nnonobjective quotatives the least (2.8%, 2.12M quotes), followed byLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22120.25 \u22120.125 0 0.125 0.25\nPercentage rate of change (\u03b2)\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\nFigure 3: Percentage yearly rate of change of nonobjective quo-\ntative usage for each outlet category. A solid circle denotes a\nsignificant effect (p<0.05), and a hollow circle denotes an in-\nsignificant effect. Note that the reported trends correspond to\nthe estimated \ud835\udefd\ud835\udefdcoefficients in Eq. (1).\n2014 2017 2020\nYear0.010.000.010.02 Nonobjective\nQuotative\nFigure 4: Percentage yearly rate of change of nonobjective quo-\ntative usage for all outlets combined. We show the percentage of\nnonobjective quotatives after performing centering and plot a\nregression line showing the \ud835\udefd\ud835\udefdcoefficients estimated in our fixed\neffects model.\nthe right-center (3.1%, 0.94M) and left-center outlets (3.3%, 2.45M)\nand finally, right (5.7%, 0.75M) and left outlets (6.7%, 0.46M).\nOutlets considered more partisan by MB/FC used nonobjective quo-\ntatives more. Pairwise differences between averages are statistically\nsignificant under the Wilcoxon Rank-Sum Test with Bonferroni\ncorrection.\nTo study how the usage of nonobjective quotatives evolved, we\nuse a fixed effects linear probability model. For each quote \ud835\udc5e\ud835\udc5ein\nour dataset, let \ud835\udc5c\ud835\udc5c[\ud835\udc5e\ud835\udc5e]be the outlet in which \ud835\udc5e\ud835\udc5ewas reported, \ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]be\nthe bias category of the outlet, and \ud835\udc61\ud835\udc61[\ud835\udc5e\ud835\udc5e]be the time when it was in\nreported in months relative to the starting period of our dataset (May\n2013). We then define the model as\n\ud835\udc66\ud835\udc66\ud835\udc5e\ud835\udc5e=\ud835\udefc\ud835\udefc\ud835\udc5c\ud835\udc5c[\ud835\udc5e\ud835\udc5e]+\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]+\ud835\udefd\ud835\udefd\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]\ud835\udc61\ud835\udc61[\ud835\udc5e\ud835\udc5e]+\ud835\udf16\ud835\udf16\ud835\udc5e\ud835\udc5e, (1)\nwhere the dependent variable \ud835\udc66\ud835\udc66\ud835\udc5e\ud835\udc5eequals 1 if the verb used in the quote\n\ud835\udc5e\ud835\udc5eis nonobjective and 0 otherwise, \ud835\udefc\ud835\udefc\ud835\udc5c\ud835\udc5c[\ud835\udc5e\ud835\udc5e]is an outlet-level intercept,\n\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]is a category-level intercept, and \ud835\udefd\ud835\udefd\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]is a category-level trend\nin the usage of nonobjective quotatives \u2013 the effect we are interested\nin estimating.4Since we are modeling time-series data (one per\noutlet), autocorrelation may shrink the confidence intervals of model\n4Alternatively, this model can be written in R notation as \ud835\udc66\ud835\udc66\u223c\ud835\udc5c\ud835\udc5c+\ud835\udc4f\ud835\udc4f+\ud835\udc4f\ud835\udc4f:\ud835\udc61\ud835\udc61, where \ud835\udc66\ud835\udc66is\nthe same outcome, \ud835\udc61\ud835\udc61is the time in months, and \ud835\udc5c\ud835\udc5cand\ud835\udc4f\ud835\udc4fare categorical variables for the\noutlet and bias category.\n26\nTiancheng Hu, Manoel Horta Ribeiro, Robert West, and Andreas Spitz\n201420172020\nYear0.010.000.010.02 Nonobjective\nQuotativeLeft\n201420172020\nYearLeft-Center\n201420172020\nYearLeast-Biased\n201420172020\nYearRight-Center\n201420172020\nYearRight\nFigure 5: Trends in the usage of nonobjective quotatives across outlets of different political leaning. For each media bias category\n(one per column), we show the percentage of nonobjective quotatives after performing outlet-level centering and plot a regression line\nshowing the \ud835\udefd\ud835\udefdcoefficients estimated in our fixed effects model.\nestimates [see Bertrand et al . [5] for details]. To address this, we\nestimate the model using cluster robust standard errors, clustering\non the outlet level [11].\nWe depict the estimated trends nonobjective quotative usage in\nFig. 3 [i.e., the estimated \ud835\udefd\ud835\udefd\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]in Equation (1)]. Although the least-\nbiased outlets used nonobjective quotatives less on average (c.f.,\nFig. 2), we find that their usage of nonobjective quotatives increases\nover time. We estimate that least-biased outlets increase their usage\nof nonobjective quotatives by 0.08% per year and that right-center\nand left-center outlets increase their usage by 0.10% and 0.06% per\nyear, respectively. If we compare the level of nonobjective quotative\nusage from 2013 to 2020 (beginning and end of our study), these\nchanges translate to relative increases of 19.9% for least-biased\noutlets, 21.3% for right-center and 13.6% for left-center outlets. In\ncontrast, left outlets experienced a statistically insignificant decrease\nin their usage of nonobjective quotatives by 0.12% per year, and right\noutlets experienced a smaller, not statistically significant increase in\nusage of nonobjective quotatives (of roughly 0.01%).\nWe further illustrate the results obtained in the fixed effects model\nin Figure 4 and 5.In Figure 4, we center the overall quotative usage\naround 0 and plot the month-level nonobjective quotative usage,\nalong with a regression line capturing the trend. We see that the\noverall rate of nonobjective quotative usage among all outlets is\nincreasing, and therefore, we argue that quotatives indicate a decline\nin objectivity in U.S political news. The increase in nonobjective\nquotative usage in all outlets aggregated in percentage per year\n(slope) is 0.079% ( \ud835\udc5d\ud835\udc5d<0.001)\nIn Figure 5, we plot at the outlet category level: we center each\noutlet time series around 0 and then report the month-level (de-\nmeaned) usage of nonobjective quotatives per outlet category, along\nwith a regression line capturing the trend in each time series. Here,\nwe again see that the usage of nonobjective quotatives increases for\ncentrist outlets, decreases for outlets on the left, and only slightly\nincreases for outlets on the right, although the two latter results were\nnot statistically significant according to the model.\nAnother way to understand the change in quotative usage is to\nconsider the extremes. We compare how quotative usage changes\nbetween the first 12 months (May 2013 - April 2014) and the last\n12 months (May 2019 - April 2020) of our dataset. In Table 1, we\nreport the quotatives that experienced the largest changes in terms of\nabsolute percentage points (on the left) and odds ratio (on the right).\nWe find that the usage of the quotative \u201csay\u201d, considered the gold\nstandard of quotatives, fell by more than 10% percentage points. AtQuotative Percentage Change Quotative Odds Ratio\nsay -10.18 \u2193 tweet 1 \u219217.04\ntweet 4.157 \u2191 falter 1\u219211.88\ntell 1.843 \u2191 caption 1 \u219210.86\nwrite 1.555 \u2191 restate 1\u21926.772\nadd 1.020 \u2191 remark 1\u21925.614\nrespond 0.3538 \u2191 punctuate 1\u21924.855\ncontinue 0.3454 \u2191 blurt 4.891\u21921\ndeclare 0.2325 \u2191 disclose 4.911\u21921\nremark 0.2159 \u2191 enthuse 6.335\u21921\nclaim 0.2028 \u2191 exult 15.65\u21921\nTable 1: Changes in quotatives used. We report the most\nchanged quotatives between our dataset\u2019s first and last 12\nmonths in absolute change and odds ratio. Italic highlighting\ndenotes nonobjective quotatives.\nthe same time, we see an increase in other objective quotatives (e.g.,\ntell), but this increase does not account for the entire ten percentage\npoints. Lower in the list, we see that nonobjective quotatives like\nclaim, remark, and declare are used more often. Finally, we high-\nlight that quotatives reveal changes in where journalist source their\nquotes, with both \u201ctweet\u201d and \u201ccaption\u201d (usually employed when\nthe speaker uploads a picture or video on social media) experiencing\nlarge relative increases in usage.\n3.2 RQ2: How Do News Outlets Use Nonobjective\nQuotatives When Covering Politicians of\nDifferent Parties?\nNext, we investigate whether the outlets are biased in their quotative\nusage when they cover politicians from ideologically similar vs.\nopposing political parties.\nQuotative Bias Across Outlet Categories. For each quote \ud835\udc5e\ud835\udc5e, let\n\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]be the party of the politician who uttered the quote. Keeping\nwith the notation in Eq. (1), we again use a fixed effects linear\nprobability model\n\ud835\udc66\ud835\udc66\ud835\udc5e\ud835\udc5e=\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]+\ud835\udf02\ud835\udf02\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]+\ud835\udf0e\ud835\udf0e\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e],\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]+\ud835\udf16\ud835\udf16\ud835\udc5e\ud835\udc5e, (2)\nwhere the dependent variable \ud835\udc66\ud835\udc66\ud835\udc5e\ud835\udc5eequals 1 if the quotative used in\nthe quote \ud835\udc5e\ud835\udc5eis nonobjective and 0 otherwise, \ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]is a category-level\nintercept, \ud835\udf02\ud835\udf02\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]is a party-level intercept, and \ud835\udf0e\ud835\udf0e\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e],\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]captures the\n27\nQuotatives Indicate Decline in Objectivity in U.S. Political News\ninteraction between pairs of outlet bias category ( \ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]) and speaker\nparty ( \ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]). We emphasize that outlet and outlet category are outlet-\nlevel attributes while political party is a politician-level attribute. We\nagain cluster standard errors on the outlet level to address autocorrela-\ntion. Note that here, we are particularly interested in the contrasts be-\ntween different combinations of outlet categories and speaker parties,\ne.g., the difference between how left outlets quote Democratic and\nRepublican speakers (in the model \ud835\udf0e\ud835\udf0eleft,democratic \u2212\ud835\udf0e\ud835\udf0eleft,republican ).\nFor each media bias category, we show the estimated percentage\ndifference in the usage of nonobjective quotatives for Democratic\nand Republican speakers in Figure 6. We find that, for every outlet\ncategory, there is a significant difference in quotative usage between\nDemocratic and Republican speakers. Notably, this difference is\nnearly 2%, around a third of the overall nonobjective quotative usage,\nfor both left and right media outlets, which use more nonobjective\nquotatives when referring to politicians from opposing political\nparties. For centrist outlets, we see a Democratic bias in the usage\nof quotatives, with Republicans being quoted with nonobjective\nquotatives around 1% more for least-biased and left-center outlets\nand nearly 0.5% more for right-center outlets.\nTrends in Quotative Bias. Finally, we investigate if quotative bias\nhas evolved during the study period, using a fixed effects linear\nprobability model:\n\ud835\udc66\ud835\udc66\ud835\udc5e\ud835\udc5e=\ud835\udefc\ud835\udefc\ud835\udc5c\ud835\udc5c[\ud835\udc5e\ud835\udc5e]+\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e]+\ud835\udf02\ud835\udf02\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]+\ud835\udf06\ud835\udf06\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e],\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]\ud835\udc61\ud835\udc61[\ud835\udc5e\ud835\udc5e]+\ud835\udf16\ud835\udf16\ud835\udc5e\ud835\udc5e, (3)\nwhere the dependent variable \ud835\udc66\ud835\udc66\ud835\udc5e\ud835\udc5eequals 1 if the quotative used in the\nquote \ud835\udc5e\ud835\udc5eis nonobjective and 0 otherwise, \ud835\udefc\ud835\udefc\ud835\udc5c\ud835\udc5c[\ud835\udc5e\ud835\udc5e],\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e], and \ud835\udf02\ud835\udf02\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]are\noutlet, category, and party-level intercepts, and \ud835\udf06\ud835\udf06\ud835\udc4f\ud835\udc4f[\ud835\udc5e\ud835\udc5e],\ud835\udc5d\ud835\udc5d[\ud835\udc5e\ud835\udc5e]is the trend\nin usage of nonobjective quotatives for each party/bias category\ncombination.\nFor each media bias category, we depict the difference in the\ntrends of nonobjective quotative usage for Democrats and Republi-\ncans in Figure 7. For left and centrist outlets, the gap between how\nnonobjective quotatives are used to quote Democrats and Republi-\ncans is increasing in the study period. These increases are statistically\nsignificant and substantial compared to the existing level of quotative\nbias observed in our data. For example, the estimated contrast of the\ntrend is around 0.33% for left-center outlets, and the existing quo-\ntative bias is 1.08%. Thus, the annual relative increase of quotative\nbias is above 30%. Left outlets exhibit the most increase in quotative\nbias in absolute terms, at 0.5% per year. For right outlets, we find\nthis difference in trends leans towards Republicans, but the effect is\nnot statistically significant.\n4 DISCUSSION\nIn this work, we analyzed quotatives to study political journalism and\nsought to answer the following two questions: How has the usage of\nnonobjective quotatives evolved in U.S. political journalism (RQ1)?\nHow do news outlets use nonobjective quotatives when covering\npoliticians of different parties (RQ2)? To answer these questions,\nwe proposed a method to automatically identify quotatives for direct\nquotes using dependency parsing. We then extracted quotatives from\na large dataset of speaker-attributed quotes, resulting in over 6.7\nmillion quotes over eight years, from 2013 to 2020. By counting\nthe usage of objective and nonobjective quotatives, we analyzed the\nstatic and dynamic trends of quotative usage.We find that the more partisan outlets use more nonobjective quo-\ntatives (Figure 2). However, during the study period, centrist outlets\n(classified as least-biased, left-center, and right-center by MB/FC)\nexperienced a significant increase in the usage of nonobjective quo-\ntatives, suggesting that they may be \u201ccatching up\u201d to the more biased\noutlets (Figure 5). We further observe that outlets tend to use more\nnonobjective quotatives when covering politicians of the opposing\nideology, thereby exhibiting \u201cquotative bias\u201d (Figure 6). Last, we\nfind a rapid increase in quotative bias for most outlet categories\nover time, which may indicate that U.S. political news is becoming\nincreasingly polarized (Figure 7).\nThese findings suggest that two simultaneous processes are at\nplay: outlets are adopting more nonobjective quotatives overall and\nthe usage of nonobjective quotatives is increasingly \u201cmediated\u201d by\nthe party affiliation of quoted politicians. Both processes indicate\na measurable decrease in journalistic objectivity. While detecting\nbias often requires some level of human judgment to determine\nneutrality, and while it is debatable how a neutral or balanced view\ncan be presented in any specific context, quotative usage can be\nregarded as an easily quantifiable form of bias due to its prominence\nwithin journalism. There are clear and established rules for the\nusage of quotes on which journalists have historically agreed, as\nis evident from textbooks [ 8,26,30] and editorial guidelines [ 29,\n35]. Although objective journalism is a 20th-century invention and\ncould be considered an anomaly throughout journalism history, it\nis commonly regarded as central to today\u2019s democratic process. In\nthat context, our results indicate a decrease in the level of objective\nquotative usage in U.S. politics news coverage, which can be seen\nas a devolution of journalism as a profession.\nThe ways in which the observed increase in nonobjective quota-\ntives relates to broader trends in U.S. politics and the news ecosystem\nremains unclear. On the one hand, the observed trend may merely\nreflect the reality of the news business. As newspapers struggle to\nretain subscribers and attract clicks [ 36], outlets (including the least-\nbiased ones) may have succumbed to nonobjective quotatives as\nthey adapt to the fast-paced style of Web-first publishing and try\nto produce engaging content. Alternatively, journalists themselves\nmay simply be subject to trends of increasing polarization in the\ngeneral public [ 1], becoming more prone to Freudian slips when\nreporting the speech of politicians they (dis)like. On the other hand,\nthe increase in quotative bias may influence people\u2019s opinions about\npoliticians [ 12] or erode the reader\u2019s trust in the media outlet, as they\nmight disagree with the opinions subtly embedded in the news piece\nby the writer [18].\nREFERENCES\n[1]Alan I. Abramowitz and Kyle L. Saunders. 2008. Is Polarization a Myth? The\nJournal of Politics 70, 2 (2008), 542\u2013555.\n[2]Peter Beharrell, Howard Davis, John Eldridge, John Hewitt, Jean Hart, Gregg\nPhilo, Paul Walton, and Brian Winston. 2009. More Bad News (Routledge Re-\nvivals). Routledge.\n[3]Allan Bell. 1991. The Language of News Media. Wiley-Blackwell.\n[4]Dan Bernhardt, Stefan Krasa, and Mattias Polborn. 2008. Political Polarization\nand the Electoral Effects of Media Bias. Journal of Public Economics 92, 5\n(2008), 1092\u20131104.\n[5]Marianne Bertrand, Esther Duflo, and Sendhil Mullainathan. 2004. How Much\nShould We Trust Differences-in-differences Estimates? The Quarterly Journal of\nEconomics 119, 1 (2004), 249\u2013275.\n[6]Sandrine Boudana. 2011. A Definition of Journalistic Objectivity as a Perfor-\nmance. Media, Culture & Society 33, 3 (2011), 385\u2013398.\n28\nTiancheng Hu, Manoel Horta Ribeiro, Robert West, and Andreas Spitz\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22123 \u22122 \u22121 0 1 2 3\nDemocratic \u2212 Republican\nPercentage nonobjective quotative (\u03c3)\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\nFigure 6: Difference in nonobjective quotative usage between\nDemocratic and Republican speakers. All estimates are sig-\nnificant. Reported differences correspond to the contrasts\n\ud835\udf0e\ud835\udf0edemocratic \u2212\ud835\udf0e\ud835\udf0erepublican in Eq. (2)(in percentage points).\nLeft\nLeft\u2212Center\nLeast\u2212Biased\nRight\u2212Center\nRight\n\u22120.5 \u22120.25 0 0.25 0.5\nDemocratic \u2212 Republican\nPercentage rate of change (\u03bb)\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\nFigure 7: Difference in percentage yearly rate of change of\nnonobjective quotative usage between Democratic and Repub-\nlican speakers for each media outlet category. A solid circle\ndenotes a significant effect (p<0.05) and a hollow circle denotes\nan insignificant effect. Reported trends correspond to the con-\ntrasts \ud835\udf06\ud835\udf06democratic \u2212\ud835\udf06\ud835\udf06republican in Eq. (3)(in percentage points).\n[7]Megan Brenan. 2022. Media Confidence Ratings at Record Lows. Gallup (2022).\n[8]Brian S Brooks, George Kennedy, Daryl R Moen, and Don Ranly. 2007. News\nReporting and Writing. Macmillan.\n[9]Andrew Calcutt and Philip Hammond. 2011. Journalism Studies: A Critical\nIntroduction. Routledge.\n[10] Carmen Rosa Caldas-Coulthard. 1992. Reporting Speech in Narrative Discourse:\nStylistic and Ideological Implications. Ilha do Desterro A Journal of English\nLanguage, Literatures in English and Cultural Studies 27 (1992), 067\u2013082.\n[11] A Colin Cameron and Douglas L Miller. 2015. A Practitioner\u2019s Guide to Cluster-\nrobust Inference. Journal of Human Resources 50, 2 (2015), 317\u2013372.\n[12] Richard R. Cole and Donald Lewis Shaw. 1974. \u2019Powerful\u2019 Verbs and \u2019Body\nLanguage\u2019: Does the Reader Notice? Journalism Quarterly 51, 1 (1974), 62\u201366.[13] Dave D\u2019Alessio and Mike Allen. 2006. Media Bias in Presidential Elections: A\nMeta-Analysis. Journal of Communication 50, 4 (2006), 133\u2013156.\n[14] Stefano DellaVigna and Ethan Kaplan. 2007. The Fox News Effect: Media Bias\nand Voting. The Quarterly Journal of Economics 122, 3 (2007), 1187\u20131234.\n[15] Graham N. Dixon and Christopher E. Clarke. 2013. Heightening Uncertainty\nAround Certain Science: Media Coverage, False Balance, and the Autism-Vaccine\nControversy. Science Communication 35, 3 (2013).\n[16] Carroll Doherty, JTAJB Kiley, A Tyson, and B Johnson. 2019. Public highly\ncritical of state of political discourse in the US Pew Research Center. (2019).\n[17] Elisabeth Gidengil and Joanna Everitt. 2003. Talking Tough: Gender and Reported\nSpeech in Campaign News Coverage. Political Communication 20, 3 (2003),\n209\u2013232.\n[18] Albert C. Gunther. 1992. Biased Press or Biased Public? Attitudes Toward Media\nCoverage of Social Groups. The Public Opinion Quarterly 56, 2 (1992).\n[19] David Ingram and Peter Henshall. 2012. The News Manual. Vol. 1. Chapter 8.\n[20] Dan Jurafsky and James H Martin. 2022. Speech and Language Processing (3rd\ned. draft ed.). online.\n[21] Kim Fridkin Kahn and Patrick J Kenney. 2002. The Slant of the News: How\nEditorial Endorsements Influence Campaign Coverage and Citizens\u2019 Views of\nCandidates. American Political Science Review 96, 2 (2002), 381\u2013394.\n[22] Sandra K\u00fcbler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing.\nSynthesis Lectures on Human Language Technologies 1, 1 (2009), 1\u2013127.\n[23] Jonathan K\u00fclz, Andreas Spitz, Ahmad Abu-Akel, Stephan G\u00fcnnemann, and\nRobert West. 2022. United States Politicians\u2019 Tone Became More Negative with\n2016 Primary Campaigns. CoRR abs/2207.08112 (2022). arXiv:2207.08112\n[24] Gunho Lee. 2017. Verb Objectivity and Source Qualification: Comparison of\nQuotation Attributions in Offline and Online Newspapers. Journalism 18, 7\n(2017), 890\u2013906.\n[25] Brian McNair. 2017. After Objectivity? Journalism Studies 18, 10 (2017).\n[26] Melvin Mencher and Wendy P Shilton. 1997. News Reporting and Writing. Brown\n& Benchmark Publishers.\n[27] Amy Mitchell, Katie Simmons, Katerina Eva Matsa, and Laura Silver. 2018.\nPublics Globally Want Unbiased News Coverage, but are Divided on Whether\nTheir News Media Deliver. (2018).\n[28] Michael O\u2019Connell. 1999. Is Irish Public Opinion towards Crime Distorted by\nMedia Bias? European Journal of Communication 14, 2 (1999), 191\u2013212.\n[29] Reuters. 2008. Reuters Handbook of Journalism. https://www.trust.org/\ncontentAsset/raw-data/652966ab-c90b-4252-b4a5-db8ed1d438ce/file.\n[30] Carole Rich. 2015. Writing and Reporting News: A Coaching Method. Cengage\nLearning.\n[31] Michael Ryan. 2001. Journalistic Ethics, Objectivity, Existential Journalism,\nStandpoint Epistemology, and Public Journalism. Journal of Mass Media Ethics\n16, 1 (2001), 3\u201322.\n[32] Michael Schudson. 1981. Discovering the News: A Social History of American\nNewspapers.\n[33] Kenji Sonoda. 1997. Subject-verb Inversion Before a Quotation in the Media\nDiscourse. Current English Studies 1997, 36 (1997).\n[34] Maija Stenvall. 2008. On Emotions and the Journalistic Ideals of Factuality and\nObjectivity\u2014Tools for Analysis. Journal of Pragmatics 40, 9 (2008), 1569\u20131586.\n[35] The Associated Press. 2020. The Associated Press Stylebook: 2020-2022 . Basic\nBooks.\n[36] Neil Thurman, Seth C. Lewis, and Jessica Kunert. 2019. Algorithms, Automation,\nand News. Digital Journalism 7, 8 (2019), 980\u2013992.\n[37] Teun A Van Dijk. 1988. News as Discourse. Lawrence Erlbaum Associates.\n[38] Timot\u00e9 Vaucher, Andreas Spitz, Michele Catasta, and Robert West. 2021. Quote-\nbank: A Corpus of Quotations from a Decade of News. In The Fourteenth ACM\nInternational Conference on Web Search and Data Mining, WSDM\u201921. ACM.\n29\nDesign Thinking for Journalism in the  Age of AI\u2217\u2217 \nTowards an Innova,on Process for Responsible AI Applica,ons \nRoxana\tPortugal\u2020,\tBartosz\tWilczek,\tMaximilian\tEder,\tNeil\tThurman,\tMario\tHaim\t\n\tDepartment\t of\tMedia\tand\tCommunication ,\tLMU\tMunich \t\n\tMunich,\tBavaria, \tGermany\t\n\t{roxana.portugal,\tbartosz.wilczek,\tmaximilian.eder,\tneil.thurman,\tmario.haim}@ iFkw.lmu.de\t\nABSTRACT \t\nArtificial\tIntelligence\t(AI)\ttechnologies\toffer\topportunities\tfor\t\nnews\t organizations\t to\t become\t more\t efficient.\t At\t the\t same\t\ntime,\t the\t adoption\t of\t AI\t in\t journalism\t raises\t concerns,\t\nincluding\twhether\tsuch\tefficiency -driven\t AI\t applications\t will\t\nendanger\t the\t democratic\t function\t of\t news\t organizations.\t In\t\nthis\t paper,\t we\t present\t a\t Design\t Thinking\t (DT)\t process\t that\t\ndraws\t on\t co -creation\t with\t journalists, \taims\t to \tbalance\t\nefficiency\tand\tquality\tstandards ,\tand\tprototypes\t a\tresponsible\t\nAI\t application\t for\t journalism.\t We\t conceptualized \tthe\t DT\t\nprocess\tbased\ton\tinterdisciplinary\tliterature\tand\ttested\tit\t in\ta\t\nproject\t with\t journalism\t students \tfrom\t a\t leading\t German\t\njournalism\tschool. \t\nCCS\tCONCEPTS\t\n\u2022\tGeneral\t and\t references\t \u279d\u279d  Cross -computing\t tools\t and\t\ntechniques\t \u279d\u279d  Design\t\nKEYWORDS\t\nArtiGicial\t Intelligence,\t EfGiciency ,\tQuality ,\tJournalism,\t Design\t\nThinking \t\n1 Introduction \t\nThe\tuse\tof\tArtificial\tIntelligence\t(AI)\t for\tscalable\tproducts\t has\t\nincreased\t along\twith\tthe\tgrowth\tin\t computing\tpower\tand\tdata\t\navailability.\tThis \talso\tapplies\tin\tjournalism,\twhere\tAI\thas\tbeen\t\ndescribed\t as\t \u201can\t umbrella\t term\t for\t a\t range\t of\t technologies\u201d\t\n[9:1914] \tthat\t draw\t on\t rule- based\t systems\t and\t machine\t\nlearning.\tIn\tpart\tdue\tto\tthe\teconomic\tchallenges\tthey\tface,\t68\t\npercent\t of\t the\t news\t organizations\t inve stigated\t by\t Beckett\t\n[6:32] \thave\t started\t to\t adopt\t AI\t to\t make\t journalists\u2019\t work\t\nmore\tefficient,\tand\t20\tpercent\tname\tAI\tas\ta\ttool\tto\timprove\t\ntheir\tbusiness\tmodels.\tNews\torganizations\thave\texplored\tthe\t\npotential\tof\tAI\tthroughout\tall\tstages\tof\tthe\tnews\tvalue\tch ain\t\n[10,35] ,\te.g.,\t to\t monitor\t events,\t check\t facts,\t create\t content,\t\nrecommend\tnews,\tand\toptimize\tpaywalls.\t \tAt\t the\t same\t time,\t however,\t the\t adoption\t of\t AI\t in\t\njournalism\traises\tconcerns,\tincluding\twhether\tsuch\tefficiency -\ndriven\tAI\tapplications\twill\tendanger\tt he\tdemocratic\tfunction\t\nof\t news\t organizations\t [5,13] ,\t which\t involves\t securing\t \u201cthe\t\nquality\t of\t public\t discourse\u201d\t [16:193] .\t For\t instance,\t D\u00f6rr,\t\nK\u00f6berer\t and\t Haim\t [12]\targue\t for\t more\t accountability\t and\t\ntransparency\t regarding \tthe\t AI -based\t production\t of\t\njournalis tic\t content.\t Regarding\t the\t personalized\t distribution\t\nof\tjournalistic\tcontent,\tHelberger,\tKarppinen,\tand\tMakhortykh\t\n[16]\tstate\t that\t AI\t applications\t should\t present\t users\t with\t\ncontent\t diversity\t to\t prevent\t the\t formation\t of\t possible\t filter\t\nbubbles. \tAccordingly, \tAI\tapplications\tin\tjournalism\tshould\tnot\t\nonly\t be\t responsible\t for\t increasing\t the\t efficiency\t of\t news\t\norganizations\t but\t also\t adhere\t to\t journalistic\t quality\t\nstandards.\t However,\t while\t the\t implementation\t of\t efficiency\t\nand\t quality\t standards\t may\t lead\t to\t trade -offs\t[34],\t research\t\nand\t best\t practice\t guidelines\t on\t how\t news\t organizations\t can\t\nbalance\tefficiency\tand\tquality\tstandards\tand,\tthereby,\tdevelop\t\nresponsible\t AI\t applications,\t remain\t scarce\t (e.g.,\t\n[4,15,21,27,31] .\t\t\nMoreover,\t technology\t providers\t without\t dedicated\t\njournalistic\t roots\t are\t increasingly\t shaping\t how\t AI\t is\t used\t in\t\njournalism\t [28].\t Due\t to\t this\t external\t dependency,\t we\t argue\t\nthat\tthere\tis\tan\turgent\tneed\tfor\tmore\tuser -centric\tapproaches\t\nthat\t involve\t journalists\t in\t the\t co -creation\t of\t AI\t applications\t\n[2,11,19,3 0].\tMethodologically,\twe\targue\tthat\tDesign\tThinking\t\n(DT)\toffers\tsuch\tan\tapproach.\tAfter\tall,\tDT\tallows\tfor\ta\thuman -\ncentric\t perspective\t on\t complex\t problems\t [3]\tand\t helps\t\norganizations\t with\t their\t innovation\t processes\t [26],\t not\t least\t\nin\tthe\trealm\tof\tAI -driven \tinnovation\t [33].\t\nAgainst\t this\t background ,\twe\t present\t a\t DT\t process\t\n(Fig.\t1)\t that\tdraws\ton\tco- creation\twith\tjournalists\tand\taims\tto\t\nbalance\tefficiency\tand\tquality\tstandards\tduring\tthe\tinnovation\t\nof\t AI\t applications\t in\t news\t organizations.\t We\t conceptualized\t\nthe\t DT\t process\t based\t on\t literature\t from\t computer\t science,\t\njournalism\t studies,\t and\t DT.\t We\t tested\t it\t in\ta\t project\t with\t\njournalism \tstudents \t(overall:\t N\t=\t15)\t from\ta\tleading\tGerman\t\njournalism\t school\t between\t December\t 2022\t and\t February\t\n2023.\t More\tspecifically,\tt his\tproject\t aimed\tto\tdevelop\ta\tlow -\nfidelity\t prototype\t of\t a\t responsible\t AI\t application\t for\t local\t\njournalism.\tAfter\tall,\ta\tsignificant\tchallenge\tfacing\tjournalism\t\ntoday\t lies\t in\t the\t collapse\t of\t local\t news\t provision\t [32]\t with\t\npotentially\t severe\t consequences\t for\t local\t communitie s\t and,\t\nmore\tbroadly\tfor\tdemocratic\tsocieties\t[22]. \t\n \u2217Design\tThinking\tfor\tJournalism\tin\tthe\t Age\tof\tAI\t\n\u2020Corresponding\tauthor \t\nPermission\t to\t make\t digital\t or\t hard\t copies\t of\t part\t or\t all\t of\t this\t work\t for\t\npersonal\tor\tclassroom\tuse\tis\tgranted\twithout\tfee\tprovided\tthat\tcopies \tare\tnot\t\nmade\tor\tdistributed\tfor\tprofit\tor\tcommercial\tadvantage\tand\tthat\tcopies\tbear\t\nthis\tnotice\tand\tthe\tfull\tcitation\ton\tthe\tfirst\tpage.\tCopyrights\tfor\tthird- party\t\ncomponents\t of\t this\t work\t must\t be\t honored.\t For\t all\t other\t uses,\t contact\t the\t\nowner/author(s). \t\nC+J\t\u2022 DATAJ Conference ,\tJune,\t2023,\tZurich ,\tSwitzerland \t\n\u00a9\t2023\tCopyright\theld\tby\tthe\towner/author(s). \t\n30\n\t\nFigure\t1.\t\tDT\tprocess\t to\tdesign\ta\t responsible\tAI\tapplication\t in\tjournalism \t(images\tproduced\twith\tDALL -E).\nThe\trest\tof\tthis \tpaper\tis\tstructured\tas\tfollows:\tsection\t2\t\nsummarizes\t the\tDT\tprocess\t we\tdeveloped\t and\t assessed ;\t\nsection\t3\tpresents\trelated\twork\tand\tcompares\tit\twith\tour\tDT\t\nprocess;\tsection\t4\t presents\t conclusions. \t\n2 DT\tprocess\tfor\t responsible\tAI \t\nOur\t innovation\t process\t for\t responsible\t AI \t(Fig.\t 1) \tdraws\t on\t\nthe\t widely\t applied\t DT\t approach\t developed\t by\t the\t Stanford\t\nDesign\t School\t [20:313] .\tTo\tadapt\t this\t approach\t to\t our\t\njournalistic\t use\t case,\t we\t incorporated\t software\t engineering\t\ntechniques,\tparticularly\tfrom\trequirements\tengineering \t(RE),\t\nthat\taim\tto\tidentify\tuser\tneeds\tnot\tonly\tfrom\ta\tfunctional\tbut\t\nalso\t from\t a\t qualitative\t p oint\t of\t view,\t i.e.,\tqualit y\t standards\t\nshould\tbe\tamalgamated\tinto\t the\tsoftware\tproduction\t [25].\t\t\nFurthermore,\t RE\ttechniques\talso\tbring\tnecessary\ttrade -\noffs\u2014which\t often\t show\t up\t when\t implementing\t quality\t\nstandards\t [8]\u2014to\t light\t early\t in\t the\t design\t process.\t For \t\ninstance,\tthe\timplementation\tof\tmore\ttransparency\tmay\tresult\t\nin\t less\t privacy.\t Early\t detection\t of\t this\t trade -off\t would\t allow\t\nmitigation,\tsuch\tas\timplementing\tstricter\tprivacy\tregulations\t\nin\tother\tparts\tof\tthe\tproposed\tsoftware .\t\nIn\t the\t next\t sections ,\t we\t present\t the\t DT\t steps\t in\t more\t\ndetail. \t\n2.1  Empathize \nFor\t the\t first\t DT\t step, \t\u201cempathize\u201d,\t an\t online\t survey\t was\t\nconducted\t to\t identify\t the\t most\t relevant\t problem\t area\t along\t\nthe\t news\t value\t chain\t in\t local\t journalism.\t Participants\t were\t\nasked\t to\t identify\t activities \twhere\t economic\t pressure,\t time\t\nconstraints,\t and/or\t the\t need\t to\t meet\t specific\t quality\t\nstandards\t affect\t local\t journalists\t the\t most.\t Based\t on\t this\t\nsurvey \t(provided\tupon\trequest ),\ttime\tconstraints\tregarding\t\nvideo\tcreation  were\tidentified\tas\tthe\tmost\trelevant\tp roblem\t\narea.\t All\t but\t one\t of\t the\t subsequent\t DT\t steps \u2014i.e.,\t\u201cproblem\t\ndefinition\u201d,\t \u201cquality\t standards\t definition\u201d,\t \u201cideation\u201d,\t and\t\n\u201ctest\u201d \u2014were\tconducted\tvia\tin -person\tworkshops\tto\tfacilitate\t\ncollaboration\tand\tco -creation\tamong\tthe\tparticipants.\tThe\tDT\t\nprototy ping\t step \twas,\t however,\t undertaken\t by\t the\t authors\t\nwithout\t the\t involvement\t of\t the\t participants ,\t as\t the\tparticipants\t had\t only\t limited\t expertise\t regarding\t existing\t AI\t\napplications .\t\n2.2  Problem definition \nThe\tgoal\tof\tthis\tworkshop\t (n\t=\t14\tparticipants)\t was\tto\tobtain\t\nmeaningful\tand\tactionable\tproblem\tstatements\tregarding\ttime\t\nconstraints\t during\t video\tcreation.\tFor\tthat\tpurpose,\tproblem\t\nexample\t cards\t were\t created\t to\t speed\t up\t the\t acquisition\t or\t\nrecall\tof\tknowledge\t(Fig.\t 2).\tParticipant s\twere\tasked\tto\tdefine\t\nthe\tcore\tproblem\tin\ttwo\tsteps.\tFirst,\tthey\twere\tasked\tto\tselect\t\nthe\tthree\tmost\trelevant\tproblems\tpresented\t from\tthe\texample\t\ncards\tand\tto\tsuggest\tfurther\tproblems\tthemselves \t(left\tpart\tin\t\nFig.\t 3) .\t Second,\t based\t on \tthis\t selection,\t they \twere\t asked\t to\t\ndefine\t the\t core\t problem.\t As\t Fig.\t 3\tshows,\ttime\tconstraints\t\nregarding\t editing\t and\t assembling\t video\t footage\t into\t a\t\nfinished\tproduct \twere\tidentified\tas\tthe\tcore\tproblem. \t\n\t\nFigure\t2.\tCards\twith\texamples\trelated\tto\tvideo\t creation.\t\nNext,\tparticipants\twere\tasked\tto\tspecify\tfactors\tthat\tlead\t\nto\tthis\tcore\tproblem.\tFor\tthat\tpurpose,\tthe\ttriangle\ttechnique\t\n[18]\twas\tapplied.\tIt\tvisualizes\tthe\tproblem\tdefinition\tthrough\t\na\t triangular\t center,\t the\t core\t problems \ton\t the\t left,\t and\t the\t\nfactors\tleading\tto\t the\tcore\tproblem s\ton\tthe\tright\t(Fig.\t 3).\t\n\t\t\t \t\nFigure\t3.\tTriangle\ttechnique\tfor\tdefining\tthe\tproblem. \t\n31\nC+J \u2022 DATAJ , June, 20 23, Zurich,  Switzerland R. Portugal  et al.  \n\t\n \n 2.3  Quality standards definition \nThe\t goal\t of\t the\t next\t workshop\t (n\t =\t 10\t participants)\t was\tto\t\nidentify \trelevant\tjournalistic\tquality\tstandards\tfor\tediting\tand\t\nassembling\tvideo\tfootage\tinto\ta\tfinished\tproduct.\tTo\tfacilitate\t\na\t discussion\t regarding\t possible\t trade- offs,\t quality\t standards\t\nwere\t assigned \tto\tpossible\tfunctionalities\tof\tthe\tAI\tapplication. \t\n\t\nFigure\t4.\tQuality\tstandards\tcards\trelated\tto\tproblem\t\nfactors.\t\nFor\tthat\tpurpose,\tcards\twere\tcreated\twhere\tquality\tstandards\t\nwere\tlinked\tto\tproblem\tfactors\t(Fig.\t 4).\tThe\tquality\ts tandards\t\nwere\t determined\t based\t on\t the\t Code\t of\t the\t German\t Press\t\nCouncil\tas\twell\tas\tliterature\ton\tjournalistic\tquality. \t\nWith\t the\t back\t of\t the\t cards\t indicating\t only\t the\t quality\t\nstandards\t and\t using\t the\t Non -Functional\t Requirement s\t\nframework\t [8],\t participants\t wer e\t instructed\t to\t model\t\ncorresponding\trelationships.\tFig.\t 5\tshows\tan\texample\tof\tsuch\t\na\t model.\t A\t\u201c+\u201d\t indicates\t a\t positive \tcontribution \trelationship \t\nbetween\t quality\t standards ,\t while \ta\t \u201c\u2013\u201d\t indicates\t a \tnegative\t\ncontribution\tor \tconflict. \t\n\t\nFigure\t5.\tModeling\ttrade- offs\tbetween\tquality\tstandards \t\n2.4  Ideation \nThe\t goal\t of\t this\t workshop\t (n\t =\t 13\t participants)\t was\t to\t co -\ncreate\t the\t core\t idea\t of\t the\t prototype.\t For\t that\t purpose,\t\nparticipants\twere\tpresented\t with\t existing\tAI\tapplications\tfor\t\nvideo\tcreation,\twhich \tfacilitate d\tthe\tideation\tof\tan\tinnovative\t\nAI\t application.\t Subsequently,\t using\t resources\t from\t earlier\t\nworkshops\t (e.g.,\t problem\t factors,\t here\t con ceptualized\t as\t\nfunctionalities,\t and\t quality\t standards) ,\tparticipants\t were\t\nasked\tto\tprepare\ta\tlogical\tsequence\tof\thow\tthe\tAI\tapplication\t\nwould\t address\t the\t problem\t identified.\t More\t specifically,\t a\t\ntimeline\t was\t created\t indicating\t which\t functionalities\t and\twhich\t corresponding\t quality\t standards\t were\tnecessary\t at\t\nwhich\tpoint\tin\tthe\tideated\tAI\tapplication\t(Fig.\t 6).\t\n\t\nFigure\t6.\tTechnique\tfor\tideating\tthe\tprototype .\t\n2.5  Prototype \nThe\t DT\t process\t facilitated\t the\t prototyping\t of\t the\t AI\t\napplication\t in\t different\t ways \t[37].\tFirst,\t the\t problem\t factors\t\nwere\t transformed\t into\t functionalities\t of\t the\t AI \tapplication. \t\nSecond,\t the\t logical\t order\t of\t features\t was\t given\t by\t the\t\nparticipants\t to\thelp\t define \tthe\tinputs\t and\t outputs\t that\t are\t\nrequired\t by\t the\t e nvisioned\t AI\t application.\t Third,\t\nfunctionalities\t were\t\nmapped\t to\t quality\t\nstandards\t to\t support\t the\t\nselection\t of\t corresponding\t\ntechnologies .\t\t\nFrom \t these\t\ncontributions ,\t the\t authors \t\ncompiled\t a\t low -fidelity\t\nprototype\t using\t mock -up\t\nand\t sketching\t techniques\t\nfor\t each\t of\t the\t proposed \t\nfunctions .\t Fig.\t 7\tshows\t the\t\nresulting\t prototype\t for\t the\t\nfootage\t selection\t function.\t\nPrototypes\tfor\tall\t functions \t\nof\t the\t AI\t app lication\tare\t\navailable\t in\t GitHub\t and\t\nZenodo\t [37].\t\n2.6  Test \nThe\tgoal\tof\tthe\tlast\tworkshop\twas\tto\tdetermine\t whether\tthe\t\ndeveloped\t prototype\t met\tthe\tparticipants\u2019 \trequirements.\tThe\t\nworkshop\t consisted\t of\t two\t steps.\t First,\t participants\t were\t\nasked\tto\tassess\tthe\tprototype\tregarding\tits\tfunctionalities\tand\t\nquality\t standards.\t Second,\t participants\t suggested\t changes\t to\t\nthe\tprototype\tto\ttailor\tit\teven\tfurther\tto\tthe\toriginal ly\tdefined\t\ncore\tproblem\t(Fig.\t 8).\tBased\ton\tthis\tfeedback,\tthe\tprototype\t\nwas\t refined.\t Th e\ttesting\t was\t iterated\t twice , \to n c e \ti n -person\t\nduring\t the\t workshop \t(n\t =\t 9\t participants) ,\t and\t once\t digitally\t\nvia\ta\tshared\tonline\tdocument \t(n\t=\t7\tparticipants) .\t\nFigure\t7.\tPrototype\tof\tthe\t\nfeature\t\u201cfootage\tselection\u201d . \n32\nDesign Thinking for journalism in the AI age C+J \u2022 DATAJ , June, 20 23, Zurich, Switzerland \n\t\n \t\nFigure\t8.\tTesting\tthe\tprototype\tusing\tthe\twhiteboard \t\n3 Embedding\tinto\trelated\twork \t\nHalskov\tand\tLundqvist\t [14]\thave\tused\tdomain\tand\ttechnology\t\ninspiration\t cards\t to\t accelerate\t knowledge\t gathering\t and\t\nsimplify\tDT\tworkshops.\tThis\tpractice\thas\tbeen \talso\tapplied\tby \t\nAI\tdevelopers\tsuch\tas\tNexocode \t[23].\tIn\tour\tDT\tprocess,\twe\t\nused\t cards\t not\t only\t to\t speed\t up\t the\t process\t but\t also\t to\t\nfacilitate\t collaboration\t and\t co -creation\t among\t participants\t\nduring\tthe\tworkshops.\tSinders\tand\tAhmad\t [29]\tapplied\ta\tDT\t\napproa ch\tthat\tmoves\tfrom\tgeneral\tto\tmore\tspecific\tquestions,\t\nthereby\t adding\t more\t complexity\t in\t each\t subsequent\t\nworkshop.\tOur\tDT\tprocess\tapplied\ta\tsimilar\tapproach,\tas\twe\t\nfirst\tidentified\ta\tbroad\tproblem\tand\tthen\tworked\tthrough\tthe\t\ncomplexity\t by\t gradually\t breaking\t the\t problem\t down.\t In\t\naddition,\t we \timplemented \tthe\t bottom -up\tapproach \tof\t DT\t\nduring\t the\t definition\t of\t quality\t standards,\t i.e.,\t by\t using\t the\t\nNon-Functional\tRequirement s\tframework\t [8].\t\n\t Furthermore,\tTang \t[30]\thas\tused\tDT\tto\tcollect\tas\tmany\t\nideas\tas\tpossible\twithout\tconsidering\tfeasibility\tor\trationality.\t\nWe\t agree\t with\t the\t author\t that\t free\t brainstorming\t may\t\nfacilitate\t creativity.\t However,\t we\t argue\t that\t particularly\t\nduring\t the\t prototyping\t step\t of\t the\t DT\t process\t the\t\nconsideration\t of\t feasibility\t is\tnecessary \tto\t facilitate\t the\t\nimplementation \t(i.e.,\tcoding)\tof\tthe\tprototype.\t Feasibility\tcan\t\nbe\t increased\t by\t organizing\t (i.e.,\t rationalizing)\t the\t\ncorresponding\tfunctionalities\tand\tquality\tstandards. \t\nFinally,\tespecially\tin \tcomputer\tscience,\tDT\tapproaches\t\nhave\t focused\t on\t solutions\t to\t agilize \tDT\twith\t the\t goal\t of\t\nincreasing\t its\t effectiveness\t and\t efficiency .\tFor\t instance,\t\nregarding \tthe\t preparation \tof\t a\t DT\t process,\t Parizi\t et\t al.\t [24]\t\npropose \tusing \ta\t recommendation\t system\t that\t optimizes\t the\t\nselection\tof\ttechniques\t that\tare\tused \tduring\teach\tstep\tof\t the\t\nDT\tprocess. \tMoreover,\t Ahmed\tet\tal.\t [1]\tpropose \ta\tLean\tDesign\t\nThinking\t Methodology\t (LDTM) ,\twhich\t is\t a\t data -driven\t\napproach\tto\tsupport\t problem\tdiscovery. \tBoth\tapproaches \tcan\t\nimprove\t the\tDT\t process.\t For\t instance,\t our\t selection\t of\t\ntechni ques\t was\t restricted\t by\t the\t duration\t of\t the\t workshops\t\n(the\tworkshops\tconsisted\tof\ttwo\tsprints\t of\t20\tto\t30\tminutes\t\neach).\t A\trecommendation\tsystem\tcould\tfacilitate\tthe\tselectio n\t\nof\ttechniques\tthat\tare\tsimple\tand\tyet\toptimize\tresults.\t\tA \tdata-\ndriven \tapproach,\t in\t turn,\t could\t be\t used\t in\t addition\t to\t an\t\nempathizing\t workshop\t (or\t survey) \tto\t extend\t the\t problem\t\ndiscovery.\t \t4 Conclusions\t\nWhile\t AI\t technologies\t offer\t opportunities\t for\t news\t\norganizations\tto\tbecome\tmore\tefficient,\tthe\tadoption\tof\tAI\tin \t\njournalism\t raise s\tconcerns,\t namely\t whether\t such\t efficiency -\ndriven\tAI\tapplications\twill\tendanger\tthe\tdemocratic\tfunction\t\nof\t journalism.\t Accordingly,\t we\t argue\t that\t AI\t applic ations\t in\t\njournalism\t should\t be\t responsible\t so\t that\t they\t not\t only\t\nincrease\tthe\tefficiency\tof\tnews\torganizations\tbut\talso\tadhere\t\nto\tjournalistic\tquality\tstandards. \t\nTherefore, in this paper, we present a DT process that \ndraws on co -creation with journalists and balances efficiency and \nquality standards with the goal of innovating  responsible AI \napplications in journalism.  We developed the DT process based \non interdisciplinary literature and assessed it based  on a project \nwith journalism students (overall:\t N\t =\t 15)\tfrom a leading German \njournalism school. In sum, the project developed a low -fidelity \nprototype of a responsible AI application that aims to solve a core \nproblem in local journalism, namely time constraints regarding \nediting and assembling video footag e into a finished product . \nWith its specific functionalities, the developed prototype aims to \nincrease efficiency and thereby mitigate time constraints. At the \nsame time, it incorporates journalistic quality standards.  \nJournalists are increasingly involved  in the co- creation \nof AI applications [2,11,14,19,29,30],  however, contrary to our \nDT process, these co- creation approaches  have\t not\t appl ied\t\nspecific\ttechniques\t to\taccommodate\t quality\tstandards .\ti.e.,\tthe\t\nso-called\t Non-Functional\t Requirements\t that\t software\t\nengineering \thas\tbeen\tinvestigating\tfor\tmore\tthan\t20\tyears . As \npresented in this paper, these requirements  are, however,  relevant \nfor develop ing responsible AI applications, i.e., AI applications \nthat increase journalistic efficiency and adhere to journalistic \nquality standards.  \nFinally , DT has been criticized because it may restrict \ncreativity due to its formally structured  process [17,36] . \nAccordingly,\t in\t the\t future,\t further\t techniques\t could\t be\t\nincorporated\t into\t DT. For instance, Dimitrakopoulou and Lewis \n[11] suggest merging DT with techniques that facilitate more \nreflective listening  processes to improve the empathizing step of \nthe DT process. After all, this step  is particularly important to \nengage the participants  with DT.  This is corroborated by Chaplin \n[7]. Halskov\tand\tLundqvist\t [14]\temphasize\tthe\timportance\tof\t\nusing \tdiverse\t prototyping :\tFor\t example ,\tsketches\t on\t a\t\nwhiteboard,\t digital\t 3D\t models,\t or\tscenarios,\t which\t can\t be\t\nused\tto\t further\tdefine\t the\tdesign\t space. ,\ti.e.\tto\tfind\ta\tproblem\t\nspace .\tKolko\t [17],\tin\tturn,\tproposes\tthe\tuse\tof\tlateral\tthinking,\t\nwhich\t involves\t examining\t a\t situation\t from\t different,\t also\t\nunexpected,\tperspectives. \t\nACKNOWLEDGMENTS \t\nThis\t Design\t Thinking\t project\t is\t part\t of\t our\t research \tproject\t\n\u201cTowards\tResponsible\tAI\tin\tLocal\tJournalism\u201d,\tfunded\tby\tthe\t\nVolkswagen\tFoundation .\tWe\tthank\t the\tjournalism\tstudents\tfor\t\nparticipating\tin\tthis \tDesign\tThinking\t project .\t\n33\nC+J \u2022 DATAJ , June, 20 23, Zurich,  Switzerland R. Portugal  et al.  \n\t\n \n REFERENCES \t\n[1]\t Bakhtiyar\tAhmed,\tThomas\tDannhauser ,\tand\tNada\tPhilip.\t2018.\tA\tlean\t\nDesign\tThinking\tmethodology\t(ldtm)\tfor\tmachine\tlearning\tand\tmodern\t\ndata\tprojects.\tIn\t 2018\t10th\tComputer\tScience\tand\tElectronic\tEngineering\t\n(CEEC) ,\t IEEE,\t Colchester,\t United\t Kingdom,\t 11\u2013 14.\t\nDOI:https://doi.org/10.1109/CEEC.201 8.8674234\t\n[2]\t Tanja\t Aitamurto,\t Mike\t Ananny,\t Chris\t W.\t Anderson,\t Larry\t Birnbaum,\t\nNicholas\t Diakopoulos,\t Matilda\t Hanson,\t Jessica\t Hullman,\t and\t Nick\t\nRitchie.\t2019.\tHCI\tfor\taccurate,\timpartial\tand\ttransparent\tjournalism:\t\nChallenges\t and\t solutions.\t In\t Extended\t Abstracts\t of\t the\t 2019\t CHI\t\nConference\t on\t Human\t Factors\t in\t Computing\t Systems ,\t ACM,\t Glasgow\t\nScotland\tUk.\tDOI:https://doi.org/10.1145/3290607.3299007 \t\n[3]\t John\tAlford\tand\tBrian\tW\tHead.\t2017.\tWicked\tand\tless\twicked\tproblems:\t\nA\ttypology\tand\ta\tcontingency\tframework.\t Policy\tand\tSociety\t 36,\t3\t(July\t\n2017),\t 397\u2013413.\t\nDOI:https://doi.org/10.1080/14494035.2017.1361634 \t\n[4]\t Jack\t Bandy\t and\t Nicholas\t Diakopoulos.\t 2021.\t Curating\t quality?\t How\t\nTwitter\u2019s\ttimeline\talgorithm\ttreats\tdifferent\ttypes\tof\tnews.\t Social\tMedia\t\n+\t Society \t 7,\t 3\t (July\t 2021).\t\nDOI:https://doi.org/10.1177/20563051211041648 \t\n[5]\t Mariella\t Bastian,\t Natali\t Helberger,\t and\t Mykola\t Makhortykh.\t 2021.\t\nSafeguarding\t the\t journalistic\t DNA:\t Attitudes\t towards\t the\t role\t of\t\nprofessional\tvalues\tin\talgorithmic\tnews\trecommender\tdesigns.\t Digital\t\nJournalism \t 9,\t 6\t (July\t 2021),\t 835 \u2013863.\t\nDOI:https://doi.org/10.1080/21670811.2021.1912622 \t\n[6]\t Charlie\tBeckett.\t2019.\t New\tpowers,\tnew\tresponsibilities:\tA\tglobal\tsurvey\t\nof\tjournalism\tand\tartificial\tintelligence. \tLondon\t School\t of\t Ecconomics\t\nand\tPolitical\tSc ience\t(LSE),\tLondon. \t\n[7]\t Heather\tChaplin.\t2016.\tGuide\tto\tjournalism\tand\tdesign.\t Tow\tCenter\tfor\t\nDigital\t Journalism .\t Retrieved\t from\t\nhttps://www.cjr.org/tow_center_reports/guide_to_journalism_and_des\nign.php \t\n[8]\t Lawrence\tChung,\tBrian\tA.\tNixon,\tEric\tYu,\tand\tJoh n\tMylopoulos.\t2000.\t\nNon-functional\trequirements\tin\tsoftware\tengineering .\tSpringer\tScience\t+\t\nBusines\tMedia,\tNew\tYork. \t\n[9]\t Mark\t Deuze\t and\t Charlie\t Beckett.\t 2022.\t Imagination,\t algorithms\t and\t\nnews:\t Developing\t AI\t literacy\t for\t journalism.\t Digital\tJournalism \t10,\t 10\t\n(November\t 2022),\t 1913\u20131918.\t\nDOI:https://doi.org/10.1080/21670811.2022.2119152 \t\n[10]\tNicholas\tDiakopoulos.\t2019.\t Automating\tthe\tnew s:\tHow\talgorithms\tare\t\nrewriting\tthe\tmedia .\tHarvard\tUniversity\tPress,\tCambridge. \t\n[11]\tDimitra\t Dimitrakopoulou\t and\t Seth\t C.\t Lewis.\t 2022.\t The\t generative\t\ndialogue\tframework\tand\tthe\tpursuit\tof\tbetter\tlistening\tby\tjournalists:\tA\t\ndesign -centered\t approach\t for\t more\t constructive\t conversations\t with\t\naudiences.\t Digital\t Journalism \tahead- of-print\t (May\t 2022).\t\nDOI:https://doi.org/10.1080/21670811.2022.2075415 \t\n[12]\tKonstantin\t D\u00f6rr,\t Mario\t Haim,\t and\t Nina\t K\u00f6berer.\t 2017.\t Normative\t\nQualit\u00e4tsanspr\u00fcche\t an\t algorithmischen\t Journalismu s.\t In\tGesellschaft\t\nohne\tDiskurs?\tDigitaler\tWandel\tund\tJournalismus\taus\tmedienethischer\t\nPerspektive. ,\tAlexander\tFilipovi\u0107,\tMarlis\tPrinzing\tand\tIngrid\tStapf\t(eds.).\t\nNomos,\t Baden -Baden,\t 121\u2013134.\t\nDOI:https://doi.org/10.5771/9783845279824 -121\t\n[13]\tMario\tHaim\tand\tAndreas\tGraefe.\t 2018.\tAutomatisierter\tJournalismus:\t\nAnwendungsbereiche,\tFormen\tund\tQualit\u00e4t.\tIn\t Journalismus\tim\tInternet,\t\nChristian\t Nuernbergk\t and\t Christoph\t Neuberger\t (eds.).\t Springer\t\nFachmedien\t Wiesbaden,\t Wiesbaden,\t 139 \u2013160.\t\nDOI:https://doi.org/10.1007/ 978-3-531-93284- 2_5\t\n[14]\tKim\tHalskov\tand\tCaroline\tLundqvist.\t2021.\tFiltering\tand\tinforming\tthe\t\ndesign\tspace:\tTowards\tdesign -space\tthinking.\t ACM\tTrans.\tComput. -Hum.\t\nInteract. \t 28,\t 1\t (February\t 2021),\t 1 \u201328.\t\nDOI:https://doi.org/10.1145/3434462 \t\n[15]\tNatali\tHelbe rger.\t2019.\tOn\tthe\tdemocratic\trole\tof\tnews\trecommenders.\t\nDigital\t Journalism \t7,\t 8\t (September\t 2019),\t 993\u2013 1012.\t\nDOI:https://doi.org/10.1080/21670811.2019.1623700 \t\n[16]\tNatali\tHelberger,\tKari\tKarppinen,\tand\tLucia\tD\u2019Acunto.\t 2018.\tExposure\t\ndiversity\tas\ta\tdesign\tp rinciple\tfor\trecommender\tsystems.\t Information,\t\nCommunication\t &\t Society \t21,\t 2\t (February\t 2018),\t 191\u2013 207.\t\nDOI:https://doi.org/10.1080/1369118X.2016.1271900 \t\n[17]\tJon\tKolko.\t2018.\tThe\tdivisiveness\tof\tdesign\tthinking.\t interactions \t25,\t3\t\n(April\t2018),\t28 \u201334.\tDOI:https://doi.org/10.1145/3194313 \t\n[18]\tGerd\t Macke,\t Ulrike\t Hanke,\t and\t Pauline\t Viehmann.\t 2008.\t\nHochschuldidaktik:\tlehren,\tvortragen,\tpr\u00fcfen.\t Beltz,\tWeinheim,\tBasel.\t\n[19]\tBrian\t McKernan,\t Jennifer\t Stromer -Galley,\t Ania\t Korsunska,\t Sarah\t E.\t\nBolden,\t Patr\u00edcia\t Rossini ,\t and\t Jeff\t Hemsley.\t 2022.\t A\t human -centered\t\ndesign\t approach\t to\t creating\t tools\t to\t help\t journalists\t monitor\t digital\tpolitical\tads:\tinsights\tand\tchallenges.\t Digital\tJournalism \tahead- of-print\t\n(April\t2022).\tDOI:https ://doi.org/10.1080/21670811.2022.2064321 \t\n[20]\tPietro\tMicheli,\tSarah\tJ.\tS.\tWilner,\tSabeen\tHussain\tBhatti,\tMatteo\tMura,\t\nand\t Michael\t B.\t Beverland.\t 2019.\t Doing\t design\t thinking:\t Conceptual\t\nreview,\t synthesis,\t and\t research\t agenda.\t J\tProd\tInnov\tManag \t36,\t 2\t\n(March\t 2019),\t124\u2013 148.\tDOI:https://doi.org/10.1111/jpim.12466 \t\n[21]\tCristina\t Monzer,\t Judith\t Moeller,\t Natali\t Helberger,\t and\t Sarah\t Eskens.\t\n2020.\tUser\tperspectives\ton\tthe\tnews\tpersonalisation\tprocess:\tAgency,\t\ntrust\t and\t utility\t as\t building\t blocks.\t Digital\tJournalism \t8,\t 9\t (October\t\n2020),\t 1142\u2013 1162.\t\nDOI:https://doi.org/10.1080/21670811.2020.1773291 \t\n[22]\tRagnhild\t Kristine\t Olsen,\t Victor\t Pickard,\t and\t Oscar\t Westlund.\t 2020.\t\nCommunal\t news\t work:\t COVID -19\t calls\t for\t collective\t funding\t of\t\njournalism.\t Digital\t Journalism \t8,\t 5\t (May\t 2020),\t 673\u2013 680.\t\nDOI:https://doi.org/10.1080/21670811.2020.1763186 \t\n[23]\tDorota\t Owczarek.\t 2021.\t Applying\t design\t thinking\t to\t artificial\t\nintelligence:\tWhy\tshould\tyou\tuse\tit\tin\tyour\tAI -based\tprojects?\t Nexocode .\t\nRetrieved\t from\t https://nexocode.com/blog/posts/applying- design -\nthinking -to-ai\t\n[24]\tRafael\tParizi,\tMarina\tMoreira,\tIgor\tCouto,\tSabrina\tMarczak,\tand\tTayana\t\nConte.\t 2022.\t Tool\t proposal\t for\t recommending\t design\t thinking\t\ntechniques\t in\t software\t development.\t JSERD\t 10,\t 3\t (March\t 2022).\t\nDOI:https://doi.org/10.5753/jserd.2021.1931 \t\n[25]\tRoxana\t Lisette\t Quintanilla\t Portugal,\t Luiz\t Marcio\t Cysneiros,\t and\t Julio\t\nCesar\tSampaio\tDo\tPrado\tLeite.\t 2022.\tExplainability\tin\ta\ttime\tof\tsocially\t\nresponsible\t software.\t In\t 2022\tIEEE\t30th\tInternational\tRequirements\t\nEngineering\t Conference\t (RE) ,\tIEEE,\t Melbourne,\t Australia,\t 295\u2013 301.\t\nDOI:https://doi.org/10.1109/RE54965.2022.00044 \t\n[26]\tDaniel\t Schallmo\t and\t Klaus\t Lang.\t 2020.\t Design\tThinking\terfolgreich\t\nanwenden:\tSo\tentwickeln\tSie\tin\t7\tPhasen\tkundenorientierte\tProdukte\tund\t\nDienstleistungen \t(2.,\t aktualisierte\t Auflage\t ed.).\t Springer\t Gabler,\t\nWiesbaden\t [Heidelberg].\t DOI:https://doi.org/10.1007/978 -3-658-\n28325- 4\t\n[27]\tAnna\tSchj\u00f8tt\tHansen\tand\tJannie\tM\u00f8ller\tHartley.\t 2021.\tDesigning\twhat\u2019s\t\nnews:\t An\t ethnography\t of\t a\t personalization\t algorithm\t and\t the\t data -\ndriven\t (re)assembling\t of\t the\t news.\t Digital\tJournalism \tahead- of-print\t\n(October\t 2021).\t\nDOI:https://doi.org/10.1080/21670811.2021.1988861 \t\n[28]\tFelix\t M.\t Simon.\t 2022.\t Uneasy\t bedfellows:\t AI\t in\t the\t news,\t platform\t\ncompanies\tand\tthe\tissue\tof\tjournalistic\tautonomy.\t Digital\tJournalism \t10,\t\n10\t (November\t 2022),\t 1832\u2013 1854.\t\nDOI:https://doi.org/10.1080/21670811.2022.2063150 \t\n[29]\tCaroline\t Sinders\t and\t Sana\t Ahmad.\t 2021.\t The\t labor\t behind\t the \ttools:\t\nUsing\t design\t thinking\t methods\t to\t examine\t content\t moderation\t\nsoftware.\t interactions \t28,\t 4\t (July\t 2021),\t 6 \u20138.\t\nDOI:https://doi.org/10.1145/3470492 \t\n[30]\tYingying\tTang.\t2020.\tPromoting\tuser\tadvocacy\tthrough\tdesign\tthinking\t\nin\t the\t age\t of\t automated\t writing.\t In\t Proceedings\t of\t the\t 38th\t ACM\t\nInternational\tConference\ton\tDesign\tof\tCommunication ,\tACM,\tDenton\tTX\t\nUSA,\t1\u2013 6.\tDOI:https://doi.org/10.1145/3380851.3416784 \t\n[31]\tNeil\t Thurman,\t Seth\t C.\t Lewis,\t and\t Jessica\t Kunert.\t 2019.\t Algorithms,\t\nautomation,\tand\tnews.\t Digital\tJournalism \t7,\t8\t(September\t2019),\t980 \u2013\n992.\tDOI:https://doi.org/10.1080/21670811.2019.1685395 \t\n[32]\tKarin\t Wahl -Jorgensen.\t 2019.\t The\t challenge\t of\t local\t news\t provision.\t\nJournalism \t 20,\t 1\t (January\t 2019),\t 163 \u2013166.\t\nDOI:https://doi.org/10.1177/1464884918809281 \t\n[33]\tAmanda\tJ.\tWeller.\t2019.\tDesign\tThinking\tfor\ta\tuser -centered\tapproach\t\nto\t artificial\t intelligence.\t She\tJi:\tThe\tJournal\tof\tDesign,\tEconomics,\tand\t\nInnovation \t 5,\t 4\t (2019),\t 394\u2013 396.\t\nDOI:https://doi.org/10.1016/j.sheji.201 9.11.015\t\n[34]\tJess\t Whittlestone,\t Rune\t Nyrup,\t Anna\t Alexandrova,\t and\t Stephen\t Cave.\t\n2019.\tThe\trole\tand\tlimits\tof\tprinciples\tin\tAI\tethics:\tTowards\ta\tfocus\ton\t\ntensions.\tIn\t Proceedings\tof\tthe\t2019\tAAAI/ACM\tConference\ton\tAI,\tEthics,\t\nand\t Society ,\t ACM,\t Honolulu\t HI\t USA,\t 195\u2013 200.\t\nDOI:https://doi.org/10.1145/3306618.3314289 \t\n[35]\tBartosz\tWilczek\tand\tMario\tHaim.\t2022.\tWie\tkann\tK\u00fcnstliche\tIntelligenz\t\ndie\tEffizienz\tvon\tMedienorganisationen\tsteigern?\t Medienwirtschaft \t19,\t\n4\t(2022),\t44\u2013 50.\t\n[36]\tSofie\t Willemsen,\t Tamara\t Witschg e,\t and\t Sabrina\t Sauer.\t 2021.\t\nImprovisation\tand\tentrepreneurial\tjournalism:\tReimagining\tinnovation.\t\nJournalism\t Studies \t22,\t 11\t (August\t 2021),\t 1487 \u20131503.\t\nDOI:https://doi.org/10.1080/1461670X.2021.1951618 \t\n[37]\tRoxana\t Lisette\t Quintanilla\t Portugal.\t Pilot\t prototyp es\t using\t Design\t\nThinking\t for\t the\t journalistic\t problem\t \"time\t constraints\t regarding\t\nediting\tand\tassembling\tvideo\tfootage\tinto\ta\tfinished\tproduct \".\tIn\tZenodo \t\n(a\t repository\t for\t preserving\t research\t materials)\t DOI:\t\n10.5281/zenodo.7961998. \t\n34\n35First Steps Towards a Source Recommendation Engine:\nInvestigating How Sources Are Used in News Articles\nAlexander Spangher, Jonathan May\nspangher@usc.edu\nUniv. Southern Cal., Information Sciences Institute\nLos Angeles, USAJames Youn, Nanyun Peng\nUniv. California, Los Angeles\nLos Angeles, USA\nABSTRACT\nA source-recommendation tool to surface useful sources to journal-\nists could save journalists time and diversify the breadth of sources\nconsidered. However, to build an effective service, we must under-\nstand journalists\u2019 needs: how and why sources are used today. We\ntake steps towards this goal by building effective source attribution\nmodels that can reliably extract a broad variety of sources (i.e. peo-\nple, documents, databases, etc.) from news articles based on the\nlinguistic patterns associated with their use. We construct a large an-\nnotated training dataset and show that models trained on this dataset\nout-compete previous approaches in the literature. We use these mod-\nels to audit articles from major news outlets (e.g. New York Times,\nBBC and others). We find, for instance, that on average, 50% of\nsentences in these articles have attributable sources. Finally we show\nthat there are patterns to the way sources are used in news writing\nby showing, via two experiments, that we can predict when sources\nneed to be added to a news article. We hope in future work to explain\nthese predictions, to study why different types of sources are used\ntogether, and ultimately how to recommend them for journalists.\n1 INTRODUCTION\nJournalism informs our worldviews, and articles themselves are in-\nformed by various informational sources. Sources tend to be used\ntogether in canonical ways: articles covering local crime, for in-\nstance, will likely include quotes from both a victim and a police\nofficer [ 17,20], and articles covering political debates will include\nvoices from both political parties [4].\nPatterns of source-usage beats have not previously been mod-\neled. Previous work, we show, has extracted quotes1from news\narticles [ 7,13] with high-precision but low recall. Such work can\nanalyze aggregate quote patterns across documents [ 12,21] but\nprovides little reliable insight into why sources are used together\nwithin a story. Such insights are crucial for building effective source\nrecommendation engines for journalists.\nIn this work, we take steps towards a source-recommendation\nengine by (1) providing tools to understand which information is\nattributable to sources in news articles and (2) showing that sources\nare used in a predictable way. We build, to-date, the largest annotated\ndataset, to our knowledge, of sources in news articles, with 1,304\narticles. Asource is a person, document or database which provides\ninformation directly to a journalist.2We introduce 16 categories\n1Aquote is verbatim or paraphrased information from a person or a document. Sourced\ninformation is broader and includes actions by the journalist to uncover information:\nfirst-person observations, analyses or experiments.\n2For example, the source for the following sentence in a news article:\u201c\u2018A perp walk\nwould be great\u2019, said Trump, as reported in the New York Times.\u201d would be the New\nYork Times, not Donald Trump. Sources may be named entities (e.g. \u201cLaurent Lamothe,\u201d\nin Table 1), or canonical indicators (e..g \u201cauthorities\u201d) and they are notpronouns.Sentence\nPrime Minister Laurent Lamothe announced his\nresignation. \u2190fromState ment\nThe announcement followed a corruption commis-\nsion\u2019s report. \u2190fromReport\n\u201cThere was no partisan intereference\u201d said the com-\nmission. \u2190fromQuote\nHowever, curfews were imposed in cities in anticipa-\ntion of protests. \u2190fromOrder\nIt remains to be seen whether the opposition will\ncoalesce around a new candidate.\nTable 1: Different informational sources used to compose a single\nnews article. Source attributions shown in bold. Some sources\nmay be implicit (e.g. 4th sent.) or too ambiguous (last sent.).\nInformation types used by journalists are shown on the right.\nOur central question: does this article need another source?\nof sourcing (some shown in Tables 1 and 2). We use this dataset\nto train strong models for source attribution, achieving an overall\nattribution accuracy of 83% using GPT3 6.7B.3Additionally, we\ntest numerous baselines and show that previous lexical approaches\n[7], bootstrapping [ 14], and distant-supervision [ 21] underperform.\nFinally, our work is the first to show that sources complement each\nother in two novel experiments. We hope our work leads to future\nwork analyzing types of sources used together and predicting specific\nsources needed by journalists.\n2 PROBLEM FORMULATION\nWe model a news article as a list of sentences where each sentence\ncan be attributed to zero, one or more sources. We wish to perform\ntwo tasks: (1) source attribution, where we attribute information\nin each sentence to a source and (2) source prediction, where we\npredict if a document needs another source.\n2.1 Source Attribution\nA sentence isattributable to a source if there is an explicit orimplicit4\nindication that the facts in it came from that source. A sentence is\nnotattributable if the sentence does not convey concrete facts (i.e. it\nconveys analysis, speculation, or context provided by the journalist),\nor if it cannot be determined where the facts originated. We allow for\nan expansive set of information channels to be considered (see Table\n3GPT3 sizes: https://blog.eleuther.ai/gpt3-model-sizes/\n4In some cases, a sentence\u2019s source is not mentioned in the article but can still be\ndetermined if (1) the information can only have come from a small number of commonly-\nused sources5(2) the information is based on an eye-witness account by the journalist.\n36Information Channel Num. Sentences\nNo Quote 23614\nDirect Quote 7928\nIndirect Quote 6564\nBackground/Narrative 3818\nStatement/Public Speech 3280\nPublished Work/Press Report 2730\nEmail/Social Media Post 1352\nProposal/Order/Law 896\nCourt Proceeding 540\nDirect Observation 302\nOther 610\nTable 2: Prevalence of different information channels.\n2 for some of the top channels) and design a set of 16 canonical\ninformational categories that journalists rely on.6\n2.2 Source Prediction\nOur original goal: can we effectively recommend sources to journal-\nists? would be a hopeless task if sources were combined randomly\nin news writing. One way to explore whether this is true or not is to\nask: can we predict if an article is missing sources?\nWe create two binary classification tasks to probe this question:\n(1)Ablation: Choose one source in an article. To generate POS-\nITIVE examples, remove all sentences attributable to that\nsource. To generate NEGATIVE examples, remove an equal\nnumber of sentences attributable to no source.\n(2)NewsEdits: Sample article-versions from the [ 19]NewsEdits\ncorpus, which is a corpus of news articles along with their\nupdates. Identify articles at time \ud835\udc61\ud835\udc61where the update at time\n\ud835\udc61\ud835\udc61+1either adds a source ( POSITIVE ) or does not ( NEGATIVE ).\nAblation assumes that the composition of sources in an article\nis cohesively balanced, and induces reasoning about this balance.\nNewsEdits relaxes this assumption and probes if this composition\nmight change, either due to the article\u2019s completeness, changing\nworld events that necessitate new sources, or some other factor.7\n3 CORPUS CREATION AND ANNOTATION\nWe select 1,304 articles from the NewsEdits corpus [ 19] and dedupli-\ncate across versions. We recruit two annotators to annotate sources.\nOne annotator is a trained journalist with over 4 years of experience\nworking in a major newsroom, and the other is a undergraduate assis-\ntant. The senior annotator checks and mentors the junior annotator\nuntil they have a high agreement rate. Then, they collectively anno-\ntate 1,304 articles, including 50 articles jointly. From these 50, we\ncalculate an agreement rate of more than \ud835\udf05\ud835\udf05=.82for source attribu-\ntion and \ud835\udf05\ud835\udf05=.45for quote-type categorization. Categories shown in\nTable 2 are developed early in the annotation process and expanded\nuntil a reasonable set captures all further observations. Categories\nare also refined and adjusted following conversations with experi-\nenced journalists and professors. For a full list of categories, see\nappendix. Note: we do not perform modeling on these categories in\nthe present work, but use them for illustration and evaluation.\n6These 16 categories are formulated both in conversation with journalists and after\nextensive annotation and schema expansion.\n7[19] found that many news updates were factual and tied to event changes.4 SOURCE ATTRIBUTION RESULTS\nWe split Source Attribution into two steps: detection (isthe sentence\nattributable?) and retrieval (what is that attribution?) because using\ndifferent models for each step is more effective than modeling both\njointly. Additionally, we test a number of baselines. Each baseline\nperforms detection and retrieval in one step: so, for detection evalua-\ntion comparison we simply ask whether they attributed anysource to\na sentence. Since detection is a binary classification task, F1-score\nis used to measure. We use accuracy, or retrieval with \ud835\udc58\ud835\udc58=1for\nretrieval. Shown in Table 3 is a sample of our results.\nBaseline Methods\nR1, Co-Occurrence: We identify sentences where a source co-\noccurs with verbs indicated \u201cspeaking\u201d (using a list of 538 verbs\n[15], PERSON Named Entities and specific 301 noun-phrases, e.g.\n\u201cauthorities\u201d[8]). We group entities by last name.\nR2, Governance: We expand on R1 and process using syntactic\ndependency parsing [9] to introduce additional heuristics.8\nQuootstrap:[ 14] We use a set of 1,000 lexical patterns provided\nby the authors and identify all sentences that match these.9\nQuoteBank : We match articles in our annotation set with articles\nprocessed and released by [21]. We find 139 articles.10\nDetection Methods\nSentence: We adapt a binary sentence classifier where each token\nin each sentence is embedding using the BigBird-base trans-\nformer architecture [ 22]. Tokens are combined via self attention to\nyield a sentence embedding, which is fed into a binary classification\nlayer. Thus, each sentence is independent of the others.\nFull-Doc: We use a similar architecture, but instead of embedding\ntokens in each sentence separately, we embed tokens in the whole\ndocument, then split into sentences.\nRetrieval Methods\nSequence Labeling: predicts whether each token in a document is\na source-token or not. We pass each document through a BigBird-base\nto obtain token embeddings and then use a token-level classifier.\nSpan Detection: predicts start and stop tokens of the sentence\u2019s\nsource. We use BigBird-base , and separate start/stop-token clas-\nsifiers [ 1]. We experiment with inducing decaying reward around\nstart/stop positions to reward near-misses, and expand the objective\nto induce source salience as in [6], but find no improvement.\nGeneration: We formulate retrieval as open-ended generation and\nfine-tune GPT3 models to generate source-names.11\nFor+coref variations, we evaluate approaches on articles after\nresolving all coreferences using [ 10]. For +Nones variations, we\nadditionally train our models to detect when sentences do notcontain\nsources. We use this as a further corrective to eliminate false positives\nintroduced during detection.\n8Specifically, we identify sentences where the name is an \ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b \ud835\udc5b\ud835\udc5b dependency to a\nspeaking verb governor. \ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b\ud835\udc5b \ud835\udc5b\ud835\udc5b is a grammatical part-of-speech, and a governor is a\nhigher node in a syntactic parse tree.\n9Authors created a bootstrapping algorithm to discover lexical patterns indicative of\nsourcing. The relatively small size of our dataset compared with theirs prevents us from\nusing this architecture to extract meaningful patterns from our dataset.\n10We also discard articles where QuoteBank reported quotations or context that are not\nfound in our articles, because our corpus was created from NewsEdits, so it\u2019s possible\nthat the version of the articles that we examined were different from theirs.\n11We prompts with \u201c <article>To which source can we attribute\nthe sentence <sentence>?\u201d.\n2\n37All Direct\nQuoteIndirect\nQuoteStatement/\nSpeechEmail/ So-\ncialPublished\nWork/\nPressOtherDetection\nF1 scoreRules 1 59.1 64.7 69.3 81.2 76.2 72.7 37.4\nRules 2 68.8 71.3 79.8 89.8 82.1 79.2 32.5\nQuootstrap 33.4 85.0 81.3 51.3 58.6 33.1 3.0\nSentence 87.1 91.0 98.7 94.1 92.7 85.4 61.4\nFull-Seq 88.2 92.0 98.7 96.4 89.8 86.4 65.1Retrieval\naccuracy on gold-\nlabeled sourced sentsRules 1 (+coref ) 46.4 (52.8) 47.8 (57.3) 48.4 (54.5) 43.0 (49.8) 51.7 (49.4) 37.8 (38.3) 30.2 (34.9)\nRules 2 (+coref ) 22.5 (36.6) 20.7 (31.6) 22.5 (42.0) 30.3 (56.1) 21.3 (30.3) 27.4 (32.3) 30.2 (30.2)\nQuoteBank 5.5 9.9 16.0 16.4 17.7 4.3 0.5\nSeqLabel 38.5 37.2 43.4 40.0 31.2 32.3 17.7\nSpanDetect (+coref ) 59.5 (53.6) 61.1 (51.2) 59.5 (56.8) 67.6 (60.6) 44.4 (79.0) 51.6 (54.6) 36.5 (42.6)\nGPT3 1.3B (+coref ) 78.9 (73.2) 80.9 (78.7) 86.9 (82.5) 85.0 (76.3) 71.9 (56.1) 57.9 (54.4) 38.3 (31.2)\nGPT3 6.7B 91.4 94.0 95.5 91.1 91.0 81.6 57.3Both\nacc. all\nsentsGPT3 1.3B (+Nones) 70.9 (73.1) 79.5 (82.4) 82.9 (84.8) 82.9 (85.9) 73.4 (73.4) 60.5 (61.0) 53.0 (64.5)\nGPT3 6.7B (+Nones) 80.0 (83.0) 90.4 (92.3) 90.7 (92.9) 89.9 (92.9) 91.1 ( 91.0) 78.0 (78.2) 68.9 (68.3)\nTable 3: Source Detection F1 scores (top), measured as correctly identifying source sentences, Source Retrieval accuracy (middle),\nmeasured as the % of known source-sentences that are correctly labeled, and Pipeline accuracy (bottom), measured as % of all\nsentences correctly attributed. In Both, we use the top-performing quote-detection module to identify quotes, then perform retrieval.\nTakeaway: We can attribute sources with accuracy >80%.\nGold (Train) Gold (Test) Silver\n# docs 1032 272 9051\n# sent / doc 30 67.5 27\ndoc len (chars) 3952 7885 3984\n# sources / doc 6.8 12.1 8.2\n% sents sourced 47.7% 46.9% 57.4%\n% source-sents, top 37.5% 28.1% 31.8%\n% source-sents, bot 5.9% 2.4% 6.7%\nsource entropy 1.6 2.1 1.8\n\u2207sources / version n/a n/a +2\nmost sourced sent 96th p 92th p 0th p\nTable 4: Corpus-level statistics for our training, test, and silver-\nstandard datasets. Shown are averages across the entire corpus.\nDocuments in the test set are longer than the training, but the\nmodel seems to generalize well to the silver-standard corpus,\nas statistics match. \u201cSource-sents, top\u201d and \u201cSource-sents, bot\u201d\nrefer to the % of sourced sentences attributed to the most and\nleast used sources in a story. \u201cmost sourced sent\u201d refers to the\nsentence with the most likelihood of being sourced in the docu-\nment (as a percentile of doc. length)\n4.1 Results and Discussion\nAs shown in Table 3, we find that the GPT3 6.7B retrieval model\npaired with the Full-Seq detection module in a pipeline performed\nbest, achieving an overall attribution accuracy of 83%. In the +None\nsetting, both GPT3 1.3B and 6.7B are used to identify false positives\nintroduced by the detection stage and outperform their counterparts.\nOverall, we find that resolving coreference does not improve perfor-\nmance.The poor performance of both rules-based approaches and\nQuoteBank, which also uses heuristics,12indicates that this task is\nmore complex than simple lexical cues.\n12Quotebank\u2019s algorithm condenses input data to a BERT span-classifier by (1) looking\nfor double-quotes (2) identifying candidate speakers through a lookup table.5 INSIGHTS FROM SOURCE ANALYSIS\nHaving built an attribution pipeline that performs reasonably well,\nwe wish to derive insights into how sources are used in news articles.\nWe further sample 9051 unlabeled documents from NewsEdits and\nuse our best-performing attribution model to extract all sources.\nWe ask two questions: how much an article is sourced? When do\nsources get used in the reporting and writing process? We report our\nstatistics in Table 4 (more detailed analysis in the appendix.)\nInsight #1: \u223c50% of sentences are sourced, and sources are used\nunevenly. Most articles, we find, attribute roughly half the informa-\ntion in their sentences to sources. This the percentage of sources used\nis fairly consistent between longer and shorter documents. So, as a\ndocument grows, it adds roughly an equal amount of sourced and\nunsourced content (e.g. explanations, analysis, predictions, etc.).13\nWe also find that sources are used unevenly. The most-used source in\neach article usually contributes \u223c35%of sourced sentences, whereas\nthe least-used source contributes \u223c5%. This shows a hierarchy be-\ntween major and minor sources used in reporting and suggests future\nwork analysing the differences between these sources.\nInsight #2: Sources begin and end documents, and are added\nwhile reporting. Next we examine when sources are used in the\nreporting process. We find that articles early in their publication\ncycle tend to have fewer sources, and add on average two sources\nper subsequent version. This indicates an avenue of future work:\nunderstanding which kinds of sources get added in later versions can\nhelp us recommend sources as the journalist is writing. Finally, we\nalso find, in terms of narrative structure, that journalists tend to lead\ntheir stories with sourced information: the most likely position for\n13For more details, see the appendix.\n3\n38a source is the first sentence, the least likely position is the second.\nThe second-most likely position is the end of the document.14\n6 SOURCE PREDICTION\nWe wish to examine whether there is a pattern to the way sources are\nused together in news reporting, so we design a task called source\nprediction. We outlined two approaches to this task in Section 2.2.\n6.1 Task Dataset Creation\nAblation. We take the 9051 silver-standard documents explored\nin the previous section and design three variations of this task. As\nshown in Table 4, articles tend to use sources lopsidedly: one source\nis usually primary. Thus, we design Easy (Top Source, in Table 1),\nMedium (Secondary) and Hard (Any Source) variations of our task.\nFor Easy, we choose the source with the most sentences attributed to\nit. For Medium, we randomly choose among the top 3 sources. And\nfor Hard, we randomly choose any of the sources. Then, we create\naPOSITIVE example by removing all sentences attributed to the\nchosen source, and a NEGATIVE example from the same document\nby removing an equal number of sentences not attributed to any\nsources.\nNewsEdits. We sample an additional 40,000articles from the\nNewsEdits corpora and perform attribution on them. We sample\nversions pairs that have roughly the same number of added, deleted\nand edited sentences in between versions in order to reduce possible\nconfounders, as [ 19] showed that these edit-operations were pre-\ndictable. We identify article-version pairs where 2 or more sources\nwere added between version \ud835\udc61\ud835\udc61and \ud835\udc61\ud835\udc61+1and label these as POSITIVE ,\nand 0 or 1 sources added as NEGATIVE .\n6.2 Modeling\nWe use three models: (1) FastText [ 5] for sentence classification,\n(2) A BigBird-based model: we use BigBird with self-attention for\ndocument classification, similar to [ 19].15Finally, (3) we fine-tune\nGPT3 1.3 to perform prompt-completion for binary classification.\nFor each model, we test two setups. First, we train on the vanilla\ntext of the document. Then, in the +source variants, we train by\nappending each sentence\u2019s source attribution to the end of it.16The\nsource annotations are obtained from our attribution pipeline.\nTo further make sense of our results, we train a classifier to\nidentify four reporting topics plus one general topic17. We identify\narticles in the New York Times Annotated Corpus [16] with keyword\nsets corresponding to each topic (or \u201call\u201d for Other News). Using\nthese as distant supervision, we train a FastText classifier to output\none of these 5 categories.\n14The sources might be used in for different purposes: [ 18] performed an analysis on\nnews articles\u2019 narrative structure, and found that sentences conveying the Main Idea\nlead the article while sentences conveying Evaluations orPredictions.\n15Concretely, we obtain token embeddings of the entire document, which we combine\nfor each sentence using self-attention. We contextualize each sentence embedding using\na shallow transformer architecture. We finally combine these sentence embeddings\nusing another self-attention layer to obtain a document embedding for classification. We\nutilize curriculum learning based on document length, a linear loss-decay schedule.\n16Like so: <sent 1>. SOURCE: <source 1>. <sent 2> SOURCE:\n<source 2>... <sent n> SOURCE: <source n>.\n17These four have been identified as especially socially valuable topics, or \u201cbeats,\u201d due\nto their impact on government responsiveness [3]6.3 Results and Discussion\nOur results are shown in Table 5. Overall, we find that our exper-\niments are statistically significant with t-test \ud835\udc5d\ud835\udc5d< .01. However,\nstatistical significance does not preclude confounding, and both the\nAblation and the NewsEdits setups contain possible confounders.\nIn the Ablation set up, we might be inadvertently learning stylistic\ndifferences rather than source-based differences. To address this, we\ninvestigate (1) whether lexical confounders, such as speaking verbs,\nmight be artificially removed in the ablated documents: they are\nnot18(2) whether statistically significant differences between counts\nof named entities or source signifiers (defined in Section 4) exist:\nthey do not and (3) we create secondary test sets where NEGATIVE\nisnon-ablated documents. This changes the nature of the stylistic\ndifferences between POSITIVE and NEGATIVE while not affecting\nsourcing differences19. We find that under this setting, the accuracy\nof our classifiers differs by within 3 points.\nIn the NewsEdits setup, we have taken care to balance our dataset\nalong axes where prior work have found predictability.20We balance\nfor length, version number and edit operations.\nHaving attempted to address confounding in various ways in\nboth experiments, we have more confidence in our conclusions that\nsources are chosen to complement each other. To illustrate, consider\nTable 5, where Election coverage is the most easily predictable\nacross all tasks. This might be because of efforts to include both\nleft-wing and right-wing voices. It also might be because the cast\nof characters (e.g. campaign strategists, volunteers, voters) stays\nrelatively consistent across stories.\nTwo additional findings are that (1) harder tasks yield lower ac-\ncuracies and, (2) larger GPT3-based language models generally\nperform better. Although not especially surprising, this further con-\nfirms our intuitions about what these tasks are probing. We were\nsurprised to find that, in general, adding additional information in\nboth stages of this project (i.e. coreference in the attribution stage or\nsource information in the prediction stage), did not improve the mod-\nels\u2019 performance21. We had hypothesized that the signal introduced\nwould not harm the GPT3-based models, but this was untrue. It could\nbe that the larger models are already incorporating a notion of coref-\nerence and attribution, and our method of adding this information\nchanged English grammar in a way that harmed performance.\n7 RELATED WORK\nPrior work in quote attribution has been aimed at identifying direct\nand indirect quotes in news articles. Early work explored rules-based\nmethods [ 2,11] and statistical classifiers [ 13] to attribute sources\nto quotes. More recent work has extended these ideas by using\nbootstrapping to discover new patterns [ 14] and perturbations on\nthese patterns to generalize to larger language models [ 21]. Such\nworks focuses on a narrow set of sources: namely, quotes given by\n18We use lexicons defined in our rules-based methods to measure the number of speaking\nverbs in our dataset. We find a mean of \ud835\udc5b\ud835\udc5b=[34,32]speaking verbs per document in\n\ud835\udc66\ud835\udc66=[0,1]classes in the Top case, \ud835\udc5b\ud835\udc5b=[35,34]in the Medium, and \ud835\udc5b\ud835\udc5b=[35,37]in\nHard. None of these differences are statistically significant.\n19We do not want to train on such datasets, because there are statistically significant\nlength differences and other stylistic concerns ablated and non-ablated articles.\n20For instance, [ 19] found that whether a sentence would be added or removed between\nversions could be predicted.\n21In contrast, adding source information to smaller language model, BigBird , helped\nwith harder tasks like the Medium, Hard and NewsEdits).\n4\n39Other News Disaster Elections Labor SafetyTop Sour.\nAblatedFastText (+source) 66.1 (66.0) 65.8 (64.5) 69.8 (69.8) 68.8 (68.2) 68.0 (68.0)\nBigBird (+source) 74.2 (73.9) 68.4 (69.7) 78.3 (74.9) 74.0 (73.4) 78.1 (73.4)\nGPT3 1.3B (+source) 78.3 (74.9) 75.5 (69.5) 81.5 (78.0) 72.7 (70.9) 80.0 (65.1)Secondary\nSourceFastText (+source) 57.6 (57.8) 63.2 (63.2) 60.8 (61.1) 61.0 (62.3) 63.3 (64.1)\nBigBird (+source) 63.8 (65.1) 61.8 (69.7) 63.1 (65.7) 64.3 (64.9) 61.7 (62.5)\nGPT3 1.3B (+source) 67.1 (65.4) 67.9 (65.1) 72.9 (68.0) 58.8 (65.9) 65.6 (66.7)Any\nSourceFastText (+source) 54.5 (54.8) 60.5 (59.2) 57.1 (57.6) 57.8 (56.5) 56.2 (56.2)\nBigBird (+source) 57.5 (59.4) 53.9 (55.3) 55.5 (60.6) 55.8 (60.4) 57.8 (56.2)\nGPT3 1.3B (+source) 55.0 (59.0) 53.9 (56.1) 63.6 (61.3) 63.4 (39.3) 49.0 (51.7)News\nEditsFastText (+source) 58.1 (56.8) 48.9 (55.8) 62.1 (61.9) 58.6 (61.2) 48.8 (49.6)\nBigBird (+source) 63.5 (69.4) 63.9 (65.3) 64.5 (62.6) 64.8 (60.4) 64.8 (64.2)\nGPT3 1.3B (+source) 65.0 (64.0) 63.9 (56.1) 64.6 (61.3) 62.4 (39.3) 51.0 (51.7)\nTable 5: Results for source prediction, broken into four canonical news topics and \u2018other.\u2019 The \u201cTop Source Ablated\u201d category (top\ngrouping) is our prediction task run on articles ablated by removing the source that has the most sentences, the \u201dSecondary Source\nAblated\u201d category (second grouping) is where a source contributing more than 10% of sentences is removed, and the \u201cAny Source\nAblated\u201d category (third grouping) is where any source is randomly removed. The NewsEdits task (bottom grouping) is to predict\nwhether the article at time \ud835\udc61\ud835\udc61will be added sources at time \ud835\udc61\ud835\udc61+1.Takeaway : On all of these tasks, our models were able to significantly\noutperform random, or 50% accuracy. In general, our expectations are confirmed that: (a) harder tasks yield lower-accuracy results and (b)\nmore powerful models improve performance. This indicates that there is a pattern to the way sources are included in news writing.\npeople, rather than our more expansive set of informational sources.\nSurprisingly, we observe low performance from QuoteBank, even in\ncategories it is trained to detect.\n8 CONCLUSIONS\nWe have offered a more expansive definition sourcing in journalism\nand introduced the largest attribution dataset capturing this notion.\nWe have developed strong models to identify and attribute infor-\nmation in news articles. We have used these attribution models to\ncreate a large silver standard dataset that we used to probe whether\nsource inclusion in news writing follows predictable patterns. We\nhave future work planned to identifying groups of source types and\nto ultimately use these insights to build a source recommendation\nengine.\nREFERENCES\n[1]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding. arXiv\npreprint arXiv:1810.04805 (2018).\n[2]David K Elson and Kathleen R McKeown. 2010. Automatic attribution of quoted\nspeech in literary narrative. In Twenty-fourth AAAI conference on artificial intelli-\ngence.\n[3]James T Hamilton. 2011. All the news that\u2019s fit to sell. In All the News That\u2019s Fit\nto Sell. Princeton University Press.\n[4]Tiancheng Hu, Manoel Horta Ribeiro, Robert West, and Andreas Spitz. 2022.\nQuotatives Indicate Decline in Objectivity in US Political News. arXiv preprint\narXiv:2210.15476 (2022).\n[5]Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016.\nBag of Tricks for Efficient Text Classification. arXiv preprint arXiv:1607.01759\n(2016).\n[6]Yuval Kirstain, Ori Ram, and Omer Levy. 2021. Coreference Resolution without\nSpan Representations. In Proceedings of the 59th Annual Meeting of the Associa-\ntion for Computational Linguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 2: Short Papers). 14\u201319.\n[7]Grace Muzny, Michael Fang, Angel Chang, and Dan Jurafsky. 2017. A two-stage\nsieve approach for quote attribution. In Proceedings of the 15th Conference of the\nEuropean Chapter of the Association for Computational Linguistics: Volume 1,\nLong Papers. 460\u2013470.\n[8]Edward Newell, Drew Margolin, and Derek Ruths. 2018. An attribution relations\ncorpus for political news. In Proceedings of the Eleventh International Conference\non Language Resources and Evaluation (LREC 2018).[9]Joakim Nivre. 2010. Dependency parsing. Language and Linguistics Compass 4,\n3 (2010), 138\u2013152.\n[10] Shon Otmazgin, Arie Cattan, and Yoav Goldberg. 2022. LingMess: Linguisti-\ncally Informed Multi Expert Scorers for Coreference Resolution. arXiv preprint\narXiv:2205.12644 (2022).\n[11] Tim O\u2019Keefe, Silvia Pareti, James R Curran, Irena Koprinska, and Matthew Hon-\nnibal. 2012. A sequence labelling approach to quote attribution. In Proceedings of\nthe 2012 Joint Conference on Empirical Methods in Natural Language Processing\nand Computational Natural Language Learning. 790\u2013799.\n[12] Sebastian Pad\u00f3, Andr\u00e9 Blessing, Nico Blokker, Erenay Dayan\u0131k, Sebastian Haunss,\nand Jonas Kuhn. 2019. Who sides with whom? towards computational construction\nof discourse networks for political debates. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Linguistics. 2841\u20132847.\n[13] Silvia Pareti, Tim O\u2019keefe, Ioannis Konstas, James R Curran, and Irena Koprinska.\n2013. Automatically detecting and attributing indirect quotations. In Proceedings\nof the 2013 Conference on Empirical Methods in Natural Language Processing.\n989\u2013999.\n[14] Dario Pavllo, Tiziano Piccardi, and Robert West. 2018. Quootstrap: Scalable\nunsupervised extraction of quotation-speaker pairs from large news corpora via\nbootstrapping. In Twelfth International AAAI Conference on Web and Social\nMedia.\n[15] Jeroen Peperkamp and Bettina Berendt. 2018. Diversity Checker: Toward rec-\nommendations for improving journalism with respect to diversity. In Adjunct\nPublication of the 26th Conference on User Modeling, Adaptation and Personal-\nization. 35\u201341.\n[16] Evan Sandhaus. 2008. The new york times annotated corpus. Linguistic Data\nConsortium, Philadelphia 6, 12 (2008), e26752.\n[17] Alexander Spangher and Divya Choudhary. 2022. If it Bleeds, it Leads: A\nComputational Approach to Covering Crime in Los Angeles. arXiv preprint\narXiv:2206.07115 (2022).\n[18] Alexander Spangher, Xinyu Hua, Yao Ming, and Nanyun Peng. 2023. Sequentially\nControlled Text Generation. arXiv preprint arXiv:2301.02299 (2023).\n[19] Alexander Spangher, Xiang Ren, Jonathan May, and Nanyun Peng. 2022. NewsEd-\nits: A News Article Revision Dataset and a Novel Document-Level Reasoning\nChallenge. In Proceedings of the 2022 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies.\n127\u2013157.\n[20] Kobie Van Krieken. 2022. Story character, news source or vox pop? Representa-\ntions and roles of citizen perspectives in crime news narratives. Journalism 23, 9\n(2022), 1975\u20131994.\n[21] Timote Vaucher, Andreas Spitz, Michele Catasta, and Robert West. 2021. Quote-\nbank: a corpus of quotations from a decade of news. In Proceedings of the 14th\nACM International Conference on Web Search and Data Mining. 328\u2013336.\n[22] Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris\nAlberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang,\net al.2020. Big bird: Transformers for longer sequences. Advances in Neural\nInformation Processing Systems 33 (2020), 17283\u201317297.\n5\n2023", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Proceedings of the Joint Computation and Journalism European Data & Computational Journalism Conference", "author": ["B Heravi", "T Plattner", "F Stalph"], "pub_year": "2023", "venue": "Proceedings of the \u2026", "abstract": "Automated fact-checking (AFC) has grown in popularity to address the online spread of  misinformation, propaganda, and misinformation about critical contemporary issues. Various"}, "filled": false, "gsrank": 545, "pub_url": "https://openresearch.surrey.ac.uk/view/pdfCoverPage?instCode=44SUR_INST&filePid=13213083730002346&download=true", "author_id": ["Pfperm8AAAAJ", "", "PAk_-N8AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:reGskEFtvBQJ:scholar.google.com/&output=cite&scirp=544&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D540%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=reGskEFtvBQJ&ei=aLWsaMDWKeHUieoP9LKZ6AI&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:reGskEFtvBQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://openresearch.surrey.ac.uk/view/pdfCoverPage?instCode=44SUR_INST&filePid=13213083730002346&download=true"}}]