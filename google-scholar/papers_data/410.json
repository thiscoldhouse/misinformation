[{"title": "Experiments in detecting persuasion techniques in the news", "year": "2019", "pdf_data": "Experiments in Detecting\nPersuasion Techniques in the News\nSeunghak Yu\nMIT CSAIL\nCambridge, MA, USA\nseunghak@csail.mit.eduGiovanni Da San Martino\nQatar Computing Research Institute, HBKU\nDoha, Qatar\ngmartino@hbku.edu.qa\nPreslav Nakov\nQatar Computing Research Institute, HBKU\nDoha, Qatar\npnakov@hbku.edu.qa\nAbstract\nMany recent political events, like the 2016 US Presidential elections or the 2018\nBrazilian elections have raised the attention of institutions and of the general public\non the role of Internet and social media in in\ufb02uencing the outcome of these events.\nWe argue that a safe democracy is one in which citizens have tools to make them\naware of propaganda campaigns. We propose a novel task: performing \ufb01ne-grained\nanalysis of texts by detecting all fragments that contain propaganda techniques as\nwell as their type. We further design a novel multi-granularity neural network, and\nwe show that it outperforms several strong BERT-based baselines.\n1 Introduction\nJournalistic organisations, such as Media Bias/Fact Check ,1provide reports on news sources high-\nlighting the ones that are propagandistic. Obviously, such analysis is time-consuming and possibly\nbiased and it cannot be applied to the enormous amount of news that \ufb02ood social media and the\nInternet. Research on detecting propaganda has focused primarily on classifying entire articles as\npropagandistic/non-propagandistic [ 1,2,11]. Such learning systems are trained using gold labels\nobtained by transferring the label of the media source, as per Media Bias/Fact Check judgment, to\neach of its articles. Such distant supervision setting inevitably introduces noise in the learning process\n[8] and the resulting systems tend to lack explainability.\nWe argue that in order to study propaganda in a sound and reliable way, we need to rely on high-\nquality trusted professional annotations and it is best to do so at the fragment level, targeting speci\ufb01c\ntechniques rather than using a label for an entire document or an entire news outlet. Therefore, we\npropose a novel task: identifying speci\ufb01c instances of propaganda techniques used within an article.\nIn particular, we design a novel multi-granularity neural network, and we show that it outperforms\nseveral strong BERT-based baselines.\nOur corpus could enable research in propagandistic and non-objective news, including the develop-\nment of explainable AI systems. A system that can detect instances of use of speci\ufb01c propagandistic\ntechniques would be able to make it explicit to the users why a given article was predicted to be\npropagandistic. It could also help train the users to spot the use of such techniques in the news.\n1http://mediabiasfactcheck.com/\nAI for Social Good workshop at NeurIPS (2019), Vancouver, Canada.arXiv:1911.06815v1  [cs.CL]  15 Nov 2019\n2 Corpus Annotated with Propaganda Techniques\nWe retrieved 451 news articles from 48 news outlets, both propagandistic and non-propagandistic\naccording to Media Bias/Fact Check , which professionals annotators2annotated according to eighteen\npersuasion techniques [ 9], ranging from leveraging on the emotions of the audience \u2014such as using\nloaded language orappeal to authority [6] and slogans [ 4]\u2014 to using logical fallacies \u2014such as straw\nmen [12] (misrepresenting someone\u2019s opinion), hidden ad-hominem fallacies , and red herring [13,\np. 78] (presenting irrelevant data).3Some of these techniques weren studied in tasks such as hate\nspeech detection and computational argumentation [7].\nThe total number of technique instances found in the articles, after the consolidation phase, is\n7;485, out of a total number of 21;230sentences (35.2%). The distribution of the techniques in\nthe corpus is also uneven: while there are 2;547occurrences of loaded language , there are only 15\ninstances of straw man (more statistics about the corpus can be found in [ 3]). We de\ufb01ne two tasks\nbased on the corpus described in Section 2: ( i)SLC (Sentence-level Classi\ufb01cation) , which asks to\npredict whether a sentence contains at least one propaganda technique, and ( ii)FLC (Fragment-level\nclassi\ufb01cation) , which asks to identify both the spans and the type of propaganda technique. Note\nthat these two tasks are of different granularity, g1andg2, namely tokens for FLC and sentences for\nSLC. We split the corpus into training, development and test, each containing 293, 57, 101 articles\nand 14,857, 2,108, 4,265 sentences, respectively.\nOur task requires speci\ufb01c evaluation measures that give credit for partial overlaps of fragments. Thus,\nin our precision and recall versions, we give partial credit to imperfect matches at the character level,\nas in plagiarism detection [10].\nLetsandtbe two fragments, i.e., sequences of characters. We measure the overlap of two annotated\nfragments as C(s;t;h ) =j(s\\t)j\nh\u000e(l(s);l(t)), wherehis a normalizing factor, l(a)is the labelling of\nfragmenta, and\u000e(a;b) = 1 ifa=b, and 0otherwise.\nWe now de\ufb01ne variants of precision and recall able to account for the imbalance in the corpus:\nP(S;T ) =1\njSjX\ns2S;\nt2TC(s;t;jsj); R (S;T ) =1\njTjX\ns2S;\nt2TC(s;t;jtj); (1)\nIn eq. (1), we de\ufb01neP(S;T )to be zero ifjSj= 0andR(S;T )to be zero ifjTj= 0. Finally, we\ncompute the harmonic mean of precision and recall in Eq. (1)and we obtain an F 1-measure. Having\na separate function Cfor comparing two annotations gives us additional \ufb02exibility compared to\nstandard NER measures that operate at the token/character level, e.g., we can change the factor that\ngives credit for partial overlaps and be more forgiving when only a few characters are wrong.\n3 Models\nWe depart from BERT [5], and we design three baselines.\nBERT. We add a linear layer on top of BERT and we \ufb01ne-tune it, as suggested in [ 5]. For the FLC\ntask, we feed the \ufb01nal hidden representation for each token to a layer Lg2that makes a 19-way\nclassi\ufb01cation: does this token belong to one of the eighteen propaganda techniques or to none of them\n(cf. Figure 1-a). For the SLC task, we feed the \ufb01nal hidden representation for the special [CLS]\ntoken, which BERT uses to represent the full sentence, to a two-dimensional layer Lg1to make a\nbinary classi\ufb01cation.\nBERT-Joint. We use the layers for both tasks in the BERT baseline, Lg1andLg2, and we train for\nboth FLC and SLC jointly (cf. Figure 1-b).\nBERT-Granularity. We modify BERT-Joint to transfer information from SLC directly to FLC.\nInstead of using only the Lg2layer for FLC, we concatenate Lg1andLg2, and we add an extra\n19-dimensional classi\ufb01cation layer Lg1;2on top of that concatenation to perform the prediction for\nFLC (cf. Figure 1-c).\n2http://www.aiidatapro.com . The company performs professional annotations in the NLP domain,\nalthough they were not expert in propaganda techniques before this work.\n3For a complete list see http://propaganda.qcri.org/annotations/definitions.html\n2\n...\nBERTToken\nLabel 1Token\nLabel 2Token\nLabel N \nBERTSentence\nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n... ...\nBERTSentence\nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n......\n......\nBERTSentence\nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n(c) BERT-Granu (d) Multi-Granularity Network(a) BERT (b) BERT-Joint... ... ... ... ...\n... ...\n... ...CLS T 1 T2 TN CLS T 1 T2 TN\nCLS T 1 T2 TNCLS T 1 T2 TNg1o\ng2o g2og1w g1wg1L g2L \ng1,2L \nf fFigure 1: The architecture of the baseline models (a-c), and of our multi-granularity network (d).\nMulti-Granularity Network. We propose a model that can drive the higher-granularity task (FLC)\non the basis of the lower-granularity information (SLC), rather than simply using low-granularity\ninformation directly. Figure 1-d shows the architecture of this model.\nMore generally, suppose there are ktasks of increasing granularity, e.g., document-level, paragraph-\nlevel, sentence-level, word-level, subword-level, character-level. Each task has a separate classi\ufb01ca-\ntion layerLgkthat receives the feature representation of the speci\ufb01c level of granularity gkand outputs\nogk. The dimension of the representation depends on the embedding layer, while the dimension of\nthe output depends on the number of classes in the task. The output ogkis used to generate a weight\nfor the next granularity task gk+1through a trainable gate f:\nwgk=f(ogk) (2)\nThe gatefconsists of a projection layer to one dimension and an activation function. The resulting\nweight is multiplied by each element of the output of layer Lgk+1to produce the output for task gk+1:\nogk+1=wgk\u0003ogk+1 (3)\nIfwgk= 0for a given example, the output of the next granularity task ogk+1would be 0 as well. In\nour setting, this means that, if the sentence-level classi\ufb01er is con\ufb01dent that the sentence does not\ncontain propaganda, i.e., wgk= 0, then ogk+1= 0and there would be no propagandistic technique\npredicted for any span within that sentence. Similarly, when back-propagating the error, if wgk= 0\nfor a given example, the \ufb01nal entropy loss would become zero, i.e., the model would not get any\ninformation from that example. As a result, only examples strongly classi\ufb01ed as negative in a\nlower-granularity task would be ignored in the high-granularity task. Having the lower-granularity\nas the main task means that higher-granularity information can be selectively used as additional\ninformation to improve the performance, but only if the example is not considered as highly negative.\nFor the loss function, we use a cross-entropy loss with sigmoid activation for every layer, except for\nthe highest-granularity layer LgK, which uses a cross-entropy loss with softmax activation. Unlike\nsoftmax, which normalizes over all dimensions, the sigmoid allows each output component of layer\nLgkto be independent from the rest. Thus, the output of the sigmoid for the positive class increases\nthe degree of freedom by not affecting the negative class, and vice versa. As we have two tasks, we\nuse sigmoid activation for Lg1and softmax activation for Lg2. Moreover, we use a weighted sum of\nlosses with a hyper-parameter \u000b:\nLJ=Lg1\u0003\u000b+Lg2\u0003(1\u0000\u000b) (4)\nAgain, we use BERT [ 5] for the contextualized embedding layer and we place the multi-granularity\nnetwork on top of it.\n3\nModelTask SLC Task FLC\nP R F 1 P R F 1\nAll-Propaganda 23.92 100.0 38.61 - - -\nBERT 63.20 53.16 57.74 21.48 21.39 21.39\nJoint 62.84 55.46 58.91 20.11 19.74 19.92\nGranu 62.80 55.24 58.76 23.85 20.14 21.80\nMulti-Granularity\nReLU 60.41 61.58 60.98 23.98 20.33 21.82\nSigmoid 62.27 59.56 60.71 24.42 21.05 22.58\nTable 1: Sentence-level (left) and fragment-level experiments (right). All-propaganda is a baseline\nthat always output the propaganda class.\n4 Experiments and Evaluation\nWe used the PyTorch4framework and the pretrained BERT model,5which we \ufb01ne-tuned for our\ntasks.6To deal with class imbalance, we give weight to the binary cross-entropy according to\nthe proportion of positive samples. For the \u000bin the joint loss function, we use 0.9 for sentence\nclassi\ufb01cation, and 0.1 for word-level classi\ufb01cation. In order to reduce the effect of random \ufb02uctuations\nfor BERT, all the reported numbers are the average of three experimental runs with different random\nseeds. As it is standard, we tune our models on the dev partition and we report results on the test\npartition.\nThe left side of Table 1 shows the performance for the three baselines and for our multi-granularity\nnetwork on the FLC task. For the latter, we vary the degree to which the gate function is applied:\nusing ReLU is more aggressive compared to using the Sigmoid, as the ReLU outputs zero for a\nnegative input. Table 1 (right) shows that using additional information from the sentence-level for\nthe token-level classi\ufb01cation (BERT-Granularity) yields small improvements. The multi-granularity\nmodels outperform all baselines thanks to their higher precision. This shows the effect of the model\nexcluding sentences that it determined to be non-propagandistic from being considered for token-level\nclassi\ufb01cation.\nThe right side of Table 1 shows the results for the SLC task. We apply our multi-granularity network\nmodel to the sentence-level classi\ufb01cation task to see its effect on low granularity when we train the\nmodel with a high granularity task. Interestingly, it yields huge performance improvements on the\nsentence-level classi\ufb01cation result. Compared to the BERT baseline, it increases the recall by 8.42%,\nresulting in a 3.24% increase of the F 1score. In this case, the result of token-level classi\ufb01cation is\nused as additional information for the sentence-level task, and it helps to \ufb01nd more positive samples.\nThis shows the opposite effect of our model compared to the FLC task.\n5 Conclusions\nWe have argued for a new way to study propaganda in news media: by focusing on identifying the\ninstances of use of speci\ufb01c propaganda techniques. Going at this \ufb01ne-grained level can yield more\nreliable systems and it also makes it possible to explain to the user why an article was judged as\npropagandistic by an automatic system.\nWe experimented with a number of BERT-based models and devised a novel architecture which\noutperforms standard BERT-based baselines. Our \ufb01ne-grained task can complement document-level\njudgments, both to come out with an aggregated decision and to explain why a document \u2014or an\nentire news outlet\u2014 has been \ufb02agged as potentially propagandistic by an automatic system.\nIn future work, we plan to include more media sources, especially from non-English-speaking media\nand regions. We further want to extend the tool to support other propaganda techniques.\n4http://pytorch.org\n5http://github.com/huggingface/pytorch-pretrained-BERT\n6Our source code together with the dataset are available in GitHub: http://anonymous.for.review .\n4\n6 Acknowledgements\nThis research is part of the Propaganda Analysis Project,7which is framed within the Tanbih project.8\nThe Tanbih project aims to limit the effect of \u201cfake news\u201d, propaganda, and media bias by making\nusers aware of what they are reading, thus promoting media literacy and critical thinking. The project\nis developed in collaboration between the Qatar Computing Research Institute (QCRI), HBKU and\nthe MIT Computer Science and Arti\ufb01cial Intelligence Laboratory (CSAIL).\nReferences\n[1] A. Barr\u00f3n-Cede\u00f1o, G. Da San Martino, I. Jaradat, and P. Nakov. Proppy: A system to unmask\npropaganda in online news. In Proceedings of the Thirty-Third AAAI Conference on Arti\ufb01cial\nIntelligence , AAAI \u201919, pages 9847\u20139848, Honolulu, HI, USA, 2019.\n[2]A. Barr\u00f3n-Cedeno, I. Jaradat, G. Da San Martino, and P. Nakov. Proppy: Organizing the news\nbased on their propagandistic content. Information Processing & Management , 56(5):1849\u2013\n1864, 2019.\n[3]G. Da San Martino, S. Yu, A. Barr\u00f3n-Cede\u00f1o, R. Petrov, and P. Nakov. Fine-grained analysis\nof propaganda in news articles. In Proceedings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and 9th International Joint Conference on Natural Language\nProcessing , EMNLP-IJCNLP 2019, pages 5640\u20135650, Hong Kong, China, 2019.\n[4]L. Dan. Techniques for the Translation of Advertising Slogans. In Proceedings of the Interna-\ntional Conference Literature, Discourse and Multicultural Dialogue , LDMD \u201915, pages 13\u201323,\nMures, Romania, 2015.\n[5]J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional\ntransformers for language understanding. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies , NAACL-HLT \u201919, pages 4171\u20134186, Minneapolis, MN, USA, 2019.\n[6]J. Goodwin. Accounting for the force of the appeal to authority. In Proceedings of the 9th\nInternational Conference of the Ontario Society for the Study of Argumentation , OSSA \u201911,\npages 1\u20139, Ontario, Canada, 2011.\n[7]I. Habernal, H. Wachsmuth, I. Gurevych, and B. Stein. Before name-calling: Dynamics and\ntriggers of ad hominem fallacies in web argumentation. In Proceedings of the 2018 Conference\nof the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies , NAACL-HLT \u201918, pages 386\u2013396, New Orleans, LA, USA, 2018.\n[8]B. D. Horne, S. Khedr, and S. Adali. Sampling the news producers: A large news and feature data\nset for the study of the complex media landscape. In Proceedings of the Twelfth International\nAAAI Conference on Web and Social Media , ICWSM \u201918, Stanford, CA, USA, 2018.\n[9]C. R. Miller. The Techniques of Propaganda. From \u201cHow to Detect and Analyze Propaganda,\u201d\nan address given at Town Hall, 1939. The Center for learning.\n[10] M. Potthast, B. Stein, A. Barr\u00f3n-Cede\u00f1o, and P. Rosso. An evaluation framework for plagiarism\ndetection. In Proceedings of the 23rd international conference on computational linguistics:\nPosters , COLING \u201910, pages 997\u20131005, Beijing, China, 2010.\n[11] H. Rashkin, E. Choi, J. Y . Jang, S. V olkova, and Y . Choi. Truth of varying shades: Analyzing\nlanguage in fake news and political fact-checking. In Proceedings of the 2017 Conference on Em-\npirical Methods in Natural Language Processing , EMNLP \u201917, pages 2931\u20132937, Copenhagen,\nDenmark, 2017.\n[12] D. Walton. The straw man fallacy . Royal Netherlands Academy of Arts and Sciences, 1996.\n[13] A. Weston. A rulebook for arguments . Hackett Publishing, 2018.\n7http://propaganda.qcri.org\n8http://tanbih.qcri.org\n5", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Experiments in detecting persuasion techniques in the news", "author": ["S Yu", "GDS Martino", "P Nakov"], "pub_year": "2019", "venue": "arXiv preprint arXiv:1911.06815", "abstract": "Many recent political events, like the 2016 US Presidential elections or the 2018 Brazilian  elections have raised the attention of institutions and of the general public on the role of"}, "filled": false, "gsrank": 643, "pub_url": "https://arxiv.org/abs/1911.06815", "author_id": ["ayy2eo0AAAAJ", "URABLy0AAAAJ", "DfXsKZ4AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:DQOnj2UArOgJ:scholar.google.com/&output=cite&scirp=642&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D640%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=DQOnj2UArOgJ&ei=erWsaPG6EvnSieoPxKLpgQ0&json=", "num_citations": 18, "citedby_url": "/scholar?cites=16765775948995298061&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:DQOnj2UArOgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1911.06815"}}, {"title": "Perils and challenges of social media and election manipulation analysis: The 2018 us midterms", "year": "2019", "pdf_data": "Perils and Challenges of Social Media and Election\nManipulation Analysis: The 2018 US Midterms\nAshok Deb\nUSC Information Sciences Institute\nMarina del Rey, CA\nashok@isi.eduLuca Luceri *\nUniversity of Applied Sciences and Arts of Southern\nSwitzerland, and University of Bern\nManno, Switzerland\nluca.luceri@supsi.ch\nAdam Badaway\nUSC Information Sciences Institute\nMarina del Rey, CA\nbadawy@isi.eduEmilio Ferrara\nUSC Information Sciences Institute\nMarina del Rey, CA\nemiliofe@usc.edu\nABSTRACT\nOne of the hallmarks of a free and fair society is the ability to conduct\na peaceful and seamless transfer of power from one leader to another.\nDemocratically, this is measured in a citizen population\u2019s trust in the\nelectoral system of choosing a representative government. In view of\nthe well documented issues of the 2016 US Presidential election, we\nconducted an in-depth analysis of the 2018 US Midterm elections\nlooking specifically for voter fraud or suppression. The Midterm\nelection occurs in the middle of a 4 year presidential term. For the\n2018 midterms, 35 Senators and all the 435 seats in the House of\nRepresentatives were up for re-election, thus, every congressional\ndistrict and practically every state had a federal election. In order\nto collect election related tweets, we analyzed Twitter during the\nmonth prior to, and the two weeks following, the November 6, 2018\nelection day. In a targeted analysis to detect statistical anomalies or\nelection interference, we identified several biases that can lead to\nwrong conclusions. Specifically, we looked for divergence between\nactual voting outcomes and instances of the #ivoted hashtag on the\nelection day. This analysis highlighted three states of concern: New\nYork, California, and Texas. We repeated our analysis discarding\nmalicious accounts, such as social bots. Upon further inspection and\nagainst a backdrop of collected general election-related tweets, we\nidentified some confounding factors, such as population bias, or bot\nand political ideology inference, that can lead to false conclusions.\nWe conclude by providing an in-depth discussion of the perils and\nchallenges of using social media data to explore questions about\nelection manipulation.\nKEYWORDS\nsocial media, political elections, data science for society\n*Also with USC Information Sciences Institute.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA\n\u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9999-9/18/06. . . $15.00\nhttps://doi.org/10.1145/1122445.1122456ACM Reference Format:\nAshok Deb, Luca Luceri, Adam Badaway, and Emilio Ferrara. 2019. Perils\nand Challenges of Social Media and Election Manipulation Analysis: The\n2018 US Midterms. In The Web Conference \u201919: Data Science for Social\nGood Workshop, May 14, 2019, San Francisco, CA. ACM, New York, NY ,\nUSA, 10 pages. https://doi.org/10.1145/1122445.1122456\nINTRODUCTION\nInherent bias of drawing conclusions from political polls stretch\nback to the famous headline of \"Dewey Defeats Truman\" in the\n1948 US Presidential election [ 43]. Confounding factors that led to\nfalse conclusions in the 1948 election included telephone surveys\nwhich did not use robust statistical methods and an under-sampling\nof Truman supporters. Likewise, in 2016, many political pundits\nunderestimated the likelihood that Donald Trump would be elected\nas President of the United States. The research community demon-\nstrated a strong interest in studying social media to get a better\nunderstanding of how the 2016 events unfolded. Numerous studies\nconcluded that social media can be a vehicle for political manipula-\ntion, citing factors such as the effect of fake news and disinforma-\ntion [ 5,9,28,29,33,46,49,51,55], bots [ 7,8,41,50,53,58,59],\npolarization [3, 6], etc.\nResearch also suggests that social media data comes with sig-\nnificant biases that limit the ability to forecast offline events, e.g.,\nthe outcomes of political elections [ 22\u201326,38], or public health\nissues [ 2,36,57]. Despite these well documented issues and chal-\nlenges, social media are frequently relied upon and referred to as a\ntrusted source of information to speculate about, or try to explain,\noffline events. One such example is the recent 2018 US Midterm\nelections where widespread claims of voter fraud and voter suppres-\nsion appeared in the news, often based on social media reports and\naccounts.\nIn this paper, we seek to understand whether it is possible to\nuse Twitter as a sensor to estimate the expected amount of votes\ngenerated by each state. We propose an undertaking in which we\nuse the tweets with the hashtag #ivoted on the election day as a\nproxy for actual votes. At first, this seemed like a promising research\ndirection, as tweet volumes and vote counts correlated well for 47 of\nthe 50 states in America. We also considered if this would be a useful\napproach to detecting voting issues like fraud or suppression, for\nexample by isolating statistical anomalies in estimated and observedarXiv:1902.00043v1  [cs.SI]  31 Jan 2019\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA A. Deb, L. Luceri, A. Badaway, and E. Ferrara\nvolumes. To get a sense of expected tweet volume, we carried out\nthe same analysis against general keywords related to the midterm\nelection from a month before election day through two weeks after\nthe election. We also considered how bots may have had an influence\non election manipulation narratives by measuring their activity in\nthe social media discourse. We finally applied a political ideology\ninference technique and tested it to see how well it compared to an\nexternal source of polls data.\nThe conclusions from our analysis are complex, and this work\nis meant as a note of caution about the risks of using social media\nanalysis to infer political election manipulation such as voter fraud\nand voter suppression.\nContributions of this work\nAfter exploring multiple Twitter data sets and two external sources\n(vote counts and Gallup), we came to the following contributions:\n\u2022We explored how social media analysis carries a lot of risks\ninvolved mainly with population bias, data collection bias,\nlack of location-specific data, separation of bots (and orga-\nnizations) from humans, information verification and fact-\nchecking, and lastly assigning political ideology.\n\u2022We saw a significant difference in the removal of retweets in\nour analysis as compared with including them. However, the\neffect was isolated to one particular state, Texas, indicating\nthat the sensitivity of this effect could be a factor of location.\n\u2022There is a significant difference between people\u2019s reported\npolitical ideologies using a source like Gallup versus that\ncan be inferred on social media. It is not possible to know\nif this is due to limitations of political inference algorithms,\nconfounders, population representation biases, or else.\n\u2022In the two states (NY & TX) where there was a statistically\nsignificant discrepancy between vote counts and instances\nof self-reported voting via #ivoted hashtags, we found only\nlimited anecdotal evidence of tweets reporting issues of voter\nfraud or suppression. The divergence can possibly be ex-\nplained by confounding factors, locality and selection bias, or\nsocial influence of particular candidates in those states (e.g.,\nAlexandria Ocasio-Cortez in NY and Beto O\u2019Rourke in TX).\nBACKGROUND\nThe US Midterm elections were held on 6 November, 2018. They are\nreferred to as mid-term elections because they occur in the middle\nof a presidential term. Senators serve for 6 years, thus, every 2 years,\nnearly a third of the Senators are up for re-election. The Senate is\ndivided into 3 classes, depending on which year they were elected.\nClass I was elected in 2012 and are up for re-election in 2018.\nFor 2018, 35 Senators out of a total of 100 senators in the 115th\nCongress will be up for re-election. Of the 35 senators up for election,\n33 are in Senate Class I and two are Senators who vacated, whereas\n15 are in what is to be considered contentious races. The 33 Class I\nare 30 (23 Democrats (D), 5 Republicans (R), 2 Independents (I))\nup for re-election and 3 Republicans (R) who are retiring. Details\non the Senate seats up for re-election are in Table 1. Additionally,\nall 535 House of Representative seats are up for re-election every 2\nyears. Excluded from our analysis are the non-voting delegates for\nDC and the US Territories.Table 1: US Senate Seats Up for Election in 2018\nIncumbent State Party Status\nTammy Baldwin WI D Contested\nJohn Barraso WY R Safe\nSherrod Brown OH D Contested\nMaria Cantrell WA D Safe\nBen Cardin MD D Safe\nTom Carper DE D Safe\nBob Casey PA D Safe\nBob Corker TN R Retiring\nTed Cruz TX R Contested\nJoe Donnelly IN D Contested\nDianne Feinstein CA D Safe\nDeb Fischer NE R Safe\nJeff Flake AZ R Retiring\nKirsten Gillibrand NY D Safe\nOrrin Hatch UT R Retiring\nMartin Heinrich NM D Safe\nHeidi Heitkamp ND D Contested\nDean Heller NV R Contested\nMazie Hirono HI D Safe\nCindy Hyde-Smith MS R Contested\nTim Kaine V A D Safe\nAngus King ME I Safe\nAmy Klobuchar MN D Safe\nJoe Manchin WV D Contested\nClaire McCaskill MO D Contested\nBob Menendez NJ D Contested\nChris Murphy CT D Safe\nBill Nelson FL D Contested\nBernie Sanders VT I Safe\nTina Smith MN D Contested\nDebbie Stabenow MI D Safe\nJon Tester MT D Contested\nElizabeth Warren MA D Safe\nSheldon Whitehouse RI D Safe\nRoger Wicker MS R Safe\nRELATED WORK\nSince the 2016 US Presidential election, there has been a big spot-\nlight on the sovereignty of the US election system. The Bot Disclo-\nsure and Accountability Act of 20181gave clear guidelines for what\nhas to be disclosed by social media companies. The article The Rise\nof Social Bots [18] brought awareness to the issue of social bots in\nsocial media platforms. In [ 7], Bessi & Ferrara focused on social\nbots detection within the online discussion related to the 2016 presi-\ndential election. Other than characterizing the behavioral differences\nbetween humans and bots, there was not an in-depth analysis of any\nmalicious intent. In this paper, we address the potential malicious\nactivity in online political discussion along the lines of voter fraud,\nvoter suppression, political misinformation, and then report on the\nbiases we found.\nVoting Issues\nConcerns related to voter fraud took center stage after the 2000\nUS Presidential election, where it was argued that the candidate\n1https://www.congress.gov/bill/115th-congress/senate-bill/3127/text\nPerils and Challenges of Social Media and Election Manipulation The Web Conference \u201919, May 14, 2019, San Francisco, CA\nwith the most votes lost and the Supreme Court decided the winner\n[39]. Since then, a host of public debate, congressional testimony,\nand several new laws passed, such as the Help America V ote Act\n[34], which surprisingly needed to happened after the National V oter\nRegistration Act of 1993 (NVRA).2The effects of the NVRA were\nresearched by Highton and Wolfinger [32], who concluded that\nprovisions in the NVRA would increase voter turnout by 4.7%-8.7%\nand that purging voter rolls of those who had not voted in the last\ntwo years would have a 2% effect. Lastly, they identified the two\nmost vulnerable non-voting groups to be those under the age of 30\nand those who moved within 2 years of an election [32].\nMoreover, it has been argued that the current US voter registra-\ntion has a minimal impact on registration and that there is marginal\nvalue in any updated laws [ 31]. Therefore, the main concern argued\nby both parties is voter suppression [ 56]. Specifically, due to re-\ncent voter identification laws, there is an increased chance of voter\nsuppression [ 30]. However, in this work we seek to find instances\nof voter suppression from an online social media analysis. To our\nknowledge, this has not been done before.\nPolitical Manipulation\nSocial media serve as convenient platforms for people to connect and\nto exchange ideas. However, social media networks like Twitter and\nFacebook can be used for malicious purposes [ 17]. Especially in the\ncontext of political discussion, there is a significant risk of mass ma-\nnipulation of public opinion. Concerning the ongoing investigation\nof Russian meddling in the 2016 US Presidential election, Badawy\net al. [4] studied political manipulation by analyzing the released\nRussian troll accounts on Twitter. After using label propagation to\nassign political ideology, they found that Conservatives retweeted\nRussian trolls over 30 times more than Liberals and produced 36\ntimes more tweets. More recently, Stella et al . [52] highlighted how\nbots can play significant roles in targeting influential humans to\nmanipulate online discussion thus increasing in-fighting. Especially\nfor the spread of fake news, various studies showed how political\nleaning [ 1], age [ 28], and education [ 49] can greatly affect fake news\nspread, alongside with other mechanisms that leverage emotions\n[20,21] and cognitive limits [ 44,45]. Additionally, Dutt et al . [16]\nshowed how foreign actors can more so than just backing one candi-\ndate or the other, often manipulate social media for the purpose of\nsowing discord.\nBias\nBesides manipulation, other potential problems may affect data\noriginating from online social systems. Selection bias is one such\nexample. Concisely, this bias yields a statistically non-representative\nsample of the true population. A main concern outlined by Ruths\nand Pfeffer [48], and to a lesser degree by Malik et al . [37] , is that\nsocial media samples are not representative of the whole voting\npopulation because users self-select to participate on the platform\nand in specific online discussions. Each social media platform has\nits own set of biases. Mislove et al . [40] looked specifically at the\nTwitter population from a location, gender, and ethnicity viewpoint.\nFrom a location perspective, they found underrepresented counties\nin the Mid-West and over-represented counties in highly dense urban\n2https://www.justice.gov/crt/about-national-voter-registration-actareas [ 40]. Biases in the representation of gender [ 47], ethnicity [ 11],\nand other sources of distortions [ 13] can also potentially affect the\ninference of political ideology.\nDATA\nIn this study, we examine different data sources to investigate and\nexplore the risk of using social media in the context of political\nelection manipulation.\nWe used Twitter as a sensor to estimate the expected amount of\nvotes generated by each state. For this purpose, we carried out two\ndata collections. In the first one, we gathered the tweets with the\nhashtag #ivoted on election day. The second collection aimed to\nenlarge the spectrum to a longer period of time exploiting a variety\nof general keywords, related to the midterm election, to collect the\ntweets. As a basis for comparison, we employ two external sources.\nThe United States Election Project is used to unveil the amount of\nvoters in each state, while Gallup to have an estimate of the political\npolarization both at the country level and at the state level. By means\nof these three data sources, we assembled five data sets (DS1-DS5),\nwhich will be analyzed in turn in the following subsections.\nDS1: #ivoted Dataset. The #ivoted Dataset (DS1) gathers the\ntweets with the hashtag #ivoted generated on the day of the election,\nNovember 6, 2018. It should be noticed that #ivoted was promoted by\nTwitter and Instagram\u2014which typically affects the hashtag spread\n[19,54]\u2014to encourage citizens to participate in the midterm elec-\ntions and increase the voter turnout. We used the Python module\nTwyton to collect tweets through the Twitter Streaming API3during\nelection day. The data collection time window ranged from 6 a.m.\nEST on November 6 (when the first polling station opened) to 1 a.m.\nHST on November 7 (2 hours after the last polling station closed).\nOverall, we collected 249,106 tweets. As a sanity check, we queried\ntheOSoMe API provided by Indiana University [ 14]. OSoMe tracks\nthe Twitter Decahose, a pseudo-random 10% sample of the stream,\nand therefore can provide an estimate of the total volume: OSoME\ncontains 29.7K tweets with the #ivoted hashtag posted by 27.2K\nusers\u2014it is worth noting that trending topics are typically slightly\nover-represented in the Twitter Decahose [ 14,42]\u2014by extrapolation,\nthis would suggest an estimated upper bound of the total volume at\naround 300K tweets. In addition, on election day, Twitter reported\nthat the hashtag #ivoted was trending with over 200K tweets (cf.\nFig. 1). Having collected 249K such tweets, we can conclude that\nwe have at our disposal a nearly complete #ivoted sample dataset.\nDS2 & DS3: General Midterm Dataset. In the General Midterm\nDataset, we collect tweets on a broader set of keywords. Further,\nwe consider two different time windows for the data collection. The\nrationale behind these choices is to evaluate the sensitivity of our\nstudy against a different, but correlated, set of data. In other words,\nthe main purpose is to detect whether any divergence arose with\nthe #ivoted Dataset analysis or, on the other hand, to inspect the\nconsistency of the results in different settings.\nTweets were collected by using the following keywords as a\nfilter: 2018midtermelections ,2018midterms ,elections ,midterm , and\nmidtermelections . We distinguish two data sets according to their\n3Please note that we utilize the same approach for every Twitter data collection discussed\nin this work.\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA A. Deb, L. Luceri, A. Badaway, and E. Ferrara\nFigure 1: Screen shot of the United States trends on election day\nshowing the #ivoted hashtag trending with 200K tweets.\ntemporal extent. In DS2, we consider only tweets generated on the\nelection day with exactly the same time window used for DS1. The\nthird data set (DS3) provides a view of the political discussion from\na wide-angle lens. It includes tweets from the month prior (October\n6, 2018) to two weeks after (November 19, 2018) the day of the\nelection. We kept the collection running after the election day as\nseveral races remained unresolved. As a result, DS3 consists of 2.7\nmillion tweets, whose IDs are publicly available for download.4\nDS4: Actual Voting Data. The first external data source used as a\nbasis of comparison is made available by the United States Election\nProject. They report on their website5the expected voter turnout\nper state, along with the (official or certified) information source\nand other statistics about voters. The data (DS4) we use in this work\nwas assessed on November 18, 2018, and reflects a voter turnout of\n116,241,100 citizens, which is aligned with other reported counts.\nDS5: Party Affiliation Data. To have an assessment of the political\nparty affiliation across the country, we make use of an evaluation pro-\nvided by Gallup, through the Gallup Daily tracking survey, a system\nwhich continuously monitors Americans\u2019 attitudes and behaviors .6\nThe data set (DS5), collected on January 22, 2019, depicts the politi-\ncal leaning over a sample size of 180,106 citizens. In particular, the\ndata shows the percentage of Democratic and Republican population\nin each state and over the entire country. Gallup\u2019s evaluation shows\nthat, at the national level, there exists a democratic advantage (7%),\nas 45% of the population is assessed as democratic leaning while\n38% is estimated as republican.\nData Pre-processing\nData pre-processing involved only Twitter data sets and consisted of\nthree main steps. First, we removed any duplicate tweet, which may\n4https://github.com/A-Deb/midterms\n5http://www.electproject.org/2018g\n6https://www.gallup.com/174155/gallup-daily-tracking-methodology.aspxTable 2: Datasets Statistics\nStatistic DS1 DS2 DS3\n# of Tweets 90,763 20,450 452,288\n# of Retweets 146,546 54,866 1,869,313\n# of Replies 11,797 6,730 267,973\n# of Authors 174,854 72,022 977,996\n# of Users 178,503 77,749 997,406\nhave been captured by accidental duplicate queries to the Twitter\nAPI. Then, we excluded from our analysis all the tweets not written\nin English language. Despite the majority of the tweets were in\nEnglish, and to a very lesser degree in Spanish (3,177 tweets), we\nidentified about 59 languages in the collected tweets. Finally, we\ninspected tweets from other countries and removed them as they\nwere out of the context of this study. In particular, we filtered out\ntweets related to the Cameroon election (October 7, 2018), to the\nDemocratic Republic of the Congo presidential election (December\n23, 2018), to the Biafra call for Independence (#biafra, #IPOB), to\ndemocracy in Kenya (#democracyKE), to the two major political\nparties in India (BJP and UPA), and to college midterm exams.\nOverall, we count for almost 3 millions tweets distributed over\nthe three Twitter data sets (DS1-DS3). In Table 2, we report some\naggregate statistics. It should be noticed that the number of authors is\nlower than the number of users, which in turn also includes accounts\nthat got a retweet (or reply) of a tweet that was not captured in our\ncollection and, thus, they do not appear as authors .\nMETHODOLOGY\nState Identification\nThe usage of geo-tagged tweets to assign a state to each user has been\nshown to not be effective, being the fraction of geo-tagged tweets\naround 0.5% [ 12]. The location of the data is of utmost importance,\nespecially at the state and local level. However, less than 1% of the\ncollected tweets have been geo-tagged. Nevertheless, we aim to map\nas many users as possible to a US state, to conduct a state by state\ncomparison. For this purpose, we leveraged tweet metadata, which\nmay include the self-reported user profile location. The location\nentry is a user-generated string (up to 100 characters), and it is\npulled from the user profile metadata for every tweet. From this field,\nwe first search for the two-letter capitalized state codes, followed by\nthe full name of the state. Our analysis does not include Washington,\nD.C., so we have to ensure anything initially labeled Washington\ndoes not include any variant of DC. Using this string-search method,\nwe managed to assign a state to approximately 50% of the tweets\nand 30% of the users. Some users had multiple states over their tweet\nhistory, thus, we only used the most common reported state. A few\nusers often switched their location from a state name to something\nelse: for example, one user went from New York, NY toVote Blue! \u2014\nfor such users, we kept the valid state location.\nBot Detection\nBot detection has received ample attention [ 18] and increasingly\nsophisticated techniques keep emerging [ 35]. In this study, we re-\nstrict our bot detection analysis to the use of the widely popular\nBotometer ,7developed by Indiana University. The underpinnings of\n7https://botometer.iuni.iu.edu/\nPerils and Challenges of Social Media and Election Manipulation The Web Conference \u201919, May 14, 2019, San Francisco, CA\nFigure 2: Bot Score Distribution\nthe system were first published in [ 15,53] and further revised in [ 59].\nBotometer is based on an ensemble classifier [ 10] fed by over 1,000\nfeatures related to the Twitter account under analysis and extracted\nthrough the Twitter API. Botometer aims to provide an indicator,\nnamely bot score , that is used to classify an account either as a bot or\nas a human. The lower the bot score, the higher the probability that\nthe user is not an automated and/or controlled account. In this study\nwe use version v3 of Botometer, which brings some innovations and\nimportant detailed in [ 59]\u2014e.g., the bot scores are now rescaled and\nnot centered around 0.5 anymore.\nIn Figure 2, we depict the bot score distribution of the 1,131,540\ndistinct users in our datasets. The distribution exhibits a right skew:\nmost of the probability mass is in the range [0, 0.2] and some peaks\ncan be noticed around 0.3. Prior studies used the 0.5 threshold to\nseparate humans from bots. However, according to the re-calibration\nintroduced in the latest version of Botometer [ 59], along with the\nemergence of increasingly more sophisticated bots, we here lower\nthe bot score threshold to 0.3 (i.e., a user is labeled as a bot if the bot\nscore is above 0.3). This threshold corresponds to the same level of\nsensitivity setting of 0.5 in prior versions of Botometer (cf. Fig 5 in\n[59]). In both DS1 and DS3, 21.1% of the users have been classified\nas bots, while in DS2 the percentage achieves the 22.9% of the users.\nFinally, 19.5% of the 295,352 users for which a State was identified\nhave been scored as bots.\nOverall, Botometer did not return a score for 42,904 accounts,\nwhich corresponds to 3.8% of the users. To further examine this\nsubset of users, we make use of the Twitter API. Interestingly, 99% of\nthese accounts were suspended by Twitter, whereas the remaining 1%\nwere protected (by privacy settings). For the users with an assigned\nlocation, only 1,033 accounts did not get a Botometer score. For\nthose users, we assume that the accounts suspended (1,019) are bots\nand the private accounts (14) are humans.\nStatistical Vote Comparison\nOnce the states have been identified and the bots detected, we com-\npared the distribution of our various Twitter datasets (DS1, DS2, and\nDS3) with our control data in DS4 and DS5. To do this, we start by\ncounting the number of tweets per state and dividing it by the total\nnumber of tweets across all states. We denote this fractional share in\nterms of tweets as State Tweet Rate (STR) , for each state iasST R(i)=no. tweets from State i\n\u00cd50\njno. tweets from State j(1)\nFor the actual voter data (DS4), we perform a similar metric to\ndetermine the State Vote Rate (SVR) of each state ias\nSV R(i)=no. votes from State i\n\u00cd50\njno. votes from State j(2)\nWe then calculate the difference \u03b4(i)for each state i. Here it is\nimportant to note that any positive value indicates more tweets than\nvotes, as a percentage, and vice versa:\n\u03b4(i)=ST R(i)\u2212SV R(i) (3)\nLastly, we convert the difference into standard deviations s(i)\n(stdevs) by dividing \u03b4(i)by the standard deviation of all differences:\ns(i)=\u03b4(i)q\u00cd(\u03b4(i)\u2212\u03b4)\n50(4)\nbeing \u03b4the average difference over all states. We then inspect the\nresults for any anomalous state iwhose standard deviation |s(i)|\u2265 2.\nStates beyond two standard deviations are worth further inspection.\nPolitical Ideology Inference\nWe classify users by their ideology based on the political leaning of\nthe media outlets they share. We use lists of partisan media outlets\ncompiled by third-party organizations, such as AllSides8and Media\nBias/Fact Check.9We combine liberal and liberal-center media\noutlets into one list and conservative and conservative-center into\nanother. The combined list includes 641 liberal and 398 conservative\noutlets. However, in order to cross reference these media URLs with\nthe URLs in the Twitter dataset, we need to get the expanded URLs\nfor most of the links in the dataset, since most of them are shortened.\nAs this process is quite time-consuming, we get the top 5,000 URLs\nby popularity and then retrieve the long version for those. These\ntop 5,000 URLs account for more than 254K, or more than 1/3 of\nall the URLs in the dataset. After cross-referencing the 5,000 long\nURLs with the media URLs, we observe that 32,115 tweets in the\ndataset contain a URL that points to one of the liberal media outlets\nand 25,273 tweets with a URL pointing to one of the conservative\nmedia outlets. We use a polarity rule to label Twitter users as liberal\nor conservative depending on the number of tweets they produce\nwith links to liberal or conservative sources. In other words, if a user\nhas more tweets with URLs to liberal sources, he/she is labeled as\nliberal and vice versa. Although the overwhelming majority of users\ninclude URLs that are either liberal or conservative, we remove any\nuser that has equal number of tweets from each side. Our final set of\nlabeled users includes 38,920 users.\nTo classify the remaining accounts as liberal or conservative, we\nuse label propagation, similar to prior work [ 4]. For this purpose,\nwe construct a retweet network, containing nodes (Twitter users)\nwith a direct link between them if one user retweet a post of another.\nTo validate results of the label propagation algorithm, we apply\nstratified cross (5-fold) validation to a set of more than 38,920 seeds.\nWe train the algorithm on 4/5 of the seed list and see how it performs\n8https://www.allsides.com/media-bias/media-bias-ratings\n9https://mediabiasfactcheck.com/\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA A. Deb, L. Luceri, A. Badaway, and E. Ferrara\nFigure 3: Political ideology difference, in terms of percentage of\nliberals vs. conservatives, between DS5 and DS3\non the remaining 1/5. Both precision and recall scores are around\n0.89. Since we combine liberal and liberal-center into one list (same\nfor conservatives), we can see that the algorithm is not only labeling\nthe far liberal or conservative correctly, which is a relatively easier\ntask, but it is performing well on the liberal/conservative center as\nwell. Overall, we find that the liberal users population is almost three\ntimes larger the conservative counterpart (73% vs. 27%).RESULTS\n#ivoted (DS1) Statistical Analysis\nThere were 249,106 tweets in the #ivoted data set, of those we could\nmap a state location for 78,162 unique authors. Once we remove\nthe 15,856 bots (using a bot threshold score of 0.3), we have 62,306\nremaining authors of tweets and retweets. After applying the method\ndescribed in Statistical V ote Comparison section, we see that three\nstates show an anomalous behavior from the remaining 47 states.\nFigure 4a shows how New York is 5.8 standard deviations greater\nthan the mean difference between the #ivoted percentage and the\nactual voting percentage. Furthermore, both California and Texas\nhave a stdev 2.2 greater than the mean. This would lead to believe\nthat if there was voter suppression, it would most likely be in these\nthree states, as they exhibit significantly more self-reported voting\ntweets than vote counts.\nHowever, since our data set has both tweets and retweets, to check\nthe sensitivity of our findings, we repeated our analysis without the\nretweets. Once removed, the 34,754 remaining tweets, again without\nbots, we noticed something interesting. Not only did Texas drop\nfrom 2.2 stdevs to 0.4 stdevs, but New York increased from 5.8\nstdevs to 6.3 stdevs. This highlights the sensitivity our this type of\nanalysis to location-specific factors such as state, and information\ndynamic factors such as retweet filtering. Further inspection showed\nthat 62.2% of the tweet activity in Texas (in the #ivoted data set) was\nbased on retweets, highlighting how this class of tweet can produce\ndifferent results for some populations, and similar ones for others,\nsince the average across the states stayed at 0 (e.g., see Figure 4b).\nGeneral Midterm (DS2&DS3) Statistical Analysis\nWe carried out the same analysis against the general keywords data\nset both on election day (DS2) and for a month before to two weeks\nafter the election (DS3).\nIn DS2, we have 72,022 users, from which we filtered out 16,859\nbots (using a bot threshold of 0.3). From the remaining 55,163\nauthors, we were able to map a state for 26,081 users. Performing\nthe same comparative analysis from before, we found the same\nanomalies in the same three states: CA (1.6 stdev), TX (2.8 stdev),\nand NY (5.6 stdev). Visually, this can be appreciated in Figure\n4c. Expanding the analysis to DS3, we removed 206,831 users, as\nclassified as bots, from the set of 977,966 authors. This left us with\n771,135 users from which we could identify a state for 295,705 of\nthem. The statistical analysis revealed the same outliers also in this\ndata set: CA (2.8 stdev), TX (3.1 stdev), and NY (4.7 stdev), as can\nbeen seen in Figure 4d.\nBot Sensitivity\nNext, we investigate whether discarding malicious accounts, such\nas social bots, from the set of users may have affected the findings\nabove. Table 4 shows the number (and percentage) of bots and\nhumans per state in DS3. The list of states is sorted (in descending\norder) according to the percentage of bots, while the horizontal line\nseparates the states with a bots percentage above and below the\naverage (20.3%). Note in particular that all the three outliers (in\nbold) have values below the average. However, the distribution of\nbot prevalence per state varies greatly and it should be analyzed\nPerils and Challenges of Social Media and Election Manipulation The Web Conference \u201919, May 14, 2019, San Francisco, CA\n(a) #ivoted vs. Actual Votes\n (b) #ivoted (w/o RTs) vs. Actual Votes\n(c) General (election) vs. Actual Votes\n (d) General (overall) vs. Actual Votes\nFigure 4: Various datasets versus Actual Votes (DS4) all without bots\ntaking into account both the state population size and the number\nof Twitter users per state. Highly populated states like California,\nTexas, and New York, have large sheer numbers of bots but low\nproportional bot percentage. This should be taken into account when\ndrawing conclusions from this analysis. On the other side, this topic\nopens the way to further discussions about bots association with a\ngiven state. One could make the argument that if the account was\nidentified as a bot, there is no point to assigning it to a state. However,\nthe fact that automated accounts declare a location in their profile\ncan be viewed as a malicious strategy to embed in the social system\nthus, it should be prudently examined.\nFor these reasons, we repeated our analysis including social bots\nin the users set. Results with or without bots are substantially un-\nchanged. In the interest of space, we do not duplicate the maps\nshown in Figure 4, but the same anomalies are revealed if bots are\nretained. It should be noticed that also for the #ivoted dataset (DS1),\nthe percentage of bots in the three outlier states are below the average\n(21.0%), NY (16.0%), CA (19.4%) and TX (20.2%), respectively.\nPolitical Ideology Analysis\nNext we examine what topics talk about and how they address politi-\ncally charged topics. Table 3 shows the top 10 hashtags discussed\nrespectively by humans and bots, for both liberal and conservative\nideologies. The hashtags have been colored to show the common\ntopics between bots and humans for each political wing. The amount\nof overlap between bots and humans hashtags is noticeable. This is\nlikely the reason why the removal of bots from the analyzed accounts\ndid not have any significant impact on our outcome. To carefully\ninterpret this table, it should be noticed that the liberal group isalmost three times larger than the conservative one, as we stated in\nPolitical Ideology section.\nAdditionally, we took our political ideology labels by state and\ncompared with DS5, the Gallup poll survey. As mentioned before,\nthe political ideology inference assigned 73% liberal labels and\n27% conservative labels to the nation at a whole. That compares\nwith Gallup reporting of 45% to 38% for the Nation as a whole.\nAt the state level, we ran a comparison to see the difference in\nour assessment of political leaning of a state versus Gallup\u2019s. For\nexample, Alabama is 35% liberal and 50% conservative, according to\nGallup, giving the state a marked Republican advantage. However, in\nTwitter we observed 42% Liberal and 31% Conservative user labels,\nwhich may suggest the opposite trend. Figure 3 shows the difference\nbetween the Gallup poll and our analysis. For Alabama going from\na Republican advantage of 15% (Gallup) to a Democratic advantage\nof 11% (Twitter) would imply a shift of 26 percent points toward the\nliberal side. Overall, every state showed movement toward the left, as\nlow as a few percent points and as high as over 60% difference. This\ncorroborates the suspect that left-leaning users are over-represented\nin our data.\nVoting Issues\nNew York was the state that exhibited the strongest statistical anom-\naly. Thus, we conducted a manual inspection reading all tweets\noriginating from there. We found no red flags, but we isolated a few\ntweets of interest. The first one is in Figure 5 and it is from a user\nwho was classified as a human and from inspection of the account\nshown to live in New York. The user mentions some important issues:\nat 11:20 am on the day of the election, they found out they are the\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA A. Deb, L. Luceri, A. Badaway, and E. Ferrara\nTop 10 Hashtags\nLiberal Conservative\nBots#BlueWave #BrowardCounty\n#V oteBlue #MAGA\n#MAGA #Broward\n#NovemberisComing #RedWave\n#TheResistance #V oteRedToSaveAmerica\n#Democrats #StopTheSteal\n#Trump #V oteRed\n#vote #Democrats\n#Florida #Redwavepolls\n#GOTV #WednesdayWisdom\nHumans#NovemberisComing #BrowardCounty\n#V oteBlue #Broward\n#BlueWave #MAGA\n#vote #IranRegime\n#txlege #Tehran\n#electionday #StopTheSteal\n#Russia #RedWave\n#unhackthevote #PalmBeachCounty\n#AMJoy #Redwavepolls\n#Trump #Florida\nTable 3: Top 10 hashtags: liberals, conservatives, humans, bots\nFigure 5: #ivoted tweet from New York\nvictim of voter fraud. There is no information to suggests this was\nresolved in any meaningful way or if the accusation is substantiated.\nA second example of potential voter issue was found after a\nmanual inspection of the tweets in New York. The tweet thread in\nFigure 6 is heavily redacted, but it shows an ongoing conversation\nthrough replies and it shows multiple people presenting multiple\nsides. The original tweet was actually posted on 5 November, 2018\nand by the time of our viewing had received a significant number\nof retweets. It is from this original tweet that we see a reply where\nthe user is complaining that they can not get to the voting booth\nwithout a photo ID. User 3 then asks for the name and number of\nthe community and then User 4 provides an election hotline number.\nThis indicates that many people today are willing to speculate on\nTwitter, but nothing seems to indicate that they also were going to\nthe official Department of Justice website to file a complaint.\nFrom our inspection other tweets that are noteworthy include:\n(1)\"First time voter in my family registered over a month ago on\nDMV website online not realizing it\u2019s not automated. . . she\ncould not vote. Not right.\"\n(2)\"More voter fraud in Ohio. Why is it that all the errors are\nalways the Democrats?? Because the only way they can win\nis if they cheat!! This madness needs to stop.\"\nFigure 6: #ivoted tweet from Florida\n(3)What we did see in our Twitter collection is early skepticism\nthat there would be false claims of voter fraud. A user tweeted\n\"a little over 24 hours from now the Racist in Chief will start\nTweeting about rigged elections, voter fraud and illegal aliens\nvoting en mass...\".\n(4)Shortly afterwards, many people started to retweet a user\nthat stated \"Massive voter fraud in Texas Georgia Florida and\nothers\" and also indicating that MSM (main stream media) are\nputting out fake polls. The Washington Post @washingtonpost\ntweeted \"without evidence, Trump and Sessions warn of voter\nfraud\" which was retweeted throughout election day.\n(5)There was a user who tweeted about voting machine malfunc-\ntions which mapped to a story/blog from the Atlanta Journal\nConstitution (https://t.com/riCGdbwQ6R) about machines\nbeing down; people left and were encouraged to come back.\nThere was an offer for casting a paper provisional ballot, but\nmany said they did not trust the paper ballot and wanted to\nvote on a machine.\nDISCUSSION & RECOMMENDATIONS\nOur results have highlighted the challenges of using social media\nin election manipulation analysis. A superficial interpretation of\nanomalies in online activity compared to real world data can lead to\nmisleading or false conclusions. In our case, we wanted to determine\nthe feasibility of using social media as a sensor to detect election\nmanipulation such as widespread voter suppression or voter fraud.\nWhile we did not find widespread or systematic manipulation, we\nlearned a few lessons worthy of a discussion:\n\u2022Data biases of online platforms can drastically affect the\nfeasibility of a study. In our case, we were looking for a\nrepresentative sample of actual voters who are not bots and\nPerils and Challenges of Social Media and Election Manipulation The Web Conference \u201919, May 14, 2019, San Francisco, CA\nTable 4: General Midterms DS3: bot and human population by\nState (sorted by percent-wise bot prevalence).\nState # of bots # of humans\nWY 97 (27.2%) 246 (68.9%)\nID 258 (23.8%) 791 (73.0%)\nND 289 (22.9%) 931 (73.9%)\nAZ 1,514 (22.5%) 4,997 (74.2%)\nNV 711 (22.4%) 2,377 (74.8%)\nUT 420 (22.2%) 1,425 (75.4%)\nDE 170 (22.1%) 575 (74.9%)\nNM 325 (22.1%) 1,100 (74.7%)\nNH 283 (22.1%) 968 (75.5%)\nRI 402 (21.9%) 1,382 (75.3%)\nWV 246 (21.7%) 854 (75.2%)\nFL 4,696 (21.5%) 16,583 (75.9%)\nMO 932 (21.4%) 3,336 (76.5%)\nAL 697 (21.3%) 2,466 (75.4%)\nTN 1,209 (21.3%) 4,369 (76.9%)\nWI 808 (21.3%) 2,900 (76.4%)\nMT 202 (21.0%) 730 (75.9%)\nCO 1,144 (20.9%) 4,178 (76.4%)\nNJ 1,311 (20.8%) 4,838 (76.8%)\nMS 336 (20.6%) 1,239 (75.9%)\nME 290 (20.6%) 1,093 (77.6%)\nCT 571 (20.4%) 2,141 (76.6%)\nSC 769 (20.3%) 2,933 (77.5%)\nOK 552 (20.2%) 2,098 (76.8%)\nKS 661 (20.2%) 2,526 (77.2%)\nGA 1,962 (20.2%) 7,489 (76.9%)\nWA 1,561 (19.9%) 6,143 (78.2%)\nNE 323 (19.9%) 1,253 (77.1%)\nAK 160 (19.8%) 622 (77.1%)\nHI 230 (19.8%) 895 (77.1%)\nPA 1,898 (19.7%) 7,460 (77.6%)\nMI 1,441 (19.6%) 5,714 (77.7%)\nIA 414 (19.6%) 1,654 (78.2%)\nV A 1,487 (19.6%) 5,931 (78.1%)\nMA 1,372 (19.4%) 5,553 (78.4%)\nNC 1,685 (19.3%) 6,872 (78.5%)\nIL 1,702 (19.2%) 6,926 (78.0%)\nIN 885 (19.1%) 3,593 (77.6%)\nAR 199 (19.1%) 814 (78.0%)\nKY 548 (19.0%) 2,270 (78.9%)\nMN 866 (19.0%) 3,622 (79.6%)\nOR 1,067 (18.9%) 4,416 (78.3%)\nTX 5,550 (18.7%) 23,448 (79.1%)\nOH 1,722 (18.6%) 7,271 (78.7%)\nCA 7,073 (18.2%) 30,429 (78.5%)\nVT 113 (17.9%) 505 (80.2%)\nMD 887 (17.8%) 3,963 (79.7%)\nNY 4,798 (17.5%) 21,896 (79.9%)\nLA 708 (15.6%) 3,708 (81.7%)\nSD 82 (15.4%) 439 (82.4%)whose political ideology and location could be known. De-\nspite troves of data were collected and analyzed, various\nencountered biases could not be adjusted for.\n\u2022The second main issue is consistency in the analysis: the\nsensitivity to choices made when carrying out data clean-\ning, parameter settings of inference algorithms, etc. yield\na so-called garden of forking paths [27]: some results can\nsignificantly vary in function of such choices (for example,\nlocation bias and the removal or retention of retweets played\na role in determining whether Texas exhibited a statistical\nanomaly in terms of expected versus cast votes).\n\u2022Political ideologies reported by Gallup significantly vary with\nrespect to that can be inferred on social media. We were un-\nable to determine if this is due to limitations of the employed\npolitical inference tool, population biases, or other factors.\nThis is an open problem in social media analysis and a neces-\nsary one to tackle before social media can be used to robustly\nreplace polling.\n\u2022The actual voting numbers reported by official sources cor-\nrelated very closely to what we inferred from our analysis\non Twitter for 47 of 50 states. As such, the approach seemed\npromising to identify voter suppression or fraud. However,\nthe results show a more complex picture: no evidence of\nfraud or suppression beyond anecdotal was found in the three\nanomalous states under scrutiny. Yet, we suggest that prior\nand during elections there should be an online social media\npresence for the Department of Justice to engage with people\nwho have a potential voting issue.\nCONCLUSION AND FUTURE WORK\nIn this work, we conducted an investigation to analyze social me-\ndia during the 2018 US Midterm election. In addition to studying\nbots and the political ideology of users, we studied the correlation\nbetween people talking about voting and actual voter data. We then\nhighlighted a few issues that could lead to inaccurate conclusions. In\nparticular, removing or retaining the bots didn\u2019t change the outcome\nof our results. This was not the case in prior studies. However, in our\ncase, removing retweets did make a significant difference for one\nstate, Texas, suggesting a dependency, or bias, on location.\nThe challenges we faced can all be expanded upon in future work.\nWe only mapped a state to 44.7% of DS1 and 30.2% to DS2/DS3. If\nwe can evaluate a user timeline to better recognize what state they\nmay be from that would enhance future location based studies. Our\npolitical ideology inference started with the labeling of 38K users\nleveraging any link they posted, and then labels were propagated on\nthe retweet network. We could potentially identify the users with\nhigh centrality and evaluate their timeline for party affiliation and\napproach the inference problem from a different angle. We could\nalso focus on separating not just human from bot accounts, but\nalso human from corporate accounts. Some of the users that were\nclassified as human could be operating as part of a collective body,\nthat while not necessarily malicious, may insert an inorganic bias.\nUltimately, one of the goals of this work was to explore the feasi-\nbility of using social media as a sensor to detect possible election\nmanipulation at scale: despite our initial effort did not produce the\nexpected results, we highlighted some useful lessons that will illu-\nminate on future endeavors to use such data for social good.\nThe Web Conference \u201919, May 14, 2019, San Francisco, CA A. Deb, L. Luceri, A. Badaway, and E. Ferrara\nAcknowledgements . The authors gratefully acknowledge support by the Air Force\nOffice of Scientific Research (award #FA9550-17-1-0327). L. Luceri is funded by the\nSwiss National Science Foundation (SNSF) via the CHIST-ERA project UPRISE-IoT .\nREFERENCES\n[1]Hunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the\n2016 election. Journal of Economic Perspectives 31, 2 (2017), 211\u201336.\n[2]Jon-Patrick Allem, Emilio Ferrara, Sree Priyanka Uppu, Tess Boley Cruz, and\nJennifer B Unger. 2017. E-cigarette surveillance with social media data: social\nbots, emerging topics, and trends. JMIR public health and surveillance (2017).\n[3]Marina Azzimonti and Marcos Fernandes. 2018. Social media networks, fake news,\nand polarization . Technical Report. National Bureau of Economic Research.\n[4]Adam Badawy, Emilio Ferrara, and Kristina Lerman. 2018. Analyzing the Digital\nTraces of Political Manipulation: The 2016 Russian Interference Twitter Campaign.\nInInt. Conference on Advances in Social Networks Analysis and Mining . 258\u2013265.\n[5]Adam Badawy, Kristina Lerman, and Emilio Ferrara. 2018. Who Falls for Online\nPolitical Manipulation? arXiv preprint arXiv:1808.03281 (2018).\n[6]Christopher A Bail, Lisa P Argyle, Taylor W Brown, John P Bumpus, Haohan\nChen, MB Fallin Hunzaker, Jaemin Lee, Marcus Mann, Friedolin Merhout, and\nAlexander V olfovsky. 2018. Exposure to opposing views on social media can\nincrease political polarization. PNAS 115, 37 (2018), 9216\u20139221.\n[7]Alessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US\nPresidential election online discussion. First Monday 21, 11 (2016).\n[8]Olga Boichak, Sam Jackson, Jeff Hemsley, and Sikana Tanupabrungsun. 2018.\nAutomated Diffusion? Bots and Their Influence During the 2016 US Presidential\nElection. In International Conference on Information . Springer, 17\u201326.\n[9]Alexandre Bovet and Hern\u00e1n A Makse. 2019. Influence of fake news in Twitter\nduring the 2016 US presidential election. Nature communications 10, 1 (2019), 7.\n[10] Leo Breiman. 2001. Random forests. Machine learning 45, 1 (2001), 5\u201332.\n[11] Jonathan Chang, Itamar Rosenn, Lars Backstrom, and Cameron Marlow. 2010.\nePluribus: Ethnicity on Social Networks. ICWSM 10 (2010), 18\u201325.\n[12] Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010. You are where you\ntweet: a content-based approach to geo-locating twitter users. In CIKM . 759\u2013768.\n[13] Aron Culotta. 2014. Reducing sampling bias in social media data for county\nhealth inference. In Joint Statistical Meetings Proceedings . 1\u201312.\n[14] Clayton A Davis, Giovanni Luca Ciampaglia, Luca Maria Aiello, Keychul Chung,\nMichael D Conover, Emilio Ferrara, Alessandro Flammini, Geoffrey C Fox, Xi-\naoming Gao, Bruno Gon\u00e7alves, et al .2016. OSoMe: the IUNI observatory on\nsocial media. PeerJ Computer Science 2 (2016), e87.\n[15] Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and\nFilippo Menczer. 2016. Botornot: A system to evaluate social bots. In Proceedings\nof the 25th International Conference Companion on World Wide Web .\n[16] Ritam Dutt, Ashok Deb, and Emilio Ferrara. 2018. \u201cSenator, We Sell Ads\u201d: Anal-\nysis of the 2016 Russian Facebook Ads Campaign. In International Conference\non Intelligent Information Technologies . Springer, 151\u2013168.\n[17] Emilio Ferrara. 2015. Manipulation and abuse on social media. ACM SIGWEB\nNewsletter Spring (2015), 4.\n[18] Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro\nFlammini. 2016. The rise of social bots. Commun. ACM 59, 7 (2016), 96\u2013104.\n[19] Emilio Ferrara, Onur Varol, Filippo Menczer, and Alessandro Flammini. 2016.\nDetection of promoted social media campaigns. In Tenth International AAAI\nConference on Web and Social Media . 563\u2013566.\n[20] Emilio Ferrara and Zeyao Yang. 2015. Measuring emotional contagion in social\nmedia. PloS one 10, 11 (2015), e0142390.\n[21] Emilio Ferrara and Zeyao Yang. 2015. Quantifying the effect of sentiment on\ninformation diffusion in social media. PeerJ Computer Science 1 (2015), e26.\n[22] Daniel Gayo-Avello. 2011. Don\u2019t turn social media into another\u2019Literary Di-\ngest\u2019poll. Commun. ACM 54, 10 (2011), 121\u2013128.\n[23] Daniel Gayo-Avello. 2012. \" I Wanted to Predict Elections with Twitter and all\nI got was this Lousy Paper\"\u2013A Balanced Survey on Election Prediction using\nTwitter Data. arXiv preprint arXiv:1204.6441 (2012).\n[24] Daniel Gayo-Avello. 2012. No, you cannot predict elections with Twitter. IEEE\nInternet Computing 16, 6 (2012), 91\u201394.\n[25] Daniel Gayo-Avello. 2013. A meta-analysis of state-of-the-art electoral prediction\nfrom Twitter data. Social Science Computer Review 31, 6 (2013), 649\u2013679.\n[26] Daniel Gayo Avello, Panagiotis T Metaxas, and Eni Mustafaraj. 2011. Limits of\nelectoral predictions using Twitter. In ICWSM .\n[27] Andrew Gelman and Eric Loken. 2013. The garden of forking paths: Why multiple\ncomparisons can be a problem, even when there is no \u201dfishing expedition\u201d or \u201dp-\nhacking\u201d and the research hypothesis was posited ahead of time. Department of\nStatistics, Columbia University (2013).\n[28] Nir Grinberg, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson, and\nDavid Lazer. 2019. Fake news on Twitter during the 2016 U.S. presidential\nelection. Science 363, 6425 (2019), 374\u2013378.[29] Andrew Guess, Jonathan Nagler, and Joshua Tucker. 2019. Less than you think:\nPrevalence and predictors of fake news dissemination on Facebook. Science\nAdvances 5, 1 (2019), eaau4586.\n[30] Zoltan Hajnal, Nazita Lajevardi, and Lindsay Nielson. 2017. V oter identification\nlaws and the suppression of minority votes. The Journal of Politics 79, 2 (2017).\n[31] Benjamin Highton. 2004. V oter registration and turnout in the United States.\nPerspectives on Politics 2, 3 (2004), 507\u2013515.\n[32] Benjamin Highton and Raymond E Wolfinger. 1998. Estimating the effects of the\nNational V oter Registration Act of 1993. Political Behavior 20, 2 (1998), 79\u2013104.\n[33] Philip N Howard, Gillian Bolsover, Bence Kollanyi, Samantha Bradshaw, and\nLisa-Maria Neudert. 2017. Junk news and bots during the US election: What were\nMichigan voters sharing over Twitter. CompProp, OII, Data Memo (2017).\n[34] Brian Kim. 2003. Help America V ote Act.\n[35] Sneha Kudugunta and Emilio Ferrara. 2018. Deep Neural Networks for Bot\nDetection. Information Sciences 467, October (2018), 312\u2013322.\n[36] David Lazer, Ryan Kennedy, Gary King, and Alessandro Vespignani. 2014. The\nparable of Google Flu: traps in big data analysis. Science 343, 6176 (2014).\n[37] Momin M Malik, Hemank Lamba, Constantine Nakos, and Jurgen Pfeffer. 2015.\nPopulation bias in geotagged tweets. People 1, 3,759.710 (2015), 3\u2013759.\n[38] Panagiotis T Metaxas, Eni Mustafaraj, and Dani Gayo-Avello. 2011. How (not) to\npredict elections. In 3rd International Conference on Social Computing . 165\u2013171.\n[39] Lorraine C Minnite. 2017. The myth of voter fraud . Cornell University Press.\n[40] Alan Mislove, Sune Lehmann, Yong-Yeol Ahn, Jukka-Pekka Onnela, and J Niels\nRosenquist. 2011. Understanding the Demographics of Twitter Users. ICWSM\n(2011).\n[41] Bjarke M\u00f8nsted, Piotr Sapie \u02d9zy\u00b4nski, Emilio Ferrara, and Sune Lehmann. 2017.\nEvidence of Complex Contagion of Information in Social Media: An Experiment\nUsing Twitter Bots. Plos One 12, 9 (2017), e0184148.\n[42] Fred Morstatter, J\u00fcrgen Pfeffer, Huan Liu, and Kathleen M Carley. 2013. Is\nthe Sample Good Enough? Comparing Data from Twitter\u2019s Streaming API with\nTwitter\u2019s Firehose. In ICWSM .\n[43] Frederick Mosteller and Leonard William Doob. 1949. The pre-election polls of\n1948 . Social Science Research Council.\n[44] Gordon Pennycook and David G. Rand. 2018. Lazy, not biased: Susceptibility\nto partisan fake news is better explained by lack of reasoning than by motivated\nreasoning. Cognition (2018).\n[45] Gordon Pennycook and David G Rand. 2019. Cognitive reflection and the 2016\nUS presidential election. Personality and Social Psychology Bulletin 45, 2 (2019).\n[46] Nathaniel Persily. 2017. The 2016 US Election: Can democracy survive the\ninternet? Journal of democracy 28, 2 (2017), 63\u201376.\n[47] Evaggelia Pitoura, Panayiotis Tsaparas, Giorgos Flouris, Irini Fundulaki, Panagio-\ntis Papadakos, Serge Abiteboul, and Gerhard Weikum. 2018. On Measuring Bias\nin Online Information. ACM SIGMOD Record 46, 4 (2018), 16\u201321.\n[48] Derek Ruths and J\u00fcrgen Pfeffer. 2014. Social media for large studies of behavior.\nScience 346, 6213 (2014), 1063\u20131064.\n[49] Dietram A Scheufele and Nicole M Krause. 2019. Science audiences, misinfor-\nmation, and fake news. PNAS (2019), 201805871.\n[50] Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol, Kai-Cheng Yang,\nAlessandro Flammini, and Filippo Menczer. 2018. The spread of low-credibility\ncontent by social bots. Nature communications 9, 1 (2018), 4787.\n[51] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news\ndetection on social media: A data mining perspective. ACM SIGKDD Explorations\nNewsletter 19, 1 (2017), 22\u201336.\n[52] Massimo Stella, Emilio Ferrara, and Manlio De Domenico. 2018. Bots increase ex-\nposure to negative and inflammatory content in online social systems. Proceedings\nof the National Academy of Sciences 115, 49 (2018), 12435\u201312440.\n[53] Onur Varol, Emilio Ferrara, Clayton A Davis, Filippo Menczer, and Alessan-\ndro Flammini. 2017. Online human-bot interactions: Detection, estimation, and\ncharacterization. In Int. AAAI Conference on Web and Social Media . 280\u2013289.\n[54] Onur Varol, Emilio Ferrara, Filippo Menczer, and Alessandro Flammini. 2017.\nEarly Detection of Promoted Campaigns on Social Media. EPJ Data Science 6,\n13 (2017).\n[55] Soroush V osoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false\nnews online. Science 359, 6380 (2018), 1146\u20131151.\n[56] Tova Wang. 2012. The politics of voter suppression: Defending and expanding\nAmericans\u2019 right to vote . Cornell University Press.\n[57] Matthew L Williams, Pete Burnap, and Luke Sloan. 2017. Crime sensing with\nbig data: The affordances and limitations of using open-source communications to\nestimate crime patterns. The British Journal of Criminology 57, 2 (2017).\n[58] Samuel C Woolley and Douglas R Guilbeault. 2017. Computational propaganda\nin the United States of America: Manufacturing consensus online. Computational\nPropaganda Research Project (2017), 22.\n[59] Kai-Cheng Yang, Onur Varol, Clayton A Davis, Emilio Ferrara, Alessandro Flam-\nmini, and Filippo Menczer. 2019. Arming the public with AI to counter social\nbots. Human Behavior and Emerging Technologies 1, 1 (2019).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Perils and challenges of social media and election manipulation analysis: The 2018 us midterms", "author": ["A Deb", "L Luceri", "A Badaway", "E Ferrara"], "pub_year": "2019", "venue": "\u2026 of the 2019 world wide web \u2026", "abstract": "One of the hallmarks of a free and fair society is the ability to conduct a peaceful and seamless  transfer of power from one leader to another. Democratically, this is measured in a citizen"}, "filled": false, "gsrank": 645, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3308560.3316486", "author_id": ["WO95x00AAAAJ", "veoVwKwAAAAJ", "", "0r7Syh0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:xsCh_PtwYpEJ:scholar.google.com/&output=cite&scirp=644&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D640%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=xsCh_PtwYpEJ&ei=erWsaPG6EvnSieoPxKLpgQ0&json=", "num_citations": 100, "citedby_url": "/scholar?cites=10476059910794756294&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:xsCh_PtwYpEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1902.00043"}}, {"title": "Opinion Mining and Clusters Detection in Online Public Debates: a Quantitative Analysis", "year": "2022", "pdf_data": "UNIVERSIT\u00c0\nDEGLI STUDI\nDI BRESCIADOTTORATO DI RICERCA IN INGEGNERIA DELL\u2019INFORMAZIONE\nXXXIV CICLO\nOpinion Mining and Clusters Detection in Online Public\nDebates: a Quantitative Analysis\nAlessandro Galeazzi\nRelatore:\nProf. Francesco Gringoli, Universit `a degli Studi di Brescia\nCorrelatore:\nProf. Walter Quattrociocchi, Universit `a degli Studi di Roma \u201cLa\nSapienza\u201d\nSettore Scienti\ufb01co Disciplinare ING-INF/03\n\nThe dissertation of Alessandro Galeazzi is approved.\nAdvisor:\nProf. Francesco Gringoli, University of Brescia\nCo-advisor:\nProf. Walter Quattrociocchi, \u201cLa Sapienza\u201d University of Rome\nThe dissertation of Alessandro Galeazzi has been reviewed by:\nProf. Petra Kralj Novak, Department of Network and Data Science, Central Euro-\npean University, Austria\nProf. Andrea Gabrielli, Department of Engineering, University Roma Tre, Italy\n\ni\nTABLE OF CONTENTS\nAcknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\nVita and Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii\nChapter 1: Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 State of the Art . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.2 Advances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\nChapter 2: Methods and Datasets . . . . . . . . . . . . . . . . . . . . . 11\n2.1 Data Download . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.1.1 Twitter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.1.2 Reddit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.1.3 Facebook . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\nii\n2.1.4 Gab . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.1.5 Instagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.1.6 Youtube . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.2 Quantitative Techniques . . . . . . . . . . . . . . . . . . . . . . . 13\n2.2.1 Network Representation . . . . . . . . . . . . . . . . . . . . 14\n2.2.2 Similarity Network Analysis . . . . . . . . . . . . . . . . . . 15\n2.2.3 Latent Ideology . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.2.4 User\u2019s Leaning . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.2.5 Homophily in the Interaction Network . . . . . . . . . . . . 18\n2.2.6 Dynamic Information Spreading Model . . . . . . . . . . . . 18\n2.2.7 Topic Modeling . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.2.8 Epidemiological Models . . . . . . . . . . . . . . . . . . . . 21\n2.3 Data Processing Tools . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.3.1 URL Classi\ufb01cation . . . . . . . . . . . . . . . . . . . . . . . 23\n2.3.2 Short URL Resolver . . . . . . . . . . . . . . . . . . . . . . 23\n2.3.3 Account Geolocation . . . . . . . . . . . . . . . . . . . . . . 23\niii\nChapter 3: Quantifying the Impact of Misinformation and Bots on Twit-\nter 2019 European Elections Online Debate . . . . . . . . . 25\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n3.2 Results and Discussion . . . . . . . . . . . . . . . . . . . . . . . . 30\n3.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n3.4 Materials and Methods . . . . . . . . . . . . . . . . . . . . . . . . 44\n3.4.1 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . 44\n3.4.2 Account Interactions . . . . . . . . . . . . . . . . . . . . . . 46\n3.4.3 Account Geolocation . . . . . . . . . . . . . . . . . . . . . . 46\nChapter 4: Measuring the Evolution of Polarization and News In\ufb02u-\nencers between Two U.S. Presidential Elections on Twitter . 51\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n4.2.1 News Media on Twitter in 2016 and 2020 . . . . . . . . . . . 55\n4.2.2 News Media In\ufb02uencers . . . . . . . . . . . . . . . . . . . . 61\n4.2.3 Polarization among Twitter Users . . . . . . . . . . . . . . . 72\n4.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\niv\n4.4 Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n4.4.1 News Media URL Classi\ufb01cation . . . . . . . . . . . . . . . . 84\n4.4.2 In\ufb02uencer Type Classi\ufb01cation . . . . . . . . . . . . . . . . . 87\n4.4.3 Similarity Network Analysis . . . . . . . . . . . . . . . . . . 88\n4.4.4 Latent Ideology Estimation . . . . . . . . . . . . . . . . . . 89\nChapter 5: Evaluation of the Echo Chamber Impact on Social Media . 93\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n5.2 Characterizing Echo Chambers in Social Media . . . . . . . . . . . 97\n5.2.1 Operational De\ufb01nitions . . . . . . . . . . . . . . . . . . . . 97\n5.2.2 Implementation on Social Media . . . . . . . . . . . . . . . 99\n5.3 Comparative Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 101\n5.3.1 Polarization and Homophily in the Interaction Networks . . . 102\n5.3.2 Effects on Information Spreading . . . . . . . . . . . . . . . 105\n5.3.3 News Consumption on Facebook and Reddit . . . . . . . . . 108\n5.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n5.5 Materials and Methods . . . . . . . . . . . . . . . . . . . . . . . . 112\nv\n5.5.1 Labelling of Media Sources . . . . . . . . . . . . . . . . . . 112\n5.5.2 Data Availability Statement . . . . . . . . . . . . . . . . . . 113\n5.5.3 Empirical Data Sets . . . . . . . . . . . . . . . . . . . . . . 114\n5.5.4 Dataset Detailed Description . . . . . . . . . . . . . . . . . 115\n5.5.4.1 Reddit . . . . . . . . . . . . . . . . . . . . . . . . . 118\n5.5.5 Analysis for other Datasets . . . . . . . . . . . . . . . . . . 120\n5.5.6 Robustness of the SIR Dynamics . . . . . . . . . . . . . . . 123\nChapter 6: Measuring the Rise of COVID-19 Debate on Social Media . 133\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n6.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n6.2.1 Interaction Patterns . . . . . . . . . . . . . . . . . . . . . . 139\n6.2.2 Information Spreading . . . . . . . . . . . . . . . . . . . . . 141\n6.2.3 Questionable VS Reliable Information Sources . . . . . . . . 144\n6.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n6.4 Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n6.4.1 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . 149\nvi\n6.4.2 Matching Ability . . . . . . . . . . . . . . . . . . . . . . . . 151\n6.4.3 Text Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 153\n6.4.4 Epidemiological Models . . . . . . . . . . . . . . . . . . . . 156\n6.4.5 Linear Regression Coef\ufb01cients . . . . . . . . . . . . . . . . 158\nChapter 7: Conclusion and Future Works . . . . . . . . . . . . . . . . . 159\n7.1 Summary of Key Findings . . . . . . . . . . . . . . . . . . . . . . 159\n7.2 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\nAppendix A: Tables for Measuring the Evolution of Polarization and\nNews In\ufb02uencers between two U.S. Presidential Elections\non Twitter . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\nvii\nACKNOWLEDGEMENTS\nI would like to thank Francesco Gringoli and Walter Quattrociocchi for their pre-\ncious advice, extraordinary commitment and patient guidance throughout my re-\nsearch.\nI am thankful to all the people I had the opportunity to work with. Niccol `o Di\nMarco, Carlo Michele Valensise, and Fabiana Zollo deserve a special mention.\nGabriele Etta went beyond being an exceptional colleague and became a good\nfriend. I am also profoundly in debt to Matteo Cinelli for being an incredible\nguide, a wonderful colleague, and, most of all, a sincere friend.\nA big thank you to all my friends and teammates, who patiently listened to count-\nless unsolicited and unnecessary explanations of my work. I am grateful to Gio-\nvanna for reading and revising all my abstracts and messy sentences. I am in debt\nto my old friend Chiara, for helping me survive since high school, without asking\nanything back. A shout-out to \u201dI Fioi del Negroni\u201d who were always available to\nuplift me and share good times.\nI also thank my parents and brothers, whose encouragement was fundamental in\nreaching this goal.\nLastly, a very special thought to Francesca. Her absolute trust in my abilities\nand unconditional support during the bad days of these years contributed to this\nviii\nachievement at least as much as I did.\nThis thesis would have never been possible without them.\nix\nVita\n2016\nB.Sc. in Ingegneria dell\u2019informazione\n108/110\nUniversity of Padova, Padova, Italy\n2018\nM.Sc. in ICT for Internet and Multimedia\n110/110 cum laude\nUniversity of Padova, Padova, Italy\n2018\nM.Sc. in Communication Engineering\nNational Taiwan University, Taipei, Taiwan\nx\nPublications\n[1] M. Gentil, A. Galeazzi, F. Chiariotti, M. Polese, A. Zanella, M. Zorzi, \u201cA\nDeep Neural Network Approach for Customized Prediction of Mobile De-\nvices Discharging Time\u201d, GLOBECOM 2017-2017 IEEE Global Communi-\ncations Conference , 1-6\n[2] M. Cinelli, S. Cresci, A. Galeazzi, W. Quattrociocchi, M. Tesconi, \u201cThe lim-\nited reach of fake news on Twitter during 2019 European elections\u201d, PloS\none15 (6), e0234689\n[3] G. Bonaccorsi, F. Pierri, M. Cinelli, A. Flori, A. Galeazzi, F. Porcelli, A.L.\nSchmidt, C.M. Valensise, A. Scala, W. Quattrociocchi, F. Pammolli, \u201cEco-\nnomic and social consequences of human mobility restrictions under COVID-\n19\u201d, Proceedings of the National Academy of Sciences 117 (27), 15530-\n15535\n[4] P. Galeazzi, A. Galeazzi, \u201cThe ecological rationality of decision criteria\u201d,\nSynthese , 1-24\n[5] M. Cinelli, W. Quattrociocchi, A. Galeazzi, C.M. Valensise, E. Brugnoli,\nA.L. Schmidt, P. Zola, F. Zollo, A. Scala, \u201cThe COVID-19 Social Media\nInfodemic\u201d, Scienti\ufb01c Reports 10 (16598 (2020))\n[6] M. Cinelli, G.D.F. Morales, A. Galeazzi, W. Quattrociocchi, M. Starnini,\n\u201cThe echo chamber effect on social media\u201d, Proceedings of the National\nAcademy of Sciences 118 (9)\n[7] A. Galeazzi, L. Badia, S.-C. Chang and F. Gringoli, \u201cReputation-Based Spec-\ntrum Data Fusion against Falsi\ufb01cation Attacks in Cognitive Networks\u201d, 19th\nMediterranean Communication and Computer Networking Conference (Med-\nComNet) , 2021\nxi\n[8] A. Galeazzi, M. Cinelli, G. Bonaccorsi, F. Pierri, A.L. Schmidt, A. Scala, F.\nPammolli, W. Quattrociocchi, \u201cHuman mobility in response to COVID-19 in\nFrance, Italy and UK\u201d, Scienti\ufb01c Reports 11 (1),1-10\n[9] C.M. Valensise, A. Serra, A. Galeazzi, G. Etta, M. Cinelli, W. Quattrociocchi,\n\u201cEntropy and complexity unveil the landscape of memes evolution\u201d, Scien-\nti\ufb01c Reports 11, 20022 (2021)\n[10] G. Etta, M. Cinelli, A. Galeazzi, C.M. Valensise, M. Conti, W. Quattro-\nciocchi, \u201cNews consumption and social media regulations policy\u201d, arXiv\npreprint, arXiv:2106.03924 (Under Review)\n[11] C.M. Valensise, M. Cinelli, M. Nadini, A. Galeazzi, A. Peruzzi, G. Etta, F.\nZollo, A. Baronchelli, W. Quattrociocchi, \u201cLack of evidence for correlation\nbetween COVID-19 infodemic and vaccine acceptance\u201d, [Under Review]\n[12] J. Flamino, A. Galeazzi, S. Feldman, M.W. Macy, B. Cross , Z. Zhou, M.\nSera\ufb01no, A. Bovet, H.A. Makse, B.K. Szymanski, \u201cTwitter In\ufb02uencers and\nIncreased Polarization during two U.S. Presidential Elections\u201d, (Under re-\nview)\nxii\nAbstracts & Posters\n[1] A. Galeazzi, \u201cHuman mobility in response to COVID-19 in France, Italy and\nUK\u201d, Urban Complex Systems 2020 , 2020\nPresentations\n[1] A. Galeazzi, \u201cHuman mobility in response to COVID-19 in France, Italy and\nUK\u201d, Urban Complex Systems 2020 , December 2020\n[2] A. Galeazzi, \u201cReputation-Based Spectrum Data Fusion against Falsi\ufb01cation\nAttacks in Cognitive Networks\u201d, 19th Mediterranean Communication and\nComputer Networking Conference (MedComNet) , June 2020\nxiii\nABSTRACT\nThe advent of online platforms dramatically changed the way people create and\ncommunicate content. In online social media, users can easily share information\nthat thousands of peers may consume almost immediately. Moreover, the unique\nfeatures offered by online social platforms also allow immediate feedback and\ninteractions, creating the perfect environment for the proliferation of an intense\ndebate around controversial topics. Nevertheless, this new and disintermediated\ntype of communication and platforms\u2019 feed algorithms may in\ufb02uence the dynam-\nics of online discussion, creating a fertile environment for the formation of clusters\nof users reinforcing their opinion through repeated interactions called echo cham-\nbers.\nIn this thesis, we study the debate around controversial topics in online social\nmedia, such as political elections and disease outbreaks, and analyze the factors\nin\ufb02uencing its dynamics. We also assess the impact of unsubstantiated rumors\nand measure the shift in polarization around political elections. Finally, we com-\npare the effect of echo chambers around several topics and across different social\nxiv\nmedia and quantify the online infodemic concurrent with the recent pandemic.\nIn our studies, we \ufb01nd evidence that users tend to cluster together into groups\nwith opposite opinions around debated topics and consume information adhering\nto their system of beliefs. This characteristic appears to dominate the informa-\ntion consumption dynamics in online social media, in\ufb02uencing the spread of both\ncon\ufb01rmed news and unsubstantiated rumors.\nxv\nSOMMARIO\nLa nascita di piattaforme online tramite cui condividere informazioni con una\nplatea virtualmente illimitata ha radicalmente cambiato il modo di comunicare.\nAttraverso i social media, chiunque `e in grado di creare contenuti che non solo\nsono fruiti quasi in tempo reale da migliaia di utenti, ma che, grazie alle funzioni\nofferte dalle varie piattaforme online, possono ottenere un feedback immediato\ntramite commenti e reazioni. Questa modalita\u2019 di comunicazione veloce e disin-\ntermediata, da un lato, fornisce il mezzo perfetto per la proliferazione di dibattiti\nsu temi controversi, dall\u2019altro, grazie anche alla presenza di algoritmi che riducono\nla diversita\u2019 dei contenuti a cui un utente `e esposto, crea l\u2019ambiente perfetto per la\nformazione di gruppi ideologicamente omogenei di persone, de\ufb01niti echo cham-\nbers. In questi ambienti, grazie a ripetute interazioni con altri ideologicamente\naf\ufb01ni, gli utenti sono esposti a una visione parziale e omogenea dell\u2019argomento\ndibattuto, che li porta a rinforzare la propria opinione preesistente e ignorare po-\nsizioni contrarie.\nQuesta tesi si pone l\u2019obiettivo di analizzare molteplici aspetti che in\ufb02uenzano\nxvi\nil dibattito online. In particolare, `e stata studiata l\u2019evoluzione del dibattito nei\nsocial media riguardo argomenti controversi quali elezioni politiche e pandemia,\nevoluzione della polarizzazione e impatto di notizie non veri\ufb01cate sulle elezioni\npresidenziali americane, la presenza di echo chambers in varie piattaforme e at-\ntorno diversi argomenti di dibattito; `e stata inoltre misurata la magnitudo dell\u2019\n\u201cinfodemia\u201d concomitante con la recentente pandemia. Lo studio dimostra come\ngli utenti, quando dibattono sui social media attorno ad argomenti controversi, ten-\ndono ad aggregarsi in fazioni ideologicamente opposte, consumando informazioni\nche rinforzano la loro visione e ignorando altri punti di vista. Questa caratteristica\nsembra dominare il consumo di informazioni online, in\ufb02uenzando la diffusione\nsia di contenuti fondati sia di informazioni non veri\ufb01cate.\n1\nCHAPTER 1\nINTRODUCTION\nOnline social media platforms allow us to create and communicate content to an\nincredible amount of people and these interactions are the source of a huge amount\nof information about several users\u2019 characteristics. Thus, these digital traces can\nbe exploited to study people\u2019s behavior in online social media and this new per-\nspective attracted many researchers from various disciplines proposing different\napproaches to enhance this emerging \ufb01eld.\nIn this thesis, we use several techniques to perform quantitative analyses of\nsocial media data for studying different aspects of users\u2019 behavior on online plat-\nforms. In particular, we rely on complex network theory to highlight interaction\nstructures among users, we use a source-based approach to estimate misinforma-\ntion circulation, we perform statistical analysis on information diffusion patterns\nand use epidemiological models to mimic the news spreading dynamic, and we\nemploy arti\ufb01cial intelligence techniques to perform semantic analysis on text. The\nscope of this work is to understand the role that several factors have in the diffusion\nof information, ranging from the characteristic of the content itself to the topolog-\nical aspect of the diffusion network and the impact of the automated accounts and\n2\nsuggestion algorithms.\n1.1 State of the Art\nThe advent of the internet has radically changed many aspects of our daily life.\nNowadays, people use online resources in the most diverse areas of their life, from\nwork to entertainment. One of the most renewed aspects is how users access, con-\nsume and interact with information. In the past, the information \ufb02ow, and thus the\nagenda setting, was mainly unidirectional from the source (such as newspapers\nor tv programs) to the audience. Now, people are not just exposed to a plethora\nof different information sources but can also produce, share and communicate\ntheir original contents in a disintermediated, or at least algorithm mediated, way.\nThroughout online social media, users can create and share contents potentially\nwith the entire society. Moreover, the unique features implemented in such plat-\nforms allow users to interact among themselves and receive immediate feedback\non what they publish.\nThis new way of producing and sharing content dramatically changed the paradigm\nof accessing and consuming information: it democratized the information market\npotentially making every user also a publisher. However, this change in the infor-\nmation consumption dynamic brought new potential threats to the public society.\nIn particular, disinformation and misinformation, that is, the spread of inaccurate\n3\nor false information, has become a problem of primary interest to the point that\nthe World Economic Forum listed it as one of the most critical threats of our soci-\nety [1].\nThus, the spread of fake news has attracted the attention of many researchers\nfrom various \ufb01elds and several aspects of rumors spreading dynamics and online\nnews consumption have been investigated. In particular, one thread of research\nfocused on the data-driven modeling of factors in\ufb02uencing the spreading of true\nand false news. In [2] authors studied the spreading of rumors on Facebook and\nshowed that polarization is one of the main drivers of news spreading. Authors\nof [3] studied the news consumption pattern on Facebook showing that users tend\nto interact with a limited set of pages, while Cinelli et al. investigated the users\u2019\nnews consumption and \ufb01nd that selective exposure, i.e. the tendency of users to ac-\nquire only information that adheres to their beliefs, dominates the Facebook news\nconsumption patters [4]. Also, authors of [5] studied the news consuming behav-\nior of 10 million of Facebook users and found that the exposure to ideologically\ndiverse content is limited by personal choices more than algorithmic factors.\nTogether with the analysis of users\u2019 news consumption patterns, which high-\nlighted the role of human behaviors such as selective exposure and selection bias\nin limiting the exposition to opposite opinions, researchers also studied the topo-\nlogical structures that in\ufb02uence the spread of information and misinformation.\n4\nEcho Chambers. One of the most popular concepts in this area is the idea\nof echo chambers [2], [6]\u2013[10]. Intuitively, an echo chamber can be de\ufb01ned as\na group of users that interact among themselves on a debated topic and reinforce\ntheir opinion due to repeated contacts with others sharing the same beliefs. Re-\ncently, both the existence and the impact on the news spreading dynamics of echo\nchambers have been questioned [11]\u2013[13] revealing that the debate about such a\nstructure and its possible effect on news consumption dynamics is still open in the\nacademic community.\nSocial Bots. Another aspect that has attracted the attention of researchers is the\nin\ufb02uence of automated accounts on the spread of true and false news. Authors of\n[14] compared the spread of information and misinformation in Twitter and found\nthat automated accounts (bot) play a limited role, while in [15] authors claim that\nbots play a substantial role in the spread of low credibility content. These opposite\nresults may derive from the different de\ufb01nitions of what misinformation is and\nshow that more research has to be done to clarify online spreading dynamics [16].\nMisinformation and Society. All the attention academics dedicated in study-\ning misinformation and the conditions that may foster its spreading is justi\ufb01ed by\nthe importance this phenomenon has on the public society. Indeed, the in\ufb02uence\nof social media in various aspects of the public society such as political election,\nbehavior adoption, and so on, has been not clari\ufb01ed yet and concerns about the\n5\npossible negative effects on the democratic process have been raised. For ex-\nample, researchers studied the in\ufb02uence of fake news and bots on the 2016 U.S.\npresidential election on Twitter and found that bots and misinformation may have\nharmed the online debate [17]. However, Bovet et al. found that users\u2019 propen-\nsity to consume fake news may depend on their political leaning [18] and authors\nof [19] showed that misinformation is consumed mainly by a small portion of\nusers with well-de\ufb01ned characteristics. Nevertheless, the concern about the neg-\native in\ufb02uence of social media on the outcome of political elections has been so\nhigh that in 2019 Twitter announced it would not allow any political advertise-\nment on the platform [20]. The in\ufb02uence of fake news and bots on the public\ndebate has been under the attention of governments and academia also in many\nother circumstances, such as Brexit and 2019 European elections [21]\u2013[23]. More\nrecently, the concern about the impact of misinformation about COVID-19 has\nbeen so high that WHO immediately launched an online platform to mitigate the\nphenomenon [24].\nThe spread of misinformation and its consequences are not the only threats that\nonline social media could bring to public society, but also the fragmentation of the\nonline ecosystem into echo chambers with opposite views has been a reason of\nconcern for the public society [25]. Indeed, the idea that online social media may\nfoster polarization and increase the ideological distance between opposite factions\n6\nhas gained momentum due to events such as the Pittsburgh synagogue shooting\nor the Christchurch mosque shooting [26]. For example, in the \ufb01rst case, the au-\nthor of the attack was very active on Gab, a far-right social media that performs\nlittle control on the content posted [27], and the same platform has been consid-\nered responsible for the dissemination of the video of the Christchurch attack[28].\nMore recently, social media have been suspected to have fostered the capitol hill\nriot [29], [30], where some Trump supporters occupied the United States Capitol\nto stop the formalization of Joe Biden\u2019s victory. Part of the public opinion consid-\nered this event as the consequence of the tweets and declaration made by Trump\nin the months before the formalization date in which he sustained the presence of\nelectoral fraud and denied to admit Joe Biden victory [31]. Trump was also for-\nmally impeached for \u201cincitement of insurrection\u201d by the U.S. Congress, moreover\nFacebook and Twitter banned his account because \u201cthe risks of allowing President\nTrump to continue to use our service during this period are simply too great\u201d [32]\nand \u201cdue to the risk of further incitement of violence\u201d [33]. This unprecedented\ndecision on the one hand triggered the protests against \u201cBig Tech censorship\u201d [34],\non the other hand, highlighted the lack of understanding and regulation of the in-\nterplay between online social media and of\ufb02ine public society.\n7\n1.2 Advances\nIn this thesis, we analyze the online debate around controversial themes of pub-\nlic interest, such as political elections or COVID-19 outbreaks, quantifying the\npresence and the impact of misinformation on online discussion. We also study\nthe effect of news feed algorithms on polarization and how they may affect the\nspreading of information and misinformation. We rely on data taken from main-\nstream social media such as Twitter, Facebook, and Youtube as well as less know\nplatforms such as Gab. The idea of using digital traces to study users\u2019 online be-\nhavior can be traced back to [35], in which the concept of computational social\nscience is introduced. One advantage of this approach is that it allows researchers\nto rely on an amount of data that was not available using other research meth-\nods such as surveys or lab experiments. Moreover, some psychology and social\nsciences studies that exploited surveys or lab experiments as research technique\nmay suffer from reproducibility issue [36], [37]. Recently, through the analysis\nof social media data, researches obtained relevant insights on various aspects of\nonline human behavior, such as bounds on the users\u2019 maximum number of con-\ntacts [38], news diet and selection bias [4], [5], polarization around debated topics\nand controversial events[3], [18], [39]\u2013[41], and echo chambers [42]\u2013[44]. Never-\ntheless, the debate in the academic community is still open and several aspects of\n8\nusers\u2019 online behavior are still to be clari\ufb01ed. For instance, most of these studies\nfocused only on one platform, and hence their result may not hold for other social\nmedia. Second, the environment itself is subject to changes over time: social plat-\nforms may occasionally modify their feed algorithms, their policy on the contents\nallowed, or their features. Although caution should be taken when generalizing\nthe knowledge obtained from social media data, research exploiting this method-\nology is providing us important insights on events, such as political elections or\nCOVID-19 outbreak, in almost real-time.\nIn this thesis, we present a series of works addressing different aspects of online\nsocial media. First, we study the interaction patterns of different public \ufb01gures\nduring the 2019 European elections, showing the limited circulation fake news\nhad during the electoral campaign. Second, we analyze the difference in the debate\naround the 2016 and 2020 U.S. presidential elections on Twitter, assessing the role\nof automated accounts and quantifying the differences in terms of polarization. We\ncontinue our study with a comparative analysis of the polarization and the echo\nchamber effect on four social media around several debated topics, highlighting\nclues for the feed algorithms effect on users\u2019 segregation. Finally, we analyze the\ndramatic increase in the amount of news about COVID-19 shared at the beginning\nof the \ufb01rst virus outbreak, focusing on the differences and similarities in the spread\ndynamic of information and misinformation.\n9\nOur research shows that users tend to cluster into groups with homogeneous\nbeliefs around debated topics. Such a structure, called echo chambers, may be\nfostered by different factors, one of which is the platform feed algorithms. Indeed,\na stronger feed algorithm may enhance the segregation of users according to their\nbeliefs and reduce the exposure to opposite contents, fostering the echo chamber\neffect. Moreover, we found that online misinformation tends to circulate among\nspeci\ufb01c clusters of users and its volume is far lower with respect to reliable in-\nformation. In general, most users rarely interact with misinformation sources, but\nsome strongly endorse this kind of content and are very prone to share them. This\nis coherent with the presence of echo chambers, in some of which misinformation\nmay easily proliferate. Nevertheless, the limited reach of fake news may be also\nthe consequence of the policies adopted by online platforms to limit the spread of\nsuch contents. Finally, our results about the COVID-19 debate show that misin-\nformation and reliable information have comparable spreading patterns. Although\nthe share of misinformation circulating changes from platform to platform, the\ndynamic diffusion is the same for both reliable and questionable contents.\nThe rest of this thesis is structured as follow: Chapter 2, 3, 4 and 5 are dedicated\nto the works about 2019 European Elections, U.S. 2020 presidential election, echo\nchamber effect, and COVID-19 infodemic respectively. In chapter 5 conclusions\nand future work are presented, while in Appendices A,B and C reports tables and\n10\nstatistics of the dataset used in the studies.\n11\nCHAPTER 2\nMETHODS AND DATASETS\nThe works presented in this thesis required several techniques to gather and ana-\nlyze the datasets. In this section, we present an overview of the methods used for\ndownloading, processing, and analyzing the data.\n2.1 Data Download\nThis section is dedicated to summarizing the techniques used for gathering data\nfrom different platforms, which can vary from the use of of\ufb01cial API to scrap-\ning. However, to be compliant with the legislation and the terms of services only\npublicly available information has been downloaded from each platform.\n2.1.1 Twitter\nTwitter provides an of\ufb01cial API documented at https://developer.twitter.\ncom/en/docs to retrieve different contents. Their API allows searching for\ntweets matching speci\ufb01c keywords, users details, follower-following relationships,\nand engagement information. However, Twitter applies limitations in terms of\nboth the rate limit and the amount of information that can be downloaded.\n12\n2.1.2 Reddit\nReddit provides an of\ufb01cial API that allows access to several types of publicly\navailable content, such as submissions and subreddit data, user information, and\nengagement details. Moreover, the website https://pushshift.io/ pro-\nvides a near real-time mirroring of all public available Reddit content, accessible\nvia a registration-free API.\n2.1.3 Facebook\nFacebook provided the Facebook Graph API to access their publicly available\ndata. Together with data on public available posts, this API allowed to retrieve\nalso user-level information, such as likes on posts, replies, and so on. Currently,\nthis API has been dismissed.\n2.1.4 Gab\nGab does not have any of\ufb01cially documented API, but it is still possible to down-\nload data directly querying the website. However, the rate limit bounds severely\nimpact the amount of information accessible. To overcome this problem, we de-\nveloped a multi IP parallel crawler to stream all the contents in near real-time.\nMoreover, a dataset containing one year of Gab post is available at the website\nhttps://pushshift.io/ .\n13\n2.1.5 Instagram\nSince no of\ufb01cial API are available for Instagram data, we built our process to\ncollect public content related to our keywords and we manually took notes of\nposts, comments to populate the Instagram Dataset.\n2.1.6 Youtube\nYoutube data can be collected with the of\ufb01cial API documented at https://\ndevelopers.google.com/youtube/v3 . This API provides access to dif-\nferent contents such as channel information, comments under videos, and video\nstatistics. Although it is not possible to directly search for videos containing one\nor more keywords in the title or description, an endpoint that returns a list of video\nrelated to speci\ufb01c keywords is provided.\n2.2 Quantitative Techniques\nIn this section, we provide an overview of the various techniques we used to ana-\nlyze the data. To overcome the heterogeneous challenges faced in our research, we\nadopt several methods from different sectors such as computer science, complex\nnetworks theory, statistics, epidemiology, and machine learning.\n14\n2.2.1 Network Representation\nIn our work, we frequently use network representation to represent interaction pat-\nterns among entities. We build directed and undirected networks to characterize\nrelationships among users, while we rely on bipartite networks to represent rela-\ntionships between users and other entities.\nDirected networks are built using, for instance, retweets, follower-following,\nor other interaction information. In such cases, nodes represent users and edges\nrepresent interactions. Edges\u2019 direction can vary depending on the type of the\nconsidered relationship and the purpose of the study.\nUndirected networks are used to represent symmetric relationships such as co-\ncommenting or co-liking. In these networks, nodes represent users, and two users\nare connected if and only if they performed the same action, for example com-\nmenting under the same post. In such cases, the direction of an edge is not mean-\ningful nor possible to assess.\nBipartite networks are used to represent interactions between different types\nof entities, for example between users and posts or users and domains. In these\ncases, the two entities are represented by two different types of nodes and edge\nrepresenting relationships between entities can connect only nodes of two different\ntypes.\n15\n2.2.2 Similarity Network Analysis\nIn our work, we use similarity network analysis to identify clusters of in\ufb02uential\nusers based on the audience they reach. For each user iin the set of I=f1;:::;ing,\ncalled the set of in\ufb02uencers, we create a vector~Siof sizeU, where U is the size\nof the set of unique users in our dataset. Given a user u2Uand and in\ufb02uencers i,\nthe element si\nuof vector~Side\ufb01nes the number of times user uhas interacted with\nin\ufb02uenceri. We de\ufb01ne the adjacency matrix Aof sizeI\u0002Ifor our similarity net-\nworks by setting ai;jto the cosine similarity between vectors~Siand~Sj. It follows\nthat the higher the cosine similarity, the more users have the similar number of in-\nteractions for in\ufb02uencers i;j. An undirected weighted network is created using the\nadjacency matrix Aand communities are detected by the Louvain algorithm [45].\nWe quantify the severity of community splitting using two measures of separa-\ntion between communities. The \ufb01rst is modularity, which computes the sum of the\ndifference between the fraction of edges within each community and such fraction\nexpected within this community in a random network with the same number of\nnodes and edges. This metric has a range of [\u00000:5;1][46]. A positive value in-\ndicates the presence of communities separated from each other, and the closer the\nmodularity is to 1, the stronger communities are separated.\nThe second measure uses the normalized cut, which is the sum of the weights\n16\nof every edge that links a pair of communities divided by the sum of the weights of\nall edges. The result has a range of [0;1]where the smaller the value, the stronger\nthe separation among communities.\n2.2.3 Latent Ideology\nThe latent ideology estimation allows inferring the ideological position of users\naround a debated topic and is based on users\u2019 interactions such as likes, retweets,\nmentions, comments, and so on. It follows the method developed in [12], [47], and\nwe use correspondence analysis [48] (CA) to infer users\u2019 ideological positions, as\ndone in [12].\nLetAbe the adjacency matrix of the network between a set of users called\nin\ufb02uencers and all the users that interacted with them. The element aijofAis\nequal to the number of times user iinteracted with in\ufb02uencer j.\nThe CA method is executed in the following steps [49]. The matrix of standard-\nized residuals of the adjacency matrix is computed as S=D\u00001=2\nr(P\u0000rc)D\u00001=2\nc,\nwhere P=A(P\nijaij)\u00001is the adjacency matrix normalized by the total num-\nber of interactions, r=P1is the vector of row sums, c=1TPis the vector of\ncolumn sums, Dr=diag(r)andDc=diag(c). Using the standardized residuals\nallows the inference to account for the variation of popularity and activity of the\nin\ufb02uencers and the users, respectively [12]. Then, a SVD is computed such that\n17\nS=UD\u000bVTwithUUT=VVT=IandD\u000bbeing a diagonal matrix with the\nsingular values on its diagonal. The positions of the users are given by the standard\nrow coordinates: X=D\u00001=2\nrUwhere we only consider the \ufb01rst dimension, cor-\nresponding to the largest singular value. Finally, the ideological positions of the\nusers are found by standardizing the row coordinates to have a mean of zero and a\nstandard deviation of one. The ideological position of the in\ufb02uencers is given by\nthe median of the weighted positions of their audience.\n2.2.4 User\u2019s Leaning\nIn our work, one of the most frequently required tasks is the quanti\ufb01cation of\nusers\u2019 leaning around debated topics through the analysis of the content they pro-\nduced. We measure the individual leaning of a useritoward a speci\ufb01c topic xi\nthrough the analysis of the content it produced. Let aibe the number of contents\nproduced by user iand de\ufb01neCi=fc1;c2;:::;caigas the set of all contents pro-\nduced byi. The individual leaning of user ican be de\ufb01ned as the average of the\nleanings of produced contents,\nxi\u0011Pai\nj=1cj\nai: (2.1)\n18\n2.2.5 Homophily in the Interaction Network\nGiven a network of users, homophily can be de\ufb01ned as the nodes\u2019 tendency to\ninteract with others with similar characteristics. In network terms, this translates\ninto a nodeiwith a given leaning ximore likely to be connected with nodes with a\nleaning close to xi[10]. In our studies, this concept can be quanti\ufb01ed by de\ufb01ning,\nfor each user i, the average leaning of their neighborhood, as:\nxN\ni\u00111\nk!\niX\njAijxj (2.2)\nwhereAijis the adjacency matrix of the interaction network, Aij= 1if there is a\nlink from node ito nodej,Aij= 0otherwise, and k!\ni=P\njAijis the out-degree\nof nodei. The presence of homophily is assessed by studying the relationship\nxi\u0018xN\ni.\n2.2.6 Dynamic Information Spreading Model\nTo model the spreading dynamics of news and rumors, we leverage on the SIR\nmodel. In the SIR model, each agent can be susceptible, infectious, or recovered.\nSusceptible users may become infectious upon contact with infected neighbors,\nwith a speci\ufb01c transmission probability \f, and infectious users can recover with\nprobability \u0017. We run the SIR dynamics on the interaction networks of users\n19\nstarting the epidemic process with only one node iinfected and stopping it when\nno more infectious nodes are left.\nThe set of nodes in a recovered state at the end of the dynamics started with user\nias a seed of infection, i.e., those that become aware of the information initially\npropagated by user iforms the set of in\ufb02uence of useri,Ii[50]. We de\ufb01ne the\naverage leaning of the set of in\ufb02uence of user i,\u0016i, as\n\u0016i\u0011jIij\u00001X\nj2I ixj: (2.3)\nTo analyze the impact of users\u2019 leaning on information spreading, we de\ufb01ne\nthe average leaning h\u0016(x)iof the in\ufb02uence sets reached by users with leaning x\nand study the relationships h\u0016(x)i\u0018x.\n2.2.7 Topic Modeling\nIn our study, we apply topic modeling to analyze the context around online de-\nbates. We build word embeddings for the text corpus and then we cluster words\nby the Partitioning Around Medoids (PAM) algorithm on their vector representa-\ntions to assess the topics around which the perception of the COVID-19 debate is\nconcentrated.\nOur word embeddings are the distributed representations of words learned by\nneural networks in which each word is represented as a vector in Rn. This repre-\n20\nsentation has the property that similar words are embedded into vectors close to\neach other. Skip-gram model [51] is used to construct word embedding for each\ncorpus. Given the sequence of words w1;w2;:::;wTthat is the representation of\na content, stochastic gradient descent with gradient computed through backpropa-\ngation rule [52] is employed to maximize the average log probability\n1\nTTX\nt=12\n4kX\nj=\u0000klogp(wt+jjwt)3\n5 (2.4)\nwherekis the size of the training window.\nThe Skip-gram model associates an input and output vectors uwandvwto each\nwordw.Thus, we de\ufb01ne the probability of correctly predicting the word wigiven\nthe wordwjas:\np(wijwj) =exp\u0000\nuT\nwivwj\u0001\nVX\nl=1exp\u0000\nuT\nlvwj\u0001(2.5)\nwhereVis the number of words in the corpus vocabulary. The training quality is\naffected mainly by two parameters, namely the dimensionality of word vectors(i.e.\nthe dimension of the word embedding representation space) and the size of the\nsurrounding words window\nTo increase the performance, preprocessing steps in which we remove special\nstrings such as urls, stop-words, and other special charters and patterns are per-\n21\nformed.\nTo identify topics, clustering by using the Partition Around Medioids (PAM)\ntechnique with the cosine distance matrix of words in the vector representation as\nproximity metric is performed. The average silhouette width for different values of\nthe number of clusters kis calculated to select the best values and the cluster sta-\nbility is evaluated by computing the average pairwise Jaccard similarity between\nclusters based on 90% sub-samples of the data. Lastly, we produce word clouds\nto identify the topic of each words cluster.\n2.2.8 Epidemiological Models\nIn our studies, we use two epidemiological models to estimate the infodemic\ngrowth, namely the exponential model of [53] (EXP) and the classical SIR model\n[54] (SIR). The exponential model provides an estimate of the basic reproduction\nnumberR0and has been successfully employed in data-scarce settings and shown\nto be on-par with more traditional compartmental models.\nThe following equation fully describes the model:\nI=\u0014R0\n(1 +d)t\u0015t\n(2.6)\nwhereIis the incidence, tis the number of days, R0is the basic reproduction\nnumber, and dis a damping factor accounting for the transmissibility reduction\n22\nover time. The other model that is used in our work is the classical SIR model\n[54]. In this model, a susceptible population can be infected with a rate \fby\ncoming into contact with infected individuals, but infected individuals can recover\nwith a rate\u0017. The following set of differential equations describe the model:\n@tS=\u0000\fS\u0001I=N\n@tI=\fS\u0001I=N\u0000\u0017I (2.7)\n@tR=\u0017I\nwhereSis the number of susceptible, Iis the number of infected and Ris the\nnumber of recovered.\nR0=\f=\u0017, also known as the basic reproduction number, corresponds to the\nproportion between the rate of infection \fand the rate of recovery \u0017.\nThe basic reproduction numbers REXP\n0 andRSIR\n0for the EXP and the SIR\nmodel are estimated by using least-square estimates of the model parameters[55].\n2.3 Data Processing Tools\nThis section is dedicated to the description of the tools developed and utilized to\nmanipulate our datasets.\n23\n2.3.1 URL Classi\ufb01cation\nOne common task that is frequently performed on datasets is URL classi\ufb01cation.\nRelying on third-party data, we build lists of domains related to the online news\noutlet that contains information about the level of reliability and other feature of\neach source. Thus, from each URL we extract the domains, and then each domain\nis classi\ufb01ed according to the information in our list if present.\n2.3.2 Short URL Resolver\nFrequently, URLs are shortened using shortening URL services such as Bitly or\nCuttly. To extract the domain from such type of URL is \ufb01rst necessary to retrieve\nthe unshortened URL. To resolve shortened URLs, we rely on a tool that sends\nhead requests over the internet for each shortened URL and stores the answer.\nGiven the considerable size of our datasets and in order to speed up the process, a\nmulti-IP parallel approach has been adopted.\n2.3.3 Account Geolocation\nOn online platforms, users may occasionally leave hints about the place they live\nand this information can be used to assign them a location.\nTo perform this task, we exploit several different geolocator services such as\nGoogle Maps, Bing, and GeoNames that offer their services via Web APIs. Thus,\n24\nwe identify geographical hints and used them to query one of the available geolo-\ncators and associated the corresponding geographic coordinates to the correspond-\ning account.\n25\nCHAPTER 3\nQUANTIFYING THE IMPACT OF MISINFORMATION AND BOTS ON\nTWITTER 2019 EUROPEAN ELECTIONS ONLINE DEBATE\nFake news and misinformation have been listed to be a major threat to our society\nand concerns about the possible impact of fake news on the outcome of political\nelection have been raised. Moreover, automated account are suspected of fake\nnews dissemination to in\ufb02uence election results. In this chapter, we analyze the\nimpact of fake news on the 2019 European Elections on Twitter. In particular,\nwe followed the activity of accounts owned by users with different roles in the\npublic society such as politicians, news outlets, and show business personalities.\nWe considered also recognized fake news spreader and analyze the interactions\nwith other actors, providing important insight on the role and the impact of fake\nnews during this election.\n3.1 Introduction\nThe wide diffusion of online social media platforms such as Facebook and Twitter\nraised concerns about the quality of the information accessed by users and about\nthe way in which users interact with each other [2], [39], [40], [56]\u2013[60]. Re-\n26\ncently, the chairman of Twitter announced that political advertisements will be\nbanned from Twitter soon, claiming that our democratic systems are not prepared\nto deal with the negative consequences brought by the power and in\ufb02uence of\nonline advertising campaigns [20]. In this context, a wide body of scienti\ufb01c litera-\nture focused on the in\ufb02uence and on the impact of disinformation and automation\n(i.e., social bots) on political elections [14], [17], [18], [41], [61]\u2013[65]. In [18]\nthe authors studied the impact of fake news on the 2016 US Presidential elections,\n\ufb01nding that users sensitivity to misinformation is linked to their political leaning.\nIn [61] is highlighted that fake news consumption is limited to a very small frac-\ntion of users with well de\ufb01ned characteristics (middle aged, conservative leaning\nand strongly engaged with political news). Authors of [14] studied the spreading\nof news on Twitter in a 10 years time span and found that, although false news\nspread faster and broader than true news, social bots boost false and true news\ndiffusion at the same rate. The pervasive role of social bots in the spread of disin-\nformation was instead reported in [66] for \ufb01nancial discussions, where as much as\n71% of users discussing hot US stocks were found to be bots. The effects of fake\nand unsubstantiated news affected also the outcome of other important events at in-\nternational level. For instance, the evolution of the Brexit debate on Facebook has\nbeen addressed in [67] where evidence about the effects of echo chambers, con\ufb01r-\nmation bias in news consumption and clustering are underlined. Nevertheless, as\n27\nstated in [16], the conclusions of these and other studies are partially con\ufb02icting.\nThis con\ufb02ict can be the result of the differences in the de\ufb01nitions of fake news or\nmisinformation adopted by different authors, that have somewhat contributed in\nswitching the attention from the identi\ufb01cation of fake news to the de\ufb01nition itself.\nIn particular, authors in [2] and [3] focused their attention on the process that\ncan boost the spreading of information over social media. In these works, it is\nhighlighted that phenomena such as selective exposure, con\ufb01rmation bias and the\npresence of echo chambers play a pivotal role in information diffusion and are able\nto shape the content diet of users. Given the central role of echo chambers in the\ndiffusion process, authors of [68] propose a methodology based on users polar-\nization for the early identi\ufb01cation of topics that could be used for creating misin-\nformation. However, in [69] it is stressed that the phenomenon of echo chambers\ncan drive the spreading of misinformation and that apparently there are no simple\nways to limit this problem.\nConsidering the increasing attention paid to the in\ufb02uence of social media on\nthe evolution of the political debate, it becomes of primary interest to understand,\nat a fast pace, how different actors participate in the online debate. Such concerns\nwere renewed in the view of the US Presidential Election of November 2020 or\nthe future national elections in EU countries.\nThe goal of our work is to characterize the information \ufb02ow among different\n28\nactors that took place in the run up to the last European Parliament elections held\nbetween the 23rd and 26th of May, 2019. According to the European legislation,\nevery 5 years all the country members of the EU have to hold elections to renovate\ntheir members at the European Parliament. The election can be held in a temporal\nwindow of few days and every state can decide in which days to hold the vot-\ning procedure. During the electoral campaign, concerns about the impact of fake\nnews on the upcoming European election were risen by several news outlets [21]\nand misinformation have been monitored, also thanks to the effort of NGOs, in\ndifferent platforms [22]. The EU itself started a joint and coordinated action on\nmisinformation mitigation [70]. Based on what happened during Brexit and the\nUS 2016 election, also EU leaders encouraged the adoption of measures at the Eu-\nropean level to counteract the diffusion and impact of Fake News [23]. Additional\nevidence of the potential impact of misinformation during European Election mo-\ntivated studies at national level such as [71]. Starting from these premises, our\nstudy aims to assess the reach of fake news during European Elections. In this\ncontext, we characterize the public debate on Twitter in the months before the\nelections. In particular, we aim at understanding which role was played by users\nthat have different positions in public society, including disinformation outlets and\npopular actors either directly or indirectly related to politics, to obtain a wide view\nof the process. Through a thorough quantitative analysis on a dataset of 399,982\n29\ntweets posted by 863 accounts in the three months before the elections, we \ufb01rst\nanalyze the information \ufb02ow from a geographical point of view and then we char-\nacterize the interactions among different classes of actors. Finally, we compare\nthe impact of disinformation-related accounts with respect to all others. We \ufb01nd\nthat all classes, except of\ufb01cial news outlets, have a strong tendency towards intra-\nclass interaction and that the debate rarely cross the national borders. Moreover,\ndisinformation spreaders have a marginal role in the information exchange and are\nignored by other actors, despite their repeated attempts to join the conversation.\nAlthough the maximum outreach of fake news accounts is lower than that of other\ncategories, when we take into account comparable levels of popularity we observe\nan outreach for disinformation that is larger than that of traditional outlets and\ncomparable to that of politicians. Such evidence demonstrates that disinformation\noutlets have a rather active followers base. However, the lack of interactions be-\ntween fake news accounts and others demonstrated that their user base is con\ufb01ned\nto a peripheral portion of the network, suggesting that the countermeasures taken\nby Twitter, such as suspension or ban of suspicious accounts, might have been\neffective in keeping the Twittersphere clean.\n30\ninteractions\nclass users tweets retweets replies mentions articles\nfake 45 24,331 4,375 2,640 12,927 4,389\nof\ufb01cial 333 207,171 49,515 9,966 99,595 48,095\npoliticians 328 88,627 23,188 5,603 57,512 2,324\nshowbiz 98 29,873 5,414 2,838 21,475 146\nsocial media 8 8,824 402 3,901 4,499 22\nsport 37 33,616 6,057 2,059 25,490 10\ntrademarks 6 4,289 207 1,789 2,293 0\nVIPs 11 3,251 192 812 2,238 9\ntotal 863 399,982 89,350 29,608 226,029 54,995\nTable 3.1: Dataset summary.\n3.2 Results and Discussion\nBy exploiting Twitter APIs, we collected data from the Twitter timelines of 863\nusers. This resulted in the acquisition of 399,982 tweets shared between Febru-\nary 28 and May 22, 2019. The 863 users in our dataset are classi\ufb01ed into 8\ncategories, based on their roles in the society. In detail, we have categories en-\ncompassing trusted news outlets (labeled official ), politicians, disinforma-\ntion outlets ( fake ), show business personalities ( showbiz ), of\ufb01cial accounts of\nsocial media platforms, sport personalities, famous brands ( trademarks ), and\nother VIPs. By leveraging information contained in tweets and users metadata\nthat we collected, we also computed the interactions between all the accounts of\nour dataset and we geolocated Twitter users, whenever possible. A detailed view\nof our Twitter dataset is summarized in Table 3.1 while additional information is\n31\navailable in the \u201cMaterials and Methods\u201d Section.\nBy leveraging account interactions, we built a directed graph G= (V;E)where\neach nodevi2Vcorresponds to a Twitter account and each link ei= (vA;vB)2\nEfrom nodevAto nodevBexists\u0000\ni.e.,A B\u0001\nif and only if vAinteracted with\nvBin one of the following ways: (i) vAretweetedvB; (ii)vAreplied tovB; (iii)vA\nmentionedvBin a tweet; (iv) vAtweeted a link to an article that mentioned vB.\nWe refer to the last type of interaction as indirect \u2013 whereas all others are direct\n\u2013 since Web links do not point directly to Twitter accounts, but rather point to\nWeb pages outside Twitter that, in turn, mention accounts in our dataset. Our rich\ninteraction network is thus representative of the information \ufb02ow across different\nactors, including disinformation outlets, and several countries involved in the 2019\nEuropean Parliament elections.\nWe \ufb01rst characterize the geographical composition of our dataset. As shown\nin Figure 3.1, our dataset is mainly made up of accounts located in the EU and\nthe US. However, a small fraction of accounts belong to other parts of the world.\nThis is due to the fact that we integrated our initial set of accounts with a subset\nof popular accounts (more than 1M followers) that interacted with them. Notably,\nonly a small fraction of accounts belong to non EU/US places. This may be a\n\ufb01rst signal that the interactions rarely cross national borders. Indeed, the top panel\nof Figure 3.2 shows the geographic distribution of user interactions on a world\n32\n1.014.69\n22.431.0118.250.13\n2.530.3838.66\n5.20.130.510.25\n0.63 0.380.132.53\n0.380.13\n0.510.13\nAmericaAsiaEuropeOceania\nfakeofficialpolitician showbiz\nsocial mediasport\ntrademarkvip\n010203040users (%)\nFig.3.1: Heatmap showing the distribution of users interacting with the different actor classes, per\ngeographic area.\nmap, while the bottom panel represents the information as a chord diagram where\ninteractions are grouped by actor class and by country. The top panel highlights\nthat the vast majority of interactions (65%) is initiated by of\ufb01cial accounts (green\nlinks) and that a considerable number of links between the US and the EU (10%)\nexists. The chord diagram of Figure 3.2 provides more details about countries\nand classes, con\ufb01rming that the biggest contribution to the debate is provided by\nof\ufb01cial accounts, followed by politicians. However, it is noticeable that most of\n33\n(a) Node-link diagram showing the geographic representation of information flows. For clarity,\nself-loops are omitted. Cosa sideduce daquesta figura?.\n(b) Chord diagram showing class interactions grouped by\ncountry. The vast majority of all interactions occurs between\nactors within the same country and, often, also of the same\nclass. Icolorinell\u2019anello piuesterno (quello delle nazioni) a\ncosa corrispon dono? Senon hanno unsignificato particolare\npotremmo toglierli (met terli tipo tutti neri) perche\u2019 cosi\u2019 ho\npaura checonfondano unpo\u2019dalmomento cheabbiamo gia\u2019\ndiversi coloriall\u2019interno.\nfake politicians social media trademarks\nofficial showbiz sport VIPs\nFig 2. Network describing the interactions between 8 classes of actors in the months\npreceding the 2019 European elections.\nprovided by official accounts, followed by politicians. However, it is noticeable that most 51\nOctober 29, 2019 3/10\nfake\nofficialpoliticianshowbizsocial mediasporttrademarkvip\nAE\nAU\nBE\nCA\nCH\nCN\nCO\nDE\nESFRIEINITPRPSSAUKUS\nFig. 3.2: Node-link diagram showing the geographic representation of information \ufb02ows (top)\nand Chord diagram showing class interactions grouped by country (bottom) during EU elections.\nLoops are taken into account only in the chord diagram, that highlights the tendency of accounts\nto interact mainly with users in the same nation and often also in the same class.\n34\nthe links start and end in the same country, while the center of the chord diagram\nis almost empty, implying that the debate rarely crossed national borders. The\nonly relevant exception is represented by of\ufb01cial news outlets that tend to cite\npoliticians from other countries (11% of all links). This is particularly clear for\nthe UK, where a relevant fraction of links coming from of\ufb01cial accounts point\nto US politicians (36% of all links from UK news outlets) \u2013 that is, UK news\noutlets tweet about US politicians quite often. All other groups tend to refer only\nto accounts from the same country and often also of the same type. Although\na precise assessment of the causes of this phenomenon is beyond the scope of\nthis work, we provide further details and brie\ufb02y discuss the possible impact of\nlanguage barriers in the following paragraph.\ncountry totalhome\nlangother\nlangshome lang\nfrom outsidehome total\nratioother\nhome ratiooutside\ntotal ratio\nUK 249,923 243,342 6,581 323,857 0.9737 0.0270 1.2958\nUSA 246,760 241,735 5,025 325,464 0.9796 0.0208 1.3190\nSpain 178,815 159,091 19,724 7,286 0.8897 0.1240 0.0407\nFrance 178,593 152,482 26,111 5,943 0.8538 0.1712 0.0333\nItaly 159,814 135,128 24,686 1,024 0.8455 0.1827 0.0064\nGermany 135,481 96,187 39,294 967 0.7100 0.4085 0.0071\nTable 3.2: The column country refers to the geolocation of the tweets at national level. The column\ntotal is the total number of tweets located in the respective country. The column home lang reports\nthe number of tweets using the national language of the country. The column home lang from\noutside reports the number of tweets made in different countries that the national language of the\ncountry belonging to the respective row. The other columns report the ratio deriving from the\nprevious columns.\nIn order to give more details about the impact of language barriers on the de-\nbate among nations, we provide more details about the languages used in the six\n35\n100101102103104105\nenesfrdeitottweetsA \u2013 USA\n100101102103104105\nenfresdeitotB \u2013 UK\n100101102103104105\ndeenfresitotC \u2013 Germany\n100101102103104105\nfrenesitdeottweetsD \u2013 France\n100101102103104105\nitenesfrdeotlanguageE \u2013 Italy\n100101102103104105\nesenfritdeotF \u2013 Spain\nFig.3.3: Per country distribution of languages in the tweets of our dataset.\nmore relevant nations in our analysis. Figure 3.3 shows that the national language\nis indeed the most frequent in the tweets of the respective country; nonetheless\nother languages, and especially English in non-English speaking countries, is well\nrepresented within the Twittersphere. Table 3.2 provides more details concerning\nthe usage of national and foreign languages in different countries. In summary, we\ncan conclude that despite the national language is the most used in each countries\nalso other languages are quite well represented and therefore the impact of lan-\nguage barriers is present but it is not the unique element that determines the lack\nof inter-connections among countries.\nIn order to understand how accounts of the same type interact among them-\n36\nA B\nC D\nFig.3.4: Geographic representation of intra-class interactions for the four biggest classes of actors:\nfake (panel A), politicians (panel B), of\ufb01cial (panel C), and showbiz (panel D). Notably, panel A\nhas only one link between two nodes in the UK, while all other panels exhibit a large number of\ninteractions. For clarity, self-loops are omitted.\nselves, we induced subgraphs based on node categories hence obtaining one sub-\ngraph for each category. Figure 3.4 shows the subgraphs plotted in a world map,\nfor the four biggest classes of actors: fake (panel A), politicians (panel B), of\ufb01cial\n(panel C), and showbiz (panel D). We note that only subgraphs related to of\ufb01cial\nnews outlets, politicians and showbiz accounts are well connected. Indeed, the\nproportion of nodes belonging to the largest connected component is respectively\n66%, 91% and 84% of the total number of nodes. On the contrary, the graph re-\nlated to disinformation news outlets (panel A) comprises mostly isolated nodes.\nIn the case of disinformation news outlets the nodes belonging to the largest con-\nnected component are about 9% of the total number of nodes. Such evidence sug-\n37\ngests that Twitter accounts related to disinformation outlets rarely dialogue with\ntheir peers, but rather they prefer to interact with other types of actors. Further-\nmore, comparing Figure 3.4 with the chord diagram of Figure 3.2, we can infer\nthat outlets labelled as fake also display a tendency towards self-mentioning. In-\nstead, politicians and showbiz accounts show a relevant percentage of interactions\nwith others from the same class (respectively 42% and 22%, without consider-\ning self interactions) while of\ufb01cial news outlets interact mainly with other classes\n(71% of total links amount). Although there are some similarities in the statistics\nof fake and of\ufb01cial outlets \u2013 that is, both try to interact with other classes \u2013 only\nof\ufb01cial accounts catch the attention of other actors, while fake outlets are most of\nthe times ignored.\nTo clarify the way in which different actors participated in the debate, we also\nanalyzed the proportion of incoming and outgoing links by class. Results are\nshown in Figure 3.5. In the \ufb01rst row all types of interactions were considered (i.e.,\nboth direct andindirect ), while in the second one only direct interactions (retweets,\nreplies, mentions) were taken into account. Some differences arise when compar-\ning all outgoing links with direct outgoing links (left-hand side of Figure 3.5), in\nparticular with regards to the classes fake and of\ufb01cial. When all kinds of interac-\ntions ( direct +indirect ) are taken into account, we note an increment in the fraction\nof outgoing links that point to politicians (blue-colored bar, +57% and +51% re-\n38\nFig.3.5: Outgoing and incoming links by class. The top row accounts for all types of interactions,\nthe bottom one only considers direct interaction (i.e., replies, retweets, mentions). For this analysis\nself-loops are considered, which explains the tendency of all classes towards self-interaction.\nspectively) for both classes. In other words, the classes labelled as fake and of\ufb01cial\ninteract with politicians mainly through external resources. These could be news\narticles mentioning politicians, that are linked and shared in Twitter.\nThe proportions of incoming links are shown in the right-hand side of Fig-\nure 3.5. The most relevant difference between direct andindirect links concerns\nthe category of politicians. In fact, there is an increase of links coming from the\n39\nof\ufb01cial and fake classes (+49% and +5%) that is in accordance with the differ-\nences found in the case of outgoing links. Again, we notice that accounts, except\nfor of\ufb01cial ones, display the tendency to interact mainly within their own classes,\nand this is even more evident when only direct links are taken into consideration.\nFinally, by analyzing the behavior of the of\ufb01cial and fake classes, we noticed\nthat both of them mainly refer to politicians when external sources are taken into\naccount. However, politicians mostly interact among themselves and only a small\nfraction (9%) of their outgoing links are directed to of\ufb01cial accounts, with disin-\nformation outlets being substantially ignored. Indeed, we measure the number of\nnodes connected by reciprocal direct links (i.e. A and B are connected in both di-\nrection with a link representing a mention, a retweet or a reply) among the classes.\nWe found that fake news accounts, news outlets and politicians reach progressively\nhigher reciprocity scores especially within their own classes. The average percent-\nage of nodes connected by reciprocated links in the same class is \u0016= 23:4%and\nonly 9% of fake news accounts are reciprocally interconnected. Moreover, fake\nnews accounts exhibit a behavior that differs from other classes when the per-\ncentage of nodes connected by reciprocated inter-class links is taken into account:\nwhile the average percentage is \u0016= 5:5%, fake news accounts do not display\nmutual connections with any other class. Such evidence, combined with the infor-\nmation conveyed in Figures 3.2 and 3.4, suggests that disinformation outlets try\n40\nto \ufb01t in the political debate, but they are essentially ignored by mainstream news\nsources, by politicians, and also by the other classes of actors. Interestingly,the\nbehavior of fake news accounts is akin to that of automated accounts as shown\nby the authors of [72] during the Catalan Referendum: both fake news and auto-\nmated accounts tend to target popular users in order to increase their relevance and\nimpact in the public debate.\nOur previous \ufb01nding indicates that Twitter accounts related to disinformation\noutlets did not seem to be able to enter the main electoral debate. However, despite\nnot attracting interest from the main actors involved in the debate, they could still\nhave had an impact on the general audience. To investigate this issue we study the\nengagement obtained by the different classes of actors. In particular, each actor\nproduces tweets, and each tweet obtains a certain engagement that derives from\nthe interactions (e.g., retweets) of other users with that tweet. We can thus aggre-\ngate the engagement obtained by all tweets of a given actor, to have an indication\nof the engagement obtained by that actor. Similarly, we can aggregate the engage-\nment obtained by all tweets from actors of a given class (e.g., politicians, fake\nnews outlets, etc.), to have an indication of the engagement obtained by that class\nof actors. In our study, engagement obtained by a given tweet is simply computed\nas the number of retweets that tweet obtained. With respect to other measures of\nengagement (e.g., the number of likes/favorites to a tweet), retweets provide an\n41\nindication for how much a message spread. As such, they arguably represent a\ngood indicator for investigating the reach of fake and authoritative news, which is\nthe goal of our study. Figure 3.6 compares the distribution of the engagement gen-\nerated by all tweets of disinformation outlets (grey-colored), with those generated\nby tweets of all the other classes. Overall, Figure 3.6 shows that the engage-\nment obtained by disinformation outlets is lower than that obtained by all other\nclasses. In other words, tweets from accounts in the fake class, tend to receive less\nretweets than those obtained by other accounts. To dig deeper into this issue, we\nalso considered the popularity of the accounts belonging to the different classes of\nactors. As a measure of popularity for an account, we considered its number of\nfollowers. Then, we compared the relation between the popularity of our accounts\nand the mean engagement they obtain, for the different classes of actors. Results\nare shown in Figure 3.7 by means of a bi-dimensional kernel density estimation,\nfor the 6 biggest classes of actors. When we consider also the popularity of the\naccounts, an important feature of disinformation outlets emerges. Indeed, for mid-\nlow levels of popularity (number of followers \u0014100,000) accounts linked to the\nspread of disinformation actually obtain more engagement than of\ufb01cial news out-\nlets, and almost the same engagement obtained by politicians. This \ufb01nding is also\nshown in Figure 3.8, where popularity is logarithmically quantized into 7 buck-\nets. This important \ufb01nding suggests that the audience of disinformation accounts\n42\nis more active and more prone to share contents, with respect to that of the other\nclasses. Anyway, no disinformation outlet currently reaches high levels of popu-\nlarity (number of followers \u00151M), in contrast with all other classes of actors. As\na consequence, highly popular of\ufb01cial news outlets still obtain more engagement\nthan disinformation outlets. This indicates that, although the audience of disinfor-\nmation outlets is more prone to share information than others, their in\ufb02uence on\nthe public debate remains rather limited. Additionally, even though disinformation\naccounts make efforts to attract interest of other central users, they cannot really\n\ufb01t into the information \ufb02ow in any signi\ufb01cant way.\n3.3 Conclusions\nWe analyzed the interactions of several accounts belonging to different \ufb01gures of\nthe public society in the context of the 2019 European Parliament elections. To\nhave a wide view of the phenomenon, we included in our dataset also person-\nalities not directly related to politics, such as show business and sport \ufb01gures,\ntogether with a set of disinformation outlets. We collected all the tweets made\nby the selected accounts in the three months before the election days and we per-\nformed a quantitative analysis to identify the characteristics of the debate. By\nleveraging a semi-automated geolocalization technique, we also performed a ge-\nographical analysis of the phenomenon. Results show that the debate on Twitter\n43\nrarely crossed national borders \u2013 that is, accounts tended to interact mainly with\nothers coming from the same nation. Moreover, there was a strong tendency of\nintra-class interaction \u2013 that is, accounts mainly mentioned others from the same\nclass. The only relevant exception were accounts of of\ufb01cial news outlets, espe-\ncially those located in the United Kingdom, that had a non-negligible percentage\nof links pointing to the US. Moreover, it is interesting that disinformation outlets\ndid not interact among themselves, but rather they exhibited a tendency towards\nself-mentions and they tried to catch the attention of other popular accounts. Nev-\nertheless, differently from of\ufb01cial news outlets, disinformation outlets were almost\ncompletely ignored by other actors, thus holding a peripheral position in the in-\nteraction network and having a limited in\ufb02uence on the information \ufb02ow. Still,\nthey exhibited an outreach on general public higher than of\ufb01cial news outlet and\ncomparable with the politicians at the same levels of popularity, thus implying that\nthe user base of disinformation outlets was more active than that of other classes\nof actors. However, all other categories overcame disinformation outlets in terms\nof absolute maximum outreach, thanks to their signi\ufb01cantly larger absolute pop-\nularity. Finally, the limited and bounded contribution that disinformation outlets\nhad on the overall interactions suggests that the strategies employed by Twitter\nto counteract the spreading of disinformation \u2013 that is, the ban or suspension of\nsuspicious accounts \u2013 may have had a mitigation effect on the spreading of fake\n44\nnews thus preserving the integrity of the Twittersphere.\n3.4 Materials and Methods\n3.4.1 Data Collection\nOur dataset is based on a list of 863 Twitter accounts, split across 8 categories\nand 18 countries. A pseudonymized version of our dataset is publicly available on\nGitHub( https://github.com/cinhelli/Limited-Reach-Fake-\nNews-Twitter-2019-EU-Elections ). Initially, we only considered in\nour study the 5 biggest European countries (UK, Germany, France, Italy and\nSpain) and the US. Then, other countries were added when we extended the dataset\nto also include popular users that interacted with users from our initial set.\nThe \ufb01rst category of accounts (labeled fake ) in our study is related to known\ndisinformation outlets. It contains 49 Twitter accounts responsible for sharing dis-\ninformation, identi\ufb01ed in authoritative reports \u2013 such as Reuters\u2019 Digital News\nReport 2018 [73] and a report from the European Journalism Observatory [74] \u2013\nand fact-checking Web sites \u2013 such as Snopes [75] and Politifact [76]. Our list\nof of\ufb01cial news outlets (labeled official ) contains 347 Twitter accounts. It\nincludes accounts corresponding to the main news outlets in each of the consid-\nered countries, derived from the media list released by the European Media Mon-\nitor [77], as well as the Twitter accounts of the main US news outlets. We then\n45\nconsidered a list of 349 politicians (labeled politicians ). This list includes\nall available Twitter accounts of the members of the European parliament [78] as\nof March 2019, as well as the main politicians for each considered country that\ndid not belong to the European parliament.\nWe \ufb01rstly exploited Twitter APIs to crawl the timelines of all the accounts be-\nlonging to the 3 previous lists. In order to match the electoral period, we only\nretained tweets shared between February 28 and May 22, 2019. After this step,\nwe also manually classi\ufb01ed a small subset of popular users (more than 1M fol-\nlowers) that interacted with those of our initial list in the considered time period.\nThese accounts were classi\ufb01ed in 5 additional categories, based on their role in the\nsociety. In this way, we obtained additional 100 showbiz accounts (e.g., actors,\ntv hosts, singers), 10 social media accounts (e.g., Youtube\u2019s of\ufb01cial account),\n37sport accounts (e.g., sport players and the of\ufb01cial accounts of renown sport\nteams), 6 trademarks accounts related to famous brands (e.g., Nike, Adidas)\nand 11 accounts of VIPs (e.g., the Pope, Elon Musk, J.K. Rowling). For each\nof these additional accounts, we crawled the respective timeline and only retained\ntweets shared in our considered time period.\nAfter this data collection process, we ended up with the dataset summarized in\nTable 3.1, comprising more than 850 labeled accounts and almost 400,000 tweets.\n46\n3.4.2 Account Interactions\nFor each account, we also computed its interactions with other accounts. In partic-\nular, we split interactions into 4 different categories: retweets, replies, mentions,\nand article mentions.\nThe \ufb01rst 3 types of interactions are straightforward, while an article mention\nis detected when an account shares a tweet containing a URL to a Web page that\nmentions one of the labeled accounts in our dataset. To obtain information about\narticle mentions we scraped all the Web pages linked within the tweets of our\ndataset. Within each page, we performed language detection and named entity\nrecognition. Finally, we cross-checked person named entities with our lists of\nusers.\n3.4.3 Account Geolocation\nWhenever possible, we also exploited the location \ufb01eld of Twitter accounts (both\nthe 863 labeled ones, as well as all others with which they interacted) in order to\ngeolocate them.\nFor this process, we exploited several different geolocators (e.g., Google Maps,\nBing, GeoNames) that offer their services via Web APIs. We \ufb01rst selected all\naccounts with a non-empty location \ufb01eld. Then, we built a blacklist for discarding\nthose locations that were too vague or clearly ironic (e.g., global, worldwide, Mars,\n47\nthe internet), as is frequently the case with user-generated input. For each distinct\nlocation that was not removed during the \ufb01ltering step, we queried one of the\navailable geolocators and we associated the corresponding geographic coordinates\nto all accounts with that location.\n48\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\n100101102103104\n100101102103104105106engagement (num. RTs)tweets\nfake official politicians\nshowbiz social media sport\ntrademarks VIPs\nFig. 3.6: Distribution of the engagement obtained by tweets of disinformation outlets (grey-\ncolored) and comparison with the engagement obtained by tweets of all other classes. Overall,\ndisinformation outlets obtain less engagement than others, as shown by their distribution spanning\nsmaller values on the xaxis. Engagement for a given tweet is computed as the number of retweets\nobtained by that tweet.\n49\n100101102103104105\n100101102103104105106107108popularity (num. followers)engagement (num. RTs)\n0.250.500.751.00\n100101102103104105\n100101102103104105106107108popularity (num. followers)engagement (num. RTs)\n0.250.500.751.00\n100101102103104105\n100101102103104105106107108popularity (num. followers)engagement (num. RTs)\n0.250.500.751.00\n100101102103104105\n100101102103104105106107108popularity (num. followers)engagement (num. RTs)\n0.250.500.751.00\n100101102103104105\n100101102103104105106107108popularity (num. followers)engagement (num. RTs)\n0.250.500.751.00\n100101102103104105\n100101102103104105106107108popularity (num. followers)engagement (num. RTs)\n0.250.500.751.00\nfake official politicians\nshowbiz social media sport\nFig.3.7: Kernel density estimation of engagement and popularity of the accounts belonging to the\nmain classes of actors. Despite obtaining overall less engagement, disinformation outlets (grey-\ncolored) actually obtain more engagement than of\ufb01cial news outlets (green-colored) at middle\nand low popularity levels. Popularity for a given user is computed as its number of followers.\nEngagement for a given user is computed as the mean number of retweets obtained by tweets of\nthat user.\n50\n[102,103)[103,104)[104,105)[105,106)[106,107)[107,108)[108,\u221e)\n[102,103)[103,104)[104,105)[105,106)[106,107)[107,108)[108,\u221e)100101102103104\n100101102popularity (num. followers)engagementaccounts\nfake politicians social media trademarks\nofficial showbiz sport VIPs\nFig. 3.8: Engagement obtained at different popularity levels by the different classes of actors.\nAlthough disinformation outlets (labeled fake ) do not reach high popularity levels, they consis-\ntently obtain more engagement than of\ufb01cial news outlets at middle and low popularity levels, and\ncomparable engagement with respect to politicians.\n51\nCHAPTER 4\nMEASURING THE EVOLUTION OF POLARIZATION AND NEWS\nINFLUENCERS BETWEEN TWO U.S. PRESIDENTIAL ELECTIONS\nON TWITTER\nIn the previous chapter, we analyzed the impact of fake news during 2019 Euro-\npean election and showed that they had a marginal role in the online debate. This\n\ufb01nding suggests that only one part of users endorsing a speci\ufb01c narrative interact\nwith misinformation and fake news spreaders, while the majority of in\ufb02uential\npublic personalities do not involve with such contents. Nevertheless, in some\ncases part of the research suggested that automated accounts may have strongly\nin\ufb02uenced the public debate by injecting misinformation, such as during the 2016\nU.S. presidential election. During the last years, platforms increased the effort to\nlimit the spread of misinformation and adopted several countermeasures such as\nthe suspension of suspicious accounts and the reduction of the visibility of ques-\ntionable contents. Thus, one question of interest is how the online debate has been\naffected from these measures over the last years.\nIn this chapter, we analyze the public debate around 2020 U.S. presidential\nelection on Twitter and compare the results with the 2016 U.S. presidential elec-\n52\ntion. We quantify the change in polarization between the two elections and provide\ninsights about the evolution of the Twitter environment.\n4.1 Introduction\nA growing number of studies have documented increasing political polarization\nin the U.S. that is deeper than at any time since the American Civil War [79]\u2013\n[81]. Partisan division over issues has increased among those af\ufb01liated with po-\nlitical and news media organizations \u2013 elected representatives, party of\ufb01cials, and\npolitical pundits \u2013 alongside an alarming increase in affective polarization among\nvoters. This two-level pattern \u2013 issue polarization among political elites and af-\nfective polarization among voters \u2013 invites further research on the diffusion of\npolarized political information between those in positions of political in\ufb02uence\nand the larger population.\nThis diffusion of political information is dif\ufb01cult to track with traditional sur-\nvey and roll call data that lack relational measures. Increasing reliance on social\nmedia for political communication is opening up unprecedented opportunities to\nstudy the diffusion of political information and misinformation [14] over commu-\nnication networks [82]. Our study leverages social media data from Twitter to\nbetter understand the diffusion dynamics of news media information during the\ntwo most recent U.S. election cycles.\n53\nTwitter users are embedded in relatively stable communication networks cre-\nated by the exchange of \u201cretweets.\u201d A 2015 study by Metaxas et al. [83] found\nthat \u201cretweeting indicates not only interest in a message, but also trust in the mes-\nsage and the originator, and agreement with the message contents.\u201d The content\nof retweets makes it possible to identify information that is highly biased, as well\nas the ideological direction of the bias. Using retweet data we also can iden-\ntify \u201cin\ufb02uencers\u201d who are the users with the greatest ability to broadly propagate\nnew information over the retweet network. Typically, in\ufb02uencer tweets are highly\nlikely to be retweeted, not only by their followers, but also by their followers\u2019 fol-\nlowers, and so on. We classify Twitter in\ufb02uencers into two categories. The \ufb01rst\nincludes the \u201caf\ufb01liated\u201d who are associated with media or political organizations,\nand the other consists of the \u201cunaf\ufb01liated\u201d who do not have such associations, so\nmost likely represent themselves or informal groups.\nOur study also aims to better understand how polarization unfolds on social\nmedia. To clarify, political scientists distinguish multiple types and levels of po-\nlarization [84]\u2013[89]: policy polarization (extreme differences of opinion on highly\nsalient issues), partisan polarization (alignment of opinions with opposing political\nparties), ideological polarization (alignment of opinions with liberal vs. conser-\nvative world views), and geographic polarization (regional alignment of opinions,\ne.g., \u201cred state/blue state\u201d). Each of these four types of polarization can in turn be\n54\nclassi\ufb01ed by level: elite polarization among political of\ufb01cials and pundits, media\npolarization among news organizations, and polarization among the underlying\npopulation as usually measured by exit polls and opinion surveys. In this paper,\nwe use data from social media to study ideological polarization among the political\nelite, news organizations, and Twitter users more broadly. Over the past decade,\nthe rapid growth of Twitter, Facebook, Reddit and other social media have trans-\nformed the communications and information propagation landscape. Alongside\ntraditional broadcast media and face-to-face communication, people now have the\nability to search for and exchange information with billions of other users in a\nglobal network. Recent studies have examined the impact of new technologies\nlike Twitter and YouTube on election outcomes [90]\u2013[99], including the effects\nof disinformation [16], [18], [19], [39], [100], [101]. Other studies have docu-\nmented how social media platforms contribute to polarization through the creation\nof echo chambers [12], [102]\u2013[110]. In contrast, here we focus on the increased\npolarization and involvement of Twitter in\ufb02uencers from from the 2016 to 2020\nU.S. presidential elections. We measure longevity of Twitter in\ufb02uencers and the\nlandscape of polarization of themselves and their retweeters during this period.\nOur study focuses on the diffusion of news media information between in\ufb02u-\nencers and those whom they in\ufb02uence, as well as the change in composition and\npopularity of these in\ufb02uencers and their retweeters. To maintain the consistency\n55\nbetween the results from 2016 and 2020 elections, we follow the methodology of\nRef. [18] to identify and classify the in\ufb02uences and their retweeters in the 2020\nU.S. election data. We classify tweets containing a link to a news outlet into sev-\neral news media categories corresponding to their different political orientations.\nWe observe that the volume of tweets and users with a center orientation decreased\nfrom the 2016 election to the 2020 election. For each news media category, we\nreconstruct the corresponding retweet network and identify the most important\nnews media in\ufb02uencers of the category by \ufb01nding the most important nodes in\nterms of their ability to spread information in the network. The top 25 in\ufb02uencers\nin each news media category are then classi\ufb01ed as af\ufb01liated with a media or with a\npolitical organization or unaf\ufb01liated. Finally, we measure the strength of the polar-\nization of the in\ufb02uencers and of their retweeters, de\ufb01ned as the level of separation\nof the in\ufb02uencers\u2019 retweeters in two opposite clusters and \ufb01nd a clear, signi\ufb01cant\nincrease of the polarization from 2016 to 2020.\n4.2 Results\n4.2.1 News Media on Twitter in 2016 and 2020\nWe tracked the spread of political news on Twitter in 2016 and 2020 by analyzing\ntwo datasets containing tweets posted between June 1stand election day (Novem-\nber8thin 2016 and November 2ndin 2020). The data were collected continuously\n56\nusing the Twitter Search API with the names of the two presidential candidates in\neach of the presidential elections in 2016 and 2020 as keywords. (Had we used\nmore keywords targeting speci\ufb01c media outlets or hashtags concerning speci\ufb01c\nnews events we would risk missing election-related tweets that did not contain\nreferences to the list of outlets or events.) The 2016 dataset contains 171 mil-\nlion tweets sent by 11 million users and was used in Refs. [18], [94] to assess the\nin\ufb02uence of disinformation on Twitter in 2016. The 2020 dataset contains 702\nmillion tweets sent by 20 million users. Hence, we observe a signi\ufb01cant increase\nin Twitter involvement in distributing election polarization, since in four years the\nnumber of Twitter users nearly double and number of tweets per user more than\ndouble, increasing the total number of tweets more than fourfold.\nThe classi\ufb01cations of news media websites presented below and used in this\npaper, including \u201cfake\u201d, \u201cextremely biased\u201d, \u201cleft\u201d, \u201cright\u201d, and especially the\nboundaries between categories, are a matter of opinion, rather than a statement of\nfact. The categorizations and labels assigned to the corresponding classes used\nhere originated in publicly available datasets from fact-checking and bias rating\norganizations credited below. The political views and conclusions contained in\nthis article should not be interpreted as representing those of the authors or their\nfunders.\nFor each tweet containing a URL link, we extracted the domain name of the\n57\nURL (e.g. www.cnn.com ) and classi\ufb01ed each link directing to a news media\noutlet according to this outlet\u2019s political bias. The 2016 and 2020 classi\ufb01cations\nrely on the website allsides.com (AS), followed by the bias classi\ufb01cation\nfrommediabiasfactcheck.com (MBFC) for outlets not present in AS (both\ntaken as of January 7 2021 for the 2020 classi\ufb01cation). We classi\ufb01ed URL links\nin \ufb01ve news media categories for outlets that mostly conform to professional stan-\ndards of fact-based journalism: right ,right-leaning ,center ,left-leaning andleft.\nWe also include three additional news media categories to include outlets that tend\nto disseminate disinformation: extreme-right bias ,extreme-left bias andfake news .\nWebsites in the fake news category have been \ufb02agged by fact-checking organiza-\ntions as spreading fabricated news or conspiracy theories, while websites in the\nextremely biased category have been \ufb02agged for reporting controversial informa-\ntion that distorts facts and may rely on propaganda, decontextualized information,\nor opinions misrepresented as facts. A detailed explanation of the methodologies\nused by AS and MBFC for rating news outlets and of the differences in classi\ufb01-\ncation between 2016 and 2020 is given in the Methods section. The full lists of\noutlets in each category in 2016 and 2020 are given in Tabs. A.1 and A.2. In\nthe 2016 dataset, 30.7 million tweets, sent by 2.3 million users, contain a URL\ndirected to a media outlet website. The 2020 dataset contained 72.7 million tweets\nwith news links sent by 3.7 million users. This number reveals remarkable drop\n58\nof fraction of \ufb02ow of tweets from users associated with media form 18% in 2016\nto10% so nearly half lower. This came from mainly from smaller growth of pro-\nductivity of media af\ufb01liated users.\nThe fractions of tweets and users who sent a tweet in each of the news media\ncategories are shown in Fig. 4.1 A and B (the numbers are reported in Tab. A.3)\nalong with other statistics about the activity of users in each category. Between\n2016 and 2020, these fractions decreased most in the center category and increased\nmost in the left-leaning category, with a smaller increase in the fractions in the\nright-leaning category. The shift away from the center may indicate the increasing\npolarization, both among users as well as media outlets. However, most of the de-\ncrease in the fraction of center media outlets re\ufb02ects the shift of CNN.com , which\nwas categorized by AS as center in 2016 and as left-leaning in 2020, combined\nwith CNN accumulating more than twice the number of tweets in 2020 than the\ntop outlet of the center category ( thehill.com ) (see Tab. A.2).\nThe fraction of tweets in the fake and extremely biased category, representing\noutlets that were most susceptible to sharing disinformation, decreased from 10%\nto 6% for fake news and from 13% to 6% for extremely right-bias news. The\nnumber of users who shared those tweets also decreased for extremely right-biased\nnews (from 6% to 3%) but not for fake news (which remained at 3%) (see Tab.\nA.3). The fraction of tweets in the extremely-left bias category is very small (2%\n59\nA B C D\n0.000.250.500.751.00\n20162020\nyeary year 2016 2020\n0.000.250.500.751.00\n20162020\nyeary year 2016 2020Proportion of tweets Proportion of users\nLeft Left\nleaningCenterRight\nleaningRight\nFake news & extreme biasLeft Left\nleaningCenterRight\nleaningRight\nFake news & extreme bias0.00.20.40.6 2016 2020E.B. left\nLeft\nLeft leaning\nCenter\nRight leaning\nRight\nE.B. right\nFake news\nE.B. left\nLeft\nLeft leaning\nCenter\nRight leaning\nRight\nE.B. right\nFake newsE.B. leftLeftLeft leaningCenterRight leaningRightE.B. rightFake news\nLinks category User main category\n0.00.20.40.6Proportion\nof links\nFig. 4.1: Distribution of news media links in 2016 and 2020, by news media category. Panels\nA and B show the fractions of tweets and users that sent tweets with a URL pointing to a website\nbelonging to one of the categories. Users are classi\ufb01ed in the category in which they posted the\nmost links. For the users that have at least two links classi\ufb01ed, panels C and D report the fraction\nof links across categories as a function of the users\u2019 main categories.\nin 2016 and even less, 0.05% in 2020).\nFig. 4.1 C and D shows the fraction of URLs across categories as a function of\na user\u2019s modal category for users that posted at least two links in our datasets. The\nanalysis reveals two clusters in 2016 and 2020, one with categories from the right\nand fake news (fake news, extreme-right bias news, right news and right-leaning\nnews) and the second one with categories from the center and left (center news,\nleft-leaning news, left news, extreme-left bias news). These two clusters can be\ninterpreted as two echo chambers. Asymmetrical patterns in Fig. 4.1 C and D\nreveal that users in the right wing echo chamber also link to a very limited number\nof left wing media outlets, but that the opposite relation does not occur. This is\nconsistent with asymmetry between left-leaning and right-leaning users in social\nmedia observed in previous studies [5], [18], [110].\n60\nIn order to estimate the volume of tweets sent from automated accounts such\nas bots, we counted the number of tweets sent from unof\ufb01cial Twitter clients, e.g.,\nTwitter clients other than the Twitter Web client, Android client, IPhone client or\nother of\ufb01cial clients. Unof\ufb01cial Twitter clients include a variety of different ap-\nplications used to automate all or part of an account activity, such as third party\napplications used typically by brands and professionals (e.g. SocialFlow or Hoot-\nsuite) or bots created with malicious intentions [94].\nThe overall fraction of tweets sent from unof\ufb01cial clients was 8% in 2016 and\n1% in 2020. A similar drop over the same period was observed in the average\nactivity of these users (see Tab. A.3). This decrease could be attributed in part\nto measures taken by Twitter to limit the virality of disinformation. Our results\nshow that while the relative volume of tweets linking to disinformation websites\ndropped approximately by a half in 2020 compared to 2016, the fraction of users\nsharing fake news decreased signi\ufb01cantly (Fig. 4.1 A and B and Tab. A.3).\nTo understand how users shifted between categories from 2016 to 2020, we\ntrack users that are present in both election datasets and in both years are classi\ufb01ed\ninto the category in which they posted the most tweets in each year. Fig. 4.2 shows\nthe resulting shifts. The two largest of them are of users that were in the center\nand left news category in 2016 and shifted to the left-leaning category in 2020.\nThis re\ufb02ects the consolidation of the left-leaning category as the largest in 2020,\n61\nwith the three most widely shared outlets: New York Times ,Washington Post and\nCNN (see Tab. A.6). We also observe a large fraction of users in the fake and\nextremely biased news category in 2016 that moved to the right news category\nin 2020. However, these user shifts also re\ufb02ect the change in the classi\ufb01cation\nof media outlets from 2016 to 2020. We infer the ideological position of Twitter\nusers without relying on the news outlet classi\ufb01cation in section 4.2.3, and show\nthat the resulting positions are highly correlated with the user positions computed\nusing the news categories in which they posted.\n4.2.2 News Media In\ufb02uencers\nTo capture the dynamics of information diffusion, we reconstruct retweet networks\ncorresponding to each news media category. We add a link, or directed edge, going\nfrom nodevto nodeuin the news network when user uretweets the tweet of user\nvthat contains a URL linking to a website belonging to one of the news media\ncategories. With this convention, the direction of the link represents the direction\nof the in\ufb02uence between Twitter users. We do not include multiple links with the\nsame direction between the same two users or self-links (when a user retweets their\nown tweets). The in-degree of a node is the number of links that point inward to\nthe node and its out-degree is the number of links that originate at a node and point\noutward to other nodes. With our convention, the in-degree of a user is equal to the\n62\nFig. 4.2: Shifts of users across news media categories from 2016 to 2020. The size of each\ncategory in 2016 corresponds to the number of unique users in the category in 2016 (Fig. 4.1). The\nshift from one category to another is proportional to the fraction of users that were classi\ufb01ed in\n2016 and in 2020 in the two respective categories.\nnumber of users they retweeted at least once and their out-degree is the number of\nusers who have retweeted them at least once. The higher a node\u2019s out-degree, the\ngreater its local in\ufb02uence. The characteristics of the retweet networks are given in\nTab. A.4.\n63\nFig. 4.3: Comparison of top 100 rankings generated by the PageRank algorithm and by the\nCollective In\ufb02uence (CI) algorithm using the 2016 and 2020 retweet networks. Ranked Bias\nOverlap (RBO) [111] and Jaccard Similarity are computed over the two top 100 lists, shown below\ntheir respective news category labels. For this analysis, RBO\u2019s weight parameter pis set to 0:98.\nThe RBO values are generally above 0.7 indicating a high agreement of the two ranking, especially\nfor the top ranked users. The only network that show a poor agreement between the rankings is\nthe extreme bias left network of 2020. This may be explained by the small size and low average\ndegree of the network compared to networks of other categories (see Tab. A.4).\n64\nIn each retweet network, we use the Collective In\ufb02uence (CI) algorithm [112]\nto \ufb01nd the best spreaders of information, i.e. the in\ufb02uencers of the correspond-\ning news media category. Speci\ufb01cally, the CI algorithm \ufb01nds the minimal set of\nnodes that can collectively reach the entire network when information diffuses ac-\ncording to a linear threshold model. The CI algorithm considers in\ufb02uence as an\nemergent collective property, not as a local property such as the node\u2019s out-degree.\nIt does this by \ufb01nding the smallest set of nodes needed for global cascades. Ac-\ncordingly, the CI algorithm is able to rank super-spreaders of information in social\nnetworks [18], [113], [114].\nHere, we use a directed version of the algorithm to identify the super-spreaders\nof information as the nodes with the highest CI outto be able to compare results\nfrom both elections [18]. The 2016 in\ufb02uencers\u2019 rankings are shown in the upper\npanel in Fig. 4.4 for the top \ufb01ve in\ufb02uencers, and in Tab. A.5 for the top 25 in-\n\ufb02uencers. Analysis of these results reveals that traditional news in\ufb02uencers were\nmostly journalists with veri\ufb01ed Twitter accounts linked to traditional news media\noutlets. In contrast, fake and extremely biased news are sent mainly by in\ufb02uencers\nwhose accounts are unveri\ufb01ed or deleted, with deceptive pro\ufb01les and much shorter\nlife-span on Twitter than traditional media in\ufb02uencers. However, some of these in-\n\ufb02uencers, despite their unknown, non-public nature, still played a major role in the\ndiffusion of disinformation and information on Twitter [18].\n65\nThe results from analysis of 2020 data are shown in the bottom panel of Fig. 4.4.\nFor in\ufb02uencers that persisted from 2016, their previous position in 2016 is listed in\npurple parentheses (see also Tab. A.6). Those in\ufb02uencers are often highly ranked\nin both the 2016 and the 2020 analyses. Among the union of top 100 in\ufb02uencers\nfrom each category in 2020 (representing 598 unique users) 150 were already in\nthe top 100 of one category in 2016. Yet, this means that 75% of the top 100\nin\ufb02uencers in 2020 are new to such high ranking.\nThe CI algorithm operates on the unweighted retweet networks. To verify that\na ranking computed on the weighted networks would not produce signi\ufb01cantly\ndifferent results, we compare the CI ranking with the ranking obtained from the\nPageRank algorithm applied to the weighted networks. The comparison reveals a\nstrong agreement, especially for highly-ranked users as shown in Fig. 4.3\nFig. 4.4 shows the retweet networks for each news media category in 2016 and\n2020, among communities formed by the union of the top 30 in\ufb02uencers for each\ncategory. The two force directed network layouts are computed using the same\nparameters and show two main clusters, with the right-biased and fake news in-\n\ufb02uencers in one cluster and the left-biased in\ufb02uencers in the other. The increased\nseparation in 2020 is notable. In 2016 the center in\ufb02uencers are mostly between\nthe two clusters; in 2020 the separation between the two clusters increased and\nonly a few in\ufb02uencers remain within a central position (e.g. @thehill ). We\n66\nquantify the polarization of the full set of top 100 in\ufb02uencers and of their retweet-\ners, using all the retweets between them, in detail in the next section.\nFake and extremely biased news are sent mostly by in\ufb02uencers whose accounts\nare unveri\ufb01ed or deleted, with fake news seeing a signi\ufb01cant increase in deleted\nin\ufb02uencer accounts from two in the top 25 in 2016 to eight in 2020 (see Tabs. A.5\nand A.6). Conversely, the extreme right-biased news in 2020 consisted primarily\nof veri\ufb01ed in\ufb02uencers that grew from 15 veri\ufb01ed in the top 25 in 2016 to 23 in\n2020.\nUsing a manual labeling process (see section 4.4), we classify the top 25 in-\n\ufb02uencers of each news media category for 2016 and 2020 as af\ufb01liated with media\nor political organizations, or unaf\ufb01liated, in order to observe the makeup of in\ufb02u-\nencer types for these categories. An in\ufb02uencer af\ufb01liated with a media organization\ncould be a media company or of\ufb01cial media outlet (e.g. @FoxNews ), or a writer,\nreporter, consultant, or other individual who has directly corresponded with a me-\ndia outlet in an of\ufb01cially recognized capacity (e.g. @joelpollak ). An in\ufb02u-\nencer af\ufb01liated with a political party could be a politician (e.g. @JoeBiden ), a\npolitical campaign platform or an af\ufb01liate of the platform, or someone who of\ufb01-\ncially represents an aspect of U.S. politics (e.g. @joncoopertweets ). We also\nsplit the unaf\ufb01liated category into two subcategories: independent and \u201cother.\u201d An\nindependent in\ufb02uencer is an in\ufb02uencer not of\ufb01cially af\ufb01liated with any media or\n67\n20202016\nFig. 4.4: Retweet networks formed by the top 30 in\ufb02uencers within each media category, by\nyear. The 2016 network (upper panel) was generated from 2016 data using the same algorithm\nas used in [18] but with different parameters to ease its comparison with the bottom panel gener-\nated from 2020 data. The arrows show the directions of links between users, from the source of\nin\ufb02uence (the original poster) to the recipient (the retweeter). The size of a node is proportional\nto its out-degree in the complete combined network, i.e., the number of different users that have\nretweeted the node at least once with a URL directing to a media outlet. The color of a node\nindicates the news media category with which the node is af\ufb01liated. Nodes ranked in the top 30\nof multiple categories are represented by pie charts where the size of each slice is proportional to\ntheir CI outranking (i.e. the node\u2019s collective in\ufb02uence). Both networks are visualized using a force-\ndirected graph layout. The tables on either side of the networks show the top \ufb01ve users in each news\nmedia category. The number in green to the left of each user is their unique index, used to label\nthe user\u2019s node in the network. Users ranked in the top 30 for multiple news media categories have\ncolored superscripts, indicating the rank and media classi\ufb01cation of their other top \ufb01ve positions.\nVeri\ufb01ed users are indicated by a checkmark X. In the 2020 tables, a user\u2019s 2016 rank is displayed\nwith the purple number to the left of their 2020 rank. Three usernames in the top 10 changed\nbetween 2016 and 2020: @DRUDGE REPORT became @NEWS MAKER ,@HuffingtonPost be-\ncame @HuffPost , and @TruthFeedNews became @TAftermath2020 . Those users will\nhave their new handle displayed in the 2016 tables for consistency (as well as in Figs. 4.7 and\n4.9).\n68\npolitical platforms (e.g. @amberofmanyhats ). The \u201cother\u201d category represents\nin\ufb02uencers whose accounts have no descriptions or context that could be used to\nidentify them.\nFig. 4.5: Reshuf\ufb02ing of distribution of the top 25 in\ufb02uencer types from 2016 to 2020, by\nnews media category. In\ufb02uencers are classi\ufb01ed as af\ufb01liated with a media organization, political\norganization, independent, or other (e.g. unidenti\ufb01ed).\nThe fractions of in\ufb02uencers in these categories are shown in Fig. 4.5. It reveals\nthat unaf\ufb01liated in\ufb02uencers are more common in the fake and extreme-bias cate-\ngories, while af\ufb01liated in\ufb02uencers are more common in the other news categories.\nA similar trend is evident in the fractions of veri\ufb01ed and unveri\ufb01ed in\ufb02uencers\nfound in these categories (see Tab. A.6), as fake and extreme-bias news categories\n69\nrank > 501\n2\n3\n4\n5\n6\n7\n8\n9\n10\n32\nCNN\nthehill\npolitico\nCNNPolitics\nReuters\nNateSilver538\nAP\nbusiness\nUSATODAY\nAP_Politics\nkylegriffin1\nJonLemire\nNewsweek\nyarotrof\nJoeBiden\nProjectLincoln1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n13\n29\nrank > 50\nLegend\nLinked to media organization\nLinked to political organization\nOtherIndependent\nFig. 4.6: Change in rankings 2016-2020, Center Bias . Outlines the change in the ranks of the\ntop 10 center bias users from 2016 and 2020, ranked by CI in\ufb02uence. Each \ufb02ow connects the best\nranking for a user in 2016, whose rank is displayed to the left of the user handle, to their rank\nin 2020. The color of the lines match the bias of the users best ranking, and gradients represent\na change in the bias classi\ufb01cation of their best ranking. Note user @kylegrif\ufb01n1 is more highly\nranked in the left leaning bias (rank 3) but we chose to show its center ranking for this center bias\nplot, as the difference in rank is small and it keeps the \ufb01gure focused on the center bias.\ngenerally contain fewer veri\ufb01ed in\ufb02uencers. In addition, media-af\ufb01liated in\ufb02u-\nencers seem to have a greater presence in the left, left-leaning, and center news\ncategories compared to their counterparts. Interestingly, the number of media-\naf\ufb01liated in\ufb02uencers within most of the categories actually decreases from 2016\nto 2020. The exceptions are the extreme-right bias and fake news categories,\nwhich actually increased in media-af\ufb01liated in\ufb02uencers, while the extreme-right\n70\nbias category also increased in politically-linked in\ufb02uencers. This indicates a shift\nin polarization of in\ufb02uencers af\ufb01liated with right-biased political and media orga-\nnizations toward the extreme-right bias and fake news, as well as the emergence\nof new media-af\ufb01liated in\ufb02uencers in these categories. We discuss these changes\nin more detail below. In addition to changes in user types and veri\ufb01ed users from\n2016 to 2020, we observe a signi\ufb01cant reshuf\ufb02e of the ranking of in\ufb02uencers.\nFig. 4.7 shows the change in rankings of the top 10 in\ufb02uencers in left and left-\nleaning, right and right-leaning and extreme-right bias and fake news categories.\nThe ranking reshuf\ufb02e in the center news category is shown in Fig. 4.6.\nThe comparison reveals several interesting changes between 2016 and 2020.\nFirst, we see that highly in\ufb02uential users rise from obscurity. Across all cat-\negories, a set of previously unranked or very low-ranked users break in to the\ntop-10 rankings. These users include, for example, @TeaPainUSA ,@svdate ,\n@kylegriffin1 ,@marklevinshow ,@DavidHarrisJr , etc. Considering\nall unique users in the top 25 in\ufb02uential users (across all categories of news me-\ndia), we see that 58% came from outside the top 100 in\ufb02uential users in 2016.\nHowever, most of these newly in\ufb02uential users are related in some way to media\nor political organizations, while 28% of these new in\ufb02uencers are independent.\nObserving the change in rankings by news media category, we see that right/right-\nleaning and extreme-right bias/fake news categories have a signi\ufb01cantly higher\n71\nfraction of top 10 in\ufb02uencers who were previously outside the top 50, compared to\nthe change in rankings among the groups in left/left-leaning news categories. All\ncategories show a large number of in\ufb02uencers falling out of the top 50 from 2016\nto 2020, and in the case of the left news in\ufb02uencers, we see their former positions\n\ufb01lled by users who were much less in\ufb02uential in 2016. The in\ufb02uencers with ex-\ntreme right bias and fake news af\ufb01liations show the most volatility with regards to\nretaining top-10 in\ufb02uencer positions, with many top-10 in\ufb02uencers in 2016 ranked\nbelow 50 in 2020 (or were even banned from Twitter, like @RealAlexJones ).\nThe change of classi\ufb01cation of some news media outlets is also re\ufb02ected in the\ncategory shifts of their Twitter accounts. In particular, @CNN and@politico\n\u2013 previously the \ufb01rst and third highest ranked in\ufb02uencers in the center category\nin 2016 \u2013 shifted to left-leaning. Such shifts of large and in\ufb02uential media in-\n\ufb02uencers across news categories indicates the increased content polarization on\nTwitter. A shift of media-af\ufb01liated in\ufb02uencers from the right to the extreme right\nis also visible (e.g. @DailyMail ,@JudicialWatch ,@marklevinshow ),\nas well as the emergence of new-media af\ufb01liated in\ufb02uencers in these categories\n(e.g. @newsmax ,@OANN or@RaheemKassam ). In contrast to the shift to the\nextremes among large media in\ufb02uencers, the center rankings remained fairly con-\nsistent between 2016 and 2020 as shown in Fig. 4.6. Some new users rose from\nlow ranks to \ufb01ll in the gaps, including @JoeBiden , but only one user dropped\n72\nIcon Legend\nLinked to media organization\nLinked to political organization\nOtherIndependentRank 2016 User Rank 2020\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n12\n3119\nrank > 50Rank 2016 User Rank 2020\n1\n2\n3\n4\n6\n7\n8\n9\n10\n11\n12\n14\n19\n32\nrank > 50Rank 2016 User Rank 2020\nFoxNews\nWSJ\nrealDonaldTrump\nDailyCaller\nWashTimes\nRT_com\ndcexaminer\nNEWS_MAKER\nRT_America\nnypost\nFoxNewsInsider\nWSJPolitics\nDailyMail\nAllenWest\nKellyannePolls\nRealJamesWoods\nTeamTrump\nLouDobbs\nfoxandfriends\nDonaldJTrumpJr\nmarklevinshow\nEricTrump\nbrithume\nMZHemingway\nKimStrassel\nSaraCarterDC\nTrumpWarRoom\njsolomonReports1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n31\n37\nrank > 50\nPrisonPlanet\nrealDonaldTrump\nDailyCaller\nRealAlexJones\nBreitbartNews\nzerohedge\nNEWS_MAKER\nwikileaks\nmitchellvii\nseanhannity\nDailyMail\nWayneDupreeShow\nLindaSuhler\nTAftermath2020\nRealJamesWoods\nRickRWells\nLouDobbs\ngatewaypundit\nDonaldJTrumpJr\nJudicialWatch\nmarklevinshow\nThomas1774Paine\nTomFitton\njoelpollak\nRaheemKassam\ndbongino\nnewsmax\nOANN\nDavidJHarrisJr\ncatturd21\n2\n3\n4\n5\n6\n7\n8\n9\n10\n13\n16\n27\n37\nrank > 501\n23\n4\n5\n6\n7\n8\n910\n13\n19273250\nrank > 50\nCNN\nHuffPost\nnytimes\nTIME\nwashingtonpost\nABC\npolitico\nthedailybeast\nCNNPolitics\nNBCNews\nRawStory\nHuffPostPol\nSlate\nNewYorker\nPolitiFact\nCBSNews\nMotherJones\nTPM\nvoxdotcom\nABCPolitics\nSalon\nezraklein\nthinkprogress\nMSNBC\nDavidCornDC\nNPR\nkylegriffin1\nNoahShachtman\nTeaPainUSA\nsvdate1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n14\n22\n25\n50\nrank > 50\nColor Legend\nCenter\nLeft Leaning\nLeft\nExtreme LeftExtreme Right\nRight\nRight LeaningFake\nFig.4.7:Change in in\ufb02uencers rankings from 2016 to 2020. In\ufb02uencers ranked in the top 10 in\nat least one news media category in 2016 or 2020 are shown. The 2016 rankings are displayed to\nthe left of the username, with 2020 rankings on the right. For each user only one shift is shown. Its\ncolor changes from the user\u2019s highest ranked news media category in 2016 to such color for 2020.\nEach panel shows the change over time between two news media categories.\nout of the top 50 entirely, and the remaining shifts are internal to these top-ranked\nusers.\n4.2.3 Polarization among Twitter Users\nThe evolution of in\ufb02uencers across different news media categories (Figs. 4.1 and\n4.2) suggests an increased polarization in the relations among in\ufb02uencers between\n73\nFig. 4.8: Similarity network for a random subsample of the 2020 in\ufb02uencers . Each edge is\nweighted by the cosine similarity between retweeting users. Size of the node represents that node\u2019s\ndegree centrality. The pie charts representing the nodes illustrate the news categories to which that\nnode belongs, with the size of the slices denoting their relative in\ufb02uence for that category. For\nclarity, edges below the average inter-community edge weight are hidden. Nodes are grouped\nrelative to each other by their detected community.\n2016 and 2020. Here we broaden the scope of polarization analysis to the Twitter\nusers who are consuming and retweeting the in\ufb02uencers\u2019 content. For the 2016\nand 2020 data, we consider the union of the top 100 in\ufb02uencers of each news me-\ndia category as a single set representing the most in\ufb02uential users covering the\nentire news media ideological spectrum for the target year. For this analysis we\nuse all the retweets in our datasets, not only those containing a link to a news\noutlet, and remove the ones sent from unof\ufb01cial Twitter clients to capture only\ntweets sent by humans. Using these in\ufb02uencers as nodes, we create two fully\nconnected similarity networks derived from the 2016 and 2020 Twitter network,\nrespectively. An edge between any two in\ufb02uencers in the created networks repre-\nsents similarity of the number of retweets of these two in\ufb02uencers for every user\nin the corresponding Twitter network (see Methods for more details). In both sim-\n74\nilarity networks, a community detection algorithm found two communities. One\ncontained in\ufb02uencers af\ufb01liated with news media in the center, left-leaning and left\nnews categories, while the other contained those af\ufb01liated with news media in the\nright-leaning, right and fake news categories. This indicates that in\ufb02uencers sep-\narate their user bases according to the content they generate. We illustrate this\nseparation in Fig. 4.8 that shows a sample of the 2020 similarity network. To\nquantify the difference in community separation and, subsequently, polarization,\nbetween the two networks, we measured the modularity and normalized cut be-\ntween communities (see section 4.4 for details).\nThe modularity for the 2020 network was 0.39 with a standard error (SE) of\n0.01, versus 0.365 (SE = 0.007) in 2016, indicating more closely knit communities\nin 2020, with stronger in-community ties and weaker between-community ties.\nConsistent with the increase of community modularity, the average normalized\ncut of 0.36 (SE = 0.04) in 2016 decreased to 0.128 (SE = 0.005) in 2020. To\ninterpret this change, we note that on average, each node in the 2016 similarity\nnetwork had 64% of in-community edges and 36% of across-community edges.\nThe latter fraction decreased to 13% in 2020, dropping nearly three times lower\nthan it was in 2016. This indicates much stronger separation of these communities\nin the later election. We also computed the above metrics on networks generated\nfrom user quote similarity in order to show that retweets are the strongest form\n75\nof endorsement of in\ufb02uencer content, and subsequently the best approach for our\nanalysis (see Tab. A.7).\nTo quantify and compare the polarization not only among Twitter in\ufb02uencers\nbut also among the users, we infer the ideology of Twitter users based on the ide-\nological alignment of political actors they follow [12], [47]. The bipartite network\nof followers is then projected on a one dimensional scale using correspondence\nanalysis [48], [49], which applies a SVD decomposition of the adjacency matrix\nstandardized to account for the differences in popularity and activity of the in\ufb02u-\nencers and their followers (see section 4.4 for details). Two users are close on the\nresulting latent ideology scale if they follow similar in\ufb02uencers. This method has\nbeen shown to produce ideological estimates of the members of the U.S. Congress\nhighly correlated with ideological estimates based on roll call voting similarity\nsuch as DW-NOMINATE [47].\nFor 2016 and 2020, the data for the analysis consists of the union of the top\n100 in\ufb02uencers of each news media category and the sets of users that retweeted\nat least three different in\ufb02uencers (considering all tweets in our datasets, not only\nthe ones with URLs). Following the \ufb01nding in [83] that \u201cretweeting indicates not\nonly interest in a message, but also trust in the message and the originator, and\nagreement with the message contents,\u201d we interpret retweeting a form of endorse-\nment of the content being retweeted. Twitter offers other types of interactions\n76\nallowing users to comment on the content, such as quote tweets and replies. The\nratio of quotes to retweets of users to in\ufb02uencers was very stable and small ( <5%)\nin 2016 and 2020, for users on the left and right sides of the latent ideology (see\nTab. A.8-A), which motivated our focus on retweets to infer the ideology of users.\nWe note that the ratio of quotes to retweets from users of one side of the ideology\nspectrum to in\ufb02uencers of the other side increased from 2016 to 2020, indicating\nan increased usage of quotes to comment on tweets from in\ufb02uencers of the oppo-\nsite side. However, the overall usage of quotes over retweets remained small (see\nTab. A.8-B). We extract the coordinates of each user on the \ufb01rst dimension of the\nresults of the correspondence analysis applied to the weighted network of retweets\nbetween the users and the in\ufb02uencers (see section 4.4 for the details and robust-\nness checks that we performed). Finally, for 2016 and 2020, the coordinates of\nall users are standardized to a mean of zero and a standard deviation of one. Two\nusers are close together on the latent ideology scale if they tend to retweet similar\nin\ufb02uencers. The in\ufb02uencers\u2019 latent ideological positions are then computed as the\nmedian of their retweeters\u2019 positions.\nFig. 4.9 shows the result of this analysis. The latent ideology of the top \ufb01ve\nin\ufb02uencers of each category is shown as a box plot representing the distribution\nof the ideology of the users who retweeted them. The distribution of ideology\npositions of the users and of the in\ufb02uencers, displayed in green and purple, re-\n77\n@CNNPolitics@NBCNews@TIME@HuffPost@crooksandliars@PalmerReport\n@Slate\n@HuffPostPol\n@thedailybeast@RawStory\n@Reuters@peterdaou\n@thehill@washingtonpost\n@ABC\n@WSJ@BoldBlueWave\n@Bipartisanism\n@CNN@nytimes\n@politico\n@RealAlexJones@RT_America\n@FoxNews@WashTimes\n@NEWS_MAKER@wikileaks@nypost\n@PrisonPlanet@zerohedge\n@dcexaminer\n@realDonaldTrump@DailyCaller\n@BreitbartNews@RT_comfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\nextreme bias left\n0369\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers@DearAuntCrabby@MeidasTouch\n@funder\n@HuffPost@DavidCornDC\n@thedailybeast\n@Reuters@JonLemire\n@thehill@washingtonpost@MSNBC\n@ABC\n@WSJ@ImpeachmentHour\n@kylegriffin1\n@AP@TheDemCoalition\n@CNN@nytimes\n@FoxNews@nypost\n@JudicialWatch@gatewaypundit\n@dbongino@realDonaldTrump\n@WayneDupreeShow\n@DavidJHarrisJr@marklevinshow\n@DonaldJTrumpJr@EricTrump@seanhannity@BreitbartNews\n@jsolomonReports\n@RealJamesWoodsfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\nextreme bias left\n0369\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers2016 2020\nLeft Left Right Right\nFig. 4.9: Latent ideology scale of in\ufb02uencers and their retweeters in 2016 (left) and 2020\n(right) . The latent ideology of the top \ufb01ve in\ufb02uencers of each category is shown as a box plot\nrepresenting the distribution of the ideology of the users who retweeted them. The distributions for\nthe users are shown in green, and the distributions for the top 100 in\ufb02uencers of each news media\ncategory (computed as the median of the ideology of their retweeters) are displayed in purple. Box\nplots indicate the 25% and 75% percentiles of the distributions with whiskers indicating the 5%\nand 95% percentiles. Pie charts next to the in\ufb02uencers\u2019 names represent the news categories to\nwhich they belong (weighted by their respective CI ranks in each category).\nspectively, shows that polarization increased between 2016 and 2020. This is\ncon\ufb01rmed by a Hartigans\u2019 dip test (HDT) for unimodality, which measures mul-\ntimodality in a sample by the maximum difference, over all sample points, be-\ntween the empirical distribution function, and the unimodal distribution function\nthat minimizes that maximum difference [115]. For the user distribution, the test\nstatistics isD= 0:1086 (95% CI: [0.108,0.109]) in 2016 and D= 0:1474 (95%\nCI: [0.1471,0.1477]) in 2020. For the in\ufb02uencer distribution, the test statistics is\n78\nD= 0:17(95% CI: [0.16,0.20]) in 2016 and D= 0:21(95% CI: [0.19,0.23])\nin 2020. All tests reject the null hypothesis of a unimodal distribution with p <\n2:2\u000210\u000016and the 95% con\ufb01dence intervals are computed from 1000 bootstrap\nsamples using the bias-corrected and accelerated method. Increasing values of the\ntest statistic indicates distributions that increasingly deviate from a unimodal dis-\ntribution, corroborating the growing division found in the similarity networks.\nTo understand if the measured increase in polarization is due to the arrival of new\nusers and in\ufb02uencers in 2020, we repeat this analysis including only users (shown\nin Fig. 4.10), only in\ufb02uencers (Fig. 4.11) or only users and in\ufb02uencers (Fig. 4.12)\nthat were active during both elections. In all cases we observe an increase of the\nHartigans\u2019 dip test (HDT) statistics (see Fig. 4.13 and Tab. A.9) indicating that\nthe increased polarization is not only due to the departure and arrival of new users\nbetween elections but also to a change of behavior of the users that remained. The\nlargest increase in HDT for the user distribution is obtained when all users of 2016\nand 2020 and only in\ufb02uencers that were present during both years are considered\n(+0:08). This setting also corresponds to the smallest increase of the dip test of\nthe in\ufb02uencer distribution ( +0:01, within 95% CI), suggesting that the new in\ufb02u-\nencers of 2020 have more polarized ideologies than the in\ufb02uencers who remained\nfrom 2016 and that the increased polarization of the users is due in large part to\nthe arrival and departure of users between elections (see Fig. 4.13 and Tab. A.9).\n79\n@DearAuntCrabby\n@MeidasTouch@funder\n@HuffPost@DavidCornDC\n@thedailybeast\n@Reuters@JonLemire\n@thehill@washingtonpost@MSNBC\n@ABC\n@WSJ@ImpeachmentHour\n@kylegriffin1\n@AP@TheDemCoalition\n@CNN@nytimes\n@FoxNews@nypost\n@JudicialWatch@gatewaypundit\n@dbongino@realDonaldTrump\n@WayneDupreeShow\n@DavidJHarrisJr@marklevinshow\n@DonaldJTrumpJr@EricTrump@seanhannity@BreitbartNews\n@jsolomonReports\n@RealJamesWoodsfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\nextreme bias left\n0369\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers@CNNPolitics@NBCNews@TIME@HuffPost@crooksandliars@PalmerReport\n@Slate\n@HuffPostPol\n@thedailybeast@RawStory\n@Reuters@peterdaou\n@thehill@washingtonpost\n@ABC\n@WSJ@BoldBlueWave\n@Bipartisanism\n@CNN@nytimes\n@politico\n@RealAlexJones@RT_America\n@FoxNews@WashTimes\n@NEWS_MAKER@wikileaks@nypost\n@PrisonPlanet@zerohedge\n@dcexaminer\n@realDonaldTrump@DailyCaller\n@BreitbartNews@RT_comfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\nextreme bias left\n0369\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers2020 2016\nLeft Right Left Right\nFig. 4.10: Latent ideology scale of in\ufb02uencers and their retweeters in 2016 (left) and 2020\n(right) using only users active in both years . The latent ideology of the top 5 in\ufb02uencers of each\ncategory is shown as a box plot representing the distribution of the ideology of the users having\nretweeted them. The distribution of the ideology estimate of the users is shown in green and the\ndistribution of the ideology estimate of the top 100 in\ufb02uencers of each news category (computed\nas the median of the ideology of their retweeters) is displayed in purple. Pie charts next to the\nin\ufb02uencers\u2019 names represent the news categories they belong to (weighted by their respective CI\nranks in each category). Hartigans\u2019 dip test for unimodality applied to the user distribution is\nD= 0:094(p < 2:2\u000210\u000016) in 2016 and D= 0:117(p < 2:2\u000210\u000016) in 2020. The test\nstatistics for the in\ufb02uencer distribution is D= 0:178(p <2:2\u000210\u000016) in 2016 and D= 0:214\n(p<2:2\u000210\u000016) in 2020.\nFigure 4.9 reveals a clear increase in polarization of the users and in\ufb02uencers\nin 2020 compared to 2016 and an alignment of their latent ideologies in two dis-\ntinct groups, mirroring the news media classi\ufb01cation groupings seen in Fig. 4.4\nand Fig. 4.8. The box plots show that the distributions of users retweeting in-\n80\n@CNNPolitics@NBCNews@HuffPost@PalmerReport\n@Slate\n@HuffPostPol\n@thedailybeast@RawStory\n@Reuters\n@thehill@washingtonpost\n@ABC\n@WSJ@CNN@nytimes\n@politico\n@FoxNews@WashTimes@nypost\n@PrisonPlanet@zerohedge\n@dcexaminer\n@realDonaldTrump@DailyCaller\n@BreitbartNews@RT_comfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\nextreme bias left\n036\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers@HuffPost@DavidCornDC\n@thedailybeast\n@Reuters\n@thehill@washingtonpost@MSNBC\n@ABC\n@WSJ@kylegriffin1\n@AP@CNN@nytimes\n@FoxNews@nypost\n@JudicialWatch@gatewaypundit\n@realDonaldTrump@WayneDupreeShow\n@marklevinshow\n@DonaldJTrumpJr@EricTrump@seanhannity@BreitbartNews\n@RealJamesWoodsfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\n036\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers2016 2020\nLeft Right Left Right\nFig. 4.11: Latent ideology scale of in\ufb02uencers and their retweeters in 2016 (left) and 2020\n(right) using only in\ufb02uencers active in both years . The latent ideology of the top 5 in\ufb02uencers\nof each category is shown as a box plot representing the distribution of the ideology of the users\nhaving retweeted them. The distribution of the ideology estimate of the users is shown in green\nand the distribution of the ideology estimate of the top 100 in\ufb02uencers of each news category\n(computed as the median of the ideology of their retweeters) is displayed in purple. Pie charts next\nto the in\ufb02uencers\u2019 names represent the news categories they belong to (weighted by their respective\nCI ranks in each category). Hartigans\u2019 dip test for unimodality applied to the user distribution is\nD= 0:107(p < 2:2\u000210\u000016) in 2016 and D= 0:183(p < 2:2\u000210\u000016) in 2020. The test\nstatistics for the in\ufb02uencer distribution is D= 0:163(p <2:2\u000210\u000016) in 2016 and D= 0:173\n(p<2:2\u000210\u000016) in 2020.\n\ufb02uencers became more concentrated in 2020, with two clear opposite poles and\nfewer in\ufb02uencers having a user base bridging opposite ideologies. These results\nindependently con\ufb01rm the shift of news outlets and in\ufb02uencers from the center\nto the right and left observed using the news media classi\ufb01cations by external\nsources. Indeed, we \ufb01nd an extremely high correlation (above 0:90for 2016 and\n81\n@CNNPolitics@NBCNews@HuffPost@PalmerReport\n@Slate\n@HuffPostPol\n@thedailybeast@RawStory\n@Reuters\n@thehill@washingtonpost\n@ABC\n@WSJ@CNN@nytimes\n@politico\n@FoxNews@WashTimes@nypost\n@PrisonPlanet@zerohedge\n@dcexaminer\n@realDonaldTrump@DailyCaller\n@BreitbartNews@RT_comfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\nextreme bias left\n0369\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers@HuffPost@DavidCornDC\n@thedailybeast\n@Reuters\n@thehill@washingtonpost@MSNBC\n@ABC\n@WSJ@kylegriffin1\n@AP@CNN@nytimes\n@FoxNews@nypost\n@JudicialWatch\n@gatewaypundit\n@realDonaldTrump\n@WayneDupreeShow\n@marklevinshow\n@DonaldJTrumpJr@EricTrump@seanhannity@BreitbartNews\n@RealJamesWoodsfake news\nextreme bias right\nright news\nright leaning newscenter news\nleft leaning news\nleft news\n0369\n\u22122 \u22121 0 1 2\nLatent ideologydensityinfluencers\nusers2016 2020\nLeft Right Left Right\nFig. 4.12: Latent ideology scale of in\ufb02uencers and their retweeters in 2016 (left) and 2020\n(right) using only users and in\ufb02uencers active in both years . The latent ideology of the top 5\nin\ufb02uencers of each category is shown as a box plot representing the distribution of the ideology of\nthe users having retweeted them. The distribution of the ideology estimate of the users is shown in\ngreen and the distribution of the ideology estimate of the top 100 in\ufb02uencers of each news category\n(computed as the median of the ideology of their retweeters) is displayed in purple. Pie charts next\nto the in\ufb02uencers\u2019 names represent the news categories they belong to (weighted by their respective\nCI ranks in each category). Hartigans\u2019 dip test for unimodality applied to the user distribution is\nD= 0:095(p < 2:2\u000210\u000016) in 2016 and D= 0:140(p < 2:2\u000210\u000016) in 2020. The test\nstatistics for the in\ufb02uencer distribution is D= 0:164(p <2:2\u000210\u000016) in 2016 and D= 0:171\n(p<2:2\u000210\u000016) in 2020.\n2020) between the users\u2019 latent ideology position and their left- or right-leaning\ndistribution computed using the news media categories in which they posted (see\nsection 4.4). This high correlation indicates that the shift in bias observed at the\nlevel of the media outlets is also present at the level of the users\u2019 retweeting pattern\nand serves as an independent validation of the media outlet classi\ufb01cation.\n82\ninfluencers usersall datacommon\ninfluencerscommon\nuserscommon users\nand influencers\n2016 2020 2016 20200.150.20\n0.1250.1500.1750.200\n0.120.160.200.24\n0.090.120.150.180.21D\ninfluencers users\nFig.4.13: Hartigans\u2019 dip test values for ideology distribution of users and in\ufb02uencers when consid-\nering all users and in\ufb02uencers or only in\ufb02uencers or users present in 2016 and 2020. 95% CI error\nbars are obtained by bootstrap with 1000 runs for each dataset and Bias-corrected and accelerated\ncon\ufb01dence intervals method. The numerical values are reported in Table A.9.\n4.3 Discussion\nThis work uses Twitter retweets to study polarization among in\ufb02uencers and those\nthey in\ufb02uence in the months leading up the 2016 and 2020 U.S. Presidential elec-\ntions. Multiple analyses con\ufb01rm a robust pattern of increasing division into oppos-\ning echo chambers, largely due to the arrival of new, more polarized in\ufb02uencers\nand users in 2020. Among the top 100 in\ufb02uencers aggregated across all news\nmedia categories in 2020, seventy-\ufb01ve percent were not present in 2016, demon-\n83\nstrating how dif\ufb01cult it is to retain in\ufb02uencer status. The number of in\ufb02uencers\naf\ufb01liated with media organizations declined by 10% between 2016 and 2020, re-\nplaced by in\ufb02uencers af\ufb01liated with political organizations with center or right\norientations and those with independent organizational af\ufb01liation. Most of the in-\n\ufb02uencers who appeared in 2020 were associated with prominent media or political\nparty organizations.\nFuture research should build on this structural analysis by examining the con-\ntent of the messages. Content analysis is needed to distinguish between tweets\nthat are positively and negatively quoted and to develop measures of in\ufb02uence that\ngo beyond the ability to attract attention from retweeters. For example, an ur-\ngent question to answer is whether the in\ufb02uence of unaf\ufb01liated Twitter in\ufb02uencers\ngoes beyond being news spreaders: do they also have the ability to set the issue\nagenda? Our study is limited to describing what happened on Twitter. Future re-\nsearch should analyze message content for clues about the ability of in\ufb02uencers\nto mobilize voters and social movements of\ufb02ine. We also focused on the \ufb02ow of\ninformation from in\ufb02uencers to those who retweet them. Future research should\ninvestigate how the actions of the retweeters and followers affect the in\ufb02uencers,\nhow in\ufb02uencers form networks across types of media, and what are the of\ufb02ine\nconsequences of polarization of Twitter in\ufb02uencers and users, including the im-\npact on voting. It should also be possible to monitor interactions on other social\n84\nmedia and during non-election periods to permit \ufb01ner grained analysis of the new\nentrants.\n4.4 Methods\n4.4.1 News Media URL Classi\ufb01cation\nThe website www.allsides.com (AS) rates media bias using a combination of\nseveral methods such as blind surveys, editorial review, third party analysis (e.g.\nacademic research), independent review and community feedbacks (see www.\nallsides.com/media-bias/media-bias-\\rating-methods for a\ndetailed explanation of their methodology). The website mediabiasfact\\\ncheck.com (MBFC) scores media bias by evaluating wording, sourcing, and\nstory choices as well as political endorsement (see mediabiasfactcheck.\ncom/methodology ). MBFC is maintained by a small independent team of\nresearchers and journalists, offers the largest set of biased and inaccurate news\nsources among \ufb01ve fact checking datasets [116], and is widely used for labeling\nbias and veracity of news sources (e.g., in [117]\u2013[119]).\nTo be consistent with the results from 2016 [18], we discard as insigni\ufb01cant\noutlets that accumulate less than 1%of the cumulative number of tweets of the\nmore popular outlets in each category. Removing uniformly insigni\ufb01cant outlets\nfrom all categories also ensures that the tweet volume in each category is indepen-\n85\ndent of the number of outlets classi\ufb01ed in this category by AS and MBFC. The full\nlists of outlets in each category in 2016 and 2020 are given in Tabs. A.1 and A.2.\nAS and MBFC updated their bias classi\ufb01cation for several outlets between 2016\nand 2020, changing the classi\ufb01cation used in our analyses as well. For example,\nCNN Web News was classi\ufb01ed in the center category in 2016 by AS and then in\ntheleft-leaning category in 2020, re\ufb02ecting a bias shift occurring during this time\n(seewww.allsides.com/blog/yes-cnns-media-bias-has\n-shifted-left ).\nIn Ref. [18], the fake news and extreme-bias categories were based on the clas-\nsi\ufb01cation of a team of media experts (available at github.com/alexbovet/\nopensources ) and was cross-checked using the factual reporting scores from\nMBFC. As the classi\ufb01cation source from 2016 was not updated in 2020, we use\nthe list of outlets classi\ufb01ed as \u201cquestionable sources\u201d from MBFC as a reference\nfor 2020. MBFC describes a questionable source as one \u201cthat exhibits one or more\nof the following: extreme bias, consistent promotion of propaganda/conspiracies,\npoor or no sourcing to credible information, a complete lack of transparency\nand/or is fake news.\u201d MBFC rates the factual reporting of each source on a scale\nfrom 0 (very high) to 10 (very low) based on their history of reporting factually\nand backing up claims with well-sourced evidence. Outlets with a level of \u201clow\u201d\n(score of 7, 8 or 9) or \u201cvery low\u201d (score of 10) are classi\ufb01ed in the fake news\n86\ncategory while outlets with a \u201cmixed\u201d level (score of 5 or 6) are classi\ufb01ed in the\nextremely biased category. No outlets in the disinformation categories have a level\nhigher than \u201cmixed.\u201d A \u201clow\u201d or \u201cvery low\u201d factual reporting level on MBCF cor-\nresponds to sources that rarely, or almost never use credible sources and \u201cneed to\nbe checked for intentional fake news, conspiracy, and propaganda.\u201d A \u201cmixed\u201d\nlevel is assigned to sources that \u201cdo not always use proper sourcing or source to\nother biased/mixed factual sources.\u201d We also verify that all outlets in the extremely\nbiased category have a \u201cbias\u201d reported on MBFC of \u201cright\u201d, \u201cextreme right\u201d, \u201cleft\u201c\nor \u201cextreme left.\u201d\nWe identify in our datasets (we give the top hostname as an example in paren-\nthesis) for the fake news category: 16 hostnames in 2016 (top: thegatewaypundit.\ncom) and 20 hostnames in 2020 (top: thegatewaypundit.com ), for the ex-\ntremely biased (right) category: 17 hostnames in 2016 (top: breitbart.com )\nand 10 hostnames in 2020 (top: breitbart.com ), for the extremely biased\n(left) category: 7 hostnames in 2016 (top: dailynewsbin.com ) and 7 host-\nnames in 2020 (top: occupydemocrats.com ), for the left news category: 18\nhostnames in 2016 (top: huffingtonpost.com ) and 18 hostnames in 2020\n(top:rawstory.com ), for the left-leaning news category: 19 hostnames in 2016\n(top:nytimes.com ) and 19 hostnames in 2020 (top: nytimes.com ), for the\ncenter news category: 13 hostnames in 2016 (top: cnn.com ) and 13 hostnames in\n87\n2020 (top: thehill.com ), for the right-leaning news category: 7 hostnames in\n2016 (top: wsj.com ) and 13 hostnames in 2020 (top: nypost.com ), for right\nnews category: 20 hostnames in 2016 (top: foxnews.com ) and 19 hostnames in\n2020 (top: foxnews.com ). The full lists of outlets in each category in 2016 and\n2020 are given in SI Tabs. A.1 and A.2.\n4.4.2 In\ufb02uencer Type Classi\ufb01cation\nFor each of the years 2016 and 2020, we manually classi\ufb01ed the top-25 in\ufb02uencers\nin each news media category as af\ufb01liated to a media organization or a political or-\nganization, or unaf\ufb01liated (classi\ufb01ed either as an independent user or as an uniden-\nti\ufb01ed \u201cother\u201d user). The manual labeling procedure was as follows: Eight of the\nauthors were randomly assigned a subset of the union of the top-25 in\ufb02uencers in\nthese category lists to independently classify, such that each subset was examined\nby three different authors. Each author was shown the account name of the in-\n\ufb02uencer along with descriptions, posts, and all available non-Twitter information\nsuch as their Wikipedia entry. Each in\ufb02uencer was then assigned their category\nbased on the majority vote of the three independent classi\ufb01cations.\n88\n4.4.3 Similarity Network Analysis\nWe start by creating for each in\ufb02uencer ia vector~Siof sizeU, which stands for\nthe number of users in our dataset. We used a set of 588in\ufb02uencers for the 2016\ndataset, and a set of 661in\ufb02uencers for the 2020 dataset. An index uis assigned\nto the speci\ufb01c user. The vector element si\nude\ufb01nes the number of times user uhas\nretweeted in\ufb02uencer i. Then, we create the adjacency matrix Aof sizeI\u0002Ifor\nour similarity networks by setting ai1;i2to the cosine similarity between vectors\n~Si1and~Si2. It follows that the higher the cosine similarity, the more users have\nthe similar number of retweets for in\ufb02uencers i1;i2.\nWe detect communities in the similarity network using the Louvain algorithm [45].\nIn the similarity networks for both election years, we found two communities.\nUsing the accounts of in\ufb02uencers in each community, we found that both elec-\ntion years one community contains in\ufb02uencers primarily associated with fake\nand right-biased news categories, while the other contains in\ufb02uencers from center\nand left-biased news categories. This split coincides with an underlying division\namong the Twitter user bases in the content they propagate.\nWe quantify the severity of this split using two measures of separation between\ncommunities. First is modularity that computes the sum of difference between\nthe fraction of edges within each community and such fraction expected within\n89\nthis community in a random network with the same number of nodes and edges.\nThis metric has a range of [\u00000:5;1][46]. A positive value indicates the presence\nof communities separated from each other. The closer the modularity is to 1, the\nstronger communities are separated.\nThe second measure uses the normalized cut, which is the sum of the weights\nof every edge that links a pair communities divided by the sum of the weights of\nall edges. The result has a range of [0;1]where the smaller the value, the stronger\nthe separation among communities.\n4.4.4 Latent Ideology Estimation\nThe latent ideology estimation follows the method developed in [12], [47] adapted\nto using retweet interactions instead of following relations. As in [12], we use\ncorrespondence analysis [48] (CA) to infer ideological positions of Twitter users.\nThe adjacency matrix, A, of the retweet network between the in\ufb02uencers and\ntheir retweeters is the matrix with element aijequal to the number of times user i\nretweeted in\ufb02uencer j. We only select tweets that have been sent from the of\ufb01cial\nTwitter client in order to limit the presence of bots and professional accounts and\nwe also remove users that show a low interest in the U.S. elections by removing\nusers that retweeted less than three different in\ufb02uencers. For the 2016 data, the\nmatrix Ahas 751,311 rows corresponding to distinct users, 593 columns corre-\n90\nsponding to in\ufb02uencers and the total number of retweets equal to 39,385,772. For\nthe 2020 data, the matrix Ahas 2,034,970 rows corresponding to distinct users,\n591 columns corresponding to in\ufb02uencers and the total number of retweets equal\nto 153,463,788.\nThe CA method is executed in the following steps [49]. The matrix of standard-\nized residuals of the adjacency matrix is computed as S=D\u00001=2\nr(P\u0000rc)D\u00001=2\nc,\nwhere P=A(P\nijaij)\u00001is the adjacency matrix normalized by the total number\nof retweets, r=P1is the vector of row sums, c=1TPis the vector of col-\numn sums, Dr=diag(r)andDc=diag(c). Using the standardized residuals\nallows the inference to account for the variation of popularity and activity of the\nin\ufb02uencers and the users, respectively [12]. Then, a SVD is computed such that\nS=UD\u000bVTwithUUT=VVT=IandD\u000bbeing a diagonal matrix with the\nsingular values on its diagonal. The positions of the users are given by the standard\nrow coordinates: X=D\u00001=2\nrUwhere we only consider the \ufb01rst dimension, cor-\nresponding to the largest singular value. Finally, the ideological positions of the\nusers are found by standardizing the row coordinates to have a mean of zero and a\nstandard deviation of one. The ideological position of the in\ufb02uencers is given by\nthe median of the weighted positions of their retweeters.\nWe tested the robustness of our method by varying the way we construct ma-\ntrixAas follow: 1) removing entries with weight 1 to discard relations show-\n91\ning a weak ideological alignment; 2) considering the logarithm of the number of\nretweets as weight for in\ufb02uencer for a sublinear relation between the number of\nretweets and the strength of ideology alignment; 3) considering a random subsam-\nple of the 2020 retweet data of the same size than the 2016 retweet data to control\nfor a potential effect of the difference in sizes of the two datasets. All of these ro-\nbustness tests match the results of our initial method with correlation coef\ufb01cients\nbetween the user position distributions in the robustness tests and in the initial con-\n\ufb01guration at above 0.995. We also compare the users\u2019 latent ideology distribution\nwith the users average leaning distribution and \ufb01nd a correlation above 0.90 for\n2016 and 2020. The average leaning of users is computed for all users having at\nleast three tweets classi\ufb01ed in at least one news media category and estimated as\nthe weighted average of the news media category positions, given as: fake news =\n4/3, extreme-right bias = 1, right = 2/3, right-leaning = 1/3, center = 0, left-leaning\n= -1/3, left = -2/3, extreme-left bias = -1.\n92\n93\nCHAPTER 5\nEV ALUATION OF THE ECHO CHAMBER IMPACT ON SOCIAL\nMEDIA\nPrevious chapter analyzes the changes between 2020 and 2016 U.S. presidential\nelections. One of the main results of the study is the increase in polarization from\n2016 to 2020: respect to 2016, in 2020 the two factions interacted less and in-\ncreased the distance between their political position. Our \ufb01nding is also supported\nby recent events such as the Capitol Hill riot, which could be seen as an expression\nof such increase in polarization and radicalization of the electorate.\nAlthough users segregation is the consequence of a plethora of contributing\ncauses, online environmental factors may foster polarization and favor the raise of\nonline echo chambers. In particular, platforms\u2019 feed algorithms may be respon-\nsible for increasing the homogeneity of users\u2019 news diet and boost homophilic\ninteractions. In this chapter, we provide a comparative analysis of the echo cham-\nber effect in four different social media around several topics. By means of net-\nworks built upon users\u2019 interaction, we also compare the spreading dynamic and\nstudy the presence of echo chambers around the same topic in different platforms.\nOur analysis provide insights on the differences and similarities of echo chambers\n94\nacross different social media and around several topics.\n5.1 Introduction\nSocial media radically changed the mechanism we access information and form\nour opinions [2], [11], [120]\u2013[122]. We need to understand how people seek or\navoid information and how those decisions affect their behavior [123], especially\nwhen the news cycle\u2014dominated by the disintermediated diffusion of informa-\ntion\u2014alters the way information is consumed and reported on. A recent study [14]\nlimited to Twitter claimed that fake news travels faster than real ones. However, a\nmultitude of factors affects information spreading on social media platforms. On-\nline polarization, for instance, may foster misinformation spreading [2], [68]. Our\nattention span remains limited [4], [124], and feed algorithms might limit our se-\nlection process by suggesting contents similar to the ones we are usually exposed\nto [3], [5], [119]. Furthermore, users show the tendency to favor information ad-\nhering to their beliefs and join groups formed around a shared narrative, i.e., echo\nchambers [2], [6]\u2013[10]. We can broadly de\ufb01ne echo chambers as environments in\nwhich the opinion, political leaning, or belief of users about a topic get reinforced\ndue to repeated interactions with peers or sources having similar tendencies and\nattitudes. Selective exposure [125] and con\ufb01rmation bias [126] (i.e., the tendency\nto seek information adhering to pre-existing opinions) may explain the emergence\n95\nof echo chambers on social media [2], [9], [40], [57].\nAccording to group polarization theory [42], an echo chamber can act as a\nmechanism to reinforce an existing opinion within a group, and as a result, move\nthe entire group towards more extreme positions. Echo chambers have been shown\nto exist in various forms of online media such as blogs [127], forums [128], and\nsocial-media sites [12], [129], [130]. Some studies point out echo chambers as an\nemerging effect of human tendencies, such as selective exposure, contagion, and\ngroup polarization [5], [42], [131]\u2013[133]. However, recently, the effects and the\nvery existence of echo chambers have been questioned [11]\u2013[13]. This issue is\nalso fueled by the scarcity of comparative studies on social media, especially for\nwhat concerns news consumption [43]. In this context, the debate around echo\nchambers is fundamental to understanding social media\u2019s in\ufb02uence on informa-\ntion consumption and public opinion formation. In this paper, we explore the key\ndifferences between social media platforms and how they are likely to in\ufb02uence\nthe formation of echo chambers or not. As recently shown in the case of selective\nexposure to news outlets, studies considering multiple-platforms can offer a fresh\nview to long-debated problems [134]. Different platforms offer different interac-\ntion paradigms to users, ranging from retweets and mentions on Twitter to likes\nand comments in groups on Facebook, thus triggering very different social dynam-\nics [135]. We introduce an operational de\ufb01nition of echo chambers to provide a\n96\ncommon methodological ground to explore how different platforms in\ufb02uence their\nformation. In particular, we operationalize the two common elements that char-\nacterize echo chambers into observables that can be quanti\ufb01ed and empirically\nmeasured, namely: ( i) the inference of the user\u2019s leaning for a speci\ufb01c topic (e.g.,\npolitics, vaccines), ( ii) the structure of their social interactions on the platform.\nThen, we use these elements to assess echo chambers\u2019 presence by looking at two\ndifferent aspects: ( i) homophily in interactions concerning a speci\ufb01c topic and ( ii)\nbias in the information diffusion from like-minded sources. We focus our analy-\nsis on multiple platforms: Facebook, Twitter, Reddit, and Gab. These platforms\npresent similar features and functionalities (e.g., they all allow social feedback ac-\ntions such as likes or upvotes) and design (e.g., Gab is similar to Twitter) but also\ndistinctive features (e.g., Reddit is structured in communities of interest called\nsubreddits). Reddit is one of the most visited websites worldwide1and is orga-\nnized as a forum to collect discussions on a wide range of topics, from politics to\nemotional support. Gab claims to be a social platform aimed at protecting free-\ndom of speech. However, low moderation and regulation on content has resulted\nin widespread hate speech. For these reasons, it has been repeatedly suspended by\nits service provider, and its mobile app has been banned from both App and Play\nstores [136]. Overall, we account for the interactions of more than 1M active users\n1https://www.alexa.com/siteinfo/reddit.com\n97\non the four platforms, for a total of more than 100M unique pieces of content, in-\ncluding posts and social interactions. Our analysis shows that platforms organized\naround social networks and news feed algorithms, such as Facebook and Twitter,\nfavor the emergence of echo chambers.\nWe conclude this work by directly comparing news consumption on Facebook\nand Reddit, \ufb01nding higher segregation on Facebook than on Reddit.\n5.2 Characterizing Echo Chambers in Social Media\n5.2.1 Operational De\ufb01nitions\nTo explore the key differences between social media platforms and how they in\ufb02u-\nence echo chambers\u2019 formation, we need to operationalize a de\ufb01nition for them.\nFirst, we need to identify the attitude of users at a micro-level. On online so-\ncial media, the individual leaning of a useritoward a speci\ufb01c topic, xi, can\nbe inferred in different ways, via the content produced, or the endorsement net-\nwork among users [137]. Concerning content, we can de\ufb01ne the leaning as the\nattitude expressed by a piece of content towards a speci\ufb01c topic. This leaning\ncan be explicit (e.g., arguments supporting a narrative) or implicit (e.g., framing\nand agenda-setting). Let us consider a user iproducing a number aiof contents,\nCi=fc1;c2;:::;caig, whereaiis the activity of useriand each content leaning is\nassigned a numeric value. Then the individual leaning of user ican be de\ufb01ned as\n98\nthe average of the leanings of produced contents,\nxi\u0011Pai\nj=1cj\nai: (5.1)\nOnce inferred individual leanings, polarization can be de\ufb01ned as a state of the\nsystem such that the distribution of leanings, P(x), is concentrated in one or more\nclusters. A possible example is the case of a single cluster, distinguishable by a\nsingle, extreme peak in P(x). Another example is the typical case of topics char-\nacterized by positive versus negative stances, in which a bimodal distribution can\ndescribe polarization. For instance, if opinions are assumed to be embedded in\na one-dimensional space [138], x2[\u00001;+1]without loss of generality, as usual\nfor controversial topics, then polarization is characterized by two well-separated\npeaks inP(x), for positive and negative opinions. In contrast, neutral ones are\nabsent or underrepresented in the population. Note that polarization can happen\nindependently from the structure or the very presence of social interactions. Ho-\nmophily in social interactions can be quanti\ufb01ed by representing interactions as a\nsocial network and then analyzing its structure concerning the opinions of the users\n[10], [105], [139]. Social networks can be reconstructed in different ways from on-\nline social media, where links represent social relationships or interactions. Since\nwe are interested in capturing the possible exchange of opinions between users, we\nassume links as the substrate over which information may \ufb02ow. For instance, if\n99\nuserifollows user jon Twitter, user ican see tweets produced by user j, there is a\n\ufb02ow of information from node jto nodeiin the network. When the reconstructed\nnetwork is directed, we assume the link direction points to potential in\ufb02uencers\n(opposite of information \ufb02ow). Actions such as mentions or retweets may convey\nsimilar \ufb02ows. In some cases, direct relations between users are not available in\nthe data, so one needs to assume some proxy for social connections, e.g., a link\nbetween two users if they comment on the same post on Facebook. Crucially,\nthe two elements characterizing the presence of echo chambers, polarization, and\nhomophilic interactions, should be quanti\ufb01ed independently.\n5.2.2 Implementation on Social Media\nThis section explains how we implement the operational de\ufb01nitions de\ufb01ned above\non different social media. For each medium, we detail (i)how we quantify users\u2019\nleaning, and (ii)how we reconstruct how the information spread.\nTwitter . We consider the set of tweets posted by user ithat contain links to\nnews outlets of known political leaning. Each news outlet is associated with a\npolitical leaning score ranging from extreme left to extreme right following the\nMaterials and Methods classi\ufb01cation. We infer the individual leaning of a user\ni,xi2[\u00001;+1] by averaging the news organizations\u2019 scores linked by user i\naccording to (5.1). We analyze three different data sets collected on Twitter related\n100\nto controversial topics: gun control, Obamacare, and abortion. For each data set,\nthe social interaction network is reconstructed using the following relation so that\nthere is a direct link from node ito nodejif userifollows user j(i.e., the source).\nHenceforth we focus on the data set about abortion, and others are reported in the\nresults section without discussion.\nFacebook . We quantify the individual leaning of users considering endorse-\nments in the form of likes to posts. Posts are produced by pages that are labeled\nin a certain number of categories, and to each category, we assign a numerical\nvalue (e.g., Anti-Vax (+1) or Pro-Vax (-1)). Each like to a post (only one like\nper post is allowed) represents an endorsement for that content, which is assumed\nto be aligned with the leaning associated with the page. Thus, the user\u2019s leaning\nis de\ufb01ned as the average of the content leanings of the posts liked by the user,\naccording to (5.1).\nWe analyze three different data sets collected on Facebook regarding a speci\ufb01c\ntopic of discussion: vaccines, science versus conspiracy, and news. The interaction\nnetwork is de\ufb01ned by considering comments. In such an interaction network, two\nusers are connected if they co-commented at least one post. Henceforth we focus\non the data set about vaccines and news, and others are reported in the results\nsection without discussion.\nReddit . The individual leaning of users is quanti\ufb01ed similarly to Twitter by\n101\nconsidering the links to news organizations in the content produced by the users,\nsubmissions, and comments. We build the interaction network considering com-\nments and submissions. There exists a direct link from node ito nodejif user\nicomments on a submission or comment by user j(we assume that ireads the\ncomment they are replying to, which is written by j).\nWe analyze three data sets collected on different subreddits: the donald, poli-\ntics, and news. In the following, we focus on the data set collected on the Politics\nand the News subreddit, and others are reported in the results section without dis-\ncussion.\nGab. The political leaning xiof useriis computed by considering the set of\ncontents posted by user icontaining a link to news outlets of a known political\nleaning, similarly to Twitter and Reddit. To obtain the leaning xiof useri, we\naveraged the scores of each link posted by user iaccording to (5.1). The interac-\ntion network is reconstructed by exploiting the co-commenting relationships under\nposts in the same way as for Facebook. Given two users iandj, an undirected edge\nbetweeniandjexists if and only if they comment under the same post.\n5.3 Comparative Analysis\nIn the following, we perform a comparative analysis of four different social me-\ndia. We select one dataset for each social media: Abortion (Twitter), Vaccines\n102\n(Facebook), Politics (Reddit), and Gab as a whole. Results for other datasets for\nthe same medium are qualitatively similar and we show them in section 5.5.5. We\n\ufb01rst characterize echo chambers in the networks\u2019 topology, then look at their ef-\nfects on information diffusion. Finally, we directly compare news consumption on\nFacebook and Reddit.\n5.3.1 Polarization and Homophily in the Interaction Networks\nThe network\u2019s topology can reveal echo chambers, where users are surrounded by\npeers with similar leaning, and thus they get exposed with a higher probability\nto similar contents. In network terms, this translates into a node iwith a given\nleaningximore likely to be connected with nodes with a leaning close to xi[10].\nThis concept can be quanti\ufb01ed by de\ufb01ning, for each user i, the average leaning of\ntheir neighborhood, as xN\ni\u00111\nk!\niP\njAijxj, whereAijis the adjacency matrix of\nthe interaction network, Aij= 1if there is a link from node ito nodej,Aij= 0\notherwise, and k!\ni=P\njAijis the out-degree of node i. Fig. 5.1 shows the cor-\nrelation between the leaning of a user iand the leaning of their neighbors, xN\ni,\nfor the four social media under consideration. The probability distributions P(x)\n(individual leaning) and PN(x)(average leaning of neighbors) are plotted on the\nxandyaxis, respectively. All plots are color-coded contour maps, representing\nthe number of users in the phase space (x;xN): the brighter the area in the plan,\n103\n(a) Twitter (b) Reddit\n(c) Facebook (d) Gab\nFig. 5.1: Joint distribution of the leaning of users xand the average leaning of their neighborhood\nxNNfor different data sets. Colors represent the density of users: the lighter, the larger the number\nof users. Marginal distribution P(x)andPN(x)are plotted on the x and y axis, respectively.\nFacebook and Twitter present by homophilic clustering.\nthe larger the density of users in that area. The topics of vaccines and abortion,\non Facebook and Twitter, respectively show a strong correlation between the lean-\ning of a user and the average leaning of their nearest neighbors. Similar behavior\nis found for different topics from the same social media platform, as shown in\n104\nsection 5.5.5. Conversely, Reddit, and Gab show a different picture. The corre-\nsponding plots in Fig. 5.1 display a single bright area, indicating that users do not\nsplit into groups with opposite leaning but form a single community, biased to the\nleft (Reddit) or the right (Gab). Similar results are found for different data sets on\nReddit, as shown in section 5.5.5\n(a) Twitter (b) Reddit\n(c) Facebook (d) Gab1101001000\n1 2 3 4 5\nCommunity IDCommunity Size\nAgainst\nAbortionPro\nAbortion\n110100100010000\n0 5 10 15 20\nCommunity IDCommunity Size\nExtreme\nLeftExtreme\nRight\n101103105\n0 20 40 60\nCommunity IDCommunity Size\nPro VaccinesAnti Vaccines\n110100100010000\n0 5 10 15 20\nCommunity IDCommunity Size\nExtreme\nLeftExtreme\nRight\nFig. 5.2: Size and average leaning of communities detected in different data sets. Panels a and c\nshow the full spectrum of leanings related to the topics of abortions and vaccines w.r.t communities\nin panels b and d where the political leaning is less sparse.\n105\nThe presence of homophilic interactions can be con\ufb01rmed by the community\nstructure of the interaction networks. We detect communities by applying the Lou-\nvain algorithm [45], removing singleton communities with only one user. Then,\nwe computed each community\u2019s average leaning, determined as the average of in-\ndividual leanings of its members. Fig. 5.2 shows the communities emerging for\neach social medium, arranged by increasing average leaning on the x-axis (color-\ncoded from blue to red), while the y-axis reports the size of the community. On\nFacebook and Twitter, communities span the whole spectrum of possible lean-\nings, but users with similar leanings form each community. Some communities\nare characterized by a robust average leaning, especially in the case of Facebook.\nThese results are in accordance with the observation of homophilic interactions.\nInstead, communities on Reddit and Gab do not cover the whole spectrum, and all\nshow similar average leaning. Furthermore, the almost total absence of communi-\nties with leaning very close to 0 con\ufb01rms the polarized state of the systems.\n5.3.2 Effects on Information Spreading\nSimple models of information spreading can gauge the presence of echo chambers:\nusers are expected to exchange information more likely with peers sharing a sim-\nilar leaning [10], [44], [140]. Classical epidemic models such as the susceptible-\ninfected-recovered (SIR) model [141] have been used to study the diffusion of in-\n106\nformation, such as rumors or news [142]\u2013[144]. In the SIR model, each agent can\nbe in either of three states: susceptible (unaware of the circulating information),\ninfectious (aware and willing to spread it further), or recovered (knowledgeable\nbut not ready to transmit it anymore). Susceptible (unaware) users may become\ninfectious (aware) upon contact with infected neighbors, with a speci\ufb01c transmis-\nsion probability \f. Infectious users can spontaneously become recovered with\nprobability\u0017. To measure the effects of the leaning of users on the diffusion of\ninformation, we run the SIR dynamics on the interaction networks, by starting the\nepidemic process with only one node iinfected, and stopping it when no more\ninfectious nodes are left.\nThe set of nodes in a recovered state at the end of the dynamics started with user\nias a seed of infection, i.e., those that become aware of the information initially\npropagated by user iforms the set of in\ufb02uence of useri,Ii[50]. Thus, the set of\nin\ufb02uence of a user represents those individuals that can be reached by a piece of\ncontent sent by him/her, depending on the effective infection ratio \f=\u0017. One can\ncompute the average leaning of the set of in\ufb02uence of user i,\u0016i, as\n\u0016i\u0011jIij\u00001X\nj2I ixj: (5.2)\nThe quantity \u0016iindicates how polarized are the users that can be reached by a\nmessage initially propagated by user i[10].\n107\nFig. 5.3 shows the average leaning h\u0016(x)iof the in\ufb02uence sets reached by users\nwith leaning x, for the different data sets under consideration. The recovery rate\n\u0017is \ufb01xed at 0.2 for every dataset. In contrast, the ratio between the infection rate\n\fand average degree hkidepends on the speci\ufb01c dataset and is reported in the\ncaption of each \ufb01gure.\nAgain, one can observe a clear distinction between Facebook and Twitter, on\none side, and Reddit and Gab on the other side. For the topics of vaccines and\nabortion, on Facebook and Twitter, respectively, users with a given leaning are\nmuch more likely to be reached by information propagated by users with similar\nleaning, i.e.,h\u0016(x)i\u0018x. Similar behavior is found for different topics from the\nsame social media platform, as shown in section 5.5.5. Conversely, Reddit and\nGab show a different behavior: the average leaning of the set of in\ufb02uence, h\u0016(x)i,\ndoes not depend on the leaning x. As expected, the average leaning in these media\nis not zero. Still, it assumes negative (positive) values in Reddit (Gab), indicating\nthat the users of this platform are more likely to receive left (right)-leaning content.\nThese results indicate that information diffusion is biased toward individuals\nwho share similar leaning in some social media, namely Twitter and Facebook. In\ncontrast, in others \u2013 Reddit and Gab in our analysis \u2013 this effect is absent. Such\na latter con\ufb01guration may depend upon two factors: a) Gab and Reddit are not\nbursting the echo chamber effects, or b) we are observing the dynamic inside a\n108\nsingle echo chamber.\nOur results are robust for different values of the effective infection ratio \f=\u0017,\nas shown in section 5.5.6 Furthermore, Fig. 5.3 shows that the spreading capacity,\nrepresented by the average size of the in\ufb02uence sets (color-coded in Fig. 5.3),\ndepends on the leaning of the users. On Twitter, pro-abortion users are more\nlikely to reach larger audiences. The same is true for anti-vax users on Facebook,\nleft-leaning users on Reddit, and right-leaning users on Gab (in this data set, left-\nleaning users are almost absent).\n5.3.3 News Consumption on Facebook and Reddit\nThe striking differences observed across social media, in terms of homophily in\nthe interaction networks and information diffusion, could be attributed to different\ntopics taken into account. For this reason, here we compare Facebook and Reddit\non a common topic, news consumption. Facebook and Reddit are particularly apt\nto a cross-comparison since they share the de\ufb01nition of individual leaning (com-\nputed by using the classi\ufb01cation provided by mediabiasfactcheck.org, see Mate-\nrials and Methods for further details) and the rationale in creating connections\namong users that is based on an interaction network. Fig. 5.4 shows a direct\ncomparison of news consumption on Facebook and Reddit along the metrics used\nin the previous Sections to quantify the presence of echo chambers: i) the corre-\n109\n(a) Twitter (b) Reddit\n(c) Facebook (d) Gab\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n4080120160Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n20002500300035004000Influence Set \nAverage Size\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n1000200030004000Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n100200300Influence Set \nAverage Size\nFig. 5.3: Average leaning h\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, for dif-\nferent data sets under consideration. Size and color of each point represent the average size of\nthe in\ufb02uence sets. The parameters of the SIR dynamics are set to \f= 0:10hki\u00001for panel (a),\n\f= 0:01hki\u00001for panel (b), \f= 0:05hki\u00001for panel (c) and \f= 0:05hki\u00001for panel (d), while\n\u0017is \ufb01xed at 0.2 for all simulations.\nlation between the leaning of a user xand the average leaning of neighbors xN\n(top row), ii) the average leaning of communities detected in the networks (middle\nrow), and iii) the average leaning h\u0016(x)iof the in\ufb02uence sets reached by users\nwith leaning x, by running SIR dynamics (bottom row). One can see that all three\n110\nmeasures con\ufb01rm the picture obtained for other data sets: On Facebook, we ob-\nserve a clear separation among users depending on their leaning, while on Reddit,\nusers\u2019 leanings are more homogeneous and show only one peak. In the latter social\nmedia, even users displaying a more extreme leaning (noticeable in the marginal\nhistogram of Figure 5.4 column (b) top row) tend to interact with the majority.\nMoreover, on Facebook, the seed user\u2019s leaning affects who the \ufb01nal recipients\nof the information are, therefore indicating the presence of echo chambers. On\nReddit, this effect is absent.\n5.4 Conclusions\nSocial media platforms provide direct access to an unprecedented amount of con-\ntent. Platforms originally designed for user entertainment changed the way infor-\nmation spread. Indeed, feed algorithms mediate and in\ufb02uence the content promo-\ntion accounting for users\u2019 preferences and attitudes. Such a paradigm shift affected\nthe construction of social perceptions and the framing of narratives; it may in\ufb02u-\nence policy-making, political communication, and the evolution of public debate,\nespecially on polarizing topics. Indeed, users online tend to prefer information\nadhering to their worldviews, ignore dissenting information, and form polarized\ngroups around shared narratives. Furthermore, when polarization is high, misin-\nformation quickly proliferates.\n111\nSome argued that the veracity of the information might be used as a determi-\nnant for information spreading patterns. However, selective exposure dominates\ncontent consumption on social media, and different platforms may trigger very\ndifferent dynamics. In this work, we explore the key differences between the lead-\ning social media platforms and how they are likely to in\ufb02uence the formation of\necho chambers and information spreading.\nTo assess the different dynamics, we perform a comparative analysis on more\nthan 100M pieces of content concerning controversial topics (e.g., gun control,\nvaccination, abortion) from Gab, Facebook, Reddit, and Twitter. The analysis fo-\ncuses on two main dimensions: i) homophily in the interaction networks and ii)\nbias in the information diffusion toward like-minded peers. Our results show that\nthe aggregation in homophilic clusters of users dominate online dynamics. How-\never, a direct comparison of news consumption on Facebook and Reddit shows\nhigher segregation on Facebook. Furthermore, we \ufb01nd signi\ufb01cant differences\nacross platforms in terms of homophilic patterns in the network structure and bi-\nases in the information diffusion towards like-minded users. A clear-cut distinc-\ntion emerges between social media having a feed algorithm tweakable by the users\n(e.g., Reddit) and social media that don\u2019t provide such an option (e.g., Facebook\nand Twitter). Our work provides important insights into the understanding of so-\ncial dynamics and information consumption on social media. The next envisioned\n112\nstep addresses the temporal dimension of echo chambers to understand better how\ndifferent social feedback mechanisms, speci\ufb01c to distinct platforms, can impact\ntheir formation.\n5.5 Materials and Methods\nHere we provide details about the labelling of news outlets and the data sets con-\nsidered.\n5.5.1 Labelling of Media Sources\nThe labelling of news outlets is based on the information provided by Media\nBias/Fact Check (MBFC https://mediabiasfactcheck.com ), an inde-\npendent fact-checking organization that rates news outlets on the base of the relia-\nbility and of the political bias of the contents they produce and share. The website\nprovides the political bias related to a wide range of media outlets. The labelling\nprovided by MBFC, retrieved in June 2019, ranges from Extreme Left to Extreme\nRight for what concerns the political bias. Moreover, certain media outlets are\nclassi\ufb01ed as \u2018questionable\u2019 sources or \u2018conspiracy-pseudoscience\u2019 sources if they\ntend to publish misinformation or false contents. Often, such news outlets (with-\nout an explicit political label reported by MBFC) actually display a political bias\nthat is reported in their description, as shown in Figure 5.5.\n113\nConsidering the importance of including such media outlets in our analysis, we\nmanually reported their classi\ufb01cation from the description provided by MBFC,\nthus adding 468outlets to the pool of 1722 news outlets that already have a clear\npolitical label. The total number of labelled news outlets is 2190 and the overall\nleaning is summarized in Figure 5.6. In order to compute the individual leaning of\nusers we convert each label into a numerical value, namely, -1 for Extreme Left,\n-0.66 for Left, -0.33 for Left-Center, 0 for Least Biased, 0.33 for Right-Center,\n0.66 for Right and +1 for Extreme Right.\n5.5.2 Data Availability Statement\nFor what concerns Gab, all data are available on the Pushshift public reposi-\ntory ( https://pushshift.io/what-is-pushshift-io/ ) at this link\nhttps://files.pushshift.io/gab/ . Reddit Data are available on the\nPushshift public repository at this link https://search.pushshift.io/\nreddit/ . For what concerns Facebook and Twitter, we provide data according to\ntheir Terms of Services on the corresponding author institutional page at this link\nhttps://walterquattrociocchi.site.uniroma1.it/ricerca . For\nnews outlet classi\ufb01cation, we used data from Media Bias Fact-check ( https:\n//mediabiasfactcheck.com ), an independent fact-checking organization.\nFor further details about data, refer to the following section.\n114\n5.5.3 Empirical Data Sets\nTable 5.1 reports summary statistics of the data sets under consideration. Due to\nthe structural differences among platforms, each dataset has different features. For\nTwitter, we used tweets regarding three topics collected by Garimella et al. [8],\nnamely Gun control ,Obamacare , and Abortion . Tweets linking to a news\nsource with a known bias are classi\ufb01ed based on MBFC. Facebook data sets\nwere created by using Facebook Graph API and were previously explored in [107]\n(Science and Conspiracy ), [145] ( Vaccines ) and [3] ( News ). For the two data\nsetsScience and Conspiracy andVaccines , data were labelled in a binary way,\nrespectively pro vaccines/anti vaccines and pro science/conspiracy based on the\npage they were posted. Posts in the data set News were instead classi\ufb01ed based on\nMBFC labelling. Reddit datasets have been obtained by downloading comments\nand submission posted in the subreddit Politics ,The Donald andNews and la-\nbelled according to the classi\ufb01cation obtained from MBFC. Gab data set has been\ncollected from https://files.pushshift.io/gab and contains posts,\nreplies and quotes. Posts were labelled according to MBFC classi\ufb01cation. We\nprovide a detailed description of each datasets in the next section.\n115\n5.5.4 Dataset Detailed Description\nTwitter\nWe follow a two-step procedure for creating the Twitter datasets. First, tweets\nduring the interest periods are retrieved from the Internet Archive Twitter Stream.2\nFor each topic, we use the keywords speci\ufb01ed by Lu et al. [146]. Each user that has\nposted 5or more tweets on the topic during the window of interest is considered\nactive. We then use the Twitter\u2019s REST API3to collect all tweets and followers for\neach active user. These tweets and relationships are the basis for reconstructing\neach network. For more info on the datasets, see the work by Garimella et al. [8].\nGun control : The interest window spans 14 days in June 2016. We consider\nC= 19 M tweets produced by N= 7506 users. We reconstruct a directed follow\nnetwork formed by E= 1 053 275 directed edges. The largest weakly connected\ncomponent includes more than 99% of nodes. We identify the individual leaning\nofNc= 6994 users.\nObamacare : The interest window spans 7 days in June 2016. We consider\nC= 34 M tweets produced by N= 8773 users. We reconstruct a directed follow\nnetwork formed by E= 3 797 871 directed edges. The largest weakly connected\ncomponent includes more than 99% of nodes. We identify the individual leaning\n2https://archive.org/details/twitterstream\n3https://developer.twitter.com/en/docs/twitter-api/v1\n116\nofNc= 7899 users.\nAbortion : The interest window spans 7 days in June 2016. We consider\nC= 34 M tweets produced by N= 3995 users. We reconstruct a directed follow\nnetwork formed by E= 2 330 276 directed edges. The largest weakly connected\ncomponent includes more than 99% of nodes. We identify the individual leaning\nofNc= 3809 users.\nFacebook\nScience and Conspiracy : The dataset was built by downloading posts of selected\nFacebook pages divided into two groups, namely conspiracy news and science\nnews. Conspiracy pages were selected based on their name, their self description\nand with the aid of debunking pages. The selection process was iterated until\nconvergence among annotators. The dataset, that includes post from pages and\ncomments to such posts, was created by using Facebook Graph API and has been\npreviously explored [107]. We consider 75 172 posts by 73 pages categorized in\nScience (34) and Conspiracy (39) that involve N= 183 378 active users (at least\n1 like and 1 comments), for which we identify the individual leaning, that co-\ncommented 20 807 976 times. Using this dataset we build an undirected network,\nwhere two users (nodes) are connected if and only if they commented under the\nsame post at least once. The largest connected component of the co-commenting\n117\nnetwork has G= 181 960 nodes andE= 20 807 491 links.\nVaccines : The dataset was generated in three steps: \ufb01rst a search for pages\ncontaining the keywords vaccine, vaccines, or vaccination was made. Then the raw\noutcome was cleaned from spurious pages. Finally, all the posts and comments of\nselected pages were downloaded and pages were manually classi\ufb01ed in Pro-Vax\nand Anti-Vax groups. The dataset was created by using Facebook Graph API\nand has been previously explored [145]. We consider 94 776 posts by 243 pages\ncategorized in Pro-Vax (145) and Anti-Vax (98) that involve 221 758 active users\n(at least 1 like and 1 comment), for which we identify the individual leaning,\nthat co-commented 46 198 446 times. Using this dataset we build an undirected\nnetwork, where two users (nodes) are connected if and only if they commented\nunder the same post at least once. The largest connected component of the co-\ncommenting network has G= 220 275 nodes andE= 46 193 632 links.\nNews : The dataset was built by considering a set of Facebook pages of news\noutlets listed by the Europe Media Monitor. By using the Facebook Graph API,\nall the posts and comments related to these pages in the period 2010-2015 were\ndownloaded. Facebook pages are labelled according to the annotation obtained\nby MBFC. The dataset without annotations has been previously explored [3]. We\nconsider 15 540 posts by 180 pages categorized from Left to Right (Left (12),\nLeft-Center (80), Least-Biased (42), Right-Center (33), Right (13)). Such posts\n118\nwere co-commented 13 525 230 times by 38663 active users (users with at least 3\nlikes and 3 comments), for which we identify the individual leaning. Using this\ndataset we build a undirected network, where two users (nodes) are connected\nif and only if they commented under the same post at least once. The largest\nconnected component of the co-interaction network has G= 38 594 nodes and\nE= 13 525 119 links.\n5.5.4 Reddit\nPolitics : We consider 353 864 comments and submissions posted on the subreddit\npolitics in the year 2017. From comments under submissions we reconstructed\na directed network formed by N= 240 455 users andE= 5 030 565 directed\nedges, where each edge represents a direct reply to a comment. The largest weakly\nconnected component includes more than 99% of nodes. We exploited the classi-\n\ufb01cation retrieved from MBFC to identify the individual leaning of Nc= 37 148\nusers, that is considered as a scalar feature of the node.\nThe Donald : We consider 1:234M comments and submissions posted on the\nsubreddit TheDonald in the year 2017. From comments a submissions we re-\nconstructed a directed network formed by N= 138 617 users andE= 5 025 290\ndirected edges, where each edge represents a direct reply to a comment. The\nlargest weakly connected component includes more than 99% of nodes. We ex-\n119\nploited the classi\ufb01cation retrieved from MBFC to identify the individual leaning\nofNc= 21 905 users.\nNews : We consider 723 235 comments and submissions posted on the subreddit\nnews in the year 2017. From comments a submissions we reconstructed a directed\nnetwork formed by N= 179 549 users andE= 1 070 589 directed edges, where\neach edge represents a direct reply to a comment. The largest weakly connected\ncomponent includes more than 99% of nodes. We exploited the classi\ufb01cation re-\ntrieved from MBFC to identify the individual leaning of Nc= 36 875 users.\nGab\nThe dataset, downloaded from https://files.pushshift.io/gab , spans\nfrom the \ufb01rst Gab post (occurred in 2016) to the late 2018 and it includes data re-\ngarding post-reply relationships, number of upvotes of posts, repost or replies and\ntheir timestamps. We selected all the contents (post, reply, quote) in the time win-\ndow ranging from 11/2017 to 10/2018, that is C= 13 580 937 unique pieces of\ncontent created by N= 165 162 unique users. We consider all the post that have\na link to an external source, for an amount of 3 302 621 posts (excluding YouTube\nlinks). By extracting the domain from each link we obtain a set of 75 436 unique\ndomains. In this set, 1650 unique domains for a total of 1 454 502 URLs ( 44%)\nwere labelled using the classi\ufb01cation provided by MBFC. We identi\ufb01ed the in-\n120\nTable 5.1: For each data set, we report: the starting date of collection T0, time spanTexpressed in\ndays (d) or years (y), number of unique contents C, number of users N, coveragenc(fraction of\nusers with classi\ufb01ed leaning), size of the giant component Gand average node degree hki.\nMedia Data set T0T C N n cGhki\nTwitterGun control 06/2016 14 d 19M 3963 0.93 3717 798\nObamacare 06/2016 7 d 39M 8703 0.90 8703 1405\nAbortion 06/2016 7 d 34M 7401 0.95 6828 478\nFacebookSci/Cons 01/2010 5 y 75 172 183 378 1.00 181960 228\nVaccines 01/2010 7 y 94 776 221 758 1.00 220275 419\nNews 01/2010 6 y 15 540 38 663 1.00 38594 700\nRedditPolitics 01/2017 1 y 353 864 240 455 0.15 240455 9\nThe Donald 01/2017 1 y 1:234M138 617 0.16 138617 31\nNews 01/2017 1 y 723 235 179 549 0.20 179549 3\nGab Gab 11/2017 1 y 13M165 162 0.13 20701 328\ndividual leaning of Nc= 31 286 users. We also reconstructed the interaction\nnetwork using co-commenting as a proxy, that is, two users are connected if and\nonly if they commented under the same post at least once. The largest connected\ncomponent of the network includes G= 20 701 nodes, about 66% of the users\nwith assigned leaning, and E= 8 273 412 edges. The individual leaning xiis\nconsidered as a scalar feature of the node.\n5.5.5 Analysis for other Datasets\nIn this section we report the results obtained for other four data sets not discussed\nin the sections before for the sake of brevity, namely \u201cScience and Conspiracy\u201d\n(Facebook), \u201cGun control\u201d (Twitter), \u201cObamacare\u201d (Twitter) and \u2018The Donald\u201d\n(Reddit). The techniques and the pipeline is the same used for the datasets ana-\n121\nlyzed in the previous sections.\nScience and Conspiracy\nFigure 5.7 displays the results obtained for the Facebook dataset called \u201cScience\nand Conspiracy\u201d, described in Section 5.5.4. Panel (a) shows the joint distribution\nof the leaning of users, x, against the average leaning of their neighborhood XN.\nWe note that the community referred to as \u201cScience\u201d, to which is associated a\nleaning of -1, is much smaller than the community called \u201dConspiracy\u201d and for\nthis reason it is not clearly visible in the density plot but only in the histograms at\nits margins. Panel (b) shows the size and average leaning of communities detected\nby the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning\nh\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, for two different\nvalues of the infection probability, while the recovery rate is \ufb01xed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ufb02uence sets.\nGuncontrol\nFigure 5.8 shows the results obtained for the Twitter dataset \u201cGun control\u201d, de-\nscribed in Section 5.5.4. Panel (a) shows the joint distribution of the leaning of\nusers,x, against the average leaning of their neighborhood XN, in which two dif-\n122\nferent regions are clearly visible. Panel (b) shows the size and average leaning of\ncommunities detected by the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning\nh\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, for two different\nvalues of the infection probability, while the recovery rate is \ufb01xed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ufb02uence sets.\nObamacare\nFigure 5.9 shows the results obtained for the Twitter dataset referred to as \u201cOba-\nmacare\u201d, described in Section 5.5.4. Panel (a) shows the joint distribution of the\nleaning of users, x, against the average leaning of their neighborhood XN, in\nwhich two interconnected regions are clearly visible. Panel (b) shows the size and\naverage leaning of communities detected by the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning\nh\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, for two different\nvalues of the infection probability, while the recovery rate is \ufb01xed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ufb02uence sets.\n123\nTheDonald\nFigure 5.10 shows the results obtained for the Reddit dataset \u201cThe Donald\u201d, de-\nscribed in Section 5.5.4. Panel (a) displays the joint distribution of the leaning of\nusers,x, against the average leaning of their neighborhood XN, showing a unique\nregion spanning most of the x-axis and concentrated on the values around 0.25 on\nthe y-axis. Such a region is also characterized by few peaks of leaning (spanning\nmainly from Center to Extreme Right) that are displayed in the histogram on the\ntop margin. Panel (b) shows the size and average leaning of communities detected\nby the Louvain algorithm.\nPanels (c) and (d) show the results of the SIR dynamics: the average leaning\nh\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, for two different\nvalues of the infection probability, while the recovery rate is \ufb01xed \u0017= 0:2. Size\nand color of each point is related to the average size of the in\ufb02uence sets.\n5.5.6 Robustness of the SIR Dynamics\nIn this section, we provide additional results for the SIR dynamics run with differ-\nent parameters on the 6 data sets considered in section 5.3, namely \u201cAbortion\u201d on\nTwitter, \u201cPolitics\u201d and \u201cNews\u201d on Reddit, \u201cVaccines\u201d and \u201cNews\u201d on Facebook,\nand Gab.\nThe results, reported in Fig. 5.11, are qualitatively identical to the ones in\n124\nthe main paper and are reported here for the sake of brevity. Details about the\nparameters used in the simulations are provided in the caption of Fig. 5.11.\n125\n110100100010000\n2 4 6 8 10 12\nCommunity IDCommunity Size\nExtreme\nLeftExtreme\nRight\n1101001000\n0 10 20 30 40\nCommunity IDCommunity Size\nExtreme LeftExtreme Right\n\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n5101520Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n600700800900Influence Set \nAverage Size\n(a) Facebook (b) Reddit\nFig.5.4: Direct comparison of news consumption on Facebook (left column) and Reddit (right col-\numn) Joint distribution of the leaning of users xand the average leaning of their nearest-neighbor\nxN(top row), size and average leaning of communities detected in the interaction networks (mid-\ndle row), and average leaning h\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, by\nrunning SIR dynamics (bottom row) with parameters \f= 0:05hkifor panel (a) and \f= 0:006hki\nfor panel (b) and \u0017= 0:2for both. Facebook presents a highly segregated structure w.r.t. Reddit\n126\nFig. 5.5: Example of the web page of MBFC for two news outlets, namely New York Time and\nBreitbart. Notice that, although Breitbart is labeled as \u201dQuestionable\u201d, an explicit leaning appears\nin its description.\n0100200300400500\nExtreme LeftLeft\nLeft\u2212CenterLeast\nRight\u2212CenterRight\nExtreme Right\nFig. 5.6: Distribution of the leanings assigned to each source, ranging from Extreme Left (numer-\nical value: -1, colored in blue) to Extreme Right (numerical value: +1, colored in red).\n127\n(a) \n1e+011e+031e+05\n0 5 10 15 20\nCommunity IDCommunity Size\nScienceConspiracy\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nseed leaninginfluence set leaning\n2.02.53.03.5Influence set \naverage size\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n306090Influence Set \nAverage Size(b) \n(c) (d) \nFig.5.7: Science vs Conspiracy. Panel (a): Individual leaning versus neighborhood leaning. Panel\n(b): Community detection. Panel (c) and (d): average leaning h\u0016(x)iof the in\ufb02uence sets reached\nby users with leaning x, for infection probability \f= 0:01hki\u00001and\f= 0:02hki\u00001, respectively,\nwherehkiis the average degree of the network.\n128\n(a) (b) \n(c) (d) \n1101001000\n1 2 3\nNumber of CommunitiesCommunity Size\nAgainst\nGuncontroPro\nGuncontrol\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n20406080Influence Set \nAverage Size\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n3.54.04.55.05.5Influence Set \nAverage Size\nFig. 5.8: Gun control. Panel (a): Individual leaning versus neighborhood leaning. Panel (b):\nCommunity detection. Panel (c) and (d): average leaning h\u0016(x)iof the in\ufb02uence sets reached by\nusers with leaning x, for infection probability \f= 0:1hki\u00001and\f= 0:2hki\u00001, respectively, where\nhkiis the average degree of the network.\n129\n(a) (b) \n(c) (d) \n1101001000\n1 2 3 4\nNumber of CommunitiesCommunity Size\nAgainst ObamacarePro Obamacare\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n100200300400500Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n46810Influence Set \nAverage Size\nFig. 5.9: Obamacare. Panel (a): Individual leaning versus neighborhood leaning. Panel (b): Com-\nmunity detection. Panel (c) and (d): average leaning h\u0016(x)iof the in\ufb02uence sets reached by users\nwith leaning x, for infection probability \f= 0:1hki\u00001and\f= 0:2hki\u00001, respectively, where hki\nis the average degree of the network.\n130\n(a) (b) \n(c) (d) \n1101001000\n0 10 20 30\nCommunity IDCommunity Size\nExtreme\nLeftExtreme\nRight\n\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n255075100125Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n23002400250026002700Influence Set \nAverage Size\nFig. 5.10: The Donald. Panel (a): Individual leaning versus neighborhood leaning. Panel (b):\nCommunity detection. Panel (c) and (d): average leaning h\u0016(x)iof the in\ufb02uence sets reached by\nusers with leaning x, for infection probability \f= 0:0067hki\u00001and\f= 0:013hki\u00001, respectively,\nwherehkiis the average degree of the network.\n131\n(a) Abortion(Twitter) (b) Politics (Reddit)\n(c) Vaccines (Facebook) (d) Gab\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n4.04.55.05.56.06.5Influence Set \nAverage Size\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n100200300400Influence Set \nAverage Size\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n4.04.55.05.56.0Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n5678910Influence Set \nAverage Size\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n2345Influence Set \nAverage Size\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\n\u22121.0\u22120.50.00.51.0\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSeed LeaningInfluence Set Leaning\n200022002400Influence Set \nAverage Size\n(c) News (Facebook) (d) News (Reddit)\nFig. 5.11: Additional results of the SIR dynamics for the six data sets considered in the main\npaper. Average leaning h\u0016(x)iof the in\ufb02uence sets reached by users with leaning x, for infection\nprobability\f= 0:05hki\u00001(Abortion on Twitter, panel (a)), \f= 0:005hki\u00001(Politics on Reddit,\npanel (b)),\f= 0:02hki\u00001(Vaccines on Facebook, panel (c)), \f= 0:025hki\u00001(Gab, panel (d)),\n\f= 0:025hki\u00001(News on Facebook, panel (e)), \f= 0:01hki\u00001(News on Reddit, panel (f)), while\nthe recovery rate is \ufb01xed \u0017= 0:2. Size and color of each point is related to the average size of the\nin\ufb02uence sets.\n132\n133\nCHAPTER 6\nMEASURING THE RISE OF COVID-19 DEBATE ON SOCIAL MEDIA\nThe previous chapter was dedicated to the study of the echo chambers effect on\ndifferent platform and around several debated topics. Our study showed that users\ntend to interact with peers holding the same beliefs and thus cluster together into\nideologically homogeneous groups. This tendency may be fostered by platform\nfeed algorithms that strongly suggest contents adhering to users beliefs. Moreover,\nour analysis also revealed important insights on the spreading patterns of news\ninside echo chambers and how each platform may experience different diffusion\npatterns. Hence, one question of primary interest is how events of high public\ninterest are debated on different platforms.\nIn this chapter, we analyze the impact of a dramatic event such as the COVID-\n19 outbreak on different online environments. We compare the information con-\nsumption about COVID-19 in \ufb01ve different social platforms considering both the\ncontents created and the engagement they receive. We also study the diffusion of\nnews from reliable and questionable sources and compare their popularity across\nplatforms.\n134\n6.1 Introduction\nThe World Health Organization (WHO) de\ufb01ned the SARS-CoV-2 virus outbreak\nas a severe global threat[147]. As foreseen in 2017 by the global risk report of the\nWorld Economic forum, global risks are interconnected. In particular, the case of\nthe COVID-19 epidemic (the infectious disease caused by the most recently dis-\ncovered human coronavirus) is showing the critical role of information diffusion\nin a disintermediated news cycle [1].\nThe term infodemic [24], [148] has been coined to outline the perils of misin-\nformation phenomena during the management of disease outbreaks [149]\u2013[151],\nsince it could even speed up the epidemic process by in\ufb02uencing and fragmenting\nsocial response [152]. As an example, CNN has recently anticipated a rumor about\nthe possible lock-down of Lombardy (a region in northern Italy) to prevent pan-\ndemics[153], publishing the news hours before the of\ufb01cial communication from\nthe Italian Prime Minister. As a result, people overcrowded trains and airports\nto escape from Lombardy toward the southern regions before the lock-down was\nput in place, disrupting the government initiative aimed to contain the epidemics\nand potentially increasing contagion. Thus, an important research challenge is to\ndetermine how people seek or avoid information and how those decisions affect\ntheir behavior [123], particularly when the news cycle \u2013 dominated by the disin-\n135\ntermediated diffusion of information \u2013 alters the way information is consumed and\nreported on.\nThe case of the COVID-19 epidemic shows the critical impact of this new infor-\nmation environment. The information spreading can strongly in\ufb02uence people\u2019s\nbehavior and alter the effectiveness of the countermeasures deployed by govern-\nments. To this respect, models to forecast virus spreading are starting to account\nfor the behavioral response of the population with respect to public health in-\nterventions and the communication dynamics behind content consumption [152],\n[154], [155].\nSocial media platforms such as YouTube and Twitter provide direct access to\nan unprecedented amount of content and may amplify rumors and questionable\ninformation. Taking into account users\u2019 preferences and attitudes, algorithms me-\ndiate and facilitate content promotion and thus information spreading [156]. This\nshift from the traditional news paradigm profoundly impacts the construction of\nsocial perceptions [3] and the framing of narratives; it in\ufb02uences policy-making,\npolitical communication, as well as the evolution of public debate [145], [157],\nespecially when issues are controversial [2]. Users online tend to acquire infor-\nmation adhering to their worldviews [4], [40], to ignore dissenting information\n[124], [158] and to form polarized groups around shared narratives [57], [109].\nFurthermore, when polarization is high, misinformation might easily proliferate\n136\n[68], [159]. Some studies pointed out that fake news and inaccurate information\nmay spread faster and wider than fact-based news [14]. However, this might be\nplatform-speci\ufb01c effect. The de\ufb01nition of \u201cFake News\u201d may indeed be inadequate\nsince political debate often resorts to labelling opposite news as unreliable or fake\n[16]. Studying the effect of the social media environment on the perception of po-\nlarizing topics is being addressed also in the case of COVID-19. The issues related\nto the current infodemics are indeed being tackled by the scienti\ufb01c literature from\nmultiple perspectives including the dynamics of hatespeech and conspiracy theo-\nries [160], [161], the effect of bots and automated accounts [162], and the threats\nof misinformation in terms of diffusion and opinions formation [163], [164].\nIn this work we provide an in-depth analysis of the social dynamics in a time\nwindow where narratives and moods in social media related to the COVID-19 have\nemerged and spread. While most of the studies on misinformation diffusion focus\non a single platform [2], [14], [18], the dynamics behind information consumption\nmight be particular to the environment in which they spread on. Consequently,\nin this study we perform a comparative analysis on \ufb01ve social media platforms\n(Twitter, Instagram, YouTube, Reddit and Gab) during the COVID-19 outbreak.\nThe dataset includes more than 8 million comments and posts over a time span\nof 45 days. We analyze user engagement and interest about the COVID-19 topic,\nproviding an assessment of the discourse evolution over time on a global scale for\n137\neach platform. Furthermore, we model the spread of information with epidemic\nmodels, characterizing for each platform its basic reproduction number ( R0), i.e.\nthe average number of secondary cases (users that start posting about COVID-\n19) an \u201cinfectious\u201d individual (an individual already posting on COVID-19) will\ncreate. In epidemiology, R0= 1 is a threshold parameter. When R0<1the\ndisease will die out in a \ufb01nite period of time, while the disease will spread for\nR0>1. In social media, R0>1will indicate the possibility of an infodemic.\nFinally, coherently with the classi\ufb01cation provided by the fact-checking orga-\nnization Media Bias/Fact Check [165] that classi\ufb01es news sources based on the\ntruthfulness and bias of the information published, we split news outlets into two\ngroups. These groups are either associated to the diffusion of (mostly) reliable or\n(mostly) questionable contents and we characterize the spreading of information\nregarding COVID-19 relying on this classi\ufb01cation. We \ufb01nd that users in main-\nstream platforms are less susceptible to the diffusion of information from ques-\ntionable sources and that information deriving from news outlets marked either as\nreliable or questionable do not present signi\ufb01cant difference in the way it spreads.\nOur \ufb01ndings suggest that the interaction patterns of each social media com-\nbined with the peculiarity of the audience of each platform play a pivotal role in\ninformation and misinformation spreading. We conclude the paper by measuring\nrumor\u2019s ampli\ufb01cation parameters for COVID-19 on each social media platform.\n138\n6.2 Results\nWe analyze mainstream platforms such as Twitter, Instagram and YouTube as well\nas less regulated social media platforms such as Gab and Reddit. Gab is a crowd-\nfunded social media whose structure and features are Twitter-inspired. It performs\nvery little control on content posted; in the political spectrum, its user base is\nconsidered to be far-right. Reddit is an American social news aggregation, web\ncontent rating, and discussion website based on collective \ufb01ltering of information.\nWe perform a comparative analysis of information spreading dynamics around\nthe same argument in different environments having different interaction settings\nand audiences. We collect all pieces of content related to COVID-19 from the 1st\nof January to the 14th of February. Data have been collected \ufb01ltering contents ac-\ncordingly to a selected sample of Google Trends\u2019 COVID-19 related queries such\nas:coronavirus ,coronavirusoutbreak ,imnotavirus ,ncov ,ncov -19,pandemic ,wuhan .\nThe deriving dataset is then composed of 1,342,103 posts and 7,465,721 comments\nproduced by 3,734,815 users. For more details regarding the data collection refer\nto section 6.4.\n139\n6.2.1 Interaction Patterns\nFirst, we analyze the interactions (i.e., the engagement) that users have with COVID-\n19 topics on each platform. The upper panel of Figure 6.1 shows users\u2019 engage-\nment around the COVID-19 topic. Despite the differences among platforms, we\nobserve that they all display a rather similar distribution of the users\u2019 activity char-\nacterized by a long tail. This entails that users behave similarly for what concern\nthe dynamics of reactions and content consumption. Indeed, users\u2019 interactions\nwith the COVID-19 content present attention patterns similar to any other topic\n[166]. The highest volume of interactions in terms of posting and commenting\ncan be observed on mainstream platforms such as YouTube and Twitter.\nThen, to provide an overview of the debate concerning the disease outbreak,\nwe extract and analyze the topics related to the COVID-19 content by means of\nNatural Language Processing techniques. We build word embedding for the text\ncorpus of each platform, i.e. a word vector representation in which words sharing\ncommon contexts are in close proximity. Moreover, by running clustering pro-\ncedures on these vector representations, we separate groups of words and topics\nthat are perceived as more relevant for the COVID-19 debate. For further details\nrefer to section 6.4. The results (Figure 6.1, middle panel) show that topics are\nquite similar across each social media platform. Debates range from comparisons\n140\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n1\n2\n3\n4\n5\n 6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n100101102103104\n100100.5101101.5102\nNumber of interactionsNumber of postsfavourite\nreblog\nreplyGab\n100101102103\n100101102103104\nNumber of interactionsNumber of postscommentReddit\n100101102103104\n100102104106\nNumber of interactionsNumber of postscomment\ndislike\nlike\nviewY ouTube\n100101102103104\n100101102103104105\nNumber of interactionsNumber of postscomment\nlikeInstagram\n100101102103104105106\n100101102103104\nNumber of interactionsNumber of postsfavourite\nretweetTwitter\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n101102103104\n01\u2212Jan\n15\u2212Jan\n30\u2212Jan\n14\u2212Feb\nTimeCumulative number of postsGab\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n101102103104\n01\u2212Jan\n15\u2212Jan\n30\u2212Jan\n14\u2212Feb\nTimeCumulative number of postsReddit\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n102.5103103.5104104.5105\n01\u2212Jan\n15\u2212Jan\n30\u2212Jan\n14\u2212Feb\nTimeCumulative number of postsY ouTube\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n101102103104\n01\u2212Jan\n15\u2212Jan\n30\u2212Jan\n14\u2212Feb\nTimeCumulative number of postsInstagram\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n100101102103104105106\n01\u2212Jan\n15\u2212Jan\n30\u2212Jan\n14\u2212Feb\nTimeCumulative number of postsTwitter\n1 Diamond Princess\n2 Biological warfare\n3 Death toll, infection rates\n4 Chinese wet markets\n5 Bill Gates Foundation simulation\n6 Mass cremation in Wuhan\n7 Economic impact\n8 Virus spreading\n9 Colloidal silver\n10 Prayers, God blessing request\n11 Suspended flights \n12 Protection advice\n13 Tencent censorship\n14 Other\n1 Death toll, infection rates\n2 Governments and decision making\n3 Economic impact\n4 Disease description and sympthoms\n5 Diamond Princess\n6 Suspended flights and repatriation\n7 Li Wenliang\n8 Comparison with other viruses\n9 Chinese crisis\n10 Cure and therapy\n11 Hong Kong protests\n12 Virus spreading\n13 Protection advice\n14 Hospitals\n15 Racism\n16 Biological warfare\n17 Bill Gates Foundation simulation\n18 Tencent censorship\n19 Other\n1 Death toll, infection rates\n2 Communist regime\n3 Chinese wet markets\n4 Prayers, God blessing request\n5 Protection advice\n6 Economic impact\n7 Virus spreading\n8 Comparison with other viruses\n9 Governments and decision making\n10 Disease description \n11 Suspended flights and repatriation\n12 Cure and therapy\n13 Racism\n14 Other\n1 Chinese crisis\n2 Protection advice\n3 Death toll, infection rates\n4 Governments \n5 Prayers, God blessing request\n6 Comparison with other viruses\n7 Diamond Princess\n8 Huoshenshan hospital\n9 Racism\n10 Other\n1 Suspended flights and repatriation\n2 Economic impact\n3 Protection advice\n4 Prayers, God blessing request\n5 Death toll, infection rates\n6 Biological warfare\n7 Communist regime\n8 Huoshenshan hospital\n9 Comparison with other viruses\n10 Chinese wet markets\n11 Virus spreading\n12 Disease description and sympthoms\n13 Racism\n14 Other\nFig. 6.1: Upper panel: activity (likes, comments, reposts, etc..) distribution for each social me-\ndia. Middle panel: most discussed topics about COVID-19 on each social media. Lower panel:\ncumulative number of content (posts, tweets, videos, etc..) produced from the 1stof January to the\n14thof February. Due to the Twitter API limitations in gathering past data, the \ufb01rst data point for\nTwitter is dated January 27th.\nto other viruses, requests for God blessing, up to racism, while the largest volume\nof interaction is related to the lock-down of \ufb02ights.\nFinally, to characterize user engagement with the COVID-19 on the \ufb01ve plat-\n141\nforms, we compute the cumulative number of new posts each day (Figure 6.1,\nlower panel). For all platforms, we \ufb01nd a change of behavior around the 20th\nof January, that is the day that the World Health Organization (WHO) issued its\n\ufb01rst situation report on the COVID-19 [167]. The largest increase in the number\nof posts is on the 21stof January for Gab, the 24thJanuary for Reddit, the 30th\nJanuary for Twitter, the 31thJanuary for YouTube and the 5thof February for In-\nstagram. Thus, social media platforms seem to have speci\ufb01c timings for content\nconsumption; such patterns may depend upon the difference in terms of audience\nand interaction mechanisms (both social and algorithmic) among platforms.\n6.2.2 Information Spreading\nEfforts to simulate the spreading of information on social media by reproducing\nreal data have mostly applied variants of standard epidemic models [168]\u2013[171].\nCoherently, we analyze the observed monotonic increasing trend in the way new\nusers interact with information related to the COVID-19 by using epidemic mod-\nels. Unlike previous works, we do not only focus on models that imply speci\ufb01c\ngrowth mechanisms, but also on phenomenological models that emphasize the re-\nproducibility of empirical data [172].\nMost of the epidemiological models focus on the basic reproduction number\nR0, representing the expected number of new infectors directly generated by an\n142\n0 20 40\nday\n0\n500\n1000\n1500\n2000\n2500\nusers\nR\n0\n = 2.3\n0 20 40\nday\n0\n500\n1000\n1500\n2000\n2500\nusers\nGab\nR\n0\n = 1.46\n0 20 40\nday\n0\n1000\n2000\n3000\n4000\nR\n0\n = 2.6\n0 20 40\nday\n0\n1000\n2000\n3000\n4000\nReddit\nR\n0\n = 1.46\n0 20 40\nday\n0\n1\n2\n3\n4\n5\n10\n4\nR\n0\n = 3.3\n0 20 40\nday\n0\n1\n2\n3\n4\n5\n10\n4\nYouTube\nR\n0\n = 1.61\n0 20 40\nday\n0\n0.5\n1\n1.5\n2\n10\n4\nR\n0\n = 130\n0 20 40\nday\n0\n0.5\n1\n1.5\n2\n10\n4\nInstagram\nR\n0\n = 2.25\n0 20 40\nday\n0\n1\n2\n3\n4\n10\n5\nR\n0\n = 4.6\n0 20 40\nday\n0\n1\n2\n3\n4\n10\n5\nTwitter\nR\n0\n = 1.84\nFig. 6.2: Growth of the number of authors vs time. Time is expressed in number of days since\n1stJan2020 (day 1). Shaded areas represents [5%;95%] estimates of the models obtained via\nbootstrapping least square estimates of the EXP model (upper panels) and of the SIR model (lower\npanels). For details the SIR and the EXP model, see SI.\ninfected individual for a given time period [55]. An epidemic occurs if R0>1,\n\u2013 i.e., if an exponential growth in the number of infections is expected at least in\nthe initial phase. In our case, we try to model the growth in number of people\npublishing a post on a subject as an infective process, where people can start pub-\nlishing after being exposed to the topic. While in real epidemics R0>1highlights\nthe possibility of a pandemic, in our approach R0>1indicates the emergence of\nan infodemic. We model the dynamics both with the phenomenological model of\n[53] (from now on referred to as the EXP model) and with the standard SIR (Sus-\nceptible, Infected, Recovered) compartmental model [54]. Further details on the\nmodeling approach can be found in section 6.4.\nAs shown in Figure 6.2, each platform has its own basic reproduction num-\n143\nGab Reddit YouTube Instagram Twitter\nREXP\n0 [1:42;1:52] [1:44;1:51] [1:56;1:70] [2:02;2:64] [1:65;2:06]\nRSIR\n0 [2:2;2:5] [2:4;2:8] [3:2;3:5] [1:1x102;1:6x102][4:0;5:1]\nTable 6.1: [5%;95%] interval of con\ufb01dence R0as estimated from bootstrapping the least square\n\ufb01ts parameter of the EXP and of the SIR model. Notice that, due to the steepness of the growth of\nthe number of new authors in Instagram, R0assumes unrealistic values \u0018102for the SIR model.\nberR0. As expected, all the values of R0are supercritical - even considering\ncon\ufb01dence intervals (Table 6.1) - signaling the possibility of an infodemic. This\nobservation may facilitate the prediction task of information spreading during crit-\nical events. Indeed, according to this result we can consider information spreading\npatterns on each social media to predict social response when implementing crisis\nmanagement plans.\nWhileR0is a good proxy for the engagement rate and a good predictor for\nepidemic-like information spreading, social contagion phenomena might be in\ngeneral more complex [133], [173], [174]. For instance, in the case of Instagram,\nwe observe an abrupt jump in the number of new users that cannot be explained\nwith continuous models like the standard epidemic ones; accordingly, the SIR\nmodel estimates a value of R0\u0018102that is way beyond what has been observed\nin any real-world epidemic.\n144\n6.2.3 Questionable VS Reliable Information Sources\nWe conclude our analysis by comparing the diffusion of information from ques-\ntionable and reliable sources on each platform. We tag links as reliable or question-\nable according to the data reported by the independent fact-checking organization\nMedia Bias/Fact Check [165]. In order to clarify the limits of an approach that\nis based on labelling news outlets rather than single articles, as for instance per-\nformed in [18], [19], we report the de\ufb01nitions used in this paper for questionable\nand reliable information sources. In accordance with the criteria established by\nMBFC, by questionable information source we mean a news outlet systematically\nshowing one or more of the following characteristics: extreme bias, consistent pro-\nmotion of propaganda/conspiracies, poor or no sourcing to credible information,\ninformation not supported by evidence or unveri\ufb01able, a complete lack of trans-\nparency and/or fake news. By reliable information sources we mean news outlets\nthat do not show any of the aforementioned characteristics. Such outlets can any-\nway produce contents potentially displaying a bias towards liberal/conservative\nopinion, but this does not compromise the overall reliability of the source.\nFigure 6.3 shows, for each platform, the plots of the cumulative number of\nposts and reactions related to reliable sources versus the cumulative number of\nposts and interactions referring to questionable sources. By interactions we mean\n145\nEUER\u000b\nGab 5.6 1.4 3.9\nReddit 22.7 40.1 0.55\nTwitter 15.1 15.6 0.97\nYouTube 1.4\u00021043.9\u00021040.35\nTable 6.2: The average engagement of a post is the number of reactions expected for a post and is a\nmeasure of how much a post is ampli\ufb01ed in each social media platform. The average engagement\nEU(for unreliable post) and ER(for reliable post) vary from platform to platform, and are the\nlargest in Twitter and the lowest in Gab. The coef\ufb01cient of relative ampli\ufb01cation \u000b=EU=ER\nmeasures whether a social media ampli\ufb01es more unreliable ( \u000b > 1) or reliable ( \u000b < 1) posts.\nAmong more popular social media platforms, we notice that Twitter is the most neutral ( \u000b\u00181%\ni.e.EU\u0018ER), while YouTube ampli\ufb01es unreliable sources less ( \u000b\u00184=10). Among less popular\nsocial media platforms, Reddit reduces the impact of unreliable sources ( \u000b\u00181=2) while Gab\nstrongly ampli\ufb01es them ( \u000b\u00184).\nthe overall reactions, e.g. likes or other form or endorsement and comments, that\ncan be performed with respect to a post on a social platform. Surprisingly, all\nthe posts show a strong linear correlation, i.e., the number of posts/reactions re-\nlying on questionable and reliable sources grows with the same pace inside the\nsame social media platform. We observe the same phenomenon also for the en-\ngagement with reliable and questionable sources. Hence, the growth dynamics of\nposts/interactions related to questionable news outlets is just a re-scaled version of\nthe growth dynamics of posts/reactions related to reliable news outlets; however,\nthe re-scaling factor \u001a(i.e., the fraction of questionable over reliable) is strongly\ndependent on the platform.\nIn particular, we observe that in mainstream social media the number of posts\nproduced by questionable sources represents a small fraction of posts produced\n146\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf0 500 1000 1500 0 100000 200000 0 1082x1080 5x1051060 500 1000 0 2000 4000 0 2000 4000 6000 0 25000 50000 75000025005000750010000\n05x1041050100200300400\n02x1064x1066x106050100150200250\n0200040000250500750\n010002000300040005000 from questionable sourcesCumulative number of posts Cumulative reactions to posts\nfrom questionable sources\u03c1 = 0.70\nCumulative number of posts from reliable sources\n\u03c1 = 2.7                              \u03c1 = 0.03                              \u03c1 = 0.02                            \u03c1 = 0.11\nCumulative reactions to posts from reliable sources\u03c1 = 0.05                             \u03c1 = 0.07 \u03c1 = 0.11Gab Reddit YouTube Twitter\nFig. 6.3: Upper panels: plot of the cumulative number of posts referring to questionable sources\nversus the cumulative number of posts referring to reliable sources. Lower panel: plot of the\ncumulative number of engagements relatives to questionable sources versus the cumulative number\nof engagements relative to reliable sources. Notice that a linear behavior indicates that the time\nevolution of questionable posts/engagements is just a re-scaled version of the time evolution of\nreliable posts/engagements. Each plot indicates the regression coef\ufb01cients \u001a, representing the ratio\namong the volumes of questionable and reliable posts ( \u001apost) and engagements ( \u001aeng). In more\npopular social media, the number of questionable posts represents a small fraction of the reliable\nones; same thing happens in Reddit. Among less popular social media, a peculiar effect is observed\nin Gab: while the volume of questionable posts is just the \u001870% of the volume of reliable ones,\nthe volume of engagements for questionable posts is \u00183times bigger than the volume for reliable\nones. Further details concerning the regression coef\ufb01cients are reported in Methods.\n147\nby reliable ones; the same thing happens in Reddit. Among less regulated so-\ncial media, a peculiar effect is observed in Gab: while the volume of posts from\nquestionable sources is just the \u001870% of the volume of posts from reliable ones,\nthe volume of reactions for the former ones is \u00183times bigger than the volume\nfor the latter ones. Such results hint the possibility that different platform react\ndifferently to information produced by reliable and questionable news outlets.\nTo further investigate this issue, we de\ufb01ne the ampli\ufb01cation factor Eas the av-\nerage number of reactions to a post; hence, Eis a measure that quanti\ufb01es the extent\nto which a post is ampli\ufb01ed in a social media. We observe that the ampli\ufb01cation EU\n(for unreliable posts posts produced by questionable outlets) and ER(for reliable\nposts posts produced by reliable outlets) vary from social media platform to social\nmedia platform and that assumes the largest values in YouTube and the lowest in\nGab. To measure the permeability of a platform to posts from questionable/reliable\nnews outlets, we then de\ufb01ne the coef\ufb01cient of relative ampli\ufb01cation \u000b=EU=ER.\nIt is a measure of whether a social media ampli\ufb01es questionable ( \u000b>1) or reliable\n(\u000b <1) posts. Results are shown in Table 6.2. Among mainstream social media,\nwe notice that Twitter is the most neutral ( \u000b\u00181i.e.EU\u0018ER), while YouTube\nampli\ufb01es questionable sources less ( \u000b\u00184=10). Among less popular social media,\nReddit reduces the impact of questionable sources ( \u000b\u00181=2), while Gab strongly\nampli\ufb01es them ( \u000b\u00184).\n148\nTherefore, we conclude that the main drivers of information spreading are re-\nlated to speci\ufb01c peculiarities of each platform and depends upon the group dynam-\nics of individuals engaged with the topic.\n6.3 Conclusions\nIn this work we perform a comparative analysis of users\u2019 activity on \ufb01ve different\nsocial media platforms during the COVID-19 health emergency. Such a timeframe\nis a good benchmark for studying content consumption dynamics around critical\nevents in a times when the accuracy of information is threatened. We assess user\nengagement and interest about the COVID-19 topic and characterize the evolution\nof the discourse over time.\nFurthermore, we model the spread of information using epidemic models and\nprovide basic growth parameters for each social media platform. We then ana-\nlyze the diffusion of questionable information for all channels, \ufb01nding that Gab\nis the environment more susceptible to misinformation dissemination. However,\ninformation deriving from sources marked either as reliable or questionable do\nnot present signi\ufb01cant differences in their its spreading patterns. Our analysis sug-\ngests that information spreading is driven by the interaction paradigm imposed\nby the speci\ufb01c social media or/and by the speci\ufb01c interaction patterns of groups\nof users engaged with the topic. We conclude the paper by computing rumor\u2019s\n149\nampli\ufb01cation parameters for social media platforms.\nWe believe that the understanding of social dynamics between content con-\nsumption and social media platforms is an important research subject, since it may\nhelp to design more ef\ufb01cient epidemic models accounting for social behavior and\nto design more effective and tailored communication strategies in time of crisis.\n6.4 Methods\n6.4.1 Data Collection\nTable 6.3 reports the data breakdown of the \ufb01ve social media platforms. Dif-\nferent data collection processes have been performed depending on the platform.\nIn all cases we guided the data collection by a set of selected keywords based\non Google Trends\u2019 COVID-19 related queries such as: coronavirus, pandemic,\ncoronaoutbreak, china, wuhan, nCoV , IamNotA Virus, coronavirus update, coron-\navirus transmission, coronavirusnews, coronavirusoutbreak.\nThe Reddit dataset was downloaded from the Pushift.io archive, exploiting the\nrelated API. In order to \ufb01lter contents linked to COVID-19, we used our set of\nkeywords.\nIn Gab, although no of\ufb01cial guides are available, there is an API service that\ngiven a certain keyword, returns a list of users, hashtags and groups related to\nit. We queried all the keywords we selected based on Google Trends and we\n150\ndownloaded all hashtags linked to them. We then manually browsed the results\nand selected a set of hashtags based on their meaning. For each hashtag in our list,\nwe downloaded all the posts and comments linked to it.\nFor YouTube, we collected videos by using the YouTube Data API by searching\nfor videos that matched our keywords. Then an in depth search was done by\ncrawling the network of videos by searching for more related videos as established\nby the YouTube algorithm. From the gathered set, we \ufb01ltered the videos that\nmatched coronavirus, nCov, corona virus, corona-virus, corvid, covid or SARS-\nCoV in the title or description. We then collected all the comments received by\nthose videos.\nFor Twitter, we collect tweets related to the topic coronavirus by using both the\nsearch and stream endpoint of the Twitter API. The data derived from the stream\nAPI represent only 1% of the total volume of tweets, further \ufb01ltered by the selected\nkeywords. The data derived from the search API represent a random sample of the\ntweets containing the selected keywords up to a maximum rate limit of 18000\ntweets every 10 minutes.\nSince no of\ufb01cial API are available for Instagram data, we built our own process\nto collect public contents related to our keywords. We manually took notes of\nposts, comments and populated the Instagram Dataset.\n151\nPosts Comments Users Period\nGab 6,252 4,364 2,629 01/01-14/02\nReddit 10,084 300,751 89,456 01/01-14/02\nYouTube 111,709 7,051,595 3,199,525 01/01-14/02\nInstagram 26,576 109,011 52,339 01/01-14/02\nTwitter 1,187,482 - 390,866 27/01-14/02\nTotal 1,342,103 7,465,721 3,734,815\nTable 6.3: Data breakdown of the number of posts, comments and users for all platforms.\n6.4.2 Matching Ability\nWe consider all the posts in our dataset that contain at least one URL linking to\na website outside the related social media platfrom (e.g., tweets pointing outside\nTwitter). We separate URLs in two main categories obtained using the classi\ufb01ca-\ntion provided by MediaBias/FactCheck (MBFC). MBFC provides a classi\ufb01cation\ndetermined by ranking bias in four different categories, one of them being Fac-\ntual/Sourcing. In that category, each news outlet is associated to a label that refers\nto its reliability as expressed in three labels, namely Conspiracy-Pseudoscience,\nPro-Science or Questionable. Noticeably, also the Questionable set include a wide\nrange of political bias, from Extreme Left to Extreme Right.\nUsing such a classi\ufb01cation, we assign to each of these outlets a binary label that\npartially stems from the labelling provided by MBFC. We divide the news outlets\ninto Questionable and Reliable. All the outlets already classi\ufb01ed as Questionable\nor belonging to the category Conspiracy-Pseudoscience are labelled as Question-\n152\nGab Reddit YouTube Instagram Twitter\nPosts containing a URL 3778 10084 351786 1328 356448\nMatched 0.47 0.55 0.035 0.09 0.27\nQuestionable 0.38 0.045 0.064 0.05 0.10\nReliable 0.62 0.955 0.936 0.95 0.90\nTable 6.4: Number of posts containing a URL, matching ability and classi\ufb01cation for each of the\n\ufb01ve platforms.\nable, the rest is labelled as Reliable. Thus, by questionable information source\nwe mean a news outlet systematically showing one or more of the following char-\nacteristics: extreme bias, consistent promotion of propaganda/conspiracies, poor\nor no sourcing to credible information, information not supported by evidence or\nunveri\ufb01able, a complete lack of transparency and/or fake news. By reliable infor-\nmation sources we mean news outlets that do not show any of the aforementioned\ncharacteristics. Such outlets can anyway produce contents potentially displaying a\nbias towards liberal/conservative opinion, but this does not compromise the overall\nreliability of the source.\nConsidering all the 2637 news outlets that we retrieve from the list provided\nby MBFC we end up with 800 outlets classi\ufb01ed as Questionable 1837 outlets\nclassi\ufb01ed as Reliable. Using such a classi\ufb01cation we quantify our overall ability\nto match and label domains of posts containing URLs, as reported in Table 6.4.\nThe matching ability that is low doesn\u2019t refer to the ability of identifying known\ndomain but to the ability of \ufb01nding the news outlets that belong to the list provided\nby MBFC. Indeed in all the social networks we \ufb01nd a tendency towards linking to\n153\nother social media platforms, as shown in Table 6.5.\nGab Reddit YouTube Instagram Twitter Facebook\nGab 0.003 0.002 0.001 0.002 0.138\u00180\nReddit 0.043 0.006 0.009 0.001\u00180 0\nYouTube 0\u00180 0.292\u00180 0.088 0.081\nInstagram 0 0 0.003 0 0.001 0.001\nTwitter 0.059 0.001 0.257 0.003\u00180\u00180\nTable 6.5: Fraction of URLs pointing to social media. Table should be read as entries in each row\nlink to entries in each column. For example, Gab links to Reddit 0.003.\n6.4.3 Text Analysis\nTo provide an overview of the debate concerning the virus outbreak on the vari-\nous platforms, we extract and analyze all topics related to COVID-19 by applying\nNatural Language Processing techniques to the written content of each social me-\ndia platform. We \ufb01rst build word embedding for the text corpus of each platform,\nthen, to assess the topics around which the perception of the COVID-19 debate\nis concentrated, we cluster words by running the Partitioning Around Medoids\n(PAM) algorithm on their vector representations.\nWord embeddings, i.e., distributed representations of words learned by neural\nnetworks, represent words as vectors in Rnbringing similar words closer to each\nother. They perform signi\ufb01cantly better than the well-known Latent Semantic\nAnalysis (LSA) and Latent Dirichlet Allocation (LDA) for preserving linear regu-\nlarities among words and computational ef\ufb01ciency on large data sets [175]. In this\n154\npaper we use the Skip-gram model [51] to construct word embedding of each so-\ncial media corpus. More formally, given a content represented by the sequence of\nwordsw1;w2;:::;wT, we use stochastic gradient descent with gradient computed\nthrough backpropagation rule [52] for maximizing the average log probability\n1\nTTX\nt=12\n4kX\nj=\u0000klogp(wt+jjwt)3\n5 (6.1)\nwherekis the size of the training window. Therefore, during training the vector\nrepresentations of closely related words are pushed to be close to each other.\nIn the Skip-gram model, every word wis associated with its input and output\nvectors,uwandvw, respectively. The probability of correctly predicting the word\nwigiven the word wjis de\ufb01ned as\np(wijwj) =exp\u0000\nuT\nwivwj\u0001\nVX\nl=1exp\u0000\nuT\nlvwj\u0001(6.2)\nwhereVis the number of words in the corpus vocabulary. Two major parameters\naffect the training quality: the dimensionality of word vectors, and the size of the\nsurrounding words window. We choose 200 as vector dimension \u2013 that is typical\nvalue for training large dataset \u2013 and 6 words for the window.\nBefore applying the tool, we reduced the contents to those written in English\n155\nas detected with cld3. Then we cleaned the corpora by removing HTML code,\nURLs and email addresses, user mentions, hashtags, stop-words, and all the spe-\ncial characters including digits. Finally, we dropped words composed by less than\nthree characters, words occurring less than \ufb01ve times in all the corpus, and con-\ntents with less than three words.\nTo analyze the topics related to COVID-19, we cluster words by PAM and\nusing as proximity metric the cosine distance matrix of words in their vector rep-\nresentations. In order to select the number of clusters, k, we calculate the average\nsilhouette width for each value of k. Moreover, for evaluating the cluster stabil-\nity, we calculate the average pairwise Jaccard similarity between clusters based on\n90% sub-samples of the data. Lastly, we produce word clouds to identify the topic\nof each cluster. To provide a view about the debate around the virus outbreak, we\nde\ufb01ne the distribution over topics \u0002cfor a given content cas the distribution of\nits words among the word clusters. Thus, to quantify the relevance of each topic\nwithin a corpus, we restrict to contents cwith max \u0002c>0:5and consider them\nuniquely identi\ufb01ed as a single topic each. Table 6.6 shows the results of the text\ncleaning and topic analysis for all the data.\n156\nCleaned contents Vocabulary size Topics Contents with max \u0002>0:5\nInstagram 21,189 posts 15,324 17 4,467\nTwitter 638,214 posts 22,587 21 369,131\nGab 5,853 posts 3,024 19 2,986\nReddit 10,084 posts 1,968 34 6,686\nYouTube 815,563 comments 35,381 30 679,261\nTable 6.6: Results of text cleaning and analysis for all the corpora.\n6.4.4 Epidemiological Models\nSeveral mathematical models can be used to analyse potential mechanisms that un-\nderline epidemiological data. Generally, we can distinguish among phenomeno-\nlogical models that emphasize the reproducibility of empirical data without in-\nsights in the mechanisms of growth, and more insightful mechanistic models that\ntry to incorporate such mechanisms [172].\nTo \ufb01t our cumulative curves, we \ufb01rst use the adjusted exponential model of [53]\nsince it naturally provides an estimate of the basic reproduction number R0. This\nphenomenological model (from now on indicated as EXP) has been successfully\nemployed in data-scarce settings and shown to be on-par with more traditional\ncompartmental models for multiple emerging diseases like Zika, Ebola, and Mid-\ndle East Respiratory Syndrome [53].\nThe model is de\ufb01ned by the following single equation:\nI=\u0014R0\n(1 +d)t\u0015t\n(6.3)\n157\nHere,Iis incidence, tis the number of days, R0is the basic reproduction\nnumber and dis a damping factor accounting for the reduction in transmissibility\nover time. In our case, we interpret Ias the number Cauthof authors that have\npublished a post on the subject.\nAs a mechanistic model, we employ the classical SIR model [54]. In such\na model, a susceptible population can be infected with a rate \fby coming into\ncontact with infected individuals; however, infected individuals can recover with\na rate\r. The model is described by a set of differential equations:\n@tS=\u0000\fS\u0001I=N\n@tI=\fS\u0001I=N\u0000\rI (6.4)\n@tR=\rI\nwhereSis the number of susceptible, Iis the number of infected and Ris the\nnumber of recovered. In our case, we interpret the number I+Ras the number\nCauthof authors that have published a post on the subject.\nIn the SIR model, the basic reproduction number R0=\f=\r corresponds to the\nration among the rate of infection by contact \fand the rate of recovery \r. Notice\nthat for the SIR model, vaccination strategies correspond to bringing the system\nin a situation where S < N=R 0; in such a way, both the number of infected will\n158\ndecrease.\nTo estimate the basic reproduction numbers REXP\n0 andRSIR\n0for the EXP and\nthe SIR model, we use least square estimates of the models\u2019 parameters[55]. The\nrange of parameters is estimated via bootstrapping [172], [176].\n6.4.5 Linear Regression Coef\ufb01cients\nTable 6.7 reports the regression coef\ufb01cient \u001a, the intercept and the R2values for the\nlinear \ufb01t of Figure 6.3. High values of R2con\ufb01rm the linear relationship between\nreliable and questionable sources in information diffusion.\nDataset Type Intercept Coef\ufb01cient ( \u001a)R2\nGab Posts -22.321 0.695 0.996\nReddit Posts -4.111 0.047 0.997\nYoutube Posts 4.529 0.073 0.998\nTwitter Posts -151.44 0.110 0.998\nGab Reactions 74.577 2.721 0.981\nReddit Reactions -70.677 0.026 0.990\nYoutube Reactions -8854.33 0.025 0.986\nTwitter Reactions -2136.978 0.107 0.987\nTable 6.7: Coef\ufb01cients and R2of the linear regressions displayed in Figure 3.\n159\nCHAPTER 7\nCONCLUSION AND FUTURE WORKS\nIn this chapter, we summarize the results of the works presented, drawn conclu-\nsions, and sketch the line of the research for future works.\n7.1 Summary of Key Findings\nThe research presented in this thesis mainly focused on two aspects of the social\nmedia environment: information consumption dynamics and echo chambers. We\n\ufb01rst showed the marginal role of fake news during the 2019 European elections,\nthen we analyzed and quanti\ufb01ed the difference in polarization between the 2016\nand 2020 U.S. presidential elections. We also compared the share of misinforma-\ntion and fake news circulating, showing the decrease in the presence of fake news\nand automated accounts. We also highlighted the presence of two clusters of users\nwith opposite political leaning that increased the opinion distance over time. Thus,\nwe looked at the possible environmental factors that may foster the polarization\nof users and the rise of echo chambers by comparing the debate around several\ntopics on different platforms. We found that social media feed algorithms may\nfoster the echo chamber effects and that information consumption is in\ufb02uenced by\n160\nthe structure of echo chambers. Finally, we observed how different social media\nplatforms reacted to the COVID-19 outbreak. We found a dramatic increase in the\namount of news shared on all platforms that leads to an overabundance of both re-\nliable and questionable information. This uncontrolled proliferation of COVID-19\ncontents has been so impressive to the point that the term \u201cinfodemic\u201d has been\ncoined to describe it. Moreover, we compared the proliferation of questionable\nand reliable news among different platforms \ufb01nding that their level of diffusion\nand consumption depends on the environment in which they spread, but has com-\nparable dynamics for both types of news. To conclude, the level of diffusion of\na piece of information depends on the presence of an audience, or better an echo\nchamber, prone to endorse that type of content. However, several factors such as\nthe platform feature, the characteristic of the user base or the feed algorithm, may\nin\ufb02uence the existence of such users and thus the level of diffusion of the infor-\nmation. Nevertheless, the spreading dynamic seems to be independent from some\ncharacteristic of the content, such as reliability.\n7.2 Future Works\nAlthough a considerable amount of research about echo chambers and informa-\ntion spreading has been published, there are still open questions. One of the most\nimportant is the process dominating the rise of polarization and echo chambers.\n161\nWe now have several techniques to reveal the presence of polarization and echo\nchambers, but we still lack tools to describe the rise and evolution of echo cham-\nbers. However, this line of research is likely to bene\ufb01t from the vast amount of\nhistorical data that some platforms recently made available for academic purposes.\nA better understanding of the echo chambers evolution may aid the design of ac-\ntions and feed algorithms that reduce polarization and segregation among users.\nAnother important question is the quanti\ufb01cation of the segregation level among\nonline communities. Even if some studies tried to model polarization, we still\nmiss a metric to measure the polarization level for different topics and across sev-\neral platforms, allowing us to compare and study the evolution of polarization\nover time. A crucial element of online social media studies is the representative-\nness and the biases that possibly affect the data gathered from online platforms.\nIndeed, online data may not re\ufb02ect the of\ufb02ine world in an unbiased manner or not\nadequately represent all the aspects of an online environment, and the effects on\nresearch results of such biases still need to be precisely addressed. Finally, we\nstill lack of knowledge about the relationship between online debate and of\ufb02ine\nactions. Frequently, social media platforms have been identi\ufb01ed as the trigger of\nactions such as assault, shootings and radicalization, but we still do not know to\nwhich extent the online echo system can in\ufb02uence of\ufb02ine behaviours.\n162\n163\nREFERENCES\n[1] W. Quattrociocchi, \u201cPart 2-social and political challenges: 2.1 western democracy in cri-\nsis?\u201d In Global Risk Report World Economic Forum , 2017.\n[2] M. Del Vicario, A. Bessi, F. Zollo, F. Petroni, A. Scala, G. Caldarelli, H. E. Stanley, and\nW. Quattrociocchi, \u201cThe spreading of misinformation online,\u201d Proceedings of the National\nAcademy of Sciences , vol. 113, no. 3, pp. 554\u2013559, 2016.\n[3] A. L. Schmidt, F. Zollo, M. Del Vicario, A. Bessi, A. Scala, G. Caldarelli, H. E. Stanley,\nand W. Quattrociocchi, \u201cAnatomy of news consumption on facebook,\u201d Proceedings of the\nNational Academy of Sciences , vol. 114, no. 12, pp. 3035\u20133039, 2017.\n[4] M. Cinelli, E. Brugnoli, A. L. Schmidt, F. Zollo, W. Quattrociocchi, and A. Scala, \u201cSelec-\ntive exposure shapes the facebook news diet,\u201d PloS one , vol. 15, no. 3, e0229129, 2020.\n[5] E. Bakshy, S. Messing, and L. A. Adamic, \u201cExposure to ideologically diverse news and\nopinion on facebook,\u201d Science , vol. 348, no. 6239, pp. 1130\u20131132, 2015.\n[6] K. H. Jamieson and J. N. Cappella, Echo chamber: Rush Limbaugh and the conservative\nmedia establishment . Oxford University Press, 2008.\n[7] R. K. Garrett, \u201cEcho chambers online?: Politically motivated selective exposure among In-\nternet news users,\u201d Journal of Computer-Mediated Communication , vol. 14, no. 2, pp. 265\u2013\n285, 2009.\n[8] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis, \u201cPolitical dis-\ncourse on social media: Echo chambers, gatekeepers, and the price of bipartisanship,\u201d in\nProceedings of the 2018 World Wide Web Conference , ser. WWW \u201918, Lyon, France: In-\nternational World Wide Web Conferences Steering Committee, 2018, pp. 913\u2013922, ISBN :\n978-1-4503-5639-8.\n[9] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis, \u201cThe Effect of\nCollective Attention on Controversial Debates on Social Media,\u201d in WebSci \u201917: 9th Inter-\nnational ACM Web Science Conference , 2017, pp. 43\u201352.\n164\n[10] W. Cota, S. C. Ferreira, R. Pastor-Satorras, and M. Starnini, \u201cQuantifying echo chamber ef-\nfects in information spreading over political communication networks,\u201d EPJ Data Science ,\nvol. 8, no. 1, p. 35, Dec. 2019.\n[11] E. Dubois and G. Blank, \u201cThe echo chamber is overstated: The moderating effect of po-\nlitical interest and diverse media,\u201d Information, Communication & Society , vol. 21, no. 5,\npp. 729\u2013745, 2018.\n[12] P. Barber \u00b4a, J. T. Jost, J. Nagler, J. A. Tucker, and R. Bonneau, \u201cTweeting from left to right:\nIs online political communication more than an echo chamber?\u201d Psychological science ,\nvol. 26, no. 10, pp. 1531\u20131542, 2015.\n[13] A. Bruns, Echo chamber? what echo chamber? reviewing the evidence , 2017.\n[14] S. V osoughi, D. Roy, and S. Aral, \u201cThe spread of true and false news online,\u201d Science ,\nvol. 359, no. 6380, pp. 1146\u20131151, 2018.\n[15] C. Shao, G. L. Ciampaglia, O. Varol, A. Flammini, and F. Menczer, \u201cThe spread of fake\nnews by social bots,\u201d arXiv preprint arXiv:1707.07592 , vol. 96, pp. 96\u2013104, 2017.\n[16] D. Ruths, \u201cThe misinformation machine,\u201d Science , vol. 363, no. 6425, pp. 348\u2013348, 2019.\n[17] A. Bessi and E. Ferrara, \u201cSocial bots distort the 2016 us presidential election online dis-\ncussion,\u201d First Monday , vol. 21, no. 11-7, 2016.\n[18] A. Bovet and H. A. Makse, \u201cIn\ufb02uence of fake news in twitter during the 2016 us presiden-\ntial election,\u201d Nature communications , vol. 10, no. 1, p. 7, 2019.\n[19] N. Grinberg, K. Joseph, L. Friedland, B. Swire-Thompson, and D. Lazer, \u201cFake news on\ntwitter during the 2016 us presidential election,\u201d Science , vol. 363, no. 6425, pp. 374\u2013378,\n2019.\n[20] Twitter stops all political advertising ,https://twitter.com/jack/status/\n1189634360472829952 , Accessed: 2020-04-04.\n[21] Is russia trying to sway the european elections? https://www.bbc.com/news/\nblogs-trending-48296557 , Accessed: 2020-04-04.\n165\n[22] Fakewatch ,https://secure.avaaz.org/campaign/en/disinfo_network_\nreport/ , Accessed: 2020-04-04.\n[23] Eu leaders to warn of cyber, fake news threat to may elections ,https://www.reuters.\ncom/article/us- eu- disinformation/eu- leaders- to- warn- of-\ncyber- fake- news- threat- to- may- elections- idUSKCN1R11QM , Ac-\ncessed: 2020-04-04.\n[24] J. Zarocostas, \u201cHow to \ufb01ght an infodemic,\u201d The Lancet , vol. 395, no. 10225, p. 676, 2020.\n[25] Why social media makes us more polarized and how to \ufb01x it ,https://www.scientific-\namerican.com/article/why-social-media-makes-us-more-polarized-\nand-how-to-fix-it/ , Accessed: 2021-09-15.\n[26] A mass murder of, and for, the internet ,https://www.nytimes.com/2019/03/\n15/technology/facebook- youtube- christchurch- shooting.html ,\nAccessed: 2021-09-15.\n[27] On gab, an extremist-friendly site, pittsburgh shooting suspect aired his hatred in full ,\nhttps://www.nytimes.com/2018/10/28/us/gab-robert-bowers-\npittsburgh-synagogue-shootings.html , Accessed: 2021-09-15.\n[28] Far-right extremists still downloading christchurch massacre footage ,https://www.\ntheage.com.au/national/far-right-extremists-still-downloading-\nchristchurch- massacre- footage- 20210818- p58jwq.html , Accessed:\n2021-09-15.\n[29] The storming of capitol hill was organized on social media. https://www.nytimes.\ncom/2021/01/06/us/politics/protesters-storm-capitol-hill-\nbuilding.html , Accessed: 2021-09-15.\n[30] Capitol hill riot lays bare what\u2019s wrong with social media ,https://www.politico.\neu / article / us - capitol - hill - riots - lay - bare - whats - wrong -\nsocial-media-donald-trump-facebook-twitter/ , Accessed: 2021-09-15.\n[31] The 65 days that led to chaos at the capitol ,https://www.bbc.com/news/world-\nus-canada-55592332 , Accessed: 2021-09-15.\n166\n[32] Permanent suspension of @realdonaldtrump ,https://about.fb.com/news/\n2021/01/responding-to-the-violence-in-washington-dc/ , Accessed:\n2021-09-15.\n[33] Permanent suspension of @realdonaldtrump ,https://blog.twitter.com/en_\nus/topics/company/2020/suspension , Accessed: 2021-09-15.\n[34] Trump sues twitter, google and facebook alleging \u2019censorship\u2019 ,https://www.bbc.\ncom/news/world-us-canada-57754435 , Accessed: 2021-09-15.\n[35] D. Lazer, A. Pentland, L. Adamic, S. Aral, A.-L. Barabasi, D. Brewer, N. Christakis, N.\nContractor, J. Fowler, M. Gutmann, et al. , \u201cComputational social science.,\u201d Science (New\nYork, NY) , vol. 323, no. 5915, pp. 721\u2013723, 2009.\n[36] M. Baker, \u201cOver half of psychology studies fail reproducibility test,\u201d Nature News , vol. 27,\n2015.\n[37] B. Owens, \u201cReplication failures in psychology not due to differences in study populations,\u201d\nNature , vol. 19, 2018.\n[38] B. Gonc \u00b8alves, N. Perra, and A. Vespignani, \u201cModeling users\u2019 activity on twitter networks:\nValidation of dunbar\u2019s number,\u201d PloS one , vol. 6, no. 8, e22656, 2011.\n[39] H. Allcott and M. Gentzkow, \u201cSocial media and fake news in the 2016 election,\u201d Journal\nof economic perspectives , vol. 31, no. 2, pp. 211\u201336, 2017.\n[40] A. Bessi, M. Coletto, G. A. Davidescu, A. Scala, G. Caldarelli, and W. Quattrociocchi,\n\u201cScience vs conspiracy: Collective narratives in the age of misinformation,\u201d PloS one ,\nvol. 10, no. 2, e0118093, 2015.\n[41] M. Del Vicario, S. Gaito, W. Quattrociocchi, M. Zignani, and F. Zollo, \u201cNews consumption\nduring the italian referendum: A cross-platform analysis on facebook and twitter,\u201d in 2017\nIEEE International Conference on Data Science and Advanced Analytics (DSAA) , IEEE,\n2017, pp. 648\u2013657.\n[42] C. R. Sunstein, \u201cThe law of group polarization,\u201d Journal of political philosophy , vol. 10,\nno. 2, pp. 175\u2013195, 2002.\n167\n[43] P. Barber \u00b4a,Social media, echo chambers, and political polarization , 2020.\n[44] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis, \u201cQuantifying\nControversy in Social Media,\u201d in WSDM \u201916: 9th ACM International Conference on Web\nSearch and Data Mining , 2016, pp. 33\u201342.\n[45] V . D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, \u201cFast unfolding of commu-\nnities in large networks,\u201d Journal of statistical mechanics: theory and experiment , vol. 2008,\nno. 10, P10008, 2008.\n[46] U. Brandes, D. Delling, M. Gaertler, R. Gorke, M. Hoefer, Z. Nikoloski, and D. Wag-\nner, \u201cOn modularity clustering,\u201d IEEE transactions on knowledge and data engineering ,\nvol. 20, no. 2, pp. 172\u2013188, 2007.\n[47] P. Barber \u00b4a, \u201cBirds of the same feather tweet together: Bayesian ideal point estimation using\ntwitter data,\u201d Political analysis , vol. 23, no. 1, pp. 76\u201391, 2015.\n[48] J.-P. Benz \u00b4ecriet al. ,L\u2019analyse des donn \u00b4ees. Dunod Paris, 1973, vol. 2.\n[49] O. Nenadic and M. Greenacre, \u201cCorrespondence analysis in r, with two-and three-dimensional\ngraphics: The ca package,\u201d Journal of statistical software , vol. 20, no. 3, 2007.\n[50] P. Holme, \u201cNetwork reachability of real-world contact sequences,\u201d Phys. Rev. E , vol. 71,\np. 046 119, 4 Apr. 2005.\n[51] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, \u201cDistributed representations\nof words and phrases and their compositionality,\u201d in Proceedings of the 26th International\nConference on Neural Information Processing Systems - Volume 2 , ser. NIPS\u201913, Lake\nTahoe, Nevada: Curran Associates Inc., 2013, pp. 3111\u20133119.\n[52] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, \u201cLearning representations by back-\npropagating errors,\u201d Nature , vol. 323, no. 6088, pp. 533\u2013536, 1986.\n[53] D. N. Fisman, T. S. Hauck, A. R. Tuite, and A. L. Greer, \u201cAn idea for short term outbreak\nprojection: Nearcasting using the basic reproduction number,\u201d PloS one , vol. 8, no. 12,\n2013.\n168\n[54] N. T. Bailey et al. ,The mathematical theory of infectious diseases and its applications .\nCharles Grif\ufb01n & Company Ltd, 5a Crendon Street, High Wycombe, Bucks HP13 6LE.,\n1975.\n[55] J. Ma, \u201cEstimating epidemic exponential growth rate and basic reproduction number,\u201d In-\nfectious Disease Modelling , 2020.\n[56] F. Zollo and W. Quattrociocchi, \u201cMisinformation spreading on facebook,\u201d in Complex\nSpreading Phenomena in Social Systems , Springer, 2018, pp. 177\u2013196.\n[57] M. Del Vicario, G. Vivaldo, A. Bessi, F. Zollo, A. Scala, G. Caldarelli, and W. Quattrocioc-\nchi, \u201cEcho chambers: Emotional contagion and group polarization on facebook,\u201d Scienti\ufb01c\nreports , vol. 6, p. 37 825, 2016.\n[58] V . Bakir and A. McStay, \u201cFake news and the economy of emotions: Problems, causes,\nsolutions,\u201d Digital journalism , vol. 6, no. 2, pp. 154\u2013175, 2018.\n[59] D. A. Scheufele and N. M. Krause, \u201cScience audiences, misinformation, and fake news,\u201d\nProceedings of the National Academy of Sciences , vol. 116, no. 16, pp. 7662\u20137669, 2019.\n[60] W. Quattrociocchi, G. Caldarelli, and A. Scala, \u201cOpinion dynamics on interacting net-\nworks: Media competition and social in\ufb02uence,\u201d Scienti\ufb01c reports , vol. 4, p. 4938, 2014.\n[61] N. Grinberg, K. Joseph, L. Friedland, B. Swire-Thompson, and D. Lazer, \u201cFake news on\ntwitter during the 2016 u.s. presidential election,\u201d Science , vol. 363, no. 6425, pp. 374\u2013378,\n2019. eprint: https://science.sciencemag.org/content/363/6425/\n374.full.pdf .\n[62] R. Wald, T. M. Khoshgoftaar, A. Napolitano, and C. Sumner, \u201cPredicting susceptibility to\nsocial bots on twitter,\u201d in 2013 IEEE 14th International Conference on Information Reuse\n& Integration (IRI) , IEEE, 2013, pp. 6\u201313.\n[63] N. Mele, D. Lazer, M. Baum, N. Grinberg, L. Friedland, K. Joseph, W. Hobbs, and C.\nMattsson, \u201cCombating fake news: An agenda for research and action,\u201d Di https://www. hks.\nharvard. edu/publications/combating-fake-news-agenda-research-and-action (Retrieved Oc-\ntober 17, 2018) , 2017.\n169\n[64] S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, and M. Tesconi, \u201cThe paradigm-shift\nof social spambots: Evidence, theories, and tools for the arms race,\u201d in Proceedings of the\n26th International Conference on World Wide Web Companion (WWW\u201917 Companion) ,\n2017, pp. 963\u2013972.\n[65] A. Fourney, M. Z. Racz, G. Ranade, M. Mobius, and E. Horvitz, \u201cGeographic and temporal\ntrends in fake news consumption during the 2016 us presidential election,\u201d in Proceedings\nof the 2017 ACM on Conference on Information and Knowledge Management , ACM, 2017,\npp. 2071\u20132074.\n[66] S. Cresci, F. Lillo, D. Regoli, S. Tardelli, and M. Tesconi, \u201cCashtag piggybacking: Uncov-\nering spam and bot activity in stock microblogs on twitter,\u201d ACM Transactions on the Web\n(TWEB) , vol. 13, no. 2, p. 11, 2019.\n[67] M. D. Vicario, F. Zollo, G. Caldarelli, A. Scala, and W. Quattrociocchi, \u201cThe anatomy of\nbrexit debate on facebook,\u201d CoRR , vol. abs/1610.06809, 2016. arXiv: 1610.06809 .\n[68] M. D. Vicario, W. Quattrociocchi, A. Scala, and F. Zollo, \u201cPolarization and fake news:\nEarly warning of potential misinformation targets,\u201d ACM Transactions on the Web (TWEB) ,\nvol. 13, no. 2, pp. 1\u201322, 2019.\n[69] W. Quattrociocchi, \u201cInside the echo chamber,\u201d Scienti\ufb01c American , vol. 316, no. 4, pp. 60\u2013\n63, 2017.\n[70] Tackling online disinformation ,https://secure.avaaz.org/campaign/en/\ndisinfo_network_report/ , Accessed: 2020-04-04.\n[71] F. Pierri, A. Artoni, and S. Ceri, \u201cInvestigating italian disinformation spreading on twitter\nin the context of 2019 european elections,\u201d PloS one , vol. 15, no. 1, e0227821, 2020.\n[72] M. Stella, E. Ferrara, and M. De Domenico, \u201cBots increase exposure to negative and in-\n\ufb02ammatory content in online social systems,\u201d Proceedings of the National Academy of\nSciences , vol. 115, no. 49, pp. 12 435\u201312 440, 2018. eprint: https://www.pnas.\norg/content/115/49/12435.full.pdf .\n[73] Measuring the reach of \u201dfake news\u201d and online disinformation in europe ,https://\nreutersinstitute.politics.ox.ac.uk/our-research/measuring-\n170\nreach - fake - news - and - online - disinformation - europe , Accessed:\n2020-04-04.\n[74] European journalism observatory ,https://en.ejo.ch/ , Accessed: 2020-04-04.\n[75] Snopes ,https://www.snopes.com/ , Accessed: 2020-04-04.\n[76] Politifact ,https://www.politifact.com/ , Accessed: 2020-04-04.\n[77] European media monitor ,https : / / emm . newsbrief . eu / overview . html ,\nAccessed: 2020-04-04.\n[78] Members of the european parliament ,http : / / www . europarl . europa . eu /\nmeps/en/home , Accessed: 2020-04-04.\n[79] D. W. Brady and H. C. Han, \u201cPolarization then and now: A historical perspective,\u201d Red\nand blue nation , vol. 1, pp. 119\u2013151, 2006.\n[80] C. Hare and K. T. Poole, \u201cThe polarization of contemporary american politics,\u201d Polity ,\nvol. 46, no. 3, pp. 411\u2013429, 2014.\n[81] R. Axelrod, J. J. Daymude, and S. Forrest, \u201cPreventing extreme polarization of political\nattitudes,\u201d arXiv preprint arXiv:2103.06492 , 2021.\n[82] D. Guilbeault and D. Centola, \u201cTopological measures for identifying and predicting the\nspread of complex contagions,\u201d Nature communications , vol. 12, no. 1, pp. 1\u20139, 2021.\n[83] P. Metaxas, E. Mustafaraj, K. Wong, L. Zeng, M. O\u2019Keefe, and S. Finn, \u201cWhat do retweets\nindicate? results from user survey and meta-review of research,\u201d in Proceedings of the\nInternational AAAI Conference on Web and Social Media , vol. 9, 2015.\n[84] N. McCarty, Polarization: What everyone needs to know\u00ae . Oxford University Press, 2019.\n[85] W. A. Galston and P. S. Nivola, \u201cDelineating the problem,\u201d Red and blue nation , vol. 1,\npp. 1\u201347, 2006.\n171\n[86] A. I. Abramowitz and M. P. Fiorina, \u201cPolarized or sorted? just what\u2019s wrong with our\npolitics, anyway,\u201d The American Interest , 2013.\n[87] M. P. Fiorina and S. J. Abrams, \u201cPolitical polarization in the american public,\u201d Annu. Rev.\nPolit. Sci. , vol. 11, pp. 563\u2013588, 2008.\n[88] G. C. Layman, T. M. Carsey, and J. M. Horowitz, \u201cParty polarization in american politics:\nCharacteristics, causes, and consequences,\u201d Annu. Rev. Polit. Sci. , vol. 9, pp. 83\u2013110, 2006.\n[89] L. Mason, \u201c\u2018\u2018i disrespectfully agree\u201d: The differential effects of partisan sorting on social\nand issue polarization,\u201d American Journal of Political Science , vol. 59, no. 1, pp. 128\u2013145,\n2015.\n[90] R. Ef\ufb01ng, J. Van Hillegersberg, and T. Huibers, \u201cSocial media and political participation:\nAre facebook, twitter and youtube democratizing our political systems?\u201d In International\nconference on electronic participation , Springer, 2011, pp. 25\u201335.\n[91] M. Broersma and T. Graham, \u201cSocial media as beat: Tweets as a news source during the\n2010 british and dutch elections,\u201d journalism practice , vol. 6, no. 3, pp. 403\u2013419, 2012.\n[92] P. T. Metaxas and E. Mustafaraj, \u201cSocial media and the elections,\u201d Science , vol. 338,\nno. 6106, pp. 472\u2013473, 2012.\n[93] A. Ceron, L. Curini, and S. M. Iacus, Politics and big data: Nowcasting and forecasting\nelections with social media . Routledge, 2016.\n[94] A. Bovet, F. Morone, and H. A. Makse, \u201cValidation of twitter opinion trends with national\npolling aggregates: Hillary clinton vs donald trump,\u201d Scienti\ufb01c reports , vol. 8, no. 1, pp. 1\u2013\n16, 2018.\n[95] F. B. Soares, R. Recuero, and G. Zago, \u201cIn\ufb02uencers in polarized political networks on\ntwitter,\u201d in Proceedings of the 9th international conference on social media and society ,\n2018, pp. 168\u2013177.\n[96] P. Grover, A. K. Kar, Y . K. Dwivedi, and M. Janssen, \u201cPolarization and acculturation in\nus election 2016 outcomes\u2013can twitter analytics predict changes in voting preferences,\u201d\nTechnological Forecasting and Social Change , vol. 145, pp. 438\u2013460, 2019.\n172\n[97] S. Lee and M. Xenos, \u201cSocial distraction? social media use and political knowledge in two\nus presidential elections,\u201d Computers in human behavior , vol. 90, pp. 18\u201325, 2019.\n[98] Z. Acharoui, A. Alaoui, B. Ettaki, J. Zerouaoui, and M. Dakkon, \u201cIdentifying political\nin\ufb02uencers on youtube during the 2016 moroccan general election,\u201d Procedia Computer\nScience , vol. 170, pp. 1102\u20131109, 2020.\n[99] G. Suau-Gomila, C. Pont-Sorribes, and R. Pedraza-Jim \u00b4enez, \u201cPoliticians or in\ufb02uencers?\ntwitter pro\ufb01les of pablo iglesias and albert rivera in the spanish general elections of 20-d\nand 26-j,\u201d Communication & Society , pp. 209\u2013225, 2020.\n[100] C. Shao, P.-M. Hui, L. Wang, X. Jiang, A. Flammini, F. Menczer, and G. L. Ciampaglia,\n\u201cAnatomy of an online misinformation network,\u201d PloS one , vol. 13, no. 4, e0196087, 2018.\n[101] C. Machado, B. Kira, V . Narayanan, B. Kollanyi, and P. Howard, \u201cA study of misinforma-\ntion in whatsapp groups with a focus on the brazilian presidential elections.,\u201d in Companion\nproceedings of the 2019 World Wide Web conference , 2019, pp. 1013\u20131019.\n[102] M. D. Conover, J. Ratkiewicz, M. Francisco, B. Gonc \u00b8alves, F. Menczer, and A. Flammini,\n\u201cPolitical polarization on twitter,\u201d in Fifth international AAAI conference on weblogs and\nsocial media , 2011.\n[103] M. Prior, \u201cMedia and political polarization,\u201d Annual Review of Political Science , vol. 16,\npp. 101\u2013127, 2013.\n[104] D. Mocanu, L. Rossi, Q. Zhang, M. Karsai, and W. Quattrociocchi, \u201cCollective attention\nin the age of (mis) information,\u201d Computers in Human Behavior , vol. 51, pp. 1198\u20131204,\n2015.\n[105] A. Bessi, F. Petroni, M. Del Vicario, F. Zollo, A. Anagnostopoulos, A. Scala, G. Caldarelli,\nand W. Quattrociocchi, \u201cHomophily and polarization in the age of misinformation,\u201d The\nEuropean Physical Journal Special Topics , vol. 225, no. 10, pp. 2047\u20132059, 2016.\n[106] C. Vaccari, A. Valeriani, P. Barber \u00b4a, J. T. Jost, J. Nagler, and J. A. Tucker, \u201cOf echo cham-\nbers and contrarian clubs: Exposure to political disagreement among german and italian\nusers of twitter,\u201d Social media+ society , vol. 2, no. 3, p. 2 056 305 116 664 221, 2016.\n173\n[107] A. Bessi, F. Zollo, M. Del Vicario, M. Puliga, A. Scala, G. Caldarelli, B. Uzzi, and W.\nQuattrociocchi, \u201cUsers polarization on facebook and youtube,\u201d PloS one , vol. 11, no. 8,\ne0159641, 2016.\n[108] Y . Lelkes, G. Sood, and S. Iyengar, \u201cThe hostile audience: The effect of access to broad-\nband internet on partisan affect,\u201d American Journal of Political Science , vol. 61, no. 1,\npp. 5\u201320, 2017.\n[109] C. A. Bail, L. P. Argyle, T. W. Brown, J. P. Bumpus, H. Chen, M. F. Hunzaker, J. Lee, M.\nMann, F. Merhout, and A. V olfovsky, \u201cExposure to opposing views on social media can\nincrease political polarization,\u201d Proceedings of the National Academy of Sciences , vol. 115,\nno. 37, pp. 9216\u20139221, 2018.\n[110] M. Cinelli, G. D. F. Morales, A. Galeazzi, W. Quattrociocchi, and M. Starnini, \u201cThe\necho chamber effect on social media,\u201d Proceedings of the National Academy of Sciences ,\nvol. 118, no. 9, 2021.\n[111] W. Webber, A. Moffat, and J. Zobel, \u201cA similarity measure for inde\ufb01nite rankings,\u201d ACM\nTransactions on Information Systems , vol. 28, no. 4, p. 20, 2010.\n[112] F. Morone and H. A. Makse, \u201cIn\ufb02uence maximization in complex networks through opti-\nmal percolation,\u201d Nature , vol. 524, no. 7563, pp. 65\u201368, 2015.\n[113] F. Morone, B. Min, L. Bo, R. Mari, and H. A. Makse, \u201cCollective in\ufb02uence algorithm to\n\ufb01nd in\ufb02uencers via optimal percolation in massively large social media,\u201d Scienti\ufb01c reports ,\nvol. 6, no. 1, pp. 1\u201311, 2016.\n[114] X. Teng, S. Pei, F. Morone, and H. A. Makse, \u201cCollective in\ufb02uence of multiple spread-\ners evaluated by tracing real information \ufb02ow in large-scale social networks,\u201d Scienti\ufb01c\nreports , vol. 6, no. 1, pp. 1\u201311, 2016.\n[115] J. A. Hartigan and P. M. Hartigan, \u201cThe dip test of unimodality,\u201d The annals of Statistics ,\npp. 70\u201384, 1985.\n[116] L. Bozarth, A. Saraf, and C. Budak, \u201cHigher ground? how groundtruth labeling impacts\nour understanding of fake news about the 2016 us presidential nominees,\u201d in Proceedings\nof the International AAAI Conference on Web and Social Media , vol. 14, 2020, pp. 48\u201359.\n174\n[117] T. J. Main, The rise of the alt-right . Brookings Institution Press, 2018.\n[118] P. Stefanov, K. Darwish, A. Atanasov, and P. Nakov, \u201cPredicting the topical stance and\npolitical leaning of media using tweets,\u201d in Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics , 2020, pp. 527\u2013537.\n[119] M. Cinelli, W. Quattrociocchi, A. Galeazzi, C. M. Valensise, E. Brugnoli, A. L. Schmidt,\nP. Zola, F. Zollo, and A. Scala, \u201cThe covid-19 social media infodemic,\u201d Scienti\ufb01c Reports ,\nvol. 10, 2020.\n[120] L. Bode, \u201cPolitical news in the news feed: Learning politics from social media,\u201d Mass\ncommunication and society , vol. 19, no. 1, pp. 24\u201348, 2016.\n[121] N. Newman, R. Fletcher, A. Kalogeropoulos, and R. Nielsen, Reuters institute digital news\nreport 2019 . Reuters Institute for the Study of Journalism, 2019, vol. 2019.\n[122] S. Flaxman, S. Goel, and J. M. Rao, \u201cFilter bubbles, echo chambers, and online news\nconsumption,\u201d Public opinion quarterly , vol. 80, no. S1, pp. 298\u2013320, 2016.\n[123] T. Sharot and C. R. Sunstein, \u201cHow people decide what they want to know,\u201d Nature Human\nBehaviour , vol. 4, pp. 1\u20136, 2020.\n[124] A. Baronchelli, \u201cThe emergence of consensus: A primer,\u201d Royal Society open science ,\nvol. 5, no. 2, p. 172 189, 2018.\n[125] J. T. Klapper, The effects of mass communication. 1960.\n[126] R. S. Nickerson, \u201cCon\ufb01rmation bias: A ubiquitous phenomenon in many guises,\u201d Review\nof general psychology , vol. 2, no. 2, pp. 175\u2013220, 1998.\n[127] E. Gilbert, T. Bergstrom, and K. Karahalios, \u201cBlogs are echo chambers: Blogs are echo\nchambers,\u201d in 42nd Hawaii International Conference on System Sciences , 2009, pp. 1\u201310.\n[128] A. Edwards, \u201c(how) do participants in online discussion forums create \u2018echo chambers\u2019?:\nThe inclusion and exclusion of dissenting voices in an online forum about climate change,\u201d\nJournal of Argumentation in Context , vol. 2, no. 1, pp. 127\u2013150, 2013.\n175\n[129] M. Gr \u00a8omping, \u201c\u2018Echo Chambers\u2019 Partisan Facebook Groups during the 2014 Thai Elec-\ntion,\u201d Asia Paci\ufb01c Media Educator , vol. 24, no. 1, pp. 39\u201359, 2014.\n[130] W. Quattrociocchi, A. Scala, and C. R. Sunstein, Echo chambers on Facebook , 2016.\n[131] I. Himelboim, S. McCreery, and M. Smith, \u201cBirds of a feather tweet together: Integrating\nnetwork and content analyses to examine cross-ideology exposure on twitter,\u201d Journal of\ncomputer-mediated communication , vol. 18, no. 2, pp. 154\u2013174, 2013.\n[132] D. Nikolov, D. F. Oliveira, A. Flammini, and F. Menczer, \u201cMeasuring online social bub-\nbles,\u201d PeerJ Computer Science , vol. 1, e38, 2015.\n[133] F. Baumann, P. Lorenz-Spreen, I. M. Sokolov, and M. Starnini, \u201cModeling echo chambers\nand polarization dynamics in social networks,\u201d Physical Review Letters , vol. 124, no. 4,\np. 048 301, 2020.\n[134] A. Gollwitzer, C. Martel, W. J. Brady, P. P \u00a8arnamets, I. G. Freedman, E. D. Knowles, and\nJ. J. Van Bavel, \u201cPartisan differences in physical distancing are linked to health outcomes\nduring the covid-19 pandemic,\u201d Nature Human Behaviour , vol. 4, 2020.\n[135] Y . Golovchenko, C. Buntain, G. Eady, M. A. Brown, and J. A. Tucker, \u201cCross-platform\nstate propaganda: Russian trolls on twitter and youtube during the 2016 us presidential\nelection,\u201d The International Journal of Press/Politics , vol. 25, p. 1 940 161 220 912 682,\n2020.\n[136] S. Zannettou, B. Bradlyn, E. De Cristofaro, H. Kwak, M. Sirivianos, G. Stringini, and\nJ. Blackburn, \u201cWhat is gab: A bastion of free speech or an alt-right echo chamber,\u201d in\nCompanion Proceedings of the The Web Conference 2018 , International World Wide Web\nConferences Steering Committee, 2018, pp. 1007\u20131014.\n[137] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis, \u201cQuantifying\ncontroversy on social media,\u201d TSC: ACM Transactions on Social Computing , vol. 1, no. 1,\np. 3, 2018.\n[138] M. H. DeGroot, \u201cReaching a consensus,\u201d Journal of the American Statistical Association ,\nvol. 69, no. 345, pp. 118\u2013121, 1974.\n176\n[139] G. Kossinets and D. J. Watts, \u201cOrigins of homophily in an evolving social network,\u201d Amer-\nican journal of sociology , vol. 115, no. 2, pp. 405\u2013450, 2009.\n[140] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis, \u201cReducing Con-\ntroversy by Connecting Opposing Views,\u201d in WSDM \u201917: 10th ACM International Confer-\nence on Web Search and Data Mining , 2017, pp. 81\u201390.\n[141] R. M. Anderson and R. M. May, Infectious diseases in humans . Oxford: Oxford University\nPress, 1992.\n[142] M. Jalili and M. Perc, \u201cInformation cascades in complex networks,\u201d Journal of Complex\nNetworks , vol. 5, no. 5, pp. 665\u2013693, 2017.\n[143] L. Zhao, H. Cui, X. Qiu, X. Wang, and J. Wang, \u201cSir rumor spreading model in the new\nmedia age,\u201d Physica A: Statistical Mechanics and its Applications , vol. 392, no. 4, pp. 995\u2013\n1003, 2013.\n[144] C. Granell, S. G \u00b4omez, and A. Arenas, \u201cDynamical interplay between awareness and epi-\ndemic spreading in multiplex networks,\u201d Phys. Rev. Lett. , vol. 111, p. 128 701, 12 Sep.\n2013.\n[145] A. L. Schmidt, F. Zollo, A. Scala, C. Betsch, and W. Quattrociocchi, \u201cPolarization of the\nvaccination debate on facebook,\u201d Vaccine , vol. 36, no. 25, pp. 3606\u20133612, 2018.\n[146] H. Lu, J. Caverlee, and W. Niu, \u201cBiaswatch: A lightweight system for discovering and\ntracking topic-sensitive opinion bias in social media,\u201d in CIKM , ACM, 2015, pp. 213\u2013222.\n[147] W. H. Organization, Naming the coronavirus disease (covid-19) and the virus that causes\nit,https:www.who.int/emergencies/diseases/novel-coronavirus-\n2019/technical-guidance/naming-the-coronavirus-disease-(covid-\n2019)-and-the-virus-that-causes-it , 2020 (accessed April 9, 2020).\n[148] WHO Situation Report 13 ,https://www.who.int/docs/default-source/\ncoronaviruse/situation-reports/20200202-sitrep-13-ncov-v3.\npdf?sfvrsn=195f4010_6 , Accessed: 2010-09-30.\n[149] W. H. Organization, Director-general\u2019s remarks at the media brie\ufb01ng on 2019 novel coro-\nnavirus on 8 february 2020 ,https://www.who.int/dg/speeches/detail/\n177\ndirector-general-s-remarks-at-the-media-briefing-on-2019-\nnovel-coronavirus---8-february-2020 , 2020 (accessed April 9, 2020).\n[150] M. Mendoza, B. Poblete, and C. Castillo, \u201cTwitter under crisis: Can we trust what we rt?\u201d\nInProceedings of the \ufb01rst workshop on social media analytics , 2010, pp. 71\u201379.\n[151] K. Starbird, J. Maddock, M. Orand, P. Achterman, and R. M. Mason, \u201cRumors, false \ufb02ags,\nand digital vigilantes: Misinformation on twitter after the 2013 boston marathon bombing,\u201d\nIConference 2014 Proceedings , 2014.\n[152] L. Kim, S. M. Fast, and N. Markuzon, \u201cIncorporating media data into a model of infectious\ndisease transmission,\u201d PloS one , vol. 14, no. 2, 2019.\n[153] T. John and C. Ben Wedeman, Italy prohibits travel and cancels all public events in its\nnorthern region to contain coronavirus ,https://edition.cnn.com/2020/03/\n08/europe/italy-coronavirus-lockdown-europe-intl/index.html ,\n2020 (accessed April 9, 2020).\n[154] J. Shaman, A. Karspeck, W. Yang, J. Tamerius, and M. Lipsitch, \u201cReal-time in\ufb02uenza\nforecasts during the 2012\u20132013 season,\u201d Nature communications , vol. 4, no. 1, pp. 1\u201310,\n2013.\n[155] C. Viboud and A. Vespignani, \u201cThe future of in\ufb02uenza forecasts,\u201d Proceedings of the Na-\ntional Academy of Sciences , vol. 116, no. 8, pp. 2802\u20132804, 2019.\n[156] J. Kulshrestha, M. Eslami, J. Messias, M. B. Zafar, S. Ghosh, K. P. Gummadi, and K.\nKarahalios, \u201cQuantifying search bias: Investigating sources of bias for political searches\nin social media,\u201d in Proceedings of the 2017 ACM Conference on Computer Supported\nCooperative Work and Social Computing , 2017, pp. 417\u2013432.\n[157] M. Starnini, M. Frasca, and A. Baronchelli, \u201cEmergence of metapopulations and echo\nchambers in mobile agents,\u201d Scienti\ufb01c reports , vol. 6, p. 31 834, 2016.\n[158] F. Zollo, A. Bessi, M. Del Vicario, A. Scala, G. Caldarelli, L. Shekhtman, S. Havlin, and\nW. Quattrociocchi, \u201cDebunking in a world of tribes,\u201d PloS one , vol. 12, no. 7, 2017.\n[159] C. Wardle and H. Derakhshan, \u201cInformation disorder: Toward an interdisciplinary frame-\nwork for research and policy making,\u201d Council of Europe report , vol. 27, 2017.\n178\n[160] L. Schild, C. Ling, J. Blackburn, G. Stringhini, Y . Zhang, and S. Zannettou, \u201c\u201dgo eat a bat,\nchang!\u201d: An early look on the emergence of sinophobic behavior on web communities in\nthe face of covid-19,\u201d arXiv preprint arXiv:2004.04046 , 2020.\n[161] N. Vel \u00b4asquez, R. Leahy, N. J. Restrepo, Y . Lupu, R. Sear, N. Gabriel, O. Jha, and N.\nJohnson, \u201cHate multiverse spreads malicious covid-19 content online beyond individual\nplatform control,\u201d arXiv preprint arXiv:2004.00673 , 2020.\n[162] E. Ferrara, \u201cWhat types of covid-19 conspiracies are populated by twitter bots?\u201d First\nMonday , 2020.\n[163] F. Alam, S. Shaar, A. Nikolov, H. Mubarak, G. D. S. Martino, A. Abdelali, F. Dalvi, N.\nDurrani, H. Sajjad, K. Darwish, et al. , \u201cFighting the covid-19 infodemic: Modeling the\nperspective of journalists, fact-checkers, social media platforms, policy makers, and the\nsociety,\u201d arXiv preprint arXiv:2005.00033 , 2020.\n[164] G. K. Shahi, A. Dirkson, and T. A. Majchrzak, \u201cAn exploratory study of covid-19 misin-\nformation on twitter,\u201d arXiv preprint arXiv:2005.05710 , 2020.\n[165] M. B. C. (MBFC), Media bias/fact check, the most comprehensive meida bias check re-\nsource ,https://mediabiasfactcheck.com/ , 2020 (accessed April 9, 2020).\n[166] D. M. Romero, B. Meeder, and J. Kleinberg, \u201cDifferences in the mechanics of information\ndiffusion across topics: Idioms, political hashtags, and complex contagion on twitter,\u201d in\nProceedings of the 20th international conference on World wide web , 2011, pp. 695\u2013704.\n[167] W. H. Organization, Novel coronavirus (2019-ncov) situation report - 1 21 january 2020 ,\nhttps://www.who.int/docs/default-source/coronaviruse/situation-\nreports/20200121-sitrep-1-2019-ncov.pdf?sfvrsn=20a99c10_4 ,\n2020 (accessed April 9, 2020).\n[168] L. Pellis, F. Ball, S. Bansal, K. Eames, T. House, V . Isham, and P. Trapman, \u201cEight chal-\nlenges for network epidemic models,\u201d Epidemics , vol. 10, pp. 58\u201362, 2015.\n[169] Y . Liu, B. Wang, B. Wu, S. Shang, Y . Zhang, and C. Shi, \u201cCharacterizing super-spreading\nin microblog: An epidemic-based information propagation model,\u201d Physica A: Statistical\nMechanics and its Applications , vol. 463, pp. 202\u2013218, 2016.\n179\n[170] J. Skaza and B. Blais, \u201cModeling the infectiousness of twitter hashtags,\u201d Physica A: Sta-\ntistical Mechanics and its Applications , vol. 465, pp. 289\u2013296, 2017.\n[171] J. T. Davis, N. Perra, Q. Zhang, Y . Moreno, and A. Vespignani, \u201cPhase transitions in infor-\nmation spreading on structured populations,\u201d Nature Physics , pp. 1\u20137, 2020.\n[172] G. Chowell, \u201cFitting dynamic models to epidemic outbreaks with quanti\ufb01ed uncertainty:\nA primer for parameter uncertainty, identi\ufb01ability, and forecasts,\u201d Infectious Disease Mod-\nelling , vol. 2, no. 3, pp. 379\u2013398, 2017.\n[173] D. Centola, \u201cThe spread of behavior in an online social network experiment,\u201d Science ,\nvol. 329, no. 5996, pp. 1194\u20131197, 2010.\n[174] M. Del Vicario, A. Scala, G. Caldarelli, H. E. Stanley, and W. Quattrociocchi, \u201cModeling\ncon\ufb01rmation bias and polarization,\u201d Scienti\ufb01c reports , vol. 7, p. 40 391, 2017.\n[175] T. Mikolov, W.-t. Yih, and G. Zweig, \u201cLinguistic regularities in continuous space word\nrepresentations,\u201d in Proceedings of the 2013 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language Technologies , Atlanta,\nGeorgia: Association for Computational Linguistics, Jun. 2013, pp. 746\u2013751.\n[176] B. Efron and R. J. Tibshirani, An introduction to the bootstrap . CRC press, 1994.\n180\n181\nAPPENDIX A\nTABLES FOR MEASURING THE EVOLUTION OF POLARIZATION\nAND NEWS INFLUENCERS BETWEEN TWO U.S. PRESIDENTIAL\nELECTIONS ON TWITTER\n182\nfake news extreme bias (right) news right news\nhostnames N hostnames N hostnames N\n1 thegatewaypundit.com 761 756 breitbart.com 1 854 920 foxnews.com 1 122 732\n2 truthfeed.com 554 955 dailycaller.com 759 504 dailymail.co.uk 474 846\n3 infowars.com 478 872 americanthinker.com 179 696 washingtonexaminer.com 462 769\n4 therealstrategy.com 241 354 wnd.com 141 336 nypost.com 441 648\n5 conservativetribune.com 212 273 freebeacon.com 129 077 bizpacreview.com 170 770\n6 zerohedge.com 186 706 newsninja2012.com 127 251 nationalreview.com 164 036\n7 rickwells.us 78 736 hannity.com 114 221 lifezette.com 139 257\n8 departed.co 72 773 newsmax.com 94 882 redstate.com 105 912\n9 thepoliticalinsider.com 66 426 endingthefed.com 88 376 allenbwest.com 104 857\n10 therightscoop.com 63 852 truepundit.com 84 967 theconservativetreehouse.com 102 515\n11 teaparty.org 48 757 westernjournalism.com 77 717 townhall.com 102 408\n12 usapoliticsnow.com 46 252 dailywire.com 67 893 investors.com 102 295\n13 clashdaily.com 45 970 newsbusters.org 60 147 theblaze.com 99 029\n14 thefederalistpapers.org 45 831 ilovemyfreedom.org 54 772 theamericanmirror.com 91 538\n15 red\ufb02agnews.com 45 423 100percentfedup.com 54 596 ijr.com 71 558\n16 thetruthdivision.com 44 486 pjmedia.com 46 542 judicialwatch.org 70 543\n17 weaselzippers.us 45 199 thefederalist.com 55 835\n18 hotair.com 55 431\n19 conservativereview.com 54 307\n20 weeklystandard.com 50 707\nright leaning news center news left leaning news\nhostnames N hostnames N hostnames N\n1 wsj.com 310 416 cnn.com 2 291 736 nytimes.com 1 811 627\n2 washingtontimes.com 208 061 thehill.com 1 200 123 washingtonpost.com 1 640 088\n3 rt.com 157 474 politico.com 1 173 717 nbcnews.com 512 056\n4 realclearpolitics.com 128 417 usatoday.com 326 198 abcnews.go.com 467 533\n5 telegraph.co.uk 82 118 reuters.com 283 962 theguardian.com 439 580\n6 forbes.com 64 186 bloomberg.com 266 662 vox.com 369 789\n7 fortune.com 57 644 businessinsider.com 239 423 slate.com 279 438\n8 apnews.com 198 140 buzzfeed.com 278 642\n9 observer.com 128 043 cbsnews.com 232 889\n10 \ufb01vethirtyeight.com 124 268 politifact.com 198 095\n11 bbc.com 118 176 latimes.com 190 994\n12 ibtimes.com 72 424 nydailynews.com 188 769\n13 bbc.co.uk 71 941 theatlantic.com 177 637\n14 mediaite.com 152 877\n15 newsweek.com 149 490\n16 npr.org 142 143\n17 independent.co.uk 127 689\n18 cnb.cx 87 094\n19 hollywoodreporter.com 84 997\nleft news extreme bias (left) news\nhostnames N hostnames N\n1 huf\ufb01ngtonpost.com 1 057 518 dailynewsbin.com 189 257\n2 thedailybeast.com 378 931 bipartisanreport.com 119 857\n3 dailykos.com 324 351 bluenationreview.com 75 455\n4 rawstory.com 297 256 crooksandliars.com 73 615\n5 politicususa.com 293 419 occupydemocrats.com 73 143\n6 time.com 252 468 shareblue.com 50 880\n7 motherjones.com 210 280 usuncut.com 27 653\n8 talkingpointsmemo.com 199 346\n9 msnbc.com 177 090\n10 mashable.com 173 129\n11 salon.com 172 807\n12 thinkprogress.org 172 144\n13 newyorker.com 171 102\n14 mediamatters.org 152 160\n15 nymag.com 121 636\n16 theintercept.com 109 591\n17 thenation.com 54 661\n18 people.com 47 942\nTable A.1: Hostnames in each media category in 2016 . We also show the number ( N) of tweets\nwith a URL pointing toward each hostname. Tweets with several URLs are counted multiple times.\nReproduced from [18]\n183\nfake news extreme bias (right) news right news\nhostnames N hostnames N hostnames N\n1 thegatewaypundit.com 1 883 852 breitbart.com 2 192 997 foxnews.com 3 136 578\n2 hannity.com 428 483 dailymail.co.uk 600 523 dailycaller.com 771 765\n3 waynedupree.com 258 838 bongino.com 346 103 washingtonexaminer.com 717 017\n4 judicialwatch.org 233 085 thenationalpulse.com 215 017 justthenews.com 689 725\n5 truepundit.com 176 647 freebeacon.com 197 092 thefederalist.com 687 091\n6 zerohedge.com 165 960 newsmax.com 192 924 dailywire.com 396 233\n7 davidharrisjr.com 150 887 pjmedia.com 123 338 theepochtimes.com 288 656\n8 political\ufb02are.com 145 838 newsbusters.org 71 008 nationalreview.com 283 172\n9 djhjmedia.com 112 049 therightscoop.com 66 676 saraacarter.com 267 237\n10 rumble.com 101 979 americanthinker.com 59 142 townhall.com 256 631\n11 theconservativetreehouse.com 99 716 theblaze.com 191 515\n12 oann.com 97 325 thepostmillennial.com 181 674\n13 thedcpatriot.com 90 209 westernjournal.com 165 914\n14 washingtonews.today 79 314 redstate.com 144 010\n15 rightwingtribune.com 58 442 thegreggjarrett.com 139 749\n16 rt.com 54 985 bizpacreview.com 97 375\n17 wnd.com 54 929 twitchy.com 95 401\n18 gellerreport.com 54 277 trendingpolitics.com 92 094\n19 national\ufb01le.com 52 393 lifenews.com 90 064\n20 summit.news 49 539\nright leaning news center news left leaning news\nhostnames N hostnames N hostnames N\n1 nypost.com 1 701 531 thehill.com 2 256 888 nytimes.com 6 775 402\n2 wsj.com 887 537 apnews.com 1 182 504 washingtonpost.com 6 438 506\n3 forbes.com 748 636 usatoday.com 993 957 cnn.com 5 577 352\n4 washingtontimes.com 408 349 businessinsider.com 773 328 politico.com 2 290 755\n5 foxbusiness.com 212 742 newsweek.com 756 820 nbcnews.com 2 231 564\n6 thebulwark.com 175 417 reuters.com 746 033 theguardian.com 1 116 515\n7 marketwatch.com 96 626 bbc.com 296 098 theatlantic.com 1 046 475\n8 realclearpolitics.com 93 120 economist.com 123 939 abcnews.go.com 1 042 419\n9 detroitnews.com 77 223 \ufb01vethirtyeight.com 101 824 npr.org 871 571\n10 dallasnews.com 75 910 ft.com 91 524 bloomberg.com 767 059\n11 rasmussenreports.com 58 712 foreignpolicy.com 87 729 cbsnews.com 747 442\n12 chicagotribune.com 56 974 factcheck.org 79 456 cnbc.com 649 041\n13 jpost.com 55 223 news.sky.com 78 372 axios.com 621 609\n14 msn.com 613 127\n15 news.yahoo.com 586 724\n16 independent.co.uk 513 765\n17 latimes.com 451 878\n18 citizensforethics.org 382 101\n19 buzzfeednews.com 369 962\nleft news extreme bias (left) news\nhostnames N hostnames N\n1 rawstory.com 2 148 200 occupydemocrats.com 18 151\n2 msnbc.com 1 606 071 lancastercourier.com 5815\n3 thedailybeast.com 1 404 756 deepleft\ufb01eld.info 5753\n4 huffpost.com 1 121 642 tplnews.com 4022\n5 politicususa.com 671 043 bipartisanreport.com 3243\n6 palmerreport.com 434 503 bossip.com 2287\n7 motherjones.com 424 106 polipace.com 586\n8 vox.com 420 613\n9 vanityfair.com 352 964\n10 nymag.com 320 049\n11 newyorker.com 288 409\n12 dailykos.com 288 384\n13 slate.com 250 942\n14 salon.com 229 583\n15 rollingstone.com 190 828\n16 thenation.com 130 272\n17 alternet.org 126 788\n18 theintercept.com 104 153\nTable A.2: Hostnames in each media category in 2020 . We also show the number ( N) of tweets\nwith a URL pointing toward each hostname. Tweets with several URLs are counted multiple times.\n184\n2016\nNtptNupuNt=Nupt;n=opu;n=oNt;n=o=Nu;n=o\nFake news 2 991 073 0 :10 68 391 0 :03 43:73 0:19 0:07 124:22\nExtreme bias right 3 969 639 0 :13 131 346 0 :06 30:22 0:09 0:05 56:73\nRight news 4 032 284 0 :13 194 229 0 :08 20:76 0:11 0:07 33:77\nRight leaning news 1 006 746 0 :03 64 771 0 :03 15:54 0:18 0:09 31:56\nCenter news 6 322 257 0 :21 600 546 0 :26 10:53 0:20 0:05 38:10\nLeft leaning news 7 491 344 0 :24 903 689 0 :39 8:29 0:14 0:06 19:16\nLeft news 4 353 999 0 :14 327 411 0 :14 13:30 0:14 0:07 26:16\nExtreme bias left 609 503 0 :02 19 423 0 :01 31:38 0:06 0:03 74:21\n2020\nNtptNupuNt=Nupt;n=opu;n=oNt;n=o=Nu;n=o\nFake news 4 348 747 0 :06 99 020 0 :03 43:92 0:01 0:01 81:77\nExtreme bias right 4 064 820 0 :06 107 250 0 :03 37:90 0:02 0:01 73:62\nRight news 8 691 901 0 :12 382 358 0 :10 22:73 0:02 0:01 44:52\nRight leaning news 4 648 000 0 :06 288 207 0 :08 16:13 0:02 0:01 23:35\nCenter news 7 568 472 0 :10 398 241 0 :11 19:00 0:03 0:02 33:96\nLeft leaning news 33 093 267 0 :45 2 136 830 0 :59 15:49 0:03 0:02 22:85\nLeft news 10 513 306 0 :14 237 685 0 :07 44:23 0:03 0:02 73:42\nExtreme bias left 39 857 0:00 887 0 :00 44:93 0:05 0:02 82:59\nTable A.3: Tweet and user volume corresponding to each media category on Twitter between\nJune 1stuntil election day in 2016 (top) and 2020 (bottom) . Number,Nt, and proportion, pt, of\ntweets with a URL pointing to a website belonging to one of the media categories. Number, Nu,\nand proportion, pu, of unique users in each category. Users are classi\ufb01ed in the category where\nthe posted the largest number of tweets. Ties are randomly assigned. Proportion of tweets sent by\nnon-of\ufb01cial clients, pt,n/o, proportion of users having sent at least one tweet from an non-of\ufb01cial\nclient,pu,n/o, and average number of tweets per user sent from non-of\ufb01cial clients, Nt,n/o=Nu;n=o.\n185\nNews category Nodes Edges hkimax(kout) max(kin)\u001b(kout)=hki\u001b(kin)=hki\n2016Fake News 175,605 1,143,083 6.51 42,468 1232 32\u00064 2:49\u00060:06\nExtreme bias (right) 249,659 1,637,927 6.56 51,845 588 36\u00066 2:73\u00060:03\nRight 345,644 1,797,023 5.20 86,454 490 44\u000611 2:70\u00060:04\nRight leaning 216,026 495,307 2.29 32,653 129 45\u000611 1:72\u00060:02\nCenter 864,733 2,501,037 2.89 229,751 512 75\u000639 2:69\u00060:06\nLeft leaning 1,043,436 3,570,653 3.42 145,047 843 59\u000619 3:38\u00060:10\nLeft 536,903 1,801,658 3.36 58,901 733 47\u000612 3:50\u00060:08\nExtreme bias (left) 78,911 277,483 3.52 23,168 648 33\u00066 2:49\u00060:08\n2020Fake News 367,487 1,861,620 5.06 90,125 292 59\u000611 2:05\u00060:02\nExtreme bias (right) 445,776 2,008,760 4.50 89,902 313 60\u000616 2:09\u00060:02\nRight 674,935 4,452,861 6.59 109,053 607 54\u00069 2:43\u00060:03\nRight leaning 882,552 3,203,999 3.63 115,302 298 59\u000616 1:86\u00060:02\nCenter 1,163,610 4,461,011 3.83 276,289 709 65\u000629 2:37\u00060:04\nLeft leaning 2,355,587 17,461,102 7.41 325,726 1,564 63\u000620 3:62\u00060:05\nLeft 819,684 4,688,119 5.71 175,841 1,042 57\u000614 2:68\u00060:04\nExtreme bias (left) 21,411 26,888 1.25 5,755 27 41\u00063 0:60\u00060:01\nTable A.4: Retweet network characteristics for each news category. Number of nodes, edges,\naverage degree and degree heterogeneity of each network. The in- and out-degree heterogeneities\nare calculated by taking the average and standard error of 1000 independent samples of the degree\nheterogeneity ( \u001b(kin)=hkiand\u001b(kout)=hki), each of which is computed on 78,911 samples with\nreplacements from their respective degree distributions.\n186\nrank fake news extreme bias (right) news right news right leaning news\n(7 veri\ufb01ed, 2 deleted, (15 veri\ufb01ed, 1 deleted, (22 veri\ufb01ed, 0 deleted, (20 veri\ufb01ed, 1 deleted\n19 unveri\ufb01ed) 9 unveri\ufb01ed) 2 unveri\ufb01ed) 4 unveri\ufb01ed)\n1 @PrisonPlanet X @realDonaldTrump X @FoxNews X @WSJX\n2 @RealAlexJones X @DailyCaller X @realDonaldTrump X @WashTimes X\n3 @zerohedge @BreitbartNews X @dcexaminer X @RT comX\n4 @DRUDGE REPORT @wikileaks X @DRUDGE REPORT @realDonaldTrump X\n5 @realDonaldTrump X @DRUDGE REPORT @nypost X @RT America X\n6 @mitchellvii X @seanhannity X @FoxNewsInsider X @WSJPolitics X\n7 deleted @WayneDupreeShow X @DailyMail X @DRUDGE REPORT\n8 @TruthFeedNews @LindaSuhler @AllenWest X @KellyannePolls X\n9 @RickRWells @mitchellvii X @RealJamesWoods X @TeamTrump X\n10 deleted @LouDobbs X @foxandfriends X @LouDobbs X\n11 @gatewaypundit X @PrisonPlanet X @foxnation X @rebeccaballhaus X\n12 @infowars @DonaldJTrumpJr X @LouDobbs X @WSJopinion X\n13 @Lagartija Nix @ger\ufb01ngerpoken @KellyannePolls X @reidepstein X\n14 @DonaldJTrumpJr X @FreeBeacon X @JudicialWatch X deleted\n15 @ThePatriot143 @ger\ufb01ngerpoken2 @PrisonPlanet X @JasonMillerinDC X\n16 @V ofEurope @TeamTrump X @wikileaks X @DanScavino X\n17 @KitDaniels1776 @Italians4Trump @TeamTrump X @PaulManafort X\n18 @Italians4Trump @benshapiro X @IngrahamAngle X @SopanDeb X\n19 @ Makada @KellyannePolls X @marklevinshow X @asamjulian\n20 @BigStick2013 @DanScavino X @LifeZette X @JudicialWatch X\n21 @conserv tribuneX deleted @theblaze X @Makada\n22 @Miami4Trump @JohnFromCranber @FoxBusiness X @mtracey X\n23 @MONAKatOILS @true pundit @foxnewspolitics X @Italians4Trump\n24 @JayS2629 @ThePatriot143 @BIZPACReview @Telegraph X\n25 @ARnews1936 @RealJack @DonaldJTrumpJr X @RealClearNews X\nrank center news left leaning news left news extreme bias (left) news\n(24 veri\ufb01ed, 0 deleted, (25 veri\ufb01ed, 0 deleted (21 veri\ufb01ed, 0 deleted, (7 veri\ufb01ed, 1 deleted,\n1 unveri\ufb01ed) 0 unveri\ufb01ed) 0 unveri\ufb01ed) 17 unveri\ufb01ed)\n1 @CNN X @nytimes X @HuffPost X @Bipartisanism X\n2 @thehill X @washingtonpost X @TIME X @PalmerReport X\n3 @politico X @ABC X @thedailybeast X @peterdaou X\n4 @CNNPolitics X @NBCNews X @RawStory X @crooksandliars X\n5 @Reuters X @SlateX @HuffPostPol X @BoldBlueWave\n6 @NateSilver538 X @PolitiFact X @NewYorker X @Shareblue X\n7 @AP X @CBSNews X @MotherJones X @Karoli\n8 @business X @voxdotcom X @TPM X @RealMuckmaker\n9 @USATODAY X @ABCPolitics X @Salon X @GinsburgJobs\n10 @AP Politics X @ezraklein X @thinkprogress X @AdamsFlaFan\n11 @FiveThirtyEight X @nytpolitics X @mmfa X @mcspocky\n12 @bpolitics X @guardian X @joshtpm X @Shakestweetz X\n13 @jaketapper X @NYDailyNews X @MSNBC X deleted\n14 @DRUDGE REPORT @latimes X @NYMag X @JSavoly\n15 @cnnbrk X @BuzzFeedNews X @samstein X @OccupyDemocrats\n16 @businessinsider X @Mediaite X @JuddLegum X @ZaibatsuNews\n17 @AC360 X @HillaryClinton X @mashable X @wvjoe911\n18 @cnni X @nytopinion X @theintercept X @DebraMessing X\n19 @brianstelter X @CillizzaCNN X @DavidCornDC X @SayNoToGOP\n20 @KellyannePolls X @MSNBC X @dailykos X @coton luver\n21 @wikileaks X @KFILE X @JoyAnnReid X @EJLandwehr\n22 @SopanDeb X @TheAtlantic X @nxthompson X @mch7576\n23 @KFILE X @SopanDeb X @thenation X @RV Awonk\n24 @BBCWorld X @Fahrenthold X @justinjm1 X @Carja\n25 @NewDay X @BuzzFeed X @ariannahuff X @Brasilmagic\nTable A.5: Top 25 CI news spreaders of the retweet networks corresponding to each media\ncategory in 2016 . Veri\ufb01ed users have a checkmark ( X) next to their username. Verifying its\naccounts is a feature offered by Twitter, that \u201clets people know that an account of public interest\nis authentic\u201d. Unveri\ufb01ed accounts do not have a checkmark and accounts marked as deleted have\nbeen deleted, either by Twitter or by the users themselves. Reproduced from [18].\n187\nrank fake news extreme bias (right) news right news right leaning news\n(10 veri\ufb01ed, 8 deleted, (23 veri\ufb01ed, 2 deleted, (23 veri\ufb01ed, 1 deleted, (23 veri\ufb01ed, 2 deleted\n7 unveri\ufb01ed) 0 unveri\ufb01ed) 1 unveri\ufb01ed) 0 unveri\ufb01ed)\n1 @seanhannity X (12) @DonaldJTrumpJr X (25) @DonaldJTrumpJr X @nypost X\n2 deleted (3) @BreitbartNews X (19) @marklevinshow X (1) @WSJ X\n3 @DavidJHarrisJr @dbongino X @jsolomonReports @DonaldJTrumpJr X\n4 @JudicialWatch X @marklevinshow X (9) @RealJamesWoods X @EricTrump X\n5 @WayneDupreeShow X (1) @realDonaldTrump (1) @FoxNews X (4) @realDonaldTrump\n6 @catturd2 @newsmax X @SaraCarterDC X (2) @WashTimes X\n7 @TomFitton X @DailyMail X @DailyCaller X @marklevinshow X\n8 @OANN X @RaheemKassam X @MZHemingway X @brithume X\n9 @dbongino X @RealJamesWoods X @TrumpWarRoom X @RealJamesWoods X\n10 @Thomas1774Paine @joelpollak X (3) @dcexaminer X @KimStrassel X\n11 @RealMattCouch @JackPosobiec X @JackPosobiec X @newtgingrich X\n12 deleted @TomFitton X @seanmdav X @TrumpWarRoom X\n13 (3) @zerohedge @TrumpWarRoom X @realDailyWire X deleted\n14 @Rasmussen PollX @RCamposDuffy X @GOPChairwoman X @MichaelCBender X\n15 @atensnut @EricTrump X (2) @realDonaldTrump @RandPaul X\n16 (1) @PrisonPlanet X @JasonMillerinDC X @GreggJarrett X (15) @JasonMillerinDC X\n17 @CassandraRules X (14) @FreeBeacon X @newtgingrich X @JackPosobiec X\n18 deleted @AlexMarlow X @kayleighmcenany X @BillKristol X\n19 @DineshDSouza X @bennyjohnson X @RepDougCollins X @AriFleischer X\n20 (5) @realDonaldTrump @FrankelJeremy X @RichardGrenell X @Rasmussen PollX\n21 @HowleyReporter deleted @AndrewCMcCarthy X @IngrahamAngle X\n22 deleted @SteveGuest X @SteveGuest X @RudyGiuliani X\n23 deleted @BrentScher X @SecretsBedard X @MZHemingway X\n24 deleted @IngrahamAngle X @parscale X @Forbes X\n25 deleted @kimguilfoyle X @dbongino X (11) @rebeccaballhaus X\nrank center news left leaning news left news extreme bias (left) news\n(24 veri\ufb01ed, 0 deleted, (24 veri\ufb01ed, 0 deleted (23 veri\ufb01ed, 0 deleted, (3 veri\ufb01ed, 1 deleted,\n1 unveri\ufb01ed) 1 unveri\ufb01ed) 2 unveri\ufb01ed) 21 unveri\ufb01ed)\n1 (2) @thehill X @CNNX (13) @MSNBC X @DearAuntCrabby\n2 (7) @AP X (1) @nytimes X (3) @thedailybeast X @funder X\n3 (5) @Reuters X @kylegrif\ufb01n1 X @kylegrif\ufb01n1 X @ImpeachmentHour\n4 @kylegrif\ufb01n1 X (3) @ABC X (19) @DavidCornDC X @MeidasTouch\n5 @JonLemire X (2) @washingtonpost X (1) @HuffPost X @TheDemCoalition X\n6 @Newsweek X @CNNPolitics X @NoahShachtman X @grantstern X\n7 @yarotrof X @NPRX (4) @RawStory X (15) @OccupyDemocrats\n8 (9) @USATODAY X (4) @NBCNews X (7) @MotherJones X @Stop Trump20\n9 @ProjectLincoln (7) @CBSNews X @TeaPainUSA @InSpiteOfTrump\n10 @JoeBiden X @politico X @svdate X @froggneal\n11 @TheDemCoalition X @ddale8 X @voxdotcom X @atav1k\n12 @TheEconomist X @CREWcrew X @maddow X @diamondlilron\n13 (10) @AP PoliticsX @cnnbrk X @joncoopertweets X @HollyHuntley3\n14 @TheRickWilson X @maddow X @SlateX deleted\n15 @tribelaw X @jaketapper X @PoliticusSarah X @patrickinmass\n16 @SkyNews X @ThePlumLineGS X @tribelaw X @Franpianos\n17 @maddow X @NatashaBertrand X @JoeBiden X @willapercy\n18 @FinancialTimes X @tribelaw X @TheRickWilson X @Jerrygence\n19 @joncoopertweets X @axiosX @realTuckFrumper @bethlevin\n20 @FrankFigliuzzi1 X (18) @nytopinion X @VanityFair X @nyx with\n21 @JimLaPorta X @maggieNYT X @CREWcrew X @vg123e\n22 @DonaldJTrumpJr X (14) @latimes X (6) @NewYorker X @watercutter11\n23 (24) @BBCWorld X @ProjectLincoln @PalmerReport X @404HDTV\n24 @APFactCheck X @60Minutes X @11thHour X @jstarace\n25 @KamalaHarris X @business X (5) @HuffPostPol X @amberofmanyhats\nTable A.6: Top 25 CI news spreaders of the retweet networks corresponding to each media\ncategory in 2020 . Veri\ufb01ed users have a checkmark ( X) next to their username. Unveri\ufb01ed accounts\ndo not have a checkmark and accounts marked as deleted have been deleted, either by Twitter or\nby the users themselves. If a user held a position in the top 25 in 2016 as well, we mark that\nposition for reference in parentheses next to the username. Despite @realDonaldTrump having\ntheir account permanently suspended, due to the role they played in the 2020 Election, we have\nchosen to keep their original Twitter username in the table. However, we count this account as\ndeleted, and have removed their previously assigned checkmark.\n188\nYear Modularity (SE) Normalized Cut (SE) Right Ratio Left Ratio\n2016 0.234 (0.004) 0.66 (0.03) 0.038 0.05\n2020 0.236 (0.007) 0.58 (0.03) 0.038 0.08\nTable A.7: Tabulated analysis of the similarity network using quotes instead of retweets for the\ntop in\ufb02uencers (as determined by the CI rankings of the retweet networks). The similarity network\nis found for the 2016 and 2020 data. Using Louvain community detection reveals two commu-\nnities with left- and center-oriented in\ufb02uencers in one community, and right- and fake-oriented\nin\ufb02uencers in the other. Left side of table: average modularity and average normalized cut, with\nthe standard errors (SE) in parentheses, determined by taking sub-samples of in\ufb02uencers from the\nquote similarity network, detecting the two dichotomous communities with the sub-sampled quote\nsimilarity network, then recording their modularities and normalized cuts. Right side of table: ratio\nof quotes-to-retweets within the complete similarity network. Speci\ufb01cally, number of user quotes\nof in\ufb02uencer tweets over number of user retweets of in\ufb02uencer tweets. Right ratio indicates the\naverage ratio for the community with right-oriented in\ufb02uencers. Left ratio indicates the average\nratio for the community with left-oriented in\ufb02uencers. These ratios are found for both 2016 and\n2020.\nAoverall quotes/retweets\n2016 2020\nfrom usersright 0.03 0.03\nleft 0.05 0.04\nBquotes/retweets\n2016 2020\nto in\ufb02uencers\nright left right left\nfrom usersright 0.02 0.19 0.02 0.49\nleft 0.56 0.03 3.76 0.03\nTable A.8: Comparison of fraction of retweets and quotes from users to in\ufb02uencers with differ-\nent latent ideology estimates. Users and in\ufb02uencers are divided in two categories based on their\nideology estimates, namely left (ideology <0) and right (ideology >0). Table Ashows the overall\nproportion of quotes over retweets from users on the right and on the left revealing that the number\nof quotes represent only a small fraction ( \u00145%) of the number of retweets. Table Bshows the\nproportion of quotes over retweets from users to in\ufb02uencers for all pairs of ideology categories in\n2016 and in 2020.\n189\nusers distributions in\ufb02uencers distributions\n2016 95% CI 2020 95% CI difference 2016 95% CI 2020 95% CI difference\nall 0.1086 [0.1082,0.1091] 0.1474 [0.1471,0.1477] 0.0388 0.1786 [0.1606,0.1965] 0.2091 [0.1907,0.2282 0.0305\ncommon users 0.0941 [0.0934,0.0947] 0.1172 [0.1166,0.1178] 0.0231 0.1793 [0.1616,0.1979] 0.2143 [0.1952,0.2336] 0.0350\ncommon in\ufb02uencers 0.1070 [0.1065,0.1076] 0.1830 [0.1825,0.1834] 0.0760 0.1641 [0.1290,0.1951] 0.1741 [0.1376,0.2122] 0.0100\ncommon users\nand in\ufb02uencers0.0947 [0.0940,0.0955] 0.1399 [0.1390,0.1406] 0.0452 0.1650 [0.1314,0.2034] 0.1719 [0.1379,0.2086] 0.0069\nTable A.9: Hartigans\u2019 dip test statistics of the users and in\ufb02uencers latent ideology distributions\nwhen considering all users and in\ufb02uencers, only users that were present in 2016 and 2020, only\nin\ufb02uencers that were present in 2016 and 2020 and only users and in\ufb02uencers that were present\nin 2016 and 2020. 95% con\ufb01dence intervals are computed from 1000 bootstrap samples with the\nbias-corrected and accelerated con\ufb01dence intervals method.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Opinion Mining and Clusters Detection in Online Public Debates: a Quantitative Analysis", "author": ["A Galeazzi"], "pub_year": "2022", "venue": "NA", "abstract": "The advent of online platforms dramatically changed the way people create and communicate  content. In online social media, users can easily share information that thousands of peers"}, "filled": false, "gsrank": 646, "pub_url": "https://iris.unibs.it/handle/11379/555016", "author_id": ["DK0tXAIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:cWkx6ygIes8J:scholar.google.com/&output=cite&scirp=645&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D640%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=cWkx6ygIes8J&ei=erWsaPG6EvnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:cWkx6ygIes8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://iris.unibs.it/bitstream/11379/555016/2/phd_thesis_galeazzi_pdfa.pdf"}}, {"title": "Bad news: Clickbait and deceptive ads on news and misinformation websites", "year": "2020", "pdf_data": "This paper appears at the Workshop on Technology and Consumer Protection (ConPro \u201920).\nBad News: Clickbait and Deceptive Ads on News\nand Misinformation Websites\nEric Zeng, Tadayoshi Kohno, Franziska Roesner\nPaul G. Allen School of Computer Science & Engineering\nUniversity of Washington\nAbstract \u2014A key aspect of online ads that has not been\nsystematically studied by the computer security community is\ntheir visible, user-facing content. Motivated by anecdotal evidence\nof problematic content such as clickbait, misinformation, scams,\nand malware, particularly in native advertising, we conducted\na systematic measurement study of ad content on mainstream\nnews sites and known misinformation sites. We provide evidence\nfor signi\ufb01cant numbers of problematic ads on popular news\nand misinformation sites, primarily served through native ad\nplatforms. This work begins a rich, systematic line of inquiry\ninto problematic ad content, ultimately to inform technical and/or\nregulatory solutions.\nI. I NTRODUCTION\nOnline advertisements are an unavoidable fact of the mod-\nern web \u2014 they are embedded in and \ufb01nancially support the\nmajority of content websites. Signi\ufb01cant prior work in the\ncomputer security and privacy community has studied the\necosystem of online advertising, particularly in terms of its\nprivacy implications (e.g., [6, 16, 19, 37\u201339, 48, 56, 65, 66])\nor the use of ads to spread malware (e.g., [40, 55, 69, 70]).\nWhat has not been substantively considered in the security\ncommunity, however, is the visible, user-facing content of\nthese advertisements (except to the extent it relates to privacy,\ne.g., people \ufb01nding highly personalized ad content or ad\ntargeting explanations \u201ccreepy\u201d [17, 64]).\nMeanwhile, there is signi\ufb01cant anecdotal evidence that the\ncontent of online advertisements can be deeply problem-\natic [33, 41, 46, 47, 57, 62, 63] \u2014 consider the examples\nin Figure 1, a row of low-quality ads colloquially called a\n\u201cchumbox\u201d. These concerns have been voiced particularly\nabout native advertising , that is, ads that appear to be \ufb01rst-\nparty content on the hosting website (such as inline search\nresults or recommended articles) but are actually paid for by\nan advertiser. Concerns about native ads include the fact that\nthey are deceptive: users are not reliably able to identify them\nas ads [3, 20, 30, 67, 68] and may click on them thinking\nthat they are reading another story on a news site. Anec-\ndotally, native ads also commonly use \u201cclickbait\u201d techniques\nor other \u201cdark patterns\u201d, e.g., curiosity-provoking headlines\nor shocking imagery to attract attention and entice users to\nclick. Further, these ads seem to often lead to low-quality\ncontent, misinformation, or even outright scams (e.g., cure-\nall supplements) and malware.\nDespite these issues \u2014 or perhaps because of them \u2014 native\nads are appealing to ad networks and hosting websites, as they\nFig. 1. Portion of a \u201cchumbox\u201d native ad banner, showing four ads that\nuse \u201cclickbait\u201d techniques to entice clicks (such as distasteful imagery,\nsensationalism, provoking curiosity, and urgency). Such ads often lead to low-\nquality sites, misinformation, or outright scams.\nhave the potential to generate a signi\ufb01cant amount of revenue.\nPrior work has shown, and native ad platforms themselves\nclaim that they generate signi\ufb01cantly higher clickthrough rates\n(0.2% vs. 0.05%) than traditional \u201cdisplay ads\u201d [5, 36, 59].\nAs a result, online news and media publications, which have\nrecently struggled to raise revenue [23, 28], frequently host\nnative advertising on their properties.\nDespite these many growing concerns about problematic\ncontent and dark patterns in online advertising, there has been\nlimited systematic, scienti\ufb01c study of this phenomenon. We\nargue that these issues should be a concern of the computer\nsecurity and privacy community, alongside the now well-\nunderstood privacy concerns regarding how those ads are tar-\ngeted. First, these ads use misleading, deceptive, and in some\ncases illegal practices \u2014 impacting users \ufb01nancially, wasting\ntheir time and attention, and spreading scams, misinformation,\nand malware. At the same time, not all problematic ads\nare equally harmful: we must understand the spectrum of\nproblematic ad content practices, their prevalence, and their\nimpacts. Second, the locations where these ads appear can\ncompound their harms: for example, on mainstream news and\nmedia websites, deceptive native ads may bene\ufb01t from the\ntrust that users have in the hosting website. Moreover, there\nis growing evidence that online ads are used to \ufb01nancially\nsupport news and media websites that spread disinformation\n(e.g., [2, 12, 14, 21, 22, 33, 50]). To fully understand the\npotentially harmful impacts, we must understand where these\nads appear on the web and how they are targeted at individual\nconsumers. The security and privacy community has the right\ntools (e.g., web crawlers, ad and tracker detectors), experience,\nand mindset to conduct a systematic study of this ecosystem.\nIn this work, we lay the foundation for such a systematic\nstudy of problematic ad content. We present the results from an\ninitial measurement study of ad content on news, media, and\nknown misinformation websites, and we surface hypotheses\nand directions for future work in the security and privacy\ncommunity. Speci\ufb01cally, we focus on the following research\nquestions:\n1) How prevalent are different types of problematic ad\ncontent on the modern web?\n2) How does the prevalence of problematic ad content\ndiffer across different types of ads (native vs. display),\ndifferent ad platforms, and different types of websites\n(news/media vs. known misinformation)?\nWe performed a mixed-methods measurement study, using\nquantitative and qualitative techniques to explore ad content\non popular news/media and known misinformation1sites in\nJanuary 2020. Among other \ufb01ndings, we present empirical\nevidence that native ads use problematic techniques signi\ufb01-\ncantly more often than traditional display ads. We also \ufb01nd\nthat both popular news sites and misinformation sites both\nrun a signi\ufb01cant amount of problematic ads, but that this\nphenomenon is not evenly distributed \u2014 that is, some sites\nchoose to run problematic ads while others do not. Comparing\nad platforms, we \ufb01nd that Taboola is responsible for serving\nthe majority of problematic ads in our dataset, that Google\nalso serves a signi\ufb01cant number of problematic ads (though\nthese represent a small percentage of their ads overall), and\nthat there are certain (smaller) native ad platforms that appear\nmore frequently on misinformation sites.\nOur results and systematic measurement methodology lay a\nfoundation for future work to further understand this ecosys-\ntem \u2014 e.g., studying the concrete impacts of problematic ads\non users, or the ways that these ads may be targeted at\nmore susceptible populations \u2014 in order to ultimately inform\ntechnical and/or regulatory solutions.\nII. R ELATED WORK\nOur work falls within a tradition of studying the security\nand privacy implications of the online advertising ecosystem.\nThese prior works focused primarily on the privacy-invasive\nmechanisms of targeted advertising (e.g., [6, 16, 17, 19, 37\u2013\n39, 48, 56, 64\u201366]) and on malicious advertisements that\nspread malware or perpetrate clickfraud or phishing attacks\n(e.g., [40, 55, 69, 70]). We argue that the visible content of\nonline ads \u2014 particularly deceptive or manipulative content \u2014\nmust also be systematically studied via scienti\ufb01c web mea-\nsurement methodologies.\nWe note that one piece of this picture has been rigor-\nously studied: network traces leading to software engineering\ndownload attacks revealed that a large fraction were reached\nvia deceptive online ads [46]. Our view here is broader,\nconsidering a spectrum of problematic content ranging from\ntime-wasting clickbait to outright scams and download attacks.\n1Information that is deliberately false is often called \u201cdisinformation\u201d,\nwhile unintentionally incorrect information is called \u201cmisinformation\u201d [31].\nFor simplicity, we default to the term misinformation , as we do not always\nknow \u2014 and do not aim to clarify \u2014 the underlying intent of the creator.In addition to studies of deception in native advertising\nand anecdotal evidence of problematic ad content discussed\nin Section I, our work is also thematically related to broader\ndiscussions of \u201cdark patterns\u201d [8] on the web and in mobile\napps (e.g., [7, 27, 49]). Most closely related is recent work\nsystematically studying af\ufb01liate marketing on YouTube and\nPinterest [43, 60] and dark patterns on shopping websites [42],\nthough neither considered web ads.\nFinally, our work adds to a growing, multi-disciplinary\nliterature studying online mis/disinformation. Most related to\nour investigation, evidence is emerging (mostly anecdotally)\nthat online advertising plays a role in \ufb01nancially supporting\nmis/disinformation (e.g., [14, 21, 22, 33, 50]) or directly\nspreading it (e.g., [34]). In this work, we begin systematically\nexploring one aspect of this relationship, considering the\ncontent of the ads that appear on known misinformation sites.\nIII. M ETHODOLOGY\nWe designed a rigorous methodology to allow us to study\nthe prevalence of different types of problematic ad content. At\na high level, our methodology involved crawling websites of\ninterest, scraping the ads from these sites, and performing a\nsystematic manual qualitative analysis of ad and landing page\ncontent for selected samples of ads.\nA. Input Datasets\nMainstream News and Media Sites. We collected a dataset of\n6714 news and media sites from the Alexa Web Information\nService API [4], which categorizes websites in the Alexa top\n1 million by topic. We scraped all domains in the \u201cNews\u201d\ncategory, and all domains in subcategories in other top-level\ncategories that ended in \u201cNews and Media\u201d or \u201cMagazines and\nE-Zines\u201d. We excluded known misinformation sites.\nMisinformation Sites. We compiled a dataset of 1158 known\nmisinformation websites (spreading political disinformation,\nhoaxes, conspiracies, and other misleading and false content)\nbased on a combination of existing sources [1, 18, 29, 35, 44,\n51, 52, 54]. These lists are surely incomplete, but allow us to\nstudy ads on known misinformation sites.\nB. Crawling Infrastructure\nWe built a web crawler using Puppeteer [26], a browser\nautomation and instrumentation library for the Chromium\nbrowser. Our crawler takes a URL as input, visits the URL,\nidenti\ufb01es each ad on the page using the EasyList \ufb01lter list\nfor Adblock Plus [15], a popular list of CSS selectors and\ndomains used by many ad blockers to detect ads and trackers.\nThe crawler screenshots each ad, stores its HTML content,\nand then clicks on each ad, and screenshots and scrapes the\nlanding page.\nBecause ads that appear on a site\u2019s homepage may differ\nfrom those on article pages (e.g., some sites show native ads\nonly at the bottom of articles), we crawled both the homepage\nand one article page for each site in our dataset. We found the\nURLs for articles using three heuristics: extracting the RSS\nfeed from the site\u2019s HTML metadata, guessing the RSS feed\nby appending \u201c/feed\u201d or \u201c/rss\u201d to the domain, and randomly\nclicking links on the homepage and using Firefox\u2019s Readability\nlibrary [45] (which transforms web articles into a simpler\nformat) as an article-detection heuristic.\nClicking on ads raises ethical questions, since advertisers\npay per click. We note that prior works have used similar\nmethodologies [55, 69] and that even loading ads can lead to\n(smaller) costs (per impression). We believe that our measure-\nments were small-scale compared to the overall business of the\ncompanies potentially impacted, and that fully studying this ad\necosystem, including landing pages, is crucial to understanding\nand reducing problematic content online.\nIdentifying Ad Platforms. In addition to studying the content of\nthe ads, we are also interested in the ad platforms responsible\nfor delivering ads. The process for serving an individual ad is\ncomplex: often many companies are involved in taking an ad\nfrom an advertiser to a publisher, via supply side providers,\nad exchanges, demand side providers, and ad servers. For the\npurposes of this study, we attempt to identify the third-party\nplatform used directly by publishers to allow ads to run on\ntheir websites, such as Google Ad Manager. These platforms\nusually appear as a Javascript \ufb01le or iframe embedded in the\npublisher\u2019s website (i.e., the host website).\nTo identify these publisher-side ad platforms, we use two\ncomplementary approaches. First, we detected well-known\nplatforms like Google Ad Manager, Taboola, and Outbrain\nusing CSS selectors that match HTML classes that we de-\ntermined to be associated with the platform, based on manual\ninspection. For native ads that contain multiple ads in a single\narea, we also built selectors to split each individual ad into\na separate record in our database. Second, for each DOM\nsubtree we detected as an ad, we recorded each third-party\nresource in the subtree (iframes, anchors, images, and scripts),\nas well as any modi\ufb01cations made to the subtree via third-\nparty Javascript elsewhere in the document. Post-crawl, we\nmanually identi\ufb01ed the publisher-side ad platform or other\nentity (e.g., ad exchange or third-party image host) behind\nthe 100 most popular third-party resources \u2014 we did this by\nexamining the resources and reading promotional materials\nor documentation at the domain of the resources. Lastly, we\nlabeled the ad platforms we identi\ufb01ed in both approaches as\neither native ad platforms or display ad platforms, based on\nhow they describe their own product on their websites.\nStudying Site-Based, Not Pro\ufb01le-Based, Targeting. To enable\ncomparisons between ads that appear on different types of\nsites, we wanted to maximize the chance that if we see a\nproblematic ad, it was served based on the site we were\nvisiting, not on the fact that our crawler has visited many\nmisinformation sites in the past.\nWe thus visit each site using a separate browser instance in\na new Docker container (i.e., containing no tracking cookies\nor other persistent browser state), to approximate a new user\nwithout a tracking pro\ufb01le. However, we must assume that\nthe ad ecosystem may nevertheless successfully track our\ncrawler, even across Docker instances, using \ufb01ngerprinting, IPtargeting, and other techniques [16, 48]. Embracing this reality,\nwe thus \u201cwarm\u201d the pro\ufb01le of our crawler by visiting all the\nsites in our input datasets twice, in random order, collecting\ndata only on the second run (still using new containers for each\nsite in each run). In other words, we ensure that the crawler\u2019s\nbrowsing pro\ufb01le looks consistent throughout the measurement\nto any ad networks able to \ufb01ngerprint our crawler.\nCrawls. We created our dataset during January 15-19, 2020,\nsuccessully crawling 6498 mainstream news sites (plus 5831\narticles) and 1055 misinformation sites (plus 863 articles).\nAcross these pages, we detected 81,870 ads, 55,045 of which\nwere visible HTML elements.\nC. Qualitative Analysis\nFinally, we qualitatively analyzed and labeled the ads we\nobserved on a subset of the websites we crawled. We generated\na codebook to describe different types of problematic ads\nwe observed in a preliminary analysis of the dataset, with\neach code describing a set of ads with similar advertisers,\nproducts, and advertising tactics. Our codes ranged from ads\nfor things that could cause material harm, such as potentially\nmisleading ads for supplements and investment pitches, to\nads that people \ufb01nd irritating, such as ads for celebrity news\ncontent farms. The codebook was informed by prior academic\nresearch, regulations, and journalism on deceptive advertising,\nclickbait, malvertising, and advertising industry practices [20,\n33, 41, 46, 47, 57, 62, 63]. The full codebook with de\ufb01nitions\nis included in the Appendix, and these categories are also listed\nin each table in our results.\nBecause we crawled 55,045 ads in total, we could only\nmanually analyze a subsample of our dataset. For this pre-\nliminary work, we coded three different samples of websites,\nfocusing on sites that users visit most: (1) 100 of the most\npopular news sites and their articles, (2) 100 of the most\npopular misinformation sites and their articles, and (3) 100\nnews sites (and articles) that have a similar popularity to\nthe misinformation set. For the \ufb01rst and second samples,\nwe discarded sites that our crawler could not reach and\nsupplemented them with additional sites from the ranked lists\nuntil our sample size was 100 for each. The third sample\nallows us to control for the effect of site popularity on the\ntypes of ads that appear.\nFor each site in the samples, we coded each ad that appeared\non the home page and article page, using a single code per\nad. In total, we coded 2058, 1308, and 2048 ads from the top\n100 news sites, top 100 misinformation sites, and 100 similar\npopularity news sites respectively, for a total of 5414 ads.\nD. Limitations\nOur dataset contains a signi\ufb01cant number ads of that could\nnot be analyzed, because they were not initialized and were not\nrendered, or because of being occluded by other site content.\nOur crawler was unable to take screenshots of approximately\none-third of ads detected using Easylist, because they were\nuninitialized and had zero height and/or width. Of the 5413\nads in our manually labeled sample, 1813 had no screenshot\nTABLE I\nDisplay Ad Platforms Native Ad Platforms\nCode Total Amazon Concert Google TownNews Subtotal Outbrain PowerInbox RevContent Taboola Zergnet Subtotal Unknown\nContent Farms 283 0 0 13 0 13 0 0 1 178 87 266 4\nInsurance Advertorials 96 0 0 21 0 21 0 0 15 59 0 74 1\nInvestment Pitches 43 0 0 10 0 10 0 2 6 24 0 32 1\nMisleading Political Poll 14 0 0 10 0 10 0 0 0 0 0 4\nMortgage Advertorials 29 0 0 4 0 4 0 0 4 21 0 25 0\nPotentially Unwanted Software 8 0 0 7 0 7 0 0 0 1 0 1 0\nProduct Advertorials 103 0 0 8 0 8 0 0 2 92 0 94 1\nSponsored Editorials 50 0 0 29 0 29 0 0 0 9 0 9 12\nSponsored Search 196 0 0 17 0 17 0 0 0 177 0 177 2\nSupplements 256 0 0 106 0 106 0 2 38 98 0 138 12\nProblematic Ads Subtotal 1078 0 0 225 0 225 0 4 66 659 87 816 37\nCharities and PSAs 17 0 0 17 0 17 0 0 0 0 0 0 0\nPolitical Campaign 28 0 0 12 0 12 0 0 0 0 0 0 16\nProducts and Services 1214 0 8 1050 1 1059 1 2 0 93 0 96 59\nSelf-Link 82 0 8 28 1 37 5 0 4 17 0 26 19\nBenign Ads Subtotal 1341 0 16 1107 2 1125 6 2 4 110 0 122 94\nTotal Coded 2419 0 16 1332 2 1350 6 6 70 769 87 938 137\nOccluded/Uninitialized Ads 2995 1 16 1666 7 1690 292 0 16 72 45 425 876\nGrand Total 5414 1 32 2998 9 3040 298 6 86 841 132 1363 1013\nRaw counts of coded ads across ad platforms, from the samples of misinformation, top news, and similar popularity news sites. Subtotals for native ad\nplatforms and display ad platforms are listed inline. The percentage of a particular ad code contributed by a platform can be calculated by dividing the cell\nby the row-wise total (e.g., 55% of ads for investment pitches were served by Taboola, or 24/43). The percentage of ads within a platform of a speci\ufb01c code\ncan be calculated by dividing the cell by the column-wise total (e.g., 8% of Google Ads were labeled as \u201cSupplements\u201d, or 106/1332).\n(33.5%), and 1182 (21.8%) were occluded or otherwise did not\ncontain meaningful content. While the percentage of occluded\nand uninitialized ads were similar across our three samples of\ncoded ads (40-47%), we observed that a substantially larger\nnumber of display ads, primarily from Google, were not\nrendered compared to native ads (56% vs. 31%).\nTo sanity check the quality of the data we collected via\nour crawler, we ran the ad detection algorithm described\nabove in a standard desktop browser on 10 randomly sampled\nnews and misinformation sites, and found 55.2% of ads were\nuninitialized, occluded, or otherwise false positives, compared\nto 58.3% on the same sites in our crawled dataset, suggesting\nthat our crawled data is similar to what users actually see.\nWe suggest several reasons why some ads were not loaded\nor visible: (1) the elements were false positives in the ad\nblocker\u2019s detection algorithm, (2) the Docker environment and\nvirtual frame buffer interfered with the browser\u2019s rendering,\n(3) content on the website, such as sign-up interstitials or\ncookie banners, occluded the ad content, and (4) the ad\nplatform chose not to \ufb01ll the ad space, e.g., due to detecting\nour visits as anomalous, low demand for ads, or high latency\nduring real-time bidding. In drawing our conclusions, we\nassume that the distribution of problematic content among the\nads that did not load because of the crawling environment is\nsimilar to that among the ads that did. Future work must vali-\ndate this assumption and address this measurement challenge.\nAdditionally, our method for identifying ad platforms was\nnot comprehensive (we did not identify ad platforms for 20.7%\nof the ads crawled), nor does it perfectly describe the entity\n\u201cresponsible\u201d for working with problematic advertisers. For\nexample, sites might con\ufb01gure Google Ad Manager to allow\nads from a third-party ad exchange, where many third-party\nsupply-side providers may bid on the site\u2019s ad inventory. Nev-\nertheless, we chose to investigate the ad platforms used directlyby publishers, as these platforms often have content policies\nin place against malicious and harmful content [24, 25, 61].\nIV. R ESULTS\nA. Which ad platforms show problematic ads?\nWe \ufb01rst investigate whether native ad platforms are the\nprimary culprit for problematic content in ads on news and\nmisinformation sites. Table I shows the count of each ad\ncontent code across allof our samples, comparing their\nprevalence across native and traditional display ad platforms.\nBased on the subtotals for all native ad platforms and dis-\nplay ad platforms, we highlight several high-level conclusions.\nFirst, a signi\ufb01cant fraction of all coded ads contain some kind\nof problematic content: of the 2419 ads we coded, 1078 of\n(44.6%) them were labeled as problematic. Second, native\nads are indeed primarily responsible for these issues: 87%\nof native ads (that loaded during the crawl) were labeled as\nproblematic, compared to 20% of display ads. Third, however,\ndisplay ads do also include non-trivial numbers of problematic\nads (particularly for supplements) \u2014 thus, conversations about\nad content should not focus exclusively on native ads.\nNext, we analyze the prevalence of problematic ads on\nspeci\ufb01c ad platforms, from two perspectives. First, which ad\nplatforms serve the largest absolute number of problematic\nads, contributing most to what users see? Second, which ad\nproviders serve disproportionately many problematic ads, as a\nfraction of all ads they serve?\nWe observe that Taboola served the largest number of\nproblematic ads in our samples (61.1% of all problematic ads),\nand that proportionally, most of the ads served by Taboola\nwere problematic (85.7%). Taboola also served a large diver-\nsity of problematic ads: we saw examples for all categories\nin our codebook except for misleading political polls. By\ncontrast, other native ad platforms with signi\ufb01cant numbers\nTABLE II\nTop 100 News Top 100 Misinfo 100 Popularity Adjusted News\nHomepage Article Homepage Article Homepage Article\nCode n % n % n % n % n % n %\nContent Farms 46 12.5% 66 12.1% 3 1.5% 62 15.4% 37 9.4% 69 13.7%\nInsurance Advertorials 18 4.9% 21 3.9% 6 2.9% 20 5.0% 5 1.3% 26 5.2%\nInvestment Pitches 9 2.4% 10 1.8% 5 2.4% 10 2.5% 2 0.5% 7 1.4%\nMortgage Advertorials 0 0.0% 13 2.4% 0 0.0% 5 1.2% 1 0.3% 10 2.0%\nMisleading Political Polls 1 0.3% 1 0.2% 5 2.4% 7 1.7% 0 0.0% 0 0.0%\nPotentially Unwanted Software 0 0.0% 1 0.2% 3 1.5% 2 0.5% 0 0.0% 2 0.4%\nProduct Advertorials 12 3.3% 33 6.1% 0 0.0% 16 4.0% 8 2.0% 34 6.7%\nSponsored Editorials 14 3.8% 11 2.0% 1 0.5% 0 0.0% 14 3.6% 10 2.0%\nSponsored Search 39 10.6% 56 10.3% 6 2.9% 41 10.2% 20 5.1% 34 6.7%\nSupplements 22 6.0% 72 13.2% 35 17.1% 73 18.2% 11 2.8% 43 8.5%\nProblematic Ads Subtotal 161 43.6% 284 52.1% 64 31.2% 236 58.7% 98 24.9% 235 46.6%\nCharities and PSAs 7 2.0% 0 0.0% 3 1.5% 1 0.3% 4 1.1% 2 0.4%\nPolitical Campaigns 0 0.0% 3 0.6% 10 5.0% 13 3.3% 1 0.3% 1 0.2%\nProducts and Services 179 51.6% 240 45.5% 124 61.7% 143 36.4% 273 69.1% 255 51.7%\nSelf Links 22 6.0% 18 3.3% 4 2.0% 9 2.2% 18 4.6% 11 2.2%\nBenign Ads Subtotal 208 56.4% 261 47.9% 141 68.8% 166 41.3% 296 75.1% 269 53.4%\nTotal # of Ads Coded 369 545 205 402 394 504\nOccluded/Uninitialized Ads 466 678 255 446 594 556\nCounts of ads we labeled across our samples of news and misinformation sites. Percentages are computed columnwise (with the total number of coded ads\nas the denominator). We do not see evidence for substantial differences in the prevalence of problematic ad content across these samples.\nof ads in our samples served a more concentrated selection of\nproblematic ad types: 100% of the ads on the Zergnet network\nwere for content farm-style articles and slideshows, and 57.6%\nof all RevContent ads advertised some sort of supplement.\nGoogle was the most popular ad platform in our sample,\nmaking up nearly the entirety of the display ads that we coded.\nWhile most ads served through Google were benign ads for\nvarious products and services, 16.9% of Google-served ads\nwere problematic, accounting for 20.8% of problematic ads\nin our samples. While Google\u2019s platform does not serve as\nmany problematic ads proportionally, due to its large volume\nof ads in general, we note that the number of problematic ads\nit serves is substantial, second only to Taboola.\nThese results suggest that while the advertising ecosystem is\nlarge and complex, a large proportion of problematic content\n\ufb02ows through large platforms popular with publishers, like\nGoogle Ads and Taboola. Efforts to eliminate problematic ads\ncould start by focusing on regulating or improving ad content\nmoderation on these platforms.\nB. Are problematic ads more frequent on misinfo. sites?\nWe next consider whether problematic ads appear dispro-\nportionately more often on misinformation sites, compared to\nlegitimate news/media sites. We initially hypothesized that we\nwould see such a difference, because news sites might choose\nto include higher quality ads, and/or because the ad targeting\necosystem might be more likely to serve problematic ads to\nmisinformation sites. Table II investigates this relationship,\nbreaking down labeled ads between the three samples of\nwebsites, considering both homepages and article pages.\nWe draw several conclusions. First, although we see some\ndifferences, the numbers are small \u2014 overall, we do notsee\nevidence for signi\ufb01cant differences between the types of sites.TABLE III\nMainstream News Misinformation\nAvg. # of Ads/Page Homepage Article Homepage Article\nAll Ads 5.80 6.37 2.37 5.16\nDisplay Ads 5.57 5.22 1.78 2.79\nNative Ads 0.23 1.15 0.59 2.37\nAll Coded Ads 8.27 12.35 4.90 8.88\nCoded Display Ads 6.89 9.05 4.53 6.58\nCodes Native Ads 1.38 3.30 0.37 1.38\nAverage number of ads per page. Top: Ads on allcrawled pages. Bottom:\nManually labeled ads. While mainstream news sites tend to have more ads on\nthe homepage, misinformation sites run more native ads. (Note that the native\nad fraction is an underestimate, since uncommon, unknown ad providers are\nconsidered display ads here.)\nIn other words, it does not appear that visitors to popular\nmisinformation sites are signi\ufb01cantly more likely to encounter\nproblematic ads. Second, in all samples, problematic ads\nappear more on articles than homepages. This may be because\nsome sites \u201chide\u201d problematic ads beyond the homepage.\nWithout automated classi\ufb01cation of problematic ads, we\ncannot consider the prevalence of these issues below the top-\nranked websites that we studied manually. However, recall that\nour measurement infrastructure automatically identi\ufb01es a set\nof popular ad providers associated with ads. Based on this\nmetadata, which is available even for ads that did not load\nproperly, we can estimate the proportion of native ads in our\nwhole crawled dataset, i.e., thousands of sites.\nTable III shows the average number of native and display\nads per page, for sites in our full dataset. On average, we\nsee that news sites run more ads than misinformation sites\non their homepages, but both run similar numbers of ads on\ntheir articles. However, news sites appear to use a signi\ufb01cantly\ngreater fraction of display ads compared to misinformation\nTABLE IV\nTop 100 News Top 100 Misinfo 100 Popularity Adjusted News\nHomepage Article Homepage Article Homepage Article\nSome Problematic Ads 43 44 24 42 29 40\nAds, None Problematic 54 47 47 34 61 50\nNo Ads 3 9 29 24 10 10\nCounts (or percents) of sites in our three samples that include no ads, only \u201cclean\u201d ads, and at least one problematic ad. Problematic ads are clustered: a large\nfraction of sites in each sample include only \u201cclean\u201d ads. We caution that these are underestimates, due to ads that were not loaded.\nTABLE V\nMisinformation Mainstream News\nHome Page Article Home Page Article\nPlatform Ad Format n % n % n % n % Total\nAd Butler Display 1 0.0% 1 0.0% 109 0.3% 102 0.3% 213\nAmazon Display 5 0.2% 10 0.2% 23 0.1% 50 0.1% 88\nAuctionNudge Display 0 0.0% 0 0.0% 2 0.0% 1 0.0% 3\nConcert Display 0 0.0% 0 0.0% 77 0.2% 72 0.2% 149\nGoogle Display 1322 52.8% 1572 35.3% 25753 68.3% 20947 56.3% 49594\nTownNews Display 0 0.0% 0 0.0% 452 1.2% 321 0.9% 773\nConnatix Interactive 1 0.0% 0 0.0% 20 0.1% 35 0.1% 56\nInsticator Interactive 3 0.1% 4 0.1% 168 0.4% 169 0.5% 344\nAdBlade Native 13 0.5% 47 1.1% 0 0.0% 18 0.0% 78\ncontent.ad Native 163 6.5% 495 11.1% 3 0.0% 165 0.4% 826\nFeedNetwork Native 8 0.3% 0 0.0% 0 0.0% 0 0.0% 8\nMGID Native 58 2.3% 234 5.3% 0 0.0% 75 0.2% 367\nOutbrain Native 15 0.6% 148 3.3% 694 1.8% 1470 4.0% 2327\nPowerInbox Native 20 0.8% 43 1.0% 0 0.0% 1 0.0% 64\nRevContent Native 197 7.9% 567 12.7% 55 0.1% 418 1.1% 1237\nTaboola Native 111 4.4% 452 10.2% 1336 3.5% 5866 15.8% 7765\nZergnet Native 69 2.8% 277 6.2% 89 0.2% 558 1.5% 993\nUnknown 517 20.7% 601 13.5% 8928 23.7% 6939 18.6% 16985\nTotal 2503 4451 37709 37207 81870\nCounts of ads from each ad platform, across allcrawled pages. Percentages are computed columnwise (with the total number of ads as the denominator).\nGoogle Ads and Taboola are similarly popular across both populations, but many smaller native ad platforms are present on misinformation sites but rare on\nnews sites, such as content.ad and RevContent.\nsites, when considering the full dataset . This result suggests\nthat as we consider lower-ranked news and misinformation\nsites, the gap between the quality of ads on those sites might\nbe larger than what we observe for the popular subset.\nMore broadly, Table III also provides large-scale evidence\nthat misinformation sites heavily leverage the targeted ad\necosystem for monetization \u2014 supporting recent reports [12,\n22] and underscoring the need for advertisers and ad platforms\nto consider their role in supporting (or combating) these actors.\nC. Are problematic ads evenly distributed across sites?\nThe previous section showed that problematic ad content\nappears roughly equally often, on average, on different sam-\nples of sites. However, this result does not imply that all sites\ninclude equal numbers or fractions of problematic ads.\nTable IV divides sites into three categories: those that\ncontain problematic ads, those that do not, and those that do\nnot have any ads at all. What we \ufb01nd is that sites do indeed\ndiffer on this point: the problematic ads we see are clustered in\n32%\u201357% of the ad-supported sites in each sample, though we\ndo not see evidence for large differences between the samples.\nIn other words, certain sites use ad platforms or preferences\nthat allow problematic ads to run, but others run only or\nprimarily \u201cclean\u201d ads.Due to the challenges with many ads not loading discussed\nabove, and because ads that appear are not consistent across\npage loads, the number of sites that run problematic ads\nmay be an underestimate . Due to this concern, we manually\ninvestigated a sample of \u201cclean\u201d sites, which indeed appeared\nto only include display ads for benign products and services.\nAlso anecdotally, we observed that sites with problematic\nads are also not created equal: some sites include a mix of\n\u201cclean\u201d display ads and one native ad, while others contain\n10+ problematic native ads.\nD. Do misinformation sites use a different set of ad providers?\nLastly, we investigate whether misinformation sites use\ndifferent ad platforms than news sites. Are there speci\ufb01c ad\nplatforms that are more popular among misinformation site\noperators? We might expect to see such difference because,\nfor example, these site operators tolerate lower quality adver-\ntisements, or because certain ad platforms are willing to work\nwith misinformation sites but not others.\nTable V shows the distribution of ad platforms used by\nmisinformation sites compared to news sites across our entire\ndataset. We see that Google Ads are common in both popula-\ntions, comprising 52.8% of ads on misinformation homepages,\nand 68.3% of ads on news site homepages. Taboola is the\nsecond most common ad platform and most common native\nad platform, especially on article pages, making up 10.2%\nand 15.8% of ads on misinformation and news article pages.\nHowever, we see that certain native ad providers, such as\ncontent.ad, RevContent, and Zergnet, are much more popular\namong misinformation sites. We note that these ad platforms\nalso run high proportions of problematic ads (see Table I).\nOur results suggest that misinformation sites appear largely\nto be able to work with the same types of ad platforms as\nmainstream news sites \u2014 i.e., we do not see much evidence\nthat they have been systematically \u201cdeplatformed\u201d by any\nmajor providers. These results are consistent with prior work\nfrom GDI showing that misinformation sites generate revenue\nfrom roughly the same ad exchanges as mainstream news\nsites [22]. Our data also suggests that with the exception of\nTaboola, mainstream news sites tend to avoid using many\nnative ad platforms that misinformation sites use, perhaps due\nto the low quality ad content served by those platforms.\nV. D ISCUSSION AND CONCLUSION\nWe argue that problematic content of online \u2014 particularly\nnative \u2014 ads should be a subject of systematic study by the\ncomputer security and privacy community. In this paper, we\nprovide initial results, which raise many additional questions\nand lay a foundation for future work. For example:\nLarger-Scale Systematic Measurement. Our work considers a\nsmall set of popular sites. While these are (by de\ufb01nition) the\nsites users are most likely to visit, our results raise the question\nof how things look in the longer tail. For example, perhaps\nlower-ranked sites tolerate more problematic ads, or perhaps\n(as suggested by Table III) lower-ranked misinformation sites\nare worse than similarly-ranked news sites. One key challenge\nto a larger-scale analysis is the need for automated classi\ufb01ca-\ntion of problematic ad content; future work might build on\nour labels in the Appendix and prior work on clickbait or\nadversarial ad detection (e.g., [10, 53, 58]). The methodology\nwe present can also lay a foundation for future measurements,\nbut we highlight several additional measurement challenges\nthat must be addressed: (1) classifying problematic ads often\nrequires considering both the ad itself and the landing page,\nbut automatically clicking on ads should be thought through\ncarefully given that it impacts the ad ecosystem, and (2) many\nads were not loaded by our crawler (perhaps due to anomaly\ndetection by ad networks due to our clicking). Prior work\non tracking detection either did not have to contend with\nthe challenge of ads not loading due to anomaly detection\n(because it did not require clicking on ads) or did not notice\nthe limitation (because it did not inspect ads visually).\nRole of Ad Targeting. The types of ads that appear on a\nwebsite result from a combination of the ad platform\u2019s policies\nand partners, options chosen by site\u2019s owner, and the ad\nplatform\u2019s targeting of the end user. We described and used a\nmethodology that isolated ad targeting based on hosting site,\nnot the user. While we studied news and misinformation sites,\nother types of sites warrant investigation (e.g., sites targetedat children). Additionally, we hypothesize that there is an\ninterplay between problematic ad content and the \ufb01ne-grained\n(and privacy-invasive) user targeting enabled by today\u2019s online\nad ecosystem. Who is being targeted with different types of\nproblematic ads? Are there some potentially vulnerable pop-\nulations (e.g., seniors, or people who frequently visit known\nmisinformation sites) being disproportionately exploited?\nUnderstanding and Differentiating Impacts on Users. Beyond\nstudying the ad ecosystem technically via web measurement,\nit is crucial to also study the actual human impacts of these\nproblematic ad practices. Not all of the practices we discuss\nare equally harmful, and to combat them, particularly through\npolicy and regulation, we must understand their relative harms.\nFor example, false advertising and scams are not only prob-\nlematic but illegal under existing regulations. But is \u201cclickbait\u201d\nmerely annoying, or actively harmful? Future work should\nconduct user studies to help clarify these harms. For example,\nhow do people actually perceive and interact with these ads?\nHow much time do people spend on low-quality sites reached\nvia ads, and how do they value that time compared to the time\nthey spend elsewhere on the web? How well do the various\n\u201cdark patterns\u201d we see work in practice, and on which types of\nusers \u2014 are some manipulative techniques disproportionately\nsuccessful, and are some users particularly vulnerable? While\nprior work in the marketing literature has considered related\nissues (e.g., [9, 11, 13, 32]), these works typically focus on\ndeception in legitimate product ads and/or do not include large-\nscale measurement studies.\nDefenses: Policies, Regulations, Tools. Many ad platforms,\nincluding native ad platforms, have explicit policies against\nproblematic ad content (e.g., [25, 61]). In our analysis, how-\never, we saw many examples of ads that either violate these\npolicies or only technically meet them. Understanding the\nroot cause of this discrepancy requires further investigation:\nperhaps some violating ads are dif\ufb01cult to detect, some poli-\ncies are inconsistently enforced, or the policies as written\nare insuf\ufb01cient to prevent the types of ads we identi\ufb01ed as\nproblematic. At the same time, some types of problematic ads\nmay be annoying, but are not suf\ufb01ciently problematic to ban\noutright (especially by U.S. regulatory agencies, which are\nconstrained by the First Amendment). Combining systematic\nweb measurements with user studies (proposed above) to\nunderstand the concrete impacts on end users may provide\nclarity on where to draw the line. Beyond policy, technical\ndefenses may play an immediate role in helping end users. For\nexample, future work might explore designing and evaluating a\nbrowser extension that detects and warns users of problematic\ncontent in ads, or that blocks only problematic ads.\nLast Word. The potential harms of online ads have become a\ncore interest of the computer security and privacy community\nin the last decade. In this work, we expand that focus to\nconsider the visible content of advertisements. We aim for our\nwork to lay the foundation to rich future investigations into\nthis aspect of the online ad ecosystem, ultimately reducing the\nspread of misinformation and other low-quality content online.\nACKNOWLEDGEMENTS\nWe thank Ryan Calo for helpful discussions and feedback\non earlier versions of this work. We also thank Christine\nChen and Ivan Evtimov for help developing and re\ufb01ning the\nqualitative codebook. This work is supported in part by the\nNational Science Foundation under Awards CNS-1565252 and\nCNS-1651230.\nREFERENCES\n[1] Alexa Web Information Service, \u201cAlexa - Top Sites by\nCategory - Top/News/Alternative,\u201d https://www.alexa.\ncom/topsites/category/Top/News/Alternative, accessed\non 2019-07-24.\n[2] Alexander Smith and Vladimir Banic, \u201cFake News:\nHow a Partying Macedonian Teen Earns Thousands\nPublishing Lies,\u201d NBC News, December 2016,\nhttps://www.nbcnews.com/news/world/fake-news-how-\npartying-macedonian-teen-earns-thousands-publishing-\nlies-n692451.\n[3] M. A. Amazeen and B. W. Wojdynski, \u201cReducing native\nadvertising deception: Revisiting the antecedents and\nconsequences of persuasion knowledge in digital news\ncontexts,\u201d Mass Communication and Society , vol. 22,\nno. 2, pp. 222\u2013247, 2019.\n[4] Amazon, \u201cAlexa Web Information Service API,\u201d https:\n//awis.alexa.com/.\n[5] A. Aribarg and E. M. Schwartz, \u201cNative advertising in\nonline news: Trade-offs among clicks, brand recognition,\nand website trustworthiness,\u201d Journal of Marketing\nResearch , vol. 57, no. 1, pp. 20\u201334, 2020. [Online].\nAvailable: https://doi.org/10.1177/0022243719879711\n[6] M. A. Bashir, S. Arshad, W. Robertson, and C. Wilson,\n\u201cTracing information \ufb02ows between ad exchanges using\nretargeted ads,\u201d in 25th USENIX Security Symposium ,\n2016.\n[7] C. B \u00a8osch, B. Erb, F. Kargl, H. Kopp, and S. Pfattheicher,\n\u201cTales from the dark side: Privacy dark strategies and pri-\nvacy dark patterns,\u201d Proceedings on Privacy Enhancing\nTechnologies , vol. 2016, no. 4, p. 237\u2013254, jul 2016.\n[8] H. Brignull, \u201cDark patterns,\u201d 2019, https://www.\ndarkpatterns.org/.\n[9] C. Campbell and P. E. Grimm, \u201cThe challenges na-\ntive advertising poses: Exploring potential federal trade\ncommission responses and identifying research needs,\u201d\nJournal of Public Policy & Marketing , vol. 38, no. 1,\npp. 110\u2013123, 2019.\n[10] A. Chakraborty, B. Paranjape, S. Kakarla, and N. Gan-\nguly, \u201cStop clickbait: Detecting and preventing clickbaits\nin online news media,\u201d in IEEE/ACM International Con-\nference on Advances in Social Networks Analysis and\nMining (ASONAM) , 2016.\n[11] A. W. Craig, Y . K. Loureiro, S. Wood, and J. M.\nVendemia, \u201cSuspicious minds: Exploring neural pro-\ncesses during exposure to deceptive advertising,\u201d Journal\nof Marketing Research , vol. 49, no. 3, pp. 361\u2013372, 2012.[12] L. G. Crovitz, \u201cHow Amazon, Geico and Wal-\nmart fund propaganda,\u201d The New York Times,\nJan. 2020, https://www.nytimes.com/2020/01/21/opinion/\nfake-news-russia-ads.html.\n[13] P. R. Darke and R. J. B. Ritchie, \u201cThe defensive con-\nsumer: Advertising deception, defensive processing, and\ndistrust,\u201d Journal of Marketing Research , vol. 44, no. 1,\npp. 114\u2013127, 2007.\n[14] P. Dave and C. Bing, \u201cRussian disinformation on\nYouTube draws ads, lacks warning labels: researchers,\u201d\nJun. 2019, https://www.reuters.com/article/us-alphabet-\ngoogle-youtube-russia/russian-disinformation-on-\nyoutube-draws-ads-lacks-warning-labels-researchers-\nidUSKCN1T80JP.\n[15] Easylist Filter List Project, \u201cEasylist,\u201d https://easylist.to.\n[16] S. Englehardt and A. Narayanan, \u201cOnline tracking: A 1-\nmillion-site measurement and analysis,\u201d in ACM Confer-\nence on Computer and Communications Security (CCS) ,\n2016.\n[17] M. Eslami, S. R. K. Kumaran, C. Sandvig, and K. Kara-\nhalios, \u201cCommunicating algorithmic process in online\nbehavioral advertising,\u201d in ACM Conference on Human\nFactors in Computing Systems (CHI) , 2018.\n[18] FactCheck.org, \u201cMisinformation directory,\u201d\nhttps://www.factcheck.org/2017/07/websites-post-\nfake-satirical-stories/.\n[19] I. Faizullabhoy and A. Korolova, \u201cFacebook\u2019s advertising\nplatform: New attack vectors and the need for interven-\ntions,\u201d in Workshop on Consumer Protection (ConPro) ,\n2018.\n[20] Federal Trade Commission, \u201cAn Exploration\nof Consumers\u2019 Advertising Recognition in the\nContexts of Search Engines and Native Advertising,\u201d\nhttps://www.ftc.gov/reports/blurred-lines-exploration-\nconsumers-advertising-recognition-contexts-search-\nengines-native, December 2017.\n[21] Global Disinformation Index, \u201cCutting the Funding\nof Disinformation: The Ad-Tech Solution,\u201d\nMay 2019, https://disinformationindex.org/wp-\ncontent/uploads/2019/05/GDI Report Screen AW2.pdf.\n[22] \u2014\u2014, \u201cThe Quarter Billion Dollar Question: How\nis Disinformation Gaming Ad Tech?\u201d Sep. 2019,\nhttps://disinformationindex.org/wp-content/uploads/\n2019/09/GDI Ad-tech Report Screen AW16.pdf.\n[23] B. Goggin, \u201c7,800 people have lost their\njobs so far this year in a media landslide,\u201d\nhttps://www.businessinsider.com/2019-media-layoffs-\njob-cuts-at-buzzfeed-huffpost-vice-details-2019-2,\nDecember 2019.\n[24] Google, \u201cAd Manager and Ad Exchange program\npolicies - Prevent malware in ad content,\u201d\nhttps://support.google.com/admanager/answer/181490?\nhl=en&ref topic=28145.\n[25] \u2014\u2014, \u201cGoogle Ads policies,\u201d https://support.google.com/\nadspolicy/answer/6008942.\n[26] \u2014\u2014, \u201cPuppeteer,\u201d https://developers.google.com/web/\ntools/puppeteer/.\n[27] C. M. Gray, Y . Kou, B. Battles, J. Hoggatt, and A. L.\nToombs, \u201cThe dark (patterns) side of UX design,\u201d in CHI\nConference on Human Factors in Computing Systems ,\n2018.\n[28] E. Grieco, N. Sumida, and S. Fedeli, \u201cAbout\na third of large U.S. newspapers have suffered\nlayoffs since 2017,\u201d https://www.pewresearch.org/fact-\ntank/2018/07/23/about-a-third-of-large-u-s-newspapers-\nhave-suffered-layoffs-since-2017/, July 2018.\n[29] C. Herbert, \u201cThe fake news codex,\u201d http://www.\nfakenewscodex.com, December 2018.\n[30] D. A. Hyman, D. J. Franklyn, C. Yee, and M. Rahmati,\n\u201cGoing Native: Can Consumers Recognize Native Ad-\nvertising? Does it Matter?\u201d 19 Yale J.L. & Tech. 77,\n2017.\n[31] C. Jack, \u201cLexicon of lies: Terms for problematic infor-\nmation,\u201d Data & Society, Aug. 2017.\n[32] G. V . Johar, \u201cConsumer involvement and deception from\nimplied advertising claims,\u201d Journal of Marketing Re-\nsearch , vol. 32, no. 3, pp. 267\u2013279, 1995.\n[33] Joshua Gillin, \u201cThe more outrageous, the better: How\nclickbait ads make money for fake news sites,\u201d https:\n//www.politifact.com/punditfact/article/2017/oct/04/\nmore-outrageous-better-how-clickbait-ads-make-mone/,\nOctober 2017.\n[34] D. Keating, K. Schaul, and L. Shapiro, \u201cThe Facebook\nads Russians targeted at different groups,\u201d The Washing-\nton Post, Nov. 2017, https://www.washingtonpost.com/\ngraphics/2017/business/russian-ads-facebook-targeting/.\n[35] Kim LaCapria, \u201cSnopes\u2019 \ufb01eld guide to fake news sites\nand hoax purveyors,\u201d Snopes, January 2016, https://www.\nsnopes.com/news/2016/01/14/fake-news-sites/.\n[36] Laura Kloot, \u201cNative Ads vs. Display Ads: What are the\ndifferences?\u201d https://www.outbrain.com/blog/native-ads-\nvs-display-ads/, July 2018.\n[37] M. L \u00b4ecuyer, G. Ducoffe, F. Lan, A. Papancea, T. Petsios,\nR. Spahn, A. Chaintreau, and R. Geambasu, \u201cXray:\nEnhancing the web\u2019s transparency with differential cor-\nrelation,\u201d in 23rd USENIX Security Symposium , 2014.\n[38] M. Lecuyer, R. Spahn, Y . Spiliopolous, A. Chaintreau,\nR. Geambasu, and D. Hsu, \u201cSunlight: Fine-grained tar-\ngeting detection at scale with statistical con\ufb01dence,\u201d\ninACM Conference on Computer and Communications\nSecurity (CCS) , 2015.\n[39] A. Lerner, A. K. Simpson, T. Kohno, and F. Roesner,\n\u201cInternet Jones and the Raiders of the Lost Trackers:\nAn Archaeological Study of Web Tracking from 1996 to\n2016,\u201d in 25th USENIX Security Symposium , 2016.\n[40] Z. Li, K. Zhang, Y . Xie, F. Yu, and X. Wang, \u201cKnow-\ning your enemy: Understanding and detecting malicious\nweb advertising,\u201d in ACM Conference on Computer and\nCommunications Security (CCS) , 2012.\n[41] J. Mahoney, \u201cA Complete Taxonomy of Internet Chum,\u201d\nThe Awl, June 2015, https://www.theawl.com/2015/06/a-\ncomplete-taxonomy-of-internet-chum/.[42] A. Mathur, G. Acar, M. Friedman, E. Lucherini, J. Mayer,\nM. Chetty, and A. Narayanan, \u201cDark patterns at scale:\nFindings from a crawl of 11k shopping websites,\u201d Pro-\nceedings of the ACM on Human-Computer Interaction\n(CSCW) , 2019.\n[43] A. Mathur, A. Narayanan, and M. Chetty, \u201cEndorsements\non Social Media: An Empirical Study of Af\ufb01liate Market-\ning Disclosures on YouTube and Pinterest,\u201d Proceedings\nof the ACM on Human-Computer Interaction (CSCW) ,\nvol. 2, Nov. 2018.\n[44] Media Bias/Fact Check Team, \u201cMedia Bias/Fact Check:\nThe Most Comprehensive Media Bias Resource,\u201d https:\n//mediabiasfactcheck.com/fake-news/.\n[45] Mozilla, \u201cmozilla/readability,\u201d https://github.com/\nmozilla/readability.\n[46] T. Nelms, R. Perdisci, M. Antonakakis, and M. Ahamad,\n\u201cTowards measuring and mitigating social engineering\nsoftware download attacks,\u201d in 25th USENIX Security\nSymposium , 2016.\n[47] C. Newton, \u201cYou might also like this story about\nweaponized clickbait,\u201d The Verge, apr 2014,\nhttps://www.theverge.com/2014/4/22/5639892/how-\nweaponized-clickbait-took-over-the-web.\n[48] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kr \u00a8ugel,\nF. Piessens, and G. Vigna, \u201cCookieless monster: Explor-\ning the ecosystem of web-based device \ufb01ngerprinting,\u201d\nIEEE Symposium on Security and Privacy , pp. 541\u2013555,\n2013.\n[49] M. Nouwens, I. Liccardi, M. Veale, D. Karger, and\nL. Kagal, \u201cDark patterns after the GDPR: Scraping con-\nsent pop-ups and demonstrating their in\ufb02uence,\u201d in CHI\nConference on Human Factors in Computing Systems ,\n2020.\n[50] A. Ohlheiser, \u201cThis is how Facebook\u2019s fake-news\nwriters make money,\u201d Washington Post, Nov.\n2016, https://www.washingtonpost.com/news/the-\nintersect/wp/2016/11/18/this-is-how-the-internets-fake-\nnews-writers-make-money/.\n[51] OpenSources Contributors, \u201cOpensources,\u201d\nhttps://github.com/OpenSourcesGroup/opensources,\nApril 2017.\n[52] Politifact, \u201cFact-checking U.S. politics,\u201d https://www.\npolitifact.com/.\n[53] M. Potthast, T. Gollub, M. Hagen, and B. Stein, \u201cThe\nclickbait challenge 2017: Towards a regression model for\nclickbait strength,\u201d 2018.\n[54] PropOrNot Team, \u201cIs it propaganda or not?: Your\nfriendly neighborhood propaganda identi\ufb01cation service,\nsince 2016!\u201d http://www.propornot.com/p/home.html.\n[55] V . Rastogi, R. Shao, Y . Chen, X. Pan, S. Zou, and\nR. Riley, \u201cAre these ads safe: Detecting hidden attacks\nthrough the mobile app-web interfaces,\u201d in NDSS , 2016.\n[56] F. Roesner, T. Kohno, and D. Wetherall, \u201cDetecting and\ndefending against third-party tracking on the web,\u201d in\nUSENIX Symposium on Networked Systems Design and\nImplementation (NSDI) , 2012.\n[57] Sapna Maheshwari and John Herrman, \u201cPublishers\nAre Rethinking Those \u2018Around the Web\u2019 Ads,\u201d\nhttps://www.nytimes.com/2016/10/31/business/media/\npublishers-rethink-outbrain-taboola-ads.html, October\n2016.\n[58] D. Sculley, M. E. Otey, M. Pohl, B. Spitznagel,\nJ. Hainsworth, and Y . Zhou, \u201cDetecting adversarial ad-\nvertisements in the wild,\u201d in ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining\n(KDD) , 2011.\n[59] Sharon Hurley Hall, \u201cNative Ads vs. Display Ads,\u201d\nhttps://blog.taboola.com/native-ads-vs-display-ads/,\nNovember 2019.\n[60] M. Swart, A. Mathur, and M. Chetty, \u201cIs This\nAn Ad? Help Us Identify Misleading Content\nOn YouTube,\u201d Freedom to Tinker, Jul. 2019,\nhttps://freedom-to-tinker.com/2019/07/09/is-this-an-\nad-help-us-identify-misleading-content-on-youtube/.\n[61] Taboola, \u201cAdvertising content policies overview,\u201d https:\n//help.taboola.com/hc/en-us/articles/115007287467-\nAdvertising-Content-Policies-Overview.\n[62] J. Temperton, \u201cWe need to talk about the internet\u2019s fake\nads problem,\u201d Wired, March 2017, https://www.wired.co.\nuk/article/fake-news-outbrain-taboola-hillary-clinton.\n[63] K. Tiffany, \u201cA mysterious gut doctor is begging\namericans to throw out \u201cthis vegetable\u201d now. but, like,\nwhich?\u201d V ox, May 2019, https://www.vox.com/the-\ngoods/2019/5/8/18537279/chum-box-weird-sponsored-\nlinks-gut-doctor.\n[64] B. Ur, P. G. Leon, L. F. Cranor, R. Shay, and Y . Wang,\n\u201cSmart, useful, scary, creepy: Perceptions of online be-\nhavioral advertising,\u201d in Symposium on Usable Privacy\nand Security (SOUPS) , 2012.\n[65] G. Venkatadri, A. Andreou, Y . Liu, A. Mislove, K. P.\nGummadi, P. Loiseau, and O. Goga, \u201cPrivacy Risks\nwith Facebook\u2019s PII-Based Targeting: Auditing a Data\nBroker\u2019s Advertising Interface,\u201d in IEEE Symposium on\nSecurity and Privacy , 2018.\n[66] P. Vines, F. Roesner, and T. Kohno, \u201cExploring ADINT:\nUsing Ad Targeting for Surveillance on a Budget - or -\nHow Alice Can Buy Ads to Track Bob,\u201d in Workshop on\nPrivacy in the Electronic Society (WPES) , 2017.\n[67] B. W. Wojdynski, \u201cThe deceptiveness of sponsored news\narticles: How readers recognize and perceive native ad-\nvertising,\u201d American Behavioral Scientist , vol. 60, no. 12,\npp. 1475\u20131491, 2016.\n[68] B. W. Wojdynski and N. J. Evans, \u201cGoing native: Effects\nof disclosure position and language on the recognition\nand evaluation of online native advertising,\u201d Journal of\nAdvertising , vol. 45, no. 2, pp. 157\u2013168, 2016.\n[69] X. Xing, W. Meng, B. Lee, U. Weinsberg, A. Sheth,\nR. Perdisci, and W. Lee, \u201cUnderstanding malvertising\nthrough ad-injecting browser extensions,\u201d in 24th Inter-\nnational Conference on World Wide Web (WWW) , 2015.\n[70] A. Zarras, A. Kapravelos, G. Stringhini, T. Holz,\nC. Kruegel, and G. Vigna, \u201cThe dark alleys of Madi-son Avenue: Understanding malicious advertisements,\u201d\ninACM Internet Measurement Conference , 2014.\nAPPENDIX\nThe table below provides detailed explanations of the problematic ads labels we used.\nTABLE VI\nPROBLEMATIC ADCODEBOOK\nCategory De\ufb01nition\nContent Farms News sites and blogs that contain a high density of ads, often broken up into slideshows to arti\ufb01cially increase ads\nloaded. The content of the articles are typically about human interest news, celebrity news, or political news.\nInsurance Advertorials Ads appearing to be news articles about people saving money on car or health insurance, to persuade consumers to\ngive personal information to insurance companies for quotes. The landing page does not clearly disclose that it is an\nad.\nMortgage Advertorials Ads for mortgage re\ufb01nancing, promising large savings, sometimes citing changes to government policies. The goal is\nto collect consumers\u2019 personal information and send it to lenders for quotes. Unclear advertising disclosure.\nInvestment Pitches Ads for investment opportunities that make sensationalist claims about their returns, \u201csecret stock picks\u201d, or predictions\nof imminent economic turmoil. The advertisers are not af\ufb01liated with established brokerages or \ufb01nancial institutions.\nMisleading Political Polls Ads that appear to be political opinion polls, about politically polarizing candidates or issues, but require users to\nsubmit names and email addresses \u2014 likely for fundraising or advertising purposes.\nPotentially Unwanted Software Ads for software downloads that primarily consist of misleading UI elements, like large buttons labeled \u201cDownload\u201d\nor \u201cWatch Now\u201d, rather than advertising the name of the product or its functionality.\nProduct Advertorials Ads for consumer products written in the style of a blog post or news article that do not obviously disclose that they\nwere written by the advertiser, other than in the \ufb01ne print in the header or footer of the page.\nSponsored Editorial Articles hosted on news sites paid for and/or authored by an advertiser, to sell products or promote their views.\nSponsored Search Ads for products or travel packages, but rather than linking to a speci\ufb01c business, links to search results for the product.\nSupplements Ads for supplements which claim about solve various chronic medical conditions, such as tinnitus, dark spots, weight\nloss, and toe nail fungus, but are not FDA approved.\nCharities / PSAs Charitable causes, public service announcements, class action lawsuit settlements, and other ads in the public interest.\nPolitical Campaigns Ads for political candidates or advocacy organizations, intended to spur people into taking action, including voting,\nsigning petitions, donating, or other forms of political participation.\nProducts and Services Straightforwards ads for various consumer products. No deception about the intent or identity of the ad is used.\nSelf Links Ads that link to a page on the parent domain. Some native ad platforms will recommend both sponsored content and\n1st party articles from the publisher.\nLabels used to describe ads in our qualitative analysis. The top section includes ad content we consider problematic, based on prior work, while the bottom\nsection includes more neutral ad content.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Bad news: Clickbait and deceptive ads on news and misinformation websites", "author": ["E Zeng", "T Kohno", "F Roesner"], "pub_year": "2020", "venue": "\u2026 on Technology and \u2026", "abstract": "A key aspect of online ads that has not been systematically studied by the computer security  community is their visible, user-facing content. Motivated by anecdotal evidence of"}, "filled": false, "gsrank": 648, "pub_url": "https://badads.cs.washington.edu/files/Zeng-ConPro2020-BadNews.pdf", "author_id": ["y5yR8WIAAAAJ", "s_YDrrgAAAAJ", "q5GIWC0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:U9nSBCwCj94J:scholar.google.com/&output=cite&scirp=647&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D640%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=U9nSBCwCj94J&ei=erWsaPG6EvnSieoPxKLpgQ0&json=", "num_citations": 68, "citedby_url": "/scholar?cites=16037039186172369235&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:U9nSBCwCj94J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://badads.cs.washington.edu/files/Zeng-ConPro2020-BadNews.pdf"}}, {"title": "Diplomov\u00e1 pr\u00e1ce \u0160\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch", "year": "2019", "pdf_data": " \n \n \n \n \n\u010cesk\u00e1 zem\u011bd\u011blsk\u00e1 univerzita v Praze \n \nProvozn\u011b ekonomick\u00e1 fakulta \n \nKatedra informa\u010dn\u00edch technologi\u00ed \n \n \n \n \n \nDiplomov\u00e1 pr\u00e1ce \n \n\u0160\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch \n \n \nBc. Richard Hartman   \n \n \n \n \n \n \n \n\u00a9 2019  \u010cZU v Praze  \n\n \n \n \n \n \n \n \n! ! ! \n \nM\u00edsto tohoto textu vlo\u017ete P\u0158EDN\u00cd stranu zad\u00e1n\u00ed pr\u00e1ce, \nkter\u00e9 si m\u016f\u017eete vyexportovat do PDF v IS.CZU.cz, \npokud ji\u017e m\u00e1te schv\u00e1len\u00e9 zad\u00e1n\u00ed i d\u011bkanem PEF. \n \n! ! ! \n  \n \n \n \n \n \n \n! ! ! \n \nM\u00edsto tohoto textu vlo\u017ete ZADN\u00cd stranu zad\u00e1n\u00ed pr\u00e1ce, \nkter\u00e9 si m\u016f\u017eete vyexportovat do PDF v IS.CZU.cz, \npokud ji\u017e m\u00e1te schv\u00e1len\u00e9 zad\u00e1n\u00ed i d\u011bkanem PEF. \n \nV p\u0159\u00edpad\u011b, \u017ee Va\u0161e zad\u00e1n\u00ed je na v\u00edce ne\u017e 2 strany, vlo\u017ete i \ndal\u0161\u00ed strany. \n \n \n! ! ! \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\u010cestn\u00e9 prohl\u00e1\u0161en\u00ed \n \nProhla\u0161uji, \u017ee svou diplomovou pr\u00e1ci \"\u0160\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch\" jsem \nvypracoval samostatn\u011b pod veden\u00edm vedouc\u00edho diplomov\u00e9 pr\u00e1ce a s pou\u017eit\u00edm odborn\u00e9 \nliteratury a dal\u0161\u00edch informa\u010dn\u00edch zdroj\u016f, kter\u00e9 jsou citov\u00e1ny v pr\u00e1ci a uvedeny v seznamu \npou\u017eit\u00fdch zdroj\u016f na konci pr\u00e1ce. Jako autor uveden\u00e9 diplomov\u00e9 pr\u00e1ce d\u00e1le prohla\u0161uji, \u017ee \njsem v souvislosti s jej\u00edm vytvo\u0159en\u00edm neporu\u0161il autorsk\u00e1 pr\u00e1va t\u0159et\u00edch osob. \n  \n \nV Praze dne 29. 11. 2019                    ___________________________ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nPod\u011bkov\u00e1n\u00ed \n \nR\u00e1d bych touto cestou pod\u011bkoval panu Ing. V\u00e1clavu Lohrovi, Ph.D. za jeho \nodborn\u00e9 veden\u00ed, v\u011bnovan\u00fd \u010das a v\u011bcn\u00e9 p\u0159ipom\u00ednky, kter\u00e9 mi poskytl k vypracov\u00e1n\u00ed t\u00e9to \npr\u00e1ce. \n \n \n \n \n \n \n \n \n 6  \n \n\u0160\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch  \n \n \nAbstrakt \n \nTato diplomov\u00e1 pr\u00e1ce se zab\u00fdv\u00e1 problematikou \u0161\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch. \nHlavn\u00edm c\u00edlem diplomov\u00e9 pr\u00e1ce je definovat vlivy \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch \u010di z\u00e1m\u011brn\u011b \nzkreslen\u00fdch informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch a objasnit mo\u017enosti obrany proti \u0161\u00ed\u0159en\u00ed takov\u00fdch \ninformac\u00ed.  \nPr\u00e1ce je \u010dlen\u011bna do teoretick\u00e9 a praktick\u00e9 \u010d\u00e1sti. V teoretick\u00e9 \u010d\u00e1sti jsou rozebr\u00e1ny \nr\u016fzn\u00e9 p\u0159\u00edstupy k obran\u011b v\u016f\u010di \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch informac\u00ed v\u010detn\u011b konkr\u00e9tn\u00edch n\u00e1stroj\u016f. D\u00e1le \njsou zde pops\u00e1ny p\u0159\u00edstupy pro \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v a vyu\u017eit\u00ed soci\u00e1ln\u00edch bot\u016f. \nPraktick\u00e1 \u010d\u00e1st pr\u00e1ce je zam\u011b\u0159ena na komparaci vybran\u00fdch n\u00e1stroj\u016f. Na z\u00e1klad\u011b \npoznatk\u016f o mo\u017enostech obrany proti fale\u0161n\u00fdm zpr\u00e1v\u00e1m a komparace n\u00e1stroj\u016f je \nvypracovan\u00e1 p\u0159\u00edpadov\u00e1 studie. V p\u0159\u00edpadov\u00e9 studii se d\u00e1le rozv\u00edj\u00ed vybran\u00fd postup obrany \nproti \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v. Pomoc\u00ed strojov\u00e9ho u\u010den\u00ed je p\u0159ipraven klasifika\u010dn\u00ed model pro \nanglick\u00e9 texty a dva klasifika\u010dn\u00ed modely, kter\u00e9 lze aplikovat pro \u010desky psan\u00e9 texty. Pro \ntvorbu klasifika\u010dn\u00edch model\u016f na \u010desk\u00e9 texty byl pou\u017eit vlastn\u00ed dataset. Ten je slo\u017een\u00fd z \nov\u011b\u0159en\u00fdch zpravodajsk\u00fdch a fale\u0161n\u00fdch zpr\u00e1v.  \n \nKl\u00ed\u010dov\u00e1 slova:  soci\u00e1ln\u00ed m\u00e9dia, soci\u00e1ln\u00ed s\u00edt\u011b, fake news, \u0161\u00ed\u0159en\u00ed informac\u00ed, dezinformace, \nmonitoring, detekce, soci\u00e1ln\u00ed boti, hoax, clickbait   \n  \n \n \n \n \n \n 7 Information spread in social networks  \n \n \nAbstract \n \nThis thesis deals with the issue of  information spread on social networks. The main \naim of the thesis is to define the effects of spreading false or intentionally distorted \ninformation on social networks and clarify the possibilities of defense against the \ndissemination of available information. \nThe work is divided into theoretical and practical parts. The theoretical part discusses \nvarious approaches to defense against the spread of false information, including specific \ntools. Furthermore, there are described approaches for spreading false news and using social \nbots. \nThe practical part is focused on comparison of selected tools. Based on information \nabout possibilities of defense against false reports and comparisons of tools, a case study is \nelaborated. The case study further develops ways to defend against the spread of false \nmessages. Create one model using machine learning for classification for English texts and \ntwo classification models using machine learning that can be applied to Czech written texts. \nFor classification models for Czech texts was used own dataset. It consists of verified news \nand hoaxes. \n  \nKeywords : social media, social networks, fake news, information spread, misinformation, \nmonitoring, detection, social bots, hoax, clickbait  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 8 Obsah \n \n \n1 \u00davod ........................................................................................................................... 11  \n2 C\u00edl pr\u00e1ce a metodika ................................................................................................ 12  \n2.1 C\u00edl pr\u00e1ce ........................................................................................................... 12  \n2.2 Metodika .......................................................................................................... 12  \n3 Teoretick\u00e1 v\u00fdchodiska ............................................................................................. 13  \n3.1 Fake news a soci\u00e1ln\u00ed s\u00edt\u011b .................................................................................. 13  \n3.1.1 Soci\u00e1ln\u00ed s\u00edt\u011b ............................................................................................... 13  \n3.1.2 Co jsou fake news ..................................................................................... 13  \n3.2 Vliv \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch informac\u00ed ................................................................. 15  \n3.2.1 Historie fake news: ................................................................................... 15  \n3.2.2 Identifikace vlivu fake news: .................................................................... 15  \n3.2.3 Schopnost poznat fake news: .................................................................... 16  \n3.2.4 D\u016fvody vzniku: ......................................................................................... 16  \n3.2.5 Zpr\u00e1vy na soci\u00e1ln\u00edch s\u00edt\u00edch ....................................................................... 20  \n3.3 Anal\u00fdza technologick\u00fdch postup\u016f pro z\u00edsk\u00e1n\u00ed dat ........................................... 20  \n3.4 Anal\u00fdza dosahu a dopadu \u0161\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00ed .......................... 23  \n3.4.1 Obecn\u00fd postup .......................................................................................... 23  \n3.4.2 Hled\u00e1n\u00ed vhodn\u00e9ho prost\u0159ed\u00ed pro komunikaci. ........................................... 26  \n3.4.3 N\u00e1stroje pro anal\u00fdzu soci\u00e1ln\u00edch s\u00edt\u00ed ...... Chyba! Z\u00e1lo\u017eka nen\u00ed definov\u00e1na.  \n3.5 Zp\u016fsoby \u0161\u00ed\u0159en\u00ed fake news ................................................................................. 27  \n3.5.1 Boti Obecn\u011b .............................................................................................. 32  \n3.6 Mo\u017enosti obrany proti \u0161\u00ed\u0159en\u00ed z\u00e1m\u011brn\u011b zkreslen\u00fdch informac\u00ed ......................... 38  \n3.6.1 Fake news a Facebook .............................................................................. 41  \n4 Vlastn\u00ed pr\u00e1ce ............................................................................................................. 43  \n4.1 Existuj\u00edc\u00ed n\u00e1stroje a postupy pro odhalov\u00e1n\u00ed \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v a preventivn\u00ed \nopat\u0159en\u00ed ........................................................................................................................ 43  \n4.1.1 Detekce ..................................................................................................... 43  \n4.1.2 Ov\u011b\u0159ov\u00e1n\u00ed skute\u010dnost\u00ed ............................................................................... 51  \n4.1.3 Proud zpr\u00e1v ............................................................................................... 53  \n4.1.4 Edukace ..................................................................................................... 53  \n4.1.5 N\u00e1stroje pro podporu \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v ............................................ 55  \n4.1.6 N\u00e1stroje pro odhalov\u00e1n\u00ed bot\u016f .................................................................... 57  \n4.1.7 Obrana s\u00edt\u011b Twitter proti fake news ...... Chyba! Z\u00e1lo\u017eka nen\u00ed definov\u00e1na.  \n4.2 P\u0159\u00edpadov\u00e1 studie: Klasifika\u010dn\u00ed modely pro rozpozn\u00e1n\u00ed fale\u0161n\u00fdch zpr\u00e1v na z\u00e1klad\u011b \nanal\u00fdzy textu ............................................................................................................... 62  \n \n \n \n \n \n 9 4.2.1 Klasifika\u010dn\u00ed model pro anglick\u00e9 prost\u0159ed\u00ed ................................................ 62  \n4.2.1.1 Tvorba klasifika\u010dn\u00edho modelu ........................................................... 62  \n4.2.1.2 Otestov\u00e1n\u00ed klasifika\u010dn\u00edho modelu a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti .... 65  \n4.2.2 Klasifika\u010dn\u00ed model pro \u010desk\u00e9 prost\u0159ed\u00ed .................................................... 65  \n4.2.2.1 Tvorba datasetu pro \u010desk\u00e9 prost\u0159ed\u00ed .................................................. 65  \n4.2.2.2 Tvorba klasifika\u010dn\u00edho modelu ........................................................... 68  \n4.2.2.3 Dataset pro tvorbu modelu o 4 t\u0159\u00edd\u00e1ch v \u010desk\u00e9m prost\u0159ed\u00ed ............... 70  \n4.2.2.4 Tvorba klasifika\u010dn\u00edho modelu ........................................................... 71  \n4.2.2.5 Otestov\u00e1n\u00ed klasifika\u010dn\u00edho modelu a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti .... 71  \n4.2.3 Dataset pro tvorbu upraven\u00e9ho modelu o 2 t\u0159\u00edd\u00e1ch v \u010desk\u00e9m prost\u0159ed\u00ed ... 72  \n4.2.3.1 Otestov\u00e1n\u00ed klasifika\u010dn\u00edho modelu a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti .... 73  \n5 V\u00fdsledky a diskuse ................................................................................................... 74  \n5.1 Podkapitola \u00farove\u0148 2 ........................................................................................ 74  \n5.1.1 Podkapitola \u00farove\u0148 3 ............................ Chyba! Z\u00e1lo\u017eka nen\u00ed definov\u00e1na.  \n5.1.2 Podkapitola \u00farove\u0148 3 ............................ Chyba! Z\u00e1lo\u017eka nen\u00ed definov\u00e1na.  \n5.2 Podkapitola \u00farove\u0148 2 ........................................................................................ 76  \n6 Z\u00e1v\u011br.......................................................................................................................... 78  \n7 Seznam pou\u017eit\u00fdch zdroj\u016f ........................................................................................ 79  \n8 P\u0159\u00edlohy ....................................................................................................................... 82  \n \nSeznam obr\u00e1zk\u016f  \nOdkazovan\u00fd seznam obr\u00e1zk\u016f \nObr\u00e1zek 1 Hospod\u00e1\u0159sk\u00e9 noviny Botometr ........................................................................... 58 \nObr\u00e1zek 2 Bot \u00fa\u010det Botometr .............................................................................................. 58 \nObr\u00e1zek 3 Hospod\u00e1\u0159sk\u00e9 noviny BotOrNot .......................................................................... 59 \nObr\u00e1zek 4 Hospod\u00e1\u0159sk\u00e9 noviny Twitter Audit p\u0159ehled ....................................................... 60 \nObr\u00e1zek 5 Hospod\u00e1\u0159sk\u00e9 noviny Twitter Audit .................................................................... 60 \nObr\u00e1zek 6 Hospod\u00e1\u0159sk\u00e9 noviny Twitter Audit sleduj\u00edc\u00ed ..................................................... 61 \nObr\u00e1zek 7 Uk\u00e1zka k\u00f3du pro nastaven\u00ed pavouka s vyu\u017eit\u00edm frameworku Scrapy v Pythonu \npro z\u00edsk\u00e1n\u00ed dat, kter\u00fd bude proch\u00e1zet web irozhlas.cz ........................................................ 68 \n \nSeznam tabulek  \nOdkazovan\u00fd seznam tabulek \nTabulka 1 Sezman hodnocen\u00fdch dom\u00e9n ............................................................................. 45  \nTabulka 2 Hodnocen\u00ed dom\u00e9n vybran\u00fdmi n\u00e1stroji ................................................................ 45  \nTabulka 3 Seznam hodnocen\u00fdch zpr\u00e1v ............................................................................... 46  \nTabulka 4 Hodnocen\u00ed zpr\u00e1v vybran\u00fdmi n\u00e1stroji .................................................................. 48  \n \n \n \n \n \n 10 Tabulka 5 Cen\u00edk slu\u017eby Socio Hawk ................................................................................... 55  \nTabulka 6 Cena slu\u017eby Twitter audit ................................................................................... 59  \nTabulka 7 Blokovan\u00e9 dom\u00e9ny na Twitteru .......................................................................... 49  \n \n \n \n \n \n \n \n \n \n 11 1 \u00davod \nTato diplomov\u00e1 pr\u00e1ce se zab\u00fdv\u00e1 problematikou \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch \u010di z\u00e1m\u011brn\u011b \nzkreslen\u00fdch informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch.  \n \nDan\u00e9 t\u00e9ma jsem si zvolil, proto\u017ee fale\u0161n\u00e9 zpr\u00e1vy p\u0159edstavuj\u00ed ohromn\u00e9 riziko i potenci\u00e1l \novliv\u0148ov\u00e1n\u00ed ve\u0159ejnosti. Pro \u00fa\u010dely ovliv\u0148ov\u00e1n\u00ed n\u00e1zor\u016f velk\u00e9ho mno\u017estv\u00ed lid\u00ed se soci\u00e1ln\u00ed s\u00edt\u011b \nukazuj\u00ed jako mocn\u00fd n\u00e1stroj, kter\u00fd posunul hranice politick\u00e9 i komer\u010dn\u00ed propagandy na zcela \nnovou \u00farove\u0148. \n \n\u0160\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v a dezinformac\u00ed bylo sou\u010d\u00e1st\u00ed lidsk\u00e9 historie daleko d\u0159\u00edve, ne\u017e \np\u0159i\u0161el n\u00e1stup internetu. S p\u0159\u00edchodem internetu a vzniku soci\u00e1ln\u00edch s\u00edt\u00ed na internetu, ale \nz\u00edsk\u00e1v\u00e1me mo\u017enost oslovit masy, p\u0159esto vyvolat dojem, \u017ee zpr\u00e1va je personalizovan\u00e1 a \nur\u010den\u00e1 p\u0159\u00edmo potencion\u00e1ln\u00edmu konzumentovi. \n \nV teoretick\u00e9 \u010d\u00e1sti budou pops\u00e1ny konkr\u00e9tn\u00ed n\u00e1stroje pro p\u0159\u00edm\u00e9 \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v \n\u010di jejich nep\u0159\u00edmou podporu. Zam\u011b\u0159\u00edm se i na n\u00e1stroje odhaluj\u00edc\u00ed soci\u00e1ln\u00ed boty. Prim\u00e1rn\u011b \ndefinuji mo\u017enosti obrany proti \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v, a to jak v zahrani\u010d\u00ed, tak i pro \u010desky \nmluv\u00edc\u00ed publikum. Budou porovn\u00e1no n\u011bkolik p\u0159\u00edstup\u016f pro zisk da, z nich\u017e n\u011bkter\u00e9 budou \nuplatn\u011bny v praktick\u00e9 \u010d\u00e1sti.  \n \nPraktick\u00e1 \u010d\u00e1st pr\u00e1ce je zam\u011b\u0159ena na porovn\u00e1n\u00ed p\u0159\u00edstup\u016f k odhalen\u00ed fale\u0161n\u00fdch zpr\u00e1v. \nPorovn\u00e1n\u00ed n\u00e1stroj\u016f vyu\u017e\u00edvaj\u00edc\u00ed r\u016fzn\u00e9 p\u0159\u00edstupy k odhalen\u00ed fale\u0161n\u00fdch zpr\u00e1v a objasnit mo\u017enosti \nobrany proti \u0161\u00ed\u0159en\u00ed z\u00e1m\u011brn\u011b zkreslen\u00fdch informac\u00ed. D\u00e1le tak\u00e9 porovn\u00e1n\u00ed n\u00e1stroj\u016f pro \nodhalov\u00e1n\u00ed automatick\u00fdch \u00fa\u010dt\u016f na soci\u00e1ln\u00edch s\u00edt\u00edch, takzvan\u00fdch soci\u00e1ln\u00edch bot\u016f. Pro v\u011bt\u0161\u00ed \nkomplexnost jsou zahrnuty i slu\u017eby, kter\u00e9 naopak podporuj\u00ed tvorbu fale\u0161n\u00fdch \u00fa\u010dt\u016f. \nV r\u00e1mci p\u0159\u00edpadov\u00e9 studie budou vytvo\u0159eny modely pro anglick\u00e9 a \u010desk\u00e9 prost\u0159edn\u00ed, \njejich\u017e \u00fa\u010delem bude rozpoznat fale\u0161n\u00e9 zpr\u00e1vy na z\u00e1klad\u011b jednoho z p\u0159\u00edstup\u016f, kter\u00fd se bude \njevit jako aplikovateln\u00fd pro \u010desk\u00e9 prost\u0159ed\u00ed.  Bude vyhodnocena procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost \nzvolen\u00e9ho p\u0159\u00edstupu. \n \n \n \n \n \n \n 12 2 C\u00edl pr\u00e1ce a metodika \n2.1 C\u00edl pr\u00e1ce \nC\u00edlem pr\u00e1ce je definovat vlivy \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch \u010di z\u00e1m\u011brn\u011b zkreslen\u00fdch informac\u00ed \nna soci\u00e1ln\u00edch s\u00edt\u00edch a objasnit mo\u017enosti obrany proti \u0161\u00ed\u0159en\u00ed z\u00e1m\u011brn\u011b zkreslen\u00fdch \ninformac\u00ed. Sou\u010d\u00e1st\u00ed pr\u00e1ce bude anal\u00fdza technologick\u00fdch postup\u016f pro z\u00edsk\u00e1n\u00ed a validaci \ndat, porovn\u00e1n\u00ed p\u0159\u00ednos\u016f dostupn\u00fdch n\u00e1stroj\u016f pro anal\u00fdzu a odhalov\u00e1n\u00ed fake news. \nD\u00edl\u010d\u00edmi c\u00edli je popsat technologick\u00e9 postupy pro \u0161\u00ed\u0159en\u00ed takov\u00fdch informac\u00ed, vyhodnotit \nz\u00e1va\u017enost uveden\u00e9ho probl\u00e9mu v \u010desk\u00e9m prost\u0159ed\u00ed a jak\u00fdch soci\u00e1ln\u00edch s\u00edt\u00ed se tento \nprobl\u00e9m t\u00fdk\u00e1 nejv\u00edce. \n2.2 Metodika \nMetodika \u0159e\u0161en\u00e9 problematiky diplomov\u00e9 pr\u00e1ce je zalo\u017eena na studiu odborn\u00e9 \nliteratury. Zpracov\u00e1n\u00ed teoretick\u00e9 \u010d\u00e1sti pr\u00e1ce bude \u0159e\u0161eno pomoc\u00ed liter\u00e1rn\u00ed re\u0161er\u0161e.  \n \nVlastn\u00ed \u0159e\u0161en\u00ed bude realizov\u00e1no formou p\u0159\u00edpadov\u00fdch studi\u00ed. Anal\u00fdza ji\u017e objeven\u00fdch \nfake news pomoc\u00ed dostupn\u00fdch n\u00e1stroj\u016f a objeven\u00e9 postupy pro \u0161\u00ed\u0159en\u00ed a odhalov\u00e1n\u00ed \nfake news budou konfrontov\u00e1ny s v\u00fdstupy teoretick\u00e9 \u010d\u00e1sti pr\u00e1ce. \n \n \n \n \n \n \n 13 3 Teoretick\u00e1 v\u00fdchodiska \n3.1 Fake news a soci\u00e1ln\u00ed s\u00edt\u011b \n3.1.1 Soci\u00e1ln\u00ed s\u00edt\u011b \nWebov\u00e1 slu\u017eba, kter\u00e1 obvykle registrovan\u00fdm \u010dlen\u016fm, umo\u017e\u0148uje tvorbu ve\u0159ejn\u00e9ho, \u010di \n\u010d\u00e1ste\u010dn\u011b ve\u0159ejn\u00e9ho profilu a navazovat virtu\u00e1ln\u00ed vztahy s ostatn\u00edmi u\u017eivateli dan\u00e9 s\u00edt\u011b. \nUmo\u017e\u0148uje tak\u00e9 komunikovat mezi sebou, sd\u00edlen\u00ed spole\u010dn\u00e9ho multimedi\u00e1ln\u00edho obsahu, \nodkaz\u016f, pl\u00e1n\u016f akc\u00ed a dal\u0161\u00ed aktivity. V\u011bt\u0161ina obsahu soci\u00e1ln\u00edch s\u00edt\u00ed je tvo\u0159ena samotn\u00fdmi \nu\u017eivateli. Soci\u00e1ln\u00ed s\u00edt\u011b virtu\u00e1ln\u011b propojuj\u00ed r\u016fzn\u00e9 osoby a instituce na z\u00e1klad\u011b spole\u010dn\u00fdch \np\u0159\u00e1telsk\u00fdch \u010di pracovn\u00edch vztah\u016f nebo stejn\u00e9ho z\u00e1jmu.  \nSoci\u00e1ln\u00ed s\u00edt\u011b jsou tedy jednou z kategori\u00ed soci\u00e1ln\u00edch m\u00e9di\u00ed.  (1) \n3.1.2 Co jsou fake news \nDefinujeme Fake news jako um\u011ble vytvo\u0159en\u00e9 informace, kter\u00e9 napodobuj\u00ed obsah \nzpravodajstv\u00ed svou formou, ale ne v organiza\u010dn\u00edm procesu nebo \u00famyslu. Fake news \npostr\u00e1daj\u00ed redak\u010dn\u00ed normy a procesy zpravodajsk\u00fdch m\u00e9di\u00ed pro zaji\u0161t\u011bn\u00ed p\u0159esnosti a \nd\u016fv\u011bryhodnosti informace. Fake news se p\u0159ekr\u00fdvaj\u00ed s ostatn\u00edmi zkreslen\u00fdmi informacemi, \njako misinformation (fale\u0161n\u00e9, nebo zav\u00e1d\u011bj\u00edc\u00ed informace), disinformation (nepravdiv\u00e9 \ninformace, kter\u00e9 se z\u00e1m\u011brn\u011b \u0161\u00ed\u0159\u00ed za \u00fa\u010delem oklam\u00e1n\u00ed lid\u00ed) (2) \n \nFake news na sebe upozor\u0148ovali v ned\u00e1vn\u00e9m politick\u00e9m kontextu, ale jsou \nzdokumentov\u00e1ny p\u0159\u00edpady na mnoho jin\u00fdch t\u00e9mat, nap\u0159\u00edklad: p\u0159\u00edpady ohledn\u011b vakcinace, \nv\u00fd\u017eivy, finan\u010dn\u00edho trhu aj. To je zvl\u00e1\u0161\u0165 zhoubn\u00e9, \u017ee parazituj\u00ed na tradi\u010dn\u00edm zpravodajstv\u00ed, z \nkter\u00e9ho sou\u010dasn\u011b t\u011b\u017e\u00ed i podkop\u00e1vaj\u00ed jej. Masivn\u00ed \u0161\u00ed\u0159en\u00ed dezinformac\u00ed v\u202fdigit\u00e1ln\u00edm prost\u0159ed\u00ed \nbylo identifikov\u00e1n\u00ed jako velk\u00fd glob\u00e1ln\u00ed probl\u00e9m se silou ovlivnit volby a ohrozit demokracii.  \n \nJako dezinformaci m\u016f\u017eeme ozna\u010dit: hoaxy, konspira\u010dn\u00ed teorie, um\u011ble vytvo\u0159en\u00e9 \nzpr\u00e1vy, click-bait titulky a v\u202fn\u011bkter\u00fdch p\u0159\u00edpadech dokonce i satyru.  \n \n \n \n \n \n \n 14 D\u016fvody pro vznik takov\u00fdch zpr\u00e1v jsou bu\u010f snadn\u00e1 monetizace d\u00edky velk\u00e9 \nn\u00e1v\u0161t\u011bvnosti na webu, kam odkazuj\u00ed (prost\u0159ednictv\u00edm reklam), nebo politick\u00e9 motivy se \nsnahou ovlivnit svobodnou v\u016fli. Skute\u010dn\u00fd dopad fake news na volby je velice t\u011b\u017eko \nm\u011b\u0159iteln\u00fd a obt\u00ed\u017en\u011b jej lze prok\u00e1zat. (3) \n \nExistuje velk\u00e9 mno\u017estv\u00ed zdroj\u016f, kter\u00e9 lze ozna\u010dit jako fake news. Melissa Zimdars, \nprofesorka komunikace na Merrimack College, roz\u0159azuje fale\u0161n\u00e9 zpravodajsk\u00e9 weby do \u010dty\u0159 \nr\u016fzn\u00fdch n\u00ed\u017ee uveden\u00fdch kategori\u00ed: \n \nZdroje satiry: Tyto str\u00e1nky obvykle pou\u017e\u00edvaj\u00ed humor, p\u0159eh\u00e1n\u011bn\u00ed nebo parodii, aby se \nvyj\u00e1d\u0159ily k aktu\u00e1ln\u00edm ud\u00e1lostem. P\u0159\u00edklady zahrnuj\u00ed Onion, Sports Pickle a News Biscuit. \n \nZdroje Clickbait: Senza\u010dn\u00ed titulky nebo obr\u00e1zky, kter\u00e9 jsou navr\u017eeny tak, aby p\u0159il\u00e1kaly \nn\u00e1v\u0161t\u011bvn\u00edky k n\u00e1v\u0161t\u011bv\u011b str\u00e1nky nebo odkazu s c\u00edlem generovat zisk skrze reklamn\u00ed \nprost\u0159edky. Informace jsou \u010dasto d\u016fv\u011bryhodn\u00e9, ale mohou b\u00fdt tak\u00e9 zav\u00e1d\u011bj\u00edc\u00ed, neobjektivn\u00ed \nnebo vy\u017eaduj\u00ed kliknut\u00ed na n\u011bkolik sn\u00edmk\u016f nebo obr\u00e1zk\u016f k z\u00edsk\u00e1n\u00ed skute\u010dn\u00fdch informac\u00ed. \nP\u0159\u00edklady: Liberal America, RedState, The Blaze. \n \nNespolehliv\u00e9 zdroje: Tyto zdroje obvykle nelze p\u0159ijmout za nomin\u00e1ln\u00ed hodnotu a je \nt\u0159eba je d\u00e1le ov\u011b\u0159it z jin\u00fdch zdroj\u016f, aby bylo mo\u017en\u00e9 ur\u010dit, zda jsou informace d\u016fv\u011bryhodn\u00e9. \nPrezentovan\u00e9 informace jsou \u010dasto zalo\u017eeny na pov\u011bsti nebo sly\u0161en\u00ed. P\u0159\u00edklady: Brietbart, \nOccupy Democrats, Washington Examiner. \n \nFale\u0161n\u00e9: tyto zdroje pou\u017e\u00edvaj\u00ed zkreslen\u00e9 nebo fale\u0161n\u00e9 titulky s c\u00edlem rozzu\u0159it, \u0161okovat \nnebo urazit lidi na soci\u00e1ln\u00edch m\u00e9di\u00edch, aby podpo\u0159ili lajky, sd\u00edlen\u00ed nebo reklamn\u00ed p\u0159\u00edjmy. \nP\u0159\u00edklady: BostonLeader, BuzzfeedUSA, CBS News.com.Co (4) \n \n \n \n \n \n \n 15 3.2 Vliv \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch informac\u00ed \n3.2.1 Historie fake news: \n\u017durnalistick\u00e9 normy objektivity a nestranosti se objevily jako reakce mezi novin\u00e1\u0159i \nproti roz\u0161\u00ed\u0159en\u00e9mu pou\u017eit\u00ed propagandy v\u202fprvn\u00ed sv\u011btov\u00e9 v\u00e1lce a vzestupu korpor\u00e1tn\u00ed \nreklamy a v\u202f20. letech 20. stolet\u00ed.  \nD\u00edky technologi\u00edm 20. stolet\u00ed existovali dominantn\u00ed hr\u00e1\u010di (tisk, r\u00e1dio a tv vys\u00edl\u00e1n\u00ed), \nkte\u0159\u00ed do ur\u010dit\u00e9 m\u00edry dr\u017eely dan\u00e9 normy. Internet razantn\u011b sn\u00ed\u017eil vstupn\u00ed cenu pro nov\u00e9 \nsubjekty: mnoho z\u202fnich odm\u00edtlo dr\u017eet se norem a podkopaly obchodn\u00ed modely \ntradi\u010dn\u00edch zpravodajsk\u00fdch zdroj\u016f, kter\u00e9 se jinak t\u011b\u0161ily vysok\u00e9 \u00farovn\u011b d\u016fv\u011bry \nve\u0159ejnosti.  \nD\u016fv\u011bra v\u202fmasov\u00e1 m\u00e9dia se propadla na historick\u00e9 minimum v\u202froce 2016  \nHistoricky nejni\u017e\u0161\u00ed d\u016fv\u011bru v\u202fmasov\u00e1 m\u00e9dia   \n  \nVelk\u00fd rozmach za\u017eilo u\u017eit\u00ed propagandy v\u202fobdob\u00ed 1 sv\u011btov\u00e9 v\u00e1lky a vzestup korpor\u00e1tn\u00ed \npropagandy po roce 1920. (5) \n   \nV\u202froce 2016 bylo do oxfordsk\u00e9ho slovn\u00edku p\u0159id\u00e1no slovo \u201epost-truth\u201c v\u202fp\u0159ekladu \npostpravda. Jedn\u00e1 se o situaci, kdy p\u0159i vytv\u00e1\u0159en\u00ed p\u0159edstavy o realit\u011b p\u0159eva\u017euj\u00ed emoce \nna d ove\u0159en\u00fdmi fakty. Toto slovo bylo hojn\u011b pou\u017e\u00edv\u00e1no v\u202fdob\u011b volby Donalda Trumpa \na Brexitu. (6) \n \n3.2.2 Identifikace vlivu fake news: \nDezinformace mohou, v\u00e9st ke \u0161patn\u00fdm rozhodnut\u00edm a n\u00e1sledn\u00e9 d\u016fsledky jsou \np\u0159etrv\u00e1vaj\u00edc\u00ed a obt\u00ed\u017en\u011b napraviteln\u00e9, odhalen\u00ed je d\u016fle\u017eit\u00fdm c\u00edlem v\u011bdeck\u00e9 a ve\u0159ejn\u00e9 \npolitiky. (7) \n \n \n \n \n \n \n 16 3.2.3 Schopnost poznat fake news: \nStudie na Stanfordsk\u00e9 univerzit\u011b v listopadu 2016, kter\u00e9 se \u00fa\u010dastnilo v\u00edce ne\u017e 7800 \nstudent\u016f ze st\u0159edn\u00edch \u0161kol prost\u0159ednictv\u00edm vysok\u00e9 \u0161koly, zjistilo, \u017ee v\u00edce ne\u017e 80 % \nst\u0159edo\u0161kol\u00e1k\u016f nemohlo rozli\u0161it legitimn\u00ed zpr\u00e1vy od reklam sponzorovan\u00fdch a \nfale\u0161n\u00fdch zpr\u00e1v. Vysoko\u0161kol\u00e1ci m\u011bli pot\u00ed\u017ee s identifikac\u00ed aktivistick\u00fdch p\u0159\u00edsp\u011bvk\u016f v \nsoci\u00e1ln\u00edch m\u00e9di\u00edch a potenci\u00e1ln\u00ed zaujatost\u00ed. Jedn\u00e1 se o generaci, kter\u00e1 m\u00e1 k digit\u00e1ln\u00edm \ntechnologi\u00edm nejbl\u00ed\u017ee, p\u0159esto maj\u00ed velk\u00e9 pot\u00ed\u017ee s hodnocen\u00edm a ur\u010dov\u00e1n\u00edm legitimity \ninformac\u00ed. (8) \n   \n3.2.4 D\u016fvody vzniku:  \nFale\u0161n\u00e9 zpr\u00e1vy jsou prost\u0159edkem k c\u00edli, nikoli c\u00edlem samy o sob\u011b. Strany, kter\u00e9 zadaly \npropagaci fale\u0161n\u00fdch zpravodajsk\u00fdch server\u016f, tak \u010din\u00ed s ohledem na c\u00edl. Zat\u00edmco \njak\u00fdkoli medi\u00e1ln\u00ed p\u0159\u00edsp\u011bvek lze do ur\u010dit\u00e9 m\u00edry pova\u017eovat za neobjektivn\u00ed, odli\u0161uje \nfale\u0161n\u00e9 zpravodajsk\u00e9 kampan\u011b to, \u017ee jsou \u010dasto zalo\u017eeny na vymy\u0161len\u00fdch, \nneexistuj\u00edc\u00edch faktech a \u010dasto vyu\u017e\u00edvaj\u00ed \u0161okuj\u00edc\u00ed nadpisy \u201eclickbait\u201c, aby p\u0159il\u00e1kaly \n\u010dten\u00e1\u0159ovu pozornost. \n \nMotivac\u00ed k tvorb\u011b fake news m\u016f\u017ee b\u00fdt cel\u00e1 \u0159ada nap\u0159\u00edklad: \u0161patn\u00e1 \u017eurnalistika, \nparodie, provokace, v\u00e1\u0161e\u0148, partyz\u00e1nstv\u00ed, zisk, politick\u00fd vliv propagandy. (9) \n \nZisk: \nExistuje velk\u00e9 mno\u017estv\u00ed zp\u016fsob\u016f, jak t\u011b\u017eit z \u0161\u00ed\u0159en\u00ed fake news. Nejb\u011b\u017en\u011bj\u0161\u00ed metoda je \npomoc\u00ed reklamy. Fale\u0161n\u00e9 zpravodajsk\u00e9 weby velice dob\u0159e sm\u011b\u0159uj\u00ed u\u017eivatele soci\u00e1ln\u00edch \ns\u00edt\u00ed na sv\u00e9 weby. P\u0159esto\u017ee popisy a nadpisy, kter\u00e9 pou\u017e\u00edvaj\u00ed, jsou charakteristick\u00e9 jako \nclickbait, nelze pop\u0159\u00edt, \u017ee funguj\u00ed. \n \nN\u011bkter\u00e9 weby, kter\u00e9 zve\u0159ej\u0148uj\u00ed zav\u00e1d\u011bj\u00edc\u00ed informace nebo obsah pova\u017eovan\u00fd za \nfale\u0161n\u00e9 zpr\u00e1vy, maj\u00ed v\u00fdznamn\u00fd provoz. Nap\u0159\u00edklad web infowars.com, je str\u00e1nka, kter\u00e1 \n\u010dasto zve\u0159ej\u0148uje konspira\u010dn\u00ed teorie m\u00e1 p\u0159ibli\u017en\u011b stejn\u00fd po\u010det n\u00e1v\u0161t\u011bvn\u00edk\u016f jako \nChicago tribune. \n \n \n \n \n \n 17  \nP\u0159esto\u017ee reklamy na t\u011bchto str\u00e1nk\u00e1ch jsou jednotliv\u011b levn\u011bj\u0161\u00ed ne\u017e reklamy b\u011b\u017en\u00fdch \nzpravodajsk\u00fdch server\u016f, kumulovan\u00e9 p\u0159\u00edjmy t\u011bchto dodavatel\u016f jsou zna\u010dn\u00e9. \n \nReklama v\u0161ak p\u0159edstavuje pouze nejzjevn\u011bj\u0161\u00ed zp\u016fsob, jak profitovat z fale\u0161n\u00fdch zpr\u00e1v. \nJe tak\u00e9 mo\u017en\u00e9 pokusit se t\u011b\u017eit z reakc\u00ed na fake news. \n \nJe zn\u00e1mo, \u017ee ceny akci\u00ed mohou b\u00fdt pomoc\u00ed Twitteru siln\u011b ovlivn\u011bny. Nap\u0159\u00edklad akcie \namerick\u00e9ho ultra-n\u00edzkon\u00e1kladov\u00e9ho dopravce (ULCC) Spirit Airlines klesly o 5 % den \npot\u00e9, co na soci\u00e1ln\u00edch s\u00edt\u00edch prob\u011bhlo video s p\u011bstn\u00edm soubojem pasa\u017e\u00e9ru kv\u016fli \nzru\u0161en\u00e9mu letu. \n  \nVliv fake news na krypto m\u011bny: \nV lednu 2017 jihokorejsk\u00e1 vl\u00e1da vyzvala k dal\u0161\u00ed regulaci obchodov\u00e1n\u00ed s \nkryptom\u011bnami kv\u016fli rychl\u00e9mu n\u00e1r\u016fstu popularity u m\u00edstn\u00ed populace. Jejich v\u00fdroky \nbyly vy\u0148aty z kontextu b\u011b\u017en\u00fdmi m\u00e9dii a mnoz\u00ed byli p\u0159esv\u011bd\u010deni, \u017ee se zem\u011b p\u0159ipravuje \nna p\u0159\u00edm\u00fd z\u00e1kaz. Tr\u017en\u00ed hodnoty kryptom\u011bn klesly v pr\u016fm\u011bru o 10 %, Ripple dokonce \no cel\u00fdch 25 %. \n \nDal\u0161\u00ed pozoruhodn\u00fd p\u0159\u00edpad manipulace se zpr\u00e1vami se stal v \u010dervnu 2017. Tehdy se \nobjevil p\u0159\u00edb\u011bh, \u017ee Vitalik Buterin, spoluzakladatel kryptom\u011bny Ethereum, zem\u0159el p\u0159i \nsmrteln\u00e9 autonehod\u011b. Trh reagoval t\u00e9m\u011b\u0159 okam\u017eit\u011b. Investo\u0159i se za\u010dali Etherea \nzbavovat a trvalo jen \u0161est hodin, ne\u017e cena Etherea klesla o 12 %. To znamen\u00e1, \u017ee \ncelkov\u00e1 hodnoty Etherea poklesla p\u0159ibli\u017en\u011b o 4 miliardy dolar\u016f. S\u00e1m Vitalik musel \nzve\u0159ejnit selfie na Twitteru, aby ve\u0159ejnost p\u0159esv\u011bd\u010dil, \u017ee je v po\u0159\u00e1dku a \u017ee zpr\u00e1vy byly \nfale\u0161n\u00e9. \n(10) \n  \n \n \n \n \n \n 18 Zni\u010den\u00ed reputace a \u00fanik dat: \n \nC\u00edlen\u00e9 zni\u010den\u00ed pov\u011bsti jedince (v origin\u00e1le character assassination) a dal\u0161\u00ed formy \u010dern\u00e9 \npropagandy nemus\u00ed b\u00fdt v\u017edy politicky motivovan\u00e9. \u00da\u010dinek c\u00edlen\u00e9ho \u00fatoku m\u016f\u017ee b\u00fdt \nvelmi v\u00e1\u017en\u00fd, obzvl\u00e1\u0161t\u011b kdy\u017e je dob\u0159e na\u010dasovan\u00fd. \n \nV politick\u00e9 oblasti jsou \u00faniky dat \u0161iroce vyu\u017e\u00edv\u00e1ny v \u00fasil\u00ed o kybernetickou propagaci \nV roce 2016 bylo nejv\u00fdrazn\u011bj\u0161\u00edm vyu\u017eit\u00edm t\u00e9to techniky v USA \u00fanik e-mail\u016f \nDemokratick\u00e9ho n\u00e1rodn\u00edho v\u00fdboru (DNC) prost\u0159ednictv\u00edm str\u00e1nky dcleaks.com, kter\u00e1 \nse uskute\u010dnila t\u011bsn\u011b p\u0159ed jmenovac\u00ed dohodou strany. \n \nV roce 2017 kampa\u0148 francouzsk\u00e9ho prezidentsk\u00e9ho kandid\u00e1ta Emmanuela Macrona \nbyla ot\u0159esena \u00fanikem jejich vlastn\u00edch e-mailov\u00fdch zpr\u00e1v. Archivy unikly jen n\u011bkolik \nhodin p\u0159edt\u00edm, ne\u017e za\u010dalo moratorium na pokryt\u00ed kampan\u011b ve francouzsk\u00fdch \nsd\u011blovac\u00edch prost\u0159edc\u00edch. V tomto p\u0159\u00edpad\u011b Macron volby stejn\u011b vyhr\u00e1l. (11) \n \nObecn\u00e9 vn\u00edm\u00e1n\u00ed politik\u016f jako nepoctiv\u00fdch lid\u00ed d\u011bl\u00e1 \u00fanik e-mail\u016f a dal\u0161\u00edch citliv\u00fdch \ndokument\u016f od politik\u016f docela efektivn\u00ed. Koneckonc\u016f, pokud voli\u010d v\u011b\u0159\u00ed, \u017ee jim politik \nu\u017e l\u017ee, mohou b\u00fdt ochotn\u011bj\u0161\u00ed uv\u011b\u0159it tvrzen\u00edm, kter\u00e1 se v jeho e-mailu pravd\u011bpodobn\u011b \nnach\u00e1zej\u00ed. Hlasit\u00e9 protesty o tom, jak byl politik hacknut, d\u011blaj\u00ed unikl\u00e9 zpr\u00e1vy v\u00edce \nv\u011brohodn\u011bj\u0161\u00ed ne m\u00e9n\u011b. \n \nOhro\u017een\u00ed nejsou jen politi\u010dt\u00ed p\u0159edstavitel\u00e9. Nap\u0159\u00edklad mexi\u010dt\u00ed novin\u00e1\u0159i jsou b\u011b\u017en\u011b \nobt\u011b\u017eov\u00e1ni roboty na Twitteru pod kontrolou drogov\u00fdch kartel\u016f. Sou\u010d\u00e1st\u00ed toho jsou \nhrozby smrti. V zemi, o n\u00ed\u017e je zn\u00e1mo, \u017ee je pro novin\u00e1\u0159e jednou z nejnebezpe\u010dn\u011bj\u0161\u00edch \nna sv\u011bt\u011b, je t\u0159eba takov\u00e9 hrozby br\u00e1t v\u00e1\u017en\u011b. Nem\u011blo by tedy b\u00fdt p\u0159ekvapen\u00edm, \u017ee do \ngalerie ob\u011bt\u00ed bombardov\u00e1n\u00ed v Manchesteru byl p\u0159id\u00e1n obr\u00e1zek jedn\u00e9 prominentn\u00ed \nmexick\u00e9 novin\u00e1\u0159ky (Andrea Noel). Obr\u00e1zek byl \u0161iroce p\u0159ij\u00edm\u00e1n jako autentick\u00fd a \ndistribuov\u00e1n \u0159adou sleduj\u00edc\u00edch a medi\u00e1ln\u00edch web\u016f, ani\u017e by si toho byli v\u011bdomi. (12) \n  \n \n \n \n \n \n 19 \u00daniky dat jsou tak\u00e9 velmi \u00fa\u010dinn\u00fdmi n\u00e1stroji manipulace s ve\u0159ejn\u00fdm m\u00edn\u011bn\u00edm. \nSamotn\u00e1 skute\u010dnost, \u017ee do\u0161lo k \u00faniku, potvrzuje v\u0161echna unikl\u00e1 data jako legitimn\u00ed v \no\u010d\u00edch b\u011b\u017en\u00e9 populace. P\u0159edpokl\u00e1dejme, \u017ee dojde k \u00faniku a 99% dokument\u016f je \nlegitimn\u00edch, ale 1% bylo manipulov\u00e1no, aby pomohlo agend\u011b p\u016fvodce \u00faniku. \nOrganizace ob\u011bti bude m\u00edt t\u011b\u017ekosti dok\u00e1zat, \u017ee do\u0161lo k jak\u00e9koli manipulaci, nato\u017e kter\u00e9 \ndokumenty byly upraveny. Samotn\u00e1 skute\u010dnost, \u017ee do\u0161lo k \u00faniku, rovn\u011b\u017e naru\u0161uje \nd\u016fv\u011bryhodnost c\u00edle. (9) \n \nKyberterorismus \nNB\u00da / N\u00e1rodn\u00ed centrum kybernetick\u00e9 bezpe\u010dnosti definuje kyberterorismus takto: \n\u201eKyberterorismus zahrnuje agresivn\u00ed a excesivn\u00ed jedn\u00e1n\u00ed, kter\u00e9 je prov\u00e1d\u011bno se \nz\u00e1m\u011brem vyvolat strach ve spole\u010dnosti, a jeho\u017e prost\u0159ednictv\u00edm je dosahov\u00e1no \npolitick\u00fdch, n\u00e1bo\u017eensk\u00fdch nebo ideologick\u00fdch c\u00edl\u016f. Za vyu\u017eit\u00ed kyberprostoru a \ninforma\u010dn\u00edch a komunika\u010dn\u00edch technologi\u00ed ohro\u017euje chod st\u00e1tu, jeho \u00fastavn\u00ed z\u0159\u00edzen\u00ed \nnebo obranyschopnost mimo jin\u00e9 c\u00edlen\u00edm na kritickou informa\u010dn\u00ed infrastrukturu a \nv\u00fdznamn\u00e9 informa\u010dn\u00ed syst\u00e9my.\u201c  \nV u\u017e\u0161\u00edm pojet\u00ed lze za kyberterorismus pova\u017eovat pouze takov\u00e9 teroristick\u00e9 aktivity v \nkyberprostoru, kter\u00e9 zp\u016fsob\u00ed rozs\u00e1hl\u00e9 naru\u0161en\u00ed po\u010d\u00edta\u010dov\u00fdch s\u00edt\u00ed \u010di za\u0159\u00edzen\u00ed se \nz\u00e1va\u017en\u00fdmi a\u017e fat\u00e1ln\u00edmi dopady. P\u0159i t\u011bchto \u00fatoc\u00edch m\u016f\u017ee doch\u00e1zet ke ztr\u00e1t\u00e1m na \n\u017eivotech \u010di v p\u0159\u00edpad\u011b kompromitace finan\u010dn\u00edho syst\u00e9mu k velmi z\u00e1va\u017en\u00fdm \nekonomick\u00fdm ztr\u00e1t\u00e1m s t\u011b\u017eko p\u0159edv\u00eddateln\u00fdmi d\u016fsledky. St\u00e1t se v\u0161ak v kyberprostoru \nmus\u00ed br\u00e1nit i p\u0159ed dal\u0161\u00edmi teroristick\u00fdmi aktivitami jak\u00fdmi jsou nap\u0159. podn\u011bcov\u00e1n\u00ed k \nnen\u00e1visti \u010di tvorba a \u0161\u00ed\u0159en\u00ed propagandy. V\u00fdznamnou roli zde hraj\u00ed tzv. nov\u00e1 m\u00e9dia. \n(13) \n \nVzhledem k rostouc\u00ed z\u00e1vislosti civilizace na informa\u010dn\u00edch a komunika\u010dn\u00edch \ntechnologi\u00edch se st\u00e1v\u00e1 jejich zranitelnost v\u00fdznamnou hrozbou. \u010c\u00edm v\u00edce v\u011bc\u00ed bude \np\u0159ipojeno (stane se sou\u010d\u00e1st\u00ed kyberprostoru), s t\u00edm v\u011bt\u0161\u00edm rizikem zneu\u017eit\u00ed tedy mus\u00edme \npo\u010d\u00edtat. Je tedy ot\u00e1zkou, zda jsme dostate\u010dn\u011b p\u0159ipraveni na tyto \u00fatoky a jak se na n\u011b \np\u0159ipravovat, aby to nebylo \u201ezbrojen\u00ed na minulou v\u00e1lku\u201c. Jak ji\u017e bylo nazna\u010deno \u201e\u00fatok\u201c \nnemus\u00ed b\u00fdt pouze na spole\u010dnosti ve v\u00fdznamu komer\u010dn\u00edch subjekt\u016f. C\u00edlem \u00fatoku se \nm\u016f\u017ee st\u00e1t spole\u010dnost jako celek \u010di n\u00e1rod konkr\u00e9tn\u00edho st\u00e1tu, ale i jedinec pohybuj\u00edc\u00ed se \n \n \n \n \n \n 20 na soci\u00e1ln\u00edch s\u00edt\u00edch.  A\u010dkoliv se mnoz\u00ed politici sna\u017e\u00ed uzav\u0159\u00edt hranice st\u00e1tu v\u016f\u010di \np\u0159\u00edchoz\u00edm migrant\u016fm a t\u00edm i p\u0159\u00edchodu potencion\u00e1ln\u00edch terorist\u016f, kyberprostor \u017e\u00e1dn\u00e9 \ntakov\u00e9 hranice nerespektuje. Propaganda na soci\u00e1ln\u00edch s\u00edt\u00edch, webu m\u016f\u017ee \u201evychovat\u201c \nteroristy v ob\u010danech zasa\u017een\u00fdch st\u00e1t\u016f. Velkou s\u00edlu uk\u00e1zal nap\u0159\u00edklad ISIS v n\u00e1boru \nbojovn\u00edk\u016f. (13) \n   \n3.2.5 Zpr\u00e1vy na soci\u00e1ln\u00edch s\u00edt\u00edch \nV\u00fdzkumn\u00e1 studie Pew z kv\u011btna 2016 zjistila, \u017ee 62 % dosp\u011bl\u00fdch v Americe z\u00edsk\u00e1v\u00e1 \nzpr\u00e1vy p\u0159es soci\u00e1ln\u00ed m\u00e9dia a 18 % z nich se pravideln\u011b spol\u00e9h\u00e1 na pouze na zpr\u00e1vy ze \nsoci\u00e1ln\u00edch m\u00e9di\u00ed. Stejn\u011b jako u\u017eivatel\u00e9 Facebooku, i u\u017eivatel\u00e9 Reddit, Twitter a \nTumblr konzumuj\u00ed na t\u011bchto str\u00e1nk\u00e1ch obrovsk\u00e9 mno\u017estv\u00ed zpr\u00e1v. (14) \n \n3.3 Anal\u00fdza technologick\u00fdch postup\u016f pro z\u00edsk\u00e1n\u00ed dat \nWeb Scraping \nWeb Scraping je sada softwarov\u00fdch technik pou\u017e\u00edvan\u00fdch k automatick\u00e9mu z\u00edsk\u00e1v\u00e1n\u00ed \nn\u011bkter\u00fdch informac\u00ed z webov\u00fdch str\u00e1nek m\u00edsto ru\u010dn\u00edho kop\u00edrov\u00e1n\u00ed. C\u00edlem web Scrapingu \nje hledat ur\u010dit\u00e9 druhy informac\u00ed, extrahovat je a agregovat. Zejm\u00e9na se zam\u011b\u0159uje na \ntransformaci nestrukturovan\u00fdch dat na webu, obvykle ve form\u00e1tu HTML, do \nstrukturovan\u00fdch dat, kter\u00e1 lze ulo\u017eit a analyzovat v centr\u00e1ln\u00ed m\u00edstn\u00ed datab\u00e1zi nebo tabulce. \nN\u00e1stroje nebo p\u0159\u00edstupy obvykle simuluj\u00ed lidsk\u00e9 zkoum\u00e1n\u00ed World Wide Webe bu\u010f \nimplementac\u00ed protokol p\u0159enosu hypertextu n\u00edzk\u00e9 \u00farovn\u011b nebo simulac\u00ed vhodn\u00fdch \nwebov\u00fdch prohl\u00ed\u017ee\u010d\u016f. Scraping webu \u00fazce souvis\u00ed s indexov\u00e1n\u00edm webu, co\u017e je technika \nz\u00edsk\u00e1v\u00e1n\u00ed informac\u00ed p\u0159ijat\u00e1 n\u011bkolika vyhled\u00e1va\u010di k indexov\u00e1n\u00ed informac\u00ed na webu za \npomoci bot\u016f. Naproti tomu se web scraping zam\u011b\u0159uje na transformaci nestrukturovan\u00fdch \ndat na webu. (15) \n  \n \n \n \n \n \n 21 N\u00e1stroje a slu\u017eby pro web scraping: \nScraper API \nN\u00e1stroj pro v\u00fdvoj\u00e1\u0159e usnad\u0148ujic\u00ed tvrobu vlastn\u00edch program\u016f, zpracov\u00e1v\u00e1 proxy servery, \nprohl\u00ed\u017ee\u010de a captcha. V\u00fdhodou je, \u017ee slu\u017eba m\u00e1 \u0159adu vlastn\u00edch proxy server\u016f, spravuje \nvlastn\u00ed intern\u00ed fond v\u00edce ne\u017e stovek tis\u00edc proxy server\u016f m\u00e1 inteligentn\u00ed sm\u011brovac\u00ed logiku, \nkter\u00e1 sm\u011bruje po\u017eadavky prost\u0159ednictv\u00edm r\u016fzn\u00fdch pods\u00edt\u00ed a automaticky \u0161krt\u00ed po\u017eadavky \nv po\u0159ad\u00ed, aby se zabr\u00e1nilo z\u00e1kaz\u016fm na z\u00e1kald\u011b ip adresy a captchy.  \nDostupn\u00e9 na: https://www.scraperapi.com  (16) \n \nScrapeSimple \nSlu\u017eba pro u\u017eivatele, kte\u0159\u00ed si cht\u011bj\u00ed nechat napsat vlastn\u00ed program. Sb\u011br dat na webu je tak \njednoduch\u00fd, jako vypl\u0148ov\u00e1n\u00ed formul\u00e1\u0159e s pokyny, jak\u00fd druh dat u\u017eivatel po\u017eaduje. Sta\u010d\u00ed \nsd\u011blit, jak\u00e9 informace pot\u0159ebuje, z jak\u00fdch web\u016f, a navrhnou vlastn\u00ed program, kter\u00e1 bude \npravideln\u011b poskytovat informace (mohou b\u00fdt denn\u011b, t\u00fddn\u011b, m\u011bs\u00ed\u010dn\u011b) ve form\u00e1tu CSV \np\u0159\u00edmo do mailov\u00e9 schr\u00e1nky. Tato slu\u017eba je ide\u00e1ln\u00ed pro u\u017eivatele, kte\u0159\u00ed nemaj\u00ed \u017e\u00e1dnou \nznalost programov\u00e1n\u00ed.  \nDostupn\u00e9 na: https://www.scrapesimple.com  (17) \n \nOctoparse \nN\u00e1stroj pro u\u017eivatele, kte\u0159\u00ed cht\u011bj\u00ed extrahovat data z webov\u00fdch str\u00e1nek bez nutnosti \nk\u00f3dov\u00e1n\u00ed, a p\u0159esto maj\u00ed kontrolu nad cel\u00fdm procesem pomoc\u00ed snadno pou\u017eiteln\u00e9ho \nu\u017eivatelsk\u00e9ho rozhran\u00ed. Data si u\u017eivatel ozna\u010d\u00ed pomoc\u00ed interaktivn\u00edho zobrazen\u00ed \npo\u017eadovan\u00e9 str\u00e1nky. \nDosutpn\u00e9 na: https://www.octoparse.com/ (18) \n \nScrapy \nScrapy je webov\u00e1 scrapingov\u00e1 knihovna pro v\u00fdvoj\u00e1\u0159e Pythonu, kte\u0159\u00ed cht\u011bj\u00ed ps\u00e1t \n\u0161k\u00e1lovateln\u00e9 webov\u00e9 moduly. Jedn\u00e1 se o framework pro proch\u00e1zen\u00ed webu, kter\u00fd \nzpracov\u00e1v\u00e1 mno\u017estv\u00ed obt\u00ed\u017e\u00ed (po\u017eadavky ve front\u011b, proxy middleware atd.), kter\u00e9 jinak \nzt\u011b\u017euj\u00ed vytv\u00e1\u0159en\u00ed webov\u00fdch modul\u016f. \n  \n \n \n \n \n \n 22 Podporovan\u00e9 funkce \nExportuje data, kter\u00e1 shroma\u017e\u010fuje, do n\u011bkolika form\u00e1t\u016f, jako je JSON nebo CSV, a ukl\u00e1d\u00e1 \nje na pozad\u00ed podle u\u017eivatelsk\u00e9ho v\u00fdb\u011bru. M\u00e1 \u0159adu vestav\u011bn\u00fdch roz\u0161\u00ed\u0159en\u00ed pro \u00fakoly, jako je \nmanipulace s cookies, spoofing u\u017eivatelsk\u00fdch agent\u016f, omezen\u00ed hloubky proch\u00e1zen\u00ed a dal\u0161\u00ed. \nM\u00e1 API pro snadn\u00e9 vytv\u00e1\u0159en\u00ed vlastn\u00edch dopl\u0148k\u016f. Scrapy tak\u00e9 nab\u00edz\u00ed cloud pro hosting \npavouk\u016f, kde se pavouci daj\u00ed \u0161k\u00e1lovat podle pot\u0159eby a b\u011b\u017e\u00ed od tis\u00edc\u016f k miliard\u00e1m.  \n \nPavouci \nPavouci jsou t\u0159\u00eddy, kter\u00e9 definuj\u00ed, jak dolovat data z ur\u010dit\u00e9ho webu (nebo skupiny web\u016f), \nv\u010detn\u011b toho, jak prov\u00e9st proch\u00e1zen\u00ed (tj. Sledovat odkazy) a jak extrahovat strukturovan\u00e1 \ndata z jejich str\u00e1nek (tj. V anglick\u00e9m origin\u00e1le Scraping polo\u017eek). Jin\u00fdmi slovy, pavouci \njsou m\u00edstem, kde definujete vlastn\u00ed chov\u00e1n\u00ed pro proch\u00e1zen\u00ed a anal\u00fdzu str\u00e1nek pro konkr\u00e9tn\u00ed \nweb (nebo v n\u011bkter\u00fdch p\u0159\u00edpadech skupinu web\u016f). \n  \nU pavouk\u016f proch\u00e1z\u00ed dolovac\u00ed cyklus n\u011b\u010d\u00edm podobn\u00fdm \nZa\u010dnete generov\u00e1n\u00edm po\u010d\u00e1te\u010dn\u00edch po\u017eadavk\u016f na proch\u00e1zen\u00ed prvn\u00edch adres URL a ur\u010dete \nfunkci zp\u011btn\u00e9ho vol\u00e1n\u00ed, kter\u00e9 se m\u00e1 volat s odpov\u011bd\u00ed sta\u017eenou z t\u011bchto po\u017eadavk\u016f. \nPrvn\u00ed po\u017eadavky, kter\u00e9 maj\u00ed b\u00fdt provedeny, se z\u00edskaj\u00ed vol\u00e1n\u00edm metody start_requests (), \nkter\u00e1 (ve v\u00fdchoz\u00edm nastaven\u00ed) generuje po\u017eadavek na URL zadan\u00e9 v start_urls a metodu \nparse jako funkci zp\u011btn\u00e9ho vol\u00e1n\u00ed pro po\u017eadavky. \n  \nVe funkci zp\u011btn\u00e9ho vol\u00e1n\u00ed analyzujete odpov\u011b\u010f (webovou str\u00e1nku) a vr\u00e1t\u00edte bu\u010f p\u0159\u00edkazy s \nextrahovan\u00fdmi daty, objekty polo\u017eek, objekty po\u017eadavk\u016f, nebo iterovateln\u00e9 tyto objekty. \nTyto po\u017eadavky budou tak\u00e9 obsahovat zp\u011btn\u00e9 vol\u00e1n\u00ed (mo\u017en\u00e1 stejn\u00e9) a pot\u00e9 budou sta\u017eeny \npomoc\u00ed Scrapy a jejich odpov\u011b\u010f bude zpracov\u00e1na zadan\u00fdm zp\u011btn\u00fdm vol\u00e1n\u00ed. \n  \nVe funkc\u00edch zp\u011btn\u00e9ho vol\u00e1n\u00ed analyzujete obsah str\u00e1nky, obvykle pomoc\u00ed selektor\u016f (ale \nm\u016f\u017eete tak\u00e9 pou\u017e\u00edt BeautifulSoup, lxml nebo jak\u00fdkoli jin\u00fd preferovan\u00fd mechanismus) a \ngenerovat polo\u017eky s analyzovan\u00fdmi daty. \n  \n  \n \n \n \n \n \n 23 Nakonec budou polo\u017eky vr\u00e1cen\u00e9 z pavouka obvykle olo\u017eeny do datab\u00e1ze, nebo zapisov\u00e1ny \ndo souboru pomoc\u00ed exportu zdroje. \nDostupn\u00e9 na: https://scrapy.org  (19) \n \nDiffbot \nDiffbot se li\u0161\u00ed od v\u011bt\u0161iny uveden\u00fdch n\u00e1stroj\u016f, proto\u017ee pou\u017e\u00edv\u00e1 po\u010d\u00edta\u010dov\u00e9 vid\u011bn\u00ed (m\u00edsto \nhtml anal\u00fdzy) k identifikaci relevantn\u00edch informac\u00ed na str\u00e1nce. To znamen\u00e1, \u017ee i kdy\u017e se \nzm\u011bn\u00ed struktura HTML str\u00e1nky, program bude fungovat, pokud str\u00e1nka vypad\u00e1 vizu\u00e1ln\u011b \nstejn\u011b. \nDostupn\u00e9 na: https://www.diffbot.com  (20) \n \nCheerio \nUr\u010deno pro v\u00fdvoj\u00e1\u0159e v NodeJS, kte\u0159\u00ed cht\u011bj\u00ed p\u0159\u00edm\u00fd zp\u016fsob anal\u00fdzy HTML. N\u00e1stroj ocen\u00ed ti, \nkte\u0159\u00ed jsou obezn\u00e1meni s jQuery, proto\u017ee Cheerio nab\u00edz\u00ed API podobn\u00e9 jQuery. Jedn\u00e1 se o \nnejvyu\u017e\u00edvan\u011bj\u0161\u00ed knihovnu pro anal\u00fdzu html psanou v NodeJS. \nDostupn\u00e9 na : https://cheerio.js.org  (21) \n \nBeautiful Soup \nN\u00e1stroj ur\u010den\u00fd pro v\u00fdvoj\u00e1\u0159e v Pythonu, kte\u0159\u00ed cht\u011bj\u00ed jednoduch\u00e9 rozhran\u00ed pro anal\u00fdzu \nHTML a nemus\u00ed nutn\u011b pot\u0159ebovat s\u00edlu a slo\u017eitost, kter\u00e1 je sou\u010d\u00e1st\u00ed aplikace Scrapy. \nDostupn\u00e9 na: https://www.crummy.com/software/BeautifulSoup/  (22) \n3.4 Anal\u00fdza dosahu a dopadu \u0161\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00ed \nPr\u016fb\u011bh anal\u00fdzy soci\u00e1ln\u00edch s\u00edt\u00ed nem\u00e1 \u017e\u00e1dn\u00fd pevn\u00fd r\u00e1mec. D\u016fvod, pro\u010d neexistuje jednotn\u00fd \nuniverz\u00e1ln\u00ed postup je prost\u00fd. Existuje mnoho soci\u00e1ln\u00edch s\u00edt\u00ed, neust\u00e1le zanikaj\u00ed a vznikaj\u00ed \nnov\u00e9 a sou\u010dasn\u00e9 proch\u00e1zej\u00ed postupn\u00fdm mnohdy radik\u00e1ln\u00edm v\u00fdvojem. \n3.4.1 Obecn\u00fd postup \nMonitoring kl\u00ed\u010dov\u00fdch slov  \nKl\u00ed\u010dem k co nejlep\u0161\u00edmu vyu\u017eit\u00ed soci\u00e1ln\u00edch m\u00e9di\u00ed je poslech toho, co publikum \u0159\u00edk\u00e1 o \nzkouman\u00e9m t\u00e9matu, konkurentech a trhu obecn\u011b. Jakmile jsou z\u00edsk\u00e1na data, m\u016f\u017ee se \n \n \n \n \n \n 24 prov\u00e9st anal\u00fdza, na z\u00e1klad\u011b, kter\u00e9 lze p\u0159ipravit komunika\u010dn\u00ed strategii. Pom\u016f\u017ee n\u00e1m tak\u00e9 \nodhalit, zdali se na ur\u010dit\u00e9 soci\u00e1ln\u00ed s\u00edti dan\u00e9mu t\u00e9matu n\u011bkdo ji\u017e v\u011bnuje.  (1) \n \nAnal\u00fdza n\u00e1lad  \n \nUmo\u017e\u0148uje pomoc\u00ed m\u011b\u0159en\u00ed jednozna\u010dn\u00fdch metrik jako like/dislike, for/against ur\u010dit n\u00e1ladu \nokolo dan\u00e9ho t\u00e9matu. Sna\u017e\u00ed se zahrnout i n\u00e1lady p\u0159\u00edsp\u011bvk\u016f. To je obecn\u011b probl\u00e9m, jeliko\u017e \nstroj neum\u00ed dostate\u010dn\u011b odhalit sarkasmus, ironii atd. Proto v p\u0159\u00edpadech jako je p\u0159\u00edsp\u011bvek: \n\u201eNo to se jim zas poda\u0159ilo\u201c je pot\u0159eba lidsk\u00e9ho n\u00e1hledu pro ur\u010den\u00ed kontextu textu.  \nZm\u011bna n\u00e1lad, kterou dok\u00e1\u017eeme pomoc\u00ed anal\u00fdzy n\u00e1lad odhalit, n\u00e1m m\u016f\u017ee poskytnout \nv\u010dasnou indikaci nap\u0159\u00edklad p\u0159i nastal\u00e9m probl\u00e9mu. Nap\u0159\u00edklad p\u0159i probl\u00e9mu s ur\u010ditou \u010d\u00e1st\u00ed \nv\u00fdrobku n\u00e1m na soci\u00e1ln\u00edch s\u00edt\u00ed po\u010det fanou\u0161k\u016f pravd\u011bpodobn\u011b neklesne, ale m\u016f\u017ee se zv\u00fd\u0161it \nmno\u017estv\u00ed negativn\u00edch n\u00e1lad. Co\u017e n\u00e1m d\u00e1v\u00e1 \u0161anci adekv\u00e1tn\u011b reagovat na nastal\u00fd probl\u00e9m. \n \nOt\u00e1zky, na kter\u00e9 m\u016f\u017ee anal\u00fdza n\u00e1lad odpov\u00eddat:  \n\u2022 Je recenze na\u0161eho v\u00fdrobku pozitivn\u00ed nebo negativn\u00ed. \n\u2022 Je z\u00e1kazn\u00edk spokojen s na\u0161\u00ed odpov\u011bd\u00ed, komunikac\u00ed. \n\u2022 Na z\u00e1klad\u011b vzorku tweet\u016f, jak lid\u00e9 reaguj\u00ed na danou reklamn\u00ed kampa\u0148, produkt. \n\u2022 Existuj\u00ed n\u011bjak\u00e9 vzorce chov\u00e1n\u00ed z\u00e1kazn\u00edka dle aktu\u00e1ln\u00edho d\u011bn\u00ed ve spole\u010dnosti, kter\u00e9 \nby m\u011bli vliv na na\u0161i firmu. \n \nAnal\u00fdza n\u00e1lad m\u016f\u017ee prob\u00edhat dva zp\u016fsoby monitoringu: \n \no Aktivn\u00ed monitoring \n Znamen\u00e1, \u017ee se na n\u00e1ladu zept\u00e1me, sna\u017e\u00edme se zjistit n\u00e1lady aktivn\u00edm p\u0159\u00edstupem. \n\uf0a7 Anketa, hlasov\u00e1n\u00ed, dotazn\u00edk. \n\uf0a7 V\u00fdsledky ankety se mus\u00ed normalizovat na c\u00edlovou b\u00e1zi klient\u016f  \n\uf0a7 Do ankety nejdou v\u0161ichni potenci\u00e1ln\u00ed z\u00e1kazn\u00edci, \u00fa\u010dastn\u00edci mohou ovliv\u0148ovat \nv\u00fdsledky ve sv\u016fj prosp\u011bch znaj\u00ed-li v\u00fdsledky p\u0159edem, ovlivn\u011bn\u00ed n\u00e1zorem v\u011bt\u0161iny. \n\uf0a7 Omezen\u00fd rozsah voleb -> nelze zjistit n\u011bco, co v anket\u011b nen\u00ed. \n\uf0a7 Mo\u017en\u00fdm \u0159e\u0161en\u00edm omezen\u00ed voleb je forma interview, p\u0159i kter\u00e9 respondent m\u016f\u017ee u \nn\u011bkter\u00fdch ot\u00e1zek odpov\u011bd\u011bt dle sv\u00e9ho.  \n \n \n \n \n \n 25 \uf0a7 Aktivn\u00ed monitoring m\u016f\u017ee p\u0159in\u00e9st zaj\u00edmav\u00e9 informace, ale jeho proveden\u00ed je obecn\u011b \nvelice n\u00e1ro\u010dn\u00e9 a v prost\u0159ed\u00ed soci\u00e1ln\u00edch s\u00edt\u00ed obzvl\u00e1\u0161t\u011b. \n \no Pasivn\u00ed monitoring \nPasivn\u00ed monitoring znamen\u00e1, \u017ee naslouch\u00e1me. Na n\u00e1ladu se tedy nept\u00e1me, ale \nprohled\u00e1v\u00e1me soci\u00e1ln\u00ed s\u00edt\u011b a monitorujeme d\u011bn\u00ed okolo na\u0161\u00ed zna\u010dky, segmentu, konkurenci. \n \nN\u00e1lady jsou subjektivn\u00ed vyj\u00e1d\u0159en\u00ed pocitu. Pro na\u0161e \u00fa\u010dely, ale pot\u0159ebujeme objektivn\u00ed, \nnejl\u00e9pe \u010d\u00edseln\u00e9 vyj\u00e1d\u0159en\u00ed. Sna\u017e\u00edme se tedy o objektivizaci subjektivn\u00edch n\u00e1zor\u016f. \nZjednodu\u0161en\u011b m\u016f\u017eeme n\u00e1lady \u010dlenit jako pozitivn\u00ed, neutr\u00e1ln\u00ed a negativn\u00ed. \n \nSubjektivn\u00ed tvrzen\u00ed lze tak\u00e9 d\u011blit od n\u011bkolika kategori\u00ed: \n\u2022 Subjektivn\u00ed tvrzen\u00ed: Je tvrzen\u00ed zalo\u017een\u00e9 na v\u011bdom\u00e9m p\u0159esv\u011bd\u010den\u00ed o pravdivosti \ntvrzen\u00ed. Nap\u0159\u00edklad \u201cV\u00fdrobek firmy XY se v\u017edy porouch\u00e1 t\u011bsn\u011b po z\u00e1ru\u010dn\u00ed dob\u011b.\u201d \n\u2022 N\u00e1zor: P\u0159edstavuje vyj\u00e1d\u0159en\u00ed osobn\u00edho p\u0159esv\u011bd\u010den\u00ed. \u201eM\u011bl bys koupit v\u00fdrobek firmy \nXY, ten je nejlep\u0161\u00ed\u201c. \n\u2022  N\u00e1lada: P\u0159edstavuje vyj\u00e1d\u0159en\u00ed ur\u010dit\u00e9ho osobn\u00edho vztahu. \u201cMiluji filmy s hercem \nXY.\u201d \nObecn\u00fd postup pro pr\u00e1ci s v\u00fdsledky monitoringu pro anal\u00fdzu n\u00e1lad: \n \nJednotliv\u00e9 n\u00e1zory ozna\u010d\u00edme jako pozitivn\u00ed, negativn\u00ed neutr\u00e1ln\u00ed. \nV\u00fdsledky je vhodn\u00e9 pro snadn\u011bj\u0161\u00ed interpretaci p\u0159en\u00e9st do grafu, d\u00edky tomu m\u016f\u017eeme vid\u011bt, \njak se n\u00e1lada vyv\u00edjela v z\u00e1vislosti na \u010dase.  \nKe grafu p\u0159ipojte ud\u00e1losti t\u00fdkaj\u00edc\u00ed se va\u0161\u00ed zna\u010dky, jako zm\u00ednky o firm\u011b v m\u00e9di\u00edch, reklamn\u00ed \nkampa\u0148 a jin\u00e9. \nJe velice vhodn\u00e9 sna\u017eit se naj\u00edt spou\u0161t\u011b\u010de zm\u011bny n\u00e1lad, tedy d\u016fvody, pro\u010d se zm\u011bnila \nn\u00e1lada, zm\u011bnil se po\u010det citac\u00ed. T\u00edm z\u00edsk\u00e1me mo\u017enost odhalit dopady marketingov\u00fdch \nstrategi\u00ed, ale i mo\u017enost odhalit alfa \u010dleny soci\u00e1ln\u00edch skupin kter\u00fdm jsme nep\u0159ikl\u00e1dali \nvelkou v\u00e1hu, a p\u0159esto ovlivnili n\u00e1lady v soci\u00e1ln\u00edch skupin\u00e1ch. (23) \n \n \n \n \n \n 26 3.4.2 Hled\u00e1n\u00ed vhodn\u00e9ho prost\u0159ed\u00ed pro komunikaci. \nM\u00e1me mo\u017enost sledovat, v\u00fdvoj vn\u00edm\u00e1n\u00ed dan\u00e9ho produktu, slu\u017eeb a zna\u010dky sledovan\u00e9 \nfirmy v \u010dasov\u00e9m horizontu, odkud je z geografick\u00e9ho hlediska nejlep\u0161\u00ed odezva, jak\u00fd dopad \na\u0165 ji\u017e pozitivn\u00ed, nebo negativn\u00ed maj\u00ed ud\u00e1losti a vystupov\u00e1n\u00ed firmy a pou\u010dit se z t\u011bchto \npoznatk\u016f. D\u00edky t\u011bmto poznatk\u016fm nastavit \u00fasp\u011b\u0161nou strategii p\u0159\u00edstupu komunikace, \nvystupov\u00e1n\u00ed atd. \nZji\u0161\u0165ujeme: \n\uf0b7 \u010c\u00edm jsou dan\u00e9 soci\u00e1ln\u00ed s\u00edt\u011b typick\u00e9. \no Sd\u00edlen\u00edm kr\u00e1tk\u00fdch videoklip\u016f (Snapchat) \no Sd\u00edlen\u00edm Tweet\u016f (Twitter) \no Soust\u0159ed\u011bn\u00edm na jedno t\u00e9ma? (Rodina.cz) \n\uf0b7 Jak\u00e9 jsou soci\u00e1ln\u00ed s\u00edt\u011b, na kter\u00e9 chcete vstoupit \n\uf0b7 Kolik je zde u\u017eivatel\u016f \n\uf0b7 Bonita \n\uf0b7 Potenci\u00e1l \no Strm\u00fd n\u00e1r\u016fst u\u017eivatel\u016f v sou\u010dasnosti \no Neot\u0159el\u00fd n\u00e1pad \n\uf0b7 Kl\u00ed\u010dov\u00e9 prvky \no Mo\u017enosti pou\u017eit\u00ed analytick\u00fdch n\u00e1stroj\u016f \no Otev\u0159enost profil\u016f: Nap\u0159\u00edklad pro Twitter je typick\u00e9 nastaven\u00ed otev\u0159en\u00fdch \nprofil\u016f. Naproti tomu u\u017eivatel\u00e9 Facebooku maj\u00ed mnohdy nastaven\u00e9 \nsoukrom\u00ed, tak aby jejich \u010dinnost na Facebooku mohli vid\u011bt pouze p\u0159\u00e1tel\u00e9 \natd.  \n\uf0b7 Mo\u017enosti monetizace \n\uf0b7 Kl\u00ed\u010dov\u00e9 prvky dan\u00e9 soci\u00e1ln\u00ed s\u00edt\u011b \n\uf0b7 Stanoven\u00ed t\u00e9ma \n\uf0b7 Nalezen\u00ed skupin \no P\u0159i v\u00fdb\u011bru soci\u00e1ln\u00ed s\u00edt\u011b, kter\u00e1 nen\u00ed orientov\u00e1na na jedno t\u00e9ma mus\u00edme \nv dan\u00e9 soci\u00e1ln\u00ed s\u00edti naj\u00edt skupiny lid\u00ed, kte\u0159\u00ed se o dan\u00e9 t\u00e9ma zaj\u00edmaj\u00ed, nebo by \nmohly b\u00fdt potencion\u00e1ln\u00edmi z\u00e1kazn\u00edky. \n \n \n \n \n \n 27 o V t\u00e9to \u010d\u00e1sti anal\u00fdzy op\u011bt m\u016f\u017eeme vyu\u017e\u00edt kl\u00ed\u010dov\u00e1 slova a jejich pomoc\u00ed naj\u00edt \nkonkr\u00e9tn\u00ed skupiny, u n\u011bkter\u00fdch str\u00e1nek s otev\u0159en\u00fdmi \u00fa\u010dty mo\u017en\u00e1 i konkr\u00e9tn\u00ed \nu\u017eivatele. \n \n\uf0b7 Nalezen\u00ed alfa u\u017eivatel\u016f skupiny: \no Nalezen\u00ed alfa u\u017eivatel\u016f je samoz\u0159ejm\u011b mo\u017en\u00e9 i ru\u010dn\u011b.  \n\uf0a7 Po nalezen\u00ed skupin a str\u00e1nek v\u011bnovan\u00fdch na\u0161emu t\u00e9matu str\u00e1nky \nprojdeme a ru\u010dn\u011b vyp\u00ed\u0161eme nap\u0159\u00edklad do Excelu ty u\u017eivatele, kte\u0159\u00ed \nv nich \u017eiv\u011b diskutuj\u00ed. Z t\u011bchto u\u017eivatel\u016f se pak budeme sna\u017eit vybrat \nnejvlivn\u011bj\u0161\u00ed u\u017eivatele podle po\u010dtu jejich p\u0159\u00e1tel, dosah\u016f jejich \np\u0159\u00edsp\u011bvk\u016f, validit\u011b jejich p\u0159\u00edsp\u011bvk\u016f a podobn\u011b. Tento zp\u016fsob je \nkv\u016fli \u010dasov\u00e9 n\u00e1ro\u010dnosti skute\u010dn\u011b mo\u017en\u00fd jen u men\u0161\u00edch skupin.  \n \no vyhledejte, kdo o t\u00e9matu hovo\u0159\u00ed (ti pro n\u00e1s nejsou a\u017e tak zaj\u00edmav\u00ed) \no kdo k t\u00e9matu nejv\u00edce odpov\u00edd\u00e1 (to jsou pravd\u011bpodobn\u011b alfa u\u017eivatel\u00e9) \no kdo m\u00e1 nejv\u00edce p\u0159\u00e1tel, kontakt\u016f (validuje v\u00fdznam alfa u\u017eivatele) \no sledujte, jak na jeho reakce reaguj\u00ed ostatn\u00ed alfa u\u017eivatel\u00e9 (odstra\u0148te excesy, \ndiskusn\u00ed trolly atd.) \no Velmi \u00fa\u010dinn\u00e9 m\u016f\u017ee b\u00edt c\u00edlen\u00ed na tyto u\u017eivatele pomoc\u00ed soci\u00e1ln\u00edch bot\u016f (24) \n3.5 Zp\u016fsoby \u0161\u00ed\u0159en\u00ed fake news \nExistuj\u00ed slu\u017eby umo\u017e\u0148uj\u00edc\u00ed propagaci a distribuci fale\u0161n\u00fdch zpr\u00e1v. Cenov\u00fd model je v \ntakovou chv\u00edli celkem pevn\u011b dan\u00fd: za pevn\u011b danou finan\u010dn\u00ed \u010d\u00e1stku dod\u00e1 poskytovatel \nslu\u017eby p\u0159esn\u011b dan\u00fd po\u010det akc\u00ed. P\u0159\u00edkladem akc\u00ed jsou reakce u p\u0159\u00edsp\u011bvk\u016f, po\u010det sleduj\u00edc\u00edch, \nkoment\u00e1\u0159e atd. N\u011bkter\u00e9 slu\u017eby vyu\u017e\u00edvaj\u00ed boty, jin\u00e9 garantuj\u00ed vyu\u017eit\u00ed lid\u00ed nam\u00edsto bot\u016f, aby \nse p\u0159ede\u0161lo postih\u016fm od provozovatel\u016f soci\u00e1ln\u00edch s\u00edt\u00ed. \nZ\u00e1rove\u0148 \u010dl\u00e1nky mus\u00ed p\u0159it\u00e1hnout pozornost re\u00e1ln\u00fdch u\u017eivatel\u016f, \u010dasto tedy m\u00ed\u0159\u00ed na siln\u00e9 \nemoce. \n \n \n \n \n \n \n 28 Nav\u00edc n\u011bkter\u00e9 slu\u017eby vyu\u017e\u00edvaj\u00ed komunitn\u00edho mechanismu, aby p\u0159im\u011bli u\u017eivatele k akc\u00edm \npodporuj\u00edc\u00edm klienta z\u00e1jmy v \u0161\u00ed\u0159en\u00ed fake news. Nap\u0159\u00edklad u\u017eivatel\u016fm je nab\u00eddnut ur\u010dit\u00fd \npo\u010det likes na jejich vlastn\u00ed posty, kdy\u017e ud\u011blaj\u00ed dostate\u010dn\u00fd po\u010det p\u0159edepsan\u00fdch akc\u00ed.  \nV\u00fdroba fake news vy\u017eaduje st\u00e1le v\u00edce komplexn\u00edch n\u00e1stroj\u016f a online prost\u0159ed\u00ed je takov\u00fdch \nn\u00e1stroj\u016f pln\u00e9. V z\u00e1sad\u011b lze n\u011bkter\u00e9 ze slu\u017eeb, pou\u017e\u00edvat legitimn\u011b, nap\u0159\u00edklad v obsahov\u00e9m \nmarketingu, ale jako ka\u017ed\u00fd jin\u00e9ho mocn\u00e9ho n\u00e1stroje, vid\u00edme, jak se diskutuje v \nunderground f\u00f3rech, zneu\u017e\u00edv\u00e1n\u00ed se a vyu\u017e\u00edv\u00e1 k \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v a manipulaci \nve\u0159ejn\u00e9ho m\u00edn\u011bn\u00ed. \nTyto nab\u00eddky jsou k dispozici na online underground trz\u00edch a v n\u011bkter\u00fdch ohledech je lze \npova\u017eovat za n\u00e1r\u016fst st\u00e1vaj\u00edc\u00edch slu\u017eeb, jako je Black Hat (SEO), podvody s klik\u00e1n\u00edm (click \nfraud) a n\u00e1kup n\u00e1v\u0161t\u011bvnosti webu prost\u0159ednictv\u00edm re\u00e1ln\u00fdch u\u017eivatel\u016f a bot\u016f. \nPodvody s klik\u00e1n\u00edm se v\u0161ak d\u00edky pokrok\u016fm v technologi\u00edch odhalov\u00e1n\u00ed podvod\u016f s \nklik\u00e1n\u00edm staly m\u00e9n\u011b lukrativn\u00ed. Tomu \u010delili tv\u016frci online underground n\u00e1stroj\u016f t\u00edm, \u017ee \np\u0159esm\u011brovali sv\u00e9 dovednosti na rozvoj slu\u017eeb propagace na soci\u00e1ln\u00edch m\u00e9di\u00edch. (25) \n \nNab\u00eddka se li\u0161\u00ed a odr\u00e1\u017e\u00ed region\u00e1ln\u00ed rozd\u00edly v soci\u00e1ln\u00ed a online kultu\u0159e. Existuj\u00ed v\u0161ak \nspole\u010dn\u00e9 z\u00e1kladn\u00ed trendy s t\u00edm, jak jsou prod\u00e1v\u00e1ny: od vytv\u00e1\u0159en\u00ed a distribuce obsahu a\u017e po \numl\u010den\u00ed vybran\u00e9ho serveru, pokud to slou\u017e\u00ed \u00fa\u010delu z\u00e1kazn\u00edka. \n \nZat\u00edmco n\u011bkter\u00e9 \u010d\u00ednsk\u00e9 slu\u017eby nab\u00edzej\u00ed vytv\u00e1\u0159en\u00ed, distribuci a \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v, \nn\u011bkte\u0159\u00ed tak\u00e9 nab\u00edzej\u00ed opak, kter\u00fdm je odeb\u00edr\u00e1n\u00ed obsahu. \n \n118t Negative News ( \u5927 \u826f \u9020 \u8d1f\u9762 \u4fe1\u606f \u7406) tuto slu\u017ebu nab\u00edz\u00ed. Na odstran\u011bn\u00ed zpr\u00e1vy \nnebo p\u0159\u00edsp\u011bvku na konkr\u00e9tn\u00ed url adrese je pot\u0159eba 3 a\u017e 5 dn\u00ed a poplatek z\u00e1vis\u00ed na popularit\u011b \nobsahu a na tom, kde je publikov\u00e1n. \n \nV roce 2012 Pekingsk\u00e1 policie uzav\u0159ela skupinu zn\u00e1mou jako \u201eYage Times\u201c, o kter\u00e9 bylo \nshled\u00e1no, \u017ee se anga\u017euje v podnik\u00e1n\u00ed sni\u017eov\u00e1n\u00ed negativn\u00ed publicity zpravodajsk\u00fdch \np\u0159\u00edb\u011bh\u016f, kter\u00e9 jsou pro z\u00e1kazn\u00edka nep\u0159\u00edzniv\u00e9. V roce 2011 skupina \u00fadajn\u011b vyd\u011blala touto \n\u010dinnost\u00ed 50 milion\u016f RMB. Zp\u016fsoby \u010dinnosti Yage Times zahrnovaly upl\u00e1cen\u00ed \nadministr\u00e1tor\u016f webov\u00e9 str\u00e1nky, ve kter\u00e9 je p\u0159\u00edb\u011bh publikov\u00e1n, nebo hacknut\u00ed na webov\u00e9 \nstr\u00e1nky za \u00fa\u010delem odstran\u011bn\u00ed \u010dl\u00e1nku. \n \n \n \n \n \n 29 Firma se s\u00eddlem v Rusku Weberaser m\u00e1 i anglickou verzi, kter\u00e1 se zam\u011b\u0159uje na odstran\u011bn\u00ed \nne\u017e\u00e1douc\u00edho obsahu nebo informac\u00ed z internetu nebo na odstran\u011bn\u00ed nejlep\u0161\u00edch v\u00fdsledk\u016f z \nvyhled\u00e1va\u010d\u016f. Cena z\u00e1vis\u00ed na slo\u017eitosti \u00fakolu a dostupn\u00e9m \u010dase, za\u010d\u00edn\u00e1 od 3 000 RUB. (26) \n \nCrowdsourcing propagace obsahu \nCo je pozoruhodn\u00e9 typicky v rusk\u00e9m undergroundu, je vyu\u017e\u00edv\u00e1n\u00ed crowdsourcingu k \nmanipulaci ve\u0159ejn\u00e9ho m\u00edn\u011bn\u00ed. Funguje to stejn\u011b jako jak\u00e1koli \u010dinnost v r\u00e1mci \ncrowdsourcingu: podpora projekt\u016f t\u00edm, \u017ee je z\u00edskaj\u00ed mnoho p\u0159\u00edsp\u011bvk\u016f od zna\u010dn\u00e9ho po\u010dtu \nlid\u00ed. (p\u0159\u00edsp\u011bvek ve form\u011b likes, sd\u00edlen\u00ed koment\u00e1\u0159 atd. Mnohdy v\u00fdm\u011bnou za z\u00edsk\u00e1n\u00ed jedn\u00e9 \nakce od ostatn\u00edch u\u017eivatel\u016f, zadavatel s\u00e1m provede p\u0159edem ur\u010den\u00fd po\u010det akc\u00ed na jin\u00e9 \nprojekty) \nP\u0159ijet\u00edm tohoto modelu, p\u0159ek\u00e1\u017eky vstupu na trh \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1vy a manipulace \nve\u0159ejn\u00e9ho m\u00edn\u011bn\u00ed jsou prakticky omezeny na pln\u011bn\u00ed \u00fakol\u016f a propagaci jin\u00e9ho obsahu s \nmal\u00fdm a\u017e \u017e\u00e1dn\u00fdm pen\u011b\u017en\u00edm kapit\u00e1lem. \n \nP\u0159\u00edklad: VTope je online slu\u017eba s v\u00edce ne\u017e 2 000 000 p\u0159ev\u00e1\u017en\u011b re\u00e1ln\u00fdmi u\u017eivateli a \npodporou platforem jako VKontakte (VK), Ok.com, YouTube, Twitter, Ask.fm, Facebook \na Instagram. Model zahrnuje zahrnuje implementa\u010dn\u00ed \u00fakoly (l\u00edb\u00ed se nebo follow , nebo \np\u0159\u00edsp\u011bvek, p\u0159ipojen\u00ed se ke skupin\u011b atd.), Kter\u00e9 motivuj\u00ed u\u017eivatele k zisku bod\u016f za dan\u00e9 \nakce. U\u017eivatel\u00e9 mohou body d\u00e1le prodat nebo pou\u017e\u00edt pro vlastn\u00ed propagaci. \n \nOnline hlasovac\u00ed a peti\u010dn\u00ed slu\u017eby: \nManipulace s hlasov\u00e1n\u00edm a pr\u016fzkumy ve\u0159ejn\u00e9ho m\u00edn\u011bn\u00ed na soci\u00e1ln\u00edch m\u00e9di\u00edch a dal\u0161\u00edch \nonline platform\u00e1ch m\u016f\u017ee b\u00fdt jedn\u00edm z nej\u00fa\u010dinn\u011bj\u0161\u00edch prost\u0159edk\u016f ovliv\u0148ov\u00e1n\u00ed ve\u0159ejn\u00e9ho \nm\u00edn\u011bn\u00ed a tato slu\u017eba je nab\u00edzena tak\u00e9 v rusk\u00e9m undergroundu. \n \nSlu\u017eba je sama o sob\u011b je schopna manipulovat t\u00e9m\u011b\u0159 s jak\u00fdmkoli hlasovac\u00edm syst\u00e9mem na \ninternetu a obch\u00e1zet bezpe\u010dnostn\u00ed kontroly, jako je IP adresa, Captcha, a mechanismy \nov\u011b\u0159ov\u00e1n\u00ed v soci\u00e1ln\u00edch m\u00e9di\u00edch, SMS a e-mailech, jako\u017e i registrace na webu, kde prob\u00edh\u00e1 \nhlasov\u00e1n\u00ed. \nNap\u0159\u00edklad u rusk\u00e9 firmy Siguldin maj\u00ed budouc\u00ed z\u00e1kazn\u00edci bezplatnou zku\u0161ebn\u00ed verzi, kde \ndostanou 10 a\u017e 20 hlas\u016f; platba za\u010d\u00edn\u00e1 50 hlasov\u00e1n\u00edm. \n \n \n \n \n \n 30 Poplatky z\u00e1vis\u00ed na tom, jak jsou hlasy ov\u011b\u0159ov\u00e1ny. Hlas, kter\u00fd obch\u00e1z\u00ed IP adresu, Captcha \nnebo jinou jednoduchou autentizaci, stoj\u00ed RUB 1 a\u017e RUB 1.5. Hlasovac\u00ed syst\u00e9my, kter\u00e9 \nvy\u017eaduj\u00ed autentizaci p\u0159es soci\u00e1ln\u00ed m\u00e9dia, budou st\u00e1t RUB 2 a\u017e RUB 3, zat\u00edmco syst\u00e9my \nvy\u017eaduj\u00edc\u00ed podrobnou online registraci stoj\u00ed RUB 3 a\u017e RUB 4. U hlasovac\u00edch syst\u00e9m\u016f, \nkter\u00e9 vy\u017eaduj\u00ed potvrzen\u00ed SMS a slo\u017eit\u011bj\u0161\u00ed metody ov\u011b\u0159ov\u00e1n\u00ed, je z\u00e1kazn\u00edkovi stanvena \n\u010d\u00e1stka 5 RUB za hlasov\u00e1n\u00ed. (25) \n \nCo vid\u00ed u\u017eivatel? \nNejv\u011bt\u0161\u00edm faktorem \u00fasp\u011bchu fale\u0161n\u00fdch zpr\u00e1v v roce 2016 byla jejich vysok\u00e1 \u00farove\u0148 \nsoci\u00e1ln\u00edho zapojen\u00ed. Celkov\u00e1 m\u00edra zapojen\u00ed (engagement rate) ve spojen\u00ed s fake news byla \nvy\u0161\u0161\u00ed ne\u017e u ofici\u00e1ln\u00edch zpr\u00e1v ov\u011b\u0159en\u00fdch sd\u011blovac\u00edch prost\u0159edk\u016f b\u011bhem t\u0159\u00ed m\u011bs\u00edc\u016f p\u0159ed \namerick\u00fdmi volbami v listopadu 2016. \n\u00dasp\u011bch takov\u00fdch zpr\u00e1v lze \u010d\u00e1ste\u010dn\u011b p\u0159i\u010d\u00edst pou\u017eit\u00ed emotivn\u011b zaj\u00edmav\u00fdch titulk\u016f, kter\u00e9 jsou \nnavr\u017eeny tak, aby p\u0159im\u011bly u\u017eivatele k interakci s obsahem, kter\u00fdm je \u010dten\u00ed, sd\u00edlen\u00ed, sd\u00edlen\u00ed \natd. Jak to d\u011blaj\u00ed? (27) \n \nModern\u00ed u\u017eivatel internetu je p\u0159et\u00ed\u017een informacemi a obvykle vykazuje velmi kr\u00e1tkou dobu \npozornosti.  \n \nTo ovliv\u0148uje zp\u016fsob vytv\u00e1\u0159en\u00ed a pou\u017e\u00edv\u00e1n\u00ed titulk\u016f a obr\u00e1zk\u016f ve fale\u0161n\u00fdch zpr\u00e1v\u00e1ch, ty jsou \nnavr\u017eeny tak, aby upoutaly pozornost u\u017eivatele na prvn\u00ed pohled. Tato fakta se tak\u00e9 shoduj\u00ed \ns my\u0161lenkami jejich \u010dten\u00e1\u0159e, tak\u017ee se c\u00edt\u00ed jako sou\u010d\u00e1st kmene a posiluj\u00ed / potvrzuj\u00ed sv\u00e9 \nmy\u0161lenky a zaujatosti. (28) \nV oblasti manipulace s politick\u00fdm n\u00e1zorem to b\u00fdv\u00e1 ve form\u011b vysoce stranick\u00e9ho obsahu. \nPolitick\u00e9 fale\u0161n\u00e9 zpr\u00e1vy maj\u00ed tendenci se p\u0159izp\u016fsobovat extr\u00e9m\u016fm politick\u00e9ho spektra; \n\u201eUm\u00edrn\u011bn\u00e9\u201c fale\u0161n\u00e9 zpr\u00e1vy ve skute\u010dnosti neexistuj\u00ed. (5) \n \nJak vid\u00edme n\u00ed\u017ee, existuj\u00ed ur\u010dit\u00e9 rozd\u00edly v provozu na Twitteru a Facebooku. \n \nNa Twitteru je up\u0159ednost\u0148ovanou strategi\u00ed zviditelnit p\u0159\u00edb\u011bh pomoc\u00ed co nejv\u00edce u\u017eivatel\u016f. \nP\u0159\u00edsp\u011bvky na Twitteru jsou \u010dasto \u0159azeny podle po\u010dtu zpr\u00e1v, nab\u00eddek a lajk\u016f. Pro tento \u00fa\u010del \nse ve velk\u00e9m pou\u017e\u00edvaj\u00ed roboti pro retweet nebo citov\u00e1n\u00ed zpr\u00e1v. \n \n \n \n \n \n 31 V n\u011bkter\u00fdch p\u0159\u00edpadech boti jednodu\u0161e zve\u0159ejn\u00ed stejnou zpr\u00e1vu bez v\u00fdrazn\u00e9 zm\u011bny textu. \nTakov\u00fd vzorec chov\u00e1n\u00ed usnad\u0148uje jejich identifikaci a Twitter \u00fasp\u011b\u0161n\u011b pou\u017e\u00edv\u00e1 tyto vzorce \nk blokov\u00e1n\u00ed n\u011bkter\u00fdch zneu\u017e\u00edvan\u00fdch \u00fa\u010dt\u016f.  \n  \nP\u0159\u00edklad: P\u0159ed francouzsk\u00fdmi volbami bylo n\u011bkolik p\u0159\u00edpad\u016f, kdy r\u016fzn\u00e9 \u00fa\u010dty tweetly \nzpravodajsk\u00e9 p\u0159\u00edb\u011bhy se stejn\u00fdm textem \u2013 pozn\u00e1vac\u00ed znak aktivity bot\u016f. Proto\u017ee je \nnepravd\u011bpodobn\u00e9, \u017ee by u\u017eivatel\u00e9 skute\u010dn\u011b sledovali tyto \u00fa\u010dty, tyto tweety by se \u0161\u00ed\u0159ily \np\u0159edev\u0161\u00edm u\u017eivateli, kte\u0159\u00ed hledaj\u00ed informace o konkr\u00e9tn\u00edch zpr\u00e1v\u00e1ch nebo ud\u00e1lostech \npomoc\u00ed kl\u00ed\u010dov\u00fdch slov nebo hashtag\u016f. Twitter boti \u00fasp\u011b\u0161n\u011b vyu\u017e\u00edvaj\u00ed saturac\u00ed hled\u00e1n\u00ed na \nTwitteru pomoc\u00ed spr\u00e1vn\u00fdch slov ve spr\u00e1vn\u00fd \u010das, \u010d\u00edm\u017e zvy\u0161uj\u00ed n\u00e1v\u0161t\u011bvnost webu sm\u011brem k \ndoty\u010dn\u00e9mu webu. \n \nToto nen\u00ed jedin\u00fd zp\u016fsob, jak \u0161\u00ed\u0159it dezinformace na Twitteru, samoz\u0159ejm\u011b. Dal\u0161\u00ed u\u017eite\u010dnou \nstrategi\u00ed je vyu\u017eit\u00ed legitimn\u011b vyhl\u00ed\u017eej\u00edc\u00edho \u00fa\u010dtu, vytvo\u0159en\u00ed p\u0159\u00edsp\u011bvku s dezinformacemi a \nn\u00e1sledn\u00e9 pou\u017eit\u00ed dal\u0161\u00edch \u00fa\u010dt\u016f pro retweet nebo citov\u00e1n\u00ed. \nTento typ kampan\u011b byl pou\u017eit v p\u0159\u00edpad\u011b francouzsk\u00fdch prezidentsk\u00fdch voleb, kde bylo \nn\u00e1sledn\u011b identifikov\u00e1no v\u00edce ne\u017e 5 400 podez\u0159el\u00fdch \u00fa\u010dt\u016f. \n \nNa Facebooku: \nObecn\u011b \u0159e\u010deno, strategie pou\u017eit\u00e9 na Facebooku jsou podobn\u00e9 strategi\u00edm jinde. Existuj\u00ed \nv\u0161ak ur\u010dit\u00e9 rozd\u00edly. Proto\u017ee je algoritmus Facebooku \u0159\u00edzen m\u00edrou zapojen\u00ed, \u010dl\u00e1nky s \nvelk\u00fdm po\u010dtem lajk\u016f a sd\u00edlen\u00ed se \u010dast\u011bji objevuj\u00ed ve zpravodajsk\u00fdch zdroj\u00edch. V\u00fdsledkem \nje, \u017ee \u010dl\u00e1nky budou pravd\u011bpodobn\u011bji navr\u017eeny tak, aby byly sd\u00edlen\u00e9 na z\u00e1klad\u011b titulku a \nfotografie. Krom\u011b toho jsou u fale\u0161n\u00fdch zpr\u00e1v na Facebooku \u010dast\u011bji uv\u00e1d\u011bny konzistentn\u00ed \nzna\u010dky (konkr\u00e9tn\u00ed dom\u00e9ny).  \n \nDal\u0161\u00ed platformy soci\u00e1ln\u00edch m\u00e9di\u00ed \n \nPlatformy soci\u00e1ln\u00edch m\u00e9di\u00ed v \u010c\u00edn\u011b se podobn\u011b pou\u017e\u00edvaj\u00ed k dezinformac\u00edm. Principy jsou \nst\u00e1le stejn\u00e9 jako na ostatn\u00edch soci\u00e1ln\u00edch sit\u00edch. Velkou s\u00edlu maj\u00ed s\u00edt\u011b Weibo a Guba \n(26) \n \n \n \n \n \n 32 3.5.1 Boti Obecn\u011b \nBoti (zkr\u00e1cen\u00fd v\u00fdraz pro softwarov\u00e9 roboty) se objevili ji\u017e v\u202fpo\u010d\u00e1tc\u00edch po\u010d\u00edta\u010d\u016f. Jedn\u00edm \nz\u202fp\u0159\u00edklad\u016f m\u016f\u017ee b\u00fdt chatbot, algoritmus sestaven\u00fd tak aby udr\u017eoval konverzaci s\u202f\u010dlov\u011bkem, \njak si jej v\u202f50 letech 20. stolet\u00ed p\u0159edstavoval Alan Turing (tzv. Turing\u016fv test m\u00e1 za c\u00edl \nprov\u011b\u0159it, jestli se um\u011bl\u00e1 inteligence opravdu chov\u00e1 inteligentn\u011b. Proto\u017ee inteligenci lze jen \nt\u011b\u017eko definovat, t\u00edm h\u016f\u0159e testovat, pou\u017e\u00edv\u00e1 Turing\u016fv test porovn\u00e1n\u00ed s \u010dlov\u011bkem.)  \nSen o vytvo\u0159en\u00ed po\u010d\u00edta\u010dov\u00e9ho algoritmu, kter\u00fd \u00fasp\u011b\u0161n\u011b projde Turingov\u00fdm testem, po \ndesetilet\u00ed vedl v\u00fdzkum um\u011bl\u00e9 inteligence, o \u010dem\u017e sv\u011bd\u010d\u00ed iniciativy, jako je Loebnerova \ncena, co\u017e je ka\u017edoro\u010dn\u00ed sout\u011b\u017e program\u016f um\u011bl\u00e9 inteligence, kter\u00e9 simuluj\u00ed lidskou \nkonverzaci.  \nV\u202fdne\u0161n\u00ed dob\u011b ekosyst\u00e9m soci\u00e1ln\u00edch m\u00e9di\u00ed obsahuj\u00edc\u00ed stovky milion\u016f jedinc\u016f p\u0159in\u00e1\u0161\u00ed \nohromnou p\u0159\u00edle\u017eitost, a\u0165 ji\u017e ekonomickou \u010di politickou, k\u202fuplatn\u011bn\u00ed n\u00e1vrh\u016f algoritm\u016f, kter\u00e9 \nsimuluj\u00ed lidsk\u00e9 chov\u00e1n\u00ed.  \nTakov\u00fd syst\u00e9m tak\u00e9 p\u0159edstavuje novou v\u00fdzvu vzhledem k\u202fmno\u017estv\u00ed dimenz\u00ed, kter\u00e9 je \npot\u0159eba simulovat v\u010detn\u011b aktivity jako sd\u00edlen\u00ed obsahu, tvorba obsahu, vyjad\u0159ov\u00e1n\u00ed \nsentimentu atd. (29) \n \nBoti jsou nej\u010dast\u011bji vytv\u00e1\u0159eni pro ne\u0161kodn\u00e9 nebo v\u00fdhodn\u00e9 \u00fa\u010dely, jako je automatizace jinak \n\u00fanavn\u00e9 a \u010dasov\u011b n\u00e1ro\u010dn\u00e9 \u00fakoly nebo souhrnn\u00e9 informace ze samostatn\u00fdch zdroj\u016f. Boti se \ntak\u00e9 \u010dasto pou\u017e\u00edvaj\u00ed jako automatick\u00e9 odpov\u011bdi na dotazy, \u010dasto p\u0159ij\u00edman\u00e9 spole\u010dnostmi a \nzna\u010dkami. Boti jsou tak\u00e9 zneu\u017e\u00edv\u00e1ni k ovliv\u0148ov\u00e1n\u00ed rozhovor\u016f a politick\u00fdch debat, \u0161\u00ed\u0159en\u00ed \ndezinformac\u00ed a odcizen\u00ed osobn\u00edch \u00fadaj\u016f u\u017eivatel\u016f m\u00e1 roboty definovan\u00e9 jako kus \nspustiteln\u00e9ho softwaru, kter\u00fd automatizuje proces interakce mezi u\u017eivateli a obsahem nebo \njin\u00fdmi u\u017eivateli.  \nByla vytvo\u0159ena topologie nazna\u010duj\u00edc\u00ed \u0161est r\u016fzn\u00fdch typ\u016f robot\u016f: \n\u25cf Web crawler \n\u25cf Chatboti  \n\u25cf Spamboty (roboti, kte\u0159\u00ed inzeruj\u00ed a zve\u0159ej\u0148uj\u00ed spam na platform\u00e1ch pro online zas\u00edl\u00e1n\u00ed \nzpr\u00e1v) \n\u25cf Soci\u00e1ln\u00ed roboti (obecn\u00fd koncept automatizace, kter\u00fd funguje na soci\u00e1ln\u00edch platform\u00e1ch) \n\u25cf Trollov\u00e9 (u\u017eivatelsk\u00e9 \u00fa\u010dty p\u0159edpokl\u00e1daj\u00edc\u00ed identitu ostatn\u00edch) \n \n \n \n \n \n 33 \u25cf Kyborgov\u00e9 a hybridn\u00ed \u00fa\u010dty (kombinace automatizovan\u00e9ho a lidsk\u00e9ho dohledu) (30) \n\u201eSoci\u00e1ln\u00ed robot se obecn\u011b ch\u00e1pe jako program, kter\u00fd automaticky vytv\u00e1\u0159\u00ed obsah a \nkomunikuje s lidmi na soci\u00e1ln\u00edch m\u00e9di\u00edch. (30) \nSocial Bots  \n  \nSoci\u00e1ln\u00ed bot (social bot), tak\u00e9 zn\u00e1m\u00fd jako sybil account (podle zn\u00e1m\u00e9ho psychiatrick\u00e9ho \np\u0159\u00edpadu Shirley Manson, kter\u00e1 m\u011bla 16 osobnost\u00ed, zpopularizovan\u00e9 v\u202fknize a filmu) je \npo\u010d\u00edta\u010dov\u00fd algoritmus kter\u00fd automaticky vytv\u00e1\u0159\u00ed obsah a prov\u00e1d\u00ed interakci s\u202flidsk\u00fdmi \nu\u017eivateli soci\u00e1ln\u00edch s\u00edt\u00ed. Tito \u201eagenti \u201c a jejich interakce byli pozorov\u00e1ni v\u202fonline soci\u00e1ln\u00edch \nm\u00e9di\u00edch ji\u017e n\u011bkolik uplynul\u00fdch let. DARPA pravideln\u011b organizuje sout\u011b\u017e v\u202fdetekci bot\u016f, \naby podpo\u0159ila v\u00fdvoj technologi\u00ed pro v\u010dasnou detekci z\u00e1vadn\u00e9 organizovan\u00e9 aktivity.  \nN\u011bkter\u00e9 \u00fa\u010dty \u0159\u00edzen\u00e9 boty jsou pro z\u00e1bavu, n\u00e1pomocn\u00e9, nebo alespo\u0148 ne\u0161kodn\u00e9, ale neetick\u00e9 \npou\u017eit\u00ed soci\u00e1ln\u00edch bot\u016f je obrovsk\u00fd probl\u00e9m, obzvl\u00e1\u0161t\u011b kdy\u017e je vyu\u017eito mnoho \u00fa\u010dt\u016f ke \nkoordinovan\u011b \u0159\u00edzen\u00e9 kampani. (31) \n \nJak\u00fd je smysl soci\u00e1ln\u00edch bot\u016f? V\u202fprvn\u00ed kategorii jsou ne\u0161kodn\u00ed, \u010di dokonce n\u00e1pomocn\u00ed \nboti. Nap\u0159\u00edklad soci\u00e1ln\u00ed bot, kter\u00fd automaticky seskupuje obsah z\u202fr\u016fzn\u00fdch zdroj\u016f (jako \njednoduch\u00fd news feed), nebo automatick\u00fd chatbot, jen\u017e odpov\u00edd\u00e1 na \u010dast\u00e9 dotazy, kter\u00e9 \ndost\u00e1vaj\u00ed zna\u010dky a spole\u010dnosti p\u0159i z\u00e1kaznick\u00e9 p\u00e9\u010di.  \nA\u010dkoliv tento typ bot\u016f je navrhnut tak, aby poskytovali u\u017eite\u010dn\u00e9 informace, mohu n\u011bkdy \nb\u00fdt \u0161kodliv\u00ed, nap\u0159\u00edklad kdy\u017e se pod\u00edl\u00ed na \u0161\u00ed\u0159en\u00ed neov\u011b\u0159en\u00fdch informac\u00ed a f\u00e1m. Zn\u00e1my je \np\u0159\u00edklad d\u011bn\u00ed po bombov\u00e9m \u00fatoku na z\u00e1vod maratonu v\u202fBostonu. Nepravdiv\u00e9 obvin\u011bn\u00ed se \ndivoce \u0161\u00ed\u0159ilo na s\u00edti Twitter hlavn\u011b d\u00edky bot\u016fm, kte\u0159\u00ed automaticky retweetovali post bez \nov\u011b\u0159en\u00ed fakt\u016f \u010di zkontrolov\u00e1n\u00ed d\u016fv\u011bryhodnosti zdroje.  \nS\u202fka\u017edou novou technologi\u00ed p\u0159ich\u00e1z\u00ed jej\u00ed potencion\u00e1ln\u00ed zneu\u017eit\u00ed a soci\u00e1ln\u00ed m\u00e9dia toho \nnejsou v\u00fdjimkou. Druh\u00e1 kategorie soci\u00e1ln\u00ed bot\u016f zahrnuje \u0161kodliv\u00e9 entity navr\u017een\u00e9 \nspeci\u00e1ln\u011b za \u00fa\u010delem \u0161kodit a ubl\u00ed\u017eit. Tito boti zav\u00e1d\u011bj\u00ed, zneu\u017e\u00edvaj\u00ed a manipuluj\u00ed s\u202fdiskusemi \nna soci\u00e1ln\u00edch s\u00edt\u00edch pomoc\u00ed zv\u011bst\u00ed, spamu, malwaru, dezinformac\u00ed, astroturfingem, pomluv \nnebo jen vytv\u00e1\u0159en\u00edm \u201ehluku\u201c.  \nTo v\u0161e vede k\u202fn\u011bkolika \u00farovn\u00edm \u0161kod pro spole\u010dnost. Nap\u0159\u00edklad boti pou\u017eit\u00ed pro politick\u00fd \nastroturfing um\u011ble nafouknou podporu pro kandid\u00e1ta, jejich \u010dinnost m\u016f\u017ee ohrozit \ndemokracii ovlivn\u011bn\u00edm v\u00fdsledk\u016f voleb. Ve skute\u010dnosti se to ji\u017e mo\u017en\u00e1 stalo. B\u011bhem \n \n \n \n \n \n 34 americk\u00fdch voleb v\u202froce 2010 zah\u00e1jila mal\u00e1 skupina soci\u00e1ln\u00edch bot\u016f kampa\u0148 proti jednomu \nkandid\u00e1tovi do americk\u00e9ho sen\u00e1tu za Delaware. Vz\u00e1jemn\u011b postovali a zvy\u0161ovali dosah \ntis\u00edce tweet\u016f, kter\u00e9 ukazovaly na internetov\u00e9 str\u00e1nky s\u202fneov\u011b\u0159en\u00fdmi informacemi, jen\u017e \nkandid\u00e1ta o\u010der\u0148ovali a podporovali jeho oponenta.   \nSt\u00e1le v\u00edce p\u0159\u00edklad\u016f ni\u010div\u00fdch \u00fa\u010dink\u016f soci\u00e1ln\u00edch bot\u016f je hl\u00e1\u0161eno ka\u017ed\u00fdm dnem od novin\u00e1\u0159\u016f, \nanalytik\u016f a v\u00fdzkumn\u00edk\u016f po cel\u00e9m sv\u011bt\u011b.   \nAutomatick\u00e9 syst\u00e9my pro obchod na burz\u00e1ch p\u0159edpov\u00eddaj\u00edc\u00ed v\u00fdvoj trhu zachytili velk\u00e9 \nmno\u017estv\u00ed konverzac\u00ed o nov\u00e9 technologicky zam\u011b\u0159en\u00e9 firm\u011b a za\u010daly v\u202fohromn\u00e9m mno\u017estv\u00ed \nprov\u00e1d\u011bt transakce pr\u00e1v\u011b na z\u00e1klad\u011b t\u011bch konverzac\u00ed, kter\u00e9 ve skute\u010dnosti byly \nvykonstruov\u00e1ny a \u0161\u00ed\u0159eny pomoc\u00ed bot\u016f. To vedlo k\u202f200n\u00e1sobn\u00e9mu zv\u00fd\u0161en\u00ed hodnoty firmy \nna burze. (3) \nNapodobov\u00e1n\u00ed lidsk\u00e9ho chov\u00e1n\u00ed:  \nJednou z\u202fnejv\u011bt\u0161\u00edch v\u00fdzev v\u202fdetekci bot\u016f na soci\u00e1ln\u00edch s\u00edt\u00edch je pochopit, co v\u0161e modern\u00ed \nboti dok\u00e1\u017e\u00ed. Rann\u00e9 v\u00fdtvory zvl\u00e1daly p\u0159ev\u00e1\u017en\u011b jeden typ aktivity: Automaticky p\u0159id\u00e1vali \nobsah. Tito boti byli velice jednodu\u0161\u0161\u00ed a jejich detekce byla odhaliteln\u00e1 velice snadno za \npou\u017eit\u00ed jednoduch\u00e9 detek\u010dn\u00ed strategie.  V\u202froce 2011 t\u00fdm Texas A&M University \nimplementoval honeypot past, d\u00edky kter\u00e9 se povedlo detekovat tis\u00edce soci\u00e1ln\u00edch bot\u016f. \nHoneypot (z angli\u010dtiny p\u0159elo\u017eeno jako \u201chrnec medu\u201d, pou\u017e\u00edv\u00e1 se ale pouze anglick\u00fd \npojem) je past na \u00fato\u010dn\u00edky, kte\u0159\u00ed se sna\u017e\u00ed napadnout po\u010d\u00edta\u010d, server, po\u010d\u00edta\u010dovou s\u00ed\u0165 nebo \njin\u00e9 za\u0159\u00edzen\u00ed. \u00dato\u010dn\u00edk je jedno, jestli \u010dlov\u011bk nebo n\u011bjak\u00fd program, se sna\u017e\u00ed naj\u00edt v syst\u00e9mu \nnejslab\u0161\u00ed m\u00edsto a na to za\u00fato\u010dit. Tohoto principu pr\u00e1v\u011b vyu\u017e\u00edv\u00e1 obrana pomoc\u00ed honeypot, \nkter\u00fd se tv\u00e1\u0159\u00ed jako zd\u00e1nliv\u011b nejslab\u0161\u00ed \u010dl\u00e1nek a t\u00edm upout\u00e1 pozornost \u00fato\u010dn\u00edka nebo \nzaznamen\u00e1 jeho \u010dinnost, spolu se kterou nap\u0159\u00edklad i metodu \u00fatoku. \nZ\u00e1kladn\u00ed my\u0161lenka byla jednoduch\u00e1 a efektivn\u00ed. T\u00fdm vytvo\u0159il n\u011bkolik Twitter \u00fa\u010dt\u016f, jejich\u017e \njedin\u00fdm \u00fakolem bylo pouze vytvo\u0159it nesmysln\u00e9 tweety s\u202fbezv\u00fdznamn\u00fdm obsahem, kter\u00fd \nby \u017e\u00e1dn\u00e9ho \u010dlov\u011bka nikdy nezaj\u00edmal. Tyto \u00fa\u010dty v\u0161ak p\u0159il\u00e1kaly mnoho sleduj\u00edc\u00edch. \nPodrobn\u011bj\u0161\u00ed zkoum\u00e1n\u00ed potvrdilo, \u017ee podez\u0159el\u00ed sleduj\u00edc\u00ed byli skute\u010dn\u011b soci\u00e1ln\u00ed boti sna\u017e\u00edc\u00ed \nse roz\u0161\u00ed\u0159it sv\u00e9 soci\u00e1ln\u00ed vazby v\u202fr\u00e1mci zkouman\u00e9 s\u00edt\u011b.  Sofistikovanost soci\u00e1ln\u00edch bot\u016f roste \nka\u017ed\u00fdm dnem. Ji\u017e v\u202froce 2013 p\u0159i pokusu opakovat honeypot experiment z\u202froku 2012 \np\u0159inesl pouze hrstku detekovan\u00fdch bot\u016f.  Hranice mezi chov\u00e1n\u00edm skute\u010dn\u00e9 osoby a \nchov\u00e1n\u00edm bot\u016f napodobuj\u00edc\u00edch lidsk\u00e9 chov\u00e1n\u00ed je st\u00e1le m\u00e9n\u011b a m\u00e9n\u011b z\u0159eteln\u00e1. Nap\u0159\u00edklad \nsoci\u00e1ln\u00ed boti mohou vyhled\u00e1vat informace na webu a vypl\u0148ovat dle toho sv\u016fj profil, sd\u00edlet \n \n \n \n \n \n 35 posb\u00edran\u00fd materi\u00e1l v\u202fp\u0159eddefinovan\u00e9 \u010dasy, napodobovat lidsk\u00e9 chov\u00e1n\u00ed na z\u00e1klad\u011b \nCirkadi\u00e1nn\u00ed rytmu (v\u00fdkyvy ve sledov\u00e1n\u00ed a aktivit\u00e1ch na z\u00e1klad\u011b denn\u00edho rytmu). Mohou se \ndokonce \u00fa\u010dastnit v\u00edce komplexn\u00edch interakc\u00ed jako je zapojen\u00ed se do konverzace s\u202fdal\u0161\u00edmi \nlidmi, komentov\u00e1n\u00ed p\u0159\u00edsp\u011bvk\u016f, zodpov\u00eddan\u00ed dotaz\u016f.  \nN\u011bkte\u0159\u00ed boti specificky c\u00edl\u00ed na v\u011bt\u0161\u00ed vliv z\u00edsk\u00e1n\u00edm nov\u00fdch sleduj\u00edc\u00edch a roz\u0161\u00ed\u0159en\u00ed jejich \nsoci\u00e1ln\u00edch kruh\u016f. Mohou prohled\u00e1vat soci\u00e1ln\u00ed s\u00edt\u011b a hledat popul\u00e1rn\u00ed a slavn\u00e9 lidi, sledovat \nje, nebo upoutat jejich pozornost zasl\u00e1n\u00edm dotaz\u016f v\u202fnad\u011bji, \u017ee si jich v\u0161imnou.  \n  \nAby byli v\u00edc viditeln\u00ed, mohou infiltrovat popul\u00e1rn\u00ed diskuse, generovat tematicky vhodn\u00fd, a \ndokonce potencion\u00e1ln\u011b zaj\u00edmav\u00fd obsah, d\u00edky identifikov\u00e1n\u00ed relevantn\u00edch kl\u00ed\u010dov\u00fdch slov a \nhled\u00e1n\u00edm online informac\u00ed, kter\u00e9 by se hodili do prob\u00edhaj\u00edc\u00ed konverzace. Pot\u00e9 co je \ninformace nalezena, bot m\u016f\u017ee automaticky vytvo\u0159it odpov\u011b\u010f s\u202fvyu\u017eit\u00edm algoritm\u016f pro \np\u0159irozen\u00fd jazyk, p\u0159\u00edpadn\u011b poskytnout odkaz na m\u00e9dia, nebo webovou adresu obsahuj\u00edc\u00ed \nrelevantn\u00ed informace.  \nDal\u0161\u00ed roboti maj\u00ed za c\u00edl manipulovat identitami skute\u010dn\u00fdch lid\u00ed: N\u011bkte\u0159\u00ed kradou identitu \nosvojen\u00edm si podobn\u00fdch variant skute\u010dn\u00e9ho u\u017eivatelsk\u00e9ho jm\u00e9na a kraden\u00edm osobn\u00edch \ninformac\u00ed jako jsou fotky a odkazy. Je\u0161t\u011b pokro\u010dilej\u0161\u00ed mechanismy mohou b\u00fdt vyu\u017eity: \nN\u011bkte\u0159\u00ed boti jsou schopni \u201eklonovat\u201c chov\u00e1n\u00ed skute\u010dn\u00fdch lid\u00ed interagovat s\u202fjejich p\u0159\u00e1teli a \nsd\u00edlet podobn\u00fd, \u010di stejn\u00fd obsah se stejn\u00fdmi \u0159asov\u00fdmi vzorci jako kop\u00edrovan\u00e1 osoba.  (29) \n \nDopad soci\u00e1ln\u00edch bot\u016f \nSoci\u00e1ln\u00ed roboti poskytuj\u00ed jak aktivitu na platform\u00e1ch soci\u00e1ln\u00edch m\u00e9di\u00ed, tak vytv\u00e1\u0159ej\u00ed \natraktivn\u011bj\u0161\u00ed platformu simulac\u00ed vysok\u00e9 aktivity a velk\u00e9 u\u017eivatelsk\u00e9 z\u00e1kladny. Na druh\u00e9 \nstran\u011b tito boti obvykle sni\u017euj\u00ed kvalitu z\u00e1\u017eitku pro lidsk\u00e9 u\u017eivatele, a nav\u00edc zbyte\u010dn\u011b \nzat\u011b\u017euj\u00ed pr\u00e1ci na serverech. Po\u010det sleduj\u00edc\u00edch, L\u00edb\u00ed se, p\u0159\u00e1tel je pova\u017eov\u00e1no za dobr\u00e9 m\u00edry \ntoho, jak popul\u00e1rn\u00ed a vlivn\u00fd je jednotlivec na soci\u00e1ln\u00edch m\u00e9di\u00edch. V d\u016fsledku toho za\u010dal \ntrend n\u00e1kupu sleduj\u00edc\u00edch / p\u0159\u00e1tel, jak je vysv\u011btleno. V d\u016fsledku toho roboti tak\u00e9 zp\u016fsobuj\u00ed \nzkreslen\u00fd a nafouknut\u00fd po\u010det sleduj\u00edc\u00edch, co\u017e m\u00e1 za n\u00e1sledek nep\u0159edv\u00eddatelnost pro \nmarketingov\u00e9 spole\u010dnosti i investory. Marketingov\u00e9 spole\u010dnosti p\u0159ich\u00e1zej\u00ed o reklamu na \npen\u00edze u\u017eivatel\u016fm, kte\u0159\u00ed nejsou ani skute\u010dn\u00fdmi lidmi, zat\u00edmco investo\u0159i nakupuj\u00ed akcie \nspole\u010dnost\u00ed, kter\u00e9 ve skute\u010dnosti nestoj\u00ed za svou fale\u0161n\u011b prezentovanou hodnotu. \n \n \n \n \n \n 36 Soci\u00e1ln\u00ed roboty lze pou\u017e\u00edt jako n\u00e1stroj k manipulaci s konverzacemi na soci\u00e1ln\u00edch \nplatform\u00e1ch. V\u011bdci zjistili, \u017ee b\u011bhem politick\u00fdch diskus\u00ed t\u00fdkaj\u00edc\u00edch se prezidentsk\u00fdch \nvoleb v roce 2016 v U.S bylo p\u0159ibli\u017en\u011b 15 % \u00fa\u010dastn\u00edc\u00edch se u\u017eivatel\u016f roboti. Tito roboti \nbyli zodpov\u011bdn\u00ed za p\u0159ibli\u017en\u011b 19 % celkov\u00fdch rozhovor\u016f. V roce 2017 bylo shrom\u00e1\u017ed\u011bno \nt\u00e9m\u011b\u0159 1 milion tweet\u016f diskutuj\u00edc\u00edch o n\u011bmeck\u00fdch parlamentn\u00edch. Bylo zji\u0161t\u011bno, \u017ee 7,4 % z \ncelkov\u00e9ho souboru tweet\u016f bylo generov\u00e1no automatick\u00fdmi roboty. Podobn\u00e9 v\u00fdsledky jako \nstudium n\u011bmeck\u00fdch voleb, p\u0159inesl v\u00fdzkum \u0161v\u00e9dsk\u00fdch voleb. V\u00fdsledky ukazuj\u00ed, \u017ee \np\u0159ibli\u017en\u011b 6 % twitterov\u00fdch \u00fa\u010dt\u016f \u00fa\u010dastn\u00edc\u00edch se diskuse o \u0161v\u00e9dsk\u00fdch volb\u00e1ch bylo \nklasifikov\u00e1no jako roboti. Tyto studie zd\u016fraz\u0148uj\u00ed u\u017eite\u010dnost soci\u00e1ln\u00edch robot\u016f. \nMnoho z t\u011bchto zd\u016frazn\u011bn\u00fdch probl\u00e9m\u016f lze vid\u011bt tak\u00e9 v jin\u00fdch pr\u016fmyslov\u00fdch odv\u011btv\u00edch. \nP\u0159ibli\u017en\u011b 25 % hudebn\u00edho pr\u016fmyslu a jeho um\u011blc\u016f maj\u00ed roboty jako sleduj\u00edc\u00ed, mnoho z \nnich si um\u011blec a jejich veden\u00ed koup\u00ed, aby uk\u00e1zali lep\u0161\u00ed \u010d\u00edsla. To op\u011bt zp\u016fsobuje finan\u010dn\u00ed \n\u0161kody inzerent\u016fm a investor\u016fm a vytv\u00e1\u0159\u00ed nespravedliv\u00e9 v\u00fdhody v\u016f\u010di jin\u00fdm um\u011blc\u016fm a \nskupin\u00e1m t\u00edm, \u017ee zveli\u010duje skute\u010dn\u00fd po\u010det sleduj\u00edc\u00edch a aktivitu. (30) \n \nIdentifikace soci\u00e1ln\u00edch bot\u016f \nJin\u00e9 studie uk\u00e1zaly, \u017ee vzorce chov\u00e1n\u00ed lze pou\u017e\u00edt k efektivn\u00ed identifikaci soci\u00e1ln\u00edch robot\u016f. \nDetekce robot\u016f pomoc\u00ed vzorc\u016f chov\u00e1n\u00ed je sice efektivn\u00ed, ale zahrnuje i zna\u010dnou dobu \nv\u00fdpo\u010dtu pro sb\u011br i anal\u00fdzu dat. Hlavn\u00edmi rysy, kter\u00e9 jsou analyzov\u00e1ny pomoc\u00ed identifikace \nchov\u00e1n\u00ed, jsou \u0159et\u011bzce zve\u0159ejn\u011bn\u00e9 u\u017eivatelem, frekvence nov\u00fdch p\u0159\u00edsp\u011bvk\u016f a legitimita \nadresy URL zve\u0159ejn\u011bn\u00e9 u\u017eivateli. Tento typ anal\u00fdzy chov\u00e1n\u00ed se tak\u00e9 naz\u00fdv\u00e1 detekce na \n\u00farovni post-level nebo tak\u00e9 detekce na \u00farovni tweetu konkr\u00e9tn\u011b pro Twitter. \nTuring\u016fv test byl vytvo\u0159en v roce 1950 Alanem Turingem a je testem vytvo\u0159en\u00fdm k \npozorov\u00e1n\u00ed, zda se po\u010d\u00edta\u010d m\u016f\u017ee v rozhovoru s vy\u0161et\u0159ovatelem jevit jako \u010dlov\u011bk. Test byl \np\u016fvodn\u011b navr\u017een tak, aby m\u011b\u0159il inteligenci po\u010d\u00edta\u010d\u016f. Alan Turing v\u011b\u0159il, \u017ee po\u010d\u00edta\u010d t\u00edm, \u017ee \np\u0159em\u00fd\u0161l\u00ed a reaguje na ot\u00e1zky a prohl\u00e1\u0161en\u00ed vy\u0161et\u0159ovatele, mus\u00ed b\u00fdt inteligentn\u00ed, co\u017e \ndokazuje, \u017ee dok\u00e1\u017ee myslet. Test byl nasazen jako hra v p\u016fvodn\u00ed podob\u011b, vy\u0161et\u0159ovatel m\u011bl \ndv\u011b konverzace, jedna byla s \u010dlov\u011bkem a druh\u00e1 s po\u010d\u00edta\u010dem (implementov\u00e1no pomoc\u00ed \njednoduch\u00e9ho chatu). C\u00edlem vy\u0161et\u0159ovatele bylo zjistit, kdo byl \u010dlov\u011bk a kdo byl robot t\u00edm, \n\u017ee pomoc\u00ed anal\u00fdzy obsahu odpov\u011bdi zjistil, zda bylo chov\u00e1n\u00ed agenta lidsk\u00e9 nebo ne. \nAnalyzovan\u00e9 informace byly jak chov\u00e1n\u00ed, tak informace shrom\u00e1\u017ed\u011bn\u00e9 o agentovi, kter\u00e9 lze \ntak\u00e9 nazvat metadaty. \n \n \n \n \n \n 37 Bylo provedeno n\u011bkolik studi\u00ed, kde identifikace bot\u016f je zalo\u017eena na metadatech u\u017eivatele, \nV\u011bt\u0161ina studi\u00ed p\u0159istupuje k anal\u00fdze chov\u00e1n\u00ed, jak bylo uvedeno v\u00fd\u0161e. Dokonce i ve studii, \nkde byla zahrnuta metadata, bylo hlavn\u00edm zam\u011b\u0159en\u00edm detekce na \u00farovni post-level a \nmetadata byla p\u0159id\u00e1na pouze za \u00fa\u010delem ov\u011b\u0159en\u00ed, zda by mohla p\u0159isp\u011bt k efektivit\u011b \nv\u00fdzkumu. Je mnohem \u010dasov\u011b efektivn\u011bj\u0161\u00ed extrahovat data na \u00farovni \u00fa\u010dtu z platformy nebo \nsyst\u00e9mu, a proto je velmi atraktivn\u00ed ve srovn\u00e1n\u00ed s post-level informacemi, kter\u00e9 mus\u00ed b\u00fdt \np\u0159ed anal\u00fdzou zpracov\u00e1ny a transformov\u00e1ny do \u010diteln\u00fdch dat. V kontextu t\u00e9to studie jsou \nmetadata definov\u00e1na jako striktn\u011b metadata na \u00farovni \u00fa\u010dtu, pokud nen\u00ed v\u00fdslovn\u011b uvedeno \njinak. Nap\u0159\u00edklad datum vytvo\u0159en\u00ed \u00fa\u010dtu, mno\u017estv\u00ed p\u0159\u00e1tel a um\u00edst\u011bn\u00ed jsou v\u0161echno funkce \nmetadat. (32) \n  \nNejjednodu\u0161\u0161\u00ed postup pro detekci bot\u016f: \n1. Abnorm\u00e1ln\u00ed aktivita \u00fa\u010dtu \nPo\u010det reakc\u00ed na p\u0159\u00edsp\u011bvky m\u016f\u017ee b\u00fdt ukazatelem. V\u011bt\u0161ina p\u0159\u00edsp\u011bvk\u016f m\u00e1 celkem \np\u0159edv\u00eddatelnou \u017eivotnost, podle platformy. (Star\u0161\u00ed p\u0159\u00edsp\u011bvky obvykle neza\u010dnou z ni\u010deho \nnic z\u00edsk\u00e1vat velk\u00fd po\u010det reakc\u00ed). P\u0159\u00edpadn\u011b okam\u017eit\u00fd velk\u00fd po\u010det koment\u00e1\u0159\u016f u p\u0159\u00edsp\u011bvku, \nm\u016f\u017ee nazna\u010dovat automaticky generovan\u00e9 reakce.  \n2. M\u00edra zapojen\u00ed \n \nFale\u0161n\u00e9 automatick\u00e9 akce, jako je hodnocen\u00ed l\u00edb\u00ed se mi, retweety a sd\u00edlen\u00ed, jsou \nnejjednodu\u0161\u0161\u00ed, zat\u00edmco koment\u00e1\u0159e jsou t\u011b\u017e\u0161\u00ed a je m\u00e9n\u011b pravd\u011bpodobn\u00e9, \u017ee by se o n\u011b \npokusily boti. Tak\u017ee, pokud m\u00e1 n\u011bkdo tis\u00edce lajk\u016f, ale jen m\u00e1lo nebo \u017e\u00e1dn\u00e9 koment\u00e1\u0159e, \nm\u016f\u017ee to nazna\u010dovat aktivitu bot\u016f. Mezi dal\u0161\u00ed \u010derven\u00e9 vlajky pat\u0159\u00ed koment\u00e1\u0159e s velk\u00fdm \nmno\u017estv\u00edm propaga\u010dn\u00edch zpr\u00e1v-mnohokr\u00e1t s napodoben\u00fdm \u00fa\u010dtem, podle jako \novliv\u0148ovatele -, aby p\u0159im\u011bli spot\u0159ebitele ke kliknut\u00ed. \n \n3. Sleduj\u00edc\u00ed versus zapojen\u00ed \nVelk\u00e9 mno\u017estv\u00ed sleduj\u00edc\u00edch s minim\u00e1ln\u00edm zapojen\u00edm a po\u010dtem reakac\u00ed m\u016f\u017ee nazna\u010dovat, \n\u017ee si n\u011bkdo koupil bot \u00fa\u010dty, obzvl\u00e1\u0161t\u011b pak, kdy\u017e n\u00e1r\u016fst sleduj\u00edc\u00edch prob\u011bhl n\u00e1razov\u011b v \nkr\u00e1tk\u00e9m \u010dase. \n  \n \n \n \n \n \n 38 4. P\u016fvod sleduj\u00edc\u00edch \n\u00da\u010dty sleduj\u00edc\u00ed influencera jsou nep\u0159im\u011b\u0159en\u011b ze zn\u00e1m\u00fdch click-farm zem\u00ed, nebo maj\u00ed \nspojitost se str\u00e1nkami na \u010dern\u00e9 listin\u011b a nemaj\u00ed povolen\u00fd geotagging. \n \n5. Kop\u00edrov\u00e1n\u00ed \u017eivotopisu, fr\u00e1z\u00ed \nKdy\u017e m\u00e1j\u00ed sleduj\u00edc\u00ed podobn\u00e9 \u017eivotopisy a jm\u00e9na, pou\u017e\u00edvaj\u00ed v p\u0159\u00edsp\u011bvc\u00edch mnoho \nopakuj\u00edc\u00edch se fr\u00e1z\u00ed nebo jsou do zna\u010dn\u00e9 m\u00edry pr\u00e1zdn\u00e9, jedn\u00e1 se o \u010dervenou vlajku. Politi\u010dt\u00ed \nboti maj\u00ed velmi \u010dasto tejn\u00fd obr\u00e1zek \n \n6. Procento sleduj\u00edc\u00edch s nov\u011b vytvo\u0159en\u00fdmi \u00fa\u010dty  \n \nDal\u0161\u00ed \u010dervenou vlajkou je, kdy\u017e velk\u00e9 mno\u017estv\u00ed sleduj\u00edc\u00edch \u00fa\u010dt\u016f bylo vytvo\u0159enou teprve \nned\u00e1vno. Jakmile je bot zablokov\u00e1n na ur\u010dit\u00e9 platform\u011b, jedin\u00fdm zp\u016fsobem, jak vyd\u011blat, je \nzalo\u017eit nov\u00e9 \u00fa\u010dty.  \n \n7. Retweet Test \n \nDal\u0161\u00edm znakem je, kdy\u017e m\u00e1 \u00fa\u010det velk\u00e9 mno\u017estv\u00ed retweet\u016f, sd\u00edlen\u00ed a lajk\u016f, ale m\u00e1 \nminim\u00e1ln\u00ed mno\u017estv\u00ed reakc\u00ed na retweetech. (33) \n3.6 Mo\u017enosti obrany proti \u0161\u00ed\u0159en\u00ed z\u00e1m\u011brn\u011b zkreslen\u00fdch informac\u00ed \nV roce 2017 prob\u011bhla meta anal\u00fdza, kter\u00e1 zkoumala faktory, na z\u00e1klad\u011b, kter\u00fdch lze \u010delit \npostoj\u016fm a v\u00ed\u0159e vznikl\u00fdch na z\u00e1klad\u011b dezinformac\u00edm.  \nMeta anal\u00fdza odhalila velk\u00e9 \u00fa\u010dinky dezinformac\u00ed v\u016f\u010di odhalov\u00e1n\u00ed a p\u0159etrv\u00e1v\u00e1n\u00ed \ndezinformac\u00ed tv\u00e1\u0159\u00ed v tv\u00e1\u0159 odhalen\u00ed. Vytrvalost byla siln\u011bj\u0161\u00ed a odhalovac\u00ed efekt byl slab\u0161\u00ed, \nkdy\u017e publikum samo tvo\u0159ilo d\u016fvody na podporu po\u010d\u00e1te\u010dn\u00ed dezinformace. Podrobn\u00e1 \nodhalovac\u00ed zpr\u00e1va pozitivn\u011b korelovala s odhalovac\u00edm efektem. P\u0159ekvapiv\u011b v\u0161ak podrobn\u00e1 \nodhalovac\u00ed zpr\u00e1va tak\u00e9 pozitivn\u011b korelovala s efektem dezinformace a perzistence. (7) \n  \n \n \n \n \n \n 39 Doporu\u010den\u00ed pro odhalov\u00e1n\u00ed dezinformac\u00ed na z\u00e1klad\u011b meta anal\u00fdzy: \n \nDoporu\u010den\u00ed 1: sn\u00ed\u017eit po\u010det argument\u016f, kter\u00e9 jsou v souladu s dezinformacemi.  \nZji\u0161t\u011bn\u00ed nazna\u010duj\u00ed, \u017ee vypracov\u00e1n\u00ed zpr\u00e1v v souladu s dezinformacemi sni\u017euje m\u00edru \np\u0159ij\u00edm\u00e1n\u00ed odhaluj\u00edc\u00ed zpr\u00e1vy, co\u017e zt\u011b\u017euje odstran\u011bn\u00ed fale\u0161n\u00fdch p\u0159esv\u011bd\u010den\u00ed. Zpracov\u00e1n\u00ed \nd\u016fvod\u016f konkr\u00e9tn\u00ed ud\u00e1losti umo\u017e\u0148uje p\u0159\u00edjemc\u016fm vytvo\u0159it ment\u00e1ln\u00ed model, kter\u00fd m\u016f\u017ee \npozd\u011bji zkreslit zpracov\u00e1n\u00ed nov\u00fdch informac\u00ed a zkomplikovat podtr\u017een\u00ed prvotn\u00edho \np\u0159esv\u011bd\u010den\u00ed. M\u00e9dia politici by proto m\u011bli informovat o incidentu dezinformace zp\u016fsobem, \nkter\u00fd sni\u017euje podrobn\u00e9 my\u0161lenky na podporu dezinformac\u00ed.  \n \nDoporu\u010den\u00ed 2: vytvo\u0159it podm\u00ednky, kter\u00e9 usnadn\u00ed kontrolu a proti argument dezinformac\u00ed.  \nzapojit publikum do kontroly a protiozn\u00e1men\u00ed dezinformac\u00ed \nZji\u0161t\u011bn\u00ed poukazuj\u00ed na z\u00e1v\u011br, \u017ee zapojen\u00ed publika do kontroly a proti ozn\u00e1men\u00ed dezinformac\u00ed \nzvy\u0161uje s\u00edlu n\u00e1pravn\u00e9ho \u00fasil\u00ed. Ve\u0159ejn\u00e9 mechanismy a vzd\u011bl\u00e1vac\u00ed iniciativy by proto m\u011bly \nvyvolat stav zdrav\u00e9ho skepticismu.  \n \nDoporu\u010den\u00ed 3: Opravit dezinformace s nov\u00fdmi podrobn\u00fdmi informacemi, tedy zav\u00e9st nov\u00e9 \ninformace jako sou\u010d\u00e1st odhaluj\u00edc\u00ed zpr\u00e1vy. \nAnal\u00fdzy nazna\u010dily, \u017ee p\u0159\u00edjemci dezinformac\u00ed m\u00e9n\u011b pravd\u011bpodobn\u011b p\u0159ijmou odhalovac\u00ed \nzpr\u00e1vy, kdy\u017e protiopat\u0159en\u00ed jednodu\u0161e ozna\u010d\u00ed dezinformaci za \u0161patnou, ne\u017e kdy\u017e odhal\u00ed \ndezinformaci nov\u00fdmi detaily. V\u00fdsledek pozorov\u00e1n\u00ed nazna\u010duje, \u017ee kone\u010dn\u00e1 perzistence \ndezinformac\u00ed z\u00e1vis\u00ed na tom, jak je p\u016fvodn\u011b vn\u00edm\u00e1na, a podrobn\u00e9 odhalov\u00e1n\u00ed nemus\u00ed v\u017edy \nfungovat podle o\u010dek\u00e1v\u00e1n\u00ed. (34) \n \nPokra\u010dov\u00e1n\u00ed ve v\u00fdvoji varovn\u00fdch syst\u00e9m\u016f \nTv\u016frci politik by si m\u011bli b\u00fdt v\u011bdomi pravd\u011bpodobn\u00e9ho p\u0159etrv\u00e1v\u00e1n\u00ed dezinformac\u00ed v r\u016fzn\u00fdch \noblastech. V politick\u00e9 oblasti existuj\u00ed varovn\u00e9 syst\u00e9my, jako je Factcheck.org.  \n \nPokud vyhled\u00e1v\u00e1n\u00ed na Facebooku odhal\u00ed p\u0159\u00edb\u011bh identifikovan\u00fd jako nep\u0159esn\u00fd (pat\u0159\u00ed do \njedn\u00e9 z p\u011bti hlavn\u00edch skupin pro kontrolu fakt\u016f), nov\u011b implementovan\u00e1 funkce poskytuje \nodkazy na informace o kontrole fakt\u016f. \n \n \n \n \n \n \n 40 Nap\u0159\u00edklad Snopes.com zve\u0159ejnil opravy fale\u0161n\u00fdch zpr\u00e1v, kter\u00e9 tvrd\u00ed, \u017ee miliard\u00e1\u0159 koupil \nmal\u00e9 m\u011bsto Buford, Wyoming.  \n \nSou\u010dasn\u011b v\u011bdeck\u00e9 stipendium a praxe nab\u00edzej\u00ed n\u011bkter\u00e9 inovativn\u00ed iniciativy, jako je \nretractionwatch.com, zalo\u017een\u00e9 v roce 2010 Ivanem Oranskim a Adamem Marcusem, kter\u00e9 \n\u010dten\u00e1\u0159\u016fm poskytuj\u00ed aktu\u00e1ln\u00ed informace o v\u011bdeck\u00fdch sta\u017een\u00edch. \n \nV souladu s doporu\u010den\u00edm 3, Retraction Watch \u010dasto aktualizuje \u010dten\u00e1\u0159e o podrobnostech \nretrak\u010dn\u00edch vy\u0161et\u0159ov\u00e1n\u00ed online. Takov\u00fd pr\u016fb\u011b\u017en\u00fd monitorovac\u00ed syst\u00e9m vytv\u00e1\u0159\u00ed \u017e\u00e1douc\u00ed \npodm\u00ednky kontroly a protiopat\u0159en\u00ed k dezinformac\u00edm.  \n \nTato metaanal\u00fdza za\u010dala p\u0159ezkumem relevantn\u00ed literatury o vytrvalostech postoj\u016f a \np\u0159esv\u011bd\u010den\u00ed a pot\u00e9 posoudila dopad moder\u00e1tor\u016f na dezinforma\u010dn\u00ed, odhalovac\u00ed a \ndezinforma\u010dn\u00ed perzistence. \n.Na z\u00e1klad\u011b na\u0161ich zji\u0161t\u011bn\u00ed nab\u00edz\u00edme t\u0159i doporu\u010den\u00ed: (a) omezit argumenty, kter\u00e9 podporuj\u00ed \ndezinformace, (b) zapojit publikum do kontroly a protiozn\u00e1men\u00ed dezinformac\u00ed a (c) zav\u00e9st \nnov\u00e9 informace jako sou\u010d\u00e1st odhaluj\u00edc\u00ed zpr\u00e1vy. Tato doporu\u010den\u00ed samoz\u0159ejm\u011b nezohled\u0148uj\u00ed \ndispozi\u010dn\u00ed charakteristiky publika a nemus\u00ed b\u00fdt \u00fa\u010dinn\u00e1 nebo m\u00e9n\u011b \u00fa\u010dinn\u00e1 pro lidi s \nur\u010dit\u00fdmi ideologiemi a kulturn\u00edm z\u00e1zem\u00edm. (33) \n \nBad news: \nOnline hra, kter\u00e1 umo\u017e\u0148uje lidem nasazovat roboty na Twitter, tvo\u0159it d\u016fkazy v photo-\nshopu a podn\u011bcovat konspira\u010dn\u00ed teorie, se uk\u00e1zala jako \u00fa\u010dinn\u00e1 p\u0159i zvy\u0161ov\u00e1n\u00ed jejich \npov\u011bdom\u00ed o \u201efale\u0161n\u00fdch zpr\u00e1v\u00e1ch\u201c, zjistila studie z University of Cambridge. \n \nV\u00fdsledky studie 15 000 u\u017eivatel\u016f hry \u201eBad News\u201c, kter\u00e1 byla spu\u0161t\u011bna loni v univerzitn\u00ed \nlaborato\u0159i pro soci\u00e1ln\u00ed rozhodov\u00e1n\u00ed v Cambridge (CDSMLab), uk\u00e1zaly, \u017ee bylo mo\u017en\u00e9 \nvy\u0161kolit ve\u0159ejnost, aby byla schopna l\u00e9pe odhalovat a rozli\u0161ovat propagandu. \n \n\"V\u00fdzkum nazna\u010duje, \u017ee fale\u0161n\u00e9 zpr\u00e1vy se \u0161\u00ed\u0159\u00ed rychleji a hloub\u011bji ne\u017e pravdiv\u00e9, tak\u017ee boj \nproti dezinformac\u00edm m\u016f\u017ee b\u00fdt jako boj v prohran\u00e9 bitv\u011b,\" \u0159ekl Sander van der Linden, \n\u0159editel CDSMLab. \n \n \n \n \n \n 41 Facebook investoval do prevence \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v a Rusko bylo obvin\u011bno z \u0161\u00ed\u0159en\u00ed \nnepravdiv\u00fdch informac\u00ed, kter\u00e9 maj\u00ed vliv na volby. Rusko takov\u00e9 akce odm\u00edtlo. \nStudie zve\u0159ejn\u011bn\u00e1 v \u00fater\u00fd v \u010dasopise Palgrave Communications uk\u00e1zala, \u017ee hran\u00ed \u201ebad \nnews\u201c po dobu pouh\u00fdch 15 minut pomohlo u\u017eivatel\u016fm vyvinout \u201ement\u00e1ln\u00ed protil\u00e1tky\u201c \nproti fale\u0161n\u00fdm zpr\u00e1v\u00e1m. \n \nV\u00fdsledky uk\u00e1zaly, \u017ee u hr\u00e1\u010d\u016f bylo o 21 procent m\u00e9n\u011b pravd\u011bpodobn\u00e9, \u017ee budou v\u011b\u0159it \nfale\u0161n\u00fdm zpr\u00e1v\u00e1m, ne\u017e byli p\u0159ed hran\u00edm hry. \n \nT\u00fdm p\u0159elo\u017eil hru do dev\u00edti jazyk\u016f, v\u010detn\u011b n\u011bm\u010diny, srb\u0161tiny, pol\u0161tiny a \u0159e\u010dtiny ve \nspolupr\u00e1ci s britsk\u00fdm ministerstvem zahrani\u010d\u00ed, a WhatsApp zadala novou hru pro \nplatformu pro zas\u00edl\u00e1n\u00ed zpr\u00e1v, uvedl CDSMLab. (4) \n3.6.1 Fake news a Facebook \nOv\u011b\u0159ov\u00e1n\u00ed fakt\u016f na Facebooku t\u0159et\u00edmi stranami  \nFacebook nov\u011b (2019) zavedl hodnocen\u00ed obsahu s\u202fpomoc\u00ed extern\u00edch subjekt\u016f.  \nExtern\u00ed subjekty maj\u00ed mo\u017enost n\u00e1sledn\u00e9ho hodonocen\u00ed:  \n1. Nepravda:\u202fHlavn\u00ed tvrzen\u00ed tohoto obsahu jsou fakticky nepravdiv\u00e1. Toto \nhodnocen\u00ed obecn\u011b odpov\u00edd\u00e1 hodnocen\u00edm \u201enepravda\u201c a\u202f\u201ep\u0159ev\u00e1\u017en\u011b nepravda\u201c \npou\u017e\u00edvan\u00fdm na webech subjekt\u016f zab\u00fdvaj\u00edc\u00edch se ov\u011b\u0159ov\u00e1n\u00edm fakt\u016f.  \n2. Sm\u011bs pravdy i\u202fnepravdy:\u202fTvrzen\u00ed v\u202ftomto obsahu jsou sm\u011bs\u00ed pravdiv\u00fdch \na\u202fnepravdiv\u00fdch v\u00fdrok\u016f, nebo je hlavn\u00ed tvrzen\u00ed zav\u00e1d\u011bj\u00edc\u00ed \u010di ne\u00fapln\u00e9.  \n3. Nepravdiv\u00fd titulek:\u202fPrim\u00e1rn\u00ed tvrzen\u00ed v\u202ftextu \u010dl\u00e1nku je pravdiv\u00e9, ale tvrzen\u00ed \nv\u202ftitulku je fakticky nespr\u00e1vn\u00e9.  \n4. Pravda:\u202fHlavn\u00ed tvrzen\u00ed v\u202ftomto obsahu jsou fakticky pravdiv\u00e1. Toto hodnocen\u00ed \nobecn\u011b odpov\u00edd\u00e1 hodnocen\u00edm \u201epravda\u201c a\u202f\u201ep\u0159ev\u00e1\u017en\u011b pravda\u201c pou\u017e\u00edvan\u00fdm na \nwebech subjekt\u016f zab\u00fdvaj\u00edc\u00edch se ov\u011b\u0159ov\u00e1n\u00edm fakt\u016f.  \n5. Nen\u00ed zp\u016fsobil\u00fd:\u202fV\u202fobsahu se objevuje tvrzen\u00ed, kter\u00e9 nen\u00ed mo\u017en\u00e9 ov\u011b\u0159it. Bylo \npravdiv\u00e9 v\u202fdob\u011b, kdy bylo naps\u00e1no, poch\u00e1z\u00ed z\u202fjin\u00e9 soci\u00e1ln\u00ed platformy nebo \n \n \n \n \n \n 42 z\u202fwebu \u010di str\u00e1nky, jejich\u017e hlavn\u00edm \u00fa\u010delem je vyj\u00e1d\u0159en\u00ed n\u00e1zoru nebo agendy \nur\u010dit\u00e9ho politika.  \n6. Satira:\u202fObsah je zve\u0159ejn\u011bn na str\u00e1nce nebo dom\u00e9n\u011b, kter\u00e1 je zn\u00e1m\u00e1 sv\u00fdmi \nsatirick\u00fdmi p\u0159\u00edsp\u011bvky, p\u0159\u00edpadn\u011b by soudn\u00e9mu \u010dlov\u011bku m\u011blo doj\u00edt, \u017ee obsah je \nmy\u0161len ironicky nebo jako humorn\u00e1 zpr\u00e1va se soci\u00e1ln\u00edm p\u0159esahem. P\u0159esto by \nmohlo b\u00fdt vhodn\u00e9 dodat dal\u0161\u00ed kontext.  \n7. N\u00e1zor:\u202fObsah je vyj\u00e1d\u0159en\u00edm osobn\u00edho n\u00e1zoru, obhajuje ur\u010dit\u00fd \u00fahel pohledu \n(nap\u0159\u00edklad na spole\u010denskou nebo politickou problematiku) nebo je jeho \u00fa\u010delem \npropagace autora. Mimo jin\u00e9 se to t\u00fdk\u00e1 obsahu poch\u00e1zej\u00edc\u00edho z\u202fwebu nebo \nstr\u00e1nky, jejich\u017e hlavn\u00edm \u00fa\u010delem je vyjad\u0159ov\u00e1n\u00ed n\u00e1zor\u016f nebo agendy ve\u0159ejn\u011b \nzn\u00e1m\u00fdch osobnost\u00ed, think tank\u016f (instituc\u00ed zab\u00fdvaj\u00edc\u00edch se v\u00fdzkumem \u010di \nanal\u00fdzou politiky), neziskov\u00fdch organizac\u00ed nebo firem.  \n8. Gener\u00e1tor legr\u00e1cek:\u202fJedn\u00e1 se o\u202fweby, kter\u00e9 u\u017eivatel\u016fm umo\u017e\u0148uj\u00ed vytv\u00e1\u0159et \nvlastn\u00ed \u017eertovn\u00e9 zpr\u00e1vy za \u00fa\u010delem sd\u00edlen\u00ed na webech soci\u00e1ln\u00edch m\u00e9di\u00ed.  \n9. Zat\u00edm bez hodnocen\u00ed:\u202fJedn\u00e1 se o\u202fv\u00fdchoz\u00ed stav obsahu p\u0159ed ov\u011b\u0159en\u00edm fakt\u016f \nsubjektem zab\u00fdvaj\u00edc\u00edm se ov\u011b\u0159ov\u00e1n\u00edm fakt\u016f nebo pokud je URL nefunk\u010dn\u00ed. \nPokud je hodnocen\u00ed ponech\u00e1no v\u202ftomto stavu (nebo je do tohoto stavu vr\u00e1ceno \nz\u202fjin\u00e9ho hodnocen\u00ed), znamen\u00e1 to, \u017ee bychom na z\u00e1klad\u011b va\u0161eho hodnocen\u00ed \nnem\u011bli prov\u00e1d\u011bt \u017e\u00e1dnou akci.  \nV\u202fp\u0159\u00edpad\u011b, \u017ee kontrolovan\u00e1 zpr\u00e1va obdr\u017e\u00ed negativn\u00ed hodnocen\u00ed, Facebook omez\u00ed distribuci \ndan\u00e9ho obsahu. Pokud se u\u017eivatel rozhodne sd\u00edlet zpr\u00e1vu, obdr\u017e\u00ed v\u00fdstrahu s\u202fhodnocen\u00edm \npravdivosti obsahu od extern\u00edho hodnot\u00edc\u00edho subjektu.  \n \nPodobn\u00e9 hodnocen\u00ed budou tak\u00e9 obdr\u017eovat str\u00e1nky a dom\u00e9ny. Str\u00e1nk\u00e1m s\u202fvy\u0161\u0161\u00edm po\u010dtem \nnahl\u00e1\u0161en\u00fdch p\u0159\u00edsp\u011bvk\u016f bude sn\u00ed\u017eena distribuce.  \n \nSubjekty mohou proti hodnocen\u00ed vzn\u00e9st n\u00e1mitku, nebo napravit sd\u00edlenou informaci a zru\u0161it \nt\u00edm omezen\u00ed.  (25) \n \n \n \n \n \n \n 43 4 Vlastn\u00ed pr\u00e1ce \n4.1 Existuj\u00edc\u00ed n\u00e1stroje a postupy pro odhalov\u00e1n\u00ed \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v a \npreventivn\u00ed opat\u0159en\u00ed \n4.1.1 Detekce \nFake news detector AI \nDetekuje fale\u0161n\u00e9 zpravodajsk\u00e9 weby pomoc\u00ed modelu um\u011bl\u00e9 intelgince zalo\u017een\u00e9m na \num\u011bl\u00e9 neuronov\u00e9 s\u00edti. \nDostupn\u00e9 na: http://www.fakenewsai.com/   \n \nFake News Detector \nN\u00e1stroj umo\u017e\u0148uje detekovat a ozna\u010dit fale\u0161n\u00e9 a extr\u00e9mn\u011b neobjektivn\u00ed zpr\u00e1vy. \n \nExistuje n\u011bkolik zp\u016fsob\u016f, jak n\u00e1stroj pou\u017e\u00edt: \n\u2022 Pomoc\u00ed roz\u0161\u00ed\u0159en\u00ed pro Chrome nebo Firefox \n\u2022 Pomoc\u00ed roz\u0161\u00ed\u0159en\u00ed do Telegramu \n\u2022 Zkop\u00edrov\u00e1n\u00edm a vlo\u017een\u00edm odkazu nebo textu do pole na adrese \nhttps://fakenewsdetector.org/    \n \nPo ozna\u010den\u00ed nov\u00e9 zpr\u00e1vy budou ostatn\u00ed u\u017eivatel\u00e9, kte\u0159\u00ed pou\u017e\u00edvaj\u00ed detektor fale\u0161n\u00fdch \nzpr\u00e1v, vid\u011bt dan\u00e1 ozna\u010den\u00ed, budou mu v\u011bnovat v\u00edce pozornosti a mohou tak\u00e9 ozna\u010dit. Data \njsou pot\u00e9 ulo\u017eena do datab\u00e1ze. \n \nRoz\u0161\u00ed\u0159en\u00ed pak na facebooku zobraz\u00ed n\u00e1zor ostatn\u00edch lid\u00ed: \nDostupn\u00e9 na: https://fakenewsdetector.org/en  \n \nBS Detector \nBS Detector je plug-in vyu\u017e\u00edvan\u00fd prohl\u00ed\u017ee\u010d\u00edch v\u202fMozilla a Chromu k\u202fdetekci \np\u0159\u00edtomnosti zdroje Fake news a upozorn\u011bn\u00ed na danou skute\u010dnost. Funguje tak, \u017ee vyhled\u00e1v\u00e1 \nodkazy na webov\u00e9 str\u00e1nky a porovn\u00e1v\u00e1 je s\u202fdatab\u00e1z\u00ed str\u00e1nek, kter\u00e9 ji\u017e byly v\u202fdatab\u00e1zi \n \n \n \n \n \n 44 n\u00e1stroje ozna\u010deny jako nespolehliv\u00e9. BS detector byl vyu\u017e\u00edv\u00e1n Facebookem k\u202fvy\u0159e\u0161en\u00ed \n\u0161\u00ed\u0159en\u00ed fake news na jejich soci\u00e1ln\u00ed s\u00edti. V\u202fsou\u010dasn\u00e9 dob\u011b ji\u017e FB uvedl, \u017ee pracuje na vlastn\u00ed \ntechnice k\u202fpotla\u010den\u00ed tohoto probl\u00e9mu. Detektor pouze uv\u00e1d\u00ed varovnou zpr\u00e1vu, pokud je \n\u010dl\u00e1nek pova\u017eov\u00e1n za fale\u0161n\u00fd, neuv\u00e1d\u00ed procento chyb v\u202fhl\u00e1\u0161en\u00ed a ani nesd\u00edl\u00ed, jak\u00fd typ zpr\u00e1vy \nnalezl, zda jde o nepodlo\u017een\u00e9 zpr\u00e1vy, fake news, dezinformaci.  \nDostupn\u00e9 na: https://bsdetector.tech/  \n \nMedia Bias Fact Check add-on \nToto roz\u0161\u00ed\u0159en\u00ed pro Chrome je vyu\u017e\u00edv\u00e1 datab\u00e1zi webu MediaBiasFactCheck.com a \nupozor\u0148uje nejen na proch\u00e1zen\u00ed fale\u0161n\u00fdm zpravodajsk\u00fdm serverem, ale tak\u00e9 upozorn\u00ed na \npolitick\u00e9 zaujet\u00ed legitimn\u00edch web\u016f.  \nDostupn\u00e9 na: https://mediabiasfactcheck.com/  \n \nFlock Fake News Detector  \nFake News Detector je funkce p\u0159idan\u00e1 Flockem \u2013 co\u017e je messenger a platforma pro \nspolupr\u00e1ci. Kdykoli jsou pos\u00edl\u00e1ny odkazy b\u011bhem chatov\u00e1n\u00ed, aktivuje se algoritmus FND. \nZkontroluje obsah odkaz\u016f dle vlastn\u00ed datab\u00e1ze webov\u00fdch str\u00e1nek. Poskytuje statistick\u00e9 \nhodnocen\u00ed a generuje varovnou zpr\u00e1vu, pokud zdroj nen\u00ed shled\u00e1n spolehliv\u00fdm. Datab\u00e1ze \nweb\u016f m\u00e1 v\u00edce ne\u017e 600 zpravodajsk\u00fdch adres URL, kter\u00e9 jsou kontrolov\u00e1ny skute\u010dnost\u00ed. \nNev\u00fdhodou tohoto syst\u00e9mu je, \u017ee jejich datab\u00e1ze pro kontrolu skute\u010dnost\u00ed obsahuje m\u00e9n\u011b \nz\u00e1znam\u016f a \u0161ance na spolehliv\u00e9 varov\u00e1n\u00ed p\u0159ed fale\u0161nou zpr\u00e1vou st\u00e1le nejsou vysok\u00e9. \nDostupn\u00e9 na: https://flock.com/  \n \nNews guard \nPou\u017e\u00edv\u00e1 novin\u00e1\u0159e k ov\u011b\u0159en\u00ed platnosti pomoc\u00ed 9 krit\u00e9ri\u00ed. U\u017eivatele varuje pomoc\u00ed \ndopl\u0148ku do prohl\u00ed\u017ee\u010de. Kdy v p\u0159\u00edpad\u011b, \u017ee je str\u00e1nka d\u016fv\u011bryhodn\u00e9 znak dopl\u0148ku sv\u00edt\u00ed zelen\u011b, \nv p\u0159\u00edpad\u011b, str\u00e1nka nen\u00ed d\u016fv\u011bryhodn\u00e1, znak sv\u00edt\u00ed \u010derven\u011b. \nV p\u0159\u00edpad\u011b, \u017ee str\u00e1nka nen\u00ed obsa\u017eena v datab\u00e1zi dopl\u0148ku, z\u016fstane znak \u0161ediv\u00fd.  \nV \u010desk\u00e9 prost\u0159ed\u00ed nem\u011bl dopln\u011bk v datab\u00e1zi \u017e\u00e1dnou z testovan\u00fdch dom\u00e9n. \nDostupn\u00e9 na: https://www.newsguardtech.com/   \n  \n \n \n \n \n \n 45  \nV n\u00ed\u017ee uveden\u00fdch tabulk\u00e1ch je zn\u00e1zorn\u011bna \u00fasp\u011b\u0161nost n\u00e1stroj\u016f p\u0159i identifikaci dom\u00e9n \nsd\u00edlej\u00edc\u00ed fale\u0161n\u00e9 zpr\u00e1vy. Tabulka \u010d\u00edslo 1 obsahuje seznam hodnocen\u00fdch dom\u00e9n. Tabulka \n\u010d\u00edslo 2 zn\u00e1zor\u0148uje \u00fasp\u011b\u0161nost, kdy u prvn\u00edch 4 dom\u00e9n bylo o\u010dek\u00e1van\u00fdm hodnocen\u00edm dom\u00e9n \njako \u201efale\u0161n\u00e9\u201c a u dom\u00e9n 5 a\u017e 8 bylo o\u010dek\u00e1v\u00e1n\u00e9 hodnocen\u00e9 dom\u00e9n jako nefale\u0161n\u00e9 (v tabulce \nozna\u010deno jako \u201ereal\u201c). Z 32 dotaz\u016f na 8 dom\u00e9n bylo nespr\u00e1vn\u011b za\u0159azeno 17. Spr\u00e1vn\u011b bylo \nza\u0159azeno 15 dotaz\u016f.  \n \nTabulka 1 Sezman hodnocen\u00fdch dom\u00e9n \nid URL \n1 https://parlamentnilisty.cz  \n2 http://www.bezpolitickekor ektnosti.cz  \n3 https://www.zvedavec.org  \n4 http://aeronet.cz  \n5 https://www.irozhlas.cz/  \n6 https://ww w.e15.cz  \n7 https://www.aktualne.cz  \n8 http://denikreferendum.cz  \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \nTabulka 2 Hodnocen\u00ed dom\u00e9n vybran\u00fdmi n\u00e1stroji \nId dom\u00e9n y \nN\u00e1zev n\u00e1stroje  1 2 3 4 5 6 7 8 \nFake news detector AI  real fake fake fake fake fake fake fake \nFake News Detector  real real fake real real real real real \nBS Detector real fake real real real fake real fake \n Media BiasFact Check add -on real real real real real real real real \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n \n \n \n \n \n \n 46 Tabulka 3 Pom\u011br spr\u00e1vn\u011b / nespr\u00e1vn\u011b za\u0159azen\u00fdch dom\u00e9n \n  \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n \nV n\u00ed\u017ee uveden\u00fdch tabulk\u00e1ch je zn\u00e1zorn\u011bna \u00fasp\u011b\u0161nost n\u00e1stroj\u016f p\u0159i identifikaci \nkonkr\u00e9tn\u00edch \u010dl\u00e1nk\u016f. Tabulka \u010d\u00edslo 3 obsahuje seznam hodnocen\u00fdch \u010dl\u00e1nk\u016f. Tabulka \u010d\u00edslo 4 \nzn\u00e1zor\u0148uje \u010dl\u00e1nk\u016f vybran\u00fdmi n\u00e1stroji, kdy u prvn\u00edch 4 \u010dl\u00e1nk\u016f bylo o\u010dek\u00e1van\u00fdm \nhodnocen\u00edm \u010dl\u00e1nk\u016f jako fale\u0161n\u00e9 (v tabulce ozna\u010deno \u201efake\u201c) a u \u010dl\u00e1nk\u016f 5 a\u017e 8 bylo \no\u010dek\u00e1v\u00e1n\u00e9 hodnocen\u00e9 \u010dl\u00e1nk\u016f jako nefale\u0161n\u00e9 (v tabulce ozna\u010deno jako \u201ereal\u201c). Z 32 dotaz\u016f \nna 8 \u010dl\u00e1nk\u016f bylo nespr\u00e1vn\u011b za\u0159azeno 14. Spr\u00e1vn\u011b bylo za\u0159azeno 18 dotaz\u016f.  \n \nTabulka 4 Seznam hodnocen\u00fdch zpr\u00e1v \nid Nadpis \u010dl\u00e1nku  URL \u010dl\u00e1nku \n1 Karel Gott: Uprchl\u00edci strkaj\u00ed \np\u0159ed kameru d\u011bti, za nimi jdou \nmlad\u00ed mu\u017ei v modern\u00edch \nohozech. Amerika n\u00e1s chce \ndr\u017eet ve strachu, abychom \nnerostli. Ilumin\u00e1ti nedovol\u00ed \nTrumpa http://www .parlamentnilisty.cz/arena/monitor/Karel-\nGott-Uprchlici-strkaji-pred-kameru-deti-za-nimi-\njdou-mladi-muzi-v-modernich-ohozech-Amerika-\nnas-chce-drzet-ve-strachu-abychom-nerostli-\nIluminati-nedovoli-Trumpa-429151 \n2 \u0160v\u00e9dsko je ve v\u00e1lce a \nzodpov\u011bdn\u00ed jsou politici. http://www .bezpolitickekorektnosti.cz/?p=94649 \nNespr\u00e1vn\u011b \nza\u0159azeno\n53%Spr\u00e1vn\u011b \nza\u0159azeno\n47%\n \n \n \n \n \n 47 Nep\u011bkn\u00e9 rekordy, ale premi\u00e9r \nby oslavoval \n3 Report\u00e9r al-D\u017eaz\u00edry se \ninfiltroval do proizraelsk\u00e9 \nlobby ve Washingtonu https://www .zvedavec.org/komentare2017/10/7401-\nreporter-al-dzaziry-se-infiltroval-do-proizraelske-\nlobby-ve-washingtonu.htm \n4 Varov\u00e1n\u00ed pro Babi\u0161e od Fica: https://aeronet .cz/news/varovani-pro-babise-od-fica-\ndnes-uz-vime-ze-organizatori-tech-demonstraci-po-\nvrazde-jana-kuciaka-byli-z-organizaci-ktere-plati-\ngeorge-soros-slovenska-obdoba-uooz-zacala-\nvysetrovat-organizatory/ \n5 Zmocn\u011bnec USA pro Ukrajinu \nVolker rezignoval. Objevil se \nve st\u00ed\u017enosti ohledn\u011b \nvy\u0161et\u0159ov\u00e1n\u00ed Bidena https://www .irozhlas.cz/zpravy-svet/ukrajina-\ndonald-trump-volodymyr-zelenskyj-kyjev-hunter-\nbiden-joe-biden-usa_1909280619_gak \n6 V okol\u00ed syrsk\u00e9ho m\u011bsta R\u00e1s al-\nAjn se st\u0159\u00edlelo, nehled\u011b na \np\u0159\u00edm\u011b\u0159\u00ed https://zpravy .aktualne.cz/zahranici/v-okoli-\nsyrskeho-mesta-ras-al-ajn-se-stale-bojuje-i-kdyz-\nbyl/r~975c91b6f17d11e982ef0cc47ab5f122/ \n7 British Airways hroz\u00ed pokuta \np\u0159es p\u011bt miliard za lo\u0148sk\u00fd \u00fanik \ndat z\u00e1kazn\u00edk\u016f https://www .e15.cz/zahranicni/british-airways-\nhrozi-pokuta-pres-pet-miliard-za-lonsky-unik-dat-\nzakazniku-1360440 \n8 Kv\u016fli Panama Papers p\u016fjde do \nv\u011bzen\u00ed prvn\u00ed \u010dlov\u011bk. \nNovin\u00e1\u0159ka, kter\u00e1 o nich psala http://denikreferendum .cz/clanek/28928-kvuli-\npanama-papers-pujde-do-vezeni-prvni-clovek-\nnovinarka-ktera-o-nich-psala \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n  \n \n \n \n \n \n 48 Tabulka 5 Hodnocen\u00ed zpr\u00e1v vybran\u00fdmi n\u00e1stroji \n Id \u010dl\u00e1nku \nN\u00e1zev n\u00e1s troje 1 2 3 4 5 6 7 8 \nFake news detector AI fake fake fake fake fake real fake fake \nFake News Detector  fake real fake fake real fake real fake \nBS Detector fake fake fake fake fake fake real fake \n Media BiasFact Check add -on real real real real real real fake real \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n \nTabulka 6 Pom\u011br spr\u00e1vn\u011b / nespr\u00e1vn\u011b za\u0159azen\u00fdch zpr\u00e1v \n  \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n \n  \nNespr\u00e1vn\u011b \nza\u0159azeno\n44%\nSpr\u00e1vn\u011b \nza\u0159azeno\n56%\n \n \n \n \n \n 49 Obrana s\u00edt\u011b Twitter proti fake news \nSpole\u010dnosti se proti \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v br\u00e1n\u00ed mnoha zp\u016fsoby. Jedn\u00edm ze zp\u016fsob\u016f je \nblokace odkaz\u016f na n\u011bkter\u00e9 weby. Neexistuje ve\u0159ejn\u00fd seznam blokovan\u00fdch dom\u00e9n. Pro \n\u00fa\u010dely t\u00e9to pr\u00e1ce jsem pou\u017eil seznam adres dom\u00e9n zve\u0159ejn\u011bn\u00ed NFNZ a ru\u010dn\u011b otestoval \nmo\u017enost sd\u00edlet na Twitteru.  \n \nTabulka 7 Blokovan\u00e9 dom\u00e9ny na Twitteru \nBlokovan\u00e9 dom\u00e9ny Neblokovan\u00e9 \ndom\u00e9ny \nac24.cz almanach.cz \naeronet.cz alternews.cz \nantiilluminati.net auria.sk \nbadatel.net cez-okno.net \nbadatel.sk ctusi.info \nbeo.sk eiaktivity.sk \nbezpolitickekorektnosti.cz  inespravy.sk \nceskoaktualne.cz infowars.cz \nczechfreepress.cz instory.cz \ndolezite.sk mikan.cz \ne-republika.cz nadhlad.com \neurasia24.cz neskutocne.sk \nfreepub.cz obcianskytribunal.sk  \nhlavnespravy.sk rodinajezaklad.sk \ninfokuryr.cz ruvr.ru \nisstras.eu sho.sk \nlajkit.cz slobodnyvysielac.sk \nmagnificat.sk spolocnostsbm.com \nmegazine.cz stopautogenocide.sk \nnazorobcana.sk vaseforum.sk \nnovarepublika.cz vkpatriarhat.org.ua \nnwoo.org vlastnihlavou.cz \n \n \n \n \n \n 50 osud.cz voxvictims.com \npanobcan.sk ze-sveta.cz \nparatdnes.cz   \nparlamentnilisty.cz \npravdive.eu \nprotiprudu.org \nprotiproud.cz \nprvopodstata.com \nrukojmi.cz \nslovenskeslovo.sk \nsvetkolemnas.info \nsvobodnenoviny.eu \nvlasteneckenoviny.cz \nzemavek.sk \nzvedavec.org \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \nCelkem 39 % z dom\u00e9n, kter\u00e9 \u0161\u00ed\u0159\u00ed fale\u0161n\u00e9 zpr\u00e1vy je mo\u017eno p\u0159idat do Tweetu a sd\u00edlet \ns ostatn\u00edmi u\u017eivateli. Zbyl\u00fdch 61 % je blokov\u00e1no a nelze je na s\u00edti Twitter sd\u00edlet. \n \nTabulka 8 Pom\u011br blokovan\u00fdch a neblokovan\u00fdch dom\u00e9n Twitter \n \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed  \n \nBlokovan\u00e9 \ndom\u00e9ny\n61%Neblokovan\u00e9 \ndom\u00e9ny\n39%\n \n \n \n \n \n 51 4.1.2 Ov\u011b\u0159ov\u00e1n\u00ed skute\u010dnost\u00ed \nFact-checkers jsou lid\u00e9, kte\u0159\u00ed ov\u011b\u0159uj\u00ed pravost a p\u0159esnost zpr\u00e1v. Jejich zji\u0161t\u011bn\u00ed jsou \nzve\u0159ejn\u011bna na n\u00e1sleduj\u00edc\u00edch webov\u00fdch str\u00e1nk\u00e1ch. \n \nFactCheck \nneziskov\u00e1 slu\u017eba pro voli\u010de, jej\u00ed\u017e c\u00edlem je sn\u00ed\u017eit \u00farove\u0148 podvod\u016f a zmatk\u016f v americk\u00e9  \npolitice. Sleduj\u00ed faktickou p\u0159esnost toho, co \u0159\u00edkaj\u00ed hlavn\u00ed ameri\u010dt\u00ed politi\u010dt\u00ed  \nakt\u00e9\u0159i ve form\u011b televizn\u00edch reklam, debat, projev\u016f, rozhovor\u016f a tiskov\u00fdch zpr\u00e1v. \nDostupn\u00e9 na: https://www.factcheck.org/   \n \nFirst Draft \nPoskytuje zdroje pro hl\u00e1\u0161en\u00ed a sd\u00edlen\u00ed informac\u00ed, kter\u00e9 se objevuj\u00ed online. Funguje na \nprinicpu nahla\u0161ov\u00e1n\u00ed fale\u0161n\u00fdch zpr\u00e1v u\u017eivateli. \nDostupn\u00e9 na: https://firstdraftnews.org/    \n \nFull Fact \nBritsk\u00e1 nez\u00e1visl\u00e1 charitativn\u00ed organizace prov\u00e1d\u011bj\u00edc\u00ed kontrolu fakt\u016f. Na str\u00e1nk\u00e1ch je \nmo\u017eno vyhled\u00e1vat konkr\u00e9tn\u00ed hesla, ke kter\u00fdm str\u00e1nka nab\u00eddne ov\u0159en\u00e1 fakta. \nDostupn\u00e9 na: https://fullfact.org/     \n \nPolitiFact \nSlu\u017eba, kter\u00e1 poskytuje sk\u00f3re medi\u00e1ln\u00edch v\u00fdrok\u016f: PolitiFact je americk\u00e1 webov\u00e1 \nstr\u00e1nka pro kontrolu skute\u010dnost\u00ed a d\u016fv\u011bryhodnosti prohl\u00e1\u0161en\u00ed americk\u00fdch \u010dinitel\u016f \nzapojen\u00fdch do americk\u00e9 politiky. Tento syst\u00e9m ud\u011bluje rozsudek ve form\u011b pravdo-metr (v \norigin\u00e1le Truth-O-Meter), co\u017e je m\u00edra p\u0159esnosti prohl\u00e1\u0161en\u00ed.  Nev\u00fdhodou tohoto syst\u00e9mu je, \n\u017ee je nutn\u00e1 lidsk\u00e1 intervence. Za druh\u00e9, funguje pouze pro americkou politiku. \nDostupn\u00e9 na: https://www.politifact.com/   \n \nThe Trust Project: \nJedn\u00e1 se o konsorcium zpravodajsk\u00fdch spole\u010dnost\u00ed, kter\u00e9 se sna\u017e\u00ed vyv\u00edjet standardy \ntransparentnosti, d\u00edky kter\u00fdm by \u0161lo obecn\u011b posoudit kvalitu a d\u016fv\u011bryhodnost zpr\u00e1v. \n \n \n \n \n \n 52 Dostupn\u00e9 na: https://thetrustproject.org/      \n \nPolitical correction: \nProjekt kde vybran\u00ed odborn\u00edci kontroluj\u00ed fakta politick\u00fdch prohl\u00e1\u0161en\u00ed. Prim\u00e1rn\u011b se \nzam\u011b\u0159uj\u00ed na americk\u00e9 politiky. \nDostupn\u00e9 na: http://politicalcorrection.org/factcheck/     \n \nDemagog: \nStudentsk\u00fd projekt, jeho\u017e c\u00edlem je provoz nez\u00e1visl\u00e9 factcheckingov\u00e9 platformy. \nV sou\u010dasnosti zaji\u0161\u0165uje kontrolu faktick\u00fdch tvrzen\u00ed, kter\u00e1 zazn\u00ed v politick\u00fdch televizn\u00edch a \nrozhlasov\u00fdch debat\u00e1ch. Zam\u011b\u0159uje se na \u010deskou politickou sc\u00e9nu. \nDostupn\u00e9 na: https://demagog.cz/  \n  \n \n \n \n \n \n 53 4.1.3 Proud zpr\u00e1v \nThe Factual: \nKa\u017ed\u00fd den je publikov\u00e1no p\u0159es 10 000 \u010dl\u00e1nk\u016f o stovk\u00e1ch zpravodajsk\u00fdch t\u00e9mat. \n \nFactual automaticky analyzuje, jak d\u016fv\u011bryhodn\u00fd p\u0159\u00edb\u011bh je. Hodnocen\u00ed je zalo\u017eeno na \nrozmanitosti zdroj\u016f, faktick\u00e9m t\u00f3nu psan\u00ed, odborn\u00fdch znalostech autora a dal\u0161\u00edch. \nVe zkratce The factual funguje jako timeline \u010dl\u00e1nk\u016f, kter\u00e9 by m\u011bli b\u00fdt hodnotn\u00e9 a ov\u011b\u0159en\u00e9. \nDostupn\u00e9 na: https://www.thefactual.com/   \n \nAll Sides: \nHodnot\u00ed zaujatost m\u00e9di\u00ed a vyhled\u00e1v\u00e1 nap\u0159\u00ed\u010d politick\u00fdm spektrem a poskytuje vyv\u00e1\u017een\u00e9 \nzpr\u00e1vy. \nDostupn\u00e9 na: https://www.allsides.com/unbiased-balanced-news   \n \nBlockBird \nNab\u00edz\u00ed agregovan\u00e9 zpr\u00e1vy, ov\u011b\u0159en\u00e9 komunitou, podpo\u0159en\u00e9 um\u011blou inteligenc\u00ed. U\u017eivatel\u00e9 \njsou k ov\u011b\u0159ov\u00e1n\u00ed \u010dl\u00e1nk\u016f motivov\u00e1ni odm\u011bnou ve form\u011b token\u016f vybran\u00e9 kryptom\u011bny. \n \nDostupn\u00e9 na: https://blockbird.io/  \n \n4.1.4 Edukace \nDigiPo \nje interinstitucion\u00e1ln\u00ed projekt, kter\u00fd student\u016fm pom\u00e1h\u00e1 kontrolovat p\u0159\u00edb\u011bhy a uv\u00e1d\u011bt je ve \nspr\u00e1vn\u00fd kontext. C\u00edlem je vybudovat, informa\u010dn\u00ed a webovou gramotnost student\u016f t\u00edm, \u017ee \nse studenti budou \u00fa\u010dastnit \u0161irok\u00e9ho interinstitucion\u00e1ln\u00edho projektu, kter\u00fd bude kontrolovat, \nkomentovat a poskytovat souvislosti s r\u016fzn\u00fdmi zpravodajsk\u00fdmi p\u0159\u00edb\u011bhy, kter\u00e9 se objevuj\u00ed \nna Twitteru a Facebooku. \nDostupn\u00e9 na: https://www.aascu.org/AcademicAffairs/ADP/DigiPo/    \n  \n \n \n \n \n \n 54 Bad news \nVe h\u0159e Bad News hraje hr\u00e1\u010d roli propagandisty. \u00dakolem hr\u00e1\u010de je \u0161\u00ed\u0159it zpr\u00e1vy, aby ovlivnil \nve\u0159ejnou debatu. K tomu m\u016f\u017ee vyu\u017e\u00edt nap\u0159\u00edklad arm\u00e1du trol\u016f. Hra by m\u011bla hr\u00e1\u010de nen\u00e1siln\u011b \np\u0159im\u011bt zamyslet se o nebezpe\u010dn\u00fdch d\u016fsledc\u00edch, kter\u00e9 m\u016f\u017ee dezinformace m\u00edt na \nka\u017edodenn\u00ed \u017eivot a spole\u010dnost jako celek. \n \nHra je v sou\u010dasnosti dostupn\u00e1 v 11 jazykov\u00fdch mutac\u00edch: \n\u2022 anglicky \n\u2022 \u010desky, \n\u2022 holandsky, \n\u2022 n\u011bmecky, \n\u2022 \u0159ecky, \n\u2022 esperantem, \n\u2022 polsky, \n\u2022 rumunsky, \n\u2022 srbsky, \n\u2022 slovinsky, \n\u2022 \u0161v\u00e9dsky. \n \nZvol si info \nStudentsk\u00fd projekt po\u0159\u00e1daj\u00edc\u00ed edukativn\u00ed p\u0159edn\u00e1\u0161ky pro ve\u0159ejnost, na z\u00e1kladn\u00edch i st\u0159edn\u00edch \n\u0161kol\u00e1ch. Prim\u00e1rn\u011b se \u0161kolen\u00ed zam\u011b\u0159uje na medi\u00e1ln\u00ed gramotnost. \n \nDostupn\u00e9 na: https://zvolsi.info/   \n \nFake it to make It \nJedn\u00e1 so hru ve stylu simulace, kde hr\u00e1\u010di p\u0159evezmou roli n\u011bkoho, kdo vytv\u00e1\u0159\u00ed a distribuuje \nfale\u0161n\u00e9 zpr\u00e1vy za \u00fa\u010delem zisku. Hr\u00e1\u010di se u\u010d\u00ed, jak se dezinformace vytv\u00e1\u0159ej\u00ed, \u0161\u00ed\u0159\u00ed a \nemocion\u00e1ln\u011b zac\u00edluj\u00ed. D\u00edky tomu by m\u011bli b\u00fdt l\u00e9pe p\u0159ipraveni b\u00fdt skepti\u010dt\u00ed k \ndezinformac\u00edm, se kter\u00fdmi se v budoucnu setkaj\u00ed. Hra je v anglick\u00e9m a n\u011bmeck\u00e9m jazyce. \nDostupn\u00e9 na: http://www.fakeittomakeitgame.com/   \n \n \n \n \n \n \n 55 Fake Scape \nBrn\u011bn\u0161t\u00ed studenti politologie z Masarykovi univerzity v Brn\u011b p\u0159ipravili \u00fanikovou hru s \nt\u00e9matem fake news. Hr\u00e1\u010di maj\u00ed v roli novin\u00e1\u0159\u016f prok\u00e1zat schopnost ov\u011b\u0159ovat informace. \nProjekt z\u00edskal 2 m\u00edsto v celosv\u011btov\u00e9m fin\u00e1le americk\u00e9 sout\u011b\u0159e Peer-to-Peer. \nDostupn\u00e9 na: http://fakescape.cz/  \n \n4.1.5 N\u00e1stroje pro podporu \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v \nSocio Hawk: \nSpole\u010dnost umo\u017e\u0148uj\u00edc\u00ed n\u00e1kup lajk\u016f a sleduj\u00edc\u00edch na v\u011bt\u0161in\u011b zn\u00e1m\u00fdch soci\u00e1ln\u00edch s\u00edt\u00edch. \nSpole\u010dnost tvrd\u00ed, \u017ee pou\u017e\u00edv\u00e1 white-hat metody, kter\u00e9 jsou 100% bezpe\u010dn\u00e9, aby poskytly \nskute\u010dn\u00e9 lajky / sleduj\u00edc\u00ed. Funguje d\u00edky komunitn\u00edmu syst\u00e9mu. U\u017eivatel\u016fm jsou nab\u00edzeni \npob\u00eddky, jako jsou hern\u00ed \u017eetony, bezplatn\u00e9 stahov\u00e1n\u00ed atd., aby dali lajky a sledov\u00e1n\u00ed. \n \nTabulka 9 Cen\u00edk slu\u017eby Socio Hawk \n      \n N\u00e1kup \nsleduj\u00edc\u00edch \nna \ninstagramu     \nPO\u010cET \nSLEDUJ\u00cdC\u00cdC\nH 500 1000 2500 5000 10000 \nCENA V USD 8 15 35 64 118 \n N\u00e1kup lajk\u016f \nna \ninstagramu     \nPO\u010cET \nLAJK\u016e 500 1000 2500 5000 10000 \nCENA V USD 3 6 14 26 44 \n \n \n \n \n \n 56  N\u00e1kup \nshl\u00e9dnut\u00ed na \nInstagramu     \nPO\u010cET \nSHL\u00c9DNUT\u00cd  1000 3000 5000 10000 25000 \nCENA V USD 4 8 15 28 52 \n N\u00e1kup lajk\u016f \nna \nFacebookov\nou str\u00e1nku     \nPO\u010cET \nLAJK\u016e 100 300 500 1000 2500 \nCENA V USD 5 12 22 39 88 \n N\u00e1kup lajk\u016f \nna \nFacebookov\n\u00fd \nPost/Photo/\nVideo      \nPO\u010cET \nLAJK\u016e 100 250 500 1000 2000 \nCENA V USD 4 7 12 18 28 \n N\u00e1kup \nshl\u00e9dnut\u00ed \nvide\u00ed na \nFacebooku     \nPO\u010cET \nSHL\u00c9DNUT\u00cd 1000 2500 5000 10000 25000 \nCENA V USD 5 12 18 25 28 \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n \n \n \n \n \n 57 RootJazz \nRootjazz je spole\u010dnost zab\u00fdvaj\u00edc\u00ed se v\u00fdvojem softwaru, kter\u00e1 vytv\u00e1\u0159\u00ed aplikace pro \nautomatizaci \u010dinnost\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch. Za 1 r\u00e1zov\u00fd poplatek poskytnou hotov\u00e9 bota pro \nu\u017eit\u00ed kupuj\u00edc\u00edm dle vlastn\u00edho uv\u00e1\u017een\u00ed. V nab\u00eddce jsou: \n\u2022 Instadub \no Bot zam\u011b\u0159uj\u00ed\u00ed se na Instagram. Obsahuje funkce jako nahr\u00e1v\u00e1n\u00ed fotek, automatick\u00e9 \nsledov\u00e1n\u00ed, generov\u00e1n\u00ed koment\u00e1\u0159\u016f, reakc\u00ed. \no Cena je 97 USD za program \n\u2022 TwitterDub \no Bot zam\u011b\u0159uj\u00edc\u00ed se na Twitter. Obsahuje funkce jako autimatick\u00e9 sledov\u00e1n\u00ed, \ngenerov\u00e1n\u00ed koment\u00e1\u0159\u016f, generov\u00e1n\u00ed tweet\u016f. \no Cena je 97 USD za program \n\u2022 TumblingJazz - Tumblr Bot\u00a8 \no Bot zam\u011b\u0159uj\u00ed\u00ed se na Instagram. Obsahuje funkce jako automatick\u00e1 tvorba \u00fa\u010dt\u016f, \nautoamtick\u00e9 seldov\u00e1n\u00ed nov\u00fdch \u00fa\u010dt\u016f.  \no Cena je 77 USD za program \nDostupn\u00e9 na: https://rootjazz.com/   \n \nInstalex  \nAplikace se s\u00eddlem v rusku. Ceny jsou uvedeny v rublech. Nab\u00edz\u00ed funkce jako masss \nfollow, ale i newsletter v directu, koment\u00e1\u0159e na ig, pl\u00e1nov\u00e1n\u00ed post\u016f atd. \nPrim\u00e1rn\u011b se zam\u011b\u0159uje na Instgram a TikTok. Cenov\u00e1 politika je po p\u0159epo\u010dtu za ka\u017edou \nakci cca 300 K\u010d \nDostupn\u00e9 na: https://instalex.pro/  \n4.1.6 N\u00e1stroje pro odhalov\u00e1n\u00ed bot\u016f \nBotometr \nBotometer je spolupr\u00e1ce mezi Indiana University Network Science Institute (IUNI) a \nCentrem pro komplexn\u00ed v\u00fdzkum s\u00edt\u00ed a syst\u00e9m\u016f (CNetS). Botometer je algoritmus \nstrojov\u00e9ho u\u010den\u00ed vy\u0161kolen\u00fd pro klasifikaci \u00fa\u010dtu jako bot nebo \u010dlov\u011bk zalo\u017een\u00fd na des\u00edtk\u00e1ch \ntis\u00edc ozna\u010den\u00fdch p\u0159\u00edklad\u016f. Kdy\u017e zkontroluje \u00fa\u010det, prohl\u00ed\u017ee\u010d na\u010dte ve\u0159ejn\u00fd profil a stovky \nve\u0159ejn\u00fdch tweet\u016f a zm\u00ednek pomoc\u00ed Twitter API. Tato data jsou p\u0159ed\u00e1v\u00e1na do rozhran\u00ed \n \n \n \n \n \n 58 Botometer API, kter\u00e9 extrahuje asi 1200 funkc\u00ed charakterizuj\u00edc\u00edch profil \u00fa\u010dtu, p\u0159\u00e1tele, \nstrukturu soci\u00e1ln\u00ed s\u00edt\u011b, vzorce \u010dasov\u00e9 aktivity, jazyk a sentiment. Nakonec tyto funkce \npou\u017e\u00edvaj\u00ed r\u016fzn\u00e9 modely strojov\u00e9ho u\u010den\u00ed pro v\u00fdpo\u010det sk\u00f3re bot\u016f. Nezachov\u00e1vaj\u00ed se \u017e\u00e1dn\u00e1 \ndata krom\u011b ID \u00fa\u010dtu, sk\u00f3re a zp\u011btn\u00e9 vazby poskytnut\u00e9 u\u017eivatelem. Ve zkratce Botometer \nkontroluje aktivitu \u00fa\u010dtu na s\u00edti Twitter a d\u00e1v\u00e1 mu sk\u00f3re na z\u00e1klad\u011b pravd\u011bpodobnosti, \u017ee \n\u00fa\u010det bude bot. Vy\u0161\u0161\u00ed sk\u00f3re znamen\u00e1 v\u011bt\u0161\u00ed pravd\u011bpodobnost, \u017ee \u00fa\u010det je bot. \nDostupn\u00e9 na: https://botometer.iuni.iu.edu/  \n \n \n \nZdroj: https://botometer.iuni.iu.edu/  \n \n \n \nZdroj: https://botometer.iuni.iu.edu/  \n \nTweetBotOrNot \n \nPou\u017e\u00edv\u00e1 strojov\u00e9 u\u010den\u00ed ke klasifikaci Twitter \u00fa\u010dt\u016f jako robot\u016f. V\u00fdchoz\u00ed model je z 93,53 % \np\u0159esn\u00fd p\u0159i klasifikaci robot\u016f a 95,32 % p\u0159esn\u00fd p\u0159i klasifikaci non-robot\u016f. Rychl\u00fd model je \nz 91,78 % p\u0159esn\u00fd p\u0159i klasifikaci robot\u016f a z 92,61 % p\u0159esn\u00fd p\u0159i klasifikaci non-robot\u016f. \nJedn\u00e1 se o open source software. K\u00f3d dostupn\u00fd zde: \nhttps://github.com/mkearney/tweetbotornot \nObr\u00e1zek 1 Hospod\u00e1\u0159sk\u00e9 noviny Botometr  \nObr\u00e1zek 2 Bot \u00fa\u010det Botometr  \n \n \n \n \n \n 59 Live verze dostupn\u00e1 na: https://mikewk.shinyapps.io/botornot/  \n \n \nZdroj: https://mikewk.shinyapps.io/botornot/ \n \nTwitter audit \nTwitterAudit je n\u00e1stroj, kter\u00fd m\u00e1 naj\u00edt a blokovat fale\u0161n\u00e9 sleduj\u00edc\u00ed vybr\u00e1n\u00e9ho Twitter \u00fa\u010dtu. \nSlu\u017eba je u\u010d\u00edc\u00ed se v tom smyslu, \u017ee ozna\u010deni mohou b\u00fdt roboti, trollov\u00e9 nebo prost\u011b \nneaktivn\u00ed \u00fa\u010dty. V d\u016fsledku toho mohou b\u00fdt skute\u010dn\u00ed sleduj\u00edc\u00ed n\u011bkdy myln\u011b ozna\u010deni jako \nfale\u0161n\u00ed. Jakmile bude tento sleduj\u00edc\u00ed ru\u010dn\u011b zkontrolov\u00e1n, m\u016f\u017ee se ozna\u010dit jako \u201ene \nfale\u0161n\u00fd\u201c. \nSlu\u017eba je zpoplatn\u011bna n\u00e1sledovn\u011b: \n \nTabulka 10 Cena slu\u017eby Twitter audit \nMaxim\u00e1ln\u00ed po\u010det an alyzovan\u00fdch sleduj\u00edc\u00edch  10 000 100 000 Neomezen\u00fd  \nCena za m\u011bs\u00edc v USD  4,99 14,99 29,99 \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \nDostupn\u00e9 na: https://www.twitteraudit.com/  \nObr\u00e1zek 3 Hospod\u00e1\u0159sk\u00e9 noviny BotOrNot  \n \n \n \n \n \n 60  \nZdroj: https://www.twitteraudit.com/  \n \n \n \nZdroj: https://www.twitteraudit.com/  \n \nObr\u00e1zek 4 Hospod\u00e1\u0159sk\u00e9 noviny Twitter Audit p\u0159ehled  \nObr\u00e1zek 5 Hospod\u00e1\u0159sk\u00e9 noviny Twitter Audit  \n \n \n \n \n \n 61  Zdroj: \nhttps://www.twitteraudit.com/  \n \nObr\u00e1zek 6 Hospod\u00e1\u0159sk\u00e9 noviny Twitter Audit sleduj\u00edc\u00ed  \n \n \n \n \n \n 62 4.2 P\u0159\u00edpadov\u00e1 studie: Klasifika\u010dn\u00ed modely pro rozpozn\u00e1n\u00ed fale\u0161n\u00fdch \nzpr\u00e1v na z\u00e1klad\u011b anal\u00fdzy textu \nVzhledem k neust\u00e1le se m\u011bn\u00edc\u00edm n\u00e1zv\u016fm dom\u00e9n, ze kter\u00fdch jsou sd\u00edleny fale\u0161n\u00e9 zpr\u00e1vy \njsem pro \u00fa\u010dely t\u00e9to pr\u00e1ce vybral metodu detekce na z\u00e1klad\u011b obsahu textu. C\u00edlem je zjistit, \nzda je mo\u017en\u00e9, m\u00edt spolehliv\u00fd model pro \u010desky psan\u00e9 texty, kter\u00fd analyzuje zpravodajsk\u00e9 \n\u010dl\u00e1nky, aby posoudil, zda je pravd\u011bpodobn\u00e9, \u017ee se jedn\u00e1 o skute\u010dn\u00e9 zpr\u00e1vy.  \n4.2.1 Klasifika\u010dn\u00ed model pro anglick\u00e9 prost\u0159ed\u00ed \nDataset pro tvorbu klasifika\u010dn\u00edho modelu v anglick\u00e9m prost\u0159ed\u00ed \nV anglick\u00e9m jazyce jsou ji\u017e existuj\u00edc\u00ed datasety fale\u0161n\u00fdch zpr\u00e1v, kter\u00e9 lze vyu\u017e\u00edt pro tvorbu \nklasifika\u010dn\u00edho modelu. Pro \u00fa\u010dely t\u00e9to pr\u00e1ce pou\u017eiji dataset \u201eFakeNewsNet: A Data \nRepository with News Content, Social Context and Spatiotemporal Information for \nStudying Fake News on Social Media\u201c (34) vznikl\u00fd pod Institutem pro kvantitativn\u00ed \nsoci\u00e1ln\u00ed v\u011bdu v Harvardu. \n \n4.2.1.1 Tvorba klasifika\u010dn\u00edho modelu \nPro tvorbu modelu vyu\u017eiji classificationbox od machinebox io um\u00edst\u011bn\u00fd do docker \nkontejneru. \nN\u00e1stroj umo\u017e\u0148uje pou\u017e\u00edt strojov\u00e9 u\u010den\u00ed k automatick\u00e9 klasifikaci r\u016fzn\u00fdch typ\u016f dat, jako \njsou text, obr\u00e1zky, strukturovan\u00e1 a nestrukturovan\u00e1 data. \n \nTvorba modelu: \n \nVytvo\u0159it model ur\u010duj\u00edc\u00ed dostupn\u00e9 t\u0159\u00eddy \nNau\u010dit model s konkr\u00e9tn\u00edmi vstupy (p\u0159\u00edklady) za\u0159azen\u00e9 do spr\u00e1vn\u00e9 t\u0159\u00eddy (P\u0159\u00edklady je \nmo\u017en\u00e9 p\u0159id\u00e1vat i po tvorb\u011b modelu a d\u00e1le tak vylep\u0161ovat model) \nProv\u00e9st p\u0159edpov\u011bdi \nVyhodnotit \u00fasp\u011b\u0161nost p\u0159edpov\u011bd\u00ed a p\u0159\u00edpadn\u011b upravit model pro v\u011bt\u0161\u00ed \u00fasp\u011b\u0161nost p\u0159edpov\u011bd\u00ed. \n \nPro tvorbu modelu bude pou\u017eit n\u00e1hodn\u00fd v\u00fdb\u011br 80 % p\u0159\u00edklad\u016f, dal\u0161\u00edch 20 % se pou\u017eije pro \nov\u011b\u0159en\u00ed p\u0159esnoti p\u0159edpov\u011bd\u00ed.  \n \nSpus\u0165te Classificationbox \nPomoc\u00ed p\u0159\u00edkazov\u00e9ho \u0159\u00e1dku spustit: \ndocker run-p 8080:8080-e \"MB_KEY=$MB_KEY\" machinebox/classificationbox \n \n \n \n \n \n \n 63 ClassificationBox se ovl\u00e1d\u00e1 pomoc\u00ed HTTP metod viz n\u00e1sleduj\u00edc\u00ed p\u0159\u00edklady: \n \nTvorba modelu o 2 t\u0159\u00edd\u00e1ch: \nPOST http://localhost:8080/classificationbox/models \n{ \n \"id\": \"1\", \n \"name\": \"eng_fake\", \n \"options\": { \n  \"ngrams\": 1, \n  \"skipgrams\": 1 \n }, \n \"classes\": [ \n  \"real\", \n  \"fake\", \n ] \n} \nVytvo\u0159\u00ed model s ID = 1  \nN\u00e1zev modelu bude \u201ceng_fake\u201d  \nModel bude m\u00edt 2 t\u0159\u00eddy: \u201cReal\u201d a \u201cFake\u201d \nPo\u010det slov n-gram\u016f generovan\u00fdch z textu je = 1 \nVzd\u00e1lenost mezi slovy, ze kter\u00fdch se maj\u00ed generovat n-gramy je = 1  \n \nU\u010den\u00ed modelu: \nPomoc\u00ed p\u0159\u00edkazu post vlo\u017e\u00edme jednotliv\u00e9 p\u0159\u00edklady, za\u0159azen\u00e9 do spr\u00e1vn\u00e9 t\u0159\u00eddy. \nPOST http://localhost:8080/classificationbox/models/1/teach \n{ \n \"class\": \"fake\", \n \"inputs\": [ \n  {\"key\": \"title\", \"type\": \"text\", \"value\": \"Title of fake news example 1\"}, \n  {\"key\": \"perex\", \"type\": \"text\",  \"value\": \"Perex of fake news example 1\"}, \n  {\"key\": \"article\", \"type\": \"text\", \"value\": \"Fake news example 1 Article\"} \n  \n ] \n} \nP\u0159\u00edkaz POST na model s ID = 1 \nVlo\u017e\u00ed do t\u0159\u00eddy \u201efake\u201c n\u00e1sleduj\u00edc\u00ed vstup: \nProm\u011bnn\u00e1 s n\u00e1zvem \u201etitle\u201c, typ prom\u011bnn\u00e9 je text, hodnota ulo\u017en\u00e1 do prom\u011bnn\u00e9 je \"Title of \nfake news example 1\" \nProm\u011bnn\u00e1 s n\u00e1zvem \u201eperex\u201c, typ prom\u011bnn\u00e9 je text, hodnota ulo\u017en\u00e1 do prom\u011bnn\u00e9 je \"Perex \nof fake news example 1\" \nProm\u011bnn\u00e1 s n\u00e1zvem \u201earticle\u201c, typ prom\u011bnn\u00e9 je text, hodnota ulo\u017en\u00e1 do prom\u011bnn\u00e9 je \"Fake \nnews example 1 Article \" \n \nV\u00fdpis statistik modelu: \nKdykoli v pr\u016fb\u011bhu pr\u00e1ce s modelem si m\u016f\u017eeme nechat vypsat statistiky modelu. Na \nz\u00e1klad\u011b statistik je mozn\u011b vid\u011bt, zda model obsahuje vyv\u00e1\u017een\u00e9 mno\u017estv\u00ed p\u0159\u00edklad\u016f pro \nv\u0161echny t\u0159\u00eddy. \n \n \n \n \n \n 64 GET http://localhost:8080/classificationbox/models/1/stats \nOdpov\u011b\u010f: \n{ \"predictions\": 101, \n \"examples\": 2000, \n \"classes\": [ \n  {\"name\": \"fake\", \"examples\": 1000}, \n  {\"name\": \"real\", \"examples\": 1000} \n ] \n} \nSk\u00f3re predikce je nastaveno na 101 (\u010c\u00edseln\u00e1 hodnota, kter\u00e1 ozna\u010duje hodnocen\u00ed predikce.) \nPo\u010det p\u0159\u00edklad\u016f je 2000 \nVe t\u0159\u00edd\u011b \u201efake\u201c je 1000 p\u0159\u00edklad\u016f \nVe t\u0159\u00edd\u011b \u201ereal\u201c je 1000 p\u0159\u00edklad\u016f \n \nTvorba p\u0159edpov\u011bdi: \n \nPOST http://localhost:8080/classificationbox/models/1/predict \n{ \n \"limit\": 2, \n \"inputs\": [ \n  {\"key\": \"title\", \"type\": \"text\", \"value\": \"Title of fake news example N\"}, \n  {\"key\": \"perex\", \"type\": \"text\",  \"value\": \"Perex of fake news example N\"}, \n  {\"key\": \"article\", \"type\": \"text\", \"value\": \"Fake news example N Article\"}\n  \n ] \n} \nLimit: Maxim\u00e1ln\u00ed po\u010det t\u0159\u00edd, kter\u00e9 se maj\u00ed vr\u00e1tit, v na\u0161em p\u0159\u00edpad\u011b 2. \nVstup, kter\u00fd se m\u00e1 spr\u00e1vn\u011b za\u0159adit je: \nProm\u011bnn\u00e1 s n\u00e1zvem \u201etitle\u201c, typ prom\u011bnn\u00e9 je text, hodnota ulo\u017en\u00e1 do prom\u011bnn\u00e9 je \"Title of \nfake news example N\" \nProm\u011bnn\u00e1 s n\u00e1zvem \u201eperex\u201c, typ prom\u011bnn\u00e9 je text, hodnota ulo\u017en\u00e1 do prom\u011bnn\u00e9 je \"Perex \nof fake news example N\" \nProm\u011bnn\u00e1 s n\u00e1zvem \u201earticle\u201c, typ prom\u011bnn\u00e9 je text, hodnota ulo\u017en\u00e1 do prom\u011bnn\u00e9 je \"Fake \nnews example N Article \" \n \n\u00dasp\u011b\u0161n\u00e1 odpov\u011b\u010f: \n{ \n \"success\": true, \n \"classes\": [ \n  { \n   \"id\": \"fake\", \n   \"score\": 0.91 \n  }, \n  { \n   \"id\": \"real\", \n   \"score\": 0.10 \n  } \n \n \n \n \n \n 65  ] \n} \nClasses: Vrac\u00ed seznam t\u0159\u00edd. Je zaru\u010deno, \u017ee bude vr\u00e1cena alespo\u0148 jedna t\u0159\u00edda a maxim\u00e1ln\u011b \n2. \nScore: Sk\u00f3re predikce. Sou\u010det sk\u00f3re je v\u017edy roven \u010d\u00edslu, kter\u00e9 jsme nastavili p\u0159i tvorb\u011b \nmodelu. V na\u0161em p\u0159\u00edpad\u011b se sou\u010det mus\u00ed rovnat 101. V tomto konkr\u00e9tn\u00edm p\u0159\u00edpad\u011b by se \np\u0159\u00edklad za\u0159adil do kategorie \u201efake\u201c \n \n4.2.1.2 Otestov\u00e1n\u00ed klasifika\u010dn\u00edho modelu a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti \nModel o 2 t\u0159\u00edd\u00e1ch \nPro u\u010den\u00ed se vyu\u017eije 80 procent sesb\u00edran\u00fdch \u010dl\u00e1nk\u016f a 20 procent pro n\u00e1slednou kontrolu a \nvalidaci vytvo\u0159en\u00e9ho modelu.  \nCelkem z\u00e1znam\u016f: 2000 \nPro u\u010den\u00ed pou\u017eito: 1600 z\u00e1znam\u016f \nPro kontrolu a validaci modelu vyu\u017eito: 400 z\u00e1znam\u016f \nSpr\u00e1vn\u011b za\u0159azeno: 358 \nNespr\u00e1vn\u011b: 42 \nPo\u010det chyb: 0 \nP\u0159esnost: 89.5 % \n \n4.2.2 Klasifika\u010dn\u00ed model pro \u010desk\u00e9 prost\u0159ed\u00ed \n4.2.2.1 Tvorba datasetu pro \u010desk\u00e9 prost\u0159ed\u00ed \nVoln\u011b p\u0159\u00edstupn\u00fd dataset fale\u0161n\u00fdch zpr\u00e1v a ov\u011b\u0159en\u00fdch zpr\u00e1v v \u010desk\u00e9m jazyce v dob\u011b \nvypracov\u00e1n\u00ed t\u00e9to pr\u00e1ce nebyl. Proto jsem zvolil cestu tvorby vlastn\u00edho datasetu. \n \nJako ukazatel pro tuto pr\u00e1ci jsem se rozhodl vyj\u00edt z ratingu webov\u00fdch zpravodajsk\u00fdch \nm\u00e9di\u00ed Nada\u010dn\u00edho fondu nez\u00e1visl\u00e9 \u017eurnalistiky: \n  \n \n \n \n \n \n 66 Hodnocen\u00ed na \u0161k\u00e1le - p\u0159epo\u010det  \nA pr\u016fm\u011br v\u011bt\u0161\u00ed nebo roven 0.85  \nA- pr\u016fm\u011brn\u00e9 hodnocen\u00ed se pohybuje v rozmez\u00ed 0.8 a\u017e 0.85  \nB+ pr\u016fm\u011brn\u00e9 hodnocen\u00ed se pohybuje v rozmez\u00ed 0.7 a\u017e 0.8  \nB pr\u016fm\u011brn\u00e9 hodnocen\u00ed se pohybuje v rozmez\u00ed 0.6 a\u017e 0.7  \nB- pr\u016fm\u011brn\u00e9 hodnocen\u00ed se pohybuje v rozmez\u00ed 0.5 a\u017e 0.6  \nC pr\u016fm\u011brn\u00e9 hodnocen\u00ed je men\u0161\u00ed ne\u017e 0.5  \n\u0158azen\u00ed uvnit\u0159 jednotliv\u00fdch hodnocen\u00ed na \u0161k\u00e1le (A, A- a podobn\u011b) je podle abecedy.  \n\u2022 A Aktu\u00e1ln\u011b  \n\u2022 A Den\u00edk  \n\u2022 A Den\u00edk N  \n\u2022 A Den\u00edk Referendum  \n\u2022 A E15  \n\u2022 A iRozhlas  \n\u2022 A-Euro  \n\u2022 A-Lidovky.cz  \n\u2022 A-Novinky.cz  \n\u2022 B+ Echo 24  \n\u2022 B+ iDnes  \n\u2022 B+ Ihned  \n\u2022 B Globe 24  \n\u2022 B INFO.CZ  \n\u2022 B Reflex  \n\u2022 B T\u00fdden  \n\u2022 B- Blesk  \n\u2022 B- \u010cti doma  \n\u2022 B- F\u00f3rum 24  \n\u2022 B- Hal\u00f3 noviny  \n\u2022 C AC 24  \n\u2022 C Aeronet  \n\u2022 C \u010ceskoAktu\u00e1ln\u011b.cz  \n\u2022 C Eurozpr\u00e1vy  \n \n \n \n \n \n 67 \u2022 C Parlamentn\u00ed listy  \n\u2022 C Sputnik News  \n\u2022 C Stars 24  \n\u2022 C St\u0159edoevropan  \n(35)  \n \nNa z\u00e1klad\u011b hodncen\u00ed dom\u00e9n nada\u010dn\u00edm fondem nez\u00e1visl\u00e9 \u017eurnalistiky, jsem vybral dom\u00e9ny \nz kategorie C a ozna\u010dil ji jako t\u0159\u00eddu fake. Dom\u00e9ny z kategorie A jsem ozna\u010dil jako t\u0159\u00eddu \nreal. Pro v\u011bt\u0161\u00ed variabilitu zkouman\u00e9ho vzorku jsem za\u0159adil i zpr\u00e1vy z \u201e\u017deb\u0159\u00ed\u010dku \u010desk\u00fdch \nneov\u011b\u0159en\u00fdch \u010dl\u00e1nk\u016f\u201c od \u010cesk\u00e9ho rozhlasu (36)  \n  \nSb\u011br dat \nPro urychlen\u00ed procesu z\u00edsk\u00e1v\u00e1n\u00ed \u010dl\u00e1nk\u016f do datasetu, oproti manu\u00e1ln\u00edmu kop\u00edrov\u00e1n\u00ed \njednotliv\u00fdch \u010dl\u00e1nk\u016f jsem se rozhodl vyu\u017e\u00edt framework Scrapy: \n  \nV ubuntu spu\u0161t\u011bn\u00e9m ve virtual boxu jsem p\u0159ipravil pavouky pro jednotliv\u00e9 dom\u00e9ny. \nScrapy umo\u017e\u0148uje v\u00fdb\u011br \u010d\u00e1st\u00ed na\u010dten\u00e9 webov\u00e9 str\u00e1nky pomoc\u00ed dvou metod: \n\u2022 Pomoc\u00ed css slektor\u016f \n\u2022 V\u00fdb\u011br uzl\u016f pomoc\u00ed navigace XPath \n \nC\u00edlem bylo z\u00edskat: \n\u2022 Url \u010dl\u00e1nku \n\u2022 Nadpis \n\u2022 Perex \n\u2022 Obsah \u010dl\u00e1nku \n \n \n \n \n \n \n 68 Obr\u00e1zek 7 K\u00f3d pavouka s vyu\u017eit\u00edm frameworku Scrapy pro irozhlas.cz \n \nZdroj: Vlastn\u00ed zpracov\u00e1n\u00ed \n \nV\u00fdstup lze definovat p\u0159\u00edmo v nastaven\u00ed pavouka jako vlastnost v\u00fdstupn\u00edho form\u00e1tu: \nFEED_FORMAT=\"csv\" \nFEED_URI=\"nazev.csv\" \n \n4.2.2.2 Tvorba klasifika\u010dn\u00edho modelu \nPro usnadn\u011bn\u00ed pr\u00e1ce je mo\u017en\u00e9 pou\u017e\u00edt varianty skript\u016f, jako nap\u0159\u00edklad Textclass psan\u00fd v \nGo. \n \nN\u00e1stroj pro klasifikaci textu pro machinebox psan\u00fd v jazyce Go. \nTextclass provde n\u00e1sleduj\u00edc\u00ed kroky: \n\u2022 Vytvo\u0159\u00ed nov\u00fd model \n\u2022 Pou\u017eije vybarn\u00e9 procento p\u0159\u00edklad\u016f k v\u00fduce modelu \n\u2022 K ov\u011b\u0159en\u00ed modelu pou\u017eije zb\u00fdvaj\u00edc\u00ed p\u0159\u00edklady \n\u2022 Zobraz\u00ed v\u00fdsledky, v\u010detn\u011b procentu\u00e1ln\u00ed p\u0159esnosti modelu \n\n \n \n \n \n \n 69 V termin\u00e1lu prove\u010fte: \ntextclass -teachratio 0.8 -src ./data_pro_model_obecn\u011b  \n \nN\u00e1stroj provede POST 80 % n\u00e1hodn\u00fdch p\u0159\u00edklad\u016f pro tvorbu klasifika\u010dn\u00edho modelu, \nzbyl\u00fdch 20 % bude pou\u017eito pro otestov\u00e1n\u00ed modelu. \n-src ozna\u010duje zdroj, ze kter\u00fdch m\u00e1 n\u00e1stroj vz\u00edt p\u0159ipraven\u00e1 data. \n \n\u00daprava dat pro tvrobu modelu s n\u00e1strojem Textclass: \n \nJe pot\u0159eba vytvo\u0159it adres\u00e1\u0159ovou strukturu, kter\u00e1 organizuje soubory do t\u0159\u00edd, s ka\u017edou \nslo\u017ekou jako n\u00e1zvem t\u0159\u00eddy: \n/data_pro_model_obecn\u011b \n                /trida1 \n                               trida1Priklad1.txt \n                               trida1Priklad2.txt \n                               trida1PrikladN.txt \n                /trida2 \n                               trida2Priklad1.txt \n                               trida2Priklad2.txt \n                               trida2PrikladN.txt \n                /tridaN \n                               tridaNPriklad1.txt \n                               tridaNPriklad2.txt \n                               tridaNPrikladN.txt \n \nSoubory mohou b\u00fdt text libovoln\u00e9 velikosti, jeden soubor rovn\u00e1 se jeden p\u0159\u00edklad. \n \n \n \n \n \n \n 70 4.2.2.3 Dataset pro tvorbu modelu o 4 t\u0159\u00edd\u00e1ch v \u010desk\u00e9m prost\u0159ed\u00ed \nV \u010desk\u00e9m jazyce nen\u00ed odpov\u00eddaj\u00edc\u00ed dataset. Je pot\u0159eba vytvo\u0159it vlastn\u00ed. Probl\u00e9m vyvst\u00e1v\u00e1 \np\u0159i ur\u010den\u00ed, podle jak\u00e9ho kl\u00ed\u010de roz\u0159azovat \u010dl\u00e1nky na zpravodajsky spr\u00e1vn\u00e9 a fale\u0161n\u00e9 zpr\u00e1vy. \nPro \u00fa\u010dely modelu o 4 t\u0159\u00edd\u00e1ch jsem v t\u00e9to pr\u00e1ci jsem zvolil n\u00e1sleduj\u00edc\u00ed postup: \n \nT\u0159\u00edda spolehliv\u00e9 zdroje: Na z\u00e1klad\u011b hodncen\u00ed dom\u00e9n nada\u010dn\u00edm fondem nez\u00e1visl\u00e9 \n\u017eurnalistiky, jsem vybral dom\u00e9ny z kategorie A. P\u0159\u00edklady: Aktu\u00e1ln\u011b, Den\u00edk, Den\u00edk N, \nDen\u00edk Referendum, E15, iRozhlas \n \nT\u0159\u00edda nespolehliv\u00e9 zdroje: Na z\u00e1klad\u011b hodncen\u00ed dom\u00e9n nada\u010dn\u00edm fondem nez\u00e1visl\u00e9 \n\u017eurnalistiky, jsem vybral dom\u00e9ny z kategorie B. Tyto zdroje obvykle nelze p\u0159ijmout za \nnomin\u00e1ln\u00ed hodnotu a je t\u0159eba je d\u00e1le ov\u011b\u0159it z jin\u00fdch zdroj\u016f, aby bylo mo\u017en\u00e9 ur\u010dit, zda jsou \ninformace d\u016fv\u011bryhodn\u00e9. Prezentovan\u00e9 informace jsou \u010dasto zalo\u017eeny na pov\u011bsti nebo \nsly\u0161en\u00ed. P\u0159\u00edklady: Globe 24, INFO.CZ, Reflex, T\u00fdden, Blesk, \u010cti doma, F\u00f3rum 24, Hal\u00f3 \nnoviny \n \nT\u0159\u00edda satira: Na z\u00e1klad\u011b seznamu satirick\u00fdch webu, kter\u00e9 dalo dohromady uskupen\u00ed Zvol si \nInfo. Tyto str\u00e1nky obvykle pou\u017e\u00edvaj\u00ed humor, p\u0159eh\u00e1n\u011bn\u00ed nebo parodii, aby se vyj\u00e1d\u0159ily k \naktu\u00e1ln\u00edm ud\u00e1lostem. P\u0159\u00edklady: az247, Manipulatori, Flowee, Strach cz \n \nT\u0159\u00edda fale\u0161n\u00e9 zdroje: Na z\u00e1klad\u011b hodncen\u00ed dom\u00e9n nada\u010dn\u00edm fondem nez\u00e1visl\u00e9 \u017eurnalistiky, \njsem vybral dom\u00e9ny z kategorie C.  tyto zdroje pou\u017e\u00edvaj\u00ed zkreslen\u00e9 nebo fale\u0161n\u00e9 titulky s \nc\u00edlem rozzu\u0159it, \u0161okovat nebo urazit lidi na soci\u00e1ln\u00edch m\u00e9di\u00edch, aby podpo\u0159ili lajky, sd\u00edlen\u00ed \nnebo reklamn\u00ed p\u0159\u00edjmy. P\u0159\u00edklady: AC 24, Aeronet, \u010ceskoAktu\u00e1ln\u011b.cz, Eurozpr\u00e1vy, \nParlamentn\u00ed listy, Sputnik News, Stars 24, St\u0159edoevropan. \n  \n \n \n \n \n \n 71 4.2.2.4 Tvorba klasifika\u010dn\u00edho modelu \n\u00daprava dat pro tvorbu modelu: \nAdres\u00e1\u0159ov\u00e1 struktura, kter\u00e1 organizuje soubory do 4 t\u0159\u00edd, s ka\u017edou slo\u017ekou jako n\u00e1zvem \nt\u0159\u00eddy: \n/data_pro_model_v1 \n                /spolehlive \n                               spolehlivePriklad1.txt \n                               spolehlivePriklad2.txt \n                               spolehlivePrikladN.txt \n                /nespolehlive \n                               nespolehlivePriklad1.txt \n                               nespolehlivePriklad2.txt \n                               nespolehlivePrikladN.txt \n                /satira \n                               satiraPriklad1.txt \n                               satiraPriklad2.txt \n                               satiraPrikladN.txt \n                /falesne \n                               falesnePriklad1.txt \n                               falesnePriklad2.txt \n                               falesnePrikladN.txt \n \n4.2.2.5 Otestov\u00e1n\u00ed klasifika\u010dn\u00edho modelu a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti \nModel o 4 t\u0159\u00edd\u00e1ch \nPro u\u010den\u00ed se vyu\u017eije 80 procent sesb\u00edran\u00fdch \u010dl\u00e1nk\u016f a 20 procent pro n\u00e1slednou kontrolu a \nvalidaci vytvo\u0159en\u00e9ho modelu.  \nCelkem z\u00e1znam\u016f: 1005 \nPro u\u010den\u00ed pou\u017eito: 804 z\u00e1znam\u016f \nPro kontrolu a validaci modelu vyu\u017eito: 201 z\u00e1znam\u016f \nSpr\u00e1vn\u011b za\u0159azeno: 124 \n \n \n \n \n \n 72 Nespr\u00e1vn\u011b: 77 \nErrorrs: 0 \nP\u0159esnost: 61.92 % \n \n4.2.3 Dataset pro tvorbu upraven\u00e9ho modelu o 2 t\u0159\u00edd\u00e1ch v \u010desk\u00e9m prost\u0159ed\u00ed \nT\u0159\u00edda fale\u0161n\u00e9 zdroje: Na z\u00e1klad\u011b hodnocen\u00ed dom\u00e9n nada\u010dn\u00edm fondem nez\u00e1visl\u00e9 \n\u017eurnalistiky, jsem vybral dom\u00e9ny z kategorie C.  tyto zdroje pou\u017e\u00edvaj\u00ed zkreslen\u00e9 nebo \nfale\u0161n\u00e9 titulky s c\u00edlem rozzu\u0159it, \u0161okovat nebo urazit lidi na soci\u00e1ln\u00edch m\u00e9di\u00edch, aby \npodpo\u0159ili lajky, sd\u00edlen\u00ed nebo reklamn\u00ed p\u0159\u00edjmy. P\u0159\u00edklady: AC 24, Aeronet, \n\u010ceskoAktu\u00e1ln\u011b.cz, Eurozpr\u00e1vy, Parlamentn\u00ed listy, Sputnik News, Stars 24, St\u0159edoevropan. \nPro v\u011bt\u0161\u00ed variabilitu zkouman\u00e9ho vzorku jsem za\u0159adil i zpr\u00e1vy z \u201e\u017deb\u0159\u00ed\u010dku \u010desk\u00fdch \nneov\u011b\u0159en\u00fdch \u010dl\u00e1nk\u016f\u201c (36) \n \nT\u0159\u00edda spolehliv\u00e9 zdroje: Na z\u00e1klad\u011b hodncen\u00ed dom\u00e9n nada\u010dn\u00edm fondem nez\u00e1visl\u00e9 \n\u017eurnalistiky, jsem vybral dom\u00e9ny z kategorie A. P\u0159\u00edklady: Aktu\u00e1ln\u011b, Den\u00edk, Den\u00edk N, \nDen\u00edk Referendum, E15, iRozhlas \n \nP\u00ed\u0159prava datasetu pro Classificationbox s u\u017eit\u00edm n\u00e1stroje Textclass: \nAdres\u00e1\u0159ov\u00e1 struktura, kter\u00e1 organizuje soubory do 2 t\u0159\u00edd, s ka\u017edou slo\u017ekou jako n\u00e1zvem \nt\u0159\u00eddy: \n/data_pro_model_cz \n                /real \n                               realPriklad1.txt \n                               realPriklad2.txt \n                               realPrikladN.txt \n                /fake \n                               fakePriklad1.txt \n                               fakePriklad2.txt \n                               fakePrikladN.txt \n \n \n \n \n \n 73 4.2.3.1 Otestov\u00e1n\u00ed klasifika\u010dn\u00edho modelu a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti \nModel o 2 t\u0159\u00edd\u00e1ch \nPro u\u010den\u00ed se vyu\u017eije 80 procent sesb\u00edran\u00fdch \u010dl\u00e1nk\u016f a 20 procent pro n\u00e1slednou kontrolu a \nvalidaci vytvo\u0159en\u00e9ho modelu.  \nCelkem z\u00e1znam\u016f: 1005 \nPro u\u010den\u00ed pou\u017eito: 804 z\u00e1znam\u016f \nPro kontrolu a validaci modelu vyu\u017eito: 201 z\u00e1znam\u016f \nSpr\u00e1vn\u011b za\u0159azeno: 167 \nNespr\u00e1vn\u011b: 34 \nChyby: 0 \nP\u0159esnost: 83.08457711442786 % \n \n \n \n \n \n 74 5 V\u00fdsledky a diskuse \n5.1 Porovn\u00e1n\u00ed n\u00e1stroj\u016f pro \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v \nFake news mohou v\u00e9st ke \u0161patn\u00fdm rozhodnut\u00edm a n\u00e1sledn\u00e9 d\u016fsledky jsou p\u0159etrv\u00e1vaj\u00edc\u00ed a \nobt\u00ed\u017en\u011b napraviteln\u00e9. C\u00edlen\u00e9 u\u017eit\u00ed prokazateln\u011b ovliv\u0148uje finan\u010dn\u00ed trhy, m\u00e1 velk\u00e9 dopady na \npolitickou situaci a je hodnoceno jako forma kyberterorismu. \n \nExistuj\u00ed slu\u017eby umo\u017e\u0148uj\u00edc\u00ed propagaci a distribuci fale\u0161n\u00fdch zpr\u00e1v. Cenov\u00fd model je v \ntakovou chv\u00edli celkem pevn\u011b dan\u00fd. Za pevn\u011b danou finan\u010dn\u00ed \u010d\u00e1stku dod\u00e1 poskytovatel \nslu\u017eby p\u0159esn\u011b dan\u00fd po\u010det akc\u00ed. P\u0159\u00edkladem akc\u00ed jsou reakce u p\u0159\u00edsp\u011bvk\u016f, po\u010det sleduj\u00edc\u00edch, \nkoment\u00e1\u0159e atd. N\u011bkter\u00e9 slu\u017eby vyu\u017e\u00edvaj\u00ed boty, jin\u00e9 garantuj\u00ed vyu\u017eit\u00ed lid\u00ed nam\u00edsto bot\u016f, aby \nse p\u0159ede\u0161lo postih\u016fm od provozovatel\u016f soci\u00e1ln\u00edch s\u00edt\u00ed. \n \nPro zdatn\u011bj\u0161\u00ed u\u017eivatele je mo\u017en\u00e9 zakoupit si hotov\u00e9 boty, kter\u00e9 pak lze spou\u0161t\u011bt na \nvlastn\u00edch serverech (nap\u0159\u00edklad programy od rootjazz.com). \n \nFirma se s\u00eddlem v Rusku Weberaser se zam\u011b\u0159uje na odstran\u011bn\u00ed ne\u017e\u00e1douc\u00edho obsahu nebo \ninformac\u00ed z internetu a na odstran\u011bn\u00ed nejlep\u0161\u00edch v\u00fdsledk\u016f z vyhled\u00e1va\u010d\u016f. Cena z\u00e1vis\u00ed na \nslo\u017eitosti \u00fakolu a dostupn\u00e9m \u010dase, za\u010d\u00edn\u00e1 od 3 000 RUB. \n \nN\u011bkter\u00e9 slu\u017eby vyu\u017e\u00edvaj\u00ed komunitn\u00edho mechanismu, aby p\u0159im\u011bli u\u017eivatele k akc\u00edm \npodporuj\u00edc\u00edm klienta z\u00e1jmy v \u0161\u00ed\u0159en\u00ed fake news. P\u0159\u00edkladem m\u016f\u017ee b\u00fdt VTope-online slu\u017eba s \nv\u00edce ne\u017e 2 000 000 p\u0159ev\u00e1\u017en\u011b re\u00e1ln\u00fdmi u\u017eivateli. \n  \n \n \n \n \n \n 75 5.2 Mo\u017enosti obrany proti \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch zpr\u00e1v:  \nV t\u00e9to pr\u00e1ci se povedlo vyty\u010dit 4 z\u00e1kladn\u00ed p\u0159\u00edstupy, jak se br\u00e1nit proti \u0161\u00ed\u0159en\u00ed fale\u0161n\u00fdch \nzpr\u00e1v.  \n5.2.1 Edukace \nZe v\u0161ech zkouman\u00fdch p\u0159\u00edstup\u016f, m\u00e1 tento zp\u016fsob obrany v prost\u0159ed\u00ed \u010desky mluv\u00edc\u00edho \npublika nejv\u011bt\u0161\u00ed nejv\u00edce \u010dinnost\u00ed. Vyu\u017e\u00edv\u00e1 se v\u00fdznamn\u011b zp\u016fsob gamifikace v\u00fduky. \nP\u0159\u00edkladem m\u016f\u017ee b\u00fdt online hra Bad News, nebo \u00fanikov\u00e1 hra \u201eFakeScape. Proti \u0161\u00ed\u0159en\u00ed \nfale\u0161n\u00fdch zpr\u00e1v p\u016fsob\u00ed i studentsk\u00fd projekt po\u0159\u00e1daj\u00edc\u00ed edukativn\u00ed p\u0159edn\u00e1\u0161ky \u201eZvol si info\u201c. \n \n5.2.2 Cenzurovan\u00fd obsah \nPon\u011bkud kontroverzn\u011b se m\u016f\u017ee jevit zp\u016fsob obrany pomoc\u00ed slu\u017eeb, kter\u00e9 \nzprost\u0159edkov\u00e1vaj\u00ed jen ov\u011b\u0159en\u00e9 texty. U\u017eivatel mus\u00ed v\u011b\u0159it poskytovateli slu\u017eby, \u017ee poskytuje \nskute\u010dn\u011b nestrann\u00e9 informace. P\u0159\u00edkladem m\u016f\u017ee b\u00fdt slu\u017eba The Factual.  \n \n5.2.3 Fact checkers \nFact checkers jsou lid\u00e9, kte\u0159\u00ed ov\u011b\u0159uj\u00ed pravost a p\u0159esnost zpr\u00e1v. Na \u010desk\u00e9 sc\u00e9n\u011b je to \nweb Demagog.cz. Tento postup jde jen obt\u00ed\u017en\u011b automatizovat a vy\u017eaduje zna\u010dn\u00e9 lidsk\u00e9 \u00fasil\u00ed. \n \n5.2.4 Detekce \nDetekce fale\u0161n\u00fdch zpr\u00e1v prob\u00edh\u00e1 pomoc\u00ed dvou p\u0159\u00edstup\u016f. Prvn\u00ed z nich je \u010dern\u00e1 listina \ndom\u00e9n, kter\u00e9 v minulosti ji\u017e \u0161\u00ed\u0159ili fale\u0161n\u00e9 zpr\u00e1vy. Nev\u00fdhodou takov\u00e9ho p\u0159\u00edstupu je neust\u00e1l\u00e1 \npot\u0159eba aktualizace seznamu. Na z\u00e1klad\u011b seznamu od NFNZ bylo otestov\u00e1no sd\u00edlen\u00ed 61 \ndom\u00e9n \u0161\u00ed\u0159\u00edc\u00edch fale\u0161n\u00e9 zpr\u00e1vy. Z celkov\u00e9ho po\u010dtu testovan\u00fdch dom\u00e9n, kter\u00e9 \u0161\u00ed\u0159\u00ed fale\u0161n\u00e9 \nzpr\u00e1vy bylo 61 % blokovan\u00fdch a 39 % neblokovan\u00fdch na s\u00edti Twitter. To ukazuje, \u017ee i velk\u00e1 \nspole\u010dnost jako je Twitter nezvl\u00e1d\u00e1 v sou\u010dasnosti udr\u017eovat \u010dernou listinu dom\u00e9n zcela \naktu\u00e1ln\u00ed. \n \n \n \n \n \n 76 Druh\u00fd p\u0159\u00edstup je na z\u00e1klad\u011b anal\u00fdzy textu. Pr\u016fm\u011brn\u00e1 procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost \nv rozpozn\u00e1n\u00ed a spr\u00e1vn\u00e9m za\u0159azen\u00ed dom\u00e9n do kategori\u00ed dom\u00e9ny \u0161\u00ed\u0159\u00edc\u00ed fale\u0161n\u00e9 zpr\u00e1vy a \ndom\u00e9ny \u0161\u00ed\u0159\u00edc\u00ed nefale\u0161n\u00e9 zpr\u00e1vy v \u010desk\u00e9m jazyce byla u testovan\u00fdch n\u00e1stroj\u016f pouh\u00fdch 47 %. \n \nPr\u016fm\u011brn\u00e1 procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost v rozpozn\u00e1n\u00ed fale\u0161n\u00fdch a nefale\u0161n\u00fdch zpr\u00e1v \nv \u010desk\u00e9m jazyce, byla u testovan\u00fdch n\u00e1stroj\u016f 56 %.   \n \nZ v\u00fdsledk\u016f zkouman\u00fdch n\u00e1stroj\u016f je patrn\u00e9, \u017ee sch\u00e1z\u00ed spolehliv\u00fd detek\u010dn\u00ed syst\u00e9m pro \n\u010desk\u00e9 texty. Syst\u00e9m vyu\u017e\u00edvaj\u00edc\u00ed seznam blokovan\u00fdch dom\u00e9n m\u00e1 nev\u00fdhody v neust\u00e1le \np\u0159ib\u00fdvaj\u00edc\u00edch nov\u00fdch dom\u00e9n\u00e1ch. Jako potencion\u00e1ln\u011b vhodn\u00fd p\u0159\u00edstup se jev\u00ed vyu\u017eit\u00ed \nstrojov\u00e9ho u\u010den\u00ed pro anal\u00fdzu text\u016f, p\u0159\u00edpadn\u011b kombinace obou metod. \n5.3 V\u00fdsledky p\u0159\u00edpadov\u00fdch studi\u00ed \nV r\u00e1mci p\u0159\u00edpadov\u00fdch studi\u00ed jsem se sna\u017eil zjistit, zda je mo\u017en\u00e9 m\u00edt spolehliv\u00fd model \npro \u010desky psan\u00e9 texty, kter\u00fd za pomoci strojov\u00e9ho u\u010den\u00ed analyzuje zpravodajsk\u00e9 \n\u010dl\u00e1nky. Aby posoudil, s jakou pravd\u011bpodobnost\u00ed se jedn\u00e1 o nefale\u0161n\u00e9 nebo fale\u0161n\u00e9 \nzpr\u00e1vy.  \n5.3.1 Model pro anglick\u00e9 prost\u0159ed\u00ed \nPro anglick\u00e9 prost\u0159ed\u00ed jsem vyu\u017eil existuj\u00edc\u00ed dataset p\u0159ipraven\u00fd Institutem pro \nkvantitativn\u00ed soci\u00e1ln\u00ed v\u011bdu v Harvardu.  \nKlasifika\u010dn\u00ed model m\u00e1 dv\u011b t\u0159\u00eddy a jeho procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost je 89.5 %. \nNa z\u00e1klad\u011b tohoto modelu je vid\u011bt, \u017ee je mo\u017en\u00e9 m\u00edt funk\u010dn\u00ed model pro anglicky psan\u00e9 \n\u010dl\u00e1nky. \n5.3.2 Model pro \u010desk\u00e9 prost\u0159ed\u00ed \nPro \u010desky psan\u00e9 \u010dl\u00e1nky jsem sestavil vlastn\u00ed dataset s v\u00edce ne\u017e 1000 p\u0159\u00edklady pro v\u00fduku \nmodelu. Zvolil jsem klasifika\u010dn\u00ed model obsahuj\u00edc\u00ed \u010dty\u0159i t\u0159\u00eddy, kter\u00fdmi jsou: spolehliv\u00e9 \nzdroje, nespolehliv\u00e9 zdroje, satira a fale\u0161n\u00e9 zdroje. Procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost modelu je 61.92 \n%. \n \n \n \n \n \n 77 Tento model dos\u00e1hl p\u0159ibli\u017en\u011b stejnou procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost jako hodnocen\u00e9 n\u00e1stroje \npro detekci fale\u0161n\u00fdch zpr\u00e1v. Na z\u00e1klad\u011b zku\u0161enost\u00ed z tvorby modelu pro anglick\u00e9 prost\u0159ed\u00ed, \njsem se rozhodl model zjednodu\u0161it a upravit. \n \n5.3.3 Upraven\u00fd model pro \u010desk\u00e9 prost\u0159ed\u00ed \nNov\u00fd model klasifikuje pouze do dvou t\u0159\u00edd. Obsahuje t\u0159\u00eddu fale\u0161n\u00e9 zpr\u00e1vy a nefale\u0161n\u00e9 \nzpr\u00e1vy. Procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nost modelu je 83.01 %.   \nTento klasifika\u010dn\u00ed model dos\u00e1hl v\u00fdrazn\u011b lep\u0161\u00ed procentu\u00e1ln\u00ed \u00fasp\u011b\u0161nosti ne\u017e v\u0161echny \ntestovan\u00e9 n\u00e1stroje pro detekci fale\u0161n\u00fdch zpr\u00e1v. Tento model ukazuje, \u017ee je mo\u017en\u00e9 m\u00edt \nspolehliv\u00fd model pro \u010desky psan\u00e9 texty, kter\u00fd za pomoci strojov\u00e9ho u\u010den\u00ed analyzuje \nzpravodajsk\u00e9 \u010dl\u00e1nky, aby posoudil, zda je pravd\u011bpodobn\u00e9, \u017ee se jedn\u00e1 o nefale\u0161n\u00e9, nebo \nfale\u0161n\u00e9 zpr\u00e1vy. \n5.3.4 Datasety a v\u00fdstupy z p\u0159\u00edpadov\u00fdch studi\u00ed \nV r\u00e1mci pr\u00e1ce vznikl o\u010di\u0161t\u011bn\u00fd dataset vhodn\u00fd pro u\u010den\u00ed model\u016f strojov\u00e9ho u\u010den\u00ed. Data \nbyla z\u00edsk\u00e1na pomoc\u00ed frameworku Scrapy, kter\u00fd um\u00ed parsov\u00e1n\u00ed z\u00edskan\u00e9ho textu. Dataset pro \n\u010desk\u00e9 prost\u0159ed\u00ed a zdrojov\u00e9 k\u00f3dy pavouk\u016f psan\u00fdch s vyu\u017eit\u00edm Scrapy frameworku, jsou \nsou\u010d\u00e1st\u00ed elektronick\u00e9 p\u0159\u00edlohy diplomov\u00e9 pr\u00e1ce. Sou\u010d\u00e1st\u00ed je i exportovan\u00fd Docker kontejner \nobsahuj\u00edc\u00ed fin\u00e1ln\u00ed upraven\u00fd model pro rozpozn\u00e1v\u00e1n\u00ed fale\u0161n\u00fdch zpr\u00e1v.  \n \n \n \n \n \n \n \n 78 6 Z\u00e1v\u011br \nC\u00edlem pr\u00e1ce bylo definovat vlivy \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch \u010di z\u00e1m\u011brn\u011b zkreslen\u00fdch \ninformac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch a objasnit mo\u017enosti obrany. Fake news mohou v\u00e9st ke \n\u0161patn\u00fdm rozhodnut\u00edm a n\u00e1sledn\u00e9 d\u016fsledky jsou p\u0159etrv\u00e1vaj\u00edc\u00ed a obt\u00ed\u017en\u011b napraviteln\u00e9. \nC\u00edlen\u00e9 u\u017eit\u00ed prokazateln\u011b ovliv\u0148uje finan\u010dn\u00ed trhy, m\u00e1 velk\u00e9 dopady na politickou \nsituaci a je hodnoceno jako forma kyberterorismu. \n \nSou\u010d\u00e1st\u00ed pr\u00e1ce byla anal\u00fdza dostupn\u00fdch n\u00e1stroj\u016f pro odhalov\u00e1n\u00ed fake news. V r\u00e1mci \nanal\u00fdzy se uk\u00e1zalo, \u017ee n\u00e1stroje si neum\u00ed dostate\u010dn\u011b poradit s \u010desk\u00fdm jazykem a jejich \n\u00fasp\u011b\u0161nost v odhalov\u00e1n\u00ed fake news byla velmi n\u00edzk\u00e1 a dosahovala procentu\u00e1ln\u00ed \n\u00fasp\u011b\u0161nosti okolo 50 %. \n \nJako vybranou metodu obrany proti fake news jsem zvolil detekci na z\u00e1klad\u011b anal\u00fdzy \ntextu s vyu\u017eit\u00edm strojov\u00e9ho u\u010den\u00ed. Celkem jsem sestavil t\u0159i klasifika\u010dn\u00ed modely.  \n \nPro tvorbu model\u016f byl pou\u017eit klasifika\u010dn\u00ed box od v\u00fdvoj\u00e1\u0159\u016f Machinebox.io. Box byl \num\u00edst\u011bn do kontejneru v programu Docker. Data pro \u010desk\u00fd dataset byla sb\u00edr\u00e1na za \npomoci frameworku pro programovac\u00ed jazyk Python a d\u00e1le byla upravena pomoc\u00ed \nskriptu v programovac\u00edm jazyce Go. \n \nPrvn\u00ed model pro anglick\u00e9 texty byl nau\u010den na z\u00e1klad\u011b datasetu p\u0159ipraven\u00fd Institutem \npro kvantitativn\u00ed soci\u00e1ln\u00ed v\u011bdy v Harvardu. \u00dasp\u011b\u0161nost modelu byla 89.5 %.  \nDruh\u00fd model pro \u010desky psan\u00e9 texty m\u011bl \u00fasp\u011b\u0161nost 61.92 %, jeliko\u017e p\u0159i \u010dty\u0159ech t\u0159\u00edd\u00e1ch \nnebyla dostate\u010dn\u00e1 polarizace v\u00fdsledk\u016f a jednotliv\u00e9 t\u0159\u00eddy m\u011bly tendenci se vz\u00e1jemn\u011b \np\u0159ekr\u00fdvat. T\u0159et\u00ed model pro \u010desky psan\u00e9 texty m\u011bl pouze dv\u011b t\u0159\u00eddy a dos\u00e1hl \u00fasp\u011b\u0161nosti \n83.01 %. T\u00edm se potvrdil p\u0159edpoklad, \u017ee je mo\u017en\u00e9 m\u00edt model s vysokou procentu\u00e1ln\u00ed \n\u00fasp\u011b\u0161nost\u00ed i pro \u010desky psan\u00e9 texty. \n \n \n \n \n. \n \n \n \n \n \n 79 7 Seznam pou\u017eit\u00fdch zdroj\u016f \n \n(1) PAVL\u00cd\u010cEK, Anton\u00edn. Nov\u00e1 m\u00e9dia a soci\u00e1ln\u00ed s\u00edt\u011b . Praha: Oeconomica, 2010. ISBN \n978-802-4517-421. \n(2) GRINBERG, Nir, Kenneth JOSEPH a FRIEDLAND. Science [online]. 2019, \n363(6425) [cit. 2019 -11-25]. DOI: 10.1126/science.aau2706. ISSN 00 36-8075. \n(3) SHAO, Chengcheng, Giovanni CIAMPAGLIA, Onur VAROL, Kai-Cheng YANG, \nAlessandro FLAMMINI a Filippo MENCZER. The spread of low-credibility content \nby social bots. Nature Communications . 2018, 9(1). DOI: 10.1038/s41467-018-\n06930-7. ISSN 2041-1723. Dostupn\u00e9 z: http://www.nature.com/articles/s41467-018-\n06930-7 \n(4) ROOZENBEEK, Jon a Sander VAN DER LINDEN. Fake news game confers \npsychological resistance against online misinformation. Palgrave Communications . \n2019, 5(1). DOI: 10.1057/s41599-019-0279-9. ISSN 2055-1045. Dostupn\u00e9 z: \nhttp://www.nature.com/articles/s41599 -019-0279-9 \n(5) LAZER, David MJ, et al. The science of fake news. Science, 2018, 359.6380: 1094-\n1096. b.r. DOI: LAZER, David MJ, et al. The science of fake news. Science, 2018, \n359.6380: 1 094-1096. \n(6) MCINTYRE, Lee. Post-truth . Cambridge, Massachusetts: MIT Press, 2018. MIT \nPress essential knowledge series. ISBN 978 -026-2535-045. \n(7) CHAN, Man-pui, Christopher JONES, Kathleen HALL JAMIESON a Dolores \nALBARRAC\u00cdN. Debunking: A Meta-Analysis of the Psychological Efficacy of \nMessages Countering Misinformation. Psychological Science . 2017, 28(11), 1531-\n1546. DOI: 10.1177/0956797617714579. ISSN 0956-7976. Dostupn\u00e9 z: \nhttp://journals. sagepub.com/doi/10.1177/0956797617714579  \n(8) AGRAWAL, Divyakant, Ceren BUDAK a Amr EL ABBADI. Information diffusion \nin social networks. Proceedings of the 20th ACM international conference on \nInformation and knowledge management - CIKM '11 . New York, New York, USA: \nACM Press, 2011, , 2609-. DOI: 10.1145/2063576.2064036. ISBN 9781450307178. \nDostupn\u00e9 z: http://dl.acm.org/citation.cfm?doid=20 63576.2064036  \n(9) GU, Lion; KROPOTOV, Vladimir; YAROCHKIN, Fyodor. The fake news machine: \nhow propagandists abuse the internet and manipulate the public. Trend Micro, 2017, \n5. \n(10) MIRTAHERI, Mehrnoosh, et al. Identifying and Analyzing Cryptocurrency \nManipulations in Social Media. arXiv preprint arXiv:1902.03110, 2019.  \n(11) THOMAS, Kurt, Angelika MOSCICKI, Daniel MARGOLIS et al. Data Breaches, \nPhishing, or Malware?. Proceedings of the 2017 ACM SIGSAC Conference on \nComputer and Communications Security - CCS '17 . New York, New York, USA: \nACM Press, 2017, , 1421-1434. DOI: 10.1145/3133956.3134067. ISBN \n9781450349468. Dostupn\u00e9 z: http://dl.acm.org/citation.cfm?doid=3133956.3134067  \n(12) O\u2019CARROLL., Tanya. Mexico\u2019s misinformation wars: How organized troll netw orks \nattack and harass journalists and activists in Mexico. In: Amnesty Internationa l \n \n \n \n \n \n 80 [online]. 2017 [cit. 2019-07-31]. Dostupn\u00e9 z: https://medium.com/amnesty-insights/ \nmexico-s-misinformation -wars-cb748ecb32e9.  \n(13) AUDIT N\u00c1RODN\u00cd BEZPE\u010cNOSTI: Ministerstvo vnitra \u010cR, odbor bezpe\u010dnostn\u00ed \npolitiky a prevence kriminality Nad \u0160tolou 3, 170 34  Praha 7 \u2013 Letn\u00e1. Praha, 2016.  \n(14) GOTTFRIED, Jeffrey; SHEARER, Elisa. News use across social media platforms \n2016. Pew Research Center. 2016. 2016.  \n(15) VARGIU, Eloisa a Mirko URRU. Exploiting web scraping in a collaborative \nfiltering- based approach to web advertising. Artificial Intelligence Research . 2012, \n2(1). DOI: 10.5430/air.v2n1p44. ISSN 1927-6982. Dostupn\u00e9 z: \nhttp://www.sciedu.ca/journal/index.php/air/article/vi ew/1390 \n(16) ScraperApi: Documentation. Proxi APi web Scraping  [online]. [cit. 2019-11-27]. \nDostupn\u00e9 z: https://www.scraperapi.com/documentation  \n(17) Scrapesimple: Turn any website into a CSV without coding  [online]. [cit. 2019-11-\n27]. Dostupn\u00e9 z: https://www.scrapesimple.com/  \n(18) Octoparse: Web scraping tool. : Advanced Web Scraping Features  [online]. [cit. \n2019-11-27]. Dostupn\u00e9 z: https://www.octopa rse.com/ \n(19) Scrapy: Scrapy 1.8 documentation. Scrapy: A fast and powerful scraping  [online]. \n[cit. 2019 -11-27]. Dostupn\u00e9 z: https://docs.scrapy.org/en/latest/  \n(20) Diffbot crawl bot: Knowledge graph. Diffbot: Extract anything. On any page. At any \ntime. [online]. [cit. 2019-11-27]. Dostupn\u00e9 z: \nhttps://www.diffbot.com/products/crawlbot/  \n(21) Https://cheerio.js.org/: Fast, flexible & lean implementation of core jQuery designed \nspecifically for the server.  [online]. [cit. 2019-11-27]. Dostupn\u00e9 z: \nhttps://cheerio.js.org/  \n(22) Beautiful Soup Documentation: Beautiful Soup 4.4.0 documentation \u00bb. Beautiful \nsoup [online]. [cit. 2019-11-27]. Dostupn\u00e9 z: \nhttps://www.crummy.com/software/BeautifulSo up/bs4/doc/#  \n(23) RUHI, Umar. Social Media Analytics as a business intelligence practice: current \nlandscape & future prospects. Umar Ruhi (2014),\" Social Media Analytics as a \nBusiness Intelligence Practice: Current Landscape & Future Prospects\", Journal of \nInternet Social Networking & Virtual Communities, 2014, 2014.  [online]. [cit. 2019-\n11-25]. \n(24) STIEGLITZ, Stefan, et al. Social media analytics\u2013 Challenges in topic discovery, data \ncollection, and data preparation. International journal of information management, \n2018, 39: 156 -168. [online]. [cit. 2019 -11-25]. \n(25) RAMLUCKAN, Trishana; WANLESS, Alicia; VAN NIEKERK, Brett. Cyber- Influence \nOperations: A Legal Perspective. In: ECCWS 2019 18th European Conference on \nCyber Warfare and Security. Academic Conferences and publishing limited, 2019. p. \n379. b.r. \n(26) PAUL, Christopher; MATTHEWS, Miriam. Defending against Russian Propaganda. \nThe SAGE Handbook of Propaganda, 2019, 286.  b.r. \n(27) GRINBERG, Nir, Kenneth JOSEPH, Lisa FRIEDLAND, Briony SWIRE-\nTHOMPSON a David LAZER. Science. 2019, 363(6425). DOI: \n10.1126/science.aau 2706. ISSN 0036 -8075. \n \n \n \n \n \n 81 (28) Timothy Egan. (2016 January 22). The New York Times. \u201cThe Eight-Second \nAttention Span.\u201d Last accessed on 31 May 2017, \nhttps://www.nytimes.com/2016/01/22/opinion/the-eight-second-attention-span.html.  \n[online]. [cit. 2019 -11-25]. \n(29) FERRARA, Emilio, Onur VAROL, Clayton DAVIS, Filippo MENCZER a \nAlessandro FLAMMINI. The rise of social bots. Communications of the ACM . 2016, \n59(7), 96-104. DOI: 10.1145/2818717. ISSN 00010782. Dostupn\u00e9 z: \nhttp://dl.acm.org/citation.cfm?doid=2963119.2 818717 \n(30) BESSI, Alessandro a Emilio FERRARA. Social bots distort the 2016 U.S. \nPresidential election online discussion. First Monday . 2016, 21(11). DOI: \n10.5210/fm.v21i11.7090. ISSN 13960466. Dostupn\u00e9 z: \nhttp://journals.uic.edu/ojs/index.php/fm/article /view/7090  \n(31) GEIGER, Lauren. To Bot or Not To Bot: An Exploratory Usage Study of Digitized \nMaterials from the North Carolina Collection. 2019.  b.r. \n(32) Stanford History Education Group, Evaluating Information: The Cornerstone of \nCivic Online Reasoning (Technical Report. Stanford, Calif.: Stanford University, \n2016), https://purl.stanford.edu/ fv751yt5934 . \n(33) HYSLIP, Thomas a Jason PITTMAN. A Survey of Botnet Detection Techniques by \nCommand and Control Infrastructure. Journal of Digital Forensics, Security and \nLaw. 2015. DOI: 10.153 94/jdfsl.2015.1195. ISSN 15587223.  \n(34) Shu, Kai, 2019, \"FakeNewsNet\", https://doi.org/10.7910/DVN/UEMMHS, Harvard \nDataverse, V1, UNF:6:f65WJbC1l58CmjSZdPw5ew== [fileUNF] . DOI: \nhttps://doi.org/10.7910/DVN/UEMMHS.  \n(35) Hodnocen\u00ed m\u00e9di\u00ed: Rating webov\u00fdch zpravodajsk\u00fdch m\u00e9di\u00ed  [online]. [cit. 2019-11- 27]. \nDostupn\u00e9 z: https://rating.nfnz.cz/  \n(36) \u017deb\u0159\u00ed\u010dek \u010desk\u00fdch neov\u011b\u0159en\u00fdch \u010dl\u00e1nk\u016f: Dezinforma\u010dn\u00ed texty maj\u00ed nad pravdiv\u00fdmi \nnavrch [online]. \u010cesk\u00fd rozhlas, 2016 [cit. 2019-11-27]. Dostupn\u00e9 z: \nhttps://interaktivni.r ozhlas.cz/dezinformace/  \n \n \n \n \n \n \n \n 82 8 P\u0159\u00edlohy na p\u0159ilo\u017een\u00e9m disku\n\uf0b7 model.tar: Klasifika\u010dn\u00ed model pro \u010desk\u00e9 prost\u0159ed\u00ed v exportovan\u00e9m kontejneru pro \nDocker \n\uf0b7 cz_data: Dataset pro \u010desk\u00e9 texty rozd\u011blen\u00fd do 2 t\u0159\u00edd \n\uf0b7 eng_data: Dataset pro anglick\u00e9 texty rozd\u011blen\u00fd do 2 t\u0159\u00edd \n\uf0b7 spiders: Zdrojov\u00e9 k\u00f3dy pavouk\u016f vyu\u017e\u00edvaj\u00edc\u00ed framework Scrapy \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Diplomov\u00e1 pr\u00e1ce \u0160\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch", "author": ["BR Hartman"], "pub_year": "2019", "venue": "NA", "abstract": "Tato diplomov\u00e1 pr\u00e1ce se zab\u00fdv\u00e1 problematikou \u0161\u00ed\u0159en\u00ed informac\u00ed na soci\u00e1ln\u00edch s\u00edt\u00edch. Hlavn\u00edm  c\u00edlem diplomov\u00e9 pr\u00e1ce je definovat vlivy \u0161\u00ed\u0159en\u00ed nepravdiv\u00fdch \u010di z\u00e1m\u011brn\u011b zkreslen\u00fdch"}, "filled": false, "gsrank": 650, "pub_url": "https://theses.cz/id/gajnmu/zaverecna_prace.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:oDqrG5Lr4tcJ:scholar.google.com/&output=cite&scirp=649&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D640%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=oDqrG5Lr4tcJ&ei=erWsaPG6EvnSieoPxKLpgQ0&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:oDqrG5Lr4tcJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://theses.cz/id/gajnmu/zaverecna_prace.pdf"}}, {"title": "The COVID-19 social media infodemic", "year": "2020", "pdf_data": "1\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreportsThe COVID\u201119 social media \ninfodemic\nMatteo Cinelli1,2, Walter Quattrociocchi1,2,3*, Alessandro Galeazzi4, Carlo Michele Valensise5, \nEmanuele Brugnoli1, Ana Lucia Schmidt2, Paola Zola6, Fabiana Zollo1,2,7 & Antonio Scala1,3\nWe address the diffusion of information about the COVID\u201119 with a massive data analysis on Twitter, \nInstagram, YouTube, Reddit and Gab. We analyze engagement and interest in the COVID\u201119 topic and provide a differential assessment on the evolution of the discourse on a global scale for each \nplatform and their users. We fit information spreading with epidemic models characterizing the basic \nreproduction number \nR0 for each social media platform. Moreover, we identify information spreading \nfrom questionable sources, finding different volumes of misinformation in each platform. However, information from both reliable and questionable sources do not present different spreading patterns. \nFinally, we provide platform\u2011dependent numerical estimates of rumors\u2019 amplification.\nThe World Health Organization (WHO) defined the SARS-CoV-2 virus outbreak as a severe global  threat\n1. As \nforeseen in 2017 by the global risk report of the World Economic forum, global risks are interconnected. In \nparticular, the case of the COVID-19 epidemic (the infectious disease caused by the most recently discovered human coronavirus) is showing the critical role of information diffusion in a disintermediated news  cycle\n2.\nThe term infodemic3,4 has been coined to outline the perils of misinformation phenomena during the man -\nagement of disease  outbreaks5\u20137, since it could even speed up the epidemic process by influencing and frag-\nmenting social  response8. As an example, CNN has recently anticipated a rumor about the possible lock-down \nof Lombardy (a region in northern Italy) to prevent  pandemics9, publishing the news hours before the official \ncommunication from the Italian Prime Minister. As a result, people overcrowded trains and airports to escape from Lombardy toward the southern regions before the lock-down was put in place, disrupting the government initiative aimed to contain the epidemics and potentially increasing contagion. Thus, an important research challenge is to determine how people seek or avoid information and how those decisions affect their  behavior\n10, \nparticularly when the news cycle\u2014dominated by the disintermediated diffusion of information\u2014alters the way information is consumed and reported on.\nThe case of the COVID-19 epidemic shows the critical impact of this new information environment. The \ninformation spreading can strongly influence people\u2019s behavior and alter the effectiveness of the countermeas -\nures deployed by governments. To this respect, models to forecast virus spreading are starting to account for the behavioral response of the population with respect to public health interventions and the communication dynamics behind content  consumption\n8,11,12.\nSocial media platforms such as Y ouTube and Twitter provide direct access to an unprecedented amount of \ncontent and may amplify rumors and questionable information. Taking into account users\u2019 preferences and atti-tudes, algorithms mediate and facilitate content promotion and thus information  spreading\n13. This shift from the \ntraditional news paradigm profoundly impacts the construction of social  perceptions14 and the framing of narra-\ntives; it influences policy-making, political communication, as well as the evolution of public  debate15,16, especially \nwhen issues are  controversial17. Users online tend to acquire information adhering to their  worldviews18,19, to \nignore dissenting  information20,21 and to form polarized groups around shared  narratives22,23. Furthermore, when \npolarization is high, misinformation might easily  proliferate24,25. Some studies pointed out that fake news and \ninaccurate information may spread faster and wider than fact-based  news26. However, this might be platform-\nspecific effect. The definition of \u201cFake News\u201d may indeed be inadequate since political debate often resorts \nto labelling opposite news as unreliable or  fake27. Studying the effect of the social media environment on the \nperception of polarizing topics is being addressed also in the case of COVID-19. The issues related to the cur -\nrent infodemics are indeed being tackled by the scientific literature from multiple perspectives including the open\n1CNR-ISC, Rome, Italy. 2Universit\u00e0 Ca\u2019 Foscari di Venezia, Venice, Italy. 3Big Data in Health Society, Rome, \nItaly. 4Universit\u00e0 di Brescia, Brescia, Italy. 5Politecnico di Milano, Milan, Italy. 6CNR-IIT, Pisa, Italy. 7Center for the \nHumanities and Social Change, Venice, Italy. *email: w.quattrociocchi@unive.it\n2\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/dynamics of hatespeech and conspiracy  theories28,29, the effect of bots and automated  accounts30, and the threats \nof misinformation in terms of diffusion and opinions  formation31,32.\nIn this work we provide an in-depth analysis of the social dynamics in a time window where narratives and \nmoods in social media related to the COVID-19 have emerged and spread. While most of the studies on misin-\nformation diffusion focus on a single  platform17,26,33, the dynamics behind information consumption might be \nparticular to the environment in which they spread on. Consequently, in this paper we perform a comparative analysis on five social media platforms (Twitter, Instagram, Y ouTube, Reddit and Gab) during the COVID-19 outbreak. The dataset includes more than 8 million comments and posts over a time span of 45 days. We analyze user engagement and interest about the COVID-19 topic, providing an assessment of the discourse evolution \nover time on a global scale for each platform. Furthermore, we model the spread of information with epidemic \nmodels, characterizing for each platform its basic reproduction number ( \nR0 ), i.e. the average number of second-\nary cases (users that start posting about COVID-19) an \u201cinfectious\u201d individual (an individual already posting on COVID-19) will create. In epidemiology, \nR0\u00a0=\u00a01 is a threshold parameter. When R0<1 the disease will die \nout in a finite period of time, while the disease will spread for R0>1 . In social media, R0>1 will indicate the \npossibility of an infodemic.\nFinally, coherently with the classification provided by the fact-checking organization Media Bias/Fact  Check34 \nthat classifies news sources based on the truthfulness and bias of the information published, we split news outlets \ninto two groups. These groups are either associated to the diffusion of (mostly) reliable or (mostly) questionable contents and we characterize the spreading of information regarding COVID-19 relying on this classification. We find that users in mainstream platforms are less susceptible to the diffusion of information from question -\nable sources and that information deriving from news outlets marked either as reliable or questionable do not present significant difference in the way it spreads.\nOur findings suggest that the interaction patterns of each social media combined with the peculiarity of the \naudience of each platform play a pivotal role in information and misinformation spreading. We conclude the paper by measuring rumor\u2019s amplification parameters for COVID-19 on each social media platform.\nResults\nWe analyze mainstream platforms such as Twitter, Instagram and Y ouTube as well as less regulated social media platforms such as Gab and Reddit. Gab is a crowdfunded social media whose structure and features are Twitter-inspired. It performs very little control on content posted; in the political spectrum, its user base is considered to be far-right. Reddit is an American social news aggregation, web content rating, and discussion website based on collective filtering of information.\nWe perform a comparative analysis of information spreading dynamics around the same argument in differ -\nent environments having different interaction settings and audiences. We collect all pieces of content related to COVID-19 from the 1st of January to the 14th of February. Data have been collected filtering contents accord -\ningly to a selected sample of Google Trends\u2019 COVID-19 related queries such as: coronavirus , coronavirusout -\nbreak , imnotavirus , ncov , ncov -19, pandemic , wuhan . The deriving dataset is then composed of 1,342,103 posts \nand 7,465,721 comments produced by 3,734,815 users. For more details regarding the data collection refer to Methods.\nInteraction patterns. First, we analyze the interactions (i.e., the engagement) that users have with COVID-\n19 topics on each platform. The upper panel of Fig.\u00a0 1 shows users\u2019 engagement around the COVID-19 topic. \nDespite the differences among platforms, we observe that they all display a rather similar distribution of the users\u2019 activity characterized by a long tail. This entails that users behave similarly for what concern the dynamics of reactions and content consumption. Indeed, users\u2019 interactions with the COVID-19 content present attention \npatterns similar to any other  topic\n35. The highest volume of interactions in terms of posting and commenting can \nbe observed on mainstream platforms such as Y ouTube and Twitter.\nThen, to provide an overview of the debate concerning the disease outbreak, we extract and analyze the topics \nrelated to the COVID-19 content by means of Natural Language Processing techniques. We build word embed -\nding for the text corpus of each platform, i.e. a word vector representation in which words sharing common contexts are in close proximity. Moreover, by running clustering procedures on these vector representations, we \nseparate groups of words and topics that are perceived as more relevant for the COVID-19 debate. For further details refer to Methods. The results (Fig.\u00a0 1, middle panel) show that topics are quite similar across each social \nmedia platform. Debates range from comparisons to other viruses, requests for God blessing, up to racism, while the largest volume of interaction is related to the lock-down of flights.\nFinally, to characterize user engagement with the COVID-19 on the five platforms, we compute the cumulative \nnumber of new posts each day (Fig.\u00a0 1, lower panel). For all platforms, we find a change of behavior around the \n20th of January, that is the day that the World Health Organization (WHO) issued its first situation report on the COVID-19\n36. The largest increase in the number of posts is on the 21st of January for Gab, the 24th January for \nReddit, the 30th January for Twitter, the 31th January for Y ouTube and the 5th of February for Instagram. Thus, social media platforms seem to have specific timings for content consumption; such patterns may depend upon the difference in terms of audience and interaction mechanisms (both social and algorithmic) among platforms.\nInformation spreading. Efforts to simulate the spreading of information on social media by reproducing \nreal data have mostly applied variants of standard epidemic  models37\u201340. Coherently, we analyze the observed \nmonotonic increasing trend in the way new users interact with information related to the COVID-19 by using \nepidemic models. Unlike previous works, we do not only focus on models that imply specific growth mecha-nisms, but also on phenomenological models that emphasize the reproducibility of empirical  data\n41.\n3\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Most of the epidemiological models focus on the basic reproduction number R0 , representing the expected \nnumber of new infectors directly generated by an infected individual for a given time  period42. An epidemic \noccurs if R0>1,\u2014i.e., if an exponential growth in the number of infections is expected at least in the initial \nphase. In our case, we try to model the growth in number of people publishing a post on a subject as an infec -\ntive process, where people can start publishing after being exposed to the topic. While in real epidemics R0>1 \nhighlights the possibility of a pandemic, in our approach R0>1 indicates the emergence of an infodemic. We \nmodel the dynamics both with the phenomenological model  of43 (from now on referred to as the EXP model) \nand with the standard SIR (Susceptible, Infected, Recovered) compartmental  model44. Further details on the \nmodeling approach can be found in Methods.\nAs shown in Fig.\u00a0 2, each platform has its own basic reproduction number R0 . As expected, all the values of R0 \nare supercritical\u2014even considering confidence intervals (Table\u00a0 1)\u2014signaling the possibility of an infodemic. This \nobservation may facilitate the prediction task of information spreading during critical events. Indeed, according \nto this result we can consider information spreading patterns on each social media to predict social response when implementing crisis management plans.\nWhile \nR0 is a good proxy for the engagement rate and a good predictor for epidemic-like information spread-\ning, social contagion phenomena might be in general more  complex45\u201347. For instance, in the case of Instagram, \nwe observe an abrupt jump in the number of new users that cannot be explained with continuous models like the standard epidemic ones; accordingly, the SIR model estimates a value of \nR0\u223c102 that is way beyond what \nhas been observed in any real-world epidemic.\nFigure\u00a01.  Upper panel: activity (likes, comments, reposts, etc.) distribution for each social media. Middle panel: \nmost discussed topics about COVID-19 on each social media. Lower panel: cumulative number of content (posts, tweets, videos, etc.) produced from the 1st of January to the 14th of February. Due to the Twitter API limitations in gathering past data, the first data point for Twitter is dated January 27th.\n4\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Questionable VS reliable information sources. We conclude our analysis by comparing the diffusion \nof information from questionable and reliable sources on each platform. We tag links as reliable or question-\nable according to the data reported by the independent fact-checking organization Media Bias/Fact  Check34. In \norder to clarify the limits of an approach that is based on labelling news outlets rather than single articles, as for instance performed  in\n33,48, we report the definitions used in this paper for questionable and reliable information \nsources. In accordance with the criteria established by MBFC, by questionable information source we mean a news outlet systematically showing one or more of the following characteristics: extreme bias, consistent promo-tion of propaganda/conspiracies, poor or no sourcing to credible information, information not supported by evidence or unverifiable, a complete lack of transparency and/or fake news. By reliable information sources we \nmean news outlets that do not show any of the aforementioned characteristics. Such outlets can anyway produce \ncontents potentially displaying a bias towards liberal/conservative opinion, but this does not compromise the overall reliability of the source.\nFigure\u00a0 3 shows, for each platform, the plots of the cumulative number of posts and reactions related to reliable \nsources versus the cumulative number of posts and interactions referring to questionable sources. By interactions we mean the overall reactions, e.g. likes or other form or endorsement and comments, that can be performed with respect to a post on a social platform. Surprisingly, all the posts show a strong linear correlation, i.e., the number of posts/reactions relying on questionable and reliable sources grows with the same pace inside the same social media platform. We observe the same phenomenon also for the engagement with reliable and questionable \nsources. Hence, the growth dynamics of posts/interactions related to questionable news outlets is just a re-scaled \nversion of the growth dynamics of posts/reactions related to reliable news outlets; however, the re-scaling factor \n\u03c1 (i.e., the fraction of questionable over reliable) is strongly dependent on the platform.\nIn particular, we observe that in mainstream social media the number of posts produced by questionable \nsources represents a small fraction of posts produced by reliable ones; the same thing happens in Reddit. Among less regulated social media, a peculiar effect is observed in Gab: while the volume of posts from questionable sources is just the \n\u223c70% of the volume of posts from reliable ones, the volume of reactions for the former ones \nis \u223c3 times bigger than the volume for the latter ones. Such results hint the possibility that different platform \nreact differently to information produced by reliable and questionable news outlets.\nTo further investigate this issue, we define the amplification factor E as the average number of reactions to a \npost; hence, E is a measure that quantifies the extent to which a post is amplified in a social media. We observe \nthat the amplification EU (for unreliable posts posts produced by questionable outlets) and ER (for reliable posts \nFigure\u00a02.  Growth of the number of authors versus time. Time is expressed in number of days since 1st January \n2020 (day 1). Shaded areas represents [5%, 95%] estimates of the models obtained via bootstrapping least square estimates of the EXP model (upper panels) and of the SIR model (lower panels). For details the SIR and the EXP model, see SI.\nTable 1.  [5%, 95%] interval of confidence R0 as estimated from bootstrapping the least square fits parameter \nof the EXP and of the SIR model. Notice that, due to the steepness of the growth of the number of new authors in Instagram, \nR0 assumes unrealistic values \u223c102 for the SIR model.Gab Reddit You Tub e Instagram Twitter\nREXP\n0[1.42, 1.52] [1.44, 1.51] [1.56, 1.70] [2.02, 2.64] [1.65, 2.06]\nRSIR\n0[2.2, 2.5] [2.4, 2.8] [3.2, 3.5] [1.1\u00d7102, 1.6\u00d7102] [4.0, 5.1]\n5\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/posts produced by reliable outlets) vary from social media platform to social media platform and that assumes \nthe largest values in Y ouTube and the lowest in Gab. To measure the permeability of a platform to posts from questionable/reliable news outlets, we then define the coefficient of relative amplification \n\u03b1=EU/ER . It is a \nmeasure of whether a social media amplifies questionable ( \u03b1> 1 ) or reliable ( \u03b1< 1 ) posts. Results are shown in \nTable\u00a0 2. Among mainstream social media, we notice that Twitter is the most neutral ( \u03b1\u223c1 i.e. EU\u223cER ), while \nY ouTube amplifies questionable sources less (  \u03b1\u223c4/10 ). Among less popular social media, Reddit reduces the \nimpact of questionable sources (  \u03b1\u223c1/2 ), while Gab strongly amplifies them (  \u03b1\u223c4).\nTherefore, we conclude that the main drivers of information spreading are related to specific peculiarities of \neach platform and depends upon the group dynamics of individuals engaged with the topic.\nFigure\u00a03.  Upper panels: plot of the cumulative number of posts referring to questionable sources versus \nthe cumulative number of posts referring to reliable sources. Lower panel: plot of the cumulative number of engagements relatives to questionable sources versus the cumulative number of engagements relative to reliable sources. Notice that a linear behavior indicates that the time evolution of questionable posts/engagements is just a re-scaled version of the time evolution of reliable posts/engagements. Each plot indicates \nthe regression coefficients \n\u03c1 , representing the ratio among the volumes of questionable and reliable posts ( \u03c1post ) \nand engagements ( \u03c1eng ). In more popular social media, the number of questionable posts represents a small \nfraction of the reliable ones; same thing happens in Reddit. Among less popular social media, a peculiar effect \nis observed in Gab: while the volume of questionable posts is just the \u223c70% of the volume of reliable ones, the \nvolume of engagements for questionable posts is \u223c3 times bigger than the volume for reliable ones. Further \ndetails concerning the regression coefficients are reported in Methods.\nTable 2.  The average engagement of a post is the number of reactions expected for a post and is a measure of \nhow much a post is amplified in each social media platform. The average engagement EU (for unreliable post) \nand ER (for reliable post) vary from platform to platform, and are the largest in Twitter and the lowest in Gab. \nThe coefficient of relative amplification \u03b1=EU/ER measures whether a social media amplifies more unreliable \n( \u03b1> 1 ) or reliable ( \u03b1< 1 ) posts. Among more popular social media platforms, we notice that Twitter is the \nmost neutral ( \u03b1\u223c1% i.e. EU\u223cER ), while Y ouTube amplifies unreliable sources less ( \u03b1\u223c4/10 ). Among less \npopular social media platforms, Reddit reduces the impact of unreliable sources ( \u03b1\u223c1/2 ) while Gab strongly \namplifies them ( \u03b1\u223c4).EUER\u03b1\nGab 5.6 1.4 3.9\nReddit 22.7 40.1 0.55\nTwitter 15.1 15.6 0.97\nYou Tu b e 1.4\u00d71043.9\u00d71040.35\n6\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Conclusions\nIn this work we perform a comparative analysis of users\u2019 activity on five different social media platforms during \nthe COVID-19 health emergency. Such a timeframe is a good benchmark for studying content consumption dynamics around critical events in a times when the accuracy of information is threatened. We assess user engagement and interest about the COVID-19 topic and characterize the evolution of the discourse over time.\nFurthermore, we model the spread of information using epidemic models and provide basic growth param-\neters for each social media platform. We then analyze the diffusion of questionable information for all channels, finding that Gab is the environment more susceptible to misinformation dissemination. However, information deriving from sources marked either as reliable or questionable do not present significant differences in their its spreading patterns. Our analysis suggests that information spreading is driven by the interaction paradigm imposed by the specific social media or/and by the specific interaction patterns of groups of users engaged with the topic. We conclude the paper by computing rumor\u2019s amplification parameters for social media platforms.\nWe believe that the understanding of social dynamics between content consumption and social media plat -\nforms is an important research subject, since it may help to design more efficient epidemic models accounting for social behavior and to design more effective and tailored communication strategies in time of crisis.\nMethods\nData collection. Table\u00a0 3 reports the data breakdown of the five social media platforms. Different data col-\nlection processes have been performed depending on the platform. In all cases we guided the data collection by a set of selected keywords based on Google Trends\u2019 COVID-19 related queries such as: coronavirus, pandemic, coronaoutbreak, china, wuhan, nCoV , IamNotAVirus, coronavirus_update, coronavirus_transmission, corona-virusnews, coronavirusoutbreak.\nThe Reddit dataset was downloaded from the Pushi ft.io archive, exploiting the related API. In order to filter \ncontents linked to COVID-19, we used our set of keywords.\nIn Gab, although no official guides are available, there is an API service that given a certain keyword, returns \na list of users, hashtags and groups related to it. We queried all the keywords we selected based on Google Trends and we downloaded all hashtags linked to them. We then manually browsed the results and selected a set of hashtags based on their meaning. For each hashtag in our list, we downloaded all the posts and comments linked to it.\nFor Y ouTube, we collected videos by using the Y ouTube Data API by searching for videos that matched our \nkeywords. Then an in depth search was done by crawling the network of videos by searching for more related \nvideos as established by the Y ouTube algorithm. From the gathered set, we filtered the videos that matched \ncoronavirus, nCov, corona virus, corona-virus, corvid, covid or SARS-CoV in the title or description. We then collected all the comments received by those videos.\nFor Twitter, we collect tweets related to the topic coronavirus by using both the search and stream endpoint \nof the Twitter API. The data derived from the stream API represent only 1% of the total volume of tweets, further filtered by the selected keywords. The data derived from the search API represent a random sample of the tweets containing the selected keywords up to a maximum rate limit of 18000 tweets every 10 minutes.\nSince no official API are available for Instagram data, we built our own process to collect public contents \nrelated to our keywords. We manually took notes of posts, comments and populated the Instagram Dataset.\nMatching ability. We consider all the posts in our dataset that contain at least one URL linking to a website \noutside the related social media platfrom (e.g., tweets pointing outside Twitter). We separate URLs in two main categories obtained using the classification provided by MediaBias/FactCheck (MBFC). MBFC provides a clas-sification determined by ranking bias in four different categories, one of them being Factual/Sourcing. In that category, each news outlet is associated to a label that refers to its reliability as expressed in three labels, namely \nConspiracy-Pseudoscience, Pro-Science or Questionable. Noticeably, also the Questionable set include a wide \nrange of political bias, from Extreme Left to Extreme Right.\nUsing such a classification, we assign to each of these outlets a binary label that partially stems from the \nlabelling provided by MBFC. We divide the news outlets into Questionable and Reliable. All the outlets already classified as Questionable or belonging to the category Conspiracy-Pseudoscience are labelled as Questionable, the rest is labelled as Reliable. Thus, by questionable information source we mean a news outlet systematically showing one or more of the following characteristics: extreme bias, consistent promotion of propaganda/con -\nspiracies, poor or no sourcing to credible information, information not supported by evidence or unverifiable, a Table 3.  Data breakdown of the number of posts, comments and users for all platforms.Posts Comments Users Period\nGab 6,252 4,364 2,629 01/01\u201314/02\nReddit 10,084 300,751 89,456 01/01\u201314/02\nYou Tu b e 111,709 7,051,595 3,199,525 01/01\u201314/02\nInstagram 26,576 109,011 52,339 01/01\u201314/02\nTwitter 1,187,482 \u2013 390,866 27/01\u201314/02\nTotal 1,342,103 7,465,721 3,734,815\n7\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/complete lack of transparency and/or fake news. By reliable information sources we mean news outlets that do not \nshow any of the aforementioned characteristics. Such outlets can anyway produce contents potentially displaying a bias towards liberal/conservative opinion, but this does not compromise the overall reliability of the source.\nConsidering all the 2637 news outlets that we retrieve from the list provided by MBFC we end up with 800 \noutlets classified as Questionable 1837 outlets classified as Reliable. Using such a classification we quantify our \noverall ability to match and label domains of posts containing URLs, as reported in Table\u00a0 4.The matching ability \nthat is low doesn\u2019t refer to the ability of identifying known domain but to the ability of finding the news outlets \nthat belong to the list provided by MBFC. Indeed in all the social networks we find a tendency towards linking to other social media platforms, as shown in Table\u00a0 5.\nText analysis. To provide an overview of the debate concerning the virus outbreak on the various platforms, \nwe extract and analyze all topics related to COVID-19 by applying Natural Language Processing techniques to the written content of each social media platform. We first build word embedding for the text corpus of each platform, then, to assess the topics around which the perception of the COVID-19 debate is concentrated, we cluster words by running the Partitioning Around Medoids (PAM) algorithm on their vector representations.\nWord embeddings, i.e., distributed representations of words learned by neural networks, represent words as \nvectors in \nRn bringing similar words closer to each other. They perform significantly better than the well-known \nLatent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) for preserving linear regularities among words and computational efficiency on large data  sets\n49. In this paper we use the Skip-gram  model50 to construct \nword embedding of each social media corpus. More formally, given a content represented by the sequence of words \nw1,w2,...,wT , we use stochastic gradient descent with gradient computed through backpropagation \n rule51 for maximizing the average log probability\nwhere k is the size of the training window. Therefore, during training the vector representations of closely related \nwords are pushed to be close to each other.\nIn the Skip-gram model, every word w is associated with its input and output vectors, uw and vw , respectively. \nThe probability of correctly predicting the word wi given the word wj is defined as\nwhere V is the number of words in the corpus vocabulary. Two major parameters affect the training quality: the \ndimensionality of word vectors, and the size of the surrounding words window. We choose 200 as vector dimen-\nsion\u2014that is typical value for training large dataset\u2014and 6 words for the window.(1)1\nTT\ufffd\nt=1\uf8ee\n\uf8f0k\ufffd\nj=\u2212klogp(wt+j|wt)\uf8f9\n\uf8fb\n(2)p(wi|wj)=exp/parenleftBig\nuT\nwivwj/parenrightBig\nV/summationdisplay\nl=1exp/parenleftBig\nuT\nlvwj/parenrightBigTable 4.  Number of posts containing a URL, matching ability and classification for each of the five platforms.Gab Reddit You Tub e Instagram Twitter\nPosts containing a URL 3,778 10,084 351,786 1,328 356,448\nMatched 0.47 0.55 0.035 0.09 0.27\nQuestionable 0.38 0.045 0.064 0.05 0.10\nReliable 0.62 0.955 0.936 0.95 0.90\nTable 5.  Fraction of URLs pointing to social media. Table should be read as entries in each row link to entries \nin each column. For example, Gab links to Reddit 0.003.Gab Reddit You Tub e Instagram Twitter Facebook\nGab 0.003 0.002 0.001 0.002 0.138 \u223c\u00a00\nReddit 0.043 0.006 0.009 0.001 \u223c\u00a00 0\nYou Tu b e 0 \u223c\u00a00 0.292 \u223c\u00a00 0.088 0.081\nInstagram 0 0 0.003 0 0.001 0.001\nTwitter 0.059 0.001 0.257 0.003 \u223c\u00a00 \u223c\u00a00\n8\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Before applying the tool, we reduced the contents to those written in English as detected with cld3 . Then we \ncleaned the corpora by removing HTML code, URLs and email addresses, user mentions, hashtags, stop-words, \nand all the special characters including digits. Finally, we dropped words composed by less than three characters, words occurring less than five times in all the corpus, and contents with less than three words.\nTo analyze the topics related to COVID-19, we cluster words by PAM and using as proximity metric the cosine \ndistance matrix of words in their vector representations. In order to select the number of clusters, k, we calculate \nthe average silhouette width for each value of k . Moreover, for evaluating the cluster stability, we calculate the \naverage pairwise Jaccard similarity between clusters based on 90% sub-samples of the data. Lastly, we produce word clouds to identify the topic of each cluster. To provide a view about the debate around the virus outbreak, we define the distribution over topics \n/Theta1c for a given content c  as the distribution of its words among the word \nclusters. Thus, to quantify the relevance of each topic within a corpus, we restrict to contents c  with max\ufffdc>0.5 \nand consider them uniquely identified as a single topic each. Table\u00a0 6 shows the results of the text cleaning and \ntopic analysis for all the data.\nEpidemiological models. Several mathematical models can be used to analyse potential mechanisms that \nunderline epidemiological data. Generally, we can distinguish among phenomenological models that emphasize the reproducibility of empirical data without insights in the mechanisms of growth, and more insightful mecha-nistic models that try to incorporate such  mechanisms\n41.\nTo fit our cumulative curves, we first use the adjusted exponential model  of43 since it naturally provides an \nestimate of the basic reproduction number R0 . This phenomenological model (from now on indicated as EXP) has \nbeen successfully employed in data-scarce settings and shown to be on-par with more traditional compartmental models for multiple emerging diseases like Zika, Ebola, and Middle East Respiratory  Syndrome\n43.\nThe model is defined by the following single equation:\nHere, I is incidence, t  is the number of days, R0 is the basic reproduction number and d  is a damping factor \naccounting for the reduction in transmissibility over time. In our case, we interpret I  as the number Cauth of \nauthors that have published a post on the subject.\nAs a mechanistic model, we employ the classical SIR  model44. In such a model, a susceptible population can \nbe infected with a rate \u03b2 by coming into contact with infected individuals; however, infected individuals can \nrecover with a rate \u03b3 . The model is described by a set of differential equations:\nwhere S is the number of susceptible, I  is the number of infected and R  is the number of recovered. In our case, \nwe interpret the number I+R as the number Cauth of authors that have published a post on the subject.\nIn the SIR model, the basic reproduction number R0=\u03b2/\u03b3 corresponds to the ration among the rate of \ninfection by contact \u03b2 and the rate of recovery \u03b3 . Notice that for the SIR model, vaccination strategies correspond \nto bringing the system in a situation where S<N/R0 ; in such a way, both the number of infected will decrease.\nTo estimate the basic reproduction numbers REXP\n0 and RSIR\n0 for the EXP and the SIR model, we use least square \nestimates of the models\u2019  parameters42. The range of parameters is estimated via  bootstrapping41,52.\nLinear regression coefficients. Table\u00a0 7 reports the regression coefficient \u03c1 , the intercept and the R2 values \nfor the linear fit of Fig.\u00a0 3. High values of R2 confirm the linear relationship between reliable and questionable \nsources in information diffusion.(3) I=/bracketleftbiggR0\n(1+d)t/bracketrightbiggt\n(4)\u2202tS=\u2212\u03b2S\u00b7I/N\n\u2202tI=\u03b2S\u00b7I/N\u2212\u03b3I\n\u2202tR=\u03b3ITable 6.  Results of text cleaning and analysis for all the corpora.Cleaned contents Vocabulary size Topics Contents with max\ufffd> 0.5\nInstagram 21,189 posts 15,324 17 4,467\nTwitter 638,214 posts 22,587 21 369,131\nGab 5,853 posts 3,024 19 2,986\nReddit 10,084 posts 1,968 34 6,686\nYou Tu b e 815,563 comments 35,381 30 679,261\n9\nVol.:(0123456789) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/Data availability\nThe datasets generated during and/or analysed during the current study are available from the corresponding \nauthor on reasonable request.\nReceived: 11 April 2020; Accepted: 15 September 2020\nReferences\n 1. Organization, W .\u00a0H. Naming the coronavirus disease (COVID-19) and the virus that causes it. https  ://www.who.int/emerg  encie  \ns/disea  ses/novel -coron  aviru  s-2019/techn ical-guida  nce/namin  g-the-coron  aviru  s-disea  se-(covid -2019)-and-the-virus -that-cause  \ns-it (2020 (accessed April 9, 2020)).\n 2. Quattrociocchi, W . Part 2-social and political challenges: 2.1 western democracy in crisis? In Global Risk Report World Economic \nForum  (2017).\n 3. WHO Situation Report 13. https ://www.who.int/docs/defau  lt-sourc  e/coron  aviru  se/situa  tion-repor  ts/20200  202-sitre p-13-ncov-v3.\npdf?sfvrs  n=195f4  010_6. Accessed: 2010-09-30.\n 4. Zarocostas, J. How to fight an infodemic. Lancet  395, 676 (2020).\n 5. Organization, W .\u00a0H. Director-general\u2019s remarks at the media briefing on 2019 novel Coronavirus on 8 February 2020. https ://www.\nwho.int/dg/speec  hes/detai  l/direc  tor-gener al-s-remar  ks-at-the-media -briefi  ng-on-2019-novel -coron  aviru  s---8-febru  ary-2020  (2020 \n(accessed April 9, 2020)).\n 6. Mendoza, M., Poblete, B. & Castillo, C. Twitter under crisis: Can we trust what we RT?. Proceedings of the first workshop on social \nmedia analytics  71\u201379 (2010).\n 7. Starbird, K., Maddock, J., Orand, M., Achterman, P . & Mason, R.\u00a0M. Rumors, false flags, and digital vigilantes: Misinformation on twitter after the 2013 boston marathon bombing. IConference 2014 Proceedings (2014).\n 8. Kim, L., Fast, S. M. & Markuzon, N. Incorporating media data into a model of infectious disease transmission. PLoS ONE 14, 1 \n(2019).\n 9. John, T. & Ben\u00a0Wedeman, C. Italy prohibits travel and cancels all public events in its northern region to contain Coronavirus. https  \n://editi  on.cnn.com/2020/03/08/europ  e/italy  -coron  aviru  s-lockd own-europ  e-intl/index  .html  (2020 (accessed April 9, 2020)).\n 10. Sharot, T. & Sunstein, C. R. How people decide what they want to know. Nat. Hum. Behav.  2020, 1\u20136 (2020).\n 11. Shaman, J., Karspeck, A., Y ang, W ., Tamerius, J. & Lipsitch, M. Real-time influenza forecasts during the 2012\u20132013 season. Nat. \nCommun.  4, 1\u201310 (2013).\n 12. Viboud, C. & Vespignani, A. The future of influenza forecasts. Proc. Natl. Acad. Sci. 116, 2802\u20132804 (2019).\n 13. Kulshrestha, J. et\u00a0al.  Quantifying search bias: Investigating sources of bias for political searches in social media. In Proceedings of \nthe 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, 417\u2013432 (2017).\n 14. Schmidt, A. L. et al.  Anatomy of news consumption on Facebook. Proc. Natl. Acad. Sci. 114, 3035\u20133039 (2017).\n 15. Starnini, M., Frasca, M. & Baronchelli, A. Emergence of metapopulations and echo chambers in mobile agents. Sci. Rep. 6, 31834 \n(2016).\n 16. Schmidt, A. L., Zollo, F., Scala, A., Betsch, C. & Quattrociocchi, W . Polarization of the vaccination debate on Facebook. Vaccine  \n36, 3606\u20133612 (2018).\n 17. Del Vicario, M. et al. The spreading of misinformation online. Proc. Natl. Acad. Sci. 113, 554\u2013559 (2016).\n 18. Bessi, A. et al. Science vs. conspiracy: collective narratives in the age of misinformation. PLoS ONE 10, e0118093 (2015).\n 19. Cinelli, M. et al. Selective exposure shapes the Facebook news diet. PLoS ONE 15, e0229129 (2020).\n 20. Zollo, F. et al. Debunking in a world of tribes. PLoS ONE 12, 1 (2017).\n 21. Baronchelli, A. The emergence of consensus: a primer. R. Soc. Open Sci. 5, 172189 (2018).\n 22. Del Vicario, M. et al. Echo chambers: emotional contagion and group polarization on Facebook. Sci. Rep. 6, 37825 (2016).\n 23. Bail, C. A. et al.  Exposure to opposing views on social media can increase political polarization. Proc. Natl. Acad. Sci.  115, \n9216\u20139221 (2018).\n 24. Vicario, M. D., Quattrociocchi, W ., Scala, A. & Zollo, F. Polarization and fake news: early warning of potential misinformation targets. ACM Trans. Web (TWEB) 13, 1\u201322 (2019).\n 25. Wardle, C. & Derakhshan, H. Information disorder: Toward an interdisciplinary framework for research and policy making. \nCouncil of Europe report  27 (2017).\n 26. Vosoughi, S., Roy, D. & Aral, S. The spread of true and false news online. Science  359, 1146\u20131151 (2018).\n 27. Ruths, D. The misinformation machine. Science  363, 348\u2013348 (2019).\n 28. Schild, L. et\u00a0al.  \u201c go eat a bat, chang!\u201d: An early look on the emergence of sinophobic behavior on web communities in the face of \ncovid-19. arXiv preprint arXiv  :2004.04046   (2020).\n 29. Vel\u00e1squez, N. et\u00a0al. Hate multiverse spreads malicious COVID-19 content online beyond individual platform control. Preprint arXiv  \n:2004.00673   (2020).\n 30. Ferrara, E. What types of COVID-19 conspiracies are populated by twitter bots? First Monday  (2020).\n 31. Alam, F. et\u00a0al. Fighting the COVID-19 infodemic: modeling the perspective of journalists, fact-checkers, social media platforms, policy \nmakers, and the society . Preprint arXiv  :2005.00033   (2020).Table 7.  Coefficients and R2 of the linear regressions displayed in Fig.\u00a03.Dataset Type Intercept Coefficient ( \u03c1)R2\nGab Posts \u2212 22.321 0.695 0.996\nReddit Posts \u2212 4.111 0.047 0.997\nYoutu b e Posts 4.529 0.073 0.998\nTwitter Posts \u2212 151.44 0.110 0.998\nGab Reactions 74.577 2.721 0.981\nReddit Reactions \u2212 70.677 0.026 0.990\nYoutu b e Reactions \u2212 8854.33 0.025 0.986\nTwitter Reactions \u2212 2136.978 0.107 0.987\n10\nVol:.(1234567890) Scientific RepoRtS  |        (2020) 10:16598  | https://doi.org/10.1038/s41598-020-73510-5\nwww.nature.com/scientificreports/ 32. Shahi, G.\u00a0K., Dirkson, A. & Majchrzak, T.\u00a0A. An exploratory study of COVID-19 misinformation on twitter . Preprint arXiv \n:2005.05710   (2020).\n 33. Bovet, A. & Makse, H. A. Influence of fake news in twitter during the 2016 us presidential election. Nat. Commun.  10, 1\u201314 (2019).\n 34. (MBFC), M. B.\u00a0C. Media bias/fact check, the most comprehensive Meida bias check resource. https ://media  biasf actch  eck.com/  \n(2020 (accessed April 9, 2020)).\n 35. Romero, D.\u00a0M., Meeder, B. & Kleinberg, J. Differences in the mechanics of information diffusion across topics: idioms, political \nhashtags, and complex contagion on twitter. In Proceedings of the 20th international conference on World wide web, 695\u2013704 (2011).\n 36. Organization, W .\u00a0H. Novel Coronavirus (2019-NCOV) situation report-1 21 January 2020. https ://www.who.int/docs/defau  lt-sourc  \ne/coron  aviru  se/situa  tion-repor  ts/20200  121-sitre  p-1-2019-ncov.pdf?sfvrs  n=20a99  c10_4  (2020 (accessed April 9, 2020)).\n 37. Pellis, L. et al. Eight challenges for network epidemic models. Epidemics  10, 58\u201362 (2015).\n 38. Liu, Y. et al. Characterizing super-spreading in microblog: an epidemic-based information propagation model. Physica A 463, \n202\u2013218 (2016).\n 39. Skaza, J. & Blais, B. Modeling the infectiousness of twitter hashtags. Physica A  465, 289\u2013296 (2017).\n 40. Davis, J. T., Perra, N., Zhang, Q., Moreno, Y . & Vespignani, A. Phase transitions in information spreading on structured popula-\ntions. Nat. Phys.  2020, 1\u20137 (2020).\n 41. Chowell, G. Fitting dynamic models to epidemic outbreaks with quantified uncertainty: a primer for parameter uncertainty, \nidentifiability, and forecasts. Infect. Dis. Model. 2, 379\u2013398 (2017).\n 42. Ma, J. Estimating epidemic exponential growth rate and basic reproduction number. Infectious Disease Modelling  (2020).\n 43. Fisman, D. N., Hauck, T. S., Tuite, A. R. & Greer, A. L. An idea for short term outbreak projection: nearcasting using the basic reproduction number. PLoS ONE  8, 1 (2013).\n 44. Bailey, N.\u00a0T. et\u00a0al.  The mathematical theory of infectious diseases and its applications  (Charles Griffin & Company Ltd, 5a Crendon \nStreet, High Wycombe, Bucks HP13 6LE, 1975).\n 45. Centola, D. The spread of behavior in an online social network experiment. Science  329, 1194\u20131197 (2010).\n 46. Del Vicario, M., Scala, A., Caldarelli, G., Stanley, H. E. & Quattrociocchi, W . Modeling confirmation bias and polarization. Sci. \nRep. 7, 40391 (2017).\n 47. Baumann, F., Lorenz-Spreen, P ., Sokolov, I. M. & Starnini, M. Modeling echo chambers and polarization dynamics in social net -\nworks. Phys. Rev. Lett. 124, 048301 (2020).\n 48. Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on Twitter during the 2016 us presidential \nelection. Science  363, 374\u2013378 (2019).\n 49. Mikolov, T., Yih, W .-T. & Zweig, G. Linguistic regularities in continuous space word representations. In Proceedings of the Con -\nference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 746\u2013751 (Association for Computational Linguistics  2013 (Georgia, Atlanta, 2013).\n 50. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. & Dean, J. Distributed representations of words and phrases and their compo-\nsitionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems\u2014Volume 2, NIPS\u201913, \n3111\u20133119 (Curran Associates Inc., Red Hook, NY , USA, 2013).\n 51. Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by back-propagating errors. Nature  323, 533\u2013536. https  \n://doi.org/10.1038/32353  3a0 (1986).\n 52. Efron, B. & Tibshirani, R. J. An Introduction to the Bootstrap  (CRC Press, London, 1994).\nAuthor contributions\nM.C., A.G., C.M.V ., A.L.S., P .Z. collected and prepared the data. All authors conceived the experiments. M.C., \nA.G., C.M.V ., A.L.S., E.B., and A.S. conducted the experiments. All authors analysed the results, wrote and reviewed the manuscript.\nCompeting interests  \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to W .Q.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat  iveco  mmons .org/licen  ses/by/4.0/.\n\u00a9 The Author(s) 2020", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The COVID-19 social media infodemic", "author": ["M Cinelli", "W Quattrociocchi", "A Galeazzi"], "pub_year": "2020", "venue": "Scientific reports", "abstract": "We address the diffusion of information about the COVID-19 with a massive data analysis on  Twitter, Instagram, YouTube, Reddit and Gab. We analyze engagement and interest in the"}, "filled": false, "gsrank": 651, "pub_url": "https://www.nature.com/articles/s41598-020-73510-5", "author_id": ["3qOq_28AAAAJ", "_OCIc6UAAAAJ", "DK0tXAIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:Wkw9MHsziXAJ:scholar.google.com/&output=cite&scirp=650&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D650%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Wkw9MHsziXAJ&ei=e7WsaLT2OY6IieoP0sKRuAk&json=", "num_citations": 2837, "citedby_url": "/scholar?cites=8109069208240606298&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Wkw9MHsziXAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-020-73510-5.pdf"}}, {"title": "Fighting the infodemic: the 4 i framework for advancing communication and trust", "year": "2023", "pdf_data": "Sundelson\u00a0 et\u00a0al. BMC Public Health         (2023) 23:1662  \nhttps://doi.org/10.1186/s12889-023-16612-9\nRESEARCH\nFighting the\u00a0infodemic: the\u00a04 i Framework \nfor\u00a0Advancing Communication and\u00a0Trust\nAnne E. Sundelson1,2*, Amelia M. Jamison3, Noelle Huhn1,2, Sarah\u2011Louise Pasquino4 and Tara Kirk Sell1,2 \nAbstract \nBackground The proliferation of false and misleading health claims poses a major threat to public health. This \nongoing \u201cinfodemic\u201d has prompted numerous organizations to develop tools and approaches to manage the spread \nof falsehoods and communicate more effectively in an environment of mistrust and misleading information. However, \nthese tools and approaches have not been systematically characterized, limiting their utility. This analysis provides \na characterization of the current ecosystem of infodemic management strategies, allowing public health practitioners, \ncommunicators, researchers, and policy makers to gain an understanding of the tools at their disposal.\nMethods A multi\u2011pronged search strategy was used to identify tools and approaches for combatting health\u2011related \nmisinformation and disinformation. The search strategy included a scoping review of academic literature; a review \nof gray literature from organizations involved in public health communications and misinformation/disinformation \nmanagement; and a review of policies and infodemic management approaches from all U.S. state health departments \nand select local health departments. A team of annotators labelled the main feature(s) of each tool or approach using \nan iteratively developed list of tags.\nResults We identified over 350 infodemic management tools and approaches. We introduce the 4 i Framework \nfor Advancing Communication and Trust (4 i FACT), a modified social\u2011 ecological model, to characterize different \nlevels of infodemic intervention: informational, individual, interpersonal, and institutional. Information\u2011level strategies \nincluded those designed to amplify factual information, fill information voids, debunk false information, track circu\u2011\nlating information, and verify, detect, or rate the credibility of information. Individual\u2011level strategies included those \ndesigned to enhance information literacy and prebunking/inoculation tools. Strategies at the interpersonal/commu\u2011\nnity level included resources for public health communicators and community engagement approaches. Institutional \nand structural approaches included resources for journalists and fact checkers, tools for managing academic/scientific \nliterature, resources for infodemic researchers/research, resources for infodemic managers, social media regulation, \nand policy/legislation.\nConclusions The 4 i FACT provides a useful way to characterize the current ecosystem of infodemic management \nstrategies. Recognizing the complex and multifaceted nature of the ongoing infodemic, efforts should be taken to uti\u2011\nlize and integrate strategies across all four levels of the modified social\u2011 ecological model.\nKeywords  Misinformation, Disinformation, Infodemic, Fact check, Social media, Social\u2011 ecological modelOpen Access\n\u00a9 The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecom\u2011\nmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.BMC P ublic Health\n*Correspondence:\nAnne E. Sundelson\nasundel1@jhu.edu\nFull list of author information is available at the end of the article\nPage 2 of 12 Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \nBackground\nIn today\u2019s interconnected, digitalized world, it has \nbecome increasingly apparent that information about \na public health event\u2014particularly false or mislead -\ning information\u2014can lead to negative health outcomes. \nThe ongoing COVID-19 pandemic has reinforced this \nfact, prompting the World Health Organization (WHO) \nto declare a simultaneous \u201cinfodemic\u201d or \u201coverabun -\ndance of false or misleading information on COVID-19, \nwhich poses a grave threat to response efforts and pub -\nlic health\u201d [1]. In the midst of this infodemic, research -\ners have uncovered associations between exposure to or \nbelief in COVID-19-related misinformation (false or mis -\nleading information that is spread unwittingly by those \nwho do not know it is false) and psychological distress, \nnon-adherence to recommended mitigation measures, \nreduced intent to get vaccinated, and violence against \nhealthcare workers [2\u20135]. Disinformation, or false infor -\nmation that is spread deliberately by those seeking to \ncause harm, is also a growing concern, as there is evi -\ndence that state actors may be using disinformation to \nfuel pernicious debates about public health issues in the \nUnited States (US), particularly vaccination [6].\nThe rise of social media and digital technologies has \nundoubtedly contributed to the infodemic. Indeed, \nresearchers have found that on Twitter, false informa -\ntion travels faster and more widely than true informa -\ntion [7]. The mechanisms that underly the viral spread of \nfalse information on social media are complex and con -\ntested, but scholars have highlighted the role of platform \nalgorithms and echo chambers (online environments in \nwhich individuals only see content that aligns with their \npre-existing beliefs), both of which may facilitate selec -\ntive exposure to (potentially false) information [8\u201310].\nOnce exposed, cognitive and psychological processes \ndictate whether an individual will believe false informa -\ntion or reject it. Unfortunately, human cognitive process -\ning is subject to inherent biases that can make individuals \nvulnerable to misinformation/disinformation [11]. There \nis some evidence that individuals may be more prone to \nthese biases when presented with information in a so-\ncalled \u201cfilter-bubble\u201d (an algorithmically curated infor -\nmation environment) or echo chamber [12], further \nunderscoring the role of social media in the propagation \nof false information. Mistrust\u2014of governments, indi -\nviduals in positions of authority, or institutions\u2014has also \nbeen implicated in belief in/the spread of misinformation \nand disinformation [13, 14], as individuals with high lev -\nels of mistrust are likely to reject official information and \nseek out alternative explanations (which may take the \nform of conspiracy theories) [15].\nWhile a large and growing body of research is dedi -\ncated to understanding both the mechanisms and impact of misinformation and disinformation, fewer efforts \nhave sought to characterize the full spectrum of misin -\nformation/disinformation management strategies [16]. \nTwo recent analyses, for example, characterized only \na subset of existing strategies, focusing mainly on psy -\nchological and cognitive interventions [17, 18]. Further, \nthese analyses focused on false information more gen -\nerally, without a specific focus on strategies for manag -\ning health-related misinformation/disinformation. Over \nthe past several years, numerous organizations have \ndeveloped tools and approaches to manage the spread \nof falsehoods and communicate more effectively in an \nenvironment of misleading health claims. The WHO, \nfor example, ran a crowdsourced technical consultation \nin 2020 on infodemic management strategies, leading to \nthe development of an infodemic management frame -\nwork [19]. Other groups have developed more local and \ncommunity-based approaches, including training trusted \ncommunity messengers to disseminate accurate infor -\nmation about COVID-19 [20]. Additionally, researchers \nhave crafted innovative interventions designed to refute \nor confer resistance to health-related misinformation/\ndisinformation [21\u201323]. Taken together, these tools and \napproaches can serve as a resource for public health \npractitioners and those working in health communica -\ntions, research, or policy, who will be faced with health-\nrelated misinformation and disinformation for years to \ncome. However, because such approaches have not been \nsystematically characterized, practitioners and policy \nmakers are unlikely to be able to take full advantage of \nthem when crafting their own infodemic management \nstrategies.\nThe aim of this analysis was to characterize the current \necosystem of infodemic management strategies, allowing \npublic health practitioners, communicators, researchers, \nand policy makers to gain an in-depth understanding of \nthe tools and approaches at their disposal. Specifically, \nwe sought to accomplish two goals: first, in an explora -\ntory review, we identify existing tools and approaches for \ninfodemic management, and second, through a qualita -\ntive content analysis of these tools and approaches, we \ndevelop a conceptual framework to characterize points of \ninfodemic intervention. This work was conducted as part \nof a large multi-stage research project exploring effec -\ntive public health communication strategies to utilize in \nan environment of false or misleading information and \nmistrust.\nMethods\nSearch strategy\nThe research team utilized a multi-pronged search strat -\negy to identify tools and approaches for combatting \nhealth-related misinformation and disinformation. First, \nPage 3 of 12\n Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \n \na scoping review of academic literature indexed in Pub -\nMed, Scopus, and Web of Science was conducted using \ntwo sets of keywords: one relating to misinformation and \ndisinformation and another relating to management of \nor solutions to misinformation and disinformation. The \nsearch strategy for each database can be seen in Table\u00a01.\nTo expedite the scoping review, final search results \nfrom all three databases were filtered to exclude non-\nreview articles, yielding a total of 413 reviews. These \nreviews were uploaded to Covidence, a literature review \nsoftware program. Duplicates were identified and \nremoved, yielding 313 unique reviews. AES then con -\nducted title and abstract screening followed by full text \nreview. Reviews were included in the final corpus if they \nwere accessible online, available in English, and con -\ntained discussion of interventions or strategies for man -\naging/combatting health-related misinformation and \ndisinformation. Reviews were excluded if they were not \nwritten in English, were not accessible online, or did not \ncontain discussion of interventions or strategies for man -\naging/combatting health-related misinformation and dis -\ninformation. A total of 43 reviews were included in the final corpus. These reviews were re-read in full by AES, \nwho extracted individual tools, strategies, or approaches \nfor managing/combatting health-related misinformation/\ndisinformation and added them to an Excel file.\nNext, all members of the research team (AES, AMJ, \nNH, and SLP) conducted independent searches of grey \nliterature, including publications, reports, and products \naccessible through web searches. This search was built \naround a deductive list of organizations involved in mis -\ninformation and disinformation management and health \ncommunications, including international and intergov -\nernmental organizations, US-based federal agencies, \nnon-governmental organizations, technology and media \ncompanies, non-profits, think tanks, and research cent -\ners. To supplement the above searches, the research team \nscanned all U.S. state health department websites for mis -\ninformation and disinformation management practices, \npolicies, and tools. In addition to state health depart -\nments, the websites of the following large local health \ndepartments were also searched for misinformation \nand disinformation management tools and strategies: \nthe New York City Department of Health and Mental \nTable 1 Search strategy for scoping literature review\nSearch \nSequencePubMed Scopus Web of Science\n1 \"Disinformation\"[Mesh] TITLE\u2011ABS\u2011KEY(misinformation OR disin\u2011\nformation OR \u201cfake information\u201d OR \u201cfake \nnews\u201d OR \u201cconspiracy theor*\u201d OR infodem* \nOR \u201cfalse science\u201d OR \u201cmisleading informa\u2011\ntion\u201d OR rumor*)TS = (misinformation OR disinformation \nOR \"fake information\" OR \"fake news\" \nOR \"conspiracy theor*\" OR infodem* OR \"false \nscience\" OR \"misleading information\" \nOR rumor* OR rumour*)\n2 misinformation[tiab] OR disinformation[tiab] \nOR \"fake information\"[tiab] OR \"fake \nnews\"[tiab] OR \"conspiracy theor*\"[tiab] \nOR infodem*[tiab] OR \"false science\"[tiab] \nOR \"misleading information\" \nOR rumor*[tiab]TITLE\u2011ABS\u2011KEY(\u201cdigital health literacy\u201d \nOR \u201chealth literacy\u201d OR \u201cscience literacy\u201d \nOR \u201ctools against\u201d OR \u201cpreventive measure*\u201d \nOR \u201cmethods to address\u201d OR \u201cinfodemic \nmanagement\u201d OR \u201cmanag* infodemic*\u201d \nOR \u201cinformation literacy\u201d OR \u201ceHealth liter \u2011\nacy\u201d OR \u201cfact check*\u201d OR solution OR \u201crumor \ntrack*\u201d OR mythbust* OR debunk* OR preb \u2011\nunk* OR rebuttal)TS = (\"digital health literacy\" OR \"health lit \u2011\neracy\" OR \"science literacy\" OR \"tools against\" \nOR \"preventive measure*\" OR \"methods \nto address\" OR \"infodemic management\" \nOR \"manag* infodemic*\" OR \"information \nliteracy\" OR \"eHealth literacy\" OR \"fact check*\" \nOR solution OR \"rumor track*\" OR mythbust* \nOR debunk* OR prebunk* OR rebuttal)\n3 #1 OR #2 #1 AND #2 #1 AND #2\n4 \"Health Literacy\"[Mesh]\n5 \"digital health literacy\"[tiab] OR \"health \nliteracy\"[tiab] OR \"science literacy\"[tiab] \nOR \"tools against\"[tiab] OR \"preven\u2011\ntive measure*\"[tiab] OR \"methods \nto address\"[tiab] OR combat*[tiab] \nOR countermeasure*[tiab] OR \"info \u2011\ndemic management\"[tiab] OR \"man\u2011\naging infodemic*\"[tiab] OR \"infor \u2011\nmation literacy\"[tiab] OR \"eHealth \nliteracy\"[tiab] OR \"fact check*\"[tiab] \nOR solution*[tiab] OR \"rumor tracking\"[tiab] \nOR mythbust*[tiab] OR debunk*[tiab] \nOR prebunk*[tiab] OR rebuttal[tiab]\n6 #4 OR #5\n7 #3 AND #6\nPage 4 of 12 Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \nHygiene, the San Diego County Health Department, \nPublic Health \u2013 Seattle and King County, the Baltimore \nCity Health Department, and the Philadelphia Depart -\nment of Public Health. Team members also engaged in \norganic searches to identify additional sources. Tools and \napproaches were added to the Excel file as they were dis -\ncovered, with care taken not to add duplicates.\nSimilar search terms were used to search the gray lit -\nerature and health department websites as those used in \nthe scoping literature review, though many websites did \nnot have advanced search functions. As such, individual \nkeywords or phrases were often used to search for rel -\nevant tools and approaches (e.g., \u201cinfodemic manage -\nment\u201d or \u201cmisinformation\u201d). All searches were conducted \nbetween October 2022 and January 2023.\nTools and approaches were included in the Excel \nfile if they were focused on addressing misinforma -\ntion or disinformation related to a health topic (broadly \ndefined). Tools and approaches were not limited by date \nof development and included those that emerged prior to \nCOVID-19 as well as those that were in development at \nthe time the searches were conducted. Further, tools were \nnot limited by geography or language, but as our research \nteam is based in the US and speaks English, these tools \nare more prominent in the data.\nQualitative data analysis\nThe main feature(s) of each tool or approach were \nlabelled in Excel using an iteratively developed list of tags. \nThe initial list of tags was informed by the scoping litera -\nture review and developed by AES. This list was refined \nby the research team through group discussions as new \ntools and approaches were identified. Tools/approaches \nwere coded with relevant tag(s) by the same researcher \nwho entered the tool/approach into the working Excel \nfile. Each entry could be coded with up to 3 tags. The \nresearch team held weekly meetings to discuss any cod -\ning questions and to revise the tag list as necessary.\nResults\nWe identified over 350 tools and approaches for manag -\ning health-related misinformation and disinformation. \nMany of the tools did not distinguish between misinfor -\nmation and disinformation and were designed to combat \nfalse information in general (disinformation turns into \nmisinformation once it is believed and propagated by \nthose who believe it, so it is not always necessary or even \npossible to distinguish between the two [24]).\nTo characterize the infodemic management strategies \nidentified in the search, we present the 4 i Framework for \nAdvancing Communication and Trust (4 i FACT). The \n4 i FACT, which is based on Bronfenbrenner\u2019s ecologi -\ncal systems theory and the widely used social-ecological model (SEM) [25, 26], consists of four levels (informa -\ntion, individual, interpersonal/community, and institu -\ntional/structural), each of which contains a subset of the \ntags used to label individual strategies. A description of \nthe tags in each level is shown in Fig.\u00a01.\nEach level of the 4 i FACT is described below, along \nwith a description of the tags contained in each level and \nexamples of the tools and approaches associated with \neach tag.\nInformation\nTags in the information level were used to label tools or \napproaches that targeted information itself, including \naccurate information, false information, or lack of infor -\nmation (i.e., information voids).\nAmplifying factual information\nWe identified 108 tools and approaches designed to \ndisseminate or amplify accurate information or other -\nwise direct individuals to credible sources of informa -\ntion. These approaches often made use of social media \nto ensure accurate information reached as many people \nas possible. During the COVID-19 pandemic, for exam -\nple, the Baltimore City Health Department launched a \nseries of social media campaigns to ensure Baltimore \nresidents had accurate and up-to-date information \nabout the COVID-19 vaccines. The posts for these cam -\npaigns, which were written humorously using vernacu -\nlar and graphics popular on social media, were designed \nto \u201cgo viral\u201d [27]. Other organizations designed their \napproaches around social media to combat false informa -\ntion spread on these platforms. For example, \u201cDear Pan -\ndemic\u201d is an ongoing effort to provide social media users \nwith easy-to-understand, factual, and practical informa -\ntion about COVID-19 on Facebook and Instagram [28].\nFilling information voids\nWe identified 50 tools/approaches designed to fill infor -\nmation voids. Some of these tools were chatbots that \nwere programmed to answer common questions. VIRA, \nfor instance, is a chatbot developed by the Johns Hopkins \nInternational Vaccine Access Center that uses artificial \nintelligence (AI) to answer common questions about the \nCOVID-19 vaccines [29]. Other approaches relied on \nhuman interaction rather than AI. Several state health \ndepartments, for instance, including those in Minnesota \n[30], Georgia [31], and Illinois [32] ran telephone hotlines \nduring the COVID-19 pandemic to answer residents\u2019 \nquestions. Search engine optimization was also used to \nfill information voids. The WHO and Google, for exam -\nple, partnered during the COVID-19 pandemic to create \nan organized search results panel for anyone searching \nfor information about COVID-19 online [33]. The search \nPage 5 of 12\n Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \n \nresults panel directs Google users to credible sources of \ninformation like the WHO or CDC, thereby ensuring fac -\ntual responses to search queries.\nDebunking false information\nWe identified 100 tools/approaches designed to fact \ncheck or debunk circulating false information. Many \nof the tools with this tag were traditional fact-checking \nwebsites that provided lists of false claims and accom -\npanying refutations or alternative explanations. Some of \nthese websites were dedicated to either specific topics \nor specific sources of misinformation or disinformation. \nThe #CoronaVirusFacts Alliance, for example, is a web -\nsite containing a categorized database of fact-checked \nrumors about COVID-19 [34]. The EUvsDisinfo Data -\nbase is a collection of debunked disinformation from pro-\nKremlin sources. The database contains debunked claims \non a variety of topics, including COVID-19, bioweapons, \nand other geopolitical issues [35].\nInformation tracking\nWe identified 44 tools/approaches designed to track cir -\nculating information, including false or misleading infor -\nmation. Many of these were social listening tools, which \ntrack conversations on social media and often rely on \nAI and machine learning (ML). The Early AI-Supported \nResponse with Social Listening (EARS) Platform, for \nexample, is a platform developed by the WHO that uses AI to search for COVID-19-related conversations and \nposts from major social media platforms, allowing users \nto gain an understanding of how individuals are talk -\ning about COVID-19 online [36]. Some of the tools and \napproaches with this tag facilitated reporting of misin -\nformation. During the 2014\u20132016 Ebola outbreak, for \nexample, a group of intergovernmental and academic \norganizations created DeySay, a rumor-tracking messag -\ning system that allowed community members to report \nEbola-related rumors via text message. The rumors \nreported through this system were used to inform rel -\nevant debunking materials, allowing public health com -\nmunicators to refute misinformation in real time [37].\nVerification, credibility, and\u00a0detection\nWe identified 32 tools designed to detect false informa -\ntion or evaluate content or source credibility. These tools \ncan be split into two broad categories: those designed to \nverify or rate sources of information, and those designed \nto confirm the authenticity of information by detect -\ning manipulation or bot-like activity. An example of a \ntool that falls into the first category is Media Bias/Fact \nCheck, which is a website that rates the bias and cred -\nibility of media sources and directs users to news pieces \nfrom the \"least biased\" sources [38]. An example of a \ntool in the second category is Botometer, which is an \nonline tool that helps users determine whether specific \nTwitter accounts are likely to be bots [39].\u00a0 Most of the \nFig. 1 The 4 i Framework for Advancing Communication and Trust (4 i FACT) with types of tools and approaches\nPage 6 of 12 Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \nverification, credibility, and detection tools were auto -\nmated and relied on AI/ML.\nIndividual\nTags in the individual level were used to identify tools \nand approaches designed to increase individual-level \nresiliency to misinformation and disinformation.\nEnhancing information literacy\nWe identified 58 tools/approaches designed to encourage \nor teach individuals to think critically about the informa -\ntion they consumed, thereby reducing their susceptibility \nto false or misleading claims. Some of these approaches \nwere focused on a single type or form of information, \nsuch as scientific or health-related information. The San \nDiego County Health Department, for example, devel -\noped an online resource (a webpage with links to other \nsites) informing users how to find credible scientific \ninformation about COVID-19 as well as how to critically \nevaluate scientific information about the disease [40]. \nOther tools and approaches were focused on digital or \nmedia literacy. For example, the non-profit New America \nis currently developing Cyber Citizenship, which is a col -\nlection of media and digital literacy resources for educa -\ntors who are interested in helping their students build \nresilience to misinformation and disinformation online \n[41]. Other tools and approaches with this tag were \ndesigned to enhance information literacy more broadly. \nSarah Blakeslee at California State University, Chico, for \nexample, developed the CRAAP Test, which is a tool that \nhelps individuals evaluate the credibility of a source of \ninformation based on its Currency, Relevance, Authority, \nAccuracy and Purpose (CRAAP) [42].\nPrebunking/inoculation\nPrebunking, also referred to as inoculation, is a strat -\negy in which individuals are pre-emptively exposed to \nanticipated false information or common tactics used in \nmisinformation and disinformation campaigns, making \nthem (theoretically) less susceptible to misinformation \nand disinformation when they come across it [43, 44]. We \nidentified 11 prebunking tools/approaches in this search, \nmany of which were in gamified formats. For example, \nGo Viral! is an online game developed by the University \nof Cambridge, UK Cabinet Office, and the WHO. Players \nof the game learn how to create viral false content using \ncommon manipulation tactics. In doing so, they develop \n\u201cpsychological resistance\u201d against future misinformation \nand disinformation campaigns [45].\nInterpersonal/community\nTags in the interpersonal/community level were used \nto label tools and approaches that were focused on communication and relationship or trust building at the \ninterpersonal or community level.\nResources for\u00a0public health communicators\nThese resources (of which we identified 62) were \ndesigned to enhance the credibility and efficacy of pub -\nlic health communication\u2014particularly in the midst of \nmistrust and misinformation\u2014and included messaging \nguidance, sharable materials, and toolkits. Many targeted \ntraditional public health communicators, such as health \ndepartment employees, physicians, or community health \nworkers. The Public Health Communications Collabora -\ntive, for example, compiled a collection of toolkits, talk -\ning points, messaging, and graphics to help public health \nleaders communicate credibly and persuasively about \nCOVID-19, along with other health topics [46]. Other \nresources targeted non-traditional public health com -\nmunicators, including parents, teachers, and faith lead -\ners. The Public Health Association of British Columbia, \nfor example, partnered with CANVax to develop The \nCOVID-19 Misinformation Toolkit for Kids (and Par -\nents!) at Home, which is a guide for parents outlining \nhow to discuss COVID-19 vaccines with their children \n[47]. In addition, in 2021, the Office of the U.S. Surgeon \nGeneral released A Community Toolkit for Address -\ning Health Misinformation, which provides guidance to \nteachers, school administrators, healthcare professionals, \ncommunity members, and faith leaders on understand -\ning, identifying, discussing, and ultimately combatting \nhealth-related misinformation [48].\nCommunity engagement\nWe identified 25 community engagement approaches. \nThese approaches typically involved efforts to identify \nand train trusted messengers who could communicate \naccurate health information or encourage protective \nhealth-related behavior among members of their com -\nmunities. For example, the nonprofit Vaccinate Your \nFamily recently developed SQUAD\u2122, which is a program \nthat provides training and mentorship to individuals who \nwant to become vaccine advocates in their communities \n[49]. Many of the approaches in this level were aimed at \novercoming communication barriers (like lack of trust) \namong hard-to-reach, marginalized, or vulnerable popu -\nlations. Live Chair Health, for example, is an organization \nthat trains U.S. barbers in health education in order to \nclose the life expectancy gap and overcome medical mis -\ntrust among Black men. Recently, they have been training \nbarbers to discuss COVID-19-related issues with their \nclients, including vaccination [50]. Some of the com -\nmunity engagement efforts we identified were designed \nto (re)build trust in the healthcare system at large. \nThe International Vaccine Access Center, for example, \nPage 7 of 12\n Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \n \npartnered with local community leaders and other \norganizations in Baltimore to counter vaccine myths and \nencourage members of the African American community \nto get vaccinated against COVID-19. The more overarch -\ning goal of the program, however, was to \u201cbuild trust in \nboth vaccination and the broader health system\u201d [51].\nInstitutional/structural\nTags in the institutional/structural level were often \napplied to tools or approaches that were designed to shift \nthe burden of infodemic management from the \u201cdemand\u201d \nside (i.e., focusing on information consumers) to the \n\u201csupply\u201d side (i.e., focusing on information purveyors).\nPolicy or\u00a0legislation\nWe identified 33 regulatory or legislative approaches. \nThese approaches can be divided into three categories. \nThe first category consisted of efforts to regulate online \ncontent or otherwise hold individuals or companies crim -\ninally responsible for sharing false information online. \nIn the US, for example, some have proposed changes to \nSect.\u00a0 230 of the Communications Decency Act, which \nprotects online platforms from legal action based on the \ncontent shared by third parties. Proposed changes are \nintended to amend Sect.\u00a0230 by making online platforms \nliable for using their algorithms to promote the spread \nof health-related misinformation during a public health \nemergency [52].\nThe second category of regulatory and legislative \napproaches consisted of policies designed to enhance \ndigital or media literacy. The government of Singapore, \nfor example, recently released its Digital Readiness Blue -\nprint, which is a national plan for increasing access to \nand use of digital technology as well as enhancing digital \nliteracy among citizens. One of the aims outlined in the \nplan is to \u201cstrengthen focus on information and media lit -\neracy to build resilience in an era of online falsehoods\u201d \n[53]. In the US, proposed legislation has included efforts \nto implement a national strategy for information/media \nliteracy education and the development of a commission \nto oversee information/media literacy in schools [54].\nThe final category of policy/legislative approaches con -\nsisted of policies related to medical boards or licensure in \nthe US. The Tennessee State Medical Board, for example, \ninstituted a policy in 2021 that allows removal of medical \nlicenses from physicians spreading misinformation about \nthe COVID-19 vaccines [55].\nSocial media regulation\nWe identified 13 approaches or policies designed to regu -\nlate information on social media platforms. These efforts \ncan be divided into two broad categories: soft content \nmoderation and hard content moderation. Soft content moderation generally consisted of efforts to reduce the \nvisibility or amplification of posts containing false infor -\nmation or efforts to alert individuals that certain posts \nmay contain false content. Hard content moderation \ninvolved removal of posts or suspension of accounts \npropagating false information. Meta is an example of a \nsocial media company that has employed both soft and \nhard content moderation. During the COVID-19 pan -\ndemic, for example, Meta introduced a series of policies \nto combat misinformation and disinformation about the \nvirus on Facebook, including using its algorithm to limit \nthe spread of false information and removing posts or \naccounts responsible for repeatedly sharing misinforma -\ntion [56].\nThe remaining institutional/structural-level tools con -\nsisted of capacity building tools for those working in \nhealth communications, public health, or infodemic \nresearch/management.\nManaging academic/scientific literature\nWe identified 3 tools/approaches designed to help aca -\ndemics or public health professionals keep track of \nemerging or retracted scientific literature. The COVID \nContents (CC) Initiative, for example, was an effort \nundertaken by the Istituto Superiore di Sanit\u00e0 (ISS) in \nItaly. During the height of the COVID-19 pandemic, \nISS established a working group to sift through peer-\nreviewed papers and pre-prints on COVID-19. The work -\ning group compiled their findings into an open-access \nweekly report called Covid Contents, the aim of which \nwas to provide health professionals with up-to-date and \nsynthesized information about COVID-19 as it emerged \n[57].\nResources and\u00a0standards for\u00a0journalists/fact checkers\nWe identified 13 resources or standards for journalists/\nfact-checkers. Some of these were designed to ensure \njournalists had access to accurate information and ade -\nquate resources when reporting on public health emer -\ngencies. In 2020, for example, the International Center \nfor Journalists, together with the International Journal -\nists\u2019 Network launched the Global Health Crisis Report -\ning Forum, now called the ICFJ Pamela Howard Forum \non Global Crisis Reporting, which provided journalists \nwith information about COVID-19 along with other \nresources to improve their coverage of the pandemic \n[58]. Other tools and approaches with this tag aimed to \nimprove or bolster the fact checking industry. The Inter -\nnational Fact Checking Network (IFCN) Code of Princi -\nples, for example, is an effort to promote fact checking \nin journalism and establish professional standards and \ncodes of conduct for fact checkers across the globe [59].\nPage 8 of 12 Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \nResources for\u00a0infodemic researchers/research\nWe identified 9 tools/approaches designed to facilitate \nresearch on misinformation/disinformation and infode -\nmiology. The Mercury Project, for example, is an effort to \nfund research that will help \u201ccombat the growing global \nthreat posed by low Covid-19 vaccination rates and pub -\nlic health mis- and disinformation\u201d [60].\nResources for\u00a0infodemic managers\nWe identified 38 high-level resources for those manag -\ning misinformation and disinformation as public health, \ncommunity, or industry leaders. Many of the tools and \napproaches with this tag consisted of frameworks, tool -\nkits, or high-level guides outlining how to combat health-\nrelated misinformation/disinformation or infodemics \nmore broadly. The U.S. Cybersecurity and Infrastruc -\nture Security Agency (CISA), for example, developed \nthe COVID-19 Disinformation Toolkit, which provides \ninformation and guidance to state, local, tribal, and ter -\nritorial officials on misinformation and disinformation \nrelated to COVID-19 [61].\nDiscussion\nWhile not comprehensive, the tools and approaches iden -\ntified by the research team provide valuable insight into \nthe current ecosystem of infodemic management strate -\ngies, which can be characterized using a modified social-\necological model with four levels. The tools/approaches \nin each level target important components and determi -\nnants of health-related misinformation and disinforma -\ntion, including information itself, individual resiliency, \ncommunication and interpersonal/inter-community rela -\ntionships and trust, and institutional and structural fac -\ntors. However, each type of approach has accompanying \nstrengths and weaknesses.\nIn terms of the information-level approaches, there \nare some practical considerations that are important to \nacknowledge. Findings from cognitive and psychologi -\ncal research suggest that human information processing \nis dictated largely by biases and heuristics [62], particu -\nlarly in conditions of uncertainty [63]. If, for example, \ninformation provided to individuals is contrary to pre-\nestablished beliefs, such information (factual or not) may \nsimply be dismissed in favor of alternative explanations, \na phenomenon referred to as confirmation bias [64]. \nThis bias not only makes individuals vulnerable to false \ninformation (particularly if such information conforms \nwith their pre-existing beliefs), but also likely limits the \nimpact of many of the information-level approaches in \nthe database, including amplifying factual information, \nfilling information voids, verification/credibility/detec -\ntion, and debunking false information. Indeed, there is \nevidence that debunking false information is extremely challenging when such information aligns with individu -\nals\u2019 pre-existing beliefs [65]. The scale of false informa -\ntion also presents a practical challenge, as new rumors \nand claims constantly emerge. While the incorporation of \nartificial intelligence tools can support information-level \ninterventions at scale, they introduce an additional set of \ncomplications and challenges associated with accuracy, \ninterpretation, and the need for trained or experienced \npersonnel [66].\nIn contrast to the information-level approaches, indi -\nvidual-level approaches are designed to encourage indi -\nviduals to think more critically about information they \ncome across, thereby helping them overcome some of the \ncognitive biases and heuristics that make them suscepti -\nble to false information in the first place. There is some \nevidence that such approaches can be effective. Preb -\nunking interventions, for example, have been shown to \nreduce the likelihood that individuals will be persuaded \nby false information or share it with others [43\u201345, 67]. \nIn addition, there is evidence that information literacy \ninterventions can change the way individuals think about \nand evaluate the information they consume [68, 69]. \nHowever, in order for such interventions to have real-\nworld impact, individuals must agree to be inoculated \nand/or undergo information literacy training. This could \nprove challenging, especially considering the ongoing \npoliticization of public health. Enhancing individual-\nlevel resiliency will also need to be a continual process as \nincreasingly savvy actors and misinformation campaigns \ncontinue to adapt and evolve. Finally, it should be noted \nthat enhancing science literacy will not necessarily make \nindividuals more trusting of information provided to \nthem by scientists. On the contrary, improving individu -\nals\u2019 knowledge of the scientific process (and of the inher -\nent uncertainties involved in scientific research) may \ncause them to be more skeptical of scientific information \nin general [70].\nThe communication and community engagement \napproaches identified in this search touch on one of the \nmost important components of and contributors to mis -\ninformation and disinformation: lack of trust. By lever -\naging trusted community messengers and (re)building \ntrust in the healthcare system, these approaches offer \npromising ways to overcome barriers to communication \nand reduce the spread and impact of false information. \nHowever, identifying messengers and establishing trust \nwith certain communities\u2014particularly those that have \nexperienced marginalization or oppression\u2014will require \nongoing investment and resources. Indeed, scholars \nargue that community engagement should be thought of \nas a component of disaster preparedness in addition to \nresponse [71]. Moreover, community engagement and \ncommunication approaches will need to be tailored to \nPage 9 of 12\n Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \n \nthe specific information needs of different communities. \nInformation tracking tools may help identify such needs, \nas well as what kind of false information is circulating at \na given time.\nThe institutional and structural-level approaches\u2014par -\nticularly those relating to social media regulation and \npolicy or legislation\u2014are important given that they allow \nfor a more supply-side approach to combatting misinfor -\nmation/disinformation. Such approaches may be valuable \nbecause, as discussed above, cognitive biases make it dif -\nficult to prevent individuals from believing false infor -\nmation or to correct it once it has been seen. However, \nthere may be unintended consequences associated with \nefforts to regulate the supply of false information. For \nexample, there is evidence that flagging false content, a \nform of social media regulation, may make individuals \nmore likely to believe that content that is not flagged is \ntrue [72]. This phenomenon, referred to as the implied \ntruth effect, could be problematic if unflagged content \nis actually false. In addition, social media regulation \ncould potentially increase conspiratorial beliefs or claims \namong those whose social media activity is limited by \nsuch regulation (i.e., shutting down accounts may prove \nto individuals that they are being lied to or that there is \na conspiracy against them) [73, 74]. The very architec -\nture of social media may also undermine efforts to con -\ntain misinformation, as financial incentives to keep users \nengaged continue to prioritize sensational content over \nmore staid, but factual, claims. Structural approaches \nthat require policy change may also be difficult to enact. \nIn the US, political tensions have colored debates over \nsocial media policies. It should also be noted that legisla -\ntive efforts to contain \u201cmisinformation\u201d have been used \nto legally arrest and detain journalists and others around \nthe world. In some instances, the arbiter of \u201ctruth\u201d may \nbe a government or administration that is hostile to \nclaims that undermine its legitimacy.\nNotwithstanding the challenges and limitations \ndescribed above, each level of the 4 i FACT contains val -\nuable approaches for managing and mitigating the effects \nof health-related misinformation and disinformation. \nSimilar levels (information, population, system) have \nbeen identified in previous work on the evaluation of \nemergency risk communication [75], which suggests that \nsocial-ecological models offer a useful way to character -\nize points of intervention or evaluation of information-\nrelated processes during public health emergencies. Such \nmodels are likely useful because they reflect complex \nrealities. Indeed, information (including false informa -\ntion) does not exist in a vacuum, but in a complex sys -\ntem of individuals, communities, and institutions. The \n4 i FACT reflects this reality, offering possible points of \nintervention at each level of the system. However, given their associated limitations, interventions that target only \none level of the system are unlikely to be effective on their \nown. As such, the most effective strategy for combatting \nhealth-related misinformation and disinformation will \nlikely be one that is multi-faceted and stretches across \nmultiple (or ideally all) levels of the 4 i FACT.\nThis research offers a characterization of infodemic \nmanagement strategies that public health practitioners, \ncommunicators, and policy makers can use to guide cur -\nrent and future approaches. However, this study is sub -\nject to some limitations. The dataset developed for this \nstudy is not an exhaustive list of all past or existing mis -\ninformation and disinformation management strategies. \nTools and approaches that were not discussed in aca -\ndemic or gray literature or that were not featured on U.S. \nstate or selected large local health department websites \nwere likely missed. Moreover, given that searches were \nconducted in English and only U.S. health department \nwebsites were searched, the database is unlikely to be rep -\nresentative of strategies at the international level. Finally, \nwhile efforts were taken to ensure tools and approaches \nwere described using the most up-to-date and accurate \ninformation available, it is possible that some were mis -\ninterpreted or mischaracterized. Recognizing that any \neffort at a comprehensive list would be outdated as soon \nas it was compiled, the tagging system developed by the \nresearch team focuses on broader approaches that con -\ntinue to resonate, even as the details of specific tools con -\ntinue to evolve.\nConclusions\nThe current ecosystem of infodemic management strate -\ngies can be characterized using a modified social-ecologi -\ncal model, the 4 i FACT, with four interconnected, nested \nlevels: information, individual, interpersonal, and institu -\ntional. Public health practitioners, communicators, and \npolicy makers can use this model, and the approaches \ncontained within it, to inform current and future efforts \nto combat health-related misinformation and disinfor -\nmation, which continue to pose a threat to public health. \nGiven the complexity of the information environment \nand the fact that approaches in each level have associated \nstrengths and limitations, efforts should be taken to uti -\nlize and integrate strategies across all four levels of the 4 \ni FACT. No single intervention can adequately address all \nlevels of the infodemic, and any comprehensive approach \nto infodemic management must consider action across \nall levels.\nAbbreviations\nWHO  World Health Organization\nUS  United States\n4 i FACT   4 I Framework for Advancing Communication and Trust\nPage 10 of 12 Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \nSEM  Social\u2011 ecological model\nCDC  Centers for Disease Control and Prevention\nNASEM  National Academies of Sciences, Engineering, and Medicine\nAI  Artificial intelligence\nML  Machine learning\nAcknowledgements\nNot applicable.\nAuthors\u2019 contributions\nTKS conceptualized the study and oversaw study procedures. All authors \ncontributed to data collection. AES drafted the manuscript. All authors read, \nedited, and approved the final manuscript.\nFunding\nFunding for this research was provided by U.S. Centers for Disease Control \nand Prevention (CDC), contract number 75D30122C14281, and the National \nAcademies of Sciences, Engineering, and Medicine (NASEM).\nAvailability of data and materials\nThe datasets generated and analyzed during the current study are not yet \npublicly available as the research team is still exploring ways to display the \ndata in a searchable format. In the meantime, data are available from the cor \u2011\nresponding author on reasonable request.\nDeclarations\nEthics approval and consent to participate\nThe research is based on publicly available documents; therefore, ethics \napproval and consent were not sought.\nConsent for publication\nNot applicable.\nCompeting interests\nNone to declare.\nAuthor details\n1 Johns Hopkins Center for Health Security, 700 E. Pratt Street, Suite 900, Balti\u2011\nmore, MD 21202, USA. 2 Department of Environmental Health and Engineer \u2011\ning, Johns Hopkins Bloomberg School of Public Health, 615 N. Wolfe Street, \nRoom E7527, Baltimore, MD 21205, USA. 3 Department of Health, Behavior \nand Society, Johns Hopkins Bloomberg School of Public Health, 615 N. Wolfe \nStreet, Baltimore, MD 21205, USA. 4 Department of International Health, Johns \nHopkins Bloomberg School of Public Health, 615 N. Wolfe Street, Baltimore, \nMD 21205, USA. \nReceived: 12 April 2023   Accepted: 24 August 2023\nReferences\n 1. Coronavirus disease 2019 (COVID \u201119) Situation Report \u2013 100. World \nHealth Organization; 2020. cited 2023 Apr 9. Report No.: 100. Available \nfrom:https:// apps. who. int/ iris/ bitst ream/ handle/ 10665/ 332053/ nCoVs \nitrep 29Apr 2020\u2011 eng. pdf .\n 2. Rocha YM, de Moura GA, Desid\u00e9rio GA, de Oliveira CH, Louren\u00e7o FD, de \nFigueiredo Nicolete LD. The impact of fake news on social media and its \ninfluence on health during the COVID \u201119 pandemic: a systematic review. \nJ Public Health (Berl). 2021 Cited 2023 Mar 23;https:// doi. org/ 10. 1007/ \ns10389\u2011 021\u2011 01658\u2011z.\n 3. Loomba S, de Figueiredo A, Piatek SJ, de Graaf K, Larson HJ. Measuring \nthe impact of COVID \u201119 vaccine misinformation on vaccination intent in \nthe UK and USA. Nat Hum Behav. 2021;5(3):337\u201348.\n 4. Bhatti OA, Rauf H, Aziz N, Martins RS, Khan JA. Violence against Healthcare \nWorkers during the COVID \u201119 Pandemic: A Review of Incidents from a \nLower \u2011Middle \u2011Income Country. Ann Glob Health. 2021;87(1):41. 5. Roozenbeek J, Schneider CR, Dryhurst S, Kerr J, Freeman ALJ, Recchia G, \net al. Susceptibility to misinformation about COVID \u201119 around the world. \nR Soc Open Sci. 2020;7(10):201199.\n 6. Broniatowski DA, Jamison AM, Qi S, AlKulaib L, Chen T, Benton A, et al. \nWeaponized Health Communication: Twitter Bots and Russian Trolls \nAmplify the Vaccine Debate. Am J Public Health. 2018;108(10):1378\u201384.\n 7. Vosoughi S, Roy D, Aral S. The spread of true and false news online. Sci\u2011\nence. 2018;359(6380):1146\u201351.\n 8. Cinelli M, De Francisci MG, Galeazzi A, Quattrociocchi W, Starnini \nM. The echo chamber effect on social media. Proc Natl Acad Sci. \n2021;118(9):e2023301118.\n 9. T\u00f6rnberg P . Echo chambers and viral misinformation: Modeling fake news \nas complex contagion. PLoS One. 2018;13(9):e0203958.\n 10. Pariser E. The filter bubble: how the new personalized web is changing \nwhat we read and how we think. London: Penguin; 2011. p. 179.\n 11. Pantazi M, Hale S, Klein O. Social and Cognitive Aspects of the Vulnerabil\u2011\nity to Political Misinformation. Polit Psychol. 2021;42(S1):267\u2013304.\n 12. Rhodes SC. Filter Bubbles, Echo Chambers, and Fake News: How Social \nMedia Conditions Individuals to Be Less Critical of Political Misinforma\u2011\ntion. Polit Commun. 2022;39(1):1\u201322.\n 13. De Freitas L, Basdeo D, Wang HI. Public trust, information sources and \nvaccine willingness related to the COVID \u201119 pandemic in Trinidad and \nTobago: an online cross\u2011sectional survey. Lancet Regional Health \u2011 Ameri\u2011\ncas. 2021;1(3):100051.\n 14. Melki J, Tamim H, Hadid D, Makki M, Amine JE, Hitti E. Mitigating \ninfodemics: the relationship between news exposure and trust and \nbelief in COVID \u201119 fake news and social media spreading. PLoS One. \n2021;16(6):e0252830.\n 15. Pierre JM. Mistrust and misinformation: a two \u2011component, socio \u2011\nepistemic model of belief in conspiracy theories. J Soc Polit Psychol. \n2020;8(2):617\u201341.\n 16. Sundelson AE, Huhn N, Jamison AM, Pasquino SL, Kirk Sell T. Infodemic \nManagement Approaches Leading up to, During, and Following the \nCOVID \u201119 Pandemic. Johns Hopkins Center for Health Security; 2023 \n[Cited 2023 Apr 11]. Available from:https:// www. cente rforh ealth secur  ity. \norg/ our \u2011 work/ publi catio ns/ infod emic\u2011 manag ement \u2011 appro aches\u2011 leadi \nng\u2011 up \u2011 to\u2011 during\u2011 and\u2011 follo  wing\u2011 the \u2011 covid\u2011 19\u2011 pande mic .\n 17. Roozenbeek J, Culloty E, Suiter J. Countering misinformation. Eur Psychol. \n2023;28(3):189\u2013205.\n 18. Kozyreva A, Lewandowsky S, Hertwig R. Citizens versus the internet: \nconfronting digital challenges with cognitive tools. Psychol Sci Public \nInterest. 2020;21(3):103\u201356.\n 19. Tangcharoensathien V, Calleja N, Nguyen T, Purnat T, D\u2019Agostino M, \nGarcia\u2011Saiso S, et al. Framework for Managing the COVID \u201119 Infodemic: \nMethods and Results of an Online, Crowdsourced WHO Technical Consul\u2011\ntation. J Med Internet Res. 2020;22(6):e19659.\n 20. Korin MR, Araya F, Idris MY, Brown H, Claudio L. Community\u2011based organi\u2011\nzations as effective partners in the battle against misinformation. Front \nPublic Health. 2022;10:853736.\n 21. Featherstone JD, Zhang J. Feeling angry: the effects of vaccine misinfor \u2011\nmation and refutational messages on negative emotions and vaccination \nattitude. J Health Commun. 2020;25(9):692\u2013702.\n 22. Ophir Y, Romer D, Jamieson PE, Jamieson KH. Counteracting Mislead\u2011\ning Protobacco YouTube Videos: The Effects of Text \u2011Based and Narrative \nCorrection Interventions and the Role of Identification. Int J Commun. \n2020;14:16.\n 23. Piltch\u2011Loeb R, Su M, Hughes B, Testa M, Goldberg B, Braddock K, et al. \nTesting the efficacy of attitudinal inoculation videos to enhance COVID \u2011\n19 vaccine acceptance: quasi\u2011 experimental intervention trial. JMIR Public \nHealth Surveill. 2022;8(6):e34615.\n 24. Appelman N, Dreyer S, Bidare PM, Potthast KC. Truth, intention and harm: \nConceptual challenges for disinformation\u2011targeted governance. Internet \nPolicy Review. 2022. Cited 2023 Aug 1; Available from:https:// polic  yrevi \new. info/ artic les/ news/ truth\u2011 inten tion\u2011 and\u2011 harm\u2011 conce ptual\u2011 chall enges\u2011 \ndisin forma tion\u2011 targe ted\u2011 gover  nance/ 1668.\n 25. Bronfenbrenner U. Ecological systems theory. In: Making human beings \nhuman: Bioecological perspectives on human development. Thousand \nOaks: Sage Publications Ltd; 2005. p. 106\u201373.\n 26. Golden SD, McLeroy KR, Green LW, Earp JAL, Lieberman LD. Upending the \nSocial Ecological Model to Guide Health Promotion Efforts Toward Policy \nand Environmental Change. Health Educ Behav. 2015;42(1_suppl):8S\u201114S.\nPage 11 of 12\n Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \n \n 27. Instagram. 2021 Cited 2023 Apr 9. B\u2019More City Health on Instagram: \u201cYou \nknow where there are microchips? In your phone. You know where there \naren\u2019t microchips? In your vaccine. Get\u2026.\u201d Available from:https:// www. \ninsta gram. com/p/ CUVPO  cVKsax/.\n 28. Ritter AZ, Aronowitz S, Leininger L, Jones M, Dowd JB, Albrecht S, et al. \nDear pandemic: nurses as key partners in fighting the COVID \u201119 info \u2011\ndemic. Public Health Nurs. 2021;38(4):603\u20139.\n 29. Weeks R, Sangha P , Cooper L, Sedoc J, White S, Gretz S, et al. Usability and \nCredibility of a COVID \u201119 Vaccine Chatbot for Young Adults and Health \nWorkers in the United States: Formative Mixed Methods Study. JMIR Hum \nFactors. 2023;30(10): e40533.\n 30. Minnesota COVID \u201119 Response. Cited 2023 Apr 9. Contact Us. Available \nfrom:https:// mn. gov/ covid 19/ conta ct \u2011 us/ index. jsp .\n 31. Georgia Department of Public Health. Cited 2023 Apr 9. COVID \u201119 Hot \u2011\nline. Available from:https:// dph. georg  ia. gov/ conta cts/ covid\u2011 19\u2011 hotli ne .\n 32. Illinois Department of Public Health. Cited 2023 Apr 9. COVID \u201119 Public \nCommunication. Available from:https:// dph. illin ois. gov/ covid 19/ resou \nrces\u2011 infor  mation/ daily\u2011 commu nicat ion. html .\n 33. World Health Organization. Cited 2023 Apr 9. Reaching digital popula\u2011\ntions everywhere with trusted information. Available from:https:// www. \nwho. int/ teams/ digit al\u2011 health\u2011 and\u2011 innov ation/ digit al\u2011 chann els/ reach ing\u2011 \ndigit al\u2011 popul ations\u2011 every  where \u2011 with\u2011 trust  ed\u2011 infor  mation.\n 34. Poynter. Cited 2023 Apr 9. CoronaVirusFacts Alliance. Available \nfrom:https:// www. poynt  er. org/ coron aviru sfact salli ance/.\n 35. EUvsDisinfo. Cited 2023 Jul 31. Disinfo Database. Available from:https:// \neuvsd isinfo. eu/ disin forma tion\u2011 cases/.\n 36. McGowan BS. World Health Organization\u2019s Early AI\u2011supported \nResponse with Social Listening Platform (WHO EARS). J Med Libr Assoc. \n2022;110(2):273\u20135.\n 37. Spadacini BM. Tracking Rumors to Contain Disease: The Case of DeySay \nin Liberia\u2019s Ebola Outbreak. USAID Impact Blog. 2016. Cited 2023 Apr 9. \nAvailable from:https:// blog. usaid. gov/ 2016/ 09/ track  ing\u2011 rumors\u2011 to \u2011 conta \nin\u2011 disea se \u2011 the \u2011 case \u2011 of\u2011 deysay\u2011 in\u2011 liber  ias\u2011 ebola\u2011 outbr  eak/.\n 38. Media Bias/Fact Check. Cited 2022 Oct 10. Media Bias/Fact Check News. \nAvailable from:https:// media biasf actch eck. com/.\n 39. Botometer by OSoMe. Cited 2022 Oct 10. Available from:https:// botom \neter. iuni. iu. edu .\n 40. COVID \u201119 in San Diego. Cited 2023 Apr 9. Finding Credible Sources of \nInformation. Available from:https:// www. sandi egoco unty. gov/ conte nt/ \nsdc/ hhsa/ progr ams/ phs/ commu nity_ epide miolo gy/ dc/ 2019\u2011 nCoV/ \nEvalu ating Infor  mation/ Credi bleSo urces. html .\n 41. OER Commons. Cited 2023 Apr 9. Cyber Citizenship. Available \nfrom:https:// www. oerco mmons. org/ hubs/ cyber  citiz enship .\n 42. Blakeslee S. The CRAAP Test. LOEX Quarterly. 2004 Oct 1;31(3). Available \nfrom:https:// commo ns. emich. edu/ loexq uarte rly/ vol31/ iss3/4.\n 43. van der Linden S, Leiserowitz A, Rosenthal S, Maibach E. Inoculating \nthe Public against Misinformation about Climate Change. Global Chall. \n2017;1(2):1600008.\n 44. Roozenbeek J, van der Linden S, Nygren T. Prebunking interventions \nbased on the psychological theory of \u201cinoculation\u201d can reduce sus\u2011\nceptibility to misinformation across cultures. Harvard Kennedy School \nMisinformation Review. 2020;1(2).\n 45. Basol M, Roozenbeek J, Berriche M, Uenal F, McClanahan WP , van der \nLinden S. Towards psychological herd immunity: cross\u2011 cultural evidence \nfor two prebunking interventions against COVID \u201119 misinformation. Big \nData Soc. 2021;8(1):20539517211013868.\n 46. Public Health Communications Collaborative. Cited 2023 Apr 9. Mes\u2011\nsaging guidance and Answers to Tough Questions about public health. \nAvailable from:https:// publi cheal thcol labor ative. org/ resou rces/.\n 47. CANVax. Cited 2023 Apr 9. The COVID \u201119 Misinformation Toolkit for Kids \n(and Parents!) at Home. Available from:https:// canvax. ca/ covid\u2011 19\u2011 misin \nforma tion\u2011 toolk  it\u2011 kids\u2011 and\u2011 paren ts\u2011 home .\n 48. A Community Toolkit for Addressing Health Misinformation. Office of the \nU.S. Surgeon General; 2021. Cited 2023 Apr 9. Available from:https:// oes. \ngsa. gov/ colla borat ions/ misin forma tion\u2011 toolk  it/.\n 49. Vaccinate Your Family. Cited 2023 Apr 9. Our Programs. Available \nfrom:https:// vacci natey  ourfa mily. org/ about \u2011 us/ our \u2011 missi on\u2011 histo ry/ our \u2011 \nprogr ams/.\n 50. Live Chair Health. Cited 2023 Apr 9. About. Available from:https:// www. \nlivec hair. co/ about \u2011 us. 51. Centers for Disease Control and Prevention. 2021. Cited 2023 Aug 3. \nBaltimore Faith Community Promoting COVID \u201119 Vaccine Confidence. \nAvailable from:https:// www. cdc. gov/ vacci nes/ covid\u2011 19/ health\u2011 depar \ntments/ featu res/ balti more. html .\n 52. Sen. Klobuchar A [D M. Text \u2011 S.2448 \u2011 117th Congress (2021\u20132022): \nHealth Misinformation Act of 2021. 2021 Cited 2023 Apr 9. Available \nfrom:https:// www. congr  ess. gov/ bill/ 117th\u2011 congr  ess/ senate \u2011 bill/ 2448/ \ntext.\n 53. Digital Readiness Blueprint. Singapore: Ministry of Communications and \nInformation; Cited 2023 Apr 9. Available from:https:// www. mci. gov. sg/ \nen/ portf  olios/ digit al\u2011 readi ness/ digit al\u2011 readi ness\u2011 bluep rint.\n 54. Rep. Beyer DS. Text \u2011 H.R.6971 \u2011 117th Congress (2021\u20132022): Educating \nAgainst Misinformation and Disinformation Act. 2022 Cited 2023 Apr 9. \nAvailable from:https:// www. congr  ess. gov/ bill/ 117th\u2011 congr  ess/ house \u2011 bill/ \n6971.\n 55. Wadhwani A. Medical board meets to review COVID misinformation \npolicy. Tennessee Lookout. 2021. Cited 2023 Apr 9; Available from:https:// \ntenne sseel ookout. com/ 2021/ 12/ 06/ medic al\u2011 board\u2011 meets\u2011 to \u2011 review\u2011 \ncovid\u2011 misin forma tion\u2011 policy/.\n 56. Facebook Help Centre. Cited 2023 Apr 9. COVID \u201119 policy updates and \nprotections. Available from:https:// www. faceb ook. com/ help/ 23076 48814 \n94641.\n 57. Bertinato L, Brambilla G, Castro PD, Rosi A, Nisini R, Barbaro A, et al. How \ncan we manage the COVID \u201119 infodemics? A case study targeted to \nhealth workers in Italy: Covid 19 Contents. Annali dell\u2019Istituto Superiore di \nSanit\u00e0. 2021;57(2):121\u20137.\n 58. ICFJ International Center for Journalists. Cited 2023 Apr 9. Covering \nCOVID \u201119: Resources for Journalists. Available from: https:// www. icfj. org/ \nour\u2011 work/ cover  ing\u2011 covid\u2011 19\u2011 resou rces\u2011 journ alists\n 59. IFCN Code of Principles. Cited 2023 Apr 9. Available from: https:// ifcnc \nodeof princ iples. poynt  er. org/\n 60. Press Release: 2022 Mercury Project Grantee Teams. Social Science \nResearch Council (SSRC). 2022. Cited 2023 Mar 1. Available from: https:// \nwww. ssrc. org/ progr ams/ the \u2011 mercu ry\u2011 proje ct/ cohort \u2011 annou nceme nt/\n 61. COVID \u201119 Disinformation Toolkit. Cybersecurity and Infrastructure Secu\u2011\nrity Agency; 2020. Cited 2023 Apr 9. Available from: https:// www. cisa. \ngov/ resou rces\u2011 tools/ resou rces/ covid\u2011 19\u2011 disin forma tion\u2011 toolk  it\n 62. Korteling JE, Brouwer AM, Toet A. A neural network framework for cogni\u2011\ntive bias. Front Psychol. 2018;3(9):1561.\n 63. Tversky A, Kahneman D. Judgment under uncertainty: heuristics and \nbiases. Science. 1974;185(4157):1124\u201331.\n 64. Nickerson RS. Confirmation bias: a ubiquitous phenomenon in many \nguises. Rev Gen Psychol. 1998;2(2):175\u2013220.\n 65. Lewandowsky S, Ecker UKH, Seifert CM, Schwarz N, Cook J. Misinforma\u2011\ntion and its correction: continued Influence and successful debiasing. \nPsychol Sci Public Interest. 2012;13(3):106\u201331.\n 66. Garc\u00eda\u2011Mar\u00edn D, El\u00edas C, Soengas\u2011P\u00e9rez X. Big Data and Disinformation: \nAlgorithm Mapping for Fact Checking and Artificial Intelligence. In: \nV\u00e1zquez\u2011Herrero J, Silva\u2011Rodr\u00edguez A, Negreira\u2011Rey MC, Toural\u2011Bran C, \nL\u00f3pez\u2011 Garc\u00eda X, editors. Total Journalism: Models, Techniques and Chal\u2011\nlenges. Cham: Springer International Publishing; 2022. https:// doi. org/ 10. \n1007/ 978\u20113\u2011 030\u2011 88028\u20116_ 10. Cited 2023 Aug 7. 123\u201335. (Studies in Big \nData).\n 67. Iles IA, Gillman AS, Platter HN, Ferrer RA, Klein WMP . Investigating the \npotential of inoculation messages and self\u2011affirmation in reducing the \neffects of health misinformation. Sci Commun. 2021;43(6):768\u2013804.\n 68. Guess AM, Lerner M, Lyons B, Montgomery JM, Nyhan B, Reifler J, et al. \nA digital media literacy intervention increases discernment between \nmainstream and false news in the United States and India. Proc Natl Acad \nSci. 2020;117(27):15536\u201345.\n 69. McGrew S, Smith M, Breakstone J, Ortega T, Wineburg S. Improving \nuniversity students\u2019 web savvy: an intervention study. Br J Educ Psychol. \n2019;89(3):485\u2013500.\n 70. Howell EL, Brossard D. (Mis)informed about what? What it means to \nbe a science \u2011literate citizen in a digital world. Proc Natl Acad Sci U S A. \n2021;118(15):e1912436117.\n 71. Schoch\u2011Spana M, Franco C, Nuzzo JB, Usenza C. Community Engage \u2011\nment: Leadership Tool for Catastrophic Health Events. Biosecur Bioterror. \n2007;5(1):8\u201325.\n 72. Pennycook G, Bear A, Collins E, Rand DG. The Implied Truth Effect: Attach\u2011\ning Warnings to a Subset of Fake News Headlines Increases Perceived \nPage 12 of 12 Sundelson\u00a0et\u00a0al. BMC Public Health         (2023) 23:1662 \n\u2022\n fast, convenient online submission\n \u2022\n  thorough peer review by experienced researchers in your \ufb01eld\n\u2022 \n rapid publication on acceptance\n\u2022 \n support for research data, including large and complex data types\n\u2022\n  gold Open Access which fosters wider collaboration and increased citations \n maximum visibility for your research: over 100M website views per year \u2022\n  At BMC, research is always in progress.\nLearn more biomedcentral.com/submissionsReady to submit y our researc h Ready to submit y our researc h  ?  Choose BMC and benefit fr om: ?  Choose BMC and benefit fr om: \nAccuracy of Headlines Without Warnings. Rochester; 2019. Cited 2022 \nDec 3. Available from:https:// papers. ssrn. com/ abstr act= 30353 84.\n 73. Barrett JS, Yang SY, Muralidharan K, Javes V, Oladuja K, Castelli MS, et al. \nConsiderations for addressing anti\u2011 vaccination campaigns: How did we \nget here and what can we do about it? Clin Transl Sci. 2022;15(6):1380\u20136.\n 74. Helm RK, Nasu H. Regulatory Responses to \u201cFake News\u201d and freedom of \nexpression: normative and empirical evaluation. Hum Rights Law Rev. \n2021;21(2):302\u201328.\n 75. Savoia E, Lin L, Gamhewage GM. A conceptual framework for the \nevaluation of emergency risk communications. Am J Public Health. \n2017;107(S2):S208\u201314.\nPublisher\u2019s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub \u2011\nlished maps and institutional affiliations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fighting the infodemic: the 4 i framework for advancing communication and trust", "author": ["AE Sundelson", "AM Jamison", "N Huhn", "SL Pasquino"], "pub_year": "2023", "venue": "BMC Public Health", "abstract": "Background The proliferation of false and misleading health claims poses a major threat to  public health. This ongoing \u201cinfodemic\u201d has prompted numerous organizations to develop"}, "filled": false, "gsrank": 653, "pub_url": "https://link.springer.com/article/10.1186/s12889-023-16612-9", "author_id": ["", "IgG5S9cAAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:LP_SOmi7sqUJ:scholar.google.com/&output=cite&scirp=652&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D650%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=LP_SOmi7sqUJ&ei=e7WsaLT2OY6IieoP0sKRuAk&json=", "num_citations": 20, "citedby_url": "/scholar?cites=11939811618450505516&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:LP_SOmi7sqUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1186/s12889-023-16612-9.pdf"}}, {"title": "Fine-grained analysis of propaganda in news articles", "year": "2019", "pdf_data": "Fine-Grained Analysis of Propaganda in News Articles\nGiovanni Da San Martino1Seunghak Yu2Alberto Barr \u00b4on-Cede \u02dcno3\nRostislav Petrov4Preslav Nakov1\n1Qatar Computing Research Institute, HBKU, Qatar\n2MIT Computer Science and Arti\ufb01cial Intelligence Laboratory, Cambridge, MA, USA\n3Universit `a di Bologna, Forl `\u0131, Italy,4A Data Pro, So\ufb01a, Bulgaria\nfgmartino, pnakov g@hbku.edu.qa\nseunghak@csail.mit.edu ,a.barron@unibo.it\nrostislav.petrov@adata.pro\nAbstract\nPropaganda aims at in\ufb02uencing people\u2019s\nmindset with the purpose of advancing a spe-\nci\ufb01c agenda. Previous work has addressed\npropaganda detection at the document level,\ntypically labelling allarticles from a propa-\ngandistic news outlet as propaganda. Such\nnoisy gold labels inevitably affect the quality\nof any learning system trained on them. A\nfurther issue with most existing systems is the\nlack of explainability. To overcome these lim-\nitations, we propose a novel task: performing\n\ufb01ne-grained analysis of texts by detecting all\nfragments that contain propaganda techniques\nas well as their type. In particular, we cre-\nate a corpus of news articles manually anno-\ntated at the fragment level with eighteen pro-\npaganda techniques and we propose a suit-\nable evaluation measure. We further design\na novel multi-granularity neural network, and\nwe show that it outperforms several strong\nBERT-based baselines.\n1 Introduction\nResearch on detecting propaganda has focused\nprimarily on articles (Barr \u00b4on-Cedeno et al., 2019;\nRashkin et al., 2017). In many cases, there are no\nlabeled data for individual articles, but there are\nsuch labels for entire news outlets. Thus, often all\narticles from the same news outlet get labeled the\nway that this outlet is labeled. Yet, it has been\nobserved that propagandistic sources could post\nobjective non-propagandistic articles periodically\nto increase their credibility (Horne et al., 2018).\nSimilarly, media generally recognized as objec-\ntive might occasionally post articles that promote a\nparticular editorial agenda and are thus propagan-\ndistic. Thus, it is clear that transferring the label\nof the news outlet to each of its articles, could in-\ntroduce noise. Such labels can still be useful for\ntraining robust systems, but they cannot be used to\nget a fair assessment of a system at testing time.One option to deal with the lack of labels for arti-\ncles is to crowdsource the annotation. However, in\npreliminary experiments we observed that the av-\nerage annotator cannot detach her personal mind-\nset from the judgment of propaganda and bias,\ni.e., if a clearly propagandistic text expresses ideas\naligned with the annotator\u2019s beliefs, it is unlikely\nthat she would judge it as such.\nWe argue that in order to study propaganda in a\nsound and reliable way, we need to rely on high-\nquality trusted professional annotations and it is\nbest to do so at the fragment level, targeting spe-\nci\ufb01c techniques rather than using a label for an en-\ntire document or an entire news outlet.\nOurs is the \ufb01rst work that goes at a \ufb01ne-grained\nlevel: identifying speci\ufb01c instances of propaganda\ntechniques used within an article. In particular, we\ncreate a corresponding corpus. For this purpose,\nwe asked six experts to annotate articles from\nnews outlets recognized as propagandistic and\nnon-propagandistic, marking speci\ufb01c text spans\nwith eighteen propaganda techniques. We also\ndesigned appropriate evaluation measures. Taken\ntogether, the annotated corpus and the evalua-\ntion measures represent the \ufb01rst manually-curated\nevaluation framework for the analysis of \ufb01ne-\ngrained propaganda. We release the corpus (350K\ntokens) as well as our code in order to enable fu-\nture research.1Our contributions are as follows:\n\u000fWe formulate a new problem: detect the use\nof speci\ufb01c propaganda techniques in text.\n\u000fWe build a new large corpus for this problem.\n\u000fWe propose a suitable evaluation measure.\n\u000fWe design a novel multi-granularity neural\nnetwork, and we show that it outperforms\nseveral strong BERT-based baselines.\n1The corpus, the evaluation measures, and the models are\navailable at http://propaganda.qcri.org/arXiv:1910.02517v1  [cs.CL]  6 Oct 2019\nOur corpus could enable research in propagandis-\ntic and non-objective news, including the devel-\nopment of explainable AI systems. A system that\ncan detect instances of use of speci\ufb01c propagan-\ndistic techniques would be able to make it explicit\nto the users why a given article was predicted to be\npropagandistic. It could also help train the users to\nspot the use of such techniques in the news.\nThe remainder of this paper is organized as\nfollows: Section 2 presents the propagandistic\ntechniques we focus on. Section 3 describes\nour corpus. Section 4 discusses an evaluation\nmeasures for comparing labeled fragments. Sec-\ntion 5 presents the formulation of the task and\nour proposed models. Section 6 describes our ex-\nperiments and the evaluation results. Section 7\npresents some relevant related work. Finally, Sec-\ntion 8 concludes and discusses future work.\n2 Propaganda and its Techniques\nPropaganda comes in many forms, but it can\nbe recognized by its persuasive function, sizable\ntarget audience, the representation of a speci\ufb01c\ngroup\u2019s agenda, and the use of faulty reasoning\nand/or emotional appeals (Miller, 1939). Since\npropaganda is conveyed through the use of a num-\nber of techniques, their detection allows for a\ndeeper analysis at the paragraph and the sentence\nlevel that goes beyond a single document-level\njudgment on whether a text is propagandistic.\nWhereas the de\ufb01nition of propaganda is widely\naccepted in the literature, the set of propaganda\ntechniques differs between scholars (Torok, 2015).\nFor instance, Miller (1939) considers seven tech-\nniques, whereas Weston (2018) lists at least 24,\nand Wikipedia discusses 69.2The differences are\nmainly due to some authors ignoring some tech-\nniques, or using de\ufb01nitions that subsume the def-\ninition used by other authors. Below, we describe\nthe propaganda techniques we consider: a curated\nlist of eighteen items derived from the aforemen-\ntioned studies. The list only includes techniques\nthat can be found in journalistic articles and can\nbe judged intrinsically, without the need to retrieve\nsupporting information from external resources.\nFor example, we do not include techniques such as\ncard stacking (Jowett and O\u2019Donnell, 2012, page\n237), since it would require comparing against ex-\nternal sources of information.\n2http://en.wikipedia.org/wiki/\nPropaganda_techniques ; last visit May 2019.The eighteen techniques we consider are as fol-\nlows (cf. Table 1 for examples):\n1. Loaded language. Using words/phrases with\nstrong emotional implications (positive or nega-\ntive) to in\ufb02uence an audience (Weston, 2018, p. 6).\nEx.: \u201c[. . . ] a lone lawmaker\u2019s childish shouting.\u201d\n2. Name calling or labeling. Labeling the ob-\nject of the propaganda campaign as either some-\nthing the target audience fears, hates, \ufb01nds un-\ndesirable or otherwise loves or praises (Miller,\n1939). Ex.: \u201cRepublican congressweasels\u201d, \u201cBush\nthe Lesser.\u201d\n3. Repetition. Repeating the same message over\nand over again, so that the audience will eventually\naccept it (Torok, 2015; Miller, 1939).\n4. Exaggeration or minimization. Either rep-\nresenting something in an excessive manner: mak-\ning things larger, better, worse (e.g., \u201cthe best of\nthe best\u201d, \u201cquality guaranteed\u201d) or making some-\nthing seem less important or smaller than it ac-\ntually is (Jowett and O\u2019Donnell, 2012, p. 303),\ne.g., saying that an insult was just a joke. Ex.:\n\u201cDemocrats bolted as soon as Trumps speech\nended in an apparent effort to signal they can\u2019t\neven stomach being in the same room as the pres-\nident\u201d; \u201cI was not \ufb01ghting with her; we were just\nplaying.\u201d\n5. Doubt. Questioning the credibility of some-\none or something. Ex.: A candidate says about his\nopponent: \u201cIs he ready to be the Mayor?\u201d\n6. Appeal to fear/prejudice. Seeking to build\nsupport for an idea by instilling anxiety and/or\npanic in the population towards an alternative,\npossibly based on preconceived judgments. Ex.:\n\u201cstop those refugees; they are terrorists.\u201d\n7. Flag-waving. Playing on strong national feel-\ning (or with respect to a group, e.g., race, gender,\npolitical preference) to justify or promote an ac-\ntion or idea (Hobbs and Mcgee, 2008). Ex.: \u201cen-\ntering this war will make us have a better future in\nour country.\u201d\n8. Causal oversimpli\ufb01cation. Assuming one\ncause when there are multiple causes behind an\nissue. We include scapegoating as well: the trans-\nfer of the blame to one person or group of people\nwithout investigating the complexities of an issue.\nEx.: \u201cIf France had not declared war on Germany,\nWorld War II would have never happened.\u201d\nDoc ID Technique \u000fSnippet\n783702663 loaded language \u000funtil forced to act by a worldwide storm of outrage .\n732708002 name calling, labeling \u000fdismissing the protesters as lefties and hugging Barros publicly\n701225819 repetition\u000fFarrakhan repeatedly refers to Jews as Satan . He states to his audience [. . . ] call them by\ntheir real name, \u2018 Satan .\u2019\n782086447 exaggeration, minimization \u000fheal the situation of extremely grave immoral behavior\n761969038 doubt\u000fCan the same be said for the Obama Administration ?\n696694316 appeal to fear/prejudice \u000fA dark, impenetrable and irreversible winter of persecution of the\nfaithful by their own shepherds will fall .\n776368676 flag-waving\u000fcon\ufb02icted, and his 17 Angry Democrats that are doing his dirty work are a disgrace to\nUSA ! \u2014Donald J. Trump\n776368676 flag-waving\u000fattempt (Mueller) to stop the will of We the People !!! It\u2019s time to jail Mueller\n735815173 causal oversimplification \u000fhe said The people who talk about the \u201dJewish question\u201d are gen-\nerally anti-Semites . Somehow I don\u2019t think\n781768042 causal oversimplification \u000fwill not be reversed, which leaves no alternative as to why God\njudges and is judging America today\n111111113 slogans\u000fBUILD THE WALL!\u201d Trump tweeted.\n783702663 appeal to authority \u000fMonsignor Jean-Franois Lantheaume, who served as \ufb01rst Counsellor of\nthe Nunciature in Washington, con\ufb01rmed that \u201cVigan said the truth. Thats all\u201d\n783702663 black-and-white fallacy \u000fFrancis said these words: Everyone is guilty for the good he could have\ndone and did not do . . . If we do not oppose evil, we tacitly feed it .\n729410793 thought-terminating cliches \u000fI do not really see any problems there. Marx is the President\n770156173 whataboutism\u000fPresident Trump \u2014 who himself avoided national military service in the 1960\u2019s\u2014 keeps\nbeating the war drums over North Korea\n778139122 reductio ad hitlerum \u000f\u201cVichy journalism,\u201d a term which now \ufb01ts so much of the mainstream media.\nIt collaborates in the same way that the Vichy government in France collaborated with the Nazis.\n778139122 red herring\u000fIt describes the tsunami of vindictive personal abuse that has been heaped upon Julian from\nwell-known journalists, many claiming liberal credentials. The Guardian, which used to consider itself the\nmost enlightened newspaper in the country , has probably been the worst.\n698018235 bandwagon\u000fHe tweeted, \u201c EU no longer considers #Hamas a terrorist group. Time for US to do same.\u201d\n729410793 obfusc., int. vagueness, confusion \u000fThe cardinal\u2019s of\ufb01ce maintains that rather than saying \u201cyes,\u201d there is\na possibility of liturgical \u201cblessing\u201d of gay unions, he answered the question in a more subtle way without\ngiving an explicit \u201cyes.\u201d\n783702663 straw man\u000f\u201cTake it seriously, but with a large grain of salt.\u201d Which is just Allen\u2019s more nuanced way of\nsaying: \u201cDon\u2019t believe it .\u201d\nTable 1: Instances of the different propaganda techniques from our corpus. We show the document ID, the tech-\nnique, and the text snippet, in bold. When necessary, some context is provided to better understand the example.\n9. Slogans. A brief and striking phrase that may\ninclude labeling and stereotyping. Slogans tend to\nact as emotional appeals (Dan, 2015). Ex.: \u201cMake\nAmerica great again!\u201d\n10. Appeal to authority. Stating that a claim is\ntrue simply because a valid authority/expert on the\nissue supports it, without any other supporting ev-\nidence (Goodwin, 2011). We include the special\ncase where the reference is not an authority/expert,\nalthough it is referred to as testimonial in the liter-\nature (Jowett and O\u2019Donnell, 2012, p. 237).\n11. Black-and-white fallacy, dictatorship. Pre-\nsenting two alternative options as the only pos-\nsibilities, when in fact more possibilities exist\n(Torok, 2015). As an extreme case, telling the\naudience exactly what actions to take, eliminat-\ning any other possible choice ( dictatorship ).Ex.:\n\u201cYou must be a Republican or Democrat; you are\nnot a Democrat. Therefore, you must be a Repub-\nlican\u201d; \u201cThere is no alternative to war.\u201d12. Thought-terminating clich \u00b4e.Words or\nphrases that discourage critical thought and mean-\ningful discussion about a given topic. They are\ntypically short, generic sentences that offer seem-\ningly simple answers to complex questions or\nthat distract attention away from other lines of\nthought (Hunter, 2015, p. 78). Ex.: \u201cit is what it\nis\u201d; \u201cyou cannot judge it without experiencing it\u201d;\n\u201cit\u2019s common sense\u201d, \u201cnothing is permanent ex-\ncept change\u201d, \u201cbetter late than never\u201d; \u201cmind your\nown business\u201d; \u201cnobody\u2019s perfect\u201d; \u201cit doesn\u2019t\nmatter\u201d; \u201cyou can\u2019t change human nature.\u201d\n13. Whataboutism. Discredit an opponent\u2019s posi-\ntion by charging them with hypocrisy without di-\nrectly disproving their argument (Richter, 2017).\nFor example, mentioning an event that discred-\nits the opponent: \u201cWhat about . . . ?\u201d (Richter,\n2017). Ex.: Russia Today had a proclivity for\nwhataboutism in its coverage of the 2015 Balti-\nmore and Ferguson protests in the US, which re-\nvealed a consistent refrain: \u201cthe oppression of\nblacks in the US has become so unbearable that\nthe eruption of violence was inevitable\u201d, and that\nthe US therefore lacks \u201cthe moral high ground to\ndiscuss human rights issues in countries like Rus-\nsia and China.\u201d\n14. Reductio ad Hitlerum. Persuading an audi-\nence to disapprove an action or idea by suggest-\ning that the idea is popular with groups hated in\ncontempt by the target audience. It can refer to\nany person or concept with a negative connota-\ntion (Teninbaum, 2009). Ex.: \u201cOnly one kind of\nperson can think this way: a communist.\u201d\n15. Red herring. Introducing irrelevant mate-\nrial to the issue being discussed, so that every-\none\u2019s attention is diverted away from the points\nmade (Weston, 2018, p. 78). Those subjected to\na red herring argument are led away from the is-\nsue that had been the focus of the discussion and\nurged to follow an observation or claim that may\nbe associated with the original claim, but is not\nhighly relevant to the issue in dispute (Teninbaum,\n2009). Ex.: \u201cYou may claim that the death penalty\nis an ineffective deterrent against crime \u2013 but what\nabout the victims of crime? How do you think sur-\nviving family members feel when they see the man\nwho murdered their son kept in prison at their ex-\npense? Is it right that they should pay for their\nson\u2019s murderer to be fed and housed?\u201d\n16. Bandwagon. Attempting to persuade the tar-\nget audience to join in and take the course of ac-\ntion because \u201ceveryone else is taking the same ac-\ntion\u201d (Hobbs and Mcgee, 2008). Ex.: \u201cWould you\nvote for Clinton as president? 57% say yes.\u201d\n17. Obfuscation, intentional vagueness, confu-\nsion. Using deliberately unclear words, so that the\naudience may have its own interpretation (Supra-\nbandari, 2007; Weston, 2018, p. 8). For instance,\nwhen an unclear phrase with multiple possible\nmeanings is used within the argument, and, there-\nfore, it does not really support the conclusion. Ex.:\n\u201cIt is a good idea to listen to victims of theft.\nTherefore, if the victims say to have the thief shot,\nthen you should do it.\u201d\n18. Straw man. When an opponent\u2019s proposition\nis substituted with a similar one which is then re-\nfuted in place of the original (Walton, 1996). We-\nston (2018, p. 78) speci\ufb01es the characteristics of\nthe substituted proposition: \u201ccaricaturing an op-\nposing view so that it is easy to refute.\u201dProp Non-prop All\narticles 372 79 451\navg length (lines) 49.8 34.4 47.1\navg length (words) 973.2 635.4 914.0\navg length (chars) 5,942 3,916 5,587\nTable 2: Statistics about the articles retrieved\nwith respect to the category of the media source:\nprop agandistic, non-prop agandistic, and all together.\nNews Outlet # News Outlet #\nFreedom Outpost 133 The Remnant Magazine 14\nFrontpage Magazine 56 Breaking911 11\nshtfplan.com 55 truthuncensored.net 8\nLew Rockwell 26 The Washington Standard 6\nvdare.com 20 www.unz.com 5\nremnantnewspaper.com 19 www.clashdaily.com 1\nPersonal Liberty 18\nTable 3: Number of articles retrieved from news outlets\ndeemed propagandistic by Media Bias/Fact Check.\nWe provided the above de\ufb01nitions, together\nwith some examples and an annotation schema, to\nour professional annotators, so that they can man-\nually annotate news articles. The details are pro-\nvided in the next section.\n3 Data Creation\nWe retrieved 451 news articles from 48 news out-\nlets, both propagandistic and non-propagandistic,\nwhich we annotated as described below.\n3.1 Article Retrieval\nFirst, we selected 13 propagandistic and 36 non-\npropagandistic news media outlets, as labeled by\nMedia Bias/Fact Check.3Then, we retrieved arti-\ncles from these sources, as shown in Table 2. Note\nthat 82.5% of the articles are from propagandistic\nsources, and these articles tend to be longer.\nTable 3 shows the number of articles re-\ntrieved from each propagandistic outlet. Over-\nall, we have 350k word tokens, which is compa-\nrable to standard datasets for other \ufb01ne-grained\ntext analysis tasks, such as named entity recog-\nnition, e.g., CoNLL\u201902 and CoNLL\u201903 covered\n381K, 333K, 310K, and 301K tokens for Spanish,\nDutch, German, and English, respectively (Tjong\nKim Sang, 2002; Tjong Kim Sang and De Meul-\nder, 2003).\n3http://mediabiasfactcheck.com/\n3.2 Manual Annotation\nWe aim at obtaining text fragments annotated with\nany of the 18 techniques described in Section 2\n(see Figure 1 for an example). Since the time re-\nquired to understand and memorize all the pro-\npaganda techniques is signi\ufb01cant, this annotation\ntask is not well-suited for crowdsourcing. We part-\nnered instead with a company that performs pro-\nfessional annotations, A Data Pro.4Appendix A\nshows details about the instructions and the tools\nprovided to the annotators.\nWe computed the \rinter-annotator agree-\nment (Mathet et al., 2015). We chose \rbecause\n(i) it is designed for tasks where both the span and\nits label are to be found and ( ii) it can deal with\noverlaps in the annotations by the same annotator5\n(e.g., instances of doubt often use name calling or\nloaded language to reinforce their message). We\ncomputed\rs, where we only consider the iden-\nti\ufb01ed spans, regardless of the technique, and \rsl,\nwhere we consider both the spans and their labels.\nLetabe an annotator. In a preliminary exer-\ncise, four annotators a[1;::;4]annotated six articles\nindependently, and the agreement was \rs= 0:34\nand\rsl= 0:31. Even taking into account that\n\ris a pessimistic measure (Mathet et al., 2015),\nthese values are low. Thus, we designed an an-\nnotation schema composed of two stages and in-\nvolving two annotator teams, each of which cov-\nered about 220documents. In stage 1, both a1and\na2annotated the same documents independently.\nIn stage 2, they gathered with a consolidator c1to\ndiscuss all instances and to come up with a \ufb01nal\nannotation. Annotators a3anda4and consolida-\ntorc2followed the same procedure. Annotating\nthe full corpus took 395 man hours.\nTable 4 shows the \ragreements on the full cor-\npus. As in the preliminary annotation, the agree-\nments for both teams are relatively low: 0.30 and\n0.34 for span selection, and slightly lower when la-\nbeling is considered as well. After the annotators\ndiscussed with the consolidator on the disagreed\ncases, the\rvalues got much higher: up to 0.74\nand 0.76 for each team. We further analyzed the\nannotations to determine the main cause for the\ndisagreement by computing the percentage of in-\nstances spotted by one annotator only in the \ufb01rst\nstage that are retained as gold annotations.\n4http://www.aiidatapro.com\n5See (Meyer et al., 2014; Mathet et al., 2015) for other\nalternatives, which lack some properties; ( ii) in particular.Annotations spans ( \rs) +labels ( \rsl)\na1a2 0.30 0.24\na3a4 0.34 0.28\na1c1 0.58 0.54\na2c1 0.74 0.72\na3c2 0.76 0.74\na4c2 0.42 0.39\nTable 4:\rinter-annotator agreement between an-\nnotators spotting spans alone ( spans ) and spotting\nspans+labeling ( +labels ). The top-2 rows refer to the\n\ufb01rst stage: agreement between annotators. The bottom\n4 rows refer to the consolidation stage: agreement be-\ntween each annotator and the \ufb01nal gold annotation.\nFigure 1: Example given to the annotators.\nOverall the percentage is 53% (5;921 out of\n11;122), and for each annotator is a1= 70% ,\na2= 48% ,a3= 57% ,a4= 31% . Observ-\ning such percentages together with the relatively\nlow differences in Table 4 between \rsand\rslfor\nthe same pairs (ai;aj)and(ai;cj), we can con-\nclude that disagreements are in general not due to\nthe two annotators assigning different labels to the\nsame or mostly overlapping spans, but rather be-\ncause one has missed an instance in the \ufb01rst stage.\n3.3 Statistics about the Dataset\nThe total number of technique instances found\nin the articles, after the consolidation phase, is\n7;485, with respect to a total number of 21;230\nsentences (35.2%). Table 5 reports some statistics\nabout the annotations. The average propagandis-\ntic fragment has a length of 47characters and the\naverage length of a sentence is 112.5 characters.\nOn average, the propagandistic techniques are\nhalf a sentence long. The most common ones are\nloaded language andname calling, labeling with\n2;547and1;294occurrences, respectively. They\nappear 6.7 and 4.7 times per article, while no other\ntechnique appears more than twice. Note that rep-\netition are in\ufb02ated as we asked the annotators to\nmark both the original and the repeated instances.\nPropaganda Technique inst avg. length\nloaded language 2,547 23:70\u000625:30\nname calling, labeling 1,294 26:10\u000619:88\nrepetition 767 16:90\u000618:92\nexaggeration, minimization 571 45:36\u000635:55\ndoubt 562 123:21\u000697:65\nappeal to fear/prejudice 367 93:56\u000674:59\n\ufb02ag-waving 330 61:88\u000668:61\ncausal oversimpli\ufb01cation 233 121:03\u000671:66\nslogans 172 25:30\u000613:49\nappeal to authority 169 131:23\u0006123:2\nblack-and-white fallacy 134 98:42\u000673:66\nthought-terminating cliches 95 34:85\u000629:28\nwhataboutism 76 120:93\u000669:62\nreductio ad hitlerum 66 94:58\u000664:16\nred herring 48 63:79\u000661:63\nbandwagon 17 100:29\u000697:05\nobfusc., int. vagueness, confusion 17 107:88\u000686:74\nstraw man 15 79:13\u000650:72\nall 7,485 46:99\u000661:45\nTable 5: Corpus statistics including instances per tech-\nnique and their avg. length in terms of characters.\n4 Evaluation Measures\nOur task is a sequence labeling one, with the fol-\nlowing key characteristics: ( i) a large number of\ntechniques whose spans might overlap in the text,\nand ( ii) large lengths of these spans. This requires\nan evaluation measure that gives credit for par-\ntial overlaps.6We derive an ad hoc measure fol-\nlowing related work on named entity recognition\n(NER) (Nadeau and Sekine, 2007) and (intrinsic)\nplagiarism detection (PD) (Potthast et al., 2010).\nWhile in NER, the relevant fragments tend to be\nshort multi-word strings, in PD \u2014and in our pro-\npaganda technique identi\ufb01cation task\u2014 the length\nvaries widely (cf. Table 5), and instances span\nfrom single tokens to full sentences or even longer\npieces of text. Thus, in our precision and re-\ncall versions, we give partial credit to imperfect\nmatches at the character level, as in PD.\nLet document dbe represented as a sequence of\ncharacters. A propagandistic text fragment is then\nrepresented as t= [ti;:::;t j]\u0012d. A document\nincludes a set of (possibly overlapping) fragments\nT. Similarly, a learning algorithm produces a set S\nwith fragments s= [sm;:::;s n], predicted on d.\nA labeling function l(x)2f1;:::; 18gassociates\ns2Sto one of the eighteen techniques. Figure 2\ngives examples of gold and predicted fragments.\n6The evaluation measures for the CoNLL\u201902 and\nCoNLL\u201903 NER tasks, where an instance is considered prop-\nerly identi\ufb01ed if and only if both the boundaries and the label\nare correct (Tsai et al., 2006), are not suitable in our context.\nt1 (c=1)                     t2 (c=2)             t3 (c=3) T\ns1 (c=1)              s2 (c=2) s3(c=2)       s4 (c=4)\nSFigure 2: Example of gold annotation (top) and the pre-\ndictions of a supervised model (bottom) in a document\nrepresented as a sequence of characters. The class of\neach fragment is shown in parentheses. s1goes beyond\nt1\u2019s proper boundaries; s2ands3partially spot t2, but\nfail to identify it entirely; s4spots the exact boundaries\noft3, but fails to assign it the right label.\nWe de\ufb01ne the following function to handle par-\ntial overlaps between fragments with same labels:\nC(s;t;h ) =j(s\\t)j\nh\u000e(l(s);l(t)); (1)\nwherehis a normalizing factor and \u000e(a;b) = 1 if\na=b, and 0otherwise. In the future, \u000ecould be\nre\ufb01ned to account for custom distance functions\nbetween classes, e.g., we might consider mistak-\ningloaded language forname calling or labeling\nless problematic than confusing it with Reduction\nad Hitlerum . Given Eq. (1), we now de\ufb01ne vari-\nants of precision and recall able to account for the\nimbalance in the corpus:\nP(S;T) =1\njSjX\ns2S;\nt2TC(s;t;jsj); (2)\nR(S;T) =1\njTjX\ns2S;\nt2TC(s;t;jtj); (3)\nWe de\ufb01ne Eq. (2) to be zero if jSj= 0 and\nEq. (3) to be zero if jTj= 0. Following Potthast\net al. (2010), in Eqs. (2) and (3) we penalize sys-\ntems predicting too many or too few instances by\ndividing byjSjandjTj, respectively, e.g., in Fig-\nure 2P(fs2;s3g;T)< P(fs3g;T). Finally, we\ncombine Eqs. (2) and (3) into an F 1-measure, the\nharmonic mean of precision and recall.\nHaving a separate function Cto be responsible\nfor comparing two annotations gives us some ad-\nditional \ufb02exibility that is missing in standard NER\nmeasures that operate at the token/character level.\nFor example, in Eq. (1) we could easily change the\nfactor that gives credit for partial overlaps by be-\ning more forgiving when only few characters are\nwrong.\n5 Tasks and Proposed Models\nWe de\ufb01ne two tasks based on the corpus described\nin Section 3: ( i)SLC (Sentence-level Classi\ufb01ca-\ntion) , which asks to predict whether a sentence\ncontains at least one propaganda technique, and\n(ii)FLC (Fragment-level classi\ufb01cation) , which\nasks to identify both the spans and the type of pro-\npaganda technique. Note that these two tasks are\nof different granularities, g1andg2, i.e., tokens for\nFLC and sentences for SLC. We split the corpus\ninto training, development and test, each contain-\ning 293, 57, 101 articles and 14,857, 2,108, 4,265\nsentences.\n5.1 Baselines\nWe depart from BERT (Devlin et al., 2019), as it\nhas achieved state-of-the-art performance on mul-\ntiple NLP benchmarks, and we design three base-\nlines based on it.\nBERT. We add a linear layer on top of BERT\nand we \ufb01ne-tune it, as suggested in (Devlin et al.,\n2019). For the FLC task, we feed the \ufb01nal hid-\nden representation for each token to a layer Lg2\nthat makes a 19-way classi\ufb01cation: does this to-\nken belong to one of the eighteen propaganda tech-\nniques or to none of them (cf. Figure 3-a). For the\nSLC task, we feed the \ufb01nal hidden representation\nfor the special [CLS] token, which BERT uses to\nrepresent the full sentence, to a two-dimensional\nlayerLg1to make a binary classi\ufb01cation.\nBERT-Joint. We use the layers for both tasks\nin the BERT baseline, Lg1andLg2, and we train\nfor both FLC and SLC jointly (cf. Figure 3-b).\nBERT-Granularity. We modify BERT-Joint to\ntransfer information from SLC directly to FLC.\nInstead of using only the Lg2layer for FLC, we\nconcatenate Lg1andLg2, and we add an extra\n19-dimensional classi\ufb01cation layer Lg1;2on top of\nthat concatenation to perform the prediction for\nFLC (cf. Figure 3-c).\n5.2 Multi-Granularity Network\nWe propose a model that can drive the higher-\ngranularity task (FLC) on the basis of the lower-\ngranularity information (SLC), rather than simply\nusing low-granularity information directly. Fig-\nure 3-d shows the architecture of this model. More\ngenerally, suppose there are ktasks of increas-\ning granularity, e.g., document-level, paragraph-\nlevel, sentence-level, word-level, subword-level,\ncharacter-level.\n...\nBERTToken\nLabel 1Token\nLabel 2Token\nLabel N \nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n... ...\nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n......\n......\nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n(c) BERT-Granu (d) Multi-Granularity Network(a) BERT (b) BERT-Joint... ... ... ... ...\n... ...\n... ...CLS T 1 T2 TN CLS T 1 T2 TN\nCLS T 1 T2 TNCLS T 1 T2 TNg1o\ng2o g2og1w g1wg1L g2L \ng1,2L \nf fFigure 3: The architecture of the baseline models (a-c),\nand of our proposed multi-granularity network (d).\nEach task has a separated classi\ufb01cation layer Lgk\nthat receives the feature representation of the spe-\nci\ufb01c level of granularity gkand outputs ogk. The\ndimension of the representation depends on the\nembedding layer, while the dimension of the out-\nput depends on the number of classes in the task.\nThe output ogkgenerates a weight for the next\ngranularity task gk+1through a trainable gate f:\nwgk=f(ogk) (4)\nThe gatefconsists of a projection layer to one\ndimension and an activation function. The result-\ning weight is multiplied by each element of the\noutput of layer Lgk+1to produce the output for\ntaskgk+1:\nogk+1=wgk\u0003ogk+1 (5)\nIfwgk= 0 for a given example, the output of\nthe next granularity task ogk+1would be 0 as well.\nIn our setting this means that, if the sentence-level\nclassi\ufb01er is con\ufb01dent the sentence does not con-\ntain propaganda, i.e., wgk= 0, then ogk+1= 0\nand there would be no propagandistic technique\npredicted for any span within that sentence. Simi-\nlarly, when back-propagating the error, if wgk= 0\nfor a given example, the \ufb01nal entropy loss would\nbecome zero; i.e. the model would not get any in-\nformation from that example. As a result, only ex-\namples strongly classi\ufb01ed as negative in a lower-\ngranularity task would be ignored in the high-\ngranularity task. Having the lower-granularity as\nthe main task means that higher-granularity infor-\nmation can be selectively used as additional infor-\nmation to improve the performance, but only if the\nexample is not considered as highly negative. We\nshow this in Section 6.3.\nFor the loss function, we use a cross-entropy loss\nwith sigmoid activation for every layer, except for\nthe highest-granularity layer LgK, which uses a\ncross-entropy loss with softmax activation. Un-\nlike softmax, which normalizes over all dimen-\nsions, the sigmoid allows each output component\nof layerLgkto be independent from the rest. Thus,\nthe output of the sigmoid for the positive class\nincreases the degree of freedom by not affecting\nthe negative class, and vice versa. As we have\ntwo tasks, we use sigmoid activation for Lg1and\nsoftmax activation for Lg2. Moreover, we use a\nweighted sum of losses with a hyper-parameter \u000b:\nLJ=Lg1\u0003\u000b+Lg2\u0003(1\u0000\u000b) (6)\nAgain, we use BERT (Devlin et al., 2019) for\nthe contextualized embedding layer and we place\nthe multi-granularity network on top of it.\n6 Experiments and Evaluation\n6.1 Experimental Setup\nWe used the PyTorch framework and the pre-\ntrained BERT model, which we \ufb01ne-tuned for our\ntasks. We trained all models using the follow-\ning hyper-parameters: batch size of 16, sequence\nlength of 210, weight decay of 0.01, and early\nstopping on validation F 1with patience of 7. For\noptimization, we used Adam with a learning rate\nof 3e-5 and a warmup proportion of 0.1. To deal\nwith class imbalance, we give weight to the binary\ncross-entropy according to the proportion of posi-\ntive samples. For the \u000bin the joint loss function,\nwe use 0.9 for sentence classi\ufb01cation, and 0.1 for\nword-level classi\ufb01cation. In order to reduce the\neffect of random \ufb02uctuations for BERT, all the re-\nported numbers are the average of three experi-\nmental runs with different random seeds. As it is\nstandard, we tune our models on the dev partition\nand we report results on the test partition.\n6.2 Fragment-Level Propaganda Detection\nTable 6 shows the performance for the three base-\nlines and for our multi-granularity network on the\nFLC task. For the latter, we vary the degree to\nwhich the gate function is applied: using ReLU is\nmore aggressive compared to using the Sigmoid,\nas the ReLU outputs zero for a negative input.\nNote that, even though we train the model to pre-\ndict both the spans and the labels, we also evalu-\nated it with respect to the spans only.ModelSpans Full Task\nP R F 1 P R F 1\nBERT 39.57 36.42 37.90 21.48 21.39 21.39\nJoint 39.26 35.48 37.25 20.11 19.74 19.92\nGranu 43.08 33.98 37.93 23.85 20.14 21.80\nMulti-Granularity\nReLU 43.29 34.74 38.28 23.98 20.33 21.82\nSigmoid 44.12 35.01 38.98 24.42 21.05 22.58\nTable 6: Fragment-level experiments (FLC task).\nShown are two evaluations: ( i)Spans checks only\nwhether the model has identi\ufb01ed the fragment spans\ncorrectly, while ( ii)Full task is evaluation wrt the ac-\ntual task of identifying the spans and also assigning the\ncorrect propaganda technique for each span.\nTable 6 shows that joint learning (BERT-Joint)\nhurts the performance compared to single-task\nBERT. However, using additional information\nfrom the sentence-level for the token-level classi-\n\ufb01cation (BERT-Granularity) yields small improve-\nments. The multi-granularity models outperform\nall baselines thanks to their higher precision. This\nshows the effect of the model excluding sen-\ntences that it determined to be non-propagandistic\nfrom being considered for token-level classi\ufb01ca-\ntion. Nevertheless, the performance of sentence-\nlevel classi\ufb01cation is far from perfect, achieving\nan F1of up to 60.98 (cf. Table 7). The information\nit contributes to the \ufb01nal classi\ufb01cation is noisy and\nthe more conservative removal of instances per-\nformed by the Sigmoid function yields better per-\nformance than the more aggressive ReLU.\n6.3 Sentence-Level Propaganda Detection\nTable 7 shows the results for the SLC task. We\napply our multi-granularity network model to the\nsentence-level classi\ufb01cation task to see its effect\non low granularity when we train the model with a\nhigh granularity task. Interestingly, it yields huge\nperformance improvements on the sentence-level\nclassi\ufb01cation result. Compared to the BERT base-\nline, it increases the recall by 8.42%, resulting in\na 3.24% increase of the F 1score. In this case, the\nresult of token-level classi\ufb01cation is used as addi-\ntional information for the sentence-level task, and\nit helps to \ufb01nd more positive samples. This shows\nthe opposite effect of our model compared to the\nFLC task. Note also that using ReLU is more ef-\nfective than using the Sigmoid, unlike in token-\nlevel classi\ufb01cation.\nModel Precision Recall F1\nAll-Propaganda 23.92 100.0 38.61\nBERT 63.20 53.16 57.74\nBERT-Granu 62.80 55.24 58.76\nBERT-Joint 62.84 55.46 58.91\nMGN Sigmoid 62.27 59.56 60.71\nMGN ReLU 60.41 61.58 60.98\nTable 7: Sentence-level (SLC) results. All-propaganda\nis a baseline which always output the propaganda class.\nThus, since the performance range of the token-\nlevel classi\ufb01cation is low, we think it is more ef-\nfective to get additional information after aggres-\nsively removing negative samples by using ReLU\nas a gate in the model.\n7 Related Work\nPropaganda identi\ufb01cation has been tackled mostly\nat the article level. Rashkin et al. (2017) created\na corpus of news articles labelled as belonging\nto four categories: propaganda, trusted, hoax, or\nsatire. They included articles from eight sources,\ntwo of which are propagandistic. Barr \u00b4on-Cede \u02dcno\net al. (2019) experimented with a binarized version\nof the corpus from (Rashkin et al., 2017): propa-\nganda vs. the other three categories. The corpus\nlabels were obtained with distant supervision, as-\nsuming that all articles from a given news outlet\nshare the label of that outlet, which inevitably in-\ntroduces noise (Horne et al., 2018).\nA related \ufb01eld is that of computational argu-\nmentation which, among others, deals with some\nlogical fallacies related to propaganda. Haber-\nnal et al. (2018b) presented a corpus of Web fo-\nrum discussions with cases of ad hominem fal-\nlacy identi\ufb01ed. Habernal et al. (2017, 2018a) in-\ntroduced Argotario , a game to educate people to\nrecognize and create fallacies. A byproduct of Ar-\ngotario is a corpus with 1:3karguments annotated\nwith \ufb01ve fallacies, including ad hominem ,red her-\nring andirrelevant authority , which directly relate\nto propaganda techniques (cf. Section 2). Differ-\nently from (Habernal et al., 2017, 2018a,b), our\ncorpus has 18 techniques annotated on the same\nset of news articles. Moreover, our annotations\naim at identifying the minimal fragments related to\na technique instead of \ufb02agging entire arguments.8 Conclusion and Future Work\nWe have argued for a new way to study propa-\nganda in news media: by focusing on identifying\nthe instances of use of speci\ufb01c propaganda tech-\nniques. Going at this \ufb01ne-grained level can yield\nmore reliable systems and it also makes it possible\nto explain to the user why an article was judged as\npropagandistic by an automatic system.\nIn particular, we designed an annotation schema\nof 18 propaganda techniques, and we annotated\na sizable dataset of documents with instances of\nthese techniques in use. We further designed an\nevaluation measure speci\ufb01cally tailored for this\ntask. We made the schema and the dataset publicly\navailable, thus facilitating further research. We\nhope that the corpus would raise interest outside\nof the community of researchers studying propa-\nganda: the techniques related to fallacies and the\nones relying on emotions might provide a novel\nsetting for the researchers interested in Argumen-\ntation and Sentiment Analysis.\nWe experimented with a number of BERT-based\nmodels and devised a novel architecture which\noutperforms standard BERT-based baselines. Our\n\ufb01ne-grained task can complement document-level\njudgments, both to come out with an aggregated\ndecision and to explain why a document \u2014or an\nentire news outlet\u2014 has been \ufb02agged as poten-\ntially propagandistic by an automatic system.\nWe are collaborating with A Data Pro to expand\nthe corpus. In the mid-term, we plan to build an\nonline platform where professors in relevant \ufb01elds\n(e.g., journalism, mass communication) can train\ntheir students to recognize and annotate propa-\nganda techniques. The hope is to be able to ac-\ncumulate annotations as a by-product of using the\nplatform for training purposes.\nAcknowledgments\nThis research is part of the Tanbih project,7which\naims to limit the effect of \u201cfake news\u201d, propa-\nganda and media bias by making users aware\nof what they are reading. The project is de-\nveloped in collaboration between the MIT Com-\nputer Science and Arti\ufb01cial Intelligence Labora-\ntory (CSAIL) and the Qatar Computing Research\nInstitute (QCRI), HBKU.\n7http://tanbih.qcri.org/\nReferences\nAlberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the 33rd AAAI Conference on Arti\ufb01-\ncial Intelligence , AAAI \u201919, pages 9847\u20139848, Hon-\nolulu, HI, USA.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nLavinia Dan. 2015. Techniques for the Translation of\nAdvertising Slogans. In Proceedings of the Interna-\ntional Conference Literature, Discourse and Multi-\ncultural Dialogue , LDMD \u201915, pages 13\u201323, Mures,\nRomania.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, MN, USA.\nJean Goodwin. 2011. Accounting for the force of the\nappeal to authority. In Proceedings of the 9th Inter-\nnational Conference of the Ontario Society for the\nStudy of Argumentation , OSSA \u201911, pages 1\u20139, On-\ntario, Canada.\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings\nof the Conference on Empirical Methods in Natu-\nral Language Processing , EMNLP \u201917, pages 7\u201312,\nCopenhagen, Denmark.\nIvan Habernal, Patrick Pauli, and Iryna Gurevych.\n2018a. Adapting serious game for fallacious argu-\nmentation to German: pitfalls, insights, and best\npractices. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation , LREC \u201918, Miyazaki, Japan.\nIvan Habernal, Henning Wachsmuth, Iryna Gurevych,\nand Benno Stein. 2018b. Before name-calling: Dy-\nnamics and triggers of ad hominem fallacies in web\nargumentation. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201918, pages 386\u2013\n396, New Orleans, LA, USA.\nRenee Hobbs and Sandra Mcgee. 2008. Teaching\nabout propaganda: An examination of the historical\nroots of media literacy. Journal of Media Literacy\nEducation , 6(62):56\u201367.Benjamin D Horne, Sara Khedr, and Sibel Adali. 2018.\nSampling the news producers: A large news and fea-\nture data set for the study of the complex media land-\nscape. In International AAAI Conference on Web\nand Social Media , ICWSM \u201918, Stanford, CA, USA.\nJohn Hunter. 2015. Brainwashing in a large group\nawareness training? The classical conditioning hy-\npothesis of brainwashing. Master\u2019s thesis, Uni-\nversity of Kwazulu-Natal, Pietermaritzburg, South\nAfrica.\nGarth S. Jowett and Victoria O\u2019Donnell. 2012. What is\npropaganda, and how does it differ from persuasion?\nInPropaganda & Persuasion , chapter 1, pages 1\u201348.\nSage Publishing.\nYann Mathet, Antoine Widl \u00a8ocher, and Jean-Philippe\nM\u00b4etivier. 2015. The uni\ufb01ed and holistic method\ngamma (\r) for inter-annotator agreement mea-\nsure and alignment. Computational Linguistics ,\n41(3):437\u2013479.\nChristian M. Meyer, Margot Mieskes, Christian Stab,\nand Iryna Gurevych. 2014. DKPro agreement: An\nopen-source Java library for measuring inter-rater\nagreement. In Proceedings of the International\nConference on Computational Linguistics , COL-\nING \u201914, pages 105\u2013109, Dublin, Ireland.\nClyde R. Miller. 1939. The Techniques of Propaganda.\nFrom \u201cHow to Detect and Analyze Propaganda,\u201d an\naddress given at Town Hall. The Center for learning.\nDavid Nadeau and Satoshi Sekine. 2007. A sur-\nvey of named entity recognition and classi\ufb01cation.\nLingvisticae Investigationes , 30(1):3\u201326.\nMartin Potthast, Benno Stein, Alberto Barr \u00b4on-Cede \u02dcno,\nand Paolo Rosso. 2010. An evaluation framework\nfor plagiarism detection. In Proceedings of the In-\nternational Conference on Computational Linguis-\ntics, COLING \u201910, pages 997\u20131005, Beijing, China.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing , EMNLP \u201917, pages 2931\u20132937, Copen-\nhagen, Denmark.\nMonika L Richter. 2017. The Kremlin\u2019s platform for\n\u2018useful idiots\u2019 in the West: An overview of RT\u2019s ed-\nitorial strategy and evidence of impact. Technical\nreport, Kremlin Watch.\nFrancisca Niken Vitri Suprabandari. 2007. Ameri-\ncan propaganda in John Steinbeck\u2019s The Moon is\nDown. Master\u2019s thesis, Sanata Dharma University,\nYogyakarta, Indonesia.\nGabriel H Teninbaum. 2009. Reductio ad Hitlerum:\nTrumping the judicial Nazi card. Michigan State\nLaw Review , page 541.\nErik F. Tjong Kim Sang. 2002. Introduction to the\nCoNLL-2002 shared task: Language-independent\nnamed entity recognition. In Proceedings of the\n6th Conference on Natural Language Learning ,\nCoNLL \u201902, pages 155\u2013158, Taipei, Taiwan.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the 7th Conference on Natural Lan-\nguage Learning , CoNLL \u201903, pages 142\u2013147, Ed-\nmonton, Canada.\nRobyn Torok. 2015. Symbiotic radicalisation strate-\ngies: Propaganda tools and neuro linguistic pro-\ngramming. In Proceedings of the Australian Se-\ncurity and Intelligence Conference , pages 58\u201365,\nPerth, Australia.\nRichard Tzong-Han Tsai, Shih-Hung Wu, Wen-Chi\nChou, Yu-Chun Lin, Ding He, Jieh Hsiang, Ting-\nYi Sung, and Wen-Lian Hsu. 2006. Various criteria\nin the evaluation of biomedical named entity recog-\nnition. BMC bioinformatics , 7:92.\nDouglas Walton. 1996. The straw man fallacy . Royal\nNetherlands Academy of Arts and Sciences.\nAnthony Weston. 2018. A rulebook for arguments .\nHackett Publishing.\nA Annotation Guidelines\nWe provided the de\ufb01nitions in Section 2 together\nwith some examples and an annotation schema,\nto our professional annotators, so that they could\nmanually annotate news articles. The annotators\nperformed their task following the instructions dis-\nplayed in Figure A.1. In order to help them, we\nbuilt the \ufb02owchart displayed in the same \ufb01gure. It\npartitions the set of techniques hierarchically and\ncan be traversed by answering a series of ques-\ntions. These instructions and the \ufb02owchart were\nalways available to the annotators, next to the an-\nnotation interface (cf. Figure 1). As an example of\nthe process for generating the questions, the \ufb01rst\nsubdivision is inspired by the following descrip-\ntion of propaganda: \u201cPropaganda comes in many\nforms, but you can recognize it by [. . . ] the use of\nfaulty reasoning and/or emotional appeals\u201d. The\ndescription distinguishes between logical fallacies\nand techniques appealing to emotions.\nWe aim at identifying propagandistic techniques in news ar-\nticles. We provide you with a news article and a \ufb02owchart\nto guide you through the identi\ufb01cation of propaganda tech-\nniques. The de\ufb01nition of each technique is shown when set-\nting the mouse pointer on the name of the technique in the\n\ufb02owchart. You are free to annotate single words, phrases,\nor sentences, but we encourage you to select the minimal\namount of text in which the propaganda technique appears.\n1. Let us look at the \ufb02owchart [below]\n2. Let us look at an example which includes four propa-\nganda techniques [cf. Figure 1]\n\u000fName calling : the democrats are being called \u201dbabies\u201d\n\u000fBlack-and-white fallacy : obstruction vs progress\n\u000fLoaded language : stupid, petty, killing\u000fExaggeration : killing a grandma, stomaching the\npresence of a person\nUse the \ufb02owchart as your guide to spot propaganda. If you\nare not sure about a propaganda technique (any rounded box\nin the \ufb02owchart), just click on it and a new page will open\nwith explanations and examples when necessary. [cf. Sec-\ntion 2]\nTIPS\n\u000fSome sentences might be tricky. Please try to select the\nright technique(s)\n\u000fYour emotions have nothing to do with the articles, as\nyou are requested to spot propagandistic techniques,\nnot their message: try to distance yourself from the\ncontents and avoid being biased.\n\u000fOne text fragment may include more than one tech-\nnique at the same time\nFigure A.1: Instructions as provided to the professional annotators in the Anafora-based annotation process (top).\nFlowchart to drive the identi\ufb01cation of propaganda techniques (bottom).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fine-grained analysis of propaganda in news articles", "author": ["GDS Martino", "S Yu", "A Barr\u00f3n-Cede\u00f1o", "R Petrov"], "pub_year": "2019", "venue": "arXiv preprint arXiv \u2026", "abstract": "Propaganda aims at influencing people's mindset with the purpose of advancing a specific  agenda. Previous work has addressed propaganda detection at the document level, typically"}, "filled": false, "gsrank": 655, "pub_url": "https://arxiv.org/abs/1910.02517", "author_id": ["URABLy0AAAAJ", "ayy2eo0AAAAJ", "0q0QVG4AAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:PmI5M_FzwNkJ:scholar.google.com/&output=cite&scirp=654&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D650%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PmI5M_FzwNkJ&ei=e7WsaLT2OY6IieoP0sKRuAk&json=", "num_citations": 30, "citedby_url": "/scholar?cites=15690668581542519358&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:PmI5M_FzwNkJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/1910.02517"}}, {"title": "Combating Problematic Information Online with Dual Process Cognitive Affordances", "year": "2023", "pdf_data": "Combating Problematic Information Online with Dual Process\nCognitive Affordances\nMd Momen Bhuiyan\nDissertation submitted to the Faculty of the\nVirginia Polytechnic Institute and State University\nin partial fulfillment of the requirements for the degree of\nDoctor of Philosophy\nin\nComputer Science and Applications\nSang Won Lee, Co-chair\nTanushree Mitra, Co-chair\nKurt Luther\nMichael A. Horning\nNitesh Goyal\nJune 20, 2023\nBlacksburg, Virginia\nKeywords: automatic affordance, reflective affordance, design, information consumption,\nmisinformation, filter bubble\nCopyright 2023, Md Momen Bhuiyan\nCombating Problematic Information Online with Dual Process Cog-\nnitive Affordances\nMd Momen Bhuiyan\n(ABSTRACT)\nDual process theories of mind have been developed over the last decades to posit that hu-\nmans use heuristics or mental shortcuts (automatic) and analytical (reflective) reasoning\nwhile consuming information. Can such theories be used to support users\u2019 information con-\nsumption in the presence of problematic content in online spaces? To answer, I merge these\ntheories with the idea of affordances from HCI to into the concept of dual process cogni-\ntive affordances, consisting of automatic affordance and reflective affordance. Using this\nconcept, I built and tested a set of systems to address two categories of online problematic\ncontent: misinformation and filter bubbles. In the first system, NudgeCred, I use cognitive\nheuristics from the MAIN model to design automatic affordances for better credibility as-\nsessment of news tweets from mainstream and misinformative sources. In TransparencyCue,\nI show the promise of value-centered automatic affordance design inside news articles differ-\nentiating content quality. To encourage information consumption outside their ideological\nfilter bubble, in NewsComp, I use comparative annotation to design reflective affordances\nthat enable active engagement with stories from opposing-leaning sources. In OtherTube, I\nuse parasocial interaction, that is, experiencing information feed through the eyes of some-\none else, to design a reflective affordance that enables recognition of filter bubbles in their\nYouTube recommendation feeds. Each system shows various degrees of success and outlines\nconsiderations in cognitive affordances design. Overall, this thesis showcases the utility of\ndesign strategies centered on dual process information cognition model of human mind to\ncombat problematic information space.\nCombating Problematic Information Online with Dual Process Cog-\nnitive Affordances\nMd Momen Bhuiyan\n(GENERAL AUDIENCE ABSTRACT)\nOver the last several decades, billions of users have moved to the internet for everyday infor-\nmation gathering, allowing information flow around the globe at a massive scale. This flow\nis managed by algorithms personalized to each users\u2019 need, creating a complicated trio of\nproducer-algorithm-consumer. This has resulted in some unforeseen challenges. Bad infor-\nmation producers takes the advantage of system to promote problematic content, such as,\nfalse information, termed as misinformation. Personalized algorithms have created filters of\nwhat people see oftentimes isolating them from diverse perspectives of information, creating\na distorted perception of reality. Augmenting the online technology infrastructure to combat\nthese challenges has become crucial and the overall goal of this thesis. Cognitive psychol-\nogists theorize that two cognitive processes are at play when people consume information,\nalso known as dual process theories. Can we design new tools to combat these challenges\nby tapping into each of these processes? In this thesis, I answer this question through a\nseries of studies. In each of these studies, I combine this theory from psychology with design\nguides from Human-Computer Interaction to design socio-technical design. I evaluated each\nof these systems through controlled experimentation. The result of these studies informs\nways we can capitalize on users\u2019 information processing mechanism to combat various types\nof problematic information online.\nAcknowledgments\nThis thesis would not be possible without the support of so many unbelievably talented\npeople. You have helped me be a better person and a better learner. Therefore, I dedicate\nthis thesis to you:\n\u2022My mom, my late dad, and my brother, who have been always there for me\n\u2022My advisors Sang Won Lee and Tanushree Mitra, who supported and inspired me both\nin good times and bad\n\u2022My dissertation committee members: Mike Horning, for helping me make sense of\nnewsmaking from the journalistic side; Kurt Luther, for piquing my interest from my\nfirst HCI course with you and your quick feedback whenever I needed; and Nitesh\nGoyal, for your encouragement and bringing in the industry perspective in our discus-\nsion. Your feedback during this thesis has been invaluable\n\u2022All the lab members from both Social Computing Lab at UW and Echolab. Notably,\nMattia Samory, an incredible mentor; Shruti Phadke, although we didn\u2019t collaborate,\nI received your help more times than I deserved; Prerna Juneja, for your amazing at-\ntention to detail; Vartan Kesiz Abnousi, for all the late-night laughs before deadlines;\nCarlos Bautista Isaza, for softening my workload; the rest of the graduate students:\nBrian, Deepika, Kristen, Neelesh, Saloni, Andy, Amber, Daniel(E), Daniel(D), Danny,\nDash, Emily, Muskan, Priya, Robin, Rodney, Ruipu, Tausif, and Viral; and the un-\ndergraduate team for all your help with my research\n\u2022Mentors and Friends from the HCI community, Aakash Gautam, Lindah Kotut, Jane\nIm, Tianyi Li, Shuo Niu, So Yeon, Sukrit Venkatagiri, and Yan Chen\nv\n\u2022My mentees Donghan, Marx, Jelson, Liling, Stephen, Stephanie, and Hayoung for\nbeing such great mentees\n\u2022My collaborators in and outside VT: Connie Moon Sehat from Credibility Coalition,\nAmy Zhang from MIT, Kelsey Vick, from department of Communication\n\u2022All my friends, classmates, seniors and juniors here at Virginia Tech\n\u2022Finally, all the participants of my studies, from the industry, online and the local\ncommunity\nContents\nList of Figures xvii\nList of T ables xxiii\n1 Introduction 1\n1.1 Problematic Information Online: Misinformation and Filter Bubbles . . . . . 2\n1.2 Affordance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 Dual Process Cognitive Affordances . . . . . . . . . . . . . . . . . . . . . . . 5\n1.4 Designing Affordances against Misinformation and Filter Bubbles . . . . . . 7\n1.5 Designing Automatic Affordances to Distinguish Content Credibility . . . . 8\n1.5.1 NudgeCred: Supporting News Credibility Assessment on SocialMedia\nThrough Nudges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.5.2 TransparencyCue: DesigningTransparencyCuesinOnlineNewsPlat-\nforms to Promote Trust . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.6 Designing Reflective Affordances to Raise Awareness on Filter Bubble . . . . 12\n1.6.1 NewsComp: Facilitating Diverse News Reading through Comparative\nAnnotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n1.6.2 OtherTube: Facilitating Content Discovery and Reflection By Ex-\nchanging YouTube Recommendations with Strangers . . . . . . . . . 14\nvii\n1.7 Thesis Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n1.8 Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n2 Background and Literature Review 18\n2.1 Problematic Information Typology: Misinformation and Filter bubble . . . . 18\n2.2 Dual Process Theories on Information Processing . . . . . . . . . . . . . . . 20\n2.3 Affordances in HCI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.4 Designing Against Problematic Information . . . . . . . . . . . . . . . . . . 23\n2.4.1 Designing for Distinguishing Information Credibility . . . . . . . . . 23\n2.4.2 Designing for Reflection on Algorithmic Filters . . . . . . . . . . . . 25\n3 NudgeCred: Supporting News Credibility Assessment on Social Media\nThrough Nudges 27\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3.2.1 Nudges to Steer Human Behavior . . . . . . . . . . . . . . . . . . . . 31\n3.2.2 Heuristic Cues for Credibility . . . . . . . . . . . . . . . . . . . . . . 31\n3.2.3 Factors Affecting Credibility Perception: Partisanship, Attitude to-\nwards Politics, and Media . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3 Formative Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.4 Designing NudgeCred . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.4.1 Design Guides . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.4.2 Outlining the Design . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.5 Study 1: Evaluating Impact on Perceptions of Credibility in a Controlled\nSetting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n3.5.1 Method (Study 1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n3.5.2 Results (Study 1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n3.6 Study 2: Field Deployment . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n3.6.1 Method (Study 2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.6.2 Results (Study 2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n3.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n3.7.1 RQ1: Effect of Nudges on Credibility . . . . . . . . . . . . . . . . . . 59\n3.7.2 RQ2: Influence of Political Partisanship on Nudge Effects . . . . . . 60\n3.7.3 RQ3: Influence of Political Cynicism and Media Skepticism on Nudge\nEffects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n3.7.4 Opportunities in Designing News Credibility Nudges . . . . . . . . . 62\n3.7.5 Challenges in Designing Nudges with Heuristics . . . . . . . . . . . . 62\n3.8 Implications And Opportunities for Designing Credibility Nudges . . . . . . 63\n3.9 Limitations and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n3.10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n4 T ransparencyCue: Designing T ransparency Cues in Online News Plat-\nforms to Promote T rust 70\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n4.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n4.2.1 Defining Transparency in Journalism . . . . . . . . . . . . . . . . . . 74\n4.2.2 Existing Transparency Practices in Journalism . . . . . . . . . . . . . 75\n4.2.3 Designing for Trust in News Through Information Disclosure . . . . . 75\n4.2.4 Effect of Transparency on Perception of Trust . . . . . . . . . . . . . 77\n4.3 Interviewing News Consumers and Journalists Using a Scenario . . . . . . . 78\n4.3.1 Developing a Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n4.3.2 Recruitment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n4.3.3 Interview Procedure and Analysis . . . . . . . . . . . . . . . . . . . . 84\n4.4 News Consumer Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n4.4.1 RQa: What aspects of journalistic practice do news consumers want\ndisclosed within news articles as transparency cues? . . . . . . . . . . 86\n4.4.2 RQb: What should designers consider in promoting transparency cues\nfor news consumers? . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n4.5 Journalist Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n4.5.1 RQa: What aspects of journalistic practice do journalists want dis-\nclosed within news articles as transparency cues? . . . . . . . . . . . 94\n4.5.2 RQb: What should designers consider in promoting transparency cues\nfor journalists? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n4.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.6.1 Comparing the Perspectives of News Consumers and Journalists . . .100\n4.6.2 Design Suggestions Based on Existing Journalistic Practices . . . . . 102\n4.6.3 Considering Design Issues . . . . . . . . . . . . . . . . . . . . . . . . 107\n4.6.4 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n4.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n5 NewsComp: F acilitating Diverse News Reading through Comparative An-\nnotation 117\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n5.2 Background and Related Works . . . . . . . . . . . . . . . . . . . . . . . . . 121\n5.2.1 The Need for Multiperspective News Consumption . . . . . . . . . . 121\n5.2.2 Barriers to Multiperspective News Consumption Online . . . . . . . 122\n5.2.3 Designing for Information Consumption through Comparison . . . .123\n5.2.4 Annotating Using the Crowd and its Effect . . . . . . . . . . . . . . 124\n5.3 Formative Study For Designing NewsComp : Think-Aloud Interviews . . . . . 125\n5.3.1 Inaccurate Algorithmic Annotation . . . . . . . . . . . . . . . . . . . 125\n5.3.2 Annotating on Google Drawings . . . . . . . . . . . . . . . . . . . . 126\n5.3.3 The NewsComp Interface and How It Works . . . . . . . . . . . . . . 128\n5.4 Evaluation Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n5.4.1 Article Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n5.4.2 Measuring Credibility, Quality, Current Event Knowledge, Media Lit-\neracy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n5.4.3 Recruitment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\n5.4.4 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n5.4.5 Participant Pool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n5.4.6 Gold Standard Generation . . . . . . . . . . . . . . . . . . . . . . . . 137\n5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n5.5.1 RQ1: How well do users perform comparative annotation? . . . . . . 139\n5.5.2 RQ2: Howdoescomparativenewsannotationaffectusers\u2019perceptions\nof credibility and news quality? . . . . . . . . . . . . . . . . . . . . . 146\n5.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n5.6.1 RQ1: Annotation Performance . . . . . . . . . . . . . . . . . . . . . 148\n5.6.2 RQ2: The Effect of Engaging through Annotation . . . . . . . . . . . 150\n5.6.3 Applications of Annotated Data . . . . . . . . . . . . . . . . . . . . . 151\n5.6.4 Merging Articles Into One and Testing Effects . . . . . . . . . . . . . 151\n5.6.5 Implications for Comparative Annotation Task Design . . . . . . . . 152\n5.6.6 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\n5.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n6 OtherT ube: F acilitating Content Discovery and Reflection By Exchanging\nY ouT ube Recommendations with Strangers 155\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\n6.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n6.2.1 Supporting Diverse Content Discovery Online Through Recommen-\ndations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n6.2.2 Social Comparison and Self-Presentation . . . . . . . . . . . . . . . . 159\n6.3 OtherTube: Design and Implementation . . . . . . . . . . . . . . . . . . . . 159\n6.3.1 Creating an Anonymous Profile . . . . . . . . . . . . . . . . . . . . . 160\n6.3.2 Sharing and Removing YouTube Recommendations . . . . . . . . . . 162\n6.3.3 Interacting with Strangers\u2019 Recommendations . . . . . . . . . . . . . 163\n6.4 Study Deployment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n6.4.1 Recruitment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n6.4.2 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\n6.4.3 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n6.4.4 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n6.4.5 Method of Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n6.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\n6.5.1 (Content Discovery) RQ1. How do users discover content by browsing\nrecommendations personalized for strangers? . . . . . . . . . . . . . . 173\n6.5.2 (Interaction and Engagement) RQ2. What factors affect users\u2019 inter-\nactionandengagementwithrecommendationspersonalizedforstrangers? 176\n6.5.3 (Self-Presentation) RQ3. How do users present themselves when shar-\ning recommendations with strangers? . . . . . . . . . . . . . . . . . . 180\n6.5.4 (Self-Reflection) RQ4. How does browsing recommendations person-\nalized for strangers facilitate self-reflection? . . . . . . . . . . . . . . 182\n6.5.5 (Learning about others and the algorithm) RQ4. How does browsing\nrecommendations personalized for strangers facilitate understanding? 185\n6.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\n6.6.1 RQ1 & RQ2: Content Discovery, Interaction, and Engagement . . . .188\n6.6.2 RQ3: \u201cProfile Work\u201d for Self-Presentation to Strangers . . . . . . . . 189\n6.6.3 RQ4: Reflecting on Oneself and Others . . . . . . . . . . . . . . . . . 191\n6.6.4 Design Implications . . . . . . . . . . . . . . . . . . . . . . . . . . . 192\n6.6.5 Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n6.6.6 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n6.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n7 Discussion 195\n7.1 Design Implications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n7.1.1 Affecting Stakeholder Power Dynamics . . . . . . . . . . . . . . . . . 195\n7.1.2 Addressing Adversarial Manipulation . . . . . . . . . . . . . . . . . . 196\n7.1.3 Designing for Long Run . . . . . . . . . . . . . . . . . . . . . . . . . 197\n7.1.4 Choosing Between Cognitive Processes . . . . . . . . . . . . . . . . . 197\n7.2 Cognitive Affordances and Attitude Formation: Moderators . . . . . . . . . 199\n7.3 Applying Affordances in Other Scenarios . . . . . . . . . . . . . . . . . . . . 200\n7.3.1 Against Other Problematic Content . . . . . . . . . . . . . . . . . . 201\n7.3.2 For Certain User Groups . . . . . . . . . . . . . . . . . . . . . . . . . 202\n7.4 Ethical Considerations for Cognitive Affordances . . . . . . . . . . . . . . . 202\n8 Conclusion 204\n8.1 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\nBibliography 206\nAppendices 271\nAppendix A NudgeCred 272\nA.1 Example Tweets Used in Study 1 . . . . . . . . . . . . . . . . . . . . . . . . 272\nA.2 Study 2: Interview Questionnaire . . . . . . . . . . . . . . . . . . . . . . . . 272\nAppendix B NewsComp 275\nB.1 Thinkaloud Interviews Questionnaires . . . . . . . . . . . . . . . . . . . . . 275\nB.2 Articles Used in the Deployment . . . . . . . . . . . . . . . . . . . . . . . . 276\nB.3 Effect of User Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . 277\nB.4 RQ2: Mixed-Effects Models . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\nAppendix C OtherT ube 278\nC.1 Distribution of Users Who Passed Eligibility Criteria and Signed Up . . . . . 278\nC.2 Need for Reflection and Insight Questionnaire . . . . . . . . . . . . . . . . . 278\nC.2.1 Need for Self-Reflection . . . . . . . . . . . . . . . . . . . . . . . . . 278\nC.2.2 Insight . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\nC.3 Semi-Structured Interview Questions . . . . . . . . . . . . . . . . . . . . . . 279\nList of Figures\n1.1 NudgeCred Interface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2 NewsComp system. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.3 OtherTube embedded inside the YouTube homepage. . . . . . . . . . . . . . 14\n3.1 Three types of interventions (marked by blue arrows) currently employed by\nTwitter to tackle misinformation. Tweet (a) with a link to proper authority\nregarding COVID-19, (b) with a warning, and (c) removed. Here, both (a)\nand (b) are examples of nudges. Around the beginning of our work (July\n2018), only (c) was operational. Twitter added others later. . . . . . . . . . 28\n3.2 Our nudge design: [Top] A decision tree shows the intervention logic and\n[Bottom] three nudge designs. (a). The Reliable nudge on a tweet from\nCNN Breaking News without questions in its comment thread. (b). The\nQuestionable nudge is applied to a tweet with questions from Fox News, a\nmainstream media outlet. (c). The Unreliable nudge is activated on a tweet\nfrom 100PercentFedUP.com , an extremely biased, non-mainstream website.\nThe numbers indicate: (1) a change in background, (2) a tooltip message\nshown when hovered over, (3) a button to open a survey questionnaire for\nusers to rate the credibility of the news tweet, and (4) a button to show more\nquestions in the comments. . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.3 Screenshot of how clicking on the survey button would pop open the five-item\ncredibility questionnaire. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\nxvii\n3.4 Distributionofdemographics, politicalideology, politicalcynicism, andmedia\nskepticism in our participants in Study 1. . . . . . . . . . . . . . . . . . . . . 46\n3.5 Shows interaction effects between user groups and nudge types in Study 1.\nThe numbers inside the brackets are the effect sizes, Cohen\u2019s d.. . . . . . . 49\n3.6 Types of nudges based on transparency and mode of thinking. This figure\nemulates Figure 1 by Caraban et al. [70]. This work lies in the bottom-right\nquadrant. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n4.1 Our scenario with three transparency features. Here, feature \u201ca\u201d corresponds\nto source characteristics conveying the expertise of the author; features \u201cb\u201d\nand\u201cc\u201daremessagecharacteristicsshowing, respectively, crucialdetailsabout\nthe event and the reporting style. In feature \u201cc,\u201d reporting style includes\nwhether the article is high or low in summary news lead (SNL) or inverted\npyramid style reporting, the proportions of first- and secondhand accounts,\nthe proportions of direct and indirect quotes, and the number of claims made. 80\n5.1 A Google Drawings board used for think-aloud interviews. Similar to the\nhigh-fidelity interface, two articles are presented side by side here. Users can\nuse all the available tools to link similar statements or highlight dissimilar\nstatements that contain important information which should be included in\nthe other article. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n5.2 NewsComp Interface showcasing features with random annotations.\n1 An-\nnotation instructions in two steps: find and connect similar statements, and\nanswer if a statement with no corresponding, similar statement is important\nto include in the other article.\n2 Toolbar to finalize a connection by provid-\ning a rationale\n3 A solid arrow representing a connection already created\n4\nA dashed arrow indicating that the connection creation tool is active\n5 A list\nof connections including deletion buttons\n6 The importance question in step 2. 129\n5.3 Study design showing the experimental conditions for each of the four par-\nticipant groups. Here, C and T respectively represent control and treatment\ngroups; the number of participants is given in parentheses. Because we used\nfour articles, we had two control groups (C1\u20132) and two treatment groups\n(T1\u20132). Article E XP represents an article about event X from a source with\npolitical leaning P (L for left, R for Right). Articles with X= 1were about\nimmigration, while those with X= 2were about abortion. For example, E 2R\nindicates a news article about abortion from a right-leaning source. The E 1\npair had high contrast, while the E 2pair had low contrast. In the study, we\nrandomized the order/position of the articles for each participant. . . . . . 131\n5.4 Graphs showing the distribution of participant demographics across the treat-\nment and control groups. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n5.5 Distribution of connection making by users. White and red dots respectively\nrepresent the average and experts\u2019 annotation. . . . . . . . . . . . . . . . . . 138\n5.6 Distribution of importance detection by users. White and red dots respec-\ntively represent the average and experts\u2019 annotation. . . . . . . . . . . . . . 139\n5.7 (a & b) User agreements on incorrect and correct annotations. (c & d) We\nfiltered annotations by the number of concurring users to see how annotation\nperformance changes as the threshold moves. Here, for connection making\nand importance detection, the F1 scores peak at five (55%) and six (41%)\nusers, respectively. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\n5.8 Distribution of recall and precision for connection-making and importance\ndetection divided into low/high CEK users (top), and low/high VML users\n(bottom). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n5.9 Annotation counts by coded rationales divided into correct and incorrect an-\nnotations. The numbers over the bars represent the ratio of correct to incor-\nrect annotations within each code. . . . . . . . . . . . . . . . . . . . . . . . 143\n5.10 False positive detection with OLS using the top 50 TF-IDF words in users\u2019 re-\nsponses. Here, we listed only words with significant coefficients. For example,\nwhen users\u2019 mentioned \u201cquote\u201d in a rationale, the annotation was less likely\nto be erroneous. On the other hand, when users mentioned the general nature\nof the event (\u201clawsuit\u201d in this example), the annotation was more likely to be\nerroneous. The model effect sizes ( R2) were 0.34 and 0.22, respectively. . . .144\n5.11 Interaction effects of groups and articles. We only found a marginal interac-\ntion effect (p=0.052) for credibility score on articles regarding immigration\n(c).. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n6.1 How OtherTube works. Each day, OtherTube collects YouTube recommen-\ndations when users access the YouTube homepage. Users have until the end\nof the day to remove items they do not want to share. Users can browse\nrecommendations collected from others as late as the previous day. . . . . . 160\n6.2 OtherTube Options page.\n1 Avatar builder\n2 Shared demographic info\n3\nHow the profile will appear to others. . . . . . . . . . . . . . . . . . . . . . . 161\n6.3 OtherTube Browser action page.\n1 Collected videos with options to remove\nfrom the shared set. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\n6.4 OtherTube embedded inside the YouTube homepage.\n1 Show or hide the\nembedded content.\n2 Browse different strangers or different recommendation\nsessions from the current stranger, and pin the current stranger.\n3 The\nstranger\u2019s profile.\n4 YouTube recommendations collected from this stranger.\n5\nLink to a daily survey.\n6 The user\u2019s own YouTube recommendations, which\nOtherTube collects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\n6.5 Demography of the participants in the study. . . . . . . . . . . . . . . . . . 168\n6.6 Distribution of participants\u2019 need for self-reflection and insight, bucketed for\nease of understanding. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n6.7 Mean with 95% CI of participants\u2019 responses to the daily survey Likert items\nfrom the first and last days of the study. We also performed a Mann-Whitney\nU test comparing responses on the first and last days. In (b), * indicates\np <0.05; in (f), .indicates p <0.10.. . . . . . . . . . . . . . . . . . . . . . 173\nA.1 Sample tweets used in Study 1 without the interventions. The examples\ninclude reliable, questionable and unreliable tweets from left-/center-/right-\nleaning sources. Here, there is a mix of politically contentious (e.g., immi-\ngration, racism and LGBTQ+) and not so contentious issues (e.g., flood and\nnational security). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\nC.1 Demography of the participants who passed screening criteria and signed up\nfor the study. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\nList of T ables\n1.1 Transparency cues based on the suggestions from the journalists and news\nconsumers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.1 Example sources in our mainstream news category. . . . . . . . . . . . . . . 41\n3.2 Example non-mainstream news sources and their categories of reporting in-\naccuracy. The tooltip messages read: \u201cThis source is considered unreliable\nbecause it promotes <InaccuracyType >\u201d.. . . . . . . . . . . . . . . . . . . . 41\n3.3 Example news sources and their political biases. . . . . . . . . . . . . . . . . 43\n3.4 IRR of the five-item questionnaire on credibility in the formative study. . . .45\n3.5 Items used in measuring political cynicism and media skepticism. We used\na five-point Likert scale (Strongly Agree \u2013 Strongly Disagree) with a \u201cDon\u2019t\nknow\u201d option. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.6 Mann-Whitney U test results for Study 1. Here, \u2018n\u2019 denotes the number of\ntweets rated in each condition. Avg. Cred. is the mean of \u2018n\u2019 credibility\nscores; * p <0.05, *** p <0.001.. . . . . . . . . . . . . . . . . . . . . . . . 49\nxxiii\n3.7 Regression models on the credibility score. The base model contains nudge\ntype, user group, control variables and the interaction between user group\nand nudge type. The politics and media model adds users\u2019 political ideology,\nmedia skepticism and political cynicism variables to the base model. The\n3-way interaction model further includes the interactions of nudge type, user\ngroup and other variables with significant main effects in the politics and\nmedia model (Gender, Interest in the Tweet, Ideology and Media Skepticism). 50\n4.1 Demography of our journalist pool. \u201cJourn.\u201d here stands for \u201cjournalist.\u201d . .82\n4.2 Professional background of our journalist pool. In the network column, \u201cfree-\nlance\u201d indicates that the journalist is not associated with an organization.\nNote that we aggregated the roles of journalists and their associations to\nnews networks and audiences to ensure anonymity, as required by the IRB.\nKnowledge of network affiliation and role would have been enough to reveal\nthe identities of several participants. . . . . . . . . . . . . . . . . . . . . . . 82\n4.3 Demography of our news consumer pool. We asked demographic questions\nat the beginning of each interview (see Appendix A for the list of questions).\nNote that some of the participants chose not to specify a political affiliation.\n* This participant was a former journalist. . . . . . . . . . . . . . . . . . . . 83\n4.4 Theme summary split by when each theme emerged\u2014before or after show-\ning the scenario to the participants. Note that while responses aligned with\ncertain themes emerged both before and after scenario exposure, the themes\u2019\npositions in this table are dictated by when they emerged most commonly. .86\n4.5 Design suggestions summarized according to two criteria: implementation\nrequirements and consensus or disagreement among participants. Here, the\nrequirements of access to (and knowledge of) an organization\u2019s resources (and\nprotocols), such as internal/external databases of prior corrections, conflicts\nof interest, and behind-the-scenes materials could make it difficult for a third\nparty to implement the design cues. The two right-most column suggest both\nwithin-group and between-group disagreement among our participants. As\nan example, the Behind-the-scenes Cue, discussed in section 4.6.2, could be\nhard to implement without access to organizations\u2019 materials. Some of the\njournalists disagreed as to the feasibility of disclosing portions of this informa-\ntion (e.g., televising meetings). Another example is the Author Expertise Cue\n(section 4.6.2) discussed by both groups with some disagreement from jour-\nnalists due to its (e.g., years in reporting) negative impact on new journalists,\nwhich could be hard to implement due to the required access to organizations\u2019\nprotocols. Additionally, we provided sample questions designers could use to\nbuild transparency cues. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\n5.1 Questionnairesusedinthestudy. Credibilityandqualityquestionswereasked\nafter reading or annotating. (I) means these items were inverted for analysis.\nThe correct responses appear in boldface. The CEK questionnaire contains\nmultiple-choice questions, while the VML, credibility, and quality questions\nare 5-point Likert items. The VML and CEK items were presented in the\npre-survey. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\n5.2 Coding scheme for annotation rationales. . . . . . . . . . . . . . . . . . . . . 142\n5.3 Themes in users\u2019 responses to a question asking what they noticed about\nthe two articles overall. Note that while an example response may belong to\nmultiple themes, only the portion relevant to the listed theme is presented in\nbold.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\n6.1 Daily Survey Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n6.2 Mixed effects negative binomial model for daily click count on Another Per-\nsona in Figure 6.4. In this model, user is a random-effects variable. User de-\nmography, their browsing habits, their need for self-reflection, the day when\nthe clicks were counted, and the number of unique stranger data sets avail-\nable to browse on OtherTube on the day when the clicks were counted are\nfixed-effects variables. The estimated negative binomial regression coefficient\n\u03b2is the difference in the logs of expected counts of the response variable due\nto a one-unit change in the predictor variable. . . . . . . . . . . . . . . . . . 176\nB.1 Linear models of recall and precision for connection-making and importance\ndetection with user characteristics as predictors. . . . . . . . . . . . . . . . . 275\nB.2 Mixed-effects regression on quality and credibility score using the interaction\nof experimental condition and articles. . . . . . . . . . . . . . . . . . . . . . 276\nChapter 1\nIntroduction\nOver the last couple of decades, online information feeds like the social feed on Facebook\nor Twitter, the newsfeed on Google News or CNN, and recommendation feed like YouTube\nor Reddit have become the place where users go every day and browse information served\nto them. Each of these feeds is generated by the algorithms based on different proper-\nties [164]. For example, Facebook feeds take into account the virtual network the user has\nbuilt with their friends, family, acquaintances, other users, and other interests. Research\nshows that YouTube algorithm utilizes users\u2019 interests and watch history to generate rec-\nommendations [ 99]. News sites like CNN or Google News are also ramping up their use\nof algorithms on their feeds to provide more personalized experience to their readers [ 167].\nOverall, these online information feeds play an important role in shaping public opinion.\nWith more and more people using online feeds for daily information consumption, a seem-\ningly unimportant misleading content can be spread widely and have a significant impact.\nFor example, when social feeds allow each individual to act as information creators, many\nnamed and unnamed sources with dubious credibility can easily flood the information space\nwith misinformation [ 505]. Or, when the recommendation feed generated by YouTube heav-\nily applies personalization, it creates an algorithmic filter where users are often exposed to\nlimited viewpoints [ 341]. Due to the limited capacity of the users to attend to these is-\nsues on their feeds, design interventions are required to support users in online information\nconsumption. In this dissertation proposal, I apply the theory of dual process information\n1\nconsumption to develop design guides that can help combat these rising issues in online news\nfeeds.\n1.1 Problematic Information Online: Misinformation\nand Filter Bubbles\nAtypicaluserparsesthroughacomplexwebofinformationonlineeveryday. Theyencounter\ninformation on social media, news platforms, entertainment platforms, and many others.\nUsers go online for various purposes including out of curiosity, to learn, to get entertained\nand such. However, users have a limited bandwidth to pay attention to all the complexities\nand problematic content on online news feeds where they need external assistance. In online\nsetting, various types of problematic content exist, such as, misinformation, hate speech,\nconspiracy theories, filter bubble, and algorithmic injustice. I further discuss the definition\nof problematic content and its typology in more details in Section 2.1. Among all types of\nproblematic content, misinformation and filter bubbles are two major concerns that I aim\nto address in this thesis. Below, I will first introduce the advent of each of these issues.\nNow, socio-technical systems and micro-blogging platforms like Facebook, Twitter, and\nYouTube on the web allow a direct path from the producers (e.g., journalists, content\ncreators, and influencers) to the consumers. Often, information feed generated by social\nalgorithms on these platforms comes from a vast number of sources. Unlike the past, when\nmuch of the curation of information were led by mainstream news outlets for TV media, in-\nformation from any point of the internet can flow into these feeds, passing through very few\nfilters. As the difference between producer and consumer of information gets more blurry\nday by day, it changes the way users become informed, debate, and form their opinions.\nSuch an information environment can foster confusion, and encourage speculation, rumors,\nand mistrust. We see increasing evidence of such mistrust on various public issues every\nday. For example, Covid-19 related misinformation has been so widespread, it causes con-\nfusion for many people [ 495]. In some cases, increasing exposure to unsubstantiated rumors\nmay become more mainstream, like QAnon conspiracy [ 391]. Therefore, there has been\nan increase in public scrutiny on social platforms and their role in filtering and advancing\nharmful content online. While platforms like Facebook and Twitter put significant effort\ninto stopping and spreading such misinformation through algorithmic filters, technological\nsolutions often have a limited effect on the overall spread of misinformation. Most often,\nmisinformation spread before platforms can identify whether something is misinformative\nbecause algorithms are not sophisticated enough to identify human-generated problematic\ninformation. In many cases, these algorithms catch up, only after misinformation has al-\nready spread. Furthermore, sources of misinformation also adapt as technological solutions\ndesigned against them improve at identifying them. Overall, these preventive measures built\ninto algorithms have their limitations. On top of that, platforms\u2019 efforts to curb misinforma-\ntion often get scrutinized by the public due to the concern that it threatens the circulation\nof free speech [ 108].\nWith the Internet and social media, a common belief is that it is supposed to increase the\nnumber of available viewpoints and perspectives available, leading to a very diverse pool of\ninformation However, some have also argued that it could also lead to people joining groups\nof their choice who share their world view and cut themselves off from any information\nthat might challenge their beliefs [ 439]. Indeed, some research suggest that personalization\nalgorithms used by online platforms such as Facebook and Google show users perspectives\naligned with what they prefer and filters out contents with viewpoints they differ from [ 341].\nThese personalization algorithms typically prioritize and filter information based on a user\u2019s\nprior interaction with the system on similar interests [ 113], because it helps platforms\u2019 goal\nto improve engagement [ 151]. This process could lead users to receive biased information.\nIn particular, for political information, it might lead to the situation where the user never\nsees contrasting or opposing viewpoints on a political or moral issue. Pariser et. al. termed\nthis situation as a \u201cfilter bubble\u201d where users will not even know what they are missing\nin their feeds [ 341]. Filter bubbles have been widely criticized for their negative effect on\nusers\u2019 autonomy of choices. In response, researchers are developing algorithms to combat\nthose bubbles by promoting diversity [ 200,491]. However, these developments are often at\nodds with platforms policy for increasing engagement [ 15]. Overall, both the problem of\nmisinformation and filter bubbles are pervasive problems in online news feeds and hard to\nresolve by simply the algorithms.\n1.2 Affordance\nTo address this concern, we need to help users recognize problematic content. In this thesis,\nI use the concept of affordance from HCI to create designs that enable people to recognize\ncontent. TheideaofaffordanceswasfirstestablishedbyGibsonin\u201cTheEcologicalApproach\nto Visual Perception\u201d, based on his observation on human interactions with objects in the\nphysical world [ 160]. To Gibson, \u201caffordances of the environment are what it offers the\nanimal, what it provides or furnishes, either for good or ill\u201d. Gibson exemplifies this with\nan example of surface of the earth and what it affords, \u201cIf a terrestrial surface is nearly\nhorizontal (instead of slanted), nearly flat (instead of convex or concave), and sufficiently\nextended(relativetothesizeoftheanimal)andifitssubstanceisrigid(relativetotheweight\nof the animal), then the surface affords support.\u201d Gibson\u2019s \u201cecological\u201d approach means that\nto understand either the properties of the surface or the perception of the animal, one\nmust also consider the environment created by the relationship between the two. Norman\ntook Gibson\u2019s idea to the field of human-computer interaction and the research of user\nexperience [ 159]. Where Gibson was concerned with the theories of human perception and\ninteractions in nature, Norman\u2019s focus was on the creation and use of the affordances in HCI\ndesign. So, in The Design of Everyday Things , when Norman popularized the use of the\nword \u201caffordance\u201d, he was describing a characteristic of a designed product that informs the\nuser of a function [ 329]. However, Norman\u2019s early work did explore the functionality and use\nof physical objects, including doors, switches, keyboards, and clocks. But as these methods\nwere extended to digital interfaces, the focus remained on optimizing for interface usability.\n1.3 Dual Process Cognitive Affordances\nWhile Norman popularized the concept of affordances, there has been some debate around\nit, including Norman saying some of his readers misuse the term in HCI. Norman says that\nthe unqualified term affordance refers to real affordance, which is about the physical char-\nacteristics of a device or interface that allow its operation, whereas many HCI and usability\nresearchers use it without qualification to refer to perceived affordance, which is about char-\nacteristics in the appearance of a device that give clues for its proper operation [ 331]. To\naddress this concern, Hartson came up with four types of affordances based on the role\nan affordance plays: cognitive, physical, sensory, and functional [ 191]. To him, Norman\u2019s\nperceived affordance was actually cognitive affordance. As Hartson defines, \u201cA cognitive af-\nfordance is a design feature that helps, aids, supports, facilitates, or enables thinking and/or\nknowing about something. As a simple example, clear and precise words in a button label\ncould be a cognitive affordance enabling users to understand the meaning of the button in\nterms of the functionality behind the button and the consequences of clicking on it\u201d. Now,\nto help users recognize problematic content, I take this concept of cognitive affordances that\nenable thinking about something and extend it by looking into the underlying process that\ngoes during such thinking.\nThis is where Dual Process Theories of Mind comes in. Cognitive and social psychologists\nhave argued about the idea of dual process cognition over several decades based on their\nwork on thinking, reasoning, decision-making, and social judgment [ 129]. They argue that\nthere are two separate cognitive systems underlying thinking and reasoning. Throughout\nthis work, we will be referring to these two processes as automatic and reflective modes of\ncognition. Automatic process is universally shared by many animals and is the process often\nused during information consumption. This process allows people to use mental shortcuts\nas heuristics to quickly make judgments about a piece of information. On the other hand,\nreflectiveprocess isdeliberate and requiresimagining newscenarios to analyzebefore making\na judgment about a piece of information. A brief discussion on the evolution of these theories\nis further discussed in the Related Work section. To illustrate, let\u2019s take the example of\na user coming across a piece of information and its source. When consuming this piece\nof information, the reader may use the appearance of the source as a shortcut to judge\nwhether the piece of information is credible or not. Or, before judging the credibility of\na piece of information, they might consider their existing knowledge around the topic of\nthat information and reflect on the possibility of the truthfulness of the information. To\nassist users during information processing, we can design new affordances that enable the\nuse of either or both of these processes. I will term these together as Dual Process Cognitive\nAffordances , where Automatic Cognitive Affordance enables using automatic thinking and\nReflective Cognitive Affordance enables using reflective thinking. In short, I will call these\nAutomatic Affordance and Reflective Affordance throughout the text.\n1.4 Designing Affordances against Misinformation and\nFilter Bubbles\nIn this work, I use the idea of designing dual process cognitive affordances against the\nonline problematic information domain. To illustrate this idea, let\u2019s take the example of the\nstructure of a social media platform, its existing affordances, and how we can reimagine new\ncognitiveaffordances. Afundamentalaspectofsuchplatformsisthesocialinteractionfeature\nwhich allows users to interact in various ways, one-to-one, one-to-many, or many-to-many\nfashion. Allowing users to create posts and allowing others to leave comments in response to\na post is an example of a many-to-many interaction feature. Generally, this comment section\nmay not have been built with any idea of perceiving the credibility of the information in\na post. However, what I argue here is that we can augment this interaction feature with\nnew design affordances that will enable users to judge the credibility of the information in\na better manner. For example, an algorithm can be devised to analyze the comments to\ncheck whether these comments identify the limitations of the piece of information conveyed\nin the post. If this analysis is presented to the users, it will afford, that is, enable a user\nto use the analysis as a basis for making (not necessarily) quick judgments. Now this is an\nexample of designing automatic affordances. We can also augment this interaction feature\nwith a reflective affordance design. Consider the example of someone posting a news article\nfrom a certain news source. Now, let\u2019s imagine a design affordance that allows readers to\nsee how a different news source frame the same story with a different title. This affordance\ncould enable users to compare and make a reflective judgment of the credibility of the news\nitem. Notice that the purpose of devising affordances in the context of designing against\nproblematic information is goal centric, instead of usability centric, that is, unlike Norman\u2019s\ninitial intent. This is where I diverge a little from Norman when talking about affordances.\nTo summarize, the goal of this thesis is to present how we can help users become aware of\nproblematic information on their online information feed through meaningful design adop-\ntion. To do that, I marry the dual-process theories from social psychology with the idea of\naffordance design from Human-Computer Interaction (HCI) to develop a systemic approach\nto designing dual process cognitive affordances for assisting users in information consump-\ntion online. Below, I outline how I designed four systems using these affordances against\nmisinformation and filter bubbles. These four systems are asked based on four major online\nscenarios where users typically face the problem of misinformation and filter bubbles. Two of\nthese scenarios are related to misinformation and designing automatic affordances against it,\nwhile the other two are related to filter bubbles and designing reflective affordances against\nit.\n1.5 Designing Automatic Affordances to Distinguish\nContent Credibility\nAs mentioned earlier, automatic cognitive routes are effortless where people typically use\nshortcuts (e.g., attractiveness of a source) based on past experiences. Some communica-\ntion theorists have suggested that design affordances online spaces can help users apply such\nshortcuts or heuristics (for automatic processing) to distinguish misinformative content from\nmore credible ones by acting like a cue [ 435]. Therefore, in another word, automatic affor-\ndances can also be called design cues. Throughout this work, I will use the terms automatic\naffordance and design cues interchangeably. Now, to help users distinguish misinformative\ncontent using automatic processing, I explore two questions:\n(RQA)How can we use design automatic affordance to help users distinguish reliable and\nunreliable information sources?\n(RQB)How can we design affordances to help users distinguish degrees of trustworthiness\namong reliable information sources?\nI answer these research questions through two studies described below. In the first study,\ncalled NudgeCred, I designed affordances to help users distinguish reliable content from\nmainstream news sources and unreliable information from fringe misinformative sources.\nIn the second study, I utilize the concept of transparency as a means to design automatic\naffordances to separate different degrees of trustworthiness within reliable mainstream news\nsources.\n1.5.1 NudgeCred: Supporting News Credibility Assessment on\nSocialMedia Through Nudges\n(a)\nDoes \nthe \ntwitter \naccount \nor \nthe \nembedded \nurl \nbelong \nto \nmainstream \nor \nnon-mainstream \nnews \nlist? \nIs \nthere \na \nquestion \nin \nthe \ntweet \nreplies?\nNo\nYes\nIntervention \nLogic\nDesign\n(b)\n(c)\nNon-mainstream\nMainstream\nFigure 1.1: NudgeCred Interface.\nWhen it comes to misinformation on online news feeds, social media feeds are the ones with\nthe most impact [ 9]. Therefore, in designing automatic affordances or cues, I address the\nfirst research question on helping users distinguish misinformation from credible information\nthrough a system called NudgeCred. Here, I apply communication theories on heuristics that\npeople often use to automatically judge content credibility to design new cues to nudgeusers\ninto better credibility evaluation. Specifically, I use two heuristics in this design: authority\nheuristic and bandwagon heuristics. Authority heuristic allows users to differentiate news\ncontent from mainstream sources and non-mainstream sources. Bandwagon heuristic further\nhelps users to differentiate news stories with questionable or controversial or ambiguous\nreporting from news stories without such questions. Figure 1.1summarizes how this design\nworks. To examine its effectiveness, I conducted two studies\u2014a controlled experiment in\nSection3.5and an in-the-wild experiment in Section 3.6\u2014by recruiting the US nationally\nrepresentative population sample. My analysis reveals significant evidence that design cues\nbased on heuristics in NudgeCred can help users distinguish content credibility. This design\nis extensible through the use of other heuristics. However, in the second study, participants\nalso showed concern that design cues built around bandwagon heuristics, i.e., relying on the\nannotation from other users or the crowd, can be problematic in practice and we continue\non this concern in the next work. Chapter 3reveals the details of this work.\n1.5.2 T ransparencyCue: Designing T ransparency Cues in Online\nNews Platforms to Promote T rust\nTo answer our second research question, I examine what values stakeholders desire when\njudging between reliable news sources. For news platforms, like cnn.com or Google News ,\nsuch values could be based on journalistic values or news consumers\u2019 human values. In\nthis work, I look into how to adopt one such value shared by both groups, i.e, the value\nof transparency in news reports through affordance design. To incorporate it in our design\nI conducted an interview study. In this study, I interviewed both news consumers and\nT ransparency\nCues (Section)Example Questions Implementation\nRequirementsSuggested\nByDisagreed\nBy\nNewsworthiness\nCues (6.2.1)Which news values does this report represent (e.g.,\nconflict, sensationalism, eliteness and entertainment)?\nTo what degree?Requires access to\norganizations\u2019 news valuesNews\nconsumers-\nFairness Cues\n(6.2.2)Who are the named parties in this article? To what\ndegree does this report represent each political\na\ufb00iliation (left/center/right)? Did the reporter receive\ncomments from all contacted parties?Requires knowledge of\norganizations\u2019 procedures\nfor getting commentsNews\nconsumers-\nPresence of\nEvidence Cue\n(6.2.3)Does the report cite an authoritative source of\nevidence? Is there ambiguity in how sources are\nrepresented?Requires access to o\ufb00icial\nsource materials (might\nbe openly available)Both\ngroups-\nAnonymous\nSource Cue\n(6.2.4)Does this report contain anonymously sourced\ninformation? Why was the information not available\nwithout anonymity? How did the reporter verify the\ninformation? How acceptable is the verification\nmaterial?Requires knowledge of\norganizations\u2019 procedures\nfor anonymous sourcingNews\nconsumersSome\njournalists\nFact-check Cue\n(6.2.5)Has any internal/external entity fact-checked this\ninformation? Who fact-checked it (with links)?Requires access to\ninternal/external fact\ncheckers and their\nproceduresBoth\ngroups-\nCorrection Cue\n(6.2.5)Have there been any corrections to this report? Why?\nHow were the corrections framed?Requires knowledge of\norganizations\u2019 correction\nprotocolsBoth\ngroupsSome\njournalists\nAuthor\nExpertise Cue\n(6.2.6)What skills does the reporter have? What is the\nreporter\u2019s educational background? How objective has\nthe reporter been in past reports?Requires comprehensive\nknowledge of journalists\u2019\nreporting historyBoth\ngroupsSome\njournalists\nBehind-the-\nscenes Cue\n(6.2.7)Does this report contain any behind-the-scenes\ndetails? How did the reporting process occur over\ntime?Requires access to\nbehind-the-scenes\nmaterials for a reportJournalists Some\njournalists\nConflict of\nInterest Cue\n(6.2.8)Does this report cover any entity with which the\nreporter/organization has a conflict of interest? How\ndoes the reporter/organization deal with such\nconflicts?Requires access to news\norganizations\u2019/journalists\u2019\nfinancial informationJournalists -\nTable 1.1: Transparency cues based on the suggestions from the journalists and news con-\nsumers.\njournalists to understand how transparency can be realized on news platforms to promote\ntheir perception of the trustworthiness of news items there. My analysis revealed a set of\ntransparency-centered cues, that is, automatic affordances and their design considerations\nincluding the cases where stakeholders\u2019 have conflicting desires. A summary of this result\nis show in Table 1.1. Similar, to the value of transparency, other journalistic values (such\nas, accountability or journalistic freedom) can be considered in future works. I present this\nwork in chapter 4.\n1.6 Designing Reflective Affordances to Raise A ware-\nness on Filter Bubble\nCompared to automatic processing, people use reflective or a slow and effortful route for\nanalytical tasks. In HCI research, a large number of works explore the space for design\nfor reflection in many application areas, such as behavioral change, personal informatics,\nand mental health [ 411,421]. Extending this approach to combat filter bubbles, I examine\nthe design of reflective affordances that may allow users to apply this mode of thinking to\nunderstand their filter bubbles and discover content outside such bubbles. Here, I ask:\n(RQC)How can we design reflective affordances to facilitate news reading outside their filter\nbubbles?\n(RQD)How can we design reflective affordances to facilitate content discovery outside their\ninterest filter imposed by recommender systems?\nFor this purpose, I built two systems to help answer these two questions, outlined below.\nFor RQC, I designed a system called NewsComp that enables reflection by seeing the side-\nby-side contrast of news stories from opposing-leaning sources. To address RQD, I designed\nOtherTube which enables content discovery outside of users\u2019 existing interests on YouTube\nby swapping recommendation feed with a stranger.\n1.6.1 NewsComp: F acilitating Diverse News Reading through Com-\nparative Annotation\nIn a news environment, a vast majority of news consumers tend to consume news stories from\ntheir preferred source, which typically puts a particular political spin on most news stories.\nFigure 1.2: NewsComp system.\nThus, news consumers often see one-sided views on news stories. How can we address\nthis challenge of informing readers of multiple perspectives on any news event? For this\npurpose, I built NewsComp, a system affording users to contrast news stories from multiple\nperspectives by showing a side-by-side view of news stories from opposing-leaning sources.\nFigure1.2shows the interface. This interface enables readers to engage with opposing\nperspectives by allowing them to annotate both similarities and dissimilarities between two\nstories. Using this interface, I conducted a study to examine whether using this system\nimpacted users\u2019 attitudes toward news articles. Results reveal that between high-contrast\nnews articles, NewsComp affects users\u2019 credibility perception. Furthermore, the annotation\nactivity also led users to recognize various differences across articles, such as how journalists\nplace information in an article differently, how different news articles emphasize different\nviewpoints, and how different news articles use various linguistic markers to attract their\naudience. I have explained the details of this work in chapter 5.\n1.6.2 OtherT ube: F acilitating Content Discovery and Reflection\nBy Exchanging Y ouT ube Recommendations with Strangers\nRecXchange: 1\n2 3\n4\n5\n6\nFigure 1.3: OtherTube embedded inside the YouTube homepage.\nTo help user understand their filter bubbles on non-news setting like for YouTube, I designed\na system called OtherTube. YouTube\u2019s recommender algorithm primarily takes users\u2019 prior\nengagement into account to provide recommendations [ 99]. To help user realize algorithmic\nfilters on their interests, OtherTube allows users to exchange their YouTube recommenda-\ntions with strangers. To help further reflect, OtherTube allows users to share their persona\nwith demographic details and their interests with other users. Figure 1.3shows the interface.\nI have conducted a study to examine what users realize about their own YouTube recom-\nmendations and what type of content they discover by seeing others\u2019 recommendations by\nusing this system. Our results show promising results. We find that users reflect on their\nown interests by comparing against others\u2019 interests when using OtherTube. I have further\nexplained this system in chapter 6.\n1.7 Thesis Contributions\nThe focus of this dissertation is to examine how to combat problematic information online by\nempoweringusersthroughthemeansofdesign. Tothatend,Imakethreemaincontributions:\n\u2022First, I introduce the concept of dual process cognitive affordances, consisting of au-\ntomatic and reflective affordances, by marrying the idea of cognitive affordances with\ndual process theories on cognition\n\u2022Second, using the concept of automatic and reflective affordance, I introduce four novel\nsystems I built called NudgeCred, TransparencyCue, NewsComp, and OtherTube\n\u2022Third, Itesttheeffectivenessofthesesystemsagainsttwotypesofproblematiccontent,\nmisinformation and filter bubbles\nThese contributions inform researchers, design practitioners, platforms and the users about\nthe application of dual process cognitive affordances in the problematic information setting\nin online space.\n1.8 Thesis Outline\nIn Chapter 2, I provide relevant background around the dual-process theory and existing\napproaches to address misinformation and filter bubbles. Here, I present how this work fits\ninto the existing literature.\nIn Chapter 3-6, I present the systems and studies I conducted to answer our four research\nquestions.\n\u2022Chapter 3introduces NudgeCred system with design cues for using two heuristics\nas automatic affordance. It also includes two studies to answer particular research\nquestions catered to the design. I present the analysis of those studies and discuss\nfuture research directions.\n\u2022Chapter 4shows the details of the interview study I conducted to find transparency\nfeatures to design automatic affordance including the recruitment of a diverse pool of\nnews consumers and journalists, the analysis of responses, and a comparison between\nthe two groups\u2019 responses.\n\u2022Chapter 5shows our design of NewsComp to contrast and reflect on opposing news\nsources. Here, I present the deployment of the system to examine the effectiveness of\nthe design and the performance of the users in comparative annotation tasks.\n\u2022Chapter 6explains our design of OtherTube by exchanging recommendation feed be-\ntween strangers to reflect on recommendation filter. This chapter explains how I\nconducted a 10-day study with this design and how the use of the tool impacted users\u2019\nperception of their YouTube recommendation bubble.\nChapter 7presents the design implications from the four affordances I designed, the po-\ntential opportunity to apply the design in different scenarios, and a discussion on ethical\nconsiderations for affordance design. In chapter 8, I conclude by proposing future research\non design-based approaches to tackle problems in online news feeds.\nChapter 2\nBackground and Literature Review\nThis thesis presents a set of systems built around the concept of dual-process cognitive affor-\ndances to address the problematic information, such as, misinformation and filter bubbles.\nBelow, I provide background on problematic information, dual process theories, and HCI\nresearch on designing affordances. Then I present contemporary works on approaches to\naddress these problems and how our work fits into those works.\n2.1 Problematic Information Typology: Misinforma-\ntion and Filter bubble\nProblematic information has been used in various context online, especially in the last seven\nyears, i.e., 2016 US Presidential Election [ 285]. Researchers have used the term problematic\ninformation in both broad and limited context. For example, some use it only regarding\nmisinformation and disinformation [ 210]. However, in this work, I will use it to cover \u201ca\nbroad range of information created by a human or non-human entity that can cause any\ntype of harm, intentional or unintentional towards an individual or the society in general\u201d.\nFromhuman-generatedside, thisdefinitionincludesmisinformation, disinformation, conspir-\nacy, propaganda, hate speech, extremism, and others. This definition include problematic\nmachine behavior such as filter bubbles, echo chamber, discrimination, and behavior modifi-\n18\ncation through psychological manipulation (e.g., addiction and radicalization) from algorith-\nmic biases, misclassification and misuse [ 33,413]. Since this thesis focuses on misinformation\nand filter bubbles, below I will focus on these two.\nWithin the academic investigation, various terms and definition have been used to identify\nmisinformation. Misinformation in general has been described as a new types of information\ndisorder connected to infostorm or infoglut or information overload [ 17,185,245]. Early\nscholarships tended to narrower definition focusing on particular topics of misinformation,\nsuch as misleading health information, governmentally organised propaganda or Wikipedia\nhoaxes [ 131,249,485]. Some scholars would distinguish between misinformation and dis-\ninformation by the intent of the producer [ 249], while some may use it interchangbly [ 138].\nThere are two primary types of distinction scholar make, one group consider disinforma-\ntion as a subset of misinformation, with the intentional spreading [ 466]. The other group\nconsider disinformation as the opposite of misinformation, i.e., disinformation is intentional\nand misinformation being non-intentional production and spread [ 133]. However, in this\nwork, I will consider the core premise of all these definitions, i.e., misinformation is \u201cfalse or\nmisleading information\u201d, independent of the intent. The reason behind this choice is that in\nonline space the intention can frequently vary. Here, one person may share a piece of false\ninformation as a joke where the next person re-sharing the same piece of information can\ndo it with an intent to mislead their peer. Furthermore, this definition is more useful in the\ncontext of designing intervention where the design practitioner do not need to consult the\nsource to determine whether an intervention is needed or not.\nThe term filter bubble was coined by Pariser et. al. in his book titled \u201cFilter Bubble\u201d [ 341].\nPariser calls it, \u201cA world constructed from the familiar is a world in which there\u2019s nothing\nto learn ... (since there is) invisible autopropaganda, indoctrinating us with our own ideas\u201d.\nA predecessor of this concept can be found in the idea of cyberbalkanization, stemming\nfrom the limits created by bounded rationality [ 62]. As Alstyne et. al. put it, \u201c[on the\ninternet] Regardless of how fast data scrolls across the screen, absorption is bounded. In the\nlimit, people must choose some information contacts over others. Filters, even sophisticated\nelectronic filters, must be selective in order to provide value. Thus, certain contacts, ideas,\nor both, will be screened out\u201d [ 470]. Over the years, online platforms have developed better\nalgorithms to personalize and to selectively curate information shown to a user based on\ntheir their location, their interaction behavior, and history [ 57]. Consequently, users become\nisolated from information that disagrees with their own viewpoints, effectively being trapped\nin their own cultural or ideological bubbles [ 341]. Here, algorithms continuously learn from\nthe feedback of the user, termed as feedback loop, which gate keeps opposing view, causing\nfilter bubble [ 51]. Though impact of this problem is often considered in the context of\npolitical ideological isolation, both cyberbalkanization and filter bubble defines isolation in\nterms of any interest internet users may have. In this work, we subscribe to this broader\ndefinition, instead of the political ideological isolation.\n2.2 Dual Process Theories on Information Processing\nDual Process theories were developed over multiple decades by cognitive psychologist. The\ntwo processes that occur during information processing has been referred by different names\nincluding automatic and controlled [ 414], Implicit and Explicit [ 378], heuristics and system-\natic, System 1 and System 2 [ 428], and reflexive and reflective [ 268]. The automatic mode\nof cognition is generally considered as more universal cognition shared between humans and\nany other animals [ 128]. It includes instinctive behaviors that are innately programmed or\nlearned over through evolution. Dual-process theorists generally agree that automatic pro-\ncesses are rapid and parallel in nature, although there are deviations that consider these\nprocesses as sequential.\nDual-process theorists suggest that the reflective mode of cognition has evolved much more\nrecently [ 128]. This mode of thinking is slow and makes use of the central working mem-\nory. The psychology of memory systems has a large focus on this conceptualization [ 153].\nDespite its limited capacity and slow speed of operation, reflective mode permits a person\nto use hypothetical thinking that cannot be achieved by the automatic mode of cognition.\nHere, hypothetical thinking refers to constructing mental models or simulations of future\npossibilities. While we may oftentimes decide our actions based on past experience, doing\nwhat has worked well in the past, reflective thinking allows us to consider new avenues.\nIn social psychology, dual-process theories of social cognition emerged in the 1980s [ 80]. In\nthis domain, research particularly focuses on the automatic and unconscious processing of\nsocial information in such domains as stereotyping, and attitude change [ 142]. They posit\nthatcuesinapersuasioncontextcanleadtheusertomakesomeassociationsbetweenthecue\nand the information [ 435]. Petty and Cacioppo introduced the elaboration likelihood model\n(ELM) which suggests that such cues can result in an attitude formation through peripheral\ninformation processing [ 355]. Another well-known model, the heuristic-systematic model\n(HSM)makesuse of dualprocesses where systematic processing refers tothe use of analytical\nconsiderationonthejudgment-relevantinformation, andheuristicprocessingreliesonmental\nshortcuts to judgment rules, i.e., heuristics that are already stored in memory [ 80]. For\nexample, an attractive source in an advertisement can promote a positive while a superficial\nassociation between the source and the product. For another, long information can trigger\nthe \u201clength implies strength\u201d heuristic [ 435], leading to the conclusion that the message\nis credible without taking into consideration what the message says. This is contrasted\nwith the more cognitively effortful information processing. In such a case, a user may pay\nsignificant attention to evaluating message content rather than peripheral characteristics\nlike the attractiveness of the source or font color. Overall, dual process theories provide\nthe basis that if design patterns can trigger these cognitive routes in a particular fashion it\ncan help users consume information. In particular, in this thesis, we carefully craft design\ncues to trigger automatic cognition that helps users associate content credibility. To trigger\na reflective mode of thinking, we propose design affordances that allow contrast between\ncontent within and outside of the filter bubble.\n2.3 Affordances in HCI\nAs mentioned earlier, affordances originally proposed by Gibson, was introduced to HCI by\nNorman in the late 1980s [ 161,330]. Over the years, this idea became a key concept in HCI.\nInitially, Norman described affordances as \u201cthe perceived or actual properties of the thing,\nprimarily those fundamental properties that determine just how the thing could possibly\nbe used\u201d [ 330]. To Norman, \u201cWhen affordances are taken advantage of, the user knows\nwhat to do just by looking: no picture, label, or instruction is required.\u201d [ 330]. Scholar have\nidentified various properties and taxonomy of affordances. Scholars identified three types of\naffordances depending on the relationship between affordances and perceptual information:\nvisible, hidden, and false affordances [ 154]. Affordance theory has also been applied in inter-\naction design by categorizing affordances by levels of cognitive control [ 471] McGrenere et.\nal. argued for separating affordances from their perception, and Norman concurs [ 293,327].\nSome argued for mediated action perspective on affordances, where technology affordances\nare \u201cpossibilities for human action mediated by cultural means conceived as a relational\nproperty of a three-way interaction between the person, mediational means, and environ-\nment\u201d[219]. Hartsoncameupwiththeideaofcognitiveaffordancetodistinguishaffordances\nthat help certain cognitive function from Norman\u2019s real affordances, or as he calls it physical\naffordances [ 191]. In this work, I build on top of this concept proposed by Hartson et. al.\nby connecting cognitive affordances with Dual Process theories on cognition.\nDespite the introduction, Norman did not provide any recipe for how to design affordances\nin his seminal work [ 330]. Though, Norman did recommended some practices in design\nof affordance, such as, considering cultural constraints, conventions, using metaphors and\ncoherent conceptual model [ 328]. Later, scholars have introduced some processes for de-\nsigning affordances, such as, considering artifact-user interaction in affordance design [ 280].\nAffordance-based approach has been utilized in various aspects of HCI research, including\nproduct development, interaction design, usability, robotic agent design[ 155,288,498]. In\nonline setting, affordance has also been used various context, such as, social media[ 477]. In\nthis work, I apply affordance in the context of problematic information online.\n2.4 Designing Against Problematic Information\nHCI designers have long been working on design-based solutions to problems like information\ncredibility judgment and filter bubbles. Below, I outline these works and where the works\npresented in this thesis stand.\n2.4.1 Designing for Distinguishing Information Credibility\nAt present, social media platforms are taking three approaches to combat misinformation\u2014\nremoving misinformation, reducing their reach, and raising awareness [ 389,393]. The first\nline of action falls under the practices of crowdsourced (in-house and community-driven) and\ntechnology-assisted moderation [ 193,198,419] by enforcing established community guide-\nlines [60,393]. The second approach involves reviews from fact-checking services followed by\ndownranking [ 64,277] and the application of warning/correction labels [ 312,394,467]. The\nthird approach largely focuses on contextualizing misleading content through design inter-\nventions, such as providing source transparency [ 132,423,445,455], prioritizing content from\ntrusted authorities [ 192,388], and showing related news stories from various sources [ 276].\nSome of these interventions also target particular issues (e.g., voting [ 395]) or particular\ninteractions (e.g., message forwarding [ 433]).\nAside from these platform-led efforts, researchers have also taken up the challenge of design-\ning tools to aid in assessing information credibility. These works span several approaches,\nincluding fact-checking systems, interventions, media literacy programs and games [ 76,114,\n255,279,387]. There are multiple scholarly efforts for computationally assessing content\ncredibility [ 75,181,286,309,374]. There are some scholarly works on establishing ap-\npropriate credibility signals for online content, as well as on designing guides for labeling\nmanipulated media [ 207,397,500]. Some works examine particular crowd-led credibility\nlabeling, including ratings by partisan crowds and the relationship between ratings from\ncrowds and experts [ 36,42,308,351].\nScholars have employed multiple types of messages as interventions against misinforma-\ntion, including theory-centered messages [ 82], warning messages [ 68,352], corrective mes-\nsages [152,213,361], and opposing argument messages [ 94]. Studies examined the efficacy\nofinterventionsinvariousgenresofnews, includingpublichealth[ 354,361]andpolitics[ 352].\nSome research examined the effectiveness of interventions across countries [ 178].Others ex-\namined effects for interventions across time by offering real-time correction versus delayed\nretraction [ 152,213]. Real-time correction tools utilize various strategies, including mining\ndatabases of well-known fact-checking websites (such as, Snopes and PolitiFact) or crowd-\nsourcing fact-checking. Paynter and colleagues looked into how to strategize corrections by\ncombining several existing techniques (e.g., salience of a graphical element in a warning);\ntheycallthisapproach\u201coptimizeddebunking\u201d[ 348]. Somesuggestthatwhilecorrectionscan\nbe effective, they can also backfire by inadvertently provoking users into attitude-consistent\nmisperceptions [ 350]. However, others were unable to replicate such backfiring effects [ 494].\nWarnings about information credibility have been more successful than corrections and are\nnot prone to the same backfiring effect [ 53]. This work builds on providing warnings through\ndesign cues that could trigger automatic cognition by associating design cues with the cred-\nibility of the content.\n2.4.2 Designing for Reflection on Algorithmic Filters\nReflection has received significant attention in HCI works. Existing research has shown\npromise of reflection in various areas such as education [ 170,214,253,461], health or wellbe-\ning [149,174,398,454], and self-knowledge or personal informatics [ 16,123,261,265,266].\nSeveral models have been proposed around personal informatics systems including Li et.\nal.\u2019s Stage- Based Model of Personal Informatics Systems [ 265], Epstein et al.\u2019s the Lived\nInformatics Model of Personal Informatics [ 123] and Niess et. al.\u2019s Tracker Goal Evolution\nModel [324]. Purpose of many of these systems is to facilitate behavior change [ 35,93,283],\nespecially through goal-setting [ 244,304]. In a similar vein, designing for reflection around\nonline social space has also received some attention [ 28,105,264]. Some of the prior work\non social media revolves around personal informatics [ 105,264]. For example, some works\ntrack affective expressions in users social activities (e.g., posts and comments [ 105,231]),\nthus providing insight into their personal behavior.\nWhile existing systems for reflection typically have an explicit metrics with desirable be-\nhavior changes\u2014e.g., eating healthily, regular exercise, enhancing productivity, the current\napproach of personal informatics or self-tracking may not work well for reflecting upon their\nfilter bubbles and discovering new content. In this case, previous works that involves social\nelements for reflection can be effective for users to understand their position through pro-\njecting oneself onto others. There have been works focusing on interpersonal informatics ,\nhelping users understand their social network and how that influence their behavior [ 31]. For\nexample, Feustel et. al. examines reflection using cohort data from multiple sources [ 136].\nDifferent properties of data may stimulate reflection including showing invisible information,\nallowing to compare, revealing ambiguity and providing multiple perspectives [ 310]. For ex-\nample, some previous work shows promise of providing data for comparison [ 469]. However,\nuse of recommendations or works against filter bubble in this space is sparse. Among the\nexisting works, some used personalized recommendation as a tool to trigger reflection on\na particular artifact [ 242,333]. Some systems also used visualization of unfiltered and cu-\nrated feeds to improve users understanding of recommender systems by reflecting on them\n[126,127]. Our work builds on these prior works to help users reflect on their own feed and\nescape from their filter bubbles.\nChapter 3\nNudgeCred: Supporting News\nCredibility Assessment on Social\nMedia Through Nudges\n3.1 Introduction\nSocialmediaplatformshavewitnessedanunprecedentedriseinmisinformationaroundpublic\nissues (e.g., COVID-19 and the 2016 US Presidential Election [ 8,495])1. To tackle, they\nhave responded by experimenting with various design interventions [ 394,467]. These include\nattaching warning labels and links to show additional context from trusted sources (see\nfigure3.1for an example). With an intent to raise awareness and lead users to investigate\nthe veracity of a news item [ 396], such design interventions can act as nudges\u2014a choice-\npreserving technique to steer behavior [ 442].Nudges differ from methods such as real-time\ncorrections that often act as mandates and can backfire [ 152]. Furthermore, nudges can\novercome the scale issue that many real-time systems face who rely on limited number\nof expert fact-checkers and quality crowd workers [ 24]. Despite the benefits, there is little\nempirical evidence whether nudge-based socio-technical interventions affect users\u2019 perception\nof credibility of online information. Furthermore, what complicates such investigation is that\n1part of this chapter appears in [ 43]\n27\nFigure3.1: Threetypesofinterventions(markedbybluearrows)currentlyemployedbyTwit-\nter to tackle misinformation. Tweet (a) with a link to proper authority regarding COVID-19,\n(b) with a warning, and (c) removed. Here, both (a) and (b) are examples of nudges. Around\nthe beginning of our work (July 2018), only (c) was operational. Twitter added others later.\npeople with strong ideological leaning may resist nudges [ 449].Existing works, again, lack\nempirical evidence of the effects of ideological leaning on nudges regarding perception of\ncredibility. Therefore, considering the constraints under which these nudges may or may not\nwork is crucial. This paper does just that.\nFor the purpose of our investigation, we design nudges with heuristic cues, i.e., mental\nshortcuts that people often use to judge credibility [ 300].The choice of heuristic cues over\nreflective ones reduces cognitive burden on users, given the immense amount of content users\nsee online [ 128].Incorporating design guides from nudge and heuristics literature [ 435,458],\nwe built NudgeCred which operationalizes three design nudges\u2014 Reliable,Questionable and\nUnreliable . Devised with two heuristic cues\u2014the authority of the source and other users\u2019\nopinions\u2014each of our nudges designates a particular level of credibility of news content\non social media. These two heuristics comprise both external authoritative sources of in-\nformation and social interactions of the crowd. Among the three nudges, both Reliable\nand Questionable are applied to information originating from mainstream sources on Twit-\nter, while Unreliable makes posts from non-mainstream sources less visible (see Figure 3.2).\nHere, Questionable and Reliable differentiate between mainstream news items that raised\nquestions in their Twitter replies compared to those that did not. Questioned items are\nhighlighted in yellow to warn of the potential controversy in evolving news stories from\nmainstream media, while those lacking questions are highlighted in green, signifying their\nreliability. By directing users\u2019 attention to the two heuristics, NudgeCred assists users in\nmaking meaningful news credibility evaluations.\n(a)\nDoes \nthe \ntwitter \naccount \nor \nthe \nembedded \nurl \nbelong \nto \nmainstream \nor \nnon-mainstream \nnews \nlist? \nIs \nthere \na \nquestion \nin \nthe \ntweet \nreplies?\nNo\nYes\nIntervention \nLogic\nDesign\n(b)\n(c)\nNon-mainstream\nMainstream\nFigure3.2: Ournudgedesign: [Top]Adecisiontreeshowstheinterventionlogicand[Bottom]\nthree nudge designs. (a). The Reliablenudge on a tweet from CNN Breaking News without\nquestions in its comment thread. (b). The Questionable nudge is applied to a tweet with\nquestions from Fox News, a mainstream media outlet. (c). The Unreliable nudge is activated\non a tweet from 100PercentFedUP.com , an extremely biased, non-mainstream website. The\nnumbers indicate: (1) a change in background, (2) a tooltip message shown when hovered\nover, (3) a button to open a survey questionnaire for users to rate the credibility of the news\ntweet, and (4) a button to show more questions in the comments.\nTo demonstrate our nudge-based approach, we built NudgeCred as a Chrome extension2.\nWe followed an iterative design process. We first tested our initial design of NudgeCred by\nconducting a formative study with 16 university students and 36 Amazon Mechanical Turk\nworkers. Results from the formative study helped us refine our design and suggested three\n2How NudgeCred works: https://www.dropbox.com/s/2mt4tpdxebccokt/nudgecred_cropped.mp4\nconfounds\u2014political ideology, political cynicism, and media skepticism\u2014that may restrict\nimpacts on users\u2019 credibility perceptions. We then conducted two sets of experiments using\nour final design: Study 1, a controlled experiment to examine the impact of the nudges with\na representative US population ( n= 430); and Study 2, a qualitative field deployment with\nTwitter users ( n= 12) to gain insight into how we can improve NudgeCred\u2019s design. Analyz-\ning users\u2019 credibility responses from Study 1 revealed that the Unreliable nudge significantly\nreduced users\u2019 perceptions of credibility for non-mainstream news sources. For Questionable ,\nusers in the treatment group rated news tweets with questions as less credible than the users\nin the control group, and those without questions as more credible. We did not find any\neffect of users\u2019 political ideology, media skepticism, or political cynicism on the effects of\nnudges. These outcomes suggest that NudgeCred worked irrespective of these confounds.\nResults from our field deployment (Study 2) show that NudgeCred improved recognition\nof news content and elicited attention towards all three nudges, particularly Questionable .\nParticipants also suggested additional design considerations, such as incorporating heuristics\nthat users would trust, applying nudges to share buttons, and using nudges to distinguish\nnews genres and biases. To conclude, we offer design directions for news credibility nudging\nby exploring transparency-mode of thinking nudge categories, other heuristics and nudging\nmethods from prior literature. Overall, our contributions include:\n\u2022A novel approach using heuristic cues to nudge users towards meaningful credibility\nassessment of news items in social media.\n\u2022A quantitative evaluation of this approach by examining users\u2019 credibility perception\nwhile considering three confounds\u2014political ideology, political cynicism, and media\nskepticism.\n\u2022A qualitative understanding of the opportunities and challenges of this approach in\ndesigning credibility nudges.\n3.2 Related W ork\n3.2.1 Nudges to Steer Human Behavior\nThe concept of nudgeshas been frequently used to steer civic behavior for achieving impor-\ntantsocietalgoals[ 182,441,443]. Theideastemsfrombehavioraleconomicsandpsychology,\nwhich define it as a \u201cchoice architecture\u201d that encourages citizens to act in a certain way\nwhile allowing them to act in other ways, thereby being a favorable alternative to imposing\nmandates [ 212]. Such approaches have been highly effective in areas such as environmental\nprotection, financial regulation, and anti-obesity policy [ 182,441,443]. In online settings,\ntechnology-mediated nudges have been applied for such purposes as encouraging better pass-\nword management, improving mobile privacy, and encouraging frugal shopping [ 25,30,218].\nComparatively, nudges regarding online news is getting traction recently in works such as\nPennycook and colleagues\u2019 \u201caccuracy nudge\u201d (an accuracy reminder) and Nekmat\u2019s \u201cfact-\ncheck alert nudge\u201d [ 319,354], who investigated impact of nudging on misinformation sharing\nintention. This work not only extends existing line of research by employing heuristics to\nassist credibility judgment, but also shows a method of devising such heuristic cue design.\n3.2.2 Heuristic Cues for Credibility\nCognitive psychologists have long argued that when information overload occurs\u2014as it typ-\nically does in online social media environments\u2014humans turn to the cognitively effortless\nroute of peripheral processing [ 80,355].While existing HCI works focus extensively on\nreflective processing, we use automatic or peripheral processing in this study [ 2].Periph-\neral processing means that they depend on heuristic cues, such as the attractiveness of the\nsource or the font color, to evaluate message content [ 355]. Communication researchers, in\nresponse, have offered a well-established list of technology-mediated heuristic cues, high-\nlighted in the MAIN model, which attempts to explain how certain cues influence users\u2019\nperception of credibility in online contexts [ 435]. The MAIN model suggests that four tech-\nnological affordances influence perceptions of credibility: Modality, Agency, Interactivity,\nand Navigability. These technological affordances trigger various peripheral cues by which\nusers then judge the credibility of online content. For example, the agency affordance fo-\ncuses on how users perceive source information in computer-mediated contexts. Often, the\nperceived agent or source of authority can be the machine, the user themselves, or the\nperceived authors of information on a particular website. For online news, agency is often\nattributed to the message\u2019s source, and these sources can trigger the authority heuristic\u2014the\nperception that the source is an expert on the subject matter [ 437]. Similarly, information\nsurrounding a message, such as ratings and recommendations, may also provide contextual\ninformation. For example, when a group of users likes or shares a news article on social\nmedia, the action signals that the group deems the information trustworthy. This signal,\nin turn, can influence users\u2019 perception of the information\u2019s credibility while serving as a\nbandwagon heuristic [ 435,436]. In summary, the space of all possible heuristics under the\nfour affordances is vast, offering us numerous possibilities for designing credibility nudges.\nAmong these heuristics, we utilize authority and bandwagon heuristics in our nudge design.\nWe discuss the remaining design possibilities later (see section 3.8).\n3.2.3 F actors Affecting Credibility Perception: Partisanship, At-\ntitude towards Politics, and Media\nScholars have found numerous factors that may influence information credibility. Based on\nfindings from our formative study (discussed in section 3.3), we contextualize our research\non three behavioral confounds\u2014partisanship, attitude towards politics, and attitude towards\nmedia. Historically, scholars have failed to reach a consensus on the role of partisan bias in\ncredibility perception. Earlier work suggested that users perceive unbiased information as\nmore credible compared to one-sided information [ 13,349]. Compared to this result, other\nresearch found that users would perceive news conforming to their own attitudes as more\ncredible than unbiased news [ 88,278,301]. For this reason, users with strong partisan biases\nmight even resist nudges on attitude-challenging news items, rather than be influenced.\nSunstein hypothesized that a considerably large number of people evaluate nudges based\non whether they approve of the underlying political objective, naming this \u201cpartisan nudge\nbias\u201d [443,449]. Hence, we made sure to test our nudge design across a population with\nbalanced partisan affiliations, allowing us to measure the effects of partisanship.\nSimilar to users\u2019 partisan attitude, users\u2019 media skepticism can influence their perceptions of\nthe credibility of mainstream and non-mainstream content. Media skepticism is \u201cthe feeling\nthat the mainstream media are neither credible nor reliable, that journalists do not live by\ntheir professional standards, and that the news media get in the way of society rather than\nhelp society\u201d [ 463]. Scholars have found that media skepticism is negatively associated with\nexposure to mainstream media and positively associated with non-mainstream media [ 462].\nMedia is also generally blamed for its role in enhancing institutional distrust by depicting\nmost governmental policies negatively and causing cynicism towards politics [ 69]. Studies\nhave also demonstrated that users with high media skepticism and political cynicism rated\ncitizen journalists as more credible than mainstream ones [ 71]. Drawing from these works,\nwe examine and provide the first empirical evidence of the effects of political ideology, media\nskepticism, and political cynicism on credibility nudge.\n3.3 F ormative Study\nWedesigned NudgeCred in an iterativefashion. Initially, webuilt a prototype and conducted\na pilot study to evaluate it3.\nMethod We built our prototype as a Chrome extension with two types of nudges (de-\nscribed in section 3.4.2); namely, Questionable (tweets highlighted in yellow, which indicate\ncaution) and Unreliable (tweets that are less visible). This extension would alter the Twitter\nhomescreen in real-time when users visit them. As mentioned in Figure 3.2, users could\nclick on a survey button added by the extension. Clicking the survey questionnaire but-\nton would open a pop-up overlay comprising our study measurements for credibility. We\ndiscus them further in section 3.5.1(refer Figure 3.3to see how it looked). With this\nsetup, we conducted a study with 52 participants from Amazon Mechanical Turk (n=36)\nand the university (n=36) [41].For recruitment from the university, we used a university\nportal available for participant recruitment. For the MTurk users, we used MTurk portal\nwith some filtering conditions, such high rate of work acceptance (>95%), over 18 years\nof, US resident and familiarity with Twitter. In a pre-study survey, we collected users\u2019\ndemographic details, such as gender and political leaning. Participants were divided into\ntwo groups of treatment (seeing tweets with nudges) and control (not seeing any nudge).\nIn a 2-week study period, we asked our participants to rate the credibility of three to five\n3All of our studies have been approved by our Institutional Review Board.\ntweets from their Twitter feeds every day. We did so by reminding them everyday to spend\naround 20 minutes on Twitter by completing an MTurk HIT. Afterwards, we reached out to\n16 users\u20148 control and 8 treatment users\u2014 to get feedback on our design where 8 of them\nfinally agreed. In all studies, we compensated our participants adhering to Federal minimum\nwage requirements ($7.25).\nResult In our study, we hypothesized that users in the treatment group would rate tweets\nwithboth Questionable and Unreliable nudgesaslesscrediblecomparedtousersinthecontrol\ngroup. A Mann-Whitney U test on the credibility ratings showed that our hypothesis was\ntrue for Unreliable nudge (avg. cred. (Control) = 0.51, avg. cred. (Treatment) = 0.43and\nZ= 210236 , p < 0.001, Cohen\u2019s d= 1.291). However, wefoundtheoppositefor Questionable\nnudge, i.e., the treatment group rated those tweets as more credible than the control group\n(avg. cred. (Control) = 0.67, avg. cred. (Treatment) = 0.71andZ= 502140 , p < 0.001,\nCohen\u2019s d= 0.188). Furthermore, in our post-hoc analyses, we found that for Republican\nusers the effects of nudges were not significant.\nTo make sense of the discrepancies in our quantitative result, we conducted interviews fol-\nlowedbyathematicanalysis. Weidentifiedthreethemesintheinterviews. First, whenasked\nwhich news organization users follow, participants showed a trend of interest in ideologically\naligned news sources. While a majority of Democrats mentioned mainstream sources (e.g.,\nCNN, NBC, the New York Times, and the Washington Post), most Republicans named\na mixture of mainstream and non-mainstream sources (e.g., the Wall Street Journal, Fox\nNews, Joe Rogan, and Candace Owens). This trend led us to assume that our intervention\nmay be less effective if it contradicts users\u2019 political stances. Second, we found several hints\nthat cynicism towards politics and media skepticism can influence the impact of nudges. For\nexample, one participant suggested that he prefers news without biases which mainstream\nmedia does not do anymore. Another (Republican) participant expressed frustration that\nshe had to stay away from discussing politics on social media, as she often ran into argu-\nments with others. If Republicans are indeed more skeptical of mainstream media on the\nwhole, and also equally mistrusting of social media platforms, then our intervention could\nbe perceived as yet another attempt by social media to integrate ideologically motivated\ninterventions into their news feeds. Therefore, we decided to examine whether these senti-\nments of media skepticism and political cynicism adversely affect the interventions. Third,\nconsistent with our quantitative result, we found the opposite of the expected reaction to\nthe Questionable intervention. For example, a participant responded: \u201cI found that these\ntweets [with Questionable intervention] seem ... more accurate than things that I normal ly\nread\u201d. This conflicting reaction may have stemmed from the lack of a clear hierarchy, i.e.,\nthe absence of nudges on more credible news tweets. Subsequently, we revised our design\nwith a third nudge called Reliable(tweets highlighted in green to indicate reliability). These\nfindings suggest that our initial prototype did not adequately support better news credibility\njudgments by users, and informed us to consider three confounds (users\u2019 political ideologies\nand attitude towards politics and media) in evaluating our system.\n3.4 Designing NudgeCred\n3.4.1 Design Guides\nTo design nudges with heuristic cues, we employ design guides from two strands of literature:\nthe nudge perspective and the heuristic perspective.\nNudge Perspective\nTo design effective nudges, the literature suggests two primary aspects to consider: the mode\nof thinking involved (automatic vs. reflective) and the degree of transparency (transparent\nvs. non-transparent) [ 186].\nMode of Thinking: Cognitive psychologists developed dual process theories, a set of psy-\nchological theories for understanding human decision-making. These theories describe two\nmain modes of cognition: automatic and reflective [128]. The automatic mode is fast and in-\nstinctive. It uses prior knowledge or past repeated behavior and minimal cognitive capacity\nto decide on actions. Reflective thinking, on the other hand, is slow and effortful. It uses\ngreater cognitive capacity to make a goal-oriented choice by critically examining the effects\nof choices before selection.\nT ransparency: Scholars introduced epistemic transparency (i.e., whether users would un-\nderstand the purpose of a nudge) to divide existing nudge designs into two categories: trans-\nparent and non-transparent [ 186]. Thaler and Sunstein adopted transparency as a guiding\nprinciple for nudges [ 451]. This is because of the concern that a designer may manipulate\npeople into their own preferred direction using systems for behavioral changes.\nUsing the combination of these two dimensions, Hansen and Jespersen grouped existing\nnudges into four categories: reflective transparent, automatic transparent, reflective non-\ntransparent, and automatic non-transparent [ 186]. In designing technology-mediated nudges\nfor credibility, we pick one quadrant from these categories: transparent nudges with the\nautomatic mode of thinking. We chose the automatic mode as it requires less cognitive\neffort to process information, especially given the information overload in social media and\nthe instant nature of media consumption. Scholars in the past argued that use of automatic\nmodeoverreflectivemodefordesigncouldaddresstwopotentialproblems\u2013lackofmotivation\nand lack of ability\u2013that typically restrain users from performing tasks such as critically\nevaluating credibility [ 2]. Furthermore, our design does not prevent users from critically\nreflecting on the news content. We chose the transparent design to explicitly reveal the\nmotives behind it. We later discuss the potential for nudge designs in the remaining three\nquadrants (see section 3.8).\nHeuristic Perspective\nThis work applies heuristics to design nudges for social media in order to enhance users\u2019\nperceptions of the credibility of news. Cognitive psychologists have proposed models of how\neffective heuristics work [ 239]. One of the models, called F ast and F rugal Heuristics suggests\nthatusersshouldbeabletomakeinferencesusing\u201cfast, frugal, andaccurate\u201dheuristicswhen\nfaced with environmental challenges (e.g., information overload) [ 458]. According to Todd\net. al., simple heuristics work when they follow two principles: they exploit the structure of\nthe environment and are robust. In social media, structures include sources of news items,\npopularity (indicated by the number of shares or replies), and the way that information\nis organized by time and personal interactions. They argued that heuristics that exploit\nexisting structured information can be \u201caccurate without being complex\u201d [ 458]. Another\nsuccess criteria for heuristic design is the robustness of the decision model. A computational\nstrategy utilizing a limited set of information can yield more robustness [ 458]. Employing\nthese principles, our design includes only two heuristics, outlined below. These heuristics\nseem useful to users to investigate misinformation [ 156].\n\u2022 Authority Heuristic : We limit the source of news to a handful of known organizations\nfollowed by a binary classification of the organizations.\n\u2022 Bandwagon Heuristic : We utilize the conversational structure (or replies) of the envi-\nronment as an indicator of credibility assuming a skew in the reply distribution.\n3.4.2 Outlining the Design\nOur design of NudgeCred is built on the idea of applying subtle heuristic cues in certain\ncontexts in social media. It is powered by three types of socio-technical interventions\u2014\nUnreliable ,Questionable , and Reliable. Using the principles of fast and frugal heuristic\ndesign, our design uses a two-level decision tree with two heuristics (see figure 3.2). They\nare triggered based on whether a news tweet originates from an official authority. Thus,\nthe first step of our tool design relies on the authority heuristic . Communication schol-\nars have long argued that revealing the official authority of content results in applying the\nauthority heuristic in credibility judgments [ 435]. We apply the authority heuristic by dif-\nferentiating between mainstream and non-mainstream news tweets. We do not apply nudges\nto tweets that do not come from mainstream and non-mainstream sources. We opt to use\nsource-based credibility annotation due to the challenging nature of annotating article-level\ncredibility. While we may flag some accurate articles from non-mainstream media in this\nmethod, other work demonstrated that this number could be few (14%) compared to the\naccuracy (82%) [ 412]. For such false-positives, users still have the opportunity to fact-check\nthem.\nTo flag inaccurate content from mainstream media, we apply another criteria of whether\nsomeone replied to a mainstream tweet with a question. Literature suggests that such\nquestions, depending on users\u2019 prior knowledge of the subject matter, can instigate curiosity\nand motivate them to investigate to a varying degree [ 272]. We employ this property by\nshowing the number of questions as a bandwagon heuristic (\u201cif others question this story,\nthen I should doubt it, too\u201d) on mainstream news tweets. Thus, our study had three nudges:\nmainstream news tweets that did not have questions raised about their content ( Reliable),\nmainstream news tweets that had questions raised about their content ( Questionable ), and\nnon-mainstream news tweets ( Unreliable ). To employ epistemic transparency in the design,\nour design includes a tooltip with the reasoning behind each nudge. Figure 3.2shows the\noverall design. Before delving into each intervention, we propose a classification of news\nsources that enables our application of the authority heuristic .\nClassifying Authority of News\nOur nudge-based interventions work on two types of news sources: mainstream and non-\nmainstream. In journalism and communication literature, the term \u201cmainstream media\u201d\nlacks an official definition. For the purposes of our study, mainstream news sources are\nsources recognized as more reliable in prior scholarly work. Opting for a heuristic approach,\nwe use such existing literature to create a reliability measure which may later be replaced;\nthis is not our primary contribution. In this approach, the first two authors iteratively\ncollected a list of mainstream news websites by referring to two prior works, including Pew\nSurvey and NPR [ 305,410]. Next, we refined our list with the help of our in-house journalism\nand communication media expert by referring to the most circulated and the most trusted\nnews sources [ 87,305], subsequently removing a news aggregator (Google News) and a local\nsource (AMNewYork). Table 3.1shows a sample. Every source on our final list of 25 news\nsources follows standard journalistic practices in news reporting [ 18].\nFor non-mainstream news sources , we refer to Opensources.co , a professionally curated\nlist of websites known to spread questionable content [ 338]. Each source in this list is cate-\ngorized based on its level of information reliability (e.g., \u2018extreme bias,\u2019 \u2018rumor,\u2019 \u2018clickbait\u2019).\nThe curators manually analyzed each source\u2019s domain-level characteristics, reporting and\nwriting styles before assigning a particular category. From this list, we remove the \u2018politics\u2019\nMainstream Source\nThe Economist CNN The Blaze\nNew York Times NPR BBC\nWashington Post MSNBC Fox News\nChicago Tribune WSJ Politico\nNew York Post Newsday NY Daily\nTable 3.1: Example sources\nin our mainstream news\ncategory.Website Category Inaccuracy Type Message\nabcnews.com.co Fake news misinformation\nbreitbart.com Extreme Bias partisan stories\namericantoday.news Rumor Mills rumor\ninfowars.com Conspiracy Theory conspiracy\nrt.com State News state propaganda\nTable 3.2: Example non-mainstream news sources and\ntheir categories of reporting inaccuracy. The tooltip\nmessages read: \u201cThis source is considered unreliable be-\ncause it promotes <InaccuracyType >\u201d.\nand \u2018reliable\u2019 categories to retain sources which were explicitly labeled as promoting unreli-\nable news, a total of 397 sources spanning 10 categories. Table 3.2shows a sample from this\nlist. We do not intervene in the rest of the sources that do not fall into these two categories.\nUsing this notion of mainstream and non-mainstream news sources, we apply three nudges.\nThree Nudges\nThe Unreliable nudge detects whether a tweet comes from an unreliable authority. Our\ndesign applies this nudge by examining whether a tweet from a user\u2019s feed originates from a\nnon-mainstream news site and subsequently reduces the item\u2019s opacity, rendering it harder\nto read. We call these tweets unreliable non-mainstream tweets ( TU) [See (c) in figure\n3.2]. To instigate epistemic transparency, Unreliable provides an explanation of its ac-\ntion through a tooltip message: \u201cThis source is considered unreliable because it promotes\n<InaccuracyType >.\u201d Table 3.2shows the list of <InaccuracyType >messages based on the\nsource and its category in opensources.co .\nThe Questionable nudgeis applied to mainstream news tweets ( TQ) when at least one ques-\ntion is raised about the information in the corresponding Twitter reply thread4. Prior studies\nsuggestthatlesscrediblereportsonaneventaremarkedbyquestionsandinquiries[ 309,503].\n4Though Twitter has recently rolled out a threaded reply structure, at the time of the study, it did not\nexist. Thus, we only took direct replies into account.\nTo detect questions, our algorithm is kept intentionally simple. Our algorithm looks for \u201c?\u201d\nmark to identify questions\u2014a simple but transparent method that is understandable by\nusers. It is worth noting that our focus is not to develop the most sophisticated algorithm to\ndetect questionable news, rather testing the effectiveness of nudge in credibility assessment.\nIn that regard, using the simple heuristic serves its role and have benefits in simplicity and\ntransparencyforuserstounderstand. Whileinvestigatingadvancednaturallanguageparsing\nmethods to identify relevance of the questions to the news article or more advanced machine\nlearning techniques to detect questions is worth looking into [ 260,496], such investigations\nwould require significant work, perhaps amounting to a separate full contribution. Hence we\nleave those as future paths to pursue. Instead our approach works as a minimum baseline\nto identify questions. To make users aware of these questioned mainstream tweets, the\nQuestionable nudge is applied by changing the background color of the tweet to yellow while\nshowing the number of questions (see (b) in figure 3.2). By showing this number, we promote\na collective endorsement that multiple users have doubts about this news [ 436]. Additionally,\na tooltip message offers transparency by explaining the reason behind the nudge activation.\nForTQ, the tooltip message follows the format: \u201cSeveral users have questioned this item.\nQuestions include: <first reply tweet with a question >\u201d (e.g., for a tweet containing a news\nreport with missing details, such as time of an event, a reader may have replied to ask:\n\u201cWhen did this happen?\u201d), thus directing further attention to other users\u2019 comments in an\neffort to stimulate the bandwagon heuristic . The bandwagon effect has been demonstrated\nto be powerful in influencing credibility judgments [ 237].\nThe Reliable nudge is triggered when the source of the news tweet is an official, mainstream\nsource and was not questioned in the replies; specifically, reliable mainstream tweets ( TR)\nwere emphasized with a green background highlight (see figure 3.2(a)). A tooltip message\nis formatted for TRas follows: \u201cThis tweet seems more reliable. Nobody has questioned this\nSource Type Twitter Account Political Bias Source Type Twitter Account Political Bias\nMainstream CNN Breaking News Left Non-mainstream Daily Kos Left\nMainstream NY Post Right Non-mainstream Breitbart Right\nMainstream Politico Center Non-mainstream Zero Hedge Conspiracy\nTable 3.3: Example news sources and their political biases.\nitem yet.\u201d The colored highlights and the corresponding tooltip messages create contrast\nwithin the mainstream news tweets, helping users navigate them better. Note that we\nincluded this nudge in response to the findings from the formative study.\n3.5 Study 1: Evaluating Impact on Perceptions of Cred-\nibility in a Controlled Setting\nTo evaluate our design, we conducted two studies. Study 1 evaluates impact on credibility\nperception in a controlled setting while Study 2 is a field deployment. In Study 1, we\nexamine three research questions on the effect of nudges on users\u2019 credibility perceptions in\na controlled setting simulating a Twitter feed with multiple tweets for each nudge.\nRQ1.Can heuristic-based design nudges on an online social news feed help users distinguish\nbetween reliable, questionable, and unreliable information?\nRQ2.Do users\u2019 partisan attitudes affect their responses to credibility nudges?\nRQ3. Do users\u2019 political cynicism and media skepticism affect their responses to credibility\nnudges?\n3.5.1 Method (Study 1)\nSelecting news tweets for a controlled environment\nFor this study, we simulated a Twitter feed with a fixed set of tweets which would be\nshown to every user. To simulate a realistic Twitter feed, we selected news sources from\nour previously compiled list of mainstream and non-mainstream sources, and then selected\nseveral tweets from each source (see Table 3.1and3.2). We used a balanced approach to\nselect sources with left-wing, centrist, and right-wing biases. For bias categorization, we used\nmediabiasfactcheck.com , a source used in other scholarly works [ 228,295]. For each news\nsource under each bias category, we first found the source\u2019s Twitter handle. We retained\nthe Twitter accounts that had the greatest numbers of followers5(a mark of popularity of\nthe news source on Twitter). Table 3.3shows sample Twitter accounts with their perceived\npolitical biases. For each source, we selected the tweet within the last 48 hours that had\nthe highest number of shares. With three nudges working across three political leaning\ncategories, our feed comprised 9 tweets (3 political leanings \u00d73 nudges). Appendix A.1\nshows several tweets from this list. To add variation, we created another set of 9 tweets\nusing the second most followed Twitter accounts from our list of news sources, resulting in\na second feed for our controlled environment. Users were randomly shown one of the two\nfeeds, totaling 9 tweets in each case. To evaluate our RQs, we needed to measure users\u2019\ncredibility perception, political ideology, political cynicism, and media skepticism.\n5We excluded Fox News\u2019 Twitter handle due to its inactivity for several months until the time of the\nstudy.\nFigure 3.3: Screenshot of how clicking on the survey button would pop open the five-item\ncredibility questionnaire.\nItem IRR\nIs/not biased 0.83\nIs/not fair 0.79\nDoes/not biased tell the whole story 0.80\nIs/not accurate 0.79\nCan/not trusted 0.79\nTable 3.4: IRR of the five-item ques-\ntionnaire on credibility in the forma-\ntive study.Pol.1. Electedo\ufb00icialsputtheirowninterestsaheadofpublic\u2019sinterest\nCyn.2. It seems like politicians only care about special interests\n1. The media provide accurate information\nMed.2. The media provide trustworthy information\nSkep. 3. The media deal fairly with all sides\n4. The information provided by the media needs to be confirmed\nTable 3.5: Items used in measuring political cynicism\nand media skepticism. We used a five-point Likert\nscale (Strongly Agree \u2013 Strongly Disagree) with a\n\u201cDon\u2019t know\u201d option.\nMeasuring News Credibility , Political Ideology , Political Cynicism & Media\nSkepticism\nWe used a five-item questionnaire by Meyer et. al. [ 303] to measure users\u2019 perceptions of\ncredibility for every news tweet (see Figure 3.3). In our formative study, we found this\nmeasure had a high Cronbach \u03b1(\u03b1= 0.95) and individual inter-item correlations (see Table\n3.4), showing a high level of internal consistency. To capture partisan attitudes, we survey\nparticipants for their political ideology on a seven-point Likert scale ranging from \u201cstrong\nRepublican\u201dto\u201cstrongDemocrat\u201d. Wesurveyparticipantsonmediaskepticismandpolitical\ncynicism using a validatedquestionnaire from journalism scholarship(see Table 3.5) [71]. For\nboth variables, we average the responses across questions and use the median to create a\nbinary response variable with values \u201clow\u201d and \u201chigh.\u201d Note that we had to revert the first\nthree media skepticism questions before averaging.\nFigure 3.4: Distribution of demographics, political ideology, political cynicism, and media\nskepticism in our participants in Study 1.\nRecruitment\nOur study participants were recruited starting the third week of July 2019 and spanning a\nperiod of three weeks. We required three qualifications for user participation: (1) age of 18\nor older, (2) US resident, and (3) familiarity with Twitter. This choice of US population\nwas purposeful due to the difficulty in measuring our confounds across global population.\nUsers\u2019 political leaning has different meanings in different countries (e.g., political left-right\nare different in the US and Europe). Similarly, levels of skepticism/cynicism might vary by\ncountry. We focused on US-population due to the availability of well-established measure-\nments for our confounds from the communication literature [ 71,303].We recruited 430 users\nfrom Qualtrics , well-balanced by partisan affiliations. Figure 3.4shows their demographics.\nThis sample is mostly balanced across gender, age, and education, with a slight skew toward\nfemales.\nStudy Procedure\nWe presented our participants a set of tweets collected right before the start of recruitment.\nWe chose this approach because studies have shown that there is a lag in terms of the\namount of time media coverage takes to influence public opinion, with some exceptions\n(e.g. mass shootings) [ 385]. As a result, we anticipated that participants would be least\nlikely to be familiar with the most current tweets. Participants were randomly assigned to\neither the treatment or the control group, with a quota check to ensure balanced allocation\nacross political ideology. To counter order effects, we presented tweets in random order.\nWe added attention checks\u2013questions with options reversed\u2013right before the Twitter feed.\nTaking recommendations from Qualtrics, we also discarded participants who spent less than\nsix minute to respond\u2013the half of the median time spent by users in a soft-launch of 50\nusers.Participants saw each tweet and answered the questions for that item before scrolling\ndown to the next one. This approach reflects a natural setting of modern social media sites,\nwhere users browse feeds in real-time, click links in-situ, and the same post usually do not\nappear again at a later time point. To reduce response bias, we framed the questions to\nask for credibility of the items (e.g., how do you feel about the post?) instead of the effects\nof nudges (e.g., how does the nudge affect your perception?). The unexpected effect on\nQuestionable in our formative study suggests a lack of response bias.\nMethod of Analysis\nWe initially perform mean comparison with Mann-Whitney U-test. However, note that each\nuser saw multiple tweets with each intervention. To model such repeated measurements for\nthe same intervention, we further use a mixed-effects logistic regression.\ny=X\u03b2+Zu+\u03f5 (3.1)\nIn Eq.3.1, the response variable (credibility score) ( y) is the dependent measure for our\nexperiment. While fixed effects ( X) are the independent measure, random effects ( Z) are\nthe variables repeated in multiple observations; that is, tweets. The residual ( \u03f5) is the error\nin fitting. Finally, \u03b2and uare the coefficients of fixed and random effects, respectively.\nWe used an Rimplementation of a linear mixed-effects regression model, lme4.lmer , on our\ndataset [ 52].\nDependent V ariable: Ourdependentmeasureisthecredibilityscore, acontinuousvariable\ncomputed by averaging the five credibility question responses (see Figure 3.4) followed by\nstandardization. We perform robustness checks by rerunning mixed-effects ordinal logistic\nregressions on each of the five credibility questions. We find no significant differences in\nthe resulting model coefficients, suggesting sufficiency in modeling the credibility score as\ncontinuous.\nIndependent V ariables: The independent variables related to RQ1 include main effects\nand interaction effects derived from the two experimental conditions: users\u2019 group (control\nor treatment) and intervention type ( TR,TQ,TU). For RQ2 and RQ3, we examine three\nvariables, including political ideology, political cynicism, and media skepticism. For the\nsake of analysis, we map political ideology, measured on a seven-point Likert scale, to three\ngroups consisting of Democrats, Independents, and Republicans. Following a prior scholarly\nwork [71], we used the median score across all the questions in each variable (political cyni-\ncism and media skepticism) to split the participants into two groups. In our representative\nUS sample, the median for media skepticism was 2.75(\u03b1= 0.72,M= 2.48,SD= 0.98)\nand the median for political cynicism was 4.00(r= 0.53,M= 4.09,SD= 0.81). Similar to\nCarr et al., we considered values greater than the median as high on that category and vice\nversa [71]. In other words, media skepticism of 3.00 would be labeled high media skepticism,\nwhile 2.75 would be labeled low media skepticism. We also include the political leanings of\nthe news sources used in our tweet selection procedure as an additional independent variable.\nControl V ariables: Prior studies indicate that the level of interest in a news story can\ninfluence users\u2019 credibility assessment [ 299]. Therefore, we include participants\u2019 interest in\na tweet as a control variable, measured on a five-point Likert scale ranging from low to high\nControl Treatment Bet. Subj. MWU-test\nAvg. Cred. Avg. Cred. (Cohen\u2019s d)\nTR0.62 0.67 187488.0(0.162)***\nTQ0.58 0.55 198180.5(0.072)*\nTU0.46 0.37 171763.0(0.296)***\nn693 597\nTable 3.6: Mann-Whitney U test results\nfor Study 1. Here, \u2018n\u2019 denotes the num-\nber of tweets rated in each condition.\nAvg. Cred. is the mean of \u2018n\u2019 credibility\nscores; * p <0.05, *** p <0.001.\n0.751.00\n0.50\n0.25\n0.00Reliable\nQuestionable\nUnreliableFigure 3.5: Shows interaction effects between user\ngroups and nudge types in Study 1. The numbers\ninside the brackets are the effect sizes, Cohen\u2019s d.\ninterest. Other control variables include users\u2019 demographics, such as gender, age, education,\nand Twitter usage frequency.\n3.5.2 Results (Study 1)\nRQ1: Effect of the Nudges\nFor RQ1, initially we investigated our data using mean comparison. Table 3.6shows the\nmean values and Mann-Whitney U test results of our experiment and Figure 3.5shows\ncorresponding interaction plots. Users in the treatment group rated the credibility of non-\nmainstream news tweets ( TU) significantly lower than did users in the control group, suggest-\ning the effectiveness of our intervention ( Z=171763 , p<0.001, Cohen\u2019s d=0.296). Addition-\nally, treatment users rated mainstream news tweets without questions ( TR) as more credible\nthan corresponding control users ( Z=187488 , p<0.001, Cohen\u2019s d=0.162). Our participants\nshowed significant decrease in their rating of mainstream news tweets with questions ( TQ)\n(Z=198180 , p<0.05, Cohen\u2019s d=0.072).\nOur experimental setting with each user rating multiple tweets prompted us to further\nanalyze the data using a series of mixed-effects regression models. Table 3.7shows this\nanalysis. To determine the effects of the experimental conditions, our base model includes\nBase Model Politics & Media Model 3-Way Interaction Model\n\u03b2 SE \u03b2 SE \u03b2 SE\n(Intercept) 0.29*** 0.27*** 0.32***\nControl Variables\nGender (Male) 0.03* 0.05 0.03* 0.05 0.04 0.07\nEducation -0.00 -0.01 -0.01 -0.03 -0.01 -0.04\nAge 0.00 0.01 0.01 0.03 0.01 0.04\nSocial Media Usage 0.01 0.01 0.01 0.02 0.01 0.02\nInterest in the Tweet 0.09*** 0.45 0.09*** 0.45 0.08*** 0.36\nExperimental condition\nType(Mainstream-Question) -0.03 -0.05 -0.03 -0.05 -0.07 -0.11\nType(Non-mainstream) -0.16** -0.26 -0.16** -0.26 -0.23** -0.38\nGroup(Treatment) 0.04** 0.07 0.04** 0.07 0.08 0.13\nType(Mainstream-Question):Group(Treatment) -\n0.06***-0.08 -\n0.06***-0.08 -0.11* -0.14\nType(Non-mainstream):group(Treatment) -\n0.10***-0.13 -\n0.10***-0.13 -\n0.21***-0.26\nPolitics and Media\nIdeology(Democrat) 0.03* 0.05 0.01 0.01\nIdeology(Republican) -0.03* -0.04 -0.03 -0.05\nPolitical Cynicism(Low) 0.01 0.02 0.01 0.02\nMedia Skepticism(Low) 0.05*** 0.08 0.06** 0.11\nAccount Leaning(Conspiracy) 0.07 0.08 0.06 0.07\nAccount Leaning(Left) 0.09 0.14 0.09 0.14\nAccount Leaning(Right) 0.00 0.01 0.00 0.00\nExperimental Condition x Other Variables\nGroup(Treatment):Gender(Male) -0.08* -0.11\nType(Non-mainstream):Interest in the Tweet 0.02* 0.11\nType(Non-mainstream):Group(Treatment):Gender(Male) 0.09* 0.08\nType(Non-mainstream):Group(Treatment):Interest In a\nTweet0.03* 0.10\nAdj. R2(Marg./Cond.) .310/.483 .347/.494 .358/.508\nN = 3870 * p<.05, ** p<.01, *** p<.001\nTable 3.7: Regression models on the credibility score. The base model contains nudge\ntype, user group, control variables and the interaction between user group and nudge type.\nThe politics and media model adds users\u2019 political ideology, media skepticism and political\ncynicism variables to the base model. The 3-way interaction model further includes the\ninteractions of nudge type, user group and other variables with significant main effects in\nthepoliticsandmediamodel(Gender,InterestintheTweet,IdeologyandMediaSkepticism).\nnews source type, group assignment, and their corresponding interactions. We find that\ntweet type\u2014mainstream or non-mainstream\u2014is strongly correlated with a tweet\u2019s credibil-\nity score. Non-mainstream tweets are generally rated less credible than mainstream news\nsources with a small effect size ( \u03b2=\u22120.16,p<0.01and Cohen\u2019s f=.07). This result suggests\nthat users can differentiate between mainstream and non-mainstream tweets even without\nour nudges. However, treatment users (those who received nudges) generally rated tweets as\nslightly more credible than control users ( \u03b2=0.04,p<0.01, Cohen\u2019s f=0.04). Nevertheless,\nthereisaninteractioneffectbetweentweettypeandusergroup. Treatmentusersscorednon-\nmainstream tweets lower than control users with a medium effect size ( \u03b2=\u22120.10,p<0.001\nand Cohen\u2019s f=0.16). Treatment users also rated mainstream tweets with questions as less\ncredible than did control users ( \u03b2=\u22120.06,p<0.001, Cohen\u2019s f=0.16). The decrease in the\ncredibilityperceptionscoresofbothmainstreamquestionedtweets( TQ)andnon-mainstream\nones ( TU) suggests that our nudges can help users consume these news items as less credible,\nthereby answering RQ1.\nRQ2: Effect of Political Ideology\nTo answer RQ2, we examine the political ideology variable in our politics and media regres-\nsion model. Politically Independent users serve as the point of reference for this variable. We\nfind that Democrats generally rated all tweets slightly higher in credibility than did Inde-\npendent users ( \u03b2=0.03,p<0.05, Cohen\u2019s f=0.06), whereas Republicans rated them slightly\nlower than Independents ( \u03b2=\u22120.03,p<0.05, Cohen\u2019s f=0.06). Due to this main effect,\nin our 3-way interaction model, we further explore whether political ideology had any in-\nteractions with the three nudges and the users\u2019 group assignments. However, we find no\nsignificant interaction. Therefore, nudges changed users\u2019 credibility perceptions irrespective\nof their political leanings. We discuss these findings later.\nRQ3: Effect of Political Cynicism and Media Skepticism\nTo answer this RQ, we examine two variables (political cynicism, and media skepticism) in\nour politics and media regression model. Between media skepticism and political cynicism,\nonly media skepticism had a significant effect, where users with lower media skepticism rated\ntweets as more credible ( \u03b2=0.05,p<0.001, Cohen\u2019s f=0.10). In our 3-way interaction model,\nwe further explore whether media skepticism had any interactions with our key variables of\ninterest\u2014treatment and control groups, and the three nudges. We do not find any significant\ninteraction effects. Therefore, nudges changed users\u2019 credibility perceptions irrespective of\ntheir attitudes towards politics and media. We elaborate on these findings in the Discussion\nsection.\nEffect of Control V ariables\nWe examine whether user demographics and users\u2019 interest in a news story had any effect on\nhow they rated the credibility of the news tweet. Across all three models, the effects exerted\nby our control variables are consistent. Independent of whether a user was assigned to the\ncontrol or treatment group and independent of the type of news (whether mainstream or\nnon-mainstream)theysaw, usersprovidedhighercredibilityscoreswhentheywereinterested\nin a story, with a large effect (base model effects: \u03b2=0.09, p<0.001, Cohen\u2019s f=0.5). Among\ndemographic variables, male users rated tweets as more credible with a small effect size (base\nmodel effects: \u03b2=0.03, p<0.05, Cohen\u2019s f=0.03). The remaining demographic variables did\nnot show any significant effect6.\n3.6 Study 2: Field Deployment\nTo gain insights into how we can understand and improve the current design nudges for\ncredibility, we conducted a qualitative study. For this purpose, we recruited participants to\nuse NudgeCred on Twitter for five days. This process allowed us to evaluate it in a more\necologically valid environment than Study 1 [ 59]. Below, we describe the process.\n6Additionally, we examined whether there was any learning effect compounded from seeing multiple\nnudges. To do so, we added the order (from 1 to 9) of the tweets in which participants evaluated their\ncredibility and its interaction with nudge type and user group in our regression models. We found no\nsignificant effect of the order.\n3.6.1 Method (Study 2)\nRecruitment\nTo recruit users for this study, we used Twitter advertising, following a prior strategy [ 207].\nWe devised several targeting mechanisms to promote the advertisement to our desired group,\nincluding age range (>=18), language (English), location (USA) and whether users followed\ntop mainstream and non-mainstream news accounts in our list. Initially, we were not suc-\ncessful in getting responses from broader regions, so we iteratively revised the location to\ntarget nearby states for effective recruitment. Additionally, we promoted the advertisement\nwithin our academic network on Twitter. From 50 interested participants, we recruited 12\nparticipants for the study by filtering our spams and users with less than 100 followers .\nOverall, our participant group consisted of 5 females and 7 males with an average age of\n29.5 (std. dev. = 6.5) and a political tilt towards Democrats (Democrat = 6, Independent\n= 4, Republican = 2).\nProcedure\nFollowed by an informed consent process, we instructed users to install the NudgeCred\nbrowser extension. To promote a natural setting, we encouraged users to use Twitter during\nthe five-day study as they normally would. However, it is possible that Twitter\u2019s news\nfeed algorithm may not have surfaced news items on their feed each time. Hence, we also\nencouraged users to visit the Twitter profiles of some news sources each day to ensure that\nusers experience how NudgeCred works. After five days, we asked them to fill out a post-\nstudy survey on demographic details followed by an interview in a semi-structured manner\n(see Appendix A.2for the interview questions). To facilitate their responses, we asked users\nto walk us through their news feed during the interview. Each participant received a $30\ngift card for participating.\n3.6.2 Results (Study 2)\nWe analyzed the interview data using a grounded theory approach [ 430]. The first author\ntranscribed the audio from the interviews and analyzed the data to come up with a set of\nthemes. These themes were discussed and refined with the other authors. Below, we present\nour final set of themes.\nNudgeCred facilitates more conscious news consumption\nMost of our participants (9/12) provided positive feedback on their overall experience with\nNudgeCred, referring to the design and application. Some participants (U1,U6,U9) particu-\nlarly mentioned that they liked the bandwagon heuristic with the questions in replies.\n\u201cIt [NudgeCred] quickly highlights. So you know what to look for. Especial ly when it\u2019s\na question mark, I do actual ly open up the comment section and read what the question\nis. \u201d (U9)\nOtherslikeditbecauseitservedasaneducationaltoolto\u201ctraintheusertothoughtfullythink\nabout\u201d news (U4) or because it did not add overhead to their current Twitter experience\n(U2). Overall, users reported two phenomena. We describe them below.\nImproved Recognition of News Content and News Genres: One of the impacts that\nparticipants (5/12) mentioned was the perceived difference in the amount of news content\nin their feed compared to their prior experience. For example, they perceived that there was\nmore news content in their feed than before. NudgeCred even helped some participants pay\nmore attention to the types of content that news sources produced.\n\u201cIt [NudgeCred] real ly just told me that NPR produces more articles that are opinionated\n[the participant was referring to an Op-Ed] on Twitter than I thought. \u201d (U1)\nThe article labeled as Questionable made them realize that it was an op-ed article, rather\nthan news.\nAttention towards Bandwagon Heuristic: Out of the three nudges, participants (7/12)\nnoticed the Questionable tweets highlighted in yellow the most, and the number of questions\nbelow them.\n\u201cI noticed the one [question icon] at the bottom more ... most people who use Twitter\na lot ... 9 out of 10 are more likely in tune with the replies/retweets. Usual ly I use\nthose as a sign of popularity. \u201d (U1)\n\u201cIf I see it [a tweet] as yel low ... I do get the information that this is either ... a lot of\npeople don \u2019t like the news article or this article might have controversial or incorrect\nfacts. \u201d (U10)\nWhile users, as U1 indicated, may see traditional retweet or reply numbers as an indicator of\npopularity, one participant (U10) correctly pointed out the bandwagon cue as an indicator\nof controversy. Thus, nudges imitating existing designs on social media can be useful.\nOverall, these phenomena support that our nudges can improve users\u2019 news perception in\ntwo ways: (i) with an overall impression of total news items on users\u2019 feeds broken down\nbased on the reliability of sources, facilitating better perception on its genres; and (ii) with\nindividual attention towards particular news items.\nConcerns in Using Heuristics for Nudging News Credibility\nInterviews also revealed two concerns regarding our nudge design. We discuss these concerns\nbelow.\nT rust Issues with Heuristics: A majority of our participants (7/12) questioned the use of\nbandwagonheuristictodifferentiate Reliableand Questionable newsitems. Becauseaudience\ncomposition can vary by the source and the topic of a news item, and influence bandwagon\nheuristic, they were concerned about its disparate impact. One participant pointed out that\nfollowers of the New York Times (NYT) are comparatively more diverse than followers of Fox\nNews. Consequently, audiences with an opposing stance on a news report from the NYT may\nquestion it. In contrast, Fox News, having a homogeneous audience which mostly supports\nits reporting, may hardly question their reports. Therefore, our bandwagon heuristic would\nbe skewed based on the audience of a report.\n\u201cNYT [The New Y ork times] and MSM [mainstream media] in general have a lot\nmore reactions from skeptical readers given the current administration. And to some,\nthe color-coding and the number of questions may indicate that the news is subjective\nor \u201cfake\u201d when you compare it with other outlets such as F ox News that have fewer\nreactions on Twitter and a more homogeneous audience. \u201d (U7)\nThese responses suggest that even though a user may understand the bandwagon heuristic,\nthe heuristic itself may have some shortcomings, which makes it challenging for the user to\ntrust it as a metric for gauging credibility.\nAdverse Effects of Nudges: Our participants (2/12) suggested two adverse effects of the\nnudges. One participant (U11) proposed that users may use the bandwagon heuristic based\non like-minded questions as a justification for their attitude-consistent belief in politically\nopposing news, thus promoting a confirmation bias .\n\u201cIf I agree with you and you are questioning an article that I questioned as wel l ... since\nyou personal ly agree with me, it confirms my bias against that piece of information. \u201d\n(U11)\nA similar effect has been suggested by scholars in the past, who show that rating mechanisms\non online platforms (e.g., Facebook \u201clikes\u201d) may guide users\u2019 news selection process [ 298].\nIf such effects exist, users may become more polarized. Compared to confirmation bias\nstemming from the existence of a nudge, the absence of nudges , mentioned by U4, could\nalso have a harmful effect.\n\u201cI think the ones that I subconsciously ignore are the ones that have no color at al l. If\nthere aren \u2019t any flags ... no color blocks, I am more inclined to assume that the content\nis valid. \u201d (U4)\nThisparticipantsuggestedthattheabsenceofnudgescreatesanillusionofvalidityofcontent\nwithout nudges. Indeed, recent research points out the same phenomenon when false reports\nare not tagged, resulting in a false sense of being validated [ 353]. One way to address this\nconcern is, again, to be transparent about not being nudged with an additional tool tip\nmessage for the news items that are not nudged.\nOverall, our participants\u2019 concerns suggest that designers need to evaluate two aspects of\nnudges: (i) How trustworthy the design components of the nudges are (ii) Whether the\npresence and absence of nudges adversely affect users.\nOpportunities for Credibility Nudge Design\nIn addition to differentiating news credibility, we asked participants what other functions\nthey would like in NudgeCred. Participants suggested improvements in three directions.\nExtending the News Source List: Our participants were concerned on the limited set\nof news sources we considered. They (5/12) suggested that they often see misinformation\nfrom non-news entities, including their acquaintances. To allow more news identification,\nsome (2/12) asked us to include local news sources. With our participants following diverse\nsources for information, our limited news source list was naturally inadequate for them.\nIndicating News Genres and Reporting Biases: Suggestions from the participants\nincluded distinguishing opinion items from news (3/12) and indicating bias in a report as a\nnudge (2/12).\n\u201cGive a notification that say what I am seeing is an op-ed rather than straight facts. \u201d\n(U4)\n\u201cIs it possible to state that this news article is biased towards this particular claim?\u201d\n(U10)\nA recent survey shows that about 50% US adults \u201care not sure what an op-ed is\u201d and that\nabout 42% of respondents perceive that opinion and commentary are often posed as news\nin most news articles [ 367]. Therefore, a significant share of the population may appreciate\nhaving nudges that differentiate op-eds from news as well as other indicators of bias stems.\nIncorporating such attributes in nudging might help users better determine the credibility\nof news content.\nCurbing Misinformation Sharing: To prevent the sharing of misinformation, some par-\nticipants (2/12) proposed implementing nudges on share (or retweet) buttons.\n\u201c[when someone clicks the share button] If there is a notification that says this source\nis not credible then people would be less likely to share it. \u201d (U2)\nResearch indicates that about 59% of links shared on Twitter have never been clicked [ 146],\ni.e., users often share news items without reading them. If nudges can help user determine\nthe unreliabilityof news from misinformativesources, they mightbe less likelyto share them.\nIn summary, our participants proposed improvements to our nudge design in three key\nareas: (i) improving existing classifications by extending the source list, (ii) expanding news\nclassifications of nudges in alternate areas, and (iii) targeting users\u2019 interactions with news\non social media.\n3.7 Discussion\nBelow, we elaborate on our results, starting with each research question from Study 1,\nfollowed by opportunities and challenges suggested by the participants in Study 2.\n3.7.1 RQ1: Effect of Nudges on Credibility\nOur regression analyses in Study 1 revealed that users\u2019 credibility ratings were considerably\ndifferent between the treatment (nudged) group and the control group. While other nudge\ndesigns have proven effective in reducing sharing intentions of misinformative content, their\neffectiveness was shown on a particular news genre, such as COVID-19 and HIV [ 319,354].\nIn contrast, we examined the effects of our nudges on a wide variety of popular news items\nsurfacing over multiple days, thus offering a more generalized result. Our intervention pro-\nvides a less authoritative approach that gives users simple but transparent information for\nthem to make their own judgments. News feeds, as they typically present limited informa-\ntion on social media, have few features to distinguish content quality. Tweets from bots,\nfriends, mainstream news, and non-mainstream sources are all given equal weight in terms of\nvisual representation in any feed, making it difficult for users to sift through them. Though\npeople are capable of identifying misinformation, social media makes it challenging to make\ninformed analytical judgments [ 352]. Our results suggest that users might appreciate it if\nsocial media sites provide tangible signals to work through this clutter, which is further\nexemplified by participants\u2019 suggestion to differentiate news and op-eds in Study 2.\nApart from facilitating better perceptions of the credibility of news, NudgeCred may also act\nas a \u201ctranslucent system\u201d [ 124]. The theory of social translucence posits that we should aim\nfor systems that make online social behavior visibleto facilitate awareness and accountabil-\nity. Note that our participants in Study 2 suggested improved recognition of particular types\nof news content on their feed and were more aware of what they were seeing on their feeds.\nOur nudges on news content that are liked or shared by users\u2019 followers or friends could also\nhave similar impacts, wherein users become more awareof their peers\u2019 news consumption\nbehaviors. When their peers like/share misleading news, one may hold the peers accountable\nby pointing out the misleading content. Besides, after seeing the nudges on unreliable con-\ntent, users may restrain themselves from sharing such content and reflect on their sharing\nhabits.\n3.7.2 RQ2: Influence of Political Partisanship on Nudge Effects\nOur regression results suggest that NudgeCred changed users\u2019 perception of credibility irre-\nspective of their political views; that is, there were no interaction effects between political\ncharacteristics and the effects of interventions. This result is consistent with recent studies\nshowing the success of interventions in limiting sharing intentions of misinformation, irre-\nspective of users\u2019 political affiliation [ 387,494].Although some prior literature argue that\ncitizens may view nudges as partisan policies and may not support nudges when they con-\nflict with users\u2019 partisan preference [ 443], other scholars suggest that this behavior can be\ncountered by reducing partisan cues in nudges [ 449]. We incorporated this suggestion in our\ndesign by showing nudges on news content from all political leanings and nudging news con-\ntent in both directions (Reliable, Questionable, and Unreliable). However, in practice, users\ntend to typically follow news based on their partisan preferences [ 241]. In such a setting,\nusers who follow only alternative fringe sources may see mostly Unreliable nudges triggered\non their reports and perceive NudgeCred as partisan. One potential design solution is to\nshow the similar news item from reliable sources, with the same partisan view, to help them\nunderstand the alternatives.\n3.7.3 RQ3: Influence of Political Cynicism and Media Skepticism\non Nudge Effects\nIn our study, we did not find any impact of political cynicism or media skepticism on nudge\neffects. Thisconvincingnatureofournudges\u2014thatnudgesworkedirrespectiveofusers\u2019prior\nmedia skepticism and political cynicism\u2014is promising. Our result for media skepticism\nis aligned with a recent work where media skepticism did not affect nudge effects [ 319].\nResearch suggests that media skeptics, despite significant exposure to alternate sources, still\nseemtohavemoderatetohighconsumptionofmainstreamnews[ 464]. Therefore, ournudges\ncould improve news credibility assessment of both mainstream and non-mainstream sources\nby skeptics in the wild. Scholars suggest that exposure to fake news mediated by belief in\nits realism increases political cynicism [ 32]. Thus, if nudges can reduce belief in fake news,\nit could help mitigate increasing cynicism towards politics. Furthermore, our nudges can be\nutilized as an alternative to censorship by social media, thus helping mitigate the concern\nthat social media apply censorship in a disparate manner across different political affiliation,\nas raised by participants in our formative study.\n3.7.4 Opportunities in Designing News Credibility Nudges\nOur field deployment of NudgeCred showed several opportunities in designing credibility\nnudge in the future. First, participants\u2019 attention to the bandwagon heuristic reveals how\ndesigners can utilize existing Twitter infrastructure in their design. Though the impact of\nthe bandwagon effect in collaborative filtering has been discussed in the literature [ 436], it\nhas been underutilized in a news credibility context. Our study suggests that applications\nsimilar to ours can act as valuable markers of information credibility. Second, participants\nseeking nudges on a wider set of sources (e.g., news and non-news sources), and alternate\ntypes of taxonomies (e.g., news and op-eds) suggests their need for tools to differentiate\ninformation reliability. Comparatively, nudges on tweet actions (e.g., retweet and share)\nmay play a stronger role in curbing the spread of misinformation, as research indicates that\nsharing without thinking is often weaponized for this purpose [ 484]. For example, when users\nclick on the share button, activating a \u201ctimer nudge\u201d\u2014a visual countdown to complete the\naction\u2014could make users rethink before they share [ 481].\n3.7.5 Challenges in Designing Nudges with Heuristics\nOur final evaluation presented several challenges in designing credibility nudges. First, par-\nticipants showed their skepticism towards the selection of heuristics (e.g., bandwagon heuris-\ntic) in design. Though the bandwagon heuristic can be robust and hard to falsify, in an open\nforum such as Twitter, it is open for manipulation. Perhaps, as one of the participants sug-\ngested, feedback on the validity of the question may be helpful. Still, problems may also\nexist with feedback. For one, due to partisan attitude, feedback wars, similar to edit wars in\nWikipedia, might result [ 434]. Additionally, due to frequent updates and the scale of social\nmedia content, feedback from volunteers might be scarce on most items. Perhaps a system\ndesigner can show the distribution of feedback by users\u2019 leanings to reduce the effects of\nfeedback wars and solicit user contributions by promoting items with scarce feedback. Sec-\nond, participants\u2019 concerns with the bandwagon heuristic promoting confirmation bias might\nbe an extension of prior findings that users tend to prefer selecting information (including\npolitical information) consistent with their preexisting beliefs [ 236]. However, scholars have\nshown that the extent of confirmation bias in information selection, particularly in news se-\nlection, is small [ 190]. In the event of confirmation bias, we can computationally de-bias the\nheuristic cue, as in prior works [ 3]. Lastly, audience misperceptions of non-nudged content\nbeing credible indicate an additional challenge in design. This effect has also been demon-\nstrated in a recent work [ 353]. One way to solve this problem would be to add nudges to all\ncontent. Aside from these challenges, one participant (U7) pointed out that \u201cNews might\nchange and the user wil l not see the update when more legitimate questions are added to the\nreplies\u201d. As user interactions accumulate over time, the number of questions in replies could\nchange, wherein the same tweet would be categorized as Reliable at first and Questionable\nat a later time. This change in nudge category stemming from our choice of the bandwagon\nheuristic could imply an inconsistency in nudge design. System designers can incorporate\ndelayed intervention mechanisms and inform users of this cold-start issue. Overall, these\nchallenges inform designers about considerations for designing nudges with heuristics.\n3.8 Implications And Opportunities for Designing Cred-\nibility Nudges\nWe built NudgeCred by fusing the theoretical background on nudges with theories underpin-\nning credibility evaluation. Researchers have the opportunity to explore the nudge categories\nwe built our design around, experiment effectiveness of other heuristics and utilize alternate\nFigure 3.6: Types of nudges based on transparency and mode of thinking. This figure\nemulates Figure 1 by Caraban et al. [ 70]. This work lies in the bottom-right quadrant.\nnudging method. Below, we elaborate a few possibilities around these areas while discussing\npotential considerations.\nExploring Additional Nudge Categories Referring to the four categories of nudges,\ndivided along the two dimensions of transparency and mode of thinking (automatic or reflec-\ntive), we have illustrated how NudgeCred resides on one of the four quadrants\u2014 transparent\nautomatic (see Figure 3.6).Nudge theorists describe transparent nudges with reflective\nand automatic mode as, respectively, reflective decision making and instinctive decision\nmaking [ 186]. Technology-mediated nudging research focus more on transparent reflective\nquadrant [ 70]. For example, Facebook\u2019s \u201cRelated Articles\u201d feature to tackle misinformation\nexemplifies such a nudge design [ 422]. Twitter\u2019s blue check \u201cverified\u201d marker on profiles\nis another example of a transparent automatic credibility nudge. Between reflective and\nautomatic mode of thinking, each has their own benefit. For example, while nudges with\nautomatic mode of thinking can be diminished over time, reflective mode of thinking can\neducate users and have a lasting impact. On the other hand, design considering reflective\nmode of thinking requires additional considerations such as motivating the users and assist-\ning in reflection [ 2]. For example, to motivate users we can show statistics of how often users\nmisread a news tweet as a nudge and to assist them in reflection this nudge can include\nthe list of the most common mistakes. For non-transparent quadrants, scholars propose\nreflective ones as a manipulation of behavior and automatic ones as a manipulation of choice,\nin both cases without users\u2019 awareness. An example of non-transparent automatic nudging\ncould be showing the average reading time of an article which could prompt users to think\nshorter articles as less detailed and less credible. Comparatively, research show fewer work\nin non-transparent reflective quadrant [ 70]. Due to their deceptive nature, designers need to\nconsider ethical consideration while experimenting on non-transparent quadrants. Overall,\nthis is the start of work in this space; much research needs to be done in cataloging and\nevaluating news credibility nudges along the other dimensions spanning the four quadrants.\nExploring Alternate Heuristics for Nudging Credibility Our nudge design is based\non two heuristics under the Agency affordance, drawn from the MAIN model\u2019s list of\ntechnology-mediated affordances affecting credibility judgment. Designers have the oppor-\ntunity to explore the other heuristics in their design. For example, designers could offer\ndesign cues to distinguish news items with/without video footage and prompt a realism\nheuristic from Modality affordance. Or, design cues distinguishing news tweets with in-\nteractive content (e.g., interactive 3D footage or charts) could prompt interaction heuristic\nfrom Interactivity affordance. For Navigability affordance, designers can prompt browsing\nheuristic by providing additional hyperlinks to journalists\u2019 past activities (e.g., MuckRack\nprofile [376]) besides news items.\nExamining Alternate Nudging Method While the original proposers of the concept\ndid not lay out a fixed method for creating successful nudges [ 409], Caraban et. al. recently\ndevised six broad categories for 23 nudging methods used in prior HCI works, namely,\nFacilitate (e.g., default choice and hiding),Confront (e.g., remind consequence and pro-\nvide multiple viewpoint ),Deceive (e.g., add inferior alternative and deceptive visualization ),\nSocial Influence (e.g., enable comparison and public commitment ),Fear(e.g., reduce dis-\ntanceand scarcity) and Reinforce (e.g., ambient feedback and subliminal priming ) [70].\nUnder these categories, NudgeCred utilizes two methods from two categories. First, it works\nas a Facilitate category by facilitating decision making through a combination of color-\ncoding and translucent hidingmethod. Second, it operates as a social influence nudge\ncategory with enabling social comparison method through the use of number of questions\nasked by other responders. Technology-mediated credibility nudges can utilize other meth-\nods from this classification. For example, similar to NewsCube [ 342], designers can use\nconfront category by offering multiple viewpoint method on news items. Or, flashing key-\nwords around news items (e.g., \u201creliable\u201d or \u201cquestionable\u201d) utilizing subliminal priming\nmethod under Reinforce category [ 356], could affect users\u2019 credibility perception of those\nitems.\nDesigning Against Adversarial Agents. Our approach to be transparent suggests that\nadversarial entities, upon knowing algorithmic detail, can manipulate the system. For ex-\nample, by commenting on a factual mainstream news with a question, they can create a\nmisperception of it being questionable. This is a problem that most online platforms struggle\nwith\u2013balancing between being transparent about their algorithm while safeguarding against\nadversaries. Indeed, platforms like Reddit while publishing their ranking algorithms include\n\u201csome fuzzing\u201d to avoid manipulation of their voting system [ 91]. Hence, some opaqueness\nin the algorithm might be desirable. At the same time, platform developers could also mis-\nuse this fuzziness in the algorithm for their own benefit, such as to drive engagement [ 187].\nIndeed, Twitter\u2019s content moderation practice has been controversial in the past, in some\ncases resulting in reversal of moderation decisions [ 273]. Similar controversy could arise re-\ngarding nudging policy. Therefore, designing nudges requires consideration for the multiple\nstakeholders of a social platform\u2014platform developer, consumers and news producers. De-\nsigners would need to consider the degree to which a nudge would be resistant to adversarial\nattacks by each stakeholder. For example, crowds\u2019 question based bandwagon heuristic has\na high-level of susceptibility of manipulation by the consumers compared to the platform de-\nvelopers and news producers. On the other hand, our authority heuristic is more susceptible\nto manipulation by the platform designers compared to the news producers and consumers.\nOverall, a potential solution to this problem would be creating a collaborative standard\nauthorized by all stakeholders. For example, Facebook has already created a third-party\noversight board for content moderation [ 49]. A similar strategy can be applied to determine\nnudging criteria.\nConsidering Shortcomings of Nudging as a Design Approach Despite its success,\nnudging has its own shortcomings. Prior literature proposes that nudges may have dimin-\nished effects in the long term for two reasons: (i) nudges relying on automatic cognition may\nfail to educate the user, and (ii) prolonged exposure may have various effects such as trans-\nform nudge effects into background noise [ 262,444], invoke a feeling of intrusiveness [ 482],\nand reduce users\u2019 perception of autonomy [ 263]. Such effects may lead to unforeseen con-\nsequences. For example, a default choice nudge promoting vaccination that reduced users\u2019\nperception of autonomy resulted in users unsubscribing from the program [ 263]. In our case,\nif users repeatedly encounter their favored political news source labeled as Questionable or\nUnreliable , they could become averse to the design. However, designers can apply several\nstrategies to counter this problem. On one end, they can alter the design over time or\nprompt users to change the intervention settings over time [ 247]. As an alternate, they can\nalso choose to deploy reflective nudges which are less susceptible to the diminishing effect.\nA potential problem with the altering design is that news consumers may need to re-learn\nhow nudges operate. Regardless, designers would first have to understand the rate at which\nnudge effects diminishes, a direction for future research.\n3.9 Limitations and F uture W ork\nOur work is not without limitations. Our Study 1 was conducted in a controlled setting as\nopposed to in the wild. However, we see two reasons that suggest that our results demon-\nstrating the utility of nudges in credibility assessment could extend to naturalistic Twitter\nsetup as well. First, research shows that self-reported measures pertaining to social media\nusage correlate with observed behavior in the wild [ 177,353]. Second, large-scale survey-\nbased research on nudges pertaining to news on social media, show that nudges affect related\nattitude, such as sharing intention of misinformation [ 319,354].Our second limitation re-\nlates to choice of population. Because we tested variables (e.g., political ideology and media\nskepticism) that has different meaning across countries, we had to limit our experimental\npopulation to the US. To generalize our findings to the global population, future research\ncould replicate our study in the context of each country. Third, our recruitment had limi-\ntations that are characteristic of any online service-based recruitment. Though we may not\nhave obtained the true nationally representative sample in the US, research suggests that\nQualtrics provides reasonably representative US sample (approximately 6% deviance from\nthe US census) around demography such as gender, age, race and political affiliation [ 197].\nOverall, a large-scale Twitter deployment might reconcile these concerns in the future. We\ninitially attempted to do so by contacting a large number of Twitter users, without much\nsuccess due to a lack of platform-level cooperation (Our research account was repeatedly\nblocked). While a 2015 study had successfully piggybacked on Twitter\u2019s infrastructure to\nrun large-scale recruitment efforts on the platform [ 173], we were unable to do so, despite fol-\nlowing similar strategy. We anticipate that changes to Twitter\u2019s policies may have prevented\nus from running large-scale recruitment on the platform [ 208].\n3.10 Conclusion\nIn this study, we provide evidence that a nudge-based design that directs users\u2019 attention\nto specific social cues on the news can affect their credibility judgments. We used three\nnudges: Reliable, applied to mainstream news tweets without questions in replies; Question-\nable, applied to mainstream news tweets with questions in replies; and Unreliable , applied\nto non-mainstream news tweets. Our experiment suggests that users who saw tweets with\nReliablenudge as more credible, and tweets with Questionable and Unreliable nudges as less\ncredible compared to the control users. Moreover, our nudges were not affected by users\u2019 po-\nlitical preferences, political cynicism, and media skepticism. Through interviews, we found\nevidence of how nudges can impact users\u2019 news consumption and how the current design\ncan be improved. This research proposes further exploration of nudge-based system design\napproaches for online platforms.\nChapter 4\nT ransparencyCue: Designing\nT ransparency Cues in Online News\nPlatforms to Promote T rust\n4.1 Introduction\nWhile growth in communication technology has connected news consumers to diverse sources\nof information, it has also prompted a steady decline in public trust in the mainstream\nmedia, as well as the exploitation of public opinion through the spread of \u201cfake news\u201d or\nmisinformation [ 27,78]1.A partial cause of the larger issue of distrust in mainstream\nmedia might be attributed to news consumers\u2019 inability to distinguish quality journalism\nfrom deceptive content; this inability is the focus of this study. To this end, scholars suggest\nadopting greater level of transparency within the news-making process [ 289,359,407].This\nshift from a \u201ctrust me\u201d to a \u201cshow me\u201d journalism has the potential to promote trust among\nreaders, especially by protecting against erroneous and deceptive sources of reporting [ 246,\n311].Online news platforms have the potential to offer novel interface designs to support\nsuch an increase in transparency [ 48,89].\nDespite calls for transparency in news, surprisingly little is known about how to promote\n1part of this chapter appears in [ 44]\n70\ntransparency to increase trust in news articles, especially from a design perspective. In\nthis respect, designers in news organizations need to consider the competing perspectives\nof stakeholders; for example, journalists may want to protect certain information, whereas\nnews consumers may expect it to be revealed. Furthermore, journalists and consumers\nhave to consider organizational policy. Although some prior scholarly work has explored\ntransparency practices in journalism [ 79,175,220], these works discuss them without a\nparticular focus on design and without considering the perspectives of both stakeholder\ngroups. Some recent work has promoted transparency standards for news websites [ 369],\nbut they focus largely on site-level measures instead of article-level measures. As discussions\nto support transparent journalism are just starting to gain traction in HCI communities (see\nthe CHI\u201919 workshop on the topic [ 4]),we have yet to identify effective design principles\nthat can guide the design of these user interfaces.\nThis work bridges the gap between communication literature and HCI design in terms of\npresenting transparency in news articles. We examine the perspectives of two stakeholders\u2014\njournalists and news consumers\u2014to inform designers of ways to embed transparency in\nnews articles. In particular, news organizations both large and small with internal design\nteams (e.g., The New York Times [ 457]) can benefit from the findings of this work. Addi-\ntionally, news aggregators (e.g., Google News) and other third-party news providers (e.g.,\nAllSides.com ) may also choose to adopt our design suggestions on how transparency should\nbe practiced in digital news articles. Communication scholars have suggested that people\ntake into consideration certain information characteristics when evaluating whether a piece\nof information is trustworthy. People assess the sourceof the message (e.g., the author\u2019s ex-\npertise) and the message itself (e.g., the quality of the message), and they use these insights\nas meaningful cues to evaluate the overall trustworthiness of a piece of information [ 299].\nCombining the concept of design cues with transparency, we argue that disclosing certain\nsource- and message-level transparency cues within news articles can be an important step\ntowards designing trustworthy online news websites [ 139,220,435]. Overall, we ask:\nRQ. How can designers utilize transparency cues to promote trust in digital news articles\nwhile considering the perspectives of journalists and news consumers alike?\nRQa. What aspects of journalistic practice do news consumers and journalists want\ndisclosed within news articles as transparency cues?\nRQb. What should designers consider in promoting transparency cues for news consumers\nand journalists?\nTo answer these questions, we interviewed journalists and news consumers. Our journalist\npool consisted of 15 journalists with diverse reporting backgrounds who worked in local, na-\ntional, and international newsrooms. For our news consumer interviews, our pool comprised\n16 citizens from both local and online communities with novice to savvy news-reading behav-\niors. We complemented our interviews with a scenario-based design approach [ 72,202]\u2014a\nuser-centered design approach that employs prototype mockups and descriptions to help\nend-users envision a future system and how they will use it. We provided our interview\nparticipants with a scenario: a prototype mockup developed with two sets of transparency\ncues. These cues disclose underlying journalistic practices pertaining to the message being\nreported and the sourcereporting that message (see figure 4.1). Stimulated by our scenario,\nparticipants recommended various transparency cues capturing source and message charac-\nteristics to address the reasons for underlying distrust, with some additional transparency\ncues to reveal the process of reporting. Many of these suggestions concern information which\nis fundamental to high-quality journalistic news reporting.\nOur analysis revealed that news consumers identified two main areas in which increased\ntransparency could improve trust; namely, the level of objectivity in a report and the qual-\nity of the evidence that underlies the claims in a report. For objectivity, our analysis showed\nthat designers have the opportunity to incorporate transparency cues to reveal biases in news\nselection and framing. For evidence, our news consumers asked for transparency in evidence\npresentation, anonymous sourcing, fact-checking, and correction. Meanwhile, our journalists\nproposed transparency in evidence presentation, the reporting process, and personal/organi-\nzational conflicts of interest (e.g., gifts journalists might receive and stakes in other business\norganizations owners might have). Both groups suggested the need for transparency cues\nto highlight evidence in news reporting, such as by including verification materials. The\nscenario design also prompted participants to point out additional considerations, such as\ndesigning for ease of comprehension, reducing bias while presenting transparency indica-\ntors, and including appropriate details within the transparency feature (such as displaying\nboth the number and nature of corrections to an article). Other suggestions include design-\ning markers for distinguishing reporting quality within news items, and for distinguishing\nbetween news and non-news items. When we compare the responses between our two stake-\nholder groups, we see conflicting suggestions that would require trade-offs in design. For\nexample, trade-offs exist between being fully transparent and preserving autonomy by plac-\ning limits on transparency. Similar trade-offs exist between opting for simple features to\nease comprehension and including sophisticated features to illustrate appropriate nuances.\nWe discuss how designers can utilize existing journalistic practices in designing transparency\ncues catering to our participants\u2019 areas of interest, and thus, how they can consider the per-\nspectives of both stakeholders in their designs. However, to draw a more complete picture,\nfuture work would need to consider news organizations and sources (people) themselves as\nstakeholders of news. Furthermore, while participants responded with consistent themes\nin the interviews, without properly controlled experiments, our results are not evidence of\nefficacy of the design ideas. Still, our results have implications for design practitioners in\nhighlightingappropriatejournalisticpracticesonnewswebsitesthroughtransparencyandfor\ndesign researchers in future investigations of balancing the constraints imposed by stakehold-\ners, considering remaining stakeholders, and conducting controlled experiments to evaluate\nefficacy.\n4.2 Related W ork\n4.2.1 Defining T ransparency in Journalism\nWith rapid improvements in communication technology, the news-gathering process has\nshifted from a model of verification (the principal value being getting things right and ex-\nercising caution against getting things wrong) to a model of assertion, where the principal\nvalue is to get the news out fast, even at the expense of rigorous verification [ 224]. This shift\nmay result in journalists making more mistakes, thereby directly affecting news consumers\u2019\ntrust in journalism [ 19]. Some scholars argue that transparency (or openness) could be a\nmechanism for building both trust and accountability [ 10,358]. In this work, we define\ntransparency as this notion of openness about the news makers themselves, their journalistic\nroutines and practices, and their decision-making processes [ 465]. Prior work shows that one\nof the ways journalists practice transparency is through disclosure of information, known as\ndisclosure transparency [220]. Disclosure transparency can be realized in different ways, such\nas how story assignments are decided over meetings, disclosing verification process, linking\nsource material for a report, and acknowledging and correcting errors [ 195,256]. When\ndiscussing transparency in this work, we utilize this principle of disclosure transparency.\n4.2.2 Existing T ransparency Practices in Journalism\nThe earliest examples of transparency practices in journalism date back to the 1930s, when\nbylinescontainingthenamesofreportersresponsibleforanarticlewerefirstintroduced[ 405].\nPractices have evolved from early practices like the use of ombudsman columns (which goes\nback to the 1960s) to newer ones, such as inviting users to experience the journalistic process\nfirsthand (e.g., attending news meetings) [ 100,112]. For a comparison of transparency\npractices across newsrooms, see [ 459]. Prior scholarly works looked at various aspects of\ntransparency in online news. Examining three online newspapers (The New YorkTimes, The\nGuardian, andDagensNyheter), scholarsfoundthateachoftheseorganizationsimplemented\ndifferent sets of transparency features [ 220]. Revers found wide adoption of transparency\nin social-media-aided reporting [ 381]. Offering transparency features across organizations\nis a comparatively recent phenomenon. For example, some social media sites have begun\noffering transparency in news content (e.g., through a corrections and ethics policy) [ 132,\n423,445,455]. Despite significant work, research seems to look at transparency in isolation,\nfrom either journalists\u2019 or news consumers\u2019 perspectives alone. We bridge this gap in existing\nwork by exploring both journalists\u2019 and news consumers\u2019 views on a problem scenario.\n4.2.3 Designing for T rust in News Through Information Disclosure\nHCI research has been considering trust as a driver for design for a considerable amount\nof time in such areas as e-commerce, remote work, and digital currency [ 55,95,382,399].\nGenerally, these works use two concepts of trust: trust being mediated by technology for\nindividual-to-individual relationships and technology being the object of trust [ 97,179]. Ex-\nisting works support that openness (or transparency) influences trust [238]. In this work,\nwe explore the trust relationship between individuals and information. In online informa-\ntional systems, particularly for news, trust is often considered synonymous with credibil-\nity [140,448,460], and we adopt this concept in our work. Communication literature further\nguides us around the relationship between information disclosure and trust.\nIncommunicationliterature,trusthastypicallybeenconsideredasubsetofthelargerconcept\nof credibility, where individuals who \u201ctrust\u201d a given speaker (i.e., the source) or piece of\ninformation (the message itself) also deem it more credible [ 299]. Studies have suggested that\nwhen people evaluate the trustworthiness of online information, they consider a number of\ncharacteristics. These may include evaluations of who conveyed the information (the source),\nhowitwassaid(themessage),andwhereitwassaid(mediumorchannelcharacteristics)[ 230,\n299]. However, research also indicates that most people don\u2019t spend a tremendous amount\nof time engaging in close analysis of online content, often relying instead on surface-level\nfeatures, such as the quality of a website\u2019s design or how easy it is to use [ 139]. Several\ntheories have expanded this observation and shown that individuals have only a limited\nnumber of cognitive resources to evaluate information online; therefore, they often rely on\ncognitive heuristics to evaluate information [ 128,435]. By cognitive heuristics, we mean the\nmental shortcuts individuals use to ignore some information on a site while paying attention\nto other information when evaluating the trustworthiness of the claims presented. On any\ngiven website, various design features serve as cues to trigger a heuristic. For example,\nFacebook uses \u201clikes\u201d as a cue to trigger the \u201cpopularity heuristic\u201d of a given post [ 54].\nSeveral researchers have attempted to explain the role that these feature cues play in helping\npeople evaluate information. Fogg\u2019s Prominence-Interpretation Theory suggests that people\nevaluate the trustworthiness of a website based on feature cues that attract users\u2019 attention\nthe most [ 140]. For example, only if a user notices a feature cue (such as an indicator of\nan author\u2019s expertise) would that cue have an impact on the user\u2019s overall perception of the\nsource\u2019s credibility. Sundar\u2019s MAIN Model also suggests that credibility is conveyed online\nby four broad website characteristics that serve as their own cues to users for denoting the\ncredibility of information [ 435].\nDrawinguponthenotionthatfeaturecuescanbeusedaswaystotriggerheuristicevaluations\nof a given piece of content, we explore the design of a series of disclosure transparency cues\nthat aid users in evaluating the trustworthiness of a given piece of online news. Literature on\nthe subject does not provide any exhaustive list of features for disclosure. Therefore, when\ndesigning our problem scenario, we selected a few features mentioned in existing literature\nthat could influence users\u2019 trust. For example, studies have shown that a source\u2019s apparent\nexpertise has a significant positive impact on users\u2019 trust in it [ 302]. Similarly, message-level\ncharacteristics, such as how crucial pieces of information in an article are emphasized or\nframed can improve the article\u2019s level of transparency and cue readers to evaluate its claims\nmeaningfully. In Section 4.3.1, we explain in greater detail how we used these characteristics\nto develop our scenario.\n4.2.4 Effect of T ransparency on Perception of T rust\nThough scholars suggest a positive association between transparency and perceptions of\ncredibility [ 195,221,246], when investigated, effects of transparency on news consumers\u2019\nperceptions of a news article\u2019s credibility seem somewhat ambiguous. While one prior study\nsuggests that a single transparency feature had almost no effect on readers\u2019 perception of\nnews credibility [ 223], a recent study supports the idea that multiple transparency indicators\ncan improve an audience\u2019s perception of news articles\u2019 credibility [ 103]. News consumers may\nalsoprefercertainfeaturesoverothers(e.g., hyperlinkingsourcematerialoverdescribinghow\nan article was framed) [ 222]. Taken together, there seems to be some effect of transparency\non trust; however, proper sets of features must be constructed, and their construction is the\nfocus of this work.\n4.3 Interviewing News Consumers and Journalists Us-\ning a Scenario\nWe studied our research question through interviews. For this purpose, we built a scenario\nto stimulate our participants. Below, we describe the scenario and our recruitment process.\n4.3.1 Developing a Scenario\nOne of the main challenges in designing transparency attributes in news websites to build\ntrust is obtaining stakeholders\u2019 reactions to a system that has not yet been built. In such\ncases, scholars have suggested opting for an alternate approach, called a scenario-based ap-\nproach, to facilitate users\u2019 reactions [ 72]. A scenario not only provides concrete examples to\nstimulate users\u2019 responses, but it also provides a holistic view of future possibilities. Further-\nmore, scenario narratives can be made flexible and adapted to expand a user\u2019s imagination.\nIn his seminal work on scenario-based design, Jack Carroll suggests that such an approach\nmotivatesamoreintegrativeproblemanalysiscomparedtotraditionalrequirementgathering\ntechniques [ 392]. We exploited this approach to build an example news article with multiple\ntransparency cues. Our scenario is powered by disclosing two sets of transparency cues:\none that captures the characteristics of the message being reported, and one that shows the\nquality and expertise of the sourcereporting that message. Source- and message-based cues\nare fundamental for signaling the underlying credibility of a report [ 435], and are thereby\nkey to enhancing users\u2019 trust in journalistic practices. Figure 4.1shows the scenario we\ndeveloped. The left side of this figure contains a news article, and the right side contains the\ntransparency cues. Below, we describe how we adopted and implemented each of the design\ncharacteristics shown.\nSource Credibility Cues\nPrior literature indicates that source expertise is one of the primary indicators that people\nuse to evaluate the credibility of a news article. In this context, users may consider sources\nfrom two perspectives: sources can be taken to be either the organizations that employ\njournalists or the journalists themselves. In our design, we disclose three indicators of a\njournalist\u2019s expertise, including experience in years, number of retractions, and domain of\nexpertise. Here, we contextualize the number of retractions by presenting it together with\nthe total number of articles written by the journalist. For example, 2/100 indicates that\nthe author had 2 retractions out of the 100 articles she wrote. In Figure 4.1, we show\nthis information in the upper-right corner as part of feature \u201ca\u201d. We used this terminology\n(features \u201ca,\u201d \u201cb,\u201d and \u201cc\u201d) during our interviews to simplify references to specific features\nfor our participants.\nMessage Credibility Cues\nTo give readers cues about the quality of an article, we turn to existing journalistic practices\nin article writing. We rely on cuing users with the presence of two types of attributes inside\na report: attributes identifying the degree of completeness of crucial information in a report\n(as shown in feature \u201cb\u201d) and how information is presented within the report in terms of its\nuse of language characteristics that could indicate bias (as shown in feature \u201cc\u201d).\nCuing the Presence of Crucial Information. As early as the mid 19th century, tra-\nditional journalism has followed the practice of formatting a story by first presenting the\nNB The News Beat\nWho\n local and federal law enforcement officers\nWhat\n search\noffices of Roman Catholic Archdiocese of \nGalveston HoustonWhere\nWednesday When\nfor evidence in a clergy sexual abuse case Why\nsurprise search How\nNews Snips\nReporting Style\nDirect Quote\nIndirect Quote\nClaims made\n1st hand account\n2nd hand accountHigh SNLAuthor: Laurie Goodstein\nPast RetractionsReporting Tenure 10 years\n2 of 100\nExpertise National Religion Correspondenta\nb\ncFigure 4.1: Our scenario with three transparency features. Here, feature \u201ca\u201d corresponds to\nsource characteristics conveying the expertise of the author; features \u201cb\u201d and \u201cc\u201d are message\ncharacteristics showing, respectively, crucial details about the event and the reporting style.\nIn feature \u201cc,\u201d reporting style includes whether the article is high or low in summary news\nlead (SNL) or inverted pyramid style reporting, the proportions of first- and secondhand\naccounts, the proportions of direct and indirect quotes, and the number of claims made.\ncrucial information about an event, called main event descriptors [ 362]. These main event\ndescriptors answer fundamental questions about an event, and these questions are some-\ntimes referred to as 5W1H: who, what, where, when, why , and how. To give users cues as\nto the presence or absence of these descriptors, we highlight each of them in our design\nwith different colors, as shown in Figure 4.1in the section named \u201cNews Snips\u201d (or feature\n\u201cb\u201d). This feature was inspired partially by Wikipedia\u2019s Infoboxes [ 490], and it isolates the\nmost important information within a news report. These descriptors can also be calculated\ncomputationally\u2014multiple prior works have calculated the 5W1H descriptors by applying\nnatural language processing techniques [ 203,267,326,479,480].\nCuing Reporting Style. To give readers cues as to how a report is written, we resort\nto identifying two aspects of standard journalistic practice in a report: how information is\npresented and how it is attributed to its source. Journalistic practice in structuring news\narticles varies, though a handful of patterns are commonly used [ 189]. In our design, we focus\non \u201chard news,\u201d or news that involves political, economic, and social issues [ 269]. This is also\na prevalent type of news in the misinformation domain, and these articles tend to follow a\nparticular pattern. Prior literature suggests that journalists traditionally format hard news\nby organizing information in a top-down style, starting with the most important information\nbefore presenting supporting information in diminishing order of prominence [ 362]. This\nformat is also known as the \u201cinverted pyramid style,\u201d and it is a common structure in\ncontent from news agencies like the Associated Press, whose content is frequently syndicated\nto many national and international outlets. We examine the degree to which a report follows\nthis standard of writing through a metric called the summary news lead, or SNL [ 125]. In\nFigure4.1, the left side of feature \u201cc\u201d visualizes this metric as high or low SNL, indicating\nthe degree to which a report follows this style.\nAnother crucial property of an article is the sources underlying it. Traditionally, journalists\ndivide sources into two categories: firsthand accounts and secondhand accounts. Firsthand\naccounts are retellings of reporters\u2019 direct observations of an event, while secondhand ac-\ncounts come from authoritative sources with direct knowledge of an event. While both first-\nand secondhand accounts are useful, firsthand accounts are more accurate [ 297]. To give\nusers cues as to the nature of sources used in an article, we identify the proportion of claims\nbased on first- and secondhand accounts.\nBiasreductionisyetanotherstandardjournalismpractice. Toidentifythepresenceofbiasor\nsubjectivity in a report, we examine the framing of quotes in reported secondhand accounts.\nReporters can quote secondhand accounts either directly or indirectly [ 38]. They may also\nintroduce their own biases in the process by using framing that alters perspectives [ 172,271].\nFor example, a journalist may describe a secondhand account using the word \u201cclaim\u201d to\nexpress doubt in the quoted statement. In prior works, natural language processing has\nJourn. Gender Exp. (yrs) Journ. Gender Exp. (yrs) Journ. Gender Exp. (yrs) Journ. Gender Exp. (yrs)\nJ1 Male 7 J5 Female 20 J9 Male 5 J13 Male 5\nJ2 Male 11 J6 Male 5 J10 Female 9 J14 Male 6\nJ3 Female 3 J7 Female 3 J11 Female 7 J15 Male 10\nJ4 Female 3 J8 Male 35 J12 Female 3\nTable 4.1: Demography of our journalist pool. \u201cJourn.\u201d here stands for \u201cjournalist.\u201d\nbeen applied to detect these kinds of cues [ 400,425]. Both observation types and biases are\nshown to the right of the article as feature \u201cc\u201d in Figure 4.1.\n4.3.2 Recruitment\nUsing this design, we interviewed 15 journalists from various news organizations and 16\ngeneral news consumers recruited from the local community and online communities on\nReddit. Our interviewee pool primarily resided in the United States, with the exception of\ntwo international journalists. We recruited journalists through a combination of personal\ncontacts and social media (Twitter and Facebook). We recruited a majority of our journalist\npool ( n=11) from personal contacts. Due to the recent focus on misinformation in US\npolitics, we also searched for journalists covering politics and misinformation on Twitter\nthrough keyword searches of Twitter bios containing a combination of the following terms:\n\u201cjournalist\u201dandanotherwordfrom\u201cmisinformation,\u201d \u201cdisinformation,\u201d and\u201cpolitics.\u201d After\nmanually verifying the collected Twitter profiles, we compiled a list and reached out to eight\njournalists via email. Out of the eight, two eventually participated in an interview. On\nRole Network Audience\nAnchor, editor, reporter (corporate, court,\nforeign, misinformation, politics),\ntechnology researchABC, AP, Athens Messenger, Buzzfeed, CBC, Daily\nReflector, freelance, KBZK, MotherJones, News4SA,\nToledo Blade, Roanoke Times, WSJLocal/metro,\nnational,\ninternational\nTable4.2: Professionalbackgroundofourjournalistpool. Inthenetworkcolumn, \u201cfreelance\u201d\nindicates that the journalist is not associated with an organization. Note that we aggregated\nthe roles of journalists and their associations to news networks and audiences to ensure\nanonymity, as required by the IRB. Knowledge of network affiliation and role would have\nbeen enough to reveal the identities of several participants.\nNews Cons. Gender Profession Political Orient. Leaning\nU1 Male Attorney Democrat Conservative\nU2 Male Real estate agent (veteran) Libertarian Conservative\nU3 Male Residential service Republican Conservative\nU4 Male Educator (retired) Democrat Liberal\nU5 Female Director (local theater) Democrat Liberal\nU6 Male Construction management (ex-police) Libertarian Conservative\nU7 Male Software developer Independent Moderate\nU8 Female Graduate student (neuroscience) Democrat Moderate\nU9 Male Manager (food service) Libertarian Moderate\nU10 Male Undergraduate student (geography) Independent Moderate\nU11 Male Undergraduate student (aerospace) Democrat Liberal\nU12 Female Financial advisor \u2013 Liberal\nU13 Female Management consulting \u2013 \u2013\nU14 Female Special education teacher \u2013 \u2013\nU15 Female Civic organization (ex-nurse) Independent Liberal\nU16* Female Civic organization \u2013 \u2013\nTable 4.3: Demography of our news consumer pool. We asked demographic questions at the\nbeginning of each interview (see Appendix A for the list of questions). Note that some of\nthe participants chose not to specify a political affiliation. * This participant was a former\njournalist.\nFacebook, we joined an invite-only Facebook group of international journalists (IJNet2),\nwhich comprises a global network of more than 90,000 media professionals.We posted a\nrecruitment advertisement in this group and were able to recruit 2 international journalists.\nThrough these combined techniques, our final journalist group consisted of 15 journalists,\nwith 2 reporters residing outside the US. Our 15 journalists (hereinafter referred as J1\u2013\nJ15) had varying journalism experience, including such roles as anchor, editor, reporter\n(corporate, court, foreign, misinformation, politics, social media) and technology research.\nTheir network affiliations included ABC, AP, Athens Messenger, Buzzfeed, CBC, The Daily\nReflector, freelance, KBZK, MotherJones, News4SA, Toledo Blade, Roanoke Times, and\nWSJ. The distribution of journalists\u2019 genders was even. Their experience in the industry\nranged from 3 to 35 years, and they served audiences at varying levels, including local/metro\n(n= 7), national( n= 6)andinternational( n= 2). Tables 4.1and4.2showthedemography\nand professional background of our journalist pool. To preserve journalists\u2019 anonymity, we\ndo not report their roles and organizations individually.\n2https://www.facebook.com/IJNet/\nFor news consumer recruitment, we reached out to the local Chamber of Commerce and\nseveral local institutions (e.g., theaters, schools, and civic organizations). Additionally, we\nadvertised on Reddit using multiple approaches. We posted on two subreddits dedicated to\nsurveys, r/favors and r/samplesize . We also sent direct messages to the top 10+ most\nactive members (during the month when we were recruiting) in news and politics subreddits,\nsuchas r/politics ,r/news,r/worldnews , and r/inthenews . Weresortedtosendingdirect\nmessages because the moderators of these subreddits did not allow us to post recruitment\nadvertisements. we reached over 50 users through direct messages sent from a research\naccount. We selected the most active members of each community based on the number of\ncomments users in those subreddits posted that month, which we calculated using Bigquery3.\nWe also advertised through several mailing lists at our university. Overall, among our pool of\nnews consumers, we had 2 university students, 2 Reddit users, and 12 participants from local\ninstitutions. Weofferedournewsconsumers$15giftcardsforparticipatinginourinterviews.\nTable4.3shows the demography of our pool of news consumers. Considering users\u2019 political\nleanings (the rightmost column), our news consumer pool seemed fairly balanced. We took\npoliticalleaningintoconsiderationbecauseitaffectsusers\u2019perceptionsofthetrustworthiness\nof various news sources [ 215].\n4.3.3 Interview Procedure and Analysis\nOur semi-structured interviews with participants took place mostly over Zoom video call\nsoftware, though eight interviews with news consumers took place in person. A typical\ninterview lasted 40\u201370 minutes. Each interview was recorded and transcribed verbatim by\nthefirstauthorforsubsequentanalysis. Usingthegroundedtheorymethod[ 81], thefirstand\n3https://bigquery.cloud.google.com\nsecond authors open-coded all the interviews and came up with an initial set of themes4.\nIn this phase, these authors read all the transcripts multiple times to determine codes.\nNext, these two authors discussed the codes with the other authors to resolve inconsistencies\nand determine relationships between the codes through axial coding (e.g., combining news\nselection and framing into objectivity in section 4.4.1).After repeating this process multiple\ntimes, we revised the codes into a final set of themes. We discuss those final themes as they\npertain to our research question in the next section.\nTo summarize, our interviews with the participants (journalists and consumers) revolved\naround transparency factors related to trust through a series of questions pertaining to rea-\nsons for distrust of media ( In your lifetime, do you think the news industry has changed?\nIn what way? ), how emergence of fake news affects news consumption ( As you are probably\naware, the subject of fake news is now a popular topic. Has this focus on fake news impacted\nyour news consumption in any way? ), and through a discussion on possible design improve-\nments (after viewing the design scenario, W ould there be any other interactive-type features\nthat you would think could be beneficial? ). See Appendix A for the full list of questions.\nFor each participant pool, we focused our analysis on two sub-RQs: (RQa) What aspects of\njournalistic practice do news consumers and journalists want disclosed within news articles\nas transparency cues? (Sections 4.4.1and4.5.1) and (RQb) What should designers consider\nin promoting transparency cues for news consumers and journalists? (Sections 4.4.2and\n4.5.2). However, participants\u2019 responses also varied before and after seeing the scenario.\nThe answers to the sub-RQs are summarized in Table 4.4.\n4While some work in CSCW and HCI provides inter-coder reliability for the grounded approach [ 292], it\nis typically neither appropriate nor required due to a lack of a predefined coding scheme [ 66]\nPool (Section)Before Showing the Scenario (Section)After Showing the Scenario\nRQa. What aspects of\njournalistic practice do\nnews consumers and\njournalists want disclosed\nwithin news articles as\ntransparency cues?News\nConsumers(4.4.1)Transparency in objectivity of\nnews selection and framing\n(4.4.1)Transparency in four aspects of\nevidence: presentation, sourcing,\nverification, and correction(4.4.1)Transparency in author expertise\nJournalists (4.5.1)Transparency in reporting process ( 4.5.1)Transparency in evidence presen-\ntation\n(4.5.1)Transparency in conflict of inter-\nest\nRQb. What should\ndesigners consider in\npromoting transparency\ncues for news consumers\nand journalists?News\nConsumers(4.4.2)Designingforeasycomprehension ( 4.4.2)Hyperlinking without taking away\nfrom the article\n(4.4.2)Reducing bias considering con-\nsumer cynicism\nJournalists (4.5.2)Presenting complicated details\nwith features\n(4.5.2)Contrasting attributes between\norganizations\n(4.5.2)Twodimensions fordistinguishing\narticle quality\nTable 4.4: Theme summary split by when each theme emerged\u2014before or after showing the\nscenario to the participants. Note that while responses aligned with certain themes emerged\nboth before and after scenario exposure, the themes\u2019 positions in this table are dictated by\nwhen they emerged most commonly.\n4.4 News Consumer Perspective\nHere, we outline results from our news consumers divided into themes that emerged in our\nanalyses. We contextualize them with respect to our two sub-questions regarding attributes\ntodiscloseastransparencyanddesignissuestoconsider. Notethatweredactedsomeentities\n(e.g., name of a news organization) in our quotes for the sake of anonymity.\n4.4.1 RQa: What aspects of journalistic practice do news con-\nsumers want disclosed within news articles as transparency\ncues?\nAnalyzing the responses to our interview questions, we found three aspects of reporting\nregarding source and message to consider for transparency design that may improve trust in\nnews media. We discuss each aspect below.\nT ransparency in objectivity of news selection and framing\nWe identified three notions in our interviews that collectively suggest that the lack of trust\nin the media is partially derived from a perception that the media is losing its ability to be\nobjective in its reporting. Specifically, news consumers highlighted that current practices\nof heightened polarization, opinion-laden reporting, and sensationalism in headlines have\nincreased mistrust. In combination, these themes show a lack of objectivity in two aspects\nof news reporting: news selection and news framing . Here, news selection refers to the\nprocess of selecting stories to cover, and news framing refers to how reporters make certain\ninformation more salient in an article [ 106,489]. We present these themes below.\nMany of our news consumers (9/16) emphasized that readers\u2019 perceptions of polarization in\nthe media and bias in news stories are two reasons behind distrust of the news. Some of this\nbiasisexhibitedin news selection , orwhatisprioritizedinnewscoverage. Newsconsumers\nillustrated their view through examples, such as conservatives feeling that left-leaning news\norganizations prioritize negative coverage of right-leaning politicians and issues, and vice\nversa.\n\u201cThe British tanker gets taken [captured] in the Straits of Hormuz [by Iran]. But that\u2019s\nnot the headline. The headline is T rump cal l Ocasio [a Democratic congresswoman]\nbad name and told her to go back to wherever she came from. \u201d\u2014 U2\n\u201cLike I said earlier, they want to get a certain story. And then they build the facts\naround what they want, how they want to portray the story, instead of actual ly just\nreporting the news. \u201d\u2014 U12\nOn top of news selection, news consumers (5/16) often saw news articles loaded with opinion\nand complained that news organizations frameinformation based on a particular agenda.\nIf readers are unable to differentiate between opinion and news, they may run into the pitfall\nof considering everything opinion and consequently distrusting journalistic news.\n\u201cAnd even within the same paper, I think it\u2019s easy to lose sight of whether it\u2019s an\nopinion piece or it\u2019s an analysis. That\u2019s another thing they (news papers) say, \u201cit\u2019s\nnews analysis. \u201d But the analysis is loaded with opinion. \u201d\u2014 U5\n\u201cI\u2019m just giving an example. An earthquake happened. And they show the one building\nthat fel l down and say it\u2019s destruction, and that\u2019s not real ly what happened. \u201d\u2014 U12\nSome of our news consumers (4/16) also noted a lack of objectivity in the form of un-\nrepresentative headlines . Given the relatively recent influx of alternative news sources,\ntraditional organizations are trying different tactics to seize the attention of consumers.\nSince many people read only headlines, news organizations often attempt to gain consumers\u2019\nattention by writing headlines that are considered clickbait.\n\u201cClickbait is a big problem. Even highly reputable sources are resorting to sensationalist\nheadlines at times to grab attention. And obviously, sensationalism has always sold.\n\u201cIf it bleeds, it leads\u201d has been a line for decades. \u201d\u2014 U7\nTaken together, these findings suggest that news consumers are concerned that modern\njournalism is losing its capacity for objectivity. Some see this lack of objectivity in partisan\nreporting, while others observe it in how reporters choose their words. Some readers also\ntake issue with headlines that either express a partisan view or engage in some form of\ntrickery to entice users to click and read. These concerns could be a byproduct of \u201cagenda\nsetting\u201d[107]. Prior research has argued that, as part of \u201cagenda setting\u201d, news organizations\noften push a certain narrative by selectively publishing a subset of news stories and focusing\non particular pieces of information within a given story [ 119,291,404]. Taking this aspect\ninto consideration, system designers can design cues to distinguish high-quality articles from\nlow-quality articles (discussed in sections 4.6.2and4.6.2).\nT ransparency in four aspects of evidence: presentation, sourcing, verification,\nand correction\nNext to objectivity, our news consumers expressed concerns with how current journalistic\npractice uses facts and evidence in reporting. Participants focused on four areas relevant\nto this topic: (1) the presence of evidence details, (2) the use of anonymous sources, (3)\ndecreasing levels of fact-checking, and (4) hard-to-find corrections. Below, we discuss these\npoints regarding evidence.\nThe presence of evidence details was one important aspect for consumers (4/16) in\nregard to trusting the legitimacy of news reporting. According to our news consumers, links\nto source materials and information on all named parties in an article would help users better\ndetermine the trustworthiness of an article.\n\u201cMaybe if it has statistics and similar stuff in it... where that information come from?\nIf you know where the source came from, you can kind of test the legitimacy. \u201d\u2014 U10\nNewsconsumers(5/16)alsoreferredtooneparticularaspectofsourcing\u2014therisein reports\nbased on anonymous sources \u2014as a problematic trend in news media and a reason for\ndoubting the trustworthiness of such reports. Some news consumers suggested that much\npolitical reporting now relies on anonymous sources, while others pointed out how biases in\nanonymous sources compel them to doubt the veracity of such reports.\n\u201cCertainly, anytime anyone quotes an anonymous source, it\u2019s a suspect. [Based on]\nThe background of that anonymous source, what biases do they have? \u201d\u2014 U14\nIt has long been a common practice in journalism to issue retractions and corrections when\njournalists have reported something inaccurately. Some news consumers (2/16) expressed\nconcern that modern journalism either seems to check facts less frequently, or that journal-\nists often don\u2019t correct themselves when they make mistakes in reporting. These concerns\nabout a lack of visible corrections and retractions could indicate a lack of accountability in\nreporting.\n\u201cI think the biggest problem with any media or any news now in any format is that when\nthey screw up, they won \u2019t own it. They\u2019l l dance around and point fingers somewhere\nelse.\u201d\u2014 U6\nConsequently, news consumers (4/16) mentioned that they were now becoming more re-\nliant on checking facts through other means, such as comparing news stories against related\ncontent and using fact-checking services.\n\u201cI guess, I try to verify things by looking at multiple sources. If a bunch of different\nsources are al l saying the same thing, then that seems more likely to be accurate. And I\nuse websites that are specifical ly set up for fact checking purposes, like political things. \u201d\n\u2014 U8\nIn this vein, some users (5/16) suggested features to compare journalistic performance. For\nexample, they expressed a need to include information on journalists\u2019 past reporting trends,\nsuch as hyperlinks to past articles and reviews of the accuracy or political stance present in\nprevious coverage by a given journalist.\n\u201cProvide a link to maybe a list of their other articles. So, you can see perspectives on\nthem.\u201d\u2014 U9\nCollectively, our pool of news consumers felt that journalists should present more details on\nevidence. They expressed concern over the increasing reliance on anonymous source\u2013based\nreporting and decreasing stress on error correction when journalists make mistakes. They\nalso noted a wider availability of news sources that often complicate ascertaining what is\nfact. These concerns are not unwarranted. Research shows an increase in anonymous source\nuse in news reports [ 287,373] and a significant number (48%) of factual inaccuracies in\nUS news articles [ 364]. Though there is an increase (twofold, between 1997 and 2007) in\nthe number of corrections over time [ 320], newspapers still fail to correct a large number of\nmistakes [ 281,418]. Transparency regarding each of these aspects can be designed into a\nnews web page (discussed in sections 4.6.2\u20134.6.2).\nT ransparency in author expertise\nAfter seeing our design, news consumers (5/16) asked for several author-centric details to\npromote transparency. They suggested multiple transparency features, such as outlining the\nbiography of the journalist and including their educational background ( \u201cwhere they\u2019re from,\nwhere they went to col lege\u201d -U1) and other organizations they have worked in ( \u201c ... nice to\nhave a way to expand expertise to see al l news organization names they worked in. \u201d -U7). The\ndisclosure of such information could inform consumers about reporters\u2019 expertise. To some\nnews consumers, trusting a journalist is easier than trusting an institution ( \u201cI don \u2019t think you\nshould real ly trust one news organization. Y ou should look at the reporters that you feel [are\ntrustworthy]\u201d -U1).This suggestion is not surprising, given how existing research suggests\nthat expertise is a primary dimension of credibility; background information about a reporter\nmight be a manifestation of such expertise [ 299]. In that case, cues that expose the expertise\nof the organization may also affect news consumers\u2019 perceptions of how a story was created,\nand, in turn, result in greater trust. Indeed, prior research showed that providing additional\ninformation about journalists, such as photos and bios of reporters, fosters greater trust in an\norganization [ 102]. Our participants provided some nuance to these findings by suggesting\nspecific types of background information, such as journalists\u2019 professional and educational\nbackground. It seems that respondents found most of these suggestions desirable because\nthe information may help individuals determine whether journalists are capable of reporting\nobjectively on a given topic. For example, consumers might question \u201cwhere they\u2019re from\u201d in\norder to understand how coverage of a story might be affected by the journalist\u2019s pre-existing\nbiases. Considering these suggestions, designers can implement transparency cues that are\nindicative of reporters\u2019 objectivity. We discuss this later in Section 4.6.2.\n4.4.2 RQb: What should designers consider in promoting trans-\nparency cues for news consumers?\nDesigning for easy comprehension\nSeveral news consumers (4/16) preferred information displayed statistically, since it is easy\nto comprehend. More specifically, they asked for design that presents information in a\nsimplified manner. Oftentimes, they used nontechnical terms to convey this idea.\n\u201cGive me a report, ABCD... like accuracy... like 3/4 key attributes that you\u2019re looking\nfor in a reporter [The participant is asking for statistics on a set of easy-to-comprehend\nevaluation criteria.] \u201d\u2014 U2\nHaving too much information could itself be distracting, as pointed out by some of the\nnews consumers (3/16). Consequently, this suggestion might be coming from a tendency to\nreduce cognitive load. Taking these problems into consideration, designers could implement\ntransparency features as simple markers and give users the ability to switch them on and\noff.\nHyperlinking without taking away from the report\nThough several news consumers (5/16) suggested hyperlinking as a way to provide more\ninformation, some (2/16) insisted that hyperlinks take users away from the primary news\nand might thus distract readers.\n\u201cIf there is even one more click to get to that information [more transparency detail]...\nI feel like losing tons of people. Because we\u2019re al l just so lazy or busy. \u201d\u2014 U8\nThis suggestion to reduce distractions might be another reference to reducing cognitive load\nin getting information. To address this problem, web pages could provide previews of each\nhyperlink whenever a user hovers over them. For example, Wikipedia has already imple-\nmented such a preview feature to provide context without the cost of context switching [ 340].\nReducing bias considering consumer cynicism\nThroughout the interviews, our news consumers (7/16) showed cynicism towards news media\nin general. Referring to biases in news reporting, news consumers expressed a reluctance\nto trust any information. Consequently, some of them (3/16) suggested that transparency\nfeatures should come from a third-party reviewer.\n\u201cI stil l watch the news. I want to be informed. But I don \u2019t take everything for face\nvalue.\u201d\u2014 U12\n\u201cPotential ly not even in their own words, in a third party words... like an outside\nreviewer that judges their way of what they\u2019ve written previously and puts them on a\npolitical scale. \u201d\u2014 U7\nThis suggestion for outside oversight in transparency indicators implies that news consumers\nsuspect news organizations of making improper claims of transparency. If readers cannot\ntrust the transparency indicators, they will have no effect. To design against cynicism,\ndesigners may apply de-biasing techniques to modify either the environment or the decision-\nmaker [316]; in our case, these are the design and the news consumer, respectively. As\nparticipant U7 mentioned, setting up a (bipartisan) third-party authority might be useful as\na modification to the environment. Alternatively, designers can pursue nudging techniques,\nsuch as considering the opposite (e.g., asking news consumers why a statistic is inappropri-\nate) [1,274].\n4.5 Journalist Perspective\nIn this section, we outline the themes from journalists as we did with those from news\nconsumers with respect to our sub\u2013research questions about attributes to disclose for trans-\nparency and design issues to consider.\n4.5.1 RQa: What aspects of journalistic practice do journalists\nwant disclosed within news articles as transparency cues?\nOur journalists suggested transparency in two specific areas: characteristics of news organi-\nzations and the reporting process. Overall, they discussed three features for transparency:\n(i) providing evidence to support an article, (ii) emphasizing the process of reporting, and\n(iii) noting the reporter or organization\u2019s conflicts of interest. Below, we elaborate on their\ndefinition of trust and the areas where they suggested increased transparency.\nT ransparency in evidence presentation\nA majority of our journalists (10/15) brought up evidence as one key area for improving\ntrust in news. Some of them (5/15) suggested that publishing unedited evidence material\nalongside a report can help news consumers to fact-check the report. We also found that\nnews consumers preferred such transparency around evidence.\n\u201cI would say... give out documents for open access. I am for opening that up so\nthat people can check it up... some leverage for the people to do fact checking on the\njournalist\u2019s work. \u201d\u2014 J13\nProviding source material can empower news consumers to verify information themselves,\nthus streamlining their capability to fact-check while holding journalists more accountable.\nFor example, transparency cues that highlight a position (e.g., a page number or time code)\nwithin a source (e.g., a document, audio recording, or video) can help news consumers\nidentify discrepancies between the source material and an article based on it. Studies have\nfound that the use of hyperlinks for evidence on news sites can increase perceptions of news\ncredibility, drive users to seek out more information, and drive longer engagement [ 486]. We\nfurther discuss how designers can utilize this suggestion in section 4.6.2.\nT ransparency in the reporting process\nOur scenario suggestions also prompted several journalists (4/15) to think about other ways\nnewsroomscouldshownewsaudiencestheirreportingprocesses, suchasbyprovidingbehind-\nthe-scenes details. Such contextualization could include how journalists went about making\ndecisions while writing a story, thus revealing the underlying journalistic process of news\nreporting.\n\u201cI think as soon as the meeting ends, I, as a reporter, can go to F acebook or social\nmedia, and say, this is what I\u2019m doing today, this is what I\u2019m doing right away at 9\no\u2019clock in the morning, this is why I do this. what do y\u2019al l think about it? \u201d\u2014 J9\nJournalists\u2019 suggestions to show the processes that produce their reports seem to be an at-\ntempt to show professional practices in their newsrooms compared to others, and to allow\nconsumerstocomparethequalityofthejournalisticstandardsofvariousorganizations. Some\nresearchsuggeststhatexplainingelementsofthereportingprocess, suchasverificationproce-\ndures, increases news consumers\u2019 trust in a given article [ 321]. Research also points out that\ncompared to author-related attributes, such as a journalist\u2019s biography, showing evidence or\na behind-the-scenes verification process more significantly enhances users\u2019 trust [ 102]. We\ndiscuss what transparency cues designers can utilize regarding behind-the-scenes verification\nin section 4.6.2.\nT ransparency in conflicts of interest\nApart from the features related to author expertise and corrections provided in our scenario,\nseveral journalists (4/15) suggested conflicts of interest as a consideration for transparency.\nTheysuggestedthatbothjournalistsandorganizationscanbemoretransparentinpresenting\ntheir conflicts of interest, such as relationships with the people that journalists are reporting\non ( \u201c ... reporting mechanism for meetings when you go to different parties and lobbying\nevents. \u201d -J12) or the financial background of a journalistic organization ( \u201cThe key would be\nif it is a ... for-profit/non-profit organization. If for-profit, is there an easy way to to show\nprofitability? funding-wise where it is coming from. \u201d -J2). Such details may contextualize\nthe perspective in a report and help consumers identify any potential bias in coverage. We\nfurther discuss how designers can follow existing practices to show transparency on conflicts\nof interest in section 4.6.2.\n4.5.2 RQb: What should designers consider in promoting trans-\nparency cues for journalists?\nPresenting complicated details with features\nAfter reviewing our scenario with several transparency features (e.g., years in reporting,\nretractions), a majority of the journalists (8/15) raised concerns about missing complicated\ndetails in our design. For example, our journalists suggested that reporting the number of\nyears a reporter has worked in journalism does not necessarily reflect whether the reporter\nhas done high-quality work throughout that time. Conversely, readers could use this metric\nto discount high-quality coverage from less experienced journalists:\n\u201cIt\u2019s like... first time I am getting in the news business... writing a story... reporting\nmy first story... and somebody immediately rejects it because they see that the person\nonly had one year of professional [journalistic] experience. \u201d\u2014 J1\nSeveral journalists (4/15) similarly suggested improving the retraction metric by including\nadditional disclosures as to the nature of retractions and corrections, ranging from \u201csmall\nmistakes,\u201d like minor technicalities or spelling errors, to \u201csevere mistakes,\u201d like factual errors.\n\u201cThose two things (corrections) could have been the address of a building for example,\nwhich is meaningless. Or they could have been like just fundamental facts about a\nstory. Like she said, x happened and it didn \u2019t happen. \u201d\u2014 J14\nThese suggestions imply that designers may inadvertently create a false sense of accuracy if\nthey do not lay out these additional nuances. To address this issue, designers need to handle\nthese details appropriately, with statistical evidence.\nContrasting attributes between organizations\nWhile discussing our feature set in the scenario, several journalists (4/16) suggested that\nsome transparency features (e.g., corrections) regarding journalistic practices might not be\ncomparable between organizations. Though designers can promote transparency to com-\npare practices within and between organizations, our journalists were particularly concerned\nabout inter-organization comparisons. They reasoned that organizations often vary in their\npractices and standards, making it harder to conceptualize a fair comparison of such prac-\ntices. For example, referring to the number of retractions in the scenario, some journalists\nmentioned diverging practices across organizations: Some organizations might issue correc-\ntion in an article for minor errors, while others may not. Consequently, such comparisons\ncould lead readers to draw mistaken conclusions.\n\u201cIt depends on the situation. [F or minor framing issues,] some news organization\nmight change that wording but not issue a correction. Others wil l issue a correction\nand change the wording. Others won \u2019t do anything at al l. \u201d\u2014 J10\nDue to lack of standards in practices across organizations, designers may seek to create\ntheir own standards for presenting this contrast. For instance, they could set criteria for\nretractionsandpenalizeinstitutionsthatdonotfollowthem. Ifdesignersapplysuchmethods\nto standardize these practices, news consumers should be informed about the standards.\nT wo dimensions for distinguishing report quality\nFrom their domain knowledge, our journalists (4/15) showed interest in differentiating the\nquality of a journalistic report along two dimensions: (i) quality within news items and (ii)\nquality between news and non-news items. With respect to differentiating quality within\na report, our journalists suggested markers to signal original and derivative work ( \u201c ...that\u2019s\ngood because it wil l show if it\u2019s an original piece of work, as opposed to a derivative. \u201d -\nJ2) and markers to denote whether the story is a breaking news report ( \u201cSo a pop-up-like\ndisclaimer that this is what we\u2019re doing right now, we are trying to col lect the information. \u201d\n-J4, speaking about a piece of breaking news). For differentiating along the news/non-news\ndimension, journalists suggested markers that indicate news versus opinion, news versus\nsatire ( \u201c ...maybe something that scrapes the website, looks at the \u2018about me,\u2019 looks for satire\nand flags that. \u201d -J12), and credible news versus misinformation ( \u201chas it been, like, highly\ndistributed and shared across channels that are sort of questionable?\u201d -J2). Designersneedto\nmakenewsconsumersawareoftherelationshipbetweeneachattributeandthecorresponding\ndimension. Consideringnewsconsumers\u2019desireforsimplicity,designersmayseektoprioritize\none dimension over others. For example, designers might consider distinguishing news versus\nopinion, as research indicates that the majority of US adults are poor at differentiating\nbetween the two [ 306].\n4.6 Discussion\nOur news consumers and journalists suggested several aspects of news coverage where trans-\nparency cues can be helpful, as well as a set of design issues to consider. Below, we first\ncompare the two groups (section 4.6.1), followed by discussions of how designers can lever-\nage aspects of transparency in existing organizational practices (section 4.6.2) and of design\nissues (section 4.6.3).\n4.6.1 Comparing the Perspectives of News Consumers and Jour-\nnalists\nAgreement on presenting evidence and differences in reporting aspects for trans-\nparency\nNews consumers and journalists alike agreed that presenting evidence details can effectively\nimprove transparency in news reporting. In terms of disclosing the reporting context for\ntransparency, our analysis shows that news consumers focus on a given report with only\npassing interest in the reporter, while journalists\u2019 suggestions encompassed four main ar-\neas: the report, the reporter, the reporting organization, and the reporting process. While\nour news consumers were often interested in indicators of bias in a story, our journalists\nshowed openness to sharing information, such as revealing conflicts of interest and reporting\nprocedures to address concerns around bias.\nConflict between simplicity and nuance in design\nRecall that several news consumers asked for designs that simplify information. Contrary to\nthat, our journalists\u2019 objections to some of our design features also point out concerns that\nsimple metrics may be insufficient without additional context. From a technological stand-\npoint, our journalist pool seemed more savvy and provided technical details (e.g., \u201cheatmap\u201d\nand \u201cpop-up\u201d) when discussing feature designs. Comparatively, some of our news consumers\noffered suggestions in more general terms (e.g., \u201caccuracy\u201d). Given this tension between the\ntwo stakeholder groups, designers would have to be conscious of trade-offs between simplicity\nand nuance in the design of these features. For example, they may provide specific, nuanced\ninformation in some cases (e.g., severity of corrections) while excluding other details. When\nsuch a level of nuance is required, designers can engage the audience by adding summary\nmarkers as a means of digging deeper into more general statistics.\nConflict between transparency and autonomy\nSeveral journalists (5/15) felt that some of the transparency features were impractical due\nto ethical, professional, or corporate boundaries. Some mentioned their own stances on\nprotecting the confidentiality of sources, especially anonymous sources like whistleblowers,\nfearingbacklash. Thepervasivenessofanonymoussourcesinpoliticalreportingmayreinforce\nthis stance. Others mentioned that news organizations were unlikely to support some of the\nsuggestions, such as televising meetings, from fear of exposing trade secrets. However, there\nhave also been instances in the past where an organization, such as the NYT, televised its\neditorial meetings [ 456]. These instances suggest that organizations could be open to these\nkinds of transparency practices.\n\u201cWil l that [putting a live camera in a morning meeting] ever happen? I don \u2019t think so.\nBecause there\u2019s just a lot of stuff that we talked about in that meeting that\u2019s sort of,\nlike, behind-the-curtain stuff. And we talk about like, should we do the story about the\nschool? Y eah! Because our demo[graphic] is 24- to 44-year-old moms who care about\nthe school system. \u201d\u2014 J9\nPrior research suggests that transparency, which creates a limited form of accountabil-\nity [143], can facilitate severe scrutiny and restrict journalistic autonomy [ 10]. As news\nconsumers seek greater disclosure, organizations might impose constraints on full trans-\nparency due to concerns regarding secrecy and maintaining an autonomous corporate im-\nage. Designers will have to address this tension between stakeholders that arises from these\ncompeting values. To address this issue, designers could ask at least three questions when\nimplementing a transparency feature in a news article: Does this feature violate any policy\nof the organization? Does this feature violate the privacy expectations of a source referenced\nin the article? Do news consumers desire this transparency feature? If the answer to either\nof the first two questions are yes, designers would have to revise the feature. To this end,\nunderstanding the policy norms of news organizations, as well as the privacy expectations\nof sources referenced in a news report, might be an important consideration for research.\n4.6.2 Design Suggestions Based on Existing Journalistic Practices\nBoth of our participantgroups suggested severalaspects of transparency for reporting. What\ndesign cues can HCI designers build around these aspects? We propose that these cues be\ndeveloped on the basis of existing practices in news organizations. These design suggestions\nare summarized in Table 4.5.\nNewsworthiness cues for news selection bias\nConsidering objectivity, our news consumers referred to two areas where bias is injected in\nthe production of news: news selection and framing. Journalists select stories to cover using\ncriteria for newsworthiness , also known as news values , based on their desire to appeal to\npublic interests [ 67]. Though early research proposed such news values as timeliness (how\nrecently the event occurred), proximity (how close to the audience the event took place),\nconflict, and sensationalism [ 147,415], journalism has evolved to consider additional news\nvalues, such as eliteness (presence of an entity with great societal power), exclusivity, and\nentertainment [ 188]. Empirically, scholars have found that conflict and eliteness are the\nstrongest predictors of newsworthiness [ 56]. Existing transparency practices in the media\noften broadly specify news selection on a site-level basis. For example, ProPublica offers a\nmission statement that says \u201cto expose abuses of power...\u201d [ 372]. Compared to such site-\nlevel practices, designers could offer transparency cues explaining the newsworthiness of each\narticle. For example, they can identify the criteria of newsworthiness that a particular story\nmeets.\nF airness cues for framing bias\nThe fairness concern is studied in communication literature as framing bias (i. e., levels of\nopinion within a given report). Scholars propose that journalists raise the salience of specific\ninformation to prime the target audience into thinking in a particular way [ 119,325]. Such\nframingisoftenfoundincoverageofcongressionalcandidates[ 117,416],taxpolicies[ 121]and\nracial issues [ 148]. As one news consumer suggested, left-leaning organizations often cover\nright-leaning politicians by framing their point of view negatively. Research also suggests\nthat journalists can be unaware of their own biases in how they select certain words, and in\nhow they omit or decide to include certain details [ 250,251]. Overall, prior research indicates\nthat a skew in fairness exists in the coverage of certain news areas. To differentiate balanced\nnews stories from ones that are skewed, designers can promote design cues that indicate\nthe viewpoints or sources covered in a story and how such viewpoints are presented. For\nexample, designers can use computational tools to identify all named parties (both persons\nand organizations) in a report and detect the author\u2019s or organization\u2019s stance towards each\nof them [ 21,254]. Transparency cues could also make consumers aware of the efforts of\njournalists to get multiple sides of a given story. Journalists might consider disclosing which\nviewpoint(s) they were unable to cover or did not receive any comment on, as well as the\nextent of their efforts to obtain such information.\nPresence of Evidence Cues\nOur news consumers suggested opportunities for transparency cues that highlight good jour-\nnalistic practices relating to source materials. Designers can construct transparency cues to\nindicate how sources are presented in a report. For example, design cues can differentiate\nthe existence of source materials, show the timeline of the collection of such materials, and\nindicate how information from the source materials is presented in a given report. In this\nrespect, designers can utilize computational tools to highlight evidence details. For instance,\nthey might indicate whether all named parties in a report have hyperlinks, whether sources\nare referenced ambiguously (e.g., \u201csources said\u201d vs \u201c<name>, a spokesperson for <com-\npany>, said\u201d), and contextualize quotes (e.g., when users hover over a quote, a tooltip can\nshow the full paragraph containing the quote).\nAnonymous Source Cues\nA recent survey suggests that although news consumers realize the numerous reasons for\nusing anonymous sources, they are concerned that news organizations unnecessarily omit\njustification for this practice [ 368]. To justify their use according to the Associated Press\u2019s\n2014 guidelines [ 366], designers may show transparency cues regarding why the requested\ninformation is not available on the record, how reliable the source is, and what resources\n(e.g., public documents, on-the-record sources, and reactions from those affected by a story)\nhave been used to corroborate information from anonymous sources. In practice, some orga-\nnizations show their verification procedures for anonymous sources at the site level, instead\nof at the article level. For example, ProPublica shares how they generally verify anonymous\nsources without going into specifics for each case [ 176]. Taking a step further, designers can\nestablish verification standards for anonymous reporting and provide design cues outlining\nthem on news websites. For example, designers can show the degree of acceptability of vari-\nous verification materials (e.g., public documents compared to reactions from those affected\nby a story).\nF act-checking and Correction Cues\nConsidering the concerns pertaining to fact-checking and corrections, designers could offer\ntransparency cues that detail who fact-checked the information (e.g., reporter / copy editor\n/ editor / third-party fact-checker), quick links to ask ombudsmen to verify the information,\na timeline of changes to the article, and statistics pertaining to corrections made by the orga-\nnization and the author. Computationally, designers can also use third-party trackers (e.g.,\nwww.newsdiffs.org ) that analyze changes in news reports published by an organization and\nshow what changes were made. Designers could propose cues that highlight how corrections\nare framed in a report, signifying the degree to which organizations take responsibility for\nerrors in their coverage. For example, when news media organizations include corrections,\nthey often use a range of framing devices, such as \u201cclarification\u201d (evades responsibility) and\n\u201capology\u201d (assumes responsibility) [ 162].\nAuthor Expertise Cues\nIn addition to article-related aspects, our news consumers suggested several features related\nto author expertise. In practice, some organizations display biographies of their journal-\nists along with their professional histories (e.g., reporting areas) and personal information\n(e.g., education) on their websites. Designers could additionally indicate differences, such as\ndesired values in journalism. Existing surveys list several characteristics (e.g., skills, knowl-\nedge, and work values) and their importance in the journalism profession [ 141]. Using this\ninformation, designers can prioritize showing certain information (e.g., active listening skills,\nwhich are more important than time management skills). However, as suggested in the in-\nterviews, designers would need to consider nonstandard practices across organizations before\nshowing these contrasts. Comparisons within an organization might also not be meaningful\nin some cases, due to skewed distributions (e.g., the level of education for New York Times\nreporters [ 478]). Moreover, comparisons between generations can be tricky due to changes in\nrequired skills (e.g., the addition of technological skills in current job postings [ 141]). Apart\nfrom professional skills, HCI designers can also focus on journalists\u2019 expertise in being ob-\njective, since some news consumers positioned author expertise in relation to objectivity in\na report. Transparency in journalists\u2019 and their editors\u2019 writing skills might be useful in this\nregard. Furthermore, designers can construct new indicators, such as summaries of fairness\nin journalists\u2019 past reports, signaling their historical patterns of objectivity.\nBehind-the-scenes Cues for the Reporting Process\nApart from presenting ample evidence in the report, our journalists proposed greater disclo-\nsure of reporting processes or behind-the-scenes details as another avenue of transparency.\nIn the past, some organizations have used such practices as inviting community members to\nmeetings to disclose these details. Some recent examples in which behind-the-scenes details\nare disclosed include podcasts on how investigative journalists track their sources, and tweets\nby journalists containing their daily notebooks [ 47,240]. Designers can adopt these details\nwhen creating news websites. For example, by leveraging diverse sources of information (e.g.,\nsocial media posts and organizations\u2019 internal trackers), designers can present details that\ncorrespond to a given report in a timeline. Furthermore, HCI designers might also consider\nbuilding systems to support journalists in sharing their work in progress and collaborating\nwith the community [ 166].\nConflict of Interest Cues\nTransparently disclosing an organization\u2019s conflicts of interest may be useful in providing\nnews consumers with insight into the financial holdings of a company, which might impact\nits reporting. For example, many consumers aren\u2019t aware that ABC is owned by The Walt\nDisney Company, while CBS is owned by ViacomCBS, a subsidiary of National Amuse-\nments. McChesney has extensively documented the conflicts of interest that arise with news\norganizations when they are forced to cover issues that impact their parent companies [ 290].\nWhile currently not prevalent in journalism, some organizations engage in practices detail-\ning funding sources at the site level. For example, several organizations, including The\nEconomist [ 118], NJ Spotlight [ 322], and ProPublica [ 371]) list all of their donors. Some\nothers, such as The Wisconsin Center for Investigative journalism [ 492], provide extensive\ndetails that include donation amounts. However, a handful go so far as to highlight when a\ndonor is mentioned in a story (e.g., Texas Tribune). Informed by existing practices, designers\ncould promote design cues at the article level whenever donors are mentioned.\n4.6.3 Considering Design Issues\nConflicting priorities: value-sensitive design\nThroughout the study, we noticed several conflicts between our two stakeholder groups. For\nexample, news consumers prefer designs that are quick and easy to comprehend, while jour-\nnalists prefer designs that provide sufficient nuance in transparency attributes. Similarly,\njournalists would like to retain their autonomy, while news consumers want more account-\nability on the organizational level. To address these conflicts, HCI designers can utilize an\nexisting design approach known as value-sensitive design [144]. This approach suggests that\ndesigners should not consider conflicts as \u201ceither/or\u201d situations, but rather as constraints\non the design space [ 145]. Depending on the nature of the conflict, designers might be able\nto balance some tension using existing HCI design principles. For example, social translu-\ncenceis a design principle that addresses the accountability-autonomy conflict [ 124]. To\nillustrate, in the case of putting live cameras in news meetings, designers could incorporate\nsocial translucence by showing the video while redacting sensitive content through appropri-\nate methods, such as blurring and muting. Such details could lead to increased visibility of\njournalists\u2019 activity while imposing limited accountability on the journalists\u2019 work, without\nsacrificing privacy. When balance between conflicts is not feasible, designers could discuss\na workable design space with the stakeholders. For example, news consumers may spare\ntransparency in some aspects (e.g., the identity of an anonymous source) while requiring it\nin others (e.g., how many times a particular anonymous source was used).\nOrganizations\u2019 openness to transparency\nSome of our participants were wary of whether organizations would be open to implement-\ning site-level features (e.g., \u201cI don \u2019t foresee it being adopted broadly by news organizations\nvoluntarily. Because I think the commercial ones, especial ly, would see it as just a cost with\nno benefit. \u201d -U8). Prior scholarly work has revealed organizations\u2019 unwillingness to increase\ntransparency regarding certain aspects, including their methods and motives [ 79,246]. How-\never, therehasalsobeenageneraltrendofnewsorganizationsadoptinggreatertransparency.\nIn this respect, some news organizations have been opting for an in-house, ad hoc frame-\nwork of transparency. For example, Axios created a \u201cbill of rights\u201d for news production that\nprioritizes transparency surrounding editorial ethics policies for sources and article correc-\ntions [22]. Meanwhile, a large number of national and international organizations ( n >200)\nare adopting third-party frameworks on transparency (e.g., Trust Project) [ 369]. In its 37\ntransparency indicators, the Trust Project largely focuses on site-level features, with only\na handful of article-level transparency indicators, such as disclosing corrections and distin-\nguishing between news and other kinds of material (viz., opinion, satire, advertising) [ 370].\nComparatively, our work illuminates ways in which listed organizations can transform site-\nlevel features into more specific, article-level features. For example, as mentioned earlier,\ninstead of providing a comprehensive list of donors, designers can offer transparency when-\never a donor is mentioned in a report. Article-level transparency may especially help with\nthe concern that news consumers may not notice transparency features [ 447]. In general,\nthis work offers guidance for priorities, as well as design issues to consider for transparency.\nStandardizing organizational practices for contrast\nOur discussion with journalists emphasizes the need for a set of transparency metrics that\ncan be compared across news organizations. A precursor for such an implementation is\na standardization of practices across organizations. If consensus develops around a stan-\ndard that is common to a group of stakeholders, it may guide organizations to follow that\nstandard when reporting news. Considering recent efforts in standardizing transparency\npractices (e.g., the Trust Project), creating credibility standards (e.g., W3C Credible Web\nCommunity Group [ 476]), and creating transparency markup standards ( schema.org [402]),\nstandards in organizational practice assist can these efforts. Notably, past platforms like\nnews aggregators had to work with external websites and tools (e.g., Politifact and the\nShare the Facts widget [ 452]) to identify fact checks. Designers can address this problem by\ntransmitting transparency details as metadata and making it easier for site designers across\nwebsites to show transparency without added hassle. In addition, standardization of organi-\nzational practices could create further barriers to fringe sources\u2019 constant production of false\nstories. For instance, if providing source material in a report is mandatory per transparency\nstandards, it may place a burden on the creators and maintainers of alternative and fake\nnews websites, therefore slowing their pace of publication.\nF easibility of transparency cues in practice\nIn addition to the complexity arising from the lack of standards in practices among organiza-\ntions, designers would also have to comply with the priorities of the organizations for which\ntheywork. Aswementionedbefore, apartfromdedicateddesignteamsinnewsorganizations\n(e.g., the design team at the NYT [ 457]), other third-party news entities could also adopt\nour results by providing \u201ctransparency as a service\u201d through either a browser extension or a\ndedicated website. For example, Allsides.com boasts of showing news from the left-center-\nright perspective [ 14]. Here, Allsides.com may have a priority in being transparent about\nbiases in left-center-right news sources. For such third-party entities, designers may have\nto consider their access to organizational resources in implementing certain features (e.g.,\nprior reporting history). To this end, we summarized the implementation feasibility for our\ndesign suggestions based on access to an organization\u2019s resources in Table 4.5. Here, behind-\nthe-scenes details are only available directly from organizations, while cues for presence of\nevidence can be computationally detected. There are certain details that fall in between\nthat can be managed with secondary services. For example, information about the author\u2019s\nreporting history or retractions could be sourced from third-party databases, such as Muck\nRack [375]. Additional complexity may arise whenever subjective ratings for transparency\ncues have to be computationally scored. For example, designers may seek to compute how\nwell a news report fits with newsworthiness criteria, and this information could be subjec-\ntive to the audience. Crowdsourcing of such subjective ratings may be a possible solution\nto this issue. Other works have shown promise in crowdsourcing subjective ratings (e.g.,\ncredibility) [ 42].\nConsidering news consumers\u2019 changing values\nApart from the specific design issues of production-side aspects, our study indicates that\ndesigners would have to take into account the changing habits of news consumers, such as\nincreasing polarization and cynicism. For such changing values, designers can personalize\ntransparency cue design. For instance, some news consumers (U3) preferred earlier jour-\nnalistic norms (\u201cCronkite era\u201d reporting) such as objectivity; that is, reporting the facts\nonly while leaving the interpretation and implications up to the audience. For these news\nconsumers seeking fact-only news, designers could focus on certain transparency features\n(e.g., presence of evidence cues) that highlight facts in an article. On the other hand, there\nwere news consumers (U1 and U9) who considered such an understanding of objectivity out-\ndated [390] and instead asked journalists to be open about their biases. For those who asked\nfor transparency on biases, designers could show features (e.g., conflict of interest cues) that\ndisclose this information. In either case, future work focusing on how each design affects\ntrust for readers with varying political stances could provide further guides for designers,\nespecially since prior scholarly works suggests that design interventions may or may not\naffect perceptions of trustworthiness depending on users\u2019 political ideologies [ 387,494].\nResiliency considerations to avoid manipulation\nSome news consumers were concerned about the trustworthiness of transparency cues. Con-\nsidering that transparency features can also be exploited by bad actors, these features must\nbe made resilient to manipulation. In our study, each design cue has different levels of re-\nsilience to manipulation. While bad actors can easily manipulate numbers (e.g., an author\u2019s\nexperience in years), it is harder to exploit cues that require further documentation with\nproof (e.g., for-/nonprofit organizations\u2019 legal documents, police reports as evidence). Sev-\neral steps can be taken to further prevent exploitation of these cues. Interdependent cues\ncan be devised, such that manipulation of certain attributes can reveal inconsistencies or\ndefects in the cues. For example, the number of reports and percentage of corrections by\nan author have a dependency that can signal manipulation of each individually, but not in\nunison. Resiliency can also be achieved through a third-party authority who verifies this\ndata (e.g., an ombudsman and third-party fact-checkers). Eventually, frequent audits may\nalso help keep the system in check, albeit at the cost of resources and time. However, it is\nimportant to note that bad actors with enough resources (e.g., state-funded actors) may still\nmanipulate highly resilient features.\nCan transparency do harm?\nThe suggestion that transparency can improve trust is quite complicated in practice. As\nO\u2019Neillargues, despite increasing transparency, trust has receded [ 335]. According to her,\nwhile transparency may help when there is prior deception, increasing transparency may\nalso \u201cproduce a flood of unsorted information and misinformation that provides little but\nconfusion unless it can be sorted and assessed.\u201d As our journalists noted, some features could\ncreate a false equivalence between reporters from different organizations. Given the level of\nskepticism in news media [ 169], more transparency could cause consumers to become more\nskeptical about news\u2014perhaps even about factual reports. To counter, our results offer\nparticular priorities to consider (e.g., news selection and framing) in a structured fashion\n(e.g., through proper comparison across organizations). There are also considerations for\ntransparency around specific areas. As Cunningham notes, \u201cTo assume that we can know\nwhat someone thinks by identifying their personal traits, habits and predilections is a dan-\ngerous notion, and really has nothing to do with clarity.\u201d [ 101] Our journalists remarked that\ntransparency around sources could be harmful. Some sources prefer to stay anonymous for\na variety of reasons, such as preventing backlash from the organization. Some journalists\nalso prefer to keep sources anonymous out of necessity, so as not to lose potential sources\nof information on future events. Given these constraints, future research could be directed\ntowards quantifying the benefits and drawbacks of each transparency cue.\n4.6.4 Limitations\nInthisstudy, weexploreasubsetofthelargerissuethatisgrowingdistrustinthemedia; that\nis, howtransparency through design cues can contribute to improvingperceptions of trust for\nnews articles. Our work is limited in focus, as we prioritize the perceptions of two particular\ngroups of stakeholders: news consumers and journalists. While news organizations may play\na much larger role in what gets adopted on their sites, our intent is to inform HCI designers\nand these organizations of the recommendations from our two stakeholder groups. This\nwork is also limited in its perspective on designing features, to the exclusion of examining\nand setting organizations\u2019 policies. It is worth noting that we did not consider journalists\nfrom alternative media (e.g., Breitbart, One America News Network, and Newsmax), who\nare known for their particular (and perceivably strong) partisan views. Journalists in such\norganizations with significant viewership may view these questions of trust and transparency\ndifferently, and they may need separate attention in future works.\nFurthermore, while we used a scenario-based design to elicit feedback on which transparency\ncues can act as trust indicators, we can not definitively predict how the cues may affect\nusers\u2019 trust without conducting a controlled user study on a functional system, given the\nambiguous effect found in past experiments [ 103,223]. However, similarly to one of the\nexperiments, the addition of multiple transparency features to a news item has the potential\nto affect users\u2019 perceptions of credibility [ 103]. Still, taking these design considerations into\naccount, we have to be careful to test whether such a design could simply overwhelm news\nconsumers, resulting in an undesirable opposite effect.\nResult-wise, our study suffers from some limitations common in qualitative studies. First,\nwe had a limited number of participants. Furthermore, we could only interview people\nwho agreed to participate. Therefore, a self-selection bias exists in our study. Moreover,\nwe reached a majority of our participants by a combination of convenience and snowball\nsampling strategies. Though these are acceptable strategies in social science research [ 39],\ntheir use adds to the limitations of our study. Even so, we tried to address this problem\nby reaching out to a variety of sources. For example, in our news consumer pool, we had\na mix of news-savvy and non-savvy participants with diverse backgrounds. Additionally, as\nwe progressed through our interviews, very few new themes emerged in the final interviews\nof each group. Therefore, our results may have reached empirical saturation despite the\nlimited sample size. Second, our participant population is mainly US-based, with some\nexceptions; therefore, our findings might not be generalizable to other countries. Indeed,\ntrust in the media varies by country [ 383]. Since we conducted the study during the latter\nyearsoftheTrumpadministration,theremightbesomeperiod-specificeffectsthatinfluenced\nthe perceptions of both groups of participants (e.g., the concern overobjectivity in news\nselection). Future studies in other regions and time periods might be able to address this\nlimitation.\n4.7 Conclusion\nIn this work, we examined how designers can adopt transparency features as indicators of\ntrust on news websites. We explored these questions in a dual-perspective setting, inter-\nviewing journalists and news consumers with a scenario-based approach. Our results imply\nthat HCI designers can offer indicators of trustworthiness through transparency cues that\nreflect objectivity and evidence in news articles, authors\u2019 expertise, the process of reporting,\nand personal and organizational conflict of interest. Both groups agreed on some cues while\noffering differing views on others.\nT ransparency\nCues (Section)Example Questions Implementation\nRequirementsSuggested\nByDisagreed\nBy\nNewsworthiness\nCues (6.2.1)Which news values does this report represent (e.g.,\nconflict, sensationalism, eliteness and entertainment)?\nTo what degree?Requires access to\norganizations\u2019 news valuesNews\nconsumers-\nFairness Cues\n(6.2.2)Who are the named parties in this article? To what\ndegree does this report represent each political\na\ufb00iliation (left/center/right)? Did the reporter receive\ncomments from all contacted parties?Requires knowledge of\norganizations\u2019 procedures\nfor getting commentsNews\nconsumers-\nPresence of\nEvidence Cue\n(6.2.3)Does the report cite an authoritative source of\nevidence? Is there ambiguity in how sources are\nrepresented?Requires access to o\ufb00icial\nsource materials (might\nbe openly available)Both\ngroups-\nAnonymous\nSource Cue\n(6.2.4)Does this report contain anonymously sourced\ninformation? Why was the information not available\nwithout anonymity? How did the reporter verify the\ninformation? How acceptable is the verification\nmaterial?Requires knowledge of\norganizations\u2019 procedures\nfor anonymous sourcingNews\nconsumersSome\njournalists\nFact-check Cue\n(6.2.5)Has any internal/external entity fact-checked this\ninformation? Who fact-checked it (with links)?Requires access to\ninternal/external fact\ncheckers and their\nproceduresBoth\ngroups-\nCorrection Cue\n(6.2.5)Have there been any corrections to this report? Why?\nHow were the corrections framed?Requires knowledge of\norganizations\u2019 correction\nprotocolsBoth\ngroupsSome\njournalists\nAuthor\nExpertise Cue\n(6.2.6)What skills does the reporter have? What is the\nreporter\u2019s educational background? How objective has\nthe reporter been in past reports?Requires comprehensive\nknowledge of journalists\u2019\nreporting historyBoth\ngroupsSome\njournalists\nBehind-the-\nscenes Cue\n(6.2.7)Does this report contain any behind-the-scenes\ndetails? How did the reporting process occur over\ntime?Requires access to\nbehind-the-scenes\nmaterials for a reportJournalists Some\njournalists\nConflict of\nInterest Cue\n(6.2.8)Does this report cover any entity with which the\nreporter/organization has a conflict of interest? How\ndoes the reporter/organization deal with such\nconflicts?Requires access to news\norganizations\u2019/journalists\u2019\nfinancial informationJournalists -\nTable4.5: Designsuggestionssummarizedaccordingtotwocriteria: implementationrequire-\nments and consensus or disagreement among participants. Here, the requirements of access\nto (and knowledge of) an organization\u2019s resources (and protocols), such as internal/external\ndatabases of prior corrections, conflicts of interest, and behind-the-scenes materials could\nmake it difficult for a third party to implement the design cues. The two right-most column\nsuggest both within-group and between-group disagreement among our participants. As an\nexample, the Behind-the-scenes Cue, discussed in section 4.6.2, could be hard to implement\nwithout access to organizations\u2019 materials. Some of the journalists disagreed as to the feasi-\nbility of disclosing portions of this information (e.g., televising meetings). Another example\nis the Author Expertise Cue (section 4.6.2) discussed by both groups with some disagree-\nment from journalists due to its (e.g., years in reporting) negative impact on new journalists,\nwhich could be hard to implement due to the required access to organizations\u2019 protocols.\nAdditionally, we provided sample questions designers could use to build transparency cues.\nChapter 5\nNewsComp: F acilitating Diverse\nNews Reading through Comparative\nAnnotation\n5.1 Introduction\nNews media often produces content that is significantly biased in favor of a particular ide-\nology, especially on contentious topics [ 199,313,438], and news consumers are affected by\nsuch biases [ 111]1. Therefore, developing an informed opinion on a subject requires critically\nconsuming news content from multiple sources. While the internet gives users access to news\nfrom multiple sources, when given choices, people tend to choose content that aligns with\ntheir viewpoints due to confirmation-seeking tendencies [ 84,323,323,431,440]. Further-\nmore, the task of engaging with multipleperspectives is not easy and probably not performed\nequitably by all users [ 209,420]. One potential solution to this problem could be to use ex-\nperts (i.e., journalists) to combine news items on an event from varying sources into a single\nstory. However, a limited number of experts would likely find it difficult to manage the vol-\nume of news stories generated by news outlets from around the world. On the other hand,\nstudies have shown that crowdworkers\u2019 output can be significantly correlated with experts\u2019\n1part of this chapter appears in [ 46]\n117\nin some annotation tasks [ 11,12,42,63,446]. Building on such results, this work explores\nwhether crowdsourcing could be a viable approach to combining news articles from varying\nsources. For a lay user, such a crowdsourcing task can be broken down into two aspects of\ncomparative annotation: (i) finding similarities and (ii) finding important disparities. These\nannotations can be useful to both news consumers and fact-checkers, whether professional or\ncrowdsourced (e.g., BirdWatch2). For everyday news consumers, merged articles can provide\nbalanced perspectives on news events. Second, fact-checkers can use similarity/dissimilarity\nannotations to validate claims through multiple sources or trace the origin of specific state-\nments. Besides, a by-product of any annotation task is that performing the task could also\naffect the annotators attitude towards the content, in our case, the news articles or the issue\nat hand. In this work, we ask:\nRQ1.How wel l do users perform comparative annotation?\nRQ2.How does comparative news annotation affect users\u2019 perceptions of credibility and\nnews quality?\nHere, we use a simplified notion of comparative annotation: statements that are similar\nand statements that are dissimilar but important. Using the concept of comparative news\nannotation, wedevelopedandtestedNewsComp(seetheinterfaceinFigure 5.2): aprototype\nthatallowsreaderstocompareandannotatesimilarandcontrastingstatementsbetweenonly\ntwo news articles. NewsComp has two components: (i) a comparative or side-by-side view of\ntwo articles from different sources, and (ii) an annotation tool. Specifically, the annotation\ntool allows performing the two annotation tasks: (i) identifying similar statements across\na pair of articles and connecting them with lines (\n3 in Figure 5.2), and (ii) identifying\ndisparate statements (statements with no similarity) from each article that are important\n2https://blog.twitter.com/en_us/topics/product/2021/introducing-birdwatch-a-community-based-\napproach-to-misinformation\nand should be included in the other article in the pair (\n6 in Figure 5.2). To design the tool,\nwe conducted a series of think-aloud formative studies with Google Drawings to observe the\nannotation process. During those interviews, we noticed users considering different criteria\nfor annotation. For example, some considered only the content in each statement, while\nothers considered the underlying themes behind the statements. Informed by the think-\naloud sessions, we ask annotators to provide the reasoning behind their annotation (e.g.,\n2\nin Figure 5.2).\nTo answer our research questions, we conducted a between-subjects experiment with News-\nComp in a controlled environment. We recruited 109 participants using Facebook adver-\ntising, which allowed us to recruit users from a large and diverse pool. Participants were\nrandomly assigned to either the treatment or the control group. For the study, we used\ntwo pairs of articles on two contentious topics: immigration and abortion. To generate gold\nstandards for the sake of comparison, we recruited two experts from the university\u2019s De-\npartment of Communication (one of whom had five years experience as a journalist) and\nasked them to perform annotation and rate the articles. Our experts found different degrees\nof similarity between the two pairs of articles; specifically, the pair of immigration articles\nhad high dissimilarity (high contrast), while the pair of abortion articles pair was highly\nsimilar (low contrast). During the study, users in the treatment read and annotated a pair\nof articles on the same topic, and then responded to a questionnaire designed to address our\nresearch questions (related to perceptions of credibility and quality). Meanwhile, users in\nthe control group read a pair of articles on separate events without adding annotations and\nresponded to the same questionnaire. We analyzed the extent to which news consumers\u2019 an-\nnotations matched experts\u2019 annotations, the impact of article topic and users\u2019 news expertise\n(knowledge of current events, perceived value of media literacy) on annotation quality, the\nreasons behind annotations, and how the treatment group\u2019s article perception compared to\nthe control.\nRegarding RQ1, we found that users performed poorly on both annotation tasks. However,\nthey had higher precision in finding similarities than in identifying important statements\namong the disparate statements. We also found that filtering out annotations based on the\nnumber of users who annotated an item can rule out some false positives in finding similar\nstatements, thus improving their collective F1 score. In our study, ruling out annotations\nmade by fewer than five or six users produced the highest F1 score. Users with low current\nevent knowledge made more annotations and had higher recall. We also found that while\nannotating statement similarity, users provided different types of criteria, such as seeing\nconnections when two statements discuss the same person, location, date, quote, or other\ninformation. Among statements with no similarity, when annotating if a statement is im-\nportant and should be included in the other article, users sometimes marked a statement\nimportant if it provided clarification or elaboration on other statements or if it provided\na missing perspective. Furthermore, we found that both generic words (e.g., \u201cquote\u201d and\n\u201csimilar\u201d) and article-specific words (e.g., \u201clawsuit\u201d) mentioned in the rationales can differ-\nentiate incorrect annotations from correct ones. Perhaps such generic words in rationales\ncan be used to filter out false positives in annotations on articles on different topics. Com-\nparing the articles, annotators also saw differences in perspectives presented, information\nplacement, depth of detail, amount of factual/opinion statements, empathetic presentation,\nand use of inflammatory language. Perceptions of NewsComp itself were mixed, though\nskewed more towards positive than negative. Regarding RQ2, we found that the treatment\ngroup\u2019s credibility ratings were significantly different compared to the control group\u2019s for\nhigh-contrast articles. For low-contrast articles, users in both groups performed similarly.\nThere were no significant effects on perceptions of quality. Overall, this study indicates that\nwe can leverage the comparative annotation mechanism to engage users in reading multiple\nperspectives. However, since users produce annotations with high error rates, creating tools\nto assist in annotation could help reduce errors.\nWe discuss applications for annotated data, such as developing a holistic view of an event\nfrom multiple news sources, teaching machines to discern article quality, training machine\nlearning algorithms to generate better annotations, and assisting fact-checkers in their work.\nWe conclude with implications for the design of future comparative annotation tasks, such\nas modularizing into subtasks, providing supporting features to reduce load, and supporting\nco-annotation by multiple users.\n5.2 Background and Related W orks\nIn this section, we begin by providing some background on media bias and multi-perspective\nonline news consumption. Thereafter, we discuss related research on designing annotation\ntools for making sense of information and the effects of such annotations.\n5.2.1 The Need for Multiperspective News Consumption\nWhile news articles should ideally follow established journalistic practices, various forms of\nbiases and inaccuracies are injected into articles during the content production process. This\nbegins in the information gathering stage, where journalists must select events and related\nfacts from sources. In doing so, news publishers can influence which topics readers perceive\nto be relevant by selectively reporting on topics of their choosing [ 403]. Next, journalists\ninclude and exclude information from sources (e.g., press releases, other news articles, and\nstudies), shapingtheperspectiveontheevent. Inthewritingphase, journalistsmakestylistic\nchoices which may reflect their view of the news item, thereby producing biased coverage.\nFor instance, journalists may introduce bias through the use of labeling (\u201ca senator\u201d vs.\n\u201ca Republican senator\u201d) and word choice (\u201cillegal alien\u201d vs. \u201cundocumented immigrant\u201d).\nSuch methods allow journalists to promote a particular interpretation of a topic [ 120].\nResearchsuggeststhatamajorityofnewsconsumersareaffectedbymediabias[ 111,248,317]\nin different ways [ 117,403]. Such bias can influence voting or election outcomes [ 110,117,\n317]. Furthermore, media bias promotes polarization in public opinion, especially on con-\ntentious topics [ 438]. Some scholars argue that media bias challenges the pillars of American\ndemocracy [ 217,499]. Overall, these works point to the need to consume news from diverse\nperspectives to deal with biases in the media.\n5.2.2 Barriers to Multiperspective News Consumption Online\nLazarsfeld et al. introduced the two-step flow model of communication, referring to the two\ngatekeeping stages that occur before an individual forms an opinion on a subject: first by\nnews organizations, and then by opinion leaders in the individual\u2019s social circle [ 258]. Even\nthough the internet has democratized access to information, including news, news consump-\ntion in the internet age still seems to follow the two-step flow model in communication in\nat least two ways: news selection and consumption [ 86,258,424]. First, personalization\nalgorithms act as filters for content selection; thus, they perform a gatekeeping function\nsimilar to that of opinion leaders in the pre-internet age [ 341,424,432]. Second, pervasive,\necho chamber\u2013esque news comment sections tend to promote opinions from opinion leaders\nwith views aligned with users\u2019 own beliefs [ 86,211]. One problematic aspect of this internet-\nbased, two-step communication is that users may not be aware of the second gatekeeping\nstage, giventhatalgorithmiceffectsareoftenhidden, andpartisanbiasesofopinionleadersin\ncomment sections may also be obscured by anonymity [ 96,424]. Even when readers become\naware of content with a political slant opposed to their own, they may lack the motivation\nto consume that content that due to political polarization and confirmation-seeking tenden-\ncies[29,77,109,137,234,323,440]. Indeed, someresearchhasfoundthatwhilepeoplemight\nread more content when using diverse content selection tools, this leads primarily to an in-\ncrease in the amount of content consumed, not the diversity of the content [ 84]. One reason\nfor this outcome could be individual differences between diversity-seeking and challenge-\naverse people; challenge-averse people may tend not to consume diverse content [ 314]. To\naddress this bias, some prior works developed mechanisms to promote diverse news selection\nthrough design tools, such as NewsCube [ 342,343,344,345], or through nudges to read alter-\nnative viewpoints [ 406]. Though these prior works demonstrated improved exposure\u2014that\nis, clicks or visits to news sites with diverse political slants\u2014there is a gap in our understand-\ning of whether design tools can encourage critical engagement and whether such engagement\naffects users\u2019 perceptions of the news. Furthermore, these tools do not ensure that people\nread articles on the same events from politically diverse sources. We aim to bridge this gap\nby bundling pairs of articles on the same event from differing perspectives in a comparative\nannotation interface to test engagement and its effects.\n5.2.3 Designing for Information Consumption through Compari-\nson\nScholarship on reasoning, comprehension, and learning outlines different mechanisms in\nunderstanding information, whether users learn from data or the structure of informa-\ntion [20,225,474]. Sometimes, reading multiple sources alone can help change a reader\u2019s\nmental model of a subject [ 58,427]. Comparison can further help people recognize common\nfeatures shared across items or identify features that distinguish them [ 85,225,473,474].\nSome suggest that a comparison mechanism allows users to create broad concept categories\nby grouping similar concepts in either a bottom-up approach (clustering) or a top-down\napproach (assigning existing categories) [ 501]. In HCI research, creating design elements\nor affordances for easier information consumption is not new. For example, interactive ele-\nments allow users to choose where to go or what to read next [ 130]. Such design elements can\nassist readers in constructing a cognitive model to support a thorough understanding of a\nnews event. This construction of a news schema is supported by providing signals\u2014layouts,\nvisual elements, and textual structures\u2014to news readers that meet their expectations for\nnews [229]. For example, a newspaper reader\u2019s understanding of certain affordances (e.g.,\nsection labels, such as \u201copinion\u201d) may assist them in contextualizing and understanding the\ninformation [ 450]. It may even boost recall significantly [ 357]. Building on a similar idea, we\ndesign a comparative interface where pairs of articles are displayed side by side to facilitate\nthe comparison process for users.\n5.2.4 Annotating Using the Crowd and its Effect\nIn educational settings, annotation has long been used to boost reading comprehension,\ncritical thinking and meta-cognitive skill improvement. Many online annotation tools have\nbeen developed over the last decade, including Gibeo [ 34] and HyLighter [ 259]. Much of the\nresearch on annotation focuses on effects in classroom settings and often takes the form of\ncollaborative annotation [ 332]. On annotation tasks, prior research also suggests that users\u2019\nperformance may vary with demographic characteristics, political biases, task complexity,\nand subject matter [ 23,42,194,301,307]. Some research indicates that annotation tech-\nnology could improve users\u2019 effectiveness and efficiency in information-related tasks, such as\nsearch tasks [ 226]. Informed by such outcomes, we explore the effectiveness of comparative\nannotation in identifying content quality in a news consumption setting.\n5.3 F ormative Study F or Designing NewsComp : Think-\nAloud Interviews\nTo design an interface where users can simultaneously compare news articles, we began with\na set of think-aloud interviews3. We used two types of prototypes during this phase: a high-\nfidelity interface powered by algorithmic similarity metrics and a Google Drawings board.\nBy high-fidelity, we mean an interactive prototype with a working front-/back-end. During\nthis phase, we conducted a total of 10 think-aloud interviews with four members of our\nresearch groups (none of whom are authors of this paper) and six undergraduate students\nwith different majors (communication, political science, and computer science) and levels of\nnews consumption expertise. We used a separate set of participants for interviews with each\nprototype. These interviews revealed several aspects for consideration in our design. Below,\nwe discuss how our interview process evolved and summarize the insights we gathered.\n5.3.1 Inaccurate Algorithmic Annotation\nThis phase consisted of six interviews conducted with an interface we designed to support\ncomparison through similarity scores obtained from a state-of-the-art sentence transformer\nand its semantic sentence matcher4. All six participants mentioned that the algorithm\u2019s\nsimilarity annotations were inaccurate. This effect may result from differences in how users\nand algorithms compute similarities. Whereas a human can take a statement, event, sur-\nrounding sentences and other contextual aspects into consideration while finding similarity,\nalgorithms are likely to prioritize word similarity.\n3All of our studies were approved by the institutional review board at our university\n4https://huggingface.co/sentence-transformers/all-mpnet-base-v2\nFigure 5.1: A Google Drawings board used for think-aloud interviews. Similar to the high-\nfidelity interface, two articles are presented side by side here. Users can use all the available\ntools to link similar statements or highlight dissimilar statements that contain important\ninformation which should be included in the other article.\n5.3.2 Annotating on Google Drawings\nNext, we moved towards asking users to perform the annotation task using a Google Draw-\nings board. Here, we laid out a pair of news articles side by side on the drawing board\nby segmenting them into sentences (see Figure 5.1). Then, we asked our participants to\nperform two annotation tasks, one after another: (i) find similar statements between the\ntwo articles and draw lines between them, and (ii) revisit statements without corresponding,\nsimilar statements to see if they convey important information that should be included in\nthe other article. Since users reported inaccuracies in algorithmic statement matching, we\nrefrained from providing machine-generated annotations as suggestions. Figure 5.1shows a\nscreenshot of the interface and the annotations provided by one of the participants. As in\nthe prior interviews, we recorded participants\u2019 actions. These tasks took longer compared to\nthe previous interviews, as users iterated over each statement multiple times to add anno-\ntations. After completing the task, we asked semi-structured interview questions to clarify\nthe participants\u2019 actions. Our observations and the participants\u2019 answers helped us identify\nseveral considerations for our study, outlined below.\nCriteria for Finding Similarities: Content and Underlying Theme\nAfter the annotation task sessions, we asked participants to elaborate on the criteria they\nused to find similarities. From their responses, we found two similarity criteria: content\nand underlying theme. Though one participant mentioned structural position (e.g., the lede\nin a news article) as a criterion, none of the other participants mentioned it. In our final\ndeployment, we asked users to provide rationales for why statements were similar.\nConsiderations for Finding Important Information Present in Only One Article\nWhen asked about how participants chose statements conveying important information that\nwas worthy of inclusion in the other article, they mentioned two considerations. The first\nof these considerations was whether a statement fit the narrative of the other article. Par-\nticipants suggested that a statement in article A should only be labeled \u201cimportant\u201d if it\nfits the narrative in article B and provides important context missing from article B. Such\nmissing information might include statements detailing what happened after an event or how\nsomething happened. Even when a statement did not fit within the narrative of the other\narticle, some suggested that such a statement should still be included ( \u201cThis task is difficult,\nbecause the two articles are focusing on different narratives ... the other article does a bad\njob at portraying them as such [smuggled people being seen as inhuman]. Therefore, I think\nthat bringing the human cost displayed here into the other article would be helpful. \u201d -P3).\nParticipants mentioned that any information among the dissimilar statements that could be\ninferred from other statements or the context of an article did not need to be included. In\nlight of these nuances in the reasoning behind answering the questions, the result suggests\nthat participants were more critically engaged in reading and comparing the two articles\nduring this exercise than they were during the exercise that presented ML-recommended re-\nsults. Therefore, in our final design, we asked users to provide rationales behind annotations\nwhen finding something important to be included in the other article.\nReaders Have V arying Expertise in Identifying Similarities\nDuring these interviews, we noticed that readers\u2019 different levels of expertise in reading news\nand knowledge on the topic led to different annotations. During two interviews with partic-\nipants who had less news expertise, we presented another participant\u2019s thematic connection\nannotations and asked if the interviewees could understand the original annotator\u2019s inten-\ntions. Neither participant was able to explain the annotator\u2019s intentions. These findings led\nus to one of our research questions; specifically, how user characteristics relating to news\nexpertise affect comparative annotation.\nOverall, both studies revealed to us that a comparative annotation task could strengthen\nusers\u2019 engagement with news content, and we implemented such a task in our final design\nfor NewsComp.\n5.3.3 The NewsComp Interface and How It W orks\nBased on the findings from our two formative studies, Figure 5.2shows the final NewsComp\ninterface we implemented. At the top of the page, instructions for the tasks are laid out\nFigure 5.2: NewsComp Interface showcasing features with random annotations.\n1 Annota-\ntion instructions in two steps: find and connect similar statements, and answer if a statement\nwith no corresponding, similar statement is important to include in the other article.\n2 Tool-\nbartofinalizeaconnectionbyprovidingarationale\n3 Asolidarrowrepresentingaconnection\nalready created\n4 A dashed arrow indicating that the connection creation tool is active\n5 A\nlist of connections including deletion buttons\n6 The importance question in step 2.\n(\n1). The task asks the user to read the pair of articles and perform two steps: (i) find\nsimilar statements within the articles and create links between them, and (ii) check if a\nstatement with no corresponding similar statement in one article is important and worthy\nof inclusion in the other article. To help users understand how to perform the two steps,\nthere is a button below the task description that opens a video/GIF showing a tutorial of\nboth steps. In our deployment, we made a point of reminding users to watch the tutorial\nbefore proceeding. A toolbar below the taks description (\n2 ) helps users perform the first\nstep. Specifically, when users link two statements, the toolbar shows the statements that\nare highlighted (in yellow) and provides a text box where they can supply a rationale for the\nconnection right before finalizing the annotation. Below the toolbar, two news articles are\npresented side by side (as in our initial interface) with the article title at the top, followed\nby statements segmented exactly as in the original article. To limit preexisting biases, there\nare no links to the canonical source, nor any reference to the authorship. The interface also\nhides any nontextual components (i.e., videos and images). To begin connecting statements,\nusers click the two statements to select them. Selected statements are highlighted with a\nyellow background. To mark a statement as worthy of inclusion in the other article, each\nstatement contains a checkbox (\n6 ). There is also a text box below this checkbox for users\nto provide a rationale for marking a statement as important. When a user connects two\nstatements, the checkbox and text box for the statement are programatically disabled and\ngrayed out. After selecting a statement from each article, a dashed arrow representing a\npending connection appears (\n4 ). When a user finalizes a connection by filling in a rationale\nand clicking \u201cconnect,\u201d the dashed arrow (\n ) changes to a solid arrow (\n ) to represent a\nconfirmed connection (\n3 ). In addition, a list of connections appears to the right of the\narticles (\n5 ) to allow users to delete connections they have created. Users can delete a\nconnection by clicking the cross button next to it. After finishing both tasks, users scroll to\nthe bottom of the page and click a button to confirm they have finished the annotation tasks.\nC1(n=27)\nRead \nE\n1\nL \n& \nQA\nRead \nE\n2\nR \n& \nQA\nRead \nE\n2\nL \n& \nQA\nRead \nE\n1\nR \n& \nQA\nC2(n=20)\nT1(n=27)\nRead \n& \nAnnotate \nE\n1\nL+E\n1\nR\nQA\nRead \n& \nAnnotate \nE\n2\nL+E\n2\nR\nQA\nT2(n=35)Figure 5.3: Study design showing the experimental conditions for each of the four participant\ngroups. Here, C and T respectively represent control and treatment groups; the number of\nparticipants is given in parentheses. Because we used four articles, we had two control\ngroups (C1\u20132) and two treatment groups (T1\u20132). Article E XP represents an article about\nevent X from a source with political leaning P (L for left, R for Right). Articles with X= 1\nwere about immigration, while those with X= 2were about abortion. For example, E 2R\nindicates a news article about abortion from a right-leaning source. The E 1pair had high\ncontrast, while the E 2pair had low contrast. In the study, we randomized the order/position\nof the articles for each participant.\nThis system was built with a React front end with Bootstrap CSS , and a Flask back-end\nserver with a MySQL database. To draw the connection lines, we used the Leader-Line5.\nTo scrape news articles, we used NewsPaper6.For the formative study, we used Sentence\nTransformer7to generate sentence embedding and calculate sentence pair similarity score.\n5.4 Evaluation Study\nUsing NewsComp, we examine two research questions:\nRQ1.How wel l do users perform comparative annotation?\nRQ2.How does comparative news annotation affect users\u2019 perceptions of credibility and\nnews quality?\nTo answer, we conducted a between-subjects experiment in a controlled environment using\n5https://github.com/anseki/leader-line\n6https://newspaper.readthedocs.io\n7https://huggingface.co/sentence-transformers\ntwo pairs of news articles. We created a separate interface for the control users. In the\ncontrol interface, only one article is shown at a time. Figure 5.3shows the study design for\nour experiment with four experimental groups: two treatment and two control groups. Each\ngroup read two news articles. While the treatment group was able to view two articles on\nthe same topic simultaneously, the control users read articles on different topics sequentially\nto account for any learning effects from recall and comparison. All four groups read stories\nfrom two sources with different political leanings. We randomized article location (left or\nright) for the treatment group and article order (first or second) for the control group to\naccount for any ordering effect.\n5.4.1 Article Selection\nFor our study, we picked two politically contentious topics (immigration and abortion),\nwhere reading content from diverse perspectives can be beneficial. The topics were chosen\nfrom recent news coverage at the time of the user studies. For each topic, we chose articles\npublished at least two weeks prior to deployment to limit possible recall effects. Pairs\nwere selected by finding two articles from politically opposed sources under the same story\nbundle on Google News. When choosing article pairs, we picked pairs with different levels of\nsimilarity and difference. Since the article pair on abortion(E 2) had more similarities than\ndifferences, we categorized the pair into the low-contrast category. On the other hand, the\npair on immigration (E 1) had more apparent differences than similarities, so we categorized\nit into the high-contrast category. This categorization was confirmed by our experts\u2019 gold\nstandard annotations (see 5.4.6), which identifiedmore than 50% of the article text as similar\nin the low-contrast pair while identifying less than 25% of the text as similar in the high-\ncontrast pair. The selected articles (E 1L, E 1R, E 2L, E 2R) are reproduced in Appendix B.2.\nCredibility[ 303]i) It is biased (I)\nii) It is not fair (I)\niii) It doesn\u2019t tell the whole story (I)\niv) It is not accurate (I)\nv) It cannot be trusted (I)\nQuality[ 468]i) It shows multiple viewpoints\nii) It has information on causes and consequences\niii) It provides balanced viewpoints\nCurrent\nEvent\nKnowledge\n(CEK) [282]i) Who is/was Kamala Harris? (a) President (b) Vice President (c) Senator from California (d) UN\nAmbassador\nii) What does the recent Supreme Court ruling overturning Roe v. Wade entail? (a) Abortion is not a\nconstitutionally protected right (b) In Missouri, abortion is legal before 24 weeks (c) All US states allow\nabortion for rape and incest (d) There is confusion about abortion rights relating to miscarriage\nand ectopic pregnancy\niii) In California (a) everyone, including undocumented individuals, has the right to access their\ncrime report (b) there are no immigrant detention facilities (c) state and local police officers cannot\ninquire about an individual\u2019s immigration status during a routine check\niv) How is the Fed responding to the high inflationary economic condition? (a) Raising the interest rate\n(b) Lowering the interest rate (c) Keeping the interest rate the same\nValue of Me-\ndia Literacy\n(VML) [475]i) Two people might see the same news story and get different information from it\nii) People are influenced by news whether they realize it or not\niii) News is designed to attract an audience\u2019s attention\niv)Writing techniques can be used to influence a viewer\u2019s perception\nv) People should accept information from the news on face value (I)\nvi) It is the job of citizens to overcome their own biases in consuming news\nvii) People need to critically engage with news content\nviii) The main purpose of the news should be to entertain viewers (I)\nTable 5.1: Questionnaires used in the study. Credibility and quality questions were asked\nafter reading or annotating. (I) means these items were inverted for analysis. The correct\nresponses appear in boldface. The CEK questionnaire contains multiple-choice questions,\nwhile the VML, credibility, and quality questions are 5-point Likert items. The VML and\nCEK items were presented in the pre-survey.\n5.4.2 Measuring Credibility , Quality , Current Event Knowledge,\nMedia Literacy\nTo address RQ1, we measured two expertise metrics: current event knowledge and value of\nmedia literacy . Here, the value of media literacy differentiates users\u2019 general media literacy\nfrom their expertise on topics related to our study. To answer RQ2, we use perceptions of\narticle credibility and quality, and we compare the treatment groups\u2019 assessments with the\ncontrol groups\u2019. Below, we discuss how we measured each metric.\nCurrent Event Knowledge (CEK) and V alue of Media Literacy (VML)\nTocaptureusers\u2019news-relatedknowledge, weadaptedtheCurrentEventKnowledgemeasure\ncreated by Maksl et. al. [ 282]. Here, we included questions relevant to the two chosen article\ntopics and some other timely topics (see Table 5.1). To measure users\u2019 perceptions of media\nliteracy, we used a prior scale created by Vraga et. al. [ 475]. To calculate CEK scores, we\nadded 1 point for each right answer and deducted 1 point for each wrong answer. In our\nstudy, CEK ranged from -1 to 7, with 4 being the median value. For VML, we average the\nresponses across items. The score for VML ranged from 1 to 8, with 6 being the median.\nFinally, for both measurements, we use the median score to create a binary response variable\nwith values \u201clow\u201dand \u201chigh.\u201d Forexample, users scoring less than 4 in CEK were categorized\nas low-CEK users and vice versa.\nCredibility & Quality\nWe used a five-item questionnaire by Meyer et al. [ 303] to measure users\u2019 perceptions of\ncredibility for every news item (see Table 5.1). In our study, we found that this measure\nhad high internal consistency (Cronbach\u2019s \u03b1= 0.85), close to the result in Meyer et al. For\nnews quality detection, we use a modified version of the questionnaire suggested by Urban\net al. [468] (see Table 5.1). Similarly to the credibility questionnaire, participants\u2019 responses\nto these questions showed high internal consistency (Cronbach\u2019s \u03b1= 0.89). We measured all\nof these items on a 5-point Likert scale, from \u201cStrongly Disagree\u201d (1) to \u201cStrongly Agree\u201d\n(5). Note that scores for the credibility items are inverted for analysis.\n5.4.3 Recruitment\nTo recruit participants for our final NewsComp interface, we used Facebook advertising\nfor two weeks in August 2022. This method allowed us to organically recruit diverse par-\nticipants from a large pool. We also did limited advertising on news subreddits (such\nas, r/politics, r/moderatepolitics, r/news, r/neoliberal, and r/conservative )\nthrough private messages from our research group\u2019s Reddit account, reaching about 40 users.\nTwo users responded to these messages. Since the article topics are US-centric, our ads tar-\ngeted people living in the US with interest in news-related pages. Thus, our study result\nmay not be generalizable beyond the context of the US. The advertisement led users to a\npre-survey to sign up for the study. In the pre-survey, we screened users with the following\nstudy eligibility criteria: (i) I am 18 years old or over, (ii) I reside in the United States,\n(iii) I read at least one news article online every day, (iv) My primary language for news\nconsumption is English, and (v) I use a laptop or a desktop for online news reading. Besides\nthese criteria, we also screened out users who failed attention checks, had an IP address\noutside of the US, or spent very little time (less than half of the median time, which was\ntwo minutes) in the pre-survey. Overall, 685 users clicked on the survey, out of which 238\npassed the screening criteria. We invited all of these participants to the study in multiple\nbatches. Ultimately, 109 participants completed the study. Participants who completed\nthe study were compensated with $7.50 gift cards for the 30-minute study, in line with the\nstate\u2019s minimum wage.\n5.4.4 Procedure\nUsers who met the screening criteria in the pre-survey filled out the rest of the survey, which\ncontained questions about demography, including gender, age, race, education, and political\naffiliation, and the two news expertise measures. Within three days of submitting the survey,\nwe invited eligible users to participate in the study via email. In the email, we provided the\nconsentdocument, instructionsforusingtheinterface, andalinktothestudywebsite. When\nusers clicked the link to access the study website, they were randomly assigned to one of four\ngroups (two treatment and two control) to ensure a balanced sampling design. Since some\npeoplewhoclickedthelinkultimatelydidnotcompletethestudy,thefinalgroupsizesarenot\nexactlyequal. Recallthataftervisitingthestudywebsite, treatmentuserswereaskedtoview\na tutorial on how to add annotations before reading and annotating articles. After finishing\nthe annotation process, users responded to the credibility and quality questionnaire. The\nannotation interface, including the articles and annotations, was still visible at this time. In\nthe control condition, there was no annotation task, and participants read only one article at\na time. The control users additionally responded to the credibility and quality questionnaire\nafter reading each article (see Figure 5.3).\n5.4.5 Participant Pool\nDue to screening and self-selection bias, our study participants were not equally distributed\nin certain demographic dimensions, such as age. Additionally, since one of our aims was to\nidentify how users with different demographic characteristics compare in their annotations\nin RQ2, we invited more users in the treatment condition. Though our pre-survey had\nFigure 5.4: Graphs showing the distribution of participant demographics across the treat-\nment and control groups.\na large number of categories for different demographic characteristics, we merged groups\nwith small numbers of respondents for more meaningful differentiation. Figure 5.4shows\nthis distribution. Here, we grouped two consecutive age groups, merged participants from\nnonwhiteracestogether, anddividedrespondentsbyeducationintothosewithanyuniversity\ndegree versus those with no degree. Generally, participants were skewed towards younger\nage groups, male, white, college-educated, and politically left-leaning.\n5.4.6 Gold Standard Generation\nTo compare annotation quality, we used expert-produced gold standards. To obtain gold\nstandards for both the annotations and the perception metrics, we recruited two senior PhD\nstudents from the university\u2019s Department of Communication for an interview session. Both\nhad past experience in conducting news content analysis research and were familiar with\nboth topics used in our study. One of the experts also worked as a journalist for more\nthan five years. To generate credibility and quality perception scores, both were given the\noriginal links to the news articles and asked to rate the RQ1 questions8. They were also\n8This task was performed before generating annotations. We did not ask them to work within the\ncomparative interface, with the assumption that they would rate the articles accurately irrespective of any\ncomparison.\nImmigration Abortion\n(a)2.55.07.510.012.5total annotation\nImmigration Abortion\n(b)02468correct annotation\nImmigration Abortion\n(c)0.00.20.40.60.81.0recall\nImmigration Abortion\n(d)0.00.20.40.60.81.0precisionFigure 5.5: Distribution of connection making by users. White and red dots respectively\nrepresent the average and experts\u2019 annotation.\nallowed to do any outside research they wished. After rating their perceptions, we provided\nthe article pairs in a Google Drawings board and asked them to add annotations, much like\nthe process from our think-aloud interviews. After adding annotations independently, the\nexpert annotators met with each other to resolve any conflicts. Through this method, we\nbuilt consensus around our gold standard annotations.\n5.5 Results\nTo answer both research questions, we compared users\u2019 annotation and perception responses\nagainst the expert-produced gold standards. For this purpose, we performed a series of\nanalyses involving mean testing, analysis of variance, and regression. For free-form text\nresponses (specifically, the annotation rationales), three authors performed thematic coding\n(see supplemental document for data and codes). Below, we outline the results.\nImmig\n[L]Immig\n[R]Abort\n[L]Abort\n[R]\n(a)51015total annotation\nImmig\n[L]Immig\n[R]Abort\n[L]Abort\n[R]\n(b)0123correct annotation\nImmig\n[L]Immig\n[R]Abort\n[L]Abort\n[R]\n(c)0.00.20.40.60.81.0recall\nImmig\n[L]Immig\n[R]Abort\n[L]Abort\n[R]\n(d)0.00.20.40.60.81.0precision\nFigure 5.6: Distribution of importance detection by users. White and red dots respectively\nrepresent the average and experts\u2019 annotation.\n5.5.1 RQ1: How well do users perform comparative annotation?\nPerformance on Connection-Making\nFigure5.5shows the distribution of total connections users made, correct connections made,\ntheir recall, and precision relative to the gold standard. The median number of connections\nbetween articles fell below the gold standard for both article pairs, as shown in Figure 5.5(a).\nBetween the two article topics (immigration and abortion), users on average made more\nconnections\u2014correct or otherwise\u2014between the abortion articles (the low-contrast article\npair). Furthermore, users\u2019 precision was significantly better on the abortion articles than on\nthe immigration articles (Mann-Whitney U = 136.5, p < 0.001). However, we did not find\nany significant difference in recall.\nPerformance on Importance Detection\nFigure5.6shows the distribution of total importance annotations users made, correct im-\nportance annotations, recall, and precision relative to the gold standard. As shown in\nFigure5.6(a), the median number of importance annotations was consistently above the\ngold standard. Between the two article pairs, users on average annotated more items as\nimportant\u2014correctly or otherwise\u2014in the immigration articles (the high-contrast article\nIncorrect\nAnnotationsCorrect\nAnnotations\n(a)51015annotated by # of users\nConnection Making\nIncorrect\nAnnotationsCorrect\nAnnotations\n(b)510Importance Detection\n2 4 6 8\nThreshold (# of users)\n(c)255075100Performance on Connection\nMaking After Filtering out\nAnnotations by User Count\nprecision\nrecall\nf1\n2 4 6 8\nThreshold (# of users)\n(d)20406080100Performance on Importance\nDetection After Filtering out\nAnnotations by User Count\nprecision\nrecall\nf1Figure 5.7: (a & b) User agreements on incorrect and correct annotations. (c & d) We\nfiltered annotations by the number of concurring users to see how annotation performance\nchanges as the threshold moves. Here, for connection making and importance detection, the\nF1 scores peak at five (55%) and six (41%) users, respectively.\npair). Though users\u2019 recall was high due to the large numbers of importance annotations\nadded, their precision was low, with the median per article being less than or equal to 0.25.\nComparatively, for connection-making annotation task, users\u2019 median precision and recall\nare higher than these median for importance annotations.\nAnnotation Agreement\nNext, we examined how users agreed on annotations among themselves by plotting the\ncount of users annotating each item. Figure 5.7shows the distribution of this analysis.\nHere, we differentiated between agreement on correct and incorrect annotations. For the\nconnection-making task (Figure 5.7(a)), we found that the annotation count for correct\nitems was significantly higher than the count for incorrect items (Mann-Whitney U = 517.0,\np < 0.01). However, for importance detection (Figure 5.7(b)), the corresponding counts\ndid not differ significantly. Furthermore, we also observed some outliers (high agreement\nin some annotations) in the connection-making annotation task not made by the experts.\nIn Figures 5.7(c) and (d), we examine how annotation performance changes by filtering\nannotations by the number of concurring users. Overall, a threshold of five users produces\nthe highest F1 score (55%) for the connection task, while peak performance (41%) occurs at\nlow high\nCEK0.00.20.40.60.81.0recall(a)connection making\nlow high\nCEK0.00.20.40.60.81.0precision(b)connection making\nlow high\nCEK0.00.20.40.60.81.0recall(c)importance detection\nlow high\nCEK0.00.20.40.60.81.0precision\n(d)importance detection\nlow high\nVML0.00.20.40.60.81.0recall\n(e)connection making\nlow high\nVML0.00.20.40.60.81.0precision(f)connection making\nlow high\nVML0.00.20.40.60.81.0recall(g)importance detection\nlow high\nVML0.00.20.40.60.81.0precision\n(h)importance detectionFigure 5.8: Distribution of recall and precision for connection-making and importance de-\ntection divided into low/high CEK users (top), and low/high VML users (bottom).\na threshold of six users for the importance detection task.\nEffect of News Expertise\nWe investigated whether levels of news expertise affect users\u2019 annotation performance with\nNewsComp by performing Mann-Whitney U tests on precision and recall scores (for both\nconnection-making and importance detection). Figure 5.8shows the distribution of those\nscores divided by two news expertise criteria, Current Event Knowledge (CEK) and Value of\nMedia Literacy (VML) perception. Here, only for recall scores on the importance detection\ntask (Figure 5.8(c)), we found significant differences in values between low and high CEK\n(Mann-Whitney U = 810.5, p < 0.05). None of the other tests detected a statistically\nsignificant difference. Furthermore, we modeled these variables against user characteristics\nwith a series of linear models (M1\u2013M4 in Table B.1in Appendix B.3). These models were\nCode Definition Example Response\nConnectionEmpty (20%) Empty or N/A response\nPerson (19%) Mentions that both statements refer to one or more\npersons involved in an event (not including quotes)They are similar because they both mention\nthe owners of the truck\nLocation (1%) Mentions that both statements refer to the same\nlocation where an event occurredThis excerpt shows where the truck was\nfound and both gave an identical location\n...\nDate (2%) Mentionsthatbothstatementsrefertoasingledate\nwhen an event occurred or will occurBoth statements note that the ban wil l take\neffect on August 25th\nQuote (9%) Mentions that both statements reference either the\nsame quote or different quotes from the same per-\nsonThey are similar because both highlight a\nquote from Becerra (HHS Secretary) in-\nsisting ...\nInformation\n(48%)Mentions that both statements contain the same\ninformation describing the what, why, or how of\nthe eventSimilar because [both] discuss Medical\nT reatment and Labor Act\nImportanceEmpty (29%) Empty or N/A response\nImportant\n(15%)Mentions that a statement is important without\nproviding a reason[because it is an] important part of the news\nClarification\n(43%)Mentions that a statement clarifies or elaborates on\nother statementsThe statement in the other article from\nBecerra (HHS Secretary) is confusing .\nMissing (8%) Mentions that a statement presents a perspective\nmissing from the other articleNo statement from Lawrence in the other\narticle\nFactual (4%) Mentions that a statement is factual and not an\nopinionF acts here. It isn \u2019t opinion being interjected\ninto a news story.\nTable 5.2: Coding scheme for annotation rationales.\nsimilarly significant ( \u03b2= 0.35, p < 0.01in M1). However, since the model effect sizes\n(R2) are low (0\u0303.10), there may be confounding variables not accounted for in these models\naffecting the outcome. It is therefore difficult to make any strong claims in this regard, and\nwe instead leave this to future experiments.\nReasons behind the Annotations\nThree of the authors thematically coded the rationales provided by the participants during\nannotation. Each author performed initial coding and discussed the results with the others\nto agree upon a code book. Then, the first author coded the responses accordingly and the\nothers checked the final codes. Participants annotated 250 connections and 305 important\nstatements. Table 5.2shows the coding scheme we developed for each annotation task\nwith sample responses matching the code. There are six codes for connection-making and\nfive codes for importance detection (including one in each for empty responses). Here, the\ncodes in the connection-making task offer potential answers to the 5W1H questions (Who,\nempty person location date quote information\n(a) Connection Making0204060count 0.46\n0.34\n0.331.00.430.52\nIncorrect Annotations\nCorrect Annotations\nempty important clarification missing factual\n(b) Importance Detection020406080100count\n0.18\n0.110.23\n0.2 0.23Figure 5.9: Annotation counts by coded rationales divided into correct and incorrect anno-\ntations. The numbers over the bars represent the ratio of correct to incorrect annotations\nwithin each code.\nWhat, Where, When, Why, and How). For example, the code \u201cPerson\u201d answers the who\naspect of the event, while the code \u201cInformation\u201d answers a combination of what, why,\nand how questions. For importance detection, users sometimes claimed that a statement\nwas important without explaining the reason for this assessment. In other cases, users\nmentioned that a statement was important because it clarified or elaborated on existing\nstatements, or because it provided an account from a missing perspective. Figure 5.9shows\nthe count of each rationale in terms of the developed codes, divided into correct and incorrect\nannotations. For connection-making (Figure 5.9(a)), we found that a majority of users\nidentified similarities when the same information was presented in both articles, followed\nby mentions of the same person. For importance detection(Figure 5.9(b)), many responses\nwere coded into the clarification and elaboration categories, followed by the empty response\ncategory. Figure 5.9suggeststhattherationalesarenotdistributedproportionallyforcorrect\nand incorrect annotations. Notably, users appear more likely to make errors in certain cases.\nFor example, for importance detection (Figure 5.9(b)), the ratio of correct and incorrect\n\u201cimportant\u201d annotations shows that these annotations are more likely to be mistaken than\nothers. Although we performed regression on the codes to differentiate correct and incorrect\nannotations, the model effect sizes were very low for both models ( R2<0.05).\nSince differentiating correct and incorrect annotations by codes did not work well, we fit two\nFigure 5.10: False positive detection with OLS using the top 50 TF-IDF words in users\u2019\nresponses. Here, we listed only words with significant coefficients. For example, when users\u2019\nmentioned\u201cquote\u201dinarationale, theannotationwaslesslikelytobeerroneous. Ontheother\nhand, when users mentioned the general nature of the event (\u201clawsuit\u201d in this example), the\nannotation was more likely to be erroneous. The model effect sizes ( R2) were 0.34 and 0.22,\nrespectively.\nImmigration[L] Immigration[R]\n(a)0.00.20.40.60.81.0Quality\nControl\nTreatment\nExpert\nAbortion[L] Abortion[R]\n(b)0.00.20.40.60.81.0Quality\nControl\nTreatment\nExpert\nImmigration[L] Immigration[R]\n(c)0.00.20.40.60.81.0Credibility Control\nTreatment\nExpert\nAbortion[L] Abortion[R]\n(d)0.00.20.40.60.81.0Credibility Control\nTreatment\nExpert\nFigure 5.11: Interaction effects of groups and articles. We only found a marginal interaction\neffect (p=0.052) for credibility score on articles regarding immigration (c).\nmodels to predict incorrect annotations (false positives) for both the connection-making and\nimportance detection tasks using the top 50 TF-IDF9text features from users\u2019 responses\non the rationals. Figure 5.10shows the text features with significance for this analysis.\nExamining the words with significant coefficients, we can see that some words are generic\n(e.g., \u201cquote\u201d, \u201csimilar\u201d, \u201ccontext\u201d), while others are article-specific (e.g., \u201cGarland\u201d (the\ncurrent attorney general), \u201clawsuit\u201d, \u201csmuggling\u201d). These differences suggest that such\ngeneric words in rationales can be used across articles to differentiate false positives from\ntrue positives, while specific words may not be usable. We discuss these results further in\nsection5.6.1.\n9TF-IDF stands for term frequency\u2013inverse document frequency, a statistic representing how important\na word is to a document in a collection of documents\nTheme(n) Example Response\nPerspectivesandBiases(22) They were taking different sides of the equation and putting forward different thought\nprocesses\nInformation Placement or\nDepth (14)The right article was less descriptive and focused more on the restrictions and not the\ncase. It was definitely telling the story from one point of view. The article on the left\nwas very informative and unbiased\nFactuality or Opinions (16) Article B provided responses from the Idaho government, whereas Article A did not\ninclude commentary from Idaho, but instead from Texas which did not seem relevant\nEmpathetic Reporting (5) There were more humane aspect in the article on the left\nInflammatory Language (3) Article B seemed to be making the issue out to be more controversial by going back\nand forth between perspectives more frequently\nTable 5.3: Themes in users\u2019 responses to a question asking what they noticed about the two\narticles overall. Note that while an example response may belong to multiple themes, only\nthe portion relevant to the listed theme is presented in bold.\nComparative Perception between Article Pairs\nAfter the annotation task, in addition to asking about credibility and quality perception,\nwe asked users what they noticed when comparing the two articles (\u201cComparing the two\narticles, what else did you notice about how each portrayed the issue?\u201d). Analyzing the\nresponses, we found five themes, summarized in Table 5.3. Notably, more than one fourth\nof the participants remarked on informational placement or depth (16/62), perspectives and\nbiases(22/62)andfactuality/opinions(16/22). Somealsonoticedempatheticnewsreporting\n(5/62) and the use of inflammatory language (3/62).\nPerception of the T ool\nApart from the task-specific questions, we also asked annotators about their perceptions\nof the NewsComp tool. Overall, perceptions of the tool were split among positive (28/62),\nneutral (21/62), and negative (15/62) sentiment. The reasons behind negative sentiment\nincluded the lengthy nature of the task (3/15), difficulty in performing annotation (8/15),\nand confusion regarding the instructions (4/15). While it may have been hard in the begin-\nning, users quickly learned how to use the tool ( \u201cIt was a bit confusing to learn how to use\nthe tool, but it was easy to use once I played around with it. \u201d -U1). Improvements to the\ntool design could potentially address these issues. For instance, during connection-making,\na search tool could assist users with finding similar statements quickly. Users also suggested\nimprovements such as allowing them to set the weight of the connected lines, change the\ncolors of lines, and see how others annotated a statement.\n5.5.2 RQ2: How does comparative news annotation affect users\u2019\nperceptions of credibility and news quality?\nTo answer this question, we performed a two-way ANOVA on the response variables, cred-\nibility scores, and quality scores. To calculate each score, we first summed item scores for\nthe questionnaire on each score (credibility and quality) and standardized them on a [0, 1]\ninterval. Then, we performed the two-way ANOVA on the group and article interaction.\nFigure5.11shows the result of this analysis. We did not find any significant difference in\nquality perceptions. We also performed a one-sample t-test on users\u2019 quality perception re-\nsponses against those of the experts. Though we did find some similarity for the abortion\narticles (Figure 5.11(b)), in the case of the immigration articles ( 5.11(a)); that is, the high-\ncontrast pair, the difference between the users\u2019 and experts\u2019 ratings was significant. This\nresult suggests that neither group performed well on the quality question, especially for the\nhigh-contrast article pair.\nNext, we analyzed the interaction of credibility with the articles. In Figure 5.11(c), our anal-\nysis found that the interaction between the experimental group and the article is marginally\nsignificant for the articles on immigration with a close to moderate effect size (F(1) = 3.83,\np = 0.052, Cohen\u2019s f = 0.22). We did not find any significant effect for articles on abor-\ntion. Note that when we fit a mixed-effects regression model on the same data additionally\nconsidering repeated measure, we found significant interaction effects on the high-contrast\narticles (see Appendix B.4). Moreover, when we look at the articles on abortion, despite\nthe experts not performing comparative annotation, their perceptions of one article (from\na left-leaning source) were significantly lower than those of the other (from a right-leaning\nsource). During our discussion, we found that experts used certain criteria to arrive at this\nassessment10. On the other hand, the comparative annotation task may have given users the\nimpression that both articles are highly similar (leading to similar ratings) and discouraged\nthem from examining other differences too closely. This result suggests that there is room\nfor improvement in task designs for comparative annotation. We discuss further implications\nin section 5.6.2.\n5.6 Discussion\nThrough our experiment, we found that users generally perform poorly in annotation tasks\nfor finding similar statements and identifying important statements among statements with\nno similarity between two news articles. However, they have better precision in finding sim-\nilarities than in identifying important statements. We found that when a high number of\nusers find two statements similar, such annotations have a high chance of coinciding with ex-\nperts\u2019 annotations. Furthermore, we found that users with low current event knowledge may\nperform better annotations. Analyzing users\u2019 rationales behind the annotations, we found\nseveral reasons for finding similarities (e.g., mentions of the same person or information)\nand identifying important statements among statements with no similarity (e.g., statements\nclarifying something or providing a missing perspective). Furthermore, we found that certain\nwords have significant power in differentiating false and true positives. After annotation,\n10These articles talk about the DOJ\u2019s challenge against an abortion restriction law in Idaho. Here, the\nexperts mentioned that the article from the left-leaning source did not mention an opposing perspective,\nsuch as that of Idaho\u2019s government. Note, however, that the article did cite the state attorney general of\nTexas, who supports abortion restrictions.\nusers also mentioned noticing differences in how article pairs represented things, such as\nperspectives, information placement, information depth, and facts/opinions. In RQ2, we\nfound that annotation tasks may have limited effects on users\u2019 perception of news credibility\nfor high-contrast news articles. Below, we discuss the implications of these results.\n5.6.1 RQ1: Annotation Performance\nOur results indicate that although users perform poorly in general, their performance varies\nacross annotation task types and article pairs, depending on the degree of contrast between\nthearticlesinthepair. Comparedtotheexperts,averageusersseemtofindfewerconnections\nandconsidermorestatementsworthyofinclusionintheotherarticleinapair. Thisdifference\nshows how experts and users differ when reading two news articles. This difference could\nstem from analytical capabilities; that is, perhaps finding similarities and differences is a task\nthatrequiresparticularexpertiserelatingtonews. Or, perhapslowknowledgeusersaremore\nattentive to the articles. Another reason behind the difference could be users\u2019 preconceived\nbiases regarding the media in general [ 216]. Such perceptions may have influenced users to\nsee fewer connections and more differences. Therefore, one direction for future research may\nbe to examine the rationales behind identified differences by varying the task complexity\nand user characteristics. For example, we can ask readers to perform small subtasks, such as\nidentifying sources or labeling word choices [ 184] to test if these influence their perceptions\nof bias.\nAnother noteworthy aspect here is that our participant group came from Facebook ad-\nvertising, not from platforms like Amazon Mechanical Turk or Upwork typically used for\ncrowdsourcing. This suggests that users outside of crowd work platforms can also perform\neffectively on crowdsourced tasks. In the future, research could look into how well workers\nfrom crowdsourcing platforms and other sources compare in terms of performance.\nOur result indicates that crowd annotation in subjective tasks is to a little extent affected\nby users\u2019 backgrounds\u2014in our case, their news expertise, aligning with prior works [ 116,\n205,386]. Therefore, we can train users using their news expertise as a targeting criterion.\nSince user performance also varies by task, helping users improve quality on a particular task\narea might also help. Furthermore, designers can support users in annotation tasks through\nvarious interventions. For example, since our TF-IDF models identified some generic words\nthat can distinguish false positives, such data could also be used to provide users with\nfeedback or warnings to improve annotation quality.\nWe also discovered the effects of comparative annotation on users\u2019 overall impressions, lead-\ning to differences in perceptions of viewpoints, information attributes (placement, depth,\nand factuality/opinion), and emotional attributes (empathetic vs. inflammatory language).\nThese differences could impact users\u2019 attitudes towards an article. For example, between\ninformational and emotional attributes, understanding which differences impact perceptions\nof trustworthiness could be one future avenue of work.\nTo improve users\u2019 performance, one option could be through collaboration\u2014learning from\neachotherthroughsocialannotation[ 201]. Indeed, priorresearchshowsthatwhenpeoplesee\nothers\u2019 annotations, it can persuade them to take certain actions, such as changing ratings\nwhenfacedwithopposingsocialopinions[ 98]. Furthermore,researchsuggeststhatdisplaying\nsocial information about the annotator, such as their level of expertise, can persuade and\nbuild trust [ 165]. Incorporating social information on other annotators during collaboration\nmay improve learning. In a collaborative environment, we still need to handle annotator\nbias, since bias from a small group of users could propagate to a larger pool of users and\ncause unexpected effects. Therefore, examining such collaborative annotations and their\nimpact on user performance is another potential direction of research.\n5.6.2 RQ2: The Effect of Engaging through Annotation\nWhile it may not be true in all cases, our results indicate that in cases where there is\nsignificant contrast between a pair of news articles, users might be somewhat influenced\nby comparative annotation tasks. Our work can inform related future works on improving\nengagement with plural viewpoints through annotations [ 493]. Compared to works that\nshow visualizing biases alone does not improve perception of bias [ 426], our work suggests\nthat additional engagement could be helpful. The effect we see may stem from complex\ninformation processing that occurs when users engage with competing messages [ 37]. Since\nour result did not reveal any universally significant effect, it does point towards the idea\nthat only certain perceptions are affected. Therefore, one direction for future research could\ninclude looking into different perception paradigms to further identify the limits of such\neffects.\nEven though we found limited effects on perceptions of credibility, this does not necessarily\nlimit the applicability of comparative annotation. As we saw in section 5.1.6, a user\u2019s under-\nstanding of the differences between articles could have other impacts. Besides, repeatedly\nannotating two sources can create certain impressions in the long run. For example, seeing\nrepeated differences in the use of factual statements or depth in reporting could affect users\u2019\nperceptions of credibility. Furthermore, we can ask whether crowdworkers from such plat-\nforms as Mechanical Turk would also remain unaffected by the annotation task. In any case,\nNewsComp could be purposefully deployed to crowdworkers while also providing general\nusers the option to perform annotation. In such a case, users desiring more ways to engage\nand community fact-checkers might be more attracted to it. Regardless, there are further\nuses for the annotated data.\n5.6.3 Applications of Annotated Data\nOur annotated data could be used in various ways. For instance, it could be incorporated\ninto a system that combines information from multiple sources to provide a holistic view of\nan event. It is not uncommon in online spaces for information overload to make it harder for\npeopletoefficientlyconsumeinformation[ 6,122]. Aholisticviewcouldparticularlybeuseful\nto users in such a scenario, especially for sensemaking purposes [ 487,488]. Such a system\nwould mimic strategies humans typically employ to consume information efficiently, such as\norganizing information by tagging, sorting, and indexing [ 73]. We could further build upon\nthis by introducing mechanisms for peer-curated information [ 363] A second potential use of\nthe annotated data would be in training algorithmic models to generate better annotations,\nwhich could in turn be used to better curate information for readers. As we saw in our initial\nthink-aloud interviews, people find the accuracy of existing SOTA ML systems insufficient\nfor finding semantic similarities and differences. The annotated data could help to improve\nsuch algorithms. A third use of the data is for fact-checkers. Fact-checkers can use annotated\ninformation to validate claims through the use of linked statements from multiple sources.\nThey can also use such links to trace the origins of statements. Perhaps a portion of these\nfact-checking tasks could be delegated to automatic fact-checking algorithms. Furthermore,\neven crowd fact-checkers (e.g., from Twitter\u2019s BirdWatch) could use the annotated data to\nvalidate claims.\n5.6.4 Merging Articles Into One and T esting Effects\nOne of the goals of this research on comparative annotation was to combine diverse per-\nspectives into one. With our annotated data, crowd tasks can be designed to accomplish\nsuch merging of perspectives. However, there are some considerations for task design in this\nprocess. Take similar statements as an example\u2014if two statements are very similar, a task\ncould ask workers to choose one or the other. On the other hand, if selecting one state-\nment necessarily results in the omission of important information from the other, then the\ncrowd task may also require editing. In the case of merging important disparate statements,\nas noted in our think-aloud interviews, one important consideration is checking whether a\nstatement fits the narrative of the current article. We can either include this criteria or\ndiscard it, which would lead to differences in the outcome, (i.e, the merged article). Taking\na step further, this merging process can be extended from article pairs to larger groups of\narticles. Merging larger groups of articles would require a multistep selection, voting, and\nreconciliation process. Finally, while we found that the effect of annotation on perception\nwas limited, could merged articles affect users\u2019 perceptions of an event differently than ar-\nticles from a single source? Future research answering such a question would generate new\nknowledge regarding the utility of comparative annotation.\n5.6.5 Implications for Comparative Annotation T ask Design\nMotivated by users\u2019 perceptions of NewsComp, we identified two major issues in the com-\nparative annotation task: the lengthy nature of the task and difficulty in performing the\ntask. Since one of our research questions focused on the impact of performing annotation,\nour experiment was designed so that users performed a complete annotation task on two ar-\nticles before responding to the questions. If the annotation impact is not of interest, both of\nthese issues can be resolved. First, we can modularize the tasks by breaking them into small\npieces (e.g., making connections between two paragraphs instead of two entire articles), in\nline with prior research on devising microtasks for complex work [ 232,233]. However, could\nsuch modularization cause a backfire effect? For example, if an annotator is assigned two\ndissimilar paragraphs from a pair of broadly very similar articles, could that skew their\nperception? This is one potential consideration for designing small, modular tasks.\nSecond, even if the task is not divided into smaller components, there are other options for\nimprovement. For instance, finding similarities can be made easier through the addition of\nsuch features as automatic suggestion and filtering. Here, algorithms can provide automatic\nsuggestions and users can search by keyword to limit the options to choose from.\nThird,taskscanbedividedforco-annotationtoreducedifficulty. Forexample,oneannotator\nmight suggest connections while another annotator votes on the suggestions. In addition,\nas a tutorial, displaying example annotations from other users could also help resolve some\nconcerns. However, the examples need to be generic enough not to significantly impact users\u2019\nown future annotations.\nFourth, apart from issues related to task difficulty, there is another issue that will need\nattention in the future. In the think-aloud interviews and the deployment of NewsComp,\nwe discovered some disconnects in the rationales provided for annotations. Particularly, for\nconnection-making, we did not see use of thematic similarity during deployment. Perhaps\nregular users may need nudges to identify high-level thematic similarity. Overall, there are\nample opportunities for improving the tasks in NewsComp.\n5.6.6 Limitations\nOur work is not without limitations. First, our study was conducted in a controlled envi-\nronment which may differ from that of a user\u2019s typical news reading sessions. Therefore,\nsome of the observed effects could have been products of the environment. However, we\nemulated a typical news consumption environment as best we could, from content selection\nto the design of the interface. Therefore, our results offer some validity that future works can\nbuild on. Second, since our study procedure involved signing up for the study and voluntary\ncompletion criteria, some self-selection bias exists, similar to other research in this domain.\nHowever, we did advertise on Facebook to find users organically instead of recruiting users\nfrom crowd survey platforms, which provided some benefits to the selection process. Third,\nwe conducted the study within a US-centric context, limiting its generalizability. Future\nresearch could resolve such issues by conducting similar research with a larger country pool.\nFinally, the task in the study was a bit lengthy ( 20 min) relative to tasks that crowd work-\ners typically perform. Though the articles in the study were not excessively long (11-16\nsentences), this could still have affected task quality. Future work can further examine how\nperformance varies by task complexity. Overall, our work has certain merits that require\nfurther exploration in the future.\n5.7 Conclusion\nIn this work, we examined how well users perform on a comparative news annotation task\nfeaturing a pair of news articles, and how the annotation task affects users\u2019 perceptions of\nthe articles. Comparing our users\u2019 annotations against those of experts, we found that users\ngenerally performed very poorly on the annotation task. However, certain information, such\nasthenumberofuserswhomadeagivenannotationandusers\u2019rationalesbehindannotations,\ncan be used to detect incorrect annotations. Furthermore, we found some marginal changes\nin users\u2019 credibility perceptions for certain news articles after completing the annotation\nprocess. Our work has implications for designing future comparative annotation systems.\nChapter 6\nOtherT ube: F acilitating Content\nDiscovery and Reflection By\nExchanging Y ouT ube\nRecommendations with Strangers\n6.1 Introduction\nSocial media and content sharing platforms primarily use algorithms to individualize their\nfeeds and content in order to increase user engagement [ 104,134]1. These algorithms typ-\nically work by predicting what users will be interested in based on their prior interaction\nhistories [ 99]. This mechanism often ends up limiting the set of content that users are likely\nto consume, filtering out the vast majority of content available that users could have en-\njoyed [104]. While the resulting recommended feed may increase user engagement, users\nmay be trapped in a filter bubble\u2014isolation from alternate viewpoints\u2014potentially limiting\ntheir choices [ 40,341]. However, it is challenging for users to gain awareness of their lim-\nited content consumption and to understand others with broad information intercepted by\nalgorithms. Users with low cognitive reflection are especially susceptible to being swayed\n1part of this chapter appears in [ 45]\n155\nto extreme beliefs [ 429]. Other research shows that while some people might be aware of\nthe existence of such filters, they take little action against them (e.g., clearing their brows-\ning history, using a browser\u2019s \u201cincognito\u201d function, and clicking/liking different posts) [ 65].\nThough algorithmic improvement for diverse recommendations has been an active area of\nresearch [ 200,491], it still falls short of its goal, resulting in the persistence of filters [ 61].\nTherefore, the limitations of modern recommender systems raise the need for design inter-\nventions that can facilitate diverse content discovery, reflection, and understanding.\nOne potential intervention approach in bursting algorithmic bubbles is to present diverse\nviewpoints [ 337,406] by exchanging recommendations with others and recognizing how one\u2019s\nsocial media feed is different from those of other users. For example, in the case of YouTube,\none way to implement this solution is to show users recommendations that others received;\nthat is, a collection of videos that YouTube\u2019s algorithms recommended to other users of\nthe platform. We anticipate that seeing recommendations from strangers may be beneficial\nfor users who are otherwise exposed to a limited set of content. First, knowing the kinds\nof videos that are recommended to other users can facilitate reflection on one\u2019s own tastes\nand consumption behaviors through social comparison. Prior research suggests that such\ncomparison between peers could lead to improved self-knowledge or reflection [ 135,502].\nSecond, seeing diverse recommendations from strangers could also facilitate discovery of\nnew content, such as content that simply seems interesting, content that specific groups\nof users watch, and content that a user did not know was available. Lastly, exchanging\nrecommendations may be more effective if users present themselves (or a proxy of their\ntastes) to strangers, to some extent [ 26,408].\nThe goal of this paper is to explore the idea of exchanging algorithmically mediated recom-\nmendations as a way to facilitate content discovery and reflection, and to assess the potential\nbarriers to such approach in self-presentation and content consumption. We accomplish this\nbydesigning, developing, andevaluatingOtherTube\u2014abrowserplug-inforYouTube\u2014which\nrecords the videos recommended to a user from the YouTube homepage and displays them to\nothers. OtherTube allows users to see strangers\u2019 YouTube recommendations (see Figure 6.4)\nas part of the homepage. To facilitate better social comparison, OtherTube also lets users\ncreate an anonymous persona (see Figure 6.2) and display it along with the recommended\nvideos. Furthermore, OtherTube lets a user remove recommendations that they do not want\nto share. More specifically, we aim to answer the following research questions:\nRQ1. How do users discover content by browsing recommendations personalized for\nstrangers?\nRQ2.What factors affect users\u2019 interactions and engagement with recommendations per-\nsonalized for strangers?\nRQ3.How do users present themselves when sharing recommendations with strangers?\nRQ4.How does browsing recommendations personalized for strangers facilitate reflection?\nTo answer, we are conducting a 10-day long user study with the plug-in. To recruit a\ndiverse set of users for the study, as opposed to recruiting a more homogeneous group from\na university, we are using a Facebook advertisement. In addition, we log all the interactions\nthat happened within OtherTube during that period, such as the number of videos clicked\nand the number of clicks to see different personas.\nOur preliminary analyses show that OtherTube can help some users, but not all, in develop-\ning new interests and rediscovering prior ones by seeing strangers\u2019 personalized recommenda-\ntions. Upon viewing others\u2019 recommended videos, users were able to understand more about\ntheir interests and how unique those interests were. Encountering other users with similar\ninterests also gave users a sense of belonging. Next, I outline the design of OtherTube, our\nstudy protocol and preliminary results.\n6.2 Related W ork\nIn this section, we briefly review existing research around content discovery and reflection\npertaining to recommender systems. With our system supporting self-presentation and com-\nparison with strangers, we also review related literature.\n6.2.1 Supporting Diverse Content Discovery Online Through Rec-\nommendations\nSocial recommender systems have become ubiquitous over the last decade, in areas such\nas social media (e.g., Facebook), e-commerce (e.g., Amazon), video sharing platforms (e.g.,\nYouTube), and recreational services (e.g., Netflix). As recommender systems have become\nhighlyaccurateinestimatingusers\u2019preferences[ 180], italsocomeswithcaveats, suchasfilter\nbubbles [ 341]. These problems prompted inquiry into diversifying users\u2019 exposure to differ-\ning viewpoints [ 380]. In this respect, one line of research takes diversification as a quality\nmetric for recommender systems\u2019 performance and introduces novel approaches to improve\nit [74,200,257,294,491]. However, these methods face challenge as they have to trade-off di-\nversity with accuracy [ 504]. In parallel, there has also been some research over design-centric\napproach to address the issue of filter bubble on social platforms [ 163,252,296,336,401].\nTheseapproachesincludedesigninterventionstounderstandusers\u2019owncontentconsumption\nhabit by showing information such as their topic-wise content consumption [ 401], political\nleaning of the sources they consume information from [ 406] and political leaning of their\nown social network [ 163]. Some of these approaches also promote viewpoints from alternate\nperspectives, such as, related content from alternate sources [ 336] and viewpoints from a\nuser with different political ideology [ 252]. Our work adapts the approach of showing alter-\nnate viewpoints for YouTube by extending a particular demography-based feed exchanging\napproach to a stranger-centered feed exchanging one.\n6.2.2 Social Comparison and Self-Presentation\nThe theory behind behavior change leveraging social comparison is not new [ 135]. In some\ncases, such comparison could act as a support. In others, social comparison can trigger peer\npressure which promotes competition [ 90,360]. Prior studies found this mixed effect within\nthe same system [ 92,270,497]. Research also shows that constructing better self presen-\ntation for social comparison on sites like Facebook may lead to improved self concept and\nself-esteem [ 157,502]. Motivated by these existing results, we designed OtherTube to allow\nusers to create own persona which can be shared and compared against strangers. While\ncomparison might be easier when information from others are available, it also conflicts with\nusers\u2019 need to preserve privacy for certain information [ 315]. To address this concern, Gar-\nbett and colleagues used pseudonyms and avatars, protecting users\u2019 identities [ 150]. Since\nsome research suggest the presence of toxic interactions on YouTube [ 83,334], we use a sim-\nilar approach to anonymize users\u2019 self-presentation (using pseudonyms, avatars and generic\ndemographic information) in our design of OtherTube.\n6.3 OtherT ube: Design and Implementation\nTo provide an environment that can be integrated into users\u2019 YouTube usage, we built Oth-\nerTube. OtherTube is a Chrome extension usable across all operating systems; users need\nonly use the Chrome browser to browse YouTube. Our system works by collecting a user\u2019s\nYouTube recommendations\u2014specifically, the top two or three rows of videos\u2014each time a\nuser visits the YouTube homepage. It stores the recommended videos in a database to be\nFigure6.1: HowOtherTubeworks. Eachday, OtherTubecollectsYouTuberecommendations\nwhen users access the YouTube homepage. Users have until the end of the day to remove\nitems they do not want to share. Users can browse recommendations collected from others\nas late as the previous day.\nshared with strangers from the next dayonward. In short, users are givenaccess to strangers\u2019\nrecommended videos in exchange for providing their own recommended videos to strangers.\nFigure6.1demonstrates this process. Additionally, OtherTube provides three main affor-\ndances: (a) an option to allow users to create an anonymous profile (Figure 6.2), (b) an\noption to remove collected recommendations that they may not want to share (Figure 6.3),\nand (c) an option to choose between browsing strangers\u2019 profiles2and recommendations from\nusers\u2019 own YouTube homepages (Figure 6.4). We describe each of these affordances below.\n6.3.1 Creating an Anonymous Profile\nTo give users extra information about the strangers whose YouTube recommendations they\nare browsing, OtherTube asks users to create an anonymous profile. For each user, we\ngenerate a random screen name\u2014a combination of an adjective, a noun, and a number (e.g.,\n2Throughout the text, we use the term persona and profile interchangeably.\n1\n2\n3Figure 6.2: OtherTube Options page.\n1\nAvatar builder\n2 Shared demographic info\n3\nHow the profile will appear to others.\n1Figure 6.3: OtherTube Browser action page.\n1\nCollected videos with options to remove\nfrom the shared set.\namazedOtter4)\u2014automatically in the back end. Users can choose an avatar for their profile\nand set several demographic attributes. Figure 6.2shows the available options. The avatar\nbuilder allows users to choose a skin tone, hair color, clothing color, and appearance3. For\ndemographic attributes, users have the option to share or not share their age, gender /\ngender identity, ethnicity, race, and location. To provide anonymity, users can only set their\nage as a decade-based bucket (e.g., Teen and Twenties) and location by state or province.\nPer each attribute, users also have the option to enter their own values for some of these\nattributes. Apart from the demographic details, users have the option to fill out an open-\nended \u201cAbout Me\u201d section in their profile. For example, Figure 6.4shows a profile with\nthe text \u201cLove traveling, food, and my family\u201d in this section. Furthermore, at the top of\nthe page and the About Me input field, we put disclaimers asking users not to share any\npersonally identifiable details. Users also have the option to update their profiles at any\ntime. Finally, note that OtherTube does not start collecting recommendations from a user\nor show others recommendations until users have created a profile. This ensures that users\n3We used a third-party library, AvataaarsJs , for the avatar builder\nonly see collected videos attached to a profile.\n6.3.2 Sharing and Removing Y ouT ube Recommendations\nEach time users visit the YouTube homepage, OtherTube collects their YouTube recommen-\ndations and sends them to a back-end server, which then stores them in a database. Going\nforward, we will call each visit a session. It is worth nothing that the recommended videos\nare generated by YouTube\u2019s algorithm; they do not simply consist of a user\u2019s browsing his-\ntory. This means that the collected videos do not constitute an interaction trace, so the\nplug-in does not have to monitor a user\u2019s entire watch history, which could be perceived\nas private data. While recommended videos are typically not the one that a user watched,\nrecommended videos are heavily customized for individuals based on their watch history,\ncontaining items from topics and content creators they watched previously [ 99]. It remains\nunclear if users would perceive algorithmically recommended content as a part of their self-\npresentation. Such content is neither technically private data nor under users\u2019 complete\ncontrol. We discuss related results in section 6.5.3.\nOnce a session of recommended videos is stored on the server, the recommendations are\nshared with other users over the following days. If users do not want to share certain\nYouTube recommendations with strangers, they have the option to remove collected videos.\nWe facilitate this through a feature of the Chrome extension. When users click on the\nextension button next to Chrome\u2019s address bar, the extension shows a list of sessions sorted\nby time, with the most recently collected items at the top. While browsing the collected\nsessions, users can click a remove button in the upper-right corner of each video (the blue\ntrash can icon in Figure 6.3) to remove content that they would rather not share with\nstrangers.\nRecXchange: 1\n2 3\n4\n5\n6Figure 6.4: OtherTube embedded inside the YouTube homepage.\n1 Show or hide the em-\nbedded content.\n2 Browse different strangers or different recommendation sessions from\nthe current stranger, and pin the current stranger.\n3 The stranger\u2019s profile.\n4 YouTube\nrecommendations collected from this stranger.\n5 Link to a daily survey.\n6 The user\u2019s own\nYouTube recommendations, which OtherTube collects.\n6.3.3 Interacting with Strangers\u2019 Recommendations\nOtherTube embeds recommendations from strangers, which are collected through the steps\ndescribed in Sections 6.3.1and6.3.2, at the top of the YouTube homepage (see Figure 6.4).\nUsershaveanoptiontohideorshowtherecommendationsusingatogglebuttonintheupper-\nright corner of the embedded content (Figure 6.4-\n1). In the upper-left corner, OtherTube\ndisplays three buttons that allow users to browse another stranger\u2019s recommendations (An-\nother Persona, browse another recommendation session within the same stranger\u2019s persona\n(More From This User), and pin this stranger\u2019s persona (Pin User) (Figure 6.4-\n2). Each time\nusers click Another Persona or More From This User, the server returns a random stranger\u2019s\nrecommendations or a random session from the current stranger, respectively. When a user\nclicks Pin User, a shortcut to the displayed user\u2019s profile and recommended video collections\nis created below the button. We added this button in case a user wants to follow another\nstranger\u2019s recommended videos. To the right of the three buttons, a stranger\u2019s profile is\nshown, consisting of their avatar, their demographic info, and their About Me text. Be-\nlow the profile, OtherTube shows the current stranger\u2019s YouTube recommendations. While\nYouTube has recently started showing animated previews of each video, to make our imple-\nmentation easier, OtherTube only shows still images (known as thumbnails ) of videos, as it\nwas in the past. Below the recommended videos, there is a link to a daily survey which we\nasked participants to fill out each day during our study (see Figure 6.4). Finally, OtherTube\nonly tracks users\u2019 interactions within the plug-in (e.g., clicks on the Another Persona, More\nFrom This User, and Pin User buttons; and clicks on videos).\nWe built the front end of OtherTube using the React and Polymer JavaScript libraries, with\nBootstrap CSS for styling. The back end consists of a Flask-Nginx server with a MySQL\ndatabase for storage. All communication between the front end and back end is encrypted\nusing SSL. After building the tool, we tested it within our research groups and ran a pilot\nstudy, fixing technical issues and improving usability. We distributed the extension through\nthe Chrome Web Store.\n6.4 Study Deployment\nUsing OtherTube, we conducted a 10-day-long study4. Below, we outline our recruitment\nmethod, study procedure, data collection process, and analysis.\n6.4.1 Recruitment\nFor our study, we aimed to recruit participants who use YouTube on a regular basis. In\naddition, we decided to recruit participants using social media, specifically using Facebook\nAds, informed by others\u2019 successes in recruiting diverse populations [ 7,377,483]. This\nadvertising technique allowed us to reach a more diverse and targeted demography compared\nto Amazon Mechanical Turk or dedicated survey sites like Qualtrics [ 50]. Initially, we ran\nan advertisement campaign targeting individuals living in the US who are 18 years of age\nor older, speak English, and are interested in YouTube videos. While limiting our target\ndemographic to those who live in the US would limit our findings, we did not want to have\nto account for language barriers in exchanging video recommendations. Our goal was to still\nreach diverse populations in terms of age, gender, and ethnicity. In addition, studying users\nliving in a single nation provides some useful common ground upon which they can relate\ntheir interests to those of others (e.g., popular artists and domestic news in the nation). The\nrecruitment campaign was set to run for one week, from July 8, 2021 to July 15, 2021. We\nspent $315 on the campaign and received 568 responses.\n4This study was approved by the university\u2019s Institutional Review Board.\n6.4.2 Procedure\nUsers who clicked the Facebook advertisement were redirected to a pre-survey to sign up for\nthe study. At the beginning of the pre-survey, we screened users according to several criteria.\nTo be eligible for the study, users had to: (i) be 18 or over, (ii) be currently residing in the\nUnited States, (iii) visit YouTube at least once a day, (iv) typically browse YouTube on a\nlaptop or desktop computer (as opposed to mobile-only users), (v) typically use Chrome to\nbrowse YouTube, (vi) have English as the primary language of the YouTube content they\nwatch, and (vii) typically start browsing YouTube from YouTube homepage (youtube.com).\nOut of the users who submitted the presurvey ( n= 568), 318 were eligible for the study. We\ninvited these participants via email to start the study5. The invitations were sent out in two\nbatches: (i) July 19\u2013August 3, 2021, and (ii) August 5\u2013August 18, 2021. Note that while\nthe emails to all participants in a given batch were sent out on the same day, users could\nhave started using the extension on different days, resulting in batch periods exceeding 10\ndays. Out of 318 invitees, 41 participated in the study by installing the plug-in and filling\nout the daily survey at least once. We created an instructional document describing how to\nparticipate in the study. Users who accepted the invitation had to install the OtherTube\nextension from the Chrome Web Store. After installing the extension, users had to create\nprofiles. At the beginning of the study, to mitigate the cold start problem, we created a\nresearchaccountsothatparticipantscouldbegintoseeembeddedrecommendationsfromthe\nfirst day. For 10 consecutive days, users were asked to use YouTube as they normally would\nand interact with OtherTube. Each day, they were also asked to submit a daily survey which\ntook about five minutes. We sent reminder emails around 6 P.M. EDT each day to remind\nusers who had not yet submitted the daily survey. Despite the reminders, participants did\nnot consistently submit the survey, leaving us with 356 (8.7 on average) responses instead of\n5Initially, we prioritized minorities for invites to form a diverse pool. Due to the limited response, we\neventually reached out to all participants.\n410(41participantsx10days). Uponcompletionofthestudy, weinvitedabouthalf( n= 19)\nof the participants to an interview based on their survey completion rates. Of those invited,\n12 participated in the interviews. Each meeting was recorded for analysis. Because one user\nrevealed that they neither followed the study instructions nor had a clear understanding\nof how the plug-in works, which would have left the user with no context for many of our\nquestions, we ignored this user\u2019s response and analyzed the remaining 11 recordings. We\ncompensated study participants with $25 gift cards and interview participants with $15 gift\ncards, adhering to federal minimum wage requirements.\n6.4.3 Participants\nOur pre-study survey was mainly designed to filter out ineligible users and create a diverse\nparticipantpoolbymatchingdemographicquotas. However,wedidnotcompletelyfulfillthis\nobjective due to an inconsistent response to study invites. Figure 6.5shows the distribution\nof age, gender, political affiliation, and length of a typical YouTube browsing session among\nour 41 participants. The participants\u2019 demography is balanced by gender. However, it\nis heavily skewed by race, with only one Black or African American participant despite\na sufficient number of Black or African American users signing up for the study (see the\ncontrast in Appendix C.1). This disparity could be caused by hesitancy towards installing\ntools or hesitancy towards research studies due to past injustices [ 206,243]. Finally, by\npolitical affiliation, the majority were Democrats.\n6.4.4 Data Collection\nWe collected data from our participants in multiple ways, beginning with the pre-study\nquestionnaire. The questionnaire was followed by interaction traces and daily surveys during\nFemale Male01020No of UsersGender\nWhite Black \nor \nAfrican \nAmericanAsian Hispanic \nor \nLatino/a/x01020Race\nDem Ind Rep020Political Affiliation\n<\n 30min<\n an hour<\n 2hours>\n 2hours01020Typical YouTube Session LengthFigure 6.5: Demography of the participants in the study.\nthe study, and the post-study interviews came last.\nPre-Study Questionnaire: Need for Self-Reflection and Insight\nIn the pre-study questionnaire, along with demographic questions, we asked about users\u2019\nneed for self-reflection and insight (see Appendix C.2for the items), using scales from prior\nresearch[ 183]on5-pointLikertitemswithresponsesfrom\u201cstronglydisagree\u201d(1)to\u201cstrongly\nagree\u201d (5). We measured these metrics to see if the self-assessed need for self-reflection and\ninsight would correlate with how users interact with OtherTube. Participants\u2019 responses had\na high level of consistency for both questions, similar to prior studies (Cronbach \u03b1[Need for\nSelf-Reflection]: 0.97, Cronbach \u03b1[Insight]: 0.95) [ 171,183]. For each trait, we found the\nmean of the items after inverting items that were phrased in the opposing sense. Figure 6.6\nshows the distribution of user responses for need for self-reflection and insight. Here, we see\na skew towards a greater need for self-reflection.\nInteraction T races from OtherT ube\nAs mentioned before, we collected data on users\u2019 interactions with OtherTube, including\nclicks to see recommendations from different strangers, clicks to see more from a stranger,\nclicks to watch videos, clicks to pin strangers, and clicks to remove own recommendations.\n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.00510152025Number of Users(a) Need for self-reflection\n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.00246810Number of Users (b) Insight\nFigure 6.6: Distribution of participants\u2019 need for self-reflection and insight, bucketed for ease\nof understanding.\nQuestion\nT ypeItem\nLikert-scale(a) Today, I saw some videos on OtherTube that caught my attention.\n(b) Today, OtherTube recommended me videos that I would not have expected in my feed.\n(c) Today, I discovered some new types of content on OtherTube that I would like to watch.\n(d) Today, YouTube recommended me some videos that I would not have expected in my feed.\n(e) Because of using OtherTube, YouTube is recommending diverse videos to me.\n(f) I feel comfortable sharing my recommended videos with others on OtherTube.\nOpen-ended(a) If there were any videos that caught your attention from OtherTube, could you tell us what they were and why\nyou were interested in them?\n(b) If you removed any recommended videos of yours from the OtherTube plug-in, could you tell us why?\n(c) While using OtherTube, did you learn anything new about certain populations (different age group, different\ngender)? If so, what did you learn?\n(d) While using OtherTube, did you learn anything new about your own taste compared to others? If so, what did\nyou learn?\n(e) What made you hesitate to watch videos from OtherTube, if any?\nTable 6.1: Daily Survey Questions\nDaily Survey: Perceptions of Recommendations on OtherT ube\nIn the daily surveys, we asked users Likert scale\u2013based and open-ended questions about their\nexperiences with OtherTube on YouTube. Table 6.1shows the questions. We included sev-\neral Likert items on a 5-point scale from \u201cstrongly disagree\u201d (1) to \u201cstrongly agree\u201d (5) about\nusers\u2019 perceptions of OtherTube on YouTube. These questions captured users\u2019 perceptions\nof content discovery each day, whether their own YouTube recommendations were affected\nby their interactions with OtherTube, and how they felt about sharing their YouTube rec-\nommendations with strangers. Through open-ended questions, our goal was to understand\nparticipants\u2019 reflections on themselves and others, and to learn the motivation behind any\nactions they performed or chose not to perform (e.g., content removal or hesitation to watch\ncontent).\nInterview\nAfter completion of the 10-day study, we interviewed 11 participants. The interviews fo-\ncused on understanding users\u2019 behavior when using the tool, including how they presented\nthemselves to others, how they used the features of the plug-in, and whether using Other-\nTube encouraged content discovery or facilitated any reflection. We ended the conversations\nwith some usability questions. Additionally, after analyzing each interviewee\u2019s daily survey\nresponses, we asked them to elaborate on any points that seemed unclear. For example,\nbecause one user mentioned that their interests are \u201cconservative\u201d in their daily survey, we\nasked them to elaborate on what they meant by that (i.e., whether the user was interested\nin political conservatism or had conservative viewing habits, preferring to watch the same\nkinds of videos). This participant reported that \u201cconservative\u201d meant they watch only what\nthey like, and they carefully select what videos to watch. See Appendix C.3for the complete\ninterview questionnaire.\n6.4.5 Method of Analysis\nWe gathered both quantitative (pre-study survey, Likert scale\u2013based daily survey questions,\nand interaction traces) and qualitative responses (open-ended daily survey questions and\ninterview responses). Below, we describe our analytical methodology.\nLikert Items on the Daily Survey\nTo gain insight into self-assessment on the statements, we checked the average responses\nto each Likert item on the daily survey. We also performed Mann-Whitney U tests, a\nnon-parametric test, to see if using OtherTube produced any changes in their perceptions,\ncomparing the responses from participants\u2019 first and last days of using OtherTube. Because\nnot all users submitted the survey on each of the 10 days, the last day might not have been\nthe 10th day for each user.\nInteraction T races\nTo answer RQ2, we modeled the number of daily clicks on the Another Persona button using\nnegative binomial regression6. The independent and control variables for the regression con-\nsisted of users\u2019 demographics, the need for self-reflection, and insight. Because we recorded\nthe number of clicks on each of 10 days, resulting in repeated measures by each user, we\nused a mixed-effects regression model. Additionally, because clicks are a count variable, we\nused negative binomial regression7. Because some users did not click the buttons every day\nand random effects require multiple observations per user, we used users who clicked the\nbutton on at least 3 days. Therefore, instead of 410, we had 280 data points from 32 users\n(an average of 8.8 data points per person) for our model. We used mixed_model from the\nGLMMadaptive R package [ 384]. For the sake of interpretation, we present marginal coeffi-\ncients instead of fixed effect coefficients in this model8. Additionally, we also examined the\nSpearman rank correlation, a nonparametric test, to assess whether there is any correlation\nbetween users\u2019 interactions and engagement; that is, clicks on videos, Another Persona, and\nMore from This User. Apart from these tests, we also analyzed other simple statistics.\n6WedidthesamethingfortheMorefromThisUserbutton, buttheresultswerenotsignificant; therefore,\nwe omitted them from this paper.\n7Due to overdispersion, we chose a negative binomial model over Poisson regression.\n8Given the nonlinear link function ( Log) in our model, random effect intercepts can have a multiplicative\neffect, not additive, complicating interpretation. Therefore, following Hedeker et al. [ 196], we extracted the\nmarginal coefficients and their standard errors from the model using the GLMMadaptive R package.\nOpen-ended daily survey responses\nWe performed thematic analysis on the open-ended daily survey responses. With five open-\nended questions, we had 1,780 responses (356 daily survey submissions \u00d7 5 questions), 976\nof which were either empty or contained unhelpful responses, like \u201cno\u201d or an incomplete re-\nsponse (e.g., \u201cYoga videos\u201d for Open-ended-(a) in 6.1). This left us with 804 valid responses.\nThree researchers performed thematic analysis on this data. Initially, each of the coders\ncame up with their own set of codes. After discussion, we converged on a set of 52 codes.\nThrough discussion, we reduced this subset of 52 codes to a list of 21 themes. Two of the\nresearchers coded a sample (159 items, or 20%) into the set of 52 codes. Coders had almost\nperfect agreement despite the large number of codes (Cohen\u2019s \u03ba= 0.82) [472]. One of the\ncoders coded the rest of the items. Due to the uneven number of codes associated with each\nuser, as some did not regularly fill out the daily survey, we merged the 10-day codes for each\nperson into a single set. Consequently, as we present our results, \u201ctheme (10/41)\u201d means\nthat out of 41 users, 10 users\u2019 responses contained at least one response belonging to the\ntheme. Each user may have given such a response anywhere from 1 to 10 times over 10 days.\nInterview\nSimilarly to the open-ended survey responses, we performed thematic analysis on the in-\nterview responses. One of the researchers performed an initial analysis and came up with\n35 codes from the interviews. Then, this researcher discussed the codes and corresponding\nquotes with other researchers. After resolving disagreements, we were left with 24 codes\nfrom the interviews. As most of them were related to the daily survey themes, we merged\nthe two sets.\n12345agreement\n(a) Today, I saw some videos\non   RecXchange That\ncaught my attention\n*\n(b) Today, RecXchange recommended\nme videos that I would\nnot have expected in my feed.\n(c) Today, I discovered some\nnew types of content on RecXchange\nthat I would like to watch\nfirst day last day12345agreement\n(d) Today, YouTube recommended\nme some videos that I would\nnot have expected in my feed\nfirst day last day\n(e) Because of using RecXchange\nYouTube is recommending\ndiverse videos to me\nfirst day last day\n.\n(f) I feel comfortable sharing\nmy recommended videos\nwith others on RecXchangeFigure6.7: Meanwith95%CIofparticipants\u2019responsestothedailysurveyLikertitemsfrom\nthe first and last days of the study. We also performed a Mann-Whitney U test comparing\nresponses on the first and last days. In (b), * indicates p <0.05; in (f), .indicates p <0.10.\n6.5 Results\nBased on our research questions, we present results consistent across daily survey themes,\ninteraction trace analysis, and interview themes. Note that the daily survey and interview\nquotes are presented in the format \u201cU1 (survey)\u201d and \u201cU1 (interview)\u201d.\n6.5.1 (Content Discovery) RQ1. How do users discover content\nby browsing recommendations personalized for strangers?\nIn the daily survey, the majority of participants agreed with the statement (mode: 4, \u201csome-\nwhat agree\u201d) saying that they saw some videos on OtherTube that caught their attention.\nFurther analysis shows that this perception did not change between the first and last days.\nThis result is shown in Figure 6.7-(a), where a Mann-Whitney U test shows no significant\ndifference. Our analysis revealed two themes that illustrate how users utilized OtherTube to\ndiscover content: (i) users developed new interests, and (ii) users rediscovered content they\nused to like. We present these themes below.\nUsers developed new interests\nIn the daily survey, a majority of our participants ( n= 36/41 ) mentioned finding new\ninterests. Users found interests in multiple ways. Sometimes, they found new interests out\nof curiosity ( \u201cI had no clue what it [a video that caught their attention] was about but just\ncurious on the content\u201d -U1 (survey) ). Other times, new content led to the development of\na new interest due to its usefulness ( \u201c ... A video about investing for your kids\u2019 future. I have\na newborn and want to do that for her\u201d -U2 (survey) ). There were also cases where users\nfound new content that fit within their existing interests ( \u201cRelaxing Video Game Music\nin a Cozy Room (Nintendo 64) [caught my attention]). I enjoy similar relaxing music\nplaylists\u201d -U12 (survey) . Some users also watched content for the sake of exploration\n(\u201cI don \u2019t normal ly listen to that [classical music] and it was a welcome change\u201d -U17\n(survey)). Interviewees also responded similarly, with one mentioning how they bumped\ninto new interests on OtherTube. Merely encountering the embedded interface of OtherTube\ncould trigger changes in consumption behaviour.\n\u201cWhat I like about it is that some it forced me out of my comfort zone of what I would\njust do ... It makes you to stop and, like, look and think before you decide to make a\ndifferent choice. \u201d\u2014 U17 (interview)\nWe also noticed that participants were able to recognize profiles that had similar tastes to\ntheir own. ( \u201cI came across a user who had watched videos that were my interest. He was\ninterested in computers and video games. So, I liked those videos too\u201d -U20 (survey) ).\nThis tendency demonstrates not only that one can find interesting videos using OtherTube,\nbut also people that they can connect with, due to the similarity of the content that they\nwatch. OtherTube\u2019s additional functions to retrieve more videos from a particular user can\nbe useful to further explore the person\u2019s content. Analyzing the number of clicks on More\nfrom This User and the number of clicks on videos users watched, we found a statistically\nsignificant positive correlation (Spearman\u2019s \u03c1= 0.42,p < 0.001). This pattern suggests\nthat finding a profile based on similarities in taste could be a new way to find and watch\nnew content\u2014in essence, subscribing to other viewers, not creators, to follow their content\nconsumption patterns. We discuss these implications further in Section 6.6.1.\nUsers rediscovered content they used to like\nUsing OtherTube, some users ( n= 11/41) found content they used to like ( \u201cold throwback\nvideos from my childhood [caught my attention]\u201d -U11 (survey) ). They also found channels\nthey used to like ( \u201ca video game reviewer, Zero Punctuation, popped up in one of the\nOtherT ube recommendations. So seeing that was pretty nostalgic. \u201d -U3 (survey) ).\nApart from these themes, our participant interviews further revealed users\u2019 issues with find-\ning strangers with similar interests. For example, while users\u2019 About Me details were some-\ntimes useful, they wanted more features, such as filtering users by demographic or interest\n(\u201cTheir favorite content creator, maybe your favorite video. \u201d -U26 (interview) ).\nSummary: By browsing OtherTube, participants both found new interests and rediscov-\nered old ones. They found new interests out of curiosity, usefulness, or desire to explore.\nItems caught participants\u2019 attention similarly on both the first and final days of the study.\nFinally, participants also recognized others who had tastes similar to their own.\nClick Count per Day (Another Persona)\n\u03b2 std. Err.\n(Intercept) 5.5024*** 1.0936\nAge -0.0284* 0.0135\nGender[Male] 0.2592 0.2303\nRace[Black or African American] -1.2113 0.7136\nRace[Hispanic or Latino/a/x] -0.1595 0.3895\nRace[White] 0.2526 0.2412\nDaily Browsing Length[less than 1 hr] -0.6087 0.3839\nDaily Browsing Length[less than 2 hrs] -0.1536 0.3628\nDaily Browsing Length[greater than 2 hrs] 0.1773 0.4109\nNeed for Self-Reflection -0.4149*** 0.2108\nInsight -0.0829 0.1730\nDay -0.0453* 0.0185\n# of Users Available on the Day -0.0083 0.009\nDispersion 0.9119 0.1244\nlog.Lik -721.8501\nN = 280 * p<.05, ** p<.01, *** p<.001\nTable 6.2: Mixed effects negative binomial model for daily click count on Another Persona\nin Figure 6.4. In this model, user is a random-effects variable. User demography, their\nbrowsing habits, their need for self-reflection, the day when the clicks were counted, and the\nnumber of unique stranger data sets available to browse on OtherTube on the day when the\nclicks were counted are fixed-effects variables. The estimated negative binomial regression\ncoefficient \u03b2is the difference in the logs of expected counts of the response variable due to\na one-unit change in the predictor variable.\n6.5.2 (Interaction and Engagement) RQ2. What factors affect\nusers\u2019 interaction and engagement with recommendations\npersonalized for strangers?\nTo investigate what factors affected users\u2019 interactions with OtherTube, we modeled users\u2019\nclick activity on Another Persona over time using a mixed-effects negative binomial model.\nWe considered several factors in this model, including users\u2019 demography, their need for\nself-reflection, their YouTube browsing length, and number of available unique profiles to\nbrowse on a given day. Table 6.2shows the result. We find that users with higher age\ntend to interact less with OtherTube when browsing different persona on OtherTube ( \u03b2=\n\u22120.03, p < 0.05). Our users with a greater need for self-reflection also interacted less with\nOtherTube ( \u03b2=\u22120.41, p < 0.001). This result was particularly interesting because we\nhypothesized that those who believe that they need reflection would use OtherTube more\nthan those who did not have such thoughts, given our goal of facilitating reflection behind\nthe tool. Perhaps our design will be more effective and promising for those without an\nexplicit desire for self-reflection. Additionally, as the days passed, users interacted less with\nthe tool ( \u03b2=\u22120.05, p < 0.05). This decrease could have been caused by seeing the same\nprofiles repeatedly, due to the limited number of users in the study ( \u201c[On day 4]i haven \u2019t\nseen many changes. [On day 6] no same as yesterday. \u201d -U4 (survey) ). To understand users\u2019\nengagement with the videos, we analyzed users\u2019 clicks on videos. We found that most users\n(n= 37/41) watched at least one video on OtherTube. Overall, participants collectively\nclicked on 6% or 398 videos out of all the collected videos on OtherTube.\nWhiledemographicattributesandotherenvironmentalfactorscanaffectinteraction,itmight\nhave been the content itself that encouraged or discouraged interaction with content from\nOtherTube. Analysis of users\u2019 daily survey responses revealed content-related factors that\ndiscouraged users from watching videos; these are discussed below.\nUsers hesitated to watch content that was not of interest to them\nA majority of our users ( n= 25/41) mentioned that they did not watch content because\nthe content did not relate to their interests ( \u201cI didn \u2019t find them [videos I hesitated to watch]\ninteresting\u201d -U40 (survey) ). Some users referred to such content as \u201cboring\u201d ( \u201cseemed\nboring or predictable\u201d -U35 (survey) ) or \u201ccomplicated\u201d ( \u201clooked boring, or too techy and\ncomplicated\u201d -U36 (survey) ). In the interview, one of the participants further elaborated on\nhow their motivation for browsing YouTube at times affects whether they would engage with\ncertain type of content ( \u201cSometimes I don \u2019t want to be educated. I just want to enjoy. Other\npeople want maybe to learn about the history of Macedonia or something. I don \u2019t sometimes\nwant to learn that. \u201d -U15 (interview) ).\nUsers hesitated to watch content that was not helpful\nIn contrast, content utility was the main factor for some users\u2019 ( n= 6/41) engagement with\ncontent in OtherTube ( \u201cI just didn \u2019t click the ones that seemed pointless and not helpful to\nmy personal development or learning\u201d -U2 (survey) ). Some expressed hesitation in terms of\nwasted time ( \u201cThey could be a waste of time to watch if I don \u2019t like them\u201d -U26 (survey) ).\nUsers hesitated to watch disturbing and offensive content\nSomeusers( n= 7/41)werealsohesitanttowatchcontentthatseemeddisturbingoroffensive\nto them. Various types of content could fall into this category, including horror videos ( \u201cI\ndidn \u2019t want to watch horror\u201d -U13 (survey) ), sexually charged videos ( \u201cI didn \u2019t want to\nwatch videos that seemed strangely sexual ly charged, like mouth ASMRs\u201d -U38 (survey) )\nand uncomfortable topics ( \u201cI was disturbed by videos in uncomfortable topics I wouldn \u2019t\nwant to think about, such as, physiological anomalies and unsolved murder mysteries\u201d -U39\n(survey)).\nUsers hesitated to watch clickbait-esque content\nClickbait was one reason some users supplied for not watching content ( n= 4/41). Users\nused both video titles ( \u201cTitles were terrible and looked like trash\u201d -U16 (survey) ) and\nthumbnails ( \u201cI was hesitant to watch videos with objectifying thumbnail pictures of women\u201d\n-U38 (survey) ) to rule out this kind of content.\nSome of the barriers discussed so far may reduce the overall effectiveness of our approach,\nas users may consider the content displayed by OtherTube to consist of low-quality items\n(e.g., spam, clickbait-esque videos) or even explicit (e.g., profanity) . Future designs could\nintroduce some mechanisms (e.g., automated spam filtering) to mitigate such perceptions.\nUsers hesitated to watch videos for fear of an interaction effect on their Y ouT ube\nrecommendations\nA few of our participants ( n= 4/41) were hesitant to watch content because they assumed\ndoing so would affect their future YouTube recommendations ( \u201cI saw an interesting video on\nNetscape, but didn \u2019t click given it\u2019s from a new channel I\u2019m not familiar with, but also being\naware that the YT algorithm is going to try and keep me engaged by literal ly suggesting more\nof said video\u201d -U25 (survey) ). Some of our interviewees further revealed that they deal with\ncontent that they do not want to watch by blocking it. Similar blocking mechanisms can be\nadded to OtherTube to filter out content that users do not want to see. We leave this for\nfuture exploration.\n\u201cI curated it [Y ouT ube] fairly careful ly. Occasional ly I would get some random stuff [on\nY ouT ube recommendations]. Usual ly I just click on the little dots [a button on Y ouT ube\nvideos with a drop-down menu to block content users do not want to be recommended]\nand I\u2019d say \u201cdon \u2019t recommend this channel\u201d . \u201d\u2014 U39 (interview)\nThis issue raises an interesting question of how users\u2019 engagement from watching content on\nOtherTube could affect their future recommendations from YouTube. In light of this, should\ndesigners make OtherTube available within a sandbox or incognito viewing mode? Sandbox-\ning may encourage some users concerned about impacting the recommendation algorithm to\ninteract and explore more content.\nSummary: Our analyses show that factors such as lower age and lower need for self-\nreflection positively affected users\u2019 daily interaction with OtherTube. However, participants\u2019\ninteraction also subsided as days passed. We additionally found that 90% of our participants\nwatchedatleastonevideoonOtherTube. Somecontentfactorsalsodiscouragedengagement,\nincluding lack of relevance to users\u2019 interests, lack of utility, and offensive or clickbait-esque\nnature.\n6.5.3 (Self-Presentation) RQ3. How do users present themselves\nwhen sharing recommendations with strangers?\nOtherTube offers two ways for users to present themselves to strangers: (i) a self-built profile\nand (ii) moderating the YouTube recommendations to be shared with others. Among our\nparticipants, few ( n= 5/41) decided against sharing any of their demographic information,\nwhilesix participantsshared all of the demographic attributes except their location. The rest\nfilled out all the demographic information in their profiles. Most ( n= 30/41) filled out the\nAbout Me section with details ranging from their occupations (e.g., \u201cmanager\u201d and \u201crecent\ncollege graduate\u201d) to generic interests (e.g., photography, traveling, yoga, and music) and\nmore specific ones (e.g., DIY, Hololive videos, and BTS). Our interview revealed that users\nwanted to change their About Me to explain the reasons behind specific interests ( \u201c[If I were\nto redo the study,] I would be more specific. My interests may be updated as they changed.\nSo I like to explain to you why I have seen, like, niche content in my recommendations. \u201d -\nU38 (interview) ).\nTo understand users\u2019 moderation practices for self-presentation with respect to YouTube\nrecommendations, we examined users\u2019 activity in removing collected videos. We found that\neight users removed 104 videos (<1.5% of the total videos shared). Two out of those eight\nusers were responsible for about 80% (84) of the removed items. Therefore, it seems that\nmost participants were not especially concerned about removing content they did not want\nto share. Both the daily survey and interview responses support the notion that the majority\ndid not show any concern ( \u201cI wasn \u2019t going to arrange in any way what videos I was watching\n[or remove videos] because I\u2019m not ashamed of the videos I watch. \u201d -U39 (interview) ).\nEven those who were concerned at first became comfortable sharing over time. In our daily\nsurvey, we found that mean of the users\u2019 initial responses were close to \u201cneither agree nor\ndisagree\u201d regarding the statement \u201cI feel comfortable sharing my recommended videos with\nothers on OtherTube.\u201d However, Figure 6.7(f) shows an increase in perceptions of comfort\nwith sharing over time. We examined the difference in frequencies using a Mann-Whitney U\ntest, and the result was marginally significant ( p= 0.07). Analysis of the open-ended daily\nsurveyresponses revealedtwofurtherreasons whysome usershad concernsregarding sharing\nvideos. This result helps us understand how participants self-present through recommended\nvideos.\nAbout a quarter of the participants ( n= 12/41) did not want to share certain content. Some\n(n= 7) were concerned that certain videos did not represent their interests ( \u201cI removed some\nfor being literal ly not content that I watch, that your tool seemed to pul l from Y ouT ube\u2019s\nsuggestions\u201d -U25 (survey) ). Others moderated recommended videos for the sake of other\nviewers. While participants realized that they were sharing content anonymously ( \u201c[Did\nnot want to share because I am] Self Conscious even though its anonymous haha\u201d -U5\n(survey)), some ( n= 6) still felt uncomfortable sharing certain content ( \u201cSome [videos] felt\nexcessive, or sorta just weird. And I\u2019m not sure about sharing that. \u201d -U25 (survey) ). During\nthe interviews, participants also revealed that they thought their content might not be of\ninterest to others ( \u201cThe educational stuff I\u2019m watching is very entertaining. But I\u2019m pretty\ncertain that other people would be extremely bored by that. \u201d -U39 (interview) ).\nSummary: To present themselves to strangers, participants moderated both their self-\nbuilt profiles and the videos they shared on OtherTube. While a majority filled out their\nanonymous profile, some did so only partially or not at all. Participants also revealed\nrationales for not sharing videos, such as content not matching their interests.\n6.5.4 (Self-Reflection) RQ4. How does browsing recommenda-\ntions personalized for strangers facilitate self-reflection?\nUsing OtherTube, our participants were able to reflect on themselves from various perspec-\ntives. We found the following themes here: (i) understanding of own interests and their\nuniqueness, (ii) feelings of belonging from seeing users with similar interests, and (iii) feel-\nings of superiority from comparing content. These patterns help us understand the kinds of\nself-reflection that the system can facilitate. We illustrate these themes below.\nUsers understood more about their own interests\nOne of the effects of using OtherTube seems to be users ( n= 14/41) understanding their own\ninterests, what they like ( \u201cI learn that I have interest in cooking after watching some cooking\nvideos\u201d-U41 (survey) ), and what they do not like ( \u201cI am not interested in animation or\nanything about computers or how computers work\u201d -U15 (survey) ). Some also realized their\npreferences in terms of video length ( \u201cI like short and fun videos, nothing too long or too\nserious. \u201d -U16 (survey) ) Others realized that their identity influences their interests ( \u201cI saw\nmy tastes to be very related to my identify [sic] and cultural background\u201d -U29 (survey) ).\nAfter seeing strangers\u2019 YouTube recommendations, a majority of our participants ( n=\n29/41) further realized that their interests were unique compared to those of others ( \u201cI\nlearned how unique and distinct my taste and preferences are\u201d -U9 (survey) ). Some thought\nthat their interests on YouTube were very narrow or selective compared to those of others.\nSome of them defined this narrowness in terms of topics of interest ( \u201cI mainly focus just on\ngaming while other people hit a lot more genres\u201d -U26 (survey) ).\nSeeing others with similar interests gave users feelings of belonging\nUsers were surprised to find strangers with similar interests ( \u201cI was surprised to see another\nperson also to be having similar tastes as me, it was like seeing my own watch history\u201d -\nU29 (survey) ). Seeing others with interests similar to their own, many of them ( n= 22/41)\nrealized that they are not so different from others ( \u201cI continue to learn that we aren \u2019t so\ndifferent. I have always thought that from a gender perspective, but age is real ly where I\nfeel my eyes are being opened. \u201d -U5 (survey) ). Some found commonality among similar\ndemographics ( \u201cPeople near my age enjoy similar content\u201d -U19 (survey) ). Others found\ncommonality with different demographics ( \u201cI like the same videos as a woman in her 50\u2019s\nwhich made me laugh because I\u2019m 28\u201d -U2 (survey) ). Some also expressed their alignment in\ninterests with particular demographics over others ( \u201cI learned that I am more likely to share\ninterests with older women than men of my age\u201d -U13 (survey) ). Some users expressed\nboth their uniqueness and their differences as part of being normal ( \u201cI think that I am fairly\nnormal or that weird is normal. Everyone has their own tastes. \u201d -U5 (survey) ). To see\nmore from strangers with similar interests, OtherTube provided users with a pin button that\nallowed them to save other profiles for later perusal. We found that some of the participants\n(n= 8/41) indeed pinned some strangers ( n= 18/41).\nOur interviews further revealed that upon seeing users with similar interests, a few were\ninterested in communicating with them, potentially to recommend them other interests ( \u201cI\nthink it\u2019d be interesting to maybe even have that kind of connection where you\u2019re sharing. I\ndon \u2019t want to say like you\u2019re friending someone on F acebook. But maybe sharing of content\n... kind of being able to make a recommendation saying if you like this, maybe you like that. \u201d\n-U17 (interview) ). However, at the same time, others were not interested in communicating\nfor fear of toxic interactions. The quote below illustrates this issue.\n\u201cBut I\u2019ve been on Y ouT ube for years ... my impression is that overal l, Y ouT ube is\nan extremely toxic place. And the only way I managed to avoid the toxicity is by\nblocking creators who I find to be like bad people and not reading the comments section.\nSome of the most innocuous videos wil l have thumbs down on them for like, I don \u2019t\nknow what reason. So I don \u2019t know if I want to connect with those people [who watch\nsuch videos]... And I thought that the way that you guys were doing it by making\nit impersonal was kind of good. Because then nobody could spew profanities at each\nother.\u201d\u2014 U39 (interview)\nSome users felt superior when comparing their content to others\u2019\nAlthough not many, a few of our participants ( n= 6/41) also reported feelings of superiority\nafter seeing others\u2019 recommendations ( \u201cApparently, my taste is better than most people\u2019s. \u201d\n-U16 (survey) ). Some of them attributed this sense of superiority to the lack of variety\nin others\u2019 recommendations ( \u201cI have more tastes than this lady. I seek out more content. \u201d\n-U19 (survey) ). Manifestations of superiority go against our goal of understanding others\nand could be detrimental ( \u201cyounger crowds listen to stupid stuff\u201d -U6 (survey) ).\nSummary: Using OtherTube, participants reflected on themselves and their interests.\nWhen participants found others with interests matching their own, they experienced a feel-\ning of belonging, and vice versa. Comparing interests with others, some also felt superior to\nothers.\n6.5.5 (Learning about others and the algorithm) RQ4. How does\nbrowsing recommendations personalized for strangers facil-\nitate understanding?\nAfter seeing strangers\u2019 recommendations, participants expressed what they learned and how\nOtherTube increased their understanding of others. Some were surprised by the content\nothers watch, while others were surprised by the fact that their preconceived notions about\ncertain demographics did not always match. Users also discovered diversity in strangers\u2019\nrecommendations. We illustrate these themes below.\nUsers were surprised by some of the content others watch\nWhen browsing their OtherTube feeds, some users ( n= 11/41) were surprised to see certain\ncontent. Sometimes, users were surprised by content when it came from a particular profile\nor demographic they did not expect it to come from ( \u201cI found it very cool that someone in\ntheir 40s was stil l watching Olivia Rodrigo. Makes me feel better about aging haha\u201d -U5\n(survey)). However, comparing users\u2019 responses over time, this surprise seems to have grad-\nually subsided. Indeed, Figure 6.7(b) shows a decrease in perceptions of seeing unexpected\ncontent on OtherTube, and this difference was statistically significant ( p <0.05). This re-\nsult may indicate that participants got used to the recommended videos from OtherTube.\nHowever, it is worth noting that it is unknown whether this trend would have arisen even\nwith users being exposed to completely new sets of profiles every day; the limited number\nof profiles available could have contributed to this trend. Still, the mean of their responses\nin Figure 6.7(b) did not fall below \u201csomewhat agree\u201d (4) on users\u2019 last day.\nUsers were surprised to see that certain stereotypes do not reflect reality\nA few of our participants ( n= 6/11) were surprised to see that some stereotypes did not\nmatch reality ( \u201c ... It [different interests among people] chal lenges some stereotypes as I\nsee things on their feed that I wouldn \u2019t have expected\u201d -U40 (survey) ). Some found users\nof certain ages watching videos they would not expect them to watch ( \u201cI continue to be\nsurprised by music recommendations in particular. A lot of older persons getting younger\nartists and some younger persons recommended classic rock/pop\u201d -U5 (survey) ). Some also\nwere surprised in terms of gender stereotypes ( \u201cI saw a male user watching some homey\nvlogs and that was a bit surprising\u201d -U8 (survey) ).\nUsers learned something particular about a person or a demographic, which\ncould be stereotypical\nUsing OtherTube, about half of our participants ( n= 17/41 ) mentioned learning about\nothers\u2019 lives by watching the recommendations that strangers received ( \u201cI learnt how you can\ntel l about what is happening in somebody\u2019s life by looking at the videos they are watching. \u201d\n-U29 (survey) ). Some participants discovered what a particular demographic might be\ninterested in ( \u201cMen may be more into horror\u201d -U13 (survey) and \u201c40s and older watch more\nhealth related videos\u201d -U41 (survey) ). While some people experienced a feeling of superiority\nwhen learning about others\u2019 interests, others had the opposite reaction ( \u201cI learned to respect\nother\u2019s choices\u201d -U29 (survey) ).\nMeanwhile, some users ( n= 5/41) also found that stereotypes about the kinds of content\nparticulardemographicsprefermatchedwhattheysaw( \u201c ... It reaffirms some stereotypes that\nI had, as some videos are expected\u201d -U40 (survey) ). Users most often mentioned stereotypes\nabout age, particularly for younger people ( \u201cT oday was much more in line with expectations.\nA teenager recommended some Pokemon videos, 20s getting anime. \u201d -U5 (survey) ). Some\nnoticedsimilarrecommendationsrelatedtoethnicity( \u201cI learned than ethnic Americans likely\nhave video interests in their ethnic culture\u201d -U38 (survey) ). Some also employed stereotypes\nto infer strangers\u2019 ages ( \u201cDespite keeping their age hidden, my first profile today was clearly\na kid/teen\u201d -U5 (survey) ). One obstacle in understanding more about others could have\nbeen that some users kept their demographic information hidden, as allowed by OtherTube\n(\u201cseveral people didn \u2019t put their demographics. So I don \u2019t know their age group, gender. \u201d -\nU41 (survey) ).\nUsers discovered diversity in strangers\u2019 interests\nSome of the participants ( n= 10/41 ) liked the diversity of the content they found on\nOtherTube( \u201cI like the diversity of participants and the content of the videos\u201d -U11 (survey) ).\nThey found diversity within particular strangers\u2019 feeds ( \u201c ... even within personas, it\u2019s getting\nharder to pin down a common thread. The recommendations can be pretty diverse. \u201d -U3\n(survey)). Users also found diversity across demographics ( \u201cEvery age group is different and\nthey al l post different material on here. \u201d -U4 (survey) ).\nApart from reflecting on self and learning about others, nearly half of our participants\n(n= 18/41 ) learned something about YouTube content broadly or what is trending on\nYouTube using OtherTube. Some learned about common interests of people on YouTube\n(\u201cThey [OtherT ube users] al l have fun videos\u201d -U11 (survey) ). Others learned of new\nphenomena on YouTube ( \u201cPeople are using Y ouT ube as a news source with more regularity\u201d\n-U18 (survey) ). Some discovered the popularity of certain content genres on YouTube ( \u201cK-\npop is massively popular. even more than I imagined\u201d -U17 (survey) ). Some also learned\nabout the popularity of content they already watch on YouTube ( \u201cRealized some content I\nwatch is actual ly popular. \u201d -U25 (survey) ). Some also realized how the YouTube algorithm\ncan affect their interests ( \u201cWhen I don \u2019t have my own tastes in videos, Y outube shapes my\ntastes\u201d-U13 (survey) ).\nSummary: After using OtherTube for 10 days, participants learned several things about\nothers. Some of these things surprised users, particularly when their preconceived ideas did\nnot match what they learned. Participants realized how diverse people\u2019s interests can be on\nYouTube.\n6.6 Discussion\nThis study presents the utility of exchanging YouTube recommendations with strangers.\nRQ1 reveals unique ways in which this can facilitate content discovery. RQ2 identifies de-\nmographics that might be interested in browsing recommendations catered to strangers and\nwatching videos from them. In RQ3, we found that while few participants put effort into\nself-presentation, they felt comfortable in setting up an anonymous profile and sharing rec-\nommended videos; a few of them, however, did moderate their recommended videos. Finally,\nwe saw how users reflected on themselves and others through RQ4.\n6.6.1 RQ1 & RQ2: Content Discovery , Interaction, and Engage-\nment\nWhile YouTube provides some features for finding new content (e.g., search or subscription,\nexploring trending videos), diversification of YouTube recommendations is still challenging.\nIt is especially hard to recommend diverse content to users based solely on their watch\nhistory. As one of our participants noted,\n\u201cI sometimes want to find new songs ... it [Y ouT ube] just kind of recycles a bunch of\nsongs that I\u2019ve heard ... In that instance, I actual ly have to basical ly open an incognito\ntab and pretend I\u2019m just a random nobody to get actual ly novel or interesting music\nrecommendations ... If I were to look for something new, I probably wouldn \u2019t be using\nmy existing Google account essential ly, rather try pretending to be a new person. \u201d\u2014\nU25 (interview)\nIn a way, our design emulates what this user has to do to get novel recommendations. Use\nof OtherTube shows some promising results, with participants in the study both developing\nnew interests and rediscovering prior interests after seeing content from strangers. As our\nextension embeds diverse recommendations in available content on YouTube, it could also\nact as a nudge for people to turn to find new interests. At the same time, our results also\nilluminate limits in types of diverse content that can be shown. For example, recommending\noffensive or excessively unfamiliar content could make people more hesitant to watch new\nkinds of content. Consequently, there is room for improvement in designing systems for\nexchanging recommendations with strangers, especially in assisting users to find people with\nsimilar interests or showing profiles not completely randomly, but based on a few similari-\nties, to prevent adverse reactions from users. We could devise intelligent algorithms based\non users\u2019 profiles to show content they may like. Additionally, we could computationally\nfilter out spam content, like clickbait videos. Others may need more case-by-case input\n(e.g., content on unfamiliar topics). Overall, our work lays a foundation in this domain for\nexchanging recommendations between strangers, and further exploration is still needed.\n6.6.2 RQ3: \u201cProfile W ork\u201d for Self-Presentation to Strangers\nSilfverberg et al. introduced the idea of \u201cprofile work,\u201d which is the amount of effort people\ndevote to presenting themselves to others [ 417]. Similarly to their findings, we saw that users\nput forth extra effort to moderate the content that would be shared, despite the fact that\nthe content was algorithmically recommended videos\u2014not exact watch histories\u2014and even\nthoughtheiridentitieswerenotrevealed. However, thisinclinationwaslimitedtoafewusers,\nsome of whose efforts even subsided over time based on the result shown in Figure 6.7(f).\nThe implication of this observation is that for some users, such systems can provide features\nto reduce the effort required to moderate one\u2019s self-presentation. For example, in OtherTube,\nit could have been tiring to remove items one by one per collected session. To improve this\nexperience, designers could provide easy filters for what users do and do not want to share.\nWith our design centered around strangers, participants also raised questions about the right\namount of information to reveal in self-presentation. If users do not present enough informa-\ntion due to privacy concerns, it might be hard for others to differentiate them from bots or\nspammers. As a result, others may perceive such profiles to be misleading, not credible, or\neven not authentic. For example, U21\u2019s reflection on the avatars in the anonymous profiles\nmade him wonder whether the putative strangers existed in real life.\n\u201cThere were no real pictures. There wasn \u2019t any photographs of them on the beach or\nlike a stock photo or something like that ... I\u2019m not sure that I\u2019m real ly engaging with\nsomeone who actual ly exists and not with algorithm. \u201d\u2014 U21 (interview)\nConsequently, users may not engage with such profiles. In our interviews, we found some\nsigns of disengagement due to disbelief about certain information presented in profiles (e.g.,\none user used the word \u201cnormy\u201d in his About Me text and claimed to be in his 80s, despite\nreportingasignificantlylowerageinthesign-upsurvey),thoughthiswasonlythecaseforone\nparticipant. Future work could delve into this tension between anonymity and authenticity.\nFinally, while we did not receive complaints about privacy in sharing videos, some of the\nquotes (e.g., users mentioning that they watch regional/local videos) prompt such a discus-\nsion. Here, shared videos could potentially be used to identify users if certain details more\nspecific than those allowed by our anonymous profile format appear regularly (e.g., multiple\nvideos about a certain location or neighborhood, watching a friend or relative\u2019s YouTube\nchannel). Existingresearchalreadyshowshowsparsedata\u2014uniqueinterests\u2014canbeusedto\nde-anonymize users [ 318]. Further consideration is needed to resolve such issues in practice.\n6.6.3 RQ4: Reflecting on Oneself and Others\nAs our results suggest, OtherTube helps users understand more about their interests and\ncompare those interests with others\u2019 on YouTube. This understanding could positively im-\npact users if they experience a feeling of belonging by seeing others with similar interests.\nThen again, the opposite can also happen; that is, if users are not able to find others with\nsimilar interests, they may instead feel disconnected, isolated, or atypical. A potential solu-\ntion to address the opposite effect is to design the system to suggest recommendations from\nusers with some common ground (e.g., someone from the same demographic group, someone\nwith similar taste) and monitor their interactions (e.g., video clicks). However, pairings of\nextremely similar users should be avoided, as this may lead users back into their filter bub-\nbles. Understanding the right amount of similarity and dissimilarity from which users can\neasily relate to others while still learning something is an interesting challenge. Being able\nto to search or filter users by demography and interests, as opposed to randomly suggest-\ning profiles, may be another option for improving users\u2019 experiences with the approach of\nexchanging recommendations employed in OtherTube.\nOur results also suggest potential in creating social connections between strangers with\ncommon interests. Future works would need to balance opposing desires (users who want\nto connect vs. those who do not) for connection in their designs. Perhaps designers can\nprovide limited options for connecting pairs of strangers. For example, the system could\nunlock messaging options between two users only if they have multiple shared interests and\nwant to connect [ 115]. Alternatively, communication can be centered around content, such\nas by allowing users to recommend videos directly and respond to recommendations in a\nminimal fashion (e.g., using an emoji). Overall, future works could explore these directions\nfor supporting reflection by exchanging recommendations with strangers.\n6.6.4 Design Implications\nOn platforms such as YouTube, where recommendation algorithms contribute to shaping\nusers\u2019 tastes and potentially trap users in filter bubbles for the sake of engagement, our\napproach of exchanging recommendations shows new ways to expand the scope of content\ndiscovery and improve reflection. For content discovery, existing systems already adopt\nmultiple approaches to provide users alternate recommendations to explore. For example,\napart from the site\u2019s personalized recommendations, T rending on Y ouT ube aims to promote\nexploration into \u201cvideos that a wide range of viewers would find interesting\u201d [ 168]. Mean-\nwhile, services like Spotify suggest content through features like Discover W eekly , based on\ninterests from others with preferences similar to users\u2019 own [ 158]. In contrast, our approach\ndoes not aggregate interests from any particular group; rather, it promotes exploration into\nother individual users\u2019 interests. Because we use other individuals\u2019 YouTube recommen-\ndations, our approach is fundamentally unlike YouTube\u2019s trending recommendations. As\ncompanies such as Alphabet, which owns YouTube, become keen to provide users with more\nopportunities to curate and expand their interests [ 227], our approach may provide such an\nopportunity. Aside from this, our approach also has the potential to fill a gap in the social\nfunctionality of systems like YouTube by creating connections between strangers based on\nsimilarity in interests. Recommender systems can eventually use such weak social ties to\nimprove recommendations.\n6.6.5 Ethical Considerations\nWe took several steps in our design and our study to minimize potential harm. First, we\ncollected only data that was needed for the tool and study. These included recommenda-\ntions from users\u2019 YouTube homepages and their activity within the extension: the embedded\ncontent on the YouTube homepage, the extension\u2019s browser action page, and the extension\u2019s\noptions page. Second, we set the extension\u2019s content rating to \u201cmature\u201d on the Chrome\nWeb Store to remind users that they could see explicit content in others\u2019 YouTube recom-\nmendations. Third, we explicitly asked users to not share identifiable information in their\nprofile fields to reduce the risk of an information leak (see Figure 6.2). In case users were\nuncomfortable sharing any demographic details with others, the extension defaulted to not\nsharing any information; users manually chose what information to share with others. Sim-\nilarly, we also let users remove recommended videos if they felt uncomfortable sharing them\nwith others.\n6.6.6 Limitations\nOur study is not without limitations. First, we had a limited number of participants from\nthe US with limited demographic distribution. Therefore, we cannot account for scenarios\nin which users live in different nations and speak different languages. Additionally, while\nmany users signed up for the study, only a select few ultimately participated. Therefore,\nsome self-selection bias exists. These users could simply be those who are most open to\nexchanging recommendations. Furthermore, we recruited users who use the Chrome browser\nonadesktoporlaptopcomputer(requiredfortheOtherTubeextensiontowork)andwhouse\nYouTube regularly. These criteria likely excluded users who do not use YouTube regularly\nor who use it on a different platform (e.g., mobile phones). Second, our implementation\nof OtherTube also introduced some limits to the study. For example, some participants\nhesitated to watch content because preview clips were unavailable. One interview participant\nmentioned that they had trouble going back to a profile they had forgotten to pin. This\nissue could have impacted their overall interaction and engagement with OtherTube. Third,\nthe first few participants from the first batch saw fewer profiles compared to other users; for\ncomparison, the last person in the study had a maximum of 40 profiles to browse. Therefore,\nusers\u2019 responses to the daily survey were affected by the limited sample. Future deployment\nwith larger samples could potentially resolve these issues.\n6.7 Conclusion\nIn this work, we investigated the exchange of social recommendations with strangers as a\ntool to promote content discovery and reflection on social media sites like YouTube. Our\ninvestigation revealed how users want to present themselves, as well as factors that affect\ntheir interaction and engagement with such a system. Our work has implications for future\nexploration into exchanging personalized recommendations with strangers.\nChapter 7\nDiscussion\nIn our online life, we use various affordances provided by each platform to accomplish dif-\nferent types of cognitive tasks. This work explores design of new affordances to parse the\ncomplex web of information in online problematic information space. I have designed four\nsystems that showcase the possibility of leveraging dual process information processing the-\nory to design dual process cognitive affordances. Below I start the discussion with the design\nimplications of these cognitive affordances. Next, I discuss potential direction for applying\nthese affordances, the impact it could bring about on the online information ecosystem. I\nend with a discussion on ethical implication of design affordances and affecting attitude.\n7.1 Design Implications\nIn this thesis, I have laid out the design and deployment of four novel systems. Through\nthis process, I have collected empirical feedback on considerations for improving such design.\nBelow I summarize the design implications implication.\n7.1.1 Affecting Stakeholder Power Dynamics\nIn TransparencyCue work, we found that different stakeholders had different view when it\ncomes to what affordances should be designed. Whereas news consumers looked for certain\n195\ntransparency from news organization, there were reluctance among journalists to present\na few revealing the underlying journalistic processes. This indicate that certain affordance\ndesign can affect the power relationship between different stakeholders, not just between\ninformation producers and consumers. Take the power dynamics between a social media\nplatform and its consumers. While platforms tend to dictate what content is shown to users,\ndesign affordances against problematic content can disrupt this power relationship. For\nexample, design of OtherTube and NudgeCred could empower content consumers to choose\nwhat they want to engage with. In such a case, these platforms may not be open to support\nthird-party intervention on their platform, since it may adversely affect their economic gain.\nCase in point, recently many platforms including Twitter and Reddit has made it harder\nto use their API by third parties, by making it significantly expensive [ 365]. Therefore,\nwhile designing affordances against problematic information, future researchers and design\npractitioner needs to consider how their design could impact the stakeholder power dynamics\nand how platforms may react to them.\n7.1.2 Addressing Adversarial Manipulation\nIn our NudgeCred study, the simplicity of our algorithm for affordance design brought about\nquestions of adversaries taking advantage of them. This problem is not exactly a new one.\nTake the case of search engines optimization feature (SEO). Since its introduction, various\nadversarial agents began taking advantage of SEO features through various means, such as\nadding more keywords in webpage headers [ 284]. There are several potential approaches to\ncounter this problem when designing affordances. One of the approaches would be to not\nuse vulnerable information as triggers for affordance design. For example, in NudgeCred\ndesign, users\u2019 social interaction as a trigger is vulnerable, since this interaction can easily be\nmanipulated. Instead, if filtered social interaction based on users\u2019 historical information, we\ncould have accounted for these vulnerability to a certain degree. On the other hand, if we\nused a third-party reliable source of information (e.g., fact-checking by snope.com) to detect\nquestionable content, it wouldbe much less vulnerable Another solution to adversarial attack\nis to make the algorithms behind the affordances very opaque. However, such opaqueness\ncounteracts the transparency principle of designing affordances. In general, whatever means\ndesigners employ in designing affordances to counter adversarial manipulation, they still\nneed to continuously monitor for such attacks.\n7.1.3 Designing for Long Run\nInOthertubework, wesawreductioninuserengagementwiththeaffordances. InNudgeCred\nwork, we also discussed the issue of novelty wearing off from the design cues. This is a\nchallenge that impacts most HCI design, not just affordances. Over time, users may get used\nto a new affordance which could impact their perception of the design as well as interaction\nwith it in different ways. Some may intuitively get used to interacting with an affordance,\nwhile other may ignore it like a background noise. Therefore, we need to examine this avenue\nof research to find out under what condition users would interact with an affordance instead\nof ignoring them in the long run. For example, a reminder about the functionality of an\naffordance once in a while could make users interact with it for longer period. A tutorial\nof how an affordance work in different scenario could also act like such as a reminder. We\nleave this line of investigation for future research.\n7.1.4 Choosing Between Cognitive Processes\nSince both types of affordances show some impact on attitude formation, one question that\ndesign practitioner may ask is how they should choose to design between designing auto-\nmatic and reflective affordances. Before responding to this question, let us consider how the\ncognition process may have worked out for the participants in our study. Now, generally\nscholars behind dual process theories suggests that these two processes are very distinctive in\nnature [128]. Keeping that in mind, we build dual process affordances with the assumption\nthat each affordance will lead to use of respective cognitive process, at least for a majority\nof the users. However, in our study, we did not distinguish whether the effect, that is, the\nbehavior formation came exactly from the use of a particular process. Rather the resulting\nbehavior formation could be product of either of these processes or both of these process,\ndepending on the individual. Take an example quote from NudgeCred where the participant\nmentioned that when they saw questionable nudge, they thought those news items were con-\ntroversial. This example seems to indicate the creation of a mental shortcut. This shortcut\ncould have happened just from automatic thinking or from a combination of both automatic\nand reflective thinking. For the case of combined processing, it could also have played out\nin different ways. For one, automatic and reflective processing could have happened simul-\ntaneously. Since automatic processing is faster, reflective processing would catch up later.\nInstead of these processes ocurring in parallel, the opposite could have also happened. Auto-\nmatic process could have finished first, followed by rationalization by the reflective process.\nSo far, I have assumed that both automatic and reflective mode would come to a coherent\nconclusion, by resolving any conflict if it happens. However, this might not be true in all\ninstances for everyone. Rather, some may see dissonance between these process which may\nresult in more deliberation between these processes later on, although that may not the case\nfor the quote I started with. What this discussion has taught us is that although we may\ndesign affordances to elicit certain mental route use, we can not control it, rather the usage\nof mental routes could play out in different ways depending on individual tendencies.\nNow going back to the question of choosing between the processes, my response to this\nquestion is that it depends a lot on the audience. As most people tend to use automatic\ncognitive function due to the ease of use [ 128], if a design practitioner want to appeal to the\nlargest number of users, designing automatic cognitive affordance would be the better choice\nhere. However, if the audience appreciates use of reflective thinking, design practitioner\nshould consider reflective affordance design. Overall, a general rule of thumb would be a\nhybridapproachwherepractitionersshoulddesignbothautomaticandreflectiveaffordances.\nThis way users can opt to choose either or both.\n7.2 Cognitive Affordances and Attitude F ormation: Mod-\nerators\nIn this dissertation, I have primarily focused on answering whether dual process cognitive\naffordances can impact attitude formation. Since we found the evidence of this relationship,\nthe next evident question that arises is: what are the moderators that impact this relation-\nship?In our study, we looked for some moderators, such as, user demography, behavioral\nfactors, prior knowledge on information topics, or their values. The reason this list was not\ncomprehensive is primarily due to limitations of standard human-subjects research. Going\nbeyond that, in an information consumption setting, the list of factors, both intrinsic and\nextrinsic, could be very large as well as diverse. Here, I will discuss a few based on prior\nliterature. In the ELM model, Petty et. al. suggests that motivation behind the information\nprocessing is a key factor in this relationship [ 355]. This motivation could be very differ-\nent for the scenarios I have designed the systems. Some may go to social media to learn\nabout a news topic or learn about their friends or purely for entertainment purpose. Such\nmotivation could affect the attention mechanism they are willing to deploy during browsing,\nwhich in turn could impact the cognitive processing occurring. For example, in NudgeCred,\nthe motivation of individuals could have greatly impacted individuals\u2019 credibility judgment.\nAnother factor that could affect use of a particular cognitive process is the availability of\ncognitive resources [ 379]. For example, users might be more alert and engage reflection more\nfrequently at the start of the day compared to the end of the day when their mental load\ncapacity has depleted. Another moderating factor is the expertise of the user on a particular\ntopic of information [ 5]. Scholars argue that expertise on a topic lead to use of the analytical\nroute on information consumption on that topic [ 5]. Thus, effect of NudgeCred could have\nvaried by tweet topic. Various individual dispositions could also affect the effectiveness of\nan affordance [ 347]. For example, individuals who are more open to diverse information con-\nsumption could be affected more by OtherTube tool. Some other factors that could affecting\nthe efficacy of cognitive affordances is the mood of the users [ 204]. For example, users in\npositive mood may engage different degree of reflection while using OtherTube. To sum,\nthe list of factors moderating the relationship between affordances and attitude formation is\nvery large. I leave such discussion for the future.\n7.3 Applying Affordances in Other Scenarios\nIn this thesis, I focused on two types of problematic information, misinformation and filter\nbubble, for designing dual process cognitive affordances. Furthermore, we conducted the\ndeployment of our designs on general US population. However, our affordance design ap-\nproach has the potential for use to combat other types of problematic information and can\nbe designed targeting any subset of the population. Below, I discuss this opportunity to\napply cognitive affordances in these two scenarios.\n7.3.1 Against Other Problematic Content\nOur design can be adopted against other types of problematic content. To show this, I will\nstart by showing how designs for misinformation be applied against other types of problem-\natic content like hate speech, propaganda, and conspiracy. Lets first look at the algorithm\nbehindNudgeCred. Itusessomepriorannotationofmainstreamandnon-mainstreamsource,\nand users social interaction like questioning. For the design against hate speech, we will first\nneed a similar annotation of hate speech sources like the hate map from SPLC1. Next,\nwe can replace looking for questions by looking for a confirmation of hate speech in user\nreaction using a lexicon or dictionary of frequently used words in response. However, this is\nstill a simplication and does not consider that keywords appearing in hate speech lexicons is\ncontext dependent. For example, using n-word by a black person is not a hate speech while\nothers may use it for that purpose [ 346]. However, discussion on such nuances is not within\nthe scope of this work. After the detection, we can apply color coding similar to NudgeCred\nwhere we can swap the tooltips with information about hate speech. We can follow the\nsame procedure for others as well. Now that we see that design process can be translated,\nthe next question is, would it impact users attitude? This question is more complicated\nto answer. That is because, while interventions on misinformation and filter bubble have\nshown promising result, it may not work that well for certain groups. For example, user\ngroups like conspiracists tend to have strong bias in their conspiracy attitude and most prior\nintervention show lack of any effect [ 339]. Therefore, before making any claim here, we need\nempirical evidence, and leave it as a future work.\n1https://www.splcenter.org/hate-map\n7.3.2 F or Certain User Groups\nCompared to extending the design affordances against other types of problematic content,\ndesigning affordances for certain user group is tricky. Take the example of design affordances\nfor user with neuro-divergence. Since their cognitive process differ from neurotypical users,\nthey may not recognize the design cues we built so far. Or even if they do recognize the cues,\nit could have different impact on their attitude. Furthermore, they may have other issue.\nFor example, reflection is already challening for neurotypical people and could be harder for\nthem [421]. Or, new design affordances can easily trigger sensory overload for them [ 275].\nTherefore, designing cognitive affordances for these users require careful considerations and\nwe leave it up to future designers.\n7.4 Ethical Considerations for Cognitive Affordances\nDesign of affordances against problematic information can bring out some of the concerns of\nbehavior modification. As Selinger critiques, \u201cW ould someone who values their freedom to\nchoose be okay with the idea that their behavior is being modified in ways they are not aware\nof?\u201d[409] Inspired by Hansen\u2019s work on transparency in nudge design [ 186], I argue that\ncognitive affordances can be distinguished into two types: transparent and non-transparent.\nHere, non-transparent affordances would be manipulative by definition, while transparent\naffordances could rather be empowering the users instead of manipulating. This empow-\nerment comes from design practitioner disclosing the purpose and mechanism behind an\naffordance design. Such disclosure removes the said ethical dilemma posed by the question\nfrom Selinger. In the four studies conducted, I have followed this principle of transparency\n(like the tooltip showing the rationale for intervention in NudgeCred). In addition, I would\nalsoarguethatreflectiveaffordancesbydesignallowsanalyticalthinkingamongitsaudience,\nand thus not manipulative in nature. Therefore, designing reflective cognitive affordances\nwould be more desirable from an ethical perspective. In addition to thinking of transparency\nin affordance design, designers also need to think about ethics from the perspective of the\ntype of value is embedded during design. This idea has been explored in many HCI concepts,\nsuch as, values-sensitive design, reflective design, and values in design [ 144,235,411]. These\nresearch suggest that the value of the designers affect how technologies are imagined, how\nunderlying mechanism behind the design constructed, and corresponding ethical considera-\ntion. For example, the type of data being used when devising a cognitive affordance requires\ncorresponding ethical consideration, such as, asking if the data being used is private or not.\nHowever, discussion on these considerations relate to each instances of design, instead of\nthe abstract level of cognitive affordance design. Therefore, I leave this discussion up to the\npractitioners during their design process.\nChapter 8\nConclusion\nOnline news platforms are increasingly becoming complicated as new sources try to break\nin and the platforms try to improve engagement. When the HCI community is debating\nwhether to convert the research direction in these domains from a \u201cfix it\u201d to a \u201cburn it\ndown\u201d [453], this thesis still takes the stance of the former by augmenting existing systems\nwith improvements meant to help users. Using dual process theories of mind, I propose de-\nsigns that can help users tackle the issue of misinformation and filter bubbles on their online\nnews feeds. In NudgeCred, I introduce automatic affordances built on heuristics to assist\nusers in differentiating news content reliability on social media using their automatic mode\nof cognition. My evaluation shows the promise of this approach working in real-world sce-\nnarios. In TransparencyCue, I present a set of design opportunity for automatic affordances\nto promote stakeholder values like transparency on news platforms through an interview\nstudy of news consumers and journalists. In NewsComp, I present a reflective affordance to\npromote news reading from diverse perspectives. In OtherTube, I used reflective affordance\ndesign by swapping recommendation with others to help users become more aware of the\ninterest bubble imposed by algorithmic recommendation bubble and engage in content dis-\ncovery new interests. Overall, this set of systems may provide much-needed assistance for\nthe users to tackle the issue of misinformation and filter bubbles.\n204\n8.1 F uture W ork\nEach of the works presented in this thesis opens up an avenue for a new line of research.\nNudgeCred shows promise for using alternate heuristics to design automatic affordances.\nSuch systems could be designed based on what different users need, instead of a universal\none. Additionally, looking into the effects of such design on users with extreme beliefs in\ncontentious topics could help us understand the limitations of such designs. In Transparen-\ncyCue work, I presented a set of design cues where a logical next step would be to conduct\na controlled evaluation of how the audience perceives such design cues. Especially, tack-\nling the conflicts in such design could open up direction for compromise in designing such\nsystems. In NewsComp, the performance of the users in annotation creates several chal-\nlenges for effective adoption of this affordance. If users make more mistakes, it can result\nin wrong perception. Therefore, this design has to be modified to improve performance. If\nexchanging recommendations in YouTube through OtherTube helps users realize filter bub-\nbles, it may also present new challenges. For example, at scale, it could be hard to match\nusers against each other. Therefore, sophisticated methods need to be designed to provide\nimproved matching. Future research may also delve into the question of whether these de-\nsigns provide meaningful guides to the users in the long, which is often an issue with many\nsolutions. Finally, there is also potential to apply the same theoretical grounded approach\nto designs solutions for other issues in problematic information domain. Overall, these are\nseveral avenues for future work beyond this thesis.\nBibliography\n[1]Bradley J Adame. Training in the mitigation of anchoring bias: A test of the consider-\nthe-opposite strategy. Learning and Motivation , 53:36\u201348, 2016.\n[2]Alexander T Adams, Jean Costa, Malte F Jung, and Tanzeem Choudhury. Mindless\ncomputing: designing technologies to subtly influence behavior. In Proceedings of the\n2015 ACM international joint conference on pervasive and ubiquitous computing , pages\n719\u2013730, 2015.\n[3]Gediminas Adomavicius, Jesse Bockstedt, Shawn Curley, and Jingjing Zhang. De-\nbiasing user preference ratings in recommender systems. In RecSys 2014 W orkshop\non Interfaces and Human Decision Making for Recommender Systems (IntRS 2014) ,\npages 2\u20139. Citeseer, 2014.\n[4]Tanja Aitamurto, Mike Ananny, Chris W Anderson, Larry Birnbaum, Nicholas Di-\nakopoulos, Matilda Hanson, Jessica Hullman, and Nick Ritchie. Hci for accurate, im-\npartial and transparent journalism: Challenges and solutions. In Extended Abstracts\nof the 2019 CHI Conference on Human F actors in Computing Systems , page W22.\nACM, 2019.\n[5]Joseph W Alba and J Wesley Hutchinson. Dimensions of consumer expertise. Journal\nof consumer research , 13(4):411\u2013454, 1987.\n[6]Linda Aldoory and Mark A Van Dyke. The roles of perceived \u201cshared\u201d involvement\nandinformationoverloadinunderstandinghowaudiencesmakemeaningofnewsabout\nbioterrorism. Journalism & Mass Communication Quarterly , 83(2):346\u2013361, 2006.\n206\n[7]Shahmir H Ali, Joshua Foreman, Ariadna Capasso, Abbey M Jones, Yesim Tozan, and\nRalph J DiClemente. Social media as a recruitment platform for a nationwide online\nsurvey of covid-19 knowledge, beliefs, and practices in the united states: methodology\nand feasibility analysis. BMC medical research methodology , 20:1\u201311, 2020.\n[8]Hunt Allcott and Matthew Gentzkow. Social media and fake news in the 2016 election.\nJournal of Economic Perspectives , 31(2):211\u201336, 2017.\n[9]Hunt Allcott, Matthew Gentzkow, and Chuan Yu. Trends in the diffusion of misinfor-\nmation on social media. Research & Politics , 6(2):2053168019848554, 2019.\n[10]David S Allen. The trouble with transparency: The challenge of doing journalism\nethics in a surveillance society. Journalism Studies , 9(3):323\u2013340, 2008.\n[11]Jennifer Allen, Antonio A Arechar, Gordon Pennycook, and David G Rand. Scaling\nup fact-checking using the wisdom of crowds. Science advances , 7(36):eabf4393, 2021.\n[12]JenniferAllen, CameronMartel, andDavidGRand. Birdsofafeatherdon\u2019tfact-check\neach other: Partisanship and the evaluation of news in twitter\u2019s birdwatch crowd-\nsourced fact-checking program. In CHI Conference on Human F actors in Computing\nSystems, pages 1\u201319, 2022.\n[13]Mike Allen. Meta-analysis comparing the persuasiveness of one-sided and two-sided\nmessages. W estern Journal of Speech Communication , 55(4):390\u2013404, 1991.\n[14]AllSides. Allsides | balanced news via media bias ratings for an unbiased news per-\nspective. https://www.allsides.com/unbiased-balanced-news , 2012. (Accessed\non 04/08/2021).\n[15]Bobby Allyn. 4 takeaways from facebook whistleblower frances hau-\ngen\u2019s testimony : Npr. https://www.npr.org/2021/10/05/1043377310/\nfacebook-whistleblower-frances-haugen-congress , 10 2021. (Accessed on\n11/13/2021).\n[16]PaulAndr\u00e9, MCSchraefel, AlanDix, andRyenWWhite. Expressingwell-beingonline:\ntowards self-reflection and social awareness. In Proceedings of the 2011 iConference ,\npages 114\u2013121. ACM, 2011.\n[17]Mark Andrejevic. Infoglut: How too much information is changing the way we think\nand know . Routledge, 2013.\n[18]AP. Associated press news values and principles. https://www.ap.org/about/news-\nvalues-and-principles/, 2018.\n[19]Amelia Arsenault and Manuel Castells. Conquering the minds, conquering iraq: The\nsocial production of misinformation in the united states\u2013a case study. Information,\nCommunication & Society , 9(3):284\u2013307, 2006.\n[20]WBrianArthur. Inductivereasoningandboundedrationality. The American economic\nreview, 84(2):406\u2013411, 1994.\n[21]IsabelleAugenstein, TimRockt\u00e4schel, AndreasVlachos, andKalinaBontcheva. Stance\ndetection with bidirectional conditional encoding. arXiv preprint arXiv:1606.05464 ,\n2016.\n[22]Axios. Axios - editorial ethics policy. https://www.axios.com/about/ethics , 2016.\n(Accessed on 03/25/2021).\n[23]Mevan Babakar. Crowdsourced factchecking, May 2018.\n[24]Mevan Babakar. Crowdsourced factchecking: There is a role for\ncrowdsourcing in factchecking but (so far) it\u2019s not factchecking.\nhttps://medium.com/@meandvan/crowdsourced-factchecking-4c5168ea5ac3, 2018.\n[25]KhaledBachour, JonBird, VaivaKalnikaite, YvonneRogers, NicolasVillar, andStefan\nKreitmayer. Fast and frugal shopping challenge. In CHI\u201912 Extended Abstracts on\nHuman F actors in Computing Systems , pages 1459\u20131460. ACM, 2012.\n[26]Mitja D Back, Juliane M Stopfer, Simine Vazire, Sam Gaddis, Stefan C Schmukle,\nBoris Egloff, and Samuel D Gosling. Facebook profiles reflect actual personality, not\nself-idealization. Psychological science , 21(3):372\u2013374, 2010.\n[27]Adam Badawy, Emilio Ferrara, and Kristina Lerman. Analyzing the digital traces\nof political manipulation: The 2016 russian interference twitter campaign. In 2018\nIEEE/ACM International Conference on Advances in Social Networks Analysis and\nMining (ASONAM) , pages 258\u2013265. IEEE, 2018.\n[28]Jae-eul Bae, Youn-kyung Lim, Jin-bae Bang, and Myung-suk Kim. Ripening room:\nDesigning social media for self-reflection in self-expression. In Proceedings of the 2014\nConference on Designing Interactive Systems , DIS \u201914, page 103\u2013112, New York, NY,\nUSA, 2014. Association for Computing Machinery. ISBN 9781450329026. doi: 10.\n1145/2598510.2598567. URL https://doi.org/10.1145/2598510.2598567 .\n[29]Joseph O Baker and Amy E Edmonds. Immigration, presidential politics, and partisan\npolarization among the american public, 1992\u20132018. Sociological Spectrum , 41(4):287\u2013\n303, 2021.\n[30]Rebecca Balebako, Pedro G Leon, Hazim Almuhimedi, Patrick Gage Kelley, Jonathan\nMugan, Alessandro Acquisti, Lorrie Faith Cranor, and Norman Sadeh. Nudging users\ntowardsprivacyonmobiledevices. In Proc. CHI 2011 W orkshop on Persuasion, Nudge,\nInfluence and Coercion , pages 193\u2013201. Citeseer, 2011.\n[31]Elizabeth Bales and William Griswold. Interpersonal informatics: Making social in-\nfluence visible. In CHI \u201911 Extended Abstracts on Human F actors in Computing\nSystems, CHI EA \u201911, page 2227\u20132232, New York, NY, USA, 2011. Association for\nComputing Machinery. ISBN 9781450302685. doi: 10.1145/1979742.1979924. URL\nhttps://doi.org/10.1145/1979742.1979924 .\n[32]Meital Balmas. When fake news becomes real: Combined exposure to multiple news\nsources and political attitudes of inefficacy, alienation, and cynicism. Communication\nresearch, 41(3):430\u2013454, 2014.\n[33]Jack Bandy. Problematic machine behavior: A systematic literature review of algo-\nrithm audits. Proceedings of the acm on human-computer interaction , 5(CSCW1):\n1\u201334, 2021.\n[34]Scott Bateman, Rosta Farzan, Peter Brusilovsky, and Gord McCalla. Oats: The open\nannotation and tagging system. Proceedings of I2LOR , 2006.\n[35]Eric PS Baumer. Reflective informatics: conceptual dimensions for designing tech-\nnologies of reflection. In Proceedings of the 33rd Annual ACM Conference on Human\nF actors in Computing Systems , pages 585\u2013594. ACM, 2015.\n[36]Joshua Becker, Ethan Porter, and Damon Centola. The wisdom of partisan crowds.\nProceedings of the National Academy of Sciences , 116(22):10717\u201310722, 2019.\n[37]W Lance Bennett. Perception and cognition. In The handbook of political behavior ,\npages 69\u2013193. Springer, 1981.\n[38]Sabine Bergler. Conveying attitude with reported speech. In Computing attitude and\naffect in text: Theory and applications , pages 11\u201322. Springer, 2006.\n[39]Michael S Bernstein, Mark S Ackerman, Ed H Chi, and Robert C Miller. The trouble\nwith social computing systems research. In CHI\u201911 Extended Abstracts on Human\nF actors in Computing Systems , pages 389\u2013398. 2011.\n[40]Alessandro Bessi, Fabiana Zollo, Michela Del Vicario, Michelangelo Puliga, Antonio\nScala, Guido Caldarelli, Brian Uzzi, and Walter Quattrociocchi. Users polarization on\nfacebook and youtube. PloS one , 11(8):e0159641, 2016.\n[41]Md Momen Bhuiyan, Kexin Zhang, Kelsey Vick, Michael A Horning, and Tanushree\nMitra. Feedreflect: A tool for nudging users to assess news credibility on twitter. In\nCompanion of the 2018 ACM Conference on Computer Supported Cooperative W ork\nand Social Computing , pages 205\u2013208, 2018.\n[42]Md Momen Bhuiyan, Amy X Zhang, Connie Moon Sehat, and Tanushree Mitra. In-\nvestigating differences in crowdsourced news credibility assessment: Raters, tasks, and\nexpert criteria. arXiv preprint arXiv:2008.09533 , 2020.\n[43]Md Momen Bhuiyan, Michael Horning, Sang Won Lee, and Tanushree Mitra. Nudge-\ncred: supporting news credibility assessment on social media through nudges. Proceed-\nings of the ACM on Human-Computer Interaction , 5(CSCW2):1\u201330, 2021.\n[44]MdMomenBhuiyan, HaydenWhitley, MichaelHorning, SangWonLee, andTanushree\nMitra. Designing transparency cues in online news platforms to promote trust: Jour-\nnalists\u2019& consumers\u2019 perspectives. Proceedings of the ACM on Human-Computer In-\nteraction , 5(CSCW2):1\u201331, 2021.\n[45]Md Momen Bhuiyan, Carlos Augusto Bautista Isaza, Tanushree Mitra, and Sang Won\nLee. Othertube: Facilitating content discovery and reflection by exchanging youtube\nrecommendationswithstrangers. In Proceedings of the 2022 CHI Conference on Human\nF actors in Computing Systems , pages 1\u201317, 2022.\n[46]Md Momen Bhuiyan, Sang Won Lee, Nitesh Goyal, and Tanushree Mitra. Newscomp:\nFacilitating diverse news reading through comparative annotation. In Proceedings of\nthe 2023 CHI Conference on Human F actors in Computing Systems , pages 1\u201317, 2023.\n[47]Ricardo Bilton. How one washington post reporter uses pen\nand paper to make his tracking of trump get noticed \u00bb nie-\nman journalism lab. https://www.niemanlab.org/2016/09/\nhow-one-washington-post-reporter-uses-pen-and-paper-to-make-his-tracking-of-trump-get-noticed/ ,\n2016. (Accessed on 09/29/2019).\n[48]Bernd Bl\u00f6baum. Trust and journalism in a digital environment. 2014.\n[49]Oversight Board. Oversight board | independent judgment. transparency. legitimacy.\nhttps://oversightboard.com/ , 2020. (Accessed on 04/05/2021).\n[50]Taylor C Boas, Dino P Christenson, and David M Glick. Recruiting large online\nsamples in the united states and india: Facebook, mechanical turk, and qualtrics.\nPolitical Science Research and Methods , 8(2):232\u2013250, 2020.\n[51]Bal\u00e1zs Bod\u00f3, Natali Helberger, Sarah Eskens, and Judith M\u00f6ller. Interested in di-\nversity: The role of user attitudes, algorithmic feedback loops, and policy in news\npersonalization. Digital journalism , 7(2):206\u2013229, 2019.\n[52]Ben Bolker. lme4 package | r documentation. https://www.\nrdocumentation.org/packages/lme4/versions/1.1-18-1, 2018.\n[53]Toby Bolsen and James N Druckman. Counteracting the politicization of science. J.\nCommun. , 65(5):745\u2013769, 2015.\n[54]Porismita Borah and Xizhu Xiao. The importance of \u2018likes\u2019: The interplay of message\nframing, source, and social endorsement on credibility perceptions of health informa-\ntion on facebook. Journal of health communication , 23(4):399\u2013411, 2018.\n[55]Paul Bossauer, Thomas Neifer, Gunnar Stevens, and Christina Pakusch. Trust versus\nprivacy: Using connected car data in peer-to-peer carsharing. In Proceedings of the\n2020 CHI Conference on Human F actors in Computing Systems , pages 1\u201313, 2020.\n[56]Mark Boukes, Natalie P Jones, and Rens Vliegenthart. Newsworthiness and story\nprominence: How the presence of news factors relates to upfront position and length\nof news stories. Journalism , page 1464884919899313, 2020.\n[57]EnginBozdag. Biasinalgorithmicfilteringandpersonalization. Ethics and information\ntechnology , 15:209\u2013227, 2013.\n[58]Ivar Br\u00e5ten and Helge I Str\u00f8ms\u00f8. Measuring strategic processing when students read\nmultiple texts. Metacognition and Learning , 6(2):111\u2013130, 2011.\n[59]Marilynn B Brewer and William D Crano. Research design and issues of validity.\nHandbook of research methods in social and personality psychology , pages 3\u201316, 2000.\n[60]Campbell Brown. Introducing facebook news - about facebook. https://about.fb.\ncom/news/2019/10/introducing-facebook-news/ , 2019. (Accessed on 09/11/2020).\n[61]Lauren Valentino Bryant. The youtube algorithm and the alt-right filter bubble. Open\nInformation Science , 4(1):85\u201390, 2020.\n[62]E Brynjolfsson and MV Alstyne. Electronic communities: Global village or cyber-\nbalkans? In International Conference on Information Systems, December , pages 16\u2013\n18, 1996.\n[63]DavidVBudescuandEvaChen. Identifyingexpertisetoextractthewisdomofcrowds.\nManagement Science , 61(2):267\u2013280, 2015.\n[64]Guido Buelow. Automation plus expert journalism: How full fact is fight-\ning misinformation - about facebook. https://about.fb.com/news/2019/06/\ninside-feed-full-fact-interview/ , 2019. (Accessed on 09/11/2020).\n[65]Laura Burbach, Patrick Halbach, Martina Ziefle, and Andr\u00e9 Calero\u00c2\u00a0Valdez. Bubble\nTrouble: Strategies Against Filter Bubbles in Online Social Networks. Lecture Notes\nin Computer Science (including subseries Lecture Notes in Artificial Intel ligence and\nLecture Notes in Bioinformatics) , 11582 LNCS:441\u2013456, 2019. ISSN 16113349. doi:\n10.1007/978-3-030-22219-2_33.\n[66]Laila Burla, Birte Knierim, Jurgen Barth, Katharina Liewald, Margreet Duetz, and\nThomas Abel. From text to codings: intercoder reliability assessment in qualitative\ncontent analysis. Nursing research , 57(2):113\u2013117, 2008.\n[67]Lynette Sheridan Burns and Benjamin J Matthews. Understanding journalism . Sage,\n2018.\n[68]Julie G Bush, Hollyn M Johnson, and Colleen M Seifert. The implications of correc-\ntions: Then why did you mention it. 1994.\n[69]Joseph N Cappella and Kathleen Hall Jamieson. Spiral of cynicism: The press and\nthe public good . Oxford University Press on Demand, 1997.\n[70]Ana Caraban, Evangelos Karapanos, Daniel Gon\u00e7alves, and Pedro Campos. 23 ways\nto nudge: A review of technology-mediated nudging in human-computer interaction.\nIn Proceedings of the 2019 CHI Conference on Human F actors in Computing Systems ,\npage 503. ACM, 2019.\n[71]D Jasun Carr, Matthew Barnidge, Byung Gu Lee, and Stephanie Jean Tsang. Cynics\nand skeptics: Evaluating the credibility of mainstream and citizen journalism. J. Mass\nCommun. Q. , 91(3):452\u2013470, 2014.\n[72]John M Carroll. Making use: scenario-based design of human-computer interactions .\nMIT press, 2000.\n[73]LizCarverandMurrayTuroff. Human-computerinteraction: thehumanandcomputer\nas a team in emergency management information systems. Communications of the\nACM, 50(3):33\u201338, 2007.\n[74]Pablo Castells, Neil J. Hurley, and Saul Vargas. Novelty and Diversity in Recom-\nmender Systems , pages 881\u2013918. Springer US, Boston, MA, 2015. ISBN 978-1-\n4899-7637-6. doi: 10.1007/978-1-4899-7637-6_26. URL https://doi.org/10.1007/\n978-1-4899-7637-6_26 .\n[75]Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. Information credibility on\ntwitter. In Proc. WWW , pages 675\u2013684. ACM, 2011.\n[76]Mike Caulfield. Web literacy for student fact-checkers. 2017.\n[77]Pew Reseach Center. Political polarization in the american public. Ann Rev Polit Sci ,\n2014.\n[78]PewResearchCenter. Furtherdeclineincredibilityratingsformostnewsorganizations,\n2012.\n[79]Kalyani Chadha and Michael Koliska. Newsrooms and transparency in the digital age.\nJournalism Practice , 9(2):215\u2013229, 2015.\n[80]Shelly Chaiken. The heuristic model of persuasion. In Social influence: the ontario\nsymposium , volume 5, pages 3\u201339. Hillsdale, NJ: Lawrence Erlbaum, 1987.\n[81]Kathy Charmaz. Constructing grounded theory: A practical guide through qualitative\nanalysis. sage, 2006.\n[82]Xinran Chen, Sei-Ching Joanna Sin, Yin-Leng Theng, and Chei Sian Lee. Deterring\nthe spread of misinformation on social network sites: A social cognitive theory-guided\nintervention. Proceedings of the Association for Information Science and T echnology ,\n52(1):1\u20134, 2015.\n[83]Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu. Detecting offensive language in\nsocial media to protect adolescent online safety. In 2012 International Conference\non Privacy, Security, Risk and T rust and 2012 International Conference on Social\nComputing , pages 71\u201380. IEEE, 2012. doi: 10.1109/SocialCom-PASSAT.2012.55.\n[84]Sidharth Chhabra and Paul Resnick. Does clustered presentation lead readers to\ndiverse selections? In CHI\u201913 Extended Abstracts on Human F actors in Computing\nSystems, pages 1689\u20131694. 2013.\n[85]Michelene Chi. Conceptual change within and across ontological categories: Examples\nfrom learning and discovery in science. 1992.\n[86]Sujin Choi. The two-step flow of communication in twitter-based public forums. Social\nscience computer review , 33(6):696\u2013711, 2015.\n[87]Cision. Top 10 u.s. daily newspapers. https://www. cision.com/us/2017/09/top-10-u-\ns-daily-newspapers-2/, 2017.\n[88]Russell D Clark III and Anne Maass. The role of social categorization and perceived\nsource credibility in minority influence. European Journal of Social Psychology , 18(5):\n381\u2013394, 1988.\n[89]Mark Coddington. Building frames link by link: The linking practices of blogs and\nnews sites. International Journal of Communication , 6:20, 2012.\n[90]Sheldon Ed Cohen and SI Syme. Social support and health. Academic Press, 1985.\n[91]Devin Coldewey. Reddit overhauls upvote algorithm to thwart cheaters and\nshow the site\u2019s true scale | techcrunch. https://techcrunch.com/2016/12/06/\nreddit-overhauls-upvote-algorithm-to-thwart-cheaters-and-show-the-sites-true-scale/\n?guccounter=1 , 2016. (Accessed on 01/03/2021).\n[92]Sunny Consolvo, Katherine Everitt, Ian Smith, and James A Landay. Design require-\nments for technologies that encourage physical activity. In Proceedings of the SIGCHI\nconference on Human F actors in computing systems , pages 457\u2013466, New York, NY,\nUSA, 2006. Association for Computing Machinery.\n[93]Sunny Consolvo, David W. McDonald, and James A. Landay. Theory-Driven Design\nStrategies for T echnologies That Support Behavior Change in Everyday Life , page\n405\u2013414. Association for Computing Machinery, New York, NY, USA, 2009. ISBN\n9781605582467. URL https://doi.org/10.1145/1518701.1518766 .\n[94]John Cook, Stephan Lewandowsky, and Ullrich KH Ecker. Neutralizing misinforma-\ntion through inoculation: Exposing misleading argumentation techniques reduces their\ninfluence. PloS one , 12(5):e0175799, 2017.\n[95]Eric Corbett and Christopher A Le Dantec. Going the distance: Trust work for cit-\nizen participation. In Proceedings of the 2018 CHI conference on human factors in\ncomputing systems , pages 1\u201313, 2018.\n[96]Denzil Correa, Leandro Ara\u00fajo Silva, Mainack Mondal, Fabr\u00edcio Benevenuto, and Kr-\nishna P Gummadi. The many shades of anonymity: Characterizing anonymous social\nmedia content. In Ninth International AAAI Conference on W eb and Social Media ,\n2015.\n[97]CynthiaLCorritore, BeverlyKracher, andSusanWiedenbeck. On-linetrust: concepts,\nevolving themes, a model. International journal of human-computer studies , 58(6):\n737\u2013758, 2003.\n[98]DanCosley,ShyongKLam,IstvanAlbert,JosephAKonstan,andJohnRiedl. Isseeing\nbelieving? how recommender system interfaces affect users\u2019 opinions. In Proceedings\nof the SIGCHI conference on Human factors in computing systems , pages 585\u2013592,\n2003.\n[99]Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for youtube\nrecommendations. In Proceedings of the 10th ACM Conference on Recommender\nSystems, RecSys \u201916, page 191\u2013198, New York, NY, USA, 2016. Association for\nComputing Machinery. ISBN 9781450340359. doi: 10.1145/2959100.2959190. URL\nhttps://doi.org/10.1145/2959100.2959190 .\n[100]Stephanie Craft and Kyle Heim. Transparency in journalism: Meanings, merits, and\nrisks. The handbook of mass media ethics , pages 217\u2013228, 2009.\n[101]Brent Cunningham. Skin deep: when\u2019transparency\u2019is a smoke screen. Columbia Jour-\nnalism Review , 45(2):9\u201311, 2006.\n[102]Alex Curry and Natalie Jomini Stroud. Trust in online news. Center for Media\nEngagement, University of T exas at Austin , 2017.\n[103]Alexander L Curry and Natalie Jomini Stroud. The effects of journalistic trans-\nparency on credibility assessments and engagement intentions. Journalism , page\n1464884919850387, 2019.\n[104]JamesDavidson, BenjaminLiebald, JunningLiu, PalashNandy, andTaylorVanVleet.\nThe YouTube video recommendation system. RecSys\u201910 - Proceedings of the 4th ACM\nConference on Recommender Systems , pages 293\u2013296, 2010. doi: 10.1145/1864708.\n1864770.\n[105]Munmun De Choudhury, Michael Gamon, Aaron Hoff, and Asta Roseway. \u201cmoon\nphrases\u201d: A social media faciliated tool for emotional reflection and wellness. In 2013\n7th International Conference on Pervasive Computing T echnologies for Healthcare and\nW orkshops , pages 41\u201344. IEEE, European Alliance for Innovation, 2013.\n[106]Claes H De Vreese. News framing: Theory and typology. Information design journal\n& document design , 13(1), 2005.\n[107]James W Dearing, Everett M Rogers, and Everett Rogers. Agenda-setting , volume 6.\nSage, 1996.\n[108]Michela Del Vicario, Alessandro Bessi, Fabiana Zollo, Fabio Petroni, Antonio Scala,\nGuido Caldarelli, H Eugene Stanley, and Walter Quattrociocchi. The spreading of\nmisinformation online. Proceedings of the National Academy of Sciences , 113(3):554\u2013\n559, 2016.\n[109]Michela Del Vicario, Antonio Scala, Guido Caldarelli, H Eugene Stanley, and Walter\nQuattrociocchi. Modeling confirmation bias and polarization. Scientific reports , 7(1):\n1\u20139, 2017.\n[110]Stefano DellaVigna and Ethan Kaplan. The fox news effect: Media bias and voting.\nThe Quarterly Journal of Economics , 122(3):1187\u20131234, 2007.\n[111]Peter M DeMarzo, Dimitri Vayanos, and Jeffrey Zwiebel. Persuasion bias, social in-\nfluence, and unidimensional opinions. The Quarterly journal of economics , 118(3):\n909\u2013968, 2003.\n[112]Mark Deuze. The web and its journalisms: considering the consequences of different\ntypes of newsmedia online. New media & society , 5(2):203\u2013230, 2003.\n[113]Nicholas Diakopoulos. Algorithmic accountability: Journalistic investigation of com-\nputational power structures. Digital journalism , 3(3):398\u2013415, 2015.\n[114]Nicholas Diakopoulos, Munmun De Choudhury, and Mor Naaman. Finding and as-\nsessing social media information sources in the context of journalism. In Proc. CHI ,\npages 2451\u20132460. ACM, 2012.\n[115]AbrahamDoris-Down, HusaynVersee, andEricGilbert. Politicalblend: anapplication\ndesigned to bring people together based on political differences. In Proceedings of the\n6th International Conference on Communities and T echnologies , pages 120\u2013130, New\nYork, NY, USA, 2013. Association for Computing Machinery.\n[116]Tim Draws, David La Barbera, Michael Soprano, Kevin Roitero, Davide Ceolin,\nAlessandro Checco, and Stefano Mizzaro. The effects of crowd worker biases in fact-\nchecking tasks. In 2022 ACM Conference on F airness, Accountability, and T rans-\nparency, pages 2114\u20132124, 2022.\n[117]James N Druckman and Michael Parkin. The impact of media bias: How editorial\nslant affects voters. The Journal of Politics , 67(4):1030\u20131049, 2005.\n[118]The Economist. About us | the economist. https://www.economist.com/help/\nabout-us , 2010. (Accessed on 10/11/2020).\n[119]Robert M Entman. Framing: Toward clarification of a fractured paradigm. 1993.\n[120]Robert M Entman. Framing bias: Media in the distribution of power. Journal of\ncommunication , 57(1):163\u2013173, 2007.\n[121]Robert M Entman, Carole Bell, Cary Frith, and Barbara Miller. Constraining the\npolitics of self-interest: How the media helped to sell the bush tax cuts. In Research\nConference of the National Communication Association, Boston, MA , 2005.\n[122]Martin J Eppler and Jeanne Mengis. The concept of information overload-a review of\nliteraturefromorganizationscience, accounting, marketing, mis, andrelateddisciplines\n(2004). Kommunikationsmanagement im W andel , pages 271\u2013305, 2008.\n[123]Daniel A Epstein, An Ping, James Fogarty, and Sean A Munson. A lived informatics\nmodel of personal informatics. In Proceedings of the 2015 ACM International Joint\nConference on Pervasive and Ubiquitous Computing , pages 731\u2013742, New York, NY,\nUSA, 2015. Association for Computing Machinery.\n[124]Thomas Erickson and Wendy A Kellogg. Social translucence: an approach to de-\nsigning systems that support social processes. ACM transactions on computer-human\ninteraction (TOCHI) , 7(1):59\u201383, 2000.\n[125]Marcus Errico, J April, A Asch, L Khalfani, M Smith, and X Ybarra. The evolution\nof the summary news lead. Media History Monographs , 1(1), 1997.\n[126]Motahhare Eslami, Amirhossein Aleyasen, Karrie Karahalios, Kevin Hamilton, and\nChristian Sandvig. Feedvis: A path for exploring news feed curation algorithms. In\nProceedings of the 18th acm conference companion on computer supported cooperative\nwork & social computing , pages 65\u201368, New York, NY, USA, 2015. Association for\nComputing Machinery.\n[127]Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy\nVuong, Karrie Karahalios, Kevin Hamilton, and Christian Sandvig. \u201d i always as-\nsumed that i wasn\u2019t really that close to [her]\u201d reasoning about invisible algorithms\nin news feeds. In Proceedings of the 33rd annual ACM conference on human fac-\ntors in computing systems , pages 153\u2013162, New York, NY, USA, 2015. Association for\nComputing Machinery.\n[128]Jonathan St BT Evans. In two minds: dual-process accounts of reasoning. T rends in\ncognitive sciences , 7(10):454\u2013459, 2003.\n[129]Jonathan St BT Evans. Dual-processing accounts of reasoning, judgment, and social\ncognition. Annu. Rev. Psychol. , 59:255\u2013278, 2008.\n[130]William P Eveland Jr and Sharon Dunwoody. User control and structural isomorphism\nor disorientation and cognitive load? learning from the web versus print. Communi-\ncation research , 28(1):48\u201378, 2001.\n[131]Gunther Eysenbach. Credibility of health information and digital media: New perspec-\ntives and implications for youth . MacArthur Foundation Digital Media and Learning\nInitiative, 2008.\n[132]Facebook. How facebook has prepared for the 2019 uk general\nelection - about facebook. https://about.fb.com/news/2019/11/\nhow-facebook-is-prepared-for-the-2019-uk-general-election/ , 2019. (Ac-\ncessed on 09/11/2020).\n[133]Don Fallis. What is disinformation? Library trends , 63(3):401\u2013426, 2015.\n[134]Haiyan Fan and Marshall Scott Poole. What is personalization? perspectives on\nthe design and implementation of personalization in information systems. Journal of\nOrganizational Computing and Electronic Commerce , 16(3-4):179\u2013202, 2006.\n[135]Leon Festinger. A theory of social comparison processes. Human relations , 7(2):117\u2013\n140, 1954.\n[136]Clayton Feustel, Shyamak Aggarwal, Bongshin Lee, and Lauren Wilcox. People like\nme: Designing for reflection on aggregate cohort data in personal informatics systems.\nProceedings of the ACM on Interactive, Mobile, W earable and Ubiquitous T echnologies ,\n2(3):1\u201321, 2018.\n[137]MorrisPFiorina, SamuelJAbrams, etal. Politicalpolarizationintheamericanpublic.\nANNUAL REVIEW OF POLITICAL SCIENCE-P ALO AL TO- , 11:563, 2008.\n[138]Luciano Floridi. Brave. net. world: the internet as a disinformation superhighway?\nThe Electronic Library , 14(6):509\u2013514, 1996.\n[139]B. J. Fogg. Prominence-interpretation theory: Explaining how people assess credibility\nonline. In CHI \u201903 Extended Abstracts on Human F actors in Computing Systems , CHI\nEA \u201903, pages 722\u2013723, New York, NY, USA, 2003. ACM. ISBN 1-58113-637-4. doi:\n10.1145/765891.765951. URL http://doi.acm.org/10.1145/765891.765951 .\n[140]Brian J Fogg. Prominence-interpretation theory: Explaining how people assess cred-\nibility online. In CHI\u201903 extended abstracts on human factors in computing systems ,\npages 722\u2013723. Citeseer, 2003.\n[141]O*NET OnLine National Center for O*NET Development. 27-3022.00 - reporters and\ncorrespondents. https://www.onetonline.org/link/details/27-3022.00 , 2020.\n(Accessed on 10/13/2020).\n[142]Joseph P Forgas. Affective influences on attitudes and judgments. 2003.\n[143]Jonathan Fox. The uncertain relationship between transparency and accountability.\nDevelopment in practice , 17(4-5):663\u2013671, 2007.\n[144]Batya Friedman. Value-sensitive design. interactions , 3(6):16\u201323, 1996.\n[145]Batya Friedman, Peter H Kahn, and Alan Borning. Value sensitive design and in-\nformation systems. The handbook of information and computer ethics , pages 69\u2013101,\n2008.\n[146]Maksym Gabielkov, Arthi Ramachandran, Augustin Chaintreau, and Arnaud Legout.\nSocial clicks: What and who gets read on twitter? In Proceedings of the 2016 ACM\nSIGMETRICS international conference on measurement and modeling of computer\nscience, pages 179\u2013192, 2016.\n[147]Johan Galtung and Mari Holmboe Ruge. The structure of foreign news: The presen-\ntation of the congo, cuba and cyprus crises in four norwegian newspapers. Journal of\npeace research , 2(1):64\u201390, 1965.\n[148]Oscar H Gandy, Katharina Kopp, Tanya Hands, Karen Frazer, and David Phillips.\nRace and risk: Factors affecting the framing of stories about inequality, discrimination,\nand just plain bad luck. The Public Opinion Quarterly , 61(1):158\u2013182, 1997.\n[149]Feng Gao. Design for reflection on health behavior change. In Proceedings of the 2012\nACM international conference on Intel ligent User Interfaces , pages379\u2013382, NewYork,\nNY, USA, 2012. Association for Computing Machinery.\n[150]Andrew Garbett, David Chatting, Gerard Wilkinson, Clement Lee, and Ahmed Khar-\nrufa. ThinkActive: Designing for Pseudonymous Activity T racking in the Classroom ,\npage 1\u201313. Association for Computing Machinery, New York, NY, USA, 2018. ISBN\n9781450356206. URL https://doi.org/10.1145/3173574.3173581 .\n[151]R Kelly Garrett. Echo chambers online?: Politically motivated selective exposure\namong internet news users. JCMC, 14(2):265\u2013285, 2009.\n[152]R Kelly Garrett and Brian E Weeks. The promise and peril of real-time corrections to\npolitical misperceptions. In Proc. CSCW , pages 1047\u20131058. ACM, 2013.\n[153]Susan E Gathercole. Short-term and working memory , volume 9. Psychology Press,\n2001.\n[154]William W Gaver. Technology affordances. In Proceedings of the SIGCHI conference\non Human factors in computing systems , pages 79\u201384, 1991.\n[155]William W Gaver. Situating action ii: Affordances for interaction: The social is\nmaterial for design. Ecological psychology , 8(2):111\u2013129, 1996.\n[156]Christine Geeng, Savanna Yee, and Franziska Roesner. Fake news on facebook and\ntwitter: Investigating how people (don\u2019t) investigate. In Proceedings of the 2020 CHI\nConference on Human F actors in Computing Systems , pages 1\u201314, 2020.\n[157]Brittany Gentile, Jean M Twenge, Elise C Freeman, and W Keith Campbell. The effect\nof social networking websites on positive self-views: An experimental investigation.\nComputers in human behavior , 28(5):1929\u20131933, 2012.\n[158]Dave Gershgorn. How spotify\u2019s algorithm knows exactly what you want\nto listen to | by dave gershgorn | onezero. https://onezero.medium.com/\nhow-spotifys-algorithm-knows-exactly-what-you-want-to-listen-to-4b6991462c5c ,\n2019. (Accessed on 09/09/2021).\n[159]Guiseppe Getto, Liza Potts, Michael J Salvo, and Kathie Gossett. Teaching ux: De-\nsigning programs to train the next generation of ux experts. In Proceedings of the 31st\nACM international conference on Design of communication , pages 65\u201370, 2013.\n[160]James J Gibson. 04-JJ Gibson-Ch8-Affordances. Chapter Eight The Theory of Affor-\ndances, pages 127\u2013136, 1986. ISSN 10725520.\n[161]James J Gibson. The ecological approach to visual perception: classic edition . Psy-\nchology press, 2014.\n[162]Eytan Gilboa and Uri Paz. Errors and corrections. The International Encyclopedia of\nJournalism Studies , pages 1\u20135, 2019.\n[163]Nabeel Gillani, Ann Yuan, Martin Saveski, Soroush Vosoughi, and Deb Roy. Me, my\necho chamber, and i: Introspection on social media polarization. The W eb Conference\n2018 - Proceedings of the W orld Wide W eb Conference, WWW 2018 , pages 823\u2013831,\n2018. doi: 10.1145/3178876.3186130.\n[164]Tarleton Gillespie. The relevance of algorithms. Media technologies: Essays on com-\nmunication, materiality, and society , 167(2014):167, 2014.\n[165]Jennifer Golbeck and Kenneth R Fleischmann. Trust in social q&a: the impact of\ntext and photo cues of expertise. Proceedings of the American Society for Information\nScience and T echnology , 47(1):1\u201310, 2010.\n[166]Emily Goligoski and Stephanie Ho. 25 ways community members can support your\nnewsroom - global investigative journalism network. https://gijn.org/2019/02/\n18/25-ways-community-members-can-support-your-newsroom/ , 2019. (Accessed\non 10/14/2020).\n[167]Google. How google news stories are selected - google news help. https://support.\ngoogle.com/googlenews/answer/9005749?hl=en , . (Accessed on 11/12/2021).\n[168]Google. Trending on youtube - youtube help. https://support.google.com/\nyoutube/answer/7239739?hl=en , . (Accessed on 09/09/2021).\n[169]Jeffrey Gottfried, Mason Walker, and Amy Mitchell. Americans are largely\nskeptical of the news media, but say there is room for confidence to im-\nprove | pew research center. https://www.journalism.org/2020/08/31/\namericans-are-largely-skeptical-of-the-news-media-but-say-there-is-room-for-confidence-to-improve/ ,\n2020. (Accessed on 03/25/2021).\n[170]Sten Govaerts, Katrien Verbert, Erik Duval, and Abelardo Pardo. The student activity\nmeter for awareness and self-reflection. In CHI\u201912 Extended Abstracts on Human\nF actors in Computing Systems , pages 869\u2013884. Association for Computing Machinery,\nNew York, NY, USA, 2012.\n[171]Anthony M. Grant, John Franklin, and Peter Langford. The self-reflection and insight\nscale: A new measure of private self-consciousness. Social Behavior and Personality ,\n30(8):821\u2013836, 2002. ISSN 03012212. doi: 10.2224/sbp.2002.30.8.821.\n[172]StephanGreeneandPhilipResnik. Morethanwords: Syntacticpackagingandimplicit\nsentiment. In Proceedings of human language technologies: The 2009 annual conference\nof the north american chapter of the association for computational linguistics , pages\n503\u2013511. Association for Computational Linguistics, 2009.\n[173]Catherine Grevet and Eric Gilbert. Piggyback prototyping: Using existing, large-scale\nsocial computing systems to prototype new ones. In Proc. CHI , pages 4047\u20134056.\nACM, 2015.\n[174]Andrea Grimes, Brian M Landry, and Rebecca E Grinter. Characteristics of shared\nhealth reflections in a local community. In Proceedings of the 2010 ACM conference\non Computer supported cooperative work , pages 435\u2013444, New York, NY, USA, 2010.\nAssociation for Computing Machinery.\n[175]Harmen P Groenhart and Jo LH Bardoel. Conceiving the transparency of journalism:\nMoving towards a new media accountability currency. Studies in Communication\nSciences, 12(1):6\u201311, 2012.\n[176]Jason Grotto. How do we verify anonymous sources?\n- propublica. https://www.propublica.org/article/\nask-propublica-illinois-vetting-anonymous-sources , 2018. (Accessed on\n10/14/2019).\n[177]Andrew Guess, Kevin Munger, Jonathan Nagler, and Joshua Tucker. How accurate\nare survey responses on social media and politics? Political Communication , 36(2):\n241\u2013258, 2019.\n[178]Andrew M Guess, Michael Lerner, Benjamin Lyons, Jacob M Montgomery, Brendan\nNyhan, Jason Reifler, and Neelanjan Sircar. A digital media literacy intervention\nincreases discernment between mainstream and false news in the united states and\nindia. Proceedings of the National Academy of Sciences , 117(27):15536\u201315545, 2020.\n[179]Siddharth Gulati, Sonia Sousa, and David Lamas. Modelling trust: An empirical as-\nsessment. In IFIP Conference on Human-Computer Interaction , pages 40\u201361.Springer,\n2017.\n[180]Asela Gunawardana and Guy Shani. Evaluating Recommender Systems , pages 265\u2013\n308. Springer US, Boston, MA, 2015. ISBN 978-1-4899-7637-6. doi: 10.1007/\n978-1-4899-7637-6_8. URL https://doi.org/10.1007/978-1-4899-7637-6_8 .\n[181]Aditi Gupta, Ponnurangam Kumaraguru, Carlos Castillo, and Patrick Meier. Tweet-\ncred: Real-time credibility assessment of content on twitter. In International Confer-\nence on Social Informatics , pages 228\u2013243. Springer, 2014.\n[182]David Halpern. Inside the nudge unit: How smal l changes can make a big difference .\nRandom House, 2016.\n[183]Kirsi Halttu and Harri Oinas-kukkonen. Human \u2013 Computer Interaction Persuading\nto Reflect : Role of Reflection and Insight in Persuasive Systems Design for Physical\nHealth Persuading to Reflect : Role of Reflection and Insight in Persuasive Systems\nDesign for Physical Health. Human\u2013Computer Interaction , 32(5-6):381\u2013412, 2017.\nISSN 0737-0024. doi: 10.1080/07370024.2017.1283227. URL https://doi.org/10.\n1080/07370024.2017.1283227 .\n[184]Felix Hamborg, Karsten Donnay, and Bela Gipp. Automated identification of media\nbias in news articles: an interdisciplinary literature review. International Journal on\nDigital Libraries , 20(4):391\u2013415, 2019. ISSN 14321300.\n[185]Pelle G Hansen, Vincent F Hendricks, and Rasmus K Rendsvig. Infostorms. Metaphi-\nlosophy, 44(3):301\u2013326, 2013.\n[186]Pelle Guldborg Hansen and Andreas Maal\u00f8e Jespersen. Nudge and the manipulation\nof choice: A framework for the responsible use of the nudge approach to behaviour\nchange in public policy. European Journal of Risk Regulation , 4(1):3\u201328, 2013.\n[187]Karen Hao. He got facebook hooked on ai. now he can\u2019t fix its misinforma-\ntion addiction | mit technology review. https://www.technologyreview.com/2021/\n03/11/1020600/facebook-responsible-ai-misinformation/ , 2021. (Accessed on\n04/05/2021).\n[188]Tony Harcup and Deirdre O\u2019neill. What is news? news values revisited (again). Jour-\nnalism studies , 18(12):1470\u20131488, 2017.\n[189]Tim Harrower. Inside Reporting: A Practical Guide to the Craft of Journalism (2012) .\n2007.\n[190]William Hart, Dolores Albarrac\u00edn, Alice H Eagly, Inge Brechan, Matthew J Lindberg,\nand Lisa Merrill. Feeling validated versus being correct: a meta-analysis of selective\nexposure to information. Psychological bul letin , 135(4):555, 2009.\n[191]H. Rex Hartson. Cognitive, physical, sensory, and functional affordances in interaction\ndesign. Behaviour and Information T echnology , 22(5):315\u2013338, 2003. ISSN 0144929X.\ndoi: 10.1080/01449290310001592587.\n[192]Del Harvey. Helping you find reliable public health information on\ntwitter. https://blog.twitter.com/en_us/topics/company/2019/\nhelping-you-find-reliable-public-health-information-on-twitter.html ,\n2019. (Accessed on 09/11/2020).\n[193]Del Harvey and David Gasca. Serving healthy conversation. https:\n//blog.twitter.com/official/en_us/topics/product/2018/Serving_Healthy_\nConversation.html , 2018. (Accessed on 09/11/2020).\n[194]Naeemul Hassan, Mohammad Yousuf, Mahfuzul Haque, Javier A Suarez Rivas, and\nMd Khadimul Islam. Towards a sustainable model for fact-checking platforms:\nExamining the roles of automation, crowds and professionals. Jan 2017. doi:\n10.1145/3308560.3316734.\n[195]Arthur S Hayes, Jane B Singer, and Jerry Ceppos. Shifting roles, enduring values: The\ncredible journalist in a digital age. Journal of mass media ethics , 22(4):262\u2013279, 2007.\n[196]DonaldHedeker, StephenHCduToit, HakanDemirtas, andRobertDGibbons. Anote\non marginalization of regression parameters from mixed models of binary outcomes.\nBiometrics , 74(1):354\u2013361, 2018.\n[197]MS Heen, Joel D Lieberman, and Terance D Miethe. A comparison of different online\nsampling approaches for generating national samples. Center for Crime and Justice\nPolicy, 1(9):1\u20138, 2014.\n[198]John Hegeman. Facing facts: Facebook\u2019s fight against misinfor-\nmation - about facebook. https://about.fb.com/news/2018/05/\nfacing-facts-facebooks-fight-against-misinformation/ , 2018. (Accessed\non 09/11/2020).\n[199]Edward S Herman and Noam Chomsky. Manufacturing consent: The political economy\nof the mass media . Random House, 2010.\n[200]Yoshinori Hijikata, Takuya Shimizu, and Shogo Nishida. Discovery-oriented collabo-\nrative filtering for improving user satisfaction. In Proceedings of the 14th international\nconference on Intel ligent user interfaces , pages 67\u201376, New York, NY, USA, 2009.\nAssociation for Computing Machinery.\n[201]Janette R. Hill, Liyan Song, and Richard E. West. Social learning theory and web-\nbased learning environments: A review of research and discussion of implications.\nInternational Journal of Phytoremediation , 21(1):88\u2013103, 2009. ISSN 15497879.\n[202]Michael A Horning, Harold R Robinson, and John M Carroll. A scenario-based ap-\nproach for projecting user requirements for wireless proximal community networks.\nComputers in Human Behavior , 35:413\u2013422, 2014.\n[203]Lei Hou, Juanzi Li, Zhichun Wang, Jie Tang, Peng Zhang, Ruibing Yang, and Qian\nZheng. Newsminer: Multifaceted news analysis for event search. Knowledge-Based\nSystems, 76:17\u201329, 2015.\n[204]Daniel J Howard and Thomas E Barry. The role of thematic congruence between a\nmood-inducing event and an advertised product in determining the effects of mood on\nbrand attitudes. Journal of Consumer Psychology , 3(1):1\u201327, 1994.\n[205]Christoph Hube, Besnik Fetahu, and Ujwal Gadiraju. Understanding and mitigating\nworker biases in the crowdsourced collection of subjective judgments. In Proceedings\nof the 2019 CHI Conference on Human F actors in Computing Systems , pages 1\u201312,\n2019.\n[206]Travonia B Hughes, Vijay R Varma, Corinne Pettigrew, and Marilyn S Albert. African\namericans and clinical research: evidence concerning barriers and facilitators to par-\nticipation and recruitment recommendations. The Gerontologist , 57(2):348\u2013358, 2017.\n[207]Jane Im, Sonali Tandon, Eshwar Chandrasekharan, Taylor Denby, and Eric Gilbert.\nSynthesized social signals: Computationally-derived social signals from account his-\ntories. In Proceedings of the 2020 CHI Conference on Human F actors in Computing\nSystems, pages 1\u201312, 2020.\n[208]Twitter Inc. The twitter rules. https://help.twitter.com/en/\nrules-and-policies/twitter-rules , 2019. (Accessed on 09/13/2019).\n[209]Reuters Institute. Overview and key findings of the 2022 digital news report | reuters\ninstitute for the study of journalism. https://reutersinstitute.politics.ox.\nac.uk/digital-news-report/2022/dnr-executive-summary , 2022. (Accessed on\n09/11/2022).\n[210]Caroline Jack. Lexicon of lies: Terms for problematic information. 2017.\n[211]Kathleen Hall Jamieson and Joseph N Cappella. Echo chamber: Rush Limbaugh and\nthe conservative media establishment . Oxford University Press, 2008.\n[212]Peter John, Graham Smith, and Gerry Stoker. Nudge nudge, think think: two strate-\ngies for changing civic behaviour. The Political Quarterly , 80(3):361\u2013370, 2009.\n[213]Hollyn M Johnson and Colleen M Seifert. Sources of the continued influence effect:\nWhen misinformation in memory affects later inferences. J. Exp. Psychol. Learn. Mem.\nCogn., 20(6):1420, 1994.\n[214]Andrew Johnston, Shigeki Amitani, and Ernest Edmonds. Amplifying reflective think-\ning in musical performance. In Proceedings of the 5th conference on Creativity &\ncognition , pages 166\u2013175, New York, NY, USA, 2005. Association for Computing Ma-\nchinery.\n[215]Mark Jurkowitz, Amy Mitchell, Elisa Shearer, and Mason Walker.\nU.s. media polarization and the 2020 election: A nation divided\n| pew research center. https://www.journalism.org/2020/01/24/\nu-s-media-polarization-and-the-2020-election-a-nation-divided/ , 2020.\n(Accessed on 04/14/2021).\n[216]Mark Jurkowitz, Amy Mitchell, Elisa Shearer, and Mason Walker. U.s.\nmedia polarization and the 2020 election: A nation divided | pew re-\nsearch center. https://www.pewresearch.org/journalism/2020/01/24/\nu-s-media-polarization-and-the-2020-election-a-nation-divided/ , 2020.\n(Accessed on 09/15/2022).\n[217]Daniel Kahneman and Amos Tversky. Choices, values, and frames. In Handbook of the\nfundamentals of financial decision making: Part I , pages 269\u2013278. World Scientific,\n2013.\n[218]Shipi Kankane, Carlina DiRusso, and Christen Buckley. Can we nudge users toward\nbetter password management?: An initial study. In Extended Abstracts of the 2018\nCHI Conference on Human F actors in Computing Systems , pageLBW593.ACM,2018.\n[219]Victor Kaptelinin and Bonnie Nardi. Affordances in HCI: Toward a mediated action\nperspective. Conference on Human F actors in Computing Systems - Proceedings , pages\n967\u2013976, 2012. doi: 10.1145/2207676.2208541.\n[220]Michael Karlsson. Rituals of transparency: Evaluating online news outlets\u2019 uses of\ntransparency rituals in the united states, united kingdom and sweden. Journalism\nstudies, 11(4):535\u2013545, 2010.\n[221]Michael Karlsson. The immediacy of online news, the visibility of journalistic processes\nand a restructuring of journalistic authority. Journalism , 12(3):279\u2013295, 2011.\n[222]Michael Karlsson and Christer Clerwall. Transparency to the rescue? evaluating citi-\nzens\u2019 views on transparency tools in journalism. Journalism Studies , pages 1\u201311, 2018.\n[223]MichaelKarlsson, ChristerClerwall, andLarsNord. Youain\u2019tseennothingyet: Trans-\nparency\u2019s (lack of) effect on source and message credibility. Journalism Studies , 15(5):\n668\u2013678, 2014.\n[224]Michael Karlsson, Christer Clerwall, and Lars Nord. Do not stand corrected: Trans-\nparency and users\u2019 attitudes to inaccurate news and corrections in online journalism.\nJournalism & Mass Communication Quarterly , 94(1):148\u2013167, 2017.\n[225]Kenneth A Kavale. The reasoning abilities of normal and learning disabled readers on\nmeasures of reading comprehension. Learning Disability Quarterly , 3(4):34\u201345, 1980.\n[226]Ricardo Kawase, Eelco Herder, and Wolfgang Nejdl. A comparison of paper-based and\nonline annotations in the workplace. In European Conference on T echnology Enhanced\nLearning , pages 240\u2013253. Springer, 2009.\n[227]Keen. Keen | expand your interests. https://staykeen.com/about , 2021. (Accessed\non 09/07/2021).\n[228]Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh,\nDavid Corney, Benno Stein, and Martin Potthast. Semeval-2019 task 4: Hyperparti-\nsan news detection. In Proceedings of the 13th International W orkshop on Semantic\nEvaluation , pages 829\u2013839, 2019.\n[229]Damon Kiesow, Shuhua Zhou, and Lei Guo. Affordances for Sense-Making: Exploring\nTheir Availability for Users of Online News Sites. Digital Journalism , 0(0):1\u201320, 2021.\ndoi: 10.1080/21670811.2021.1989316. URL https://doi.org/10.1080/21670811.\n2021.1989316 .\n[230]Spiro Kiousis. Public trust or mistrust? perceptions of media credibility in the infor-\nmation age. Mass communication & society , 4(4):381\u2013403, 2001.\n[231]Joel Kiskola, Thomas Olsson, Heli V\u00e4\u00e4t\u00e4j\u00e4, Aleksi H. Syrj\u00e4m\u00e4ki, Anna Rantasila,\nPoika Isokoski, Mirja Ilves, and Veikko Surakka. Applying Critical V oice in Design of\nUser Interfaces for Supporting Self-Reflection and Emotion Regulation in Online News\nCommenting . Association for Computing Machinery, New York, NY, USA, 2021. ISBN\n9781450380966. URL https://doi.org/10.1145/3411764.3445783 .\n[232]Aniket Kittur, Ed H Chi, and Bongwon Suh. Crowdsourcing user studies with mechan-\nical turk. In Proceedings of the SIGCHI conference on human factors in computing\nsystems, pages 453\u2013456, 2008.\n[233]Aniket Kittur, Boris Smus, Susheel Khamkar, and Robert E Kraut. Crowdforge:\nCrowdsourcing complex work. In Proceedings of the 24th annual ACM symposium on\nUser interface software and technology , pages 43\u201352, 2011.\n[234]JoshuaKlayman. Varietiesofconfirmationbias. Psychology of learning and motivation ,\n32:385\u2013418, 1995.\n[235]Cory Knobel and Geoffrey C Bowker. Values in design. Communications of the ACM ,\n54(7):26\u201328, 2011.\n[236]Silvia Knobloch-Westerwick and Jingbo Meng. Looking the other way: Selective ex-\nposure to attitude-consistent and counterattitudinal political information. Communi-\ncation Research , 36(3):426\u2013448, 2009.\n[237]Silvia Knobloch-Westerwick, Nikhil Sharma, Derek L Hansen, and Scott Alter. Impact\nof popularity indications on readers\u2019 selective exposure to online news. J. Broadcast.\nElectron. Media , 49(3):296\u2013313, 2005.\n[238]Bran Knowles, Mark Rouncefield, Mike Harding, Nigel Davies, Lynne Blair, James\nHannon, John Walden, and Ding Wang. Models and patterns of trust. In Proceed-\nings of the 18th ACM Conference on Computer Supported Cooperative W ork & Social\nComputing , pages 328\u2013338, 2015.\n[239]D. Koehler and N. Harvey. In D. Koehler & N. Harvey (Eds.). (2004). Blackwell\nhandbook of judgment and decision making (pp. 62\u201388). Oxford, UK: Blackwell. pages\n62\u201388, 2004.\n[240]Sarah Koenig. Season one - serial. https://serialpodcast.org/season-one , 2014.\n(Accessed on 09/29/2019).\n[241]Andrew Kohut, Carroll Doherty, Michael Dimock, and Scott Keeter. Cable leads\nthe pack as campaign news source. Pew Center for the People and the Press.\nRetrieved from https://www.pewresearch.org/wp-content/uploads/sites/4/legacy-\npdf/2012-Communicating-Release.pdf , 2012.\n[242]Kalliopi Kontiza, Olga Loboda, Louis Deladiennee, Sylvain Castagnos, and Yannick\nNaudet. A museum app to trigger users\u2019 reflection. In International W orkshop on\nMobile Access to Cultural Heritage (MobileCH2018) , Barcelona, Spain, 2018.\n[243]Malcolm Koo and Harvey Skinner. Challenges of internet recruitment: a case study\nwith disappointing results. Journal of Medical Internet Research , 7(1):e6, 2005.\n[244]Elizabeth V Korinek, Sayali S Phatak, Cesar A Martin, Mohammad T Freigoun,\nDaniel E Rivera, Marc A Adams, Pedja Klasnja, Matthew P Buman, and Eric B\nHekler. Adaptive step goals and rewards: a longitudinal growth model of daily steps\nfor a smartphone-based walking intervention. Journal of behavioral medicine , 41(1):\n74\u201386, 2018.\n[245]Bill Kovach and Tom Rosenstiel. Blur: How to know what\u2019s true in the age of infor-\nmation overload . Bloomsbury Publishing USA, 2011.\n[246]Bill Kovach and Tom Rosenstiel. The elements of journalism: What newspeople should\nknow and the public should expect . Three Rivers Press (CA), 2014.\n[247]Geza Kovacs, Zhengxuan Wu, and Michael S Bernstein. Not now, ask later: Users\nweaken their behavior change regimen over time, but expect to re-strengthen it immi-\nnently. arXiv preprint arXiv:2101.11743 , 2021.\n[248]Steven Kull, Clay Ramsay, and Evan Lewis. Misperceptions, the media, and the iraq\nwar. Political science quarterly , 118(4):569\u2013598, 2003.\n[249]Srijan Kumar, Robert West, and Jure Leskovec. Disinformation on the web: Impact,\ncharacteristics, and detection of wikipedia hoaxes. In Proceedings of the 25th interna-\ntional conference on W orld Wide W eb , pages 591\u2013602, 2016.\n[250]Jim A. Kuypers. Press Bias and Politics: How the Media F rame Controversial Is-\nsues. Greenwood Publishing Group, 2002. ISBN 978-0-275-97758-0. Google-Books-ID:\nGHIQimmDvbcC.\n[251]Jim A. Kuypers. Issues of Bias in the News Media , page 127\u2013154. Peter Lang, 2013.\nISBN 1-4331-2094-1.\n[252]MIT Media Lab. Overview \u2039 flipfeed \u2014 mit media lab. https://www.media.mit.\nedu/projects/flipfeed/overview/ , 2017. (Accessed on 08/31/2021).\n[253]KK Lamberty and Janet L Kolodner. Camera talk: Making the camera a partial\nparticipant. In Proceedings of the SIGCHI Conference on Human F actors in Comput-\ning Systems , pages 839\u2013848, New York, NY, USA, 2005. Association for Computing\nMachinery.\n[254]Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami,\nand Chris Dyer. Neural architectures for named entity recognition. arXiv preprint\narXiv:1603.01360 , 2016.\n[255]Issie Lapowski. Newsguard wants to fight fake news with humans, not algorithms,\n2018.\n[256]Joseph D Lasica. Transparency begets trust in the ever-expanding blogosphere. Online\nJournalism Review , 12, 2004.\n[257]Neal Lathia, Stephen Hailes, Licia Capra, and Xavier Amatriain. Temporal diversity in\nrecommender systems. In Proceedings of the 33rd international ACM SIGIR conference\non Research and development in information retrieval , pages 210\u2013217, New York, NY,\nUSA, 2010. Association for Computing Machinery.\n[258]Paul F Lazarsfeld, Bernard Berelson, and Hazel Gaudet. The people\u2019s choice. In The\npeople\u2019s choice . Columbia University Press, 1968.\n[259]David G Lebow and Dale W Lick. Hylighter: An effective interactive annotation\ninnovation for distance education. In 20th Annual Conference on Distance T eaching\nand Learning , pages 1\u20135, 2005.\n[260]Kenton Lee, Luheng He, Mike Lewis, and Luke Zettlemoyer. End-to-end neural coref-\nerence resolution. arXiv preprint arXiv:1707.07045 , 2017.\n[261]Matthew L Lee and Anind K Dey. Reflecting on pills and phone use: supporting\nawareness of functional abilities for older adults. In Proceedings of the SIGCHI Con-\nference on Human F actors in Computing Systems , pages 2095\u20132104, New York, NY,\nUSA, 2011. Association for Computing Machinery.\n[262]Min Kyung Lee, Sara Kiesler, and Jodi Forlizzi. Mining behavioral economics to design\npersuasive technology for healthy choices. In Proceedings of the SIGCHI Conference\non Human F actors in Computing Systems , pages 325\u2013334. ACM, 2011.\n[263]Birthe A Lehmann, Gretchen B Chapman, Frits ME Franssen, Gerjo Kok, and\nRobert AC Ruiter. Changing the default to promote influenza vaccination among\nhealth care workers. V accine, 34(11):1389\u20131392, 2016.\n[264]Ian Li, Anind Dey, and Jodi Forlizzi. Grafitter: leveraging social media for self reflec-\ntion. XRDS: Crossroads, The ACM Magazine for Students , 16(2):12\u201313, 2009.\n[265]Ian Li, Anind Dey, and Jodi Forlizzi. A stage-based model of personal informatics\nsystems. In Proceedings of the SIGCHI conference on human factors in computing\nsystems, pages 557\u2013566, New York, NY, USA, 2010. Association for Computing Ma-\nchinery.\n[266]Ian Li, Anind K Dey, and Jodi Forlizzi. Understanding my data, myself: support-\ning self-reflection with ubicomp technologies. In Proceedings of the 13th international\nconference on Ubiquitous computing , pages 405\u2013414, New York, NY, USA, 2011. As-\nsociation for Computing Machinery.\n[267]JuanziLi, JunLi, andJieTang. Aflexibletopic-drivenframeworkfornewsexploration.\nIn Proceedings of KDD , volume 2007, 2007.\n[268]Matthew D Lieberman. Social cognitive neuroscience: a review of core processes.\nAnnu. Rev. Psychol. , 58:259\u2013289, 2007.\n[269]Yehiel Limor and Rafi Mann. Journalism: Reporting, writing and editing. T el Aviv:\nOpen University Press (in Hebrew) , 1997.\n[270]James J Lin, Lena Mamykina, Silvia Lindtner, Gregory Delajoux, and Henry B Strub.\nFish\u2019n\u2019steps: Encouraging physical activity with an interactive computer game. In\nInternational conference on ubiquitous computing , pages 261\u2013278, Berlin, Heidelberg,\n2006. Springer, Springer Berlin Heidelberg.\n[271]Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and Alexander Hauptmann. Which\nside are you on?: identifying perspectives at the document and sentence levels. In\nProceedings of the tenth conference on computational natural language learning , pages\n109\u2013116. Association for Computational Linguistics, 2006.\n[272]Jordan Litman, Tiffany Hutchins, and Ryan Russon. Epistemic curiosity, feeling-of-\nknowing, and exploratory behaviour. Cognition & Emotion , 19(4):559\u2013582, 2005.\n[273]Elizabeth Lopatto. In its latest confusing decision, twitter reinstates the\nnew york post - the verge. https://www.theverge.com/2020/10/30/21542801/\ntwitter-lifts-ny-post-ban-policy-changes , 2020. (Accessed on 04/05/2021).\n[274]Charles G Lord, Mark R Lepper, and Elizabeth Preston. Considering the opposite: a\ncorrective strategy for social judgment. Journal of personality and social psychology ,\n47(6):1231, 1984.\n[275]TamariLukava,DafneZuleimaMorgadoRamirez,andGiuliaBarbareschi. Twosidesof\nthe same coin: accessibility practices and neurodivergent users\u2019 experience of extended\nreality. Journal of Enabling T echnologies , 16(2):75\u201390, 2022.\n[276]Tessa Lyons. Replacing disputed flags with related arti-\ncles - about facebook. https://about.fb.com/news/2017/12/\nnews-feed-fyi-updates-in-our-fight-against-misinformation/ , 2017. (Ac-\ncessed on 09/11/2020).\n[277]Tessa Lyons. Hard questions: How is facebook\u2019s fact-checking program\nworking? - about facebook. https://about.fb.com/news/2018/06/\nhard-questions-fact-checking/ , 2018. (Accessed on 09/11/2020).\n[278]Diane M Mackie and Sarah Queller. The impact of group membership on persuasion:\nRevisiting \u201cwho says what to whom with what effect?\u201d. Attitudes, behavior, and social\ncontext: The role of norms and group membership , pages 135\u2013155, 2000.\n[279]Rakoen Maertens, Jon Roozenbeek, Melisa Basol, and Sander van der Linden. Long-\nterm effectiveness of inoculation against misinformation: Three longitudinal experi-\nments. Journal of Experimental Psychology: Applied , 2020.\n[280]Jonathan RA Maier and Georges M Fadel. Affordance-based methods for design. In\nInternational Design Engineering T echnical Conferences and Computers and Informa-\ntion in Engineering Conference , volume 37017, pages 785\u2013794, 2003.\n[281]Scott R Maier. Setting the record straight: When the press errs, do corrections follow?\nJournalism Practice , 1(1):33\u201343, 2007.\n[282]Adam Maksl, Seth Ashley, and Stephanie Craft. Measuring news media literacy. Jour-\nnal of Media Literacy Education , 6(3):29\u201345, 2015.\n[283]Sylvain Malacria, Joey Scarr, Andy Cockburn, Carl Gutwin, and Tovi Grossman.\nSkillometers: Reflective widgets that motivate and help users to improve performance.\nIn Proceedings of the 26th annual ACM symposium on User interface software and\ntechnology , pages 321\u2013330, New York, NY, USA, 2013. Association for Computing\nMachinery.\n[284]Ross A Malaga. Worst practices in search engine optimization. Communications of\nthe ACM , 51(12):147\u2013150, 2008.\n[285]Giada Marino and Laura Iannelli. Seven years of studying the associations between\npolitical polarization and problematic information: a literature review. F rontiers in\nSociology , 8:91, 2023.\n[286]Zlatina Marinova, Jochen Spangenberg, Denis Teyssou, Symeon Papadopoulos, Nikos\nSarris, Alexandre Alaphilippe, and Kalina Bontcheva. Weverify: Wider and enhanced\nverification for you project overview and tools. In 2020 IEEE International Conference\non Multimedia & Expo W orkshops (ICMEW) , pages 1\u20134. IEEE, 2020.\n[287]Renee Martin-Kratzer and Esther Thorson. Use of anonymous sources declines in us\nnewspapers. Newspaper Research Journal , 28(2):56\u201370, 2007.\n[288]Nafiseh Masoudi, Georges M Fadel, Christopher C Pagano, and Maria Vittoria Elena.\nAreviewofaffordancesandaffordance-baseddesigntoaddressusability. In Proceedings\nof the Design Society: International Conference on Engineering Design , volume 1,\npages 1353\u20131362. Cambridge University Press, 2019.\n[289]Kelly McBride and Tom Rosenstiel. The new ethics of journalism: Principles for the\n21st century . CQ Press, 2013.\n[290]Robert D McChesney. The problem of the media: US communication politics in the\ntwenty-first century . NYU Press, 2004.\n[291]Maxwell E McCombs and Donald L Shaw. The agenda-setting function of mass media.\nPublic opinion quarterly , 36(2):176\u2013187, 1972.\n[292]Nora McDonald, Sarita Schoenebeck, and Andrea Forte. Reliability and inter-rater\nreliability in qualitative research: Norms and guidelines for cscw and hci practice.\nProceedings of the ACM on Human-Computer Interaction , 3(CSCW):1\u201323, 2019.\n[293]Joanna McGrenere and Wayne Ho. Affordances: Clarifying and evolving a concept.\nIn Graphics interface , volume 2000, pages 179\u2013186, 2000.\n[294]Sean M McNee, John Riedl, and Joseph A Konstan. Being accurate is not enough:\nhow accuracy metrics have hurt recommender systems. In CHI\u201906 extended abstracts\non Human factors in computing systems , pages 1097\u20131101, New York, NY, USA, 2006.\nAssociation for Computing Machinery.\n[295]Mediabiasfactcheck. About - media bias/fact check. https://mediabiasfactcheck.\ncom/about/ , 2019. (Accessed on 09/18/2019).\n[296]Ania Medrek. NEWS BY ASSOCIATION: Designing a way out of the echo chamber.\n(April), 2018.\n[297]Melvin Mencher and Wendy P Shilton. News reporting and writing . Brown & Bench-\nmark Publishers, 1997.\n[298]Solomon Messing and Sean J Westwood. Selective exposure in the age of social media:\nEndorsements trump partisan source affiliation when selecting news online. Commu-\nnication research , 41(8):1042\u20131063, 2014.\n[299]Miriam J Metzger. Making sense of credibility on the web: Models for evaluating\nonline information and recommendations for future research. Journal of the American\nSociety for Information Science and T echnology , 58(13):2078\u20132091, 2007.\n[300]Miriam J Metzger, Andrew J Flanagin, and Ryan B Medders. Social and heuristic\napproaches to credibility evaluation online. Journal of communication , 60(3):413\u2013439,\n2010.\n[301]Miriam J Metzger, Ethan H Hartsell, and Andrew J Flanagin. Cognitive dissonance\nor credibility? a comparison of two theoretical explanations for selective exposure to\npartisan news. Communication Research , page 0093650215613136, 2015.\n[302]Hans K Meyer, Doreen Marchionni, and Esther Thorson. The journalist behind the\nnews: credibility of straight, collaborative, opinionated, and blogged \u201cnew\u201d. American\nBehavioral Scientist , 54(2):100\u2013119, 2010.\n[303]Philip Meyer. Defining and measuring credibility of newspapers: Developing an index.\nJournalism quarterly , 65(3):567\u2013574, 1988.\n[304]Susan Michie, Michelle Richardson, Marie Johnston, Charles Abraham, Jill Francis,\nWendy Hardeman, Martin P Eccles, James Cane, and Caroline E Wood. The behavior\nchange technique taxonomy (v1) of 93 hierarchically clustered techniques: building an\ninternational consensus for the reporting of behavior change interventions. Annals of\nbehavioral medicine , 46(1):81\u201395, 2013.\n[305]Amy Mitchell, Jeffrey Gottfried, Jocelyn Kiley, and Katerina Eva Matsa. Political\npolarization & media habits. Pew Research Center , 21, 2014.\n[306]Amy Mitchell, Jeffrey Gottfried, Michael Barthel, and Nami Sum-\nida. Can americans tell factual from opinion statements in the news?\n| pew research center. https://www.journalism.org/2018/06/18/\ndistinguishing-between-factual-and-opinion-statements-in-the-news/ ,\n2018. (Accessed on 01/23/2020).\n[307]Tanushree Mitra and Eric Gilbert. Credbank: A large-scale social media corpus with\nassociated credibility annotations. In Proc. ICWSM\u201915 , 2015.\n[308]Tanushree Mitra, Clayton J Hutto, and Eric Gilbert. Comparing person-and process-\ncentric strategies for obtaining quality data on amazon mechanical turk. In Proceedings\nof the 33rd Annual ACM Conference on Human F actors in Computing Systems , pages\n1345\u20131354, 2015.\n[309]Tanushree Mitra, Graham P Wright, and Eric Gilbert. A parsimonious language model\nof social media credibility across disparate events. In Proc. CSCW , pages 126\u2013145.\nACM, 2017.\n[310]Ine Mols, Elise van den Hoven, and Berry Eggen. Informing design for reflection: An\noverview of current everyday practices. In Proceedings of the 9th Nordic Conference on\nHuman-Computer Interaction , NordiCHI \u201916, New York, NY, USA, 2016. Association\nfor Computing Machinery. ISBN 9781450347631. doi: 10.1145/2971485.2971494. URL\nhttps://doi.org/10.1145/2971485.2971494 .\n[311]NivMorandZviReich. From\u201ctrustme\u201dto\u201cshowme\u201djournalism: Candocumentcloud\nhelp to restore the deteriorating credibility of news? Journalism Practice , 12(9):1091\u2013\n1108, 2018.\n[312]Adam Mosseri. Addressing hoaxes and fake news - about facebook. https://about.\nfb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake-news/ ,\n2016. (Accessed on 09/11/2020).\n[313]Sendhil Mullainathan and Andrei Shleifer. Media bias, 2002.\n[314]Sean A Munson and Paul Resnick. Presenting diverse political opinions: how and\nhow much. In Proceedings of the SIGCHI conference on human factors in computing\nsystems, pages 1457\u20131466, 2010.\n[315]Sean A Munson, Hasan Cavusoglu, Larry Frisch, and Sidney Fels. Sociotechnical\nchallenges and progress in using social media for health. Journal of medical Internet\nresearch, 15(10):e226, 2013.\n[316]Rosanna Nagtegaal, Lars Tummers, Mirko Noordegraaf, and Victor Bekkers. De-\nsigning to debias: Measuring and reducing public managers\u2019 anchoring bias. Public\nAdministration Review , 80(4):565\u2013576, 2020.\n[317]Joseph Napolitan. The election game and how to win it . Doubleday, 1972.\n[318]Arvind Narayanan and Vitaly Shmatikov. Robust de-anonymization of large sparse\ndatasets. In 2008 IEEE Symposium on Security and Privacy (sp 2008) , pages 111\u2013125.\nIEEE, 2008.\n[319]Elmie Nekmat. Nudge effect of fact-check alerts: Source influence and media skepti-\ncism on sharing of news misinformation in social media. Social Media+ Society , 6(1):\n2056305119897322, 2020.\n[320]Neil Nemeth and Craig Sanders. Number of corrections increase at two national news-\npapers. Newspaper Research Journal , 30(3):90\u2013104, 2009.\n[321]First Draft News. Research on crosscheck journalists and readers sug-\ngests positive impact for project. https://firstdraftnews.org/latest/\ncrosscheck-qualitative-research/ , 2017. (Accessed on 01/22/2020).\n[322]NJ Spotlight News. Funders | nj spotlight news. https://www.njspotlight.com/\nabout/funders/ , 2020. (Accessed on 10/11/2020).\n[323]Raymond S Nickerson. Confirmation bias: A ubiquitous phenomenon in many guises.\nReview of general psychology , 2(2):175\u2013220, 1998.\n[324]Jasmin Niess and Pawe\u0142 W Wo\u017aniak. Supporting meaningful personal fitness: The\ntracker goal evolution model. In Proceedings of the 2018 CHI Conference on Human\nF actors in Computing Systems , pages 1\u201312, New York, NY, USA, 2018. Association\nfor Computing Machinery.\n[325]Matthew C Nisbet, Dietram A Scheufele, James Shanahan, Patricia Moy, Dominique\nBrossard, and Bruce V Lewenstein. Knowledge, reservations, or promise? a media ef-\nfects model for public perceptions of science and technology. Communication Research ,\n29(5):584\u2013608, 2002.\n[326]Brian Keith Norambuena, Michael Horning, and Tanushree Mitra. Evaluating the\ninverted pyramid structure through automatic 5w1h extraction and summarization. In\nProc. of the 2020 Computation+ Journalism Symposium. Computation+ Journalism ,\npages 1\u20137, 2020.\n[327]Dan Norman. Signifiers, not affordances. 15(6):1\u201323, 2016.\n[328]Don Norman. Affordances and design. Unpublished article, available online at:\nhttp://www. jnd. org/dn. mss/affordances-and-design. html , 2004.\n[329]Don Norman. The design of everyday things: Revised and expanded edition . Basic\nbooks, 2013.\n[330]Donald A Norman. The psychology of everyday things. Basic books, 1988.\n[331]Donald A Norman. Affordance, conventions, and design. interactions , 6(3):38\u201343,\n1999.\n[332]Elena Novak, Rim Razzouk, and Tristan E. Johnson. The educational use of social an-\nnotation tools in higher education: A literature review. Internet and Higher Education ,\n15(1):39\u201349, 2012. ISSN 10967516. doi: 10.1016/j.iheduc.2011.09.002.\n[333]Alexander Nussbaumer, Milos Kravcik, and Dietrich Albert. Supporting self-reflection\nin personal learning environments through user feedback. In UMAP W orkshops , 2012.\n[334]AdewaleObadimu, EstherMead, MuhammadNihalHussain, andNitinAgarwal. Iden-\ntifying toxicity within youtube video comment. In International Conference on Social\nComputing, Behavioral-Cultural Modeling and Prediction and Behavior Representation\nin Modeling and Simulation , pages 214\u2013223. Springer, 2019.\n[335]Onora O\u2019neill. A question of trust: The BBC Reith Lectures 2002 . Cambridge Uni-\nversity Press, 2002.\n[336]Ruchi Ookalkar, Kolli Vishal Reddy, and Eric Gilbert. Pop: Bursting news filter\nbubbles on twiter through diverse exposure. Proceedings of the ACM Conference on\nComputer Supported Cooperative W ork, CSCW , pages 18\u201321, 2019. doi: 10.1145/\n3311957.3359513.\n[337]Ruchi Ookalkar, Kolli Vishal Reddy, and Eric Gilbert. Pop: Bursting news filter\nbubbles on twitter through diverse exposure. In Conference Companion Publication\nof the 2019 on Computer Supported Cooperative W ork and Social Computing , pages\n18\u201322, 2019.\n[338]OpenSources. Opensources. http://opensources.co, 2018.\n[339]Cian O\u2019Mahony, Maryanne Brassil, Gillian Murphy, and Conor Linehan. The efficacy\nof interventions in reducing belief in conspiracy theories: A systematic review. Plos\none, 18(4):e0280902, 2023.\n[340]Nirzar Pangarkar. How we designed page previews for wikipedia and what could\nbe done with them in the future \u2013 wikimedia blog. https://blog.wikimedia.org/\n2018/04/18/how-we-designed-page-previews-for-wikipedia/ , 2018. (Accessed\non 10/15/2019).\n[341]Eli Pariser. The filter bubble: How the new personalized web is changing what we read\nand how we think . Penguin, 2011.\n[342]Souneil Park, Seungwoo Kang, Sangyoung Chung, and Junehwa Song. Newscube:\ndelivering multiple aspects of news to mitigate media bias. In Proceedings of the\nSIGCHI conference on human factors in computing systems , pages 443\u2013452, 2009.\n[343]Souneil Park, Minsam Ko, Jungwoo Kim, Ho-jin Choi, and Junehwa Song. NewsCube2\n. 0 : An Exploratory Design of a Social News Website for Media Bias Mitigation.\nW orkshop on Social Recommender Systems , pages 1\u20135, 2011. URL https://pdfs.\nsemanticscholar.org/b87b/f0986b2e9fe34a22ed0c19cfd32ed06857d0.pdf .\n[344]SouneilPark, KyungSoonLee, andJunehwaSong. Contrastingopposingviewsofnews\narticles on contentious issues. ACL-HL T 2011 - Proceedings of the 49th Annual Meeting\nof the Association for Computational Linguistics: Human Language T echnologies , 1:\n340\u2013349, 2011.\n[345]Souneil Park, Seungwoo Kang, Sangyoung Chung, and Junehwa Song. A computa-\ntional framework for media bias mitigation. ACM T ransactions on Interactive Intel li-\ngent Systems , 2(2), 2012. ISSN 21606463. doi: 10.1145/2209310.2209311.\n[346]Sara Parker and Derek Ruths. Is hate speech detection the solution the world wants?\nProceedings of the National Academy of Sciences , 120(10):e2209384120, 2023.\n[347]John W Payne, James R Bettman, and Eric J Johnson. The adaptive decision maker .\nCambridge university press, 1993.\n[348]Jessica Paynter, Sarah Luskin-Saxby, Deb Keen, Kathryn Fordyce, Grace Frost, Chris-\ntine Imms, Scott Miller, David Trembath, Madonna Tucker, and Ullrich Ecker. Evalu-\nation of a template for countering misinformation\u2014real-world autism treatment myth\ndebunking. PloS one , 14(1), 2019.\n[349]Cornelia Pechmann. Predicting when two-sided ads will be more effective than one-\nsided ads: The role of correlational and correspondent inferences. Journal of Marketing\nResearch , 29(4):441\u2013453, 1992.\n[350]Gordon Pennycook and David G Rand. Assessing the effect of \u201cdisputed\u201d warnings\nand source salience on perceptions of fake news accuracy. 2017.\n[351]Gordon Pennycook and David G Rand. Fighting misinformation on social media using\ncrowdsourced judgments of news source quality. Proceedings of the National Academy\nof Sciences , 116(7):2521\u20132526, 2019.\n[352]Gordon Pennycook, Ziv Epstein, Mohsen Mosleh, Antonio A Arechar, Dean Eckles,\nand David Rand. Understanding and reducing the spread of misinformation online.\nUnpublished manuscript: https://psyarxiv. com/3n9u8 , 2019.\n[353]Gordon Pennycook, Adam Bear, Evan T Collins, and David G Rand. The implied\ntruth effect: Attaching warnings to a subset of fake news headlines increases perceived\naccuracy of headlines without warnings. Management Science , 2020.\n[354]Gordon Pennycook, Jonathon McPhetres, Yunhao Zhang, Jackson G Lu, and David G\nRand. Fighting covid-19 misinformation on social media: Experimental evidence for a\nscalable accuracy-nudge intervention. Psychological science , 31(7):770\u2013780, 2020.\n[355]RichardEPettyandJohnTCacioppo. Theelaborationlikelihoodmodelofpersuasion.\nIn Communication and persuasion , pages 1\u201324. Springer, 1986.\n[356]Charlie Pinder, Jo Vermeulen, Russell Beale, and Robert Hendley. Subliminal priming\nof nonconscious goals on smartphones. In Proceedings of the 17th International Con-\nference on Human-Computer Interaction with Mobile Devices and Services Adjunct ,\npages 825\u2013830, 2015.\n[357]Val Pipps, Heather Walter, Kathleen Endres, and Patrick Tabatcher. Information\nrecall of internet news: Does design make a difference? a pilot study. Journal of\nMagazine Media , 11(1):1\u201320, 2009.\n[358]Patrick Lee Plaisance. Transparency: An assessment of the kantian roots of a key\nelement in media ethics practice. Journal of Mass Media Ethics , 22(2-3):187\u2013207,\n2007.\n[359]Patrick Lee Plaisance and Joan A Deppa. Perceptions and manifestations of autonomy,\ntransparencyandharmamongusnewspaperjournalists. Journalism & Communication\nMonographs , 10(4):327\u2013386, 2009.\n[360]Bernd Ploderer, Wolfgang Reitberger, Harri Oinas-Kukkonen, and Julia van Gemert-\nPijnen. Social interaction and reflection for behaviour change, 2014.\n[361]Sara Pluviano, Caroline Watt, and Sergio Della Sala. Misinformation lingers in mem-\nory: failure of three pro-vaccination strategies. PLoS One , 12(7):e0181640, 2017.\n[362]Horst Po\u00a0\u0308 ttker. News and its communicative quality: The inverted pyramid\u2014when\nand why did it appear? Journalism Studies , 4(4):501\u2013511, 2003.\n[363]Odette Pollar. Surviving information overload: how to find, filter, and focus on what\u2019s\nimportant . Thomson Crisp Learning, 2003.\n[364]Colin Porlezza, Scott R Maier, and Stephan Russ-Mohl. News accuracy in switzerland\nand italy: a transatlantic comparison with the us press. Journalism Practice , 6(4):\n530\u2013546, 2012.\n[365]Jon Porter. Twitter announces new api pricing, posing a challenge for small\ndevelopers - the verge. https://www.theverge.com/2023/3/30/23662832/\ntwitter-api-tiers-free-bot-novelty-accounts-basic-enterprice-monthly-price ,\n2023. (Accessed on 06/10/2023).\n[366]Associated Press. Ap news values and principles. 2014.\n[367]THE MEDIA INSIGHT PROJECT. Americans and the news media:\nWhat they do \u2014 and don\u2019t \u2014 understand about each other - ameri-\ncan press institute. https://www.americanpressinstitute.org/publications/\nreports/survey-research/americans-and-the-news-media/ , 2018. (Accessed on\n09/07/2020).\n[368]The Media Insight Project. What americans know, and don\u2019t, about\nhow journalism works - american press institute. https://www.\namericanpressinstitute.org/publications/reports/survey-research/\nwhat-americans-know-about-journalism/ , 2018. (Accessed on 10/02/2020).\n[369]The Trust Project. Frontpage. https://thetrustproject.org/ , 2015. (Accessed on\n10/14/2019).\n[370]The Trust Project. Collaborator materials. https://thetrustproject.org/\ncollaborator-materials/ , 2019. (Accessed on 01/23/2020).\n[371]ProPublica. Supporters \u2014 propublica. https://www.propublica.org/supporters ,\n2017. (Accessed on 10/11/2020).\n[372]ProPublica. This is what propublica is now covering \u2014 propublica. https:\n//www.propublica.org/article/this-is-what-propublica-is-now-covering ,\n2017. (Accessed on 07/10/2020).\n[373]Hoyt Purvis. Anonymous sources: More or less and why and where? Southwestern\nMass Communication Journal , 30(2), 2015.\n[374]Vahed Qazvinian, Emily Rosengren, Dragomir R Radev, and Qiaozhu Mei. Rumor\nhas it: Identifying misinformation in microblogs. In Proceedings of the Conference on\nEmpirical Methods in Natural Language Processing , pages 1589\u20131599. Association for\nComputational Linguistics, 2011.\n[375]Muck Rack. Muck rack for journalists and public relations. https://muckrack.com/ ,\n2009. (Accessed on 03/25/2021).\n[376]Muck Rack. Muck rack | for journalists. https://muckrack.com/journalists , 2019.\n(Accessed on 09/14/2019).\n[377]Danielle E Ramo and Judith J Prochaska. Broad reach and targeted recruitment using\nfacebook for an online survey of young adult substance use. Journal of medical Internet\nresearch, 14(1):e28, 2012.\n[378]Arthur S Reber. Implicit learning and tacit knowledge. Journal of experimental psy-\nchology: General , 118(3):219, 1989.\n[379]Marc-Andre Reinhard and Siegfried L Sporer. Verbal and nonverbal behaviour as a\nbasisforcredibilityattribution: Theimpactoftaskinvolvementandcognitivecapacity.\nJournal of Experimental Social Psychology , 44(3):477\u2013488, 2008.\n[380]Paul Resnick, R Kelly Garrett, Travis Kriplean, Sean A Munson, and Natalie Jomini\nStroud. Bursting your (filter) bubble: strategies for promoting diverse exposure. In\nProceedings of the 2013 conference on Computer supported cooperative work companion ,\npages 95\u2013100, New York, NY, USA, 2013. Association for Computing Machinery.\n[381]Matthias Revers. The twitterization of news making: Transparency and journalistic\nprofessionalism. Journal of communication , 64(5):806\u2013826, 2014.\n[382]Jens Riegelsberger. Interpersonal cues and consumer trust in e-commerce. In CHI\u201903\nExtended Abstracts on Human F actors in Computing Systems , pages 674\u2013675, 2003.\n[383]Zacc Ritter. How much does the world trust journalists? https://news.gallup.\ncom/opinion/gallup/272999/world-trust-journalists.aspx , 2019. (Accessed on\n03/22/2021).\n[384]Dimitris Rizopoulos. Glmmadaptive: generalized linear mixed models using adaptive\ngaussian quadrature. R package version 0.5\u20131 , 2019.\n[385]Marilyn Roberts, Wayne Wanta, and Tzong-Horng Dzwo. Agenda setting and issue\nsalience online. Communication research , 29(4):452\u2013465, 2002.\n[386]Kevin Roitero, Michael Soprano, Shaoyang Fan, Damiano Spina, Stefano Mizzaro, and\nGianluca Demartini. Can the crowd identify misinformation objectively? the effects\nof judgment scale and assessor\u2019s background. In Proceedings of the 43rd International\nACM SIGIR Conference on Research and Development in Information Retrieval , pages\n439\u2013448, 2020.\n[387]Jon Roozenbeek and Sander van der Linden. Fake news game confers psychological\nresistance against online misinformation. Palgrave Communications , 5(1):1\u201310, 2019.\n[388]Guy Rosen. An update on our work to keep people informed and limit misinfor-\nmation about covid-19 - about facebook. https://about.fb.com/news/2020/04/\ncovid-19-misinfo-update/ , 2020. (Accessed on 09/11/2020).\n[389]Guy Rosen and Tessa Lyons. Remove, reduce, inform: New steps to man-\nage problematic content - about facebook. https://about.fb.com/news/2019/04/\nremove-reduce-inform-new-steps/ , 2019. (Accessed on 09/11/2020).\n[390]Jay Rosen. Beyond objectivity. 1993.\n[391]Matthew Rosenberg. How republican voters took qanon mainstream -\nthe new york times. https://www.nytimes.com/2020/10/19/us/politics/\nqanon-trump-republicans.html , 10 2020. (Accessed on 11/08/2021).\n[392]Mary Beth Rosson, John M Carroll, and Natalie Hill. Usability engineering: scenario-\nbased development of human-computer interaction . Morgan Kaufmann, 2002.\n[393]Yoel Roth and Ashita Achuthan. Building rules in public: Our approach to synthetic\n& manipulated media. https://blog.twitter.com/en_us/topics/company/2020/\nnew-approach-to-synthetic-and-manipulated-media.html , 2020. (Accessed on\n09/11/2020).\n[394]Yoel Roth and Nick Pickles. Updating our approach to misleading in-\nformation. https://blog.twitter.com/en_us/topics/product/2020/\nupdating-our-approach-to-misleading-information.html , 2020. (Accessed\non 09/11/2020).\n[395]Twitter Safety. Strengthening our approach to deliberate attempts to mis-\nlead voters. https://blog.twitter.com/en_us/topics/company/2019/\nstrengthening-our-approach-to-deliberate-attempts-to-mislead-vot.html ,\n2019. (Accessed on 09/11/2020).\n[396]Twitter Safety. Expanding our policies to further protect the civic con-\nversation. https://blog.twitter.com/en_us/topics/company/2020/\ncivic-integrity-policy-update.html , 2020. (Accessed on 09/11/2020).\n[397]Emily Saltz, Tommy Shane, Victoria Kwan, Claire Leibowicz, and Claire Wardle.\nIt matters how platforms label manipulated media. here are 12 principles design-\ners should follow. - the partnership on ai. https://www.partnershiponai.org/\nit-matters-how-platforms-label-manipulated-media-here-are-12-principles-designers-should-follow/ ,\n2020. (Accessed on 07/01/2020).\n[398]CorinaSasandAlanDix. Designingforreflectiononpersonalexperience. International\nJournal of Human-Computer Studies , 69(5):281\u2013282, 2011.\n[399]Corina Sas and Irni Eliana Khairuddin. Design for trust: An exploration of the chal-\nlenges and opportunities of bitcoin users. In Proceedings of the 2017 CHI Conference\non Human F actors in Computing Systems , pages 6499\u20136510, 2017.\n[400]Roser Saur\u00ed and James Pustejovsky. Factbank: a corpus annotated with event factu-\nality. Language resources and evaluation , 43(3):227, 2009.\n[401]Jorrit Schaap. Bubble Trouble \u2013 Venture Out of Your Filter Bubbles. pages 1\u201314,\n2020.\n[402]schema.org. Markup for news - schema.org. https://schema.org/docs/news.html ,\n2017. (Accessed on 01/24/2020).\n[403]Dietram A Scheufele. Agenda-setting, priming, and framing revisited: Another look\nat cognitive effects of political communication. Mass communication & society , 3(2-3):\n297\u2013316, 2000.\n[404]Dietram A Scheufele and David Tewksbury. Framing, agenda setting, and priming:\nThe evolution of three media effects models. Journal of communication , 57(1):9\u201320,\n2007.\n[405]Michael Schudson. Discovering the news: A social history of American newspapers .\nBasic Books, 1981.\n[406]Paul Resnick Sean A. Munson, Stephanie Y. Lee. Encouraging reading of diverse\npolitical viewpoints with a browser widget. In ICWSM, 2013.\n[407]Katharine Q Seelye. Times panel proposes steps to build credibility. New Y ork Times ,\n9, 2005.\n[408]Gwendolyn Seidman. Self-presentation and belonging on facebook: How personality\ninfluences social media use and motivations. Personality and individual differences , 54\n(3):402\u2013407, 2013.\n[409]Evan Selinger and Kyle Whyte. Is there a right way to nudge? the practice and ethics\nof choice architecture. Sociology Compass , 5(10):923\u2013935, 2011.\n[410]Alina Selyukh, Maria Hollenhorst, and Katie Park. Disney-fox deal:\nWho controls digital media? conglomerates, brands in one chart|npr.\nhttps://www.npr.org/sections/alltechconsidered/2016/10/28/ 499495517/big-media-\ncompanies-and-their-many-brands-in-one-chart, 2016.\n[411]Phoebe Sengers, Kirsten Boehner, Shay David, and Joseph Kaye. Reflective design.\nCritical Computing - Between Sense and Sensibility - Proceedings of the 4th Decennial\nAarhus Conference , pages 49\u201358, 2005. doi: 10.1145/1094562.1094569.\n[412]Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol, Kai-Cheng Yang, Alessan-\ndro Flammini, and Filippo Menczer. The spread of low-credibility content by social\nbots. Nature communications , 9(1):1\u20139, 2018.\n[413]Renee Shelby, Shalaleh Rismani, Kathryn Henne, Ajung Moon, Negar Ros-\ntamzadeh, Paul Nicholas, YILLA-AKBARI N\u2019MAH, Jess Gallegos, Andrew Smart,\nand GURLEEN VIRK. Identifying sociotechnical harms of algorithmic systems: Scop-\ning a taxonomy for harm reduction. arXiv preprint arXiv:2210.05791 , 2022.\n[414]Richard M Shiffrin and Walter Schneider. Automatic and controlled processing revis-\nited. 1984.\n[415]Pamela J Shoemaker, Tsan-Kuo Chang, and Nancy Brendlinger. Deviance as a pre-\ndictor of newsworthiness: Coverage of international events in the us media. Annals of\nthe International Communication Association , 10(1):348\u2013365, 1987.\n[416]John Sides. Analysis | is the media biased toward clinton or trump? here\nis some actual hard data. W ashington Post , Sep 2016. ISSN 0190-8286.\nURL https://www.washingtonpost.com/news/monkey-cage/wp/2016/09/20/\nis-the-media-biased-toward-clinton-or-trump-heres-some-actual-hard-data/ .\n[417]Suvi Silfverberg, Lassi A. Liikkanen, and Airi Lampinen. \u201dI\u2019ll press play, but I won\u2019t\nlisten\u201d. page 207, 2011. doi: 10.1145/1958824.1958855.\n[418]Craig Silverman. Regret the error: how media mistakes pol lute the press and imperil\nfree speech . Sterling Publishing Company, Inc., 2009.\n[419]Henry Silverman. Helping fact-checkers identify false claims faster - about facebook.\nhttps://about.fb.com/news/2019/12/helping-fact-checkers/ , 2019. (Accessed\non 09/11/2020).\n[420]Slate. How people read online: Why you won\u2019t fin-\nish this article. https://slate.com/technology/2013/06/\nhow-people-read-online-why-you-wont-finish-this-article.html , 06 2013.\n(Accessed on 09/11/2022).\n[421]Petr Slovak, Chris Frauenberger, and Geraldine Fitzpatrick. Reflective practicum: A\nframework of sensitising concepts to design for transformative reflection. Conference\non Human F actors in Computing Systems - Proceedings , 2017-May:2696\u20132707, 2017.\ndoi: 10.1145/3025453.3025516.\n[422]Jeff Smith. Designing against misinformation - facebook de-\nsign - medium. https://medium.com/facebook-design/\ndesigning-against-misinformation-e5846b3aa1e2 , 2019. (Accessed on\n09/18/2019).\n[423]Jeff Smith, Alex Leavitt, and Grace Jackson. Designing new ways to give context\nto news stories | facebook newsroom. https://newsroom.fb.com/news/2018/04/inside-\nfeed-article-context/, 2018.\n[424]Oren Soffer. Algorithmic personalization and the two-step flow of communication.\nCommunication Theory , 31(3):297\u2013315, 2021.\n[425]Sandeep Soni, Tanushree Mitra, Eric Gilbert, and Jacob Eisenstein. Modeling factual-\nity judgments in social media text. In Proceedings of the 52nd Annual Meeting of the\nAssociation for Computational Linguistics (V olume 2: Short Papers) , pages 415\u2013420,\n2014.\n[426]Timo Spinde, Felix Hamborg, Karsten Donnay, Angelica Becerra, and Bela Gipp.\nEnabling news consumers to view and understand biased news coverage: a study on\nthe perception and visualization of media bias. In Proceedings of the ACM/IEEE joint\nconference on digital libraries in 2020 , pages 389\u2013392, 2020.\n[427]Steven A Stahl, Cynthia R Hynd, Bruce K Britton, Mary M McNish, and Dennis\nBosquet. What happens when students read multiple source documents in history?\nReading Research Quarterly , 31(4):430\u2013456, 1996.\n[428]Keith E Stanovich and Richard F West. Individual differences in reasoning: Implica-\ntions for the rationality debate? Behavioral and brain sciences , 23(5):645\u2013665, 2000.\n[429]DominikASteculaandMarkPickup. Socialmedia, cognitivereflection, andconspiracy\nbeliefs. F rontiers in Political Science , 3:62, 2021.\n[430]Anselm Strauss and Juliet Corbin. Grounded theory methodology. Handbook of qual-\nitative research , 17:273\u201385, 1994.\n[431]Natalie Jomini Stroud. Polarization and partisan selective exposure. Journal of com-\nmunication , 60(3):556\u2013576, 2010.\n[432]Natalie Jomini Stroud. Niche news: The politics of news choice . Oxford University\nPress on Demand, 2011.\n[433]Jay Sullivan. Introducing a forwarding limit on messenger - about facebook. https://\nabout.fb.com/news/2020/09/introducing-a-forwarding-limit-on-messenger/ ,\n2020. (Accessed on 09/11/2020).\n[434]R\u00f3bert Sumi, Taha Yasseri, et al. Edit wars in wikipedia. In 2011 IEEE Third\nInternational Conference on Privacy, Security, Risk and T rust and 2011 IEEE Third\nInternational Conference on Social Computing , pages 724\u2013727. IEEE, 2011.\n[435]S Shyam Sundar. The main model: A heuristic approach to understanding technology\neffects on credibility. Digital media, youth, and credibility , 73100, 2008.\n[436]S Shyam Sundar, Anne Oeldorf-Hirsch, and Qian Xu. The bandwagon effect of col-\nlaborative filtering technology. In CHI\u201908 extended abstracts , pages 3453\u20133458. ACM,\n2008.\n[437]S Shyam Sundar, Haiyan Jia, T Franklin Waddell, and Yan Huang. Toward a theory\nof interactive media effects (time). The handbook of the psychology of communication\ntechnology , pages 47\u201386, 2015.\n[438]Cass R Sunstein. The law of group polarization. University of Chicago Law School,\nJohn M. Olin Law & Economics W orking Paper , (91), 1999.\n[439]Cass R Sunstein. The polarization of extremes. The Chronicle of Higher Education ,\n54(16):9, 2007.\n[440]Cass R Sunstein. http://republic.com 2.0, 2009.\n[441]Cass R Sunstein. Why nudge?: The politics of libertarian paternalism . Yale University\nPress, 2014.\n[442]Cass R Sunstein. The ethics of nudging. Y ale J. on Reg. , 32:413, 2015.\n[443]Cass R Sunstein. Do people like nudges? 2016.\n[444]Cass R Sunstein. Nudges that fail. Behavioural Public Policy , 1(1):4\u201325, 2017.\n[445]Twitter Support. New labels for government and state-affiliated me-\ndia accounts. https://blog.twitter.com/en_us/topics/product/2020/\nnew-labels-for-government-and-state-affiliated-media-accounts.html ,\n2020. (Accessed on 09/11/2020).\n[446]James Surowiecki. The wisdom of crowds . Anchor, 2005.\n[447]Hanaa Tameez. Maybe greater transparency can increase trust\nin news \u2014 but readers have to find your transparency first \u00bb\nnieman journalism lab. https://www.niemanlab.org/2020/01/\nmaybe-greater-transparency-can-increase-trust-in-news-but-readers-have-to-find-your-transparency-first/ ,\n2020. (Accessed on 02/23/2021).\n[448]Harsh Taneja and Katie Yaeger. Do people consume the news they trust? In Pro-\nceedings of the 2019 CHI Conference on Human F actors in Computing systems , pages\n1\u201310, 2019.\n[449]David Tannenbaum, Craig R Fox, and Todd Rogers. On the misplaced politics of\nbehavioural policy interventions. Nature Human Behaviour , 1(7):0130, 2017.\n[450]David Tewksbury and Scott L Althaus. Differences in knowledge acquisition among\nreaders of the paper and online versions of a national newspaper. Journalism & Mass\nCommunication Quarterly , 77(3):457\u2013479, 2000.\n[451]Richard H Thaler. Nudge: Improving decisions about health, wealth, and happiness,\n2008.\n[452]Share the Facts. Share the facts. http://www.sharethefacts.org/ , 2016. (Accessed\non 01/22/2020).\n[453]Jacob Thebault-Spieker, Stevie Chancellor, Michael Ann DeVito, Niloufar Salehi, Alex\nLeavitt, David Karger, and Katta Spiel. Do we fix it or burn it down? towards practi-\ncable critique at cscw. In Companion Publication of the 2021 Conference on Computer\nSupported Cooperative W ork and Social Computing , CSCW \u201921, page 234\u2013237, New\nYork, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450384797.\ndoi: 10.1145/3462204.3483281. URL https://doi.org/10.1145/3462204.3483281 .\n[454]Anja Thieme, Jayne Wallace, Paula Johnson, John McCarthy, Si\u00e2n Lindley, Peter\nWright, PatrickOlivier, andThomasDMeyer. Designtopromotemindfulnesspractice\nand sense of self for vulnerable women in secure hospital services. In Proceedings of\nthe SIGCHI Conference on Human F actors in Computing Systems , pages 2647\u20132656,\nNew York, NY, USA, 2013. Association for Computing Machinery.\n[455]Sreethu Thulasi. Understand why you\u2019re seeing certain ads and how you can ad-\njust your ad experience - about facebook. https://about.fb.com/news/2019/07/\nunderstand-why-youre-seeing-ads/ , 2019. (Accessed on 09/11/2020).\n[456]NY Times. Timescast | march 22, 2010 - video - nytimes.com. https://www.\nnytimes.com/video/continuous/1247467418484/timescast.html , 2010. (Accessed\non 09/29/2019).\n[457]The New York Times. Product and design | the new york times company. https:\n//www.nytco.com/careers/product-and-design/ , 2019. (Accessed on 03/05/2021).\n[458]Peter M. Todd and Gerd Gigerenzer. Pr\u00e9cis of Simple heuristics that make us smart.\nBehavioral and Brain Sciences , 23(5):727\u2013780, 2000. ISSN 0140525X. doi: 10.1017/\nS0140525X00003447.\n[459]Newsroom Transparency Tracker. Discover the people, policies, and practices behind\nthe news. https://www.newsroomtransparencytracker.com/ , 2019. (Accessed on\n01/24/2020).\n[460]Shawn Tseng and BJ Fogg. Credibility and computing technology. Communications\nof the ACM , 42(5):39\u201344, 1999.\n[461]Tiffany Tseng and Coram Bryant. Design, reflect, explore: encouraging children\u2019s\nreflections with mechanix. In CHI\u201913 Extended Abstracts on Human F actors in Com-\nputing Systems , pages 619\u2013624. Association for Computing Machinery, New York, NY,\nUSA, 2013.\n[462]Yariv Tsfati. Online news exposure and trust in the mainstream media: Exploring\npossible associations. American Behavioral Scientist , 54(1):22\u201342, 2010.\n[463]Yariv Tsfati and Joseph N Cappella. Do people watch what they do not trust? ex-\nploring the association between news media skepticism and exposure. Communication\nResearch , 30(5):504\u2013529, 2003.\n[464]Yariv Tsfati and Joseph N Cappella. Why do people watch news they do not trust? the\nneed for cognition as a moderator in the association between news media skepticism\nand exposure. Media psychology , 7(3):251\u2013271, 2005.\n[465]Gaye Tuchman. Objectivity as strategic ritual: An examination of newsmen\u2019s notions\nof objectivity. American Journal of sociology , 77(4):660\u2013679, 1972.\n[466]Miroslav Tudjman and Nives Mikelic. Information science: Science about information,\nmisinformation and disinformation. Proceedings of Informing Science+ Information\nT echnology Education , 3:1513\u20131527, 2003.\n[467]Twitter. Notices on twitter and what they mean. https://help.twitter.com/en/\nrules-and-policies/notices-on-twitter , 2019. (Accessed on 09/11/2020).\n[468]Juliane Urban and Wolfgang Schweiger. News quality from the recipients\u2019 perspective:\nInvestigating recipients\u2019 ability to judge the normative quality of news. Journalism\nStudies, 15(6):821\u2013840, 2014.\n[469]Nina Valkanova, Sergi Jorda, Martin Tomitsch, and Andrew Vande Moere. Reveal-\nit! the impact of a social visualization projection on public awareness and discourse.\nIn Proceedings of the SIGCHI Conference on Human F actors in Computing Systems ,\npages 3461\u20133470, New York, NY, USA, 2013. Association for Computing Machinery.\n[470]Marshall Van Alstyne and Erik Brynjolfsson. Global village or cyber-balkans? model-\ning and measuring the integration of electronic communities. Management science , 51\n(6):851\u2013868, 2005.\n[471]Kim J Vicente and Jens Rasmussen. Ecological interface design: Theoretical founda-\ntions. IEEE T ransactions on systems, man, and cybernetics , 22(4):589\u2013606, 1992.\n[472]Anthony J Viera, Joanne M Garrett, et al. Understanding interobserver agreement:\nthe kappa statistic. F am med , 37(5):360\u2013363, 2005.\n[473]Stella Vosniadou and William F Brewer. Theories of knowledge restructuring in de-\nvelopment. Review of educational research , 57(1):51\u201367, 1987.\n[474]Stella Vosniadou and Andrew Ortony. Similarity and analogical reasoning . Cambridge\nUniversity Press, 1989.\n[475]Emily Vraga, Melissa Tully, John E Kotcher, Anne-Bennett Smithson, and Melissa\nBroeckelman-Post. A multi-dimensional approach to measuring news media literacy.\nJournal of Media Literacy Education , 7(3):41\u201353, 2015.\n[476]W3. Credible web community group. https://www.w3.org/community/\ncredibility/ , 2017. (Accessed on 01/30/2020).\n[477]David Wagner, Gabriele Vollmar, and Heinz-Theo Wagner. The impact of information\ntechnology on knowledge creation: An affordance approach to social media. Journal\nof Enterprise Information Management , 2014.\n[478]Jonathan Wai and Kaja Perina. Expertise in journalism: Factors shaping a cognitive\nand culturally elite profession. Journal of Expertise , 1(1):57\u201378, 2018.\n[479]Canhui Wang, Min Zhang, Liyun Ru, and Shaoping Ma. An automatic online news\ntopickeyphraseextractionsystem. In 2008 IEEE/WIC/ACM International Conference\non W eb Intel ligence and Intel ligent Agent T echnology , volume 1, pages 214\u2013219. IEEE,\n2008.\n[480]Wei Wang. Chinese news event 5w1h semantic elements extraction for event ontology\npopulation. In Proceedings of the 21st International Conference on W orld Wide W eb ,\npages 197\u2013202. ACM, 2012.\n[481]Yang Wang, Pedro Giovanni Leon, Kevin Scott, Xiaoxuan Chen, Alessandro Acquisti,\nand Lorrie Faith Cranor. Privacy nudges for social media: an exploratory facebook\nstudy. In Proceedings of the 22nd International Conference on W orld Wide W eb , pages\n763\u2013770, 2013.\n[482]Yang Wang, Pedro Giovanni Leon, Alessandro Acquisti, Lorrie Faith Cranor, Alain\nForget, and Norman Sadeh. A field trial of privacy nudges for facebook. In Proc. CHI ,\npages 2367\u20132376. ACM, 2014.\n[483]Yixue Wang and Siyu Yao. Study on intention-aware recommendation of youtube\nvideos. 2020.\n[484]Claire Wardle. Misinformation has created a new world disorder -\nscientific american. https://www.scientificamerican.com/article/\nmisinformation-has-created-a-new-world-disorder/ , 2019. (Accessed on\n05/27/2020).\n[485]C Kay Weaver, Judy Motion, and Juliet Roper. From propaganda to discourse (and\nback again): Truth, power, the public interest and public relations. Public relations:\nCritical debates and contemporary practice , 7:21, 2006.\n[486]MatthewSWeber. Newspapersandthelong-termimplicationsofhyperlinking. Journal\nof Computer-Mediated Communication , 17(2):187\u2013201, 2012.\n[487]Karl E Weick. Sensemaking in organizations , volume 3. Sage, 1995.\n[488]Karl E Weick, Kathleen M Sutcliffe, and David Obstfeld. Organizing and the process\nof sensemaking. Organization science , 16(4):409\u2013421, 2005.\n[489]David Manning White. The \u201cgate keeper\u201d: A case study in the selection of news.\nJournalism quarterly , 27(4):383\u2013390, 1950.\n[490]Wikipedia. Help:infobox - wikipedia. https://en.wikipedia.org/wiki/Help:\nInfobox, 2006. (Accessed on 10/01/2019).\n[491]Mark Wilhelm, Ajith Ramanathan, Alexander Bonomo, Sagar Jain, Ed H. Chi, and\nJennifer Gillenwater. Practical diversified recommendations on youtube with deter-\nminantal point processes. In Proceedings of the 27th ACM International Conference\non Information and Knowledge Management , CIKM \u201918, page 2165\u20132173, New York,\nNY, USA, 2018. Association for Computing Machinery. ISBN 9781450360142. doi:\n10.1145/3269206.3272018. URL https://doi.org/10.1145/3269206.3272018 .\n[492]WisconsinWatch. Funding | wisconsinwatch.org. https://www.wisconsinwatch.org/\nabout/funding/ . (Accessed on 10/11/2020).\n[493]Gavin Wood, Kiel Long, Tom Feltwell, Scarlett Rowland, Phillip Brooker, Jamie\nMahoney, John Vines, Julie Barnett, and Shaun Lawson. Rethinking engage-\nment with online news through social and visual co-annotation. Conference on\nHuman F actors in Computing Systems - Proceedings , 2018-April:1\u201312, 2018. doi:\n10.1145/3173574.3174150.\n[494]Thomas Wood and Ethan Porter. The elusive backfire effect: Mass attitudes\u2019 steadfast\nfactual adherence. Political Behavior , 41(1):135\u2013163, 2019.\n[495]Robin Worrall. Social media used to spread, create covid-19 falsehoods\n\u2013 harvard gazette. https://news.harvard.edu/gazette/story/2020/05/\nsocial-media-used-to-spread-create-covid-19-falsehoods/ , 2020. (Accessed\non 09/12/2020).\n[496]Caiming Xiong, Victor Zhong, and Richard Socher. Dynamic coattention networks for\nquestion answering. arXiv preprint arXiv:1611.01604 , 2016.\n[497]Yan Xu, Erika Shehan Poole, Andrew D Miller, Elsa Eiriksdottir, Dan Kestranek,\nRichard Catrambone, and Elizabeth D Mynatt. This is not a one-horse race: under-\nstanding player types in multiplayer pervasive health games for youth. In Proceedings\nof the ACM 2012 conference on computer supported cooperative work , pages 843\u2013852,\nNew York, NY, USA, 2012. Association for Computing Machinery.\n[498]Hsiao-chen You and Kuohsiang Chen. Applications of affordance and semantics in\nproduct design. Design Studies , 28(1):23\u201338, 2007.\n[499]John R Zaller et al. The nature and origins of mass opinion . Cambridge university\npress, 1992.\n[500]Amy X Zhang, Aditya Ranganathan, Sarah Emlen Metz, Scott Appling, Connie Moon\nSehat, Norman Gilmore, Nick B Adams, Emmanuel Vincent, Jennifer Lee, Martin\nRobbins, et al. A structured response to misinformation: Defining and annotating\ncredibility indicators in news articles. In Companion Proceedings of the The W eb\nConference 2018 , pages 603\u2013612, 2018.\n[501]Pengyi Zhang and Dagobert Soergel. Cognitive mechanisms in sensemaking: A quali-\ntative user study. Journal of the Association for Information Science and T echnology ,\n71(2):158\u2013171, 2020. ISSN 23301643. doi: 10.1002/asi.24221.\n[502]Shanyang Zhao, Sherri Grasmuck, and Jason Martin. Identity construction on face-\nbook: Digital empowerment in anchored relationships. Computers in human behavior ,\n24(5):1816\u20131836, 2008.\n[503]ZheZhao, PaulResnick, andQiaozhuMei. Enquiringminds: Earlydetectionofrumors\nin social media from enquiry posts. In Proceedings of the 24th international conference\non world wide web , pages 1395\u20131405, 2015.\n[504]Tao Zhou, Zolt\u00e1n Kuscsik, Jian-Guo Liu, Mat\u00fa\u0161 Medo, Joseph Rushton Wakeling, and\nYi-Cheng Zhang. Solving the apparent diversity-accuracy dilemma of recommender\nsystems. Proceedings of the National Academy of Sciences , 107(10):4511\u20134515, 2010.\n[505]Fabiana Zollo and Walter Quattrociocchi. Misinformation spreading on facebook. In\nComplex spreading phenomena in social systems , pages 177\u2013196. Springer, 2018.\n\nAppendices\n271\nAppendix A\nNudgeCred\nA.1 Example T weets Used in Study 1\nFigureA.1shows several tweets used in Study 1. These tweets were selected by finding\nthe most popular tweets from the last 48 hours from various partisan sources. Notice the\npartisan nature of the items including immigration, racism and LGBTQ+ issues.\nA.2 Study 2: Interview Questionnaire\n\u2022Could you tell me about your news reading on twitter? How often do you read news?\nand what type of news do you read?\n\u2022How often do you come across misinformation?\n\u2022Have you ever felt the need for any tools to improve news reading on twitter?\n\u2022Have you ever used any tools to improve news reading on twitter? What tool? How\ndid it work?\n\u2022(Asking them to share their screen for twitter feed) How would you compare your\nTwitter use during the study to how you normally do?\n272\nFigure A.1: Sample tweets used in Study 1 without the interventions. The examples include\nreliable, questionable and unreliable tweets from left-/center-/right-leaning sources. Here,\nthere is a mix of politically contentious (e.g., immigration, racism and LGBTQ+) and not\nso contentious issues (e.g., flood and national security).\n\u2022Could you tell me about a time when you paid more attention to a news on Twitter\nin the last 5 days? Why? What was it about?\n\u2022How satisfied were you with what you saw on Twitter in the last 5 days?\n\u2022What aspect of the intervention did you notice most? How did that impact you?\n\u2022When using the extension, did you think of anything it was missing? What more\nshould it do?\n\u2022Can you think of any other application of this extension that you would like?\n\u2022During the study, did you have any issues with NudgeCred? Is there any aspect of the\nusability (eg., design, speed, accuracy) you thought could be improved?\n\u2022How did you feel about the plugin overall? What did you like about it? What did you\ndislike about it?\n\u2022Would you continue using it after this study?\nAppendix B\nNewsComp\nB.1 Thinkaloud Interviews Questionnaires\n\u2022What are the viewpoints expressed in each article? How would you compare the\nviewpoints between the articles?\n\u2022How would you compare the numbers of actors reported in each article?\n\u2022How would you compare each article providing complete information about what hap-\npened/where/when/who was involved?\n\u2022How would you compare the analytical quality in each article? Do they provide infor-\nmation on causes, consequences, evaluations and claims of/from the event?\n\u2022How transparent are the authors for each article about their sources (e.g,name, func-\ntion, circumstances of quote)?\nImp. Recall (M1) Imp. Precision (M2) Conn. Recall(M3) Conn. Precision(M4)\n\u03b2 std. err. \u03b2 std. err. \u03b2 std. err. \u03b2 std. err.\n(Intercept) 0.32*** 0.08 0.21*** 0.04 0.34*** 0.05 0.37*** 0.05\nCEK[Low] 0.35** 0.13 0.05 0.07 0.07 0.06 0.02 0.07\nVML[Low] 0.18 0.12 -0.02 0.06 -0.04 0.06 0.02 0.07\nR2=0.12 R2=0.01 R2=0.04 R2=0.19\nNobs=62 *p<0.05, **p<0.01, ***p<0.001\nTable B.1: Linear models of recall and precision for connection-making and importance\ndetection with user characteristics as predictors.\n275\nQual(M5) Cred(M6)\n\u03b2 std. err. \u03b2 std. err.\n(Intercept) 0.67*** 0.05 0.65*** 0.05\nGroup[Treat.] 0.01 0.07 0.11 0.07\nArticle[Abortion(R)] 0.04 0.07 0.01 0.07\nArticle[Immigration(L)] 0.03 0.07 0.11 0.07\nArticle[Immigration(R)] -0.01 0.05 0.04 0.05\nGroup [Treat.] * Article[Abortion(R)] -0.07 0.09 -0.17* 0.08\nGroup [Treat.] * [Immigration(L)] 0.00 0.09 -0.18 0.09\nGroup [Treat.] * Article[Immigration(R)] 0.02 0.08 -0.12 0.08\nR2= 0.43 R2= 0.48\nNuser= 109,Narticle = 4,Nobs= 218 *p<0.05, **p<0.01, ***p<0.001\nTable B.2: Mixed-effects regression on quality and credibility score using the interaction of\nexperimental condition and articles.\n\u2022How would you compare the comprehensibility of the article pair (e.g., simplicity in\nterms/phasing, conciseness, coherence)?\n\u2022How would you compare impartiality in content presentation between the articles (bal-\nanced viewpoints and actors, article\n\u2022author personally evaluating/judging the reported situation)?\n\u2022How would you compare ethical standards (e.g., discriminating any party involved,\nneutral phrasing) between the reports?\n\u2022Whose perspective this article represents more than others? Is there any particular\ngroup/party/side that the article focus to represent compared to the other article?\nB.2 Articles Used in the Deployment\n\u2022E1L:Immigration (Left)\n\u2022E1R:Immigration (Right)\n\u2022E2L:Abortion (Left)\n\u2022E2R:Abortion (Right)\nB.3 Effect of User Characteristics\nWe modeled user characteristics to predict precision and recall in annotation tasks, shown\nin tableB.1. We accounted for several factors in these models, including users\u2019 demographic\ncharacteristics (age, gender, education, and political affiliation) and news expertise metrics\n(CEK and VML).\nB.4 RQ2: Mixed-Effects Models\nBesides ANOVA, we also performed a series of mixed-effects regression model on users\u2019\nquality and credibility perception using experimental variables, in Table B.2. Similar to\nANOVA results, we found significant interaction effect on credibility only for high contrast\narticle.\nAppendix C\nOtherT ube\nC.1 Distribution of Users Who Passed Eligibility Cri-\nteria and Signed Up\nTotal 318 users signed up for our study. Figure C.1shows the demography of these users.\nC.2 Need for Reflection and Insight Questionnaire\nThese questions have been taken from Halttu et. al. [ 183].\nC.2.1 Need for Self-Reflection\n\u2022I am not really interested in analyzing my behavior. (R)\n\u2022It is important for me to evaluate the things that I do.\n\u2022I am very interested in examining what I think about.\n\u2022It is important to me to try to understand what my feelings mean.\n\u2022I have a definite need to understand the way that my mind works.\n\u2022It is important for me to be able to understand how my thoughts arise.\n278\nFemale Male0100No of UsersGender\nWhite Black \nor \nAfrican \nAmericanAsian Hispanic \nor \nLatino/a/x050100Race\nDem Ind Rep0100Political Affiliation\n<\n 30min<\n an hour<\n 2hours>\n 2hours050100Typical YouTube Session LengthFigure C.1: Demography of the participants who passed screening criteria and signed up for\nthe study.\nC.2.2 Insight\n\u2022I usually have a very clear idea about why I\u2019ve behaved in a certain way.\n\u2022My behavior often puzzles me. (R)\n\u2022Thinking about my thoughts makes me more confused. (R)\n\u2022Often I find it difficult to make sense of the way I feel about things.(R)\n\u2022I usually know why I feel the way I do.\nC.3 Semi-Structured Interview Questions\n\u2022How do you typically use YouTube to find new content?\n\u2022How would you describe the benefits and limitations in the features provided by\nYouTube to find new content?\n\u2022Can you walk me through your recommendation feed? How did you use features\n[sharing video, setting persona, browsing OtherTube] in OtherTube?\n\u2022Whatwereyourimpressionswhenyousawstrangers\u2019profilesandrecommendedvideos?\n\u2022Could you describe any profile/recommended videos from the strangers during the\nstudy that stood out or were memorable to you? Why?\n\u2022How would you compare strangers\u2019 recommendations to your YouTube recommenda-\ntion?\n\u2022Would you continue to use OtherTube after the study? If so, what would be the\npurpose/motivation? If not, why not?\n\u2022Among the features provided in OtherTube about choosing your persona, what was\nimportant for you to present about yourself to others?\n\u2022How would you describe the features offered by the tool to share/remove recommended\nvideos from your feed?\n\u2022What concerns would you have regarding sharing your profile and recommendation?\n\u2022Is there anything else where the tool should be more transparent about?\n\u2022Other than using the plugin, was there anything that you had to do and you have not\ndone regularly for this study?\n\u2022What did you like about the tool? What did you not like about the tool? Do you have\nany suggested changes on the tool for us to improve it?", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Combating Problematic Information Online with Dual Process Cognitive Affordances", "author": ["MD Bhuiyan"], "pub_year": "2023", "venue": "NA", "abstract": "Dual process theories of mind have been developed over the last decades to posit that humans  use heuristics or mental shortcuts (automatic) and analytical (reflective) reasoning while"}, "filled": false, "gsrank": 656, "pub_url": "https://vtechworks.lib.vt.edu/items/4d7de6cd-54d5-4f9c-b719-63c8742bb77e", "author_id": ["wgWTeXQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:uCfSOs4hkCQJ:scholar.google.com/&output=cite&scirp=655&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D650%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=uCfSOs4hkCQJ&ei=e7WsaLT2OY6IieoP0sKRuAk&json=", "num_citations": 1, "citedby_url": "/scholar?cites=2634642951645571000&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:uCfSOs4hkCQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://vtechworks.lib.vt.edu/bitstreams/b8ed84db-006a-4f76-8e7c-cb69f5832189/download"}}, {"title": "Ideological biases in social sharing of online information about climate change", "year": "2021", "pdf_data": "ZK[KF ZIN FZ\\OIS K\nOno{w{rtmkw ltk\u20aco\u20ac tz\u20ac{mtkw \u20acsk~tzr {q{zwtzo\ntzq{~yktt{z kl{ut mwtykto mskzro\n\\~t\ufffd\ufffdkz Q1G1Ikzz OJ\n*.Oktz [1_ok\ufffdo~. N\ufffd\ufffdow \\1W1_twwtky\ufffd\nJo|k~\ufffdyoz\ufffd {qI{y|\ufffd\ufffdo~ [mtozmo. ]zt\ufffdo~\ufffdt\ufffd\ufffd {qK\ufffdo\ufffdo~. K\ufffdo\ufffdo~. Jo\ufffd{z .]zt\ufffdon Rtzrn{y\n*\ufffdm7;4E o\ufffdo\ufffdo~1km1\ufffdv\nFl\u20act~kmt\nK\ufffd|{\ufffd\ufffd~o \ufffd{yontk m{z\ufffdoz\ufffd t\ufffdkzty|{~\ufffdkz\ufffd m{y|{zoz\ufffd {q{|tzt{z q{~yk\ufffdt{z k~{\ufffdzn mwtyk\ufffdo\nmskzro1 Vzwtzo \ufffd{mtkw yontk \ufffd\ufffdms k\ufffd\\\ufffdt\ufffd\ufffdo~. \ufffdsoq{m\ufffd\ufffd {q\ufffdst\ufffd\ufffd\ufffd\ufffdn\ufffd. |~{\ufffdtno kzk\ufffdoz\ufffdo \ufffd{\n\ufffd\ufffd\ufffdn\ufffd |\ufffdlwtm ozrkroyoz\ufffd kznntrt\ufffdkw yontk nt\ufffd\ufffdoytzk\ufffdt{z ~owk\ufffdon \ufffd{mwtyk\ufffdo mskzro1 [sk~/\ntzrkwtzv\ufffd{kz{zwtzo k~\ufffdtmwo t\ufffdkztzntmk\ufffd{~ {qyontk ozrkroyoz\ufffd1 Frr~ork\ufffdon wtzv/\ufffdsk~tzr\nq{~y\ufffd kzo\ufffd\ufffd{~v \ufffd\ufffd~\ufffdm\ufffd\ufffd~o \ufffdstms yk|\ufffd m{wwom\ufffdt\ufffdo yontk ozrkroyoz\ufffd l\ufffd\ufffdso\ufffd\ufffdo~ |{|\ufffdwk\ufffdt{z1\nNo~o \ufffdom{z\ufffd\ufffd~\ufffdm\ufffd lt|k~\ufffdt\ufffdo zo\ufffd\ufffd{~v\ufffd wtzvtzr \\\ufffdt\ufffd\ufffdo~ \ufffd\ufffdo~\ufffd \ufffd{\ufffdso\ufffdol |kro\ufffd \ufffdso\ufffd \ufffdsk~on.\n\ufffd\ufffdtzr knk\ufffdk\ufffdo\ufffd {qk||~{\ufffdtyk\ufffdow\ufffd 916ytwwt{z Kzrwt\ufffds/wkzr\ufffdkro \ufffd\ufffdoo\ufffd\ufffd l\ufffdkwy{\ufffd\ufffd 5ytwwt{z\n\ufffd\ufffdo~\ufffd n\ufffd~tzr kzo\ufffdoz\ufffdq\ufffdw \ufffdo\ufffdoz/\ufffdoov |o~t{n moz\ufffd~on {z\ufffdsokzz{\ufffdzmoyoz\ufffd {q\ufffdso][\ufffdt\ufffds/\nn~k\ufffdkw q~{y \ufffdsoWk~t\ufffd Fr~ooyoz\ufffd {zmwtyk\ufffdo mskzro1 I{yy\ufffdzt \ufffd\ufffdno\ufffdom\ufffdt{z tzntmk\ufffdo\ufffd \ufffdsk\ufffd\n\ufffdso{l\ufffdo~\ufffdon tzq{~yk\ufffdt{z/\ufffds k~tzr zo\ufffd\ufffd{~v mkzlo|k~\ufffdt\ufffdt{zon tz\ufffd{\ufffd\ufffd{\ufffdokvw\ufffd m{zzom\ufffdon\nm{y|{zoz\ufffd\ufffd. ~o|~o\ufffdoz\ufffdtzr \ufffd\ufffdl\ufffdo\ufffd\ufffd {qk~\ufffdtmwo\ufffd \ufffdsk~on l\ufffdkr~{\ufffd| {q\ufffd\ufffdo~\ufffd1 _omsk~km\ufffdo~t\ufffdo\n\ufffdso\ufffdo |k~\ufffdt\ufffdt{z\ufffd \ufffds~{\ufffdrs kzkw\ufffd\ufffdt\ufffd {q\ufffdol n{yktz\ufffd kzn\ufffdo\ufffd\ufffdm{z\ufffdoz\ufffd q~{y \ufffdsk~on k~\ufffdtmwo\ufffd. qtzn/\ntzr\ufffdsoy \ufffd{lol~{knw\ufffd no\ufffdm~tlon k\ufffdkwoq\ufffd/\ufffdtzr2oz\ufffdt~{z yoz\ufffdkwt\ufffd\ufffd r~{\ufffd| kznk~trs\ufffd/\ufffdtzr2mwt/\nyk\ufffdo \ufffdmo|\ufffdtm r~{\ufffd|1 I{~~owk\ufffdt{z kzkw\ufffd\ufffdt\ufffd \ufffds{\ufffd\ufffd k\ufffd\ufffd~tvtzr |{\ufffdt\ufffdt\ufffdo k\ufffd\ufffd{mtk\ufffdt{z lo\ufffd\ufffdooz woq\ufffd2\n~trs\ufffd |{wt\ufffdtmkw tno{w{r\ufffd kznoz\ufffdt~{zyoz \ufffdkwt\ufffd\ufffd2\ufffdmo|\ufffdtm mwtyk\ufffdo tno{w{r\ufffd ~o\ufffd|om\ufffdt\ufffdow\ufffd1 S{{vtzr\nk\ufffdtzq{~yk\ufffdt{z/\ufffds k~tzr {\ufffdo~ \ufffdtyo. \ufffdso~o t\ufffdm{z\ufffdtno~klwo \ufffd\ufffd~z{\ufffdo~ tz\ufffdsoozrkron \ufffd\ufffdo~ |{|\ufffdwk/\n\ufffdt{zkzn\ufffdsok~\ufffdtmwo\ufffd \ufffdsk\ufffdk~o\ufffdsk~on. l\ufffd\ufffd\ufffdso\ufffdol n{yktz \ufffd{\ufffd~mo\ufffd kzn|{wk~t\ufffdon zo\ufffd\ufffd{~v\n\ufffd\ufffd~\ufffdm\ufffd\ufffd~o k~o~owk\ufffdt\ufffdow\ufffd |o~\ufffdt\ufffd\ufffdoz\ufffd1 \\st\ufffd \ufffd\ufffd\ufffdn\ufffd |~{\ufffdtno\ufffd o\ufffdtnozmo \ufffdsk\ufffd{zwtzo \ufffdsk~tzr {qzo\ufffd\ufffd\nyontk m{z\ufffdoz\ufffd ~owk\ufffdon \ufffd{mwtyk\ufffdo mskzro t\ufffdl{\ufffds |{wk~t\ufffdon kzn|{wt\ufffdtmt\ufffdon. \ufffdt\ufffds ty|wtmk\ufffdt{z\ufffd\nq{~{|tzt{z n\ufffdzkytm\ufffd kzn|\ufffdlwtm nolk\ufffdo k~{\ufffdzn \ufffdst\ufffdty|{~\ufffdkz\ufffd \ufffd{mto\ufffdkw mskwwozro1\nOz\ufffd~{n\ufffdm\ufffdt{z\nOz\u20ac|t\ufffdo {q\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac {z\ufffdsomk\ufffd\u20aco\u20ac kzn |~tyk~\u00de oqqom\ufffd\u20ac {qmwtyk\ufffdo mskzro. t\ufffd~oyktz\u20ac\nkm{z\ufffd~{\ufffdo~\u20actkw \ufffd{|tm tz|\ufffdlwtm kzn |{wt\ufffdtmkw nt\u20acm{\ufffd~\u20aco1 [\ufffd~\ufffdo\u00de\u20ac sk\ufffdo w{zr \u20acs{\u00d0z \u20ac\ufffdl\u20ac\ufffdkz\ufffdtkw\n\ufffdk~tk\ufffdt{z tz|\ufffdlwtm lowtoq\u20ac k~{\ufffdzn mwtyk\ufffdo mskzro *q{~ o\u00f0ky|wo d4.5f+kzn \ufffdsowo\ufffdow {q|{wk~t\u20ack/\n\ufffdt{z lo\ufffd\u00d0ooz tznt\ufffdtn\ufffdkw\u20ac \u20ac\ufffd||{~\ufffdtzr kzn {||{\u20actzr km\ufffdt{z \ufffd{yt\ufffdtrk\ufffdo kz\ufffds~{|{roztm mwtyk\ufffdo\nmskzro sk\u20aclooz r~{\u00d0tzr d6f1Tontk m{\ufffdo~kro {qmwtyk\ufffdo \u20acmtozmo kzn \ufffdsoq~kyo\u20ac \ufffd\u20acon \ufffd{|~o\u20acoz\ufffd\n\ufffdsotzq{~yk\ufffdt{z mkzsk\ufffdo kzty|{~\ufffdkz\ufffd ty|km\ufffd {z|\ufffdlwtm |o~mo|\ufffdt{z\u20ac kzn \u00d0twwtzrzo\u20ac\u20ac \ufffd{\ufffdkvo\nkm\ufffdt{z d7f.|~o\u20acoz\ufffd ntqqo~oz\ufffd y{\ufffdt\ufffdk\ufffdt{z\u20ac kzn mkww\u20ac q{~km\ufffdt{z d9fkzn tzqw\ufffdozmo \ufffdsokmm\ufffd~km\u00de kzn\nPLOS ONE\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 4259k4444444444\nk4444444444\nk4444444444\nk4444444444\nk4444444444\nOPEN ACCESS\nIt\ufffdk\ufffdt{z> Ikzz \\QG._ok\ufffdo~ O[._twwtky\ufffd N\\W\n*5354+ Ono{w{rtmkw ltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo\ntzq{~yk\ufffdt{z kl{\ufffd\ufffd mwtyk\ufffdo mskzro1 WS{[ VUK\n4:*7+> o3593:9:1 s\ufffd\ufffd|\ufffd>22 n{t1{~r243146;4 2u{\ufffd~zkw1\n|{zo13593:9 :\nKnt\ufffd{~> Qk~{\ufffd\u00f8k\ufffd Qkzv{\ufffd\ufffdvt. _o\ufffd\ufffd W{yo~kztk z\n]zt\ufffdo~\ufffdt\ufffd\ufffd {q\\omsz{w{r\ufffd. WVSFU J\nZomot\ufffdon> F\ufffdr\ufffd\ufffd\ufffd 7.5353\nFmmo|\ufffdon> F|~tw 45.5354\nW\ufffdlwt\ufffdson> F|~tw 56.5354\nI{|\ufffd~trs\ufffd> \u00a95354 Ikzz o\ufffdkw1\\st\ufffdt\ufffdkz{|oz\nkmmo\ufffd\ufffd k~\ufffdtmwo nt\ufffd\ufffd~tl\ufffd\ufffdon \ufffdzno~ \ufffdso\ufffdo~y\ufffd {q\ufffdso\nI~ok\ufffdt\ufffdo I{yy{z\ufffd F\ufffd\ufffd~tl\ufffd\ufffdt{z Stmoz\ufffdo. \ufffdstms\n|o~yt\ufffd\ufffd \ufffdz~o\ufffd\ufffd~tm\ufffdo n\ufffd\ufffdo.nt\ufffd\ufffd~tl\ufffd \ufffdt{z.kzn\n~o|~{n\ufffdm\ufffdt{z tzkz\ufffdyont\ufffdy. |~{\ufffdtnon \ufffdso{~trtzkw\nk\ufffd\ufffds{~ kzn\ufffd{\ufffd~mo k~om~ont\ufffdon1\nJk\ufffdk F\ufffdktwkltwt\ufffd \ufffd[\ufffdk\ufffdoyoz\ufffd> \\soo\ufffd\ufffdo~zkw nk\ufffdk\n\ufffd\ufffdon tz\ufffdst\ufffd\ufffd\ufffd\ufffdn\ufffd *\\\ufffdt\ufffd\ufffdo~ |{\ufffd\ufffd\ufffd. zo\ufffd\ufffd k~\ufffdtmwo\ufffd+\n\ufffdk\ufffd|\ufffdlwtmw\ufffd k\ufffdktwklwo \ufffdsoz \ufffdso\ufffd\ufffd\ufffdn\ufffd \ufffdk\ufffdmk~~ton\n{\ufffd\ufffd.l\ufffd\ufffd\ufffdtzmo \ufffdso{~trtzkw nk\ufffdkt\ufffd{\ufffdzon l\ufffd\ufffdst~n\n|k~\ufffdto\ufffd \ufffdomkzz{\ufffd |\ufffdlwt\ufffds \ufffdsom{y|wo\ufffdo nk\ufffdk\ufffdo\ufffd\n\ufffdt\ufffds{\ufffd\ufffd tzq~tzrtzr \\o~y\ufffd {q]\ufffdo*\\\ufffdt\ufffd\ufffdo~+ {~\nm{|\ufffd~trs\ufffd *zo\ufffd\ufffd k~\ufffdtmwo\ufffd+1 Oz\ufffd\ufffdokn \ufffdosk\ufffdo ykno\nk\ufffdktwklwo wt\ufffd\ufffd\ufffd{q\ufffd{\ufffd~mo\ufffd *\ufffd\ufffdoo\ufffd OJ\ufffd.zo\ufffd\ufffd k~\ufffdtmwo\n]ZS\ufffd+ \ufffd{\ufffdsk\ufffdtz\ufffdo~o\ufffd\ufffdon |k~\ufffdto\ufffd mkz~o|~{n\ufffdmo {\ufffd~\n\ufffd{~v1 L\ufffdwwno\ufffdktw\ufffd {q\ufffdsonk\ufffdk\ufffdo\ufffd kznk\ufffdktwkltwt\ufffd\ufffd k~o\nrt\ufffdoz low{\ufffd1 Ltr\ufffdsk~o ~o|{\ufffdt\ufffd{~\ufffd *s\ufffd\ufffd|>22n{t1 {~r2431\n:3<72y=1qt r\ufffdsk~o146997 9=3+ sk\ufffdlooz m~ok\ufffdon\n\ufffdt\ufffds\ufffdsonk\ufffdk~o}\ufffdt~on \ufffd{~o|~{n\ufffdmo {\ufffd~~o\ufffd\ufffdw\ufffd\ufffd1\nw{zro\ufffdt\ufffd\u00de {q~o|~{n\ufffdmon yo\u20ac\u20ackro\u20ac d:f1Zomoz\ufffd \u00d0{~v sk\u20ac\u20acs{\u00d0z \ufffdsk\ufffd yontk oqqom\ufffd\u20ac \ufffdk~\u00de no|ozn/\ntzr{zo\u00f0t\u20ac\ufffdtzr |{wt\ufffdtmkw ltk\u20aco\u20ac d;f1]zno~\u20ac\ufffdkzntzr \ufffdsoyontk wkzn\u20acmk|o k~{\ufffdzn mwtyk\ufffdo mskzro\nt\u20ac{qvo\u00dety|{~\ufffdkzmo tzyk||tzr |\ufffdlwtm ozrkroyoz\ufffd \u00d0t\ufffds \ufffdsot\u20ac\u20ac\ufffdo kzn \u20ac\ufffd||{~\ufffd q{~|{wt\ufffdtmkw\nkm\ufffdt{z\u20ac \ufffd{m{zq~{z\ufffd t\ufffd1\nF\u20ac\u20aco\u20ac\u20actzr \u00d0stms |o{|wo k~oo\u00f0|{\u20acon \ufffd{\u00d0sk\ufffd tzq{~yk\ufffdt{z t\u20acq\ufffdznkyoz\ufffdkw \ufffd{kz\u00de\u20ac\ufffd\ufffdn\u00de {q\ufffdso\noqqom\ufffd\u20ac {qyontk {z|\ufffdlwtm \ufffdzno~\u20ac\ufffdkzntzr kzn {|tzt{z1 \\so nt\u20ac~\ufffd|\ufffdt\ufffdo ty|km\ufffd {q{zwtzo yontk\nsk\u20ac\ufffd~kz\u20acq{~yon \ufffdsoyontk oz\ufffdt~{zyoz\ufffd. ~kntmkww\u00de kw\ufffdo~tzr \ufffdsont\ufffdo~\u20act\ufffd\u00de {qm{z\ufffdoz\ufffd |o{|wo\nozm{\ufffdz\ufffdo~ k\u20ac\u00d0oww k\u20ac\ufffdsoo\u00f0|{\u20ac\ufffd~o |~{mo\u20ac\u20ac t\ufffd\u20acowq1 Oznt\ufffdtn\ufffdkw\u20ac k~oqkmon \u00d0t\ufffds k\u00d0tno ~kzro {q\nyontk {|\ufffdt{z\u20ac *l{\ufffds \u20ac{mtkw kzn \ufffd~knt\ufffdt{zkw+. zo\u00d0 |k\ufffd\ufffdo~z\u20ac {qo\u00f0|{\u20ac\ufffd~o *\u20acowom\ufffdon l\u00de\ufffdsoozn \ufffd\u20aco~\n{~n~t\ufffdoz l\u00de\ufffdsot~ \u20ac{mtkw zo\ufffd\u00d0{~v+ kzn tzm~ok\u20acon |~{n\ufffdm\ufffdt{z {q\ufffd\u20aco~/rozo~k\ufffdon m{z\ufffdoz\ufffd d<f1\nW~o\ufffdt{\ufffd\u20ac \u00d0{~v tz\ufffdst\u20ack~ok sk\u20acq{m\ufffd\u20acon {z\ufffdsooqqom\ufffd\u20ac {qtzmtnoz\ufffdkw o\u00f0|{\u20ac\ufffd~o {zyontk k\u00d0k~o/\nzo\u20ac\u20ac *o1r1 d=f+ kzn \ufffdsont\ufffdo~\u20act\ufffd\u00de |~o\u20acoz\ufffdon l\u00de{zwtzo ~om{yyozno~ \u20ac\u00de\u20ac\ufffdoy\u20ac *o1r1 d43f+1 [\ufffdms\noqq{~\ufffd\u20ac k~osky|o~on l\u00de\ufffdsont\ufffdo~\u20act\ufffd\u00de {q{zwtzo |wk\ufffdq{~y\u20ac. \ufffdso~k|tn |kmo {q\ufffdsot~ no\ufffdow{|yoz\ufffd\nkzn \ufffdso{lq\ufffd\u20acmk\ufffdt{z {q\ufffdsokwr{~t\ufffdsytm |~{mo\u20ac\u20aco\u20ac \ufffdso\u00de q{ww{\u00d0. kzn k\u20ack~o\u20ac\ufffdw\ufffd z{\ufffdzt\ufffdo~\u20ackw\n\ufffdzno~\u20ac\ufffdkzntzr {qo\u00f0|{\u20ac\ufffd~o oqqom\ufffd\u20ac t\u20ac|{\u20ac\u20actlwo1 _so\ufffdso~ kztznt\ufffdtn\ufffdkw t\u20acm{z\u20ac\ufffdytzr \ufffdsozo\u00d0\u20ac\n{zwtzo q~{y kworkm\u00de yontk {~rkzt\u20ack\ufffdt{z. {~|~{n\ufffdmtzr kzn m{z\u20ac\ufffdytzr tzq{~yk\ufffdt{z {z\u20ac{mtkw\nyontk. \ufffdsoq\ufffdznkyoz\ufffdkw n\u00dezkytm {qm{yy\ufffdztmk\ufffdt{z o\u00f0|{\u20ac\ufffd~o kzn tzqw\ufffdozmo t\u20ac\ufffdsk\ufffd {qzo\ufffd\u00d0{~v\nq{~yk\ufffdt{z d44f. lk\u20acon {zm~ok\ufffdt{z {qzo\u00d0 ~owk\ufffdt{z\u20acst|\u20ac lo\ufffd\u00d0ooz \ufffd\u20aco~\u20ac kzn yontk m{z\ufffdoz\ufffd l\u00dek\n\ufffdk~to\ufffd\u00de {qyokz\u20ac *\u20ac\ufffdms k\u20ac\u00d0ol/l~{\u00d0\u20actzr kzn \u20ac{mtkw tzq{~yk\ufffdt{z/\u20acsk~tzr+1 Vzwtzo yontk o\u00f0|{/\n\u20ac\ufffd~o m~ok\ufffdo\u20ac kzo\ufffd\u00d0{~v \ufffdsk\ufffd wtzv\u20ac \u20ac{\ufffd~mo\u20ac kzn m{z\u20ac\ufffdyo~\u20ac {qm{z\ufffdoz\ufffd *z{no\u20ac+ \ufffdtk\ufffdsot~ tz\ufffdo~km/\n\ufffdt{z\u20ac *onro\u20ac+. ~o}\ufffdt~tzr kzo\ufffd\u00d0{~v |o~\u20ac|om\ufffdt\ufffdo q{~t\ufffd\u20ac|~{|o~ \ufffdzno~\u20ac\ufffdkzntzr1\n\\st\u20ac \u20ac\ufffd\ufffdn\u00de kty\u20ac \ufffd{no\u20acm~tlo |k\ufffd\ufffdo~z\u20ac {q\u20acsk~tzr {zwtzo yontk m{z\ufffdoz\ufffd kl{\ufffd\ufffd mwtyk\ufffdo mskzro1\n_stwo km{y|wo\ufffdo ~om{~n {q\ufffd\u20aco~\u20ac) o\u00f0|{\u20ac\ufffd~o \ufffd{ntrt\ufffdkw m{z\ufffdoz\ufffd t\u20ac{zw\u00de |{\u20ac\u20actlwo \ufffdtkkmm\ufffd~k\ufffdo\n\ufffd~kmvtzr {q\u00d0ol l~{\u00d0\u20actzr st\u20ac\ufffd{~to\u20ac. yontk ozrkroyoz\ufffd mkzlotzqo~~on q~{y \ufffdsom{z\ufffdoz\ufffd \ufffd\u20aco~\u20ac\n\u20acsk~o {z\u20ac{mtkw yontk1 [sk~tzr k\u00d0ol k~\ufffdtmwo ~o}\ufffdt~o\u20ac km\ufffdt{z l\u00de\ufffdso\ufffd\u20aco~. kzn mk\ufffd\u20aco\u20ac t\ufffd\ufffd{k||ok~\n{z\ufffdso\u20ac{mtkw yontk qoon\u20ac {qq~tozn\u20ac kzn q{ww{\u00d0o~\u20ac. k\u20ac\u00d0oww k\u20acm{z\ufffd~tl\ufffd\ufffdtzr \ufffd{krr~ork\ufffdo \ufffd~ozn\u20ac.\n{q\ufffdoz kn\ufffdo~\ufffdt\u20acon l\u00de\u20ac{mtkw yontk |wk\ufffdq{~y\u20ac1 \\st\u20ac t\u20ac\ufffd\u20acon \ufffd{tzntmk\ufffdo k\u20actrztqtmkz\ufffdw\u00de strso~ wo\ufffdow\n{qozrkroyoz\ufffd \ufffdskz o\u00f0|{\u20ac\ufffd~o1 [{mtkw \u20acsk~tzr {qm{z\ufffdoz\ufffd tz\u20ac\ufffdkz\ufffdtk\ufffdo\u20ac k|~{y{\ufffdt{z yomskzt\u20acy.\ntzm~ok\u20actzr \ufffdso\ufffdt\u20actltwt\ufffd\u00de {qkz\u00dem{z\ufffdoz\ufffd km~{\u20ac\u20ac k\ufffd\u20aco~)\u20ac \u20ac{mtkw zo\ufffd\u00d0{~v kzn wtvow\u00de tzntmk\ufffdtzr \ufffdsk\ufffd\n\ufffdso\u20acsk~o~ kr~oo\u20ac \u00d0t\ufffds. {~k||~{\ufffdo\u20ac {q.\ufffdsom{z\ufffdoz\ufffd1 \\so\u20aco qkm\ufffd{~\u20ac. kw{zr \u00d0t\ufffds \ufffdsotzm~ok\u20actzr \ufffd\u20aco\n{q\u20ac{mtkw yontk k\u20ack\u20ac{\ufffd~mo {qzo\u00d0\u20ac d45f. yokz \ufffdsk\ufffd \u20ac\ufffd\ufffdn\u00de {qntrt\ufffdkw yontk \u20acsk~tzr mkz|~{\ufffdtno\ntz\u20actrs\ufffd\u20ac tz\ufffd{ s{\u00d0 tzq{~yk\ufffdt{z t\u20ac|~{|krk\ufffdon {zwtzo. tzmw\ufffdntzr ty|{~\ufffdkz\ufffd m{z\ufffdoy|{~k~\u00de t\u20ac\u20ac\ufffdo\u20ac\nwtvomwtyk\ufffdo mskzro1 Oz|k~\ufffdtm\ufffdwk~. _ok\ufffdo~ o\ufffdkw1d46f \u20acs{\u00d0\u20ac \ufffdsk\ufffd zo\ufffd\u00d0{~v kzkw\u00de\u20act\u20ac {q\u20ac\ufffdms |~{|/\nkrk\ufffdt{z |k\ufffd\ufffdo~z\u20ac mkz~o\ufffdokw yokztzrq\ufffdw \u20ac{mtkw \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac {qzo\u00d0\u20ac ozrkroyoz\ufffd kzn m{z\u20ac\ufffdy|\ufffdt{z\nk~{\ufffdzn |{wt\ufffdtmkw o\ufffdoz\ufffd\u20ac1\nNo~o \u00d0o{|o~k\ufffdt{zkwt\u20aco {\ufffd~\u20ac\ufffd\ufffdn\u00de {q{zwtzo tzq{~yk\ufffdt{z/\u20acsk~tzr k~{\ufffdzn mwtyk\ufffdo mskzro l\u00de\no\u00f0kytztzr wtzv/\u20acsk~tzr {z\\\u00d0t\ufffd\ufffdo~1 ]\u20aco~ |{\u20ac\ufffd\u20ac *\ufffd\u00d0oo\ufffd\u20ac+ ~oqo~ozmtzr mwtyk\ufffdo mskzro kzn m{z/\n\ufffdktztzr wtzv\u20ac \ufffd{\u00d0ol m{z\ufffdoz\ufffd *]ZS\u20ac. \u00d0stms k~o{q\ufffdoz ~ozno~on tz\ufffd{ zo\u00d0\u20ac lw\ufffd~l\u20ac {~tykro\u20ac tz\n\ufffdso\\\u00d0t\ufffd\ufffdo~ mwtoz\ufffd+ \u00d0o~o m{wwom\ufffdon q~{y \ufffdso\\\u00d0t\ufffd\ufffdo~ \u20ac{mtkw yontk |wk\ufffdq{~y \ufffdtkt\ufffd\u20ac|\ufffdlwtm FWO1\n\\st\u20ac nk\ufffdk\u20aco\ufffd \u00d0k\u20ac\ufffd\u20acon \ufffd{m{z\u20ac\ufffd~\ufffdm\ufffd lt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v\u20ac wtzvtzr \ufffd\u20aco~\u20ac \ufffd{\ufffdsontrt\ufffdkw yontk \ufffdso\u00de\n\u20acsk~on1 Fzkw\u00de\u20act\u20ac {qzo\ufffd\u00d0{~v \ufffd{|{w{r\u00de qtzn\u20ac \u20ac\ufffd~{zr m{yy\ufffdzt\ufffd\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~o. \u20ac\ufffd||woyoz\ufffdon l\u00de\nm{y|k~t\u20ac{z {q\u20ac{\ufffd~mo n{yktz\u20ac kzn \ufffdo\u00f0\ufffd\ufffdkw m{z\ufffdoz\ufffd {qk~\ufffdtmwo\u20ac \u20acsk~on \u00d0t\ufffdstz okms m{yy\ufffdzt\ufffd\u00de1\nK\u00f0|w{~k\ufffdt{z {qno\ufffdom\ufffdon m{yy\ufffdzt\ufffdto\u20ac tnoz\ufffdtqto\u20ac \u20ac\ufffd~{zr tno{w{rtmkw |{wk~t\u20ack\ufffdt{z \u00d0t\ufffdstz \ufffdso\nzo\u00d0\u20ac/\u20acsk~tzr zo\ufffd\u00d0{~v \u00d0so~o \ufffd\u20aco~\u20ac k~o\u20acor~ork\ufffdon l\u00dent\ufffdo~roz\ufffd {|tzt{z\u20ac. ~k\ufffdso~ \ufffdskz kz{zr{/\ntzr|~{mo\u20ac\u20ac. kzkw\ufffdo~zk\ufffdt\ufffdo noqtzt\ufffdt{z \u00d0stms t\u20acty|{~\ufffdkz\ufffd tz{\ufffdso~ m{z\ufffdo\u00f0\ufffd\u20ac d47f1 V\ufffdo~kww \ufffdso\n~o\u20ac\ufffdw\ufffd\u20ac tzntmk\ufffdo strsw\u00de |{wk~t\u20acon kzn |{wt\ufffdtmt\u20acon ozrkroyoz\ufffd \u00d0t\ufffds \u00d0ol m{z\ufffdoz\ufffd k~{\ufffdzn mwtyk\ufffdo\nmskzro. \u00d0t\ufffds wk~row\u00de \u20acor~ork\ufffdon kzn tno{w{rtmkww\u00de ltk\u20acon m{yy\ufffdzt\ufffdto\u20ac ~omot\ufffdtzr tzq{~yk\ufffdt{z\nq~{y ntqqo~oz\ufffd yontk \u20ac{\ufffd~mo\u20ac1 _onoy{z\u20ac\ufffd~k\ufffdo \ufffdsk\ufffd \ufffdso{l\u20aco~\ufffdon m{~~owk\ufffdt{z lo\ufffd\u00d0ooz |{wt\ufffdtmkw\n\ufffdto\u00d0\u20ac kzn mwtyk\ufffdo mskzro lowtoq\u20ac *o1r1 d6f+ o\u00f0\ufffdozn\u20ac \ufffd{{zwtzo tzq{~yk\ufffdt{z \u20ac{\ufffd~mo\u20ac kzn \ufffdsot~\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 5259L\ufffdzntzr> \\It\ufffdq\ufffdznon l\ufffdkzKW[ZI Zo\ufffdok~ms\n[\ufffd\ufffdnoz\ufffd\ufffds t|*r~kz\ufffd z\ufffdylo~ KW2T93:95 ;24.s\ufffd\ufffd|\ufffd>22\no|\ufffd~m1\ufffdv~t1{~ r2+1O_kznN_kmvz{\ufffdwonro q\ufffdzntzr\nq~{y K[ZI *r~kz\ufffd z\ufffdylo~ K[2U3455<62 4.s\ufffd\ufffd|\ufffd>22\no\ufffd~m1\ufffdv~t1{~ r2+kznUKZI *r~kz\ufffd z\ufffdylo~ UK2\nW34;76:24. s\ufffd\ufffd|\ufffd>22zo~m1\ufffdv ~t1{~r2+1 \\soq\ufffdzno~\ufffd skn\nz{~{wotz\ufffd\ufffd\ufffdn\ufffd no\ufffdtrz. nk\ufffdkm{wwom\ufffdt{z kzn\nkzkw\ufffd\ufffdt\ufffd. nomt\ufffdt{z \ufffd{|\ufffdlwt\ufffds. {~|~o|k~k \ufffdt{z{q\ufffdso\nykz\ufffd\ufffdm~t|\ufffd1\nI{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd >\\sok\ufffd\ufffds{~\ufffd sk\ufffdo nomwk~on\n\ufffdsk\ufffdz{m{y|o\ufffdtzr tz\ufffdo~o\ufffd\ufffd\ufffd o\ufffdt\ufffd\ufffd1\n\u20acsk~on ~okno~\u20acst|\u20ac1 L{~\ufffdsoqt~\u20ac\ufffd \ufffdtyo. \u00d0o\ufffd~kmv zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {\ufffdo~ k;/\u00d0oov |o~t{n. tzmw\ufffdn/\ntzrknt\u20ac~\ufffd|\ufffdt\ufffdo yontk o\ufffdoz\ufffd *\ufffdso kzz{\ufffdzmoyoz\ufffd {q\ufffdso\u00d0t\ufffdsn~k\u00d0kw {q\ufffdso][F q~{y \ufffdsoWk~t\u20ac\nFr~ooyoz\ufffd {zmwtyk\ufffdo mskzro+. \ufffd{\u20acs{\u00d0 \ufffdso|o~\u20act\u20ac\ufffdozmo {q\ufffdso{l\u20aco~\ufffdon |{wk~t\u20ack\ufffdt{z kzn |{wt\ufffdt/\nmt\u20ack\ufffdt{z {qyontk \u20acsk~tzr ~owk\ufffdon \ufffd{mwtyk\ufffdo mskzro {\ufffdo~ \ufffdtyo kzn \u00d0t\ufffds \ufffdk~\u00detzr lkmvr~{\ufffdzn\nwo\ufffdow\u20ac {q|\ufffdlwtm tz\ufffdo~o\u20ac\ufffd1\n[{mtkw yontk nk\ufffdk sk\u20aclooz \ufffd\u20acon \ufffd{\u20ac\ufffd\ufffdn\u00de \u20aco\ufffdo~kw k\u20ac|om\ufffd\u20ac {q|\ufffdlwtm {|tzt{z k~{\ufffdzn mwtyk\ufffdo\nmskzro. tzmw\ufffdntzr k\ufffd\ufffdt\ufffd\ufffdno\u20ac \ufffd{\u00d0k~n\u20ac kzn ozrkroyoz\ufffd \u00d0t\ufffds mwtyk\ufffdo mskzro yt\ufffdtrk\ufffdt{z \u20ac\ufffd~k\ufffdorto\u20ac\nd49f. yontk q~kytzr {q\ufffdsowokvon \ufffdIwtyk\ufffdork\ufffdo\ufffd oyktw\u20ac {zb{\ufffd\\\ufffdlo d9f.kzn \ufffdso\u20ac|~okntzr {q\nmkww\u20ac q{~m{wwom\ufffdt\ufffdo km\ufffdt{z k\ufffd\ufffdsoIVW49 m{zqo~ozmo d4:f1 Uo\ufffd\u00d0{~v\u20ac k~okztz\ufffd\ufffdt\ufffdt\ufffdo ~o|~o\u20acoz\ufffdk/\n\ufffdt{z. kzn m{yo \u00d0t\ufffds ks{\u20ac\ufffd {qkzkw\u00de\ufffdtmkw \ufffd{{w\u20ac \ufffd{\ufffdzno~\u20ac\ufffdkzn \ufffdso\u20acsk|o {q{zwtzo nt\u20acm\ufffd\u20ac\u20act{z\u20ac\nk~{\ufffdzn mwtyk\ufffdo mskzro? q{~o\u00f0ky|wo Kwro\u20acoy o\ufffdkw1d4;f o\u00f0|w{~o \ufffdsozo\ufffd\u00d0{~v {qs\u00de|o~wtzv\u20ac\nlo\ufffd\u00d0ooz lw{r\u20ac. \u00d0stwo _twwtky\u20ac o\ufffdkw1d4<f \u20ac\ufffd\ufffdn\u00de \ufffdso\u20ac\ufffd~\ufffdm\ufffd\ufffd~o {qq{ww{\u00d0o~. ~o\ufffd\u00d0oo\ufffd kzn yoz\ufffdt{z\nzo\ufffd\u00d0{~v\u20ac {z\\\u00d0t\ufffd\ufffdo~1 Ozl{\ufffds {q\ufffdso\u20aco \u20ac\ufffd\ufffdnto\u20ac. \ufffd\u20aco~ m{yy\ufffdzt\ufffdto\u20ac ykztqo\u20ac\ufffd k\u20acnoz\u20acow\u00de tz\ufffdo~m{z/\nzom\ufffdon mw\ufffd\u20ac\ufffdo~\u20ac \u00d0t\ufffds \u20actytwk~ msk~km\ufffdo~t\u20ac\ufffdtm\u20ac1 \\so\u20aco m{yy\ufffdzt\ufffdto\u20ac k~ostrsw\u00de |{wk~t\u20acon. \u20ac\ufffdms \ufffdsk\ufffd\nokms m{yy\ufffdzt\ufffd\u00de t\u20ac\u00d0oww no\u20acm~tlon l\u00dek\u20actzrwo \ufffdto\u00d0|{tz\ufffd. \u00d0t\ufffds qo\u00d0y{no~k\ufffdo \ufffd{tmo\u20ac1 [tytwk~ |k\ufffd/\n\ufffdo~z\u20ac sk\ufffdo kw\u20ac{ looz {l\u20aco~\ufffdon q{~{zwtzo |{wt\ufffdtmkw nt\u20acm{\ufffd~\u20aco *o1r1 d4=\u02d857f+1 \\st\u20ac |k\ufffd\ufffdo~z {q{|tz/\nt{z|{wk~t\u20ack\ufffdt{z kzn \u20acor~ork\ufffdt{z sk\u20acty|{~\ufffdkz\ufffd ty|wtmk\ufffdt{z\u20ac q{~{|tzt{z mskzro kzn \ufffdso\nwtvowts{{n {qrw{lkw m{z\u20acoz\u20ac\ufffd\u20ac d59f1 W{wk~t\u20ack\ufffdt{z tz{zwtzo \u20ac{mtkw yontk t\u20acy{\u20ac\ufffd q~o}\ufffdoz\ufffdw\u00de \u20ac\ufffd\ufffdn/\ntontz\ufffdso|{wt\ufffdtmkw \u20ac|so~o. o\u20ac|omtkww\u00de q{~\ufffd\u00d0{/|k~\ufffd\u00de |{wt\ufffdtmkw \u20ac\u00de\u20ac\ufffdoy\u20ac \u00d0t\ufffds kztno{w{rtmkw \u20ac|wt\ufffd\nkw{zr kwoq\ufffd/~trs\ufffd k\u00f0t\u20ac1 N{\u00d0o\ufffdo~. \ufffdso|soz{yoz{z kw\u20ac{ o\u00f0\ufffdozn\u20ac \ufffd{\ufffdsom{y|o\ufffdtzr {|tzt{z\u20ac\nk~{\ufffdzn mwtyk\ufffdo mskzro. \u00d0stms k~o{q\ufffdoz \u20acty|wtqton k\u20acknolk\ufffdo lo\ufffd\u00d0ooz oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd\u20ac *\u20ac\ufffd|/\n|{~\ufffdtzr \ufffdso\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac kzn |~{y{\ufffdtzr km\ufffdt{z+ kzn \u20acmo|\ufffdtm\u20ac *n{\ufffdl\ufffdtzr {~{||{\u20actzr \ufffdso\nm{z\u20acoz\u20ac\ufffd\u20ac kzn zoon q{~km\ufffdt{z+. z{\ufffd\u00d0t\ufffds\u20ac\ufffdkzntzr \ufffdsont\ufffdo~\u20act\ufffd\u00de {q\ufffdto\u00d0|{tz\ufffd\u20ac kzn ~o|~o\u20acoz\ufffdk/\n\ufffdt{z\u20ac {q\ufffdst\u20acm{y|wo\u00f0 t\u20ac\u20ac\ufffdo d5:f1 \\so\u20aco |~o\ufffdt{\ufffd\u20ac zo\ufffd\u00d0{~v/lk\u20acon \u20ac\ufffd\ufffdnto\u20ac rozo~kww\u00de \ufffd~ok\ufffd nk\ufffdk\u20aco\ufffd\u20ac\nk\u20ac\u20actzrwo \u20aczk|\u20acs{\ufffd\u20ac. kw{zr \u00d0t\ufffds \ufffdsoty|wtmt\ufffd k\u20ac\u20ac\ufffdy|\ufffdt{z \ufffdsk\ufffd \ufffdso|soz{yozk \ufffdzno~ \u20ac\ufffd\ufffdn\u00de \ufffdk~to\u20ac\n\u20acw{\u00d0w\u00de1 \\so tz\ufffdo~\ufffdkw\u20ac \u20ac\ufffd\ufffdnton ~kzro q~{y y{z\ufffds\u20ac \ufffd{\u00deok~\u20ac. l\ufffd\ufffdl\u00dems{{\u20actzr \u20ac\ufffdms k\ufffdtyo\u20acmkwo t\ufffdt\u20ac\n|{\u20ac\u20actlwo \ufffd{{\ufffdo~w{{v \ufffdsomskzro\u20ac \ufffdsk\ufffd \u20ac{mtkw zo\ufffd\u00d0{~v\u20ac mkzo\u00f0|o~tozmo tz\u20acs{~\ufffdo~ |o~t{n\u20ac1\n\\so |k\ufffd\ufffdo~z {q|{wk~t\u20ack\ufffdt{z tzl{\ufffds |{wt\ufffdtmkw kzn mwtyk\ufffdo mskzro m{z\ufffdo\u00f0\ufffd\u20ac t\u20ac{q\ufffdoz k\u20ac\u20ac{mtk\ufffdon\n\u00d0t\ufffds \ufffdsoo\u00f0t\u20ac\ufffdozmo {qoms{ mskylo~\u20ac tz\ufffdso\u20ac{mtkw yontk om{\u20ac\u00de\u20ac\ufffdoy. \u00d0so~ol\u00de \ufffd\u20aco~\u20ac ms{{\u20aco \ufffd{\nk\u20ac\u20ac{mtk\ufffdo \u00d0t\ufffds |o{|wo kzn zo\u00d0\u20ac/yontk \u20ac{\ufffd~mo\u20ac \u00d0stms m{zq{~y \ufffd{kzn ~otzq{~mo \ufffdsot~ o\u00f0t\u20ac\ufffdtzr\nlowtoq\u20ac d4<f1 Kms{ mskylo~\u20ac sk\ufffdo looz |~{|{\u20acon \ufffd{m{z\ufffd~tl\ufffd\ufffdo \ufffd{\ufffdso\u20ac|~okntzr {qyt\u20actzq{~yk/\n\ufffdt{z d5;f. |{wt\ufffdtmkw zo\ufffd\u00d0{~v\u20ac {qoz\ufffdt~{zyoz\ufffdkw km\ufffd{~\u20ac d5<f. o\u00f0|{\u20ac\ufffd~o \ufffd{|{wt\ufffdtmkw tzq{~yk\ufffdt{z {z\n\u20ac{mtkw yontk d54f. kzn {zwtzo m{z\ufffdoz\ufffd k~{\ufffdzn mwtyk\ufffdo mskzro *o1r1 d4;. 4<.5=f+1 Oz\ufffdst\u20ac\u00d0{~v \u00d0o\nq{m\ufffd\u20ac {z\ufffdso\u20ac\ufffd~\ufffdm\ufffd\ufffd~kw |soz{yoz{z {qoms{ mskylo~\u20ac l\ufffd\ufffd{\ufffdso~ \u20acms{wk~\u20ac sk\ufffdo w{{von k\ufffds{\u00d0\n\ufffdso\u00de k~owtzvon \ufffd{|\u20ac\u00dems{w{rtmkw |~{mo\u20ac\u20aco\u20ac \u20ac\ufffdms k\u20acm{zqt~yk\ufffdt{z ltk\u20ac *o1r1 d63f+1\nW~o\ufffdt{\ufffd\u20ac \u20ac\ufffd\ufffdnto\u20ac {qtzq{~yk\ufffdt{z/\u20acsk~tzr k~{\ufffdzn mwtyk\ufffdo mskzro sk\ufffdo q{m\ufffd\u20acon {z\ufffdso|~{yt/\nzozmo {qntqqo~oz\ufffd \u20ac{\ufffd~mo\u20ac1 Uo\u00d0ykz d64f kzkw\u00de\u20acon \ufffdso\ufffd\u00d0oo\ufffd\u20ac kzn tzq{~yk\ufffdt{z \u20ac{\ufffd~mo\u20ac \u20acsk~on\nkw{zr\u20actno \ufffdso~owok\u20aco {q\ufffdsoOWII FZ9 _M4 ~o|{~\ufffd. qtzntzr kq{m\ufffd\u20ac {z\ufffdso|\ufffdlwtm ozrkroyoz\ufffd\n\u00d0t\ufffds \u20acmtozmo. kzn kn{ytzkzmo {qyktz\u20ac\ufffd~oky yontk \u20ac{\ufffd~mo\u20ac1 [oro~lo~r kzn Gozzo\ufffd\ufffd d4:f\no\u00f0kytzon \ufffdsol~okvn{\u00d0z {qntqqo~oz\ufffd wtzv \u20ac{\ufffd~mo\u20ac \ufffd\u20acon kw{zr\u20actno mkww\u20ac \ufffd{m{wwom\ufffdt\ufffdo km\ufffdt{z k\ufffd\n\ufffdsoIVW49 m{zqo~ozmo1 Rt~twozv{ kzn [\ufffdo|msozv{\ufffdk d65f \u20ac\ufffd\ufffdnton \ufffdso]ZS\u20ac \u20acsk~on {z\\\u00d0t\ufffd\ufffdo~\n{\ufffdo~ \ufffdsom{\ufffd~\u20aco {q{zo\u00deok~ tzqt\ufffdontqqo~oz\ufffd wkzr\ufffdkro\u20ac. qtzntzr \ufffdsk\ufffd l\u00dem{\ufffdz\ufffd~\u00de. \ufffdso][n{yt/\nzk\ufffdon \ufffd{\ufffdkw \ufffd\u00d0oo\ufffd m{\ufffdz\ufffd\u20ac. kzn kyt\u00f0 {q\ufffd~knt\ufffdt{zkw yontk. km\ufffdt\ufffdt\u20ac\ufffd kzn \u20acmo|\ufffdtm \u20act\ufffdo\u20ac \u00d0o~o \u20acsk~on1\nW{wk~t\u20ack\ufffdt{z t\u20ackm{yy{z {l\u20aco~\ufffdk\ufffdt{z tz\ufffdsomwtyk\ufffdo mskzro nolk\ufffdo1 U{\ufffdklwo \u20ac\ufffd\ufffdnto\u20ac \u20ac\ufffdms k\u20ac\nJ\ufffdzwk| o\ufffdkw1d6fsk\ufffdo \u20acs{\u00d0z \ufffdsk\ufffd \ufffdso|{wk~t\u20ack\ufffdt{z oqqom\ufffd tzmwtyk\ufffdo mskzro {|tzt{z sk\u20acr~{\u00d0z\nlo\ufffd\u00d0ooz 4==; kzn 534:1 Fzty|km\ufffd {q|{wk~t\u20ack\ufffdt{z mkzlo{l\u20aco~\ufffdon tz\ufffdsoq~kyo\u20ac \ufffd\u20acon \ufffd{nt\u20ac/\nm\ufffd\u20ac\u20ac mwtyk\ufffdo mskzro. \u20ac\ufffdms k\u20acl\u00deQkzr kzn Nk~\ufffd d66f. \u00d0s{ kzkw\u00de\u20acon \ufffdso\ufffdsoyo\u20ac |~o\u20acoz\ufffd tz\\\u00d0t\ufffd/\n\ufffdo~)\u20ac mwtyk\ufffdo mskzro nolk\ufffdo km~{\u20ac\u20ac \ufffd\u00d0{\u00deok~\u20ac1 \\so\u00de q{\ufffdzn ntqqo~ozmo\u20ac tz\ufffdso\ufffdo~ytz{w{r\u00de \ufffd\u20acon\nl\u00de{||{\u20actzr r~{\ufffd|\u20ac. \u00d0t\ufffds Zo|\ufffdlwtmkz/wokztzr \u20ac\ufffdk\ufffdo\u20ac tz\ufffdso][\ufffd\u20actzrglobalwarming tz\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 6259\n|~oqo~ozmo \ufffd{climatechange. kzn {q\ufffdoz \ufffd\u20actzr s{k\u00f0 q~kyo\u20ac \ufffd{mk\u20ac\ufffd n{\ufffdl\ufffd {z\ufffdso\u20acmtoz\ufffdtqtm m{z/\n\u20acoz\u20ac\ufffd\u20ac1 V)Uotww o\ufffdkw1d67f q{\ufffdzn \ufffdsk\ufffd \ufffdst\u20ac\ufffd~ozn o\u00f0\ufffdoznon \ufffd{\ufffdsoyontk m{\ufffdo~kro {q\ufffdso|\ufffdlwtmk/\n\ufffdt{z {q\ufffdsoOWII FZ9 \u00d0{~vtzr r~{\ufffd| ~o|{~\ufffd\u20ac1 G\u00de\u20ac\ufffd\ufffdn\u00detzr \ufffdsoq~kyo\u20ac \ufffd\u20acon tzzo\u00d0\u20ac|k|o~ kzn\n\ufffdowo\ufffdt\u20act{z l~{knmk\u20ac\ufffd\u20ac. \ufffdso\u00de q{\ufffdzn mwok~ |~oqo~ozmo\u20ac q{~ntqqo~oz\ufffd q~kyo\u20ac ky{zr\u20ac\ufffd \ufffdso\ufffdk~t{\ufffd\u20ac\nzo\u00d0\u20ac {~rkzt\u20ack\ufffdt{z\u20ac1 [{yo \u00d0{~v sk\u20acw{{von k\ufffdm{\ufffdz\ufffdo~tzr \ufffdsor~{\u00d0tzr wo\ufffdow\u20ac {q|{wk~t\u20ack\ufffdt{z.\ntzmw\ufffdntzr cskzr o\ufffdkw1d;f\u00d0s{ \u20ac\ufffd\ufffdn\u00de \ufffdsooqqom\ufffd {qmwk~tq\u00detzr yo\u20ac\u20ackro\u20ac {zkmm\ufffd~km\u00de {\ufffdo~ \ufffdso|o~/\nmot\ufffdon wo\ufffdow\u20ac {qm{z\u20acoz\u20ac\ufffd\u20ac ky{zr mwtyk\ufffdo \u20acmtoz\ufffdt\u20ac\ufffd\u20ac1 Fy{zr \ufffdsot~ o\u00f0|o~tyoz\ufffdkw r~{\ufffd|. o\u00f0|{/\n\u20ac\ufffd~o \ufffd{\ufffdsomwk~tq\u00detzr yo\u20ac\u20ackro wokn \ufffd{y{~o \ufffdztq{~y kmm\ufffd~km\u00de k~{\ufffdzn \ufffdso\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac\n\ufffds~{\ufffdrs r~ok\ufffdo~ ty|km\ufffd tz\ufffdsok~ok\u20ac {qw{\u00d0o~ lk\u20acowtzo lowtoq1\n\\so oqqom\ufffd\u20ac {q|{wk~t\u20ack\ufffdt{z n{z{\ufffdkw\u00d0k\u00de\u20ac ykztqo\u20ac\ufffd o}\ufffdkww\u00de {zokms ozn {q\ufffdso{|tzt{z \u20ac|om/\n\ufffd~\ufffdy1 [ms\ufffdwn\ufffd o\ufffdkw1d69f m{y|k~on \ufffdso\ufffd\u20ackro {q\ufffdso\ufffdo~y\u20acclimatechange kznglobalwarming\nkm~{\u20ac\u20ac \ufffdso\u00d0ol\u20act\ufffdo\u20ac {qk\u20aco~to\u20ac {q\ufffdstzv \ufffdkzv\u20ac1 Ztrs\ufffd/\u00d0tzr \ufffdstzv \ufffdkzv\u20ac \u00d0o~o y{~o wtvow\u00de \ufffd{\ufffd\u20aco\nglobalwarming. \u00d0t\ufffds \ufffdso{||{\u20act\ufffdo \ufffd~ozn {l\u20aco~\ufffdon tzwoq\ufffd/\u00d0tzr \ufffdstzv \ufffdkzv\u20ac1 \\so\u20aco qtzntzr\u20ac {q\nm{z\ufffdoz\ufffd ntqqo~ozmo\u20ac q~{y |{wk~t\u20acon \u20ac{\ufffd~mo\u20ac o\u00f0\ufffdozn\u20ac lo\u00de{zn \ufffdsomwtyk\ufffdo mskzro nolk\ufffdo1 L\ufffd~\ufffdso~\nkzkw\u00de\u20act\u20ac {qmwtyk\ufffdo \u20acmo|\ufffdtm {~rkzt\u20ack\ufffdt{z\u20ac kzn \ufffdsot~ q\ufffdzntzr \u20ac{\ufffd~mo\u20ac l\u00deLk~~oww d6:f q{\ufffdzn \u20acsk~on\n\u20ac{\ufffd~mo\u20ac {qq\ufffdzntzr km~{\u20ac\u20ac ykz\u00de {q\ufffdsoy1 Go\u00de{zn \ufffdso\ufffd{|tm {qmwtyk\ufffdo mskzro. L~oow{z o\ufffdkw1\nd6;f |~o\u20acoz\ufffd kz{\ufffdo~\ufffdto\u00d0 {qs{\u00d0 \ufffdsontqqo~oz\ufffd {zwtzo km\ufffdt\ufffdt\u20acy \u20ac\ufffd~k\ufffdorto\u20ac {qwoq\ufffd/ kzn ~trs\ufffd/\u00d0tzr\nr~{\ufffd|\u20ac ykztqo\u20ac\ufffd ntqqo~oz\ufffd \ufffd\u00de|o\u20ac {qm{z\ufffdoz\ufffd kzn k\ufffdntozmo\u20ac1 \\so\u00de strswtrs\ufffd kvo\u00dentqqo~ozmo tz\n\ufffdso|o~mot\ufffdon \u20ac\ufffd~k\ufffdorto\u20ac {q\ufffdsontqqo~oz\ufffd r~{\ufffd|\u20ac1 Soq\ufffd/\u00d0tzr r~{\ufffd|\u20ac \ufffdk~ro\ufffd \ufffdsk\u20acs\ufffdkr km\ufffdt\ufffdt\u20acy\ufffd\nwokntzr \ufffd{\u20ac{mtkw |~{y{\ufffdt{z {qy{\ufffdoyoz\ufffd\u20ac \u00d0so~ok\u20ac ~trs\ufffd/\u00d0tzr r~{\ufffd|\u20ac ozrkro y\ufffdms y{~o\n~okntw\u00de \u00d0t\ufffds \u20ac\u00dey|k\ufffdso\ufffdtm yontk {~rkzt\u20ack\ufffdt{z\u20ac \ufffd{|~{y{\ufffdo \ufffdsot~ yo\u20ac\u20ackro\u20ac kzn r{kw\u20ac1 L~oow{z\no\ufffdkw1kw\u20ac{ ~om{rzt\u20aco k\u20actytwk~ \ufffd~ozn tzr~{\ufffd| m{so~ozmo \u00d0so~o ~trs\ufffd/\u00d0tzr r~{\ufffd|\u20ac k~o\ufffdtrs\ufffdo~\n\u00d0soz m{y|k~on \ufffd{woq\ufffd/\u00d0tzr r~{\ufffd|\u20ac q{~yon q~{y kw{{\u20aco m{kwt\ufffdt{z {qy\ufffdw\ufffdt|wo t\u20ac\u20ac\ufffdo/won r~{\ufffd|\u20ac1\nI{z\u20actno~tzr \ufffdst\u20acm{{~ntzk\ufffdon q\ufffdzntzr {qy\ufffdw\ufffdt|wo r~{\ufffd|\u20ac kzn ozrkroyoz\ufffd \u00d0t\ufffds yontk {~rkzt/\n\u20ack\ufffdt{z\u20ac. t\ufffdt\u20ac\ufffd{loo\u00f0|om\ufffdon \ufffdsk\ufffd mwtyk\ufffdo \u20acmo|\ufffdtm yo\u20ac\u20ackrtzr t\u20acwtvow\u00de \ufffd{loy{~o m{z\u20act\u20ac\ufffdoz\ufffd \ufffdskz\nm{y|o\ufffdtzr oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd tzq{~yk\ufffdt{z1\nFw{zr \u00d0t\ufffds mwtyk\ufffdo mskzro. \u20ac\ufffd\ufffdnto\u20ac {qtzq{~yk\ufffdt{z/\u20acsk~tzr {z\u20ac{mtkw yontk sk\ufffdo oyl~kmon\nknt\ufffdo~\u20act\ufffd\u00de {qntqqo~oz\ufffd \ufffd{|tm\u20ac? [\ufffdk~lt~n d6<f \u20ac\ufffd\ufffdnton \ufffdso\u20ac|~okn {qyt\u20actzq{~yk\ufffdt{z k~{\ufffdzn yk\u20ac\u20ac\n\u20acs{{\ufffdtzr o\ufffdoz\ufffd\u20ac tz\ufffdso]zt\ufffdon [\ufffdk\ufffdo\u20ac. qtzntzr kmw\ufffd\u20ac\ufffdo~ {qkw\ufffdo~zk\ufffdt\ufffdo zo\u00d0\u20ac \u20act\ufffdo\u20ac \u20aco|k~k\ufffdo q~{y\nyktz\u20ac\ufffd~oky yontk \u20ac{\ufffd~mo\u20ac1 F~tq o\ufffdkw1d6=f kzn Jow^tmk~t{ o\ufffdkw1d5;f \u20ac\ufffd\ufffdn\u00de \ufffdso\u20ac|~okntzr\nlosk\ufffdt{\ufffd~ {q~\ufffdy{\ufffd~\u20ac kzn yt\u20actzq{~yk\ufffdt{z {z\\\u00d0t\ufffd\ufffdo~ kzn Lkmol{{v ~o\u20ac|om\ufffdt\ufffdow\u00de kzn mwk\u20ac\u20actq\u00de\n{l\u20aco~\ufffdon \ufffd~ozn\u20ac1 [msytn\ufffd o\ufffdkw1d73f kzkw\u00de\u20aco kzo\ufffd\u00d0{~v {qzo\u00d0\u20ac/~owk\ufffdon |kro\u20ac {zLkmol{{v.\n\u00d0so~o \ufffd\u00d0{|kro\u20ac k~om{zzom\ufffdon tq\ufffdso\u00de sk\ufffdo |{\u20ac\ufffd\u20ac \ufffdsk\ufffd k~owtvon {~m{yyoz\ufffdon {zl\u00de\ufffdso\u20ackyo\n\ufffd\u20aco~1 \\sot~ mw\ufffd\u20ac\ufffdo~ kzkw\u00de\u20act\u20ac ~o\ufffdokw\u20ac kstrsw\u00de |{wk~t\u20acon \u20ac\ufffd~\ufffdm\ufffd\ufffd~o. k\u20ac\u20acooz tzkz\ufffdylo~ {q{\ufffdso~\nm{z\ufffdo\u00f0\ufffd\u20ac *o1r1 d4=f+1 _twwtky\u20ac o\ufffdkw1d74f kw\u20ac{ \u20ac\ufffd\ufffdn\u00de \ufffdsom{yy\ufffdzt\ufffd\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {q|{wt\ufffdtmkw zo\u00d0\u20ac/\n\u20acsk~tzr \ufffdtk\\\u00d0t\ufffd\ufffdo~. qtzntzr m{yy\ufffdzt\ufffdto\u20ac msk~km\ufffdo~t\u20acon l\u00del{\ufffds ro{r~k|stmkw kzn |{wt\ufffdtmkw qkm/\n\ufffd{~\u20ac1 _ok\ufffdo~ o\ufffdkw1d46f o\u00f0kytzon tzq{~yk\ufffdt{z/\u20acsk~tzr {z\\\u00d0t\ufffd\ufffdo~ n\ufffd~tzr \ufffdso]RMozo~kw Kwom/\n\ufffdt{z tz5349. \u20acs{\u00d0tzr \u20ac\ufffd~{zr m{yy\ufffdzt\ufffd\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~o o\u00f0|wktzon l\u00detno{w{rtmkw. ro{r~k|stmkw kzn\n\ufffd{|tmkw |~oqo~ozmo\u20ac1 Kkms {q\ufffdso\u20aco \u20ac\ufffd\ufffdnto\u20ac \u20acs{\ufffdwn lom{z\u20actno~on tz\ufffdsom{z\ufffdo\u00f0\ufffd {q\ufffdso\ufffd\u00de|tmkw\n\u20acsk~o~ kzn \ufffdsotzq{~yk\ufffdt{z \ufffdso\u00de k~oo\u00f0|{\u20acon \ufffd{1U{\ufffd kww\ufffd\u20aco~\u20ac {z\u20ac{mtkw yontk k~oo\u00f0|{\u20acon \ufffd{\n\ufffdso\u20ackyo tzq{~yk\ufffdt{z. kzn \ufffd\u00de|tmkww\u00de \ufffdso\u00de k~oo\u00f0|{\u20acon \ufffd{tzq{~yk\ufffdt{z tz\u00d0stms \ufffdso\u00de sk\ufffdo\nkw~okn\u00de \u20acs{\u00d0z kztz\ufffdo~o\u20ac\ufffd \ufffds~{\ufffdrs \ufffdsot~ {\u00d0z nomt\u20act{z\u20ac {q\u00d0stms \ufffd\u20aco~\u20ac \ufffd{q{ww{\u00d0. kw{zr \u00d0t\ufffds\nkwr{~t\ufffdsytm qtw\ufffdo~tzr oqqom\ufffd\u20ac1 [sk~tzr tzq{~yk\ufffdt{z ~o}\ufffdt~o\u20ac km\ufffdt{z {z\ufffdso\ufffd\u20aco~)\u20ac |k~\ufffd kzn k\u20ac\u20ac\ufffdms\n\ufffds{\u20aco \u00d0s{ ms{{\u20aco \ufffd{\u20acsk~o k~owtvow\u00de |k~\ufffd {qky{~o strsw\u00de tz\ufffdo\u20ac\ufffdon \u20ac\ufffdl\u20aco\ufffd {q\ufffdso\ufffd\u20aco~\u20ac o\u00f0|{\u20acon\n\ufffd{kmo~\ufffdktz |tomo {qtzq{~yk\ufffdt{z1\n\\so ~o\u20ac\ufffd{q\ufffdso|k|o~ |~{moon\u20ac k\u20acq{ww{\u00d0\u20ac1 [om\ufffdt{z To\ufffds{n\u20ac no\ufffdktw\u20ac \ufffdsoyo\ufffds{n {qnk\ufffdk m{wwom/\n\ufffdt{z kzn |~o|k~k\ufffdt{z. kw{zr \u00d0t\ufffds \ufffdso\ufffdomszt}\ufffdo\u20ac \ufffd\u20acon \ufffd{m{z\u20ac\ufffd~\ufffdm\ufffd kzn kzkw\u00de\u20aco \ufffdsotzq{~yk/\n\ufffdt{z/\u20acsk~tzr zo\ufffd\u00d0{~v\u20ac1 V\ufffd~ yktz ~o\u20ac\ufffdw\ufffd\u20ac q{ww{\u00d0 tz[om\ufffdt{z Zo\u20ac\ufffdw\ufffd\u20ac. tzmw\ufffdntzr zo\ufffd\u00d0{~v kzkw\u00de\u20act\u20ac\nkzn msk~km\ufffdo~t\u20ack\ufffdt{z {qm{yy\ufffdzt\ufffd\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac. kzn qtzkww\u00de [om\ufffdt{z Jt\u20acm\ufffd\u20ac\u20act{z |~{\ufffdtno\u20ac k\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 7259\n\ufffds{~{\ufffdrs nt\u20acm\ufffd\u20ac\u20act{z {q\ufffdsoyktz qtzntzr\u20ac {q\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de kzn |wkmo\u20ac \ufffdsoy tz\ufffdso\u00d0tno~ m{z\ufffdo\u00f0\ufffd {q\nyontk oqqom\ufffd\u20ac {z\ufffdsomwtyk\ufffdo mskzro nolk\ufffdo1 Fnnt\ufffdt{zkw nk\ufffdk kzn \ufffdt\u20ac\ufffdkwt\u20ack\ufffdt{z\u20ac mkzloq{\ufffdzn tz\n\ufffdso[4Ltwo1\nTo\ufffds{n\ufffd\n\\\u00d0oo\ufffd m{wwom\ufffdt{z kzn |~o/|~{mo\u20ac\u20actzr\n\\st\u20ac kzkw\u00de\u20act\u20ac \ufffd\u20aco\u20ac \u20aco\ufffdoz \u00d0oov\u20ac {q\\\u00d0t\ufffd\ufffdo~ nk\ufffdk m{wwom\ufffdon q~{y \ufffdso[\ufffd~okytzr FWO d75f1 \\\u00d0oo\ufffd\u20ac\nm{z\ufffdktztzr \ufffdso\u20ac\ufffd~tzr\u20acclimatechange {~globalwarming \u00d0o~o m{wwom\ufffdon lo\ufffd\u00d0ooz 534;/39/43\nkzn 534;/3:/5;. rt\ufffdtzr kztzt\ufffdtkw nk\ufffdk\u20aco\ufffd {q9.653. 733\ufffd\u00d0oo\ufffd\u20ac l\u00de4.=;9. 9=6\ufffd\u20aco~\u20ac1 Oz\u20ac|om\ufffdt{z\n\u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd y{\u20ac\ufffd {q\ufffdsom{z\ufffdoz\ufffd m{yo\u20ac q~{y \ufffdso][kzn \ufffdso]R1\n\\so m{wwom\ufffdt{z |o~t{n mk|\ufffd\ufffd~o\u20ac kvo\u00deo\ufffdoz\ufffd tz\ufffdso\ufffdzq{wntzr mwtyk\ufffdo mskzro zk~~k\ufffdt\ufffdo. \ufffdso\nkzz{\ufffdzmoyoz\ufffd {z4\u20ac\ufffdQ\ufffdzo 534; l\u00de\ufffdsoz/][ W~o\u20actnoz\ufffd J{zkwn \\~\ufffdy| \ufffdsk\ufffd \ufffdso][F \u00d0{\ufffdwn\n\u00d0t\ufffdsn~k\u00d0 q~{y \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd {zmwtyk\ufffdo mskzro yt\ufffdtrk\ufffdt{z1 \\st\u20ac o\ufffdoz\ufffd mk\ufffd\u20acon kwk~ro\n\u20ac|tvo {qkm\ufffdt\ufffdt\ufffd\u00de {z\\\u00d0t\ufffd\ufffdo~ k~{\ufffdzn \ufffdso\ufffd{|tm {qmwtyk\ufffdo mskzro tww\ufffd\u20ac\ufffd~k\ufffdon l\u00de[4Ltrtz[4Ltwo1\n\\{\u20ac\ufffd\ufffdn\u00de \ufffdst\u20aco\ufffdoz\ufffd tz\ufffdsom{z\ufffdo\u00f0\ufffd {qkw{zro~ |o~t{n {q\ufffdz{~ykw\ufffd km\ufffdt\ufffdt\ufffd\u00de. \ufffdsom{wwom\ufffdt{z \u20ac|kz\u20ac\n\u20aco\ufffdoz \u00d0oov\u20ac moz\ufffd~on {z\ufffdso\u00d0oov {qr~ok\ufffdo\u20ac\ufffd km\ufffdt\ufffdt\ufffd\u00de1 _o\u20aco|k~k\ufffdo \ufffdsonk\ufffdk\u20aco\ufffd tz\ufffd{ \u20aco\ufffdoz {zo/\n\u00d0oov tz\ufffdo~\ufffdkw\u20ac \ufffd{kmm{\ufffdz\ufffd q{~\ufffdso|{\ufffdoz\ufffdtkw \u00d0oovw\u00de |o~t{ntmt\ufffd\u00de tz\u20ac{mtkw yontk \ufffd\u20ackro kzn rt\ufffdo\u20ac\n\u20ac\ufffdqqtmtoz\ufffd \u20acky|wtzr noz\u20act\ufffd\u00de q{~~{l\ufffd\u20ac\ufffd zo\ufffd\u00d0{~v kzkw\u00de\u20aco\u20ac1\n\\st\u20ac \u20ac\ufffd\ufffdn\u00de q{m\ufffd\u20aco\u20ac {z\ufffdsontrt\ufffdkw yontk ozrkroyoz\ufffd kzn \u20acsk~tzr losk\ufffdt{\ufffd~ {q\\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\u20ac\nnt\u20acm\ufffd\u20ac\u20actzr mwtyk\ufffdo mskzro1 \\{mk|\ufffd\ufffd~o \ufffdst\u20aclosk\ufffdt{\ufffd~. \ufffdsonk\ufffdk\u20aco\ufffd t\u20acqtw\ufffdo~on \ufffd{~oy{\ufffdo kww\n~o\ufffd\u00d0oo\ufffd\u20ac *\u00d0so~o k\ufffd\u20aco~ ~o|{\u20ac\ufffd\u20ac kz{~trtzkw \ufffd\u00d0oo\ufffd+ kzn }\ufffd{\ufffdo\u20ac *\u00d0so~o k\ufffd\u20aco~ ~o|{\u20ac\ufffd\u20ac kz{~trtzkw\n\ufffd\u00d0oo\ufffd \u00d0t\ufffds \ufffdsot~ {\u00d0z m{yyoz\ufffdk~\u00de |~o|oznon+1 \\so |\ufffd~|{\u20aco {q\ufffdst\u20acqtw\ufffdo~ t\u20ac\ufffd{q{m\ufffd\u20ac {z{~trtzkw\n\ufffd\u00d0oo\ufffd\u20ac. \u00d0stms k~ok\u20ac\u20ac\ufffdyon \ufffd{lo\ufffdso\u20ac\ufffd~{zro\u20ac\ufffd k\ufffdktwklwo yok\u20ac\ufffd~o {q\ufffd\u20aco~ ozrkroyoz\ufffd \u00d0t\ufffds m{z/\n\ufffdoz\ufffd? \ufffdsow{\u00d0oqq{~\ufffd m{\u20ac\ufffd {q~o\ufffd\u00d0oo\ufffdtzr kzn }\ufffd{\ufffdtzr yokz\u20ac \ufffdsk\ufffd \ufffd\u20aco~ ozrkroyoz\ufffd mkzz{\ufffd lo\ntzqo~~on k\u20acmwok~w\u00de q~{y \ufffdso\u20aco \ufffd\u00d0oo\ufffd \ufffd\u00de|o\u20ac1 \\so ~oyktztzr \ufffd\u00d0oo\ufffd\u20ac k~oq\ufffd~\ufffdso~ qtw\ufffdo~on \ufffd{~o\ufffdktz\n{zw\u00de \ufffds{\u20aco \u00d0stms m{z\ufffdktz kzoylonnon wtzv *]ZS+ \ufffd{\u00d0ol m{z\ufffdoz\ufffd1 \\so\u20aco wtzv\u20ac k~o\ufffdsontrt\ufffdkw\nyontk t\ufffdoy\u20ac \u20acsk~on l\u00de\ufffdso\ufffd\u00d0oo\ufffd k\ufffd\ufffds{~. tzmw\ufffdntzr zo\u00d0\u20ac k~\ufffdtmwo\u20ac. lw{r |{\u20ac\ufffd\u20ac. \ufffdtno{\u20ac kzn {\ufffdso~\nm{z\ufffdoz\ufffd1 [\ufffdms \ufffd\u00d0oo\ufffd\u20ac mkzlom{y|{\u20acon l\u00deykz\ufffdkw tz\u20aco~\ufffdt{z {qkwtzv {~mwtmvtzr \ufffdsoj\u20acsk~o) l\ufffd\ufffd/\n\ufffd{z{q\ufffdoz |~o\u20acoz\ufffdon kw{zr\u20actno {zwtzo zo\u00d0\u20ac m{z\ufffdoz\ufffd1 F||wtmk\ufffdt{z {qkww\ufffdsoqtw\ufffdo~\u20ac wok\ufffdo\u20ac knk\ufffdk\u20aco\ufffd\n{q9=5. <63\ufffd\u00d0oo\ufffd\u20ac m{z\ufffdktztzr ]ZS\u20ac l\u00de4=9. 467\ufffd\u20aco~\u20ac. l~{voz n{\u00d0z {\ufffdo~ \ufffdso;/\u00d0oov \u20ac\ufffd\ufffdn\u00de\n|o~t{n tz\\klwo 41T{\u20ac\ufffd z{\ufffdklw\u00de. \ufffdsomoz\ufffd~o |{tz\ufffd {q\ufffdsonk\ufffdk\u20aco\ufffd tz\u00d0oov 7tzmw\ufffdno\u20ac \ufffdso][tz\ufffdoz/\n\ufffdt{z \ufffd{\u00d0t\ufffdsn~k\u00d0 q~{y \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd. |~{n\ufffdmtzr kn~kyk\ufffdtm \u20ac\ufffd~ro tz\\\u00d0t\ufffd\ufffdo~ km\ufffdt\ufffdt\ufffd\u00de1\n]ZS \ufffdkwtnk\ufffdt{z\nK\ufffdo~\u00de ]ZS q{\ufffdzn tz\ufffdso\ufffd\u00d0oo\ufffd nk\ufffdk\u20aco\ufffd \u00d0k\u20ac\ufffdkwtnk\ufffdon tzJomoylo~ 534; \ufffd{oz\u20ac\ufffd~o \ufffdsk\ufffd t\ufffd\u00d0k\u20ack\n\u00d0{~vtzr wtzv \ufffd{kztnoz\ufffdtqtklwo t\ufffdoy {q{zwtzo m{z\ufffdoz\ufffd1 \\st\u20ac \ufffdkwtnk\ufffdt{z \u20ac\ufffdo| \u00d0k\u20aczomo\u20ac\u20ack~\u00de q{~k\n\\klwo 41_oovw\u00de \ufffd\u00d0oo\ufffd\u20ac kzn \ufffdzt}\ufffdo \ufffd\u20aco~\u20ac tz{\ufffd~ qtw\ufffdo~on nk\ufffdk\u20aco\ufffd1 _oov 7.tz\u00d0stms \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd kzz{\ufffdz mo/\nyoz\ufffd \u00d0k\u20acykno. tzmw\ufffdno\u20ac ykz\u00de y{~o \ufffd\u00d0oo\ufffd\u20ac \ufffdskz kz\u00de{\ufffdso~ \u00d0oov. kmm{\ufffdz\ufffdtzr q{~69& {qkww\ufffdso\ufffd\u00d0oo\ufffd\u20ac \u20ac\ufffd\ufffdnton1\n_oov V~trtzkw \\\u00d0oo\ufffd\u20ac ]zt}\ufffdo \ufffd\u20aco~\u20ac\n4 95.;6; 5;.7==\n5 :3.=55 64.;:=\n6 ;<.696 6<.:<6\n7 53=. :6; =:.93:\n9 :;.567 6:.:53\n: :9.57< 67.:59\n; 9<.:== 5<.96:\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o13593:9:1\ufffd33 4\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 9259\nz\ufffdylo~ {q~ok\u20ac{z\u20ac1 Lt~\u20ac\ufffdw\u00de. okms ]ZS y\ufffd\u20ac\ufffd lokmmo\u20ac\u20actlwo \ufffd{kww{\u00d0 \u20ac\ufffdl\u20aco}\ufffdoz\ufffd kzkw\u00de\u20act\u20ac {qm{z/\n\ufffdoz\ufffd1 [om{znw\u00de. \ufffd\u00de|{r~k|stmkw o~~{~\u20ac l\u00de\ufffd\u00d0oo\ufffd k\ufffd\ufffds{~\u20ac k~o\u20ac{yo\ufffdtyo\u20ac tzm{~~om\ufffdw\u00de tz\ufffdo~|~o\ufffdon l\u00de\n\ufffdso\\\u00d0t\ufffd\ufffdo~ FWO k\u20ac]ZS\u20ac. \u20ac\ufffdms k\u20ac|o~t{n\u20ac q{ww{\u00d0on l\u00dekw|skz\ufffdyo~tm msk~km\ufffdo~\u20ac *hello.world+1\n\\st~nw\u00de. \ufffdso\ufffdkwtnk\ufffdt{z |~{mo\u20ac\u20ac skznwo\u20ac \u20acs{~\ufffdozon ]ZS\u20ac. \u00d0stms ~o|~o\u20acoz\ufffd \ufffdsoyku{~t\ufffd\u00de {q]ZS\u20ac\ntz\ufffd\u00d0oo\ufffd\u20ac1 Tkz\u00de \\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\u20ac ykvo \ufffd\u20aco{q\ufffdst~n/|k~\ufffd\u00de ]ZS \u20acs{~\ufffdozo~\u20ac. \u20aco~\ufffdtmo\u20ac \u00d0stms m~ok\ufffdo k\n~ont~om\ufffd \ufffd{krt\ufffdoz w{zr ]ZS q~{y k\u20acs{~\ufffdo~ \ufffdo~\u20act{z \ufffdsk\ufffd mkz\ufffdsoz lo\ufffd\u20acon \ufffd{~on\ufffdmo \ufffdsomsk~km/\n\ufffdo~\u20aczoonon \ufffd{oylon ]ZS tzk\ufffd\u00d0oo\ufffd *\ufffdst\u20ac t\u20ac\ufffdzzomo\u20ac\u20ack~\u00de \u20actzmo \\\u00d0t\ufffd\ufffdo~ tzmw\ufffdno\u20ac t\ufffd\u20ac{\u00d0z \u20acs{~\ufffd/\noztzr \u20aco~\ufffdtmo \ufffdsk\ufffd ~on\ufffdmo\u20ac kz\u00de]ZS \ufffd{56msk~km\ufffdo~\u20ac+1 ]ZS \u20acs{~\ufffdozo~\u20ac k~okw\u20ac{ \u20ac{yo\ufffdtyo\u20ac \ufffd\u20acon\n\ufffd{m{zmokw \ufffdso\ufffdk~ro\ufffd ]ZS q~{y kz\u00de{zo \u00d0s{ yk\u00de |{\ufffdoz\ufffdtkww\u00de mwtmv {zt\ufffd1\\so\u20aco \u20acs{~\ufffd wtzv\u20ac y\ufffd\u20ac\ufffd\nlo\ufffd~kmon \ufffd{\ufffdsot~ no\u20ac\ufffdtzk\ufffdt{z l{\ufffds \ufffd{oz\u20ac\ufffd~o \ufffdso\u00de |{tz\ufffd \ufffdw\ufffdtyk\ufffdow\u00de \ufffd{k\ufffdkwtn ~o\u20ac{\ufffd~mo. kzn kw\u20ac{\n\ufffd{lo\ufffd~ok\ufffdon kw{zr\u20actno {\ufffdso~ wtzv\u20ac \ufffd{\ufffdso\u20ackyo no\u20ac\ufffdtzk\ufffdt{z1\nKkms ]ZS t\u20ac~o\u20ac{w\ufffdon tznt\ufffdtn\ufffdkww\u00de. yk~vtzr k\u20ac\ufffdkwtn {zw\u00de \ufffds{\u20aco \ufffdsk\ufffd ~o\ufffd\ufffd~z N\\\\W \u20ac\ufffdk\ufffd\ufffd\u20ac\nm{no 5aa tyyontk\ufffdow\u00de {~\ufffds~{\ufffdrs k\u20acykww z\ufffdylo~ {q|o~ykzoz\ufffd ~ont~om\ufffd\u20ac *634%634%444\n%5aa \u20ac\ufffdk\ufffd\ufffd\u20ac m{no\u20ac+1 \\so 5aa \u20ac\ufffdk\ufffd\ufffd\u20ac m{no\u20ac tzntmk\ufffdo \ufffdk~t{\ufffd\u20ac \u20ac\ufffdmmo\u20ac\u20acq\ufffdw {\ufffd\ufffdm{yo\u20ac \ufffd{kzN\\\\W\n~o}\ufffdo\u20ac\ufffd1\nTkz\u00de \ufffdkwtn ]ZS\u20ac tzmw\ufffdnon y{ntqto~\u20ac tz\u20aco~\ufffdon q{~\ufffd~kmvtzr kzn yo\ufffdknk\ufffdk |\ufffd~|{\u20aco\u20ac. \u00d0t\ufffds{\ufffd\ufffd\nkw\ufffdo~tzr \ufffdsono\u20ac\ufffdtzk\ufffdt{z |kro1 \\st\u20ac mkzwokn \ufffd{ykz\u00de ]ZS\u20ac |{tz\ufffdtzr \ufffd{\ufffdso\u20ackyo ~o\u20ac{\ufffd~mo. \u20ac{\ufffd{\nytztyt\u20aco \ufffdso|{\u20ac\u20actltwt\ufffd\u00de {qm{z\u20actno~tzr \ufffdso\u20aco k\u20acnt\u20ac\ufffdtzm\ufffd ]ZS\u20ac. kww\u20acmsoyo\u20ac kzn }\ufffdo~to\u20ac k~o\n~oy{\ufffdon q~{y \ufffdso~o\u20ac{w\ufffdon ]ZS\u20ac1 F\u20acykww z\ufffdylo~ {qn{yktz\u20ac \u00d0o~o kn\ufffdo~\u20acow\u00de kqqom\ufffdon l\u00de\ufffdst\u20ac1\nb{\ufffd\\\ufffdlo kzn {\ufffdso~ M{{rwo \u20aco~\ufffdtmo\u20ac \u00d0o~o \ufffdsoy{\u20ac\ufffd |~{ytzoz\ufffd. wk~row\u00de n\ufffdo\ufffd{\ufffdso\u20ac\ufffd~\ufffdm\ufffd\ufffd~o {q\n\ufffdsot~ wtzv\u20ac1 F\u20ack~o\u20ac\ufffdw\ufffd. {\ufffd~|~{mo\u20ac\u20ac n{o\u20ac z{\ufffdnt\u20ac\ufffdtzr\ufffdt\u20acs lo\ufffd\u00d0ooz ntqqo~oz\ufffd b{\ufffd\\\ufffdlo \ufffdtno{\u20ac\n\u00d0t\ufffdstz \ufffdsozo\ufffd\u00d0{~v\u20ac1\n\\so \ufffdkwtnk\ufffdt{z |~{mo\u20ac\u20ac ~o\u20ac\ufffdw\ufffd\u20ac tzkyk||tzr lo\ufffd\u00d0ooz okms ~k\u00d0]ZS *k\u20acrt\ufffdoz tzk\ufffd\u00d0oo\ufffd+\nkzn \ufffdso\ufffdkwtnk\ufffdon qtzkw no\u20ac\ufffdtzk\ufffdt{z kq\ufffdo~ kz\u00dekmmo|\ufffdklwo ~ont~om\ufffd |k\ufffds\u20ac1 Fz\u00de \ufffd\u00d0oo\ufffd m{z\ufffdktztzr k\ufffd\nwok\u20ac\ufffd {zo\ufffdz\ufffdkwtnk\ufffdon ]ZS t\u20ac~oy{\ufffdon q~{y \ufffdsonk\ufffdk\u20aco\ufffd1 Ltzkww\u00de. kww\ufffd\u20aco~\u20ac \u00d0s{ \ufffd\u00d0oo\ufffdon y{~o\n\ufffdskz 93\ufffdtyo\u20ac \u00d0t\ufffdstz krt\ufffdoz \u00d0oov k~o~oy{\ufffdon? \ufffdst\u20ac\ufffds~o\u20acs{wn t\u20acq{\ufffdzn \ufffd{lok\u20acoz\u20actlwo wtyt\ufffd \ufffd{\nyt\ufffdtrk\ufffdo \ufffdsoty|km\ufffd {qk\ufffd\ufffd{yk\ufffdon kmm{\ufffdz\ufffd\u20ac. o\u20ac|omtkww\u00de zo\u00d0\u20ac krr~ork\ufffd{~ kmm{\ufffdz\ufffd\u20ac1 Fm~{\u20ac\u20ac \ufffdso\n\u20aco\ufffdoz \u00d0oov\u20ac 5;4\ufffdzt}\ufffdo kmm{\ufffdz\ufffd\u20ac \u00d0o~o kqqom\ufffdon. wokntzr \ufffd{\ufffdso~oy{\ufffdkw {q::.<=5\ufffd\u00d0oo\ufffd\u20ac\n*k||~{\u00f0tyk\ufffdow\u00de 4&{q\ufffdso\ufffd{\ufffdkw nk\ufffdk\u20aco\ufffd+1 \\st\u20ac woq\ufffd579. 77:\ufffd\u00d0oo\ufffd\u20ac l\u00de446. 497\ufffd\u20aco~\u20ac \u20acsk~tzr 97.\n7:5nt\u20ac\ufffdtzm\ufffd. \ufffdkwtnk\ufffdon. ]ZS\u20ac km~{\u20ac\u20ac kww{q\ufffdso\u20aco\ufffdoz {zo/\u00d0oov \u00d0tzn{\u00d0\u20ac1\nUo\ufffd\u00d0{~v m{z\u20ac\ufffd~\ufffdm\ufffdt{z\nGt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v\u20ac. m{z\ufffdktztzr \ufffd\u00d0{z{no mwk\u20ac\u20aco\u20ac ~o|~o\u20acoz\ufffdtzr \ufffd\u20aco~\u20ac kzn ]ZS\u20ac. k~om{z\u20ac\ufffd~\ufffdm\ufffdon\nl\u00dem~ok\ufffdtzr kzonroi%j\u00d0sozo\ufffdo~ \ufffd\u20aco~i\u20acsk~o\u20ac ]ZSj.tww\ufffd\u20ac\ufffd~k\ufffdon l\u00deLtr41T\ufffdw\ufffdt|wo \u20acsk~o\u20ac {q\n]ZSjl\u00de\ufffd\u20aco~itzm~oyoz\ufffd \ufffdsoonro \u00d0otrs\ufffd \u20ac{\ufffdsk\ufffd \ufffdsoqtzkw lt|k~\ufffdt\ufffdo onro \u00d0otrs\ufffdw*i.j+~o|~o/\n\u20acoz\ufffd\u20ac \ufffdsoz\ufffdylo~ {q\ufffdtyo\u20ac \ufffd\u20aco~i\u20acsk~on ]ZSj1\nUo\u00f0\ufffd k\ufffdzt|k~\ufffdt\ufffdo |~{uom\ufffdt{z t\u20ac|~{n\ufffdmon q~{y \ufffdsolt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v. \u00d0so~ol\u00de kzo\ufffd\u00d0{~v {q\n{zw\u00de ]ZS z{no\u20ac t\u20acm~ok\ufffdon. \u00d0so~o onro\u20ac ozm{no \ufffdsoz\ufffdylo~ {q\ufffd\u20aco~\u20ac \ufffdsk\ufffd \u20acsk~on \ufffdsom{zzom\ufffdon\n|kt~ {q]ZS\u20ac1 \\so zo\ufffd\u00d0{~v m{z\u20ac\ufffd~\ufffdm\ufffdt{z |~{mo\u20ac\u20ac t\u20actww\ufffd\u20ac\ufffd~k\ufffdon tzLtr41\\so ]ZS\u20ac \u20acsk~on l\u00dek\n\u20actzrwo \ufffd\u20aco~ *Ltr 4k+q{~y kq\ufffdww\u00de m{zzom\ufffdon mwt}\ufffdo {qz{no\u20ac ~o|~o\u20acoz\ufffdtzr \ufffdso\u20acsk~tzr |k\ufffd\ufffdo~z q{~\n\ufffdsk\ufffd \ufffd\u20aco~ *Ltr 4l+1 \\so \u00d0s{wo \ufffdzt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v t\u20ac\ufffdsoz m{z\u20ac\ufffd~\ufffdm\ufffdon l\u00dem{y|{\u20actzr \ufffdsomwt}\ufffdo\u20ac\nq{~kww\ufffd\u20aco~\u20ac *Ltr 4m+1\\so |~{uom\ufffdt{z kww{\u00d0\u20ac \ufffdso\ufffd\u20aco{qoqqtmtoz\ufffd \ufffdzt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v kzkw\u00de\u20act\u20ac kwr{/\n~t\ufffdsy\u20ac kzn q{m\ufffd\u20aco\u20ac \ufffdsokzkw\u00de\u20act\u20ac {z\ufffdso~owk\ufffdt{z\u20acst|\u20ac lo\ufffd\u00d0ooz ]ZS\u20ac1 \\so \ufffdzt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v {q\n]ZS\u20ac ~o|~o\u20acoz\ufffd\u20ac \ufffdsom{wwom\ufffdt\ufffdo |k\ufffd\ufffdo~z {q\u20acsk~tzr {zwtzo m{z\ufffdoz\ufffd {q\ufffdso\ufffdk~ro\ufffdon \\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\n|{|\ufffdwk\ufffdt{z1 [\ufffdk\ufffdt\u20ac\ufffdtm\u20ac q{~\ufffdso\u20aco\ufffdoz {zo/\u00d0oov zo\ufffd\u00d0{~v\u20ac m~ok\ufffdon k~ort\ufffdoz tz[4\\klwo tz[4Ltwo1\n_o~o\u20ac\ufffd~tm\ufffd {\ufffd~kzkw\u00de\u20aco\u20ac \ufffd{\ufffdsortkz\ufffd m{y|{zoz\ufffd \ufffd{k\ufffd{tn \ufffdsot\u20ac\u20ac\ufffdo {qzo\ufffd\u00d0{~v q~kryoz\ufffdk/\n\ufffdt{z kzn wtyt\ufffd t\ufffd\u20acty|km\ufffd {zm{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z1 Ozkwwmk\u20aco\u20ac \ufffdsortkz\ufffd m{y|{zoz\ufffd m{z\u20act\u20ac\ufffd\u20ac {q\nk~{\ufffdzn \ufffd\u00d0{\ufffdst~n\u20ac {qkww]ZS z{no\u20ac tz\ufffdsozo\ufffd\u00d0{~v1 Vzo ty|{~\ufffdkz\ufffd no\u20actrz nomt\u20act{z ykno tz\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 :259\n\ufffdst\u20ac|~{mo\u20ac\u20ac t\u20acs{\u00d0 \ufffd\u20aco~ \u20acsk~o\u20ac k~oozm{non tz\ufffd{ \ufffdzt|k~\ufffdt\ufffdo onro \u00d0otrs\ufffd? ntqqo~oz\ufffd \u00d0otrs\ufffdtzr\n\u20acmsoyo\u20ac \u20actrztqtmkz\ufffdw\u00de ty|km\ufffd \ufffdso|o~q{~ykzmo {qm{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z kwr{~t\ufffdsy\u20ac1 ]\u20aco~ m{z/\n\ufffd~tl\ufffd\ufffdt{z\u20ac \ufffd{\ufffdzt|k~\ufffdt\ufffdo onro \u00d0otrs\ufffd\u20ac k~o\u20acmkwon l\u00de\ufffdsoqkm\ufffd{~ 42*ki\u22124+.\u00d0so~okit\u20ac\ufffdso\ufffd{\ufffdkw\nz\ufffdylo~ {qk~\ufffdtmwo \u20acsk~o\u20ac l\u00de\ufffd\u20aco~i*tzmw\ufffdntzr ~o|ok\ufffdon wtzv\u20ac+. \u20ac\ufffdms \ufffdsk\ufffd \ufffdso\ufffd{\ufffdkw \ufffdzt|k~\ufffdt\ufffdo onro\n\u00d0otrs\ufffd m{z\ufffd~tl\ufffd\ufffdt{z l\u00deokms \ufffd\u20aco~ t\u20acki25*k\u20ac|~{|{\u20acon tzUo\u00d0ykz d76f+1 \\st\u20ac s\u00de|o~l{wtm\n\u00d0otrs\ufffdtzr \u20acmsoyo \u00d0k\u20acq{\ufffdzn \ufffd{kww{\u00d0 ~{l\ufffd\u20ac\ufffd ~om{\ufffdo~\u00de {qm{yy\ufffdzt\ufffd\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac kq\ufffdo~ |~{uom/\n\ufffdt{z d77f1 _t\ufffds{\ufffd\ufffd \ufffdst\u20ac\u00d0otrs\ufffdtzr qkm\ufffd{~. k\ufffd\u20aco~)\u20ac onro \u00d0otrs\ufffd m{z\ufffd~tl\ufffd\ufffdt{z \ufffd{\ufffdso|~{uom\ufffdon zo\ufffd/\n\u00d0{~v t\u20ac}\ufffdkn~k\ufffdtm tz\ufffdsoz\ufffdylo~ {q]ZS\u20ac \u20acsk~on. \u20actzmo okms \ufffd\u20aco~ m~ok\ufffdo\u20acki*ki\u22124+25 onro\u20ac tz\n\ufffdso|~{uom\ufffdt{z. mk\ufffd\u20actzr \ufffd\u20aco~\u20ac \u00d0s{ \u20acsk~o ykz\u00de k~\ufffdtmwo\u20ac \ufffd{}\ufffdtmvw\u00de n{ytzk\ufffdo \ufffdsozo\ufffd\u00d0{~v kzn\n\u20ac\ufffdl\u20aco}\ufffdoz\ufffd kzkw\u00de\u20act\u20ac1\nI{y|\ufffd\ufffdtzr \ufffdso|~{uom\ufffdt{z ~o}\ufffdt~o\u20ac vz{\u00d0wonro {q\ufffdsoltknukmozm\u00de yk\ufffd~t\u00f0B{q\ufffdsortkz\ufffd\nm{y|{zoz\ufffd. \u00d0so~o \ufffdso~{\u00d0\u20ac ~o|~o\u20acoz\ufffd \ufffd\u20aco~\u20ac kzn \ufffdsom{w\ufffdyz\u20ac ~o|~o\u20acoz\ufffd ]ZS\u20ac? kzn kntkr{zkw\nyk\ufffd~t\u00f0D\u20ac\ufffdms \ufffdsk\ufffdDiiB42*ki\u22124+1Mt\ufffdoz \ufffdso\u20aco yk\ufffd~tmo\u20ac. \ufffdsoknukmozm\u00de yk\ufffd~t\u00f0 q{~\ufffdso\u00d0otrs\ufffdon\n\ufffd\u20aco~ |~{uom\ufffdt{z PBBTDBkzn sozmo \ufffdso\u00d0otrs\ufffd {qkzonro lo\ufffd\u00d0ooz ]ZS\u20acikznjtz\ufffdso|~{uom/\n\ufffdt{z\nw\u0085iCj\u0086\u0088d\nu9Usersw\u0085uCi\u0086w\u0085uCj\u0086\ndeg\u0085u\u0086\u00007B \u00854\u0086\nLtr41[msoyk\ufffdtm ntkr~ky {q\ufffdsolt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v m{z\u20ac\ufffd~ \ufffdm\ufffdt{z kzn \ufffdzt|k~\ufffdt\ufffdo |~{uom\ufffdt{z1 Kkms \ufffd\u20aco~ t\u20acm{zzom\ufffdon \ufffd{\ufffdso]ZS\u20ac \ufffdso\u00de \u20acsk~o tz\n\ufffdso\u20ac\ufffd\ufffdn\u00de \u00d0oov1 \\so \ufffdzt|k~\ufffdt\ufffdo |~{uom\ufffdt{z m~ok\ufffdo\u20ac onro\u20ac lo\ufffd\u00d0ooz \ufffd\u00d0{]ZS\u20ac \u00d0sozo\ufffdo ~\ufffdso\u00de k~o\u20acsk~on l\u00de\ufffdso\u20ackyo |o~\u20ac{z1 T\ufffdw\ufffdt|wo onro\u20ac tz\ufffdso\n|~{uom\ufffdt{ ztzntmk\ufffdo \ufffdsk\ufffd y\ufffdw\ufffdt|wo \ufffd\u20aco~\u20ac sk\ufffdo \u20acsk~on \ufffdso|kt~ {q]ZS\u20ac. kzn \ufffdst\u20actzq{~yk\ufffd t{zt\u20ac\ufffd~kmvon l\u00deonro \u00d0otrs\ufffd\u20ac1 F\ufffd\u20aco~)\u20ac onro m{z\ufffd~tl \ufffd\ufffdt{z\n\ufffd{\ufffdso|~{uom\ufffdt{ ztzm~ok\u20aco\u20ac }\ufffdkn~k\ufffdtm kww\u00de\u00d0t\ufffds \ufffdsoz\ufffdylo~ {q]ZS\u20ac \ufffdso\u00de \u20acsk~o. |{\ufffdoz\ufffdtkww\u00de wokntzr \ufffd{kn{ytzkzmo {qstrsw\u00de km\ufffdt\ufffdo \ufffd\u20aco~\u20ac tz\ufffdso\n\ufffdzt|k~ \ufffdt\ufffdo|~{uom\ufffdt{ z.q{~o\u00f0ky|wo ]\u20aco~ 6*~on+ tz\ufffdso|~{uom\ufffdt{ z?\ufffdst\u20act\u20acskznwon l\u00deks\u00de|o~l{wtm \u00d0otrs\ufffd tzr\u20acmsoyo *\u20acoo [om\ufffdt{z Uo\ufffd\u00d0{~v\nm{z\u20ac\ufffd~\ufffd m\ufffdt{z+1\ns\ufffd\ufffd|\ufffd>22 n{t1{~r243146;4 2u{\ufffd~zkw1|{zo1 3593:9:1r334\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 ;259\nI{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z\nI{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z \u00d0k\u20ac\ufffd\u20acon \ufffd{qtzn mw\ufffd\u20ac\ufffdo~\u20ac {qnoz\u20acow\u00de tz\ufffdo~m{zzom\ufffdon z{no\u20ac tz\ufffdsozo\ufffd/\n\u00d0{~v. \u00d0stms tz\ufffdst\u20acm{z\ufffdo\u00f0\ufffd ~o|~o\u20acoz\ufffd \u20aco\ufffd\u20ac{q]ZS\u20ac \u00d0stms \u00d0o~o \u20acooz l\u00dekr~{\ufffd| {q\u20actytwk~ \\\u00d0t\ufffd/\n\ufffdo~\ufffd\u20aco~\u20ac1 I{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z d79f t\u20ackyokz\u20ac {qkwr{~t\ufffdsytmkww\u00de tnoz\ufffdtq\u00detzr \u20ac\ufffdms mw\ufffd\u20ac\ufffdo~\u20ac tz\nkrt\ufffdoz \ufffdzt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v1 \\st\u20ac \u20ac\ufffd\ufffdn\u00de \ufffd\u20acon kr~oon\u00de kwr{~t\ufffdsy |~{|{\u20acon l\u00deIwk\ufffd\u20aco\ufffd o\ufffdkw1d7:f\n\ufffdsk\ufffd |k~\ufffdt\ufffdt{z\u20ac z{no\u20ac tz\ufffd{ m{yy\ufffdzt\ufffdto\u20ac \u20ac\ufffdms \ufffdsk\ufffd \ufffdsoy{n\ufffdwk~t\ufffd\u00de {q\ufffdso|k~\ufffdt\ufffdt{z t\u20ac{|\ufffdtyt\u20acon?\ny{n\ufffdwk~t\ufffd\u00de yok\u20ac\ufffd~o\u20ac \ufffdso|~{|{~\ufffdt{z {qonro\u20ac \u00d0t\ufffdstz m{yy\ufffdzt\ufffdto\u20ac ~owk\ufffdt\ufffdo \ufffd{\ufffdso|~{|{~\ufffdt{z {q\nonro\u20ac lo\ufffd\u00d0ooz m{yy\ufffdzt\ufffdto\u20ac1 Oqkm{yy\ufffdzt\ufffd\u00de k\u20ac\u20actrzyoz\ufffd t\u20ac\u20actrztqtmkz\ufffdw\u00de lo\ufffd\ufffdo~ \ufffdskz ~kzn{y. k\ny{n\ufffdwk~t\ufffd\u00de \u20acm{~o lo\ufffd\u00d0ooz 316kzn 31;t\u20ac\ufffd\u00de|tmkww\u00de {l\u20aco~\ufffdon d79f1 T{n\ufffdwk~t\ufffd\u00de \u20acm{~o\u20ac q{~okms\nzo\ufffd\u00d0{~v k~ort\ufffdoz tz[4\\klwo tz[4Ltwo1\nI{z\ufffdoz\ufffd kzkw\u00de\u20act\u20ac\nWkro m{z\ufffdoz\ufffd \u00d0k\u20acm{wwom\ufffdon q{~okms \ufffdkwtnk\ufffdon ]ZS \ufffd\u20actzr Jtqql{\ufffd d7;f. kz{zwtzo \u20aco~\ufffdtmo q{~\no\u00f0\ufffd~km\ufffdtzr \ufffdsom{z\u20ac\ufffdt\ufffd\ufffdoz\ufffd |k~\ufffd\u20ac {qkzN\\TS n{m\ufffdyoz\ufffd kzn |~o\u20acoz\ufffdtzr \ufffdsoy tzkzok\u20actw\u00de kzk/\nw\u00de\u20acon q{~yk\ufffd1 Oz\u20ac{yo mk\u20aco\u20ac. Jtqql{\ufffd {zw\u00de tnoz\ufffdtqto\u20ac \ufffdso\ufffdt\ufffdwo kzn mkzz{\ufffd k\ufffd\ufffd{yk\ufffdtmkww\u00de no\ufffdom\ufffd\n\ufffdsom{z\ufffdoz\ufffd {qk\u00d0ol|kro1 \\{yt\ufffdtrk\ufffdo \ufffdsoty|km\ufffd {q\ufffdst\u20ac. \ufffdso\ufffdt\ufffdwo t\u20ac\ufffd\u20acon k\u20ac\ufffdso|kro m{z\ufffdoz\ufffd\nq{~\u20ac\ufffdms ]ZS\u20ac1 \\st\u20ac \u20ac\ufffdl\u20ac\ufffdt\ufffd\ufffd\ufffdt{z kqqom\ufffdon wo\u20ac\u20ac\ufffdskz 9&{q\ufffdso]ZS\u20ac tzokms \u00d0oov. o\u00f0mo|\ufffd _oov\n7\u00d0stms ~o}\ufffdt~on \u20ac\ufffdl\u20ac\ufffdt\ufffd\ufffd\ufffdt{z tz91=& {q\ufffdso]ZS\u20ac1 Fnnt\ufffdt{zkww\u00de. k\u20acykww z\ufffdylo~ {qn{yktz\u20ac\n\u00d0o~o tzm{y|k\ufffdtlwo \u00d0t\ufffds \ufffdsoJtqql{\ufffd FWO1 \\st\u20ac kmm{\ufffdz\ufffd\u20ac q{~k~{\ufffdzn 7&{qkww]ZS\u20ac tz\ufffdsortkz\ufffd\nm{y|{zoz\ufffd\u20ac {qkz\u00de\u00d0oov kzn y{\u20ac\ufffdw\u00de k~t\u20aco n\ufffdo\ufffd{|kro q{~yk\ufffd\ufffdtzr {~\ufffdtyo{\ufffd\ufffd t\u20ac\u20ac\ufffdo\u20ac1\nVzwtzo m{z\ufffdoz\ufffd \u00d0k\u20ackzkw\u00de\u20acon }\ufffdkz\ufffdt\ufffdk\ufffdt\ufffdow\u00de l\u00demkwm\ufffdwk\ufffdtzr \ufffdo~y q~o}\ufffdozm\u00de/tz\ufffdo~\u20aco n{m\ufffd/\nyoz\ufffd q~o}\ufffdozm\u00de *\\L/OJL+ \u20acm{~o\u20ac. \ufffd~ok\ufffdtzr okms ]ZS k\u20ackn{m\ufffdyoz\ufffd kzn \ufffdso\u20aco\ufffd{qkww]ZS\u20ac tz\n\ufffdso\u00d0s{wo zo\ufffd\u00d0{~v k\u20ac\ufffdsom{~|\ufffd\u20ac1 \\L/OJL kzkw\u00de\u20aco\u20ac kty \ufffd{tnoz\ufffdtq\u00de nt\u20ac\ufffdtzm\ufffdt\ufffdo {~ty|{~\ufffdkz\ufffd\n\ufffd{voz\u20ac *\ufffd\u20ac\ufffdkww\u00de \u00d0{~n\u20ac+ tzkn{m\ufffdyoz\ufffd. lk\u20acon {z\ufffdsot~ q~o}\ufffdozm\u00de tz\ufffdson{m\ufffdyoz\ufffd ~owk\ufffdt\ufffdo \ufffd{\n\ufffdsot~ q~o}\ufffdozm\u00de km~{\u20ac\u20ac \ufffdsom{~|\ufffd\u20ac1 \\s~oo vtzn\u20ac {q\ufffd{voz \u00d0o~o \u20ac\ufffd\ufffdnton tz\ufffdst\u20ac\u00d0k\u00de. tz\ufffds~oo \u20aco|k/\n~k\ufffdo kzkw\u00de\u20aco\u20ac> \u00d0ol n{yktz\u20ac. |kro m{z\ufffdoz\ufffd \ufffdztr~ky\u20ac. kzn |kro m{z\ufffdoz\ufffd ltr~ky\u20ac1 _ol n{yktz\u20ac\n\u00d0o~o o\u00f0\ufffd~km\ufffdon q{~okms ]ZS \ufffd{|o~yt\ufffd kzkw\u00de\u20act\u20ac {q\ufffdso\u20ac{\ufffd~mo\u20ac {qm{z\ufffdoz\ufffd \u20acsk~on {z\\\u00d0t\ufffd\ufffdo~1\n_{~n\u20ac kzn ltr~ky\u20ac *\ufffd\u00d0{/\u00d0{~n |s~k\u20aco\u20ac+ \u00d0o~o o\u00f0\ufffd~km\ufffdon q~{y \ufffdso\u00d0ol |kro\u20ac k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds\nokms ]ZS \ufffd{kww{\u00d0 wk~ro/\u20acmkwo kzkw\u00de\u20act\u20ac {q\ufffdso\ufffd{|tm\u20ac \u00d0t\ufffdstz \ufffdsom{z\ufffdoz\ufffd1 Goq{~o mkwm\ufffdwk\ufffdtzr \ufffdso\n\\L/OJL \ufffdom\ufffd{~\u20ac q{~|kro m{z\ufffdoz\ufffd. \ufffdso[z{\u00d0lkww \u20ac\ufffdoyyo~ d7<f \u00d0k\u20ack||wton \ufffd{okms m{z\ufffdoz\ufffd\n\ufffd{voz1 Kkms \u20ac\ufffdoyyon \ufffd{voz t\u20acyk||on lkmv \ufffd{\ufffdsoy{\u20ac\ufffd m{yy{z \ufffd{voz \ufffdsk\ufffd yk|\u20ac \ufffd{t\ufffdq{~\nok\u20aco {q~okntzr. o1r1tqqt\u20acso~. qt\u20acson kzn qt\u20acstzr kwwk||ok~ {zmo kzn qt\u20acso\u20ac k||ok~\u20ac \ufffd\u00d0tmo \ufffdsoz\n\ufffdsoqtzkw ~o|~o\u20acoz\ufffdk\ufffdt{z {q\ufffdso\u20aco \ufffd{voz\u20ac t\u20acqt\u20acso\u20ac1\n\\L/OJL \u20acm{~o \ufffdom\ufffd{~\u20ac q{~okms ]ZS k~omkwm\ufffdwk\ufffdon kzn ~o|~o\u20acoz\ufffd \ufffdsoq~o}\ufffdozm\u00de {q\ufffd{voz\u20ac tz\nkn{m\ufffdyoz\ufffd ~owk\ufffdt\ufffdo \ufffd{\ufffdsot~ q~o}\ufffdozm\u00de km~{\u20ac\u20ac \ufffdsom{~|\ufffd\u20ac1 L{~\ufffd{vozttzn{m\ufffdyoz\ufffd d\u00d0osk\ufffdo\nTF-IDF\u0085tCd\u0086\u0088tf\u0085tCd\u0086log7\u0087n\n7\u0087df\u0085t\u0086\ufffd\ufffd\n\u00877\ufffd \ufffd\nC \u00855\u0086\n\u00d0so~ont\u20ac\ufffdsoz\ufffdylo~ {qn{m\ufffdyoz\ufffd\u20ac tz\ufffdsom{~|\ufffd\u20ac.tf*t.d+m{\ufffdz\ufffd\u20ac \ufffdsoq~o}\ufffdozm\u00de {qttzdkzn\ndf*t+ m{\ufffdz\ufffd\u20ac \ufffdsoz\ufffdylo~ {qn{m\ufffdyoz\ufffd\u20ac tz\ufffdsom{~|\ufffd\u20ac \u00d0stms m{z\ufffdktzt1\\{msk~km\ufffdo~t\u20aco okms\nm{yy\ufffdzt\ufffd\u00de q{\ufffdzn tz\ufffdso\u20acsk~tzr zo\ufffd\u00d0{~v. \ufffdso\\L/OJL \ufffdom\ufffd{~\u20ac q{~okms ]ZS tzkm{yy\ufffdzt\ufffd\u00de\n\u00d0o~o \u20ac\ufffdyyon \ufffd{{l\ufffdktz krr~ork\ufffdo \u20acm{~o\u20ac1 Oz\ufffdso\u20aco m{yy\ufffdzt\ufffd\u00de/wo\ufffdow m{y|k~t\u20ac{z\u20ac. kstrs\n\\L/OJL \u20acm{~o q{~km{yy\ufffdzt\ufffd\u00de yokz\u20ac \ufffdsk\ufffd \ufffdsort\ufffdoz \ufffd{voz k||ok~\u20ac y{~o q~o}\ufffdoz\ufffdw\u00de tz\ufffdso\n]ZS\u20ac tz\ufffdst\u20acm{yy\ufffdzt\ufffd\u00de. \u00d0soz m{y|k~on \ufffd{{\ufffdso~ m{yy\ufffdzt\ufffdto\u20ac1 Ozokms mk\u20aco. \ufffd{voz\u20ac \u00d0stms\n{mm\ufffd~ tzqo\u00d0o~ \ufffdskz 93]ZS\u20ac. {~y{~o \ufffdskz 93& {qkww]ZS\u20ac tzkrt\ufffdoz \u00d0oov k~o~ouom\ufffdon. \u20ac\ufffdms\n\ufffdsk\ufffd \ufffdo~\u00de m{yy{z {~\ufffdo~\u00de ~k~o \ufffd{voz\u20ac k~o{yt\ufffd\ufffdon1 _okw\u20ac{ ~oy{\ufffdon k\u20aco\ufffd{qm{yy{z \u20ac\ufffd{|/\n\u00d0{~n\u20ac tzmw\ufffdntzr trump.paris kznagreement1 Oz|~tzmt|wo. n/r~ky\u20ac mkzlo\u20ac\ufffd\ufffdnton \u00d0t\ufffds kz\u00de\n\ufffdkw\ufffdo {qn.l\ufffd\ufffdlo\u00de{znnB5\ufffd{voz q~o}\ufffdozm\u00de t\u20acrozo~kww\u00de \ufffd{{w{\u00d0\ufffd{lo\ufffd\u20acoq\ufffdw1\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 <259\nOno{w{rtmkw m{ntzr {q\u20ac{\ufffd~mo n{yktz\u20ac\n\\{o\u00f0kytzo tno{w{rtmkw |{\u20act\ufffdt{ztzr {q|{|\ufffdwk~ \u20ac{\ufffd~mo n{yktz\u20ac kw{zr k\u00f0o\u20ac {q|{wt\ufffdtmkw wokztzr\n*q~{y woq\ufffd2|~{r~o\u20ac\u20act\ufffdo \ufffd{~trs\ufffd2m{z\u20aco~\ufffdk\ufffdt\ufffdo+ kzn mwtyk\ufffdo \u20acmo|\ufffdtmt\u20acy *q~{y oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd \ufffd{\n\u20acmo|\ufffdtm+. :5{q\ufffdso;9y{\u20ac\ufffd m{yy{zw\u00de \u20acsk~on \u20ac{\ufffd~mo n{yktz\u20ac km~{\u20ac\u20ac \ufffdsooz\ufffdt~o \u20ac\ufffd\ufffdn\u00de |o~t{n\n\u00d0o~o ykz\ufffdkww\u00de m{non q{~tno{w{rtmkw ltk\u20ac *wt\u20ac\ufffdon tz[7\\klwo tz[4Ltwo+1 Ono{w{r\u00de o\u00f0|~o\u20ac\u20acon tz\nk~\ufffdtmwo\u20ac q~{y okms n{yktz \u00d0k\u20acr~knon {zk\ufffds~oo/|{tz\ufffd \u20acmkwo q{~|{wt\ufffdtmkw {|tzt{z *Soq\ufffd/Uo\ufffd/\n\ufffd~kw/Ztrs\ufffd+ kzn mwtyk\ufffdo mskzro {|tzt{z *Kz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd/Uo\ufffd\ufffd~kw/ [mo|\ufffdtm+. \u00d0t\ufffds kzknnt\ufffdt{zkw\nz\ufffdww ~k\ufffdtzr *]zmwok~+ knnon \ufffd{l{\ufffds \u20acmkwo\u20ac q{~mk\u20aco\u20ac \u00d0so~o z{mwok~ tno{w{r\u00de \u00d0k\u20ac\u20acooz1\nF\ufffdoky {q\u20act\u00f0s\ufffdykz m{no~\u20ac \ufffd\u20acon \ufffdst\u20ac\u20acmkwo \ufffd{tzno|oznoz\ufffdw\u00de \u20acm{~o \ufffdo\u00f0\ufffdo\u00f0\ufffd~km\ufffd\u20ac {qk~\ufffdtmwo\u20ac2\nm{z\ufffdoz\ufffd q~{y \ufffdsoy{\u20ac\ufffd m{yy{zw\u00de \u20acsk~on n{yktz\u20ac1 L{~\ufffdso;9n{yktz\u20ac \u00d0t\ufffds \ufffdsoy{\u20ac\ufffd \u20acsk~o\u20ac\nkm~{\u20ac\u20ac \ufffdso\u20aco\ufffdoz/\u00d0oov |o~t{n. \u00d0o\u20acky|won \ufffdso|kro m{z\ufffdoz\ufffd q{~qt\ufffdoy{\u20ac\ufffd \u20acsk~on k~\ufffdtmwo\u20ac *\ufffd\u20actzr\nJtqql{\ufffd \ufffd{o\u00f0\ufffd~km\ufffd mwokz \ufffdo\u00f0\ufffd. k\u20acno\u20acm~tlon kl{\ufffdo+1 Oqqo\u00d0o~ \ufffdskz qt\ufffdok~\ufffdtmwo\u20ac q~{y k|{|\ufffdwk~\nn{yktz \u00d0o~o k\ufffdktwklwo tz\ufffdsonk\ufffdk\u20aco\ufffd. \ufffdsoz kww\u00d0o~o tzmw\ufffdnon1 Oz\u20ac{yo mk\u20aco\u20ac. \ufffdso|kro q{~yk\ufffd\u20ac\n\u00d0o~o tzm{y|k\ufffdtlwo \u00d0t\ufffds \ufffdsoJtqql{\ufffd FWO. ~o\ufffd\ufffd~ztzr z{m{z\ufffdoz\ufffd q{~43n{yktz\u20ac *\u20acoo [7\\klwo tz\n[4Ltwoq{~\ufffdsoo\u00f0mw\ufffdnon n{yktz\u20ac+1 _oknnt\ufffdt{zkww\u00de o\u00f0mw\ufffdnon \ufffdso\u20ac{mtkw yontk \u20act\ufffdo\u20acTwitter.\nWordpress kznReddit? \ufffdso\u20aco n{z{\ufffdsk\ufffdo ont\ufffd{~tkw m{z\ufffd~{w kzn \ufffdso~oq{~o wkmv k\ufffdztqton tno{w{rt/\nmkw|{\u20act\ufffdt{z1 \\st\u20ac woq\ufffdk\u20aco\ufffd{q:5n{yktz\u20ac \ufffd{lom{non1 Kkms o\u00f0\ufffd~km\ufffd m{z\u20act\u20ac\ufffdon {q\ufffd|\ufffd{\ufffds~oo\nm{y|wo\ufffdo |k~kr~k|s\u20ac *{qk\ufffdwok\u20ac\ufffd 63\u00d0{~n\u20ac+ q~{y \ufffdsowtzvon \u00d0ol |kro \ufffdo\u00f0\ufffd1 \\{wtyt\ufffd kz\u00de\u20ac\ufffdluom/\n\ufffdt\ufffdt\ufffd\u00de k~t\u20actzr q~{y \ufffdsom{no~\u20ac) |o~\u20ac{zkw |o~\u20ac|om\ufffdt\ufffdo\u20ac. okms o\u00f0\ufffd~km\ufffd \u00d0k\u20ackz{z\u00deyt\u20acon *t1o1\u20ac{\ufffd~mo\nn{yktz kzn k\ufffd\ufffds{~ tzq{~yk\ufffdt{z \u00d0o~o ~oy{\ufffdon+ \u00d0soz |~o\u20acoz\ufffdon q{~m{ntzr1\nI{no~\u20ac \u00d0o~o |~{\ufffdtnon \u00d0t\ufffds \ufffdsoq{ww{\u00d0tzr noqtzt\ufffdt{z\u20ac \ufffd{sow| ykvo \ufffdsot~ k\u20ac\u20aco\u20ac\u20acyoz\ufffd\u20ac>\n\u02ddLeft> Fwoq\ufffd/\u00d0tzr \u20ac\ufffdkzmo mkzlomsk~km\ufffdo~t\u20acon l\u00de\ufffdso|~{y{\ufffdt{z {q\u20ac\ufffdk\ufffdo lozoqt\ufffd\u20ac kzn \u20aco~\ufffdtmo\u20ac.\n|\ufffdlwtm tz\ufffdo\u20ac\ufffdyoz\ufffd tzkzn ~or\ufffdwk\ufffdt{z {q|~t\ufffdk\ufffdo l\ufffd\u20actzo\u20ac\u20aco\u20ac. tzm~ok\u20acon \ufffdk\u00f0k\ufffdt{z {qm{~|{~k\ufffdt{z\u20ac\nkzn strs ok~zo~\u20ac. kzn \u20ac\ufffd||{~\ufffd q{~\u00d0{~vo~\u20ac kzn \ufffd~kno \ufffdzt{z\u20ac1\n\u02ddRight> F~trs\ufffd/\u00d0tzr \u20ac\ufffdkzmo mkzlomsk~km\ufffdo~t\u20acon l\u00de|~{y{\ufffdtzr w{\u00d0\ufffdk\u00f0k\ufffdt{z kzn ytztyt\u20actzr\n\ufffdsotz\ufffdo~qo~ozmo {qr{\ufffdo~zyoz\ufffd tz|o~\u20ac{zkw kzn l\ufffd\u20actzo\u20ac\u20ac wt\ufffdo\u20ac1 W\ufffdlwtm tz\ufffdo\u20ac\ufffdyoz\ufffd t\u20acytzt/\nyt\u20acon. tzqk\ufffd{\ufffd~ {qkww{\u00d0tzr yk~vo\ufffd q{~mo\u20ac \ufffd{m{z\ufffd~{w r~{\u00d0\ufffds kzn |~{\ufffdt\u20act{z {q\u20aco~\ufffdtmo\u20ac1\n\u02ddEnvironmentalist> Fzoz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd \u20ac\ufffdkzmo \u20ac\ufffd||{~\ufffd\u20ac \ufffdso\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac {zkz\ufffds~{/\n|{roztm mwtyk\ufffdo mskzro kzn |~{y{\ufffdo\u20ac tyyontk\ufffdo km\ufffdt{z l\u00der{\ufffdo~zyoz\ufffd\u20ac kzn tznt\ufffdtn\ufffdkw\u20ac \ufffd{\nyt\ufffdtrk\ufffdo \ufffdsoq\ufffd\ufffd\ufffd~o ty|km\ufffd\u20ac1\n\u02ddSceptic> Fmwtyk\ufffdo \u20acmo|\ufffdtm \u20ac\ufffdkzmo {||{\u20aco\u20ac \ufffdso\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac {zkz\ufffds~{|{roztm mwtyk\ufffdo\nmskzro1 [\ufffdms {||{\u20act\ufffdt{z \ufffdk~to\u20ac q~{y }\ufffdo\u20ac\ufffdt{ztzr \ufffdsoo\u00f0t\u20ac\ufffdozmo {~mk\ufffd\u20aco\u20ac {qmwtyk\ufffdo mskzro.\n\ufffd{{||{\u20actzr oqq{~\ufffd\u20ac \ufffd{yt\ufffdtrk\ufffdo t\ufffd\u20acty|km\ufffd\u20ac1\nKkms m{no~ k\u20ac\u20actrzon k\u20acm{~o \ufffd{okms k~\ufffdtmwo o\u00f0\ufffd~km\ufffd tzno|oznoz\ufffdw\u00de1 \\sk\ufffd t\u20ac.\u20act\u00f0m{no~\u20ac rozo~/\nk\ufffdon \ufffd|\ufffd{qt\ufffdo\u20acm{~o\u20ac q{~okms {q:5n{yktz\u20ac *tz|~km\ufffdtmo. \ufffdst\u20acky{\ufffdz\ufffdon \ufffd{4:=< \u20acm{~o\u20ac {\ufffd\ufffd{qk\nyk\u00f0ty\ufffdy {q4<:3. \u00d0t\ufffds okms n{yktz ~omot\ufffdtzr \ufffd|\ufffd{63\u20acm{~o\u20ac+1 Kkms k~\ufffdtmwo \u20acm{~o t\u20ackztz\ufffdoro~\nnoz{\ufffdtzr \ufffdsowo\ufffdow {qtno{w{rtmkw ltk\u20ac \ufffdsom{no~ {l\u20aco~\ufffdo\u20ac tz\ufffdsk\ufffd k~\ufffdtmwo */42324 q{~woq\ufffd2zo\ufffd\ufffd~kw2\n~trs\ufffd {~oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd2zo\ufffd\ufffd~kw2\u20acmo| \ufffdtm.tz{~no~. \u00d0t\ufffds \ufffdzmwok~ \u20acm{~o\u20ac trz{~on? \u20acoo[6\n\\klwo tz[4Ltwo+1 \\so k~\ufffdtmwo \u20acm{~o\u20ac k\u20ac\u20actrzon l\u00deokms m{no~ \u00d0o~o \ufffdsoz k\ufffdo~kron q{~okms n{yktz\n\ufffd{no\ufffdo~ytzo kz{\ufffdo~kww n{yktz \u20acm{~o q{~\ufffdsk\ufffd m{no~1 Kkms n{yktz \u20acm{~o t\u20ack~okw/\ufffdkw\ufffdon z\ufffdy/\nlo~tz\ufffdso~kzro d\u22124. 4f?\ufffdso~o k~o:\u20acm{~o\u20ac q{~okms n{yktz. {zoq~{y okms m{no~1\n[tzmo \ufffdsok\u20ac\u20actrzyoz\ufffd {qtno{w{rtmkw ltk\u20ac t\u20ac\u20ac{yo\u00d0sk\ufffd \u20ac\ufffdluom\ufffdt\ufffdo. \u00d0o|o~q{~yon kzknu\ufffd\u20ac\ufffd/\nyoz\ufffd \ufffd{\ufffdson{yktz \u20acm{~o\u20ac k\u20ac\u20actrzon l\u00deokms m{no~1 \\st\u20ac knu\ufffd\u20ac\ufffdyoz\ufffd z{~ykwt\u20acon okms n{yktz\n\u20acm{~o l\u00de\u20ac\ufffdl\ufffd~km\ufffdtzr \ufffdsoyokz n{yktz \u20acm{~o q{~\ufffdsk\ufffd m{no~ km~{\u20ac\u20ac kww:5n{yktz\u20ac. \ufffdsoz nt\ufffdtntzr\nl\u00de\ufffdso\u20ac\ufffdkznk~n no\ufffdtk\ufffdt{z1 \\st\u20ac |~{mo\u20ac\u20ac ~o|~o\u20acoz\ufffd\u20ac n{yktz \u20acm{~o\u20ac k\u20acz/\u20acm{~o\u20ac kzn z{~ykwt\u20acon\nq{~\u20ac\ufffdluom\ufffdt\ufffdo ltk\u20ac {qtznt\ufffdtn\ufffdkw m{no~\u20ac1 Ltzkww\u00de. \u00d0ok\ufffdo~kro \ufffdsoz{~ykwt\u20acon n{yktz \u20acm{~o\u20ac\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 =259\nkm~{\u20ac\u20ac kwwm{no~\u20ac \ufffd{qtzn k\u20actzrwo n{yktz \u20acm{~o1 \\st\u20ac |~{mo\u20ac\u20ac \u00d0k\u20ack||wton q{~l{\ufffds |{wt\ufffdtmkw kzn\nmwtyk\ufffdo mskzro tno{w{r\u00de1 [tzmo u\ufffdnryoz\ufffd {qmwtyk\ufffdo mskzro tno{w{r\u00de ~owto\u20ac {z\u20ac{yo vz{\u00d0wonro\n{qmwtyk\ufffdo mskzro *o1r1 \ufffdso\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac+ \ufffdsom{no~\u20ac \u00d0o~o ~om~\ufffdt\ufffdon q~{y \ufffdso|{\u20ac\ufffdr~kn\ufffd/\nk\ufffdo~o\u20acok~ms m{yy\ufffdzt\ufffd\u00de tz\u20acmtozmo\u20ac k\ufffd\ufffdso]zt\ufffdo~\u20act\ufffd\u00de {qK\u00f0o\ufffdo~1\nL\ufffdww ~o\u20ac\ufffdw\ufffd\u20ac q{~\ufffdsom{ntzr {qokms n{yktz k~o|~o\u20acoz\ufffdon tz[5Ltrtz[4Ltwo1 \\{\ufffdo\u20ac\ufffd\ufffdso~owt/\nkltwt\ufffd\u00de {q{\ufffd~m{ntzr o\u00f0o~mt\u20aco \u00d0om{y|k~o {\ufffd~r~kno\u20ac \ufffd{\ufffdson{yktz k\u20ac\u20aco\u20ac\u20acyoz\ufffd\u20ac l\u00deTontk\nGtk\u20ac2Lkm\ufffd Isomv d7=f *TGLI+. kqkm\ufffd/msomvtzr kzn yontk ltk\u20ac \u20act\ufffdo1 _o\ufffd~kz\u20acwk\ufffdo \ufffdsoTGLI ~k\ufffd/\ntzr\u20ac \ufffd{{\ufffd~{\u00d0z \u20acmkwo kzn k||w\u00de \ufffdso\u20ackyoz/\u20acm{~o z{~ykwt\u20ack\ufffdt{z. \ufffdsoz mkwm\ufffdwk\ufffdon \ufffdsom{~~owk\ufffdt{z\n{q\ufffdso|{wt\ufffdtmkw ltk\u20ac \u20acm{~o\u20ac l\u00de{\ufffd~m{no~\u20ac krktz\u20ac\ufffd \ufffds{\u20aco q~{y TGLI q{~\ufffds{\u20aco n{yktz\u20ac \u00d0stms\nsk\ufffdo looz ~k\ufffdon l\u00deTGLI1 _oqtzn \u20ac\ufffd~{zr |{\u20act\ufffdt\ufffdo m{~~owk\ufffdt{z *Wok~\u20ac{z)\u20ac rB31<.pD43\u2212:.\nnB7=+noy{z\u20ac\ufffd~k\ufffdtzr \ufffdsk\ufffd \ufffdso|{wt\ufffdtmkw m{ntzr |~{mo\u20ac\u20ac t\u20acm{z\u20act\u20ac\ufffdoz\ufffd \u00d0t\ufffds \ufffdsoo\u00f0|o~\ufffd k\u20ac\u20aco\u20ac\u20ac/\nyoz\ufffd\u20ac |~{\ufffdtno l\u00deTGLI1 U{o}\ufffdt\ufffdkwoz\ufffd o\u00f0\ufffdo~zkw k\u20ac\u20aco\u20ac\u20acyoz\ufffd\u20ac k~ok\ufffdktwklwo q{~mwtyk\ufffdo mskzro\ntno{w{r\u00de. l\ufffd\ufffd\ufffdso~{l\ufffd\u20ac\ufffd |o~q{~ykzmo {q{\ufffd~m{ntzr |~{mo\u20ac\u20ac q{~|{wt\ufffdtmkw ltk\u20ac rt\ufffdo\u20ac m{zqtnozmo\ntz\ufffdsoyo\ufffds{n{w{r\u00de1 [ooLtr5kkzn 5lq{~\ufffdsok\ufffdo~kro ~o\u20ac\ufffdw\ufffd\u20ac km~{\u20ac\u20ac n{yktz\u20ac kzn m{no~\u20ac q{~\n|{wt\ufffdtmkw kzn mwtyk\ufffdo mskzro ltk\u20ac ~o\u20ac|om\ufffdt\ufffdow\u00de1\nI{y|k~t\u20ac{z\u20ac {\ufffdo~ \ufffdtyo\n\\{yok\u20ac\ufffd~o \ufffdsomskzro tz|k\ufffd\ufffdo~z\u20ac {q\u20acsk~tzr mwtyk\ufffdo yontk {\ufffdo~ \ufffdtyo. \ufffdso|kt~\u00d0t\u20aco \u20actytwk~t\ufffd\u00de\n{q\ufffdso\u20aco\ufffd\u20ac{q\ufffd\u20aco~\u20ac. k~\ufffdtmwo\u20ac *]ZS\u20ac+ kzn \u20ac{\ufffd~mo n{yktz\u20ac \u00d0k\u20acmkwm\ufffdwk\ufffdon q{~\ufffdso\u20aco\ufffdoz \u00d0oov\u20ac tz\n\ufffdso\u20ac\ufffd\ufffdn\u00de |o~t{n1 Fzk\u20ac\u00deyyo\ufffd~tm \u20actytwk~t\ufffd\u00de yok\u20ac\ufffd~o t\u20acnoqtzon \ufffd{rt\ufffdo kztzntmk\ufffdt{z {q|o~\u20act\u20ac/\n\ufffdozmo lo\ufffd\u00d0ooz \u00d0oov\u20ac kzn tnoz\ufffdtq\u00de tzqw\ufffd\u00f0o\u20ac {qzo\u00d0 |k~\ufffdtmt|kz\ufffd\u20ac {~m{z\ufffdoz\ufffd1 \\st\u20ac o\u00f0|~o\u20ac\u20act{z\nm{y|k~o\u20ac \u00d0oov\u20acAkznBl\u00de\ufffdsoq~km\ufffdt{z {q\ufffdso\ufffd\u20aco~\u20ac.u.wtzv\u20ac.l.{~n{yktz\u20ac. d.\ufffdsk\ufffd k||ok~on tz\n\u00d0oovA\ufffdsk\ufffd kw\u20ac{ k||ok~on tz\u00d0oovB1Oz{~no~ \ufffd{kmm{\ufffdz\ufffd q{~\ufffdso~o|ok\ufffdon \ufffd\u20ackro m{yy{z tz\n{zwtzo \u20ac{mtkw zo\ufffd\u00d0{~v\u20ac. kyok\u20ac\ufffd~o {qs{\u00d0 ykz\u00de \ufffdtyo\u20ac k\ufffd\u20aco~. ]ZS {~n{yktz k||ok~\u20ac tzokms\n{q\ufffdso\ufffd\u00d0{\u00d0oov\u20ac t\u20actzmw\ufffdnon l\u00de\ufffd\u20actzr y\ufffdw\ufffdt\u20aco\ufffd\u20ac q{~u.lkznd1\nSu\nACB\u0088yuAiuBy\nyuAyCSl\nACB\u0088ylAilBy\nylAyCSd\nACB\u0088ydAidBy\nydAyB\u00856\u0086\n^kw\ufffdo\u20ac {q\ufffdso\u20actytwk~t\ufffd\u00de yok\u20ac\ufffd~o qkww\u00d0t\ufffdstz \ufffdso~kzro d3.4f1^kw\ufffdo\u20ac k||~{kmstzr 3\u20actrztq\u00de\n\ufffdsk\ufffd \ufffdo~\u00de qo\u00d0{q\ufffdso\ufffd\u20aco~\u20ac *~o\u20ac|om\ufffdt\ufffdow\u00de ]ZS\u20ac. n{yktz\u20ac+ tz\u00d0oovAk~okw\u20ac{ |~o\u20acoz\ufffd tz\u00d0oovB.\n\u00d0so~ok\u20ac \ufffdkw\ufffdo\u20ac k||~{kmstzr 4\u20actrztq\u00de \ufffdsk\ufffd zok~w\u00de kww{q\ufffdso\ufffd\u20aco~\u20ac *~o\u20ac|om\ufffdt\ufffdow\u00de ]ZS\u20ac. n{yktz\u20ac+\ntz\u00d0oovAk~okw\u20ac{ |~o\u20acoz\ufffd tz\u00d0oovB1U{\ufffdo \ufffdsk\ufffd l\u00deno\u20actrzSA.B=\u0088SB.Aq{~A=\u0088Btzrozo~kw1\nZo\ufffd\ufffdw\ufffd\ufffd\n\\st\u20ac \u20acom\ufffdt{z nt\ufffdtno\u20ac {\ufffd~~o\u20ac\ufffdw\ufffd\u20ac tz\ufffd{ \ufffds~oo yktz qtzntzr\u20ac1 Oz\ufffdsoqt~\u20ac\ufffd |k~\ufffd \u00d0oq{m\ufffd\u20ac {z_oov 7\n{q\ufffdso\u20ac\ufffd\ufffdn\u00de |o~t{n. tz\u00d0stms \ufffdso][\u00d0t\ufffdsn~k\u00d0kw q~{y \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd \u00d0k\u20ackzz{\ufffdzmon. \ufffd{\nnoy{z\u20ac\ufffd~k\ufffdo \ufffdsol~{kn tno{w{rtmkw |{wk~t\u20ack\ufffdt{z {l\u20aco~\ufffdon tz\ufffdsotzq{~yk\ufffdt{z/\u20acsk~tzr zo\ufffd\u00d0{~v\u20ac1\n[om{znw\u00de. \u00d0omsk~km\ufffdo~t\u20aco \ufffdso\u20ac\ufffdl/m{yy\ufffdzt\ufffdto\u20ac \ufffdsk\ufffd ykvo \ufffd|\ufffdsozo\ufffd\u00d0{~v. \u20acs{\u00d0tzr \ufffdsk\ufffd \u20aco\ufffd/\no~kwwtzvon woq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffd kwt\u20ac\ufffd m{yy\ufffdzt\ufffdto\u20ac m{/o\u00f0t\u20ac\ufffd \u00d0t\ufffds k\u20actzrwo ~trs\ufffd/\u00d0tzr2\u20acmo|\ufffdtm\nm{yy\ufffdzt\ufffd\u00de1 Ltzkww\u00de. \u00d0ow{{v k\ufffdkww\u20aco\ufffdoz \u00d0oov\u20ac tz\ufffdso\u20ac\ufffd\ufffdn\u00de |o~t{n \ufffd{o\u00f0|w{~o s{\u00d0 zo\ufffd\u00d0{~v\n\u20ac\ufffd~\ufffdm\ufffd\ufffd~o kzn |{wk~t\u20ack\ufffdt{z mskzro\u20ac {\ufffdo~ \ufffdtyo1\nIwtyk\ufffdo yontk \u20acsk~tzr t\u20ac|{wk~t\u20acon kzn |{wt\ufffdtmt\u20acon\n_olortz l\u00demsk~km\ufffdo~t\u20actzr \ufffdsotzq{~yk\ufffdt{z/\u20acsk~tzr zo\ufffd\u00d0{~v n\ufffd~tzr \ufffdsomoz\ufffd~kw \u00d0oov {q\ufffdso\n\u20ac\ufffd\ufffdn\u00de |o~t{n. _oov 7.tz\u00d0stms \ufffdso][\u00d0t\ufffdsn~k\u00d0kw q~{y \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd \u00d0k\u20ackzz{\ufffdzmon1\nJ\ufffd~tzr \ufffdst\u20ac\u00d0oov. ;.7=:]ZS\u20ac \u00d0o~o \u20acsk~on l\u00de75.446\\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\u20ac1 Fq\ufffdo~ |~{uom\ufffdt{z \ufffdst\u20ac|~{/\nn\ufffdmo\u20ac k\ufffdzt|k~\ufffdt\ufffdo zo\ufffd\u00d0{~v {q;.7=:]ZS\u20ac m{zzom\ufffdon l\u00de43;. 637onro\u20ac tzntmk\ufffdtzr \u00d0stms |kt~\u20ac\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 43259\n{q]ZS\u20ac \u00d0o~o m{/\u20acsk~on1 Ltr6\u20acs{\u00d0\u20ac \ufffdso]ZS m{/\u20acsk~o zo\ufffd\u00d0{~v {q\ufffdsoqt\ufffdowk~ro\u20ac\ufffd m{yy\ufffdzt/\n\ufffdto\u20acl\u00de\ufffd{\ufffdkw \u20acsk~o m{\ufffdz\ufffd1 \\so wk\u00de{\ufffd\ufffd t\u20acno\ufffdo~ytzon l\u00de\ufffdsoL{~moF\ufffdwk\u20ac5 kwr{~t\ufffdsy d93f. \u00d0stms\nr~{\ufffd|\u20ac noz\u20acow\u00de m{zzom\ufffdon z{no\u20ac \ufffd{ro\ufffdso~? \ufffdt\u20ac\ufffdkw tz\u20ac|om\ufffdt{z \u20acs{\u00d0\u20ac kmwok~ |k~\ufffdt\ufffdt{z tz\ufffd{ \ufffd\u00d0{\nwk~ro mw\ufffd\u20ac\ufffdo~\u20ac1 Fwr{~t\ufffdsytm m{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z ~o\ufffdokw\u20ac q\ufffd~\ufffdso~ |k~\ufffdt\ufffdt{ztzr \u00d0t\ufffdstz \ufffdsowk~ro~\nmw\ufffd\u20ac\ufffdo~ {q\ufffdsozo\ufffd\u00d0{~v. tww\ufffd\u20ac\ufffd~k\ufffdon l\u00de\ufffdsontqqo~oz\ufffd z{no m{w{\ufffd~\u20ac1 G\u00dem{z\u20actno~tzr \ufffdsom{z\ufffd~k\u20ac\ufffdtzr\n\u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac q{\ufffdzn l\u00de\ufffdsom{yy\ufffdzt\ufffd\u00de no\ufffdom\ufffdt{z kzn zo\ufffd\u00d0{~v wk\u00de{\ufffd\ufffd kwr{~t\ufffdsy\u20ac. \ufffdso~o t\u20aco\ufffdtnozmo\n{qy\ufffdw\ufffdt|wo wk\u00deo~\u20ac {q\u20ac\ufffd~\ufffdm\ufffd\ufffd~o \u00d0t\ufffdstz \ufffdsozo\ufffd\u00d0{~v1 U{\ufffdo \ufffdsk\ufffd \ufffdsowk~ro \u00deoww{\u00d0 z{no \u20aco|k~k\ufffdon\nLtr51F\ufffdo~kro n{yktz tno{w{rt mkw|{\u20act\ufffdt{ z\u20ack\u20ac\u20actrzon l\u00deokms m{no~ kzn \ufffdso{\ufffdo~kww k\ufffdo~kro km~{\u20ac\u20ac kwwm{no~\u20ac1 ^kw\ufffdo\u20ac \u20acs{\ufffdwn lo\ufffds{\ufffdrs\ufffd\n{qk\u20ac\u20ac\ufffdkznk~n no\ufffdtk\ufffdt{z\u20ac q~{y \ufffdsoyokz1 ^o~\ufffdtmkw lk~\u20ac tzntmk\ufffdo\u00b1{zo\u20ac\ufffdkznk~n no\ufffdtk\ufffdt{z km~{\u20ac\u20ac \ufffdsom{no~\u20ac1\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{z o13593:9:1r3 35\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 44259\nq~{y \ufffdso\ufffd\u00d0{yktz mw\ufffd\u20ac\ufffdo~\u20ac t\u20acyoutube.com/watch1 \\st\u20ac z{no t\u20acntqqtm\ufffdw\ufffd \ufffd{tz\ufffdo~|~o\ufffd k\u20act\ufffdkrr~o/\nrk\ufffdo\u20ac ykz\u00de b{\ufffd\\\ufffdlo \ufffdtno{ wtzv\u20ac. \u20acooytzrw\u00de q~{y kww\u20actno\u20ac {q\ufffdsonolk\ufffdo1 _omkzz{\ufffd \ufffdo~tq\u00de \ufffdst\u20ac\n\u00d0t\ufffds {\ufffd~\ufffdo\u00f0\ufffd/lk\u20acon m{z\ufffdoz\ufffd kzkw\u00de\u20act\u20ac1\n\\so~o t\u20ack\u20ac\ufffd~{zr m{~~owk\ufffdt{z lo\ufffd\u00d0ooz {|tzt{z\u20ac kl{\ufffd\ufffd mwtyk\ufffdo mskzro kzn |{wt\ufffdtmkw tno{w{r\u00de\no\u00f0|~o\u20ac\u20acon tz\u20acsk~on m{z\ufffdoz\ufffd1 Ltr7|w{\ufffd\u20ac \ufffdso|{\u20act\ufffdt{z {q\ufffdso:5\u00d0ol n{yktz\u20ac {zk\u00f0o\u20ac {qmwtyk\ufffdo\nltk\u20ac kzn |{wt\ufffdtmkw ltk\u20ac. lk\u20acon {zm{z\ufffdoz\ufffd {qk~\ufffdtmwo\u20ac m{non l\u00de\ufffdso|kzow1 Soq\ufffd/~trs\ufffd |{wt\ufffdtmkw tno{w/\n{r\u00dekzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd/\u20ac mo|\ufffdtm mwtyk\ufffdo {|tzt{z\u20ac k~o\ufffdo~\u00de \u20ac\ufffd~{zrw\u00de m{~~owk\ufffdon *Wok~\u20ac{z)\u20ac\nrB31<:+ kzn \ufffdo~\u00de qo\u00d0n{yktz\u20ac k||ok~ tz\ufffdso~trs\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffdk wt\u20ac\ufffdkzn woq\ufffd/\u00d0tzr2\u20acmo|/\n\ufffdtm}\ufffdkn~kz\ufffd\u20ac1\nTk||tzr tno{w{rto\u20ac2{|tzt{z\u20ac k\u20ac\u20ac{mtk\ufffdon \u00d0t\ufffds \u00d0ol n{yktz\u20ac {z\ufffd{ \ufffdsotzq{~yk\ufffdt{z/\u20acsk~tzr\nzo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o \u20acs{\u00d0\u20ac kzk\u20ac\u20ac{mtk\ufffdt{z lo\ufffd\u00d0ooz zo\ufffd\u00d0{~v |{\u20act\ufffdt{z kzn \ufffdto\u00d0|{tz\ufffd1 Ltr9\u20acs{\u00d0\u20ac\n\ufffdsozo\ufffd\u00d0{~v ntkr~ky q~{y Ltr6\u00d0t\ufffds ]ZS/z{no m{w{\ufffd~\u20ac kw\ufffdo~on \ufffd{\u20acs{\u00d0 ltk\u20aco\u20ac tz\ufffdso|{wt\ufffdtmkw2\nmwtyk\ufffdo {|tzt{z\u20ac o\u00f0|~o\u20ac\u20acon l\u00de\ufffdsot~ \u00d0ol n{yktz\u20ac1 Ltr9km{w{\ufffd~\u20ac \ufffdsoz{no\u20ac \ufffd{strswtrs\ufffd \ufffdso\nwoq\ufffd/~trs\ufffd |{wt\ufffdtmkw ltk\u20ac1 \\so woq\ufffd/skzn mw\ufffd\u20ac\ufffdo~ m{z\ufffdktz\u20ac |~on{ytzkz\ufffdw\u00de woq\ufffd/\u00d0tzr \u20act\ufffdo\u20ac1 \\so ~trs\ufffd/\nskzn mw\ufffd\u20ac\ufffdo~ sk\u20ackstrs m{zmoz\ufffd~k\ufffdt{z {q~trs\ufffd/\u00d0tzr \u20act\ufffdo\u20ac. l\ufffd\ufffdkw\u20ac{ sk\u20acykz\u00de \ufffdzm{non \u20act\ufffdo\u20ac1 F\n\u20actytwk~ |k\ufffd\ufffdo~z mkzlo\u20acooz tzLtr9l.\u00d0stms m{w{\ufffd~\u20ac z{no\u20ac l\u00demwtyk\ufffdo mskzro ltk\u20ac. \u00d0t\ufffds \ufffdso\nwoq\ufffd/skzn mw\ufffd\u20ac\ufffdo~ |~on{ytzkz\ufffdw\u00de oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd kzn \ufffdso~trs\ufffd/skzn mw\ufffd\u20ac\ufffdo~ m{z\ufffdktztzr y{\u20ac\ufffd\nLtr61Ozq{~yk\ufffd t{z/\u20acsk~tzr zo\ufffd\u00d0{~v\u20ac k~o|{wk~t\u20acon1 Ww{\ufffd \u20acs{\u00d0\u20ac \ufffdso]ZS m{/\u20acsk~tz rzo\ufffd\u00d0{~v q{~\ufffdso\u00d0oov tz\u00d0stms \ufffdso][\u00d0t\ufffdsn~k\u00d0kw\nq~{y \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd \u00d0k\u20ackzz{\ufffdzmon *_oov 7{q\ufffdso\u20ac\ufffd\ufffdn\u00de |o~t{n+1 \\so qt\ufffdowk~ro\u20ac\ufffd m{yy\ufffdzt\ufffdt o\u20acl\u00de\ufffd{\ufffdkw \u20acsk~o m{\ufffdz\ufffd k~ont\u20ac|wk\u00deon\n*:;1:=& {q;.7=:z{no\u20ac+1 I{yy\ufffdzt \ufffdto\u20ac4\u22129k~om{w{\ufffd~on lw\ufffdo. \u00deoww{\u00d0. r~ooz. ~onkzn |\ufffd~|wo ~o\u20ac|om\ufffdt\ufffdow\u00de kzn z{no \u20act\u00feot\u20ac|~{|{~\ufffdt {zkw\n\ufffd{\ufffdso\u20ac}\ufffdk~o ~{{\ufffd {q\ufffd{\ufffdkw \u20acsk~o m{\ufffdz\ufffd1 U{no |wkmoyoz\ufffd \ufffd\u20aco\u20ac kq{~mo/nt ~om\ufffdon kwr{~t\ufffdsy d93f \u00d0stms r~{\ufffd|\u20ac noz\u20acow\u00de m{zzom\ufffdon z{no\u20ac\n\ufffd{ro\ufffdso~? \ufffdst\u20acwk\u00de{\ufffd\ufffd strswtrs\ufffd\u20ac \ufffd\u00d0{wk~ro mw\ufffd\u20ac\ufffdo~\u20ac. \u00d0t\ufffds q{\ufffd~ m{yy\ufffdzt\ufffdt o\u20ac{z\ufffdsowoq\ufffdkzn k\u20actzrwo m{yy\ufffdzt\ufffd\u00de {z\ufffdso~trs\ufffd1\ns\ufffd\ufffd|\ufffd>22n{t1{ ~r243146;42u {\ufffd~zkw1|{zo 13593:9:1r336\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 45259\n{q\ufffdso\u20acmo|\ufffdtm n{yktz\u20ac1 \\kvoz \ufffd{ro\ufffdso~. \ufffdso\u20aco qtzntzr\u20ac noy{z\u20ac\ufffd~k\ufffdo \u20actrztqtmkz\ufffd \u20ac\ufffd~ozr\ufffds {q\n|{wk~t\u20ack\ufffdt{z kzn |{wt\ufffdtmt\u20ack\ufffdt{z tztzq{~yk\ufffdt{z/\u20acsk~tzr kl{\ufffd\ufffd mwtyk\ufffdo mskzro {z\\\u00d0t\ufffd\ufffdo~. \u00d0t\ufffds\n\ufffd\u00d0{wk~ro mw\ufffd\u20ac\ufffdo~\u20ac {q\ufffd\u20aco~\u20ac kzn tzq{~yk\ufffdt{z \u20ac{\ufffd~mo\u20ac. l~{knw\u00de msk~km\ufffdo~t\u20acon k\u20ackwoq\ufffd/\u00d0tzr2oz\ufffdt/\n~{zyoz\ufffdkwt\u20ac\ufffd r~{\ufffd| kzn k~trs\ufffd/\u00d0tzr2\u20acmo|\ufffdtm r~{\ufffd|1\nIsk~km\ufffdo~t\u20ack\ufffdt{z {qtzq{~yk\ufffdt{z/\u20acsk~tzr m{yy\ufffdzt\ufffdto\u20ac\n\\so yktz \u20ac{\ufffd~mo n{yktz\u20ac kzn tzntmk\ufffdt\ufffdo m{z\ufffdoz\ufffd {qyontk k~\ufffdtmwo\u20ac \u20acsk~on \u00d0t\ufffdstz \ufffdsoqt\ufffdowk~r/\no\u20ac\ufffdm{yy\ufffdzt\ufffdto\u20ac tz_oov 7mkzlo\u20acooz tzLtr:.tz\u00d0stms \ufffdso~kntt {q\ufffdsomt~mwo\u20ac \u20acs{\u00d0 \ufffdso~owk/\n\ufffdt\ufffdo\u20act\u00feo\u20ac {q\ufffdso\u20aco yku{~ m{yy\ufffdzt\ufffdto\u20ac1 No~o I{yy\ufffdzt\ufffdto\u20ac 4.6.7kzn 9k~om{yy\ufffdzt\ufffdto\u20ac\n\u00d0t\ufffdstz \ufffdsowoq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffdkwt \u20ac\ufffdmw\ufffd\u20ac\ufffdo~ tz\ufffdsotzq{~yk\ufffdt{z/\u20acsk~tzr zo\ufffd\u00d0{~v. \u00d0so~ok\u20ac\nI{yy\ufffdzt\ufffd\u00de 5t\u20ac\ufffdso\u20actzrwo m{yy\ufffdzt\ufffd\u00de tz\ufffdso~trs\ufffd/\u00d0tzr2\u20acmo|\ufffdtm mw\ufffd\u20ac\ufffdo~1 Ltr:\ufffd\u20aco\u20ac k\\L/OJL\n\u00d0otrs\ufffdtzr \u20acmsoyo q{~okms \ufffd{voz. \u20ac\ufffdms \ufffdsk\ufffd \ufffdso|~{ytzoz\ufffd \ufffd{voz\u20ac k~o\ufffds{\u20aco \ufffdsk\ufffd k~omsk~km\ufffdo~/\nt\u20ac\ufffdtm {qk|k~\ufffdtm\ufffdwk~ m{yy\ufffdzt\ufffd\u00de \u00d0soz m{y|k~on \ufffd{\ufffdsozo\ufffd\u00d0{~v k\u20ack\u00d0s{wo1 [{\ufffd~mo n{yktz\u20ac k~o\n\u20acs{\u00d0z tzLtr:kkzn m{z\ufffdoz\ufffd t\u20ac\u20acs{\u00d0z tzLtr:l*\ufffdztr~ky\u20ac+ kzn Ltr:m*ltr~ky\u20ac+. \ufffd{kww{\u00d0 k\nmsk~km\ufffdo~t\u20ack\ufffdt{z {q\ufffdsol~{kn \ufffdsoyo\u20ac tzokms m{yy\ufffdzt\ufffd\u00de tz\ufffdo~y\u20ac {qro{r~k|stm q{m\ufffd\u20ac. |{wt\ufffdtmkw\n{~mwtyk\ufffdo \u20acmtozmo ltk\u20aco\u20ac kzn vo\u00de\u20ac\ufffdluom\ufffd\u20ac {qtz\ufffdo~o\u20ac\ufffd1 \\klwo 5\u20ac\ufffdyyk~t\u20aco\u20ac \ufffdso\u20aco m{yy\ufffdzt\ufffdto\u20ac\n\ufffd\u20actzr \ufffdsonk\ufffdk q~{y Ltr:1\nS{{vtzr k\ufffd\u20ac{\ufffd~mo n{yktz\u20ac *Ltr :k+.ntqqo~oz\ufffd ro{r~k|stm kzn |{wt\ufffdtmkw ltk\u20aco\u20ac mkzlo\ntzqo~~on lk\u20acon {zok~wto~ kzkw\u00de\u20act\u20ac {qn{yktz tno{w{r\u00de1 I{yy\ufffdzt\ufffd\u00de 5qok\ufffd\ufffd~o\u20ac |~on{ytzkz\ufffdw\u00de\n~trs\ufffd/\u00d0tzr \u20ac{\ufffd~mo\u20ac. \u00d0so~ok\u20ac I{yy\ufffdzt\ufffdto\u20ac 4\u20196/9m{z\ufffdktz m{z\ufffdoz\ufffd q~{y woq\ufffd/\u00d0tzr \u20ac{\ufffd~mo\u20ac1\nLtr71Iwtyk\ufffdo yontk m{z\ufffdoz\ufffd t\u20ac|{wt\ufffdtmt\u20acon1 Tokz |{wt\ufffdtmk wtno{w{r\u00de *woq\ufffd/\ufffd{/~trs\ufffd+ kzn mwtyk\ufffdo {|tzt{z\n*oz\ufffdt~{zy oz\ufffdkwt\u20ac\ufffd/\ufffd{/ \u20acmo|\ufffdtm+ o\u00f0|~o\u20ac\u20acon tzm{z\ufffdoz\ufffd q~{y \ufffdso:5m{non \u00d0ol n{yktz\u20ac {\ufffdo~ \ufffdso\u20act\u00f0m{no~\u20ac *\u20acoo Ono{w{rtmkw\nm{ntzr {q\u20ac{\ufffd~mo n{yktz\u20ac+ 1W{tz\ufffd \u20act\u00feot\u20ac|~{|{~\ufffdt{zk w\ufffd{\ufffdso\u20ac}\ufffdk~o ~{{\ufffd {q\ufffd{\ufffdkw \u20acsk~o m{\ufffdz\ufffd kzn wtzo\u20ac tzntmk\ufffdo\u00b1{zo\n\u20ac\ufffdkznk~n no\ufffdtk\ufffdt{z1 Sklow\u20ac k~o\u20acs{\u00d0z q{~43y{\u20ac\ufffd q~o}\ufffdoz\ufffdw\u00de \u20acsk~on n{yktz\u20ac tz\ufffdsom{non wt\u20ac\ufffd1\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o13593:9:1r3 37\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 46259\nLtr91Uo\ufffd\u00d0{~v mw\ufffd\u20ac\ufffdo~\u20ac k~otno{w{rt mkww\u00de ltk\u20acon1 \\so \ufffd\u00d0{wk~ro mw\ufffd\u20ac\ufffdo~\u20ac \u00d0t\ufffdstz \ufffdso]ZS m{/\u20acsk~tz rzo\ufffd\u00d0{~v q{~_oov\n7\u20acs{\u00d0z \u00d0t\ufffds ]ZS\u20ac m{w{\ufffd~on l\u00de>*k+\ufffdsok\ufffdo~kro |{wt\ufffdtmkw ltk\u20ac {q\ufffdsot~ \u20ac{\ufffd~mo n{yktz? kzn *l+\ufffdsok\ufffdo~kro mwtyk\ufffdo\nmskzro ltk\u20ac {q\ufffdsot~ \u20ac{\ufffd~mo n{yktz1 Zon noz{\ufffdo\u20ac woq\ufffd/\u00d0tzr n{yktz\u20ac. lw\ufffdo noz{\ufffdo\u20ac ~trs\ufffd/\u00d0tzr n{yktz\u20ac. r~ooz noz{\ufffdo\u20ac\noz\ufffdt~{zy oz\ufffdkwt\u20ac\ufffd n{yktz\u20ac. {~kzro noz{\ufffdo\u20ac \u20acmo|\ufffdtm n{yktz\u20ac1 _st\ufffdo noz{\ufffdo\u20ac kz\u00den{yktz m{non k\u20aczo\ufffd\ufffd~kw kzn n{yktz\u20ac\nz{\ufffdm{non k~otzr~k\u00de1\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o13593:9:1r3 39\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 47259\n\\o~y\u20ac \u20ac\ufffdms k\u20acdecision kznwithdraw tzokms {q\ufffdsom{yy\ufffdzt\ufffdto\u20ac \u20acs{\u00d0 \ufffdsk\ufffd \ufffdsoWk~t\u20ac Fr~oo/\nyoz\ufffd kzz{\ufffdzmoyoz\ufffd t\u20ackyku{~ \ufffd{|tm {qm{z\ufffdo~\u20ack\ufffdt{z n\ufffd~tzr \ufffdst\u20ac\u20aco\ufffdoz/nk\u00de |o~t{n. o\ufffdoz \u20ac|kz/\nztzr \ufffdsotno{w{rtmkw2ro{r~k|stm nt\ufffdt\u20act{z\u20ac tww\ufffd\u20ac\ufffd~k\ufffdon l\u00deLtr:k1\\so woq\ufffd/\u00d0tzr m{yy\ufffdzt\ufffdto\u20ac k~o\n~ok\u20ac{zklw\u00de \u20actytwk~ \ufffd{okms {\ufffdso~. \u00d0stwo \ufffdso~trs\ufffd/\u00d0tzr m{yy\ufffdzt\ufffd\u00de t\u20ac\ufffdzt}\ufffdo tzt\ufffd\u20acyoz\ufffdt{z {q\n|~o\ufffdt{\ufffd\u20ac ][|{wt\ufffdtmkw qtr\ufffd~o\u20ac \u20ac\ufffdms k\u20acObama kznGore kzn \ufffd\u20aco{q\u20acmtoz\ufffdtqtm \ufffdo~ytz{w{r\u00de1 \\so\nltr~ky\u20ac y{\u20ac\ufffdw\u00de m{zqt~y \ufffdsoqtzntzr\u20ac tzLtr:l.l\ufffd\ufffdkw\u20ac{ strswtrs\ufffd ntqqo~ozmo\u20ac tz\ufffdo~ytz{w{r\u00de.\no1r1r~ok\ufffdo~ |~{ytzozmo {qglobalwarming tz~trs\ufffd/\u00d0tzr I{yy\ufffdzt\ufffd\u00de 51Ltr:kzn \\klwo 5noy/\n{z\u20ac\ufffd~k\ufffdo \ufffdsk\ufffd \ufffdso~o t\u20ac\ufffdk~tk\ufffdt{z tz\ufffdsoro{r~k|stm \u20acm{|o {q\ufffdsom{yy\ufffdzt\ufffdto\u20ac1 \\so y{\u20ac\ufffd k||k~oz\ufffd\nm{z\ufffd~k\u20ac\ufffd o\u00f0t\u20ac\ufffd\u20ac lo\ufffd\u00d0ooz I{yy\ufffdzt\ufffd\u00de 4.\u00d0stms sok\ufffdtw\u00de qok\ufffd\ufffd~o\u20ac ]Rzo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac. kzn I{yy\ufffd/\nzt\ufffdto\u20ac 5kzn 6.\u00d0stms tzmw\ufffdno y{\u20ac\ufffdw\u00de ][\u20ac{\ufffd~mo\u20ac1 \\so nt\u20ac\ufffd~tl\ufffd\ufffdt{z {q\u00d0{~n\u20ac kzn ltr~ky\u20ac tzLtr\n:lkzn :m\u20acs{\u00d0 \u20ac{yo \ufffd{|tmkw ntqqo~ozmo\u20ac lo\ufffd\u00d0ooz \ufffdsoq{\ufffd~ m{yy\ufffdzt\ufffdto\u20ac tz\ufffdsowoq\ufffd/\u00d0tzr mw\ufffd\u20ac\ufffdo~1\nI{yy\ufffdzt\ufffdto\u20ac 6kzn 7tzmw\ufffdno y{~o \ufffdo~y\u20ac ~owk\ufffdon \ufffd{\ufffdsom{z\u20aco}\ufffdozmo\u20ac {q\ufffdsonomt\u20act{z q{~\ufffdso\nAmerican |o{|wo \u00d0so~ok\u20ac I{yy\ufffdzt\ufffd\u00de 4t\u20acyktzw\u00de m{zmo~zon \u00d0t\ufffds \ufffdsotz\ufffdo~zk\ufffdt{zkw |{wt\ufffdtmkw\nLtr:1[{\ufffd~mo n{yktz\u20ac kzn m{z\ufffdoz\ufffd {qyontk k~\ufffdtmwo\u20ac \u20acsk~on \u00d0t\ufffdstz \ufffdsoqt\ufffdo wk~ro\u20ac\ufffd m{yy\ufffdzt \ufffdto\u20ac tz\ufffdsotzq{~yk\ufffdt{z /\u20acsk~tzr zo\ufffd\u00d0{~v1\n\\{voz\u20ac tzokms |w{\ufffd k~o\u00d0otrs\ufffd on*\ufffd\u20actzr \\L/OJL+ \ufffd{ykvo nt\u20ac\ufffdtzm\ufffdt\ufffdo \ufffd{voz\u20ac |~{ytzoz\ufffd1 It~mwo \u20act\u00feot\u20ac\u20acmkwon \ufffd{tzntmk\ufffdo \ufffdso\ufffd{\ufffdkw z\ufffdylo~ {q\n]ZS \u20acsk~o\u20ac \u00d0t\ufffdstz \ufffdsom{yy\ufffdzt\ufffd\u00de1 \\o~y\u20ac m{w{\ufffd~on lwkmv k~o\ufffdsostrso\u20ac\ufffd \u00d0otrs\ufffdon \ufffdo~y\u20ac ~o}\ufffdt~on \ufffd{~okms 49& {q\ufffdso\ufffd{\ufffdkw \u00d0otrs\ufffd tzk\nm{yy\ufffdz t\ufffd\u00de1L{~\ufffdt\u20ac\ufffdkw mwk~t\ufffd\u00de. okms \u20ac\ufffdoyyon \ufffd{voz t\u20ac~o|~o\u20acoz\ufffdon l\u00de\ufffdsoy{\u20ac\ufffd m{yy{z \ufffd{voz \ufffdsk\ufffd yk|\u20ac \ufffd{t\ufffd*{~|kt~ {q\ufffd{voz\u20ac q{~ltr~ky\u20ac+1\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 13593:9:1r3 3:\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 49259\n~kytqtmk\ufffdt{z\u20ac1 \\so\u20aco qtzntzr\u20ac \u20ac\ufffdrro\u20ac\ufffd r~ok\ufffdo~ q{m\ufffd\u20ac kzn m{so~ozmo ky{zr\u20ac\ufffd \ufffdso~trs\ufffd/\u00d0tzr kzn\nmwtyk\ufffdo/\u20acmo|\ufffdtm q~kyo\u20ac kzn \u20ac\ufffd||{~\ufffd \ufffdsoqtzntzr\u20ac {qd6;f. \u00d0t\ufffds r~ok\ufffdo~ q~kryoz\ufffdk\ufffdt{z ky{zr\u20ac\ufffd\n\ufffdsowoq\ufffd/\u00d0tzr kzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd q~kyo\u20ac? \ufffdst\u20acyk\u00de |k~\ufffdw\u00de ~oqwom\ufffd \ufffdsowk~ro~ \u20act\u00feo{q\ufffdsowoq\ufffd/\n\u00d0tzr2oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd mw\ufffd\u20ac\ufffdo~ tz\ufffdsotzq{~yk\ufffdt{z/\u20acsk~tzr zo\ufffd\u00d0{~v. \u00d0stms |o~yt\ufffd\u20ac r~ok\ufffdo~\ntz\ufffdo~zkw ntqqo~oz\ufffdtk\ufffdt{z1\nI{z\u20act\u20ac\ufffdozm\u00de {qzo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {\ufffdo~ \ufffdtyo\n\\{\ufffdzno~\u20ac\ufffdkzn \ufffdsom{z\u20act\u20ac\ufffdozm\u00de {q\ufffdso|{wk~t\u20acon tzq{~yk\ufffdt{z/\u20acsk~tzr |~{mo\u20ac\u20ac {\ufffdo~ \ufffdtyo. \ufffdso\nzo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o \u00d0k\u20aco\u00f0kytzon kw{zr \u00d0t\ufffds \u20actytwk~t\ufffd\u00de2|o~\u20act\u20ac\ufffdozmo {q\ufffdso\u20aco\ufffd\u20ac{q\ufffd\u20aco~\u20ac. \u20ac{\ufffd~mo\nn{yktz\u20ac kzn \u20acsk~on ]ZS\u20ac *k~\ufffdtmwo\u20ac+ km~{\u20ac\u20ac kww\u00d0oov\u20ac tz\ufffdso\u20ac\ufffd\ufffdn\u00de |o~t{n1 [tytwk~t\ufffd\u00de \u20acm{~o\u20ac k~o\n~o|{~\ufffdon tz\\klwo 61Ltr;|~o\u20acoz\ufffd\u20ac \ufffdsozo\ufffd\u00d0{~v ntkr~ky\u20ac {q\ufffdso~oyktztzr \u20act\u00f0\u00d0oov\u20ac tz{\ufffd~\n\u20ac\ufffd\ufffdn\u00de |o~t{n *_oov\u20ac 4\u22126\u20199\u2212;+1\nOzokms \u00d0oov. k\u20actytwk~ nt\ufffdt\u20act{z tz\ufffd{ \ufffd\u00d0{mw\ufffd\u20ac\ufffdo~\u20ac t\u20ac{l\u20aco~\ufffdon tz\ufffdsotzq{~yk\ufffdt{z/\u20acsk~tzr\nzo\ufffd\u00d0{~v. kw\ufffds{\ufffdrs \ufffdso\u20ac|omtqtm m{y|{\u20act\ufffdt{z {q\ufffdso\ufffd\u20aco~\u20ac kzn \u20acsk~on k~\ufffdtmwo\u20ac \ufffdsk\ufffd q{~y \ufffdsozo\ufffd/\n\u00d0{~v mskzro\u20ac \u20ac\ufffdl\u20ac\ufffdkz\ufffdtkww\u00de {\ufffdo~ \ufffdtyo1 \\so z\ufffdylo~ {qm{yy\ufffdzt\ufffdto\u20ac tz\ufffdsowoq\ufffd/skzn kzn ~trs\ufffd/\nskzn mw\ufffd\u20ac\ufffdo~\u20ac \ufffdk~to\u20ac {\ufffdo~ \ufffdso\u00d0oov\u20ac kzn \ufffdso~owk\ufffdt\ufffdo \u20act\u00feo\u20ac {q\ufffdsontqqo~oz\ufffd m{yy\ufffdzt\ufffdto\u20ac kw\u20ac{\nmskzro1 N{\u00d0o\ufffdo~. okms \u00d0oov ~o\ufffdokw\u20ac \ufffdso\u20ackyo l~{kn |k\ufffd\ufffdo~z {qkwk~ro~ woq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz/\n\ufffdkwt\u20ac\ufffd mw\ufffd\u20ac\ufffdo~ \u20ac|wt\ufffd tz\ufffd{ \u20aco\ufffdo~kw \u20acykwwo~ \u20ac\ufffdl/m{yy\ufffdzt\ufffdto\u20ac. \u00d0t\ufffds k\u20acykwwo~ ~trs\ufffd/\u00d0tzr2\u20acmo|\ufffdtm mw\ufffd\u20ac/\n\ufffdo~.\u20acs{\u00d0tzr \ufffdsk\ufffd \ufffdst\u20ac|k\ufffd\ufffdo~z t\u20acz{\ufffdkzk~\ufffdoqkm\ufffd {q\ufffdsotzm~ok\u20acon km\ufffdt\ufffdt\ufffd\u00de n\ufffd~tzr _oov 71\\kvoz\n\ufffd{ro\ufffdso~ \u00d0t\ufffds Ltr6.\ufffdso\u20aco ~o\u20ac\ufffdw\ufffd\u20ac noy{z\u20ac\ufffd~k\ufffdo \ufffdsk\ufffd \ufffdso|k\ufffd\ufffdo~z {qzo\ufffd\u00d0{~v nt\ufffdt\u20act{z |o~\u20act\u20ac\ufffd\u20ac {\ufffdo~\n\ufffdtyo. \u20ac|kzztzr y\ufffdw\ufffdt|wo \u00d0oov\u20ac {qjz{~ykw) km\ufffdt\ufffdt\ufffd\u00de kzn {zoo\u00f0mo|\ufffdt{zkw \u00d0oov {qstrs yontk\nkm\ufffdt\ufffdt\ufffd\u00de1\nI{z\u20actno~tzr \ufffdsotz\ufffdo~/\u00d0oov \u20actytwk~t\ufffd\u00de lo\ufffd\u00d0ooz \ufffd\u20aco~ |{|\ufffdwk\ufffdt{z\u20ac kzn \ufffdso\u20ac{\ufffd~mo n{yktz\u20ac\nkzn ]ZS\u20ac \ufffdso\u00de \u20acsk~on. \\klwo 6\u20acs{\u00d0\u20ac \ufffdsotz\ufffdo~/\u00d0oov \u20actytwk~t\ufffd\u00de {q\ufffdzt}\ufffdo \ufffd\u20aco~\u20ac. ]ZS\u20ac kzn \u00d0ol/\n\u20act\ufffdon{yktz \u20acsk~o\u20ac. kw{zr \u00d0t\ufffds \ufffdsoytzty\ufffdy. yokz. yk\u00f0ty\ufffdy kzn \u20ac\ufffdkznk~n no\ufffdtk\ufffdt{z {q|kt~/\n\u00d0t\u20aco \u20actytwk~t\ufffd\u00de yok\u20ac\ufffd~o\u20ac1 \\so \u20acsk~on k~\ufffdtmwo\u20ac tz\\klwo 6l\u20acs{\u00d0 \ufffdsow{\u00d0o\u20ac\ufffd \u20actytwk~t\ufffd\u00de lo\ufffd\u00d0ooz\n\u00d0oov\u20ac. \u00d0t\ufffds k\u20acwtrs\ufffdw\u00de strso~ \u20actytwk~t\ufffd\u00de lo\ufffd\u00d0ooz knukmoz\ufffd \u00d0oov\u20ac1 Oz\ufffd\ufffdt\ufffdt\ufffdow\u00de. \ufffdso\u20ac{\ufffd~mo n{yktz\u20ac\\klwo 51Isk~km\ufffdo~t \u20ack\ufffdt{z {q\ufffdsoqt\ufffdo wk~ro\u20ac\ufffd m{yy\ufffdzt\ufffdto\u20ac tz_oov 71\nI{yy\ufffdz t\ufffd\u00de4\\st\u20ac t\u20ac\ufffdsowk~ro\u20ac\ufffd m{yy\ufffdzt\ufffd \u00dekzn t\u20acn{ytzk\ufffdon l\u00deyktz\u20ac\ufffd~o kyyontk {\ufffd\ufffdwo\ufffd\u20ac. \u20ac\ufffdms k\u20acTheGuardian\nkznTheIndependent. y{\u20ac\ufffdw\u00de q~{y \ufffdso]R1 \\st\u20ac m{yy\ufffdzt\ufffd \u00detzmw\ufffdno\u20ac yktz\u20ac\ufffd ~oky zo\u00d0\u20ac ~o|{~\ufffdtzr\nkzn nt\u20acm\ufffd\u20ac\u20aco\u20ac \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd {zmwtyk\ufffdo mskzro kwy{\u20ac\ufffd o\u00f0mw\ufffd\u20act\ufffdow\u00de. q{m\ufffd\u20actzr {z\ufffdso\nm{z\u20aco}\ufffdo zmo\u20ac {qW~o\u20actnoz\ufffd \\~\ufffdy|)\u20ac nomt\u20act{z kzn kz\u00detz\ufffdo~zk\ufffdt{z kw~o\u20ac|{z \u20aco\u20ac1\nI{yy\ufffdz t\ufffd\u00de5\\st\u20ac m{yy\ufffdzt\ufffd \u00detzmw\ufffdno\u20ac ykz\u00de ~trs\ufffd/\u00d0tzr \u20ac{\ufffd~mo\u20ac. tzmw\ufffdntzr kw\ufffdo~zk\ufffdt\ufffdo zo\u00d0\u20ac \u20act\ufffdo\u20ac \u20ac\ufffdms k\u20ac\nBreitbart kznTheDailyCaller1 [{mtkw yontk \u20act\ufffdo\u20ac k~okw\u20ac{ |~{ytzoz\ufffd tz\ufffdst\u20acm{yy\ufffdz t\ufffd\u00dek\u20ac\nFacebook. Twitter. kznGab kwwk||ok~. \u20ac\ufffdrro\u20ac\ufffd tzr\ufffdsk\ufffd \ufffdst\u20acr~{\ufffd| mk|\ufffd\ufffd~o\u20ac k\ufffd\ufffdoy|\ufffd\u20ac \ufffd{\ufffd\u20aco\\\u00d0t\ufffd\ufffdo~ \ufffd{\n~o/\u20acsk~o m{z\ufffdoz\ufffd q~{y {\ufffdso~ \u20ac{mtkw |wk\ufffdq{~y \u20ac1[{yo o\u20ac\ufffdklwt\u20acs onyontk {\ufffd\ufffdwo\ufffd\u20ac \u20ac\ufffdms k\u20acTheDailyMail\nkznFoxNews k~o|~o\u20acoz\ufffd. l\ufffd\ufffdk~owo\u20ac\u20acq{m\ufffd\u20acon tz\ufffdst\u20acm{yy\ufffdz t\ufffd\u00de\ufffdskz kw\ufffdo~zk\ufffdt\ufffdo zo\u00d0\u20ac \u20act\ufffdo\u20ac1 \\st\u20ac\nm{yy\ufffdzt\ufffd \u00dekw\u20ac{ nt\u20acm\ufffd\u20ac\u20aco\u20ac \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd nomt\u20act{z ykno l\u00deW~o\u20actnoz\ufffd \\~\ufffdy|. k\u20ac\u00d0oww k\u20ac\nmo~\ufffdktz k\u20ac|om\ufffd\u20ac {qmwtyk\ufffdo \u20acmtozmo1 \\st\u20ac t\u20ac\ufffdso{zw\u00de m{yy\ufffdz t\ufffd\u00de\ufffd{q{m\ufffd\u20ac {zq{~yo~ ][|{wt\ufffdtmtkz\u20ac\nObama kznGore kzn \ufffdso|s~k\u20acoglobalwarming n{ytzk\ufffdo\u20ac \ufffdsoltr~ky mw{\ufffdn *Ltr :m+1\nI{yy\ufffdz t\ufffd\u00de6\\st\u20ac m{yy\ufffdzt\ufffd \u00dem{z\u20act\u20ac\ufffd\u20ac {qykz\u00de yktz\u20ac\ufffd~o kyn{yktz\u20ac ~o\ufffdokwtzr k][q{m\ufffd\u20ac1 \\so y{\u20ac\ufffd |~{ytzoz\ufffd\nn{yktz\u20ac so~o k~oo\u20ac\ufffdklwt\u20acson yktz\u20ac\ufffd~o kyyontk \u20ac{\ufffd~mo\u20ac \u20ac\ufffdms k\u20ac\ufffdsoWashington Post kznNewYork\nTimes1 F\u20ac\u00d0t\ufffds I{yy\ufffdzt\ufffd \u00de4.\ufffdsoWk~t\u20ac Fr~ooyoz\ufffd {zmwtyk\ufffdo mskzro t\u20ackvo\u00de\ufffd{|tm {qtz\ufffdo~o\u20ac\ufffd1\nI{yy\ufffdz t\ufffd\u00de7\\st\u20ac m{yy\ufffdzt\ufffd \u00detzmw\ufffdno\u20ac kz\ufffdylo~ {qkw\ufffdo~zk\ufffdt\ufffdo kzn \u20acykwwo~ zo\u00d0\u20ac yontk n{yktz\u20ac \u00d0t\ufffds ky{\u20ac\ufffdw\u00de\nwoq\ufffd/\u00d0tzr ltk\u20ac. \u20ac\ufffdms k\u20acDailyKoskznMotherJones. ky{zr\u20ac\ufffd o\u20ac\ufffdklwt\u20acs onyktz\u20ac\ufffd ~oky zo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac1\n\\so m{z\ufffdoz\ufffd so~o t\u20ac\u20actytwk~ \ufffd{\ufffdsk\ufffd {qI{yy\ufffdzt\ufffd \u00de4kzn I{yy\ufffdzt\ufffd \u00de6.l\ufffd\ufffdkw\u20ac{ ~oqo~ozmo\u20ac \ufffdsoz ][\nKz\ufffdt~{zyoz \ufffdkwW~{\ufffdom\ufffdt{z Frozm\u00de Fnytzt\u20ac\ufffd~k \ufffd{~[m{\ufffd\ufffd W~\ufffdt\ufffd\ufffd kzn Ttmstrkz m{zr~o\u20ac\u20acy kz\\ty\n_kwlo~r q{~\ufffdsot~ m{yyoz\ufffd\u20ac k~{\ufffdzn mwtyk\ufffdo mskzro1\nI{yy\ufffdz t\ufffd\u00de9\\st\u20ac m{yy\ufffdzt\ufffd \u00det\u20acm{y|~t\u20acon {qkyt\u00f0 {q\u20ac{mtkw yontk. zo\u00d0\u20ac kzn m{yyoz\ufffdk ~\u00de\u20act\ufffdo\u20ac1 Frktz. \ufffdsoWk~t\u20ac\nFr~ooyoz\ufffd nomt\u20act{z t\u20ackq{m\ufffd\u20ac. \u00d0t\ufffds knnt\ufffdt{zkw q~kytzr k~{\ufffdzn rw{lkw m{z\u20aco}\ufffdoz mo\u20ackzn {|tzt{z/\n|tomo\u20ac {z\ufffdsonomt\u20act{z1\ns\ufffd\ufffd|\ufffd>22n {t1{~r243146;42u {\ufffd~zkw1|{z o13593:9:1\ufffd33 5\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 4:259\nq~{y \u00d0stms m{z\ufffdoz\ufffd \u00d0k\u20ac\u20acsk~on \u20acs{\u00d0 strso~ \u20actytwk~t\ufffd\u00de lo\ufffd\u00d0ooz \u00d0oov\u20ac tz\\klwo 6m1]\u20aco~ |{|\ufffd/\nwk\ufffdt{z\u20ac \u20acs{\u00d0 wtyt\ufffdon |o~\u20act\u20ac\ufffdozmo lo\ufffd\u00d0ooz \u00d0oov\u20ac. \u20ac\ufffdyyk~t\u20acon l\u00de\\klwo 6k1\\so {\ufffdo~kww |k\ufffd\ufffdo~z\nt\u20ac\ufffdsk\ufffd. q~{y \u00d0oov \ufffd{\u00d0oov. kwtyt\ufffdon |~{|{~\ufffdt{z {q\ufffdso\ufffd\u20aco~ |{|\ufffdwk\ufffdt{z kzn \u20aco\ufffd{q\u20ac{\ufffd~mo\nn{yktz\u20ac |o~\u20act\u20ac\ufffd. \u00d0t\ufffds y\ufffdms w{\u00d0o~ |o~\u20act\u20ac\ufffdozmo tz\ufffdso\u20aco\ufffd\u20ac{qk~\ufffdtmwo\u20ac \ufffdsk\ufffd k~o\u20acsk~on1 \\st\u20ac t\u20ackz\ntz\ufffdo~o\u20ac\ufffdtzr qtzntzr \u00d0t\ufffds ~o\u20ac|om\ufffd \ufffd{\ufffdsostrs m{z\u20act\u20ac\ufffdozm\u00de tz\ufffdso\ufffd\u00d0{/mw\ufffd\u20ac\ufffdo~ zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\n\ufffdsk\ufffd t\u20ac~owtklw\u00de {l\u20aco~\ufffdon o\ufffdo~\u00de \u00d0oov1 \\so wkmv {q|o~\u20act\u20ac\ufffdozmo tz\u20acsk~on ]ZS\u20ac yk\u00de loo\u00f0|wktzon\nl\u00de\ufffdsorozo~kw \ufffd{wk\ufffdtwt\ufffd\u00de {qzo\u00d0\u20ac yontk. \u00d0so~o k~\ufffdtmwo\u20ac \ufffd\u00de|tmkww\u00de sk\ufffdo k\u20acs{~\ufffd wtqo\ufffdtyo *o1r1 5/6\nnk\u00de\u20ac \ufffdt\u20actltwt\ufffd\u00de tz{zwtzo \u20acsk~tzr d46f+1 T{no~k\ufffdo |o~\u20act\u20ac\ufffdozmo {q\ufffd\u20aco~\u20ac kzn \u20ac{\ufffd~mo\u20ac lo\ufffd\u00d0ooz\n\u00d0oov\u20ac |o~sk|\u20ac \u20ac\ufffdrro\u20ac\ufffd\u20ac kzkm\ufffdt\ufffdo m{~o r~{\ufffd| \u00d0s{ k~o|~o\u20acoz\ufffd okms \u00d0oov. \u00d0t\ufffds k\u00d0tno~ r~{\ufffd|\n\u00d0s{ k||ok~ wo\u20ac\u20acq~o}\ufffdoz\ufffdw\u00de1\nFyk~von ntqqo~ozmo mkzlo{l\u20aco~\ufffdon tz\ufffdso\ufffd\u00de|tmkw \u20actytwk~t\ufffd\u00de \u20acm{~o\u20ac q{~_oov 7kzn q{~\n{\ufffdso~ \u00d0oov\u20ac1 S{\u00d0o~ \u20actytwk~t\ufffd\u00de \u20acm{~o\u20ac \u00d0o~o {l\u20aco~\ufffdon q{~\ufffd\u20aco~\u20ac. ]ZS\u20ac kzn n{yktz\u20ac q~{y _oov 7\nk||ok~tzr tz{\ufffdso~ \u00d0oov\u20ac. \u00d0stwo m{z\ufffdo~\u20acow\u00de. strso~ \u20actytwk~t\ufffd\u00de \u00d0k\u20ac{l\u20aco~\ufffdon q{~\ufffd\u20aco~\u20ac. ]ZS\u20ac\nkzn n{yktz\u20ac q~{y \ufffdso{\ufffdso~ \u20act\u00f0\u00d0oov\u20ac k||ok~tzr tz_oov 71\\so z\ufffdylo~ {qzo\u00d0 \ufffd\u20aco~\u20ac. ]ZS\u20ac\nkzn n{yktz\u20ac tz_oov 7kw\u20ac{ \u20acs{\u00d0\u20ac k\u20ac\ufffdk~v m{z\ufffd~k\u20ac\ufffd \u00d0t\ufffds {\ufffdso~ \u00d0oov\u20ac> ;314& {q\ufffd\u20aco~\u20ac. <513& {q\n]ZS\u20ac kzn 7;1=& {qn{yktz\u20ac k~o\ufffdzt}\ufffdo \ufffd{_oov 7kzn z{\ufffd|~o\u20acoz\ufffd tzkz\u00de{\ufffdso~ \u00d0oov1 \\st\u20ac t\u20ac\n\u20ac\ufffd~{zr o\ufffdtnozmo \ufffdsk\ufffd \ufffdsoo\ufffdoz\ufffd\u20ac {q_oov 7k||ok~ \ufffd{sk\ufffdo \u20ac|\ufffd~~on kztzqw\ufffd\u00f0 {ql{\ufffds \u20ac{mtkw\nyontk |k~\ufffdtmt|kz\ufffd\u20ac kzn ntrt\ufffdkw yontk \u20ac{\ufffd~mo\u20ac *\ufffd\u20aco~\u20ac> yokz 7=16&. ytz1 791:&. yk\u00f01 9415&.\\klwo 61[tytwk~t\ufffd\u00de \u20acm{~o\u20ac q{~\ufffd\u20aco~\u20ac. ]ZS\u20ac kzn n{yktz\u20ac lo\ufffd\u00d0ooz okms {q\ufffdso\u20aco\ufffdoz \u00d0oov\u20ac mkwm\ufffdwk\ufffdon \ufffd\u20actzr K}*6+1[tytwk~t\ufffd\u00de t\u20acnt~om\ufffdt{z kw1\\so \u20actytwk~t\ufffd \u00dert\ufffdoz tzmoww*7.\n4+t\u20ac\ufffdso|~{|{~\ufffdt {z{q\ufffdso\ufffd\u20aco~\u20ac2]ZS\u20ac 2n{yktz\u20ac tz_oov 7kw\u20ac{ tz\u20acooz _oov 41I{{w \u20acskno\u20ac tzntmk\ufffdo \ufffdkw\ufffdo\u20ac \u20acykwwo~ \ufffdskz \ufffdsoyokz \u00d0stwo \u00d0k~y \u20acskno\u20ac tzntmk\ufffdo \ufffdkw\ufffdo\u20ac\nr~ok\ufffdo~ \ufffdskz \ufffdsoyokz1\n_oov 4 5 6 7 9 : ;\n4 315= 3166 316= 3159 3159 3155\n5 3157 3163 3169 3155 3157 3154 ytz1*S+ B313<7\n6 314= 3154 316< 3153 314= 314< yokz1*S+ B3156:\n7 313< 313= 3149 3144 3143 313= yk\u00f01*S+ B316<=\n9 314< 3153 3159 316: 3157 3154 \u20ac\ufffdno\ufffd1*S+ B313;<\n: 314= 3155 315: 3169 315: 3159\n; 3153 3156 315< 316: 315; 3163\n*k+F\u20ac\u00deyyo\ufffd~ tm{\ufffdo~wk| {q\ufffd\u20aco~\u20ac1\n_oov 4 5 6 7 9 : ;\n4 3146 313< 3144 313: 3139 3137\n5 3143 3147 3143 3139 3139 3137 ytz1*S+ B31355\n6 3139 3143 314: 3139 3137 3136 yokz1*S+ B313;<\n7 3135 3136 313: 313: 3136 3135 yk\u00f01*S+ B314=6\n9 3137 3139 313: 314= 314: 313; \u20ac\ufffdno\ufffd1*S+ B3137;\n: 3137 3139 313: 3143 314; 314:\n; 3137 3137 3139 313= 313= 314=\n*l+F\u20ac\u00deyyo\ufffd ~tm{\ufffdo~wk| {q]ZS\u20ac1\n_oov 4 5 6 7 9 : ;\n4 3199 319= 31;5 319< 3197 3194\n5 3177 319< 31;9 317< 3199 317< ytz1*S+ B31499\n6 3167 3174 31;: 3175 3175 316= yokz1*S+ B317=:\n7 3149 3153 315= 3156 3155 314< yk\u00f01*S+ B31;:;\n9 3174 3176 3196 31;: 3195 317: \u20ac\ufffdno\ufffd1*S+ B3149<\n: 3174 3195 319: 31;: 319: 3196\n; 317: 3197 31:5 31;; 319= 31:6\n*m+F\u20ac\u00deyyo\ufffd~ tm{\ufffdo~wk| {qn{yktz\u20ac1\ns\ufffd\ufffd|\ufffd>22n{ t1{~r243146;42u {\ufffd~zkw1|{zo 13593:9:1\ufffd336\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 4;259\nLtr;1I{z\u20act\u20ac\ufffdoz\ufffd zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {\ufffdo~ \ufffdtyo1 Uo\ufffd\u00d0{~v ntkr~ky\u20ac {q\ufffdso\ufffd{|qt\ufffdom{yy\ufffdzt\ufffdt o\u20ackm~{\u20ac\u20ac \ufffdso\u20act\u00f0~oyktztzr \u00d0oov\u20ac1 Kkms qtr\ufffd~o\nt\u20ac{~toz\ufffdon \u20ac\ufffdms \ufffdsk\ufffd \ufffdsowoq\ufffd/\u00d0tzr mw\ufffd\u20ac\ufffdo~ t\u20ac{z\ufffdsowoq\ufffdkzn \ufffdso~trs\ufffd/\u00d0tzr mw\ufffd\u20ac\ufffdo~ t\u20ac{z\ufffdso~trs\ufffd1 Ozokms mk\u20aco z{no m{w{\ufffd~ \u20actrztqto\u20ac m{yy\ufffdz t\ufffd\u00de\nyoylo ~\u20acst| kzn \u20act\u00feot\u20ac|~{|{~\ufffdt{zkw \ufffd{\ufffdso\u20ac}\ufffdk~o ~{{\ufffd {q\ufffd{\ufffdkw \u20acsk~o m{\ufffdz\ufffd1 I{yy\ufffdzt \ufffdto\u20ack~owklowwon 4\u22129tznom~ok\u20actzr {~no~ {q\u20act\u00feo. kzn\nm{w{~on lw\ufffdo. \u00deoww{\u00d0. r~ooz. ~onkzn |\ufffd~|wo ~o\u20ac|om\ufffdt\ufffdow\u00de1 U{no |wkmoyoz\ufffd t\u20acno\ufffdo~ytzon l\u00de\ufffdsoW\u00de\ufffds{z ty|woyoz \ufffdk\ufffdt{z {q\ufffdsoL{~moF\ufffd wk\u20ac5\nkwr{~t\ufffd syd93f1\ns\ufffd\ufffd|\ufffd>22 n{t1{~r243146;4 2u{\ufffd~zkw1|{zo1 3593:9:1r33;\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 4<259\n\u03c3B5143&? ]ZS\u20ac> yokz ;316&. ytz1 ::1:&. yk\u00f01 ;615&.\u03c3B:197&? n{yktz\u20ac> yokz 5=1<&.\nytz1 5;16&. yk\u00f01 6419&.\u03c3B7154&+1 _stwo \u00d0ol n{yktz\u20ac o\u00f0stlt\ufffd \ufffdsoy{\u20ac\ufffd \u20ac\ufffdkltwt\ufffd\u00de lo\ufffd\u00d0ooz\n\u00d0oov\u20ac. ]ZS\u20ac o\u00f0stlt\ufffd \ufffdsowok\u20ac\ufffd \u20ac\ufffdkltwt\ufffd\u00de kzn \ufffd\u20aco~\u20ac qkwwlo\ufffd\u00d0ooz \ufffdso\u20aco \ufffd\u00d0{o\u00f0\ufffd~oyo\u20ac1\n\\{m{zqt~y \ufffdsk\ufffd \ufffdso|o~\u20act\u20ac\ufffdoz\ufffd \ufffd\u00d0{/mw\ufffd\u20ac\ufffdo~ zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac \u20acooz tzLtr;k~o|{wk~t\u20acon\nkw{zr \ufffdso\u20ackyo woq\ufffd/~trs\ufffd |{wt\ufffdtmkw kzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd/\u20acmo|\ufffdtm tno{w{rtmkw k\u00f0o\u20ac k\u20ac\ufffdsk\ufffd \u20acooz q{~\n_oov 7*\u20acoo Ltr9+.\ufffdson{yktz ltk\u20ac m{ntzr\u20ac \u00d0o~o k||wton \ufffd{\ufffdsozo\ufffd\u00d0{~v\u20ac m~ok\ufffdon q{~_oov\u20ac 4/\n6kzn 9/;*[:kzn [;Ltr\u20ac tz[4Ltwo+1 L\ufffd~\ufffdso~y{~o. k\ufffdo~kro ltk\u20aco\u20ac \u00d0o~o mkwm\ufffdwk\ufffdon q{~kwwm{y/\ny\ufffdzt\ufffdto\u20ac tzokms \u00d0oov tzLtr<1\\~ozn\u20ac tz|{wk~t\u20ack\ufffdt{z {\ufffdo~ \ufffdtyo k~o\u20acs{\u00d0z k\u20aczo\ufffd\u00d0{~v k\ufffdo~/\nkro\u20ac q{~|{wt\ufffdtmkw kzn mwtyk\ufffdo mskzro ltk\u20aco\u20ac. kw{zr\u20actno \ufffdsom{yy\ufffdzt\ufffd\u00de k\ufffdo~kro\u20ac. tzLtr<1Oz\ny{\u20ac\ufffd \u00d0oov\u20ac. \ufffdso\u00d0s{wo/zo\ufffd\u00d0{~v k\ufffdo~kro \u20acs{\u00d0\u20ac ytwn woq\ufffd/\u00d0tzr kzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd ltk\u20ac1\n_oov 9\u20acs{\u00d0\u20ac *q{~ \ufffdso{zw\u00de \ufffdtyo km~{\u20ac\u20ac \ufffdso\u20aco\ufffdoz/\u00d0oov |o~t{n+ kwk~ro zo\ufffd\ufffd~kw m{yy\ufffdzt\ufffd\u00de1\n[\ufffd||{~\ufffdtzr \ufffdso\ufffdt\u20ac\ufffdkw o\ufffdtnozmo \u20acooz tz[:kzn [;Ltr\u20ac tz[4Ltwo. kzn \ufffdsom{yy\ufffdzt\ufffd\u00de/wo\ufffdow ltk\u20ac\n\u20acm{~o\u20ac tzLtr<.\ufffdso\u20aco qtzntzr\u20ac \u20acs{\u00d0 \ufffdsk\ufffd \ufffdso|{wk~t\u20acon zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o {l\u20aco~\ufffdon tz_oov 7t\u20ac\n|o~\u20act\u20ac\ufffdoz\ufffd kzn t\u20acz{\ufffdkzk~\ufffdoqkm\ufffd {q\ufffdsotzm~ok\u20aco tzkm\ufffdt\ufffdt\ufffd\u00de tz\ufffdsomwtyk\ufffdo mskzro m{z\ufffdo~\u20ack\ufffdt{z\nno\u20ac|t\ufffdo \ufffdso\ufffd\ufffd~z{\ufffdo~ tz\ufffd\u20aco~\u20ac. \u20ac{\ufffd~mo n{yktz\u20ac kzn \u20acsk~on k~\ufffdtmwo\u20ac1\nJt\ufffdm\ufffd\ufffd\ufffdt{z\n\\st\u20ac |k|o~ |~o\u20acoz\ufffd\u20ac kzkzkw\u00de\u20act\u20ac {qntrt\ufffdkw yontk \u20acsk~tzr losk\ufffdt{\ufffd~ k~{\ufffdzn \ufffdsom{z\ufffdo\u20ac\ufffdon t\u20ac\u20ac\ufffdo\n{qmwtyk\ufffdo mskzro1 V\ufffd~ kzkw\u00de\u20act\u20ac w{{v\u20ac k\ufffd\ufffdsozo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o q{~yon l\u00de\ufffd\u20aco~\u20ac \u20acsk~tzr \u00d0ol\nk~\ufffdtmwo\u20ac ~owk\ufffdon \ufffd{mwtyk\ufffdo mskzro. m{yltztzr zo\ufffd\u00d0{~v kzkw\u00de\u20act\u20ac \u00d0t\ufffds m{y|\ufffd\ufffdk\ufffdt{zkw kzn s\ufffdykz\n\ufffdo\u00f0\ufffdkzkw\u00de\u20aco\u20ac \ufffd{tnoz\ufffdtq\u00de kzn msk~km\ufffdo~t\u20aco m{yy\ufffdzt\ufffdto\u20ac {q\ufffd\u20aco~\u20ac kzn \ufffdsok~\ufffdtmwo\u20ac2\u20ac{\ufffd~mo\u20ac \ufffdso\u00de\nLtr<1So\ufffdow\u20ac {q|{wt\ufffdtmkw kzn mwtyk\ufffdo mskzro ltk\u20ac {\ufffdo~ \ufffdsom{\ufffd~\u20aco {q\ufffdso\u20aco\ufffdoz \u00d0oov \u20ac\ufffd\ufffdn\u00de |o~t{n1 \\so\u20aco k~oyok\u20ac\ufffd~on k\u20ac\ufffdso\nyokz m{non ltk\u20ac {qn{yktz\u20ac \u00d0otrs\ufffdon l\u00de\ufffd{\ufffdkw \u20acsk~o\u20ac *\u20acoo Ono{w{rtm kwm{ntzr {q\u20ac{\ufffd~mo n{yktz\u20ac+ 1Gtk\u20ac tzokms {q\ufffdsoqt\ufffdowk~ro\u20ac\ufffd\nm{yy\ufffdz t\ufffdto\u20ac k~o~o|~o\u20acoz\ufffdo nl\u00de\ufffdso\u20acmk\ufffd\ufffdo~ |{tz\ufffd\u20ac tzokms \u00d0oov. kzn \ufffdsoltk\u20ac km~{\u20ac\u20ac \ufffdso\u00d0s{wo zo\ufffd\u00d0{~v t\u20acrt\ufffdoz l\u00de\ufffdsowtzo\u20ac1 \\so\nm{w{\ufffd~ {q\ufffdsom{yy\ufffdzt\ufffd\u00de |{tz\ufffd\u20ac t\u20acm{z\u20act\u20ac\ufffdoz\ufffd \u00d0t\ufffds {\ufffdso~ qtr\ufffd~o\u20ac1 Ozy{\u20ac\ufffd \u00d0oov\u20ac. \ufffdsok\ufffdo~kro zo\ufffd\u00d0{~v ltk\u20ac t\u20acwoq\ufffd{qmoz\ufffd~o kzn\ny{~o oz\ufffdt~{zyoz \ufffdkwt\u20ac\ufffd \ufffdskz \u20acmo|\ufffdtm1 \\st\u20ac \ufffd~ozn m{z\ufffdtz\ufffdo\u20ac \ufffd{\ufffdsotznt\ufffdtn\ufffdkw m{yy\ufffdz t\ufffdto\u20ac. \u00d0t\ufffds \ufffdsoyku{~t\ufffd\u00de lotzr woq\ufffd/\u00d0tzr kzn\noz\ufffdt~{zy oz\ufffdkwt\u20ac\ufffd1\ns\ufffd\ufffd|\ufffd>22 n{t1{~r243146;4 2u{\ufffd~zkw1|{zo1 3593:9:1r33<\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 4=259\n\u20acsk~o1 \\so kty t\u20ac\ufffd{\ufffdzno~\u20ac\ufffdkzn s{\u00d0 |o{|wo ozrkro \u00d0t\ufffds. kzn \u20acsk~o {zwtzo yontk m{z\ufffdoz\ufffd\nkl{\ufffd\ufffd mwtyk\ufffdo mskzro {z\u20ac{mtkw yontk *\u20ac|omtqtmkww\u00de \\\u00d0t\ufffd\ufffdo~+1\n_osk\ufffdo q{\ufffdzn \ufffdsk\ufffd ky{zr\u20ac\ufffd \ufffdsom{yy\ufffdzt\ufffdto\u20ac {q\u20acsk~on ]ZS\u20ac. ~trs\ufffd/\u00d0tzr kzn mwtyk\ufffdo\n\u20acmo|\ufffdtm \ufffdto\u00d0\u20ac k~o\u20ac\ufffd~{zrw\u00de m{~~owk\ufffdon. k\u20ack~owoq\ufffd/\u00d0tzr kzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd \ufffdto\u00d0\u20ac1 \\st\u20ac m{~~owk/\n\ufffdt{z sk\u20aclooz {l\u20aco~\ufffdon tztznt\ufffdtn\ufffdkw\u20ac loq{~o \ufffd\u20actzr \u20ac\ufffd~\ufffdo\u00de/lk\u20acon yo\ufffds{n\u20ac *o1r1 d6.94.95f+1 V\ufffd~\n\u20ac\ufffd\ufffdn\u00de \u20acs{\u00d0\u20ac \ufffdsk\ufffd \ufffdsok\u20ac\u20ac{mtk\ufffdt{z o\u00f0\ufffdozn\u20ac \ufffd{yontk {\ufffd\ufffdwo\ufffd\u20ac. \u20ac|omtqtmkww\u00de \ufffd{\ufffdsom{z\ufffdoz\ufffd |~{n\ufffdmon\nl\u00dekwk~ro \u20aco\ufffd{q{zwtzo zo\u00d0\u20ac |~{\ufffdtno~\u20ac *Ltr 7+.kzn t\u20ackyku{~ qok\ufffd\ufffd~o {qs{\u00d0 {zwtzo m{z\ufffdoz\ufffd t\u20ac\n\u20acsk~on1 Zomoz\ufffd \u00d0{~v l\u00deN{~z\u20aco\u00de o\ufffdkw1d95f \u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd \ufffdso\u20acmo|\ufffdtmt\u20acy/m{z\u20aco~\ufffdk\ufffdt\u20acy wtzv yk\u00de\nlo\u20ac\ufffd~{zro\u20ac\ufffd tz\ufffdso][1\\st\u20ac qtzntzr t\u20ac\u20ac\ufffd||{~\ufffdon so~o. \u00d0so~o \u00d0o{l\u20aco~\ufffdo \ufffd\u00d0{wk~ro m{yy\ufffdzt/\n\ufffdto\u20aclk\u20acon yktzw\u00de {z][\u20ac{\ufffd~mo\u20ac? {zoy{~o woq\ufffd/\u00d0tzr kzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd. \ufffdso{\ufffdso~ y{~o\n~trs\ufffd/\u00d0tzr kzn \u20acmo|\ufffdtm1 Fw\ufffds{\ufffdrs \u00d0ontnz{\ufffdo\u00f0kytzo \u00d0so~o \ufffdso\ufffd\u20aco~\u20ac tz{\ufffd~nk\ufffdk\u20aco\ufffd \u00d0o~o\nw{mk\ufffdon ro{r~k|stmkww\u00de. \ufffdson{ytzkzmo {q][\u20ac{\ufffd~mo\u20ac tz\ufffd\u00d0{{q\ufffdsom{yy\ufffdzt\ufffdto\u20ac. kzn {q]R\n\u20ac{\ufffd~mo\u20ac tz{zo{q\ufffdsom{yy\ufffdzt\ufffdto\u20ac. \u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsk\ufffd \ufffdso\u20aco m{yy\ufffdzt\ufffdto\u20ac k~owk~row\u00de q{~yon k~{\ufffdzn\n\ufffd\u20aco~\u20ac q~{y \ufffds{\u20aco m{\ufffdz\ufffd~to\u20ac1 V\ufffd~ {\ufffdo~kww q{m\ufffd\u20ac {zKzrwt\u20acs/wkzr\ufffdkro \ufffd\u00d0oo\ufffd\u20ac kzn yontk m{z\ufffdoz\ufffd.\n|w\ufffd\u20ac wk~ro z\ufffdylo~\u20ac {q\\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\u20ac tz\ufffdso\u20aco m{\ufffdz\ufffd~to\u20ac *zok~w\u00de 49& {q{zwtzo ][kn\ufffdw\ufffd\u20ac \ufffd\u20acon\n\\\u00d0t\ufffd\ufffdo~ tz534; d45f+. k~om{z\u20act\u20ac\ufffdoz\ufffd \u00d0t\ufffds \ufffdst\u20acm{zuom\ufffd\ufffd~o1\nOz\ufffdst\u20ac\u20ac\ufffd\ufffdn\u00de \u00d0oqtzn \ufffd\u00d0{wo\ufffdow\u20ac {qm{yy\ufffdzt\ufffd\u00de \u20ac\ufffd~\ufffdm\ufffd\ufffd~o1 F\ufffd\ufffdsostrso\u20ac\ufffd wo\ufffdow. \ufffdso~o t\u20ac|{wk~t/\n\u20ack\ufffdt{z kzn \u20acor~ork\ufffdt{z \u00d0t\ufffds kwk~ro woq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd r~{\ufffd|tzr kzn k\u20acykwwo~ ~trs\ufffd/\n\u00d0tzr2\u20acmo|\ufffdtm r~{\ufffd|tzr mwok~w\u00de \ufffdt\u20actlwo tz\ufffdso\u20acsk~tzr zo\ufffd\u00d0{~v kq\ufffdo~ \ufffdsok||wtmk\ufffdt{z {q\ufffdsoq{~mo/\nnt~om\ufffdon wk\u00de{\ufffd\ufffd kwr{~t\ufffdsy1 _t\ufffdstz \ufffdsowoq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffd kwt\u20ac\ufffd r~{\ufffd|. kwr{~t\ufffdsytm m{yy\ufffd/\nzt\ufffd\u00de no\ufffdom\ufffdt{z qtzn\u20ac *\ufffd\u00de|tmkww\u00de+ q{\ufffd~ \u20acykwwo~ r~{\ufffd|tzr\u20ac. msk~km\ufffdo~t\u20acon l\u00deq\ufffd~\ufffdso~ kzkw\u00de\u20act\u20ac k\u20ac\nkl{\ufffdo1 O\ufffdt\u20actz\ufffdo~o\u20ac\ufffdtzr \ufffd{z{\ufffdo \ufffdsk\ufffd \ufffdso~trs\ufffd/\u00d0tzr2mwtyk\ufffdo \u20acmo|\ufffdtm r~{\ufffd| t\u20acy{~o noz\u20acow\u00de m{z/\nzom\ufffdon tz\ufffdo~zkww\u00de \ufffdskz \ufffdsowoq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd r~{\ufffd| *[\ufffd\ufffdnoz\ufffd)\u20ac t/\ufffdo\u20ac\ufffd k||wton \ufffd{k\ufffdo~kro\nmw\ufffd\u20ac\ufffdo~tzr m{oqqtmtoz\ufffd\u20ac {qkwwwoq\ufffd/\u00d0tzr kzn ~trs\ufffd/\u00d0tzr m{yy\ufffdzt\ufffdto\u20ac tzLtr\u20ac 6kzn ;.\u00d0t\ufffds mw\ufffd\u20ac/\n\ufffdo~tzr m{oqqtmtoz\ufffd\u20ac mkwm\ufffdwk\ufffdon tzMo|st \ufffd\u20actzr Sk\ufffdk|\u00de)\u20ac kwr{~t\ufffdsy d96f.pB3134=+1 \\st\u20ac qtzntzr\noms{o\u20ac \ufffdso{l\u20aco~\ufffdk\ufffdt{z l\u00deI{wwo{zt o\ufffdkw1d97f \ufffdsk\ufffd tz\ufffdso][.km\ufffdt\ufffdo Zo|\ufffdlwtmkz\u20ac o\u00f0stlt\ufffd r~ok\ufffdo~\nwo\ufffdow\u20ac {qs{y{|stw\u00de \ufffdskz Joy{m~k\ufffd\u20ac tz\ufffdsot~ |k\ufffd\ufffdo~z\u20ac {qtz\ufffdo~km\ufffdt{z {z\\\u00d0t\ufffd\ufffdo~1\n\\so \ufffdoy|{~kw kzkw\u00de\u20act\u20ac |~o\u20acoz\ufffdon kl{\ufffdo rt\ufffdo\u20ac m{zqtnozmo \ufffdsk\ufffd \ufffdso|{wk~t\u20acon zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm/\n\ufffd\ufffd~o t\u20ac~{l\ufffd\u20ac\ufffd {\ufffdo~ \ufffdtyo. no\u20ac|t\ufffdo \ufffd\ufffd~z{\ufffdo~ tz\ufffdso\ufffd\u20aco~ |{|\ufffdwk\ufffdt{z\u20ac. \u20aco\ufffd\u20ac{q\u20acsk~on k~\ufffdtmwo\u20ac kzn\nzo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac1 _o\u20ac\ufffd\ufffdnton \u20actytwk~t\ufffd\u00de lo\ufffd\u00d0ooz \ufffdso\u20aco\ufffd\u20ac{q\ufffd\u20aco~\u20ac. ]ZS\u20ac kzn n{yktz\u20ac km~{\u20ac\u20ac \ufffdso\n\u20aco\ufffdoz \u00d0oov\u20ac. k\u20ac\u00d0oww k\u20ac\ufffdso|~{|{~\ufffdt{z {q\ufffd\u20aco~\u20ac. ]ZS\u20ac kzn n{yktz\u20ac k||ok~tzr {zw\u00de tz\ufffdso\no\u00f0mo|\ufffdt{zkw _oov 7*tz\u00d0stms mwtyk\ufffdo mskzro \u00d0k\u20ac\ufffdso\u20ac\ufffdluom\ufffd {qkyktz\u20ac\ufffd~oky zo\u00d0\u20ac o\ufffdoz\ufffd\n\u00d0soz W~o\u20actnoz\ufffd \\~\ufffdy| kzz{\ufffdzmon \ufffdso][\u00d0t\ufffdsn~k\u00d0kw q~{y \ufffdsoWk~t\u20ac Fr~ooyoz\ufffd+1 \\st\u20ac yku{~\no\ufffdoz\ufffd \u20ac\ufffdl\u20ac\ufffdkz\ufffdtkww\u00de tzm~ok\u20acon \ufffdso\ufffd{w\ufffdyo {q\u20ac{mtkw yontk yo\u20ac\u20ackro\u20ac ~owk\ufffdon \ufffd{mwtyk\ufffdo mskzro\nkzn n~o\u00d0 tzkztzm~ok\u20acon z\ufffdylo~ {qzo\u00d0 \ufffd\u20aco~\u20ac. \u00d0s{ \u20acsk~on kr~ok\ufffdo~ z\ufffdylo~ {qk~\ufffdtmwo\u20ac q~{y k\nr~ok\ufffdo~ z\ufffdylo~ {q{zwtzo tzq{~yk\ufffdt{z \u20ac{\ufffd~mo\u20ac1 \\s\ufffd\u20ac \u00d0o{l\u20aco~\ufffdon zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o kzn m{y/\n|{\u20act\ufffdt{z tzl{\ufffds jz{~ykw {|o~k\ufffdt{z) k\u20ac\u00d0oww k\u20actzkz\ufffdz\ufffd\u20ac\ufffdkw \u20ac\ufffdk\ufffdo {qstrs km\ufffdt\ufffdt\ufffd\u00de. \u20acs{\u00d0tzr \ufffdso\n\ufffd\u00de|tmkw wo\ufffdow {q\u00d0oov/\ufffd{/\u00d0oov \ufffd{wk\ufffdtwt\ufffd\u00de k\u20ac\u00d0oww k\u20ac\ufffdso\u20ac\ufffdl\u20ac\ufffdkz\ufffdtkw mskzro \ufffdzno~ \ufffdsotzqw\ufffdozmo {q\n\ufffdsont\u20ac~\ufffd|\ufffdt\ufffdo yktz\u20ac\ufffd~oky zo\u00d0\u20ac o\ufffdoz\ufffd1 F\ufffdkww\ufffdtyo\u20ac. tzmw\ufffdntzr \ufffdsont\u20ac~\ufffd|\ufffdt\ufffdo o\ufffdoz\ufffd. \ufffdso|{wk~/\nt\u20acon zo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o ~oyktz\u20ac \u20ac\ufffd~{zr kzn mwok~w\u00de \ufffdt\u20actlwo. no\u20ac|t\ufffdo \u20ac\ufffdl\u20ac\ufffdkz\ufffdtkw mskzro\u20ac tzt\ufffd\u20ac\nm{z\u20ac\ufffdt\ufffd\ufffdoz\ufffd |k~\ufffd\u20ac *\ufffd\u20aco~\u20ac kzn k~\ufffdtmwo\u20ac+1 F\u20ac\u20ac\ufffdms. \u00d0om{zmw\ufffdno \ufffdsk\ufffd \ufffdsol~{kn \ufffd{|{w{rtmkw qok\ufffd\ufffd~o\u20ac\n\ufffdt\u20actlwo tzLtr\u20ac 6kzn ;k~o\u20ac\ufffdklwo {\ufffdo~ \ufffdso\u20aco\ufffdoz/\u00d0oov n\ufffd~k\ufffdt{z {q{\ufffd~nk\ufffdk\u20aco\ufffd1 [tytwk~w\u00de. \u00d0o\nqtzn \ufffdsk\ufffd \ufffdsok\u20ac\u20ac{mtk\ufffdt{z {qwoq\ufffd/\u00d0tzr2oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd \ufffdto\u00d0\u20ac. kzn {q~trs\ufffd/\u00d0tzr2\u20acmo|\ufffdtm \ufffdto\u00d0\u20ac.\nk~o|o~\u20act\u20ac\ufffdoz\ufffd. k\u20ac\u20acs{\u00d0z tzLtr9kkzn 9l.[:kzn [;Ltr\u20ac tz[4Ltwo1 L\ufffd\ufffd\ufffd~o \u20ac\ufffd\ufffdn\u00de yk\u00de qtzn t\ufffd\nq~\ufffdt\ufffdq\ufffdw \ufffd{o\u00f0kytzo \u00d0so\ufffdso~ \u20ac\ufffdms \u20ac\ufffdkltwt\ufffd\u00de o\u00f0t\u20ac\ufffd\u20ac q{~{\ufffdso~ {zwtzo zo\ufffd\u00d0{~v\u20ac {~{\ufffdso~ |{wt\ufffdtmt\u20acon\nnt\u20acm\ufffd\u20ac\u20act{z\u20ac1\n\\so \u20actytwk~t\ufffd\u00de \u20ac\ufffdk\ufffdt\u20ac\ufffdtm\u20ac tz\\klwo 6\u20ac\ufffdrro\u20ac\ufffd krozo~kw \ufffd~ozn q{~k\u20acykww |~{|{~\ufffdt{z {q\ufffdso\n\ufffd\u20aco~\u20ac. ]ZS\u20ac kzn n{yktz\u20ac \ufffd{|o~\u20act\u20ac\ufffd km~{\u20ac\u20ac \u00d0oov\u20ac \u00d0stwo {\ufffdso~\u20ac k||ok~ {zw\u00de \u20ac|{~kntmkww\u00de1 Oz\ufffdso\n]ZS mk\u20aco. \ufffdsom{y|k~k\ufffdt\ufffdow\u00de w{\u00d0wo\ufffdow\u20ac {q\u20actytwk~t\ufffd\u00de k~oz{\ufffd\u20ac\ufffd~|~t\u20actzr k\u20aczo\u00d0\u20ac k~\ufffdtmwo\u20ac k~o\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 53259\n}\ufffdtmvw\u00de \u20ac\ufffd|o~\u20aconon l\u00dezo\u00d0 qkm\ufffd\u20ac kzn |o~\u20ac|om\ufffdt\ufffdo\u20ac1 Fy{zr \ufffdso\ufffd\u20aco~\u20ac kzn n{yktz\u20ac. \ufffdsoo\ufffdtnozmo\n\u20ac\ufffdrro\u20ac\ufffd\u20ac \ufffdsozo\ufffd\u00d0{~v sk\u20ack\u20ac\ufffdklwo m{~o \u00d0t\ufffds kz\ufffdz\u20ac\ufffdklwo |o~t|so~\u00de1 V\ufffdo~ \ufffdso\u20aco\ufffdoz \u00d0oov\u20ac \u20ac\ufffd\ufffdn/\nton.kz\ufffdylo~ {q\u00d0ol\u20act\ufffdo\u20ac o\u20ac\ufffdklwt\u20acs \ufffdsoy\u20acow\ufffdo\u20ac k\u20acm~t\ufffdtmkw \ufffd{\ufffdsoqw{\u00d0 {qtzq{~yk\ufffdt{z k~{\ufffdzn mwt/\nyk\ufffdo mskzro. ot\ufffdso~ k\u20aczo\u00d0\u20ac \u20ac{\ufffd~mo\u20ac *\u20ac\ufffdms k\u20acTheGuardian {~Breitbart+ {~k\u20acm{zn\ufffdt\ufffd\u20ac q{~\n|o~\u20ac{zkw {|tzt{z\u20ac *\u20ac\ufffdms k\u20acTwitter kznWordpress+1 Tkz\u00de {\ufffdso~ \u20act\ufffdo\u20ac k~o|o~t|so~kw \ufffd{\ufffdso\nzo\u00d0\u20ac/\u20acsk~tzr zo\ufffd\u00d0{~v {qmwtyk\ufffdo mskzro. k||ok~tzr \u20ac|{~kntmkww\u00de \u00d0t\ufffds kw{\u00d0o~ q~o}\ufffdozm\u00de {q\n\ufffd\u20ackro1 \\st\u20ac |k|o~ sk\u20acnowtlo~k\ufffdow\u00de k\ufffd{tnon \u20ac\ufffd\ufffdn\u00detzr \ufffd\u20aco~\u20ac k\u20actznt\ufffdtn\ufffdkw\u20ac. l\ufffd\ufffdt\ufffd\u20acooy\u20ac ~ok\u20ac{z/\nklwo \ufffd{o\u00f0|om\ufffd km{~o r~{\ufffd| {qm{yyt\ufffd\ufffdon kzn \u20ac\ufffd~{zrw\u00de tz\ufffdo~o\u20ac\ufffdon |o{|wo \u00d0s{ ~or\ufffdwk~w\u00de \u20acsk~o\ntzq{~yk\ufffdt{z kl{\ufffd\ufffd mwtyk\ufffdo mskzro. \u00d0t\ufffds {\ufffdso~\u20ac \u00d0s{ m{z\ufffd~tl\ufffd\ufffdo wo\u20ac\u20acq~o}\ufffdoz\ufffdw\u00de {~{zw\u00de \u00d0soz\ny{\ufffdt\ufffdk\ufffdon l\u00deo\u00f0\ufffdo~zkw qkm\ufffd{~\u20ac1 I{z\u20actno~tzr \ufffdst\u20ac\ufffd\u20aco~ losk\ufffdt{\ufffd~ tz\ufffdsom{z\ufffdo\u00f0\ufffd {q\ufffdso|o~\u20act\u20ac\ufffdoz\ufffd\nzo\ufffd\u00d0{~v \u20ac\ufffd~\ufffdm\ufffd\ufffd~o \u00d0osk\ufffdo {l\u20aco~\ufffdon. t\ufffdk||ok~\u20ac \ufffdsk\ufffd \ufffdso~o\ufffdokwon |{wk~t\u20ack\ufffdt{z t\u20ackqok\ufffd\ufffd~o {q\ufffdso\n\u20ac\u00de\u20ac\ufffdoy k\u20ack\u00d0s{wo kzn z{\ufffdmk\ufffd\u20acon l\u00de\u20ac|omtqtm o\ufffdoz\ufffd\u20ac {~\ufffd\u20aco~\u20ac1\n\\st\u20ac k~\ufffdtmwo tww\ufffdytzk\ufffdo\u20ac \u20aco\ufffdo~kw zo\u00d0 ntyoz\u20act{z\u20ac {q\ufffdsoyontk nolk\ufffdo k~{\ufffdzn oz\ufffdt~{zyoz\ufffdkw\n|{wt\ufffdtm\u20ac kzn mwtyk\ufffdo mskzro1 \\so qtzntzr\u20ac m{y|woyoz\ufffd |~o\ufffdt{\ufffd\u20ac \u20ac\ufffd\ufffdnto\u20ac \ufffdsk\ufffd sk\ufffdo \u20acs{\u00d0z mwt/\nyk\ufffdo/~owk\ufffdon oms{ mskylo~\u20ac o\u00f0t\u20ac\ufffd tznt~om\ufffd \ufffd\u20aco~/\ufffd\u20aco~ tz\ufffdo~km\ufffdt{z\u20ac *o1r1 d4<. 5;f+ l\u00de\u20acs{\u00d0tzr\n\ufffdsk\ufffd \u20actytwk~ \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac kw\u20ac{ msk~km\ufffdo~t\u20aco |k\ufffd\ufffdo~z\u20ac {qtzq{~yk\ufffdt{z/\u20acsk~tzr1 \\so \\\u00d0t\ufffd\ufffdo~ yo\u20ac\u20ackro\u20ac\n\ufffdsk\ufffd q{~y \ufffdso\u20acsk~tzr zo\ufffd\u00d0{~v \u20ac\ufffd\ufffdnton so~o ~oqwom\ufffd kyomskzt\u20acy {qzo\u00d0\u20ac |~{y{\ufffdt{z kzn km\ufffdt\ufffdo\nk\ufffd\ufffdoy|\ufffd\u20ac \ufffd{tzq{~y {\ufffdso~\u20ac. \u00d0stms t\u20acz{\ufffdkw\u00d0k\u00de\u20ac \ufffdsomk\u20aco tznt~om\ufffd |o~\u20ac{zkw tz\ufffdo~km\ufffdt{z\u20ac1 _okw\u20ac{\nmk|\ufffd\ufffd~o k\ufffdt\ufffdkw knnt\ufffdt{zkw owoyoz\ufffd l\u00deo\u00f0|w{~tzr \ufffdsozo\ufffd\u00d0{~v \ufffd{|{w{r\u00de {\ufffdo~ \ufffdtyo kzn noy{z/\n\u20ac\ufffd~k\ufffdtzr \ufffdsk\ufffd \ufffdso|{wk~t\u20acon \u20ac\ufffd~\ufffdm\ufffd\ufffd~o |o~\u20act\u20ac\ufffd\u20ac. o\ufffdoz \u00d0soz \ufffdso~o t\u20acknt\u20ac~\ufffd|\ufffdt\ufffdo yktz\u20ac\ufffd~oky zo\u00d0\u20ac\no\ufffdoz\ufffd1 Ozknnt\ufffdt{z. \u00d0osk\ufffdo \u20acs{\u00d0z k\u20ac\ufffd~{zr m{~~owk\ufffdt{z lo\ufffd\u00d0ooz |{wt\ufffdtmkw kzn mwtyk\ufffdo/~owk\ufffdon\ntno{w{rtmkw ltk\u20aco\u20ac tzzo\u00d0\u20ac |~{n\ufffdm\ufffdt{z kzn m{z\u20ac\ufffdy|\ufffdt{z. \u00d0t\ufffds k\u20ac\u20ac{mtk\ufffdt{z\u20ac lo\ufffd\u00d0ooz woq\ufffd/\u00d0tzr2\noz\ufffdt~{zyoz\ufffdkw kzn ~trs\ufffd/\u00d0tzr2\u20acmo|\ufffdtm |{\u20act\ufffdt{z\u20ac1 \\st\u20ac \u00d0tnoz\u20ac \ufffdso\u20acm{|o {q|~o\ufffdt{\ufffd\u20ac \u20ac\ufffd\ufffdnto\u20ac {q\nyktz\u20ac\ufffd~oky zo\u00d0\u20ac yontk *o1r1 d94f+ \ufffd{tzmw\ufffdno \ufffdsotzm~ok\u20actzrw\u00de ty|{~\ufffdkz\ufffd {zwtzo zo\u00d0\u20ac yontk1\n_soz w{{von k\ufffdtzt\u20ac{wk\ufffdt{z. \u20aco\ufffdo~kw n{yktz\u20ac k||ok~ \ufffd{lom{non \u00d0t\ufffds y{~o {qkwoq\ufffd/\u00d0tzr.\noz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd ltk\u20ac \ufffdskz \u00d0{\ufffdwn loo\u00f0|om\ufffdon l\u00den{yktz vz{\u00d0wonro o\u00f0|o~\ufffd\u20ac1 \\\u00de|tmkww\u00de zo\ufffd\ufffd~kw\n\u20act\ufffdo\u20ac. \u20ac\ufffdms k\u20acGw{{ylo~r. k~o~o|{~\ufffdon k\u20acwoq\ufffd/\u00d0tzr kzn oz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd |~tyk~tw\u00de \ufffds~{\ufffdrs \ufffdso\nwoz\u20aco\u20ac \ufffdso\u00de \ufffd\u20aco\ufffd{m{\ufffdo~ \ufffdso\u20ac|omtqtm \ufffd{|tm {qmwtyk\ufffdo mskzro1 V\ufffdso~ n{yktz\u20ac. \u20ac\ufffdms k\u20ac\ufffdsoJktw\u00de\nIkwwo~. yk\u00de sk\ufffdo looz |{{~w\u00de ~o|~o\u20acoz\ufffdon l\u00de\ufffdsom{z\ufffdoz\ufffd \u20acky|wtzr |~{mo\u20ac\u20ac k\u20acqkm\ufffd\ufffdkw kzn \u20acmtoz/\n\ufffdtqtm o\u00f0\ufffd~km\ufffd\u20ac \ufffdkvoz \u00d0t\ufffds{\ufffd\ufffd \u20ac\ufffd~~{\ufffdzntzr mskwwozrtzr m{z\ufffdo\u00f0\ufffd \u00d0o~o m{z\u20actno~on k\u20ac\u20ac\ufffd||{~\ufffdtzr\n\ufffdso\u20acmtoz\ufffdtqtm m{z\u20acoz\u20ac\ufffd\u20ac1 \\st\u20ac \ufffdr{{n qkt\ufffds\ufffd {z\ufffdso|k~\ufffd {q\ufffdsom{no~\u20ac ~o\ufffd\ufffd~z\u20ac k|k~\ufffdtm\ufffdwk~w\u00de o~~{/\nzo{\ufffd\u20ac ~o\u20ac|{z\u20aco q{~_k\ufffd\ufffd\u20ac ]|_t\ufffds \\sk\ufffd. k|~{ytzoz\ufffd lw{r tz\ufffdso\u20acmo|\ufffdtmkw m{yy\ufffdzt\ufffd\u00de1 Tkz\u00de\n{q\ufffdsot~ k~\ufffdtmwo\u20ac |~o\u20acoz\ufffd }\ufffd{\ufffdk\ufffdt{z\u20ac q~{y |\ufffdlwtm qtr\ufffd~o\u20ac kzn \u20acmtoz\ufffdtqtm |k|o~\u20ac tzknnt\ufffdt{z \ufffd{\ufffdsot~\n{\u00d0z m{yyoz\ufffdk~\u00de \ufffdsk\ufffd q~o}\ufffdoz\ufffdw\u00de mskwwozro\u20ac \ufffdsoq~kytzr. \u00d0stms k~om{z\ufffdo\u00f0\ufffd\ufffdkw mw\ufffdo\u20ac \ufffdsk\ufffd yk\u00de\nlo\ufffdzk\ufffdktwklwo \ufffd{\ufffdsom{no~\u20ac1 \\so wk\u20ac\ufffdo\u00f0|wkzk\ufffdt{z q{~|{\u20ac\u20actlwo yt\u20acmwk\u20ac\u20actqtmk\ufffdt{z {qmo~\ufffdktz\nn{yktz\u20ac tnoz\ufffdtqton tz\ufffdst\u20aco\u00f0o~mt\u20aco t\u20ac\ufffdso~o|{\u20ac\ufffdtzr {qm{z\ufffdoz\ufffd q~{y {\ufffdso~ \u20ac{\ufffd~mo\u20ac1 Oz\ufffdo\u20ac\ufffdtrk\ufffdt{z\n{q\ufffdsok~\ufffdtmwo\u20ac m{non q~{y L{\u00f0 Uo\u00d0\u20ac q{\ufffdzn \ufffdsk\ufffd \ufffds~oo {q\ufffdsoqt\ufffdok~\ufffdtmwo\u20ac \u00d0o~o q~{y F\u20ac\u20ac{mtk\ufffdon\nW~o\u20ac\u20ac \u20ac{\ufffd~mo\u20ac. \u00d0stms yk\u00de |~o\u20acoz\ufffd kntqqo~oz\ufffd ont\ufffd{~tkw ltk\u20ac \ufffd{L{\u00f0 Uo\u00d0\u20ac {~trtzkw m{z\ufffdoz\ufffd1 \\so\nms{tmo {q\u00d0stms m{z\ufffdoz\ufffd \ufffd{~o|{\u20ac\ufffd q~{y {\ufffdso~ \u20ac{\ufffd~mo\u20ac t\u20ackzty|{~\ufffdkz\ufffd ont\ufffd{~tkw nomt\u20act{z kzn k\u20ac\n\u20ac\ufffdms \u00d0olowto\ufffdo \ufffdst\u20actzmw\ufffd\u20act{z sk\u20acz{\ufffdkn\ufffdo~\u20acow\u00de kqqom\ufffdon {\ufffd~qtzntzr\u20ac1\nL\ufffd\ufffd\ufffd~o \u00d0{~v tz\ufffdst\u20ack~ok m{\ufffdwn q\ufffd~\ufffdso~ o\u00f0kytzo \ufffdso\ufffdto\u20aclo\ufffd\u00d0ooz |{wt\ufffdtmkw kzn oz\ufffdt~{zyoz\ufffdkw\n{|tzt{z\u20ac1 \\st\u20ac \u20ac\ufffd\ufffdn\u00de \ufffd\u20acon s\ufffdykz m{no~\u20ac \ufffd{no\ufffdom\ufffd ltk\u20aco\u20ac q~{y k~\ufffdtmwo m{z\ufffdoz\ufffd1 _stwo \ufffdst\u20ac\nk||~{kms \u00d0k\u20ac\u20ac\ufffdmmo\u20ac\u20acq\ufffdw. t\ufffdmk~~to\u20ac \u20ac\ufffdl\u20ac\ufffdkz\ufffdtkw m{\u20ac\ufffd\u20ac \u00d0stms ykvo t\ufffdsk~n \ufffd{{|o~k\ufffdo q{~wk~ro\nnk\ufffdk\u20aco\ufffd\u20ac1 O\ufffdm{\ufffdwn lok~r\ufffdon \ufffdsk\ufffd {\ufffd~\ufffd\u20aco{q\u20ac\ufffdluom\ufffdt\ufffdo s\ufffdykz r~kntzr t\u20ackwtyt\ufffdk\ufffdt{z tz{\ufffd~\nkzkw\u00de\u20act\u20ac. l\ufffd\ufffdt\ufffdt\u20ackzomo\u20ac\u20ack~\u00de m{y|~{yt\u20aco rt\ufffdoz \ufffdsotzso~oz\ufffdw\u00de \u20ac\ufffdluom\ufffdt\ufffdo zk\ufffd\ufffd~o {q|{wt\ufffdtmkw\nkzn oz\ufffdt~{zyoz\ufffdkw lowtoq\u20ac kzn \ufffdsom\ufffd~~oz\ufffd wkmv {q{luom\ufffdt\ufffdo \ufffd{{w\u20ac q{~kzkw\u00de\u20actzr \u20ac\ufffdms m{y|wo\u00f0\ntz\ufffdo~|~o\ufffdk\ufffdt{z\u20ac tzwk~ro }\ufffdkz\ufffdt\ufffdto\u20ac {qnk\ufffdk1 Fzk\ufffd\ufffd{yk\ufffdon mwk\u20ac\u20actqto~ q{~\ufffdso\u20aco ltk\u20aco\u20ac \u00d0{\ufffdwn\n~o}\ufffdt~o \u20actrztqtmkz\ufffd \u00d0{~v q{~t\ufffd\u20acm~ok\ufffdt{z *\ufffd\u20actzr klwozn {qykmstzo wok~ztzr kzn zk\ufffd\ufffd~kw wkz/\nr\ufffdkro |~{mo\u20ac\u20actzr+. l\ufffd\ufffd\u00d0{\ufffdwn \u20ac\ufffd||{~\ufffd q\ufffd\ufffd\ufffd~o wk~ro/\u20acmkwo \u20ac\ufffd\ufffdnto\u20ac. kzomo\u20ac\u20ack~\u00de \u20ac\ufffdo| rt\ufffdoz \ufffdso\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 54259\no\ufffdo~/tzm~ok\u20actzr \ufffd{w\ufffdyo {q{zwtzo m{z\ufffdoz\ufffd1 Fz{\ufffdso~ ~o\u20acok~ms }\ufffdo\u20ac\ufffdt{z m{zmo~z\u20ac \u00d0so\ufffdso~ \ufffdso\n|k\ufffd\ufffdo~z\u20ac {l\u20aco~\ufffdon {z\\\u00d0t\ufffd\ufffdo~ o\u00f0\ufffdozn \ufffd{{\ufffdso~ {zwtzo |wk\ufffdq{~y\u20ac1 _o\u20ac\ufffd\ufffdnton \\\u00d0t\ufffd\ufffdo~ n\ufffdo\ufffd{t\ufffd\u20ac\n|~{ytzoz\ufffd ~{wo k\u20ackyokz\u20ac q{~\ufffd\u20aco~\u20ac \ufffd{qtzn zo\u00d0\u20ac \u20ac\ufffd{~to\u20ac d99f kzn t\ufffd\u20acq~o}\ufffdoz\ufffd \ufffd\u20ackro k\u20ack|wk\ufffd/\nq{~y q{~wt\ufffdow\u00de |{wt\ufffdtmkw nolk\ufffdo\u20ac tz\u00d0stms \u20ac\ufffd~kzro~\u20ac mkztz\ufffdo~km\ufffd1 Oq\u20ac\ufffdt\ufffdklwo nk\ufffdk\u20aco\ufffd\u20ac m{\ufffdwn lo\n{l\ufffdktzon. t\ufffd\u00d0{\ufffdwn lo|{\u20ac\u20actlwo \ufffd{k||w\u00de \u20actytwk~ yo\ufffds{n\u20ac \ufffd{{\ufffdso~ |{|\ufffdwk~ \u20act\ufffdo\u20ac \u20ac\ufffdms k\u20acLkmol{{v\nkzn Zonnt\ufffd? s{\u00d0o\ufffdo~. |~t\ufffdkm\u00de ~o\u20ac\ufffd~tm\ufffdt{z\u20ac |~o\ufffdoz\ufffd ~o\u20acok~ms {zykz\u00de \u20ac{mtkw yontk |wk\ufffdq{~y\u20ac1\nLtzkww\u00de. {zoq\ufffd~\ufffdso~ }\ufffdo\u20ac\ufffdt{z \ufffdsk\ufffd t\u20acz{\ufffdknn~o\u20ac\u20acon so~o t\u20acn{\u00d0z\u20ac\ufffd~oky o\u00f0|{\u20ac\ufffd~o \ufffd{\u20acsk~on m{z/\n\ufffdoz\ufffd. \ufffdsk\ufffd t\u20ac.\u00d0s{ \u20acoo\u20ac \ufffdsok~\ufffdtmwo\u20ac \ufffdsk\ufffd k~o\u20acsk~on l\u00de\\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\u20acD O\ufffdt\u20ac|~{lklwo \ufffdsk\ufffd \ufffdso\ufffd\u20aco~\u20ac\nmk|\ufffd\ufffd~on tz{\ufffd~nk\ufffdk\u20aco\ufffd. \ufffdsk\ufffd \u20acowom\ufffd kzn \u20acsk~o {zwtzo k~\ufffdtmwo\u20ac kl{\ufffd\ufffd mwtyk\ufffdo mskzro \ufffds~{\ufffdrs\n\\\u00d0t\ufffd\ufffdo~. km\ufffdk\u20acj{|tzt{z wokno~\u20ac) *q{ww{\u00d0tzr \ufffdsow{zr/o\u20ac\ufffdklwt\u20acson \ufffd\u00d0{/\u20ac\ufffdo| qw{\u00d0 y{now {qRk\ufffd\u00fe\nkzn Sk\u00fek~\u20acqown d9:f+. w{mk\ufffdtzr zo\u00d0 tzq{~yk\ufffdt{z kl{\ufffd\ufffd \ufffdso\ufffd{|tm kzn nt\u20ac\u20acoytzk\ufffdtzr t\ufffd\ufffd{\ufffdsot~\nq{ww{\u00d0o~\u20ac1 Tok\u20ac\ufffd~tzr \ufffdso\ufffd{w\ufffdyo {qn{\u00d0z\u20ac\ufffd~oky \ufffdto\u00d0\u20ac kzn ~o\ufffd\u00d0oo\ufffd ~k\ufffdo\u20ac \u00d0{\ufffdwn kz\u20ac\u00d0o~ ty|{~/\n\ufffdkz\ufffd }\ufffdo\u20ac\ufffdt{z\u20ac kl{\ufffd\ufffd \u00d0stms yo\u20ac\u20ackro\u20ac k~oy{~o oqqom\ufffdt\ufffdo \u00d0soz \u20acsk~on {z\u20ac{mtkw yontk1 Vzo vo\u00de\n}\ufffdo\u20ac\ufffdt{z t\u20ac\ufffdsoo\u00f0\ufffdoz\ufffd \ufffd{\u00d0stms |{wk~t\u20ack\ufffdt{z o\u00f0t\u20ac\ufffd\u20ac tz\ufffdst\u20ac\u20acom{znk~\u00de m{z\u20ac\ufffdy|\ufffdt{z {qmwtyk\ufffdo\nmskzro yontk. {~\u00d0so\ufffdso~ zo\ufffd\u00d0{~v oqqom\ufffd\u20ac yt\ufffdtrk\ufffdo |{wk~t\u20ack\ufffdt{z l\u00demk|\ufffd\ufffd~tzr \ufffdto\u00d0\u20ac q~{y l{\ufffds\n\u20actno\u20ac1\nFz\u00de rk\ufffdso~tzr {qnk\ufffdk q~{y {zwtzo \u20ac{mtkw zo\ufffd\u00d0{~v\u20ac ~o}\ufffdt~o\u20ac mk~oq\ufffdw m{z\u20actno~k\ufffdt{z {q\ufffdso\nltk\u20aco\u20ac \ufffdsk\ufffd t\ufffdyk\u00de tz\ufffd~{n\ufffdmo1 \\so \ufffd\u20aco~\u20ac {q{zwtzo |wk\ufffdq{~y\u20ac k~okntqqo~oz\ufffd nt\u20ac\ufffd~tl\ufffd\ufffdt{z {q|o{|wo\n\ufffdskz \ufffdsorozo~kw |{|\ufffdwk\ufffdt{z> \ufffdso\u00de \ufffdozn \ufffd{lo\u00de{\ufffdzro~. y{~o \u00d0okw\ufffds\u00de kzn lo\ufffd\ufffdo~ on\ufffdmk\ufffdon d9;f1\nV\ufffd~ \u20acky|wtzr {zvo\u00de\u00d0{~n\u20ac yokz\u20ac \ufffdsk\ufffd \u00d0o\u00d0twwmk|\ufffd\ufffd~o \ufffd\u20aco~\u20ac \u00d0s{ k~oy{~o ozrkron \u00d0t\ufffds \ufffdso\n\ufffd{|tm {qmwtyk\ufffdo mskzro. kzn y{~o{\ufffdo~ k~o\u20actrztqtmkz\ufffdw\u00de tz\ufffdo\u20ac\ufffdon oz{\ufffdrs \ufffd{\u20acsk~o tzq{~yk\ufffdt{z\n\u00d0t\ufffds \ufffdsot~ q{ww{\u00d0o~\u20ac1 F\u20ac\u20ac\ufffdms \u00d0ok~om{z\u20actno~tzr kstrsw\u00de/y{\ufffdt\ufffdk\ufffdon \u20acky|wo {qkmo~\ufffdktz |k~\ufffd {q\n\u20ac{mto\ufffd\u00de. l\ufffd\ufffd\ufffdst\u20act\u20ac\u00d0sk\ufffd \u00d0twwlo\ufffdt\u20actlwo \ufffd{ykz\u00de \ufffd\u20aco~\u20ac \u00d0soz \ufffdso\u00de \ufffdt\u20act\ufffd \\\u00d0t\ufffd\ufffdo~1 \\st\u20ac \u20acky|wtzr\nkw\u20ac{ o\u00f0|wktz\u20ac \ufffdsontqqo~ozmo q~{y Mw{lkw _k~ytzr)\u20ac [t\u00f0Fyo~tmk\u20ac d4f\ufffdsk\ufffd \u00d0o{l\u20aco~\ufffdo. k\u20ac{zw\u00de\n\ufffdso\ufffdkwk~yon\ufffd kzn \ufffdnt\u20acyt\u20ac\u20act\ufffdo\ufffd \ufffd\u00de|o\u20ac k~owtvow\u00de \ufffd{lotz\ufffdo\u20ac\ufffdon oz{\ufffdrs \ufffd{lomk|\ufffd\ufffd~on1 \\so \u00d0{~v\n{q_twwtky\u20ac o\ufffdkw1d4<f \u20ac\ufffd||{~\ufffd \ufffdst\u20ack\u20ac\ufffdsot~ m{ntzr {q\\\u00d0t\ufffd\ufffdo~ \ufffd\u20aco~\u20ac q{\ufffdzn {zw\u00de \ufffdsoo\u00f0\ufffd~oyo\noz\ufffdt~{zyoz\ufffdkwt\u20ac\ufffd\u20ac kzn \u20acmo|\ufffdtm\u20ac1 V\ufffd~ vo\u00de\u00d0{~n\u20ac \u00d0o~o ms{\u20acoz \ufffd{mk|\ufffd\ufffd~o k\u20acy\ufffdms {q\ufffdsoKzrwt\u20acs\nwkzr\ufffdkro m{y|{zoz\ufffd\u20ac {q\ufffdsomwtyk\ufffdo mskzro m{z\ufffdo~\u20ack\ufffdt{z {zwtzo. l\ufffd\ufffd\ufffdso{l\u20aco~\ufffdon \u20ac\ufffd~\ufffdm\ufffd\ufffd~o\u20ac\nyk\u00de \ufffdk~\u00de tz{\ufffdso~ wkzr\ufffdkro\u20ac1 \\so\u20aco qkm\ufffd{~\u20ac \u20acs{\ufffdwn lom{z\u20actno~on tzkz\u00dekzkw\u00de\u20act\u20ac {q\u20ac{mtkw\nyontk nk\ufffdk l\ufffd\ufffd\u00d0on{z{\ufffdlowto\ufffdo \ufffdsk\ufffd \ufffdso\u00de kqqom\ufffd \ufffdso\u20ac\ufffd~ozr\ufffds {q{\ufffd~qtzntzr\u20ac tzkz\u00de\u00d0k\u00de1\n\\st\u20ac \u00d0{~v noy{z\u20ac\ufffd~k\ufffdo\u20ac \ufffdsk\ufffd yontk m{yy\ufffdztmk\ufffdt{z {qtzq{~yk\ufffdt{z k~{\ufffdzn mwtyk\ufffdo mskzro\nqkmo\u20ac ykz\u00de mskwwozro\u20ac tz\ufffdsokro{q\u20ac{mtkw yontk1 ]\u20aco~\u20ac ~o\ufffd\ufffd~z \ufffd{\ufffdso\u20ackyo \ufffd~\ufffd\u20ac\ufffdon \u20ac{\ufffd~mo\u20ac q{~\ntzq{~yk\ufffdt{z o\ufffdoz \u00d0soz |~o\u20acoz\ufffdon \u00d0t\ufffds zo\u00d0 m{z\ufffdo\u00f0\ufffd\u20ac. kzn kz\u00dek\ufffd\ufffdoy|\ufffd\u20ac \ufffd{k\ufffd\ufffd~km\ufffd zo\u00d0 ~okno~/\n\u20acst|\u20ac zoon \ufffd{m{z\u20actno~ \ufffdst\u20aclosk\ufffdt{\ufffd~1 ]zno~\u20ac\ufffdkzntzr s{\u00d0 \ufffdso\u20aco \ufffd~\ufffd\u20ac\ufffdon \ufffdto\u20acq{~y \u00d0twwlovo\u00de\n\ufffd{m{ylk\ufffdtzr \ufffdso\u20ac|~okn {qyt\u20actzq{~yk\ufffdt{z \ufffdsk\ufffd m\ufffd~~oz\ufffdw\u00de mskwwozro\u20ac {zwtzo \u20ac{mtkw zo\ufffd\u00d0{~v\u20ac\nkzn \ufffdt\ufffdkw q{~|~{y{\ufffdtzr km\ufffdt{z {zmwtyk\ufffdo mskzro kzn {\ufffdso~ \u20ac{mto\ufffdkw mskwwozro\u20ac1\n[\ufffd||{~\ufffdtzr tzq{~yk\ufffdt{z\n[4Ltwo1\n*WJL+\nF\ufffd\ufffds{~ I{z\ufffd~tl\ufffd\ufffdt{z\ufffd\nI{zmo|\ufffd\ufffdkwt\u00fek\ufffdt{z> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~1\nJk\ufffdk m\ufffd~k\ufffdt{z> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~1\nL{~ykw kzkw\u00de\u20act\u20ac> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~. N\u00de\u00d0ow \\1W1_twwtky\u20ac1\nL\ufffdzntzr km}\ufffdt\u20act\ufffdt{z> N\u00de\u00d0ow \\1W1_twwtky\u20ac1\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 55259\nOz\ufffdo\u20ac\ufffdtrk\ufffdt{z> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~. N\u00de\u00d0ow \\1W1_twwtky\u20ac1\nTo\ufffds{n{w{r\u00de> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~. N\u00de\u00d0ow \\1W1_twwtky\u20ac1\n[{q\ufffd\u00d0k~o> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~1\n[\ufffd|o~\ufffdt\u20act{z> Oktz [1_ok\ufffdo~. N\u00de\u00d0ow \\1W1_twwtky\u20ac1\n^t\u20ac\ufffdkwt\u00fek\ufffdt{z> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~1\n_~t\ufffdtzr \u02d8{~trtzkw n~kq\ufffd> \\~t\u20ac\ufffdkz Q1G1Ikzz1\n_~t\ufffdtzr \u02d8~o\ufffdto\u00d0 \u2019ont\ufffdtzr> \\~t\u20ac\ufffdkz Q1G1Ikzz. Oktz [1_ok\ufffdo~. N\u00de\u00d0ow \\1W1_twwtky\u20ac1\nZoqo~ozmo\ufffd\n41 Sot\ufffdo~{\ufffdt \ufffd\ufffdF.Tktlkms K.Z{\ufffdo~/Z oz{\ufffdq I.Lotzlo~ rM.N{\ufffdo W1Mw{lkw _k~ytzr )\ufffd[t\ufffdFyo~tmk\ufffd> [o|/\n\ufffdoylo~ 5345? 53461\n51 To\ufffdkr Q.L\ufffd\u00c6ms\ufffdwtz \\.[msk\u00c6qo~T[1 Mw{lkw \ufffdk~ytzr)\ufffd qt\ufffdoMo~ykz\ufffd\ufffd >F\ufffd\ufffd|{w{r\ufffd {qMo~ykz\ufffd )\ufffdto\ufffd\ufffd {z\nmwtyk\ufffdo mskzro kzn|k\ufffd\ufffdo~z\ufffd {qyontk \ufffd\ufffdokzntzq{~yk\ufffdt {z1W\ufffdlwtm ]zno~\ufffd\ufffdkz ntzr {q[mtozmo1 534;? 5:\n*7+>767\u02d879 41s\ufffd\ufffd|\ufffd>22n{ t1{~r243144;; 23=:6::5 9499=599< WTOJ> 5:47547<\n61 J\ufffdzwk| ZK.TmI~tr s\ufffdFT. bk~{\ufffds QN1\\so W{wt\ufffdtmkw Jt\ufffdtno {zIwtyk\ufffdo Iskzro> Wk~\ufffdt\ufffdkz W{wk~t\ufffdk\ufffd t{z\n_tnoz\ufffd tz\ufffdso]1[1 Kz\ufffdt~{zyoz\ufffd >[mtozmo kznW{wtm\ufffd q{~[\ufffd\ufffd\ufffdktzk lwoJo\ufffdow{|yoz\ufffd1 534:? 9<*9+>7\u02d856 1\n71 Lownykz S.Nk~\ufffd W[.Sot\ufffdo~{ \ufffdt\ufffd\ufffd F.Tktlkms K.Z{\ufffdo~/Zoz{\ufffd qI1J{N{\ufffd\ufffdtwo Tontk Wo~mo|\ufffd t{z\ufffd Sokn \ufffd{\nFm\ufffdt{zD \\so Z{wo {qN{\ufffd\ufffdtwo Tontk Wo~mo|\ufffdt{z\ufffd .W{wt\ufffdtmkw Kqqtmkm\ufffd. kznOno{w{r\ufffd tzW~ontm\ufffd tzrIwtyk\ufffdo\nIskzro Fm\ufffdt\ufffdt\ufffdy1 I{yy\ufffdz tmk\ufffdt{z Zo\ufffdok~ms1 534;? 77*<+>43== \u02d844571 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144; ;2\n33=6:935479 :9=47\n91 W{~\ufffdo~ FQ.Noww\ufffd\ufffdoz O1Oz\ufffdo\ufffd\ufffd trk\ufffdtzr Wk~\ufffdtmt|k\ufffd{~\ufffd J\ufffdzkyt m\ufffd\\s~{\ufffdrs [{mtkw Tontk ]\ufffdtzr kT\ufffdw\ufffdtno\ufffdo~ yt/\nzkz\ufffd \ufffdL~kyo\ufffd F||~{km s>\\so Ik\ufffdo {qIwtyk\ufffd ork\ufffdo {zb{\ufffd\\\ufffdlo1 Q{\ufffd~zkw {qI{y|\ufffd\ufffdo~/ Tontk\ufffdon I{y/\ny\ufffdztmk\ufffdt{z 15347? 4=*7+>435 7\u02d843741 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431444 42umm71453: 9\n:1 I{zz{~ W.Nk~~t\ufffd K.M\ufffd\ufffd [.Lo~zkzn{ Q.[skzv JG.R\ufffd~\ufffd \\.o\ufffdkw1Oz\ufffdo~|o~\ufffd {zkw m{yy\ufffdztmk\ufffd t{zkl{\ufffd\ufffd mwt/\nyk\ufffdo mskzro> s{\ufffd yo\ufffd\ufffdkro\ufffd mskzro \ufffdsoz m{yy\ufffdztm k\ufffdon \ufffds~{\ufffdrs \ufffdty\ufffdwk\ufffdon {zwtzo \ufffd{mtkw zo\ufffd\ufffd{~v\ufffd1\nIwtyk\ufffdtm Iskzro1 534:? 46:*6+>7:6 \u02d87;:1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431433 ;2\ufffd439<7 /34:/4:76/\ufffd\n;1 cskzr G.\ufffdkzno~Stznoz [.Ttwnozlo~ro~ T.Tk~w{z QZ.N{\ufffdo WJ.Sot\ufffdo~{\ufffdt \ufffd\ufffdF1K\ufffd|o~tyo z\ufffdkwoqqom\ufffd\ufffd\n{qmwtyk\ufffdo yo\ufffd\ufffdkro\ufffd \ufffdk~\ufffd ro{r~k|stm kww\ufffd1 Uk\ufffd\ufffd~o Iwtyk\ufffdo Iskzro1 534<? <*9+>6;3\u02d86 ;71s\ufffd\ufffd|\ufffd>2 2n{t1{~r2\n431436<2 \ufffd7499</34</ 3455/3\n<1 ^kwvozl\ufffd~r W.Wo\ufffdo~ Q1I{yy Zo\ufffdok~m s\u0152^to\ufffd\ufffd q~{y K\ufffd~{|o\ufffd Lt\ufffdo Iskwwozr o\ufffdq{~\ufffdsoL\ufffd\ufffd\ufffd~o {qTontk/\nKqqom\ufffd\ufffd Zo\ufffdok~ms1 Oz\ufffdo~zk\ufffdt{zkw Q{\ufffd~zkw {qI{yy\ufffdz tmk\ufffdt{z1 5346? ;*3+1\n=1 Loo\ufffdoww Q\\1Froznk [o\ufffd\ufffdtzr \ufffds~{\ufffdrs [{mtkw Tontk> \\so Oy|{~\ufffdkzmo {qOzmtnoz\ufffdkw Uo\ufffd\ufffd K\ufffd|{\ufffd\ufffd~o kzn\n[{mtkw Ltw\ufffdo~tzr tz\ufffdsoJtrt\ufffdkw K~k1 W{wt\ufffdtmkw Zo\ufffdok~ms Y\ufffdk~\ufffdo~w\ufffd 1534<? ;4*5+>7<5\u02d8 7=71 s\ufffd\ufffd|\ufffd>22n{ t1{~r2431\n44;;243:9= 45=4;;77<=9\n431 T{\u00c6wwo~Q.\\~twwtzr J.Nowlo~r o~U.\ufffdkzK\ufffdG1J{z{\ufffdlwkyo t\ufffd{z\ufffdsokwr{~t\ufffdsy> kzoy|t~tmkw k\ufffd\ufffdo\ufffd\ufffdyoz \ufffd{q\ny\ufffdw\ufffdt|wo ~om{yyozno ~\ufffd\ufffd\ufffd\ufffdoy\ufffd kzn\ufffdsot~ ty|km\ufffd {zm{z\ufffdoz\ufffd nt\ufffdo~\ufffdt\ufffd\ufffd1 Ozq{~yk\ufffdt{ z.I{yy\ufffdz tmk\ufffdt{z \u2019\n[{mto\ufffd\ufffd1 534<? 54*;+>=9=\u02d8 =;;1 s\ufffd\ufffd|\ufffd>22n{t1{~ r243143<32 46:=44<a153 4<147773;:\n441 Ik\ufffd\ufffdoww\ufffd T1I{yy\ufffdz tmk\ufffdt{z. W{\ufffdo~ kznI{\ufffdz\ufffdo~/|{\ufffd o~tz\ufffdsoUo\ufffd\ufffd{~v [{mto\ufffd\ufffd1 Oz\ufffdo~zk\ufffdt{zkw Q{\ufffd~zkw {q\nI{yy\ufffdz tmk\ufffdt{z1 533;? 4*4+1\n451 [sok~o~ K.M{\ufffd\ufffdq~ton Q1Uo\ufffd\ufffd ]\ufffdo Fm~{\ufffd\ufffd [{mtkw Tontk Wwk\ufffdq{~y \ufffd534;1 Wo\ufffd Zo\ufffdok~ms Ioz\ufffdo~? 534;1\nF\ufffdktwklwo q~{y> s\ufffd\ufffd|>22\ufffd\ufffd\ufffd1 u{\ufffd~zkwt\ufffdy1{~r 2534;23= 23;2zo\ufffd\ufffd/\ufffd\ufffd o/km~{\ufffd\ufffd/\ufffd{ mtkw/yontk/|w k\ufffdq{~y\ufffd/53 4;21\n461 _ok\ufffdo~ O[._twwtky\ufffd N.It{~{tkz \ufffdO.Qk\ufffdz\ufffd S.I{kz \\.Gkzn\ufffdmmt [1I{yy\ufffdz t\ufffdto\ufffd {q{zwtzo zo\ufffd\ufffd o\ufffd|{/\n\ufffd\ufffd~o n\ufffd~tzr \ufffdso]RMozo~kw Kwom\ufffdt{z 53491 Vzwtzo [{mtkw Uo\ufffd\ufffd{~v\ufffd kznTontk1 534=? 43/44>4<\u02d863 1\ns\ufffd\ufffd|\ufffd>22n{t1{~ r2431434 :2u1{\ufffdzoy153 4=139133 4\n471 JtTkrrt{ W.K\ufffdkz\ufffd Q.G~\ufffd\ufffd{z G1Nk\ufffdo Fyo~tmkz )\ufffd[{mtkw F\ufffd\ufffdt\ufffd\ufffdno\ufffd Gom{yo T{~o W{wk~t\ufffdonD Fyo~tmkz\nQ{\ufffd~zkw {q[{mt{w{ r\ufffd14==:? 435*6+>:=3 \u02d8;991 s\ufffd\ufffd|\ufffd>22n{t1{~ r243143< :2563==9\n491 Lo~zkzno\ufffd T.Wtmm{w{ S[M. Tk\ufffdzk~n J._t||{{ T.Totwt I.Fwkzt N1\\kwvtzr Iwtyk\ufffd oIskzro \ufffdtk[{mtkw\nTontk> I{yy\ufffdztm k\ufffdt{z. Kzrkroy oz\ufffdkznGosk\ufffdt{\ufffd~1 Oz>W~{moontzr\ufffd {q\ufffdso<\ufffdsFIT I{zqo~oz mo{z\n_ol [mtozmo? 534:1 |1<9\u02d8=71 F\ufffdktwklwo q~{y> s\ufffd\ufffd|>22n{t1k my1{~r24314 47925=3 <46415=3<4:; 1\n4:1 [oro~lo~ rF.Gozzo\ufffd\ufffd _S1 [{mtkw Tontk kzn\ufffdsoV~rkzt\ufffdk\ufffdt{ z{qI{wwom\ufffdt\ufffdo Fm\ufffdt{z> ]\ufffdtzr \\\ufffdt\ufffd\ufffdo~ \ufffd{\nK\ufffd|w{~o \ufffdsoKm{w{rt o\ufffd{q\\\ufffd{ Iwtyk\ufffdo Iskzro W~{\ufffdo\ufffd\ufffd\ufffd1 \\so I{yy\ufffdz tmk\ufffdt{z Zo\ufffdto\ufffd1 5344? 47*6+>4=;\u02d8\n5491 s\ufffd\ufffd|\ufffd>22n{ t1{~r243143<3 243;4775 41534419=;593\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 56259\n4;1 Kwro\ufffdoy J.[\ufffdo\ufffdvkw S.Jtkv{|{ \ufffdw{\ufffd U1[\ufffd~\ufffdm\ufffd\ufffd~o kznI{z\ufffdoz\ufffd {q\ufffdsoJt\ufffdm{\ufffd~ \ufffdo{zIwtyk\ufffdo Iskzro tz\n\ufffdsoGw{r{\ufffd| so~o> \\so GtrWtm\ufffd\ufffd~o1 Kz\ufffdt~{zy oz\ufffdkw I{yy\ufffdz tmk\ufffdt{z1 5349? =*5+>4:=\u02d84 <<1s\ufffd\ufffd|\ufffd>22n{t1{~ r2\n43143<32 4;9573651534 71=<696 :\n4<1 _twwtky\ufffd N\\W. TmT\ufffd~~k\ufffd QZ.R\ufffd~\ufffd \\.Skylo~\ufffd LN1Uo\ufffd\ufffd{~ vkzkw\ufffd\ufffdt\ufffd ~o\ufffdokw\ufffd {|oz q{~\ufffdy\ufffd kznoms{\nmskylo~\ufffd tz\ufffd{mtkw yontk nt\ufffdm\ufffd\ufffd\ufffdt {z\ufffd{qmwtyk\ufffdo mskzro1 Mw{lkw Kz\ufffdt~{zyoz\ufffd kwIskzro1 5349? 65>45:\u02d8\n46<1 s\ufffd\ufffd|\ufffd>22n{ t1{~r2431434: 2u1rw{oz\ufffdmsk 15349136 133:\n4=1 I{z{\ufffdo~ TJ. M{zm \ufffdkw\ufffdo\ufffd G.Lwkyytzt F.Tozm\ufffdo ~L1Wk~\ufffdt\ufffdkz k\ufffd\ufffdyyo\ufffd~ to\ufffdtz{zwtzo |{wt\ufffdtmkw km\ufffdt\ufffdt\ufffd\ufffd 1\nKWQ Jk\ufffdk [mtozmo1 5345? 4*4+>:1 s\ufffd\ufffd|\ufffd>22n{t1{ ~r243144732o| un\ufffd:\n531 I{z{\ufffdo~ T.Zk\ufffdvto\ufffdtm\ufffd Q.L~kzmt\ufffdm {T.M{zm \ufffdkw\ufffdo\ufffd G.Tozm\ufffdo ~L.Lwkyytzt F1W{wt\ufffdtmkw W{wk~t\ufffdk\ufffdt{z {z\n\\\ufffdt\ufffd\ufffdo~1 Oz>Oz\ufffdo~zk \ufffdt{zkw FFFO I{zqo~ozmo {z_ol kzn[{mtkw Tontk? 53441 |1<=\u02d8=:1 F\ufffdktwklwo q~{y>\ns\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1kkkt1{~r2{m \ufffd2tzno\ufffd1|s| 2OI_[T2OI _[T442|k |o~2\ufffdto\ufffd25< 7;1\n541 _oov\ufffd GK.Skzo J[.Rty JN. Soo[[.R\ufffdkv U1Ozmtnoz\ufffdkw K\ufffd|{\ufffd\ufffd~o .[owom\ufffdt\ufffdo K\ufffd|{\ufffd\ufffd~o .kznW{wt\ufffdtmk w\nOzq{~yk\ufffdt{ z[sk~tzr> Oz\ufffdor~k\ufffdtzr Vzwtzo K\ufffd|{\ufffd\ufffd~o Wk\ufffd\ufffdo~z\ufffd kznK\ufffd|~o\ufffd\ufffdt{ z{z[{mtkw Tontk1 Q{\ufffd~zkw {q\nI{y|\ufffd\ufffdo~/ Tontk\ufffdon I{yy\ufffdztm k\ufffdt{z1 534;? 55*:+>6:6\u02d8 6;=1 s\ufffd\ufffd|\ufffd>22n{t1{~ r24314444 2umm71454==\n551 Is{t Q.SooQR1Oz\ufffdo\ufffd\ufffdtrk\ufffdtzr \ufffdsooqqom\ufffd\ufffd {qzo\ufffd\ufffd \ufffdsk~tzr kzn|{wt\ufffdtmkw tz\ufffdo~o\ufffd\ufffd {z\ufffd{mtkw yontk zo\ufffd\ufffd{~v\nso\ufffdo~{rozot \ufffd\ufffd1I{y|\ufffd\ufffdo~\ufffd tzN\ufffdyk zGosk\ufffdt{~1 5349? 77>59<\u02d8 5::1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434 :2u1msl1534 71\n44135=\n561 Gkv\ufffds\ufffd K.To\ufffd\ufffdtzr [.Fnkytm S1K\ufffd|{\ufffd\ufffd~o \ufffd{tno{w{rtmk ww\ufffdnt\ufffdo~\ufffdo zo\ufffd\ufffd kzn{|tzt{z {zLkmol{{v1 [mt/\nozmo1 53491 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431445 :2\ufffdmtozmo1kkk 44:3 WTOJ> 59=96<53\n571 Fnkytm SF.Mwkzmo U1\\so W{wt\ufffdtmkw Gw{r{\ufffd| so~o kzn\ufffdso5337 ]1[1 Kwom\ufffdt{z> Jt\ufffdtnon \\so\ufffd Gw{r1 Oz>\nW~{moontzr\ufffd {q\ufffdso6~nOz\ufffdo~zk\ufffdt{zkw _{~v\ufffds{| {zStzv Jt\ufffdm{\ufffdo~\ufffd 1StzvRJJ)391 FIT? 53391 |16:\u02d8761\nF\ufffdktwklwo q~{y> s\ufffd\ufffd|>22n{t1k my1{~r24314 4792446 75;4144675;; 1\n591 [\ufffdz\ufffd\ufffdotz IZ1 Zo|\ufffdlwtm1m{y 5131W~tzmo\ufffd{ z]zt\ufffdo~\ufffdt\ufffd\ufffd W~o\ufffd\ufffd? 533;1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|>22\ufffd\ufffd\ufffd1 u\ufffd\ufffd{~1{~r2\n\ufffd\ufffdklwo2u1m\ufffd\ufffd; \ufffdl\ufffd\ufffd1\n5:1 V)Uotww [Q.N\ufffdwyo T1Fztm{ztm k||~{kms q{~~o|~o\ufffdoz\ufffd tzrmwtyk\ufffdo mskzro1 Mw{lkw Kz\ufffdt~{zy oz\ufffdkw\nIskzro1 533=? 4=*7+>735\u02d8 7431 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434:2u1 rw{oz\ufffdmsk 1533=13;1337\n5;1 Jow^tmk~t{ T.Go\ufffd\ufffdt F.c{ww{ L.Wo\ufffd~{zt L.[mkwk F.Ikwnk~owwt M.o\ufffdkw1\\so \ufffd|~okntzr {qyt\ufffdtzq{~yk\ufffd t{z\n{zwtzo1 W~{moontzr\ufffd {q\ufffdsoUk\ufffdt{zkw Fmknoy\ufffd {q[mtozmo\ufffd1 534:? 446*6+>997 \u02d899=1 s\ufffd\ufffd|\ufffd>22n{t1 {~r2431\n43;62|zk\ufffd 1494;774446\n5<1 Qk\ufffdz\ufffd S._krrwo Q.Lt\ufffdso~ JZ1 Fzoy|t~tmkw o\ufffdkytzk\ufffd t{z{qoms{ mskylo~\ufffd tz][mwtyk\ufffdo |{wtm\ufffd zo\ufffd/\n\ufffd{~v\ufffd1 Uk\ufffd\ufffd~o Iwtyk\ufffdo Iskzro1 5349? 9>;<5\u02d8; <:1s\ufffd\ufffd|\ufffd>22n{t1{~ r2431436 <2zmwtyk\ufffdo5 :::\n5=1 Nk\u00c6\ufffd\ufffd\ufffdwo~ \\1Nok\ufffdtzr \ufffd|\ufffdsonolk\ufffdoD Tok\ufffd\ufffd~tz rq~kryoz\ufffdk \ufffdt{zkzn|{wk~t\ufffdk\ufffdt{z tzkMo~ykz mwtyk\ufffdo\nmskzro s\ufffd|o~wtzv zo\ufffd\ufffd{~v1 [{mtkw Uo\ufffd\ufffd{~ v\ufffd1534<? 97>636\u02d86461 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434:2u1 \ufffd{mzo\ufffd1534; 1\n431335\n631 Jow^tmk~t{ T.[mkwk F.Ikwnk~o wwtM.[\ufffdkzwo\ufffd NK.Y\ufffdk\ufffd\ufffd~{mt{m mst_1T{nowtz rm{zqt~yk\ufffdt{ zltk\ufffd kzn\n|{wk~t\ufffdk\ufffdt{z1 [mtoz\ufffdtqt mZo|{~\ufffd\ufffd1 534;? ;*4+>736=4 1s\ufffd\ufffd|\ufffd>22n{t1{~ r2431436 <2\ufffd~o|736=4 WTOJ> 5<3;7<;7\n641 Uo\ufffdykz \\W1\\~kmvtzr \ufffdso~owok\ufffdo {qOWII FZ9 {z\\\ufffdt\ufffd\ufffdo~> ]\ufffdo~\ufffd. m{yyoz\ufffd\ufffd .kzn\ufffd{\ufffd~mo\ufffd q{ww{\ufffdtzr\n\ufffdso~owok\ufffdo {q\ufffdso_{~vtzr M~{\ufffd| O[\ufffdyyk~\ufffd q{~W{wtm\ufffdykv o~\ufffd1W\ufffdlwtm ]zno~\ufffd\ufffdkzn tzr{q[mtozmo1 534;?\n5:*;+><49\u02d8 <591 s\ufffd\ufffd|\ufffd>22 n{t1{~r243144 ;;23=:6: :594::5<7;; WTOJ> 5:<:<35 9\n651 Rt~twozv{ FW.[\ufffdo|msoz v{\ufffdk [V1 W\ufffdlwtm ytm~{lw{r rtzr {zmwtyk\ufffdo mskzro> Vzo \ufffdok~ {q\\\ufffdt\ufffd\ufffdo~ \ufffd{~wn/\n\ufffdtno1 Mw{lkw Kz\ufffdt~{ zyoz\ufffdkw Iskzro1 5347? 5:>4;4\u02d84<51 s\ufffd\ufffd|\ufffd>22n{t1 {~r2431434:2u 1rw{oz\ufffdmsk 15347135 1\n33<\n661 Qkzr [T. Nk~\ufffd W[1W{wk~t\ufffdon q~kyo\ufffd {z\ufffdmwtyk\ufffdo mskzro\ufffd kzn\ufffdrw{lkw \ufffdk~ytzr\ufffd km~{\ufffd\ufffd m{\ufffdz\ufffd~to \ufffdkzn\n\ufffd\ufffdk\ufffdo\ufffd> K\ufffdtnozmo q~{y \\\ufffdt\ufffd\ufffdo ~ltrnk\ufffdk1 Mw{lkw Kz\ufffdt~{ zyoz\ufffdkw Iskzro1 5349? 65>44\u02d84;1 s\ufffd\ufffd|\ufffd>22n{t1{~ r2\n431434:2 u1rw{oz\ufffdms k153491351343\n671 V)Uotww [._twwtky\ufffd N\\W. R\ufffd~\ufffd \\._to~\ufffdyk G.G{\ufffdv{qq T1J{ytzkz\ufffd q~kyo\ufffd tzworkm\ufffd kzn\ufffd{mtkw yontk\nm{\ufffdo~kro {q\ufffdsoOWII Ltq\ufffds F\ufffd\ufffdo\ufffd\ufffdyo z\ufffdZo|{~\ufffd1 Uk\ufffd\ufffd~o Iwtyk\ufffd oIskzro1 5349? 91\n691 [ms\ufffdwn\ufffd QW.R{z~k\ufffds [N.[ms\ufffdk~\ufffd U1\ufffdMw{lkw \ufffdk~ytzr\ufffd {~\ufffdmwtyk\ufffdo mskzro\ufffd D_so\ufffdso~ \ufffdso|wkzo\ufffd t\ufffd\n\ufffdk~ytzr no|ozn\ufffd {z}\ufffdo\ufffd\ufffdt{z \ufffd{~ntzr 1W\ufffdlwtm V|tzt{z Y\ufffdk~\ufffdo~w\ufffd1 5344? ;9*4+>449\u02d8 4571 s\ufffd\ufffd|\ufffd>22n{t1{~ r2\n43143=62 |{}2zq}3;6\n6:1 Lk~~oww Q1Uo\ufffd\ufffd{~ v\ufffd\ufffd~\ufffdm\ufffd\ufffd~o kzntzqw\ufffdozmo {q\ufffdsomwtyk\ufffdo mskzro m{\ufffdz\ufffdo~/y {\ufffdoyoz\ufffd1 Uk\ufffd\ufffd~o Iwtyk\ufffdo\nIskzro1 534:? :*7+>6;3\u02d86 ;71s\ufffd\ufffd|\ufffd>2 2n{t1{~r243143 6<2zmwtyk\ufffdo 5<;9\n6;1 L~oow{z J.Tk~\ufffdtmv F.R~ot\ufffd\ufffd J1Lkw\ufffdo o}\ufffdt\ufffdkwo zmto\ufffd> Vzwtzo km\ufffdt\ufffdt\ufffdy q~{y woq\ufffd\ufffd{~trs\ufffd1 [mtozmo1 5353?\n6:=*:93<+ >44=;\u02d845341 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431445:2 \ufffdmtozmo1kll5 75<WTOJ> 65<<6< :6\n6<1 [\ufffdk~lt~n R1K\ufffdkytztzr \ufffdsoFw\ufffdo~zk\ufffdt\ufffdo Tontk Km{\ufffd\ufffd \ufffd\ufffdoy \\s~{\ufffdrs \ufffdsoW~{n\ufffdm\ufffdt{z {qFw\ufffdo~zk\ufffd t\ufffdoUk~~k/\n\ufffdt\ufffdo\ufffd {qTk\ufffd\ufffd [s{{\ufffdtzr K\ufffdoz\ufffd\ufffd {z\\\ufffdt\ufffd\ufffdo~1 Oz>Oz\ufffdo~zk \ufffdt{zkw FFFO I{zqo~ozm o{z_ol kzn [{mtkw\nTontk? 534;1 |1563\u02d856= 1F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22kkk t1{~r2{m\ufffd2tz no\ufffd1|s|2O I_[T2OI_[ T4;2|k|o~2\n\ufffdto\ufffd249: 361\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 57259\n6=1 F~tqF.[skzkskz R.Is{\ufffd LQ.J{\ufffd{\ufffd \ufffd{b.[\ufffdk~lt~n R.[|t~{ K[1N{\ufffd Ozq{~yk\ufffdt{ z[z{\ufffdlkw w\ufffd>K\ufffd|w{~tzr\n\ufffdsoZ{wo {qK\ufffd|{\ufffd\ufffd~o tzVzwtzo Z\ufffdy{~ W~{|krk\ufffdt{ z1Oz>W~{moontzr\ufffd {q\ufffdso4=\ufffds FIT I{zqo~oz mo{z\nI{y|\ufffd\ufffdo~/ [\ufffd||{~\ufffdon I{{|o~k \ufffdt\ufffdo_{~v \u2019[{mtkw I{y|\ufffd\ufffdtzr? 534:1 |17::\u02d87;;1 F\ufffdktwkl woq~{y> s\ufffd\ufffd|>22\nn{t1kmy1{~r 24314479 25<4<37<15<4= =:71\n731 [msytn\ufffd FS.c{ww{ L.Jow^tmk~t{ T.Go\ufffd\ufffdt F.[mkwk F.Ikwnk~owwt M.o\ufffdkw1Fzk\ufffd{y\ufffd {qzo\ufffd\ufffd m{z\ufffd\ufffdy |\ufffdt{z\n{zLkmol{{v1 W~{moo ntzr\ufffd {q\ufffdsoUk\ufffdt{zkw Fmknoy\ufffd {q[mtozmo\ufffd1 534;? 447*45+>63 69\u02d8636=1 s\ufffd\ufffd|\ufffd>22\nn{t1{~r243143 ;62|zk\ufffd14: 4;395447 WTOJ> 5<5:93<5\n741 _twwtky\ufffd T.It{~{tkz\ufffd O._twwtky\ufffd N1Jtqqo~oz\ufffd Uo\ufffd\ufffd q{~Jtqqo~oz\ufffd ^to\ufffd\ufffd> W{wt\ufffdtmk wUo\ufffd\ufffd/[ sk~tzr I{yy\ufffd/\nzt\ufffdto\ufffd {z[{mtkw Tontk \\s~{\ufffdrs \ufffdso]RMozo~kw Kwom\ufffdt{z tz53491 Oz>Oz\ufffdo~zk\ufffdt{zkw FFFO I{zqo~oz mo{z\n_ol kzn[{mtkw Tontk? 534:1 |144<\u02d84591 F\ufffdktwkl woq~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1kkkt1{~r2{ m\ufffd2tzno\ufffd1|s|2OI _[T2\nOI_[T 4:2|k|o~2\ufffdto\ufffd 246565245<9 31\n751 \\\ufffdt\ufffd\ufffdo~ [\ufffd~okytzr FWOn{m\ufffdyoz\ufffd k\ufffdt{z?1 s\ufffd\ufffd|\ufffd>22no\ufffd ow{|o~1\ufffd\ufffdt\ufffd \ufffdo~1m{y2oz2n{ m\ufffd2\ufffd\ufffdoo\ufffd\ufffd2q tw\ufffdo~/~okw\ufffdty o2k|t/\n~oqo~ozmo2 |{\ufffd\ufffd/\ufffd\ufffdk\ufffd\ufffd\ufffdo\ufffd/ qtw\ufffdo~1 Fmmo\ufffd\ufffdo n>3<236253 531\n761 Uo\ufffdykz TKQ1 [mtoz\ufffdtqtm m{wwkl{~ k\ufffdt{z zo\ufffd\ufffd{~v\ufffd1 OO1[s{~\ufffdo\ufffd\ufffd |k\ufffds\ufffd. \ufffdotrs\ufffdon zo\ufffd\ufffd{~v\ufffd. kznmoz\ufffd~kwt\ufffd\ufffd1\nWs\ufffd\ufffd Zo\ufffd K15334? :7>34:4651 s\ufffd\ufffd|\ufffd>22n{t1{~ r243144362 Ws\ufffd\ufffdZo\ufffdK1:71 34:465 WTOJ> 447:469:\n771 Ikzz \\QG. _ok\ufffdo~ O[._twwtky\ufffd N\\W1 O\ufffdt\ufffdm{~~om\ufffd \ufffd{|~{uom\ufffd kznno\ufffdom\ufffdD N{\ufffd \ufffdotrs\ufffdtzr \ufffdzt|k~\ufffdt\ufffdo |~{uom/\n\ufffdt{z\ufffd tzqw\ufffdoz mo\ufffdm{yy\ufffd zt\ufffd\ufffdno\ufffdom\ufffdt{z1 Uo\ufffd\ufffd{~v [mtozmo1 5353? |14\u02d84=1 s\ufffd\ufffd|\ufffd>22 n{t1{~r243143 4;2z\ufffd\ufffd1\n5353144\n791 Uo\ufffdykz TKQ. Mt~\ufffdkz T1Ltzntzr kzno\ufffdkw\ufffdk\ufffdtzr m{yy\ufffd zt\ufffd\ufffd\ufffd\ufffd~\ufffdm\ufffd\ufffd~o tzzo\ufffd\ufffd{~v\ufffd1 Ws\ufffd\ufffd Zo\ufffd K15337?\n:=1s\ufffd\ufffd|\ufffd>22n{t1 {~r243144362W s\ufffd\ufffdZo\ufffdK 1:=13::466 WTOJ> 47==995:\n7:1 Iwk\ufffd\ufffdo\ufffd F.Uo\ufffdykz TKQ. T{{~o I1Ltzntzr m{yy\ufffd zt\ufffd\ufffd\ufffd\ufffd~\ufffdm\ufffd\ufffd~o tz\ufffdo~\ufffd wk~ro zo\ufffd\ufffd{~v\ufffd 1Ws\ufffd\ufffd Zo\ufffd K1\n5337? ;3>3::4 441s\ufffd\ufffd|\ufffd>22n{t1{~ r2431443 62Ws\ufffd\ufffdZo\ufffd K1;313::444 WTOJ> 49:=;7 6<\n7;1 Jtqql{\ufffd Fzkw\ufffd\ufffdo FWOno\ufffdow{|o~ n{m\ufffdyoz\ufffdk\ufffdt {z?1s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1ntqql{\ufffd1m{y2 no\ufffd2n{m\ufffd2kzkw \ufffd\ufffdo21 Fmmo\ufffd\ufffdo n>\n534</39/5 61\n7<1 W{~\ufffdo~ TL1 Fzkwr{~t\ufffdsy q{~\ufffd\ufffdqqt\ufffd \ufffd\ufffd~t||tzr1 W~{r~ky >owom\ufffd~{ztm wtl~k~\ufffd kzntzq{~yk\ufffdt {z\ufffd\ufffd\ufffd\ufffdoy\ufffd1 4=<3?\n47*6+>463\u02d8 46;1 s\ufffd\ufffd|\ufffd>22 n{t1{~r243144 3<2ol37: <47\n7=1 Tontk Gtk\ufffd2Lkm\ufffd Isomv?1 s\ufffd\ufffd|\ufffd>22 yontkltk\ufffd qkm\ufffdmsomv1m{y2 1Fmmo\ufffd\ufffdon> 534</3;/3 :1\n931 Qkm{y\ufffd T.^oz\ufffd\ufffd~tzt \\.No\ufffdykz z[.Gk\ufffd\ufffdtkz T1L{~moF\ufffdw k\ufffd5. kI{z\ufffdtz\ufffd{\ufffd \ufffdM~k|s Sk\ufffd{\ufffd\ufffd Fwr{~t\ufffdsy q{~\nNkzn\ufffd Uo\ufffd\ufffd{~v ^t\ufffd\ufffdkwt\ufffdk\ufffdt{z Jo\ufffdtrzon q{~\ufffdsoMo|st [{q\ufffd\ufffdk~o1 WSV[ VUK1 5347? =*:+>4\u02d8451 s\ufffd\ufffd|\ufffd>22\nn{t1{~r243146 ;42u{\ufffd~zkw1| {zo133=<:;= WTOJ> 57=47:;<\n941 Lownykz S.Tktlkms K_. Z{\ufffdo~/Z oz{\ufffdq I.Sot\ufffdo~{\ufffdt\ufffd \ufffdF1Iwtyk\ufffdo {zIklwo> \\so Uk\ufffd\ufffd~o kznOy|km\ufffd {q\nMw{lkw _k~ytzr I{\ufffdo~kro {zL{\ufffdUo\ufffd\ufffd. IUU. kznT[UGI1 \\so Oz\ufffdo~zk\ufffdt{zkw Q{\ufffd~zkw {qW~o\ufffd\ufffd2W{wt/\n\ufffdtm\ufffd1 5345? 4;*4+>6\u02d864 1s\ufffd\ufffd|\ufffd>22 n{t1{~r243144 ;;24=73 4:454475974 3\n951 N{~z\ufffdo\ufffd TQ.Nk~~t\ufffd KF.Ltowntzr R[1Zowk\ufffdt{z\ufffdst |\ufffdky{zr m{z\ufffd|t~k\ufffd{ ~tkwlowtoq\ufffd. m{z\ufffdo~\ufffdk\ufffdt\ufffd ykznmwt/\nyk\ufffdo \ufffdmo|\ufffdtmt\ufffdy km~{\ufffd\ufffd zk\ufffdt{z\ufffd1 Uk\ufffd\ufffd~o Iwtyk\ufffdo Iskzro1 534<? <*;+>:47\u02d8: 531s\ufffd\ufffd|\ufffd>22n{t1{~ r2431436< 2\n\ufffd7499</34< /349;/5\n961 Sk\ufffdk|\ufffd T1Tktz/yoy {~\ufffd\ufffd~tkzrwo m{y|\ufffd\ufffdk\ufffdt{z \ufffdq{~\ufffdo~\ufffd wk~ro *\ufffd|k~\ufffdo *|{\ufffdo~/wk\ufffd ++r~k|s\ufffd1 \\so{~o\ufffdtm kw\nI{y|\ufffd\ufffdo~ [mtozmo1 533<? 73;*4+>79< \u02d87;61 s\ufffd\ufffd|\ufffd>22n{t1{~ r2431434:2 u1\ufffdm\ufffd1533<13;13 4;\n971 I{wwo{zt K.Z{\ufffd\ufffdk F.F~\ufffdtn\ufffd\ufffd{z F1Kms{ Iskylo ~{~W\ufffdlwtm [|so~oD W~ontm\ufffd tzrW{wt\ufffdtmkw V~toz\ufffdk\ufffdt{z kzn\nTok\ufffd\ufffd~tz rW{wt\ufffdtmkw N{y{|stw\ufffd tz\\\ufffdt\ufffd\ufffdo ~]\ufffdtzr GtrJk\ufffdk1 Q{\ufffd~zkw {qI{yy\ufffdz tmk\ufffdt{z1 5347? :7*5+>64;\u02d8\n6651 s\ufffd\ufffd|\ufffd>22n{ t1{~r24314444 2um{y1453<7\n991 [sok~o~ K.Tk\ufffd\ufffdk RK1Uo\ufffd\ufffd ]\ufffdo Fm~{\ufffd\ufffd [{mtkw Tontk Wwk\ufffdq{~y\ufffd 534<1 Wo\ufffd Zo\ufffdok~ms Ioz\ufffdo~? 534<1\nF\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\ufffd\ufffd\ufffd 1u{\ufffd~zkwt\ufffdy 1{~r2534<23=24 32zo\ufffd\ufffd /\ufffd\ufffdo/km~{\ufffd\ufffd /\ufffd{mtkw/yo ntk/|wk\ufffdq{~y\ufffd/ 534<2\n1\n9:1 Rk\ufffd\ufffd K.Sk\ufffdk~\ufffdqown WL1Wo~\ufffd{zkw tzqw\ufffdozmo> \ufffdso|k~\ufffd |wk\ufffdon l\ufffd|o{|wo tz\ufffdsoqw{\ufffd {qyk\ufffd\ufffd m{yy\ufffdztm k/\n\ufffdt{z\ufffd1 Uo\ufffd b{~v. Ub.][> L~oo W~o\ufffd\ufffd? 4=991\n9;1 _{umtv [.N\ufffdrso\ufffd F1[t\ufffdtzr ]|\\\ufffdt\ufffd\ufffdo~ ]\ufffdo~\ufffd1 Wo\ufffd Zo\ufffdok~ms Ioz\ufffdo~? 534=1 F\ufffdktwklwo q~{y> s\ufffd\ufffd|\ufffd>22\n\ufffd\ufffd\ufffd1|o\ufffd ~o\ufffdok~ms1{~r2t z\ufffdo~zo\ufffd 2534=2372572 \ufffdt\ufffdtzr/\ufffd|/\ufffd\ufffd t\ufffd\ufffdo~/\ufffd\ufffdo~\ufffd21\nPLOS ONEOno{w{rtm kwltk\ufffdo\ufffd tz\ufffd{mtkw \ufffdsk~tzr {q{zwtzo tzq{~yk\ufffdt {zkl{\ufffd\ufffd mwtyk\ufffdo mskzro\nWSV[ VUK \ufffds\ufffd\ufffd|\ufffd>22n{t1{~ r243146; 42u{\ufffd~zkw1|{ zo13593: 9: F|~tw 56.5354 59259", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Ideological biases in social sharing of online information about climate change", "author": ["TJB Cann", "IS Weaver", "HTP Williams"], "pub_year": "2021", "venue": "Plos one", "abstract": "Exposure to media content is an important component of opinion formation around climate  change. Online social media such as Twitter, the focus of this study, provide an avenue to"}, "filled": false, "gsrank": 658, "pub_url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0250656", "author_id": ["TtllgDgAAAAJ", "Vtgh0DgAAAAJ", "vARIotQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:nssB-RHxaa0J:scholar.google.com/&output=cite&scirp=657&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D650%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=nssB-RHxaa0J&ei=e7WsaLT2OY6IieoP0sKRuAk&json=", "num_citations": 45, "citedby_url": "/scholar?cites=12495783700610534302&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:nssB-RHxaa0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0250656&type=printable"}}]