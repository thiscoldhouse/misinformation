[{"title": "A calibrated measure to compare fluctuations of different entities across timescales", "year": "2020", "pdf_data": "1\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreportsA calibrated measure to compare \nfluctuations of different entities \nacross timescales\nJan Cho\u0142oniewski1, Julian Sienkiewicz1, Naum Dretnik2, Gregor Leban3, Mike Thelwall4 & \nJanusz A. Ho\u0142yst1,5*\nA common way to learn about a system\u2019s properties is to analyze temporal fluctuations in associated \nvariables. However, conclusions based on fluctuations from a single entity can be misleading when used without proper reference to other comparable entities or when examined only on one timescale. \nHere we introduce a method that uses predictions from a fluctuation scaling law as a benchmark \nfor the observed standard deviations. Differences from the benchmark (residuals) are aggregated across multiple timescales using Principal Component Analysis to reduce data dimensionality. The first component score is a calibrated measure of fluctuations\u2014the reactivity RA of a given entity. We \napply our method to activity records from the media industry using data from the Event Registry news aggregator\u2014over 32M articles on selected topics published by over 8000 news outlets. Our approach distinguishes between different news outlet reporting styles: high reactivity points to activity fluctuations larger than expected, reflecting a bursty reporting style, whereas low reactivity suggests a relatively stable reporting style. Combining our method with the political bias detector Media Bias/\nFact Check we quantify the relative reporting styles for different topics of mainly US media sources \ngrouped by political orientation. The results suggest that news outlets with a liberal bias tended to be the least reactive while conservative news outlets were the most reactive.\nFluctuations occur everywhere and are frequently sources of useful knowledge about intrinsic properties of \nsystems, with diverse applications. When thermal  activity\n1 or heart rate variability are  measured2, they can give \nmeaningful information if system-specific features are taken into account, such as the fluctuation\u2013dissipation  theorem\n3, or norms for heart rate variability in various groups of  people2,4. In financial engineering, forecast-\ning the volatility of stock  prices5,6 is central to hedging strategies for stock  portfolios7. There are multiple ways \nto quantify fluctuation levels, including the variance (or standard deviation), Fano  factor8, and coefficient of \n variation9. Nevertheless, studying just absolute (variance) or relative (Fano factor) fluctuations can give mislead-\ning conclusions when the system\u2019s size is ignored. For example, the variance \u03c32\nE of energy thermal fluctuations \nshould be proportional to the number of particles in a  system3 while for many non-thermal objects the variance \nin an ensemble of similar units (e.g. crop volumes in groups of fields) scales with the system size in agreement with Taylor\u2019s  law\n10. For time-dependent systems the rescaled range of an observable can depend on the length of \nthe observation window /Delta1 according to Hurst\u2019s  law11. In many cases time series fluctuation patterns can change \nwith amplitude levels and in these systems generalized Hurst exponents should be calculated with Multifractal Detrended Fluctutions  Analysis\n6,12.\nIn this study we introduce the notion of reactivity  (RA), which is related to the residuals of the temporal \nfluctuation scaling law (or the temporal Taylor power law; TFS)13,14 that links the mean and the variance of \na dynamical process for each observed entity through a power law. In this context, by a residual we mean the measured standard deviation of an observed system variable (henceforth called activity ) calibrated against values \nexpected from the TFS at a given timescale. The TFS is ubiquitous in complex  systems\n15. Analyses of the fitted \npower law exponent have been applied e.g. to measure the lexical richness of texts in the presence of topical  variations\n16, to characterize UK  crime17 and human behavior under high  pressure18, and to detect strong emo-\ntions in physiological  timeseries19.OPEN\n1Center of Excellence for Complex Systems Research, Faculty of Physics, Warsaw University of Technology, \nKoszykowa 75, 00-662 Warsaw, Poland. 2Slovenian Press Agency, Tivolska 48, 1000 Ljubljana, Slovenia. 3Artificial \nIntelligence Laboratory, Jo\u017eef Stefan Institute, Jamova 39, 1000 Ljubljana, Slovenia. 4School of Mathematics and \nComputing, University of Wolverhampton, Wulfruna Street, Wolverhampton WV1 1L Y, UK. 5ITMO University, 49 \nKronverkskiy av., Saint Petersburg, Russia 197101. *email: janusz.holyst@pw.edu.pl\n2\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/Differences between entities in the above-mentioned datasets may cause them not to follow the TFS strictly. \nAlthough fluctuation scaling residuals cluster in geographical and financial  data15, properties of residuals seem \nto have been rarely studied. One somewhat similar application of the TFS is date abnormality quantification by \nmeasuring the fluctuation scaling of adjective usage in Japanese  blogs22 but this focused on detecting special \ndates rather than quantifying activity fluctuations.\nThe concept of reactivity will be applied to data from the Event Registry news  aggregator23, containing over \n32M articles on 39 topics (we will also call them keywords  or concepts , interchangeably) published by over 8000 \nnews outlets (also sources , publishers ). Understanding media activity is a challenge because of the need to take \ninto account differences in size, scope and political bias, as well as differences in reporting styles by topic and \nmultiple timescales. Due to the complex nature of online news media (many interacting units participating in \ndynamic information exchanges), it is unsurprising that the activity of news outlets, measured by the number \nof articles published over time, follows the  TFS24.\nIn the paper, we study fluctuations in news outlet activities f(t)\ns,\ufffd(k) , focusing on multiple topics k  (e.g. Cli -\nmate change  or European Union ) and timescales /Delta1 (from a few minutes to a few months). We found that the \nTFS residual value Rs,\ufffd(k) for a given news outlet s  is more characteristic of a timescale /Delta1 than of a topic k . To \naggregate properties of fluctuations at different timescales, for each concept k we considered the 14-dimensional space corresponding to corrections to TFS for \n\ufffd\u2208/braceleftbig\n1 min, ..., 60 days/bracerightbig\n and performed Principal Component \nAnalysis to reduce the dimensionality of the data set. The first component score is our calibrated measure of fluctuations: the reactivity  \nRAs(k) of publisher s  when reporting a topic k , see Eq.\u00a0(3 ). A negative reactivity means \nsmaller-than-typical fluctuations, and a positive reactivity means larger-than-typical fluctuations. We found that the median reactivity of news outlets from a given country was high if significant happenings related to a topic had taken place during the period analyzed. Additionally, we considered news outlet reactivity by political bias provided by media  biasf  actch  eck.com . Analyses showed that news outlets with a liberal bias were, on average, \nless reactive while conservative news outlets were more reactive.\nWe use a pipeline of multiple theoretical approaches. The simplified scheme in Fig.\u00a0 1 summarizes the funda-\nmental concepts of this study for later reference.\nResults\nOur reactivity method is described with news publishing data from the Event Registry (ER)  dataset23. We \nextracted all articles published in 2018 mentioning one of K topics ( K=|K|=39 , for details see Dataset \ninfo subsection of Methods). We divided the news articles into sets corresponding to topics K and publishers \nS ( |S|=8155  ), obtaining a list of article publication dates and times fs(k)={ \u03c4s,1(k),\u03c4s,2(k),...} for each \nkeyword k and publisher s .\nThe activity timeseries f(t)\ns,\ufffd(k) were obtained by aggregating a list of article publication occurrences with \ntimestamps using D=14 time window sizes \ufffd\u2208{1 min, ..., 60 days } for each of the 39 keywords separately \n(see Extracting timeseries from lists of articles subsection of Methods: Statistical Methods). Figure\u00a0 1 visualizes \nthe whole process for 1 keyword, 2 publishers and 3 time windows. This is shown in the left column. Next, the timeseries were processed using the TFS procedure (see Temporal fluctuation scaling subsection of Methods: Statistical Methods) to obtain the scaling exponent \n\u03b1\ufffd(k) and the multiplicative factor B\ufffd(k) . An example TFS \nplot is in Fig.\u00a0 2, corresponding to the middle column of Fig.\u00a0 1. We then calculated TFS residuals Rs,\ufffd(k) for each \nkeyword k and each relevant combination of publisher s  and time window size /Delta1 as a logarithm of a ratio of \nobserved source\u2019s activity standard deviation \u03c3s,\ufffd(k) and an expected source\u2019s activity standard deviation \u02dc\u03c3s,\ufffd(k) . \nThe last value results from the mean activity \u00b5s,\ufffd(k)=/angbracketleftBig\nf(t)\ns,\ufffd/angbracketrightBig\n and the TFS law, i.e.\nFor each concept k  we then have a S\u00d7D-dimensional matrix \u02c6R(k) containing TFS residuals Rs,\ufffd(k) , i.e., logarith -\nmic differences between observed activity fluctuations of a publisher s  in a given timescale /Delta1 and corresponding \npredictions resulting from the TFS scaling law that contains information about the magnitudes of fluctuations of other publishers.\nThe residuals \nRs,\ufffd(k) are shown as red segments in the middle column of Fig.\u00a0 1 and corresponding cells in \nmatrix \u02c6R in the middle panel of the right column in the same plot.\nCorrelations of residuals across timescales and concepts. Let us now investigate whether the TFS \nresiduals are similar for a given publisher across all concepts k and time window sizes /Delta1 . For this, we calcu-\nlate the Pearson correlation between residual values obtained for every pair of (k ,\ufffd) combinations, a total of \nN=K\u00d7D=546 combinations. The aggregation was performed over all sources publishing on both topics\u2014\nsee the Agglomerative Clustering of correlation matrices subsection of Methods for details.\nFigure\u00a0 3 gives a 546\u00d7546 matrix of correlations \u03c1(k1,\ufffd1;k2,\ufffd2) between all possible combinations of \n(k ,\ufffd) . Each row/column stands for one concept-time window size combination. The columns/rows were clus -\ntered using Agglomerative Clustering and their order is from the leaves of the resulting dendrogram. The most striking observation is that around 92% of the elements of this matrix are positive valued and the mean value of off-diagonal elements is 0.26. Moreover, the residuals separate roughly into three groups connected to different timescales\u2014\n/Delta1\u22641h (short ), 1h<\ufffd\u22641 day  (medium ), \ufffd> 1 day  (long). Moreover, inside the groups residuals \nfor a keyword also tend to be adjacent\u2014to see this, compare the sizes of the color clusters and the size of the thin-nest color marker. To further quantify this observation, we calculated the means of in-group and between-group correlation matrix elements for the groups (see Supplementary Information: Aggregated correlation matrices). (1)\nRs,\ufffd=log10/bracketleftbigg\u03c3s,\ufffd\n\u02dc\u03c3s,\ufffd/bracketrightbigg\n, where \u02dc\u03c3s,\ufffd=B\ufffd/angbracketleftBig\nf(t)\ns,\ufffd/angbracketrightBig\u03b1\ufffd\n3\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/ce BSour ce CSour ce D\nSour ce E\nSour ce FSour ce GSour ce H\nSour ce I\nSour ce J\n02040\n02 55 07 5 100\ntimeactivitySource A: \u2206= 20\n02040\n02 55 07 5 100\ntimeactivitySource B: \u2206= 20R20(A)\n0.40.81.21.6\n1.5 1.6 1.7 1.81 .9 2.0\nlog10(\u00b5)log10(\u03c3)Taylor scaling and residuals: \u2206=20\n02040\n02 55 07 5 100\ntimeactivitySource A: \u2206= 10\n02040\n02 55 07 5 100\ntimeactivitySource B: \u2206= 10R10(B)\n0.751.001.25\n1.2 1.3 1.4 1.51 .6 1.7\nlog10(\u00b5)log10(\u03c3)Taylor scaling and residuals: \u2206=10\n02040\n02 55 07 5 100\ntimeactivitySource A: \u2206= 5\n02040\n02 55 07 5 100\ntimeactivitySource B: \u2206= 5\n0.60.81.01.2\n0.9 1.0 1.1 1.21 .3 1.4\nlog10(\u00b5)log10(\u03c3)Taylor scaling and residuals: \u2206=5PC1P C2PC3\nSource JSource ISource HSource GSource FSource ESource DSource CSource BSource A\n0.00.5\n=\nR20R10 R5\nSource JSource ISource HSource GSource FSource ESource DSource CSource BSource A\n\u22120.250.000.250.50\nx\nPC1P C2PC3\nR5R10R20\n\u22120.40.00.4)\nource A08\n00cali\n0Source C\nFigure\u00a01.  A scheme and a pipeline of methods used in this study. In this example we use 10 hypothetical sources  (i.e., news outlets): \n(A)\u2013(J) (top row on the plot) all writing about a given concept  k (e.g., \u201cEuropean Union\u201d); each is described with one timeseries \nreflecting their activity f(t)\ns,\ufffd(k) , i.e., number of published articles over time (examples shown in the left column for sources A and \nB). Each series can be divided into windows of size /Delta1 (here /Delta11=20 , /Delta12=10 , /Delta13=5\u2014see left column). In each window the \nnumber of articles is summed and then the mean  \u00b5 and standard deviation  \u03c3 of these sums are calculated. These pairs for each \nsource and window size are shown on the plot in the middle column and the fit to them in a log-log scale (solid line) is the temporal \nfluctuation scaling (TFS, Eq.\u00a0(9 )). Differences between \u03c3 and TFS, given by Eq. (1 ) are residuals and are gathered in a matrix \u02c6R \n(middle plot in the right column) which is then an input for PCA. As an outcome of PCA we obtain a matrix \u02c6P of projections to new \ndimensions\u2014Principal Components (PCs, top plot in the right column) and a transformation matrix \u02c6G (bottom plot). The first PC, \ni.e. the value in s-th row of the first column of the matrix \u02c6P is the key observable in our study and we will use the reactivity  RAs(k) for \nthe keyword k  and source s . World map has been obtained using ggplot2 R  package20 using maps R package  data21.\n4\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/Averaging over all concepts reveals dependencies between Rs,\ufffd(k) for various pairs of time window sizes /Delta1 . The \nlong group had high in-group correlations (0.55) compared to medium  (0.38) and short  (0.36); residuals in the \nmedium  group positively correlated with the long  group (0.33) and slightly less to the short  group (0.16). There \nwas no correlation between short  and long  timescales (0.06). Similarly, we averaged the correlation matrix ele -\nments for pairs of concepts over all time window sizes. The mean of the diagonal elements was 0.52, and the \nmean of the off-diagonal elements was 0.26.\nThus, residuals for the given source and concept positively correlate for time windows of similar size. In the \nsame manner, residuals for a given source and time window positively correlate across different keywords. This \nis surprising because the residuals for each concept were calculated using different article sets.\nPrincipal components analysis of publisher residuals for each concept. So far we have considered \nstandard deviation residuals separately for different lengths of observation windows /Delta1 . For every publisher s \nand for every topic k there are 14 standard deviation residuals Rs,\ufffd(k) in matrix \u02c6R(k) (the middle matrix in the \nright row of Fig.\u00a0 1). To reduce the dimensionality of these observations we performed Principal Component \nAnalysis (PCA) on the residuals Rs,\ufffd(k) assuming that values for different /Delta1 are related to mutually orthogonal \ndirections. PCA produces a matrix of projections of the original variables to Principal Components (PCs) \u02c6P(k ) \n(top matrix in the right column) as well as a matrix \u02c6G(k) (bottom matrix) of new basis vectors that transforms \n\u02c6R(k) into \u02c6P(k ) according to\nThe columns of the transformation matrix \u02c6G(k) are eigenvectors of the empirical covariance matrix \u02c6R(k)\u02c6RT(k) \nof residuals. The first column G1(k) corresponds to the largest eigenvalue and it defines the direction of the first \nprincipal component  axis25. To make the PCs comparable across keywords, we forced the directions of the axes \nto have the sign of the contribution from the shortest time window residual (  1 min  ). The first PC (PC1, elements \nof the first column of the matrix \u02c6P(k ) ) is almost the mean of the residuals for all time window sizes, i.e., all /Delta1 \ncontribute to this PC almost in the same way (see top row in the matrix on the left panel of Fig.\u00a0 4). This usually \nexplains around 50% of the variance (right panel in Fig.\u00a0 4). The second PC (PC2, the second column of \u02c6P(k ) ; \n30% of variance) has opposing signs for contributions from residuals for time window sizes below 1 day and over 1 day; contributions for the extreme values were the highest. In the third PC (around 10% of variance), contributions for \n/Delta1\u226430 min  and /Delta1\u22653 days  have opposite signs to those for /Delta1 over 1\u00a0h and below 3\u00a0days. PC1 \nis the residual of a source for a given keyword averaged over the timescales analyzed. Thus, high absolute values of PC1 indicate atypically low/high fluctuations in timeseries of the source for one or more time window sizes. PC2 shows whether the atypical fluctuations were observed for short or long timescales. PC3 seems to describe (2)\n\u02c6P(k )=\u02c6R(k)\u02c6G(k)Figure\u00a02.  An example temporal fluctuation scaling plot for the keyword k= China ( /Delta1 =1 day). Each point \nrepresents one publisher s , its mean \u00b5s,\ufffd(k) and standard deviation \u03c3s,\ufffd(k) of activity timeseries calculated for \ntime window size /Delta1 . The black line represents an OLS fit to the points after calculating the logarithm of \u00b5 and \u03c3 . \nThe vertical distance from the line to a point for logarithmic variables is the residual Rs,\ufffd(k) as described in the \n\u201cResults\u201d section. Point colors represent source biases; shapes\u2014sources\u2019 continents. Several sources with known and unknown political bias are annotated.\n5\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/the variance of a source in scales of several hours; it is probably connected to whether a source has a day/night \nactivity cycle. PCs in the cleaned dataset (Fig.\u00a0 4) have a very similar composition to that in the raw data (see \nSupplementary Information: Cleaning dataset).\nWe calculated a correlation matrix of vectors representing each source\u2019s selected PC p  for each keyword k , \nas for the residuals.\nFigure\u00a0 5 shows that for each PC value, all keywords form a separate cluster. The mean correlation inside a \ncluster corresponding to results for one PC and all keywords was 0.44.\nThis finding means that the reporting style is intrinsic for a source rather than a keyword, nevertheless, we \nbelieve that slight differences in the values for various keywords might capture subtle reporting style differences between groups of sources when aggregated. We select the first PC as the main indicator of source s  reporting \nstyle on a given topic k \u2014reactivity  \nRAs(k)\u2014as the first principal component score:\nFigure\u00a03.  Agglomerative Clustering of a correlation matrix of residuals for all concepts and time window sizes. \nEach row/column stands for one of 546 (k ,\ufffd) combinations. A color bar for the correlation matrix values is on \nthe right hand side. Additional color labels on top of the matrix represent time window size /Delta1 (lightest\u20141 min, \ndarkest\u201460 days); color labels on the left side of the matrix represent different keywords k . Residuals for short \n( \ufffd<  1 h), medium (1 h <\ufffd<  1 day), and long ( \ufffd>  1 day) time windows are clustered together; inside the \nthree clusters, residuals for most keywords k  tend to be close to each other.\n6\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/where Rs(k) is the s -th row of matrix \u02c6R(k) and G1(k) denotes the first column of transformation matrix \u02c6G(k).\nFor news outlet activities, an intuitive interpretation would be that higher-than-expected fluctuations show a \nreactive  reporting style for a given topic by a given source (e.g. activity influenced by external events) and lower \nfluctuations indicate a stable  reporting style. These differences are subtle but clearly visible in the Supplementary \nInformation: Additional dataset info. A source\u2019s relative burstiness for a topic compared to other news outlets \nmight be useful when interpreting an article as a signal lateral to general interest (number of articles) or senti -\nment towards the topic.\nAggregated reactivity. Having defined a measure of the reactivity RAs(k) of publisher s towards topic k, \nwe used it to quantify the typical reporting style of groups of publishers. Two features of news outlets that we \nhave used for aggregation are their political bias  and country of origin . Below, we analyze patterns of median \nreactivity by group.\nReactivity by country. The median RAs(k) by country for polarizing concepts (see the Concepts subsection \nof Methods) are in Fig.\u00a0 6 (for other concepts\u2014see Supplementary Information: Aggregated reactivity). Rows \nrepresent countries with the most sources tracked by ER with the highest topping the list; columns stand for \nconcepts. Colors indicate the medians \ufffdRA s(k)\ufffds\u2208Sc=Cc(k) of the reactivity for all sources s\u2208Sc from a given \ncountry c when reporting a given topic\u00a0 k. Recall that reactivity RAs(k) has a logarithmic nature (since the origi-\nnal variables were logarithmic), so one unit difference translates to an order of magnitude (factor 10) difference in fluctuations. It is clear that sources from United States, United Kingdom, France, and Australia have fewer-than-typical fluctuations for all the polarizing concepts\u2014colors are very close to white ( \nCc(k)\u2248\u2212 0.7 ). Russian, \nCzech, Polish, and Ukrainian sources also seem to typically cover the topics stably ( Cc(k)\u2248\u2212 1.5 ), Chinese, \nand Indonesian\u2014reactively ( Cc(k)\u22481.0 ). German and Argentinian publishers most reactively reported on \nAbortion  ( Cc(k)\u22481.5, 2.1  , respectively); Canada and Indonesia on Cannabis  (2.9,\u00a01.8); India and Indonesia on \nCapital punishment  (0.9,\u00a00.7); India and China on Homosexuality (3.6,\u00a02.7); China and India on Same-sex mar -\nriage  (5.2,\u00a01.6). Interestingly, in Italy the topic Homosexuality was reported rather stably ( \u22120.5  ) but Same-sex \nmarriage \u2014reactively (1.2). The most notable stable reporting was observed for Russian, Chinese, Spanish and \nIndian sources for Abortion  ( \u22123.2,\u22122.1,\u22122.0,\u22121.9  ). Stable reporting was also found for Cannabis  by Polish and \nRussian outlets ( \u22122.5,\u22122.11  ); Capital punishment  in Czech Republic and Poland ( \u22122.2,\u22122.0  ); Homosexuality in \nRussia, Ukraine and Canada ( \u22122.4,\u22121.3,\u22121.2  ), Same-sex marriage in Poland and Mexico ( \u22122.2,\u22122.0  ). The val-\nues seem to reflect the temperature of the national views towards a given concept. For example, in 2018, Canada legalized Cannabis\n26 and India legalized Homosexuality27. Publishers from both countries tended to report reac-\ntively on the respective topics, presumably driven by the legislative changes. Similarly, in China, there were two major rulings on Same-sex marriages\n28. Indonesia reactively reported (1.9, see SI) on Terrorism  as it suffered six \nterrorist attacks in  201829; the high reactivity of Italian media for Shooting  (4.1, see SI) might be an effect of the \nMacerata  shooting30. The French media were reactive towards China  (3.6, see SI) as 2018 was an important year \nfor bilateral relations between the two  countries31. Recall that high reactivity  does not necessary mean that the \ngiven keyword was frequently discussed in the given country. In fact Fig.\u00a0 6 indicates that Same-sex marriage and \nHomosexuality\u00a0  were discussed in China very reactively but less frequently than Capital punishment , which was \nreported very stably (compare square colors and sizes in the above-mentioned figure). Similarly, Homosexuality in India was a reactive topic although it attracted less interest than Abortion  or Cannabis , which were reported \nvery stably. More such examples can be found in the Supplementary Information.\nReactivity by political bias. The above analysis has shown that the median value of \n\ufffdRA s(k)\ufffds\u2208G reflects the \ngeneral attitude of a group of sources G (e.g. from the same country) towards a topic k. Around 10% of the \npublishers in Event Registry were also annotated by media  biasf actch  eck.com for political bias\u2014see the Dataset (3) RAs(k)\u2261Ps,1(k)=Rs(k)G1(k)\nFigure\u00a04.  Principal Component Analysis of residuals by time window size for the keyword European Union \n(clean data). (left) Contributions of residuals Rs,\ufffd(k) for the /Delta1 analyzed to the first four PCs (first four rows \nof matrix \u02c6G ). The first principal component is roughly the arithmetic mean of the residuals over different \ntimescales, the second PC has opposite loadings for long and short timescales. (right) A cumulative explained \nvariance ratio for first four PCs. The first four PCs explain typically around 97% of variance.\n7\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/info: Political bias of sources subsection of Methods. This is used to investigate the reactivity of sources grouped \nby political bias.\nA general tendency was that sources marked as left  represent (on average) a stable reporting style towards \nmost concepts, while right  tended to have a reactive/bursty style. For 30 out 39 analyzed concepts (see Supple -\nmentary Information: Aggregated reactivity), sources in the right  group had the highest or the second highest \nreactivity, while the left  group had the lowest or the second lowest for 26 concepts; often (in 18 cases) all the \ngroups left-center, center, right-center had their median above the left  and below the right . The right  was relatively \nnonreactive for the concepts Kim Kardashian , Marvel comics , and Same-sex marriage; the left  was relatively \nreactive for Cannabis (drug), Climate change , and Shooting . The positions of pro-science and low-Q-news (ie. low \nquality news) did not have a stable pattern, perhaps caused by the low number of sources in these groups. The sources with annotated bias were mostly of US origin.\nFigure\u00a05.  Agglomerative Clustering of a correlation matrix of the first four principal components of the \nresiduals Ps,p(k) ( a=1,...,4 ) for all concepts k . Each row/column stands for one (k ,\u00a0p) combination. A color \nbar for the correlation matrix values is on the right hand side. Additional color labels above the matrix represent an order of PC a  (lightest\u20141st PC, darkest\u20144th PC); color labels on the left side of the matrix represent \ndifferent keywords k . PCs \nPs,p(k) of the same order p  are clustered; the mean correlation coefficient /angbracketleftbig\n\u03c1/parenleftbig\nk1,p1;k2,p2)/parenrightbig/angbracketrightbig\np1=p 2=0.44.\n8\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/To compare reactivity values across all of the analyzed keywords, we calculated the median reactivity of each \nbias group b for each keyword k as \ufffdRA s(k)\ufffdbias (s)=b=Pb(k) , where s\u2014publisher, bias(s)\u2014a political bias of a \nsource s. We defined the relative median reactivity of a bias group for a keyword as follows:\nThus, a bias group with the lowest Bb(k) for a given k  will indicate \u02dcBb(k)=0 . In Fig.\u00a0 7 (left panel), reports \u02dcBb(k) \nby a bias group for all the keywords. To quantify the general tendencies of the relative median reactivity \u02dcBb(k) , \nwe performed a Kruskal\u2013Wallis test with the FDR-adjusted Dunn\u2019s test for pairwise  comparisons32 of the bias (4)\u02dcBb(k)=Bb(k)\u2212min\nb\u2032Bb\u2032(k)\nFigure\u00a06.  The median reactivity Cc(k) of the reactivity for all sources from a given country c  for keywords k  \nrelated to \u201cpolarizing\u201d concepts. Square size is proportional to the mean daily number of articles published by \nsources from a given country c  on a given topic k ; color represents the median reactivity Cc(k)=\ufffdRAs(k)\ufffds\u2208Sc \nof sources from the country c . Missing squares indicate that there were no publishers from the country that \npublished at least 36 articles on the topic in our dataset. Red symbols correspond to topics that were reactively discussed in the country in 2018.\nFigure\u00a07.  Comparison of relative median reactivity \u02dcBb(k) between political bias groups for all keywords. \nLeft-oriented sources are generally less reactive than the right -oriented sources. (a ) values of relative median \nreactivity \u02dcBb(k) (see Eq.\u00a0(4 )) for all keywords by political bias. (b ) Results of pairwise Dunn median tests with \na two-step Benjamini\u2013Krieger\u2013Y ekutieli FDR  adjustment32; the adjusted p -values describe the likelihood of \nthe observed difference in medians of two samples assuming there is no difference between the medians of their populations. Thus, the lower the p -value, the more statistically significant the difference between the two \ngroup medians. \n\u2217\u2217\u2217\u2217\u2212 p\u2208[0, 0.001)  , \u2217\u2217\u2217\u2212 p\u2208[0.001, 0.005)  , \u2217\u2217\u2212 p\u2208[0.005, 0.01)  , \u2217\u2212p \u2208[0.01, .05)  , \n.\u2212p\u2208[0.05, 0.1  ), otherwise p\u2208[0.1, 1]  . The color indicates which group had the higher median\u2014black \nif the median of the group from the corresponding row was higher than the median of the group from the corresponding column; white\u2014the opposite case.\n9\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/groups; the results are in Fig.\u00a0 7 (right panel). Both left  and pro-science typically had lower \u02dcBb(k) values than the \nremaining groups but are statistically indistinguishable from each other. On the other hand, the relative reactiv-\nity \u02dcBb(k) for right  was significantly higher than the remaining groups; Unknown  scored similarly but even this \ngroup had lower average reactivity than right . Low-Q-news  and left-center were distinguishable from right  and \nUnknown  only; the relative median reactivity \u02dcBb(k) of center  and right-center are over left and below right . The \nstatistical tests confirmed that the left  is significantly less reactive than the right .\nDiscussion\nThis paper reports a novel two-step method to quantify the temporal fluctuations of a variable f(t)\ns,\ufffd(k) describing \nthe dynamics of entities s  belonging to a complex system, such as news outlets in the media space. In this case \nf(t)\ns,\ufffd(k) is the number of articles published by the outlet s  about a keyword k  during a time window /Delta1 around a \ntime moment t . The first step consists of checking whether the Temporal Fluctuation Scaling law (TFS) is valid \nfor the system of entities s and, if so, determining TFS residuals for various time window sizes /Delta1 . The residuals \nare ratios of empirical standard deviations f(t)\ns,\ufffd(k) (measured from a time series) to the value predicted by the \nTFS  law15,18. The second step is dimensionality reduction using Principal Component Analysis (PCA) to obtain \na value independent of the time window size. The First Principal Component PC1\u00a0\u00a0  contains aggregated infor -\nmation about fluctuations in all timescales and we call this reactivity . To give a practical application, we used a \ncase study of the online news aggregator Event  Registry23.\nWe started with calculating TFS for activity timeseries in several timescales /Delta1 for each keyword k  separately \n(Fig.\u00a0 2) and then obtained TFS residuals Rs,\ufffd(k) (see Eq.\u00a0(1 )) in each timescale /Delta1 for every source s . Using a cor -\nrelation matrix of the residual values (Fig.\u00a0 3), we showed that the residuals of a given source positively correlate \nacross different keywords for similar time window sizes. Moreover, using this method there are three timescales for fluctuations of publishers\u2019 activities (short \u2014\n/Delta1\u2264 1 h, medium \u20141 h <\ufffd\u2264 1 day, long\u20141 day <\ufffd  ) reported \n in24. We conclude that reporting style is intrinsic to a publisher but small differences in the values for keywords \ncapture subtle differences in reporting style. A similar observation was reported  in15 for a spatial clustering of \nworld precipitation data and a clustering of financial stocks from the same sectors.\nTo extract the most substantial factors that could aggregate the residuals over different timescales we utilized \nPCA. PCA reveals linear combinations of residuals at different timescales to form an uncorrelated orthogonal \nbasis set where consecutive PCA components correspond to the highest variances between news sources (Eq.\u00a0(2 )). \nFrom the results, PC1, later called reactivity RAs(k) (Eq.\u00a0(3 )), is a good summary of source s  deviation from the \ntypical variation of activity on a topic k . In fact, the reactivity value for the dataset has nearly the same loadings \nfrom residuals Rs,\ufffd(k) at each timescale /Delta1 . On the other hand, the PC2 has opposing loadings from residuals \nin short (  \ufffd< 1 day) and long (  \ufffd> 1 day) timescales. The 1st and 2nd PCs together explain about 80% of the \ncumulative variance for the dataset (Fig.\u00a0 4) and therefore can be used to reduce the system dimensionality. A \ncorrelation matrix of the PC values \u02c6P(k ) (Fig.\u00a0 5) upholds our observation\u2014PC values for a given source obtained \nfrom various keywords positively correlate and therefore seem to be intrinsic to the source.\nWe then aggregated reactivity values grouped by political bias or country of origin to assess the relative report-\ning style of the groups towards different topics. First, we showed that the reactivity measure can detect which topics were reported reactively by comparing the results grouped by source country (Fig.\u00a0 6), e.g., legalization of \nCannabis in Canada and Homosexuality in India. Such topics would not be highlighted and could be disregarded if one relied only on activity, i.e., taking into account only the number of articles about the given keyword. Then, we analyzed differences in reporting style between (mostly American) sources grouped by political bias (Fig.\u00a0 7). \nGroups left and pro-science had been typically less reactive than others for the concepts. On the other hand, news \noutlets annotated as right  were usually the most reactive.\nThe reactivity value is dimensionless and normalized which enables comparisons of source reactivity across \ndifferent context. For example, it could be applied to compare the relative volatility of stocks in various stock exchanges. Although our reactivity  \nRAs(k) coefficient (Eq.\u00a0 3) is similar in concept to Fano  factor8 and the coef-\nficient of  variation9 it has several advantages compared to them. (i) It is based on a comparison of activity fluctua-\ntions of a given object to activity fluctuations in an ensemble of other objects that obeying temporal fluctuation scaling, so it has a well-defined zero level . (ii) Its single value takes into account fluctuations at multiple timescales \n/Delta1 due to Principal Component Analysis. (iii) It is not correlated ( \u03c1=\u2212 0.05 ) with activity and so can be used \nto compare fluctuations in entities of different sizes. In fact, the correlation between the Fano factor and activ -\nity for the ER data set is about \u03c1=0.3 . Thus, this factor overestimates fluctuations for large publishers and the \ncorrelation between the coefficient of variation and activity is about \u03c1=\u2212 0.57 , overestimating fluctuations for \nsmall and medium outlets (for details\u2014see Supplementary Information: Measure comparisons).\nAnother way of comparing reactivity to the Fano factor and the coefficient of variation is to use them instead \nof TFS residuals in the first step of our method and perform the second step and analyses without changes (see Supplementary Information: Measures comparisons). Correlation matrices obtained with these alternative vari-\nability measures could not be clustered into three timescales. For the Fano factor, two regimes were observed (for \n/Delta1 below or above 15 min) and a typical correlation inside each cluster was lower than for the reactivity RA . For \nthe coefficient of variation, two regimes also exist (for /Delta1 below or above 1 day) and almost all values positively \ncorrelated. Our reactivity approach finds clustering in three timescales  (Fig.\u00a0 3) that cover both divisions found by \nthe Fano (Supplementary Fig.\u00a0S18) and coefficient of variation (Supplementary Fig.\u00a0S17) approaches separately. \nIt follows that while the Fano is sensitive to the short timescale division and the coefficient of variation to the long timescale, reactivity takes into account all the timescales in the case analyzed. Moreover, aggregating vari -\nability by the political bias  of a source (Fig.\u00a0 7) was most successful when reactivity RA was used, because ordering \npolitical biases by median relative variability was similar to ordering on a political spectrum\u2014from left  through \ncenter to right . For the coefficient of variation (Supplementary Fig.\u00a0S23), the ordering seemed uninformative\u2014the \n10\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/left-center  group had the lowest relative fluctuations and left  had the highest. For the Fano factor, only left  biased \nsources had a median significantly different from other bias groups.\nOur reactivity parameter, RAs(k) is related to fluctuations of a single unit s  at different timescales but it should \nnot be mistaken for the generalized Hurst H (q) exponent that is calculated from a scaling law describing q -th \norder fluctuation as the function of time window size /Delta1 . In fact, reactivity  RA is related to the scaling behavior \n(TFS) that comes from comparing different units. This means that reactivity  takes into account features following \nfrom a set of entities while the generalized Hurst exponent H(q) reflects only scaling for the timeseries of a single \nentity. The relation between the TFS scaling exponent and the Hurst exponent H (2) was discussed  in15. Since \nthe TFS scaling law takes into account fluctuations of order q=2 , we are not considering how the RA  measure \nis dependent on the multifractality of a timeseries when the Hurst exponent is q -dependent.\nWe have summarized above the properties of the reactivity measure RA , which is related to the first principal \ncomponent PC1 of the residuals matrix \u02c6R(k) . The first two PCs (PC1 and PC2) have also been used to detect \ncorrupted time series (see SI: Cleaning Dataset) in our dataset. The first type of data corruption is related to an \nabnormally large number of published articles by a given outlet in a short time period (a few minutes to a few hours) and is likely to be result of changes in the website shape that misleads the web crawler. This can be detected by a high value of the PC1 for this publisher. The second type of data corruption is related to missing records in \na period that can be caused by the lack of a functional crawler. This can be detected by a value of PC2 indicating \nlarge corrections to TFS in long timescales for this publisher.\nWe believe the new approach is universal and can be applied to other fields where a proper assessment of the \nrelative amount of signal variation is critical (e.g. financial  markets\n33\u201335, or  neuroscience36,37). Additionally, the \nnumber of sources annotated by political bias was relatively low and skewed towards the US which significantly decreased the reliability and generality of the results, although giving a more homogeneous dataset to ana-lyze. Unfortunately, mass-scale automatic bias classification with high accuracy seems out-of-reach for  now\n38,39. \nMoreover, more information could be extracted from similar datasets by inspection of consecutive PCs. For example PC2 indicates whether the fluctuations described by PC1 are biased towards short or long timescales. A method to adjust the mean and variance of corrupted timeseries might be developed using the new method to compensate for the two described disturbances (artificial activity spike, periods of missing data). One of the \nbiggest disadvantages of the new measure is its high computational complexity, but this could be resolved using \napproximate  methods\n40.\nIn conclusion, we have introduced a method that uses predictions from a fluctuation scaling law to bench -\nmark observed standard deviations and our reactivity measure RA  aggregates information about fluctuations \nat different timescales. We show that the approach makes it possible to compare news outlet reporting styles by geography and political orientation.\nMethods\nDataset info. Online news media are hard to analyze on a large scale due to their distributed character \ncompared to social media. Social media data is concentrated around a few important platforms (like Twitter or Facebook) but the news industry has a huge number of news outlets. Nevertheless, mass-scale surveillance of the online news industry is possible with news aggregators such as Event Registry (ER, www.event  regis  try.org). \nER is an online system which collects, annotates, clusters, and stores news items from online sources around the \n globe\n23. The system has been maintained by the Artificial Intelligence Laboratory (Jo\u017eef Stefan Institute, Lju-\nbljana, Slovenia) since 2014 and tracks tens of thousands of publishers in near real-time. While its purpose is to \ntrack world events by clustering news items (across different languages), access to this database was provided by one of the coauthors. We queried the system to download all articles containing one of selected concepts (see the \u201cConcepts\u201d subsection of \u201cMaterials and methods\u201d). Each article was represented as a tuple: publisher, keyword \n(topic), timestamp .\nSources. When our data set was created there were 8155 sources in ER that published at least three articles per \nmonth about at least one of the analyzed concepts. To examine geographical and political differences between \nthe publishers, we considered the sources\u2019 countries of origin and political biases, where applicable. Source counts by continent can be found in Table\u00a01.Table 1.  Sources by continents. Only sources which published at least one article per month about at least one \nof the analyzed keywords.Continent Sources (With known bias)\nEurope 3065 76\nNorth America 2650 526\nAsia 1015 71\nSouth America 655 4\nAfrica 426 7\nUnknown 190 7\nOceania 154 18\n11\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/Source countries of origin are reported by ER. Sources from all continents were present in the dataset; over \ntwo thirds were in Europe (37%) or North America (33%). Asia (13%) and Africa (5%) are underrepresented \nin the set compared to their populations. The relatively small number of publishers from South America (8%) and Oceania (2%) seems to be justified by their relatively small populations. Geographic data was missing for 2% of sources.\nPolitical bias of sources. Political bias data was gathered from Media Bias/Fact Check (MBFC, www.media \nbiasf actch  eck.com). At the moment of writing, the website listed 2896 online media bias annotations, but only \n709 overlapped with our list. While its credibility is sometimes questioned, it has been regarded as accurate \nenough to be used as ground-truth for e.g. media bias  classifiers\n39,41,42, fake news  studies43\u201345, and automatic \nfact-checking  systems46\u201348.\nMBFC groups sources into 8 categories: left  (92 sources in our list), left-center (255), center (147), right-center \n(125), right  (53), pro-science  (27), fake-news  (21), conspiracy  (17), satire  (2). We merged the last three categories to \none\u2014 low-Q-news  (41). Following the website, sources marked as left  are \u201cmoderately to strongly biased toward \nliberal causes through story selection and/or political affiliation\u201d , left-center have \u201cslight to moderate liberal bias\u201d , \nsources marked as right  are \u201cmoderately to strongly biased toward conservative causes\u201d and right-center \u201cmedia \nsources are slightly to moderately conservative in bias\u201d . Center media are considered to have a minimal bias, \nprovide factual and sourced reporting, and to be \u201cthe most credible media sources\u201d . Sources with an extreme liberal/conservative bias are listed mainly as fake-news or conspiracy . Sources from all continents can be found in \nthe MBFC list but the distribution is very US-centered\u2014the vast majority of sources tracked by ER and annotated by MBFC are in North America (75%); the rest consist of a few European (10%), Asian (10%), Oceanian (4%), African (1.5%), and South American (1%) news outlets.\nConcepts. One of natural language processing techniques implemented in ER is the extraction of concepts and \nentities (called here topics  or keywords , despite often being longer than one word) involved in a given piece of \nnews. ER identifies keywords using Wikipedia and so every keyword has an associated Wikipedia article. The set \nof concepts selected for the study consisted of 19 countries and 20 current topics. We chose a few countries from all the continents: North America (United States , Mexico), Europe (United Kingdom , France , Germany , Austria , \nPoland , Slovenia , and European Union ), Asia (China , India , Japan , North Korea , Iran), South America (Brazil, \nArgentina ), Africa (Egypt , South Africa , Morocco ), and Oceania (Indonesia ). The current topics set was divided \ninto \u201cpolarizing\u201d and \u201cother\u201d topics. The first group consists of concepts which we expect to be perceived in dif-\nferent way by various political groups (Cannabis (drug), Capital punishment , Abortion , Homosexuality, Same-sex \nmarriage ). These concepts seem likely to differentiate between liberal and conservative views. For example, they \nwere a vital part of questionnaire in the NetSense  experiment\n49\u201351; unfortunately, Event Registry had too few \narticles on other topics used in the study (Premarital sex, Euthanasia ) for statistical analyses. The \u201cother\u201d group \ncontains keywords related to violence (Terrorism , Shooting ), sports (Real Madrid C.F., Roger Federer, Usain Bolt ), \ncelebrities (Kim Kardashian , British royal family ), and other concepts covered nowadays (Facebook , Islam , Cli-\nmate change , Universe , Bitcoin , Blockchain , Marvel Comics ).\nNumbers of sources and articles for each concept are in the Supplementary Information: Additional dataset info.\nStatistical methods. Extracting timeseries from lists of articles. The raw data for this study consists of \nlists of article publication dates and times fs(k)=/braceleftbig\n\u03c4s,1(k),\u03c4s,2(k),.../bracerightbig\n for each keyword k and publisher s that \nhad at least three articles with the keyword. To obtain timeseries, we divided the observation period (01.01\u2013\n31.12.2018, T=1 year) into non-overlapping windows of length /Delta1 and counted occurrences of publications in \nwindow t as follows:\nwhere |X | is the number of elements of a set X . For a given /Delta1 , we have W=\u2308T/\ufffd\u2309 time windows.\nTo allow statistical analyses, the longest period analyzed was 60 days. There was not much information in \ntimescales below a few minutes as the exact position of the timestamp was often determined by the crawl time. \nWe chose 14 time window sizes /Delta1\u2208{ 1 min, 5 min, 15 min, 30 min, 1 h, 3 h, 6 h, 12 h, 1 day, 3 days, 7 days, 14 \ndays, 30 days, 60 days } for the study. When the window length /Delta1 did not divide T  without a reminder, we treated \nthe last time window equally with the rest.\nTemporal fluctuation scaling.  The following introduces temporal fluctuation scaling (TFS), which was been \napplied to our data and served as a starting point to define TFS residuals.\nFirst, we calculate means of the timeseries:\nthen variances:\nwhere(5) f(t)\ns,\ufffd(k)=/vextendsingle/vextendsingle/vextendsingle/braceleftbig\n\u03c4s,i(k):t\ufffd\u2264\u03c4s,i(k)<( t+1)\ufffd/bracerightbig/vextendsingle/vextendsingle/vextendsingle\n(6)/angbracketleftBig\nf(t)\ns,\ufffd(k)/angbracketrightBig\n=W\u22121W/summationdisplay\nt=1f(t)\ns,\ufffd(k)\n(7) \u03c32\ns,\ufffd(k)=/angbracketleftbigg/bracketleftBig\nf(t)\ns,\ufffd(k)/bracketrightBig2/angbracketrightbigg\n\u2212/angbracketleftBig\nf(t)\ns,\ufffd(k)/angbracketrightBig2\n12\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/It has been observed for router activity and email traffic (but also stock markets, river flows, or printing activity)15 \nthat the standard deviation of the i-th entity\u2019s activity (calculated in windows of size /Delta1 ) scales with its mean with \nan exponent \u03b1 (and a multiplicative constant B ):\nArtificial examples of this procedure are shown in Fig.\u00a0 1, explaining how a set of sources publishing about a \nsingle concept gives rise to TFS (middle column in Fig.\u00a0 1) for different time windows.\nRecent theoretical advances have greatly improved our understanding of mechanisms that underlie TFS \nin a given  system40,52\u201354. One of the generative mechanisms is that entity activities in this class of systems can \nbe described with Tweedie distributions; exponents between 1 and 2 suggests the compound Poisson-gamma \n distribution55. This model arises when in each time step activity of an entity is a sum of i.i.d. gamma-distributed \nrandom variables and the number of the random variables is drawn from a Poisson distribution.\nIn the case of news outlet activities, each random variable might be an occurrence of a real world event which \ncauses a news outlet to write articles describing it; the number of articles per event follows a Gamma distribu -\ntion. Each outlet can have a different threshold for an event importance or relevance (influencing the Poisson \nprocess rate) and/or attitude towards a topic (influencing parameters of the distribution of articles per event) \nwhich can account for heterogeneity in the number of articles and temporal activity fluctuations amount of the entities creating the system.\nAgglomerative clustering of correlation matrices. To analyze relationships between residuals \nRs,\ufffd(k) (see Eq.\u00a0(1)) \nand Principal Components Ps,p(k) (see the subsection below) for various combination of keywords k and time \nwindow sizes /Delta1 or Principal Components p, we calculated correlation matrices. Each row/column of the matrix \nrepresents correlations between one pair (k ,\ufffd) or one pair (k,\u00a0 p) with the remaining pairs. As keywords were \nreported by different numbers of publishers, it was necessary to calculate correlation coefficients using only \npublishers that covered both keywords. We used Pearson\u2019s correlation coefficient; here for residuals, similarly for PCs:\nwhere \nRs,\ufffd(k)\u2014the residual of publisher s  calculated for keyword k  and time window size /Delta1 , Sk \u2014a set of pub-\nlishers that published articles about a keyword k , Sk1,k2=Sk1\u2229Sk2 , and \u00afRx=1\n|Sk1,k2|/summationtext\ns\u2208Sk1,k2Rs,\ufffdx(kx).\nTo group combinations that were positively correlated, we performed Agglomerative Clustering (AC) of \nthe  matrices56. The usual inputs to clustering algorithms are dissimilarity (distance) matrices so we calculated \ndistances between the (k ,\ufffd) pairs as follows:\nAC is a bottom-up clustering method\u2014the algorithm is initialized with each (k ,\ufffd) combination in a separate \ncluster. Then, at each step, the nearest pair of clusters is merged. We selected the unweighted pair group method \nwith arithmetic mean (UPGMA) which defines the distance between clusters A  and B  as the arithmetic mean of \nthe distances between objects in the clusters:\nThe result of the clustering can be drawn as a rooted tree (a dendrogram) and used to sort the rows/columns of \na correlation matrix.\nPrincipal component analysis (PCA). Despite being over a hundred years  old57, PCA is commonly used in \ncontemporary exploratory analyses of highly dimensional  datasets25,58\u201360. This method transforms an original \nset of variables to so-called Principal Components (PC). PCs are mutually orthogonal linear combinations of the \noriginal variables. The first PC is a linear combination of the original variables so that the variance of the data along the axis is maximized; the remaining PCs are constructed in a similar way with additional requirements of orthogonality to all the previous PCs. The main PCA applications are visualization and dimensionality reduc-\ntion. Nowadays, the procedure is usually carried out using Singular Value Decomposition (SVD) of the data \nmatrix (or, equivalently, Eigenvalue Decomposition of the data covariance matrix). The scikit-learn, a Python machine learning  library\n61 which we performed all the PCA procedures in the study with, uses the LAPACK \nimplementation of the  SVD62.\nIn the paper, we denote the decomposition of a matrix \u02c6R that includes the original data vectors into PCs as \nfollows:(8)/angbracketleftbigg/bracketleftBig\nf(t)\ns,\ufffd(k)/bracketrightBig2/angbracketrightbigg\n=W\u22121W/summationdisplay\nt=1/parenleftBig\nf(t)\ns,\ufffd(k)/parenrightBig2\n(9) \u02dc\u03c3s,\ufffd(k)=B\ufffd/angbracketleftBig\nf(t)\ns,\ufffd(k)/angbracketrightBig\u03b1\ufffd.\n(10)\u03c1(k1,\ufffd1;k2,\ufffd2)=/summationtext\ns\u2208Sk1,k2/parenleftbig\nRs,\ufffd1(k1)\u2212\u00afR1/parenrightbig/parenleftbig\nRs,\ufffd2(k2)\u2212\u00afR2/parenrightbig\n/radicalBig/summationtext\ns\u2208Sk1,k2/parenleftbig\nRs,\ufffd1(k1)\u2212\u00afR1/parenrightbig2/radicalBig/summationtext\ns\u2208Sk1,k2/parenleftbig\nRs,\ufffd2(k2)\u2212\u00afR2/parenrightbig2\n(11) d(k1,\ufffd1;k2,\ufffd2)=1\u2212\u03c1(k1,\ufffd1;k2,\ufffd2)\n(12)d(A ,B)=1\n|A||B|/summationdisplay\na\u2208A/summationdisplay\nb\u2208Bd(a,b).\n(13) \u02c6R=\u02c6P\u02c6GT\u21d0\u21d2\u02c6P=\u02c6R\u02c6G\n13\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/where a matrix \u02c6P contains projections of the original variables to principle components, and \u02c6G is a matrix of new \nbasis vectors: a transformation matrix for old variables to principle components.\nOne of the most important features of PCA is its ability to detect linear correlations among the components \nof data vectors and to indicate the amount of variance explained by each of the newly-introduced variables, i.e., \nPCs. If the consecutive PCs explain a considerable amount of variance, e.g., 90%, the remaining variables can be \nignored. This is known as dimensionality reduction. In the case of our data we make use of the first PC which \nusually explains over 60% of variance (cf Fig.\u00a0 4).\nAs it is impossible to visualize 14 dimensions, Fig.\u00a0 8 shows residuals for two selected dimensions\u20141 min \n( R1 min  ) and 1 h (  R1h ) for the keyword Terrorism . The plot shows that R1 min  and R1h are not independent: the \nlarger R1 min  the larger R1h , so they should not be treated as a valid set of coordinates. As an outcome of PCA we \nobtain two new directions\u2014 P1 and P2 that explain, respectively, 70% and 30% of the total variance and create a \nbetter setting to describe this data. The value of P1 , i.e., the projection of the original variables onto the first PC, \nis the reactivity , examined in this study.\nKruskal\u2013Wallis test and Dunn\u2019s post-hoc test. To check for differences in relative median reactivity \u02dcBb(k) \nbetween bias groups, we performed Kruskal\u2013Wallis  tests63. After a significant Kruskal\u2013Wallis test, pairwise com-\nparisons were performed to order bias groups by increasing medianQBb . The p-values were FDR adjusted using \nthe two-step Benjamini\u2013Krieger\u2013Y ekutieli  method32. In our study, we used the scikit-posthocs64 implementation \nof these tests.\nData availability\nThe dataset analyzed in the study (lists of news publication timestamps by keyword and publisher) is available from the corresponding author on reasonable request.\nCode availability\nPython scripts for calculating TFS and reactivity from a list of timestamps as well as scripts that aggregate reac-tivity are available from the corresponding author on reasonable request.\nReceived: 29 June 2020; Accepted: 13 November 2020\nReferences\n 1. Kondepudi, D. & Prigogine, I. Modern Thermodynamics: From Heat Engines to Dissipative Structures  2nd edn. (Wiley, Hoboken, \n2015).\n 2. Shaffer, F. & Ginsberg, J. P . An overview of heart rate variability metrics and norms. Front. Public Health  5, 258. https  ://doi.\norg/10.3389/fpubh  .2017.00258   (2017).\n 3. Marconi, U. M. B., Puglisi, A., Rondoni, L. & Vulpiani, A. Fluctuation-dissipation: response theory in statistical physics. Phys. Rep. \n461, 111\u2013195. https  ://doi.org/10.1016/j.physr  ep.2008.02.002  (2008).\n 4. An, C. E. et al. Heart rate variability as an index of resilience. Mil. Med. https ://doi.org/10.1093/milme  d/usz32  5 (2019).\n 5. Liu, Y . et al.  Statistical properties of the volatility of price fluctuations. Phys. Rev. E  60, 1390\u20131400. https  ://doi.org/10.1103/PhysR  \nevE.60.1390  (1999).\n 6. Kwapie\u0144, J. & Dro\u017cd\u017c, S. Physical approach to complex systems. Phys. Rep. 515, 115\u2013226. https ://doi.org/10.1016/j.physr  \nep.2012.01.007  (2012).R 1 minR 1 hour\nP1 P2\n70%\n30%s\nRAs\nFigure\u00a08.  Illustration of PCA dimension reduction. Points are original data\u2014residuals coming from the \nTerrorism  keyword for two selected time windows: 1 min ( R1 min  ) and 1 h ( R1h ). Blue vectors show directions of \nthe new set of variables obtained by the PCA method: first ( P1 ) and second ( P2 ) Principal Components. While \nred arrows mark the amount of variance explained by these variables (the length of each arrow is proportional to the variance explained by the respective PC). The blue point is a selected source s  and the blue dotted line shows \nthe projection of this data point onto the first PC which is this source\u2019s reactivity \nRAs.\n14\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/ 7. Mantegna, R. N. & Stanley, H. E. Introduction to Econophysics: Correlations and Complexity in Finance (Cambridge University \nPress, Cambridge, 2007).\n 8. Fano, U. Ionization Yield of Radiations. II. The Fluctuations of the Number of Ions. Phys. Rev. 72, 26\u201329. https ://doi.org/10.1103/\nPhysR  ev.72.26  (1947).\n 9. Allison, P . D. Measures of inequality. Am. Sociol. Rev.  43, 865. https  ://doi.org/10.2307/20946  26 (1978).\n 10. Smith, H. F. An empirical law describing heterogeneity in the yields of agricultural crops. J. Agric. Sci. 28, 1\u201323. https ://doi.\norg/10.1017/S0021  85960 00505  16 (1938).\n 11. Hurst, H. E. The problem of long-term storage in reservoirs. Int. Assoc. Sci. Hydrol. Bull.  1, 13\u201327. https  ://doi.org/10.1080/02626  \n66560 94936  44 (1956).\n 12. Matia, K., Ashkenazy, Y . & Stanley, H. E. Multifractal properties of price fluctuations of stocks and commodities. Europhys. Lett. \n(EPL) 61, 422\u2013428. https  ://doi.org/10.1209/epl/i2003  -00194 -y  (2003).\n 13. Taylor, L. R. Aggregation, variance and the mean. Nature  189, 732\u2013735. https  ://doi.org/10.1038/18973  2a0 (1961).\n 14. Taylor, R. A. J. Taylors Power Law: Order and Pattern in Nature (Academic Press, London, 2019).\n 15. Eisler, Z., Bartos, I. & Kertesz, J. Fluctuation scaling in complex systems: Taylors law and beyond. Adv. Phys. 57, 89\u2013142. https  ://\ndoi.org/10.1080/00018  73080  18930 43  (2008).\n 16. Gerlach, M. & Altmann, E. G. Scaling laws and fluctuations in the statistics of word frequencies. New J. Phys. 16, 113010. https  ://\ndoi.org/10.1088/1367-2630/16/11/11301  0 (2014).\n 17. Hanley, Q. S., Khatun, S., Y osef, A. & Dyer, R.-M. Fluctuation scaling, Taylors law, and crime. PLoS ONEhttps  ://doi.org/10.1371/\njourn  al.pone.01090  04 (2014).\n 18. Wang, Y ., Zhang, Q., Zhu, C., Hu, M. & Duong, V . Human activity under high pressure: a case study on fluctuation scaling of air \ntraffic controllers communication behaviors. Phys. A Stat. Mech. Appl. 441, 151\u2013157. https ://doi.org/10.1016/j.physa .2015.08.040  \n(2016).\n 19. Cho\u0142oniewski, J. et al. Temporal Taylors scaling of facial electromyography and electrodermal activity in the course of emotional \nstimulation. Chaos Solit. Fract.  90, 91\u2013100. https  ://doi.org/10.1016/j.chaos  .2016.04.023 (2016).\n 20. Wickham, H. ggplot2: Elegant Graphics for Data Analysis (Version 3.3.4) (Springer, New Y ork, 2016).\n 21. Becker, R.\u00a0A., Wilks, A.\u00a0R., Brownrigg, R., Minka, T.\u00a0P . & Deckmyn, A. maps: Draw Geographical Maps (Version 3.3.0). https ://CRAN.R-proje  ct.org/packa  ge=maps  (2018).\n 22. Watanabe, H., Sano, Y ., Takayasu, H. & Takayasu, M. Statistical properties of fluctuations of time series representing appearances of words in nationwide blog data and their applications: an example of modeling fluctuation scalings of nonstationary time series. \nPhys. Rev. E 94, 052317. https  ://doi.org/10.1103/PhysR  evE.94.05231  7 (2016).\n 23. Leban, G., Fortuna, B., Brank, J. & Grobelnik, M. Event registry: learning about world events from news. In Proceedings of the \n23rd International Conference on World Wide Web, WWW \u201914 Companion, 107\u2013110, https ://doi.org/10.1145/25679 48.25770 24  \n(Association for Computing Machinery, New Y ork, NY , USA, 2014).\n 24. Cho\u0142oniewski, J., Sienkiewicz, J., Leban, G. & Ho\u0142yst, J. A. Modelling of temporal fluctuation scaling in online news network with independent cascade model. Phys. A Stat. Mech. Appl. 523, 129\u2013144. https  ://doi.org/10.1016/j.physa .2019.02.035  (2019).\n 25. Ringn\u00e9r, M. What is principal component analysis?. Nat. Biotechnol.  26, 303\u2013304. https  ://doi.org/10.1038/nbt03  08-303 (2008).\n 26. Wikipedia. Cannabis in Canada. https  ://en.wikip  edia.org/w/index  .php?title =Canna  bis_in_Canad  a&oldid  =92646 4860 (2019).\n 27. Wikipedia. Homosexuality in India. https  ://en.wikip  edia.org/w/index  .php?title  =Homos  exual  ity_in_India  &oldid  =92531  0796  \n(2019).\n 28. Wikipedia. Recognition of same-sex unions in China. https ://en.wikip  edia.org/w/index .php?title =Recog  nitio  n_of_same-sex_union  \ns_in_China  &oldid  =92551 8643  (2019).\n 29. Wikipedia. Terrorism in Indonesia. https ://en.wikip  edia.org/w/index .php?title =Terro  rism_in_Indon  esia&oldid =92661 1352 (2019).\n 30. Wikipedia. Macerata shooting. https  ://en.wikip  edia.org/w/index  .php?title =Macer  ata_shoot  ing&oldid =92052  5256  (2019).\n 31. Minist\u00e8re de l\u2019Europe et des Affaires. France and China. https ://www.diplo  matie  .gouv.fr/en/count  ry-files /china /franc e-and-china  \n/ (2018).\n 32. Pike, N. Using false discovery rates for multiple comparisons in ecology and evolution. Methods Ecol. Evol. 2, 278\u2013282. https ://\ndoi.org/10.1111/j.2041-210X.2010.00061  .x (2011).\n 33. N\u00e6s, R. & Skjeltorp, J. A. Order book characteristics and the volume-volatility relation: empirical evidence from a limit order \nmarket. J. Financ. Mark.  9, 408\u2013432. https ://doi.org/10.1016/j.finma  r.2006.04.001  (2006).\n 34. Linsley, P . M. & Lawrence, M. J. Risk reporting by the largest UK companies: readability and lack of obfuscation. Account. Audit. Account. J.  20, 620\u2013627. https  ://doi.org/10.1108/09513  57071  07626  01 (2007).\n 35. Dentcheva, D. & Stock, G. J. On the price of risk in a mean-risk optimization model. Quant. Finance  18, 1699\u20131713. https  ://doi.\norg/10.1080/14697  688.2018.14367  65 (2018).\n 36. Nawrot, M. P . et al.  Measurement of variability dynamics in cortical spike trains. J. Neurosci. Methods 169, 374\u2013390. https  ://doi.\norg/10.1016/j.jneum  eth.2007.10.013  (2008).\n 37. Deco, G. & Hugues, E. Neural network mechanisms underlying stimulus driven variability reduction. PLoS Comput. Biol.https  ://\ndoi.org/10.1371/journ  al.pcbi.10023 95  (2012).\n 38. Hamborg, F., Donnay, K. & Gipp, B. Automated identification of media bias in news articles: an interdisciplinary literature review. \nInt. J. Digit. Libr.  20, 391\u2013415. https  ://doi.org/10.1007/s0079  9-018-0261-y  (2019).\n 39. Baly, R., Karadzhov, G., Alexandrov, D., Glass, J. & Nakov, P . Predicting Factuality of Reporting and Bias of News Media Sources. \nIn Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , 3528\u20133539, https  ://doi.org/10.18653  \n/v1/D18-1389  (Association for Computational Linguistics, Brussels, Belgium, 2018).\n 40. Zhao, L., Sheppard, L. W ., Reid, P . C., Walter, J. A. & Reuman, D. C. Proximate determinants of Taylors law slopes. J. Anim. Ecol.  \n88, 484\u2013494. https  ://doi.org/10.1111/1365-2656.12931   (2019).\n 41. Dinkov, Y ., Ali, A., Koychev, I. & Nakov, P . Predicting the Leading Political Ideology of Y ouTube Channels Using Acoustic, Textual, \nand Metadata Information. In Interspeech 2019, 501\u2013505, https ://doi.org/10.21437  /Inter  speec  h.2019-2965  (ISCA, 2019).\n 42. Stefanov, P ., Darwish, K. & Nakov, P . Predicting the Topical Stance of Media and Popular Twitter Users. arXiv  :1907.01260  (2019).\n 43. Shu, K., Wang, S. & Liu, H. Beyond news contents: the role of social context for fake news detection. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM\u201919, 312\u2013320, https ://doi.org/10.1145/32896 00.32909 94  \n(Association for Computing Machinery, New Y ork, NY , USA, 2019).\n 44. Bovet, A. & Makse, H. A. Influence of fake news in Twitter during the 2016 US presidential election. Nat. Commun.  10, 1\u201314. https  \n://doi.org/10.1038/s4146  7-018-07761  -2 (2019).\n 45. Badawy, A., Lerman, K. & Ferrara, E. Who falls for online political manipulation? In Companion Proceedings of The 2019 World \nWide Web Conference on\u2014WWW\u201919, 162\u2013168, https ://doi.org/10.1145/33085 60.33164 94 (ACM Press, San Francisco, USA, 2019).\n 46. Barr\u00f3n-Cede\u00f1o, A., Jaradat, I., Da San Martino, G. & Nakov, P . Proppy: organizing the news based on their propagandistic content. \nInform. Process. Manag.  56, 1849\u20131864. https  ://doi.org/10.1016/j.ipm.2019.03.005 (2019).\n 47. Y e, J. & Skiena, S. Mediarank: computational ranking of online news sources. In Proceedings of the 25th ACM SIGKDD International \nConference on Knowledge Discovery & Data Mining, KDD\u201919, 2469\u20132477, https ://doi.org/10.1145/32925 00.33307 09 (Association \nfor Computing Machinery, New Y ork, NY , USA, 2019).\n15\nVol.:(0123456789) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/ 48. Nadeem, M., Fang, W ., Xu, B., Mohtarami, M. & Glass, J. FAKTA: an automatic end-to-end fact checking system. In Proceedings \nof the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) , 78\u201383, \nhttps ://doi.org/10.18653  /v1/N19-4014  (Association for Computational Linguistics, Minneapolis, Minnesota, 2019).\n 49. Bahulkar, A., Szymanski, B. K., Chawla, N., Lizardo, O. & Chan, K. Influence of personal preferences on link dynamics in social networks. Complexity 1\u201312, 2017. https  ://doi.org/10.1155/2017/45435  63 (2017).\n 50. Bahulkar, A., Szymanski, B.\u00a0K., Chan, K. & Lizardo, O. Impact of Attributes on Group Formation. In 2018 IEEE/ACM Interna-tional Conference on Advances in Social Networks Analysis and Mining (ASONAM), 1250\u20131257, https  ://doi.org/10.1109/ASONA  \nM.2018.85086  58 (IEEE, Barcelona, 2018).\n 51. Nigam, A. et\u00a0al. ONE-M: modeling the co-evolution of opinions and network connections. In: Berlingerio, M., Bonchi, F., G\u00e4rt-\nner, T., Hurley, N. & Ifrim, G. (eds.) Machine Learning and Knowledge Discovery in Databases, vol. 11052, 122\u2013140, https ://doi.org/10.1007/978-3-030-10928 -8_8  (Springer International Publishing, Cham, 2019).\n 52. Reuman, D. C., Zhao, L., Sheppard, L. W ., Reid, P . C. & Cohen, J. E. Synchrony affects Taylors law in theory and data. Proc. Natl. Acad. Sci.https ://doi.org/10.1073/pnas.17035  93114   (2017).\n 53. James, C., Azaele, S., Maritan, A. & Simini, F. Zipfs and Taylors laws. Phys. Rev. E 98, 032408. https ://doi.org/10.1103/PhysR  \nevE.98.03240 8 (2018).\n 54. Sakoda, G., Takayasu, H. & Takayasu, M. Tracking Poisson parameter for non-stationary discontinuous time series with Taylors abnormal fluctuation scaling. Stats  2, 55\u201369. https  ://doi.org/10.3390/stats  20100  05 (2019).\n 55. Kendal, W . S. & J\u00f8rgensen, B. Taylors power law and fluctuation scaling explained by a central-limit-like convergence. Phys. Rev. E 83, 066115. https  ://doi.org/10.1103/PhysR  evE.83.06611  5 (2011).\n 56. Liu, X., Zhu, X.-H., Qiu, P . & Chen, W . A correlation-matrix-based hierarchical clustering method for functional connectivity \nanalysis. J. Neurosci. Methods 211, 94\u2013102. https ://doi.org/10.1016/j.jneum  eth.2012.08.016  (2012).\n 57. Pearson, K. Liii. On lines and planes of closest fit to systems of points in space. J. Sci.  2, 559\u2013572. https ://doi.org/10.1080/14786  \n44010 94627  20 (1901).\n 58. Bollen, J., Van de Sompel, H., Hagberg, A. & Chute, R. A principal component analysis of 39 scientific impact measures. PLoS \nONE  4, 1\u201311. https ://doi.org/10.1371/journ  al.pone.00060  22 (2009).\n 59. Gajewski, L. G., Cho\u0142oniewski, J. & Holyst, J. A. Key courses of academic curriculum uncovered by data mining of students grades. Acta Physica Polonica A  129, 1071\u20131076. https  ://doi.org/10.12693 /APhys  PolA.129.1071  (2016).\n 60. Sienkiewicz, J., Soja, K., Holyst, J. A. & Sloot, P . M. A. Categorical and geographical separation in science. Sci. Rep. 8, 8253. https  \n://doi.org/10.1038/s4159  8-018-26511  -4 (2018).\n 61. Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825\u20132830 (2011).\n 62. Anderson, E. et\u00a0al. Lapack: a portable linear algebra library for high-performance computers. In Proceedings of the 1990 ACM/\nIEEE Conference on Supercomputing, 2\u201311 (IEEE Computer Society Press, 1990).\n 63. Kruskal, W . H. & Wallis, W . A. Use of ranks in one-criterion variance analysis. J. Am. Stat. Assoc. 47, 583\u2013621. https ://doi.\norg/10.1080/01621  459.1952.10483  441 (1952).\n 64. Terpilowski, M. scikit-posthocs: pairwise multiple comparison tests in python. J. Open Source Softw. 4, 1169. https ://doi.\norg/10.21105 /joss.01169  (2019).\nAcknowledgements\nJ.Ch., J.S. and J.A.H. are thankful to Slovenian Press Agency STA and especially to Aljo\u0161a Rehar for the hospitality \nduring secondments in the framework of RENOIR Project. The political bias of the news outlets was courtesy of Dave van Zart, the owner of Media Bias/Fact Check ( www.media  biasf  actch  eck.com). Helpful insights from \nEduardo Altmann, Stanis\u0142aw Dro\u017cd\u017c, and Przemys\u0142aw Biecek are gratefully acknowledged. The work was partially supported as RENOIR Project by the European Union Horizon 2020 research and innovation programme under \nthe Marie Sk\u0142odowska\u2013Curie Grant Agreement No. 691152 and by Ministry of Science and Higher Education \n(Poland), Grant Nos. 34/H2020/2016, 329025/PnH/2016 and by National Science Centre, Poland Grant No. 2015/19/B/ST6/02612. J.A.H. was partially supported by the Russian Scientific Foundation, Agreement #17-71-30029 with co-financing of Bank Saint Petersburg and by POB Research Centre Cybersecurity and Data Science of Warsaw University of Technology within the Excellence Initiative Program\u2014Research University (IDUB).\nAuthor contributions\nJ.C.\u2014conception, design, data acquisition, data analysis, interpretation, software, draft, revision; J.S.\u2014design, interpretation, draft, revision; N.D.\u2014interpretation; G.L.\u2014data acquisition; M.T.\u2014revision; J.A.H.\u2014conception, design, interpretation, draft, revision, supervision.\nCompeting interests  \nThe authors declare no competing interests.\nAdditional information\nSupplementary information is available for this paper at https ://doi.org/10.1038/s4159 8-020-77660 -4.\nCorrespondence and requests for materials should be addressed to J.A.H.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n16\nVol:.(1234567890) Scientific Reports  |        (2020) 10:20673  | https://doi.org/10.1038/s41598-020-77660-4\nwww.nature.com/scientificreports/Open Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article\u2019s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat  iveco  mmons .org/licen  ses/by/4.0/.\n\u00a9 The Author(s) 2020", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A calibrated measure to compare fluctuations of different entities across timescales", "author": ["J Cho\u0142oniewski", "J Sienkiewicz", "N Dretnik", "G Leban"], "pub_year": "2020", "venue": "Scientific reports", "abstract": "A common way to learn about a system\u2019s properties is to analyze temporal fluctuations in  associated variables. However, conclusions based on fluctuations from a single entity can be"}, "filled": false, "gsrank": 132, "pub_url": "https://www.nature.com/articles/s41598-020-77660-4", "author_id": ["sJiIy5AAAAAJ", "mIwu11QAAAAJ", "", "5pAxBWsAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:Mv_aygb8YNQJ:scholar.google.com/&output=cite&scirp=131&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Mv_aygb8YNQJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 12, "citedby_url": "/scholar?cites=15303508639908298546&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Mv_aygb8YNQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.nature.com/articles/s41598-020-77660-4.pdf"}}, {"title": "Fakeflow: Fake news detection by modeling the flow of affective information", "year": "2021", "pdf_data": "FakeFlow: Fake News Detection by Modeling the\nFlow of Affective Information\nBilal Ghanem1, Simone Paolo Ponzetto2, Paolo Rosso1, Francisco Rangel3\n1Universitat Polit `ecnica de Val `encia, Spain\n2University of Mannheim, Germany\n3Symanto Research, Germany\nbigha@doctor.upv.es, simone@informatik.uni-mannheim.de,\nprosso@dsic.upv.es, francisco.rangel@symanto.com\nAbstract\nFake news articles often stir the readers\u2019 atten-\ntion by means of emotional appeals that arouse\ntheir feelings. Unlike in short news texts, au-\nthors of longer articles can exploit such affec-\ntive factors to manipulate readers by adding ex-\naggerations or fabricating events, in order to\naffect the readers\u2019 emotions. To capture this,\nwe propose in this paper to model the \ufb02ow of\naffective information in fake news articles us-\ning a neural architecture. The proposed model,\nFakeFlow, learns this \ufb02ow by combining topic\nand affective information extracted from text.\nWe evaluate the model\u2019s performance with sev-\neral experiments on four real-world datasets.\nThe results show that FakeFlow achieves su-\nperior results when compared against state-of-\nthe-art methods, thus con\ufb01rming the impor-\ntance of capturing the \ufb02ow of the affective in-\nformation in news articles.\n1 Introduction\nIn today\u2019s information landscape, fake news are\nused to manipulate public opinion (Zhou and Za-\nfarani, 2018) by reshaping readers\u2019 opinions re-\ngarding some issues. In order to achieve this goal,\nauthors of fake news\u2019 narratives need to capture the\ninterest of the reader. Thus, they are putting efforts\nto make their news articles look more objective and\nrealistic. This is usually done by adding misleading\nterms or events that can have a negative or positive\nimpact on the readers\u2019 emotions.\nShort text false information, e.g., fake claims or\nmisleading headlines, might be less harmful than\nnews articles. They may have some eye-catching\nterms that aim to manipulate the readers\u2019 emotions\n(Chakraborty et al., 2016). In many cases, the iden-\nti\ufb01cation of this kind of exaggeration in short state-\nments can unmask the fabrication. On the other\nhand, in fake news articles the authors exploit the\nlength of the news to conceal their fabricated story.This fact exposes the readers to be emotionally\nmanipulated while reading longer texts that have\nseveral imprecise or fabricated plots. The \ufb02ow\nof information has been investigated for different\ntasks: Reagan et al. (2016) studied the emotional\narcs in stories in order to understand complex emo-\ntional trajectories; Maharjan et al. (2018) model\nthe \ufb02ow of emotions over a book and quantify its\nusefulness for predicting success in books; Kar\net al. (2018) explore the problem of creating tags\nfor movies from plot synopses using emotions.\nUnlike previous works (Rashkin et al., 2017; Shu\net al., 2018; Castelo et al., 2019; Ghanem et al.,\n2020) that discarded the chronological order of\nevents in news articles, in this work we propose a\nmodel that takes into account the affective changes\nin texts to detect fake news. We hypothesize that\nfake news has a different distribution of affective\ninformation across the text compared to real news,\ne.g. more fear emotion in the \ufb01rst part of the article\nor more overall offensive terms, etc. Therefore,\nmodeling the \ufb02ow of such information may help\ndiscriminating fake from real news. Our model\nconsists of two main sub-modules, topic-based and\naffective information detection. We combine these\ntwo sub-modules since a news article\u2019s topic may\nhave a correlation with its affective information.\nFor example, a fake news article about Islam or\nBlack people is likely to provoke fear and express\nnegative sentiment while another fake news that is\nin favor of a particular politician might try to evoke\nmore positive emotions and also express some ex-\naggerations.\nThe contributions of our work are as follows:\n\u2022We design a model that detects fake news arti-\ncles by taking into account the \ufb02ow of affective\ninformation1.\n1Available at https://github.com/bilalghanem/fake \ufb02owarXiv:2101.09810v1  [cs.CL]  24 Jan 2021\n\u2022Extensive experiments on four standard datasets\ndemonstrate the effectiveness of our model over\nstate-of-the-art alternatives.\n\u2022We build a novel fake news dataset, called Multi-\nSourceFake, that is collected from a large set of\nwebsites and annotated on the basis of the joint\nagreement of a set of news sources.\n2 Related Work\nPrevious work on fake news detection is mainly\ndivided into two main lines, namely with a focus\non social media (Zubiaga et al., 2015; Aker et al.,\n2017; Ghanem et al., 2019) or online news articles\n(Tausczik and Pennebaker, 2010; Horne and Adali,\n2017; Rashkin et al., 2017; Barr \u00b4on-Cedeno et al.,\n2019). In this work we focus on the latter one. Fact-\nchecking (Karadzhov et al., 2017; Zlatkova et al.,\n2019; Shu et al., 2019a) is another closely related\nresearch topic. However, fact-checking targets only\nshort texts (that is, claims) and focuses on using\nexternal resources (e.g. Web, knowledge sources)\nto verify the factuality of the news. The focus in\nprevious work on fake news detection is mainly on\nproposing new feature sets. Horne and Adali (2017)\npresent a set of content-based features, including\nreadability (number of unique words, SMOG read-\nability measure, etc.), stylistic (frequency of part-\nof-speech tags, number of stop words, etc.) and psy-\ncholinguistic features (i.e., several categories from\nthe LIWC dictionary (Tausczik and Pennebaker,\n2010)). When these features are fed into a Support\nVector Machine (SVM) classi\ufb01er and applied, for\ninstance, to the task of distinguishing satire from\nreal news, they obtain high accuracies. Using the\nsame features for the task of fake news detection,\nhowever, results in somewhat lower scores. P \u00b4erez-\nRosas et al. (2018) propose a model (FakeNewsDe-\ntector) that uses a feature set consisting of unigrams\nand bigrams, psycholinguistic, readability, punctu-\nation and dependency-based syntactic features, and\nthey evaluate the performance of their model in a\ncross-domain experiment. Rashkin et al. (2017)\nuse a model based on ngram features with a Max-\nEntropy classi\ufb01er and apply it to a dataset with\ndifferent types of fake news articles (e.g., satire,\nhoax, propaganda, etc.). Similar to the previous\nwork, the authors evaluate their system\u2019s perfor-\nmance on in-domain and out-of-domain test sets,\nrespectively. News, and in particular fake news, are\ndynamic in nature and change constantly. In order\nto approach the dynamic nature of news, Casteloet al. (2019) propose a topic-agnostic model (Top-\nicAgnostic) that is based on morphological (count\nof part-of-speech tags), psycholinguistic (personal\nconcerns, affection, and perception categories from\nthe LIWC dictionary), readability (Gunning Fog\nmetric, etc.) and Web-Markup features to capture\npatterns of the Web pages\u2019 layout (frequency of ad-\nvertisements, presence of an author name, etc.). All\nof the morphological, psycholinguistic and read-\nability features in the TopicAgnostic model were\nextracted from headlines and texts of the news ar-\nticles. The approach obtains a better performance\nthan FakeNewsDetector on three different datasets\nusing a SVM classi\ufb01er. FakeNewsTracker (Shu\net al., 2019b) is a deep neural network-based model\nthat consists of two branches: one encodes news\narticle texts and the other encodes social media en-\ngagements (e.g., tweets and their replies). A similar\nmodel called Emotionally Infused Network (EIN)\nis proposed in Ghanem et al. (2020). EIN encodes\nthe text of the article and their affective content,\nbased on several dictionaries, and then combines\nthe two vector representations. The authors evalu-\nate their model on a multi-class false information\ndataset and show the effectiveness of using emo-\ntion features extracted from the text. Despite the\nlarge variety of features and models that have been\nexplored in previous work, none of these works\nconsiders the sequence of affective information in\ntext; instead, they feed the entire news articles as\none segment into their models. In contrast, the aim\nof our work is to evaluate this source of informa-\ntion, using a neural architecture.\n3 The FakeFlow Model\nGiven an input document, the FakeFlow model\n\ufb01rst divides it into Nsegments. Then it uses both\nword embeddings and other affective features such\nasemotions, hyperbolic words , etc. in a way to\ncatch the \ufb02ow of emotions in the document. The\nmodel learns to pay attention to the \ufb02ow of affective\ninformation throughout the document, in order to\ndetect whether it is fake or real.\nFigure 1 shows the architecture of the FakeFlow\nmodel. The neural architecture has two main mod-\nules: The \ufb01rst module uses a Convolutional Neural\nNetwork (CNN) to extract topic-based information\nfrom articles (left branch). The second module\nmodels the \ufb02ow of the affective information within\nthe articles via Bidirectional Gated Recurrent Units\n(Bi-GRUs) (right branch).\nFigure 1: The architecture of the FakeFlow model.\n3.1 Topic-based Information\nGiven a segment n2Nof words, the model \ufb01rst\nembeds words to vectors through an embedding ma-\ntrix. Then it uses a CNN that applies convolution\nprocesses and max pooling to get an abstractive\nrepresentation of the input segment. This repre-\nsentation highlights important words, in which the\ntopic information of the segment is summarized.\nThen it applies a fully connected layer on the out-\nput segments to get a smaller representation ( vtopic)\nfor later concatenation with the representation of\naffective information:\nvtopic =f(Wacnn v+ba)\nwhereWaandbaare the corresponding weight ma-\ntrix and bias terms, and fis an activation function\nsuch as ReLU, tanh, etc.\nKey to FakeFlow is its ability to capture the rele-\nvance of the affective information with respect to\nthe topics. For this, we concatenate the topic sum-\nmarized vector vtopic with the representation vector\nva\u000bect , aimed at capturing the affective information\nextracted from each segment (Section 3.2).\nvconcat =vtopic\bva\u000bect\nTo merge the different representations and capture\ntheir joint interaction in each segment, the model\nprocesses the produced concatenated vector vconcat\nwith another fully connected layer:\nvfc=f(Wcvconcat +bc)In order to create an attention-focused representa-\ntion of the segments to highlight important ones\nand to provide the model with the ability to weight\nsegments differently according to the similarity\nof neighboring segments, the model applies a\ncontext-aware self-attention mechanism (Zheng\net al., 2018) on vfc. This is a crucial step, as the\nimportance of a segment at timestep tis related\nto the other segments since they share the same\ncontext in the news article. Moreover, applying the\nattention layer can help us understand which fea-\ntures are most relevant by showing to which words\nthe network attends to during learning. The output\nof the attention layer is an attention matrix ltwith\nscores for each token at each timestep.\n3.2 Affective Flow of Information\nTo model the affective information \ufb02ow in the news\narticles, we choose the following lexical features,\nunder the assumption that they have a different\ndistribution across the articles\u2019 segments. We use\na term frequency representation weighted by the\narticles\u2019 length to extract the following features\nfrom each segment n:\n\u2022Emotions : We use emotions as features to detect\ntheir change among articles\u2019 segments. For that\nwe use the NRC emotions lexicon (Mohammad\nand Turney, 2010) that contains \u001814K words\nlabeled using the eight Plutchik\u2019s emotions ( 8\nFeatures ).\n\u2022Sentiment : We extract the sentiment from the\ntext, positive andnegative , again using the NRC\nlexicon (Mohammad and Turney, 2010) ( 2 Fea-\ntures ).\n\u2022Morality : We consider cue words from the Moral\nFoundations Dictionary2(Graham et al., 2009)\nwhere words are assigned to one (or more) of the\nfollowing categories: care, harm, fairness, un-\nfairness (cheating), loyalty, betrayal, authority,\nsubversion, sanctity anddegradation (10 Fea-\ntures ).\n\u2022Imageability : We use a list of words rated by\ntheir degree of abstractness and imageability3.\nThese words have been extracted from the MRC\npsycholinguistic database (Wilson, 1988) and\nthen using a supervised learning algorithm, the\n2https://moralfoundations.org/other-materials/\n3https://github.com/ytsvetko/metaphor/tree/master/\nresources/imageability\nwords have been annotated by the degrees of\nabstractness and imageability. The list contains\n4,295 and 1,156 words rated by their degree of\nabstractness and imageability, respectively ( 2\nFeatures ).\n\u2022Hyperbolic : We use a list of\u0018350 hyperbolic\nwords (Chakraborty et al., 2016), i.e., words with\nhigh positive or negative sentiment (e.g., terri-\nfying, breathtakingly, soul-stirring, etc.). The\nauthors extracted these eye-catching words from\nclickbaits news headlines ( 1 Feature ).\nTo model the \ufb02ow of the above features, we rep-\nresent each segment of an article by a vector va\u000bect\ncapturing all 23 features listed above. Then we\nfeed the document\u2019s vectors to a Bi-GRU network\nto summarize the contextual \ufb02ow of the features\nfrom both directions4to obtainv\row.\nGiven the segments\u2019 \ufb02ow representation ( v\row)\nof an article and their relevance to the topics ( lt),\nFakeFlow applies a dot product operation and then\naverages the output matrix across the segments to\nget a compact representation vcompact , which is\nthen fed into a fully connected layer:\nv\fnal =f(Wdvcompact +bd)\nFinally, to generate the overall factuality label of\nan article, a softmax layer is applied to the output\nof the fully connected layer.\n4 Fake News Datasets\nDespite the recent efforts for debunking online fake\nnews, there is a dearth of publicly available datasets.\nMost of the available datasets are small in size (e.g.,\nthe Politifact5dataset in (Shu et al., 2018) has \u0018700\navailable articles, the Celebrity dataset in (P \u00b4erez-\nRosas et al., 2018) has \u0018500 articles, etc.), their\ntest parts have not been manually annotated, or\nhave been collected from a very small number of\nnews sources. Nonetheless, we evaluate FakeFlow\non three different available datasets to demonstrate\nits performance. In addition, we create our own\ndataset. Table 1 gives an overview of the datasets\nthat we used in our work.\nMultiSourceFake : We rely on different resources\nfor creating the training and test portions of the\ndataset, so as to provide a challenging benchmark.\n4During prototyping, GRU produced better overall results\nthan LSTM.\n5https://www.politifact.com/For the training part, we use OpenSources.co\n(OS), MediaBiasFactCheck.com (MBFC), and Poli-\ntiFact6news websites\u2019 lists. OS list contains 560\ndomains, MBFC list has 548 domains, and the Poli-\ntiFact list has 227 domains. These lists have been\nannotated by professional journalists. The lists con-\ntain domains of online news websites annotated\nbased on the content type (as in the OS news list:\nsatire, reliable , etc.; and in the PolitiFact news list:\nimposter, parody, fake news , etc.) or from a factu-\nality perspective (as in the MBFC news list: low,\nmedium, and high factuality). From the OS list,\nwe select domains that are in one of the following\ncategories: fake, bias, reliable, hate, satire, orcon-\nspiracy . We consider domains under the reliable\ncategory as real news sources, and the rest as fake.\nThe PolitiFact list is different from the OS list since\nit has only labels for domains that are either fake\nor with mixed content. We discard the mixed ones7\nand map the remaining ones to the fake news la-\nbel. Finally, we select from the MBFC list those\ndomains that are annotated either as high or low\nfactual news and we map them to real and fake\nlabels, respectively. Out of these three \ufb01nal lists,\nwe select only those domains for our dataset that\nare annotated in all lists in a consistent way; for ex-\nample, we discard those domains that are annotated\nas real in the OS list but their label in the MBFC\nlist is fake (low factuality). The \ufb01nal list contains\n85 news websites. We now proceed by projecting\nthe domain-level ground truth onto the content of\nthose domains and randomly sample articles, with\na maximum of 100 news articles per domain.8\nFor the test part, we use the leadstories.com fact\nchecking website for which professional journalists\nannotated online news articles on the article level as\nfake or real. We do not follow the way we annotate\nthe training part since the projection of the domain-\nlevel ground truth inevitably introduces noise. The\njournalists that annotated leadstories.com assigned\na set of labels to the fake news articles like, e.g.,\nfalse, no evidence, satire, misleading , etc.; we map\nthem all to the fake label. In addition, we discard\nall articles that are multimedia-based. After col-\nlecting the news articles, we postprocess them by\ndiscarding very short articles (less than 30 words).\nThe test part includes 689 fake news articles. We\ncomplement the set with a sample of 1,000 real\n6https://www.politifact.com/article/2017/apr/20/politifacts-\nguide-fake-news-websites-and-what-they/\n7The discarded label is \u201cSome fake stories\u201d.\n8Some of the websites included less than 100 news articles.\nFigure 2: The distribution of the documents\u2019 length in\nthe MultiSourceFake dataset.\nName Total Training Test\nMultiSourceFake 11,397 9,708 1,689\nTruthShades 23,000 16,000 4,000 - 3,000\nPoliticalNews 14,240 11,392 2,848\nFakeNewsNet 20,208 16,156 4,039\nTable 1: Number of articles in the datasets.\nnews articles from the training part. The overall\ndataset consists of 5,994 real and 5,403 fake news\narticles. The average document length (number\nof words) in the MultiSourceFake dataset is 422\nwords, and the 95th percentile value is 942. Figure\n2 shows the distribution of the documents\u2019 length\nin the dataset.\nTruthShades : This dataset has been proposed in\nRashkin et al. (2017). The dataset was crawled\nfrom a set of domains that are annotated by pro-\nfessional journalists as either propaganda, hoax,\nsatire , orreal. The dataset has been built from the\nEnglish Gigaword corpus for real news, and other\nseven unreliable domains that annotated in one of\nthe three previous false information labels.\nPoliticalNews : Due to the fact that: \u201ca classi\ufb01er\ntrained using content from articles published at a\ngiven time is likely to become ineffective in the fu-\nture\u201d (Castelo et al., 2019), the authors of this work\ncollected a dataset by crawling news websites in\nbetween the years 2013 to 2018 in order to evaluate\ntheir model\u2019s performance on different years.\nFakeNewsNet : is a fake news repository that con-\nsists of two comprehensive datasets, one collected\nusing claims from PolitiFact and the other from\nthe GossipCop fact checking website. Given the\nlarge number of true and false claims from these\ntwo fact checking websites, Shu et al. (2018) built\nnews datasets that contain visual and textual news\narticles content and social media information by\nsearching Twitter for users who shared news. Out\nof the whole collected information, we use only the\ntextual information of news articles, which is the\npart we are interested in.5 Experiments\nExperimental setup. We split the articles\u2019 text\nintoNsegments and set the maximum length of\nsegments to 800 words, applying zero padding to\nthe ones shorter than 800 words. Concerning the\nFakeFlow hyper-parameters, we tune various pa-\nrameters ( dropout, the size of the dense layers, ac-\ntivation functions, CNN \ufb01lter sizes and their num-\nbers, pooling size, size of the GRU layer, and the op-\ntimization function ) (see Appendix A for the search\nspace) using early stopping on the validation set. In\naddition to these hyper-parameters, we also use the\nvalidation set to pick the best number of segments\n(N). Regarding the MultiSourceFake dataset, we\nuse 20% of the training part for validation. We rep-\nresent words using pre-trained word2vec Google-\nNews-300 embeddings9. For evaluation, we follow\nthe setup from related work. We report accuracy\nand weighted precision, recall and F1 score, and\nmacro F1 for some datasets where the classes are\nimbalanced.\nBaselines. To evaluate the performance of our\nmodel, we use a combination of fake news detec-\ntion models and deep neural network architectures:\n\u2022CNN, LSTM : We use CNN and LSTM mod-\nels and validate their performance when treating\neach document as one fragment. We experiment\nwith different hyper-parameters and report re-\nsults for the ones that performed best on the\nvalidation set.\n\u2022HAN : The authors of (Yang et al., 2016) pro-\nposed a Hierarchical Attention Networks (HAN)\nmodel for long document classi\ufb01cation. The pro-\nposed model consists of two levels of attention\nmechanisms, i.e., word and sentence attention.\nThe model splits each document into sentences\nand learns sentence representations from words.\n\u2022BERT : is a text representation model that\nshowed superior performance on multiple natu-\nral language processing (NLP) benchmarks (De-\nvlin et al., 2019). We use the pre-trained bert-\nbase-uncased version which has 12-layers and\nyields output embeddings with a dimension of\nsize 768. We feed the hidden representation of\nthe special [CLS] token, that BERT uses to sum-\nmarize the full input sentence, to a softmax layer.\nExperimentally, we found that \ufb01ne-tuning BERT\n9https://code.google.com/archive/p/word2vec/\nlayers gives a higher performance. It is worth\nmentioning that BERT input length is limited to\n512 word pieces (sub-words level) (Devlin et al.,\n2019), thus, we discard the rest of the text in\nlong news articles.\n\u2022Fake News Detection Models : We compare\nour model to several fake news detection mod-\nels. We use Horne and Adali (2017) model,\nFakeNewsDetector (P \u00b4erez-Rosas et al., 2018),\nRashkin et al. (2017) model, and EIN (Ghanem\net al., 2020).10\n\u2022Longformer : Giving that Transformer-based\nmodels (i.e. BERT) are unable to process long\nsequences, we use Longformer (Beltagy et al.,\n2020), which is a SOTA model for long docu-\nment tasks. In our experiments, we set the max\nsequence length to 1500 to handle documents\nthat have more than 512 tokens in the Multi-\nSourceFake dataset (see Figure 2). Also, we\nfound that \ufb01ne-tuning the Longformer model\ngives better results and a much faster conver-\ngence.\n6 Results and Analysis\nTable 2 presents the results of our proposed model\nand the baselines on the MultiSourceFake dataset.\nOur best result was achieved by using 10 as the\nnumber of segments ( N, as found on the valida-\ntion data). In Figure 3 we show the model\u2019s per-\nformance for segments of different length.11In\ngeneral, the results show that models that are based\non either word ngrams or word embeddings are\nperforming better than other models that use hand-\ncrafted features, e.g. Horne and Adali (2017). Also,\ndespite the huge amount of data used to train the\nBERT model, the results show that BERT performs\nworse than FakeFlow and also fails to outperform\nsome of the other models. We speculate that this\nis due to the fact that the input length in BERT is\nlimited to 512 words, as we mentioned previously,\nand a large portion of the news articles in the Mul-\ntiSourceFake dataset has a length greater than 512\nwords. The results of the Longformer model con-\n\ufb01rm our claim regarding the documents\u2019 length and\nshow a signi\ufb01cantly higher F1 score than the BERT\n10We only compare TopicAgnostic on the dataset the au-\nthors proposed (PoliticalNews).\n11In the case of N=1 in Figure 3, we set the maximum\nsegment length to 1500 words instead of 800 to not lose parts\nof the longer articles.\nFigure 3: The accuracy and F1 results of the FakeFlow\nmodel using different N(number of segments).\nModel Acc. Prec. Rec. F1macro\nMajority Class 0.59 0.35 0.59 0.37\nHorne and Adali (2017) 0.80 0.75 0.78 0.80\nFakeNewsDetector 0.86 0.86 0.86 0.86\nLSTM 0.91 0.86 0.91 0.90\nCNN 0.91 0.89 0.89 0.91\nRashkin et al. (2017) 0.92 0.92 0.92 0.92\nBERT 0.93 0.93 0.94 0.93\u2021\nEIN 0.93 0.94 0.93 0.93\u2021\nHAN 0.94 0.94 0.94 0.93\u2021\nLongformer 0.97 0.97 0.97 0.97\u2020\nFakeFlow 0.96 0.93 0.97 0.96\nFakeFlow \u2013 Topic only 0.91 0.89 0.90 0.90\nFakeFlow \u2013 Affective only 0.61 0.38 0.60 0.40\nTable 2: Results on the MultiSourceFake dataset. (\u2021) in-\ndicates a statistically signi\ufb01cant improvement of Fake-\nFlow over the referred model using McNemar test; (\u2020)\nindicates no statistically signi\ufb01cant improvement over\nFakeFlow .\nmodel. This emphasizes that despite the strong per-\nformance of BERT on multiple NLP benchmarks, it\nis unable to handle long text documents, in contrast,\ne.g., to vanilla text categorization (Adhikari et al.,\n2019). In addition, Longformer\u2019s results show a\nhigher F1 score than the FakeFlow model, yet, the\ndifference is statically insigni\ufb01cant.\nTo isolate the contribution of topical vs. affective\ninformation we run two simpli\ufb01ed versions of our\narchitecture, each consisting of the networks to\ncapture topical and affective information only. The\nresults show that the \ufb02ow of the affect information\nhas a weak performance when used alone; this\nemphasizes that affective information of a news\narticle is a meaningful, yet complementary source\nof information.\nPerformance on Multiple Datasets. In Table\n3 we compare the performance of the FakeFlow\nmodel to SOTA results on the other datasets we in-\ntroduced in Section 4. The TruthShades dataset has\ntwo test sets, in-domain and out-of-domain. In the\nin-domain con\ufb01guration, training and test articles\ncome from the same sources, and from different\nsources in out-of-domain con\ufb01guration. The re-\nsults demonstrate that FakeFlow achieves a better\nTruthShades Acc. Prec. Rec. F1macro\nOut-of-domain\nRashkin et al. (2017) 0.67 0.70 0.67 0.65\nFakeFlow 0.68 0.69 0.68 0.68\nIn-domain\nRashkin et al. (2017) 0.91 0.91 0.91 0.91\nFakeFlow 0.96 0.96 0.96 0.96\nPoliticalNews Acc. Prec. Rec. F1weighted\nTopicAgnostic 0.87 0.87 0.87 0.87\nFakeFlow 0.88 0.88 0.88 0.88\nFakeNewsNet Acc. Prec. Rec. F1weighted\nFakeNewsTracker 0.80 0.82 0.75 0.79\nOne-Hot LR 0.82 0.90 0.72 0.80\nFakeFlow 0.86 0.86 0.86 0.85\nTable 3: Results on multiple datasets. We compare the\nFakeFlow model to SOTA models on each dataset.\nF1 on both test sets. In a similar way, the results on\nthe PoliticalNews dataset show that FakeFlow also\noutperforms the TopicAgnostic model, although\nthe gap in results is not very large. Finally, regard-\ning the FakeNewsNet dataset, it looks that the deep\nlearning-based model (FakeNewsTracker) does not\nachieve a good performance comparing to the other\nproposed baseline by the authors, which is a Logis-\ntic Regression (LR) classi\ufb01er with one-hot vectors\nof the news articles\u2019 text. Furthermore, it seems\nthat a simple word-based model works better than\na more sophisticated model that incorporates so-\ncial media and context information. The FakeFlow\nmodel, on the other hand, achieves a better result,\noutperforming both the FakeNewsTracker and the\nLR baseline.\nTopic-Aware Model. Constantly, new events are\ncovered by news agencies. These events are dif-\nferent from the old ones in terms of discourse and\ntopic. Therefore, a fake news detector trained on\nnews articles from years back is unable to detect\nrecent news. In this experiment, we are evaluating\nour approach on the PoliticalNews dataset that is\nconstructed from news distributed across different\nyears (2013 to 2018). Following the experimental\nsetup in (Castelo et al., 2019), we train the Fake-\nFlow model on news from one year and test on\nthe other years, one year at a time for testing. For\nexample, we train the model on news from 2013\nand we test on news from 2015. Note that each test\nset is associated with 5 results, one for each year.\nFigure 4 shows the average accuracy for each test\nset. We compare FakeFlow to the TopicAgnostic\nmodel that proved to be effective at detecting fake\nFigure 4: Topic aware experiment\u2019s results.\nnews from different years. It is worth mentioning\nthat the features of the TopicAgnostic model have\nbeen extracted from both headlines and text of the\nnews articles. However, the results show that both\nmodels have a similar performance, except for the\n2013 test set where FakeFlow achieves a higher\naccuracy with a difference of 7%. The experiment\nshows that FakeFlow is capable of detecting fake\nnews from different years, with a \ufb02at performance\nacross the years.\nAttention Weights. The proposed FakeFlow\nmodel shows that taking into account the \ufb02ow of\naffective information in fake news is an important\nperspective for fake news detection. We argue that\nbeing able to better understand the behaviour of\nthe model can make it more transparent to the end-\nusers. Figure 5 illustrates this by showing the at-\ntention weights of a fake news article across the 10\nsegments (left bar).12The \ufb01gure shows that Fake-\nFlow attends more to the beginning of the article.\nFor better understanding, we match the affective\ninformation with the attention weights. Regarding\nthe news text in the \ufb01gure, the emotions features13\nshow a clear example of how fake news articles\ntry to manipulate the reader. It looks as if the ex-\nistence of fear, sadness , and surprise emotions at\nthe beginning of the article have triggered the at-\ntention on this part. Towards the end of the article,\non the other hand, we can notice that such neg-\native emotions do not exist, while emotions like\njoyandanticipation appear. This exempli\ufb01es how\nfake news try to attract the readers\u2019 attention in\nthe \ufb01rst part of the text. Regarding the morality\nfeatures, we only match the word \u201ckill\u201d with the\nharm category. Also, for the hyperbolic feature,\nwe match the words \u201cterrifying\u201d and \u201cpowerful\u201d.\nIn the same manner, both morality andhyperbolic\nfeatures match words that occur at the beginning\nof the article. Lastly, for both sentiment andim-\n12We averaged the attention weight matrix along the\ntimesteps (number of segments) representations.\n13Words with multiple colors mean that they have been\nannotated with multiple emotion types in the NRC lexicon.\nageability features, we are not able to \ufb01nd a clear\ninterpretation in this example where many words\nacross the segments match.\nReal vs. Fake Analysis. In Table 4 we present an\nanalysis on both real and fake news articles. The\nanalysis gives an intuition to the reader on the dis-\ntribution of the used features across the articles\u2019\nsegments. It shows that an emotion like fearhas on\naverage a higher difference between the \ufb01rst and\nthe last segment in fake news than in real ones (see\nFigure 6 for a visualized distribution). Also, a fea-\nture like hyperbolic has a higher average value and\nlower standard deviation across all segments for\nfake news than real news, thus indicating that fake\nnews have a higher amount of hyperbolic words\nwith similarly high values.\nFigure 6: The \ufb02ow of the Fear emotion in fake (\u0011) and\nreal (\u2022) news articles in the MultiSourceFake dataset.\nY-axis presents the average number of Fear emotion\nwords in 0-1 scale; the X-axis presents the document\ntext, divided into 10 segments.\n7 Conclusion\nIn this paper we presented FakeFlow, a model that\ntakes into account the \ufb02ow of affective informa-\ntion ( emotions, sentiment, hyperbolic words , etc.)\nin texts to better detect fake news articles. The\nmodel receives as input a text, segmented into\nsmaller units, instead of processing one long frag-\nment. This enables it to learn the \ufb02ow of affective\ninformation by modeling the interaction between\nthe topic and affective terms in the news article.\nWe evaluated our model on four different datasets\nand compared it to several strong baselines. The\nextensive experiments show the effectiveness of\nFakeFlow over state-of-the-art models. Although\nFakeFlow was trained using a limited amount of\ntext, the results demonstrated that it achieves results\non-par with resource-hungry models (e.g. BERT\nand Longformer). In future work, we plan to ex-\ntend our dataset and study more \ufb01ne-grained news\ntypes, e.g. propaganda, from an emotional per-\nspective. Moreover, we plan to investigate how\nwe can replace the lexicon-based information withlanguage-independent approaches in an attempt to\nmake our model multilingual.\nAcknowledgment\nThe \ufb01rst author would like to thank Ines Rehbein\nand Ana Uban for their valuable comments and\nsuggestions. The work of the third author was par-\ntially funded by the Spanish MICINN under the\nresearch project MISMIS-FAKEnHATE on MIS-\ninformation and MIScommunication in social me-\ndia: FAKE news and HATE speech (PGC2018-\n096212-B-C31) and by the Generalitat Valenciana\nunder the research project DeepPattern (PROME-\nTEO/2019/121).\nReferences\nAshutosh Adhikari, Achyudh Ram, Raphael Tang, and\nJimmy Lin. 2019. Docbert: Bert for document clas-\nsi\ufb01cation. arXiv preprint arXiv:1904.08398 .\nAhmet Aker, Leon Derczynski, and Kalina Bontcheva.\n2017. Simple open stance classi\ufb01cation for rumour\nanalysis. In Proceedings of the International Con-\nference Recent Advances in Natural Language Pro-\ncessing, RANLP 2017 , pages 31\u201339.\nAlberto Barr \u00b4on-Cedeno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the AAAI Conference on Arti\ufb01cial In-\ntelligence , volume 33, pages 9847\u20139848.\nIz Beltagy, Matthew E Peters, and Arman Cohan.\n2020. Longformer: The Long-document Trans-\nformer. arXiv preprint arXiv:2004.05150 .\nSonia Castelo, Thais Almeida, Anas Elghafari, A \u00b4ecio\nSantos, Kien Pham, Eduardo Nakamura, and Juliana\nFreire. 2019. A Topic-Agnostic Approach for Iden-\ntifying Fake News Pages. In Companion Proceed-\nings of The 2019 World Wide Web Conference , pages\n975\u2013980.\nAbhijnan Chakraborty, Bhargavi Paranjape, Sourya\nKakarla, and Niloy Ganguly. 2016. Stop Clickbait:\nDetecting and Preventing Clickbaits in Online News\nMedia. In Advances in Social Networks Analysis\nand Mining (ASONAM), 2016 IEEE/ACM Interna-\ntional Conference on , pages 9\u201316.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171\u20134186.\nFigure 5: Emotional interpretation of a fake news article by showing the attention weights (the bar on the left) and\nhighlighting the emotions in the text.\nFeaturesReal News Fake News\n\u0016first seg:\u0016last seg:\u0016all seg:\u001ball seg:\u0016first seg:\u0016last seg:\u0016all seg:\u001ball seg:EmotionsAnger 0.175 0.167 0.170 0.003 0.183 0.170 0.171 0.008\nAnticipation 0.301 0.315 0.264 0.025 0.293 0.305 0.260 0.022\nDisgust 0.095 0.101 0.095 0.004 0.096 0.091 0.091 0.007\nFear 0.254 0.250 0.238 0.010 0.265 0.226 0.238 0.011\nJoy 0.217 0.226 0.183 0.021 0.207 0.203 0.175 0.020\nSadness 0.161 0.158 0.160 0.006 0.155 0.155 0.158 0.007\nSurprise 0.140 0.144 0.123 0.012 0.142 0.123 0.120 0.008\nTrust 0.446 0.466 0.400 0.031 0.461 0.421 0.401 0.029Senti.Positive 0.599 0.623 0.558 0.030 0.608 0.591 0.554 0.032\nNegative 0.369 0.337 0.347 0.011 0.367 0.336 0.350 0.013MoralityHarm 0.007 0.011 0.007 0.002 0.008 0.013 0.007 0.002\nCare 0.026 0.023 0.019 0.004 0.021 0.022 0.019 0.003\nFairness 0.003 0.013 0.007 0.002 0.005 0.020 0.009 0.004\nUnfairness 0.000 0.000 0.001 0.000 0.001 0.000 0.001 0.001\nLoyalty 0.016 0.017 0.019 0.002 0.014 0.016 0.019 0.003\nBetrayal 0.004 0.003 0.005 0.001 0.002 0.003 0.004 0.001\nAuthority 0.025 0.032 0.026 0.003 0.024 0.028 0.026 0.002\nSubversion 0.005 0.004 0.004 0.001 0.006 0.007 0.005 0.002\nSanctity 0.005 0.005 0.004 0.001 0.005 0.006 0.005 0.002\nDegradation 0.003 0.004 0.003 0.001 0.006 0.004 0.003 0.001ImgImageability 0.845 1.203 1.144 0.122 0.877 1.184 1.145 0.124\nAbstraction 0.424 0.331 0.352 0.028 0.382 0.304 0.342 0.037\nHyperbolic 0.042 0.05 0.045 0.005 0.046 0.044 0.047 0.003\nTable 4: A quantitative analysis of the features existence across articles\u2019 segments. We present the average value\nin the \ufb01rst segment ( \u0016first seg:), the average value in the last segment ( \u0016last seg:), the average value in the all 10\nsegments (\u0016all seg:), and the standard deviation ( \u001b all seg:) of a feature across the 10 segments, both in real and\nfake news.\nBilal Ghanem, Alessandra Teresa Cignarella, Cristina\nBosco, Paolo Rosso, and Francisco Manuel Rangel\nPardo. 2019. UPV-28-UNITO at SemEval-2019\nTask 7: Exploiting Post\u2019s Nesting and Syntax Infor-\nmation for Rumor Stance Classi\ufb01cation. In Proceed-\nings of the 13th International Workshop on Semantic\nEvaluation , pages 1125\u20131131.\nBilal Ghanem, Paolo Rosso, and Francisco Rangel.\n2020. An emotional analysis of false information in\nsocial media and news articles. ACM Transactions\non Internet Technology (TOIT) , 20(2):1\u201318.\nJesse Graham, Jonathan Haidt, and Brian A Nosek.\n2009. Liberals and Conservatives Rely on Different\nSets of Moral Foundations. Journal of personality\nand social psychology , 96(5):1029\u20131046.\nBenjamin D Horne and Sibel Adali. 2017. This Just\nIn: Fake News Packs a Lot in Title, Uses Simpler,\nRepetitive Content in Text Body, More Similar to\nSatire than Real News. In Eleventh International\nAAAI Conference on Web and Social Media , pages\n759\u2013766.\nSudipta Kar, Suraj Maharjan, and Thamar Solorio.\n2018. Folksonomication: Predicting tags for movies\nfrom plot synopses using emotion \ufb02ow encoded\nneural network. In Proceedings of the 27th Inter-\nnational Conference on Computational Linguistics ,\npages 2879\u20132891.\nGeorgi Karadzhov, Preslav Nakov, Llu \u00b4\u0131s M `arquez,\nAlberto Barr \u00b4on-Cede \u02dcno, and Ivan Koychev. 2017.\nFully automated fact checking using external\nsources. In Proceedings of the International Con-\nference Recent Advances in Natural Language Pro-\ncessing, RANLP 2017 , pages 344\u2013353.\nSuraj Maharjan, Sudipta Kar, Manuel Montes-y\nG\u00b4omez, Fabio A Gonzalez, and Thamar Solorio.\n2018. Letting emotions \ufb02ow: Success prediction\nby modeling the \ufb02ow of emotions in books. arXiv\npreprint arXiv:1805.09746 .\nSaif M Mohammad and Peter D Turney. 2010. Emo-\ntions Evoked by Common Words and Phrases: Us-\ning Mechanical Turk to Create an Emotion Lexicon.\nInProceedings of the NAACL HLT 2010 workshop\non computational approaches to analysis and gener-\nation of emotion in text , pages 26\u201334. Association\nfor Computational Linguistics.\nVer\u00b4onica P \u00b4erez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic De-\ntection of Fake News. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 3391\u20133401, Santa Fe, New Mexico, USA.\nAssociation for Computational Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of Varying\nShades: Analyzing Language in Fake News and Po-\nlitical Fact-Checking. In Proceedings of the 2017\nConference on Empirical Methods in Natural Lan-\nguage Processing , pages 2931\u20132937.Andrew J Reagan, Lewis Mitchell, Dilan Kiley,\nChristopher M Danforth, and Peter Sheridan Dodds.\n2016. The emotional arcs of stories are dominated\nby six basic shapes. EPJ Data Science , 5(1):1\u201312.\nKai Shu, Limeng Cui, Suhang Wang, Dongwon Lee,\nand Huan Liu. 2019a. defend: Explainable fake\nnews detection. In Proceedings of the 25th ACM\nSIGKDD International Conference on Knowledge\nDiscovery & Data Mining , pages 395\u2013405.\nKai Shu, Deepak Mahudeswaran, and Huan Liu. 2019b.\nFakeNewsTracker: a Tool for Fake News Collection,\nDetection, and Visualization. Computational and\nMathematical Organization Theory , 25(1):60\u201371.\nKai Shu, Deepak Mahudeswaran, Suhang Wang, Dong-\nwon Lee, and Huan Liu. 2018. FakeNewsNet: A\nData Repository with News Content, Social Context\nand Dynamic Information for Studying Fake News\non Social Media. arXiv preprint arXiv:1809.01286 .\nYla R Tausczik and James W Pennebaker. 2010. The\nPsychological Meaning of Words: LIWC and Com-\nputerized Text Analysis Methods. Journal of lan-\nguage and social psychology , 29(1):24\u201354.\nMichael Wilson. 1988. MRC Psycholinguistic\nDatabase: Machine-usable dictionary, version 2.00.\nBehavior research methods, instruments, & comput-\ners, 20(1):6\u201310.\nZichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,\nAlex Smola, and Eduard Hovy. 2016. Hierarchi-\ncal Attention Networks for Document Classi\ufb01cation.\nInProceedings of the 2016 conference of the North\nAmerican chapter of the association for computa-\ntional linguistics: human language technologies ,\npages 1480\u20131489.\nGuineng Zheng, Subhabrata Mukherjee, Xin Luna\nDong, and Feifei Li. 2018. Opentag: Open Attribute\nValue Extraction from Product Pro\ufb01les. In Proceed-\nings of the 24th ACM SIGKDD International Con-\nference on Knowledge Discovery & Data Mining ,\npages 1049\u20131058.\nXinyi Zhou and Reza Zafarani. 2018. Fake news: A\nsurvey of research, detection methods, and opportu-\nnities. arXiv preprint arXiv:1812.00315 .\nDimitrina Zlatkova, Preslav Nakov, and Ivan Koychev.\n2019. Fact-checking meets fauxtography: Verify-\ning claims about images. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP) , pages 2099\u20132108.\nArkaitz Zubiaga, Maria Liakata, Rob Procter, Kalina\nBontcheva, and Peter Tolmie. 2015. Towards Detect-\ning Rumours in Social Media. In AAAI Workshop:\nAI for Cities , pages 35\u201341.\nA Appendices\nA.1 Hyper-parameters\nFor FakeFlow hyper-parameters, we tune the fol-\nlowing parameters with the their correspondent\nsearch space:\n\u2022Dropout: random selection in the range [0.1,\n0.6],\n\u2022 Dense layers: [8, 16, 32, 64, 128],\n\u2022 Activation functions: [selu, relu, tanh, elu],\n\u2022CNN \ufb01lters\u2019 sizes: [(2, 3, 4), (3, 4, 5), (4, 5,\n6), (3, 5), (2, 4), (4,), (5,), (3, 5, 7), (3, 6)],\n\u2022Numbers of CNN \ufb01lters: [4, 8, 16, 32, 64,\n128],\n\u2022 Pooling size: [2, 3],\n\u2022 GRU units: [8, 16, 32, 64, 128],\n\u2022Optimization function: [adam, adadelta, rm-\nsprop, sgd],\n\u2022For the early stopping, we set the \u2018patience\u2018\nparameter to 4 and we set the epochs number\nto 50.\nFor the parameters selection, we use hyperopt14\nlibrary that receives the above search space to ran-\ndomly select different Ncombination of parame-\nters (trials). We use a small value of Nin all of our\nexperiments to avoid overdrawn \ufb01netuning; we set\nNto 35.\nA.2 Topic Aware experiments\nIn Figure 4, we present the average accuracy of our\nmodel when we train on different years and test a\nspeci\ufb01c one. In the following we show the results\nbefore we averaged them.\nTrainTest2013 2014 2015 2016 2017 2018\n2013 0.00 0.82 0.74 0.76 0.78 0.74\n2014 0.84 0.00 0.79 0.76 0.81 0.74\n2015 0.79 0.81 0.00 0.82 0.80 0.82\n2016 0.80 0.76 0.87 0.00 0.85 0.79\n2017 0.79 0.82 0.76 0.80 0.00 0.85\n2018 0.79 0.75 0.81 0.83 0.83 0.00\nAverage 0.80 0.79 0.79 0.79 0.81 0.79\nTable 5: FakeFlow results for each train-test run for the\nTopic-Aware experiment.\n14https://github.com/hyperopt/hyperopt", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Fakeflow: Fake news detection by modeling the flow of affective information", "author": ["B Ghanem", "SP Ponzetto", "P Rosso", "F Rangel"], "pub_year": "2021", "venue": "arXiv preprint arXiv \u2026", "abstract": "Fake news articles often stir the readers' attention by means of emotional appeals that  arouse their feelings. Unlike in short news texts, authors of longer articles can exploit such"}, "filled": false, "gsrank": 133, "pub_url": "https://arxiv.org/abs/2101.09810", "author_id": ["mjrzZZcAAAAJ", "VmIFG0EAAAAJ", "HFKXPH8AAAAJ", "1Jfq3xIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:hdA1Nk06a88J:scholar.google.com/&output=cite&scirp=132&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=hdA1Nk06a88J&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 105, "citedby_url": "/scholar?cites=14946103891655512197&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:hdA1Nk06a88J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2101.09810"}}, {"title": "The sally smedley hyperpartisan news detector at SemEval-2019 task 4", "year": "2019", "pdf_data": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019) , pages 1057\u20131061\nMinneapolis, Minnesota, USA, June 6\u20137, 2019. \u00a92019 Association for Computational Linguistics1057The Sally Smedley Hyperpartisan News Detector at SemEval-2019 Task 4:\nLearning Classi\ufb01ers with Feature Combinations and Ensembling\nKazuaki Hanawa*1;2, Shota Sasaki*1;2, Hiroki Ouchi1;2, Jun Suzuki2;1, Kentaro Inui2;1\n(* equal contribution)\n1RIKEN AIP,2Tohoku University\nfhanawa, sasaki.shota, hiroki.ouchi, jun.suzuki, inui g\n@ecei.tohoku.ac.jp\nAbstract\nThis paper describes our system submitted to\nthe formal run of SemEval-2019 Task 4: Hy-\nperpartisan news detection. Our system is\nbased on a linear classi\ufb01er using several fea-\ntures, i.e., 1) embedding features based on\nthe pre-trained BERT embeddings, 2) arti-\ncle length features, and 3) embedding fea-\ntures of informative phrases extracted from\ntheby-publisher dataset. Our system\nachieved 80.9% accuracy on the test set for\nthe formal run and got the 3rd place out of 42\nteams.\n1 Introduction\nHyperpartisan news detection (Kiesel et al., 2019;\nPotthast et al., 2018) is a binary classi\ufb01cation task,\nin which given a news article text, systems have\nto decide whether or not it follows a hyperparti-\nsan argumentation, i.e., \u201cwhether it exhibits blind,\nprejudiced, or unreasoning allegiance to one party,\nfaction, cause, or person\u201d (2019). As resources\nfor building such a system, the by-publisher\nandby-article datasets are provided by the\norganizer. The by-publisher dataset is a col-\nlection of news articles labeled with the over-\nall bias of the publisher as provided by Buz-\nzFeed journalists or MediaBiasFactCheck.com.\nTheby-article dataset is a collection labeled\nthrough crowdsourcing on an article basis. This\ndata contains only the articles whose labels are\nagreed by all the crowd-workers. The performance\nmeasure is accuracy on a balanced set of articles.\nOur system is based on a linear classi\ufb01er\nusing several types of features mainly consist-\ning of 1) embedding features based on the pre-\ntrained BERT embeddings (Devlin et al., 2018)\nand 2) article length features and 3) embedding\nfeatures of informative phrases extracted from\nby-publisher dataset. Our system achieved80.9% accuracy on the test set for the formal run\nand got 3rd place out of 42 teams in the formal\nrun.\n2 System Description\nThis section \ufb01rst presents an overview of our sys-\ntem and then elaborate on the feature set.\n2.1 Overview of Our System\nOur system is based on a linear classi\ufb01er that mod-\nels the conditional probability distribution over the\ntwo labels (positive or negative) given features.\nLetfbe a feature vector. Wdenotes a trainable\nweight matrix, and bis a trainable bias vector,\nwhere f2RD,W2RD\u00022andb2R2, respec-\ntively. Then, we compute the conditional proba-\nbility as follows:\ny=softmax (W>f+b): (1)\nwhere, softmax (\u0001)represent the softmax function\nthat receives an N-dimensional vector xand re-\nturns another Ndimensional vector, namely:\nsoftmax (x) =exp(x)P\niexp(xi); (2)\nandx= (x1;:::;x N)>. After the softmax com-\nputation, we obtain the two-dimensional vector\ny2R2. We assume that the \ufb01rst dimension of\nthis vector represents the probability of the pos-\nitive label, and the second one represents that of\nthe negative label.\nTo boost the performance, we concatenate three\ntypes of features, f1,f2, and f3, into the single fea-\nture vector f, where f12RD1,f22RD2and\nf32RD3andD=D1+D2+D3.\nAsf1,f2andf3, we design the following fea-\ntures.\n\u000ff1: BERT feature (Section 2.2)\n1058\u000ff2: Article length feature (Section 2.3)\n\u000ff3: Informative phrase feature (Section 2.4)\nFor training our classi\ufb01ers, we used only\nthe by-article dataset but not the\nby-publisher dataset. This is because\nthe labels of the by-publisher dataset turned\nout rather noisy. In our preliminary experiments,\nwe found that the performance drops when\ntraining the classi\ufb01ers on the by-publisher\ndataset.\nFurthermore, we apply the following three tech-\nniques.\n1.Word dropout : We adopted word dropout\n(Iyyer et al., 2015) for regularization. The\ndropout rate was set to 0.3.\n2.Over sampling : As mentioned above, the\ngold label distribution of the training set is\nunbalanced while that of the test set is bal-\nanced. We deal with this imbalance problem\nby sampling 169 ( 407\u0000238) extra examples\nfrom hyperpartisan data.\n3.Ensemble : We trained 100 models with dif-\nferent random seeds. In addition, we trained\nmodels for 40, 50, 60 and 70 epochs for each\nseed. Consequently, we \ufb01nally average the\noutput of these 400 models.\n2.2 BERT Feature\nOur system uses BERT (Devlin et al., 2018). As a\nstrategy for applying BERT to downstream tasks,\nDevlin et al. (2018) recommends a \ufb01ne-tuning ap-\nproach, which \ufb01ne-tunes the parameters of BERT\non a target task. In contrast, we adopt a feature-\nbased approach, which uses the hidden states of\nthe pre-trained BERT in a task-speci\ufb01c model as\ninput representation. A main advantage of this\napproach is computational ef\ufb01ciency. We do not\nhave to update any parameters of BERT. Once we\ncalculate a \ufb01xed feature vector for an article, we\ncan reuse it across all the models for ensemble.\nIn our system, we used BERT to compute a fea-\nture vector f1for an input article. Speci\ufb01cally, we\n\ufb01rst fed an article to the pre-trained BERT model\nas input and extracted the representations of all the\nwords from the top four hidden layers. Then, to\nsummarize these representations into a single fea-\nture vector f1, we tried the following three meth-\nods.\n1.Average : Averaging the representations of all\nthe words in an article.2.BiLSTM : Using the representations as input\nto BiLSTM. This is the same method as the\nbest performing one reported by Devlin et al.\n(2018).\n3.CNN : Using the representations as input to\nCNN in the same way as Kim (2014).\nAs we describe in Section 3.2, we \ufb01nally adopted\nthe averaged BERT vectors as f1.\n2.3 Article Length Feature\nAsf2, we design a feature vector representing the\nlength of an input article. In our preliminary ex-\nperiments, we found a length bias in hyperparti-\nsan articles and non-hyperpartisan articles. Thus\na vector representing the length bias is expected\nto be useful for discriminating these two types of\narticles.\nSpeci\ufb01cally, we de\ufb01ne a one hot feature vec-\ntorf2representing distribution of the lengths of\narticles (the number of words in an article). To\nrepresent the length of an article as a vector, we\nmake use of histogram bins. Consider the 100-\nranged histogram bins. The \ufb01rst bin represents\nthe length 1 to 100, and the second one repre-\nsents the length 101 to 200. If the length of an\narticle is 255, the value of the third bin (201 to\n300) takes 1. In the same way, the third element\nof the length vector takes 1 and the others 0, i.e.,\nf2= [0;0;1;0;0;\u0001\u0001\u0001]. In our system, we set the\ndimension of the vector as D2= 11 , whose last\n(11-th) element corresponds to the length longer\nthan 1000.\n2.4 Informative Phrase Feature\nIn the development set, we found some phrases in-\nformative and useful for discriminating whether or\nnot a given article is hyperpartisan. We extracted\nsuch informative phrases and mapped them to a\nfeature vector f3. In this section, we \ufb01rst explain\nthe procedure of extracting informative phrases,\nand then we describe how to map them to a fea-\nture vector.\n2.4.1 Phrase Set Creation\nTo create an informative phrase set, we exploit the\nby-publisher articles. Basically, we take ad-\nvantage of chi-squared statistics of N-grams (N=\n1;2;3).\nCreation of ShFirst, we calculate each chi-\nsquared value \u001fxiofN-gramxiappearing in the\n1059by-publisher articles as follows:\n\u001fxi=(O\u0000E)2\nE: (3)\nOandEare de\ufb01ned as follows:\nO=ffalse(xi); (4)\nE=Tfalse\u0002ftrue(xi)\nTtrue; (5)\nwhereftrue(\u0001)andffalse(\u0001)are functions that cal-\nculate the frequency of xiin hyperpartisan articles\nand non-hyperpartisan articles, respectively. Ttrue\nandTfalseare the summation of the frequency of\nallN-grams in hyperpartisan articles and non-\nhyperpartisan articles, respectively.\nThen, based on the chi-squared values \u001fxi, we\nsort and select top- M N -grams. We can obtain a\ntypicalN-gram set (hereinafter, referred to as Sh)\nthat is informative for judging whether an article\nis hyperpartisan or not.1In our system, we use\nM= 200;000.\nShcan mostly catch the characteristics of hy-\nperpartisan articles. However, Shmay include\nsomeN-grams that are typical of a certain pub-\nlisher. This is because the by-publisher\ndataset is labeled by the overall bias of the pub-\nlisher as provided by BuzzFeed journalists or Me-\ndiaBiasFactCheck.com.\nCreation of SpTo remedy this problem, we cre-\nate another phrase set Spconsisting of N-grams\nthat are typical of a publisher, and exclude them\nfromSh.\nHere we consider a certain publisher pl. First,\nwe calculate each chi-squared value of N-gramxi\nin the same way as Eq 3,4,5 for Sh, but here we\nconsidertrue andfalse as appearing in articles\nof publisher pland articles of other publishers, re-\nspectively, instead of appearing in hyperpartisan\narticles and non-hyperpartisan articles. Then, we\npick up only N-gramxiwhereftrue(xi)is less\nthanffalse(xi)and sort all of them by the chi-\nsquared values. This is because we aim to ex-\nclude onlyN-grams that are typical of a certain\npublisher.\nNext, we try four types of ways to create Spl\nfrom sorted\u001fxvalue statistics. Here jdenotes the\nindex of the N-gram list sorted by \u001fxvalues, i.e.,\n\u001fx1is the highest value in all calculated \u001fxvalues.\n1Actually, we cut off N-gram xifftrue (x)is more than\n100,000 for Sh.1.Top-To: The \ufb01rst setting is to select top- To\nN-grams. Concretely, Splis de\ufb01ned as fol-\nlows:\nSpl=fxjjj\u0014Tog: (6)\n2.\u001f-based : The second setting is to select N-\ngrams based on \u001fvalues. Concretely, Splis\nde\ufb01ned as follows:\nSpl=fxjj\u001fxj>Tcg: (7)\n3.ftrue-based : The third setting is to select N-\ngrams based on ftrue(xj)values. Concretely,\nSplis de\ufb01ned as follows:\nSpl=fxjjftrue(xj)>Tf;j\u0014Tmg:(8)\n4.ftrue-ffalseratio-based : The fourth setting is\nto selectN-grams based on ratios between\nftrueandffalse. Concretely, Splis de\ufb01ned as\nfollows:\nSpl=\u001a\nxj\f\f\f\fftrue(xj)\nffalse(xj)>Tr;j\u0014Tm\u001b\n:(9)\nTo,Tc,Tf,TrandTmare hyper-parameters2.\nNext, we obtain Spde\ufb01ned as follows:\nSp=[\nlSpl: (10)\nAt last, we obtain an \ufb01ltered N-gram setSde\ufb01ned\nas follows:\nS=ShnSp: (11)\n2.4.2 Phrase Embedding\nWe map each of the obtained N-gram phrase set\nSto a feature vector f3. We exploited GloVe vec-\ntors (Pennington et al., 2014) instead of one-hot\nvectors in order to facilitate generalization.\nFirst, we enumerate N-grams included in an ar-\nticle and compute each N-gram vector. Each vec-\ntor is the average of GloVe vectors of included\nwords. For example, the vector for the phrase\n\u201cnews article\u201d is computed as follows:\nGloVe (news) + GloVe (article)\n2:\nHere, GloVe (w) denotes the GloVe\n(glove.840B3) vector of the word w. Then, we\ncompute f3as the average of all N-gram vectors\nincluded in the article.\n2In our experiments, we \ufb01x Tmto 200,000.\n3https://nlp.stanford.edu/projects/\nglove/\n1060Method Accuracy\nAverage 0.760\nBiLSTM 0.712\nCNN 0.758\nTable 1: Accuracy of hyperpartisan classi\ufb01cation for\neach operation on BERT vectors.\n3 Experiments\n3.1 Settings\nWe trained linear classi\ufb01ers on the by-article\ndataset (not on the by-publisher dataset). In\norder to estimate the performance in the test set\nwith each setting, we conducted 5-fold cross val-\nidation on by-article dataset. For optimiza-\ntion of the classi\ufb01ers, we use Adam with learning\nrate of 0.001, \f1= 0:9,\f2= 0:999. We set the\nminibatch size to 32. Note that we did not take en-\nsemble approach in the experiments we report in\nSection 3.2 and Section 3.3 for ef\ufb01ciency.\n3.2 Operation on BERT Vectors\nWe conducted experiments on each of the\nthree methods for BERT vectors ( BERT-Base,\nUncased4) mentioned in Section 2.2. In this ex-\nperiment, we only used f1as a feature vector f,\ni.e., without using f2andf3.\nTable 1 shows the performance in each setting.\nThe averaging method was the best performance\nthis time. We therefore decided to adopt average\nBERT vectors as f1for the evaluation of the for-\nmal run. In addition, we also used averaged BERT\nvectors as f1in the following experiments.\n3.3 Method to Create N-gram Set\nAs mentioned in Section 2.4, we examined which\nmethod is the best to create an informative N-\ngram setS(and f3derived from them). In this\nexperiment, we also used f1andf2withf3as a\nfeature.\nTable 2 shows the performance in each setting.\nThe performance was the best when we adopted\nTop-To(To= 100 ) forSpcreation. We therefore\nusedf3created in this setting.\n3.4 Ablation\nTo verify the contribution of each three types of\nfeatures, we conducted feature ablation experi-\nments. In addition, we investigated to what extent\n4https://github.com/google-research/\nbertMethod Accuracy\nTop-To(To= 100 ) 0.777\nTop-To(To= 1000 ) 0.771\n\u001f-based (Tc= 20000 ) 0.752\nftrue-based (Tf= 50 ) 0.754\nftrue-based (Tf= 150 ) 0.764\nftrue-ffalseratio-based ( Tr= 0:5) 0.754\nftrue-ffalseratio-based ( Tr= 0:8) 0.771\nftrue-ffalseratio-based ( Tr= 1:0) 0.756\nTable 2: Accuracy of hyperpartisan classi\ufb01cation for\neach method to create N-gram set.\nFeatures Ensemble Accuracy\nf1,f2,f3true 0.788\nf1,f2,f3false 0.777\nf1,f2 false 0.769\nf1 false 0.760\nTable 3: Result of ablation.\nensemble approach improve the performance. In\nthis experiments, we use only 10 (not 100) differ-\nent random seeds for ensemble due to time con-\nstraints.\nTable 3 shows the performance in each setting.\nWe found that f2andf3improved the accuracy by\nabout 0.01, respectively. Additionally, by using\nthe ensemble method, the accuracy increased by\nabout 0.01.\n4 Conclusion\nWe described our system submitted to the formal\nrun of SemEval-2019 Task 4: Hyperpartisan news\ndetection. We trained a linear classi\ufb01er using sev-\neral features mainly consisting of 1) BERT embed-\nding features, 2) article length features indicating\nthe distribution of lengths of articles and 3) em-\nbedding features derived from \ufb01ltered N-grams\nthat are typically found in hyperpartisan articles.\nOur system achieved 80.9% accuracy on the test\nset for the formal run and got 3rd place out of 42\nteams.\nAcknowledgments\nThis work was supported by JST CREST Grant\nNumber JPMJCR1301, Japan.\n1061References\n2019. Pan @ SemEval 2019 - Hyperpartisan\nNews Detection. https://pan.webis.de/\nsemeval19/semeval19-web/index.html .\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. arXiv preprint arXiv:1810.04805 .\nMohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber,\nand Hal Daum \u00b4e III. 2015. Deep unordered compo-\nsition rivals syntactic methods for text classi\ufb01cation.\nInProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and the\n7th International Joint Conference on Natural Lan-\nguage Processing , volume 1, pages 1681\u20131691.\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\nBenno Stein, and Martin Potthast. 2019. Semeval-\n2019 task 4: Hyperpartisan news detection. In Pro-\nceedings of The 13th International Workshop on Se-\nmantic Evaluation (SemEval) .\nYoon Kim. 2014. Convolutional neural networks for\nsentence classi\ufb01cation. In Proceedings of the 2014\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP) , pages 1746\u20131751.\nJeffrey Pennington, Richard Socher, and Christo-\npher D. Manning. 2014. GloVe: Global vectors for\nword representation. In Empirical Methods in Nat-\nural Language Processing (EMNLP) , pages 1532\u2013\n1543.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2018. A sty-\nlometric inquiry into hyperpartisan and fake news.\nInProceedings of 56th Annual Meeting of the Asso-\nciation for Computational Linguistics (ACL) , pages\n231\u2013240.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The sally smedley hyperpartisan news detector at SemEval-2019 task 4", "author": ["K Hanawa", "S Sasaki", "H Ouchi", "J Suzuki"], "pub_year": "2019", "venue": "Proceedings of the 13th \u2026", "abstract": "This paper describes our system submitted to the formal run of SemEval-2019 Task 4:  Hyperpartisan news detection. Our system is based on a linear classifier using several features, ie,"}, "filled": false, "gsrank": 134, "pub_url": "https://aclanthology.org/S19-2185/", "author_id": ["", "8z_iqUEAAAAJ", "RRrTYTEAAAAJ", "XO5CrIsAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ws_7qeBht_wJ:scholar.google.com/&output=cite&scirp=133&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ws_7qeBht_wJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 15, "citedby_url": "/scholar?cites=18210131235848310722&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ws_7qeBht_wJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://aclanthology.org/S19-2185.pdf"}}, {"title": "An Analysis of People's Reasoning for Sharing Real and Fake News", "year": "2021", "pdf_data": "An Analysis of People's Reasoning for Sharing\nReal and Fake News\nAnu Shrestha and Francesca Spezzano\nComputer Science Department\nBoise State University\nanushrestha@u.boisestate.edu\nfrancescaspezzano@boisestate.edu\nAbstract. The problem of the increase in the volume of fake news and\nits widespread over social media has gained massive attention as most of\nthe population seeks social media for daily news diet. Humans are equally\nresponsible for the surge of fake news spread. Thus, it is imperative to\nunderstand people's behavior when they decide to share real and fake\nnews items on social media. In an attempt to do so, we performed an\nanalysis on data collected through a survey where participants (n= 363\n) were asked whether they were willing to share the given news item on\ntheir social media and explain the reasoning for their decision. The re-\nsults show that the analysis presents several commonalities with previous\nstudies. Moreover, we also addressed the problem of predicting whether\na person will share a given news item or not. For this, we used intrin-\nsic features from participants' open-ended responses and demographics\nattributes. We found that the perceived emotions triggered by the news\nitem show a strong in\ruence on the user's decision to share news items\non social media.\nKeywords: Fake News \u00b7News Sharing \u00b7Emotion \u00b7Misinformation \u00b7\nSocial Media.\n1 Introduction\nSocial media has emerged as popular information source people rely on for events,\nbreaking news, and emergencies. Indeed, it has become a source of daily news\ndiet for the increasingly large population. Statistics show that majority of the\npopulation (71% of American adults) ever get news through social media in\n2020 [24] which was increased by 3% since 2018 [23]. The landscape of news\nconsumption and information \row has drastically changed with the popularity\nof social media. It has transformed how news content is created, how people en-\ngage with news items, and share information, blurring the journalists' boundary\nCopyright \u00a92021 for this paper by its authors. Use permitted under Creative Com-\nmons License Attribution 4.0 International (CC BY 4.0). Presented at the MISINFO\n2021 Workshop, held in conjunction with the 30th ACM The Web Conference, 2021,\nin Ljubljana, Slovenia.\n\n2 A. Shrestha and F. Spezzano\nin traditional media that is \frst verifying and then disseminating only the ac-\ncurate news items [25]. Moreover, users in social media (both organizations and\nindividuals) actively participate in creating and sharing news items with friends,\nfamilies, and other readers due to its ease of use, lower cost, and convenience\nof further sharing [2, 29]. This shift of news paradigm has led to an unprece-\ndented transformation in both news quality and quantity that users encounter\nin social media, increasing the probability of potential encounters and the spread\nof fake news, fostering social media as a fertile ground for the production and\npropagation of fake news.\nThe sheer volume of fake news being observed in social media has recently be-\ncome an obvious cause of concern. Many studies have highlighted the character-\nistics of fake news through linguistic and psychological attributes [11,20,21,27],\nwriting styles [3,11,13], network-based attributes [7] and hybrid attributes con-\nsidering both linguistic and network [29].\nDespite several studies illustrating cues to identify fake news and mitigate\nits spread, there is a worrisome amount of fake news widely spreading over so-\ncial media. Fake news has been identi\fed as more likely to go viral than real\nnews, spreading faster and wider [35]. Additionally, an analysis of news about\nthe 2016 election conducted by BuzzFeed, also found more engagement with fake\nnews than real news [32]. Earlier studies analyzed the potential reason behind\nthis rapid di\u000busion of news in social media, focusing on various factors, in-\ncluding polarized communities of users with common belief (echo-chambers) [4],\nepidemiological models [12]. Some studies highlighted the actors responsible for\nspreading fake news, including bots and cyborgs [6]. Although bots are equally\nresponsible for spreading real and fake news, the considerable spread of fake\nnews is caused by human activity [30, 35] as people are generally not able to\naccurately identify which news item is fake and which is real [34]. Thus, it is\ncrucial to understand the people's sharing behavior of fake and real news on\nsocial media to minimize fake news di\u000busion.\nIn this context, this study seeks to better understand how people reason\nwhen they decide to share real news and fake news. In particular, we surveyed\n363 undergraduate students where we asked participants to report and explain\ntheir willingness to share given news item (with headline and image) on their\nsocial media. We also leveraged the demographic attributes of participants like\ngender and political orientation in our study. We performed a comprehensive\ndata analysis to investigate the pattern of news sharing behavior, the role of\ndemographics in news sharing decisions, and why people share real and fake\nnews. Furthermore, we addressed the problem of predicting whether a person\nwill share a given news item or not according to emotion, psychological, and\ndemographics features as a binary classi\fcation task.\nOur experiments show several commonalities with previous \fndings regarding\nnews sharing behavior.\n{News sharing is rare as only a small percentage (19.2% to 28.2%) of users\nexpressed the willingness to share news in social media, regardless of news\nveracity.\nAn Analysis of People's Reasoning for Sharing Real and Fake News 3\n{Female participants are prone to share more news than male participants\nregardless of news veracity.\n{Left-leaning participants tend to share real news more than fake news, inde-\npendently of the news source's political orientation, and right-leaning par-\nticipants were instead more prone to share news items from sources with the\nsame political-leaning, independently of news veracity.\n{The prominent themes illustrated by the approaches used by participants to\nmake their sharing decisions falls under subjectivity and the focus on others\ninterest or disinterest in news topic.\n{Emotion features are more e\u000bective in predicting people's willingness to share\na given news item.\n2 Related Work\nSeveral studies have been conducted to understand the characteristics of users\nthat are likely to contribute to spreading fake news on social networks. Vosoughi\net al. [35] revealed that the fake news spreaders had, on average, signi\fcantly\nfewer followers, followed signi\fcantly fewer people, and were signi\fcantly less\nactive on Twitter. Moreover, bots tend to spread both real and fake news, and\nthe considerable spread of fake news on Twitter is caused by human activity.\nShrestha and Spezzano showed that social network properties help in identifying\nactive fake news spreaders [26]. Shu et al. [30] analyzed user pro\fles to under-\nstand the characteristics of users that are likely to trust/distrust fake news. They\nfound that, on average, users who share fake news tend to be registered for a\nshorter time than the ones who share real news and that bots are more likely\nto post a piece of fake news than a real one, even though users who spread\nfake news are still more likely to be humans than bots. They also show that\nreal news spreaders are more likely to be more popular and that older people\nand females are more likely to spread fake news. Guess et al. [9] also analyzed\nuser demographics as predictors of fake news sharing on Facebook and found\nout political-orientation, age, and social media usage to be the most relevant.\nSpeci\fcally, people are more likely to share articles they agree with (e.g., right-\nleaning people tended to share more fake news because the majority of the fake\nnews considered in the study were from 2016 and pro-Trump), seniors tend to\nshare more fake news probably because they lack digital media literacy skills\nthat are necessary to assess online news truthfulness, and the more people post\nin social media, the less they are likely to share fake news, most likely because\nthey are familiar with the platform and they know what they share.\nShrestha et al. [28] analyzed the linguistic patterns used by a user in their\ntweets and personality traits as a predictor for identifying users who tend to\nshare fake news on Twitter data [22, 28]. Likewise, Giachanou et al. [8] pro-\nposed an approach based on a convolutional neural network to process the user\nTwitter feed in combination with features representing user personality traits\nand linguistic patterns used in their tweets to address the problem of discrimi-\nnating between fake news spreaders and fact-checkers.\n4 A. Shrestha and F. Spezzano\nFig. 1: News items used in our survey instrument.\nMa et al. [15] went beyond the user and news characteristics and analyzed\nthe characteristics of di\u000busion networks to explain users' news sharing behavior.\nThey found opinion leadership, news preference, and tie strength to be the most\nimportant factors at predicting news sharing, while homophily hampered news\nsharing in users' local networks. Also, people driven by grati\fcations of infor-\nmation seeking, socializing, and status-seeking were more likely to share news\non social media platforms [14].\n3 Data Collection\nWe conducted an online survey delivered via Qualtrics. Through this online sur-\nvey, participants were given four news headlines and accompanying images. For\neach news item, participants were asked whether they were willing to share the\ngiven news item on their social media and write an explanation of the reasoning\nfor their decision. We considered the four news items shown in Figure 1 and\ngathered from politifact.com. In this news set, two are real news items, and\ntwo are fake news items, as fact-checked by politifact.com. Both real and fake\nnews items are one from a left-leaning source and one from a right-leaning source.\nNews source political-leaning has been gathered from mediabiasfactcheck.com.\nWe recruited undergraduate students ( n= 363 ) from a volunteer pool in\ngeneral education social science courses (Psychology 101) to participate in our\nsurvey (258 F, 101 M, 4 Other; mean age 19.7, SD = 4.25). The research was ap-\nproved by the university IRB. Participants were compensated with course credit\n(volunteering for studies being one option for a research experience requirement).\nParticipants received no training.\nAn Analysis of People's Reasoning for Sharing Real and Fake News 5\nPercentage of Sharing\nNews Item 1 (Fake) 19.2%\nNews Item 2 (Fake) 22.9%\nNews Item 3 (Real) 20.0%\nNews Item 4 (Real) 28.2%\nTable 1: News Sharing Behavior.\n4 Data Analysis\nNews sharing is rare. We start the analysis of our data by observing that only\na small percentage of users expressed the willingness to share news in social\nmedia, independently of the veracity of the news. As shown in Table 1, this\npercentage ranges between 19.2% and 28.2% among the news considered in our\nsurvey. Previous research [10] has shown that sharing news articles from fake\nnews domains on Facebook was a rare activity during the 2016 U.S. presidential\ncampaign. Our data on fake news sharing is aligned with this result, but our\nrespondents also showed some preliminary evidence that this pattern may be\ntrue for real news sharing as well.\nThe role of demographics in news sharing. We collected demographic data from\nour survey participants, including gender, political orientation, and age. As most\nparticipants are in the same age range (18-25), we did not consider age in our\nanalysis.\nWhen looking at di\u000berences in sharing behavior according to gender (see\nFigure 2), we observe that the female participants were more prone to share\nboth the fake news items considered than male participants who were more\nskeptical about the same news items. Shu et al. [31] in his studies have shown a\nsimilar result where female users tend to trust fake news more than male users.\nIn general, females were more prone to share more news items than males (three\nvs. one).\nRegarding participants political orientation, we see two interesting patterns\nas reported in Figure 3: (1) left-leaning participants were more prone to share\nreal news than fake news, independently of the political orientation of the news\nsource; (2) right-leaning participants were instead more prone to share news\nitems from sources with the same political-leaning (news items 1 and 3), in-\ndependently of news veracity. Similarly, Guess et al. [10] have shown that, in\n2016, conservatives were more likely to share articles from pro-Trump fake news\ndomains than liberals or moderates.\nWhy people share real and fake news? Yaqub et al. [36] analyzed open-ended\nresponses of participants in the study where they explained the reason behind\ntheir intention to share true, false, and satire headlines. In their study, the most\nfrequent rationales behind sharing/not sharing news were (1) the interest/non-\ninterest towards the news, (2) the potential of generating discussion among the\n6 A. Shrestha and F. Spezzano\n(a) News item 1 (fake)\n (b) News item 2 (fake)\n(c) News item 3 (real)\n (d) News item 4 (real)\nFig. 2: Distribution of participant's gender.\nfriends, (3) the fact that the news is not relevant to the user's life, and (4) the\nperceived news credibility, especially as a motivation for not sharing news.\nWe conducted a similar analysis on a sample of our data (n=25). Speci\fcally,\nwe conducted a thematic analysis to identify the prominent themes that illus-\ntrated the approaches used by participants to make their sharing decisions. We\nfollowed an inductive approach to generating codes [5]. We found out the prin-\ncipal codes to be focused on potential others (\"My friends would/would not be\ninterested in this\"), interest or disinterest in the news topic, and subjectivity/the\nself (\"I would/wouldn't share this because...\", \"I would call that fake/real\") and\nare mostly aligned with the \fnding by Yaqub et al. [36].\nRegarding performing credibility assessment before making the sharing de-\ncision, we also found in our sample data that this was performed more often for\nfake news (28% of the times for news item 1 and 56% for news item 2) than for\nreal news (24% of the times for news item 3 and 16% for news item 4). Moreover,\nwhen performed, the credibility assessment was much more correct in the case\nof fake news (100% of the times for news item 1 and 93% for news item 2) than\nreal news (67% of the times for news item 3 and 25% for news item 4).\nOverall, the data analysis performed in this section shows that our collected\ndata presents several commonalities with previous studies, ensuring we have qual-\nity data suitable for further investigations.\nAn Analysis of People's Reasoning for Sharing Real and Fake News 7\n(a) News item 1\n(fake, right-leaning source)\n(b) News item 2\n(fake, left-leaning source)\n(c) News item 3\n(real, right-leaning source)\n(d) News item 4\n(real, left-leaning source)\nFig. 3: Distribution of participant's self-identi\fed political orientation.\n5 Predicting News Sharing\nIn this section, we address the problem of predicting whether a person will share\nor not a news item according to emotion and psychological features generated\nwhen they consider a news item and demographics (gender and political orien-\ntation) as well. We modeled the problem as a binary classi\fcation task where\nwe computed emotion and psychological features from participants' open-ended\nresponses to the survey question asking for an explanation of their decision to\nshare or not the given news item.\n5.1 Textual Features Extraction\nEmotion Features (Emotion) In order to compute a vector of scores quan-\ntifying participants' emotions when deciding whether or not to share a news\nitem, we considered their open-ended survey responses and proceeded as fol-\nlows. We started by cleaning responses' text by expanding contraction words,\ncorrecting misspellings and grammatical mistakes using LanguageTool1and re-\nplacing negated words with their WordNet antonym. Next, we extracted emo-\n1https://pypi.org/project/language-tool-python/\n8 A. Shrestha and F. Spezzano\ntions from the text by using the Emotion Intensity Lexicon (NRC-EIL) [18]\nand EmoLex [33]. Emotion features computed via NRC-EIL include anger, joy,\nsadness, fear, disgust, anticipation, surprise, and trust, while Emolex2features\ninclude happy, sad, angry, don't care, inspired, afraid, amused, and annoyed. Fea-\nture vectors have been computed by using the approaches proposed in [16,17]. In\naddition, we also considered emotion-related features as computed by the 2015\nLinguistic Inquiry and Word Count (LIWC) [19] tool, which includes e\u000bective\nprocesses like anxiety, anger, positive and negative emotion.\nPsycho-linguistic Features (LIWC) To understand the relationship between\npsychological states and the participants' decision-making, we considered the set\nof psycho-linguistic features computed by the Linguistic Inquiry and Word Count\n(LIWC) tool [19]. LIWC is a transparent text analysis tool that counts words in\npsychologically meaningful categories. Speci\fcally, we considered psychological\nprocesses that include social processes (e.g., family, friends), cognitive processes\n(e.g., think, cause, perhaps), perceptual processes (e.g., see, heard, felt), biologi-\ncal processes (e.g., eat, pain, love), relativity (e.g., area, move, day) and personal\nconcerns (e.g., work, leisure, achieve, home, money, religion, death).\nDemographics (Demog) As explicit features, we used participants' self-identi\fed\ngender and political orientation to understand if the demographic attributes pro-\nvide potential cues in predicting users' sharing decisions.\n5.2 Experimental Setting and Results\nWe used each group of features described in the previous section as input to\na random forest classi\fer to compute the performance of these features in pre-\ndicting whether a reader of a news item (a participant of our survey) is willing\nto share or not the given news item on their social networks. We also tried\nother classi\fers such as Support Vector Machine (SVM) and logistic regression,\nbut random forest achieved the best results. Hence, in the paper, we report the\nresults of random forest only. We used class weighting to deal with the class\nimbalance and performed 5-fold cross-validation.\nThe results are reported in Table 2 according to the area under the ROC\ncurve (AUROC), average precision (AvgP), and F1-measure (F1). As can be\nseen, when each feature group is considered separately, emotion features are the\nbest performing features compared to LIWC features and demographics with\n72% vs. 61% and 52% AUROC and 40% vs. 25% and 20% average precision\nfor news item 1, 71% vs. 61% and 57% AUROC and 42% vs. 31% and 25%\naverage precision for news item 2, 77% vs. 59% and 62% AUROC and 58%\nvs. 31% and 26% average precision for news item 3 and 78% vs. 61% and 59%\nAUROC and 56% vs. 40% and 42% average precision for news item 4 (bold\nin Table 2). We further considered a combination of all feature groups to see\n2https://sites.google.com/site/emolexdata/\nAn Analysis of People's Reasoning for Sharing Real and Fake News 9\nFeatures AUROC AvgP F1\nNews Item 1 (Fake)LIWC 0.611 0.247 0.166\nDemog 0.518 0.207 0.228\nEmotion 0.720 0.403 0.228\nAll 0.722 0.382 0.129\nNews Item 2 (Fake)LIWC 0.608 0.307 0.175\nDemog 0.565 0.250 0.325\nEmotion 0.706 0.416 0.162\nAll 0.707 0.421 0.122\nNews Item 3 (Real)LIWC 0.586 0.310 0.257\nDemog 0.617 0.258 0.300\nEmotion 0.771 0.578 0.477\nAll 0.796 0.585 0.439\nNews Item 4 (Real)LIWC 0.611 0.397 0.302\nDemog 0.590 0.317 0.356\nEmotion 0.784 0.564 0.423\nAll 0.786 0.562 0.359\nTable 2: Comparison of emotion, psycho-linguistic, and demographic features to\npredict whether a news item will be shared or not. We used a random forest\nclassi\fer. Best results among feature groups considered separately are in bold.\nBest overall results are shaded.\nif combining demographics, psychological and emotional features can provide\ncomplementary information that can help improve the prediction. We observed\nthat when the combination of all feature groups is considered, the performance\nremained more or less the same if not improved according to AUROC (shaded\nin Table 2). This demonstrates that emotion features are more e\u000bective than\nother groups of features considered in our study for predicting people's sharing\nbehavior. Hence, one of the motivations for potential news-sharing behavior in\nsocial media could be emotional persuasion. It will not be inaccurate to say that\nbeing persuaded by strong emotions like anger, fear, surprise, joy, etc., triggered\nby news content, people tend to get involved and share more news on social\nmedia. This \fnding aligns with the previous research by Berger et al. [1] which\nalso states that emotional arousal tends to increases the likelihood of sharing\nnews on social media.\n6 Conclusion and Future Work\nTo sum up, this paper presents \fndings from studying people's reasoning when\nthey decide to share real and fake news items provided with headlines and im-\nages. This paper investigates the correlation between the user's sharing decision\nand explicit attributes provided by participants like demographics and politi-\ncal orientation. Furthermore, we addressed the problem of predicting whether\na person will share a given news item or not using intrinsic features like psy-\n10 A. Shrestha and F. Spezzano\nchological and emotion from participants' open-ended responses explaining their\nwillingness to share given news item along with demographics attributes.\nThe results show that news sharing is rare, and among the participants ex-\npressing willingness to share, females are prone to share more news in general.\nParticipants' political orientation exerts a signi\fcant pattern on news sharing\nbehavior that is left-leaning participants' news sharing behavior is motivated by\nnews veracity rather than political orientation. In contrast, it is the other way\naround for right-leaning participants. Likewise, it shows the possibility of users\nsharing news items depends on the perceived relevance of news interest among\nfriends and families. Moreover, this paper also highlights that the perceived emo-\ntions triggered by the news item show a strong in\ruence on user's news sharing\nbehavior in social media.\nOne potential limitation of our study is that we have considered only four\nnews of each political leaning (2 fake and 2 real). Considering a bigger set of\nnews items could have shown signi\fcant patterns and support to our \fndings.\nFurthermore, this work focuses on a younger sample of the limited range of age,\ndue to which we did not consider age in demographic attributes. It could have\nadded some more insights regarding news sharing behavior among di\u000berent age\ngroups if we could consider participants of a wide range of ages (from younger\nto older population). We will address these limitations in our future work.\nAcknowledgements\nThis work has been supported by the National Science Foundation under Award\nno. 1943370. We thank Brian Stone for facilitating the data collection and Ashlee\nMilton and Maria Soledad Pera for providing us with the code used in their\npapers [16,17] to compute emotional features.\nReferences\n1. Berger, J.: Arousal increases social transmission of information. Psychological\nscience 22(7), 891{893 (2011)\n2. Bruns, A., High\feld, T., Lind, R.A.: Blogs, twitter, and breaking news: The\nprodusage of citizen journalism. Produsing theory in a digital world: The\nintersection of audiences and production in contemporary theory 80(2012), 15{32\n(2012)\n3. Castillo, C., Mendoza, M., Poblete, B.: Information credibility on twitter. In:\nProceedings of the 20th international conference on World wide web. pp. 675{684\n(2011)\n4. Del Vicario, M., Bessi, A., Zollo, F., Petroni, F., Scala, A., Caldarelli, G.,\nStanley, H.E., Quattrociocchi, W.: The spreading of misinformation online.\nProceedings of the National Academy of Sciences 113(3), 554{559 (2016)\n5. DNSc, J., Strauss, A.: Basics of Qualitative Research: Techniques and Procedures\nfor Developing Grounded Theory. SAGE Publications, Inc, Los Angeles, fourth\nedition edn. (Dec 2014)\nAn Analysis of People's Reasoning for Sharing Real and Fake News 11\n6. Ferrara, E., Varol, O., Davis, C., Menczer, F., Flammini, A.: The rise of social\nbots. Communications of the ACM 59(7), 96{104 (2016)\n7. Gayo-Avello, D., Metaxas, P.T., Mustafaraj, E., Strohmaier, M., Schoen, H.,\nGloor, P., Castillo, C., Mendoza, M., Poblete, B.: Predicting information\ncredibility in time-sensitive social media. Internet Research (2013)\n8. Giachanou, A., Rissola, E.A., Ghanem, B., Crestani, F., Rosso, P.: The role of\npersonality and linguistic patterns in discriminating between fake news spreaders\nand fact checkers. In: Natural Language Processing and Information Systems:\n25th International Conference on Applications of Natural Language to\nInformation Systems, NLDB 2020. p. 181. Springer Nature\n9. Guess, A., Nagler, J., Tucker, J.: Less than you think: Prevalence and predictors\nof fake news dissemination on facebook. Science advances 5(1), eaau4586 (2019)\n10. Guess, A., Nagler, J., Tucker, J.: Less than you think: Prevalence and predictors\nof fake news dissemination on facebook. Science Advances 5(1) (2019)\n11. Horne, B.D., Adali, S.: This just in: Fake news packs a lot in title, uses simpler,\nrepetitive content in text body, more similar to satire than real news. In: The 2nd\nInternational Workshop on News and Public Opinion at ICWSM (2017)\n12. Jin, F., Dougherty, E., Saraf, P., Cao, Y., Ramakrishnan, N.: Epidemiological\nmodeling of news and rumors on twitter. In: Proceedings of the 7th workshop on\nsocial network mining and analysis. pp. 1{9 (2013)\n13. Jin, Z., Cao, J., Zhang, Y., Luo, J.: News veri\fcation by exploiting con\ricting\nsocial viewpoints in microblogs. In: Proceedings of the AAAI Conference on\nArti\fcial Intelligence. vol. 30 (2016)\n14. Lee, C.S., Ma, L.: News sharing in social media: The e\u000bect of grati\fcations and\nprior experience. Computers in human behavior 28(2), 331{339 (2012)\n15. Ma, L., Lee, C.S., Goh, D.H.: Understanding news sharing in social media from\nthe di\u000busion of innovations perspective. In: 2013 IEEE International Conference\non Green Computing and Communications and IEEE Internet of Things and\nIEEE Cyber, Physical and Social Computing. pp. 1013{1020. IEEE (2013)\n16. Milton, A., Batista, L., Allen, G., Gao, S., Ng, Y., Pera, M.S.: \"don't judge a\nbook by its cover\": Exploring book traits children favor. In: RecSys 2020:\nFourteenth ACM Conference on Recommender Systems, Virtual Event, Brazil,\nSeptember 22-26, 2020. pp. 669{674. ACM (2020)\n17. Milton, A., Pera, M.S.: What snippets feel: Depression, search, and snippets. In:\nCantador, I., Chevalier, M., Melucci, M., Mothe, J. (eds.) Proceedings of the\nJoint Conference of the Information Retrieval Communities in Europe (CIRCLE\n2020), Samatan, Gers, France, July 6-9, 2020. CEUR Workshop Proceedings,\nvol. 2621 (2020)\n18. Mohammad, S.: Word a\u000bect intensities. In: Proceedings of the Eleventh\nInternational Conference on Language Resources and Evaluation, LREC 2018,\nMiyazaki, Japan, May 7-12, 2018. European Language Resources Association\n(ELRA) (2018)\n19. Pennebaker, J.W., Boyd, R.L., Jordan, K., Blackburn, K.: The development and\npsychometric properties of liwc2015. Tech. rep. (2015)\n20. P\u0013 erez-Rosas, V., Kleinberg, B., Lefevre, A., Mihalcea, R.: Automatic detection of\nfake news. In: Proceedings of the 27th International Conference on\nComputational Linguistics. pp. 3391{3401 (2018)\n21. Potthast, M., Kiesel, J., Reinartz, K., Bevendor\u000b, J., Stein, B.: A stylometric\ninquiry into hyperpartisan and fake news. In: Proceedings of the 56th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long\nPapers). pp. 231{240 (2018)\n12 A. Shrestha and F. Spezzano\n22. Rangel, F., Giachanou, A., Ghanem, B., Rosso, P.: Overview of the 8th author\npro\fling task at pan 2020: Pro\fling fake news spreaders on twitter. In: CLEF\n(2020)\n23. Shearer, E., Matsa, K.E.: News use across social media platforms 2018. Pew\nResearch Center (2018)\n24. Shearer, E., Mitchell, A.: News use across social media platforms in 2020. Pew\nResearch Center (2020)\n25. Shoemaker, P.J., Vos, T.P., Reese, S.D.: Journalists as gatekeepers. The\nhandbook of journalism studies 73(2009)\n26. Shrestha, A., Spezzano, F.: Online misinformation: from the deceiver to the\nvictim. In: ASONAM '19: International Conference on Advances in Social\nNetworks Analysis and Mining. pp. 847{850. ACM (2019)\n27. Shrestha, A., Spezzano, F.: Textual characteristics of news title and body to\ndetect fake news: A reproducibility study. In: Advances in Information Retrieval -\n43rd European Conference on IR Research, ECIR 2021, Proceedings, Part II.\nLecture Notes in Computer Science, vol. 12657, pp. 120{133. Springer (2021)\n28. Shrestha, A., Spezzano, F., Joy, A.: Detecting fake news spreaders in social\nnetworks via linguistic and personality features. In: CLEF (2020)\n29. Shu, K., Sliva, A., Wang, S., Tang, J., Liu, H.: Fake news detection on social\nmedia: A data mining perspective. ACM SIGKDD explorations newsletter 19(1),\n22{36 (2017)\n30. Shu, K., Wang, S., Liu, H.: Understanding user pro\fles on social media for fake\nnews detection. In: 1st IEEE International Workshop on Fake MultiMedia\n(FakeMM 2018) (2018)\n31. Shu, K., Wang, S., Liu, H.: Understanding user pro\fles on social media for fake\nnews detection. In: 2018 IEEE Conference on Multimedia Information Processing\nand Retrieval (MIPR). pp. 430{435. IEEE (2018)\n32. Silverman, C.: This analysis shows how viral fake election news stories\noutperformed real news on facebook. BuzzFeed News 16(2016)\n33. Song, K., Gao, W., Chen, L., Feng, S., Wang, D., Zhang, C.: Build emotion\nlexicon from the mood of crowd via topic-assisted joint non-negative matrix\nfactorization. In: Proceedings of the 39th International ACM SIGIR conference\non Research and Development in Information Retrieval, SIGIR 2016. pp.\n773{776. ACM (2016)\n34. Spezzano, F., Shrestha, A., Fails, J.A., Stone, B.W.: That's fake news!\ninvestigating how readers identify the reliability of news when provided title,\nimage, source bias, and full articles. Proceedings of the ACM on Human\nComputer Interaction journal 5(CSCW1, Article 109) (2021)\n35. Vosoughi, S., Roy, D., Aral, S.: The spread of true and false news online. Science\n359(6380), 1146{1151 (2018)\n36. Yaqub, W., Kakhidze, O., Brockman, M.L., Memon, N., Patil, S.: E\u000bects of\ncredibility indicators on social media news sharing intent. In: Proceedings of the\n2020 CHI Conference on Human Factors in Computing Systems. p. 1{14. CHI '20\n(2020)", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "An Analysis of People's Reasoning for Sharing Real and Fake News", "author": ["S Anu", "S Francesca"], "pub_year": "2021", "venue": "Proceedings of the Workshop on Misinformation \u2026", "abstract": "The problem of the increase in the volume of fake news and its widespread over social media  has gained massive attention as most of the population seeks social media for daily news"}, "filled": false, "gsrank": 135, "pub_url": "https://par.nsf.gov/servlets/purl/10326083", "author_id": ["", ""], "url_scholarbib": "/scholar?hl=en&q=info:d19s0cuQ9VMJ:scholar.google.com/&output=cite&scirp=134&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=d19s0cuQ9VMJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:d19s0cuQ9VMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://par.nsf.gov/servlets/purl/10326083"}}, {"title": "Interrogating Fake News in the Composition Classroom: Pedagogical Plans", "year": "2019", "pdf_data": "The Liminal: Inter disciplinar y Journal of T echnology in E ducation The Liminal: Inter disciplinar y Journal of T echnology in E ducation \nVolume 1 Issue 1 Article 6 \nAugust 2019 \nInterr ogating F ake News in the Composition Classr oom: Interr ogating F ake News in the Composition Classr oom: \nPedagogical Plans Pedagogical Plans \nShelly A. Galliah \nMichigan T echnological Univ ersity ,, sagallia@mtu.edu \nFollow this and additional works at: https:/ /digitalcommons.du.edu/theliminal \n Part of the Arts and Humanities Commons , Curriculum and Instruction Commons , Curriculum and \nSocial Inquir y Commons , and the Educational Methods Commons \nRecommended Citation Recommended Citation \nGalliah, Shelly A. (2019) \"Interr ogating F ake News in the Composition Classr oom: P edagogical Plans, \" The \nLiminal: Inter disciplinar y Journal of T echnology in E ducation : Vol. 1: Iss. 1, Ar ticle 6. \nAvailable at: https:/ /digitalcommons.du.edu/theliminal/v ol1/iss1/6 \nThis Ar ticle on P edagogy is br ought t o you for fr ee and open access b y Digital Commons @ DU. It has been \naccepted for inclusion in The Liminal: Inter disciplinar y Journal of T echnology in E ducation b y an authoriz ed edit or \nof Digital Commons @ DU. F or mor e information, please contact jennif er.cox@du.edu,dig-commons@du.edu . \nInterr ogating F ake News in the Composition Classr oom: P edagogical Plans Interr ogating F ake News in the Composition Classr oom: P edagogical Plans \nAbstr act Abstr act \nThis brief ar ticle ar gues that the skills de veloped in the first-y ear Composition classr oom, such as \nanalyzing texts, interr ogating ar guments, inv estigating media bias, conducting r esear ch, and thinking \ncritically ar e crucial for helping students r ecogniz e the v arious forms of disinformation and post-truth as \nwell as how t o avoid cir culating these and fur ther polluting the media and information ecospher es. It also \nargues that Composition instruct ors must r emain centrist t o avoid exacerbating political polarization and \nalienating students who might be r esistant t o inv estigating fak e news. This ar ticle summariz es some k ey \nreadings and pr actical activities that Composition instruct ors ma y incorpor ate int o their classr ooms. \nKeywor ds Keywor ds \ncentrist, classr oom, Composition, confirmation bias, critical thinking, democr acy, disinformation, \necospher e, fak e news, lessons, media bias, misinformation, pedagogy , polarization, political, politics, post-\ntruth, public discourse, r esear ch, resear ch skills \nThis ar ticle on pedagogy is a vailable in The Liminal: Inter disciplinar y Journal of T echnology in E ducation: \nhttps:/ /digitalcommons.du.edu/theliminal/v ol1/iss1/6 \nThe current American president, Donald J. Trump, has used the term fake news  for all \nmedia that criticize him, his ideologies, or his policies.  Although the president has usually \ntargeted the entire mainstream press, in a January 17, 2018 GOP blog entitled \u201cThe Highly \nAnticipated 2017 Fake News Awards,\u201d his team pinpointed certai n newspapers and networks \nfor their biased journalistic mistakes: ABC, Time , The New York Times  (two stories), The \nWashington Post  (two stories), CNN (four stories), and Newsweek . These media outlets \nsubsequently addressed their errors, retracted their stories, and even disciplined their writers \u2014\nresponsible habits of sound journalism \u2014but this blog ignored these correction s. After \ndisparaging these media sources for their reporting mistakes, many of which hardly deserved \nthe charge of \u201cfake news,\u201d the blog e nded with an encomium to President Trump and his \naccomplishments, which ironically contain ed exaggerated, fabricated claims (actual fake news) \nabout economic growth, the rising employment rates of Hispanics and African Americans, and \nthe retreat of ISIS. In fact, in the period of January 2017 to December 30, 2018, President \nTrump has voiced an astounding 7,645 false or misleading claims. Not surprisingly, the greatest \nnumber of half-truths concern immigration, the subject of his first major campaign speech in \nJune 27, 2015, when he referred to the US as a \u201cdumping ground\u201d for Mexico\u2019s worst  \n(Capehart, 2017). Several of these false claims derive from certain statements repeated over one \nhundred times ( Washington Post , 2018). This iteration matters because in the already chaotic \nand confusing media ecosphere, \u201cwhen we see multiple messages about the same topic, our \nbrains use that as a short- cut to credibility\u201d (Wardle, 2017). In other words, if repeated often \nenough, even the most outlandish claims, such as the earth being flat or climate change being an \nalarmist global hoax, may acquire the semblance of truth. \nDespite President Trump\u2019s misuse of the word and his own falsifications, the \nphenomenon of fake news  is far more complicated and far more dangerous. Some have \ncategorized fake news according to its complexity of information and its intention to deceive, \nwhether they divide it into seven types (Wardle, 2017) or only two types (Alcott & Gentzkow, \n2017); or according to its goals of satirizing an event/person, making money, and/or promoting \nan agenda (Barclay, 2018). Others equate fake news with propaganda, hoaxes, and falsifications \n\u201cmasterfully manipulated to look like credible journalistic reports that ar e easily spread online \nto large audiences willing to believe the fictions and spread the word\u201d (Holnan, 2016). On the \nother hand, Benkler, Faris, & Roberts (2018) reject fake news  altogether for more precise terms \ndelineating types of fabrications and thei r respective purposes: propaganda and disinformation , \nwhich manipulate people \u201cfor political ends\u201d; bullshit , profit-driven communication that \ncompletely disregards the truth; and misinformation , unintentionally misleading information \nthat is not politically motivated (p. 24). These authors also argue that the creators and \ndisseminators of false claims may not have the goal of persuasion, but manipulation, or, at the \nworst, disorientation. Disorientation is the debilitating condition in which the target population, \noverwhelmed by too many fabrications and confusing messages, is completely unable to \ndistinguish truths from falsehoods (p. 24). Conservative talk-show host Rush Limbaugh, who \nhas long railed against \u201cthe four corners of deceit\u201d (academia , government, science, and the \n1Galliah: Interrogating Fake News in the Composition Classroom\nPublished by Digital Commons @ DU, 2019\nmedia) (Horn, 2010) is one of the biggest generators of disorientation, a condition endangering \nif not disabling democracy. \nRecently, a new genre of fake news, deep fakes , has raised the stakes on both the spread  \nof disinformation and the difficulty of distinguishing between the real and the unreal, between \nfact and fiction.  Deep fakes, a portmanteau of the terms deep learning  and fake are video and/or \naudio fabrications generated from existing data , which may or may not be detectable depending \non the expertise of their creators. Although this machine learning technique was original ly \nlimited to the AI community, the emergence of FakeApp, and the 2017 Reddit posts of \ncelebrities\u2019 heads on adult film stars\u2019 bodies brought this genre to public attention (Schwartz, \n2018). Creating a deep fake still takes subsequent skill, but machine-learning techniques may \nenable regular citizens to circumvent and adapt the technology to avoid detection. In the worst \ncase scenario, deep fakes could be used to create propaganda to support ideologies and damage \nreputations. Imagine, for instance, the catastrophic effects of a deep fake of candidate Elizabeth \nWarren shouting racist epithets if it were released a few days before the US election. This is but \none example of how deep fakes, like all fake news, may \u201cbe weaponized in ways that weaken \nthe fabric of democracy itself\u201d (Schwartz, 2018).  \nBoth the normalization and popularity of fake news, in all its forms, have also led some \nto argue that we are currently living in an era of post-truth. According to Holnan, PolitiFact \nnamed all fake news \u201c2016 Lie of the Year\u201d whereas Oxford named post-truth  its \u201c2016 Word \nof the Year,\u201d which seemed appropriate given the mistruths involved in both the Brexit fiasco  \nand the American presidential campaigns. We are living through a fuzzy time in which facts \nmay or may not have a relationship with the truth, an era in which \u201cobjective facts are less \ninfluential in shaping public opinion than appeals to emotion and personal belief\u201d (McIntyre, \n2017, Location 173) or political affiliation This last explanation is eerily close to Colbert\u2019s  \nword truthism , a state referring to whether a fact feels true  according to whether it motivates a \nperson\u2019s emotions and supports their ideology \u2014even if that fact is a deep fake video of ex-\nPresident Obama referring to the current U.S. leader as a \u201cdipshit\u201d ( Vincent, 2018 ).  \nIn a crowded information environment in which people rarely have time to dissect texts, \nand in which they encounter repeated mistruths, these fabrications spread, aided by the ease of \ndigital technology.  \nMy Understanding of The Composition Instructor\u2019s Role  in the Post-Truth \nEnvironment  \nAs the previous paragraphs indicate, there is an \u201cepistemic crisis\u201d (Benkler, Faris, & \nRoberts, 2018) invading American society in which educators should and must intervene. That \nis, educators have a responsibility to equip their students with tools for interrogating \nfabrications such as fake news. Using their own expertise and course curriculum, they must help \nstudents navigate and, ideally, not contribute to this current crisis. Educators must guide their \nstudents in not only understanding the phenomena of fake news,  but also in assessing its \nnegative impact on thinking critically, understanding key issues, and making informed \ndecisions \u2014all of which affect democracy and the public sphere. Unfortunately, I do not possess \n2The Liminal: Interdisciplinary Journal of Technology in Education, Vol. 1, Iss. 1 [2019], Art. 6\nhttps://digitalcommons.du.edu/theliminal/vol1/iss1/6\nthe requisite skillset to explain machine-learning techniques nor the forensic technology to \nidentify deep fakes, but as a composition teacher, I may facilitate students in strengthening their \ncritical thinking and research skills, so that they may recognize more low-technological versions \nof fake news and distinguish truths from fabrications.  \nThese tasks , though, are admittedly tricky in the current polarized political atmosphere \ndominated by a president who caters to a radicalized right and a Democratic house who wants to \nquash, repeatedly,  the president\u2019s worse impulses and policies. Instructors must also contend \nwith both a perceived, if not real, political gap between themselves and their students; that is, \nthere is the prevailing stereotype that  colleges and universities are havens for Republic an-\nbashing liberals, places lacking what Cass Sunstein (2018) refers to as \u201cideological diversity.\u201d \nFurthermore, the current president, appealing to his populist base and following Limbaugh\u2019s \nlead about the \u201cfour corners of deceit ,\u201d has also turned liberal  and smart  into potent pejoratives, \nones he often, along with fake news , applies to the mainstream media. Thus, conservative \nstudents, such as those at my university \u2014Michigan Tech in Houghton, Michigan \u2014may arrive \nto class already deeply suspicious of their liberal instructors and  their curriculum. These same \nstudents might also assume that the only prevalent (and harmful ) media bias is a liberal one, \nechoing the sentiment of the most popular and main Republican network, Fox News,1 whose \ndeep affiliations with the radicalized right (Benkler, Faris, & Roberts, 2018) also make it a fake \nnews megaphone. The situation becomes more complex when students confront these \nuncomfortable ideas in first-year courses, which are often seen as hurdles taught by members of \nan inexperienced graduate labor force, many of whom may be international students with \noutsiders\u2019 perspectives. As a very mature and liberal graduate student from Canada, I am in a \nparticularly awkward position to instruct students on media bias and the dangers of fake news, \nfor they often see my stance as elitist, anti-American, and even, gasp!,  socialist . Therefore, in \nleading students through these tasks and their associated concepts, instructors must recognize \nand admit their own politics, while remaining as centrist as possible and stressing that \nrespecting facts and recognizing mistruths are important to everyone across the political \nspectrum. \nNext are summarized two lessons I have used and one that I plan to attempt for \nimparting to students the importance of creating reasonable arguments, of attacking \nunreasonable ones, and of recognizing faulty and/or slanted information: stressing the \nimportance of Composition to a healthy public discourse, distinguishing between types of \nfabrications, and investigating media bias and its relationship to the factuality of information. \n                                                           \n1 Fox is currently the most watched television news network (Katz, 2018), with its October 2018 viewers \ntotaling more than those of MSNBC and CNN combined. This network is growing increasingly popular, averaging \nmore viewers in the 24-hour-day in October 2018 than in October 2016, the strategic month before the election. \n\u201cFNC marked 28 consecutive months as the No. 1 basic cable network in prime time with nea rly 1.7 million total \nviewers for the month of October 2018, and the 5th consecutive month as the most-watched basic cable network in \nprime time with more than 2.8 million viewers, according to Nielsen data\u201d (Katz , 2018). To put this number in \nperspective, MSNBC\u2019s and CNN\u2019s viewers  were 1,575,000 and 931,000. In October 2018, Hannity  also claimed the \ntitle of the most watched cable news program, for the seventh month in a row. \n3Galliah: Interrogating Fake News in the Composition Classroom\nPublished by Digital Commons @ DU, 2019\nFor each of these lessons, there are summaries of key readings and brief explanations of \nclassroom activities. \nStressing the Importance of the First-Year Composition Course \nTo develop an ethos of objectivity, and to stress the significance  of composition beyond \nthe classroom, I assign, near the beginning of the term, John Duffy\u2019s (2012)  short article  \n\u201cVirtuous Arguments .\u201d Although written a few years ago to address Rush Limbaugh\u2019s \ninflammatory rhetoric about Sandra Fluke, this essay speaks even more to the current moment. \nUsing key figures from across the political spectrum, such as Rush Limbaugh, Maxine Waters \nand Neil Boortz, Duffy argues that the state of public discourse is abysmal, toxic, and \ncontagious. However, he contends that in composition classrooms lies at least a partial cure: in \nthese, \u201cthere is a well -organized, systematic, and dedicated effort taking place each day to \npromote an ethical discourse grounded in the virtues of honesty, accountability, and \ngenerosity.\u201d He emphasizes that this course\u2019s instruction in argument is crucial not only for \nwriting essays (and passing the course),  but also for developing ethical reasoning; creating \nsound arguments is fundamentally about acknowledging \u201cthe rationality of the audience,\u201d \ndeveloping a relationship of trust, and making \u201ca statement of our own integrity, our willingness \nto support assertions with proofs.\u201d  In other words, the first step in persuasion is respecting your \nreader by building an argument based on reasons and evidence, rather than emotions, and \ncarefully checking your sources for both mis and disinformation. \nDuffy\u2019s essay is assigned for its several pedagogical purposes. With its clear reasoning, \nstrong examples, variety of sources, integration of naysayers, and respectful, yet impassioned \ntone, it acts as a model of virtuous argument that students may later emulate. The author also \nappears fa ir by including links to debased rhetoric from several political leaders , dismantling the \nidea that liberal professors  customarily attack only the right. Duffy\u2019s linked sources  also enable  \nstudents to explore these unhealthy exchanges further and find comparative examples for \nclassroom discussion. He also addresses how composition is  often  type casted  as a useless class  \nconcerning only the aloof (and , they believe, impractical) studies of grammar and rhetoric. \nInstead, Duffy enthusiastically hales composition as a course that makes a difference: students \nlearn not only how to create effective arguments , but also how to recognize ineffective, \nmisinforme d, and toxic ones \u2014essential , valuable  real-world skills for bettering  discourse in the \ncivic arena and  improving democracy. His essay also underscores crucial points repeated \nthroughout the term: analyzing bad arguments, misinformation, and disinformation in the \npolluted information environment will involve students confronting their own confirmation \nbiases and perfo rming the uncomfortable task of critiquing political leaders whose ideologies \nalign with their own. To this end, when we read this article in class, I request that students bring \nin faulty and/or unfair statements from political leaders they both respect  and disrespect  so that \nthey may practice the virtue of fairness  while confronting  their own prejudices.  \nIn other words, Duffy\u2019s essay helps to situate composition as a course in which students \nrecognize that it is their duty, not just as students, but as both American and global citizens, to \nunderstand the values of ethical arguments and the dangers of faulty  reasoning and mistruths \n4The Liminal: Interdisciplinary Journal of Technology in Education, Vol. 1, Iss. 1 [2019], Art. 6\nhttps://digitalcommons.du.edu/theliminal/vol1/iss1/6\neverywhere , even  those lurking in the most outrageous examples of  fake news.  Throughout the \nterm, I regularly  review  this essay as well as iterate that composition  helps them develop crucial \ncritical thinking skills for navigating the murky  post-truth waters . \nInvestigating Fake News and Its Dissemination \n Once students are familiar with critiquing the strengths and weaknesses of arguments, \ntasks which begin with Duffy\u2019s essay and continue for several weeks on both written and \nmultimodal texts, they progress to interrogating and categorizing fake news. This analysis takes \nplace near the planning of their core research assignments (the annotated bibliography and the \npersuasive research essay). To distinguish between the current misuse of the term fake news  and \nits actual definitions and ramifications, they will read selections from Barclay\u2019s Fake News, \nPropaganda, and Plain Old Lies  (2018), which returns to yellow journalism to uncover the \ntangled, historical roots of fake news. Also assigned are Wardle\u2019s brief but pithy article \u201c Fake \nNews; It\u2019s Complicated \u201d (2017) and its hyperlinks along with this infographic  (nd.) from the \nInternational Federation of Library Associations and Institutions, which offers clues for \ndiscerning fake news.  In class, I also address the current misuse of the term fake news , unpack \nits various definitions, and direct them to other resources, such as various fake news wikis. \nStudents enjoy reading and responding to Wardle\u2019s article because of its nonpartisan \nposition that people of all political beliefs are susceptible to fake news and that, for everyone, \nemotions and personal predispositions contribute to the spread of disinformation. The author \nalso connects the growth of fake news to the transformation from a one- to-many broadcast \nsystem to a one- to-one system in which atoms of information are \u201ctargeted at users who are \nmore likely to accept and share a particular message,\u201d whether it is a  \u201cmisleading or fabricated \narticle, image, video or meme\u201d to those within their circle. This article, then, helps students \nunderstand how their partialities, prejudices, and (seemingly innocuous) social media practices, \nsuch as sharing questionable articles and suspected deep fakes without vetting them, might be \ncontributing to the spread of falsifications and further confusion between truth and fiction. \nLastly, she creates a useful matrix classifying types of fake news and the motivations for \ncreating them. \nIn class, we first consider Wardle\u2019s pithy quote that fighting fake news involves \ninstructing people \u201cto second guess their instinctual reactions. If you find yourself incredibly \nangry at a piece of content or feeling smug (because your viewpoint has been reaffirmed), take \nanother look.\u201d Students discuss whether they have ever shared a dubious story withou t \nthoroughly reading it or checking it because its content bothered or, alternatively, vindicated \nthem. Often, Stephen Colbert\u2019s definition of truthism  is raised in conjunction with sharing these \ntexts.  \nAfter we review these sources in class, students form groups to locate at least two \nparticularly viral but suspicious stories (or a story and a meme) circulating on social media, \nTwitter, and so on, ones they have shared and/or have been shared with them. They then \nanalyze these texts according to two criter ia: Wardle\u2019s misinformation matrix and the prompts \nfrom the IFLIA. That is, they first need to identify the type of fabrication as well as whether its \n5Galliah: Interrogating Fake News in the Composition Classroom\nPublished by Digital Commons @ DU, 2019\nintent is to parody, manipulate, persuade, and so on. When using the IFLIA criteria, students \nmust also evaluate the writer\u2019s credentials, political affiliation, and any potential bias in the \nstory\u2019s original place of publication.  Ideally, they begin this activity in class and then finish it at \nhome by completing slides from a shared Google PowerPoint,  thus contributing the content for \nthe next day\u2019s class.  \nDuring or near this class session, students are also directed to these online sources: Fact-\nCheck\u2019s Misinformation directory  (2018) and PolitiFact\u2019s  Truth-0-Meter (2019). In the past, \nstudents have admitted their unfamiliarity with these resources as well as their subsequent \nusefulness for evaluating circulating political untruths. These sources also create a bridge to the \nnext learning module: recognizing media bias. \nAnalyzing Media Bias and its Relationship to Fake News \nWhat is also key to understanding the fake news phenomena is grasping that both mis \nand disinformation emerge not only from haphazardly written stories shared on social media, \nbut also from respected and/or well-known media outlets. By this point in the term, the class has \ndiscussed the relationship between confirmation bias and the echo chamber. Students are also \nworking on their extended annotated bibliography for their research essay, in which they must \nsummarize and analyze the arguments and evidence of their sources, the methods of these \narticles, and the credibility and potential bias of their authors. Because they may incorporate \ntwo newspaper/magazine articles from well-known sources, they often conflate popular  and \nrespected , a particularly dangerous habit in the current media atmosphere dominated by the \nright-leaning, fact-bending network Fox News, and by the trend of media outlets moving either \nfurther left or further right and producing viral, biased stories.  \nTo make them more media- savvy, I first introduce them to Otero\u2019s media bias org chart  \n(2018), and, on occasion, have even emphasized that all their newspaper/magazine sources \nbelong to the green section, and, if absolutely necessary, the yellow. The website \nhttps://mediabiasfactcheck.com  (2018) is also presented and reviewed for its content, \norganization, information, and methodology. This website\u2019s top menu divides media resources \ninto the following categories: left bias, left-center bias, least biased, right-center bias, right bias, \npro-science, conspiracy-pseudoscience, questionable sources, and satire. It also clearly \ndistinguishes between media bias and factual reporting, so students may see that even if a \nsource has a political slant with which they disagree, this source may still score highly on \nfactual reporting and accurate information. Contrarily, a media source confirming their beliefs \nmay or may not be reliable. This resource is introduced for two main reasons: students must use \nit to verify the credibility of every newspaper or magazine article for their annotated \nbibliography; and they will eventually recruit it for a future class activity.   \nThat is, I am currently designing two classroom activities around the Media Bias/Fact \nCheck website. First, students will be given a (paper or digital) version of the media bias \nfactcheck arrow and then be divided  into small groups. These groups will be assigned a \ncontroversial, polarized, but not overdone topic recently in the news, such as the Dakota Access \nPipeline, the immigration debate, the defunding of the Special Olympics, and so on. Using th e \n6The Liminal: Interdisciplinary Journal of Technology in Education, Vol. 1, Iss. 1 [2019], Art. 6\nhttps://digitalcommons.du.edu/theliminal/vol1/iss1/6\nchosen topic, they will a) either perform a simple Google Search and locate five to ten different \nsources; or b) analyze a selection of sources given to them. They will study these sources, \nanalyzing them for their ideological bent, slanted language, and the credibility of information, \nfact-checking if necessary. Then, they will rank these sources before comparing their analyses \nwith those on the Media Bias/Fact Check website. If there is a discrepancy, students will discuss \nwhy their evaluations differ, which raises the specter of their own political biases. That is, both \nvery liberal and very conservative students often judge sources that disagree with their \nideologies most harshly. Lastly, students will rate the sources from the most to least reputable, \nimagining how and if they could use them for a potential university research essay.  \nOn the subsequent day in class, or as a discussion topic, I may also request that students \ndeeply explore either the \u201cConspiracy -Pseudoscience\u201d or \u201cQuestionable Sources\u201d sections of \nthe same website. If they are working in the first section, they must further investigate some of \nthese conspiracies and generalize about those popular on both the left and the right. If they are \nassigned the second section, they will select a few of these questionable sources, travelling to \ntheir websites and analyzing their content for bias, factual claims, fabrications, fake news, and \nso on. Students will then upload their analyses online as Canvas posts, each one providing a \ndeeper window into these sources, exposing the entire class to these fabrications. In the past, I \nhave found that,  in general, students not only really enjoy researching conspiracies and \nextremely unbelievable, biased fake news , but also tend to explore their findings further for \nfuture essays, such as researching the origins of certain conspiracies.   \nConclusion: Emphasizing that Composition Matters to an Ethical Public Discourse \nAs is evident  from these sample readings and basic lesson plans, teaching students how \nto navigate the post-truth world and the polluted media atmosphere does not necessarily mean \nre-inventing the wheel and discarding those sound practices, such as thinking critically, \nanalyzing texts, conducting research, and scrutinizing sources, which are already situated in the \ncomposition curriculum. By using these and other associated activities, instructors may also \nappear centrist while helping students recognize their own bias es, the slants of various media \nsources, and diverse types of untruths.  \nWhatever their curriculum, instructors must always emphasize that students have a \nsignificant role in detecting fake news, critiquing it, responding to it, and, ideally, eradicating it. \nOr, as Duffy (2012) puts it, in the first-year writing course of composition, students may not \nonly work to move \u201cus toward healthier, more productive, and more generous forms of public \nargument \u201d but also endeavor to build a healthy public sphere in which fake news will fail to \nthrive.  \n7Galliah: Interrogating Fake News in the Composition Classroom\nPublished by Digital Commons @ DU, 2019\nReferences \nAlcott, H., & Gentzkow, M. (2017). Social media and fake news in the 2016 election. Journal of \nEconomic Perspectives , 31(2), 211 -236. \nwww.aeaweb.org/full_issue.php?doi=1257/jep.31.2#page=213  \nBarclay, D. A. (2018). Fake news, propaganda, and plain old lies . Lanham, MD: Rowman & \nLittlefield. \nBenkler, Y., Faris, R. , & Roberts, H. (2018). Network propaganda: Manipulation, \ndisinformation, and radicalization in American politics . New York: Oxford University \nPress. \nCapehart, J. (2017, June 17). Opinion: Donald Trump\u2019s \u2018Mexican rapists\u2019 rhetoric will keep the \nRepublican Party out of the White House. Washington Post . Retrieved from \nhttps://www.washingtonpost.com/blogs/post-partisan/wp/2015/06/17/trumps-mexican-\nrapists-will-keep -the-republican-party-out-of-the-white-house/  \nDuffy, J. (2012, March 6). Virtuous arguments. Inside Higher Ed . Retrieved from \nhttps://www.insidehighered.com/views/2012/03/16/essay-value-first-year-writing-courses  \nFactCheck.o rg. (2018). FactCheck.org . Retrieved from https://www.factcheck.org/  \nGOP, Team. (2018, Jan. 17). The highly anticipated fake news awards. GOP . \nRetrieved from https://gop.com/the-highly-anticipated-2017 -fake-news-awards/  \nHolnan, A. D. (2016, Dec. 13). 2016 Lie of the year: Fake News. Politifact . Retrieved from \nhttp://www.politifact.com/truth-o -meter/article/2016/dec/13/2016- lie-year-fake-news/  \nHorn, H. (2010, Sept. 10). Is the right wing anti-science? Prominent journal Nature  calls out \nconservative commentators and politicians. Politics | The Atlantic . Retrieved from \nhttps://www.theatlantic.com/politics/archive/2010/09/is-the-right-wing-anti-\nscience/344226/  \nInternational Federation of Library Associations and Institutions (IFLA). (nd). How to spot fake \nnews. IFLA . Retrieved from http://blogs.ifla.org/lpa/files/2017/01/How- to-Spot-Fake-\nNews-1.jpg  \nKatz, A. J. (2018, Oct. 30). October 2018 ratings: Fox News channel averaged more total \nviewers than CNN and MSNBC combined. TVNewser . Retrieved from \nhttps://www.adweek.com/tvnewser/october-2018 -ratings-fox-news-channel-averaged-\nmore-viewers-than-cnn-and-msnbc-combined/382598  \nMedia Bias/Fact Check. (2019).  Media Bias/Fact Check . Retrieved from \nhttps://mediabiasfactcheck.com/fake-news/  \nMcIntyre, L. (2017). Post-Truth . The MIT Press Essential Knowledge series . [Kindle version]. \nBoston: The MIT Press. \nOtero, V. (2018). Media bias chart: Version 4. MediaBias.org . Retrieved from \nhttps://www.adfontesmedia.com/  \nPolitifact. (2019, Jan. 13). Truth-O-Meter. Politifact . Retrieved from \nhttps://www.politifact.com/truth-o -meter/statements/  \n8The Liminal: Interdisciplinary Journal of Technology in Education, Vol. 1, Iss. 1 [2019], Art. 6\nhttps://digitalcommons.du.edu/theliminal/vol1/iss1/6\nRabin-Havt, Ari & Media Matters. (2016). Lies incorporated: The world of post-truth politics . \nAnchor Books: New York. \nSchwartz, O. You thought fake news was bad? Deep fakes are where truth goes to die. \nTechnology | The Guardian . Retrieved from \nhttps://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth  \nSunstein, C. (2018, Sept. 17). The problem with all those liberal professors: \nThe paucity of Republicans at many top schools hurts everyone. Bloomberg. Retrieved \nfrom https://www.bloomberg.com/opinion/articles/2018-09 -17/colleges-have-way-too-\nmany-liberal-professors  \nVincent, J. (2018, April 17). Watch Jordan Peele use AI to make Barack Obama deliver a PSA \nabout fake news. The Verge. Retrieved from \nhttps://www.theverge.com/tldr/2018/4/17/17247334/ai-fake-news-video-barack-obama-\njordan -peele-buzzfeed  \nWardle, C. (2017, Feb. 16). Fake new s: It\u2019s complicated. FirstDraft. Retrieved from  \nhttps://medium.com/1st-draft/fake-news -its-complicated-d0f773766c79 . \nWashington Post. (2018, Dec. 30). In 710 days, Trump has made 7,645 false or misleading \nclaims. Washington Post . Retrieved from \nhttps://www.washingtonpost.com/graphics/politics/trump-claims-\ndatabase/?utm_term=.3f7b612f1a3c  \n \n9Galliah: Interrogating Fake News in the Composition Classroom\nPublished by Digital Commons @ DU, 2019", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Interrogating Fake News in the Composition Classroom: Pedagogical Plans", "author": ["SA Galliah"], "pub_year": "2019", "venue": "The Liminal: Interdisciplinary Journal of \u2026", "abstract": "This brief article argues that the skills developed in the first-year Composition classroom, such  as analyzing texts, interrogating arguments, investigating media bias, conducting research"}, "filled": false, "gsrank": 136, "pub_url": "https://digitalcommons.du.edu/theliminal/vol1/iss1/6/", "author_id": ["h31G32AAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:uAQz_Yksk-oJ:scholar.google.com/&output=cite&scirp=135&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=uAQz_Yksk-oJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:uAQz_Yksk-oJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://digitalcommons.du.edu/cgi/viewcontent.cgi?article=1029&context=theliminal"}}, {"title": "A Replication Report on\" Political polarization of news media and influencers on Twitter in the 2016 and 2020 US presidential elections\" by Flamino et al. 2023", "year": "2025", "pdf_data": "Kn\u00f6pfle, Philipp; Haim, Mario; Breuer, Johannes\nWorking Paper\nA Replication Report on \"Political polarization of news media and\ninfluencers on Twitter in the 2016 and 2020 US presidential elections\"\nby Flamino et al. 2023\nI4R Discussion Paper Series, No. 238\nProvided in Cooperation with:\nThe Institute for Replication (I4R)\nSuggested Citation: Kn\u00f6pfle, Philipp; Haim, Mario; Breuer, Johannes (2025) : A Replication Report\non \"Political polarization of news media and influencers on Twitter in the 2016 and 2020 US\npresidential elections\" by Flamino et al. 2023, I4R Discussion Paper Series, No. 238, Institute for\nReplication (I4R), s.l.\nThis Version is available at:\nhttps://hdl.handle.net/10419/319836\nStandard-Nutzungsbedingungen:\nDie Dokumente auf EconStor d\u00fcrfen zu eigenen wissenschaftlichen\nZwecken und zum Privatgebrauch gespeichert und kopiert werden.\nSie d\u00fcrfen die Dokumente nicht f\u00fcr \u00f6ffentliche oder kommerzielle\nZwecke vervielf\u00e4ltigen, \u00f6ffentlich ausstellen, \u00f6ffentlich zug\u00e4nglich\nmachen, vertreiben oder anderweitig nutzen.\nSofern die Verfasser die Dokumente unter Open-Content-Lizenzen\n(insbesondere CC-Lizenzen) zur Verf\u00fcgung gestellt haben sollten,\ngelten abweichend von diesen Nutzungsbedingungen die in der dort\ngenannten Lizenz gew\u00e4hrten Nutzungsrechte.Terms of use:\nDocuments in EconStor may be saved and copied for your personal\nand scholarly purposes.\nYou are not to copy documents for public or commercial purposes, to\nexhibit the documents publicly, to make them publicly available on the\ninternet, or to distribute or otherwise use the documents in public.\nIf the documents have been made available under an Open Content\nLicence (especially Creative Commons Licences), you may exercise\nfurther usage rights as specified in the indicated licence.\n \nJune  2025  \n \n   \n \n \n \nNo. 238  \nI4R DISCUSSION PAPER SERIES \n \nA Replication Report on \n\u201cPolitical polarization of news media \nand influencers on Twitter in the 2016 \nand 2020 US presidential elections\u201d \nby Flamino et al. 2023  \n \nPhilipp Kn\u00f6pfle \nMario Haim  \nJohannes Breuer  \n \n      \n \nE-Mail: joerg.peters@rwi -essen.de Hohenzollernstra\u00dfe 1-3  www.i4replication.org  \nRWI \u2013 Leibniz  Institute for Economic Research  45128 Essen/Germany    \n  ISSN: 2752- 1931   \n \nI4R DISCUSSION PAPER SERIES  \nI4R DP No. 238 \nA Replication Report on \u201cPolitical polarization of \nnews media and influencers on Twitter in the \n2016 and 2020 US presidential elections\u201d,  \nby Flamino et al. 2023  \nPhilipp Kn\u00f6pfle1, Mario Haim1, Johannes Breuer2 \n1LMU Munich/G ermany  \n2GESIS \u2013 Leibniz Institute for the Social Science, Cologne/Germany  \nJUNE  2025 \nAny opinions in this paper are those of the author(s) and not those of  the Institute for Replication ( I4R). Research published in this series may \ninclude views on policy, but I4R takes no institutional policy positions.  \nI4R Discussion Papers are research papers of the Institute for Replication which are widely circulated to promote replication s and meta-\nscientific work in the social sciences. Provided in cooperation with EconStor, a service of the ZBW \u2013 Leibniz Information Centre for Economics , \nand RWI \u2013 Leibniz Institute for Economic Research, I4R Discussion Papers are among others listed in RePEc (see IDEAS, EconPapers). \nComplete list of all I4R DPs -  downloadable for free  at the I4R website.  \nI4R Discussion Papers often represent preliminary work and are circulated to encourage discussion. Citation of such a paper s hould account \nfor its provisional character. A revised version may be available directly from the author.  \nEditors  \nAbel Brodeur  Anna Dreber  J\u00f6rg Ankel -Peters \nUniversity of Ottawa Stockholm School of Economics  RWI \u2013 Leibniz  Institute for Economic Research  \n\nA Replication Report on \u201cPolitical polarization of news media and \ninfluencers on Twitter in the 2016 and 2020 US presidential \nelections\u201d by Flamino et al. 2023  \nPhilipp Kn\u00f6pfle [1]  \nMario Haim [2]  \nJohannes Breuer [3]  \nAbstract  \nFlamino et al. (2023) estimate the levels of ideological polarization and echo chamber behavior \nfor Twitter (now X) users during the 2016 and 2020 U.S. presidential elections using political bias \nclassification and network analysis methods. Using 873 milli on tweets, they find a decline in the \nproportion of fake and extremely biased content but identify an increase in echo chamber \nbehaviors and latent ideological polarization among both users and influencers over the \ninvestigated period. Using the Twitter da ta and analysis code provided in the complementary \nOSF.io repository , we successfully reproduced the results of their analysis with only minor \ndeviations due to small technical adjustments. In general, social media analyses frequently blur \nthe distinction between reproduction and replication due to the dynamic nature of platform data \nand changing access policies resulting in diffi culties retrieving consistent datasets over time.  \nHence, we conducted a robustness check by querying the Twitter/X Batch Compliance API to \nevaluate how many tweets from the initial dataset remain accessible today. Our \"rehydration\" \nattempts expose d substantial limitations in the Twitter/X API, as data retrieval issues arose across \nboth free and paid access tiers, preventing us from re -collecting the original dataset or obtaining \nreliable estimates of tweet accessibility from the original study. Whil e the study was largely \nreproducible with the intermediary and aggregated data provided, its full reproducibility and \nreplicability are constrained by restrictive social media platform data access policies.  \nInstitute for Replication\nI4R DP No. 238\n3\n1.Introduction\nSocial media has fundamentally transformed political communication dynamics over the \npast decades, with platforms like Twitter1 playing a prominent role in disseminating news \nand shaping public opinion (see, e.g., Crilley & Gillespie, 2019; Zhuravskaya, Petrova, \nand Enikolopov, 2020). In light of these changes, research has repeatedly raised \nconcerns about the spread of disinforma tion (e.g., A\u00efmeur, Amri, and Brassard, 2023), \nthe creation of echo chambers (e.g., Cinelli et al., 2021), and the deepening of ideological \npolarization (e.g., Kubin and von Sikorski, 2021). Our replication report focuses on a \nprominent study from this are a. The study by Flamino et al. (2023) investigated \npolarization dynamics on Twitter during the 2016 and 2020 U.S. presidential elections. \nMore specifically, the study used 873 million tweets to analyze shifts in the political \nlandscape of Twitter, focusing  on changes in the dissemination of politically biased and \nfake news, the role of political influencers, as well as patterns of polarization over time.  \nThe original study by Flamino et al. (2023) was motivated by a growing body of literature \ndocumenting increasing polarization in the United States. Researchers have observed \nboth issue polarization among political elites, such as elected representatives an d news \norganizations, and affective polarization among voters, characterized by growing partisan \nanimosity. While traditional survey and roll call voting data have limitations in capturing \nthe temporal and relational dynamics of polarization, the rise of s ocial media offers \nunprecedented opportunities for tracking the diffusion of political information and \nmisinformation on a large scale. Platforms like Twitter, Facebook, and Reddit provide vast \ndata for analyzing how political messages propagate within (an d across) social networks, \noffering insights into various dynamics, such as the spread of disinformation or the \nemergence of echo chambers.  \nThe study by Flamino et al. (2023) analyzed data collected during the months leading up \nto the 2016 and 2020 U.S. elections (June 1 to election day: November 8, 2016, and \nNovember 2, 2020). The 2016 dataset consists of 171 million tweets from 11 million us ers, \n1 Since 23.07.2023, the platform formerly known as Twitter has been renamed to X. In this report, we \ncontinue to use the name Twitter, as the data originate from a period when the platform was still known \nby that name. Accordingly, we will use the term \u201ctwee ts\u201d when referring to posts on the platform.  \nInstitute for Replication\nI4R DP No. 238\n4\nwhereas the 2020 dataset contains 702 million tweets from 20 million users, reflecting a \nlarge increase in participation in political discourse on this platform over the four -year \nperiod. Tweets were collected using the names of presidential candidates as keywords. \nThe researchers supplemented the datasets with political bias classifications, extracting \nthe domain names of URLs in tweets linking to news media outlets. Each outlet was \nclassified according to its political bias using the bias classification f rom allsides.com (AS) \nfor outlets with a documented bias rating in their database, and from \nmediabiasfactcheck.com (MBFC) for others. These classifications were accessed on \nJanuary 7, 2021, for the 2020 dataset.  \nTo identify key political influencers \u2014users with the highest potential to spread \ninformation \u2014the researchers performed a network analysis. They created a similarity \nnetwork based on the frequency with which users retweeted influencers, using a cosine \nsimilarity matrix to quantify the overlap in retweet patterns. This allowed them to construct \nan adjacency matrix that revealed the connections between influencers based on shared \nuser interactions. The analysis uncovered two primary communities in both electio n \nyears: one predominantly composed of influencers linked to fake news and right -leaning \noutlets, and another associated with center and left -leaning outlets. The division between \nthese communities was assessed using metrics such as modularity and normaliz ed cut, \nwhich demonstrated a stronger polarization in the 2020 dataset compared to 2016.  \nThe main findings of the original study are both descriptive and comparative. First, the \nresearchers assessed the proportion of fake and extremely biased news content on \nTwitter between the two elections. Second, they document an increase in echo chamber \nbehaviors and latent ideological polarization among both all users and influencers, \noperationalized as the degree of separation between the political alignments of content \nshared by users. The study further found that new influencers emerging in 2020 were \nmore polarized than those active in 2016. Additionally, there was a notable shift in the \ncomposition of influencers with a reported decline in those affiliated with news \norganizations and a rise in those tied to political organizations.  \nThe present replication report aims to computationally reproduce (Dreber & Johannesson, \n2023) and validate these findings. By computationally reproducing the original analyses, \nInstitute for Replication\nI4R DP No. 238\n5\nthis report seeks to assess the reliability of the original study\u2019s conclusions and can, thus, \nalso contribute to broader discussions about transparency and rigor in computational \nsocial science research. Due to Twitter/X API restrictions, we are unable to  replicate \nFlamino et al.'s data collection process. Consequently, we are also unable to reproduce \ntheir data pre -processing pipeline.  \n2.Data and material availability\na.Reproduction restrictions\nTwitter has implemented various regulatory and technical limitations which, in turn, \ninfluence the possibilities of reproduction (see Breuer & Haim, 2024 for a discussion of \nthis issue). Importantly, the raw Twitter data cannot be shared according to the p latform\u2019s \nown terms of services. The initial data in 2016 and 2020 was collected via Twitter\u2019s so -\ncalled Firehose API which has been shut down since.2 Moreover, after the acquisition of \nTwitter by Elon Musk and changes in its policies, Twitter has implemented significant \nchanges in its API access, including pricing and usage restrictions. The Firehose API is \nno longer available under the same conditions , and access now typically comes through \nspecific commercial partnerships or premium API tiers. However, as has been critically \nobserved in similar public -private collaborations, such partnerships may undermine the \nindependence of academic research (Breuer  et al., 2020; Wagner, 2023).  \nA common way of addressing the data sharing limitations that is also used by Flamino et \nal. (2023) involves sharing the tweet IDs from the original sample, enabling replicators to \nselectively re -query these tweets via the API in a process known as rehydrat ion. However, \ngiven the current pricing structure of Twitter's API, this approach seems highly impractical: \nA quick back -of-the-envelope calculation shows that re -querying the original data used \nby Flamino et al. (2023) via the Twitter API under the new fi nancial and access restrictions \nwould cost approximately: 873.000.000 tweets / 1.000.000 tweets per month (read -limit \nat the Twitter -API at the \u201cPro\u201d access tier)3 * 5.000 $\n\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc61\u210e = 4.365.000$. With the rate limits \n2 See https://developer.x.com/en/updates/changelog . \n3 See access level \u201cpro\u201d: https://developer.x.com/en/products/x -api. \nInstitute for Replication\nI4R DP No. 238\n6\nin place at this level of API access, it would also take roughly 72,75 years [(873.000.000 \ntweets / 1.000.000 tweets per month) / 12 months] to recollect the full data. Even if a team \nof researche rs had such time and financial resources , research has shown that re -\ncollecting tweets often results in a significant loss of the original sample (Pfeffer et al., \n2022) \u2014 this can amount to even up to 45% of the data  (Kn\u00f6pfle & Schatto -Eckrodt, \n2024) . This issue is especially pronounced when dealing with datasets that include \ndiscussions on sensitive and pol arizing topics (Assenmacher et al., 2023; K\u00fcpfer, 2024). \nGiven the steep costs, the extensive time required to re -query the data, and the very low \nlikelihood of achieving full rehydration success, this method is unlikely to be a feasible \noption for replication ana lyses that involve larger Twitter data sets.  \nSo, on one hand, the inability to share raw materials limits the capacity to re -run analyses, \na key aspect of reproduction. On the other hand, relying on rehydration allowed for by the \nplatform\u2019s terms of service, leads to systematic data loss, aligning mo re closely with a \nconceptual replication. Consequently, while our analysis falls within the scope of \nsystematic replications, we classify our approach as a computational reproduction (see \nDreber & Johannesson, 2024).  \nInstitute for Replication\nI4R DP No. 238\n7\nb.Data and Code Availability in Flamino et al. (2023)\nFlamino et al.\u2019s (2023) OSF.io repository  contains all the analysis code necessary to \ncomputationally reproduce their analysis and generate the six figures that summarize the \ncentral findings of their study. The repository includes 26 Python scripts, 10 R files, as \nwell as C and Cython source file s, all of which are essential for reproducing their results. \nHowever, due to restrictions on sharing raw Twitter data (as noted above), Flamino et al. \n(2023) opted to share an anonymized and processed version of their dataset. This dataset \ncontains the fol lowing information: tweet ID, user ID, date and time of the tweet, political \norientation, and information about whether  the tweet came from an official/unofficial \nsource. The unzipped text file containing just the tweet IDs themselves is roughly 16 GB \nin size. Table 1 provides a summary of the materials provided via the OSF repository.  \nAs their analysis is very computationally intensive, it is important and commendable to \nnote that Flamino et al. (2023) provide intermediary outputs of their calculations when \nfeasible, such as network models, summarized data, and other analysis artifacts.  We \nreproduced Flamino et al.\u2019s (2023) analysis on a Windows desktop computer with the \nfollowing specifications: Windows 11 Pro 64 -Bit, Intel i9 -10900 3.7 GHz with 20 cores, \nand 32GB RAM. The replication took place between July and November 2024. The \nrepro duction was performed  with Python (V. 3.12.3 ) and R (R. 4.3.3 ). \nFully  Partial  No \nRaw data provided  x \nProcessing code provided  x \nAnalysis data provided  x \nAnalysis code provided  x \nIntermediary data output  x \nTable 1 Reproduction material availability  \nInstitute for Replication\nI4R DP No. 238\n8\nc.Contact with the original authors\nThe initial OSF repository for this study included almost all necessary materials for \nreproduction. There only was a minor issue with limited access to the linked 2020 data \nset. To resolve this issue, we reached out to the original authors via the Institut e for \nReplication and the original authors provided assistance that addressed the specific \nproblem in a timely manner. Shortly after this, the authors also made several updates to \nthe OSF repository, including revisions to the code, data organization, and \ndocumentation. These updates resulted in significant improvements in the usability of the \nrepository for our replication/reproduction. Notably, only with the revised materials, we \nwere able to successfully reproduce the study's results as described in the following.  \n3.Computational reproduction of Flamino et al. (2023)\nFlamino et al. (2023) present the majority of their findings through six key figures in their \npaper. In our reproduction attempt4, we successfully replicated five of these figures. Our \ntable 2 summarizes our reproduction process of the figures from Flamino et al. (2023), \ndetailing the data basis, reproduction changes (such as file -path adjustments and \nencoding modifications), and th e success of each reproduction, with corresponding \ndeviations and minor issues noted for figures where this applies.  \nWe present our reproduced versions of these figures in the following. We were unable to \nreproduce Figure 2, which is a Sankey diagram. The issue appears to stem from \ncompatibility problems with the underlying chart rendering libraries in our computational \nenvironment. Additionally, we found minor differences across the news categories for \nFigure 1. These differences are relatively small and do not affect the conclusions, given \nthe large volume of data involved. Considering the sheer size and comp utational \ncomplexity of the project the reproduction process overall went smoothly, requiring only \nminor adjustments to account for differences in computing environments and technical \n4 For code and other materials used in our reproduction, see https://osf.io/a4uxk/ . \nInstitute for Replication\nI4R DP No. 238\n9\nspecifications, such as file path modifications, additional library installations, and file \nrenaming.  \nThe most common adjustments involved modifying file paths to adapt from a Unix -based \nsystem (used in the original analysis) to a Windows -based system, including converting \nrelative paths to absolute paths. Encoding changes were also required to ensure data  \ncompatibility. Beyond these basic adjustments, additional changes were necessary to \naddress library and dependency issues. These included, for example, updating specific \ndependencies (e.g., updating the floweaver Python library from version 2.0.1 to 2.1.0 ), \nresolving widget rendering errors, and correcting minor typos in the OSF folder names \n(e.g., changing 'ulrs' to 'urls'). In some cases, we needed to rename files for consistency \nwith the provided scripts (e.g., renaming sim_network_large_2020_anon.pkl t o \nsim_network_large_2020.pkl and similarly for the 2016 file).  \nWe also encountered and resolved a few library -specific conflicts  on our machine . For \ninstance, the Python library python -louvain required reinstallation to avoid name space \nconflicts, and the R package Matrix had to be installed separately to ensure proper \nfunctionality.  \nOverall, the minor nature of the adjustments we made underscores the robustness of the \noriginal analysis, as the majority of the results could be reproduced without substantial \nchanges. This experience also serves as a reminder of the technical challenges that can \narise when reproducing complex computational social science research across different \ncomputing environments, even when the original materials are well -prepared and publicly \navailable. Some minor  lack of information about the original authors\u2019 computational \nenvironment is also in line with more systematic evaluations of study reproducibility \n(Artner et al., 2021; Chan et al., 2024).  \nInstitute for Replication\nI4R DP No. 238\n10\nFigure \n# Figure Title  Data basis  Reproduction changes  Reproduction \nSuccess?  \nFigure 1  Distribution of \nnews media links \nin 2016 and 2020 \nby news media \ncategory.  The authors provide an \nanonymized and pre -\nprocessed version of the data.  File-path adjustments from \nUnix to Windows system.  Yes, see Figure 1 and \nTables A1 and A2 in \nthe appendix for \ndeviations from the \nauthor -provided \nvalues. Reproduction \nsuccessful with minor \nadjustments.  \nFigure 2  Shifts of users \nacross news \nmedia categories \nfrom 2016 to 2020.  Intermediary data provided.  File-path adjustments from \nUnix to Windows system, \nencoding changes.  No, the Python script \nfor generating the \nSankey diagram does \nnot render properly in \nour computational \nenvironment.  \nFigure 3  Reshuffling \ndistribution of the \ntop 25 influencer \ntypes from 2016 to \n2020, by news \nmedia category.  Intermediary data provided.  File-path adjustments from \nUnix to Windows system.  Yes, see Figure 2.  \nFigure 4  Change in \ninfluencers\u2019 \nrankings from \n2016 to 2020.  Intermediary data provided.  File-path adjustments from \nUnix to Windows system, \nencoding changes, update \nof floweaver dependency \nfrom version 2.0.1 to 2.1.0, \nadjusted widget rendering \ndue to programming \nenvironment \nincompatibilities.  Yes, see Figure 3.  \nFigure 5  Similarity networks \nfor nodes among \nthe top 25 \ninfluencers from \neach news media \ncategory for the \ntwo election years.  Intermediary data provided.  Corrected a minor typo in \nthe OSF.io folders (ulrs \ud83e\udc6a \nurls), file -path adjustments, \nre-import community library \nbecause of naming conflict \n(\u201cpip install python -lovain\u201d), \nrenamed file from \n\u201csim_network_large_2020_\nanon.pkl\u201d to \n\u201csim_network_large_2020.p\nkl\u201d and \n\u201csim_network_large_2016_\nanon.pkl\u201d to \n\u201csim_network_l arge_2016.p\nkl\u201d. Yes, see Figure 4.  \nFigure 6  Latent ideology \nscale of \ninfluencers and \ntheir retweeters in \n2016 (left) and \n2020 (right).  Intermediary data provided.  File-path adjustments, \nadditionally installed R \nlibrary \u201cMatrix\u201d.  Yes, see Figure 5.  \nTable 2 Reproduction success overview\nInstitute for Replication\nI4R DP No. 238\n11\nFigure 1 Our reproduction of Figure 1 in Flamino et al. (2023)  \nFigure 2 Our reproduction of Figure 3 in Flamino et al. (2023)  \nInstitute for Replication\nI4R DP No. 238\n12\nFigure 3 Our reproduction of Figure 4 in Flamino et al. (2023 ) \nFigure 4 Our reproduction of figure 5 in  Flamino et al. (2023)  \nInstitute for Replication\nI4R DP No. 238\n13\nFigure 5 Our reproduction of figure 6 in Flamino et al. (2023)  \n4.Twitter Rehydration attempt\nPerforming a complete reproduction or any in -depth replication of Flamino et al.'s analysis \nrequires a re -collection of the original raw data set.5 That is, since Twitter/X data cannot \nbe shared for legal reasons, fully replicating each step of their analysis - such as applying \nthe same preprocessing pipeline - requires access to the original data. In the case of \nTwitter/X data rehydration provides a  somewhat cost-efficient approach to achieve this. \nHowever, as previously discussed, this is not a feasible option for a research team with \nmoderate resources due to the current restrictions imposed by the Twitter /X API. To \ndemonstrate what a data recollection might yield under today\u2019s access conditions, we \ninitially planned to use the Twitter /X Batch Compliance API6 to rehydrate a sub-sample of \n5 For a direct replication, rehydration appears to be the most practical approach, while a conceptual \nreplication would benefit from designing a new data collection strategy.  \n6 See https://developer.x.com/en/docs/x -api/compliance/batch -compliance/quick -start. It is important to \nnote that the Twitter Batch Compliance API is not designed for researchers but rather for developers to \nprogrammatically ensure datasets remain compliant with Twitter's policies by handling large -scale updates \non the status of tweets and user accounts, such as deletions or suspensions.  \nInstitute for Replication\nI4R DP No. 238\n14\nFlamino et al.\u2019s dataset. The Batch Compliance API allows researchers to evaluate the \nextent to which their datasets remain intact by identifying tweets or user accounts that \nhave been deleted, made private, or restricted since the original data collection. \nResearchers submit a batch of tweet or user IDs through the compliance request endpoint \nof the Twitter /X API. The API then checks each ID against Twitter /X's database to \ndetermine its current status \u2014whether it has been deleted, made private, or restricted \u2014\nand returns a compliance status for each ID, helping researchers assess the availability \nof the data (Kn\u00f6pfle & Schatto -Eckrodt, 2024). While this allows u s to hypothetically \ngauge the current accessibility of the data, it does not replace a full re -collection of the \ndataset.  \nWe attempted to connect to the API under the free access tier in July and December \n2024. In July 2024, we were unable to receive any response from the API or submit \nrequests. However, in December 2024, we successfully queried the API, but received \nempty fi elds where tweet statuses were expected, a common issue reported with the API7. \nNotably, in December, the API had previously introduced a rate limit across all access \ntiers, restricting the frequency of queries. We also tested the API under the paid \u201cBasic \u201d \naccess  tier8. Although we were able to connect and send requests  to the API , we still \nencountered issues with retrieving the expected data. Therefore, under the current \naccess conditions, not only are we unable to actually re -collect the data, but we were also \nunable to assess the number  of tweets that would potentially be re -collectable.  \nOverall, our attempts to rehydrate the dataset under the current API access conditions \nhighlight the challenges researchers face in reproducing and replicating social media -\nbased studies, underscoring the limitations imposed by evolving platform policies a nd \naccess restrictions and the assessment made by Davidson et al. (2023) that \u201cPlatform -\ncontrolled social media APIs threaten open science\u201d.  \n7 See https://devcommunity.x.com/t/batch -compliance -getting -empty -response/158801 , \nhttps://devcommunity.x.com/t/batch -compliance -endpoint -returning -incomplete -results/225311 , \nhttps://devcommunity.x.com/t/batch -compliance -not-returning -expected -result -for-deleted -tweets/179554 , \nhttps://devcommunity.x.com/t/batch -compliance -results -highly -inconsistent -with-tweet -lookup/171605 , \nhttps://devcommunity.x.com/t/batch -compliance -getting -empty -response/158801 ,  \n8 See https://developer.x.com/en/products/x -api. \nInstitute for Replication\nI4R DP No. 238\n15\n5.Conclusion\nWe were able to successfully computationally reproduce the findings of Flamino et al. \n(2023) by recreating five out of six key figures from their analysis of Twitter dynamics \nduring the 2016 and 2020 U.S. presidential elections based on the data, code, and \nadditional materials provided by the authors via their OSF  reposi tory. Minor discrepancies \nin Figure 1 were negligible, while Figure 2, a Sankey diagram, could not be reproduced \ndue to rendering library compatibility issues in our computational environment . \nOverall, the reproduction required only minor adjustments, such as modifying file paths, \ncorrecting typos, addressing encoding issues, and updating software dependencies. \nThese adjustments were primarily related to differences in computing environments and  \ndid not reflect issues with the original materials. The authors\u2019 provision of intermediary \ndata outputs and detailed code was instrumental in facilitating the process , offering an \neffective approach to replicating Twitter/X studies where data sharing is restricted for legal \nreasons.  \nThe outcomes of our endeavor underscore both the robustness of the original analysis as \nwell as the importance of comprehensive, well -documented materials in computational \nsocial science research. It also further highlights ongoing challenges posed by chan ging \ndata access policies for platform APIs and software dependencies, emphasizing the need \nfor transparent and accessible data access and research practices.  \nInstitute for Replication\nI4R DP No. 238\n16\nReferences  \nArtner, R., Verliefde, T., Steegen, S., Gomes, S., Traets, F., Tuerlinckx, F., & Vanpaemel, \nW. (2021). The reproducibility of statistical results in psychological research: An\ninvestigation using unpublished raw data. Psychological Methods , 26(5), 527 -546.\nAssenmacher, D., Sen, I., Fr\u00f6hling, L., & Wagnero, C. (2023). The end of the rehydration \nera-the problem of sharing harmful twitter research data. In 2nd Workshop on Novel \nEvaluation Approaches for Text Classification Systems (NEATCLasS) . \nA\u00efmeur, E., Amri, S., & Brassard, G. (2023). Fake news, disinformation and \nmisinformation in social media: a review. Social Network Analysis and Mining , 13(1), 30.  \nBreuer, J., Bishop, L., & Kinder -Kurlanda, K. (2020). The practical and ethical challenges \nin acquiring and sharing digital trace data: Negotiating public -private partnerships. New \nMedia & Society , 22(11), 2058 \u20132080.  \nBreuer, J., & Haim, M. (2024). Are We Replicating Yet? Reproduction and Replication in \nCommunication Research. Media and Communication , 12. \nChan, C. H., Schatto -Eckrodt, T., & Gruber, J. (2024). What makes computational \ncommunication science (ir) reproducible?. Computational Communication Research , 6(1). \nCinelli, M., De Francisci Morales, G., Galeazzi, A., Quattrociocchi, W., & Starnini, M. \n(2021). The echo chamber effect on social media. Proceedings of the National Academy \nof Sciences , 118(9), e2023301118.  \nCrilley, R., & Gillespie, M. (2019). What to do about social media? Politics, populism and \njournalism. Journalism, 20(1), 173 -176. \nDavidson, B. I., Wischerath, D., Racek, D., Parry, D. A., Godwin, E., Hinds, J., Van Der \nLinden, D., Roscoe, J. F., Ayravainen, L., & Cork, A. G. (2023). Platform -controlled social \nmedia APIs threaten open science. Nature Human Behaviour . \nDreber, A., & Johannesson, M. (2024). A framework for evaluating reproducibility and \nreplicability in economics. Economic Inquiry . \nFlamino, J., Galeazzi, A., Feldman, S., Macy, M. W., Cross, B., Zhou, Z., ... & Szymanski, \nB. K. (2023). Political polarization of news media and influencers on Twitter in the 2016 \nand 2020 US presidential elections. Nature Human Behaviour , 7(6), 904 -916. \nKn\u00f6pfle, P., & Schatto -Eckrodt, T. (2024). The Challenges of Replicating Volatile \nPlatform -Data Studies: Replicating Schatto -Eckrodt et al.(2020). Media and \nCommunication , 12. \nK\u00fcpfer, A. (2024). NonRandom Tweet Mortality and Data Access Restrictions: \nCompromising the Replication of Sensitive Twitter Studies. Political Analysis , 1-14. \nInstitute for Replication\nI4R DP No. 238\n17\nKubin, E., & Von Sikorski, C. (2021). The role of (social) media in political polarization: a \nsystematic review. Annals of the International Communication Association , 45(3), 188 -\n206. \nPfeffer, J., Mooseder, A., Hammer, L., Stritzel, O., & Garcia, D. (2022). This Sample \nseems to be good enough! Assessing Coverage and Temporal Reliability of Twitter\u2019s \nAcademic API. ArXiV.  \nWagner, M. W. (2023). Independence by permission. Science , 381(6656), 388 -391. \nZhuravskaya, E., Petrova, M., & Enikolopov, R. (2020). Political effects of the internet and \nsocial media. Annual Review of Economics , 12(1), 415 -438. \nInstitute for Replication\nI4R DP No. 238\n18\nAppendix  \nTable A1. Minor reproduction differences for Flamino et al.\u2019s (2023) figure 1, year 2016. \nNews Category  Replicated unique \nusers 2016 (N_rep)  Unique users 2016 (N)  Absolute \ndifference  \n(N_rep \u2013 N) Relative \nDifference \n(%) \n((N_rep \u2013 \nN)/N)*100  \nFake & extreme \nbias (N_u)  244986  244971  -15 -0.0061\nRight news \n(N_u)  175445  175519  -74 -0.0422\nRight leaning \nnews (N_u)  64055  63903  152 0.2378  \nCenter news \n(N_u)  596776  596951  -175 -0.0293\nLeft leaning \nnews  901643  901885  -242 -0.0268\nLeft news (N_u)  326901  326577  324 0.0992  \nFake & extreme \nbias (p_u)  0.1060635  0.106057  0.0000065  0.0061  \nRight news \n(p_u)  0.0759566  0.07598863  -\n0.00003203  -0.0422\nRight leaning \nnews (p_u)  0.02773177  0.02766596  0.00006581  0.2379  \nCenter news \n(p_u)  0.2583663  0.2584421  -0.0000758 -0.0293\nLeft leaning \nnews (p_u)  0.3903544  0.3904592  -0.0001048 -0.0268\nLeft news (p_u)  0.1415275  0.1413872  0.0001403  0.0992  \nFake & extreme \nbias (Nt_Nu)  30.9006  30.90249  -0.00189 -0.0061\nRight news \n(Nt_Nu)  22.98318  22.97349  0.00969  0.0422  \nInstitute for Replication\nI4R DP No. 238\n19\nRight leaning \nnews (Nt_Nu)  15.7169  15.75428  -0.03738 -0.2373\nCenter news \n(Nt_Nu)  10.59402  10.59091  0.00311  0.0294  \nLeft leaning \nnews (Nt_Nu)  8.308548  8.306318  0.00223  0.0268  \nLeft news \n(Nt_Nu)  13.31901  13.33223  -0.01322 -0.0991\nFake & extreme \nbias (pu_no)  0.0568808  0.05705573  -\n0.00017493  -0.3065\nRight news \n(pu_no)  0.06250962  0.06225537  0.00025425  0.4083  \nRight leaning \nnews (pu_no)  0.09039107  0.09065302  -\n0.00026195  -0.2889\nCenter news \n(pu_no)  0.05480951  0.05476999  0.00003952  0.0721  \nLeft leaning \nnews (pu_no)  0.05939269  0.05945104  -\n0.00005835  -0.0981\nLeft news \n(pu_no)  0.07018945  0.07024377  -\n0.00005432  -0.0773\nFake & extreme \nbias \n(Ntno_Nuno)  70.91166  70.69858  0.21308  0.3014  \nRight news \n(Ntno_Nuno)  39.63217  39.77725  -0.14508 -0.3648\nRight leaning \nnews (col 9)  31.78981  31.77335  0.01646  0.0518  \nCenter news \n(Ntno_Nuno)  38.37378  38.39021  -0.01643 -0.0428\nLeft leaning \nnews \n(Ntno_Nuno)  19.2202  19.19618  0.02402  0.1251  \nLeft news \n(Ntno_Nuno)  26.21368  26.2194  -0.00572 -0.0218\nInstitute for Replication\nI4R DP No. 238\n20\nTable A2. Minor reproduction differences for Flamino et al.\u2019s (2023) figure 1, year 2020. \nNews Category  Replicated unique \nusers 2020 (N_rep)  Unique users 2020 \n(N) Absolute \ndifference  \n(N_rep \u2013 N) Relative \nDifference \n(%) \n((N_rep \u2013 \nN)/N)*100  \nFake news \n(N_u)  99127  99134  -7 -0.0071\nExtreme bias \nright (N_u)  107165  107090  75 0.0701  \nRight news \n(N_u)  382251  382704  -453 -0.1184\nRight leaning \nnews (N_u)  287938  287895  43 0.0149  \nCenter news \n(N_u)  398506  398242  264 0.0663  \nLeft leaning \nnews (N_u)  2136945  2136823  122 0.0057  \nLeft news (N_u)  237684  237718  -34 -0.0143\nExtreme bias \nleft (N_u)  862 872 -10 -1.1477\nFake news \n(p_u)  0.02715453  0.02715644  -0.00000191 -0.0070\nExtreme bias \nright (p_u)  0.02935643  0.02933588  0.00002055  0.0700  \nRight news \n(p_u)  0.1047126  0.1048367  -0.0001241 -0.1184\nRight leaning \nnews (p_u)  0.07887679  0.07886501  0.00001178  0.0149  \nCenter news \n(p_u)  0.1091654  0.1090931  0.0000723  0.0663  \nLeft leaning \nnews (p_u)  0.5853877  0.5853543  0.0000334  0.0057  \nLeft news (p_u)  0.06511038  0.06511969  -0.00000931 -0.0143\nExtreme bias \nleft (p_u)  0.0002361335  0.0002388728  -\n0.0000027393  -1.1477\nInstitute for Replication\nI4R DP No. 238\n21\nFake news \n(Nt_Nu)  43.87046  43.86736  0.0031  0.0071  \nExtreme bias \nright (Nt_Nu)  37.93048  37.95705  -0.02657 -0.0700\nRight news \n(Nt_Nu)  22.73873  22.71181  0.02692  0.1185  \nRight leaning \nnews (Nt_Nu)  16.14236  16.14478  -0.00242 -0.0150\nCenter news \n(Nt_Nu)  18.99212  19.00471  -0.01259 -0.0663\nLeft leaning \nnews (Nt_Nu) 15.48625  15.48714  -0.00089 -0.0057\nLeft news \n(Nt_Nu)  44.23228  44.22596  0.00632  0.0143  \nExtreme bias \nleft (Nt_Nu)  46.23782  45.70757  0.53025  1.1601  \nFake news \n(pu_no)  0.006547157  0.006597131  -0.000049974 -0.7575\nExtreme bias \nright (pu_no)  0.008752858  0.008787002  -0.000034144 -0.3884\nRight news \n(pu_no)  0.00777238  0.00776318  0.0000092  0.1185  \nRight leaning \nnews (pu_no)  0.01196785  0.01185849  0.00010936  0.9222  \nCenter news \n(pU_no)  0.01743261  0.01740399  0.00002862  0.1644  \nLeft leaning \nnews (pU_no)  0.01709403  0.01713993  -0.0000459 -0.2677\nLeft news \n(pU_no)  0.01658925  0.01644806  0.00014119  0.8584  \nExtreme bias \nleft (pU_no)  0.02436195  0.02522936  -0.00086741 -3.4388\nFake news \n(Ntno_Nuno)  84.03544  83.39297  0.64247  0.7703  \nInstitute for Replication\nI4R DP No. 238\n22\nExtreme bias \nright \n(Ntno_Nuno)  72.75586  72.52391  0.23195  0.3199  \nRight leaning \nnews \n(Ntno_Nuno)  23.23999  23.45782  -0.21783 -0.9285\nCenter news \n(Ntno_Nuno)  33.81474  33.8928  -0.07806 -0.2303\nLeft leaning \nnews \n(Ntno_Nuno)  22.88401  22.82403  0.05998  0.2628  \nLeft news \n(Ntno_Nuno)  74.27974  74.90665  -0.62691 -0.8367\nExtreme bias \nleft \n(Ntno_Nuno)  86.52381  82.59091  3.9329  4.7645  \nInstitute for Replication\nI4R DP No. 238\n23", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A Replication Report on\" Political polarization of news media and influencers on Twitter in the 2016 and 2020 US presidential elections\" by Flamino et al. 2023", "author": ["P Kn\u00f6pfle", "M Haim", "J Breuer"], "pub_year": "2025", "venue": "NA", "abstract": "Flamino et al. (2023) estimate the levels of ideological polarization and echo chamber  behavior for Twitter (now X) users during the 2016 and 2020 US presidential elections using"}, "filled": false, "gsrank": 137, "pub_url": "https://www.econstor.eu/handle/10419/319836", "author_id": ["bXGZ0XYAAAAJ", "hw1R1lIAAAAJ", "n6q5R2QAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:f9Yt4vXynJMJ:scholar.google.com/&output=cite&scirp=136&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=f9Yt4vXynJMJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:f9Yt4vXynJMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.econstor.eu/bitstream/10419/319836/1/I4R-DP238.pdf"}}, {"title": "A multi-modal method for satire detection using textual and visual cues", "year": "2020", "pdf_data": "A Multi-Modal Method for Satire Detection using Textual and Visual Cues\nLily Li1, Or Levi2, Pedram Hosseini3, David A. Broniatowski3\n1Jericho Senior High School, New York, USA\n2AdVerifai, Amsterdam, Netherlands\n3The George Washington University, Washington D.C., USA\nlily.li@jerichoapps.org, or@adverifai.com\nfphosseini,broniatowski g@gwu.edu\nAbstract\nSatire is a form of humorous critique, but it is sometimes misinterpreted by readers as legitimate\nnews, which can lead to harmful consequences. We observe that the images used in satirical\nnews articles often contain absurd or ridiculous content and that image manipulation is used to\ncreate \ufb01ctional scenarios. While previous work have studied text-based methods, in this work\nwe propose a multi-modal approach based on state-of-the-art visiolinguistic model ViLBERT. To\nthis end, we create a new dataset consisting of images and headlines of regular and satirical news\nfor the task of satire detection. We \ufb01ne-tune ViLBERT on the dataset and train a convolutional\nneural network that uses an image forensics technique. Evaluation on the dataset shows that our\nproposed multi-modal approach outperforms image-only, text-only, and simple fusion baselines.\n1 Introduction\nSatire is a literary device that writers employ to mock or ridicule a person, group, or ideology by passing\njudgment on them for a cultural transgression or poor social behavior. Satirical news utilizes humor\nand irony by placing the target of the criticism into a ridiculous, \ufb01ctional situation that the reader must\nsuspend their disbelief and go along with (Maslo, 2019). However, despite what absurd content satirical\nnews may contain, it is often mistaken by readers as real, legitimate news, which may then lead to\nthe unintentional spread of misinformation. In a recent survey conducted by The Conversation1, up to\n28% of Republican respondents and 14% of Democratic respondents reported that they believed stories\nfabricated by the Babylon Bee, a satirical news website, to be \u201cde\ufb01nitely true\u201d. In these instances, the\nconsequences of satire are indistinguishable from those of fake news.\nFigure 1: Examples of satirical news images created by altering existing images.\nTo reduce the spread of misinformation, social media platforms have partnered with third-party fact-\ncheckers to \ufb02ag false news articles and tag articles from known satirical websites as satire for users\n1https://theconversation.com/too-many-people-think-satirical-news-is-real-121666arXiv:2010.06671v1  [cs.CL]  13 Oct 2020\n(Facebook, nd; Google, nd). However, due to the high cost and relative inef\ufb01ciency of employing experts\nto manually annotate articles, many researchers have tackled the challenge of automated satire detection.\nExisting models for satirical news detection have yet to explore the visual domain of satire, even though\nimage thumbnails of news articles may convey information that reveals or disproves the satirical nature\nof the articles. In the \ufb01eld of cognitive-linguistics, Maslo (2019) observed the use of altered images\nshowing imaginary scenarios on the satirical news show The Daily Show. This phenomenon also extends\nto satirical news articles, as seen in Figure 1. For example, Figure 1(a) depicts the Marvel Cinematic\nUniverse character Hulk from the \ufb01lm Avengers: In\ufb01nity War and the United States President Donald\nTrump spliced together. Alone, each of the two images is serious and not satirical, but, since they come\nfrom drastically different contexts, combining the two images creates a clearly ridiculous thumbnail that\ncomplements the headline of the article.\nIn our work, we propose a multi-modal method for detecting satirical news articles. We hypothesize\nthat 1) the content of news thumbnail images when combined with text, and 2) detecting the presence of\nmanipulated or added characters and objects, can aid in the identi\ufb01cation of satirical articles.\n2 Related Work\nPrevious work proposed methods for satirical news detection using textual content (Levi et al., 2019).\nSome works utilize classical machine learning algorithms such as SVM with handcrafted features from\nfactual and satirical news headlines and body text, including bag-of-words, n-grams, and lexical features\n(Burfoot and Baldwin, 2009; Rubin et al., 2016). More recent works use deep learning to extract learned\nfeatures for satire detection. Yang et al. (2017) proposed a hierarchical model with attention mechanism\nand handcrafted linguistic features to understand satire at a paragraph and article-level.\nWhile previous work utilize visiolinguistic data for similar tasks, there is no related work that employs\nmulti-modal data to classify articles into satirical and factual news. Nakamura et al. (2019) created a\ndataset containing images and text for fake news detection in posts on the social media website Reddit.\nWhile they include a category for satire/parody in their 6-way dataset, since they use only content that\nhas been submitted by Reddit users, it is not representative of mainstream news media. Multi-modal\napproaches have also been tried in sarcasm detection; Castro et al. (2019) compiled a dataset of scenes\nfrom popular TV shows and Cai et al. (2019) used tweets comprising of text and images from Twitter.\n3 Methods\n3.1 Data\nWe create a new multi-modal dataset of satirical and regular news articles. The satirical news is collected\nfrom four websites that explicitly declare themselves to be satire, and the regular news is collected from\nsix mainstream news websites2. Speci\ufb01cally, the satirical news websites we collect articles from are The\nBabylon Bee, Clickhole, Waterford Whisper News, and The DailyER. The regular news websites are\nReuters, The Hill, Politico, New York Post, Huf\ufb01ngton Post, and Vice News. We collect the headlines\nand the thumbnail images of the latest 1000 articles for each of the publications. The dataset contains a\ntotal of 4000 satirical and 6000 regular news articles.\n3.2 Proposed Models\nMulti-Modal Learning. We use Vision & Language BERT (ViLBERT), a multi-modal model proposed\nby Lu et al. (2019) that processes images and text in two separate streams. Each stream consists of\ntransformer blocks based on BERT (Devlin et al., 2018) and co-attentive layers that facilitate interaction\nbetween the visual and textual modalities. In each co-attentive transformer layer, multi-head attention\nis computed the same as a standard transformer block except the visual modality attends to the textual\nmodality and vice-versa. To learn representations for vision-and-language tasks, ViLBERT is pre-trained\nusing the masked multi-model modeling and multi-modal alignment prediction tasks on the Conceptual\nCaptions dataset (Sharma et al., 2018). We choose to use ViLBERT because of its high performance\n2The regular news websites we use are listed by Media Bias/Fact Check https://mediabiasfactcheck.com/ , a\nvolunteer-run and nonpartisan organization dedicated to fact-checking and determining the bias of news publications\non a variety of visiolinguistic tasks, including Visual Question Answering, Image Retrieval, and Visual\nCommonsense Reasoning. We \ufb01ne-tune ViLBERT on the satire detection dataset by passing the element-\nwise product of the \ufb01nal image and text representations into a learned classi\ufb01cation layer.\nImage Forgery Detection. Since satirical news images are often forged from two or more images\n(known as image splicing), we implement an additional model that uses error level analysis (ELA). ELA\nis an image forensics technique that takes advantage of lossy JPEG compression for image tampering\ndetection (Krawetz, 2007). In ELA, each JPEG image is resaved at a known compression rate, and the\nabsolute pixel-by-pixel differences between the original and the resaved images are compared. ELA can\nbe used to identify image manipulations where a lower quality image was spliced into a higher quality\nimage or vice-versa. To detect image forgeries as an indicator of satirical news, we preprocess the images\nusing ELA with a compression rate of 90% and use them as input into a CNN.\nFor the CNN, we use two convolutional layers with 32 kernels and a \ufb01lter width of 5, each followed\nby a max-pooling layer. The output features from the CNN are fed into a MLP with a hidden size of 256\nand a classi\ufb01cation layer. We pretrain the model on the CASIA 2.0 image tampering detection dataset\n(Dong et al., 2013) before \ufb01ne-tuning on the images of the satire detection dataset.\nImplemention. We divide the data into training and test sets with a ratio of 80%:20%. We train all our\nmodels with a batch size of 32 and Adam optimizer. We use the MMF (Singh et al., 2020) implementation\nof ViLBERT and \ufb01ne-tune it for 12 epochs with a learning rate of 5e-6. We extract Mask RCNN (He et\nal., 2017) features from the images in the dataset as visual input. The ViLBERT model has 6 transformer\nblocks in the visual stream and 12 transformer blocks in the textual stream. Our ELA+CNN model is\ntrained with a learning rate of 1e-5 for 7 epochs.3\n3.3 Baselines\nTo create fair baselines for our \ufb01ne-tuned ViLBERT model, we train multi-modal models that use sim-\nple fusion. In the model denoted as Concatenation, ResNet-101 (He et al., 2016) and BERT features\nare concatenated and a MLP is trained on top. In the model denoted as Average fusion, the output of\nResNet-101 and BERT are averaged. We choose these two models as our baselines to evaluate the effects\nof ViLBERT\u2019s early fusion of visual and textual representations and multi-modal pre-training on Con-\nceptual Captions (Sharma et al., 2018). We also \ufb01ne-tune uni-modal ResNet-101 and BERT BASE models\nto compare the performance of the multi-modal models to.\nType Model Accuracy F1 score AUC-ROC\nAll regular news 60.00 \u2014 50.00\nBaselinesResNet101 73.54 65.26 80.28\nBERT BASE 91.33 88.64 96.77\nSimple fusion (average) 92.53 90.44 96.74\nSimple fusion (concatenation) 92.74 90.70 97.31\nProposed ModelsELA+CNN 44.20 51.86 44.61\nViLBERT 93.80 92.16 98.03\nTable 1: Model performance on satire detection dataset.\n4 Results and Discussion\n4.1 Experimental Results\nWe measure the performance of the proposed and baseline models using Accuracy, F1 score, and AUC-\nROC metrics. The results are shown in Table 1. The models using only the visual modality (ResNet-101\nand CNN+ELA) do not perform as well as the model that uses only the text modality (BERT BASE ). The\nsimple fusion models (Average fusion, Concatenation) perform marginally better than BERT BASE .\nSurprisingly, the performance of the ELA+CNN model was very poor, achieving an accuracy worse\nthan random chance. While this is not in line with our initial hypothesis, there might be several reasons\n3Scripts for our experiments are available at: https://github.com/lilyli2004/satire\nfor these results: Firstly, ELA is not able to detect image manipulations if the images have been resaved\nmultiple times since after they have been compressed at a high rate there is little visible change in error\nlevels (Krawetz, 2007). This makes it especially dif\ufb01cult to identify manipulation in images taken from\nthe Internet, as they have usually undergone multiple resaves and are not camera originals. Additionally,\nalthough ELA can be used as a method to detect and localize the region of an image that has been poten-\ntially altered, it does not allow for the identi\ufb01cation of what kind of image manipulation technique was\nused. This is important because even reputable news publications, such as Reuters and The Associated\nPress use Photoshop and other software to perform minor adjustments to photos, for example, to alter\nthe coloring or lighting, or to blur the background (Schlesinger, 2007; The Associated Press, 2014).\nViLBERT outperforms the simple fusion multi-modal models because it uses early, deep fusion and\nhas undergone multi-modal pre-training rather than only separate uni-modal visual and text pre-training.\nViLBERT also performs almost 3.5 F1 points above the uni-modal BERT BASE model.\n4.2 Model Misclassi\ufb01cation Study\nAfter classi\ufb01cation, we randomly select 20% of the test set samples misclassi\ufb01ed by ViLBERT and\nobserved them for patterns across multiple samples. Figure 2 shows examples of misclassi\ufb01ed samples.\nWe observed three main reasons that may have been the cause of the incorrectly classi\ufb01ed articles: 1)\nThe model misinterpreted the headline (Figure 2(a)), 2) the model lacks knowledge of current events\n(Figure 2(b)), and 3) the article covered a bizarre but true story (Figure 2(c)).\nFigure 2(a) shows an article from Politico that has been classi\ufb01ed as satire. The image does not portray\nanything strange or out of the ordinary. However, the headline uses the word \u201cbursts\u201d, which the model\nmight be incorrectly interpreting in the literal sense even though it is being used metaphorically. If\n\u201cbursts\u201d was intended to be literal, it would drastically change the meaning of the text, which may be\nwhy the model failed to classify the article as factual. Figure 2(b) shows a satirical article from Babylon\nBee that has been misclassi\ufb01ed as factual. Its image has also not been heavily altered or faked; in fact,\nit is the same image that was used as the original thumbnail of the Joe Rogan podcast episode that is\nthe subject of the article. However, the model fails to recognize the ridiculousness of the text, since\nit does not have the political knowledge to spot the contrast between the \u201calt-right\u201d and the American\npolitician Bernie Sanders. In Figure 2(c), an article is from the factual publication The New York Post is\nmisclassi\ufb01ed as satirical. Although both the headline and the image seem very ridiculous, the story and\nthe image were, in fact, not fabricated. Thus, identifying text/images as absurd might not always aid in\nsatire detection, since ViLBERT fails in classifying this article as factual because it is unable to tell that\nthe image has not been forged.\nFigure 2: Examples of articles misclassi\ufb01ed by ViLBERT\n5 Conclusion and Future Investigations\nIn this paper we create a multi-modal satire detection dataset and propose two models for the task based\non the characteristics of satirical images and their relationships with the headlines. While our model\nbased on image tampering detection performed signi\ufb01cantly worse than the baselines, empirical evalua-\ntion showed the ef\ufb01cacy of our proposed multi-modal approach compared to simple fusion and uni-modal\nmodels. In future work on satire detection, we will incorporate image forensics methods to identify image\nsplicing in satirical images, as well as knowledge about politics and other current issues.\nReferences\nClint Burfoot and Timothy Baldwin. 2009. Automatic satire detection: Are you having a laugh? In Proceedings\nof the ACL-IJCNLP 2009 Conference Short Papers , pages 161\u2013164, Suntec, Singapore, August. Association for\nComputational Linguistics.\nYitao Cai, Huiyu Cai, and Xiaojun Wan. 2019. Multi-modal sarcasm detection in twitter with hierarchical fusion\nmodel. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages\n2506\u20132515, Florence, Italy, July. Association for Computational Linguistics.\nSantiago Castro, Devamanyu Hazarika, Ver \u00b4onica P \u00b4erez-Rosas, Roger Zimmermann, Rada Mihalcea, and Soujanya\nPoria. 2019. Towards multimodal sarcasm detection (an Obviously perfect paper). In Proceedings of the\n57th Annual Meeting of the Association for Computational Linguistics , pages 4619\u20134629, Florence, Italy, July.\nAssociation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of deep bidirec-\ntional transformers for language understanding.\nJing Dong, Wei Wang, and Tieniu Tan. 2013. CASIA image tampering detection evaluation database. In 2013\nIEEE China Summit and International Conference on Signal and Information Processing , pages 422\u2013426. IEEE.\nFacebook. n.d. Fact-checking on Facebook: What publishers should know . Business Help Center.\nGoogle. n.d. What does each label mean? Publisher Help Center.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition.\nInProceedings of the IEEE conference on computer vision and pattern recognition , pages 770\u2013778.\nKaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Girshick. 2017. Mask r-cnn. 2017 IEEE International\nConference on Computer Vision (ICCV) , Oct.\nNeal Krawetz. 2007. A picture\u2019s worth: Digital image analysis and forensics. Black Hat Brie\ufb01ngs .\nOr Levi, Pedram Hosseini, Mona Diab, and David A. Broniatowski. 2019. Identifying nuances in fake news vs.\nsatire: Using semantic and linguistic cues. arXiv preprint arXiv:1910.01160 .\nJiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. Vilbert: Pretraining task-agnostic visiolinguistic\nrepresentations for vision-and-language tasks. In Advances in Neural Information Processing Systems , pages\n13\u201323.\nAdi Maslo. 2019. Parsing satirical humor: a model of cognitive-linguistic satire analysis. Knji\u02c7zevni jezik ,\n(30):231\u2013253.\nKai Nakamura, Sharon Levy, and William Yang Wang. 2019. r/fakeddit: A new multimodal benchmark dataset\nfor \ufb01ne-grained fake news detection.\nVictoria Rubin, Niall Conroy, Yimin Chen, and Sarah Cornwell. 2016. Fake news or truth? using satirical cues to\ndetect potentially misleading news. In Proceedings of the Second Workshop on Computational Approaches to\nDeception Detection , pages 7\u201317, San Diego, California, June. Association for Computational Linguistics.\nDavid Schlesinger. 2007. The use of Photoshop . Reuters Blogs Dashboard.\nPiyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. 2018. Conceptual Captions: A cleaned,\nhypernymed, image alt-text dataset for automatic image captioning. In Proceedings of the 56th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers) , pages 2556\u20132565, Melbourne,\nAustralia, July. Association for Computational Linguistics.\nAmanpreet Singh, Vedanuj Goswami, Vivek Natarajan, Yu Jiang, Xinlei Chen, Meet Shah, Marcus Rohrbach,\nDhruv Batra, and Devi Parikh. 2020. Mmf: A multimodal framework for vision and language research.\nhttps://github.com/facebookresearch/mmf .\nThe Associated Press. 2014. AP News Values and Principals .\nFan Yang, Arjun Mukherjee, and Eduard Dragut. 2017. Satirical news detection and analysis using attention\nmechanism and linguistic features. In Proceedings of the 2017 Conference on Empirical Methods in Natural\nLanguage Processing , pages 1979\u20131989, Copenhagen, Denmark, September. Association for Computational\nLinguistics.\nThis work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://\ncreativecommons.org/licenses/by/4.0/ .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A multi-modal method for satire detection using textual and visual cues", "author": ["L Li", "O Levi", "P Hosseini", "DA Broniatowski"], "pub_year": "2020", "venue": "arXiv preprint arXiv \u2026", "abstract": "Satire is a form of humorous critique, but it is sometimes misinterpreted by readers as  legitimate news, which can lead to harmful consequences. We observe that the images used in"}, "filled": false, "gsrank": 138, "pub_url": "https://arxiv.org/abs/2010.06671", "author_id": ["", "jvmxT70AAAAJ", "a0QBxoYAAAAJ", "K8c3PvUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:9dHdl_fcZGIJ:scholar.google.com/&output=cite&scirp=137&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=9dHdl_fcZGIJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 29, "citedby_url": "/scholar?cites=7090034669350932981&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:9dHdl_fcZGIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2010.06671"}}, {"title": "Publishing controversy", "year": "2021", "pdf_data": "Publishing controversy\nNorman A. Poole\nBJPsych Bulletin (2021) 45, 257 \u2013258, doi:10.1192/bjb.2020.127\nSouth West London and St George \u2019s\nMental Health NHS Trust, London, UK\nCorrespondence to Dr Norman A. Poole\n(bjpbulletin@rcpsych.ac.uk )\nFirst received 18 Nov 2020, accepted\n18 Nov 2020\n\u00a9 The Author 2021. Published by\nCambridge University Press on behalf of\nthe Royal College of Psychiatrists. This is\nan Open Access article, distributed underthe terms of the Creative CommonsAttribution licence ( http://creative\ncommons.org/licenses/by/4.0/ ), which\npermits unrestricted re-use, distribution,and reproduction in any medium,provided the original work is properly\ncited.Summary Two recent papers on a controversial topic in this journal attracted\nsigni\ufb01cant criticism from readers. This editorial addresses these criticisms and\ndescribes changes to be made to the journal \u2019s editorial and review procedures in light\nof the complaints received.\nKeywords Editorial policy; publishing ethics; gender identity; gender incongruence.\nPsychiatry, like other branches of medicine, is no stranger to\ncontroversy. Anthony Clare \u2019sPsychiatry in Dissent1ran the\ngamut of contested areas \u2013from the validity of psychiatric\ndiagnosis to electroconvulsive therapy and psychosurgery \u2013\nwhich are, to varying degrees, still with us. Some have arguedthat disputes over the concept of mental disorder generally\n2\nand certain speci \ufb01c categories3merely demonstrate that\npsychiatry is a pseudoscience: psychiatric diagnosis, unlikethe remainder of medicine, is a matter of value judgementsrather than \u2018hard facts \u2019. In this view, psychiatrists are\nreally just pathologising people who transgress some sortof social norm.\nSince the heyday of such arguments, it has been increas-\ningly understood that, yes, values are involved in diagnosis,but this is true also in other medical specialties. In PeterSedgwick \u2019s memorable phrase, \u2018The fracture of a septuagen-\narian \u2019s femur has, within the world of nature, no more\nsigni\ufb01cance than the snapping of an autumn leaf from its\ntwig \u2019.\n4But we deprecate the \ufb01rst, so consider it disordered.\nYet psychiatry remains the more controversial specialty.Bill Fulford draws an analogy between the di \ufb00erent ways\nwe use the word \u2018good \u2019when thinking about a \u2018good\nstrawberry \u2019versus a \u2018good painting \u2019.\n5It turns out that\nthere is greater agreement about the former than the latter,hence less con \ufb02ict and controversy. And what constitutes a\nperson \u2019s very nature and identity is a lot more like paintings\nthan strawberries.\nThe BJPsych Bulletin , representing views within and\nabout psychiatry, cannot evade controversial issues, but nei-ther should we court them for their own sake. At the heart ofsuch controversies are real people with real lives, oftenostracised and denigrated. So, we have a duty to be respect-ful and balanced when articles on controversial topics areaccepted for publication. We recently published two papers\n6\non gender incongruence that have attracted a signi \ufb01cant\nnumber of letters and complaints, particularly regardingMarcus Evans \u2019opinion piece \u2018Freedom to think: the need\nfor thorough assessment and treatment of gender dysphoricchildren \u2019.\n7In light of the criticisms, we reviewed the article\nand have published a corrigendum of clari \ufb01cations and add-\nitional information that provides a stronger evidence basefor his arguments. Importantly, Evans has also provided adeclaration of interest statement addressing his involvementin a judicial review of gender-a \ufb03rming treatment for\nminors.\nChanges to editorial procedures\nCriticisms of the paper have been discussed by the editorialboard. It was never the intention for the board to reviewthe evidence for and against gender-a \ufb03rming treatment.\nWe appreciate that there are gaps in the evidence base con-cerning psychological outcomes of gender-a \ufb03rming surgery,\n8\nso see the journal \u2019sr o l ea se n a b l i n gd i s c u s s i o n .W es e e kt o\npresent the su \ufb00ering caused by prejudice and failings in\ncare systems, address omissions in the evidence base, andenable clinicians and patients to express concerns about eth-ical practice. The journal \u2019s position is not to censor one or\nother argument \u2013albeit clarity and care are needed when dis-\ncussing emotive issues and the potential harms of psychiatricpractice. The editorial board have discussed how handlingeditors should deal with submissions about such controversialtopics, and agreed the following recommendations.\n(a) The Special Articles category currently combines\nboth review and opinion pieces. We will reintroduceEDITORIAL\n257\nhttps://doi.org/10.1192/bjb.2020.127  Published online by Cambridge University Press\nReview and Opinion type papers to clarify for readers\nthe nature of the content.\n(b) We have added to the instructions for authors that\nOpinion pieces can include references from newsitems and blogs.\n(c) We will not accept an Opinion article with reviews\nsolely by the author \u2019s suggested reviewers. As a gen-\neral rule, editors do avoid this. However, it is now a\ufb01rm policy for Opinion pieces to ensure that an inde-\npendent review is always sought, even though thismay lead to delays to the peer review process. Wemay call on editorial board members as required toprovide reviews.\n(d) Reviewer invitation templates will be revised to\ninclude a link to the COPE Ethical Guidelines forPeer Reviewers and the Reviewer Support Hub on\nCambridge Core (in development). We will encourage\nreviewers and editors to use sites such as https://\nmediabiasfactcheck.com/ to check the level of bias\nof non-scholarly sites.\n(e) If an article involves a controversial issue, handling\neditors will seek to balance it, either in reviewsor with a counterbalancing article, commentary oreLetter, although we acknowledge that this may notalways be possible.\nI appreciate that the published corrigendum and review\nof editorial processes will, for some, not go far enough. Manyof the complainants sought retraction rather than correctionand pointed to the distress such papers can cause an alreadymarginalised group of people. I am deeply sorry for the hurtcaused and have invited authors of the complaint letters tosubmit counterbalancing articles and/or eLetters to ensurethat the spectrum of opinions is presented. Readers are wel-come to submit correspondence by clicking the e-letters tabwhen accessing the article via the following link: https://doi.\norg/10.1192/bjb.2020.72 .\nCOPE, the Committee on Publication Ethics, has guide-\nlines\n9for editors considering retraction of an academic\npaper. Its criteria cover situations where there is clear evi-dence of unreliability or falsi \ufb01cation of data, plagiarism,\ncopyright infringement or manipulation of the peer reviewprocess. These do not apply here. Failure to disclose amajor con \ufb02ict of interest can also lead to retraction where\nnon-disclosure has \u2018unduly a \ufb00ected interpretations of the\nwork \u2019by editors and peer reviewers. However, Evans has\nbeen candid about his opinions, which are of a piece withhis involvement in the judicial review.\nDerek Bolton \u2019sWhat is Mental Disorder?\n10has long\nstruck me as a \ufb01ne argument for the constructive value of\ndisagreement. Where concepts are contended, they aresubject to competing pressures from the various stake-\nholders, including patients, carers, doctors, psychologists,social scientists, the general public and politicians. He wasreferring to disputes about the boundary between orderand disorder, health and illness, but it applies to controver-sial issues within psychiatry generally. In this spirit, theBJPsych Bulletin will always strive for open, transparent\nand respectful dialogue.\nAbout the author\nNorman A. Poole is Editor of the BJPsych Bulletin and a consultant neuro-\npsychiatrist at St George \u2019s Hospital, South West London and St George \u2019s\nMental Health NHS Trust, UK.\nDeclaration of interest\nN.P. is Editor of the BJPsych Bulletin .\nReferences\n1Clare A. Psychiatry in Dissent: Controversial Issues in Thought and Practice\n(2nd edn). Routledge, 1976.\n2Szasz TS. The Myth of Mental Illness: Foundations of a Theory of Personal\nConduct . Secker & Warburg, 1962.\n3Boyle M. Schizophrenia: A Scienti \ufb01c Delusion? (2nd edn). Routledge,\n2002.\n4Sedgwick P. Psycho Politics . Unkant Publishers, 2015 (original published\n1983): p 30.\n5Fulford KWM, Van Staden CW. Values-based practice: topsy-turvy\ntake-home messages from ordinary language (and a few next steps).InThe Oxford Handbook of Philosophy and Psychiatry (eds KWM Fulford,\nM Davies, RGT Gipps, JZ Graham, G Sadler, G Stanghellini, et al.):385 \u2013412. Oxford University Press, 2013.\n6Gri\ufb03n L, Clyde K, Byng R, Bewley S. Sex, gender and gender identity: a\nre-evaluation of the evidence. BJPsych Bull [Epub ahead of print] 21 Jul\n2020. Available from: https://doi.org/10.1192/bjb.2020.73 .\n7Evans M. Freedom to think: the need for thorough assessment\nand treatment of gender dysphoric children. BJPsych Bull [Epub ahead\nof print] 21 Jul 2020. Available from: https://doi.org/10.1192/bjb.\n2020.72 .\n8Mueller SC. Mental health treatment utilization in transgender persons:\nwhat we know and what we don \u2019t know. Am J Psychiatry 2020; 177:\n657 \u20139.\n9Committee on Publication Ethics. Retraction Guidelines . COPE, 2019\n(https://doi.org/10.24318/cope.2019.1.4 ).\n10Bolton D. What is Mental Disorder? An Essay in Philosophy, Science, and\nValues . Oxford University Press, 2008.\n258EDITORIAL\nPoole Publishing controversy\nhttps://doi.org/10.1192/bjb.2020.127  Published online by Cambridge University Press", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Publishing controversy", "author": ["NA Poole"], "pub_year": "2021", "venue": "BJPsych Bulletin", "abstract": "Two recent papers on a controversial topic in this journal attracted significant criticism from  readers. This editorial addresses these criticisms and describes changes to be made to the"}, "filled": false, "gsrank": 139, "pub_url": "https://www.cambridge.org/core/journals/bjpsych-bulletin/article/publishing-controversy/2377F29BF9D05201172001FB060F86F8", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:07_WOIb_3d0J:scholar.google.com/&output=cite&scirp=138&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=07_WOIb_3d0J&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 1, "citedby_url": "/scholar?cites=15987215204179427283&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:07_WOIb_3d0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/2377F29BF9D05201172001FB060F86F8/S2056469420001278a.pdf/publishing_controversy.pdf"}}, {"title": "VeraCT scan: Retrieval-augmented fake news detection with justifiable reasoning", "year": "2024", "pdf_data": "VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable\nReasoning\nCheng Niu1,Yang Guan1,Yuanhao Wu1,Juno Zhu1,Juntong Song1,Randy Zhong1,\nKaihua Zhu1,Siliang Xu1,Shizhe Diao2, and Tong Zhang3\n1NewsBreak\n2Hong Kong University of Science and Technology\n3University of Illinois Urbana-Champaign\ncheng.niu@newsbreak.com\nAbstract\nThe proliferation of fake news poses a sig-\nnificant threat not only by disseminating mis-\nleading information but also by undermining\nthe very foundations of democracy. The re-\ncent advance of generative artificial intelligence\nhas further exacerbated the challenge of distin-\nguishing genuine news from fabricated stories.\nIn response to this challenge, we introduce Ve-\nraCT Scan, a novel retrieval-augmented sys-\ntem for fake news detection. This system oper-\nates by extracting the core facts from a given\npiece of news and subsequently conducting an\ninternet-wide search to identify corroborating\nor conflicting reports. Then sources\u2019 credibility\nis leveraged for information verification. Be-\nsides determining the veracity of news, we also\nprovide transparent evidence and reasoning to\nsupport its conclusions, resulting in the inter-\npretability and trust in the results. In addition to\nGPT-4 Turbo, Llama-2 13B is also fine-tuned\nfor news content understanding, information\nverification, and reasoning. Both implementa-\ntions have demonstrated state-of-the-art accu-\nracy in the realm of fake news detection1.\n1 Introduction\nThe contemporary digital landscape is rife with\nthe proliferation of fake news, presenting a multi-\nfaceted challenge that undermines public discourse,\naffects democratic processes, and incites real-world\nconsequences (Vasu et al., 2018). Fake news, char-\nacterized by the deliberate dissemination of misin-\nformation, exploits the rapid spread of information\nonline, often outpacing the verification processes\nthat traditional media outlets adhere to.\nFake news detection is defined as the process\nof identifying and verifying the veracity of news\ncontent, employing various computational and man-\nual methods. This process involves distinguishing\n1Our demo is available at https://veractscan.\nnewsbreak.com/ . Demo video at https://youtu.\nbe/t1__iuOG9H8 .between true and false information, considering\nthe intent behind the information dissemination,\nwhether it be to mislead, harm, or manipulate pub-\nlic opinion.\nTraditional approaches in fake news detection\nhave primarily focused on the linguistic features,\nalso called content-based detection (Castillo et al.,\n2011; P\u00e9rez-Rosas et al., 2018; Giachanou et al.,\n2019; Przybyla, 2020; Giachanou et al., 2020;\nSheikhi, 2021; Kirchknopf et al., 2021; Zhou et al.,\n2020), which demands laborious feature engineer-\ning and is ineffective when the fake news is written\nby imitating the real news to mislead intention-\nally. Another line of research is the social context-\nbased method (Qazvinian et al., 2011; Baly et al.,\n2018; Shu et al., 2020; Monti et al., 2019; Nan\net al., 2023), which analyzes the interactions among\nusers, publishers, and posts. However, the feasibil-\nity of obtaining user information is challenging for\nthe real-world application. A more recent research\napproach is the knowledge-based method (Hu et al.,\n2021; Saeed et al., 2022; Pan et al., 2023; Chen\net al., 2023; Liao et al., 2023; Zhang and Gao, 2023;\nLi et al., 2024), which discerns the veracity of a\nfactual claim by comparing against the evidence\nretrieved from external knowledge base. However,\ncurrent approaches often do not fully utilize exter-\nnal resources like the Internet. Additionally, there\nis a lack of development and optimization of a com-\nprehensive end-to-end pipeline that includes news\ncomprehension, search optimization, verification,\nand reasoning.\nIn this paper, we introduce VeraCT Scan, a novel\nretrieval-augmented system for fake news detec-\ntion. VeraCT Scan initiates this process by iden-\ntifying key factual claims across multiple levels\nof granularity. For each identified factual claim,\na comprehensive internet search is conducted to\ngather relevant information. Then, the veracity of\nthe news is determined by combining this typically\ndisparate and conflicting information, taking intoarXiv:2406.10289v2  [cs.CL]  24 Jun 2024\naccount the varying degrees of source credibility.\nTo increase the trustworthiness of our approach, we\nunderscore the necessity of a transparent reasoning\nprocess and provide rationales for each supporting\nor conflicting judgment.\nIn summary, our main contributions are:\n(i)We introduce VeraCT Scan, that operates\nacross multiple levels of information granular-\nity, employing optimized information retrieval\ntechniques to enhance fake news detection per-\nformance.\n(ii)We investigate the generation of verification\nrationales as a means to increase the system\u2019s\ntransparency and trustworthiness. Addition-\nally, we address the management of conflict-\ning evidence by leveraging the credibility of\nsources, thereby improving the reliability of\nthe verification process.\n(iii) We conduct a comprehensive evaluation of\nVeraCT Scan using several fake news detec-\ntion datasets. Our results demonstrate that the\nsystem achieves state-of-the-art performance\nin news verification tasks, employing both\nprompted and fine-tuned LLMs.\n2 Related Work\nIn this section, we first review the progress of\nfake news detection and then discuss the retrieval-\naugmented generation methods.\n2.1 Fake News Detection\nExisting fake news detection methods can be\ncategorized into three types: 1) Content-Based\nMethods (Sheikhi, 2021; P\u00e9rez-Rosas et al., 2018;\nCastillo et al., 2011; Przybyla, 2020; Giachanou\net al., 2019; Huang et al., 2023; Giachanou et al.,\n2020; Kirchknopf et al., 2021; Nakamura et al.,\n2020; Chen et al., 2023; Zhou et al., 2020) which\nanalyze articles\u2019 linguistic features (e.g., text\nlength, punctuation usage, emotion symbols) to\ndifferentiate fake news from real ones. However,\nthese methods demand laborious feature engineer-\ning and are often ineffective when fake news is\nwritten to intentionally mislead readers. 2) So-\ncial Context-Based Methods (Shu et al., 2020; Nan\net al., 2023; Baly et al., 2018; Monti et al., 2019;\nQazvinian et al., 2011) which analyze the interac-\ntions among users, publishers, and posts to detect\nfake news. However, the feasibility of obtaining\nuser information in the news propagation process\npresents challenges for the real-world applicabil-ity of this method. 3) Fact-Based Methods (Saeed\net al., 2022; Pan et al., 2023; Hu et al., 2021; Xu\net al., 2023; Chen et al., 2023; Cheung and Lam,\n2023) which focus on factual claim verification\nby comparing against external knowledge. These\nmethods fall short in providing an end-to-end so-\nlution that considers information seeking and the\nmanagement of conflicting evidence.\nRecently, Wang and Shu (2023) leverage large\nlanguage models (LLMs) to decompose complex\nclaims into sequences of first-order logic, and then\nguide the search and information verification. Dif-\nferent from their work, we propose a pipeline that\nincludes full steps to classify fake news. Liao et al.\n(2023) outlines a multi-step process for detecting\nfake news, which consists of news summarization,\nsearching, and verification. In contrast to their\nmethod, we employ LLMs instead of specifically\ntrained encoder-decoder transformers for these nat-\nural language processing tasks. In addition, we\nleverage source credibility to differentiate conflict-\ning evidences, a common challenge in real-world\nnews verification that has rarely been explored in\nprevious research.\n2.2 Retrieval-Augmented Generation\nThe integration of retrieval-augmented generation\n(RAG) allows LLMs to extend beyond the limits\nof the training corpus by retrieving information\nfrom external knowledge bases before the genera-\ntive process (Lewis et al., 2020; Chen et al., 2024).\nRAG has emerged as a solution to overcome the\nlimitations of LLMs including the challenge of\nout-of-date knowledge and the tendency to pro-\nduce hallucinations or irrelevant and factually in-\ncorrect content. By integrating external, up-to-date\ndocuments into the generation process, LLMs can\ngenerate more reliable responses across a broad\nspectrum of tasks, including open-domain ques-\ntion answering (Izacard and Grave, 2021; Trivedi\net al., 2023; Li et al., 2023; Xu et al., 2024), dia-\nlogue systems (Cai et al., 2019; Peng et al., 2023),\nand code generation (Zhou et al., 2023b). RAG is\nalso commonly integrated into commercial chatbot\nproducts to provide updated information, e.g Per-\nplexity2and Gemini3. In this paper, we leverage\nRAG for fake news detection by generating both\nverdicts and justifications.\n2https://www.perplexity.com\n3https://gemini.google.com\nFACT\nFACTFACT\nQuery\ngenerationSearchFinal\nclassification\nKey fact\nextraction\nVerification\nWEB\nWEB\nWEBresultFigure 1: Main workflow of VeraCT Scan. VeraCT Scan includes the following steps: 1) extract key facts from the\nnews to verify; 2) generate search queries for each extracted fact; 3) search; 4) verify the fact based on each search\nresult; 5) aggregate all verifications with a final classification model.\n3 Approach\nIn this paper, the term \"claim\" refers to the fact\nstated in a news article. The terms \"factual claim ex-\ntraction\" and \"fact extraction\" are used interchange-\nably throughout the paper.\nFigure 1 shows the main workflow of VeraCT\nScan. We prompt GPT-4 Turbo for key fact extrac-\ntion, query generation, verification, and rationale\ngeneration (See Appendix A for prompts being\nused). These individual components can be eas-\nily exchange to other LLMs or search engines. In\nthis work, the outputs from GPT-4 Turbo, supple-\nmented with manual reviews, serve as training data\nto fine-tune Llama-2 13B (Touvron et al., 2023),\nenabling it to support these tasks as well. Regard-\ning the search component, we employ both Google\nand our proprietary in-house news search engine\nfor comprehensive information retrieval.\n3.1 Key Fact Extraction\nIn this paper, we focus on identifying facts at two\nlevels of granularity: (i) the primary fact reported\nby the news story and (ii) all the salient facts being\nreported in the news article.\nGiven that the internet search operates as a state-\nless module, we instruct the LLM in the prompt to\nensure each key fact is self-contained with its infor-\nmation. This approach allows the search function\nto generate queries for each key fact independently,\nwithout relying on additional context.\nIn line with the previous research (Shahandashti\net al., 2024), our manual review has confirmed the\nhigh quality of key facts being identified by GPT-4\nTurbo.\n3.2 Query Generation and Search\nWhen verifying a fact, we prompt GPT-4 Turbo\nto generate search queries. We allow up to threequeries per fact to search the Internet. Subse-\nquently, GPT-4 Turbo assesses the relevance of\nthe results returned by each query. The goal is to\nidentify the shortest sequence of queries that can\nretrieve all the relevant information. This optimal\nquery sequence is then utilized to fine-tune Llama-\n2 13B, enabling its query generation capabilities.\nWe have developed a proprietary search engine\ndesigned to support news searches for articles pub-\nlished within the last six months. This search en-\ngine is especially effective in searching articles\nhosted on NewsBreak platform and can be used in\nNewsBreak APP. To ensure comprehensive search\nresults, we also utilize the Google search API4.\n3.3 Fact Verification and Rationale\nGeneration\nOnce the search results are retrieved, each fact is\nevaluated against them. GPT-4 Turbo is prompted\nto iterate each of the search results, and determine\nwhether the search result supports, conflicts with,\nor is unrelated to the fact. If the search result aligns\nwith the fact, it is labeled as \"support\". If it con-\ntradicts the fact, it is labeled as \"negate\". If the\nfact is not mentioned or only partially mentioned\nin the search result, the label \"baseless\" is applied.\nBesides, a rationale is generated to justify the judg-\nment. A concrete example of our pipeline is shown\nin Appendix B.\n3.4 Source Credibility and Final Decision\nWhen researching a given topic, it is common to\nencounter conflicting information on the Internet.\nTo avoid bias from single source, multiple sources\nare used to corroborate each other. Therefore, as-\nsessing the credibility of each information source\n4https://developers.google.com/\ncustom-search/v1/overview\nis crucial. Mediabiasfactcheck.com is one of the\nmost comprehensive resources for assessing me-\ndia bias on the internet, offering credibility ratings\nfor over 8,000 news publishers. Similarly, News-\nBreak has developed a proprietary 5-level credi-\nbility rating system for more than 30,000 publish-\ners. While NewsBreak\u2019s ratings are also based on\nthe credibility of source content, unlike mediabi-\nasfactcheck.com, NewsBreak does not identify the\npolitical bias of the sources.\nIn this paper, NewsBreak\u2019s rating systems serves\nas features to train a LightGBM(Ke et al., 2017)\nclassifier that determines the likelihood of a fact\nclaim being true. Besides, domain and verification\nflags (i.e. support, negate, or baseless) from each\nsearch result are also used as classification features.\n3.5 Llama-2 13B Fine Tuning\nTo enhance service stability, response speed, and\nreduce costs, Llama-2 13B is fine-tuned to support\nour fake news detection pipeline.\nDataset Following previous studies(Zhou et al.,\n2023a; Taori et al., 2023), we utilize a mixed\ndataset of diverse tasks for supervised fine-\ntuning (SFT). Outputs of GPT-4 Turbo from the\ntasks described above are used as part of the train-\ning data. Specifically, we purposely modify some\nkey factual claims being extracted from news arti-\ncles into fake ones when generating claim verifica-\ntion data set. Besides, the following datasets have\nalso been incorporated into the training set:\n1.QA with RAG: GPT-4 generated answers\nto questions in NewsBreak search logs us-\ning knowledge retrieved from our proprietary\nsearch engine.\n2.WebGLM(Liu et al., 2023): web-enhanced\nquestion-answering dataset.\n3.No robots(Rajani et al., 2023): a diverse in-\nstruction fine-tuning dataset created by skilled\nhuman annotators.\nThe training data distribution is shown in Table 1.\nThis design allows a single model to handle both\ngeneral question-answering and specialized news\nverification tasks, resulting in significant reductions\nin inference costs.\nHyper parameters To enhance the capability of\nprocessing long inputs, we trained the model with\nRoPE scaling(Su et al., 2021; Liu et al., 2024).\nSpecifically, we adjusted the context window size\nin SFT to be twice as large as that in the originalTask/Dataset # Samples % Samples\nKey Fact Extraction 10299 18.52\nQuery Generation 3000 5.39\nFact Verification 23429 42.12\nQA with RAG 8091 14.55\nNo robots(Rajani et al., 2023) 9500 17.08\nWebGLM(Liu et al., 2023) 1300 2.34\nTotal 55619 100.0\nTable 1: The distribution of the fine-tuning data from\ndifferent tasks/datasets.\nKey Task ROUGE-1 ROUGE-2 ROUGE-L\nKey Fact Extraction 0.678 0.497 0.655\nQuery Generation 0.690 0.503 0.662\nRationale Generation 0.637 0.449 0.600\nTable 2: Performance of key tasks.\nLlama-2 model, setting it to 8192 tokens, and we\nset the scaling factor at 2.0. We employed full\ntraining with an initial learning rate of 1e-5, and\nlimited the training to 1 epoch. The training process\nwas executed on four NVIDIA A100 GPUs.\n3.6 Key Task Evaluations\nThe end-to-end metrics will be present in Section 5.\nIn this section, we present the performance metrics\nfor the critical components.\nWith GPT-4 Turbo outputs as the gold standard,\nwe benchmarked the finetuned Llama-2 model on\nkey fact extraction, query generation, and ratio-\nnale generation. ROUGE scores (Lin, 2004) were\nemployed as the metrics, as shown in Table 2.\nFor the fact verification accuracy, micro-F1 score\nwas employed as the metric. According to human\nreview, GPT-4 Turbo achieved a score of 0.805,\nwhile the finetuned Llama-2 model achieved 0.759.\n4 Experimental Settings\nIn this section, we conduct comprehensive fake\nnews detection benchmarks using multiple datasets.\n4.1 Datasets\nBuzzFeedNews(Silverman et al., 2016) This\ndataset consists of news articles shared on Face-\nbook during the week surrounding the 2016 U.S.\nelection. It includes data collected from nine dif-\nferent news agencies, spanning from September 19\nto 23, and then September 26 and 27. Each arti-\ncle was fact-checked by a team of five BuzzFeed\njournalists. The articles are categorized under four\nlabels: mostly true, mostly false, a mix of true and\nfalse, and no factual content. In line with Shu et al.\n(2019), we utilize the subset of 182 news articles\nfor our benchmark. Each article in this subset has\nbeen assigned one of two binary labels (true or fake\nnews), making it suitable for our binary classifica-\ntion setting.\nFakenewsnet (Shu et al., 2017a,b, 2018) A fake\nnews dataset characterized by its rich diversity, in-\ncluding news articles and social context. The con-\ntents have been sourced from PolitiFact5and Gos-\nsipCop6, with most of them dating back to before\n2018. In this paper, we have chosen to utilize the\nPolitiFact portion due to its high quality, as all the\nfacts have been verified by domain experts.\nLLMFake (Chen and Shu, 2024) A misinfor-\nmation dataset is further modified by LLMs such as\nChatGPT. These models utilize various techniques,\nincluding paraphrasing, rewriting, etc. for infor-\nmation manipulation. The information within this\ndataset traces back to 2020 or earlier.\nPolitiFact-Snopes-2024 The dataset was manu-\nally collected from the prestigious fact-checking\norganizations PolitiFact and Snopes7. It includes\napproximately 1,200 verifiable claims along with\nthe fact-check rating labels that determine the level\nof truthfulness for each claim. The clarifications\nfor the labels and the additional detailed analysis\nreports were not collected. Non-text-based claims\nwere filtered out, and exclusive fact-checks with\nsupporting sources specific to these organizations\nwere also filtered out.\nFakeNews2024 This dataset consists 46 real\nnews and 63 fake news articles. All the news arti-\ncles are less than one year old, and are confirmed\nby NewsBreak moderation team.\nThe first three datasets were selected to en-\nable a comparison of our system against three dis-\ntinct fake news detection methods: content-based,\nLLMs-based, and retrieval-augmented approaches.\nThe last two datasets are used to demonstrate our\napproach\u2019s ability to detect the latest fake news.\n4.2 Evaluation Metrics\nFor the existing datasets, we strive to employ the\nsame evaluation metrics that have been utilized in\nprior studies to enable direct comparisons.\nFor BuzzFeedNews, we report the precision, re-\ncall, and F1 scores related to fake news, as well as\n5https://www.politifact.com\n6https://www.gossipcop.com is now closed\n7https://www.snopes.comMethod Accuracy Precision Recall F1\nP\u00e9rez-Rosas et al. (2018) 75.5 74.5 76.9 75.7\nShu et al. (2019) 86.4 84.9 89.3 87.0\nZhou et al. (2020) 87.9 85.7 90.2 87.9\nOurs (GPT) 79.1 81.2 75.8 78.4\nOurs (Llama) 73.6 71.3 79.1 75.0\nTable 3: Detection performance on BuzzFeedNews.\nthe accuracy for the entire dataset. For Fakenews-\nnet, PolitiFact-Snopes-2024, and FakeNews2024,\nwe report the precision (P-F), recall (R-F), and F1\nscore (F1-F) of the fake news, the precision (P-T),\nrecall (R-T), and F1 score (F1-T) of the real news,\nas well as the Micro F1 score (F1) of the overall\ndataset. For LLMFake, we report the detection suc-\ncess rate, which is calculated by the percentage of\nsuccessfully identified fake news (Chen and Shu,\n2024).\n4.3 Implementation Details\nTo aid in the verification of news articles, the main\nfactual claim of each news article is identified and\nthen compared against internet search results. To\nensure a fair comparison, we have developed heuris-\ntics to carefully filter out fact-checking content\nfrom search engine results in all the experiments\nbelow.\nThe datasets above except LLMFake are each\naggregated to train the final LightGBM classifier,\nutilizing the features outlined in Section 3.4, and\nsubsequently report the end-to-end accuracy. Both\nthe training and testing processes are conducted\nusing a 5-fold cross-validation approach. We also\nprovided baseline benchmarks for comparison.\n5 Experimental Results\nThe performance with the BuzzfeedNews dataset\nis detailed in Table 3. The baseline methods be-\ning reported in Zhou et al. (2020) utilize features\nfrom article content, and outperform our approach.\nThis outcome is expected since BuzzfeedNews\ndataset focuses primarily on a limited range of top-\nics, specifically the 2016 US election. The nature\nof the fake news within this dataset allows it to be\neffectively modeled through content features. Fur-\nthermore, the fake news articles are approximately\n7 years old, posing additional challenges for search\nengines in retrieving relevant evidences.\nIn Table 4, we present a performance compari-\nson between VeraCT Scan and another retrieval-\naugmented system, utilizing the FakeNewsNet\nMethod F1 F1-T R-T P-T F1-F R-F P-F\nLiao et al. (2023) 72.9 75.7 78.0 73.5 70.2 68.1 72.8\nOurs (GPT) 80.3 81.9 85.9 78.2 78.3 74.1 83.0\nOurs (Llama) 77.3 79.0 82.3 75.9 75.3 71.9 79.1\nTable 4: Detection performance on Fakenewsnet.\nDataset Written Paraphrasing Rewriting Generating\nGPT-4-based Zero-shot Detector (COT) (Chen and Shu, 2024)\nPolitifact 62.6 56.0 53.6 41.6\nGossipcop 26.3 30.0 25.0 25.7\nCoAID 81.0 82.2 73.3 52.7\nOurs (GPT)\nPolitifact 63.7 62.2 60.0 60.7\nGossipcop 42.9 42.0 40.3 39.4\nCoAID 83.7 86.0 77.9 69.8\nOurs (Llama)\nPolitifact 56.3 55.9 55.5 51.1\nGossipcop 31.2 30.3 34.6 28.6\nCoAID 74.4 75.6 70.9 60.5\nTable 5: Detection performance on LLMFake.\ndataset. Our two implementations, GPT-4 Turbo\nand the fine-tuned version of Llama-2 13B, both\nexhibit superior accuracy. This comparison un-\nderscores the efficacy of using either prompted or\nfine-tuned LLMs over specialized encoder-decoder\ntransformers that have been specifically trained for\nthis task.\nTable 5 presents the detection performance using\nLLMFake. Notably, although the news articles in\nLLMFake are from 2020 or earlier\u2014falling within\nGPT-4\u2019s inherent knowledge base, VeraCT Scan\nsignificantly outperforms GPT-4 in verification ac-\ncuracy. Notably, the Llama-2 13B implementation\nalso wins 7 out of 12 benchmarks. This underscores\nthe benefits and efficacy of incorporating knowl-\nedge from the Internet. It is important to note that\nLLMFake verification is not straightforward. Ac-\ncording to Chen and Shu (2024), the accuracy of\nhuman annotations falls well below 40%.\nIn Tables 6 and 7, we present the detection ac-\ncuracy of our system when tested against the latest\nnews articles. Unlike BuzzFeedNews, these two\ndatasets consist of a wide variety of topics, includ-\ning politics, entertainment, international warfare,\nand more. Both implementations of our system\npresent relatively high detection accuracy, and un-\nderscores the effectiveness in verifying the latest\nnews. Our approach benefits significantly from the\nenhanced efficiency of both Google and our propri-\netary search engine in sourcing relevant evidences\nfor recent news.Method F1 F1-T R-T P-T F1-F R-F P-F\nOurs (GPT) 91.7 91.7 90.7 92.8 91.7 92.8 90.7\nOurs (Llama) 85.6 85.9 86.4 85.3 85.3 84.8 85.9\nTable 6: Detection performance on PolitiFact-Snopes-\n2024.\nMethod F1 F1-T R-T P-T F1-F R-F P-F\nOurs (GPT) 89.9 87.6 84.8 90.7 91.5 93.7 89.4\nOurs (Llama) 82.9 80.0 78.3 81.8 85.9 87.3 84.6\nTable 7: Detection performance on FakeNews2024.\n6 Conclusion and Future Work\nIn this paper, we present VeraCT Scan, a novel\nretrieval-augmented system for fake news detection.\nTwo of our implementations, properly prompted\nGPT-4 Turbo and fine-tuned Llama-2 13B demon-\nstrated notable accuracy in detection. Specifically,\nthe GPT-4 Turbo implementation exhibited state-\nof-the-art performance in several datasets. VeraCT\nScan is especially successful in identifying the lat-\nest instances of fake news. This emphasizes the\ncritical role of search result relevance in gathering\ncompelling evidence.\nOur observations reveal that the rationales gen-\nerated by LLMs offer rich insights into potentially\ndubious aspects with a high degree of details. As\na future work, we plan to investigate the potential\nof using these rationales as input features for the\nfinal verification classifier. And throughout our\nevaluations, Llama-2 13B consistently lags behind\nGPT-4 Turbo in terms of detection accuracy. We\nwill explore more effective fine-tuning strategies to\nnarrow this performance gap.\nFurthermore, we observe that within the entire\nsystem, the majority of errors occur during the veri-\nfication stage, with a smaller fraction arising during\nthe claim extraction phase. The causes of these er-\nrors include: (i) Irrelevant search results used for\nverification. (ii) Updated news events leading to\noutdated reports being used for verification. (iii)\nEach report only supporting a part of the claim, ne-\ncessitating the proper merging of relevant informa-\ntion from multiple news reports for full verification.\n(iv) Improper normalization of named entities or\ntemporal expressions during the claim extraction\nstage, making alignment difficult during verifica-\ntion (e.g., \"last weekend\" vs. an exact date). We\nhope to address these issues in future work.\n7 Limitations\nNews events are inherently dynamic, and the truth\nsurrounding them can evolve over time. When ver-\nifying a news article being published in 2015 that\ndiscusses the average income increase ratio since\n2001, it is crucial to obtain accurate data spanning\nfrom 2001 to 2015. This task presents challenges\nnot only to search engines but also to LLMs. We\nhave observed that our system performs more ef-\nfectively when verifying more recent news articles.\nTo close the gap, it requires truly understanding of\ntimestamps by LLMs and the ability to accurately\nperform time sensitive calculations.\nIt has been noted that low-quality news articles\nfrequently mix facts with opinions. In addition\nto verifying facts, it\u2019s important to distinguish the\nopinion segments within a news report. To ac-\ncomplish this, it is crucial to integrate article-level\nlinguistic features with retrieval-augmented fact\nverification methods.\nFake news can be deliberately created on a large\nscale. Beyond verifying individual articles, check-\ning the authenticity of clusters of articles, can sig-\nnificantly enhance the detection effectiveness.\nFor practical considerations such as enhancing\nservice robustness, reducing latency, and cutting\ncosts, it is desirable to develop a smaller-sized\nLLM specifically for fake news detection. We plan\nto significantly invest in creating high-quality train-\ning data and explore advanced fine-tuning technolo-\ngies to bridge the performance gap with GPT-4 in\nthis area.\n8 Ethical Discussion\nDetecting fake news is a critical task with signifi-\ncant consequences. The effectiveness of this detec-\ntion depends on various factors, such as the qual-\nity of searches, the impartial assessment of source\ncredibility, and the language understanding capa-\nbilities of large language models (LLMs), among\nothers. Our system aims to gather pertinent evi-\ndence from reputable sources, thereby aiding users\nin making informed decisions but not making those\ndecisions for them. This approach is clearly out-\nlined on our demo site.\nReferences\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news mediasources. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing ,\npages 3528\u20133539, Brussels, Belgium. Association\nfor Computational Linguistics.\nDeng Cai, Yan Wang, Wei Bi, Zhaopeng Tu, Xiaojiang\nLiu, Wai Lam, and Shuming Shi. 2019. Skeleton-\nto-response: Dialogue generation guided by retrieval\nmemory. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n1219\u20131228, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nCarlos Castillo, Marcelo Mendoza, and Barbara Poblete.\n2011. Information credibility on twitter. In Proceed-\nings of the 20th International Conference on World\nWide Web , WWW \u201911, page 675\u2013684, New York, NY ,\nUSA. Association for Computing Machinery.\nCanyu Chen and Kai Shu. 2024. Can LLM-generated\nmisinformation be detected? In The Twelfth Interna-\ntional Conference on Learning Representations .\nJiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.\n2024. Benchmarking large language models in\nretrieval-augmented generation. Proceedings of\nthe AAAI Conference on Artificial Intelligence ,\n38(16):17754\u201317762.\nZiwei Chen, Linmei Hu, Weixin Li, Yingxia Shao, and\nLiqiang Nie. 2023. Causal intervention and coun-\nterfactual reasoning for multi-modal fake news de-\ntection. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 627\u2013638, Toronto,\nCanada. Association for Computational Linguistics.\nTsun Hin Cheung and Kin Man Lam. 2023. Factllama:\nOptimizing instruction-following language models\nwith external knowledge for automated fact-checking.\nIn2023 Asia Pacific Signal and Information Pro-\ncessing Association Annual Summit and Conference,\nAPSIPA ASC 2023 , 2023 Asia Pacific Signal and In-\nformation Processing Association Annual Summit\nand Conference, APSIPA ASC 2023, pages 846\u2013853.\nInstitute of Electrical and Electronics Engineers Inc.\nPublisher Copyright: \u00a92023 IEEE.; 2023 Asia Pa-\ncific Signal and Information Processing Association\nAnnual Summit and Conference, APSIPA ASC 2023\n; Conference date: 31-10-2023 Through 03-11-2023.\nAnastasia Giachanou, Paolo Rosso, and Fabio Crestani.\n2019. Leveraging emotional signals for credibility\ndetection. In Proceedings of the 42nd international\nACM SIGIR conference on research and development\nin information retrieval , pages 877\u2013880.\nAnastasia Giachanou, Guobiao Zhang, and Paolo Rosso.\n2020. Multimodal multi-image fake news detection.\nIn2020 IEEE 7th International Conference on Data\nScience and Advanced Analytics (DSAA) , pages 647\u2013\n654.\nLinmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong,\nDuyu Tang, Chuan Shi, Nan Duan, and Ming Zhou.\n2021. Compare to the knowledge: Graph neural fake\nnews detection with external knowledge. In Proceed-\nings of the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers) , pages 754\u2013763, Online.\nAssociation for Computational Linguistics.\nKung-Hsiang Huang, Kathleen McKeown, Preslav\nNakov, Yejin Choi, and Heng Ji. 2023. Faking\nfake news for real fake news detection: Propaganda-\nloaded training data generation. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\npages 14571\u201314589, Toronto, Canada. Association\nfor Computational Linguistics.\nGautier Izacard and Edouard Grave. 2021. Leveraging\npassage retrieval with generative models for open do-\nmain question answering. In Proceedings of the 16th\nConference of the European Chapter of the Associ-\nation for Computational Linguistics: Main Volume ,\npages 874\u2013880, Online. Association for Computa-\ntional Linguistics.\nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang,\nWei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu.\n2017. Lightgbm: A highly efficient gradient boost-\ning decision tree. Advances in neural information\nprocessing systems , 30.\nArmin Kirchknopf, Djordje Slijep \u02c7cevi\u00b4c, and Matthias\nZeppelzauer. 2021. Multimodal detection of infor-\nmation disorder from social media. In 2021 Inter-\nnational Conference on Content-Based Multimedia\nIndexing (CBMI) , pages 1\u20134.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\nrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rock-\nt\u00e4schel, Sebastian Riedel, and Douwe Kiela. 2020.\nRetrieval-augmented generation for knowledge-\nintensive nlp tasks. In Proceedings of the 34th Inter-\nnational Conference on Neural Information Process-\ning Systems , NIPS \u201920, Red Hook, NY , USA. Curran\nAssociates Inc.\nDaliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin\nWang, Michal Lukasik, Andreas Veit, Felix Yu, and\nSanjiv Kumar. 2023. Large language models with\ncontrollable working memory. In Findings of the As-\nsociation for Computational Linguistics: ACL 2023 ,\npages 1774\u20131793, Toronto, Canada. Association for\nComputational Linguistics.\nMiaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao,\nand Zhu Zhang. 2024. Self-checker: Plug-and-play\nmodules for fact-checking with large language mod-\nels.\nHao Liao, Jiahao Peng, Zhanyi Huang, Wei Zhang,\nGuanghua Li, Kai Shu, and Xing Xie. 2023. Muser:\nA multi-step evidence retrieval enhancement frame-\nwork for fake news detection. In Proceedings of the29th ACM SIGKDD Conference on Knowledge Dis-\ncovery and Data Mining , KDD \u201923, page 4461\u20134472,\nNew York, NY , USA. Association for Computing\nMachinery.\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out , pages 74\u201381, Barcelona, Spain.\nAssociation for Computational Linguistics.\nXiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan\nZeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong,\nand Jie Tang. 2023. Webglm: Towards an efficient\nweb-enhanced question answering system with hu-\nman preferences. In Proceedings of the 29th ACM\nSIGKDD Conference on Knowledge Discovery and\nData Mining , KDD \u201923, page 4549\u20134560, New York,\nNY , USA. Association for Computing Machinery.\nXiaoran Liu, Hang Yan, Chenxin An, Xipeng Qiu, and\nDahua Lin. 2024. Scaling laws of roPE-based extrap-\nolation. In The Twelfth International Conference on\nLearning Representations .\nFederico Monti, Fabrizio Frasca, Davide Eynard, Da-\nmon Mannion, and Michael M. Bronstein. 2019.\nFake news detection on social media using geometric\ndeep learning. CoRR , abs/1902.06673.\nKai Nakamura, Sharon Levy, and William Yang Wang.\n2020. Fakeddit: A new multimodal benchmark\ndataset for fine-grained fake news detection. In Pro-\nceedings of the Twelfth Language Resources and\nEvaluation Conference , pages 6149\u20136157, Marseille,\nFrance. European Language Resources Association.\nQiong Nan, Qiang Sheng, Juan Cao, Yongchun Zhu,\nDanding Wang, Guang Yang, Jintao Li, and Kai Shu.\n2023. Exploiting user comments for early detec-\ntion of fake news prior to users\u2019 commenting. arXiv\npreprint arXiv:2310.10429 .\nLiangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan\nLuu, William Yang Wang, Min-Yen Kan, and Preslav\nNakov. 2023. Fact-checking complex claims with\nprogram-guided reasoning. In Proceedings of the\n61st Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n6981\u20137004, Toronto, Canada. Association for Com-\nputational Linguistics.\nBaolin Peng, Michel Galley, Pengcheng He, Hao Cheng,\nYujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou\nYu, Weizhu Chen, et al. 2023. Check your facts and\ntry again: Improving large language models with\nexternal knowledge and automated feedback. arXiv\npreprint arXiv:2302.12813 .\nVer\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 3391\u20133401, Santa Fe, New Mexico, USA.\nAssociation for Computational Linguistics.\nPiotr Przybyla. 2020. Capturing the style of fake news.\nProceedings of the AAAI Conference on Artificial\nIntelligence , 34(01):490\u2013497.\nVahed Qazvinian, Emily Rosengren, Dragomir R.\nRadev, and Qiaozhu Mei. 2011. Rumor has it: Identi-\nfying misinformation in microblogs. In Proceedings\nof the 2011 Conference on Empirical Methods in Nat-\nural Language Processing , pages 1589\u20131599, Edin-\nburgh, Scotland, UK. Association for Computational\nLinguistics.\nNazneen Rajani, Lewis Tunstall, Edward\nBeeching, Nathan Lambert, Alexander M.\nRush, and Thomas Wolf. 2023. No robots.\nhttps://huggingface.co/datasets/\nHuggingFaceH4/no_robots .\nMohammed Saeed, Nicolas Traub, Maelle Nicolas, Gi-\nanluca Demartini, and Paolo Papotti. 2022. Crowd-\nsourced fact-checking at twitter: How does the\ncrowd compare with experts? In Proceedings of\nthe 31st ACM International Conference on Informa-\ntion & Knowledge Management , CIKM \u201922, page\n1736\u20131746, New York, NY , USA. Association for\nComputing Machinery.\nKimya Khakzad Shahandashti, Mithila Sivakumar, Mo-\nhammad Mahdi Mohajer, Alvine B. Belle, Song\nWang, and Timothy C. Lethbridge. 2024. Evaluating\nthe effectiveness of gpt-4 turbo in creating defeaters\nfor assurance cases.\nSaeid Sheikhi. 2021. An effective fake news de-\ntection method using woa-xgbtree algorithm and\ncontent-based features. Applied Soft Computing ,\n109:107559.\nKai Shu, Deepak Mahudeswaran, Suhang Wang, Dong-\nwon Lee, and Huan Liu. 2018. Fakenewsnet: A data\nrepository with news content, social context, and spa-\ntiotemporal information for studying fake news on\nsocial media. Big data , 8 3:171\u2013188.\nKai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and\nHuan Liu. 2017a. Fake news detection on social\nmedia: A data mining perspective. SIGKDD Explor.\nNewsl. , 19(1):22\u201336.\nKai Shu, Suhang Wang, and Huan Liu. 2017b. Exploit-\ning tri-relationship for fake news detection. ArXiv ,\nabs/1712.07709.\nKai Shu, Suhang Wang, and Huan Liu. 2019. Beyond\nnews contents: The role of social context for fake\nnews detection. In Proceedings of the Twelfth ACM\nInternational Conference on Web Search and Data\nMining , WSDM \u201919, page 312\u2013320, New York, NY ,\nUSA. Association for Computing Machinery.\nKai Shu, Xinyi Zhou, Suhang Wang, Reza Zafarani,\nand Huan Liu. 2020. The role of user profiles for\nfake news detection. In Proceedings of the 2019\nIEEE/ACM International Conference on Advances\nin Social Networks Analysis and Mining , ASONAM\n\u201919, page 436\u2013439, New York, NY , USA. Association\nfor Computing Machinery.Craig Silverman, Lauren Strapagiel, Hamza Shaban,\nEllie Hall, and Jeremy Singer-Vine. 2016. Hy-\nperpartisan facebook pages are publishing false\nand misleading information at an alarming rate.\nhttps://github.com/BuzzFeedNews/\n2016-10-facebook-fact-check .\nJianlin Su, Yu Lu, Shengfeng Pan, Bo Wen, and Yunfeng\nLiu. 2021. Roformer: Enhanced transformer with\nrotary position embedding. CoRR , abs/2104.09864.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy\nLiang, and Tatsunori B. Hashimoto. 2023. Stan-\nford alpaca: An instruction-following llama\nmodel. https://github.com/tatsu-lab/\nstanford_alpaca .\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023. Llama 2: Open foundation and fine-\ntuned chat models.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\nand Ashish Sabharwal. 2023. Interleaving retrieval\nwith chain-of-thought reasoning for knowledge-\nintensive multi-step questions. In Proceedings of\nthe 61st Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers) ,\npages 10014\u201310037, Toronto, Canada. Association\nfor Computational Linguistics.\nNorman Vasu, Benjamin Ang, Terri-Anne Teo, Shashi\nJayakumar, Muhammad Faizal, and Juhi Ahuja. 2018.\nFake news: National security in the post-truth era.\nTechnical report, S. Rajaratnam School of Interna-\ntional Studies.\nHaoran Wang and Kai Shu. 2023. Explainable claim\nverification via knowledge-grounded reasoning with\nlarge language models. In The 2023 Conference on\nEmpirical Methods in Natural Language Processing .\nWeizhi Xu, Q. Liu, Shu Wu, and Liang Wang. 2023.\nCounterfactual debiasing for fact verification. In\nAnnual Meeting of the Association for Computational\nLinguistics .\nXin Xu, Shizhe Diao, Can Yang, and Yang Wang. 2024.\nCan we verify step by step for incorrect answer de-\ntection?\nXuan Zhang and Wei Gao. 2023. Towards LLM-based\nfact verification on news claims with a hierarchical\nstep-by-step prompting method. In Proceedings of\nthe 13th International Joint Conference on Natural\nLanguage Processing and the 3rd Conference of the\nAsia-Pacific Chapter of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , pages\n996\u20131011, Nusa Dua, Bali. Association for Compu-\ntational Linguistics.\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao\nSun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu,\nLILI YU, Susan Zhang, Gargi Ghosh, Mike Lewis,\nLuke Zettlemoyer, and Omer Levy. 2023a. LIMA:\nLess is more for alignment. In Thirty-seventh Con-\nference on Neural Information Processing Systems .\nShuyan Zhou, Uri Alon, Frank F. Xu, Zhengbao Jiang,\nand Graham Neubig. 2023b. Docprompting: Gener-\nating code by retrieving the docs. In The Eleventh\nInternational Conference on Learning Representa-\ntions .\nXinyi Zhou, Atishay Jain, Vir V . Phoha, and Reza Za-\nfarani. 2020. Fake news early detection: A theory-\ndriven model. Digital Threats , 1(2).\nA Prompts\nHere we list the prompts used in the pipeline:\nMAIN CLAIM EXTRACTION\nGiven the input content below, please summarize the single key claim.\nInput content: {content}\nPlease output with the follow json format {{\"key_claim\": XXX}}.\nPlease output now:\nKEY CLAIMS EXTRACTION\nGiven the input content below, please extract distinct key claims. The key claims should be concrete enough containing clear\ncontext so that it can be efficiently verified.\nInput content: {content}\nPlease output with the follow json format {{\"key_claims\": [{{\"claim\": XXX}}, ...]}}.\nPlease output now:\nQUERY GENERATION\nGiven the claim below, please generate a Google query which can be used to search content to verify this claim.\nClaim: {claim}\nPlease output with the following JSON format {{\"query\": \"XXX\"}}\nPlease output now:\nCONTENT CLAIM VERIFICATION\nBelow is one web search result\nSearch Result:\n{search_result}\nBelow is a claim to be verified\nClaim: {claim}\nPlease perform the following rules to generate an output with this json format : {{\"support_or_negate_or_baseless\": \"support\" or\n\"negate\" or \"baseless\", \"confidence\": \"high\" or \"medium\" or \"low\", \"rationale\": \"XXX\"}}\nRule 1: if the search result content support the claim, set the \"support_or_negate_or_baseless\" field as \"support\", and offer a\nconfident score and a rationale.\nRule 2: if the search result content negate the claim, set the \"support_or_negate_or_baseless\" field as \"negate\", and offer a\nconfident score and a rationale.\nRule 3: if the search result content cannot either support or negate the claim, set the \"support_or_negate_or_baseless\" field as\n\"baseless\", and offer a confident score and a rationale.\nTo clarify: if the content of the search results does not contradict the claim, but lacks some or all of the information presented in\nthe claim, please use the label \"baseless\" rather than \"negate\".\nPlease output now:\nSAME NEWS /RELEVANT VERIFICATION\nBelow is one web search result.\nSearch Result: {search_result}\nBelow is a claim:\nClaim: {claim}\nPlease make the following two investigations:\n1. Please check if the news article and the search result is about the same news story.\n2. Please check if the search result contains content (facts, opinions, or claims) related to the news article.\nPlease output with the following json format :\n{{\"about_the_same_news_story\": \"yes\" or \"no\", \"contains_related_content\": \"yes\" or \"no\"}}\nPlease output now:\nTable 8: Prompts used for key tasks.\nB Sample Results\nWe provide an illustration of the process involved in verifying a news article below.\nNEWS ARTICLE :Scientists Warn Eggs Are Causing Thousands of People to \u2019Suddenly\u2019 Form Blood Clots\nIn what appears to be another example of the global elite attempting to distract the public from the real cause of the surge in heart\nproblems since the jab rollout, scientists now want us to believe that a nutrient found in eggs increases the risk of blood clotting.\nExpress.co.uk reports: The study conducted by Cleveland Clinic, suggested that choline could make the blood more prone to\nclotting.\nCholine is sometimes sold in over-the-counter dietary supplements.\nIt is deemed an essential nutrient that is widely recommended for optimal health.\nAccording to Medical News Today, it supports various bodily functions, including cellular growth and metabolism.\n...\nCLAIMS :1. A study conducted by Cleveland Clinic suggested that choline could make the blood more prone to clotting.\n2. Choline is deemed an essential nutrient that supports various bodily functions, including cellular growth and metabolism.\n3. Researchers found that consuming choline in high concentrations could lead to blood clotting.\n4. The interaction between choline and gut bacteria produces TMAO, which has been linked to an increased risk of blood clots,\nheart attack, and stroke.\n...(8 claims extracted)\nVERIFY : A study conducted by Cleveland Clinic suggested that choline could make the blood more prone to clotting.\nGENERATED QUERIES :\n1. Cleveland Clinic study choline blood clotting\n2. Researchers found that consuming choline in high concentrations could lead to blood clotting.\nNUM OF SEARCH RESULTS :18\nVERIFICATION & R ATIONALE :\nTitle: Study from 2017 misrepresented to link eggs to blood clots.\nResult: supported\nDomain: apnews.com\nRationale: The search result explicitly mentions a study conducted by the Cleveland Clinic in 2017, which found that taking\nsupplements in capsule form of choline 2014 a nutrient present in red meat, egg yolks, and other foods 2014 raised levels of a\ncompound in the body (trimethylamine N-oxide, or TMAO) that could make the blood more prone to clotting. This directly\nsupports the claim that consuming choline in high concentrations could lead to blood clotting.\n\u2014\nTitle: Cleveland Clinic Researchers First to Show Dietary Choline and Gut Bacteria Byproduct Linked with Increased Blood...\nResult: supported\nDomain: clevelandclinic.org\nRationale: The search result explicitly states that Cleveland Clinic researchers have shown for the first time in humans that\ncholine is directly linked to increased production of a gut bacteria byproduct that increases the risk of blood-clotting events like\nheart attack and stroke. This directly supports the claim that choline could make the blood more prone to clotting.\n\u2014\nTitle: Cleveland Clinic study did not conclude eggs are causing...\nResult: baseless\nDomain: reuters.com\nRationale: The provided search result does not contain information about the effect of choline intake on blood clotting. It only\nmentions a study done by Cleveland Clinic regarding eggs, which is unrelated to the claim about choline.\n...\nFINAL DECISION :Supported\nTable 9: An example of our pipeline ouput. Given that multiple claims can be extracted from a single article, we only\nexemplify the verification details of the first claim. The system generated two search queries related to the claim,\nresulting in the retrieval of 18 documents from the web. Based on the analysis of these documents, 14 documents\nare marked baseless (irrelevant or not fully support the claim), whereas the remaining 4 documents support the\nclaim. By considering the sources credibility, the claim is classified as supported.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "VeraCT scan: Retrieval-augmented fake news detection with justifiable reasoning", "author": ["C Niu", "Y Guan", "Y Wu", "J Zhu", "J Song", "R Zhong"], "pub_year": "2024", "venue": "arXiv preprint arXiv \u2026", "abstract": "The proliferation of fake news poses a significant threat not only by disseminating misleading  information but also by undermining the very foundations of democracy. The recent"}, "filled": false, "gsrank": 140, "pub_url": "https://arxiv.org/abs/2406.10289", "author_id": ["", "", "bzCZ4p0AAAAJ", "", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:P-ysy3KcpnUJ:scholar.google.com/&output=cite&scirp=139&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D130%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=P-ysy3KcpnUJ&ei=HLWsaIeTGKzWieoPic2ZoAU&json=", "num_citations": 6, "citedby_url": "/scholar?cites=8477635365428849727&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:P-ysy3KcpnUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2406.10289?"}}, {"title": "Political Fact Checking in the Tax Context", "year": "2022", "pdf_data": "Ohio Nor thern Univ ersity Law Re view Ohio Nor thern Univ ersity Law Re view \nVolume 49 Issue 1 Article 1 \nPolitical F act Checking in the T ax Context Political F act Checking in the T ax Context \nBret N. Bogenschneider PH.D ., JD , LLM \nFollow this and additional works at: https:/ /digitalcommons.onu.edu/onu_law_r eview \n Part of the Law Commons \nRecommended Citation Recommended Citation \nBogenschneider , Bret N. PH.D ., JD , LLM () \"P olitical F act Checking in the T ax Context, \" Ohio Nor thern \nUniv ersity Law Re view : Vol. 49: Iss. 1, Ar ticle 1. \nAvailable at: https:/ /digitalcommons.onu.edu/onu_law_r eview/v ol49/iss1/1 \nThis Ar ticle is br ought t o you for fr ee and open access b y the ONU Journals and Publications at \nDigitalCommons@ONU. It has been accepted for inclusion in Ohio Nor thern Univ ersity Law Re view b y an \nauthoriz ed edit or of DigitalCommons@ONU. F or mor e information, please contact digitalcommons@onu.edu . \n1 Ohio Northern University \nLaw Review \nLead Articles \nPolitical Fact Checking in the Tax Context \nBRET N. BOGENSCHNEIDER , PHD, JD, LLM* \n\u201cIf you\u2019ve ever found yourself engage d in a futile, one-sided argument \nwith a politician on your TV screen, you\u2019re  hardly alone in your frustration.\u201d1 \nINTRODUCTION  \nThe origin and nature of facts h as become an increasingly prominent \ntopic in American journalism and political discourse.2  Fact checking \nfunctions in part as the evaluation of truth claims by politicians,3 and has been \nshown to prompt politicians to make more fact-based claims.4  The purposes \nof fact checking has been stated as fo llows: \u201cThe purpose [of fact checking] \nis to discover and publish whether a clai m is accurate or not.  This is based \non various information sources, such as scientific studies, experts and official \n \n* Bret N. Bogenschneider, PhD, JD, LLM, Associate Pr ofessor of Accounting, Western Illinois University, \nCollege of Business & Technology. \n 1. Mark Hemingway, Lies, Damned Lies, and \u2018Fact Checking\u2019,  WASH. EXAMINER  (Dec. 19, \n2011, 12:00 AM), https://www.washingtonexaminer.c om/weekly-standard/lies-damned-lies-and-fact-\nchecking. \n 2. Lucas Graves, Anatomy of a Fact Check: Objective Pr actice and the Contested Epistemology \nof Fact Checking , 10 C OMM ., CULTURE & CRITIQUE  518, 518-19 (2017) [hereinafter Graves, Anatomy of \na Fact Check ]; Cary Spivak, The Fact-Checking Explosion , 32 A M. JOURNALISM . REV. 38, 39-40 (2010). \n 3. Sakari Nieminen & Valtteri Sankari, Checking PolitiFact\u2019s Fact-Checks , 22 J OURNALISM \nSTUD. 358, 370-71 (2021). \n 4. See  Karen Bogenschneider & Bret N. Bogenschneider, Empirical Evidence From State \nLegislators: How, When, and Who Uses Research in Policymaking , 26 P SYCHOL . PUB. POL\u2019Y & L. 413, \n421 (2020). \n1Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n2 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nstatistics.  Usually, fact-checkers are interested in claims made by politicians \nand other influential actors.\u201d5 \nIn tax policy discourse, facts are presented as supposedly objective ideas \ngiven in support of a respective tax policy position.6  Yet, such supposed \n\u201cfacts\u201d are often disagreed upon even when based on the same underlying data.\n7  Nearly all matters within tax discourse can be reasonably disagreed \nupon depending on the context,8 including even the applicable tax rates,9 \nwhich are numeric but still can be described as either statutory or effective and accordingly either as high or low.\n10  As an illustration, a prior scholarly \ndebate on fact checking centered on Mitt Romney\u2019s less than flattering description of an Obama tax policy proposal.\n11  Even in that simplistic case, \nboth The Fact Checker and PolitiFact obtained data from the Tax Policy \n \n 5. See Nieminen & Sankari, supra  note 3, at 358 (\u201cFact-checking means evaluating the \ntruthfulness of claims presented in public.\u201d). \n 6. The leading search result for fact checking a tax policy claim is by the Tax Foundation relating \nto a claim by former  President Obama. \nIt seems the President has decided to join along with Warren Buffett in decrying the fact that \nhis (considerable) income is (unfairly) taxed at a lower rate than most middle-class Americans.  In a recent speech, he suggested that his eff ective tax rate was lower than someone earning \n$50,000.  It\u2019s a potentially compelling talking point  \u2013 that is, if it were true. . . . President \nObama\u2019s claim that he pays a lo wer tax rate than a teacher ma king $50,000 a year isn\u2019t true.  \nA single taxpayer with $50,000 of income would have paid 11.9 percent in federal income \ntaxes for 2010, while the Obamas paid more than twice that rate \u2014 25.3 percent (and higher \nrates than that in 2009 and 2008). \nRichard Morrison, Fact Checking the President\u2019s Tax Claims, T\nAX FOUND . (Sept. 28, 2011), \nhttps://taxfoundation.or g/fact-checking-presidents-tax-claims. \n 7. See Brian J. Gaines et al., Same Facts, Different Interpretations: Partisan Motivation and \nOpinion on Iraq , 69 J.  POL. 957 (2007). \n 8. See, e.g.,  Howard Gleckman, The Profound Philosophical Disagreement Over The Refundable \nChild Tax Credit , TAX POL\u2019Y CTR. (Jan. 28, 2022), https://www.ta xpolicycenter.or g/taxvox/profound-\nphilosophical-disagreement-over -refundable-child-tax-credit. \n 9. See  Brian Faler, Why Corporate Tax Reform is So Messy , POLITICO , https://www.politico.com/ \nstory/2017/09/06/corporate-tax-reform-trump-242373 (last updated Sept. 6, 2017, 12:53 PM) (\u201c\u2018Talking \nabout effective tax rate and tax rates in general is a choose-your-own adventure deal,\u2019 said Kyle Pomerleau, \nan economist at the conservative-leaning Tax Foundati on.  \u2018People will choose which rates line up with \ntheir world view.\u2019\u201d).  10. Compare Robert Bellafiore, How Do Transfers and Progressive Taxes Affect the Distribution \nof Income? , \nTAX FOUND . (Mar. 12, 2019), https://ta xfoundation.org/average-fede ral-tax-rates-income-\ngroup/#:~:text=For%20example %2C%20those%20in%20the%20lowest%20quintile%20paid,had%20an\n%20even%20higher%20rate%20of%2033.3%20percent (\u201cThe re sult of all federal taxes and transfers is a \nredistribution of income from high- to low-income households.\u201d), with Jesse Eisinger et al., The Secret \nIRS Files: Trove of Never-Before-Seen Record s Reveal How the Wealthie st Avoid Income Tax , \nPROPUBLICA  (June 8, 2021, 5:00 AM), https://www.propubli ca.org/article/the-secret-irs-files-trove-of-\nnever-before-seen-records-reveal-how -the-wealthiest-avoid-income-tax. \n 11. Molly Moorhead, Mitt Romney Would Cut Millionaires\u2019 Taxes, Obama Says , POLITI FACT, \n(Aug. 3,  2012), https://www.politifact.com/ factchecks/2012/aug/03/barack -obama/obama-romney-would \n-cut-millionaires-taxes/. \n2Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  3 \nCenter website,12 but were still unable to reach a definitive conclusion as to \nits accuracy.13 \nThe thesis of this article is that the objectivity norm of journalism14 is \ndifficult to apply in the tax context b ecause nearly all supposed \u201cfacts\u201d relate \nto an underlying and often undisclosed causal theory.15  Political discussants \nusually hold countervailing ideas of causation in respect of tax policy; that is, \nnearly all facts that journalists might set out to check turn out to be relative \nto an ideology, thus rendering such f acts subjective to the ideology applied \nwithin the respective paradigm.16  Accordingly, fact checking by journalists \ndoes not necessarily reveal objective truths about taxation and at times may serve as a type of rhetoric designed to sway public opinion on tax policy \nmatters.\n17  Furthermore, the particular methods of journalistic \ncommunication, such as clarity and conciseness, may not be well-suited to \ncontext dependent fields such as taxation.18  Fact checking within tax policy \nmay then be thought of as elusive but nonetheless still potentially helpful.19  \nAs Amazeen wrote: \u201cIt is precisely because facts are complex and often not self-evident that more fact-checking, rather than less, is necessary.\u201d\n20  If tax \npolicy is thought to be a particularly  complex area then perhaps more fact \nchecking is necessary in this area of political debate.21 \nAs explained in detail throughout this article, the trouble is that \njournalistic fact checking methodology en tails neither a consistently applied \nepistemology, nor a scientific one, for the evaluation of causal claims.22  In \nthe context of fact-checking matters of taxation and tax policy, this often has \nthe effect of suggesting that ther e are right or wrong answers in tax \nsomewhere out there over the rainbow, and then to say one politician or another has made a true or false claim without mentioning the rainbow.\n23  The \n \n 12. Michelle A. Amazeen, Revisiting the Epistemology of Fact-Checking , 27 C RITICAL REV. 1, 14 \n(2015) [hereinafter Amazeen, Revisiting the Epistemology ]. \n 13. Id. \n 14. See Michael Schudson, The Objectivity Norm in American Journalism , 2 J OURNALISM  149, \n149-50 (2001); Brent Cunningham, Re-thinking Objectivity , 42 C OLUM . JOURNALISM REV. 24, 26 (2003). \n 15. See  KARL POPPER , THE LOGIC OF SCIENTIFIC DISCOVERY , 38-39  (Routledge Classics 2002). \n 16. L OUIS EISENSTEIN , THE IDEOLOGIES OF TAXATION  12 (Harv. U. Press 2010). \n 17. See Edward J. McCaffery & Jonathan Baron, Thinking About Tax , 12 P SYCH ., PUB. POL\u2019Y, & \nL. 106 (2006). \n 18. Graves, Anatomy of a Fact Check, supra note 2, at 520. \n 19. Amazeen, Revisiting the Epistemology, supra note 12, at 17; Graves, Anatomy of a Fact Check, \nsupra note 2, at 520. \n 20. Amazeen, Revisiting the Epistemology,  supra note 12, at 3 (emphasis in original). \n 21. See id. \n 22. Joseph E. Uscinski & Ryden W. Butler, The Epistemology of Fact Checking , 25 C RITICAL REV. \n162, 168-69 (2013) [hereinafter Uscinski & Butler]; Joseph E. Uscinski, The Epistemology of Fact \nChecking (Is Still Na\u00ecve): Rejoinder to Amazeen , 27 C RITICAL REV. 243, 248-49 (2015) [hereinafter \nUscinski, Rejoinder to Amazeen ]. \n 23. Gaines et al., supra  note 7, at 957.  At times, it may be po ssible to say that a claim is false even \nwhen viewed from the paradigm in which it arose.  This would be a situation where fact-checking might \n3Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n4 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nfact checking might be better approached by disclosing or evaluating the \nideological theory to which the politician has applied in making the claim.24  \nNotably, this evaluation of competi ng theories using evidence was the first \nmodern description of science given by Karl Popper \u2013 the recommendation \nof this article is really to say that journalists should push fact checking methods toward the epistemologies of science.\n25 \nFact checking conducted without a defi ned epistemology may also risk \nsome unraveling of science or scientific  methods.  The potential for backward \nprogress by journalists through the crowding out of science has caused justifiable concern among scholars who pr efer for journalism to proceed in a \nstructured manner to the fullest extent possible.\n26  If scientific methods have \nbeen applied to a given issue to regulate the journalistic analysis, yet when applied are not uncovered during the \u201cfact checking\u201d process, the journalistic analysis may operate in competition with scientific inquiry.  Amazeen\u2019s recommendation might then be revised to ward epistemological quality rather \nthan quantity in fact checking if ther e is a risk arising from such flawed \nmethods, with the recommendation to then  read as follows: \u201cIt is precisely \nbecause facts are complex and often not self-evident that more [ epistemology \nin] fact-checking  . . . is necessary.\u201d\n27 \nDemonstrably false hypotheses regarding tax policy, such as the Laffer \nCurve,28 are occasionally resurrected by journalists in the process of fact \nchecking long after having been abandoned in scientific discourse. 29  A s   \nbe very helpful.  For example, if a politician claime d: \u201cTax rates are higher on the wealthy in New York \nthan London or Frankfurt,\u201d the fact-checker could gather the tax rates from those jurisdictions and see if \nthat were true based simply on the statutory rate). \n 24. As an illustration, a fact checking journalis t might refer to the underlying theory and say: \nUnder Mitt Romney\u2019s view, tax cuts for the wealthy always lead to some degree of economic \ngrowth, so the lost revenue from a tax cut might  be offset by the larger economy resulting from \nthe tax cut.  If you believe tax cuts always cause economic growth, then Romney\u2019s claim is \ntrue.  Tax scholars and other social scientists disagree however on this causal relation advanced \nby Romney and there is currently very little empi rical evidence that tax cuts for the wealthy \nhave resulted in economic growth in the past when  this has been tried.  If you do not think tax \ncuts cause economic growth, then lost revenue from a tax cut may not be offset by the larger \neconomy, and Romney\u2019s claim is false. \nSee generally Moorhead, supra note 11. \n 25. P OPPER , supra note 15, at 438. \n 26. Graves, Anatomy of a Fact Check, supra note 2, at 520, 530. \n 27. Amazeen, Revisiting the Epistemology, supra note 12, at 3 (alteration in original) (emphasis \nadded).  28. See  Victor A. Canto et al., Tax Rates, Factor Employment, and Market Production , in T\nHE \nSUPPLY -SIDE EFFECTS OF ECONOMIC POLICY  20-21 (1981);  Alan S. Blinder , Thoughts on the Laffer \nCurve , in THE SUPPLY -SIDE EFFECTS OF ECONOMIC POLICY  86, 91 (1981). \n 29. See Jane G. Gravelle, International Corporate Tax Rate Comparisons and Policy Implications , \nCONG. RSCH. SERV. 16 (Jan. 6, 2014), https://sgp.fas.org/crs/misc/R41743.pdf [hereinafter Gravelle , \nComparisons]; Jane G. Gravelle & Donald J. Marples, Tax Rates and Economic Growth , CONG. RSCH. \nSERV. 8 (Jan. 2, 2014), https://s gp.fas.org/crs/ misc/R42111.pdf. \n4Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  5 \nperhaps the prime example, tax scholars are generally aware that the Laffer \nCurve idea that tax cuts might yield higher tax receipts was advanced by President Reagan in various debates and policy proposals in the 1980\u2019s.\n30  \nResearch was undertaken to determin e if the idea was possible and it was \ndetermined not to be supported by any evidence.31  Some tax scholars think \nthe U.S. economy is not on the point of the curve where Laffer proposed while \nothers think that there is no such curve.32  However, persons born after these \nevents, including some journalists, may have never heard of the Laffer Curve \nand think the proposal is novel and possibl y true, thus worthy of a fact check.  \nIt seems fair to say that  fact checking can potentially crowd out expert views \nand occasionally result in the re-introduction of misinformation in the tax \ncontext.33  The reintroduction of ideas known to be false may involve what is \nreferred to as \u201cmotivated reasoning\u201d in the social sciences and explains why \nscholars are concerned about the epis temology, namely the methods, that \njournalists use in fact checking, specifically with respect to tax policy.34 \nThe number of organizations engaged in fact checking has expanded in \nrecent years, and now ranges from internet websites,35 to newspapers,36 and \nto various policy organi zations and think tanks,37 thus yielding a multitude of \ncompeting factual results.  If facts coul d be objectively determined in some \nway, then fact-finding could at times be seen as akin to judicial findings of \nfacts in a legal dispute, thus endowing the fact checker organization as the finder-of-fact in the role of a judge or jury in legal contexts.  Journalists and \nmedia organizations are thought by some scholars to hold a monopoly power \nover truth claims in political discourse and, as such, could potentially influence the results of an election by favoring one politician\u2019s claims over \nanother.\n38 \n \n 30. See generally Ronald Reagan and the Laffer Curve , PRESIDENTIAL HIST. GEEKS  (May 31, \n2012, 12:16 AM), https://potus-geeks.liv ejournal.com/226929.html (\u201cReagan  was inspired by the work of \nan economist named Arthur Laffer . . . who had developed something called the Laffer Curve.\u201d). \n 31. Blinder, supra note 28 at 86-87, 91. \n 32. Laurence H. Meyer , Foreword  to T HE SUPPLY -SIDE EFFECTS OF ECONOMIC POLICY  vii-viii \n(1981). \n 33. See generally Arthur Laffer, The Laffer Curve: Past, Present, and Future, H ERITAGE FOUND . \n(June 1, 2004), https://www.heritage.org/taxes/re port/the-laffer-curve-pas t-present-and-future. \n 34. Nathan Walter & Nikita A. Salovich, Unchecked vs. Uncheckable: Ho w Opinion-Based Claims \nCan Impede Corrections of Misinformation , 24 M ASS COMM . & SOC\u2019Y. 500, 503-04 (2021). \n 35. See Our Process , FACTCHECK .ORG, https://www.factch eck.org/our-process/ (last updated \nAug. 12, 2020).  36. See generally Linda Qiu, Fact-Checking Health Claims About the Inflation Reduction Act , \nN.Y.\n TIMES  (Aug. 19, 2022), https://www.nytimes.com/2022/ 08/19/us/politics/fact-check-health-claims-\ninflation-reduction-act.html.  37. Compare About Us, T\nAX POL\u2019Y CTR, https://www.taxpolicycenter.org/about (last visited Oct. \n1, 2022), with  About Heritage: Mission , HERITAGE FOUND , https://www.heritage.org/about-heritage/ \nmission (last visited Oct. 1, 2022).  38. Uscinski, Rejoinder to Amazeen , supra note 22, at 249. \n5Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n6 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nThe point of scholarly concern is that it is not at all certain that the \nfinders-of-fact have the ability to acc urately determine facts in the tax \ncontext.39  Uscinski refers to this potential of an increasingly misinformed \ndemocratic electorate as a \u201cdark place\u201d: \nIf we take the claims put forth in Amazeen\u2019s article at face value, we \nend up in a dark place: media organizations that have assumed a \nmonopoly over determining the truth, with the power to sway \nelections, but that don\u2019t use consistent, scientific, or rigorous methods when asserting who the \u201cliars\u201d are.\n40 \nThe despair reflected in Uscinski \u2019s comments seems to indicate both \nbona fide concerns about flaws in jour nalistic methods and also the potential \nfor a wider dissemination of bad information via modern technology.41  Yet, \njournalists have seemingly always decried dubious claims by politicians \nduring elections.42  Here, the new \u201cdark place concern\u201d is potentially linked \nto the rise in the internet and cable te levision which yields more egalitarian \nsources of misinformation premised on flawed fact checking methods or results.\n43 \nOther fact-checkers have set out to evaluate claims on a rating scale,44 \nrather than to evaluate the claim as formally right or wrong in a specific \ncontext.45   Even such an approach might not resolve many tax policy claims.  \nFor example, a typical journalistic clai m in tax policy is that taxes on the \nwealthy are relatively high in the United States.46  A rating scale approach \nmight rate this as partially true, if other countries such as Singapore have lower statutory tax rates, resulting perh aps in a six rating on a ten-point rating \nscale.  However, as measured on an effective tax rate basis, taxes on the wealthy might also be seen as relatively low in comparison to other taxpayers.\n47  Furthermore, the actual amount of taxes paid in dollar terms  \n 39. Id. \n 40. Id. \n 41. See  James H. Kuklinski et al., Misinformation and the Currency of Democratic Citizenship , 62 \nJ. POL. 790, 791, 794 (2000). \n 42. Nieminen & Sankari, supra  note 3, at 359. \n 43. Andrew M. Guess et al. , Exposure to Untrustworthy Websites in the 2016 US Election , 4 \nNATURE HUM. BEHAV . 472, 476 (2020). \n 44. See Angie Drobnic Holan, The Principles of the Truth-O-Meter: PolitiFact\u2019s Methodology for \nIndependent Fact-Checking , P OLITI FACT, https://www.politifact.com/ar ticle/2018/feb/12/principles-\ntruth-o-meter-politifacts-methodology-i/ (last updated Apr. 18, 2022). \n 45. See  Michelle Amazeen et al., Correcting Political and Consumer Misperceptions: The \nEffectiveness and Effects of Rating Scal e Versus Contextual Correction Formats, 95 J OURNALISM & MASS \nCOMM . Q. 28 (2018) [hereinafter Amazeen et al., Correcting Misperceptions ]. \n 46. See, e.g. , Ben Johnson, Fact Check: Do The Rich  Really Pay No Taxes? , DAILY WIRE (June \n10, 2021), https://www.dailywire.com/news/fact -check-do-the-rich-r eally-pay-no-taxes. \n 47. This article asserts the ex traordinary and novel tax policy ar gument that taxes on lower income \npersons should be raised to e qual the taxes on the wealthy.  See David Callahan, Are Taxes on the Rich \n6Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  7 \nmight also be measured over time and us ed to evaluate the relative change on \nthat basis.48  The rating assigned by the fact-checking organization thus \ninvolved a subjective  evaluation of the competing ideas within tax policy in \norder to arrive at the numerical score in the rating system.49  The numerical \nscore or rating is designed to present an objective criterion to evaluate the \nclaim yet it is not so.50  The rating scale is simply not applicable to evaluate \nthe truth of claims from competing pa radigms, and is neither objective nor \nsubjective when viewed from the othe r perspective or paradigm, where the \nfigures given in the other system do not count in this system.51  The six-point \nrating scale would accordingly be invalid, or alternately such a middle rating \nsuch as a six might be interpreted as comprising a simple acknowledgement \nof the existence of perhaps many different ways to see a matter of tax policy. \nYet, the direction of change in epis temological quality within journalistic \npractices appears to be favorable.52  The methods of fact checking purport to \nrepresent perhaps even baby steps toward  a more defined epistemology.53  So, \nfact checking can be seen as a good thing \u2013 in other words, we want journalists to try to determine facts even if they sometimes get it wrong.  \nMany journalism scholars seem to favor  improved methods within fact \nchecking even where that may be extrem ely difficult, such as in respect to \ntaxes.\n54  A push among journalists toward epistemology is also significant to \nphilosophy, as Richard Rorty once criticized as the uncovering of truths by \ndiscourse within the democracy.55  In philosophical terms, the push towards \nany methodology of fact checking by journalists, technically speaking no \nmatter how flawed, represents foremost an admission of the importance of epistemology beyond mere discourse in democracy.\n56 \n \nToo High? , D \u00c9MOS  (Mar. 4, 2013), https://www.demos.org/ blog/are-taxes-rich-too-high (\u201cThe big \nproblem today is that not the rich are overtax ed, but that everyone else is undertaxed.\u201d). \n 48. See  THOMAS PIKETTY , CAPITAL IN THE TWENTY -FIRST CENTURY  175 n.4 (Harv. U. Press \n2014). \n 49. Amazeen et al., Correcting Misperceptions, supra  note 45, at 29; see Amazeen, Revisiting the \nEpistemology, supra note 12, at 6. \n 50. See  Amazeen , Revisiting the Epistemology, supra note 12, at 8. \n 51. Amazeen et al., Correcting Misperceptions, supra  note 45, at 42, 44. \n 52. See  Andrew Tompkins, Fact-Checking Under Challengi ng Conditions: Problems With \nTechnology, Resources, Conflict, and Repression , DW  AKADEMIE  (July 17, 2020), https://www.dw.com/ \nen/fact-checking-under-challenging-conditions-problems-with-technology-resources-conflict-and-\nrepression/a-54012616. \n 53. See  Uscinski & Butler, supra  note 22, at 162. \n 54. See  Tompkins, supra note 52. \n 55. R ICHARD RORTY , PHILOSOPHY AND THE MIRROR OF NATURE  134 (1979); see also Gaines et \nal., supra  note 7, at 957; \u00c9tienne Brown, Propaganda, Misinformation, and the Epistemic Value of \nDemocracy , 30 C RITICAL REV. 194, 196 (2019). \n 56. For further background to this philosophical question see J\u00fcrgen Habermas, Richard Rorty\u2019s \nPragmatic Turn , in RORTY AND HIS CRITICS  31, 49 (Blackwell Publishing 2000). \n7Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n8 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nI. F ACTS IN THE TAX CONTEXT  \nThe field of taxation serves as a ready case study for problems in the \nepistemology of fact checking.  A litany of organizations currently originate \nand uncover supposed tax facts, including various websites such as the Tax Policy Center\n57 and the Tax Foundation,58 which are often cited by \njournalists.59  Many of the given facts are numeric, such as tax rates or other \nstatistics, which are taken to be observable realities or truths in deference to Kelvin\u2019s Dictum.\n60  However, extrapolations are often taken from the data to \nreach conclusions reflecting the correspondence theory of truth.61  T h i s  \ncorrespondence understanding of truth applies the philosophical terminology that can be understood in lay terms as finger pointing, for example, a person \npointing a finger at a goose and proclaiming: \u201cHey there is a goose over \nthere!\u201d  Truth or falsity is determined simply then by whether other people look and see a goose in the indicated direction.  In the tax context, the correspondence theory is applied wh ere the politician points a finger and \nproclaims: \u201cHey there is high taxes over there!\u201d\n62  Epistemological problems \noften arise in the political arena even with such basic methods.63 \nA correspondence theory of truth h as been referenced nonetheless as a \npossible epistemology of fact checking.64  Such a theory was proposed at least \npartly in response to scholarly critiques of fact checking of opinion statements, future events, and other matters not in the nature of facts.\n65  \nAlthough fact originators often publish a description of their respective \nprocesses to address these concerns, met hods may be idiosyncratic, resulting \nin the potential for disagreements wh en applying the correspondence theory \nof truth.66  A disagreement over facts thus yields competing truth claims that \n \n 57. The Tax Policy Center is rated as le ft leaning in its fact check results.  Tax Pol\u2019y Center , MEDIA \nBIAS FACT CHECK , https://mediabiasfactcheck.com/tax-policy- center/ (last updated Nov. 10, 2021).  \n(\u201cOverall, we rate the Tax Policy Center least biased in research and left-center biased as a whole, based \non a blog that favors left-leaning policy issues.  Th is source is also high in factual reporting.\u201d). \n 58. The Tax Foundation is rated as right leaning in its fact check results.  Tax Found. , MEDIA BIAS \nFACT CHECK , https://mediabiasfactcheck.com/tax-foundation/ (last updated Oct. 8, 2022) (\u201cOverall, we \nrate the Tax Foundation Right-Center biased based on advocating for Libertaria n economic policy.  We \nalso rate them Mostly Factual in reporting due to a few half-true claims, despite  proper sourcing and neutral \nwording.\u201d). \n 59. The Tax Foundation even publishes a list of \u201cfacts\u201d for citation by journalists.  See Tax Facts \nfor Journalists (and Taxpayers) , TAX FOUND . (Apr. 11, 2012), https://taxfou ndation.org/press-release/tax-\nfacts-journalists-and-taxpayers/.  60. William Thomson, Electrical Units of Measurement , in\n POPULAR LECTURES AND ADDRESSES  \n73 (London, MacMillan and Co. 1889).  61. Graves, Anatomy of a Fact Check, supra note 2, at 520. \n 62. Id. \n 63. Id. \n 64. Id . at 520. \n 65. See Uscinski & Butler, supra note 22, at 168-70. \n 66. See, e.g.,  D\nR. BRET N. BOGENSCHNEIDER , HOW AMERICA WAS TRICKED ON TAX POLICY : \nSECRETS AND UNDISCLOSED PRACTICES  63 (2020) [hereinafter B OGENSCHNEIDER , SECRETS ]. \n8Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  9 \ncan be debated by politic ians in parallel tracks.67  A correspondence approach \nto journalistic fact checking might be  seen as appealing to identify specific \nfacts where it is possible to independently verify68\u2013 typically in the context \nof finance \u201cverification\u201d means to count something, such as tax dollars.69  \nWhere the fact checker claims to do so mething independently this is usually \nto count something where both compe ting perspectives and paradigms agree \nthe item should be counted.70  For example, both Republicans and Democrats \nwould want to know the amount of tax dollars collected under current law \neven if they have different ideas of what the law ought to be.71 \nYet, despite its potential, the corr espondence idea of truth simply does \nnot seem to function very well in the tax context.72  The same Federal tax data \noften engenders situations where even a simple number, such as a tax rate \ntaken from a tax statute, may be reasonably seen as in dispute.73  That is to \nsay, we often cannot agree on counting methods to determine how much tax \nhas been collected where one organization uses a cash method, and another uses a special method to first count cas h, and then make subtractions for \nfuture benefits that might be received, or additions for taxes paid by \ncorporations on behalf of sharehol ders \u2013 indeed, this is how the \nCongressional Budget Office actually calculates tax rates.\n74 \nMerpert referenced four of these types of categories comprised of factual \nclaims that are candidates for fact checking by a correspondence or similar \nmethod: (1) historical data, (2) comparisons, (3) legality, and (4) statistical.75  \nIllustrations can be presented, however, wherein each of these categories the correspondence theory may not suffice as a workable epistemology in the tax \ncontext.  In respect of historical tax data, an epistemological problem relates \nto cherry-picking favorable tax data to support a policy position.\n76  Since most \npeople do not have a working knowledge of the tax system in current or \nprevious eras, the non-comparative hi storical references would be of \nmarginal value in political discourse where the tax rate was high or low and \n \n 67. See  Uscinski & Butler, supra  note 22, at 163. \n 68. See  Alfred Hermida, Tweets and Truth: Journalism as a Discipline of Collaborative \nVeri \ufb01cation , 6 J OURNALISM PRAC. 659, 661 (2012). \n 69. See BOGENSCHNEIDER , SECRETS , supra  note 66, at 104-06. \n 70. See Graves, Anatomy of a Fact Check, supra note 2, at 522-23. \n 71. See  BOGENSCHNEIDER , SECRETS , supra  note 66, at 10. \n 72. Id. at 161; Graves, Anatomy of a Fact Check, supra  note 2, at 520. \n 73. See id. at 14-15. \n 74. B OGENSCHNEIDER , SECRETS , supra  note 66, at 104-05, 109 (\u201cHence, where a philosopher or \npolitician proposes that a tax policy is \u2018just\u2019 or \u2018f air\u2019 by applying a cash-basi s method of accounting for \none group of taxpayers, a nd an accrual-basis method of accounti ng for another group of taxpayers, the \nsupposedly \u2018philosophical\u2019 conclusions  are a type of rhetoric or political gamesmanship generally \ncomprising a means to fool the innocent and take their money.\u201d). \n 75. A. Merpert et al., Is That Even Checkable? An Experi mental Study in Identifying Checkable \nStatements in Political Discourse , 35 C OMM . RES. REP. 48, 49 (2018). \n 76. See BOGENSCHNEIDER , SECRETS , supra  note 66, at 10-11. \n9Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n10 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \neconomic growth did or did not occur.77  As to comparisons and statistical \ndata, in the period leading up to the p assage of the Tax Cuts and Jobs Act of \n2017,78 corporate tax rates were simultaneously described as both high and \nlow by different organizations.79  The Council on Foreign Relations reported \nthe statutory tax rate of 35% was relatively high compared to other nations \nand tax cuts were needed to spur corporate activity.80  The Brookings \nInstitution later determined that the tax predictions used to formulate the law \nhad not come to fruition especially in relation to corporate taxes.81 \nThe legality of tax avoidance planning  reflects perhaps one of the most \ndebated issues within tax scholarship: whether tax laws should be presumed \nto be objectively determinate with th e same interpretation of the meaning of \nthe words and whether taxpayers who avoid taxes are doing so legally or not.\n82  Since most tax planning is designed to exploit the indeterminacy of \ninterpretation, many tax practitioners pr esume that tax law is indeterminate.83  \nTherefore, it would be possible for large corporations to avoid most or all taxes legally by exploiting the indeterminacy of laws.\n84  Thus, in addition to \nproblems with statistics and comparisons, in many cases legality in the tax \ncontext would not be objectively determinate.85 \nII. P ROBLEMS WITH FACT CHECKING IN THE TAX CONTEXT  \nNearly all fact checking is subject to a critique taken from the philosophy \nof science that insofar as the fact check er must always adopt an underlying \ntheory or paradigm to whic h the supposed \u201cfact\u201d relates.86  In tax discourse, \nfacts are given in reference to a causal theory and rarely in regard to  \n 77. Merpert et al., supra  note 75, at 49. \n 78. See generally H.R.  REP. No. 115-97 (2017). \n 79. U.S. Corp. Tax Reform , C OUNCIL ON FOREIGN RELS., https://web.archive.org/web/ \n20181223000141/https://www.cfr.org/b ackgrounder/us-corporate-tax-refo rm (last updated Nov. 3, 2017). \n 80. See id. \n 81. William G. Gale, Did the 2017 Tax Cut\u2014The Tax Cuts and Jobs Act\u2014Pay for Itself?, \nBROOKINGS INST. (Feb. 14, 2020), https://www.brookings.edu/policy2020/votervital/did-the-2017-tax-\ncut-the-tax-cuts-and-jobs-act-pay-for-itself/. \nBefore and after passage of the Tax Cuts  and Jobs Act (TCJA), several prominent \nconservatives, including Republicans in the House and Senate, former Reagan economist Art \nLaffer, and members of the Trump administration,  claimed that the act would either increase \nrevenues or at least pay for itself.  In principl e, a tax cut could \u201cpay for itself\u201d if it spurred \nsubstantial economic growth\u2014if tax revenues rose from the combination of higher wages and hours worked, greater investment returns, and la rger corporate profits.  The TCJA, however, is \nnot that tax cut. \n 82. See  Mark Burton, Responsive Regulation and the Uncertainty of Tax Law - Time to Reconsider \nthe Commissioner\u2019s Model of Cooperative Compliance? , 5 \nEJOURNAL TAX RES. 71, 72 (2007). \n 83. Id. at 73. \n 84. Id. at 73, 82. \n 85. Id. at 73. \n 86. See Amazeen, Revisiting the Epistemology, supra note 12, at  4. \n10Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  11 \nindependent observations despite what h as been previously suggested in other \nscholarship on the epistemol ogy of fact checking processes.87  The critique \nrepresents a difference in the understand ing of science that evolved between \nthe seventeenth and twentieth centuries  where fact checking has at times \nreverted back to the seven teenth-century approach.88  The more modern view \nof science originating with Karl Popper  is that facts arise from theory, and \nnot vice versa.89  Popper explained as follows: \n[T]he theoretician must long before  [experimentation] have done his \nwork, or at least what is the most important part of his work: he must \nhave formulated his question as sharply as possible.  Thus it is he who shows the experimenter the way.  But even the experimenter is \nnot in the main engaged in making exact observations; his work, too, \nis largely of a theoretical kind.  Theory dominates the experimental work from its initial planning up to the finishing touches in the laboratory.\n90 \nIllustrations of many epistemic problem s can be readily identified in tax \ndiscourse, ranging from skepticism to relativism,91 positive to realist, \nreligious to secular.92  Tax policy is accordingly a minefield for epistemology \nbecause of the idea that tax figures or  numbers are give n independent of \ntheory.93  The tax policy landscape is also  littered with paradoxes, where \nempirical results conflict with theoretical predictions, such as the supposed migration of wealthy persons or corpor ations away from higher taxes appears \nto happen in reverse, where the wealthy migrate toward higher-tax jurisdictions and not away.\n94  Even though the idea of mobile capital is widely \nheld as universal truth in lay circles, there is little to no empirical evidence for it as nearly all large corporations operate in high-tax jurisdictions by \nchoice.\n95  Also widespread is the cherry -picking of supposed facts in support \nof a preferred tax policy, with perh aps the foremost illu stration being the \ncounting of only income tax receipts pa id by the wealthy rather than income, \nwage and other taxes paid by working taxpayers.96 \n \n 87. Id. at 3. \n 88. See POPPER , supra note 15, at 3-4. \n 89. Id. at 1. \n 90. Id. at 90. \n 91. Jeffrey Schoenblum, Tax Fairness or Unfairness? A Consideration of the Philosophical Bases \nfor Unequal Taxation of Individuals , 12 A M. J. TAX POL\u2019Y 221, 228 (1995). \n 92. See POPPER , supra  note 15, at 94. \n 93. See BOGENSCHNEIDER , SECRETS , supra note 66, at 4, 60. \n 94. See id. at 8-10, 34. \n 95. Id. at 17. \n 96. Id. at 10-11. \n11Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n12 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nIn the tax context, facts are usually not empirical observations where a \njournalist can point a finger to a number  as an objective statement of fact and \nanyone else might be expected to agree.97  The number itself will nearly \nalways reflect interpretations of what th e observer sets out to look for, or even \nwhat the originator of the number chose to count as an observation.98  The \nprocess of fact checking may, at times, even reflect the concealment of a \ncompeting theory to which comp eting facts have been proposed.99  Thus, fact \ncheckers face additional unique epistemo logical problems in the tax context, \nseveral of which are detailed below.100 \nA. Fact Checking of Non-Causal Ideology \nA prominent critique of the epistemo logy of fact checking by Uscinski \nand Butler challenged the ability to  fact check a causal theory.101  Of course, \na causal prediction technically may not be fact checked, yet the critique is \ncounterintuitive because it reverses the colloquial usage of terms.102  I n  \ncolloquial speech, scientific knowledge of  causation is often referred to as \nfactual.  For example, the scientific theory of gravity is taken as fact and a journalist could indeed be expected to  fact check a politician who denied the \ntheory of gravity.  A disagreement could even result in that simple context if \nthe politician was referring to gravity in relation to general relativity, rather than gravity on the surface of the Earth.\n103  In reality, the proposed \ndemarcation between facts and causation drawn by Uscinski and Butler is not \na significant epistemological issue be cause facts are used within causal \nparadigms.104  Rather, the primary epistemol ogical concern in fact checking \nis in respect of the supposed evalua tion of non-facts by fact checking ideas \nthat are completely non-causal, such as superstitious beliefs.105  The fact \nchecking of a superstitious belief woul d be, for example, if a journalist \nattempted to fact check a claim by a politician to have been chosen by God \nto lead. \nA similar illustration of fact checking was developed by Graves in respect \nof a claim made by Glenn Beck: \u201c[The Muslim Brotherhood] want[s] to declare war on Israel.\u201d\n106  Ultimately, PolitiFact adjudicated the claim false \n \n 97. Id. at 4. \n 98. See  Uscinski & Butler, supra  note 22, at 177. \n 99. See  id. at 167-68. \n 100. See infra  Sections II.A-D. \n 101. Uscinski & Butler, supra  note 22, at 169. \n 102. See  id. \n 103. See  id. \n 104. See  id. \n 105. See BOGENSCHNEIDER , SECRETS , supra  note 66, at 32-33. \n 106. See  Graves, Anatomy of a Fact Check, supra note 2, at 524. \n12Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  13 \nbut after significant dispute.107  The trouble is that the claim relates foremost \nto ideology, similar to the problem e xplained in the preceding paragraph, and \nis not a \u201cfact\u201d in the sense of a fact within a causal paradigm.108  A n  \nappropriate response to Graves then is that PolitiFact appears to fact check \nclaims that are not in the nature of facts.109  PolitiFact found Beck\u2019s claim to \nbe false, or in other words, not a \u201cfact\u201d.110  However, in epistemological \nterms, the ideological claim was really a \u201cnothing\u201d as it did not relate to any causal hypothesis and should not have been investigated at all.\n111  The issue \nof evaluating mental states as \u201cscience \u201d was debated within the philosophy \nof science throughout the eighteenth and nineteenth centuries.  The epistemological problem was not addressed  in regards to the Beck statement \nonly because the nothing claim was found to  be \u201cfalse\u201d so therefore found to \nbe not true.\n112  If the claim had been found to be true or confirmed, then the \nepistemological problem: what was set out to be checked was really a \u201cnothing\u201d, may have been evident even to journalists. Absent some epistemology that is able to disti nguish superstition from modern science \nalong the lines of Popper, fact checking runs the risk of formally reviving \nnineteenth-century Viennese debates over doctrinal skepticism that are \nbeyond the scope of this paper.\n113  For this reason, PolitiFact and other fact \nchecking organizations may need to cr eate a new category of non-verifiable \nclaims that are not subject to fact checking. The category of non-verifiable claims may indeed include a substantial portion or perhaps even the majority \nof politicians\u2019 statements.  A possible vagueness critique of a politician could \nbe that he or she simply does not make any factual claims or statements that can be checked for accuracy. \n \n 107. Lucas Graves, Glenn Beck Says Muslim Brotherhoo d Wants to Declare War on Israel , \nPOLITI FACT (Feb. 15, 2011), https://www.politifact.com/fac tchecks/2011/feb/15/gl enn-beck/glenn-beck-\nsays-muslim-brotherhood-wants-declare-w/ [hereinafter Graves, Muslim Brotherhood ]. \n 108. Id . \n 109. See  Graves, Anatomy of a Fact Check, supra note 2, at 524, 529. \n 110. As a matter of Popperian science, causal hypothese s are tested using evidence.  It is the theory \nof causation which may be found to be false.  Facts ar e criteria within the theory from which the hypothesis \narises.  The testing of the hypothesis may involve the measurement of the criteria within that theoretical \nparadigm.  The colloquial or lay understanding of science differs from this approach where the accepted \ncausal hypothesis, such as the theory of gravity, are them selves taken as facts.  This leads to the oft-given \nassertion of confirming the hypothesis by testing.  Howe ver, a base tenant of P opperian science is that \nhypotheses are always tentative so that there is no form al confirmation just consistent results for the time \nbeing until a better causal theory is cr eated.  In the illustration of the th eory of gravity, Newtonian physics \nonly works at the Earth\u2019s surface, so the theo ry is not confirmed away from Earth.  See POPPER , supra \nnote 15, at 38-40; Graves, Muslim Brotherhood, supra note 107. \n 111. See  Uscinski & Butler, supra  note 22, at 166, 169. \n 112. See  Graves, Muslim Brotherhood, supra note 107. \n 113. See generally P OPPER , supra  note 15. \n13Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n14 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nB. Resurrection of Dead Theories \nMuch of the epistemological debate regarding fact checking, both for and \nagainst, seem to be an analysis of questions that were addressed by Popper \nand others a century ago in response to doctrinal skepticism.114  Perhaps most \nsignificant, in the tax context, \u201cfacts\u201d are rarely given independently of an \nunderlying theory.115  As an illustration, imagine that a journalist engaged in \nfact checking on tax policy finds the Laffer Curve theory and reasonably \ndetermines it to comprise a novel consensu s of truth by checking a wide range \nof tax policy organization websites.  This  is indeed a plausible outcome for a \njournalist conducting a first review of the Laffer Curve not having encountered the idea before, as a comprehensive internet search could yield \na number of advocacy organizations such  as the Tax Foundation that cite to \nthe Laffer Curve to support their assertion that tax cuts will yield higher tax \nreceipts.\n116  Assume further that the jour nalist is not aware of empirical \nevidence to the contrary.  The fact checker could then develop and check \n\u201cfacts\u201d related to the Laffer Curve, such as concluding that it is true that tax \ncuts will yield more tax revenue \u2013 an idea that nearly all tax experts believe \nto be false.117  The journalist has in that case followed the journalistic \nmethodology of fact checking to the le tter and yet determined that false \ninformation is true by proceeding with the consensus approach.  This problem \noccurs because the fact checker has no t been trained in the field and is \nreviewing non-scientific sources that apply a consensus methodology only.118 \nA significant problem in fact checking is that some claims may be \nreasonably thought to comprise a consensus truth if there is no asterisk placed \non the disproven theory, as required as a condition of science or scientific methods.\n119  In a university context, for example, a professor presenting the \nLaffer Curve might be expected to add a qualifier such as, \u201cwe do not really \nknow whether our society is on the point of the \u2018curve\u2019 where a reduction in tax rates might yield higher receipts\u201d or \u201csome scholars think that raising tax rates would yield higher tax receipts.\u201d  A reasonable conclusion then is that in some fields, particularly taxation, where disproven theories are continuously re-introduced into the poli tical process, that fact checking could \nresult in the re-introduction of disprove n theories.  Alternately, the fact \ncheckers would need to be themselv es checked by someone with technical \n \n 114. See Graves, Anatomy of a Fact Check, supra  note 2, at 520-21. \n 115. But see  id. at 520. \n 116. See, e.g.,  Alex Durante, Reviewing Recent Evidence of the Effect of Taxes on Economic \nGrowth , TAX FOUND . (May 21, 2021), https://ta xfoundation.org/ reviewing-recent-evid ence-effect-taxes-\neconomic-growth/. \n 117. See  Gravelle , Comparisons , supra  note 24, at 16. \n 118. See Graves, Anatomy of a Fact Check, supra note 2, at 522. \n 119. See generally infra Section II.C. \n14Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  15 \nknowledge in the field once a hidden consensus view was thought to have \nbeen identified.120  A process of checking with an expert seems to be a better \ndescription of the fact checking pro cesses that many journalists currently \napply in reporting on tax policy claims.121  The fact checking methodology \ncurrently depends significantly on the ability of the journalist to determine \nwho is an expert in the field of taxation and tax policy in order to check for \nconsensus views.122 \nC. Limits of Bayesian Science \nIn Bayesian science, the consensus views of scientists constitute science \nproper.123  Fact checkers are broadly engaged in the checking of factual \nclaims to correspond to these consensus views of scientists.124  However, one \nlimitation of Bayesian science is the situation where scientists disagree on the \nproper interpretation of data.125  The fact checker then must evaluate dueling \nviews of multiple persons labele d \u201cscientists\u201d to determine which \ninterpretation should be considered in the nature of truth.126  In that case, fact \ncheckers take on the role of an actual scientist working in the field \u2013 to become familiar with the accumulated knowledge of mankind in that \nparticular field, evaluate the data, and to communicate it to others.\n127  \nRigorous study of the academic literature  on a given topic, typically as part \nof a PhD program, facilitates the ability of a person to identify and draw out \nlegitimate and consensus views of scientist s.  As a result, the practical import \nof fact checking is that persons engaged in fact checking are essentially \nperforming one of the primary roles of Bayesian scientists without actual \ntraining in the field of study.128 \nFurthermore, the views of tax experts may not, at the time of fact \nchecking review, have coalesced into a c onsensus that might be identified and \nmediated to the public in Bayesian terms.129  The Laffer Curve illustration is \naccordingly a significant challenge for Bayesians, including fact checkers \nacting in part as Bayesian scientists w ithout formal training, because a wide \ngroup of adherents continue to advan ce an idea that has been checked and \n \n 120. See Graves, Anatomy of a Fact Check, supra  note 2, at 527. \n 121. Id. \n 122. Id. \n 123. See John G. Bullock, Partisan Bias and the Bayesian Ideal in the Study of Public Opinion , 71 \nJ. POL. 1109 (2009). \n 124. Graves, Anatomy of a Fact Check, supra note 2, at 527. \n 125. See generally id.  \n 126. See  Petter Bae Brandtzaeg et al., How Journalists and Social Media Users Perceive Online \nFact-Checking and Verification Services , 12 J OURNALISM PRAC. 1109, 1122 (2018). \n 127. See Graves, Anatomy of a Fact Check, supra  note 2, at 527. \n 128. Id. \n 129. See id.; Bullock, supra note 123, at 1110. \n15Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n16 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nshown not to be true.130  Of course, fact checking as an extension of Bayesian \nscience has significant appeal in well-de veloped fields with relatively clear \nconsensus views.  A lack of evidence c ould also be identified by fact checkers \nas an indication of falsehood where the evidence is simply unavailable.  The \nappeal of Bayesian science is thus mitig ated in fields such as taxation where \ncausal relations are in significant dispute.131 \nAlthough fact checking has proceeded la rgely in Bayesian terms, it could \nproceed also in Popperian terms wher e the fact checker could review a \nstatement to see if it has been shown to be false .132  In Popperian science, the \noutright falsification of a theory by ev idence can be seen as a matter of degree \nbut still may be applied as a means to introduce a new and different scientific \ntheory.133  A scientific process entails the substitution of the old idea \nrepresented by the Laffer Curve thought to  be false by a new idea; here, the \nnew idea would be that higher tax recei pts would be obtained at reasonably \nhigher tax rates.134  The substitution is in effect what Popper referred to in his \nbook as a process of scientific \u201cdiscovery\u201d, with emphasis on the word \ndiscovery.135  Such a Popper falsity revi ew does not necessarily require \nadvanced knowledge of the field of study which a journalist might not be \nexpected to possess.136  Hence, Popperian science encourages and allows for \nthe development of new scientific ideas.137  The testing of theory by \nfalsification accordingly has signi ficant appeal as a fact-checking \nmethodology in that many ideas about taxa tion could be immediately falsified \nwith the introduction of evidence.138 \nD. Post Truth Concerns \nPerhaps the most well-known instance of fact checking in recent times \nrelates to the concept of epistemological \u201cpost truth\u201d.139  One example is, of \ncourse, President Trump\u2019s claim that he could not reveal his tax returns \nbecause he was under IRS audit.140  Such a claim is false from the paradigm \n \n 130. See Gravelle , Comparisons, supra  note 24, at 16. \n 131. Uscinski & Butler, supra  note 22, at 168-69. \n 132. P OPPER , supra  note 15, at 90. \n 133. See  id. at 278. \n 134. Id.; B OGENSCHNEIDER , SECRETS , supra  note 66, at 32. \n 135. P OPPER , supra  note 15, at 32. \n 136. See  id. at 7. \n 137. Id. \n 138. See id. at 274. \n 139. Pablo Capilla, Post-Truth as a Mutation of Epistemology in Journalism , 9 M EDIA & COMM . \n313, 314 (2021). \n 140. Martin Pengelly, Trump Made Up Audit Excuse for Not Releasing Tax Returns on Fly, Book \nSays, G UARDIAN  (Sep. 30, 2022), https://www.theguardian. com/books/2022/sep/ 30/trump-audit-tax-\nreturns-plane-chris-christie-maggie-haberman-book. \n16Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  17 \nof the professional tax community where there is no such rule.141  From the \nperspective of epistemology proper, the claim is technically non-verifiable \nbecause it relates to a rabbit hole paradi gm that Trump posited where he had \nbeen supposedly advised by his tax lawyer there was such a consideration or rule toward non-disclosure of tax returns whilst under audit.\n142  If a tax lawyer \nhad advised Trump of such a rule, that advisement would be legally \nprivileged information unless Trump\u2019s statements constituted a waiver of the \nprivilege.  So, the reference is in theory completely uncheckable if the lawyer\u2019s privileged advice cannot be di sclosed pursuant to the attorney-client \nprivilege.  The politician has effectively po sited an alternate paradigm of truth \nby referencing something known not to be checkable.\n143 \nIn a democracy, the more often a polit ician is revealed not to share an \nagreed paradigm with the voters, the less relatable and electable that person might appear to be.  On the other hand,  with respect to Trump\u2019s tax returns, \nvarious newspapers and ot her journalistic organizati ons strongly implied the \nreturns might contain evidence of tax fraud or other criminal behavior.\n144  For \nvarious reasons, this represents a potentia l \u201cpost truth\u201d turn in fact checking \nas well by the journalists themselves.145  As Capilla explained: \u201cThe [post \ntruth] hypothesis is that, if the news me dia were to spread different types of \nreality, it would be impossible to establish a single epistemological justification, and doubts might even be cast about the very idea of verifying facts.\u201d\n146 \nOne probable reason for Trump\u2019s refusal to disclose his tax returns was \nthat such returns would have repor ted very little, possibly zero, taxable \nincome; this could imply that Trump w as not very good at business, one of \nthe primary tenants of his campaign.147  Any professional tax expert should \nhave been able to identify that Trum p was in the real estate business where \ntax liability can usually or often be avoided partially or entirely.148  \n \n 141. Kevin McCoy & David Jackson, IRS: Trump Can Release Tax Returns, Regardless of Audit , \nUSA  TODAY  (Feb. 26, 2016, 3:29 PM), https://www.usa today.com/story/news/ politics/onpolitics/2016/02 \n/26/donald-trump-internal-re venue-service-audits/80996086/. \n 142. Pengelly, supra  note 140. \n 143. See generally Brendan Nyhan & Jason Rei \ufb02er, When Corrections Fail: The Persistence of \nPolitical Misperceptions, 32 P OL. BEHAV . 303 (2010). \n 144. See Elie Mystal, Trump is Either a Tax Fraud or the World\u2019s Worst Businessman , WASH. POST \n(Sept. 28, 2020, 10:43 AM), h ttps://www.washingtonpost.com/ou tlook/2020/09/28/trump-taxes-fraud-\nbusiness-failure/. \n 145. Capilla,  supra note 139, at 314. \n 146. Id. \n 147. See Mystal, supra note 144. \n 148. Max Ehrenfreund, How Donald Trump and Other Real-Est ate Developers Pay Almost Nothing \nin Taxes, WASH. POST (Oct. 4, 2016, 6:11 AM), https://www.wa shingtonpost.com/news/wonk/wp/2016/ \n10/04/how-donald-trump-and-other-real -estate-developers-pay-almost-nothing-in-taxes/ (\u201cThe average \nfirm in real estate development pays just over 1 percen t of its income in taxes, according to data compiled \n17Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n18 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nAccordingly, journalists engaged in  fact checking probably should have \ndiscovered this and expected the tax returns not to report significant amounts \nof taxable income.  The Trump tax returns comprise a prime illustration of the counterintuitive nature of tax policy where extremely wealthy people often do not pay taxes.\n149  The lack of agreement on a proper interpretation \nof data, such as the refusal to release a tax return, leads to a significant issue \nwithin fact checking - verifying interpre tational results or perhaps even rating \nsuch claims on a scale of truthfulness.150  The fact checking process \nnonetheless at times appears to be the favoring of one interpretive position over another.\n151 \nCONCLUSION  \nWhereas Karl Popper referred to a Logic of Scientific Discovery , the \njournalistic process of fact checking could instead be called a methodology for the discovery of lay ideas.\n152  In epistemological terms, fact checking is \nthe communication of ideas from one layperson to another.153  At first blush, \nthis may seem to be the triumph of Richard Rorty\u2019s view that discourse within a democracy preempts all epistemology.\n154  Perhaps causal relations widely \nknown in tax or similar circles are never really to be known by the democratic electorate.  Lay knowledge of tax policy might then be known by trial and error only.  This would mean that lay persons, or the democracy itself, simply \nlearned from their mistakes over time rather than setting out to make causal predictions in the future, as scientists and other scholars normally set out to \ndo.  In this sense, science is actually knowing the results of experiments by \nmeans superior to trial and error. \nHowever, fact checking seems to be overall helpful for democratic \nprocesses, and not harmful as some scholars have worried.\n155  This is because \nthe wider dissemination of both correct and incorrect ideas about causation, \nsuch as in respect of tax policy, expands human knowledge with little \ndownside from the dissemination of some wrong ideas however frustrating it \n \nby Aswath Damodaran, a professor at New York Un iversity.  The average fo r all the industries in \nDamodaran\u2019s database is almost 11 percent.\u201d). \n 149. Id. \n 150. See  Amazeen et al., Correcting Misperceptions, supra  note 45, at  31. \n 151. See  Kelly Riddell, Eight Examples Where \u2018Fact-Checking\u2019 Became Opinion Journalism , \nWASH. TIMES (Sept. 26, 2016), https://www.washington times.com/news/2016/sep/26/eight-examples-\nwhere-fact-checki ng-became-opinion-/. \n 152. P OPPER , supra  note 15, at 32. \n 153. See Amazeen, Revisiting the Epistemology,  supra  note 12, at 3, 4. \n 154. Riddell, supra  note 151; Jennifer Jerit & Jason Barabas, Bankrupt Rhetoric: How Misleading \nInformation Affects Knowle dge about Social Security, 70 P UB. OPINION Q. 278, 296 (2006); see also \nUscinski & Butler, supra  note 22, at 169. \n 155. See  Amazeen, Revisiting the Epistemology, supra  note 12, at 16. \n18Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1\n2022] POLITICAL FACT CHECKING IN THE TAX CONTEXT  19 \nmay be to experts in the field.156  Uscinski\u2019s excellent epistemological \ncritique, may represent in part, a false nostalgia for a past time where \nepistemology formed the basis for political discourse for all inhabitants of a \nsmall village, and truths we re known to all concerned. 157  An appropriate \nresponse to Uscinski is simply that, ev en if some ideas are incorrect or wrong \nin political discourse, that does not r estrain scientific progress significantly \nbecause scientists themselves are not obliged to follow wrong ideas.  The \ndemocracy seems to increasingly look to scientists for truth even if the lay \npublic does not know what that means .158  It is not necessary for scientific \ndiscovery and advancement that the laypersons comprising the democratic \nelectorate know the definition of truth.159  In the tax policy context, recent \nevents indicate that disproven tax id eas have been rejected by policymakers \naround the world, and the international race to the bottom on corporate tax \nrates has been curtailed.160 \nIn defense of fact checking pro cesses, Graves has carefully documented \nand described the methods applied at  PolitiFact, a leading fact checking \norganization.161  The methods reveal that journalists most often intend to \ncheck facts fairly in an e ffort to reveal the truth.162  However, the results of \nGraves\u2019 investigation reflect a near co mplete discretion for journalists to \ndetermine which fact claims are to be checked or not.163  Disturbingly, Graves \nalso notes confusion by the general public about misperceptions of the non-scientific processes applied in fact checking.\n164  The general public often \nholds a colloquial view of science as the collation of facts.165  T h i s  v i e w  \nwould understand fact checking as checking for the correspondence of political claims to a codex of gathered facts \u2013 essentially the sixteenth-century view of science.\n166  Fact checkers, including journalists, often apply a \nBayesian version of science, as explaine d above, as they see that a codex does \nnot exist and that checking with books is not a workable approach for many factual investigations.\n167 \n \n 156. See Uscinski & Butler, supra  note 22, at 168-69. \n 157. Id. at 163. \n 158. See Uscinski, Rejoinder to Amazeen, supra note 22, at 249-50. \n 159. See supra Section II.C. \n 160. David Milliken et al., G7 Finance Ministers Agree Global Minimum Tax of at Least 15%,  \nREUTERS  (June 7, 2021, 3:28 PM), http s://www.reuters.com/business/g7-fi nance-ministers-agree-global-\nminimum-tax-least-15-2021-06-05/. \n 161. See  Graves, Anatomy of a Fact Check, supra note 2, at 523. \n 162. Amazeen, Revisiting the Epistemology, supra note 12, at 17-18. \n 163. Graves,  Anatomy of a Fact Check, supra  note 2, at 524. \n 164. See  id. at 520. \n 165. Id. \n 166. See generally id. \n 167. See  supra Section II.C. \n19Bogenschneider: Political Fact Checking in the Tax Context\nPublished by DigitalCommons@ONU,\n20 OHIO NORTHERN UNIVERSITY LAW REVIEW  [Vol. 49 \nThe potential for disingenuous checking of supposed facts is also a \nconcern of significant import to fact checking processes, where a journalist \nmay take a partisan position in the political process, thus creating a charge of partisan bias.\n168  Such concerns over partisanship may be especially \npronounced in the context of tax policy.169  Contrary to the conclusion of \nUscinski and Butler, tax facts exist within causal paradigms so fact checking \ndoes take place in respect of causation. 170   The most pervasive \nepistemological problem for fact checkers is the fact checking of non-facts, or nothings, such as superstitious beliefs. \nGuarded optimism seems appropriate as journalism, broadly speaking, \naids social science as it functions by analogy as a microphone.\n171  Any \nreporting of science or facts relevant to causal relations, generally yields a net \nbenefit to science, if at the very least it engenders curiosity among the lay public.\n172  As an illustration, recently it was reported that the wealthiest \npersons in the United States do not pay mu ch in taxes on the basis of leaked \ntax returns, reflecting no more than 3.4% effective tax rate.173  T h a t  \ninformation is best viewed as a fact re lated to one or more causal theories of \ntaxation likely to be releva nt to political discourse.174  In order to understand \nthe significance of that information in political terms, and to communicate it \nto the public, journalists should be expected to follow the standard process of \nfact checking on Bayesian terms to reach a new consensus view.175  A s  \nexplained above, journalists would need then to distinguish the statutory tax \nrate of potentially 40.8% from the effective tax rate that is much less. 176  The \nnew facts may result in some updating of beliefs, countering misperceptions \nthat the wealthy pay more in taxes th an the data indicat es they actually do.177  \nThe good news is that the process of updating beliefs about  taxation and tax \npolicy based on new evidence constitutes rapid epistemological progress in \nhistorical terms, even if it feels slow. \n \n 168. Uscinski & Butler, supra note 22, at 168-69. \n 169. See Graves,  Anatomy of a Fact Check, supra note 2, at 527. \n 170. Uscinski & Butler, supra note 22, at 168, 170. \n 171. But see  Brown, supra note 55, at 198. \n 172. Amazeen, Revisiting the Epistemology, supra note 12, at 16. \n 173. See  Eisenger et al., supra  note 10. \n 174. See Uscinski & Butler, supra  note 22, at 168. \n 175. Amazeen, Revisiting the Epistemology, supra note 12, at 8-9. \n 176. History of Federal Income Tax Rates: 1913 \u2013 2022 , BRADFORD TAX INST., https://bradfordtax \ninstitute.com/Free_Resources/Federal-Income-T ax-Rates.aspx (last visited Oct. 1, 2022). \n 177. See  Scott A. Hodge, Testimony: Senate Budget Committee Hear ing on the Progressivity of the \nU.S. Tax Code , TAX FOUND . (Mar. 25, 2021), https://taxf oundation.org/rich-pay-thei r-fair-share-of-taxes/. \n20Ohio Northern University Law Review, Vol. 49 [], Iss. 1, Art. 1\nhttps://digitalcommons.onu.edu/onu_law_review/vol49/iss1/1", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Political Fact Checking in the Tax Context", "author": ["BN Bogenschneider"], "pub_year": "2022", "venue": "Ohio NUL Rev.", "abstract": "The origin and nature of facts has become an increasingly prominent topic in American  journalism and political discourse. 2 Fact checking functions in part as the evaluation of truth"}, "filled": false, "gsrank": 142, "pub_url": "https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/onulr49&section=5", "author_id": ["Jdy_baUAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:j-rORiVpdaoJ:scholar.google.com/&output=cite&scirp=141&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D140%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=j-rORiVpdaoJ&ei=HbWsaO33J7TWieoP1pCJ2AY&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:j-rORiVpdaoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://digitalcommons.onu.edu/cgi/viewcontent.cgi?article=1307&context=onu_law_review"}}]