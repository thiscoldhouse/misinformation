[{"title": "Resolving Conflicting Evidence in Automated Fact-Checking: A Study on Retrieval-Augmented LLMs", "year": "2025", "pdf_data": "arXiv:2505.17762v1  [cs.CL]  23 May 2025Resolving Conflicting Evidence in Automated Fact-Checking:\nA Study on Retrieval-Augmented LLMs\nZiyu Ge1\u2217,Yuhao Wu1\u2217,Daniel Wai Kit Chin1,Roy Ka-Wei Lee1and Rui Cao2\n1Singapore University of Technology and Design\n2University of Cambridge\n{ziyu ge, roy lee}@sutd.edu.sg, {yuhao wu, daniel chin}@mymail.sutd.edu.sg, rc990@cam.ac.uk\nAbstract\nLarge Language Models (LLMs) augmented with\nretrieval mechanisms have demonstrated signifi-\ncant potential in fact-checking tasks by integrat-\ning external knowledge. However, their reliabil-\nity decreases when confronted with conflicting ev-\nidence from sources of varying credibility. This\npaper presents the first systematic evaluation of\nRetrieval-Augmented Generation (RAG) models\nfor fact-checking in the presence of conflicting ev-\nidence. To support this study, we introduce CON-\nFACT (Conflicting Evidence for Fact-Checking)1,\na novel dataset comprising questions paired with\nconflicting information from various sources. Ex-\ntensive experiments reveal critical vulnerabilities\nin state-of-the-art RAG methods, particularly in\nresolving conflicts stemming from differences in\nmedia source credibility. To address these chal-\nlenges, we investigate strategies to integrate me-\ndia background information into both the retrieval\nand generation stages. Our results show that effec-\ntively incorporating source credibility significantly\nenhances the ability of RAG models to resolve con-\nflicting evidence and improve fact-checking perfor-\nmance.\n1 Introduction\nMotivation. Fact-checking systems are essential tools for\ncombating the spread of misinformation, as they help ver-\nify claims by retrieving and analyzing evidence from di-\nverse sources [Guo et al. , 2022; Nakov et al. , 2021 ]. Mod-\nern fact-checking pipelines increasingly rely on Retrieval-\nAugmented Generation (RAG) frameworks, which integrate\nexternal evidence into Large Language Models (LLMs) to\nverify claims [Lewis et al. , 2020; Guu et al. , 2020 ]. How-\never, a critical challenge arises when fact-checking systems\nencounter conflicting evidence \u2014that is, when retrieved docu-\nments present opposing stances on a claim, often originating\nfrom sources with varying levels of credibility [Guo et al. ,\n2022; Schlichtkrull, 2024; Hong et al. , 2024 ].\n\u2217These authors contributed equally.\n1Dataset available at https://github.com/zoeyyes/CONFACT\nClaim : Paul Pogba retire d from international football in response to \nFrench President Macron's comments on Islamist terrorism .\nDocument #1\n Document #2\nStance  #1: Refuted . Stance  #2: Supported .Figure 1: The retrieved documents from Google to verify the claim.\nThe retrieved documents from different media sources have different\nstances towards the claim.\nFor example, consider the claim: \u201c Paul Pogba retired\nfrom international football in response to French President\nMacron\u2019s comments on Islamist terrorism \u201d, the retrieved evi-\ndence might include conflicting documents, as shown in Fig-\nure 1, such as one from BBC2, a highly credible source,\nand another from Mehr News Agency3, which is flagged as\nuntrustworthy4. To fact-check this claim accurately, a fact-\nchecking system must not only analyze the evidence but also\nassess the credibility of each source\u2014prioritizing reliable in-\nformation while discounting less trustworthy content.\nThis challenge is exacerbated by the rapid proliferation of\nlow-credibility content and automated misinformation gen-\nerated by LLMs themselves [Chen and Shu, 2024; Wang et\nal., 2024a ]. Fact-checking in this context requires robust sys-\ntems capable of resolving conflicts in evidence while reason-\ning about source credibility\u2014capabilities that are currently\nunderexplored in fact-checking research.\n2https://www.bbc.co.uk/sport/football/54691842\n3https://en.mehrnews.com/news/165168/\nPogba-quits-intl-football-after-comments-from-Macron-report\n4https://mediabiasfactcheck.com/mehr-news-agency/\nResearch Objectives. Addressing these gaps, this paper fo-\ncuses on the problem of fact-checking with conflicting evi-\ndence , where retrieved documents present opposing stances\non a claim. Specifically, we aim to evaluate the ability of\nretrieval-augmented LLMs to identify, analyze, and resolve\nconflicts in evidence by determining which sources to trust\nfor claim verification. To enable this, we introduce CON-\nFACT (Conflicting Evidence for Fact-Checking), a novel\ndataset designed to systematically study this challenge. Each\ninstance in CONFACT comprises a claim paired with docu-\nments exhibiting conflicting stances, annotated with source\ncredibility ratings.\nWe conduct extensive experiments to evaluate state-of-the-\nart RAG models on CONFACT, revealing critical limitations\nin their ability to reason through conflicting evidence and\nprioritize trustworthy sources. Motivated by these findings,\nwe further explore strategies for incorporating media back-\nground information\u2014such as source metadata and credibility\nscores\u2014into both the retrieval and generation processes. Our\nresults demonstrate that effectively integrating source credi-\nbility enhances the robustness of retrieval-augmented LLMs\nin resolving conflicting evidence for fact-checking.\nContributions. In this work, we made the following con-\ntributions in this work:\n\u2022Dataset Creation : We introduce CONFACT , a novel\ndataset for studying fact-checking with conflicting evi-\ndence. The dataset includes claims paired with conflict-\ning retrieved documents, annotated with source credibil-\nity and stance labels to facilitate systematic evaluation.\n\u2022Performance Evaluation : We conduct a comprehen-\nsive evaluation of RAG-based LLMs on CONFACT ,\nrevealing critical vulnerabilities in resolving conflicting\nevidence and reasoning about source credibility.\n\u2022Methodological Innovations : We propose and evaluate\nmultiple strategies for integrating media background in-\nformation into RAG pipelines, demonstrating significant\nimprovements in fact-checking performance through ef-\nfective credibility-aware reasoning.\n2 Related Work\n2.1 RAG for Automated Fact-Checking\nAutomated fact-checking (AFC) has gained significant atten-\ntion in recent years [Guo et al. , 2022; Nakov et al. , 2021 ].\nWhile LLMs have demonstrated strong performance in vari-\nous Natural Language Understanding (NLU) tasks [Liet al. ,\n2023 ], they remain limited in AFC, as fact-checking often\nrequires evidence beyond the parametric knowledge stored\nwithin LLMs [Schlichtkrull et al. , 2023; Thorne et al. , 2018;\nWang, 2017 ]. RAG [Lewis et al. , 2020; Ram et al. , 2023 ]\nfacilitates the adaptation of LLMs to AFC by incorporat-\ning external retrieved evidence to LLMs [Panet al. , 2023a;\nPanet al. , 2023b; Chen et al. , 2024; Zhang and Gao, 2024 ].\nHowever, not all retrieved evidence is reliable [Guo et al. ,\n2022; Hong et al. , 2024 ], and information from untrust-\nworthy sources may contain misinformation, leading to con-\nflicting evidence. Recent studies have shown that retrieval-\naugmented LLMs are particularly vulnerable to contradic-tions in augmented texts [Min et al. , 2020; Lee et al. , 2024;\nChen et al. , 2021; Amplayo et al. , 2023 ]. Given the risks\nposed by unreliable sources, it is crucial to investigate the ro-\nbustness of retrieval-augmented LLMs in AFC, particularly\nin handling conflicting evidence.\n2.2 Source Credibility Estimation\nSource credibility estimation is crucial, as not all media\nsources are reliable; however, this problem remains underex-\nplored. Early works addressed this issue by estimating media\ncredibility through analysis of fake news records associated\nwith sources [Mukherjee and Weikum, 2015; Popat et al. ,\n2016; Popat et al. , 2017 ]. The authors in [Baly et al. , 2018 ]\nintroduced the first dataset with human-annotated factuality\nratings of news sources and utilized various features, such as\nWikipedia information and source URLs, for credibility es-\ntimation. Subsequent studies proposed more robust models\nusing diverse features of media sources [Zhang et al. , 2019;\nBaly et al. , 2020; Hounsel et al. , 2020 ]. In contrast to these\nclassification approaches, the work in [Schlichtkrull, 2024 ]\nemphasized the generation of detailed background checks for\nmedia sources.\nDespite these advancements, the impact of estimated\nsource credibility in fact-checking is still unknown. has re-\nceived limited attention. To date, only [Schlichtkrull, 2024 ]\nconducted a small-scale experiment with 20 claims, examin-\ning whether incorporating source background checks could\nbenefit claim verification. In this paper, we extend this line\nof inquiry by comprehensively evaluating how media source\nbackgrounds can facilitate fact-checking models, and explor-\ning optimal strategies for integrating source credibility infor-\nmation into these systems.\n3 CONFACT Dataset\nTheCONFACT dataset is specifically designed to facil-\nitate the study of fact-checking in scenarios where con-\nflicting evidence is retrieved from sources of varying\ncredibility, thereby addressing a critical gap in existing\ndatasets like A VERITEC [Schlichtkrull et al. , 2023 ]and\nFactCheckQA [Bashlovkina et al. , 2023 ]. The construction\ninvolved two key steps: 1) identifying claims likely to retrieve\nconflicting evidence \u2013 particularly those frequently associated\nwith misinformation from untrustworthy sources, and 2) en-\nsuring that retrieved documents for claim verification present\nconflicting stances.\n3.1 Claim Collection\nTo identify claims likely to retrieve conflicting evidence, we\nutilized two widely used fact-checking datasets:\n\u2022A VERITEC. This dataset [Schlichtkrull et al. ,\n2023 ]contains 4,568 real-world claims fact-checked\nby 50 organizations, categorized as Conflicting\nEvidence/Cherry-picking ,Not Enough Evidence ,Re-\nfuted , and Supported . We selected claims labeled as\nRefuted orSupported , which involve clear factuality.\n\u2022FactCheckQA. This dataset [Bashlovkina et al. , 2023 ]\nincludes 20,871 claims annotated as true,false , orother .\nWe focused on claims labeled as true orfalse , which\nprovide definitive factuality.\nClaims from these datasets were merged5, covering di-\nverse topics. This process resulted in 3,180 claims: 566 from\nA VERITEC and 2,614 from FactCheckQA.\n3.2 Conflicting Evidence Collection\nTo facilitate the study of conflicting evidence in fact-\nchecking, we retrieved relevant documents for claim verifi-\ncation. Instead of directly querying Google with the origi-\nnal claims, we transformed each claim into a binary question\nregarding its veracity using GPT-46, following the approach\noutlined in [Schlichtkrull, 2024; Bashlovkina et al. , 2023 ].\nFor example, the claim Nigeria had a population of 45 mil-\nlion at the time of independence\u201d was converted into the ques-\ntionDid Nigeria have a population of 45 million at the time\nof independence?\u201d . Each question was then submitted as a\nquery on Google, from which we retrieved the top 10 web\npages7. To ensure reproducibility, the retrieved web pages\nwere archived using the Wayback Machine8.\n3.3 Conflict Evidence Annotation\nNext, we annotated the stances of the collected evidence doc-\numents using a two-stage process designed to identify con-\nflicting viewpoints.\nStage 1: GPT-4 Annotation. We employed GPT-4 to clas-\nsify the stance of each document with respect to its corre-\nsponding claim as either supporting orrefuting . To enhance\nrobustness, we used three distinct prompt variations: (i) clas-\nsify the stance based solely on the document URL; (ii) clas-\nsify the stance using the retrieved webpage content; and (iii)\nprompt GPT-4 to provide its reasoning prior to making a clas-\nsification. The specific prompts are detailed in Appendix A.\nThe final stance for each document was determined\nthrough majority voting across these three approaches. We\ndefined a claim as exhibiting conflicting evidence if it was\nassociated with documents classified as both supporting and\nrefuting . Out of 3,180 claims, 611 (17.8%) met this criterion\nand advanced to the next stage.\nStage 2: Human Annotation. Human annotators subse-\nquently validated the conflicting evidence identified in Stage\n1. For each claim, annotators reviewed pairs of documents\u2014\none labeled as supporting and another as refuting by GPT-4.\nThe annotators verified the stances and assessed the credibil-\nity of the sources on a 5-point scale (1 = least credible, 5 =\nmost credible). Additionally, they categorized each source\ninto one of the following groups: Mainstream News ,Govern-\nment ,Non-profit ,Academic ,Social Media , orOther . Each\ndocument pair was independently reviewed by two annota-\ntors, with any disagreements resolved by a third annotator.\nDetailed annotation guidelines are provided in Appendix H.\n5Claims from social media platforms were excluded as they are\nless findable by search engines.\n6https://openai.com/index/gpt-4/\n7Searches and scraping were conducted within a single week\n(September 12\u201319, 2024)\n8https://web.archive.org/Split Labels # Sources\nModC 125 Yes; 486 No 2469\nHumC 51 Yes; 236 No 1418\nTable 1: Statistics of the ModC and HumC split of our CONFACT .\n3.4 Dataset Analysis\nThe final CONFACT dataset consists of two splits: Model\nConflicts (ModC) and Human Conflicts (HumC). ModC com-\nprises claims with conflicting evidence identified by GPT-\n4 during Stage 1. Given that GPT-4 is a powerful closed-\nsource model, this split contains conflicts that may be partic-\nularly challenging for most open-source models to resolve.\nHumC consists of claims where the evidence is conflict-\ning from a human perspective, aiming to assess how effec-\ntively fact-checking systems can mitigate human uncertainty\nwhen verifying such evidence. The inter-annotator agree-\nment for HumC, as measured by Krippendorff\u2019s Alpha, was\n0.586\u2014indicating strong agreement while also reflecting the\ngeneral confusion among annotators when dealing with con-\nflicting documents. Following prior work [Bashlovkina et al. ,\n2023; Schlichtkrull, 2024 ], we further formulate the claim\nverification task into a binary question regarding claim verac-\nity, making it more naturally suited for retrieval-augmented\nLLMs. The binary questions were generated with GPT-4 as\ndiscussed in Section 3.2. Claims labeled as true/supported\ncorrespond to questions with Yesas answers, and those la-\nbeled as false/refuted correspond to questions with Noas an-\nswers. The statistics of CONFACT are provided in Table 1\nand an illustration of a data sample from CONFACT is pro-\nvided in Appendix B.\nAn analysis of document credibility revealed key chal-\nlenges in assessing source credibility. Annotators frequently\noverestimated the reliability of Mainstream News sources,\nwith 95.8% of these sources rated as credible or neutral.\nCross-referencing these ratings with expert annotations from\nMedia Bias / Fact Check (MBFC)9showed that 30% of mis-\nleading sources were flagged as unreliable by MBFC, while\nannotators classified 69.8% of these as trustworthy. These\nfindings underscore the challenges of accurately assessing\ncredibility and highlight the importance of addressing con-\nflicting evidence in fact-checking tasks. More details for the\ndistribution of source credibility over source types are avail-\nable in Appendix F.\n4 Methodology\nIn this section, we evaluate retrieval-augmented LLMs on the\nCONFACT dataset to assess their robustness in fact-checking\nwhen confronted with conflicting evidence. We begin by\nformally defining the task in Section 4.1. Next, in Sec-\ntion 4.2, we describe baseline retrieval-augmented LLMs for\nfact-checking. Finally, Section 4.3 presents strategies for in-\ncorporating media source background information at various\nstages of the RAG pipeline.\n4.1 Problem Definition\nGiven a claim verification question Qwith its relevant N\nretrieved documents {Dn}N\nn=1from CONFACT , a retrieval-\n9https://mediabiasfactcheck.com/\n1. Retrieval\nquestion\n2. Ranking\n 3. Answer Generation\nCredible Score \ud835\udc94\ud835\udc50\ud835\udc5f\ud835\udc52\ud835\udc51\nRelevance Score  \ud835\udc94\ud835\udc5f\ud835\udc52\ud835\udc59\n(a)\n(b)\n(c)\n(d)Documents\n{\ud835\udc37\ud835\udc5b}\ud835\udc5b=1\ud835\udc41Relevant Paragraphs\n{\ud835\udc43\ud835\udc58}\ud835\udc58=1\ud835\udc3e\nFiltered Documents\nSource\nBackgroun dFigure 2: (a) illustrates a general framework of RAG methods in-\nvolving three stages: retrieval, ranking and answer generation. (b-d)\ndemonstrate our source-aware retrieval-augmented LLMs, incorpo-\nrating source background information in three stages of the general\nRAG framework.\naugmented LLM is expected to generate an answer Ato the\nquestion that reflects the veracity of the original claim against\navailable evidence. The system is evaluated on its accuracy\nin correctly predicting the veracity of claims (i.e., whether A\nexactly matches the ground-truth label \u02c6Afor the converted\nquestion for claim verification). In addition, we report the\nMacro-F1 score as an auxiliary metric to assess performance\nacross classes, particularly given the imbalanced nature of the\ndataset.\nA typical retrieval-augmented fact-checking workflow\nconsists of three main stages: retrieval ,ranking , and answer\ngeneration [Wang et al. , 2024b; Gao et al. , 2023 ], as illus-\ntrated in Figure 2(a).\n\u2022Retrieval : Given a claim verification question Q, a RAG\nmodel retrieves relevant documents from an external\nknowledge base, represented as {Dn}N\nn=1. Retrieved\ndocuments were provided on CONFACT to ensure re-\nproducibility, as retrieval is time-varying.\n\u2022Ranking : Retrieved documents are chunked into short\npassages, and a ranking function selects the top- Kmost\nrelevant paragraphs {Pk}K\nk=1for fact-checking.\n\u2022Answer Generation : The selected paragraphs {Pk}K\nk=1\nare passed to an LLM to generate the final answer A.\n4.2 Baseline Retrieval-Augmented LLMs\nBaseline retrieval-augmented LLMs adhere to the standard\nworkflow illustrated in Figure 2(a). In this process, the most\nrelevant set of paragraphs {Pk}K\nk=1are extracted and used as\ninput for answer generation. We evaluate multiple prompting\nstrategies for leveraging these augmented contexts:\n\u2022Direct Answer (DirA. ): The Kselected paragraphs are\nprovided to the LLM along with the claim verificationquestion, and the model directly generates an answer.\n\u2022Majority Vote (MajV . ): The model first predicts answer\ncandidates Akfor each paragraph Pk. A majority vote\nis then conducted to select the final answer.\n\u2022Discern and Answer (DisA. ): Inspired by [Hong et al. ,\n2024 ], an explicit instruction is added to filter out mis-\nleading passages before generating an answer.\n\u2022Chain-of-Thought (CoT ): This strategy prompts the\nLLM to generate a rationale before predicting the an-\nswer [Wei et al. , 2022 ], improving reasoning in multi-\nstep verification tasks.\nWhile these strategies perform well in standard question-\nanswering tasks, they struggle when the retrieved evidence\nexhibits conflicting viewpoints. For instance, DirA. may con-\nflate misinformation with factual content, MajV . fails if mis-\nleading sources outnumber reliable ones, and DisA. depends\non the LLM\u2019s ability to filter unreliable information, which is\nnot always effective. These limitations motivate the incorpo-\nration of media background knowledge.\n4.3 Retrieval-Augmented LLMs with Media\nSource Backgrounds\nTo improve fact-checking performance in the presence of\nconflicting evidence, we propose integrating background in-\nformation from the source of the media at different stages of\nthe RAG pipeline.\nMedia Source Background Provider\nFor each retrieved document, we extract background informa-\ntion about its source. The MBFC website serves as our pri-\nmary source background provider (GT-MB), offering expert\nannotations on media bias and factual reliability. If a source\nis available in MBFC, its credibility rating is retrieved. Oth-\nerwise, the background is marked as missing.\nTo extend coverage beyond MBFC, we introduce a\nHybrid-MB provider, combining MBFC annotations with\nan LLM-based background generator [Schlichtkrull, 2024 ].\nThe generator first retrieves real-time information about the\nsource\u2019s publisher, past credibility ratings, and history of mis-\ninformation via Google Search APIs10. It then processes\nthis information using an in-context learning approach with\na set of pre-defined prompts, generating a credibility sum-\nmary (denoted as B) that includes factual accuracy, bias, and\nmisinformation history (Refer to Appendix I for the designed\nprompts).\nAlthough the generated source credibility description is\ncomprehensive, it may not be directly applicable at all stages\nof retrieval-augmented LLMs. Therefore, we further map this\ndescription into a credibility score scred\u2208(0,1)using a pre-\ndiction model \u03c0\u03b8:\nscred=\u03c0\u03b8(B). (1)\nThe model is trained on [Baly et al. , 2018 ], which provides\nlabeled credibility supervision. More details about the credi-\nble score prediction are provided in Appendix I.\n10https://developers.google.com/custom-search/v1/overview\nMedia Background Incorporation\nWe explore to incorporate source credibility information in\nthree stages of the RAG pipeline:\n1. Source Filtering in Retrieval ( SF): It aims to filter in-\ncredible information in the document level. Documents from\nsources described as low credible according to Bare filtered\nbefore ranking (Figure 2(b)) (more details in Appendix G.1).\nThe remaining documents are ranked, and the top- Kpara-\ngraphs are used for answer generation.\n2. Credibility Weighting in Ranking ( CW): Instead of filter-\ning in the document level, credibility scores influence ranking\n(Figure 2(c)). The final ranking score for a paragraph Pmis\ncomputed as:\nsm=srel,m+\u03b2\u2217scred,m, (2)\nwhere srel,mis the relevance score and \u03b2balances relevance\nand credibility. We considered both a soft (CW soft) and a\nhard (CW hard) setting for leveraging the credible score where\nCW hardfurther maps scredinto 0 and 1. Specifically, if scredis\nbelow a threshold \u03b3, it will be mapped to 0, otherwise, 1.\n3. Source Backgrounds Augmentation in Generation\n(SBA): Source backgrounds are included at the answer gen-\neration stage (Figure 2(d)). We evaluate four strategies:\n\u2022SBA dir: Concatenates each paragraph with its source\nbackground for source-aware paragraphs ( [Pk,Bk]).\nTheKsource-aware paragraphs are fed to LLMs for a\ndirect answer.\n\u2022SBA CoT: Uses CoT prompt with source-aware para-\ngraphs.\n\u2022SBA exp: Receives source-aware paragraphs and uses ex-\nplicit instructions to filter unreliable sources.\n\u2022SBA ens: Uses a two-stage process where candidate an-\nswers are generated per paragraph, and conflicts are re-\nsolved based on source-aware rationales:\nAk,Rk=LLM([Pk,Bk],Q) (3)\nA\u2217=LLM([A1,R1, . . . ,AD,RD],Q) (4)\nwhereA\u2217is the final answer after considering all ratio-\nnales.\nRefer to Appendix G.2 for the designed prompts.\n5 Experiments\n5.1 Main Experimental Results\nWe conducted extensive experiments on the ModC and\nHumC splits of CONFACT (for implementation details,\nsee Appendix C) to evaluate the performance of retrieval-\naugmented LLMs in fact-checking scenarios involving con-\nflicting evidence. Our evaluation compares baseline RAG\nmodels that do not consider media source backgrounds (Base-\nline) against models that integrate source credibility data at\ndifferent stages of the pipeline, using the strategies intro-\nduced in Section 4.3 (i.e., Source Filtering ( SF), Credibility\nWeighting ( CW[\u00b7]), and Source Background Augmentation\n(SBA [\u00b7])). The experiment results are presented in Table 2.\nBelow, we analyze key findings from our experiments by ad-\ndressing three research questions.RQ 1 :How do vanilla retrieval-augmented LLMs perform\nwhen confronted with conflicting evidence from sources of\nvarying credibility?\nAs shown in the first block of Table 2, vanilla RAG models\nexhibit difficulties when dealing with conflicting evidence.\nTheir performance is notably limited, as reflected by lower\nF1 scores, suggesting challenges in correctly classifying the\nminority class (i.e., claims where the majority of retrieved\nevidence is misleading). This is primarily due to three key\nissues. First, hallucination \u2014 when presented with con-\nflicting sources, LLMs sometimes generate factually incor-\nrect responses that do not accurately reflect the retrieved evi-\ndence. Second, over-reliance on high-frequency responses \u2014\nthe Majority V ote setting biases the system toward the dom-\ninant source perspective, often amplifying misinformation if\nit is overrepresented in retrieval. Third, inability to distin-\nguish misinformation from reliable sources \u2014 since vanilla\nRAG models do not assess source credibility, they treat all re-\ntrieved documents as equally valid, leading to incorrect fact-\nchecking outputs. Notably, using GPT-4o in RAG methods\n(Appendix J) showed no clear advantage over open-source\nmodels, highlighting the problem\u2019s complexity.\nAmong the baseline answering strategies, Discern-and-\nAnswer ( DisA.) and Chain-of-Thought ( CoT ) prompting\nachieve better results than direct answer generation. This im-\nprovement suggests that prompting LLMs to explicitly reason\nabout retrieved content helps mitigate the influence of un-\nreliable sources. However, despite these improvements, the\noverall accuracy and F1 scores remain suboptimal, highlight-\ning the need for more effective mechanisms to incorporate\nsource credibility into the fact-checking process.\nRQ 2 :Does incorporating media source backgrounds im-\nprove fact-checking performance in RAG-based LLMs?\nIncorporating media background information into RAG\nmodels generally leads to improved performance, although\nthe degree of improvement varies across models. Specifically,\nLLaMA-3.1 shows a 10% absolute improvement in F1 score,\nwhile Mistral achieves a 5% in accuracy improvement when\nmedia backgrounds are integrated on the ModC split. Similar\nimprovements are observed on HumC, with the incorporation\nof source credibility information. These results indicate that\nproviding source credibility cues helps LLMs resolve con-\nflicting evidence more effectively.\nHowever, not all models benefit equally from media back-\ngrounds. Specifically, Qwen-2 exhibits the least improve-\nment, which we attribute to its weaker long-context process-\ning capabilities. The inclusion of source background infor-\nmation significantly increases input length. In models that do\nnot handle extended sequences efficiently, this can dilute rel-\nevant context, increase token misalignment, and disrupt self-\nattention mechanisms, ultimately leading to suboptimal fact-\nchecking performance. This finding suggests that as LLM\narchitectures improve in handling long inputs, the benefits\nof integrating source-aware fact-checking will likely become\nmore pronounced.\nRQ 3 :What is the most effective strategy for incorporating\nmedia source backgrounds into retrieval-augmented LLMs?\nDifferent strategies for integrating media backgrounds\nshow distinct patterns of performance across RAG mod-\nModC HumC\nSet. Meth. LLaMA-3.1 Qwen-2 Mistral LLaMA-3.1 Qwen-2 Mistral\nAcc. F1 Acc. F1 Acc. F1 Acc. F1 Acc. F1 Acc. F1\nBsl.DirA. 71.36 66.13 78.40 45.96 77.58 70.82 70.03 63.81 77.70 67.83 75.96 67.87\nMajV . 79.87 45.96 79.71 45.90 79.54 45.83 82.93 49.07 82.93 49.07 82.93 49.07\nDisA. 72.18 63.26 78.89 69.54 76.10 70.70 69.69 57.87 80.14 70.04 77.35 71.16\nCoT 77.58 68.50 72.34 67.74 75.46 71.52 75.96 65.50 72.47 64.32 73.87 67.99\nGTSF 71.52 66.28 78.40 69.87 77.74 70.98 69.34 62.97 77.70 67.83 76.31 68.19\nCW soft 67.76 62.75 75.61 65.57 75.12 67.82 67.25 60.45 73.87 61.65 73.52 64.10\nCW hard 68.09 63.62 74.30 64.59 74.47 67.74 68.99 62.93 73.17 61.50 74.22 66.01\nSBA dir 73.16 67.96 79.21 70.51 79.87 73.06 72.82 66.46 78.40 68.11 78.40 69.80\nSBA CoT 78.07 68.32 71.85 67.83 76.92 73.94 78.40 66.07 72.47 67.75 77.00 72.44\nSBA exp 74.47 64.57 80.03 70.13 73.65 68.98 71.40 58.31 80.49 67.44 75.26 69.20\nSBA ens 76.76 68.35 67.92 64.39 66.61 64.53 75.61 65.19 67.94 63.13 68.29 64.79\nHyb.SF 67.10 62.30 78.07 68.96 75.45 68.62 64.46 58.72 77.70 65.65 74.91 66.31\nCW soft 70.05 65.00 77.41 68.35 77.25 70.02 70.73 64.15 77.00 66.05 77.35 67.85\nCW hard 70.38 65.49 77.74 68.96 76.92 69.72 70.38 64.36 77.35 67.14 75.26 66.30\nSBA direct 74.96 69.30 79.05 70.20 80.03 73.46 74.91 68.06 78.75 68.06 78.75 70.76\nSBA CoT 75.29 65.78 73.00 68.69 75.29 71.90 73.87 61.20 74.22 68.26 75.96 71.14\nSBA exp 76.10 64.53 80.69 70.50 72.83 70.50 75.26 60.88 82.93 70.56 74.91 71.47\nSBA ens 76.76 67.75 66.78 63.25 67.27 63.81 74.91 63.39 64.11 58.01 66.55 60.07\nTable 2: Performance of retrieval-augmented LLMs on the ModC andHumC splits of our CONFACT dataset. Baseline (Bsl.) denotes\nmodels without incorporating source backgrounds. GT-MB (GT) represents models that only consider incorporating source backgrounds with\nground-truth human annotations. Hybrid-MB (Hyb. ) demonstrates models incorporated with both human-annotated source backgrounds as\nwell as automatically generated media backgrounds. The best results (the highest summation of Acc. and F1) are underlined.\nels. Our results indicate that the most effective approach is\nto incorporate media backgrounds at the answer generation\nstage, combined with a structured reasoning strategy such as\nCoT prompting or explicit instructions to discern unreliable\nsource.\nIn contrast, strategies that introduce media backgrounds in\nearlier stages-such as retrieval or ranking-are less effective.\nThis is likely due to information loss when converting de-\ntailed textual source descriptions into a single credibility level\nor a credibility score. The credibility score predictor, despite\nbeing trained on expert-annotated data, does not always pro-\nvide precise mappings between background descriptions and\nfactual reliability, leading to potential misclassifications.\nFurthermore, credibility-aware ranking strategies ( CW soft\nand CW hard) sometimes degrade performance. This oc-\ncurs because credibility and relevance are not always\naligned\u2014highly credible sources may not contain the most\npertinent evidence for verifying a claim. Additionally,\ncredibility-based filtering can risk removing crucial counter-\nevidence. Fact-checking often requires evaluating mislead-\ning claims in context, and aggressively filtering out sources\ndeemed unreliable may leave models without the necessary\ncontrastive information to identify misinformation. As a re-\nsult, ranking methods that overly rely on credibility scores\ncan paradoxically reduce fact-checking accuracy by limiting\nthe model\u2019s ability to reason over conflicting viewpoints.\nComparing GT-MB (which uses expert-verified MBFC\ncredibility labels) and Hybrid-MB (which estimates credibil-\nity for missing sources using LLM-based retrieval), we do not\nobserver obvious superiority of Hybrid-MB. This indicates\nthat current source credibility estimation methods remain lim-\nited, which could add noise to source credibility aware RAG\nmethods. Manually curated credibility assessments are stillmore reliable than automated credibility prediction. Detailed\nerror analysis is provided in Appendix E.\nSummary of Findings. Our results demonstrate that\nretrieval-augmented LLMs struggle with conflicting evidence\nwhen source credibility is not explicitly considered. Integrat-\ning media backgrounds improves performance, but the effec-\ntiveness of this approach depends on how and where the infor-\nmation is introduced within the pipeline. The most effective\nstrategy is incorporating background information at the an-\nswer generation stage, where structured reasoning techniques\nsuch as Chain-of-Thought prompting or explicit instructions\nto discern unreliable source to resolve conflicting claims more\neffectively. In contrast, relying solely on credibility-aware\nfiltering or ranking may inadvertently introduce biases or re-\nmove crucial context needed for fact-checking.\nOur findings also reveal a fundamental trade-off between\nusing expert-verified credibility data (GT-MB) and automated\ncredibility estimation (Hybrid-MB). While expert annota-\ntions provide higher reliability, automated credibility infer-\nence allows for broader source coverage and scalability. Im-\nproving the accuracy of LLM-based credibility prediction\nremains a key open challenge for future research. These\ninsights contribute to the broader field of AI-driven fact-\nchecking by demonstrating both the potential and limita-\ntions of leveraging source credibility to enhance retrieval-\naugmented generation for misinformation detection.\n5.2 Ablation Studies\nTo further understand the impact of media source back-\ngrounds on fact-checking with conflicting evidence, we con-\nduct ablation studies focusing on GT-MB model on HumC, as\nthey avoid noise from automated source estimation (Hybrid-\nMB) and HumC is more challenging as shown in Section 5.1.\nTop-K Chk. Meth.LLaMA-3.1 Qwen-2\nAcc. F1 Acc. F1\nTop-10 Para.SBA dir 71.78 65.04 79.09 69.76\nSBA CoT 76.66 66.02 57.14 67.34\nSBA exp 74,22 63.06 65.16 67.86\nSBA ens 74.56 63.62 50.52 48.43\nTop-5 Sent.SBA dir 62.37 57.52 72.82 62.28\nSBA CoT 67.94 58.84 61.32 62.28\nSBA exp 67.25 54.71 75.12 64.18\nSBA ens 68.99 59.76 54.01 53.90\nTable 3: Ablation results when using top- 10pieces of augmented\ncontext paragraph (para.) and top- 5sentence-level (sent.) chunking\nstrategy.\nw/o Background GT Hybrid\nAcc. 49.45 50.34 48.47\nTable 4: Human performance on CONFACT without background\ninformation, provided with GT background information, and hybrid\nbackground information.\nHere, we consider the most powerful way (i.e., in the answer\ngeneration stage) to incorporate source credibility informa-\ntion.\nEffect of the Number of Augmented Paragraphs. We as-\nsess whether increasing the number of retrieved paragraphs\nimproves fact-checking performance by expanding the evi-\ndence set from 5 (Table 2) to 10 documents (the first block\nin Table 3). Surprisingly, this does not enhance accuracy as\nmodels may struggle with long inputs as well as be distracted\nfrom irrelevant information.\nThe main reasons are twofold: (1) Increasing the number\nof retrieved documents introduces lower-relevance evidence,\nwhich makes it harder for the model to discern factual cor-\nrectness. (2) Longer input sequences overwhelm LLM atten-\ntion mechanisms, leading to poorer factual reasoning. These\nfindings suggest that retrieving fewer but more relevant docu-\nments is more effective than increasing retrieval breadth when\ndealing with conflicting claims.\nImpact of Chunking Strategies. We compare paragraph-\nlevel (Table 2) vs. sentence-level chunking (the second\nblock in Table 3) for retrieved evidence in the fact-checking\npipeline. Paragraph-level chunking consistently outperforms\nsentence-level chunking, as fragmented sentences often lack\nsufficient context to resolve factual disputes. However, longer\nparagraph inputs increase computational overhead.\nA potential solution is de-contextualization methods,\nwhere sentences are supplemented with surrounding context\nbefore being processed by LLMs. Future work could explore\nsuch strategies to maintain high-context resolution while min-\nimizing input length constraints.\n5.3 Human Evaluation\nBeyond the quantitative analysis in Section 5.1, we con-\nduct a qualitative study to assess human fact-checking perfor-\nmance under conflicting evidence. We select 20 fact-checking\nclaims from CONFACT and recruit four NLP researchers as\nhuman evaluators. Each human evaluator evaluates 10 claims\nacross three settings, mirroring Section 5.1: (1) without any\nsource background, (2) with curated media backgrounds from\nMBFC (GT), and (3) with both MBFC-curated and automat-\nically generated source backgrounds (Hybird). The accuracyof human evaluations is summarized in Table 4.\nOur findings indicate that humans often respond with \u201dun-\nsure\u201d when faced with conflicting evidence, mirroring model\nperformance: while GT media backgrounds boost accuracy,\nhybrid sources (including AI-generated backgrounds) tend to\nintroduce noise and mislead evaluators. This suggests that un-\nreliable or AI-generated context can impair judgment rather\nthan enhance it.\nThese results have critical implications for real-world fact-\nchecking organizations. Fact-checkers must adopt rigorous\nsource verification methods to mitigate misinformation risks,\nand automated tools should prioritize high-fidelity data cura-\ntion over broad retrieval to reduce misleading noise. More-\nover, AI-generated evidence should be treated as assistive\nrather than authoritative, with human oversight ensuring ef-\nfective verification of conflicting claims.\nOverall, this human evaluation highlights the complexity\nof fact-checking amid conflicting evidence, reinforcing the\nneed for high-quality evidence retrieval and robust verifica-\ntion mechanisms in both human and automated fact-checking\nsystems.\n6 Conclusion\nThis study presents a systematic evaluation of RAG models\nin fact-checking scenarios involving conflicting evidence\u2014a\ncritical yet underexplored challenge. To support this, we\nintroduce the CONFACT dataset, which pairs fact-checking\nclaims with contradictory information from sources of vary-\ning credibility. Our analysis indicates that existing RAG mod-\nels struggle when faced with conflicting evidence, often as-\ncribing undue reliability to less credible sources.\nTo address this issue, we integrate background information\nfrom the media sources into the RAG pipelines. Our find-\nings reveal that incorporating source credibility signals dur-\ning answer generation significantly enhances performance by\nreducing the models\u2019 susceptibility to misinformation. How-\never, challenges remain, particularly in accurately assessing\nsource credibility and mitigating biases in evidence retrieval.\nThese findings have practical implications for real-world\nfact-checking. Automated systems must go beyond naive re-\ntrieval and adopt rigorous source validation to avoid ampli-\nfying unreliable claims. Moreover, AI-assisted verification\nshould complement human expertise, ensuring that models\nserve as tools to support rather than replace professional fact-\ncheckers. Future work should focus on refining automated\ncredibility assessments, improving evidence ranking, and rea-\nsoning under uncertainty.\nDespite the progress demonstrated, we acknowledge sev-\neral limitations of our current framework, including biases in\nsource labeling and the absence of more advanced baseline\nsystems. These are discussed in Appendix D\nOverall, our study confronts the complexities of conflict-\ning evidence in fact-checking, and underscores the urgent\nneed for trustworthy, AI-driven verification systems. Ad-\ndressing these challenges is essential for strengthening re-\nsilience against misinformation and ensuring the reliability\nof AI-assisted fact-checking in journalistic, policy, and pub-\nlic discourse contexts.\nAcknowledgement\nThis research/project is supported by the National Research\nFoundation, Singapore under its National Large Language\nModels Funding Initiative (AISG Award No: AISG-NMLP-\n2024-004). Any opinions, findings and conclusions or rec-\nommendations expressed in this material are those of the\nauthor(s) and do not reflect the views of National Research\nFoundation, Singapore. This research/project is supported by\nthe Ministry of Education, Singapore, under its SUTD-SMU\nJoint Grant Call, if applicable).\nReferences\n[Amplayo et al. , 2023 ]Reinald Kim Amplayo, Kellie Web-\nster, Michael Collins, Dipanjan Das, and Shashi Narayan.\nQuery refinement prompts for closed-book long-form QA.\nInProceedings of the 61st Annual Meeting of the Associ-\nation for Computational Linguistics (Volume 1: Long Pa-\npers), ACL , pages 7997\u20138012, 2023.\n[Baly et al. , 2018 ]Ramy Baly, Georgi Karadzhov, Dimitar\nAlexandrov, James R. Glass, and Preslav Nakov. Pre-\ndicting factuality of reporting and bias of news media\nsources. In Proceedings of the 2018 Conference on Em-\npirical Methods in Natural Language Processing , pages\n3528\u20133539, 2018.\n[Baly et al. , 2020 ]Ramy Baly, Georgi Karadzhov, Jisun An,\nHaewoon Kwak, Yoan Dinkov, Ahmed Ali, James R.\nGlass, and Preslav Nakov. What was written vs. who read\nit: News media profiling using text analysis and social me-\ndia context. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, ACL 2020,\nOnline, July 5-10, 2020 , pages 3364\u20133374, 2020.\n[Bashlovkina et al. , 2023 ]Vasilisa Bashlovkina, Zhaobin\nKuang, Riley Matthews, Edward Clifford, Yennie Jun,\nWilliam W. Cohen, and Simon Baumgartner. Trusted\nsource alignment in large language models. CoRR ,\nabs/2311.06697, 2023.\n[Chen and Shu, 2024 ]Canyu Chen and Kai Shu. Can llm-\ngenerated misinformation be detected? In The Twelfth\nInternational Conference on Learning Representations,\nICLR , 2024.\n[Chen et al. , 2021 ]Anthony Chen, Pallavi Gudipati, Shayne\nLongpre, Xiao Ling, and Sameer Singh. Evaluating en-\ntity disambiguation and the role of popularity in retrieval-\nbased NLP. In Proceedings of the 59th Annual Meeting\nof the Association for Computational Linguistics and the\n11th International Joint Conference on Natural Language\nProcessing, ACL/IJCNLP , pages 4472\u20134485, 2021.\n[Chen et al. , 2024 ]Jifan Chen, Grace Kim, Aniruddh Sri-\nram, Greg Durrett, and Eunsol Choi. Complex claim ver-\nification with evidence retrieved in the wild. In Proceed-\nings of the 2024 Conference of the North American Chap-\nter of the Association for Computational Linguistics: Hu-\nman Language Technologies (Volume 1: Long Papers),\nNAACL , pages 3569\u20133587, 2024.\n[Dubey et al. , 2024 ]Abhimanyu Dubey, Abhinav Jauhri,\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang,\nAngela Fan, et al. The llama 3 herd of models. arXiv\npreprint arXiv:2407.21783 , 2024.\n[Gao et al. , 2023 ]Yunfan Gao, Yun Xiong, Xinyu Gao,\nKangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun,\nQianyu Guo, Meng Wang, and Haofen Wang. Retrieval-\naugmented generation for large language models: A sur-\nvey. CoRR , abs/2312.10997, 2023.\n[Guo et al. , 2022 ]Zhijiang Guo, Michael Sejr Schlichtkrull,\nand Andreas Vlachos. A survey on automated fact-\nchecking. Trans. Assoc. Comput. Linguistics , 10:178\u2013206,\n2022.\n[Guu et al. , 2020 ]Kelvin Guu, Kenton Lee, Zora Tung,\nPanupong Pasupat, and Mingwei Chang. Retrieval aug-\nmented language model pre-training. In International con-\nference on machine learning , pages 3929\u20133938. PMLR,\n2020.\n[Hong et al. , 2024 ]Giwon Hong, Jeonghwan Kim, Junmo\nKang, Sung-Hyon Myaeng, and Joyce Jiyoung Whang.\nWhy so gullible? enhancing the robustness of retrieval-\naugmented models against counterfactual noise. In Find-\nings of the Association for Computational Linguistics:\nNAACL , pages 2474\u20132495, 2024.\n[Hounsel et al. , 2020 ]Austin Hounsel, Jordan Holland, Ben\nKaiser, Kevin Borgolte, Nick Feamster, and Jonathan R.\nMayer. Identifying disinformation websites using infras-\ntructure features. In 10th USENIX Workshop on Free and\nOpen Communications on the Internet, FOCI , 2020.\n[Kwon and others, 2023 ]Woosuk Kwon et al. Efficient\nmemory management for large language model serving\nwith paged attention. In Proc. of the ACM SIGOPS 29th\nSymposium on Operating Systems Principles , 2023.\n[Leeet al. , 2024 ]Yoonsang Lee, Xi Ye, and Eunsol Choi.\nAmbigdocs: Reasoning across documents on different en-\ntities under the same name. CoRR , abs/2404.12447, 2024.\n[Lewis et al. , 2020 ]Patrick S. H. Lewis, Ethan Perez, Alek-\nsandra Piktus, Fabio Petroni, Vladimir Karpukhin, Na-\nman Goyal, Heinrich K \u00a8uttler, Mike Lewis, Wen-tau Yih,\nTim Rockt \u00a8aschel, Sebastian Riedel, and Douwe Kiela.\nRetrieval-augmented generation for knowledge-intensive\nNLP tasks. In Advances in Neural Information Process-\ning Systems 33: Annual Conference on Neural Informa-\ntion Processing Systems 2020, NeurIPS 2020, December\n6-12, 2020, virtual , 2020.\n[Liet al. , 2023 ]Dongfang Li, Zetian Sun, Xinshuo Hu,\nZhenyu Liu, Ziyang Chen, Baotian Hu, Aiguo Wu, and\nMin Zhang. A survey of large language models attribu-\ntion. CoRR , abs/2311.03731, 2023.\n[Min et al. , 2020 ]Sewon Min, Julian Michael, Hannaneh\nHajishirzi, and Luke Zettlemoyer. Ambigqa: Answering\nambiguous open-domain questions. In Proceedings of the\n2020 Conference on Empirical Methods in Natural Lan-\nguage Processing, EMNLP , pages 5783\u20135797, 2020.\n[Mistral.AI, 2023 ]Mistral.AI. La plateforme, 2023.\n[Mukherjee and Weikum, 2015 ]Subhabrata Mukherjee and\nGerhard Weikum. Leveraging joint interactions for credi-\nbility analysis in news communities. In Proceedings of the\n24th ACM International Conference on Information and\nKnowledge Management, CIKM , pages 353\u2013362, 2015.\n[Nakov et al. , 2021 ]Preslav Nakov, David P. A. Corney,\nMaram Hasanain, Firoj Alam, Tamer Elsayed, Alberto\nBarr\u00b4on-Cede \u02dcno, Paolo Papotti, Shaden Shaar, and Gio-\nvanni Da San Martino. Automated fact-checking for as-\nsisting human fact-checkers. In Proceedings of the Thir-\ntieth International Joint Conference on Artificial Intelli-\ngence, IJCAI , pages 4551\u20134558, 2021.\n[Panet al. , 2023a ]Liangming Pan, Xinyuan Lu, Min-Yen\nKan, and Preslav Nakov. Qacheck: A demonstration sys-\ntem for question-guided multi-hop fact-checking. In Pro-\nceedings of the 2023 Conference on Empirical Methods in\nNatural Language Processing, EMNLP , pages 264\u2013273,\n2023.\n[Panet al. , 2023b ]Liangming Pan, Xiaobao Wu, Xinyuan\nLu, Anh Tuan Luu, William Yang Wang, Min-Yen Kan,\nand Preslav Nakov. Fact-checking complex claims with\nprogram-guided reasoning. In Proceedings of the 61st An-\nnual Meeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), ACL , pages 6981\u20137004,\n2023.\n[Popat et al. , 2016 ]Kashyap Popat, Subhabrata Mukherjee,\nJannik Str \u00a8otgen, and Gerhard Weikum. Credibility assess-\nment of textual claims on the web. In Proceedings of the\n25th ACM International Conference on Information and\nKnowledge Management, CIKM , pages 2173\u20132178, 2016.\n[Popat et al. , 2017 ]Kashyap Popat, Subhabrata Mukherjee,\nJannik Str \u00a8otgen, and Gerhard Weikum. Where the truth\nlies: Explaining the credibility of emerging claims on the\nweb and social media. In Proceedings of the 26th Interna-\ntional Conference on World Wide Web Companion , pages\n1003\u20131012, 2017.\n[Ram et al. , 2023 ]Ori Ram, Yoav Levine, Itay Dalmedigos,\nDor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and\nYoav Shoham. In-context retrieval-augmented language\nmodels. Trans. Assoc. Comput. Linguistics , 11:1316\u2013\n1331, 2023.\n[Robertson and Zaragoza, 2009 ]Stephen E. Robertson and\nHugo Zaragoza. The probabilistic relevance framework:\nBM25 and beyond. Found. Trends Inf. Retr. , 3(4):333\u2013389,\n2009.\n[Schlichtkrull et al. , 2023 ]Michael Schlichtkrull, Zhijiang\nGuo, and Andreas Vlachos. Averitec: A dataset for real-\nworld claim verification with evidence from the web. In\nAdvances in Neural Information Processing Systems 36:\nAnnual Conference on Neural Information Processing Sys-\ntems 2023, NeurIPS , 2023.\n[Schlichtkrull, 2024 ]Michael Schlichtkrull. Generating me-\ndia background checks for automated source critical rea-\nsoning. CoRR , abs/2409.00781, 2024.\n[Thorne et al. , 2018 ]James Thorne, Andreas Vlachos,\nChristos Christodoulopoulos, and Arpit Mittal. FEVER:a large-scale dataset for fact extraction and VERification.\nInProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computational\nLinguistics , pages 809\u2013819, 2018.\n[Wang et al. , 2024a ]Lionel Z. Wang, Yiming Ma, Renfei\nGao, Beichen Guo, Zhuoran Li, Han Zhu, Wenqi Fan,\nZexin Lu, and Ka Chung Ng. Megafake: A theory-driven\ndataset of fake news generated by large language models.\nCoRR , abs/2408.11871, 2024.\n[Wang et al. , 2024b ]Xiaohua Wang, Zhenghua Wang, Xuan\nGao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan\nShi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng\nYin, Changze Lv, Xiaoqing Zheng, and Xuanjing Huang.\nSearching for best practices in retrieval-augmented gener-\nation. In Proceedings of the 2024 Conference on Empirical\nMethods in Natural Language Processing, EMNLP , pages\n17716\u201317736, 2024.\n[Wang, 2017 ]William Yang Wang. \u201cliar, liar pants on fire\u201d:\nA new benchmark dataset for fake news detection. In Pro-\nceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics , pages 422\u2013426, 2017.\n[Weiet al. , 2022 ]Jason Wei, Xuezhi Wang, Dale Schuur-\nmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi,\nQuoc V . Le, and Denny Zhou. Chain-of-thought prompt-\ning elicits reasoning in large language models. In Ad-\nvances in Neural Information Processing Systems 35: An-\nnual Conference on Neural Information Processing Sys-\ntems 2022, NeurIPS , 2022.\n[Yang et al. , 2024 ]An Yang, Baosong Yang, Binyuan Hui,\nBo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,\nChengyuan Li, Dayiheng Liu, Fei Huang, et al. Qwen2\ntechnical report. arXiv preprint arXiv:2407.10671 , 2024.\n[Zhang and Gao, 2024 ]Xuan Zhang and Wei Gao. Rein-\nforcement retrieval leveraging fine-grained feedback for\nfact checking news claims with black-box LLM. In\nProceedings of the 2024 Joint International Conference\non Computational Linguistics, Language Resources and\nEvaluation (LREC-COLING) , pages 13861\u201313873, 2024.\n[Zhang et al. , 2019 ]Yifan Zhang, Giovanni Da San Mar-\ntino, Alberto Barr \u00b4on-Cede \u02dcno, Salvatore Romeo, Jisun An,\nHaewoon Kwak, Todor Staykovski, Israa Jaradat, Georgi\nKaradzhov, Ramy Baly, Kareem Darwish, James R. Glass,\nand Preslav Nakov. Tanbih: Get to know what you are\nreading. In Proceedings of the 2019 Conference on Em-\npirical Methods in Natural Language Processing and the\n9th International Joint Conference on Natural Language\nProcessing, EMNLP-IJCNLP , pages 223\u2013228, 2019.\nAPPENDIX\nA Prompts for Annotation with GPT-4\nA. System Prompt\nYou are an expert in fact-checking. Analyze the claim, evi-\ndence, and claim date. Consider the timeline and disregard\npost-claim events. Determine if the evidence supports, re-\njects, or is inconclusive about the claim.\nB. URL Prompt\nReview the URL content to determine its support, rejection,\nor neutrality toward the claim. Consider the claim date. Re-\nspond only with: - Support - Reject - Not enough evidence.\nNo additional text.\nClaim: {claim}\nDate of Claim: {claim_date}\nURL: {evidence_url}\nC. Text Prompt without Justification\nReview the text to determine its position on the claim con-\nsidering the claim date. Respond only with: - Support -\nReject - Not enough evidence. No additional text.\nClaim: {claim}\nDate when the claim was made: {claim_date}\nScraped Content: {evidence_content}\nD. Text Prompt with Justification\nEvaluate the text against the claim date. Assess if it sup-\nports, rejects, or is inconclusive about the claim. Provide\nup to 500 words of reasoning and conclude with: - Support\n- Reject - Not enough evidence. Start your conclusion with\n\u2019Final answer: \u2019.\nClaim: {claim}\nDate when the claim was made: {claim_date}\nScraped Content: {evidence_content}\nIn this section, we provide the specific prompts used for\nthe first stage of conflicting evidence annotation with GPT-4\n(Section 3.2). We used three variants prompts to query GPT-\n4 in order to enhance the robustness of annotation. The three\nprompting strategies all leveraged the same system prompt as\nshown in Box A, and their individual prompting instructions\nare provided in Box B, C and D, respectively.\nB Illustration of Data on CONFACT\nFig 3 presents a sample from the CONFACT dataset. Each\ninstance in CONFACT comprises a question (converted from\nits original claim), a ground-truth answer, and a set of con-\nflicting evidence.\nC Implementation Details\nTo handle long retrieved documents effectively, we apply a\nparagraph-based chunking strategy, where each document is\nFigure 3: A Data Sample from CONFACT\nsplit into passages of at most 256 words. This ensures that\nretrieved evidence remains contextually relevant while fitting\nwithin the token constraints of large language models. For re-\ntrieval and ranking, we use BM25 [Robertson and Zaragoza,\n2009 ]to select the top-5 most relevant paragraphs for each\nclaim. While we experimented with more advanced neural\nranking approaches [Schlichtkrull et al. , 2023 ], we did not\nobserve any significant improvements in our setting.\nInference is performed using the vLLM framework [Kwon\nand others, 2023 ], which optimizes key-value (KV) cache\nmemory for efficient large-scale inference. We conducted\nall experiments with BFloat16 precision on a cluster of\n2\u00d7NVIDIA A100-80 GPUs, employing greedy decod-\ning for response generation. To evaluate RAG-based fact-\nchecking performance, we experiment with three state-of-\nthe-art LLMs: LLaMA-3.1-8B [Dubey et al. , 2024 ], Qwen-\n2-8B [Yang et al. , 2024 ], and Mistral-v0.3-7B [Mistral.AI,\n2023 ]. For methods that leveraging source credibility scores,\nwe set the score threshold \u03b3to 0.3 and the balancing hyperpa-\nrameter \u03b2to 0.8, based on preliminary experiments optimiz-\ning both accuracy and macro-F1 performance.\nAcademic/\nResearchGovernmentMainstream\nNews MediaNon-profit\nOrganisationSocial Media Others\nVery Unreliable 2 0 0 0 3 3\nUnreliable 10 1 27 5 25 34\nNeutral 18 7 231 59 47 95\nReliable 65 74 334 110 15 112\nVery Reliable 20 65 27 33 0 4\nTable 5: Reliability Breakdown for each Media Source Type\nD Limitations\nWe identify three main limitations of our study.\nBias in Source Credibility Annotations. Our credibility an-\nnotations rely on the Media Bias/Fact Check (MBFC) dataset,\nwhich may carry inherent biases. As a result, any systematic\nbias present in MBFC is inherited by our framework and may\ninfluence model behavior during training and evaluation.\nContext-Independent Credibility Assumptions. Our ap-\nproach treats media source credibility as static and context-\nindependent. In reality, a source\u2019s reliability may vary across\ntopics, time periods, or issue-specific reporting. Future work\ncould explore dynamic, context-aware credibility estimation\nmethods to address this limitation.\nSimplified Baselines. While more sophisticated baselines\nthat decompose claims into finer-grained components may\nimprove factual verification, we deliberately adopt a simpli-\nfied setting to isolate the effect of source credibility. Inte-\ngrating decomposition-based approaches remains an impor-\ntant direction for future work.\nE Error Analysis\nWe conduct an error analysis to examine the limitations of\nbest performing RAG-based LLM (Llama-3.1) using GT-\nMB. We randomly sampled 50 cases where the model pro-\nduced incorrect answers and categorized the errors.\nErrors Due to Conflicting or Irrelevant Retrieved Con-\ntexts. These errors occur when the retrieved evidence either\nlacks relevance or presents conflicting claims. For example,\nin response to the question \u201c Has climate change increased\nhurricane frequency? \u201d, one retrieved source affirmed an in-\ncrease, while another refuted it based on different datasets.\nInstead of reconciling the conflicting claims, the model incor-\nrectly aligned with the source that contained more surface-\nlevel keyword matches. This suggests that simple retrieval-\nbased approaches struggle with conflicting evidence, rein-\nforcing the need for advanced ranking methods that assess\nboth relevance and credibility before generating an answer.\nFuture work could explore iterative ranking and selection\nstrategies where the model answers a question only when a\nsufficient set of corroborative evidence is identified.\nErrors from Inaccurate Media Background Estimation.\nThis error type is prevalent in the Hybrid-MB setting,\nwhere automatically generated media backgrounds misclas-\nsify source reliability, leading the model to prioritize mislead-\ning information. For instance, in answering \u201c Has the deficit\ncome down under the Conservatives? ,\u201d the ground truth an-\nswer is Yes, supported by data from Full Fact, a highly cred-\nible source. However, retrieved evidence from Tax ResearchUK, a critical government watchdog, suggested No. Due to\nan erroneous background classification labeling Tax Research\nUK as highly reliable, the model was misled and answered in-\ncorrectly. These findings highlight the risks of relying on gen-\nerated media backgrounds without rigorous validation, em-\nphasizing the necessity of robust source credibility estimation\ntechniques.\nLLM Bias in Resolving Conflicting Evidence. Some er-\nrors stem from the model\u2019s tendency to favor the majority\nviewpoint among retrieved contexts, even when the oppos-\ning evidence is more credible. For example, in cases where\nthree low-credibility sources supported one claim while a sin-\ngle authoritative source contradicted them, the model fre-\nquently defaulted to the majority position. This bias sug-\ngests that LLMs may lack the ability to critically weigh con-\nflicting evidence, underscoring the need for improved rea-\nsoning mechanisms that incorporate source reliability assess-\nments. Mitigating such biases requires integrating structured\nfact-checking methodologies that encourage LLMs to assess\nthe credibility of competing claims rather than defaulting to\nfrequency-based heuristics.\nOverall, these error categories reveal fundamental chal-\nlenges in fact-checking with conflicting evidence. Address-\ning them requires advancements in retrieval ranking, media\nbackground estimation, and bias mitigation to ensure auto-\nmated fact-checking systems align with real-world journalis-\ntic and verification practices.\nF Distribution of Source Credibility\nTable 5 shows the credibility annotations across different\nsource types. We observed over-estimation of credibility for\nmainstream news media by non-expert annotators. They have\nannotated about 95%of mainstream news media as trustwor-\nthy probably due to their popularity. However, journalism\nhave identified 30%of them as incredible.\nG Detailed Implementations for RAG\nMethods\nG.1 Credibility Related Information Extraction\nfrom Background\nE. Prompt to Classify Credibility\nYou are InfoHuntGPT, a world-class AI assistant used by\njournalists to predict the credibility of media sources. Your\ntask is to read the example media sources (with their corre-\nsponding credibility descriptions) and then assess the target\nmedia using only the details provided. Do not include any\nadditional information, and follow these rules strictly:\n1. Read all the information about each example media\nsource and note its final credibility rating.\n2. Examine the target media\u2019s description and any rele-\nvant Wikipedia or article information, if provided.\n3. Determine the target media\u2019s credibility using one of\nthese labels: high ,medium , orlow.\n\u2022Low : The source demonstrates questionable re-\nliability, has a track record of publishing mis-\ninformation, failed fact checks, or lacks trans-\nparency.\n\u2022Medium : The source is generally reliable but\nmay display occasional bias or minor factual is-\nsues, with no consistent pattern of publishing\nfalse information.\n\u2022High : The source consistently provides reliable,\nfactual information, uses proper sourcing, and\nshows little to no history of failed fact checks.\n4. Pay special attention to any indication of failed fact\nchecks or repeated misinformation\u2014this may reduce\ncredibility.\n5. If there is virtually no information or the details ap-\npear highly suspicious, you may conclude low credi-\nbility.\n6. Output only the final credibility assessment for the tar-\nget media (one word: high ,medium , orlow).\n7. Do not provide disclaimers or references to your rea-\nsoning. Do not include any additional commentary.\nProvide the credibility label in one line.\nExample 1\nMedia Description: [Media Background Details]\nWikipedia: [Wikipedia Summary]\nCredibility: [High/Medium/Low]\n...\nExample N\n...\nTarget Media Description : [Media Background De-\ntails]\nTarget Media Wikipedia : [Wikipedia Summary]\nTarget Media Credibility :\nPredicted source background descriptions are detailed and\ncomprehensive, whereas contain irrelevant information about\nthe source credibility (e.g., the founder of a source). Consid-\nering the issue, we further distill the credibility related con-\ntent from the description using the prompt illustrated in BoxE. Specifically, we classify the credibility of a source into\nthree levels: low,medium andhigh, following [Baly et al. ,\n2018 ]. To ensure the accuracy of our automatic source cred-\nibility prediction framework, we further conducted a quanti-\ntative evaluation on [Baly et al. , 2018 ]. Our automatic source\ncredibility prediction framework achieved 70.04% in a zero-\nshot manner.\nG.2 Source Background Incorporation\nF. System Prompt\nYou are given a question and several pieces of evidence.\nYour task is to analyze the evidence and provide a concise\nanswer to the question.\nFor each piece of evidence, the background of its source\nmedia is provided. When evaluating the evidence, it is cru-\ncial to take into account the credibility of the source media,\nas this can significantly influence the reliability of the evi-\ndence. Additionally, consider any potential biases that may\nbe inherent in the source media, especially if they are ex-\nplicitly mentioned. This will help ensure a more nuanced\nand thorough evaluation of the evidence, factoring in both\nthe content and the context in which it is presented.\nG. SBA dir\nEvidence 1: [Evidence text]\nSource Media Description: [Description of the source me-\ndia]\n. . .\nEvidence N: [Evidence text]\nSource Media Description: [Description of the source me-\ndia]\nQuestion: [Question to be answered based on the evidence\nprovided]\nH. SBA CoT\nQuestion: [Question to be answered based on the evidence\nprovided]\nEvidence 1: [Evidence text]\nSource Media Description: [Description of the source\nmedia]\n. . .\nEvidence N: [Evidence text]\nSource Media Description: [Description of the source\nmedia]\nGiven the above evidence, first explain your reasoning for\nany contradictions or conflicting information. After your\nreasoning, provide your final answer to the question. Start\nyour answer with \u2019Final Answer\u2019 and clearly separate it\nfrom the rest of your analysis. Your final answer should\nbe either \u2019yes\u2019 or \u2019no\u2019. Include only one final answer, and\navoid adding any additional explanation after it.\nOutput format:\nAnalysis: [Your reasoning here]\n#*# Final Answer: [yes/no]\nQuestion...Supporting \nEvidence\nQuestionEvidence 1  \nEvidence N  Refuting \nEvidence\nCategorizing Evidence LLMLLM\nFinal Answer\nGenerating AnswerFigure 4: Workflow of the Ensemble Method.\nI. SBA exp\nQuestion: [Question to be answered based on the evidence\nprovided]\nSome evidence below may have been perturbed with wrong\ninformation. Find the perturbed passages and ignore them\nwhen eliciting the correct answer.\nEvidence 1: [Evidence text]\nSource Media Description: [Description of the source\nmedia]\n. . .\nEvidence N: [Evidence text]\nSource Media Description: [Description of the source\nmedia]\nFirst, thoroughly analyze all the provided evidence before\nmaking your final decision. Identify the perturbed sen-\ntences and carefully consider their implications in your\nanalysis. Once you have completed your review, provide\nyour final answer to the question based on the evidence\nyou analyzed. Start your answer with \u2019Final Answer:\u2019 and\nensure it is clearly separated from your evidence analysis.\nYour final answer should be either \u2019yes\u2019 or \u2019no\u2019. Make\nsure to include only one final answer, and do not include\nany additional text after it.\nWhen incorporating source background in the generation\nstage of RAG methods, for the SBA dir, SBA CoTand SBA exp\nsettings, the source-aware paragraphs (i.e., concatenation of\nthe paragraph and the background description of its source)\nserve as the augmented context for answer generation, while\nusing different instructions. In SBA CoT, the model is re-\nquired to provide a rationale besides the answer; in SBA exp\nthe model is explicitly instructed to ignore augmented texts\nfrom incredible sources. Detailed prompts are shown in Box\nG and H.\nFor the SBA enssetting, a two stage prompting mechanism\nis exploited. As illustrated in Fig 4, we first employ a LLM\nto categorize each piece of evidence as either supporting or\nrefuting (Box J). Next, we prompt the LLM to generate the\nfinal answer using the categorized evidence (Box K).J. SBA ens: Categorizing Evidence\nFor each piece of evidence, the background of its source\nmedia is provided. When evaluating the evidence, it is cru-\ncial to take into account the credibility of the source media,\nas this can significantly influence the reliability of the evi-\ndence. Additionally, consider any potential biases that may\nbe inherent in the source media, especially if they are ex-\nplicitly mentioned. This will help ensure a more nuanced\nand thorough evaluation of the evidence, factoring in both\nthe content and the context in which it is presented.\nQuestion: [Question to Answer]\nSupporting Evidence:\n- Sentence: [Sentence/Paragraph]\n- Credibility Analysis: [Description of the source media]\n. . .\nRefuting Evidence:\n- Sentence: [Sentence/Paragraph]\n- Credibility Analysis: [Description of the source media]\n. . .\nGiven the above support and oppose evidence, first explain\nyour reasoning for any contradictions or conflicting infor-\nmation. Your analysis should be no more than 500 words.\nPlease ignore the difference in the amount of supporting\nand opposing evidence and choose more detailed and truth-\nful sentences of evidence. Once you have completed your\nanalysis, provide your final answer to the question based on\nthe evidence you analyzed. Start your answer with \u2019Final\nAnswer:\u2019 and ensure it is clearly separated from your evi-\ndence analysis. Your final answer should be either \u2019yes\u2019 or\n\u2019no\u2019. Make sure to include only one final answer, and do\nnot include any additional text after it.\nK. SBA ens: Generating Final Answer\nInstructions\n1.Comprehend the Question:\n\u2022 Carefully read the question to understand what\nis being asserted.\n\u2022 Identify the key components and assertions\nwithin the question.\n2.Analyze the Sentence:\n\u2022 Examine the sentence to see how it relates to the\nquestion.\n\u2022 Determine if the sentence provides evidence, an\nexample, or a counterpoint to the question.\n\u2022 Look for keywords or phrases that directly sup-\nport or refute the question.\n3.Evaluate the Media Background:\n\u2022 Review the media background information to\nunderstand the broader context.\n\u2022 Consider the credibility of the sources men-\ntioned and any potential biases.\n\u2022 Identify any historical information or prior\nevents that relate to the question.\n4.Integrate Information:\n\u2022 Combine insights from the sentence and media\nbackground.\n\u2022 Assess whether the sentence, in the context of\nthe media background, provides sufficient sup-\nport for the question.\n\u2022 Consider if there are contradictions or align-\nments between the sentence and the media back-\nground.\n5.Logical Reasoning:\n\u2022 Use critical thinking to evaluate the connections.\n\u2022 Ask yourself if the evidence logically leads to\nthe conclusion stated in the question.\n\u2022 Consider alternative interpretations or whether\nadditional information is needed.\n6.Conclude:\n\u2022 Evaluate the reliability of the media background\nand determine whether the sentence supports the\nquestion.\n\u2022 Ensure that your conclusion is based solely on\nthe information provided.\n7.Answer:\n\u2022 Optionally, provide a justification based on the\nabove steps, explaining your reasoning. Keep\nyour justification under 300 words.\n\u2022 Provide a clear and concise Yes orNoanswer\nto the question.\nQuestion: [Question to Answer]\nEvidence: [Evidence]\nMedia Background Analysis: [Source Media Description\nof the Evidence Provided]\nBased on the provided sentence and the media background,\nbegin by thoroughly analyzing the evidence, giving special\nattention to the credibility and potential biases of the media\nsource. After your analysis, provide your final answer to\nthe question. Start your answer with \u2019Final Answer:\u2019.H Annotation Instructions\nParticipants were presented with a claim and a corresponding\nURL linking to an online article or post. They were instructed\nto visit these URLs, review the content, and assess whether it\nsupported or contradicted the claim. Following this evalua-\ntion, they were required to rate the source\u2019s credibility and\nclassify its type. Figure 5 illustrates a screenshot of the user\nlabeling process.\nFigure 5: Screenshot of Annotation Platform\nI Media Background Prediction\nI.1 Demonstrations for Media Background\nPrediction.\nAs shown in Fig 6, to build a media background for an un-\nknown media source, we begin by gathering foundational in-\nformation: specifically, we collect 10 article titles from the\nsource and compile its Wikipedia summary to form an initial\nguess. Next, following the method in [Schlichtkrull, 2024 ],\nwe conduct a structured Google search using 42 targeted\nqueries about the media, collecting the resulting answers to\nsupplement our initial information. Finally, we incorporate\nthese newly acquired insights into the initial hypothesis to\nproduce a comprehensive, final media background descrip-\ntion. An example of predicted media background is shown in\nBox L.\nGather Inputs\nArticle Titles\nWikipedia InfoGoogle Search\nQuestion 1 \n...\nQuestion 42\nMedia BackgroundUpdate initial guess \nwith additional informationInitial Guess AnswersLLM\nLLM\nLLMAnswer questions \nbased on search resultsGenerate initial guess                  Source Media\nDomainFigure 6: Illustration of the process to generate the media back-\nground by LLMs.\nL. Generated Description for the Source Media\nHistory: Oxford University Press OUP is one of the oldest\nand largest university presses in the world, with a history\ndating back to 1586. academic.oup.com is the online\nplatform for OUP that hosts a vast collection of scholarly\njournals, books, and articles.\nFunded by/Ownership: OUP is a department of the Uni-\nversity of Oxford and is self-funded through the sales of its\npublications.\nAnalysis/Bias: The platform, academic.oup.com ,\npublishes peer-reviewed journals and books from a wide\nrange of disciplines, including humanities, social sciences,\nand natural sciences. The editorial process for these pub-\nlications is rigorous and follows the highest standards of\nacademic integrity. While the platform may have a slight\nbias towards the perspectives of its authors and editors, it\nstrives to provide balanced and informative content.\nFailed Fact Checks: Oxford University Press has no\nrecord of any failed fact-checks. They are considered a rep-\nutable source of academic information. They have over 300\njournals and a range of books that cover most disciplines.\nI.2 Credibility Score Prediction\nWe utilize the MBFC dataset to train a model for predicting\nmedia credibility scores. The dataset consists of media de-\nscriptions paired with credibility scores.\nThe BigBird-RoBERTa model serves as the backbone of\nour architecture, combined with a regression head to output\ncredibility scores. After training on the MBFC dataset, the\nmodel is evaluated and used to predict credibility scores for\nnew media descriptions.Set. Meth.4o-mini\nAcc. F1\nBal. CoT 78.23 70.42\nGT CoT 79.05 71.33\nTable 6: Additional Experiment Results using the 4o-mini Model\nJ Additional Experiment Results\nWe conducted additional experiments using the GPT-4o-mini\nmodel under the top 5 paragraphs setting. The results are pre-\nsented in Table 6. The results showed the conflicting evidence\nin fact-checking is also challenging to strong closed-source\nLLMs, indicating the need for source-critical fact-checking\nmethods.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Resolving Conflicting Evidence in Automated Fact-Checking: A Study on Retrieval-Augmented LLMs", "author": ["Z Ge", "Y Wu", "DWK Chin", "RKW Lee", "R Cao"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "Large Language Models (LLMs) augmented with retrieval mechanisms have demonstrated  significant potential in fact-checking tasks by integrating external knowledge. However, their"}, "filled": false, "gsrank": 34, "pub_url": "https://arxiv.org/abs/2505.17762", "author_id": ["", "XIyHTG0AAAAJ", "", "uQxdOlsAAAAJ", "pwYGonwAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:5NMZttNBe5AJ:scholar.google.com/&output=cite&scirp=33&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D30%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=5NMZttNBe5AJ&ei=CrWsaIYfwNmJ6g-p2qHxBQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:5NMZttNBe5AJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2505.17762"}}, {"title": "Assessing Media Bias in Cross-Linguistic and Cross-National Populations", "year": "2021", "pdf_data": "Assessing Media Bias in Cross-Linguistic and Cross-National Populations\nAllan Sales,1Albin Zehe,2Leandro Balby Marinho,1Adriano Veloso,3Andreas Hotho2andJanna\nOmeliyanenko2\n1Federal University of Campina Grande\n2University of W \u00a8urzburg\n3Federal University of Minas Gerais\nallanmelo@copin.ufcg.edu.br, zehe@informatik.uni-wuerzburg.de, lbmarinho@computacao.ufcg.edu.br,\nadrianov@dcc.ufmg.br, hotho@informatik.uni-wuerzburg.de, janna.omeliyanenko@uni-wuerzburg.de\nAbstract\nMedia bias is a worldwide concern. Although automated\nmethods exist for the analysis of various forms of media bias,\nlanguage is still an important barrier toward spotting world-\nwide differences in reporting. In this paper, we propose a\nmethodology based on word embeddings, lexicon translation,\nand document similarity to assess media bias in news articles\npublished in different idioms. We model media bias under the\nperspective of subjective language use, i.e., the more subjec-\ntive the content of a news article is, the more biased it is.\nOur core assumption is that news articles reporting the same\nevents, but written in different languages, should have similar\nlevels of subjectivity; otherwise, we may have spotted biased\ntext. Our method consists of using translated versions of sub-\njectivity lexicons that were originally constructed for mea-\nsuring subjectivity in the Brazilian Portuguese language. We\nevaluate our approach on two labeled data sets to show that\nour method is valid and apply our methodology to analyze\nrecent and largely resounded topics, such as the Venezuela\ncrisis and Syrian war, on four distinct idioms: Portuguese,\nGerman, English, and Spanish.\nIntroduction\nIn his bestseller book, \u201cBias: A CBS Insider Exposes How\nthe Media Distort the News\u201d (Goldberg 2014), Bernard\nGoldberg exposes how the news media industry ignored a\nfundamental premise in journalism: providing objective and\ndisinterested reports. A key message from his book is that,\nin many cases, media is intentionally reporting facts charged\nwith biased opinion. This may exert great in\ufb02uence on read-\ners whose own biases may be reinforced or shaped. While\nmedia bias analysis has a long tradition in social sciences\nand communication, only in recent years it has attracted in-\nterest from the computer science and computational linguis-\ntics communities.\nThe literature distinguishes among different types of me-\ndia bias, among which the most usual are statement and\nframing. The Statement Bias is the preference for express-\ning oneself more (or less) favourable about a certain subject\n(e.g., party and politician) (Saez-Trumper, Castillo, and Lal-\nmas 2013). The Framing effect (or framing bias) is related\nCopyright \u00a9 2021, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.tohow the information is conveyed to the readers, in order\nto in\ufb02uence their judgment on a given topic (Entman 2007).\nAlthough there is a broad and interdisciplinary body of\nwork on media bias analysis, these works are still limited in\ntheir cross-language and country compatibility. Each coun-\ntry has its own news outlets producing news charged with the\nshared qualities that de\ufb01ne its population, such as language\n(or dialect) and geography. While most of the works found\nin the reviewed literature focus on speci\ufb01c countries or lan-\nguages, spotting news reporting differences across different\ncountries and languages remains an open research question.\nIn this paper, we introduce a new methodology based on\nlexicon translation, word embeddings, document similarity,\nand a parallel corpus for large-scale assessment of media\nbias in cross-language populations. We characterize media\nbias in terms of subjectivity bias. In order to perform frame\nanalysis on news articles, two broad questions are usually\nasked (Entman 1993): (1) What information is conveyed? (2)\nHow is that information conveyed? These questions de\ufb01ne\naframe (Hamborg, Donnay, and Gipp 2018), which is our\nunit of study. In this paper, we \ufb01x (1) to recent and largely\nresounded topics worldwide: the Venezuela crisis and the\nSyrian war. Next, we propose a new subjectivity measure to\nanswer (2). This measure addresses the challenge of calcu-\nlating comparable subjectivity scores across news written in\ndifferent languages.\nOur methodology relies on the translation of handcrafted\nsubjectivity lexicons, initially constructed for the Brazilian\nPortuguese language, to other languages (i.e., German, En-\nglish, and Spanish). The fact that subjectivity lexicons are a\nset of independent words that do not compose meaning en-\nables their discrete translation. Our methodology relies on\ntwo main premises: (i) the unprecedented accuracy of cur-\nrent machine translators and (ii) word embeddings that can\nmitigate eventual translation imprecision. That is, even when\nthe expressions in the lexicons and target textual documents\ndo not match in a syntactic level, they shall be close to each\nother in the semantic space induced by the embedding.\nA variety of factors might be associated with the language\nsubjectivity, such as the structure of the linguistics (Kris-\ntiansen, Garrett, and Coupland 2005). Therefore, one issue\nthat we need to consider in the construction of a score that is\ncomparable across languages is that some languages may be\ninherently more subjective than others, and thus their subjec-\nProceedingsoftheFifteenth InternationalAAAIConferenceonWebandSocial Media(ICWSM2021)\n561\nSubjectivity reference score (europarl corpus)\nNorm\nNormNormNormS0\nS0\nS0\nS0wmd Portuguese\nwmd English\nwmd Spanishwmd GermanInput Text\n(word embeddings)\nS1\nS1\nS1Parallel lexicons (word embeddings)\nS1Normalized\nSubjectivity scoresS ref S ref S ref S ref\nSubjectivity\nnormalization \nstageSubjectivity\ncomputation\nstageFigure 1: Task description. Given distinct sets of news articles and subjectivity lexicons in different languages, we compute\nthe news articles\u2019 subjectivity bias as the Word Mover\u2019s Distance to their respective language subjectivity lexicon (Subjectivity\ncomputation stage). In order to remove the base subjectivity of the language, we calculate a normalized subjectivity bias by\nsubtracting the values from a pre-computed subjectivity reference value of their language derived from the parallel Europarl\ncorpus (Subjectivity Normalization Stage).\ntivity biases may not be directly comparable. For overcom-\ning that, we propose to model subjectivity bias as a combina-\ntion of the interlocutor (e.g., writer or speaker) subjectivity\nand the language subjectivity (i.e., the level of subjectivity\nthat is inherent to the language). We rely on a parallel cor-\npus1from where we extract reference subjectivity bias val-\nues (or normalization factors) for each target language. Fig-\nure 1 summarizes our methodology (see Section for more\ndetails). Given a set of topic-wise similar news articles writ-\nten in distinct languages, we compute their distances to their\nrespective subjectivity lexicons in a word embedding space\nand normalize the results considering a precomputed sub-\njectivity reference value from the parallel corpus. Our main\ncontributions can be summarized as follows:\n\u2022 We introduce a new media bias metric that disentangles\nlanguage subjectivity from interlocutor subjectivity. This\nenables us to compute and compare media bias in cross-\nlinguistic and cross-national populations.\n\u2022 We conduct a thorough validation of our methodology,\nshowing that: (i) it is able to correctly distinguish between\nobjective and subjective text, and (ii) it is comparable to\nan approach that translates the whole text in another id-\niom to Portuguese (instead of translating the lexicons in\nPortuguese to the target idiom as we propose to do).\n\u2022 We apply our method to analyze news in various id-\nioms about two largely resounded topics worldwide: the\nVenezuela crisis and Syrian war. This leads to interesting\ninsights about the level of bias that different countries ex-\n1A parallel corpus is a corpus that contains a collection of texts\nin one language and their translations into a set of other languages.hibit in their news articles about these topics (e.g., News\narticles published in Brazil addressing the Venezuela Cri-\nsis are more subjective than the ones addressing the Syr-\nian War).\nBackground: Subjectivity and Bias\nIn order to provide a clear basis for our analysis, this section\ndetails our understanding of what makes a text subjective\nand introduces the terminology that we use in this paper.\nThe Normative Theory of Journalism is concerned with\nwhat the media should do in society (Benson 2008). Ac-\ncording to (Siebert et al. 1956) in their book Four Theo-\nries of the Press, \u201cthe press takes on the form and coloration\nof the social and political structures within which it oper-\nates\u201d (pp.1-2). Given that we use news articles written in\nlanguages spoken mostly by European and American coun-\ntries, we are probably transiting between two kinds of Nor-\nmative theories: Free press theory andSocial responsibility\ntheory. Still according to (Siebert et al. 1956), the free press\ntheory (mostly adopted in the US), states complete freedom\nof speech and economic operation of the media, dismissing\nany interference of the government. The social responsibil-\nity theory (mostly adopted in European countries), in turn, is\nsimilar to the free press theory but places greater emphasis\non the accountability of the media.\nAlthough there may be differences in the dominant ideas\nabout the obligations of mass media in different societies,\nmedia organizations of different nations typically share\nmany common ethical standards including the principles\nof truthfulness, accuracy, objectivity, impartiality, fairness,\nand public accountability. We propose an automatic method-\n562\nology for shedding light on these differences concerning the\nobjectivity principle.\nDimensions of Subjectivity Before delving into our pro-\nposed methodology, we \ufb01rst need to de\ufb01ne what we re-\ngard as subjective language. Similar to (Amorim, Canc \u00b8ado,\nand Veloso 2018; Sales, Balby, and Veloso 2019), we study\nsubjectivity under \ufb01ve subjectivity dimensions: argumenta-\ntion, presupposition, sentiment, valuation, and modalization.\nThese lexicons were constructed anchored in the pragmatics\ntheory and (Recasens, Danescu-Niculescu-Mizil, and Juraf-\nsky 2013). According to (Verhagen 2005), the theory of ar-\ngumentation and pragmatics assume implicit markers of po-\nsitioning in language as clues to the speakers subjectivity.\nIn the following, we brie\ufb02y de\ufb01ne each dimension and give\nexamples of expressions that characterize it.\n\u2022Argumentation aims to identify argumentative discourse\nin text, which might be indicative of an attempt to con-\nvince the reader of a speci\ufb01c point of view. E.g., \u201ceven\u201d\nand \u201cby the way\u201d;\n\u2022Presupposition contains expressions related to a prior as-\nsumption of something\u2019s veracity. This kind of discourse\nis characterized by the interlocutor\u2019s veracity assumption\nof something before the current event he/she is mention-\ning. E.g., \u201cnowadays\u201d and \u201cadmit\u201d;\n\u2022Sentiment implies appealing to an emotional discourse,\nnot necessarily positive or negative. E.g., \u201cfall in love\u201d\nand \u201cfear\u201d;\n\u2022Valuation is related to giving value or intensifying some-\nthing. E.g.: \u201ca lot\u201d, \u201cbetter\u201d and \u201cbig\u201d;\n\u2022Modalization shows that the author takes an attitude\ntowards his/her judgment. E.g., \u201cundeniable\u201d and \u201cun-\ndoubted\u201d.\nSubjectivity Bias Amorim et al. (Amorim, Canc \u00b8ado, and\nVeloso 2018), together with Brazilian Portuguese linguists,\nbuilt lexicons for each of the dimensions mentioned above\nin the Brazilian Portuguese language. These enable us to\nuse several ways for measuring subjectivity of textual docu-\nments written in Portuguese, e.g., counting the occurrences\nof the words of each lexicon in the document, using tf-idf\nlike scores, or calculating similarities between texts and sub-\njectivity lexicons in some vector space. In the latter case, the\ncloser the documents and lexicons are, the more subjective\nthe documents are. We refer to the calculated similarities us-\ning lexicons as subjectivity bias.\nWe consider the subjectivity bias to be composed of two\nparts: the language subjectivity (caused by the language) and\ntheinterlocutor subjectivity (caused by the author). If we\nwant to compare the subjectivity of news articles in differ-\nent languages, we therefore need to do a normalization step\nto remove the language subjectivity and only compare the\ninterlocutor subjectivity.\nRelated Work\nThere is a large body of work in media bias analysis. While\ncommunications and social sciences have a long tradition inthis area, it has been attracting a lot of attention from the\ncomputer science and computational linguistics communi-\nties. Hamborg et al. (Hamborg, Donnay, and Gipp 2018) put\ntogether a thorough review of media bias analysis, covering\nthe existing literature and also establishing synergy points\nbetween social and computer sciences.\nOn the side of news analysis, there is extensive lit-\nerature on distinct media bias types, such as jour-\nnalistic biases (e.g., selection and coverage), con\ufb01rma-\ntion/statement bias (Lazaridou, Krestel, and Naumann 2017;\nSaez-Trumper, Castillo, and Lalmas 2013; Lin, Bagrow, and\nLazer 2011; Nickerson 1998; Dallmann et al. 2015), psy-\nchological/cognitive biases (Recasens, Danescu-Niculescu-\nMizil, and Jurafsky 2013; Caliskan, Bryson, and Narayanan\n2017), and subjectivity bias (Sales, Balby, and Veloso 2019;\nMihalcea, Banea, and Wiebe 2007; Chaturvedi et al. 2018).\nMost of the works regarding framing bias detection\nare based on sentiment analysis, which aims to identify\nan author\u2019s opinion toward some entity mentioned in the\ntext (Oelke, Geisselmann, and Keim 2012; Mundim 2018;\nDe Cock et al. 2018). However, state-of-the-art sentiment\nanalysis methods on news articles still perform poorly, given\nthe lack of clearly de\ufb01ned targets and large-scale news anno-\ntated data sets for training machine learning methods (Bal-\nahur et al. 2013; Hamborg, Donnay, and Gipp 2018).\nMore recently, some researchers have proposed new alter-\nnatives for assessing framing bias apart from sentiment anal-\nysis. The authors of (Card et al. 2016), for example, trained\na logistic classi\ufb01er using unigrams, bigrams, and personas\n(e.g., characterizations of entities) as features for identify-\ning the primary frame (the emphasized dominant aspect) of\nnews articles. The classi\ufb01er received, as input, manually an-\nnotated news articles about immigration with 15categories\nof framing bias, such as Economic and Politics. The au-\nthors of (Bai et al. 2018), in turn, introduced an improve-\nment of the Matrix Factorization Method, where they apply\na jointed penalty function for detecting whether frames over\nillegal immigration change over time. Differently from these\nworks, we rely on an unsupervised approach given the dif\ufb01-\nculty in \ufb01nding and/or assembling annotated biased data.\nSales et al. (Sales, Balby, and Veloso 2019) propose a\nholistic approach for analyzing the textual content of news\nstories about three consecutive Brazilian Presidential elec-\ntions in search of three kinds of bias: coverage, associa-\ntion, and subjectivity. For computing subjectivity bias, they\napplied the Word Mover\u2019s Distance (WMD) (Kusner et al.\n2015) between each news article of interest and each of\n\ufb01ve subjectivity lexicons containing expressions associated\nwith different subjectivity dimensions. A limitation of this\napproach is that it is not applicable across multiple lan-\nguages. In this paper, we address this issue by proposing\na new methodology that yields comparable scores for texts\nin different languages, enabling us to analyze the difference\nin subjectivity across multiple countries and languages. To\nthis end, we (1) point out some constraints that need to be\nsatis\ufb01ed when translating the lexicons, (2) provide lexicon\ntranslations that satisfy these constraints for three additional\nlanguages, and (3) introduce a normalization stage ensuring\nthe comparability of the scores across multiple languages.\n563\nSome works have proposed to detect subjective language\nin a multilingual setting (Chaturvedi et al. 2015, 2018).\nHowever, subjectivity in those works is related to the task\nof classifying a news article as either neutral or opinionated\n(e.g., positive or negative). In our work, subjectivity is de-\n\ufb01ned in a broader and more transparent sense that goes way\nbeyond positive or negative polarities.\nThe related works mentioned above reveal several solu-\ntions available to expose media bias. Differently from us,\nmost of the works in this area are focused on single lan-\nguages, and the ones that deal with multilingual settings,\nsuch as (Chaturvedi et al. 2015), only consider English and\nSpanish. With our contributions, we expect to pave the way\nto more effective, fast, and transparent methods for the au-\ntomated detection of media bias across different languages.\nDatasets\nThis section describes the data collection process as well\nas the kind of data that was collected. It includes two data\nsets of news (one where we apply our methodology and\nother for the validation), one data set annotated with sub-\njective/objective labels (which we have used to validate our\nmethodology), Wikipedia corpora in all languages consid-\nered (which we use to train word embeddings and validate\nour methodology), and the parallel Europarl corpus (used to\nderive subjectivity reference values).\nWebhose News\nWebhose is a company specialized in turning unstructured\nweb content into structured data. They provide several news\narticles data sets in distinct languages crawled from several\nsections of different news outlets2. Nesta pesquisa n \u00b4os uti-\nlizamos os datasets com not \u00b4\u0131cias em alem \u02dcao, ingl \u02c6es, por-\ntugu\u02c6es e espanhol\nN\u00b4os rotulamos cada not \u00b4\u0131cias de cada dataset\nIn order to validate our methodology, we labeled each\nnews article in the data set as \u201cinformative\u201d or \u201copinion-\nated\u201d. For that, we have manually de\ufb01ned sets of keywords\nthat indicate opinionated news and searched whether the\nnews article URL contains one or more of these keywords.\nThe keywords are distinct for each language (English:\nblog, opinion, column; Portuguese: blog, coluna, opiniao\n(opini \u02dcao); German: kolumne, meinung, kommentar; Span-\nish: blog, editor, editorial, opinion (opini \u00b4on)).\nFor our experiments, we randomly sampled 1;200\n(roughly the size of the smallest category, i.e., opinionated\nPortuguese news) articles from each category (opinionated\nand informative) and language.\nEventRegistry News\nFor building a data set containing news about the Venezuela\nCrisis and Syrian War, we used a news monitor named\nEventRegistry3. EventRegistry enables one to search news\nby keywords or by topics, such as \u201cpolitics\u201d.\nWe submit either the keyword \u201cVenezuela\u201d or \u201cSyria\u201d\n(considering their respective translations to all considered\n2https://webhose.io/free-datasets/\n3http://eventregistry.org/idioms) to EventRegistry and \ufb01lter the news published in the\npolitics sections that contain one or more words in their body\nindicating that the article is addressing the \u201cSyrian War\u201d or\nthe \u201cVenezuela Crisis\u201d topic.\nFor that, we select a set of keywords that are strongly re-\nlated to these topics. We use the words \u201cwar\u201d and \u201ccrisis\u201d,\nrespectively, as initial keywords for the two topics. These\nwere selected as the most representative words for the top-\nics based on the autocomplete feature of Wikipedia: when\nentering \u201cVenezuela\u201d in the search bar, Wikipedia suggests\nthe article \u201cVenezuelan Presidential Crisis\u201d; for \u201cSyria\u201d it\nsuggests \u201cSyrian Civil War\u201d. This may provide a good hint\nof how these topics are reported by the media. To consider\nalternative ways of how these topics might be reported by\nthe media in each language, we expanded the initial set of\nkeywords by adding the most similar words according to a\nword embedding. For each language, we trained a word em-\nbedding model on all news articles related to the topic (e.g.,\nwe trained a skip-gram model on all English texts returned\nby EventRegistry for the query \u201cVenezuela\u201d) and selected\nall words that have a cosine similarity above the (empirically\nde\ufb01ned) threshold of 0:6to the seed words. For the English\nmodels, we end up with \u201ccon\ufb02ict\u201d and \u201cstrife\u201d as the two\nmost similar words to \u201cwar\u201d, while \u201ccrises\u201d and \u201cturmoil\u201d\nare the most similar to \u201ccrisis\u201d.\nFor each article we hold information about headline, tex-\ntual body, publication date, country, topic, URL and lan-\nguage. The resulting data set contains 13:102 news arti-\ncles published in 126 distinct countries by 1:654 distinct\nnews outlets, from which 9:004 refer to the Venezuela Cri-\nsis and 4:098 to the Syrian War. News published in Por-\ntuguese, German and English cover the period of time from\n03/10/2019 to 08/26/2019, while news in Spanish range\nfrom 07/20/2019 to 08/26/2019. Figure 2 illustrates the dis-\ntribution of news articles by country, language and topic.\nUnited StatesUnited KingdomIndiaCanada\nTurkey IsraelEgyptSyriaFrance\nRussia Nigeria Iran\nGermanySwitzerlandBrazil\nUnited StatesCanadaIndiaUnited Kingdom\nIsrael RussiaBrazilPortugal\nVenezuela SpainPeruMexicoGermanySyria Venezuela\nlang eng ger por spa\nFigure 2: Distribution of news articles by country, language\nand topic. The larger the cell area, the higher the number of\nnews articles published in that country.\nEuroparl Corpus\nThe Europarl4is a corpus containing parliamentarians\u2019\nspeeches from the European Union parliament manually\n4https://www.statmt.org/europarl/\n564\ntranslated into all 21European languages. The corpus is\ncommonly used for automatic language translation tasks.\nIn this research, we use the German, English, Portuguese,\nand Spanish versions of the Europarl corpus for building a\nsentence aligned corpus, in which each speech in our cor-\npus could be found translated into the other languages. We\nassume that, due to the careful translations that are required\nin the parliament, the subjectivity level in the translations\nshould be as close as possible to the original version. We\nuse this corpus as a reference for our normalization proce-\ndure (see Section for further details).\nSubjectivity Dataset v1.0\nThe Subjectivity Dataset v1.05(Pang and Lee 2004) (SDv1)\nis a movie review data set commonly used for subjectivity\nclassi\ufb01cation tasks. It contains 5:000 sentences from IMDb\nplot summaries, labeled as \u201cObjective\u201d, and 5:000 from\nsnippets from the Rotten Tomatoes pages, labeled as \u201cSub-\njective\u201d. We removed sentences not written in English6from\nthe data set, ending up with 4:985 Objective and 4:963 Sub-\njective sentences. As with the Webhose data set, in Section\nwe show that our methodology is able to \ufb01nd signi\ufb01cant dif-\nferences in subjectivity between the Objective and Subjec-\ntive sentences.\nWikipedia\nWe downloaded the English, Portuguese, Spanish, and Ger-\nman Wikipedia dumps dated June 1st, 2019, and extracted\nthe running text out of it.7Wikipedia promotes content poli-\ncies to enforce a neutral point of view. Moreover, Wikipedia\narticles are built collaboratively and are open for review,\nwhich naturally tends to lead to unbiased articles (Green-\nstein and Zhu 2012). Due to this comparatively high degree\nof neutrality, we use the Wikipedia corpus both as a resource\nfor training word embeddings and as an unbiased compari-\nson corpus.\nMethodology Description\nIn this section, we present our methodology in more detail\n(depicted in Figure 1).\nThe methodology is composed of three stages:\n1) Deriving parallel subjectivity lexicons for all languages in\nour data sets. Here, we translate the original Portuguese\nlexicons to all target languages, pointing out and satisfy-\ning a set of constraints that are necessary for the transla-\ntion.\n2) Computing subjectivity bias, depicted on the left-hand\nside of Figure 1. Here, we calculate the subjectivity bias\nseparately for each news article in our data sets based on\nthe subjectivity lexicons of its language.\n3) Calculating normalized subjectivity bias, depicted on the\nright-hand side of Figure 1. We use language subjectivity\nbias to normalize the subjectivity biases calculated in the\n5http://www.cs.cornell.edu/people/pabo/movie-review-data/\n6According to langdetect, https://pypi.org/project/langdetect/\n7https://github.com/Kyubyong/wordvectors\nA\ufb01nal After all Immerhin Al \ufb01n y a cabo\nComo se As if Als ob Como siPois Because Puesto que DennFigure 3: Example of a subset of the argumentation sub-\njectivity lexicon in Brazilian Portuguese translated into En-\nglish, German, and Spanish, respectively.\nprevious stage, in order to make them comparable across\nthe distinct languages. This step is necessary because dif-\nferent languages may be generally more subjective than\nothers (see Section ).\nDeriving Parallel Subjectivity Lexicons\nThis step is concerned with deriving parallel lexicons for\nall languages present in our data sets from the original Por-\ntuguese subjectivity lexicons. Parallel lexicons, in this re-\nsearch, can be understood as a set of lexicons translated into\nmultiple languages8. Figure 3 depicts an example of parallel\nlexicons.\nWe perform the lexicon translation in two steps, an auto-\nmatic translation step and a manual post-processing step, as\nshown in (Banea, Mihalcea, and Wiebe 2013):\n1.Translation: We translate the Portuguese lexicons into\nthe other languages using the automatic translation tool\nDeepL9, which has been obtaining comparable perfor-\nmance to the Google Translate system (Macketanz et al.\n2018). Also, the company provides a BLEU score com-\nparing itself to other companies on their website.10\n2.Post-Processing: For our method to perform correctly, we\nneed to perform deduplication on the translated words and\nensure that all translated lexicons contain an equal num-\nber of words (see below). We do this by updating dupli-\ncated words based on an online dictionary (e.g., Pons11).\nWe went through the translated lists of words, searched\nfor duplicate words, and tried to \ufb01nd alternative transla-\ntions. If we could not \ufb01nd an alternative translation, we\nrandomly removed one of the words in the original lexi-\ncon that led to duplicates in the translation. As an exam-\nple, consider the Portuguese words \u201caturdir\u201d and \u201cator-\ndoar\u201d, which translate to German as \u201cbet \u00a8auben\u201d (to stun).\nSince we cannot \ufb01nd an alternative translation for \u201catur-\ndir\u201d or \u201catordoar\u201d, then we randomly remove one of them\nfrom the lexicon set.\nThe post-processing step is necessary to ful\ufb01ll the follow-\ning requirements for creating parallel subjectivity lexicons\naccording to our method.\nFirst, lexicons representing the same subjectivity dimen-\nsion (e.g. argumentation) must have the same length in all\n8The concept is analogous to the \u201cparallel corpus\u201d but using\nlexicons instead of text documents.\n9https://www.deepl.com/\n10https://www.deepl.com/quality.html\n11https://en.pons.com/translate\n565\nlanguages. We show in Section that WMD (Kusner et al.\n2015) (the method in charge of computing the subjectivity\nscores) would return slightly different results if the underly-\ning lexicons have different sizes.\nSecondly, all expressions of one lexicon must be unique\nfor that lexicon, meaning that we will not \ufb01nd repeated\nwords in one lexicon in any language. This requirement is\nessential because if we keep duplicated words in the lexi-\ncon, the word will in\ufb02uence the subjectivity score more than\nit should. For example, if we compute the distance between\nthe piece of text \u201cthe book is on the table\u201d and the lexicon\n\u201cbook book\u201d the method will return a higher subjective bias\nthan if the lexicon was \u201cbook novel.\u201d\nAs a consequence of these requirements, if we cannot \ufb01nd\na unique translation of the Portuguese word in all languages,\nwe remove that word from our analysis. After these two\nsteps, we end up with \ufb01ve equally sized, deduplicated sub-\njectivity lexicons for each language.\nAfter this deduplication, the argumentation lexicon de-\ncreased from 110 to88expressions, presenting the most\nsigni\ufb01cant decrease. This is somewhat expected since the\nargumentation set contains the more complex expressions\n(expressions composed of two or more words) over all lexi-\ncons, making it harder to \ufb01nd synonyms or alternative trans-\nlations. The sentiment lexicon decreased from 153to138ex-\npressions. Since many words in Portuguese are synonyms, it\nbecomes challenging to \ufb01nd the same amount of synonyms\nin all other languages. The modalization lexicon presented\nthe smallest decrease from 55to54expressions, while the\nvaluation and the presupposition suffered no decrease and\nremained with 81and54expressions, respectively. While\nthere might be a loss of detectable subjectivity in the Por-\ntuguese language, caused by the removal of some words\nfrom the original Portuguese lexicons, we show in Section\nthat, in practice, this loss is negligible.\nComputing Subjectivity Bias\nThis step performs the subjectivity bias computation for\neach language. For that, we use the method introduced by\nSales et al. (Sales, Balby, and Veloso 2019) for comput-\ninginverse subjectivity bias (ISB) scores for each language,\nwhich we will then normalize to make it comparable across\nlanguages in the next stage.\nGiven a word embedding model, \ufb01ve lexicons represent-\ning \ufb01ve subjectivity dimensions and a set of news articles,\nthe method relies on a word embedding model for comput-\ning the Word Mover\u2019s Distance (WMD) between each lex-\nicon and news article. The WMD takes two documents as\ninput, corresponding in our case to one news article and one\nlexicon, which are represented as a weighted set of word\nembeddings, and calculates the distance between them as\nthe sum of Euclidean distance between the two documents\u2019\nwords (Kusner et al. 2015). Doing this for each lexicon\nyields a 5-dimensional subjectivity vector representing the\ndegree of subjectivity associated with the news article. Since\nthe measure is based on distance rather than similarity, the\nresulting value is the inverse of the subjectivity bias: a higher\nISB value implies lower subjectivity bias and vice versa.For each language, we train one skip-gram word embed-\nding (Mikolov et al. 2013b,a) over a Wikipedia dump of the\nrespective language and then calculate the WMD between\na news article and the language\u2019s subjectivity lexicons as\nshown on the left side of Figure 1.\nWe have used the Wikipedia corpus (in each considered\nidiom) for training our word embeddings. As a result, we\nexpect to have word embeddings that are mostly unbiased\nregarding subjectivity. This is important since we want to\nisolate, as much as possible, the bias caused by the inter-\nlocutor.\nAt the end of this stage, subjectivity bias scores are al-\nready comparable for news of the same language. However,\nwe cannot directly compare scores across languages since\nsimilar levels of subjectivity for distinct languages might\npresent distinct subjectivity biases.\nSubjectivity Normalization\nWe propose to use a parallel corpus, which we can consider\nto be equally biased in terms of the interlocutor across the\nlanguages, for computing ISBs reference values for all target\nlanguages and check how much the news ISB rates deviate\nfrom its respective reference values. To this end, we sim-\nply calculate the difference between the ISB of a speci\ufb01c\nnews article and the median of ISBs in the reference corpus\nfor the article\u2019s language. This is depicted on the right hand\nside of Figure 1. The outcome of this stage is a normalized\nISB that can take any value in the real numbers domain. The\nhigher the score, the lesser the subjectivity associated with\nthe news, where a value of zero means that the article is ex-\nactly as biased as the reference corpus.\nWe use a subset of 15;000randomly selected speeches\nfrom the Europarl sentence aligned corpus (described in\nSection ) for computing the reference rates of the target lan-\nguages. After computing the ISBs in the Europarl corpus,\nwe end up with a distribution over 15;000 ISBs for each\nlanguage-dimension, depicted along with their mean and\nmedian in Figure 4. We de\ufb01ne the language\u2019s reference rate,\nfor each subjectivity dimension, as the median of the respec-\ntive distribution. Note that the mean and median are usually\nclose to each other for each language-dimension, which al-\nlows us to use either one. Also note that, distinct languages\npresent different mean/median values for the same dimen-\nsion. This is, per se, a clear indication that the language\ncontains an inherent subjectivity and the normalization step\nis necessary. We will further substantiate the normalization\nstep in Section section.\nExperiments\nIn this section, we \ufb01rst validate our method by applying it\non corpora where we know the level of subjectivity con-\ntained in the text and showing that our method can recover\nthis information. Next, we show an application of the pro-\nposed methodology to assess media bias on our news data\nset, comparing the level of subjectivity in news from differ-\nent countries about two topics. In addition, we provide an\nanalysis of how the results would change if we choose not\nto run the Normalization Stage and directly compared the\n566\narg sen val mod preeng ger por spa\n.65 .725 .8 .65 .725 .8 .65 .725 .8 .65 .725 .8 .65 .725 .801530\n01530\n01530\n01530\ncolour mean medianFigure 4: Density plots of ISBs by language and dimension\nof subjectivity calculated over the Europarl corpus. The dis-\ntribution mean is shown in red and the median in blue.\nsubjectivity values after the subjectivity computing stage.\nAll results are presented through con\ufb01dence intervals with\na con\ufb01dence level of 99%. All the code, data, and resources\nused in this research are available at Github12.\nMethodology Validation\nWe validate the proposed method from distinct perspectives.\nFirst, we show that we can \ufb01nd signi\ufb01cant differences in sub-\njectivity scores between subjective and objective texts. Sec-\nondly, we show that either translating the lexicons to other\nidioms or translating the texts of other idioms to Portuguese\nyield compatible results, indicating that both methods are\nvalid. Thirdly, we compare the automatically translated lex-\nicons to manually adapted lexicons produced by a linguist.\nFinally, we justify the need of having equal sized lexicons\nand show that the reduced lexicons after our translation step\nlead to the same conclusions as the original version on Por-\ntuguese texts.\nSubjectivity Detection We use Wikipedia, Webhose, and\nSDv1 for validating our methodology, showing that it can ef-\nfectively distinguish between objective and subjective text.\nWikipedia and Webhose enable us to show how well our\nmethod performs in multiple languages, since they contain\narticles written in German, Portuguese, English, and Span-\nish. However, we only have weak labels for these corpora,\nas described in Section . SDv1, on the other hand, contains\nonly English text, but features manually annotated sentences\nwith objective/subjective labels. We added Wikipedia to this\nexperiment because Wikipedia has content policies for en-\nforcing unbiased articles, and hence serve as a good refer-\nence of objective texts. Regarding the Webhose data set, we\nexpect that opinionated news present higher subjectivity val-\nues than informative ones, which should, in turn, be equally\nor more subjective than Wikipedia\u2019s articles. For SDv1, sub-\njective sentences should present higher subjectivity values\nthan objective ones.\nWe compute the ISB for each set of textual documents,\nand present the con\ufb01dence intervals of the mean in Figure 5.\nIf two con\ufb01dence intervals overlap, we can not infer any sig-\nni\ufb01cant difference between them. Results show signi\ufb01cant\n12https://github.com/allansales/InternationalMediaBias\narg mod pre sen valWebhose\nenggerporspa enggerporspa enggerporspa enggerporspa enggerporspa0.700.740.780.82\narg mod pre sen valSDv1\n0.790.800.81\nInformative/Objective Opinative/Subjective WikipediaFigure 5: Con\ufb01dence intervals of the mean of ISBs for in-\nformative news, opinionated news, and Wikipedia\u2019s articles\nby language. If two intervals do not overlap, it implies a sig-\nni\ufb01cant difference.\ndifferences for all languages and dimensions across the dif-\nferent text sources in both Webhose and SDv1 data sets. It is\nnoteworthy that the most subjective sources, i.e., Webhose\nopinionated news articles and the subjective sentences of\nSDv1, always present the lowest ISB scores. Moreover, the\nWebhose informative news present lower ISB values than\nWikipedia articles, as one could expect. These results pro-\nvide strong evidence that our approach can identify subjec-\ntive language correctly. As an example, we provide the most\nsubjective13and objective14news article found in our data\nset, according to the argumentation dimension.\nLexicon vs News Translation Instead of translating the\nlexicons to other languages, we could translate the news\narticles themselves to Portuguese and then apply the same\nmethodology with the original, untranslated lexicons. This\napproach may have certain advantages over translating the\nlexicons: (i) the lexicons post-processing is no longer nec-\nessary, and; (ii) the context of the translated words in the\ntext may be preserved. However, this approach is dif\ufb01cult\nto apply to a large number of documents in practice due to\nthe costs of commercial machine translation services. More-\nover, since lexicons are sets of words with no collective\nmeaning, they are much easier to translate. The lack of con-\ntext of the words and expressions in the lexicons, as well as\neventual translation imprecision, are mitigated, to some ex-\n13https://web.archive.org/web/20190920131028/https:\n//reliefweb.int/report/syrian-arab-republic/under-secretary-\ngeneral-humanitarian-affairs-and-emergency-relief-90\n14https://web.archive.org/web/20200115145321/https:\n//www.sana.sy/en/?p=171635\n567\ntent, by the use of the word embedding-based WMD in our\nmethod. That is, we expect that the word embedding mod-\nels will place both contextual words as well as the correct\ntranslation close to the words/expressions contained in the\ntranslated lexicons in the semantic space. In order to com-\npare the two approaches, we apply this alternative approach\nto a subset of our data and show that this leads to compara-\nble conclusions, albeit with lower statistical signi\ufb01cance due\nto the lower number of samples.\nWe test the alternative approach by translating texts from\nthe Webhose and SDv1 data sets to Portuguese using DeepL\nand running the methodology as previously detailed. From\nthe Webhose data set, we randomly select 120 news arti-\ncles, out of which 60are opinionated and 60are informa-\ntive, from the data set of each language (i.e., German, En-\nglish, and Spanish). We do not include Portuguese news in\nthis experiment since, our original lexicon is in Portuguese\nand does not need a translation; consequently, results would\nnot differ from those obtained in the previous experiment.\nFor the smaller SDv1, we were able to translate the entire\ndata set.\nFigure 6 presents the con\ufb01dence intervals for differences\nof ISBs between objective and subjective sources for both\ntext translation (red) and lexicon translation (blue). We\ncan make two main observations in this plot: First, we\nsee that translating the full text detects a signi\ufb01cant differ-\nence of ISBs between the informative/objective and opinion-\nated/subjective texts in all languages with 99 % con\ufb01dence\nlevel, except argumentation and valuation in English in the\nWebhose data set. Note that, if we lower the con\ufb01dence level\nto90 %, the difference becomes signi\ufb01cant in all subjectiv-\nity dimensions. We assume that the lower con\ufb01dence stems\nmostly from the small sample size, as we only use 120arti-\ncles per language in this setting. However, the method still\nshows rather signi\ufb01cant differences between the opinionated\nand informative news, albeit with a lower con\ufb01dence.\nSecondly, we can compare the con\ufb01dence intervals pro-\nduced by the lexicon and text translation. Two non-\noverlapping con\ufb01dence intervals of the same language, data\nset, and subjectivity dimension imply a signi\ufb01cant differ-\nence. For the Webhose data set, we cannot \ufb01nd a signi\ufb01cant\ndifference between the adopted approaches, indicating that\neither approach would lead to the same conclusions. As to\nthe SDv1 data set, the lexicon translation approach presents\nsigni\ufb01cant differences in all subjectivity dimensions, except\nthe sentiment one. However, there is no case where one in-\nterval includes zero and the other does not, meaning that the\napproaches agree with each other and our conclusions would\ntend to be similar using either.\nSome factors might in\ufb02uence these results, such as the\ntext length: news articles are commonly composed of mul-\ntiple sentences while each instance of SDv1 is a single sen-\ntence. In any case, we show that our lexicons translation ap-\nproach is at least as reliable as a text translation for comput-\ning the subjectivity values.\nAs an additional comparison, we compute the Pearson\ncorrelation between ISBs of the 120news articles using ei-\nther lexicon or news translation approach. The values pro-\nduced by the approaches reach an average correlation of\narg mod pre sen valWebhose\neng ger spa eng ger spa eng ger spa eng ger spa eng ger spa0.00.020.04\narg mod pre sen valSDv1\n0.00.010.02\narticle/sentence lexiconFigure 6: Con\ufb01dence intervals of the difference of ISBs for\nobjective and subjective sources. At the top: Con\ufb01dence in-\ntervals computed over a subset of 60opinionated and 60in-\nformative news articles, for each language, from the Web-\nhose data set. At the bottom: Con\ufb01dence intervals computed\nover the entire set of Objective and Subjective sentences\nfrom the SDv1 data set. The color indicates the approach:\nlexicon (blue) and article/sentence translation (red). Con\ufb01-\ndence intervals without zero imply signi\ufb01cant difference.\n0:76 over all dimensions and languages, showing a reason-\nable agreement about what is subjective and objective news.\nThe correlations are broken down in Figure 7 per language\nand subjectivity dimension.\nOverall, the experiments in this section show that both\nmethods mostly agree about the subjectivity of texts, further\nsuggesting that both are valid.\nLexicon Translation vs Manual Adaptation Ideally, we\nwould have our lexicons adapted by linguists to each tar-\nget language. While this is dif\ufb01cult to achieve and does not\nscale for any possible idiom, we asked a Brazilian linguist\nspecialized in English to adapt some of our Portuguese lex-\nicons to English. We compute the WMD between the lin-\nguist\u2019s resulting lexicons and ours, aiming to verify how the\nautomatic translation compares to a manual adaptation made\nby an expert. Given the high cognitive effort of this task, our\nlinguist adapted only the presupposition and the modaliza-\ntion lexicons to English.\nNote that the smaller the WMD value, the higher the se-\nmantic agreement between the lexicons. Given that WMD is\nde\ufb01ned on the [0;+1) interval, we normalized it for better\ninterpretability. We use the min-max normalization where\nmin is0, and we de\ufb01ne max as the distance of the automat-\nically translated lexicon to a \u201crandom\u201d lexicon. Speci\ufb01cally,\nwe sampled 40random lexicons from the vocabulary of our\n568\n0.83\n....\n0.670.81\n....\n0.650.81\n....\n0.650.81\n....\n0.640.87\n....\n0.75\n0.82\n....\n0.670.84\n....\n0.70.88\n....\n0.760.9\n....\n0.810.93\n....\n0.86\n0.79\n....\n0.620.82\n....\n0.660.85\n....\n0.710.58\n....\n0.30.87\n....\n0.75argmodpresenval\nger eng spa\n0.50.60.70.80.9estimateFigure 7: Pearson correlation con\ufb01dence intervals between\nISBs taken over the parallel lexicon approach and the news\narticles translation approach. The darker the cell, the smaller\nthe correlation between the approaches, and vice-versa.\nEnglish word embedding and averaged the WMD between\nthese lexicons and our automatically translated lexicon. Now\nour normalized score will lie in the [0;1]interval. Finally, to\ncome up with a similarity metric, we subtract the normalized\nscore from 1. So, the closer to 1, the higher the agreement\nbetween the lexicons.\nFor presupposition, this similarity score is 0:70, while for\nmodalization we have 0:76. Notice that these results denote\na high semantic agreement between the compared lexicons.\nOne key strength of our approach is that even when the trans-\nlation is not completely accurate, it is enough that the trans-\nlated expressions are close to the correct ones in the embed-\nding space. Moreover, even when an expression that carries\nsubjectivity appears in a text and not in our lexicons, our\nmethod will still be able to capture this signal of subjectiv-\nity, since this expression will be probably close to the ones\nin our lexicons in the embedding space.\nLexicons Size Effect In this experiment, we investigate\nhow much the reduction of the lexicon size in our trans-\nlation process in\ufb02uences the results of the method, that is,\nwhether our translation process reduces the expressiveness\nof the lexicon. Figure 8 shows the relative change in aver-\nage ISBs from the original Portuguese lexicon and the re-\nduced lexicon resulting from the translation process, that is\nmean(ISBdim\nmod)=mean(ISBdim\norig);where ISBdim\norigandISBdim\nmod are\nthe ISB computed with the original and modi\ufb01ed lexicon for\nsubjectivity dimension dim, respectively. We compare the\nISBs computed over a Portuguese Wikipedia sample, con-\ntaining 13:000 randomly chosen articles.\nThe results indicate that, as expected: (i) decreasing the\nlexicon sizes also decreases the detectable subjectivity in the\ntext, and (ii) the strength of the decrease is associated with\nthe number of words removed from the lexicon. The argu-\nmentation lexicon, which had 22words removed, presents\nthe highest decrease in subjectivity detection; followed by\nthe sentiment lexicon with 15words removed and the modal-\nization lexicon with 1word difference from its original ver-\nsion. However, the loss of detected subjectivity when using\nFigure 8: Relative change of ISBs computed over a sample\nof Portuguese Wikipedia articles through the original Por-\ntuguese lexicons and the decreased sized Portuguese lexi-\ncons after deriving parallel subjectivity lexicons.\narg mod pre sen valcountry\n0.0\ncountry Brazil Germany United States Venezuela\narg mod pre sen valstance\n0.0\nstance least left left_center right right_center\nFigure 9: Con\ufb01dence intervals of the difference of ISBs in\nnews related to Venezuela Crisis and Syrian War by country,\nlanguage and news outlet slant. Intervals entirely above or\nbelow zero mean higher subjectivity bias in articles about\nthe Venezuela Crisis or Syrian War, respectively.\nthe smaller version of the lexicons is only a small fraction of\nthe whole value.\nOverall we can conclude that, while our translation\nmethod does reduce the expressiveness of the lexicon, it is\nonly by a relatively small amount. Therefore, the modi\ufb01ed\nlexicon should still be able to reliably detect subjective texts.\nCase Studies\nAfter validating that our methodology can detect subjec-\ntive text as expected, we apply it to news articles about the\nVenezuelan Crisis and the Syrian War to analyze the subjec-\ntivity regarding these topics from different points of view.\nUnless otherwise speci\ufb01ed, in the following Con\ufb01dence In-\ntervals entirely above/below zero imply a higher subjectivity\nbias in articles about Venezuela Crisis/Syrian War topic, re-\nspectively.\nTopic Subjectivity by Countries This experiment inves-\ntigates whether the media reports in different countries are\nmore subjective when reporting on one topic than the other.\nThe selected countries are the ones who presented the high-\nest number of published news for each language.\nFigure 9 shows the con\ufb01dence intervals built over the\n569\nUnited States VenezuelaBrazil Germany\narg mod pre sen val arg mod pre sen val\u22120.020.000.020.04\n\u22120.020.000.020.04\ntopic Syria VenezuelaFigure 10: Con\ufb01dence intervals of the mean ISB in news re-\nlated to Venezuela Crisis and Syrian War by country. Inter-\nvals entirely above or below zero mean higher subjectivity\nbias in articles about the Venezuela Crisis or Syrian War,\nrespectively.\ndifferences between the ISBs of news reporting on the\nVenezuela Crisis and the Syrian War. The dotted line rep-\nresents the zero value across the boxes.\nResults show that the Brazilian media is signi\ufb01cantly\nmore biased when reporting about the Venezuela Crisis,\nmanifesting signi\ufb01cant differences in all subjectivity dimen-\nsions. The United States media reports are more subjec-\ntive about Venezuela, while presenting more argumenta-\ntion level towards the Syrian War topic. German media is\nroughly equally biased when reporting about both topics.\nThe Venezuelan media, in turn, is, surprisingly, a bit more\nbiased when addressing the Syrian War than their own crisis\nsituation, exhibiting two signi\ufb01cantly different subjectivity\ndimensions.\nThe results, in some cases, re\ufb02ect these countries\u2019 cur-\nrent positioning regarding the Venezuelan Crisis and the\nSyrian War. Regarding Brazil, one could expect the coun-\ntry to present a signi\ufb01cant difference in subjectivity towards\nVenezuela Crisis topic, since Brazil has currently a far right-\nwing government that is often con\ufb02icting with Venezuela15\nbut has little involvement with Syria\u2019s current war16. Ger-\nmany, in its turn, has taken a position regarding Venezuela\u2019s\nsituation17and also has some involvement with Syria. The\nUnited States took part in both events. Last, Venezuela\u2019s\ncase is intriguing since it is naturally expected that its media\nwould be more biased towards Venezuela\u2019s than other sit-\nuations. However, one possible reason is the decreasing of\npress freedom during the Chav \u00b4ez and, afterward, Maduro\u2019s\ngovernment (Hawkins 2016).\nA more detailed version of the countries subjectivities\nsplit by topic is given in Figure 10.\nTopic Subjectivity by Political Stance This experiment\naims to investigate whether the media reports, split by their\npolitical stance, are more subjective when reporting on one\n15https://www.bbc.com/news/world-latin-america-47300962\n16https://en.wikipedia.org/wiki/Foreign involvement inthe\nSyrian Civil War\n17https://www.bbc.com/news/world-latin-america-47115857\narg mod pre sen valNo norm Norm0.70.720.740.76\n0.00.010.020.03\nlang eng ger por spaFigure 11: Subjectivity con\ufb01dence intervals of Syrian War\nand Venezuela Crisis computed before (No norm) and after\nthe Normalization Stage (Norm).\ntopic or the other. For example, are news reported by the\nright-wing news outlets more subjective than the left-wing\nsubjective when reporting about Venezuela Crisis in com-\nparison with the Syrian War?\nFor \ufb01nding the political stance of each news outlet, we\ngather information from Media Bias Fact Check18(MBFC).\nIt is important to remark that we run this experiment only\nwith the 2;351articles published by the 219news outlets\n(covering 37countries) in our data sets mapped by MBFC.\nResults, depicted in Figure 9, show that news outlets are\nmore subjective when reporting about the Venezuela Crisis,\nregardless of the political stance. Also, right-wing news out-\nlets present the highest difference of subjectivity between\nthe topics. In some cases (e.g., presupposition), the differ-\nence is signi\ufb01cantly higher than the other political stances.\nThe right-wing results might be related to their rivalry\nwith left-wing governments and the fact that far right-wing\nrepresentatives often associate Venezuela\u2019s current situation\nwith socialism.19\nNormalization Stage Effect\nOur last experiment aims to attest how the Normalization\nStage affects results and how not using it would lead to dif-\nferent conclusions. For doing this, we compute the ISBs for\nall news in our database a) including the Normalization stage\nand b) excluding the Normalization stage. We show the con-\n\ufb01dence intervals for the mean of these values for each lan-\nguage and subjectivity dimension in Figure 11.\nWe can point out some differences in results obtained\nfrom the different subjectivity computation approaches\n(with and without the Normalization Stage):\n\u2022 The ISBs values decrease when running the Normaliza-\ntion Stage (in the presented example, in a scale range of\nabout 0:7). This decreasing effect re\ufb02ects what is intended\nwhen applying normalization: removing the presence of\nthe language subjectivity in the \ufb01nal computed value. Be-\nfore normalization, each subjectivity value aggregates the\n18https://mediabiasfactcheck.com/\n19https://www.theguardian.com/world/2018/dec/16/liberate-\nvenezuela-from-maduro-urges-bolsonaro-ally\n570\nlanguage subjectivity itself summed up with the interlocu-\ntor\u2019s subjectivity; after normalization, each value repre-\nsents only the interlocutor\u2019s subjectivity.\n\u2022 The distances between con\ufb01dence intervals for different\nlanguages in each particular subjectivity dimension are\nsmaller. Focusing on one subjectivity dimension (e.g., ar-\ngumentation), it is noticeable that the distances between\ncon\ufb01dence intervals inside a box increase from the nor-\nmalized to the unnormalized values;\n\u2022 Some conclusions would change without eliminating the\nlanguage subjectivity: For example, taking a look at\nthe argumentation dimension, without normalization one\nwould conclude that English, German and Portuguese\nnews articles do not present signi\ufb01cant subjectivity dif-\nferences, as their con\ufb01dence intervals overlap.\nConclusion\nMedia Bias is an important research topic due to its in\ufb02uence\non people\u2019s personal decisions on important issues. The lan-\nguages singularities are a barrier for automatically assessing\nmedia bias in cross-linguistic and cross-national scenario,\nwhere the language is charged with the qualities that charac-\nterize each country and its people.\nIn this paper, we present a methodology for assessing\nmedia bias, instantiated as subjectivity analysis, in cross-\nlinguistic scenarios, and on a large scale. The methodology\nrequires parallel lexicons, subjectivity reference values, and\na word embedding model representing the vocabulary for\neach language. We use machine translation for creating the\nparallel lexicons and compute subjectivity based on the dis-\ntance between the input text and its respective language lex-\nicon. The subjectivity reference values are computed over\na parallel corpus, serving as an equally biased corpus in\nterms of interlocutor\u2019s subjectivity, making it possible to es-\ntimate the language bias differences. Finally, we applied the\nmethodology over the news of two recent and resounded top-\nics. Among our main \ufb01ndings we can highlight:\n\u2022 Different languages exhibit different \u201cbase levels\u201d of sub-\njectivity, that is, one language may be generally more sub-\njective than another;\n\u2022 Taking into account the language bias is important in or-\nder to isolate the interlocutor\u2019s bias, which is the measure\nwe are really interested in;\n\u2022 We \ufb01nd subjectivity in news about the Venezuela Crisis\nsigni\ufb01cantly higher than in news about the Syrian War,\nmainly in Portuguese and English languages, and their\nmost publishing countries, Brazil and the United States;\n\u2022 Right-wing news outlets showed a higher subjectivity bias\ntowards the crisis in Venezuela than news outlets follow-\ning other political ideologies.\nLimitations and Future Work Some limitations of our\nwork should be noted. First, regarding the labelling of our\nvalidation data set, the Webhose News (Section ), we use\na rather small number of keywords for detecting opinion-\nated news with high precision, albeit potentially low recall.However, leaving some \u201cfalse negatives\u201d in the informative\ncorpus will not heavily in\ufb02uence the overall subjectivity dis-\ntribution in the informative news. This means that the dif-\nferences should still be signi\ufb01cant if we do not detect all\nopinionated news with our keywords (as con\ufb01rmed in Sec-\ntion ). Last, factors other than the interlocutor and the lan-\nguage subjectivity, such as cultural or regional biases, might\nhave in\ufb02uenced our obtained subjectivity bias values. Also,\nas a threat to validity we point out that we do not remove\nquotes or anything else from news articles. We assume that\nthe selection of quotations is a conscious decision made by\nthe author and all such decisions must be taken into account\nfor our subjectivity calculation.\nAs future work we plan to measure whether the results\nchange if we normalize the subjectivity biases after the sub-\njectivity computing stage, instead of forcing the lexicon\nsizes to be equal by manually removing some translations.\nAlso, we plan to include more languages into the analysis,\nmeasuring the impact of this addition to the lexicon sizes\nand allowing to draw even more global conclusions about\nthe addressed as well as other topics.\nReferences\nAmorim, E.; Canc \u00b8ado, M.; and Veloso, A. 2018. Auto-\nmated Essay Scoring in the Presence of Biased Ratings. In\nProceedings of the 2018 Conference of the North American\nChapter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Papers) ,\nvolume 1, 229\u2013237.\nBai, Q.; Wei, K.; Chen, M.; Hu, Q.; and He, L. 2018. Mining\nTemporal Discriminant Frames via Joint Matrix Factoriza-\ntion: A Case Study of Illegal Immigration in the US News\nMedia. In International Conference on Knowledge Science,\nEngineering and Management, 260\u2013267. Springer.\nBalahur, A.; Steinberger, R.; Kabadjov, M. A.; Zavarella, V .;\nder Goot, E. V .; Halkia, M.; Pouliquen, B.; and Belyaeva,\nJ. 2013. Sentiment Analysis in the News. CoRR\nabs/1309.6202. URL http://arxiv.org/abs/1309.6202.\nBanea, C.; Mihalcea, R.; and Wiebe, J. 2013. Porting multi-\nlingual subjectivity resources across languages. IEEE Trans-\nactions on Affective Computing 4(2): 211\u2013225.\nBenson, R. 2008. Journalism: normative theories. The inter-\nnational encyclopedia of communication .\nCaliskan, A.; Bryson, J. J.; and Narayanan, A. 2017. Seman-\ntics derived automatically from language corpora contain\nhuman-like biases. Science 356(6334): 183\u2013186. doi:10.\n1126/science.aal4230. URL http://opus.bath.ac.uk/55288/.\nCard, D.; Gross, J.; Boydstun, A.; and Smith, N. A. 2016.\nAnalyzing framing through the casts of characters in the\nnews. In Proceedings of the 2016 Conference on Empiri-\ncal Methods in Natural Language Processing, 1410\u20131420.\nChaturvedi, I.; Cambria, E.; Zhu, F.; Qiu, L.; and Ng, W. K.\n2015. Multilingual subjectivity detection using deep mul-\ntiple kernel learning. Proceedings of Knowledge Discovery\nand Data Mining, Sydney .\n571\nChaturvedi, I.; Ragusa, E.; Gastaldo, P.; Zunino, R.; and\nCambria, E. 2018. Bayesian network based extreme learning\nmachine for subjectivity detection. Journal of The Franklin\nInstitute 355(4): 1780\u20131797.\nDallmann, A.; Lemmerich, F.; Zoller, D.; and Hotho, A.\n2015. Media bias in german online newspapers. In Pro-\nceedings of the 26th ACM Conference on Hypertext & Social\nMedia, 133\u2013137. ACM.\nDe Cock, R.; Mertens, S.; Sundin, E.; Lams, L.; Mistiaen,\nV .; Joris, W.; and d\u2019Haenens, L. 2018. Refugees in the news:\nComparing Belgian and Swedish newspaper coverage of the\nEuropean refugee situation during summer 2015. Commu-\nnications 43(3): 301\u2013323.\nEntman, R. 1993. Framing: Toward Clari\ufb01cation of A Frac-\ntured Paradigm. The Journal of Communication 43: 51\u201358.\ndoi:10.1111/j.1460-2466.1993.tb01304.x.\nEntman, R. 2007. Framing Bias: Media in the Distribution\nof Power. Journal of Communication 57: 163 \u2013 173. doi:\n10.1111/j.1460-2466.2006.00336.x.\nGoldberg, B. 2014. Bias: A CBS insider exposes how the\nmedia distort the news. Regnery Publishing.\nGreenstein, S.; and Zhu, F. 2012. Collective Intelligence and\nNeutral Point of View: The Case of Wikipedia. Working Pa-\nper 18167, National Bureau of Economic Research. doi:10.\n3386/w18167. URL http://www.nber.org/papers/w18167.\nHamborg, F.; Donnay, K.; and Gipp, B. 2018. Automated\nidenti\ufb01cation of media bias in news articles: an interdisci-\nplinary literature review. International Journal on Digital\nLibraries doi:10.1007/s00799-018-0261-y.\nHawkins, K. A. 2016. Responding to radical populism:\nChavismo in Venezuela. Democratization 23(2): 242\u2013262.\nKristiansen, T.; Garrett, P.; and Coupland, N. 2005. Intro-\nducing subjectivities in language variation and change. Acta\nLinguistica Hafniensia 37(1): 9\u201335.\nKusner, M.; Sun, Y .; Kolkin, N.; and Weinberger, K. 2015.\nFrom word embeddings to document distances. In Interna-\ntional Conference on Machine Learning, 957\u2013966.\nLazaridou, K.; Krestel, R.; and Naumann, F. 2017. Identi-\nfying Media Bias by Analyzing Reported Speech. In Data\nMining (ICDM), 2017 IEEE International Conference on ,\n943\u2013948. IEEE.\nLin, Y .-R.; Bagrow, J. P.; and Lazer, D. 2011. More V oices\nThan Ever? Quantifying Media Bias in Networks. ICWSM\n1(arXiv: 1111.1227): 1.\nMacketanz, V .; Ai, R.; Burchardt, A.; and Uszkoreit, H.\n2018. TQ-AutoTest\u2013An Automated Test Suite for (Ma-\nchine) Translation Quality. In Proceedings of the Eleventh\nInternational Conference on Language Resources and Eval-\nuation (LREC 2018).\nMihalcea, R.; Banea, C.; and Wiebe, J. 2007. Learning\nMultilingual Subjective Language via Cross-Lingual Projec-\ntions. In Proceedings of the 45th Annual Meeting of the\nAssociation of Computational Linguistics, 976\u2013983. Asso-\nciation for Computational Linguistics. URL http://www.\naclweb.org/anthology/P07-1123.Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013a.\nEf\ufb01cient Estimation of Word Representations in Vector\nSpace. CoRR abs/1301.3781. URL http://dblp.uni-trier.de/\ndb/journals/corr/corr1301.html#abs-1301-3781.\nMikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and\nDean, J. 2013b. Distributed Representations of Words and\nPhrases and their Compositionality. In Burges, C. J. C.;\nBottou, L.; Welling, M.; Ghahramani, Z.; and Weinberger,\nK. Q., eds., Advances in Neural Information Processing\nSystems 26, 3111\u20133119. Curran Associates, Inc. URL http:\n//papers.nips.cc/paper/5021-distributed-representations-of-\nwords-and-phrases-and-their-compositionality.pdf.\nMundim, P. S. 2018. O vi \u00b4es da cobertura pol \u00b4\u0131tica da im-\nprensa nas eleic \u00b8 \u02dcoes presidenciais brasileiras de 2002, 2006 e\n2010. Revista Brasileira de Ci \u02c6encia Pol \u00b4\u0131tica 7 \u2013 46. ISSN\n0103-3352. URL http://www.scielo.br/scielo.php?script=\nsciarttext&pid=S0103-33522018000100007&nrm=iso.\nNickerson, R. S. 1998. Con\ufb01rmation bias: A ubiquitous phe-\nnomenon in many guises. Review of general psychology\n2(2): 175.\nOelke, D.; Geisselmann, B.; and Keim, D. A. 2012. Vi-\nsual Analysis of Explicit Opinion and News Bias in Ger-\nman Soccer Articles. In EuroVis Workshop on Visual Ana-\nlytics, EuroVA 2012, Vienna, Austria, June 4-5, 2012. doi:\n10.2312/PE/EuroV AST/EuroV A12/049-053. URL https://\ndoi.org/10.2312/PE/EuroV AST/EuroV A12/049-053.\nPang, B.; and Lee, L. 2004. A Sentimental Education: Senti-\nment Analysis Using Subjectivity Summarization Based on\nMinimum Cuts. In Proceedings of the ACL.\nRecasens, M.; Danescu-Niculescu-Mizil, C.; and Jurafsky,\nD. 2013. Linguistic models for analyzing and detecting bi-\nased language. In Proceedings of the 51st Annual Meeting\nof the Association for Computational Linguistics (Volume 1:\nLong Papers), volume 1, 1650\u20131659.\nSaez-Trumper, D.; Castillo, C.; and Lalmas, M. 2013. So-\ncial media news communities: gatekeeping, coverage, and\nstatement bias. In Proceedings of the 22nd ACM interna-\ntional conference on Conference on information & knowl-\nedge management, 1679\u20131684. ACM.\nSales, A.; Balby, L.; and Veloso, A. 2019. Media Bias Char-\nacterization in Brazilian Presidential Elections. In Proceed-\nings of the 30th ACM Conference on Hypertext and Social\nMedia, HT \u201919, 231\u2013240. New York, NY , USA: ACM. ISBN\n978-1-4503-6885-8. doi:10.1145/3342220.3343656. URL\nhttp://doi.acm.org/10.1145/3342220.3343656.\nSiebert, F.; Siebert, F.; Peterson, T.; Peterson, T.; Schramm,\nW.; of the Churches of Christ in the United States of Amer-\nica. Department of the Church, N. C.; and Life, E. 1956.\nFour Theories of the Press: The Authoritarian, Libertarian,\nSocial Responsibility, and Soviet Communist Concepts of\nWhat the Press Should Be and Do. An Illini book ; 72421-6.\nUniversity of Illinois Press. ISBN 9780252724213. URL\nhttps://books.google.com.br/books?id=4Q-oePDdcC8C.\nVerhagen, A. 2005. Constructions of intersubjectivity: Dis-\ncourse, syntax, and cognition. Oxford University Press on\nDemand.\n572", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Assessing Media Bias in Cross-Linguistic and Cross-National Populations", "author": ["A Sales", "A Zehe", "LB Marinho", "A Veloso"], "pub_year": "2021", "venue": "Proceedings of the \u2026", "abstract": "Media bias is a worldwide concern. Although automated methods exist for the analysis of  various forms of media bias, language is still an important barrier toward spotting worldwide"}, "filled": false, "gsrank": 35, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/18084", "author_id": ["", "rQaucw8AAAAJ", "6XO2tOwAAAAJ", "j2BEVSoAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:M3B2Z1ME25kJ:scholar.google.com/&output=cite&scirp=34&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D30%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=M3B2Z1ME25kJ&ei=CrWsaIYfwNmJ6g-p2qHxBQ&json=", "num_citations": 6, "citedby_url": "/scholar?cites=11086459663967219763&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:M3B2Z1ME25kJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/18084/17887"}}, {"title": "Leveraging commonsense knowledge on classifying false news and determining checkworthiness of claims", "year": "2021", "pdf_data": "Leveraging Commonsense Knowledge on Classifying False News and\nDetermining Checkworthiness of Claims\nIpek Baris Schlicht\u00031, Erhan Sezerer2, Selma Tekir2, Oul Han3, and Zeyd Boukhers4\n1ibarsch@doctor.upv.es, Universitat Polit `ecnica de Val `encia / Valencia, Spain\n2ferhansezerer,selmatekir g@iyte.edu.tr, Izmir Institute of Technology / Izmir, Turkey\n3hanoul@gmail.com, 2bytes Corp. / Anyang, South Korea\n4boukhers@uni-koblenz.de, University of Koblenz-Landau / Koblenz, Germany\nAbstract\nWidespread and rapid dissemination of false\nnews has made fact-checking an indispensable\nrequirement. Given its time-consuming and\nlabor-intensive nature, the task calls for an au-\ntomated support to meet the demand. In this\npaper, we propose to leverage commonsense\nknowledge for the tasks of false news classi\ufb01-\ncation and check-worthy claim detection. Ar-\nguing that commonsense knowledge is a factor\nin human believability, we \ufb01ne-tune the BERT\nlanguage model with a commonsense question\nanswering task and the aforementioned tasks\nin a multi-task learning environment. For pre-\ndicting \ufb01ne-grained false news types, we com-\npare the proposed \ufb01ne-tuned model\u2019s perfor-\nmance with the false news classi\ufb01cation mod-\nels on a public dataset as well as a newly col-\nlected dataset. We compare the model\u2019s per-\nformance with the single-task BERT model\nand a state-of-the-art check-worthy claim de-\ntection tool to evaluate the check-worthy claim\ndetection. Our experimental analysis demon-\nstrates that commonsense knowledge can im-\nprove performance in both tasks.\n1 Introduction\nThe increase of social media usage in recent years\nhas changed the way of consuming news. Although\nsocial media is useful for following the updates\nof breaking events such as the COVID-19 pan-\ndemic, it also misleads through false news spread-\ning rapidly and globally on platforms (Karlova and\nFisher, 2013; V osoughi et al., 2018), which results\nin negative emotions, confusion, and anxiety in so-\nciety (Budak et al., 2011) and even in the manipula-\ntion of major outcomes, such as political elections\n(V osoughi et al., 2018; Lazer et al., 2018).\n\u0003Corresponding Author: ibarsch@doctor.upv.es. Work\ndone during the time at the University of Koblenz-Landau,\nGermany.To combat false news, the number of fact-\nchecking initiatives around the world has increased.\nHowever, manual fact-checking can satisfy only a\nsmall share of the demand as fact-checking is a la-\nbor intensive and time consuming task. It requires\nfact checkers to contact people/organizations that\nare mentioned in the claim, consult experts that pro-\nvide background knowledge if needed, seek source\nvalidation, etc. Typical fact-checking for one news\nitem takes about one day in order to research the\nfacts and report the result (Graves, 2018). This\nyields a time lag between the spread of false news\nand the delivery of the fact-checked article (Hassan\net al., 2015a).\nIn recent years, we have seen a growing inter-\nest in developing computational approaches for\ncombating false news. Some studies focus on\nautomatising the steps of manual fact-checking\n(Cazalens et al., 2018; Thorne and Vlachos, 2018;\nGraves, 2018). As a seminal study, ClaimBuster\n(Hassan et al., 2015b, 2017) is the \ufb01rst end-to-end\nautomatic fact-checking framework and is widely\nused by professional fact checkers and journalists\n(Adair et al., 2019). ClaimBuster identi\ufb01es check-\nworthy factual claims in texts from various data\nsources (e.g social media, websites) using a classi-\n\ufb01cation and score model that is trained on human\nlabeled political debates, searches identi\ufb01ed claims\nagainst fact-checking websites, collects support-\ning/debunking evidences and in a \ufb01nal step creates\na report which combines the search results, afore-\nmentioned evidences and claim checkworthiness\nscore. Although ClaimBuster is able to spot simple\ndeclarative claims, it misses those implicitly stated\nin sentences (Graves, 2018).\nOther studies focus on false news detection\nbased on the style of news content or social mediaarXiv:2108.03731v1  [cs.CL]  8 Aug 2021\ncontext (Shu et al., 2017; Zhou and Zafarani, 2020).\nMost of these studies treat false news detection as\na binary classi\ufb01cation problem that labels a news\narticle as fake or true. As an example, Singhania\net al. (2017) propose a three level hierarchical at-\ntention network model (3HAN) that exploits the\narticle structure. The authors evaluated on a dataset\nthat is constructed of a small list of fake and legit\nnews sources and outperformed models such as\nsingle level hierarchical attention network (HAN)\n(Yang et al., 2016).\nHowever, on the web, multiple types of false\nnews can be found such as satire or propaganda\n(Zannettou et al., 2019; Rashkin et al., 2017b).\nWhile satire conveys irony or parody and contains\nunrealistic situations, propaganda mimics the style\nof real news and can mislead readers with malin-\ntent. Furthermore, political polarization propels\nbiases in news (Lazer et al., 2018). False news de-\ntection models must therefore be more \ufb01ne-grained\nthan the aforementioned binary models in order\nto address diverse types of false news. Therefore,\nthe literature is in quest of new techniques and\nmethodologies (Bozarth and Budak, 2020) as well\nas datasets (Torabi Asr and Taboada, 2019).\nAddressing the diversity of false news, we iden-\ntify one common trait that enables them all. We\npoint out that the impression of veracity is created\nby a seeming plausibility of news stories, since hu-\nmans believe depending on how much a story \ufb01ts\ntheir prior knowledge (Connell and Keane, 2004,\n2003). This background knowledge is termed as\ncommonsense knowledge . Goldwasser and Zhang\n(2016) already demonstrated that commonsense\nknowledge can improve satire detection better than\ntraditional text classi\ufb01cation models. With this\nmotivation, we integrate commonsense knowledge\ninto the tasks of false news classi\ufb01cation and check-\nworthy claim detection, applied on diverse news.\nIn our study, commonsense knowledge is captured\nby a commonsense question answering (CSQA)\ntask (Talmor et al., 2019) where the inputs are ques-\ntions and multiple choices as answer candidates,\nand the output is an answer (Task A in Table 1).\nFor classifying different types of news on the web,\nwe leverage the false news taxonomy proposed by\nZannettou et al. (2019). In this task, the inputs are\nbody and title of a news article and the output is\nthe news type, namely satire, conspiracy, propa-\nganda, bias-right, bias-left or neutral (Task B in\nTable 1). In check-worthy claim detection, the in-put is a sentence and the output is a label indicating\nits checkworthiness, namely, check-worthy factual\nstatement (CFS), not factual statement (NFS) and\nunimportant factual statement (UFS) (Task C in Ta-\nble 1). To transfer commonsense knowledge to task\nB and C using multitask training (Liu et al., 2019),\nwe prepend them with \ufb01ne-tuning a pre-trained\nBERT model over a CSQA task.\nThe main contributions of this study are as fol-\nlows:\n\u2022To the best of our knowledge, it is the \ufb01rst\nattempt to leverage commonsense knowledge\nto classify fake news and detect check-worthy\nclaims.\n\u2022We collected a new community interest news\ndataset (CIND) from the social media plat-\nform Reddit. Unlike the publicly available\nfalse news collection NELA 2019 (Gruppi\net al., 2020), CIND is a collection (1) of news\nthat news consumers found interesting or plau-\nsible, (2) that features a diverse number of\nsources which makes the experiment of pre-\ndicting news from an unseen source more re-\nliable (3) that covers news events which oc-\ncurred from 2016 to 2019, allowing for fore-\ncasting. We label both datasets with the false\nnews taxonomy (Zannettou et al., 2019).\n\u2022We conducted an extensive set of experiments\nto validate our hypothesis. The results show\nthat commonsense knowledge could improve\nthe (1) predictions of 4 out of 6 classes on\nCIND and the predictions of bias-right articles\nfrom the NELA dataset for the experiment of\npredicting news articles from unseen sources,\n(2) the predictions of 3 out of 6 classes on\nCIND for the experiment of forecasting, (3)\nthe prediction of all classes in check-worthy\nclaim detection task.\nThe rest of the paper is organized as follows. Sec-\ntion 2 summarizes related work. Section 3 presents\nthe proposed models. Section 4 introduces the new\ndataset collected for this study along with other\ndatasets used for comparison. Finally, section 5\ndiscusses the experimental results.\n2 Related Work\nIn this section, we present the studies related to our\nresearch. Section 2.1 and section 2.2 outline the\nstudies in check-worthy claim detection and false\nnews classi\ufb01cation, section 2.3 presents the studies\nencoding commonsense knowledge for text classi-\n\ufb01cation tasks and section 2.4 presents the studies\nTask A: Commonsense Question Answering (CSQA)\nInput 1: Question People are very much like the animals, but one thing has secured or dominance over the planet.\nWe\u2019re better at doing what?\nInput 2: Multiple Choices a) Eat eggs b) Make tools c) eat dosa d) talk to each other e) smoke pot\nOutput: Answer b\nTask B: False News Classi\ufb01cation\nInput 1: Title TSA Agents Can Now Grope Travelers Without Fear Of Pesky Lawsuits\nInput 2: Body Transportation Security Administration (TSA) screeners have gained the upper glove when it comes to\nbeing sue ...\nOutput: News Type Conspiracy\nTask C: Check-worthy Claim Detection\nInput: Statement And I saw the cocaine scene treated with humor, as though this was a humorous little incident.\nOutput: Checkworthiness Unimportant Factual Statement (UFS)\nTable 1: Examples from each task that shows inputs and outputs.\nleveraging multi-task learning for fact-checking\nand false news classi\ufb01cation.\n2.1 Check-worthy Claim Detection\nCheck-worthy claim detection is the \ufb01rst step of\nthe fact-checking pipeline (Cazalens et al., 2018;\nGraves, 2018; Thorne and Vlachos, 2018). The\ncomponent of ClaimBuster (Hassan et al., 2015b,\n2017) that detects check-worthy claims is trained\nwith a SVM classi\ufb01er using tf-idf bag of words,\nnamed entity types, POS tags, sentiment and sen-\ntence length as a feature set. Gencheva et al. (2017)\nproposed a fully connected neural network model\ntrained on claims and their related political debate\ncontent. Additionally, CLEF Check That! Lab\n(CTL) has organized shared tasks to tackle this\nproblem in political debates (Atanasova et al., 2018,\n2019) and in social media (Barr \u00b4on-Cede \u02dcno et al.,\n2020).\n2.2 Style-based False News Classi\ufb01cation\nStyle-based approaches for false news classi\ufb01ca-\ntion attempt to capture the writing style or decep-\ntive clues in news articles (Shu et al., 2017; Zhou\nand Zafarani, 2020; Potthast et al., 2018). The\nmethods range from hand-crafted feature-based\nmethods (V olkova et al., 2017; P \u00b4erez-Rosas et al.,\n2018) to sophisticated deep neural networks (Sing-\nhania et al., 2017; Riedel et al., 2017; Karimi and\nTang, 2019).\nRiedel et al. (2017) focus on the \ufb01rst part of the fake\nnews detection problem: stance detection. Their\nmodel RDEL extracts the most frequent unigrams\nand bigrams, constructs tf-idf vectors for article\nheadlines and bodies, and also computes the co-\nsine similarity of headline and body. Finally, all of\nthese features are fed into a Multilayer Perceptron\nfor classi\ufb01cation.\nThe model 3HAN (Singhania et al., 2017) encodes\nthe body of news articles similar to HAN (Yang\net al., 2016) where the words in each sentence areencoded with BiGRU (Cho et al., 2014) and then\nan attention mechanism (Bahdanau et al., 2015)\nidenti\ufb01es informative words in a sentence. Finally\nsentences are passed through an attention layer to\n\ufb01nd informative sentences in the document before\nclassifying them with a dense layer. In addition\nto HAN, it also concatenates the encoded headline\nwith the processed body of the article and runs at-\ntention mechanism on the concatenated features\nbefore feeding it to the dense layer.\nMost of these aforementioned studies tackle the\nproblem as binary classi\ufb01cation. Few scholars\nhave investigated different types of false news. Ru-\nbin et al. (2015) differentiated false news types as\nhoaxes, satire and deliberately misleading fabri-\ncations. Rashkin et al. (2017b) studied linguistic\nfeatures for analysis of hoax, propaganda, satire\nand trusted sources. Ghanem et al. (2020) analyzed\nthe impact of emotions in clickbaits in addition\nto the sources that Rashkin et al. (2017b) studied.\nHowever, the dataset used in both studies (Rashkin\net al., 2017a; Ghanem et al., 2020) covers a few\nsources for each category. In our study, we in-\ncrease the number of sources for each category and\ninclude articles from biased sources.\n2.3 Incorporating Commonsense Knowledge\nIncorporating commonsense knowledge into text\nrepresentations can improve many tasks in NLP\nand NLU, such as machine comprehension (i.e\nWang et al. (2018)), question answering (i.e Zhong\net al. (2019b)) and opinion mining (i.e Du et al.\n(2020); Xu et al. (2019); Zhong et al. (2019a); Ma\net al. (2018). Closest to this paper is the study by\nGoldwasser and Zhang (2016) who leverage com-\nmonsense knowledge for satire detection. Their\napproach constructs a narrative representation of\nan article by extracting main actors, events and\nstatements, then makes inferences to quantify the\nlikelihood of those entities appeared in a real/satire\ncontext.\nTo leverage commonsense knowledge, one ap-\nproach is to use knowledge aware distributional\nword embeddings such as Numberbatch (Speer\net al., 2017) which is built on the commonsense\nknowledge base ConceptNet. Alternatively, com-\nmonsense knowledge can be transferred by using\nmulti-task learning (Bosselut et al., 2019). In our\nstudy, we evaluate both approaches.\n2.4 Multi-task Learning\nMulti-task learning is motivated by human learning.\nWhile learning new tasks, we apply the knowledge\nthat is gained from related tasks. In contrast to\nsingle-task learning, multi-task learning can learn\na more general representation by leveraging the\nknowledge of auxiliary tasks when the original task\nhas noisy/small amount of samples (Ruder, 2017).\nThere are several attempts to apply multi-task\nlearning to the tasks that aid fact-checking or de-\ntect false news. Kochkina et al. (2018) applied\na multi-task learning model that encodes inputs\nwith a shared LSTM and then jointly learns the\ntasks in a rumour veri\ufb01cation pipeline (stance de-\ntection, veracity and identifying rumours). Baly\net al. (2019) proposed a multi-task ordinal regres-\nsion framework for jointly predicting the factuality\nand political ideology of news media. Atanasova\net al. (2020) presented a multi-task model for verac-\nity explanation generation and veracity prediction\nbased on DistilBERT(Sanh et al., 2019).\n3 Models\nTo test whether the exploitation of commonsense\nknowledge improves false news classi\ufb01cation and\ncheck-worthy claim detection, the MTBERT model\nof Liu et al. (2019) was used. Figure 1 illustrates\nthe resulting model architecture. The model con-\nsists of two shared lower levels and two task spe-\nci\ufb01c layers. Lower layers incorporate the original\nBERT architecture where the \ufb01rst layer maps the\ninputs to tokens required by BERT and the second\nlayer resides the transformer encoders of BERT.\nThe upper two layers represent speci\ufb01c task con-\n\ufb01gurations along with their loss functions. The\nmodel is trained in two steps: First, the shared\nBERT model is trained on the pre-training tasks of\nmasked word prediction and next sentence predic-\ntion. In the second phase, all samples belonging to\nall tasks are shuf\ufb02ed. Then, each sample is used to\ntrain/\ufb01ne-tune the shared parameters of BERT with\nrespect to the loss functions of the speci\ufb01c tasks.\nQuestion & Choices\n(Commonsense\nQuestion Answering)News Articles\n(False News\nClassi\ufb01cation)Presidential Debate\nStatements\n(Checkworthy Claim\nDetection)INPUT 1Input EncoderShared BERTFalse News\nClassi\ufb01cation\nTask\nORCheckworthy Claim\nDetection\nTaskCommonsense Q&A \nTaskOR\n++\nINPUT 2a)\nb)\nc)\nd)\ne)satire\nconspiracy\npropaganda\nneutral\nleft bias\nright biasUFS\nNFS\nCFSOR+OUTPUT 1 OUTPUT 2Figure 1: Overview of MTBERT model for false news\nclassi\ufb01cation and check-worthy claim detection.\nThis training scheme enables the model to learn a\ntask by transferring the information gained from\nother tasks.\nIn our work, instead of training the BERT model\nfrom scratch, we use the HuggingFace library\n(Wolf et al., 2019) to obtain the pre-trained BERT\nmodel that would result from the \ufb01rst training\nphase. In the second phase, we \ufb01ne-tune the pre-\ntrained model using CSQA as the \ufb01rst task and false\nnews classi\ufb01cation or check-worthy claim detec-\ntion as the second task, depending on the objectives.\nThis allows the model to perform false news clas-\nsi\ufb01cation or check-worthy claim detection tasks,\nusing the information gained from the CSQA task.\nTo test the performance of the \ufb01ne-tuned MTBERT\nin false news classi\ufb01cation, we compare our results\nagainst the state-of-the-art false news classi\ufb01cation\nmodels RDEL and 3HAN. For both models, we\nencode the inputs with Glove embeddings (Pen-\nnington et al., 2014), as originally stated in their\npapers. These embeddings, however, do not in-\ncorporate commonsense knowledge. In order to\nmake them comparable, we also feed Numberbatch\nembeddings that incorporate ConceptNet common-\nsense knowledge (Speer et al., 2017) into them. We\nreport the baseline performances of HAN and SVM\nat this task, additionally. Furthermore, we compare\nthe performance against the original BERT to con-\n\ufb01rm that the performance gains depend not only on\nthe classi\ufb01er but also on the use of commonsense\nknowledge. For SVM, we used the 25,000 most fre-\nquent unigrams and bigrams as features. In all the\nSubreddits\nTheDonald\nnewright\nnews\nconspiracy\nfakenews\nnottheonion\nneutralnews\npol\npolitics\nsatire\nsavedyouaclick\nworldnews\nTable 2: List of subreddits that are used for this study.\nexperiments involving BERT and MTBERT where\nthe body of the article is merged with the headline,\nwe used the token [SEP] that is acknowledged by\nthe architecture to separate different contexts.\nFor the task of check-worthy claim detection, we\ncompare MTBERT with the results of the Claim-\nBuster API. The API gives a probability score for\nthe checkworthiness of a claim where we map\nscores below 0.33 to NFS, above 0.66 to CFS and\nthe rest to UFS. We also carry out this experiment\non (1) a SVM classi\ufb01er trained on ClaimBuster fea-\ntures (e.g POS tags, entity types, tf-idf, etc.) with\n5-fold cross validation and (2) the original BERT\nas baselines.\n4 Datasets\n4.1 Datasets for False News Classi\ufb01cation\nNELA 2019 (Gruppi et al., 2020) is a publicly\navailable dataset covering mainstream and alter-\nnative news sources. The authors scraped news\narticles from RSS feeds of all its news sources in\n2019. NELA 2019 has the following limitations\n(1) the number of satire and neutral sources is low\n(2) only events in 2019 are covered (3) the news\npublishers select which articles to share in their\nRSS feeds.\nWe propose the community interest news dataset\nCIND to overcome the aforementioned limita-\ntions of NELA 2019. Instead of relying on the\nnews sources\u2019 selection of articles, it respects\nthe interest of news consumers. As the collec-\ntion source, we choose Reddit because (1) it is\npopular in various communities (2) openly ac-\ncessible and (3) contains articles from a variety\nof news sources. Reddit users can share news\nand discuss them in online communities so-called\nsubreddits. Each subreddit has its own discus-\nsion theme and moderation system. For instance,\nusers share satire-like news articles from main-stream news sources in r/nottheonion and\ndiscuss conspiracy theories in r/conspiracy .\nArticles from unreliable sources are removed by\nthe moderators of r/nottheonion while only\nclickbait articles are allowed to be shared in\nr/savedyouaclick .\nWe selected subreddits that have been analyzed\nin Zannettou et al. (2017) or Horne et al. (2018),\nor was used as the source in a dataset before\n(Nakamura et al., 2020) which were active within\n2016-2019. Additionally, we added r/fakenews\nwhere false news stories are highlighted and fact-\nchecks are shared, with respect to the speci\ufb01ed time\nframe. Table 2 lists the subreddits that are used for\nthis study.\nWe crawled posts with PushshiftAPI (Baumgartner\net al., 2020) by ignoring those that are removed\nby moderators and users. We \ufb01ltered out the posts\nwhose metadata contain \ufb02air link text1which is\nused for posts that violate subreddit rules. We ex-\ntracted the articles by using Newspaper3k2. We\n\ufb01ltered out the articles which are not in English,\nnon news sources such as Facebook, Youtube, etc.\nand sources that were not accessible due to techni-\ncal issues such as huffpost.com .\nWe categorized the sources of news articles in\nboth datasets based on the false news taxonomy\nproposed by Zannettou et al. (2019). The news\ntypes we selected from the taxonomy are satire,\nconspiracy, propaganda, biased (left & right) as\nfalse news types and additionally neutral news\nas most credible news. For identifying the news\nsources in each category, we leveraged Media Bias\nFact Check (MBFC)3which is an independent or-\nganization that manually annotates factuality and\npolitical leaning of media sources. Labels provided\nby MBFC have been widely used by the research\ncommunity (e.g Baly et al. (2018); N\u00f8rregaard et al.\n(2019); Barr \u00b4on-Cede \u02dcno et al. (2019)). We scraped\nMBFC labels4and augmented the list with satire\nsources from the r/satire subreddit5. We ex-\nplain the sources below with the traits of online\ninformation (Wardle and Derakhshan, 2017; Zan-\nnettou et al., 2019).\nSatire sources use irony, exaggeration and humour.\n1Examples of some link texts are Not oniony\n- Removed ,misleading title ,Not a news\narticle - Removed\n2https://newspaper.readthedocs.io/en/latest/\n3https://mediabiasfactcheck.com/\n4retrieved on 29.07.2020\n5We marked the sources if their about/home pages explic-\nitly indicate that they are satiric\nType Title Source\nSatire White House Chef Quits Because Trump Has Only Eaten Fast Food For 6 Months halfwaypost\nConspiracy In Bizarre Response, Twitter Tells Trump It Does Not \u201dShadowban\u201d While Admitting It Does zerohedge\nPropaganda CNN retracts story on investigation into Trump campaign adviser\u2019s meeting with CEO of Russian fund rt\nNeutral Schiff disturbed by report that Trump not fully briefed on counters to Russian cyberattacks upi\nBias-Left Remember Trump\u2019s Promise Not to Touch Social Security? It\u2019s Gone Now nymag\nBias-Right Donald Trump Is America\u2019s Julius Caesar dailycaller\nTable 3: Example snippets from articles about Donald Trump associated with source type.\nDataset Type Tokens-Body (Avg.) Tokens-Title (Avg.) Articles(#) Sources (#)\nCommunity Interest Satire 287.65 10.48 1976 42\nNews Dataset Conspiracy 780.19 13.23 722 16\nPropaganda 752.13 10.88 1207 23\nNeutral 591.50 10.18 1365 40\nBias-Left 700.73 11.42 1881 36\nBias-Right 557.88 11.44 1284 23\nNELA 2019 Satire 233.37 10.85 1638 8\nConspiracy 652.27 11.69 3710 16\nPropaganda 538.69 11.37 6091 27\nNeutral 628.63 9.38 2366 11\nBias-Left 670.09 11.17 5262 23\nBias-Right 486.93 10.32 3857 17\nTable 4: Dataset statistics of community interest news\ndataset (CIND) and NELA 2019.Train #\nNFS 14685\nUFS 2403\nCFS 5413\nTest #\nNFS 731\nUFS 63\nCFS 238\nTable 5: Data statistics of ClaimBuster dataset.\nSatiric articles do not aim to deceive the news\nconsumer, but to entertain. However, if satire\nis taken seriously, it misinforms. We used the\nsources in the the r/satire subreddit and ex-\ncluded sources that are not mutually exclusive (e.g\nhttps://www.newyorker.com/humor is also a bias\nsource).\nConspiracy sources are not credible and mostly\nconsist of articles that are not veri\ufb01able. These\nsources fabricate content with the intention to dis-\ninform. We extracted conspiracy sources from the\nconspiracy-pseudoscience category of MBFC.\nPropaganda sources in\ufb02uence the news consumer\nin favor of a particular agenda. They may mislead\nin order to frame issues or individuals. We manu-\nally checked the questionable source category of\nMBFC to identify propaganda sources. MBFC pro-\nvides tags to inform the reason why the source is\nquestionable. One such tag is propaganda. Thus,\nwe removed the sources that have labels other than\npropaganda in this tag.\nNeutral sources are the most credible. They are\nleast biased and their reporting is factual and ver-\ni\ufb01able. We extracted least biased sources from\nMBFC as neutral sources.\nBiased sources are strongly biased toward one ide-\nology (typically: conservative/liberal) in their story\nselection and framing. We extracted biased sources\nfrom MBFC as bias sources. The bias category of\nthe dataset contains 61% of left and 39% of bias-\nright sources.\nAfter identifying source types of each article in\nboth dataset, we removed sources that have samples\nof less than 10 articles and down-sampled sourcesthat have more than 250 documents. Additionally,\nfor CIND dataset, we removed the outliers for each\ncategory by computing the length of tokens of ar-\nticle bodies and by performing the local outlier\nfactor algorithm (Breunig et al., 2000) to yield its\n\ufb01nal dataset. The details of the CIND and NELA\n2019 are shown in Table 4 and example articles are\nshown for each source type from CIND in Table 3.\n4.2 Dataset for Check-worthy Claim\nDetection\nTo evaluate the model in claim-level, we used the\nClaimBuster dataset (Arslan et al., 2020) . It con-\ntains human annotated 23k short statements with\na metadata, from all U.S presidential debates be-\ntween 1960-2016. The dataset has been used for\ndeveloping ClaimBuster. As part of the annota-\ntion process, the authors asked the coders to la-\nbel the sentences as check-worthy factual claims\n(CFS) if they contain factual claims about which\nthe public will be interested in learning about their\nveracity. Similarly, if the sentences contain fac-\ntual statements but aren\u2019t worth being fact-checked,\nthey are annotated as unimportant factual sentences\n(UFS). Lastly, the coders considered the subjective\nsentences as non-factual sentences (NFS), such as\nopinions.\n4.3 CSQA Dataset\nWe used CSQA dataset (Talmor et al., 2019) for\nthe model to learn commonsense knowledge. The\ndataset has been created based on the commonsense\nknowledge encoded in ConceptNET (Speer et al.,\n2017). The dataset contains 12k multiple-choice\nquestions that have four choices and one correct\nanswer.\n5 Experiments and Evaluation\nIn our experiments, we investigate whether CSQA\ntask helps on (1) robustness on new events and\nchanges of style by news publishers (Section 5.1),\n(2) classifying news from previously unseen pub-\nlishers (Section 5.2), and (3) discovering check-\nworthy claims (Section 5.3). We report per-class\nand average macro F1 scores for each experiment.\n5.1 Robustness on New Events and Changes\nof Style by News Publishers\nIn this analysis, we test the models\u2019 robustness\nagainst new events or the style changes by the news\npublishers. For this, we adopt the forecasting ex-\nperiment proposed by Bozarth and Budak (2020),\n\ufb01rst we extract sources that published articles in be-\ntween 2015 and 2019 from the CIND dataset. We\nuse data samples whose published year is earlier\nthan 2019 as training and the rest is as test set.\nTable 6 shows the macro-F1 scores of the models\nfor each category and the Figure 2 shows the macro-\nF1 scores of BERT variations for each month in\n2019. Overall, BERT models outperform SVMs,\nHANs and RDEL in this task, however, detecting\nright-lean articles are hard for all of the models.\nAdditionally, even though MTBERT using merged\nfeatures cannot outperform the single task in terms\nof macro-F1, it has performance gains in the classes\nconspiracy (3.42%), propaganda (2.87%) and left\n(1.21%). As shown in Figure 2, the performances\nof BERT variants in the satire class degrade but the\nperformances in propaganda and left types are sta-\nble throughout the year. Furthermore, the \ufb02uctua-\ntions in MBERT (with the merged features) are less\nthan the single task BERT on propaganda across\nthe year, which could be more generalized at iden-\ntifying propaganda throughout a year.\nMoreover, as shown in Figure 5, MTBERT pro-\nduces higher number of true positive samples than\nthe single task, BERT in conspiracy articles. How-\never, the single task BERT is better at identifying\nneutral articles for the forecasting task.\n5.2 Classifying News from Previously Unseen\nPublishers\nTo meet the condition of unseen publishers, we\norganize our tests such that the publisher of a news\narticle has not been encountered before. To see howMTBERT can generalize in such a scenario, we\nadopt the evaluation scheme for predicting unseen\nsources (Bozarth and Budak, 2020) and apply it to\nNELA and CIND datasets. First, we group news\narticles based on source (reuters, fox news, etc.)\nunder each source type (conspiracy, propaganda\nand so on). From each source type we randomly\nsample 90% sources as training set and the rest as\ntest set and repeat it 5 times. We report the mean\nand standard deviation of macro-F1 scores of sets\nin Table 7.\nSimilar to forecasting experiments, both BERT-\nbased models outperform all baseline models, al-\nthough a signi\ufb01cant performance drop is observed\nin all models compared to forecasting experiments.\nThis is expected since in forecasting experiments,\ntest set contains articles from sources that may also\nhave some samples in training set. It makes the pre-\ndictions in forecasting easier for the models consid-\nering that they can also learn from stylistic features\nof sources. We observe that satire sources are the\nbest detected types in the CIND dataset, but not\nin the NELA dataset, because the test sets contain\nonly one satire source and adds a new challenge for\nthe models.\nWe additionally ran a paired t-test on the scores.\nMTBERT combining all features signi\ufb01cantly out-\nperformed the single task version on the CIND (at\np value of 0.001, with a large effect size: cohen\u2019s d\n2.339). Yet single task BERT achieves 0.39% bet-\nter F1 score than the MTBERT on NELA dataset,\nand no signi\ufb01cant difference is observed. The rea-\nson could be the difference between the construc-\ntion of the datasets. For example, CIND contains\nselected samples by Reddit users, which might\nhave clickbait/check-worthy statements. However,\nNELA samples are collected from RSS of websites\nwhere publisher preference has a signi\ufb01cant role.\nThat also explains why a title of an article does not\nimprove the results for the NELA.\nLike the forecasting task, commonsense knowl-\nedge has a positive effect on true positive conspir-\nacy samples on CIND, as seen in Figure 6. How-\never, both BERT models misclassi\ufb01ed the samples\nfrom propaganda sources mostly as right-lean arti-\ncle (shown in Figures 6,7).\n5.3 Evaluating Commonsense Knowledge for\nIdentifying Check-worthy Claims\nFinally, we assess the help of commonsense knowl-\nedge in detecting check-worthy claims. Therefore,\nFeature Model Satire Conspiracy Propaganda Neutral Bias-Left Bias-Right F1-Macro\nTitleSVM 45.91 21.14 32.34 37.29 40.56 15.04 32.05\nBERT 54.38 33.33 46.67 46.30 49.37 19.24 41.40\nMTBERT 61.79 33.78 45.71 46.63 52.73 22.33 43.83\nBodySVM 87.08 49.56 77.68 77.42 73.40 39.13 67.38\nHAN 48.69 34.71 74.26 70.91 58.20 24.82 51.93\nHAN* 67.41 32.17 66.67 60.23 56.24 28.32 51.84\nBERT 77.18 51.80 82.38 79.74 72.00 40.99 66.90\nMTBERT 73.50 59.20 83.22 78.56 73.54 37.17 67.53\nMergedRDEL 75.72 45.53 55.02 63.11 59.28 26.74 54.66\n3HAN 45.08 25.86 52.25 46.84 34.62 18.15 39.81\n3HAN* 46.21 33.58 60.17 64.77 57.76 25.51 51.61\nBERT 77.79 60.87 83.15 85.66 75.39 43.98 71.14\nMTBERT 67.95 64.29 86.09 74.11 76.60 42.21 68.54\nTable 6: Results for the forecasting experiment for false news classi\ufb01cation. * indicates that the model using\nNumberbatch as embeddings. The bold scores are the best results per feature.\nFigure 2: Comparison of single task BERT and MTBERT in forecasting task on CIND dataset. X-axis indicates\nthe months in 2019, y-axis indicates the F1 macro scores.\nwe evaluate the MTBERT for check-worthy claim\ndetection task (see Section 4.2). We use the splits\nprovided by the authors (Arslan et al., 2020).\nTable 8 shows the performance of the models.\nUtilizing commonsense knowledge signi\ufb01cantly\nimproved the scores of each class in the task. As\nshown in Figure 8, while the single task BERT\nconfused with un/important sentences, MBERT\ncould correctly classi\ufb01ed some of the misclassi\ufb01ed\nsamples. It implies that commonsense knowledge\ncould help detection of check-worthy claims from\nthe all types of facts in the dataset.\nAdding CSQA as a downstream task in check-\nworthy claim detection was more effective on true\npositives than multiclass false news classi\ufb01cation\nwith the CSQA. That could be due to data for-mats of commonsense question answering task and\ncheck-worthy claim detection task are similar. It\nhad a positive effect on knowledge transfer between\nthe tasks. Both tasks contain short texts, one or two\nsentences, while samples in the datasets of false\nnews detection tasks are composed of long texts\nthat might bring about less overlapping between\nthe tokens from the task inputs.\n6 Discussion\nIn the experiments on the false news detection task,\nwe found that detecting right-lean articles, in gen-\neral, was not helpful among the classi\ufb01ers. The\nreason for the dif\ufb01culty in detecting right-lean ar-\nticles could be a potential data bias. Social media\nand crowd-sourced platforms tend to lend high visi-\nDataset Feature Model Satire Conspiracy Propaganda Neutral Bias-Left Bias-Right F1-Macro\nCINDTitleSVM 42.68 23.78 20.19 22.07 47.28 12.47 28.08\nBERT 53.47 37.20 26.02 30.75 50.24 17.47 35.86\nMTBERT 53.50 35.68 27.31 29.90 52.11 17.27 35.96\nBodySVM 72.30 44.90 42.75 39.27 53.62 19.77 42.75\nHAN 61.18 39.34 23.36 34.05 44.41 18.98 36.89\nHAN* 60.15 32.24 19.42 31.26 46.33 17.15 34.43\nBERT 78.82 42.63 23.00 38.94 51.27 26.57 43.54\nMTBERT 75.09 36.69 23.6 49.78 51.41 25.64 43.70\nMergedRDEL 70.11 37.88 25.12 30.37 48.99 21.76 39.04\n3HAN 54.36 29.37 20.88 31.44 44.83 17.20 33.01\n3HAN* 51.57 31.05 19.85 34.96 42.62 16.94 32.83\nBERT 76.46 43.05 23.34 46.90 51.67 23.35 44.13\nMTBERT 78.55 46.95 25.67 48.01 53.95 27.89 46.83\nNELATitleSVM 4.08 29.51 33.30 12.78 29.23 19.59 21.42\nBERT 4.59 38.50 27.94 17.89 28.32 20.91 23.02\nMTBERT 6.49 39.80 28.71 15.55 30.16 21.22 23.65\nBodySVM 8.67 43.03 35.18 22.28 36.02 26.47 28.61\nHAN 3.62 38.43 36.12 20.99 29.41 29.56 26.35\nHAN* 10.25 35.41 33.04 19.12 30.72 26.73 25.88\nBERT 16.28 44.08 38.74 17.25 38.55 34.44 31.56\nMTBERT 10.27 48.24 38.45 15.12 37.4 36.93 31.07\nMergedRDEL 11.52 39.87 35.12 21.79 33.43 28.80 28.42\n3HAN 9.79 37.79 35.92 18.59 30.98 27.81 26.86\n3HAN* 16.57 36.27 32.90 20.85 32.20 27.53 27.72\nBERT 13.92 50.04 37.94 20.48 38.33 31.24 31.99\nMTBERT 17.63 46.29 37.89 21.12 36.47 30.22 31.60\nTable 7: Results of the experiment that the news articles in test set are from previously unseen source. The cells\nindicate the mean and standard deviation of 5 folds F1 scores for each class and * indicates that the model using\nNumberbatch as embeddings. The bold scores are the best results per feature and dataset.\nModel CFS NFS UFS\nClaimBuster API 37.41 94.13 9.76\nClaimBuster 83.96 94.72 47.31\nSingle BERT 93.31 98.21 81.82\nMTBERT 95.16 98.36 88.00\nTable 8: F1 scores of each class in check-worthy claim\ndetection task. The bold scores are the best results.\nbility to viral content, which includes right-leaning\nand left-leaning news publishers that are by de\ufb01ni-\ntion extreme in their worldviews, coupled with a\nsensationalist tone. This issue also re\ufb02ects the exist-\ning dataset NELA and our newly collected dataset\nCIND. In our study, we observed that right-leaning\narticles are mostly misclassi\ufb01ed as left-leaning arti-\ncles. The dif\ufb01culty of detecting right-leaning arti-\ncles is also observed by Potthast et al. (2018) for the\nhyperpartisan news task. Additionally, Bozarth and\nBudak (2020) analyzed that fake news are mostly\nmisclassi\ufb01ed as right-leaning news and observed\nthat right-leaning news publishers sometimes cam-\npaigned false information. The signi\ufb01cant differ-\nence of our study from the prior studies (Potthast\net al., 2018; Bozarth and Budak, 2020) is that we\ntackle the problem as a multi-class news type clas-\nsi\ufb01cation because different fake news types may\nhave different implications. Biased sources can\nalso misinform the readers (Zannettou et al., 2019;\nWardle and Derakhshan, 2017), and \ufb01ne-graineddetection is vital for prioritizing what should be\nfact-checked.\nWe attempt to transfer commonsense knowledge\nto BERT representations implicitly with a multi-\ntasking approach. We achieved better performance\non the check-worthy claim detection task due to\nthe similar data type with CQSD. A sentence-based\napproach could be utilized to improve the per-\nformance in false news detection tasks and trans-\nfer knowledge more effectively than the current\nmethod. Also, explicit methods could be used for\nfalse news detection tasks. For example, a new task\ncould be introduced, a plausibility detection task\non news articles where annotators would evaluate\nthe degree of believability on articles. And then,\nthis task could be used as a downstream task.\n7 Conclusion\nIn this paper, we explore the impact of common-\nsense knowledge in the tasks of false news classi\ufb01-\ncation and check-worthy claim detection. To learn\ncommonsense knowledge implicitly, we \ufb01ne tune\nBERT jointly with CSQA for each tasks. The re-\nsults show that the proposed model can improve the\npredictions of minority classes in the datasets (e.g\nconspiracy in CIND, CFS in check-worthy claim\ndetection task). Also, similar formats of the inputs\nsuch as in CSQD and check-worthy claim detection\ncould have a positive effect on performance.\nIn conclusion, we introduced a new challenging\ndataset for a false news classi\ufb01cation task and to\nour knowledge, this is the \ufb01rst work that examines\nthe effects of using commonsense knowledge on\nfalse news classi\ufb01cation and check-worthy claim\ndetection tasks.\nReferences\nBill Adair, Mark Stencel, Cathy Clabby, and Chengkai\nLi. 2019. The human touch in automated fact-\nchecking: How people can help algorithms expand\nthe production of accountability journalism. In Com-\nputation+ Journalism Symposium , pages 1\u20135.\nFatma Arslan, Naeemul Hassan, Chengkai Li, and\nMark Tremayne. 2020. A benchmark dataset of\ncheck-worthy factual claims. In ICWSM , pages 821\u2013\n829. AAAI Press.\nPepa Atanasova, Llu \u00b4\u0131s M `arquez, Alberto Barr \u00b4on-\nCede \u02dcno, Tamer Elsayed, Reem Suwaileh, Wajdi Za-\nghouani, Spas Kyuchukov, Giovanni Da San Mar-\ntino, and Preslav Nakov. 2018. Overview of the\nCLEF-2018 checkthat! lab on automatic identi\ufb01-\ncation and veri\ufb01cation of political claims. task 1:\nCheck-worthiness. In CLEF (Working Notes) , vol-\nume 2125 of CEUR Workshop Proceedings . CEUR-\nWS.org.\nPepa Atanasova, Preslav Nakov, Georgi Karadzhov,\nMitra Mohtarami, and Giovanni Da San Martino.\n2019. Overview of the CLEF-2019 checkthat! lab:\nAutomatic identi\ufb01cation and veri\ufb01cation of claims.\ntask 1: Check-worthiness. In CLEF (Working\nNotes) , volume 2380 of CEUR Workshop Proceed-\nings. CEUR-WS.org.\nPepa Atanasova, Jakob Grue Simonsen, Christina Li-\noma, and Isabelle Augenstein. 2020. Generating\nfact checking explanations. In ACL, pages 7352\u2013\n7364. Association for Computational Linguistics.\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-\ngio. 2015. Neural machine translation by jointly\nlearning to align and translate. In ICLR .\nRamy Baly, Georgi Karadzhov, Dimitar Alexandrov,\nJames R. Glass, and Preslav Nakov. 2018. Predict-\ning factuality of reporting and bias of news media\nsources. In EMNLP , pages 3528\u20133539. Association\nfor Computational Linguistics.\nRamy Baly, Georgi Karadzhov, Abdelrhman Saleh,\nJames R. Glass, and Preslav Nakov. 2019. Multi-\ntask ordinal regression for jointly predicting the\ntrustworthiness and the leading political ideology of\nnews media. In NAACL-HLT (1) , pages 2109\u20132116.\nAssociation for Computational Linguistics.Alberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Preslav\nNakov, Giovanni Da San Martino, Maram Hasanain,\nReem Suwaileh, Fatima Haouari, Nikolay Babulkov,\nBayan Hamdan, Alex Nikolov, Shaden Shaar, and\nZien Sheikh Ali. 2020. Overview of checkthat!\n2020: Automatic identi\ufb01cation and veri\ufb01cation of\nclaims in social media. In CLEF , volume 12260 of\nLecture Notes in Computer Science , pages 215\u2013236.\nSpringer.\nAlberto Barr \u00b4on-Cede \u02dcno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Inf. Process. Manag. , 56(5):1849\u20131864.\nJason Baumgartner, Savvas Zannettou, Brian Keegan,\nMegan Squire, and Jeremy Blackburn. 2020. The\npushshift reddit dataset. In ICWSM , pages 830\u2013839.\nAAAI Press.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli C \u00b8 elikyilmaz, and Yejin Choi.\n2019. COMET: commonsense transformers for au-\ntomatic knowledge graph construction. In ACL (1) ,\npages 4762\u20134779. Association for Computational\nLinguistics.\nLia Bozarth and Ceren Budak. 2020. Toward a bet-\nter performance evaluation framework for fake news\nclassi\ufb01cation. In ICWSM , pages 60\u201371. AAAI\nPress.\nMarkus M. Breunig, Hans-Peter Kriegel, Raymond T.\nNg, and J \u00a8org Sander. 2000. LOF: identifying\ndensity-based local outliers. In SIGMOD Confer-\nence, pages 93\u2013104. ACM.\nCeren Budak, Divyakant Agrawal, and Amr El Abbadi.\n2011. Limiting the spread of misinformation in so-\ncial networks. In WWW , pages 665\u2013674. ACM.\nSylvie Cazalens, Philippe Lamarre, Julien Leblay,\nIoana Manolescu, and Xavier Tannier. 2018. A con-\ntent management perspective on fact-checking. In\nWWW (Companion Volume) , pages 565\u2013574. ACM.\nKyunghyun Cho, Bart van Merrienboer, C \u00b8 aglar\nG\u00a8ulc \u00b8ehre, Dzmitry Bahdanau, Fethi Bougares, Hol-\nger Schwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using RNN encoder-decoder\nfor statistical machine translation. In EMNLP , pages\n1724\u20131734. ACL.\nLouise Connell and Mark T Keane. 2003. Pam: A\ncognitive model of plausibility. In Proceedings of\nthe Annual Meeting of the Cognitive Science Society ,\nvolume 25.\nLouise Connell and Mark T Keane. 2004. What plau-\nsibly affects plausibility? concept coherence and\ndistributional word coherence as factors in\ufb02uenc-\ning plausibility judgments. Memory & cognition ,\n32(2):185\u2013197.\nJiachen Du, Lin Gui, Ruifeng Xu, Yunqing Xia, and\nXuan Wang. 2020. Commonsense knowledge en-\nhanced memory network for stance classi\ufb01cation.\nPepa Gencheva, Preslav Nakov, Llu \u00b4\u0131s M `arquez, Al-\nberto Barr \u00b4on-Cede \u02dcno, and Ivan Koychev. 2017.\nA context-aware approach for detecting worth-\nchecking claims in political debates. In RANLP ,\npages 267\u2013276. INCOMA Ltd.\nBilal Ghanem, Paolo Rosso, and Francisco M. Rangel\nPardo. 2020. An emotional analysis of false infor-\nmation in social media and news articles. ACM\nTrans. Internet Techn. , 20(2):19:1\u201319:18.\nDan Goldwasser and Xiao Zhang. 2016. Understand-\ning satirical articles using common-sense. Trans. As-\nsoc. Comput. Linguistics , 4:537\u2013549.\nLucas Graves. 2018. Understanding the promise\nand limits of automated fact-checking. Factsheet ,\n2:2018\u201302.\nMaur \u00b4\u0131cio Gruppi, Benjamin D. Horne, and Sibel Adali.\n2020. NELA-GT-2019: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. CoRR , abs/2003.08444.\nNaeemul Hassan, Bill Adair, James T Hamilton,\nChengkai Li, Mark Tremayne, Jun Yang, and Cong\nYu. 2015a. The quest to automate fact-checking. In\nProceedings of the 2015 Computation+ Journalism\nSymposium .\nNaeemul Hassan, Chengkai Li, and Mark Tremayne.\n2015b. Detecting check-worthy factual claims in\npresidential debates. In Proceedings of the 24th\nacm international on conference on information and\nknowledge management , pages 1835\u20131838.\nNaeemul Hassan, Gensheng Zhang, Fatma Arslan, Jo-\nsue Caraballo, Damian Jimenez, Siddhant Gawsane,\nShohedul Hasan, Minumol Joseph, Aaditya Kulka-\nrni, Anil Kumar Nayak, Vikas Sable, Chengkai Li,\nand Mark Tremayne. 2017. Claimbuster: The \ufb01rst-\never end-to-end fact-checking system. Proc. VLDB\nEndow. , 10(12):1945\u20131948.\nBenjamin D. Horne, William Dron, Sara Khedr, and\nSibel Adali. 2018. Assessing the news landscape:\nA multi-module toolkit for evaluating the credibility\nof news. In WWW (Companion Volume) , pages 235\u2013\n238. ACM.\nHamid Karimi and Jiliang Tang. 2019. Learning hierar-\nchical discourse-level structure for fake news detec-\ntion. In NAACL-HLT (1) , pages 3432\u20133442. Associ-\nation for Computational Linguistics.\nNatascha Karlova and Karen E. Fisher. 2013. A social\ndiffusion model of misinformation and disinforma-\ntion for understanding human information behaviour.\nInf. Res. , 18(1).\nElena Kochkina, Maria Liakata, and Arkaitz Zubiaga.\n2018. All-in-one: Multi-task learning for rumour\nveri\ufb01cation. In COLING , pages 3402\u20133413. Associ-\nation for Computational Linguistics.David MJ Lazer, Matthew A Baum, Yochai Ben-\nkler, Adam J Berinsky, Kelly M Greenhill, Filippo\nMenczer, Miriam J Metzger, Brendan Nyhan, Gor-\ndon Pennycook, David Rothschild, et al. 2018. The\nscience of fake news. Science , 359(6380):1094\u2013\n1096.\nXiaodong Liu, Pengcheng He, Weizhu Chen, and Jian-\nfeng Gao. 2019. Multi-task deep neural networks for\nnatural language understanding. In ACL (1) , pages\n4487\u20134496. Association for Computational Linguis-\ntics.\nYukun Ma, Haiyun Peng, and Erik Cambria. 2018.\nTargeted aspect-based sentiment analysis via em-\nbedding commonsense knowledge into an attentive\nLSTM. In AAAI , pages 5876\u20135883. AAAI Press.\nKai Nakamura, Sharon Levy, and William Yang Wang.\n2020. Fakeddit: A new multimodal benchmark\ndataset for \ufb01ne-grained fake news detection. In\nLREC , pages 6149\u20136157. European Language Re-\nsources Association.\nJeppe N\u00f8rregaard, Benjamin D. Horne, and Sibel Adali.\n2019. NELA-GT-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. In ICWSM , pages 630\u2013638. AAAI Press.\nJeffrey Pennington, Richard Socher, and Christopher D.\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In EMNLP , pages 1532\u20131543. ACL.\nVer\u00b4onica P \u00b4erez-Rosas, Bennett Kleinberg, Alexandra\nLefevre, and Rada Mihalcea. 2018. Automatic de-\ntection of fake news. In COLING , pages 3391\u20133401.\nAssociation for Computational Linguistics.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2018. A stylo-\nmetric inquiry into hyperpartisan and fake news. In\nACL (1) , pages 231\u2013240. Association for Computa-\ntional Linguistics.\nHannah Rashkin, Eric Bell, Yejin Choi, and Svitlana\nV olkova. 2017a. Multilingual connotation frames:\nA case study on social media for targeted sentiment\nanalysis and forecast. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 459\u2013\n464, Vancouver, Canada. Association for Computa-\ntional Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017b. Truth of varying\nshades: Analyzing language in fake news and po-\nlitical fact-checking. In EMNLP , pages 2931\u20132937.\nAssociation for Computational Linguistics.\nBenjamin Riedel, Isabelle Augenstein, Georgios P. Sp-\nithourakis, and Sebastian Riedel. 2017. A simple but\ntough-to-beat baseline for the fake news challenge\nstance detection task. CoRR , abs/1707.03264.\nVictoria L. Rubin, Yimin Chen, and Niall J. Conroy.\n2015. Deception detection for news: Three types\nof fakes. In ASIST , volume 52 of Proceedings of the\nAssociation for Information Science and Technology ,\npages 1\u20134. Wiley.\nSebastian Ruder. 2017. An overview of multi-\ntask learning in deep neural networks. CoRR ,\nabs/1706.05098.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof BERT: smaller, faster, cheaper and lighter. CoRR ,\nabs/1910.01108.\nKai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and\nHuan Liu. 2017. Fake news detection on social me-\ndia: A data mining perspective. SIGKDD Explo-\nrations , 19(1):22\u201336.\nSneha Singhania, Nigel Fernandez, and Shrisha Rao.\n2017. 3han: A deep neural network for fake news\ndetection. In ICONIP (2) , volume 10635 of Lec-\nture Notes in Computer Science , pages 572\u2013581.\nSpringer.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptNet 5.5: An open multilingual graph of gen-\neral knowledge. pages 4444\u20134451.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. Commonsenseqa: A ques-\ntion answering challenge targeting commonsense\nknowledge. In NAACL-HLT (1) , pages 4149\u20134158.\nAssociation for Computational Linguistics.\nJames Thorne and Andreas Vlachos. 2018. Automated\nfact checking: Task formulations, methods and fu-\nture directions. In COLING , pages 3346\u20133359. As-\nsociation for Computational Linguistics.\nFatemeh Torabi Asr and Maite Taboada. 2019. Big\ndata and quality data for fake news and mis-\ninformation detection. Big Data & Society ,\n6(1):2053951719843310.\nSvitlana V olkova, Kyle Shaffer, Jin Yea Jang, and\nNathan Oken Hodas. 2017. Separating facts from\n\ufb01ction: Linguistic models to classify suspicious and\ntrusted news posts on twitter. In ACL (2) , pages 647\u2013\n653. Association for Computational Linguistics.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151.\nLiang Wang, Meng Sun, Wei Zhao, Kewei Shen, and\nJingming Liu. 2018. Yuanfudao at semeval-2018\ntask 11: Three-way attention and relational knowl-\nedge for commonsense machine comprehension. In\nSemEval@NAACL-HLT .\nClaire Wardle and Hossein Derakhshan. 2017. Infor-\nmation disorder: Toward an interdisciplinary frame-\nwork for research and policy making. Council of\nEurope report , 27.Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R\u2019emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface\u2019s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv , abs/1910.03771.\nZhenhui Xu, Qiang Li, Wei Chen, Yingbao Cui, Zhen\nQiu, and Tengjiao Wang. 2019. Opinion-aware\nknowledge embedding for stance detection. In\nAsia-Paci\ufb01c Web (APWeb) and Web-Age Informa-\ntion Management (WAIM) Joint International Con-\nference on Web and Big Data , pages 337\u2013348.\nSpringer.\nZichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,\nAlexander J. Smola, and Eduard H. Hovy. 2016. Hi-\nerarchical attention networks for document classi\ufb01-\ncation. In HLT-NAACL , pages 1480\u20131489. The As-\nsociation for Computational Linguistics.\nSavvas Zannettou, Tristan Caul\ufb01eld, Emiliano De\nCristofaro, Nicolas Kourtellis, Ilias Leontiadis,\nMichael Sirivianos, Gianluca Stringhini, and Jeremy\nBlackburn. 2017. The web centipede: understand-\ning how web communities in\ufb02uence each other\nthrough the lens of mainstream and alternative\nnews sources. In Internet Measurement Conference ,\npages 405\u2013417. ACM.\nSavvas Zannettou, Michael Sirivianos, Jeremy Black-\nburn, and Nicolas Kourtellis. 2019. The web of false\ninformation: Rumors, fake news, hoaxes, clickbait,\nand various other shenanigans. J. Data and Informa-\ntion Quality , 11(3):10:1\u201310:37.\nPeixiang Zhong, Di Wang, and Chunyan Miao. 2019a.\nKnowledge-enriched transformer for emotion detec-\ntion in textual conversations. In EMNLP/IJCNLP\n(1), pages 165\u2013176. Association for Computational\nLinguistics.\nWanjun Zhong, Duyu Tang, Nan Duan, Ming Zhou, Jia-\nhai Wang, and Jian Yin. 2019b. Improving question\nanswering by commonsense-based pre-training. In\nNLPCC (1) , volume 11838 of Lecture Notes in Com-\nputer Science , pages 16\u201328. Springer.\nXinyi Zhou and Reza Zafarani. 2020. A survey of fake\nnews: Fundamental theories, detection methods, and\nopportunities. ACM Computing Surveys (CSUR) .\nAppendix\n7.1 Details on CIND\n7.1.1 Sample Distributions based on source type and subreddit\nThis section gives more details about CIND. Figure 3 and 4 show the distributions of source types in each\nsubreddit that we used. In the diagrams, bias tag combines bias-right and bias-left articles. Even though\nwe could expect that some subreddits contain only speci\ufb01c source types, some source types are shared\nwithin multiple subreddits. For instance, neutral sources are seen in each subreddits.\n7.1.2 Sample distributions on forecasting and unseen prediction tasks\nSplit Conspiracy Bias-Left Neutral Propaganda Bias-Right Satire\nTrain 574 955 844 847 1019 859\nTest 50 399 257 227 130 437\nTable 9: Data splits for the forecasting task.\nFold Split Conspiracy Bias-Left Neutral Propaganda Bias-Right Satire\n1 Train 662 1610 1146 1102 1087 1899\nTest 60 271 219 105 192 77\n2 Train 689 1467 1330 1189 1198 1724\nTest 33 414 35 21 81 252\n3 Train 493 1500 1301 1167 1226 1864\nTest 229 381 64 40 53 112\n4 Train 666 1653 1072 1173 1198 1686\nTest 56 228 293 34 81 290\n5 Train 648 1770 1162 1094 1057 1859\nTest 74 111 203 113 222 117\nTable 10: Data splits for the unseen prediction task.\nTables 9 and 10 include overview of the class distributions for the forecasting and unseen prediction\ntasks on CIND.\n7.2 Experimental Settings\n7.2.1 Preprocessing\nFor false news detection task, we apply the following steps by using clean-text to the news articles before\nencoding them as an input of the models library6:\n\u2022 We lower tokens.\n\u2022 We replace urls, emails, phones, numbers and currency symbols with speci\ufb01c tags.\n\u2022 We \ufb01x the unicodes and remove all whitespaces.\n7.2.2 Training and Model Parameters\nWe list the hyperparameters of each model and parameters for training them in Table 11.\n6https://pypi.org/project/clean-text/\nFigure 3: Sample distributions per source type and per subreddit.\nFigure 4: Sample distributions per source type and per subreddit. (Cont.)\nModel Parameter Name Value\n3HAN max length of words 20\nmax length of headline 20\nmax length of sentences 30\npretrained model Glove\nNumberbatch\nhidden dim 50\nword dropout 0.4\nsentence dropout 0.4\ntitle-body dropout 0.4\nmax length of vocabulary 25000\nbatch size 8\nepochs 100\n(with early stopping)\nclipnorm 5\nlearning rate 1e-3\nHAN max length of words 20\nmax length of sentences 30\npretrained model Glove\nNumberbatch\nhidden dim 50\nword dropout 0.4\nsentence dropout 0.4\nmax length of vocabulary 25000\nbatch size 8\nepochs 100\n(with early stopping)\nclipnorm 5\nlearning rate 1e-3\nSVM max length of vocabulary 25000\nRDEL max length of vocabulary 25000\nepochs 100\n(with early stopping)\nclipnorm 5\nlearning rate 1e-3\nBERT batch size 2\n& learning rate 2e-5\nMultitask epochs 4\nBERT max length of body 512\nmax lenght of title or statement 128\nTable 11: Training parameters and hyperparameters for each model.\n(a) Single BERT\n(b) Multitask BERT\nFigure 5: Confusion Matrices of Predictions from Single BERT and Multitask BERT on the forecasting task.\n(a) Single BERT\n(b) Multitask BERT\nFigure 6: Confusion Matrices of Predictions of Single BERT and Multitask BERT from the unseen prediction task\non CIND dataset.\n(a) Single BERT\n(b) Multitask BERT\nFigure 7: Confusion Matrices of Predictions from Single BERT and Multitask BERT on NELA dataset.\n(a) Single BERT\n(b) Multitask BERT\nFigure 8: Confusion Matrices of Predictions from Single BERT and Multitask BERT on the check-worthiness\ndetection task.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Leveraging commonsense knowledge on classifying false news and determining checkworthiness of claims", "author": ["IB Schlicht", "E Sezerer", "S Tekir", "O Han"], "pub_year": "2021", "venue": "arXiv preprint arXiv \u2026", "abstract": "Widespread and rapid dissemination of false news has made fact-checking an indispensable  requirement. Given its time-consuming and labor-intensive nature, the task calls for an"}, "filled": false, "gsrank": 37, "pub_url": "https://arxiv.org/abs/2108.03731", "author_id": ["ueOrUyUAAAAJ", "h4aP7RIAAAAJ", "iRawdD8AAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:SAZ0VCRiYxAJ:scholar.google.com/&output=cite&scirp=36&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D30%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=SAZ0VCRiYxAJ&ei=CrWsaIYfwNmJ6g-p2qHxBQ&json=", "num_citations": 4, "citedby_url": "/scholar?cites=1180895435476436552&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:SAZ0VCRiYxAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2108.03731"}}, {"title": "Detection and discovery of misinformation sources using attributed webgraphs", "year": "2024", "pdf_data": "Detection and Discovery of Misinformation Sources Using Attributed Webgraphs\nPeter Carragher, Evan M. Williams, Kathleen M. Carley\nCarnegie Mellon University\n4665 Forbes Ave, Pittsburgh, PA 15213\n{pcarragh, emwillia, carley}@andrew.cmu.edu\nAbstract\nWebsite reliability labels underpin almost all research in mis-\ninformation detection. However, misinformation sources of-\nten exhibit transient behavior, which makes many such la-\nbeled lists obsolete over time. We demonstrate that Search\nEngine Optimization (SEO) attributes provide strong signals\nfor predicting news site reliability. We introduce a novel at-\ntributed webgraph dataset with labeled news domains and\ntheir connections to outlinking and backlinking domains. We\ndemonstrate the success of graph neural networks in detect-\ning news site reliability using these attributed webgraphs, and\nshow that our baseline news site reliability classifier outper-\nforms current SoTA methods on the PoliticalNews dataset,\nachieving an F1 score of 0.96. Finally, we introduce and eval-\nuate a novel graph-based algorithm for discovering previ-\nously unknown misinformation news sources.\nIntroduction\nIn 2014, Sinclair Treadway and Sean Adl-Tabatabai founded\nYourNewsWire, which over time was identified by many\nfact-checkers as a purveyor of misinformation. In 2019,\nthe co-founders, blaming loss of revenue on Facebook\u2019s\nfact-checking system, rebranded their website by simply\nmigrating the domain name from \u201cyournewswire.com\u201d to\n\u201cnewspunch.com\u201d (Binder 2019).\nThe detection of misinformation sources among news do-\nmains relies heavily on preexisting domain reliability labels.\nHowever, these curated domain lists are subject to two core\nlimitations. Firstly, as illustrated above, building automated\nsystems to detect websites that consistently spread misinfor-\nmation is made challenging by the ease of the evasion and\nexit tactics available to bad actors. As researchers and fact-\nchecking organizations identify and release misinformation\nsources, the owners can shut down the site, migrate to a new\ndomain, or simply start over with a new website. Conse-\nquently, we observe that over 50% of domains on unmain-\ntained blocklists published between 2017 and 2019 are dead.\nThis presents a major obstacle for misinformation source de-\ntection and discovery tasks.\nSecondly, the vast majority of misinformation source re-\nsearch relies on signals mined from public social media data.\nCopyright \u00a9 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.As misinformation becomes increasingly prevalent in devel-\noping countries where social media usage remains uncom-\nmon or where English is not the primary language, detec-\ntion and discovery methodologies that are not dependent on\nwebsite content or social media are needed (Okereke et al.\n2021).\nWe attempt to address these obstacles by demonstrating\nthe predictive power of webgraph and Search Engine Op-\ntimization (SEO) data in detecting news site reliability and\nbias. This paper does not rely on social media data to iden-\ntify unreliable domains, but rather relies on pointers be-\ntween websites. We provide three primary contributions in\nthis work. Firstly, we introduce a novel attributed webgraph\ndataset with labeled news domains and their connections\nto top outlinking and backlinking domains, i.e. domains to\nwhich a target domain links and domains that link to the\ntarget domain. Secondly, with extensive experiments, we\ndemonstrate the predictive power present in the data by us-\ning graph neural network (GNN) models to predict the reli-\nability and bias of reliable and unreliable news domains. We\nshow that these models outperform existing work on the Po-\nliticalNews dataset (Castelo et al. 2019). We make all data1\nand code public2.\nFinally, we present a novel webgraph-based discovery ap-\nproach that is not dependent on language, content, or so-\ncial media data, and we demonstrate the success of the ap-\nproach in identifying previously-unknown unreliable news\ndomains. The content-agnostic and social media-agnostic\nnature of this work differentiates our approach from all pre-\nvious work on this topic and provides several key advan-\ntages. Firstly, this allows our approach to be implemented\nin non-English settings. Secondly, our approach is not re-\nliant on API access to social media data. Finally, our content\nagnostic system will not be impacted by increasing use of\ngenerative AI in SEO settings, which has been identified as\nan emerging threat (Petrou et al. 2023).\n1https://doi.org/10.1184/R1/25174193.v1\n2https://github.com/CASOS-IDeaS-CMU/Detection-and-\nDiscovery-of-Misinformation-Sources\nProceedings of the Eighteenth International AAAI Conference on Web and Social Media (ICWSM 2024)\n214\nRelated Work\nMisinformation Detection\nClassifying individual texts or articles is a core problem\naddressed by research in misinformation detection. Castelo\net al. (2019) address misinformation page detection using ar-\nticle content which Chen and Freire (2020) extend to unreli-\nable domain discovery using social media context. Building\non that work, Silva et al. (2021) combine website content\nand social context resulting in a misinformation page detec-\ntion method that leverages multi-modal data.\nWe depart from the article and content-centered ap-\nproaches to misinformation detection in that our detection\nsystems are at the domain-level. While a single article may\nbe considered misinformation, the collection of articles pub-\nlished by a single news domain has an associated probabil-\nity distribution that captures how likely an article is to con-\ntain misinformation, given the source. In content-centered\napproaches, reliability scores are assigned to domains based\non this distribution, labeling domains that frequently publish\narticles containing misinformation as \u201cunreliable\u201d. As we\nare concerned with misinformation sources, we discuss un-\nreliable domain detection rather than misinformation page\ndetection, using \u2018misinformation source\u2019 and \u2018unreliable do-\nmain\u2019 interchangeably.\nMotivating our domain-level and content-agnostic ap-\nproach, Petrou et al. (2023) employed change-point detec-\ntion to reveal that the linguistic features outlined in Castelo\net al. (2019) evolve over time. They find significant variance\nin the psychological features that distinguish reliable arti-\ncles from those peddling misinformation, making unreliable\npage detection difficult over long periods of time. Our we-\nbgraph methods present a novel approach to unreliable do-\nmain detection and discovery which avoids common pitfalls\nof the content-based approach.\nWebgraphs\nSeveral studies have explored the predictive power of web-\ngraphs on tasks related to unreliable domain detection. Us-\ning community detection methods, Aires, G. Nakamura, and\nF. Nakamura (2019) scrape links from US and UK news\nsites and find clusters based on political bias using labels\nfrom Media Bias Fact Check (MBFC) (Zandt 2022). Sim-\nilarly, Hrckova et al. (2021) found that partisan news do-\nmains in central Europe form clusters in webgraph data.\nSehgal et al. (2021) present a case study on hyperlink and\nsocial media usage for peddling misinformation. They ex-\nplore coordinated use of hyperlinks and social media on a\ndataset of 1.4k URLs with reliability labels drawn from var-\nious sources, including MBFC. Lee et al. used the linkage\npatterns of labeled news domains shared by Twitter users to\nvisualize connections of domains to unreliable domains on\nTwitter (Lee et al. 2022). These analyses provide theoreti-\ncal justifications for using webgraph data to detect website\nreliability and bias.\nSearch Engine Optimization\nSEO is an 80 billion dollar industry built to increase traf-\nfic to websites (McCue 2018). High-ranking pages are farmore likely to be seen. In a 2013 analysis of 300 million\nsearch engine clicks: 92% were on first page of search re-\nsults with the majority of clicks going to just the top two\n(Chitika 2013). Furthermore, users were found to be 140%\nmore likely to click the last result on the first page than the\nfirst result on the second page (Chitika 2013). Consequently,\nSEO has become ubiquitous. On a study of over 250k search\nresults, Lewandowski, S \u00a8unkler, and Yagci (2021) found that\nonly 12% were likely not to have been optimized, and 58%\nwere certainly optimized. Zhang and Cabage (2017) contrast\nthe effectiveness of SEO and social media-sharing for media\npromotion. They find that while social media-sharing results\nin more immediate boosts to traffic in the short term, link-\nbuilding is superior in the long term. In this work we elect\nto focus on link building, leaving the role that social-sharing\nstrategies plays in boosting unreliable new sources to future\nwork.\nBlack-hat SEO While many SEO practices are endorsed\nby search engines, those aimed at gaming recommendation\nalgorithms are forbidden by search engine webmaster guide-\nlines3\u2014these tactics are typically referred to as \u201cblack-hat\u201d\nSEO. For a detailed overview of white-hat and black-hat\nSEO methods, we refer the reader to the work done by\nMalaga (2010). Common black-hat SEO techniques of rele-\nvance here are: (1) attracting search engine indexers through\nnetworks of blogs (\u2018Blog Ping\u2019), (2) automated user engage-\nment in forums or comment sections (\u2018User Generated Con-\ntent\u2019), and (3) link building by spamming (\u2018Link Schem-\ning\u2019). More recently, Aswani et al. (2018) analysed the sen-\ntiment of SEO service customers and found that 32% of re-\nspondents believed that the widespread use of black-hat SEO\nmethods by SEO service providers was damaging their rank-\ning. Aswani et al. (2021) suggest that clustering domains\nbased on high level SEO attributes such as Pagerank score\nand Domain Authority can identify black-hat link scheme\nsites. This motivates our approach to identifying link scheme\nsites, which is the first step in our network-based unreliable\ndomain discovery process (Algorithm 1).\nSEO and Misinformation Search engine rankings have\nbroad impacts even outside of e-commerce; it has been\nshown that Search engine rankings can have a substan-\ntial impact on the political beliefs and voting patterns of\nusers (Epstein and Robertson 2015). Three laboratory ex-\nperiments with double-blind control group design found that\nrelatively minor changes in search engine rankings could in-\nfluence decisions of undecided voters4. Search engine au-\ndit studies\u2014studies where researchers query terms on mul-\ntiple search engines and compare the rankings\u2014have re-\nvealed a link between SEO and misinformation. For exam-\nple, Urman et al. (2022) executed conspiratorial searches\non Google, Bing, DuckDuckGo, and Yandex and found that\n3https://developers.google.com/search/docs/essentials/spam-\npolicies\n4The magnitude of the effects in this work are disputed by\nKatharina Zweig, who finds that the cumulative effect is likely on\nthe order of 2-4% rather than the 20% reported in the study (Zweig\n2017).\n215\nYandex and DuckDuckGo consistently return misinforma-\ntion from unreliable sources in their top search results. Brad-\nshaw (2019) analyzed how a set of 29 junk news sites opti-\nmize keywords to increase web-traffic and spread disinfor-\nmation over a three year period. More recently, Williams\nand Carley (2023) demonstrated the usefulness of webgraph\ndata in identifying large-scale link scheme activities around\nKremlin-aligned propaganda domains. We build on these ef-\nforts in an attempt to link specific black-hat SEO tactics to\nunreliable news sources.\nDomain Monitoring\nWeinberg et al. (2017) find that older website blocklists have\na high rate of parked domains\u2014domains that are up for sale\nand not currently in use. Domain survival rates are estimated\nusing a classifier that is trained to flag parked domains (Vis-\nsers, Joosen, and Nikiforakis 2015; Szurdi et al. 2014). We\nnote that this limitation of blocklists has notbeen recognized\nby previous work on unreliable domain lists.\nTasks\nWe evaluate our approach using three classification tasks.\n1)Reliability Prediction: a binary classification task deter-\nmining domain reliability. 2) Relative Political Bias: binary\n\u201cleft\u201d-\u201cright\u201d partisan lean classification. 3) Absolute Po-\nlitical Bias: a binary \u201ccenter\u201d-\u201cextreme\u201d task determining\nwhether the site publishes extremist or centrist content.\nPrevious research and government reporting has demon-\nstrated how IRA trolls amplify both extreme left and extreme\nright sources to sow discord and increase polarization (Brad-\nshaw, DiResta, and Miller 2022). Training separate classi-\nfiers for left-right and extreme-center dimensions of political\nbias enables a more fine-grained discovery approach.\nGiven the transient nature of many misinformation do-\nmains, classification of existing labeled domains may be of\nlimited value. We therefore introduce a final task, 4) Mis-\ninformation Domain Discovery, to allow us to identify new\nmisinformation domains. We split this process into two con-\nceptual steps: 1) Develop a set of criteria for identifying sus-\npicious backlinking patterns and 2) Extract unreliable web-\nsites to which suspicious websites link.\nData\nNews Site Identification\nTo identify a starting set of news sources for our tasks, we\nleverage information from two different sources. The bulk\nof our domain list is made up of domain labels scraped from\nMBFC5(Zandt 2022). MBFC has six grades of reliability,\nranging from very low to very high. MBFC also provides po-\nlitical bias labels ranging from extreme left (-2) to extreme\nright (+2), the distribution of which is given in figure 1.\nDomains collected by Grinberg et al. (2019) were part of\nan investigation into the role of social media in spreading\nmisinformation during the 2016 US Presidential Elections.\nAs part of their analysis, they publish lists of unreliable\nsites from various investigative sources; Buzzfeed, Politico,\n5https://mediabiasfactcheck.com/methodology/and Snopes.com, as well as domains identified in their own\nanalysis. They also draw on a blocklist built by Allcott and\nGentzkow (2017), which published a dataset of 125 URLs\nextracted from articles scraped from Politico, Snopes.com,\nand Facebook. URLs are extracted based on keywords perti-\nnent to the 2016 election. We combine the MBFC data with\nthese previous lists (Grinberg et al. 2019) for a total of 4,206\ndomains. A recent study on the correlation of news reliabil-\nity ratings constructs a similar list (Lin et al. 2022). Table 1\ngives a count of domains per source.\nDomain List Analysis\nWe investigate the survival rates of domains from\npreviously-published unreliable domain blocklists, and filter\nout dead domains. For each domain we determine whether\nthe domain responds to GET requests and whether the do-\nmains are parked, i.e., are not being held for sale by a parked\ndomain registrar. If a GET request returns a 404, the site\nis dead. If the domain is parked or dead, then it should no\nlonger be included in the dataset.\nTo determine whether domains were parked, we build a\nboosted decision tree classifier following the methodology\nproposed in Vissers, Joosen, and Nikiforakis (2015). For\nmore information on the Parked Domain classifier method-\nology, see the appendix. When applied to our list of domains,\nthe model identified 248 parked domains with 96% precision\n(based on a manual evaluation on a 10% sample).\nIn Table 1, we show that the older labeled sources from\nGrinberg et al. (2019) have low survival rates. MBFC is\ncontinuously-maintained, so it has high survival rates. With\nthe exception of the Snopes.com list (which is drawn from\nthe dedicated fact-checking site), the non-maintained lists\nhave survival rates of less than 50%. The number of links\nthat point to a site is also an indication of the status of a\nsite (Ahrefs 2022). We observe that simply dropping news\nwebsites with less than 10k backlinks excludes the majority\nof the dead domains: it filters out 63% of domains return-\ning 404s and 87% of parked domains. We postulate that this\nmakes filtering by backlinks a reasonable heuristic for the\nparked domain classifier and the 404 classifier in unreliable\ndomain discovery. This further simplifies our method such\nthat parked domain and 404 classifiers are not needed.\nIn summary, we filter out any sites that have less than 10k\nbacklinks as those are unlikely to be influential news sites.\nOur final domain reliability dataset contains 3,211 labeled\ndomains which we will refer to as MBFC* (Table 1).\nSource URLs !404 !Parked Both >10k\nMBFC 3227 97% 99% 96% 87%\nMBFC-Q 426 90% 94% 84% 67%\nSnopes 55 80% 84% 67.5% 69%\nBlocklist 359 74% 59% 43.5% 11%\nPolitico 83 65% 68% 44% 18%\nBuzzfeed 55 70% 50% 35% 11%\nTotal 4205 3910 3952 3658 3211\nTable 1: Unreliable Source Survival Rates\n216\nMBFC* Site Labels\nTo unify labels from each source, we needed to binarize la-\nbels. There are some sites that MBFC classifies as \u2018question-\nable\u2019, but it does not assign these sites a reliability score6.\nAfter inspecting a sample of these domains, we chose to\nassign these questionable websites an unreliable label. We\nhandle overlap between lists by taking the most recent label\navailable. This results in current MBFC labels having prece-\ndence over the labels assigned by earlier works.\nThe blocklist domains label unreliable websites as black\n(very low reliability), red (low), and orange/yellow (mixed),\nwhich we map to the corresponding labels used in MBFC.\nRemaining consistent with Chen and Freire (2020), any do-\nmain with a reliability rating of mixed or lower is assigned\nan unreliable label, the rest are assigned reliable labels.\nFor the bias tasks we use only the labels from MBFC as\nthe blocklist sites do not have bias labels (Grinberg et al.\n2019)). Using the >10k backlink criteria for filtering out\ndead domains, we are left with 2,629 bias labels. For the\nrelative political bias task, we label the domain left if the\nMBFC bias score is less than 0, right if the bias score greater\nthan 0. Labels of value zero, i.e., centrist labels, are dropped\nfor this task. For the absolute bias task, bias scores of -1, 0,\nand 1 are assigned the centrist label; otherwise we label it\nextreme.\nOur two final datasets contain 3,211 reliability-labeled\ndomains and 2,629 bias-labeled domains. In Figure 1 we\nvisualize the distributions of political bias labels for each\nnews site reliability label. Aside from a 2:1 ratio of reliable\nto unreliable domains, we note reliable domains tend to to\nskew centrist, whereas unreliable domains tend to skew to-\nwards political extremes. Exploratory data analysis shows\nthat SEO attributes align with our intuition with respect to\nwebsite reliability (see Figure 9 in the appendix). For exam-\nple, we find a positive correlation between the binary relia-\nbility labels and the proportion of backlinks that come from\n.edu domains (r = 0. 09), as well as from .gov domains\n(r= 0.08).\nFigure 1: Bias label counts grouped by reliability.\n6https://mediabiasfactcheck.com/fake-news/PoliticalNews\nThe PoliticalNews dataset is a popular evaluation dataset\nin fake news detection studies. It was proposed by Castelo\net al. (2019) alongside the Topic-AGnostic (TAG) classifier\nfor use in misinformation page detection. It has since been\nadopted by Chen and Freire (2020) to evaluate unreliable do-\nmain detection methods. It consists of 137 domains, includ-\ning 58 news domains and 79 unreliable domains collected\nbetween 2013 and 2018. As other detection methods have\npublished results on this evaluation set (Castelo et al. 2019;\nChen and Freire 2020), it serves as a useful benchmark for\nour SEO-based detection method.\nSite Attributes\nWe pull SEO attributes for both MBFC* and Political-\nNews using Ahrefs\u2014a proprietary search engine optimiza-\ntion toolkit that purports to possess a 13 trillion link database\nand the third most active commercial webcrawler after\nGoogle7. We pull 24 different attributes for each domain in\nour dataset, including the number of .edu domains that link\nto the website, total number of backlinks, and whether or not\nthe domain has links from user-generated content (Figure 5).\nConstructing a Webgraph\nWe construct webgraphs for the MBFC* dataset using top\nbacklink and outlink domain data from Ahrefs. As a result\nof API and monetary constraints, we limit the webgraph to\na single hop. We extract three networks for each labeled do-\nmain: a backlink network (top 10 backlinks per news site),\nan outlink network (top 10 outlinks per news site), and a\ncombined network (the union of the top 10 backlink and\noutlink networks). Once data were pulled, we constructed\nweighted and attributed Graphs (webgraphs), G=V, E\nwhere Vare websites and Eare represent either backlinks\nor outlinks of domains. We visualize the backlink network\ncolored by news-site reliability in Figure 2. Visually, unre-\nliable and reliable domains seem to largely cluster together.\nThis visual separability suggests that we should be able to\nuse network signal to classify reliability with reasonable ac-\ncuracy. For summary statistics on the three networks, see\nTable 7 in the appendix.\nMisinformation Source Detection\nFlat Baselines For our flat baseline experiments we use\nonly the SEO attributes for each URL, ignoring network\nstructure as well as the top backlinking and outlinking do-\nmains. We then run standard flat ML baselines: gradient\nboosted decision tree (GBDT), random forest, decision tree,\nMLP, and SVM. For parameters we use 50 estimators for the\nrandom forest classifier, 2 hidden layers of dimension 200\nfor the MLP and the linear kernel for the SVM. Scikit-learn\ndefaults are used for the remaining parameters. We repeat\nthese baselines for the reliability, absolute political bias, and\nrelative political bias tasks on the labelled dataset. Five-fold\ncross validation is used with an 80:20 training-test set split.\n7https://ahrefs.com/robot\n217\nFigure 2: Backlink network where node colors show relia-\nbility labels; red are low reliability, blue are high reliability,\npink are mixed reliability, grey are backlinking domains.\nGNNs For our GNN experiments, our goal is to leverage\nlocal homophily present in our partially-labeled SEO net-\nwork in order to better classify unreliable and biased do-\nmains. Formally, for a given task, for website u, our goal\nis to create node embeddings zu\u2208Rdthat map uto its\ncorresponding one-hot-encoded label yu\u2208Zc. The layer-\nwise propagation of a Graph Convolutional Neural Network\n(GCN) (Kipf and Welling 2016) can be written as:\nH(l+1)=\u03c3(\u02dcD\u22121/2\u02dcA\u02dcD\u22121/2H(l)W(l)) (1)\nwhere \u03c3is an activation function, \u02dcAis the sum of the Adja-\ncency matrix Aand its identity matrix I,\u02dcDis the diagonal\ndegree matrix of \u02dcA,H(l)is the lthlayer activation matrix,\nandW(l)is a trainable weight matrix.\nFor each task, we implement a homogeneous two layer\nGCN with 64 output channels that feed into a final linear\nlayer with relu activation and a dropout of 0.5. We found\nthat using GCN layers outperformed GraphSage (Hamilton,\nYing, and Leskovec 2017) and GAT (Veli \u02c7ckovi \u00b4c et al. 2017)\nlayers on our baseline architecture, so we chose to use GCN\nlayers for all subsequent experiments. We use crossentropy\nloss function and and an Adam optimizer. A log softmax\nactivation is applied to the final layer.\nThe graph is partially labeled as many backlinks and out-\nlinks do not have reliability or bias labeled. Consequently,\nunlabeled nodes are masked, but their features are still avail-\nable to labeled neighbors during the propagation step. To\ntrain, we use a transductive random 80:10:10 split and 0.05\nfor the learning rate. We select models using early stopping\nwith a patience of 30 and a minimum delta of 1e-4.\nLink Normalization We investigate several link normal-\nization schemes, as GNN-based models have been shown\nto work better when edge weights are normalized. The link\ndata can be represented as an Adjacency Matrix AwhereAi,jrepresents the number of links from domain itoj, and\nthe (diagonal) backlink degree matrix Db, and outlink de-\ngree matrix Do, where Di,irepresents the backlink and out-\nlink total for domain i respectively. As we only observe links\nfrom the 10 highest-volume backlinking and outlinking do-\nmains, we also have the sampled degree matrices \u02c6Dband\n\u02c6Do, with diagonal elements representing the sum of all in-\ncoming and outgoing links observed in the graph. We ex-\nplore 7 different edge-weighting approaches:\n\u2022links: Ai,j\n\u2022log links: log(A i,j) iffAi,j>0\n\u2022backlink :D\u22121\nbA\u2014 i.e. the % of j\u2019s backlinks from i\n\u2022outlink :AD\u22121\no\u2014 i.e. the % of i\u2019s outlinks that go to j\n\u2022graph-backlink :\u02c6Db\u22121A\n\u2022graph-outlink :A\u02c6Do\u22121\n\u2022page: % of j\u2019s reference pages from i\u2019s domain\nBacklink and outlink edge weightings of the form AD\u22121\nandD\u22121Afollow the random-walk normalization method.\nWe also include page, an edge weight calculated on refer-\nence page count\u2014the number of unique pages on a domain\nthat link to a target domain. Intuitively, when page i,jis near\n0, links from domain itojcome from a narrow subset of\ndomain isubpages relative to the total number of webpages\nthat reference domain j.\nDetection Results\nGiven the label imbalance on the MBFC* unreliable clas-\nsification task, we evaluate models using Binary F1 where\n\u201cunreliable\u201d is the positive label (Table 2).\nOn the PoliticalNews domain list, we replicate the TAG\nclassifier using data released by the authors (Castelo et al.\n2019) and show that models trained on SEO features consis-\ntently outperform those trained on TAG features. The SEO\nGBDT model outperforms TAG GBDT accuracy and recall\nby 14%, achieving 96% accuracy, 0.96 F1. Furthermore, the\nTAG paper reports an accuracy of 83% for a linear SVM\nclassifier (Castelo et al. 2019), which our linear SVM out-\nperforms by 10%.\nThe TAG dataset assigns domain-level labels to article-\nlevel, content-based features, so every article from a given\ndomain has the same label, but different features. On the\nother hand, SEO features exist at the domain level\u2014each\narticle is assigned the SEO features of its domain, and so\nevery article from a given domain has the same label and\nthe same SEO features. As the sample of articles in the Po-\nliticalNews dataset is drawn such that it is representative of\nthe domain labels (Castelo et al. 2019), it is not surprising\nthat domain-level SEO features outperform TAG features on\nthese labels.\nOf the flat models trained on the MBFC* dataset, GBDT\nconsistently yielded the highest F1 on the reliability and\nabsolute bias tasks and was comparable to Random Forest\non the relative bias task. Performance on MBFC* is under-\nstandably lower than for PoliticalNews, as it\u2019s domain list is\n218\nFigure 3: F1 scores for webgraph design space exploration,\nusing GCN with various network structure and link weight-\ning approaches.\nan order of magnitude larger and so the task is more chal-\nlenging. This is also shown by SVM\u2019s success on Political-\nNews (SEO F1 = 0.93) vs. its failure across all three tasks\non MBFC* (F1 <= 0.01).\nThe GNN models significantly outperform the flat clas-\nsifiers on every task across a range of link networks and\nweight schemes. GNN back andGNN outare the GNNs\ntrained with backlink andoutlink weight normalization and\nschemes. Due to the smaller dataset size, the GNN meth-\nods are not suitable for the PoliticalNews dataset. However,\nsimilar GBDT feature importances are seen for both datasets\non the reliability tasks, suggesting that classifiers trained on\nSEO features have generality (Figure 5).\nWebgraph Experiments Figure 3 provides F1 scores for\neach combination of network structure and link weighting\napproaches on the established detection tasks. We observe\nthat the outlink network achieves the strongest overall per-\nformance. The combined network often results in the low-\nest performance, particularly on the relative bias task. Addi-\ntionally, we observe that link normalization approaches have\na substantial impact on model performance. The weight-\ning approaches in Figure 3 are sorted in descending order\nfrom highest (top) to lowest (bottom) by the mean F1 score\nacross all experiments. The backlink weighting achieves the\nhighest mean F1 score. Interestingly, the highest F1 score\non the reliability task is obtained by the outlink network\nwith no link weights. However, in general the decision to\nnormalize is more important than the exact normalization\nmethod employed, and further performance increases with\nmore appropriate weighting approaches have smaller gains.\nIt is also worth noting that the graph normalized variants,\nwith sampled degree matrices \u02c6D, underperform compared\nto the backlink and outlink weightings.\nWe find the inclusion of webgraph and SEO context is\nstrongly related to the overall performance of our models.\nFigure 4 shows the effects of including a varying number of\nbacklinks in the backlink network across each task (the top\nFigure 4: Increasing backlink context improves the perfor-\nmance of our models, to a point.\nN backlinks, varying between 1 and 10). We use log weights,\nas we found those weightings to be the most intuitive as we\nvary N. We observe that, for all tasks, as the number of back-\nlinks increases, performance tends to increase as well. Ad-\nditionally, as we increase the number of backlinks used we\nobserve diminishing returns. The F1 score plateaus at 0.76\nwith top 7 backlinks for the reliability task, 0.78 with 9 back-\nlinks for the absolute bias task, and 0.68 with 10 backlinks\nfor the relative bias task.\nBlack-Hat SEO We find evidence that classic black-hat\nSEO techniques disproportionately support unreliable news\nsites. Figure 8 in the appendix shows the negative correla-\ntion between reliability and percentage of backlinks coming\nfrom blogspot domains (R =\u22120.25). This is indicative of\n\u201cBlog Ping\u201d, where link farming\u2014an SEO tool to gener-\nate backlinks\u2014is done on domains hosted by top blogging\nsites, because such sites are known to quickly attract web\ncrawlers for indexing (Malaga 2010). Similarly, black-hat\nlink building is often done through user generated content\u2014\nnamely forums and comment sections (Malaga 2010). We\nobserve similar negative correlations between the \u2018ugc\u2019 user-\ngenerated content attribute & reliability (R =\u22120.1).\nMisinformation Source Discovery\nGiven the webgraph of a labeled seed list, we seek to capture\na subset of nodes which maximizes the likelihood of nodes\nwithin that subset being unreliable. As described in Figure 6,\nour method is a two-part process based upon the hypothesis\nthat backlink sites that heavily link to known misinformation\nsources also link to unknown sources.\nLink Scheme Identification In the first stage of the dis-\ncovery process, we attempt to capture backlinking domains\nwith suspicious linking patterns. We extract the subset of\nbacklinking sites that link to multiple sites labeled as unreli-\nable (breadth constraint, \u03b2). We further parameterize by the\ntotal number of backlinks targeting unreliable sites (depth\nconstraint, \u03b1). Algorithm 1 details this process.\n219\nPoliticalNews MBFC*\nSEO TAG Reliability Abs. Bias Rel. Bias\nAcc F1 Acc F1 Acc F1 Acc F1 Acc F1\nGNN to - - - - 84 .82 85 .79 70 .69\nGNN sb - - - - 82 .79 83 .79 66 .62\nGBDT 96.2 0.96 82.5 0.82 83.5 .76 83.7 .65 71.4 .65\nRF 91.3 0.92 78.3 0.76 82.2 .74 82.9 .63 71.5 .66\nDT 93.6 0.94 80.7 0.8 77.0 .69 76.5 .56 63.5 .59\nMLP 81.0 0.81 82.1 0.81 61.4 .35 62.5 .14 54.6 .22\nSVM 92.7 0.93 80.1 0.8 63.3 .01 73.2 .00 55.7 .00\nTable 2: Comparison of flat and graph-based detection methods on each of the MBFC* and PoliticalNews (Castelo et al. 2019)\ndomain lists. For MBFC* we report F1 and accuracy on three sets of labels. For the PoliticalNews reliability labels, we compare\nthe performance of models trained on the original TAG dataset (article-level) and our SEO dataset (domain-level).\nFigure 5: SEO attribute importances from Ahrefs on predicting reliability labels on the PoliticalNews and MBFC* datasets. For\na full description of features used, see https://ahrefs.com/api/documentation/metrics-extended.\nFigure 6: Diagram of the multi-step domain discovery pro-\ncess. We begin with a list of known unreliable domains\n(red)(1), then analyze the backlink network (white) to un-\ncover link schemes (grey)(2), and pull the outlinks (blue) for\nthese link schemes (3). To filter out noise, we apply a news\nclassifier (4), a bias classifier (5), and a reliability classifier\n(6). Finally, we validate the results.Algorithm 1: The link scheme identification algorithm\nRequire: \u03b2min\u22650 \u25b7Breath criteria\nRequire: \u03b1min\u22650 \u25b7Depth criteria\nInput: G\u2190(V, E) \u25b7Backlink Network\nC \u2190 [] \u25b7Link Scheme Candidates\nfor each (s, t)\u2208 G.edges ()do\nift.reliability = 0 then \u25b7Unreliable News Sources\nC.append (s)\nend if\nend for\nL\u2190[] \u25b7Link Schemes\nfor each c\u2208 Cdo\nS\u2190G.successors (c)\n\u03b2\u2190\u03a3S\ns1\n\u03b1\u2190\u03a3S\nss.backlinks\nif\u03b2\u2265\u03b2min\u2227\u03b1\u2265\u03b1min then\nL.append (c)\nend if\nend for\n220\nNews Classification To identify candidate news domains,\nwe attempt to classify news domains in link scheme out-\nlinks. Link scheme outlinks are noisy and can contain link\nfarms, businesses, and other irrelevant sources. We train a\nclassifier on SEO features to determine which link scheme\noutlinks are news sources. We draw positive samples from\nour MBFC* dataset and we draw negative samples randomly\nfrom the Common Crawl dataset8. We found that a GBDT\nwith 50:50 negative to positive sample ratio obtained the\nbest results, obtaining 89% accuracy and 0.87 binary F1\nscore. Increasing the number of negative samples from com-\nmon crawl had little effect.\nReliability Classification To identify which news site\ncandidates are unreliable, we use our best-performing flat\nclassifiers. Specifically, we apply both the reliability and ab-\nsolute bias classifiers. Although we expect the GNNs to out-\nperform the flat baselines on the reliability task, inference\nwith a GNN requires building a link network for the URLs\non which we run inference. As the reliability classifier is\ntrained only on domains with >10k backlinks, we use the\nsame criteria to filter candidate domains because we expect\nthe classifier\u2019s performance to be inconsistent outside this\nrange. Finally, we manually evaluate the reliability of the\ncandidates, using translation tools where necessary.\nDiscovery Results\nWe run our discovery process for two datasets, the Political-\nNews evaluation set (Castelo et al. 2019) and our MBFC*\ndataset. Parameters along with resulting domain counts are\nprovided in Table 3.\nEvaluation on the PoliticalNews dataset To evaluate the\nperformance of our discovery system, we employ the partial\nF1 score metric as proposed by Chen and Freire (2020). We\nfind that the partial F1 of our webgraph-based system (0.28)\nis on par with the best reported partial F1 (0.29) of the con-\ntent and social media based system outlined in Chen and\nFreire (2020), with both systems achieving a partial F1 of\n0.25 for a large number of system configurations. The partial\nF1 metric defines the set of true positive unreliable domains\nas those labeled mixed reliability or worse by MBFC. We\nacknowledge that these results are not directly comparable\nas the current work uses a more up-to-date list of domain la-\nbels from MBFC. Rather, these results are meant to give an\nindication of performance for a system that is both challeng-\ning to evaluate and novel in terms of the methods used (i.e.\nwebgraph vs content and social media based).\nFigure 7 shows results from a design space exploration\nof the discovery algorithm. We find that optimal parame-\nters with respect to partial F1 on the PoliticalNews dataset\nare\u03b1min= 2500, \u03b2min= 2, and 100 outlinks per link\nscheme. Most notably, we find that our system is recall-\nbounded. That is to say that as we increase recall, by low-\nering the \u03b2mincriteria (finding more link schemes) and in-\ncreasing the number of outlinks used per link scheme, we\nincrease the partial F1 score. In doing so, we observe dimin-\nishing returns, analogous to our GNN experiments showing\n8https://commoncrawl.org/how F1 increases with the number of backlinks used in the\nwebgraph for reliability classification (figure 4).\nFigure 7: Link Scheme Identification; the x-axis represents\nthe # of outlinks used for each link scheme site, the z-axis\nshows the # of misinfo sites linked to (\u03b2 min), and the y-axis\nshows partial F1 score (Chen and Freire 2020).\nSystem Demonstration on our MBFC* dataset In order\nto run the discovery process for the full list of domains in\ntable 1, we select parameters based on the optimal parame-\nters from the design space exploration on the PoliticalNews\ndataset in figure 7. However, certain parameters are depen-\ndent on the size of the seed list; the depth constraint \u03b1min\nrepresents the minimum number of links to unreliable do-\nmains required for a link scheme. Since our MBFC* dataset\nhas an order of magnitude more seed domains, our criteria\nmust increase to reflect this. In Table 3 we provide the pa-\nrameters used in our discovery process. From left to right,\nwe follow the order of execution in Algorithm 1: number\nof backlinks per known unreliable domain, \u03b1minand\u03b2min\nlink scheme criteria, Llink schemes, number of outlinks per\nlink scheme, and MC misinformation source candidates. In-\ncluded are resulting domain counts after each stage in the\ndiscovery process from the size of the initial seed lists, to the\nfinal set of MC misinformation source candidates that are\nclassified as politically extreme, unreliable news domains.\nBrackets imply the range of parameters used in experimen-\ntation.\nWe observe evidence supporting the hypothesis of the dis-\ncovery method: that link scheme sites which link to known\nunreliable sites also link to unknown unreliable sites. Table\n4 provides the rate of unreliable domains in each explored\nlist, as approximated by the reliability classifier. We find that\nlink scheme outlinks contain a higher proportion of domains\nclassified as unreliable than a random sample of 3241 do-\nmains from Common Crawl and the combined outlink and\n221\nSeed Backlinks \u03b1min \u03b2min L Outlinks MC & News & Misinfo & Biased\nPNews 79 100 2.5k [1-10k] 2 [1-10] 132 100 [10-100] 4.7k 3.1k 1.7k 1.4k\nMBFC* 1179 10 400k 3 270 100 11.6k 6.9k 3.4k 2k\nTable 3: Parameters used for link scheme identification in algorithm 1 and number of candidates discovered using both the\nPoliticalNews evaluation dataset and our MBFC* dataset as seed lists in the discovery process.\nSource Misinfo Rate\nCommon Crawl 0.1%\nOutlinks & Backlinks 10%\nLink Scheme Outlinks 29%\nLink Scheme Outlinks & News Sources 49%\nTable 4: Unreliable domain rates across the various domain\nlists as given by the reliability classifier\nbacklink networks. Further improvements are gained by fil-\ntering out sites that are not news according to our News Clas-\nsifier.\nIdeally, the final stage of unreliable domain discovery\nwould involve the manual validation of all candidates do-\nmains. However, due to time and budget constraints, we in-\nstead sample 10% (200 domains) from the candidate list\nto estimate the accuracy of our discovery method. All la-\nbels were independently annotated by two researchers. Krip-\npendorf\u2019s alpha is computed to determine inter-annotator\nagreement. We find a strong agreement for reliability labels\n(\u03b1= 0.86), and some disagreement for bias labels (\u03b1 =\n0.7). As summarized in Table 5, we find that 47% of do-\nmains frequently feature misinformation (mixed or worse),\n37% predominantly feature misinformation articles (low or\nvery low), 46% are frequently biased (not center), and 38%\npredominantly feature politically polarized articles (extreme\nleft or right). We note that 42% of discovered domains are\nnot news sources, which greatly impacts our results. How-\never, given that a discovered website is a news source, it is\nhighly likely to be unreliable (83%), peddle known misin-\nformation (65%) or have extreme right political bias (65%).\nThe distribution of reliability and political bias labels for\nmanually labeled news sources is given in Table 5.\nAdditionally, we profile the distribution of countries in\nour domain lists according to their IP addresses. For the\nMBFC* dataset, we find that 90% of domain IPs are US-\nbased. In comparison, we find that 80% of the newly discov-\nered domain IPs are US-based, which is confirmed by our\nevaluation (Table 5). This reiterates our concern that misin-\nformation source discovery systems are heavily biased based\non their seed list of domains.\nWe further find evidence of evasion and exit behavior\nin the operation of unreliable news domains. We observe\ndomain switching through redirects and context switching\nthrough content changes. From our sample of candidate mis-\ninformation sources, 8% are dead URLs, 4% redirect to\nnewer domains, and 2% were once misinformation sources\nbut have since \u2018context switched\u2019 so that the domain is noReliability Bias Locale\nLabel # Label # Country #\nV . Low 63 Ext. Left 7 US 80%\nLow 10 Left 9 EU 15%\nMixed 18 Center 14 Middle East 2%\nHigh 14 Right 6 South Asia 1%\nV . High 6 Ext. Right 67 Misc. 2%\nTable 5: Evaluation of the discovered domains sample\nlonger a news site9. Together, 15% of domains in our sam-\nple were previously news sites. In our annotations, we do not\nclassify these domains as misinformation sources.\nDiscussion\nSurvival Rates Given the ease of evasion and exit tac-\ntics like domain swapping, pivoting from news to satire, or\nshutting down altogether, more dynamic approaches for de-\ntecting and discovering misinformation sources are needed.\nOnce unreliable news sites are exposed, they can be boy-\ncotted or penalized by search engines or social media com-\npanies. We find that 3 of 4 unmaintained domain lists pub-\nlished between 2019 and 2017 have domain survivability\nrates of 35-44%.\nWebgraph GNNs The outlink network outperforms both\nthe backlink and combined networks across the majority of\nour experiments (see Figure 3). Intuitively we had expected\nbacklinks to perform better, as they contain the link schem-\ning behaviour that we use identify for site discovery. How-\never, the better performance of outlinks can be understood\nin two ways; firstly, the information gained from the out-\nlink network is denser due to there being fewer outlink sites\nthan backlinks in general. If we were to compare results on a\nGNN trained on all backlinks vs. all outlinks (rather than 10\nof each), we would likely get very different results. Unfortu-\nnately, such an experiment is not feasible given data limita-\ntions. Secondly, websites have more control over their out-\nlinks than their backlinks, which may better provide a better\nproxy for site intent.\nWe find that performance on the absolute bias task, as\nmeasured by F1 score, is higher than for the relative bias\ntask (Figure 3). While this is in line with our hypothesis that\nlink structure is more predictive of absolute bias, we note\nthat it may also be due to the apparent skew in the unreliable\nlabels towards the extreme right (Figure 1). This imbalance\nlikely impacts performance on the relative bias task.\n9We used archive.org to verify domains had context-switched.\n222\nUnsurprisingly, we find diminishing returns when adding\nmore backlinking domains to the backlink network. As\nshown in Figure 4, F1 score begins to increase more slowly\nas we add successive backlinks to the network. This is fur-\nther supported by the design space exploration of the dis-\ncovery process (figure 7), where increasing the number of\noutlinks used per link scheme improves recall, to a point.\nDiscovery The core motivation for the development of the\ndiscovery process is that lists of unreliable domains will be-\ncome quickly outdated. However the discovery process is\nstill heavily biased towards the initial set of seed domains;\nTable 5 reveals that the known biases of locale and polit-\nical orientation from the MBFC dataset (Figure 1) are re-\nflected in the set of discovered domains; although slightly\nimproved, the discovered domains are still predominantly\nUS-based and skew extreme-right. We also note the poten-\ntial political bias in using the partial F1 evaluation metric as\nit relies on the MBFC list.\nWe find that a small change in location distributions oc-\ncurs during link scheme identification. This could allow re-\nsearchers investigating unreliable news domains in a given\nregion to set a starting locale distribution using both an ini-\ntial seed list as well as by appropriately filtering the link\nscheme sites computed by Algorithm 1. While the danger of\nmisuse is clear, we posit that our proposed methodology is\nextendable to other novel country and language contexts to\nbetter identify sources of misinformation. We further stress\nthe language-, content-, and social media-agnostic aspects\nof the system in this regard.\nWe note that using archive.org in combination with our\nSEO classifiers is an effective way to investigate site history.\nAs seen in our evaluation, 7% of our sample is composed\nof non-news domains with scopes that have changed over\ntime. However, backlink profiles are \u2018sticky\u2019 and in many\ncases live longer than the actual content of the domain. By\nanalysing mismatches between a domains link profile and its\ncurrent content, we can uncover evasion and exit strategies.\nLimitations and Future Work\nWe observe that blocklists of unreliable news domains have\npoor survival rates, with more than 50% of such domains\nbeing parked or returning 404s to get requests within three\nyears of publication. We employ a backlink heuristic to fil-\nter out 87% of parked domains and 63% of 404 domains\nthat have less than 10k backlinks. This heuristic also filters\nout>500 domains that are still live, albeit with a minimal\nbacklink profile. While the rationale here is to avoid train-\ning a model to predict dead domains as unreliable, it is still\na limitation of the proposed method. As a result, domains\nshould have a substantial history and a well-developed back-\nlink profile for there to be confidence in the predictions of\nthis detection method. Additionally, as with competing de-\ntection and discovery methods, a seed list of labeled domains\nis required.\nData collection through proprietary APIs can be costly.\nThis cost constrains the validation of our discovery algo-\nrithm, which is why we use flat classifiers for the discovery\nprocess. However, we have shown that the GNN method issuperior for reliability and bias prediction and so we expect\nthat the accuracy of the discovery method would be higher\nusing the GNNs for inference. We note that these methods\nare not \u2018data-hungry\u2019 and achieve impressive performance\nwith limited backlinks and outlinks (figure 4, 7).\nIn our evaluation of the unreliable domain discovery pro-\ncess, we find that the lines between extreme political bias\nand reliability become blurred. While our proposed method\nis successful in creating a new sample of domains with a\nhigh prevalence of unreliable sites among them, the final\nevaluation is not a simple process. We encounter a broad\nrange of domains in the link network, with news sites from\nall over the world appearing in the sample. In many countries\nand contexts, the spectrum of political bias may not exist on\na clear left-right scale, so it is natural that inter-annotator\nagreement for bias labels is lower. We also encountered nu-\nmerous satire sites which can be difficult to classify. Our\naim is not to ignore the subjectivity of reliability and we\nacknowledge that the evaluation of candidate unreliable do-\nmains requires the development of thorough labeling proto-\ncols.\nFinally, despite much of the related work taking advan-\ntage of social networks to determine news source reliability\nand to discover new unreliable domains, we exclusively look\nat webgraph and SEO attributes. In future work, we plan to\ncombine our current webgraph approach with social network\ndata and website content.\nConclusion\nProgress in the misinformation space is typically realized\nby the publication of lists of domains that curate unreliable\ncontent and produce misinformation. However, due to the\ntransient nature of many of these sites, we demonstrate that\nsuch lists do not stay relevant for long. With this in mind,\nwe present a novel dataset crafted from a combination of\nwebgraph data and SEO attributes. We provide strong GNN\nbaselines for predicting news reliability and political bias\nlabels on our MBFC* dataset, with F1 scores of 0.84 & 0.81\nrespectively. We achieve SoTA results with an F1 score of\n0.96 on the PoliticalNews dataset.\nAdditionally, we propose an algorithm for discovering\nnew unreliable news domains. By leveraging signals of\nblackhat link-building methods and the natural homophily\nwithin webgraphs, we introduce a graph-based methodology\nto generate sets of candidate news sources. Applying the flat\nclassifiers trained on our SEO dataset to these candidates,\nwe effectively filter out false positives. Based on partial F1\nscores, our content and social media agnostic algorithm is\nen-par with Chen and Freire (2020). Evaluating this algo-\nrithm on the MBFC* dataset, 47% of discovered domains\nare unreliable and 46% are biased. We provide annotations\nfor a sample of these newly discovered unreliable domains.\nWe demonstrate that webgraphs provide a strong signal\nfor numerous tasks in the misinformation ecosystem. This\nmethodology can allow online misinformation research in\nnew country-contexts where social media usage may be low\nand English may not be the predominant language.\n223\nEthical Statement\nWe acknowledge a growing distrust in misinformation de-\ntection systems as many feel that their advancement coin-\ncides with the erosion of free speech. While our unreliable\ndomain discovery process is a crucial line of research to en-\nable informed discussion about media reliability, it could\nalso lead to misuse if applied to reliable or opposition do-\nmains by government censors.\nA limitation of unreliable news lists is that they tend to\ncontain more extreme-right domains than extreme-left do-\nmains (figure 1). While we do not know the true underlying\nleft-right distributions of unreliable new sources, discovery\nalgorithms trained on these imbalanced lists may bias the\ndiscovery algorithm disproportionately towards unreliable\nconservative domains. This is problematic as psychological\nresearch has found that both extreme-right and extreme-left\nindividuals are susceptible to misinformation (Harper and\nBaguley 2019).\nTo validate the partisan concern, we show that a classifier\ncan be trained to distinguish left-wing domains from right-\nwing domains. Consequently, discovery algorithms biased\ntowards one side of the political spectrum may miss harmful\ndomains that target the other. As a result, we propose the use\nof an \u2018absolute\u2019 bias classifier for use in the discovery pro-\ncess, which is trained to identify politically extreme domains\ntargeting both left and right.\nAcknowledgements\nWe thank Isabel Murdock for developing the MBFC scraper.\nThis work was supported in part by the Office of Naval\nResearch grant (N000142112229) and the US Army grant\n(W911NF20D0002). Additional support was provided by\nthe Center for Computational Analysis of Social and Orga-\nnizational Systems (CASOS) at Carnegie Mellon University.\nThe views and conclusions contained in this document are\nthose of the authors and should not be interpreted as rep-\nresenting the official policies, either expressed or implied,\nof the Knight Foundation, Office of Naval Research, or the\nU.S. Government.\nReferences\nAhrefs. 2022. SEO tools & resources to grow your traffic.\nAires, V . P.; G. Nakamura, F.; and F. Nakamura, E. 2019. A\nlink-based approach to detect media bias in news websites.\nInCompanion Proceedings of The 2019 World Wide Web\nConference, 742\u2013745.\nAllcott, H.; and Gentzkow, M. 2017. Social media and fake\nnews in the 2016 election. Journal of economic perspectives,\n31(2): 211\u201336.\nAswani, R.; Ghrera, S.; Chandra, S.; and Kar, A. 2021. A hy-\nbrid evolutionary approach for identifying spam websites for\nsearch engine marketing. Evolutionary Intelligence, 14(4):\n1803\u20131815.\nAswani, R.; Kar, A. K.; Ilavarasan, P. V .; and Dwivedi, Y . K.\n2018. Search engine marketing is not all gold: Insights from\nTwitter and SEOClerks. International Journal of Informa-\ntion Management, 38(1): 107\u2013116.Binder, M. 2019. Fake news sites are simply changing their\ndomain name to get around Facebook fact-checkers.\nBradshaw, S. 2019. Disinformation optimised: gaming\nsearch engine algorithms to amplify junk news. Internet pol-\nicy review, 8(4): 1\u201324.\nBradshaw, S.; DiResta, R.; and Miller, C. 2022. Playing\nBoth Sides: Russian State-Backed Media Coverage of the#\nBlackLivesMatter Movement. The International Journal of\nPress/Politics, 19401612221082052.\nCastelo, S.; Almeida, T.; Elghafari, A.; Santos, A.; Pham,\nK.; Nakamura, E.; and Freire, J. 2019. A topic-agnostic ap-\nproach for identifying fake news pages. In Companion pro-\nceedings of the 2019 World Wide Web conference, 975\u2013980.\nChen, Z.; and Freire, J. 2020. Proactive discovery of fake\nnews domains from real-time social media feeds. In Com-\npanion Proceedings of the Web Conference 2020, 584\u2013592.\nChitika. 2013. The value of Google result positioning. West-\nborough: Chitika Insights.\nEpstein, R.; and Robertson, R. E. 2015. The search en-\ngine manipulation effect (SEME) and its possible impact\non the outcomes of elections. Proceedings of the National\nAcademy of Sciences, 112(33): E4512\u2013E4521. Publisher:\nProceedings of the National Academy of Sciences.\nGrinberg, N.; Joseph, K.; Friedland, L.; Swire-Thompson,\nB.; and Lazer, D. 2019. Fake news on Twitter during the\n2016 US presidential election. Science, 363(6425): 374\u2013\n378.\nHamilton, W.; Ying, Z.; and Leskovec, J. 2017. Inductive\nrepresentation learning on large graphs. Advances in neural\ninformation processing systems, 30.\nHarper, C. A.; and Baguley, T. 2019. \u201cYou are fake news\u201d:\nIdeological (A) symmetries in perceptions of media legiti-\nmacy.\nHrckova, A.; Moro, R.; Srba, I.; and Bielikova, M. 2021.\nQuantitative and qualitative analysis of linking patterns of\nmainstream and partisan online news media in Central Eu-\nrope. Online Information Review.\nKipf, T. N.; and Welling, M. 2016. Semi-supervised classi-\nfication with graph convolutional networks. arXiv preprint\narXiv:1609.02907.\nLee, S.; Afroz, S.; Park, H.; Wang, Z. J.; Shaikh, O.; Sehqal,\nV .; Peshin, A.; and Chau, D. H. 2022. Explaining Website\nReliability by Visualizing Hyperlink Connectivity. In 2022\nIEEE Visualization and Visual Analytics (VIS), 26\u201330. IEEE.\nLewandowski, D.; S \u00a8unkler, S.; and Yagci, N. 2021. The in-\nfluence of search engine optimization on Google\u2019s results::\nA multi-dimensional approach for detecting SEO. 12\u201320.\nISBN 978-1-4503-8330-1.\nLin, H.; Lasser, J.; Lewandowsky, S.; Cole, R.; Gully, A.;\nRand, D.; and Pennycook, G. 2022. High level of agreement\nacross different news domain quality ratings.\nMalaga, R. A. 2010. Chapter 1 - Search Engine Optimiza-\ntion\u2014Black and White Hat Approaches. In Advances in\nComputers, volume 78 of Advances in Computers: Improv-\ning the Web, 1\u201339. Elsevier.\n224\nMcCue, T. 2018. SEO Industry Approaching $80 Billion\nBut All You Want Is More Web Traffic.\nOkereke, M.; Ukor, N. A.; Ngaruiya, L. M.; Mwansa, C.; Al-\nhaj, S. M.; Ogunkola, I. O.; Jaber, H. M.; Isa, M. A.; Ekpeny-\nong, A.; and Lucero-Prisno III, D. E. 2021. COVID-19 mis-\ninformation and infodemic in rural Africa. The American\nJournal of Tropical Medicine and Hygiene, 104(2): 453.\nPetrou, N.; Christodoulou, C.; Anastasiou, A.; Pallis, G.; and\nDikaiakos, M. D. 2023. A Multiple change-point detection\nframework on linguistic characteristics of real versus fake\nnews articles. Scientific Reports, 13(1): 6086.\nSehgal, V .; Peshin, A.; Afroz, S.; and Farid, H. 2021.\nMutual Hyperlinking Among Misinformation Peddlers.\nArXiv:2104.11694 [cs].\nSilva, A.; Luo, L.; Karunasekera, S.; and Leckie, C. 2021.\nEmbracing domain differences in fake news: Cross-domain\nfake news detection using multi-modal data. In Proceedings\nof the AAAI conference on artificial intelligence, volume 35,\n557\u2013565.\nSzurdi, J.; Kocso, B.; Cseh, G.; Spring, J.; Felegyhazi, M.;\nand Kanich, C. 2014. The Long {\u201cTaile\u201d} of Typosquat-\nting Domain Names. In 23rd USENIX Security Symposium\n(USENIX Security 14), 191\u2013206.\nUrman, A.; Makhortykh, M.; Ulloa, R.; and Kulshrestha, J.\n2022. Where the earth is flat and 9/11 is an inside job: A\ncomparative algorithm audit of conspiratorial information in\nweb search results. Telematics and informatics, 72: 101860.\nVeli\u02c7ckovi \u00b4c, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio,\nP.; and Bengio, Y . 2017. Graph attention networks. arXiv\npreprint arXiv:1710.10903.\nVissers, T.; Joosen, W.; and Nikiforakis, N. 2015. Parking\nSensors: Analyzing and Detecting Parked Domains. In Pro-\nceedings of the ISOC Network and Distributed System Secu-\nrity Symposium (NDSS\u201915).\nWeinberg, Z.; Sharif, M.; Szurdi, J.; and Christin, N. 2017.\nTopics of Controversy: An Empirical Analysis of Web Cen-\nsorship Lists. Proc. Priv. Enhancing Technol., 2017(1): 42\u2013\n61.\nWilliams, E. M.; and Carley, K. M. 2023. Search engine\nmanipulation to spread pro-Kremlin propaganda. Harvard\nKennedy School Misinformation Review.\nZandt, D. V . 2022. Media Bias Fact Check: A Comprehen-\nsive Media Bias Resource.\nZhang, S.; and Cabage, N. 2017. Search Engine Optimiza-\ntion: Comparison of Link Building and Social Sharing. Jour-\nnal of Computer Information Systems, 57(2): 148\u2013159.\nZweig, K. A. 2017. Watching the watchers: Epstein and\nRobertson\u2019s\u201dSearch Engine Manipulation Effect\u201c.\nPaper Checklist\n1. Would answering this research question advance science\nwithout violating social contracts, such as violating pri-\nvacy norms, perpetuating unfair profiling, exacerbating\nthe socio-economic divide, or implying disrespect to so-\ncieties or cultures? Yes2. Do your main claims in the abstract and introduction ac-\ncurately reflect the paper\u2019s contributions and scope? Yes\n3. Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes\n4. Do you clarify what are possible artifacts in the data used,\ngiven population-specific distributions? Yes\n5. Did you describe the limitations of your work? Yes\n6. Did you discuss any potential negative societal impacts\nof your work? Yes\n7. Did you discuss any potential misuse of your work? Yes\n8. Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, respon-\nsible release, access control, and the reproducibility of\nfindings? Yes\n9. Have you read the ethics review guidelines and ensured\nthat your paper conforms to them? Yes\nAdditionally, if your study involves hypotheses testing...\n1. Did you clearly state the assumptions underlying all the-\noretical results? Yes\n2. Have you provided justifications for all theoretical re-\nsults? Yes\n3. Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical results?\nYes\n4. Have you considered alternative mechanisms or explana-\ntions that might account for the same outcomes observed\nin your study? Yes\n5. Did you address potential biases or limitations in your\ntheoretical framework? Yes\n6. Have you related your theoretical results to the existing\nliterature in social science? Yes\n7. Did you discuss the implications of your theoretical re-\nsults for policy, practice, or further research in the social\nscience domain? Yes\nAdditionally, if you are including theoretical proofs...\n1. Did you state the full set of assumptions of all theoretical\nresults? N/A\n2. Did you include complete proofs of all theoretical re-\nsults? N/A\nAdditionally, if you ran machine learning experiments...\n1. Did you include the code, data, and instructions needed\nto reproduce the main experimental results (either in the\nsupplemental material or as a URL)? Yes\n2. Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? Yes\n3. Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)? We\nreport 5-fold cross-validation results.\n4. Did you include the total amount of compute and the type\nof resources used (e.g., type of GPUs, internal cluster, or\ncloud provider)? No - the resources required are negligi-\nble.\n225\n5. Do you justify how the proposed evaluation is sufficient\nand appropriate to the claims made? Yes\n6. Do you discuss what is \u201cthe cost\u201c of misclassification and\nfault (in)tolerance? Yes\nAdditionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets...\n1. If your work uses existing assets, did you cite the cre-\nators? Yes\n2. Did you mention the license of the assets? No\n3. Did you include any new assets in the supplemental ma-\nterial or as a URL? Yes\n4. Did you discuss whether and how consent was obtained\nfrom people whose data you\u2019re using/curating? N/A, no\npersonal data\n5. Did you discuss whether the data you are using/curating\ncontains personally identifiable information or offensive\ncontent? N/A, no personally identifiable information or\noffensive content\n6. If you are curating or releasing new datasets, did you dis-\ncuss how you intend to make your datasets FAIR? Yes,\nsee https://doi.org/10.1184/R1/25174193.v1\n7. If you are curating or releasing new datasets, did you cre-\nate a Datasheet for the Dataset? Yes, see https://doi.org/\n10.1184/R1/25174193.v1\nAdditionally, if you used crowdsourcing or conducted re-\nsearch with human subjects... N/A\nParked Domain Classifiers\nWe evaluate two methods for classifying parked domains;\na classifier trained on HTML & HTTP response features\n(Vissers, Joosen, and Nikiforakis 2015) and a set of reg-\nular expressions (Regexps) that match known HTML pat-\nterns for parked domains (Szurdi et al. 2014). The regular\nexpression method does not require training. For the clas-\nsifier, we construct positive labels by scraping 3k domains\nfrom sedo.com, a popular parking domain registrar. We con-\nstruct negative labels by extracting random sample of 3k do-\nmains from Common Crawl.\nContrary to previous findings that a set of regular ex-\npression designed to catch parked domain HTML templates\nperforms better than the trained classifier (Weinberg et al.\n2017), we find that the regular expression method has low\nrecall over our evaluation set of 3000 parked domains from\nsedo.com. Regexps obtains just 26% recall on this list, with\nthe trained classifier obtaining over 90% recall. Performance\nbetween the two methods is compared in terms of accuracy\nand F1 score in Table 6.\nWe further find that Regexps have much lower recall over\nour news lists, with Regexps finding only 38% of the parked\ndomains that the trained classifier found. The status of these\ndomains, once identified by the classifiers, was manually\nverified. We attribute the gap in recall to the regular expres-\nsions being outdated.Method Acc F1 # in News List Precision\nRegexp 100% 0.43 98 100%\nClassifier 95% 0.92 253 96%\nTable 6: Evaluation of Parked Domain Classifiers\nFigure 8: Percentage of backlinks from blogspot.com sites\nFigure 9: Percentage of backlinks from .edu domains\nStatistic Backlinks Outlinks Combined\nNodes 14959 9827 20817\nEdges 32110 30397 61917\nAvg Degree 4.29 6.18 5.95\nTransitivity 0.016 0.040 0.027\nCPL 0.401 0.140 0.334\nDensity 1.4e-4 3.2e-4 1.4e-4\nAssortativity -0.104 -0.033 0.100\nTable 7: Summary Statistics for Webgraphs\n226", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Detection and discovery of misinformation sources using attributed webgraphs", "author": ["P Carragher", "EM Williams", "KM Carley"], "pub_year": "2024", "venue": "Proceedings of the International \u2026", "abstract": "Website reliability labels underpin almost all research in misinformation detection. However,  misinformation sources often exhibit transient behavior, which makes many such labeled"}, "filled": false, "gsrank": 38, "pub_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/31309", "author_id": ["FxMWswoAAAAJ", "znyBkzIAAAAJ", "KeJfN-IAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:5idV5Ifd8ZQJ:scholar.google.com/&output=cite&scirp=37&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D30%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=5idV5Ifd8ZQJ&ei=CrWsaIYfwNmJ6g-p2qHxBQ&json=", "num_citations": 9, "citedby_url": "/scholar?cites=10732602962721712102&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:5idV5Ifd8ZQJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ojs.aaai.org/index.php/ICWSM/article/download/31309/33469"}}, {"title": "Best practices for source-based research on misinformation and news trustworthiness using NewsGuard", "year": "2025", "pdf_data": "JournalofQuantitativeDescription: DigitalMedia5(2025),1\u201353 10.51685/jqd.2025.003\nBest practices for source-based research on misinformation and\nnews trustworthiness using NewsGuard\nJULALUEHRING\nUniversityofVienna&ComplexityScienceHub,Austria\nHANNAHMETZLER\nMedicalUniversityofVienna,Austria,ComplexityScienceHub,Austria&\nInstituteforGloballyDistributedOpenResearchandEducation\nRUGGEROMARINOLAZZARONI\nRWTHAachen,Germany\nAPEKSHASHETTY\nComplexityScienceHub,Austria&UniversityofVienna\nJANALASSER\nUniversityofGraz&ComplexityScienceHub,Austria\nResearchersneedreliableandvalidtoolstoidentifycasesofuntrustworthyinforma-\ntion when studying the spread of misinformation on digital platforms. A common\napproach is to assess the trustworthiness of sources rather than individual pieces of\ncontent. Oneofthemostwidelyusedandcomprehensivedatabasesforsourcetrust-\nworthiness ratings is provided by NewsGuard. Since creating the database in 2019,\nNewsGuard has continually added new sources and reassessed existing ones. While\nNewsGuard initially focused only on the US, the database has expanded to include\nsources from other countries. In addition to trustworthiness ratings, the NewsGuard\ndatabase contains various contextual assessments of the sources, which are less of-\nten used in contemporary research on misinformation. In this work, we provide an\nCorrespondingauthor: jula.luehring@univie.ac.at\nDatesubmitted: 2024-09-19\nCopyright\u00a92025(Luehringetal.). CreativeCommonsAttribution-NonCommercial-NoDerivatives4.0\nInternationalPublicLicense. Availableat: http://journalqd.org\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)2\nanalysisofthecontentoftheNewsGuarddatabase,focusingonthetemporalstability\nandcompletenessofitsratingsacrosscountries,aswellastheusefulnessofinforma-\ntiononpoliticalorientationandtopicsformisinformationstudies. Wefindthattrust-\nworthiness ratings and source coverage have remained relatively stable since 2022,\nparticularly for the US, France, Italy, Germany, and Canada, with US-based sources\nconsistentlyscoringlowerthanthosefromothercountries. Additionalinformationon\nthepoliticalorientationandtopicscoveredbysourcesiscomprehensiveandprovides\nvaluable assets for characterizing sources beyond trustworthiness. By evaluating the\ndatabaseovertimeandacrosscountries,weidentifypotentialpitfallsthatcompromise\nthevalidityofusingNewsGuardasatoolforquantifyinguntrustworthyinformation,\nparticularlyifdichotomous\u201ctrustworthy\u201d/\u201cuntrustworthy\u201dlabelsareused. Lastly,we\nproviderecommendationsfordigitalmediaresearchonhowtoavoidthesepitfallsand\ndiscussappropriateusecasesfortheNewsGuarddatabaseandsource-levelapproaches\ningeneral.\nKeywords: misinformation, source trustworthiness, NewsGuard\nMisinformationspreadsonbothsocialmediaplatforms(Lazeretal.,2018)andmainstream\nmedia channels (Tsfati et al., 2020). However, only a fraction of news consumption is attributed\nto false news \u2013 roughly 0.15% (Allen et al., 2020) \u2013 and only a minority of users engage with\nunreliable information online (Baribi-Bartov et al., 2024; Grinberg et al., 2019). Typically, these\nindividualsholdstrongpoliticalorideologicalbeliefsandacceptandactivelylookforinformation\nthat echoes their opinions (Ecker et al., 2022) \u2013 information that often comes from political elites\nor established media sources (Tsfati et al., 2020). Misinformation capitalizes on these dynamics\nto stoke conflict and evoke negative emotions, thereby exacerbating partisan divides and fueling\ninter-grouphostility(Gonz\u00e1lez-Bail\u00f3netal.,2023;Robertsonetal.,2023). Againstabackdropof\ndecliningtrustinbothmediaoutlets(Newmanetal.,2023)andinstitutions(BennettandLivingston,\n2020),itbecomesincreasinglycrucialtocomprehendthemechanismsdrivingthedisseminationof\nmisinformation,particularlyinthedigitalsphere. Whiledigitalmediafacilitatesthemeasurementof\nthesedynamics,italsohasthepotentialtoreinforcepolarizationandmisinformation(Lorenz-Spreen\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch3\netal.,2022).\nScholars across various disciplines have extensively studied the phenomenon of misinfor-\nmation,employingtermssuchasmisinformation,disinformation,fakenews,rumors,orconspiracy\ntheories,oftenusedinterchangeably(GuessandLyons,2020). Althoughthesetermsshareafocus\nonveracity,theydifferintermsofintentionality. Misinformationiscommonlyusedasanumbrella\ntermforinaccurateorunreliableinformation,regardlessofintent,e.g.,Eckeretal.(2022)orvander\nLinden(2022). However,theambiguousnatureofmisinformationpresentssignificantmethodolog-\nicalchallenges,grantingresearchersseveraldegreesoffreedom. Definingtheboundariesofmisin-\nformation\u2013\u2013essentiallydeterminingwherethetruthends\u2013\u2013isacomplextaskforseveralreasons.\nFirst,misinformationoftenappearsinsubtleformsratherthanobviouslies(Allenetal.,2024;Altay\netal.,2023; Bakir and McStay, 2018; Vargo et al., 2018), making ithardto define where it starts.\nImplicit,oftenpartisan,interpretationsoffactsdifferfromexplicitlies,makingsubtleformsofmis-\ninformationhardtodetect. Second,identifyingmisinformationinvolvesethicalconsiderations,with\ndifferentexpertsreachingdifferentconclusions. Tonavigatethesechallenges,researchersoftenfo-\ncusonbinary(true/false)casesofmisinformation,typicallyidentifiedbyfact-checkers. Whilethis\napproachaddressessomeethicalconcernsbyclearlyclassifyingfalseinformation,itcapturesonly\nasmallportionofmisinformation. Finally,conceptualchoicesareoftenshapedbymethodological\nconstraints(e.g.,availabledata)ordisciplinarypreferences(e.g.,methodologicaltraditions),which\niswhymisinformationisoftenusedasageneralumbrellatermfordifferentphenomena(Weeksand\nGil de Z\u00fa\u00f1iga, 2021). Consequently, this semantic and methodological variability has contributed\ntoimpreciseorinconclusivefindingsregardingtheprevalenceandimpactofmisinformation. While\nsomescholars,suchasAltayetal.(2023)orBudaketal.(2024),arguethattheeffectsofmisinfor-\nmation are overstated, calling it a symptom of broader social issues, others, like Tay et al. (2024),\nreason that the heterogeneity in measuring misinformation contributes to divergent evidence and\ncreatesafalsedichotomybetweenunderstandingmisinformationasasymptomoracause(alsosee\nBozarthetal.,2020).\nIndigital media research, one of themost prominent ways tomeasuremisinformationhas\nbeentousealistofsourcesthatareknowntosharemisinformationfrequently. Thisapproachhas\ntheadvantageofbeingscalable,however,itisimportanttonotethatitaddressestheeditorialprac-\ntices of the sources rather than the veracity of the content itself. NewsGuard has emerged as the\nmostwidelyuseddatabaseforsourceratings(Aslettetal.,2022;Guessetal.,2020,2021;Pratelli\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)4\net al., 2023; Robertson et al., 2023) and is particularly popular in misinformation research for its\ncomprehensivesource-leveltrustworthinessscores,whicharecompiledbasedonwebtrackingdata\nandratedandupdatedbyprofessionaleditorsandjournalists. Inadditiontoitscomprehensiveness,\nNewsGuard also offers a more fine-grained assessment of the trustworthiness of sources based on\nadherencetojournalisticqualitycriteriaandprovidesapointscorerangingfrom0(thesourceisun-\ntrustworthybecauseitseverelyviolatesbasicjournalisticstandards)to100(thesourceadherestoall\nstandardsofcredibilityandtransparency). Sincethestartofthedatabasein2019,NewsGuardhas\nconstantlyaddednewsources. WhileinitiallythefocusofNewsGuardwastheUS,thedatabasehas\nexpandedtoothercountries,suchasGermanyandFrance. GiventhepopularityoftheNewsGuard\ndatabase as a tool to quantify the prevalence of misinformation, an in-depth analysis of the tem-\nporal stability of ratings and the completeness of the database for different countries is warranted.\nFurthermore, NewsGuardrequiresalicense, andresearchersinneedofa measurement instrument\ntoquantifymisinformationmustweightheadvantagesanddisadvantagesofsource-basedmethods\nandtheinvestmentrequiredtoaccesstheNewsGuarddatabase. Withthepresentin-depthanalysis\nofthedatabase\u2019scontent,weaimtoprovideresearcherswiththenecessaryinformationtomakethis\ndecision. Where warranted, we provide recommendations for effectively utilizing the NewsGuard\ndatabaseandsource-basedapproachesalongsideouranalysisofthecontentofthedatabase.\nTracking misinformation on digital media\nTostudythediffusionordiscussionofmisinformationondigitalplatforms,computational\nresearchers commonly opt for either content- or source-based methodologies, searching for web\nlinkstocontent(viatheURL)orasource(viatheirwebdomain). Bothapproachesrelyonexperts,\nsuchasfact-checkers,tocuratelistsofcontentorsources,whichserveasthefoundationforcollect-\ning data from digital platforms. Source-based strategies, which are the focus of the present work,\noffer the advantage of encompassing a broader spectrum of sources and narratives, thus enriching\nthesamplebyconsideringamorediverseinformationenvironment. Source-basedapproachesalso\nenable the inclusion of subtler forms of misinformation and facilitate accurate estimations of both\nthe scale (Allen et al., 2020; Grinberg et al., 2019; Guess et al., 2020; Yang et al., 2021) and dy-\nnamicsofdissemination(Lasseretal.,2022,2023;Guessetal.,2021;Robertsonetal.,2023;Shao\netal.,2018).\nThe precision of source-based approaches hinges mainly on the selection and quality of\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch5\nsourceratingswithinagivenlist. Strictlyspeaking, thisconceptualizationcoversinformationdis-\nseminated by unreliable sources (rather than individual pieces of misinformation). Therefore, ob-\nservedpatternsmaybeintricatelylinkedtotheinherentbiasesorexternalforcesintheselectionof\nsources. For instance, if we analyzed misinformation in politicians\u2019 social media posts, an unbal-\nanced selection of unreliable sources would most likely reveal patterns due to partisanship rather\nthanpatternsuniversaltomisinformation. Thisunderscorestheimportanceofassessingconfound-\ningfactorssuchaspoliticalbiasesoreditorialpracticesofthesources,consideringthatalackofed-\nitorialoversightcancompromisethequalityofnewsreporting(Lazeretal.,2018). Inotherwords,\nto obtain a balanced selection of sources and account for the influence of source-related variables\notherthanreliability,source-basedapproachescanincorporateassessmentsofpolitical,cultural,or\neditorialbiasesandmisleadingtendencieswhilemaintaininggeneralizability. Nonetheless,several\nproblemsremaininpractice: First,sourcecategorizationsoftenrelyonabinaryclassificationsys-\ntem (fake/real), oversimplifying the nuanced spectrum of misinformation. Second, it is crucial to\nacknowledge that source ratings vary across time and cultural contexts, for instance, following a\nchange in ownership or editorial practices. For example, Lin et al. (2024) combined source-level\nquality ratings with context-specific keywords, e.g., hashtags linked to an anti-vaccination protest\ninOttawatoaccountformisinformation-sharingindifferentpopulations. Third,whilesourcejudg-\nmentsaretypicallymadewithoutrequiringspecifictopicexpertise,theyoftenreflectthejournalistic\ntraditionsofaparticularmediaecosystem,whichmaynotbeuniversallyapplicableacrossdifferent\ncontexts(Br\u00fcggemannetal.,2014). Source-basedapproachesareapromisingwaytotrackonline\nmisinformationatscale. However,tostudythespreadofuntrustworthynews,scientistsneedaccess\ntoreliableandcredibledatabasesofsourceratings.\nNewsGuard: A popular database for source ratings\nSince the 2016 US elections, the most popular way to track misinformation online has\nbeen to use a list of untrustworthy or unreliable sources and search for their web domains in URL\ntext (Lasser et al., 2022; Grinberg et al., 2019; Guess et al., 2020, 2021; Shao et al., 2018; Yang\netal.,2021). TheorganizationNewsGuardoffersthemostcomprehensivelistofsuchdomains(Lin\net al., 2023). It does not just provide a blacklist of untrustworthy sources but provides a trustwor-\nthinessscoreforeachsource,coveringnewssourcesacrosstheentirespectrumofnewsquality. A\ntrainedteamofexperts,mainlyconsistingofjournalistsandeditors,ratesthenewssourcesbasedon\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)6\nninejournalisticqualitycriteria1andregularlyupdatesboththecoverageofthelistbyaddingnew\nsourcesandthetrustworthinessratingsofexistingsources. Sinceitsstartin2019,thedatabasehas\nbeen constantly growing and has recently extended to countries beyond the United States, such as\nGermanyandItaly. Withrecentpoliticaleventsandcrises,demandforsuchdatabaseshasincreased,\nenhancing the popularity of NewsGuard. For instance, it has been used to study user engagement\nwithunreliablenewsduringthe2016and2020USelections(Pratellietal.,2023;Robertsonetal.,\n2023),toassessthechangingqualityofcitedinformationofpoliticalelitesintheUS(Lasseretal.,\n2022)oralternativeunderstandingsofhonestyandtruthinpoliticaldiscourse(Lasseretal.,2023),\nand to estimate the effects of source labeling on decreasing misinformation sharing (Aslett et al.,\n2022;Celadinetal.,2023).\nHowever, theNewsGuarddatabasewasinitiallycreatedasatoolforbrandsecurityrather\nthanscientificresearch. Inaddition,employingjournalistsandeditorstoassessthesourcesincluded\ninthelistincurssignificantexpenses. Givenitspredominantlyprivateaudienceandexpenses, the\nNewsGuard database is only available to subscribers who pay to license the database. Here, we\nprovideacomprehensiveassessmentofthedatabasetohelpmisinformationresearchersweighthe\nresourcesrequiredtoaccesstheNewsGuarddatabaseandtheadvantagesandlimitationsofsource-\nbasedapproachesingeneral. Weaimtoanswerthefollowingmainresearchquestion: Howvolatile\naresource-leveltrustworthinessratings,suchasthoseintheNewsGuarddatabase,acrosstimeand\nlanguage contexts? To answer our research question, we first assess the distribution of trustwor-\nthiness ratings, the process of updating them, and the inclusion and removal of sources over time.\nSecond,weassessthecompletenessofthedatabasefordifferentcountries. Lastly,weestimatethe\nusefulnessofothersource-levelinformationprovidedinthedatabase,suchasthepoliticalorienta-\ntionandtopicscoveredbysources. Toassessdifferentaspectsofthedatabase,weintroducethree\nsub-questions:\nHow stable are trustworthiness ratings over time? Investigating the development of\nthe NewsGuard database over time is important to estimate whether using an older version of the\ndatabasedistortsresultsandshouldbeusedtomeasuretrustworthinessinolderdata. Wedescribe\nthe composition of the trustworthiness score and different database versions. We also explore the\nfrequencyandreasonsformajorchanges,suchashowoftenratingschangeorsourcesareremoved.\n1https://www.newsguardtech.com/ratings/rating-process-criteria/\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch7\nAdditionally,weprovideanexemplaryreproductionofpublishedresearchusingNewsGuardratings\nfrom different points in time to assess the degree to which results vary based on changes in the\nmeasurementinstrument.\nHow complete is the database across countries, particularly for non-US countries? A\nrecentstudyhasshownhighagreementofNewsGuardwithotherexpert-ratedlistsintheUScon-\ntext (Lin et al., 2023), but an assessment for other countries is missing. Therefore, we describe\nthe coverage across and differences between countries and assess the stability of source ratings\nandcoverageovertime. Further,wecomparethecompletenessofinformationprovidedbyNews-\nGuardacrossdifferentcontextsbycross-checkingtheNewsGuarddatabasewithadatasetofdomains\nshared on social media for the US, Germany, and UK, and other existing lists of low-quality web\ndomains.\nHow valuable are contextual source labels for misinformation research? NewsGuard\nlabelsthetopics coveredaswell asthepolitical orientationsources. We analyzethetemporalsta-\nbility and completeness of these labels across countries. Additionally, we manually validate the\nlabels for German-speaking sources. We assess in what way such labels can complement source\ncharacterizationsandshedlightonaspectsofmisinformationbeyondtrustworthiness.\nDataset construction\nNewsGuard curates the list of sources it rates by tracking online activity, using multiple\nmedia monitoring tools as well as their own processes to monitor specific topics and social media\nplatforms. Per country, NewsGuard employs a group of editors to review the sources, including\na rapid response team. The organization also manually adds sources they deem influential or that\nchangedtheirwebdomain. Ontheirwebsite,NewsGuardclaimstohavereviewednewssourcesac-\ncountingfor95%ofonlineengagement,includingnewsconsumedandsharedonline. Toavoidbias\nandinconsistency, NewsGuardappliesmultiplelayersofeditorialreview. Thedatabaseautomati-\ncally updates every hour and allows tracking changes back to March 2019, when the organization\nstartedoperating. Still,howdomainsareselectedorremovedisnotdisclosedonthewebsite. Asof\nSeptember15,2024,thedatabasehas12,288entriesintotal,somewithoutatrustworthinessrating\n(7.6%). This includes 70 sources classified as a \u201cplatform\u201d (e.g., YouTube), 63 sources judged as\n\u201csatire\u201d(e.g.,TheOnion)and806lifestylesources(e.g.,healthquote-free.com). Fortheremaining\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)8\n11,349sources,thedatabaseincludesthefollowingcharacteristics:\n\u2022Uniqueidentifierforeachratinganddateofthelastupdate\n\u2022Domainnameandparentdomain(e.g.,nytimes.com)\n\u2022A trustworthiness rating as a quasi-continuous scale (between 0 and 100) and binary labels\n(N=NotTrustworthy/T=Trustworthy)basedonathresholdat60\n\u2022Languageandcountryassociatedwiththesource\n\u2022Politicalorientationofthesource(e.g.,\u201cleft\u201dand\u201cright\u201d)\n\u2022Topicscovered(e.g.,\u201clocalnews\u201d,\u201cpoliticalnews\u201d,\u201chealthinformation\u201d)bythesource\nThe team of NewsGuard experts regularly judges the trustworthiness of the selected news\nsourcesbasedonninejournalisticcriteriathatareuniversallyappliedacrosscountries. Thetrustwor-\nthinessscoreisacompositescoreofthesenineindicators. Moreprecisely,expertsassignabinary\nlabelforeachcriterion. Eachcriterionhasaweight,anumberofpoints,whichtogethermakeupthe\noveralltrustworthinessrating(rangingfrom0to100). Here,welistthecriteriaandtheirweightsin\ndescendingorder2:\n1.\u201cDoes not repeatedly publish false content\u201d, changed to \u201cDoes not repeatedly publish false\noregregiouslymisleadingcontent\u201dinDecember2023(22points)\n2.\u201cGathersandpresentsinformationresponsibly\u201d(18points)\n3.\u201cRegularly corrects or clarifies errors\u201d, changed to \u201cHas effective practices for correcting\nerrors\u201dinDecember2023(12.5points)\n4.\u201cHandlesthedifferencebetweennewsandopinionresponsibly\u201d(12.5points)\n5.\u201cAvoidsdeceptiveheadlines\u201d(10points)\n6.\u201cWebsitedisclosesownershipandfinancing\u201d(7.5points)\n2https://www.newsguardtech.com/ratings/rating-process-criteria/\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch9\n7.\u201cClearlylabelsadvertising\u201d(7.5points)\n8.\u201cRevealswho\u2019sincharge,includingpossibleconflictsofinterest\u201d(5points)\n9.\u201cThe site provides the names of content creators, along with either contact or biographical\ninformation\u201d(5points)\nSince the overall score is a sum of the individual scores for each criterion, it is not truly\ncontinuous,assomevalues(forexample,1,2,3,or4points)cannotbeachievedbyanycombination\nofcriteria.\nHow stable are trustworthiness ratings over time?\nIn the following, we review how the database, particularly the trustworthiness ratings and\nsource selection, have changed over the years since the first version of the database was compiled\nin2019.\nCoverage across time. Overthespanoffiveyears, NewsGuardhasgrownfrom2,375to\n12,288 entries in total, as shown in Figure 1A to C. NewsGuard regularly adds new sources but\nrarelyremovesany,i.e.,thedatabasehasbeengrowingtofourtimesitsinitialsize. Whencounting\ntheaddeddomainsbasedonmonthlycomparisonsofthelist,NewsGuardhasadded8,906domains\novertimebutonlyremoved685,addinganaverageof137newdomainspermonth.\nNewsGuardratingsareavailableforcustomersinanonlinedatabase(AmazonS3bucket),\nwhereacurrentsnapshotisuploadedeveryhour. Wesampledasnapshotfromthefirsthourofthe\n15thdayofeverymonth. Whenweinsteadsampledfromtheseconddayofeachmonth,weobserved\ntwo irregular dips in the number of sources (see May 2022 and February 2024 in Figure 1A). It\nis likely that errors caused this fluctuation. For instance, in May 2022, the approximately 3,500\nremoved sources that did not appear in the database were present in the database two weeks later.\nYet, this sudden disappearance and reappearance of sources illustrate the overall volatility of the\ndatabase. We therefore advise researchers to inspect several database snapshots and check their\nconsistencybeforechoosingone.\nThe most recent snapshot contains ratings for 11,349 unique domains in the 12,288 total\nentries;indicatingthatsomesourcesappearmultipletimes. Typically,thesesourcespublishindif-\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)10\nferent languages, i.e., they have the same web domain but provide multi-lingual content, or they\nhaveanentryasalocalandaglobalsource. Forinstance, theAustrianwebsiteservustv.compro-\nducesbothGerman-andEnglish-languageoutputandappearswiththecountrylabel\u201cAT\u201dandthe\nlabel\u201cALL\u201d.AccordingtoNewsGuard,thelatterservesasagenericlabelfortheEnglish-language\ntranslationofsitesthatwerealsoratedintheirrespectivelanguage. Inotherwords,eachsitewitha\nlabel\u201cALL\u201dalsoexistsinatleastoneotherlanguage,andthelabel\u201cALL\u201dcanlargelybeignored. In\nlinewiththat,duplicatedsiteshaveidenticaltrustworthinessratingsacrosscountryorlanguagecat-\negories,exceptforthreecases. Therefore,droppingduplicateddomainentriesdoesnotsubstantially\naffectdownstreamresearchresults. However,ifaclassificationofsourcesbycountryisnecessary\nfortheresearchquestionathand,researchersshouldkeepduplicateddomains.\nFurthermore,5,754oftherateddomainsbelongtoonly444uniqueparentdomains. Some\nparentdomainshavemultiplevariationsofthedomainname,probablyrepresentingthesamesource,\ne.g.,theragingpatriot.orghasdomainsendingwith.blog,.com,.net,and.pro. Otherparentdomains\nhaveverydifferentsub-domains,e.g.,24usnews.comandafricdaily.combelongtocharmdaily.com.\nTheother6,534ratingsdonothaveaparentdomainentryinthedatabase. Domainsbelongingtothe\nsameparentdomainusuallyhavethesametrustworthinessrating. Furthermore,NewsGuardupdates\ndomains belonging to the same parent domain at the same time, and they seem to assign the same\nuniqueidentifiertothosedomains. Therefore,whilethedatabasecontains10,862uniquedomains,\nitonlycontains7,073uniqueidentifiersand,therefore,individuallyrated(parent)domains.\nDistribution. NewsGuardtrustworthinessratingsrangefrom0to100. Historically,News-\nGuard considered sources with a rating below 60 as not trustworthy, therefore assigning binary\ntrustworthiness labels3. Since February 20234, NewsGuard uses a more granular categorization,\nclassifying sources with a score of 100 as \u201chigh credibility\u201d, scores between 75 and 99 as \u201cgener-\nallycredible\u201d,scoresbetween60and74as\u201ccrediblewithexceptions\u201d,scoresbetween40and59as\n\u201cproceedwithcaution\u201d,andscoresbetween0and39as\u201cproceedwithmaximumcaution\u201d. Notably,\nNewsGuardisnotablacklist. Infact,closeto60%ofsourceshaveanoverallratingofover60(see\nFig. 1B for the distribution of trustworthiness scores in the most recent vs. the first version of the\n3Snapshot of the described rating process from December 31st, 2022: https://www.newsguardtech.com/rat-\nings/rating-process-criteria/\n4Snapshot of the updated rating process from February 1st, 2023: https://www.newsguardtech.com/rat-\nings/rating-process-criteria/\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch11\ndatabaseandFig.A.1intheappendixfordistributionsperyear). Furthermore,thedistributionsalso\nclearlyshowamultimodalstructure,indicativeofthequasi-continuousnatureoftheoverallNews-\nGuard score. In addition, some combinations of characteristics seem much more prevalent than\nothers, indicatingthattheindividualcharacteristicsarenotindependent(seealso\u201cCompositionof\ntrustworthinessscore\u201dbelow).\nWhenlookingatthescoredistributionovertime,theskewtowardshighratingsdiminishes\nslightly: whiletheaveragescorewas71.8( SD=33.3)in2019,itisnowat63.6( SD=32.6)asshown\ninFigure1C.Variousexplanationsfordecreasesinaveragetrustworthinessovertimearepossible:\nFirst,thedatabasehasquadrupledinsizeandaddedmanysourceswithlowertrustworthinessscores\n(onaverage59.6, SD=27.5).\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)12\n2019 2020 2021 2022 2023 2024\nTime (months)020004000600080001000012000 Number of sources\nA\nMid-month\nBeginning of month\n0 50 100\nTrustworthiness050010001500200025003000Number of sources\nB\nMost recent\nFirst\n2019 2020 2021 2022 2023 2024\nTime (months)05001000150020002500Number of sources\nC\nChanged\nAdded\n020406080100Trustworthiness\n+1.3+1.1\n-2.0 -5.2 -1.1\n71.072.2\n68.662.862.9\nGB US IT DE FR CA AU AT NZ\nFigure 1. Description of trustworthiness ratings with panel A showing the number of\nsources with rating over time based on two different sampling strategies: when sampling\nonesnapshotofthedatabasemid-month(solidline),weobserveasteadyincrease,whereas\nsamplingatthebeginningofthemonthresultsintwoirregulardips(dashedline). PanelB:\nDistributionoftrustworthinessinthefirstandmostrecentdatabaseasahistogram. Panel\nC: Changes in trustworthiness scores over time (monthly granularity). Flags (respective\ncountrycodesinorderofappearance)anddottedlinesindicatewhencountrieswereadded\nanddashedlineswithgreenandredarrowshighlightthetopfivemajorscorechanges. The\nheightofthebarsdescribesthenumberofsourcesaddedvs. changed,withcolorsindicating\nthe proportions. We also show the average trustworthiness of sources added in the green\ntextboxes.\nAsignificantnumberofsourceswithlowerratingswereadded,inparticularduringtheonset\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch13\noftheCOVID-19pandemicin2020. ThedashedlineswitharrowsinFigure1Cshowthetopfive\nupdates in terms of their impact on the average trustworthiness. The height of the bars shows the\nnumber of sources added vs. changed (with proportions in colors and the average trustworthiness\nof added sources in green). For all major updates, the proportion of added sources is larger than\nchangedsources. ThehighestnumberofsourcesaddedwasinSeptember2020,when1,030sources\nwith on average very low trustworthiness ( M=35.3, SD=14.1) were included. It is unclear if this\ndevelopment is due to an effort by NewsGuard to include more untrustworthy news or a global\nincreaseinuntrustworthysources.\nSecond,NewsGuardemploysteamsofexpertspercountry,potentiallyleadingtodifferences\nincoverageandratingsbetweencountries. Dipsintrustworthinessmayberelatedtocountry-specific\nsourcesbeingadded. Forinstance,1,015ofthe1,030addedsourcesinSeptember2020arecoded\nas US, resulting in a drop in average trustworthiness of roughly 5%. In contrast, adding entirely\nnew countries to the database seems to have little effect on the overall trustworthiness score (see\nthedottedlineswithcountryflagsinFigure1C),indicatingthatNewsGuardcuratesabalancedmix\noftrustworthyanduntrustworthysourceswhenaddinganewcountry. Overall,smallerdipsappear\nacrossallcountriescoveredandaremostlikelyrelatedtomanylow-qualitysourcesgainingtraction\naroundthetimeoftheCOVID-19pandemic.\nAthirdinfluenceontheoveralltrustworthinessscoreisupdatesofexistingratings. News-\nGuardindicatesthedatewhenaratingwaslastupdated,evenifthescoredidnotchange. Updates\nto entries are documented on average once every eight months (249 days), but this varies strongly\npersourcebetweenafewsecondstoamaximumof790days(interquartilerange: 157to334days).\nWhen updated, trustworthiness scores mostly remain unchanged (on average, in only 20% of up-\ndatestheratingischanged). Inotherwords,ratingsrealisticallychangeonaverageeverytwoyears\n(M=570days,IQR=397daysto670days). Inaddition,themajorityofsourceshavenotdecreased\nin trustworthiness (average change of rating per source=0.1, SD=3.5). However, a few sources\ndrastically dropped in trustworthiness; for instance, conservativedailynews.com lost 80 points in\noneupdateinNovember2020. FigureA.2intheappendixillustratesthedifferencesinconsecutive\nscoresovertime,withmajorscoreupdatesinearly2020.\nOverall, the decrease in the overall trustworthiness of sources we can see in Figure 1C\ncan, therefore, be attributed to NewsGuard adding untrustworthy sources rather than previously\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)14\ntrustworthy sources losing points. This interpretation is also supported by our analysis of changes\ninindividualratingcriteriabelow.\nComposition of trustworthiness score. The trustworthiness score is a composite score\ncalculatedbasedonninejournalisticcriteria. Foreachsource,NewsGuard\u2019sratersassignaBoolean\nvalue(yes/no)percriterion. Thetrustworthinessscoreisthencalculatedasthesumoftheweighted\ncriteria. FurtherexplanationofthecriteriaandtheirweightscanbefoundintheNewsGuardFAQ5.\nInthelatestversionofthedataset,81.3%ofsourcesfulfillthecriterion\u201cAvoidsdeceptive\nheadlines\u201d (9,217 sources). The second most prevalent criterion is \u201cDoes not repeatedly publish\nfalse or egregiously misleading content\u201d, which is met by 81.2% of all sources. These two top\ncriteriaoftengotogether: Whenoneissatisfied,theothertendstobeaswell(Pearson\u2019scorrelation\ncoefficient = 0.9). A factor analysis with oblique rotation confirms that the two criteria load on\none factor, accounting for 58.1% of the explained variance, with factor loadings > 0.8. All other\ncriteria share 36.9% of the variance explained (factor loadings > 0.5). In line with that, 11.8% of\nallsourcesmeetonlythetwotopcriteriacombined,while13.4%ofsourcessatisfynoneofthenine\njournalisticcriteria. Themostcommoncombinationofcriteriais thatall ninecriteria aresatisfied\nsimultaneously(13.5%ofsources). WeprovideacorrelationmatrixofthecriteriaintheAppendix\n(TableA.1).\nWefindthataround60%ofsourceshaveneverchangedintheirfulfillmentofjournalistic\nqualitycriteriaduringupdates. WepresentupdatepatternsofindividualcriteriainFigure2A.The\nmostcommonchangeissourcesstoppingdisclosingownershipandfinancing,accountingfor12.3%\noftheobservedchanges. Theoppositechange(adisclosureofownershipandfinancing)isthethird\nmostcommonpattern, occurringin10.7%ofscoreupdates. ThisindicateseitherthatNewsGuard\nfrequentlycheckscriteriarelatedtoownershiporthatadherencetosuchcriteriaismorevolatile.\n5FromDecember31st,2023: https://www.newsguardtech.com/ratings/rating-process-criteria/\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch15\n0 5 10\n% of sourcesDoes not repeatedly publish false\nor egregiously misleading content\nGathers and presents information\nresponsibly\nHas effective practices for\ncorrecting errors\nHandles the difference between\nnews and opinion responsibly\nAvoids deceptive headlines\nWebsite discloses ownership and\nfinancing\nClearly labels advertising\nReveals who's in charge, including\nany possible conflicts of interest\nThe site provides names of content\ncreators, along with either contact\nor biographical informationA\nNegative changes\nPositive changes\nATAUCADEFRGB ITNZUS\nCountry1\n2\n3\n4\n5\n6\n7\n8\n9B\n % of sources failing criterion0 100\n2019 2020 2021 2022 2023 2024\nTime (years)60657075808590Trustworthiness\n\u00b1 95% CI\nC\nUS GB IT DE FR CA AU AT NZ\nFigure 2.PanelA:Percentageofsourcesthathavestoppedorstartedtofulfillacriterion,\nincluding multiple changes (positive vs. negative) of a single source. Panel B: Heatmap\nshowingthepercentageofsourcesthatdonotfulfillacriterionpercountryasofSeptember\n15th, 2024 (the numbers represent the criteria as shown in panel A). Panel C: Average\ntrustworthiness per country over time (truncated to range from 55 to 90), aggregated per\nyearwith95%confidenceintervals.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)16\nReproducibilityofdownstreamresearchresultsusingdifferentsnapshotsofthedatabase.\nOvertheobservationperiod,weobservebothasubstantialadditionofsources,aswellasmoremi-\nnor changes in the fulfillment of individual journalistic criteria and therefore, the overall score for\nindividualsources. Thisbegetsthequestionofwhethersuchchangescanpotentiallyinfluencethe\nconclusions drawn from research that rely on the NewsGuard database, depending on which ver-\nsionisused. Toprovideapartialanswertothisquestion,wereproducesomeoftheanalysesofthe\ntrustworthinessratingsofsourcessharedbypoliticiansintheUS,UKandGermanybyLasseretal.\n(2022), using different versions of the NewsGuard database. In Figure 3A, we show the temporal\ndevelopmentoftheaverageNewsGuardscoreofsourcessharedbyDemocratandRepublicanmem-\nbersofCongressonTwitterbetween2016and2022. WeusesnapshotsoftheNewsGuarddatabase\ntakenonMarch1from2019to2024(theoriginalresearchusedthesnapshotfromMarch1,2022).\nIn addition, we show averaged NewsGuard scores for observations that are dynamically matched-\nwiththescoresintheNewsGuarddatabaseonamonthlybasis(dottedlines). Forexample,thedata\nanalyzed for March 2020 is paired with the March 2020 version of the NewsGuard database. For\nRepublicans, the result barely changes between different versions of the database, except in 2019,\nwhere scores are substantially higher \u2013 on average 3.2 points \u2013 than the snapshot from 2020. The\ndifferencesbetweensnapshotsfromotheryearsdonotsurpass0.3pointsandrevealnotrend. For\nDemocrats,thesnapshotfrom2019alsohassubstantiallyhigherscores(2.1pointswhencompared\nto2020). Inaddition,thesnapshotfrom2024yieldsa1.3pointsloweraveragescorethanthesnap-\nshot from 2023. For other years, the differences also do not surpass 0.3 points and have no trend.\nHowever,evengiventhesometimesrelevantdifferencesinscores,themainfindingoftheresearch,\nnamely the increasing difference in average scores between Democrats and Republicans, does not\nchange.\nFigure 3B shows the average difference in the NewsGuard score of sources shared by the\npoliticiansovertime. Whenusingthe2019snapshot,whichdeviatesmoststronglyfromtheothers,\nthedifferencebetweenpartiesissmallerintheyears2020to2022comparedtoothersnapshots,but\nremains substantial. The finding that there are only minor changes in results depending on which\nversion of the database is used for the US for the continuous scale is likely due to the fact that\nsources rarely experience large changes in their rating, and that almost all major US news sources\nwerealreadycoveredinthefirstversionoftheNewsGuarddatabase: thesnapshotfrom2019covers\n15.0%oflinkspostedbyDemocratsonTwitterand18.5%oflinkspostedbyRepublicans. Forthe\n2024snapshot,thecoverageonlyincreasesslightlyto16.3%and19.6%oflinksforDemocratsand\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch17\nRepublicans,respectively. TheuseofadynamicmatchingofNewsGuarddatabaseversiondoesnot\nchangethepictureaslongascontinuousscoresareused(seemoreonthisbelow)andcoveragehas\nstabilized.\nFortheothertwocountries,GermanyandtheUK,thepictureissomewhatdifferent: differ-\nences in average ratings stratified by party show larger deviations between years (see Figures A.3\nand A.5 in the appendix). This is likely due to massive changes in the coverage of the sources\nshared by politicians in these countries by NewsGuard. For example, for members of the German\nparty SPD, coverage increased from 0.5% in 2019 to 12.7% in 2024 and from 0.2% to 12.0% for\nmembers of CDU/CSU. In the UK, the coverage for members of the Labour Party increased from\n7.8%to13.5%,andforTories,from2.4%to7.8%. Takentogether,suchcoveragedifferencesbe-\ntweenyearswouldleadtodifferentconclusionsinsomecases, butnotinothers. Forinstance, the\nNewsGuard score of small parties like DIE LINKE and the Greens in Germany shows an upward\ntrend with the 2019 version but not with newer versions. In the UK, all versions would yield the\nsamemainconclusion,namelythattheaveragescoreshowsnospecifictrendovertime. Itisusually\nthe earlier versions of the database that lead to different scores, given that coverage was still low\nwhen countries were first included. Later versions, especially 2022-2024, usually yield the same\nresult.\nAs the difference between years is largely caused by differences in coverage and not by\ndifferences in the ratings of individual sites, it is questionable if the use of a dynamic matching of\nscoresandobservationswouldincreasethevalidityofresults: Observationsfromearliertimeswith\nlowerNewsGuardcoverageofsourceswouldbelesslikelytobematchedwithascore,introducinga\nhigherlikelihoodofbiasforthesetimesduetounevencoverage. Usingmorerecentsnapshotsofthe\nNewsGuarddatabasetoinferratingsatearlierpointsintime\u2013asiseffectivelydoneif,forexample,\nasnapshotfrom2024isusedtoscorenewssourcesindatacollectedin2019\u2013alleviatesthelackof\ncoverageatthepotentialcostofusingratingsthatarelessaccurate. Insummary,ouranalysisshows\nthatforcountriesotherthantheUS,evenforcontinuousscores,theusageofdifferentversionsofthe\ndatabasehasthepotentialtosignificantlyinfluenceresearchoutcomes,likelyduetotheadditionofa\nsignificantnumberofrelevantnewsourcestothedatabaseovertheyears. Researchersinvestigating\ncountriesforwhichsourceswereonlyrecentlyaddedtothedatabase(e.g.,NewZealandorAustria)\nshould,therefore,proceedwithcautionandinvesttimetovalidatethecoverageofthedatabasefor\nagivencountry.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)18\nFigure3Cshowsthefractionofuntrustworthylinks,e.g. sourceswithaNewsGuardscore\n<60 that were shared by US politicians. This is a common approach for creating a binary \u201ctrust-\nworthy\u201d vs. \u201cuntrustworthy\u201d label from NewsGuard scores. Different from the results shown in\npanelA,panelCshowsthatdependingonthesnapshotofthedatabasethatisused,therearelarge\ndifferencesinthepercentageofsharedlinksthatareconsidereduntrustworthy\u2013particularlyforRe-\npublicans. For example, the earlier NewsGuard versions from 2019 and 2020 indicate a relatively\nstable fraction of untrustworthy links between 2% and 3%, whereas later versions show a rising\nfractionthatreaches8%from2020onward. Analyzingthisfurther,wefindthatthesechangesare\nlargelydrivenbyafewlargenewssites,mostlypopularwithconservativepoliticians,crossingthe\ncutoff threshold of 60 and becoming classified as \u201cuntrustworthy\u201d: In 2019, the sites \u201cthefederal-\nist.com\u201dand\u201cdailywire.com\u201dchangedto\u201cuntrustworthy\u201d\u2013sitesthatarelinkedtoatotalof771and\n547 times in the observation period, out of which 99.4% and 99.3% of links come from members\nof the Republican party, respectively. Note that we only report changes for sites that were linked\nto more than 300 times in the observation period. Similarly, in 2020 \u201cbreitbart.com\u201d (2504 links,\n99.3%Republican),\u201cwashingtontimes.com\u201d(1790links,94.0%Republican),and\u201cnewsmax.com\u201d\n(546links,97.1%Republican)changedlabels. Theonlychangeto\u201cuntrustworthy\u201dofamajorsite\nthatispredominantlylinkedtobyDemocratsoccursin2022for\u201cmsnbc.com\u201d,whichaccountsfor\n1176links(94.3%Democrat). Anotherenormouschangewouldhavebecomeapparentinlate2022,\nas\u201cfoxnews.com\u201dchangedto\u201cuntrustworthy\u201dforfourmonths(AugusttoNovember). Asthistime\nis outside our observation period for this replication study, the change does not become visible in\nFigure3C.However,\u201cfoxnews.com\u201daloneaccountsfor13,124links(3.1%ofalllinkswithaNews-\nGuard score) in the data set, out of which 97.4% come from Republicans, illustrating further how\ntheratingofasinglenewssitecansubstantiallyshifttheobtainedresultsifabinaryclassificationis\nused.\nLooking at other countries, the difference in the fraction of untrustworthy links detected\ndepending on the snapshot of the database used becomes even more striking: for Germany, if the\n2024snapshotofthedatabaseisused,thefractionofuntrustworthylinkssharedbymembersofthe\nFDPandCDUincreasesfromanegligibleamounttoaround5%,whiletheshareofuntrustworthy\nlinks shared by members of the AFD doubles from around 10% to around 20% (see Figure A.4 in\ntheappendix). ThischangeisentirelydrivenbyoneofthelargestGermannewspapers, \u201cbild.de\u201d,\ncrossingthe60pointsthreshold. Ofthelinksto\u201cbild.de\u201d,54.9%comefrommembersoftheAFD,\n25.6%fromtheCDUand10.3%fromtheFDP,withtheremaining9.2%dividedamongmembers\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch19\nofthepartiestotheleftofthepoliticalspectrum.\nWhilewe do notobserve similarly extremechangesfor theUK (see FigureA.6 inthe ap-\npendix),thefindingthatabinaryclassificationofUSandGermannewssourcesinto\u201cuntrustworthy\u201d\nand\u201ctrustworthy\u201dcanleadtolargedifferencesinthefractionofdetecteduntrustworthylinksfordif-\nferentversions of thedatabaseis concerning. Thisincludes major differences intheinterpretation\nof the derived results, such as whether there is a trend detected or not, and whether members of a\nparty do share links to untrustworthy sites at all. In summary, we conclude that the use of binary\nratingshas the potential to substantially distortresearch findings and continuous ratingsshould be\nused wherever possible. In addition, large changes in the prevalence of \u201cuntrustworthy\u201d sources\nshouldalwaysbeanalyzedindetailtoseeiftheyareageneralphenomenonorcanbetiedtoasingle\nmajorsourcechangingclassification. Incaseswherenocontinuousratingsareavailable,theuseof\ndynamicratingscouldsomewhatalleviatethesituation,asthedichotomousdynamicratingswould\natleastcorrespondmorecloselytothejournalisticstandardsatagivenpointintime.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)20\nFigure3.ReproductionofthetimeseriesofNewsGuardscoresofUSCongressMembers\nfromRef.Lasseretal.(2022)usingdifferentversionsoftheNewsGuarddatabasefrom2019\nto2024(alwaystakenfromthefirsthourofMarch1stofthegivenyear). PanelA:Average\nscoresforDemocratsandRepublicansindicatedindifferentshadesofblueandredforeach\nyear. Panel B: difference between the average Democrat and average Republican score,\nindicatedindifferentshadesofgrayforeachyear. PanelC:Fractionofuntrustworthylinks\n(NewsGuardscore<60)withdifferentversionsoftheNewsGuarddatabase(asinpanelA).\nFor each panel, the dotted lines indicate a dynamic value, where data was taken from the\nversionoftheNewsGuarddatabasecorrespondingtotheyearandmonthoftheobservation.\nNotethatasthefirstsnapshotoftheNewsGuarddatabaseisavailableforMarch2019,all\nobservationsbeforethatpointintimearematchedtotheNewsGuardversionfromMarch\n2019. Thetimeseriesrepresentamovingaverageoverthreemonths.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch21\nHow complete is the database across countries, particularly for non-US countries?\nCountry comparisons. The dataset (2019-2024) contains sources from nine countries in\ntotal (United States, Great Britain, Italy, Canada, France, Germany, Austria, Australia, and New\nZealand)plussourcesconsideredtobeglobal. Countrieswereaddedinthefollowingorder: Great\nBritain(countrynameinthedatabase\u201cGB\u201d),UnitedStates(US),Italy(IT),France(FR),Germany\n(DE)\u2013alladdedin2019,Canada(CA,addedin2021),Australia(AU,addedin2021),Austria(AT,\naddedin2022),andNewZealand(NZ,addedin2023). Inthefollowinganalysis,wewilldropthe\ncategory\u201cALL\u201d.\nThe majority of sources are from the United States (76.1%), followed by Great Britain\n(5.2%). Table 1 gives an overview of the total number of sources per country and their average\ntrustworthinessscores(alsoseeFig.A.7forthe numberofsourcesovertimepercountry). News-\nGuardalsolabelsthelanguageofasource,withEnglishbeingthemostrepresented(9,455sources;\n86.9%),followedbyItalian(4.9%),French(4.4%),andGerman(3.8%).\nTable 1:Countrydescriptives.\nCountry n(%) Trustworthiness(SD) Updated Changed Stablesince\nUS 8281(76.1) 56.8(34.1) 224days 559days 2021-03\nGB 568(5.2) 78.5(23.5) 224days 474days \u2014\nIT 537(4.9) 70.9(24.2) 291days 661days 2020-05\nCA 471(4.3) 87.7(15.3) 306days 430days 2022-04\nFR 424(3.9) 65.4(29.2) 326days 646days 2020-06\nDE 368(3.4) 77.0(31.2) 308days 673days 2020-12\nAU 166(1.5) 72.5(24.6) 331days 358days \u2014\nAT 42(0.4) 77.2(29.6) 338days 375days \u2014\nNZ 22(0.2) 76.3(24.7) 313days 426days 2024-01\nNote.AsofSeptember15th,2024. Sortedbynumberofsources.\nAcross all versions of the database and in most countries, the overall trustworthiness of\nsourcesremainsabove65,exceptfortheUnitedStates. US-basedoutletsareoflowertrustworthi-\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)22\nnessonaverage(seeTable1). Figure2Cshowstheaveragetrustworthinessofsourcespercountry\nover time (see also Figures A.8 and A.7 for plots by country). The trustworthiness score for US\nsources was lower from the first database version onward and remained consistently lower com-\nparedtoothercountrieswhenconsideringthenumberofsourcesratedatcomparablepointsintime.\nForexample,theaveragescoreforUSsourceswaslowersixortwelvemonthsaftertheiraddition\ntothedatabasecomparedtoFrenchsourcesatthesameinterval. ThissuggeststhatUSsourcesmay\ngenerally have lower trustworthiness overall, rather than the finding being solely explained by a\nlargercoverageoflow-trustworthyoutlets.\nWhen comparing the number of sources that meet the journalistic criteria per country, we\nobservesomestrikingpatterns. Figure2Bshowsthepercentageofsourcesthat donotfulfill agiven\nindicator by country, i.e., a high percentage indicates that many sources fail to meet the criterion.\nFormostcountries,morethan50%ofsourcesmeeteachcriterion. Interestingly,over70%ofItalian\nsources do not provide names of content creators, and over 80% do not effectively correct errors.\nA similar but less pronounced pattern is visible for French sources. Across all criteria, the United\nStates shows the highest percentage of sources not fulfilling the criteria, with 56.4% of sources\nfailingtogatherandpresentinformationresponsibly,almosttwicetheshareofsourcesthaninany\nothercountry. Furthermore, 30%ofUS-basedsourcesfailtofulfilltheheavily-weightedcriterion\n\u201cDoesnotrepeatedlypublishfalseoregregiouslymisleadingcontent\u201d.\nIntervalsbetweenupdatesofsourcesvarybycountry(seeTable 1),rangingfrom224days\nfor the US and 291 days for Italy to 308 days for Germany. Sources get updated once a year per\ncountry,onaverage. Overall, theUScoverageseemsthemoststableandcomplete. However,the\nrawnumberofmediaoutletsineachcountrymaydependonnumerousfactors(e.g.,populationsize,\nfragmentationofthemediasystem,politicalsystem,andsoon)andshouldthereforenotbeusedas\nanindicatorforgoodcoveragealone.\nTemporal analysis of country coverage. Overall,thedevelopmentoftrustworthinessin-\ndicatesthatforcountrieswithahighernumberofsources,thedatabaseseemstohavesettledintoa\nstablestate. Incontrast,fornewercountries(Canada,NewZealand,andAustralia),ratingcoverage\nstillseemstobepatchy. Toestimatewhenacountryachievesastablecoveragestate,wedetermine\na window of \u201cpoor coverage\u201d per country. To this end, we developed two criteria to evaluate sta-\nbility, visualize the results in Figure A.7, and list the first date on which a country reached stable\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch23\ncoverageinTable1. First,weexaminethedevelopmentofaveragetrustworthinessscoresovertime\nas a proxy for a potentially biased inclusion of more untrustworthy (or trustworthy) sources when\nacountryisfirstaddedtothedatabase. Wegenerallyobservehighervariabilityinthefirstmonths\nuptoayearafteracountryisaddedtothedatabase. Therefore,weassessthestabilityoftheoverall\ntrustworthiness for a given country in 6-month intervals. Within every interval, we calculate the\ndifferenceinaveragetrustworthinessfromonemonthtothenext. Wethencomparethisdifference\nto the overall variability of trustworthiness in the country, using a conservative threshold of half\nthestandarddeviationoftrustworthinessovertheentireobservationperiod. Ifonemonth-to-month\nchangeinagiven6-monthintervalsurpassesthisoverallvariabilitythreshold,weclassifytheentire\nintervalasunstablewithrespecttooveralltrustworthiness.\nSecond,weanalyzethegrowthinthenumberofsourcesincludedinthedatabaseforagiven\ncountry. Whilethetotalnumberofsourcesvariessubstantiallybetweencountries,theinitialgrowth\nrate tends to be steeper. However, the number of sources continues to increase over time for all\ncountries, which is why we calculate the percentage change in sources from month to month as a\nsecondstabilityindicatorwithin6-monthintervals. Here, weagainapplyaconservativethreshold\nof5%growth. Therefore,similartothestabilitycriterionrelatingtotheoveralltrustworthiness,if\ninagivenmonthanumberofsourceslargerthan5%ofthealreadyexistingnumberofsourcesin\nthe database was added, the entire 6-month interval is considered unstable with respect to source\nadditions.\nWedefineacountryashavingreachedstablecoverageiftwoconsecutive6-monthperiods\n(oneyear)meetbothstabilitycriteria. Accordingtoourcriteria,thismeansthatthesourcesadded\nduringastableperiodarelikelynotsystematicallybiasedtowardsmoretrustworthyoruntrustworthy\nsourcesandthatnomajornewsoutletsaremissing. Wevisualizethedevelopmentoftrustworthiness\nandsourcecoverageforeachcountryinFigureA.7withstablewindowsshadedingray. Ouranalysis\nshows that coverage of the US, Italy, France, Germany, and Canada has been stable since 2022.\nFurther, New Zealand is stable from 2024 onward and Austria and Australia show a tendency to\nstabilize in the next 6-month time interval. While Great Britain has instability in the number of\nsourcesthroughout,thetrustworthinessscorehasbeenrelativelystablesinceearly2022. Tobetter\nunderstandhowcompletethedatabaseispercountry,wedescribecomparisonswithdomainsshared\nonsocialmediaandwithotherlistsinthefollowingsections.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)24\nComparison with domains shared on social media. In the supplementary material of\nLasseretal.(2022),theauthorsdescribeamanualinspectionofwebdomainsintheirTwitter(now\nX)datasetthatwerenotcoveredbyNewsGuard(see\u201cReproducibilityofdownstreamresearchre-\nsults using different snapshots of the database\u201d). More precisely, the authors investigate all links\npostedbypoliticiansthatpointtowebpagesotherthansocialmediaplatformsandsearchplatforms.\nOverall,NewsGuardseemstocoveranotablefractionofthoselinks(US:46.5%,Germany: 58.8%,\nUK: 39.2%). Per country, the authors selected relevant domains not covered by NewsGuard that\nindividually accounted for at least 0.1% of all linked domains. Subsequently, they inspected the\nmissingdomainsandmanuallyassignedlabelstothem(e.g.,\u201cgovernment\u201d,\u201cnews\u201d,or\u201cblog\u201d).\nFor the US, 47 domains were analyzed, accounting for 21.2% of missing domains in the\ndataset. While most of these domains link to government or personal websites, none of the 47\ndomainsleadtoanewssite. FortheUK,outofthe78analyzeddomains(40.3%ofmissingdomains),\nfour domains not covered by NewsGuard are news sites, comprising a total of 1.5% of the links\nshared by the politicians. Of these sites, one was a clearly right-leaning site and two were mostly\nlinked to by members of the labour party, while the last site was a news aggregator with no clear\npoliticalleaning. Similarly,forGermanyonlyafractionoflinksnotcoveredbyNewsGuardleadto\nnewssites(1.2%),correspondingtofouroutofthe62manuallyanalyzedmissingdomains(31.5%\nof missing domains). These sites were primarily shared by members of the left, green, or liberal\nparties,indicatingthattheyarenotwidelysharedacrosspartyaffiliations.\nAlthoughtheinvestigationexaminesonly20-40%ofdomainsnotevaluatedbyNewsGuard,\nbyanalyzingthedomainsthatweremostfrequentlyshared,itdemonstratesthatNewsGuardprovides\na comprehensive list of domains shared by politicians in their social media communication across\nthe US, UK, and Germany. Moreover, the small number of missing news sites and the relative\nabsenceofsourcesfromboththeleftandrightpoliticalspectruminthemissingdomainssuggests\nthatNewsGuard\u2019sdomaincurationshowsnosystematicpoliticalbias.\nComparisonwithotherlists. Inordertoassesstheactualcoverageofsourcespercountry,\nwecomparethesourcescoveredbyNewsGuardwithotherlists. However,otherlistsareoftennot\ncompiledwiththesameobjectiveasNewsGuard,whichistocoverallsourcesresponsibleformost\nof the internet traffic. Therefore, their scope and rating system may differ. In addition, other lists\narenotavailableforeverycountry.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch25\nPrimarily for the US context, Lin et al. (2023) have compared the overlap and agreement\nbetweenratingsacrosssixlistsofexistingexpertratings,includingtheNewsGuarddatabase. While\ntrustworthiness ratings correlated significantly for the web domains included in multiple lists, the\nauthors found a high number of non-overlapping web domains between lists. For the German\ncontext, Puschmann et al. (2023) collected a list of 1,147 unique German online news domains\n(GOND)6,largelyrelyingonwebtrackingdataofarepresentativesampleof1,500Germancitizens.\nOverall,GONDhas552sourcesincommonwithNewsGuard(seeTableA.2,amongotherslabeled\nas \u201clegacy press\u201d (52.9%), \u201cdigital-born news outlet\u201d (12.0%), or \u201chyperpartisan news\u201d (10.1%).\nNewsGuard covers 244 out of 573 German-speaking sources covered by GOND, including some\notherlanguages.\nOverall,comparisonsofNewsGuardwiththetwolistsfortheUSandGermanyrevealmany\nnon-overlapping domains. However, NewsGuard\u2019s coverage of the United States and Germany\nseems extensive in that NewsGuard generally tends to cover more prominent outlets and excludes\nnicheandregionaloutlets,probablybecauseitfocusesonwebsiteswiththemostengagement.\nHow valuable are contextual source labels for misinformation research?\nPolitical orientation. Inadditiontotrustworthinessratings,theNewsGuarddatabasealso\nclassifiessourcesaccordingtotheirpoliticalorientation,relyingonaleft-to-rightconceptionofthe\npolitical spectrum. In December 2022, the categories were condensed from four (far left/slightly\nleft/slightly right/far right) to two (left/right; see Fig. 4A). Overall, the political orientation label\nis only available for a minority of the sources, specifically 33.4% (3,789 sources) in the current\ndatabaseversion.\nIntheUS,34.8%ofnewsoutletshaveapoliticalorientationlabel,incontrasttoonlyasmall\nminorityofsourcesinothercountries: 10.4%ofsourcesforGreatBritain, 13.2%forItaly, 16.9%\nfor Germany, and 20.3% for France. Figure 4C and Table A.3 show the total number of political\norientation labels per country as well as the number and percentage of sources classified as left or\nright-leaning in the most recent database. In most countries, the majority of sources with political\norientationlabelsbelongtotheright-wingspectrum. FigureA.9showsthedistributionofpolitical\norientationpercountryovertime.\n6https://osf.io/s5uhb/\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)26\nTrustworthiness ratings are generally lower for right-leaning sources (see Fig. 4B). In the\ndatabasesnapshotfromSeptember2024,theaveragetrustworthinessscoreforright-leaningsources\nis26.4( SD=20.3),incontrastto60.6( SD=26.1)forleft-leaningsources( Mdiff=34.2,t(3771)=35.4,\np<.001). When political orientation was still divided into four categories, slightly left- and right-\nleaningsourceshadmoderatetrustworthinessratings(forexample,inJune2021,81.3and59.4,re-\nspectively),andfar-leftandfar-rightsourceshadcomparativelylowerratings(54.0and15.9,respec-\ntively). In August 2021, however, when a number of untrustworthy sources ( M=40.5, SD=37.2)\nwere added to the database, the average trustworthiness of sources categorized as slightly right-\nleaningdroppedbyalmost20points. Figure4Ashowsthatthe\u201cSlightlyRight\u201dcategorydropped\nbelowthe\u201cFarLeft\u201dcategorybyalmost15points.\nInadditiontothechangeinaveragetrustworthinessscoreswithinpoliticalorientationcate-\ngoriescausedbythechangedtaxonomyofpoliticalorientationusedbyNewsGuard,thetrustworthi-\nnessaveragesperpoliticalorientationalsodifferbycountry,asshowninFigure4B.Whileforsome\ncountrieslikeFranceandCanada,theaveragetrustworthinessofleftandrightsourcesonlydiffers\nbyabout20points,othercountrieslikeAustralia,Germany,andAustriashowextremedifferences\nofover40points.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch27\n2019 2020 2021 2022 2023 2024\nTime (months)020406080100Trustworthiness\n \u00b1 95%CILabel change in 12/2022 A\nSlightly Left Far Right Far Left Slightly Right Left Right\n20 40 60 80 100\nTrustworthiness \u00b1 95%CIAT\nAU\nCA\nDE\nFR\nGB\nIT\nNZ\nUSCountry\nB\n0 10 20 30\n% of sourcesAT\nAU\nCA\nDE\nFR\nGB\nIT\nNZ\nUSC\nFigure4.Trustworthinessaveragesbypoliticalorientation. PanelA:Overtime(with95%\nconfidenceintervals). PanelB:Bycountry(with95%CIs). PanelC:Percentageofsources\npercountrywithpoliticalorientation,explainingdifferencesintrustworthinessbycountry.\nNevertheless, across all countries, sources classified as right, on average, always have a\nlowertrustworthinessscorethansourcesontheleft. However,giventhesmallpercentageofsources\nclassified as belonging to either side of the spectrum, we cannot infer that sources on the right, in\ngeneral,havelowertrustworthiness.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)28\nToassesswhethersourceswithlabelsarecorrectlyclassifiedandwhethersourceswithout\nlabelsareneutralornotclassifiedbyNewsGuardforotherreasons,wecomparedNewsGuardratings\nwith manual and other expert political source labels. First, we manually annotated the political\norientation of all German-speaking sources ever covered by NewsGuard (as of September 15th,\n2024)basedonthewebsite\u2019sfrontpage,articleheadlines,ads,andarticlecontent. Wefollowedthe\nlabels by NewsGuard (right/left) and added two labels: neutral and unidentifiable (e.g., when the\nwebsiteisunreachable). Forsourceswithavailableratings,theagreementbetweenNewsGuardand\nthemanualannotationswas83%(for64domainsoutof406,excluding20deadlinks). Second,we\ncomparedtheNewsGuardlabelstolabelsbyMediaBiasFactCheck7(MBFC,41labelsintotal,six\noverlapping with NewsGuard), resulting in an agreement of 83%. Both comparisons showed that\ndisagreementsmainlyoccurredincaseswherethemanualannotationswerelabeledasneutral,while\ntheexpertratingsassignedaspecificlabel. Inonlyonecase,NewsGuarddifferedfrombothMBFC\nandthemanualannotation.\nConsequently,intheGermancontext,theexistingratingslargelymatchedmanualpolitical\norientationlabels. Interestingly, theratedsourcestendtobenicheoutletswithmoreextreme(and\nthus,clear-cut)politicalleanings. Fortheneutralsources,wecouldnotidentifyaclearpoliticallean-\ning. Suchsourcesweretypicallylocalnewspapersormagazinesfocusingonspecialinteresttopics\n(e.g.,technologyorhealth). However,roughlyhalfwerelegacymediaormajoronlinesourcesthat\nslightlyleanedtowardsaparticularpoliticalorientation. Ourfindingssuggesttwo(notnecessarily\nmutuallyexclusive)implicationsforamissingpoliticalorientationlabel: Eitherthesourceshaveno\novertpoliticalbiasintheirreportingoraretoonichetobelabeledbyNewsGuard.\nBeforetheratingbecamebinary,afewdomainsfrequentlyoscillatedbetweenmoreextreme\nandlessextremelabels,butdomainsrarelyswitchedtheirpoliticalorientation. Thismighthavebeen\nareasonforsimplifyingthelabel. Onlyfivedomainshavechangedtheirpoliticalorientationrating\nfromlefttoright(nonehavechangedfromrighttoleft). ThesedomainsareUS-based,andtwoof\nthem also experienced a significant drop in their trustworthiness score, reducing it by 42 points in\nJanuary2020. Wethereforeconcludethatpoliticalorientationlabelsgenerallyremainstableforthe\nrelativelysmallnumberofsourcesthathavesuchalabel.\nInsummary,althoughthepoliticalorientationlabelsofsourcesprovidedbyNewsGuardare\n7SeehereforratingsystemasofAugust20th,2024: cdhttps://mediabiasfactcheck.com/methodology/\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch29\nsparse,particularlyoutsidetheUS,theratingsofcoveredsourcesappeargenerallystableovertime.\nAnin-depthinvestigationoflabelsforGermansourcesshowedthatNewsGuard\u2019spoliticalorienta-\ntionassessmentisreasonableandthelownumberoflabelscanbeexplainedbysourcesnotshowing\napoliticalleaningorbeingtooniche. Therefore,thepoliticalorientationratingbyNewsGuardmay\nbeavaluableadditiontoanalysesrelatedtosourcetrustworthiness. However,werecommendthat\nresearchers(atleast)spot-checktheratingsforthespecificcountryinwhichtheyintendtousethe\ndatabase,especiallyformajoroutletsandmainstreammediasources. Iftheresearchfocusesoncom-\nparing political bias rather than controlling for it, we advise validating and extending the existing\nratingsprovidedbyNewsGuard.\nTopics.NewsGuard experts assign labels for the topics covered by the sources. Usually,\na single source has multiple assigned topics. The number of sources with topic labels has steadily\nincreased since their introduction in October 2019. As of May 2021, roughly 50% of the sources\nhad topic labels (see Fig. A.10) for the total number and proportion of sources with topic labels).\nInSeptember2024, only352sourcesarewithoutatopiclabel(2.9%). InFigure5A,weshowthe\ndistribution of trustworthiness ratings within topics while in Figure 5B, we show raw topic label\ncounts. Note that a single source can have more than one topic label. The most popular topics\nare \u201cLocal news\u201d (40.3% of sources), \u201cPolitical news or commentary\u201d (39.5%), \u201cGeneral news\u201d\n(22.7%), \u201cHealth or medical information\u201d (13.6%), and \u201cConspiracy theories or hoaxes\u201d (12.8%).\nOvertime,topiclabelsrelatedtomisinformationhavebeenadded,mostlikelycoincidingwithsome\nof the major database updates discussed above. Figure 5C shows the top five topics discussed by\nsourcesclassifiedasuntrustworthy(measuredbythepercentageofuntrustworthysourcespublishing\nonthosetopics). InApril2020,shortlyaftertheCOVID-19pandemicstarted,NewsGuardincreas-\ninglyaddedalabelcalled\u201cCOVID-19misinformation\u201d,withmajoradditionsinAugust2021. Once\nasourcereceivesatopiclabel,itrarelychanges(exceptforfoxnews.com,whichhaschangedseven\ntimes).\nAsshowninFigure5A,averagetrustworthinessratingsgreatlydifferacrosstopics(white\ndots show the average trustworthiness of sources covering that topic). The lowest average rating\nis given to sources covering issues related to conspiracy theories ( M=12.6, SD=12.6), military\n(M=31.8, SD=34.9), and health or medical information ( M=39.3, SD=35.5). In contrast, those\ncoveringeducationhavethehighestaveragetrustworthinessscores( M=85.8, SD=16.9),butthisis\nonly0.5%ofthesources. Generally,lessprevalenttopicstendtohavehightrustworthinessscores\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)30\nwithlowvariance(e.g.,fashionwith76.5onaverage, SD=10.2),seealsoFigure5B.Considering\nonly untrustworthy sources, however, only 32.5% are labeled as covering conspiracy theories. In-\nstead,untrustworthysourcesseemtocommonlypublish\u201cPoliticalnewsorcommentary\u201d,with79%\nofalluntrustworthysources(e.g.,withatrustworthinessscore<60)coveringthistopic,followedby\nlocal(30.4%)andhealthnews(22.3%). Thesetopicsgenerallyreceiveasignificantlyhighernum-\nberoflabelsfromNewsGuardandshowahighvarianceintrustworthiness,forinstance,\u201cGeneral\nnews\u201dor\u201cLocalnews\u201d(seeFig.5AandB).Thishighlightsthatbothuntrustworthyandtrustworthy\nsourcescoverawiderangeoftopics,includingmainstreamones,andthatfringetopicsonlymake\nupasmallproportionofthenews.\nAcross countries, sources more or less publish on the same topics (see Fig. A.11 in the\nappendix). However, sources with low trustworthiness seem to publish on different topics, i.e.,\nthe trustworthiness of sources covering a given topic substantially depends on the country (see\nFig.A.12). Forinstance,formedicalinformation,sourcesinCanadaareratedastrustworthy( M=65.4,\nSD=34,27sources),whiletrustworthinessiswellbelow60intheUnitedStates( M=30.2, SD=33.3,\n1,130sources). Thedifferencebetweencountriesisalsosubstantialforpoliticalnews,withanav-\neragetrustworthinessof33.1( SD=24.8,3,498sources)intheUS,39.2( SD=29.3,111sources)in\nFrance,and81.6( SD=18.6,268sources)inGreatBritain.\nWealsoanalyzedtheinteractionofaveragetrustworthinessbytopicandpoliticalorienta-\ntion (see Figure 5A). Political and local news are among the most popular topics assigned to both\nleft- and right-wing sources, with 386 and 113 as well as 2,946 and 1,140 sources covering those\ntopics, respectively. These numbers show the differences in how many political orientation labels\nare assigned to each side. For sources classified as right-wing, trustworthiness scores for all top-\nicsareconsistentlyloweronaveragethanforsourcesontheleftside,e.g.,politicalnews: M=26.6\n(SD=20.0)ontherightand M=60.2( SD=26.0)ontheleft. 1,162right-wingsourcescoverconspir-\nacytheories( M=10.0, SD=11.4)and693sourcescoverhealth-relatednews( M=11.3, SD=15.0).\nMeanwhile,forsourceslabeledasleft-leaning,trustworthinessisparticularlylow(below50)when\nthey cover the topics \u201cConspiracies\u201d, \u201cMilitary and defense\u201d or \u201cHealth news\u201d. However, due to\nthe skewed distribution of political orientation in the database, it is impossible to say whether the\nabove-mentioned differences in countries and political orientation are due to actual differences in\nthemedialandscapeorsamplingstrategies.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch31\n0 20 40 60 80 100\nTrustworthinessConspiracies\nMilitary and defense\nHealth news\nPolitical news\nReligion\nViral content\nScience\nEntertainment\nCelebrity news\nLaw or criminal justice\nGeneral news\nLocal news\nParenting\nSports\nEnvironment\nLifestyle\nFashion\nT echnology\nBusiness\nEducation\nALeft Right\n0 2000 4000\nNumber of ratingsB\n2020 2021 2022 2023 2024\nTime (months)01000200030004000Number of ratingsC\nConspiracies\nCOVID-19 misinfo\nHealth news\nPolitical newsLocal news\nGeneral news\nGeneral / local news\nFigure 5. Panel A: Distributions of trustworthiness per topic and political orientation\n(left/right in blue/red, respectively), sorted by their average trustworthiness (white dot\nwithintheboxplotrepresentsthequartilesandwhiskersshowthewholerange). Note. We\nexcluded topics with a count below 50. Some topics are abbreviated. Panel B: Count of\ntopic labels as of September 15th, 2024. Panel C: Frequencies of misinformation-related\nlabelsovertime. Coloredlinesshowthetopfivetopicscoveredbyuntrustworthysources.\nThe dotted, vertical lines show the removal of two of those labels. The gray and dashed\nlineshowstheaveragetopiclabelcountofthosetopicsacrossallsourceswiththe95%CI.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)32\nOverall, the coverage of topic labels appears comprehensive, suggesting they could be a\nvaluable asset for misinformation research. Especially a combination of trustworthiness and topic\nlabels could complement source characterization, for instance, by distinguishing between fringe\nsourcesandthoseaddressingmainstreamissues. Forsourcesthatlackalabelforpoliticalorientation,\ntopics may help clarify if a source is genuinely neutral or tends to cover extreme topics low in\ntrustworthiness.\nConclusion\nAn inherent challenge in misinformation research lies in how false information is defined\nandmeasured. Aprominentapproachfortrackingonlinemisinformationistousealistofsources\nand their web domains. Due to its popularity and limited access, we examined the comprehensive\nNewsGuard database and analyzed the temporal stability and cross-country completeness of their\ntrustworthinessratingsandothersourcelabelsrelevanttomisinformationresearch. Here,wesum-\nmarize practical recommendations for using NewsGuard in research and discuss conclusions for\nsource-basedapproachesingeneral.\nOver50%ofthesourcesincludedinthedatabasehaveascoreof60pointsorhigher,deemed\nat least \u201ccredible with exceptions\u201d according to NewsGuard\u2019s nomenclature. These sources typi-\ncally meet two heavily weighted criteria: \u201cAvoids deceptive headlines\u201d and \u201cDoes not repeatedly\npublishfalseoregregiouslymisleadingcontent\u201d. Theaveragetrustworthinessscoreofsourcesin-\ncludedinthedatabasehasdecreasedovertimeduetotheadditionofuntrustworthysourcesrather\nthan the degradation of trustworthiness of existing ones. NewsGuard provides a new snapshot of\nitsdatabasehourly,butananalysisofupdatetimestampsofsourcesshowsthatsourceinformation\nis likely checked annually, with infrequent changes to trustworthiness ratings usually triggered by\nchangesintransparencyaboutwebsiteownershipandfinancingoreditorialpractices. Suchchanges\nare generally minor, involving updates of only one of the nine journalistic quality criteria \u2013 but\nmay influence downstream research results if sources cross the binary classification threshold at\n60(\u201ctrustworthy\u201d/\u201cuntrustworthy\u201d). However, changesinsource coveragecanbeabrupt, within-\nstances of over 1,000 sources being added or removed in a single update. To shed some light on\nthe impact of changes in the NewsGuard database on downstream research outcomes, we repro-\nducedresearchinvestigatingnews-sharingpracticesofpoliticalelitesintheUS,Germany,andthe\nUK(Lasseretal.,2022). Wefindthatafter2019,thecontentofthedatabaselargelyreachedastable\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch33\nstateintheUS,andusingdifferentversionsofthedatabasebetween2020and2024doesnotchange\nresearchoutcomesifthecontinuousNewsGuardscoreisused. Theprocessofstabilizingtooklonger\nforGermany,butafter2022,wealsoonlyobservedminordatabasechangesthere. FortheUK,the\ndatabase never reaches a stable state according to our stability criteria, mainly due to the high fre-\nquencyofabruptchangesinthenumberofsourcesincluded. However,theaveragetrustworthiness\nratingsstabilizeafter2022. Ingeneral,onceastabledatabasestateisreached,downstreamresearch\nresults relying on continuous ratings do not substantially change depending on the version of the\ndatabasethatisused.\nDespitethesenuances,thetrustworthinessratingsbyNewsGuardappearrelativelyinsensi-\ntivetotime,speakingforthereliabilityofsource-basedapproaches. Forcountriesandtimeperiods\nwhere the database is stable, we also do not see much benefit for the use of dynamic scoring in\nwhichobservationsarematchedtothecorrespondingsnapshotofthedatabaseintime. Asratingsof\nindividualsourcesarerelativelystable,weconcludethatusingalaterversionofthedatabasewith\na higher coverage is preferable to using a version closer to the time of observation but with lower\ncoverage.\nThe picture changes if binary \u201ctrustworthy\u201d and \u201cuntrustworthy\u201d labels for news sites are\nintroduced by classifying sites based on a cutoff value at a NewsGuard score of 60. In this case,\nweobservelargedifferencesinthefractionof\u201cuntrustworthy\u201dlinksthataresharedbypoliticians,\ndependingontheversionofthedatabaseusedfortheanalysis. Weshowthatthesedifferencescan\nsubstantiallychangethedirectionandinterpretationofresearchresultsinourreplicationstudy. As\na result, we strongly caution researchers against using binary trustworthiness labels if continuous\nscoresareavailable.\nUS-basedsourcesgenerallyscorelowerontrustworthinessthanothercountries;atrendthat\npersistsevenwhenaccountingfordifferentpointsintimeandthenumberofsourcesrated. Impor-\ntantly, this does not say anything about the trustworthiness of news actually consumed by the US\npopulation, whichcouldbehigher, dependingonthecontributionofeachsourcetothenewsdiets\nof US Americans. Country-specific factors seem to significantly influence journalistic traditions\nacross countries with similar media systems. Italy and France, part of the Southern cluster, show\ndistinct patterns compared to Central (e.g., Germany) and Western clusters (e.g., US). According\nto Br\u00fcggemann et al. (2014), countries belonging to the Southern cluster have a less professional-\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)34\nized journalism sector than the Central or Western clusters. In their seminal definition of media\nsystems, Hallin and Mancini (2004) state that in countries that fail to meet the professionalism in-\ndicators, the understanding of journalists serving the public interest is less pronounced. In other\nwords,whenjournalisticprofessionalismislow,journalistslackprofessionalautonomy,potentially\nexplaining less institutionalized transparency practices in these countries, as indicated by News-\nGuards\u2019journalisticcriteria. NewsGuard\u2019scriteriabroadlyreflectdifferencesinmediasystems\u2013\u2013\natleastfortheWestern,educated,industrialized,rich,anddemocratic(WEIRD)countriescovered.\nNonetheless, the differences in journalistic traditions underscore that applications of the database\nneedtobetailoredtoindividualcontextsandthatresearchersshoulddouble-checktherelevanceof\nthecriteriaforthecountrystudied8.\nThe NewsGuard database provides more than just trustworthiness ratings; it also includes\nlabels for the political orientation of sources and covered topics, which could be valuable contex-\ntualinformationformisinformationresearch. Whilemostsourceshavemultipletopiclabels,onlya\nminorityofsourceshaveoneforpoliticalorientation. About41%ofsourceshaveapoliticalorien-\ntationlabelintheUS,butonlyaround10%doinothercountries. InourmanualanalysisofGerman\nsources,weobservedthatNewsGuardtendstorateonlysourceswithaclearpoliticalleaning. Most\nratedsourcesareright-leaning,andtheseareoftendeemedlesstrustworthycomparedtoleft-leaning\nsources. ThisdisparityraisesthequestionofwhetheritstemsfromasamplingbiasbyNewsGuard\neditorsratherthananactualdifferenceintrustworthiness. WearguethatNewsGuardseemsunbiased\nforthecountrieswherecoverageandratingshavestabilizedforthefollowingreasons: First,News-\nGuardselectssourcesbasedonwebtrackingdata,suggestingthatitshouldreflecttheonlinemedia\nlandscapefortherespectivecountry. Researchonalternativemediasuggeststheemergenceofright-\nwingcounter-publicsasaresponsetothepoliticalandlegacymediacontext(Heftetal.,2020). More\nprecisely, the theory posits that a prevalence of left-leaning opinions in political and mainstream\nmediaspheres(Osmundsenetal.,2021)mayleadtoanunder-representationandmarginalizationof\nright-wingviews(Benkleretal.,2018)andfragmentationofacounter-publicalongtheright-wing\nspectrum that is highly connected (Heft et al., 2021). As NewsGuard only labels the political ori-\nentationofexplicitlypartisan,sometimeshyper-partisansources,thisexplanationwouldresultina\nhighernumberofsmaller,right-wingonlinesources. Ademandforright-wingfringepublications\nwouldalsoexplainlowertrustworthinessontheright-wingspectrum,whichalignswiththepolitical\n8https://www.newsguardtech.com/ratings/rating-process-criteria/\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch35\nasymmetry repeatedly observed in susceptibility to misinformation, e.g., recently by Robertson et\nal. (2023). Second, the source selection and trustworthiness ratings provided by NewsGuard are\nlargelyconsistentwithotherindependentfact-checkingorganizations(Linetal.,2023). Therefore,\nit is unlikely that NewsGuard has an inherent bias against right-leaning sources, both in selecting\nmore right-wing sources and in giving them lower trustworthiness ratings. NewsGuard also dis-\ncussesthistopicintheir2023SocialImpactReport9,emphasizingthattheirtrustworthinessratings\nare intended to be apolitical. Despite being incomplete, the political orientation labels may be a\nusefuladditiontothetrustworthinessratings,especiallyincombinationwithtopiclabels. However,\nthey should be interpreted with caution and potentially validated and extended for countries other\nthantheUSandGermany.\nOuranalysisfacesseverallimitationsduetoascarcityofcomparabledatasets,particularly\nfor countries other than the United States, the United Kingdom, and Germany. This limitation is\nespecially critical when considering the absence of data on non-Western countries, which remains\nasubstantialgapinthestudyofmisinformation. Addressingthisgapwouldrequireexpandingthe\nscopeofdatabaseslikeNewsGuardtoincludeabroaderrangeofcountries,especiallyintheGlobal\nSouth, where the impact of misinformation may be profound but less studied. As a result of these\nlimitations,wecannotassesspotentialbiasesintheselectionofdomainsorthereliabilityandvalid-\nityoftheNewsGuarddatabaseglobally;wecanonlyevaluatetheinternalandtemporalstabilityof\nexistingratings. Toaddressthis,wereproducedpreviousresearchfindingsusingdifferentdatabase\nversions,comparedthedatabasewiththefewexistinglists,andmanuallyvalidatedratings. Based\nontheseanalyses,theNewsGuarddatabaseappearsstableandcompleteforGreatBritain,theUS,\nGermany,andpossiblyFranceandItaly. Ouranalysisoftemporalstabilityalsoshowsthatexternal\nevents,suchaschangesinthemedialandscapeornationalandglobalcrises,maydisruptstabilityin\ncoverage. Inparticular,theonsetoftheCOVID-19pandemicappearstohavecausedinstabilityin\ntheUS,GreatBritain,andFranceduringtheearlymonthsof2020. Thiscanlikelybetracedbackto\neffortsbyNewsGuardtoincluderatingsforsourcesrelatingtothespreadofhealth(mis-)information\nthat suddenly had much wider reach early in the pandemic. For countries where coverage has not\nstabilized yet, we recommend proceeding with caution and manually assessing potential biases in\ncoveragethatcouldinfluenceresearchresultsbyinspectingfrequentdomainsthatarenotcoveredby\nNewsGuard. Additionally,ourresultsarereproducibleacrossdifferentdatabaseversions,evenwith\n9https://web.archive.org/web/20240228003711/https://www.newsguardtech.com/special-reports/social-\nimpact-report-2023/\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)36\nslightchangesintheinstrument,especiallyforitsearlyversions. Givenourobservations,werecom-\nmendthatresearchersusingNewsGuard\u2019strustworthinessratingsexamineseveralsnapshotsofthe\ndatabasetoensurenomajorsourceadditionsordeletionsoccurredrecently. Forcountriesincluded\ninNewsGuardforlonger,e.g.,theUS,Canada,France,Italy,GermanyandtheUK,wesuggestthat\nresearchers use whatever version of the database after 2022 they have access to. For more recent\nadditions,e.g.,Australia,AustriaandpotentiallyNewZealand,wesuggestthatresearchersalways\nusethemostrecentversionofthedatabaseandcarefullyexamineitfordifferencesincoveragefor\ndifferentunitsofanalysis,suchaspoliticalleaning. Lastly,thetopicandjournalisticcriteriaratings\nappearstableandmayoffervaluablecontextfortheanalysisofmisinformationdynamics. Acom-\nbinationofpoliticalorientationandtopiclabelscouldeffectivelycharacterizesourcesandidentify\nuntrustworthy sources that address and decontextualize mainstream issues beyond hyper-partisan\ncontexts. It is important to note that this analysis is specifically relevant to online misinformation\nresearch, as NewsGuard uses web traffic data to select sources for assessment. Future research\nshould compare lists of online news domains to cross-platform and offline news consumption and\nexaminehowsamplingbasedonsourcesversusstoriesinfluencesdownstreamresults.\nIn conclusion, relying on a list of rated online news sources offers a stable and scalable\nmethod for identifying content coming from untrustworthy online sources. A source-based ap-\nproachwithafine-grainedratingschemebasedonjournalisticqualitycriteriaisparticularlyvaluable\nand theoretically sound because it can encompass a wide range of sources, including less extreme\nformsofmisinformation,therebybetter-reflectingpeople\u2019sinformationdiets. Whilenoteveryarti-\nclefromanuntrustworthysourceisnecessarilyfalse\u2013introducingsomemeasurementinaccuracy\u2013\nsuchsourcesoftenrelyonsensationalistheadlinesorbiasedsourcingwhichdiminishestheiroverall\ntrustworthiness. Source-levelratingscanreflectthesebroaderpatternsarisingfromweakeditorial\npractices,evenwhenindividualarticlesvaryinaccuracy(Lazeretal.,2018). Here,theNewsGuard\ndatabase serves as a useful tool for tracking online misinformation at the level of the source, but\nresearchersshouldweighitsutilityforthestudiedcontextagainstassociatedcostsandconsideral-\nternative sources (e.g., Lin et al., 2023) for comprehensive analysis. Our findings underscore the\ncritical need for dynamic, multifaceted, and openly accessible methods to get a clear and robust\nanswerontheimpactofmisinformationonentirepopulations.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch37\nAcknowledgments\nWe acknowledge David Garcia and No\u00eblle Lebernegg for discussions about measurement\nissuesinmisinformationresearchandAnnieWaldherrforherhelpfulfeedbackonthemanuscript.\nJ. Luehring, H.M., A.S. were supported by the Vienna Science and Technology Fund (WWTF)\nandtheCityofViennaundergrant10.47379/ICT20028andgrant10.47379/VRG16005. J.Lasser\nwassupportedbytheAustrianScienceFund(FWF)undergrantP37280-NandtheEuropeanRe-\nsearchCouncil(ERC)undertheEuropeanUnion\u2019sHorizonEuropeprogram(GrantagreementNo.\n101160928). The funders played no role in study design, data collection and analysis, decision to\npublishorpreparationofthearticle.\nData andCode Availability\nReproductionmaterials,includingcodeandextendeddata,excludingtheNewsGuarddatabase,\nwhich is proprietary, are accessible on Github. To license the NewsGuard database, contact sup-\nport@newsguardtech.com.\nAuthorContributions\nContributedtotheconceptionanddesign: J.Luehring,H.M.,J.Lasser,A.S.\nContributedtotheanalysisandinterpretationofdata: J.Luehring,R.M.L.,J.Lasser,H.M.\nWrotethearticle: J.Luehring\nRevisedthearticle: J.Luehring,H.M.,J.Lasser,A.S.\nFinalapprovaloftheversiontobepublished: J.Luehring,J.Lasser,H.M.,A.S.,R.M.L.\nReferences\nAllen, J., Howland, B., Mobius, M., Rothschild, D., and Watts, D. J. (2020). Evaluating the fake\nnewsproblematthescaleoftheinformationecosystem. ScienceAdvances ,6(14):eaay3539.\nPublisher: AmericanAssociationfortheAdvancementofScience.\nAllen, J., Watts, D. J., and Rand, D. G. (2024). Quantifying the impact of misinformation and\nvaccine-skepticalcontentonFacebook. Science,384(6699):eadk3451.Publisher: American\nAssociationfortheAdvancementofScience.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)38\nAltay,S.,Berriche,M.,andAcerbi,A.(2023). MisinformationonMisinformation: Conceptualand\nMethodologicalChallenges. SocialMedia+Society ,9(1):20563051221150412. Publisher:\nSAGEPublicationsLtd.\nAslett,K.,Guess,A.M.,Bonneau,R.,Nagler,J.,andTucker,J.A.(2022). Newscredibilitylabels\nhave limited average effects on news diet quality and fail to reduce misperceptions. Sci-\nence Advances ,8(18):eabl3844. Publisher: AmericanAssociationfortheAdvancementof\nScience.\nBakir, V. and McStay, A. (2018). Fake News and The Economy of Emo-\ntions. Digital Journalism , 6(2):154\u2013175. Publisher: Routledge _eprint:\nhttps://doi.org/10.1080/21670811.2017.1345645.\nBaribi-Bartov, S., Swire-Thompson, B., and Grinberg, N. (2024). Supersharers of fake news on\nTwitter.Science,384(6699):979\u2013982. Publisher: AmericanAssociationfortheAdvance-\nmentofScience.\nBenkler, Y., Faris, R., and Roberts, H. (2018). Network Propaganda: Manipulation, Disinforma-\ntion, and Radicalization in American Politics . OxfordUniversityPress.\nBennett, W. L. and Livingston, S., editors (2020). The Disinformation Age . SSRC Anxieties of\nDemocracy.CambridgeUniversityPress,Cambridge.\nBozarth,L.,Saraf,A.,andBudak,C.(2020). HigherGround? HowGroundtruthLabelingImpacts\nOurUnderstandingofFakeNewsaboutthe2016U.S.PresidentialNominees. Proceedings\nof the International AAAI Conference on Web and Social Media ,14:48\u201359.\nBr\u00fcggemann,M.,Engesser,S.,B\u00fcchel,F.,Humprecht,E.,andCastro,L.(2014).HallinandMancini\nRevisited: FourEmpiricalTypesofWesternMediaSystems: HallinandManciniRevisited.\nJournal of Communication ,64(6):1037\u20131065.\nBudak,C.,Nyhan,B.,Rothschild,D.M.,Thorson,E.,andWatts,D.J.(2024).Misunderstandingthe\nharms of online misinformation. Nature, 630(8015):45\u201353. Publisher: Nature Publishing\nGroup.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch39\nCeladin,T.,Capraro,V.,Pennycook,G.,andRand,D.G.(2023). DisplayingNewsSourceTrust-\nworthiness Ratings Reduces Sharing Intentions for False News Posts. Journal of Online\nTrustand Safety ,1(5). Number: 5.\nEcker, U. K. H., Lewandowsky, S., Cook, J., Schmid, P., Fazio, L. K., Brashier, N., Kendeou, P.,\nVraga, E. K., and Amazeen, M. A. (2022). The psychological drivers of misinformation\nbeliefanditsresistancetocorrection. Nature Reviews Psychology ,1(1):13\u201329.\nGonz\u00e1lez-Bail\u00f3n,S.,Lazer,D.,Barber\u00e1,P.,Zhang,M.,Allcott,H.,Brown,T.,Crespo-Tenorio,A.,\nFreelon,D.,Gentzkow,M.,Guess,A.M.,Iyengar,S.,Kim,Y.M.,Malhotra,N.,Moehler,\nD., Nyhan, B., Pan, J., Rivera, C. V., Settle, J., Thorson, E., Tromble, R., Wilkins, A.,\nWojcieszak, M., de Jonge, C. K., Franco, A., Mason, W., Stroud, N. J., and Tucker, J. A.\n(2023). Asymmetric ideological segregation in exposure to political news on Facebook.\nScience, 381(6656):392\u2013398. Publisher: American Association for the Advancement of\nScience.\nGrinberg,N.,Joseph,K.,Friedland,L.,Swire-Thompson,B.,andLazer,D.(2019). Fakenewson\nTwitterduringthe2016U.S.presidentialelection. Science,363(6425):374\u2013378. Publisher:\nAmericanAssociationfortheAdvancementofScienceSection: ResearchArticle.\nGuess, A., Aslett, K., Tucker, J., Bonneau, R., and Nagler, J. (2021). Cracking Open the News\nFeed: ExploringWhatU.S.FacebookUsersSeeandSharewithLarge-ScalePlatformData.\nJournal of Quantitative Description: Digital Media ,1.\nGuess, A. M. and Lyons, B. (2020). Misinformation, disinformation, and online Propaganda. In\nPersily, N. and Tucker, J., editors, Social media and democracy: The state of the field,\nProspects for reform ,pages10\u201333.CambridgeUniversityPress,Cambridge.\nGuess,A.M.,Nyhan,B.,andReifler,J.(2020). Exposuretountrustworthywebsitesinthe2016US\nelection.NatureHumanBehaviour ,4(5):472\u2013480.Number: 5Publisher: NaturePublishing\nGroup.\nHallin, D. C. and Mancini, P. (2004). Comparing Media Systems: Three Models of Media and\nPolitics. CambridgeUniversityPress. Google-Books-ID:954NJChZAGoC.\nHeft,A.,Kn\u00fcpfer,C.,Reinhardt,S.,andMayerh\u00f6ffer,E.(2021). TowardaTransnationalInforma-\ntionEcologyontheRight? HyperlinkNetworkingamongRight-WingDigitalNewsSitesin\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)40\nEuropeandtheUnitedStates. The International Journal of Press/Politics ,26(2):484\u2013504.\nPublisher: SAGEPublicationsInc.\nHeft, A., Mayerh\u00f6ffer, E., Reinhardt, S., and Kn\u00fcpfer, C. (2020). Beyond Breitbart: Comparing\nRight-WingDigitalNewsInfrastructuresinSixWesternDemocracies. Policy & Internet ,\n12(1):20\u201345. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/poi3.219.\nLasser, J., Aroyehun, S. T., Carrella, F., Simchon, A., Garcia, D., and Lewandowsky, S. (2023).\nFromalternativeconceptionsofhonestytoalternativefactsincommunicationsbyUSpoliti-\ncians.Nature Human Behaviour ,pages1\u201312. Publisher: NaturePublishingGroup.\nLasser, J., Aroyehun, S. T., Simchon, A., Carrella, F., Garcia, D., and Lewandowsky, S. (2022).\nSocial media sharing of low-quality news sources by political elites. PNAS Nexus ,\n1(4):pgac186.\nLazer,D.,Baum,M.A.,Benkler,Y.,Berinsky,A.J.,Greenhill,K.M.,Menczer,F.,Metzger,M.J.,\nNyhan, B., Pennycook, G., Rothschild, D., Schudson, M., Sloman, S. A., Sunstein, C. R.,\nThorson,E.A.,Watts,D.J.,andZittrain,J.L.(2018). Thescienceoffakenews. Science,\n359(6380):1094\u20131096.\nLin, H., Garro, H., Wernerfelt, N., Shore, J. C., Hughes, A., Deisenroth, D., Barr, N., Berinsky,\nA.J.,Eckles,D.,Pennycook,G.,andRand,D.(2024). Reducingmisinformationsharingat\nscaleusingdigitalaccuracypromptads.\nLin,H.,Lasser,J.,Lewandowsky,S.,Cole,R.,Gully,A.,Rand,D.G.,andPennycook,G.(2023).\nHighlevelofcorrespondenceacrossdifferentnewsdomainqualityratingsets. PNASNexus ,\n2(9):pgad286.\nLorenz-Spreen, P., Oswald, L., Lewandowsky, S., and Hertwig, R. (2022). A systematic review\nof worldwide causal and correlational evidence on digital media and democracy. Nature\nHumanBehaviour ,pages1\u201328. Publisher: NaturePublishingGroup.\nNewman,N.,Fletcher,R.,Eddy,K.,Robertson,C.T.,andNielsen,R.K.(2023). ReutersInstitute\nDigitalNewsReport2023.\nOsmundsen, M., Bor, A., Vahlstrup, P. B., Bechmann, A., and Petersen, M. B. (2021). Partisan\nPolarization Is the Primary Psychological Motivation behind Political Fake News Sharing\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch41\non Twitter. American Political Science Review , 115(3):999\u20131015. Publisher: Cambridge\nUniversityPress.\nPratelli, M., Petrocchi, M., Saracco, F., and De Nicola, R. (2023). Swinging in the States: Does\ndisinformation on Twitter mirror the US presidential election system? arXiv:2303.12474\n[cs].\nPuschmann,C.,Stier,S.,Merten,L.,Kulshrestha,J.,Rauxloh,H.,andSchultz,C.(2023). German\nOnlineNewsDomains. Publisher: OSF.\nRobertson, R. E., Green, J., Ruck, D. J., Ognyanova, K., Wilson, C., and Lazer, D. (2023). Users\nchoose to engage with more partisan news than they are exposed to on Google Search.\nNature,618(7964):342\u2013348.\nShao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., and Menczer, F. (2018). The\nspreadoflow-credibilitycontentbysocialbots. Nature Communications ,9(1):4787. Pub-\nlisher: NaturePublishingGroup.\nTay, L. Q., Lewandowsky, S., Hurlstone, M. J., Kurz, T., and Ecker, U. K. H. (2024). Thinking\nclearly about misinformation. Communications Psychology , 2(1):1\u20135. Number: 1 Pub-\nlisher: NaturePublishingGroup.\nTsfati, Y., Boomgaarden, H. G., Str\u00f6mb\u00e4ck, J., Vliegenthart, R., Damstra, A., and\nLindgren, E. (2020). Causes and consequences of mainstream media dissemi-\nnation of fake news: literature review and synthesis. Annals of the Interna-\ntional Communication Association , 44(2):157\u2013173. Publisher: Routledge _eprint:\nhttps://doi.org/10.1080/23808985.2020.1759443.\nvanderLinden,S.(2022).Misinformation: susceptibility,spread,andinterventionstoimmunizethe\npublic.Nature Medicine ,28(3):460\u2013467. Number: 3Publisher: NaturePublishingGroup.\nVargo, C. J., Guo, L., and Amazeen, M. A. (2018). The agenda-setting power of fake news: A\nbigdataanalysisoftheonlinemedialandscapefrom2014to2016. New Media & Society ,\n20(5):2028\u20132049. Publisher: SAGEPublications.\nWeeks, B. E. and Gil de Z\u00fa\u00f1iga, H. (2021). What\u2019s Next? Six Observations for the Future of\nPoliticalMisinformationResearch. American Behavioral Scientist ,65(2):277\u2013289.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)42\nYang, K.-C., Pierri, F., Hui, P.-M., Axelrod, D., Torres-Lugo, C., Bryden, J., and Menczer, F.\n(2021). The COVID-19 Infodemic: Twitter versus Facebook. Big Data & Society ,\n8(1):20539517211013861. Publisher: SAGEPublicationsLtd.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch43\nOnline Appendix\n2019 2020 2021 2022 2023 2024\nTime (years)020406080100Trustworthiness\nFigure A.1. Distribution of trustworthiness per year as a violin plot (with M and SD),\nstandardizedbycount.\n2019 2020 2021 2022 2023 2024 2025\nTime (months)60\n40\n20\n02040Difference in subsequent scores\nFigure A.2. Changes in trustworthiness scores over time, calculated as the difference in\nscorespernewsdomainbetweenconsecutiveupdates.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)44\nTable A.1: Correlationmatrixofjournalisticqualitycriteria.\n1 2 3 4 5 6 7 8 9\n1 1 0.63 0.4 0.56 0.93 0.38 0.39 0.26 0.36\n2 0.63 1 0.57 0.75 0.63 0.58 0.49 0.55 0.56\n3 0.4 0.57 1 0.48 0.4 0.45 0.44 0.34 0.53\n4 0.56 0.75 0.48 1 0.57 0.52 0.51 0.47 0.5\n5 0.93 0.63 0.4 0.57 1 0.39 0.37 0.28 0.39\n6 0.38 0.58 0.45 0.52 0.39 1 0.42 0.48 0.4\n7 0.39 0.49 0.44 0.51 0.37 0.42 1 0.29 0.36\n8 0.26 0.55 0.34 0.47 0.28 0.48 0.29 1 0.47\n9 0.36 0.56 0.53 0.5 0.39 0.4 0.36 0.47 1\n2016 2018 2020 202260708090100NewsGuard scoreThe Left Party\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100NewsGuard scoreAlliance 90/The Greens\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100NewsGuard scoreSPD\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100NewsGuard scoreFDP\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100NewsGuard scoreCDU/CSU\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100NewsGuard scoreAFD\n2019\n2020\n2021\n20222023\n2024\ndynamicA B C\nD E F\nFigure A.3. Reproduction of trustworthiness ratings of sources shared by German politi-\ncianson Twitter over time fromLasser et al. (2022). Panel Ashows average NewsGuard\nscoresinTwitterpostsbymembersofthepartyDIELINKE,panelBformembersofthe\nGreens, panel C for members of the SPD, panel D for members of the FDP, panel E for\nmembersoftheCDUandCSU,andpanelFformembersoftheAFD.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch45\n2016 2018 2020 20220%5%10%% untrustworthy linksThe Left Party\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220%5%10%\nAlliance 90/The Greens\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220%5%10%\nSPD\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220%5%10%% untrustworthy linksFDP\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220%5%10%\nCDU/CSU\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220%50%100%\nAFD\n2019\n2020\n2021\n20222023\n2024\ndynamicA B C\nD E F\nFigureA.4. Fractionofuntrustworthylinks(e.g.,NewsGuardscore<60)sharedbyGerman\npoliticians on Twitter over time from Lasser et al. (2022). Panel A shows the fraction of\nuntrustworthylinkssharedinTwitterpostsbymembersofthepartyDIELINKE,panelB\nformembersoftheGreens,panelCformembersoftheSPD,panelDformembersofthe\nFDP,panelEformembersoftheCDUandCSU,andpanelFformembersoftheAFD\u2013note\nthedifferentscaleinthey-axis!\n2016 2018 2020 202260708090100NewsGuard scoreLabour\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100\nScottish National Party\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100\nLiberal Democrat\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100NewsGuard scoreT ory\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 202260708090100\nDemocratic Unionist Party\n2019\n2020\n2021\n20222023\n2024\ndynamicA B C\nD E\nFigureA.5. ReproductionoftrustworthinessratingsofsourcessharedbyUKpoliticianson\nTwitterovertimefromLasseretal.(2022). PanelAshowsaverageNewsGuardscoresin\nTwitterpostsbymembersoftheLabourparty,panelBformembersoftheScottishNational\nParty,panelCforLiberalDemocrats,panelDforTories,andpanelEformembersofthe\nDemocraticUnionistParty.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)46\n2016 2018 2020 20220.0%0.5%1.0%1.5%% untrustworthy linksLabour\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220.0%0.5%1.0%1.5%\nScottish National Party\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220.0%0.5%1.0%1.5%\nLiberal Democrat\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220.0%0.5%1.0%1.5%% untrustworthy linksT ory\n2019\n2020\n2021\n20222023\n2024\ndynamic\n2016 2018 2020 20220.0%0.5%1.0%1.5%\nDemocratic Unionist Party\n2019\n2020\n2021\n20222023\n2024\ndynamicA B C\nD E\nFigure A.6. Fraction of untrustworthy links (e.g., NewsGuard score <60) shared by UK\npoliticianspoliticiansonTwitterovertimefromLasseretal.(2022). PanelAshowsaverage\nNewsGuardscoresinTwitterpostsbymembersoftheLabourparty,panelBformembers\noftheScottishNationalParty,panelCforLiberalDemocrats,panelDforTories,andpanel\nEformembersoftheDemocraticUnionistParty.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch47\n406080100Trustworthiness scoreAT\nScore\nN_sources\n406080100AU\n406080100CA\n406080100Trustworthiness scoreDE\n406080100FR\n406080100GB\n201920202021202220232024\nTime (months)406080100Trustworthiness scoreIT\n201920202021202220232024\nTime (months)406080100NZ\n201920202021202220232024\nTime (months)406080100US25303540\n50100150\n100200300400\nNumber of sources\n100200300\n100200300400\n0200400\nNumber of sources\n100200300400500\n5101520\n400060008000\nNumber of sources\nFigureA.7. Developmentofoveralltrustworthinesspercountryovertime(greenline)and\nthenumberofsources(blueline)withshadedareasrepresentingstable6-monthwindows.\nDashedlinesindicatethefirstdateofastableinterval.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)48\nTrustworthiness051015Number of sourcesAT\nTrustworthiness01020304050Number of sourcesAU\nTrustworthiness050100150200250Number of sourcesCA\nTrustworthiness050100150200Number of sourcesDE\nTrustworthiness020406080100120Number of sourcesFR\nTrustworthiness050100150200250Number of sourcesGB\n0 50 100\nTrustworthiness050100150200Number of sourcesIT\n0 50 100\nTrustworthiness0246Number of sourcesNZ\n0 50 100\nTrustworthiness0500100015002000Number of sourcesUS\nFigure A.8. DistributionoftrustworthinesspercountryasofSeptember15th,2024.\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch49\nTable A.2: OverlapbetweenGONDandNewsGuard.\nGONDType NewsGuardScore Overlap %\ncommercialbroadcaster 89.4 58 10.5\ndigital-bornnewsoutlet 84.5 66 12.0\nhyperpartisannews 43.0 56 10.1\nlegacypress 91.0 292 52.9\npublicbroadcaster 89.0 40 7.2\ntabloidnewspaper 84.6 40 7.2\nNote.AsofSeptember15th,2024.\nTable A.3: Orientation per country.\nCountry Left(%) Right(%) Total\nUS 401(12.45) 2819(87.55) 3220\nFR 36(41.86) 50(58.14) 86\nIT 18(25.35) 53(74.65) 71\nDE 10(16.13) 52(83.87) 62\nGB 30(50.85) 29(49.15) 59\nAU 9(31.03) 20(68.97) 29\nCA 8(33.33) 16(66.67) 24\nAT 2(18.18) 9(81.82) 11\nNZ 1(25.0) 3(75.0) 4\nNote.AsofSeptember15h,2024.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)50\n0246810Number of sourcesAT\n0510152025Number of sourcesAU\n0510152025Number of sourcesCA\n020406080Number of sourcesDE\n020406080Number of sourcesFR\n0204060Number of sourcesGB\n201920202021202220232024\nTime (years)020406080Number of sourcesIT\n201920202021202220232024\nTime (years)01234Number of sourcesNZ\n201920202021202220232024\nTime (years)0100020003000Number of sourcesUSFar Left Slightly Left Slightly Right Far Right Left Right\nFigure A.9. Distributionofpoliticalorientationovertime,bycountry\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch51\n2019-10 2020-01 2020-04 2020-07 2020-10 2021-01 2021-04 2021-07 2021-10 2022-01 2022-04 2022-07 2022-11 2023-02 2023-05 2023-08 2023-11 2024-02 2024-05 2024-08\nTime (months)020004000600080001000012000Number of sourcesT otal\nWith topics\nFigure A.10. Numberofsourcesovertimewithandwithouttopiclabels.\nLuehringetal. JournalofQuantitativeDescription: DigitalMedia5(2025)52\n0 20\nNumber of ratingsPolitical news\nGeneral news\nLocal news\nEntertainment\nCelebrity newsT opicsAT\n0 50\nNumber of ratingsGeneral news\nLocal news\nPolitical news\nLifestyle\nEntertainmentT opicsAU\n0 200\nNumber of ratingsLocal news\nGeneral news\nPolitical news\nHealth news\nEntertainmentT opicsCA\n0 200\nNumber of ratingsPolitical news\nLocal news\nGeneral news\nConspiracies\nHealth newsT opicsDE\n0 100\nNumber of ratingsPolitical news\nLocal news\nGeneral news\nHealth news\nConspiraciesT opicsFR\n0 200\nNumber of ratingsPolitical news\nBusiness\nLocal news\nGeneral news\nHealth newsT opicsGB\n0 200\nNumber of ratingsGeneral news\nLocal news\nPolitical news\nHealth news\nConspiraciesT opicsIT\n0 10\nNumber of ratingsLocal news\nPolitical news\nGeneral news\nLifestyle\nEntertainmentT opicsNZ\n0 2000\nNumber of ratingsPolitical news\nLocal news\nGeneral news\nConspiracies\nHealth newsT opicsUS0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\n0 50 100Trustworthiness\nFigure A.11. Topfivemostpopulartopicspercountryandtheirtotalcount,withthesec-\nondx-axisatthetopshowingtheaveragetrustworthinessandstandarddeviationsofthose\ntopics..\nJQD:DM5(2025) BestPracticesforSource-BasedMisinformationResearch53\n0 20 40 60 80 100\nTrustworthinessPolitical news\nLocal news\nGeneral news\nConspiracies\nHealth newsT opic\nAT AU CA DE FR GB IT NZ US\nFigureA.12. Trustworthinessscoreforthetopfivemostpopulartopicsacrosscountriesin\nthemostrecentdatabase(September15,2024).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Best practices for source-based research on misinformation and news trustworthiness using NewsGuard", "author": ["J L\u00fchring", "H Metzler", "R Lazzaroni", "A Shetty"], "pub_year": "2025", "venue": "Journal of Quantitative \u2026", "abstract": "Researchers need reliable and valid tools to identify cases of untrustworthy information  when studying the spread of misinformation on digital platforms. A common approach is to"}, "filled": false, "gsrank": 39, "pub_url": "https://journalqd.org/article/view/4500", "author_id": ["9FQdKwwAAAAJ", "fpkiNJYAAAAJ", "GIkOsq8AAAAJ", "Qx2eJ0YAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:3IK7M1Z-PCAJ:scholar.google.com/&output=cite&scirp=38&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D30%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=3IK7M1Z-PCAJ&ei=CrWsaIYfwNmJ6g-p2qHxBQ&json=", "num_citations": 9, "citedby_url": "/scholar?cites=2322870416516547292&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:3IK7M1Z-PCAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://journalqd.org/article/download/4500/7376"}}, {"title": "BASE: a Bias-Aware news Search Engine for improving user awareness", "year": "2022", "pdf_data": "This is a repository copy of BASE : a Bias-Aware news Search Engine for improving user \nawareness .\nWhite Rose Research Online URL for this paper:\nhttps://eprints.whiterose.ac.uk/190267/\nVersion: Accepted Version\nProceedings Paper:\nParamita, M., Kasinidou, M., Kleanthous, S. et al. (2 more authors) (2022) BASE : a Bias-\nAware news Search Engine for improving user awareness. In: P roceedings of DESIRES \n2022. DESIRES 2022 \u2013 3rd International Conference on De sign of Experimental Search & \nInformation REtrieval Systems, 30-31 Aug 2022, San Jose, CA, U SA. CEUR Workshop \nProceedings . \neprints@whiterose.ac.uk\nhttps://eprints.whiterose.ac.uk/\nReuse \nThis article is distributed under the terms of the Creat ive Commons Attribution (CC BY) licence. This licence \nallows you to distribute, remix, tweak, and build upon t he work, even commercially, as long as you credit the \nauthors for the original work. More information and t he full terms of the licence here: \nhttps://creativecommons.org/licenses/ \nTakedown \nIf you consider content in White Rose Research Online to b e in breach of UK law, please notify us by \nemailing eprints@whiterose.ac.uk including the URL of th e record and the reason for the withdrawal request. \nBASE:a Bias-Awarenews Search Engine for\nimprovinguserawareness[Prototype]\nMonicaLestari Paramita1,\u2217,MariaKasinidou2,StylianiKleanthous2and\nFrankHopfgartner1,3\n1UniversityofSheffield,Sheffield,United Kingdom\n2OpenUniversityofCyprus, Nicosia,Cyprus\n3Universit\u00e4tKoblenz,Koblenz,Germany\nAbstract\nTheBASEprototypeaimstoimproveuserawarenessofbiasesinsearchengineresults. Itutilisesexisting\nresources and NLP tools to identify biases in news articles. It incorporates bias visualisation features to\ninform users of biases in each news article and at the search results level. It also incorporates results\nrerankingfeaturestoallowuserstoretrievedifferentsetsofresultsbasedontheirsearchpreferences.\nPreliminary evaluation results suggest the prototype achieves a positive usability score (64.3 out of 100)\nandhasapotentialforincreasinguserawarenessofbiases,withthererankingfeaturesratedmoreuseful\nthanthe biasvisualisation features.\nKeywords\nbiasinsearchengines, interfacedesign,evaluation\n1. Introduction\nIncreasingly,itbecomesobviousthatnewssearchenginesmayincludebiasesintheirsearch\nresults [1]. These biasesmay appear atthe articlelevel ,e.g., an article may present a viewthat\nis politically biased to a certain political ideology (e.g., left wing). In other cases, an article may\nproduce a certain focus, e.g., a report on COVID-19 rate for a specificcountry, oran article on\nCOVID-19 vaccine for a specific manufacturer. The focus of the article may not necessarily\nintroducebiasinthecontentitself,e.g.,anarticlethatfocusesonPfizerdoesnotnecessarily\npresents a view that is biasedtowards Pfizer. However, if a query \u2018covid vaccine\u2019 retrieves\nmostly articles with Pfizer as the entity focus, this may be seen as a bias at the results level .\nBiases attheresults level mayalso be causedby searchengine\u2019slocalisation, which promotes\nsearchresultswiththesamegeographicalfocusastheusers\u2019location[ 2]. Althoughlocalisation\naimstoproviderelevantresults,theseresultsalsohighlylimitusers\u2019viewsofthetopic, often\nwithoutusers\u2019awarenessoftheresultsthattheydo notsee. Thelackofuserawarenessofthese\nDESIRES 2022 \u2013 3rd International Conference on Design of Experimental Search & Information REtrieval Systems, 30-31\nAugust2022, SanJose,CA,USA\n\u2217Corresponding author.\n/envelope-openm.paramita@sheffield.ac.uk (M.L. Paramita); maria.kasinidou@ouc.ac.cy (M. Kasinidou);\nstyliani.kleanthous@gmail.com (S. Kleanthous); hopfgartner@uni-koblenz.de (F. Hopfgartner)\n/orcid0000-0002-9414-1853 (M.L. Paramita)\n\u00a92022 Copyright for thispaper by itsauthors. Usepermitted underCreative Commons License Attribution4.0 International (CC BY 4.0).\nCEUR\nWorkshop\nProceedingshttp://ceur-ws.org\nISSN 1613-0073\nCEUR Workshop Proceedings ( CEUR-WS.org )\nbiases have been shown to manipulate users\u2019 understandings of a topic [ 3] and influence their\ndecision making[ 4].\nPreviousstudieshaveproposedanumberofvisualisationstoincreaseuserawarenessofbiases.\nNews aggregators, such as AllSides [ 5] and GroundNews [ 6], have presented news articles\nthat represent multiple political ideologies to provide users with a balanced view. Hamborg\netal. [7]providesmatrix-basedresultstosupportusersinaccessingnewseventsfromnews\npublishersindifferentlocations(as theyoftenpresentdifferentperspectives). Otherstudies,\nsuchasPapadakosandKonstantakis[ 8],havealsoexploredtheimportanceofdisplayingbiased\naspects for the entire search results. However, very few studies have investigated designs that\nvisualises multipletypes of biases, whichareoften thecase for newsarticles.\nInthispaper,weintroduceanovelprototypeofasearchengineinterfacedesignedtoincrease\nusers\u2019awarenessofmultipletypesofbiasesintheresults. Theprototypealsoaimstoprovide\nthe ability to users to easily access different facets of the results. Instead of developing new\nmethodsformeasuringbiases,theprototypemakesuseofavailableresourcesandtechniquesto\ninform users of possible biases in the results. This means that such system can be made usable\nin thenear futureto supportusersintheirinformationseeking tasks. Aninitialevaluationof\nhow users respond to these visualisations are also provided in this study. This work provides a\nvaluablecontributioninunderstandinghowbias-awarenewssearchenginesshouldbedesigned.\n2. BASE: Bias-Aware news SearchEngineprototype\n2.1. Design\nTo identify specific features to include in the design, we conducted three user studies on\ndesigningbias-awaresearchenginesusingaparticipatoryapproach. Theseresultedineight\ndesignsthatincorporated twodifferentapproaches: i) bias visualisation approach , for informing\nusers ofpossiblebiasesinthe results, andii) results-rerankingapproach , which allows users to\naccess different results by modifying (the ranking of) the results. We invited 132 participants to\nevaluatetheseeightdesigns. Thefindingssuggestthatuserswouldlikei)toseeinformation\non different types of biases in search results, ii) the ability to re-rank the results using their\npreferredaspect, andiii)tohavebothapproaches in search engines.\nWeincorporatedfindingsfromthesestudiesintothedesignof BASE.1Theprototypeprovides\nbothbiasvisualisationandresults-rerankingfeatures. Asproof-of-concept,weselectedfour\naspectstobeincludedinthere-rankingfeatures: politicalbias,geographicallocationsofthe\npublishers, geographical focus of the articles, and the entity focus of the articles. More aspects\nmay beintegratedin thenextfutureif methods tomeasurethem becomeavailable.\nWhenusersaccesstheprototype,theyareaskedtoenteraquerysuchas\u201ccoronavirus\u201dto\nstart searching. Once the user submits the query, the system will display the search results\n(Figure1)usingtwopanels. Theleftpanelshowsthelistofarticles,andtherightpanelcontains\nfiguresthatrepresentsthebiasesattheresultslevel. Theprototypeshowstwo biasvisualisation\nfeatures. The first feature provides bias information at the article level (shown in the left panel\nasdifferenticonsontherightsideofeacharticle). Eachiconrepresentsdifferenttypesofbiases.\n1https://cycat.group.shef.ac.uk/prototype/BASE/\nFigure1: BASEprototypeinterface\nE.g., the scalerepresentspoliticalbias. Whenusers hover ontheicon, it providesinformation\nonthetypesofbiasesandthespecificbiasedaspect,e.g.,\u201cPoliticalbias: left-center\u201d. Thesecond\nfeatureprovidesbiasinformationattheresultslevel(shownintherightpanel)intheformof\ntwobarcharts(displayingpoliticalbiasandentityfocus)andtwochoroplethmaps(showing\ngeographicallocationsof thepublishersandgeographicalfocus of thearticles).\nWealsoincorporatedthe results-rerankingfeatures toallowuserstoretrievenewsarticles\nfrom specified political bias, countries, or entities, by clicking the aspect they would like to see\nfurtherusingthefiguresintherightpanel. E.g.,byclicking\u201cLeft-center\u201donthepoliticalbiasbar\nchart,theresultswillbeupdatedtocontainonlyarticlesfromnewspublishersidentifiedtohave\na\u201cleft-center\u201dbias. Similarly,ifusersclickonthecountry\u201cAustralia\u201dinthe\u201cgeographicalfocus\nof the articles\u201d graph, users will then be able to view only those articles reporting COVID-19 in\nAustralia. Wedescribethemethods toidentify andvisualisethesebiases in Section 2.2.\n2.2. Workflowofthe BASE prototype\nThis section describes the information processing workflow of the search engine (illustrated in\nFigure2)andoutlinesthemethods used tomeasureandvisualisethesebiases.\nWe limited our index on news articles related to the COVID-19 pandemic. For this, we\nused themost popular queries for this topic according to Google Trends in February 2021. We\nretrieved 100 news articles per query returned by Google News using the Zenserp API [ 9]. This\nprocesswas conducteddailytoallow users toaccessthemostupdated newsarticles.\nForeacharticle,wecarriedouttwoprocesses. Firstly,weextractedtheURLofthepublishers\nforthenewsarticles,e.g. bbc.co.uk (BBC),orft.com(FinancialTimes). TheseURLswere\nthen used to identify the political bias of the publishers and the location of the publishers.\nFigure2: BASEWorkflow\nSecondly, we crawled the content of the articles and removed the boilerplates. These contents\nwereprocessedusinganamedentityrecognisertoidentifythegeographicalfocusofthearticle\nandtheentity focus of thearticle. Wedescribetheseprocesses in moredetailbelow.\nPolitical bias. We utilised an external resource, Media Bias/Fact Check (MBFC) [ 10], to\nidentify the political bias of the publishers. MBFC is an online source that provides annotations\nofbiases basedon the publishers\u2019i) political affiliations, ii)story choices (ifthey publish from\nboth sides or just one), iii) use of biased wording to sway readers, and iv) rates of factual\nreporting. By August 2021, MBFC has annotated 3,103 news publishers using five different\nratingtorepresent thepolitical bias: \u201cleft\u201drepresents aliberal view,\u201cleft-center\u201d,\u201ccenter/least\nbiased\u201d, \u201cright-center\u201d and \u201cright\u201d represents a conservative view. It has further used four\ncategories to represent sites that are considered to be \u201cquestionable sources\u201d, \u201cpro-science\u201d,\n\u201csatire\u201dorcontaining\u201cconspiracy-pseudoscience\u201d. Theseratingswereextractedtorepresentthe\n\u201cpolitical bias of the publishers\u201d in the prototype. For cases where publishers were not included\nintheMBFCdatabase,thepoliticalbiasislistedas\u201cunknown\u201d. Thepoliticalbiasofallthenews\narticlesdisplayed inthe resultsis aggregatedandrepresented inabarchart (seeFigure 3a) to\nallow readerstoget some insights intothepossiblebias presented in theirsearch results.\nGeographicallocationofthepublishers. Wedeterminedthelocationofthepublishersby\nanalysing the suffix of the URL (e.g., \u201c bbc.co.uk \u201d is based in the UK, \u201c abc.net.au \u201d is based\nin Australia). Whenthis information wasnot available, we used \u2018 whois\u2019 command to identify\nthe country where the domain is registered. Similarly, the publisher location was extracted for\neach article, and was aggregated for all the search results. This information is displayed using a\nchoropleth map(seeFigure 3b).\nGeographicalfocusofthearticles. WeusedScrapy[ 11],anopen-sourceweb-crawling\nframework,tocrawlthecontentofthearticles. BoilerplateswereremovedusingjusTextlibrary\n[12],resultinginthemaintextcontentofthearticles. Weusedanamedentityrecogniser(spaCy\n[13] trained using the en_core_web_trf model) to identify country names discussed in each\n(a) Politicalbiasof thepublishers\n (b) Geographicallocation of thepublishers\n(c)Geographicalfocusof articles\n (d) Entityfocusof articles\nFigure3: Biasvisualisationfeatures\narticle. The most frequent country is selected as the geographical focus of the article. Similarly\nto the locations of the publishers, this information is also aggregated at the results level and is\nvisualisedusinga choropleth map(seeFigure 3c).\nEntity focus of the articles. We used spaCy [ 13] to identify the most frequent entities\ndiscussed in the article. If multiple entities had the same frequency, one was chosen randomly\nas the entity focus of the article. This information was aggregated for all the search results\nandthetop10mostpopularentitiesareshowninabarchart. E.g.,Figure 3dshowsthemost\npopularentitiesforthequery: \u201ccovidvaccine\u201d. Thisincludespopularvaccinemanufacturers,\nsuchas\u201cPfizer\u201d,\u201cModerna\u201dand\u201cAstraZeneca\u201d,andalsorelevantUKgovernmentandhealth\nentitiessuchas\u201cJointCommitteeonVaccinationandImmunisation\u201d(JCVI),\u201cMedicinesand\nHealthcareproducts RegulatoryAgency\u201d (MHRA)and\u201cNationalHealth Service\u201d (NHS).\n2.3. Infrastructure\nDuetotheamountofprocessingrequired,thebiasidentificationtaskwasperformedoffline.\nOncecompleted,thebiasinformation(andfocus)wasstoredinanindex,togetherwitheach\narticle\u2019sinformation(e.g.,URL,title,snippets,etc.). WhenuserssubmitaquerytotheBASE\nsystem,thearticlesareretrievedanddisplayedonthegraphicaluserinterface. Theinterface\nisdevelopedusingPHP,andthevisualisations(barchartandchoroplethmap)aredeveloped\nusingPlotlyJavascript open sourcegraphing library[ 14].\n2.4. Preliminary Evaluation\nApreliminaryevaluationstudyinvolving21participants \u2013 47.62% BSc, 33.33%MScand4.76%\nPhDstudents,and14.29%non-students;38.1%malesand61.9%females;rangingfrom18toover\n40 years old; from Cyprus (42.9%), Greece (47.6%), France (4.8%) and Italy (4.8%) \u2013 suggested\nthat this prototype achieves a moderately positive usability score (64.3 out of 100 using the\nSystem Usability Scale) [ 15]. Some participants mentioned that the system provided too much\ninformation that might be too complex for some to use. However, other participants found the\nsystem tobeeasytouseandhad thepotentialtoprovide moretransparencyof search results.\nA further evaluation study involving 60 MSc students \u2013 55% males, 43.33% females, 1.67%\npreferred not to say; 92% between 21-25 years old, and the remaining 26 and older; majority\n(88.33%)fromChina,andtherestfromotherAsiancountriesandSlovakia\u2013suggestedthatthey\nfoundthererankingresultsfeaturestobethemostuseful(4.08outof5). Biasinformationat\nthe results level were found to be more useful (4.02) than those at the article level (3.75), due to\nthe difficulties to understand the meaning of bias icons for each article (left panel). Participants\nliked the distribution of biases in thesearch results (right panel). They also liked the ability to\nclickonthebarchartormapstoeasilyretrieveresultsfromeachaspect. Furtherfeedbackfrom\nuserssuggestedthatusersneedmoreclarity,especiallyhowbiaseswerecalculated. Othersalso\nsuggest that the design should be more inclusive, as the \"left\" and \"right\" aspect for political\nideologiesarenot necessarily thesamenor a familiar conceptfor users from other countries.\n3. Reflectionsandconclusions\nWerealisethatbiasidentificationisachallengeonitsownandmaycontainitsownsubjectivities\nandbiases. Wereducedthisriskbyselectingtrustworthyresources(MBFC)andfocusingon\nbiasesthatcaneasilybedetermined(e.g.,locations). MBFC,however,doesnothaveanextensive\ncoverage,especiallyfornon-Englishnewssites. Moreover,thenamedentityrecogniserdoesnot\nmap any cities or towns towards therelevantcountry counts. It alsoselectsthe most frequent\nentitieswithouttakingthequerycontextintoaccount(e.g.,thatPfizerandModernaarerelevant\nentitiesfor\u201ccovidvaccine\u201dquery,butReutersisnot). Moresophisticatedmethods,therefore,\nwillneedtobeimplemented toaccuratelyidentify biases in newssearch results.\nDespitetheselimitations,theBASEprototypeillustrateshowbiasesinsearchresultscouldbe\ncommunicatedtotheusers. Theprototypeincorporatesbiasvisualisationandresults-reranking\nfeaturestoinformusersoftheexistingbiasesandsupportthemintheirsearchtasks. Weutilised\navailable resources and NLP tools to identify biases in search results. Our initial evaluation\nshowsthattheprototypehaspotentialsforincreasingtransparencyofsearchresults. Future\nworkwillinvestigatewaystoimprovethesefeaturesandtoreducethecomplexityofthesystem.\nAcknowledgments\nWewouldliketothankthereviewersfortheirconstructivefeedbackonthispaper. Thisproject\nisfundedbytheEuropeanUnion\u2019sHorizon2020researchandinnovationprogrammeunder\ngrant agreements No. 810105 (CyCAT).\nReferences\n[1]F. Hamborg, K. Donnay, B. Gipp, Automated identification of media bias in news\narticles: an interdisciplinary literature review, International Journal on Digital Li-\nbraries 20 (2019) 391\u2013415. URL: https://doi.org/10.1007/s00799-018-0261-y . doi:10.1007/\ns00799-018-0261-y .\n[2]M. L. Paramita, K. Orphanou, E. Christoforou, J. Otterbacher, F. Hopfgartner, Do you see\nwhatIsee? ImagesoftheCOVID-19pandemicthroughthelensofGoogle, Information\nProcessing & Management 58 (2021) 102654. URL: https://www.sciencedirect.com/science/\narticle/pii/S0306457321001424 . doi:10.1016/j.ipm.2021.102654 .\n[3]A. Novin, E. Meyers, Making Sense of Conflicting Science Information: Exploring Bias in\nthe Search Engine Result Page, in: Proceedings of the 2017 Conference on Conference\nHuman Information Interaction and Retrieval, CHIIR \u201917, Association for Computing\nMachinery, New York, NY, USA, 2017, pp. 175\u2013184. URL: https://doi.org/10.1145/3020165.\n3020185. doi:10.1145/3020165.3020185 .\n[4]R.Epstein,R.E.Robertson, Thesearchenginemanipulationeffect(SEME)anditspossible\nimpact on the outcomes of elections, Proceedings of the National Academy of Sciences of\ntheUnitedStates of America112(2015)E4512\u20134521. doi: 10.1073/pnas.1419828112 .\n[5]AllSides|Balancednewsviamediabiasratingsforanunbiasednewsperspective,2022.\nURL:https://www.allsides.com/unbiased-balanced-news .\n[6] GroundNews,2022. URL: https://ground.news/ .\n[7]F. Hamborg, N. Meuschke, B. Gipp, Matrix-Based News Aggregation: Exploring Different\nNewsPerspectives, in: 2017ACM/IEEEJointConferenceonDigitalLibraries(JCDL),2017,\npp. 1\u201310. doi: 10.1109/JCDL.2017.7991561 .\n[8]P. Papadakos, G. Konstantakis, bias goggles: Graph-Based Computation of the Bias\nof Web Domains Through the Eyes of Users, in: J. M. Jose, E. Yilmaz, J. Magalh\u00e3es,\nP. Castells, N. Ferro, M. J. Silva, F. Martins (Eds.), Advances in Information Retrieval,\nLectureNotesinComputerScience,SpringerInternationalPublishing,Cham,2020, pp.\n790\u2013804.doi: 10.1007/978-3-030-45439-5_52 .\n[9] Zenserp, 2022. URL: https://zenserp.com/ .\n[10] MediaBias/Fact Check,2022. URL: https://mediabiasfactcheck.com/ .\n[11] Scrapy, 2022. URL: https://scrapy.org/ .\n[12] jusText,2022. URL: https://pypi.org/project/jusText/ .\n[13] spaCy,2022. URL: https://spacy.io/models/en .\n[14] Plotlyjavascript open sourcegraphing library, 2022. URL: https://plotly.com/javascript/ .\n[15]System usability scale (sus), 2022. URL: https://www.usability.gov/how-to-and-tools/\nmethods/system-usability-scale.html .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "BASE: a Bias-Aware news Search Engine for improving user awareness", "author": ["M Paramita", "M Kasinidou"], "pub_year": "2022", "venue": "\u2026 of DESIRES 2022", "abstract": "The BASE prototype aims to improve user awareness of biases in search engine results. It  utilises existing resources and NLP tools to identify biases in news articles. It incorporates"}, "filled": false, "gsrank": 42, "pub_url": "https://eprints.whiterose.ac.uk/id/eprint/190267/", "author_id": ["w8qf-uoAAAAJ", "1uG97FkAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:vG_tGU_jEvAJ:scholar.google.com/&output=cite&scirp=41&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D40%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=vG_tGU_jEvAJ&ei=C7WsaMuIJazWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:vG_tGU_jEvAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://eprints.whiterose.ac.uk/id/eprint/190267/1/DESIRES_2022__camera_ready_v2.pdf"}}, {"title": "War Against Fake News: Avoiding Manicheism", "year": "2024", "pdf_data": "War against fake news: avoiding Manichaeism\nFerrari Sacha1\n1Center for Logic and Philosophy of Science, KU Leuven, Kardinaal\nMercierplein 2, Leuven, 3000, Belgium.\nContributing authors: sacha.ferrari@kuleuven.be;\nAbstract\nIn this article, I will analyze two strategies involved in the war against fake news:\nthe quality rating of media outlets and fact-checking. For each of them, I will point\nout the motivations of the stakeholders to undertake such demanding enterprises.\nThese motivations are allegedly for the sake of better information and democ-\nracy. In regard to the economic and sociological landscape of journalism and the\ninherent issues of such practices, one can doubt that these motivations are the\nonly ones. More importantly, these strategies raise a lot of concerns: methodolog-\nically (lack of consensus among fact-checkers), consequentially (limited positive\nimpact), ethically (self-grated authority and symbolic violence), deontologically\n(con\rict of interest and double standard), and ontologically (naive realism). These\n\fndings undermine the Manichaean picture of savior fact-checkers \fghting against\nvile fake news producers and give a sharper understanding of the war against\nfake news led by the media.\n1 Introduction\nFake news was named `World of the Year' in 2017 by Collins Dictionary1. Even though\nthis epistemic phenomenon is all but new (Burkhardt, 2017), its current form still\nhas raised concern among policy makers, academics, journalists, and human rights\nactivists in a noticeable way. In recent years, the more prominent examples of fake\nnews waves are to be found in the Brexit campaign (Rawlinson, 2020), the 2016 US\nelections (Allcott and Gentzkow, 2017), and the Covid crisis (Rocha et al., 2021).\nThe lack of quality control of the content and the viral properties of fake news can\nlead to epistemic and democratic issues: echo chambers, \flter bubbles, radicalization,\n1https://www.politico.eu/article/collins-dictionary-picks-fake-news-as-word-of-the-year/, retrieved on\n15/03/2023.\n1\ndistrust, hate speech, etc. Facing these threats, academics and other intellectuals,\ngovernments, and mainstream media are joining forces to \fght this peculiar form of\nharmful disinformation. These \fght-back strategies may take various forms: ban laws,\nfact-checking initiatives, media literacy educational programs, the quality rating of\nmedia outlets, (self)regulation of media, etc.\nSuch a narrative polarizes the public debate between vile fake news producers and\nsavior fact-checkers. In this article, I will argue that this Manichaean and dualistic\npicture of the war against fake news is merely a chimera and does not hold. To that\nend, I will \frst recall the socioeconomic background surrounding media today. I will\nthen successively analyze two of the proposed \fght strategies against fake news: the\nquality rating of media outlets and fact-checking. I will brie\ry describe what they\nconsist of and show how these practices raise methodological, ethical, deontological,\nand ontological issues. These \fndings will undermine the Manichaean picture of savior\nfact-checkers \fghting against vile fake news producers, and give a sharper understand-\ning of the war against fake news led by the media. I will now depict the sociological\nlandscape in which quality rating and fact-checking take place.\n2 The background\nTraditional journalism has been facing a severe crisis for several years now. This cri-\nsis is complex and stems from several changes in our society. A salient manifestation\nof this crisis consists in the drastic drop in the number of readers, and, as a conse-\nquence, a sales drop of printed media outlets. According to the French Ministery of\nCulture (Minist\u0012 ere de la culture, 2020), 12 million printed issues were sold daily in\nFrance in 1965. This number has constantly declined to barely 5.4 million in 2020. As\na consequence of this decline, journals receive less and less money from advertisers.\nHistorically, advertisements played an important role in the \fnancial health of news-\npapers. For instance, advertisements represented 60% of the revenues of the French\nnewspaper Le Monde in 1970, whereas it only represented 20% in 2010 (Poulet, 2009).\nMoreover, the sales price is not su\u000ecient to cover the production cost of the newspa-\npers. More and more media outlets are struggling to make ends meet. In France, 105\njournals were available on the market, whereas there are only 60 in 2020 (Minist\u0012 ere de\nla culture, 2020). In response, European countries like France and Italy give millions\nof euros of state aid each year to media outlets to save them.\nThese \fnancial troubles do not only stem from the lack of readers. Other reasons\nplay a role: the development and accessibility of alternative media formats (such as\ntelevision and the Internet), the progressive scarcity of press shops, the ecological\nincentive to digitization, the rise of fabrication cost, the rise of free journals and free\ncontent, and the decline of classi\fed ads which constituted an important source of\nrevenue (Poulet, 2009).\nThis decline in readers can also be explained by the progressive public distrust\nthat journalism is facing. We will make the reasons explicit later in the text. Fighting\nagainst fake news has been considered by some media and journalist organizations as\nnot only a way to regain trust from the audience (by debunking fake news and/or\nproviding better and more transparent content) but also as a way to face digitization\n2\nand generate more revenue. I want to make clear that I will not argue that journalists'\nwar against fake news is a purely pecuniary strategy without a democratic ideal. But I\nwill not deny either that to counteract the deep economic troubles faced by the press,\nnew strategies are needed to gain more readers and advertisers.\nIn the two following sections, I will address two strategies implemented by jour-\nnalists and media stakeholders. The \frst one consists in rating the quality of news\nwebsites and the second one consists in fact-checking other media's articles. The \frst\none is more global and aims to give the reader a general overview of the quality of the\nmedia, whereas the second one is more \fne-grained and debunks speci\fc articles in\ndetail. I will examine the motivations, the methodology, and the impact on trust and\ndemocracy of these two strategies.\n3 Quality rating\nFacing the plethora and the diversity of media outlets, a reader can easily be lost\nin which media to trust or not. Some initiatives have been launched to guide read-\ners across the variety of media outlets by giving them a quality score. For instance,\nNewsGuard was launched in 2018 to give `an online safety for readers, brands, and\ndemocracies'2. More concretely, NewsGard consists in an add-on that one can install\nin a web browser. Each news website is given a 0{100 score based on the assessment\nof nine quality criteria with a detailed `Nutrition Label'. These criteria are explicitly\nmentioned on their website. Among them, one can \fnd: the website's habit of pub-\nlishing false content, the regularity of error corrections, the reliability of the website's\nsources, the explicit di\u000berentiation between news and opinions, the presence of disclo-\nsure of con\ricts of interest, and the display of the name of the content creator. In the\nsame vein, one can mention Media Bias/Fact Check (MBFC ), an American website\nfounded in 2015. As mentioned on their website, `the mission of MBFC is to educate\nthe public on media bias and deceptive news practices'3. In order to do so, they rate\nnews websites according to two aspects: their political bias and their factual accu-\nracy. By using a 0{10 scale, MBFC gives each news website a position in the political\nspectrum (from the extremes to the center). In addition, they investigate the factual\nreporting of such websites and their commitment to trustworthiness. MBFC praises\ncommitment to non-partisanship, transparency of sources and funding, and a rigorous\nmethodology. A third organization, Transparency Map , checks media outlets and as-\nsesses their transparency according to eight criteria: mention of the sources, attached\nsupport, updates of the situation, etc. They aim to `promote transparency in news\ngathering and reporting'4.\nIn these three examples, we see that the assessment criteria and their respective\nweights in the \fnal score di\u000ber. However, according to Lin et al. (2022) who com-\npared the score given by six quality assessment websites (including NewsGuard and\nMBFC ), it seems that there is `a substantial agreement' in the \fnal score given by\nthese websites. As the authors admit, these results have to be nuanced because not all\nthe evaluators assess the same websites, and some of them (like NewsGuard ) regularly\n2https://www.newsguardtech.com/, retrieved on 15/03/2023.\n3https://mediabiasfactcheck.com/about/, retrieved on 15/03/2023.\n4https://www.transparentjournalism.org/reader/, retrieved on 15/03/2023.\n3\nupdate their evaluations. Furthermore, low-quality content websites are not often an-\nalyzed even if they sometimes reproduce good content coming from other high-quality\ncontent websites. However, NewsGuard gives a good label to journals like the New\nYork Times even though it published multiple fake news articles to support the US\ninvasion of Iraq in 2003 (Sussman, 2020).\nReducing the complexity of a media outlet to a 0{100 score seems to me slightly\narti\fcial and simplistic. I understand the desire of the evaluators to give a stable scale\nto compare media outlets, but I doubt that it will develop the reader's critical mind\nas they pretend. Media literacy is not only about receiving passive knowledge about\nwhich media to trust or not but also about acquiring the tools to assess the quality of a\nmedium by oneself. The explanative text behind each score is scarce and oversimpli\fes\nthe complexity of a media outlet's editorial board politics. I also doubt that making\ncitizens pay $4.95 a month of subscription fees (for NewsGuard ) will bring media\nliteracy equally to each class of the population. Indeed, some studies show that, among\nother factors, income and education level are correlated to the capacity to debunk fake\nnews (Wang, 2020; Arin et al., 2021; Pop and Ene, 2019). Those who might need it\nthe most will not bene\ft from it. Lastly, concerning the e\u000eciency of such a strategy\nagainst fake news, Aslett et al. (2022) ran a large-scale study to assess the impact\nof media quality labels on the readers. They found that these labels have a limited\naverage e\u000bect on the individual's news diet quality and fail to reduce misconceptions.\nAnother organization chose a more positive way to assess media quality. In 2018,\nReporters Without Border launched the Journalist Trust Initiative (JTI) project. This\nEU-funded project consists in a self-regulatory initiative designed to combat disin-\nformation online (Boulay, 2018). To do so, they want to settle a white list of media\noutlets compliant with some ethical norms of journalism and independence: system-\natic editorial process to ensure the accuracy of content, sourced statistics, location\nreporting, identi\fed authors, ethical treatment of violent or explicit content, diver-\nsity and training of editorial sta\u000b etc.5Each reliable media outlet will then receive a\nquality label. The scope of JTI is plural. First, the JTI label can be an incentive for\nother media to improve their internal process and be explicit about the methods they\nuse. Second, this label will help `consumers, advertisers, distributors, and regulators\nto identify and reward trustworthy journalism'6. Advertisers will then have a guide to\nbetter select trustworthy media and avoid those that might give them a bad reputa-\ntion. Of course, this implies a gain of advertisement revenues for media compliant with\nJTI guidelines. JTI is transparent about the situation that journalism is undergoing.\nAs claimed in the introductory video on their website: `Journalism today su\u000bers from\na loss of trust and revenue, from a loss of attention and respect. Its future is at stake.\n[...] Transparency is the only way to restore trust'.\nSome journalists and activists opposed initiatives such as JTI. According to them,\nthis label \fxes its own standard about how good journalism should be conducted,\nregardless of other journalistic practices that might be equally legitimate. One of\nthe aims of the JTI label is indeed to serve as a form of soft auto-regulation of\njournalism to anticipate stronger state regulation. For instance, in France, this quality\n5https://www.jti-app.com/report/Xlq9zOj1NoebQ1Pp, retrieved on 22/11/2023.\n6https://www.journalismtrustinitiative.org/about, retrieved on 15/03/2023.\n4\nlabel has been incorporated in the process used for public fund allocation in journalism\n(Sedel et al., 2021), which raises concerns about the \fnancial future of media outlets\nnotJTI-compliant but proposing another (legitimate) way of practicing journalism.\nHowever, this anticipation has its limits. Countries like France and Germany have\nalready implemented regulations for punishing fake news producers. As for laws against\nnegationism, these regulations raise some issues related to the freedom of speech.\nIn my perspective, it is worth noticing that the position of JTI is not neutral and\nneeds to be understood in a sociological \feld inhabiting symbolic power exchanges\n(Sedel et al., 2021; Bourdieu, 1977). Indeed, the \feld of journalism can be seen as\na market of symbolic goods. These symbolic goods are reputation, prestige, respect,\nrecognition, trustworthiness, etc. JTI is a self-designed actor entitled to award such\nsymbolic goods to media outlets. When JTI o\u000bers a trust label to a journal, it not\nonly certi\fes that this journal is compliant with some guidelines, but it also legitimizes\nthis journal in the \feld of journalism by giving it some symbolic goods (and, by doing\nso, enhancing its symbolic capital). Journals not compliant with JTI guidelines will\nbe symbolically marginalized. This marginalization can lead to what Bourdieu (1987)\ncalled symbolic violence: an implicit acceptation of a symbolic hierarchy by those who\nundergo it. The latter is arbitrarily imposed on them and will be tacitly reproduced by\nthem because this norm is considered unquestionable. In light of this interpretation, I\nhave di\u000eculties seeing how JTI can create a more respectful, plural, egalitarian, and\ndemocratic mediatic ecosystem.\n4 Fact-checking\nIn this article, I will consider news fact-checking as the activity of verifying the truth-\nfulness of published pieces of news. News fact-checking can be done by a journal (for\ninstance, Les D\u0013 ecodeurs of the French newspaper Le Monde ,Reality Check of the\nBBC ,Reality Check ofThe Guardian and Fact Checker of the Washington Post ) or\nby an organization (for instance, Factcheck.org which is run by the The Annenberg\nPublic Policy Center at the University of Pennsylvania). Other fact-checkers focus in-\nstead on politicians' statements such as PolitiFact launched by the Tampa Bay Times\nto evaluate Obama's claim during his 2008 campaign (Amazeen, 2015). The latter\nassessment process is called political fact-checking. The frontier between news fact-\nchecking and political fact-checking is sometimes narrow, especially when politicians\ncite journal articles to strengthen their points. Fact-checking can be seen as a more\nprecise strategy to \fght fake news than quality rating. There are nowadays hundreds\nof fact-checking agencies. Some of them joined the International Fact-Checking Net-\nwork (IFCN ). Launched by Poynter in 2015, this association aims at harmonizing\nfact-checking agencies by the settlement of a code of ethics. Mutatis muntandis , it is\nthe equivalent of the JTI for fact-checkers.\nIn my perspective, the main issue is the epistemic premises that fact-checking\nsupposes. Believing a claim is not only in\ruenced by the credibility or trustworthiness\nof the piece of information but also by the epistemic and social ecosystem surrounding\nthe reader (Alloing and Vanderbiest, 2018; Margolin et al., 2018): their political views,\nthe availability of other sources of information, their social class, etc. Namely, the\n5\nepistemic proximity with the source, the preexistent beliefs, the psychological bias\n(con\frmation bias, rebuttal strategies, etc.) and political a\u000eliations often overpass the\nappeal to credibility or coherence. Correcting a false belief is a complex process that\ncan not always be solved by displaying the correct piece of information to the reader.\nAs an example, political a\u000eliation seems to play an important role in belief updating.\nDemocrats and Republicans will react di\u000berently to fact-checking (Walter et al., 2020).\nDemocrats are not only those who are more prone to correcting their beliefs (Walter\net al., 2020), but are as well those who are more prone to consuming fact-checking\nwebsites (Robertson et al., 2020). As we will see later in this section, fact-checkers\ndemonstrate a more negative attitude toward conservative media outlets (Bozarth and\nBudak, 2020). Thus, it is not surprising that fact-checking websites please more to a\nDemocrat audience than to a Republican one.\nThese epistemic misconceptions explain the mitigated e\u000ecacy of fact-checking in\ncorrecting false beliefs. Some literature reviews analyzed articles treating the impact\nof fact-checking. According to Nieminen and Rapeli (2019), some studies `\fnd that\nfact-checking reduces misperceptions, others that corrections are often ine\u000bective'.\nMoreover, these studies highly focus on US media and its audience. In their meta-\nanalysis, Walter et al. (2020) point out the limited impact of fact-checking: `Though\nfact-checking can be used to strengthen preexisting convictions, its credentials as a\nmethod to correct misinformation (i.e., counter-attitudinal fact-checking) are signi\f-\ncantly limited'. This can be explained partially by the fact that individuals are more\nprone to adopting pro-attitudinal correction instead of correcting their beliefs in a way\nthat can contradict their prior political views. This e\u000bect is even more stringent dur-\ning electoral campaigns when citizens are even more overwhelmed by fake news than\nusual. However, another meta-analysis based on a di\u000berent set of articles (Chan et al.,\n2017) points out the strong e\u000bect of misinformation correction. The former authors\n(Walter et al., 2020) explain this discrepancy by the fact that they focus exclusively\non political misinformation. This type of misinformation includes more resistance and\npartisanship than other types of misinformation (e.g., about health or marketing) con-\nsidered in Chan et al.'s article. That is a possible explanation for why Walter et al's\nmeta-analysis points toward a more limited impact of fact-checking than Chan et al.\nFacing such a lack of statu quo in the literature regarding fact-checking e\u000eciency, it\nseems to me hard to justify not only the fact-checking relevance for correcting read-\ners' false beliefs caused by fake news consumption but also the amount of money and\ne\u000bort put into it if it were only for educational purposes. Indeed, as we have seen,\nfact-checkers can not correct political misinformation e\u000eciently in the context of an\nelectoral campaign, which is originally one of their main goals. As mentioned in Section\n2, there is far more at stake for journalists in this \fght against fake news: regain of\ntrust, respectability, esteem, readers, advertisers, and \fnancial health.\nIn addition to its approximate e\u000ecacy, fact-checking undergoes some methodolog-\nical issues caused by implicit biases. As Uscinski and Butler (2013) note, fact-checkers\nonly analyze the information they deem relevant to check. It includes focusing on spe-\nci\fc topics, countries, politicians, or media. This bias is inherent to fact-checking given\nthat a comprehensive check of the thousands of news articles published each day is\nvirtually impossible. Actually, this pragmatic discrimination undermines the so-called\n6\nobjectivity of fact-checkers and makes salient some of their biases. Indeed, Marietta\net al. (2015) point out that the three fact-checkers they analyzed ( FactCheck.com ,\nPolitiFact and The Washington Post ) do not consider each of the three considered\nsubjects in this study (racism, climate change, and public debt) as equally important\n(in term of coverage). But a stronger bias is also at stake. For instance, statements\nclaiming the reality of climate change were not checked. Only those against the re-\nality of climate change were. However, one can not deny that some positive articles\nabout climate change could turn out to be fake news (for instance, an article arti-\n\fcially in\rating the value of temperature increase in the coming decades to stress\nout the catastrophic impact of climate change). Fact-checkers in this study consider\nnot only climate change as real prima facie , but also never consider positive news\nabout climate change as questionable. Even if obvious claims such as the `the Earth\nis round' and `2+2=4' are virtually uncontested, there are still correct ways and in-\ncorrect ways to justify them. And fact-checkers should be concerned about it. In my\nview, spreading exaggerated news (and, hence, fake news) about the impact of cli-\nmate change will not improve trust. Even if climate change acceptance or denial does\nnot only rely on sole epistemic arguments but also on prior political views, these ex-\naggerated news could even be counterproductive and could undermine any genuine\nand honest dialogue. In contrast with climate change, fact-checkers diverge on other\ntopics. For instance, on the consequences of the growth of public debt, Politifact only\nchecked articles claiming a negative e\u000bect of the public debt, whereas the two other\nfact-checkers addressed the positive and negative statements the same way. Stated\ndi\u000berently, Marietta et al. points out that even when fact-checkers consider the same\ntopic, they evaluate positive and negative articles in a di\u000berent way. These results indi-\ncate that fact-checkers assume a set of unquestionable realities and are more reluctant\nto fact-check information con\frming their prior beliefs. This exhibits a lack of objec-\ntivity when approaching some topics. Bozarth and Budak (2020) con\frm the existence\nof some biases of fact-checkers: the latter demonstrates a more unfavorable attitude\nagainst small and conservative-leaning credible news sites. Articles from these sources\nwere more often labeled incorrectly as fake news than those from more liberal sources.\nAnother methodological problem lies in the lack of consistency between di\u000berent\nfact-checking organizations. If fact-checking is an objective and rigorous practice, we\nwould expect the conclusion concerning an article to be the same regardless of the fact-\nchecker. Lim (2018) compared the outcomes of two fact-checkers: Politifact and Fact\nChecker . The \frst issue pertains to the fact that both fact-checkers only share 10%\nof their analyzed statements in common. Furthermore, these statements were rarely\nexactly the same, which makes a comprehensive study di\u000ecult. Although fact-checkers\nalways agree on extreme news (i.e., obvious truth or obvious hoax), their conclusions\ndiverge on milder pieces of news (i.e., statements more subject to interpretation or\nambiguity). What is the usefulness of fact-checking then? Evident truths or lies are\neasily debunkable and can be done with a few clicks on the internet by any layperson.\nIt is especially when things get more complex or blurry, that the help of fact-checkers\nis potentially really useful. However the latter do not agree on the outcomes, which\nmakes fact-checking an illusory objective and universal practice. I do not mean that\nfact-checkers are not rigorous, I just mean that a lot of statements in the description\n7\nof realities are not black or white and an unequivocal and unproblematic description is\nan almost impossible task. As mentioned in the last paragraph, even trivial scienti\fc\ntruths can be justi\fed by ambiguous explanations. Of course, this equivocity is even\nmore salient when talking about political and social matters. For instance, consider\na news article that claims that `the burglaries increased in the neighborhood by 20%\nafter the migrants came into the city' (Bernecker, 2021, p. 289). If we assume that the\nstatistic is really correct (i.e., that the police monitored 20% more burglaries and the\nrise of foreigners is proven by the population registry), what is the status of such a\npiece of information? Of course, the way it is framed might suggest that the migrants\nare responsible for burglaries, which might not be true. Is that fake news fabricated for\npolitical aims? Or a simple conservative editorial bias? Or an objective { yet ambiguous\n{ statement pointing to a correlation and not causation between two events? There is\nleeway for interpretation and I doubt that, even with the most sincere commitment\nto rigor and objectivity, all fact-checkers will consider it the same way.\nThis commitment to rigor and objectivity seems also jeopardized by the con\ricts\nof interest and double standards practiced by some fact-checkers. Indeed, many media\nboth produce their own news and have their own team of fact-checkers ( Le Monde ,\nThe Washington Post ,The Guardian , etc). So they are both the judge and the jury.\nOne could have hoped for a more objective and independent position for fact-checkers.\nIronically, some of these media outlets produced fake news in the past. One can re-\nmember the statements of Julian Assange published by The Guardian which turned\nout to be a pure creation of the author (Greenwald, 2016), and the recurrent mis-\ninformation about the Russian government by The Washington Post (which is also\nthe recipient of the Pulitzer Prize and listed as trustworthy by IFCN ) (Greenwald,\n2017). My point is not to determine if there was a clear intent to deceive from these\ntwo journals or if they are just unintended errors (but I doubt this) or editorial bias.\nMerely, I want to point out that, for some fact-checking journals, the idiom `it's the\npot calling the kettle black' seems a good description of the double standard of some\nfact-checkers. I do not mean that there is no self-quality control assessment in these\nmedia outlets. Some newspapers have implemented peer-reviewing by other colleagues\nbefore publication and have internal procedures to correct or retract erroneous articles\n(e.g. after some reader complains to an ombud).\nLastly, the practices of fact-checking and quality rating of media outlets have an\nissue in common. Like the JTI, the IFCN is a self-granted agent determining what\ngood fact-checking practice is and what it is not. Note that IFCN included Politifact\nin their white list. One can question the con\rict of interest in this choice given that\nPolitifact is funded by the Tampa Bay Times , which is itself a branch of Poynter . One\ncan also question the neutrality of IFNC when it is awarded a 13.2 million dollars grant\nfrom Google7and when it allies with Facebook to \fght the spread of Covid-related\nfake news8. In addition to what precedes, these practices raise even more questions\nabout the neutrality and independence of fact-checker organizations.\n7https://blog.google/outreach-initiatives/google-news-initiative/how-google-and-youtube-are-investing-in-fact-checking/,\nretrieved on 15/03/2023.\n8https://www.facebook.com/journalismproject/coronavirus-grants-fact-checking, retrieved on\n15/03/2023.\n8\n5 Discussion and conclusion\nIn the preceding discussion, I analyzed two strategies involved in the war against fake\nnews: the quality rating of media outlets and fact-checking. For each of them, I pointed\nout the motivations of the stakeholders to undertake such a time and money-consuming\nenterprise. These motivations are allegedly for the sake of better information and\ndemocracy. In regard to the economic and sociological landscape of journalism and\nthe inherent issues of such practices, one can doubt that these motivations are the\nonly ones. To stress this point, I showed that there was no consensus in the litera-\nture about the e\u000eciency of both quality rating and fact-checking. More importantly,\nthese strategies raise a lot of issues and concerns: methodological (lack of consensus\namong fact-checkers), ethical (self-granted authority and symbolic violence), deon-\ntological (con\ricts of interest, double standards), and ontological (presupposition of\nsome elements of reality, naive realism).\nIn light of my conclusions, one can question if such \fghts against fake news are\nthe best way to regain trust in the media and improve democracy. It is important\nto remember that the lack of trust in the media is correlated not only to the rise\nof the Internet but also to the change classic journalism has been undergoing for\n\ffty years. Until the 1970s, many popular media were highly partisan and targeted\nvery speci\fc audiences. In 1974, the Watergate scandal made the headlines thanks\nto the restless work of two journalists of The Washington Post . This case study was\nprogressively considered as the new standard for good journalism and investigative\njournalism became, for many, the new trend (Poulet, 2009). As a result, many journals\nin the US and Europe left their partisan identity to endorse a more objective and\nneutral way of doing journalism. By an irony of fate, it is at this precise moment that\nthe press started disconnecting from the readers and lost many of them. One of the\nreasons lies in the fact that most of the traditional media while praising objectivity\nand denying any partisanship, took political positions in major recent elections. For\ninstance, in Europe, traditional media outlets such as Le Monde orThe Guardian\nwere more positive toward the adoption of the Maastricht treatise during the 2005\nFrench referendum, toward Hilary Clinton during the 2016 presidential US elections,\nand toward the maintenance of the UK in the EU during the Brexit referendum. The\noutcomes of these elections have been against all odds. Some journalists saw these\nresults not only as a democratic failure but also as a failure of journalists who did not\nachieve to gain the trust of the readers (Michel, 2017; Le\flli^ atre, 2016; Lordon, 2016;\nPoulet, 2009).\nThe case of journalism is just an example of more global distrust from the citizens\ntowards institutions in general. Ambiguous relations of media with politics and econ-\nomy (for instance, the billionaire Je\u000b Bezos owns The Washington Post ) put journals\nin a di\u000ecult position in terms of trust. In particular, the collaborations of media rat-\ning and fact-checking organizations with Facebook, Google, or governments do not\nimprove trust. This distrust is exacerbated each time one of these organizations claims\nthe monopoly of objectivity and implicitly patronizes the reader about news to trust\nor not. This form of symbolic power is exactly one of the main reasons for the ongoing\ndistrust. Using it again in the war against fake news will just not work or might even\nbe counterproductive.\n9\nMaybe a better alternative in the \fght against fake news is to accept the complexity\nof the social reality and the illusive commitment to neutrality. I do not expect journals\nto be impartial, but I expect the press to be. Like in history, it is by comparing the\nnarratives of di\u000berent media that one can have a more lucid description of an event.\nDiversifying one's media diet seems to me a valid autonomous and e\u000ecient way of\nreaching a simulacrum of objectivity (if any). Of course, it is asking citizens a lot\nto daily consume many di\u000berent kinds of news. It is more probable that the most\nprivileged of them could really achieve it. In addition, such an aggregation of sources\nwill lead to a more reliable version of the news only if the diversity of perspectives is\nguaranteed. This plurality could be jeopardized if the press is ruled by governments or\nby a small group of shareholders. Accepting the plurality of the journals, their di\u000berent\nperspectives, and refusing arbitrary epistemic authority seem to me in line with the\ndemocratic idea of public debate. And does not this show that inter-rater variability\nof fact-checking is a sign of a healthy ecosystem?\nMaybe fake news is an urgent threat to our democracy and must be fought (Jaster\nand Lanius, 2021). Or maybe fake news is not a problem at all and the war against it\nproduces more harm than good (Coady, 2021). Or maybe fake news is just not a real\nepistemic phenomenon and we should stop using this term (Habgood-Coote, 2019). In\nthis article, I did not take a position in this triad. In my opinion, neither fake news nor\na \fght against it is problematic per se . The problem is to polarize the public debate\nbetween vile fake news producers and savior fact-checkers. In light of the previous\ndiscussion, this Manichaeism is merely a chimera and does not hold. Fact-checkers and\nmedia quality assessors are not only driven by democratic purposes but also by the\nwillingness to regain trust and \fnancial stability. Furthermore, the ethos of these two\npractices demonstrate the use of symbolic power, methodological weaknesses, con\ricts\nof interest, double standards, and disputable ontological simpli\fcations. For these\nreasons, I assert that defending such an ingenious binary vision of the war against\nfake news is equivalent to extracting two epistemic phenomena (fake news and the war\nagainst them) out of their intelligible environment. Fake news start being considered\nas a problem nowadays because some social conditions are met (e.g., public distrust\nand \fnancial troubles of the media). Paradoxically enough, in echos with the Hegelian\nmaster-slave dialectics, the media involved in this \fght became somehow dependent on\nfake news (and the war against them) for their \fnancial future and for reestablishing\ntheir epistemic authority in a climate of global distrust.\nAcknowledgement\nPart of this work was supported by the Research Foundation Flanders (Fonds Weten-\nschappelijk Onderzoek, FWO), Grant No. G0B8616N. The author thanks Sylvia\nWenmackers for her insightful review of this article's daft.\nReferences\nAllcott, H. and M. Gentzkow. 2017. Social media and fake news in the 2016 election.\nJournal of economic perspectives 31 (2): 211{236 .\n10\nAlloing, C. and N. Vanderbiest. 2018. La fabrique des rumeurs num\u0013 eriques. comment\nla fausse information circule sur twitter? Le Temps des m\u0013 edias (1): 105{123 .\nAmazeen, M.A. 2015. Revisiting the epistemology of fact-checking. Critical\nReview 27 (1): 1{22 .\nArin, K.P., J.A. Lacomba, F. Lagos, D. Mazrekaj, and M.P. Thum. 2021. Misper-\nceptions and fake news during the Covid-19 pandemic. CESifo Working Paper\n.\nAslett, K., A.M. Guess, R. Bonneau, J. Nagler, and J.A. Tucker. 2022. News cred-\nibility labels have limited average e\u000bects on news diet quality and fail to reduce\nmisperceptions. Science advances 8 (18): eabl3844 .\nBernecker, S. 2021. An epistemic defense of news abstinence. The Epistemology of\nFake News : 286{309 .\nBoulay, E. 2018, Apr. RSF and its partners unveil the Journalism Trust Initiative to\ncombat disinformation.\nBourdieu, P. 1977. La production de la croyance. Actes de la recherche en sciences\nsociales 13 (1): 3{43 .\nBourdieu, P. 1987. Distinction: A social critique of the judgement of taste . Harvard\nUniversity Press.\nBozarth, L. and C. Budak 2020. Toward a better performance evaluation framework\nfor fake news classi\fcation. In Proceedings of the international AAAI conference on\nweb and social media , Volume 14, pp. 60{71.\nBurkhardt, J.M. 2017. History of fake news. Library Technology Reports 53 (8): 5{9 .\nChan, M.p.S., C.R. Jones, K. Hall Jamieson, and D. Albarrac\u0013 \u0010n. 2017. Debunking: A\nmeta-analysis of the psychological e\u000ecacy of messages countering misinformation.\nPsychological science 28 (11): 1531{1546 .\nCoady, D. 2021. The fake news about fake news. The epistemology of fake news : 68{81\n.\nGreenwald, G. 2016, Dec. The guardian's summary of julian assange's interview went\nviral and was completely false.\nGreenwald, G. 2017, Jan. Washpost is richly rewarded for false news about russia\nthreat while public is deceived.\nHabgood-Coote, J. 2019. Stop talking about fake news! Inquiry 62 (9-10): 1033{1065 .\n11\nJaster, R. and D. Lanius. 2021. Speaking of fake news. The epistemology of fake\nnews 19 .\nLe\flli^ atre, J. 2016, Nov. En France, les m\u0013 edias promettent de \\r\u0013 eduire la distance\navec les lecteurs\".\nLim, C. 2018. Checking how fact-checkers check. Research & Politics 5 (3):\n2053168018786848 .\nLin, H., J. Lasser, S. Lewandowsky, R. Cole, A. Gully, D. Rand, and G. Penny-\ncook. 2022. High level of agreement across di\u000berent news domain quality ratings.\nPsyArXiv .\nLordon, F. 2016, Nov. Politique post-v\u0013 erit\u0013 e ou journalisme post-politique?\nMargolin, D.B., A. Hannak, and I. Weber. 2018. Political fact-checking on Twitter:\nWhen do corrections have an e\u000bect? Political Communication 35 (2): 196{219 .\nMarietta, M., D.C. Barker, and T. Bowser. 2015. Fact-checking polarized politics:\nDoes the fact-check industry provide consistent guidance on disputed realities? The\nForum 13 (4): 577{596 .\nMichel, P. 2017, Feb. Post-v\u0013 erit\u0013 e et fake news : fausses clart\u0013 es et points aveugles.\nMinist\u0012 ere de la culture. 2020. Le tirage de quotidiens de 1945 \u0012 a 2020.\nNieminen, S. and L. Rapeli. 2019. Fighting misperceptions and doubting journalists'\nobjectivity: A review of fact-checking literature. Political Studies Review 17 (3):\n296{309 .\nPop, M.I. and I. Ene 2019. In\ruence of the educational level on the spreading of fake\nnews regarding the energy \feld in the online environment. In Proceedings of the\nInternational Conference on Business Excellence , Volume 13, pp. 1108{1117.\nPoulet, B. 2009. La \fn des journaux et l'avenir de l'information . Editions Gallimard.\nRawlinson, F. 2020. How Press Propaganda Paved the Way to Brexit . Springer Nature.\nRobertson, C.T., R.R. Mour~ ao, and E. Thorson. 2020. Who uses fact-checking\nsites? the impact of demographics, political antecedents, and media use on fact-\nchecking site awareness, attitudes, and behavior. The International Journal of\nPress/Politics 25 (2): 217{237 .\nRocha, Y.M., G.A. de Moura, G.A. Desid\u0013 erio, C.H. de Oliveira, F.D. Louren\u0018 co, and\nL.D. de Figueiredo Nicolete. 2021. The impact of fake news on social media and its\nin\ruence on health during the covid-19 pandemic: A systematic review. Journal of\nPublic Health : 1{10 .\n12\nSedel, J., A. Ouakrat, J. Pacouret, and C. No^ us. 2021. Pr\u0013 esentation du dossier. un jour-\nnalisme de \u001cqualit\u0013 e \u001d? Hi\u0013 erarchisations et classements des actualit\u0013 es. Politiques\nde communication 16 (1): 5{12. https://doi.org/10.3917/pdc.016.0005 .\nSussman, G. 2020. Making enemies: the mainstream media spectacle and US foreign\npolicy. Perspectives on Global Development and Technology 19 (1-2): 138{156 .\nUscinski, J.E. and R.W. Butler. 2013. The epistemology of fact checking. Critical\nReview 25 (2): 162{180. https://doi.org/10.1080/08913811.2013.843872 .\nWalter, N., J. Cohen, R.L. Holbert, and Y. Morag. 2020. Fact-checking: A meta-\nanalysis of what works and for whom. Political Communication 37 (3): 350{375\n.\nWang, T.L. 2020. Does fake news matter to election outcomes? The case study of\nTaiwan's 2018 local elections. Asian Journal for Public Opinion Research 8 (2):\n67{104 .\n13", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "War Against Fake News: Avoiding Manicheism", "author": ["S Ferrari"], "pub_year": "2024", "venue": "SAS 2022 Conference Proceeding", "abstract": "In this article, I will analyze two strategies involved in the war against fake news: the quality  rating of media outlets and fact-checking. For each of them, I will point out the motivations of"}, "filled": false, "gsrank": 43, "pub_url": "https://lirias.kuleuven.be/retrieve/798377", "author_id": ["ZKE8E4wAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ZLiwlbnOhIIJ:scholar.google.com/&output=cite&scirp=42&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D40%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZLiwlbnOhIIJ&ei=C7WsaMuIJazWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:ZLiwlbnOhIIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://lirias.kuleuven.be/retrieve/798377"}}, {"title": "Best practices for source-based research on misinformation and news trustworthiness", "year": "2024", "pdf_data": "Best practices for source-based research on misinformation and\nnews trustworthiness\nLUEHRING, JULA\nUniversity of Vienna & Complexity Science Hub Vienna, Austria\nMETZLER, HANNAH\nMedical University of Vienna, Austria, Complexity Science Hub Vienna, Austria &\nInstitute for Globally Distributed Open Research and Education\nLAZZARONI, RUGGERO MARINO\nRWTH Aachen, Germany\nSHETTY, APEKSHA\nComplexity Science Hub Vienna, Austria & University of Vienna\nLASSER, JANA\nUniversity of Graz & Complexity Science Hub Vienna, Austria\nResearchers need reliable and valid tools to identify cases of untrustworthy\ninformation when studying the spread of misinformation on digital platforms.\nA common approach is to assess the trustworthiness of sources rather than\nindividual pieces of content. One of the most widely used and comprehensive\ndatabases for source trustworthiness ratings is provided by NewsGuard. Since\ncreating the database in 2019, NewsGuard has continually added new sources\nand reassessed existing ones. While NewsGuard initially focused only on the\nUS, the database has expanded to include sources from other countries, such\nCorresponding author: jula.luehring@univie.ac.at\nDate submitted: 2024-09-19\n1\nLuehring et al.\nas Germany and Italy. In addition to trustworthiness ratings, the NewsGuard\ndatabase contains various contextual assessments of the sources, which are\nless often used in contemporary research on misinformation. In this work, we\nprovide an analysis of the content of the NewsGuard database, focusing on the\ntemporalstabilityandcompletenessofitsratingsacrosscountries,aswellasthe\nusefulness of information on political orientation and topics for misinformation\nstudies. We find that the trustworthiness ratings are temporally stable and\nthat coverage seems complete for the US and Germany. Information on the\npolitical orientation and topic labels of sources are relatively complete and\ncan be valuable assets in characterizing sources beyond trustworthiness. By\nevaluating the database over time and across countries, we identify potential\npitfalls that threaten the validity of using NewsGuard as a tool for quantifying\nuntrustworthy information. Lastly, we provide recommendations for digital\nmedia research on how to avoid these pitfalls and discuss appropriate use cases\nfor the NewsGuard database and source-level approaches in general.\nKeywords: misinformation, source trustworthiness, NewsGuard\nMisinformation spreads on both social media platforms (Lazer et al., 2018) and\nmainstream media channels (Tsfati et al., 2020). However, only a fraction of news con-\nsumption is attributed to false news \u2014 roughly 0.15% (Allen et al., 2020) \u2014 and only a\nminority of users actively engage with unreliable information online (Baribi-Bartov et al.,\n2024; Grinberg et al., 2019). Typically, these individuals hold strong political or ideological\nbeliefs and accept and actively look for information that echoes their opinions (Ecker et al.,\n2022) \u2014 information that often comes from political elites or established media sources\n(Tsfati et al., 2020). Misinformation capitalizes on these dynamics to stoke conflict and\nevoke negative emotions, thereby exacerbating partisan divides and fueling inter-group hos-\ntility (Gonz\u00e1lez-Bail\u00f3n et al., 2023; Robertson et al., 2023). Against a backdrop of declining\ntrust in both media outlets (Newman et al., 2023) and institutions (Bennett and Livingston,\n2020), it becomes increasingly crucial to comprehend the mechanisms driving the dissemi-\nBest Practices for Source-Based Misinformation Research 3\nnation of misinformation, particularly in the digital sphere. While digital media facilitates\nthe measurement of these dynamics, it also has the potential to reinforce polarization and\nmisinformation (Lorenz-Spreen et al., 2022).\nScholars across various disciplines have extensively studied the phenomenon of mis-\ninformation, employing terms such as misinformation, disinformation, fake news, rumors, or\nconspiracy theories, often used interchangeably (Guess and Lyons, 2020). Although these\nterms share a focus on veracity, they differ in terms of intentionality. Misinformation is\ncommonly used as an umbrella term for inaccurate or unreliable information, regardless\nof intent, e.g., Ecker et al. (2022) or van der Linden (2022). However, the ambiguous na-\nture of misinformation presents significant methodological challenges, granting researchers\nseveral degrees of freedom. Defining the boundaries of misinformation\u2013\u2013essentially deter-\nmining where the truth ends\u2013\u2013is a complex task for several reasons. First, misinformation\noften appears in subtle forms rather than obvious lies (Allen et al., 2024; Altay et al., 2023;\nBakir and McStay, 2018; Vargo et al., 2018), making it hard to define where it starts. Im-\nplicit, often partisan, interpretations of facts differ from explicit lies, making subtle forms of\nmisinformation hard to detect. Second, identifying misinformation involves ethical consid-\nerations, with different experts reaching different conclusions. To navigate these challenges,\nresearchers often focus on binary (true/false) cases of misinformation, typically identified\nby fact-checkers. While this approach addresses some ethical concerns by clearly classifying\nfalse information, it captures only a small portion of misinformation. Finally, conceptual\nchoices are often shaped by methodological constraints (e.g., available data) or disciplinary\npreferences (e.g., methodological traditions), which is why misinformation is often used as\na general umbrella term for different phenomena (Weeks and Gil de Z\u00fa\u00f1iga, 2021). Con-\nsequently, this semantic and methodological variability has contributed to imprecise or\ninconclusive findings regarding the prevalence and impact of misinformation. While some\nscholars, such as Altay et al. (2023) or Budak et al. (2024), argue that the effects of mis-\ninformation are overstated, calling it a symptom of broader social issues, others, like Tay\net al. (2024), reason that the heterogeneity in measuring misinformation contributes to di-\nvergent evidence and creates a false dichotomy between understanding misinformation as a\nsymptom or a cause (also see Bozarth et al., 2020).\nIn digital media research, one of the most prominent ways to measure misinforma-\nLuehring et al.\ntion has been to use a list of sources that are known to share misinformation frequently.\nNewsGuard has emerged as the most widely used database for source ratings (Celadin et al.,\n2023; Guess et al., 2020; Lasser et al., 2022; Pratelli et al., 2023; Robertson et al., 2023) and\nis especially popular in misinformation research for its comprehensive source-level trustwor-\nthiness scores, which are compiled based on web tracking data and rated and updated by\nprofessional editors and journalists In addition to its comprehensiveness, NewsGuard also\noffersa morefine-grained assessmentof thetrustworthinessofsources basedon adherence to\njournalistic quality criteria and provides a point score ranging from 0 (the source is untrust-\nworthy because it severely violates basic journalistic standards) to 100 (the source adheres\nto all standards of credibility and transparency). Since the start of the database in 2019,\nNewsGuard has constantly added new sources. While initially the focus of NewsGuard was\nthe US, the database has expanded to other countries, such as Germany and France. Given\nthe popularity of the NewsGuard database as a tool to quantify the prevalence of misin-\nformation, an in-depth analysis of the temporal stability of ratings and the completeness\nof the database for different countries is warranted. Furthermore, NewsGuard requires a\nlicense, and researchers in need of a measurement instrument to quantify misinformation\nmust weigh the advantages and disadvantages of source-based methods and the investment\nrequired to access the NewsGuard database. With the present in-depth analysis of the\ndatabase\u2019s content we aim to provide researchers with the necessary information to make\nthis decision. Where warranted, we provide recommendations for effectively utilizing the\nNewsGuard database and source-based approaches alongside our analysis of the content of\nthe database.\nTracking Misinformation on Digital Media\nTo study the diffusion or discussion of misinformation on digital platforms, com-\nputational researchers commonly opt for either content- or source-based methodologies,\nsearching for web links to content (via the URL) or a source (via their web domain). Both\napproaches rely on experts, such as fact-checkers, to curate lists of content or sources, which\nserve as the foundation for collecting data from digital platforms. Source-based strategies,\nwhich are the focus of the present work, offer the advantage of encompassing a broader\nspectrum of sources and narratives, thus enriching the sample by considering a more di-\nverseinformationenvironment. Source-basedapproachesalsoenabletheinclusionofsubtler\nBest Practices for Source-Based Misinformation Research 5\nforms of misinformation and facilitate accurate estimations of both the scale (Allen et al.,\n2020; Grinberg et al., 2019; Guess et al., 2020; Yang et al., 2021) and dynamics of dissemi-\nnation (Lasser et al., 2022, 2023; Pennycook et al., 2021; Robertson et al., 2023; Shao et al.,\n2018).\nThe precision of source-based approaches hinges mainly on the selection and qual-\nity of source ratings within a given list. Strictly speaking, this conceptualization covers\ninformation disseminated by unreliable sources (rather than individual pieces of misinfor-\nmation). Therefore, observed patterns may be intricately linked to the inherent biases or\nexternal forces in the selection of sources. For instance, if we analyzed misinformation in\npoliticians\u2019 social media posts, an unbalanced selection of unreliable sources would most\nlikely reveal patterns due to partisanship rather than patterns universal to misinformation.\nThis underscores the importance of assessing confounding factors such as political biases\nor editorial practices of the sources, considering that a lack of editorial oversight can com-\npromise the quality of news reporting (Lazer et al., 2018). In other words, to obtain a\nbalanced selection of sources and account for the influence of source-related variables other\nthan reliability, source-based approaches can incorporate assessments of political, cultural,\nor editorial biases and misleading tendencies while maintaining generalizability. Nonethe-\nless, several problems remain in practice: First, source categorizations often rely on a binary\nclassification system (fake/real), oversimplifying the nuanced spectrum of misinformation.\nSecond, it is crucial to acknowledge that source ratings vary across time and cultural con-\ntexts, for instance, following a change in ownership or editorial practices. For example,\nLin et al. (2024) combined source-level quality ratings with context-specific keywords, e.g.,\nhashtags linked to an anti-vaccination protest in Ottawa to account for misinformation-\nsharing in different populations. Third, while source judgments are typically made without\nrequiring specific topic expertise, they often reflect the journalistic traditions of a particular\nmediaecosystem, whichmaynotbeuniversallyapplicableacrossdifferentcontexts(Br\u00fcgge-\nmann et al., 2014). Source-based approaches are a promising way to track misinformation\nonline at scale. However, to study the spread of unreliable news, scientists need access to\nreliable and credible databases of source ratings.\nLuehring et al.\nNewsGuard: A Popular Database for Source Ratings\nSince the 2016 US elections, the most popular way to track misinformation online\nhasbeentousealistofuntrustworthyorunreliablesourcesandsearchfortheirwebdomains\nin URL text (Lasser et al., 2022; Grinberg et al., 2019; Guess et al., 2020; Shao et al., 2018;\nYang et al., 2021). The organization NewsGuard offers the most comprehensive list of such\ndomains (Lin et al., 2023). It does not just provide a blacklist of untrustworthy sources\nbut provides a trustworthiness score for each source, covering news sources across the entire\nspectrum of news quality. A trained team of experts, mainly consisting of journalists and\neditors, rates the news sources based on nine journalistic quality criteria1and regularly\nupdates both the coverage of the list by adding new sources and the trustworthiness ratings\nof existing sources. Since its start in 2019, the database has been constantly growing and\nhas recently extended to countries beyond the United States, such as Germany and Italy.\nWith recent political events and crises, demand for such databases has increased, enhancing\nthe popularity of NewsGuard. For instance, it has been used to study user engagement with\nunreliablenewsduringthe2016and2020USelections(Pratellietal.,2023;Robertsonetal.,\n2023), to assess the changing quality of cited information of political elites in the US (Lasser\net al., 2022) or alternative understandings of honesty and truth in political discourse (Lasser\net al., 2023), and to estimate the effects of source labeling on decreasing misinformation\nsharing (Celadin et al., 2023).\nHowever, the NewsGuard database was initially created as a tool for brand security\nrather than scientific research. In addition, employing journalists and editors to assess\nthe sources included in the list incurs significant expenses. Given its predominantly private\naudience and expenses, the NewsGuard database is only available to subscribers who pay to\nlicense the database. Here, we provide a comprehensive assessment of the database to help\nmisinformation researchers weigh the resources required to access the NewsGuard database\nandtheadvantagesandlimitationsofsource-basedapproachesingeneral. Weaimtoanswer\nthe following main research question: How volatile are source-level trustworthiness ratings,\nsuch as those in the NewsGuard database, across time and language contexts? To answer\nour research question, we first assess the distribution of trustworthiness ratings, the process\n1https://www.newsguardtech.com/ratings/rating-process-criteria/\nBest Practices for Source-Based Misinformation Research 7\nof updating them, and the inclusion and removal of sources over time. Second, we assess\nthe completeness of the database for different countries. Lastly, we estimate the usefulness\nof other source-level information provided in the database, such as the political orientation\nand topics covered by sources. To assess different aspects of the database, we introduce\nthree sub-questions:\nHow stable are trustworthiness ratings over time? Investigating the develop-\nment of the NewsGuard database over time is important to estimate whether using an older\nversion of the database distorts results and should be used to measure trustworthiness in\nolder data. We describe the composition of the trustworthiness score and different database\nversions. We also explore the frequency and reasons for major changes, such as how often\nratings change or sources are removed. Additionally, we provide an exemplary reproduction\nof published research using NewsGuard ratings from different points in time to assess the\ndegree to which results vary based on changes in the measurement instrument.\nHow complete is the database across countries, particularly for non-US\ncountries? A recent study has shown high agreement of NewsGuard with other expert-\nrated lists in the US context (Lin et al., 2023), but an assessment for other countries is\nmissing. Therefore, we describe the coverage across and differences between countries. Fur-\nther, we compare the completeness of information provided by NewsGuard across different\ncontexts by cross-checking the NewsGuard database with a dataset of domains shared on\nsocial media for the US, Germany, and UK, and other existing lists of low-quality web\ndomains.\nHow valuable are contextual source labels for misinformation research?\nNewsGuard labels the topics covered as well as the political orientation sources. We analyze\nthe temporal stability and completeness of these labels across countries. Additionally, we\nmanually validate the labels for German-speaking sources. We assess in what way such\nlabels can complement source characterizations and shed light on aspects of misinformation\nbeyond trustworthiness.\nLuehring et al.\nDataset Construction\nNewsGuard curates the list of sources it rates by tracking online activity. On their\nwebsite, NewsGuard claims to have reviewed news sources accounting for 95% of online\nengagement, including news consumed and shared online. The organization also manually\nadds sources they deem influential or that changed their web domain. The database auto-\nmatically updates every hour and allows tracking changes back to March 2019, when the\norganization started operating. Still, how domains are selected or removed is not disclosed\non the website. As of September 15, 2024, the database has 12,288 entries in total, some\nwithout a trustworthiness rating (7.6%). This includes 70 sources classified as a \u201cplatform\u201d\n(e.g., YouTube), 63 sources judged as \u201csatire\u201d (e.g., The Onion) and 806 lifestyle sources\n(e.g., healthquote- free.com). For the remaining 11,349 sources, the database includes the\nfollowing characteristics:\n\u2022Unique identifier for each rating and date of the last update\n\u2022Domain name and parent domain (e.g., nytimes.com)\n\u2022A trustworthiness rating as a quasi-continuous scale (between 0 and 100) and binary\nlabels (N = Not Trustworthy/T = Trustworthy) based on a threshold at 60\n\u2022Language and country associated with the source\n\u2022Political orientation of the source (e.g., \u201cleft\u201d and \u201cright\u201d)\n\u2022Topics covered (e.g., \u201clocal news\u201d, \u201cpolitical news\u201d, \u201chealth information\u201d) by the\nsource\nThe team of NewsGuard experts regularly judges the trustworthiness of the selected\nnews sources based on nine journalistic criteria that are universally applied across countries.\nThe trustworthiness score is a composite score of these nine indicators. More precisely,\nexperts assign a binary label for each criterion. Each criterion has a weight, a number of\npoints, which together make up the overall trustworthiness rating (ranging from 0 to 100).\nHere, we list the criteria and their weights in descending order2:\n2https://www.newsguardtech.com/ratings/rating-process-criteria/\nBest Practices for Source-Based Misinformation Research 9\n1.\u201cDoes not repeatedly publish false content\u201d, changed to \u201cDoes not repeatedly publish\nfalse or egregiously misleading content\u201d in December 2023 (22 points)\n2.\u201cGathers and presents information responsibly\u201d (18 points)\n3.\u201cRegularly corrects or clarifies errors\u201d, changed to \u201cHas effective practices for cor-\nrecting errors\u201d in December 2023 (12.5 points)\n4.\u201cHandles the difference between news and opinion responsibly\u201d (12.5 points)\n5.\u201cAvoids deceptive headlines\u201d (10 points)\n6.\u201cWebsite discloses ownership and financing\u2019 (7.5 points)\n7.\u201cClearly labels advertising\u201d (7.5 points)\n8.\u201cReveals who\u2019s in charge, including possible conflicts of interest\u201d (5 points)\n9.\u201cThe site provides the names of content creators, along with either contact or bio-\ngraphical information\u201d (5 points)\nSince the overall score is a sum of the individual scores for each criterion, it is not\ntruly continuous, as some values (for example, 1, 2, 3, or 4 points) cannot be achieved by\nany combination of criteria.\nDescriptive Analyses\nHow stable are trustworthiness ratings over time?\nIn the following, we review how the database, particularly the trustworthiness rat-\nings and source selection, have changed over the years since the first version of the database\nwas compiled in 2019.\nCoverage across time. Over the span of five years, NewsGuard has grown from\n2,375 to 12,288 entries in total, as shown in Figure 1A to C. NewsGuard regularly adds\nnew sources but rarely removes any, i.e., the database has been growing to four times its\ninitial size. When counting the added domains based on monthly comparisons of the list,\nLuehring et al.\nNewsGuard has added 8,906 domains over time but only removed 685, adding an average\nof 137 new domains per month.\nNewsGuard ratings are available for customers in an online database (Amazon S3\nbucket), where a current snapshot is uploaded every hour. We sampled a snapshot from\nthe first hour of the 15th day of every month. When we instead sampled from the second\nday of each month, we observed two irregular dips in the number of sources (see May\n2022 and February 2024 in Figure 1A). It is likely that errors caused this fluctuation. For\ninstance, in May 2022, the approximately 3,500 removed sources that did not appear in\nthe database were present in the database two weeks later. Yet, this sudden disappearance\nand reappearance of sources illustrate the overall volatility of the database. We therefore\nadvise researchers to inspect several database snapshots and check their consistency before\nchoosing one.\nThe most recent snapshot contains ratings for 11,349 unique domains in the 12,288\ntotal entries; indicating that some sources appear multiple times. Typically, these sources\npublish in different languages, i.e., they have the same web domain but provide multi-\nlingual content, or they have an entry as a local and a global source. For instance, the\nAustrian website servustv.com produces both German- and English-language output and\nappears with the country label \u201cAT\u201d and the label \u201cALL\u201d. According to NewsGuard, the\nlatter serves as a generic label for the English-language translation of sites that were also\nrated in their respective language. In other words, each site with a label \u201cALL\u201d also exists\nin at least one other language, and the label \u201cALL\u201d can largely be ignored. In line with\nthat, duplicated sites have identical trustworthiness ratings across country or language\ncategories, except for only three cases. Therefore, dropping duplicated domain entries does\nnot substantially affect downstream research results. However, if a classification of sources\nbycountryisnecessaryfortheresearchquestionathand, researchersshouldkeepduplicated\ndomains.\nFurthermore, 5,754 of the rated domains belong to only 444 unique parent domains.\nSome parent domains have multiple variations of the domain name, probably representing\nthe same source, e.g., theragingpatriot.org has domains ending with .blog, .com, .net, and\n.pro. Other parent domains have very different sub-domains, e.g., 24usnews.com and afric-\nBest Practices for Source-Based Misinformation Research 11\ndaily.com belong to charmdaily.com. The other 6,534 ratings do not have a parent domain\nentry in the database. Domains belonging to the same parent domain usually have the\nsame trustworthiness rating. Furthermore, NewsGuard updates domains belonging to the\nsame parent domain at the same time, and they seem to assign the same unique identifier\nto those domains. Therefore, while the database contains 10,862 unique domains, it only\ncontains 7,073 unique identifiers and, therefore, individually rated (parent) domains.\nDistribution. NewsGuard trustworthiness ratings range from 0 to 100. Histori-\ncally, NewsGuard considered sources with a rating below 60 as not trustworthy, therefore\nassigning binary trustworthiness labels3. Since February 20234, NewsGuard uses a more\ngranular categorization, classifying sources with a score of 100 as \u201dhigh credibility\u201d, scores\nbetween 75 and 99 as \u201dgenerally credible\u201d, scores between 60 and 74 as \u201dcredible with ex-\nceptions\u201d, scores between 40 and 59 as \u201dproceed with caution\u201d, and scores between 0 and\n39 as \u201dproceed with maximum caution\u201d. Notably, NewsGuard is not a blacklist. In fact,\nclose to 60% of sources have an overall rating of over 60 (see Fig. 1B for the distribution of\ntrustworthiness scores in the most recent vs. the first version of the database and Fig. A.1\nfor distributions per year). Furthermore, the distributions also clearly show a multimodal\nstructure, indicative of the quasi-continuous nature of the overall NewsGuard score. In\naddition, some combinations of characteristics seem much more prevalent than others, in-\ndicating that the individual characteristics are not independent (see also \u201cComposition of\ntrustworthiness score\u201d below).\nWhen looking at the score distribution over time, the skew towards high ratings\ndiminishes slightly: while the average score was 71.8 ( SD=33.3) in 2019, it is now at 63.6\n(SD=32.6) as shown in Figure 1C. Various explanations for decreases in trustworthiness\nover time are possible: First, the database has tripled in size and added many sources with\nlower trustworthiness scores (on average 59.6, SD=27.5).\n3Snapshot of the described rating process from December 31st, 2022: https://www.news-\nguardtech.com/ratings/rating-process-criteria/\n4Snapshot of the updated rating process from February 1st, 2023: https://www.news-\nguardtech.com/ratings/rating-process-criteria/\nLuehring et al.\n2019 2020 2021 2022 2023 2024\nTime (months)020004000600080001000012000Number of sourcesA\nSampling interval\nMid-month\nBeginning of month\n0 25 50 75 100\nTrustworthiness050010001500200025003000Number of sourcesB\nVersion\nMost recent\nFirst\n2019-03 2019-09 2020-03 2020-09 2021-03 2021-09 2022-03 2022-10 2023-04 2023-10 2024-04\nTime (months)05001000150020002500Number of sourcesC Update type\nChanged\nAddedUpdate type\nChanged\nAdded\n020406080100Trustworthiness\n+1.3+1.1-2.0 -5.2 -1.1\n71.072.2\n68.662.8\n62.9\nGB US IT DE FR CA AU AT NZ GB US IT DE FR CA AU AT NZ\nFigure 1. Description of trustworthiness ratings with A showing the number of\nsources with rating over time based on two different sampling strategies: when sam-\npling one snapshot of the database mid-month (solid line), we observe a steady in-\ncrease, whereas sampling at the beginning of the month results in two irregular dips\n(dashed line). Panel B: distribution of trustworthiness in the first and most re-\ncent database as a histogram. Panel C: changes in trustworthiness scores over time\n(monthly granularity), with flags (respective country codes in order of appearance)\nand dotted lines indicating when countries were added and vertical lines highlighting\nthe top five updates (i.e., major score changes, also shown with arrows). The height\nof the bars describes the number of sources added vs. changed, with colors indicating\nthe proportions. Note: We include the average trustworthiness of sources added in\ngreen for the major changes. Countries are listed in the order added at the top of\npanel C.\nBest Practices for Source-Based Misinformation Research 13\nA significant number of sources with lower ratings were added, especially during the\noutbreak of the COVID-19 pandemic in 2020. The dashed lines with arrows in Figure 1C\nshow the top five updates in terms of their impact on the average trustworthiness. The\nheight of the bars shows the number of sources added vs. changed (with proportions in\ncolorsandtheaveragetrustworthinessofaddedsourcesingreen). Forallmajorupdates, the\nproportion of added sources is larger than changed sources. The highest number of sources\nadded was in September 2020, when 1,030 sources with on average very low trustworthiness\n(M=35.3, SD=14.1) were included. It is unclear if this development is due to an effort\nby NewsGuard to include more untrustworthy news or a global increase in untrustworthy\nsources.\nSecond, NewsGuard employs teams of experts per country, potentially leading to\ndifferences in coverage and ratings between countries. Dips in trustworthiness may be re-\nlated to country-specific sources being added. For instance, 1,015 of the 1,030 added sources\nin September 2020 are coded as US, resulting in a drop in trustworthiness of roughly 5%.\nIn contrast, adding entirely new countries to the database seems to have little effect on the\noverall trustworthiness score (see the dotted lines with country flags in Figure 1C), indi-\ncating that NewsGuard curates a balanced mix of trustworthy and untrustworthy sources\nwhen adding a new country. Overall, smaller dips appear across all countries covered and\nare most likely related to many low-quality sources gaining traction around the time of the\nCOVID-19 pandemic.\nA third influence on the overall trustworthiness score is updates of existing ratings.\nNewsGuard indicates the date when a rating was last updated, even if the score did not\nchange. Updates to entries are documented on average once every eight months (249 days),\nbut this varies strongly per source between a few seconds to a maximum of 790 days (in-\nterquartile range: 157 to 334 days). When updated, trustworthiness scores mostly remain\nunchanged (on average, 20% of updates mean a change in the rating). In other words,\nratings realistically change every two years ( M=570 days, IQR=397 days to 670 days). In\naddition, the majority of sources have not decreased in trustworthiness (average change of\nrating per source=0.1, SD=3.5). However, a few sources drastically dropped in trustwor-\nthiness; for instance, conservativedailynews.com lost 80 points in one update in November\n2020. Figure A.2 in the appendix illustrates the differences in consecutive scores over time,\nLuehring et al.\nwith major score updates in early 2020.\nOverall, the decrease in the overall trustworthiness of sources we can see in Fig-\nure 1C can, therefore, be attributed to NewsGuard adding untrustworthy sources rather\nthan previously trustworthy sources losing points. This interpretation is also supported by\nour analysis of changes in individual rating criteria below.\nComposition of trustworthiness score. The trustworthiness score is a compos-\nite score calculated based on nine journalistic criteria. For each source, NewsGuard\u2019s raters\nassign a Boolean value (yes/no) per criterion. The trustworthiness score is then calculated\nas the sum of the weighted criteria. Further explanation of the criteria and their weights\ncan be found in the NewsGuard FAQ5.\nIn the latest version of the dataset, 81.3% of sources fulfill the criterion \u201cAvoids\ndeceptive headlines\u201d (9,217 sources). The second most prevalent criterion is \u201cDoes not\nrepeatedly publish false or egregiously misleading content\u201d, which is met by 81.2% of all\nsources. These two top criteria often go together: When one is satisfied, the other tends to\nbe as well (Pearson\u2019s correlation coefficient = 0.9). A factor analysis with oblique rotation\nconfirms that the two criteria load on one factor, accounting for 58.1% of the explained\nvariance, with factor loadings > 0.8. All other criteria share 36.9% of the variance explained\n(factor loadings > 0.5). In line with that, 11.8% of all sources meet only the two top criteria\ncombined, while 13.4% of sources satisfy none of the nine journalistic criteria. The most\ncommon combination of criteria is that all nine criteria are satisfied simultaneously (13.5%\nof sources). We provide a correlation matrix of criteria in the Appendix (Table A.1).\nWe find that around 60% of sources have never changed in their fulfillment of jour-\nnalistic quality criteria during updates. We present update patterns of individual criteria\nover time in Figure 2A. The most common change is sources stopping disclosing ownership\nand financing, accounting for 12.3% of the observed changes. The opposite change (a dis-\nclosure of ownership and financing) is the third most common pattern, occurring in 10.7%\nof score updates. This indicates either that NewsGuard frequently checks criteria related\nto ownership or that adherence to such criteria is more volatile.\n5From December 31st, 2023: https://www.newsguardtech.com/ratings/rating-process-criteria/\nBest Practices for Source-Based Misinformation Research 15\n0 5 10\n% of sources1 - Does not repeatedly publish\n false or egregiously\n misleading content\n2 - Gathers and presents\n information responsibly\n3 - Has effective practices\n for correcting errors\n4 - Handles the difference\n between news and\n opinion responsibly\n5 - Avoids deceptive headlines\n6 - Website discloses ownership\n and financing\n7 - Clearly labels advertising\n8 - Reveals who's in charge,\n including any possible\n conflicts of interest\n9 - The site provides names\n of content creators,\n along with either contact\n or biographical informationCriteriaANegative Changes\nPositive Changes\nAT AU CA DE FR GB IT NZ US\nCountry1\n2\n3\n4\n5\n6\n7\n8\n9\nB\n2019 2020 2021 2022 2023 2024\nTime (years)60657075808590Trustworthiness (95%CI)\nCUS GB IT DE FR CA AU AT NZ\nFigure 2. Panel A: percentage of sources that have stopped or started to fulfill a\ncriterion, including multiple changes (positive vs. negative) of a single source. Panel\nB: percentage of sources that do not fulfill a criterion per country (July 15th, 2024).\nPanel C: trustworthiness per country over time (truncated to range from 55 to 90),\naggregated per year with 95% confidence intervals.\nLuehring et al.\nReproducibility of downstream research results using different snapshots\nof the database. Over the observation period, we observe both a substantial addition of\nsources, as well as more minor changes in individual journalistic criteria and therefore, the\noverall score for individual sources. This begets the question of whether such changes can\npotentially influence the conclusions drawn from investigations that rely on the NewsGuard\ndatabase, depending on which version is used. To provide a partial answer to this question,\nwe reproduce some of the analyses of the trustworthiness ratings of sources shared by\npoliticians in the US, UK and Germany by Lasser et al. (2022), using different versions of\nthe NewsGuard database. In Figure 3A, we show the temporal development of the average\nNewsGuard score of sources shared by Democrat and Republican members of Congress on\nTwitter between 2016 and 2022. We use snapshots of the NewsGuard database taken on\nMarch1from2019to2024(theoriginalresearchusedthesnapshotfromMarch1, 2022). For\nRepublicans, the result barely changes between different versions of the database, except in\n2019, where scores are substantially higher\u2013on average 3.2 points higher than the snapshot\nfrom 2020. The differences between snapshots from other years do not surpass 0.3 points\nand reveal no trend. For Democrats, the snapshot from 2019 also has substantially higher\nscores (2.1 points when compared to 2020). In addition, the snapshot from 2024 yields a 1.3\npoints lower average score than the snapshot from 2023. For other years, the differences also\ndo not surpass 0.3 points and have no trend. However, even given the sometimes relevant\ndifferences in scores, the main finding of the research, namely the increasing difference in\naverage scores between Democrats and Republicans, does not change. Figure 3B shows\nthe average difference in the NewsGuard score of sources shared by the politicians over\ntime. When using the 2019 snapshot, which deviates most strongly from the others, the\ndifference between parties is smaller in the years 2020 to 2022 compared to other snapshots,\nbut remains substantial.\nThe finding that there are only minor changes depending on which version of the\ndatabase is used for the US is likely due to the fact that sources rarely change their rating,\nand that almost all major US news sources were already covered in the first version of the\nNewsGuard database: the snapshot from 2019 covers 15.0% of links posted by Democrats\non Twitter and 18.5% of links posted by Republicans. For the 2024 snapshot, the coverage\nslightly increases to 16.3% and 19.6% of links for Democrats and Republicans, respectively.\nBest Practices for Source-Based Misinformation Research 17\n2016 2017 2018 2019 2020 2021 202280859095100NewsGuard scoreDemocrat 2019\nDemocrat 2020\nDemocrat 2021Democrat 2022\nDemocrat 2023\nDemocrat 2024Republican 2019\nRepublican 2020\nRepublican 2021Republican 2022\nRepublican 2023\nRepublican 2024\n2016 2017 2018 2019 2020 2021 202204812NewsGuard score difference2019\n2020\n20212022\n2023\n2024A\nB\nFigure 3. Reproduction of the time series of NewsGuard scores of US Congress\nMembers from Ref. Lasser et al. (2022) using different versions of the NewsGuard\ndatabase from 2019 to 2024 (always taken from the first hour of March 1st of the\ngiven year). Panel A: average scores for Democrats and Republicans indicated in\ndifferent shades of blue and red for each year. Panel B: difference between the average\nDemocrat and average Republican score, indicated in different shades of grey for each\nyear. The time series represent a moving average over three months.\nFor the other two countries, Germany and the UK, the picture changes: differences\nin average ratings stratified by party show larger differences between years (see Figures A.3\nandA.4intheappendix). Thisislikelyduetomassivechangesinthecoverageofthesources\nshared by politicians in these countries by NewsGuard. For example, for members of the\nGerman party SPD, coverage increased from 0.5% in 2019 to 12.7% in 2024 and from 0.2%\nto 12.0% for members of CDU/CSU. In the UK, the coverage for members of the Labour\nParty increased from 7.8% to 13.5%, and for Tories, from 2.4% to 7.8%. Taken together,\nsuch coverage differences between years would lead to different conclusions in some cases,\nbut not in others. For instance, the NewsGuard score of small parties like DIE LINKE\nand the Greens in Germany shows an upward trend with the 2019 version but not with\nnewer versions. In the UK, all versions would yield the same main conclusion, namely that\nthe average score shows no specific trend over time. It is usually the earlier versions of\nLuehring et al.\nthe database that lead to different scores, given that coverage was still low in 2019. Later\nversions, especially 2022-2024, usually yield the same result.\nThis analysis shows that for countries other than the US, the usage of different\nversions of the database has the potential to significantly influence research outcomes, likely\ndue to the addition of a significant number of relevant new sources to the database over\nthe years. Researchers investigating countries for which sources were only recently added\nto the database (e.g., New Zealand or Austria) should, therefore, proceed with caution and\ninvest time to validate the coverage of the database for a given country.\nHow complete is the database across countries, particularly for non-US\ncountries?\nCountry coverage. The dataset (2019-2024) contains sources from nine countries\nin total (United States, Great Britain, Italy, Canada, France, Germany, Austria, Australia,\nand New Zealand) plus sources considered to be global. Countries were added in the fol-\nlowing order: Great Britain (country name in the database \u201cGB\u201d), United States (US),\nItaly (IT), France (FR), Germany (DE) \u2013 all added in 2019, Canada (CA, added in 2021),\nAustralia (AU, added in 2021), Austria (AT, added in 2022), and New Zealand (NZ, added\nin 2023). In the following analysis, we will drop the category \u201cALL\u201d.\nThe majority of sources are from the United States (76.1%), followed by Great\nBritan (5.2%). Table 1 gives an overview of the total number of sources per country and\ntheir average trustworthiness scores (also see Fig. A.5 for the number of sources over time\nper country). NewsGuard also labels the language of a source, with English being the most\nrepresented (9,455 sources; 86.9%), followed by Italian (4.9%), French (4.4%), and German\n(3.8%).\nBest Practices for Source-Based Misinformation Research 19\nTable 1: Country descriptives.\nCountry n (%) Trustworthiness (SD) Updated Changed\nUS 8281 (76.1) 56.8 (34.1) 224 days 559 days\nGB 568 (5.2) 78.5 (23.5) 224 days 474 days\nIT 537 (4.9) 70.9 (24.2) 291 days 661 days\nCA 471 (4.3) 87.7 (15.3) 306 days 430 days\nFR 424 (3.9) 65.4 (29.2) 326 days 646 days\nDE 368 (3.4) 77.0 (31.2) 308 days 673 days\nAU 166 (1.5) 72.5 (24.6) 331 days 358 days\nAT 42 (0.4) 77.2 (29.6) 338 days 375 days\nNZ 22 (0.2) 76.3 (24.7) 313 days 426 days\nNote.As of September 15th, 2024. Sorted by size.\nAcross all versions of the database and in most countries, the overall trustworthiness\nof sources remains above 65, except for the United States. US-based outlets are of lower\ntrustworthiness on average (see Table 1). Figure 2C shows the average trustworthiness of\nsources per country over time (see also Figures A.6 and A.7 for plots by country). The\ntrustworthiness score for the US was lower from the first database version onward. It\nis unclear whether US sources are of lower trustworthiness overall or if larger coverage\nof low trustworthy outlets from the start can explain this finding. The development of\ntrustworthiness indicates that for countries with a higher number of sources, the database\nseemstohavesettledintoastablestate, whereasfornewercountries(Canada, NewZealand,\nAustralia), rating coverage still seems to vary.\nWhen comparing the number of sources that meet the journalistic criteria per coun-\ntry, we observe some striking patterns. Figure 2B shows the percentage of sources that do\nnot fulfill a given indicator by country, i.e., a high percentage indicates that many sources\nfail to meet the criterion. For most countries, more than 50% of sources meet each crite-\nrion. Interestingly, over 70% of Italian sources do not provide names of content creators,\nand over 80% do not effectively correct errors. A similar but less pronounced pattern is\nLuehring et al.\nvisible for French sources. Across all criteria, the United States shows the highest percent-\nage of sources not fulfilling the criteria, with 56.4% of sources failing to gather and present\ninformation responsibly, almost twice the share of sources than in any other country. Fur-\nthermore, 30% of US-based sources fail to fulfill the heavily-weighted criterion \u201cDoes not\nrepeatedly publish false or egregiously misleading content\u201d.\nIntervalsbetweenupdatesofsourcesvarybycountry(seeTable 1), rangingfrom224\ndays for the US and 291 days for Italy to 308 days for Germany. Sources get updated once a\nyear per country, on average. Overall, the US coverage seems the most stable and complete.\nHowever, the number of media outlets in each country may depend on numerous factors\n(e.g., population size, fragmentation of the media system, political system, and so on). To\nbetter understand how complete the database is per country, we describe comparisons with\ndomains shared on social media and with other lists in the following sections.\nComparison with domains shared on social media. In the supplementary\nmaterial of Lasser et al. (2022), the authors describe a manual inspection of web domains\nin their Twitter (now X) dataset that were not covered by NewsGuard (see \u201cReproducibility\nof downstream research results using different snapshots of the database\u201d). More precisely,\nthe authors investigate all links posted by politicians that point to web pages other than\nsocial media platforms and search platforms. Overall, NewsGuard seems to cover a notable\nfraction of those links (US: 46.5%, Germany: 58.8%, UK: 39.2%). Per country, the authors\nselected relevant domains not covered by NewsGuard that individually accounted for at\nleast 0.1% of all linked domains, i.e., these domains had likely been shared repeatedly.\nSubsequently, they inspected the missing domains and manually assigned labels to them\n(e.g., \u201cgovernment\u201d, \u201cnews\u201d, or \u201cblog\u201d).\nFor the US, 47 domains were analyzed, accounting for 21.2% of missing domains in\nthe dataset. While most of these domains link to government or personal websites, none of\nthe 47 domains lead to a news site. For the UK, out of the 78 analyzed domains (40.3%\nof missing domains), four domains not covered by NewsGuard are news sites, comprising\na total of 1.5% of the links shared by the politicians. Of these sites, one was a clearly\nright-leaning site and two were mostly linked to by members of the labour party, while\nthe last site was a news aggregator with no clear political leaning. Similarly, for Germany\nBest Practices for Source-Based Misinformation Research 21\nonly a fraction of links not covered by NewsGuard lead to existing news sites (1.2%),\ncorresponding to four out of the 62 manually analyzed missing domains (31.5% of missing\ndomains analyzed). These sites were primarily shared by members of the left, green, or\nliberal parties, indicating that they are not widely shared across party affiliations.\nAlthoughtheinvestigationexaminesonly20-40%ofdomainsnotevaluatedbyNews-\nGuard, by analyzing the domains that were most frequently shared, it demonstrates that\nNewsGuard provides a comprehensive list of domains shared by politicians in their social\nmedia communication across the US, UK, and Germany. Moreover, the small number of\nmissing news sites and the relative absence of sources from both the left and right political\nspectrum in the missing domains suggests that NewsGuard\u2019s domain curation shows no\nsystematic political bias.\nComparison with other lists. In order to assess the actual coverage of sources\nper country, we compare the sources covered by NewsGuard with other lists. However,\nother lists are often not compiled with the same objective as NewsGuard, which is to cover\nall sources responsible for most of the internet traffic. Therefore, their scope and rating\nsystem may differ. In addition, other lists are not available for every country.\nPrimarily for the US context, Lin et al. (2023) have compared the overlap and agree-\nment between ratings across six lists of existing expert ratings, including the NewsGuard\ndatabase. While trustworthiness ratings correlated significantly for the web domains in-\ncluded in multiple lists, the authors found a high number of non-overlapping web domains\nbetween lists.\nFor the German context, Puschmann et al. (2024) collected a list of 1,147 unique\nGerman online news domains (GOND)6, largely relying on web tracking data of a represen-\ntative sample of 1,500 German citizens. Overall, GOND has 552 sources in common with\nNewsGuard (see Table A.2, among others labeled as \u201clegacy press\u201d (52.9%), \u201cdigital-born\nnews outlet\u201d (12.0%), or \u201chyperpartisan news\u201d (10.1%). NewsGuard covers 244 out of 573\nGerman-speaking sources covered by GOND, including some other languages.\n6https://osf.io/s5uhb/\nLuehring et al.\nOverall, comparisons of NewsGuard with the two lists for the US and Germany\nrevealmanynon-overlappingdomains. However, NewsGuard\u2019scoverageoftheUnitedStates\nand Germany seems extensive in that NewsGuard generally tends to cover more prominent\noutlets and excludes niche and regional outlets, probably because it focuses on websites\nwith the most engagement.\nHow valuable are contextual source labels for misinformation research?\nPolitical orientation. In addition to trustworthiness ratings, the NewsGuard\ndatabase also classifies sources according to their political orientation, relying on a left-to-\nright conception of the political spectrum. In December 2022, the categories were condensed\nfromfour(farleft/slightlyleft/slightlyright/farright)totwo(left/right; seeFig.4A).Over-\nall, the political orientation label is only available for a minority of the sources, specifically\n33.4% (3,789 sources) in the current database version.\nIntheUS,34.8%ofnewsoutletshaveapoliticalorientationlabel, incontrasttoonly\na small minority of sources in other countries: 10.4% of sources for Great Britain, 13.2% for\nItaly, 16.9% for Germany, and 20.3% for France. Figure 4C and Table A.3 show the total\nnumber of political orientation labels per country as well as the number and percentage of\nsources classified as left or right-leaning in the most recent database. In most countries,\nthe majority of sources with political orientation labels belong to the right-wing spectrum.\nFigure A.8 shows the distribution of political orientation per country over time.\nTrustworthiness ratings are generally lower for right-leaning sources (see Fig. 4B).\nIn the database snapshot from September 2024, the average trustworthiness score for right-\nleaning sources is 26.4 ( SD=20.3), in contrast to 60.6 ( SD=26.1) for left-leaning sources\n(Mdiff=34.2, t(3771)=35.4, p<.001). When political orientation was still divided into four\ncategories, slightly left- and right-leaning sources had moderate trustworthiness ratings (for\nexample, in June 2021, 81.3 and 59.4, respectively), and far-left and far-right sources had\ncomparatively lower ratings (54.0 and 15.9, respectively). In August 2021, however, when\na number of untrustworthy sources ( M=40.5, SD=37.2) were added to the database, the\naverage trustworthiness of sources categorized as slightly right-leaning dropped by almost\n20 points. Figure 4A shows that the \u201cSlightly Right\u201d category dropped below the \u201cFar\nBest Practices for Source-Based Misinformation Research 23\nLeft\u201d category by almost 15 points.\n2019 2020 2021 2022 2023 2024\nTime (months)020406080100Trustworthiness\nLabel change in 12/2022A\n20 40 60 80 100\nTrustworthiness (95% CI)AT\nAU\nCA\nDE\nFR\nGB\nIT\nNZ\nUSCountry\nB\n0 10 20 30\n% of sourcesAT\nAU\nCA\nDE\nFR\nGB\nIT\nNZ\nUSC\nBefore\nFar Left\nFar Right\nSlightly Left\nSlightly Right\nAfter\nLeft\nRight\nFigure 4. Trustworthiness averages by political orientation. Panel A: over time.\nPanel B: by country. Panel C: percentage of sources per country with political orien-\ntation, explaining differences in trustworthiness by country.\nLuehring et al.\nIn addition to the change in average trustworthiness scores within political orienta-\ntioncategoriescausedbythechangedtaxonomyofpoliticalorientationusedbyNewsGuard,\nthe trustworthiness averages per political orientation also differ by country, as shown in\nFig. 4B. While for some countries like France and Canada, the average trustworthiness of\nleft and right sources only differs by about 20 points and 95% confidence intervals overlap,\nother countries like Australia, Germany, and Austria show extreme differences of over 40\npoints. Nevertheless, across all countries, sources classified as right, on average, always have\na lower trustworthiness score than sources on the left. However, given the small percentage\nof sources classified as belonging to either side of the spectrum, we cannot infer that sources\non the right, in general, have lower trustworthiness. A bias in NewsGuard\u2019s procedure of\nclassifying sources as either left or right or not at all could also produce these findings.\nTo get an idea of whether sources with labels are correctly classified and whether\nsources without labels are neutral or not classified by NewsGuard for other reasons, we com-\npared NewsGuard ratings with manual and other expert source labels. First, we manually\nannotated the political orientation of all German-speaking sources ever covered by News-\nGuard (as of September 15th, 2024) based on the website\u2019s front page, article headlines,\nads, and article content. We followed the labels by NewsGuard (right/left) and added two\nlabels: neutral and unidentifiable (e.g., when the website is unreachable). For sources with\navailable ratings, the agreement between NewsGuard and the manual annotations was 83%\n(for 64 domains out of 406, excluding 20 dead links). Second, we compared the NewsGuard\nlabels to labels by MediaBiasFactCheck7(MBFC, 41 labels in total, six overlapping with\nNewsGuard), resulting in an agreement of 83%. Both comparisons showed that disagree-\nments mainly occurred in cases where the manual annotations were labeled as neutral, while\nthe expert ratings assigned a specific label. In only one case, NewsGuard differed from both\nMBFC and the manual annotation.\nConsequently, in the German context, the existing ratings largely matched manual\npolitical orientation labels. Interestingly, the rated sources tended to be niche outlets with\nmore extreme (and thus, clear-cut) political leanings. For the neutral sources, we could not\nidentify a clear political leaning. Such sources were typically local newspapers or magazines\n7See here for rating system as of August 20th, 2024: cd https://mediabiasfactcheck.com/methodol-\nogy/\nBest Practices for Source-Based Misinformation Research 25\nfocusing on special interest topics (e.g., technology or health). However, roughly half were\nlegacy media or major online sources that slightly leaned towards a particular political\norientation. Our findings suggest two (not necessarily mutually exclusive) implications\nfor a missing political orientation: Either the sources have no overt political bias in their\nreporting or are too niche to be labeled by NewsGuard.\nBefore the rating became binary, a few domains frequently oscillated between more\nextreme and less extreme labels, but domains rarely switched their political orientation.\nThis might have been a reason for simplifying the label. Only five domains have changed\ntheir political orientation rating from left to right (none have changed from right to left).\nThese domains are US-based, and two of them also experienced a significant drop in their\ntrustworthiness score, reducing it by 42 points in January 2020. We therefore conclude that\npolitical orientation labels generally remain stable for the relatively small number of sources\nthat have such a label.\nIn summary, although the political orientation labels of sources provided by News-\nGuard are sparse, particularly outside the US, the ratings of covered sources appear gener-\nally stable over time. An in-depth investigation of labels for German sources showed that\nNewsGuard\u2019s political orientation assessment is reasonable and the low number of labels can\nbe explained by sources not showing a political leaning or being too niche. Therefore, the\npolitical orientation rating by NewsGuard may be a valuable addition to analyses related\nto source trustworthiness. However, we recommend that researchers (at least) spot-check\nthe ratings for the specific country in which they intend to use the database, especially for\nmajor outlets and mainstream media sources. If the research focuses on comparing political\nbias rather than controlling for it, we advise validating and extending the existing ratings\nprovided by NewsGuard.\nTopics. NewsGuard experts assign labels for the topics covered by the sources.\nUsually, a single source has multiple assigned topics. The number of sources with topic\nlabels has steadily increased since their introduction in October 2019. As of May 2021,\nroughly 50% of the sources had topic labels (see Fig. A.9) for the total number and pro-\nportion of sources with topic labels). In September 2024, only 352 sources are without a\ntopic label (2.9%). In Figure 5B, we show the topic counts. The most popular topics are\nLuehring et al.\n\u201cLocal news\u201d (40.3% of sources), \u201cPolitical news or commentary\u201d (39.5%), \u201cGeneral news\u201d\n(22.7%), \u201cHealth or medical information\u201d (13.6%), and \u201cConspiracy theories or hoaxes\u201d\n(12.8%). Over time, topic labels related to misinformation have been added, most likely\ncoinciding with some of the major database updates discussed above. Figure 5C shows\nthe top five topics discussed by sources classified as untrustworthy (measured by the per-\ncentage of untrustworthy sources publishing on those topics). In April 2020, shortly after\nthe COVID-19 pandemic started, NewsGuard increasingly added a label called \u201cCOVID-19\nmisinformation\u201d, with major additions in August 2021. Once a source receives a topic label,\nit rarely changes (except for foxnews.com, which has changed seven times).\nAs shown in Figure 5A, average trustworthiness ratings greatly differ across topics\n(white dots show the average trustworthiness of sources covering that topic). The lowest\naverage rating is given to sources covering issues related to conspiracy theories ( M=12.6,\nSD=12.6), military ( M=31.8, SD=34.9), and health or medical information ( M=39.3,\nSD=35.5). In contrast, those covering education have the highest average trustworthiness\nscores ( M=85.8, SD=16.9, but this is only 0.5% of the sources). Generally, topics with low\ncoverage tend to have high trustworthiness scores with low variance (e.g., fashion with 76.5\non average, SD=10.2), see Figure 5B. Considering only untrustworthy sources, however,\nonly 32.5% of them are labeled as covering conspiracy theories. Instead, untrustworthy\nsources seem to commonly publish \u201cPolitical news or commentary\u201d, with 79% of all un-\ntrustworthy sources (e.g., with a trustworthiness score < 60) covering this topic, followed\nby local (30.4%) and health news (22.3%). These topics generally receive a significantly\nhigher number of labels from NewsGuard and show a high variance in trustworthiness, for\ninstance, \u201cGeneral news\u201d or \u201cLocal news\u201d (see Fig. 5A and B). This highlights that both\nuntrustworthy and trustworthy sources cover a wide range of topics, including mainstream\nones, and that fringe topics only make up a small proportion of the news.\nAcross countries, sources more or less publish on the same topics (see Fig. A.10\nin the appendix). However, sources with low trustworthiness seem to publish on different\ntopics, i.e., the trustworthiness of sources covering a given topic substantially depends on\nthe country (see Fig. A.11). For instance, for medical information, sources in Canada are\nrated as trustworthy ( M=65.4, SD=34, 27 sources), while trustworthiness is well below 60\nin the United States ( M=30.2, SD=33.3, 1,130 sources). The difference between countries\nBest Practices for Source-Based Misinformation Research 27\n0 20 40 60 80 100\nTrustworthinessConspiracies\nMilitary and defense\nHealth news\nPolitical news\nReligion\nViral content\nScience\nEntertainment\nCelebrity news\nLaw or criminal justice\nGeneral news\nLocal news\nParenting\nSports\nEnvironment\nLifestyle\nFashion\nT echnology\nBusiness\nEducationT opics\nA Left Right\n0 2000 4000\nNumber of ratingsB\n2020 2021 2022 2023 2024\nTime (months)01000200030004000Number of ratingsCConspiracies\nCOVID-19 misinfo\nHealth news\nPolitical newsLocal news\nGeneral news\nGeneral / local news\nFigure 5. A) shows the distributions of trustworthiness per topic and political ori-\nentation (left/right in blue/red, respectively), sorted by their average trustworthiness\n(white dot within the boxplot that represents the quartiles and whiskers show the\nwhole range). Note: We excluded topics with a count below 50. Some topics are\nabbreviated. B) gives the count of topics as of September 15th, 2024. C) shows the\nfrequency of misinformation-related labels over time. Colored lines show the top five\ntopics covered by untrustworthy sources. The dotted, vertical lines show the removal\nof two of those labels. The grey and dashed line shows the average topic label count\nof those topics across all sources with the 95%CI.\nis also substantial for political news, with an average trustworthiness of 33.1 ( SD=24.8,\n3,498 sources) in the US, 39.2 ( SD=29.3, 111 sources) in France, and 81.6 ( SD=18.6, 268\nLuehring et al.\nsources) in Great Britain.\nWe also analyzed the interaction of average trustworthiness by topic and political\norientation (see Figure 5A). Political and local news are among the most popular topics\nassigned to both left- and right-wing sources, with 386 and 113 as well as 2,946 and 1,140\nsourcescoveringthosetopics, respectively. Thesenumbersshowthedifferencesinhowmany\npolitical orientation labels are assigned to each side. For sources classified as right-wing,\ntrustworthiness scores for all topics are consistently lower on average than for sources on\nthe left side, e.g., political news: M=26.6 ( SD=20.0) on the right and M=60.2 ( SD=26.0)\non the left. 1,162 right-wing sources cover conspiracy theories ( M=10.0, SD=11.4) and\n693 sources cover health-related news ( M=11.3, SD=15.0). Meanwhile, for sources labeled\nas left-leaning, trustworthiness is particularly low (below 50) when they cover the topics\n\u201cConspiracies\u201d, \u201cMilitary and defense\u201d or \u201cHealth news\u201d. However, due to the skewed\ndistributionofpoliticalorientationinthedatabase,itisimpossibletosaywhethertheabove-\nmentioned differences in countries and political orientation are due to actual differences in\nthe media landscape or a sampling bias.\nOverall, the coverage of topic labels appears comprehensive, suggesting they could\nbe a valuable asset for misinformation research. Especially a combination of trustworthiness\nand topic labels could complement source characterization, for instance, by distinguishing\nbetween fringe sources and those addressing mainstream issues. For sources that lack a\nlabel for political orientation, topics may help clarify if a source is genuinely neutral or\ntends to cover extreme topics low in trustworthiness.\nConclusion\nAn inherent challenge in misinformation research lies in how false information is\ndefined and measured. A prominent approach for tracking online misinformation is to\nuse a list of sources and their web domains. Due to its popularity and limited access,\nwe examined the comprehensive NewsGuard database and analyzed the temporal stability\nand cross-country completeness of their trustworthiness ratings and other source labels\nrelevant to misinformation research. Here, we summarize practical recommendations for\nusingNewsGuardinresearchanddiscussconclusionsforsource-basedapproachesingeneral.\nBest Practices for Source-Based Misinformation Research 29\nOver 50% of the sources included in the database have a score of 60 points or higher,\ndeemed at least \u201ccredible with exceptions\u201d according to NewsGuard\u2019s nomenclature. These\nsources typically meet two high-weight criteria: \u201cAvoids deceptive headlines\u201d and \u201cDoes\nnot repeatedly publish false or egregiously misleading content\u201d. The average trustworthi-\nness score of sources included in the database has decreased over time due to the addition\nof untrustworthy sources rather than the degradation of trustworthiness of existing ones.\nNewsGuard provides a new snapshot of its database hourly, but an analysis of update\ntime stamps of sources shows that source information is likely checked annually, with in-\nfrequent changes to trustworthiness ratings usually triggered by changes in transparency\nabout website ownership and financing or editorial practices. Such changes are generally\nminor, involving updates of only one of the nine journalistic quality criteria. However,\nchanges in source coverage can be abrupt, with instances of over 1,000 sources being added\nor removed in a single update. To shed some light on the impact of changes in the News-\nGuard database on downstream research outcomes, we reproduced research investigating\nnews-sharing practices of political elites in the US, Germany, and the UK (Lasser et al.,\n2022). We find that after 2019, the content of the database largely reached a stable state in\nthe US, and using different versions of the database between 2020 and 2024 does not change\nresearch outcomes. This process took longer for Germany and the UK, but after 2022, we\nalso only observed minor database changes for these countries. Despite these nuances, the\ntrustworthiness ratings by NewsGuard appear relatively insensitive to time, speaking for\nthe reliability of source-based approaches.\nUS sources generally score lower on trustworthiness compared to other countries.\nImportantly, this does not say anything about the trustworthiness of news actually con-\nsumed by the US population, which could be higher, depending on the contribution of\neach source to the news diets of US Americans. Country-specific factors seem to signifi-\ncantly influence journalistic traditions across countries with similar media systems. Italy\nand France, part of the Southern cluster, show distinct patterns compared to Central (e.g.,\nGermany) and Western clusters (e.g., US). According to Br\u00fcggemann et al. (2014), coun-\ntries belonging to the Southern cluster have a less professionalized journalism sector than\nthe Central or Western clusters. In their seminal definition of media systems, Hallin &\nMancini (2004) state that in countries that fail to meet the professionalism indicators, the\nunderstanding of journalists serving the public interest is less pronounced. In other words,\nLuehring et al.\nwhen journalistic professionalism is low, journalists lack professional autonomy, potentially\nexplaining less institutionalized transparency practices in these countries, as indicated by\nNewsGuards\u2019 journalistic criteria. NewsGuard\u2019s criteria broadly reflect differences in media\nsystems\u2013\u2013at least for the Western, educated, industrialized, rich, and democratic countries\ncovered. Nonetheless, the differences in journalistic traditions underscore that applications\nof the database need to be tailored to individual contexts and that researchers should\ndouble-check the relevance of the criteria for the country studied8.\nThe NewsGuard database provides more than just trustworthiness ratings; it also\nincludes labels for the political orientation of sources and covered topics, which could be\nvaluable contextual information for misinformation research. While most sources have mul-\ntiple topic labels, only a minority of sources have one for political orientation. While about\n41% of sources have a political orientation label in the US, only around 10% do in other\ncountries. In our manual analysis of German sources, we observed that NewsGuard tends\nto rate only sources with a clear political leaning. Most rated sources are right-leaning, and\nthese are often deemed less trustworthy compared to left-leaning sources. This disparity\nraises the question of whether it stems from a sampling bias by NewsGuard editors rather\nthan an actual difference in trustworthiness. We argue that NewsGuard seems unbiased for\nthe countries where coverage and ratings have stabilized for the following reasons: First,\nNewsGuard selects sources based on web tracking data, suggesting that it should reflect the\nonline media landscape for the respective country. Research on alternative media suggests\nthe emergence of right-wing counter-publics as a response to the political and legacy media\ncontext (Heft et al., 2020). More precisely, the theory posits that a prevalence of left-leaning\nopinions in political and mainstream media spheres (Osmundsen et al., 2021) may lead to\nan under-representation of right-wing views and the fragmentation of a counter-public along\nthe right-wing spectrum that is highly connected (Heft et al., 2021). As NewsGuard only\nlabels the political orientation of explicitly partisan, sometimes hyper-partisan sources, this\nexplanation would result in a higher number of smaller, right-wing online sources. A de-\nmand for right-wing fringe publications would also explain lower trustworthiness on the\nright-wing spectrum, which aligns with the political asymmetry repeatedly observed in sus-\nceptibility to misinformation, e.g., recently by Robertson et al. (2023). Second, the source\n8https://www.newsguardtech.com/ratings/rating-process-criteria/\nBest Practices for Source-Based Misinformation Research 31\nselection and trustworthiness ratings provided by NewsGuard are largely consistent with\nother independent fact-checking organizations (Lin et al., 2023). Therefore, it is unlikely\nthat NewsGuard has an inherent bias against right-leaning sources, both in selecting more\nright-wing sources and in giving them lower trustworthiness ratings. NewsGuard also dis-\ncussesthistopicintheir2023SocialImpactReport9, emphasizingthattheirtrustworthiness\nratings are intended to be apolitical. Despite being incomplete, the political orientation la-\nbels may be a useful addition to the trustworthiness ratings, especially in combination with\ntopic labels. However, they should be interpreted with caution and potentially validated\nand extended for countries other than the US and Germany.\nOur analysis faces several limitations due to a scarcity of comparable datasets, par-\nticularly for countries other than the United States, the United Kingdom, and Germany.\nAs a result, we cannot assess the reliability and validity of the NewsGuard database; we can\nonly evaluate the internal and temporal stability of ratings. To address this, we reproduced\npreviousresearchfindingsusingdifferentdatabaseversions, comparedthedatabasewith the\nfew existing lists, and manually validated ratings. Based on these analyses, the NewsGuard\ndatabase appears stable and complete for Great Britain, the US, Germany, and possibly\nFrance and Italy. Additionally, our results are reproducible across different database ver-\nsions, even with slight changes in the instrument, especially for its early versions. Given our\nobservations, werecommendthatresearchersusingNewsGuard\u2019strustworthinessratingsex-\namine several snapshots of the database to ensure no major source additions or deletions\noccurred recently. For countries included in NewsGuard for longer, e.g., the US, Canada,\nFrance, Italy, Germany and the UK, we suggest that researchers use whatever version of the\ndatabaseafter2022 theyhaveaccess to. Usingdifferentversionsofthe databasefor different\nportions of any data being analyzed from different time periods does not seem necessary,\ngiven the general stability of trustworthiness ratings once a source has been included in the\ndatabase. For more recent additions, e.g., Australia, Austria and New Zealand, we suggest\nthat researchers always use the most recent version of the database and carefully examine it\nfor differences in coverage for different units of analysis, such as political leaning. Lastly, the\ntopic and journalistic criteria ratings appear stable and may offer valuable context for the\nanalysis of misinformation dynamics. A combination of political orientation and topic labels\n9https://web.archive.org/web/20240228003711/https://www.newsguardtech.com/special-\nreports/social-impact-report-2023/\nLuehring et al.\ncould effectively characterize sources and identify untrustworthy sources that address and\ndecontextualize mainstream issues beyond hyper-partisan contexts. It is important to note\nthat this analysis is specifically relevant to online misinformation research, as NewsGuard\nuses web traffic data to select sources for assessment. Future research should compare lists\nof online news domains to cross-platform and offline news consumption and examine how\nsampling based on sources versus stories influences downstream results.\nInconclusion,usingalistofratedonlinenewsdomainsappearstobeastablemethod\nfor identifying misinformation online at scale. A source-based approach with a fine-grained\nrating scheme based on journalistic quality criteria is particularly valuable and theoretically\nsound because it can encompass a wide range of sources, including less extreme forms of\nmisinformation, thereby better-reflecting people\u2019s information diets. While the NewsGuard\ndatabase serves as a useful tool for tracking online misinformation at the level of the source,\nresearchers should weigh its utility for the studied context against associated costs and\nconsider alternative sources (e.g., Lin et al., 2023) for comprehensive analysis. Our findings\nunderscore the critical need for dynamic, multifaceted, and openly accessible methods to\nget a clear and robust answer on the impact of misinformation on entire populations.\nAcknowledgments\nWe acknowledge David Garcia and No\u00eblle Lebernegg for discussions about mea-\nsurement issues in misinformation research and Annie Waldherr for her helpful feedback\non the manuscript. J. Luehring, H.M., A.S. were supported by the Vienna Science and\nTechnology Fund (WWTF) and the City of Vienna under grant 10.47379/ICT20028 and\ngrant 10.47379/VRG16005. The funders played no role in study design, data collection and\nanalysis, decision to publish or preparation of the article.\nData and Code Availability\nReproduction materials, including code and extended data, excluding the News-\nGuard database, which is proprietary, are accessible on Github. To license the NewsGuard\ndatabase, contact support@newsguardtech.com.\nBest Practices for Source-Based Misinformation Research 33\nAuthor Contributions\nContributed to the conception and design: J. Luehring, H.M., J. Lasser, A.S.\nContributed to the analysis and interpretation of data: J. Luehring, R.M.L., J. Lasser, H.M.\nWrote the article: J. Luehring\nRevised the article: J. Luehring, H.M., J. Lasser, A.S.\nFinal approval of the version to be published: J. Luehring, J. Lasser, H.M., A.S., R.M.L.\nReferences\nAllen, J., Howland, B., Mobius, M., Rothschild, D., and Watts, D. J. (2020). Evaluating\nthe fake news problem at the scale of the information ecosystem. Science Advances ,\n6(14):eaay3539. Publisher: American Association for the Advancement of Science.\nAllen, J., Watts, D. J., and Rand, D. G. (2024). Quantifying the impact of misinformation\nand vaccine-skeptical content on Facebook. Science, 384(6699):eadk3451. Publisher:\nAmerican Association for the Advancement of Science.\nAltay, S., Berriche, M., and Acerbi, A. (2023). Misinformation on Misinforma-\ntion: Conceptual and Methodological Challenges. Social Media + Society ,\n9(1):20563051221150412. Publisher: SAGE Publications Ltd.\nBakir, V. and McStay, A. (2018). Fake News and The Economy of Emo-\ntions. Digital Journalism , 6(2):154\u2013175. Publisher: Routledge _eprint:\nhttps://doi.org/10.1080/21670811.2017.1345645.\nBaribi-Bartov, S., Swire-Thompson, B., and Grinberg, N. (2024). Supersharers of fake news\non Twitter. Science, 384(6699):979\u2013982. Publisher: American Association for the\nAdvancement of Science.\nBennett, W. L. and Livingston, S., editors (2020). The Disinformation Age . SSRC Anxieties\nof Democracy. Cambridge University Press, Cambridge.\nBozarth, L., Saraf, A., and Budak, C. (2020). Higher Ground? How Groundtruth Labeling\nImpacts Our Understanding of Fake News about the 2016 U.S. Presidential Nomi-\nnees.Proceedings of the International AAAI Conference on Web and Social Media ,\n14:48\u201359.\nLuehring et al.\nBr\u00fcggemann, M., Engesser, S., B\u00fcchel, F., Humprecht, E., and Castro, L. (2014). Hallin\nand Mancini Revisited: Four Empirical Types of Western Media Systems: Hallin\nand Mancini Revisited. Journal of Communication , 64(6):1037\u20131065.\nBudak, C., Nyhan, B., Rothschild, D. M., Thorson, E., and Watts, D. J. (2024). Misunder-\nstanding the harms of online misinformation. Nature, 630(8015):45\u201353. Publisher:\nNature Publishing Group.\nCeladin, T., Capraro, V., Pennycook, G., and Rand, D. G. (2023). Displaying News Source\nTrustworthiness Ratings Reduces Sharing Intentions for False News Posts. Journal\nof Online Trust and Safety , 1(5). Number: 5.\nEcker, U.K.H., Lewandowsky, S., Cook, J., Schmid, P., Fazio, L.K., Brashier, N., Kendeou,\nP., Vraga, E. K., and Amazeen, M. A. (2022). The psychological drivers of mis-\ninformation belief and its resistance to correction. Nature Reviews Psychology ,\n1(1):13\u201329.\nGonz\u00e1lez-Bail\u00f3n, S., Lazer, D., Barber\u00e1, P., Zhang, M., Allcott, H., Brown, T., Crespo-\nTenorio, A., Freelon, D., Gentzkow, M., Guess, A. M., Iyengar, S., Kim, Y. M.,\nMalhotra, N., Moehler, D., Nyhan, B., Pan, J., Rivera, C. V., Settle, J., Thorson,\nE., Tromble, R., Wilkins, A., Wojcieszak, M., de Jonge, C. K., Franco, A., Mason,\nW., Stroud, N. J., and Tucker, J. A. (2023). Asymmetric ideological segregation\nin exposure to political news on Facebook. Science, 381(6656):392\u2013398. Publisher:\nAmerican Association for the Advancement of Science.\nGrinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B., and Lazer, D. (2019).\nFake news on Twitter during the 2016 U.S. presidential election. Science,\n363(6425):374\u2013378. Publisher: American Association for the Advancement of Sci-\nence Section: Research Article.\nGuess, A.M.andLyons, B.(2020). Misinformation, disinformation, andonlinePropaganda.\nIn Persily, N. and Tucker, J., editors, Social media and democracy: The state of the\nfield, Prospects for reform , pages 10\u201333. Cambridge University Press, Cambridge.\nGuess, A. M., Nyhan, B., and Reifler, J. (2020). Exposure to untrustworthy websites in the\nBest Practices for Source-Based Misinformation Research 35\n2016 US election. Nature Human Behaviour , 4(5):472\u2013480. Number: 5 Publisher:\nNature Publishing Group.\nHallin, D. C. and Mancini, P. (2004). Comparing Media Systems: Three Models of Media\nand Politics . Cambridge University Press. Google-Books-ID: 954NJChZAGoC.\nHeft, A., Kn\u00fcpfer, C., Reinhardt, S., and Mayerh\u00f6ffer, E. (2021). Toward a Transnational\nInformation Ecology on the Right? Hyperlink Networking among Right-Wing Dig-\nital News Sites in Europe and the United States. The International Journal of\nPress/Politics , 26(2):484\u2013504. Publisher: SAGE Publications Inc.\nHeft, A., Mayerh\u00f6ffer, E., Reinhardt, S., and Kn\u00fcpfer, C. (2020). Beyond Bre-\nitbart: Comparing Right-Wing Digital News Infrastructures in Six Western\nDemocracies. Policy & Internet , 12(1):20\u201345. _eprint: https://onlinelibrary.wi-\nley.com/doi/pdf/10.1002/poi3.219.\nLasser, J., Aroyehun, S. T., Carrella, F., Simchon, A., Garcia, D., and Lewandowsky, S.\n(2023). From alternative conceptions of honesty to alternative facts in communica-\ntions by US politicians. Nature Human Behaviour , pages 1\u201312. Publisher: Nature\nPublishing Group.\nLasser, J., Aroyehun, S. T., Simchon, A., Carrella, F., Garcia, D., and Lewandowsky, S.\n(2022). Social media sharing of low-quality news sources by political elites. PNAS\nNexus, 1(4):pgac186.\nLazer, D., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, F.,\nMetzger, M. J., Nyhan, B., Pennycook, G., Rothschild, D., Schudson, M., Sloman,\nS. A., Sunstein, C. R., Thorson, E. A., Watts, D. J., and Zittrain, J. L. (2018). The\nscience of fake news. Science, 359(6380):1094\u20131096.\nLin, H., Garro, H., Wernerfelt, N., Shore, J. C., Hughes, A., Deisenroth, D., Barr, N.,\nBerinsky, A. J., Eckles, D., Pennycook, G., and Rand, D. (2024). Reducing misin-\nformation sharing at scale using digital accuracy prompt ads.\nLin, H., Lasser, J., Lewandowsky, S., Cole, R., Gully, A., Rand, D. G., and Pennycook,\nG. (2023). High level of correspondence across different news domain quality rating\nsets.PNAS Nexus , 2(9):pgad286.\nLuehring et al.\nLorenz-Spreen, P., Oswald, L., Lewandowsky, S., and Hertwig, R. (2022). A systematic re-\nview of worldwidecausal and correlational evidence on digital media and democracy.\nNature Human Behaviour , pages 1\u201328. Publisher: Nature Publishing Group.\nNewman, N., Fletcher, R., Eddy, K., Robertson, C. T., and Nielsen, R. K. (2023). Reuters\nInstitute Digital News Report 2023.\nOsmundsen, M., Bor, A., Vahlstrup, P. B., Bechmann, A., and Petersen, M. B. (2021).\nPartisan Polarization Is the Primary Psychological Motivation behind Political Fake\nNews Sharing on Twitter. American Political Science Review , 115(3):999\u20131015.\nPublisher: Cambridge University Press.\nPennycook, G., Epstein, Z., Mosleh, M., Arechar, A.A., Eckles, D., andRand, D.G.(2021).\nShifting attention to accuracy can reduce misinformation online. Nature, pages 1\u20136.\nPublisher: Nature Publishing Group.\nPratelli, M., Petrocchi, M., Saracco, F., and De Nicola, R. (2023). Swinging in the\nStates: Does disinformation on Twitter mirror the US presidential election system?\narXiv:2303.12474 [cs].\nRobertson, R. E., Green, J., Ruck, D. J., Ognyanova, K., Wilson, C., and Lazer, D. (2023).\nUsers choose to engage with more partisan news than they are exposed to on Google\nSearch.Nature, 618(7964):342\u2013348.\nShao, C., Ciampaglia, G. L., Varol, O., Yang, K.-C., Flammini, A., and Menczer, F.\n(2018). The spread of low-credibility content by social bots. Nature Communi-\ncations, 9(1):4787. Publisher: Nature Publishing Group.\nTay, L. Q., Lewandowsky, S., Hurlstone, M. J., Kurz, T., and Ecker, U. K. H. (2024). Think-\ning clearly about misinformation. Communications Psychology , 2(1):1\u20135. Number:\n1 Publisher: Nature Publishing Group.\nTsfati, Y., Boomgaarden, H. G., Str\u00f6mb\u00e4ck, J., Vliegenthart, R., Damstra, A., and\nLindgren, E. (2020). Causes and consequences of mainstream media dissemi-\nnation of fake news: literature review and synthesis. Annals of the Interna-\ntional Communication Association , 44(2):157\u2013173. Publisher: Routledge _eprint:\nhttps://doi.org/10.1080/23808985.2020.1759443.\nBest Practices for Source-Based Misinformation Research 37\nvan der Linden, S. (2022). Misinformation: susceptibility, spread, and interventions to\nimmunizethepublic. NatureMedicine , 28(3):460\u2013467. Number: 3Publisher: Nature\nPublishing Group.\nVargo, C. J., Guo, L., and Amazeen, M. A. (2018). The agenda-setting power of fake news:\nA big data analysis of the online media landscape from 2014 to 2016. New Media &\nSociety, 20(5):2028\u20132049. Publisher: SAGE Publications.\nWeeks, B. E. and Gil de Z\u00fa\u00f1iga, H. (2021). What\u2019s Next? Six Observations for the Future\nof Political Misinformation Research. American Behavioral Scientist , 65(2):277\u2013289.\nYang, K.-C., Pierri, F., Hui, P.-M., Axelrod, D., Torres-Lugo, C., Bryden, J., and Menczer,\nF. (2021). The COVID-19 Infodemic: Twitter versus Facebook. Big Data & Society ,\n8(1):20539517211013861. Publisher: SAGE Publications Ltd.\nLuehring et al.\nOnline Appendix\n2019 2020 2021 2022 2023 2024\nTime (years)020406080100Trustworthiness\nFigure A.1. Distribution of trustworthiness per year as a violin plot (with M and\nSD), standardized by count.\nBest Practices for Source-Based Misinformation Research 39\n2019 2020 2021 2022 2023 2024 2025\nTime (months)60\n40\n20\n02040Difference in subsequent scores\nFigure A.2. Changesintrustworthinessscoresovertime, calculatedasthedifference\nin scores per news domain between consecutive updates.\nTable A.1: Correlation matrix of journalistic quality criteria.\n1 2 3 4 5 6 7 8 9\n1 1 0.63 0.4 0.56 0.93 0.38 0.39 0.26 0.36\n2 0.63 1 0.57 0.75 0.63 0.58 0.49 0.55 0.56\n3 0.4 0.57 1 0.48 0.4 0.45 0.44 0.34 0.53\n4 0.56 0.75 0.48 1 0.57 0.52 0.51 0.47 0.5\n5 0.93 0.63 0.4 0.57 1 0.39 0.37 0.28 0.39\n6 0.38 0.58 0.45 0.52 0.39 1 0.42 0.48 0.4\n7 0.39 0.49 0.44 0.51 0.37 0.42 1 0.29 0.36\n8 0.26 0.55 0.34 0.47 0.28 0.48 0.29 1 0.47\n9 0.36 0.56 0.53 0.5 0.39 0.4 0.36 0.47 1\nLuehring et al.\n2016 2018 2020 202260708090100NewsGuard scoreThe Left Party\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nAlliance 90/The Greens\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nSPD\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100NewsGuard scoreFDP\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nCDU/CSU\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nAFD\n2019\n2020\n20212022\n2023\n2024A B C\nD E F\nFigure A.3. Reproduction of trustworthiness ratings of sources shared by German\npoliticians on Twitter over time from Lasser et al. (2022). Panel A shows average\nNewsGuard scores in Twitter posts by members of the party DIE LINKE, panel B\nfor members of the Greens, panel C for members of the SPD, panel D for members\nof the FDP, panel E for members of the CDU and CSU, and panel F for members of\nthe AFD.\n2016 2018 2020 202260708090100NewsGuard scoreLabour\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nScottish National Party\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nLiberal Democrat\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100NewsGuard scoreT ory\n2019\n2020\n20212022\n2023\n2024\n2016 2018 2020 202260708090100\nDemocratic Unionist Party\n2019\n2020\n20212022\n2023\n2024A B C\nD E\nFigure A.4. Reproduction of trustworthiness ratings of sources shared by UK politi-\ncians on Twitter over time from Lasser et al. (2022). Panel A shows average News-\nGuard scores in Twitter posts by members of the Labour party, panel B for members\nof the Scottish National Party, panel C for Liberal Democrats, panel D for Tories,\nand panel E for members of the Democratic Unionist Party.\nBest Practices for Source-Based Misinformation Research 41\nTime (months)25303540Number of sourcesAT\nTime (months)50100150Number of sourcesAU\nTime (months)100200300400Number of sourcesCA\nTime (months)100200300Number of sourcesDE\nTime (months)100200300400Number of sourcesFR\nTime (months)0200400Number of sourcesGB\n201920202021202220232024\nTime (months)100200300400500Number of sourcesIT\n201920202021202220232024\nTime (months)5101520Number of sourcesNZ\n201920202021202220232024\nTime (months)400060008000Number of sourcesUS\nFigure A.5. Number of sources over time, per country.\nLuehring et al.\nTrustworthiness0.02.55.07.510.012.515.017.5Number of sourcesAT\nTrustworthiness01020304050Number of sourcesAU\nTrustworthiness050100150200250Number of sourcesCA\nTrustworthiness0255075100125150175200Number of sourcesDE\nTrustworthiness020406080100120Number of sourcesFR\nTrustworthiness050100150200250Number of sourcesGB\n0 25 50 75 100\nTrustworthiness050100150200Number of sourcesIT\n0 25 50 75 100\nTrustworthiness01234567Number of sourcesNZ\n0 25 50 75 100\nTrustworthiness025050075010001250150017502000Number of sourcesUS\nFigure A.6. Distribution of trustworthiness per country as of July, 2024.\nBest Practices for Source-Based Misinformation Research 43\nTime (months)556065707580859095TrustworthinessAT\nTime (months)TrustworthinessAU\nTime (months)TrustworthinessCA\nTime (months)556065707580859095TrustworthinessDE\nTime (months)TrustworthinessFR\nTime (months)TrustworthinessGB\n2019 2020 2021 2022 2023 2024\nTime (months)556065707580859095TrustworthinessIT\n2019 2020 2021 2022 2023 2024\nTime (months)TrustworthinessNZ\n2019 2020 2021 2022 2023 2024\nTime (months)556065707580859095TrustworthinessUS\nFigure A.7. Trustworthiness per country over time, aggregated by month.\nLuehring et al.\nTable A.2: Overlap between GOND and NewsGuard.\nGOND Type NewsGuard Score Overlap %\ncommercial broadcaster 89.4 58 10.5\ndigital-born news outlet 84.5 66 12.0\nhyperpartisan news 43.0 56 10.1\nlegacy press 91.0 292 52.9\npublic broadcaster 89.0 40 7.2\ntabloid newspaper 84.6 40 7.2\nNote.As of July 15th, 2024.\nTable A.3: Orientation per country.\nOrientation Left (%) Right (%) Total\nCountry\nUS 401 (12.45) 2819 (87.55) 3220\nFR 36 (41.86) 50 (58.14) 86\nIT 18 (25.35) 53 (74.65) 71\nDE 10 (16.13) 52 (83.87) 62\nGB 30 (50.85) 29 (49.15) 59\nAU 9 (31.03) 20 (68.97) 29\nCA 8 (33.33) 16 (66.67) 24\nAT 2 (18.18) 9 (81.82) 11\nNZ 1 (25.0) 3 (75.0) 4\nNote.As of September 15h, 2024.\nBest Practices for Source-Based Misinformation Research 45\n0246810Number of sourcesAT\n0510152025Number of sourcesAU\n0510152025Number of sourcesCA\n020406080Number of sourcesDE\n020406080Number of sourcesFR\n0204060Number of sourcesGB\n201920202021202220232024\nTime (years)020406080Number of sourcesIT\n201920202021202220232024\nTime (years)01234Number of sourcesNZ\n201920202021202220232024\nTime (years)0100020003000Number of sourcesUSOrientation\nFar Left Slightly Left Slightly Right Far Right Left Right\nFigure A.8. Distribution of political orientation over time, by country\nLuehring et al.\n2019-102020-012020-042020-072020-102021-012021-042021-072021-102022-012022-042022-072022-112023-022023-052023-082023-112024-022024-052024-08\nTime (months)020004000600080001000012000Number of sourcesT otal\nWith topics\nFigure A.9. Number of sources over time with and without topic labels.\nBest Practices for Source-Based Misinformation Research 47\n0 10 20 30\nNumber of ratingsPolitical news\nGeneral news\nLocal news\nEntertainment\nCelebrity newsT opicsAT\n0 25 50 75\nNumber of ratingsGeneral news\nLocal news\nPolitical news\nLifestyle\nEntertainmentT opicsAU\n0 100 200 300\nNumber of ratingsLocal news\nGeneral news\nPolitical news\nHealth news\nEntertainmentT opicsCA\n0 100 200\nNumber of ratingsPolitical news\nLocal news\nGeneral news\nConspiracies\nHealth newsT opicsDE\n0 50 100\nNumber of ratingsPolitical news\nLocal news\nGeneral news\nHealth news\nConspiraciesT opicsFR\n0 100 200\nNumber of ratingsPolitical news\nBusiness\nLocal news\nGeneral news\nHealth newsT opicsGB\n0 100 200\nNumber of ratingsGeneral news\nLocal news\nPolitical news\nHealth news\nConspiraciesT opicsIT\n0 5 10\nNumber of ratingsLocal news\nPolitical news\nGeneral news\nLifestyle\nEntertainmentT opicsNZ\n0 1000 2000 3000\nNumber of ratingsPolitical news\nLocal news\nGeneral news\nConspiracies\nHealth newsT opicsUS0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\n0 25 50 75 100Trustworthiness\nFigure A.10. Top five most popular topics per country and their total count,\nwith the second x-axis at the top showing the average trustworthiness and standard\ndeviations of those topics..\nLuehring et al.\n0 20 40 60 80 100\nTrustworthinessPolitical news\nLocal news\nGeneral news\nConspiracies\nHealth newsT opic\nAT AU CA DE FR GB IT NZ US\nFigure A.11. Trustworthiness score for the top five most popular topics across\ncountries in the most recent database (September 15, 2024).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Best practices for source-based research on misinformation and news trustworthiness", "author": ["J L\u00fchring", "H Metzler", "R LAZZARONI", "A Shetty", "J Lasser"], "pub_year": "2024", "venue": "NA", "abstract": "Luehring et al. as Germany and Italy. In addition to trustworthiness ratings, the NewsGuard  database contains various contextual assessments of the sources, which are less often used"}, "filled": false, "gsrank": 46, "pub_url": "https://files.osf.io/v1/resources/v6e4b/providers/osfstorage/66ebeada31d99d88ca1c41db?format=pdf&action=download&direct&version=1", "author_id": ["9FQdKwwAAAAJ", "fpkiNJYAAAAJ", "GIkOsq8AAAAJ", "Qx2eJ0YAAAAJ", "vVrhda0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:_7XVyUrXkIIJ:scholar.google.com/&output=cite&scirp=45&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D40%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=_7XVyUrXkIIJ&ei=C7WsaMuIJazWieoPic2ZoAU&json=", "num_citations": 2, "citedby_url": "/scholar?cites=9408256337790744063&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:_7XVyUrXkIIJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://files.osf.io/v1/resources/v6e4b/providers/osfstorage/66ebeada31d99d88ca1c41db?format=pdf&action=download&direct&version=1"}}, {"title": "Monant medical misinformation dataset: Mapping articles to fact-checked claims", "year": "2022", "pdf_data": "Monant Medical Misinformation Dataset: Mapping Articles to\nFact-Checked Claims\nIvan Srba\nKempelen Institute of Intelligent\nTechnologies\nBratislava, Slovakia\nivan.srba@kinit.skBranislav Pecher\u2217\nFaculty of Information Technology,\nBrno University of Technology\nBrno, Czech Republic\nbranislav.pecher@kinit.skMatus Tomlein\nKempelen Institute of Intelligent\nTechnologies\nBratislava, Slovakia\nmatus.tomlein@kinit.sk\nRobert Moro\nKempelen Institute of Intelligent\nTechnologies\nBratislava, Slovakia\nrobert.moro@kinit.skElena Stefancova\nKempelen Institute of Intelligent\nTechnologies\nBratislava, Slovakia\nelena.stefancova@kinit.skJakub Simko\nKempelen Institute of Intelligent\nTechnologies\nBratislava, Slovakia\njakub.simko@kinit.sk\nMaria Bielikova\u2020\nKempelen Institute of Intelligent\nTechnologies\nBratislava, Slovakia\nmaria.bielikova@kinit.sk\nABSTRACT\nFalse information has a significant negative influence on individuals\nas well as on the whole society. Especially in the current COVID-19\nera, we witness an unprecedented growth of medical misinforma-\ntion. To help tackle this problem with machine learning approaches,\nwe are publishing a feature-rich dataset of approx. 317k medical\nnews articles/blogs and 3.5k fact-checked claims. It also contains\n573 manually and more than 51k automatically labelled mappings\nbetween claims and articles. Mappings consist of claim presence,\ni.e., whether a claim is contained in a given article, and article stance\ntowards the claim. We provide several baselines for these two tasks\nand evaluate them on the manually labelled part of the dataset.\nThe dataset enables a number of additional tasks related to medical\nmisinformation, such as misinformation characterisation studies or\nstudies of misinformation diffusion between sources.\nCCS CONCEPTS\n\u2022Information systems \u2192Web mining ;Document representation ;\u2022\nComputing methodologies \u2192Natural language processing ;\nMachine learning .\nKEYWORDS\nmedical misinformation, dataset, fact-checking, Monant platform\n\u2217Also with Kempelen Institute of Intelligent Technologies.\n\u2020Also with slovak.AI.\nSIGIR \u201922, July 11\u201315, 2022, Madrid, Spain\n\u00a92022 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nThis is the author\u2019s version of the work. It is posted here for your personal use. Not\nfor redistribution. The definitive Version of Record was published in Proceedings of the\n45th International ACM SIGIR Conference on Research and Development in Information\nRetrieval (SIGIR \u201922), July 11\u201315, 2022, Madrid, Spain , https://doi.org/10.1145/3477495.\n3531726.ACM Reference Format:\nIvan Srba, Branislav Pecher, Matus Tomlein, Robert Moro, Elena Stefancova,\nJakub Simko, and Maria Bielikova. 2022. Monant Medical Misinformation\nDataset: Mapping Articles to Fact-Checked Claims. In Proceedings of the\n45th International ACM SIGIR Conference on Research and Development in\nInformation Retrieval (SIGIR \u201922), July 11\u201315, 2022, Madrid, Spain. ACM, New\nYork, NY, USA, 11 pages. https://doi.org/10.1145/3477495.3531726\n1 INTRODUCTION\nFalse information on the Web has been a widely researched phe-\nnomenon in computer science for the past few years, as evidenced\nby many recent surveys, e.g., [ 2,10,34,44,47,48]. The main focus\nwas initially on political fake news; however, it shifted towards the\nmedical domain with the arrival of COVID-19 pandemic and an in-\nfodemic (a surge of new misinformation1related to the COVID-19).\nMotivated by significant negative consequences of online false\ninformation, a number of approaches based on information retrieval\nand machine learning have been proposed to detect it. The main\nbranch of existing works rely on indirect features derived from\ncontent (textual as well as multimedia) and context, such as con-\ntent style, propagation patterns, author/source credibility, or social\nengagements/consumption [ 47]. This approach has several advan-\ntages, e.g., it allows to detect new cases of false information early\n(since new false information usually share similar characteristics\nwith prior cases). On the other hand, the existing methods usually\nprovide only limited single-label classification (typically a binary\none \u2013 a news article/blog/social media post is/is not a piece of false\ninformation), have insufficient explainability, and, in addition, they\nmay suffer from domain shifts (either natural changes in domain\ncharacteristics or targeted adversarial attacks).\n1We use the term misinformation to describe false or misleading information that is\ncreated and spread regardless of an intention to deceive, in contrast to disinformation ,\nwhich refers specifically to false information created and spread deliberately.arXiv:2204.12294v1  [cs.CL]  26 Apr 2022\nSIGIR \u201922, July 11\u201315, 2022, Madrid, Spain Srba et al.\nAnother branch of knowledge-based approaches evaluates the ac-\ntual content veracity by performing a fact-checking . Fact-checking\nstands for detection and verification of a claim, such as \u201cDrinking\nbleach or pure alcohol can cure the coronavirus infections\u201d2, against\na knowledge base (e.g., scientific articles [ 15], articles from sources\ndeemed reliable, such as Wikipedia [ 37], or knowledge graphs of\nknown facts [ 45,46]). This approach may be preferable in many\nsituations, including tackling false information in medical domain\nthat (from its inherent characteristics) requires accurate, easily\nexplainable and robust approaches for misinformation detection.\nFact-checking can be done either manually by professional fact-\ncheckers or (semi-)automatically with the help of AI. Manual fact-\nchecking is time consuming and, yet, scale-insufficient. On the\nother hand, fully automatic end-to-end fact-checking (e.g., [ 16]) is a\nchallenging task and existing solutions have not yet achieved a suf-\nficient accuracy, generality, and credibility [ 24]. The real promise of\ntechnologies for now lies in tools to assist fact-checkers to identify\nand investigate claims, and to deliver their conclusions as effectively\nas possible [9, 24].\nAI research may assist fact-checkers in the following steps of the\nfact-checking process [ 24,42]: 1) identification of claims worth fact-\nchecking, 2) detection of previously fact-checked claims relevant\nto the identified fact-check-worthy claims, 3) retrieving relevant\nevidence to fact-check a claim, and 4) verification of the claim\nbased on the retrieved evidence. In addition, the set of already fact-\nchecked claims can be mapped back to additional (already existing\nor new) online content. While similar to step 2 above, here the input\nis a fact-checked claim and the output a list of articles containing the\nclaim. Thus, it can be viewed as the fifth (dissemination) step in the\nfact-checking process, which is typically not done in manual fact-\nchecking as it is difficult or even impossible for the fact-checkers\nto manually find/update such relevant content [ 40]. Especially in\nmedical domain, many misinformative articles reuse claims, which\nhave already been expertly fact-checked, thus making the use of\nexisting databases of fact-checks feasible.\nAI-based fact-checking support in the multiple steps above is\nfundamentally based on document to claim mapping (document\nbeing a news article/blog, a social media post, etc.) and more specif-\nically on two IR/NLP tasks: presence detection andstance classifi-\ncation [1,3,12,13,26,39,43]. The detection of previously fact-\nchecked claims (step 2), became a target of research interest only\nrecently [ 28] and is one of the least studied research problems re-\nlated to fact-checking [ 24]. It is typically addressed at the claim to\nclaim level, i.e., previously fact-checked claims are ranked based\non their relevance for a single given claim [ 21,28]. Nevertheless,\nvery recently, Shaar et al. [ 27] formulated a more challenging ver-\nsion of this task as identification of all previously fact-checked\nclaims in an input document (that can potentially contain multiple\ncheck-worthy claims). The task includes detection of a document\u2019s\nsentences containing any of the previously fact-checked claims and\nthe stance of these sentences towards the present claims. Presence\ndetection and stance classification are also crucial for the other steps\nof the fact-checking process. In step 4, presence of an investigated\nclaim is detected to retrieve evidence and then its stance towards\n2https://www.who.int/emergencies/diseases/novel-coronavirus-2019/advice-for-\npublic/myth-bustersthe claim is used to verify factuality of the claim. Finally, both pres-\nence and stance are used in step 5 to map already fact-checked\nclaims to additional documents [40].\nWhile situation with datasets for the first branch of false infor-\nmation detection (based on content and contextual characteristics)\ncontinually improves (cf. Section 2), datasets for AI research on\nfact-checking, particularly datasets providing a mapping between\ndocuments and claims (claim presence and document stance), still\npresent a major problem hampering further research.\nIn this paper, we are introducing a novel medical misinformation\ndataset . It contains:\n\u2022full-texts, original source URL, and other extracted metadata\nof approx. 317k news articles and blog posts on medical\ntopics published between January 1, 1998 and February 1,\n2022 from a total of 207 reliable and unreliable sources;\n\u2022annotations with a source credibility score from expertly-\ncurated lists, such as Media Bias/Fact Check, when it is avail-\nable;\n\u2022around 3.5k fact-checks and extracted verified medical claims\nwith their unified veracity ratings published by fact-checking\norganisations such as Snopes or FullFact;\n\u2022573 manually and more than 51k automatically labelled map-\npings between previously verified claims and the articles;\nmappings consist of two values: claim presence (i.e., whether\na claim is contained in a given article) and article stance\n(i.e., whether a given article supports or rejects a claim or\nprovides both sides of the argument).\nThe dataset is primarily intended to be used as a training and\nevaluation set for machine learning methods for claim presence\ndetection and article stance classification, but it enables a range of\nother misinformation related tasks, such as misinformation charac-\nterisation, analyses of misinformation spreading or classification\nof source reliability. Its novelty and our main contributions lie in:\n(1)focus on medical news articles and blog posts as opposed to\nsocial media posts or political discussions;\n(2)providing multiple modalities (beside full-texts of the articles,\nthere are also images and videos), thus enabling research of\nmultimodal approaches;\n(3)mapping of the articles to the fact-checked claims (with\nmanual as well as predicted labels);\n(4)providing source credibility labels for 95% of all articles and\nother potential sources of weak labels that can be mined\nfrom the articles\u2019 content and metadata.\nThe dataset has been collected with our universal and extensible\nplatform Monant [ 35], which was designed to monitor, detect, and\nmitigate false information. We are publishing a static dump of the\ndataset3. Moreover, the dataset in Monant is being continuously\nupdated with latest articles and fact-checked claims from medical\nand other domains (e.g., general news) and also in languages other\nthan English (currently in Slovak and Czech). To access the live\n3A sample of the data together with accompanying documentation and analyses in\nJupyter notebooks is available at https://github.com/kinit-sk/medical-misinformation-\ndataset/. The full static dump is available at https://doi.org/10.5281/zenodo.5996864.\nMonant Medical Misinformation Dataset SIGIR \u201922, July 11\u201315, 2022, Madrid, Spain\nversion of the dataset, the Monant platform provides an easy-to-use\naccess by the means of a REST API4.\n2 EXISTING DATASETS\nThe majority of existing datasets [ 32] are created for purpose of\nsingle-label false information detection. They are commonly anno-\ntated only by some simple heuristics (e.g., the veracity of articles is\ndetermined by the credibility of their sources5[14,17,18]). How-\never, such heuristics do not necessarily capture the real veracity of\nthe articles (e.g., articles published by reliable sources may some-\ntimes contain misinformative content and vice versa) and, therefore,\nshould be used only as weak labels. Contrary to that, datasets an-\nnotated manually remain small or not fully annotated (e.g., just by\nits title [41]).\nAnother way to create single-label fake news datasets is to take\nadvantage of fact-checks \u2013 by following a direct link from fact-\nchecking articles to debunked online content (news article/blogs,\nsocial media posts, etc.). Examples of such datasets are FakeNews-\nNet [ 33] (rich dataset providing social context from Twitter), Fake-\nCovid dataset [ 31] (providing 5,182 fact-checking articles related\nto COVID-19 circulated in 105 countries from 92 fact-checkers,\nhowever, without the debunked content itself), CoAID dataset [ 5]\n(providing the mapping of fact-checking articles to debunked con-\ntent, although the number of news articles covered by the dataset\nis quite small), or FakeHealth dataset [ 6] (providing expertly anno-\ntated news stories published at HealthNewsReview.org6together\nwith their social engagements on Twitter). These datasets do not\nwork explicitly with claims themselves and mostly use fact-checks\njust to transfer veracity label to the original content. Thus, their suit-\nability for training AI models to support steps in the fact-checking\nprocess is limited.\nSpecific fact-checking datasets [ 11,42] are therefore created to\nsupport individual steps of fact-checking process by researchers as\nwell as in data challenges (most prominently at CLEF CheckThat!\nLab7, e.g., [ 29,30]). Most of them are focused on political domain\n(political debates) and short social media posts (mostly from Twit-\nter [22], Facebook8, or Reddit [ 23]). However, fact-checking datasets\nfocused on medical domain and providing mappings between claims\nand larger documents (such as news articles and blogs) are generally\nlacking. This presents a problem, because even though social media\nplay a significant role in creation and dissemination of medical\nmisinformation [ 36], many people are exposed to it also when they\nsearch online for health-related issues (which is done by 72% of\nadult internet users according to Pew Research Center9). In [ 40],\nthe authors created a large manually-annotated dataset (covering\ndifferent domains). They mapped fact-checking articles to relevant\ndocuments containing the fact-checked claims along with stance of\nthe documents. Unfortunately, this dataset is not public. Recently,\nShaar et al. [ 27] created a dataset providing presence and stance\n4Request for REST API access can be submitted at: https://doi.org/10.5281/zenodo.\n5996864\n5https://github.com/several27/FakeNewsCorpus, https://www.kaggle.com/mrisdal/\nfake-news\n6https://www.healthnewsreview.org/\n7https://sites.google.com/view/clef2022-checkthat/home\n8https://github.com/BuzzFeedNews/2016-10-facebook-fact-check\n9https://www.pewresearch.org/fact-tank/2014/01/15/the-social-life-of-health-\ninformation/mappings between larger documents and previously fact-checked\nclaims, nevertheless, the dataset is not available yet and it is focused\non political fact-checked claims only.\nWe can conclude that a publicly available, feature-rich, and large\nenough dataset containing medical news articles/blogs with labelled\nmappings between articles and fact-checked claims is still missing.\nIn contrast to the described datasets, our work specifically focuses\non creating a dataset containing news articles/blogs only. Focusing\non one content type allows us to extract a rich set of metadata\n(e.g., articles\u2019 authors, sources, categories). To achieve a large set\nof labelled data, we do not rely on links between fact-checking\narticles and news articles/blogs, which are often missing. Rather, we\nprovide both manually human-created and automatically predicted\nlabels of claim presence and article stance which we aggregate into\narticle-claim pair veracities.\n3 METHODOLOGY\n3.1 Data collection methodology\nTo create a medical misinformation dataset of news articles/blogs\nand fact-checked claims (and to continuously obtain new data), we\nused our research platform Monant [ 35]. Scraping of the relevant\nweb content and extraction of metadata is implemented by the\nmeans of so called monitors and data providers . Data providers\nimplement the scraping functionality. General parsers (from RSS\nfeeds, WordPress sites, Google Fact Check Tool10, etc.) as well as\ncustom crawlers and parsers were implemented (e.g., for the fact-\nchecking site Snopes). Monitors define which data providers should\nbe used, their scheduling (i.e., frequency of extractions), parameters\nsetup (e.g., a list of RSS feed URLs used as an input to the RSS feed\nparser), and data provider chaining (if additional data providers\nshould be chained, e.g., when a new article is found). All data is\nstored in a unified format in a central data storage.\nTo compile a list of medical English news sites/blogs and to deter-\nmine their credibility, we used expertly-curated lists of reliable and\nunreliable sites (e.g., Media Bias/Fact Check11or OpenSources12)\nand previous related works (e.g., [ 7]). We added additional sources\nof unknown credibility that were often referenced (linked) by the\nsources in the initial list. Next, we checked for each source, whether\nit still existed and how the data could be obtained from it (e.g., using\na WordPress or RSS feed parser or if it required a custom parser).\nWe ended up with a list of 207 medical sources in English; we have\na credibility (reliability) score for 70 of them. Examples of reliable\n(credible) sources include healthline.com, or who.int; examples of\nsources marked by the listings as unreliable are naturalnews.com,\nor healthimpactnews.com. Most of these sources contain only med-\nical content and thus no additional content selection was needed.\nIf a source contained articles falling under multiple topics (e.g.,\npolitics, home news), we restricted the scraping only to a category\ncorresponding to medical/health news/blogs.\nNext, we searched for fact-checking sources that also perform\nfact-checking of medical claims; we compiled a list of 7 of them\n(namely Snopes.com, MetaFact.io, FactCheck.org, Politifact.com,\n10https://toolbox.google.com/factcheck/explorer\n11https://mediabiasfactcheck.com/conspiracy/\n12https://github.com/BigMcLargeHuge/opensources\nSIGIR \u201922, July 11\u201315, 2022, Madrid, Spain Srba et al.\nFullFact.org, HealthFeedback.org, and ScienceFeedback.co). Sim-\nilarly to the case of news sites/blogs, we either collected all fact-\nchecking articles in the case of medical-only fact-checking sites or\nrelied on categories manually assigned by the expert fact-checkers.\nSince the fact-checked claims in the selected sources are explicitly\nstated by the fact-checkers, it was possible to automatically extract\nclaims from the fact-checking articles. Additional claims were sup-\nplemented from the list of unproven cancer treatments published\nby [8]. As veracity ratings can differ between fact-checkers, we\nunified them into a scale of 6 values: false, mostly false, true, mostly\ntrue, mixture, and unknown (meaning a veracity of the claim could\nnot be evaluated by a fact-checker or experts\u2019 consensus has not\nbeen reached yet). The latter originates mostly from the MetaFact.io\nsite, where the experts\u2019 evaluations are crowdsourced (in compari-\nson with other fact-checking portals where the fact-checking pro-\ncess is typically done by one expert only) and the claim veracity\nis determined only when the evaluation of a sufficient number of\nexperts is available.\n3.2 Data labelling methodology\nOur aim was to obtain manual ground-truth labels of claim presence ,\ni.e., whether a given verified (fact-checked) claim is present in an\narticle, and of article stance , i.e., what the stance of the article is to-\nwards the matched claim. Our proposed data labelling methodology\nwas inspired by the work of Wang et al. [ 40]. The labelling is per-\nformed in four steps: First, we identify possible article-claim pairs\nto label. Second, the pairs are distributed to annotators in batches\nguaranteeing that one pair is given to multiple annotators to min-\nimise possible mistakes in the labelling process and that the same\nannotator never sees the same pairs multiple times, even across\nbatches. Next, the pairs are annotated by the annotators. Lastly,\nthe labels from all annotators are aggregated into a single claim\npresence and article stance label for each labelled article-claim pair.\nA total number of 28 annotators participated in the labelling\nprocess, including the authors of this paper, master students, and\nother researchers. To prevent potential subjectivity and low-quality\nlabels, a match of at least two annotators had to be achieved for\nthe label to be included into the dataset. When there was no match\nbetween the first two annotators, the article-claim pair was assigned\nto up to 3 additional ones to collect more labels. Overall, inter-\nannotator agreement was high; additional annotator was required\nonly in 8.57% of cases for claim presence and in 6.94% of cases for\narticle stance labels. In quite rare cases, when the agreement was\nnot reached (covering difficult to annotate or disputable cases), the\narticle-claim pair was disregarded.\n3.2.1 Labels and their aggregation. To annotate claim presence, the\nannotators could select one of four possible labels:\n(1)Present \u2013 when the annotator can find a part of the article\n(a sentence or a paragraph) that literally or semantically\ncontains the claim.\n(2)Suggestive \u2013 when the article relates to the claim, but the\nannotator cannot identify any specific part of the article that\ncontains it (e.g., an article discusses the flu vaccine efficacy\nand suggests that they are ineffective or even harmful by\nproviding anecdotal evidence but never explicitly makes that\nclaim).(3)Not present \u2013 when the claim is not present in the article.\n(4)Can\u2019t tell \u2013 when the annotator cannot, for some reason,\nchoose any of the options above.\nWhen the annotators selected either \u201cPresent\u201d or \u201cSuggestive\u201d\nlabel, they were further asked to label the stance of the article\ntowards the identified claim, by selecting one of four possible labels:\n(1)Supporting \u2013 when the article supports the claim (directly\nor indirectly from its context).\n(2)Contradicting \u2013 when the article contradicts the claim (di-\nrectly or indirectly from its context).\n(3)Neutral \u2013 when the article does not take a stand on the\nclaim or presents arguments both forandagainst the claim.\n(4)Can\u2019t tell \u2013 when the annotator cannot, for some reason,\nchoose any of the options above.\nThe individual article-claim pair labels are aggregated as follows:\nFirst, we filter out all \u201cCan\u2019t tell\u201d labels. Next, if any of the remain-\ning claim presence or article stance labels was chosen by two or\nmore annotators for a given article-claim pair, this label is assigned\nas the final aggregated one. In case of no match in claim presence\nlabels, we lower the requirement by joining the \u201cPresent\u201d and \u201cSug-\ngestive\u201d labels into one and check again for a match. If a match is\nfound, we assign a \u201cSuggestive\u201d label as the final aggregate claim\npresence label. It is also worth noting that article stance labels can\nbe evaluated only when a given claim is present in the article. As a\nresult, there is a lower number of article stance labels compared to\nthe number of claim presence ones.\n3.2.2 Selection of article-claim pairs for labelling. The number of\nall possible article-claim pairs is equal to the number of claims times\nthe number of articles, which is far too many to label. Moreover,\nmost of them would be irrelevant, i.e., they would consist of claims\ncompletely unrelated to the articles. To deal with this problem, we\nselect for labelling only a subset of pairs with a high possibility to\nbe relevant. We used two selection methods during our labelling.\nAt first, we used ElasticSearch to select a subset of the article-\nclaim pairs. More specifically, we used each claim in turn as a\nquery to find matching articles. This returned a large set of articles\nalong with the BM25 score for each article. We kept only articles\nwith the score higher than the2\n3of the maximum score, i.e., the\nscore associated with the first matched article. We then shuffled the\nresulting set of article-claim pairs and sampled two batches, each\nwith 100 random pairs, i.e., 200 pairs in total. We split them among\nsix annotators so that each pair was assigned to three annotators.\nThe annotations were collected using spreadsheets: each annotator\nwas assigned one sheet per batch, with each row describing a single\narticle-claim pair. For each article-claim pair, the annotators were\npresented with the title of the article, the claim, article URL and the\nclaim URL for information.\nHowever, this selection method led to a significant class imbal-\nance. Out of 197 article-claim pairs, where there was an agreement\nbetween the annotators, the claims were labelled as present only in\n\u223c10% of cases, which also limited the number of stance annotations.\nWe also observed a relatively large number of \u201cCan\u2019t tell\u201d labels\nwhich were caused by several claims. These mostly too generic\nclaims (e.g., \u201cThere are more doctors\u201d) were mistakenly matched\nMonant Medical Misinformation Dataset SIGIR \u201922, July 11\u201315, 2022, Madrid, Spain\nwith many articles. The former was addressed by using our pro-\nposed claim presence detection baseline (cf. Section 5.1) instead of\nthe simple querying in ElasticSearch. To mitigate the latter, we man-\nually filtered out these problematic claims from further labelling.\nWe also switched from spreadsheets to a custom-made web-\nbased annotation application, suitable also for mobile devices, which\nenabled us to reach a wider range of annotators. The application\nstreamlined the annotation process and the article-claim pairs dis-\ntribution to the annotators. The article-claim pairs were served to\nannotators until a match of at least two annotators was achieved\nin the values of claim presence as well as the article stance. Pairs\nwith at least one label, but where no consensus had been achieved\nyet, were served to the annotators with a higher priority to keep\nthe \u201cunfinished\u201d pair labels to a minimum.\nEach article-claim pair was presented in the application as shown\nin Figure 1. The claim was presented at the top, visually separated\nfrom the rest of the presented content. Underneath the claim, the\ntitle of the article, followed by its formatted body, was presented to\nthe annotators. On the bottom, the annotators were presented with\nbuttons for assigning the claim presence label and\u2014if the annota-\ntors chose that the claim is present in the article\u2014also the article\nstance label. As the articles were long and often dealt with multiple\nclaims at the same time, we used a supportive text highlighting\nfeature: the application highlighted sentences in the article that\nwere most similar to the claim. The similarity was determined by\ncosine similarity between a sentence embedding representation\nof the given claim and the sentences of the article. Using this ap-\nproach, we collected additional 376 article-claim pair labels from\n28 annotators.\nThe collection of labels was also distributed in time. First 439\narticle-claim pairs (denoted as Sample 1 in sections below) were\nannotated in 2019 and early 2020; since this was before the onset of\nthe COVID-19 pandemic, this sample does not contain any claims or\narticles pertinent to it. The remaining 134 pairs (denoted as Sample\n2in sections below) were annotated in June 2021, thus capturing\nalso narratives spread in that time.\n4 DATASET DESCRIPTION\n4.1 Descriptive analysis of raw data\nThe dataset consists of medical news articles/blogs and fact-checked\nclaims in English language. However, the Monant platform, which\nwas used to collect the dataset and makes it accessible via an API\nendpoint, also collects articles from other domains (e.g., politics\nor general news) and in other languages (currently mostly in Slo-\nvak and Czech). Out of approx. 885k unique news articles/blogs\nfrom 256 sources, there are 317k English medical articles from 207\nsources.13Out of approx. 10k fact-checking articles extracted from\n17 fact-checking sites, there are 3.5k fact-checked medical claims\nfrom 7 fact-checking sites. And out of approx. 780k discussion posts\n(related to 48k articles), there are 711k discussions posts attached to\nEnglish medical articles. In the following analyses, we focus specif-\nically on English medical data contained in the provided dataset.\n13The content of this section and section 5.3 is based on the dataset\u2019s analysis published\nat: https://github.com/kinit-sk/medical-misinformation-dataset/. To make the analysis\nreplicable, it uses a \u201cfreeze time\u201d set to February 1, 2022. As a result, only the data, that\nwere present in the Monant platform up to this date, are considered.\nFigure 1: The mobile interface of the annotation application\nused in the later stage of article-claim pairs labelling. The\nannotators were presented with an article, a claim at the top,\nhighlighted most similar sentence and buttons for selecting\nclaim presence and article stance labels.\nThe dataset provides a rich set of features about each article.\nBesides an article\u2019s URL, title, textual body, and attached multimedia,\nit also contains information about article\u2019s authors, category, tags,\nand references. In addition, we collect (in regular intervals) the\nusers\u2019 feedback on Facebook (i.e., the number of likes or shares)\nfor each news article. In some cases, the posts from the attached\ndiscussions are available as well.\nFor 70 sources, we have an explicit source reliability (credibility)\nlabel (cf. Section 3.1 for more details): 22 sources are considered to\nbe reliable sources, 48 sources are considered to be unreliable. Out\nof all medical articles, 39% were collected from reliable sources, 56%\nfrom unreliable sources, and only 5% articles are from the sources\nwithout any reliability label.\nWherever possible, we collected all articles published by a given\nsource. Consequently, some of the articles in the dataset were pub-\nlished as soon as 1998. Nevertheless, the majority of the collected\nnews articles were published between years 2010\u20132021 as shown in\nFigure 2. We can see an increasing trend in the number of medical\nnews articles, with a significant increase in the last three years\n(the extreme rise in year 2020 can be explained by the onset of the\nCOVID-19 pandemic).\nFigure 3 shows the distribution of veracity ratings of the fact-\nchecked medical claims contained in the dataset. 983 were evaluated\nas false, 60 as mostly false, 100 as mixture, 39 as mostly true, and\n259 as true. The rating of a significant number of claims (originating\nmostly from MetaFact.io, cf. Section 3.1) is currently unknown.\nSIGIR \u201922, July 11\u201315, 2022, Madrid, Spain Srba et al.\n2000 2005 2010 2015 2020\nYear0100002000030000400005000060000Number of articles\nFigure 2: Number of collected medical articles in our dataset\naccording to their publication year.\nFalseMostlyfalseMixtureMostlytrueTrue\nunknown\nRating0500100015002000Number of claims\nFigure 3: Number of medical claims in our dataset according\nto their veracity rating.\n4.2 Labelled dataset\nThe dataset contains 573 article-claim pairs labelled by human anno-\ntators. There are 323 pairs annotated with positive claim presence\nlabels, out of which 309 also have article stance labels. The overall\ndistribution of the claim presence and article stance labels is shown\nin Table 1. It also shows distributions for individual Samples 1 and\n2. As we can see, while there is a balance between present and not\npresent labels in Sample 1 as well as overall, Sample 2 is skewed\ntowards present labels. As to the article stance, most articles sup-\nport the matched claims. There is a lack of \u201cNeutral\u201d stance labels\nin our dataset, i.e., of articles that would present both sides of the\nargument. This can make it difficult for models trained on this data\nto correctly classify this stance class.\nBesides the labels from human annotators, the dataset also con-\ntains approx. 51k article-claim pairs with labels predicted by our\nproposed baselines. Their analysis is provided in Section 5.3.\n4.3 Downstream tasks\nThe collected dataset can support a range of fact-checking and\nmisinformation-related tasks. Its main intended use is for training\nand evaluation of machine learning methods for the tasks of claim\npresence detection andarticle stance classification . The former can\nbe considered a claim-oriented document retrieval problem, i.e.,\ngiven a fact-checked claim, all documents, where it is present, areTable 1: Distribution of claim presence and article stance la-\nbels in the dataset.\nSample 1 Sample 2 Overall\nClaim presence\nPresent (incl. Suggestive) 222 (51%) 101 (75%) 323 (56%)\nNot present 217 (49%) 33 (25%) 250 (44%)\nTotal 439 134 573\nArticle stance\nSupporting 129 (61%) 74 (75%) 203 (66%)\nContradicting 62 (30%) 24 (24%) 86 (28%)\nNeutral 19 (9%) 1 (1%) 20 (6%)\nTotal 210 99 309\nretrieved; or, alternatively, as previously fact-checked claims de-\ntection, i.e., given an unverified piece of text or claim, all relevant\npreviously fact-checked claims are retrieved [ 29]. The latter is a\nclassification problem; the aim is to detect stance (position) of the\nauthor of an input piece of text towards a specified target [20].\nSince the dataset contains articles from a number of reliable\nand unreliable sources, it could be used for the misinformation\ncharacterisation task, i.e., for analyses of characteristics of articles\n(how they are written) similar to [ 7]: what topics they cover and\nhow these topics evolve over time. The mapping of articles to fact-\nchecked claims provides a straightforward grouping of the articles\nbased on the misinformation they are related to.\nThe misinformation sources often create inter-connected net-\nworks which spread and amplify the false information [ 19]. Since\nthe dataset contains full-texts of the articles, it supports the task\nofmisinformation spreading/diffusion analysis . For example, it is\npossible to analyse linking patterns between the sources, search\nfor content that is similar or even taken over from other sources,\netc. Having a publication date of the articles, it is also possible to\nanalyse where the misinformation first appeared and when (how\nfast) it was taken up by other sources. This is especially relevant\nwith respect to the spread of misinformation between countries\nand across languages. Since the data available in Monant via an API\nendpoint also contain non-English sources (at this moment Slovak\nand Czech), it can be used to develop and test multilingual methods\nand analyse spreading patterns from English-language sources to\nother languages and (possibly) vice-versa.\nBesides text, the dataset contains other modalities, such as image\nURLs, article and source metadata, etc. These can be all utilised to\ndevelop multimodal detection methods . Lastly, the dataset can also\nbe used for the task of source credibility identification by utilising the\nexisting source credibility labels and extracting a range of credibility\nindicators from the articles and available metadata, such as polarity\nof the articles, use of references, use of authors, etc.\n4.4 Ethical considerations\nThe dataset was collected and is published for research purposes\nonly.14We collected only publicly available content of news arti-\ncles/blogs. The dataset contains identities of authors of the articles\n14To ensure that it will be used only for research, the access to the dataset is given\nupon request, in which the researchers give explicit consent with the usage conditions.\nMonant Medical Misinformation Dataset SIGIR \u201922, July 11\u201315, 2022, Madrid, Spain\nif they were stated in the original source; we left this information,\nsince the presence of an author\u2019s name can be a strong credibility\nindicator. However, we anonymised the identities of the authors of\ndiscussion posts included in the dataset.\nThe main identified ethical issue related to the presented dataset\nlies in the risk of mislabelling of an article as supporting a false fact-\nchecked claim and, to a lesser extent, in mislabelling an article as not\ncontaining a false claim or not supporting it when it actually does.\nTo minimise these risks, we developed our labelling methodology\nas described in Section 3.2 and require an agreement of at least\ntwo independent annotators to assign a claim presence or article\nstance label to an article. It is also worth noting that we do not\nlabel an article as a whole as false or true. Nevertheless, we provide\npartial article-claim pair veracities based on the combination of\nclaim presence and article stance labels (cf. Section 5.3).\nAs to the veracity labels of the fact-checked claims and the\ncredibility (reliability) labels of the articles\u2019 sources, we take these\nfrom the fact-checking sites and external listings such as Media\nBias/Fact Check as they are and refer to their methodologies for\nmore details on how they were established.\nLastly, the dataset also contains automatically predicted labels\nof claim presence and article stance using our baselines described\nin the next section. These methods have their limitations and work\nwith certain accuracy as reported in this paper. This should be taken\ninto account when interpreting them.\nThe means for reporting considerable mistakes in the raw data\nand manual labels are described in the accompanying repository.15\n5 CLAIM PRESENCE AND ARTICLE STANCE\nBASELINES AND ANALYSIS\n5.1 Evaluation of claim presence baselines\nWe provide evaluation of three claim presence detection baselines\nand compare their performance on the whole manually labelled\ndataset using only Not present and Present (which includes also\nSuggestive ) classes (see Table 1 for their distribution):\n\u2022Information retrieval (IR method) \u2013 For any given claim and\nany given article, the claim presence is determined by the\nIR method as follows: First, 1-, 2- and 3-grams are extracted\nfrom the given claim. Each n-gram is assigned a TF-IDF score\nwhere TF is calculated within the claim and IDF based on\nthe whole corpus of articles. Next, we match n-grams to the\nsentences of an article. If an n-gram contains medical terms,\ntheir synonyms are also allowed when matching sentences.\nMedical terms are identified using the Academic Vocabulary\nList.16Synonyms to these terms are retrieved by comparing\nsimilarity of their word vectors using fastText17pre-trained\non Wikipedia articles. The scores of n-grams, for which there\nis an article sentence containing all their terms, are summed\nup and normalized by the sum of all n-gram scores. We do\nthis separately for 1-, 2-, and 3-grams and compute the final\npresence score as their average. The claim is classified as\npresent in a given article if the final computed score is above\na defined threshold.\n15https://github.com/kinit-sk/medical-misinformation-dataset/\n16https://www.academicvocabulary.info/x.asp\n17https://fasttext.cc\u2022Sentence embedding similarity (SE method) \u2013 This method\ncalculates a presence score based on sentence embeddings\n(using Universal Sentence Encoder [ 4], model v4) extracted\nfrom article sentences and a claim. The score is an average\nof two similarity comparisons: 1) cosine similarity between\nan article title and a claim, and 2) average cosine similarity\nbetween a claim and 5 article sentences the most similar to\nthe claim. The claim is classified as present in a given article\nif the final computed score is above a defined threshold.\n\u2022Combined IRSE method \u2013 This method, first introduced in [ 25],\nworks the same as the IR method with few important distinc-\ntions: First, the score of each matched n-gram is computed\nas a product of its TF-IDF score (IR method) and the cosine\nsimilarity between the embedding of an article sentence,\nwhich contains all terms of the given n-gram, and the claim\nembedding (SE method). Second, to make the comparison\nmore efficient, only sentences with similarity above a certain\nthreshold are considered. This threshold is computed as an\naverage of cosine similarity between the claim and an article\ntitle embeddings and cosine similarity between the claim\nand the Kmost similar sentences.\n5.1.1 Results of Claim Presence Detection. All three baselines re-\nquired a choice of a threshold to make the claim presence decisions\nbased on the computed presence scores. We chose the threshold\nvalues so that recall of the methods on the positive (i.e., Present )\nclass would roughly be the same (around 0.4). This way, we can\ncompare the methods working under the same requirement for the\nproportion of relevant items to be selected. The resulting thresholds\nfor the IR,SE, and IRSE methods were 0.5, 0.5, and 0.45 respectively.\nThe IRSE method also contains a prefiltering threshold. Our experi-\nments showed that setting its value to 0.25 enabled it to discard a\nlarge number of potential mappings without affecting the overall\nperformance of the method.\nThe results of the baselines on our labelled dataset are shown in\nTable 2. Although the IRandSEmethods achieved similar results,\nwe can see that the IRSE method outperformed both suggesting\nthe utility of their combination. This is also confirmed by Figure 4,\nwhich illustrates a relation between true positive rate and false\npositive rate of the baselines using ROC (receiver operating charac-\nteristic) curve. The IRSE method retains lower false positive rate\nwith increasing true positive rate than both the IRandSEmeth-\nods. Out of them, the IRmethod performs better with lower false\npositive rate than the SEmethod.\nWe also evaluated the baselines individually for Samples 1 and\n2 (see Table 2). Although the IRSE method retains the highest ac-\ncuracy, the accuracy drops for all methods in Sample 2 compared\ntoSample 1 . Manual inspection of the errors made by the IRSE\nmethod revealed that the decrease cannot be explained by a domain\nshift due to COVID-19. Most commonly, the errors were due to the\nclaim presence method neglecting some information in claims and\nmapping them to articles that were related but did not discuss that\nspecific case. For instance, for claim \u201cOmega-3 fatty acids decrease\ntriglycerides\u201d, we observed results that discussed other effects of\nOmega-3 fatty acids that did not relate to triglycerides. To handle\nsuch cases, a more strict threshold could be used.\nSIGIR \u201922, July 11\u201315, 2022, Madrid, Spain Srba et al.\nTable 2: Precision, recall and F1-score of the claim presence detection baselines are evaluated on the whole manually labelled\ndataset. Accuracy is computed individually on the Sample 1 andSample 2 , which were collected and annotated in 2019 and in\n2021 respectively, as well as on the dataset as a whole.\nPresent Not presentS1Acc. S2Acc. Overall Acc.Precision Recall F1-score Precision Recall F1-score\nIR method 0.81 0.40 0.53 0.54 0.89 0.67 0.66 0.46 0.62\nSE method 0.79 0.43 0.56 0.55 0.86 0.67 0.65 0.53 0.62\nIRSE method 0.91 0.45 0.6 0.58 0.95 0.72 0.71 0.56 0.67\n0.0 0.2 0.4 0.6 0.8 1.0\nFalse positive rate0.00.20.40.60.81.0True positive rateROC curve\nIRSE method\nIR method\nSE method\nFigure 4: ROC curve showing relation between true positive\nrate and false positive rate of the evaluated baseline meth-\nods. The IRSE method outperforms both the IRandSEmeth-\nods by achieving lower false positive rate at most evaluated\ntrue positive rates.\n5.2 Evaluation of article stance baselines\nTo evaluate article stance classification baselines, we utilize Sample 1\nwith 210 pairs as training set and Sample 2 with 99 pairs as testing\nset (see Table 1 for the distribution of classes in both samples).\nIn both cases, we do not consider the Not present class, as it is\nnot relevant for stance classification. In addition to the manually\nlabelled Monant data, we also utilise the Fake News Challenge (FNC)\ndataset18. Similarly, we drop the class denoting that an article is\nunrelated to the claim. This leaves us with \u223c20,450 samples with\nthe following distribution: 27.24% Supporting , 7.5% Contradicting ,\nand 65.26% Neutral .\nWe compare the performance of several baselines. The first group\nof baselines present the best models from the FNC:\n\u2022Talos19\u2013 an ensemble of a decision tree and a convolutional\nneural network, where the final decision is obtained by sim-\nple 50/50 voting. This approach uses both hand-crafted fea-\ntures in the decision tree and the word embeddings in both\nthe decision tree and the neural network.\n\u2022Athene [12] \u2013 an ensemble of multiple multi-layer percep-\ntrons. The final decision is obtained by hard voting between\n18http://www.fakenewschallenge.org/\n19https://blog.talosintelligence.com/2017/06/talos-fake-news-challenge.htmlthem. All models use the same set of hand-crafted features,\nwith only difference being their random initialisation.\n\u2022Athene-ext [12] \u2013 an extension of the Athene approach, devel-\noped after the analysis of various models in the challenge, de-\nsigned to overcome the observed problems. A single stacked\nLSTM is used with the best subset of the hand-crafted fea-\ntures, as determined by an ablation study.\n\u2022UCL [26] \u2013 a simple multi-layer perceptron which uses TF-\nIDF scores of the claim and the article and the similarity\nbetween them.\nSince the challenge took place already in 2017, these models\ncan no longer be considered state of the art, but they nevertheless\nrepresent a relatively wide range of approaches utilising both hand-\ncrafted, but also automatically extracted features, which makes\nthem interesting for benchmarking more novel models.\nThe second group comprises our proposed baseline methods\nwhich utilise CNN and LSTM combined with similarity and atten-\ntion mechanism respectively to identify parts of articles relevant\nfor stance classification:\n\u2022All Sentences CNN \u2013 the input to the CNN model is a claim\nfollowed by the first 100 sentences of the article, without any\ndetection of their relevance. The articles with higher number\nof sentences are clipped and those with lower number of\nsentences are padded with zero vector. This network is meant\nfor comparison purposes, to determine the effect of sentence\nrelevance detection.\n\u2022Attention LSTM \u2013 this model uses an LSTM network for\nobtaining high-level representations for both the claim and\nthe article body. An attention mechanism is applied on the\nhigh-level representations to identify important parts of the\narticles. Another LSTM layer is applied on the output of\nthe attention layer. A dropout with rate of 0.4 is applied to\nprevent overfitting, followed by a dense layer and a softmax\nlayer for classification.\n\u2022Similarity CNN \u2013 the input to the CNN model are the three\nmost similar sentences to a given claim (based on the cosine\nsimilarity of their embedding representations) along with\none previous and one following sentence for each. We use\nthree different convolutional layers, the outputs of which\nare concatenated together. A dropout of rate 0.25 is applied\nbefore the convolutional layers and one with rate of 0.5 is\napplied on the concatenated output of the convolutions, to\nprevent overfitting. Finally, we apply a dense layer and a\nsoftmax layer for classification.\nMonant Medical Misinformation Dataset SIGIR \u201922, July 11\u201315, 2022, Madrid, Spain\nTable 3: Comparison of the article stance classification base-\nlines. The reported metric is accuracy calculated on test sub-\nset in case of FNC. In case of manually labelled data from\nMonant, we report accuracy both as a mean of 10 runs of 5-\nfold cross-validation on Sample 1 , as well as on testing sam-\nples ( Sample 2 ). The best performance is achieved by the sim-\nilarity CNN with transfer learning.\nFNC S1 S2\nTalos 66.93 42.57 48.00\nAthene 67.81 14.36 15.00\nAthene-ext 69.00 19.31 10.00\nUCL 65.76 37.13 47.00\nAll Sentences CNN 64.91 40.54 57.00\nAttention LSTM 63.19 43.78 40.00\nSimilarity CNN 65.57 56.76 63.00\nAttention LSTM \u2013 transfer 64.79 61.83 65.00\nSimilarity CNN \u2013 transfer 71.86 74.23 73.00\nFor the last two proposed baseline models, we also employ trans-\nfer learning. We first train a general model using the FNC data and\nfine-tune it on the manually labelled Monant training data.\n5.2.1 Results of Article Stance Classification. Table 3 presents ac-\ncuracy of the baseline methods on the two datasets. In case of FNC\ndataset, we evaluate the models using a test subset of the dataset,\nas it was originally released for the competition. In case of manu-\nally labelled Monant data, we perform two evaluations. First, we\nperform a 5-fold cross-validation on the training set ( Sample 1 ) and\nreport the mean performance of the model, which is determined by\nrunning the cross-validation 10 times. Second, we evaluate models\ntrained on the whole Sample 1 on the testing set ( Sample 2 ).\nThe results show that the models that utilise simple hand-crafted\nfeatures struggle when dealing with a different dataset. This is\nevident in the Athene and its extension. We can presume that the\nused hand-crafted features are too specific for the FNC data and\ndo not generalise well to the Monant data. On the other hand,\nthe models with automatic feature extraction, which include UCL\nbaseline model, Talos , and our proposed models, show a better\nperformance and better generalisation. In addition, we can see that\nthese models retain their accuracy even on Sample 2 which was\ncollected later than the training data and could theoretically include\ndata or concept drifts.\nThe results also suggest that the identification of relevant parts\nof the articles is necessary when dealing with longer articles. In case\nof FNC data, where the average length of article is \u223c16 sentences,\nthe performance increase is not as evident. This may be due to the\nspecificity of the shorter articles, which mostly deal with a single\nclaim, and therefore can be considered relevant as a whole for\nthe classification. However, when investigating the articles from\nMonant, where the average article length is \u223c55 sentences, the\nincrease in performance observed in Attention LSTM andSimilarity\nCNN as opposed to All Sentences CNN , is noticeable. In such articles,\nthe extraction of features from the whole article results in a lot of\nnoise, which causes problems for the classification.When comparing attention mechanism with the similar sen-\ntences extracted using cosine similarity, we found out that the\nformer sometimes struggled to identify relevant parts of articles.\nIt tended to focus solely on the sentences similar to a given claim,\nwhile the arguments regarding the claims were often present in\nthe surrounding sentences instead. Since Similarity CNN took also\nthese surroundings into account, it achieved a better performance.\nLastly, the use of transfer learning contributed to a significant\nincrease of performance on the Monant data, even though the\ndiscrepancy in the distribution of classes across the datasets was\nsignificant. When we were training LSTM networks using transfer\nlearning, they often broke down and started predicting the most\ndominant class in the data. Even though the use of attention mech-\nanism helped in this regard, CNNs proved to be more stable and\nreliable for generating good claim and article representations and\ntherefore attained better performance.\n5.3 Descriptive analysis of predicted labels\nWe use the best-performing baselines, i.e., the IRSE method and\ntheSimilarity CNN with transfer learning , to predict claim presence\nand article stance labels for articles and fact-checked claims in\nthe collected dataset; these are also part of the published data. In\naddition, we aggregate these labels into article-claim pair veracities\nas follows: If an article agrees with a claim, we assign the veracity\nof the claim to the article-claim pair. If an article contradicts a claim,\nwe assign to the article-claim pair the veracity opposite to the claim\nveracity. Lastly, if an article has a neutral stance towards a claim,\nor the veracity of the claim is unknown , the article-claim pair is\nevaluated to be unknown as well.\nThe predicted labels are less precise compared to the manual\nones, but at the same time, they are available for a much larger num-\nber of articles. They are also more accurate than many commonly\nused heuristics (e.g., the ones derived solely from the reliability of\nan article\u2019s source). This makes them ideal to be used as (weak) la-\nbels for other misinformation detection methods (based on articles\u2019\ncontent style or context) while accepting some noise introduced by\nthe methods\u2019 inaccuracy in some cases.\nIn total, there are approx. 51k article-claim mappings labelled\nwith positive claim presence labels20and consequently, also with\narticle stance annotations. Out of all 317k articles, 11% are mapped\nto at least one claim. Out of all 3.5k medical claims, 35% are mapped\nto at least one article. The majority of predicted claim presence\nlabels are related to claims from MetaFact.io (66.6%), followed by\nFullFact.org (18.4%), HealthFeedback.org (9.6%), the list of cancer-\nrelated claims created in [ 8] (3.7%), and Snopes.com (1.6%). Out\nof all predicted article stance labels, 79% are supporting, 4% are\nneutral, and 17% contradicting.\nThe resulting article-claim pair veracity labels (51k in total) have\nthe following distribution: 20% are classified as false, 0.1% as mostly\nfalse, 0.1% as mixture, 0.1% as mostly true, 17% as true, and finally\n62% of article-claim pairs are labelled as unknown. A high number\nof article-claim pairs labelled as unknown is caused by the fact that\n20Note that the dataset also contains additional 366k mappings labelled with the claim\nnot present label. This happens when a presence score is below the set threshold,\nbut still achieves a meaningful value \u2013 it allows dataset users to use another (lower)\nthreshold to increase recall at the expense of precision.\nSIGIR \u201922, July 11\u201315, 2022, Madrid, Spain Srba et al.\n58% of medical claims (mostly from MetaFact.io) have an unknown\nveracity.\nOut of 35k articles mapped to at least one claim, 21% are mapped\nonly to true article-claim pair veracity labels, 22% only to false\narticle-claim pair veracity labels, and finally, 3% of articles contain\na mixture of true and false article-claim pair veracity labels. The\nremaining articles are associated only with one or several article-\nclaim mappings with unknown veracity.\nRegarding the source credibility labels, 69% of article-claim pair\nveracity labels relate to articles which come from unreliable sources.\nOut of them, 22% label article-claim pairs as false and 17% as true.\n25% of article-claim pair veracity labels relate to articles which\ncome from reliable sources; out of them, 17% label article-claim\npairs as false and 20% as true. Although further investigation is\nneeded, we can see that more veracity annotations relate to articles\nfrom unreliable sources (even when we consider the distribution of\narticles from un/reliable sources in our dataset). However, it also\nsuggests that the information on the sources\u2019 credibility (commonly\nused as a heuristic to label articles) is not sufficient and the articles\nneed to be assessed by the claims they make.\n6 CONCLUSIONS AND FUTURE WORK\nIn this paper, we introduced a labelled dataset of medical articles\nwith mappings to fact-checked claims for training and evaluation\nof machine learning methods supporting the fact-checking process.\nBesides providing a static dump of the dataset, we also provide a\nprogrammatic access to continuously updated data in our Monant\nplatform. The platform has already been maintained for over 2.5\nyears, collecting, updating, and annotating new data. The main\nsupported tasks are claim presence detection and article stance\nclassification, for which we provide manual labels, and which are\nessential for searching and checking whether a new article contains\nclaims that have already been fact-checked. In addition, the dataset\nenables a range of other tasks, such as misinformation characterisa-\ntion studies, studies of misinformation diffusion, source credibility\nclassification, etc. Thus, the dataset can be useful for researchers\ninterested in misinformation, automatised or ML-supported fact-\nchecking as well as for NLP and IR community in general.\nWe also present results of claim presence and article stance base-\nlines which are used to generate predicted labels mapping articles\nto fact-checked claims. While the former are based on combina-\ntion of classical IR approaches and sentence similarity, the latter\nuse more advanced neural networks approaches combined with\ntransfer learning to compensate for the limited number of labelled\nsamples (and class imbalance, especially w.r.t. the neutral class). The\nbaselines leave plenty of space for improvement, e.g., by applying\nstate-of-the-art pre-trained language models based on transformers.\nAlso, they currently work only for content in English language\nand are strictly limited to textual content (i.e., they cannot detect\npresence of a claim in an image, such as a screenshot from a social\nmedium post, meme, etc.).\nAs future work, we plan to: 1) extend the dataset with content in\nother languages; 2) develop multilingual methods of claim presence\nand article stance; and 3) apply them in a range of tasks, such as de-\ntection of previously fact-checked claims, mapping of these claimsto additional online content, and to automate audits of misinforma-\ntion prevalence in social media recommender systems [ 38]. Since\nthe scarcity of manually labelled data will likely remain a prob-\nlem, we will continue focusing on machine learning approaches\nthat can utilise unlabelled or limited labelled data, such as meta\nlearning or weakly supervised learning. Furthermore, we will seek\nmore efficient ways of navigating the selection of examples to label\n(active learning), and ways of gathering and exploiting previous\nexperience from other tasks as is the case of transfer and meta\nlearning.\nACKNOWLEDGMENTS\nThis work was partially supported by The Ministry of Education,\nScience, Research and Sport of the Slovak Republic under the Con-\ntract No. 0827/2021; by the Central European Digital Media Obser-\nvatory (CEDMO), a project funded by the European Union under\nthe Contract No. 2020-EU-IA-0267; and by TAILOR, a project funded\nby EU Horizon 2020 research and innovation programme under GA\nNo. 952215.\nREFERENCES\n[1]R. Baly, M. Mohtarami, J. Glass, L. M\u00e0rquez, A. Moschitti, and P. Nakov. 2018.\nIntegrating Stance Detection and Fact Checking in a Unified Corpus. In Proceed-\nings of the 2018 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, Volume 2 (Short Pa-\npers) . Association for Computational Linguistics, New Orleans, Louisiana, 21\u201327.\nhttps://doi.org/10.18653/v1/N18-2004\n[2]A. Bondielli and F. Marcelloni. 2019. A survey on fake news and rumour detection\ntechniques. Information Sciences 497 (2019), 38\u201355. https://doi.org/10.1016/j.ins.\n2019.05.035\n[3]L. Borges, B. Martins, and P. Calado. 2019. Combining similarity features and\ndeep representation learning for stance detection in the context of checking fake\nnews. Journal of Data and Information Quality (JDIQ) 11, 3 (2019), 1\u201326.\n[4]D. Cer, Y. Yang, S. Kong, N. Hua, N. Limtiaco, R. St John, N. Constant, M.\nGuajardo-Cespedes, S. Yuan, C. Tar, et al .2018. Universal sentence encoder.\narXiv:1803.11175 http://arxiv.org/abs/1803.11175\n[5] L. Cui and D. Lee. 2020. CoAID: COVID-19 Healthcare Misinformation Dataset.\narXiv:2006.00885 [cs.SI]\n[6]Enyan Dai, Yiwei Sun, and Suhang Wang. 2020. Ginger Cannot Cure Cancer:\nBattling Fake Health News with a Comprehensive Data Repository. In Proceedings\nof the International AAAI Conference on Web and Social Media , Vol. 14. 853\u2013862.\n[7]S. Dhoju, M. Main Uddin Rony, M. Ashad Kabir, and N. Hassan. 2019. Dif-\nferences in Health News from Reliable and Unreliable Media. In Compan-\nion Proceedings of The 2019 World Wide Web Conference (San Francisco, USA)\n(WWW \u201919) . Association for Computing Machinery, New York, NY, USA, 981\u2013987.\nhttps://doi.org/10.1145/3308560.3316741\n[8]A. Ghenai and Y. Mejova. 2018. Fake Cures: User-Centric Modeling of Health\nMisinformation in Social Media. Proc. ACM Hum.-Comput. Interact. 2, CSCW,\nArticle 58 (Nov. 2018), 20 pages. https://doi.org/10.1145/3274327\n[9]D Graves. 2018. Understanding the promise and limits of automated fact-\nchecking. https://reutersinstitute.politics.ox.ac.uk/our-research/understanding-\npromise-and-limits-automated-fact-checking\n[10] B. Guo, Y. Ding, L. Yao, Y. Liang, and Z. Yu. 2020. The Future of False Information\nDetection on Social Media: New Perspectives and Trends. ACM Comput. Surv.\n53, 4, Article 68 (July 2020), 36 pages. https://doi.org/10.1145/3393880\n[11] Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos. 2022. A survey on\nautomated fact-checking. Transactions of the Association for Computational\nLinguistics 10 (2022), 178\u2013206.\n[12] A. Hanselowski, A. PVS, B. Schiller, F. Caspelherr, D. Chaudhuri, C. M. Meyer,\nand I. Gurevych. 2018. A Retrospective Analysis of the Fake News Challenge\nStance-Detection Task. In Proceedings of the 27th International Conference on\nComputational Linguistics . Association for Computational Linguistics, Santa Fe,\nNew Mexico, USA, 1859\u20131874. https://www.aclweb.org/anthology/C18-1158\n[13] Momchil Hardalov, Arnav Arora, Preslav Nakov, and Isabelle Augenstein.\n2021. A survey on stance detection for mis-and disinformation identification.\narXiv:2103.00242 https://arxiv.org/abs/2103.00242\n[14] M. Hardalov, I. Koychev, and P. Nakov. 2016. In Search of Credible News. In\nArtificial Intelligence: Methodology, Systems, and Applications , Christo Dichev and\nGennady Agre (Eds.). Springer International Publishing, Cham, 172\u2013180.\nMonant Medical Misinformation Dataset SIGIR \u201922, July 11\u201315, 2022, Madrid, Spain\n[15] Anat Hashavit, Hongning Wang, Raz Lin, Tamar Stern, and Sarit Kraus. 2021.\nUnderstanding and Mitigating Bias in Online Health Search. In Proceedings of\nthe 44th International ACM SIGIR Conference on Research and Development in\nInformation Retrieval . ACM, New York, NY, USA, 265\u2013274. https://doi.org/10.\n1145/3404835.3462930\n[16] N. Hassan, G. Zhang, F. Arslan, J. Caraballo, D. Jimenez, S. Gawsane, S. Hasan,\nM. Joseph, A. Kulkarni, A. K. Nayak, and et al. 2017. ClaimBuster: The First-\nEver End-to-End Fact-Checking System. Proc. VLDB Endow. 10, 12 (Aug. 2017),\n1945\u20131948. https://doi.org/10.14778/3137765.3137815\n[17] Benjamin Horne and Sibel Adali. 2017. This Just In: Fake News Packs A Lot In\nTitle, Uses Simpler, Repetitive Content in Text Body, More Similar To Satire Than\nReal News. Proceedings of the International AAAI Conference on Web and Social\nMedia 11, 1 (May 2017), 759\u2013766.\n[18] Md Zobaer Hossain, Md Ashraful Rahman, Md Saiful Islam, and Sudipta Kar.\n2020. BanFakeNews: A Dataset for Detecting Fake News in Bangla. In Proceedings\nof the 12th Language Resources and Evaluation Conference . European Language\nResources Association, Marseille, France, 2862\u20132871. https://aclanthology.org/\n2020.lrec-1.349\n[19] Andrea Hrckova, Robert Moro, Ivan Srba, and Maria Bielikova. 2021. Quantitative\nand qualitative analysis of linking patterns of mainstream and partisan online\nnews media in Central Europe. Online Information Review (Dec. 2021). https:\n//doi.org/10.1108/OIR-10-2020-0441\n[20] Dilek K\u00fc\u00e7\u00fck and Fazli Can. 2021. Stance Detection: A Survey. Comput. Surveys\n53, 1 (Jan. 2021), 1\u201337. https://doi.org/10.1145/3369026\n[21] Watheq Mansour, Tamer Elsayed, and Abdulaziz Al-Ali. 2022. Did I See It Before?\nDetecting Previously-Checked Claims over Twitter. In Advances in Information\nRetrieval (Lecture Notes in Computer Science) , Matthias Hagen, Suzan Verberne,\nCraig Macdonald, Christin Seifert, Krisztian Balog, Kjetil N\u00f8rv\u00e5g, and Vinay\nSetty (Eds.). Springer International Publishing, Cham, 367\u2013381. https://doi.org/\n10.1007/978-3-030-99736-6_25\n[22] Tanushree Mitra and Eric Gilbert. 2015. CREDBANK: A Large-Scale Social Media\nCorpus With Associated Credibility Annotations. Proceedings of the International\nAAAI Conference on Web and Social Media 9, 1 (2015), 258\u2013267.\n[23] Kai Nakamura, Sharon Levy, and William Yang Wang. 2020. Fakeddit: A\nNew Multimodal Benchmark Dataset for Fine-grained Fake News Detection.\nInProceedings of the 12th Language Resources and Evaluation Conference . Eu-\nropean Language Resources Association, Marseille, France, 6149\u20136157. https:\n//aclanthology.org/2020.lrec-1.755\n[24] Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer Elsayed,\nAlberto Barr\u00f3n-Cede\u00f1o, Paolo Papotti, Shaden Shaar, and Giovanni Da San Mar-\ntino. 2021. Automated Fact-Checking for Assisting Human Fact-Checkers. In\nProceedings of the Thirtieth International Joint Conference on Artificial Intelligence .\nInternational Joint Conferences on Artificial Intelligence Organization, Montreal,\nCanada, 4551\u20134558. https://doi.org/10.24963/ijcai.2021/619\n[25] Branislav Pecher, Ivan Srba, Robert Moro, Matus Tomlein, and Maria Bielikova.\n2021. FireAnt: Claim-Based Medical Misinformation Detection and Monitoring.\nInProceedings of ECML PKDD 2020: Machine Learning and Knowledge Discovery\nin Databases. Applied Data Science and Demo Track . 555\u2013559. https://doi.org/10.\n1007/978-3-030-67670-4_38\n[26] B. Riedel, I. Augenstein, G. P Spithourakis, and S. Riedel. 2017. A simple\nbut tough-to-beat baseline for the Fake News Challenge stance detection task.\narXiv:1707.03264 http://arxiv.org/abs/1707.03264\n[27] Shaden Shaar, Firoj Alam, Giovanni Da San Martino, and Preslav Nakov. 2021.\nAssisting the Human Fact-Checkers: Detecting All Previously Fact-Checked\nClaims in a Document. arXiv:2109.07410 [cs] (Sept. 2021). http://arxiv.org/abs/\n2109.07410 arXiv: 2109.07410.\n[28] Shaden Shaar, Nikolay Babulkov, Giovanni Da San Martino, and Preslav Nakov.\n2020. That is a Known Lie: Detecting Previously Fact-Checked Claims. In Pro-\nceedings of the 58th Annual Meeting of the Association for Computational Lin-\nguistics . Association for Computational Linguistics, Online, 3607\u20133618. https:\n//doi.org/10.18653/v1/2020.acl-main.332\n[29] Shaden Shaar, Fatima Haouari, Watheq Mansour, Maram Hasanain, Nikolay\nBabulkov, Firoj Alam, and Preslav Nakov. 2021. Overview of the CLEF-2021\nCheckThat! Lab Task 2 on Detecting Previously Fact-Checked Claims in Tweets\nand Political Debates, Vol. 2936. CEUR-WS, Bucharest, Romania, 13. http://ceur-\nws.org/Vol-2936/paper-29.pdf\n[30] Shaden Shaar, Maram Hasanain, Bayan Hamdan, Zien Sheikh Ali, Fatima Haouari,\nAlex Nikolov, Mucahid Kutlu, Yavuz Selim Kartal, Firoj Alam, Javier Beltr\u00e1n,\nTamer Elsayed, and Preslav Nakov. 2021. Overview of the CLEF-2021 CheckThat!\nLab Task 1 on Check-Worthiness Estimation in Tweets and Political Debates. 24.\n[31] G. K. Shahi and D. Nandini. 2020. FakeCovid \u2013 A Multilingual Cross-domain\nFact Check News Dataset for COVID-19. In Workshop Proceedings of the 14th\nInternational AAAI Conference on Web and Social Media . http://workshop-\nproceedings.icwsm.org/pdf/2020_14.pdf\n[32] Karishma Sharma, Feng Qian, He Jiang, Natali Ruchansky, Ming Zhang, and Yan\nLiu. 2019. Combating Fake News: A Survey on Identification and Mitigation\nTechniques. ACM Transactions on Intelligent Systems and Technology (TIST) 10, 3\n(2019), 21. https://doi.org/10.1145/3305260[33] K. Shu, D. Mahudeswaran, S. Wang, D. Lee, and H. Liu. 2020. FakeNewsNet:\nA Data Repository with News Content, Social Context, and Spatiotemporal\nInformation for Studying Fake News on Social Media. Big Data 8, 3 (2020), 171\u2013188.\nhttps://doi.org/10.1089/big.2020.0062 arXiv:https://doi.org/10.1089/big.2020.0062\nPMID: 32491943.\n[34] K. Shu, A. Sliva, S. Wang, J. Tang, and H. Liu. 2017. Fake News Detection on\nSocial Media: A Data Mining Perspective. SIGKDD Explor. Newsl. 19, 1 (Sept.\n2017), 22\u201336. https://doi.org/10.1145/3137597.3137600\n[35] I. Srba, R. Moro, J. Simko, J. Sevcech, D. Chuda, P. Navrat, and M. Bielikova. 2019.\nMonant: Universal and Extensible Platform for Monitoring, Detection and Miti-\ngation of Antisocial Behaviour. In Workshop on Reducing Online Misinformation\nExposure \u2013 ROME 2019, colocated with SIGIR 2019 . https://rome2019.github.io/\npapers/Srba_etal_ROME2019.pdf\n[36] Victor Suarez-Lledo and Javier Alvarez-Galvez. 2021. Prevalence of Health\nMisinformation on Social Media: Systematic Review. Journal of Medical Internet\nResearch 23, 1 (Jan. 2021), e17187. https://doi.org/10.2196/17187\n[37] J. Thorne, A. Vlachos, C. Christodoulopoulos, and A. Mittal. 2018. FEVER: a Large-\nscale Dataset for Fact Extraction and VERification. In Proceedings of the 2018\nConference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long Papers) . Association\nfor Computational Linguistics, New Orleans, Louisiana, 809\u2013819. https://doi.\norg/10.18653/v1/N18-1074\n[38] Matus Tomlein, Branislav Pecher, Jakub Simko, Ivan Srba, Robert Moro, Elena Ste-\nfancova, Michal Kompan, Andrea Hrckova, Juraj Podrouzek, and Maria Bielikova.\n2021. An Audit of Misinformation Filter Bubbles on YouTube: Bubble Bursting and\nRecent Behavior Changes. In Fifteenth ACM Conference on Recommender Systems .\nACM, New York, NY, USA, 1\u201311. https://doi.org/10.1145/3460231.3474241\n[39] M. Umer, Z. Imtiaz, S. Ullah, A. Mehmood, G. S. Choi, and B. W. On. 2020. Fake\nNews Stance Detection Using Deep Learning Architecture (CNN-LSTM). IEEE\nAccess 8 (2020), 156695\u2013156706.\n[40] X. Wang, C. Yu, S. Baumgartner, and F. Korn. 2018. Relevant Document Discovery\nfor Fact-Checking Articles. In Companion Proc. of the The Web Conference 2018\n(Lyon, France) (WWW \u201918) . International World Wide Web Conferences Steering\nCommittee, 525\u2013533. https://doi.org/10.1145/3184558.3188723\n[41] Yaqing Wang, Weifeng Yang, Fenglong Ma, Jin Xu, Bin Zhong, Qiang Deng, and\nJing Gao. 2020. Weak Supervision for Fake News Detection via Reinforcement\nLearning. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 34.\nAAAI press, 516\u2013523. https://doi.org/10.1609/AAAI.V34I01.5389\n[42] Xia Zeng, Amani S. Abumansour, and Arkaitz Zubiaga. 2021. Automated fact-\nchecking: A survey. Language and Linguistics Compass 15, 10 (2021), e12438.\nhttps://doi.org/10.1111/lnc3.12438\n[43] Q. Zhang, S. Liang, A. Lipani, Z. Ren, and E. Yilmaz. 2019. From Stances\u2019 Imbalance\nto Their Hierarchical Representation and Detection. In The World Wide Web\nConference (San Francisco, CA, USA) (WWW \u201919) . Association for Computing\nMachinery, New York, NY, USA, 2323\u20132332. https://doi.org/10.1145/3308558.\n3313724\n[44] X. Zhang and A. A Ghorbani. 2020. An overview of online fake news: Character-\nization, detection, and discussion. Information Processing & Management 57, 2\n(2020), 102025.\n[45] Chen Zhao, Chenyan Xiong, Corby Rosset, Xia Song, Paul Bennett, and Saurabh\nTiwary. 2020. Transformer-XH: Multi-Evidence Reasoning with eXtra Hop\nAttention. In International Conference on Learning Representations . https://\nopenreview.net/forum?id=r1eIiCNYwS\n[46] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou,\nJiahai Wang, and Jian Yin. 2020. Reasoning Over Semantic-Level Graph for\nFact Checking. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics . Association for Computational Linguistics, Online,\n6170\u20136180. https://doi.org/10.18653/v1/2020.acl-main.549\n[47] X. Zhou and R. Zafarani. 2020. A Survey of Fake News: Fundamental Theories,\nDetection Methods, and Opportunities. ACM Comput. Surv. 53, 5, Article 109 (sep\n2020), 40 pages. https://doi.org/10.1145/3395046\n[48] A. Zubiaga, A. Aker, K. Bontcheva, M. Liakata, and R. Procter. 2018. Detection\nand Resolution of Rumours in Social Media: A Survey. ACM Comput. Surv. 51, 2,\nArticle 32 (Feb. 2018), 36 pages. https://doi.org/10.1145/3161603", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Monant medical misinformation dataset: Mapping articles to fact-checked claims", "author": ["I Srba", "B Pecher", "M Tomlein", "R Moro"], "pub_year": "2022", "venue": "Proceedings of the 45th \u2026", "abstract": "False information has a significant negative influence on individuals as well as on the whole  society. Especially in the current COVID-19 era, we witness an unprecedented growth of"}, "filled": false, "gsrank": 47, "pub_url": "https://dl.acm.org/doi/abs/10.1145/3477495.3531726", "author_id": ["7JrxTrAAAAAJ", "AsuFpHwAAAAJ", "r1VDrPMAAAAJ", "dyeyjpQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:RNtf6f9bWn4J:scholar.google.com/&output=cite&scirp=46&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D40%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=RNtf6f9bWn4J&ei=C7WsaMuIJazWieoPic2ZoAU&json=", "num_citations": 23, "citedby_url": "/scholar?cites=9104690751373040452&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:RNtf6f9bWn4J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2204.12294"}}, {"title": "Seven Initial Prominent Sources of All Information Bias Impartiality Types Parsed", "year": "2023", "pdf_data": "Media Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 40\nStudies\n Seven Initial Prominent Sources  \n of All Information Bias Impartiality  \n Types Parsed  Erik Bean  photo: Jakub \u010euri\u0161 \nABSTRACT\nEver since information was first operationalized by library science into consumer formats, \nmedia bias has been studied from the purview of information gatekeepers who decide what, \nhow, and when to publish based on story importance and factors like circulation. This concept \ndid not include individuals or entities outside of the journalism discipline. With the advent of \nthe internet and a number of social media networks that soon followed, individuals could \nmore effectively release information without waiting for gatekeepers, thus shaping the public\u2019s \nperception regardless of the topic. Scholars offered a theoretical framework for shaping the \npublic\u2019s opinion and still other scholars focused on how information could be slanted or partisan. \nHowever, these seminal approaches did not operationalize the term information bias in terms \nof the overall partiality of major sources themselves. Information evaluation tests such as the \nCurrency, Relevance, Authority, Accuracy, and Purpose (CRAAP) and Stop, Investigate, Find, \nTrace (SIFT) that have been discussed as tools to assess information for bias fall short on the \nvery first step of what to inspect and how to sort. With a gap in the literature sorting through \nthe types of biases can be daunting and confusing. The purpose of this paper is to propose one \ninitial method as the first step to sort information bias regardless of its form, analog or digital, \ninto seven prominent sources each with their own inherent but larger impartiality tied to it. The \nsources of all information bias to be discussed in alphabetical order are: 1) academic, 2) for-\nprofit, 3) government, 4) hidden agenda, 5) individuals, 6) nonprofit, and 7) watchdog groups. \nKEY WORDS\nImpartiality. Information Bias. Inspected. Media. Parsed. Sources. Types.DOI: https://doi.org/10.34135/mlar-23-01-03\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 41\nStudies photo: Jakub \u010euri\u0161 \n1 Statement of Purpose\nInformation can be generated by a variety of sources, each with its own purpose, interests, \nand biases. Understanding the source of information can help individuals evaluate its credibility \nand potential biases whether they include said information in school essays, in business white \npapers, or in sharing in social media, for example.1 With many social networks containing \nfake news and increasing misinformation, whether information literacy is taught in libraries, at \nschools, or anyone in the public willing to help people from all walks of life separate fact from \nfiction, people need to start evaluating information carefully before they subscribe to it and \nto be most responsible when contributing to civil discourse. But where should people begin \nto discern biases associated with pieces of information? One way is to separate or parse the \ninformation, if you will, into types of higher-level impartiality tied to the authors. But what types \nof information make sense? \nA review of the literature across several disciplines from journalism, media and information \nliteracy to books and media communications reveals that no single study has suggested an \noverall number or segment of all information impartiality source types, but that the seven to \nbe discussed here have, for the most part been the subject of separate studies of impartiality \nholding their source category as a separate documented bias. By categorizing information \nsources in the following seven ways, to view all of the possible most prominent sources of \ninherent impartiality tied to them, individuals can see the range of perspectives to form their \ninitial opinions of the usefulness of such information as an initial inspection or evaluative step. \nWhen tied to bias evaluation tools like CRAAP and SIFT, students and people everywhere \ncan now take the first step in parsing the information so that while other types of biases may \nlater be found, the initial bias type can more immediately identified.2 After separating such \ninformation into any one or more of the seven proposed here, people can drill down deeper \nto inspect for fallacies and other such tests outside scope of this paper, that can account for \ninformation objectivity and its authenticity. Observing the 7 initial sources of prominent bias \ntype categories to follow can, therefore, aid as the initial step in such an evaluation inspection \nprocess that undoubtedly relies on critical thinking.\n2 Methodology\nUsing databases such as ProQuest , Digital Dissertations , the Elton B. Stephenson Database  \n(EBSCO), ERIC , and Google Scholar , a broad range of journals were examined across many \ndisciplines to determine the types of information sources that were initially separated for their \nuse by libraries, students, and researchers using terms like information category history, types \nof information sources, for example. In February 2023 the popular Artificial Intelligence (AI) \ntool ChatGPT was also used based on numerous scholarly studies it could access. The initial \nquestion was: \u201cOf all the information available anywhere, on and off the internet, what categories \nhave researchers divided it into?\u201d And while the response listed some source types including \nprimary, secondary, and tertiary to academic, and popular sources like journalistic and media \ncompanies to and even grey literature like white papers and technical documents and finally \nelectronic sources, no single study has been conducted nor one that conceptually discussed \nall seven to follow here. Other search terms for the history of the study of information bias were \nused as, \u201cinformation\u201d, \u201corganization\u201d, \u201ccategories\u201d, \u201cbias\u201d, \u201cpartiality\u201d, \u201csource\u201d,  for example. \n1 See: WINEBURG, S., MCGREW, S., BREAKSTONE, J., ORTEGA, T.: Evaluating Information: The Cornerstone \nof Civic Online Reasoning. Stanford Digital Repository. Stanford, CA : Stanford University, 2019. [online]. \n[2022-11-15]. Available at: <https://purl.stanford.edu/fv751yt5934>.\n2 CAULFIELD, M.: SIFT (The Four Moves). [online]. [2023-02-09]. Available at: <https://hapgood.\nus/2019/06/19/sift-the-four-moves/>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 42\nStudiesThe results of that search are shown throughout the following literature review. However, even \nwhen ChatGPT was asked: \u201cHave sources of all information ever been categorized into these \noverall types of impartiality studies collectively: academic, for-profit, government, hidden-agenda, \nindividuals, and watch dog groups in one study?\u201d The answer was \u201cno\u201d.3 \n3 Literature\nEver since information was first operationalized by library science into the Five Laws of \nInformation Accessibility and into proposed formats such as Memex, a hypothetical device \nas a new way to organize and access information, a precursor to computers and individually \naccessed databases, but one where users could store their personal preferences and notes \nabout information they read, for example, Memex was a proposed way to make connections \nto various pieces of information to help users discern its meaning.4 With regard to the Five \nLaws they helped librarians to initially categorize information and these types did recognize \nacademic, commercial (for-profit), non-profit, but hidden agenda was labeled political or social \nissues and finally individuals were only recognized as users of the information.\nAs research continued scholars examined ways in which public opinions were shaped by \ninformation they consumed. This led to studies on media bias from the purview of information \ngatekeepers who decide what, how, and when to publish based on story importance and \nfactors like circulation.5 Thirty years later this continued look at how opinions are swayed in the \nmedia turned to information bias itself as well as how artificial intelligence-based algorithms \ncan affect news consumption. In this example from Digital Threats: Research and Practice, \nthe authors maintained, \u201cthe shift to consuming news information on SM [social media]  along \nwith the growing use of AI [artificial intelligence] for DPL [dynamic programming language] has \nchanged information bias anchoring behaviors.\u201d6\nThis concept of bias associated with specific media outlets continues to be the subject of \nmuch debate. But less is known about information bias associated with individuals who also can \ncontribute to national conversations. With the advent of the internet and several social media \nnetworks that soon followed, individuals could more effectively release information without \nwaiting for gatekeepers, thus shaping the public\u2019s perception regardless of the topic. Entman \noffered a theoretical framework for shaping the public\u2019s opinion.7 Other scholars focused on \nhow information could be slanted or partisan. 8\nHowever, these seminal approaches did not operationalize the term information bias nor the \nsources most prominently tied to overall partiality. With a gap in the literature as well as the dangers \nof misinformation that can affect people personally and professionally not to mention democratic \nvalues that rely on objectivity and authenticity of said information, sorting through the types of \nbiases can be daunting and confusing. Studies have been conducted that discuss impartiality \nof several of the seven proposed here but each has been singled out for possible impartiality.\n3 Author\u2019s note: Response to \u201cWith regard to these sources of information, academic, for-profit, government, \nhidden agenda, individuals, non-profits, and watchdog groups, which one would AI tools like ChatGPT fall \nunder and why?\u201d (See: ChatGPT. (online forum comment). [online]. [2023-02-23]. Available at: <https://\nwww.chatgpt.com>.).\n4 BUSH, V.: As We May Think. In The Atlantic Monthly, 1945, Vol. 176, No. 1, p. 101. See also: RANGANATHAN, \nS. R.: The Five Laws of Library Science . Madras : Madras Library Association, 1931.\n5  See: HERMAN, E. S., CHOMSKY, N.: Manufacturing Consent: The Political Economy of the Mass Media . \nNew York, NY : Pantheon Books, 1988.\n6 DATTA, P ., WHITMORE, M., NWANKPA, J. K.: A Perfect Storm: Social Media News, Psychological Biases, \nand AI. In\u00a0 Digital Threats: Research and Practice ,\u00a02021, Vol. 2, No. 2, p. 15:5. \n7 See: ENTMAN, R. M.: Modern Racism and the Images of Blacks in Local Television News. In Critical \nStudies in Media Communication, 1990, Vol. 7, No. 4, p. 332-345.\n8 See: BAUM, M. A.: Sex, Lies, and War: How Soft News Brings Foreign Policy to the Inattentive Public. In \nAmerican Political Science Review, 2002, Vol. 96, No. 1, p. 91-109.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 43\nStudiesFor example, in 1999, Kathleen Hall Jamieson and Paul Waldman published a book called \nThe Press Effect: Politicians, Journalists, and the Stories that Shape the Political World, in \nwhich they discussed different sources of information and their potential biases. While they did \nnot explicitly categorize sources into the prominent types this paper proposes, they provided \na detailed analysis of the ways in which different sources of information can shape public \nopinion from a journalistic purview. \u201cIn examining sources, we have found that journalists draw \non four major types: official, partisan, outside the process, and personal. The personal and \noutside sources add a valuable dimension to political coverage, bringing to bear perspectives \nthat official and partisan sources are unlikely to offer. However, journalists must be careful not \nto overuse these sources, or they risk reinforcing a sense of cynicism among the public about \npolitics and government.\u201d9\nIn 2016, David M. Croteau and William Hoynes published a book called, Media/Society: \nIndustries, Images, and Audiences. Here the two authors discussed different types of media \norganizations and the ways in which they are funded and regulated. They also separated the \ntypes of sources journalists might turn to for their stories. \u201cJournalists turn to a variety of sources \nto generate news stories. These sources can include government officials, corporate executives, \nexperts in various fields, celebrities, activists, and ordinary people. However, the selection of \nsources is not always neutral, and can reflect the biases and interests of the media organizations \nthemselves, as well as the larger societal and political forces that shape news coverage.\u201d10\nIn 2022, Jayes et al. published a paper called The impact of hyperlinks, skim reading and \nperceived importance when reading on the Web, in which they discuss the ways in which the \namount of information helps make better decisions even if that information is irrelevant for the \ndecision. \u201cFirstly, we predicted that longer sentences would be rated as more important than \nshorter sentences due to the so-called  information bias. Information bias is the  belief  that \nthe more information that can be acquired to make a decision, the better, even if that \nextra information is irrelevant for the decision .\u201d11\nHence, while there isn\u2019t one definitive scholarly paper that categorizes sources of information \ninto these seven: academic, for-profit, government, hidden agenda, individuals, non-profits, and \nwatchdog groups, Bean had proposed the concept as recently as of 2022 and many researchers \nhave written about sources, how they are used and the types of biases that can be inherently \nassociated with some as well as the individuals who seek or otherwise choose to interact with \nsuch information.12 These examples provide insights into the ways in which different sources \nof information can be shaped by public opinion and the factors that influence the production \nand dissemination of information in general.\nFinally, traditionally libraries served as a great place to start as reference experts have had \nalready vetted much of the information as well as the information in their collections available \nto their patrons. When COVID hit and schools and libraries shut down, students as well as the \npublic had little choice but to investigate information on their own as well as be responsible \nto inspect it for bias. Before, during, and after COVID academicians have provided evaluation \ntools like CRAAP and SIFT to help people separate facts from fiction. \u201c The CRAAP test can \nbe used to guide users through a series of questions designed to assess a source\u2019s credibility. \n9 JAMIESON, K. H., WALDMAN, P .: The Press Effect: Politicians, Journalists, and the Stories That Shape the \nPolitical World. Oxford : Oxford University Press, 2004, p. 73.\n10 CROTEAU, D. M., HOYNES, W.: Media/Society: Industries, Images, and Audiences. London, New York, \nThousand Oaks : Sage Publications, 2016, p. 174\n11 JAYES, L. T., et al.: The Impact of Hyperlinks, Skim Reading and Perceived Importance When Reading on \nthe Web. [online]. [2023-05-21]. Available at: <https://doi.org/10.1371/journal.pone.0263669>.\n12 BEAN, E.: Analyzing Information for Bias Is All Around You. Presented at the 2022 JEA/NSPA, National \nHigh School Journalism Convention. St. Louis, presented on 12th November 2022. [online]. [2023-05-21]. \nAvailable at: < https://studentpress.org/wp-content/uploads/2022/10/program.NHSJC.NF22.101922.\npdf>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 44\nStudiesThis test prompts users to consider a source\u2019s currency, relevance, authority, accuracy, and \npurpose before using it to make decisions or draw conclusions.\u201d13\nCRAAP relies on five steps to examine information so prospects can be more confident in \nsharing or subscribing to it. But in none of the scholarly literature are the details of how to sort \ninformation into its respective overarching bias category from the get-go using it discussed.\nThe SIFT method involves four steps: Stop, Investigate the source, Find trusted coverage, \nand Trace claims, quotes, and media to their original context. The purpose of the SIFT method \nis to provide a practical framework for evaluating information and to help users avoid falling \nfor false or misleading information regardless of where the information is located and how it is \ndisplayed digitally or in analog format. However, neither of these suggest the very first step in \nthe process, to effectively categorize the information into an overall group of partiality. Thus, this \npaper serves to propose those categories. Even if individuals simply select information served \nto them by algorithms, those pieces of information should be tied to the groups suggested here.\n4 Discussion\nBias has remained largely undefined in the literature let alone how to identify it. \u201cGiven \nthat, it makes sense librarians have taught students to assess information for bias. In a post-\ntruth society, where disinformation and hyper-partisan media weaponise bias by appealing to \nemotions rather than facts, there is an added urgency in knowing how to evaluate a source \ncritically.\u201d14 Users of information, reference librarians, students, teachers in the classroom, \nthose in the civic life, in industry and business, anyone, who may include said information for \nessays, reports, white papers, in books, blogs, for causal or important decision-making use \nin social media posts or otherwise, for personal or professional use, before they subscribe to \nor believe in or recommend such data, should inspect it for bias levels regardless of the topic.\nNoting that all information has a purpose and that when seeking information people should \nstrive to be objective and open to varying points of view before formulating a final opinion, they \nshould strive to inspect said information for possible bias it may contain, and they can do so \nby first separating such data into higher level or most prominent categories of overall partiality \nregardless of the topic discussed. This initial evaluative step can come before further analysis \nof fallacies or other evaluative inspection processes and just look at the piece of information \nfor the most prominent category of impartiality it represents.\nThat said, when one inspects for such information bias, one really is vetting or appraising \nthe material. One can say bias is nothing more than one person\u2019s opinion on any given topic, but \nis that opinion based on good information or bad information and who is to judge? According \nto Dictionary.com, \u201cvetting\u201d means, \u201cto appraise, verify, or check the accuracy, authenticity, \nvalidity\u201d15. Consequently, as the first step in this vetting or evaluative process of any piece of \ninformation regardless of its form, digital or analog, such information can be categorized into \nthese seven sources each with their own inherent impartiality, listed and discussed in alphabetic \norder: 1) Academic, 2) For-Profits, 3) Government, 4) Hidden Agenda, 5) Individuals, 6) Non-\nProfits, and 7) Watch Dog Groups.\n13 WINEBURG, S., MCGREW, S., BREAKSTONE, J., ORTEGA, T.: Evaluating Information: The Cornerstone of \nCivic Online Reasoning. Stanford Digital Repository. Stanford, CA : Stanford University, 2019, p. 6. [online]. \n[2023-03-06]. Available at: <https://purl.stanford.edu/fv751yt5934>.\n14 BURKHOLDER, J. M., PHILLIPS, K.: Breaking Down Bias: A Practical Framework for the Systematic \nEvaluation of Source Bias. In Journal of Information Literacy, 2022, Vol. 16, No. 2, p. 53.\n15 Vetting. [online]. [2023-02-22]. Available at: <https://www.dictionary.com/browse/vetting?s=t>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 45\nStudies4.1 Academic \nThe first source is Academic. Academic sources are schools, colleges, institutions, and \nuniversities. This source is on a mission to create and/or uphold knowledge. If one examines \nhigher education, one finds that in many cases professors and chairs often need to get published \nparticularly through peer reviewed journals so that their research contributes to the literature \nin a meaningful way. But this race to get published is often tied to tenure and the money they \nearn as academicians. As the Ivy League saying goes, \u201cPublish or perish\u201d, meaning that a \nprofessor cannot earn tenure if the publication does not occur; therefore, he or she might as \nwell perish. According to Enago Academy, \u201cfor graduate students, it means that if the research \nyou\u2019re working on isn\u2019t \u2018publishable\u2019, you may have a hard time finding a job. For new faculty, \n\u2018perish\u2019 means not making progress on the track to tenure.\u201d16 \nFor potential bias it could mean they might have overlooked some rigor in their study and \nthat the journal that published it could overlook it too. The viability and usability of academic \nsources has been studied to analyze its use as a source with potential partiality. Inequities in \nacademic publishing have been studied for decades. Such inequities include editorial board \nselection of the publications, gender, race as well as educational achievements, degrees. For \nexample, Girolamo et al., examined the extent to which various people in the academy were \naffected by the peer review process including faculty retention, and advancement. \u201cExperiences \nof marginalization, including inequity in peer review, may contribute to BIPOC underrepresentation \nin the academy.\u201d17 \nSometimes studies about the same topic that may be done at different times or by tracking \ndifferent variables may have disagreements among findings and conclusions. One study says \noatmeal is good for us because it is high in fiber. Another says too much oatmeal can lead to \ntoo much carbohydrate intake and weight gain. This is not to say either study is false. When \nscreening information derived from higher education, one should examine the schools the \nresearch is tied to and the publications the studies are presented in to make sure these are not \npredatory. Predatory journals are often categorized as publications that require an inordinate \namount of money for a study to be reviewed or ones that instantly publish a study with little or \nno rigorous peer review. \u201cThen came predatory publishers, which publish counterfeit journals \nto exploit the open-access model in which the author pays. These predatory publishers are \ndishonest and lack transparency.\u201d18 Therefore, when examining such studies look carefully at the \nbackgrounds of the researchers to determine what, if any, bias exists in their overall effort to lead \na conversation in their field. Again, gray areas of bias exist all around us. No study is perfect. \nWith the advent of several artificial intelligence (AI) tools including the popular ChatGPT, \none can argue that it falls under the for-profit source since it was created by OpenAI  which is \nheavily funded by Microsoft Corporation. However, when asked about how it sees itself among \nthe seven sources discussed here, ChatGPT said, \u201cAs an AI language model, ChatGPT can \nbe considered an academic source of information. Academic sources are typically created by \nexperts in a particular field, and they are subjected to a rigorous review process by other experts \nin the same field before being published. Similarly, ChatGPT is developed by a team of experts \nin natural language processing and machine learning, and its responses are generated based \non the patterns it has learned from analyzing large amounts of text data.\u201d19\n16 Publish or Perish: What Are Its Consequences? [online]. [2023-02-22]. Available at: <https://www.enago.\ncom/academy/publish-or-perish-consequences/>.\n17 GIROLAMO, T. M.: Inequity in Peer Review in Communication Sciences and Disorders. In American Journal \nof Speech-Language Pathology, 2023, Vol. 31, No. 4, p. 1898. \n18 BEALL, J.: Predatory Publishers Are Corrupting Open Access. In Nature, 2015, Vol. 521, No. 7551, p. 179.\n19 Author\u2019s note: Response to \u201cHow it sees itself among the seven sources discussed here\u201d. (See: ChatGPT. \n(online forum comment). [online]. [2023-02-23]. Available at: <https://chatgpt.com/>.).\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 46\nStudiesWe can perhaps say \u201cacademic\u201d, but also can surmise \u201cfor-profit\u201d which could have some \nbuilt in conflicts of interests within that machine learning, but we also may label AI generated \npublished content in the \u201chidden agenda\u201d source since one may never know how such text \nwas generated if the information does not contain an authentic byline. The jury is out whether \nsuch AI tools can be simply pigeonholed into the academic category as well as whether their \nuse will be widely accepted in the academy. That said, the academic source nevertheless is \nits own and brings to all the seven sources of impartiality its own inherent bias.\n4.2\tFor-Profit\nTurning to For-Profit organizations, one can postulate that it represents the most amount of \nall information most people are exposed to off and on the internet because modern culture is \nprimarily fashioned upon a free enterprise market system. According to the Heritage Foundation\u2019s \n2021 Index of Economic Freedom, which measures the degree of economic freedom in countries \naround the world, there are 161 countries of the 178 recognized by the United Nations that \nhave a mostly free economy, indicating that free enterprise is prevalent.20 However, one also \ncan postulate that individuals now represent the majority of all information found on and off  \nthe internet. \nWith the rise of social media and personal blogs, it has become easier for individuals to \npublish and share their thoughts and opinions with a global audience. Additionally, many news \noutlets and organizations rely on user-generated content, such as eyewitness accounts and \nvideos, to report on events happening around the world. But this is just a general assumption, \nand the actual distribution of information across the seven sources discussed here may \nvary depending on the context and topic being discussed. That said, the goal of for-profit \norganizations is to influence prospects to purchase their product. Therefore, bias is inherent in \ntheir sales techniques. Ford Motor Company  is one example of millions.\nFord is in the business of manufacturing cars. When Ford advertises their products, obviously \ntheir goal is to get people interested in buying them. But like all companies, they should be \nsubject to truth in advertising. They can make claims that are independently verified but should \nnot exaggerate such claims just to make a profit. Throughout the years many automobile \nmanufacturers both domestic and international have been caught exaggerating claims from \nperformance, to gas mileage, to air emission ratings.21 As such, many for-profit companies \ntry to appeal to one\u2019s emotions and overvalue their product to make sales. Therefore, double \ncheck third party reviewers like Consumer Reports that have been shown to have low bias \nand impartiality.22 \nAn example of a study that examined bias of news coverage among for-profit media \ncorporations themselves was conducted by Gilens and Hertzman who analyzed newspaper \ncoverage of the 1996 Telecommunications Act. \u201cWe find substantial differences in how \nnewspapers reported on these proposed regulatory changes depending on the financial interests \nof their corporate owners.\u201d23\n20 MILLER, T., KIM, A. B., ROBERTS, J. M.: 2021 Index of Economic Freedom . [online]. [2023-03-09]. Available \nat: <https://www.heritage.org/index/pdf/2021/book/2021_IndexOfEconomicFreedom_FINAL.pdf>.\n21 BROWN, N.: 20 Car Ads That Totally Lied to Us. [online]. [2023-03-05]. Available at: <https://www.hotcars.\ncom/20-car-ads-that-totally-lied-to-us/>.\n22 Consumer Reports Bias and Credibility. [online]. [2023-05-21]. Available at: <https://mediabiasfactcheck.\ncom/consumer-reports//>.\n23 See: GILENS, M., HERTZMAN, C.: Corporate Ownership and News Bias: Newspaper Coverage of the 1996 \nTelecommunications Act. In The Journal of Politics, 2000, Vol. 62, No. 2, p. 369-386. [online]. [2023-05-\n21]. Available at: <https://www.jstor.org/stable/2647679>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 47\nStudies4.3 Government\nGovernment entities are many. In the United States, for example, there are numerous \nagencies and departments. From the United States Department of Agriculture (USDA) to the \nCenters for Disease Control and Prevention (CDC) to the White House, there are literally dozens \nupon dozens of governmental units, and each publishes mounds of reports, demographics, \nadvisories, studies, research, and warnings.24 Bias within these reports might be tied to lobbyists \nor legislation that is profitable to certain other entities or contain \u201cpork\u201d or \u201cpork-barrel spending\u201d. \n\u201cPork\u201d is extra initiatives and/or funding that typically has nothing to do with a bill\u2019s real purpose. \nFor example, a bill designed to provide homeowners with tax relief in a certain geographic \narea, may also fund other out of state projects. \u201cOne popular U.S. government text defines \npork-barrel legislation as \u2018Appropriations made by legislative bodies for local projects that are \noften not needed but that are created so that local representatives can carry their home district \nin the next election.\u2019 But this definition betrays two important biases about pork. First, while \nappropriations may still be the most important and widely recognized form of pork, it does \ncome in a wider variety of forms than simply direct spending on local projects. Second, while \nthis definition of pork asserts that pork is generally wasteful spending initiated by self-interested \nincumbents using taxpayer dollars to support their own electoral efforts, just how wasteful one \nbelieves pork-barrel legislation is often depends on where one sits.\u201d25\nTherefore, one must inspect underlying forces that require the bill to be created. The same \nholds true for many government reports. One should ask how they were funded, and what \npurpose do they ultimately serve? The statistical data often associated with such reports is \nvulnerable to manipulation. Mark Twain (Samuel Clemens) said more than 100 years ago, \u201cFigures \ndon\u2019t lie, but liars figure\u201d. Bohanon and Curott referred to this famous quote in a 2020 Indiana \nBusiness Journal  article regarding misinterpreted U.S. Economy statistics.26 \nGovernment reports should be rigorous in terms of sample size and proper research method \napplication. So, when assessing these reports pay careful attention to possible bias associated \nwith the politics behind the governmental unit itself. Were these reports influenced by other \nagencies or people who may have censored some of the information after or prior to its release? \nGovernmental agency reports are sometimes produced to enhance their own hidden agendas. \nThey can generate reports they do not want the public to even know about. Jesse Ventura, \na former independent governor of Minnesota, wrote about these reports in his co-authored \nSimon & Schuster book, 63 Documents the Government Doesn\u2019t Want You to Read.27 However, \nin other instances, the government has a right to keep secrets such as nuclear codes, military \nplans, and those in the best interest of national security.\nTherefore, it is important one rigorously reviews such government data. When vetting these \nkinds of reports, closely examine the legislation that might have originally been created to yield \ngovernmental studies and laws. Do these reports reflect more facts rather than opinion? For \nexample, according to a Washington Post  investigative piece, U.S. officials misled the public \nabout the War in Afghanistan for many years via a variety of government documents the paper \nobtained.28\n24 The U.S. Government\u2019s Official Web Portal. [online]. [2023-05-21]. Available at: <https://www.usa.gov/>.\n25 BECKER, L.: Pork-Barrel Expenditures. [online]. [2023-05-21]. Available at: <https://search.credoreference.\ncom/content/entry/fofgac/pork_barrel_expenditures/0>.\n26 BOHANON, C., CUROTT, N.: Tossing Around Statistics Can Quickly Lead to Trouble. In Indianapolis Business \nJournal , 2020, Vol. 41, No. 24, no paging. [online]. [2023-05-21]. Available at: <https://link.gale.com/apps/\ndoc/A633726700/ITBC?u=uphoenix&sid=ebsco&xid=54ea4032>.\n27 See: VENTURA, J., RUSSELL, D.: 63 Documents That Government Doesn\u2019t Want You to Read. New York, \nNY : Skyhorse Imprint of Simon & Schuster, 2021.\n28 WHITLOCK, C.: At War with the Truth. [online]. [2022-12-09]. Available at: <https://www.washingtonpost.\ncom/graphics/2019/investigations/afghanistan-papers/afghanistan-war-confidential-documents/>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 48\nStudiesAnother example that examined the credibility of government sources was published in \na 2022 edition of Crain\u2019s Chicago Business. According to the journal, government sources \nwere among the least trusted as well as journalist when compared to scientists and their \nown coworkers. \u201cThe 22nd annual Trust Barometer survey, which includes more than 36,000 \nrespondents across 28 countries, shows that government institutions were the most trusted \nsource as recently as May 2020. But since then, trust in government has fallen 18 points to \n52%.\u201d29 These examples demonstrate how government information is its own unique type \nof source with its own unique type of credibility, such trust among the public appears to be \nwaning. When government intertwines with for profits or nonprofits, it also can contain some \nhidden agendas like pork as discussed.\n4.4 Hidden Agenda Groups\nHidden Agenda Groups purport to represent one or several causes, but covertly may \nrepresent one or several nefarious undertakings. The information they distribute may be hard \nto track to a single person or agency. They also may be hard to contact since they really are \nnot in the business of being transparent. Nor do hidden agendas provide accurate information. \nGroups like QAnon who magnify and circulate conspiracy theories are identified as a hidden \nagenda group. QAnon also recruits prominent people in power who might use the information to \namplify their messages, to further their own hidden agendas, to enhance their political standing, \nor to simply bolster their careers.30 Some of these entities are found in the form of apps, or \ndangerous computer code masquerading as a friendly game, or a website whose users were \ndrawn there by misleading search engine descriptions. \nMore recently, TikTok, the popular video sharing application, was accused of allegedly \ncollecting and distributing user data for political or other possible nefarious purposes.31 \nApplications have less impactful hidden agendas that may include buying or selling user data. \nFor example, Facebook, Google, and LinkedIn, have been accused of violating user privacy \npolicies. In Facebook \u2019s case, a company known as Cambridge Analytics knowingly used the \nsocial media giant\u2019s database of users for their own hidden agenda purposes. \u201cAs Facebook \nreeled, The New York Times delved into the relationship between Cambridge Analytica and John \nBolton, the conservative hawk named national security adviser by President Trump. The Times \nbroke the news that in 2014, Cambridge provided Mr. Bolton\u2019s \u2018super PAC\u2019 with early versions of \nits Facebook-derived profiles \u2013 the technology\u2019s first large-scale use in an American election.\u201d32\nQuite simply put, you may not ever be able to judge the bias in these groups\u2019 materials \nbecause their materials are designed to be deceptive like propaganda. They may look like a \ngame or a traditional website that portrays that they represent a good cause but underneath \nthey are funneling data or revenue for another purpose. In sum, we need to be aware that hidden \nagendas and hidden agenda groups are out there. In a worst-case scenario, if we accidentally \nparaphrase or quote them, we may be perpetuating their self-interests as our own. From \nanonymous posts, to protected sources, there is a fine line to how hidden agendas are carried \n29 DAVIS, K.: Government Officials, Journalists Least-Trusted Sources, Says Survey. [online]. [2023-05-21]. Available \nat: <https://search.ebscohost.com/login.aspx?direct=true&AuthType=shib&db=edsbig&AN=edsbig.\nA690654628&site=eds-live&scope=site&custid=uphoenix>.\n30 KUZNIA, R., DEVINE, C., GRIFFIN, D.: How QAnon\u2019s Lies Are Hijacking the National Conversation. [online]. \n[2023-05-21]. Available at: <https://www.cnn.com/2020/12/15/us/qanon-trump-twitter-invs/index.html>.\n31 MCMILLAN, R., LIN, L., LI, S.: Tiktok User Data: What Does the App Collect and Why Are U.S. Authorities \nConcerned? [online]. [2023-03-09]. Available at: <https://www.wsj.com/articles/tiktok-user-data-what-\ndoes-the-app-collect-and-why-are-u-s-authorities-concerned-11594157084>.\n32 CONFESSORE, N.: Cambridge Analytica and Facebook: The Scandal and Fallout So Far. [online]. [2023-03-\n09]. Available at: <https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.\nhtml>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 49\nStudiesout. It is sufficed to say hidden agendas exist for a multitude of purposes, uses and gratifications, \nincluding the spread of fake news and other viral internet messages with no authentication. Some \npeople are more susceptible to these messages that ultimately affect society\u2019s overall ability to \ncontribute constructively to civil discourse. As Reader noted, civility means politeness in terms \nof discourse. Uncivil people sow mistrust and can anger those susceptible to manipulation. \nOnly known processes and facts can be legitimately and openly debated.\nReader examined anonymous comments posted to news media websites for their \u201ccivility\u201d. \nUsing Condit\u2019s theory that contends good public debates are not only represented by those in \npower or who are otherwise transparent but can include those who choose to be anonymous. \n\u201cThe framework seems especially suitable for a critical analysis of the issue of anonymous \ncommentary online, as the forums themselves are (ostensibly) intended to be locations for \npluralistic debate on all manner of issues \u2013 thus, the regulation of those forums might need to \nbe even more accommodating of varied minority viewpoints, including viewpoints that may be \nconsidered on the fringes of acceptability.\u201d33\nGenerally, the study highlighted the role of anonymous, otherwise hidden agendas, in \nshaping perceptions of important debate. This is where it is significant to note how crucial it \nis that people inspect information for its objectivity, its inclusion of other sources to defend \nsuppositions, for example, and the level of transparency it portrays. Enter critical thinking and \nefforts made to encourage media literacy skills to help individuals make more informed decisions \nand resist misinformation and conspiracy theories. Thus, this type of bias, Hidden Agenda, can \nbe disguised as any individual or group of individuals whose covert opinions or behaviors may \nbe the opposite of their overt actions since their posted discourse cannot typically be verified.\n4.5 Individuals\nIndividuals are categorized into their own group simply because they can publish, share, and \ndistribute information that they or others create just like any of the other six sources discussed \nin this paper. Independence lends itself to personal bias overtly or covertly tied to a hidden \nagenda. The only way to fairly assess any level of individual bias is to assess ethos, the Greek \nrhetorical style that involves evaluating the background, credibility, or character of the writer \nor speaker. To that degree one can examine conflicts of interests that could allow the reader \nto speculate or judge the piece as bias.\nSeveral studies have identified ethos, as well as its counterparts, pathos (emotion), kairos \n(timeliness), logos (reasoning, logic) and mythos (symbolic and ritual cultural enactments) \nembedded in such discourse. In 2022, Iob, Visintin, and Palese examined editorials published \nby five major nursing journals and found that approximately 25 percent of the persuasiveness \nwas attributed to author ethos, another 25 percent to pathos, and about half dedicated to \nlogos. \u201cAristotle links Ethos to the orator, namely, the speaker or author of written texts, to their \ncredibility as a speaker. Using Ethos, authors assert their moral position, promoting full trust and \nrespect from readers (Lo Cascio, 1991).\u201d34  However, the authors maintain readers are more \nopen minded to the discourse first than the background of the author.\nAccording to Bizzell and Herzberg as well as many other Aristotle scholars, pathos is an \nemotional appeal typically related to an argument.35 Combined with ethos, pathos resonates \nas the psychological connection between author and reader. For example, Steven Spielberg is \n33 READER, B.: Free Press vs. Free Speech? The Rhetoric of \u2018Civility\u2019 in Regard to Anonymous Online \nComments. In Journalism & Mass Communication Quarterly, 2012, Vol. 89, No. 3, p. 499.\n34 See: IOB, G., VISINTINI, C., PALESE, A.: Persuasive Discourses in Editorials Published by the Top\u2010Five \nNursing Journals: Findings from a 5\u2010Year Analysis. In Nursing Philosophy, 2022, Vol. 23, No. 2, p. 2. \n35 See: BIZZELL, P ., HERZBERG, B.: The Rhetorical Tradition: Readings from Classical Times to the Present.  \nBoston, MA, New York, NY : Bedford/St. Martin\u2019s, 2021.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 50\nStudiesJewish. He had family members in the Holocaust. He directed and produced the award winning \n1993 movie Schindler\u2019s List. Spielberg\u2019s ethos and expression of pathos was fundamental to \ncreating a film that resonated with people from many religious sects. His attention to script \ndetails enabled him to connect with his audience.\nMythos is like ethos, but instead of being built upon the writer\u2019s entire background, it is \nan ongoing set of assumptions, values, or beliefs about a particular field of study, or specific \nissue. Richards describes the rhetorical style this way, \u201cThe dominant mythos of a culture is \nexpressed in its arts, literature, values, aspirations and rituals, providing individuals with the \nresources for interpreting and expressing their emotional lives and relationships with others .\u201d36 \nFinally, kairos is defined as \u201cthe opportune moment of speech, which involves not only the \nfitting occasion but also the fitting style and the fitting composition.\u201d37 Most experienced social \nmedia users have seen posts whose friends or connections have shared what they thought \nwas timely information only upon closer inspection to discover just how outdated the material \nwas in support of an argument. This is not to say outdated information is not valid, it is to say \nthere could be newer more rigorous data available.\nAll published information can be said to contain any degree of these Greek rhetorical styles. \nWe could arrange these styles in an easy to remember acronym such as KLEMP: kairos, logos, \nethos, mythos, and logos. By examining the credibility of the author and possible conflicts \nof interest, the published piece may be said to contain some bias.38 By the very virtue of \nindividual\u2019s abilities to contribute to public discourse they too represent an overall partiality \nthat upon inspection holds them accountable to their ethos, their credibility, objectivity, values, \ntransparency, and authenticity. As such individuals\u2019 perspectives and biases present can range \nfrom hidden agendas to conflicts of interest, but that one\u2019s ethos can enhance a piece of \ninformation by including that author\u2019s experience or expertise.\n4.6\tNon-Profit\nNon-Profits are either public charities, philanthropic foundations, or an enterprise that \nserves individuals, industry, or education. Examples include churches, shrines, and synagogues \nas well as governments, some business associations, municipalities, and other community \nenterprises. The Young Men\u2019s Christian Association  (YMCA), American Foundation for Suicide \nPrevention, the American Marketing Association , and the United Negro College Fund , have \nbeen reliable examples of popular non-profits. It is important to vet all publicized information \npertaining to non-profits by carefully examining any claims they make about where funds \nare distributed and if their actions align with the values they publicize, yet like any of the \nother six sources of over partiality, they too can emulate bias tied to any subject or cause \nthey may represent.\nLittle is known as to the level of nonprofit bias in communications, but a recent study \nexamined how one Kenya based nonprofit strived to remove bias from its own messaging. \nNEW STORIES Room to Read, is an international nonprofit that teaches children to read. \n36 RICHARDS, G.: Mythos and Logos. In RIEBER, R. W. (ed.): Psychology, Religion, and the Nature of the Soul. \nNew York, NY : Springer, 2011, p. 9.\n37 KINNEAVY, J. L., ESKIN, C. R.: Kairos in Aristotle\u2019s \u201cRhetoric\u201d. In\u00a0 Written Communication,\u00a02000, Vol. 17, \nNo. 3, p. 432.\n38 BEAN, E.: Weeding Out Suspect Bias Using the Greek Rhetorical Styles of KLEMP in Social Media and News \nStories. Presented at the 2022 National Council of Teachers of English Homecoming Conference. Louisville, \nKY, presented on 31st July, 2022. [online]. [2023-05-21]. Available at: <https://img1.wsimg.com/blobby/\ngo/fd10a2bf-629c-4c87-b041-43eb2af8f6a0/downloads/NCTE_2022ELATEHomecoming_Program.\npdf?ver=1684858591632>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 51\nStudies\u201cGeographically imprecise terms force people to make assumptions, and they often reflect and \nperpetuate bias by defining complex communities with singular perspectives.\u201d39\nAs a distinct type of source nonprofits can imbued impartiality for their own benefit and \ncauses regardless of what they represent and therefore, are unique among the other six sources \nidentified.\n4.7 Watchdog Groups\nThe purpose of watchdog groups is to monitor other groups by employing checks and \nbalances approach. They measure the value these groups hold for humanity. For example, \nPeople for the Ethical Treatment of Animals (PETA) helps spread awareness about animal safety \nand wellbeing and others like the Gun Violence Archive  (GVA) track incidents of gun violence \nacross America. Others track water resources such as the Environmental Working Group.40 \nWatchdog groups may contain any number of biases or hidden agendas as well that could \npossibly lead people to follow a false cause if they are not authentic or transparent in their \npublished communications. Most watchdog groups are organized as non-profits and provide a \nphilanthropic approach to their public value. Like any nonprofit one should scrutinize watchdogs \nto be sure they are legitimate. \u201cA nonprofit watchdog \u2013 also called a charity watchdog (CWD) or \nnonprofit evaluator \u2013 refers to a type of nonprofit organization that exists to gather and provide \ninformation, reviews, and ratings of other nonprofit organizations. These organizations are not \nassociated with the government, as each is an independent, nonprofit group of its own.\u201d41\nWatchdogs, while organized as nonprofits, can have biases that tie them to their own \nunique impartiality. But watchdogs, nevertheless, are grouped differently from the other six \ndiscussed, a source that as suggested earlier in this paper, should be first analyzed as such \nwhen inspecting any piece of information that one finds or appears in their newsfeed or in social \nmedia. The inspection can be something as simple as identifying the author and their affiliation, \nthe medium in which the piece of information is published, and its intended original audience.\n5 Conclusion\nThe seven sources of overall impartiality discussed in this paper have their unique biases \nthat are typically tied to their mission and purpose. Yes, it is possible that when evaluating any \npiece of information, it might be found that it can be tied to more than one of these sources \nas well as other types of biases baked into it which makes critically thinking about information \nsuch an important step in subscribing to or sharing such information. The stakes are high \nfor not properly vetting information and while the merits of traditional types of bias such as \npersonal explicit and implicit prejudice, and other types of biases more related to information \nsuch as confirmation, affinity, halo, and anchoring bias, are important types, these seven types \nof sources represent their overall bias impartiality that hold them accountable to authentic and \nobjective information when they publish any piece of information. \n39 MURALI, G., HEGRANES, C.: Charity\u2019s Guide Helps Nonprofits Use More Equitable Language. In Chronicle of \nPhilanthropy, 2022, Vol. 34, No. 7, no paging. [online]. [2023-05-21]. Available at: <https://www.philanthropy.\ncom/article/using-dignified-language-unseats-bias-and-advances-equity>.\n40 BOTE, J.: Toxic \u2018Forever Chemicals\u2019 Found in Drinking Water Throughout US. [online]. [2023-05-21]. https://\nwww.philanthropy.com/article/using-dignified-language-unseats-bias-and-advances-equity Available \nat: <https://www.usatoday.com/story/news/health/2020/01/23/pfas-toxic-forever-chemicals-found-\ndrinking-water-throughout-us/4540909002/>.\n41 What Executive Directors Need to Know About Nonprofit Watchdogs. [online]. [2023-05-21]. Available at: \n<https://www.growthforce.com/blog/nonprofit-watchdogs>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 52\nStudiesMore importantly the seven sources of bias discussed here within represent all the possible \nhigh level first types of sources for which all other biases types like fallacies, for example, might \nbe later found upon further inspection. This alone is an important factor that all who may employ \nCRAAP or SIFT as an evaluation tool should be aware. The seven initial prominent sources of \nall information bias impartiality types rest on parsing them in the initial evaluative process, a \nfirst step in critically thinking about information, who created it and its ultimate purpose. No one \ncan control how people initially interact with information. Whether they succumb to information \nserved to them by an algorithm or they search for information, parsing it into one or more of \nthese seven sources is a step in the right bias analysis recognition direction. \nLiterature and Sources:\nBAUM, M. A.: Sex, Lies, and War: How Soft News Brings Foreign Policy to the Inattentive Public. \nIn American Political Science Review , 2002, Vol. 96, No. 1, p. 91-109. ISSN 1537-5943. DOI: \n<https://doi.org/10.1017/S0003055402004252>.\nBEALL, J.: Predatory Publishers Are Corrupting Open Access. In Nature, 2012, Vol. 489, No. \n7451, p. 179. ISSN 1476-4687. DOI: <https://doi.org/10.1038/489179a>.\nBEAN, E.: Analyzing Information for Bias Is All Around You.  Presented at the 2022 JEA/NSPA, \nNational High School Journalism Convention. St. Louis, presented on 12th November 2022. \n[online]. [2023-05-21]. Available at: <https://studentpress.org/wp-content/uploads/2022/10/\nprogram.NHSJC.NF22.101922.pdf>. \nBEAN, E.: Weeding Out Suspect Bias Using the Greek Rhetorical Styles of KLEMP in Social Media \nand News Stories. Presented at the 2022 National Council of Teachers of English Homecoming \nConference. Louisville, KY, presented on 31st July, 2022. [online]. [2023-05-21]. Available at: \n<https://img1.wsimg.com/blobby/go/fd10a2bf-629c-4c87-b041-43eb2af8f6a0/downloads/\nNCTE_2022ELATEHomecoming_Program.pdf?ver=1684858591632>.\nBIZZELL, P ., HERZBERG, B.: The Rhetorical Tradition: Readings from Classical Times to the \nPresent. Boston, MA, New York, NY : Bedford/St. Martin\u2019s, 2021.\nBOHANON, C., CUROTT, N.: Tossing Around Statistics Can Quickly Lead to Trouble. \nIn Indianapolis Business Journal, 2020, Vol. 41, No. 24, no paging. ISSN 0274-4929. \n[online]. [2023-05-21]. Available at: <https://link.gale.com/apps/doc/A633726700/\nITBC?u=uphoenix&sid=ebsco&xid=54ea4032>.\nBOTE, J.: Toxic \u2018Forever Chemicals\u2019 Found in Drinking Water Throughout US. [online]. [2023-\n05-21]. Available at: <https://www.usatoday.com/story/news/health/2020/01/23/pfas-toxic-\nforever-chemicals-found-drinking-water-throughout-us/4540909002/>.\nBROWN, N.: 20 Car Ads That Totally Lied to Us. [online]. [2023-03-05]. Available at: <https://\nwww.hotcars.com/20-car-ads-that-totally-lied-to-us/>.\nBURKHOLDER, J. M., PHILLIPS, K.: Breaking Down Bias: A Practical Framework for the \nSystematic Evaluation of Source Bias. In Journal of Information Literacy , 2022,  Vol. 16, No. 2, \np. 53-68. ISSN 1750-5968. DOI: <https://doi.org/10.11645/16.2.3100>.\nBUSH, V.: As We May Think. In The Atlantic Monthly, 1945, Vol. 176, No. 1, p. 101-108. ISSN \n1072-7825.\nCAULFIELD, M.: SIFT (The Four Moves) . [online]. [2023-02-09]. Available at: <https://hapgood.\nus/2019/06/19/sift-the-four-moves/>.\nChatGPT . (online forum comment). [online]. [2023-02-23]. Available at: <https://chatgpt.com/>.\nCONFESSORE, N.: Cambridge Analytica and Facebook: The Scandal and Fallout So Far. [online]. \n[2023-03-09]. Available at: <https://www.nytimes.com/2018/04/04/us/politics/cambridge-\nanalytica-scandal-fallout.html>.\nConsumer Reports Bias and Credibility. [online]. [2023-05-21]. Available at: <https://\nmediabiasfactcheck.com/consumer-reports//>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 53\nStudiesCROTEAU, D. M., HOYNES, W.: Media/Society: Industries, Images, and Audiences. London, \nNew York, Thousand Oaks : Sage Publications, 2016.\nDATTA, P ., WHITMORE, M., NWANKPA, J. K.: A Perfect Storm: Social Media News, Psychological \nBiases, and AI. In Digital Threats: Research and Practice, 2021, Vol. 2, No. 2, p. 15:1-15:21. \nISSN 2576-5337. DOI: < https://doi.org/10.1145/3428157 >.\nDAVIS, K.: Government Officials, Journalists Least-Trusted Sources, Says \nSurvey. [online]. [2023-05-21]. Available at: <https://search.ebscohost.com/login.\naspx?direct=true&AuthType=shib&db=edsbig&AN=edsbig.A690654628&site=eds-live&scop\ne=site&custid=uphoenix>.\nENTMAN, R. M.: Modern Racism and the Images of Blacks in Local Television News. In Critical \nStudies in Media Communication, 1990, Vol. 7, No. 4, p. 332-345. ISSN 0739-3180. DOI: \n<https://doi.org/10.1080/15295039009360183>.\nGILENS, M., HERTZMAN, C.: Corporate Ownership and News Bias: Newspaper Coverage of \nthe 1996 Telecommunications Act. In The Journal of Politics , 2000, Vol. 62, No. 2, p. 369-386. \nISSN 0022-3816. [online]. [2023-05-21]. Available at: <https://www.jstor.org/stable/2647679>.\nGIROLAMO, T. M.: Inequity in Peer Review in Communication Sciences and Disorders. In \nAmerican Journal of Speech-Language Pathology, 2023, Vol. 31, No. 4, p. 1898-1912. ISSN \n1558-9110. DOI: <https://doi.org/10.1044/2022_AJSLP-21-00252>.\nHERMAN, E. S., CHOMSKY, N.: Manufacturing Consent: The Political Economy of the Mass \nMedia. New York, NY : Pantheon Books, 1988.\nIOB, G., VISINTINI, C., PALESE, A.: Persuasive Discourses in Editorials Published by the Top\u2010\nFive Nursing Journals: Findings from a 5\u2010Year Analysis. In Nursing Philosophy, 2022, Vol. 23, \nNo. 2, p. 1-9. ISSN 1466-769X. DOI: <https://doi.org/10.1111/nup.12378>.\nJAMIESON, K. H., WALDMAN, P .: The Press Effect: Politicians, Journalists, and the Stories That \nShape the Political World. Oxford : Oxford University Press, 2004.\nJAYES, L. T. et al.: The Impact of Hyperlinks, Skim Reading and Perceived Importance When \nReading on the Web. [online]. [2023-05-21]. Available at: <https://doi.org/10.1371/journal.\npone.0263669>.\nKINNEAVY , J. L., ESKIN, C. R.: Kairos in Aristotle\u2019s \u201cRhetoric\u201d. In Written Communication, 2000, \nVol. 17, No. 3, p. 432-444. ISSN 0741-0883.\nKUZNIA, R., DEVINE, C., GRIFFIN, D.: How QAnon\u2019s Lies Are Hijacking the National Conversation.  \n[online]. [2023-05-21]. Available at: <https://www.cnn.com/2020/12/15/us/qanon-trump-twitter-\ninvs/index.html>.\nMCMILLAN, R., LIN, L., LI, S.: Tiktok User Data: What Does the App Collect and Why Are U.S. \nAuthorities Concerned? [online]. [2023-03-09]. Available at: <https://www.wsj.com/articles/tiktok-\nuser-data-what-does-the-app-collect-and-why-are-u-s-authorities-concerned-11594157084>.\nMILLER, T., KIM, A. B., ROBERTS, J. M.: 2021 Index of Economic Freedom. [online]. [2023-03-09]. \nAvailable at: <https://www.heritage.org/index/pdf/2021/book/2021_IndexOfEconomicFreedom_\nFINAL.pdf>.\nMURALI, G., HEGRANES, C.: Charity\u2019s Guide Helps Nonprofits Use More Equitable Language. \nIn Chronicle of Philanthropy,  2022, Vol. 34, No. 7, no paging. ISSN 1040-676X. [online]. [2023-\n05-21]. Available at: <https://www.philanthropy.com/article/using-dignified-language-unseats-\nbias-and-advances-equity>.\nPublish or Perish: What Are Its Consequences? [online]. [2023-02-22]. Available at: <https://\nwww.enago.com/academy/publish-or-perish-consequences/>.\nRANGANATHAN, S. R.: The Five Laws of Library Science. Madras : Madras Library Association, \n1931.\nREADER, B.: Free Press vs. Free Speech? The Rhetoric of \u2018Civility\u2019 in Regard to Anonymous \nOnline Comments. In Journalism & Mass Communication Quarterly, 2012, Vol. 89, No. 3, p. \n495-513. ISSN 1077-6990. DOI: <https://doi.org/10.1177/1077699012447923>.\nMedia Literacy and Academic R esearch | Vol. 6, No. 1, June 2023\n page 54\nStudiesThe U.S. Government\u2019s Official Web Portal.  [online]. [2023-05-21]. Available at: <https://www.\nusa.gov/>.\nRICHARDS, G.: Mythos and Logos. In RIEBER, R. W. (ed.): Psychology, Religion, and the \nNature of the Soul. New York, NY : Springer, 2011, p. 9-11. DOI: <https://doi.org/10.1007/978-\n1-4419-7173-9_2>.\nVENTURA, J., RUSSELL, D.: 63 Documents That Government Doesn\u2019t Want You to Read. New \nYork City, NY : Skyhorse Imprint of Simon & Schuster, 2021.\nVetting. [online]. [2023-02-22]. Available at: <https://www.dictionary.com/browse/vetting?s=t>.\nWhat Executive Directors Need to Know About Nonprofit Watchdogs. [online]. [2023-05-21]. \nAvailable at: <https://www.growthforce.com/blog/nonprofit-watchdogs>.\nWHITLOCK, C.: At War with the Truth. [online]. [2022-12-09]. Available at: <https://www.\nwashingtonpost.com/graphics/2019/investigations/afghanistan-papers/afghanistan-war-\nconfidential-documents/>.\nWINEBURG, S., MCGREW, S., BREAKSTONE, J., ORTEGA, T.: Evaluating Information: The \nCornerstone of Civic Online Reasoning. Stanford Digital Repository. Stanford, CA : Stanford \nUniversity, 2019. [online]. [2022-11-15]. Available at: <https://purl.stanford.edu/fv751yt5934>.\nAuthor\nErik Bean, Ed.D., holds a master\u2019s degree in journalism and a doctorate in education. Currently he is an \nEnglish teacher at St. Catherine of Siena Academy in Suburban Detroit. He also is an associate research \nchair for The Center for Leadership Studies at the University of Phoenix where he serves as the Leadership \nPerspectives section editor of The Journal of Leadership Studies. Bean has 25 years of experience teaching \nEnglish composition, journalism, film studies, humanities, cyber communications, critical thinking, and \ntechnical writing. He has taught at Wayne County Community College, Berkley Public Schools, and served \nas an associate professor of arts & humanities at American Public University as well as authored numerous \ninnovative academic books for teachers and students including Social Media Writing Lesson Plans . In 2019 \nhe co-wrote Ethan\u2019s Healthy Mind Express , a picture book that placed 2nd in education and illustrations \nfrom the 2020 Royal Dragonfly Children\u2019s Literature contest. It features lessons on inclusion, neurodiversity, \nand internet safety. His most recent effort is entitled, Bias Is All Around You: A Handbook for Inspecting \nSocial Media & News Stories. In the summer of 2022, he earned a Henry Ford Innovation Nation First Place \nTeacher award for information literacy studies used in the classroom. Information literacy is the focus of \nhis most recent presentations at the 2022 JEA/NSPA Fall National High School Journalism Convention, the \n2022 National Council of Teachers of English ELATE Home Coming Conference, and the 2022 Qualitative \nReport Conference. In 2018 he also presented a paper on fake ads masquerading as news at the Internet, \nPolitics, & Policy: Long Live Democracy, symposium, University of Oxford. He also serves as the Michigan \nrepresentative for Media Literacy Now.Erik Bean, Ed.D.\nUniversity of Phoenix\nCenter for Leadership Studies & Organizational Research\nPhoenix, AZ \nUSA\nORCID ID:  https://orcid.org/0000-0003-4731-2135\n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Seven Initial Prominent Sources of All Information Bias Impartiality Types Parsed", "author": ["E Bean"], "pub_year": "2023", "venue": "Media Literacy and Academic Research", "abstract": "Ever since information was first operationalized by library science into consumer formats,  media bias has been studied from the purview of information gatekeepers who decide what,"}, "filled": false, "gsrank": 48, "pub_url": "https://www.ceeol.com/search/article-detail?id=1129816", "author_id": ["h4eY1NMAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:PgssrlJTqlsJ:scholar.google.com/&output=cite&scirp=47&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D40%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=PgssrlJTqlsJ&ei=C7WsaMuIJazWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:PgssrlJTqlsJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://bibliotekanauki.pl/articles/52494951.pdf"}}]